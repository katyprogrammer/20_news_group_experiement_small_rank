Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.127s
  training loss:		2.864913
  validation loss:		2.665724
  validation accuracy:		8.80 %
Epoch 2 of 2000 took 0.113s
  training loss:		2.710379
  validation loss:		2.534880
  validation accuracy:		10.98 %
Epoch 3 of 2000 took 0.122s
  training loss:		2.610443
  validation loss:		2.426714
  validation accuracy:		12.17 %
Epoch 4 of 2000 took 0.113s
  training loss:		2.498035
  validation loss:		2.329688
  validation accuracy:		14.35 %
Epoch 5 of 2000 took 0.121s
  training loss:		2.404198
  validation loss:		2.256692
  validation accuracy:		15.65 %
Epoch 6 of 2000 took 0.116s
  training loss:		2.334517
  validation loss:		2.230051
  validation accuracy:		18.59 %
Epoch 7 of 2000 took 0.113s
  training loss:		2.290870
  validation loss:		2.216846
  validation accuracy:		21.09 %
Epoch 8 of 2000 took 0.121s
  training loss:		2.261849
  validation loss:		2.195415
  validation accuracy:		24.35 %
Epoch 9 of 2000 took 0.116s
  training loss:		2.243214
  validation loss:		2.180685
  validation accuracy:		25.76 %
Epoch 10 of 2000 took 0.115s
  training loss:		2.227202
  validation loss:		2.166527
  validation accuracy:		29.35 %
Epoch 11 of 2000 took 0.114s
  training loss:		2.214468
  validation loss:		2.148941
  validation accuracy:		32.83 %
Epoch 12 of 2000 took 0.116s
  training loss:		2.196220
  validation loss:		2.130985
  validation accuracy:		34.67 %
Epoch 13 of 2000 took 0.125s
  training loss:		2.181564
  validation loss:		2.119693
  validation accuracy:		36.63 %
Epoch 14 of 2000 took 0.115s
  training loss:		2.166360
  validation loss:		2.094622
  validation accuracy:		37.17 %
Epoch 15 of 2000 took 0.106s
  training loss:		2.150088
  validation loss:		2.089364
  validation accuracy:		38.80 %
Epoch 16 of 2000 took 0.106s
  training loss:		2.130440
  validation loss:		2.061586
  validation accuracy:		40.11 %
Epoch 17 of 2000 took 0.106s
  training loss:		2.107773
  validation loss:		2.038265
  validation accuracy:		43.48 %
Epoch 18 of 2000 took 0.106s
  training loss:		2.084135
  validation loss:		2.015280
  validation accuracy:		43.48 %
Epoch 19 of 2000 took 0.107s
  training loss:		2.056076
  validation loss:		1.972771
  validation accuracy:		46.09 %
Epoch 20 of 2000 took 0.106s
  training loss:		2.027074
  validation loss:		1.948735
  validation accuracy:		48.48 %
Epoch 21 of 2000 took 0.106s
  training loss:		1.992545
  validation loss:		1.910581
  validation accuracy:		48.48 %
Epoch 22 of 2000 took 0.105s
  training loss:		1.956766
  validation loss:		1.863565
  validation accuracy:		50.98 %
Epoch 23 of 2000 took 0.110s
  training loss:		1.920906
  validation loss:		1.843064
  validation accuracy:		50.00 %
Epoch 24 of 2000 took 0.105s
  training loss:		1.872755
  validation loss:		1.776495
  validation accuracy:		52.61 %
Epoch 25 of 2000 took 0.105s
  training loss:		1.827003
  validation loss:		1.729375
  validation accuracy:		55.00 %
Epoch 26 of 2000 took 0.105s
  training loss:		1.777098
  validation loss:		1.674181
  validation accuracy:		58.48 %
Epoch 27 of 2000 took 0.105s
  training loss:		1.723237
  validation loss:		1.618722
  validation accuracy:		60.00 %
Epoch 28 of 2000 took 0.105s
  training loss:		1.672228
  validation loss:		1.574021
  validation accuracy:		61.30 %
Epoch 29 of 2000 took 0.105s
  training loss:		1.619901
  validation loss:		1.512756
  validation accuracy:		62.39 %
Epoch 30 of 2000 took 0.105s
  training loss:		1.563442
  validation loss:		1.452415
  validation accuracy:		64.57 %
Epoch 31 of 2000 took 0.105s
  training loss:		1.508800
  validation loss:		1.393009
  validation accuracy:		63.80 %
Epoch 32 of 2000 took 0.109s
  training loss:		1.446914
  validation loss:		1.337759
  validation accuracy:		66.85 %
Epoch 33 of 2000 took 0.106s
  training loss:		1.394181
  validation loss:		1.305258
  validation accuracy:		67.17 %
Epoch 34 of 2000 took 0.105s
  training loss:		1.337746
  validation loss:		1.230198
  validation accuracy:		68.59 %
Epoch 35 of 2000 took 0.105s
  training loss:		1.293870
  validation loss:		1.185746
  validation accuracy:		68.91 %
Epoch 36 of 2000 took 0.105s
  training loss:		1.239132
  validation loss:		1.146458
  validation accuracy:		69.89 %
Epoch 37 of 2000 took 0.105s
  training loss:		1.191727
  validation loss:		1.095594
  validation accuracy:		70.54 %
Epoch 38 of 2000 took 0.106s
  training loss:		1.142394
  validation loss:		1.052452
  validation accuracy:		71.41 %
Epoch 39 of 2000 took 0.105s
  training loss:		1.094512
  validation loss:		1.014722
  validation accuracy:		71.96 %
Epoch 40 of 2000 took 0.105s
  training loss:		1.046852
  validation loss:		0.978326
  validation accuracy:		73.15 %
Epoch 41 of 2000 took 0.105s
  training loss:		1.004388
  validation loss:		0.939405
  validation accuracy:		74.02 %
Epoch 42 of 2000 took 0.110s
  training loss:		0.976203
  validation loss:		0.907110
  validation accuracy:		73.80 %
Epoch 43 of 2000 took 0.105s
  training loss:		0.935167
  validation loss:		0.876644
  validation accuracy:		74.35 %
Epoch 44 of 2000 took 0.105s
  training loss:		0.907707
  validation loss:		0.841933
  validation accuracy:		74.35 %
Epoch 45 of 2000 took 0.105s
  training loss:		0.860829
  validation loss:		0.824528
  validation accuracy:		74.67 %
Epoch 46 of 2000 took 0.105s
  training loss:		0.837083
  validation loss:		0.806405
  validation accuracy:		74.89 %
Epoch 47 of 2000 took 0.105s
  training loss:		0.806183
  validation loss:		0.764431
  validation accuracy:		76.74 %
Epoch 48 of 2000 took 0.100s
  training loss:		0.783107
  validation loss:		0.733238
  validation accuracy:		77.39 %
Epoch 49 of 2000 took 0.100s
  training loss:		0.752147
  validation loss:		0.718652
  validation accuracy:		77.93 %
Epoch 50 of 2000 took 0.096s
  training loss:		0.729539
  validation loss:		0.688777
  validation accuracy:		78.59 %
Epoch 51 of 2000 took 0.098s
  training loss:		0.720570
  validation loss:		0.671518
  validation accuracy:		78.80 %
Epoch 52 of 2000 took 0.102s
  training loss:		0.691150
  validation loss:		0.659598
  validation accuracy:		79.24 %
Epoch 53 of 2000 took 0.095s
  training loss:		0.671292
  validation loss:		0.651968
  validation accuracy:		79.57 %
Epoch 54 of 2000 took 0.096s
  training loss:		0.653332
  validation loss:		0.653514
  validation accuracy:		79.13 %
Epoch 55 of 2000 took 0.095s
  training loss:		0.642114
  validation loss:		0.614112
  validation accuracy:		81.74 %
Epoch 56 of 2000 took 0.096s
  training loss:		0.628202
  validation loss:		0.600808
  validation accuracy:		81.85 %
Epoch 57 of 2000 took 0.100s
  training loss:		0.614370
  validation loss:		0.582640
  validation accuracy:		82.50 %
Epoch 58 of 2000 took 0.095s
  training loss:		0.597985
  validation loss:		0.595048
  validation accuracy:		81.52 %
Epoch 59 of 2000 took 0.096s
  training loss:		0.590555
  validation loss:		0.579425
  validation accuracy:		82.17 %
Epoch 60 of 2000 took 0.102s
  training loss:		0.578462
  validation loss:		0.568032
  validation accuracy:		82.50 %
Epoch 61 of 2000 took 0.095s
  training loss:		0.570241
  validation loss:		0.556553
  validation accuracy:		82.17 %
Epoch 62 of 2000 took 0.100s
  training loss:		0.545289
  validation loss:		0.558295
  validation accuracy:		82.83 %
Epoch 63 of 2000 took 0.095s
  training loss:		0.544230
  validation loss:		0.531840
  validation accuracy:		83.70 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.536442
  validation loss:		0.530348
  validation accuracy:		83.80 %
Epoch 65 of 2000 took 0.099s
  training loss:		0.527921
  validation loss:		0.535942
  validation accuracy:		83.70 %
Epoch 66 of 2000 took 0.095s
  training loss:		0.526207
  validation loss:		0.511819
  validation accuracy:		84.24 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.512859
  validation loss:		0.511049
  validation accuracy:		84.67 %
Epoch 68 of 2000 took 0.100s
  training loss:		0.501036
  validation loss:		0.504469
  validation accuracy:		84.78 %
Epoch 69 of 2000 took 0.095s
  training loss:		0.510178
  validation loss:		0.517617
  validation accuracy:		84.02 %
Epoch 70 of 2000 took 0.096s
  training loss:		0.490005
  validation loss:		0.501540
  validation accuracy:		84.89 %
Epoch 71 of 2000 took 0.095s
  training loss:		0.485510
  validation loss:		0.494222
  validation accuracy:		84.89 %
Epoch 72 of 2000 took 0.103s
  training loss:		0.475110
  validation loss:		0.500372
  validation accuracy:		84.78 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.472835
  validation loss:		0.488453
  validation accuracy:		85.00 %
Epoch 74 of 2000 took 0.095s
  training loss:		0.472848
  validation loss:		0.486394
  validation accuracy:		84.57 %
Epoch 75 of 2000 took 0.100s
  training loss:		0.465362
  validation loss:		0.491220
  validation accuracy:		84.67 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.470672
  validation loss:		0.484790
  validation accuracy:		85.11 %
Epoch 77 of 2000 took 0.096s
  training loss:		0.473966
  validation loss:		0.473198
  validation accuracy:		85.98 %
Epoch 78 of 2000 took 0.096s
  training loss:		0.452991
  validation loss:		0.468288
  validation accuracy:		86.20 %
Epoch 79 of 2000 took 0.096s
  training loss:		0.453037
  validation loss:		0.485089
  validation accuracy:		84.67 %
Epoch 80 of 2000 took 0.101s
  training loss:		0.448449
  validation loss:		0.462403
  validation accuracy:		85.76 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.440961
  validation loss:		0.465871
  validation accuracy:		84.67 %
Epoch 82 of 2000 took 0.097s
  training loss:		0.442735
  validation loss:		0.451188
  validation accuracy:		86.30 %
Epoch 83 of 2000 took 0.102s
  training loss:		0.438705
  validation loss:		0.458393
  validation accuracy:		85.87 %
Epoch 84 of 2000 took 0.096s
  training loss:		0.438988
  validation loss:		0.461552
  validation accuracy:		85.54 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.430127
  validation loss:		0.470936
  validation accuracy:		84.57 %
Epoch 86 of 2000 took 0.096s
  training loss:		0.436920
  validation loss:		0.446834
  validation accuracy:		85.76 %
Epoch 87 of 2000 took 0.098s
  training loss:		0.432820
  validation loss:		0.440895
  validation accuracy:		86.63 %
Epoch 88 of 2000 took 0.102s
  training loss:		0.411993
  validation loss:		0.433022
  validation accuracy:		87.07 %
Epoch 89 of 2000 took 0.096s
  training loss:		0.412758
  validation loss:		0.463748
  validation accuracy:		85.33 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.415739
  validation loss:		0.451907
  validation accuracy:		85.22 %
Epoch 91 of 2000 took 0.101s
  training loss:		0.413088
  validation loss:		0.479447
  validation accuracy:		84.57 %
Epoch 92 of 2000 took 0.096s
  training loss:		0.412114
  validation loss:		0.441011
  validation accuracy:		85.87 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.406144
  validation loss:		0.436650
  validation accuracy:		87.07 %
Epoch 94 of 2000 took 0.096s
  training loss:		0.404835
  validation loss:		0.456601
  validation accuracy:		85.54 %
Epoch 95 of 2000 took 0.100s
  training loss:		0.406460
  validation loss:		0.456449
  validation accuracy:		86.09 %
Epoch 96 of 2000 took 0.098s
  training loss:		0.397075
  validation loss:		0.419687
  validation accuracy:		87.39 %
Epoch 97 of 2000 took 0.096s
  training loss:		0.387614
  validation loss:		0.425984
  validation accuracy:		87.28 %
Epoch 98 of 2000 took 0.101s
  training loss:		0.402783
  validation loss:		0.423616
  validation accuracy:		86.85 %
Epoch 99 of 2000 took 0.098s
  training loss:		0.392195
  validation loss:		0.429640
  validation accuracy:		86.96 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.392152
  validation loss:		0.432261
  validation accuracy:		86.41 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.378046
  validation loss:		0.416114
  validation accuracy:		87.50 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.377597
  validation loss:		0.427341
  validation accuracy:		86.09 %
Epoch 103 of 2000 took 0.100s
  training loss:		0.390797
  validation loss:		0.411736
  validation accuracy:		87.07 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.380387
  validation loss:		0.411780
  validation accuracy:		87.07 %
Epoch 105 of 2000 took 0.096s
  training loss:		0.379015
  validation loss:		0.416370
  validation accuracy:		87.39 %
Epoch 106 of 2000 took 0.099s
  training loss:		0.381337
  validation loss:		0.409024
  validation accuracy:		87.28 %
Epoch 107 of 2000 took 0.096s
  training loss:		0.371702
  validation loss:		0.417872
  validation accuracy:		87.50 %
Epoch 108 of 2000 took 0.100s
  training loss:		0.373109
  validation loss:		0.418355
  validation accuracy:		87.50 %
Epoch 109 of 2000 took 0.096s
  training loss:		0.376230
  validation loss:		0.413721
  validation accuracy:		87.39 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.368659
  validation loss:		0.434346
  validation accuracy:		86.96 %
Epoch 111 of 2000 took 0.099s
  training loss:		0.366210
  validation loss:		0.430790
  validation accuracy:		86.52 %
Epoch 112 of 2000 took 0.096s
  training loss:		0.369552
  validation loss:		0.401157
  validation accuracy:		87.72 %
Epoch 113 of 2000 took 0.100s
  training loss:		0.366494
  validation loss:		0.406894
  validation accuracy:		87.72 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.359327
  validation loss:		0.402523
  validation accuracy:		87.61 %
Epoch 115 of 2000 took 0.099s
  training loss:		0.357254
  validation loss:		0.406762
  validation accuracy:		87.72 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.359088
  validation loss:		0.407813
  validation accuracy:		87.93 %
Epoch 117 of 2000 took 0.096s
  training loss:		0.353580
  validation loss:		0.394610
  validation accuracy:		88.15 %
Epoch 118 of 2000 took 0.100s
  training loss:		0.358726
  validation loss:		0.404677
  validation accuracy:		87.72 %
Epoch 119 of 2000 took 0.096s
  training loss:		0.357749
  validation loss:		0.409377
  validation accuracy:		87.83 %
Epoch 120 of 2000 took 0.100s
  training loss:		0.365202
  validation loss:		0.385329
  validation accuracy:		88.59 %
Epoch 121 of 2000 took 0.096s
  training loss:		0.352003
  validation loss:		0.407953
  validation accuracy:		87.61 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.349426
  validation loss:		0.408737
  validation accuracy:		88.04 %
Epoch 123 of 2000 took 0.099s
  training loss:		0.358041
  validation loss:		0.425945
  validation accuracy:		86.74 %
Epoch 124 of 2000 took 0.096s
  training loss:		0.348441
  validation loss:		0.394545
  validation accuracy:		88.26 %
Epoch 125 of 2000 took 0.100s
  training loss:		0.357819
  validation loss:		0.397910
  validation accuracy:		88.15 %
Epoch 126 of 2000 took 0.096s
  training loss:		0.342904
  validation loss:		0.392930
  validation accuracy:		88.59 %
Epoch 127 of 2000 took 0.099s
  training loss:		0.339315
  validation loss:		0.394521
  validation accuracy:		88.04 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.336712
  validation loss:		0.400344
  validation accuracy:		88.26 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.336788
  validation loss:		0.388034
  validation accuracy:		88.59 %
Epoch 130 of 2000 took 0.099s
  training loss:		0.334290
  validation loss:		0.387076
  validation accuracy:		88.37 %
Epoch 131 of 2000 took 0.096s
  training loss:		0.336718
  validation loss:		0.396094
  validation accuracy:		88.48 %
Epoch 132 of 2000 took 0.102s
  training loss:		0.344060
  validation loss:		0.396436
  validation accuracy:		88.59 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.338956
  validation loss:		0.389834
  validation accuracy:		88.37 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.339000
  validation loss:		0.387480
  validation accuracy:		88.70 %
Epoch 135 of 2000 took 0.096s
  training loss:		0.338836
  validation loss:		0.407505
  validation accuracy:		88.37 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.333076
  validation loss:		0.381424
  validation accuracy:		88.70 %
Epoch 137 of 2000 took 0.100s
  training loss:		0.337075
  validation loss:		0.412067
  validation accuracy:		87.83 %
Epoch 138 of 2000 took 0.096s
  training loss:		0.329008
  validation loss:		0.403748
  validation accuracy:		87.72 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.330047
  validation loss:		0.390772
  validation accuracy:		88.48 %
Epoch 140 of 2000 took 0.102s
  training loss:		0.323436
  validation loss:		0.383212
  validation accuracy:		88.48 %
Epoch 141 of 2000 took 0.096s
  training loss:		0.337211
  validation loss:		0.392073
  validation accuracy:		88.15 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.337486
  validation loss:		0.381647
  validation accuracy:		88.91 %
Epoch 143 of 2000 took 0.096s
  training loss:		0.321831
  validation loss:		0.395420
  validation accuracy:		88.26 %
Epoch 144 of 2000 took 0.098s
  training loss:		0.320065
  validation loss:		0.401045
  validation accuracy:		88.48 %
Epoch 145 of 2000 took 0.099s
  training loss:		0.323604
  validation loss:		0.383897
  validation accuracy:		88.59 %
Epoch 146 of 2000 took 0.096s
  training loss:		0.324629
  validation loss:		0.386801
  validation accuracy:		88.48 %
Epoch 147 of 2000 took 0.098s
  training loss:		0.314765
  validation loss:		0.402414
  validation accuracy:		87.72 %
Epoch 148 of 2000 took 0.100s
  training loss:		0.319653
  validation loss:		0.403325
  validation accuracy:		88.15 %
Epoch 149 of 2000 took 0.096s
  training loss:		0.315918
  validation loss:		0.384958
  validation accuracy:		88.70 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.313329
  validation loss:		0.379884
  validation accuracy:		88.80 %
Epoch 151 of 2000 took 0.096s
  training loss:		0.317582
  validation loss:		0.399250
  validation accuracy:		88.04 %
Epoch 152 of 2000 took 0.101s
  training loss:		0.311323
  validation loss:		0.391251
  validation accuracy:		88.48 %
Epoch 153 of 2000 took 0.098s
  training loss:		0.317445
  validation loss:		0.389573
  validation accuracy:		88.48 %
Epoch 154 of 2000 took 0.096s
  training loss:		0.309089
  validation loss:		0.382817
  validation accuracy:		88.48 %
Epoch 155 of 2000 took 0.101s
  training loss:		0.313635
  validation loss:		0.410054
  validation accuracy:		87.61 %
Epoch 156 of 2000 took 0.100s
  training loss:		0.310505
  validation loss:		0.380464
  validation accuracy:		88.70 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.310387
  validation loss:		0.386538
  validation accuracy:		88.70 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.311028
  validation loss:		0.374666
  validation accuracy:		89.13 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.312775
  validation loss:		0.379619
  validation accuracy:		88.80 %
Epoch 160 of 2000 took 0.100s
  training loss:		0.313141
  validation loss:		0.378799
  validation accuracy:		88.80 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.303441
  validation loss:		0.374178
  validation accuracy:		88.70 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.309917
  validation loss:		0.389492
  validation accuracy:		88.15 %
Epoch 163 of 2000 took 0.102s
  training loss:		0.314639
  validation loss:		0.401304
  validation accuracy:		88.48 %
Epoch 164 of 2000 took 0.096s
  training loss:		0.302082
  validation loss:		0.391851
  validation accuracy:		89.02 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.307001
  validation loss:		0.379441
  validation accuracy:		89.24 %
Epoch 166 of 2000 took 0.096s
  training loss:		0.310459
  validation loss:		0.390595
  validation accuracy:		88.80 %
Epoch 167 of 2000 took 0.098s
  training loss:		0.312480
  validation loss:		0.371989
  validation accuracy:		89.13 %
Epoch 168 of 2000 took 0.100s
  training loss:		0.299387
  validation loss:		0.385238
  validation accuracy:		87.83 %
Epoch 169 of 2000 took 0.096s
  training loss:		0.299504
  validation loss:		0.368002
  validation accuracy:		89.24 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.292712
  validation loss:		0.392054
  validation accuracy:		88.26 %
Epoch 171 of 2000 took 0.101s
  training loss:		0.302948
  validation loss:		0.429058
  validation accuracy:		87.39 %
Epoch 172 of 2000 took 0.096s
  training loss:		0.302259
  validation loss:		0.386754
  validation accuracy:		89.46 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.302369
  validation loss:		0.378526
  validation accuracy:		89.13 %
Epoch 174 of 2000 took 0.096s
  training loss:		0.290244
  validation loss:		0.407152
  validation accuracy:		88.59 %
Epoch 175 of 2000 took 0.101s
  training loss:		0.301669
  validation loss:		0.400834
  validation accuracy:		88.48 %
Epoch 176 of 2000 took 0.098s
  training loss:		0.300646
  validation loss:		0.377306
  validation accuracy:		89.35 %
Epoch 177 of 2000 took 0.096s
  training loss:		0.290077
  validation loss:		0.387924
  validation accuracy:		88.70 %
Epoch 178 of 2000 took 0.101s
  training loss:		0.291702
  validation loss:		0.404206
  validation accuracy:		88.37 %
Epoch 179 of 2000 took 0.098s
  training loss:		0.290773
  validation loss:		0.374794
  validation accuracy:		89.57 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.291309
  validation loss:		0.393276
  validation accuracy:		88.59 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.290711
  validation loss:		0.379513
  validation accuracy:		87.83 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.283628
  validation loss:		0.365469
  validation accuracy:		89.67 %
Epoch 183 of 2000 took 0.100s
  training loss:		0.289849
  validation loss:		0.366296
  validation accuracy:		89.24 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.290391
  validation loss:		0.389611
  validation accuracy:		88.80 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.286289
  validation loss:		0.365241
  validation accuracy:		89.13 %
Epoch 186 of 2000 took 0.102s
  training loss:		0.284007
  validation loss:		0.377032
  validation accuracy:		89.13 %
Epoch 187 of 2000 took 0.096s
  training loss:		0.284851
  validation loss:		0.373249
  validation accuracy:		88.80 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.280611
  validation loss:		0.398996
  validation accuracy:		88.70 %
Epoch 189 of 2000 took 0.096s
  training loss:		0.281257
  validation loss:		0.368360
  validation accuracy:		89.57 %
Epoch 190 of 2000 took 0.098s
  training loss:		0.284728
  validation loss:		0.380762
  validation accuracy:		88.59 %
Epoch 191 of 2000 took 0.100s
  training loss:		0.279366
  validation loss:		0.370867
  validation accuracy:		89.57 %
Epoch 192 of 2000 took 0.096s
  training loss:		0.281270
  validation loss:		0.381032
  validation accuracy:		88.37 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.277959
  validation loss:		0.376236
  validation accuracy:		89.57 %
Epoch 194 of 2000 took 0.101s
  training loss:		0.272180
  validation loss:		0.372870
  validation accuracy:		89.13 %
Epoch 195 of 2000 took 0.096s
  training loss:		0.284019
  validation loss:		0.396433
  validation accuracy:		87.72 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.280369
  validation loss:		0.363320
  validation accuracy:		89.67 %
Epoch 197 of 2000 took 0.096s
  training loss:		0.278546
  validation loss:		0.358354
  validation accuracy:		89.46 %
Epoch 198 of 2000 took 0.101s
  training loss:		0.284235
  validation loss:		0.371289
  validation accuracy:		88.59 %
Epoch 199 of 2000 took 0.098s
  training loss:		0.278589
  validation loss:		0.366642
  validation accuracy:		89.46 %
Epoch 200 of 2000 took 0.096s
  training loss:		0.270438
  validation loss:		0.372713
  validation accuracy:		89.46 %
Epoch 201 of 2000 took 0.101s
  training loss:		0.266231
  validation loss:		0.371217
  validation accuracy:		89.57 %
Epoch 202 of 2000 took 0.098s
  training loss:		0.271692
  validation loss:		0.361511
  validation accuracy:		89.67 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.270864
  validation loss:		0.379882
  validation accuracy:		89.24 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.272308
  validation loss:		0.360692
  validation accuracy:		88.80 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.269772
  validation loss:		0.386311
  validation accuracy:		89.02 %
Epoch 206 of 2000 took 0.100s
  training loss:		0.268896
  validation loss:		0.366649
  validation accuracy:		88.91 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.267509
  validation loss:		0.360560
  validation accuracy:		89.24 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.268638
  validation loss:		0.365034
  validation accuracy:		89.13 %
Epoch 209 of 2000 took 0.102s
  training loss:		0.279143
  validation loss:		0.377370
  validation accuracy:		88.80 %
Epoch 210 of 2000 took 0.096s
  training loss:		0.268703
  validation loss:		0.372128
  validation accuracy:		89.89 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.276072
  validation loss:		0.384631
  validation accuracy:		89.13 %
Epoch 212 of 2000 took 0.096s
  training loss:		0.266038
  validation loss:		0.366103
  validation accuracy:		89.89 %
Epoch 213 of 2000 took 0.098s
  training loss:		0.263608
  validation loss:		0.363456
  validation accuracy:		89.46 %
Epoch 214 of 2000 took 0.100s
  training loss:		0.273906
  validation loss:		0.379308
  validation accuracy:		89.13 %
Epoch 215 of 2000 took 0.096s
  training loss:		0.263610
  validation loss:		0.361421
  validation accuracy:		90.00 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.264388
  validation loss:		0.352695
  validation accuracy:		89.57 %
Epoch 217 of 2000 took 0.101s
  training loss:		0.257309
  validation loss:		0.364140
  validation accuracy:		89.67 %
Epoch 218 of 2000 took 0.096s
  training loss:		0.262240
  validation loss:		0.358208
  validation accuracy:		89.02 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.264292
  validation loss:		0.392206
  validation accuracy:		89.13 %
Epoch 220 of 2000 took 0.096s
  training loss:		0.259378
  validation loss:		0.377569
  validation accuracy:		89.02 %
Epoch 221 of 2000 took 0.100s
  training loss:		0.258182
  validation loss:		0.369996
  validation accuracy:		89.02 %
Epoch 222 of 2000 took 0.098s
  training loss:		0.264456
  validation loss:		0.362378
  validation accuracy:		90.22 %
Epoch 223 of 2000 took 0.098s
  training loss:		0.263333
  validation loss:		0.357485
  validation accuracy:		88.91 %
Epoch 224 of 2000 took 0.101s
  training loss:		0.264517
  validation loss:		0.355161
  validation accuracy:		89.02 %
Epoch 225 of 2000 took 0.098s
  training loss:		0.264706
  validation loss:		0.358077
  validation accuracy:		88.59 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.267897
  validation loss:		0.349953
  validation accuracy:		89.78 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.254294
  validation loss:		0.349041
  validation accuracy:		89.89 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.264850
  validation loss:		0.358218
  validation accuracy:		89.78 %
Epoch 229 of 2000 took 0.100s
  training loss:		0.258182
  validation loss:		0.354574
  validation accuracy:		88.91 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.258326
  validation loss:		0.358094
  validation accuracy:		89.67 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.260501
  validation loss:		0.361245
  validation accuracy:		90.11 %
Epoch 232 of 2000 took 0.102s
  training loss:		0.248985
  validation loss:		0.359159
  validation accuracy:		90.22 %
Epoch 233 of 2000 took 0.096s
  training loss:		0.246905
  validation loss:		0.353236
  validation accuracy:		89.78 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.253323
  validation loss:		0.353108
  validation accuracy:		89.67 %
Epoch 235 of 2000 took 0.096s
  training loss:		0.253313
  validation loss:		0.352595
  validation accuracy:		89.57 %
Epoch 236 of 2000 took 0.098s
  training loss:		0.250795
  validation loss:		0.356497
  validation accuracy:		90.43 %
Epoch 237 of 2000 took 0.100s
  training loss:		0.247436
  validation loss:		0.364678
  validation accuracy:		89.02 %
Epoch 238 of 2000 took 0.096s
  training loss:		0.253291
  validation loss:		0.358893
  validation accuracy:		89.89 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.258396
  validation loss:		0.350517
  validation accuracy:		90.33 %
Epoch 240 of 2000 took 0.102s
  training loss:		0.245169
  validation loss:		0.365629
  validation accuracy:		89.67 %
Epoch 241 of 2000 took 0.096s
  training loss:		0.244902
  validation loss:		0.361615
  validation accuracy:		89.46 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.248055
  validation loss:		0.375157
  validation accuracy:		89.24 %
Epoch 243 of 2000 took 0.096s
  training loss:		0.249010
  validation loss:		0.362065
  validation accuracy:		89.78 %
Epoch 244 of 2000 took 0.100s
  training loss:		0.252063
  validation loss:		0.384874
  validation accuracy:		89.13 %
Epoch 245 of 2000 took 0.098s
  training loss:		0.246005
  validation loss:		0.341767
  validation accuracy:		89.89 %
Epoch 246 of 2000 took 0.096s
  training loss:		0.245641
  validation loss:		0.365466
  validation accuracy:		89.78 %
Epoch 247 of 2000 took 0.100s
  training loss:		0.243087
  validation loss:		0.353563
  validation accuracy:		89.13 %
Epoch 248 of 2000 took 0.099s
  training loss:		0.245452
  validation loss:		0.344770
  validation accuracy:		90.11 %
Epoch 249 of 2000 took 0.096s
  training loss:		0.241964
  validation loss:		0.351208
  validation accuracy:		90.54 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.240168
  validation loss:		0.385562
  validation accuracy:		90.00 %
Epoch 251 of 2000 took 0.096s
  training loss:		0.249061
  validation loss:		0.351957
  validation accuracy:		90.00 %
Epoch 252 of 2000 took 0.100s
  training loss:		0.237947
  validation loss:		0.354655
  validation accuracy:		90.43 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.242587
  validation loss:		0.367413
  validation accuracy:		89.67 %
Epoch 254 of 2000 took 0.096s
  training loss:		0.242295
  validation loss:		0.342366
  validation accuracy:		90.43 %
Epoch 255 of 2000 took 0.102s
  training loss:		0.240787
  validation loss:		0.345996
  validation accuracy:		90.11 %
Epoch 256 of 2000 took 0.096s
  training loss:		0.238797
  validation loss:		0.360247
  validation accuracy:		90.00 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.237399
  validation loss:		0.349497
  validation accuracy:		90.43 %
Epoch 258 of 2000 took 0.096s
  training loss:		0.239693
  validation loss:		0.358200
  validation accuracy:		89.57 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.240362
  validation loss:		0.346764
  validation accuracy:		90.11 %
Epoch 260 of 2000 took 0.100s
  training loss:		0.238842
  validation loss:		0.347190
  validation accuracy:		90.33 %
Epoch 261 of 2000 took 0.096s
  training loss:		0.236283
  validation loss:		0.356189
  validation accuracy:		90.54 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.240850
  validation loss:		0.371737
  validation accuracy:		89.57 %
Epoch 263 of 2000 took 0.102s
  training loss:		0.242376
  validation loss:		0.352542
  validation accuracy:		89.67 %
Epoch 264 of 2000 took 0.096s
  training loss:		0.237126
  validation loss:		0.345238
  validation accuracy:		90.54 %
Epoch 265 of 2000 took 0.097s
  training loss:		0.231132
  validation loss:		0.361353
  validation accuracy:		90.22 %
Epoch 266 of 2000 took 0.096s
  training loss:		0.231050
  validation loss:		0.349892
  validation accuracy:		89.57 %
Epoch 267 of 2000 took 0.099s
  training loss:		0.233048
  validation loss:		0.354325
  validation accuracy:		90.54 %
Epoch 268 of 2000 took 0.099s
  training loss:		0.232029
  validation loss:		0.356177
  validation accuracy:		90.76 %
Epoch 269 of 2000 took 0.096s
  training loss:		0.232800
  validation loss:		0.347411
  validation accuracy:		90.22 %
Epoch 270 of 2000 took 0.099s
  training loss:		0.238268
  validation loss:		0.351159
  validation accuracy:		89.46 %
Epoch 271 of 2000 took 0.100s
  training loss:		0.239982
  validation loss:		0.352976
  validation accuracy:		90.00 %
Epoch 272 of 2000 took 0.096s
  training loss:		0.237760
  validation loss:		0.356418
  validation accuracy:		89.57 %
Epoch 273 of 2000 took 0.097s
  training loss:		0.229865
  validation loss:		0.344823
  validation accuracy:		90.65 %
Epoch 274 of 2000 took 0.096s
  training loss:		0.230438
  validation loss:		0.349314
  validation accuracy:		90.54 %
Epoch 275 of 2000 took 0.101s
  training loss:		0.236107
  validation loss:		0.349181
  validation accuracy:		90.22 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.234129
  validation loss:		0.363885
  validation accuracy:		90.22 %
Epoch 277 of 2000 took 0.096s
  training loss:		0.227904
  validation loss:		0.379954
  validation accuracy:		89.46 %
Epoch 278 of 2000 took 0.102s
  training loss:		0.231985
  validation loss:		0.348591
  validation accuracy:		90.22 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.229681
  validation loss:		0.376699
  validation accuracy:		89.78 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.235156
  validation loss:		0.351153
  validation accuracy:		90.22 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.224364
  validation loss:		0.377162
  validation accuracy:		89.67 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.225987
  validation loss:		0.350797
  validation accuracy:		90.43 %
Epoch 283 of 2000 took 0.100s
  training loss:		0.222993
  validation loss:		0.341528
  validation accuracy:		90.33 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.221439
  validation loss:		0.345817
  validation accuracy:		90.11 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.227084
  validation loss:		0.353762
  validation accuracy:		90.11 %
Epoch 286 of 2000 took 0.102s
  training loss:		0.223197
  validation loss:		0.382761
  validation accuracy:		89.67 %
Epoch 287 of 2000 took 0.096s
  training loss:		0.235420
  validation loss:		0.345708
  validation accuracy:		90.54 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.219406
  validation loss:		0.364111
  validation accuracy:		90.11 %
Epoch 289 of 2000 took 0.096s
  training loss:		0.221079
  validation loss:		0.357885
  validation accuracy:		88.80 %
Epoch 290 of 2000 took 0.098s
  training loss:		0.226616
  validation loss:		0.342224
  validation accuracy:		90.76 %
Epoch 291 of 2000 took 0.100s
  training loss:		0.226114
  validation loss:		0.356190
  validation accuracy:		90.54 %
Epoch 292 of 2000 took 0.096s
  training loss:		0.228755
  validation loss:		0.365716
  validation accuracy:		89.89 %
Epoch 293 of 2000 took 0.098s
  training loss:		0.221569
  validation loss:		0.371696
  validation accuracy:		90.00 %
Epoch 294 of 2000 took 0.101s
  training loss:		0.225518
  validation loss:		0.346576
  validation accuracy:		90.43 %
Epoch 295 of 2000 took 0.096s
  training loss:		0.219675
  validation loss:		0.340419
  validation accuracy:		90.33 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.219519
  validation loss:		0.349262
  validation accuracy:		90.22 %
Epoch 297 of 2000 took 0.096s
  training loss:		0.223191
  validation loss:		0.350065
  validation accuracy:		90.65 %
Epoch 298 of 2000 took 0.101s
  training loss:		0.222872
  validation loss:		0.386573
  validation accuracy:		88.26 %
Epoch 299 of 2000 took 0.098s
  training loss:		0.222208
  validation loss:		0.349376
  validation accuracy:		90.11 %
Epoch 300 of 2000 took 0.096s
  training loss:		0.215653
  validation loss:		0.350281
  validation accuracy:		90.22 %
Epoch 301 of 2000 took 0.101s
  training loss:		0.215877
  validation loss:		0.380123
  validation accuracy:		89.78 %
Epoch 302 of 2000 took 0.098s
  training loss:		0.218316
  validation loss:		0.361012
  validation accuracy:		89.13 %
Epoch 303 of 2000 took 0.096s
  training loss:		0.216635
  validation loss:		0.354330
  validation accuracy:		90.33 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.221440
  validation loss:		0.348218
  validation accuracy:		90.00 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.217008
  validation loss:		0.344061
  validation accuracy:		90.65 %
Epoch 306 of 2000 took 0.100s
  training loss:		0.211315
  validation loss:		0.351038
  validation accuracy:		90.11 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.208890
  validation loss:		0.352604
  validation accuracy:		90.22 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.215881
  validation loss:		0.349204
  validation accuracy:		90.33 %
Epoch 309 of 2000 took 0.102s
  training loss:		0.218799
  validation loss:		0.350923
  validation accuracy:		90.43 %
Epoch 310 of 2000 took 0.096s
  training loss:		0.216173
  validation loss:		0.356598
  validation accuracy:		90.11 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.220256
  validation loss:		0.340113
  validation accuracy:		90.43 %
Epoch 312 of 2000 took 0.096s
  training loss:		0.207514
  validation loss:		0.351369
  validation accuracy:		90.33 %
Epoch 313 of 2000 took 0.098s
  training loss:		0.213210
  validation loss:		0.339867
  validation accuracy:		90.76 %
Epoch 314 of 2000 took 0.100s
  training loss:		0.213431
  validation loss:		0.355436
  validation accuracy:		90.00 %
Epoch 315 of 2000 took 0.096s
  training loss:		0.212777
  validation loss:		0.342688
  validation accuracy:		90.76 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.208682
  validation loss:		0.348228
  validation accuracy:		90.76 %
Epoch 317 of 2000 took 0.102s
  training loss:		0.210024
  validation loss:		0.352550
  validation accuracy:		90.54 %
Epoch 318 of 2000 took 0.096s
  training loss:		0.211767
  validation loss:		0.344216
  validation accuracy:		90.54 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.207852
  validation loss:		0.371535
  validation accuracy:		90.00 %
Epoch 320 of 2000 took 0.096s
  training loss:		0.215311
  validation loss:		0.349437
  validation accuracy:		89.78 %
Epoch 321 of 2000 took 0.100s
  training loss:		0.216246
  validation loss:		0.353747
  validation accuracy:		90.43 %
Epoch 322 of 2000 took 0.098s
  training loss:		0.206278
  validation loss:		0.343752
  validation accuracy:		90.76 %
Epoch 323 of 2000 took 0.099s
  training loss:		0.210380
  validation loss:		0.355738
  validation accuracy:		89.89 %
Epoch 324 of 2000 took 0.104s
  training loss:		0.214479
  validation loss:		0.361383
  validation accuracy:		90.22 %
Epoch 325 of 2000 took 0.101s
  training loss:		0.216706
  validation loss:		0.361149
  validation accuracy:		90.33 %
Epoch 326 of 2000 took 0.100s
  training loss:		0.212437
  validation loss:		0.349382
  validation accuracy:		90.76 %
Epoch 327 of 2000 took 0.100s
  training loss:		0.210409
  validation loss:		0.371116
  validation accuracy:		89.35 %
Epoch 328 of 2000 took 0.100s
  training loss:		0.203643
  validation loss:		0.344142
  validation accuracy:		90.43 %
Epoch 329 of 2000 took 0.104s
  training loss:		0.209011
  validation loss:		0.344222
  validation accuracy:		90.54 %
Epoch 330 of 2000 took 0.102s
  training loss:		0.205704
  validation loss:		0.366135
  validation accuracy:		90.22 %
Epoch 331 of 2000 took 0.100s
  training loss:		0.207342
  validation loss:		0.356727
  validation accuracy:		90.65 %
Epoch 332 of 2000 took 0.106s
  training loss:		0.205577
  validation loss:		0.344087
  validation accuracy:		90.43 %
Epoch 333 of 2000 took 0.099s
  training loss:		0.199098
  validation loss:		0.358701
  validation accuracy:		90.11 %
Epoch 334 of 2000 took 0.100s
  training loss:		0.198782
  validation loss:		0.345934
  validation accuracy:		90.54 %
Epoch 335 of 2000 took 0.099s
  training loss:		0.207588
  validation loss:		0.356342
  validation accuracy:		89.02 %
Epoch 336 of 2000 took 0.101s
  training loss:		0.207424
  validation loss:		0.348571
  validation accuracy:		90.43 %
Epoch 337 of 2000 took 0.104s
  training loss:		0.199811
  validation loss:		0.368619
  validation accuracy:		90.76 %
Epoch 338 of 2000 took 0.099s
  training loss:		0.204355
  validation loss:		0.348262
  validation accuracy:		90.65 %
Epoch 339 of 2000 took 0.100s
  training loss:		0.210995
  validation loss:		0.350174
  validation accuracy:		90.22 %
Epoch 340 of 2000 took 0.105s
  training loss:		0.201044
  validation loss:		0.371258
  validation accuracy:		89.78 %
Epoch 341 of 2000 took 0.099s
  training loss:		0.203168
  validation loss:		0.345178
  validation accuracy:		90.54 %
Epoch 342 of 2000 took 0.100s
  training loss:		0.200229
  validation loss:		0.364149
  validation accuracy:		89.57 %
Epoch 343 of 2000 took 0.099s
  training loss:		0.197978
  validation loss:		0.345498
  validation accuracy:		90.54 %
Epoch 344 of 2000 took 0.102s
  training loss:		0.201207
  validation loss:		0.371711
  validation accuracy:		89.78 %
Epoch 345 of 2000 took 0.101s
  training loss:		0.203037
  validation loss:		0.338400
  validation accuracy:		90.65 %
Epoch 346 of 2000 took 0.099s
  training loss:		0.199680
  validation loss:		0.340928
  validation accuracy:		90.65 %
Epoch 347 of 2000 took 0.102s
  training loss:		0.207677
  validation loss:		0.355976
  validation accuracy:		90.22 %
Epoch 348 of 2000 took 0.102s
  training loss:		0.199882
  validation loss:		0.362187
  validation accuracy:		89.24 %
Epoch 349 of 2000 took 0.099s
  training loss:		0.205403
  validation loss:		0.353623
  validation accuracy:		90.43 %
Epoch 350 of 2000 took 0.100s
  training loss:		0.201778
  validation loss:		0.387574
  validation accuracy:		89.57 %
Epoch 351 of 2000 took 0.099s
  training loss:		0.203532
  validation loss:		0.361611
  validation accuracy:		89.89 %
Epoch 352 of 2000 took 0.104s
  training loss:		0.196545
  validation loss:		0.346239
  validation accuracy:		90.87 %
Epoch 353 of 2000 took 0.100s
  training loss:		0.192369
  validation loss:		0.352535
  validation accuracy:		90.54 %
Epoch 354 of 2000 took 0.099s
  training loss:		0.202839
  validation loss:		0.342394
  validation accuracy:		90.65 %
Epoch 355 of 2000 took 0.105s
  training loss:		0.201808
  validation loss:		0.344973
  validation accuracy:		90.98 %
Epoch 356 of 2000 took 0.099s
  training loss:		0.195302
  validation loss:		0.369405
  validation accuracy:		88.48 %
Epoch 357 of 2000 took 0.100s
  training loss:		0.192602
  validation loss:		0.358644
  validation accuracy:		90.65 %
Epoch 358 of 2000 took 0.099s
  training loss:		0.203603
  validation loss:		0.352176
  validation accuracy:		90.43 %
Epoch 359 of 2000 took 0.100s
  training loss:		0.196116
  validation loss:		0.349203
  validation accuracy:		89.89 %
Epoch 360 of 2000 took 0.104s
  training loss:		0.199646
  validation loss:		0.348708
  validation accuracy:		90.76 %
Epoch 361 of 2000 took 0.099s
  training loss:		0.196342
  validation loss:		0.348974
  validation accuracy:		90.65 %
Epoch 362 of 2000 took 0.100s
  training loss:		0.196428
  validation loss:		0.353360
  validation accuracy:		89.46 %
Epoch 363 of 2000 took 0.105s
  training loss:		0.195922
  validation loss:		0.355606
  validation accuracy:		90.54 %
Epoch 364 of 2000 took 0.099s
  training loss:		0.195378
  validation loss:		0.349970
  validation accuracy:		91.09 %
Epoch 365 of 2000 took 0.100s
  training loss:		0.190387
  validation loss:		0.355022
  validation accuracy:		90.43 %
Epoch 366 of 2000 took 0.099s
  training loss:		0.193368
  validation loss:		0.347231
  validation accuracy:		90.98 %
Epoch 367 of 2000 took 0.102s
  training loss:		0.191289
  validation loss:		0.360950
  validation accuracy:		89.57 %
Epoch 368 of 2000 took 0.102s
  training loss:		0.202826
  validation loss:		0.358176
  validation accuracy:		90.22 %
Epoch 369 of 2000 took 0.099s
  training loss:		0.193067
  validation loss:		0.343507
  validation accuracy:		90.33 %
Epoch 370 of 2000 took 0.101s
  training loss:		0.192358
  validation loss:		0.343561
  validation accuracy:		90.76 %
Epoch 371 of 2000 took 0.103s
  training loss:		0.186842
  validation loss:		0.346914
  validation accuracy:		90.87 %
Epoch 372 of 2000 took 0.099s
  training loss:		0.186615
  validation loss:		0.354827
  validation accuracy:		90.43 %
Epoch 373 of 2000 took 0.100s
  training loss:		0.193835
  validation loss:		0.342002
  validation accuracy:		90.76 %
Epoch 374 of 2000 took 0.099s
  training loss:		0.189651
  validation loss:		0.365657
  validation accuracy:		90.22 %
Epoch 375 of 2000 took 0.104s
  training loss:		0.194369
  validation loss:		0.362392
  validation accuracy:		89.67 %
Epoch 376 of 2000 took 0.101s
  training loss:		0.194035
  validation loss:		0.354916
  validation accuracy:		90.65 %
Epoch 377 of 2000 took 0.099s
  training loss:		0.188475
  validation loss:		0.356696
  validation accuracy:		90.76 %
Epoch 378 of 2000 took 0.105s
  training loss:		0.193712
  validation loss:		0.353032
  validation accuracy:		90.00 %
Epoch 379 of 2000 took 0.100s
  training loss:		0.194596
  validation loss:		0.364781
  validation accuracy:		90.33 %
Epoch 380 of 2000 took 0.100s
  training loss:		0.186542
  validation loss:		0.345364
  validation accuracy:		90.11 %
Epoch 381 of 2000 took 0.100s
  training loss:		0.191900
  validation loss:		0.345470
  validation accuracy:		90.87 %
Epoch 382 of 2000 took 0.100s
  training loss:		0.189915
  validation loss:		0.373236
  validation accuracy:		89.67 %
Epoch 383 of 2000 took 0.103s
  training loss:		0.185665
  validation loss:		0.339265
  validation accuracy:		91.09 %
Epoch 384 of 2000 took 0.099s
  training loss:		0.180711
  validation loss:		0.347278
  validation accuracy:		91.09 %
Epoch 385 of 2000 took 0.100s
  training loss:		0.183161
  validation loss:		0.413904
  validation accuracy:		89.13 %
Epoch 386 of 2000 took 0.105s
  training loss:		0.194810
  validation loss:		0.366656
  validation accuracy:		88.91 %
Epoch 387 of 2000 took 0.099s
  training loss:		0.186396
  validation loss:		0.355981
  validation accuracy:		90.43 %
Epoch 388 of 2000 took 0.100s
  training loss:		0.189985
  validation loss:		0.356334
  validation accuracy:		90.33 %
Epoch 389 of 2000 took 0.099s
  training loss:		0.185997
  validation loss:		0.344253
  validation accuracy:		91.30 %
Epoch 390 of 2000 took 0.102s
  training loss:		0.188308
  validation loss:		0.343920
  validation accuracy:		91.20 %
Epoch 391 of 2000 took 0.102s
  training loss:		0.187692
  validation loss:		0.359181
  validation accuracy:		90.98 %
Epoch 392 of 2000 took 0.099s
  training loss:		0.184846
  validation loss:		0.344958
  validation accuracy:		91.09 %
Epoch 393 of 2000 took 0.102s
  training loss:		0.182441
  validation loss:		0.351146
  validation accuracy:		91.09 %
Epoch 394 of 2000 took 0.103s
  training loss:		0.187786
  validation loss:		0.361925
  validation accuracy:		90.65 %
Epoch 395 of 2000 took 0.099s
  training loss:		0.177585
  validation loss:		0.350882
  validation accuracy:		90.65 %
Epoch 396 of 2000 took 0.100s
  training loss:		0.185070
  validation loss:		0.362446
  validation accuracy:		90.43 %
Epoch 397 of 2000 took 0.099s
  training loss:		0.188722
  validation loss:		0.350582
  validation accuracy:		90.76 %
Epoch 398 of 2000 took 0.104s
  training loss:		0.183447
  validation loss:		0.371613
  validation accuracy:		90.33 %
Epoch 399 of 2000 took 0.101s
  training loss:		0.183755
  validation loss:		0.340363
  validation accuracy:		90.65 %
Epoch 400 of 2000 took 0.099s
  training loss:		0.184737
  validation loss:		0.370747
  validation accuracy:		90.11 %
Epoch 401 of 2000 took 0.105s
  training loss:		0.192890
  validation loss:		0.357515
  validation accuracy:		89.89 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.173475
  validation loss:		0.358416
  validation accuracy:		90.87 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.186852
  validation loss:		0.346314
  validation accuracy:		90.76 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.177874
  validation loss:		0.354292
  validation accuracy:		90.33 %
Epoch 405 of 2000 took 0.101s
  training loss:		0.183978
  validation loss:		0.363770
  validation accuracy:		90.33 %
Epoch 406 of 2000 took 0.103s
  training loss:		0.179814
  validation loss:		0.354231
  validation accuracy:		90.76 %
Epoch 407 of 2000 took 0.099s
  training loss:		0.175418
  validation loss:		0.345131
  validation accuracy:		91.09 %
Epoch 408 of 2000 took 0.100s
  training loss:		0.176589
  validation loss:		0.353637
  validation accuracy:		90.54 %
Epoch 409 of 2000 took 0.105s
  training loss:		0.179326
  validation loss:		0.354279
  validation accuracy:		90.98 %
Epoch 410 of 2000 took 0.099s
  training loss:		0.179592
  validation loss:		0.349884
  validation accuracy:		90.76 %
Epoch 411 of 2000 took 0.100s
  training loss:		0.179829
  validation loss:		0.354793
  validation accuracy:		90.65 %
Epoch 412 of 2000 took 0.099s
  training loss:		0.178778
  validation loss:		0.349345
  validation accuracy:		90.87 %
Epoch 413 of 2000 took 0.102s
  training loss:		0.175649
  validation loss:		0.356283
  validation accuracy:		90.76 %
Epoch 414 of 2000 took 0.102s
  training loss:		0.176062
  validation loss:		0.354153
  validation accuracy:		91.09 %
Epoch 415 of 2000 took 0.099s
  training loss:		0.174802
  validation loss:		0.362808
  validation accuracy:		90.54 %
Epoch 416 of 2000 took 0.102s
  training loss:		0.170610
  validation loss:		0.349881
  validation accuracy:		90.98 %
Epoch 417 of 2000 took 0.103s
  training loss:		0.175501
  validation loss:		0.377002
  validation accuracy:		90.11 %
Epoch 418 of 2000 took 0.099s
  training loss:		0.181776
  validation loss:		0.364175
  validation accuracy:		90.54 %
Epoch 419 of 2000 took 0.100s
  training loss:		0.177200
  validation loss:		0.353998
  validation accuracy:		90.87 %
Epoch 420 of 2000 took 0.099s
  training loss:		0.174101
  validation loss:		0.355202
  validation accuracy:		90.11 %
Epoch 421 of 2000 took 0.104s
  training loss:		0.171369
  validation loss:		0.373773
  validation accuracy:		89.89 %
Epoch 422 of 2000 took 0.100s
  training loss:		0.175100
  validation loss:		0.348996
  validation accuracy:		91.20 %
Epoch 423 of 2000 took 0.099s
  training loss:		0.174011
  validation loss:		0.358630
  validation accuracy:		90.54 %
Epoch 424 of 2000 took 0.105s
  training loss:		0.179307
  validation loss:		0.346830
  validation accuracy:		90.76 %
Epoch 425 of 2000 took 0.100s
  training loss:		0.179472
  validation loss:		0.355578
  validation accuracy:		90.87 %
Epoch 426 of 2000 took 0.100s
  training loss:		0.169945
  validation loss:		0.363924
  validation accuracy:		90.54 %
Epoch 427 of 2000 took 0.099s
  training loss:		0.172853
  validation loss:		0.352067
  validation accuracy:		90.76 %
Epoch 428 of 2000 took 0.100s
  training loss:		0.167372
  validation loss:		0.363001
  validation accuracy:		90.43 %
Epoch 429 of 2000 took 0.103s
  training loss:		0.175633
  validation loss:		0.358376
  validation accuracy:		90.43 %
Epoch 430 of 2000 took 0.099s
  training loss:		0.174095
  validation loss:		0.362487
  validation accuracy:		90.11 %
Epoch 431 of 2000 took 0.100s
  training loss:		0.167860
  validation loss:		0.341077
  validation accuracy:		90.87 %
Epoch 432 of 2000 took 0.105s
  training loss:		0.179785
  validation loss:		0.366397
  validation accuracy:		90.76 %
Epoch 433 of 2000 took 0.099s
  training loss:		0.171168
  validation loss:		0.370056
  validation accuracy:		90.43 %
Epoch 434 of 2000 took 0.100s
  training loss:		0.172973
  validation loss:		0.393224
  validation accuracy:		89.78 %
Epoch 435 of 2000 took 0.099s
  training loss:		0.171380
  validation loss:		0.356192
  validation accuracy:		90.76 %
Epoch 436 of 2000 took 0.102s
  training loss:		0.170251
  validation loss:		0.354886
  validation accuracy:		90.22 %
Epoch 437 of 2000 took 0.102s
  training loss:		0.171590
  validation loss:		0.353400
  validation accuracy:		90.76 %
Epoch 438 of 2000 took 0.099s
  training loss:		0.169921
  validation loss:		0.354362
  validation accuracy:		91.09 %
Epoch 439 of 2000 took 0.102s
  training loss:		0.170989
  validation loss:		0.359500
  validation accuracy:		90.98 %
Epoch 440 of 2000 took 0.103s
  training loss:		0.171429
  validation loss:		0.364366
  validation accuracy:		90.54 %
Epoch 441 of 2000 took 0.100s
  training loss:		0.176239
  validation loss:		0.352763
  validation accuracy:		90.87 %
Epoch 442 of 2000 took 0.100s
  training loss:		0.172703
  validation loss:		0.349231
  validation accuracy:		91.20 %
Epoch 443 of 2000 took 0.099s
  training loss:		0.167467
  validation loss:		0.357825
  validation accuracy:		90.65 %
Epoch 444 of 2000 took 0.102s
  training loss:		0.158547
  validation loss:		0.376598
  validation accuracy:		90.65 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.165268
  validation loss:		0.373467
  validation accuracy:		90.54 %
Epoch 446 of 2000 took 0.096s
  training loss:		0.171241
  validation loss:		0.353266
  validation accuracy:		90.33 %
Epoch 447 of 2000 took 0.102s
  training loss:		0.170494
  validation loss:		0.380849
  validation accuracy:		90.43 %
Epoch 448 of 2000 took 0.096s
  training loss:		0.166547
  validation loss:		0.367645
  validation accuracy:		90.65 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.166364
  validation loss:		0.365631
  validation accuracy:		90.54 %
Epoch 450 of 2000 took 0.096s
  training loss:		0.166711
  validation loss:		0.364736
  validation accuracy:		90.65 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.166707
  validation loss:		0.353746
  validation accuracy:		90.65 %
Epoch 452 of 2000 took 0.100s
  training loss:		0.162826
  validation loss:		0.362186
  validation accuracy:		91.20 %
Epoch 453 of 2000 took 0.096s
  training loss:		0.164686
  validation loss:		0.359597
  validation accuracy:		90.87 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.161800
  validation loss:		0.379762
  validation accuracy:		90.22 %
Epoch 455 of 2000 took 0.102s
  training loss:		0.170828
  validation loss:		0.359022
  validation accuracy:		90.98 %
Epoch 456 of 2000 took 0.096s
  training loss:		0.169345
  validation loss:		0.356724
  validation accuracy:		91.09 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.167975
  validation loss:		0.357332
  validation accuracy:		90.22 %
Epoch 458 of 2000 took 0.096s
  training loss:		0.163275
  validation loss:		0.359298
  validation accuracy:		90.98 %
Epoch 459 of 2000 took 0.098s
  training loss:		0.160857
  validation loss:		0.360880
  validation accuracy:		90.98 %
Epoch 460 of 2000 took 0.100s
  training loss:		0.170115
  validation loss:		0.369026
  validation accuracy:		90.43 %
Epoch 461 of 2000 took 0.096s
  training loss:		0.162519
  validation loss:		0.366085
  validation accuracy:		90.65 %
Epoch 462 of 2000 took 0.098s
  training loss:		0.162532
  validation loss:		0.383559
  validation accuracy:		90.00 %
Epoch 463 of 2000 took 0.101s
  training loss:		0.164828
  validation loss:		0.387244
  validation accuracy:		90.00 %
Epoch 464 of 2000 took 0.096s
  training loss:		0.168655
  validation loss:		0.366584
  validation accuracy:		90.65 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.168444
  validation loss:		0.356589
  validation accuracy:		90.76 %
Epoch 466 of 2000 took 0.096s
  training loss:		0.155821
  validation loss:		0.356720
  validation accuracy:		90.87 %
Epoch 467 of 2000 took 0.101s
  training loss:		0.164432
  validation loss:		0.358200
  validation accuracy:		90.98 %
Epoch 468 of 2000 took 0.098s
  training loss:		0.161752
  validation loss:		0.363555
  validation accuracy:		91.20 %
Epoch 469 of 2000 took 0.096s
  training loss:		0.158873
  validation loss:		0.356147
  validation accuracy:		90.33 %
Epoch 470 of 2000 took 0.102s
  training loss:		0.158565
  validation loss:		0.371888
  validation accuracy:		90.65 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.154623
  validation loss:		0.359906
  validation accuracy:		90.76 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.167423
  validation loss:		0.356808
  validation accuracy:		90.54 %
Epoch 473 of 2000 took 0.096s
  training loss:		0.166353
  validation loss:		0.370866
  validation accuracy:		90.54 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.162745
  validation loss:		0.358966
  validation accuracy:		90.76 %
Epoch 475 of 2000 took 0.100s
  training loss:		0.156840
  validation loss:		0.371310
  validation accuracy:		90.54 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.160750
  validation loss:		0.373319
  validation accuracy:		90.43 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.161173
  validation loss:		0.371113
  validation accuracy:		90.54 %
Epoch 478 of 2000 took 0.102s
  training loss:		0.161506
  validation loss:		0.382161
  validation accuracy:		90.33 %
Epoch 479 of 2000 took 0.096s
  training loss:		0.155718
  validation loss:		0.369288
  validation accuracy:		90.54 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.161019
  validation loss:		0.371320
  validation accuracy:		90.87 %
Epoch 481 of 2000 took 0.096s
  training loss:		0.161257
  validation loss:		0.394419
  validation accuracy:		90.65 %
Epoch 482 of 2000 took 0.098s
  training loss:		0.162653
  validation loss:		0.364677
  validation accuracy:		90.54 %
Epoch 483 of 2000 took 0.100s
  training loss:		0.160271
  validation loss:		0.357429
  validation accuracy:		90.76 %
Epoch 484 of 2000 took 0.096s
  training loss:		0.159694
  validation loss:		0.369363
  validation accuracy:		90.54 %
Epoch 485 of 2000 took 0.098s
  training loss:		0.155453
  validation loss:		0.369914
  validation accuracy:		90.98 %
Epoch 486 of 2000 took 0.101s
  training loss:		0.158716
  validation loss:		0.366414
  validation accuracy:		91.30 %
Epoch 487 of 2000 took 0.096s
  training loss:		0.157082
  validation loss:		0.368172
  validation accuracy:		90.43 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.153950
  validation loss:		0.368446
  validation accuracy:		90.98 %
Epoch 489 of 2000 took 0.096s
  training loss:		0.159390
  validation loss:		0.380074
  validation accuracy:		91.30 %
Epoch 490 of 2000 took 0.101s
  training loss:		0.158907
  validation loss:		0.378784
  validation accuracy:		90.76 %
Epoch 491 of 2000 took 0.098s
  training loss:		0.156939
  validation loss:		0.375076
  validation accuracy:		90.87 %
Epoch 492 of 2000 took 0.096s
  training loss:		0.162890
  validation loss:		0.372726
  validation accuracy:		90.76 %
Epoch 493 of 2000 took 0.100s
  training loss:		0.158518
  validation loss:		0.368042
  validation accuracy:		90.76 %
Epoch 494 of 2000 took 0.096s
  training loss:		0.155463
  validation loss:		0.370325
  validation accuracy:		91.20 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.156241
  validation loss:		0.373371
  validation accuracy:		90.87 %
Epoch 496 of 2000 took 0.099s
  training loss:		0.148045
  validation loss:		0.373486
  validation accuracy:		91.20 %
Epoch 497 of 2000 took 0.096s
  training loss:		0.153491
  validation loss:		0.364503
  validation accuracy:		90.65 %
Epoch 498 of 2000 took 0.101s
  training loss:		0.156165
  validation loss:		0.373732
  validation accuracy:		91.09 %
Epoch 499 of 2000 took 0.096s
  training loss:		0.157907
  validation loss:		0.370803
  validation accuracy:		90.54 %
Epoch 500 of 2000 took 0.099s
  training loss:		0.155324
  validation loss:		0.386709
  validation accuracy:		90.43 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.154146
  validation loss:		0.361263
  validation accuracy:		91.20 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.156814
  validation loss:		0.371836
  validation accuracy:		90.87 %
Epoch 503 of 2000 took 0.099s
  training loss:		0.145778
  validation loss:		0.365165
  validation accuracy:		91.09 %
Epoch 504 of 2000 took 0.096s
  training loss:		0.148636
  validation loss:		0.392343
  validation accuracy:		90.76 %
Epoch 505 of 2000 took 0.100s
  training loss:		0.151168
  validation loss:		0.375385
  validation accuracy:		90.98 %
Epoch 506 of 2000 took 0.096s
  training loss:		0.155393
  validation loss:		0.392820
  validation accuracy:		90.54 %
Epoch 507 of 2000 took 0.098s
  training loss:		0.153518
  validation loss:		0.387341
  validation accuracy:		90.65 %
Epoch 508 of 2000 took 0.098s
  training loss:		0.151985
  validation loss:		0.371826
  validation accuracy:		90.87 %
Epoch 509 of 2000 took 0.096s
  training loss:		0.158858
  validation loss:		0.375739
  validation accuracy:		91.09 %
Epoch 510 of 2000 took 0.099s
  training loss:		0.153022
  validation loss:		0.373310
  validation accuracy:		91.09 %
Epoch 511 of 2000 took 0.096s
  training loss:		0.157452
  validation loss:		0.386236
  validation accuracy:		90.65 %
Epoch 512 of 2000 took 0.099s
  training loss:		0.156738
  validation loss:		0.373888
  validation accuracy:		90.76 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.149758
  validation loss:		0.359947
  validation accuracy:		90.98 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.147729
  validation loss:		0.381012
  validation accuracy:		91.09 %
Epoch 515 of 2000 took 0.099s
  training loss:		0.146725
  validation loss:		0.387762
  validation accuracy:		90.54 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.150705
  validation loss:		0.371390
  validation accuracy:		90.33 %
Epoch 517 of 2000 took 0.100s
  training loss:		0.152580
  validation loss:		0.386018
  validation accuracy:		90.87 %
Epoch 518 of 2000 took 0.096s
  training loss:		0.147762
  validation loss:		0.397430
  validation accuracy:		90.65 %
Epoch 519 of 2000 took 0.098s
  training loss:		0.145754
  validation loss:		0.372511
  validation accuracy:		90.87 %
Epoch 520 of 2000 took 0.100s
  training loss:		0.151098
  validation loss:		0.381492
  validation accuracy:		90.76 %
Epoch 521 of 2000 took 0.096s
  training loss:		0.152171
  validation loss:		0.383065
  validation accuracy:		90.98 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.146176
  validation loss:		0.371064
  validation accuracy:		90.87 %
Epoch 523 of 2000 took 0.096s
  training loss:		0.150121
  validation loss:		0.372414
  validation accuracy:		91.09 %
Epoch 524 of 2000 took 0.101s
  training loss:		0.145281
  validation loss:		0.366808
  validation accuracy:		90.33 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.145837
  validation loss:		0.374517
  validation accuracy:		90.65 %
Epoch 526 of 2000 took 0.096s
  training loss:		0.149507
  validation loss:		0.377725
  validation accuracy:		90.65 %
Epoch 527 of 2000 took 0.102s
  training loss:		0.146839
  validation loss:		0.380023
  validation accuracy:		90.87 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.154387
  validation loss:		0.375778
  validation accuracy:		91.20 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.145531
  validation loss:		0.372273
  validation accuracy:		90.54 %
Epoch 530 of 2000 took 0.096s
  training loss:		0.144281
  validation loss:		0.379646
  validation accuracy:		91.30 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.143033
  validation loss:		0.370525
  validation accuracy:		90.98 %
Epoch 532 of 2000 took 0.100s
  training loss:		0.149661
  validation loss:		0.380451
  validation accuracy:		91.20 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.143178
  validation loss:		0.369279
  validation accuracy:		91.09 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.142591
  validation loss:		0.370908
  validation accuracy:		91.09 %
Epoch 535 of 2000 took 0.102s
  training loss:		0.144457
  validation loss:		0.386758
  validation accuracy:		90.43 %
Epoch 536 of 2000 took 0.096s
  training loss:		0.143431
  validation loss:		0.366069
  validation accuracy:		90.76 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.146386
  validation loss:		0.388036
  validation accuracy:		90.87 %
Epoch 538 of 2000 took 0.096s
  training loss:		0.141692
  validation loss:		0.369642
  validation accuracy:		90.87 %
Epoch 539 of 2000 took 0.098s
  training loss:		0.144342
  validation loss:		0.368997
  validation accuracy:		90.54 %
Epoch 540 of 2000 took 0.102s
  training loss:		0.150689
  validation loss:		0.384007
  validation accuracy:		90.65 %
Epoch 541 of 2000 took 0.106s
  training loss:		0.145215
  validation loss:		0.379639
  validation accuracy:		90.65 %
Epoch 542 of 2000 took 0.110s
  training loss:		0.141376
  validation loss:		0.388451
  validation accuracy:		90.54 %
Epoch 543 of 2000 took 0.112s
  training loss:		0.144607
  validation loss:		0.377301
  validation accuracy:		91.09 %
Epoch 544 of 2000 took 0.099s
  training loss:		0.141219
  validation loss:		0.377773
  validation accuracy:		90.65 %
Epoch 545 of 2000 took 0.100s
  training loss:		0.142142
  validation loss:		0.368812
  validation accuracy:		90.76 %
Epoch 546 of 2000 took 0.099s
  training loss:		0.142701
  validation loss:		0.387605
  validation accuracy:		90.65 %
Epoch 547 of 2000 took 0.104s
  training loss:		0.144563
  validation loss:		0.386124
  validation accuracy:		90.65 %
Epoch 548 of 2000 took 0.101s
  training loss:		0.139061
  validation loss:		0.383555
  validation accuracy:		91.09 %
Epoch 549 of 2000 took 0.099s
  training loss:		0.143568
  validation loss:		0.385819
  validation accuracy:		91.09 %
Epoch 550 of 2000 took 0.104s
  training loss:		0.142760
  validation loss:		0.382366
  validation accuracy:		91.30 %
Epoch 551 of 2000 took 0.100s
  training loss:		0.141846
  validation loss:		0.390400
  validation accuracy:		90.87 %
Epoch 552 of 2000 took 0.099s
  training loss:		0.142889
  validation loss:		0.393194
  validation accuracy:		91.09 %
Epoch 553 of 2000 took 0.100s
  training loss:		0.139824
  validation loss:		0.415414
  validation accuracy:		90.54 %
Epoch 554 of 2000 took 0.100s
  training loss:		0.148057
  validation loss:		0.387077
  validation accuracy:		90.98 %
Epoch 555 of 2000 took 0.103s
  training loss:		0.140277
  validation loss:		0.379100
  validation accuracy:		90.65 %
Epoch 556 of 2000 took 0.101s
  training loss:		0.142308
  validation loss:		0.368729
  validation accuracy:		90.87 %
Epoch 557 of 2000 took 0.100s
  training loss:		0.140218
  validation loss:		0.382834
  validation accuracy:		91.30 %
Epoch 558 of 2000 took 0.106s
  training loss:		0.140222
  validation loss:		0.380948
  validation accuracy:		90.98 %
Epoch 559 of 2000 took 0.099s
  training loss:		0.141996
  validation loss:		0.384300
  validation accuracy:		90.98 %
Epoch 560 of 2000 took 0.100s
  training loss:		0.138672
  validation loss:		0.386581
  validation accuracy:		90.65 %
Epoch 561 of 2000 took 0.099s
  training loss:		0.142890
  validation loss:		0.379257
  validation accuracy:		90.98 %
Epoch 562 of 2000 took 0.101s
  training loss:		0.135772
  validation loss:		0.394451
  validation accuracy:		90.98 %
Epoch 563 of 2000 took 0.104s
  training loss:		0.136699
  validation loss:		0.390631
  validation accuracy:		90.87 %
Epoch 564 of 2000 took 0.099s
  training loss:		0.134801
  validation loss:		0.386245
  validation accuracy:		90.43 %
Epoch 565 of 2000 took 0.100s
  training loss:		0.140675
  validation loss:		0.399820
  validation accuracy:		90.98 %
Epoch 566 of 2000 took 0.104s
  training loss:		0.142929
  validation loss:		0.376234
  validation accuracy:		91.20 %
Epoch 567 of 2000 took 0.096s
  training loss:		0.136789
  validation loss:		0.399152
  validation accuracy:		91.20 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.135912
  validation loss:		0.380732
  validation accuracy:		90.87 %
Epoch 569 of 2000 took 0.096s
  training loss:		0.152048
  validation loss:		0.380562
  validation accuracy:		91.30 %
Epoch 570 of 2000 took 0.100s
  training loss:		0.137209
  validation loss:		0.401914
  validation accuracy:		90.76 %
Epoch 571 of 2000 took 0.098s
  training loss:		0.139800
  validation loss:		0.376011
  validation accuracy:		90.98 %
Epoch 572 of 2000 took 0.096s
  training loss:		0.139361
  validation loss:		0.401950
  validation accuracy:		90.98 %
Epoch 573 of 2000 took 0.100s
  training loss:		0.136981
  validation loss:		0.384060
  validation accuracy:		90.87 %
Epoch 574 of 2000 took 0.098s
  training loss:		0.139589
  validation loss:		0.381550
  validation accuracy:		91.20 %
Epoch 575 of 2000 took 0.096s
  training loss:		0.137075
  validation loss:		0.381715
  validation accuracy:		90.54 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.139301
  validation loss:		0.369996
  validation accuracy:		90.87 %
Epoch 577 of 2000 took 0.096s
  training loss:		0.134462
  validation loss:		0.381732
  validation accuracy:		90.76 %
Epoch 578 of 2000 took 0.101s
  training loss:		0.132979
  validation loss:		0.413515
  validation accuracy:		90.43 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.138119
  validation loss:		0.384708
  validation accuracy:		90.98 %
Epoch 580 of 2000 took 0.096s
  training loss:		0.135665
  validation loss:		0.391583
  validation accuracy:		90.98 %
Epoch 581 of 2000 took 0.102s
  training loss:		0.134351
  validation loss:		0.386313
  validation accuracy:		90.98 %
Epoch 582 of 2000 took 0.096s
  training loss:		0.146177
  validation loss:		0.396540
  validation accuracy:		90.76 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.140345
  validation loss:		0.375018
  validation accuracy:		91.09 %
Epoch 584 of 2000 took 0.096s
  training loss:		0.132448
  validation loss:		0.390363
  validation accuracy:		91.09 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.132724
  validation loss:		0.380421
  validation accuracy:		90.65 %
Epoch 586 of 2000 took 0.100s
  training loss:		0.128129
  validation loss:		0.397643
  validation accuracy:		90.76 %
Epoch 587 of 2000 took 0.096s
  training loss:		0.137070
  validation loss:		0.380636
  validation accuracy:		90.87 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.132651
  validation loss:		0.403487
  validation accuracy:		90.43 %
Epoch 589 of 2000 took 0.102s
  training loss:		0.135999
  validation loss:		0.382537
  validation accuracy:		91.30 %
Epoch 590 of 2000 took 0.096s
  training loss:		0.133713
  validation loss:		0.397200
  validation accuracy:		90.87 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.135853
  validation loss:		0.392834
  validation accuracy:		91.09 %
Epoch 592 of 2000 took 0.096s
  training loss:		0.127794
  validation loss:		0.385556
  validation accuracy:		91.09 %
Epoch 593 of 2000 took 0.098s
  training loss:		0.131667
  validation loss:		0.390608
  validation accuracy:		90.98 %
Epoch 594 of 2000 took 0.099s
  training loss:		0.132122
  validation loss:		0.394264
  validation accuracy:		90.98 %
Epoch 595 of 2000 took 0.096s
  training loss:		0.130792
  validation loss:		0.385036
  validation accuracy:		91.09 %
Epoch 596 of 2000 took 0.098s
  training loss:		0.128055
  validation loss:		0.400397
  validation accuracy:		90.98 %
Epoch 597 of 2000 took 0.100s
  training loss:		0.134226
  validation loss:		0.386609
  validation accuracy:		90.65 %
Epoch 598 of 2000 took 0.096s
  training loss:		0.128571
  validation loss:		0.399263
  validation accuracy:		91.30 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.128961
  validation loss:		0.369477
  validation accuracy:		90.76 %
Epoch 600 of 2000 took 0.096s
  training loss:		0.130507
  validation loss:		0.393467
  validation accuracy:		91.09 %
Epoch 601 of 2000 took 0.101s
  training loss:		0.128834
  validation loss:		0.382328
  validation accuracy:		91.20 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.128780
  validation loss:		0.394323
  validation accuracy:		90.87 %
Epoch 603 of 2000 took 0.096s
  training loss:		0.130590
  validation loss:		0.389857
  validation accuracy:		91.20 %
Epoch 604 of 2000 took 0.102s
  training loss:		0.128884
  validation loss:		0.402166
  validation accuracy:		91.09 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.129916
  validation loss:		0.383121
  validation accuracy:		91.09 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.133164
  validation loss:		0.379659
  validation accuracy:		90.76 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.124214
  validation loss:		0.405000
  validation accuracy:		90.87 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.123738
  validation loss:		0.375932
  validation accuracy:		91.20 %
Epoch 609 of 2000 took 0.100s
  training loss:		0.129111
  validation loss:		0.385505
  validation accuracy:		91.41 %
Epoch 610 of 2000 took 0.096s
  training loss:		0.128926
  validation loss:		0.395707
  validation accuracy:		90.98 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.130111
  validation loss:		0.380525
  validation accuracy:		91.09 %
Epoch 612 of 2000 took 0.102s
  training loss:		0.128001
  validation loss:		0.383452
  validation accuracy:		90.87 %
Epoch 613 of 2000 took 0.096s
  training loss:		0.125905
  validation loss:		0.398786
  validation accuracy:		90.65 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.128462
  validation loss:		0.383040
  validation accuracy:		91.20 %
Epoch 615 of 2000 took 0.096s
  training loss:		0.125031
  validation loss:		0.388433
  validation accuracy:		90.54 %
Epoch 616 of 2000 took 0.099s
  training loss:		0.131816
  validation loss:		0.407394
  validation accuracy:		90.65 %
Epoch 617 of 2000 took 0.099s
  training loss:		0.128715
  validation loss:		0.401083
  validation accuracy:		90.98 %
Epoch 618 of 2000 took 0.096s
  training loss:		0.133938
  validation loss:		0.413242
  validation accuracy:		90.87 %
Epoch 619 of 2000 took 0.099s
  training loss:		0.130629
  validation loss:		0.388844
  validation accuracy:		90.98 %
Epoch 620 of 2000 took 0.100s
  training loss:		0.125005
  validation loss:		0.389382
  validation accuracy:		91.20 %
Epoch 621 of 2000 took 0.096s
  training loss:		0.127991
  validation loss:		0.405632
  validation accuracy:		91.09 %
Epoch 622 of 2000 took 0.097s
  training loss:		0.124455
  validation loss:		0.381636
  validation accuracy:		90.98 %
Epoch 623 of 2000 took 0.096s
  training loss:		0.124553
  validation loss:		0.381639
  validation accuracy:		90.98 %
Epoch 624 of 2000 took 0.101s
  training loss:		0.127099
  validation loss:		0.402459
  validation accuracy:		90.98 %
Epoch 625 of 2000 took 0.099s
  training loss:		0.129619
  validation loss:		0.390535
  validation accuracy:		91.20 %
Epoch 626 of 2000 took 0.124s
  training loss:		0.123221
  validation loss:		0.401530
  validation accuracy:		91.09 %
Epoch 627 of 2000 took 0.101s
  training loss:		0.124069
  validation loss:		0.400983
  validation accuracy:		90.76 %
Epoch 628 of 2000 took 0.098s
  training loss:		0.131496
  validation loss:		0.410206
  validation accuracy:		90.65 %
Epoch 629 of 2000 took 0.099s
  training loss:		0.122953
  validation loss:		0.407149
  validation accuracy:		90.33 %
Epoch 630 of 2000 took 0.100s
  training loss:		0.129882
  validation loss:		0.390670
  validation accuracy:		91.20 %
Epoch 631 of 2000 took 0.100s
  training loss:		0.125577
  validation loss:		0.395845
  validation accuracy:		90.98 %
Epoch 632 of 2000 took 0.103s
  training loss:		0.122989
  validation loss:		0.392082
  validation accuracy:		90.76 %
Epoch 633 of 2000 took 0.100s
  training loss:		0.121793
  validation loss:		0.392081
  validation accuracy:		90.98 %
Epoch 634 of 2000 took 0.099s
  training loss:		0.124605
  validation loss:		0.404237
  validation accuracy:		90.87 %
Epoch 635 of 2000 took 0.106s
  training loss:		0.122723
  validation loss:		0.395707
  validation accuracy:		91.20 %
Epoch 636 of 2000 took 0.099s
  training loss:		0.123414
  validation loss:		0.393667
  validation accuracy:		90.76 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.120508
  validation loss:		0.394147
  validation accuracy:		91.41 %
Epoch 638 of 2000 took 0.096s
  training loss:		0.122946
  validation loss:		0.379074
  validation accuracy:		91.41 %
Epoch 639 of 2000 took 0.098s
  training loss:		0.125708
  validation loss:		0.396217
  validation accuracy:		91.20 %
Epoch 640 of 2000 took 0.100s
  training loss:		0.116857
  validation loss:		0.396730
  validation accuracy:		90.76 %
Epoch 641 of 2000 took 0.096s
  training loss:		0.124395
  validation loss:		0.392498
  validation accuracy:		90.54 %
Epoch 642 of 2000 took 0.097s
  training loss:		0.122425
  validation loss:		0.404848
  validation accuracy:		90.87 %
Epoch 643 of 2000 took 0.102s
  training loss:		0.130550
  validation loss:		0.396197
  validation accuracy:		90.76 %
Epoch 644 of 2000 took 0.096s
  training loss:		0.121569
  validation loss:		0.383964
  validation accuracy:		90.98 %
Epoch 645 of 2000 took 0.097s
  training loss:		0.129470
  validation loss:		0.407008
  validation accuracy:		90.98 %
Epoch 646 of 2000 took 0.096s
  training loss:		0.119268
  validation loss:		0.397137
  validation accuracy:		90.33 %
Epoch 647 of 2000 took 0.101s
  training loss:		0.123903
  validation loss:		0.403520
  validation accuracy:		90.87 %
Epoch 648 of 2000 took 0.098s
  training loss:		0.129275
  validation loss:		0.396055
  validation accuracy:		91.09 %
Epoch 649 of 2000 took 0.096s
  training loss:		0.120619
  validation loss:		0.400924
  validation accuracy:		90.87 %
Epoch 650 of 2000 took 0.100s
  training loss:		0.122653
  validation loss:		0.416098
  validation accuracy:		89.67 %
Epoch 651 of 2000 took 0.099s
  training loss:		0.121975
  validation loss:		0.395865
  validation accuracy:		90.87 %
Epoch 652 of 2000 took 0.096s
  training loss:		0.113495
  validation loss:		0.393001
  validation accuracy:		91.09 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.109642
  validation loss:		0.410778
  validation accuracy:		90.54 %
Epoch 654 of 2000 took 0.096s
  training loss:		0.119835
  validation loss:		0.401060
  validation accuracy:		90.98 %
Epoch 655 of 2000 took 0.101s
  training loss:		0.119907
  validation loss:		0.405724
  validation accuracy:		90.76 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.119805
  validation loss:		0.413823
  validation accuracy:		90.65 %
Epoch 657 of 2000 took 0.096s
  training loss:		0.116670
  validation loss:		0.394746
  validation accuracy:		91.09 %
Epoch 658 of 2000 took 0.102s
  training loss:		0.117970
  validation loss:		0.396373
  validation accuracy:		90.87 %
Epoch 659 of 2000 took 0.096s
  training loss:		0.112631
  validation loss:		0.400548
  validation accuracy:		90.87 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.110998
  validation loss:		0.393272
  validation accuracy:		90.87 %
Epoch 661 of 2000 took 0.096s
  training loss:		0.117401
  validation loss:		0.413594
  validation accuracy:		90.65 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.122426
  validation loss:		0.405016
  validation accuracy:		90.43 %
Epoch 663 of 2000 took 0.101s
  training loss:		0.117463
  validation loss:		0.391791
  validation accuracy:		91.09 %
Epoch 664 of 2000 took 0.096s
  training loss:		0.119962
  validation loss:		0.378672
  validation accuracy:		90.87 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.115922
  validation loss:		0.420826
  validation accuracy:		90.65 %
Epoch 666 of 2000 took 0.165s
  training loss:		0.120117
  validation loss:		0.403566
  validation accuracy:		90.76 %
Epoch 667 of 2000 took 0.164s
  training loss:		0.117114
  validation loss:		0.402220
  validation accuracy:		90.43 %
Epoch 668 of 2000 took 0.165s
  training loss:		0.117999
  validation loss:		0.414513
  validation accuracy:		90.65 %
Epoch 669 of 2000 took 0.164s
  training loss:		0.118557
  validation loss:		0.410515
  validation accuracy:		91.09 %
Epoch 670 of 2000 took 0.169s
  training loss:		0.121868
  validation loss:		0.421864
  validation accuracy:		90.54 %
Epoch 671 of 2000 took 0.166s
  training loss:		0.110709
  validation loss:		0.410974
  validation accuracy:		90.43 %
Epoch 672 of 2000 took 0.164s
  training loss:		0.116790
  validation loss:		0.419142
  validation accuracy:		91.20 %
Epoch 673 of 2000 took 0.170s
  training loss:		0.116343
  validation loss:		0.406162
  validation accuracy:		90.98 %
Epoch 674 of 2000 took 0.165s
  training loss:		0.121722
  validation loss:		0.417463
  validation accuracy:		90.54 %
Epoch 675 of 2000 took 0.165s
  training loss:		0.117215
  validation loss:		0.395917
  validation accuracy:		91.09 %
Epoch 676 of 2000 took 0.164s
  training loss:		0.115133
  validation loss:		0.425870
  validation accuracy:		90.87 %
Epoch 677 of 2000 took 0.166s
  training loss:		0.119775
  validation loss:		0.402981
  validation accuracy:		90.98 %
Epoch 678 of 2000 took 0.154s
  training loss:		0.111080
  validation loss:		0.409910
  validation accuracy:		90.43 %
Epoch 679 of 2000 took 0.166s
  training loss:		0.114293
  validation loss:		0.408071
  validation accuracy:		90.98 %
Epoch 680 of 2000 took 0.175s
  training loss:		0.116261
  validation loss:		0.394237
  validation accuracy:		90.98 %
Epoch 681 of 2000 took 0.178s
  training loss:		0.113329
  validation loss:		0.385216
  validation accuracy:		90.65 %
Epoch 682 of 2000 took 0.171s
  training loss:		0.118342
  validation loss:		0.411385
  validation accuracy:		90.76 %
Epoch 683 of 2000 took 0.174s
  training loss:		0.116069
  validation loss:		0.421930
  validation accuracy:		90.65 %
Epoch 684 of 2000 took 0.170s
  training loss:		0.113647
  validation loss:		0.426558
  validation accuracy:		90.43 %
Epoch 685 of 2000 took 0.179s
  training loss:		0.114517
  validation loss:		0.411006
  validation accuracy:		91.09 %
Epoch 686 of 2000 took 0.173s
  training loss:		0.109690
  validation loss:		0.394717
  validation accuracy:		91.30 %
Epoch 687 of 2000 took 0.170s
  training loss:		0.111332
  validation loss:		0.401534
  validation accuracy:		90.65 %
Epoch 688 of 2000 took 0.178s
  training loss:		0.115818
  validation loss:		0.392750
  validation accuracy:		91.20 %
Epoch 689 of 2000 took 0.169s
  training loss:		0.112946
  validation loss:		0.392144
  validation accuracy:		90.87 %
Epoch 690 of 2000 took 0.168s
  training loss:		0.110516
  validation loss:		0.394403
  validation accuracy:		90.87 %
Epoch 691 of 2000 took 0.166s
  training loss:		0.110875
  validation loss:		0.400454
  validation accuracy:		90.98 %
Epoch 692 of 2000 took 0.175s
  training loss:		0.117188
  validation loss:		0.407924
  validation accuracy:		90.65 %
Epoch 693 of 2000 took 0.176s
  training loss:		0.113010
  validation loss:		0.405024
  validation accuracy:		91.09 %
Epoch 694 of 2000 took 0.170s
  training loss:		0.109262
  validation loss:		0.415839
  validation accuracy:		90.43 %
Epoch 695 of 2000 took 0.176s
  training loss:		0.114086
  validation loss:		0.409383
  validation accuracy:		90.65 %
Epoch 696 of 2000 took 0.176s
  training loss:		0.111263
  validation loss:		0.476105
  validation accuracy:		89.46 %
Epoch 697 of 2000 took 0.172s
  training loss:		0.115643
  validation loss:		0.393812
  validation accuracy:		91.41 %
Epoch 698 of 2000 took 0.172s
  training loss:		0.108927
  validation loss:		0.409979
  validation accuracy:		90.11 %
Epoch 699 of 2000 took 0.171s
  training loss:		0.111055
  validation loss:		0.439871
  validation accuracy:		90.00 %
Epoch 700 of 2000 took 0.176s
  training loss:		0.111767
  validation loss:		0.415107
  validation accuracy:		90.87 %
Epoch 701 of 2000 took 0.172s
  training loss:		0.106892
  validation loss:		0.427776
  validation accuracy:		90.43 %
Epoch 702 of 2000 took 0.169s
  training loss:		0.111919
  validation loss:		0.408579
  validation accuracy:		90.33 %
Epoch 703 of 2000 took 0.168s
  training loss:		0.111451
  validation loss:		0.405957
  validation accuracy:		90.43 %
Epoch 704 of 2000 took 0.173s
  training loss:		0.114661
  validation loss:		0.395131
  validation accuracy:		91.41 %
Epoch 705 of 2000 took 0.177s
  training loss:		0.115162
  validation loss:		0.411678
  validation accuracy:		90.65 %
Epoch 706 of 2000 took 0.167s
  training loss:		0.110660
  validation loss:		0.416925
  validation accuracy:		91.30 %
Epoch 707 of 2000 took 0.173s
  training loss:		0.111702
  validation loss:		0.397477
  validation accuracy:		90.87 %
Epoch 708 of 2000 took 0.170s
  training loss:		0.108060
  validation loss:		0.412417
  validation accuracy:		90.98 %
Epoch 709 of 2000 took 0.175s
  training loss:		0.106151
  validation loss:		0.402141
  validation accuracy:		91.30 %
Epoch 710 of 2000 took 0.176s
  training loss:		0.108033
  validation loss:		0.423115
  validation accuracy:		90.98 %
Epoch 711 of 2000 took 0.170s
  training loss:		0.107695
  validation loss:		0.421096
  validation accuracy:		90.65 %
Epoch 712 of 2000 took 0.176s
  training loss:		0.104460
  validation loss:		0.417132
  validation accuracy:		90.33 %
Epoch 713 of 2000 took 0.175s
  training loss:		0.113086
  validation loss:		0.405106
  validation accuracy:		90.65 %
Epoch 714 of 2000 took 0.171s
  training loss:		0.108874
  validation loss:		0.416864
  validation accuracy:		90.11 %
Epoch 715 of 2000 took 0.172s
  training loss:		0.109633
  validation loss:		0.412017
  validation accuracy:		90.65 %
Epoch 716 of 2000 took 0.170s
  training loss:		0.108440
  validation loss:		0.431377
  validation accuracy:		90.54 %
Epoch 717 of 2000 took 0.176s
  training loss:		0.103494
  validation loss:		0.416660
  validation accuracy:		90.11 %
Epoch 718 of 2000 took 0.172s
  training loss:		0.108771
  validation loss:		0.403103
  validation accuracy:		90.87 %
Epoch 719 of 2000 took 0.171s
  training loss:		0.107697
  validation loss:		0.414631
  validation accuracy:		90.54 %
Epoch 720 of 2000 took 0.179s
  training loss:		0.108056
  validation loss:		0.412081
  validation accuracy:		90.43 %
Epoch 721 of 2000 took 0.169s
  training loss:		0.106861
  validation loss:		0.418780
  validation accuracy:		90.76 %
Epoch 722 of 2000 took 0.173s
  training loss:		0.107003
  validation loss:		0.428249
  validation accuracy:		90.65 %
Epoch 723 of 2000 took 0.170s
  training loss:		0.105575
  validation loss:		0.414880
  validation accuracy:		90.43 %
Epoch 724 of 2000 took 0.177s
  training loss:		0.105606
  validation loss:		0.411474
  validation accuracy:		90.98 %
Epoch 725 of 2000 took 0.175s
  training loss:		0.103250
  validation loss:		0.401458
  validation accuracy:		90.65 %
Epoch 726 of 2000 took 0.175s
  training loss:		0.107715
  validation loss:		0.402931
  validation accuracy:		90.76 %
Epoch 727 of 2000 took 0.179s
  training loss:		0.105965
  validation loss:		0.406243
  validation accuracy:		90.54 %
Epoch 728 of 2000 took 0.173s
  training loss:		0.103106
  validation loss:		0.419034
  validation accuracy:		90.65 %
Epoch 729 of 2000 took 0.200s
  training loss:		0.102762
  validation loss:		0.418595
  validation accuracy:		90.43 %
Epoch 730 of 2000 took 0.168s
  training loss:		0.101918
  validation loss:		0.416509
  validation accuracy:		90.22 %
Epoch 731 of 2000 took 0.171s
  training loss:		0.105284
  validation loss:		0.393487
  validation accuracy:		91.09 %
Epoch 732 of 2000 took 0.181s
  training loss:		0.102465
  validation loss:		0.412146
  validation accuracy:		90.87 %
Epoch 733 of 2000 took 0.170s
  training loss:		0.100429
  validation loss:		0.405976
  validation accuracy:		90.98 %
Epoch 734 of 2000 took 0.172s
  training loss:		0.108335
  validation loss:		0.413904
  validation accuracy:		90.87 %
Epoch 735 of 2000 took 0.175s
  training loss:		0.106351
  validation loss:		0.428160
  validation accuracy:		91.09 %
Epoch 736 of 2000 took 0.169s
  training loss:		0.102398
  validation loss:		0.428283
  validation accuracy:		90.33 %
Epoch 737 of 2000 took 0.173s
  training loss:		0.106881
  validation loss:		0.431477
  validation accuracy:		90.76 %
Epoch 738 of 2000 took 0.169s
  training loss:		0.099040
  validation loss:		0.407904
  validation accuracy:		90.43 %
Epoch 739 of 2000 took 0.177s
  training loss:		0.106252
  validation loss:		0.418474
  validation accuracy:		90.65 %
Epoch 740 of 2000 took 0.172s
  training loss:		0.104540
  validation loss:		0.408957
  validation accuracy:		90.11 %
Epoch 741 of 2000 took 0.171s
  training loss:		0.098894
  validation loss:		0.434858
  validation accuracy:		90.22 %
Epoch 742 of 2000 took 0.179s
  training loss:		0.101450
  validation loss:		0.421822
  validation accuracy:		90.54 %
Epoch 743 of 2000 took 0.172s
  training loss:		0.104384
  validation loss:		0.432403
  validation accuracy:		90.43 %
Epoch 744 of 2000 took 0.208s
  training loss:		0.102326
  validation loss:		0.419191
  validation accuracy:		90.76 %
Epoch 745 of 2000 took 0.329s
  training loss:		0.103933
  validation loss:		0.412378
  validation accuracy:		90.43 %
Epoch 746 of 2000 took 0.211s
  training loss:		0.100304
  validation loss:		0.420388
  validation accuracy:		90.11 %
Epoch 747 of 2000 took 0.240s
  training loss:		0.106423
  validation loss:		0.420389
  validation accuracy:		90.00 %
Epoch 748 of 2000 took 0.232s
  training loss:		0.100049
  validation loss:		0.433433
  validation accuracy:		89.78 %
Epoch 749 of 2000 took 0.215s
  training loss:		0.095427
  validation loss:		0.413635
  validation accuracy:		89.89 %
Epoch 750 of 2000 took 0.174s
  training loss:		0.102833
  validation loss:		0.434970
  validation accuracy:		90.76 %
Epoch 751 of 2000 took 0.266s
  training loss:		0.098232
  validation loss:		0.439545
  validation accuracy:		89.78 %
Epoch 752 of 2000 took 0.296s
  training loss:		0.103394
  validation loss:		0.409073
  validation accuracy:		90.65 %
Epoch 753 of 2000 took 0.299s
  training loss:		0.098934
  validation loss:		0.419851
  validation accuracy:		90.76 %
Epoch 754 of 2000 took 0.279s
  training loss:		0.103942
  validation loss:		0.405220
  validation accuracy:		91.96 %
Epoch 755 of 2000 took 0.164s
  training loss:		0.101111
  validation loss:		0.423086
  validation accuracy:		91.20 %
Epoch 756 of 2000 took 0.163s
  training loss:		0.100560
  validation loss:		0.444770
  validation accuracy:		89.57 %
Epoch 757 of 2000 took 0.163s
  training loss:		0.103324
  validation loss:		0.426695
  validation accuracy:		90.33 %
Epoch 758 of 2000 took 0.163s
  training loss:		0.100016
  validation loss:		0.431736
  validation accuracy:		90.22 %
Epoch 759 of 2000 took 0.163s
  training loss:		0.100824
  validation loss:		0.418890
  validation accuracy:		91.30 %
Epoch 760 of 2000 took 0.166s
  training loss:		0.103714
  validation loss:		0.408315
  validation accuracy:		90.98 %
Epoch 761 of 2000 took 0.254s
  training loss:		0.108079
  validation loss:		0.407970
  validation accuracy:		90.98 %
Epoch 762 of 2000 took 0.164s
  training loss:		0.097251
  validation loss:		0.428458
  validation accuracy:		90.87 %
Epoch 763 of 2000 took 0.164s
  training loss:		0.099219
  validation loss:		0.421168
  validation accuracy:		90.22 %
Epoch 764 of 2000 took 0.164s
  training loss:		0.098395
  validation loss:		0.428632
  validation accuracy:		90.00 %
Epoch 765 of 2000 took 0.164s
  training loss:		0.095171
  validation loss:		0.419644
  validation accuracy:		90.33 %
Epoch 766 of 2000 took 0.164s
  training loss:		0.098212
  validation loss:		0.448664
  validation accuracy:		90.00 %
Epoch 767 of 2000 took 0.164s
  training loss:		0.094963
  validation loss:		0.431880
  validation accuracy:		90.76 %
Epoch 768 of 2000 took 0.164s
  training loss:		0.095996
  validation loss:		0.411487
  validation accuracy:		90.65 %
Epoch 769 of 2000 took 0.164s
  training loss:		0.098971
  validation loss:		0.437156
  validation accuracy:		90.54 %
Epoch 770 of 2000 took 0.164s
  training loss:		0.097372
  validation loss:		0.421902
  validation accuracy:		90.43 %
Epoch 771 of 2000 took 0.164s
  training loss:		0.096535
  validation loss:		0.432700
  validation accuracy:		90.87 %
Epoch 772 of 2000 took 0.164s
  training loss:		0.094765
  validation loss:		0.426887
  validation accuracy:		90.22 %
Epoch 773 of 2000 took 0.164s
  training loss:		0.096851
  validation loss:		0.415054
  validation accuracy:		90.22 %
Epoch 774 of 2000 took 0.164s
  training loss:		0.098238
  validation loss:		0.419111
  validation accuracy:		90.54 %
Epoch 775 of 2000 took 0.164s
  training loss:		0.097642
  validation loss:		0.430445
  validation accuracy:		90.76 %
Epoch 776 of 2000 took 0.164s
  training loss:		0.096543
  validation loss:		0.457895
  validation accuracy:		90.33 %
Epoch 777 of 2000 took 0.164s
  training loss:		0.095595
  validation loss:		0.428332
  validation accuracy:		90.33 %
Epoch 778 of 2000 took 0.164s
  training loss:		0.097345
  validation loss:		0.410089
  validation accuracy:		90.87 %
Epoch 779 of 2000 took 0.164s
  training loss:		0.095093
  validation loss:		0.425704
  validation accuracy:		90.54 %
Epoch 780 of 2000 took 0.164s
  training loss:		0.094765
  validation loss:		0.419982
  validation accuracy:		91.41 %
Epoch 781 of 2000 took 0.164s
  training loss:		0.097167
  validation loss:		0.418799
  validation accuracy:		90.76 %
Epoch 782 of 2000 took 0.164s
  training loss:		0.100362
  validation loss:		0.440369
  validation accuracy:		89.89 %
Epoch 783 of 2000 took 0.164s
  training loss:		0.094143
  validation loss:		0.433244
  validation accuracy:		90.76 %
Epoch 784 of 2000 took 0.164s
  training loss:		0.092685
  validation loss:		0.447917
  validation accuracy:		89.89 %
Epoch 785 of 2000 took 0.164s
  training loss:		0.093927
  validation loss:		0.425417
  validation accuracy:		91.41 %
Epoch 786 of 2000 took 0.164s
  training loss:		0.092422
  validation loss:		0.442285
  validation accuracy:		89.89 %
Epoch 787 of 2000 took 0.166s
  training loss:		0.100791
  validation loss:		0.409793
  validation accuracy:		90.65 %
Epoch 788 of 2000 took 0.254s
  training loss:		0.095535
  validation loss:		0.420475
  validation accuracy:		90.76 %
Epoch 789 of 2000 took 0.164s
  training loss:		0.092682
  validation loss:		0.436392
  validation accuracy:		90.11 %
Epoch 790 of 2000 took 0.164s
  training loss:		0.092316
  validation loss:		0.421870
  validation accuracy:		91.09 %
Epoch 791 of 2000 took 0.164s
  training loss:		0.093755
  validation loss:		0.421951
  validation accuracy:		91.20 %
Epoch 792 of 2000 took 0.164s
  training loss:		0.090972
  validation loss:		0.431793
  validation accuracy:		91.20 %
Epoch 793 of 2000 took 0.163s
  training loss:		0.095593
  validation loss:		0.438341
  validation accuracy:		90.43 %
Epoch 794 of 2000 took 0.171s
  training loss:		0.091456
  validation loss:		0.414361
  validation accuracy:		90.43 %
Epoch 795 of 2000 took 0.164s
  training loss:		0.092065
  validation loss:		0.423917
  validation accuracy:		91.30 %
Epoch 796 of 2000 took 0.164s
  training loss:		0.088963
  validation loss:		0.440866
  validation accuracy:		90.54 %
Epoch 797 of 2000 took 0.164s
  training loss:		0.093454
  validation loss:		0.434851
  validation accuracy:		90.87 %
Epoch 798 of 2000 took 0.164s
  training loss:		0.093343
  validation loss:		0.416620
  validation accuracy:		91.20 %
Epoch 799 of 2000 took 0.164s
  training loss:		0.093463
  validation loss:		0.421912
  validation accuracy:		90.22 %
Epoch 800 of 2000 took 0.164s
  training loss:		0.096764
  validation loss:		0.426147
  validation accuracy:		90.65 %
Epoch 801 of 2000 took 0.164s
  training loss:		0.089142
  validation loss:		0.440572
  validation accuracy:		90.98 %
Epoch 802 of 2000 took 0.164s
  training loss:		0.094443
  validation loss:		0.424635
  validation accuracy:		91.20 %
Epoch 803 of 2000 took 0.164s
  training loss:		0.092852
  validation loss:		0.442216
  validation accuracy:		90.87 %
Epoch 804 of 2000 took 0.164s
  training loss:		0.089641
  validation loss:		0.438427
  validation accuracy:		90.98 %
Epoch 805 of 2000 took 0.164s
  training loss:		0.093885
  validation loss:		0.434900
  validation accuracy:		91.09 %
Epoch 806 of 2000 took 0.198s
  training loss:		0.090172
  validation loss:		0.461777
  validation accuracy:		90.33 %
Epoch 807 of 2000 took 0.190s
  training loss:		0.095134
  validation loss:		0.443802
  validation accuracy:		91.20 %
Epoch 808 of 2000 took 0.164s
  training loss:		0.088509
  validation loss:		0.441345
  validation accuracy:		90.76 %
Epoch 809 of 2000 took 0.164s
  training loss:		0.086555
  validation loss:		0.422179
  validation accuracy:		90.65 %
Epoch 810 of 2000 took 0.164s
  training loss:		0.093009
  validation loss:		0.426636
  validation accuracy:		90.98 %
Epoch 811 of 2000 took 0.163s
  training loss:		0.086058
  validation loss:		0.411694
  validation accuracy:		91.20 %
Epoch 812 of 2000 took 0.161s
  training loss:		0.084253
  validation loss:		0.451135
  validation accuracy:		90.65 %
Epoch 813 of 2000 took 0.167s
  training loss:		0.086718
  validation loss:		0.415191
  validation accuracy:		91.96 %
Epoch 814 of 2000 took 0.164s
  training loss:		0.087031
  validation loss:		0.442545
  validation accuracy:		90.11 %
Epoch 815 of 2000 took 0.169s
  training loss:		0.089219
  validation loss:		0.413062
  validation accuracy:		91.20 %
Epoch 816 of 2000 took 0.166s
  training loss:		0.086799
  validation loss:		0.430752
  validation accuracy:		91.63 %
Epoch 817 of 2000 took 0.201s
  training loss:		0.088570
  validation loss:		0.435745
  validation accuracy:		91.09 %
Epoch 818 of 2000 took 0.208s
  training loss:		0.090845
  validation loss:		0.442299
  validation accuracy:		90.54 %
Epoch 819 of 2000 took 0.186s
  training loss:		0.085676
  validation loss:		0.427537
  validation accuracy:		91.41 %
Epoch 820 of 2000 took 0.166s
  training loss:		0.086737
  validation loss:		0.434450
  validation accuracy:		90.98 %
Epoch 821 of 2000 took 0.164s
  training loss:		0.089070
  validation loss:		0.456814
  validation accuracy:		90.22 %
Epoch 822 of 2000 took 0.170s
  training loss:		0.085409
  validation loss:		0.433681
  validation accuracy:		90.43 %
Epoch 823 of 2000 took 0.165s
  training loss:		0.088585
  validation loss:		0.451376
  validation accuracy:		91.09 %
Epoch 824 of 2000 took 0.165s
  training loss:		0.089934
  validation loss:		0.470690
  validation accuracy:		90.76 %
Epoch 825 of 2000 took 0.161s
  training loss:		0.088146
  validation loss:		0.424577
  validation accuracy:		91.09 %
Epoch 826 of 2000 took 0.164s
  training loss:		0.086038
  validation loss:		0.446916
  validation accuracy:		90.33 %
Epoch 827 of 2000 took 0.169s
  training loss:		0.089416
  validation loss:		0.487138
  validation accuracy:		89.89 %
Epoch 828 of 2000 took 0.164s
  training loss:		0.088208
  validation loss:		0.450594
  validation accuracy:		90.87 %
Epoch 829 of 2000 took 0.166s
  training loss:		0.084631
  validation loss:		0.469289
  validation accuracy:		89.67 %
Epoch 830 of 2000 took 0.178s
  training loss:		0.086830
  validation loss:		0.453271
  validation accuracy:		90.00 %
Epoch 831 of 2000 took 0.235s
  training loss:		0.086225
  validation loss:		0.445009
  validation accuracy:		90.65 %
Epoch 832 of 2000 took 0.193s
  training loss:		0.081751
  validation loss:		0.437260
  validation accuracy:		90.22 %
Epoch 833 of 2000 took 0.212s
  training loss:		0.089059
  validation loss:		0.459860
  validation accuracy:		89.89 %
Epoch 834 of 2000 took 0.177s
  training loss:		0.087591
  validation loss:		0.434239
  validation accuracy:		90.54 %
Epoch 835 of 2000 took 0.243s
  training loss:		0.089337
  validation loss:		0.431938
  validation accuracy:		91.30 %
Epoch 836 of 2000 took 0.228s
  training loss:		0.084852
  validation loss:		0.484162
  validation accuracy:		89.67 %
Epoch 837 of 2000 took 0.261s
  training loss:		0.086881
  validation loss:		0.438001
  validation accuracy:		91.09 %
Epoch 838 of 2000 took 0.259s
  training loss:		0.083468
  validation loss:		0.443903
  validation accuracy:		90.98 %
Epoch 839 of 2000 took 0.185s
  training loss:		0.090008
  validation loss:		0.443456
  validation accuracy:		90.98 %
Epoch 840 of 2000 took 0.148s
  training loss:		0.081262
  validation loss:		0.465297
  validation accuracy:		90.76 %
Epoch 841 of 2000 took 0.100s
  training loss:		0.088511
  validation loss:		0.452293
  validation accuracy:		91.30 %
Epoch 842 of 2000 took 0.099s
  training loss:		0.085000
  validation loss:		0.467898
  validation accuracy:		90.11 %
Epoch 843 of 2000 took 0.098s
  training loss:		0.084513
  validation loss:		0.443403
  validation accuracy:		91.20 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.082524
  validation loss:		0.442710
  validation accuracy:		90.76 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.080499
  validation loss:		0.450082
  validation accuracy:		90.76 %
Epoch 846 of 2000 took 0.101s
  training loss:		0.080016
  validation loss:		0.459277
  validation accuracy:		91.09 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.081430
  validation loss:		0.439786
  validation accuracy:		90.87 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.086057
  validation loss:		0.475368
  validation accuracy:		90.33 %
Epoch 849 of 2000 took 0.102s
  training loss:		0.085946
  validation loss:		0.451761
  validation accuracy:		91.09 %
Epoch 850 of 2000 took 0.096s
  training loss:		0.082698
  validation loss:		0.465228
  validation accuracy:		90.87 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.083841
  validation loss:		0.457529
  validation accuracy:		91.09 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.085668
  validation loss:		0.435889
  validation accuracy:		90.98 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.084661
  validation loss:		0.438992
  validation accuracy:		91.41 %
Epoch 854 of 2000 took 0.100s
  training loss:		0.082487
  validation loss:		0.472069
  validation accuracy:		90.65 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.080556
  validation loss:		0.451925
  validation accuracy:		91.20 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.079926
  validation loss:		0.441741
  validation accuracy:		91.30 %
Epoch 857 of 2000 took 0.102s
  training loss:		0.080835
  validation loss:		0.453104
  validation accuracy:		90.98 %
Epoch 858 of 2000 took 0.096s
  training loss:		0.078200
  validation loss:		0.478116
  validation accuracy:		90.33 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.079772
  validation loss:		0.463261
  validation accuracy:		90.87 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.077469
  validation loss:		0.450828
  validation accuracy:		91.41 %
Epoch 861 of 2000 took 0.099s
  training loss:		0.078596
  validation loss:		0.472082
  validation accuracy:		90.43 %
Epoch 862 of 2000 took 0.099s
  training loss:		0.083178
  validation loss:		0.463086
  validation accuracy:		90.43 %
Epoch 863 of 2000 took 0.096s
  training loss:		0.080531
  validation loss:		0.433883
  validation accuracy:		90.76 %
Epoch 864 of 2000 took 0.099s
  training loss:		0.079175
  validation loss:		0.450178
  validation accuracy:		90.87 %
Epoch 865 of 2000 took 0.100s
  training loss:		0.078138
  validation loss:		0.450383
  validation accuracy:		91.20 %
Epoch 866 of 2000 took 0.096s
  training loss:		0.075248
  validation loss:		0.446782
  validation accuracy:		90.98 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.081607
  validation loss:		0.466789
  validation accuracy:		90.43 %
Epoch 868 of 2000 took 0.096s
  training loss:		0.077237
  validation loss:		0.446303
  validation accuracy:		91.30 %
Epoch 869 of 2000 took 0.101s
  training loss:		0.082165
  validation loss:		0.456648
  validation accuracy:		90.98 %
Epoch 870 of 2000 took 0.098s
  training loss:		0.079846
  validation loss:		0.449339
  validation accuracy:		91.30 %
Epoch 871 of 2000 took 0.096s
  training loss:		0.077101
  validation loss:		0.461353
  validation accuracy:		90.98 %
Epoch 872 of 2000 took 0.100s
  training loss:		0.075788
  validation loss:		0.464543
  validation accuracy:		90.76 %
Epoch 873 of 2000 took 0.096s
  training loss:		0.077925
  validation loss:		0.455436
  validation accuracy:		90.98 %
Epoch 874 of 2000 took 0.098s
  training loss:		0.079135
  validation loss:		0.454654
  validation accuracy:		90.76 %
Epoch 875 of 2000 took 0.097s
  training loss:		0.076338
  validation loss:		0.453359
  validation accuracy:		90.76 %
Epoch 876 of 2000 took 0.097s
  training loss:		0.084388
  validation loss:		0.452442
  validation accuracy:		91.52 %
Epoch 877 of 2000 took 0.099s
  training loss:		0.081389
  validation loss:		0.472226
  validation accuracy:		90.65 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.078327
  validation loss:		0.476830
  validation accuracy:		90.87 %
Epoch 879 of 2000 took 0.100s
  training loss:		0.077303
  validation loss:		0.459816
  validation accuracy:		90.98 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.090385
  validation loss:		0.460725
  validation accuracy:		91.30 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.077015
  validation loss:		0.464159
  validation accuracy:		90.76 %
Epoch 882 of 2000 took 0.099s
  training loss:		0.077409
  validation loss:		0.457009
  validation accuracy:		91.20 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.077236
  validation loss:		0.470454
  validation accuracy:		90.87 %
Epoch 884 of 2000 took 0.100s
  training loss:		0.078697
  validation loss:		0.447028
  validation accuracy:		90.98 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.082103
  validation loss:		0.493047
  validation accuracy:		90.76 %
Epoch 886 of 2000 took 0.099s
  training loss:		0.075184
  validation loss:		0.483595
  validation accuracy:		90.22 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.078587
  validation loss:		0.467674
  validation accuracy:		90.98 %
Epoch 888 of 2000 took 0.097s
  training loss:		0.075174
  validation loss:		0.505505
  validation accuracy:		90.00 %
Epoch 889 of 2000 took 0.099s
  training loss:		0.074761
  validation loss:		0.464323
  validation accuracy:		90.65 %
Epoch 890 of 2000 took 0.096s
  training loss:		0.079809
  validation loss:		0.452999
  validation accuracy:		91.30 %
Epoch 891 of 2000 took 0.100s
  training loss:		0.079569
  validation loss:		0.469517
  validation accuracy:		90.98 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.075809
  validation loss:		0.477022
  validation accuracy:		90.54 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.076713
  validation loss:		0.473354
  validation accuracy:		90.87 %
Epoch 894 of 2000 took 0.098s
  training loss:		0.076982
  validation loss:		0.485030
  validation accuracy:		90.54 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.074630
  validation loss:		0.472517
  validation accuracy:		90.65 %
Epoch 896 of 2000 took 0.100s
  training loss:		0.072419
  validation loss:		0.464283
  validation accuracy:		90.87 %
Epoch 897 of 2000 took 0.096s
  training loss:		0.075592
  validation loss:		0.454466
  validation accuracy:		91.52 %
Epoch 898 of 2000 took 0.099s
  training loss:		0.071519
  validation loss:		0.473816
  validation accuracy:		91.20 %
Epoch 899 of 2000 took 0.099s
  training loss:		0.071737
  validation loss:		0.464882
  validation accuracy:		90.87 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.076444
  validation loss:		0.456629
  validation accuracy:		91.09 %
Epoch 901 of 2000 took 0.097s
  training loss:		0.073100
  validation loss:		0.479872
  validation accuracy:		90.87 %
Epoch 902 of 2000 took 0.096s
  training loss:		0.071457
  validation loss:		0.465385
  validation accuracy:		91.30 %
Epoch 903 of 2000 took 0.101s
  training loss:		0.073464
  validation loss:		0.484702
  validation accuracy:		90.33 %
Epoch 904 of 2000 took 0.097s
  training loss:		0.079168
  validation loss:		0.466504
  validation accuracy:		91.30 %
Epoch 905 of 2000 took 0.096s
  training loss:		0.073336
  validation loss:		0.486689
  validation accuracy:		90.43 %
Epoch 906 of 2000 took 0.102s
  training loss:		0.073106
  validation loss:		0.475953
  validation accuracy:		90.87 %
Epoch 907 of 2000 took 0.096s
  training loss:		0.072515
  validation loss:		0.475560
  validation accuracy:		90.98 %
Epoch 908 of 2000 took 0.097s
  training loss:		0.070849
  validation loss:		0.495700
  validation accuracy:		90.87 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.068485
  validation loss:		0.478131
  validation accuracy:		90.87 %
Epoch 910 of 2000 took 0.098s
  training loss:		0.069729
  validation loss:		0.469669
  validation accuracy:		91.20 %
Epoch 911 of 2000 took 0.101s
  training loss:		0.075176
  validation loss:		0.499194
  validation accuracy:		90.43 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.070157
  validation loss:		0.467185
  validation accuracy:		91.52 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.069084
  validation loss:		0.473411
  validation accuracy:		90.65 %
Epoch 914 of 2000 took 0.102s
  training loss:		0.072028
  validation loss:		0.512819
  validation accuracy:		90.76 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.066749
  validation loss:		0.470273
  validation accuracy:		91.09 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.068412
  validation loss:		0.486503
  validation accuracy:		90.87 %
Epoch 917 of 2000 took 0.096s
  training loss:		0.074168
  validation loss:		0.498046
  validation accuracy:		90.33 %
Epoch 918 of 2000 took 0.099s
  training loss:		0.067820
  validation loss:		0.511203
  validation accuracy:		90.33 %
Epoch 919 of 2000 took 0.099s
  training loss:		0.071574
  validation loss:		0.479070
  validation accuracy:		91.20 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.068790
  validation loss:		0.495873
  validation accuracy:		90.87 %
Epoch 921 of 2000 took 0.099s
  training loss:		0.067119
  validation loss:		0.464546
  validation accuracy:		91.09 %
Epoch 922 of 2000 took 0.100s
  training loss:		0.070150
  validation loss:		0.488507
  validation accuracy:		91.09 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.076212
  validation loss:		0.477123
  validation accuracy:		91.20 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.064196
  validation loss:		0.487516
  validation accuracy:		91.20 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.069900
  validation loss:		0.463596
  validation accuracy:		91.74 %
Epoch 926 of 2000 took 0.101s
  training loss:		0.071438
  validation loss:		0.477970
  validation accuracy:		91.20 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.067850
  validation loss:		0.471593
  validation accuracy:		91.09 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.071485
  validation loss:		0.505080
  validation accuracy:		90.33 %
Epoch 929 of 2000 took 0.102s
  training loss:		0.069966
  validation loss:		0.493767
  validation accuracy:		90.33 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.070788
  validation loss:		0.484661
  validation accuracy:		91.20 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.065446
  validation loss:		0.485289
  validation accuracy:		90.76 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.066374
  validation loss:		0.488089
  validation accuracy:		91.30 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.064626
  validation loss:		0.474893
  validation accuracy:		91.52 %
Epoch 934 of 2000 took 0.101s
  training loss:		0.067991
  validation loss:		0.481474
  validation accuracy:		90.87 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.068575
  validation loss:		0.487554
  validation accuracy:		90.76 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.069304
  validation loss:		0.504348
  validation accuracy:		90.76 %
Epoch 937 of 2000 took 0.102s
  training loss:		0.066049
  validation loss:		0.503060
  validation accuracy:		90.43 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.066626
  validation loss:		0.506598
  validation accuracy:		90.54 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.063746
  validation loss:		0.503675
  validation accuracy:		90.65 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.073463
  validation loss:		0.510110
  validation accuracy:		90.76 %
Epoch 941 of 2000 took 0.099s
  training loss:		0.067120
  validation loss:		0.490131
  validation accuracy:		90.98 %
Epoch 942 of 2000 took 0.099s
  training loss:		0.066476
  validation loss:		0.497665
  validation accuracy:		91.09 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.069734
  validation loss:		0.501018
  validation accuracy:		91.09 %
Epoch 944 of 2000 took 0.099s
  training loss:		0.070537
  validation loss:		0.509376
  validation accuracy:		90.65 %
Epoch 945 of 2000 took 0.100s
  training loss:		0.065316
  validation loss:		0.483310
  validation accuracy:		91.52 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.060787
  validation loss:		0.501145
  validation accuracy:		90.87 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.066613
  validation loss:		0.528471
  validation accuracy:		90.54 %
Epoch 948 of 2000 took 0.096s
  training loss:		0.065404
  validation loss:		0.525720
  validation accuracy:		90.22 %
Epoch 949 of 2000 took 0.101s
  training loss:		0.067531
  validation loss:		0.545117
  validation accuracy:		90.00 %
Epoch 950 of 2000 took 0.098s
  training loss:		0.070313
  validation loss:		0.493531
  validation accuracy:		90.76 %
Epoch 951 of 2000 took 0.096s
  training loss:		0.067365
  validation loss:		0.491874
  validation accuracy:		91.63 %
Epoch 952 of 2000 took 0.102s
  training loss:		0.065366
  validation loss:		0.503794
  validation accuracy:		91.09 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.065743
  validation loss:		0.503019
  validation accuracy:		90.76 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.069463
  validation loss:		0.506169
  validation accuracy:		90.98 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.064204
  validation loss:		0.499142
  validation accuracy:		90.98 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.058512
  validation loss:		0.491827
  validation accuracy:		91.30 %
Epoch 957 of 2000 took 0.100s
  training loss:		0.066749
  validation loss:		0.540221
  validation accuracy:		90.00 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.068533
  validation loss:		0.508729
  validation accuracy:		91.09 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.064476
  validation loss:		0.527230
  validation accuracy:		90.76 %
Epoch 960 of 2000 took 0.102s
  training loss:		0.065194
  validation loss:		0.498534
  validation accuracy:		90.87 %
Epoch 961 of 2000 took 0.096s
  training loss:		0.062116
  validation loss:		0.514500
  validation accuracy:		90.76 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.061280
  validation loss:		0.507451
  validation accuracy:		90.98 %
Epoch 963 of 2000 took 0.096s
  training loss:		0.060949
  validation loss:		0.521231
  validation accuracy:		90.87 %
Epoch 964 of 2000 took 0.098s
  training loss:		0.060732
  validation loss:		0.504149
  validation accuracy:		90.87 %
Epoch 965 of 2000 took 0.100s
  training loss:		0.059109
  validation loss:		0.519004
  validation accuracy:		90.98 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.066431
  validation loss:		0.511562
  validation accuracy:		90.76 %
Epoch 967 of 2000 took 0.098s
  training loss:		0.060619
  validation loss:		0.527113
  validation accuracy:		90.87 %
Epoch 968 of 2000 took 0.101s
  training loss:		0.067589
  validation loss:		0.500290
  validation accuracy:		90.76 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.064590
  validation loss:		0.519809
  validation accuracy:		90.54 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.062121
  validation loss:		0.502098
  validation accuracy:		91.30 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.061109
  validation loss:		0.500737
  validation accuracy:		91.09 %
Epoch 972 of 2000 took 0.101s
  training loss:		0.056874
  validation loss:		0.516568
  validation accuracy:		90.87 %
Epoch 973 of 2000 took 0.098s
  training loss:		0.060631
  validation loss:		0.517811
  validation accuracy:		90.76 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.061245
  validation loss:		0.514764
  validation accuracy:		90.76 %
Epoch 975 of 2000 took 0.101s
  training loss:		0.060990
  validation loss:		0.522970
  validation accuracy:		90.65 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.060121
  validation loss:		0.515707
  validation accuracy:		90.87 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.062851
  validation loss:		0.525348
  validation accuracy:		90.65 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.057993
  validation loss:		0.516739
  validation accuracy:		90.76 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.057943
  validation loss:		0.535084
  validation accuracy:		90.65 %
Epoch 980 of 2000 took 0.100s
  training loss:		0.069033
  validation loss:		0.511628
  validation accuracy:		91.20 %
Epoch 981 of 2000 took 0.097s
  training loss:		0.060322
  validation loss:		0.513152
  validation accuracy:		90.87 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.058737
  validation loss:		0.524044
  validation accuracy:		90.87 %
Epoch 983 of 2000 took 0.102s
  training loss:		0.057719
  validation loss:		0.499843
  validation accuracy:		92.07 %
Epoch 984 of 2000 took 0.096s
  training loss:		0.062375
  validation loss:		0.515969
  validation accuracy:		91.09 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.061720
  validation loss:		0.528099
  validation accuracy:		90.98 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.056980
  validation loss:		0.509386
  validation accuracy:		91.09 %
Epoch 987 of 2000 took 0.098s
  training loss:		0.064593
  validation loss:		0.512919
  validation accuracy:		90.98 %
Epoch 988 of 2000 took 0.100s
  training loss:		0.060166
  validation loss:		0.549115
  validation accuracy:		90.22 %
Epoch 989 of 2000 took 0.096s
  training loss:		0.061962
  validation loss:		0.519199
  validation accuracy:		91.09 %
Epoch 990 of 2000 took 0.098s
  training loss:		0.055244
  validation loss:		0.538723
  validation accuracy:		90.22 %
Epoch 991 of 2000 took 0.101s
  training loss:		0.064804
  validation loss:		0.566537
  validation accuracy:		90.33 %
Epoch 992 of 2000 took 0.096s
  training loss:		0.063541
  validation loss:		0.547451
  validation accuracy:		90.54 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.062852
  validation loss:		0.528039
  validation accuracy:		90.87 %
Epoch 994 of 2000 took 0.096s
  training loss:		0.057347
  validation loss:		0.529106
  validation accuracy:		90.76 %
Epoch 995 of 2000 took 0.101s
  training loss:		0.056178
  validation loss:		0.537083
  validation accuracy:		90.65 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.058565
  validation loss:		0.566361
  validation accuracy:		90.00 %
Epoch 997 of 2000 took 0.096s
  training loss:		0.059866
  validation loss:		0.535895
  validation accuracy:		90.87 %
Epoch 998 of 2000 took 0.102s
  training loss:		0.055867
  validation loss:		0.527008
  validation accuracy:		90.87 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.056384
  validation loss:		0.578416
  validation accuracy:		89.67 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.056928
  validation loss:		0.550755
  validation accuracy:		90.33 %
Epoch 1001 of 2000 took 0.096s
  training loss:		0.067245
  validation loss:		0.547271
  validation accuracy:		90.65 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.055769
  validation loss:		0.526756
  validation accuracy:		91.09 %
Epoch 1003 of 2000 took 0.100s
  training loss:		0.058502
  validation loss:		0.544244
  validation accuracy:		90.76 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.055926
  validation loss:		0.540613
  validation accuracy:		90.87 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.056186
  validation loss:		0.537757
  validation accuracy:		90.98 %
Epoch 1006 of 2000 took 0.102s
  training loss:		0.057577
  validation loss:		0.530104
  validation accuracy:		90.87 %
Epoch 1007 of 2000 took 0.096s
  training loss:		0.056587
  validation loss:		0.525833
  validation accuracy:		91.20 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.060297
  validation loss:		0.524737
  validation accuracy:		91.30 %
Epoch 1009 of 2000 took 0.096s
  training loss:		0.063818
  validation loss:		0.531450
  validation accuracy:		91.30 %
Epoch 1010 of 2000 took 0.098s
  training loss:		0.057177
  validation loss:		0.532082
  validation accuracy:		91.20 %
Epoch 1011 of 2000 took 0.100s
  training loss:		0.056997
  validation loss:		0.574962
  validation accuracy:		90.00 %
Epoch 1012 of 2000 took 0.096s
  training loss:		0.063354
  validation loss:		0.545910
  validation accuracy:		90.65 %
Epoch 1013 of 2000 took 0.097s
  training loss:		0.051325
  validation loss:		0.543358
  validation accuracy:		90.76 %
Epoch 1014 of 2000 took 0.101s
  training loss:		0.061299
  validation loss:		0.544258
  validation accuracy:		90.76 %
Epoch 1015 of 2000 took 0.096s
  training loss:		0.057620
  validation loss:		0.537237
  validation accuracy:		90.98 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.059936
  validation loss:		0.559877
  validation accuracy:		90.54 %
Epoch 1017 of 2000 took 0.096s
  training loss:		0.062433
  validation loss:		0.535070
  validation accuracy:		91.20 %
Epoch 1018 of 2000 took 0.101s
  training loss:		0.054489
  validation loss:		0.557454
  validation accuracy:		90.11 %
Epoch 1019 of 2000 took 0.098s
  training loss:		0.052431
  validation loss:		0.538847
  validation accuracy:		91.41 %
Epoch 1020 of 2000 took 0.096s
  training loss:		0.057279
  validation loss:		0.558227
  validation accuracy:		90.65 %
Epoch 1021 of 2000 took 0.101s
  training loss:		0.054106
  validation loss:		0.564730
  validation accuracy:		90.54 %
Epoch 1022 of 2000 took 0.098s
  training loss:		0.057756
  validation loss:		0.533598
  validation accuracy:		90.87 %
Epoch 1023 of 2000 took 0.096s
  training loss:		0.054571
  validation loss:		0.573704
  validation accuracy:		90.11 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.058326
  validation loss:		0.539960
  validation accuracy:		90.98 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.052292
  validation loss:		0.536083
  validation accuracy:		91.30 %
Epoch 1026 of 2000 took 0.100s
  training loss:		0.054024
  validation loss:		0.549922
  validation accuracy:		90.65 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.056810
  validation loss:		0.555616
  validation accuracy:		90.76 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.054161
  validation loss:		0.611978
  validation accuracy:		89.24 %
Epoch 1029 of 2000 took 0.103s
  training loss:		0.057024
  validation loss:		0.538354
  validation accuracy:		90.98 %
Epoch 1030 of 2000 took 0.096s
  training loss:		0.048889
  validation loss:		0.548788
  validation accuracy:		91.30 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.054605
  validation loss:		0.557104
  validation accuracy:		90.54 %
Epoch 1032 of 2000 took 0.096s
  training loss:		0.051366
  validation loss:		0.566570
  validation accuracy:		90.65 %
Epoch 1033 of 2000 took 0.098s
  training loss:		0.051971
  validation loss:		0.566193
  validation accuracy:		90.43 %
Epoch 1034 of 2000 took 0.101s
  training loss:		0.056682
  validation loss:		0.550995
  validation accuracy:		90.98 %
Epoch 1035 of 2000 took 0.099s
  training loss:		0.051269
  validation loss:		0.574602
  validation accuracy:		90.54 %
Epoch 1036 of 2000 took 0.100s
  training loss:		0.051275
  validation loss:		0.564527
  validation accuracy:		90.33 %
Epoch 1037 of 2000 took 0.104s
  training loss:		0.049558
  validation loss:		0.562629
  validation accuracy:		90.54 %
Epoch 1038 of 2000 took 0.099s
  training loss:		0.065027
  validation loss:		0.548573
  validation accuracy:		90.98 %
Epoch 1039 of 2000 took 0.100s
  training loss:		0.052234
  validation loss:		0.560347
  validation accuracy:		90.54 %
Epoch 1040 of 2000 took 0.099s
  training loss:		0.049548
  validation loss:		0.564019
  validation accuracy:		90.76 %
Epoch 1041 of 2000 took 0.103s
  training loss:		0.052728
  validation loss:		0.581290
  validation accuracy:		90.33 %
Epoch 1042 of 2000 took 0.101s
  training loss:		0.051984
  validation loss:		0.563400
  validation accuracy:		90.54 %
Epoch 1043 of 2000 took 0.099s
  training loss:		0.049528
  validation loss:		0.569377
  validation accuracy:		90.43 %
Epoch 1044 of 2000 took 0.104s
  training loss:		0.046955
  validation loss:		0.556020
  validation accuracy:		91.52 %
Epoch 1045 of 2000 took 0.101s
  training loss:		0.047877
  validation loss:		0.567232
  validation accuracy:		90.65 %
Epoch 1046 of 2000 took 0.100s
  training loss:		0.052411
  validation loss:		0.552086
  validation accuracy:		91.74 %
Epoch 1047 of 2000 took 0.100s
  training loss:		0.055640
  validation loss:		0.594414
  validation accuracy:		90.33 %
Epoch 1048 of 2000 took 0.100s
  training loss:		0.052749
  validation loss:		0.611399
  validation accuracy:		89.46 %
Epoch 1049 of 2000 took 0.104s
  training loss:		0.053224
  validation loss:		0.595254
  validation accuracy:		90.33 %
Epoch 1050 of 2000 took 0.100s
  training loss:		0.048867
  validation loss:		0.589880
  validation accuracy:		90.87 %
Epoch 1051 of 2000 took 0.100s
  training loss:		0.059488
  validation loss:		0.634157
  validation accuracy:		89.57 %
Epoch 1052 of 2000 took 0.106s
  training loss:		0.046842
  validation loss:		0.566528
  validation accuracy:		90.43 %
Epoch 1053 of 2000 took 0.099s
  training loss:		0.047490
  validation loss:		0.565945
  validation accuracy:		91.09 %
Epoch 1054 of 2000 took 0.100s
  training loss:		0.049117
  validation loss:		0.576876
  validation accuracy:		90.65 %
Epoch 1055 of 2000 took 0.099s
  training loss:		0.048205
  validation loss:		0.619565
  validation accuracy:		90.11 %
Epoch 1056 of 2000 took 0.101s
  training loss:		0.058669
  validation loss:		0.577265
  validation accuracy:		90.65 %
Epoch 1057 of 2000 took 0.104s
  training loss:		0.047827
  validation loss:		0.597201
  validation accuracy:		90.11 %
Epoch 1058 of 2000 took 0.099s
  training loss:		0.048171
  validation loss:		0.601581
  validation accuracy:		90.33 %
Epoch 1059 of 2000 took 0.100s
  training loss:		0.048192
  validation loss:		0.597240
  validation accuracy:		90.33 %
Epoch 1060 of 2000 took 0.105s
  training loss:		0.045073
  validation loss:		0.600731
  validation accuracy:		90.22 %
Epoch 1061 of 2000 took 0.099s
  training loss:		0.053377
  validation loss:		0.591495
  validation accuracy:		90.43 %
Epoch 1062 of 2000 took 0.143s
  training loss:		0.046637
  validation loss:		0.578744
  validation accuracy:		90.76 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.047354
  validation loss:		0.591426
  validation accuracy:		90.33 %
Epoch 1064 of 2000 took 0.101s
  training loss:		0.051174
  validation loss:		0.606006
  validation accuracy:		90.22 %
Epoch 1065 of 2000 took 0.101s
  training loss:		0.048130
  validation loss:		0.583872
  validation accuracy:		90.98 %
Epoch 1066 of 2000 took 0.102s
  training loss:		0.046765
  validation loss:		0.587134
  validation accuracy:		90.22 %
Epoch 1067 of 2000 took 0.105s
  training loss:		0.049100
  validation loss:		0.573557
  validation accuracy:		91.09 %
Epoch 1068 of 2000 took 0.101s
  training loss:		0.052473
  validation loss:		0.572223
  validation accuracy:		90.98 %
Epoch 1069 of 2000 took 0.100s
  training loss:		0.049857
  validation loss:		0.610992
  validation accuracy:		90.11 %
Epoch 1070 of 2000 took 0.100s
  training loss:		0.046404
  validation loss:		0.588734
  validation accuracy:		90.54 %
Epoch 1071 of 2000 took 0.099s
  training loss:		0.047879
  validation loss:		0.592288
  validation accuracy:		90.22 %
Epoch 1072 of 2000 took 0.100s
  training loss:		0.049824
  validation loss:		0.581262
  validation accuracy:		90.76 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.049189
  validation loss:		0.632181
  validation accuracy:		89.89 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.054561
  validation loss:		0.586035
  validation accuracy:		90.87 %
Epoch 1075 of 2000 took 0.103s
  training loss:		0.045881
  validation loss:		0.595713
  validation accuracy:		90.43 %
Epoch 1076 of 2000 took 0.096s
  training loss:		0.044341
  validation loss:		0.613963
  validation accuracy:		90.54 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.046389
  validation loss:		0.620119
  validation accuracy:		90.65 %
Epoch 1078 of 2000 took 0.096s
  training loss:		0.050284
  validation loss:		0.608958
  validation accuracy:		90.11 %
Epoch 1079 of 2000 took 0.098s
  training loss:		0.048445
  validation loss:		0.592928
  validation accuracy:		90.76 %
Epoch 1080 of 2000 took 0.100s
  training loss:		0.050584
  validation loss:		0.608653
  validation accuracy:		90.22 %
Epoch 1081 of 2000 took 0.096s
  training loss:		0.045099
  validation loss:		0.599597
  validation accuracy:		90.43 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.046494
  validation loss:		0.588640
  validation accuracy:		91.41 %
Epoch 1083 of 2000 took 0.101s
  training loss:		0.046506
  validation loss:		0.593352
  validation accuracy:		90.87 %
Epoch 1084 of 2000 took 0.096s
  training loss:		0.048621
  validation loss:		0.608282
  validation accuracy:		90.65 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.045556
  validation loss:		0.608045
  validation accuracy:		90.43 %
Epoch 1086 of 2000 took 0.096s
  training loss:		0.043515
  validation loss:		0.692727
  validation accuracy:		89.13 %
Epoch 1087 of 2000 took 0.101s
  training loss:		0.052061
  validation loss:		0.640510
  validation accuracy:		90.00 %
Epoch 1088 of 2000 took 0.098s
  training loss:		0.048578
  validation loss:		0.604856
  validation accuracy:		90.98 %
Epoch 1089 of 2000 took 0.096s
  training loss:		0.048217
  validation loss:		0.612127
  validation accuracy:		90.33 %
Epoch 1090 of 2000 took 0.101s
  training loss:		0.043638
  validation loss:		0.605995
  validation accuracy:		90.76 %
Epoch 1091 of 2000 took 0.098s
  training loss:		0.044688
  validation loss:		0.613544
  validation accuracy:		90.33 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.042738
  validation loss:		0.613900
  validation accuracy:		90.11 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.042769
  validation loss:		0.619577
  validation accuracy:		89.89 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.043929
  validation loss:		0.608097
  validation accuracy:		90.76 %
Epoch 1095 of 2000 took 0.101s
  training loss:		0.045278
  validation loss:		0.610416
  validation accuracy:		90.98 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.045542
  validation loss:		0.602974
  validation accuracy:		91.20 %
Epoch 1097 of 2000 took 0.096s
  training loss:		0.042413
  validation loss:		0.613015
  validation accuracy:		90.76 %
Epoch 1098 of 2000 took 0.103s
  training loss:		0.040943
  validation loss:		0.601312
  validation accuracy:		90.98 %
Epoch 1099 of 2000 took 0.096s
  training loss:		0.042439
  validation loss:		0.643024
  validation accuracy:		90.11 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.045864
  validation loss:		0.616664
  validation accuracy:		90.54 %
Epoch 1101 of 2000 took 0.107s
  training loss:		0.039000
  validation loss:		0.615826
  validation accuracy:		90.65 %
Epoch 1102 of 2000 took 0.136s
  training loss:		0.042414
  validation loss:		0.630449
  validation accuracy:		90.54 %
Epoch 1103 of 2000 took 0.110s
  training loss:		0.039952
  validation loss:		0.625379
  validation accuracy:		90.43 %
Epoch 1104 of 2000 took 0.106s
  training loss:		0.044564
  validation loss:		0.631553
  validation accuracy:		90.11 %
Epoch 1105 of 2000 took 0.107s
  training loss:		0.041694
  validation loss:		0.598670
  validation accuracy:		90.87 %
Epoch 1106 of 2000 took 0.112s
  training loss:		0.043279
  validation loss:		0.606469
  validation accuracy:		90.98 %
Epoch 1107 of 2000 took 0.106s
  training loss:		0.042226
  validation loss:		0.609177
  validation accuracy:		91.09 %
Epoch 1108 of 2000 took 0.107s
  training loss:		0.044685
  validation loss:		0.612758
  validation accuracy:		90.43 %
Epoch 1109 of 2000 took 0.106s
  training loss:		0.047056
  validation loss:		0.630938
  validation accuracy:		90.65 %
Epoch 1110 of 2000 took 0.110s
  training loss:		0.042585
  validation loss:		0.604289
  validation accuracy:		91.30 %
Epoch 1111 of 2000 took 0.108s
  training loss:		0.040699
  validation loss:		0.629787
  validation accuracy:		90.22 %
Epoch 1112 of 2000 took 0.106s
  training loss:		0.047220
  validation loss:		0.638019
  validation accuracy:		90.54 %
Epoch 1113 of 2000 took 0.111s
  training loss:		0.039244
  validation loss:		0.632995
  validation accuracy:		90.65 %
Epoch 1114 of 2000 took 0.108s
  training loss:		0.040924
  validation loss:		0.637201
  validation accuracy:		90.54 %
Epoch 1115 of 2000 took 0.107s
  training loss:		0.042016
  validation loss:		0.633443
  validation accuracy:		90.54 %
Epoch 1116 of 2000 took 0.107s
  training loss:		0.039727
  validation loss:		0.628651
  validation accuracy:		90.76 %
Epoch 1117 of 2000 took 0.107s
  training loss:		0.041364
  validation loss:		0.657195
  validation accuracy:		89.57 %
Epoch 1118 of 2000 took 0.111s
  training loss:		0.043145
  validation loss:		0.631360
  validation accuracy:		90.87 %
Epoch 1119 of 2000 took 0.107s
  training loss:		0.039721
  validation loss:		0.628769
  validation accuracy:		90.33 %
Epoch 1120 of 2000 took 0.107s
  training loss:		0.040817
  validation loss:		0.635865
  validation accuracy:		90.54 %
Epoch 1121 of 2000 took 0.113s
  training loss:		0.039601
  validation loss:		0.664399
  validation accuracy:		90.33 %
Epoch 1122 of 2000 took 0.106s
  training loss:		0.045073
  validation loss:		0.656582
  validation accuracy:		90.11 %
Epoch 1123 of 2000 took 0.107s
  training loss:		0.045032
  validation loss:		0.648091
  validation accuracy:		90.54 %
Epoch 1124 of 2000 took 0.106s
  training loss:		0.054728
  validation loss:		0.633232
  validation accuracy:		90.65 %
Epoch 1125 of 2000 took 0.109s
  training loss:		0.040895
  validation loss:		0.642697
  validation accuracy:		90.22 %
Epoch 1126 of 2000 took 0.110s
  training loss:		0.040989
  validation loss:		0.649469
  validation accuracy:		90.33 %
Epoch 1127 of 2000 took 0.106s
  training loss:		0.040152
  validation loss:		0.648424
  validation accuracy:		91.20 %
Epoch 1128 of 2000 took 0.108s
  training loss:		0.035644
  validation loss:		0.639866
  validation accuracy:		91.09 %
Epoch 1129 of 2000 took 0.111s
  training loss:		0.039718
  validation loss:		0.625440
  validation accuracy:		90.87 %
Epoch 1130 of 2000 took 0.106s
  training loss:		0.041737
  validation loss:		0.629337
  validation accuracy:		91.09 %
Epoch 1131 of 2000 took 0.107s
  training loss:		0.040357
  validation loss:		0.650413
  validation accuracy:		90.65 %
Epoch 1132 of 2000 took 0.106s
  training loss:		0.036284
  validation loss:		0.663865
  validation accuracy:		90.33 %
Epoch 1133 of 2000 took 0.111s
  training loss:		0.041617
  validation loss:		0.666146
  validation accuracy:		90.22 %
Epoch 1134 of 2000 took 0.108s
  training loss:		0.038190
  validation loss:		0.642660
  validation accuracy:		90.76 %
Epoch 1135 of 2000 took 0.106s
  training loss:		0.040472
  validation loss:		0.687560
  validation accuracy:		89.78 %
Epoch 1136 of 2000 took 0.112s
  training loss:		0.042913
  validation loss:		0.633637
  validation accuracy:		90.87 %
Epoch 1137 of 2000 took 0.107s
  training loss:		0.038370
  validation loss:		0.648889
  validation accuracy:		90.54 %
Epoch 1138 of 2000 took 0.107s
  training loss:		0.038212
  validation loss:		0.640813
  validation accuracy:		90.98 %
Epoch 1139 of 2000 took 0.106s
  training loss:		0.041488
  validation loss:		0.655739
  validation accuracy:		90.65 %
Epoch 1140 of 2000 took 0.108s
  training loss:		0.037317
  validation loss:		0.652780
  validation accuracy:		90.33 %
Epoch 1141 of 2000 took 0.111s
  training loss:		0.037812
  validation loss:		0.643383
  validation accuracy:		91.30 %
Epoch 1142 of 2000 took 0.106s
  training loss:		0.041012
  validation loss:		0.651484
  validation accuracy:		90.76 %
Epoch 1143 of 2000 took 0.107s
  training loss:		0.036580
  validation loss:		0.653939
  validation accuracy:		90.65 %
Epoch 1144 of 2000 took 0.112s
  training loss:		0.037560
  validation loss:		0.640203
  validation accuracy:		91.41 %
Epoch 1145 of 2000 took 0.106s
  training loss:		0.041013
  validation loss:		0.630925
  validation accuracy:		91.63 %
Epoch 1146 of 2000 took 0.107s
  training loss:		0.040794
  validation loss:		0.648295
  validation accuracy:		90.65 %
Epoch 1147 of 2000 took 0.106s
  training loss:		0.037239
  validation loss:		0.666316
  validation accuracy:		90.43 %
Epoch 1148 of 2000 took 0.110s
  training loss:		0.035418
  validation loss:		0.661910
  validation accuracy:		90.65 %
Epoch 1149 of 2000 took 0.109s
  training loss:		0.037708
  validation loss:		0.683351
  validation accuracy:		90.00 %
Epoch 1150 of 2000 took 0.106s
  training loss:		0.044426
  validation loss:		0.666249
  validation accuracy:		90.65 %
Epoch 1151 of 2000 took 0.110s
  training loss:		0.035734
  validation loss:		0.650226
  validation accuracy:		90.98 %
Epoch 1152 of 2000 took 0.109s
  training loss:		0.035520
  validation loss:		0.654858
  validation accuracy:		91.30 %
Epoch 1153 of 2000 took 0.107s
  training loss:		0.036874
  validation loss:		0.679448
  validation accuracy:		90.65 %
Epoch 1154 of 2000 took 0.107s
  training loss:		0.036777
  validation loss:		0.666805
  validation accuracy:		91.20 %
Epoch 1155 of 2000 took 0.107s
  training loss:		0.041817
  validation loss:		0.662176
  validation accuracy:		90.54 %
Epoch 1156 of 2000 took 0.111s
  training loss:		0.034635
  validation loss:		0.657721
  validation accuracy:		90.87 %
Epoch 1157 of 2000 took 0.107s
  training loss:		0.034076
  validation loss:		0.673515
  validation accuracy:		90.65 %
Epoch 1158 of 2000 took 0.107s
  training loss:		0.039193
  validation loss:		0.662958
  validation accuracy:		90.65 %
Epoch 1159 of 2000 took 0.113s
  training loss:		0.033942
  validation loss:		0.680782
  validation accuracy:		90.22 %
Epoch 1160 of 2000 took 0.106s
  training loss:		0.036215
  validation loss:		0.671696
  validation accuracy:		90.65 %
Epoch 1161 of 2000 took 0.107s
  training loss:		0.042058
  validation loss:		0.693708
  validation accuracy:		90.22 %
Epoch 1162 of 2000 took 0.106s
  training loss:		0.034248
  validation loss:		0.671970
  validation accuracy:		90.54 %
Epoch 1163 of 2000 took 0.108s
  training loss:		0.035743
  validation loss:		0.665618
  validation accuracy:		90.87 %
Epoch 1164 of 2000 took 0.111s
  training loss:		0.035614
  validation loss:		0.669416
  validation accuracy:		90.87 %
Epoch 1165 of 2000 took 0.106s
  training loss:		0.034329
  validation loss:		0.666403
  validation accuracy:		90.76 %
Epoch 1166 of 2000 took 0.107s
  training loss:		0.035680
  validation loss:		0.689540
  validation accuracy:		90.76 %
Epoch 1167 of 2000 took 0.112s
  training loss:		0.040990
  validation loss:		0.674892
  validation accuracy:		91.09 %
Epoch 1168 of 2000 took 0.106s
  training loss:		0.033321
  validation loss:		0.682688
  validation accuracy:		90.98 %
Epoch 1169 of 2000 took 0.107s
  training loss:		0.037228
  validation loss:		0.690707
  validation accuracy:		90.33 %
Epoch 1170 of 2000 took 0.106s
  training loss:		0.037102
  validation loss:		0.687030
  validation accuracy:		90.33 %
Epoch 1171 of 2000 took 0.110s
  training loss:		0.035194
  validation loss:		0.676416
  validation accuracy:		91.09 %
Epoch 1172 of 2000 took 0.108s
  training loss:		0.032996
  validation loss:		0.682520
  validation accuracy:		90.43 %
Epoch 1173 of 2000 took 0.106s
  training loss:		0.034005
  validation loss:		0.689253
  validation accuracy:		90.98 %
Epoch 1174 of 2000 took 0.111s
  training loss:		0.033810
  validation loss:		0.677861
  validation accuracy:		90.76 %
Epoch 1175 of 2000 took 0.108s
  training loss:		0.031748
  validation loss:		0.677919
  validation accuracy:		90.54 %
Epoch 1176 of 2000 took 0.107s
  training loss:		0.036189
  validation loss:		0.714899
  validation accuracy:		90.00 %
Epoch 1177 of 2000 took 0.107s
  training loss:		0.033946
  validation loss:		0.697281
  validation accuracy:		90.54 %
Epoch 1178 of 2000 took 0.107s
  training loss:		0.035699
  validation loss:		0.705401
  validation accuracy:		90.43 %
Epoch 1179 of 2000 took 0.111s
  training loss:		0.032369
  validation loss:		0.704499
  validation accuracy:		90.22 %
Epoch 1180 of 2000 took 0.107s
  training loss:		0.032680
  validation loss:		0.675660
  validation accuracy:		91.20 %
Epoch 1181 of 2000 took 0.107s
  training loss:		0.030105
  validation loss:		0.725190
  validation accuracy:		90.22 %
Epoch 1182 of 2000 took 0.113s
  training loss:		0.035032
  validation loss:		0.696432
  validation accuracy:		91.09 %
Epoch 1183 of 2000 took 0.106s
  training loss:		0.033873
  validation loss:		0.712133
  validation accuracy:		90.00 %
Epoch 1184 of 2000 took 0.107s
  training loss:		0.035308
  validation loss:		0.687537
  validation accuracy:		90.87 %
Epoch 1185 of 2000 took 0.106s
  training loss:		0.035839
  validation loss:		0.694410
  validation accuracy:		90.54 %
Epoch 1186 of 2000 took 0.108s
  training loss:		0.035185
  validation loss:		0.734224
  validation accuracy:		89.57 %
Epoch 1187 of 2000 took 0.111s
  training loss:		0.032238
  validation loss:		0.703387
  validation accuracy:		90.43 %
Epoch 1188 of 2000 took 0.106s
  training loss:		0.029893
  validation loss:		0.698692
  validation accuracy:		90.76 %
Epoch 1189 of 2000 took 0.108s
  training loss:		0.030248
  validation loss:		0.722801
  validation accuracy:		90.00 %
Epoch 1190 of 2000 took 0.112s
  training loss:		0.032231
  validation loss:		0.707141
  validation accuracy:		90.76 %
Epoch 1191 of 2000 took 0.106s
  training loss:		0.034747
  validation loss:		0.736080
  validation accuracy:		90.00 %
Epoch 1192 of 2000 took 0.107s
  training loss:		0.032319
  validation loss:		0.701874
  validation accuracy:		90.65 %
Epoch 1193 of 2000 took 0.106s
  training loss:		0.034167
  validation loss:		0.707488
  validation accuracy:		90.54 %
Epoch 1194 of 2000 took 0.111s
  training loss:		0.031090
  validation loss:		0.709078
  validation accuracy:		90.87 %
Epoch 1195 of 2000 took 0.108s
  training loss:		0.031181
  validation loss:		0.737566
  validation accuracy:		90.43 %
Epoch 1196 of 2000 took 0.106s
  training loss:		0.031317
  validation loss:		0.714018
  validation accuracy:		90.22 %
Epoch 1197 of 2000 took 0.112s
  training loss:		0.032472
  validation loss:		0.710834
  validation accuracy:		90.65 %
Epoch 1198 of 2000 took 0.107s
  training loss:		0.031177
  validation loss:		0.699858
  validation accuracy:		90.87 %
Epoch 1199 of 2000 took 0.107s
  training loss:		0.031439
  validation loss:		0.705493
  validation accuracy:		90.65 %
Epoch 1200 of 2000 took 0.107s
  training loss:		0.028438
  validation loss:		0.728005
  validation accuracy:		90.65 %
Epoch 1201 of 2000 took 0.107s
  training loss:		0.029450
  validation loss:		0.722269
  validation accuracy:		90.43 %
Epoch 1202 of 2000 took 0.111s
  training loss:		0.031019
  validation loss:		0.743548
  validation accuracy:		90.11 %
Epoch 1203 of 2000 took 0.107s
  training loss:		0.030603
  validation loss:		0.716158
  validation accuracy:		90.65 %
Epoch 1204 of 2000 took 0.107s
  training loss:		0.030920
  validation loss:		0.720040
  validation accuracy:		90.43 %
Epoch 1205 of 2000 took 0.113s
  training loss:		0.033252
  validation loss:		0.714570
  validation accuracy:		90.98 %
Epoch 1206 of 2000 took 0.106s
  training loss:		0.034535
  validation loss:		0.703014
  validation accuracy:		91.41 %
Epoch 1207 of 2000 took 0.108s
  training loss:		0.038351
  validation loss:		0.720293
  validation accuracy:		90.98 %
Epoch 1208 of 2000 took 0.106s
  training loss:		0.034987
  validation loss:		0.728506
  validation accuracy:		90.65 %
Epoch 1209 of 2000 took 0.108s
  training loss:		0.037199
  validation loss:		0.732036
  validation accuracy:		90.54 %
Epoch 1210 of 2000 took 0.110s
  training loss:		0.034764
  validation loss:		0.721896
  validation accuracy:		90.98 %
Epoch 1211 of 2000 took 0.106s
  training loss:		0.032982
  validation loss:		0.718435
  validation accuracy:		90.87 %
Epoch 1212 of 2000 took 0.108s
  training loss:		0.030498
  validation loss:		0.730182
  validation accuracy:		90.22 %
Epoch 1213 of 2000 took 0.111s
  training loss:		0.028414
  validation loss:		0.710188
  validation accuracy:		90.87 %
Epoch 1214 of 2000 took 0.106s
  training loss:		0.033963
  validation loss:		0.725081
  validation accuracy:		90.87 %
Epoch 1215 of 2000 took 0.107s
  training loss:		0.030201
  validation loss:		0.737003
  validation accuracy:		90.22 %
Epoch 1216 of 2000 took 0.106s
  training loss:		0.031471
  validation loss:		0.751468
  validation accuracy:		90.65 %
Epoch 1217 of 2000 took 0.111s
  training loss:		0.029807
  validation loss:		0.730263
  validation accuracy:		91.09 %
Epoch 1218 of 2000 took 0.108s
  training loss:		0.026369
  validation loss:		0.758812
  validation accuracy:		90.43 %
Epoch 1219 of 2000 took 0.106s
  training loss:		0.048153
  validation loss:		0.737329
  validation accuracy:		90.76 %
Epoch 1220 of 2000 took 0.111s
  training loss:		0.036769
  validation loss:		0.732861
  validation accuracy:		90.43 %
Epoch 1221 of 2000 took 0.107s
  training loss:		0.029547
  validation loss:		0.743687
  validation accuracy:		90.43 %
Epoch 1222 of 2000 took 0.107s
  training loss:		0.032202
  validation loss:		0.726530
  validation accuracy:		91.09 %
Epoch 1223 of 2000 took 0.107s
  training loss:		0.029080
  validation loss:		0.743702
  validation accuracy:		90.54 %
Epoch 1224 of 2000 took 0.107s
  training loss:		0.030245
  validation loss:		0.725228
  validation accuracy:		90.87 %
Epoch 1225 of 2000 took 0.111s
  training loss:		0.032258
  validation loss:		0.750435
  validation accuracy:		90.54 %
Epoch 1226 of 2000 took 0.107s
  training loss:		0.027389
  validation loss:		0.739957
  validation accuracy:		90.65 %
Epoch 1227 of 2000 took 0.107s
  training loss:		0.029405
  validation loss:		0.722833
  validation accuracy:		91.30 %
Epoch 1228 of 2000 took 0.113s
  training loss:		0.032821
  validation loss:		0.738540
  validation accuracy:		90.54 %
Epoch 1229 of 2000 took 0.106s
  training loss:		0.028927
  validation loss:		0.765224
  validation accuracy:		90.33 %
Epoch 1230 of 2000 took 0.107s
  training loss:		0.026936
  validation loss:		0.749155
  validation accuracy:		90.65 %
Epoch 1231 of 2000 took 0.106s
  training loss:		0.031408
  validation loss:		0.741336
  validation accuracy:		90.76 %
Epoch 1232 of 2000 took 0.109s
  training loss:		0.031115
  validation loss:		0.749182
  validation accuracy:		90.98 %
Epoch 1233 of 2000 took 0.110s
  training loss:		0.028047
  validation loss:		0.742373
  validation accuracy:		90.98 %
Epoch 1234 of 2000 took 0.106s
  training loss:		0.032963
  validation loss:		0.748127
  validation accuracy:		90.98 %
Epoch 1235 of 2000 took 0.108s
  training loss:		0.029952
  validation loss:		0.772809
  validation accuracy:		90.54 %
Epoch 1236 of 2000 took 0.111s
  training loss:		0.027165
  validation loss:		0.766165
  validation accuracy:		90.65 %
Epoch 1237 of 2000 took 0.106s
  training loss:		0.027268
  validation loss:		0.769118
  validation accuracy:		90.54 %
Epoch 1238 of 2000 took 0.107s
  training loss:		0.028989
  validation loss:		0.750861
  validation accuracy:		90.43 %
Epoch 1239 of 2000 took 0.106s
  training loss:		0.025192
  validation loss:		0.745634
  validation accuracy:		90.98 %
Epoch 1240 of 2000 took 0.111s
  training loss:		0.026252
  validation loss:		0.746376
  validation accuracy:		91.20 %
Epoch 1241 of 2000 took 0.108s
  training loss:		0.028384
  validation loss:		0.783604
  validation accuracy:		90.43 %
Epoch 1242 of 2000 took 0.106s
  training loss:		0.027636
  validation loss:		0.746933
  validation accuracy:		90.54 %
Epoch 1243 of 2000 took 0.112s
  training loss:		0.026672
  validation loss:		0.759796
  validation accuracy:		90.54 %
Epoch 1244 of 2000 took 0.107s
  training loss:		0.027341
  validation loss:		0.773079
  validation accuracy:		91.20 %
Epoch 1245 of 2000 took 0.107s
  training loss:		0.028022
  validation loss:		0.763094
  validation accuracy:		90.65 %
Epoch 1246 of 2000 took 0.106s
  training loss:		0.028395
  validation loss:		0.802000
  validation accuracy:		90.00 %
Epoch 1247 of 2000 took 0.107s
  training loss:		0.026817
  validation loss:		0.741828
  validation accuracy:		91.41 %
Epoch 1248 of 2000 took 0.111s
  training loss:		0.033025
  validation loss:		0.764966
  validation accuracy:		90.65 %
Epoch 1249 of 2000 took 0.107s
  training loss:		0.029876
  validation loss:		0.770372
  validation accuracy:		90.43 %
Epoch 1250 of 2000 took 0.107s
  training loss:		0.027942
  validation loss:		0.782436
  validation accuracy:		90.54 %
Epoch 1251 of 2000 took 0.113s
  training loss:		0.027802
  validation loss:		0.772860
  validation accuracy:		90.87 %
Epoch 1252 of 2000 took 0.106s
  training loss:		0.025499
  validation loss:		0.764954
  validation accuracy:		90.76 %
Epoch 1253 of 2000 took 0.107s
  training loss:		0.024738
  validation loss:		0.777076
  validation accuracy:		90.76 %
Epoch 1254 of 2000 took 0.106s
  training loss:		0.026178
  validation loss:		0.779002
  validation accuracy:		90.76 %
Epoch 1255 of 2000 took 0.109s
  training loss:		0.025803
  validation loss:		0.766985
  validation accuracy:		90.54 %
Epoch 1256 of 2000 took 0.110s
  training loss:		0.026845
  validation loss:		0.808031
  validation accuracy:		90.00 %
Epoch 1257 of 2000 took 0.106s
  training loss:		0.027286
  validation loss:		0.777611
  validation accuracy:		90.22 %
Epoch 1258 of 2000 took 0.109s
  training loss:		0.025107
  validation loss:		0.784589
  validation accuracy:		90.33 %
Epoch 1259 of 2000 took 0.107s
  training loss:		0.024930
  validation loss:		0.776998
  validation accuracy:		90.65 %
Epoch 1260 of 2000 took 0.107s
  training loss:		0.026671
  validation loss:		0.782370
  validation accuracy:		90.65 %
Epoch 1261 of 2000 took 0.109s
  training loss:		0.023814
  validation loss:		0.775313
  validation accuracy:		90.76 %
Epoch 1262 of 2000 took 0.106s
  training loss:		0.025850
  validation loss:		0.786759
  validation accuracy:		90.22 %
Epoch 1263 of 2000 took 0.110s
  training loss:		0.025478
  validation loss:		0.796183
  validation accuracy:		90.33 %
Epoch 1264 of 2000 took 0.106s
  training loss:		0.024759
  validation loss:		0.790752
  validation accuracy:		90.65 %
Epoch 1265 of 2000 took 0.107s
  training loss:		0.027156
  validation loss:		0.775426
  validation accuracy:		90.98 %
Epoch 1266 of 2000 took 0.109s
  training loss:		0.024827
  validation loss:		0.780300
  validation accuracy:		90.76 %
Epoch 1267 of 2000 took 0.106s
  training loss:		0.026369
  validation loss:		0.804660
  validation accuracy:		90.54 %
Epoch 1268 of 2000 took 0.110s
  training loss:		0.027221
  validation loss:		0.819413
  validation accuracy:		90.11 %
Epoch 1269 of 2000 took 0.106s
  training loss:		0.024614
  validation loss:		0.805252
  validation accuracy:		90.43 %
Epoch 1270 of 2000 took 0.110s
  training loss:		0.026949
  validation loss:		0.790078
  validation accuracy:		90.22 %
Epoch 1271 of 2000 took 0.107s
  training loss:		0.026614
  validation loss:		0.806644
  validation accuracy:		90.33 %
Epoch 1272 of 2000 took 0.107s
  training loss:		0.023451
  validation loss:		0.785991
  validation accuracy:		90.87 %
Epoch 1273 of 2000 took 0.109s
  training loss:		0.028488
  validation loss:		0.817951
  validation accuracy:		90.22 %
Epoch 1274 of 2000 took 0.106s
  training loss:		0.170004
  validation loss:		0.992242
  validation accuracy:		88.80 %
Epoch 1275 of 2000 took 0.110s
  training loss:		0.053185
  validation loss:		0.785774
  validation accuracy:		90.54 %
Epoch 1276 of 2000 took 0.106s
  training loss:		0.025962
  validation loss:		0.800858
  validation accuracy:		90.11 %
Epoch 1277 of 2000 took 0.109s
  training loss:		0.030651
  validation loss:		0.802435
  validation accuracy:		90.22 %
Epoch 1278 of 2000 took 0.107s
  training loss:		0.029332
  validation loss:		0.780337
  validation accuracy:		90.65 %
Epoch 1279 of 2000 took 0.107s
  training loss:		0.029700
  validation loss:		0.763248
  validation accuracy:		90.76 %
Epoch 1280 of 2000 took 0.109s
  training loss:		0.024925
  validation loss:		0.784505
  validation accuracy:		90.87 %
Epoch 1281 of 2000 took 0.106s
  training loss:		0.027189
  validation loss:		0.801243
  validation accuracy:		90.11 %
Epoch 1282 of 2000 took 0.110s
  training loss:		0.023996
  validation loss:		0.775615
  validation accuracy:		90.54 %
Epoch 1283 of 2000 took 0.106s
  training loss:		0.023950
  validation loss:		0.810159
  validation accuracy:		90.00 %
Epoch 1284 of 2000 took 0.107s
  training loss:		0.023432
  validation loss:		0.800711
  validation accuracy:		90.65 %
Epoch 1285 of 2000 took 0.111s
  training loss:		0.024143
  validation loss:		0.776745
  validation accuracy:		90.65 %
Epoch 1286 of 2000 took 0.106s
  training loss:		0.026187
  validation loss:		0.785259
  validation accuracy:		90.54 %
Epoch 1287 of 2000 took 0.107s
  training loss:		0.023891
  validation loss:		0.797929
  validation accuracy:		90.54 %
Epoch 1288 of 2000 took 0.106s
  training loss:		0.023694
  validation loss:		0.772841
  validation accuracy:		90.98 %
Epoch 1289 of 2000 took 0.111s
  training loss:		0.025382
  validation loss:		0.810174
  validation accuracy:		90.43 %
Epoch 1290 of 2000 took 0.108s
  training loss:		0.025319
  validation loss:		0.795957
  validation accuracy:		90.54 %
Epoch 1291 of 2000 took 0.106s
  training loss:		0.030653
  validation loss:		0.810712
  validation accuracy:		90.54 %
Epoch 1292 of 2000 took 0.112s
  training loss:		0.024959
  validation loss:		0.811392
  validation accuracy:		90.65 %
Epoch 1293 of 2000 took 0.107s
  training loss:		0.026343
  validation loss:		0.802065
  validation accuracy:		90.98 %
Epoch 1294 of 2000 took 0.107s
  training loss:		0.025313
  validation loss:		0.819941
  validation accuracy:		90.76 %
Epoch 1295 of 2000 took 0.107s
  training loss:		0.028882
  validation loss:		0.804089
  validation accuracy:		90.76 %
Epoch 1296 of 2000 took 0.107s
  training loss:		0.025240
  validation loss:		0.818384
  validation accuracy:		90.54 %
Epoch 1297 of 2000 took 0.111s
  training loss:		0.024617
  validation loss:		0.796422
  validation accuracy:		90.76 %
Epoch 1298 of 2000 took 0.107s
  training loss:		0.022500
  validation loss:		0.808374
  validation accuracy:		90.87 %
Epoch 1299 of 2000 took 0.107s
  training loss:		0.021099
  validation loss:		0.812255
  validation accuracy:		90.98 %
Epoch 1300 of 2000 took 0.113s
  training loss:		0.023933
  validation loss:		0.812246
  validation accuracy:		90.87 %
Epoch 1301 of 2000 took 0.106s
  training loss:		0.022952
  validation loss:		0.810892
  validation accuracy:		90.54 %
Epoch 1302 of 2000 took 0.107s
  training loss:		0.024060
  validation loss:		0.809732
  validation accuracy:		90.87 %
Epoch 1303 of 2000 took 0.106s
  training loss:		0.024465
  validation loss:		0.821955
  validation accuracy:		90.87 %
Epoch 1304 of 2000 took 0.108s
  training loss:		0.024329
  validation loss:		0.826086
  validation accuracy:		90.65 %
Epoch 1305 of 2000 took 0.110s
  training loss:		0.031046
  validation loss:		0.823161
  validation accuracy:		90.87 %
Epoch 1306 of 2000 took 0.106s
  training loss:		0.022203
  validation loss:		0.807726
  validation accuracy:		90.76 %
Epoch 1307 of 2000 took 0.108s
  training loss:		0.024331
  validation loss:		0.829452
  validation accuracy:		90.65 %
Epoch 1308 of 2000 took 0.110s
  training loss:		0.021720
  validation loss:		0.829732
  validation accuracy:		90.76 %
Epoch 1309 of 2000 took 0.106s
  training loss:		0.021687
  validation loss:		0.828020
  validation accuracy:		90.43 %
Epoch 1310 of 2000 took 0.107s
  training loss:		0.022231
  validation loss:		0.868771
  validation accuracy:		89.57 %
Epoch 1311 of 2000 took 0.106s
  training loss:		0.029083
  validation loss:		0.870775
  validation accuracy:		89.67 %
Epoch 1312 of 2000 took 0.111s
  training loss:		0.024967
  validation loss:		0.809412
  validation accuracy:		91.20 %
Epoch 1313 of 2000 took 0.108s
  training loss:		0.024229
  validation loss:		0.820780
  validation accuracy:		91.20 %
Epoch 1314 of 2000 took 0.106s
  training loss:		0.020350
  validation loss:		0.844553
  validation accuracy:		90.22 %
Epoch 1315 of 2000 took 0.112s
  training loss:		0.021264
  validation loss:		0.831175
  validation accuracy:		90.43 %
Epoch 1316 of 2000 took 0.107s
  training loss:		0.022079
  validation loss:		0.861406
  validation accuracy:		90.00 %
Epoch 1317 of 2000 took 0.107s
  training loss:		0.022373
  validation loss:		0.841091
  validation accuracy:		90.22 %
Epoch 1318 of 2000 took 0.106s
  training loss:		0.021754
  validation loss:		0.867740
  validation accuracy:		89.67 %
Epoch 1319 of 2000 took 0.108s
  training loss:		0.021356
  validation loss:		0.835864
  validation accuracy:		90.76 %
Epoch 1320 of 2000 took 0.111s
  training loss:		0.023713
  validation loss:		0.854350
  validation accuracy:		90.54 %
Epoch 1321 of 2000 took 0.106s
  training loss:		0.023726
  validation loss:		0.853159
  validation accuracy:		90.54 %
Epoch 1322 of 2000 took 0.107s
  training loss:		0.020444
  validation loss:		0.851583
  validation accuracy:		90.54 %
Epoch 1323 of 2000 took 0.113s
  training loss:		0.025111
  validation loss:		0.871463
  validation accuracy:		90.33 %
Epoch 1324 of 2000 took 0.106s
  training loss:		0.022731
  validation loss:		0.848231
  validation accuracy:		90.65 %
Epoch 1325 of 2000 took 0.107s
  training loss:		0.020849
  validation loss:		0.832589
  validation accuracy:		90.87 %
Epoch 1326 of 2000 took 0.106s
  training loss:		0.023619
  validation loss:		0.838150
  validation accuracy:		90.98 %
Epoch 1327 of 2000 took 0.109s
  training loss:		0.020233
  validation loss:		0.852505
  validation accuracy:		90.43 %
Epoch 1328 of 2000 took 0.109s
  training loss:		0.023442
  validation loss:		0.846862
  validation accuracy:		90.54 %
Epoch 1329 of 2000 took 0.106s
  training loss:		0.030393
  validation loss:		0.876957
  validation accuracy:		90.22 %
Epoch 1330 of 2000 took 0.109s
  training loss:		0.022698
  validation loss:		0.855332
  validation accuracy:		90.43 %
Epoch 1331 of 2000 took 0.109s
  training loss:		0.019079
  validation loss:		0.855828
  validation accuracy:		90.54 %
Epoch 1332 of 2000 took 0.107s
  training loss:		0.018321
  validation loss:		0.846938
  validation accuracy:		90.65 %
Epoch 1333 of 2000 took 0.107s
  training loss:		0.021214
  validation loss:		0.843718
  validation accuracy:		90.76 %
Epoch 1334 of 2000 took 0.106s
  training loss:		0.020215
  validation loss:		0.869319
  validation accuracy:		90.43 %
Epoch 1335 of 2000 took 0.111s
  training loss:		0.018405
  validation loss:		0.844669
  validation accuracy:		90.76 %
Epoch 1336 of 2000 took 0.108s
  training loss:		0.020968
  validation loss:		0.836405
  validation accuracy:		90.98 %
Epoch 1337 of 2000 took 0.106s
  training loss:		0.021171
  validation loss:		0.865313
  validation accuracy:		90.33 %
Epoch 1338 of 2000 took 0.113s
  training loss:		0.020209
  validation loss:		0.861114
  validation accuracy:		90.65 %
Epoch 1339 of 2000 took 0.106s
  training loss:		0.020311
  validation loss:		0.874899
  validation accuracy:		90.33 %
Epoch 1340 of 2000 took 0.107s
  training loss:		0.019529
  validation loss:		0.871587
  validation accuracy:		90.33 %
Epoch 1341 of 2000 took 0.106s
  training loss:		0.021012
  validation loss:		0.892403
  validation accuracy:		90.33 %
Epoch 1342 of 2000 took 0.108s
  training loss:		0.019777
  validation loss:		0.870434
  validation accuracy:		90.43 %
Epoch 1343 of 2000 took 0.111s
  training loss:		0.019067
  validation loss:		0.863203
  validation accuracy:		90.54 %
Epoch 1344 of 2000 took 0.106s
  training loss:		0.020740
  validation loss:		0.876320
  validation accuracy:		90.11 %
Epoch 1345 of 2000 took 0.107s
  training loss:		0.018880
  validation loss:		0.876911
  validation accuracy:		90.22 %
Epoch 1346 of 2000 took 0.112s
  training loss:		0.018781
  validation loss:		0.850066
  validation accuracy:		91.09 %
Epoch 1347 of 2000 took 0.106s
  training loss:		0.018382
  validation loss:		0.885794
  validation accuracy:		90.22 %
Epoch 1348 of 2000 took 0.107s
  training loss:		0.024062
  validation loss:		0.908786
  validation accuracy:		90.00 %
Epoch 1349 of 2000 took 0.106s
  training loss:		0.019004
  validation loss:		0.868850
  validation accuracy:		91.09 %
Epoch 1350 of 2000 took 0.111s
  training loss:		0.020537
  validation loss:		0.912996
  validation accuracy:		89.67 %
Epoch 1351 of 2000 took 0.108s
  training loss:		0.018603
  validation loss:		0.895616
  validation accuracy:		90.33 %
Epoch 1352 of 2000 took 0.106s
  training loss:		0.019718
  validation loss:		0.895844
  validation accuracy:		90.11 %
Epoch 1353 of 2000 took 0.111s
  training loss:		0.016975
  validation loss:		0.894313
  validation accuracy:		90.11 %
Epoch 1354 of 2000 took 0.108s
  training loss:		0.020837
  validation loss:		0.885480
  validation accuracy:		90.54 %
Epoch 1355 of 2000 took 0.107s
  training loss:		0.020542
  validation loss:		0.874624
  validation accuracy:		90.87 %
Epoch 1356 of 2000 took 0.107s
  training loss:		0.017596
  validation loss:		0.889884
  validation accuracy:		90.33 %
Epoch 1357 of 2000 took 0.107s
  training loss:		0.022376
  validation loss:		0.891203
  validation accuracy:		90.33 %
Epoch 1358 of 2000 took 0.111s
  training loss:		0.019325
  validation loss:		0.886581
  validation accuracy:		90.65 %
Epoch 1359 of 2000 took 0.107s
  training loss:		0.019632
  validation loss:		0.917107
  validation accuracy:		90.11 %
Epoch 1360 of 2000 took 0.107s
  training loss:		0.017572
  validation loss:		0.896348
  validation accuracy:		90.54 %
Epoch 1361 of 2000 took 0.113s
  training loss:		0.019920
  validation loss:		0.896915
  validation accuracy:		90.43 %
Epoch 1362 of 2000 took 0.106s
  training loss:		0.016239
  validation loss:		0.884701
  validation accuracy:		90.87 %
Epoch 1363 of 2000 took 0.107s
  training loss:		0.020691
  validation loss:		0.889826
  validation accuracy:		90.76 %
Epoch 1364 of 2000 took 0.106s
  training loss:		0.017991
  validation loss:		0.891249
  validation accuracy:		90.65 %
Epoch 1365 of 2000 took 0.108s
  training loss:		0.019205
  validation loss:		0.895822
  validation accuracy:		90.65 %
Epoch 1366 of 2000 took 0.111s
  training loss:		0.018101
  validation loss:		0.892357
  validation accuracy:		90.76 %
Epoch 1367 of 2000 took 0.106s
  training loss:		0.017948
  validation loss:		0.896214
  validation accuracy:		90.76 %
Epoch 1368 of 2000 took 0.107s
  training loss:		0.016909
  validation loss:		0.898623
  validation accuracy:		90.00 %
Epoch 1369 of 2000 took 0.112s
  training loss:		0.020162
  validation loss:		0.898429
  validation accuracy:		90.54 %
Epoch 1370 of 2000 took 0.106s
  training loss:		0.018735
  validation loss:		0.929513
  validation accuracy:		90.11 %
Epoch 1371 of 2000 took 0.107s
  training loss:		0.019759
  validation loss:		0.909577
  validation accuracy:		90.87 %
Epoch 1372 of 2000 took 0.106s
  training loss:		0.016446
  validation loss:		0.922797
  validation accuracy:		90.00 %
Epoch 1373 of 2000 took 0.111s
  training loss:		0.016504
  validation loss:		0.942530
  validation accuracy:		90.00 %
Epoch 1374 of 2000 took 0.108s
  training loss:		0.028427
  validation loss:		0.965813
  validation accuracy:		90.11 %
Epoch 1375 of 2000 took 0.106s
  training loss:		0.020708
  validation loss:		0.909136
  validation accuracy:		90.43 %
Epoch 1376 of 2000 took 0.112s
  training loss:		0.017207
  validation loss:		0.910450
  validation accuracy:		90.43 %
Epoch 1377 of 2000 took 0.107s
  training loss:		0.017154
  validation loss:		0.917491
  validation accuracy:		90.00 %
Epoch 1378 of 2000 took 0.107s
  training loss:		0.015902
  validation loss:		0.919638
  validation accuracy:		90.54 %
Epoch 1379 of 2000 took 0.107s
  training loss:		0.019855
  validation loss:		0.951907
  validation accuracy:		89.67 %
Epoch 1380 of 2000 took 0.107s
  training loss:		0.016653
  validation loss:		0.927471
  validation accuracy:		90.54 %
Epoch 1381 of 2000 took 0.111s
  training loss:		0.016391
  validation loss:		0.928072
  validation accuracy:		90.11 %
Epoch 1382 of 2000 took 0.107s
  training loss:		0.017971
  validation loss:		0.934299
  validation accuracy:		90.43 %
Epoch 1383 of 2000 took 0.107s
  training loss:		0.018108
  validation loss:		0.916405
  validation accuracy:		90.76 %
Epoch 1384 of 2000 took 0.113s
  training loss:		0.017460
  validation loss:		0.932663
  validation accuracy:		89.78 %
Epoch 1385 of 2000 took 0.106s
  training loss:		0.017255
  validation loss:		0.950938
  validation accuracy:		90.00 %
Epoch 1386 of 2000 took 0.107s
  training loss:		0.016910
  validation loss:		0.918880
  validation accuracy:		90.43 %
Epoch 1387 of 2000 took 0.106s
  training loss:		0.017680
  validation loss:		0.918895
  validation accuracy:		90.65 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.017815
  validation loss:		0.937439
  validation accuracy:		90.33 %
Epoch 1389 of 2000 took 0.092s
  training loss:		0.014926
  validation loss:		0.941641
  validation accuracy:		90.33 %
Epoch 1390 of 2000 took 0.094s
  training loss:		0.016722
  validation loss:		0.937646
  validation accuracy:		90.33 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.016303
  validation loss:		0.922786
  validation accuracy:		90.33 %
Epoch 1392 of 2000 took 0.094s
  training loss:		0.016910
  validation loss:		0.923204
  validation accuracy:		90.54 %
Epoch 1393 of 2000 took 0.094s
  training loss:		0.016750
  validation loss:		0.947578
  validation accuracy:		90.43 %
Epoch 1394 of 2000 took 0.093s
  training loss:		0.017318
  validation loss:		0.936328
  validation accuracy:		90.54 %
Epoch 1395 of 2000 took 0.092s
  training loss:		0.016887
  validation loss:		0.945891
  validation accuracy:		90.11 %
Epoch 1396 of 2000 took 0.092s
  training loss:		0.016719
  validation loss:		0.941317
  validation accuracy:		90.33 %
Epoch 1397 of 2000 took 0.092s
  training loss:		0.016008
  validation loss:		0.957856
  validation accuracy:		90.22 %
Epoch 1398 of 2000 took 0.092s
  training loss:		0.015912
  validation loss:		0.933467
  validation accuracy:		90.54 %
Epoch 1399 of 2000 took 0.093s
  training loss:		0.014612
  validation loss:		0.956508
  validation accuracy:		90.11 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.016857
  validation loss:		0.935494
  validation accuracy:		90.33 %
Epoch 1401 of 2000 took 0.104s
  training loss:		0.017874
  validation loss:		0.953315
  validation accuracy:		90.76 %
Epoch 1402 of 2000 took 0.105s
  training loss:		0.016506
  validation loss:		0.965604
  validation accuracy:		90.54 %
Epoch 1403 of 2000 took 0.102s
  training loss:		0.017349
  validation loss:		0.949746
  validation accuracy:		90.54 %
Epoch 1404 of 2000 took 0.101s
  training loss:		0.016797
  validation loss:		0.949127
  validation accuracy:		90.43 %
Epoch 1405 of 2000 took 0.105s
  training loss:		0.017211
  validation loss:		0.972864
  validation accuracy:		90.22 %
Epoch 1406 of 2000 took 0.104s
  training loss:		0.014278
  validation loss:		0.960794
  validation accuracy:		90.11 %
Epoch 1407 of 2000 took 0.101s
  training loss:		0.014908
  validation loss:		0.965987
  validation accuracy:		90.22 %
Epoch 1408 of 2000 took 0.105s
  training loss:		0.016019
  validation loss:		0.946107
  validation accuracy:		90.54 %
Epoch 1409 of 2000 took 0.107s
  training loss:		0.014961
  validation loss:		0.971517
  validation accuracy:		90.22 %
Epoch 1410 of 2000 took 0.106s
  training loss:		0.015314
  validation loss:		0.956388
  validation accuracy:		90.65 %
Epoch 1411 of 2000 took 0.106s
  training loss:		0.016003
  validation loss:		0.965195
  validation accuracy:		90.00 %
Epoch 1412 of 2000 took 0.106s
  training loss:		0.014595
  validation loss:		0.958821
  validation accuracy:		90.22 %
Epoch 1413 of 2000 took 0.105s
  training loss:		0.014876
  validation loss:		0.959786
  validation accuracy:		90.76 %
Epoch 1414 of 2000 took 0.105s
  training loss:		0.015055
  validation loss:		0.959554
  validation accuracy:		90.33 %
Epoch 1415 of 2000 took 0.106s
  training loss:		0.014723
  validation loss:		0.969487
  validation accuracy:		90.43 %
Epoch 1416 of 2000 took 0.105s
  training loss:		0.015794
  validation loss:		0.965140
  validation accuracy:		90.54 %
Epoch 1417 of 2000 took 0.105s
  training loss:		0.016787
  validation loss:		0.958586
  validation accuracy:		90.54 %
Epoch 1418 of 2000 took 0.105s
  training loss:		0.016025
  validation loss:		0.953661
  validation accuracy:		90.76 %
Epoch 1419 of 2000 took 0.106s
  training loss:		0.015776
  validation loss:		0.982110
  validation accuracy:		90.11 %
Epoch 1420 of 2000 took 0.105s
  training loss:		0.015696
  validation loss:		0.988061
  validation accuracy:		90.11 %
Epoch 1421 of 2000 took 0.106s
  training loss:		0.016737
  validation loss:		0.969156
  validation accuracy:		90.33 %
Epoch 1422 of 2000 took 0.106s
  training loss:		0.014369
  validation loss:		0.996418
  validation accuracy:		90.22 %
Epoch 1423 of 2000 took 0.105s
  training loss:		0.014110
  validation loss:		0.968439
  validation accuracy:		90.43 %
Epoch 1424 of 2000 took 0.105s
  training loss:		0.014536
  validation loss:		0.984424
  validation accuracy:		90.11 %
Epoch 1425 of 2000 took 0.105s
  training loss:		0.014050
  validation loss:		0.973880
  validation accuracy:		90.22 %
Epoch 1426 of 2000 took 0.106s
  training loss:		0.014842
  validation loss:		0.953303
  validation accuracy:		90.65 %
Epoch 1427 of 2000 took 0.105s
  training loss:		0.016081
  validation loss:		0.987522
  validation accuracy:		90.43 %
Epoch 1428 of 2000 took 0.107s
  training loss:		0.014681
  validation loss:		1.028547
  validation accuracy:		89.78 %
Epoch 1429 of 2000 took 0.106s
  training loss:		0.017870
  validation loss:		1.024714
  validation accuracy:		89.89 %
Epoch 1430 of 2000 took 0.105s
  training loss:		0.015415
  validation loss:		0.973057
  validation accuracy:		90.54 %
Epoch 1431 of 2000 took 0.106s
  training loss:		0.013145
  validation loss:		0.992424
  validation accuracy:		90.33 %
Epoch 1432 of 2000 took 0.105s
  training loss:		0.014894
  validation loss:		1.019889
  validation accuracy:		89.78 %
Epoch 1433 of 2000 took 0.105s
  training loss:		0.013845
  validation loss:		0.978245
  validation accuracy:		90.87 %
Epoch 1434 of 2000 took 0.105s
  training loss:		0.015667
  validation loss:		0.998083
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.105s
  training loss:		0.014426
  validation loss:		0.990580
  validation accuracy:		90.33 %
Epoch 1436 of 2000 took 0.105s
  training loss:		0.018115
  validation loss:		0.974967
  validation accuracy:		90.43 %
Epoch 1437 of 2000 took 0.106s
  training loss:		0.012924
  validation loss:		1.023196
  validation accuracy:		90.22 %
Epoch 1438 of 2000 took 0.105s
  training loss:		0.014393
  validation loss:		0.998752
  validation accuracy:		90.43 %
Epoch 1439 of 2000 took 0.105s
  training loss:		0.012914
  validation loss:		0.975984
  validation accuracy:		90.98 %
Epoch 1440 of 2000 took 0.105s
  training loss:		0.012260
  validation loss:		0.988720
  validation accuracy:		90.65 %
Epoch 1441 of 2000 took 0.105s
  training loss:		0.015444
  validation loss:		1.006250
  validation accuracy:		90.11 %
Epoch 1442 of 2000 took 0.106s
  training loss:		0.016854
  validation loss:		0.982816
  validation accuracy:		90.54 %
Epoch 1443 of 2000 took 0.106s
  training loss:		0.015803
  validation loss:		1.021478
  validation accuracy:		90.00 %
Epoch 1444 of 2000 took 0.105s
  training loss:		0.026293
  validation loss:		1.009697
  validation accuracy:		90.43 %
Epoch 1445 of 2000 took 0.106s
  training loss:		0.015553
  validation loss:		1.015394
  validation accuracy:		90.22 %
Epoch 1446 of 2000 took 0.105s
  training loss:		0.014018
  validation loss:		1.022377
  validation accuracy:		90.11 %
Epoch 1447 of 2000 took 0.105s
  training loss:		0.012719
  validation loss:		1.011661
  validation accuracy:		90.11 %
Epoch 1448 of 2000 took 0.106s
  training loss:		0.014219
  validation loss:		1.010382
  validation accuracy:		90.11 %
Epoch 1449 of 2000 took 0.106s
  training loss:		0.013562
  validation loss:		1.024981
  validation accuracy:		90.33 %
Epoch 1450 of 2000 took 0.106s
  training loss:		0.013428
  validation loss:		1.031351
  validation accuracy:		90.00 %
Epoch 1451 of 2000 took 0.105s
  training loss:		0.012164
  validation loss:		1.025766
  validation accuracy:		90.00 %
Epoch 1452 of 2000 took 0.105s
  training loss:		0.013386
  validation loss:		1.019483
  validation accuracy:		90.00 %
Epoch 1453 of 2000 took 0.105s
  training loss:		0.012934
  validation loss:		1.004344
  validation accuracy:		90.43 %
Epoch 1454 of 2000 took 0.105s
  training loss:		0.012627
  validation loss:		1.006191
  validation accuracy:		90.65 %
Epoch 1455 of 2000 took 0.105s
  training loss:		0.015239
  validation loss:		1.020388
  validation accuracy:		90.11 %
Epoch 1456 of 2000 took 0.105s
  training loss:		0.012664
  validation loss:		1.018746
  validation accuracy:		90.22 %
Epoch 1457 of 2000 took 0.105s
  training loss:		0.011863
  validation loss:		1.022291
  validation accuracy:		90.33 %
Epoch 1458 of 2000 took 0.105s
  training loss:		0.022597
  validation loss:		1.055343
  validation accuracy:		90.33 %
Epoch 1459 of 2000 took 0.105s
  training loss:		16.673010
  validation loss:		34.799438
  validation accuracy:		41.63 %
Epoch 1460 of 2000 took 0.108s
  training loss:		190.953331
  validation loss:		9.155381
  validation accuracy:		13.37 %
Epoch 1461 of 2000 took 0.105s
  training loss:		5.247901
  validation loss:		3.287530
  validation accuracy:		17.83 %
Epoch 1462 of 2000 took 0.105s
  training loss:		4.156257
  validation loss:		2.579794
  validation accuracy:		33.48 %
Epoch 1463 of 2000 took 0.105s
  training loss:		2.339797
  validation loss:		2.139099
  validation accuracy:		48.26 %
Epoch 1464 of 2000 took 0.105s
  training loss:		2.139739
  validation loss:		1.914061
  validation accuracy:		47.17 %
Epoch 1465 of 2000 took 0.105s
  training loss:		1.977843
  validation loss:		1.729980
  validation accuracy:		53.26 %
Epoch 1466 of 2000 took 0.106s
  training loss:		1.788900
  validation loss:		1.573127
  validation accuracy:		58.15 %
Epoch 1467 of 2000 took 0.105s
  training loss:		1.645208
  validation loss:		1.440316
  validation accuracy:		64.78 %
Epoch 1468 of 2000 took 0.105s
  training loss:		1.542331
  validation loss:		1.332750
  validation accuracy:		70.43 %
Epoch 1469 of 2000 took 0.105s
  training loss:		1.458446
  validation loss:		1.263531
  validation accuracy:		74.46 %
Epoch 1470 of 2000 took 0.106s
  training loss:		1.381813
  validation loss:		1.205390
  validation accuracy:		75.87 %
Epoch 1471 of 2000 took 0.105s
  training loss:		1.305603
  validation loss:		1.122424
  validation accuracy:		78.26 %
Epoch 1472 of 2000 took 0.105s
  training loss:		1.233094
  validation loss:		1.064205
  validation accuracy:		78.26 %
Epoch 1473 of 2000 took 0.105s
  training loss:		1.165080
  validation loss:		0.993111
  validation accuracy:		79.35 %
Epoch 1474 of 2000 took 0.105s
  training loss:		1.089338
  validation loss:		0.928074
  validation accuracy:		80.98 %
Epoch 1475 of 2000 took 0.105s
  training loss:		1.018657
  validation loss:		0.870152
  validation accuracy:		81.85 %
Epoch 1476 of 2000 took 0.105s
  training loss:		0.956313
  validation loss:		0.806098
  validation accuracy:		81.20 %
Epoch 1477 of 2000 took 0.106s
  training loss:		0.891093
  validation loss:		0.753654
  validation accuracy:		82.39 %
Epoch 1478 of 2000 took 0.105s
  training loss:		0.842796
  validation loss:		0.730390
  validation accuracy:		82.07 %
Epoch 1479 of 2000 took 0.105s
  training loss:		0.790228
  validation loss:		0.668990
  validation accuracy:		83.59 %
Epoch 1480 of 2000 took 0.105s
  training loss:		0.751420
  validation loss:		0.640756
  validation accuracy:		83.37 %
Epoch 1481 of 2000 took 0.106s
  training loss:		0.712493
  validation loss:		0.617924
  validation accuracy:		82.83 %
Epoch 1482 of 2000 took 0.105s
  training loss:		0.681025
  validation loss:		0.586199
  validation accuracy:		83.59 %
Epoch 1483 of 2000 took 0.105s
  training loss:		0.650352
  validation loss:		0.572672
  validation accuracy:		84.24 %
Epoch 1484 of 2000 took 0.106s
  training loss:		0.617765
  validation loss:		0.547975
  validation accuracy:		84.67 %
Epoch 1485 of 2000 took 0.106s
  training loss:		0.594172
  validation loss:		0.533251
  validation accuracy:		84.13 %
Epoch 1486 of 2000 took 0.106s
  training loss:		0.572587
  validation loss:		0.505140
  validation accuracy:		85.22 %
Epoch 1487 of 2000 took 0.105s
  training loss:		0.558644
  validation loss:		0.526757
  validation accuracy:		83.59 %
Epoch 1488 of 2000 took 0.106s
  training loss:		0.539089
  validation loss:		0.483007
  validation accuracy:		85.54 %
Epoch 1489 of 2000 took 0.105s
  training loss:		0.519698
  validation loss:		0.481136
  validation accuracy:		85.54 %
Epoch 1490 of 2000 took 0.105s
  training loss:		0.502589
  validation loss:		0.459528
  validation accuracy:		86.30 %
Epoch 1491 of 2000 took 0.106s
  training loss:		0.486896
  validation loss:		0.466736
  validation accuracy:		85.98 %
Epoch 1492 of 2000 took 0.105s
  training loss:		0.481063
  validation loss:		0.453157
  validation accuracy:		86.09 %
Epoch 1493 of 2000 took 0.105s
  training loss:		0.469052
  validation loss:		0.429976
  validation accuracy:		87.17 %
Epoch 1494 of 2000 took 0.106s
  training loss:		0.462902
  validation loss:		0.411459
  validation accuracy:		87.61 %
Epoch 1495 of 2000 took 0.106s
  training loss:		0.445020
  validation loss:		0.426477
  validation accuracy:		87.07 %
Epoch 1496 of 2000 took 0.105s
  training loss:		0.430121
  validation loss:		0.421813
  validation accuracy:		86.85 %
Epoch 1497 of 2000 took 0.105s
  training loss:		0.428925
  validation loss:		0.411479
  validation accuracy:		87.28 %
Epoch 1498 of 2000 took 0.106s
  training loss:		0.410900
  validation loss:		0.400637
  validation accuracy:		87.61 %
Epoch 1499 of 2000 took 0.105s
  training loss:		0.406824
  validation loss:		0.401091
  validation accuracy:		88.04 %
Epoch 1500 of 2000 took 0.105s
  training loss:		0.403870
  validation loss:		0.375127
  validation accuracy:		88.48 %
Epoch 1501 of 2000 took 0.105s
  training loss:		0.390169
  validation loss:		0.384091
  validation accuracy:		88.37 %
Epoch 1502 of 2000 took 0.105s
  training loss:		0.387622
  validation loss:		0.380083
  validation accuracy:		88.70 %
Epoch 1503 of 2000 took 0.105s
  training loss:		0.377197
  validation loss:		0.383670
  validation accuracy:		88.59 %
Epoch 1504 of 2000 took 0.105s
  training loss:		0.375350
  validation loss:		0.371645
  validation accuracy:		88.70 %
Epoch 1505 of 2000 took 0.106s
  training loss:		0.361736
  validation loss:		0.379142
  validation accuracy:		88.37 %
Epoch 1506 of 2000 took 0.105s
  training loss:		0.358698
  validation loss:		0.382434
  validation accuracy:		88.04 %
Epoch 1507 of 2000 took 0.106s
  training loss:		0.354528
  validation loss:		0.368692
  validation accuracy:		89.02 %
Epoch 1508 of 2000 took 0.105s
  training loss:		0.347916
  validation loss:		0.359239
  validation accuracy:		88.59 %
Epoch 1509 of 2000 took 0.105s
  training loss:		0.345605
  validation loss:		0.377899
  validation accuracy:		88.59 %
Epoch 1510 of 2000 took 0.106s
  training loss:		0.345194
  validation loss:		0.359639
  validation accuracy:		89.02 %
Epoch 1511 of 2000 took 0.105s
  training loss:		0.334423
  validation loss:		0.377606
  validation accuracy:		87.93 %
Epoch 1512 of 2000 took 0.105s
  training loss:		0.331572
  validation loss:		0.366297
  validation accuracy:		88.48 %
Epoch 1513 of 2000 took 0.105s
  training loss:		0.322265
  validation loss:		0.368828
  validation accuracy:		87.72 %
Epoch 1514 of 2000 took 0.105s
  training loss:		0.321762
  validation loss:		0.348142
  validation accuracy:		89.13 %
Epoch 1515 of 2000 took 0.105s
  training loss:		0.318391
  validation loss:		0.337062
  validation accuracy:		89.78 %
Epoch 1516 of 2000 took 0.106s
  training loss:		0.304334
  validation loss:		0.352836
  validation accuracy:		89.13 %
Epoch 1517 of 2000 took 0.105s
  training loss:		0.314319
  validation loss:		0.341601
  validation accuracy:		89.57 %
Epoch 1518 of 2000 took 0.105s
  training loss:		0.306583
  validation loss:		0.344700
  validation accuracy:		89.24 %
Epoch 1519 of 2000 took 0.105s
  training loss:		0.300989
  validation loss:		0.344944
  validation accuracy:		89.13 %
Epoch 1520 of 2000 took 0.105s
  training loss:		0.293883
  validation loss:		0.348723
  validation accuracy:		89.57 %
Epoch 1521 of 2000 took 0.105s
  training loss:		0.293247
  validation loss:		0.361621
  validation accuracy:		88.48 %
Epoch 1522 of 2000 took 0.105s
  training loss:		0.289839
  validation loss:		0.339440
  validation accuracy:		89.67 %
Epoch 1523 of 2000 took 0.106s
  training loss:		0.284950
  validation loss:		0.338331
  validation accuracy:		89.35 %
Epoch 1524 of 2000 took 0.105s
  training loss:		0.287623
  validation loss:		0.317698
  validation accuracy:		90.11 %
Epoch 1525 of 2000 took 0.105s
  training loss:		0.282482
  validation loss:		0.324328
  validation accuracy:		90.22 %
Epoch 1526 of 2000 took 0.105s
  training loss:		0.274449
  validation loss:		0.330519
  validation accuracy:		89.67 %
Epoch 1527 of 2000 took 0.105s
  training loss:		0.278154
  validation loss:		0.321401
  validation accuracy:		90.22 %
Epoch 1528 of 2000 took 0.105s
  training loss:		0.275846
  validation loss:		0.337761
  validation accuracy:		89.46 %
Epoch 1529 of 2000 took 0.105s
  training loss:		0.277421
  validation loss:		0.331397
  validation accuracy:		89.67 %
Epoch 1530 of 2000 took 0.105s
  training loss:		0.268046
  validation loss:		0.345330
  validation accuracy:		89.02 %
Epoch 1531 of 2000 took 0.105s
  training loss:		0.268297
  validation loss:		0.314612
  validation accuracy:		90.43 %
Epoch 1532 of 2000 took 0.105s
  training loss:		0.256781
  validation loss:		0.336218
  validation accuracy:		89.67 %
Epoch 1533 of 2000 took 0.105s
  training loss:		0.255129
  validation loss:		0.326722
  validation accuracy:		89.35 %
Epoch 1534 of 2000 took 0.105s
  training loss:		0.256349
  validation loss:		0.321832
  validation accuracy:		89.67 %
Epoch 1535 of 2000 took 0.105s
  training loss:		0.253915
  validation loss:		0.328874
  validation accuracy:		89.24 %
Epoch 1536 of 2000 took 0.105s
  training loss:		0.256623
  validation loss:		0.315631
  validation accuracy:		89.89 %
Epoch 1537 of 2000 took 0.105s
  training loss:		0.254344
  validation loss:		0.321337
  validation accuracy:		89.57 %
Epoch 1538 of 2000 took 0.105s
  training loss:		0.250461
  validation loss:		0.320612
  validation accuracy:		90.22 %
Epoch 1539 of 2000 took 0.105s
  training loss:		0.246206
  validation loss:		0.332138
  validation accuracy:		89.67 %
Epoch 1540 of 2000 took 0.105s
  training loss:		0.248719
  validation loss:		0.316101
  validation accuracy:		89.57 %
Epoch 1541 of 2000 took 0.105s
  training loss:		0.240842
  validation loss:		0.316596
  validation accuracy:		90.00 %
Epoch 1542 of 2000 took 0.105s
  training loss:		0.239571
  validation loss:		0.336351
  validation accuracy:		89.35 %
Epoch 1543 of 2000 took 0.105s
  training loss:		0.235237
  validation loss:		0.313835
  validation accuracy:		90.33 %
Epoch 1544 of 2000 took 0.105s
  training loss:		0.235702
  validation loss:		0.317730
  validation accuracy:		89.67 %
Epoch 1545 of 2000 took 0.105s
  training loss:		0.237811
  validation loss:		0.332229
  validation accuracy:		89.02 %
Epoch 1546 of 2000 took 0.105s
  training loss:		0.236376
  validation loss:		0.309967
  validation accuracy:		89.78 %
Epoch 1547 of 2000 took 0.105s
  training loss:		0.232724
  validation loss:		0.322514
  validation accuracy:		89.57 %
Epoch 1548 of 2000 took 0.105s
  training loss:		0.235805
  validation loss:		0.307803
  validation accuracy:		90.33 %
Epoch 1549 of 2000 took 0.105s
  training loss:		0.224605
  validation loss:		0.310528
  validation accuracy:		90.22 %
Epoch 1550 of 2000 took 0.105s
  training loss:		0.228575
  validation loss:		0.326728
  validation accuracy:		89.46 %
Epoch 1551 of 2000 took 0.105s
  training loss:		0.228381
  validation loss:		0.324136
  validation accuracy:		89.13 %
Epoch 1552 of 2000 took 0.106s
  training loss:		0.226047
  validation loss:		0.326260
  validation accuracy:		90.00 %
Epoch 1553 of 2000 took 0.105s
  training loss:		0.227556
  validation loss:		0.311285
  validation accuracy:		90.11 %
Epoch 1554 of 2000 took 0.105s
  training loss:		0.222543
  validation loss:		0.324130
  validation accuracy:		89.46 %
Epoch 1555 of 2000 took 0.105s
  training loss:		0.228510
  validation loss:		0.319432
  validation accuracy:		89.13 %
Epoch 1556 of 2000 took 0.105s
  training loss:		0.222073
  validation loss:		0.313735
  validation accuracy:		89.89 %
Epoch 1557 of 2000 took 0.105s
  training loss:		0.216507
  validation loss:		0.304838
  validation accuracy:		90.33 %
Epoch 1558 of 2000 took 0.105s
  training loss:		0.221523
  validation loss:		0.302560
  validation accuracy:		90.22 %
Epoch 1559 of 2000 took 0.106s
  training loss:		0.218253
  validation loss:		0.323573
  validation accuracy:		89.02 %
Epoch 1560 of 2000 took 0.105s
  training loss:		0.212476
  validation loss:		0.324593
  validation accuracy:		89.46 %
Epoch 1561 of 2000 took 0.105s
  training loss:		0.216607
  validation loss:		0.298411
  validation accuracy:		90.87 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.213711
  validation loss:		0.318122
  validation accuracy:		89.57 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.215337
  validation loss:		0.306571
  validation accuracy:		90.11 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.217392
  validation loss:		0.307377
  validation accuracy:		90.11 %
Epoch 1565 of 2000 took 0.097s
  training loss:		0.212344
  validation loss:		0.286717
  validation accuracy:		90.76 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.209837
  validation loss:		0.323457
  validation accuracy:		89.67 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.211827
  validation loss:		0.304198
  validation accuracy:		90.33 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.211638
  validation loss:		0.305746
  validation accuracy:		90.33 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.206445
  validation loss:		0.306558
  validation accuracy:		89.46 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.207008
  validation loss:		0.309250
  validation accuracy:		90.43 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.202803
  validation loss:		0.304311
  validation accuracy:		90.22 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.209198
  validation loss:		0.309565
  validation accuracy:		90.11 %
Epoch 1573 of 2000 took 0.097s
  training loss:		0.207782
  validation loss:		0.320709
  validation accuracy:		90.11 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.201849
  validation loss:		0.329152
  validation accuracy:		89.46 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.202601
  validation loss:		0.303726
  validation accuracy:		90.33 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.199321
  validation loss:		0.307937
  validation accuracy:		90.00 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.200433
  validation loss:		0.321668
  validation accuracy:		89.67 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.201509
  validation loss:		0.306952
  validation accuracy:		90.22 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.196509
  validation loss:		0.322646
  validation accuracy:		89.78 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.197955
  validation loss:		0.307631
  validation accuracy:		90.11 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.204936
  validation loss:		0.314269
  validation accuracy:		90.43 %
Epoch 1582 of 2000 took 0.102s
  training loss:		0.202482
  validation loss:		0.317222
  validation accuracy:		89.57 %
Epoch 1583 of 2000 took 0.097s
  training loss:		0.201477
  validation loss:		0.311291
  validation accuracy:		89.89 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.199668
  validation loss:		0.304138
  validation accuracy:		90.65 %
Epoch 1585 of 2000 took 0.097s
  training loss:		0.198558
  validation loss:		0.293308
  validation accuracy:		90.65 %
Epoch 1586 of 2000 took 0.097s
  training loss:		0.201359
  validation loss:		0.314581
  validation accuracy:		90.22 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.196862
  validation loss:		0.303106
  validation accuracy:		90.33 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.198182
  validation loss:		0.305190
  validation accuracy:		90.22 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.188077
  validation loss:		0.298696
  validation accuracy:		90.54 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.196234
  validation loss:		0.318832
  validation accuracy:		90.00 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.190491
  validation loss:		0.294447
  validation accuracy:		90.87 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.194651
  validation loss:		0.300137
  validation accuracy:		90.54 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.192085
  validation loss:		0.305227
  validation accuracy:		90.00 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.189959
  validation loss:		0.301934
  validation accuracy:		90.76 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.189363
  validation loss:		0.306274
  validation accuracy:		90.43 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.188004
  validation loss:		0.301857
  validation accuracy:		90.43 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.183511
  validation loss:		0.312210
  validation accuracy:		90.43 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.192587
  validation loss:		0.308543
  validation accuracy:		90.00 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.188795
  validation loss:		0.306743
  validation accuracy:		90.33 %
Epoch 1600 of 2000 took 0.097s
  training loss:		0.187074
  validation loss:		0.311825
  validation accuracy:		90.00 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.185548
  validation loss:		0.299667
  validation accuracy:		90.54 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.184134
  validation loss:		0.299388
  validation accuracy:		90.43 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.187666
  validation loss:		0.300391
  validation accuracy:		90.98 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.182650
  validation loss:		0.304815
  validation accuracy:		90.43 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.181967
  validation loss:		0.301948
  validation accuracy:		90.98 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.185699
  validation loss:		0.311140
  validation accuracy:		90.54 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.183378
  validation loss:		0.304296
  validation accuracy:		91.09 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.186486
  validation loss:		0.296294
  validation accuracy:		91.30 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.178885
  validation loss:		0.297392
  validation accuracy:		91.96 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.186406
  validation loss:		0.316983
  validation accuracy:		89.89 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.177556
  validation loss:		0.315294
  validation accuracy:		90.33 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.184922
  validation loss:		0.310043
  validation accuracy:		90.22 %
Epoch 1613 of 2000 took 0.098s
  training loss:		0.184324
  validation loss:		0.300213
  validation accuracy:		90.43 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.176464
  validation loss:		0.307116
  validation accuracy:		90.33 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.187537
  validation loss:		0.313002
  validation accuracy:		90.33 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.184804
  validation loss:		0.308624
  validation accuracy:		90.43 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.179991
  validation loss:		0.298809
  validation accuracy:		91.20 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.175373
  validation loss:		0.299265
  validation accuracy:		90.65 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.179322
  validation loss:		0.299181
  validation accuracy:		91.09 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.176922
  validation loss:		0.299237
  validation accuracy:		90.98 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.174561
  validation loss:		0.298904
  validation accuracy:		90.98 %
Epoch 1622 of 2000 took 0.097s
  training loss:		0.176075
  validation loss:		0.303082
  validation accuracy:		90.65 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.178182
  validation loss:		0.306187
  validation accuracy:		90.65 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.185197
  validation loss:		0.294411
  validation accuracy:		90.98 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.180327
  validation loss:		0.299627
  validation accuracy:		91.09 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.172000
  validation loss:		0.291793
  validation accuracy:		91.85 %
Epoch 1627 of 2000 took 0.097s
  training loss:		0.172444
  validation loss:		0.303811
  validation accuracy:		91.20 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.171598
  validation loss:		0.307738
  validation accuracy:		90.54 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.174035
  validation loss:		0.316305
  validation accuracy:		90.43 %
Epoch 1630 of 2000 took 0.097s
  training loss:		0.176449
  validation loss:		0.295593
  validation accuracy:		91.41 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.174857
  validation loss:		0.307649
  validation accuracy:		91.30 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.178456
  validation loss:		0.306744
  validation accuracy:		90.76 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.167479
  validation loss:		0.305033
  validation accuracy:		90.76 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.168350
  validation loss:		0.309000
  validation accuracy:		90.65 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.173618
  validation loss:		0.310000
  validation accuracy:		90.76 %
Epoch 1636 of 2000 took 0.097s
  training loss:		0.175288
  validation loss:		0.308677
  validation accuracy:		90.65 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.172842
  validation loss:		0.321294
  validation accuracy:		89.89 %
Epoch 1638 of 2000 took 0.099s
  training loss:		0.168829
  validation loss:		0.295266
  validation accuracy:		91.74 %
Epoch 1639 of 2000 took 0.098s
  training loss:		0.173808
  validation loss:		0.303095
  validation accuracy:		90.98 %
Epoch 1640 of 2000 took 0.098s
  training loss:		0.169517
  validation loss:		0.313683
  validation accuracy:		90.22 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.170014
  validation loss:		0.302200
  validation accuracy:		91.20 %
Epoch 1642 of 2000 took 0.099s
  training loss:		0.168692
  validation loss:		0.310564
  validation accuracy:		90.54 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.165508
  validation loss:		0.307659
  validation accuracy:		90.87 %
Epoch 1644 of 2000 took 0.099s
  training loss:		0.171149
  validation loss:		0.310409
  validation accuracy:		90.65 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.170880
  validation loss:		0.309660
  validation accuracy:		90.43 %
Epoch 1646 of 2000 took 0.097s
  training loss:		0.170219
  validation loss:		0.302048
  validation accuracy:		91.09 %
Epoch 1647 of 2000 took 0.099s
  training loss:		0.171646
  validation loss:		0.311904
  validation accuracy:		90.65 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.163787
  validation loss:		0.301585
  validation accuracy:		91.20 %
Epoch 1649 of 2000 took 0.099s
  training loss:		0.166717
  validation loss:		0.314097
  validation accuracy:		90.33 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.167307
  validation loss:		0.306221
  validation accuracy:		90.87 %
Epoch 1651 of 2000 took 0.098s
  training loss:		0.167305
  validation loss:		0.308360
  validation accuracy:		90.65 %
Epoch 1652 of 2000 took 0.097s
  training loss:		0.169243
  validation loss:		0.321774
  validation accuracy:		90.76 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.178998
  validation loss:		0.321732
  validation accuracy:		90.76 %
Epoch 1654 of 2000 took 0.099s
  training loss:		0.168949
  validation loss:		0.305464
  validation accuracy:		90.87 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.164577
  validation loss:		0.300719
  validation accuracy:		91.09 %
Epoch 1656 of 2000 took 0.100s
  training loss:		0.169320
  validation loss:		0.296559
  validation accuracy:		91.41 %
Epoch 1657 of 2000 took 0.098s
  training loss:		0.162523
  validation loss:		0.303851
  validation accuracy:		91.20 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.163113
  validation loss:		0.311534
  validation accuracy:		90.98 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.162778
  validation loss:		0.298178
  validation accuracy:		91.41 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.159138
  validation loss:		0.307021
  validation accuracy:		90.76 %
Epoch 1661 of 2000 took 0.100s
  training loss:		0.161773
  validation loss:		0.299256
  validation accuracy:		91.52 %
Epoch 1662 of 2000 took 0.097s
  training loss:		0.169565
  validation loss:		0.302411
  validation accuracy:		90.87 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.161851
  validation loss:		0.321136
  validation accuracy:		90.76 %
Epoch 1664 of 2000 took 0.102s
  training loss:		0.162614
  validation loss:		0.319347
  validation accuracy:		90.33 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.162088
  validation loss:		0.311284
  validation accuracy:		91.09 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.165041
  validation loss:		0.313154
  validation accuracy:		90.54 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.160839
  validation loss:		0.308282
  validation accuracy:		90.98 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.157693
  validation loss:		0.306828
  validation accuracy:		90.98 %
Epoch 1669 of 2000 took 0.100s
  training loss:		0.158165
  validation loss:		0.308222
  validation accuracy:		90.65 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.155393
  validation loss:		0.305301
  validation accuracy:		90.87 %
Epoch 1671 of 2000 took 0.097s
  training loss:		0.158691
  validation loss:		0.309188
  validation accuracy:		91.09 %
Epoch 1672 of 2000 took 0.102s
  training loss:		0.151893
  validation loss:		0.313925
  validation accuracy:		90.65 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.156944
  validation loss:		0.304600
  validation accuracy:		91.09 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.159495
  validation loss:		0.292887
  validation accuracy:		91.52 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.155447
  validation loss:		0.305603
  validation accuracy:		91.20 %
Epoch 1676 of 2000 took 0.099s
  training loss:		0.160315
  validation loss:		0.302519
  validation accuracy:		91.30 %
Epoch 1677 of 2000 took 0.098s
  training loss:		0.156780
  validation loss:		0.326974
  validation accuracy:		90.22 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.158056
  validation loss:		0.313279
  validation accuracy:		90.33 %
Epoch 1679 of 2000 took 0.099s
  training loss:		0.155097
  validation loss:		0.298193
  validation accuracy:		91.74 %
Epoch 1680 of 2000 took 0.099s
  training loss:		0.157777
  validation loss:		0.313897
  validation accuracy:		90.54 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.162775
  validation loss:		0.302954
  validation accuracy:		90.98 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.150255
  validation loss:		0.325526
  validation accuracy:		90.33 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.156566
  validation loss:		0.320665
  validation accuracy:		90.33 %
Epoch 1684 of 2000 took 0.100s
  training loss:		0.156439
  validation loss:		0.312038
  validation accuracy:		91.09 %
Epoch 1685 of 2000 took 0.097s
  training loss:		0.157087
  validation loss:		0.313397
  validation accuracy:		90.54 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.158142
  validation loss:		0.309021
  validation accuracy:		91.41 %
Epoch 1687 of 2000 took 0.102s
  training loss:		0.155750
  validation loss:		0.331380
  validation accuracy:		90.43 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.163482
  validation loss:		0.318913
  validation accuracy:		90.43 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.151826
  validation loss:		0.303838
  validation accuracy:		91.41 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.153092
  validation loss:		0.324162
  validation accuracy:		90.54 %
Epoch 1691 of 2000 took 0.097s
  training loss:		0.150632
  validation loss:		0.321814
  validation accuracy:		90.76 %
Epoch 1692 of 2000 took 0.100s
  training loss:		0.154680
  validation loss:		0.332880
  validation accuracy:		90.43 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.154515
  validation loss:		0.316087
  validation accuracy:		90.98 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.151151
  validation loss:		0.328595
  validation accuracy:		90.33 %
Epoch 1695 of 2000 took 0.102s
  training loss:		0.152764
  validation loss:		0.311702
  validation accuracy:		90.87 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.149503
  validation loss:		0.307679
  validation accuracy:		91.20 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.150862
  validation loss:		0.314025
  validation accuracy:		91.30 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.151267
  validation loss:		0.315837
  validation accuracy:		91.30 %
Epoch 1699 of 2000 took 0.099s
  training loss:		0.151164
  validation loss:		0.310034
  validation accuracy:		90.54 %
Epoch 1700 of 2000 took 0.098s
  training loss:		0.151512
  validation loss:		0.306798
  validation accuracy:		91.41 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.151601
  validation loss:		0.312344
  validation accuracy:		90.87 %
Epoch 1702 of 2000 took 0.098s
  training loss:		0.155963
  validation loss:		0.308019
  validation accuracy:		91.52 %
Epoch 1703 of 2000 took 0.099s
  training loss:		0.146540
  validation loss:		0.317845
  validation accuracy:		90.54 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.149609
  validation loss:		0.328722
  validation accuracy:		90.11 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.146818
  validation loss:		0.316333
  validation accuracy:		90.65 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.149190
  validation loss:		0.307874
  validation accuracy:		91.63 %
Epoch 1707 of 2000 took 0.100s
  training loss:		0.147706
  validation loss:		0.308390
  validation accuracy:		91.09 %
Epoch 1708 of 2000 took 0.097s
  training loss:		0.151916
  validation loss:		0.306287
  validation accuracy:		91.85 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.151527
  validation loss:		0.316393
  validation accuracy:		90.76 %
Epoch 1710 of 2000 took 0.102s
  training loss:		0.144134
  validation loss:		0.310432
  validation accuracy:		90.87 %
Epoch 1711 of 2000 took 0.096s
  training loss:		0.149485
  validation loss:		0.316140
  validation accuracy:		90.43 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.144326
  validation loss:		0.334119
  validation accuracy:		90.43 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.148405
  validation loss:		0.325785
  validation accuracy:		90.76 %
Epoch 1714 of 2000 took 0.097s
  training loss:		0.150222
  validation loss:		0.312302
  validation accuracy:		90.98 %
Epoch 1715 of 2000 took 0.100s
  training loss:		0.138072
  validation loss:		0.324214
  validation accuracy:		90.43 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.148986
  validation loss:		0.314368
  validation accuracy:		91.41 %
Epoch 1717 of 2000 took 0.097s
  training loss:		0.143055
  validation loss:		0.330418
  validation accuracy:		90.65 %
Epoch 1718 of 2000 took 0.102s
  training loss:		0.150109
  validation loss:		0.321358
  validation accuracy:		90.76 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.146171
  validation loss:		0.344460
  validation accuracy:		90.22 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.143779
  validation loss:		0.312099
  validation accuracy:		90.98 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.140485
  validation loss:		0.326442
  validation accuracy:		90.33 %
Epoch 1722 of 2000 took 0.098s
  training loss:		0.145045
  validation loss:		0.305415
  validation accuracy:		91.85 %
Epoch 1723 of 2000 took 0.099s
  training loss:		0.140595
  validation loss:		0.317036
  validation accuracy:		90.76 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.142932
  validation loss:		0.331914
  validation accuracy:		90.22 %
Epoch 1725 of 2000 took 0.098s
  training loss:		0.142065
  validation loss:		0.307007
  validation accuracy:		90.98 %
Epoch 1726 of 2000 took 0.100s
  training loss:		0.144072
  validation loss:		0.313844
  validation accuracy:		90.76 %
Epoch 1727 of 2000 took 0.096s
  training loss:		0.140658
  validation loss:		0.304510
  validation accuracy:		91.52 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.146388
  validation loss:		0.335812
  validation accuracy:		90.00 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.145247
  validation loss:		0.315639
  validation accuracy:		91.20 %
Epoch 1730 of 2000 took 0.100s
  training loss:		0.137042
  validation loss:		0.329952
  validation accuracy:		90.33 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.141269
  validation loss:		0.314910
  validation accuracy:		91.09 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.139735
  validation loss:		0.343899
  validation accuracy:		90.54 %
Epoch 1733 of 2000 took 0.101s
  training loss:		0.144048
  validation loss:		0.320967
  validation accuracy:		91.41 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.141520
  validation loss:		0.338228
  validation accuracy:		90.65 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.145653
  validation loss:		0.312461
  validation accuracy:		91.30 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.136213
  validation loss:		0.328940
  validation accuracy:		90.76 %
Epoch 1737 of 2000 took 0.097s
  training loss:		0.138218
  validation loss:		0.314032
  validation accuracy:		90.76 %
Epoch 1738 of 2000 took 0.100s
  training loss:		0.139224
  validation loss:		0.319645
  validation accuracy:		91.63 %
Epoch 1739 of 2000 took 0.097s
  training loss:		0.143281
  validation loss:		0.313173
  validation accuracy:		91.41 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.129756
  validation loss:		0.320549
  validation accuracy:		90.98 %
Epoch 1741 of 2000 took 0.102s
  training loss:		0.145187
  validation loss:		0.312518
  validation accuracy:		91.09 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.132874
  validation loss:		0.307837
  validation accuracy:		91.63 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.139056
  validation loss:		0.301668
  validation accuracy:		91.85 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.139781
  validation loss:		0.314818
  validation accuracy:		90.65 %
Epoch 1745 of 2000 took 0.098s
  training loss:		0.134018
  validation loss:		0.311144
  validation accuracy:		91.52 %
Epoch 1746 of 2000 took 0.100s
  training loss:		0.138750
  validation loss:		0.318607
  validation accuracy:		91.20 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.135925
  validation loss:		0.326594
  validation accuracy:		91.30 %
Epoch 1748 of 2000 took 0.097s
  training loss:		0.137405
  validation loss:		0.304992
  validation accuracy:		91.41 %
Epoch 1749 of 2000 took 0.101s
  training loss:		0.141582
  validation loss:		0.327314
  validation accuracy:		90.65 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.138664
  validation loss:		0.335482
  validation accuracy:		90.54 %
Epoch 1751 of 2000 took 0.097s
  training loss:		0.138555
  validation loss:		0.311473
  validation accuracy:		91.30 %
Epoch 1752 of 2000 took 0.096s
  training loss:		0.137198
  validation loss:		0.320848
  validation accuracy:		91.09 %
Epoch 1753 of 2000 took 0.100s
  training loss:		0.130351
  validation loss:		0.319029
  validation accuracy:		90.76 %
Epoch 1754 of 2000 took 0.097s
  training loss:		0.126733
  validation loss:		0.316250
  validation accuracy:		90.76 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.136115
  validation loss:		0.305763
  validation accuracy:		91.63 %
Epoch 1756 of 2000 took 0.100s
  training loss:		0.134999
  validation loss:		0.310990
  validation accuracy:		91.41 %
Epoch 1757 of 2000 took 0.098s
  training loss:		0.136801
  validation loss:		0.314900
  validation accuracy:		91.63 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.134914
  validation loss:		0.320528
  validation accuracy:		90.87 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.133885
  validation loss:		0.312840
  validation accuracy:		90.87 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.132810
  validation loss:		0.319562
  validation accuracy:		91.09 %
Epoch 1761 of 2000 took 0.100s
  training loss:		0.131436
  validation loss:		0.318287
  validation accuracy:		91.41 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.133564
  validation loss:		0.321221
  validation accuracy:		90.76 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.133637
  validation loss:		0.329528
  validation accuracy:		90.76 %
Epoch 1764 of 2000 took 0.102s
  training loss:		0.132503
  validation loss:		0.324498
  validation accuracy:		90.98 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.132079
  validation loss:		0.321170
  validation accuracy:		91.41 %
Epoch 1766 of 2000 took 0.097s
  training loss:		0.128802
  validation loss:		0.318690
  validation accuracy:		91.52 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.130228
  validation loss:		0.326315
  validation accuracy:		90.87 %
Epoch 1768 of 2000 took 0.097s
  training loss:		0.141544
  validation loss:		0.313771
  validation accuracy:		91.63 %
Epoch 1769 of 2000 took 0.100s
  training loss:		0.128611
  validation loss:		0.313872
  validation accuracy:		91.63 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.127555
  validation loss:		0.333912
  validation accuracy:		90.98 %
Epoch 1771 of 2000 took 0.097s
  training loss:		0.128420
  validation loss:		0.312637
  validation accuracy:		90.98 %
Epoch 1772 of 2000 took 0.102s
  training loss:		0.128728
  validation loss:		0.324415
  validation accuracy:		91.30 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.132221
  validation loss:		0.310140
  validation accuracy:		91.63 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.131107
  validation loss:		0.336922
  validation accuracy:		90.65 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.129087
  validation loss:		0.315229
  validation accuracy:		91.41 %
Epoch 1776 of 2000 took 0.099s
  training loss:		0.130212
  validation loss:		0.313983
  validation accuracy:		91.63 %
Epoch 1777 of 2000 took 0.098s
  training loss:		0.130905
  validation loss:		0.326826
  validation accuracy:		90.76 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.123164
  validation loss:		0.336580
  validation accuracy:		90.22 %
Epoch 1779 of 2000 took 0.098s
  training loss:		0.132893
  validation loss:		0.327236
  validation accuracy:		90.76 %
Epoch 1780 of 2000 took 0.099s
  training loss:		0.130640
  validation loss:		0.331223
  validation accuracy:		90.65 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.130707
  validation loss:		0.327200
  validation accuracy:		90.76 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.128033
  validation loss:		0.329917
  validation accuracy:		90.87 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.122999
  validation loss:		0.328883
  validation accuracy:		91.20 %
Epoch 1784 of 2000 took 0.100s
  training loss:		0.125098
  validation loss:		0.328680
  validation accuracy:		91.30 %
Epoch 1785 of 2000 took 0.097s
  training loss:		0.125011
  validation loss:		0.323982
  validation accuracy:		91.20 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.124367
  validation loss:		0.312065
  validation accuracy:		91.52 %
Epoch 1787 of 2000 took 0.102s
  training loss:		0.124015
  validation loss:		0.329259
  validation accuracy:		90.76 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.124921
  validation loss:		0.328330
  validation accuracy:		91.09 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.122509
  validation loss:		0.333925
  validation accuracy:		90.98 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.122508
  validation loss:		0.329652
  validation accuracy:		90.65 %
Epoch 1791 of 2000 took 0.097s
  training loss:		0.120835
  validation loss:		0.338230
  validation accuracy:		90.76 %
Epoch 1792 of 2000 took 0.100s
  training loss:		0.125853
  validation loss:		0.335499
  validation accuracy:		90.87 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.123288
  validation loss:		0.338383
  validation accuracy:		90.54 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.120136
  validation loss:		0.326441
  validation accuracy:		90.98 %
Epoch 1795 of 2000 took 0.102s
  training loss:		0.120542
  validation loss:		0.336033
  validation accuracy:		90.65 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.122238
  validation loss:		0.332490
  validation accuracy:		90.87 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.123276
  validation loss:		0.343935
  validation accuracy:		90.22 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.127046
  validation loss:		0.340592
  validation accuracy:		91.41 %
Epoch 1799 of 2000 took 0.098s
  training loss:		0.120334
  validation loss:		0.336394
  validation accuracy:		90.65 %
Epoch 1800 of 2000 took 0.099s
  training loss:		0.119161
  validation loss:		0.322392
  validation accuracy:		91.41 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.121100
  validation loss:		0.323432
  validation accuracy:		91.52 %
Epoch 1802 of 2000 took 0.098s
  training loss:		0.120229
  validation loss:		0.314409
  validation accuracy:		91.85 %
Epoch 1803 of 2000 took 0.100s
  training loss:		0.121394
  validation loss:		0.333660
  validation accuracy:		90.76 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.120775
  validation loss:		0.333863
  validation accuracy:		90.98 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.122035
  validation loss:		0.331461
  validation accuracy:		91.20 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.117379
  validation loss:		0.339568
  validation accuracy:		90.87 %
Epoch 1807 of 2000 took 0.101s
  training loss:		0.120323
  validation loss:		0.329065
  validation accuracy:		91.41 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.116240
  validation loss:		0.322183
  validation accuracy:		91.63 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.122194
  validation loss:		0.336011
  validation accuracy:		91.20 %
Epoch 1810 of 2000 took 0.102s
  training loss:		0.121377
  validation loss:		0.324698
  validation accuracy:		90.98 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.115810
  validation loss:		0.333725
  validation accuracy:		91.09 %
Epoch 1812 of 2000 took 0.096s
  training loss:		0.118604
  validation loss:		0.325867
  validation accuracy:		91.20 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.117116
  validation loss:		0.333667
  validation accuracy:		91.41 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.115746
  validation loss:		0.325995
  validation accuracy:		91.63 %
Epoch 1815 of 2000 took 0.100s
  training loss:		0.122917
  validation loss:		0.327618
  validation accuracy:		91.09 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.116125
  validation loss:		0.323889
  validation accuracy:		91.74 %
Epoch 1817 of 2000 took 0.096s
  training loss:		0.115586
  validation loss:		0.325554
  validation accuracy:		91.85 %
Epoch 1818 of 2000 took 0.102s
  training loss:		0.115787
  validation loss:		0.336610
  validation accuracy:		91.20 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.117444
  validation loss:		0.323909
  validation accuracy:		91.63 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.116927
  validation loss:		0.342848
  validation accuracy:		91.20 %
Epoch 1821 of 2000 took 0.096s
  training loss:		0.118701
  validation loss:		0.327696
  validation accuracy:		91.41 %
Epoch 1822 of 2000 took 0.097s
  training loss:		0.115198
  validation loss:		0.330009
  validation accuracy:		91.30 %
Epoch 1823 of 2000 took 0.100s
  training loss:		0.115297
  validation loss:		0.331320
  validation accuracy:		91.63 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.114973
  validation loss:		0.347019
  validation accuracy:		90.98 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.116436
  validation loss:		0.335038
  validation accuracy:		92.28 %
Epoch 1826 of 2000 took 0.101s
  training loss:		0.115033
  validation loss:		0.337084
  validation accuracy:		91.20 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.119071
  validation loss:		0.343714
  validation accuracy:		90.98 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.114706
  validation loss:		0.351329
  validation accuracy:		91.09 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.111684
  validation loss:		0.325889
  validation accuracy:		91.85 %
Epoch 1830 of 2000 took 0.100s
  training loss:		0.116558
  validation loss:		0.347074
  validation accuracy:		91.20 %
Epoch 1831 of 2000 took 0.098s
  training loss:		0.114911
  validation loss:		0.354299
  validation accuracy:		90.98 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.116698
  validation loss:		0.338036
  validation accuracy:		91.30 %
Epoch 1833 of 2000 took 0.100s
  training loss:		0.118127
  validation loss:		0.327664
  validation accuracy:		91.74 %
Epoch 1834 of 2000 took 0.098s
  training loss:		0.113794
  validation loss:		0.357505
  validation accuracy:		90.76 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.113573
  validation loss:		0.341325
  validation accuracy:		91.30 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.117430
  validation loss:		0.332229
  validation accuracy:		91.09 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.113084
  validation loss:		0.342840
  validation accuracy:		91.30 %
Epoch 1838 of 2000 took 0.100s
  training loss:		0.106798
  validation loss:		0.352927
  validation accuracy:		91.09 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.118166
  validation loss:		0.339567
  validation accuracy:		91.41 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.111249
  validation loss:		0.349712
  validation accuracy:		90.98 %
Epoch 1841 of 2000 took 0.102s
  training loss:		0.114756
  validation loss:		0.337428
  validation accuracy:		91.63 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.108312
  validation loss:		0.332033
  validation accuracy:		91.85 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.112795
  validation loss:		0.334626
  validation accuracy:		91.74 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.113184
  validation loss:		0.337774
  validation accuracy:		91.74 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.112925
  validation loss:		0.342989
  validation accuracy:		91.09 %
Epoch 1846 of 2000 took 0.100s
  training loss:		0.110630
  validation loss:		0.350763
  validation accuracy:		90.98 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.110820
  validation loss:		0.333061
  validation accuracy:		91.52 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.108826
  validation loss:		0.334355
  validation accuracy:		91.63 %
Epoch 1849 of 2000 took 0.102s
  training loss:		0.099703
  validation loss:		0.352835
  validation accuracy:		90.98 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.110300
  validation loss:		0.327989
  validation accuracy:		91.85 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.107555
  validation loss:		0.353473
  validation accuracy:		90.54 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.108904
  validation loss:		0.353845
  validation accuracy:		90.98 %
Epoch 1853 of 2000 took 0.098s
  training loss:		0.108415
  validation loss:		0.334061
  validation accuracy:		91.96 %
Epoch 1854 of 2000 took 0.099s
  training loss:		0.104520
  validation loss:		0.338890
  validation accuracy:		91.85 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.105669
  validation loss:		0.330078
  validation accuracy:		92.28 %
Epoch 1856 of 2000 took 0.098s
  training loss:		0.109209
  validation loss:		0.360684
  validation accuracy:		90.65 %
Epoch 1857 of 2000 took 0.100s
  training loss:		0.109778
  validation loss:		0.349298
  validation accuracy:		90.98 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.108926
  validation loss:		0.350560
  validation accuracy:		91.09 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.112182
  validation loss:		0.337571
  validation accuracy:		91.63 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.107706
  validation loss:		0.348574
  validation accuracy:		91.30 %
Epoch 1861 of 2000 took 0.101s
  training loss:		0.107588
  validation loss:		0.347177
  validation accuracy:		91.20 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.101616
  validation loss:		0.352218
  validation accuracy:		90.98 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.106360
  validation loss:		0.365794
  validation accuracy:		91.09 %
Epoch 1864 of 2000 took 0.101s
  training loss:		0.107736
  validation loss:		0.351709
  validation accuracy:		91.20 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.107639
  validation loss:		0.347864
  validation accuracy:		91.09 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.102609
  validation loss:		0.361835
  validation accuracy:		91.20 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.102193
  validation loss:		0.359423
  validation accuracy:		90.98 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.104473
  validation loss:		0.340675
  validation accuracy:		91.63 %
Epoch 1869 of 2000 took 0.100s
  training loss:		0.106877
  validation loss:		0.354136
  validation accuracy:		91.41 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.103527
  validation loss:		0.358590
  validation accuracy:		91.30 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.110593
  validation loss:		0.372767
  validation accuracy:		90.43 %
Epoch 1872 of 2000 took 0.102s
  training loss:		0.109953
  validation loss:		0.357338
  validation accuracy:		91.74 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.103823
  validation loss:		0.346021
  validation accuracy:		92.07 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.101602
  validation loss:		0.353561
  validation accuracy:		91.52 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.103523
  validation loss:		0.348504
  validation accuracy:		91.63 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.099138
  validation loss:		0.350636
  validation accuracy:		91.63 %
Epoch 1877 of 2000 took 0.100s
  training loss:		0.112413
  validation loss:		0.339714
  validation accuracy:		91.74 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.100299
  validation loss:		0.358504
  validation accuracy:		91.30 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.107909
  validation loss:		0.345978
  validation accuracy:		91.41 %
Epoch 1880 of 2000 took 0.101s
  training loss:		0.103278
  validation loss:		0.367368
  validation accuracy:		90.98 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.102450
  validation loss:		0.371352
  validation accuracy:		90.54 %
Epoch 1882 of 2000 took 0.097s
  training loss:		0.102829
  validation loss:		0.370360
  validation accuracy:		91.52 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.104326
  validation loss:		0.362969
  validation accuracy:		91.41 %
Epoch 1884 of 2000 took 0.100s
  training loss:		0.105745
  validation loss:		0.367386
  validation accuracy:		90.54 %
Epoch 1885 of 2000 took 0.098s
  training loss:		0.100194
  validation loss:		0.355719
  validation accuracy:		91.63 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.103337
  validation loss:		0.373760
  validation accuracy:		90.87 %
Epoch 1887 of 2000 took 0.100s
  training loss:		0.104897
  validation loss:		0.361349
  validation accuracy:		90.87 %
Epoch 1888 of 2000 took 0.098s
  training loss:		0.099379
  validation loss:		0.374232
  validation accuracy:		90.54 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.104009
  validation loss:		0.370200
  validation accuracy:		90.65 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.105469
  validation loss:		0.354989
  validation accuracy:		91.96 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.104673
  validation loss:		0.368518
  validation accuracy:		90.87 %
Epoch 1892 of 2000 took 0.100s
  training loss:		0.107653
  validation loss:		0.375389
  validation accuracy:		90.98 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.101695
  validation loss:		0.351317
  validation accuracy:		91.74 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.107418
  validation loss:		0.361331
  validation accuracy:		91.52 %
Epoch 1895 of 2000 took 0.102s
  training loss:		0.098813
  validation loss:		0.362741
  validation accuracy:		91.20 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.105973
  validation loss:		0.378701
  validation accuracy:		90.87 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.098786
  validation loss:		0.355326
  validation accuracy:		91.96 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.101708
  validation loss:		0.376540
  validation accuracy:		90.43 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.103064
  validation loss:		0.373407
  validation accuracy:		90.76 %
Epoch 1900 of 2000 took 0.100s
  training loss:		0.099362
  validation loss:		0.347845
  validation accuracy:		91.96 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.095531
  validation loss:		0.364888
  validation accuracy:		91.63 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.095902
  validation loss:		0.386267
  validation accuracy:		90.65 %
Epoch 1903 of 2000 took 0.102s
  training loss:		0.098084
  validation loss:		0.374115
  validation accuracy:		90.98 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.098364
  validation loss:		0.373346
  validation accuracy:		91.52 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.103895
  validation loss:		0.358286
  validation accuracy:		91.74 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.092839
  validation loss:		0.372990
  validation accuracy:		90.87 %
Epoch 1907 of 2000 took 0.099s
  training loss:		0.096860
  validation loss:		0.407999
  validation accuracy:		90.11 %
Epoch 1908 of 2000 took 0.098s
  training loss:		0.098683
  validation loss:		0.373647
  validation accuracy:		91.63 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.094286
  validation loss:		0.363904
  validation accuracy:		91.41 %
Epoch 1910 of 2000 took 0.099s
  training loss:		0.099144
  validation loss:		0.359595
  validation accuracy:		91.96 %
Epoch 1911 of 2000 took 0.099s
  training loss:		0.095622
  validation loss:		0.365287
  validation accuracy:		91.96 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.095339
  validation loss:		0.366436
  validation accuracy:		91.74 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.097171
  validation loss:		0.375881
  validation accuracy:		91.20 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.099614
  validation loss:		0.367776
  validation accuracy:		91.20 %
Epoch 1915 of 2000 took 0.100s
  training loss:		0.100871
  validation loss:		0.388082
  validation accuracy:		91.20 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.096217
  validation loss:		0.361880
  validation accuracy:		91.96 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.092716
  validation loss:		0.362371
  validation accuracy:		91.96 %
Epoch 1918 of 2000 took 0.102s
  training loss:		0.096013
  validation loss:		0.364060
  validation accuracy:		91.96 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.093779
  validation loss:		0.378548
  validation accuracy:		91.30 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.095570
  validation loss:		0.383298
  validation accuracy:		91.20 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.098427
  validation loss:		0.377870
  validation accuracy:		90.76 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.094422
  validation loss:		0.398180
  validation accuracy:		90.22 %
Epoch 1923 of 2000 took 0.100s
  training loss:		0.098421
  validation loss:		0.393353
  validation accuracy:		90.11 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.092623
  validation loss:		0.383114
  validation accuracy:		90.65 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.094556
  validation loss:		0.371448
  validation accuracy:		91.30 %
Epoch 1926 of 2000 took 0.102s
  training loss:		0.095763
  validation loss:		0.392435
  validation accuracy:		90.65 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.097268
  validation loss:		0.391174
  validation accuracy:		90.87 %
Epoch 1928 of 2000 took 0.097s
  training loss:		0.098389
  validation loss:		0.374413
  validation accuracy:		90.87 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.097348
  validation loss:		0.375132
  validation accuracy:		91.30 %
Epoch 1930 of 2000 took 0.098s
  training loss:		0.096141
  validation loss:		0.376771
  validation accuracy:		91.20 %
Epoch 1931 of 2000 took 0.100s
  training loss:		0.097129
  validation loss:		0.386842
  validation accuracy:		91.20 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.094281
  validation loss:		0.363654
  validation accuracy:		91.74 %
Epoch 1933 of 2000 took 0.098s
  training loss:		0.091563
  validation loss:		0.388285
  validation accuracy:		90.87 %
Epoch 1934 of 2000 took 0.101s
  training loss:		0.096812
  validation loss:		0.377587
  validation accuracy:		91.63 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.095022
  validation loss:		0.380671
  validation accuracy:		91.96 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.091840
  validation loss:		0.403148
  validation accuracy:		90.87 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.098042
  validation loss:		0.398496
  validation accuracy:		91.09 %
Epoch 1938 of 2000 took 0.100s
  training loss:		0.097201
  validation loss:		0.391878
  validation accuracy:		90.65 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.094821
  validation loss:		0.391758
  validation accuracy:		91.52 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.093115
  validation loss:		0.383500
  validation accuracy:		91.30 %
Epoch 1941 of 2000 took 0.101s
  training loss:		0.094865
  validation loss:		0.370104
  validation accuracy:		91.74 %
Epoch 1942 of 2000 took 0.097s
  training loss:		0.093096
  validation loss:		0.383834
  validation accuracy:		91.30 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.094918
  validation loss:		0.385783
  validation accuracy:		91.30 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.094116
  validation loss:		0.378312
  validation accuracy:		91.85 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.090181
  validation loss:		0.403891
  validation accuracy:		90.98 %
Epoch 1946 of 2000 took 0.100s
  training loss:		0.094685
  validation loss:		0.392643
  validation accuracy:		91.63 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.091747
  validation loss:		0.406893
  validation accuracy:		90.54 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.097115
  validation loss:		0.402962
  validation accuracy:		90.98 %
Epoch 1949 of 2000 took 0.102s
  training loss:		0.090090
  validation loss:		0.379237
  validation accuracy:		91.85 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.093069
  validation loss:		0.410636
  validation accuracy:		91.09 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.090462
  validation loss:		0.386837
  validation accuracy:		91.52 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.086532
  validation loss:		0.384356
  validation accuracy:		91.41 %
Epoch 1953 of 2000 took 0.098s
  training loss:		0.093074
  validation loss:		0.393838
  validation accuracy:		90.65 %
Epoch 1954 of 2000 took 0.101s
  training loss:		0.086023
  validation loss:		0.398510
  validation accuracy:		91.20 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.090267
  validation loss:		0.377369
  validation accuracy:		92.07 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.091164
  validation loss:		0.398236
  validation accuracy:		90.87 %
Epoch 1957 of 2000 took 0.102s
  training loss:		0.092964
  validation loss:		0.384315
  validation accuracy:		91.74 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.084260
  validation loss:		0.410207
  validation accuracy:		90.43 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.089932
  validation loss:		0.405965
  validation accuracy:		90.65 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.088207
  validation loss:		0.408419
  validation accuracy:		91.09 %
Epoch 1961 of 2000 took 0.099s
  training loss:		0.092607
  validation loss:		0.396793
  validation accuracy:		91.63 %
Epoch 1962 of 2000 took 0.098s
  training loss:		0.088565
  validation loss:		0.401362
  validation accuracy:		91.09 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.088229
  validation loss:		0.392534
  validation accuracy:		92.39 %
Epoch 1964 of 2000 took 0.099s
  training loss:		0.091315
  validation loss:		0.403008
  validation accuracy:		91.85 %
Epoch 1965 of 2000 took 0.099s
  training loss:		0.089082
  validation loss:		0.398578
  validation accuracy:		91.52 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.089214
  validation loss:		0.389171
  validation accuracy:		91.20 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.087542
  validation loss:		0.383065
  validation accuracy:		91.85 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.090305
  validation loss:		0.418949
  validation accuracy:		90.54 %
Epoch 1969 of 2000 took 0.100s
  training loss:		0.088064
  validation loss:		0.417827
  validation accuracy:		90.22 %
Epoch 1970 of 2000 took 0.097s
  training loss:		0.086940
  validation loss:		0.434274
  validation accuracy:		90.22 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.090129
  validation loss:		0.399774
  validation accuracy:		91.30 %
Epoch 1972 of 2000 took 0.102s
  training loss:		0.089136
  validation loss:		0.397346
  validation accuracy:		91.41 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.087127
  validation loss:		0.385707
  validation accuracy:		91.74 %
Epoch 1974 of 2000 took 0.097s
  training loss:		0.087066
  validation loss:		0.401450
  validation accuracy:		91.63 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.087587
  validation loss:		0.427736
  validation accuracy:		90.87 %
Epoch 1976 of 2000 took 0.097s
  training loss:		0.088363
  validation loss:		0.418603
  validation accuracy:		90.43 %
Epoch 1977 of 2000 took 0.100s
  training loss:		0.085729
  validation loss:		0.401513
  validation accuracy:		91.74 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.087556
  validation loss:		0.406927
  validation accuracy:		91.52 %
Epoch 1979 of 2000 took 0.097s
  training loss:		0.083913
  validation loss:		0.427839
  validation accuracy:		90.87 %
Epoch 1980 of 2000 took 0.102s
  training loss:		0.087683
  validation loss:		0.425275
  validation accuracy:		90.43 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.083650
  validation loss:		0.442009
  validation accuracy:		90.65 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.088046
  validation loss:		0.419616
  validation accuracy:		90.76 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.086897
  validation loss:		0.421630
  validation accuracy:		90.43 %
Epoch 1984 of 2000 took 0.099s
  training loss:		0.089544
  validation loss:		0.423541
  validation accuracy:		90.87 %
Epoch 1985 of 2000 took 0.098s
  training loss:		0.088278
  validation loss:		0.414061
  validation accuracy:		90.87 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.084873
  validation loss:		0.419355
  validation accuracy:		90.43 %
Epoch 1987 of 2000 took 0.098s
  training loss:		0.085752
  validation loss:		0.412528
  validation accuracy:		91.63 %
Epoch 1988 of 2000 took 0.100s
  training loss:		0.088594
  validation loss:		0.397241
  validation accuracy:		91.85 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.087922
  validation loss:		0.407373
  validation accuracy:		91.52 %
Epoch 1990 of 2000 took 0.097s
  training loss:		0.087093
  validation loss:		0.399079
  validation accuracy:		91.52 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.089066
  validation loss:		0.421209
  validation accuracy:		90.76 %
Epoch 1992 of 2000 took 0.100s
  training loss:		0.088467
  validation loss:		0.425753
  validation accuracy:		90.87 %
Epoch 1993 of 2000 took 0.097s
  training loss:		0.086914
  validation loss:		0.434898
  validation accuracy:		91.09 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.083640
  validation loss:		0.394804
  validation accuracy:		91.85 %
Epoch 1995 of 2000 took 0.101s
  training loss:		0.081184
  validation loss:		0.406921
  validation accuracy:		91.74 %
Epoch 1996 of 2000 took 0.097s
  training loss:		0.083565
  validation loss:		0.417622
  validation accuracy:		90.65 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.084600
  validation loss:		0.456146
  validation accuracy:		90.43 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.088013
  validation loss:		0.408119
  validation accuracy:		91.85 %
Epoch 1999 of 2000 took 0.097s
  training loss:		0.078483
  validation loss:		0.437022
  validation accuracy:		90.98 %
Epoch 2000 of 2000 took 0.100s
  training loss:		0.087974
  validation loss:		0.414552
  validation accuracy:		91.30 %
Final results:
  test loss:			0.875244
  test accuracy:		83.88 %
