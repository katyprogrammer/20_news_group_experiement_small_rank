Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.069s
  training loss:		2.976991
  validation loss:		2.926089
  validation accuracy:		7.61 %
Epoch 2 of 2000 took 0.064s
  training loss:		2.827056
  validation loss:		2.726412
  validation accuracy:		13.04 %
Epoch 3 of 2000 took 0.064s
  training loss:		2.606199
  validation loss:		2.452048
  validation accuracy:		13.04 %
Epoch 4 of 2000 took 0.065s
  training loss:		2.398378
  validation loss:		2.256843
  validation accuracy:		30.11 %
Epoch 5 of 2000 took 0.063s
  training loss:		2.312734
  validation loss:		2.230086
  validation accuracy:		18.70 %
Epoch 6 of 2000 took 0.064s
  training loss:		2.284200
  validation loss:		2.233620
  validation accuracy:		28.70 %
Epoch 7 of 2000 took 0.063s
  training loss:		2.272170
  validation loss:		2.212824
  validation accuracy:		27.28 %
Epoch 8 of 2000 took 0.063s
  training loss:		2.263139
  validation loss:		2.204197
  validation accuracy:		28.15 %
Epoch 9 of 2000 took 0.063s
  training loss:		2.254946
  validation loss:		2.191014
  validation accuracy:		38.37 %
Epoch 10 of 2000 took 0.063s
  training loss:		2.244858
  validation loss:		2.181263
  validation accuracy:		42.50 %
Epoch 11 of 2000 took 0.061s
  training loss:		2.237096
  validation loss:		2.184687
  validation accuracy:		55.22 %
Epoch 12 of 2000 took 0.060s
  training loss:		2.226618
  validation loss:		2.157733
  validation accuracy:		44.78 %
Epoch 13 of 2000 took 0.059s
  training loss:		2.215271
  validation loss:		2.144829
  validation accuracy:		45.87 %
Epoch 14 of 2000 took 0.059s
  training loss:		2.199701
  validation loss:		2.131214
  validation accuracy:		57.50 %
Epoch 15 of 2000 took 0.059s
  training loss:		2.180567
  validation loss:		2.106298
  validation accuracy:		59.02 %
Epoch 16 of 2000 took 0.059s
  training loss:		2.161777
  validation loss:		2.083617
  validation accuracy:		56.85 %
Epoch 17 of 2000 took 0.059s
  training loss:		2.136542
  validation loss:		2.058605
  validation accuracy:		54.57 %
Epoch 18 of 2000 took 0.059s
  training loss:		2.109018
  validation loss:		2.024797
  validation accuracy:		65.65 %
Epoch 19 of 2000 took 0.058s
  training loss:		2.073722
  validation loss:		1.977144
  validation accuracy:		48.59 %
Epoch 20 of 2000 took 0.059s
  training loss:		2.035471
  validation loss:		1.927710
  validation accuracy:		65.33 %
Epoch 21 of 2000 took 0.059s
  training loss:		1.988496
  validation loss:		1.889449
  validation accuracy:		70.76 %
Epoch 22 of 2000 took 0.058s
  training loss:		1.935322
  validation loss:		1.826775
  validation accuracy:		65.11 %
Epoch 23 of 2000 took 0.058s
  training loss:		1.875641
  validation loss:		1.750059
  validation accuracy:		69.67 %
Epoch 24 of 2000 took 0.058s
  training loss:		1.807884
  validation loss:		1.688773
  validation accuracy:		65.00 %
Epoch 25 of 2000 took 0.059s
  training loss:		1.735478
  validation loss:		1.591444
  validation accuracy:		73.70 %
Epoch 26 of 2000 took 0.059s
  training loss:		1.659273
  validation loss:		1.521650
  validation accuracy:		73.26 %
Epoch 27 of 2000 took 0.058s
  training loss:		1.582805
  validation loss:		1.436678
  validation accuracy:		77.72 %
Epoch 28 of 2000 took 0.059s
  training loss:		1.501695
  validation loss:		1.351032
  validation accuracy:		81.20 %
Epoch 29 of 2000 took 0.059s
  training loss:		1.420128
  validation loss:		1.278285
  validation accuracy:		82.17 %
Epoch 30 of 2000 took 0.059s
  training loss:		1.345639
  validation loss:		1.203727
  validation accuracy:		82.07 %
Epoch 31 of 2000 took 0.059s
  training loss:		1.272020
  validation loss:		1.122893
  validation accuracy:		81.41 %
Epoch 32 of 2000 took 0.058s
  training loss:		1.200059
  validation loss:		1.068712
  validation accuracy:		84.02 %
Epoch 33 of 2000 took 0.059s
  training loss:		1.136184
  validation loss:		0.994285
  validation accuracy:		81.96 %
Epoch 34 of 2000 took 0.059s
  training loss:		1.081355
  validation loss:		0.950496
  validation accuracy:		80.98 %
Epoch 35 of 2000 took 0.058s
  training loss:		1.021839
  validation loss:		0.902117
  validation accuracy:		85.00 %
Epoch 36 of 2000 took 0.058s
  training loss:		0.976165
  validation loss:		0.862094
  validation accuracy:		79.02 %
Epoch 37 of 2000 took 0.058s
  training loss:		0.928365
  validation loss:		0.827719
  validation accuracy:		85.22 %
Epoch 38 of 2000 took 0.058s
  training loss:		0.887983
  validation loss:		0.796301
  validation accuracy:		80.98 %
Epoch 39 of 2000 took 0.058s
  training loss:		0.849949
  validation loss:		0.759750
  validation accuracy:		84.02 %
Epoch 40 of 2000 took 0.058s
  training loss:		0.821200
  validation loss:		0.730443
  validation accuracy:		85.43 %
Epoch 41 of 2000 took 0.058s
  training loss:		0.779866
  validation loss:		0.700309
  validation accuracy:		83.70 %
Epoch 42 of 2000 took 0.059s
  training loss:		0.753245
  validation loss:		0.681062
  validation accuracy:		85.65 %
Epoch 43 of 2000 took 0.058s
  training loss:		0.725051
  validation loss:		0.655637
  validation accuracy:		86.20 %
Epoch 44 of 2000 took 0.058s
  training loss:		0.700915
  validation loss:		0.637518
  validation accuracy:		86.09 %
Epoch 45 of 2000 took 0.058s
  training loss:		0.667730
  validation loss:		0.641869
  validation accuracy:		85.22 %
Epoch 46 of 2000 took 0.058s
  training loss:		0.655826
  validation loss:		0.595515
  validation accuracy:		86.52 %
Epoch 47 of 2000 took 0.059s
  training loss:		0.626187
  validation loss:		0.603643
  validation accuracy:		85.98 %
Epoch 48 of 2000 took 0.058s
  training loss:		0.613873
  validation loss:		0.575758
  validation accuracy:		86.74 %
Epoch 49 of 2000 took 0.063s
  training loss:		0.595932
  validation loss:		0.554585
  validation accuracy:		86.63 %
Epoch 50 of 2000 took 0.058s
  training loss:		0.571353
  validation loss:		0.538103
  validation accuracy:		87.07 %
Epoch 51 of 2000 took 0.059s
  training loss:		0.556357
  validation loss:		0.520825
  validation accuracy:		87.50 %
Epoch 52 of 2000 took 0.059s
  training loss:		0.539316
  validation loss:		0.514104
  validation accuracy:		87.17 %
Epoch 53 of 2000 took 0.059s
  training loss:		0.531395
  validation loss:		0.507278
  validation accuracy:		87.28 %
Epoch 54 of 2000 took 0.060s
  training loss:		0.514355
  validation loss:		0.491571
  validation accuracy:		87.39 %
Epoch 55 of 2000 took 0.059s
  training loss:		0.500535
  validation loss:		0.475320
  validation accuracy:		87.83 %
Epoch 56 of 2000 took 0.058s
  training loss:		0.487929
  validation loss:		0.473527
  validation accuracy:		87.93 %
Epoch 57 of 2000 took 0.059s
  training loss:		0.475317
  validation loss:		0.462341
  validation accuracy:		87.93 %
Epoch 58 of 2000 took 0.059s
  training loss:		0.467576
  validation loss:		0.458634
  validation accuracy:		87.93 %
Epoch 59 of 2000 took 0.060s
  training loss:		0.453633
  validation loss:		0.449872
  validation accuracy:		88.48 %
Epoch 60 of 2000 took 0.059s
  training loss:		0.439578
  validation loss:		0.433775
  validation accuracy:		88.37 %
Epoch 61 of 2000 took 0.059s
  training loss:		0.437862
  validation loss:		0.437357
  validation accuracy:		88.48 %
Epoch 62 of 2000 took 0.059s
  training loss:		0.427151
  validation loss:		0.430088
  validation accuracy:		88.37 %
Epoch 63 of 2000 took 0.059s
  training loss:		0.420036
  validation loss:		0.419821
  validation accuracy:		88.48 %
Epoch 64 of 2000 took 0.058s
  training loss:		0.407652
  validation loss:		0.419966
  validation accuracy:		88.37 %
Epoch 65 of 2000 took 0.059s
  training loss:		0.404686
  validation loss:		0.413347
  validation accuracy:		89.02 %
Epoch 66 of 2000 took 0.059s
  training loss:		0.395068
  validation loss:		0.410496
  validation accuracy:		88.80 %
Epoch 67 of 2000 took 0.059s
  training loss:		0.390873
  validation loss:		0.410114
  validation accuracy:		88.80 %
Epoch 68 of 2000 took 0.059s
  training loss:		0.389066
  validation loss:		0.398169
  validation accuracy:		89.02 %
Epoch 69 of 2000 took 0.059s
  training loss:		0.376845
  validation loss:		0.398916
  validation accuracy:		88.59 %
Epoch 70 of 2000 took 0.059s
  training loss:		0.368541
  validation loss:		0.386048
  validation accuracy:		89.24 %
Epoch 71 of 2000 took 0.059s
  training loss:		0.369192
  validation loss:		0.381944
  validation accuracy:		89.35 %
Epoch 72 of 2000 took 0.060s
  training loss:		0.365982
  validation loss:		0.377152
  validation accuracy:		89.02 %
Epoch 73 of 2000 took 0.059s
  training loss:		0.358231
  validation loss:		0.376440
  validation accuracy:		89.24 %
Epoch 74 of 2000 took 0.059s
  training loss:		0.351792
  validation loss:		0.368981
  validation accuracy:		89.57 %
Epoch 75 of 2000 took 0.059s
  training loss:		0.346763
  validation loss:		0.363457
  validation accuracy:		89.24 %
Epoch 76 of 2000 took 0.059s
  training loss:		0.345667
  validation loss:		0.354930
  validation accuracy:		89.24 %
Epoch 77 of 2000 took 0.059s
  training loss:		0.337219
  validation loss:		0.359800
  validation accuracy:		88.80 %
Epoch 78 of 2000 took 0.059s
  training loss:		0.334316
  validation loss:		0.375011
  validation accuracy:		88.59 %
Epoch 79 of 2000 took 0.059s
  training loss:		0.332709
  validation loss:		0.361852
  validation accuracy:		89.13 %
Epoch 80 of 2000 took 0.058s
  training loss:		0.330559
  validation loss:		0.342650
  validation accuracy:		89.67 %
Epoch 81 of 2000 took 0.059s
  training loss:		0.324052
  validation loss:		0.339635
  validation accuracy:		90.11 %
Epoch 82 of 2000 took 0.059s
  training loss:		0.323181
  validation loss:		0.350312
  validation accuracy:		90.11 %
Epoch 83 of 2000 took 0.059s
  training loss:		0.316171
  validation loss:		0.348222
  validation accuracy:		89.89 %
Epoch 84 of 2000 took 0.059s
  training loss:		0.315014
  validation loss:		0.342740
  validation accuracy:		90.00 %
Epoch 85 of 2000 took 0.060s
  training loss:		0.312536
  validation loss:		0.332197
  validation accuracy:		90.33 %
Epoch 86 of 2000 took 0.058s
  training loss:		0.309617
  validation loss:		0.333873
  validation accuracy:		90.54 %
Epoch 87 of 2000 took 0.059s
  training loss:		0.304503
  validation loss:		0.334893
  validation accuracy:		90.33 %
Epoch 88 of 2000 took 0.059s
  training loss:		0.300316
  validation loss:		0.330393
  validation accuracy:		90.33 %
Epoch 89 of 2000 took 0.059s
  training loss:		0.296898
  validation loss:		0.330267
  validation accuracy:		90.54 %
Epoch 90 of 2000 took 0.059s
  training loss:		0.296669
  validation loss:		0.325901
  validation accuracy:		90.22 %
Epoch 91 of 2000 took 0.059s
  training loss:		0.294435
  validation loss:		0.319130
  validation accuracy:		90.98 %
Epoch 92 of 2000 took 0.060s
  training loss:		0.292811
  validation loss:		0.321673
  validation accuracy:		90.43 %
Epoch 93 of 2000 took 0.059s
  training loss:		0.289193
  validation loss:		0.317887
  validation accuracy:		90.65 %
Epoch 94 of 2000 took 0.059s
  training loss:		0.289430
  validation loss:		0.327651
  validation accuracy:		90.11 %
Epoch 95 of 2000 took 0.059s
  training loss:		0.283808
  validation loss:		0.320765
  validation accuracy:		91.09 %
Epoch 96 of 2000 took 0.059s
  training loss:		0.284062
  validation loss:		0.312178
  validation accuracy:		91.09 %
Epoch 97 of 2000 took 0.059s
  training loss:		0.279667
  validation loss:		0.322875
  validation accuracy:		90.65 %
Epoch 98 of 2000 took 0.059s
  training loss:		0.278947
  validation loss:		0.312719
  validation accuracy:		91.09 %
Epoch 99 of 2000 took 0.059s
  training loss:		0.272817
  validation loss:		0.300090
  validation accuracy:		91.09 %
Epoch 100 of 2000 took 0.059s
  training loss:		0.273864
  validation loss:		0.304231
  validation accuracy:		91.52 %
Epoch 101 of 2000 took 0.059s
  training loss:		0.272666
  validation loss:		0.306481
  validation accuracy:		90.98 %
Epoch 102 of 2000 took 0.059s
  training loss:		0.267614
  validation loss:		0.314977
  validation accuracy:		90.87 %
Epoch 103 of 2000 took 0.059s
  training loss:		0.267563
  validation loss:		0.306928
  validation accuracy:		91.41 %
Epoch 104 of 2000 took 0.058s
  training loss:		0.257331
  validation loss:		0.301477
  validation accuracy:		91.41 %
Epoch 105 of 2000 took 0.059s
  training loss:		0.266193
  validation loss:		0.300803
  validation accuracy:		91.63 %
Epoch 106 of 2000 took 0.058s
  training loss:		0.262680
  validation loss:		0.308390
  validation accuracy:		91.20 %
Epoch 107 of 2000 took 0.059s
  training loss:		0.263870
  validation loss:		0.301867
  validation accuracy:		91.20 %
Epoch 108 of 2000 took 0.059s
  training loss:		0.255756
  validation loss:		0.304348
  validation accuracy:		91.52 %
Epoch 109 of 2000 took 0.059s
  training loss:		0.257340
  validation loss:		0.313447
  validation accuracy:		90.54 %
Epoch 110 of 2000 took 0.058s
  training loss:		0.262851
  validation loss:		0.298333
  validation accuracy:		91.74 %
Epoch 111 of 2000 took 0.057s
  training loss:		0.254180
  validation loss:		0.307636
  validation accuracy:		90.98 %
Epoch 112 of 2000 took 0.057s
  training loss:		0.251156
  validation loss:		0.307085
  validation accuracy:		91.09 %
Epoch 113 of 2000 took 0.058s
  training loss:		0.254051
  validation loss:		0.312320
  validation accuracy:		90.87 %
Epoch 114 of 2000 took 0.057s
  training loss:		0.250074
  validation loss:		0.296658
  validation accuracy:		91.74 %
Epoch 115 of 2000 took 0.057s
  training loss:		0.248193
  validation loss:		0.308792
  validation accuracy:		90.98 %
Epoch 116 of 2000 took 0.057s
  training loss:		0.250471
  validation loss:		0.299166
  validation accuracy:		91.74 %
Epoch 117 of 2000 took 0.057s
  training loss:		0.244101
  validation loss:		0.290940
  validation accuracy:		91.96 %
Epoch 118 of 2000 took 0.057s
  training loss:		0.250789
  validation loss:		0.297994
  validation accuracy:		91.52 %
Epoch 119 of 2000 took 0.058s
  training loss:		0.244751
  validation loss:		0.289795
  validation accuracy:		91.63 %
Epoch 120 of 2000 took 0.058s
  training loss:		0.244052
  validation loss:		0.295661
  validation accuracy:		91.85 %
Epoch 121 of 2000 took 0.058s
  training loss:		0.248347
  validation loss:		0.292730
  validation accuracy:		91.85 %
Epoch 122 of 2000 took 0.057s
  training loss:		0.240526
  validation loss:		0.295370
  validation accuracy:		91.63 %
Epoch 123 of 2000 took 0.057s
  training loss:		0.241677
  validation loss:		0.291227
  validation accuracy:		91.85 %
Epoch 124 of 2000 took 0.057s
  training loss:		0.236580
  validation loss:		0.300995
  validation accuracy:		91.41 %
Epoch 125 of 2000 took 0.059s
  training loss:		0.234994
  validation loss:		0.300037
  validation accuracy:		90.98 %
Epoch 126 of 2000 took 0.056s
  training loss:		0.237216
  validation loss:		0.286084
  validation accuracy:		91.63 %
Epoch 127 of 2000 took 0.056s
  training loss:		0.235126
  validation loss:		0.291109
  validation accuracy:		91.85 %
Epoch 128 of 2000 took 0.058s
  training loss:		0.238132
  validation loss:		0.289350
  validation accuracy:		91.96 %
Epoch 129 of 2000 took 0.058s
  training loss:		0.234963
  validation loss:		0.286272
  validation accuracy:		91.96 %
Epoch 130 of 2000 took 0.058s
  training loss:		0.233971
  validation loss:		0.296629
  validation accuracy:		91.63 %
Epoch 131 of 2000 took 0.058s
  training loss:		0.231925
  validation loss:		0.284788
  validation accuracy:		91.30 %
Epoch 132 of 2000 took 0.058s
  training loss:		0.230551
  validation loss:		0.285283
  validation accuracy:		91.74 %
Epoch 133 of 2000 took 0.058s
  training loss:		0.234282
  validation loss:		0.296306
  validation accuracy:		91.09 %
Epoch 134 of 2000 took 0.058s
  training loss:		0.228379
  validation loss:		0.285211
  validation accuracy:		91.74 %
Epoch 135 of 2000 took 0.058s
  training loss:		0.227828
  validation loss:		0.286004
  validation accuracy:		91.74 %
Epoch 136 of 2000 took 0.058s
  training loss:		0.226563
  validation loss:		0.289293
  validation accuracy:		91.63 %
Epoch 137 of 2000 took 0.058s
  training loss:		0.229828
  validation loss:		0.278428
  validation accuracy:		91.63 %
Epoch 138 of 2000 took 0.058s
  training loss:		0.228335
  validation loss:		0.282842
  validation accuracy:		91.63 %
Epoch 139 of 2000 took 0.054s
  training loss:		0.226137
  validation loss:		0.278584
  validation accuracy:		91.96 %
Epoch 140 of 2000 took 0.057s
  training loss:		0.222556
  validation loss:		0.292880
  validation accuracy:		91.85 %
Epoch 141 of 2000 took 0.057s
  training loss:		0.226451
  validation loss:		0.284570
  validation accuracy:		91.74 %
Epoch 142 of 2000 took 0.057s
  training loss:		0.225414
  validation loss:		0.280778
  validation accuracy:		91.74 %
Epoch 143 of 2000 took 0.057s
  training loss:		0.220026
  validation loss:		0.289961
  validation accuracy:		91.41 %
Epoch 144 of 2000 took 0.057s
  training loss:		0.224014
  validation loss:		0.286914
  validation accuracy:		91.85 %
Epoch 145 of 2000 took 0.058s
  training loss:		0.217955
  validation loss:		0.276878
  validation accuracy:		91.41 %
Epoch 146 of 2000 took 0.057s
  training loss:		0.225121
  validation loss:		0.278211
  validation accuracy:		92.17 %
Epoch 147 of 2000 took 0.057s
  training loss:		0.219776
  validation loss:		0.279340
  validation accuracy:		91.96 %
Epoch 148 of 2000 took 0.058s
  training loss:		0.219680
  validation loss:		0.281948
  validation accuracy:		91.96 %
Epoch 149 of 2000 took 0.058s
  training loss:		0.218162
  validation loss:		0.280300
  validation accuracy:		92.28 %
Epoch 150 of 2000 took 0.058s
  training loss:		0.214241
  validation loss:		0.275867
  validation accuracy:		91.96 %
Epoch 151 of 2000 took 0.057s
  training loss:		0.212633
  validation loss:		0.278792
  validation accuracy:		91.96 %
Epoch 152 of 2000 took 0.058s
  training loss:		0.210779
  validation loss:		0.288037
  validation accuracy:		91.41 %
Epoch 153 of 2000 took 0.058s
  training loss:		0.211598
  validation loss:		0.277664
  validation accuracy:		91.74 %
Epoch 154 of 2000 took 0.058s
  training loss:		0.211317
  validation loss:		0.282944
  validation accuracy:		91.96 %
Epoch 155 of 2000 took 0.058s
  training loss:		0.208704
  validation loss:		0.285231
  validation accuracy:		91.63 %
Epoch 156 of 2000 took 0.058s
  training loss:		0.212093
  validation loss:		0.282809
  validation accuracy:		91.74 %
Epoch 157 of 2000 took 0.057s
  training loss:		0.209396
  validation loss:		0.273490
  validation accuracy:		91.74 %
Epoch 158 of 2000 took 0.058s
  training loss:		0.210351
  validation loss:		0.279249
  validation accuracy:		92.07 %
Epoch 159 of 2000 took 0.058s
  training loss:		0.207936
  validation loss:		0.288324
  validation accuracy:		91.41 %
Epoch 160 of 2000 took 0.058s
  training loss:		0.213968
  validation loss:		0.280287
  validation accuracy:		91.74 %
Epoch 161 of 2000 took 0.058s
  training loss:		0.202790
  validation loss:		0.282757
  validation accuracy:		91.63 %
Epoch 162 of 2000 took 0.058s
  training loss:		0.205192
  validation loss:		0.281801
  validation accuracy:		91.63 %
Epoch 163 of 2000 took 0.057s
  training loss:		0.208582
  validation loss:		0.276566
  validation accuracy:		91.74 %
Epoch 164 of 2000 took 0.057s
  training loss:		0.205527
  validation loss:		0.281537
  validation accuracy:		91.52 %
Epoch 165 of 2000 took 0.057s
  training loss:		0.205891
  validation loss:		0.279257
  validation accuracy:		91.52 %
Epoch 166 of 2000 took 0.057s
  training loss:		0.207771
  validation loss:		0.284508
  validation accuracy:		91.52 %
Epoch 167 of 2000 took 0.057s
  training loss:		0.205009
  validation loss:		0.273761
  validation accuracy:		92.17 %
Epoch 168 of 2000 took 0.057s
  training loss:		0.204254
  validation loss:		0.274068
  validation accuracy:		91.85 %
Epoch 169 of 2000 took 0.057s
  training loss:		0.202900
  validation loss:		0.281067
  validation accuracy:		91.74 %
Epoch 170 of 2000 took 0.057s
  training loss:		0.204068
  validation loss:		0.279672
  validation accuracy:		91.96 %
Epoch 171 of 2000 took 0.057s
  training loss:		0.201270
  validation loss:		0.275399
  validation accuracy:		91.96 %
Epoch 172 of 2000 took 0.057s
  training loss:		0.206187
  validation loss:		0.281151
  validation accuracy:		91.63 %
Epoch 173 of 2000 took 0.057s
  training loss:		0.200244
  validation loss:		0.284564
  validation accuracy:		91.52 %
Epoch 174 of 2000 took 0.057s
  training loss:		0.201277
  validation loss:		0.288547
  validation accuracy:		91.41 %
Epoch 175 of 2000 took 0.057s
  training loss:		0.200906
  validation loss:		0.282186
  validation accuracy:		91.85 %
Epoch 176 of 2000 took 0.057s
  training loss:		0.199032
  validation loss:		0.275278
  validation accuracy:		91.96 %
Epoch 177 of 2000 took 0.057s
  training loss:		0.199714
  validation loss:		0.295198
  validation accuracy:		91.09 %
Epoch 178 of 2000 took 0.057s
  training loss:		0.200928
  validation loss:		0.279531
  validation accuracy:		91.52 %
Epoch 179 of 2000 took 0.058s
  training loss:		0.198483
  validation loss:		0.274302
  validation accuracy:		92.07 %
Epoch 180 of 2000 took 0.058s
  training loss:		0.196825
  validation loss:		0.278255
  validation accuracy:		91.85 %
Epoch 181 of 2000 took 0.058s
  training loss:		0.200712
  validation loss:		0.275901
  validation accuracy:		91.74 %
Epoch 182 of 2000 took 0.057s
  training loss:		0.194383
  validation loss:		0.281388
  validation accuracy:		91.20 %
Epoch 183 of 2000 took 0.058s
  training loss:		0.201942
  validation loss:		0.271678
  validation accuracy:		91.96 %
Epoch 184 of 2000 took 0.057s
  training loss:		0.195495
  validation loss:		0.277377
  validation accuracy:		92.50 %
Epoch 185 of 2000 took 0.057s
  training loss:		0.199866
  validation loss:		0.274895
  validation accuracy:		91.85 %
Epoch 186 of 2000 took 0.056s
  training loss:		0.192095
  validation loss:		0.269433
  validation accuracy:		92.39 %
Epoch 187 of 2000 took 0.056s
  training loss:		0.198736
  validation loss:		0.272345
  validation accuracy:		91.52 %
Epoch 188 of 2000 took 0.057s
  training loss:		0.195639
  validation loss:		0.285997
  validation accuracy:		91.09 %
Epoch 189 of 2000 took 0.057s
  training loss:		0.189016
  validation loss:		0.275942
  validation accuracy:		91.63 %
Epoch 190 of 2000 took 0.057s
  training loss:		0.194177
  validation loss:		0.278703
  validation accuracy:		91.30 %
Epoch 191 of 2000 took 0.057s
  training loss:		0.188100
  validation loss:		0.283608
  validation accuracy:		91.41 %
Epoch 192 of 2000 took 0.057s
  training loss:		0.192240
  validation loss:		0.278406
  validation accuracy:		91.63 %
Epoch 193 of 2000 took 0.058s
  training loss:		0.187813
  validation loss:		0.275524
  validation accuracy:		91.52 %
Epoch 194 of 2000 took 0.058s
  training loss:		0.187152
  validation loss:		0.279812
  validation accuracy:		91.52 %
Epoch 195 of 2000 took 0.068s
  training loss:		0.191914
  validation loss:		0.279322
  validation accuracy:		91.52 %
Epoch 196 of 2000 took 0.056s
  training loss:		0.192270
  validation loss:		0.275566
  validation accuracy:		91.74 %
Epoch 197 of 2000 took 0.054s
  training loss:		0.189095
  validation loss:		0.275403
  validation accuracy:		91.74 %
Epoch 198 of 2000 took 0.055s
  training loss:		0.184124
  validation loss:		0.279541
  validation accuracy:		91.96 %
Epoch 199 of 2000 took 0.054s
  training loss:		0.191525
  validation loss:		0.289521
  validation accuracy:		91.20 %
Epoch 200 of 2000 took 0.056s
  training loss:		0.185388
  validation loss:		0.273201
  validation accuracy:		91.63 %
Epoch 201 of 2000 took 0.057s
  training loss:		0.186539
  validation loss:		0.277353
  validation accuracy:		91.63 %
Epoch 202 of 2000 took 0.057s
  training loss:		0.190104
  validation loss:		0.287813
  validation accuracy:		91.52 %
Epoch 203 of 2000 took 0.057s
  training loss:		0.190700
  validation loss:		0.282425
  validation accuracy:		91.52 %
Epoch 204 of 2000 took 0.057s
  training loss:		0.186332
  validation loss:		0.288991
  validation accuracy:		91.09 %
Epoch 205 of 2000 took 0.057s
  training loss:		0.188302
  validation loss:		0.282776
  validation accuracy:		91.09 %
Epoch 206 of 2000 took 0.057s
  training loss:		0.187994
  validation loss:		0.282109
  validation accuracy:		91.85 %
Epoch 207 of 2000 took 0.057s
  training loss:		0.183825
  validation loss:		0.284101
  validation accuracy:		91.52 %
Epoch 208 of 2000 took 0.058s
  training loss:		0.187155
  validation loss:		0.289236
  validation accuracy:		91.41 %
Epoch 209 of 2000 took 0.058s
  training loss:		0.183459
  validation loss:		0.277289
  validation accuracy:		91.63 %
Epoch 210 of 2000 took 0.058s
  training loss:		0.182445
  validation loss:		0.280572
  validation accuracy:		91.52 %
Epoch 211 of 2000 took 0.058s
  training loss:		0.184990
  validation loss:		0.279087
  validation accuracy:		92.39 %
Epoch 212 of 2000 took 0.057s
  training loss:		0.184228
  validation loss:		0.283706
  validation accuracy:		91.41 %
Epoch 213 of 2000 took 0.057s
  training loss:		0.177172
  validation loss:		0.293879
  validation accuracy:		91.09 %
Epoch 214 of 2000 took 0.058s
  training loss:		0.183433
  validation loss:		0.275268
  validation accuracy:		91.85 %
Epoch 215 of 2000 took 0.057s
  training loss:		0.183424
  validation loss:		0.278742
  validation accuracy:		91.41 %
Epoch 216 of 2000 took 0.057s
  training loss:		0.184619
  validation loss:		0.282277
  validation accuracy:		91.20 %
Epoch 217 of 2000 took 0.057s
  training loss:		0.181792
  validation loss:		0.286195
  validation accuracy:		91.20 %
Epoch 218 of 2000 took 0.057s
  training loss:		0.182031
  validation loss:		0.280729
  validation accuracy:		91.30 %
Epoch 219 of 2000 took 0.058s
  training loss:		0.182504
  validation loss:		0.279434
  validation accuracy:		91.30 %
Epoch 220 of 2000 took 0.057s
  training loss:		0.179509
  validation loss:		0.276930
  validation accuracy:		91.52 %
Epoch 221 of 2000 took 0.057s
  training loss:		0.180444
  validation loss:		0.273740
  validation accuracy:		91.96 %
Epoch 222 of 2000 took 0.057s
  training loss:		0.179156
  validation loss:		0.281973
  validation accuracy:		91.52 %
Epoch 223 of 2000 took 0.057s
  training loss:		0.180854
  validation loss:		0.273536
  validation accuracy:		91.96 %
Epoch 224 of 2000 took 0.057s
  training loss:		0.180091
  validation loss:		0.278710
  validation accuracy:		91.30 %
Epoch 225 of 2000 took 0.058s
  training loss:		0.179510
  validation loss:		0.278883
  validation accuracy:		91.41 %
Epoch 226 of 2000 took 0.057s
  training loss:		0.178162
  validation loss:		0.283674
  validation accuracy:		91.30 %
Epoch 227 of 2000 took 0.058s
  training loss:		0.180442
  validation loss:		0.280058
  validation accuracy:		91.52 %
Epoch 228 of 2000 took 0.057s
  training loss:		0.178118
  validation loss:		0.283592
  validation accuracy:		91.41 %
Epoch 229 of 2000 took 0.057s
  training loss:		0.179922
  validation loss:		0.271230
  validation accuracy:		91.52 %
Epoch 230 of 2000 took 0.058s
  training loss:		0.180166
  validation loss:		0.284754
  validation accuracy:		91.52 %
Epoch 231 of 2000 took 0.057s
  training loss:		0.175787
  validation loss:		0.293288
  validation accuracy:		91.74 %
Epoch 232 of 2000 took 0.057s
  training loss:		0.176755
  validation loss:		0.279672
  validation accuracy:		91.41 %
Epoch 233 of 2000 took 0.057s
  training loss:		0.174550
  validation loss:		0.281539
  validation accuracy:		91.63 %
Epoch 234 of 2000 took 0.057s
  training loss:		0.177097
  validation loss:		0.274956
  validation accuracy:		91.74 %
Epoch 235 of 2000 took 0.057s
  training loss:		0.170372
  validation loss:		0.289967
  validation accuracy:		91.52 %
Epoch 236 of 2000 took 0.057s
  training loss:		0.177278
  validation loss:		0.278836
  validation accuracy:		91.63 %
Epoch 237 of 2000 took 0.058s
  training loss:		0.173029
  validation loss:		0.278985
  validation accuracy:		91.52 %
Epoch 238 of 2000 took 0.057s
  training loss:		0.172148
  validation loss:		0.275622
  validation accuracy:		91.74 %
Epoch 239 of 2000 took 0.057s
  training loss:		0.173975
  validation loss:		0.284352
  validation accuracy:		90.54 %
Epoch 240 of 2000 took 0.058s
  training loss:		0.179024
  validation loss:		0.271806
  validation accuracy:		91.96 %
Epoch 241 of 2000 took 0.057s
  training loss:		0.174300
  validation loss:		0.277992
  validation accuracy:		91.63 %
Epoch 242 of 2000 took 0.057s
  training loss:		0.176190
  validation loss:		0.277827
  validation accuracy:		91.96 %
Epoch 243 of 2000 took 0.057s
  training loss:		0.170804
  validation loss:		0.300885
  validation accuracy:		90.87 %
Epoch 244 of 2000 took 0.057s
  training loss:		0.172080
  validation loss:		0.289517
  validation accuracy:		90.98 %
Epoch 245 of 2000 took 0.058s
  training loss:		0.170913
  validation loss:		0.274186
  validation accuracy:		91.52 %
Epoch 246 of 2000 took 0.057s
  training loss:		0.172988
  validation loss:		0.279341
  validation accuracy:		91.52 %
Epoch 247 of 2000 took 0.057s
  training loss:		0.170828
  validation loss:		0.285617
  validation accuracy:		91.30 %
Epoch 248 of 2000 took 0.057s
  training loss:		0.170699
  validation loss:		0.282520
  validation accuracy:		91.52 %
Epoch 249 of 2000 took 0.058s
  training loss:		0.171712
  validation loss:		0.280505
  validation accuracy:		91.41 %
Epoch 250 of 2000 took 0.057s
  training loss:		0.172576
  validation loss:		0.293596
  validation accuracy:		91.09 %
Epoch 251 of 2000 took 0.057s
  training loss:		0.172217
  validation loss:		0.287438
  validation accuracy:		91.41 %
Epoch 252 of 2000 took 0.057s
  training loss:		0.169002
  validation loss:		0.287376
  validation accuracy:		91.63 %
Epoch 253 of 2000 took 0.057s
  training loss:		0.165320
  validation loss:		0.282592
  validation accuracy:		91.41 %
Epoch 254 of 2000 took 0.080s
  training loss:		0.172377
  validation loss:		0.280482
  validation accuracy:		91.74 %
Epoch 255 of 2000 took 0.066s
  training loss:		0.174090
  validation loss:		0.277224
  validation accuracy:		91.52 %
Epoch 256 of 2000 took 0.063s
  training loss:		0.169927
  validation loss:		0.288948
  validation accuracy:		90.76 %
Epoch 257 of 2000 took 0.064s
  training loss:		0.168519
  validation loss:		0.276439
  validation accuracy:		91.74 %
Epoch 258 of 2000 took 0.064s
  training loss:		0.164443
  validation loss:		0.280782
  validation accuracy:		91.63 %
Epoch 259 of 2000 took 0.063s
  training loss:		0.165439
  validation loss:		0.283400
  validation accuracy:		91.63 %
Epoch 260 of 2000 took 0.064s
  training loss:		0.169566
  validation loss:		0.287465
  validation accuracy:		91.20 %
Epoch 261 of 2000 took 0.064s
  training loss:		0.163909
  validation loss:		0.282360
  validation accuracy:		91.52 %
Epoch 262 of 2000 took 0.064s
  training loss:		0.163478
  validation loss:		0.274336
  validation accuracy:		92.28 %
Epoch 263 of 2000 took 0.064s
  training loss:		0.166891
  validation loss:		0.285190
  validation accuracy:		91.20 %
Epoch 264 of 2000 took 0.065s
  training loss:		0.164957
  validation loss:		0.282298
  validation accuracy:		91.52 %
Epoch 265 of 2000 took 0.063s
  training loss:		0.165797
  validation loss:		0.288971
  validation accuracy:		90.87 %
Epoch 266 of 2000 took 0.059s
  training loss:		0.159214
  validation loss:		0.278210
  validation accuracy:		91.41 %
Epoch 267 of 2000 took 0.059s
  training loss:		0.165576
  validation loss:		0.276354
  validation accuracy:		91.96 %
Epoch 268 of 2000 took 0.059s
  training loss:		0.162419
  validation loss:		0.273471
  validation accuracy:		91.63 %
Epoch 269 of 2000 took 0.059s
  training loss:		0.165799
  validation loss:		0.277577
  validation accuracy:		91.41 %
Epoch 270 of 2000 took 0.059s
  training loss:		0.160498
  validation loss:		0.278554
  validation accuracy:		91.52 %
Epoch 271 of 2000 took 0.059s
  training loss:		0.161776
  validation loss:		0.277912
  validation accuracy:		91.63 %
Epoch 272 of 2000 took 0.059s
  training loss:		0.161057
  validation loss:		0.278418
  validation accuracy:		90.98 %
Epoch 273 of 2000 took 0.059s
  training loss:		0.159287
  validation loss:		0.283720
  validation accuracy:		91.41 %
Epoch 274 of 2000 took 0.059s
  training loss:		0.163503
  validation loss:		0.285896
  validation accuracy:		91.41 %
Epoch 275 of 2000 took 0.059s
  training loss:		0.162326
  validation loss:		0.285282
  validation accuracy:		91.20 %
Epoch 276 of 2000 took 0.059s
  training loss:		0.160672
  validation loss:		0.278927
  validation accuracy:		92.17 %
Epoch 277 of 2000 took 0.059s
  training loss:		0.161509
  validation loss:		0.280113
  validation accuracy:		91.52 %
Epoch 278 of 2000 took 0.058s
  training loss:		0.157529
  validation loss:		0.294255
  validation accuracy:		90.76 %
Epoch 279 of 2000 took 0.059s
  training loss:		0.163379
  validation loss:		0.281902
  validation accuracy:		91.20 %
Epoch 280 of 2000 took 0.058s
  training loss:		0.159669
  validation loss:		0.276629
  validation accuracy:		91.96 %
Epoch 281 of 2000 took 0.059s
  training loss:		0.155259
  validation loss:		0.282523
  validation accuracy:		91.41 %
Epoch 282 of 2000 took 0.059s
  training loss:		0.154158
  validation loss:		0.282626
  validation accuracy:		91.52 %
Epoch 283 of 2000 took 0.059s
  training loss:		0.159132
  validation loss:		0.278649
  validation accuracy:		91.74 %
Epoch 284 of 2000 took 0.060s
  training loss:		0.158115
  validation loss:		0.282676
  validation accuracy:		90.87 %
Epoch 285 of 2000 took 0.059s
  training loss:		0.156497
  validation loss:		0.280364
  validation accuracy:		91.20 %
Epoch 286 of 2000 took 0.058s
  training loss:		0.159443
  validation loss:		0.298070
  validation accuracy:		90.98 %
Epoch 287 of 2000 took 0.058s
  training loss:		0.158546
  validation loss:		0.286705
  validation accuracy:		91.52 %
Epoch 288 of 2000 took 0.058s
  training loss:		0.158451
  validation loss:		0.283967
  validation accuracy:		91.20 %
Epoch 289 of 2000 took 0.058s
  training loss:		0.155922
  validation loss:		0.276071
  validation accuracy:		91.85 %
Epoch 290 of 2000 took 0.058s
  training loss:		0.156538
  validation loss:		0.283236
  validation accuracy:		91.85 %
Epoch 291 of 2000 took 0.058s
  training loss:		0.158251
  validation loss:		0.279429
  validation accuracy:		91.85 %
Epoch 292 of 2000 took 0.058s
  training loss:		0.158218
  validation loss:		0.282851
  validation accuracy:		91.63 %
Epoch 293 of 2000 took 0.059s
  training loss:		0.156216
  validation loss:		0.294436
  validation accuracy:		91.41 %
Epoch 294 of 2000 took 0.058s
  training loss:		0.155412
  validation loss:		0.282465
  validation accuracy:		91.85 %
Epoch 295 of 2000 took 0.059s
  training loss:		0.151791
  validation loss:		0.284528
  validation accuracy:		90.87 %
Epoch 296 of 2000 took 0.058s
  training loss:		0.156581
  validation loss:		0.280181
  validation accuracy:		91.74 %
Epoch 297 of 2000 took 0.059s
  training loss:		0.154496
  validation loss:		0.280540
  validation accuracy:		91.41 %
Epoch 298 of 2000 took 0.059s
  training loss:		0.155922
  validation loss:		0.285793
  validation accuracy:		92.17 %
Epoch 299 of 2000 took 0.059s
  training loss:		0.154205
  validation loss:		0.288660
  validation accuracy:		91.41 %
Epoch 300 of 2000 took 0.058s
  training loss:		0.153265
  validation loss:		0.281491
  validation accuracy:		91.20 %
Epoch 301 of 2000 took 0.058s
  training loss:		0.150411
  validation loss:		0.282541
  validation accuracy:		91.30 %
Epoch 302 of 2000 took 0.058s
  training loss:		0.156005
  validation loss:		0.280514
  validation accuracy:		91.41 %
Epoch 303 of 2000 took 0.058s
  training loss:		0.153051
  validation loss:		0.290174
  validation accuracy:		91.30 %
Epoch 304 of 2000 took 0.059s
  training loss:		0.154326
  validation loss:		0.278173
  validation accuracy:		91.85 %
Epoch 305 of 2000 took 0.058s
  training loss:		0.153530
  validation loss:		0.287402
  validation accuracy:		91.63 %
Epoch 306 of 2000 took 0.058s
  training loss:		0.147478
  validation loss:		0.279530
  validation accuracy:		92.28 %
Epoch 307 of 2000 took 0.059s
  training loss:		0.151339
  validation loss:		0.289410
  validation accuracy:		91.74 %
Epoch 308 of 2000 took 0.059s
  training loss:		0.151144
  validation loss:		0.292567
  validation accuracy:		91.52 %
Epoch 309 of 2000 took 0.058s
  training loss:		0.148378
  validation loss:		0.306529
  validation accuracy:		90.87 %
Epoch 310 of 2000 took 0.058s
  training loss:		0.153253
  validation loss:		0.283306
  validation accuracy:		91.09 %
Epoch 311 of 2000 took 0.058s
  training loss:		0.145447
  validation loss:		0.282851
  validation accuracy:		91.30 %
Epoch 312 of 2000 took 0.058s
  training loss:		0.154884
  validation loss:		0.286811
  validation accuracy:		91.41 %
Epoch 313 of 2000 took 0.058s
  training loss:		0.148900
  validation loss:		0.280515
  validation accuracy:		91.63 %
Epoch 314 of 2000 took 0.057s
  training loss:		0.147389
  validation loss:		0.286689
  validation accuracy:		91.41 %
Epoch 315 of 2000 took 0.059s
  training loss:		0.152599
  validation loss:		0.286663
  validation accuracy:		91.30 %
Epoch 316 of 2000 took 0.059s
  training loss:		0.144554
  validation loss:		0.279236
  validation accuracy:		91.74 %
Epoch 317 of 2000 took 0.058s
  training loss:		0.148452
  validation loss:		0.281175
  validation accuracy:		91.30 %
Epoch 318 of 2000 took 0.058s
  training loss:		0.147792
  validation loss:		0.294690
  validation accuracy:		91.41 %
Epoch 319 of 2000 took 0.059s
  training loss:		0.147586
  validation loss:		0.285169
  validation accuracy:		91.74 %
Epoch 320 of 2000 took 0.058s
  training loss:		0.148403
  validation loss:		0.289608
  validation accuracy:		91.20 %
Epoch 321 of 2000 took 0.058s
  training loss:		0.148135
  validation loss:		0.275398
  validation accuracy:		91.85 %
Epoch 322 of 2000 took 0.059s
  training loss:		0.146122
  validation loss:		0.279450
  validation accuracy:		91.41 %
Epoch 323 of 2000 took 0.059s
  training loss:		0.145078
  validation loss:		0.292290
  validation accuracy:		91.30 %
Epoch 324 of 2000 took 0.059s
  training loss:		0.145317
  validation loss:		0.284678
  validation accuracy:		91.52 %
Epoch 325 of 2000 took 0.059s
  training loss:		0.141645
  validation loss:		0.282523
  validation accuracy:		91.85 %
Epoch 326 of 2000 took 0.058s
  training loss:		0.143866
  validation loss:		0.286246
  validation accuracy:		91.09 %
Epoch 327 of 2000 took 0.058s
  training loss:		0.142146
  validation loss:		0.289764
  validation accuracy:		91.63 %
Epoch 328 of 2000 took 0.058s
  training loss:		0.144115
  validation loss:		0.280047
  validation accuracy:		91.52 %
Epoch 329 of 2000 took 0.058s
  training loss:		0.143883
  validation loss:		0.289747
  validation accuracy:		91.20 %
Epoch 330 of 2000 took 0.058s
  training loss:		0.143051
  validation loss:		0.290997
  validation accuracy:		91.09 %
Epoch 331 of 2000 took 0.059s
  training loss:		0.142098
  validation loss:		0.286249
  validation accuracy:		90.87 %
Epoch 332 of 2000 took 0.058s
  training loss:		0.148574
  validation loss:		0.293900
  validation accuracy:		91.85 %
Epoch 333 of 2000 took 0.059s
  training loss:		0.142595
  validation loss:		0.278439
  validation accuracy:		91.85 %
Epoch 334 of 2000 took 0.058s
  training loss:		0.142700
  validation loss:		0.280264
  validation accuracy:		91.85 %
Epoch 335 of 2000 took 0.058s
  training loss:		0.143881
  validation loss:		0.297808
  validation accuracy:		91.52 %
Epoch 336 of 2000 took 0.058s
  training loss:		0.143594
  validation loss:		0.287469
  validation accuracy:		91.85 %
Epoch 337 of 2000 took 0.058s
  training loss:		0.141746
  validation loss:		0.285012
  validation accuracy:		91.52 %
Epoch 338 of 2000 took 0.058s
  training loss:		0.139894
  validation loss:		0.284480
  validation accuracy:		92.28 %
Epoch 339 of 2000 took 0.058s
  training loss:		0.140506
  validation loss:		0.293404
  validation accuracy:		91.52 %
Epoch 340 of 2000 took 0.058s
  training loss:		0.140134
  validation loss:		0.284432
  validation accuracy:		91.96 %
Epoch 341 of 2000 took 0.058s
  training loss:		0.140012
  validation loss:		0.279991
  validation accuracy:		92.07 %
Epoch 342 of 2000 took 0.059s
  training loss:		0.142429
  validation loss:		0.280901
  validation accuracy:		91.85 %
Epoch 343 of 2000 took 0.059s
  training loss:		0.141080
  validation loss:		0.286562
  validation accuracy:		91.09 %
Epoch 344 of 2000 took 0.058s
  training loss:		0.135988
  validation loss:		0.292060
  validation accuracy:		91.74 %
Epoch 345 of 2000 took 0.058s
  training loss:		0.138127
  validation loss:		0.289774
  validation accuracy:		91.41 %
Epoch 346 of 2000 took 0.058s
  training loss:		0.139744
  validation loss:		0.293259
  validation accuracy:		91.96 %
Epoch 347 of 2000 took 0.067s
  training loss:		0.138247
  validation loss:		0.297600
  validation accuracy:		91.20 %
Epoch 348 of 2000 took 0.059s
  training loss:		0.142003
  validation loss:		0.293907
  validation accuracy:		91.52 %
Epoch 349 of 2000 took 0.059s
  training loss:		0.138079
  validation loss:		0.295894
  validation accuracy:		91.85 %
Epoch 350 of 2000 took 0.060s
  training loss:		0.137147
  validation loss:		0.281158
  validation accuracy:		92.17 %
Epoch 351 of 2000 took 0.059s
  training loss:		0.134075
  validation loss:		0.290028
  validation accuracy:		91.30 %
Epoch 352 of 2000 took 0.058s
  training loss:		0.136983
  validation loss:		0.280710
  validation accuracy:		91.52 %
Epoch 353 of 2000 took 0.060s
  training loss:		0.134436
  validation loss:		0.282361
  validation accuracy:		91.30 %
Epoch 354 of 2000 took 0.059s
  training loss:		0.134483
  validation loss:		0.306379
  validation accuracy:		90.76 %
Epoch 355 of 2000 took 0.059s
  training loss:		0.134339
  validation loss:		0.286182
  validation accuracy:		91.52 %
Epoch 356 of 2000 took 0.059s
  training loss:		0.135900
  validation loss:		0.289383
  validation accuracy:		91.52 %
Epoch 357 of 2000 took 0.059s
  training loss:		0.135380
  validation loss:		0.283655
  validation accuracy:		91.41 %
Epoch 358 of 2000 took 0.060s
  training loss:		0.135438
  validation loss:		0.284874
  validation accuracy:		91.63 %
Epoch 359 of 2000 took 0.059s
  training loss:		0.136819
  validation loss:		0.287411
  validation accuracy:		91.41 %
Epoch 360 of 2000 took 0.059s
  training loss:		0.134036
  validation loss:		0.293654
  validation accuracy:		91.52 %
Epoch 361 of 2000 took 0.059s
  training loss:		0.136344
  validation loss:		0.287957
  validation accuracy:		91.41 %
Epoch 362 of 2000 took 0.059s
  training loss:		0.136133
  validation loss:		0.294142
  validation accuracy:		90.87 %
Epoch 363 of 2000 took 0.059s
  training loss:		0.133232
  validation loss:		0.305143
  validation accuracy:		90.76 %
Epoch 364 of 2000 took 0.059s
  training loss:		0.134751
  validation loss:		0.282020
  validation accuracy:		92.07 %
Epoch 365 of 2000 took 0.059s
  training loss:		0.131760
  validation loss:		0.288272
  validation accuracy:		91.85 %
Epoch 366 of 2000 took 0.059s
  training loss:		0.127859
  validation loss:		0.286926
  validation accuracy:		92.17 %
Epoch 367 of 2000 took 0.059s
  training loss:		0.132730
  validation loss:		0.288890
  validation accuracy:		91.96 %
Epoch 368 of 2000 took 0.059s
  training loss:		0.135640
  validation loss:		0.295840
  validation accuracy:		91.63 %
Epoch 369 of 2000 took 0.059s
  training loss:		0.128517
  validation loss:		0.318024
  validation accuracy:		90.98 %
Epoch 370 of 2000 took 0.059s
  training loss:		0.130990
  validation loss:		0.289901
  validation accuracy:		91.20 %
Epoch 371 of 2000 took 0.059s
  training loss:		0.127216
  validation loss:		0.284965
  validation accuracy:		91.63 %
Epoch 372 of 2000 took 0.059s
  training loss:		0.131168
  validation loss:		0.282551
  validation accuracy:		91.41 %
Epoch 373 of 2000 took 0.059s
  training loss:		0.128743
  validation loss:		0.285909
  validation accuracy:		91.96 %
Epoch 374 of 2000 took 0.059s
  training loss:		0.131745
  validation loss:		0.288907
  validation accuracy:		91.85 %
Epoch 375 of 2000 took 0.059s
  training loss:		0.130020
  validation loss:		0.291465
  validation accuracy:		91.63 %
Epoch 376 of 2000 took 0.059s
  training loss:		0.131804
  validation loss:		0.288644
  validation accuracy:		91.41 %
Epoch 377 of 2000 took 0.058s
  training loss:		0.124075
  validation loss:		0.284836
  validation accuracy:		91.20 %
Epoch 378 of 2000 took 0.059s
  training loss:		0.128166
  validation loss:		0.282596
  validation accuracy:		92.17 %
Epoch 379 of 2000 took 0.059s
  training loss:		0.127364
  validation loss:		0.299138
  validation accuracy:		91.20 %
Epoch 380 of 2000 took 0.059s
  training loss:		0.130554
  validation loss:		0.289744
  validation accuracy:		91.41 %
Epoch 381 of 2000 took 0.059s
  training loss:		0.128643
  validation loss:		0.290224
  validation accuracy:		91.63 %
Epoch 382 of 2000 took 0.059s
  training loss:		0.126547
  validation loss:		0.289514
  validation accuracy:		91.09 %
Epoch 383 of 2000 took 0.059s
  training loss:		0.122244
  validation loss:		0.305448
  validation accuracy:		90.87 %
Epoch 384 of 2000 took 0.059s
  training loss:		0.128450
  validation loss:		0.294155
  validation accuracy:		91.52 %
Epoch 385 of 2000 took 0.059s
  training loss:		0.122815
  validation loss:		0.290857
  validation accuracy:		91.52 %
Epoch 386 of 2000 took 0.059s
  training loss:		0.124908
  validation loss:		0.280615
  validation accuracy:		91.63 %
Epoch 387 of 2000 took 0.059s
  training loss:		0.124455
  validation loss:		0.283861
  validation accuracy:		91.52 %
Epoch 388 of 2000 took 0.059s
  training loss:		0.123221
  validation loss:		0.283840
  validation accuracy:		91.41 %
Epoch 389 of 2000 took 0.059s
  training loss:		0.124885
  validation loss:		0.279342
  validation accuracy:		91.41 %
Epoch 390 of 2000 took 0.061s
  training loss:		0.126279
  validation loss:		0.290430
  validation accuracy:		91.74 %
Epoch 391 of 2000 took 0.059s
  training loss:		0.124109
  validation loss:		0.294505
  validation accuracy:		90.87 %
Epoch 392 of 2000 took 0.059s
  training loss:		0.125314
  validation loss:		0.292533
  validation accuracy:		91.96 %
Epoch 393 of 2000 took 0.059s
  training loss:		0.122767
  validation loss:		0.288836
  validation accuracy:		91.09 %
Epoch 394 of 2000 took 0.059s
  training loss:		0.120729
  validation loss:		0.297302
  validation accuracy:		90.87 %
Epoch 395 of 2000 took 0.059s
  training loss:		0.124236
  validation loss:		0.283549
  validation accuracy:		91.74 %
Epoch 396 of 2000 took 0.059s
  training loss:		0.122359
  validation loss:		0.290044
  validation accuracy:		91.41 %
Epoch 397 of 2000 took 0.059s
  training loss:		0.122413
  validation loss:		0.287091
  validation accuracy:		91.20 %
Epoch 398 of 2000 took 0.059s
  training loss:		0.120136
  validation loss:		0.300315
  validation accuracy:		90.76 %
Epoch 399 of 2000 took 0.059s
  training loss:		0.120456
  validation loss:		0.289142
  validation accuracy:		91.74 %
Epoch 400 of 2000 took 0.059s
  training loss:		0.119356
  validation loss:		0.286321
  validation accuracy:		91.74 %
Epoch 401 of 2000 took 0.059s
  training loss:		0.121059
  validation loss:		0.298169
  validation accuracy:		90.98 %
Epoch 402 of 2000 took 0.059s
  training loss:		0.125167
  validation loss:		0.285624
  validation accuracy:		91.96 %
Epoch 403 of 2000 took 0.059s
  training loss:		0.124357
  validation loss:		0.303136
  validation accuracy:		90.98 %
Epoch 404 of 2000 took 0.059s
  training loss:		0.116295
  validation loss:		0.287245
  validation accuracy:		91.41 %
Epoch 405 of 2000 took 0.059s
  training loss:		0.116803
  validation loss:		0.282591
  validation accuracy:		92.17 %
Epoch 406 of 2000 took 0.059s
  training loss:		0.119692
  validation loss:		0.286632
  validation accuracy:		91.41 %
Epoch 407 of 2000 took 0.059s
  training loss:		0.114580
  validation loss:		0.283621
  validation accuracy:		91.63 %
Epoch 408 of 2000 took 0.059s
  training loss:		0.115659
  validation loss:		0.292748
  validation accuracy:		91.20 %
Epoch 409 of 2000 took 0.059s
  training loss:		0.121118
  validation loss:		0.292867
  validation accuracy:		91.85 %
Epoch 410 of 2000 took 0.059s
  training loss:		0.118426
  validation loss:		0.318561
  validation accuracy:		91.20 %
Epoch 411 of 2000 took 0.059s
  training loss:		0.118424
  validation loss:		0.291898
  validation accuracy:		91.41 %
Epoch 412 of 2000 took 0.059s
  training loss:		0.116607
  validation loss:		0.293147
  validation accuracy:		91.30 %
Epoch 413 of 2000 took 0.059s
  training loss:		0.116611
  validation loss:		0.285553
  validation accuracy:		91.85 %
Epoch 414 of 2000 took 0.059s
  training loss:		0.113687
  validation loss:		0.290567
  validation accuracy:		91.52 %
Epoch 415 of 2000 took 0.059s
  training loss:		0.117915
  validation loss:		0.281723
  validation accuracy:		91.74 %
Epoch 416 of 2000 took 0.059s
  training loss:		0.115654
  validation loss:		0.296840
  validation accuracy:		91.85 %
Epoch 417 of 2000 took 0.059s
  training loss:		0.116124
  validation loss:		0.290323
  validation accuracy:		91.09 %
Epoch 418 of 2000 took 0.058s
  training loss:		0.115643
  validation loss:		0.295295
  validation accuracy:		91.41 %
Epoch 419 of 2000 took 0.058s
  training loss:		0.114931
  validation loss:		0.281083
  validation accuracy:		91.85 %
Epoch 420 of 2000 took 0.057s
  training loss:		0.110961
  validation loss:		0.286965
  validation accuracy:		91.41 %
Epoch 421 of 2000 took 0.057s
  training loss:		0.114802
  validation loss:		0.287183
  validation accuracy:		91.20 %
Epoch 422 of 2000 took 0.058s
  training loss:		0.111029
  validation loss:		0.292917
  validation accuracy:		91.41 %
Epoch 423 of 2000 took 0.058s
  training loss:		0.111524
  validation loss:		0.287901
  validation accuracy:		91.96 %
Epoch 424 of 2000 took 0.058s
  training loss:		0.110224
  validation loss:		0.296126
  validation accuracy:		91.20 %
Epoch 425 of 2000 took 0.057s
  training loss:		0.113884
  validation loss:		0.309455
  validation accuracy:		90.76 %
Epoch 426 of 2000 took 0.057s
  training loss:		0.118993
  validation loss:		0.286690
  validation accuracy:		91.74 %
Epoch 427 of 2000 took 0.057s
  training loss:		0.112381
  validation loss:		0.289305
  validation accuracy:		91.09 %
Epoch 428 of 2000 took 0.057s
  training loss:		0.112972
  validation loss:		0.283858
  validation accuracy:		91.52 %
Epoch 429 of 2000 took 0.057s
  training loss:		0.108804
  validation loss:		0.284979
  validation accuracy:		91.41 %
Epoch 430 of 2000 took 0.057s
  training loss:		0.111869
  validation loss:		0.295760
  validation accuracy:		91.30 %
Epoch 431 of 2000 took 0.058s
  training loss:		0.111912
  validation loss:		0.282262
  validation accuracy:		91.85 %
Epoch 432 of 2000 took 0.057s
  training loss:		0.108401
  validation loss:		0.287315
  validation accuracy:		91.41 %
Epoch 433 of 2000 took 0.057s
  training loss:		0.111367
  validation loss:		0.292376
  validation accuracy:		91.52 %
Epoch 434 of 2000 took 0.057s
  training loss:		0.112434
  validation loss:		0.287232
  validation accuracy:		91.09 %
Epoch 435 of 2000 took 0.058s
  training loss:		0.108500
  validation loss:		0.306956
  validation accuracy:		90.98 %
Epoch 436 of 2000 took 0.057s
  training loss:		0.112671
  validation loss:		0.298700
  validation accuracy:		91.09 %
Epoch 437 of 2000 took 0.056s
  training loss:		0.110203
  validation loss:		0.296548
  validation accuracy:		90.98 %
Epoch 438 of 2000 took 0.058s
  training loss:		0.106051
  validation loss:		0.285369
  validation accuracy:		91.41 %
Epoch 439 of 2000 took 0.057s
  training loss:		0.110981
  validation loss:		0.293826
  validation accuracy:		91.30 %
Epoch 440 of 2000 took 0.058s
  training loss:		0.107925
  validation loss:		0.304934
  validation accuracy:		90.87 %
Epoch 441 of 2000 took 0.058s
  training loss:		0.106783
  validation loss:		0.295731
  validation accuracy:		91.09 %
Epoch 442 of 2000 took 0.057s
  training loss:		0.107515
  validation loss:		0.294087
  validation accuracy:		91.30 %
Epoch 443 of 2000 took 0.066s
  training loss:		0.103181
  validation loss:		0.281755
  validation accuracy:		92.07 %
Epoch 444 of 2000 took 0.057s
  training loss:		0.108849
  validation loss:		0.289771
  validation accuracy:		91.52 %
Epoch 445 of 2000 took 0.057s
  training loss:		0.105025
  validation loss:		0.303282
  validation accuracy:		91.09 %
Epoch 446 of 2000 took 0.058s
  training loss:		0.106408
  validation loss:		0.292609
  validation accuracy:		91.09 %
Epoch 447 of 2000 took 0.057s
  training loss:		0.106526
  validation loss:		0.300020
  validation accuracy:		91.52 %
Epoch 448 of 2000 took 0.057s
  training loss:		0.106906
  validation loss:		0.285852
  validation accuracy:		91.85 %
Epoch 449 of 2000 took 0.057s
  training loss:		0.108768
  validation loss:		0.296917
  validation accuracy:		91.30 %
Epoch 450 of 2000 took 0.056s
  training loss:		0.105285
  validation loss:		0.296649
  validation accuracy:		91.30 %
Epoch 451 of 2000 took 0.057s
  training loss:		0.106787
  validation loss:		0.297953
  validation accuracy:		91.52 %
Epoch 452 of 2000 took 0.057s
  training loss:		0.109329
  validation loss:		0.288980
  validation accuracy:		91.41 %
Epoch 453 of 2000 took 0.056s
  training loss:		0.098935
  validation loss:		0.283709
  validation accuracy:		92.17 %
Epoch 454 of 2000 took 0.056s
  training loss:		0.101299
  validation loss:		0.295767
  validation accuracy:		91.09 %
Epoch 455 of 2000 took 0.056s
  training loss:		0.106510
  validation loss:		0.291798
  validation accuracy:		91.20 %
Epoch 456 of 2000 took 0.057s
  training loss:		0.099878
  validation loss:		0.291607
  validation accuracy:		90.98 %
Epoch 457 of 2000 took 0.056s
  training loss:		0.102866
  validation loss:		0.292347
  validation accuracy:		91.52 %
Epoch 458 of 2000 took 0.055s
  training loss:		0.103497
  validation loss:		0.290008
  validation accuracy:		91.52 %
Epoch 459 of 2000 took 0.056s
  training loss:		0.100287
  validation loss:		0.289064
  validation accuracy:		92.07 %
Epoch 460 of 2000 took 0.057s
  training loss:		0.102891
  validation loss:		0.299235
  validation accuracy:		90.65 %
Epoch 461 of 2000 took 0.054s
  training loss:		0.104714
  validation loss:		0.307476
  validation accuracy:		90.87 %
Epoch 462 of 2000 took 0.056s
  training loss:		0.103255
  validation loss:		0.288828
  validation accuracy:		91.63 %
Epoch 463 of 2000 took 0.058s
  training loss:		0.100941
  validation loss:		0.306050
  validation accuracy:		90.65 %
Epoch 464 of 2000 took 0.058s
  training loss:		0.102906
  validation loss:		0.290652
  validation accuracy:		91.52 %
Epoch 465 of 2000 took 0.058s
  training loss:		0.097246
  validation loss:		0.289477
  validation accuracy:		91.52 %
Epoch 466 of 2000 took 0.057s
  training loss:		0.101797
  validation loss:		0.292063
  validation accuracy:		91.52 %
Epoch 467 of 2000 took 0.056s
  training loss:		0.100927
  validation loss:		0.289135
  validation accuracy:		92.07 %
Epoch 468 of 2000 took 0.054s
  training loss:		0.097143
  validation loss:		0.293230
  validation accuracy:		91.41 %
Epoch 469 of 2000 took 0.056s
  training loss:		0.095464
  validation loss:		0.296161
  validation accuracy:		91.30 %
Epoch 470 of 2000 took 0.058s
  training loss:		0.096024
  validation loss:		0.290307
  validation accuracy:		91.41 %
Epoch 471 of 2000 took 0.058s
  training loss:		0.099092
  validation loss:		0.291736
  validation accuracy:		92.07 %
Epoch 472 of 2000 took 0.058s
  training loss:		0.096817
  validation loss:		0.296013
  validation accuracy:		91.41 %
Epoch 473 of 2000 took 0.058s
  training loss:		0.095018
  validation loss:		0.300885
  validation accuracy:		91.09 %
Epoch 474 of 2000 took 0.058s
  training loss:		0.099256
  validation loss:		0.288693
  validation accuracy:		91.74 %
Epoch 475 of 2000 took 0.058s
  training loss:		0.099098
  validation loss:		0.302492
  validation accuracy:		90.98 %
Epoch 476 of 2000 took 0.058s
  training loss:		0.097129
  validation loss:		0.314820
  validation accuracy:		91.30 %
Epoch 477 of 2000 took 0.058s
  training loss:		0.095605
  validation loss:		0.285881
  validation accuracy:		92.28 %
Epoch 478 of 2000 took 0.057s
  training loss:		0.097225
  validation loss:		0.293411
  validation accuracy:		91.52 %
Epoch 479 of 2000 took 0.058s
  training loss:		0.094732
  validation loss:		0.287427
  validation accuracy:		91.96 %
Epoch 480 of 2000 took 0.058s
  training loss:		0.094114
  validation loss:		0.298316
  validation accuracy:		91.09 %
Epoch 481 of 2000 took 0.058s
  training loss:		0.098019
  validation loss:		0.296920
  validation accuracy:		91.63 %
Epoch 482 of 2000 took 0.058s
  training loss:		0.097070
  validation loss:		0.292662
  validation accuracy:		91.41 %
Epoch 483 of 2000 took 0.058s
  training loss:		0.096922
  validation loss:		0.291201
  validation accuracy:		91.52 %
Epoch 484 of 2000 took 0.058s
  training loss:		0.096924
  validation loss:		0.288270
  validation accuracy:		91.96 %
Epoch 485 of 2000 took 0.058s
  training loss:		0.093703
  validation loss:		0.293527
  validation accuracy:		91.52 %
Epoch 486 of 2000 took 0.058s
  training loss:		0.093902
  validation loss:		0.292061
  validation accuracy:		92.17 %
Epoch 487 of 2000 took 0.058s
  training loss:		0.091785
  validation loss:		0.289421
  validation accuracy:		92.07 %
Epoch 488 of 2000 took 0.057s
  training loss:		0.095529
  validation loss:		0.290162
  validation accuracy:		91.52 %
Epoch 489 of 2000 took 0.057s
  training loss:		0.095526
  validation loss:		0.289233
  validation accuracy:		91.85 %
Epoch 490 of 2000 took 0.057s
  training loss:		0.092189
  validation loss:		0.300121
  validation accuracy:		91.30 %
Epoch 491 of 2000 took 0.057s
  training loss:		0.095611
  validation loss:		0.292507
  validation accuracy:		91.74 %
Epoch 492 of 2000 took 0.057s
  training loss:		0.093973
  validation loss:		0.306742
  validation accuracy:		90.98 %
Epoch 493 of 2000 took 0.057s
  training loss:		0.091168
  validation loss:		0.289735
  validation accuracy:		91.96 %
Epoch 494 of 2000 took 0.057s
  training loss:		0.093812
  validation loss:		0.290274
  validation accuracy:		91.52 %
Epoch 495 of 2000 took 0.057s
  training loss:		0.093218
  validation loss:		0.290418
  validation accuracy:		91.74 %
Epoch 496 of 2000 took 0.057s
  training loss:		0.092313
  validation loss:		0.294049
  validation accuracy:		91.85 %
Epoch 497 of 2000 took 0.058s
  training loss:		0.092990
  validation loss:		0.304711
  validation accuracy:		90.76 %
Epoch 498 of 2000 took 0.057s
  training loss:		0.090357
  validation loss:		0.297559
  validation accuracy:		91.74 %
Epoch 499 of 2000 took 0.058s
  training loss:		0.092423
  validation loss:		0.306351
  validation accuracy:		91.30 %
Epoch 500 of 2000 took 0.057s
  training loss:		0.089382
  validation loss:		0.299529
  validation accuracy:		91.74 %
Epoch 501 of 2000 took 0.058s
  training loss:		0.088810
  validation loss:		0.294304
  validation accuracy:		91.63 %
Epoch 502 of 2000 took 0.060s
  training loss:		0.090240
  validation loss:		0.292089
  validation accuracy:		91.85 %
Epoch 503 of 2000 took 0.055s
  training loss:		0.091454
  validation loss:		0.304903
  validation accuracy:		91.30 %
Epoch 504 of 2000 took 0.057s
  training loss:		0.091735
  validation loss:		0.301644
  validation accuracy:		91.41 %
Epoch 505 of 2000 took 0.058s
  training loss:		0.089745
  validation loss:		0.309193
  validation accuracy:		91.41 %
Epoch 506 of 2000 took 0.058s
  training loss:		0.091028
  validation loss:		0.300153
  validation accuracy:		91.41 %
Epoch 507 of 2000 took 0.058s
  training loss:		0.090771
  validation loss:		0.292785
  validation accuracy:		91.85 %
Epoch 508 of 2000 took 0.058s
  training loss:		0.089431
  validation loss:		0.325434
  validation accuracy:		91.30 %
Epoch 509 of 2000 took 0.058s
  training loss:		0.093264
  validation loss:		0.291803
  validation accuracy:		91.85 %
Epoch 510 of 2000 took 0.058s
  training loss:		0.089199
  validation loss:		0.300396
  validation accuracy:		92.17 %
Epoch 511 of 2000 took 0.057s
  training loss:		0.087777
  validation loss:		0.296763
  validation accuracy:		92.07 %
Epoch 512 of 2000 took 0.057s
  training loss:		0.087113
  validation loss:		0.294218
  validation accuracy:		91.09 %
Epoch 513 of 2000 took 0.057s
  training loss:		0.088437
  validation loss:		0.288780
  validation accuracy:		92.07 %
Epoch 514 of 2000 took 0.057s
  training loss:		0.086965
  validation loss:		0.304551
  validation accuracy:		91.41 %
Epoch 515 of 2000 took 0.058s
  training loss:		0.086248
  validation loss:		0.289706
  validation accuracy:		91.96 %
Epoch 516 of 2000 took 0.057s
  training loss:		0.085848
  validation loss:		0.295049
  validation accuracy:		91.52 %
Epoch 517 of 2000 took 0.057s
  training loss:		0.086830
  validation loss:		0.297958
  validation accuracy:		92.07 %
Epoch 518 of 2000 took 0.057s
  training loss:		0.088241
  validation loss:		0.290952
  validation accuracy:		92.07 %
Epoch 519 of 2000 took 0.060s
  training loss:		0.090171
  validation loss:		0.294122
  validation accuracy:		91.63 %
Epoch 520 of 2000 took 0.056s
  training loss:		0.086172
  validation loss:		0.297784
  validation accuracy:		91.63 %
Epoch 521 of 2000 took 0.055s
  training loss:		0.085178
  validation loss:		0.305280
  validation accuracy:		90.87 %
Epoch 522 of 2000 took 0.058s
  training loss:		0.085197
  validation loss:		0.298023
  validation accuracy:		92.07 %
Epoch 523 of 2000 took 0.058s
  training loss:		0.083731
  validation loss:		0.300200
  validation accuracy:		91.85 %
Epoch 524 of 2000 took 0.058s
  training loss:		0.086903
  validation loss:		0.301487
  validation accuracy:		91.30 %
Epoch 525 of 2000 took 0.058s
  training loss:		0.083544
  validation loss:		0.298527
  validation accuracy:		92.07 %
Epoch 526 of 2000 took 0.057s
  training loss:		0.083517
  validation loss:		0.312721
  validation accuracy:		91.20 %
Epoch 527 of 2000 took 0.057s
  training loss:		0.083885
  validation loss:		0.292470
  validation accuracy:		92.07 %
Epoch 528 of 2000 took 0.057s
  training loss:		0.085306
  validation loss:		0.299639
  validation accuracy:		91.74 %
Epoch 529 of 2000 took 0.058s
  training loss:		0.086157
  validation loss:		0.294853
  validation accuracy:		91.74 %
Epoch 530 of 2000 took 0.057s
  training loss:		0.086649
  validation loss:		0.299655
  validation accuracy:		91.41 %
Epoch 531 of 2000 took 0.057s
  training loss:		0.085350
  validation loss:		0.299164
  validation accuracy:		91.74 %
Epoch 532 of 2000 took 0.058s
  training loss:		0.084246
  validation loss:		0.309960
  validation accuracy:		90.98 %
Epoch 533 of 2000 took 0.057s
  training loss:		0.083654
  validation loss:		0.296093
  validation accuracy:		91.85 %
Epoch 534 of 2000 took 0.058s
  training loss:		0.081384
  validation loss:		0.292272
  validation accuracy:		92.07 %
Epoch 535 of 2000 took 0.057s
  training loss:		0.082415
  validation loss:		0.302652
  validation accuracy:		91.63 %
Epoch 536 of 2000 took 0.057s
  training loss:		0.081385
  validation loss:		0.315366
  validation accuracy:		90.87 %
Epoch 537 of 2000 took 0.058s
  training loss:		0.080456
  validation loss:		0.302382
  validation accuracy:		91.63 %
Epoch 538 of 2000 took 0.058s
  training loss:		0.084825
  validation loss:		0.298620
  validation accuracy:		91.85 %
Epoch 539 of 2000 took 0.058s
  training loss:		0.081682
  validation loss:		0.298781
  validation accuracy:		91.85 %
Epoch 540 of 2000 took 0.058s
  training loss:		0.081117
  validation loss:		0.307099
  validation accuracy:		91.09 %
Epoch 541 of 2000 took 0.058s
  training loss:		0.083802
  validation loss:		0.297722
  validation accuracy:		91.96 %
Epoch 542 of 2000 took 0.058s
  training loss:		0.078122
  validation loss:		0.315623
  validation accuracy:		90.98 %
Epoch 543 of 2000 took 0.058s
  training loss:		0.078974
  validation loss:		0.302994
  validation accuracy:		91.63 %
Epoch 544 of 2000 took 0.058s
  training loss:		0.084297
  validation loss:		0.298502
  validation accuracy:		91.52 %
Epoch 545 of 2000 took 0.058s
  training loss:		0.081153
  validation loss:		0.295888
  validation accuracy:		91.85 %
Epoch 546 of 2000 took 0.058s
  training loss:		0.080275
  validation loss:		0.305478
  validation accuracy:		91.30 %
Epoch 547 of 2000 took 0.058s
  training loss:		0.080937
  validation loss:		0.299717
  validation accuracy:		91.96 %
Epoch 548 of 2000 took 0.056s
  training loss:		0.078713
  validation loss:		0.311119
  validation accuracy:		91.41 %
Epoch 549 of 2000 took 0.057s
  training loss:		0.082449
  validation loss:		0.299685
  validation accuracy:		92.28 %
Epoch 550 of 2000 took 0.057s
  training loss:		0.079848
  validation loss:		0.295393
  validation accuracy:		91.74 %
Epoch 551 of 2000 took 0.057s
  training loss:		0.079308
  validation loss:		0.304969
  validation accuracy:		91.63 %
Epoch 552 of 2000 took 0.058s
  training loss:		0.080978
  validation loss:		0.295722
  validation accuracy:		92.28 %
Epoch 553 of 2000 took 0.058s
  training loss:		0.079801
  validation loss:		0.299685
  validation accuracy:		92.17 %
Epoch 554 of 2000 took 0.058s
  training loss:		0.076855
  validation loss:		0.305999
  validation accuracy:		91.96 %
Epoch 555 of 2000 took 0.057s
  training loss:		0.074688
  validation loss:		0.301972
  validation accuracy:		91.96 %
Epoch 556 of 2000 took 0.057s
  training loss:		0.077480
  validation loss:		0.301389
  validation accuracy:		92.17 %
Epoch 557 of 2000 took 0.058s
  training loss:		0.078571
  validation loss:		0.296328
  validation accuracy:		92.17 %
Epoch 558 of 2000 took 0.058s
  training loss:		0.076824
  validation loss:		0.311978
  validation accuracy:		91.41 %
Epoch 559 of 2000 took 0.058s
  training loss:		0.076990
  validation loss:		0.302035
  validation accuracy:		91.63 %
Epoch 560 of 2000 took 0.058s
  training loss:		0.081219
  validation loss:		0.295607
  validation accuracy:		92.39 %
Epoch 561 of 2000 took 0.058s
  training loss:		0.080869
  validation loss:		0.322807
  validation accuracy:		90.87 %
Epoch 562 of 2000 took 0.058s
  training loss:		0.079725
  validation loss:		0.311483
  validation accuracy:		91.20 %
Epoch 563 of 2000 took 0.058s
  training loss:		0.077039
  validation loss:		0.315788
  validation accuracy:		90.98 %
Epoch 564 of 2000 took 0.058s
  training loss:		0.075739
  validation loss:		0.303482
  validation accuracy:		91.96 %
Epoch 565 of 2000 took 0.058s
  training loss:		0.076939
  validation loss:		0.304869
  validation accuracy:		92.17 %
Epoch 566 of 2000 took 0.058s
  training loss:		0.073401
  validation loss:		0.305270
  validation accuracy:		91.74 %
Epoch 567 of 2000 took 0.058s
  training loss:		0.077362
  validation loss:		0.314749
  validation accuracy:		91.30 %
Epoch 568 of 2000 took 0.058s
  training loss:		0.075293
  validation loss:		0.302404
  validation accuracy:		91.74 %
Epoch 569 of 2000 took 0.058s
  training loss:		0.077422
  validation loss:		0.317712
  validation accuracy:		91.30 %
Epoch 570 of 2000 took 0.058s
  training loss:		0.076190
  validation loss:		0.301905
  validation accuracy:		92.07 %
Epoch 571 of 2000 took 0.057s
  training loss:		0.076347
  validation loss:		0.303621
  validation accuracy:		91.74 %
Epoch 572 of 2000 took 0.057s
  training loss:		0.073611
  validation loss:		0.311888
  validation accuracy:		91.41 %
Epoch 573 of 2000 took 0.057s
  training loss:		0.077083
  validation loss:		0.300936
  validation accuracy:		91.96 %
Epoch 574 of 2000 took 0.057s
  training loss:		0.076228
  validation loss:		0.307030
  validation accuracy:		91.96 %
Epoch 575 of 2000 took 0.057s
  training loss:		0.071373
  validation loss:		0.303365
  validation accuracy:		92.17 %
Epoch 576 of 2000 took 0.057s
  training loss:		0.077658
  validation loss:		0.320186
  validation accuracy:		90.87 %
Epoch 577 of 2000 took 0.057s
  training loss:		0.077818
  validation loss:		0.310842
  validation accuracy:		91.41 %
Epoch 578 of 2000 took 0.057s
  training loss:		0.074683
  validation loss:		0.303308
  validation accuracy:		92.17 %
Epoch 579 of 2000 took 0.057s
  training loss:		0.074176
  validation loss:		0.315737
  validation accuracy:		91.41 %
Epoch 580 of 2000 took 0.057s
  training loss:		0.073269
  validation loss:		0.310466
  validation accuracy:		91.30 %
Epoch 581 of 2000 took 0.057s
  training loss:		0.072577
  validation loss:		0.316519
  validation accuracy:		91.20 %
Epoch 582 of 2000 took 0.057s
  training loss:		0.072166
  validation loss:		0.299889
  validation accuracy:		92.39 %
Epoch 583 of 2000 took 0.057s
  training loss:		0.073952
  validation loss:		0.328408
  validation accuracy:		90.98 %
Epoch 584 of 2000 took 0.057s
  training loss:		0.076087
  validation loss:		0.320608
  validation accuracy:		90.87 %
Epoch 585 of 2000 took 0.057s
  training loss:		0.071985
  validation loss:		0.309744
  validation accuracy:		91.52 %
Epoch 586 of 2000 took 0.057s
  training loss:		0.075093
  validation loss:		0.303197
  validation accuracy:		91.85 %
Epoch 587 of 2000 took 0.057s
  training loss:		0.070792
  validation loss:		0.316401
  validation accuracy:		90.98 %
Epoch 588 of 2000 took 0.058s
  training loss:		0.074994
  validation loss:		0.319600
  validation accuracy:		91.74 %
Epoch 589 of 2000 took 0.058s
  training loss:		0.074975
  validation loss:		0.306084
  validation accuracy:		91.96 %
Epoch 590 of 2000 took 0.057s
  training loss:		0.070105
  validation loss:		0.304495
  validation accuracy:		92.17 %
Epoch 591 of 2000 took 0.057s
  training loss:		0.074356
  validation loss:		0.306866
  validation accuracy:		91.63 %
Epoch 592 of 2000 took 0.058s
  training loss:		0.072649
  validation loss:		0.325679
  validation accuracy:		91.09 %
Epoch 593 of 2000 took 0.058s
  training loss:		0.071466
  validation loss:		0.315156
  validation accuracy:		91.85 %
Epoch 594 of 2000 took 0.058s
  training loss:		0.068294
  validation loss:		0.300680
  validation accuracy:		92.28 %
Epoch 595 of 2000 took 0.058s
  training loss:		0.072347
  validation loss:		0.318224
  validation accuracy:		91.30 %
Epoch 596 of 2000 took 0.058s
  training loss:		0.068845
  validation loss:		0.320935
  validation accuracy:		91.20 %
Epoch 597 of 2000 took 0.058s
  training loss:		0.071016
  validation loss:		0.321881
  validation accuracy:		91.30 %
Epoch 598 of 2000 took 0.057s
  training loss:		0.071465
  validation loss:		0.310597
  validation accuracy:		92.07 %
Epoch 599 of 2000 took 0.057s
  training loss:		0.070111
  validation loss:		0.325079
  validation accuracy:		91.09 %
Epoch 600 of 2000 took 0.058s
  training loss:		0.071751
  validation loss:		0.311049
  validation accuracy:		91.85 %
Epoch 601 of 2000 took 0.057s
  training loss:		0.069244
  validation loss:		0.311771
  validation accuracy:		91.85 %
Epoch 602 of 2000 took 0.057s
  training loss:		0.071152
  validation loss:		0.311122
  validation accuracy:		91.74 %
Epoch 603 of 2000 took 0.057s
  training loss:		0.071040
  validation loss:		0.325799
  validation accuracy:		90.98 %
Epoch 604 of 2000 took 0.057s
  training loss:		0.068997
  validation loss:		0.310701
  validation accuracy:		91.85 %
Epoch 605 of 2000 took 0.057s
  training loss:		0.069771
  validation loss:		0.310081
  validation accuracy:		91.74 %
Epoch 606 of 2000 took 0.057s
  training loss:		0.069902
  validation loss:		0.311880
  validation accuracy:		91.85 %
Epoch 607 of 2000 took 0.057s
  training loss:		0.067655
  validation loss:		0.310182
  validation accuracy:		91.96 %
Epoch 608 of 2000 took 0.058s
  training loss:		0.072182
  validation loss:		0.319212
  validation accuracy:		91.63 %
Epoch 609 of 2000 took 0.057s
  training loss:		0.068513
  validation loss:		0.316524
  validation accuracy:		91.30 %
Epoch 610 of 2000 took 0.057s
  training loss:		0.069173
  validation loss:		0.307266
  validation accuracy:		91.74 %
Epoch 611 of 2000 took 0.058s
  training loss:		0.066051
  validation loss:		0.315320
  validation accuracy:		91.20 %
Epoch 612 of 2000 took 0.057s
  training loss:		0.066653
  validation loss:		0.329650
  validation accuracy:		90.76 %
Epoch 613 of 2000 took 0.057s
  training loss:		0.070192
  validation loss:		0.306345
  validation accuracy:		92.07 %
Epoch 614 of 2000 took 0.057s
  training loss:		0.070959
  validation loss:		0.316329
  validation accuracy:		92.07 %
Epoch 615 of 2000 took 0.057s
  training loss:		0.067042
  validation loss:		0.313248
  validation accuracy:		91.52 %
Epoch 616 of 2000 took 0.057s
  training loss:		0.066435
  validation loss:		0.317815
  validation accuracy:		91.63 %
Epoch 617 of 2000 took 0.057s
  training loss:		0.066456
  validation loss:		0.310145
  validation accuracy:		92.28 %
Epoch 618 of 2000 took 0.057s
  training loss:		0.066729
  validation loss:		0.316921
  validation accuracy:		91.52 %
Epoch 619 of 2000 took 0.057s
  training loss:		0.066747
  validation loss:		0.321113
  validation accuracy:		91.30 %
Epoch 620 of 2000 took 0.057s
  training loss:		0.064921
  validation loss:		0.322611
  validation accuracy:		91.30 %
Epoch 621 of 2000 took 0.057s
  training loss:		0.066846
  validation loss:		0.316555
  validation accuracy:		91.41 %
Epoch 622 of 2000 took 0.057s
  training loss:		0.069194
  validation loss:		0.318831
  validation accuracy:		91.85 %
Epoch 623 of 2000 took 0.057s
  training loss:		0.065177
  validation loss:		0.320241
  validation accuracy:		91.63 %
Epoch 624 of 2000 took 0.057s
  training loss:		0.067565
  validation loss:		0.311810
  validation accuracy:		91.96 %
Epoch 625 of 2000 took 0.057s
  training loss:		0.068253
  validation loss:		0.320212
  validation accuracy:		91.52 %
Epoch 626 of 2000 took 0.058s
  training loss:		0.067735
  validation loss:		0.310570
  validation accuracy:		92.07 %
Epoch 627 of 2000 took 0.058s
  training loss:		0.065167
  validation loss:		0.333618
  validation accuracy:		91.09 %
Epoch 628 of 2000 took 0.058s
  training loss:		0.070540
  validation loss:		0.323470
  validation accuracy:		91.74 %
Epoch 629 of 2000 took 0.058s
  training loss:		0.068266
  validation loss:		0.335543
  validation accuracy:		91.52 %
Epoch 630 of 2000 took 0.058s
  training loss:		0.068133
  validation loss:		0.321351
  validation accuracy:		91.30 %
Epoch 631 of 2000 took 0.058s
  training loss:		0.067100
  validation loss:		0.319217
  validation accuracy:		91.63 %
Epoch 632 of 2000 took 0.058s
  training loss:		0.064936
  validation loss:		0.310237
  validation accuracy:		92.07 %
Epoch 633 of 2000 took 0.058s
  training loss:		0.065249
  validation loss:		0.314736
  validation accuracy:		91.74 %
Epoch 634 of 2000 took 0.058s
  training loss:		0.066408
  validation loss:		0.326935
  validation accuracy:		91.20 %
Epoch 635 of 2000 took 0.058s
  training loss:		0.065781
  validation loss:		0.317191
  validation accuracy:		91.85 %
Epoch 636 of 2000 took 0.058s
  training loss:		0.064126
  validation loss:		0.321026
  validation accuracy:		91.52 %
Epoch 637 of 2000 took 0.058s
  training loss:		0.064085
  validation loss:		0.318747
  validation accuracy:		91.41 %
Epoch 638 of 2000 took 0.058s
  training loss:		0.064647
  validation loss:		0.317807
  validation accuracy:		91.74 %
Epoch 639 of 2000 took 0.058s
  training loss:		0.065493
  validation loss:		0.323492
  validation accuracy:		91.41 %
Epoch 640 of 2000 took 0.058s
  training loss:		0.065189
  validation loss:		0.322380
  validation accuracy:		91.52 %
Epoch 641 of 2000 took 0.058s
  training loss:		0.062418
  validation loss:		0.332421
  validation accuracy:		90.76 %
Epoch 642 of 2000 took 0.058s
  training loss:		0.064586
  validation loss:		0.318925
  validation accuracy:		91.85 %
Epoch 643 of 2000 took 0.058s
  training loss:		0.064066
  validation loss:		0.317289
  validation accuracy:		91.96 %
Epoch 644 of 2000 took 0.058s
  training loss:		0.063780
  validation loss:		0.328907
  validation accuracy:		91.52 %
Epoch 645 of 2000 took 0.057s
  training loss:		0.062892
  validation loss:		0.330027
  validation accuracy:		91.52 %
Epoch 646 of 2000 took 0.057s
  training loss:		0.064595
  validation loss:		0.329491
  validation accuracy:		91.09 %
Epoch 647 of 2000 took 0.058s
  training loss:		0.062122
  validation loss:		0.319878
  validation accuracy:		91.74 %
Epoch 648 of 2000 took 0.058s
  training loss:		0.061219
  validation loss:		0.318252
  validation accuracy:		91.74 %
Epoch 649 of 2000 took 0.058s
  training loss:		0.062857
  validation loss:		0.317858
  validation accuracy:		91.52 %
Epoch 650 of 2000 took 0.058s
  training loss:		0.064210
  validation loss:		0.318731
  validation accuracy:		91.85 %
Epoch 651 of 2000 took 0.057s
  training loss:		0.063258
  validation loss:		0.318052
  validation accuracy:		91.74 %
Epoch 652 of 2000 took 0.057s
  training loss:		0.062655
  validation loss:		0.322896
  validation accuracy:		92.07 %
Epoch 653 of 2000 took 0.057s
  training loss:		0.064651
  validation loss:		0.321322
  validation accuracy:		91.85 %
Epoch 654 of 2000 took 0.058s
  training loss:		0.062653
  validation loss:		0.322152
  validation accuracy:		91.74 %
Epoch 655 of 2000 took 0.057s
  training loss:		0.060649
  validation loss:		0.326959
  validation accuracy:		91.41 %
Epoch 656 of 2000 took 0.057s
  training loss:		0.061162
  validation loss:		0.311313
  validation accuracy:		92.07 %
Epoch 657 of 2000 took 0.057s
  training loss:		0.060705
  validation loss:		0.317713
  validation accuracy:		91.96 %
Epoch 658 of 2000 took 0.057s
  training loss:		0.060698
  validation loss:		0.321037
  validation accuracy:		91.63 %
Epoch 659 of 2000 took 0.058s
  training loss:		0.061248
  validation loss:		0.321184
  validation accuracy:		92.07 %
Epoch 660 of 2000 took 0.057s
  training loss:		0.061141
  validation loss:		0.327017
  validation accuracy:		91.74 %
Epoch 661 of 2000 took 0.057s
  training loss:		0.061015
  validation loss:		0.319260
  validation accuracy:		91.96 %
Epoch 662 of 2000 took 0.057s
  training loss:		0.057913
  validation loss:		0.323385
  validation accuracy:		91.74 %
Epoch 663 of 2000 took 0.057s
  training loss:		0.061200
  validation loss:		0.318283
  validation accuracy:		92.28 %
Epoch 664 of 2000 took 0.057s
  training loss:		0.058082
  validation loss:		0.330198
  validation accuracy:		91.85 %
Epoch 665 of 2000 took 0.057s
  training loss:		0.061821
  validation loss:		0.321447
  validation accuracy:		92.07 %
Epoch 666 of 2000 took 0.057s
  training loss:		0.059747
  validation loss:		0.321505
  validation accuracy:		92.07 %
Epoch 667 of 2000 took 0.057s
  training loss:		0.059887
  validation loss:		0.345394
  validation accuracy:		90.33 %
Epoch 668 of 2000 took 0.058s
  training loss:		0.059943
  validation loss:		0.318125
  validation accuracy:		92.07 %
Epoch 669 of 2000 took 0.057s
  training loss:		0.059457
  validation loss:		0.324440
  validation accuracy:		91.96 %
Epoch 670 of 2000 took 0.057s
  training loss:		0.060268
  validation loss:		0.336931
  validation accuracy:		91.20 %
Epoch 671 of 2000 took 0.057s
  training loss:		0.062239
  validation loss:		0.330432
  validation accuracy:		91.20 %
Epoch 672 of 2000 took 0.057s
  training loss:		0.057892
  validation loss:		0.325373
  validation accuracy:		91.85 %
Epoch 673 of 2000 took 0.057s
  training loss:		0.060912
  validation loss:		0.329110
  validation accuracy:		91.20 %
Epoch 674 of 2000 took 0.057s
  training loss:		0.058202
  validation loss:		0.331850
  validation accuracy:		91.09 %
Epoch 675 of 2000 took 0.057s
  training loss:		0.058650
  validation loss:		0.320220
  validation accuracy:		92.07 %
Epoch 676 of 2000 took 0.057s
  training loss:		0.057247
  validation loss:		0.339525
  validation accuracy:		90.87 %
Epoch 677 of 2000 took 0.057s
  training loss:		0.058212
  validation loss:		0.324821
  validation accuracy:		91.74 %
Epoch 678 of 2000 took 0.057s
  training loss:		0.057771
  validation loss:		0.343183
  validation accuracy:		91.20 %
Epoch 679 of 2000 took 0.057s
  training loss:		0.059515
  validation loss:		0.319748
  validation accuracy:		92.17 %
Epoch 680 of 2000 took 0.057s
  training loss:		0.057486
  validation loss:		0.325466
  validation accuracy:		91.63 %
Epoch 681 of 2000 took 0.057s
  training loss:		0.056346
  validation loss:		0.328056
  validation accuracy:		91.63 %
Epoch 682 of 2000 took 0.057s
  training loss:		0.057014
  validation loss:		0.329113
  validation accuracy:		92.28 %
Epoch 683 of 2000 took 0.057s
  training loss:		0.057289
  validation loss:		0.350723
  validation accuracy:		91.09 %
Epoch 684 of 2000 took 0.057s
  training loss:		0.058426
  validation loss:		0.327603
  validation accuracy:		91.63 %
Epoch 685 of 2000 took 0.057s
  training loss:		0.057078
  validation loss:		0.327995
  validation accuracy:		91.52 %
Epoch 686 of 2000 took 0.057s
  training loss:		0.056340
  validation loss:		0.331054
  validation accuracy:		91.74 %
Epoch 687 of 2000 took 0.057s
  training loss:		0.057218
  validation loss:		0.350604
  validation accuracy:		90.65 %
Epoch 688 of 2000 took 0.057s
  training loss:		0.056376
  validation loss:		0.323902
  validation accuracy:		92.07 %
Epoch 689 of 2000 took 0.057s
  training loss:		0.057096
  validation loss:		0.327034
  validation accuracy:		91.96 %
Epoch 690 of 2000 took 0.057s
  training loss:		0.056487
  validation loss:		0.343127
  validation accuracy:		90.87 %
Epoch 691 of 2000 took 0.057s
  training loss:		0.054943
  validation loss:		0.330944
  validation accuracy:		91.63 %
Epoch 692 of 2000 took 0.058s
  training loss:		0.055636
  validation loss:		0.333355
  validation accuracy:		91.96 %
Epoch 693 of 2000 took 0.057s
  training loss:		0.053987
  validation loss:		0.332690
  validation accuracy:		91.74 %
Epoch 694 of 2000 took 0.057s
  training loss:		0.058652
  validation loss:		0.337326
  validation accuracy:		91.09 %
Epoch 695 of 2000 took 0.057s
  training loss:		0.057461
  validation loss:		0.339997
  validation accuracy:		91.30 %
Epoch 696 of 2000 took 0.056s
  training loss:		0.056557
  validation loss:		0.332883
  validation accuracy:		91.63 %
Epoch 697 of 2000 took 0.055s
  training loss:		0.056941
  validation loss:		0.330046
  validation accuracy:		91.85 %
Epoch 698 of 2000 took 0.055s
  training loss:		0.057106
  validation loss:		0.345965
  validation accuracy:		90.76 %
Epoch 699 of 2000 took 0.057s
  training loss:		0.056671
  validation loss:		0.358558
  validation accuracy:		91.09 %
Epoch 700 of 2000 took 0.057s
  training loss:		0.055439
  validation loss:		0.336447
  validation accuracy:		91.63 %
Epoch 701 of 2000 took 0.057s
  training loss:		0.053509
  validation loss:		0.328748
  validation accuracy:		91.85 %
Epoch 702 of 2000 took 0.056s
  training loss:		0.056315
  validation loss:		0.338463
  validation accuracy:		91.85 %
Epoch 703 of 2000 took 0.055s
  training loss:		0.056182
  validation loss:		0.333108
  validation accuracy:		91.74 %
Epoch 704 of 2000 took 0.056s
  training loss:		0.053480
  validation loss:		0.339182
  validation accuracy:		91.41 %
Epoch 705 of 2000 took 0.056s
  training loss:		0.055224
  validation loss:		0.331242
  validation accuracy:		91.74 %
Epoch 706 of 2000 took 0.056s
  training loss:		0.052719
  validation loss:		0.329917
  validation accuracy:		91.63 %
Epoch 707 of 2000 took 0.056s
  training loss:		0.054185
  validation loss:		0.339344
  validation accuracy:		91.63 %
Epoch 708 of 2000 took 0.056s
  training loss:		0.053173
  validation loss:		0.336168
  validation accuracy:		91.63 %
Epoch 709 of 2000 took 0.056s
  training loss:		0.052536
  validation loss:		0.354175
  validation accuracy:		91.09 %
Epoch 710 of 2000 took 0.056s
  training loss:		0.054313
  validation loss:		0.345261
  validation accuracy:		91.20 %
Epoch 711 of 2000 took 0.056s
  training loss:		0.052094
  validation loss:		0.334280
  validation accuracy:		91.85 %
Epoch 712 of 2000 took 0.057s
  training loss:		0.054059
  validation loss:		0.335979
  validation accuracy:		91.85 %
Epoch 713 of 2000 took 0.056s
  training loss:		0.054386
  validation loss:		0.337214
  validation accuracy:		91.63 %
Epoch 714 of 2000 took 0.056s
  training loss:		0.053216
  validation loss:		0.338307
  validation accuracy:		91.41 %
Epoch 715 of 2000 took 0.056s
  training loss:		0.052592
  validation loss:		0.346663
  validation accuracy:		91.20 %
Epoch 716 of 2000 took 0.056s
  training loss:		0.053344
  validation loss:		0.332489
  validation accuracy:		92.17 %
Epoch 717 of 2000 took 0.056s
  training loss:		0.052948
  validation loss:		0.339558
  validation accuracy:		91.63 %
Epoch 718 of 2000 took 0.057s
  training loss:		0.054343
  validation loss:		0.349993
  validation accuracy:		91.20 %
Epoch 719 of 2000 took 0.055s
  training loss:		0.052591
  validation loss:		0.334190
  validation accuracy:		91.74 %
Epoch 720 of 2000 took 0.055s
  training loss:		0.054234
  validation loss:		0.340847
  validation accuracy:		91.52 %
Epoch 721 of 2000 took 0.055s
  training loss:		0.051138
  validation loss:		0.340455
  validation accuracy:		91.63 %
Epoch 722 of 2000 took 0.056s
  training loss:		0.054214
  validation loss:		0.342156
  validation accuracy:		91.63 %
Epoch 723 of 2000 took 0.056s
  training loss:		0.052448
  validation loss:		0.350507
  validation accuracy:		91.20 %
Epoch 724 of 2000 took 0.057s
  training loss:		0.051371
  validation loss:		0.333263
  validation accuracy:		92.07 %
Epoch 725 of 2000 took 0.056s
  training loss:		0.051801
  validation loss:		0.343368
  validation accuracy:		91.52 %
Epoch 726 of 2000 took 0.055s
  training loss:		0.049570
  validation loss:		0.333489
  validation accuracy:		91.74 %
Epoch 727 of 2000 took 0.055s
  training loss:		0.051564
  validation loss:		0.349304
  validation accuracy:		91.30 %
Epoch 728 of 2000 took 0.055s
  training loss:		0.051303
  validation loss:		0.335583
  validation accuracy:		91.96 %
Epoch 729 of 2000 took 0.058s
  training loss:		0.053389
  validation loss:		0.340613
  validation accuracy:		92.07 %
Epoch 730 of 2000 took 0.058s
  training loss:		0.050965
  validation loss:		0.338236
  validation accuracy:		91.74 %
Epoch 731 of 2000 took 0.058s
  training loss:		0.052315
  validation loss:		0.351825
  validation accuracy:		91.20 %
Epoch 732 of 2000 took 0.057s
  training loss:		0.051007
  validation loss:		0.336237
  validation accuracy:		92.07 %
Epoch 733 of 2000 took 0.056s
  training loss:		0.049609
  validation loss:		0.342283
  validation accuracy:		91.63 %
Epoch 734 of 2000 took 0.056s
  training loss:		0.050407
  validation loss:		0.340653
  validation accuracy:		91.96 %
Epoch 735 of 2000 took 0.057s
  training loss:		0.050454
  validation loss:		0.338025
  validation accuracy:		92.07 %
Epoch 736 of 2000 took 0.057s
  training loss:		0.051259
  validation loss:		0.334301
  validation accuracy:		92.07 %
Epoch 737 of 2000 took 0.058s
  training loss:		0.050944
  validation loss:		0.349826
  validation accuracy:		91.85 %
Epoch 738 of 2000 took 0.055s
  training loss:		0.051457
  validation loss:		0.345692
  validation accuracy:		91.63 %
Epoch 739 of 2000 took 0.056s
  training loss:		0.049641
  validation loss:		0.354074
  validation accuracy:		91.20 %
Epoch 740 of 2000 took 0.055s
  training loss:		0.051659
  validation loss:		0.362686
  validation accuracy:		91.30 %
Epoch 741 of 2000 took 0.057s
  training loss:		0.050196
  validation loss:		0.345446
  validation accuracy:		91.74 %
Epoch 742 of 2000 took 0.058s
  training loss:		0.050406
  validation loss:		0.342542
  validation accuracy:		91.85 %
Epoch 743 of 2000 took 0.055s
  training loss:		0.049279
  validation loss:		0.353284
  validation accuracy:		91.30 %
Epoch 744 of 2000 took 0.057s
  training loss:		0.049616
  validation loss:		0.345613
  validation accuracy:		91.52 %
Epoch 745 of 2000 took 0.058s
  training loss:		0.049807
  validation loss:		0.336739
  validation accuracy:		91.74 %
Epoch 746 of 2000 took 0.057s
  training loss:		0.051393
  validation loss:		0.352952
  validation accuracy:		90.87 %
Epoch 747 of 2000 took 0.057s
  training loss:		0.047739
  validation loss:		0.343311
  validation accuracy:		91.63 %
Epoch 748 of 2000 took 0.057s
  training loss:		0.049682
  validation loss:		0.352277
  validation accuracy:		91.74 %
Epoch 749 of 2000 took 0.058s
  training loss:		0.050262
  validation loss:		0.347020
  validation accuracy:		91.52 %
Epoch 750 of 2000 took 0.058s
  training loss:		0.051171
  validation loss:		0.357894
  validation accuracy:		90.98 %
Epoch 751 of 2000 took 0.058s
  training loss:		0.050163
  validation loss:		0.346611
  validation accuracy:		91.41 %
Epoch 752 of 2000 took 0.058s
  training loss:		0.047285
  validation loss:		0.345984
  validation accuracy:		91.63 %
Epoch 753 of 2000 took 0.058s
  training loss:		0.048911
  validation loss:		0.352874
  validation accuracy:		91.09 %
Epoch 754 of 2000 took 0.058s
  training loss:		0.050760
  validation loss:		0.338980
  validation accuracy:		92.17 %
Epoch 755 of 2000 took 0.058s
  training loss:		0.048080
  validation loss:		0.351862
  validation accuracy:		91.41 %
Epoch 756 of 2000 took 0.058s
  training loss:		0.048411
  validation loss:		0.342710
  validation accuracy:		92.07 %
Epoch 757 of 2000 took 0.058s
  training loss:		0.046859
  validation loss:		0.340296
  validation accuracy:		91.85 %
Epoch 758 of 2000 took 0.058s
  training loss:		0.047773
  validation loss:		0.349146
  validation accuracy:		91.63 %
Epoch 759 of 2000 took 0.058s
  training loss:		0.046914
  validation loss:		0.356425
  validation accuracy:		90.98 %
Epoch 760 of 2000 took 0.058s
  training loss:		0.048818
  validation loss:		0.351250
  validation accuracy:		91.52 %
Epoch 761 of 2000 took 0.058s
  training loss:		0.047403
  validation loss:		0.354913
  validation accuracy:		91.20 %
Epoch 762 of 2000 took 0.059s
  training loss:		0.049047
  validation loss:		0.346737
  validation accuracy:		91.63 %
Epoch 763 of 2000 took 0.058s
  training loss:		0.048046
  validation loss:		0.340042
  validation accuracy:		92.28 %
Epoch 764 of 2000 took 0.058s
  training loss:		0.046974
  validation loss:		0.344304
  validation accuracy:		91.85 %
Epoch 765 of 2000 took 0.058s
  training loss:		0.049397
  validation loss:		0.367562
  validation accuracy:		91.85 %
Epoch 766 of 2000 took 0.058s
  training loss:		0.047792
  validation loss:		0.346293
  validation accuracy:		91.63 %
Epoch 767 of 2000 took 0.058s
  training loss:		0.046306
  validation loss:		0.362970
  validation accuracy:		91.74 %
Epoch 768 of 2000 took 0.058s
  training loss:		0.048616
  validation loss:		0.348398
  validation accuracy:		91.96 %
Epoch 769 of 2000 took 0.059s
  training loss:		0.044958
  validation loss:		0.343332
  validation accuracy:		92.07 %
Epoch 770 of 2000 took 0.058s
  training loss:		0.047134
  validation loss:		0.348794
  validation accuracy:		91.41 %
Epoch 771 of 2000 took 0.058s
  training loss:		0.046571
  validation loss:		0.359851
  validation accuracy:		91.30 %
Epoch 772 of 2000 took 0.058s
  training loss:		0.049380
  validation loss:		0.354483
  validation accuracy:		91.20 %
Epoch 773 of 2000 took 0.058s
  training loss:		0.045253
  validation loss:		0.354336
  validation accuracy:		91.30 %
Epoch 774 of 2000 took 0.059s
  training loss:		0.046451
  validation loss:		0.351328
  validation accuracy:		91.41 %
Epoch 775 of 2000 took 0.056s
  training loss:		0.045697
  validation loss:		0.360761
  validation accuracy:		91.41 %
Epoch 776 of 2000 took 0.058s
  training loss:		0.047174
  validation loss:		0.360641
  validation accuracy:		91.20 %
Epoch 777 of 2000 took 0.058s
  training loss:		0.047939
  validation loss:		0.358810
  validation accuracy:		91.30 %
Epoch 778 of 2000 took 0.058s
  training loss:		0.043625
  validation loss:		0.350101
  validation accuracy:		91.74 %
Epoch 779 of 2000 took 0.058s
  training loss:		0.044904
  validation loss:		0.352528
  validation accuracy:		91.30 %
Epoch 780 of 2000 took 0.058s
  training loss:		0.046640
  validation loss:		0.348926
  validation accuracy:		91.41 %
Epoch 781 of 2000 took 0.058s
  training loss:		0.044247
  validation loss:		0.353947
  validation accuracy:		91.41 %
Epoch 782 of 2000 took 0.058s
  training loss:		0.044344
  validation loss:		0.360131
  validation accuracy:		91.20 %
Epoch 783 of 2000 took 0.058s
  training loss:		0.045476
  validation loss:		0.378003
  validation accuracy:		91.20 %
Epoch 784 of 2000 took 0.058s
  training loss:		0.045674
  validation loss:		0.359446
  validation accuracy:		91.52 %
Epoch 785 of 2000 took 0.058s
  training loss:		0.044389
  validation loss:		0.347873
  validation accuracy:		91.74 %
Epoch 786 of 2000 took 0.058s
  training loss:		0.046229
  validation loss:		0.358104
  validation accuracy:		91.52 %
Epoch 787 of 2000 took 0.058s
  training loss:		0.045735
  validation loss:		0.364006
  validation accuracy:		91.52 %
Epoch 788 of 2000 took 0.058s
  training loss:		0.044648
  validation loss:		0.366121
  validation accuracy:		91.63 %
Epoch 789 of 2000 took 0.055s
  training loss:		0.044462
  validation loss:		0.366134
  validation accuracy:		91.20 %
Epoch 790 of 2000 took 0.057s
  training loss:		0.045560
  validation loss:		0.357066
  validation accuracy:		91.30 %
Epoch 791 of 2000 took 0.057s
  training loss:		0.045249
  validation loss:		0.364392
  validation accuracy:		91.74 %
Epoch 792 of 2000 took 0.057s
  training loss:		0.044198
  validation loss:		0.370736
  validation accuracy:		91.52 %
Epoch 793 of 2000 took 0.056s
  training loss:		0.044817
  validation loss:		0.374166
  validation accuracy:		91.20 %
Epoch 794 of 2000 took 0.057s
  training loss:		0.044466
  validation loss:		0.364073
  validation accuracy:		91.52 %
Epoch 795 of 2000 took 0.057s
  training loss:		0.045488
  validation loss:		0.366311
  validation accuracy:		91.52 %
Epoch 796 of 2000 took 0.057s
  training loss:		0.044139
  validation loss:		0.364590
  validation accuracy:		91.30 %
Epoch 797 of 2000 took 0.057s
  training loss:		0.043821
  validation loss:		0.363372
  validation accuracy:		91.63 %
Epoch 798 of 2000 took 0.057s
  training loss:		0.041984
  validation loss:		0.362935
  validation accuracy:		91.30 %
Epoch 799 of 2000 took 0.058s
  training loss:		0.043535
  validation loss:		0.381899
  validation accuracy:		91.41 %
Epoch 800 of 2000 took 0.058s
  training loss:		0.042197
  validation loss:		0.362063
  validation accuracy:		91.52 %
Epoch 801 of 2000 took 0.058s
  training loss:		0.042487
  validation loss:		0.360811
  validation accuracy:		91.74 %
Epoch 802 of 2000 took 0.058s
  training loss:		0.043053
  validation loss:		0.360435
  validation accuracy:		91.96 %
Epoch 803 of 2000 took 0.058s
  training loss:		0.043101
  validation loss:		0.360865
  validation accuracy:		91.63 %
Epoch 804 of 2000 took 0.058s
  training loss:		0.043541
  validation loss:		0.363610
  validation accuracy:		91.30 %
Epoch 805 of 2000 took 0.058s
  training loss:		0.044341
  validation loss:		0.354224
  validation accuracy:		91.63 %
Epoch 806 of 2000 took 0.058s
  training loss:		0.041919
  validation loss:		0.376656
  validation accuracy:		91.20 %
Epoch 807 of 2000 took 0.057s
  training loss:		0.044541
  validation loss:		0.362033
  validation accuracy:		91.41 %
Epoch 808 of 2000 took 0.057s
  training loss:		0.041718
  validation loss:		0.365505
  validation accuracy:		91.63 %
Epoch 809 of 2000 took 0.056s
  training loss:		0.042692
  validation loss:		0.364803
  validation accuracy:		91.63 %
Epoch 810 of 2000 took 0.057s
  training loss:		0.042988
  validation loss:		0.370349
  validation accuracy:		91.20 %
Epoch 811 of 2000 took 0.057s
  training loss:		0.042564
  validation loss:		0.369811
  validation accuracy:		91.30 %
Epoch 812 of 2000 took 0.057s
  training loss:		0.041811
  validation loss:		0.364144
  validation accuracy:		91.63 %
Epoch 813 of 2000 took 0.057s
  training loss:		0.041129
  validation loss:		0.366182
  validation accuracy:		91.63 %
Epoch 814 of 2000 took 0.057s
  training loss:		0.040588
  validation loss:		0.361585
  validation accuracy:		91.30 %
Epoch 815 of 2000 took 0.056s
  training loss:		0.042937
  validation loss:		0.376113
  validation accuracy:		91.85 %
Epoch 816 of 2000 took 0.055s
  training loss:		0.040997
  validation loss:		0.362146
  validation accuracy:		91.85 %
Epoch 817 of 2000 took 0.056s
  training loss:		0.040203
  validation loss:		0.373554
  validation accuracy:		91.41 %
Epoch 818 of 2000 took 0.055s
  training loss:		0.042949
  validation loss:		0.372212
  validation accuracy:		91.30 %
Epoch 819 of 2000 took 0.057s
  training loss:		0.042317
  validation loss:		0.366045
  validation accuracy:		91.74 %
Epoch 820 of 2000 took 0.057s
  training loss:		0.041388
  validation loss:		0.378247
  validation accuracy:		91.20 %
Epoch 821 of 2000 took 0.056s
  training loss:		0.041836
  validation loss:		0.378692
  validation accuracy:		91.20 %
Epoch 822 of 2000 took 0.057s
  training loss:		0.040665
  validation loss:		0.376771
  validation accuracy:		91.63 %
Epoch 823 of 2000 took 0.056s
  training loss:		0.041658
  validation loss:		0.368917
  validation accuracy:		91.20 %
Epoch 824 of 2000 took 0.056s
  training loss:		0.039245
  validation loss:		0.380661
  validation accuracy:		91.52 %
Epoch 825 of 2000 took 0.056s
  training loss:		0.040177
  validation loss:		0.367159
  validation accuracy:		91.41 %
Epoch 826 of 2000 took 0.055s
  training loss:		0.042000
  validation loss:		0.367636
  validation accuracy:		91.85 %
Epoch 827 of 2000 took 0.056s
  training loss:		0.040829
  validation loss:		0.378388
  validation accuracy:		91.41 %
Epoch 828 of 2000 took 0.054s
  training loss:		0.040439
  validation loss:		0.384600
  validation accuracy:		91.41 %
Epoch 829 of 2000 took 0.056s
  training loss:		0.040010
  validation loss:		0.364246
  validation accuracy:		91.41 %
Epoch 830 of 2000 took 0.054s
  training loss:		0.041038
  validation loss:		0.362684
  validation accuracy:		91.52 %
Epoch 831 of 2000 took 0.056s
  training loss:		0.041669
  validation loss:		0.376950
  validation accuracy:		91.41 %
Epoch 832 of 2000 took 0.057s
  training loss:		0.038184
  validation loss:		0.369013
  validation accuracy:		91.30 %
Epoch 833 of 2000 took 0.056s
  training loss:		0.040116
  validation loss:		0.368887
  validation accuracy:		91.52 %
Epoch 834 of 2000 took 0.055s
  training loss:		0.038895
  validation loss:		0.365167
  validation accuracy:		91.85 %
Epoch 835 of 2000 took 0.056s
  training loss:		0.038761
  validation loss:		0.366007
  validation accuracy:		91.20 %
Epoch 836 of 2000 took 0.055s
  training loss:		0.039839
  validation loss:		0.373524
  validation accuracy:		91.20 %
Epoch 837 of 2000 took 0.056s
  training loss:		0.039038
  validation loss:		0.378186
  validation accuracy:		91.74 %
Epoch 838 of 2000 took 0.058s
  training loss:		0.039876
  validation loss:		0.382289
  validation accuracy:		91.41 %
Epoch 839 of 2000 took 0.058s
  training loss:		0.039263
  validation loss:		0.371009
  validation accuracy:		91.85 %
Epoch 840 of 2000 took 0.058s
  training loss:		0.038270
  validation loss:		0.381463
  validation accuracy:		91.63 %
Epoch 841 of 2000 took 0.058s
  training loss:		0.039697
  validation loss:		0.371739
  validation accuracy:		91.74 %
Epoch 842 of 2000 took 0.057s
  training loss:		0.040070
  validation loss:		0.376101
  validation accuracy:		91.20 %
Epoch 843 of 2000 took 0.057s
  training loss:		0.039126
  validation loss:		0.375660
  validation accuracy:		91.20 %
Epoch 844 of 2000 took 0.055s
  training loss:		0.041224
  validation loss:		0.369951
  validation accuracy:		91.41 %
Epoch 845 of 2000 took 0.057s
  training loss:		0.037553
  validation loss:		0.377063
  validation accuracy:		90.98 %
Epoch 846 of 2000 took 0.058s
  training loss:		0.037472
  validation loss:		0.380622
  validation accuracy:		91.52 %
Epoch 847 of 2000 took 0.057s
  training loss:		0.038229
  validation loss:		0.374121
  validation accuracy:		91.20 %
Epoch 848 of 2000 took 0.057s
  training loss:		0.038206
  validation loss:		0.377812
  validation accuracy:		91.20 %
Epoch 849 of 2000 took 0.057s
  training loss:		0.037454
  validation loss:		0.377305
  validation accuracy:		91.52 %
Epoch 850 of 2000 took 0.058s
  training loss:		0.037463
  validation loss:		0.371751
  validation accuracy:		91.63 %
Epoch 851 of 2000 took 0.057s
  training loss:		0.039188
  validation loss:		0.383986
  validation accuracy:		91.52 %
Epoch 852 of 2000 took 0.057s
  training loss:		0.037639
  validation loss:		0.387873
  validation accuracy:		91.20 %
Epoch 853 of 2000 took 0.058s
  training loss:		0.036258
  validation loss:		0.387876
  validation accuracy:		91.30 %
Epoch 854 of 2000 took 0.057s
  training loss:		0.038818
  validation loss:		0.377744
  validation accuracy:		91.63 %
Epoch 855 of 2000 took 0.057s
  training loss:		0.038204
  validation loss:		0.378793
  validation accuracy:		91.52 %
Epoch 856 of 2000 took 0.057s
  training loss:		0.037495
  validation loss:		0.374248
  validation accuracy:		91.30 %
Epoch 857 of 2000 took 0.058s
  training loss:		0.038191
  validation loss:		0.394252
  validation accuracy:		91.20 %
Epoch 858 of 2000 took 0.057s
  training loss:		0.036543
  validation loss:		0.377444
  validation accuracy:		91.41 %
Epoch 859 of 2000 took 0.057s
  training loss:		0.037699
  validation loss:		0.381417
  validation accuracy:		91.85 %
Epoch 860 of 2000 took 0.057s
  training loss:		0.038146
  validation loss:		0.382310
  validation accuracy:		91.41 %
Epoch 861 of 2000 took 0.057s
  training loss:		0.037681
  validation loss:		0.372342
  validation accuracy:		91.85 %
Epoch 862 of 2000 took 0.057s
  training loss:		0.037145
  validation loss:		0.380280
  validation accuracy:		91.30 %
Epoch 863 of 2000 took 0.057s
  training loss:		0.038994
  validation loss:		0.387997
  validation accuracy:		91.41 %
Epoch 864 of 2000 took 0.057s
  training loss:		0.037363
  validation loss:		0.382009
  validation accuracy:		91.63 %
Epoch 865 of 2000 took 0.057s
  training loss:		0.038118
  validation loss:		0.394447
  validation accuracy:		90.87 %
Epoch 866 of 2000 took 0.057s
  training loss:		0.037961
  validation loss:		0.381547
  validation accuracy:		91.63 %
Epoch 867 of 2000 took 0.057s
  training loss:		0.035930
  validation loss:		0.390014
  validation accuracy:		91.09 %
Epoch 868 of 2000 took 0.057s
  training loss:		0.037922
  validation loss:		0.381639
  validation accuracy:		91.52 %
Epoch 869 of 2000 took 0.058s
  training loss:		0.036821
  validation loss:		0.391162
  validation accuracy:		91.41 %
Epoch 870 of 2000 took 0.057s
  training loss:		0.036430
  validation loss:		0.378438
  validation accuracy:		90.98 %
Epoch 871 of 2000 took 0.058s
  training loss:		0.037391
  validation loss:		0.388719
  validation accuracy:		91.63 %
Epoch 872 of 2000 took 0.057s
  training loss:		0.035723
  validation loss:		0.380992
  validation accuracy:		91.41 %
Epoch 873 of 2000 took 0.057s
  training loss:		0.035904
  validation loss:		0.396756
  validation accuracy:		91.09 %
Epoch 874 of 2000 took 0.057s
  training loss:		0.035463
  validation loss:		0.381511
  validation accuracy:		91.63 %
Epoch 875 of 2000 took 0.057s
  training loss:		0.036995
  validation loss:		0.388688
  validation accuracy:		91.30 %
Epoch 876 of 2000 took 0.057s
  training loss:		0.036097
  validation loss:		0.403347
  validation accuracy:		91.30 %
Epoch 877 of 2000 took 0.058s
  training loss:		0.037036
  validation loss:		0.392256
  validation accuracy:		91.09 %
Epoch 878 of 2000 took 0.057s
  training loss:		0.036130
  validation loss:		0.392791
  validation accuracy:		91.30 %
Epoch 879 of 2000 took 0.057s
  training loss:		0.035896
  validation loss:		0.400964
  validation accuracy:		91.30 %
Epoch 880 of 2000 took 0.057s
  training loss:		0.037274
  validation loss:		0.390935
  validation accuracy:		91.30 %
Epoch 881 of 2000 took 0.057s
  training loss:		0.035608
  validation loss:		0.397260
  validation accuracy:		91.20 %
Epoch 882 of 2000 took 0.058s
  training loss:		0.036743
  validation loss:		0.379727
  validation accuracy:		91.30 %
Epoch 883 of 2000 took 0.057s
  training loss:		0.034893
  validation loss:		0.401784
  validation accuracy:		91.41 %
Epoch 884 of 2000 took 0.057s
  training loss:		0.035351
  validation loss:		0.381116
  validation accuracy:		91.20 %
Epoch 885 of 2000 took 0.057s
  training loss:		0.037006
  validation loss:		0.393991
  validation accuracy:		91.09 %
Epoch 886 of 2000 took 0.057s
  training loss:		0.035043
  validation loss:		0.406125
  validation accuracy:		91.41 %
Epoch 887 of 2000 took 0.057s
  training loss:		0.036291
  validation loss:		0.382692
  validation accuracy:		91.41 %
Epoch 888 of 2000 took 0.057s
  training loss:		0.033700
  validation loss:		0.383400
  validation accuracy:		91.52 %
Epoch 889 of 2000 took 0.057s
  training loss:		0.033426
  validation loss:		0.388275
  validation accuracy:		91.52 %
Epoch 890 of 2000 took 0.057s
  training loss:		0.035325
  validation loss:		0.376806
  validation accuracy:		91.63 %
Epoch 891 of 2000 took 0.058s
  training loss:		0.034800
  validation loss:		0.392460
  validation accuracy:		91.30 %
Epoch 892 of 2000 took 0.057s
  training loss:		0.032745
  validation loss:		0.389312
  validation accuracy:		91.30 %
Epoch 893 of 2000 took 0.057s
  training loss:		0.034717
  validation loss:		0.380440
  validation accuracy:		91.52 %
Epoch 894 of 2000 took 0.057s
  training loss:		0.034895
  validation loss:		0.386518
  validation accuracy:		91.41 %
Epoch 895 of 2000 took 0.057s
  training loss:		0.034796
  validation loss:		0.384977
  validation accuracy:		91.63 %
Epoch 896 of 2000 took 0.057s
  training loss:		0.033276
  validation loss:		0.393668
  validation accuracy:		91.09 %
Epoch 897 of 2000 took 0.057s
  training loss:		0.033290
  validation loss:		0.385347
  validation accuracy:		91.30 %
Epoch 898 of 2000 took 0.057s
  training loss:		0.033885
  validation loss:		0.393672
  validation accuracy:		91.41 %
Epoch 899 of 2000 took 0.057s
  training loss:		0.036195
  validation loss:		0.404882
  validation accuracy:		91.20 %
Epoch 900 of 2000 took 0.057s
  training loss:		0.034085
  validation loss:		0.411062
  validation accuracy:		91.20 %
Epoch 901 of 2000 took 0.058s
  training loss:		0.034511
  validation loss:		0.396717
  validation accuracy:		91.30 %
Epoch 902 of 2000 took 0.058s
  training loss:		0.034855
  validation loss:		0.389830
  validation accuracy:		91.20 %
Epoch 903 of 2000 took 0.057s
  training loss:		0.034089
  validation loss:		0.402037
  validation accuracy:		91.41 %
Epoch 904 of 2000 took 0.057s
  training loss:		0.034148
  validation loss:		0.390638
  validation accuracy:		91.41 %
Epoch 905 of 2000 took 0.058s
  training loss:		0.032714
  validation loss:		0.402911
  validation accuracy:		91.41 %
Epoch 906 of 2000 took 0.058s
  training loss:		0.031389
  validation loss:		0.391730
  validation accuracy:		91.20 %
Epoch 907 of 2000 took 0.057s
  training loss:		0.033102
  validation loss:		0.403690
  validation accuracy:		91.52 %
Epoch 908 of 2000 took 0.057s
  training loss:		0.033438
  validation loss:		0.386775
  validation accuracy:		91.30 %
Epoch 909 of 2000 took 0.057s
  training loss:		0.033784
  validation loss:		0.402196
  validation accuracy:		91.20 %
Epoch 910 of 2000 took 0.057s
  training loss:		0.033218
  validation loss:		0.411466
  validation accuracy:		90.98 %
Epoch 911 of 2000 took 0.057s
  training loss:		0.033250
  validation loss:		0.412696
  validation accuracy:		91.09 %
Epoch 912 of 2000 took 0.057s
  training loss:		0.033692
  validation loss:		0.404905
  validation accuracy:		91.30 %
Epoch 913 of 2000 took 0.057s
  training loss:		0.032371
  validation loss:		0.395482
  validation accuracy:		91.52 %
Epoch 914 of 2000 took 0.057s
  training loss:		0.032441
  validation loss:		0.402510
  validation accuracy:		91.30 %
Epoch 915 of 2000 took 0.057s
  training loss:		0.032885
  validation loss:		0.403426
  validation accuracy:		91.30 %
Epoch 916 of 2000 took 0.057s
  training loss:		0.033156
  validation loss:		0.391544
  validation accuracy:		91.41 %
Epoch 917 of 2000 took 0.057s
  training loss:		0.031266
  validation loss:		0.403704
  validation accuracy:		91.52 %
Epoch 918 of 2000 took 0.057s
  training loss:		0.033911
  validation loss:		0.413698
  validation accuracy:		91.20 %
Epoch 919 of 2000 took 0.057s
  training loss:		0.033191
  validation loss:		0.412689
  validation accuracy:		91.41 %
Epoch 920 of 2000 took 0.058s
  training loss:		0.033469
  validation loss:		0.395580
  validation accuracy:		91.41 %
Epoch 921 of 2000 took 0.058s
  training loss:		0.031698
  validation loss:		0.405359
  validation accuracy:		91.41 %
Epoch 922 of 2000 took 0.057s
  training loss:		0.031633
  validation loss:		0.410903
  validation accuracy:		91.30 %
Epoch 923 of 2000 took 0.057s
  training loss:		0.033111
  validation loss:		0.410051
  validation accuracy:		91.30 %
Epoch 924 of 2000 took 0.057s
  training loss:		0.031464
  validation loss:		0.421350
  validation accuracy:		90.76 %
Epoch 925 of 2000 took 0.057s
  training loss:		0.032168
  validation loss:		0.412198
  validation accuracy:		91.20 %
Epoch 926 of 2000 took 0.057s
  training loss:		0.031895
  validation loss:		0.408249
  validation accuracy:		91.30 %
Epoch 927 of 2000 took 0.057s
  training loss:		0.030399
  validation loss:		0.406477
  validation accuracy:		91.41 %
Epoch 928 of 2000 took 0.057s
  training loss:		0.033000
  validation loss:		0.404128
  validation accuracy:		91.41 %
Epoch 929 of 2000 took 0.057s
  training loss:		0.031226
  validation loss:		0.405139
  validation accuracy:		91.09 %
Epoch 930 of 2000 took 0.057s
  training loss:		0.030684
  validation loss:		0.418943
  validation accuracy:		91.09 %
Epoch 931 of 2000 took 0.057s
  training loss:		0.031939
  validation loss:		0.400674
  validation accuracy:		91.20 %
Epoch 932 of 2000 took 0.057s
  training loss:		0.032259
  validation loss:		0.406498
  validation accuracy:		91.20 %
Epoch 933 of 2000 took 0.058s
  training loss:		0.031379
  validation loss:		0.400878
  validation accuracy:		91.74 %
Epoch 934 of 2000 took 0.057s
  training loss:		0.031399
  validation loss:		0.411806
  validation accuracy:		91.30 %
Epoch 935 of 2000 took 0.057s
  training loss:		0.030198
  validation loss:		0.401423
  validation accuracy:		91.20 %
Epoch 936 of 2000 took 0.057s
  training loss:		0.030146
  validation loss:		0.418111
  validation accuracy:		91.30 %
Epoch 937 of 2000 took 0.058s
  training loss:		0.031166
  validation loss:		0.417646
  validation accuracy:		90.76 %
Epoch 938 of 2000 took 0.057s
  training loss:		0.032723
  validation loss:		0.413834
  validation accuracy:		91.20 %
Epoch 939 of 2000 took 0.057s
  training loss:		0.030339
  validation loss:		0.414277
  validation accuracy:		91.41 %
Epoch 940 of 2000 took 0.057s
  training loss:		0.030751
  validation loss:		0.425208
  validation accuracy:		91.09 %
Epoch 941 of 2000 took 0.058s
  training loss:		0.031088
  validation loss:		0.426113
  validation accuracy:		91.09 %
Epoch 942 of 2000 took 0.058s
  training loss:		0.030853
  validation loss:		0.421049
  validation accuracy:		91.09 %
Epoch 943 of 2000 took 0.058s
  training loss:		0.029931
  validation loss:		0.416083
  validation accuracy:		91.09 %
Epoch 944 of 2000 took 0.058s
  training loss:		0.031079
  validation loss:		0.406867
  validation accuracy:		91.52 %
Epoch 945 of 2000 took 0.058s
  training loss:		0.029673
  validation loss:		0.417714
  validation accuracy:		90.98 %
Epoch 946 of 2000 took 0.058s
  training loss:		0.029146
  validation loss:		0.409475
  validation accuracy:		91.30 %
Epoch 947 of 2000 took 0.058s
  training loss:		0.029266
  validation loss:		0.414909
  validation accuracy:		91.20 %
Epoch 948 of 2000 took 0.058s
  training loss:		0.029492
  validation loss:		0.397450
  validation accuracy:		91.30 %
Epoch 949 of 2000 took 0.058s
  training loss:		0.030009
  validation loss:		0.409537
  validation accuracy:		91.52 %
Epoch 950 of 2000 took 0.058s
  training loss:		0.030838
  validation loss:		0.431352
  validation accuracy:		90.98 %
Epoch 951 of 2000 took 0.058s
  training loss:		0.030029
  validation loss:		0.418967
  validation accuracy:		91.41 %
Epoch 952 of 2000 took 0.058s
  training loss:		0.028484
  validation loss:		0.405460
  validation accuracy:		91.41 %
Epoch 953 of 2000 took 0.058s
  training loss:		0.029163
  validation loss:		0.413341
  validation accuracy:		91.30 %
Epoch 954 of 2000 took 0.058s
  training loss:		0.030803
  validation loss:		0.409660
  validation accuracy:		91.63 %
Epoch 955 of 2000 took 0.058s
  training loss:		0.028642
  validation loss:		0.417237
  validation accuracy:		91.63 %
Epoch 956 of 2000 took 0.059s
  training loss:		0.029420
  validation loss:		0.418032
  validation accuracy:		91.52 %
Epoch 957 of 2000 took 0.056s
  training loss:		0.029450
  validation loss:		0.423168
  validation accuracy:		91.09 %
Epoch 958 of 2000 took 0.058s
  training loss:		0.030069
  validation loss:		0.420284
  validation accuracy:		91.09 %
Epoch 959 of 2000 took 0.058s
  training loss:		0.028876
  validation loss:		0.419127
  validation accuracy:		90.87 %
Epoch 960 of 2000 took 0.058s
  training loss:		0.029028
  validation loss:		0.432232
  validation accuracy:		90.76 %
Epoch 961 of 2000 took 0.058s
  training loss:		0.030001
  validation loss:		0.422825
  validation accuracy:		91.41 %
Epoch 962 of 2000 took 0.058s
  training loss:		0.028883
  validation loss:		0.415192
  validation accuracy:		90.98 %
Epoch 963 of 2000 took 0.058s
  training loss:		0.029860
  validation loss:		0.424402
  validation accuracy:		91.41 %
Epoch 964 of 2000 took 0.058s
  training loss:		0.029482
  validation loss:		0.418148
  validation accuracy:		91.52 %
Epoch 965 of 2000 took 0.058s
  training loss:		0.029700
  validation loss:		0.428710
  validation accuracy:		91.09 %
Epoch 966 of 2000 took 0.058s
  training loss:		0.030924
  validation loss:		0.409889
  validation accuracy:		91.30 %
Epoch 967 of 2000 took 0.058s
  training loss:		0.028694
  validation loss:		0.432969
  validation accuracy:		91.09 %
Epoch 968 of 2000 took 0.058s
  training loss:		0.028292
  validation loss:		0.413101
  validation accuracy:		91.41 %
Epoch 969 of 2000 took 0.057s
  training loss:		0.028206
  validation loss:		0.423352
  validation accuracy:		91.09 %
Epoch 970 of 2000 took 0.057s
  training loss:		0.028744
  validation loss:		0.434759
  validation accuracy:		90.76 %
Epoch 971 of 2000 took 0.057s
  training loss:		0.028870
  validation loss:		0.416323
  validation accuracy:		91.30 %
Epoch 972 of 2000 took 0.058s
  training loss:		0.028588
  validation loss:		0.426380
  validation accuracy:		91.20 %
Epoch 973 of 2000 took 0.057s
  training loss:		0.027042
  validation loss:		0.421915
  validation accuracy:		91.30 %
Epoch 974 of 2000 took 0.057s
  training loss:		0.028058
  validation loss:		0.417457
  validation accuracy:		91.20 %
Epoch 975 of 2000 took 0.057s
  training loss:		0.030146
  validation loss:		0.421966
  validation accuracy:		90.87 %
Epoch 976 of 2000 took 0.056s
  training loss:		0.027910
  validation loss:		0.428174
  validation accuracy:		91.20 %
Epoch 977 of 2000 took 0.055s
  training loss:		0.028143
  validation loss:		0.428339
  validation accuracy:		91.30 %
Epoch 978 of 2000 took 0.055s
  training loss:		0.027377
  validation loss:		0.423362
  validation accuracy:		91.30 %
Epoch 979 of 2000 took 0.057s
  training loss:		0.027366
  validation loss:		0.424279
  validation accuracy:		91.30 %
Epoch 980 of 2000 took 0.057s
  training loss:		0.026462
  validation loss:		0.431410
  validation accuracy:		91.30 %
Epoch 981 of 2000 took 0.057s
  training loss:		0.028303
  validation loss:		0.415527
  validation accuracy:		91.52 %
Epoch 982 of 2000 took 0.057s
  training loss:		0.028838
  validation loss:		0.424223
  validation accuracy:		91.09 %
Epoch 983 of 2000 took 0.057s
  training loss:		0.028421
  validation loss:		0.441655
  validation accuracy:		90.87 %
Epoch 984 of 2000 took 0.057s
  training loss:		0.027565
  validation loss:		0.420781
  validation accuracy:		91.41 %
Epoch 985 of 2000 took 0.057s
  training loss:		0.027509
  validation loss:		0.432621
  validation accuracy:		90.87 %
Epoch 986 of 2000 took 0.057s
  training loss:		0.027008
  validation loss:		0.416320
  validation accuracy:		91.41 %
Epoch 987 of 2000 took 0.056s
  training loss:		0.027603
  validation loss:		0.430643
  validation accuracy:		91.52 %
Epoch 988 of 2000 took 0.057s
  training loss:		0.026964
  validation loss:		0.414769
  validation accuracy:		91.30 %
Epoch 989 of 2000 took 0.055s
  training loss:		0.027067
  validation loss:		0.426002
  validation accuracy:		91.52 %
Epoch 990 of 2000 took 0.057s
  training loss:		0.027831
  validation loss:		0.430872
  validation accuracy:		91.30 %
Epoch 991 of 2000 took 0.055s
  training loss:		0.026617
  validation loss:		0.431838
  validation accuracy:		91.30 %
Epoch 992 of 2000 took 0.057s
  training loss:		0.026603
  validation loss:		0.439759
  validation accuracy:		90.76 %
Epoch 993 of 2000 took 0.057s
  training loss:		0.027118
  validation loss:		0.431672
  validation accuracy:		91.20 %
Epoch 994 of 2000 took 0.056s
  training loss:		0.026055
  validation loss:		0.436243
  validation accuracy:		91.20 %
Epoch 995 of 2000 took 0.057s
  training loss:		0.026686
  validation loss:		0.436135
  validation accuracy:		90.98 %
Epoch 996 of 2000 took 0.057s
  training loss:		0.026431
  validation loss:		0.434157
  validation accuracy:		91.20 %
Epoch 997 of 2000 took 0.057s
  training loss:		0.025921
  validation loss:		0.453038
  validation accuracy:		90.76 %
Epoch 998 of 2000 took 0.057s
  training loss:		0.025045
  validation loss:		0.432100
  validation accuracy:		90.87 %
Epoch 999 of 2000 took 0.057s
  training loss:		0.026148
  validation loss:		0.437858
  validation accuracy:		91.30 %
Epoch 1000 of 2000 took 0.057s
  training loss:		0.026812
  validation loss:		0.442805
  validation accuracy:		91.30 %
Epoch 1001 of 2000 took 0.057s
  training loss:		0.025825
  validation loss:		0.433494
  validation accuracy:		91.20 %
Epoch 1002 of 2000 took 0.057s
  training loss:		0.024752
  validation loss:		0.452329
  validation accuracy:		91.30 %
Epoch 1003 of 2000 took 0.057s
  training loss:		0.026163
  validation loss:		0.432856
  validation accuracy:		91.30 %
Epoch 1004 of 2000 took 0.056s
  training loss:		0.025138
  validation loss:		0.446709
  validation accuracy:		90.76 %
Epoch 1005 of 2000 took 0.057s
  training loss:		0.026118
  validation loss:		0.440543
  validation accuracy:		90.76 %
Epoch 1006 of 2000 took 0.057s
  training loss:		0.025874
  validation loss:		0.431007
  validation accuracy:		91.30 %
Epoch 1007 of 2000 took 0.057s
  training loss:		0.025750
  validation loss:		0.428794
  validation accuracy:		91.20 %
Epoch 1008 of 2000 took 0.057s
  training loss:		0.027301
  validation loss:		0.440403
  validation accuracy:		91.09 %
Epoch 1009 of 2000 took 0.056s
  training loss:		0.026566
  validation loss:		0.435939
  validation accuracy:		90.98 %
Epoch 1010 of 2000 took 0.057s
  training loss:		0.026344
  validation loss:		0.432493
  validation accuracy:		91.20 %
Epoch 1011 of 2000 took 0.056s
  training loss:		0.026144
  validation loss:		0.448149
  validation accuracy:		90.87 %
Epoch 1012 of 2000 took 0.056s
  training loss:		0.025903
  validation loss:		0.441450
  validation accuracy:		91.20 %
Epoch 1013 of 2000 took 0.057s
  training loss:		0.025546
  validation loss:		0.446059
  validation accuracy:		90.87 %
Epoch 1014 of 2000 took 0.055s
  training loss:		0.024414
  validation loss:		0.448825
  validation accuracy:		90.98 %
Epoch 1015 of 2000 took 0.056s
  training loss:		0.024005
  validation loss:		0.438321
  validation accuracy:		90.87 %
Epoch 1016 of 2000 took 0.057s
  training loss:		0.024866
  validation loss:		0.433788
  validation accuracy:		91.30 %
Epoch 1017 of 2000 took 0.055s
  training loss:		0.024631
  validation loss:		0.455580
  validation accuracy:		91.09 %
Epoch 1018 of 2000 took 0.057s
  training loss:		0.024023
  validation loss:		0.438435
  validation accuracy:		91.09 %
Epoch 1019 of 2000 took 0.056s
  training loss:		0.026504
  validation loss:		0.432407
  validation accuracy:		91.30 %
Epoch 1020 of 2000 took 0.057s
  training loss:		0.024821
  validation loss:		0.438932
  validation accuracy:		90.87 %
Epoch 1021 of 2000 took 0.055s
  training loss:		0.024580
  validation loss:		0.434333
  validation accuracy:		90.76 %
Epoch 1022 of 2000 took 0.057s
  training loss:		0.024588
  validation loss:		0.444668
  validation accuracy:		90.87 %
Epoch 1023 of 2000 took 0.057s
  training loss:		0.024426
  validation loss:		0.446415
  validation accuracy:		90.87 %
Epoch 1024 of 2000 took 0.057s
  training loss:		0.024239
  validation loss:		0.443959
  validation accuracy:		90.98 %
Epoch 1025 of 2000 took 0.055s
  training loss:		0.025067
  validation loss:		0.439477
  validation accuracy:		91.09 %
Epoch 1026 of 2000 took 0.057s
  training loss:		0.024836
  validation loss:		0.445879
  validation accuracy:		90.98 %
Epoch 1027 of 2000 took 0.057s
  training loss:		0.023838
  validation loss:		0.447328
  validation accuracy:		91.09 %
Epoch 1028 of 2000 took 0.057s
  training loss:		0.023798
  validation loss:		0.446717
  validation accuracy:		91.09 %
Epoch 1029 of 2000 took 0.057s
  training loss:		0.023793
  validation loss:		0.439761
  validation accuracy:		91.09 %
Epoch 1030 of 2000 took 0.057s
  training loss:		0.024256
  validation loss:		0.449858
  validation accuracy:		90.65 %
Epoch 1031 of 2000 took 0.057s
  training loss:		0.024720
  validation loss:		0.439090
  validation accuracy:		91.41 %
Epoch 1032 of 2000 took 0.057s
  training loss:		0.024984
  validation loss:		0.443702
  validation accuracy:		91.09 %
Epoch 1033 of 2000 took 0.057s
  training loss:		0.023988
  validation loss:		0.447195
  validation accuracy:		90.65 %
Epoch 1034 of 2000 took 0.057s
  training loss:		0.024556
  validation loss:		0.465945
  validation accuracy:		90.76 %
Epoch 1035 of 2000 took 0.057s
  training loss:		0.024929
  validation loss:		0.451111
  validation accuracy:		90.87 %
Epoch 1036 of 2000 took 0.057s
  training loss:		0.023006
  validation loss:		0.448411
  validation accuracy:		90.76 %
Epoch 1037 of 2000 took 0.055s
  training loss:		0.023808
  validation loss:		0.446898
  validation accuracy:		90.76 %
Epoch 1038 of 2000 took 0.057s
  training loss:		0.026141
  validation loss:		0.443106
  validation accuracy:		90.76 %
Epoch 1039 of 2000 took 0.057s
  training loss:		0.023677
  validation loss:		0.455429
  validation accuracy:		90.43 %
Epoch 1040 of 2000 took 0.056s
  training loss:		0.023517
  validation loss:		0.447627
  validation accuracy:		91.09 %
Epoch 1041 of 2000 took 0.057s
  training loss:		0.023692
  validation loss:		0.452382
  validation accuracy:		90.76 %
Epoch 1042 of 2000 took 0.057s
  training loss:		0.023795
  validation loss:		0.451223
  validation accuracy:		91.09 %
Epoch 1043 of 2000 took 0.057s
  training loss:		0.022607
  validation loss:		0.473240
  validation accuracy:		91.20 %
Epoch 1044 of 2000 took 0.055s
  training loss:		0.022895
  validation loss:		0.454429
  validation accuracy:		91.09 %
Epoch 1045 of 2000 took 0.057s
  training loss:		0.023764
  validation loss:		0.458245
  validation accuracy:		90.54 %
Epoch 1046 of 2000 took 0.057s
  training loss:		0.023150
  validation loss:		0.455735
  validation accuracy:		91.85 %
Epoch 1047 of 2000 took 0.057s
  training loss:		0.024058
  validation loss:		0.456870
  validation accuracy:		90.54 %
Epoch 1048 of 2000 took 0.057s
  training loss:		0.021673
  validation loss:		0.456585
  validation accuracy:		91.09 %
Epoch 1049 of 2000 took 0.057s
  training loss:		0.023109
  validation loss:		0.439394
  validation accuracy:		91.09 %
Epoch 1050 of 2000 took 0.056s
  training loss:		0.023373
  validation loss:		0.445307
  validation accuracy:		90.65 %
Epoch 1051 of 2000 took 0.057s
  training loss:		0.025150
  validation loss:		0.446975
  validation accuracy:		90.87 %
Epoch 1052 of 2000 took 0.057s
  training loss:		0.022712
  validation loss:		0.456882
  validation accuracy:		91.09 %
Epoch 1053 of 2000 took 0.057s
  training loss:		0.024690
  validation loss:		0.452809
  validation accuracy:		90.98 %
Epoch 1054 of 2000 took 0.056s
  training loss:		0.022583
  validation loss:		0.456012
  validation accuracy:		91.20 %
Epoch 1055 of 2000 took 0.056s
  training loss:		0.022947
  validation loss:		0.456501
  validation accuracy:		90.87 %
Epoch 1056 of 2000 took 0.057s
  training loss:		0.022642
  validation loss:		0.471123
  validation accuracy:		90.76 %
Epoch 1057 of 2000 took 0.056s
  training loss:		0.023178
  validation loss:		0.459597
  validation accuracy:		90.65 %
Epoch 1058 of 2000 took 0.056s
  training loss:		0.022060
  validation loss:		0.458694
  validation accuracy:		90.87 %
Epoch 1059 of 2000 took 0.056s
  training loss:		0.024206
  validation loss:		0.457764
  validation accuracy:		90.87 %
Epoch 1060 of 2000 took 0.056s
  training loss:		0.022143
  validation loss:		0.451834
  validation accuracy:		90.43 %
Epoch 1061 of 2000 took 0.055s
  training loss:		0.022522
  validation loss:		0.467499
  validation accuracy:		90.65 %
Epoch 1062 of 2000 took 0.055s
  training loss:		0.021804
  validation loss:		0.458535
  validation accuracy:		90.87 %
Epoch 1063 of 2000 took 0.055s
  training loss:		0.022237
  validation loss:		0.449580
  validation accuracy:		90.98 %
Epoch 1064 of 2000 took 0.055s
  training loss:		0.022113
  validation loss:		0.460861
  validation accuracy:		90.65 %
Epoch 1065 of 2000 took 0.055s
  training loss:		0.022462
  validation loss:		0.468917
  validation accuracy:		90.65 %
Epoch 1066 of 2000 took 0.056s
  training loss:		0.023099
  validation loss:		0.451146
  validation accuracy:		91.09 %
Epoch 1067 of 2000 took 0.056s
  training loss:		0.022141
  validation loss:		0.469510
  validation accuracy:		91.09 %
Epoch 1068 of 2000 took 0.056s
  training loss:		0.022015
  validation loss:		0.457082
  validation accuracy:		91.20 %
Epoch 1069 of 2000 took 0.055s
  training loss:		0.021831
  validation loss:		0.454685
  validation accuracy:		91.09 %
Epoch 1070 of 2000 took 0.056s
  training loss:		0.021748
  validation loss:		0.453360
  validation accuracy:		91.09 %
Epoch 1071 of 2000 took 0.056s
  training loss:		0.022406
  validation loss:		0.442304
  validation accuracy:		90.87 %
Epoch 1072 of 2000 took 0.054s
  training loss:		0.022650
  validation loss:		0.457009
  validation accuracy:		91.09 %
Epoch 1073 of 2000 took 0.057s
  training loss:		0.022021
  validation loss:		0.457013
  validation accuracy:		90.87 %
Epoch 1074 of 2000 took 0.055s
  training loss:		0.021340
  validation loss:		0.462486
  validation accuracy:		91.20 %
Epoch 1075 of 2000 took 0.055s
  training loss:		0.021374
  validation loss:		0.474882
  validation accuracy:		90.98 %
Epoch 1076 of 2000 took 0.056s
  training loss:		0.021881
  validation loss:		0.447723
  validation accuracy:		91.09 %
Epoch 1077 of 2000 took 0.055s
  training loss:		0.021805
  validation loss:		0.461015
  validation accuracy:		91.09 %
Epoch 1078 of 2000 took 0.054s
  training loss:		0.022230
  validation loss:		0.459292
  validation accuracy:		90.54 %
Epoch 1079 of 2000 took 0.056s
  training loss:		0.021238
  validation loss:		0.452896
  validation accuracy:		91.09 %
Epoch 1080 of 2000 took 0.054s
  training loss:		0.022292
  validation loss:		0.459943
  validation accuracy:		90.98 %
Epoch 1081 of 2000 took 0.055s
  training loss:		0.021425
  validation loss:		0.461224
  validation accuracy:		91.09 %
Epoch 1082 of 2000 took 0.054s
  training loss:		0.020896
  validation loss:		0.470352
  validation accuracy:		90.76 %
Epoch 1083 of 2000 took 0.055s
  training loss:		0.020785
  validation loss:		0.474842
  validation accuracy:		90.65 %
Epoch 1084 of 2000 took 0.055s
  training loss:		0.020973
  validation loss:		0.460777
  validation accuracy:		91.20 %
Epoch 1085 of 2000 took 0.056s
  training loss:		0.021803
  validation loss:		0.474200
  validation accuracy:		91.30 %
Epoch 1086 of 2000 took 0.057s
  training loss:		0.023054
  validation loss:		0.474224
  validation accuracy:		90.76 %
Epoch 1087 of 2000 took 0.057s
  training loss:		0.021213
  validation loss:		0.459880
  validation accuracy:		90.98 %
Epoch 1088 of 2000 took 0.057s
  training loss:		0.021190
  validation loss:		0.471505
  validation accuracy:		90.87 %
Epoch 1089 of 2000 took 0.057s
  training loss:		0.020687
  validation loss:		0.470785
  validation accuracy:		90.76 %
Epoch 1090 of 2000 took 0.057s
  training loss:		0.020048
  validation loss:		0.455495
  validation accuracy:		91.09 %
Epoch 1091 of 2000 took 0.058s
  training loss:		0.020847
  validation loss:		0.460147
  validation accuracy:		90.98 %
Epoch 1092 of 2000 took 0.057s
  training loss:		0.020529
  validation loss:		0.473637
  validation accuracy:		90.87 %
Epoch 1093 of 2000 took 0.058s
  training loss:		0.021293
  validation loss:		0.468852
  validation accuracy:		91.09 %
Epoch 1094 of 2000 took 0.057s
  training loss:		0.020821
  validation loss:		0.470760
  validation accuracy:		90.76 %
Epoch 1095 of 2000 took 0.057s
  training loss:		0.019883
  validation loss:		0.458533
  validation accuracy:		91.52 %
Epoch 1096 of 2000 took 0.057s
  training loss:		0.020578
  validation loss:		0.472065
  validation accuracy:		90.98 %
Epoch 1097 of 2000 took 0.058s
  training loss:		0.020057
  validation loss:		0.473249
  validation accuracy:		90.54 %
Epoch 1098 of 2000 took 0.058s
  training loss:		0.020226
  validation loss:		0.460943
  validation accuracy:		90.98 %
Epoch 1099 of 2000 took 0.058s
  training loss:		0.020350
  validation loss:		0.463134
  validation accuracy:		90.76 %
Epoch 1100 of 2000 took 0.058s
  training loss:		0.020810
  validation loss:		0.467977
  validation accuracy:		91.09 %
Epoch 1101 of 2000 took 0.058s
  training loss:		0.020165
  validation loss:		0.472103
  validation accuracy:		91.20 %
Epoch 1102 of 2000 took 0.058s
  training loss:		0.020563
  validation loss:		0.460779
  validation accuracy:		91.09 %
Epoch 1103 of 2000 took 0.058s
  training loss:		0.021076
  validation loss:		0.480551
  validation accuracy:		90.65 %
Epoch 1104 of 2000 took 0.056s
  training loss:		0.019817
  validation loss:		0.475842
  validation accuracy:		91.30 %
Epoch 1105 of 2000 took 0.055s
  training loss:		0.020294
  validation loss:		0.469270
  validation accuracy:		90.87 %
Epoch 1106 of 2000 took 0.055s
  training loss:		0.019641
  validation loss:		0.473389
  validation accuracy:		90.87 %
Epoch 1107 of 2000 took 0.057s
  training loss:		0.019357
  validation loss:		0.480503
  validation accuracy:		90.65 %
Epoch 1108 of 2000 took 0.057s
  training loss:		0.019796
  validation loss:		0.482834
  validation accuracy:		90.76 %
Epoch 1109 of 2000 took 0.057s
  training loss:		0.019068
  validation loss:		0.479867
  validation accuracy:		90.76 %
Epoch 1110 of 2000 took 0.057s
  training loss:		0.019067
  validation loss:		0.470189
  validation accuracy:		90.98 %
Epoch 1111 of 2000 took 0.057s
  training loss:		0.019720
  validation loss:		0.476044
  validation accuracy:		91.20 %
Epoch 1112 of 2000 took 0.057s
  training loss:		0.019650
  validation loss:		0.485765
  validation accuracy:		90.65 %
Epoch 1113 of 2000 took 0.057s
  training loss:		0.020161
  validation loss:		0.477733
  validation accuracy:		90.43 %
Epoch 1114 of 2000 took 0.057s
  training loss:		0.019494
  validation loss:		0.471926
  validation accuracy:		90.76 %
Epoch 1115 of 2000 took 0.057s
  training loss:		0.020597
  validation loss:		0.484987
  validation accuracy:		90.65 %
Epoch 1116 of 2000 took 0.057s
  training loss:		0.019205
  validation loss:		0.467120
  validation accuracy:		90.87 %
Epoch 1117 of 2000 took 0.057s
  training loss:		0.018612
  validation loss:		0.473147
  validation accuracy:		90.76 %
Epoch 1118 of 2000 took 0.057s
  training loss:		0.020214
  validation loss:		0.483859
  validation accuracy:		90.87 %
Epoch 1119 of 2000 took 0.057s
  training loss:		0.019330
  validation loss:		0.480501
  validation accuracy:		90.87 %
Epoch 1120 of 2000 took 0.056s
  training loss:		0.019361
  validation loss:		0.486452
  validation accuracy:		90.65 %
Epoch 1121 of 2000 took 0.057s
  training loss:		0.018796
  validation loss:		0.499685
  validation accuracy:		90.54 %
Epoch 1122 of 2000 took 0.057s
  training loss:		0.019336
  validation loss:		0.487260
  validation accuracy:		91.30 %
Epoch 1123 of 2000 took 0.057s
  training loss:		0.019629
  validation loss:		0.479349
  validation accuracy:		91.20 %
Epoch 1124 of 2000 took 0.057s
  training loss:		0.018969
  validation loss:		0.475375
  validation accuracy:		90.98 %
Epoch 1125 of 2000 took 0.056s
  training loss:		0.019055
  validation loss:		0.474786
  validation accuracy:		90.87 %
Epoch 1126 of 2000 took 0.055s
  training loss:		0.019118
  validation loss:		0.486128
  validation accuracy:		90.33 %
Epoch 1127 of 2000 took 0.056s
  training loss:		0.019770
  validation loss:		0.481699
  validation accuracy:		90.54 %
Epoch 1128 of 2000 took 0.056s
  training loss:		0.018603
  validation loss:		0.474722
  validation accuracy:		91.41 %
Epoch 1129 of 2000 took 0.056s
  training loss:		0.019014
  validation loss:		0.479438
  validation accuracy:		90.98 %
Epoch 1130 of 2000 took 0.056s
  training loss:		0.019188
  validation loss:		0.480701
  validation accuracy:		91.09 %
Epoch 1131 of 2000 took 0.056s
  training loss:		0.019124
  validation loss:		0.494429
  validation accuracy:		90.65 %
Epoch 1132 of 2000 took 0.056s
  training loss:		0.018388
  validation loss:		0.487075
  validation accuracy:		91.20 %
Epoch 1133 of 2000 took 0.056s
  training loss:		0.017945
  validation loss:		0.472953
  validation accuracy:		90.98 %
Epoch 1134 of 2000 took 0.056s
  training loss:		0.018771
  validation loss:		0.480369
  validation accuracy:		91.30 %
Epoch 1135 of 2000 took 0.057s
  training loss:		0.019466
  validation loss:		0.483003
  validation accuracy:		90.98 %
Epoch 1136 of 2000 took 0.056s
  training loss:		0.019230
  validation loss:		0.504385
  validation accuracy:		90.65 %
Epoch 1137 of 2000 took 0.056s
  training loss:		0.019273
  validation loss:		0.475350
  validation accuracy:		91.09 %
Epoch 1138 of 2000 took 0.056s
  training loss:		0.018506
  validation loss:		0.485455
  validation accuracy:		90.76 %
Epoch 1139 of 2000 took 0.057s
  training loss:		0.019036
  validation loss:		0.478798
  validation accuracy:		90.98 %
Epoch 1140 of 2000 took 0.056s
  training loss:		0.017927
  validation loss:		0.488835
  validation accuracy:		90.54 %
Epoch 1141 of 2000 took 0.056s
  training loss:		0.018422
  validation loss:		0.501201
  validation accuracy:		90.76 %
Epoch 1142 of 2000 took 0.056s
  training loss:		0.017906
  validation loss:		0.496494
  validation accuracy:		90.98 %
Epoch 1143 of 2000 took 0.056s
  training loss:		0.018080
  validation loss:		0.490998
  validation accuracy:		90.33 %
Epoch 1144 of 2000 took 0.056s
  training loss:		0.018005
  validation loss:		0.478655
  validation accuracy:		91.09 %
Epoch 1145 of 2000 took 0.056s
  training loss:		0.018006
  validation loss:		0.489683
  validation accuracy:		91.09 %
Epoch 1146 of 2000 took 0.056s
  training loss:		0.018863
  validation loss:		0.489994
  validation accuracy:		90.65 %
Epoch 1147 of 2000 took 0.055s
  training loss:		0.018856
  validation loss:		0.499965
  validation accuracy:		90.98 %
Epoch 1148 of 2000 took 0.055s
  training loss:		0.018450
  validation loss:		0.492727
  validation accuracy:		90.87 %
Epoch 1149 of 2000 took 0.056s
  training loss:		0.018264
  validation loss:		0.486503
  validation accuracy:		90.65 %
Epoch 1150 of 2000 took 0.054s
  training loss:		0.017520
  validation loss:		0.493586
  validation accuracy:		90.98 %
Epoch 1151 of 2000 took 0.054s
  training loss:		0.017343
  validation loss:		0.484999
  validation accuracy:		91.20 %
Epoch 1152 of 2000 took 0.054s
  training loss:		0.018292
  validation loss:		0.488549
  validation accuracy:		90.98 %
Epoch 1153 of 2000 took 0.057s
  training loss:		0.017172
  validation loss:		0.487661
  validation accuracy:		90.98 %
Epoch 1154 of 2000 took 0.054s
  training loss:		0.017743
  validation loss:		0.483081
  validation accuracy:		91.20 %
Epoch 1155 of 2000 took 0.054s
  training loss:		0.017891
  validation loss:		0.480066
  validation accuracy:		91.20 %
Epoch 1156 of 2000 took 0.057s
  training loss:		0.017823
  validation loss:		0.495887
  validation accuracy:		91.09 %
Epoch 1157 of 2000 took 0.055s
  training loss:		0.017453
  validation loss:		0.504674
  validation accuracy:		90.43 %
Epoch 1158 of 2000 took 0.056s
  training loss:		0.017893
  validation loss:		0.505986
  validation accuracy:		90.98 %
Epoch 1159 of 2000 took 0.054s
  training loss:		0.017230
  validation loss:		0.502387
  validation accuracy:		90.98 %
Epoch 1160 of 2000 took 0.056s
  training loss:		0.017293
  validation loss:		0.493786
  validation accuracy:		90.54 %
Epoch 1161 of 2000 took 0.058s
  training loss:		0.017095
  validation loss:		0.487440
  validation accuracy:		90.98 %
Epoch 1162 of 2000 took 0.058s
  training loss:		0.017965
  validation loss:		0.496607
  validation accuracy:		90.54 %
Epoch 1163 of 2000 took 0.057s
  training loss:		0.017376
  validation loss:		0.502107
  validation accuracy:		90.98 %
Epoch 1164 of 2000 took 0.057s
  training loss:		0.016615
  validation loss:		0.504410
  validation accuracy:		90.76 %
Epoch 1165 of 2000 took 0.055s
  training loss:		0.017229
  validation loss:		0.492707
  validation accuracy:		91.09 %
Epoch 1166 of 2000 took 0.055s
  training loss:		0.017806
  validation loss:		0.475371
  validation accuracy:		91.09 %
Epoch 1167 of 2000 took 0.058s
  training loss:		0.017318
  validation loss:		0.490798
  validation accuracy:		91.09 %
Epoch 1168 of 2000 took 0.057s
  training loss:		0.017837
  validation loss:		0.496501
  validation accuracy:		90.87 %
Epoch 1169 of 2000 took 0.057s
  training loss:		0.017039
  validation loss:		0.510237
  validation accuracy:		90.65 %
Epoch 1170 of 2000 took 0.057s
  training loss:		0.016685
  validation loss:		0.497017
  validation accuracy:		91.20 %
Epoch 1171 of 2000 took 0.057s
  training loss:		0.016760
  validation loss:		0.490024
  validation accuracy:		91.09 %
Epoch 1172 of 2000 took 0.057s
  training loss:		0.017219
  validation loss:		0.500745
  validation accuracy:		90.65 %
Epoch 1173 of 2000 took 0.057s
  training loss:		0.016705
  validation loss:		0.502656
  validation accuracy:		90.65 %
Epoch 1174 of 2000 took 0.057s
  training loss:		0.016819
  validation loss:		0.495686
  validation accuracy:		90.65 %
Epoch 1175 of 2000 took 0.057s
  training loss:		0.016348
  validation loss:		0.495582
  validation accuracy:		91.52 %
Epoch 1176 of 2000 took 0.057s
  training loss:		0.016547
  validation loss:		0.495591
  validation accuracy:		90.43 %
Epoch 1177 of 2000 took 0.057s
  training loss:		0.016958
  validation loss:		0.500358
  validation accuracy:		90.65 %
Epoch 1178 of 2000 took 0.058s
  training loss:		0.016288
  validation loss:		0.494105
  validation accuracy:		91.30 %
Epoch 1179 of 2000 took 0.057s
  training loss:		0.016882
  validation loss:		0.507858
  validation accuracy:		90.54 %
Epoch 1180 of 2000 took 0.057s
  training loss:		0.017049
  validation loss:		0.505202
  validation accuracy:		90.76 %
Epoch 1181 of 2000 took 0.058s
  training loss:		0.016784
  validation loss:		0.495822
  validation accuracy:		90.98 %
Epoch 1182 of 2000 took 0.057s
  training loss:		0.016852
  validation loss:		0.508569
  validation accuracy:		90.98 %
Epoch 1183 of 2000 took 0.057s
  training loss:		0.016603
  validation loss:		0.510760
  validation accuracy:		91.09 %
Epoch 1184 of 2000 took 0.057s
  training loss:		0.016875
  validation loss:		0.502780
  validation accuracy:		90.76 %
Epoch 1185 of 2000 took 0.058s
  training loss:		0.016341
  validation loss:		0.505141
  validation accuracy:		90.54 %
Epoch 1186 of 2000 took 0.057s
  training loss:		0.016797
  validation loss:		0.499231
  validation accuracy:		90.87 %
Epoch 1187 of 2000 took 0.057s
  training loss:		0.016084
  validation loss:		0.488045
  validation accuracy:		90.98 %
Epoch 1188 of 2000 took 0.058s
  training loss:		0.016589
  validation loss:		0.504239
  validation accuracy:		91.09 %
Epoch 1189 of 2000 took 0.057s
  training loss:		0.016402
  validation loss:		0.501470
  validation accuracy:		90.76 %
Epoch 1190 of 2000 took 0.057s
  training loss:		0.016243
  validation loss:		0.515899
  validation accuracy:		90.87 %
Epoch 1191 of 2000 took 0.057s
  training loss:		0.016392
  validation loss:		0.505851
  validation accuracy:		90.98 %
Epoch 1192 of 2000 took 0.057s
  training loss:		0.016657
  validation loss:		0.499663
  validation accuracy:		91.09 %
Epoch 1193 of 2000 took 0.057s
  training loss:		0.016271
  validation loss:		0.511886
  validation accuracy:		90.87 %
Epoch 1194 of 2000 took 0.058s
  training loss:		0.015655
  validation loss:		0.512465
  validation accuracy:		90.65 %
Epoch 1195 of 2000 took 0.057s
  training loss:		0.015863
  validation loss:		0.513201
  validation accuracy:		90.98 %
Epoch 1196 of 2000 took 0.057s
  training loss:		0.015867
  validation loss:		0.518094
  validation accuracy:		90.54 %
Epoch 1197 of 2000 took 0.057s
  training loss:		0.016609
  validation loss:		0.502660
  validation accuracy:		91.09 %
Epoch 1198 of 2000 took 0.057s
  training loss:		0.016850
  validation loss:		0.510806
  validation accuracy:		91.09 %
Epoch 1199 of 2000 took 0.057s
  training loss:		0.016489
  validation loss:		0.512602
  validation accuracy:		91.09 %
Epoch 1200 of 2000 took 0.058s
  training loss:		0.016006
  validation loss:		0.519883
  validation accuracy:		90.65 %
Epoch 1201 of 2000 took 0.057s
  training loss:		0.014975
  validation loss:		0.520003
  validation accuracy:		90.65 %
Epoch 1202 of 2000 took 0.057s
  training loss:		0.016335
  validation loss:		0.508563
  validation accuracy:		91.20 %
Epoch 1203 of 2000 took 0.057s
  training loss:		0.015973
  validation loss:		0.503280
  validation accuracy:		91.09 %
Epoch 1204 of 2000 took 0.057s
  training loss:		0.015429
  validation loss:		0.507047
  validation accuracy:		90.98 %
Epoch 1205 of 2000 took 0.057s
  training loss:		0.015231
  validation loss:		0.522001
  validation accuracy:		90.76 %
Epoch 1206 of 2000 took 0.057s
  training loss:		0.015799
  validation loss:		0.515265
  validation accuracy:		91.09 %
Epoch 1207 of 2000 took 0.057s
  training loss:		0.015349
  validation loss:		0.514815
  validation accuracy:		90.98 %
Epoch 1208 of 2000 took 0.057s
  training loss:		0.015911
  validation loss:		0.512187
  validation accuracy:		91.09 %
Epoch 1209 of 2000 took 0.058s
  training loss:		0.015953
  validation loss:		0.519725
  validation accuracy:		90.76 %
Epoch 1210 of 2000 took 0.057s
  training loss:		0.014764
  validation loss:		0.513388
  validation accuracy:		91.09 %
Epoch 1211 of 2000 took 0.057s
  training loss:		0.015136
  validation loss:		0.512014
  validation accuracy:		90.65 %
Epoch 1212 of 2000 took 0.057s
  training loss:		0.015501
  validation loss:		0.518778
  validation accuracy:		90.65 %
Epoch 1213 of 2000 took 0.057s
  training loss:		0.015683
  validation loss:		0.513189
  validation accuracy:		90.87 %
Epoch 1214 of 2000 took 0.057s
  training loss:		0.014801
  validation loss:		0.510442
  validation accuracy:		91.09 %
Epoch 1215 of 2000 took 0.057s
  training loss:		0.016921
  validation loss:		0.501139
  validation accuracy:		91.09 %
Epoch 1216 of 2000 took 0.057s
  training loss:		0.015971
  validation loss:		0.515224
  validation accuracy:		91.20 %
Epoch 1217 of 2000 took 0.057s
  training loss:		0.015167
  validation loss:		0.518663
  validation accuracy:		90.54 %
Epoch 1218 of 2000 took 0.057s
  training loss:		0.015363
  validation loss:		0.511456
  validation accuracy:		91.09 %
Epoch 1219 of 2000 took 0.058s
  training loss:		0.015311
  validation loss:		0.510810
  validation accuracy:		90.54 %
Epoch 1220 of 2000 took 0.057s
  training loss:		0.014747
  validation loss:		0.512209
  validation accuracy:		91.09 %
Epoch 1221 of 2000 took 0.058s
  training loss:		0.015811
  validation loss:		0.530876
  validation accuracy:		90.65 %
Epoch 1222 of 2000 took 0.057s
  training loss:		0.015775
  validation loss:		0.525904
  validation accuracy:		90.54 %
Epoch 1223 of 2000 took 0.058s
  training loss:		0.014665
  validation loss:		0.512726
  validation accuracy:		91.20 %
Epoch 1224 of 2000 took 0.058s
  training loss:		0.015248
  validation loss:		0.512092
  validation accuracy:		90.87 %
Epoch 1225 of 2000 took 0.058s
  training loss:		0.015135
  validation loss:		0.511475
  validation accuracy:		90.87 %
Epoch 1226 of 2000 took 0.058s
  training loss:		0.015200
  validation loss:		0.524217
  validation accuracy:		90.98 %
Epoch 1227 of 2000 took 0.058s
  training loss:		0.015051
  validation loss:		0.527234
  validation accuracy:		90.76 %
Epoch 1228 of 2000 took 0.058s
  training loss:		0.014585
  validation loss:		0.527119
  validation accuracy:		90.76 %
Epoch 1229 of 2000 took 0.057s
  training loss:		0.014880
  validation loss:		0.541604
  validation accuracy:		90.65 %
Epoch 1230 of 2000 took 0.057s
  training loss:		0.014564
  validation loss:		0.515668
  validation accuracy:		90.98 %
Epoch 1231 of 2000 took 0.057s
  training loss:		0.015124
  validation loss:		0.523330
  validation accuracy:		90.54 %
Epoch 1232 of 2000 took 0.057s
  training loss:		0.014446
  validation loss:		0.524714
  validation accuracy:		90.87 %
Epoch 1233 of 2000 took 0.057s
  training loss:		0.014325
  validation loss:		0.515265
  validation accuracy:		91.20 %
Epoch 1234 of 2000 took 0.057s
  training loss:		0.014822
  validation loss:		0.506515
  validation accuracy:		91.09 %
Epoch 1235 of 2000 took 0.057s
  training loss:		0.014969
  validation loss:		0.519984
  validation accuracy:		90.76 %
Epoch 1236 of 2000 took 0.057s
  training loss:		0.015065
  validation loss:		0.532292
  validation accuracy:		90.65 %
Epoch 1237 of 2000 took 0.057s
  training loss:		0.014605
  validation loss:		0.516655
  validation accuracy:		90.98 %
Epoch 1238 of 2000 took 0.057s
  training loss:		0.014340
  validation loss:		0.512478
  validation accuracy:		91.20 %
Epoch 1239 of 2000 took 0.057s
  training loss:		0.014951
  validation loss:		0.528996
  validation accuracy:		91.09 %
Epoch 1240 of 2000 took 0.058s
  training loss:		0.014251
  validation loss:		0.537354
  validation accuracy:		90.54 %
Epoch 1241 of 2000 took 0.057s
  training loss:		0.014988
  validation loss:		0.518910
  validation accuracy:		90.76 %
Epoch 1242 of 2000 took 0.058s
  training loss:		0.014167
  validation loss:		0.513531
  validation accuracy:		91.20 %
Epoch 1243 of 2000 took 0.057s
  training loss:		0.014186
  validation loss:		0.515985
  validation accuracy:		91.09 %
Epoch 1244 of 2000 took 0.058s
  training loss:		0.014013
  validation loss:		0.531711
  validation accuracy:		90.87 %
Epoch 1245 of 2000 took 0.057s
  training loss:		0.014216
  validation loss:		0.527090
  validation accuracy:		90.98 %
Epoch 1246 of 2000 took 0.057s
  training loss:		0.014433
  validation loss:		0.531163
  validation accuracy:		90.87 %
Epoch 1247 of 2000 took 0.057s
  training loss:		0.014433
  validation loss:		0.530121
  validation accuracy:		91.09 %
Epoch 1248 of 2000 took 0.059s
  training loss:		0.014613
  validation loss:		0.526946
  validation accuracy:		90.98 %
Epoch 1249 of 2000 took 0.056s
  training loss:		0.014521
  validation loss:		0.520861
  validation accuracy:		91.41 %
Epoch 1250 of 2000 took 0.057s
  training loss:		0.013842
  validation loss:		0.520121
  validation accuracy:		91.41 %
Epoch 1251 of 2000 took 0.057s
  training loss:		0.014285
  validation loss:		0.534951
  validation accuracy:		90.54 %
Epoch 1252 of 2000 took 0.057s
  training loss:		0.013928
  validation loss:		0.533092
  validation accuracy:		90.65 %
Epoch 1253 of 2000 took 0.057s
  training loss:		0.013756
  validation loss:		0.518898
  validation accuracy:		91.20 %
Epoch 1254 of 2000 took 0.058s
  training loss:		0.014088
  validation loss:		0.528323
  validation accuracy:		91.30 %
Epoch 1255 of 2000 took 0.057s
  training loss:		0.014030
  validation loss:		0.530766
  validation accuracy:		90.98 %
Epoch 1256 of 2000 took 0.057s
  training loss:		0.014190
  validation loss:		0.544495
  validation accuracy:		90.43 %
Epoch 1257 of 2000 took 0.057s
  training loss:		0.014635
  validation loss:		0.527564
  validation accuracy:		90.87 %
Epoch 1258 of 2000 took 0.058s
  training loss:		0.014102
  validation loss:		0.537328
  validation accuracy:		90.65 %
Epoch 1259 of 2000 took 0.058s
  training loss:		0.013786
  validation loss:		0.529075
  validation accuracy:		91.09 %
Epoch 1260 of 2000 took 0.058s
  training loss:		0.013918
  validation loss:		0.532933
  validation accuracy:		91.09 %
Epoch 1261 of 2000 took 0.058s
  training loss:		0.013310
  validation loss:		0.533644
  validation accuracy:		90.98 %
Epoch 1262 of 2000 took 0.058s
  training loss:		0.013133
  validation loss:		0.547208
  validation accuracy:		90.65 %
Epoch 1263 of 2000 took 0.058s
  training loss:		0.013356
  validation loss:		0.517897
  validation accuracy:		91.20 %
Epoch 1264 of 2000 took 0.058s
  training loss:		0.013890
  validation loss:		0.531926
  validation accuracy:		90.87 %
Epoch 1265 of 2000 took 0.058s
  training loss:		0.013196
  validation loss:		0.527597
  validation accuracy:		91.20 %
Epoch 1266 of 2000 took 0.058s
  training loss:		0.013752
  validation loss:		0.530262
  validation accuracy:		91.30 %
Epoch 1267 of 2000 took 0.058s
  training loss:		0.014248
  validation loss:		0.538113
  validation accuracy:		90.65 %
Epoch 1268 of 2000 took 0.058s
  training loss:		0.013190
  validation loss:		0.527763
  validation accuracy:		90.87 %
Epoch 1269 of 2000 took 0.058s
  training loss:		0.013231
  validation loss:		0.528817
  validation accuracy:		91.09 %
Epoch 1270 of 2000 took 0.058s
  training loss:		0.013154
  validation loss:		0.524102
  validation accuracy:		91.20 %
Epoch 1271 of 2000 took 0.058s
  training loss:		0.013545
  validation loss:		0.532292
  validation accuracy:		90.87 %
Epoch 1272 of 2000 took 0.058s
  training loss:		0.013360
  validation loss:		0.533615
  validation accuracy:		91.09 %
Epoch 1273 of 2000 took 0.057s
  training loss:		0.013774
  validation loss:		0.540709
  validation accuracy:		90.43 %
Epoch 1274 of 2000 took 0.057s
  training loss:		0.013472
  validation loss:		0.528335
  validation accuracy:		91.41 %
Epoch 1275 of 2000 took 0.057s
  training loss:		0.013767
  validation loss:		0.543128
  validation accuracy:		90.43 %
Epoch 1276 of 2000 took 0.058s
  training loss:		0.013793
  validation loss:		0.545802
  validation accuracy:		90.87 %
Epoch 1277 of 2000 took 0.057s
  training loss:		0.013372
  validation loss:		0.547737
  validation accuracy:		90.65 %
Epoch 1278 of 2000 took 0.057s
  training loss:		0.013341
  validation loss:		0.529216
  validation accuracy:		91.30 %
Epoch 1279 of 2000 took 0.057s
  training loss:		0.013631
  validation loss:		0.535098
  validation accuracy:		90.98 %
Epoch 1280 of 2000 took 0.057s
  training loss:		0.013698
  validation loss:		0.538248
  validation accuracy:		90.43 %
Epoch 1281 of 2000 took 0.057s
  training loss:		0.012854
  validation loss:		0.552986
  validation accuracy:		90.54 %
Epoch 1282 of 2000 took 0.057s
  training loss:		0.013078
  validation loss:		0.545512
  validation accuracy:		90.76 %
Epoch 1283 of 2000 took 0.057s
  training loss:		0.012776
  validation loss:		0.537777
  validation accuracy:		90.98 %
Epoch 1284 of 2000 took 0.057s
  training loss:		0.013866
  validation loss:		0.538020
  validation accuracy:		90.87 %
Epoch 1285 of 2000 took 0.057s
  training loss:		0.012698
  validation loss:		0.548358
  validation accuracy:		90.65 %
Epoch 1286 of 2000 took 0.057s
  training loss:		0.012972
  validation loss:		0.546609
  validation accuracy:		90.65 %
Epoch 1287 of 2000 took 0.057s
  training loss:		0.013025
  validation loss:		0.534013
  validation accuracy:		91.09 %
Epoch 1288 of 2000 took 0.057s
  training loss:		0.012536
  validation loss:		0.541519
  validation accuracy:		90.43 %
Epoch 1289 of 2000 took 0.057s
  training loss:		0.013142
  validation loss:		0.535907
  validation accuracy:		90.87 %
Epoch 1290 of 2000 took 0.057s
  training loss:		0.013055
  validation loss:		0.545679
  validation accuracy:		90.87 %
Epoch 1291 of 2000 took 0.057s
  training loss:		0.012716
  validation loss:		0.544927
  validation accuracy:		90.98 %
Epoch 1292 of 2000 took 0.057s
  training loss:		0.012876
  validation loss:		0.539504
  validation accuracy:		91.20 %
Epoch 1293 of 2000 took 0.058s
  training loss:		0.012777
  validation loss:		0.541349
  validation accuracy:		90.65 %
Epoch 1294 of 2000 took 0.058s
  training loss:		0.012515
  validation loss:		0.529874
  validation accuracy:		91.20 %
Epoch 1295 of 2000 took 0.058s
  training loss:		0.012665
  validation loss:		0.539734
  validation accuracy:		90.54 %
Epoch 1296 of 2000 took 0.058s
  training loss:		0.012808
  validation loss:		0.531709
  validation accuracy:		91.09 %
Epoch 1297 of 2000 took 0.058s
  training loss:		0.012632
  validation loss:		0.544975
  validation accuracy:		90.54 %
Epoch 1298 of 2000 took 0.058s
  training loss:		0.012955
  validation loss:		0.538155
  validation accuracy:		91.52 %
Epoch 1299 of 2000 took 0.057s
  training loss:		0.012312
  validation loss:		0.543332
  validation accuracy:		90.65 %
Epoch 1300 of 2000 took 0.057s
  training loss:		0.013841
  validation loss:		0.538658
  validation accuracy:		91.30 %
Epoch 1301 of 2000 took 0.057s
  training loss:		0.013848
  validation loss:		0.543779
  validation accuracy:		90.98 %
Epoch 1302 of 2000 took 0.057s
  training loss:		0.013422
  validation loss:		0.555306
  validation accuracy:		90.65 %
Epoch 1303 of 2000 took 0.057s
  training loss:		0.012601
  validation loss:		0.550090
  validation accuracy:		91.09 %
Epoch 1304 of 2000 took 0.057s
  training loss:		0.012470
  validation loss:		0.541294
  validation accuracy:		90.54 %
Epoch 1305 of 2000 took 0.057s
  training loss:		0.012220
  validation loss:		0.550375
  validation accuracy:		90.98 %
Epoch 1306 of 2000 took 0.057s
  training loss:		0.012572
  validation loss:		0.558460
  validation accuracy:		90.65 %
Epoch 1307 of 2000 took 0.057s
  training loss:		0.012499
  validation loss:		0.541713
  validation accuracy:		90.87 %
Epoch 1308 of 2000 took 0.057s
  training loss:		0.012668
  validation loss:		0.540022
  validation accuracy:		90.87 %
Epoch 1309 of 2000 took 0.057s
  training loss:		0.012730
  validation loss:		0.538486
  validation accuracy:		90.98 %
Epoch 1310 of 2000 took 0.058s
  training loss:		0.012739
  validation loss:		0.552300
  validation accuracy:		90.87 %
Epoch 1311 of 2000 took 0.058s
  training loss:		0.012120
  validation loss:		0.545976
  validation accuracy:		91.20 %
Epoch 1312 of 2000 took 0.058s
  training loss:		0.011952
  validation loss:		0.549278
  validation accuracy:		91.20 %
Epoch 1313 of 2000 took 0.058s
  training loss:		0.012295
  validation loss:		0.547501
  validation accuracy:		90.87 %
Epoch 1314 of 2000 took 0.058s
  training loss:		0.012198
  validation loss:		0.547686
  validation accuracy:		90.87 %
Epoch 1315 of 2000 took 0.056s
  training loss:		0.012313
  validation loss:		0.553380
  validation accuracy:		90.65 %
Epoch 1316 of 2000 took 0.057s
  training loss:		0.012238
  validation loss:		0.541780
  validation accuracy:		91.09 %
Epoch 1317 of 2000 took 0.057s
  training loss:		0.012237
  validation loss:		0.551007
  validation accuracy:		90.76 %
Epoch 1318 of 2000 took 0.057s
  training loss:		0.012011
  validation loss:		0.557229
  validation accuracy:		91.09 %
Epoch 1319 of 2000 took 0.057s
  training loss:		0.012003
  validation loss:		0.553586
  validation accuracy:		90.65 %
Epoch 1320 of 2000 took 0.057s
  training loss:		0.012220
  validation loss:		0.554045
  validation accuracy:		90.87 %
Epoch 1321 of 2000 took 0.057s
  training loss:		0.012098
  validation loss:		0.548268
  validation accuracy:		90.87 %
Epoch 1322 of 2000 took 0.057s
  training loss:		0.012014
  validation loss:		0.537606
  validation accuracy:		91.30 %
Epoch 1323 of 2000 took 0.057s
  training loss:		0.012422
  validation loss:		0.549673
  validation accuracy:		91.09 %
Epoch 1324 of 2000 took 0.057s
  training loss:		0.011976
  validation loss:		0.545662
  validation accuracy:		91.20 %
Epoch 1325 of 2000 took 0.057s
  training loss:		0.011998
  validation loss:		0.553636
  validation accuracy:		90.98 %
Epoch 1326 of 2000 took 0.055s
  training loss:		0.012488
  validation loss:		0.543709
  validation accuracy:		90.98 %
Epoch 1327 of 2000 took 0.057s
  training loss:		0.011897
  validation loss:		0.558855
  validation accuracy:		90.87 %
Epoch 1328 of 2000 took 0.057s
  training loss:		0.011754
  validation loss:		0.553315
  validation accuracy:		90.65 %
Epoch 1329 of 2000 took 0.057s
  training loss:		0.011808
  validation loss:		0.548383
  validation accuracy:		90.98 %
Epoch 1330 of 2000 took 0.055s
  training loss:		0.011841
  validation loss:		0.566180
  validation accuracy:		90.76 %
Epoch 1331 of 2000 took 0.057s
  training loss:		0.012246
  validation loss:		0.564318
  validation accuracy:		90.98 %
Epoch 1332 of 2000 took 0.056s
  training loss:		0.012114
  validation loss:		0.553721
  validation accuracy:		90.65 %
Epoch 1333 of 2000 took 0.057s
  training loss:		0.011660
  validation loss:		0.553999
  validation accuracy:		90.98 %
Epoch 1334 of 2000 took 0.057s
  training loss:		0.011611
  validation loss:		0.566039
  validation accuracy:		90.54 %
Epoch 1335 of 2000 took 0.056s
  training loss:		0.012054
  validation loss:		0.560871
  validation accuracy:		91.09 %
Epoch 1336 of 2000 took 0.056s
  training loss:		0.011485
  validation loss:		0.551670
  validation accuracy:		91.09 %
Epoch 1337 of 2000 took 0.055s
  training loss:		0.011841
  validation loss:		0.552614
  validation accuracy:		91.09 %
Epoch 1338 of 2000 took 0.057s
  training loss:		0.011432
  validation loss:		0.551859
  validation accuracy:		90.65 %
Epoch 1339 of 2000 took 0.056s
  training loss:		0.011881
  validation loss:		0.557756
  validation accuracy:		90.98 %
Epoch 1340 of 2000 took 0.057s
  training loss:		0.011761
  validation loss:		0.547952
  validation accuracy:		90.98 %
Epoch 1341 of 2000 took 0.057s
  training loss:		0.011840
  validation loss:		0.564299
  validation accuracy:		91.30 %
Epoch 1342 of 2000 took 0.057s
  training loss:		0.011309
  validation loss:		0.558631
  validation accuracy:		91.20 %
Epoch 1343 of 2000 took 0.056s
  training loss:		0.011683
  validation loss:		0.552867
  validation accuracy:		91.41 %
Epoch 1344 of 2000 took 0.057s
  training loss:		0.011700
  validation loss:		0.567406
  validation accuracy:		90.54 %
Epoch 1345 of 2000 took 0.055s
  training loss:		0.011493
  validation loss:		0.554677
  validation accuracy:		90.98 %
Epoch 1346 of 2000 took 0.055s
  training loss:		0.010963
  validation loss:		0.570675
  validation accuracy:		90.65 %
Epoch 1347 of 2000 took 0.055s
  training loss:		0.011182
  validation loss:		0.559142
  validation accuracy:		90.98 %
Epoch 1348 of 2000 took 0.056s
  training loss:		0.011286
  validation loss:		0.574705
  validation accuracy:		90.54 %
Epoch 1349 of 2000 took 0.055s
  training loss:		0.011249
  validation loss:		0.568696
  validation accuracy:		90.76 %
Epoch 1350 of 2000 took 0.055s
  training loss:		0.011476
  validation loss:		0.568860
  validation accuracy:		90.76 %
Epoch 1351 of 2000 took 0.054s
  training loss:		0.011389
  validation loss:		0.564569
  validation accuracy:		90.87 %
Epoch 1352 of 2000 took 0.055s
  training loss:		0.010930
  validation loss:		0.557076
  validation accuracy:		91.09 %
Epoch 1353 of 2000 took 0.057s
  training loss:		0.011319
  validation loss:		0.556871
  validation accuracy:		91.20 %
Epoch 1354 of 2000 took 0.053s
  training loss:		0.010867
  validation loss:		0.569620
  validation accuracy:		90.87 %
Epoch 1355 of 2000 took 0.054s
  training loss:		0.011095
  validation loss:		0.568194
  validation accuracy:		90.87 %
Epoch 1356 of 2000 took 0.053s
  training loss:		0.011347
  validation loss:		0.577916
  validation accuracy:		91.09 %
Epoch 1357 of 2000 took 0.057s
  training loss:		0.011148
  validation loss:		0.558249
  validation accuracy:		91.09 %
Epoch 1358 of 2000 took 0.057s
  training loss:		0.010999
  validation loss:		0.558418
  validation accuracy:		90.76 %
Epoch 1359 of 2000 took 0.054s
  training loss:		0.011279
  validation loss:		0.566889
  validation accuracy:		90.76 %
Epoch 1360 of 2000 took 0.055s
  training loss:		0.011313
  validation loss:		0.569861
  validation accuracy:		90.54 %
Epoch 1361 of 2000 took 0.057s
  training loss:		0.011473
  validation loss:		0.567118
  validation accuracy:		90.76 %
Epoch 1362 of 2000 took 0.055s
  training loss:		0.011166
  validation loss:		0.568291
  validation accuracy:		90.98 %
Epoch 1363 of 2000 took 0.056s
  training loss:		0.010831
  validation loss:		0.574073
  validation accuracy:		90.98 %
Epoch 1364 of 2000 took 0.055s
  training loss:		0.011150
  validation loss:		0.562788
  validation accuracy:		90.76 %
Epoch 1365 of 2000 took 0.055s
  training loss:		0.010825
  validation loss:		0.570009
  validation accuracy:		90.87 %
Epoch 1366 of 2000 took 0.054s
  training loss:		0.010956
  validation loss:		0.567632
  validation accuracy:		91.09 %
Epoch 1367 of 2000 took 0.055s
  training loss:		0.010884
  validation loss:		0.562312
  validation accuracy:		90.65 %
Epoch 1368 of 2000 took 0.054s
  training loss:		0.010515
  validation loss:		0.573460
  validation accuracy:		90.87 %
Epoch 1369 of 2000 took 0.056s
  training loss:		0.010864
  validation loss:		0.561087
  validation accuracy:		91.20 %
Epoch 1370 of 2000 took 0.057s
  training loss:		0.010382
  validation loss:		0.562437
  validation accuracy:		91.20 %
Epoch 1371 of 2000 took 0.057s
  training loss:		0.010849
  validation loss:		0.570734
  validation accuracy:		90.76 %
Epoch 1372 of 2000 took 0.057s
  training loss:		0.011186
  validation loss:		0.579762
  validation accuracy:		90.33 %
Epoch 1373 of 2000 took 0.057s
  training loss:		0.010943
  validation loss:		0.573644
  validation accuracy:		90.76 %
Epoch 1374 of 2000 took 0.055s
  training loss:		0.010478
  validation loss:		0.575923
  validation accuracy:		90.65 %
Epoch 1375 of 2000 took 0.054s
  training loss:		0.010651
  validation loss:		0.565396
  validation accuracy:		91.20 %
Epoch 1376 of 2000 took 0.055s
  training loss:		0.010981
  validation loss:		0.564943
  validation accuracy:		90.76 %
Epoch 1377 of 2000 took 0.057s
  training loss:		0.011128
  validation loss:		0.568467
  validation accuracy:		90.76 %
Epoch 1378 of 2000 took 0.057s
  training loss:		0.010809
  validation loss:		0.563893
  validation accuracy:		90.98 %
Epoch 1379 of 2000 took 0.057s
  training loss:		0.010608
  validation loss:		0.572443
  validation accuracy:		90.98 %
Epoch 1380 of 2000 took 0.057s
  training loss:		0.010250
  validation loss:		0.565759
  validation accuracy:		91.20 %
Epoch 1381 of 2000 took 0.057s
  training loss:		0.010540
  validation loss:		0.572615
  validation accuracy:		91.09 %
Epoch 1382 of 2000 took 0.057s
  training loss:		0.011052
  validation loss:		0.562003
  validation accuracy:		91.09 %
Epoch 1383 of 2000 took 0.057s
  training loss:		0.010857
  validation loss:		0.576549
  validation accuracy:		90.65 %
Epoch 1384 of 2000 took 0.057s
  training loss:		0.010898
  validation loss:		0.579946
  validation accuracy:		90.65 %
Epoch 1385 of 2000 took 0.057s
  training loss:		0.010448
  validation loss:		0.570567
  validation accuracy:		90.98 %
Epoch 1386 of 2000 took 0.057s
  training loss:		0.009860
  validation loss:		0.562103
  validation accuracy:		91.20 %
Epoch 1387 of 2000 took 0.057s
  training loss:		0.010788
  validation loss:		0.574018
  validation accuracy:		90.87 %
Epoch 1388 of 2000 took 0.057s
  training loss:		0.010449
  validation loss:		0.576019
  validation accuracy:		91.20 %
Epoch 1389 of 2000 took 0.055s
  training loss:		0.010551
  validation loss:		0.569528
  validation accuracy:		90.65 %
Epoch 1390 of 2000 took 0.057s
  training loss:		0.010219
  validation loss:		0.579123
  validation accuracy:		91.09 %
Epoch 1391 of 2000 took 0.057s
  training loss:		0.010919
  validation loss:		0.583402
  validation accuracy:		90.76 %
Epoch 1392 of 2000 took 0.055s
  training loss:		0.010416
  validation loss:		0.570624
  validation accuracy:		90.87 %
Epoch 1393 of 2000 took 0.057s
  training loss:		0.010290
  validation loss:		0.575807
  validation accuracy:		90.87 %
Epoch 1394 of 2000 took 0.056s
  training loss:		0.010317
  validation loss:		0.572845
  validation accuracy:		91.09 %
Epoch 1395 of 2000 took 0.057s
  training loss:		0.010568
  validation loss:		0.578048
  validation accuracy:		90.76 %
Epoch 1396 of 2000 took 0.056s
  training loss:		0.010415
  validation loss:		0.576369
  validation accuracy:		90.87 %
Epoch 1397 of 2000 took 0.057s
  training loss:		0.010563
  validation loss:		0.577973
  validation accuracy:		90.87 %
Epoch 1398 of 2000 took 0.057s
  training loss:		0.009837
  validation loss:		0.585661
  validation accuracy:		90.87 %
Epoch 1399 of 2000 took 0.057s
  training loss:		0.010197
  validation loss:		0.572642
  validation accuracy:		90.65 %
Epoch 1400 of 2000 took 0.057s
  training loss:		0.010338
  validation loss:		0.580217
  validation accuracy:		90.65 %
Epoch 1401 of 2000 took 0.057s
  training loss:		0.009937
  validation loss:		0.579633
  validation accuracy:		90.87 %
Epoch 1402 of 2000 took 0.057s
  training loss:		0.010067
  validation loss:		0.579413
  validation accuracy:		90.98 %
Epoch 1403 of 2000 took 0.057s
  training loss:		0.009942
  validation loss:		0.579374
  validation accuracy:		90.98 %
Epoch 1404 of 2000 took 0.058s
  training loss:		0.010037
  validation loss:		0.576471
  validation accuracy:		90.87 %
Epoch 1405 of 2000 took 0.058s
  training loss:		0.010197
  validation loss:		0.576690
  validation accuracy:		91.20 %
Epoch 1406 of 2000 took 0.058s
  training loss:		0.009852
  validation loss:		0.588292
  validation accuracy:		90.87 %
Epoch 1407 of 2000 took 0.058s
  training loss:		0.009862
  validation loss:		0.588777
  validation accuracy:		90.87 %
Epoch 1408 of 2000 took 0.057s
  training loss:		0.010535
  validation loss:		0.576854
  validation accuracy:		91.20 %
Epoch 1409 of 2000 took 0.057s
  training loss:		0.010187
  validation loss:		0.585278
  validation accuracy:		90.76 %
Epoch 1410 of 2000 took 0.057s
  training loss:		0.010241
  validation loss:		0.586494
  validation accuracy:		90.87 %
Epoch 1411 of 2000 took 0.057s
  training loss:		0.010159
  validation loss:		0.582971
  validation accuracy:		90.76 %
Epoch 1412 of 2000 took 0.057s
  training loss:		0.010614
  validation loss:		0.575377
  validation accuracy:		90.98 %
Epoch 1413 of 2000 took 0.057s
  training loss:		0.009730
  validation loss:		0.576604
  validation accuracy:		91.20 %
Epoch 1414 of 2000 took 0.057s
  training loss:		0.009796
  validation loss:		0.589823
  validation accuracy:		90.87 %
Epoch 1415 of 2000 took 0.057s
  training loss:		0.009891
  validation loss:		0.584108
  validation accuracy:		91.09 %
Epoch 1416 of 2000 took 0.057s
  training loss:		0.009781
  validation loss:		0.581518
  validation accuracy:		91.20 %
Epoch 1417 of 2000 took 0.056s
  training loss:		0.009757
  validation loss:		0.591845
  validation accuracy:		90.76 %
Epoch 1418 of 2000 took 0.057s
  training loss:		0.009578
  validation loss:		0.590696
  validation accuracy:		90.98 %
Epoch 1419 of 2000 took 0.057s
  training loss:		0.010248
  validation loss:		0.592213
  validation accuracy:		90.65 %
Epoch 1420 of 2000 took 0.057s
  training loss:		0.009817
  validation loss:		0.585706
  validation accuracy:		90.54 %
Epoch 1421 of 2000 took 0.057s
  training loss:		0.009697
  validation loss:		0.600725
  validation accuracy:		90.65 %
Epoch 1422 of 2000 took 0.057s
  training loss:		0.009457
  validation loss:		0.589736
  validation accuracy:		90.87 %
Epoch 1423 of 2000 took 0.058s
  training loss:		0.009789
  validation loss:		0.585063
  validation accuracy:		90.98 %
Epoch 1424 of 2000 took 0.057s
  training loss:		0.009623
  validation loss:		0.606610
  validation accuracy:		90.54 %
Epoch 1425 of 2000 took 0.056s
  training loss:		0.009867
  validation loss:		0.585057
  validation accuracy:		90.98 %
Epoch 1426 of 2000 took 0.058s
  training loss:		0.009541
  validation loss:		0.584511
  validation accuracy:		91.09 %
Epoch 1427 of 2000 took 0.057s
  training loss:		0.009353
  validation loss:		0.579528
  validation accuracy:		91.20 %
Epoch 1428 of 2000 took 0.057s
  training loss:		0.009674
  validation loss:		0.581754
  validation accuracy:		90.87 %
Epoch 1429 of 2000 took 0.056s
  training loss:		0.009418
  validation loss:		0.581940
  validation accuracy:		91.09 %
Epoch 1430 of 2000 took 0.057s
  training loss:		0.009194
  validation loss:		0.582438
  validation accuracy:		90.87 %
Epoch 1431 of 2000 took 0.057s
  training loss:		0.009504
  validation loss:		0.581916
  validation accuracy:		91.20 %
Epoch 1432 of 2000 took 0.057s
  training loss:		0.009635
  validation loss:		0.585163
  validation accuracy:		91.20 %
Epoch 1433 of 2000 took 0.057s
  training loss:		0.009055
  validation loss:		0.588899
  validation accuracy:		90.65 %
Epoch 1434 of 2000 took 0.057s
  training loss:		0.009555
  validation loss:		0.587911
  validation accuracy:		91.09 %
Epoch 1435 of 2000 took 0.057s
  training loss:		0.009215
  validation loss:		0.593713
  validation accuracy:		90.98 %
Epoch 1436 of 2000 took 0.057s
  training loss:		0.009040
  validation loss:		0.591757
  validation accuracy:		90.98 %
Epoch 1437 of 2000 took 0.057s
  training loss:		0.009070
  validation loss:		0.586427
  validation accuracy:		91.20 %
Epoch 1438 of 2000 took 0.057s
  training loss:		0.009422
  validation loss:		0.592134
  validation accuracy:		90.76 %
Epoch 1439 of 2000 took 0.057s
  training loss:		0.009477
  validation loss:		0.606700
  validation accuracy:		90.65 %
Epoch 1440 of 2000 took 0.055s
  training loss:		0.009406
  validation loss:		0.580307
  validation accuracy:		91.52 %
Epoch 1441 of 2000 took 0.057s
  training loss:		0.009138
  validation loss:		0.597752
  validation accuracy:		90.76 %
Epoch 1442 of 2000 took 0.055s
  training loss:		0.009538
  validation loss:		0.596220
  validation accuracy:		90.98 %
Epoch 1443 of 2000 took 0.057s
  training loss:		0.009278
  validation loss:		0.594405
  validation accuracy:		90.65 %
Epoch 1444 of 2000 took 0.057s
  training loss:		0.008758
  validation loss:		0.590300
  validation accuracy:		90.98 %
Epoch 1445 of 2000 took 0.057s
  training loss:		0.009879
  validation loss:		0.591245
  validation accuracy:		91.09 %
Epoch 1446 of 2000 took 0.057s
  training loss:		0.008749
  validation loss:		0.593463
  validation accuracy:		90.65 %
Epoch 1447 of 2000 took 0.055s
  training loss:		0.009391
  validation loss:		0.595650
  validation accuracy:		91.20 %
Epoch 1448 of 2000 took 0.057s
  training loss:		0.009217
  validation loss:		0.591202
  validation accuracy:		90.87 %
Epoch 1449 of 2000 took 0.057s
  training loss:		0.009265
  validation loss:		0.601804
  validation accuracy:		90.87 %
Epoch 1450 of 2000 took 0.057s
  training loss:		0.008987
  validation loss:		0.589382
  validation accuracy:		91.09 %
Epoch 1451 of 2000 took 0.057s
  training loss:		0.009443
  validation loss:		0.599743
  validation accuracy:		90.87 %
Epoch 1452 of 2000 took 0.057s
  training loss:		0.009114
  validation loss:		0.598693
  validation accuracy:		90.98 %
Epoch 1453 of 2000 took 0.057s
  training loss:		0.009340
  validation loss:		0.604348
  validation accuracy:		90.87 %
Epoch 1454 of 2000 took 0.057s
  training loss:		0.009634
  validation loss:		0.595590
  validation accuracy:		90.98 %
Epoch 1455 of 2000 took 0.057s
  training loss:		0.008972
  validation loss:		0.599140
  validation accuracy:		90.65 %
Epoch 1456 of 2000 took 0.057s
  training loss:		0.009102
  validation loss:		0.593244
  validation accuracy:		90.87 %
Epoch 1457 of 2000 took 0.057s
  training loss:		0.009052
  validation loss:		0.593709
  validation accuracy:		91.09 %
Epoch 1458 of 2000 took 0.057s
  training loss:		0.008579
  validation loss:		0.599695
  validation accuracy:		90.65 %
Epoch 1459 of 2000 took 0.056s
  training loss:		0.009160
  validation loss:		0.603072
  validation accuracy:		90.65 %
Epoch 1460 of 2000 took 0.056s
  training loss:		0.009182
  validation loss:		0.594809
  validation accuracy:		90.76 %
Epoch 1461 of 2000 took 0.055s
  training loss:		0.009071
  validation loss:		0.592579
  validation accuracy:		91.09 %
Epoch 1462 of 2000 took 0.058s
  training loss:		0.009016
  validation loss:		0.607814
  validation accuracy:		90.65 %
Epoch 1463 of 2000 took 0.056s
  training loss:		0.009044
  validation loss:		0.604004
  validation accuracy:		90.65 %
Epoch 1464 of 2000 took 0.057s
  training loss:		0.008617
  validation loss:		0.602405
  validation accuracy:		90.65 %
Epoch 1465 of 2000 took 0.056s
  training loss:		0.008896
  validation loss:		0.595902
  validation accuracy:		90.98 %
Epoch 1466 of 2000 took 0.056s
  training loss:		0.008800
  validation loss:		0.597875
  validation accuracy:		91.20 %
Epoch 1467 of 2000 took 0.056s
  training loss:		0.009269
  validation loss:		0.597210
  validation accuracy:		90.98 %
Epoch 1468 of 2000 took 0.057s
  training loss:		0.009038
  validation loss:		0.601031
  validation accuracy:		91.09 %
Epoch 1469 of 2000 took 0.056s
  training loss:		0.008726
  validation loss:		0.605868
  validation accuracy:		90.87 %
Epoch 1470 of 2000 took 0.056s
  training loss:		0.008834
  validation loss:		0.591680
  validation accuracy:		91.20 %
Epoch 1471 of 2000 took 0.057s
  training loss:		0.008761
  validation loss:		0.607488
  validation accuracy:		90.98 %
Epoch 1472 of 2000 took 0.055s
  training loss:		0.008674
  validation loss:		0.613232
  validation accuracy:		90.87 %
Epoch 1473 of 2000 took 0.055s
  training loss:		0.009011
  validation loss:		0.606472
  validation accuracy:		90.65 %
Epoch 1474 of 2000 took 0.057s
  training loss:		0.009089
  validation loss:		0.589951
  validation accuracy:		91.20 %
Epoch 1475 of 2000 took 0.055s
  training loss:		0.008776
  validation loss:		0.602108
  validation accuracy:		90.76 %
Epoch 1476 of 2000 took 0.056s
  training loss:		0.008998
  validation loss:		0.599834
  validation accuracy:		90.76 %
Epoch 1477 of 2000 took 0.055s
  training loss:		0.008906
  validation loss:		0.605516
  validation accuracy:		90.76 %
Epoch 1478 of 2000 took 0.056s
  training loss:		0.008498
  validation loss:		0.603873
  validation accuracy:		90.43 %
Epoch 1479 of 2000 took 0.055s
  training loss:		0.008946
  validation loss:		0.603602
  validation accuracy:		90.98 %
Epoch 1480 of 2000 took 0.056s
  training loss:		0.008469
  validation loss:		0.597070
  validation accuracy:		91.20 %
Epoch 1481 of 2000 took 0.056s
  training loss:		0.008608
  validation loss:		0.596731
  validation accuracy:		91.20 %
Epoch 1482 of 2000 took 0.055s
  training loss:		0.008835
  validation loss:		0.600027
  validation accuracy:		90.98 %
Epoch 1483 of 2000 took 0.056s
  training loss:		0.008668
  validation loss:		0.606208
  validation accuracy:		90.87 %
Epoch 1484 of 2000 took 0.055s
  training loss:		0.008394
  validation loss:		0.611076
  validation accuracy:		90.87 %
Epoch 1485 of 2000 took 0.056s
  training loss:		0.008962
  validation loss:		0.606342
  validation accuracy:		90.87 %
Epoch 1486 of 2000 took 0.058s
  training loss:		0.008549
  validation loss:		0.612459
  validation accuracy:		90.65 %
Epoch 1487 of 2000 took 0.058s
  training loss:		0.008668
  validation loss:		0.609523
  validation accuracy:		90.76 %
Epoch 1488 of 2000 took 0.058s
  training loss:		0.008549
  validation loss:		0.608548
  validation accuracy:		90.98 %
Epoch 1489 of 2000 took 0.058s
  training loss:		0.008582
  validation loss:		0.610795
  validation accuracy:		90.87 %
Epoch 1490 of 2000 took 0.058s
  training loss:		0.008408
  validation loss:		0.603725
  validation accuracy:		90.98 %
Epoch 1491 of 2000 took 0.058s
  training loss:		0.008382
  validation loss:		0.610704
  validation accuracy:		90.87 %
Epoch 1492 of 2000 took 0.058s
  training loss:		0.008411
  validation loss:		0.602161
  validation accuracy:		90.98 %
Epoch 1493 of 2000 took 0.057s
  training loss:		0.008670
  validation loss:		0.617366
  validation accuracy:		90.65 %
Epoch 1494 of 2000 took 0.057s
  training loss:		0.008418
  validation loss:		0.610171
  validation accuracy:		91.09 %
Epoch 1495 of 2000 took 0.057s
  training loss:		0.008713
  validation loss:		0.602153
  validation accuracy:		91.09 %
Epoch 1496 of 2000 took 0.057s
  training loss:		0.008125
  validation loss:		0.607681
  validation accuracy:		91.09 %
Epoch 1497 of 2000 took 0.057s
  training loss:		0.008199
  validation loss:		0.602254
  validation accuracy:		90.98 %
Epoch 1498 of 2000 took 0.057s
  training loss:		0.008064
  validation loss:		0.615351
  validation accuracy:		90.65 %
Epoch 1499 of 2000 took 0.057s
  training loss:		0.008375
  validation loss:		0.618282
  validation accuracy:		90.76 %
Epoch 1500 of 2000 took 0.057s
  training loss:		0.008487
  validation loss:		0.605720
  validation accuracy:		90.76 %
Epoch 1501 of 2000 took 0.057s
  training loss:		0.008206
  validation loss:		0.617894
  validation accuracy:		90.98 %
Epoch 1502 of 2000 took 0.058s
  training loss:		0.008310
  validation loss:		0.603148
  validation accuracy:		90.87 %
Epoch 1503 of 2000 took 0.057s
  training loss:		0.008431
  validation loss:		0.614338
  validation accuracy:		90.87 %
Epoch 1504 of 2000 took 0.057s
  training loss:		0.008154
  validation loss:		0.617143
  validation accuracy:		90.65 %
Epoch 1505 of 2000 took 0.058s
  training loss:		0.008423
  validation loss:		0.619104
  validation accuracy:		90.87 %
Epoch 1506 of 2000 took 0.057s
  training loss:		0.008464
  validation loss:		0.619383
  validation accuracy:		90.65 %
Epoch 1507 of 2000 took 0.058s
  training loss:		0.008275
  validation loss:		0.607545
  validation accuracy:		90.65 %
Epoch 1508 of 2000 took 0.057s
  training loss:		0.008331
  validation loss:		0.605757
  validation accuracy:		91.09 %
Epoch 1509 of 2000 took 0.057s
  training loss:		0.008206
  validation loss:		0.609348
  validation accuracy:		90.98 %
Epoch 1510 of 2000 took 0.057s
  training loss:		0.008600
  validation loss:		0.600403
  validation accuracy:		90.98 %
Epoch 1511 of 2000 took 0.057s
  training loss:		0.008349
  validation loss:		0.608832
  validation accuracy:		91.09 %
Epoch 1512 of 2000 took 0.057s
  training loss:		0.008188
  validation loss:		0.611694
  validation accuracy:		90.87 %
Epoch 1513 of 2000 took 0.058s
  training loss:		0.008148
  validation loss:		0.614529
  validation accuracy:		90.65 %
Epoch 1514 of 2000 took 0.057s
  training loss:		0.008187
  validation loss:		0.608023
  validation accuracy:		90.87 %
Epoch 1515 of 2000 took 0.058s
  training loss:		0.008084
  validation loss:		0.611494
  validation accuracy:		90.87 %
Epoch 1516 of 2000 took 0.057s
  training loss:		0.008085
  validation loss:		0.624240
  validation accuracy:		90.65 %
Epoch 1517 of 2000 took 0.057s
  training loss:		0.008100
  validation loss:		0.618323
  validation accuracy:		90.65 %
Epoch 1518 of 2000 took 0.057s
  training loss:		0.007842
  validation loss:		0.611495
  validation accuracy:		90.98 %
Epoch 1519 of 2000 took 0.058s
  training loss:		0.008031
  validation loss:		0.620374
  validation accuracy:		90.76 %
Epoch 1520 of 2000 took 0.057s
  training loss:		0.007860
  validation loss:		0.616384
  validation accuracy:		91.20 %
Epoch 1521 of 2000 took 0.057s
  training loss:		0.007846
  validation loss:		0.619625
  validation accuracy:		91.09 %
Epoch 1522 of 2000 took 0.057s
  training loss:		0.008167
  validation loss:		0.620765
  validation accuracy:		90.76 %
Epoch 1523 of 2000 took 0.057s
  training loss:		0.007926
  validation loss:		0.610849
  validation accuracy:		91.09 %
Epoch 1524 of 2000 took 0.057s
  training loss:		0.007993
  validation loss:		0.620736
  validation accuracy:		90.98 %
Epoch 1525 of 2000 took 0.055s
  training loss:		0.007564
  validation loss:		0.611931
  validation accuracy:		90.76 %
Epoch 1526 of 2000 took 0.055s
  training loss:		0.007944
  validation loss:		0.614631
  validation accuracy:		90.98 %
Epoch 1527 of 2000 took 0.055s
  training loss:		0.007733
  validation loss:		0.621110
  validation accuracy:		91.30 %
Epoch 1528 of 2000 took 0.057s
  training loss:		0.008126
  validation loss:		0.619151
  validation accuracy:		90.87 %
Epoch 1529 of 2000 took 0.057s
  training loss:		0.008173
  validation loss:		0.609351
  validation accuracy:		90.87 %
Epoch 1530 of 2000 took 0.057s
  training loss:		0.008181
  validation loss:		0.613234
  validation accuracy:		91.20 %
Epoch 1531 of 2000 took 0.057s
  training loss:		0.007828
  validation loss:		0.622241
  validation accuracy:		90.87 %
Epoch 1532 of 2000 took 0.057s
  training loss:		0.007698
  validation loss:		0.618478
  validation accuracy:		91.09 %
Epoch 1533 of 2000 took 0.057s
  training loss:		0.007707
  validation loss:		0.625095
  validation accuracy:		90.76 %
Epoch 1534 of 2000 took 0.057s
  training loss:		0.007616
  validation loss:		0.619690
  validation accuracy:		90.87 %
Epoch 1535 of 2000 took 0.057s
  training loss:		0.007663
  validation loss:		0.627201
  validation accuracy:		90.65 %
Epoch 1536 of 2000 took 0.057s
  training loss:		0.007614
  validation loss:		0.621828
  validation accuracy:		90.87 %
Epoch 1537 of 2000 took 0.056s
  training loss:		0.007621
  validation loss:		0.614726
  validation accuracy:		91.09 %
Epoch 1538 of 2000 took 0.057s
  training loss:		0.007721
  validation loss:		0.623174
  validation accuracy:		90.76 %
Epoch 1539 of 2000 took 0.057s
  training loss:		0.007836
  validation loss:		0.621037
  validation accuracy:		90.76 %
Epoch 1540 of 2000 took 0.057s
  training loss:		0.007773
  validation loss:		0.614782
  validation accuracy:		90.98 %
Epoch 1541 of 2000 took 0.057s
  training loss:		0.007705
  validation loss:		0.617739
  validation accuracy:		91.09 %
Epoch 1542 of 2000 took 0.057s
  training loss:		0.008086
  validation loss:		0.621359
  validation accuracy:		91.09 %
Epoch 1543 of 2000 took 0.057s
  training loss:		0.007887
  validation loss:		0.622006
  validation accuracy:		91.09 %
Epoch 1544 of 2000 took 0.057s
  training loss:		0.007885
  validation loss:		0.631119
  validation accuracy:		90.65 %
Epoch 1545 of 2000 took 0.057s
  training loss:		0.007848
  validation loss:		0.625211
  validation accuracy:		90.76 %
Epoch 1546 of 2000 took 0.057s
  training loss:		0.007499
  validation loss:		0.623913
  validation accuracy:		90.98 %
Epoch 1547 of 2000 took 0.057s
  training loss:		0.007807
  validation loss:		0.627449
  validation accuracy:		91.09 %
Epoch 1548 of 2000 took 0.057s
  training loss:		0.008106
  validation loss:		0.627961
  validation accuracy:		90.98 %
Epoch 1549 of 2000 took 0.057s
  training loss:		0.007670
  validation loss:		0.624955
  validation accuracy:		90.87 %
Epoch 1550 of 2000 took 0.057s
  training loss:		0.007436
  validation loss:		0.630180
  validation accuracy:		90.76 %
Epoch 1551 of 2000 took 0.055s
  training loss:		0.007632
  validation loss:		0.618289
  validation accuracy:		90.87 %
Epoch 1552 of 2000 took 0.057s
  training loss:		0.007458
  validation loss:		0.625119
  validation accuracy:		90.76 %
Epoch 1553 of 2000 took 0.057s
  training loss:		0.007600
  validation loss:		0.624175
  validation accuracy:		91.09 %
Epoch 1554 of 2000 took 0.057s
  training loss:		0.007457
  validation loss:		0.626314
  validation accuracy:		90.98 %
Epoch 1555 of 2000 took 0.055s
  training loss:		0.007473
  validation loss:		0.623863
  validation accuracy:		90.98 %
Epoch 1556 of 2000 took 0.057s
  training loss:		0.007633
  validation loss:		0.629574
  validation accuracy:		90.98 %
Epoch 1557 of 2000 took 0.057s
  training loss:		0.007638
  validation loss:		0.627651
  validation accuracy:		90.87 %
Epoch 1558 of 2000 took 0.055s
  training loss:		0.007435
  validation loss:		0.633307
  validation accuracy:		90.98 %
Epoch 1559 of 2000 took 0.057s
  training loss:		0.007497
  validation loss:		0.623110
  validation accuracy:		90.98 %
Epoch 1560 of 2000 took 0.057s
  training loss:		0.007664
  validation loss:		0.627367
  validation accuracy:		90.98 %
Epoch 1561 of 2000 took 0.057s
  training loss:		0.007276
  validation loss:		0.632182
  validation accuracy:		90.87 %
Epoch 1562 of 2000 took 0.056s
  training loss:		0.007497
  validation loss:		0.632327
  validation accuracy:		90.76 %
Epoch 1563 of 2000 took 0.057s
  training loss:		0.007560
  validation loss:		0.635186
  validation accuracy:		90.87 %
Epoch 1564 of 2000 took 0.056s
  training loss:		0.007524
  validation loss:		0.634107
  validation accuracy:		90.76 %
Epoch 1565 of 2000 took 0.057s
  training loss:		0.007336
  validation loss:		0.632559
  validation accuracy:		90.87 %
Epoch 1566 of 2000 took 0.057s
  training loss:		0.007336
  validation loss:		0.636820
  validation accuracy:		90.98 %
Epoch 1567 of 2000 took 0.057s
  training loss:		0.007564
  validation loss:		0.624907
  validation accuracy:		90.87 %
Epoch 1568 of 2000 took 0.057s
  training loss:		0.007474
  validation loss:		0.628576
  validation accuracy:		90.76 %
Epoch 1569 of 2000 took 0.057s
  training loss:		0.007800
  validation loss:		0.620479
  validation accuracy:		90.98 %
Epoch 1570 of 2000 took 0.057s
  training loss:		0.007573
  validation loss:		0.630520
  validation accuracy:		90.76 %
Epoch 1571 of 2000 took 0.057s
  training loss:		0.007079
  validation loss:		0.639800
  validation accuracy:		90.87 %
Epoch 1572 of 2000 took 0.057s
  training loss:		0.007284
  validation loss:		0.633935
  validation accuracy:		90.87 %
Epoch 1573 of 2000 took 0.057s
  training loss:		0.007111
  validation loss:		0.625914
  validation accuracy:		91.20 %
Epoch 1574 of 2000 took 0.057s
  training loss:		0.006874
  validation loss:		0.630817
  validation accuracy:		91.09 %
Epoch 1575 of 2000 took 0.057s
  training loss:		0.007309
  validation loss:		0.636754
  validation accuracy:		90.76 %
Epoch 1576 of 2000 took 0.057s
  training loss:		0.007478
  validation loss:		0.632271
  validation accuracy:		91.09 %
Epoch 1577 of 2000 took 0.057s
  training loss:		0.007330
  validation loss:		0.640015
  validation accuracy:		90.87 %
Epoch 1578 of 2000 took 0.057s
  training loss:		0.007211
  validation loss:		0.627075
  validation accuracy:		90.98 %
Epoch 1579 of 2000 took 0.057s
  training loss:		0.007083
  validation loss:		0.625450
  validation accuracy:		91.20 %
Epoch 1580 of 2000 took 0.056s
  training loss:		0.006925
  validation loss:		0.638723
  validation accuracy:		90.87 %
Epoch 1581 of 2000 took 0.057s
  training loss:		0.007373
  validation loss:		0.631534
  validation accuracy:		91.09 %
Epoch 1582 of 2000 took 0.055s
  training loss:		0.007267
  validation loss:		0.627335
  validation accuracy:		91.20 %
Epoch 1583 of 2000 took 0.055s
  training loss:		0.007219
  validation loss:		0.638751
  validation accuracy:		90.87 %
Epoch 1584 of 2000 took 0.057s
  training loss:		0.007028
  validation loss:		0.627781
  validation accuracy:		90.98 %
Epoch 1585 of 2000 took 0.057s
  training loss:		0.006995
  validation loss:		0.629650
  validation accuracy:		91.09 %
Epoch 1586 of 2000 took 0.057s
  training loss:		0.007384
  validation loss:		0.636124
  validation accuracy:		90.87 %
Epoch 1587 of 2000 took 0.057s
  training loss:		0.007108
  validation loss:		0.634672
  validation accuracy:		90.98 %
Epoch 1588 of 2000 took 0.057s
  training loss:		0.007156
  validation loss:		0.636038
  validation accuracy:		90.76 %
Epoch 1589 of 2000 took 0.057s
  training loss:		0.007198
  validation loss:		0.627990
  validation accuracy:		90.98 %
Epoch 1590 of 2000 took 0.057s
  training loss:		0.007338
  validation loss:		0.642314
  validation accuracy:		90.76 %
Epoch 1591 of 2000 took 0.056s
  training loss:		0.006957
  validation loss:		0.631278
  validation accuracy:		91.09 %
Epoch 1592 of 2000 took 0.057s
  training loss:		0.007003
  validation loss:		0.631335
  validation accuracy:		91.30 %
Epoch 1593 of 2000 took 0.057s
  training loss:		0.007209
  validation loss:		0.628116
  validation accuracy:		91.20 %
Epoch 1594 of 2000 took 0.057s
  training loss:		0.007042
  validation loss:		0.637448
  validation accuracy:		90.76 %
Epoch 1595 of 2000 took 0.057s
  training loss:		0.007252
  validation loss:		0.634070
  validation accuracy:		90.98 %
Epoch 1596 of 2000 took 0.057s
  training loss:		0.006910
  validation loss:		0.621764
  validation accuracy:		91.30 %
Epoch 1597 of 2000 took 0.055s
  training loss:		0.006778
  validation loss:		0.632025
  validation accuracy:		90.98 %
Epoch 1598 of 2000 took 0.056s
  training loss:		0.007210
  validation loss:		0.642278
  validation accuracy:		90.65 %
Epoch 1599 of 2000 took 0.055s
  training loss:		0.007054
  validation loss:		0.630512
  validation accuracy:		91.09 %
Epoch 1600 of 2000 took 0.056s
  training loss:		0.007048
  validation loss:		0.638623
  validation accuracy:		90.76 %
Epoch 1601 of 2000 took 0.056s
  training loss:		0.007027
  validation loss:		0.644740
  validation accuracy:		90.98 %
Epoch 1602 of 2000 took 0.055s
  training loss:		0.006863
  validation loss:		0.635822
  validation accuracy:		90.76 %
Epoch 1603 of 2000 took 0.055s
  training loss:		0.007175
  validation loss:		0.638828
  validation accuracy:		90.87 %
Epoch 1604 of 2000 took 0.055s
  training loss:		0.006904
  validation loss:		0.631179
  validation accuracy:		91.09 %
Epoch 1605 of 2000 took 0.055s
  training loss:		0.007060
  validation loss:		0.633979
  validation accuracy:		90.98 %
Epoch 1606 of 2000 took 0.054s
  training loss:		0.006872
  validation loss:		0.631890
  validation accuracy:		91.20 %
Epoch 1607 of 2000 took 0.055s
  training loss:		0.006984
  validation loss:		0.637533
  validation accuracy:		90.76 %
Epoch 1608 of 2000 took 0.057s
  training loss:		0.006913
  validation loss:		0.637892
  validation accuracy:		91.09 %
Epoch 1609 of 2000 took 0.054s
  training loss:		0.006823
  validation loss:		0.639399
  validation accuracy:		90.87 %
Epoch 1610 of 2000 took 0.055s
  training loss:		0.006791
  validation loss:		0.647002
  validation accuracy:		90.87 %
Epoch 1611 of 2000 took 0.055s
  training loss:		0.007022
  validation loss:		0.652503
  validation accuracy:		90.65 %
Epoch 1612 of 2000 took 0.054s
  training loss:		0.007091
  validation loss:		0.638710
  validation accuracy:		90.98 %
Epoch 1613 of 2000 took 0.054s
  training loss:		0.006602
  validation loss:		0.629735
  validation accuracy:		91.20 %
Epoch 1614 of 2000 took 0.054s
  training loss:		0.006561
  validation loss:		0.634436
  validation accuracy:		90.98 %
Epoch 1615 of 2000 took 0.057s
  training loss:		0.006781
  validation loss:		0.643496
  validation accuracy:		90.98 %
Epoch 1616 of 2000 took 0.055s
  training loss:		0.006705
  validation loss:		0.643999
  validation accuracy:		90.98 %
Epoch 1617 of 2000 took 0.055s
  training loss:		0.006482
  validation loss:		0.642593
  validation accuracy:		90.98 %
Epoch 1618 of 2000 took 0.055s
  training loss:		0.006808
  validation loss:		0.637828
  validation accuracy:		91.09 %
Epoch 1619 of 2000 took 0.057s
  training loss:		0.006686
  validation loss:		0.643483
  validation accuracy:		90.87 %
Epoch 1620 of 2000 took 0.055s
  training loss:		0.006663
  validation loss:		0.643850
  validation accuracy:		90.87 %
Epoch 1621 of 2000 took 0.056s
  training loss:		0.006603
  validation loss:		0.640968
  validation accuracy:		90.98 %
Epoch 1622 of 2000 took 0.055s
  training loss:		0.006802
  validation loss:		0.648558
  validation accuracy:		90.87 %
Epoch 1623 of 2000 took 0.056s
  training loss:		0.006792
  validation loss:		0.632315
  validation accuracy:		91.30 %
Epoch 1624 of 2000 took 0.057s
  training loss:		0.006871
  validation loss:		0.650299
  validation accuracy:		90.43 %
Epoch 1625 of 2000 took 0.057s
  training loss:		0.006555
  validation loss:		0.639965
  validation accuracy:		90.98 %
Epoch 1626 of 2000 took 0.056s
  training loss:		0.006408
  validation loss:		0.648332
  validation accuracy:		90.76 %
Epoch 1627 of 2000 took 0.054s
  training loss:		0.006203
  validation loss:		0.652217
  validation accuracy:		90.87 %
Epoch 1628 of 2000 took 0.055s
  training loss:		0.006557
  validation loss:		0.643430
  validation accuracy:		91.09 %
Epoch 1629 of 2000 took 0.055s
  training loss:		0.006572
  validation loss:		0.649762
  validation accuracy:		90.98 %
Epoch 1630 of 2000 took 0.057s
  training loss:		0.006568
  validation loss:		0.648978
  validation accuracy:		90.98 %
Epoch 1631 of 2000 took 0.057s
  training loss:		0.006514
  validation loss:		0.648457
  validation accuracy:		90.87 %
Epoch 1632 of 2000 took 0.055s
  training loss:		0.006470
  validation loss:		0.649770
  validation accuracy:		90.98 %
Epoch 1633 of 2000 took 0.055s
  training loss:		0.006476
  validation loss:		0.642144
  validation accuracy:		91.09 %
Epoch 1634 of 2000 took 0.057s
  training loss:		0.006729
  validation loss:		0.642954
  validation accuracy:		90.87 %
Epoch 1635 of 2000 took 0.057s
  training loss:		0.006668
  validation loss:		0.651013
  validation accuracy:		90.76 %
Epoch 1636 of 2000 took 0.055s
  training loss:		0.006752
  validation loss:		0.645313
  validation accuracy:		91.09 %
Epoch 1637 of 2000 took 0.057s
  training loss:		0.006396
  validation loss:		0.640766
  validation accuracy:		91.20 %
Epoch 1638 of 2000 took 0.057s
  training loss:		0.006716
  validation loss:		0.647939
  validation accuracy:		90.98 %
Epoch 1639 of 2000 took 0.056s
  training loss:		0.006603
  validation loss:		0.645351
  validation accuracy:		90.87 %
Epoch 1640 of 2000 took 0.057s
  training loss:		0.006533
  validation loss:		0.645104
  validation accuracy:		90.98 %
Epoch 1641 of 2000 took 0.056s
  training loss:		0.006388
  validation loss:		0.640767
  validation accuracy:		90.98 %
Epoch 1642 of 2000 took 0.057s
  training loss:		0.006501
  validation loss:		0.647854
  validation accuracy:		90.87 %
Epoch 1643 of 2000 took 0.057s
  training loss:		0.006242
  validation loss:		0.648063
  validation accuracy:		91.09 %
Epoch 1644 of 2000 took 0.057s
  training loss:		0.006459
  validation loss:		0.650720
  validation accuracy:		90.98 %
Epoch 1645 of 2000 took 0.057s
  training loss:		0.006499
  validation loss:		0.651198
  validation accuracy:		90.87 %
Epoch 1646 of 2000 took 0.057s
  training loss:		0.006476
  validation loss:		0.643856
  validation accuracy:		91.20 %
Epoch 1647 of 2000 took 0.057s
  training loss:		0.006332
  validation loss:		0.665595
  validation accuracy:		90.76 %
Epoch 1648 of 2000 took 0.057s
  training loss:		0.006418
  validation loss:		0.644909
  validation accuracy:		91.09 %
Epoch 1649 of 2000 took 0.057s
  training loss:		0.006623
  validation loss:		0.650514
  validation accuracy:		91.09 %
Epoch 1650 of 2000 took 0.057s
  training loss:		0.006409
  validation loss:		0.646973
  validation accuracy:		91.09 %
Epoch 1651 of 2000 took 0.057s
  training loss:		0.006293
  validation loss:		0.646373
  validation accuracy:		91.20 %
Epoch 1652 of 2000 took 0.057s
  training loss:		0.006279
  validation loss:		0.648728
  validation accuracy:		91.20 %
Epoch 1653 of 2000 took 0.057s
  training loss:		0.006431
  validation loss:		0.659385
  validation accuracy:		90.65 %
Epoch 1654 of 2000 took 0.057s
  training loss:		0.006459
  validation loss:		0.648990
  validation accuracy:		91.20 %
Epoch 1655 of 2000 took 0.057s
  training loss:		0.006243
  validation loss:		0.648874
  validation accuracy:		90.98 %
Epoch 1656 of 2000 took 0.057s
  training loss:		0.006266
  validation loss:		0.650909
  validation accuracy:		90.98 %
Epoch 1657 of 2000 took 0.055s
  training loss:		0.006456
  validation loss:		0.662131
  validation accuracy:		90.76 %
Epoch 1658 of 2000 took 0.057s
  training loss:		0.006593
  validation loss:		0.646796
  validation accuracy:		91.30 %
Epoch 1659 of 2000 took 0.057s
  training loss:		0.006435
  validation loss:		0.650997
  validation accuracy:		90.87 %
Epoch 1660 of 2000 took 0.057s
  training loss:		0.006278
  validation loss:		0.656670
  validation accuracy:		91.09 %
Epoch 1661 of 2000 took 0.057s
  training loss:		0.006450
  validation loss:		0.659743
  validation accuracy:		90.76 %
Epoch 1662 of 2000 took 0.057s
  training loss:		0.006296
  validation loss:		0.663444
  validation accuracy:		90.87 %
Epoch 1663 of 2000 took 0.057s
  training loss:		0.006118
  validation loss:		0.655048
  validation accuracy:		90.98 %
Epoch 1664 of 2000 took 0.057s
  training loss:		0.006309
  validation loss:		0.642847
  validation accuracy:		91.30 %
Epoch 1665 of 2000 took 0.057s
  training loss:		0.006364
  validation loss:		0.656840
  validation accuracy:		90.87 %
Epoch 1666 of 2000 took 0.056s
  training loss:		0.006166
  validation loss:		0.654065
  validation accuracy:		91.09 %
Epoch 1667 of 2000 took 0.057s
  training loss:		0.006128
  validation loss:		0.653601
  validation accuracy:		90.98 %
Epoch 1668 of 2000 took 0.057s
  training loss:		0.006220
  validation loss:		0.654932
  validation accuracy:		90.98 %
Epoch 1669 of 2000 took 0.057s
  training loss:		0.006191
  validation loss:		0.650001
  validation accuracy:		91.30 %
Epoch 1670 of 2000 took 0.056s
  training loss:		0.006101
  validation loss:		0.657662
  validation accuracy:		90.76 %
Epoch 1671 of 2000 took 0.057s
  training loss:		0.006242
  validation loss:		0.664376
  validation accuracy:		90.76 %
Epoch 1672 of 2000 took 0.057s
  training loss:		0.006139
  validation loss:		0.657116
  validation accuracy:		90.98 %
Epoch 1673 of 2000 took 0.057s
  training loss:		0.006073
  validation loss:		0.656314
  validation accuracy:		90.87 %
Epoch 1674 of 2000 took 0.057s
  training loss:		0.006389
  validation loss:		0.659643
  validation accuracy:		91.09 %
Epoch 1675 of 2000 took 0.057s
  training loss:		0.006401
  validation loss:		0.656669
  validation accuracy:		91.09 %
Epoch 1676 of 2000 took 0.056s
  training loss:		0.006037
  validation loss:		0.655931
  validation accuracy:		90.76 %
Epoch 1677 of 2000 took 0.057s
  training loss:		0.006070
  validation loss:		0.657521
  validation accuracy:		90.43 %
Epoch 1678 of 2000 took 0.056s
  training loss:		0.006227
  validation loss:		0.663009
  validation accuracy:		90.87 %
Epoch 1679 of 2000 took 0.055s
  training loss:		0.006070
  validation loss:		0.659956
  validation accuracy:		90.87 %
Epoch 1680 of 2000 took 0.056s
  training loss:		0.006296
  validation loss:		0.663855
  validation accuracy:		90.87 %
Epoch 1681 of 2000 took 0.056s
  training loss:		0.006154
  validation loss:		0.663756
  validation accuracy:		90.87 %
Epoch 1682 of 2000 took 0.056s
  training loss:		0.006084
  validation loss:		0.654892
  validation accuracy:		91.09 %
Epoch 1683 of 2000 took 0.056s
  training loss:		0.006059
  validation loss:		0.656908
  validation accuracy:		91.09 %
Epoch 1684 of 2000 took 0.056s
  training loss:		0.006026
  validation loss:		0.662678
  validation accuracy:		90.76 %
Epoch 1685 of 2000 took 0.056s
  training loss:		0.005991
  validation loss:		0.668699
  validation accuracy:		90.76 %
Epoch 1686 of 2000 took 0.056s
  training loss:		0.006221
  validation loss:		0.657155
  validation accuracy:		91.20 %
Epoch 1687 of 2000 took 0.056s
  training loss:		0.006220
  validation loss:		0.661234
  validation accuracy:		90.87 %
Epoch 1688 of 2000 took 0.056s
  training loss:		0.006003
  validation loss:		0.667688
  validation accuracy:		90.87 %
Epoch 1689 of 2000 took 0.057s
  training loss:		0.005912
  validation loss:		0.669873
  validation accuracy:		90.76 %
Epoch 1690 of 2000 took 0.056s
  training loss:		0.006137
  validation loss:		0.662573
  validation accuracy:		90.98 %
Epoch 1691 of 2000 took 0.056s
  training loss:		0.006269
  validation loss:		0.666384
  validation accuracy:		90.87 %
Epoch 1692 of 2000 took 0.056s
  training loss:		0.006016
  validation loss:		0.666706
  validation accuracy:		90.87 %
Epoch 1693 of 2000 took 0.056s
  training loss:		0.006017
  validation loss:		0.655327
  validation accuracy:		91.09 %
Epoch 1694 of 2000 took 0.056s
  training loss:		0.006141
  validation loss:		0.662560
  validation accuracy:		91.09 %
Epoch 1695 of 2000 took 0.057s
  training loss:		0.006125
  validation loss:		0.654314
  validation accuracy:		91.30 %
Epoch 1696 of 2000 took 0.056s
  training loss:		0.006058
  validation loss:		0.659660
  validation accuracy:		90.98 %
Epoch 1697 of 2000 took 0.055s
  training loss:		0.005713
  validation loss:		0.679904
  validation accuracy:		90.43 %
Epoch 1698 of 2000 took 0.055s
  training loss:		0.005874
  validation loss:		0.660089
  validation accuracy:		91.20 %
Epoch 1699 of 2000 took 0.056s
  training loss:		0.005881
  validation loss:		0.662140
  validation accuracy:		90.98 %
Epoch 1700 of 2000 took 0.055s
  training loss:		0.005852
  validation loss:		0.665896
  validation accuracy:		90.98 %
Epoch 1701 of 2000 took 0.057s
  training loss:		0.005880
  validation loss:		0.657630
  validation accuracy:		90.98 %
Epoch 1702 of 2000 took 0.056s
  training loss:		0.006017
  validation loss:		0.664637
  validation accuracy:		90.87 %
Epoch 1703 of 2000 took 0.056s
  training loss:		0.006009
  validation loss:		0.661695
  validation accuracy:		90.98 %
Epoch 1704 of 2000 took 0.057s
  training loss:		0.006069
  validation loss:		0.665009
  validation accuracy:		91.09 %
Epoch 1705 of 2000 took 0.054s
  training loss:		0.005895
  validation loss:		0.667784
  validation accuracy:		91.09 %
Epoch 1706 of 2000 took 0.055s
  training loss:		0.005765
  validation loss:		0.667531
  validation accuracy:		90.76 %
Epoch 1707 of 2000 took 0.055s
  training loss:		0.005687
  validation loss:		0.665867
  validation accuracy:		91.09 %
Epoch 1708 of 2000 took 0.055s
  training loss:		0.005758
  validation loss:		0.665352
  validation accuracy:		91.09 %
Epoch 1709 of 2000 took 0.055s
  training loss:		0.005741
  validation loss:		0.669032
  validation accuracy:		90.54 %
Epoch 1710 of 2000 took 0.056s
  training loss:		0.005899
  validation loss:		0.667799
  validation accuracy:		90.87 %
Epoch 1711 of 2000 took 0.055s
  training loss:		0.005791
  validation loss:		0.672506
  validation accuracy:		90.87 %
Epoch 1712 of 2000 took 0.056s
  training loss:		0.005757
  validation loss:		0.667808
  validation accuracy:		90.76 %
Epoch 1713 of 2000 took 0.055s
  training loss:		0.005943
  validation loss:		0.673207
  validation accuracy:		90.76 %
Epoch 1714 of 2000 took 0.056s
  training loss:		0.005872
  validation loss:		0.669452
  validation accuracy:		91.09 %
Epoch 1715 of 2000 took 0.057s
  training loss:		0.005813
  validation loss:		0.660134
  validation accuracy:		91.20 %
Epoch 1716 of 2000 took 0.053s
  training loss:		0.005718
  validation loss:		0.672606
  validation accuracy:		90.98 %
Epoch 1717 of 2000 took 0.058s
  training loss:		0.005824
  validation loss:		0.667372
  validation accuracy:		90.87 %
Epoch 1718 of 2000 took 0.055s
  training loss:		0.005635
  validation loss:		0.665693
  validation accuracy:		91.09 %
Epoch 1719 of 2000 took 0.057s
  training loss:		0.005563
  validation loss:		0.668850
  validation accuracy:		91.09 %
Epoch 1720 of 2000 took 0.057s
  training loss:		0.005807
  validation loss:		0.670513
  validation accuracy:		91.09 %
Epoch 1721 of 2000 took 0.057s
  training loss:		0.005580
  validation loss:		0.675095
  validation accuracy:		90.76 %
Epoch 1722 of 2000 took 0.057s
  training loss:		0.005797
  validation loss:		0.682380
  validation accuracy:		90.65 %
Epoch 1723 of 2000 took 0.057s
  training loss:		0.005869
  validation loss:		0.670883
  validation accuracy:		90.76 %
Epoch 1724 of 2000 took 0.057s
  training loss:		0.005732
  validation loss:		0.679615
  validation accuracy:		90.87 %
Epoch 1725 of 2000 took 0.057s
  training loss:		0.005572
  validation loss:		0.665264
  validation accuracy:		90.98 %
Epoch 1726 of 2000 took 0.057s
  training loss:		0.005786
  validation loss:		0.671895
  validation accuracy:		91.20 %
Epoch 1727 of 2000 took 0.057s
  training loss:		0.005821
  validation loss:		0.678152
  validation accuracy:		90.76 %
Epoch 1728 of 2000 took 0.057s
  training loss:		0.005692
  validation loss:		0.670590
  validation accuracy:		90.98 %
Epoch 1729 of 2000 took 0.057s
  training loss:		0.005889
  validation loss:		0.665449
  validation accuracy:		91.09 %
Epoch 1730 of 2000 took 0.055s
  training loss:		0.005687
  validation loss:		0.676376
  validation accuracy:		90.98 %
Epoch 1731 of 2000 took 0.056s
  training loss:		0.005885
  validation loss:		0.669122
  validation accuracy:		90.98 %
Epoch 1732 of 2000 took 0.053s
  training loss:		0.005787
  validation loss:		0.663169
  validation accuracy:		91.20 %
Epoch 1733 of 2000 took 0.055s
  training loss:		0.005557
  validation loss:		0.665086
  validation accuracy:		91.09 %
Epoch 1734 of 2000 took 0.056s
  training loss:		0.005579
  validation loss:		0.669518
  validation accuracy:		90.76 %
Epoch 1735 of 2000 took 0.057s
  training loss:		0.005570
  validation loss:		0.677118
  validation accuracy:		90.65 %
Epoch 1736 of 2000 took 0.057s
  training loss:		0.005481
  validation loss:		0.677033
  validation accuracy:		90.87 %
Epoch 1737 of 2000 took 0.055s
  training loss:		0.005527
  validation loss:		0.669389
  validation accuracy:		91.09 %
Epoch 1738 of 2000 took 0.056s
  training loss:		0.005632
  validation loss:		0.676458
  validation accuracy:		90.76 %
Epoch 1739 of 2000 took 0.055s
  training loss:		0.005483
  validation loss:		0.681020
  validation accuracy:		90.76 %
Epoch 1740 of 2000 took 0.057s
  training loss:		0.005440
  validation loss:		0.671957
  validation accuracy:		90.76 %
Epoch 1741 of 2000 took 0.057s
  training loss:		0.005596
  validation loss:		0.672069
  validation accuracy:		90.98 %
Epoch 1742 of 2000 took 0.057s
  training loss:		0.005520
  validation loss:		0.673246
  validation accuracy:		90.98 %
Epoch 1743 of 2000 took 0.055s
  training loss:		0.005499
  validation loss:		0.676227
  validation accuracy:		90.76 %
Epoch 1744 of 2000 took 0.057s
  training loss:		0.005538
  validation loss:		0.673171
  validation accuracy:		91.09 %
Epoch 1745 of 2000 took 0.056s
  training loss:		0.005579
  validation loss:		0.665984
  validation accuracy:		91.20 %
Epoch 1746 of 2000 took 0.057s
  training loss:		0.005219
  validation loss:		0.676605
  validation accuracy:		90.98 %
Epoch 1747 of 2000 took 0.057s
  training loss:		0.005492
  validation loss:		0.678217
  validation accuracy:		90.98 %
Epoch 1748 of 2000 took 0.057s
  training loss:		0.005456
  validation loss:		0.682920
  validation accuracy:		90.65 %
Epoch 1749 of 2000 took 0.057s
  training loss:		0.005566
  validation loss:		0.680387
  validation accuracy:		90.76 %
Epoch 1750 of 2000 took 0.057s
  training loss:		0.005542
  validation loss:		0.675253
  validation accuracy:		90.98 %
Epoch 1751 of 2000 took 0.057s
  training loss:		0.005367
  validation loss:		0.675901
  validation accuracy:		90.98 %
Epoch 1752 of 2000 took 0.057s
  training loss:		0.005426
  validation loss:		0.674288
  validation accuracy:		91.09 %
Epoch 1753 of 2000 took 0.057s
  training loss:		0.005436
  validation loss:		0.681690
  validation accuracy:		90.98 %
Epoch 1754 of 2000 took 0.056s
  training loss:		0.005438
  validation loss:		0.682786
  validation accuracy:		90.98 %
Epoch 1755 of 2000 took 0.057s
  training loss:		0.005402
  validation loss:		0.674574
  validation accuracy:		90.98 %
Epoch 1756 of 2000 took 0.057s
  training loss:		0.005367
  validation loss:		0.681211
  validation accuracy:		91.09 %
Epoch 1757 of 2000 took 0.057s
  training loss:		0.005452
  validation loss:		0.679017
  validation accuracy:		90.98 %
Epoch 1758 of 2000 took 0.057s
  training loss:		0.005446
  validation loss:		0.682782
  validation accuracy:		90.76 %
Epoch 1759 of 2000 took 0.057s
  training loss:		0.005341
  validation loss:		0.678576
  validation accuracy:		90.76 %
Epoch 1760 of 2000 took 0.057s
  training loss:		0.005212
  validation loss:		0.670925
  validation accuracy:		91.09 %
Epoch 1761 of 2000 took 0.056s
  training loss:		0.005501
  validation loss:		0.674864
  validation accuracy:		91.09 %
Epoch 1762 of 2000 took 0.057s
  training loss:		0.005409
  validation loss:		0.681152
  validation accuracy:		90.76 %
Epoch 1763 of 2000 took 0.055s
  training loss:		0.005518
  validation loss:		0.680858
  validation accuracy:		90.54 %
Epoch 1764 of 2000 took 0.054s
  training loss:		0.005353
  validation loss:		0.673943
  validation accuracy:		91.09 %
Epoch 1765 of 2000 took 0.056s
  training loss:		0.005320
  validation loss:		0.684021
  validation accuracy:		90.76 %
Epoch 1766 of 2000 took 0.055s
  training loss:		0.005291
  validation loss:		0.683677
  validation accuracy:		90.65 %
Epoch 1767 of 2000 took 0.056s
  training loss:		0.005238
  validation loss:		0.685867
  validation accuracy:		90.87 %
Epoch 1768 of 2000 took 0.055s
  training loss:		0.005358
  validation loss:		0.691283
  validation accuracy:		90.65 %
Epoch 1769 of 2000 took 0.055s
  training loss:		0.005408
  validation loss:		0.679498
  validation accuracy:		91.09 %
Epoch 1770 of 2000 took 0.055s
  training loss:		0.005262
  validation loss:		0.691717
  validation accuracy:		90.87 %
Epoch 1771 of 2000 took 0.056s
  training loss:		0.005465
  validation loss:		0.671354
  validation accuracy:		91.20 %
Epoch 1772 of 2000 took 0.055s
  training loss:		0.005260
  validation loss:		0.690684
  validation accuracy:		90.65 %
Epoch 1773 of 2000 took 0.056s
  training loss:		0.005340
  validation loss:		0.677904
  validation accuracy:		90.98 %
Epoch 1774 of 2000 took 0.056s
  training loss:		0.005185
  validation loss:		0.678929
  validation accuracy:		91.09 %
Epoch 1775 of 2000 took 0.056s
  training loss:		0.005227
  validation loss:		0.686175
  validation accuracy:		90.76 %
Epoch 1776 of 2000 took 0.055s
  training loss:		0.005293
  validation loss:		0.684050
  validation accuracy:		90.76 %
Epoch 1777 of 2000 took 0.054s
  training loss:		0.005215
  validation loss:		0.681319
  validation accuracy:		90.87 %
Epoch 1778 of 2000 took 0.053s
  training loss:		0.005308
  validation loss:		0.686882
  validation accuracy:		90.98 %
Epoch 1779 of 2000 took 0.055s
  training loss:		0.005339
  validation loss:		0.683488
  validation accuracy:		90.76 %
Epoch 1780 of 2000 took 0.054s
  training loss:		0.005216
  validation loss:		0.689626
  validation accuracy:		90.87 %
Epoch 1781 of 2000 took 0.055s
  training loss:		0.005059
  validation loss:		0.681925
  validation accuracy:		90.98 %
Epoch 1782 of 2000 took 0.057s
  training loss:		0.005054
  validation loss:		0.685149
  validation accuracy:		90.98 %
Epoch 1783 of 2000 took 0.054s
  training loss:		0.005208
  validation loss:		0.689548
  validation accuracy:		91.09 %
Epoch 1784 of 2000 took 0.055s
  training loss:		0.005108
  validation loss:		0.683727
  validation accuracy:		90.87 %
Epoch 1785 of 2000 took 0.057s
  training loss:		0.005145
  validation loss:		0.682876
  validation accuracy:		90.98 %
Epoch 1786 of 2000 took 0.056s
  training loss:		0.005326
  validation loss:		0.691640
  validation accuracy:		90.54 %
Epoch 1787 of 2000 took 0.057s
  training loss:		0.005187
  validation loss:		0.681103
  validation accuracy:		91.09 %
Epoch 1788 of 2000 took 0.055s
  training loss:		0.005310
  validation loss:		0.692566
  validation accuracy:		90.87 %
Epoch 1789 of 2000 took 0.054s
  training loss:		0.005317
  validation loss:		0.697506
  validation accuracy:		90.76 %
Epoch 1790 of 2000 took 0.054s
  training loss:		0.005223
  validation loss:		0.683266
  validation accuracy:		90.98 %
Epoch 1791 of 2000 took 0.055s
  training loss:		0.005076
  validation loss:		0.682158
  validation accuracy:		91.09 %
Epoch 1792 of 2000 took 0.054s
  training loss:		0.005275
  validation loss:		0.683048
  validation accuracy:		90.98 %
Epoch 1793 of 2000 took 0.056s
  training loss:		0.005217
  validation loss:		0.683579
  validation accuracy:		90.87 %
Epoch 1794 of 2000 took 0.056s
  training loss:		0.005032
  validation loss:		0.679112
  validation accuracy:		91.20 %
Epoch 1795 of 2000 took 0.039s
  training loss:		0.005174
  validation loss:		0.686297
  validation accuracy:		91.09 %
Epoch 1796 of 2000 took 0.038s
  training loss:		0.005078
  validation loss:		0.685484
  validation accuracy:		91.09 %
Epoch 1797 of 2000 took 0.038s
  training loss:		0.005051
  validation loss:		0.682037
  validation accuracy:		90.98 %
Epoch 1798 of 2000 took 0.039s
  training loss:		0.005335
  validation loss:		0.683433
  validation accuracy:		91.20 %
Epoch 1799 of 2000 took 0.138s
  training loss:		0.004980
  validation loss:		0.685150
  validation accuracy:		90.98 %
Epoch 1800 of 2000 took 0.037s
  training loss:		0.005046
  validation loss:		0.685790
  validation accuracy:		91.09 %
Epoch 1801 of 2000 took 0.038s
  training loss:		0.005004
  validation loss:		0.687338
  validation accuracy:		90.98 %
Epoch 1802 of 2000 took 0.038s
  training loss:		0.005046
  validation loss:		0.679029
  validation accuracy:		91.09 %
Epoch 1803 of 2000 took 0.039s
  training loss:		0.005179
  validation loss:		0.689727
  validation accuracy:		90.76 %
Epoch 1804 of 2000 took 0.046s
  training loss:		0.005069
  validation loss:		0.696969
  validation accuracy:		90.76 %
Epoch 1805 of 2000 took 0.046s
  training loss:		0.005103
  validation loss:		0.695629
  validation accuracy:		90.76 %
Epoch 1806 of 2000 took 0.041s
  training loss:		0.005138
  validation loss:		0.694287
  validation accuracy:		90.65 %
Epoch 1807 of 2000 took 0.038s
  training loss:		0.005069
  validation loss:		0.693202
  validation accuracy:		90.87 %
Epoch 1808 of 2000 took 0.038s
  training loss:		0.005171
  validation loss:		0.699980
  validation accuracy:		90.76 %
Epoch 1809 of 2000 took 0.046s
  training loss:		0.004998
  validation loss:		0.685275
  validation accuracy:		90.98 %
Epoch 1810 of 2000 took 0.046s
  training loss:		0.005121
  validation loss:		0.692055
  validation accuracy:		90.76 %
Epoch 1811 of 2000 took 0.040s
  training loss:		0.004967
  validation loss:		0.688843
  validation accuracy:		91.20 %
Epoch 1812 of 2000 took 0.038s
  training loss:		0.005012
  validation loss:		0.689984
  validation accuracy:		90.87 %
Epoch 1813 of 2000 took 0.038s
  training loss:		0.005078
  validation loss:		0.689088
  validation accuracy:		90.98 %
Epoch 1814 of 2000 took 0.038s
  training loss:		0.004897
  validation loss:		0.688471
  validation accuracy:		90.76 %
Epoch 1815 of 2000 took 0.038s
  training loss:		0.004758
  validation loss:		0.698497
  validation accuracy:		90.65 %
Epoch 1816 of 2000 took 0.038s
  training loss:		0.005017
  validation loss:		0.690325
  validation accuracy:		90.87 %
Epoch 1817 of 2000 took 0.037s
  training loss:		0.004905
  validation loss:		0.698209
  validation accuracy:		90.65 %
Epoch 1818 of 2000 took 0.037s
  training loss:		0.005069
  validation loss:		0.696119
  validation accuracy:		90.87 %
Epoch 1819 of 2000 took 0.038s
  training loss:		0.004985
  validation loss:		0.685650
  validation accuracy:		91.09 %
Epoch 1820 of 2000 took 0.038s
  training loss:		0.004777
  validation loss:		0.699534
  validation accuracy:		90.65 %
Epoch 1821 of 2000 took 0.038s
  training loss:		0.005008
  validation loss:		0.691702
  validation accuracy:		90.87 %
Epoch 1822 of 2000 took 0.038s
  training loss:		0.004853
  validation loss:		0.695782
  validation accuracy:		90.65 %
Epoch 1823 of 2000 took 0.037s
  training loss:		0.004994
  validation loss:		0.702170
  validation accuracy:		90.65 %
Epoch 1824 of 2000 took 0.038s
  training loss:		0.004907
  validation loss:		0.693030
  validation accuracy:		90.87 %
Epoch 1825 of 2000 took 0.038s
  training loss:		0.004988
  validation loss:		0.687397
  validation accuracy:		90.87 %
Epoch 1826 of 2000 took 0.038s
  training loss:		0.005091
  validation loss:		0.695122
  validation accuracy:		90.87 %
Epoch 1827 of 2000 took 0.038s
  training loss:		0.004819
  validation loss:		0.696069
  validation accuracy:		90.87 %
Epoch 1828 of 2000 took 0.038s
  training loss:		0.004966
  validation loss:		0.695476
  validation accuracy:		91.20 %
Epoch 1829 of 2000 took 0.038s
  training loss:		0.004722
  validation loss:		0.688299
  validation accuracy:		90.98 %
Epoch 1830 of 2000 took 0.041s
  training loss:		0.004847
  validation loss:		0.702433
  validation accuracy:		90.76 %
Epoch 1831 of 2000 took 0.038s
  training loss:		0.004764
  validation loss:		0.697001
  validation accuracy:		90.98 %
Epoch 1832 of 2000 took 0.038s
  training loss:		0.004894
  validation loss:		0.697039
  validation accuracy:		90.76 %
Epoch 1833 of 2000 took 0.036s
  training loss:		0.004864
  validation loss:		0.690808
  validation accuracy:		91.09 %
Epoch 1834 of 2000 took 0.038s
  training loss:		0.004780
  validation loss:		0.698838
  validation accuracy:		90.76 %
Epoch 1835 of 2000 took 0.038s
  training loss:		0.004704
  validation loss:		0.703008
  validation accuracy:		90.76 %
Epoch 1836 of 2000 took 0.038s
  training loss:		0.004806
  validation loss:		0.692048
  validation accuracy:		90.65 %
Epoch 1837 of 2000 took 0.037s
  training loss:		0.004813
  validation loss:		0.703709
  validation accuracy:		91.09 %
Epoch 1838 of 2000 took 0.038s
  training loss:		0.004776
  validation loss:		0.692040
  validation accuracy:		90.87 %
Epoch 1839 of 2000 took 0.039s
  training loss:		0.004805
  validation loss:		0.695344
  validation accuracy:		91.09 %
Epoch 1840 of 2000 took 0.189s
  training loss:		0.004752
  validation loss:		0.701569
  validation accuracy:		90.98 %
Epoch 1841 of 2000 took 0.057s
  training loss:		0.004985
  validation loss:		0.696769
  validation accuracy:		90.76 %
Epoch 1842 of 2000 took 0.042s
  training loss:		0.004837
  validation loss:		0.699373
  validation accuracy:		90.98 %
Epoch 1843 of 2000 took 0.042s
  training loss:		0.004724
  validation loss:		0.695650
  validation accuracy:		90.87 %
Epoch 1844 of 2000 took 0.038s
  training loss:		0.004624
  validation loss:		0.697194
  validation accuracy:		90.98 %
Epoch 1845 of 2000 took 0.037s
  training loss:		0.004772
  validation loss:		0.694937
  validation accuracy:		90.76 %
Epoch 1846 of 2000 took 0.036s
  training loss:		0.004842
  validation loss:		0.706862
  validation accuracy:		91.09 %
Epoch 1847 of 2000 took 0.036s
  training loss:		0.004778
  validation loss:		0.699839
  validation accuracy:		90.87 %
Epoch 1848 of 2000 took 0.036s
  training loss:		0.004855
  validation loss:		0.696122
  validation accuracy:		90.98 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004784
  validation loss:		0.696802
  validation accuracy:		90.76 %
Epoch 1850 of 2000 took 0.036s
  training loss:		0.004732
  validation loss:		0.695319
  validation accuracy:		90.87 %
Epoch 1851 of 2000 took 0.036s
  training loss:		0.004677
  validation loss:		0.703890
  validation accuracy:		90.87 %
Epoch 1852 of 2000 took 0.037s
  training loss:		0.004770
  validation loss:		0.696414
  validation accuracy:		90.98 %
Epoch 1853 of 2000 took 0.039s
  training loss:		0.004646
  validation loss:		0.702140
  validation accuracy:		90.98 %
Epoch 1854 of 2000 took 0.038s
  training loss:		0.004752
  validation loss:		0.712460
  validation accuracy:		90.76 %
Epoch 1855 of 2000 took 0.038s
  training loss:		0.004758
  validation loss:		0.697837
  validation accuracy:		90.87 %
Epoch 1856 of 2000 took 0.038s
  training loss:		0.004854
  validation loss:		0.701695
  validation accuracy:		90.87 %
Epoch 1857 of 2000 took 0.037s
  training loss:		0.004680
  validation loss:		0.708263
  validation accuracy:		90.76 %
Epoch 1858 of 2000 took 0.038s
  training loss:		0.004809
  validation loss:		0.707585
  validation accuracy:		90.98 %
Epoch 1859 of 2000 took 0.038s
  training loss:		0.004726
  validation loss:		0.702612
  validation accuracy:		90.98 %
Epoch 1860 of 2000 took 0.037s
  training loss:		0.004611
  validation loss:		0.701286
  validation accuracy:		90.76 %
Epoch 1861 of 2000 took 0.036s
  training loss:		0.004725
  validation loss:		0.707593
  validation accuracy:		90.87 %
Epoch 1862 of 2000 took 0.036s
  training loss:		0.004674
  validation loss:		0.704197
  validation accuracy:		90.87 %
Epoch 1863 of 2000 took 0.036s
  training loss:		0.004626
  validation loss:		0.696898
  validation accuracy:		90.98 %
Epoch 1864 of 2000 took 0.036s
  training loss:		0.004716
  validation loss:		0.692949
  validation accuracy:		90.87 %
Epoch 1865 of 2000 took 0.036s
  training loss:		0.004668
  validation loss:		0.700647
  validation accuracy:		90.98 %
Epoch 1866 of 2000 took 0.036s
  training loss:		0.004664
  validation loss:		0.702134
  validation accuracy:		90.87 %
Epoch 1867 of 2000 took 0.036s
  training loss:		0.004568
  validation loss:		0.698755
  validation accuracy:		91.09 %
Epoch 1868 of 2000 took 0.036s
  training loss:		0.004490
  validation loss:		0.714037
  validation accuracy:		90.65 %
Epoch 1869 of 2000 took 0.036s
  training loss:		0.004680
  validation loss:		0.707211
  validation accuracy:		90.87 %
Epoch 1870 of 2000 took 0.036s
  training loss:		0.004702
  validation loss:		0.704061
  validation accuracy:		90.87 %
Epoch 1871 of 2000 took 0.036s
  training loss:		0.004444
  validation loss:		0.704436
  validation accuracy:		90.87 %
Epoch 1872 of 2000 took 0.036s
  training loss:		0.004460
  validation loss:		0.701925
  validation accuracy:		90.87 %
Epoch 1873 of 2000 took 0.036s
  training loss:		0.004682
  validation loss:		0.703763
  validation accuracy:		90.87 %
Epoch 1874 of 2000 took 0.036s
  training loss:		0.004553
  validation loss:		0.699307
  validation accuracy:		91.09 %
Epoch 1875 of 2000 took 0.036s
  training loss:		0.004606
  validation loss:		0.698883
  validation accuracy:		91.09 %
Epoch 1876 of 2000 took 0.036s
  training loss:		0.004565
  validation loss:		0.702172
  validation accuracy:		90.65 %
Epoch 1877 of 2000 took 0.036s
  training loss:		0.004407
  validation loss:		0.704494
  validation accuracy:		90.76 %
Epoch 1878 of 2000 took 0.036s
  training loss:		0.004486
  validation loss:		0.707842
  validation accuracy:		90.87 %
Epoch 1879 of 2000 took 0.036s
  training loss:		0.004534
  validation loss:		0.708259
  validation accuracy:		90.65 %
Epoch 1880 of 2000 took 0.036s
  training loss:		0.004504
  validation loss:		0.704184
  validation accuracy:		90.87 %
Epoch 1881 of 2000 took 0.036s
  training loss:		0.004512
  validation loss:		0.706675
  validation accuracy:		90.87 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.004514
  validation loss:		0.701875
  validation accuracy:		90.98 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.004484
  validation loss:		0.704618
  validation accuracy:		90.76 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.004516
  validation loss:		0.706804
  validation accuracy:		90.98 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.004425
  validation loss:		0.703720
  validation accuracy:		90.87 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.004460
  validation loss:		0.708216
  validation accuracy:		90.65 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.004470
  validation loss:		0.710894
  validation accuracy:		90.76 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.004602
  validation loss:		0.702131
  validation accuracy:		91.09 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.707831
  validation accuracy:		90.87 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.004452
  validation loss:		0.713716
  validation accuracy:		90.65 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.004506
  validation loss:		0.704210
  validation accuracy:		91.20 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.004305
  validation loss:		0.709785
  validation accuracy:		90.65 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.004492
  validation loss:		0.705896
  validation accuracy:		90.76 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.708655
  validation accuracy:		90.98 %
Epoch 1895 of 2000 took 0.036s
  training loss:		0.004482
  validation loss:		0.706317
  validation accuracy:		90.98 %
Epoch 1896 of 2000 took 0.036s
  training loss:		0.004516
  validation loss:		0.711590
  validation accuracy:		90.87 %
Epoch 1897 of 2000 took 0.036s
  training loss:		0.004445
  validation loss:		0.705542
  validation accuracy:		90.87 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.004399
  validation loss:		0.703540
  validation accuracy:		90.98 %
Epoch 1899 of 2000 took 0.036s
  training loss:		0.004421
  validation loss:		0.712592
  validation accuracy:		90.87 %
Epoch 1900 of 2000 took 0.036s
  training loss:		0.004455
  validation loss:		0.699821
  validation accuracy:		90.98 %
Epoch 1901 of 2000 took 0.036s
  training loss:		0.004500
  validation loss:		0.716642
  validation accuracy:		90.65 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.004340
  validation loss:		0.712466
  validation accuracy:		90.76 %
Epoch 1903 of 2000 took 0.036s
  training loss:		0.004401
  validation loss:		0.709302
  validation accuracy:		90.76 %
Epoch 1904 of 2000 took 0.036s
  training loss:		0.004346
  validation loss:		0.715157
  validation accuracy:		90.76 %
Epoch 1905 of 2000 took 0.036s
  training loss:		0.004492
  validation loss:		0.714100
  validation accuracy:		90.65 %
Epoch 1906 of 2000 took 0.036s
  training loss:		0.004453
  validation loss:		0.717171
  validation accuracy:		90.65 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.004405
  validation loss:		0.711391
  validation accuracy:		90.65 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.004468
  validation loss:		0.719107
  validation accuracy:		90.76 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.004384
  validation loss:		0.708263
  validation accuracy:		90.98 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.004418
  validation loss:		0.714319
  validation accuracy:		90.65 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.004391
  validation loss:		0.707225
  validation accuracy:		91.09 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.004397
  validation loss:		0.714215
  validation accuracy:		90.76 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.004560
  validation loss:		0.719598
  validation accuracy:		90.65 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.004320
  validation loss:		0.714571
  validation accuracy:		90.76 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.004398
  validation loss:		0.711598
  validation accuracy:		90.98 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.708391
  validation accuracy:		90.98 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.709900
  validation accuracy:		90.98 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.004471
  validation loss:		0.710757
  validation accuracy:		90.87 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.004318
  validation loss:		0.709597
  validation accuracy:		91.09 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.004309
  validation loss:		0.716204
  validation accuracy:		90.98 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.004251
  validation loss:		0.719831
  validation accuracy:		90.87 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.004082
  validation loss:		0.707669
  validation accuracy:		90.87 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.004280
  validation loss:		0.714357
  validation accuracy:		90.76 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.004209
  validation loss:		0.717321
  validation accuracy:		91.09 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.004246
  validation loss:		0.714473
  validation accuracy:		90.65 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.713782
  validation accuracy:		90.98 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.004356
  validation loss:		0.721025
  validation accuracy:		90.76 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.004192
  validation loss:		0.714170
  validation accuracy:		90.98 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.004318
  validation loss:		0.715026
  validation accuracy:		90.98 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.004105
  validation loss:		0.711766
  validation accuracy:		91.09 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.713745
  validation accuracy:		90.98 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.004353
  validation loss:		0.722629
  validation accuracy:		90.65 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.004136
  validation loss:		0.708163
  validation accuracy:		91.09 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.004042
  validation loss:		0.724464
  validation accuracy:		91.09 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.004146
  validation loss:		0.716327
  validation accuracy:		90.98 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.712532
  validation accuracy:		91.30 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.004203
  validation loss:		0.716484
  validation accuracy:		90.98 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.004094
  validation loss:		0.711902
  validation accuracy:		91.09 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.004148
  validation loss:		0.717948
  validation accuracy:		90.98 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.004250
  validation loss:		0.720204
  validation accuracy:		90.76 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.004160
  validation loss:		0.721244
  validation accuracy:		90.76 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.004274
  validation loss:		0.727993
  validation accuracy:		90.54 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.004251
  validation loss:		0.720482
  validation accuracy:		90.87 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.004094
  validation loss:		0.721294
  validation accuracy:		91.09 %
Epoch 1945 of 2000 took 0.036s
  training loss:		0.004137
  validation loss:		0.722174
  validation accuracy:		90.98 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.004085
  validation loss:		0.716868
  validation accuracy:		90.87 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.004186
  validation loss:		0.715163
  validation accuracy:		90.98 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.004240
  validation loss:		0.722140
  validation accuracy:		90.76 %
Epoch 1949 of 2000 took 0.036s
  training loss:		0.004047
  validation loss:		0.718985
  validation accuracy:		90.87 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.004206
  validation loss:		0.718494
  validation accuracy:		90.87 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.004058
  validation loss:		0.720193
  validation accuracy:		90.98 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.004123
  validation loss:		0.727450
  validation accuracy:		90.76 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.004097
  validation loss:		0.719072
  validation accuracy:		90.98 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.004140
  validation loss:		0.723454
  validation accuracy:		90.87 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.004043
  validation loss:		0.726518
  validation accuracy:		90.54 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.004190
  validation loss:		0.723405
  validation accuracy:		90.87 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.004013
  validation loss:		0.716866
  validation accuracy:		90.87 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.004111
  validation loss:		0.725650
  validation accuracy:		90.76 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003965
  validation loss:		0.728120
  validation accuracy:		90.65 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.004162
  validation loss:		0.716020
  validation accuracy:		90.98 %
Epoch 1961 of 2000 took 0.036s
  training loss:		0.004109
  validation loss:		0.713943
  validation accuracy:		90.76 %
Epoch 1962 of 2000 took 0.037s
  training loss:		0.004049
  validation loss:		0.717671
  validation accuracy:		90.98 %
Epoch 1963 of 2000 took 0.038s
  training loss:		0.004136
  validation loss:		0.722455
  validation accuracy:		91.09 %
Epoch 1964 of 2000 took 0.038s
  training loss:		0.004061
  validation loss:		0.725262
  validation accuracy:		90.76 %
Epoch 1965 of 2000 took 0.036s
  training loss:		0.003875
  validation loss:		0.722738
  validation accuracy:		90.43 %
Epoch 1966 of 2000 took 0.036s
  training loss:		0.004099
  validation loss:		0.728303
  validation accuracy:		90.76 %
Epoch 1967 of 2000 took 0.038s
  training loss:		0.004126
  validation loss:		0.720513
  validation accuracy:		90.87 %
Epoch 1968 of 2000 took 0.038s
  training loss:		0.004083
  validation loss:		0.727054
  validation accuracy:		90.98 %
Epoch 1969 of 2000 took 0.037s
  training loss:		0.004197
  validation loss:		0.719170
  validation accuracy:		90.98 %
Epoch 1970 of 2000 took 0.037s
  training loss:		0.004119
  validation loss:		0.719715
  validation accuracy:		91.09 %
Epoch 1971 of 2000 took 0.037s
  training loss:		0.003949
  validation loss:		0.727373
  validation accuracy:		90.98 %
Epoch 1972 of 2000 took 0.037s
  training loss:		0.004101
  validation loss:		0.719321
  validation accuracy:		91.09 %
Epoch 1973 of 2000 took 0.037s
  training loss:		0.004025
  validation loss:		0.728045
  validation accuracy:		90.87 %
Epoch 1974 of 2000 took 0.036s
  training loss:		0.004019
  validation loss:		0.726180
  validation accuracy:		90.65 %
Epoch 1975 of 2000 took 0.036s
  training loss:		0.003935
  validation loss:		0.730146
  validation accuracy:		90.65 %
Epoch 1976 of 2000 took 0.036s
  training loss:		0.003961
  validation loss:		0.721307
  validation accuracy:		90.87 %
Epoch 1977 of 2000 took 0.036s
  training loss:		0.003976
  validation loss:		0.720135
  validation accuracy:		90.98 %
Epoch 1978 of 2000 took 0.036s
  training loss:		0.004047
  validation loss:		0.728116
  validation accuracy:		90.76 %
Epoch 1979 of 2000 took 0.036s
  training loss:		0.004004
  validation loss:		0.716675
  validation accuracy:		91.09 %
Epoch 1980 of 2000 took 0.036s
  training loss:		0.003922
  validation loss:		0.726594
  validation accuracy:		90.98 %
Epoch 1981 of 2000 took 0.036s
  training loss:		0.003956
  validation loss:		0.736172
  validation accuracy:		90.76 %
Epoch 1982 of 2000 took 0.036s
  training loss:		0.004034
  validation loss:		0.722799
  validation accuracy:		90.87 %
Epoch 1983 of 2000 took 0.036s
  training loss:		0.004003
  validation loss:		0.718327
  validation accuracy:		91.09 %
Epoch 1984 of 2000 took 0.036s
  training loss:		0.004051
  validation loss:		0.723483
  validation accuracy:		91.09 %
Epoch 1985 of 2000 took 0.036s
  training loss:		0.003954
  validation loss:		0.735782
  validation accuracy:		90.87 %
Epoch 1986 of 2000 took 0.036s
  training loss:		0.003922
  validation loss:		0.720157
  validation accuracy:		91.09 %
Epoch 1987 of 2000 took 0.036s
  training loss:		0.004004
  validation loss:		0.729038
  validation accuracy:		90.98 %
Epoch 1988 of 2000 took 0.036s
  training loss:		0.004009
  validation loss:		0.726799
  validation accuracy:		91.09 %
Epoch 1989 of 2000 took 0.036s
  training loss:		0.004079
  validation loss:		0.727452
  validation accuracy:		90.98 %
Epoch 1990 of 2000 took 0.036s
  training loss:		0.003892
  validation loss:		0.733052
  validation accuracy:		90.76 %
Epoch 1991 of 2000 took 0.036s
  training loss:		0.003890
  validation loss:		0.730063
  validation accuracy:		90.98 %
Epoch 1992 of 2000 took 0.036s
  training loss:		0.003902
  validation loss:		0.722876
  validation accuracy:		90.87 %
Epoch 1993 of 2000 took 0.036s
  training loss:		0.003934
  validation loss:		0.728828
  validation accuracy:		90.98 %
Epoch 1994 of 2000 took 0.036s
  training loss:		0.003801
  validation loss:		0.730336
  validation accuracy:		90.87 %
Epoch 1995 of 2000 took 0.036s
  training loss:		0.003816
  validation loss:		0.725055
  validation accuracy:		90.98 %
Epoch 1996 of 2000 took 0.036s
  training loss:		0.003912
  validation loss:		0.732559
  validation accuracy:		90.87 %
Epoch 1997 of 2000 took 0.036s
  training loss:		0.003907
  validation loss:		0.735788
  validation accuracy:		90.54 %
Epoch 1998 of 2000 took 0.036s
  training loss:		0.003874
  validation loss:		0.734590
  validation accuracy:		90.87 %
Epoch 1999 of 2000 took 0.036s
  training loss:		0.003842
  validation loss:		0.719881
  validation accuracy:		91.09 %
Epoch 2000 of 2000 took 0.036s
  training loss:		0.003817
  validation loss:		0.737845
  validation accuracy:		90.54 %
Final results:
  test loss:			1.754976
  test accuracy:		82.64 %
