Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.054s
  training loss:		2.930315
  validation loss:		2.835490
  validation accuracy:		16.09 %
Epoch 2 of 2000 took 0.044s
  training loss:		2.750234
  validation loss:		2.612416
  validation accuracy:		17.61 %
Epoch 3 of 2000 took 0.040s
  training loss:		2.544602
  validation loss:		2.393403
  validation accuracy:		27.17 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.377340
  validation loss:		2.236295
  validation accuracy:		41.63 %
Epoch 5 of 2000 took 0.038s
  training loss:		2.273993
  validation loss:		2.158192
  validation accuracy:		44.24 %
Epoch 6 of 2000 took 0.037s
  training loss:		2.212674
  validation loss:		2.128693
  validation accuracy:		46.74 %
Epoch 7 of 2000 took 0.038s
  training loss:		2.172025
  validation loss:		2.089404
  validation accuracy:		55.11 %
Epoch 8 of 2000 took 0.037s
  training loss:		2.139162
  validation loss:		2.054055
  validation accuracy:		56.63 %
Epoch 9 of 2000 took 0.038s
  training loss:		2.105035
  validation loss:		2.018375
  validation accuracy:		59.89 %
Epoch 10 of 2000 took 0.037s
  training loss:		2.069529
  validation loss:		1.975153
  validation accuracy:		57.07 %
Epoch 11 of 2000 took 0.038s
  training loss:		2.031160
  validation loss:		1.934913
  validation accuracy:		61.52 %
Epoch 12 of 2000 took 0.037s
  training loss:		1.989562
  validation loss:		1.885693
  validation accuracy:		60.98 %
Epoch 13 of 2000 took 0.037s
  training loss:		1.945013
  validation loss:		1.842669
  validation accuracy:		66.52 %
Epoch 14 of 2000 took 0.037s
  training loss:		1.897705
  validation loss:		1.788697
  validation accuracy:		65.76 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.843822
  validation loss:		1.726854
  validation accuracy:		67.83 %
Epoch 16 of 2000 took 0.051s
  training loss:		1.791239
  validation loss:		1.673801
  validation accuracy:		69.46 %
Epoch 17 of 2000 took 0.053s
  training loss:		1.733036
  validation loss:		1.611637
  validation accuracy:		70.43 %
Epoch 18 of 2000 took 0.045s
  training loss:		1.677471
  validation loss:		1.555269
  validation accuracy:		71.52 %
Epoch 19 of 2000 took 0.040s
  training loss:		1.615428
  validation loss:		1.484984
  validation accuracy:		74.35 %
Epoch 20 of 2000 took 0.037s
  training loss:		1.552524
  validation loss:		1.422375
  validation accuracy:		74.57 %
Epoch 21 of 2000 took 0.035s
  training loss:		1.497677
  validation loss:		1.371122
  validation accuracy:		75.65 %
Epoch 22 of 2000 took 0.035s
  training loss:		1.441056
  validation loss:		1.313575
  validation accuracy:		77.17 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.380765
  validation loss:		1.262131
  validation accuracy:		75.11 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.324337
  validation loss:		1.210339
  validation accuracy:		78.70 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.280140
  validation loss:		1.163782
  validation accuracy:		78.48 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.230972
  validation loss:		1.109430
  validation accuracy:		79.57 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.182831
  validation loss:		1.060940
  validation accuracy:		79.24 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.137877
  validation loss:		1.033699
  validation accuracy:		80.33 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.091373
  validation loss:		0.994124
  validation accuracy:		80.87 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.054471
  validation loss:		0.947422
  validation accuracy:		80.98 %
Epoch 31 of 2000 took 0.035s
  training loss:		1.015229
  validation loss:		0.921300
  validation accuracy:		81.41 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.975336
  validation loss:		0.873034
  validation accuracy:		82.50 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.943007
  validation loss:		0.852517
  validation accuracy:		82.61 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.910525
  validation loss:		0.826978
  validation accuracy:		82.61 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.883847
  validation loss:		0.802277
  validation accuracy:		83.15 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.850021
  validation loss:		0.784927
  validation accuracy:		82.83 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.822599
  validation loss:		0.751047
  validation accuracy:		83.91 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.797525
  validation loss:		0.717822
  validation accuracy:		84.57 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.776342
  validation loss:		0.717655
  validation accuracy:		84.24 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.743229
  validation loss:		0.672128
  validation accuracy:		85.00 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.726216
  validation loss:		0.657455
  validation accuracy:		85.43 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.705138
  validation loss:		0.641553
  validation accuracy:		85.54 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.683167
  validation loss:		0.628311
  validation accuracy:		85.11 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.660290
  validation loss:		0.605877
  validation accuracy:		86.20 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.644039
  validation loss:		0.598965
  validation accuracy:		86.09 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.628504
  validation loss:		0.575083
  validation accuracy:		86.09 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.608672
  validation loss:		0.560308
  validation accuracy:		86.85 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.592702
  validation loss:		0.551891
  validation accuracy:		87.28 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.573826
  validation loss:		0.527534
  validation accuracy:		87.28 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.560119
  validation loss:		0.511693
  validation accuracy:		87.61 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.549928
  validation loss:		0.500866
  validation accuracy:		87.72 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.538511
  validation loss:		0.497651
  validation accuracy:		88.15 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.518752
  validation loss:		0.486342
  validation accuracy:		88.37 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.508668
  validation loss:		0.480819
  validation accuracy:		87.83 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.497321
  validation loss:		0.466911
  validation accuracy:		88.48 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.490752
  validation loss:		0.458127
  validation accuracy:		88.80 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.471965
  validation loss:		0.446453
  validation accuracy:		88.80 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.461486
  validation loss:		0.432160
  validation accuracy:		89.02 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.453803
  validation loss:		0.427751
  validation accuracy:		89.02 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.447524
  validation loss:		0.422576
  validation accuracy:		89.02 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.441736
  validation loss:		0.412664
  validation accuracy:		89.13 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.434220
  validation loss:		0.408047
  validation accuracy:		89.46 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.425606
  validation loss:		0.405209
  validation accuracy:		89.67 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.417321
  validation loss:		0.403964
  validation accuracy:		89.46 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.404298
  validation loss:		0.387459
  validation accuracy:		89.78 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.401003
  validation loss:		0.385073
  validation accuracy:		89.89 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.394576
  validation loss:		0.385184
  validation accuracy:		90.00 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.389618
  validation loss:		0.376469
  validation accuracy:		90.22 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.380541
  validation loss:		0.374332
  validation accuracy:		89.35 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.380579
  validation loss:		0.363084
  validation accuracy:		90.11 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.375139
  validation loss:		0.353695
  validation accuracy:		90.11 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.367063
  validation loss:		0.360948
  validation accuracy:		90.11 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.359259
  validation loss:		0.352081
  validation accuracy:		90.00 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.358609
  validation loss:		0.353471
  validation accuracy:		90.11 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.352018
  validation loss:		0.345067
  validation accuracy:		90.43 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.346000
  validation loss:		0.356301
  validation accuracy:		90.76 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.339451
  validation loss:		0.345222
  validation accuracy:		89.89 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.334876
  validation loss:		0.339586
  validation accuracy:		90.54 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.337625
  validation loss:		0.328705
  validation accuracy:		90.65 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.322862
  validation loss:		0.325183
  validation accuracy:		90.43 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.323791
  validation loss:		0.322820
  validation accuracy:		90.65 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.322501
  validation loss:		0.326803
  validation accuracy:		90.87 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.317928
  validation loss:		0.321322
  validation accuracy:		90.65 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.312063
  validation loss:		0.312221
  validation accuracy:		90.76 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.312533
  validation loss:		0.318627
  validation accuracy:		90.87 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.311174
  validation loss:		0.312556
  validation accuracy:		90.76 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.309870
  validation loss:		0.304908
  validation accuracy:		90.65 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.299923
  validation loss:		0.316088
  validation accuracy:		91.52 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.298366
  validation loss:		0.310399
  validation accuracy:		91.09 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.298590
  validation loss:		0.298185
  validation accuracy:		91.20 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.293074
  validation loss:		0.304013
  validation accuracy:		91.41 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.291318
  validation loss:		0.304396
  validation accuracy:		91.09 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.285822
  validation loss:		0.298359
  validation accuracy:		91.30 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.287977
  validation loss:		0.285669
  validation accuracy:		91.20 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.284224
  validation loss:		0.290546
  validation accuracy:		91.63 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.277318
  validation loss:		0.288743
  validation accuracy:		91.30 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.275223
  validation loss:		0.284929
  validation accuracy:		91.41 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.275168
  validation loss:		0.294131
  validation accuracy:		91.74 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.278453
  validation loss:		0.290662
  validation accuracy:		92.07 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.272816
  validation loss:		0.303081
  validation accuracy:		91.52 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.265793
  validation loss:		0.283567
  validation accuracy:		91.96 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.265331
  validation loss:		0.279780
  validation accuracy:		92.17 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.264364
  validation loss:		0.275310
  validation accuracy:		91.85 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.255627
  validation loss:		0.272869
  validation accuracy:		91.52 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.261463
  validation loss:		0.275944
  validation accuracy:		91.52 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.259266
  validation loss:		0.277702
  validation accuracy:		91.96 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.255233
  validation loss:		0.277217
  validation accuracy:		92.07 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.252844
  validation loss:		0.271801
  validation accuracy:		91.96 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.252232
  validation loss:		0.275814
  validation accuracy:		91.96 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.248705
  validation loss:		0.270465
  validation accuracy:		92.28 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.247001
  validation loss:		0.272205
  validation accuracy:		91.96 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.246083
  validation loss:		0.266389
  validation accuracy:		92.17 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.244953
  validation loss:		0.263414
  validation accuracy:		92.17 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.242243
  validation loss:		0.266367
  validation accuracy:		92.07 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.240723
  validation loss:		0.263102
  validation accuracy:		92.28 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.237785
  validation loss:		0.263799
  validation accuracy:		92.07 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.237349
  validation loss:		0.268483
  validation accuracy:		92.17 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.234994
  validation loss:		0.259045
  validation accuracy:		92.28 %
Epoch 119 of 2000 took 0.038s
  training loss:		0.235310
  validation loss:		0.261174
  validation accuracy:		92.50 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.229100
  validation loss:		0.255701
  validation accuracy:		92.39 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.230805
  validation loss:		0.256663
  validation accuracy:		92.28 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.228005
  validation loss:		0.263336
  validation accuracy:		92.50 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.229693
  validation loss:		0.262719
  validation accuracy:		92.28 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.231213
  validation loss:		0.255339
  validation accuracy:		92.39 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.223530
  validation loss:		0.262024
  validation accuracy:		92.61 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.223862
  validation loss:		0.252153
  validation accuracy:		92.50 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.217893
  validation loss:		0.248075
  validation accuracy:		92.07 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.221354
  validation loss:		0.255528
  validation accuracy:		92.28 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.221329
  validation loss:		0.249971
  validation accuracy:		92.17 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.219886
  validation loss:		0.253560
  validation accuracy:		92.83 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.217361
  validation loss:		0.253600
  validation accuracy:		92.61 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.218994
  validation loss:		0.258986
  validation accuracy:		92.61 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.211536
  validation loss:		0.246908
  validation accuracy:		92.61 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.217016
  validation loss:		0.246938
  validation accuracy:		92.72 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.211826
  validation loss:		0.247821
  validation accuracy:		92.50 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.213682
  validation loss:		0.248217
  validation accuracy:		92.83 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.209960
  validation loss:		0.256865
  validation accuracy:		92.39 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.208991
  validation loss:		0.244211
  validation accuracy:		92.28 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.209649
  validation loss:		0.246303
  validation accuracy:		92.61 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.207018
  validation loss:		0.246958
  validation accuracy:		91.96 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.204637
  validation loss:		0.245279
  validation accuracy:		92.50 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.206990
  validation loss:		0.241386
  validation accuracy:		92.50 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.203438
  validation loss:		0.236279
  validation accuracy:		92.93 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.200373
  validation loss:		0.243756
  validation accuracy:		92.72 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.205121
  validation loss:		0.240205
  validation accuracy:		92.61 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.200621
  validation loss:		0.239154
  validation accuracy:		92.61 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.199288
  validation loss:		0.246001
  validation accuracy:		93.26 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.195818
  validation loss:		0.243140
  validation accuracy:		92.72 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.200919
  validation loss:		0.238190
  validation accuracy:		92.83 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.195758
  validation loss:		0.247424
  validation accuracy:		92.83 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.192224
  validation loss:		0.237269
  validation accuracy:		92.83 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.198019
  validation loss:		0.240858
  validation accuracy:		92.83 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.195356
  validation loss:		0.240177
  validation accuracy:		92.61 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.194457
  validation loss:		0.236042
  validation accuracy:		93.04 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.191492
  validation loss:		0.233244
  validation accuracy:		92.93 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.188193
  validation loss:		0.232328
  validation accuracy:		92.50 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.192533
  validation loss:		0.234814
  validation accuracy:		92.93 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.188672
  validation loss:		0.235203
  validation accuracy:		92.72 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.185049
  validation loss:		0.234810
  validation accuracy:		92.83 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.188494
  validation loss:		0.238722
  validation accuracy:		93.04 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.186615
  validation loss:		0.236270
  validation accuracy:		92.93 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.183256
  validation loss:		0.235460
  validation accuracy:		92.83 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.184569
  validation loss:		0.239316
  validation accuracy:		92.93 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.181460
  validation loss:		0.228489
  validation accuracy:		92.83 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.185041
  validation loss:		0.232616
  validation accuracy:		92.61 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.181716
  validation loss:		0.235589
  validation accuracy:		92.72 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.181554
  validation loss:		0.232673
  validation accuracy:		92.72 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.178068
  validation loss:		0.229608
  validation accuracy:		92.83 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.180859
  validation loss:		0.225751
  validation accuracy:		93.04 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.177207
  validation loss:		0.230324
  validation accuracy:		92.39 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.176522
  validation loss:		0.227503
  validation accuracy:		92.72 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.175844
  validation loss:		0.227808
  validation accuracy:		93.15 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.176263
  validation loss:		0.239209
  validation accuracy:		92.83 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.173564
  validation loss:		0.223132
  validation accuracy:		92.93 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.173647
  validation loss:		0.235824
  validation accuracy:		93.04 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.172414
  validation loss:		0.229120
  validation accuracy:		93.04 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.172273
  validation loss:		0.233905
  validation accuracy:		93.37 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.172416
  validation loss:		0.227006
  validation accuracy:		93.15 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.171802
  validation loss:		0.231965
  validation accuracy:		93.26 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.167583
  validation loss:		0.224098
  validation accuracy:		93.26 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.170273
  validation loss:		0.229173
  validation accuracy:		92.50 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.166695
  validation loss:		0.223352
  validation accuracy:		93.26 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.166901
  validation loss:		0.226308
  validation accuracy:		93.04 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.167566
  validation loss:		0.222506
  validation accuracy:		93.15 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.166955
  validation loss:		0.223697
  validation accuracy:		92.83 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.164483
  validation loss:		0.229775
  validation accuracy:		92.93 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.163491
  validation loss:		0.224810
  validation accuracy:		93.26 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.165152
  validation loss:		0.221679
  validation accuracy:		93.37 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.164624
  validation loss:		0.223268
  validation accuracy:		93.37 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.162889
  validation loss:		0.225741
  validation accuracy:		92.72 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.160872
  validation loss:		0.225349
  validation accuracy:		92.93 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.164238
  validation loss:		0.230280
  validation accuracy:		92.93 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.160614
  validation loss:		0.222461
  validation accuracy:		92.93 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.157289
  validation loss:		0.221901
  validation accuracy:		93.15 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.160376
  validation loss:		0.231745
  validation accuracy:		93.04 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.159621
  validation loss:		0.229671
  validation accuracy:		93.59 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.159701
  validation loss:		0.228652
  validation accuracy:		93.59 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.158636
  validation loss:		0.228101
  validation accuracy:		93.15 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.160054
  validation loss:		0.221581
  validation accuracy:		93.15 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.155259
  validation loss:		0.219968
  validation accuracy:		93.15 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.155709
  validation loss:		0.228863
  validation accuracy:		93.48 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.152276
  validation loss:		0.219841
  validation accuracy:		93.37 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.152634
  validation loss:		0.221738
  validation accuracy:		93.26 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.152343
  validation loss:		0.222474
  validation accuracy:		92.93 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.152131
  validation loss:		0.229069
  validation accuracy:		93.59 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.152790
  validation loss:		0.235136
  validation accuracy:		93.59 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.152811
  validation loss:		0.229299
  validation accuracy:		92.83 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.153245
  validation loss:		0.226475
  validation accuracy:		93.26 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.148997
  validation loss:		0.230920
  validation accuracy:		93.04 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.151720
  validation loss:		0.221851
  validation accuracy:		93.59 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.151639
  validation loss:		0.221390
  validation accuracy:		93.26 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.147810
  validation loss:		0.223138
  validation accuracy:		93.48 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.149783
  validation loss:		0.222952
  validation accuracy:		93.04 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.145427
  validation loss:		0.224622
  validation accuracy:		92.72 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.149584
  validation loss:		0.218888
  validation accuracy:		93.26 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.144638
  validation loss:		0.217049
  validation accuracy:		93.26 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.146902
  validation loss:		0.224155
  validation accuracy:		93.59 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.145148
  validation loss:		0.227445
  validation accuracy:		93.04 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.143936
  validation loss:		0.218495
  validation accuracy:		93.37 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.146930
  validation loss:		0.219060
  validation accuracy:		93.15 %
Epoch 221 of 2000 took 0.038s
  training loss:		0.144774
  validation loss:		0.224157
  validation accuracy:		93.48 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.144070
  validation loss:		0.221933
  validation accuracy:		93.48 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.146332
  validation loss:		0.218163
  validation accuracy:		93.37 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.137669
  validation loss:		0.220212
  validation accuracy:		93.04 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.142959
  validation loss:		0.223181
  validation accuracy:		93.37 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.141123
  validation loss:		0.219316
  validation accuracy:		93.48 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.140243
  validation loss:		0.217955
  validation accuracy:		93.91 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.141812
  validation loss:		0.225096
  validation accuracy:		93.48 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.136754
  validation loss:		0.220050
  validation accuracy:		93.48 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.141605
  validation loss:		0.217999
  validation accuracy:		93.59 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.138961
  validation loss:		0.221950
  validation accuracy:		93.37 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.140928
  validation loss:		0.224366
  validation accuracy:		93.37 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.137020
  validation loss:		0.217168
  validation accuracy:		93.26 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.136166
  validation loss:		0.218604
  validation accuracy:		93.15 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.136761
  validation loss:		0.216516
  validation accuracy:		93.48 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.137010
  validation loss:		0.223166
  validation accuracy:		92.72 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.135408
  validation loss:		0.222524
  validation accuracy:		93.70 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.130021
  validation loss:		0.214943
  validation accuracy:		92.83 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.133189
  validation loss:		0.228896
  validation accuracy:		93.48 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.130862
  validation loss:		0.219460
  validation accuracy:		93.59 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.134123
  validation loss:		0.219152
  validation accuracy:		93.37 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.131278
  validation loss:		0.222019
  validation accuracy:		93.59 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.131685
  validation loss:		0.218006
  validation accuracy:		93.70 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.131725
  validation loss:		0.218530
  validation accuracy:		93.80 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.131692
  validation loss:		0.226964
  validation accuracy:		92.28 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.133742
  validation loss:		0.222127
  validation accuracy:		93.70 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.134257
  validation loss:		0.219162
  validation accuracy:		93.04 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.133204
  validation loss:		0.222134
  validation accuracy:		93.59 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.126870
  validation loss:		0.218209
  validation accuracy:		93.48 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.129419
  validation loss:		0.225631
  validation accuracy:		93.04 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.127958
  validation loss:		0.226739
  validation accuracy:		93.91 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.129068
  validation loss:		0.219681
  validation accuracy:		93.48 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.125667
  validation loss:		0.220415
  validation accuracy:		93.15 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.127315
  validation loss:		0.211472
  validation accuracy:		93.37 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.128500
  validation loss:		0.221325
  validation accuracy:		93.37 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.126899
  validation loss:		0.221730
  validation accuracy:		93.48 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.128515
  validation loss:		0.216892
  validation accuracy:		93.37 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.123931
  validation loss:		0.218722
  validation accuracy:		93.48 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.124573
  validation loss:		0.218059
  validation accuracy:		93.91 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.123242
  validation loss:		0.217525
  validation accuracy:		93.80 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.123901
  validation loss:		0.221462
  validation accuracy:		93.26 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.125886
  validation loss:		0.217346
  validation accuracy:		92.93 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.125198
  validation loss:		0.217588
  validation accuracy:		93.70 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.124478
  validation loss:		0.220159
  validation accuracy:		93.59 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.123094
  validation loss:		0.216823
  validation accuracy:		93.26 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.121882
  validation loss:		0.223829
  validation accuracy:		93.91 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.123205
  validation loss:		0.221622
  validation accuracy:		93.70 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.123525
  validation loss:		0.220588
  validation accuracy:		93.70 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.122321
  validation loss:		0.216298
  validation accuracy:		92.93 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.122468
  validation loss:		0.224556
  validation accuracy:		93.26 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.120777
  validation loss:		0.224640
  validation accuracy:		93.59 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.121817
  validation loss:		0.221932
  validation accuracy:		93.37 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.118354
  validation loss:		0.214671
  validation accuracy:		93.37 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.120175
  validation loss:		0.217788
  validation accuracy:		93.80 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.117120
  validation loss:		0.221366
  validation accuracy:		93.91 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.119751
  validation loss:		0.216375
  validation accuracy:		93.91 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.116751
  validation loss:		0.223484
  validation accuracy:		93.59 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.118847
  validation loss:		0.221391
  validation accuracy:		93.91 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.118978
  validation loss:		0.224674
  validation accuracy:		93.70 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.117580
  validation loss:		0.227632
  validation accuracy:		92.93 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.117764
  validation loss:		0.223744
  validation accuracy:		93.04 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.119342
  validation loss:		0.219939
  validation accuracy:		93.70 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.113932
  validation loss:		0.221530
  validation accuracy:		93.70 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.115850
  validation loss:		0.219804
  validation accuracy:		93.91 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.112505
  validation loss:		0.223103
  validation accuracy:		93.70 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.116274
  validation loss:		0.220731
  validation accuracy:		94.13 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.116001
  validation loss:		0.223525
  validation accuracy:		93.26 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.114551
  validation loss:		0.215097
  validation accuracy:		93.37 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.115511
  validation loss:		0.223217
  validation accuracy:		94.13 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.116554
  validation loss:		0.216407
  validation accuracy:		94.02 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.113253
  validation loss:		0.219526
  validation accuracy:		94.13 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.112967
  validation loss:		0.219913
  validation accuracy:		93.80 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.112762
  validation loss:		0.220325
  validation accuracy:		92.72 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.112034
  validation loss:		0.219627
  validation accuracy:		93.91 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.113712
  validation loss:		0.229546
  validation accuracy:		93.37 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.111118
  validation loss:		0.221581
  validation accuracy:		93.70 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.112082
  validation loss:		0.220422
  validation accuracy:		93.70 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.109222
  validation loss:		0.218157
  validation accuracy:		93.59 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.110083
  validation loss:		0.221607
  validation accuracy:		93.91 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.112630
  validation loss:		0.221388
  validation accuracy:		93.70 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.108974
  validation loss:		0.216451
  validation accuracy:		93.80 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.109119
  validation loss:		0.232185
  validation accuracy:		93.15 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.111770
  validation loss:		0.214416
  validation accuracy:		93.59 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.110519
  validation loss:		0.218235
  validation accuracy:		93.26 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.110857
  validation loss:		0.222465
  validation accuracy:		93.70 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.107655
  validation loss:		0.216599
  validation accuracy:		93.59 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.107785
  validation loss:		0.221114
  validation accuracy:		93.70 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.106286
  validation loss:		0.223343
  validation accuracy:		93.48 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.108108
  validation loss:		0.230437
  validation accuracy:		93.59 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.107234
  validation loss:		0.224021
  validation accuracy:		93.80 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.106719
  validation loss:		0.230720
  validation accuracy:		93.37 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.105166
  validation loss:		0.216239
  validation accuracy:		94.02 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.104932
  validation loss:		0.222179
  validation accuracy:		94.13 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.107140
  validation loss:		0.225405
  validation accuracy:		93.37 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.104164
  validation loss:		0.226542
  validation accuracy:		94.02 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.106486
  validation loss:		0.223426
  validation accuracy:		93.48 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.105830
  validation loss:		0.223299
  validation accuracy:		93.70 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.105130
  validation loss:		0.227618
  validation accuracy:		93.91 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.106078
  validation loss:		0.216299
  validation accuracy:		93.80 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.107063
  validation loss:		0.221900
  validation accuracy:		93.80 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.104027
  validation loss:		0.217111
  validation accuracy:		93.70 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.108251
  validation loss:		0.224212
  validation accuracy:		93.91 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.102686
  validation loss:		0.223413
  validation accuracy:		93.04 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.102895
  validation loss:		0.221951
  validation accuracy:		92.83 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.104276
  validation loss:		0.220695
  validation accuracy:		93.70 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.101325
  validation loss:		0.223889
  validation accuracy:		94.02 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.104913
  validation loss:		0.216654
  validation accuracy:		93.80 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.102002
  validation loss:		0.221736
  validation accuracy:		94.13 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.099705
  validation loss:		0.218439
  validation accuracy:		93.91 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.100115
  validation loss:		0.226291
  validation accuracy:		93.48 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.101011
  validation loss:		0.224522
  validation accuracy:		94.02 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.102310
  validation loss:		0.224434
  validation accuracy:		93.48 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.100372
  validation loss:		0.226074
  validation accuracy:		93.59 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.101786
  validation loss:		0.229295
  validation accuracy:		93.59 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.100104
  validation loss:		0.220338
  validation accuracy:		93.91 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.099662
  validation loss:		0.224154
  validation accuracy:		93.37 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.097500
  validation loss:		0.227836
  validation accuracy:		93.70 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.098879
  validation loss:		0.222475
  validation accuracy:		93.48 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.097725
  validation loss:		0.222243
  validation accuracy:		93.80 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.100334
  validation loss:		0.224744
  validation accuracy:		94.02 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.099584
  validation loss:		0.221483
  validation accuracy:		94.13 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.097998
  validation loss:		0.220482
  validation accuracy:		93.04 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.097983
  validation loss:		0.219248
  validation accuracy:		94.02 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.094723
  validation loss:		0.227163
  validation accuracy:		93.80 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.096615
  validation loss:		0.228205
  validation accuracy:		94.02 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.097381
  validation loss:		0.224862
  validation accuracy:		93.80 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.096864
  validation loss:		0.219963
  validation accuracy:		93.48 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.098741
  validation loss:		0.226264
  validation accuracy:		93.59 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.096959
  validation loss:		0.225118
  validation accuracy:		93.37 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.094282
  validation loss:		0.230464
  validation accuracy:		93.91 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.095076
  validation loss:		0.223447
  validation accuracy:		93.59 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.092246
  validation loss:		0.227313
  validation accuracy:		93.70 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.089179
  validation loss:		0.223675
  validation accuracy:		93.91 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.092725
  validation loss:		0.228055
  validation accuracy:		94.02 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.097234
  validation loss:		0.228239
  validation accuracy:		93.59 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.094384
  validation loss:		0.224054
  validation accuracy:		93.59 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.096037
  validation loss:		0.227203
  validation accuracy:		93.91 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.088427
  validation loss:		0.234816
  validation accuracy:		93.37 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.093723
  validation loss:		0.221475
  validation accuracy:		93.70 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.092281
  validation loss:		0.226350
  validation accuracy:		94.13 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.090910
  validation loss:		0.224389
  validation accuracy:		94.02 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.091990
  validation loss:		0.229631
  validation accuracy:		94.02 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.094137
  validation loss:		0.235783
  validation accuracy:		93.48 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.093040
  validation loss:		0.224156
  validation accuracy:		93.91 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.090566
  validation loss:		0.226042
  validation accuracy:		93.80 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.092612
  validation loss:		0.226426
  validation accuracy:		93.26 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.090866
  validation loss:		0.229199
  validation accuracy:		93.70 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.091335
  validation loss:		0.232235
  validation accuracy:		93.91 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.087632
  validation loss:		0.230110
  validation accuracy:		93.37 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.091137
  validation loss:		0.223850
  validation accuracy:		93.70 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.088279
  validation loss:		0.220389
  validation accuracy:		94.13 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.090917
  validation loss:		0.230449
  validation accuracy:		93.91 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.090808
  validation loss:		0.229525
  validation accuracy:		93.59 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.087783
  validation loss:		0.221568
  validation accuracy:		93.59 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.091267
  validation loss:		0.229289
  validation accuracy:		93.80 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.092070
  validation loss:		0.233396
  validation accuracy:		93.70 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.091664
  validation loss:		0.224288
  validation accuracy:		93.15 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.088150
  validation loss:		0.235173
  validation accuracy:		93.48 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.087330
  validation loss:		0.225027
  validation accuracy:		93.48 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.087444
  validation loss:		0.226563
  validation accuracy:		94.13 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.086869
  validation loss:		0.225821
  validation accuracy:		93.91 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.087053
  validation loss:		0.232486
  validation accuracy:		93.59 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.088702
  validation loss:		0.238527
  validation accuracy:		93.48 %
Epoch 384 of 2000 took 0.038s
  training loss:		0.086674
  validation loss:		0.235739
  validation accuracy:		94.13 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.087430
  validation loss:		0.233717
  validation accuracy:		93.15 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.088912
  validation loss:		0.236355
  validation accuracy:		93.59 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.088229
  validation loss:		0.236436
  validation accuracy:		93.59 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.086927
  validation loss:		0.231411
  validation accuracy:		93.91 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.085459
  validation loss:		0.226871
  validation accuracy:		94.02 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.085539
  validation loss:		0.240391
  validation accuracy:		92.83 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.085225
  validation loss:		0.227526
  validation accuracy:		93.59 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.085381
  validation loss:		0.235559
  validation accuracy:		93.37 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.085602
  validation loss:		0.234837
  validation accuracy:		93.15 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.087485
  validation loss:		0.234557
  validation accuracy:		93.59 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.086398
  validation loss:		0.230741
  validation accuracy:		93.37 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.083942
  validation loss:		0.233953
  validation accuracy:		93.91 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.085054
  validation loss:		0.232024
  validation accuracy:		93.80 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.085423
  validation loss:		0.232883
  validation accuracy:		93.48 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.084261
  validation loss:		0.236886
  validation accuracy:		93.80 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.082242
  validation loss:		0.226915
  validation accuracy:		93.70 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.084182
  validation loss:		0.238757
  validation accuracy:		93.48 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.082740
  validation loss:		0.236619
  validation accuracy:		93.70 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.084806
  validation loss:		0.231323
  validation accuracy:		93.80 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.082361
  validation loss:		0.229793
  validation accuracy:		93.37 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.083838
  validation loss:		0.229173
  validation accuracy:		93.91 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.082618
  validation loss:		0.232790
  validation accuracy:		93.37 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.082985
  validation loss:		0.232652
  validation accuracy:		93.91 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.078789
  validation loss:		0.232888
  validation accuracy:		93.70 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.082650
  validation loss:		0.231479
  validation accuracy:		93.37 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.081423
  validation loss:		0.234189
  validation accuracy:		93.59 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.080281
  validation loss:		0.234250
  validation accuracy:		93.48 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.080597
  validation loss:		0.234733
  validation accuracy:		93.59 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.079353
  validation loss:		0.235970
  validation accuracy:		93.59 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.081298
  validation loss:		0.239474
  validation accuracy:		93.59 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.079981
  validation loss:		0.231748
  validation accuracy:		93.48 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.080136
  validation loss:		0.237704
  validation accuracy:		93.80 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.081208
  validation loss:		0.235247
  validation accuracy:		93.26 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.077943
  validation loss:		0.233872
  validation accuracy:		93.26 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.079778
  validation loss:		0.237900
  validation accuracy:		93.48 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.076597
  validation loss:		0.232068
  validation accuracy:		93.37 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.078250
  validation loss:		0.239618
  validation accuracy:		93.37 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.080271
  validation loss:		0.233141
  validation accuracy:		93.91 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.076707
  validation loss:		0.239992
  validation accuracy:		94.02 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.078549
  validation loss:		0.236907
  validation accuracy:		93.37 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.076707
  validation loss:		0.234740
  validation accuracy:		93.59 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.078029
  validation loss:		0.235062
  validation accuracy:		93.70 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.078051
  validation loss:		0.235946
  validation accuracy:		93.91 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.076594
  validation loss:		0.235806
  validation accuracy:		93.04 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.077385
  validation loss:		0.240197
  validation accuracy:		93.59 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.078570
  validation loss:		0.234548
  validation accuracy:		93.80 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.077401
  validation loss:		0.249786
  validation accuracy:		93.48 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.077378
  validation loss:		0.235324
  validation accuracy:		93.26 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.076089
  validation loss:		0.237512
  validation accuracy:		93.59 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.076778
  validation loss:		0.238957
  validation accuracy:		93.59 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.076909
  validation loss:		0.236537
  validation accuracy:		93.80 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.076368
  validation loss:		0.244866
  validation accuracy:		93.37 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.075804
  validation loss:		0.245745
  validation accuracy:		93.80 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.077697
  validation loss:		0.240410
  validation accuracy:		93.59 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.074851
  validation loss:		0.237623
  validation accuracy:		93.70 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.074559
  validation loss:		0.235208
  validation accuracy:		94.02 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.074993
  validation loss:		0.237306
  validation accuracy:		93.70 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.076448
  validation loss:		0.236574
  validation accuracy:		93.70 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.075318
  validation loss:		0.240660
  validation accuracy:		93.26 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.075474
  validation loss:		0.239473
  validation accuracy:		93.59 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.074905
  validation loss:		0.232483
  validation accuracy:		93.37 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.072398
  validation loss:		0.236344
  validation accuracy:		93.80 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.074115
  validation loss:		0.238313
  validation accuracy:		93.59 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.076140
  validation loss:		0.243104
  validation accuracy:		93.48 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.074521
  validation loss:		0.243946
  validation accuracy:		93.59 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.073290
  validation loss:		0.236421
  validation accuracy:		93.37 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.073113
  validation loss:		0.230463
  validation accuracy:		93.91 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.072610
  validation loss:		0.240599
  validation accuracy:		93.80 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.071857
  validation loss:		0.240209
  validation accuracy:		93.37 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.069887
  validation loss:		0.242614
  validation accuracy:		93.70 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.072919
  validation loss:		0.243696
  validation accuracy:		93.70 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.071808
  validation loss:		0.240815
  validation accuracy:		92.83 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.072741
  validation loss:		0.246677
  validation accuracy:		93.59 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.071993
  validation loss:		0.239157
  validation accuracy:		93.26 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.070307
  validation loss:		0.240932
  validation accuracy:		93.48 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.071643
  validation loss:		0.242277
  validation accuracy:		93.15 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.071200
  validation loss:		0.238770
  validation accuracy:		93.80 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.072534
  validation loss:		0.238328
  validation accuracy:		93.59 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.070123
  validation loss:		0.243049
  validation accuracy:		93.70 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.069920
  validation loss:		0.236030
  validation accuracy:		93.80 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.070104
  validation loss:		0.247888
  validation accuracy:		93.48 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.071842
  validation loss:		0.242443
  validation accuracy:		93.48 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.070985
  validation loss:		0.240102
  validation accuracy:		93.59 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.069525
  validation loss:		0.236506
  validation accuracy:		93.70 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.071043
  validation loss:		0.236119
  validation accuracy:		93.15 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.068728
  validation loss:		0.235365
  validation accuracy:		93.70 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.070680
  validation loss:		0.242752
  validation accuracy:		93.37 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.071277
  validation loss:		0.245251
  validation accuracy:		93.48 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.071431
  validation loss:		0.239488
  validation accuracy:		93.70 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.070547
  validation loss:		0.237859
  validation accuracy:		93.80 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.069456
  validation loss:		0.240769
  validation accuracy:		93.80 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.067701
  validation loss:		0.247264
  validation accuracy:		93.26 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.067008
  validation loss:		0.247027
  validation accuracy:		93.26 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.068990
  validation loss:		0.245586
  validation accuracy:		93.59 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.065327
  validation loss:		0.245788
  validation accuracy:		93.26 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.068595
  validation loss:		0.243930
  validation accuracy:		93.26 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.069455
  validation loss:		0.241796
  validation accuracy:		93.48 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.069214
  validation loss:		0.240965
  validation accuracy:		93.37 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.065895
  validation loss:		0.251420
  validation accuracy:		92.93 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.068968
  validation loss:		0.248230
  validation accuracy:		93.70 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.066399
  validation loss:		0.247433
  validation accuracy:		93.48 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.064137
  validation loss:		0.243887
  validation accuracy:		93.91 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.067619
  validation loss:		0.246523
  validation accuracy:		93.26 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.065047
  validation loss:		0.242642
  validation accuracy:		93.70 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.067190
  validation loss:		0.248930
  validation accuracy:		93.80 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.065231
  validation loss:		0.246904
  validation accuracy:		93.59 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.065112
  validation loss:		0.244681
  validation accuracy:		92.83 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.066860
  validation loss:		0.255850
  validation accuracy:		93.48 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.066262
  validation loss:		0.251858
  validation accuracy:		93.70 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.063818
  validation loss:		0.243665
  validation accuracy:		93.37 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.068558
  validation loss:		0.243316
  validation accuracy:		93.59 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.066516
  validation loss:		0.243526
  validation accuracy:		93.80 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.066763
  validation loss:		0.249175
  validation accuracy:		93.26 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.066312
  validation loss:		0.244159
  validation accuracy:		93.37 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.064521
  validation loss:		0.243417
  validation accuracy:		93.37 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.062626
  validation loss:		0.255640
  validation accuracy:		93.26 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.061716
  validation loss:		0.248295
  validation accuracy:		93.15 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.064213
  validation loss:		0.255317
  validation accuracy:		93.59 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.064258
  validation loss:		0.251770
  validation accuracy:		93.70 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.064860
  validation loss:		0.247826
  validation accuracy:		93.37 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.063956
  validation loss:		0.245691
  validation accuracy:		93.48 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.061756
  validation loss:		0.248494
  validation accuracy:		93.48 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.063494
  validation loss:		0.257050
  validation accuracy:		93.37 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.063703
  validation loss:		0.243794
  validation accuracy:		93.59 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.064197
  validation loss:		0.251267
  validation accuracy:		93.37 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.063098
  validation loss:		0.254250
  validation accuracy:		93.37 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.062381
  validation loss:		0.247886
  validation accuracy:		93.59 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.064895
  validation loss:		0.251800
  validation accuracy:		93.26 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.062405
  validation loss:		0.248561
  validation accuracy:		93.48 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.063718
  validation loss:		0.246539
  validation accuracy:		93.48 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.060476
  validation loss:		0.260946
  validation accuracy:		93.15 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.062620
  validation loss:		0.257205
  validation accuracy:		93.59 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.061195
  validation loss:		0.255047
  validation accuracy:		93.59 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.062479
  validation loss:		0.248315
  validation accuracy:		93.37 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.061023
  validation loss:		0.254892
  validation accuracy:		93.26 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.061205
  validation loss:		0.246556
  validation accuracy:		93.48 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.061759
  validation loss:		0.249269
  validation accuracy:		93.59 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.063137
  validation loss:		0.251930
  validation accuracy:		93.59 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.062378
  validation loss:		0.257770
  validation accuracy:		93.70 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.062317
  validation loss:		0.252007
  validation accuracy:		93.48 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.061852
  validation loss:		0.260422
  validation accuracy:		93.48 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.058778
  validation loss:		0.254902
  validation accuracy:		93.48 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.060107
  validation loss:		0.249905
  validation accuracy:		93.48 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.059923
  validation loss:		0.262122
  validation accuracy:		93.37 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.061152
  validation loss:		0.258038
  validation accuracy:		93.37 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.062425
  validation loss:		0.254972
  validation accuracy:		93.48 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.061130
  validation loss:		0.247621
  validation accuracy:		93.48 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.060329
  validation loss:		0.250392
  validation accuracy:		93.70 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.058903
  validation loss:		0.258658
  validation accuracy:		93.04 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.059010
  validation loss:		0.256181
  validation accuracy:		93.37 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.057999
  validation loss:		0.255154
  validation accuracy:		93.70 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.060052
  validation loss:		0.256674
  validation accuracy:		93.48 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.058236
  validation loss:		0.255192
  validation accuracy:		93.15 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.060404
  validation loss:		0.257913
  validation accuracy:		93.70 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.058527
  validation loss:		0.265877
  validation accuracy:		92.93 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.057859
  validation loss:		0.254195
  validation accuracy:		93.37 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.059773
  validation loss:		0.248182
  validation accuracy:		93.37 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.060080
  validation loss:		0.263083
  validation accuracy:		93.37 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.058017
  validation loss:		0.251917
  validation accuracy:		93.48 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.058356
  validation loss:		0.259866
  validation accuracy:		93.37 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.058382
  validation loss:		0.259939
  validation accuracy:		93.59 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.059148
  validation loss:		0.254931
  validation accuracy:		93.26 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.058326
  validation loss:		0.256606
  validation accuracy:		93.48 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.056103
  validation loss:		0.260690
  validation accuracy:		93.59 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.058568
  validation loss:		0.256181
  validation accuracy:		93.37 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.057015
  validation loss:		0.255091
  validation accuracy:		93.37 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.058903
  validation loss:		0.258778
  validation accuracy:		93.48 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.057522
  validation loss:		0.259556
  validation accuracy:		93.48 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.053847
  validation loss:		0.259660
  validation accuracy:		93.48 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.056916
  validation loss:		0.261681
  validation accuracy:		93.59 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.055324
  validation loss:		0.256019
  validation accuracy:		93.15 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.057894
  validation loss:		0.253612
  validation accuracy:		93.37 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.056456
  validation loss:		0.264669
  validation accuracy:		93.70 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.057192
  validation loss:		0.261582
  validation accuracy:		93.48 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.054509
  validation loss:		0.263918
  validation accuracy:		93.48 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.057592
  validation loss:		0.259394
  validation accuracy:		93.59 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.057226
  validation loss:		0.250267
  validation accuracy:		93.26 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.056420
  validation loss:		0.264749
  validation accuracy:		93.59 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.057509
  validation loss:		0.260131
  validation accuracy:		93.48 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.056056
  validation loss:		0.257925
  validation accuracy:		93.15 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.057720
  validation loss:		0.264552
  validation accuracy:		93.37 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.053928
  validation loss:		0.265819
  validation accuracy:		93.70 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.054527
  validation loss:		0.260068
  validation accuracy:		93.04 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.055161
  validation loss:		0.261839
  validation accuracy:		93.80 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.055888
  validation loss:		0.258340
  validation accuracy:		93.26 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.054475
  validation loss:		0.264524
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.053516
  validation loss:		0.261580
  validation accuracy:		93.37 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.053313
  validation loss:		0.258330
  validation accuracy:		93.37 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.054562
  validation loss:		0.262725
  validation accuracy:		93.37 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.053283
  validation loss:		0.269799
  validation accuracy:		93.59 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.054059
  validation loss:		0.258512
  validation accuracy:		93.48 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.053753
  validation loss:		0.271762
  validation accuracy:		93.48 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.053414
  validation loss:		0.271480
  validation accuracy:		93.48 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.054717
  validation loss:		0.259451
  validation accuracy:		93.48 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.051663
  validation loss:		0.265823
  validation accuracy:		93.48 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.052454
  validation loss:		0.268850
  validation accuracy:		93.26 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.054259
  validation loss:		0.268607
  validation accuracy:		93.48 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.052186
  validation loss:		0.258437
  validation accuracy:		93.26 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.053441
  validation loss:		0.258904
  validation accuracy:		93.59 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.051685
  validation loss:		0.264425
  validation accuracy:		93.48 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.052507
  validation loss:		0.263455
  validation accuracy:		93.37 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.051948
  validation loss:		0.270232
  validation accuracy:		93.70 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.053461
  validation loss:		0.269387
  validation accuracy:		93.37 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.052967
  validation loss:		0.269262
  validation accuracy:		93.48 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.051480
  validation loss:		0.267754
  validation accuracy:		93.37 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.049710
  validation loss:		0.263337
  validation accuracy:		93.26 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.052962
  validation loss:		0.273264
  validation accuracy:		93.48 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.052060
  validation loss:		0.262133
  validation accuracy:		93.48 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.051872
  validation loss:		0.266804
  validation accuracy:		93.37 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.050829
  validation loss:		0.265102
  validation accuracy:		93.37 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.051555
  validation loss:		0.268124
  validation accuracy:		93.59 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.051504
  validation loss:		0.268726
  validation accuracy:		93.48 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.052846
  validation loss:		0.269952
  validation accuracy:		93.37 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.050038
  validation loss:		0.264541
  validation accuracy:		93.70 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.051009
  validation loss:		0.276135
  validation accuracy:		93.37 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.052504
  validation loss:		0.261045
  validation accuracy:		93.26 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.050833
  validation loss:		0.265060
  validation accuracy:		93.48 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.050337
  validation loss:		0.281210
  validation accuracy:		93.70 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.051500
  validation loss:		0.270091
  validation accuracy:		93.59 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.049798
  validation loss:		0.265526
  validation accuracy:		93.37 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.050856
  validation loss:		0.273043
  validation accuracy:		93.37 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.049502
  validation loss:		0.271608
  validation accuracy:		93.70 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.050348
  validation loss:		0.277463
  validation accuracy:		93.70 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.050438
  validation loss:		0.269314
  validation accuracy:		93.26 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.048580
  validation loss:		0.271425
  validation accuracy:		93.48 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.050891
  validation loss:		0.268536
  validation accuracy:		93.15 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.049481
  validation loss:		0.271229
  validation accuracy:		93.48 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.050289
  validation loss:		0.266533
  validation accuracy:		93.26 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.048256
  validation loss:		0.271698
  validation accuracy:		93.59 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.048846
  validation loss:		0.266616
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.049990
  validation loss:		0.268758
  validation accuracy:		93.59 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.047904
  validation loss:		0.269709
  validation accuracy:		93.48 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.049677
  validation loss:		0.267733
  validation accuracy:		93.59 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.047563
  validation loss:		0.274905
  validation accuracy:		93.04 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.049757
  validation loss:		0.267253
  validation accuracy:		93.59 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.048650
  validation loss:		0.273530
  validation accuracy:		93.59 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.046885
  validation loss:		0.277173
  validation accuracy:		93.37 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.047632
  validation loss:		0.278698
  validation accuracy:		93.48 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.047134
  validation loss:		0.273163
  validation accuracy:		93.59 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.049254
  validation loss:		0.272717
  validation accuracy:		93.37 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.048037
  validation loss:		0.270874
  validation accuracy:		93.48 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.048783
  validation loss:		0.262406
  validation accuracy:		93.48 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.046828
  validation loss:		0.269736
  validation accuracy:		93.59 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.047256
  validation loss:		0.270281
  validation accuracy:		93.26 %
Epoch 629 of 2000 took 0.037s
  training loss:		0.047405
  validation loss:		0.273273
  validation accuracy:		93.48 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.047092
  validation loss:		0.272688
  validation accuracy:		93.48 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.047606
  validation loss:		0.273242
  validation accuracy:		93.48 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.046619
  validation loss:		0.275982
  validation accuracy:		93.48 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.046288
  validation loss:		0.273271
  validation accuracy:		93.26 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.046731
  validation loss:		0.277099
  validation accuracy:		93.26 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.046881
  validation loss:		0.269696
  validation accuracy:		93.70 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.046928
  validation loss:		0.271519
  validation accuracy:		93.48 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.047113
  validation loss:		0.269175
  validation accuracy:		93.37 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.047189
  validation loss:		0.267707
  validation accuracy:		93.59 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.047129
  validation loss:		0.276231
  validation accuracy:		93.37 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.046431
  validation loss:		0.274153
  validation accuracy:		93.59 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.047320
  validation loss:		0.272549
  validation accuracy:		93.48 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.046219
  validation loss:		0.275736
  validation accuracy:		93.59 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.046201
  validation loss:		0.283082
  validation accuracy:		93.15 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.045360
  validation loss:		0.278256
  validation accuracy:		93.37 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.045659
  validation loss:		0.281335
  validation accuracy:		93.26 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.045189
  validation loss:		0.282246
  validation accuracy:		93.59 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.046484
  validation loss:		0.277334
  validation accuracy:		93.80 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.043980
  validation loss:		0.269911
  validation accuracy:		93.70 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.044423
  validation loss:		0.279983
  validation accuracy:		93.37 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.043044
  validation loss:		0.288050
  validation accuracy:		93.59 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.044265
  validation loss:		0.283087
  validation accuracy:		93.37 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.046164
  validation loss:		0.281637
  validation accuracy:		93.48 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.043881
  validation loss:		0.278873
  validation accuracy:		93.26 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.044834
  validation loss:		0.271711
  validation accuracy:		93.59 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.042882
  validation loss:		0.280626
  validation accuracy:		93.37 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.044698
  validation loss:		0.284415
  validation accuracy:		93.59 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.041982
  validation loss:		0.279072
  validation accuracy:		93.48 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.044727
  validation loss:		0.274431
  validation accuracy:		93.48 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.043618
  validation loss:		0.283024
  validation accuracy:		93.70 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.044169
  validation loss:		0.277702
  validation accuracy:		93.59 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.043050
  validation loss:		0.281994
  validation accuracy:		93.37 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.043453
  validation loss:		0.278698
  validation accuracy:		93.37 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.043842
  validation loss:		0.279865
  validation accuracy:		93.70 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.042042
  validation loss:		0.281566
  validation accuracy:		93.37 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.042185
  validation loss:		0.272988
  validation accuracy:		93.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.043235
  validation loss:		0.278075
  validation accuracy:		93.59 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.042540
  validation loss:		0.275024
  validation accuracy:		93.48 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.043091
  validation loss:		0.277203
  validation accuracy:		93.48 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.041101
  validation loss:		0.288738
  validation accuracy:		93.59 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.043589
  validation loss:		0.283857
  validation accuracy:		93.70 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.042894
  validation loss:		0.286100
  validation accuracy:		93.48 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.042747
  validation loss:		0.281319
  validation accuracy:		93.37 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.041638
  validation loss:		0.280145
  validation accuracy:		93.80 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.041369
  validation loss:		0.277619
  validation accuracy:		93.37 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.041327
  validation loss:		0.288349
  validation accuracy:		93.37 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.042726
  validation loss:		0.278934
  validation accuracy:		93.59 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.042214
  validation loss:		0.289150
  validation accuracy:		93.37 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.040009
  validation loss:		0.276871
  validation accuracy:		93.37 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.043709
  validation loss:		0.285802
  validation accuracy:		93.15 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.040973
  validation loss:		0.281694
  validation accuracy:		93.70 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.039469
  validation loss:		0.281103
  validation accuracy:		93.59 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.041069
  validation loss:		0.294454
  validation accuracy:		93.37 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.040781
  validation loss:		0.289323
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.040983
  validation loss:		0.284204
  validation accuracy:		93.26 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.041270
  validation loss:		0.290844
  validation accuracy:		93.59 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.041778
  validation loss:		0.284451
  validation accuracy:		93.70 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.041388
  validation loss:		0.290481
  validation accuracy:		93.15 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.037883
  validation loss:		0.286674
  validation accuracy:		93.48 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.041301
  validation loss:		0.294858
  validation accuracy:		93.59 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.041258
  validation loss:		0.290537
  validation accuracy:		93.59 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.039245
  validation loss:		0.294710
  validation accuracy:		93.48 %
Epoch 692 of 2000 took 0.036s
  training loss:		0.038996
  validation loss:		0.286327
  validation accuracy:		93.26 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.040696
  validation loss:		0.293394
  validation accuracy:		93.37 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.041294
  validation loss:		0.290871
  validation accuracy:		93.59 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.040286
  validation loss:		0.280412
  validation accuracy:		93.59 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.040091
  validation loss:		0.286981
  validation accuracy:		93.59 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.040085
  validation loss:		0.288625
  validation accuracy:		93.48 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.039601
  validation loss:		0.284974
  validation accuracy:		93.70 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.039244
  validation loss:		0.292501
  validation accuracy:		93.70 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.039795
  validation loss:		0.294181
  validation accuracy:		93.37 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.037798
  validation loss:		0.286241
  validation accuracy:		93.48 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.038708
  validation loss:		0.293186
  validation accuracy:		93.37 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.039425
  validation loss:		0.295169
  validation accuracy:		93.59 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.037696
  validation loss:		0.285404
  validation accuracy:		93.15 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.039193
  validation loss:		0.290056
  validation accuracy:		93.59 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.037138
  validation loss:		0.288738
  validation accuracy:		93.26 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.037833
  validation loss:		0.292654
  validation accuracy:		93.37 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.039364
  validation loss:		0.292876
  validation accuracy:		93.48 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.038035
  validation loss:		0.286447
  validation accuracy:		93.59 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.038862
  validation loss:		0.289493
  validation accuracy:		93.15 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.036848
  validation loss:		0.290279
  validation accuracy:		93.70 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.037954
  validation loss:		0.293863
  validation accuracy:		93.48 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.038414
  validation loss:		0.283952
  validation accuracy:		93.26 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.038606
  validation loss:		0.295850
  validation accuracy:		93.70 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.037337
  validation loss:		0.287909
  validation accuracy:		93.37 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.037514
  validation loss:		0.292939
  validation accuracy:		93.37 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.038029
  validation loss:		0.288018
  validation accuracy:		93.59 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.036784
  validation loss:		0.296525
  validation accuracy:		93.48 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.037937
  validation loss:		0.288079
  validation accuracy:		93.48 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.037096
  validation loss:		0.285244
  validation accuracy:		93.70 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.037895
  validation loss:		0.292641
  validation accuracy:		93.15 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.036454
  validation loss:		0.299808
  validation accuracy:		93.26 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.036646
  validation loss:		0.291722
  validation accuracy:		93.59 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.035907
  validation loss:		0.299225
  validation accuracy:		93.48 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.038826
  validation loss:		0.290799
  validation accuracy:		93.70 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.035908
  validation loss:		0.288981
  validation accuracy:		93.15 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.038392
  validation loss:		0.293186
  validation accuracy:		93.48 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.038127
  validation loss:		0.303698
  validation accuracy:		93.37 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.036178
  validation loss:		0.294952
  validation accuracy:		93.59 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.036454
  validation loss:		0.285310
  validation accuracy:		93.48 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.036460
  validation loss:		0.297729
  validation accuracy:		93.37 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.037241
  validation loss:		0.299624
  validation accuracy:		93.80 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.036333
  validation loss:		0.289372
  validation accuracy:		93.70 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.036267
  validation loss:		0.291644
  validation accuracy:		93.59 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.036915
  validation loss:		0.299521
  validation accuracy:		93.48 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.036591
  validation loss:		0.300990
  validation accuracy:		93.59 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.034986
  validation loss:		0.293678
  validation accuracy:		93.48 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.036181
  validation loss:		0.299298
  validation accuracy:		93.48 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.035417
  validation loss:		0.293651
  validation accuracy:		93.48 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.034202
  validation loss:		0.305428
  validation accuracy:		93.59 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.035974
  validation loss:		0.306406
  validation accuracy:		93.26 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.036184
  validation loss:		0.301348
  validation accuracy:		93.59 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.034902
  validation loss:		0.293539
  validation accuracy:		93.80 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.035051
  validation loss:		0.297252
  validation accuracy:		93.59 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.035765
  validation loss:		0.292478
  validation accuracy:		93.59 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.033295
  validation loss:		0.309368
  validation accuracy:		93.48 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.033724
  validation loss:		0.296378
  validation accuracy:		93.80 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.035260
  validation loss:		0.295507
  validation accuracy:		93.48 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.034960
  validation loss:		0.300065
  validation accuracy:		93.37 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.035701
  validation loss:		0.298693
  validation accuracy:		93.37 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.034957
  validation loss:		0.301807
  validation accuracy:		93.91 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.034467
  validation loss:		0.301898
  validation accuracy:		93.37 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.034512
  validation loss:		0.301344
  validation accuracy:		93.37 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.035397
  validation loss:		0.306956
  validation accuracy:		93.26 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.034936
  validation loss:		0.306714
  validation accuracy:		93.48 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.033671
  validation loss:		0.300114
  validation accuracy:		93.48 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.034653
  validation loss:		0.300939
  validation accuracy:		93.48 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.032809
  validation loss:		0.301306
  validation accuracy:		93.26 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.033052
  validation loss:		0.308463
  validation accuracy:		93.59 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.033801
  validation loss:		0.302880
  validation accuracy:		93.48 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.034228
  validation loss:		0.302801
  validation accuracy:		93.48 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.032594
  validation loss:		0.308130
  validation accuracy:		93.26 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.033729
  validation loss:		0.302931
  validation accuracy:		93.04 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.033476
  validation loss:		0.309277
  validation accuracy:		93.48 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.033529
  validation loss:		0.308168
  validation accuracy:		93.48 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.034746
  validation loss:		0.296772
  validation accuracy:		93.80 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.033095
  validation loss:		0.309015
  validation accuracy:		93.91 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.033582
  validation loss:		0.303354
  validation accuracy:		93.15 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.032709
  validation loss:		0.306822
  validation accuracy:		93.15 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.031817
  validation loss:		0.311472
  validation accuracy:		93.48 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.033349
  validation loss:		0.301498
  validation accuracy:		93.59 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.033198
  validation loss:		0.307795
  validation accuracy:		93.37 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.034435
  validation loss:		0.303512
  validation accuracy:		93.48 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.033144
  validation loss:		0.308992
  validation accuracy:		93.91 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.032939
  validation loss:		0.305589
  validation accuracy:		93.37 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.033484
  validation loss:		0.308142
  validation accuracy:		93.26 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.032283
  validation loss:		0.301507
  validation accuracy:		93.26 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.033249
  validation loss:		0.312832
  validation accuracy:		93.70 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.032643
  validation loss:		0.311356
  validation accuracy:		93.26 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.032277
  validation loss:		0.308710
  validation accuracy:		93.48 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.032791
  validation loss:		0.298855
  validation accuracy:		93.15 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.032388
  validation loss:		0.305723
  validation accuracy:		93.37 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.028140
  validation loss:		0.302702
  validation accuracy:		93.04 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.031841
  validation loss:		0.308455
  validation accuracy:		93.37 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.031651
  validation loss:		0.320769
  validation accuracy:		93.04 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.032573
  validation loss:		0.304798
  validation accuracy:		93.37 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.031902
  validation loss:		0.308883
  validation accuracy:		93.59 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.031354
  validation loss:		0.314126
  validation accuracy:		93.48 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.031784
  validation loss:		0.311163
  validation accuracy:		93.26 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.031977
  validation loss:		0.317013
  validation accuracy:		93.37 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.032098
  validation loss:		0.308380
  validation accuracy:		93.70 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.031573
  validation loss:		0.302556
  validation accuracy:		93.48 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.032324
  validation loss:		0.308858
  validation accuracy:		93.15 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.032144
  validation loss:		0.313798
  validation accuracy:		93.48 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.031484
  validation loss:		0.311445
  validation accuracy:		93.37 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.031230
  validation loss:		0.319087
  validation accuracy:		93.48 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.031714
  validation loss:		0.309728
  validation accuracy:		93.59 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.031447
  validation loss:		0.307192
  validation accuracy:		93.37 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.030927
  validation loss:		0.305300
  validation accuracy:		93.59 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.031493
  validation loss:		0.310676
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.030170
  validation loss:		0.313618
  validation accuracy:		93.59 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.030952
  validation loss:		0.318253
  validation accuracy:		93.26 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.031261
  validation loss:		0.323609
  validation accuracy:		93.37 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.030620
  validation loss:		0.315043
  validation accuracy:		93.80 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.029274
  validation loss:		0.313838
  validation accuracy:		93.48 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.030427
  validation loss:		0.311564
  validation accuracy:		93.26 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.030428
  validation loss:		0.318490
  validation accuracy:		93.48 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.031857
  validation loss:		0.306451
  validation accuracy:		93.70 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.028911
  validation loss:		0.306601
  validation accuracy:		93.59 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.030249
  validation loss:		0.307962
  validation accuracy:		93.70 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.029454
  validation loss:		0.310435
  validation accuracy:		93.48 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.029316
  validation loss:		0.312668
  validation accuracy:		93.48 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.030151
  validation loss:		0.304986
  validation accuracy:		93.37 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.030014
  validation loss:		0.313460
  validation accuracy:		93.48 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.029890
  validation loss:		0.314691
  validation accuracy:		93.15 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.029230
  validation loss:		0.309767
  validation accuracy:		93.37 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.030270
  validation loss:		0.313653
  validation accuracy:		93.48 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.029753
  validation loss:		0.318070
  validation accuracy:		93.26 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.029393
  validation loss:		0.316418
  validation accuracy:		93.04 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.029645
  validation loss:		0.307285
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.029529
  validation loss:		0.315058
  validation accuracy:		93.15 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.029043
  validation loss:		0.316250
  validation accuracy:		93.80 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.028499
  validation loss:		0.313767
  validation accuracy:		93.15 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.029126
  validation loss:		0.317474
  validation accuracy:		93.04 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.029374
  validation loss:		0.312270
  validation accuracy:		93.26 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.028998
  validation loss:		0.315599
  validation accuracy:		93.37 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.029268
  validation loss:		0.323565
  validation accuracy:		93.48 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.029688
  validation loss:		0.314426
  validation accuracy:		93.59 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.028876
  validation loss:		0.320638
  validation accuracy:		93.37 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.028107
  validation loss:		0.315099
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.029194
  validation loss:		0.312385
  validation accuracy:		93.59 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.029458
  validation loss:		0.322765
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.027626
  validation loss:		0.313967
  validation accuracy:		93.37 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.029234
  validation loss:		0.312419
  validation accuracy:		93.59 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.027326
  validation loss:		0.324343
  validation accuracy:		93.37 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.028295
  validation loss:		0.322914
  validation accuracy:		93.48 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.028575
  validation loss:		0.319862
  validation accuracy:		93.48 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.026863
  validation loss:		0.324737
  validation accuracy:		93.48 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.027970
  validation loss:		0.321647
  validation accuracy:		93.37 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.027158
  validation loss:		0.322738
  validation accuracy:		93.48 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.026352
  validation loss:		0.321893
  validation accuracy:		93.59 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.028031
  validation loss:		0.326975
  validation accuracy:		93.15 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.028208
  validation loss:		0.316482
  validation accuracy:		93.59 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.027785
  validation loss:		0.320760
  validation accuracy:		93.48 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.027470
  validation loss:		0.327296
  validation accuracy:		93.26 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.027387
  validation loss:		0.324188
  validation accuracy:		93.80 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.026476
  validation loss:		0.317568
  validation accuracy:		93.37 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.027630
  validation loss:		0.325886
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.026543
  validation loss:		0.320008
  validation accuracy:		93.37 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.027008
  validation loss:		0.326272
  validation accuracy:		93.70 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.028077
  validation loss:		0.324465
  validation accuracy:		93.48 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.026918
  validation loss:		0.327081
  validation accuracy:		93.70 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.025659
  validation loss:		0.324710
  validation accuracy:		93.26 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.026128
  validation loss:		0.323847
  validation accuracy:		93.59 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.026994
  validation loss:		0.323933
  validation accuracy:		93.48 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.026722
  validation loss:		0.329042
  validation accuracy:		93.59 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.027163
  validation loss:		0.328777
  validation accuracy:		93.26 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.025594
  validation loss:		0.316683
  validation accuracy:		93.37 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.026615
  validation loss:		0.327246
  validation accuracy:		93.70 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.027120
  validation loss:		0.328589
  validation accuracy:		93.70 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.025794
  validation loss:		0.321052
  validation accuracy:		93.37 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.027024
  validation loss:		0.323447
  validation accuracy:		93.37 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.025812
  validation loss:		0.324690
  validation accuracy:		93.04 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.025636
  validation loss:		0.332761
  validation accuracy:		93.48 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.026202
  validation loss:		0.321840
  validation accuracy:		93.37 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.026353
  validation loss:		0.324092
  validation accuracy:		93.37 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.026630
  validation loss:		0.336288
  validation accuracy:		93.59 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.026045
  validation loss:		0.330053
  validation accuracy:		93.59 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.025651
  validation loss:		0.332468
  validation accuracy:		93.70 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.026352
  validation loss:		0.323630
  validation accuracy:		93.26 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.025422
  validation loss:		0.330434
  validation accuracy:		93.59 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.025513
  validation loss:		0.325190
  validation accuracy:		93.59 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.026245
  validation loss:		0.341349
  validation accuracy:		93.37 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.026365
  validation loss:		0.325135
  validation accuracy:		93.26 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.025152
  validation loss:		0.330045
  validation accuracy:		93.48 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.026089
  validation loss:		0.321487
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.026106
  validation loss:		0.334995
  validation accuracy:		93.48 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.024524
  validation loss:		0.323904
  validation accuracy:		93.37 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.025910
  validation loss:		0.334447
  validation accuracy:		93.70 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.025796
  validation loss:		0.338548
  validation accuracy:		93.70 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.024396
  validation loss:		0.325105
  validation accuracy:		93.04 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.024967
  validation loss:		0.329157
  validation accuracy:		93.15 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.024452
  validation loss:		0.336971
  validation accuracy:		93.26 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.024719
  validation loss:		0.330222
  validation accuracy:		93.59 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.025341
  validation loss:		0.326356
  validation accuracy:		93.48 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.024747
  validation loss:		0.331660
  validation accuracy:		93.48 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.024467
  validation loss:		0.336791
  validation accuracy:		93.15 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.025181
  validation loss:		0.339609
  validation accuracy:		93.59 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.024517
  validation loss:		0.333858
  validation accuracy:		93.15 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.025407
  validation loss:		0.329312
  validation accuracy:		93.15 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.024447
  validation loss:		0.332214
  validation accuracy:		93.70 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.023958
  validation loss:		0.330717
  validation accuracy:		93.70 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.025003
  validation loss:		0.338065
  validation accuracy:		93.37 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.024148
  validation loss:		0.335066
  validation accuracy:		93.15 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.024496
  validation loss:		0.336582
  validation accuracy:		93.59 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.024357
  validation loss:		0.332159
  validation accuracy:		93.59 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.023681
  validation loss:		0.327733
  validation accuracy:		93.48 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.024058
  validation loss:		0.332648
  validation accuracy:		93.70 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.024067
  validation loss:		0.342048
  validation accuracy:		93.70 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.022483
  validation loss:		0.341490
  validation accuracy:		93.04 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.024007
  validation loss:		0.333781
  validation accuracy:		93.70 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.023445
  validation loss:		0.329594
  validation accuracy:		93.59 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.023944
  validation loss:		0.336769
  validation accuracy:		93.37 %
Epoch 904 of 2000 took 0.036s
  training loss:		0.023424
  validation loss:		0.331749
  validation accuracy:		93.26 %
Epoch 905 of 2000 took 0.036s
  training loss:		0.023189
  validation loss:		0.342840
  validation accuracy:		93.70 %
Epoch 906 of 2000 took 0.036s
  training loss:		0.024739
  validation loss:		0.331475
  validation accuracy:		93.26 %
Epoch 907 of 2000 took 0.036s
  training loss:		0.022901
  validation loss:		0.330404
  validation accuracy:		93.37 %
Epoch 908 of 2000 took 0.036s
  training loss:		0.023693
  validation loss:		0.334479
  validation accuracy:		93.59 %
Epoch 909 of 2000 took 0.036s
  training loss:		0.024275
  validation loss:		0.340016
  validation accuracy:		93.59 %
Epoch 910 of 2000 took 0.036s
  training loss:		0.024233
  validation loss:		0.341372
  validation accuracy:		93.70 %
Epoch 911 of 2000 took 0.036s
  training loss:		0.021995
  validation loss:		0.333596
  validation accuracy:		93.37 %
Epoch 912 of 2000 took 0.036s
  training loss:		0.023587
  validation loss:		0.332599
  validation accuracy:		93.59 %
Epoch 913 of 2000 took 0.036s
  training loss:		0.021987
  validation loss:		0.344703
  validation accuracy:		93.48 %
Epoch 914 of 2000 took 0.036s
  training loss:		0.023254
  validation loss:		0.338764
  validation accuracy:		93.48 %
Epoch 915 of 2000 took 0.036s
  training loss:		0.023729
  validation loss:		0.337016
  validation accuracy:		92.93 %
Epoch 916 of 2000 took 0.036s
  training loss:		0.023643
  validation loss:		0.342978
  validation accuracy:		93.15 %
Epoch 917 of 2000 took 0.036s
  training loss:		0.023125
  validation loss:		0.338640
  validation accuracy:		93.70 %
Epoch 918 of 2000 took 0.036s
  training loss:		0.022646
  validation loss:		0.337404
  validation accuracy:		93.15 %
Epoch 919 of 2000 took 0.036s
  training loss:		0.023157
  validation loss:		0.336326
  validation accuracy:		93.48 %
Epoch 920 of 2000 took 0.036s
  training loss:		0.022943
  validation loss:		0.346343
  validation accuracy:		93.48 %
Epoch 921 of 2000 took 0.037s
  training loss:		0.022882
  validation loss:		0.336667
  validation accuracy:		93.37 %
Epoch 922 of 2000 took 0.036s
  training loss:		0.022200
  validation loss:		0.337533
  validation accuracy:		93.48 %
Epoch 923 of 2000 took 0.036s
  training loss:		0.023531
  validation loss:		0.338688
  validation accuracy:		93.37 %
Epoch 924 of 2000 took 0.036s
  training loss:		0.023019
  validation loss:		0.334824
  validation accuracy:		93.59 %
Epoch 925 of 2000 took 0.036s
  training loss:		0.023220
  validation loss:		0.351096
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.036s
  training loss:		0.022880
  validation loss:		0.345263
  validation accuracy:		93.48 %
Epoch 927 of 2000 took 0.036s
  training loss:		0.022142
  validation loss:		0.348132
  validation accuracy:		93.37 %
Epoch 928 of 2000 took 0.036s
  training loss:		0.022988
  validation loss:		0.340361
  validation accuracy:		93.70 %
Epoch 929 of 2000 took 0.036s
  training loss:		0.020777
  validation loss:		0.344377
  validation accuracy:		93.26 %
Epoch 930 of 2000 took 0.036s
  training loss:		0.022798
  validation loss:		0.339281
  validation accuracy:		93.26 %
Epoch 931 of 2000 took 0.036s
  training loss:		0.022358
  validation loss:		0.344089
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.022989
  validation loss:		0.344861
  validation accuracy:		93.48 %
Epoch 933 of 2000 took 0.036s
  training loss:		0.022741
  validation loss:		0.341818
  validation accuracy:		93.15 %
Epoch 934 of 2000 took 0.036s
  training loss:		0.023280
  validation loss:		0.349748
  validation accuracy:		93.59 %
Epoch 935 of 2000 took 0.036s
  training loss:		0.021255
  validation loss:		0.347049
  validation accuracy:		93.04 %
Epoch 936 of 2000 took 0.036s
  training loss:		0.022378
  validation loss:		0.346975
  validation accuracy:		93.37 %
Epoch 937 of 2000 took 0.036s
  training loss:		0.022191
  validation loss:		0.345284
  validation accuracy:		93.48 %
Epoch 938 of 2000 took 0.036s
  training loss:		0.022936
  validation loss:		0.350329
  validation accuracy:		93.48 %
Epoch 939 of 2000 took 0.036s
  training loss:		0.020509
  validation loss:		0.357135
  validation accuracy:		93.26 %
Epoch 940 of 2000 took 0.036s
  training loss:		0.021881
  validation loss:		0.348742
  validation accuracy:		93.37 %
Epoch 941 of 2000 took 0.036s
  training loss:		0.021499
  validation loss:		0.338570
  validation accuracy:		93.04 %
Epoch 942 of 2000 took 0.036s
  training loss:		0.020419
  validation loss:		0.344382
  validation accuracy:		93.70 %
Epoch 943 of 2000 took 0.036s
  training loss:		0.021926
  validation loss:		0.340712
  validation accuracy:		93.26 %
Epoch 944 of 2000 took 0.036s
  training loss:		0.022749
  validation loss:		0.345203
  validation accuracy:		93.37 %
Epoch 945 of 2000 took 0.036s
  training loss:		0.021098
  validation loss:		0.351107
  validation accuracy:		92.93 %
Epoch 946 of 2000 took 0.036s
  training loss:		0.020377
  validation loss:		0.341459
  validation accuracy:		93.26 %
Epoch 947 of 2000 took 0.036s
  training loss:		0.021328
  validation loss:		0.354917
  validation accuracy:		92.93 %
Epoch 948 of 2000 took 0.036s
  training loss:		0.021718
  validation loss:		0.352620
  validation accuracy:		93.04 %
Epoch 949 of 2000 took 0.036s
  training loss:		0.021293
  validation loss:		0.351899
  validation accuracy:		93.15 %
Epoch 950 of 2000 took 0.036s
  training loss:		0.021526
  validation loss:		0.358594
  validation accuracy:		93.15 %
Epoch 951 of 2000 took 0.036s
  training loss:		0.021162
  validation loss:		0.342176
  validation accuracy:		93.59 %
Epoch 952 of 2000 took 0.036s
  training loss:		0.021078
  validation loss:		0.340798
  validation accuracy:		93.26 %
Epoch 953 of 2000 took 0.036s
  training loss:		0.020228
  validation loss:		0.351403
  validation accuracy:		93.37 %
Epoch 954 of 2000 took 0.036s
  training loss:		0.021040
  validation loss:		0.345743
  validation accuracy:		93.59 %
Epoch 955 of 2000 took 0.036s
  training loss:		0.020602
  validation loss:		0.343876
  validation accuracy:		93.26 %
Epoch 956 of 2000 took 0.036s
  training loss:		0.020959
  validation loss:		0.350626
  validation accuracy:		93.70 %
Epoch 957 of 2000 took 0.036s
  training loss:		0.020719
  validation loss:		0.350104
  validation accuracy:		93.37 %
Epoch 958 of 2000 took 0.036s
  training loss:		0.020567
  validation loss:		0.357754
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.036s
  training loss:		0.019214
  validation loss:		0.346187
  validation accuracy:		93.15 %
Epoch 960 of 2000 took 0.036s
  training loss:		0.021391
  validation loss:		0.346159
  validation accuracy:		93.26 %
Epoch 961 of 2000 took 0.036s
  training loss:		0.020952
  validation loss:		0.350425
  validation accuracy:		93.48 %
Epoch 962 of 2000 took 0.036s
  training loss:		0.020730
  validation loss:		0.345309
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.036s
  training loss:		0.020731
  validation loss:		0.347344
  validation accuracy:		93.48 %
Epoch 964 of 2000 took 0.036s
  training loss:		0.020802
  validation loss:		0.342737
  validation accuracy:		93.15 %
Epoch 965 of 2000 took 0.036s
  training loss:		0.021400
  validation loss:		0.344108
  validation accuracy:		93.15 %
Epoch 966 of 2000 took 0.036s
  training loss:		0.020786
  validation loss:		0.352863
  validation accuracy:		93.48 %
Epoch 967 of 2000 took 0.036s
  training loss:		0.020139
  validation loss:		0.350776
  validation accuracy:		93.04 %
Epoch 968 of 2000 took 0.036s
  training loss:		0.020839
  validation loss:		0.363938
  validation accuracy:		93.15 %
Epoch 969 of 2000 took 0.036s
  training loss:		0.020535
  validation loss:		0.354134
  validation accuracy:		93.26 %
Epoch 970 of 2000 took 0.036s
  training loss:		0.019608
  validation loss:		0.353709
  validation accuracy:		93.26 %
Epoch 971 of 2000 took 0.036s
  training loss:		0.020705
  validation loss:		0.352662
  validation accuracy:		93.37 %
Epoch 972 of 2000 took 0.036s
  training loss:		0.019953
  validation loss:		0.352526
  validation accuracy:		93.37 %
Epoch 973 of 2000 took 0.036s
  training loss:		0.019154
  validation loss:		0.353225
  validation accuracy:		93.70 %
Epoch 974 of 2000 took 0.036s
  training loss:		0.020208
  validation loss:		0.344663
  validation accuracy:		92.93 %
Epoch 975 of 2000 took 0.036s
  training loss:		0.020169
  validation loss:		0.356130
  validation accuracy:		93.37 %
Epoch 976 of 2000 took 0.036s
  training loss:		0.020045
  validation loss:		0.358194
  validation accuracy:		92.83 %
Epoch 977 of 2000 took 0.036s
  training loss:		0.020283
  validation loss:		0.356904
  validation accuracy:		93.59 %
Epoch 978 of 2000 took 0.036s
  training loss:		0.020077
  validation loss:		0.355248
  validation accuracy:		93.15 %
Epoch 979 of 2000 took 0.036s
  training loss:		0.019548
  validation loss:		0.358974
  validation accuracy:		93.04 %
Epoch 980 of 2000 took 0.036s
  training loss:		0.019879
  validation loss:		0.353217
  validation accuracy:		93.48 %
Epoch 981 of 2000 took 0.036s
  training loss:		0.020656
  validation loss:		0.350603
  validation accuracy:		93.26 %
Epoch 982 of 2000 took 0.036s
  training loss:		0.018878
  validation loss:		0.358954
  validation accuracy:		92.93 %
Epoch 983 of 2000 took 0.036s
  training loss:		0.020065
  validation loss:		0.355080
  validation accuracy:		93.59 %
Epoch 984 of 2000 took 0.036s
  training loss:		0.019749
  validation loss:		0.356752
  validation accuracy:		93.48 %
Epoch 985 of 2000 took 0.036s
  training loss:		0.019491
  validation loss:		0.354941
  validation accuracy:		92.83 %
Epoch 986 of 2000 took 0.036s
  training loss:		0.019622
  validation loss:		0.357055
  validation accuracy:		93.15 %
Epoch 987 of 2000 took 0.036s
  training loss:		0.019643
  validation loss:		0.359303
  validation accuracy:		93.48 %
Epoch 988 of 2000 took 0.036s
  training loss:		0.018797
  validation loss:		0.361245
  validation accuracy:		93.37 %
Epoch 989 of 2000 took 0.036s
  training loss:		0.018750
  validation loss:		0.361362
  validation accuracy:		93.15 %
Epoch 990 of 2000 took 0.036s
  training loss:		0.019666
  validation loss:		0.364162
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.036s
  training loss:		0.019822
  validation loss:		0.360569
  validation accuracy:		93.04 %
Epoch 992 of 2000 took 0.036s
  training loss:		0.019637
  validation loss:		0.360984
  validation accuracy:		93.26 %
Epoch 993 of 2000 took 0.036s
  training loss:		0.019575
  validation loss:		0.362164
  validation accuracy:		93.26 %
Epoch 994 of 2000 took 0.037s
  training loss:		0.019545
  validation loss:		0.359401
  validation accuracy:		93.26 %
Epoch 995 of 2000 took 0.036s
  training loss:		0.019272
  validation loss:		0.351786
  validation accuracy:		93.26 %
Epoch 996 of 2000 took 0.036s
  training loss:		0.019195
  validation loss:		0.353049
  validation accuracy:		93.48 %
Epoch 997 of 2000 took 0.036s
  training loss:		0.018701
  validation loss:		0.355454
  validation accuracy:		93.04 %
Epoch 998 of 2000 took 0.036s
  training loss:		0.019221
  validation loss:		0.359299
  validation accuracy:		93.37 %
Epoch 999 of 2000 took 0.036s
  training loss:		0.018812
  validation loss:		0.356788
  validation accuracy:		92.93 %
Epoch 1000 of 2000 took 0.036s
  training loss:		0.019149
  validation loss:		0.362914
  validation accuracy:		93.15 %
Epoch 1001 of 2000 took 0.036s
  training loss:		0.018902
  validation loss:		0.360225
  validation accuracy:		93.37 %
Epoch 1002 of 2000 took 0.036s
  training loss:		0.019086
  validation loss:		0.363604
  validation accuracy:		93.26 %
Epoch 1003 of 2000 took 0.036s
  training loss:		0.019155
  validation loss:		0.362303
  validation accuracy:		93.26 %
Epoch 1004 of 2000 took 0.036s
  training loss:		0.018625
  validation loss:		0.365083
  validation accuracy:		93.04 %
Epoch 1005 of 2000 took 0.036s
  training loss:		0.017545
  validation loss:		0.361987
  validation accuracy:		93.15 %
Epoch 1006 of 2000 took 0.036s
  training loss:		0.019054
  validation loss:		0.364495
  validation accuracy:		93.15 %
Epoch 1007 of 2000 took 0.036s
  training loss:		0.018024
  validation loss:		0.364409
  validation accuracy:		93.15 %
Epoch 1008 of 2000 took 0.036s
  training loss:		0.018642
  validation loss:		0.363520
  validation accuracy:		93.26 %
Epoch 1009 of 2000 took 0.036s
  training loss:		0.018728
  validation loss:		0.360342
  validation accuracy:		93.26 %
Epoch 1010 of 2000 took 0.036s
  training loss:		0.018205
  validation loss:		0.372198
  validation accuracy:		93.37 %
Epoch 1011 of 2000 took 0.036s
  training loss:		0.018958
  validation loss:		0.368123
  validation accuracy:		93.15 %
Epoch 1012 of 2000 took 0.036s
  training loss:		0.017599
  validation loss:		0.362103
  validation accuracy:		93.48 %
Epoch 1013 of 2000 took 0.036s
  training loss:		0.018575
  validation loss:		0.354063
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.036s
  training loss:		0.018836
  validation loss:		0.360539
  validation accuracy:		93.26 %
Epoch 1015 of 2000 took 0.036s
  training loss:		0.018665
  validation loss:		0.362348
  validation accuracy:		93.37 %
Epoch 1016 of 2000 took 0.036s
  training loss:		0.018705
  validation loss:		0.377034
  validation accuracy:		93.26 %
Epoch 1017 of 2000 took 0.036s
  training loss:		0.018429
  validation loss:		0.361614
  validation accuracy:		93.48 %
Epoch 1018 of 2000 took 0.036s
  training loss:		0.017149
  validation loss:		0.366183
  validation accuracy:		93.26 %
Epoch 1019 of 2000 took 0.036s
  training loss:		0.018328
  validation loss:		0.369493
  validation accuracy:		93.37 %
Epoch 1020 of 2000 took 0.036s
  training loss:		0.018407
  validation loss:		0.369710
  validation accuracy:		93.26 %
Epoch 1021 of 2000 took 0.036s
  training loss:		0.018641
  validation loss:		0.360280
  validation accuracy:		93.15 %
Epoch 1022 of 2000 took 0.036s
  training loss:		0.018266
  validation loss:		0.360910
  validation accuracy:		93.37 %
Epoch 1023 of 2000 took 0.036s
  training loss:		0.018412
  validation loss:		0.360627
  validation accuracy:		93.26 %
Epoch 1024 of 2000 took 0.036s
  training loss:		0.018229
  validation loss:		0.362498
  validation accuracy:		93.04 %
Epoch 1025 of 2000 took 0.036s
  training loss:		0.018484
  validation loss:		0.373356
  validation accuracy:		93.15 %
Epoch 1026 of 2000 took 0.036s
  training loss:		0.017415
  validation loss:		0.374130
  validation accuracy:		93.26 %
Epoch 1027 of 2000 took 0.036s
  training loss:		0.017875
  validation loss:		0.364238
  validation accuracy:		93.26 %
Epoch 1028 of 2000 took 0.036s
  training loss:		0.018019
  validation loss:		0.366342
  validation accuracy:		93.26 %
Epoch 1029 of 2000 took 0.036s
  training loss:		0.017540
  validation loss:		0.376178
  validation accuracy:		93.26 %
Epoch 1030 of 2000 took 0.036s
  training loss:		0.017773
  validation loss:		0.366502
  validation accuracy:		93.26 %
Epoch 1031 of 2000 took 0.036s
  training loss:		0.017067
  validation loss:		0.367428
  validation accuracy:		93.37 %
Epoch 1032 of 2000 took 0.036s
  training loss:		0.017783
  validation loss:		0.361366
  validation accuracy:		93.48 %
Epoch 1033 of 2000 took 0.036s
  training loss:		0.017420
  validation loss:		0.379484
  validation accuracy:		93.26 %
Epoch 1034 of 2000 took 0.036s
  training loss:		0.018324
  validation loss:		0.371151
  validation accuracy:		93.04 %
Epoch 1035 of 2000 took 0.036s
  training loss:		0.017081
  validation loss:		0.364354
  validation accuracy:		93.04 %
Epoch 1036 of 2000 took 0.036s
  training loss:		0.017160
  validation loss:		0.361624
  validation accuracy:		93.15 %
Epoch 1037 of 2000 took 0.036s
  training loss:		0.017645
  validation loss:		0.372657
  validation accuracy:		93.26 %
Epoch 1038 of 2000 took 0.036s
  training loss:		0.017516
  validation loss:		0.366949
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.036s
  training loss:		0.017425
  validation loss:		0.373874
  validation accuracy:		93.15 %
Epoch 1040 of 2000 took 0.036s
  training loss:		0.017593
  validation loss:		0.376571
  validation accuracy:		93.37 %
Epoch 1041 of 2000 took 0.036s
  training loss:		0.017538
  validation loss:		0.366693
  validation accuracy:		93.04 %
Epoch 1042 of 2000 took 0.036s
  training loss:		0.016262
  validation loss:		0.375267
  validation accuracy:		93.26 %
Epoch 1043 of 2000 took 0.036s
  training loss:		0.017408
  validation loss:		0.373390
  validation accuracy:		93.26 %
Epoch 1044 of 2000 took 0.036s
  training loss:		0.015805
  validation loss:		0.365616
  validation accuracy:		93.04 %
Epoch 1045 of 2000 took 0.036s
  training loss:		0.017010
  validation loss:		0.366778
  validation accuracy:		93.37 %
Epoch 1046 of 2000 took 0.036s
  training loss:		0.015917
  validation loss:		0.370631
  validation accuracy:		93.48 %
Epoch 1047 of 2000 took 0.036s
  training loss:		0.016694
  validation loss:		0.370050
  validation accuracy:		93.26 %
Epoch 1048 of 2000 took 0.036s
  training loss:		0.017401
  validation loss:		0.375939
  validation accuracy:		93.37 %
Epoch 1049 of 2000 took 0.036s
  training loss:		0.017364
  validation loss:		0.372189
  validation accuracy:		93.15 %
Epoch 1050 of 2000 took 0.036s
  training loss:		0.017119
  validation loss:		0.375214
  validation accuracy:		93.15 %
Epoch 1051 of 2000 took 0.036s
  training loss:		0.016207
  validation loss:		0.370735
  validation accuracy:		93.15 %
Epoch 1052 of 2000 took 0.036s
  training loss:		0.016690
  validation loss:		0.370185
  validation accuracy:		93.48 %
Epoch 1053 of 2000 took 0.036s
  training loss:		0.016861
  validation loss:		0.372098
  validation accuracy:		93.26 %
Epoch 1054 of 2000 took 0.036s
  training loss:		0.016598
  validation loss:		0.380037
  validation accuracy:		93.15 %
Epoch 1055 of 2000 took 0.036s
  training loss:		0.017204
  validation loss:		0.377194
  validation accuracy:		93.26 %
Epoch 1056 of 2000 took 0.036s
  training loss:		0.016756
  validation loss:		0.378644
  validation accuracy:		93.15 %
Epoch 1057 of 2000 took 0.036s
  training loss:		0.016766
  validation loss:		0.376056
  validation accuracy:		93.04 %
Epoch 1058 of 2000 took 0.036s
  training loss:		0.016827
  validation loss:		0.380212
  validation accuracy:		93.26 %
Epoch 1059 of 2000 took 0.036s
  training loss:		0.015358
  validation loss:		0.372441
  validation accuracy:		93.26 %
Epoch 1060 of 2000 took 0.036s
  training loss:		0.016741
  validation loss:		0.377942
  validation accuracy:		93.15 %
Epoch 1061 of 2000 took 0.036s
  training loss:		0.016325
  validation loss:		0.370365
  validation accuracy:		93.37 %
Epoch 1062 of 2000 took 0.036s
  training loss:		0.016518
  validation loss:		0.370945
  validation accuracy:		93.37 %
Epoch 1063 of 2000 took 0.036s
  training loss:		0.016455
  validation loss:		0.375778
  validation accuracy:		93.26 %
Epoch 1064 of 2000 took 0.036s
  training loss:		0.016348
  validation loss:		0.369615
  validation accuracy:		93.37 %
Epoch 1065 of 2000 took 0.036s
  training loss:		0.016392
  validation loss:		0.369635
  validation accuracy:		93.15 %
Epoch 1066 of 2000 took 0.036s
  training loss:		0.016546
  validation loss:		0.382391
  validation accuracy:		93.04 %
Epoch 1067 of 2000 took 0.036s
  training loss:		0.016091
  validation loss:		0.366184
  validation accuracy:		93.26 %
Epoch 1068 of 2000 took 0.036s
  training loss:		0.016584
  validation loss:		0.377102
  validation accuracy:		93.15 %
Epoch 1069 of 2000 took 0.036s
  training loss:		0.016239
  validation loss:		0.381047
  validation accuracy:		93.15 %
Epoch 1070 of 2000 took 0.036s
  training loss:		0.015608
  validation loss:		0.378631
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.036s
  training loss:		0.015644
  validation loss:		0.371782
  validation accuracy:		93.26 %
Epoch 1072 of 2000 took 0.036s
  training loss:		0.015127
  validation loss:		0.374483
  validation accuracy:		93.26 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.015556
  validation loss:		0.380742
  validation accuracy:		93.04 %
Epoch 1074 of 2000 took 0.036s
  training loss:		0.016147
  validation loss:		0.379617
  validation accuracy:		93.04 %
Epoch 1075 of 2000 took 0.036s
  training loss:		0.016145
  validation loss:		0.380525
  validation accuracy:		93.26 %
Epoch 1076 of 2000 took 0.036s
  training loss:		0.016428
  validation loss:		0.376047
  validation accuracy:		93.15 %
Epoch 1077 of 2000 took 0.036s
  training loss:		0.016064
  validation loss:		0.375091
  validation accuracy:		93.26 %
Epoch 1078 of 2000 took 0.036s
  training loss:		0.015124
  validation loss:		0.379245
  validation accuracy:		93.04 %
Epoch 1079 of 2000 took 0.036s
  training loss:		0.015882
  validation loss:		0.377117
  validation accuracy:		93.04 %
Epoch 1080 of 2000 took 0.036s
  training loss:		0.016040
  validation loss:		0.390688
  validation accuracy:		93.15 %
Epoch 1081 of 2000 took 0.036s
  training loss:		0.015739
  validation loss:		0.371516
  validation accuracy:		93.26 %
Epoch 1082 of 2000 took 0.036s
  training loss:		0.016076
  validation loss:		0.381183
  validation accuracy:		93.04 %
Epoch 1083 of 2000 took 0.036s
  training loss:		0.015493
  validation loss:		0.384320
  validation accuracy:		93.15 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.015851
  validation loss:		0.385694
  validation accuracy:		93.04 %
Epoch 1085 of 2000 took 0.036s
  training loss:		0.015350
  validation loss:		0.378000
  validation accuracy:		93.26 %
Epoch 1086 of 2000 took 0.036s
  training loss:		0.015266
  validation loss:		0.380916
  validation accuracy:		93.26 %
Epoch 1087 of 2000 took 0.036s
  training loss:		0.015212
  validation loss:		0.376911
  validation accuracy:		93.26 %
Epoch 1088 of 2000 took 0.036s
  training loss:		0.015194
  validation loss:		0.380388
  validation accuracy:		93.15 %
Epoch 1089 of 2000 took 0.036s
  training loss:		0.015333
  validation loss:		0.376128
  validation accuracy:		93.15 %
Epoch 1090 of 2000 took 0.036s
  training loss:		0.015373
  validation loss:		0.375750
  validation accuracy:		93.37 %
Epoch 1091 of 2000 took 0.036s
  training loss:		0.014918
  validation loss:		0.383459
  validation accuracy:		93.26 %
Epoch 1092 of 2000 took 0.036s
  training loss:		0.015017
  validation loss:		0.383264
  validation accuracy:		93.26 %
Epoch 1093 of 2000 took 0.036s
  training loss:		0.015840
  validation loss:		0.381988
  validation accuracy:		93.26 %
Epoch 1094 of 2000 took 0.036s
  training loss:		0.014525
  validation loss:		0.377420
  validation accuracy:		93.26 %
Epoch 1095 of 2000 took 0.036s
  training loss:		0.014964
  validation loss:		0.385015
  validation accuracy:		93.04 %
Epoch 1096 of 2000 took 0.036s
  training loss:		0.014902
  validation loss:		0.385217
  validation accuracy:		93.26 %
Epoch 1097 of 2000 took 0.036s
  training loss:		0.014448
  validation loss:		0.386464
  validation accuracy:		93.15 %
Epoch 1098 of 2000 took 0.036s
  training loss:		0.014850
  validation loss:		0.379908
  validation accuracy:		93.26 %
Epoch 1099 of 2000 took 0.036s
  training loss:		0.015065
  validation loss:		0.375224
  validation accuracy:		93.37 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.015135
  validation loss:		0.387271
  validation accuracy:		93.15 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.014696
  validation loss:		0.381448
  validation accuracy:		93.15 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.015378
  validation loss:		0.383124
  validation accuracy:		92.93 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.014947
  validation loss:		0.387225
  validation accuracy:		93.26 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.015093
  validation loss:		0.385411
  validation accuracy:		93.15 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.015619
  validation loss:		0.387590
  validation accuracy:		93.15 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.014827
  validation loss:		0.385635
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.015149
  validation loss:		0.380632
  validation accuracy:		93.15 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.014561
  validation loss:		0.384486
  validation accuracy:		93.26 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.015222
  validation loss:		0.388030
  validation accuracy:		93.15 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.014369
  validation loss:		0.387068
  validation accuracy:		93.15 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.015121
  validation loss:		0.385088
  validation accuracy:		93.04 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.014777
  validation loss:		0.383903
  validation accuracy:		93.26 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.014644
  validation loss:		0.384901
  validation accuracy:		93.15 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.014858
  validation loss:		0.385568
  validation accuracy:		93.04 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.014835
  validation loss:		0.388154
  validation accuracy:		93.04 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.014601
  validation loss:		0.388705
  validation accuracy:		93.15 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.014550
  validation loss:		0.393406
  validation accuracy:		93.15 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.014499
  validation loss:		0.387190
  validation accuracy:		93.15 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.014394
  validation loss:		0.396851
  validation accuracy:		93.04 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.014081
  validation loss:		0.389973
  validation accuracy:		93.04 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.014352
  validation loss:		0.391532
  validation accuracy:		93.15 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.014007
  validation loss:		0.396592
  validation accuracy:		93.04 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.014207
  validation loss:		0.391814
  validation accuracy:		93.04 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.014539
  validation loss:		0.390574
  validation accuracy:		93.37 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.013885
  validation loss:		0.394332
  validation accuracy:		92.93 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.014467
  validation loss:		0.388992
  validation accuracy:		93.15 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.013907
  validation loss:		0.387936
  validation accuracy:		93.15 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.014633
  validation loss:		0.390033
  validation accuracy:		93.15 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.013693
  validation loss:		0.393455
  validation accuracy:		93.15 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.013927
  validation loss:		0.391890
  validation accuracy:		93.15 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.013823
  validation loss:		0.398373
  validation accuracy:		93.15 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.014119
  validation loss:		0.388210
  validation accuracy:		93.15 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.013919
  validation loss:		0.398597
  validation accuracy:		93.15 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.013744
  validation loss:		0.391379
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.013813
  validation loss:		0.387911
  validation accuracy:		93.26 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.014475
  validation loss:		0.392760
  validation accuracy:		93.15 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.014385
  validation loss:		0.391993
  validation accuracy:		93.15 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.013623
  validation loss:		0.391141
  validation accuracy:		93.26 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.013768
  validation loss:		0.388106
  validation accuracy:		93.15 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.014123
  validation loss:		0.392420
  validation accuracy:		93.15 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.013460
  validation loss:		0.395678
  validation accuracy:		93.15 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.013760
  validation loss:		0.392590
  validation accuracy:		93.15 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.014373
  validation loss:		0.393525
  validation accuracy:		93.26 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.013734
  validation loss:		0.398355
  validation accuracy:		93.04 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.013845
  validation loss:		0.389866
  validation accuracy:		93.15 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.013631
  validation loss:		0.395931
  validation accuracy:		93.15 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.013382
  validation loss:		0.392700
  validation accuracy:		93.15 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.013424
  validation loss:		0.402374
  validation accuracy:		93.15 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.013180
  validation loss:		0.396021
  validation accuracy:		92.93 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.012935
  validation loss:		0.390534
  validation accuracy:		93.15 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.013632
  validation loss:		0.396916
  validation accuracy:		93.04 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.013525
  validation loss:		0.403462
  validation accuracy:		93.15 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.013470
  validation loss:		0.398243
  validation accuracy:		92.93 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.012921
  validation loss:		0.391593
  validation accuracy:		93.15 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.013286
  validation loss:		0.401393
  validation accuracy:		93.04 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.013354
  validation loss:		0.401607
  validation accuracy:		93.15 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.013379
  validation loss:		0.402019
  validation accuracy:		92.93 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.012619
  validation loss:		0.395467
  validation accuracy:		93.15 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.013217
  validation loss:		0.396787
  validation accuracy:		92.93 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.012484
  validation loss:		0.397408
  validation accuracy:		93.04 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.013224
  validation loss:		0.400376
  validation accuracy:		93.04 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.012868
  validation loss:		0.400109
  validation accuracy:		93.15 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.012901
  validation loss:		0.398104
  validation accuracy:		93.15 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.013307
  validation loss:		0.403554
  validation accuracy:		93.15 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.012238
  validation loss:		0.395201
  validation accuracy:		93.04 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.013187
  validation loss:		0.401476
  validation accuracy:		93.04 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.012070
  validation loss:		0.396724
  validation accuracy:		93.04 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.013137
  validation loss:		0.399403
  validation accuracy:		93.04 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.012710
  validation loss:		0.397117
  validation accuracy:		93.04 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.012430
  validation loss:		0.405281
  validation accuracy:		93.26 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.012663
  validation loss:		0.398116
  validation accuracy:		93.04 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.012696
  validation loss:		0.404175
  validation accuracy:		93.04 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.012986
  validation loss:		0.397538
  validation accuracy:		93.37 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.012963
  validation loss:		0.400385
  validation accuracy:		93.04 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.012466
  validation loss:		0.403679
  validation accuracy:		93.15 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.012151
  validation loss:		0.400358
  validation accuracy:		93.15 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.012700
  validation loss:		0.402377
  validation accuracy:		93.04 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.012788
  validation loss:		0.405738
  validation accuracy:		93.04 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.012732
  validation loss:		0.408827
  validation accuracy:		93.04 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.013117
  validation loss:		0.405566
  validation accuracy:		92.83 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.012667
  validation loss:		0.403333
  validation accuracy:		93.04 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.012292
  validation loss:		0.394750
  validation accuracy:		93.15 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.012680
  validation loss:		0.407485
  validation accuracy:		93.04 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.012288
  validation loss:		0.400962
  validation accuracy:		93.15 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.012626
  validation loss:		0.403769
  validation accuracy:		93.04 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.012421
  validation loss:		0.400214
  validation accuracy:		93.04 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.012480
  validation loss:		0.400510
  validation accuracy:		93.04 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.012487
  validation loss:		0.406558
  validation accuracy:		93.04 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.012301
  validation loss:		0.407028
  validation accuracy:		93.15 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.012686
  validation loss:		0.403274
  validation accuracy:		93.04 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.012612
  validation loss:		0.407768
  validation accuracy:		93.26 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.011776
  validation loss:		0.409333
  validation accuracy:		92.83 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.012122
  validation loss:		0.403871
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.011872
  validation loss:		0.410065
  validation accuracy:		93.04 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.012999
  validation loss:		0.403269
  validation accuracy:		92.93 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.012304
  validation loss:		0.402063
  validation accuracy:		93.26 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.011817
  validation loss:		0.405684
  validation accuracy:		92.93 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.012169
  validation loss:		0.409710
  validation accuracy:		93.04 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.012090
  validation loss:		0.407162
  validation accuracy:		93.15 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.011340
  validation loss:		0.406523
  validation accuracy:		93.04 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.011824
  validation loss:		0.403819
  validation accuracy:		93.04 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.012121
  validation loss:		0.401300
  validation accuracy:		93.04 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.012220
  validation loss:		0.409746
  validation accuracy:		93.04 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.011430
  validation loss:		0.413272
  validation accuracy:		92.93 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.012156
  validation loss:		0.405502
  validation accuracy:		93.26 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.011747
  validation loss:		0.409865
  validation accuracy:		92.93 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.011791
  validation loss:		0.407942
  validation accuracy:		92.93 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.011523
  validation loss:		0.414856
  validation accuracy:		92.93 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.012077
  validation loss:		0.409863
  validation accuracy:		93.04 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.011629
  validation loss:		0.409709
  validation accuracy:		93.04 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.011864
  validation loss:		0.405133
  validation accuracy:		93.15 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.011776
  validation loss:		0.409173
  validation accuracy:		93.04 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.011323
  validation loss:		0.405288
  validation accuracy:		93.15 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.011785
  validation loss:		0.412406
  validation accuracy:		93.04 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.011684
  validation loss:		0.401993
  validation accuracy:		93.26 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.011903
  validation loss:		0.413954
  validation accuracy:		93.15 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.011586
  validation loss:		0.407499
  validation accuracy:		93.26 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.011516
  validation loss:		0.406348
  validation accuracy:		93.04 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.011779
  validation loss:		0.410104
  validation accuracy:		92.93 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.011781
  validation loss:		0.414539
  validation accuracy:		93.04 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.011444
  validation loss:		0.412872
  validation accuracy:		93.04 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.011528
  validation loss:		0.407115
  validation accuracy:		93.04 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.011394
  validation loss:		0.413890
  validation accuracy:		93.26 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.011430
  validation loss:		0.410184
  validation accuracy:		92.93 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.010959
  validation loss:		0.410317
  validation accuracy:		93.15 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.011535
  validation loss:		0.417651
  validation accuracy:		92.93 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.011574
  validation loss:		0.408389
  validation accuracy:		93.04 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.011456
  validation loss:		0.414087
  validation accuracy:		93.04 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.011285
  validation loss:		0.416115
  validation accuracy:		92.93 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.011219
  validation loss:		0.410354
  validation accuracy:		93.15 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.011200
  validation loss:		0.412912
  validation accuracy:		93.04 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.011052
  validation loss:		0.418918
  validation accuracy:		93.04 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.011279
  validation loss:		0.415188
  validation accuracy:		93.26 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.011063
  validation loss:		0.414589
  validation accuracy:		93.04 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.011188
  validation loss:		0.416749
  validation accuracy:		93.04 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.011025
  validation loss:		0.419401
  validation accuracy:		93.26 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.011071
  validation loss:		0.413143
  validation accuracy:		93.04 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.010969
  validation loss:		0.424280
  validation accuracy:		93.04 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.010824
  validation loss:		0.423426
  validation accuracy:		93.15 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.011302
  validation loss:		0.417151
  validation accuracy:		93.04 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.010894
  validation loss:		0.410417
  validation accuracy:		93.15 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.010944
  validation loss:		0.421172
  validation accuracy:		93.04 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.011259
  validation loss:		0.415994
  validation accuracy:		93.37 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.011114
  validation loss:		0.420321
  validation accuracy:		93.04 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.011194
  validation loss:		0.416390
  validation accuracy:		93.04 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.011302
  validation loss:		0.422795
  validation accuracy:		92.93 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.011079
  validation loss:		0.416810
  validation accuracy:		92.93 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.011044
  validation loss:		0.414440
  validation accuracy:		93.04 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.010885
  validation loss:		0.416096
  validation accuracy:		92.93 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.010696
  validation loss:		0.418441
  validation accuracy:		93.04 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.010862
  validation loss:		0.420148
  validation accuracy:		92.93 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.010780
  validation loss:		0.417982
  validation accuracy:		92.93 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.010655
  validation loss:		0.420606
  validation accuracy:		92.93 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009983
  validation loss:		0.413633
  validation accuracy:		92.93 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.010786
  validation loss:		0.417563
  validation accuracy:		93.04 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.010597
  validation loss:		0.422490
  validation accuracy:		92.93 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.010690
  validation loss:		0.419644
  validation accuracy:		92.93 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.010293
  validation loss:		0.425090
  validation accuracy:		93.15 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.010458
  validation loss:		0.428444
  validation accuracy:		92.93 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.010477
  validation loss:		0.419629
  validation accuracy:		93.04 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.010724
  validation loss:		0.428521
  validation accuracy:		93.15 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.010594
  validation loss:		0.423208
  validation accuracy:		93.15 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.010524
  validation loss:		0.426516
  validation accuracy:		93.04 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.010543
  validation loss:		0.418700
  validation accuracy:		92.83 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.010390
  validation loss:		0.418523
  validation accuracy:		93.15 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.010259
  validation loss:		0.425805
  validation accuracy:		93.04 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.010338
  validation loss:		0.420438
  validation accuracy:		92.83 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.010008
  validation loss:		0.426788
  validation accuracy:		93.04 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.010249
  validation loss:		0.422704
  validation accuracy:		93.04 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.010521
  validation loss:		0.417434
  validation accuracy:		93.15 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.010373
  validation loss:		0.421771
  validation accuracy:		92.93 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.010577
  validation loss:		0.416895
  validation accuracy:		92.93 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.010371
  validation loss:		0.426317
  validation accuracy:		93.04 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.010171
  validation loss:		0.423263
  validation accuracy:		92.93 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.010586
  validation loss:		0.420624
  validation accuracy:		93.26 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.010229
  validation loss:		0.418715
  validation accuracy:		93.15 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.010276
  validation loss:		0.425977
  validation accuracy:		92.93 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.010068
  validation loss:		0.423270
  validation accuracy:		92.93 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.010168
  validation loss:		0.423819
  validation accuracy:		93.26 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.010507
  validation loss:		0.421966
  validation accuracy:		92.93 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.009883
  validation loss:		0.424478
  validation accuracy:		92.93 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.009908
  validation loss:		0.421649
  validation accuracy:		92.93 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.010118
  validation loss:		0.422714
  validation accuracy:		93.04 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.009753
  validation loss:		0.422146
  validation accuracy:		93.04 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.009803
  validation loss:		0.428673
  validation accuracy:		92.83 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.010133
  validation loss:		0.430533
  validation accuracy:		93.15 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.009985
  validation loss:		0.425316
  validation accuracy:		93.04 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.009434
  validation loss:		0.424697
  validation accuracy:		93.15 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.010008
  validation loss:		0.424269
  validation accuracy:		92.83 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.009837
  validation loss:		0.422594
  validation accuracy:		93.15 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.009796
  validation loss:		0.430238
  validation accuracy:		93.04 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.009921
  validation loss:		0.431600
  validation accuracy:		93.04 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.009842
  validation loss:		0.426765
  validation accuracy:		93.15 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.009947
  validation loss:		0.420019
  validation accuracy:		93.15 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.009343
  validation loss:		0.432323
  validation accuracy:		93.15 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.009755
  validation loss:		0.425021
  validation accuracy:		92.93 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.010190
  validation loss:		0.425574
  validation accuracy:		92.93 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.009909
  validation loss:		0.429303
  validation accuracy:		93.15 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.009685
  validation loss:		0.432832
  validation accuracy:		93.04 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.009552
  validation loss:		0.421969
  validation accuracy:		93.26 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.009725
  validation loss:		0.433311
  validation accuracy:		93.04 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.009767
  validation loss:		0.429598
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.009659
  validation loss:		0.428385
  validation accuracy:		92.93 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.009653
  validation loss:		0.429688
  validation accuracy:		93.04 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.009210
  validation loss:		0.428162
  validation accuracy:		93.04 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.009635
  validation loss:		0.427612
  validation accuracy:		92.93 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.009582
  validation loss:		0.430613
  validation accuracy:		92.93 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.009666
  validation loss:		0.431627
  validation accuracy:		93.04 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.009448
  validation loss:		0.433839
  validation accuracy:		93.15 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.009643
  validation loss:		0.436289
  validation accuracy:		93.04 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.009729
  validation loss:		0.428498
  validation accuracy:		93.15 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.009436
  validation loss:		0.428447
  validation accuracy:		93.04 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.009496
  validation loss:		0.439960
  validation accuracy:		93.15 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.009360
  validation loss:		0.431645
  validation accuracy:		93.26 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.009067
  validation loss:		0.444534
  validation accuracy:		93.15 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.009514
  validation loss:		0.433204
  validation accuracy:		93.15 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.009278
  validation loss:		0.435426
  validation accuracy:		93.04 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.009173
  validation loss:		0.439619
  validation accuracy:		93.15 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.008843
  validation loss:		0.423297
  validation accuracy:		93.26 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.009380
  validation loss:		0.439846
  validation accuracy:		93.04 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.009057
  validation loss:		0.433835
  validation accuracy:		93.04 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.009271
  validation loss:		0.437649
  validation accuracy:		93.15 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.009154
  validation loss:		0.430004
  validation accuracy:		92.93 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.008897
  validation loss:		0.433462
  validation accuracy:		93.04 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.009422
  validation loss:		0.429871
  validation accuracy:		92.93 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.009371
  validation loss:		0.432335
  validation accuracy:		93.04 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.009570
  validation loss:		0.437582
  validation accuracy:		93.15 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.008939
  validation loss:		0.430741
  validation accuracy:		93.04 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.009366
  validation loss:		0.434447
  validation accuracy:		93.04 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.008988
  validation loss:		0.434273
  validation accuracy:		92.93 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.009103
  validation loss:		0.438517
  validation accuracy:		92.93 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.008865
  validation loss:		0.440935
  validation accuracy:		93.26 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.009249
  validation loss:		0.438273
  validation accuracy:		92.93 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.009416
  validation loss:		0.438693
  validation accuracy:		93.04 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.009051
  validation loss:		0.431285
  validation accuracy:		93.04 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.008885
  validation loss:		0.436130
  validation accuracy:		93.04 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.009072
  validation loss:		0.438486
  validation accuracy:		92.93 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.009037
  validation loss:		0.443072
  validation accuracy:		92.93 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.008969
  validation loss:		0.441909
  validation accuracy:		92.93 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.008608
  validation loss:		0.435564
  validation accuracy:		92.93 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.008936
  validation loss:		0.438996
  validation accuracy:		93.04 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.008915
  validation loss:		0.439227
  validation accuracy:		93.26 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.008985
  validation loss:		0.441820
  validation accuracy:		92.93 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.008857
  validation loss:		0.439333
  validation accuracy:		92.93 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.008956
  validation loss:		0.439564
  validation accuracy:		93.04 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.008740
  validation loss:		0.434764
  validation accuracy:		92.83 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.008688
  validation loss:		0.437548
  validation accuracy:		92.93 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.008779
  validation loss:		0.437927
  validation accuracy:		92.93 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.008826
  validation loss:		0.436971
  validation accuracy:		93.15 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.008895
  validation loss:		0.450705
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.008957
  validation loss:		0.438414
  validation accuracy:		93.15 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.008738
  validation loss:		0.440462
  validation accuracy:		92.93 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.008622
  validation loss:		0.439047
  validation accuracy:		93.26 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.008597
  validation loss:		0.443996
  validation accuracy:		93.26 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.008557
  validation loss:		0.440125
  validation accuracy:		93.04 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.008465
  validation loss:		0.437630
  validation accuracy:		93.15 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.008719
  validation loss:		0.445532
  validation accuracy:		92.93 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.008806
  validation loss:		0.444608
  validation accuracy:		93.15 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.008540
  validation loss:		0.439270
  validation accuracy:		92.93 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.008225
  validation loss:		0.440040
  validation accuracy:		93.04 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.008247
  validation loss:		0.440173
  validation accuracy:		93.04 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.008228
  validation loss:		0.445020
  validation accuracy:		92.93 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.008622
  validation loss:		0.439064
  validation accuracy:		92.93 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.008747
  validation loss:		0.435727
  validation accuracy:		93.15 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.008316
  validation loss:		0.451122
  validation accuracy:		93.15 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.008850
  validation loss:		0.439138
  validation accuracy:		92.93 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.008379
  validation loss:		0.441612
  validation accuracy:		93.15 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.008292
  validation loss:		0.447597
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.008453
  validation loss:		0.443925
  validation accuracy:		93.15 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.008579
  validation loss:		0.445700
  validation accuracy:		93.04 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.008385
  validation loss:		0.451936
  validation accuracy:		93.15 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.008390
  validation loss:		0.440795
  validation accuracy:		93.04 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.008488
  validation loss:		0.440802
  validation accuracy:		92.93 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.008707
  validation loss:		0.449872
  validation accuracy:		92.93 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.008478
  validation loss:		0.442701
  validation accuracy:		93.26 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.008376
  validation loss:		0.448603
  validation accuracy:		92.83 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.007956
  validation loss:		0.441682
  validation accuracy:		92.93 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.008501
  validation loss:		0.440746
  validation accuracy:		93.04 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.008373
  validation loss:		0.447901
  validation accuracy:		92.93 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.008269
  validation loss:		0.444238
  validation accuracy:		92.83 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.008145
  validation loss:		0.451207
  validation accuracy:		93.04 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.008217
  validation loss:		0.444760
  validation accuracy:		93.04 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.008463
  validation loss:		0.452337
  validation accuracy:		93.04 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.008449
  validation loss:		0.448191
  validation accuracy:		93.26 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.007850
  validation loss:		0.445860
  validation accuracy:		93.04 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.008323
  validation loss:		0.449985
  validation accuracy:		92.83 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.008030
  validation loss:		0.448685
  validation accuracy:		93.26 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.007880
  validation loss:		0.444451
  validation accuracy:		92.93 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.008332
  validation loss:		0.451109
  validation accuracy:		92.83 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.008128
  validation loss:		0.448280
  validation accuracy:		92.93 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.008167
  validation loss:		0.455989
  validation accuracy:		93.04 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.008100
  validation loss:		0.445112
  validation accuracy:		93.15 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.008150
  validation loss:		0.446650
  validation accuracy:		93.04 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.008204
  validation loss:		0.447155
  validation accuracy:		93.15 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.007920
  validation loss:		0.452372
  validation accuracy:		93.04 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.008263
  validation loss:		0.443337
  validation accuracy:		93.04 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.007973
  validation loss:		0.450302
  validation accuracy:		92.83 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.007919
  validation loss:		0.454695
  validation accuracy:		93.15 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.008138
  validation loss:		0.452806
  validation accuracy:		92.93 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.007913
  validation loss:		0.451221
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.007940
  validation loss:		0.445918
  validation accuracy:		92.83 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.008084
  validation loss:		0.447350
  validation accuracy:		93.04 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.007956
  validation loss:		0.446877
  validation accuracy:		93.04 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.007797
  validation loss:		0.449711
  validation accuracy:		92.83 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.007975
  validation loss:		0.444457
  validation accuracy:		92.93 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.007833
  validation loss:		0.462057
  validation accuracy:		93.04 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.007903
  validation loss:		0.447320
  validation accuracy:		93.15 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.007801
  validation loss:		0.451333
  validation accuracy:		92.93 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.007700
  validation loss:		0.449033
  validation accuracy:		93.04 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.007614
  validation loss:		0.456896
  validation accuracy:		93.15 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.007945
  validation loss:		0.450086
  validation accuracy:		93.04 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.007633
  validation loss:		0.447894
  validation accuracy:		93.15 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.007762
  validation loss:		0.452801
  validation accuracy:		93.15 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.007627
  validation loss:		0.450228
  validation accuracy:		92.93 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.007821
  validation loss:		0.449544
  validation accuracy:		93.04 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.007745
  validation loss:		0.453647
  validation accuracy:		92.93 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.007453
  validation loss:		0.454881
  validation accuracy:		92.93 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.007557
  validation loss:		0.451059
  validation accuracy:		93.04 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.007614
  validation loss:		0.451138
  validation accuracy:		93.04 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.007655
  validation loss:		0.458897
  validation accuracy:		93.04 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.007636
  validation loss:		0.453384
  validation accuracy:		92.93 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.007267
  validation loss:		0.449646
  validation accuracy:		93.04 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.007680
  validation loss:		0.459423
  validation accuracy:		92.83 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.007746
  validation loss:		0.453047
  validation accuracy:		93.04 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.007611
  validation loss:		0.453224
  validation accuracy:		93.04 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.007635
  validation loss:		0.456671
  validation accuracy:		92.83 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.007592
  validation loss:		0.452221
  validation accuracy:		92.93 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.007497
  validation loss:		0.453650
  validation accuracy:		92.93 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.007528
  validation loss:		0.457492
  validation accuracy:		93.15 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.007659
  validation loss:		0.452162
  validation accuracy:		93.04 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.007601
  validation loss:		0.457260
  validation accuracy:		92.93 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.007137
  validation loss:		0.452331
  validation accuracy:		93.04 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.007565
  validation loss:		0.456696
  validation accuracy:		93.15 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.007530
  validation loss:		0.463071
  validation accuracy:		93.04 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.007050
  validation loss:		0.448335
  validation accuracy:		93.15 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.007530
  validation loss:		0.461098
  validation accuracy:		93.15 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.007321
  validation loss:		0.454926
  validation accuracy:		93.04 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.007327
  validation loss:		0.457163
  validation accuracy:		93.15 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.007470
  validation loss:		0.467073
  validation accuracy:		93.15 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.007460
  validation loss:		0.458238
  validation accuracy:		93.15 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.007085
  validation loss:		0.457677
  validation accuracy:		93.04 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.007334
  validation loss:		0.462209
  validation accuracy:		93.15 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.007271
  validation loss:		0.454114
  validation accuracy:		93.04 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.007469
  validation loss:		0.462267
  validation accuracy:		93.15 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.007380
  validation loss:		0.453609
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.007098
  validation loss:		0.455824
  validation accuracy:		92.93 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.007290
  validation loss:		0.460073
  validation accuracy:		93.04 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.007143
  validation loss:		0.460180
  validation accuracy:		92.93 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006999
  validation loss:		0.463538
  validation accuracy:		92.83 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.007235
  validation loss:		0.456822
  validation accuracy:		93.04 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007214
  validation loss:		0.460839
  validation accuracy:		93.15 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.007243
  validation loss:		0.467009
  validation accuracy:		93.04 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.007384
  validation loss:		0.463715
  validation accuracy:		93.04 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.007210
  validation loss:		0.456793
  validation accuracy:		93.04 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.007450
  validation loss:		0.460709
  validation accuracy:		92.93 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.007110
  validation loss:		0.460915
  validation accuracy:		92.93 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.006937
  validation loss:		0.456012
  validation accuracy:		93.04 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.007148
  validation loss:		0.462610
  validation accuracy:		92.93 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.006975
  validation loss:		0.465873
  validation accuracy:		93.15 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007202
  validation loss:		0.459317
  validation accuracy:		92.93 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.006924
  validation loss:		0.458890
  validation accuracy:		93.15 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.007229
  validation loss:		0.458794
  validation accuracy:		92.93 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.006730
  validation loss:		0.460633
  validation accuracy:		92.93 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.007145
  validation loss:		0.461968
  validation accuracy:		93.15 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.006867
  validation loss:		0.459954
  validation accuracy:		93.04 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.007175
  validation loss:		0.460865
  validation accuracy:		93.04 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.006926
  validation loss:		0.465787
  validation accuracy:		93.04 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.006970
  validation loss:		0.463152
  validation accuracy:		92.93 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.006925
  validation loss:		0.465060
  validation accuracy:		93.04 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007166
  validation loss:		0.459503
  validation accuracy:		93.15 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.007045
  validation loss:		0.463451
  validation accuracy:		93.04 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.006745
  validation loss:		0.463983
  validation accuracy:		92.93 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007073
  validation loss:		0.464566
  validation accuracy:		92.93 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007177
  validation loss:		0.465733
  validation accuracy:		92.83 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.006994
  validation loss:		0.457155
  validation accuracy:		93.15 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.007177
  validation loss:		0.468285
  validation accuracy:		92.93 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.006997
  validation loss:		0.463713
  validation accuracy:		93.04 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.006824
  validation loss:		0.467627
  validation accuracy:		93.04 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.006884
  validation loss:		0.459057
  validation accuracy:		93.04 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.007018
  validation loss:		0.461069
  validation accuracy:		93.04 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.006725
  validation loss:		0.470056
  validation accuracy:		93.15 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.006837
  validation loss:		0.468723
  validation accuracy:		93.15 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.006988
  validation loss:		0.466417
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.006784
  validation loss:		0.463526
  validation accuracy:		93.15 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.006883
  validation loss:		0.468382
  validation accuracy:		93.04 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.006985
  validation loss:		0.466294
  validation accuracy:		93.04 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.006826
  validation loss:		0.470372
  validation accuracy:		92.83 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.006806
  validation loss:		0.468587
  validation accuracy:		92.93 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.006521
  validation loss:		0.466476
  validation accuracy:		93.15 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.006719
  validation loss:		0.464216
  validation accuracy:		93.04 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.006551
  validation loss:		0.469815
  validation accuracy:		92.93 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.006713
  validation loss:		0.465476
  validation accuracy:		93.04 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.006715
  validation loss:		0.472622
  validation accuracy:		93.04 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.006482
  validation loss:		0.462598
  validation accuracy:		93.04 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.006644
  validation loss:		0.471263
  validation accuracy:		93.15 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.006628
  validation loss:		0.472090
  validation accuracy:		93.15 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.006723
  validation loss:		0.467266
  validation accuracy:		93.04 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.006641
  validation loss:		0.469692
  validation accuracy:		93.04 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.006639
  validation loss:		0.471713
  validation accuracy:		93.04 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.006468
  validation loss:		0.467059
  validation accuracy:		93.04 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.006589
  validation loss:		0.473078
  validation accuracy:		93.04 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.006724
  validation loss:		0.471582
  validation accuracy:		93.26 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.006691
  validation loss:		0.472932
  validation accuracy:		92.93 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.006669
  validation loss:		0.469948
  validation accuracy:		92.93 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.006887
  validation loss:		0.468089
  validation accuracy:		93.04 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.006570
  validation loss:		0.474119
  validation accuracy:		93.26 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.006583
  validation loss:		0.468880
  validation accuracy:		93.15 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.006497
  validation loss:		0.470975
  validation accuracy:		93.15 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.006426
  validation loss:		0.471970
  validation accuracy:		92.93 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.006337
  validation loss:		0.469871
  validation accuracy:		93.04 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.006638
  validation loss:		0.474762
  validation accuracy:		92.93 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.006546
  validation loss:		0.472998
  validation accuracy:		92.83 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.006326
  validation loss:		0.468818
  validation accuracy:		93.04 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.006522
  validation loss:		0.480035
  validation accuracy:		92.93 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.006461
  validation loss:		0.471773
  validation accuracy:		93.26 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.006481
  validation loss:		0.476279
  validation accuracy:		93.04 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.006162
  validation loss:		0.475378
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.006243
  validation loss:		0.468058
  validation accuracy:		93.15 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.006350
  validation loss:		0.477246
  validation accuracy:		93.04 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.006428
  validation loss:		0.472874
  validation accuracy:		92.93 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.006655
  validation loss:		0.469870
  validation accuracy:		93.04 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.006269
  validation loss:		0.476644
  validation accuracy:		93.04 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.006407
  validation loss:		0.475919
  validation accuracy:		93.04 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.006369
  validation loss:		0.475134
  validation accuracy:		92.93 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.006296
  validation loss:		0.470055
  validation accuracy:		93.04 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.006341
  validation loss:		0.478883
  validation accuracy:		92.93 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.006168
  validation loss:		0.475899
  validation accuracy:		93.04 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.006203
  validation loss:		0.477137
  validation accuracy:		92.93 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.006202
  validation loss:		0.476406
  validation accuracy:		92.93 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.006114
  validation loss:		0.474617
  validation accuracy:		93.04 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006412
  validation loss:		0.474165
  validation accuracy:		93.04 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.006448
  validation loss:		0.472837
  validation accuracy:		93.04 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.006188
  validation loss:		0.471852
  validation accuracy:		93.04 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006044
  validation loss:		0.480148
  validation accuracy:		93.04 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.006235
  validation loss:		0.470966
  validation accuracy:		93.04 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.006134
  validation loss:		0.477061
  validation accuracy:		93.04 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.006084
  validation loss:		0.479218
  validation accuracy:		93.15 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.006094
  validation loss:		0.475796
  validation accuracy:		92.93 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006243
  validation loss:		0.478777
  validation accuracy:		93.04 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.005964
  validation loss:		0.478964
  validation accuracy:		93.04 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006289
  validation loss:		0.472061
  validation accuracy:		93.04 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.006110
  validation loss:		0.474577
  validation accuracy:		93.15 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.006007
  validation loss:		0.476389
  validation accuracy:		93.04 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.006014
  validation loss:		0.481957
  validation accuracy:		93.04 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006242
  validation loss:		0.476483
  validation accuracy:		93.04 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.006045
  validation loss:		0.481134
  validation accuracy:		93.04 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006205
  validation loss:		0.476914
  validation accuracy:		93.04 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006152
  validation loss:		0.482803
  validation accuracy:		93.04 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005995
  validation loss:		0.475906
  validation accuracy:		93.15 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006091
  validation loss:		0.471290
  validation accuracy:		93.04 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.005957
  validation loss:		0.482985
  validation accuracy:		93.04 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006112
  validation loss:		0.483413
  validation accuracy:		93.04 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.005916
  validation loss:		0.474520
  validation accuracy:		93.15 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006015
  validation loss:		0.481959
  validation accuracy:		93.04 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006063
  validation loss:		0.477045
  validation accuracy:		93.15 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.005994
  validation loss:		0.479800
  validation accuracy:		93.04 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006044
  validation loss:		0.474680
  validation accuracy:		93.04 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006120
  validation loss:		0.482865
  validation accuracy:		92.93 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.005920
  validation loss:		0.481897
  validation accuracy:		93.04 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006009
  validation loss:		0.476332
  validation accuracy:		93.15 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.005838
  validation loss:		0.482696
  validation accuracy:		93.15 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.005762
  validation loss:		0.483973
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.005824
  validation loss:		0.478406
  validation accuracy:		93.15 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.005981
  validation loss:		0.481560
  validation accuracy:		93.15 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.005968
  validation loss:		0.484252
  validation accuracy:		93.15 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.005833
  validation loss:		0.476240
  validation accuracy:		93.04 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.005947
  validation loss:		0.482999
  validation accuracy:		93.04 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006051
  validation loss:		0.478884
  validation accuracy:		93.04 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006036
  validation loss:		0.480083
  validation accuracy:		93.04 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.006014
  validation loss:		0.481775
  validation accuracy:		93.15 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.005796
  validation loss:		0.485308
  validation accuracy:		93.04 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.005657
  validation loss:		0.480567
  validation accuracy:		93.15 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.005735
  validation loss:		0.486200
  validation accuracy:		93.15 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006039
  validation loss:		0.488871
  validation accuracy:		93.15 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.005756
  validation loss:		0.478187
  validation accuracy:		93.04 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.005810
  validation loss:		0.486085
  validation accuracy:		93.04 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.005842
  validation loss:		0.481342
  validation accuracy:		93.15 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005754
  validation loss:		0.480295
  validation accuracy:		93.04 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.005811
  validation loss:		0.481520
  validation accuracy:		93.15 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.005749
  validation loss:		0.482204
  validation accuracy:		93.04 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.005905
  validation loss:		0.481461
  validation accuracy:		93.15 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.005807
  validation loss:		0.493398
  validation accuracy:		93.04 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.005967
  validation loss:		0.489245
  validation accuracy:		93.26 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.006017
  validation loss:		0.480843
  validation accuracy:		93.04 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.005736
  validation loss:		0.483566
  validation accuracy:		93.04 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.005609
  validation loss:		0.482759
  validation accuracy:		93.15 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.005831
  validation loss:		0.482014
  validation accuracy:		93.15 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.005753
  validation loss:		0.487800
  validation accuracy:		93.04 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.005657
  validation loss:		0.486772
  validation accuracy:		93.15 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.005678
  validation loss:		0.486266
  validation accuracy:		93.04 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.005675
  validation loss:		0.489442
  validation accuracy:		93.15 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.005541
  validation loss:		0.486876
  validation accuracy:		93.15 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.005525
  validation loss:		0.486737
  validation accuracy:		92.93 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.005776
  validation loss:		0.487029
  validation accuracy:		93.15 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005587
  validation loss:		0.485599
  validation accuracy:		93.15 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.005597
  validation loss:		0.487116
  validation accuracy:		93.15 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.005670
  validation loss:		0.489700
  validation accuracy:		93.15 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.005598
  validation loss:		0.485717
  validation accuracy:		93.15 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.005692
  validation loss:		0.490390
  validation accuracy:		93.15 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.005718
  validation loss:		0.486945
  validation accuracy:		93.04 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.005626
  validation loss:		0.482997
  validation accuracy:		93.15 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.005576
  validation loss:		0.482430
  validation accuracy:		93.04 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005656
  validation loss:		0.492639
  validation accuracy:		93.15 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005461
  validation loss:		0.490495
  validation accuracy:		93.15 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005501
  validation loss:		0.483622
  validation accuracy:		93.04 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.005383
  validation loss:		0.489449
  validation accuracy:		93.15 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.005561
  validation loss:		0.489094
  validation accuracy:		93.15 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.005481
  validation loss:		0.488814
  validation accuracy:		93.04 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005442
  validation loss:		0.487677
  validation accuracy:		93.15 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.005610
  validation loss:		0.493021
  validation accuracy:		93.15 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.005525
  validation loss:		0.488956
  validation accuracy:		93.15 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005499
  validation loss:		0.488967
  validation accuracy:		93.04 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005557
  validation loss:		0.491223
  validation accuracy:		93.04 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.005468
  validation loss:		0.487255
  validation accuracy:		93.15 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.005466
  validation loss:		0.490957
  validation accuracy:		93.15 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.005424
  validation loss:		0.493305
  validation accuracy:		93.04 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.005259
  validation loss:		0.491828
  validation accuracy:		93.15 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005357
  validation loss:		0.489161
  validation accuracy:		93.15 %
Epoch 1619 of 2000 took 0.037s
  training loss:		0.005485
  validation loss:		0.495642
  validation accuracy:		93.04 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.005348
  validation loss:		0.488594
  validation accuracy:		93.04 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005419
  validation loss:		0.490136
  validation accuracy:		93.15 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.005332
  validation loss:		0.487774
  validation accuracy:		93.04 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.005365
  validation loss:		0.492359
  validation accuracy:		93.26 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.005205
  validation loss:		0.494047
  validation accuracy:		93.15 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.005392
  validation loss:		0.488673
  validation accuracy:		93.04 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.005225
  validation loss:		0.490753
  validation accuracy:		93.15 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005314
  validation loss:		0.493507
  validation accuracy:		93.15 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005252
  validation loss:		0.490061
  validation accuracy:		93.15 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.005498
  validation loss:		0.489747
  validation accuracy:		92.93 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.005228
  validation loss:		0.495799
  validation accuracy:		93.15 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005251
  validation loss:		0.492543
  validation accuracy:		93.15 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005378
  validation loss:		0.492983
  validation accuracy:		93.04 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.005271
  validation loss:		0.489789
  validation accuracy:		93.15 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.005213
  validation loss:		0.491633
  validation accuracy:		93.04 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005316
  validation loss:		0.493596
  validation accuracy:		93.15 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005367
  validation loss:		0.493235
  validation accuracy:		93.15 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005222
  validation loss:		0.492586
  validation accuracy:		93.04 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.005278
  validation loss:		0.494677
  validation accuracy:		93.15 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005216
  validation loss:		0.493522
  validation accuracy:		93.15 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005229
  validation loss:		0.494231
  validation accuracy:		93.04 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.005212
  validation loss:		0.491567
  validation accuracy:		93.26 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005263
  validation loss:		0.498180
  validation accuracy:		93.04 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005028
  validation loss:		0.496811
  validation accuracy:		93.04 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005320
  validation loss:		0.497245
  validation accuracy:		93.04 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.005180
  validation loss:		0.491658
  validation accuracy:		93.04 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.005151
  validation loss:		0.493703
  validation accuracy:		93.15 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.005293
  validation loss:		0.498603
  validation accuracy:		93.04 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.005185
  validation loss:		0.493434
  validation accuracy:		93.15 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005342
  validation loss:		0.495261
  validation accuracy:		93.04 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005270
  validation loss:		0.498683
  validation accuracy:		93.15 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005060
  validation loss:		0.496429
  validation accuracy:		93.15 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005022
  validation loss:		0.493773
  validation accuracy:		93.04 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005261
  validation loss:		0.490662
  validation accuracy:		92.93 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005324
  validation loss:		0.494366
  validation accuracy:		93.04 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.005093
  validation loss:		0.492101
  validation accuracy:		93.04 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004892
  validation loss:		0.497061
  validation accuracy:		93.15 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004959
  validation loss:		0.496517
  validation accuracy:		93.15 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005085
  validation loss:		0.490969
  validation accuracy:		93.04 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005277
  validation loss:		0.496939
  validation accuracy:		93.15 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005106
  validation loss:		0.498930
  validation accuracy:		93.04 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.005096
  validation loss:		0.492299
  validation accuracy:		93.04 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.004972
  validation loss:		0.499306
  validation accuracy:		93.15 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005015
  validation loss:		0.498935
  validation accuracy:		93.15 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.005175
  validation loss:		0.499835
  validation accuracy:		93.15 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004915
  validation loss:		0.500134
  validation accuracy:		93.15 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004882
  validation loss:		0.497948
  validation accuracy:		93.04 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004953
  validation loss:		0.501818
  validation accuracy:		93.15 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005024
  validation loss:		0.495550
  validation accuracy:		93.15 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005119
  validation loss:		0.499293
  validation accuracy:		93.15 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005118
  validation loss:		0.499390
  validation accuracy:		93.15 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005088
  validation loss:		0.502072
  validation accuracy:		93.04 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005072
  validation loss:		0.493327
  validation accuracy:		93.15 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.005092
  validation loss:		0.497434
  validation accuracy:		93.15 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004936
  validation loss:		0.496843
  validation accuracy:		93.04 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005002
  validation loss:		0.499501
  validation accuracy:		93.04 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005031
  validation loss:		0.504197
  validation accuracy:		93.04 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.004930
  validation loss:		0.499377
  validation accuracy:		93.15 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005046
  validation loss:		0.501445
  validation accuracy:		93.26 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.004905
  validation loss:		0.501195
  validation accuracy:		93.15 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005005
  validation loss:		0.495379
  validation accuracy:		93.15 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004951
  validation loss:		0.498867
  validation accuracy:		93.15 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004926
  validation loss:		0.500752
  validation accuracy:		93.15 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.004734
  validation loss:		0.495534
  validation accuracy:		93.15 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004897
  validation loss:		0.501442
  validation accuracy:		93.15 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.004813
  validation loss:		0.505595
  validation accuracy:		93.15 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005008
  validation loss:		0.499031
  validation accuracy:		93.04 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.004983
  validation loss:		0.506632
  validation accuracy:		93.15 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005006
  validation loss:		0.505337
  validation accuracy:		93.15 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.004937
  validation loss:		0.501998
  validation accuracy:		93.15 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.004987
  validation loss:		0.503095
  validation accuracy:		93.15 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.004894
  validation loss:		0.501676
  validation accuracy:		93.04 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004739
  validation loss:		0.503636
  validation accuracy:		93.04 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.004947
  validation loss:		0.503268
  validation accuracy:		93.04 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.004694
  validation loss:		0.500688
  validation accuracy:		93.15 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.004657
  validation loss:		0.506809
  validation accuracy:		93.15 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.004891
  validation loss:		0.499789
  validation accuracy:		93.04 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.004922
  validation loss:		0.500644
  validation accuracy:		93.15 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004825
  validation loss:		0.500946
  validation accuracy:		93.04 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.004752
  validation loss:		0.507050
  validation accuracy:		93.15 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004753
  validation loss:		0.500891
  validation accuracy:		93.04 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004719
  validation loss:		0.502438
  validation accuracy:		93.15 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.004842
  validation loss:		0.506036
  validation accuracy:		93.04 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.004673
  validation loss:		0.503495
  validation accuracy:		93.15 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004764
  validation loss:		0.506712
  validation accuracy:		93.15 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004677
  validation loss:		0.508006
  validation accuracy:		93.15 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004826
  validation loss:		0.505672
  validation accuracy:		93.04 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.004880
  validation loss:		0.501975
  validation accuracy:		93.04 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004811
  validation loss:		0.503349
  validation accuracy:		93.15 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004738
  validation loss:		0.506601
  validation accuracy:		93.15 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.004698
  validation loss:		0.501879
  validation accuracy:		93.15 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004640
  validation loss:		0.506755
  validation accuracy:		93.15 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004755
  validation loss:		0.500193
  validation accuracy:		93.04 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004775
  validation loss:		0.505391
  validation accuracy:		93.15 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.004620
  validation loss:		0.506462
  validation accuracy:		93.15 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004749
  validation loss:		0.508365
  validation accuracy:		93.15 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004774
  validation loss:		0.506926
  validation accuracy:		93.15 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004844
  validation loss:		0.508507
  validation accuracy:		93.15 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004601
  validation loss:		0.503819
  validation accuracy:		93.04 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004652
  validation loss:		0.506024
  validation accuracy:		93.04 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.004726
  validation loss:		0.511206
  validation accuracy:		93.15 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004737
  validation loss:		0.502025
  validation accuracy:		93.04 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004683
  validation loss:		0.508885
  validation accuracy:		93.15 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004639
  validation loss:		0.503854
  validation accuracy:		93.15 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004619
  validation loss:		0.510982
  validation accuracy:		93.15 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004650
  validation loss:		0.505352
  validation accuracy:		93.15 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004585
  validation loss:		0.501594
  validation accuracy:		93.04 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004758
  validation loss:		0.508263
  validation accuracy:		93.15 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004625
  validation loss:		0.507410
  validation accuracy:		93.15 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004532
  validation loss:		0.507382
  validation accuracy:		93.15 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004568
  validation loss:		0.509157
  validation accuracy:		93.15 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004717
  validation loss:		0.508841
  validation accuracy:		93.15 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004557
  validation loss:		0.511381
  validation accuracy:		93.15 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004539
  validation loss:		0.509489
  validation accuracy:		93.15 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004584
  validation loss:		0.509790
  validation accuracy:		93.15 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004586
  validation loss:		0.505170
  validation accuracy:		93.04 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004656
  validation loss:		0.508697
  validation accuracy:		93.04 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004603
  validation loss:		0.512527
  validation accuracy:		93.15 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004481
  validation loss:		0.507496
  validation accuracy:		93.15 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004519
  validation loss:		0.507521
  validation accuracy:		93.15 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004566
  validation loss:		0.507917
  validation accuracy:		93.15 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004540
  validation loss:		0.508529
  validation accuracy:		93.15 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004508
  validation loss:		0.508926
  validation accuracy:		93.15 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004470
  validation loss:		0.511474
  validation accuracy:		93.15 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004475
  validation loss:		0.510296
  validation accuracy:		93.15 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.509943
  validation accuracy:		93.15 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004276
  validation loss:		0.504752
  validation accuracy:		93.04 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.514036
  validation accuracy:		93.15 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004573
  validation loss:		0.508847
  validation accuracy:		93.15 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004452
  validation loss:		0.514561
  validation accuracy:		93.15 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004515
  validation loss:		0.510482
  validation accuracy:		93.15 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004333
  validation loss:		0.512778
  validation accuracy:		93.04 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004578
  validation loss:		0.511621
  validation accuracy:		93.15 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004399
  validation loss:		0.506975
  validation accuracy:		93.15 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.512361
  validation accuracy:		93.15 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004357
  validation loss:		0.514927
  validation accuracy:		93.04 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004556
  validation loss:		0.512244
  validation accuracy:		93.15 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004301
  validation loss:		0.513929
  validation accuracy:		93.04 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004358
  validation loss:		0.512512
  validation accuracy:		93.15 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004468
  validation loss:		0.513464
  validation accuracy:		93.15 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.508158
  validation accuracy:		93.15 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004404
  validation loss:		0.507644
  validation accuracy:		93.04 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004369
  validation loss:		0.514069
  validation accuracy:		93.15 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004253
  validation loss:		0.510268
  validation accuracy:		93.04 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004404
  validation loss:		0.515064
  validation accuracy:		93.15 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004273
  validation loss:		0.507409
  validation accuracy:		93.04 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004473
  validation loss:		0.517825
  validation accuracy:		93.15 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004447
  validation loss:		0.512818
  validation accuracy:		93.04 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004415
  validation loss:		0.512609
  validation accuracy:		93.15 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.514866
  validation accuracy:		93.15 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.511117
  validation accuracy:		93.15 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004357
  validation loss:		0.517592
  validation accuracy:		93.15 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004327
  validation loss:		0.514082
  validation accuracy:		93.15 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004261
  validation loss:		0.510218
  validation accuracy:		93.04 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004493
  validation loss:		0.515062
  validation accuracy:		93.15 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004365
  validation loss:		0.511477
  validation accuracy:		93.15 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004206
  validation loss:		0.511549
  validation accuracy:		93.26 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004419
  validation loss:		0.515006
  validation accuracy:		93.15 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004292
  validation loss:		0.515417
  validation accuracy:		93.15 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004177
  validation loss:		0.516210
  validation accuracy:		93.15 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004364
  validation loss:		0.514315
  validation accuracy:		93.15 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.518850
  validation accuracy:		93.15 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.514067
  validation accuracy:		93.15 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004124
  validation loss:		0.517987
  validation accuracy:		93.15 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004261
  validation loss:		0.516819
  validation accuracy:		93.15 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.514822
  validation accuracy:		93.15 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004181
  validation loss:		0.518623
  validation accuracy:		93.15 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004206
  validation loss:		0.514782
  validation accuracy:		93.15 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004368
  validation loss:		0.518817
  validation accuracy:		93.04 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004122
  validation loss:		0.517409
  validation accuracy:		93.04 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004128
  validation loss:		0.518559
  validation accuracy:		93.15 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004080
  validation loss:		0.515141
  validation accuracy:		93.15 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004213
  validation loss:		0.516772
  validation accuracy:		93.15 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004208
  validation loss:		0.514207
  validation accuracy:		93.04 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004220
  validation loss:		0.519589
  validation accuracy:		93.15 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004194
  validation loss:		0.519642
  validation accuracy:		93.15 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004101
  validation loss:		0.516032
  validation accuracy:		93.15 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004164
  validation loss:		0.521792
  validation accuracy:		93.15 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004232
  validation loss:		0.518107
  validation accuracy:		93.04 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004186
  validation loss:		0.515477
  validation accuracy:		93.15 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.521822
  validation accuracy:		93.15 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004194
  validation loss:		0.517000
  validation accuracy:		93.04 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004193
  validation loss:		0.512386
  validation accuracy:		93.15 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004234
  validation loss:		0.523578
  validation accuracy:		93.04 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.515268
  validation accuracy:		93.04 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004187
  validation loss:		0.520983
  validation accuracy:		93.15 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004146
  validation loss:		0.515081
  validation accuracy:		93.15 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004167
  validation loss:		0.519957
  validation accuracy:		93.15 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004132
  validation loss:		0.519965
  validation accuracy:		93.15 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004072
  validation loss:		0.514975
  validation accuracy:		93.15 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004110
  validation loss:		0.519453
  validation accuracy:		93.15 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004007
  validation loss:		0.516944
  validation accuracy:		93.15 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003948
  validation loss:		0.520445
  validation accuracy:		93.15 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004094
  validation loss:		0.516418
  validation accuracy:		93.15 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004019
  validation loss:		0.526664
  validation accuracy:		93.04 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004002
  validation loss:		0.518212
  validation accuracy:		93.15 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004172
  validation loss:		0.521111
  validation accuracy:		93.15 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004136
  validation loss:		0.522328
  validation accuracy:		93.15 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004115
  validation loss:		0.519415
  validation accuracy:		93.15 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004004
  validation loss:		0.522283
  validation accuracy:		93.15 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004125
  validation loss:		0.523300
  validation accuracy:		93.15 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004144
  validation loss:		0.520923
  validation accuracy:		93.15 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003946
  validation loss:		0.520532
  validation accuracy:		93.15 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003882
  validation loss:		0.518770
  validation accuracy:		93.15 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004010
  validation loss:		0.522920
  validation accuracy:		93.15 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004091
  validation loss:		0.519817
  validation accuracy:		93.15 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003980
  validation loss:		0.519249
  validation accuracy:		93.15 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004099
  validation loss:		0.521383
  validation accuracy:		93.15 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003990
  validation loss:		0.523518
  validation accuracy:		93.15 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003909
  validation loss:		0.517418
  validation accuracy:		93.15 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.004173
  validation loss:		0.518795
  validation accuracy:		93.04 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.004048
  validation loss:		0.523563
  validation accuracy:		93.15 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004059
  validation loss:		0.523127
  validation accuracy:		93.04 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003972
  validation loss:		0.516585
  validation accuracy:		93.15 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.004043
  validation loss:		0.523296
  validation accuracy:		93.15 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003976
  validation loss:		0.522354
  validation accuracy:		93.15 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003972
  validation loss:		0.526072
  validation accuracy:		93.15 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004062
  validation loss:		0.526639
  validation accuracy:		93.04 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003924
  validation loss:		0.526994
  validation accuracy:		93.15 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003950
  validation loss:		0.520428
  validation accuracy:		93.04 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003898
  validation loss:		0.524773
  validation accuracy:		93.15 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003959
  validation loss:		0.524957
  validation accuracy:		93.15 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.521401
  validation accuracy:		93.04 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003889
  validation loss:		0.526246
  validation accuracy:		93.04 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003959
  validation loss:		0.527959
  validation accuracy:		93.15 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003974
  validation loss:		0.523615
  validation accuracy:		93.15 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003925
  validation loss:		0.526814
  validation accuracy:		93.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.523139
  validation accuracy:		93.04 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003989
  validation loss:		0.524682
  validation accuracy:		93.15 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003853
  validation loss:		0.526392
  validation accuracy:		93.15 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003828
  validation loss:		0.523596
  validation accuracy:		93.04 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003949
  validation loss:		0.530768
  validation accuracy:		93.15 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003885
  validation loss:		0.524249
  validation accuracy:		93.15 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003872
  validation loss:		0.529099
  validation accuracy:		93.15 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003905
  validation loss:		0.524665
  validation accuracy:		93.15 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003868
  validation loss:		0.527377
  validation accuracy:		93.15 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003819
  validation loss:		0.525467
  validation accuracy:		93.15 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003700
  validation loss:		0.531573
  validation accuracy:		93.04 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003810
  validation loss:		0.528585
  validation accuracy:		93.15 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003839
  validation loss:		0.524457
  validation accuracy:		93.04 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003934
  validation loss:		0.531189
  validation accuracy:		93.15 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003805
  validation loss:		0.523718
  validation accuracy:		93.15 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003870
  validation loss:		0.529789
  validation accuracy:		93.15 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003850
  validation loss:		0.522949
  validation accuracy:		93.04 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003888
  validation loss:		0.534417
  validation accuracy:		93.04 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003822
  validation loss:		0.525692
  validation accuracy:		93.04 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003893
  validation loss:		0.525724
  validation accuracy:		93.15 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.531396
  validation accuracy:		93.15 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003716
  validation loss:		0.525720
  validation accuracy:		93.15 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003848
  validation loss:		0.529661
  validation accuracy:		93.15 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.529143
  validation accuracy:		93.15 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.528044
  validation accuracy:		93.04 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003799
  validation loss:		0.530667
  validation accuracy:		93.15 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003693
  validation loss:		0.526382
  validation accuracy:		93.15 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003731
  validation loss:		0.530014
  validation accuracy:		93.15 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.530697
  validation accuracy:		93.15 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003742
  validation loss:		0.530112
  validation accuracy:		93.15 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003842
  validation loss:		0.530185
  validation accuracy:		93.15 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.525473
  validation accuracy:		93.15 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003787
  validation loss:		0.529386
  validation accuracy:		93.15 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003773
  validation loss:		0.533225
  validation accuracy:		93.15 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003672
  validation loss:		0.526598
  validation accuracy:		93.04 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003867
  validation loss:		0.529416
  validation accuracy:		93.15 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.527095
  validation accuracy:		93.15 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003795
  validation loss:		0.530176
  validation accuracy:		93.15 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003721
  validation loss:		0.529650
  validation accuracy:		93.04 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003726
  validation loss:		0.532811
  validation accuracy:		93.15 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003738
  validation loss:		0.527545
  validation accuracy:		93.04 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003866
  validation loss:		0.532280
  validation accuracy:		93.15 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003669
  validation loss:		0.533711
  validation accuracy:		92.93 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003756
  validation loss:		0.532511
  validation accuracy:		93.15 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003710
  validation loss:		0.529521
  validation accuracy:		93.15 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003656
  validation loss:		0.534262
  validation accuracy:		93.15 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003679
  validation loss:		0.531057
  validation accuracy:		93.15 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.531958
  validation accuracy:		93.15 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003671
  validation loss:		0.534066
  validation accuracy:		93.15 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003700
  validation loss:		0.534439
  validation accuracy:		93.15 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003694
  validation loss:		0.531991
  validation accuracy:		93.15 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.530628
  validation accuracy:		93.15 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.531496
  validation accuracy:		93.15 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003740
  validation loss:		0.534076
  validation accuracy:		93.04 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003644
  validation loss:		0.529559
  validation accuracy:		93.15 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003612
  validation loss:		0.536595
  validation accuracy:		93.15 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003671
  validation loss:		0.530178
  validation accuracy:		93.15 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.534978
  validation accuracy:		93.15 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003629
  validation loss:		0.527907
  validation accuracy:		93.15 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003479
  validation loss:		0.537250
  validation accuracy:		93.15 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003662
  validation loss:		0.529226
  validation accuracy:		93.15 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.532593
  validation accuracy:		93.15 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003649
  validation loss:		0.533181
  validation accuracy:		93.15 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003566
  validation loss:		0.532579
  validation accuracy:		93.15 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003579
  validation loss:		0.534915
  validation accuracy:		93.04 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003574
  validation loss:		0.533068
  validation accuracy:		93.15 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003676
  validation loss:		0.535960
  validation accuracy:		93.15 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003507
  validation loss:		0.537509
  validation accuracy:		93.04 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003680
  validation loss:		0.533734
  validation accuracy:		93.04 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003566
  validation loss:		0.536377
  validation accuracy:		93.04 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003670
  validation loss:		0.534144
  validation accuracy:		93.15 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003570
  validation loss:		0.533211
  validation accuracy:		93.04 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003608
  validation loss:		0.532702
  validation accuracy:		93.15 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003498
  validation loss:		0.545853
  validation accuracy:		92.93 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003645
  validation loss:		0.533813
  validation accuracy:		93.15 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003521
  validation loss:		0.536555
  validation accuracy:		93.15 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003556
  validation loss:		0.535306
  validation accuracy:		92.93 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003444
  validation loss:		0.534341
  validation accuracy:		93.15 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003520
  validation loss:		0.534533
  validation accuracy:		92.93 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003589
  validation loss:		0.536238
  validation accuracy:		93.15 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003565
  validation loss:		0.539446
  validation accuracy:		93.15 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003573
  validation loss:		0.535170
  validation accuracy:		93.15 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003562
  validation loss:		0.535688
  validation accuracy:		93.15 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003642
  validation loss:		0.539693
  validation accuracy:		93.04 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003541
  validation loss:		0.534041
  validation accuracy:		93.15 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003492
  validation loss:		0.537173
  validation accuracy:		93.15 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003538
  validation loss:		0.537539
  validation accuracy:		93.15 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.539622
  validation accuracy:		93.04 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003532
  validation loss:		0.539711
  validation accuracy:		93.04 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003468
  validation loss:		0.533518
  validation accuracy:		93.15 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003541
  validation loss:		0.538224
  validation accuracy:		93.15 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003471
  validation loss:		0.538869
  validation accuracy:		93.15 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003360
  validation loss:		0.540328
  validation accuracy:		93.15 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003503
  validation loss:		0.538354
  validation accuracy:		92.93 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003453
  validation loss:		0.537905
  validation accuracy:		93.04 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003545
  validation loss:		0.540195
  validation accuracy:		93.15 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003470
  validation loss:		0.536661
  validation accuracy:		93.15 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003403
  validation loss:		0.539685
  validation accuracy:		93.15 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003342
  validation loss:		0.539124
  validation accuracy:		92.93 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003495
  validation loss:		0.538915
  validation accuracy:		93.15 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003411
  validation loss:		0.540468
  validation accuracy:		93.15 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003438
  validation loss:		0.534679
  validation accuracy:		93.04 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003577
  validation loss:		0.538670
  validation accuracy:		93.15 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003387
  validation loss:		0.535500
  validation accuracy:		93.04 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003396
  validation loss:		0.539838
  validation accuracy:		93.04 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003360
  validation loss:		0.537279
  validation accuracy:		93.15 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003441
  validation loss:		0.543283
  validation accuracy:		93.04 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003388
  validation loss:		0.535993
  validation accuracy:		93.15 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003394
  validation loss:		0.538858
  validation accuracy:		93.15 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003333
  validation loss:		0.542723
  validation accuracy:		93.15 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003334
  validation loss:		0.540667
  validation accuracy:		93.15 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003265
  validation loss:		0.538415
  validation accuracy:		93.04 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003375
  validation loss:		0.540837
  validation accuracy:		93.04 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003344
  validation loss:		0.543701
  validation accuracy:		93.15 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003400
  validation loss:		0.538964
  validation accuracy:		93.15 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003431
  validation loss:		0.541086
  validation accuracy:		93.04 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003449
  validation loss:		0.536491
  validation accuracy:		93.04 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003379
  validation loss:		0.540345
  validation accuracy:		93.15 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003350
  validation loss:		0.539994
  validation accuracy:		93.15 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003447
  validation loss:		0.540910
  validation accuracy:		93.15 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003394
  validation loss:		0.537711
  validation accuracy:		93.04 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003380
  validation loss:		0.541192
  validation accuracy:		92.93 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003364
  validation loss:		0.539297
  validation accuracy:		93.04 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003266
  validation loss:		0.542481
  validation accuracy:		93.15 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003328
  validation loss:		0.542262
  validation accuracy:		93.15 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003302
  validation loss:		0.541257
  validation accuracy:		93.15 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.543847
  validation accuracy:		93.15 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003215
  validation loss:		0.541078
  validation accuracy:		93.04 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003276
  validation loss:		0.540881
  validation accuracy:		93.15 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003394
  validation loss:		0.540286
  validation accuracy:		93.04 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003413
  validation loss:		0.544866
  validation accuracy:		93.15 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003434
  validation loss:		0.540244
  validation accuracy:		93.04 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003336
  validation loss:		0.544030
  validation accuracy:		93.15 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.548078
  validation accuracy:		93.15 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003332
  validation loss:		0.540155
  validation accuracy:		92.93 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003336
  validation loss:		0.545469
  validation accuracy:		93.15 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003325
  validation loss:		0.543812
  validation accuracy:		93.04 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003249
  validation loss:		0.542620
  validation accuracy:		93.15 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003333
  validation loss:		0.546254
  validation accuracy:		93.15 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003344
  validation loss:		0.543575
  validation accuracy:		93.04 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003352
  validation loss:		0.542272
  validation accuracy:		93.04 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003288
  validation loss:		0.547628
  validation accuracy:		93.15 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003247
  validation loss:		0.542614
  validation accuracy:		93.04 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003267
  validation loss:		0.544041
  validation accuracy:		93.15 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003247
  validation loss:		0.543920
  validation accuracy:		93.04 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003322
  validation loss:		0.544836
  validation accuracy:		93.15 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003300
  validation loss:		0.544446
  validation accuracy:		93.04 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003254
  validation loss:		0.546472
  validation accuracy:		93.15 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003223
  validation loss:		0.543188
  validation accuracy:		92.93 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003243
  validation loss:		0.547023
  validation accuracy:		93.15 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.543916
  validation accuracy:		93.15 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003239
  validation loss:		0.548144
  validation accuracy:		93.15 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003251
  validation loss:		0.543764
  validation accuracy:		93.15 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003288
  validation loss:		0.548972
  validation accuracy:		93.15 %
Final results:
  test loss:			1.255332
  test accuracy:		84.50 %
