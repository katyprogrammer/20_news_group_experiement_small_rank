Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.102s
  training loss:		2.980588
  validation loss:		2.976739
  validation accuracy:		4.13 %
Epoch 2 of 2000 took 0.097s
  training loss:		2.960178
  validation loss:		2.950463
  validation accuracy:		12.39 %
Epoch 3 of 2000 took 0.097s
  training loss:		2.932670
  validation loss:		2.921792
  validation accuracy:		13.15 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.903593
  validation loss:		2.892737
  validation accuracy:		13.04 %
Epoch 5 of 2000 took 0.097s
  training loss:		2.873524
  validation loss:		2.862082
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.840621
  validation loss:		2.829017
  validation accuracy:		12.72 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.805833
  validation loss:		2.792494
  validation accuracy:		12.72 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.766931
  validation loss:		2.751222
  validation accuracy:		13.04 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.723800
  validation loss:		2.703993
  validation accuracy:		13.26 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.673569
  validation loss:		2.649299
  validation accuracy:		16.20 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.620181
  validation loss:		2.588780
  validation accuracy:		17.83 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.560746
  validation loss:		2.521982
  validation accuracy:		16.30 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.497777
  validation loss:		2.451674
  validation accuracy:		15.33 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.442812
  validation loss:		2.386317
  validation accuracy:		16.30 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.394015
  validation loss:		2.332220
  validation accuracy:		18.15 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.358174
  validation loss:		2.293895
  validation accuracy:		16.09 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.335744
  validation loss:		2.273002
  validation accuracy:		13.80 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.320824
  validation loss:		2.264716
  validation accuracy:		11.85 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.312456
  validation loss:		2.258067
  validation accuracy:		11.52 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.305573
  validation loss:		2.244768
  validation accuracy:		18.48 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.304089
  validation loss:		2.249868
  validation accuracy:		15.87 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.299504
  validation loss:		2.249872
  validation accuracy:		16.63 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.298535
  validation loss:		2.242720
  validation accuracy:		15.54 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.297296
  validation loss:		2.249280
  validation accuracy:		13.04 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.293960
  validation loss:		2.238573
  validation accuracy:		15.33 %
Epoch 26 of 2000 took 0.098s
  training loss:		2.295166
  validation loss:		2.243874
  validation accuracy:		16.85 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.293652
  validation loss:		2.244224
  validation accuracy:		16.52 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.291759
  validation loss:		2.238648
  validation accuracy:		13.59 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.293133
  validation loss:		2.238412
  validation accuracy:		16.63 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.291827
  validation loss:		2.235837
  validation accuracy:		16.96 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.290366
  validation loss:		2.244282
  validation accuracy:		17.61 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.289558
  validation loss:		2.233728
  validation accuracy:		19.24 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.289098
  validation loss:		2.235560
  validation accuracy:		18.91 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.288208
  validation loss:		2.236920
  validation accuracy:		21.30 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.287723
  validation loss:		2.239166
  validation accuracy:		19.35 %
Epoch 36 of 2000 took 0.101s
  training loss:		2.287220
  validation loss:		2.233212
  validation accuracy:		16.30 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.287250
  validation loss:		2.235820
  validation accuracy:		16.20 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.287499
  validation loss:		2.238854
  validation accuracy:		18.37 %
Epoch 39 of 2000 took 0.097s
  training loss:		2.285030
  validation loss:		2.231403
  validation accuracy:		15.65 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.284773
  validation loss:		2.224858
  validation accuracy:		20.43 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.284387
  validation loss:		2.231763
  validation accuracy:		22.28 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.282854
  validation loss:		2.232944
  validation accuracy:		17.93 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.283397
  validation loss:		2.235500
  validation accuracy:		22.39 %
Epoch 44 of 2000 took 0.097s
  training loss:		2.282922
  validation loss:		2.228231
  validation accuracy:		15.76 %
Epoch 45 of 2000 took 0.097s
  training loss:		2.281015
  validation loss:		2.223941
  validation accuracy:		18.80 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.281057
  validation loss:		2.228416
  validation accuracy:		17.39 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.280422
  validation loss:		2.226325
  validation accuracy:		22.39 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.278341
  validation loss:		2.226448
  validation accuracy:		20.33 %
Epoch 49 of 2000 took 0.097s
  training loss:		2.278698
  validation loss:		2.226466
  validation accuracy:		22.07 %
Epoch 50 of 2000 took 0.097s
  training loss:		2.277758
  validation loss:		2.226095
  validation accuracy:		25.43 %
Epoch 51 of 2000 took 0.097s
  training loss:		2.276341
  validation loss:		2.221821
  validation accuracy:		25.98 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.276280
  validation loss:		2.223849
  validation accuracy:		22.39 %
Epoch 53 of 2000 took 0.097s
  training loss:		2.274156
  validation loss:		2.218831
  validation accuracy:		25.76 %
Epoch 54 of 2000 took 0.097s
  training loss:		2.274062
  validation loss:		2.219605
  validation accuracy:		23.91 %
Epoch 55 of 2000 took 0.097s
  training loss:		2.272643
  validation loss:		2.223301
  validation accuracy:		22.61 %
Epoch 56 of 2000 took 0.097s
  training loss:		2.269703
  validation loss:		2.216511
  validation accuracy:		21.74 %
Epoch 57 of 2000 took 0.098s
  training loss:		2.269813
  validation loss:		2.213602
  validation accuracy:		25.11 %
Epoch 58 of 2000 took 0.097s
  training loss:		2.267980
  validation loss:		2.216398
  validation accuracy:		24.13 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.264859
  validation loss:		2.210860
  validation accuracy:		25.22 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.264638
  validation loss:		2.203214
  validation accuracy:		26.85 %
Epoch 61 of 2000 took 0.097s
  training loss:		2.261645
  validation loss:		2.209587
  validation accuracy:		26.20 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.260593
  validation loss:		2.205195
  validation accuracy:		25.76 %
Epoch 63 of 2000 took 0.097s
  training loss:		2.258882
  validation loss:		2.203679
  validation accuracy:		26.74 %
Epoch 64 of 2000 took 0.097s
  training loss:		2.254669
  validation loss:		2.195314
  validation accuracy:		24.67 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.253108
  validation loss:		2.191246
  validation accuracy:		26.96 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.249506
  validation loss:		2.192704
  validation accuracy:		27.28 %
Epoch 67 of 2000 took 0.097s
  training loss:		2.246319
  validation loss:		2.186853
  validation accuracy:		25.87 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.243440
  validation loss:		2.187623
  validation accuracy:		26.41 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.239632
  validation loss:		2.179682
  validation accuracy:		27.39 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.236776
  validation loss:		2.174445
  validation accuracy:		27.28 %
Epoch 71 of 2000 took 0.097s
  training loss:		2.230740
  validation loss:		2.170711
  validation accuracy:		27.17 %
Epoch 72 of 2000 took 0.097s
  training loss:		2.227015
  validation loss:		2.160720
  validation accuracy:		27.61 %
Epoch 73 of 2000 took 0.097s
  training loss:		2.218695
  validation loss:		2.157939
  validation accuracy:		25.54 %
Epoch 74 of 2000 took 0.097s
  training loss:		2.213687
  validation loss:		2.153343
  validation accuracy:		27.39 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.205906
  validation loss:		2.135502
  validation accuracy:		28.59 %
Epoch 76 of 2000 took 0.097s
  training loss:		2.196472
  validation loss:		2.127237
  validation accuracy:		26.96 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.185287
  validation loss:		2.119294
  validation accuracy:		25.54 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.175614
  validation loss:		2.106381
  validation accuracy:		26.85 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.164823
  validation loss:		2.085116
  validation accuracy:		26.09 %
Epoch 80 of 2000 took 0.097s
  training loss:		2.149130
  validation loss:		2.073127
  validation accuracy:		29.02 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.133317
  validation loss:		2.052954
  validation accuracy:		30.98 %
Epoch 82 of 2000 took 0.097s
  training loss:		2.118162
  validation loss:		2.038080
  validation accuracy:		30.22 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.098594
  validation loss:		2.013039
  validation accuracy:		32.61 %
Epoch 84 of 2000 took 0.097s
  training loss:		2.079195
  validation loss:		1.996782
  validation accuracy:		31.74 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.055049
  validation loss:		1.965418
  validation accuracy:		32.07 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.032016
  validation loss:		1.934116
  validation accuracy:		33.59 %
Epoch 87 of 2000 took 0.097s
  training loss:		2.009392
  validation loss:		1.915317
  validation accuracy:		32.17 %
Epoch 88 of 2000 took 0.098s
  training loss:		1.986920
  validation loss:		1.892205
  validation accuracy:		32.61 %
Epoch 89 of 2000 took 0.097s
  training loss:		1.961477
  validation loss:		1.861016
  validation accuracy:		35.76 %
Epoch 90 of 2000 took 0.097s
  training loss:		1.933879
  validation loss:		1.833960
  validation accuracy:		36.20 %
Epoch 91 of 2000 took 0.097s
  training loss:		1.912260
  validation loss:		1.817240
  validation accuracy:		37.17 %
Epoch 92 of 2000 took 0.097s
  training loss:		1.891156
  validation loss:		1.792232
  validation accuracy:		38.15 %
Epoch 93 of 2000 took 0.097s
  training loss:		1.867170
  validation loss:		1.767195
  validation accuracy:		37.28 %
Epoch 94 of 2000 took 0.097s
  training loss:		1.842515
  validation loss:		1.744639
  validation accuracy:		39.24 %
Epoch 95 of 2000 took 0.097s
  training loss:		1.827919
  validation loss:		1.737586
  validation accuracy:		40.87 %
Epoch 96 of 2000 took 0.100s
  training loss:		1.808865
  validation loss:		1.708078
  validation accuracy:		39.57 %
Epoch 97 of 2000 took 0.097s
  training loss:		1.786679
  validation loss:		1.693811
  validation accuracy:		39.02 %
Epoch 98 of 2000 took 0.097s
  training loss:		1.776702
  validation loss:		1.680943
  validation accuracy:		40.33 %
Epoch 99 of 2000 took 0.097s
  training loss:		1.759478
  validation loss:		1.662617
  validation accuracy:		39.78 %
Epoch 100 of 2000 took 0.097s
  training loss:		1.735768
  validation loss:		1.650986
  validation accuracy:		39.67 %
Epoch 101 of 2000 took 0.097s
  training loss:		1.733994
  validation loss:		1.627837
  validation accuracy:		40.33 %
Epoch 102 of 2000 took 0.097s
  training loss:		1.709086
  validation loss:		1.613907
  validation accuracy:		41.85 %
Epoch 103 of 2000 took 0.097s
  training loss:		1.692884
  validation loss:		1.604985
  validation accuracy:		41.74 %
Epoch 104 of 2000 took 0.097s
  training loss:		1.680524
  validation loss:		1.596325
  validation accuracy:		40.22 %
Epoch 105 of 2000 took 0.097s
  training loss:		1.673259
  validation loss:		1.585725
  validation accuracy:		43.91 %
Epoch 106 of 2000 took 0.097s
  training loss:		1.661110
  validation loss:		1.576525
  validation accuracy:		39.67 %
Epoch 107 of 2000 took 0.097s
  training loss:		1.652012
  validation loss:		1.554973
  validation accuracy:		41.74 %
Epoch 108 of 2000 took 0.097s
  training loss:		1.640296
  validation loss:		1.552838
  validation accuracy:		42.61 %
Epoch 109 of 2000 took 0.097s
  training loss:		1.626676
  validation loss:		1.539699
  validation accuracy:		42.17 %
Epoch 110 of 2000 took 0.097s
  training loss:		1.628346
  validation loss:		1.535310
  validation accuracy:		41.74 %
Epoch 111 of 2000 took 0.097s
  training loss:		1.611342
  validation loss:		1.526070
  validation accuracy:		42.93 %
Epoch 112 of 2000 took 0.097s
  training loss:		1.605553
  validation loss:		1.521738
  validation accuracy:		42.17 %
Epoch 113 of 2000 took 0.097s
  training loss:		1.599963
  validation loss:		1.526658
  validation accuracy:		42.83 %
Epoch 114 of 2000 took 0.097s
  training loss:		1.586901
  validation loss:		1.501972
  validation accuracy:		44.57 %
Epoch 115 of 2000 took 0.097s
  training loss:		1.574682
  validation loss:		1.506908
  validation accuracy:		45.87 %
Epoch 116 of 2000 took 0.097s
  training loss:		1.567129
  validation loss:		1.493003
  validation accuracy:		44.02 %
Epoch 117 of 2000 took 0.097s
  training loss:		1.562753
  validation loss:		1.488286
  validation accuracy:		45.00 %
Epoch 118 of 2000 took 0.097s
  training loss:		1.568081
  validation loss:		1.478015
  validation accuracy:		42.83 %
Epoch 119 of 2000 took 0.098s
  training loss:		1.566668
  validation loss:		1.480866
  validation accuracy:		44.67 %
Epoch 120 of 2000 took 0.097s
  training loss:		1.548921
  validation loss:		1.487856
  validation accuracy:		44.24 %
Epoch 121 of 2000 took 0.097s
  training loss:		1.541533
  validation loss:		1.467749
  validation accuracy:		45.22 %
Epoch 122 of 2000 took 0.097s
  training loss:		1.547128
  validation loss:		1.462124
  validation accuracy:		44.67 %
Epoch 123 of 2000 took 0.097s
  training loss:		1.554939
  validation loss:		1.478914
  validation accuracy:		43.80 %
Epoch 124 of 2000 took 0.097s
  training loss:		1.532475
  validation loss:		1.499829
  validation accuracy:		42.39 %
Epoch 125 of 2000 took 0.097s
  training loss:		1.530810
  validation loss:		1.453449
  validation accuracy:		44.24 %
Epoch 126 of 2000 took 0.097s
  training loss:		1.520654
  validation loss:		1.448811
  validation accuracy:		44.78 %
Epoch 127 of 2000 took 0.097s
  training loss:		1.539736
  validation loss:		1.542158
  validation accuracy:		41.41 %
Epoch 128 of 2000 took 0.097s
  training loss:		1.564341
  validation loss:		1.446734
  validation accuracy:		46.20 %
Epoch 129 of 2000 took 0.097s
  training loss:		1.508840
  validation loss:		1.448882
  validation accuracy:		44.13 %
Epoch 130 of 2000 took 0.097s
  training loss:		1.509760
  validation loss:		1.433788
  validation accuracy:		46.41 %
Epoch 131 of 2000 took 0.097s
  training loss:		1.571614
  validation loss:		1.467270
  validation accuracy:		42.83 %
Epoch 132 of 2000 took 0.097s
  training loss:		1.507071
  validation loss:		1.433509
  validation accuracy:		43.59 %
Epoch 133 of 2000 took 0.097s
  training loss:		1.492619
  validation loss:		1.445528
  validation accuracy:		46.09 %
Epoch 134 of 2000 took 0.097s
  training loss:		1.518459
  validation loss:		1.563586
  validation accuracy:		39.13 %
Epoch 135 of 2000 took 0.097s
  training loss:		1.585105
  validation loss:		1.490415
  validation accuracy:		40.22 %
Epoch 136 of 2000 took 0.097s
  training loss:		1.516911
  validation loss:		1.431930
  validation accuracy:		46.52 %
Epoch 137 of 2000 took 0.097s
  training loss:		1.605938
  validation loss:		1.513689
  validation accuracy:		42.17 %
Epoch 138 of 2000 took 0.097s
  training loss:		1.524342
  validation loss:		1.499097
  validation accuracy:		42.93 %
Epoch 139 of 2000 took 0.097s
  training loss:		1.535189
  validation loss:		1.450394
  validation accuracy:		45.43 %
Epoch 140 of 2000 took 0.097s
  training loss:		1.492117
  validation loss:		1.414476
  validation accuracy:		43.37 %
Epoch 141 of 2000 took 0.097s
  training loss:		1.497556
  validation loss:		1.424148
  validation accuracy:		45.43 %
Epoch 142 of 2000 took 0.097s
  training loss:		1.513843
  validation loss:		1.461356
  validation accuracy:		44.35 %
Epoch 143 of 2000 took 0.097s
  training loss:		1.490698
  validation loss:		1.419967
  validation accuracy:		45.54 %
Epoch 144 of 2000 took 0.097s
  training loss:		1.493923
  validation loss:		1.458580
  validation accuracy:		43.48 %
Epoch 145 of 2000 took 0.097s
  training loss:		1.555822
  validation loss:		1.491845
  validation accuracy:		43.80 %
Epoch 146 of 2000 took 0.097s
  training loss:		1.478324
  validation loss:		1.450759
  validation accuracy:		45.76 %
Epoch 147 of 2000 took 0.097s
  training loss:		1.477893
  validation loss:		1.417204
  validation accuracy:		45.11 %
Epoch 148 of 2000 took 0.097s
  training loss:		1.477081
  validation loss:		1.396714
  validation accuracy:		46.30 %
Epoch 149 of 2000 took 0.097s
  training loss:		1.470697
  validation loss:		1.415616
  validation accuracy:		46.85 %
Epoch 150 of 2000 took 0.098s
  training loss:		1.505070
  validation loss:		1.557304
  validation accuracy:		39.46 %
Epoch 151 of 2000 took 0.097s
  training loss:		1.540193
  validation loss:		1.411303
  validation accuracy:		45.98 %
Epoch 152 of 2000 took 0.097s
  training loss:		1.481130
  validation loss:		1.488728
  validation accuracy:		42.72 %
Epoch 153 of 2000 took 0.097s
  training loss:		1.497823
  validation loss:		1.399089
  validation accuracy:		48.15 %
Epoch 154 of 2000 took 0.097s
  training loss:		1.458283
  validation loss:		1.388943
  validation accuracy:		48.26 %
Epoch 155 of 2000 took 0.097s
  training loss:		1.502403
  validation loss:		1.419820
  validation accuracy:		47.50 %
Epoch 156 of 2000 took 0.097s
  training loss:		1.480158
  validation loss:		1.501813
  validation accuracy:		43.26 %
Epoch 157 of 2000 took 0.097s
  training loss:		1.524931
  validation loss:		1.397736
  validation accuracy:		46.30 %
Epoch 158 of 2000 took 0.097s
  training loss:		1.443816
  validation loss:		1.378694
  validation accuracy:		50.00 %
Epoch 159 of 2000 took 0.097s
  training loss:		1.445105
  validation loss:		1.389568
  validation accuracy:		47.39 %
Epoch 160 of 2000 took 0.097s
  training loss:		1.445420
  validation loss:		1.379507
  validation accuracy:		48.70 %
Epoch 161 of 2000 took 0.097s
  training loss:		1.449963
  validation loss:		1.410188
  validation accuracy:		46.20 %
Epoch 162 of 2000 took 0.097s
  training loss:		1.478189
  validation loss:		1.409217
  validation accuracy:		47.61 %
Epoch 163 of 2000 took 0.097s
  training loss:		1.446406
  validation loss:		1.379123
  validation accuracy:		50.54 %
Epoch 164 of 2000 took 0.097s
  training loss:		1.432674
  validation loss:		1.369561
  validation accuracy:		50.22 %
Epoch 165 of 2000 took 0.097s
  training loss:		1.531820
  validation loss:		1.531991
  validation accuracy:		42.07 %
Epoch 166 of 2000 took 0.097s
  training loss:		1.491315
  validation loss:		1.371231
  validation accuracy:		51.74 %
Epoch 167 of 2000 took 0.097s
  training loss:		1.481085
  validation loss:		1.366395
  validation accuracy:		53.59 %
Epoch 168 of 2000 took 0.097s
  training loss:		1.430683
  validation loss:		1.387894
  validation accuracy:		50.00 %
Epoch 169 of 2000 took 0.097s
  training loss:		1.444024
  validation loss:		1.369078
  validation accuracy:		51.41 %
Epoch 170 of 2000 took 0.097s
  training loss:		1.456779
  validation loss:		1.362199
  validation accuracy:		52.61 %
Epoch 171 of 2000 took 0.097s
  training loss:		1.440175
  validation loss:		1.389755
  validation accuracy:		53.80 %
Epoch 172 of 2000 took 0.097s
  training loss:		1.435936
  validation loss:		1.352121
  validation accuracy:		56.20 %
Epoch 173 of 2000 took 0.097s
  training loss:		1.424963
  validation loss:		1.358683
  validation accuracy:		51.52 %
Epoch 174 of 2000 took 0.097s
  training loss:		1.416743
  validation loss:		1.343244
  validation accuracy:		55.33 %
Epoch 175 of 2000 took 0.097s
  training loss:		1.416910
  validation loss:		1.342286
  validation accuracy:		56.85 %
Epoch 176 of 2000 took 0.097s
  training loss:		1.422256
  validation loss:		1.363269
  validation accuracy:		53.48 %
Epoch 177 of 2000 took 0.097s
  training loss:		1.445137
  validation loss:		1.360842
  validation accuracy:		50.98 %
Epoch 178 of 2000 took 0.097s
  training loss:		1.403997
  validation loss:		1.330542
  validation accuracy:		53.26 %
Epoch 179 of 2000 took 0.097s
  training loss:		1.429114
  validation loss:		1.327952
  validation accuracy:		56.30 %
Epoch 180 of 2000 took 0.097s
  training loss:		1.391511
  validation loss:		1.335276
  validation accuracy:		54.89 %
Epoch 181 of 2000 took 0.102s
  training loss:		1.381652
  validation loss:		1.323440
  validation accuracy:		52.83 %
Epoch 182 of 2000 took 0.097s
  training loss:		1.381140
  validation loss:		1.319293
  validation accuracy:		53.48 %
Epoch 183 of 2000 took 0.097s
  training loss:		1.383510
  validation loss:		1.315931
  validation accuracy:		57.17 %
Epoch 184 of 2000 took 0.097s
  training loss:		1.468591
  validation loss:		1.533330
  validation accuracy:		44.89 %
Epoch 185 of 2000 took 0.097s
  training loss:		1.428076
  validation loss:		1.298186
  validation accuracy:		58.59 %
Epoch 186 of 2000 took 0.097s
  training loss:		1.371485
  validation loss:		1.301815
  validation accuracy:		55.65 %
Epoch 187 of 2000 took 0.097s
  training loss:		1.357318
  validation loss:		1.294733
  validation accuracy:		57.83 %
Epoch 188 of 2000 took 0.097s
  training loss:		1.355849
  validation loss:		1.276051
  validation accuracy:		57.28 %
Epoch 189 of 2000 took 0.097s
  training loss:		1.343362
  validation loss:		1.275957
  validation accuracy:		58.37 %
Epoch 190 of 2000 took 0.097s
  training loss:		1.339410
  validation loss:		1.253034
  validation accuracy:		60.33 %
Epoch 191 of 2000 took 0.097s
  training loss:		1.315867
  validation loss:		1.249456
  validation accuracy:		61.63 %
Epoch 192 of 2000 took 0.097s
  training loss:		1.341347
  validation loss:		1.285479
  validation accuracy:		58.80 %
Epoch 193 of 2000 took 0.097s
  training loss:		1.311480
  validation loss:		1.247945
  validation accuracy:		60.54 %
Epoch 194 of 2000 took 0.097s
  training loss:		1.305315
  validation loss:		1.211576
  validation accuracy:		62.83 %
Epoch 195 of 2000 took 0.097s
  training loss:		1.287340
  validation loss:		1.264419
  validation accuracy:		60.43 %
Epoch 196 of 2000 took 0.097s
  training loss:		1.291222
  validation loss:		1.183028
  validation accuracy:		63.70 %
Epoch 197 of 2000 took 0.097s
  training loss:		1.244131
  validation loss:		1.161954
  validation accuracy:		64.57 %
Epoch 198 of 2000 took 0.097s
  training loss:		1.245813
  validation loss:		1.213110
  validation accuracy:		64.35 %
Epoch 199 of 2000 took 0.097s
  training loss:		1.229329
  validation loss:		1.189401
  validation accuracy:		64.89 %
Epoch 200 of 2000 took 0.097s
  training loss:		1.258516
  validation loss:		1.110590
  validation accuracy:		66.20 %
Epoch 201 of 2000 took 0.097s
  training loss:		1.189628
  validation loss:		1.121649
  validation accuracy:		62.39 %
Epoch 202 of 2000 took 0.097s
  training loss:		1.181767
  validation loss:		1.089650
  validation accuracy:		64.67 %
Epoch 203 of 2000 took 0.097s
  training loss:		1.184462
  validation loss:		1.066549
  validation accuracy:		66.63 %
Epoch 204 of 2000 took 0.097s
  training loss:		1.130860
  validation loss:		1.045825
  validation accuracy:		67.07 %
Epoch 205 of 2000 took 0.097s
  training loss:		1.139142
  validation loss:		1.113341
  validation accuracy:		65.65 %
Epoch 206 of 2000 took 0.097s
  training loss:		1.156358
  validation loss:		1.027840
  validation accuracy:		65.87 %
Epoch 207 of 2000 took 0.097s
  training loss:		1.094081
  validation loss:		1.027337
  validation accuracy:		64.89 %
Epoch 208 of 2000 took 0.097s
  training loss:		1.084061
  validation loss:		1.016501
  validation accuracy:		65.22 %
Epoch 209 of 2000 took 0.097s
  training loss:		1.077206
  validation loss:		0.974532
  validation accuracy:		68.04 %
Epoch 210 of 2000 took 0.097s
  training loss:		1.048808
  validation loss:		0.964701
  validation accuracy:		67.93 %
Epoch 211 of 2000 took 0.097s
  training loss:		1.027512
  validation loss:		0.956790
  validation accuracy:		68.37 %
Epoch 212 of 2000 took 0.098s
  training loss:		1.021836
  validation loss:		0.946088
  validation accuracy:		68.15 %
Epoch 213 of 2000 took 0.097s
  training loss:		1.005287
  validation loss:		0.945229
  validation accuracy:		67.07 %
Epoch 214 of 2000 took 0.097s
  training loss:		1.002286
  validation loss:		0.918462
  validation accuracy:		68.37 %
Epoch 215 of 2000 took 0.097s
  training loss:		0.990172
  validation loss:		0.915559
  validation accuracy:		67.93 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.971491
  validation loss:		0.905993
  validation accuracy:		68.15 %
Epoch 217 of 2000 took 0.097s
  training loss:		0.960167
  validation loss:		0.892062
  validation accuracy:		69.24 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.978111
  validation loss:		0.880832
  validation accuracy:		69.35 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.949850
  validation loss:		0.876752
  validation accuracy:		70.11 %
Epoch 220 of 2000 took 0.097s
  training loss:		0.932363
  validation loss:		0.854693
  validation accuracy:		70.76 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.919716
  validation loss:		0.851348
  validation accuracy:		71.52 %
Epoch 222 of 2000 took 0.097s
  training loss:		0.908775
  validation loss:		0.836620
  validation accuracy:		71.09 %
Epoch 223 of 2000 took 0.097s
  training loss:		0.910129
  validation loss:		0.855093
  validation accuracy:		69.89 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.883601
  validation loss:		0.816321
  validation accuracy:		72.61 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.880327
  validation loss:		0.816976
  validation accuracy:		71.96 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.868821
  validation loss:		0.806166
  validation accuracy:		72.17 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.857328
  validation loss:		0.805010
  validation accuracy:		73.80 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.850409
  validation loss:		0.794880
  validation accuracy:		73.48 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.850811
  validation loss:		0.787063
  validation accuracy:		72.93 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.825477
  validation loss:		0.760647
  validation accuracy:		74.67 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.832759
  validation loss:		0.760815
  validation accuracy:		74.67 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.808985
  validation loss:		0.759304
  validation accuracy:		74.57 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.822558
  validation loss:		0.747971
  validation accuracy:		75.00 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.784222
  validation loss:		0.741705
  validation accuracy:		75.33 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.803596
  validation loss:		0.763209
  validation accuracy:		74.78 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.779175
  validation loss:		0.728328
  validation accuracy:		76.41 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.766410
  validation loss:		0.715394
  validation accuracy:		76.20 %
Epoch 238 of 2000 took 0.098s
  training loss:		0.766666
  validation loss:		0.710705
  validation accuracy:		77.28 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.751299
  validation loss:		0.692865
  validation accuracy:		77.28 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.761079
  validation loss:		0.725301
  validation accuracy:		75.11 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.742022
  validation loss:		0.686707
  validation accuracy:		77.72 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.732791
  validation loss:		0.681196
  validation accuracy:		78.26 %
Epoch 243 of 2000 took 0.098s
  training loss:		0.723775
  validation loss:		0.674306
  validation accuracy:		78.59 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.728787
  validation loss:		0.678193
  validation accuracy:		77.28 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.710461
  validation loss:		0.657035
  validation accuracy:		78.59 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.703579
  validation loss:		0.661480
  validation accuracy:		79.46 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.704474
  validation loss:		0.648899
  validation accuracy:		79.46 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.693672
  validation loss:		0.643459
  validation accuracy:		79.89 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.707721
  validation loss:		0.650150
  validation accuracy:		79.02 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.692880
  validation loss:		0.648430
  validation accuracy:		79.13 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.698615
  validation loss:		0.647580
  validation accuracy:		79.57 %
Epoch 252 of 2000 took 0.097s
  training loss:		0.671067
  validation loss:		0.636962
  validation accuracy:		79.46 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.686161
  validation loss:		0.719660
  validation accuracy:		75.87 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.662326
  validation loss:		0.638218
  validation accuracy:		79.78 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.674688
  validation loss:		0.624500
  validation accuracy:		79.89 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.684081
  validation loss:		0.627243
  validation accuracy:		80.22 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.654758
  validation loss:		0.615358
  validation accuracy:		79.89 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.661052
  validation loss:		0.618376
  validation accuracy:		80.11 %
Epoch 259 of 2000 took 0.098s
  training loss:		0.657226
  validation loss:		0.614146
  validation accuracy:		80.00 %
Epoch 260 of 2000 took 0.097s
  training loss:		0.648792
  validation loss:		0.611733
  validation accuracy:		80.11 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.654278
  validation loss:		0.650240
  validation accuracy:		78.26 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.657577
  validation loss:		0.633103
  validation accuracy:		80.11 %
Epoch 263 of 2000 took 0.097s
  training loss:		0.673957
  validation loss:		0.645583
  validation accuracy:		78.15 %
Epoch 264 of 2000 took 0.097s
  training loss:		0.696187
  validation loss:		0.616500
  validation accuracy:		78.80 %
Epoch 265 of 2000 took 0.097s
  training loss:		0.653292
  validation loss:		0.663765
  validation accuracy:		77.83 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.737157
  validation loss:		0.601633
  validation accuracy:		80.65 %
Epoch 267 of 2000 took 0.097s
  training loss:		0.642396
  validation loss:		0.651202
  validation accuracy:		78.37 %
Epoch 268 of 2000 took 0.097s
  training loss:		0.630015
  validation loss:		0.608805
  validation accuracy:		79.35 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.637340
  validation loss:		0.631441
  validation accuracy:		80.76 %
Epoch 270 of 2000 took 0.097s
  training loss:		0.646341
  validation loss:		0.602746
  validation accuracy:		79.78 %
Epoch 271 of 2000 took 0.097s
  training loss:		0.670230
  validation loss:		0.645360
  validation accuracy:		77.93 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.632652
  validation loss:		0.599154
  validation accuracy:		80.54 %
Epoch 273 of 2000 took 0.100s
  training loss:		0.693314
  validation loss:		0.596623
  validation accuracy:		79.57 %
Epoch 274 of 2000 took 0.100s
  training loss:		0.643164
  validation loss:		0.592767
  validation accuracy:		80.43 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.626657
  validation loss:		0.673706
  validation accuracy:		78.15 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.653240
  validation loss:		0.603495
  validation accuracy:		80.11 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.637673
  validation loss:		0.589834
  validation accuracy:		80.76 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.664603
  validation loss:		0.741031
  validation accuracy:		74.46 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.624912
  validation loss:		0.588606
  validation accuracy:		80.54 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.615518
  validation loss:		0.582460
  validation accuracy:		80.54 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.804427
  validation loss:		1.437379
  validation accuracy:		53.04 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.804696
  validation loss:		0.610851
  validation accuracy:		80.33 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.626161
  validation loss:		0.618878
  validation accuracy:		80.11 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.625810
  validation loss:		0.581494
  validation accuracy:		80.76 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.616695
  validation loss:		0.588364
  validation accuracy:		80.76 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.636121
  validation loss:		0.592776
  validation accuracy:		80.22 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.616108
  validation loss:		0.617000
  validation accuracy:		79.57 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.608266
  validation loss:		0.582878
  validation accuracy:		80.87 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.614113
  validation loss:		0.605792
  validation accuracy:		80.00 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.614396
  validation loss:		0.589974
  validation accuracy:		80.76 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.607562
  validation loss:		0.579696
  validation accuracy:		80.87 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.630925
  validation loss:		0.582926
  validation accuracy:		81.52 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.603444
  validation loss:		0.594590
  validation accuracy:		80.54 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.648048
  validation loss:		0.778498
  validation accuracy:		73.70 %
Epoch 295 of 2000 took 0.097s
  training loss:		0.685952
  validation loss:		0.636225
  validation accuracy:		78.91 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.622162
  validation loss:		0.620909
  validation accuracy:		79.78 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.615780
  validation loss:		0.637779
  validation accuracy:		79.24 %
Epoch 298 of 2000 took 0.097s
  training loss:		0.625103
  validation loss:		0.588048
  validation accuracy:		80.33 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.625105
  validation loss:		0.594658
  validation accuracy:		80.33 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.604576
  validation loss:		0.580066
  validation accuracy:		80.54 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.606055
  validation loss:		0.609770
  validation accuracy:		80.11 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.601426
  validation loss:		0.619798
  validation accuracy:		78.80 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.604454
  validation loss:		0.575595
  validation accuracy:		80.54 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.608248
  validation loss:		0.572701
  validation accuracy:		81.41 %
Epoch 305 of 2000 took 0.098s
  training loss:		0.612004
  validation loss:		0.570372
  validation accuracy:		81.63 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.609511
  validation loss:		0.592380
  validation accuracy:		80.11 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.607943
  validation loss:		0.568210
  validation accuracy:		81.30 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.634058
  validation loss:		0.573735
  validation accuracy:		81.74 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.591983
  validation loss:		0.572953
  validation accuracy:		81.20 %
Epoch 310 of 2000 took 0.098s
  training loss:		0.579899
  validation loss:		0.568296
  validation accuracy:		81.85 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.627704
  validation loss:		0.617830
  validation accuracy:		78.91 %
Epoch 312 of 2000 took 0.097s
  training loss:		0.588916
  validation loss:		0.628997
  validation accuracy:		78.26 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.635506
  validation loss:		0.611681
  validation accuracy:		79.46 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.634527
  validation loss:		0.570676
  validation accuracy:		80.98 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.604765
  validation loss:		0.581063
  validation accuracy:		80.43 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.610849
  validation loss:		0.575725
  validation accuracy:		80.98 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.588354
  validation loss:		0.577887
  validation accuracy:		81.09 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.597020
  validation loss:		0.585248
  validation accuracy:		80.54 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.588401
  validation loss:		0.564470
  validation accuracy:		81.74 %
Epoch 320 of 2000 took 0.097s
  training loss:		0.604578
  validation loss:		0.588470
  validation accuracy:		81.41 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.625608
  validation loss:		0.555251
  validation accuracy:		82.72 %
Epoch 322 of 2000 took 0.097s
  training loss:		0.583711
  validation loss:		0.562591
  validation accuracy:		81.96 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.625489
  validation loss:		0.592199
  validation accuracy:		80.00 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.575986
  validation loss:		0.565498
  validation accuracy:		81.96 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.575613
  validation loss:		0.563039
  validation accuracy:		81.09 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.577447
  validation loss:		0.577835
  validation accuracy:		80.76 %
Epoch 327 of 2000 took 0.097s
  training loss:		0.575938
  validation loss:		0.676694
  validation accuracy:		76.52 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.615180
  validation loss:		0.560475
  validation accuracy:		81.63 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.569286
  validation loss:		0.555240
  validation accuracy:		82.83 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.581610
  validation loss:		0.572302
  validation accuracy:		82.07 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.598065
  validation loss:		0.578923
  validation accuracy:		80.54 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.583391
  validation loss:		0.550979
  validation accuracy:		81.96 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.566288
  validation loss:		0.545386
  validation accuracy:		82.93 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.573149
  validation loss:		0.548734
  validation accuracy:		81.85 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.577705
  validation loss:		0.546391
  validation accuracy:		82.93 %
Epoch 336 of 2000 took 0.098s
  training loss:		0.568672
  validation loss:		0.614932
  validation accuracy:		79.02 %
Epoch 337 of 2000 took 0.097s
  training loss:		0.575040
  validation loss:		0.576255
  validation accuracy:		80.65 %
Epoch 338 of 2000 took 0.097s
  training loss:		0.569645
  validation loss:		0.560047
  validation accuracy:		80.87 %
Epoch 339 of 2000 took 0.097s
  training loss:		0.565427
  validation loss:		0.552202
  validation accuracy:		81.41 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.558103
  validation loss:		0.548237
  validation accuracy:		82.17 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.549417
  validation loss:		0.536211
  validation accuracy:		82.93 %
Epoch 342 of 2000 took 0.097s
  training loss:		0.556566
  validation loss:		0.549669
  validation accuracy:		81.52 %
Epoch 343 of 2000 took 0.097s
  training loss:		0.563381
  validation loss:		0.545966
  validation accuracy:		82.07 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.562286
  validation loss:		0.534267
  validation accuracy:		83.59 %
Epoch 345 of 2000 took 0.097s
  training loss:		0.546337
  validation loss:		0.527291
  validation accuracy:		83.48 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.548325
  validation loss:		0.531151
  validation accuracy:		83.26 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.571846
  validation loss:		0.549071
  validation accuracy:		81.41 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.541297
  validation loss:		0.530393
  validation accuracy:		83.15 %
Epoch 349 of 2000 took 0.097s
  training loss:		0.548784
  validation loss:		0.551349
  validation accuracy:		81.30 %
Epoch 350 of 2000 took 0.097s
  training loss:		0.565536
  validation loss:		0.526673
  validation accuracy:		82.83 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.566813
  validation loss:		0.533639
  validation accuracy:		82.28 %
Epoch 352 of 2000 took 0.097s
  training loss:		0.535479
  validation loss:		0.554469
  validation accuracy:		82.07 %
Epoch 353 of 2000 took 0.097s
  training loss:		0.536772
  validation loss:		0.551643
  validation accuracy:		82.28 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.536749
  validation loss:		0.532859
  validation accuracy:		82.50 %
Epoch 355 of 2000 took 0.097s
  training loss:		0.546499
  validation loss:		0.591324
  validation accuracy:		79.46 %
Epoch 356 of 2000 took 0.097s
  training loss:		0.569757
  validation loss:		0.519240
  validation accuracy:		83.04 %
Epoch 357 of 2000 took 0.097s
  training loss:		0.534129
  validation loss:		0.518693
  validation accuracy:		83.15 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.536589
  validation loss:		0.543299
  validation accuracy:		81.74 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.543648
  validation loss:		0.521492
  validation accuracy:		83.26 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.533786
  validation loss:		0.508707
  validation accuracy:		83.37 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.524798
  validation loss:		0.516025
  validation accuracy:		83.15 %
Epoch 362 of 2000 took 0.097s
  training loss:		0.531484
  validation loss:		0.505602
  validation accuracy:		83.91 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.518827
  validation loss:		0.508730
  validation accuracy:		83.04 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.515470
  validation loss:		0.530124
  validation accuracy:		82.83 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.510552
  validation loss:		0.515184
  validation accuracy:		83.26 %
Epoch 366 of 2000 took 0.097s
  training loss:		0.527146
  validation loss:		0.512492
  validation accuracy:		82.83 %
Epoch 367 of 2000 took 0.098s
  training loss:		0.501633
  validation loss:		0.495742
  validation accuracy:		83.70 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.514645
  validation loss:		0.503383
  validation accuracy:		83.91 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.502754
  validation loss:		0.504114
  validation accuracy:		83.48 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.508705
  validation loss:		0.499422
  validation accuracy:		84.24 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.511715
  validation loss:		0.500304
  validation accuracy:		84.02 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.495855
  validation loss:		0.508609
  validation accuracy:		83.70 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.504698
  validation loss:		0.494828
  validation accuracy:		83.70 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.499588
  validation loss:		0.499697
  validation accuracy:		83.48 %
Epoch 375 of 2000 took 0.101s
  training loss:		0.494093
  validation loss:		0.488146
  validation accuracy:		84.67 %
Epoch 376 of 2000 took 0.098s
  training loss:		0.485767
  validation loss:		0.502250
  validation accuracy:		84.13 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.487579
  validation loss:		0.489429
  validation accuracy:		84.46 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.499718
  validation loss:		0.486086
  validation accuracy:		84.24 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.487146
  validation loss:		0.504673
  validation accuracy:		83.91 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.490696
  validation loss:		0.519759
  validation accuracy:		82.83 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.485193
  validation loss:		0.485902
  validation accuracy:		84.67 %
Epoch 382 of 2000 took 0.097s
  training loss:		0.485633
  validation loss:		0.485133
  validation accuracy:		83.91 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.475384
  validation loss:		0.486626
  validation accuracy:		83.59 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.478947
  validation loss:		0.480709
  validation accuracy:		85.00 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.474089
  validation loss:		0.506239
  validation accuracy:		83.26 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.468943
  validation loss:		0.523904
  validation accuracy:		83.37 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.487867
  validation loss:		0.523850
  validation accuracy:		83.59 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.476355
  validation loss:		0.482548
  validation accuracy:		85.22 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.468170
  validation loss:		0.477332
  validation accuracy:		85.22 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.466861
  validation loss:		0.484172
  validation accuracy:		83.80 %
Epoch 391 of 2000 took 0.097s
  training loss:		0.466298
  validation loss:		0.487220
  validation accuracy:		84.13 %
Epoch 392 of 2000 took 0.097s
  training loss:		0.464952
  validation loss:		0.479928
  validation accuracy:		85.43 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.458365
  validation loss:		0.472021
  validation accuracy:		85.33 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.457986
  validation loss:		0.480242
  validation accuracy:		85.22 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.459563
  validation loss:		0.487366
  validation accuracy:		84.67 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.452912
  validation loss:		0.483198
  validation accuracy:		84.57 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.461369
  validation loss:		0.469044
  validation accuracy:		85.65 %
Epoch 398 of 2000 took 0.098s
  training loss:		0.451601
  validation loss:		0.499534
  validation accuracy:		84.35 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.462604
  validation loss:		0.484082
  validation accuracy:		84.46 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.447229
  validation loss:		0.481432
  validation accuracy:		84.35 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.454208
  validation loss:		0.471413
  validation accuracy:		84.89 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.439801
  validation loss:		0.466672
  validation accuracy:		86.09 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.449621
  validation loss:		0.476618
  validation accuracy:		84.67 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.455065
  validation loss:		0.464813
  validation accuracy:		85.54 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.457563
  validation loss:		0.467676
  validation accuracy:		85.11 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.442935
  validation loss:		0.479423
  validation accuracy:		85.22 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.437458
  validation loss:		0.473003
  validation accuracy:		85.11 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.468340
  validation loss:		0.462167
  validation accuracy:		85.87 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.442983
  validation loss:		0.468104
  validation accuracy:		85.65 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.433687
  validation loss:		0.471880
  validation accuracy:		84.67 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.433902
  validation loss:		0.470125
  validation accuracy:		85.00 %
Epoch 412 of 2000 took 0.100s
  training loss:		0.444319
  validation loss:		0.461282
  validation accuracy:		85.65 %
Epoch 413 of 2000 took 0.100s
  training loss:		0.441506
  validation loss:		0.469069
  validation accuracy:		84.57 %
Epoch 414 of 2000 took 0.100s
  training loss:		0.424955
  validation loss:		0.457769
  validation accuracy:		85.98 %
Epoch 415 of 2000 took 0.100s
  training loss:		0.431062
  validation loss:		0.462804
  validation accuracy:		85.65 %
Epoch 416 of 2000 took 0.100s
  training loss:		0.431364
  validation loss:		0.458870
  validation accuracy:		85.43 %
Epoch 417 of 2000 took 0.100s
  training loss:		0.438897
  validation loss:		0.487047
  validation accuracy:		84.24 %
Epoch 418 of 2000 took 0.100s
  training loss:		0.423535
  validation loss:		0.461586
  validation accuracy:		85.33 %
Epoch 419 of 2000 took 0.100s
  training loss:		0.426970
  validation loss:		0.474644
  validation accuracy:		84.35 %
Epoch 420 of 2000 took 0.100s
  training loss:		0.436259
  validation loss:		0.464216
  validation accuracy:		85.76 %
Epoch 421 of 2000 took 0.100s
  training loss:		0.421976
  validation loss:		0.458291
  validation accuracy:		85.98 %
Epoch 422 of 2000 took 0.100s
  training loss:		0.427528
  validation loss:		0.474866
  validation accuracy:		84.35 %
Epoch 423 of 2000 took 0.100s
  training loss:		0.436774
  validation loss:		0.471725
  validation accuracy:		84.46 %
Epoch 424 of 2000 took 0.100s
  training loss:		0.426847
  validation loss:		0.473238
  validation accuracy:		85.76 %
Epoch 425 of 2000 took 0.100s
  training loss:		0.416635
  validation loss:		0.458546
  validation accuracy:		85.33 %
Epoch 426 of 2000 took 0.100s
  training loss:		0.426138
  validation loss:		0.452925
  validation accuracy:		86.30 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.422970
  validation loss:		0.445353
  validation accuracy:		86.63 %
Epoch 428 of 2000 took 0.100s
  training loss:		0.407209
  validation loss:		0.447701
  validation accuracy:		86.30 %
Epoch 429 of 2000 took 0.100s
  training loss:		0.421390
  validation loss:		0.446346
  validation accuracy:		86.30 %
Epoch 430 of 2000 took 0.100s
  training loss:		0.421445
  validation loss:		0.460415
  validation accuracy:		85.65 %
Epoch 431 of 2000 took 0.100s
  training loss:		0.425184
  validation loss:		0.451597
  validation accuracy:		85.98 %
Epoch 432 of 2000 took 0.100s
  training loss:		0.399686
  validation loss:		0.461371
  validation accuracy:		85.11 %
Epoch 433 of 2000 took 0.100s
  training loss:		0.409592
  validation loss:		0.440650
  validation accuracy:		86.74 %
Epoch 434 of 2000 took 0.100s
  training loss:		0.412488
  validation loss:		0.448326
  validation accuracy:		86.52 %
Epoch 435 of 2000 took 0.100s
  training loss:		0.412025
  validation loss:		0.446016
  validation accuracy:		86.41 %
Epoch 436 of 2000 took 0.100s
  training loss:		0.412394
  validation loss:		0.461575
  validation accuracy:		85.00 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.405789
  validation loss:		0.455766
  validation accuracy:		85.54 %
Epoch 438 of 2000 took 0.100s
  training loss:		0.393085
  validation loss:		0.446260
  validation accuracy:		86.52 %
Epoch 439 of 2000 took 0.100s
  training loss:		0.403336
  validation loss:		0.455024
  validation accuracy:		85.54 %
Epoch 440 of 2000 took 0.100s
  training loss:		0.404090
  validation loss:		0.444920
  validation accuracy:		86.74 %
Epoch 441 of 2000 took 0.100s
  training loss:		0.402801
  validation loss:		0.441028
  validation accuracy:		86.52 %
Epoch 442 of 2000 took 0.100s
  training loss:		0.390507
  validation loss:		0.444017
  validation accuracy:		86.41 %
Epoch 443 of 2000 took 0.100s
  training loss:		0.404540
  validation loss:		0.449565
  validation accuracy:		85.22 %
Epoch 444 of 2000 took 0.100s
  training loss:		0.400201
  validation loss:		0.440774
  validation accuracy:		86.41 %
Epoch 445 of 2000 took 0.100s
  training loss:		0.396721
  validation loss:		0.458967
  validation accuracy:		85.87 %
Epoch 446 of 2000 took 0.100s
  training loss:		0.402519
  validation loss:		0.458811
  validation accuracy:		85.33 %
Epoch 447 of 2000 took 0.100s
  training loss:		0.404239
  validation loss:		0.447830
  validation accuracy:		86.09 %
Epoch 448 of 2000 took 0.100s
  training loss:		0.399384
  validation loss:		0.454615
  validation accuracy:		85.43 %
Epoch 449 of 2000 took 0.100s
  training loss:		0.402049
  validation loss:		0.443072
  validation accuracy:		86.63 %
Epoch 450 of 2000 took 0.100s
  training loss:		0.391815
  validation loss:		0.445604
  validation accuracy:		86.30 %
Epoch 451 of 2000 took 0.100s
  training loss:		0.396636
  validation loss:		0.438533
  validation accuracy:		86.20 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.388395
  validation loss:		0.431792
  validation accuracy:		86.41 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.397972
  validation loss:		0.437625
  validation accuracy:		86.63 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.393246
  validation loss:		0.472258
  validation accuracy:		85.00 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.391347
  validation loss:		0.437116
  validation accuracy:		86.09 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.385354
  validation loss:		0.438228
  validation accuracy:		86.85 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.382743
  validation loss:		0.431135
  validation accuracy:		86.52 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.387718
  validation loss:		0.433333
  validation accuracy:		87.28 %
Epoch 459 of 2000 took 0.098s
  training loss:		0.395486
  validation loss:		0.434970
  validation accuracy:		86.52 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.392785
  validation loss:		0.443067
  validation accuracy:		86.20 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.387912
  validation loss:		0.448170
  validation accuracy:		86.41 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.382652
  validation loss:		0.442005
  validation accuracy:		86.30 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.389766
  validation loss:		0.432850
  validation accuracy:		86.96 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.382983
  validation loss:		0.425848
  validation accuracy:		86.74 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.377353
  validation loss:		0.436729
  validation accuracy:		86.63 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.380332
  validation loss:		0.431168
  validation accuracy:		86.85 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.383225
  validation loss:		0.433383
  validation accuracy:		86.52 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.379579
  validation loss:		0.460347
  validation accuracy:		85.33 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.388882
  validation loss:		0.438396
  validation accuracy:		86.52 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.386810
  validation loss:		0.432942
  validation accuracy:		86.63 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.374246
  validation loss:		0.441673
  validation accuracy:		86.85 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.373874
  validation loss:		0.429563
  validation accuracy:		87.07 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.365321
  validation loss:		0.424933
  validation accuracy:		87.07 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.375166
  validation loss:		0.421411
  validation accuracy:		86.85 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.369028
  validation loss:		0.454293
  validation accuracy:		85.65 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.382014
  validation loss:		0.428674
  validation accuracy:		86.96 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.371927
  validation loss:		0.429459
  validation accuracy:		87.17 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.372823
  validation loss:		0.447466
  validation accuracy:		86.52 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.372144
  validation loss:		0.433336
  validation accuracy:		86.63 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.367059
  validation loss:		0.428331
  validation accuracy:		86.74 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.373645
  validation loss:		0.433453
  validation accuracy:		86.85 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.372511
  validation loss:		0.431809
  validation accuracy:		86.85 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.365549
  validation loss:		0.459138
  validation accuracy:		86.09 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.368089
  validation loss:		0.462502
  validation accuracy:		86.30 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.381657
  validation loss:		0.461173
  validation accuracy:		85.76 %
Epoch 486 of 2000 took 0.098s
  training loss:		0.362375
  validation loss:		0.432611
  validation accuracy:		87.17 %
Epoch 487 of 2000 took 0.099s
  training loss:		0.362263
  validation loss:		0.436931
  validation accuracy:		86.85 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.359375
  validation loss:		0.425571
  validation accuracy:		87.07 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.363702
  validation loss:		0.435767
  validation accuracy:		86.85 %
Epoch 490 of 2000 took 0.098s
  training loss:		0.367128
  validation loss:		0.425558
  validation accuracy:		87.17 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.358997
  validation loss:		0.430810
  validation accuracy:		86.30 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.364602
  validation loss:		0.433616
  validation accuracy:		86.96 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.362889
  validation loss:		0.420433
  validation accuracy:		87.07 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.356548
  validation loss:		0.421830
  validation accuracy:		86.85 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.362532
  validation loss:		0.428140
  validation accuracy:		87.72 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.361644
  validation loss:		0.428454
  validation accuracy:		86.96 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.367416
  validation loss:		0.425634
  validation accuracy:		87.50 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.358111
  validation loss:		0.440070
  validation accuracy:		86.85 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.365152
  validation loss:		0.422047
  validation accuracy:		87.07 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.360283
  validation loss:		0.421294
  validation accuracy:		87.07 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.362504
  validation loss:		0.429799
  validation accuracy:		86.85 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.359333
  validation loss:		0.420292
  validation accuracy:		87.07 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.360055
  validation loss:		0.457850
  validation accuracy:		86.30 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.361529
  validation loss:		0.416064
  validation accuracy:		87.39 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.360416
  validation loss:		0.417544
  validation accuracy:		86.85 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.359925
  validation loss:		0.420337
  validation accuracy:		87.17 %
Epoch 507 of 2000 took 0.097s
  training loss:		0.364328
  validation loss:		0.434936
  validation accuracy:		86.63 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.353183
  validation loss:		0.422782
  validation accuracy:		87.28 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.356674
  validation loss:		0.418787
  validation accuracy:		87.07 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.352772
  validation loss:		0.419685
  validation accuracy:		86.96 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.350646
  validation loss:		0.424855
  validation accuracy:		86.96 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.349391
  validation loss:		0.418039
  validation accuracy:		87.17 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.357258
  validation loss:		0.424466
  validation accuracy:		87.07 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.353943
  validation loss:		0.430012
  validation accuracy:		86.85 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.348962
  validation loss:		0.425213
  validation accuracy:		86.96 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.346357
  validation loss:		0.417942
  validation accuracy:		87.61 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.352422
  validation loss:		0.422671
  validation accuracy:		87.17 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.348146
  validation loss:		0.422919
  validation accuracy:		87.50 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.346754
  validation loss:		0.415215
  validation accuracy:		87.28 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.347704
  validation loss:		0.423540
  validation accuracy:		87.07 %
Epoch 521 of 2000 took 0.098s
  training loss:		0.351334
  validation loss:		0.412635
  validation accuracy:		87.07 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.348007
  validation loss:		0.425279
  validation accuracy:		87.28 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.354601
  validation loss:		0.419493
  validation accuracy:		87.28 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.347061
  validation loss:		0.415488
  validation accuracy:		87.07 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.341737
  validation loss:		0.418619
  validation accuracy:		86.96 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.348977
  validation loss:		0.418072
  validation accuracy:		87.28 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.346209
  validation loss:		0.421337
  validation accuracy:		87.39 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.346122
  validation loss:		0.437275
  validation accuracy:		86.85 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.343598
  validation loss:		0.435415
  validation accuracy:		86.74 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.353143
  validation loss:		0.429593
  validation accuracy:		87.07 %
Epoch 531 of 2000 took 0.098s
  training loss:		0.336306
  validation loss:		0.442689
  validation accuracy:		86.52 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.345337
  validation loss:		0.422954
  validation accuracy:		87.28 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.346602
  validation loss:		0.412605
  validation accuracy:		87.17 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.341936
  validation loss:		0.419319
  validation accuracy:		87.50 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.340016
  validation loss:		0.434199
  validation accuracy:		87.39 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.342202
  validation loss:		0.419883
  validation accuracy:		86.74 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.345977
  validation loss:		0.417453
  validation accuracy:		86.96 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.339455
  validation loss:		0.413361
  validation accuracy:		87.28 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.343473
  validation loss:		0.417192
  validation accuracy:		87.72 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.338916
  validation loss:		0.414873
  validation accuracy:		87.50 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.346354
  validation loss:		0.418740
  validation accuracy:		86.63 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.346474
  validation loss:		0.424587
  validation accuracy:		86.30 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.339439
  validation loss:		0.424982
  validation accuracy:		86.74 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.348027
  validation loss:		0.420578
  validation accuracy:		86.41 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.346529
  validation loss:		0.417920
  validation accuracy:		87.50 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.337835
  validation loss:		0.415997
  validation accuracy:		87.83 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.340077
  validation loss:		0.415824
  validation accuracy:		87.28 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.337691
  validation loss:		0.421373
  validation accuracy:		87.17 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.340908
  validation loss:		0.420316
  validation accuracy:		87.39 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.336966
  validation loss:		0.420986
  validation accuracy:		87.17 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.341337
  validation loss:		0.418789
  validation accuracy:		87.50 %
Epoch 552 of 2000 took 0.098s
  training loss:		0.345984
  validation loss:		0.425879
  validation accuracy:		87.50 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.341948
  validation loss:		0.426289
  validation accuracy:		87.28 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.332080
  validation loss:		0.422064
  validation accuracy:		87.83 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.338261
  validation loss:		0.425129
  validation accuracy:		86.74 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.331849
  validation loss:		0.424726
  validation accuracy:		87.17 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.338485
  validation loss:		0.428578
  validation accuracy:		87.17 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.336857
  validation loss:		0.416406
  validation accuracy:		87.61 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.336540
  validation loss:		0.414540
  validation accuracy:		87.72 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.334567
  validation loss:		0.417034
  validation accuracy:		86.96 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.337148
  validation loss:		0.426837
  validation accuracy:		86.96 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.342506
  validation loss:		0.416015
  validation accuracy:		87.07 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.337617
  validation loss:		0.424320
  validation accuracy:		87.28 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.337629
  validation loss:		0.423698
  validation accuracy:		86.96 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.336629
  validation loss:		0.414448
  validation accuracy:		87.50 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.336952
  validation loss:		0.419791
  validation accuracy:		87.28 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.329480
  validation loss:		0.417933
  validation accuracy:		86.96 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.341326
  validation loss:		0.422147
  validation accuracy:		87.17 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.334505
  validation loss:		0.412499
  validation accuracy:		87.61 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.336665
  validation loss:		0.412824
  validation accuracy:		87.17 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.335919
  validation loss:		0.432313
  validation accuracy:		86.96 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.339063
  validation loss:		0.411517
  validation accuracy:		87.28 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.333305
  validation loss:		0.421231
  validation accuracy:		87.28 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.332225
  validation loss:		0.425812
  validation accuracy:		86.85 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.337360
  validation loss:		0.416562
  validation accuracy:		87.28 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.327270
  validation loss:		0.419696
  validation accuracy:		86.96 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.329302
  validation loss:		0.417565
  validation accuracy:		86.63 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.332915
  validation loss:		0.416674
  validation accuracy:		86.96 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.330225
  validation loss:		0.412643
  validation accuracy:		87.07 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.340427
  validation loss:		0.431094
  validation accuracy:		86.74 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.324593
  validation loss:		0.413377
  validation accuracy:		87.50 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.327623
  validation loss:		0.418314
  validation accuracy:		87.28 %
Epoch 583 of 2000 took 0.099s
  training loss:		0.329547
  validation loss:		0.422099
  validation accuracy:		86.63 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.333066
  validation loss:		0.429875
  validation accuracy:		87.17 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.335299
  validation loss:		0.416541
  validation accuracy:		87.50 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.336820
  validation loss:		0.434796
  validation accuracy:		87.39 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.335180
  validation loss:		0.411660
  validation accuracy:		87.61 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.328263
  validation loss:		0.412859
  validation accuracy:		87.07 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.328203
  validation loss:		0.414775
  validation accuracy:		87.17 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.333995
  validation loss:		0.409887
  validation accuracy:		87.17 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.328460
  validation loss:		0.416689
  validation accuracy:		86.85 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.323244
  validation loss:		0.421005
  validation accuracy:		87.07 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.327877
  validation loss:		0.430430
  validation accuracy:		86.96 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.335155
  validation loss:		0.453518
  validation accuracy:		85.76 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.335665
  validation loss:		0.421983
  validation accuracy:		86.96 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.329479
  validation loss:		0.430263
  validation accuracy:		87.28 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.323686
  validation loss:		0.418578
  validation accuracy:		86.96 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.322811
  validation loss:		0.411163
  validation accuracy:		87.17 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.336410
  validation loss:		0.411959
  validation accuracy:		87.28 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.332234
  validation loss:		0.420860
  validation accuracy:		87.17 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.329003
  validation loss:		0.415905
  validation accuracy:		87.17 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.328078
  validation loss:		0.441065
  validation accuracy:		86.41 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.319554
  validation loss:		0.418095
  validation accuracy:		86.63 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.334097
  validation loss:		0.419287
  validation accuracy:		87.50 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.328799
  validation loss:		0.422289
  validation accuracy:		87.17 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.328356
  validation loss:		0.439047
  validation accuracy:		87.07 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.332173
  validation loss:		0.433513
  validation accuracy:		86.41 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.321161
  validation loss:		0.414836
  validation accuracy:		87.39 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.325457
  validation loss:		0.423846
  validation accuracy:		86.74 %
Epoch 610 of 2000 took 0.100s
  training loss:		0.328898
  validation loss:		0.413473
  validation accuracy:		86.96 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.331612
  validation loss:		0.414092
  validation accuracy:		87.17 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.321861
  validation loss:		0.422796
  validation accuracy:		87.28 %
Epoch 613 of 2000 took 0.097s
  training loss:		0.323776
  validation loss:		0.419406
  validation accuracy:		87.07 %
Epoch 614 of 2000 took 0.098s
  training loss:		0.324547
  validation loss:		0.417178
  validation accuracy:		87.17 %
Epoch 615 of 2000 took 0.097s
  training loss:		0.325867
  validation loss:		0.413438
  validation accuracy:		87.28 %
Epoch 616 of 2000 took 0.098s
  training loss:		0.326576
  validation loss:		0.425565
  validation accuracy:		86.74 %
Epoch 617 of 2000 took 0.100s
  training loss:		0.330669
  validation loss:		0.418701
  validation accuracy:		87.17 %
Epoch 618 of 2000 took 0.100s
  training loss:		0.322091
  validation loss:		0.404450
  validation accuracy:		87.28 %
Epoch 619 of 2000 took 0.100s
  training loss:		0.323068
  validation loss:		0.426002
  validation accuracy:		86.52 %
Epoch 620 of 2000 took 0.100s
  training loss:		0.322835
  validation loss:		0.411054
  validation accuracy:		86.96 %
Epoch 621 of 2000 took 0.100s
  training loss:		0.320270
  validation loss:		0.409824
  validation accuracy:		86.96 %
Epoch 622 of 2000 took 0.100s
  training loss:		0.318941
  validation loss:		0.414895
  validation accuracy:		86.74 %
Epoch 623 of 2000 took 0.100s
  training loss:		0.324026
  validation loss:		0.432915
  validation accuracy:		86.63 %
Epoch 624 of 2000 took 0.100s
  training loss:		0.322438
  validation loss:		0.417108
  validation accuracy:		86.85 %
Epoch 625 of 2000 took 0.100s
  training loss:		0.322040
  validation loss:		0.412467
  validation accuracy:		86.85 %
Epoch 626 of 2000 took 0.100s
  training loss:		0.320589
  validation loss:		0.417760
  validation accuracy:		87.17 %
Epoch 627 of 2000 took 0.100s
  training loss:		0.322345
  validation loss:		0.415261
  validation accuracy:		86.96 %
Epoch 628 of 2000 took 0.100s
  training loss:		0.320267
  validation loss:		0.421399
  validation accuracy:		86.63 %
Epoch 629 of 2000 took 0.100s
  training loss:		0.326331
  validation loss:		0.422167
  validation accuracy:		86.74 %
Epoch 630 of 2000 took 0.100s
  training loss:		0.322161
  validation loss:		0.415810
  validation accuracy:		87.17 %
Epoch 631 of 2000 took 0.100s
  training loss:		0.315422
  validation loss:		0.419350
  validation accuracy:		86.96 %
Epoch 632 of 2000 took 0.100s
  training loss:		0.328257
  validation loss:		0.428860
  validation accuracy:		86.85 %
Epoch 633 of 2000 took 0.100s
  training loss:		0.322169
  validation loss:		0.418794
  validation accuracy:		87.17 %
Epoch 634 of 2000 took 0.100s
  training loss:		0.326403
  validation loss:		0.413443
  validation accuracy:		86.41 %
Epoch 635 of 2000 took 0.100s
  training loss:		0.324406
  validation loss:		0.423779
  validation accuracy:		86.85 %
Epoch 636 of 2000 took 0.100s
  training loss:		0.319845
  validation loss:		0.419563
  validation accuracy:		86.74 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.321757
  validation loss:		0.407636
  validation accuracy:		87.39 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.312643
  validation loss:		0.421359
  validation accuracy:		87.50 %
Epoch 639 of 2000 took 0.100s
  training loss:		0.322413
  validation loss:		0.418830
  validation accuracy:		86.74 %
Epoch 640 of 2000 took 0.100s
  training loss:		0.325110
  validation loss:		0.412805
  validation accuracy:		86.96 %
Epoch 641 of 2000 took 0.100s
  training loss:		0.313621
  validation loss:		0.427189
  validation accuracy:		86.63 %
Epoch 642 of 2000 took 0.100s
  training loss:		0.316341
  validation loss:		0.417213
  validation accuracy:		86.63 %
Epoch 643 of 2000 took 0.100s
  training loss:		0.321604
  validation loss:		0.417279
  validation accuracy:		86.85 %
Epoch 644 of 2000 took 0.100s
  training loss:		0.318110
  validation loss:		0.427362
  validation accuracy:		86.52 %
Epoch 645 of 2000 took 0.101s
  training loss:		0.321006
  validation loss:		0.417009
  validation accuracy:		86.74 %
Epoch 646 of 2000 took 0.100s
  training loss:		0.318185
  validation loss:		0.430061
  validation accuracy:		86.41 %
Epoch 647 of 2000 took 0.100s
  training loss:		0.319167
  validation loss:		0.410154
  validation accuracy:		86.63 %
Epoch 648 of 2000 took 0.100s
  training loss:		0.321862
  validation loss:		0.416889
  validation accuracy:		86.85 %
Epoch 649 of 2000 took 0.100s
  training loss:		0.310260
  validation loss:		0.418762
  validation accuracy:		86.96 %
Epoch 650 of 2000 took 0.100s
  training loss:		0.318474
  validation loss:		0.436820
  validation accuracy:		86.20 %
Epoch 651 of 2000 took 0.100s
  training loss:		0.317392
  validation loss:		0.419428
  validation accuracy:		87.39 %
Epoch 652 of 2000 took 0.100s
  training loss:		0.320591
  validation loss:		0.422229
  validation accuracy:		87.17 %
Epoch 653 of 2000 took 0.100s
  training loss:		0.314157
  validation loss:		0.420641
  validation accuracy:		87.28 %
Epoch 654 of 2000 took 0.100s
  training loss:		0.317084
  validation loss:		0.417077
  validation accuracy:		86.74 %
Epoch 655 of 2000 took 0.100s
  training loss:		0.316886
  validation loss:		0.425030
  validation accuracy:		87.07 %
Epoch 656 of 2000 took 0.099s
  training loss:		0.318425
  validation loss:		0.416790
  validation accuracy:		86.96 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.315225
  validation loss:		0.417648
  validation accuracy:		86.63 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.309256
  validation loss:		0.424737
  validation accuracy:		86.96 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.315543
  validation loss:		0.414368
  validation accuracy:		86.74 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.319288
  validation loss:		0.434331
  validation accuracy:		86.63 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.312641
  validation loss:		0.419618
  validation accuracy:		87.17 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.321543
  validation loss:		0.427659
  validation accuracy:		86.63 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.318936
  validation loss:		0.418320
  validation accuracy:		87.07 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.322126
  validation loss:		0.422448
  validation accuracy:		87.07 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.316437
  validation loss:		0.409238
  validation accuracy:		87.07 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.311458
  validation loss:		0.426421
  validation accuracy:		86.85 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.316964
  validation loss:		0.424122
  validation accuracy:		87.07 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.311640
  validation loss:		0.413527
  validation accuracy:		87.07 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.308674
  validation loss:		0.415897
  validation accuracy:		86.85 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.321251
  validation loss:		0.421572
  validation accuracy:		86.96 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.318015
  validation loss:		0.419403
  validation accuracy:		86.85 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.320009
  validation loss:		0.413349
  validation accuracy:		87.07 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.327196
  validation loss:		0.409189
  validation accuracy:		87.39 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.313955
  validation loss:		0.413120
  validation accuracy:		86.74 %
Epoch 675 of 2000 took 0.098s
  training loss:		0.320517
  validation loss:		0.413145
  validation accuracy:		86.96 %
Epoch 676 of 2000 took 0.097s
  training loss:		0.312260
  validation loss:		0.421791
  validation accuracy:		86.63 %
Epoch 677 of 2000 took 0.097s
  training loss:		0.316819
  validation loss:		0.416388
  validation accuracy:		86.96 %
Epoch 678 of 2000 took 0.097s
  training loss:		0.311899
  validation loss:		0.436890
  validation accuracy:		86.20 %
Epoch 679 of 2000 took 0.097s
  training loss:		0.315685
  validation loss:		0.417790
  validation accuracy:		87.28 %
Epoch 680 of 2000 took 0.097s
  training loss:		0.313909
  validation loss:		0.418063
  validation accuracy:		87.28 %
Epoch 681 of 2000 took 0.097s
  training loss:		0.318748
  validation loss:		0.414079
  validation accuracy:		86.74 %
Epoch 682 of 2000 took 0.097s
  training loss:		0.312665
  validation loss:		0.412673
  validation accuracy:		86.96 %
Epoch 683 of 2000 took 0.097s
  training loss:		0.314694
  validation loss:		0.411896
  validation accuracy:		86.85 %
Epoch 684 of 2000 took 0.097s
  training loss:		0.313347
  validation loss:		0.427898
  validation accuracy:		86.52 %
Epoch 685 of 2000 took 0.097s
  training loss:		0.311408
  validation loss:		0.425515
  validation accuracy:		86.85 %
Epoch 686 of 2000 took 0.097s
  training loss:		0.321992
  validation loss:		0.426516
  validation accuracy:		86.63 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.312569
  validation loss:		0.409617
  validation accuracy:		87.39 %
Epoch 688 of 2000 took 0.097s
  training loss:		0.315930
  validation loss:		0.424760
  validation accuracy:		86.85 %
Epoch 689 of 2000 took 0.097s
  training loss:		0.307795
  validation loss:		0.416794
  validation accuracy:		87.39 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.310501
  validation loss:		0.414924
  validation accuracy:		86.63 %
Epoch 691 of 2000 took 0.097s
  training loss:		0.317097
  validation loss:		0.411988
  validation accuracy:		87.28 %
Epoch 692 of 2000 took 0.097s
  training loss:		0.310705
  validation loss:		0.403076
  validation accuracy:		87.39 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.306558
  validation loss:		0.419632
  validation accuracy:		86.52 %
Epoch 694 of 2000 took 0.097s
  training loss:		0.316747
  validation loss:		0.419797
  validation accuracy:		87.28 %
Epoch 695 of 2000 took 0.097s
  training loss:		0.311166
  validation loss:		0.406889
  validation accuracy:		87.28 %
Epoch 696 of 2000 took 0.097s
  training loss:		0.316804
  validation loss:		0.415728
  validation accuracy:		86.96 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.314925
  validation loss:		0.409222
  validation accuracy:		86.52 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.311818
  validation loss:		0.428226
  validation accuracy:		87.17 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.315117
  validation loss:		0.413681
  validation accuracy:		87.07 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.314747
  validation loss:		0.413165
  validation accuracy:		87.07 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.309299
  validation loss:		0.410266
  validation accuracy:		86.85 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.311463
  validation loss:		0.401965
  validation accuracy:		87.17 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.316614
  validation loss:		0.423255
  validation accuracy:		87.07 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.316118
  validation loss:		0.410763
  validation accuracy:		86.96 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.309133
  validation loss:		0.422090
  validation accuracy:		86.63 %
Epoch 706 of 2000 took 0.098s
  training loss:		0.314818
  validation loss:		0.412943
  validation accuracy:		87.07 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.306885
  validation loss:		0.421966
  validation accuracy:		87.39 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.314839
  validation loss:		0.414499
  validation accuracy:		87.39 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.302991
  validation loss:		0.409173
  validation accuracy:		87.83 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.314464
  validation loss:		0.414178
  validation accuracy:		87.39 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.310301
  validation loss:		0.409195
  validation accuracy:		87.28 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.301495
  validation loss:		0.434748
  validation accuracy:		86.52 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.308079
  validation loss:		0.403232
  validation accuracy:		87.61 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.308854
  validation loss:		0.422552
  validation accuracy:		86.41 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.306054
  validation loss:		0.425152
  validation accuracy:		86.85 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.311560
  validation loss:		0.420247
  validation accuracy:		87.28 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.303454
  validation loss:		0.405039
  validation accuracy:		87.72 %
Epoch 718 of 2000 took 0.100s
  training loss:		0.317089
  validation loss:		0.412136
  validation accuracy:		87.17 %
Epoch 719 of 2000 took 0.107s
  training loss:		0.304679
  validation loss:		0.430979
  validation accuracy:		87.50 %
Epoch 720 of 2000 took 0.117s
  training loss:		0.315097
  validation loss:		0.416769
  validation accuracy:		87.07 %
Epoch 721 of 2000 took 0.135s
  training loss:		0.304371
  validation loss:		0.407136
  validation accuracy:		87.28 %
Epoch 722 of 2000 took 0.103s
  training loss:		0.303756
  validation loss:		0.410935
  validation accuracy:		87.28 %
Epoch 723 of 2000 took 0.103s
  training loss:		0.312309
  validation loss:		0.407503
  validation accuracy:		87.28 %
Epoch 724 of 2000 took 0.103s
  training loss:		0.316101
  validation loss:		0.403352
  validation accuracy:		87.61 %
Epoch 725 of 2000 took 0.104s
  training loss:		0.305078
  validation loss:		0.411398
  validation accuracy:		87.07 %
Epoch 726 of 2000 took 0.103s
  training loss:		0.301104
  validation loss:		0.422355
  validation accuracy:		86.85 %
Epoch 727 of 2000 took 0.100s
  training loss:		0.306736
  validation loss:		0.419347
  validation accuracy:		87.17 %
Epoch 728 of 2000 took 0.101s
  training loss:		0.301772
  validation loss:		0.433552
  validation accuracy:		86.96 %
Epoch 729 of 2000 took 0.101s
  training loss:		0.300566
  validation loss:		0.403165
  validation accuracy:		88.15 %
Epoch 730 of 2000 took 0.101s
  training loss:		0.305096
  validation loss:		0.413438
  validation accuracy:		87.50 %
Epoch 731 of 2000 took 0.101s
  training loss:		0.301379
  validation loss:		0.419446
  validation accuracy:		87.17 %
Epoch 732 of 2000 took 0.100s
  training loss:		0.309580
  validation loss:		0.405164
  validation accuracy:		87.83 %
Epoch 733 of 2000 took 0.101s
  training loss:		0.304440
  validation loss:		0.406239
  validation accuracy:		87.61 %
Epoch 734 of 2000 took 0.100s
  training loss:		0.305309
  validation loss:		0.429857
  validation accuracy:		86.85 %
Epoch 735 of 2000 took 0.101s
  training loss:		0.306802
  validation loss:		0.413487
  validation accuracy:		87.28 %
Epoch 736 of 2000 took 0.102s
  training loss:		0.308547
  validation loss:		0.401596
  validation accuracy:		87.72 %
Epoch 737 of 2000 took 0.101s
  training loss:		0.300142
  validation loss:		0.418980
  validation accuracy:		87.28 %
Epoch 738 of 2000 took 0.101s
  training loss:		0.310164
  validation loss:		0.403808
  validation accuracy:		87.61 %
Epoch 739 of 2000 took 0.101s
  training loss:		0.302271
  validation loss:		0.416907
  validation accuracy:		87.17 %
Epoch 740 of 2000 took 0.101s
  training loss:		0.302147
  validation loss:		0.411362
  validation accuracy:		87.93 %
Epoch 741 of 2000 took 0.100s
  training loss:		0.304348
  validation loss:		0.398524
  validation accuracy:		88.26 %
Epoch 742 of 2000 took 0.101s
  training loss:		0.298824
  validation loss:		0.456162
  validation accuracy:		86.20 %
Epoch 743 of 2000 took 0.104s
  training loss:		0.306581
  validation loss:		0.409749
  validation accuracy:		87.83 %
Epoch 744 of 2000 took 0.102s
  training loss:		0.306557
  validation loss:		0.416728
  validation accuracy:		87.39 %
Epoch 745 of 2000 took 0.101s
  training loss:		0.300779
  validation loss:		0.411439
  validation accuracy:		87.72 %
Epoch 746 of 2000 took 0.100s
  training loss:		0.312665
  validation loss:		0.413157
  validation accuracy:		87.61 %
Epoch 747 of 2000 took 0.101s
  training loss:		0.306379
  validation loss:		0.422478
  validation accuracy:		87.28 %
Epoch 748 of 2000 took 0.100s
  training loss:		0.305626
  validation loss:		0.424789
  validation accuracy:		87.07 %
Epoch 749 of 2000 took 0.101s
  training loss:		0.303138
  validation loss:		0.427530
  validation accuracy:		87.07 %
Epoch 750 of 2000 took 0.101s
  training loss:		0.303402
  validation loss:		0.405957
  validation accuracy:		87.72 %
Epoch 751 of 2000 took 0.101s
  training loss:		0.305386
  validation loss:		0.406362
  validation accuracy:		87.61 %
Epoch 752 of 2000 took 0.101s
  training loss:		0.300320
  validation loss:		0.400763
  validation accuracy:		87.72 %
Epoch 753 of 2000 took 0.101s
  training loss:		0.308768
  validation loss:		0.414154
  validation accuracy:		87.72 %
Epoch 754 of 2000 took 0.101s
  training loss:		0.296083
  validation loss:		0.409335
  validation accuracy:		87.50 %
Epoch 755 of 2000 took 0.101s
  training loss:		0.297746
  validation loss:		0.399554
  validation accuracy:		88.15 %
Epoch 756 of 2000 took 0.101s
  training loss:		0.300612
  validation loss:		0.413230
  validation accuracy:		87.72 %
Epoch 757 of 2000 took 0.101s
  training loss:		0.300431
  validation loss:		0.406941
  validation accuracy:		87.50 %
Epoch 758 of 2000 took 0.101s
  training loss:		0.298925
  validation loss:		0.413481
  validation accuracy:		87.83 %
Epoch 759 of 2000 took 0.103s
  training loss:		0.297295
  validation loss:		0.411310
  validation accuracy:		88.04 %
Epoch 760 of 2000 took 0.127s
  training loss:		0.294344
  validation loss:		0.397697
  validation accuracy:		87.83 %
Epoch 761 of 2000 took 0.166s
  training loss:		0.295012
  validation loss:		0.404625
  validation accuracy:		87.83 %
Epoch 762 of 2000 took 0.166s
  training loss:		0.305717
  validation loss:		0.408949
  validation accuracy:		87.83 %
Epoch 763 of 2000 took 0.166s
  training loss:		0.295964
  validation loss:		0.403210
  validation accuracy:		88.04 %
Epoch 764 of 2000 took 0.161s
  training loss:		0.300846
  validation loss:		0.398953
  validation accuracy:		87.93 %
Epoch 765 of 2000 took 0.101s
  training loss:		0.299947
  validation loss:		0.417671
  validation accuracy:		87.72 %
Epoch 766 of 2000 took 0.100s
  training loss:		0.293984
  validation loss:		0.444252
  validation accuracy:		87.17 %
Epoch 767 of 2000 took 0.102s
  training loss:		0.300631
  validation loss:		0.405506
  validation accuracy:		87.83 %
Epoch 768 of 2000 took 0.098s
  training loss:		0.301221
  validation loss:		0.402146
  validation accuracy:		87.83 %
Epoch 769 of 2000 took 0.098s
  training loss:		0.298676
  validation loss:		0.403469
  validation accuracy:		87.93 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.299433
  validation loss:		0.436323
  validation accuracy:		86.74 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.300602
  validation loss:		0.401323
  validation accuracy:		87.93 %
Epoch 772 of 2000 took 0.102s
  training loss:		0.293730
  validation loss:		0.411348
  validation accuracy:		88.04 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.293181
  validation loss:		0.400034
  validation accuracy:		88.59 %
Epoch 774 of 2000 took 0.097s
  training loss:		0.300496
  validation loss:		0.417886
  validation accuracy:		87.61 %
Epoch 775 of 2000 took 0.104s
  training loss:		0.302665
  validation loss:		0.394736
  validation accuracy:		88.15 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.296820
  validation loss:		0.423846
  validation accuracy:		87.93 %
Epoch 777 of 2000 took 0.099s
  training loss:		0.294814
  validation loss:		0.402419
  validation accuracy:		87.83 %
Epoch 778 of 2000 took 0.096s
  training loss:		0.296100
  validation loss:		0.397733
  validation accuracy:		88.59 %
Epoch 779 of 2000 took 0.101s
  training loss:		0.296930
  validation loss:		0.402778
  validation accuracy:		88.48 %
Epoch 780 of 2000 took 0.102s
  training loss:		0.294197
  validation loss:		0.399344
  validation accuracy:		87.93 %
Epoch 781 of 2000 took 0.096s
  training loss:		0.293402
  validation loss:		0.397746
  validation accuracy:		88.15 %
Epoch 782 of 2000 took 0.101s
  training loss:		0.292753
  validation loss:		0.395304
  validation accuracy:		88.04 %
Epoch 783 of 2000 took 0.101s
  training loss:		0.296910
  validation loss:		0.398261
  validation accuracy:		88.37 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.290766
  validation loss:		0.400517
  validation accuracy:		88.15 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.288284
  validation loss:		0.395958
  validation accuracy:		87.83 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.289456
  validation loss:		0.397200
  validation accuracy:		88.04 %
Epoch 787 of 2000 took 0.103s
  training loss:		0.288218
  validation loss:		0.398368
  validation accuracy:		88.15 %
Epoch 788 of 2000 took 0.098s
  training loss:		0.289086
  validation loss:		0.424955
  validation accuracy:		87.61 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.285458
  validation loss:		0.402720
  validation accuracy:		88.26 %
Epoch 790 of 2000 took 0.106s
  training loss:		0.297097
  validation loss:		0.394462
  validation accuracy:		88.15 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.297815
  validation loss:		0.400170
  validation accuracy:		88.04 %
Epoch 792 of 2000 took 0.098s
  training loss:		0.290498
  validation loss:		0.394419
  validation accuracy:		88.48 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.294818
  validation loss:		0.395418
  validation accuracy:		88.37 %
Epoch 794 of 2000 took 0.099s
  training loss:		0.285928
  validation loss:		0.392207
  validation accuracy:		88.04 %
Epoch 795 of 2000 took 0.103s
  training loss:		0.287224
  validation loss:		0.399774
  validation accuracy:		88.26 %
Epoch 796 of 2000 took 0.096s
  training loss:		0.289499
  validation loss:		0.401168
  validation accuracy:		88.48 %
Epoch 797 of 2000 took 0.098s
  training loss:		0.288952
  validation loss:		0.423721
  validation accuracy:		87.93 %
Epoch 798 of 2000 took 0.104s
  training loss:		0.292794
  validation loss:		0.428268
  validation accuracy:		87.39 %
Epoch 799 of 2000 took 0.096s
  training loss:		0.289408
  validation loss:		0.424787
  validation accuracy:		87.17 %
Epoch 800 of 2000 took 0.098s
  training loss:		0.290040
  validation loss:		0.391586
  validation accuracy:		88.26 %
Epoch 801 of 2000 took 0.096s
  training loss:		0.290106
  validation loss:		0.400142
  validation accuracy:		88.26 %
Epoch 802 of 2000 took 0.103s
  training loss:		0.291401
  validation loss:		0.407959
  validation accuracy:		87.83 %
Epoch 803 of 2000 took 0.099s
  training loss:		0.285804
  validation loss:		0.397264
  validation accuracy:		88.37 %
Epoch 804 of 2000 took 0.096s
  training loss:		0.287592
  validation loss:		0.401909
  validation accuracy:		88.26 %
Epoch 805 of 2000 took 0.104s
  training loss:		0.290841
  validation loss:		0.393316
  validation accuracy:		88.48 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.287441
  validation loss:		0.413952
  validation accuracy:		87.50 %
Epoch 807 of 2000 took 0.098s
  training loss:		0.285283
  validation loss:		0.391348
  validation accuracy:		88.91 %
Epoch 808 of 2000 took 0.097s
  training loss:		0.287619
  validation loss:		0.391029
  validation accuracy:		88.48 %
Epoch 809 of 2000 took 0.098s
  training loss:		0.281456
  validation loss:		0.400283
  validation accuracy:		88.15 %
Epoch 810 of 2000 took 0.103s
  training loss:		0.293810
  validation loss:		0.416955
  validation accuracy:		88.15 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.287155
  validation loss:		0.398533
  validation accuracy:		88.37 %
Epoch 812 of 2000 took 0.098s
  training loss:		0.283796
  validation loss:		0.386387
  validation accuracy:		88.26 %
Epoch 813 of 2000 took 0.105s
  training loss:		0.285570
  validation loss:		0.393614
  validation accuracy:		88.48 %
Epoch 814 of 2000 took 0.096s
  training loss:		0.274681
  validation loss:		0.385781
  validation accuracy:		88.70 %
Epoch 815 of 2000 took 0.098s
  training loss:		0.283190
  validation loss:		0.410305
  validation accuracy:		87.83 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.283517
  validation loss:		0.395500
  validation accuracy:		88.48 %
Epoch 817 of 2000 took 0.102s
  training loss:		0.277678
  validation loss:		0.388091
  validation accuracy:		88.80 %
Epoch 818 of 2000 took 0.100s
  training loss:		0.284829
  validation loss:		0.393759
  validation accuracy:		88.70 %
Epoch 819 of 2000 took 0.096s
  training loss:		0.285404
  validation loss:		0.402638
  validation accuracy:		88.15 %
Epoch 820 of 2000 took 0.101s
  training loss:		0.281713
  validation loss:		0.387016
  validation accuracy:		89.24 %
Epoch 821 of 2000 took 0.101s
  training loss:		0.278177
  validation loss:		0.386302
  validation accuracy:		88.80 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.281191
  validation loss:		0.396375
  validation accuracy:		87.93 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.282144
  validation loss:		0.388903
  validation accuracy:		88.48 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.279937
  validation loss:		0.401931
  validation accuracy:		88.48 %
Epoch 825 of 2000 took 0.103s
  training loss:		0.270956
  validation loss:		0.384504
  validation accuracy:		88.91 %
Epoch 826 of 2000 took 0.098s
  training loss:		0.286023
  validation loss:		0.383224
  validation accuracy:		88.80 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.284124
  validation loss:		0.412126
  validation accuracy:		87.72 %
Epoch 828 of 2000 took 0.105s
  training loss:		0.279811
  validation loss:		0.400046
  validation accuracy:		87.93 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.278669
  validation loss:		0.395387
  validation accuracy:		88.59 %
Epoch 830 of 2000 took 0.098s
  training loss:		0.279331
  validation loss:		0.391498
  validation accuracy:		88.37 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.279430
  validation loss:		0.381167
  validation accuracy:		89.02 %
Epoch 832 of 2000 took 0.099s
  training loss:		0.277105
  validation loss:		0.407661
  validation accuracy:		87.83 %
Epoch 833 of 2000 took 0.103s
  training loss:		0.276138
  validation loss:		0.388474
  validation accuracy:		88.59 %
Epoch 834 of 2000 took 0.096s
  training loss:		0.280421
  validation loss:		0.380210
  validation accuracy:		88.91 %
Epoch 835 of 2000 took 0.098s
  training loss:		0.277561
  validation loss:		0.396150
  validation accuracy:		88.37 %
Epoch 836 of 2000 took 0.104s
  training loss:		0.284222
  validation loss:		0.395641
  validation accuracy:		88.59 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.273528
  validation loss:		0.403004
  validation accuracy:		88.37 %
Epoch 838 of 2000 took 0.098s
  training loss:		0.272909
  validation loss:		0.381821
  validation accuracy:		89.13 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.276502
  validation loss:		0.402259
  validation accuracy:		87.93 %
Epoch 840 of 2000 took 0.103s
  training loss:		0.271427
  validation loss:		0.398726
  validation accuracy:		88.48 %
Epoch 841 of 2000 took 0.099s
  training loss:		0.274259
  validation loss:		0.403782
  validation accuracy:		87.83 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.277165
  validation loss:		0.394942
  validation accuracy:		88.04 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.275941
  validation loss:		0.393805
  validation accuracy:		88.37 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.270336
  validation loss:		0.388310
  validation accuracy:		88.70 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.269145
  validation loss:		0.383014
  validation accuracy:		88.70 %
Epoch 846 of 2000 took 0.097s
  training loss:		0.272286
  validation loss:		0.388447
  validation accuracy:		88.37 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.275367
  validation loss:		0.386615
  validation accuracy:		88.70 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.269237
  validation loss:		0.379948
  validation accuracy:		88.91 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.270500
  validation loss:		0.384609
  validation accuracy:		88.59 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.266337
  validation loss:		0.392338
  validation accuracy:		88.59 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.272718
  validation loss:		0.378985
  validation accuracy:		89.13 %
Epoch 852 of 2000 took 0.097s
  training loss:		0.268189
  validation loss:		0.378898
  validation accuracy:		89.24 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.275913
  validation loss:		0.377140
  validation accuracy:		89.13 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.268054
  validation loss:		0.380094
  validation accuracy:		88.91 %
Epoch 855 of 2000 took 0.098s
  training loss:		0.264978
  validation loss:		0.379515
  validation accuracy:		89.02 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.267580
  validation loss:		0.376080
  validation accuracy:		89.46 %
Epoch 857 of 2000 took 0.097s
  training loss:		0.270730
  validation loss:		0.386217
  validation accuracy:		88.48 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.269586
  validation loss:		0.385716
  validation accuracy:		88.80 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.267186
  validation loss:		0.381110
  validation accuracy:		89.02 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.269412
  validation loss:		0.391414
  validation accuracy:		88.70 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.271744
  validation loss:		0.373029
  validation accuracy:		89.35 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.264679
  validation loss:		0.386008
  validation accuracy:		88.80 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.263713
  validation loss:		0.381748
  validation accuracy:		88.91 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.263807
  validation loss:		0.375804
  validation accuracy:		88.91 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.264648
  validation loss:		0.377101
  validation accuracy:		89.24 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.260244
  validation loss:		0.374056
  validation accuracy:		89.02 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.256789
  validation loss:		0.372953
  validation accuracy:		88.80 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.261577
  validation loss:		0.381416
  validation accuracy:		88.91 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.263325
  validation loss:		0.381900
  validation accuracy:		88.80 %
Epoch 870 of 2000 took 0.097s
  training loss:		0.265633
  validation loss:		0.374277
  validation accuracy:		89.02 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.264771
  validation loss:		0.370568
  validation accuracy:		89.35 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.261852
  validation loss:		0.380214
  validation accuracy:		89.02 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.258823
  validation loss:		0.381795
  validation accuracy:		88.91 %
Epoch 874 of 2000 took 0.097s
  training loss:		0.263030
  validation loss:		0.373566
  validation accuracy:		89.02 %
Epoch 875 of 2000 took 0.098s
  training loss:		0.259160
  validation loss:		0.372210
  validation accuracy:		89.13 %
Epoch 876 of 2000 took 0.100s
  training loss:		0.257285
  validation loss:		0.373804
  validation accuracy:		89.24 %
Epoch 877 of 2000 took 0.100s
  training loss:		0.259561
  validation loss:		0.376103
  validation accuracy:		88.91 %
Epoch 878 of 2000 took 0.100s
  training loss:		0.257486
  validation loss:		0.371261
  validation accuracy:		89.13 %
Epoch 879 of 2000 took 0.098s
  training loss:		0.261138
  validation loss:		0.373777
  validation accuracy:		88.91 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.269791
  validation loss:		0.374495
  validation accuracy:		89.13 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.252334
  validation loss:		0.368645
  validation accuracy:		89.35 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.257398
  validation loss:		0.379668
  validation accuracy:		88.91 %
Epoch 883 of 2000 took 0.097s
  training loss:		0.257645
  validation loss:		0.374440
  validation accuracy:		89.13 %
Epoch 884 of 2000 took 0.098s
  training loss:		0.256059
  validation loss:		0.373633
  validation accuracy:		89.02 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.254798
  validation loss:		0.376419
  validation accuracy:		89.24 %
Epoch 886 of 2000 took 0.098s
  training loss:		0.252845
  validation loss:		0.367539
  validation accuracy:		89.89 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.248934
  validation loss:		0.396518
  validation accuracy:		88.80 %
Epoch 888 of 2000 took 0.103s
  training loss:		0.249196
  validation loss:		0.372421
  validation accuracy:		89.02 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.254398
  validation loss:		0.363962
  validation accuracy:		90.00 %
Epoch 890 of 2000 took 0.097s
  training loss:		0.260878
  validation loss:		0.375933
  validation accuracy:		88.59 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.258781
  validation loss:		0.374790
  validation accuracy:		88.91 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.250361
  validation loss:		0.379824
  validation accuracy:		88.91 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.254193
  validation loss:		0.364194
  validation accuracy:		89.78 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.251493
  validation loss:		0.364196
  validation accuracy:		89.24 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.248661
  validation loss:		0.372269
  validation accuracy:		89.35 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.249314
  validation loss:		0.362160
  validation accuracy:		89.67 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.248754
  validation loss:		0.370359
  validation accuracy:		89.02 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.251628
  validation loss:		0.362504
  validation accuracy:		89.78 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.248504
  validation loss:		0.371100
  validation accuracy:		89.02 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.245208
  validation loss:		0.366969
  validation accuracy:		89.02 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.250008
  validation loss:		0.376343
  validation accuracy:		89.24 %
Epoch 902 of 2000 took 0.096s
  training loss:		0.242358
  validation loss:		0.374001
  validation accuracy:		89.35 %
Epoch 903 of 2000 took 0.097s
  training loss:		0.243458
  validation loss:		0.368680
  validation accuracy:		89.02 %
Epoch 904 of 2000 took 0.096s
  training loss:		0.249290
  validation loss:		0.359077
  validation accuracy:		89.67 %
Epoch 905 of 2000 took 0.097s
  training loss:		0.244966
  validation loss:		0.364314
  validation accuracy:		89.67 %
Epoch 906 of 2000 took 0.096s
  training loss:		0.247019
  validation loss:		0.365104
  validation accuracy:		89.57 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.252395
  validation loss:		0.362149
  validation accuracy:		89.46 %
Epoch 908 of 2000 took 0.096s
  training loss:		0.242527
  validation loss:		0.370039
  validation accuracy:		89.24 %
Epoch 909 of 2000 took 0.097s
  training loss:		0.242439
  validation loss:		0.363620
  validation accuracy:		89.89 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.240454
  validation loss:		0.367691
  validation accuracy:		89.57 %
Epoch 911 of 2000 took 0.097s
  training loss:		0.243891
  validation loss:		0.359833
  validation accuracy:		89.67 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.245671
  validation loss:		0.360707
  validation accuracy:		89.57 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.238564
  validation loss:		0.375735
  validation accuracy:		88.91 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.248454
  validation loss:		0.361418
  validation accuracy:		89.89 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.247493
  validation loss:		0.382036
  validation accuracy:		88.59 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.242889
  validation loss:		0.361840
  validation accuracy:		89.78 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.242295
  validation loss:		0.359879
  validation accuracy:		89.46 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.240919
  validation loss:		0.364034
  validation accuracy:		89.46 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.239529
  validation loss:		0.370525
  validation accuracy:		89.35 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.236475
  validation loss:		0.365605
  validation accuracy:		89.02 %
Epoch 921 of 2000 took 0.096s
  training loss:		0.232876
  validation loss:		0.368112
  validation accuracy:		89.35 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.241229
  validation loss:		0.371715
  validation accuracy:		89.24 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.246526
  validation loss:		0.360828
  validation accuracy:		89.67 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.236471
  validation loss:		0.366063
  validation accuracy:		89.24 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.235673
  validation loss:		0.353848
  validation accuracy:		89.46 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.236198
  validation loss:		0.357128
  validation accuracy:		89.46 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.234940
  validation loss:		0.369682
  validation accuracy:		89.35 %
Epoch 928 of 2000 took 0.097s
  training loss:		0.239018
  validation loss:		0.357421
  validation accuracy:		89.57 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.244069
  validation loss:		0.370095
  validation accuracy:		89.02 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.232895
  validation loss:		0.367507
  validation accuracy:		89.46 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.235656
  validation loss:		0.352363
  validation accuracy:		89.89 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.231567
  validation loss:		0.363991
  validation accuracy:		89.35 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.234210
  validation loss:		0.353788
  validation accuracy:		89.67 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.233605
  validation loss:		0.351597
  validation accuracy:		89.78 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.230448
  validation loss:		0.358633
  validation accuracy:		89.78 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.230286
  validation loss:		0.356304
  validation accuracy:		89.89 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.232679
  validation loss:		0.367096
  validation accuracy:		89.67 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.227432
  validation loss:		0.365559
  validation accuracy:		89.89 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.236628
  validation loss:		0.351563
  validation accuracy:		89.78 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.232100
  validation loss:		0.347450
  validation accuracy:		89.89 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.232278
  validation loss:		0.360452
  validation accuracy:		89.46 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.222468
  validation loss:		0.349953
  validation accuracy:		89.67 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.231631
  validation loss:		0.366235
  validation accuracy:		89.46 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.235243
  validation loss:		0.369325
  validation accuracy:		89.02 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.226343
  validation loss:		0.360829
  validation accuracy:		89.78 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.225629
  validation loss:		0.360208
  validation accuracy:		89.89 %
Epoch 947 of 2000 took 0.096s
  training loss:		0.235781
  validation loss:		0.366836
  validation accuracy:		89.89 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.227083
  validation loss:		0.350033
  validation accuracy:		89.78 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.226330
  validation loss:		0.363792
  validation accuracy:		89.78 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.230705
  validation loss:		0.359991
  validation accuracy:		89.78 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.225509
  validation loss:		0.362161
  validation accuracy:		89.57 %
Epoch 952 of 2000 took 0.096s
  training loss:		0.223110
  validation loss:		0.356228
  validation accuracy:		89.67 %
Epoch 953 of 2000 took 0.096s
  training loss:		0.225679
  validation loss:		0.351964
  validation accuracy:		90.00 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.226995
  validation loss:		0.361093
  validation accuracy:		89.78 %
Epoch 955 of 2000 took 0.096s
  training loss:		0.231991
  validation loss:		0.354982
  validation accuracy:		89.67 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.219294
  validation loss:		0.352967
  validation accuracy:		89.67 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.227185
  validation loss:		0.350674
  validation accuracy:		90.00 %
Epoch 958 of 2000 took 0.096s
  training loss:		0.227887
  validation loss:		0.361980
  validation accuracy:		89.67 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.224938
  validation loss:		0.356654
  validation accuracy:		89.78 %
Epoch 960 of 2000 took 0.096s
  training loss:		0.217910
  validation loss:		0.365408
  validation accuracy:		89.46 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.225915
  validation loss:		0.364830
  validation accuracy:		89.35 %
Epoch 962 of 2000 took 0.096s
  training loss:		0.224167
  validation loss:		0.345854
  validation accuracy:		89.67 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.220015
  validation loss:		0.374318
  validation accuracy:		89.78 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.221663
  validation loss:		0.344633
  validation accuracy:		90.11 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.221454
  validation loss:		0.357014
  validation accuracy:		89.46 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.222329
  validation loss:		0.357817
  validation accuracy:		89.89 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.226054
  validation loss:		0.361210
  validation accuracy:		89.57 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.217953
  validation loss:		0.359105
  validation accuracy:		89.35 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.225987
  validation loss:		0.372253
  validation accuracy:		89.89 %
Epoch 970 of 2000 took 0.096s
  training loss:		0.218414
  validation loss:		0.359190
  validation accuracy:		89.57 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.217753
  validation loss:		0.351525
  validation accuracy:		89.89 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.215285
  validation loss:		0.359543
  validation accuracy:		89.89 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.213985
  validation loss:		0.362503
  validation accuracy:		89.46 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.215381
  validation loss:		0.348635
  validation accuracy:		89.89 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.219906
  validation loss:		0.378378
  validation accuracy:		89.13 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.220822
  validation loss:		0.357662
  validation accuracy:		89.57 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.213170
  validation loss:		0.359676
  validation accuracy:		89.67 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.214497
  validation loss:		0.350915
  validation accuracy:		90.00 %
Epoch 979 of 2000 took 0.098s
  training loss:		0.215674
  validation loss:		0.363331
  validation accuracy:		89.46 %
Epoch 980 of 2000 took 0.101s
  training loss:		0.216805
  validation loss:		0.358996
  validation accuracy:		89.57 %
Epoch 981 of 2000 took 0.103s
  training loss:		0.215194
  validation loss:		0.358190
  validation accuracy:		89.35 %
Epoch 982 of 2000 took 0.103s
  training loss:		0.216980
  validation loss:		0.350287
  validation accuracy:		89.57 %
Epoch 983 of 2000 took 0.103s
  training loss:		0.213579
  validation loss:		0.356764
  validation accuracy:		89.57 %
Epoch 984 of 2000 took 0.103s
  training loss:		0.216160
  validation loss:		0.349212
  validation accuracy:		89.78 %
Epoch 985 of 2000 took 0.103s
  training loss:		0.210845
  validation loss:		0.351326
  validation accuracy:		89.57 %
Epoch 986 of 2000 took 0.103s
  training loss:		0.219642
  validation loss:		0.366820
  validation accuracy:		89.57 %
Epoch 987 of 2000 took 0.103s
  training loss:		0.218022
  validation loss:		0.375453
  validation accuracy:		88.80 %
Epoch 988 of 2000 took 0.103s
  training loss:		0.215455
  validation loss:		0.358830
  validation accuracy:		89.78 %
Epoch 989 of 2000 took 0.103s
  training loss:		0.212978
  validation loss:		0.353278
  validation accuracy:		89.89 %
Epoch 990 of 2000 took 0.103s
  training loss:		0.216402
  validation loss:		0.372722
  validation accuracy:		89.35 %
Epoch 991 of 2000 took 0.103s
  training loss:		0.213030
  validation loss:		0.367058
  validation accuracy:		89.24 %
Epoch 992 of 2000 took 0.103s
  training loss:		0.209497
  validation loss:		0.356741
  validation accuracy:		89.46 %
Epoch 993 of 2000 took 0.103s
  training loss:		0.212715
  validation loss:		0.348256
  validation accuracy:		90.00 %
Epoch 994 of 2000 took 0.103s
  training loss:		0.213130
  validation loss:		0.351113
  validation accuracy:		89.89 %
Epoch 995 of 2000 took 0.103s
  training loss:		0.210426
  validation loss:		0.357564
  validation accuracy:		90.11 %
Epoch 996 of 2000 took 0.103s
  training loss:		0.214859
  validation loss:		0.345868
  validation accuracy:		89.78 %
Epoch 997 of 2000 took 0.103s
  training loss:		0.207919
  validation loss:		0.358435
  validation accuracy:		90.11 %
Epoch 998 of 2000 took 0.103s
  training loss:		0.212668
  validation loss:		0.356227
  validation accuracy:		89.78 %
Epoch 999 of 2000 took 0.103s
  training loss:		0.207042
  validation loss:		0.369564
  validation accuracy:		89.57 %
Epoch 1000 of 2000 took 0.103s
  training loss:		0.213693
  validation loss:		0.357632
  validation accuracy:		89.89 %
Epoch 1001 of 2000 took 0.103s
  training loss:		0.212962
  validation loss:		0.349301
  validation accuracy:		89.89 %
Epoch 1002 of 2000 took 0.103s
  training loss:		0.213031
  validation loss:		0.371978
  validation accuracy:		89.89 %
Epoch 1003 of 2000 took 0.103s
  training loss:		0.207491
  validation loss:		0.352780
  validation accuracy:		89.78 %
Epoch 1004 of 2000 took 0.103s
  training loss:		0.207234
  validation loss:		0.366612
  validation accuracy:		89.67 %
Epoch 1005 of 2000 took 0.103s
  training loss:		0.207032
  validation loss:		0.344319
  validation accuracy:		90.00 %
Epoch 1006 of 2000 took 0.103s
  training loss:		0.209418
  validation loss:		0.357059
  validation accuracy:		89.67 %
Epoch 1007 of 2000 took 0.103s
  training loss:		0.212280
  validation loss:		0.350897
  validation accuracy:		90.22 %
Epoch 1008 of 2000 took 0.103s
  training loss:		0.210308
  validation loss:		0.381758
  validation accuracy:		89.46 %
Epoch 1009 of 2000 took 0.103s
  training loss:		0.209063
  validation loss:		0.373499
  validation accuracy:		89.57 %
Epoch 1010 of 2000 took 0.103s
  training loss:		0.213079
  validation loss:		0.352220
  validation accuracy:		89.78 %
Epoch 1011 of 2000 took 0.103s
  training loss:		0.208079
  validation loss:		0.355311
  validation accuracy:		89.67 %
Epoch 1012 of 2000 took 0.103s
  training loss:		0.203347
  validation loss:		0.345909
  validation accuracy:		89.78 %
Epoch 1013 of 2000 took 0.103s
  training loss:		0.205246
  validation loss:		0.342043
  validation accuracy:		90.22 %
Epoch 1014 of 2000 took 0.103s
  training loss:		0.205688
  validation loss:		0.349808
  validation accuracy:		90.33 %
Epoch 1015 of 2000 took 0.103s
  training loss:		0.206369
  validation loss:		0.353695
  validation accuracy:		90.00 %
Epoch 1016 of 2000 took 0.103s
  training loss:		0.204619
  validation loss:		0.348346
  validation accuracy:		90.22 %
Epoch 1017 of 2000 took 0.103s
  training loss:		0.199362
  validation loss:		0.362495
  validation accuracy:		89.89 %
Epoch 1018 of 2000 took 0.103s
  training loss:		0.206361
  validation loss:		0.361406
  validation accuracy:		89.89 %
Epoch 1019 of 2000 took 0.103s
  training loss:		0.208815
  validation loss:		0.349613
  validation accuracy:		90.11 %
Epoch 1020 of 2000 took 0.103s
  training loss:		0.209542
  validation loss:		0.358814
  validation accuracy:		89.89 %
Epoch 1021 of 2000 took 0.103s
  training loss:		0.202773
  validation loss:		0.346781
  validation accuracy:		90.11 %
Epoch 1022 of 2000 took 0.103s
  training loss:		0.203195
  validation loss:		0.346290
  validation accuracy:		90.11 %
Epoch 1023 of 2000 took 0.103s
  training loss:		0.201287
  validation loss:		0.355646
  validation accuracy:		89.89 %
Epoch 1024 of 2000 took 0.103s
  training loss:		0.207257
  validation loss:		0.344400
  validation accuracy:		89.89 %
Epoch 1025 of 2000 took 0.103s
  training loss:		0.203853
  validation loss:		0.394581
  validation accuracy:		89.46 %
Epoch 1026 of 2000 took 0.103s
  training loss:		0.209442
  validation loss:		0.348588
  validation accuracy:		90.00 %
Epoch 1027 of 2000 took 0.103s
  training loss:		0.202211
  validation loss:		0.350141
  validation accuracy:		90.00 %
Epoch 1028 of 2000 took 0.103s
  training loss:		0.203459
  validation loss:		0.348444
  validation accuracy:		89.89 %
Epoch 1029 of 2000 took 0.103s
  training loss:		0.200610
  validation loss:		0.355340
  validation accuracy:		89.89 %
Epoch 1030 of 2000 took 0.103s
  training loss:		0.202029
  validation loss:		0.344617
  validation accuracy:		90.00 %
Epoch 1031 of 2000 took 0.103s
  training loss:		0.197434
  validation loss:		0.345678
  validation accuracy:		90.33 %
Epoch 1032 of 2000 took 0.103s
  training loss:		0.202998
  validation loss:		0.343582
  validation accuracy:		90.00 %
Epoch 1033 of 2000 took 0.103s
  training loss:		0.193508
  validation loss:		0.354433
  validation accuracy:		89.89 %
Epoch 1034 of 2000 took 0.103s
  training loss:		0.199382
  validation loss:		0.372875
  validation accuracy:		89.67 %
Epoch 1035 of 2000 took 0.103s
  training loss:		0.199946
  validation loss:		0.357366
  validation accuracy:		90.11 %
Epoch 1036 of 2000 took 0.103s
  training loss:		0.203898
  validation loss:		0.371404
  validation accuracy:		89.46 %
Epoch 1037 of 2000 took 0.103s
  training loss:		0.199213
  validation loss:		0.342187
  validation accuracy:		90.00 %
Epoch 1038 of 2000 took 0.103s
  training loss:		0.194203
  validation loss:		0.349536
  validation accuracy:		90.11 %
Epoch 1039 of 2000 took 0.099s
  training loss:		0.201413
  validation loss:		0.355460
  validation accuracy:		89.46 %
Epoch 1040 of 2000 took 0.100s
  training loss:		0.201059
  validation loss:		0.344254
  validation accuracy:		90.11 %
Epoch 1041 of 2000 took 0.099s
  training loss:		0.204070
  validation loss:		0.354252
  validation accuracy:		90.22 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.199848
  validation loss:		0.345095
  validation accuracy:		90.22 %
Epoch 1043 of 2000 took 0.099s
  training loss:		0.203961
  validation loss:		0.359435
  validation accuracy:		89.89 %
Epoch 1044 of 2000 took 0.100s
  training loss:		0.200217
  validation loss:		0.351808
  validation accuracy:		90.22 %
Epoch 1045 of 2000 took 0.099s
  training loss:		0.201009
  validation loss:		0.361826
  validation accuracy:		89.67 %
Epoch 1046 of 2000 took 0.100s
  training loss:		0.203631
  validation loss:		0.369632
  validation accuracy:		89.78 %
Epoch 1047 of 2000 took 0.099s
  training loss:		0.200548
  validation loss:		0.344237
  validation accuracy:		90.65 %
Epoch 1048 of 2000 took 0.100s
  training loss:		0.198345
  validation loss:		0.348873
  validation accuracy:		90.00 %
Epoch 1049 of 2000 took 0.102s
  training loss:		0.198047
  validation loss:		0.350359
  validation accuracy:		90.22 %
Epoch 1050 of 2000 took 0.100s
  training loss:		0.197494
  validation loss:		0.346632
  validation accuracy:		90.43 %
Epoch 1051 of 2000 took 0.100s
  training loss:		0.191724
  validation loss:		0.350072
  validation accuracy:		90.22 %
Epoch 1052 of 2000 took 0.100s
  training loss:		0.198611
  validation loss:		0.362284
  validation accuracy:		90.11 %
Epoch 1053 of 2000 took 0.099s
  training loss:		0.192089
  validation loss:		0.345681
  validation accuracy:		90.43 %
Epoch 1054 of 2000 took 0.100s
  training loss:		0.196671
  validation loss:		0.349926
  validation accuracy:		90.22 %
Epoch 1055 of 2000 took 0.100s
  training loss:		0.203559
  validation loss:		0.349863
  validation accuracy:		90.00 %
Epoch 1056 of 2000 took 0.100s
  training loss:		0.194459
  validation loss:		0.345924
  validation accuracy:		90.54 %
Epoch 1057 of 2000 took 0.100s
  training loss:		0.191393
  validation loss:		0.376732
  validation accuracy:		89.46 %
Epoch 1058 of 2000 took 0.098s
  training loss:		0.199935
  validation loss:		0.352799
  validation accuracy:		90.11 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.200259
  validation loss:		0.345301
  validation accuracy:		90.11 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.191049
  validation loss:		0.352824
  validation accuracy:		90.22 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.195264
  validation loss:		0.361109
  validation accuracy:		89.67 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.197157
  validation loss:		0.342726
  validation accuracy:		90.11 %
Epoch 1063 of 2000 took 0.096s
  training loss:		0.191999
  validation loss:		0.343463
  validation accuracy:		90.54 %
Epoch 1064 of 2000 took 0.097s
  training loss:		0.190003
  validation loss:		0.348001
  validation accuracy:		90.33 %
Epoch 1065 of 2000 took 0.096s
  training loss:		0.194901
  validation loss:		0.355223
  validation accuracy:		90.33 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.194893
  validation loss:		0.367416
  validation accuracy:		89.67 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.199776
  validation loss:		0.351388
  validation accuracy:		90.11 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.193765
  validation loss:		0.350273
  validation accuracy:		90.11 %
Epoch 1069 of 2000 took 0.097s
  training loss:		0.193466
  validation loss:		0.340683
  validation accuracy:		90.43 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.186493
  validation loss:		0.365349
  validation accuracy:		90.00 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.194120
  validation loss:		0.379307
  validation accuracy:		89.46 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.195509
  validation loss:		0.354568
  validation accuracy:		90.33 %
Epoch 1073 of 2000 took 0.096s
  training loss:		0.191614
  validation loss:		0.354627
  validation accuracy:		90.43 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.190117
  validation loss:		0.350224
  validation accuracy:		90.11 %
Epoch 1075 of 2000 took 0.096s
  training loss:		0.191850
  validation loss:		0.355431
  validation accuracy:		90.76 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.193290
  validation loss:		0.366514
  validation accuracy:		89.67 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.193696
  validation loss:		0.357222
  validation accuracy:		90.43 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.191900
  validation loss:		0.357663
  validation accuracy:		90.22 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.195323
  validation loss:		0.359963
  validation accuracy:		89.57 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.195973
  validation loss:		0.362421
  validation accuracy:		89.67 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.190252
  validation loss:		0.345698
  validation accuracy:		90.43 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.192442
  validation loss:		0.362902
  validation accuracy:		90.11 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.191416
  validation loss:		0.363279
  validation accuracy:		89.78 %
Epoch 1084 of 2000 took 0.096s
  training loss:		0.190166
  validation loss:		0.365888
  validation accuracy:		90.33 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.191708
  validation loss:		0.358622
  validation accuracy:		90.00 %
Epoch 1086 of 2000 took 0.096s
  training loss:		0.186340
  validation loss:		0.370329
  validation accuracy:		89.78 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.187853
  validation loss:		0.341778
  validation accuracy:		90.87 %
Epoch 1088 of 2000 took 0.096s
  training loss:		0.189442
  validation loss:		0.355804
  validation accuracy:		90.11 %
Epoch 1089 of 2000 took 0.096s
  training loss:		0.188312
  validation loss:		0.348687
  validation accuracy:		90.43 %
Epoch 1090 of 2000 took 0.096s
  training loss:		0.190635
  validation loss:		0.353658
  validation accuracy:		90.43 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.184819
  validation loss:		0.347263
  validation accuracy:		90.76 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.187465
  validation loss:		0.345813
  validation accuracy:		90.22 %
Epoch 1093 of 2000 took 0.096s
  training loss:		0.186435
  validation loss:		0.345623
  validation accuracy:		90.43 %
Epoch 1094 of 2000 took 0.096s
  training loss:		0.186746
  validation loss:		0.354702
  validation accuracy:		90.00 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.188089
  validation loss:		0.353179
  validation accuracy:		90.65 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.188742
  validation loss:		0.345739
  validation accuracy:		90.65 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.190864
  validation loss:		0.366535
  validation accuracy:		90.43 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.186930
  validation loss:		0.357690
  validation accuracy:		90.54 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.188428
  validation loss:		0.358491
  validation accuracy:		90.00 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.188996
  validation loss:		0.372568
  validation accuracy:		89.89 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.185290
  validation loss:		0.353933
  validation accuracy:		90.65 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.190734
  validation loss:		0.356112
  validation accuracy:		89.89 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.183128
  validation loss:		0.351824
  validation accuracy:		90.65 %
Epoch 1104 of 2000 took 0.096s
  training loss:		0.183728
  validation loss:		0.366084
  validation accuracy:		90.11 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.187227
  validation loss:		0.362539
  validation accuracy:		89.89 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.190997
  validation loss:		0.360225
  validation accuracy:		90.00 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.189927
  validation loss:		0.358369
  validation accuracy:		90.65 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.185367
  validation loss:		0.360857
  validation accuracy:		89.89 %
Epoch 1109 of 2000 took 0.096s
  training loss:		0.184098
  validation loss:		0.362472
  validation accuracy:		90.22 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.188329
  validation loss:		0.359189
  validation accuracy:		90.22 %
Epoch 1111 of 2000 took 0.096s
  training loss:		0.185998
  validation loss:		0.361335
  validation accuracy:		89.89 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.183257
  validation loss:		0.359092
  validation accuracy:		90.00 %
Epoch 1113 of 2000 took 0.096s
  training loss:		0.185586
  validation loss:		0.366867
  validation accuracy:		90.43 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.186424
  validation loss:		0.368954
  validation accuracy:		90.22 %
Epoch 1115 of 2000 took 0.096s
  training loss:		0.183812
  validation loss:		0.363888
  validation accuracy:		90.43 %
Epoch 1116 of 2000 took 0.096s
  training loss:		0.183850
  validation loss:		0.361803
  validation accuracy:		90.33 %
Epoch 1117 of 2000 took 0.096s
  training loss:		0.179434
  validation loss:		0.353304
  validation accuracy:		90.65 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.185410
  validation loss:		0.360218
  validation accuracy:		90.22 %
Epoch 1119 of 2000 took 0.096s
  training loss:		0.179685
  validation loss:		0.359446
  validation accuracy:		90.33 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.183230
  validation loss:		0.367842
  validation accuracy:		90.43 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.185615
  validation loss:		0.362830
  validation accuracy:		90.33 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.184417
  validation loss:		0.374556
  validation accuracy:		89.78 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.184735
  validation loss:		0.348259
  validation accuracy:		90.65 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.183567
  validation loss:		0.366979
  validation accuracy:		90.43 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.186326
  validation loss:		0.368345
  validation accuracy:		90.22 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.187109
  validation loss:		0.358002
  validation accuracy:		90.43 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.185934
  validation loss:		0.359695
  validation accuracy:		90.11 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.181390
  validation loss:		0.363600
  validation accuracy:		89.89 %
Epoch 1129 of 2000 took 0.096s
  training loss:		0.184820
  validation loss:		0.384305
  validation accuracy:		89.67 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.186872
  validation loss:		0.361104
  validation accuracy:		89.67 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.180546
  validation loss:		0.354718
  validation accuracy:		90.65 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.179969
  validation loss:		0.348543
  validation accuracy:		91.20 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.181275
  validation loss:		0.356050
  validation accuracy:		90.65 %
Epoch 1134 of 2000 took 0.096s
  training loss:		0.182469
  validation loss:		0.384156
  validation accuracy:		89.67 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.181003
  validation loss:		0.376731
  validation accuracy:		89.67 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.183547
  validation loss:		0.373123
  validation accuracy:		90.43 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.172630
  validation loss:		0.391238
  validation accuracy:		90.00 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.187505
  validation loss:		0.359460
  validation accuracy:		90.76 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.183313
  validation loss:		0.379052
  validation accuracy:		89.89 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.185352
  validation loss:		0.352255
  validation accuracy:		91.30 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.181162
  validation loss:		0.364677
  validation accuracy:		90.43 %
Epoch 1142 of 2000 took 0.100s
  training loss:		0.180352
  validation loss:		0.357156
  validation accuracy:		90.33 %
Epoch 1143 of 2000 took 0.100s
  training loss:		0.181745
  validation loss:		0.373136
  validation accuracy:		89.78 %
Epoch 1144 of 2000 took 0.099s
  training loss:		0.176610
  validation loss:		0.355846
  validation accuracy:		90.76 %
Epoch 1145 of 2000 took 0.100s
  training loss:		0.179579
  validation loss:		0.367274
  validation accuracy:		90.33 %
Epoch 1146 of 2000 took 0.100s
  training loss:		0.178911
  validation loss:		0.374099
  validation accuracy:		89.67 %
Epoch 1147 of 2000 took 0.100s
  training loss:		0.179170
  validation loss:		0.363738
  validation accuracy:		89.89 %
Epoch 1148 of 2000 took 0.099s
  training loss:		0.183834
  validation loss:		0.353324
  validation accuracy:		90.76 %
Epoch 1149 of 2000 took 0.100s
  training loss:		0.179979
  validation loss:		0.360881
  validation accuracy:		90.54 %
Epoch 1150 of 2000 took 0.100s
  training loss:		0.179952
  validation loss:		0.375263
  validation accuracy:		90.98 %
Epoch 1151 of 2000 took 0.100s
  training loss:		0.183958
  validation loss:		0.364831
  validation accuracy:		90.33 %
Epoch 1152 of 2000 took 0.099s
  training loss:		0.172511
  validation loss:		0.365651
  validation accuracy:		90.22 %
Epoch 1153 of 2000 took 0.100s
  training loss:		0.183352
  validation loss:		0.382622
  validation accuracy:		90.43 %
Epoch 1154 of 2000 took 0.099s
  training loss:		0.179719
  validation loss:		0.361201
  validation accuracy:		90.43 %
Epoch 1155 of 2000 took 0.100s
  training loss:		0.180670
  validation loss:		0.362430
  validation accuracy:		90.43 %
Epoch 1156 of 2000 took 0.099s
  training loss:		0.176768
  validation loss:		0.381167
  validation accuracy:		89.89 %
Epoch 1157 of 2000 took 0.100s
  training loss:		0.179336
  validation loss:		0.363772
  validation accuracy:		90.33 %
Epoch 1158 of 2000 took 0.099s
  training loss:		0.184651
  validation loss:		0.364007
  validation accuracy:		90.43 %
Epoch 1159 of 2000 took 0.100s
  training loss:		0.173166
  validation loss:		0.365045
  validation accuracy:		90.33 %
Epoch 1160 of 2000 took 0.100s
  training loss:		0.179139
  validation loss:		0.359782
  validation accuracy:		90.65 %
Epoch 1161 of 2000 took 0.100s
  training loss:		0.182834
  validation loss:		0.384645
  validation accuracy:		89.57 %
Epoch 1162 of 2000 took 0.100s
  training loss:		0.186145
  validation loss:		0.370604
  validation accuracy:		90.43 %
Epoch 1163 of 2000 took 0.100s
  training loss:		0.181073
  validation loss:		0.374373
  validation accuracy:		90.00 %
Epoch 1164 of 2000 took 0.102s
  training loss:		0.177313
  validation loss:		0.378441
  validation accuracy:		90.00 %
Epoch 1165 of 2000 took 0.098s
  training loss:		0.178646
  validation loss:		0.369141
  validation accuracy:		90.22 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.179596
  validation loss:		0.375029
  validation accuracy:		90.33 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.176346
  validation loss:		0.363745
  validation accuracy:		90.65 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.173140
  validation loss:		0.363050
  validation accuracy:		90.54 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.184296
  validation loss:		0.381106
  validation accuracy:		89.46 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.178237
  validation loss:		0.371801
  validation accuracy:		90.33 %
Epoch 1171 of 2000 took 0.096s
  training loss:		0.179456
  validation loss:		0.368842
  validation accuracy:		90.22 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.178452
  validation loss:		0.361920
  validation accuracy:		90.98 %
Epoch 1173 of 2000 took 0.097s
  training loss:		0.177887
  validation loss:		0.384305
  validation accuracy:		90.43 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.179094
  validation loss:		0.388678
  validation accuracy:		90.22 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.177904
  validation loss:		0.374863
  validation accuracy:		90.33 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.178328
  validation loss:		0.376955
  validation accuracy:		90.65 %
Epoch 1177 of 2000 took 0.097s
  training loss:		0.178902
  validation loss:		0.390718
  validation accuracy:		90.22 %
Epoch 1178 of 2000 took 0.097s
  training loss:		0.182787
  validation loss:		0.391969
  validation accuracy:		90.22 %
Epoch 1179 of 2000 took 0.097s
  training loss:		0.177193
  validation loss:		0.388029
  validation accuracy:		90.11 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.171709
  validation loss:		0.369725
  validation accuracy:		90.43 %
Epoch 1181 of 2000 took 0.097s
  training loss:		0.175477
  validation loss:		0.370931
  validation accuracy:		90.43 %
Epoch 1182 of 2000 took 0.097s
  training loss:		0.178851
  validation loss:		0.397586
  validation accuracy:		90.00 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.178430
  validation loss:		0.382806
  validation accuracy:		90.33 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.172615
  validation loss:		0.373641
  validation accuracy:		90.22 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.171523
  validation loss:		0.374883
  validation accuracy:		90.54 %
Epoch 1186 of 2000 took 0.096s
  training loss:		0.174128
  validation loss:		0.369626
  validation accuracy:		90.43 %
Epoch 1187 of 2000 took 0.097s
  training loss:		0.178283
  validation loss:		0.378919
  validation accuracy:		90.11 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.175289
  validation loss:		0.364625
  validation accuracy:		91.09 %
Epoch 1189 of 2000 took 0.097s
  training loss:		0.176244
  validation loss:		0.363805
  validation accuracy:		90.87 %
Epoch 1190 of 2000 took 0.097s
  training loss:		0.174886
  validation loss:		0.375941
  validation accuracy:		90.33 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.179405
  validation loss:		0.377613
  validation accuracy:		90.54 %
Epoch 1192 of 2000 took 0.097s
  training loss:		0.172637
  validation loss:		0.380853
  validation accuracy:		90.43 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.177843
  validation loss:		0.384939
  validation accuracy:		90.00 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.178395
  validation loss:		0.379009
  validation accuracy:		90.00 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.175159
  validation loss:		0.367914
  validation accuracy:		90.33 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.173859
  validation loss:		0.375164
  validation accuracy:		90.43 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.173710
  validation loss:		0.382864
  validation accuracy:		90.43 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.172223
  validation loss:		0.373113
  validation accuracy:		90.11 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.171163
  validation loss:		0.377992
  validation accuracy:		90.54 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.176224
  validation loss:		0.375640
  validation accuracy:		90.43 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.177420
  validation loss:		0.392978
  validation accuracy:		90.00 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.174616
  validation loss:		0.384988
  validation accuracy:		90.33 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.175244
  validation loss:		0.378234
  validation accuracy:		90.65 %
Epoch 1204 of 2000 took 0.097s
  training loss:		0.173433
  validation loss:		0.375844
  validation accuracy:		90.54 %
Epoch 1205 of 2000 took 0.097s
  training loss:		0.175056
  validation loss:		0.389416
  validation accuracy:		90.22 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.175056
  validation loss:		0.377003
  validation accuracy:		90.87 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.174151
  validation loss:		0.365781
  validation accuracy:		90.65 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.170546
  validation loss:		0.373584
  validation accuracy:		90.43 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.174301
  validation loss:		0.394540
  validation accuracy:		89.46 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.170973
  validation loss:		0.382618
  validation accuracy:		90.54 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.177611
  validation loss:		0.377504
  validation accuracy:		90.87 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.175901
  validation loss:		0.389174
  validation accuracy:		90.00 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.171601
  validation loss:		0.379695
  validation accuracy:		90.54 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.170568
  validation loss:		0.376034
  validation accuracy:		90.87 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.173713
  validation loss:		0.387183
  validation accuracy:		90.22 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.175010
  validation loss:		0.384353
  validation accuracy:		90.65 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.175524
  validation loss:		0.385059
  validation accuracy:		90.00 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.174586
  validation loss:		0.380180
  validation accuracy:		89.89 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.169723
  validation loss:		0.373798
  validation accuracy:		90.65 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.169456
  validation loss:		0.395226
  validation accuracy:		90.22 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.178010
  validation loss:		0.379808
  validation accuracy:		90.11 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.175688
  validation loss:		0.388595
  validation accuracy:		90.22 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.169098
  validation loss:		0.389197
  validation accuracy:		90.43 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.178152
  validation loss:		0.387729
  validation accuracy:		90.76 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.171087
  validation loss:		0.385133
  validation accuracy:		90.11 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.165162
  validation loss:		0.383701
  validation accuracy:		90.00 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.173841
  validation loss:		0.383532
  validation accuracy:		90.33 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.169801
  validation loss:		0.392685
  validation accuracy:		90.54 %
Epoch 1229 of 2000 took 0.099s
  training loss:		0.173129
  validation loss:		0.400859
  validation accuracy:		89.89 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.166402
  validation loss:		0.394937
  validation accuracy:		90.00 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.171063
  validation loss:		0.392515
  validation accuracy:		90.43 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.172632
  validation loss:		0.385836
  validation accuracy:		90.54 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.172452
  validation loss:		0.382290
  validation accuracy:		90.87 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.173445
  validation loss:		0.380115
  validation accuracy:		90.54 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.164128
  validation loss:		0.394358
  validation accuracy:		89.89 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.176097
  validation loss:		0.401009
  validation accuracy:		90.54 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.169687
  validation loss:		0.387781
  validation accuracy:		90.22 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.174741
  validation loss:		0.386135
  validation accuracy:		90.11 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.174445
  validation loss:		0.373724
  validation accuracy:		90.87 %
Epoch 1240 of 2000 took 0.096s
  training loss:		0.174387
  validation loss:		0.390369
  validation accuracy:		90.33 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.168882
  validation loss:		0.387680
  validation accuracy:		90.54 %
Epoch 1242 of 2000 took 0.096s
  training loss:		0.174554
  validation loss:		0.378650
  validation accuracy:		90.87 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.169900
  validation loss:		0.382032
  validation accuracy:		90.76 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.168953
  validation loss:		0.374988
  validation accuracy:		90.65 %
Epoch 1245 of 2000 took 0.096s
  training loss:		0.170865
  validation loss:		0.388757
  validation accuracy:		90.76 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.168911
  validation loss:		0.386384
  validation accuracy:		90.54 %
Epoch 1247 of 2000 took 0.096s
  training loss:		0.172111
  validation loss:		0.382954
  validation accuracy:		90.98 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.167812
  validation loss:		0.386894
  validation accuracy:		90.54 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.167714
  validation loss:		0.408436
  validation accuracy:		89.78 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.169951
  validation loss:		0.403542
  validation accuracy:		89.57 %
Epoch 1251 of 2000 took 0.096s
  training loss:		0.172617
  validation loss:		0.391296
  validation accuracy:		90.43 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.170883
  validation loss:		0.389199
  validation accuracy:		90.22 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.169937
  validation loss:		0.396017
  validation accuracy:		89.78 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.165248
  validation loss:		0.402737
  validation accuracy:		90.65 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.172389
  validation loss:		0.386584
  validation accuracy:		90.65 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.169385
  validation loss:		0.407761
  validation accuracy:		89.67 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.166399
  validation loss:		0.403732
  validation accuracy:		90.43 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.169218
  validation loss:		0.400033
  validation accuracy:		90.00 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.171797
  validation loss:		0.387727
  validation accuracy:		90.87 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.173377
  validation loss:		0.393478
  validation accuracy:		90.87 %
Epoch 1261 of 2000 took 0.097s
  training loss:		0.167915
  validation loss:		0.402799
  validation accuracy:		89.78 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.169240
  validation loss:		0.384862
  validation accuracy:		90.54 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.163457
  validation loss:		0.414812
  validation accuracy:		89.89 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.171253
  validation loss:		0.403826
  validation accuracy:		90.00 %
Epoch 1265 of 2000 took 0.097s
  training loss:		0.168050
  validation loss:		0.417033
  validation accuracy:		90.11 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.170550
  validation loss:		0.396989
  validation accuracy:		90.00 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.164726
  validation loss:		0.399010
  validation accuracy:		90.43 %
Epoch 1268 of 2000 took 0.096s
  training loss:		0.171972
  validation loss:		0.398516
  validation accuracy:		90.65 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.169755
  validation loss:		0.407211
  validation accuracy:		90.11 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.166383
  validation loss:		0.397760
  validation accuracy:		90.43 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.164519
  validation loss:		0.416075
  validation accuracy:		89.78 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.169452
  validation loss:		0.410009
  validation accuracy:		90.33 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.168646
  validation loss:		0.396984
  validation accuracy:		90.43 %
Epoch 1274 of 2000 took 0.096s
  training loss:		0.168893
  validation loss:		0.399188
  validation accuracy:		90.33 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.165795
  validation loss:		0.424111
  validation accuracy:		89.57 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.171070
  validation loss:		0.408987
  validation accuracy:		90.00 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.164299
  validation loss:		0.394969
  validation accuracy:		90.43 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.165382
  validation loss:		0.395994
  validation accuracy:		90.65 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.166128
  validation loss:		0.400016
  validation accuracy:		90.54 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.172616
  validation loss:		0.414505
  validation accuracy:		89.35 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.171128
  validation loss:		0.398341
  validation accuracy:		90.54 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.166749
  validation loss:		0.392961
  validation accuracy:		90.54 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.166336
  validation loss:		0.408333
  validation accuracy:		89.89 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.168344
  validation loss:		0.401512
  validation accuracy:		90.22 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.172866
  validation loss:		0.414256
  validation accuracy:		89.89 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.164607
  validation loss:		0.407822
  validation accuracy:		90.98 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.168301
  validation loss:		0.408328
  validation accuracy:		90.43 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.170969
  validation loss:		0.415256
  validation accuracy:		90.43 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.167107
  validation loss:		0.420683
  validation accuracy:		89.67 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.160218
  validation loss:		0.417618
  validation accuracy:		90.33 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.167238
  validation loss:		0.401653
  validation accuracy:		90.65 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.169498
  validation loss:		0.409434
  validation accuracy:		90.65 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.167878
  validation loss:		0.412767
  validation accuracy:		90.00 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.170069
  validation loss:		0.414905
  validation accuracy:		90.00 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.165337
  validation loss:		0.434711
  validation accuracy:		89.78 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.164670
  validation loss:		0.403447
  validation accuracy:		90.00 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.166255
  validation loss:		0.388150
  validation accuracy:		90.76 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.167426
  validation loss:		0.395573
  validation accuracy:		91.09 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.167625
  validation loss:		0.400405
  validation accuracy:		90.33 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.162335
  validation loss:		0.412574
  validation accuracy:		90.11 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.167418
  validation loss:		0.403628
  validation accuracy:		90.87 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.168785
  validation loss:		0.436557
  validation accuracy:		89.46 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.172226
  validation loss:		0.408185
  validation accuracy:		89.78 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.166218
  validation loss:		0.401358
  validation accuracy:		90.87 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.158207
  validation loss:		0.403474
  validation accuracy:		90.22 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.164977
  validation loss:		0.395240
  validation accuracy:		90.65 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.169907
  validation loss:		0.410120
  validation accuracy:		89.78 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.168549
  validation loss:		0.405483
  validation accuracy:		90.65 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.165004
  validation loss:		0.419167
  validation accuracy:		89.46 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.170306
  validation loss:		0.395443
  validation accuracy:		90.87 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.163310
  validation loss:		0.407856
  validation accuracy:		90.43 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.164800
  validation loss:		0.412144
  validation accuracy:		89.89 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.169125
  validation loss:		0.403414
  validation accuracy:		90.54 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.164806
  validation loss:		0.401561
  validation accuracy:		91.09 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.165255
  validation loss:		0.426065
  validation accuracy:		90.22 %
Epoch 1316 of 2000 took 0.096s
  training loss:		0.162505
  validation loss:		0.401186
  validation accuracy:		90.87 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.162662
  validation loss:		0.437051
  validation accuracy:		89.67 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.165773
  validation loss:		0.400594
  validation accuracy:		90.87 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.168071
  validation loss:		0.410916
  validation accuracy:		90.43 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.163609
  validation loss:		0.417772
  validation accuracy:		90.65 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.168464
  validation loss:		0.412719
  validation accuracy:		90.22 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.166628
  validation loss:		0.405657
  validation accuracy:		90.76 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.171112
  validation loss:		0.424085
  validation accuracy:		90.33 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.163202
  validation loss:		0.434998
  validation accuracy:		89.78 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.166212
  validation loss:		0.395080
  validation accuracy:		91.52 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.170607
  validation loss:		0.424356
  validation accuracy:		90.00 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.165793
  validation loss:		0.415038
  validation accuracy:		90.65 %
Epoch 1328 of 2000 took 0.097s
  training loss:		0.164873
  validation loss:		0.396066
  validation accuracy:		90.76 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.168503
  validation loss:		0.423565
  validation accuracy:		90.11 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.165379
  validation loss:		0.440288
  validation accuracy:		88.80 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.161044
  validation loss:		0.422402
  validation accuracy:		89.46 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.165846
  validation loss:		0.423356
  validation accuracy:		90.11 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.167205
  validation loss:		0.411353
  validation accuracy:		90.54 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.173000
  validation loss:		0.418532
  validation accuracy:		90.33 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.160230
  validation loss:		0.426571
  validation accuracy:		90.11 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.167738
  validation loss:		0.415616
  validation accuracy:		90.00 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.162894
  validation loss:		0.417262
  validation accuracy:		90.22 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.161202
  validation loss:		0.411903
  validation accuracy:		90.43 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.161438
  validation loss:		0.408128
  validation accuracy:		90.98 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.165362
  validation loss:		0.418753
  validation accuracy:		90.11 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.162492
  validation loss:		0.408461
  validation accuracy:		90.76 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.169310
  validation loss:		0.431283
  validation accuracy:		90.33 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.165535
  validation loss:		0.428057
  validation accuracy:		89.67 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.164890
  validation loss:		0.411820
  validation accuracy:		90.98 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.161621
  validation loss:		0.403545
  validation accuracy:		90.98 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.166569
  validation loss:		0.407588
  validation accuracy:		90.65 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.159475
  validation loss:		0.415102
  validation accuracy:		90.22 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.163832
  validation loss:		0.411623
  validation accuracy:		91.20 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.163249
  validation loss:		0.402790
  validation accuracy:		91.41 %
Epoch 1350 of 2000 took 0.097s
  training loss:		0.164189
  validation loss:		0.426919
  validation accuracy:		90.54 %
Epoch 1351 of 2000 took 0.097s
  training loss:		0.162544
  validation loss:		0.428848
  validation accuracy:		90.54 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.171864
  validation loss:		0.432184
  validation accuracy:		89.78 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.163546
  validation loss:		0.421706
  validation accuracy:		90.11 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.163693
  validation loss:		0.408736
  validation accuracy:		90.76 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.155955
  validation loss:		0.413794
  validation accuracy:		90.54 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.166607
  validation loss:		0.416261
  validation accuracy:		90.65 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.160516
  validation loss:		0.447379
  validation accuracy:		90.11 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.162191
  validation loss:		0.431842
  validation accuracy:		90.65 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.167894
  validation loss:		0.423828
  validation accuracy:		90.76 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.159143
  validation loss:		0.429270
  validation accuracy:		90.22 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.160314
  validation loss:		0.404476
  validation accuracy:		90.98 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.162591
  validation loss:		0.418480
  validation accuracy:		90.22 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.164093
  validation loss:		0.415103
  validation accuracy:		90.65 %
Epoch 1364 of 2000 took 0.097s
  training loss:		0.161454
  validation loss:		0.424213
  validation accuracy:		90.33 %
Epoch 1365 of 2000 took 0.097s
  training loss:		0.167667
  validation loss:		0.416671
  validation accuracy:		91.20 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.164979
  validation loss:		0.423779
  validation accuracy:		90.00 %
Epoch 1367 of 2000 took 0.097s
  training loss:		0.165028
  validation loss:		0.420926
  validation accuracy:		90.22 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.164636
  validation loss:		0.416001
  validation accuracy:		90.87 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.166481
  validation loss:		0.425297
  validation accuracy:		89.78 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.166478
  validation loss:		0.422341
  validation accuracy:		90.76 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.163077
  validation loss:		0.439529
  validation accuracy:		89.67 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.160777
  validation loss:		0.441350
  validation accuracy:		90.00 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.167127
  validation loss:		0.407343
  validation accuracy:		91.30 %
Epoch 1374 of 2000 took 0.097s
  training loss:		0.163206
  validation loss:		0.415793
  validation accuracy:		90.54 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.164879
  validation loss:		0.408830
  validation accuracy:		91.09 %
Epoch 1376 of 2000 took 0.097s
  training loss:		0.161174
  validation loss:		0.411018
  validation accuracy:		90.76 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.165412
  validation loss:		0.418746
  validation accuracy:		90.43 %
Epoch 1378 of 2000 took 0.097s
  training loss:		0.157442
  validation loss:		0.429262
  validation accuracy:		90.54 %
Epoch 1379 of 2000 took 0.097s
  training loss:		0.163141
  validation loss:		0.424229
  validation accuracy:		90.00 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.165372
  validation loss:		0.404390
  validation accuracy:		90.98 %
Epoch 1381 of 2000 took 0.097s
  training loss:		0.161333
  validation loss:		0.433234
  validation accuracy:		90.54 %
Epoch 1382 of 2000 took 0.097s
  training loss:		0.163479
  validation loss:		0.422574
  validation accuracy:		90.54 %
Epoch 1383 of 2000 took 0.097s
  training loss:		0.164123
  validation loss:		0.432955
  validation accuracy:		90.76 %
Epoch 1384 of 2000 took 0.097s
  training loss:		0.161762
  validation loss:		0.418437
  validation accuracy:		90.54 %
Epoch 1385 of 2000 took 0.097s
  training loss:		0.156567
  validation loss:		0.418942
  validation accuracy:		90.76 %
Epoch 1386 of 2000 took 0.097s
  training loss:		0.165959
  validation loss:		0.459858
  validation accuracy:		90.11 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.167218
  validation loss:		0.426254
  validation accuracy:		90.22 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.163672
  validation loss:		0.421844
  validation accuracy:		91.09 %
Epoch 1389 of 2000 took 0.097s
  training loss:		0.161243
  validation loss:		0.436097
  validation accuracy:		90.22 %
Epoch 1390 of 2000 took 0.097s
  training loss:		0.166988
  validation loss:		0.424207
  validation accuracy:		90.54 %
Epoch 1391 of 2000 took 0.097s
  training loss:		0.164444
  validation loss:		0.434286
  validation accuracy:		90.33 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.160673
  validation loss:		0.420905
  validation accuracy:		91.09 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.158086
  validation loss:		0.418957
  validation accuracy:		91.30 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.161258
  validation loss:		0.413720
  validation accuracy:		91.41 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.161796
  validation loss:		0.423850
  validation accuracy:		90.43 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.161925
  validation loss:		0.446336
  validation accuracy:		90.22 %
Epoch 1397 of 2000 took 0.097s
  training loss:		0.163814
  validation loss:		0.419658
  validation accuracy:		91.20 %
Epoch 1398 of 2000 took 0.097s
  training loss:		0.158910
  validation loss:		0.426052
  validation accuracy:		90.76 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.161055
  validation loss:		0.426736
  validation accuracy:		90.43 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.162270
  validation loss:		0.433435
  validation accuracy:		90.43 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.153771
  validation loss:		0.418245
  validation accuracy:		91.09 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.164338
  validation loss:		0.437578
  validation accuracy:		90.00 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.161180
  validation loss:		0.448399
  validation accuracy:		90.43 %
Epoch 1404 of 2000 took 0.097s
  training loss:		0.159365
  validation loss:		0.434202
  validation accuracy:		90.43 %
Epoch 1405 of 2000 took 0.097s
  training loss:		0.159559
  validation loss:		0.429523
  validation accuracy:		90.33 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.165165
  validation loss:		0.464884
  validation accuracy:		89.67 %
Epoch 1407 of 2000 took 0.097s
  training loss:		0.160228
  validation loss:		0.424229
  validation accuracy:		90.43 %
Epoch 1408 of 2000 took 0.097s
  training loss:		0.157631
  validation loss:		0.424635
  validation accuracy:		90.87 %
Epoch 1409 of 2000 took 0.097s
  training loss:		0.164976
  validation loss:		0.416598
  validation accuracy:		90.54 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.167311
  validation loss:		0.427419
  validation accuracy:		90.43 %
Epoch 1411 of 2000 took 0.097s
  training loss:		0.162752
  validation loss:		0.440899
  validation accuracy:		90.43 %
Epoch 1412 of 2000 took 0.097s
  training loss:		0.161873
  validation loss:		0.426926
  validation accuracy:		90.87 %
Epoch 1413 of 2000 took 0.097s
  training loss:		0.162623
  validation loss:		0.420392
  validation accuracy:		91.41 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.161236
  validation loss:		0.441558
  validation accuracy:		90.76 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.166461
  validation loss:		0.438373
  validation accuracy:		90.33 %
Epoch 1416 of 2000 took 0.097s
  training loss:		0.162434
  validation loss:		0.423368
  validation accuracy:		90.76 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.160292
  validation loss:		0.436258
  validation accuracy:		90.76 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.159958
  validation loss:		0.439636
  validation accuracy:		90.43 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.168360
  validation loss:		0.444238
  validation accuracy:		90.11 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.158434
  validation loss:		0.441149
  validation accuracy:		90.33 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.166771
  validation loss:		0.434018
  validation accuracy:		90.54 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.159650
  validation loss:		0.435501
  validation accuracy:		90.65 %
Epoch 1423 of 2000 took 0.097s
  training loss:		0.166491
  validation loss:		0.430773
  validation accuracy:		90.76 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.162798
  validation loss:		0.443953
  validation accuracy:		89.24 %
Epoch 1425 of 2000 took 0.097s
  training loss:		0.170286
  validation loss:		0.438944
  validation accuracy:		90.76 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.158392
  validation loss:		0.450540
  validation accuracy:		90.00 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.169508
  validation loss:		0.476193
  validation accuracy:		88.70 %
Epoch 1428 of 2000 took 0.097s
  training loss:		0.161055
  validation loss:		0.460055
  validation accuracy:		89.67 %
Epoch 1429 of 2000 took 0.099s
  training loss:		0.161097
  validation loss:		0.439623
  validation accuracy:		90.00 %
Epoch 1430 of 2000 took 0.097s
  training loss:		0.165341
  validation loss:		0.427693
  validation accuracy:		90.87 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.158915
  validation loss:		0.434399
  validation accuracy:		90.00 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.163146
  validation loss:		0.457659
  validation accuracy:		90.33 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.156388
  validation loss:		0.426762
  validation accuracy:		91.09 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.157722
  validation loss:		0.440647
  validation accuracy:		90.76 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.162672
  validation loss:		0.443198
  validation accuracy:		90.33 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.161164
  validation loss:		0.427522
  validation accuracy:		90.76 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.160887
  validation loss:		0.432768
  validation accuracy:		90.65 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.154557
  validation loss:		0.442085
  validation accuracy:		90.43 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.161724
  validation loss:		0.449391
  validation accuracy:		89.89 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.163690
  validation loss:		0.441424
  validation accuracy:		90.76 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.156220
  validation loss:		0.437306
  validation accuracy:		90.22 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.156023
  validation loss:		0.452439
  validation accuracy:		90.33 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.162099
  validation loss:		0.435880
  validation accuracy:		90.65 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.159742
  validation loss:		0.423676
  validation accuracy:		90.87 %
Epoch 1445 of 2000 took 0.097s
  training loss:		0.163140
  validation loss:		0.441844
  validation accuracy:		90.54 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.159311
  validation loss:		0.426741
  validation accuracy:		90.76 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.159500
  validation loss:		0.446350
  validation accuracy:		90.76 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.161424
  validation loss:		0.436595
  validation accuracy:		90.65 %
Epoch 1449 of 2000 took 0.097s
  training loss:		0.164579
  validation loss:		0.444570
  validation accuracy:		90.22 %
Epoch 1450 of 2000 took 0.097s
  training loss:		0.158826
  validation loss:		0.473973
  validation accuracy:		89.78 %
Epoch 1451 of 2000 took 0.097s
  training loss:		0.163472
  validation loss:		0.422733
  validation accuracy:		90.98 %
Epoch 1452 of 2000 took 0.097s
  training loss:		0.157237
  validation loss:		0.479728
  validation accuracy:		89.57 %
Epoch 1453 of 2000 took 0.097s
  training loss:		0.161778
  validation loss:		0.446444
  validation accuracy:		89.89 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.156415
  validation loss:		0.424205
  validation accuracy:		91.30 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.160003
  validation loss:		0.443869
  validation accuracy:		90.65 %
Epoch 1456 of 2000 took 0.097s
  training loss:		0.163522
  validation loss:		0.433267
  validation accuracy:		90.98 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.159977
  validation loss:		0.447938
  validation accuracy:		90.54 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.157513
  validation loss:		0.444236
  validation accuracy:		90.65 %
Epoch 1459 of 2000 took 0.097s
  training loss:		0.156808
  validation loss:		0.453536
  validation accuracy:		90.76 %
Epoch 1460 of 2000 took 0.097s
  training loss:		0.153464
  validation loss:		0.444865
  validation accuracy:		90.76 %
Epoch 1461 of 2000 took 0.097s
  training loss:		0.157317
  validation loss:		0.445274
  validation accuracy:		90.65 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.159542
  validation loss:		0.446195
  validation accuracy:		90.43 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.156136
  validation loss:		0.444863
  validation accuracy:		90.43 %
Epoch 1464 of 2000 took 0.097s
  training loss:		0.151254
  validation loss:		0.438175
  validation accuracy:		90.43 %
Epoch 1465 of 2000 took 0.097s
  training loss:		0.159371
  validation loss:		0.442642
  validation accuracy:		90.43 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.161166
  validation loss:		0.448191
  validation accuracy:		90.22 %
Epoch 1467 of 2000 took 0.097s
  training loss:		0.159918
  validation loss:		0.425394
  validation accuracy:		91.41 %
Epoch 1468 of 2000 took 0.097s
  training loss:		0.163613
  validation loss:		0.446345
  validation accuracy:		90.11 %
Epoch 1469 of 2000 took 0.097s
  training loss:		0.159495
  validation loss:		0.437228
  validation accuracy:		90.65 %
Epoch 1470 of 2000 took 0.097s
  training loss:		0.159385
  validation loss:		0.457116
  validation accuracy:		90.00 %
Epoch 1471 of 2000 took 0.097s
  training loss:		0.163954
  validation loss:		0.444959
  validation accuracy:		90.33 %
Epoch 1472 of 2000 took 0.097s
  training loss:		0.157599
  validation loss:		0.449111
  validation accuracy:		90.76 %
Epoch 1473 of 2000 took 0.097s
  training loss:		0.159929
  validation loss:		0.461856
  validation accuracy:		90.22 %
Epoch 1474 of 2000 took 0.097s
  training loss:		0.166731
  validation loss:		0.460730
  validation accuracy:		89.78 %
Epoch 1475 of 2000 took 0.097s
  training loss:		0.157791
  validation loss:		0.442384
  validation accuracy:		90.76 %
Epoch 1476 of 2000 took 0.097s
  training loss:		0.160868
  validation loss:		0.437137
  validation accuracy:		90.54 %
Epoch 1477 of 2000 took 0.097s
  training loss:		0.156261
  validation loss:		0.437123
  validation accuracy:		90.87 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.159352
  validation loss:		0.441984
  validation accuracy:		90.33 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.149923
  validation loss:		0.441183
  validation accuracy:		90.43 %
Epoch 1480 of 2000 took 0.097s
  training loss:		0.159393
  validation loss:		0.447945
  validation accuracy:		90.65 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.158655
  validation loss:		0.443397
  validation accuracy:		90.54 %
Epoch 1482 of 2000 took 0.097s
  training loss:		0.158636
  validation loss:		0.453424
  validation accuracy:		89.89 %
Epoch 1483 of 2000 took 0.097s
  training loss:		0.165874
  validation loss:		0.442965
  validation accuracy:		90.76 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.157223
  validation loss:		0.463868
  validation accuracy:		90.54 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.161108
  validation loss:		0.438079
  validation accuracy:		90.76 %
Epoch 1486 of 2000 took 0.097s
  training loss:		0.158054
  validation loss:		0.474854
  validation accuracy:		90.33 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.163234
  validation loss:		0.449372
  validation accuracy:		90.43 %
Epoch 1488 of 2000 took 0.097s
  training loss:		0.156350
  validation loss:		0.430189
  validation accuracy:		90.98 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.159114
  validation loss:		0.444536
  validation accuracy:		90.43 %
Epoch 1490 of 2000 took 0.097s
  training loss:		0.156428
  validation loss:		0.439954
  validation accuracy:		90.76 %
Epoch 1491 of 2000 took 0.097s
  training loss:		0.159219
  validation loss:		0.458545
  validation accuracy:		90.54 %
Epoch 1492 of 2000 took 0.097s
  training loss:		0.155947
  validation loss:		0.467051
  validation accuracy:		90.76 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.159381
  validation loss:		0.446477
  validation accuracy:		90.65 %
Epoch 1494 of 2000 took 0.100s
  training loss:		0.162002
  validation loss:		0.463217
  validation accuracy:		90.00 %
Epoch 1495 of 2000 took 0.100s
  training loss:		0.159297
  validation loss:		0.431387
  validation accuracy:		91.20 %
Epoch 1496 of 2000 took 0.100s
  training loss:		0.157432
  validation loss:		0.439258
  validation accuracy:		90.87 %
Epoch 1497 of 2000 took 0.100s
  training loss:		0.157125
  validation loss:		0.452924
  validation accuracy:		90.54 %
Epoch 1498 of 2000 took 0.100s
  training loss:		0.154574
  validation loss:		0.448020
  validation accuracy:		90.76 %
Epoch 1499 of 2000 took 0.100s
  training loss:		0.155822
  validation loss:		0.442566
  validation accuracy:		90.22 %
Epoch 1500 of 2000 took 0.098s
  training loss:		0.161486
  validation loss:		0.465409
  validation accuracy:		89.67 %
Epoch 1501 of 2000 took 0.097s
  training loss:		0.160237
  validation loss:		0.431185
  validation accuracy:		90.87 %
Epoch 1502 of 2000 took 0.097s
  training loss:		0.159294
  validation loss:		0.478417
  validation accuracy:		89.89 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.162629
  validation loss:		0.444091
  validation accuracy:		90.54 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.157018
  validation loss:		0.458205
  validation accuracy:		90.43 %
Epoch 1505 of 2000 took 0.097s
  training loss:		0.157854
  validation loss:		0.442510
  validation accuracy:		90.87 %
Epoch 1506 of 2000 took 0.097s
  training loss:		0.153047
  validation loss:		0.452551
  validation accuracy:		90.76 %
Epoch 1507 of 2000 took 0.097s
  training loss:		0.159792
  validation loss:		0.446975
  validation accuracy:		90.43 %
Epoch 1508 of 2000 took 0.097s
  training loss:		0.157560
  validation loss:		0.464851
  validation accuracy:		90.65 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.154246
  validation loss:		0.448059
  validation accuracy:		91.09 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.158203
  validation loss:		0.491819
  validation accuracy:		90.00 %
Epoch 1511 of 2000 took 0.097s
  training loss:		0.156350
  validation loss:		0.438321
  validation accuracy:		91.20 %
Epoch 1512 of 2000 took 0.097s
  training loss:		0.158209
  validation loss:		0.438789
  validation accuracy:		91.20 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.160013
  validation loss:		0.452854
  validation accuracy:		90.33 %
Epoch 1514 of 2000 took 0.097s
  training loss:		0.164556
  validation loss:		0.464723
  validation accuracy:		89.78 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.157643
  validation loss:		0.453944
  validation accuracy:		90.65 %
Epoch 1516 of 2000 took 0.097s
  training loss:		0.158269
  validation loss:		0.479711
  validation accuracy:		90.54 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.161952
  validation loss:		0.445736
  validation accuracy:		90.76 %
Epoch 1518 of 2000 took 0.097s
  training loss:		0.159688
  validation loss:		0.461425
  validation accuracy:		90.43 %
Epoch 1519 of 2000 took 0.097s
  training loss:		0.155601
  validation loss:		0.488072
  validation accuracy:		90.11 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.164614
  validation loss:		0.473390
  validation accuracy:		89.89 %
Epoch 1521 of 2000 took 0.097s
  training loss:		0.164429
  validation loss:		0.453204
  validation accuracy:		90.65 %
Epoch 1522 of 2000 took 0.097s
  training loss:		0.165428
  validation loss:		0.434201
  validation accuracy:		90.98 %
Epoch 1523 of 2000 took 0.097s
  training loss:		0.156601
  validation loss:		0.447095
  validation accuracy:		90.76 %
Epoch 1524 of 2000 took 0.097s
  training loss:		0.159196
  validation loss:		0.465222
  validation accuracy:		90.33 %
Epoch 1525 of 2000 took 0.097s
  training loss:		0.159352
  validation loss:		0.459216
  validation accuracy:		90.22 %
Epoch 1526 of 2000 took 0.097s
  training loss:		0.157825
  validation loss:		0.450104
  validation accuracy:		90.54 %
Epoch 1527 of 2000 took 0.097s
  training loss:		0.159383
  validation loss:		0.454290
  validation accuracy:		90.65 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.155400
  validation loss:		0.462396
  validation accuracy:		90.22 %
Epoch 1529 of 2000 took 0.097s
  training loss:		0.157658
  validation loss:		0.448786
  validation accuracy:		90.43 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.157615
  validation loss:		0.465575
  validation accuracy:		90.00 %
Epoch 1531 of 2000 took 0.097s
  training loss:		0.151456
  validation loss:		0.474911
  validation accuracy:		90.00 %
Epoch 1532 of 2000 took 0.097s
  training loss:		0.154780
  validation loss:		0.445900
  validation accuracy:		90.43 %
Epoch 1533 of 2000 took 0.097s
  training loss:		0.159343
  validation loss:		0.470619
  validation accuracy:		90.22 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.153633
  validation loss:		0.449450
  validation accuracy:		90.54 %
Epoch 1535 of 2000 took 0.098s
  training loss:		0.156489
  validation loss:		0.450180
  validation accuracy:		90.76 %
Epoch 1536 of 2000 took 0.097s
  training loss:		0.151765
  validation loss:		0.455489
  validation accuracy:		89.67 %
Epoch 1537 of 2000 took 0.097s
  training loss:		0.157328
  validation loss:		0.473870
  validation accuracy:		90.54 %
Epoch 1538 of 2000 took 0.097s
  training loss:		0.156631
  validation loss:		0.458342
  validation accuracy:		90.76 %
Epoch 1539 of 2000 took 0.097s
  training loss:		0.157580
  validation loss:		0.478749
  validation accuracy:		90.33 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.160076
  validation loss:		0.455053
  validation accuracy:		90.87 %
Epoch 1541 of 2000 took 0.097s
  training loss:		0.156866
  validation loss:		0.458269
  validation accuracy:		90.54 %
Epoch 1542 of 2000 took 0.097s
  training loss:		0.165274
  validation loss:		0.466071
  validation accuracy:		90.54 %
Epoch 1543 of 2000 took 0.097s
  training loss:		0.160252
  validation loss:		0.447129
  validation accuracy:		90.76 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.150958
  validation loss:		0.451925
  validation accuracy:		90.54 %
Epoch 1545 of 2000 took 0.097s
  training loss:		0.155566
  validation loss:		0.449448
  validation accuracy:		90.87 %
Epoch 1546 of 2000 took 0.097s
  training loss:		0.156441
  validation loss:		0.479098
  validation accuracy:		90.76 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.156346
  validation loss:		0.448660
  validation accuracy:		90.54 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.161646
  validation loss:		0.450048
  validation accuracy:		90.76 %
Epoch 1549 of 2000 took 0.097s
  training loss:		0.153095
  validation loss:		0.466659
  validation accuracy:		90.43 %
Epoch 1550 of 2000 took 0.097s
  training loss:		0.151636
  validation loss:		0.467350
  validation accuracy:		90.33 %
Epoch 1551 of 2000 took 0.097s
  training loss:		0.162718
  validation loss:		0.498572
  validation accuracy:		89.78 %
Epoch 1552 of 2000 took 0.097s
  training loss:		0.163422
  validation loss:		0.464421
  validation accuracy:		90.43 %
Epoch 1553 of 2000 took 0.097s
  training loss:		0.164408
  validation loss:		0.462256
  validation accuracy:		90.11 %
Epoch 1554 of 2000 took 0.097s
  training loss:		0.154370
  validation loss:		0.452519
  validation accuracy:		90.87 %
Epoch 1555 of 2000 took 0.097s
  training loss:		0.149320
  validation loss:		0.455948
  validation accuracy:		90.76 %
Epoch 1556 of 2000 took 0.097s
  training loss:		0.162762
  validation loss:		0.472772
  validation accuracy:		90.11 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.164521
  validation loss:		0.454518
  validation accuracy:		90.43 %
Epoch 1558 of 2000 took 0.097s
  training loss:		0.154866
  validation loss:		0.474321
  validation accuracy:		90.43 %
Epoch 1559 of 2000 took 0.097s
  training loss:		0.157484
  validation loss:		0.452768
  validation accuracy:		90.76 %
Epoch 1560 of 2000 took 0.097s
  training loss:		0.151962
  validation loss:		0.491170
  validation accuracy:		90.00 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.156008
  validation loss:		0.494403
  validation accuracy:		90.22 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.159303
  validation loss:		0.478899
  validation accuracy:		90.33 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.157373
  validation loss:		0.446542
  validation accuracy:		90.87 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.159238
  validation loss:		0.451294
  validation accuracy:		91.30 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.159421
  validation loss:		0.447133
  validation accuracy:		90.65 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.159849
  validation loss:		0.459058
  validation accuracy:		90.33 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.152876
  validation loss:		0.468121
  validation accuracy:		90.54 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.155541
  validation loss:		0.486068
  validation accuracy:		90.11 %
Epoch 1569 of 2000 took 0.097s
  training loss:		0.156437
  validation loss:		0.466100
  validation accuracy:		89.89 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.153086
  validation loss:		0.491854
  validation accuracy:		90.11 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.164814
  validation loss:		0.466566
  validation accuracy:		90.33 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.157337
  validation loss:		0.460854
  validation accuracy:		90.65 %
Epoch 1573 of 2000 took 0.097s
  training loss:		0.157499
  validation loss:		0.465588
  validation accuracy:		90.65 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.155966
  validation loss:		0.466697
  validation accuracy:		90.76 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.152600
  validation loss:		0.462222
  validation accuracy:		90.11 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.151998
  validation loss:		0.477648
  validation accuracy:		90.00 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.162102
  validation loss:		0.457302
  validation accuracy:		91.20 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.160625
  validation loss:		0.477637
  validation accuracy:		90.43 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.161666
  validation loss:		0.499820
  validation accuracy:		90.00 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.158402
  validation loss:		0.477587
  validation accuracy:		90.54 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.157511
  validation loss:		0.468146
  validation accuracy:		90.76 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.160846
  validation loss:		0.467335
  validation accuracy:		90.22 %
Epoch 1583 of 2000 took 0.097s
  training loss:		0.153764
  validation loss:		0.479850
  validation accuracy:		90.33 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.162776
  validation loss:		0.467895
  validation accuracy:		90.76 %
Epoch 1585 of 2000 took 0.097s
  training loss:		0.152757
  validation loss:		0.473844
  validation accuracy:		90.22 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.156568
  validation loss:		0.471750
  validation accuracy:		90.76 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.157187
  validation loss:		0.497441
  validation accuracy:		89.89 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.160144
  validation loss:		0.465830
  validation accuracy:		90.33 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.157563
  validation loss:		0.459868
  validation accuracy:		90.65 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.159682
  validation loss:		0.474203
  validation accuracy:		90.87 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.158975
  validation loss:		0.465237
  validation accuracy:		90.22 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.155655
  validation loss:		0.478795
  validation accuracy:		90.33 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.153116
  validation loss:		0.481009
  validation accuracy:		90.33 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.155907
  validation loss:		0.469919
  validation accuracy:		89.78 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.158374
  validation loss:		0.448032
  validation accuracy:		90.76 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.158143
  validation loss:		0.461801
  validation accuracy:		90.54 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.153326
  validation loss:		0.476460
  validation accuracy:		90.43 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.154269
  validation loss:		0.474848
  validation accuracy:		89.78 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.150544
  validation loss:		0.462370
  validation accuracy:		91.09 %
Epoch 1600 of 2000 took 0.097s
  training loss:		0.156868
  validation loss:		0.458768
  validation accuracy:		90.22 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.156686
  validation loss:		0.462369
  validation accuracy:		90.76 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.161121
  validation loss:		0.470659
  validation accuracy:		90.33 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.155071
  validation loss:		0.487266
  validation accuracy:		90.87 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.156452
  validation loss:		0.461513
  validation accuracy:		90.76 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.159322
  validation loss:		0.467158
  validation accuracy:		90.65 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.153834
  validation loss:		0.479078
  validation accuracy:		90.22 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.159019
  validation loss:		0.466625
  validation accuracy:		90.33 %
Epoch 1608 of 2000 took 0.097s
  training loss:		0.159996
  validation loss:		0.467079
  validation accuracy:		90.65 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.153706
  validation loss:		0.482009
  validation accuracy:		90.54 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.152440
  validation loss:		0.464996
  validation accuracy:		91.09 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.153447
  validation loss:		0.484548
  validation accuracy:		89.89 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.157753
  validation loss:		0.516463
  validation accuracy:		88.91 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.162185
  validation loss:		0.451624
  validation accuracy:		90.87 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.154970
  validation loss:		0.461417
  validation accuracy:		90.65 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.150608
  validation loss:		0.481943
  validation accuracy:		89.89 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.154222
  validation loss:		0.480761
  validation accuracy:		90.54 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.159764
  validation loss:		0.467426
  validation accuracy:		90.22 %
Epoch 1618 of 2000 took 0.097s
  training loss:		0.158904
  validation loss:		0.461051
  validation accuracy:		90.98 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.160020
  validation loss:		0.464165
  validation accuracy:		90.98 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.155339
  validation loss:		0.482068
  validation accuracy:		90.33 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.156938
  validation loss:		0.475502
  validation accuracy:		90.33 %
Epoch 1622 of 2000 took 0.097s
  training loss:		0.152062
  validation loss:		0.468552
  validation accuracy:		90.54 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.156800
  validation loss:		0.485267
  validation accuracy:		90.65 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.164546
  validation loss:		0.480697
  validation accuracy:		90.87 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.164714
  validation loss:		0.478032
  validation accuracy:		90.22 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.159297
  validation loss:		0.474694
  validation accuracy:		90.54 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.156346
  validation loss:		0.455658
  validation accuracy:		90.76 %
Epoch 1628 of 2000 took 0.097s
  training loss:		0.150910
  validation loss:		0.481744
  validation accuracy:		90.33 %
Epoch 1629 of 2000 took 0.097s
  training loss:		0.159756
  validation loss:		0.494259
  validation accuracy:		90.22 %
Epoch 1630 of 2000 took 0.097s
  training loss:		0.158192
  validation loss:		0.475006
  validation accuracy:		90.65 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.153664
  validation loss:		0.488015
  validation accuracy:		90.33 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.154329
  validation loss:		0.466161
  validation accuracy:		90.76 %
Epoch 1633 of 2000 took 0.097s
  training loss:		0.154909
  validation loss:		0.505777
  validation accuracy:		89.46 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.160596
  validation loss:		0.480924
  validation accuracy:		90.54 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.156734
  validation loss:		0.494651
  validation accuracy:		90.43 %
Epoch 1636 of 2000 took 0.097s
  training loss:		0.154081
  validation loss:		0.512030
  validation accuracy:		89.67 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.154314
  validation loss:		0.472758
  validation accuracy:		90.76 %
Epoch 1638 of 2000 took 0.097s
  training loss:		0.152435
  validation loss:		0.481906
  validation accuracy:		90.43 %
Epoch 1639 of 2000 took 0.097s
  training loss:		0.151581
  validation loss:		0.496537
  validation accuracy:		90.11 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.161694
  validation loss:		0.463201
  validation accuracy:		91.20 %
Epoch 1641 of 2000 took 0.097s
  training loss:		0.156645
  validation loss:		0.491669
  validation accuracy:		90.11 %
Epoch 1642 of 2000 took 0.097s
  training loss:		0.158087
  validation loss:		0.463367
  validation accuracy:		90.76 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.152950
  validation loss:		0.488586
  validation accuracy:		90.65 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.156866
  validation loss:		0.485516
  validation accuracy:		90.54 %
Epoch 1645 of 2000 took 0.097s
  training loss:		0.154280
  validation loss:		0.486993
  validation accuracy:		90.65 %
Epoch 1646 of 2000 took 0.097s
  training loss:		0.156596
  validation loss:		0.463546
  validation accuracy:		90.65 %
Epoch 1647 of 2000 took 0.097s
  training loss:		0.155929
  validation loss:		0.465014
  validation accuracy:		91.09 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.154172
  validation loss:		0.487317
  validation accuracy:		89.78 %
Epoch 1649 of 2000 took 0.097s
  training loss:		0.155873
  validation loss:		0.511019
  validation accuracy:		89.24 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.156181
  validation loss:		0.470576
  validation accuracy:		91.20 %
Epoch 1651 of 2000 took 0.097s
  training loss:		0.151247
  validation loss:		0.499320
  validation accuracy:		90.43 %
Epoch 1652 of 2000 took 0.097s
  training loss:		0.153552
  validation loss:		0.474913
  validation accuracy:		90.76 %
Epoch 1653 of 2000 took 0.097s
  training loss:		0.153551
  validation loss:		0.470996
  validation accuracy:		90.98 %
Epoch 1654 of 2000 took 0.097s
  training loss:		0.149690
  validation loss:		0.483528
  validation accuracy:		90.11 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.152108
  validation loss:		0.484022
  validation accuracy:		90.33 %
Epoch 1656 of 2000 took 0.097s
  training loss:		0.156933
  validation loss:		0.466059
  validation accuracy:		90.76 %
Epoch 1657 of 2000 took 0.097s
  training loss:		0.154071
  validation loss:		0.502732
  validation accuracy:		89.02 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.154397
  validation loss:		0.490015
  validation accuracy:		90.11 %
Epoch 1659 of 2000 took 0.097s
  training loss:		0.160294
  validation loss:		0.483091
  validation accuracy:		90.65 %
Epoch 1660 of 2000 took 0.097s
  training loss:		0.154764
  validation loss:		0.488002
  validation accuracy:		90.76 %
Epoch 1661 of 2000 took 0.097s
  training loss:		0.154929
  validation loss:		0.497256
  validation accuracy:		90.00 %
Epoch 1662 of 2000 took 0.097s
  training loss:		0.156164
  validation loss:		0.514376
  validation accuracy:		89.78 %
Epoch 1663 of 2000 took 0.097s
  training loss:		0.156152
  validation loss:		0.479912
  validation accuracy:		90.65 %
Epoch 1664 of 2000 took 0.097s
  training loss:		0.153020
  validation loss:		0.472739
  validation accuracy:		90.54 %
Epoch 1665 of 2000 took 0.097s
  training loss:		0.145922
  validation loss:		0.467135
  validation accuracy:		90.43 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.152138
  validation loss:		0.570991
  validation accuracy:		88.91 %
Epoch 1667 of 2000 took 0.097s
  training loss:		0.158938
  validation loss:		0.515095
  validation accuracy:		90.43 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.153005
  validation loss:		0.497637
  validation accuracy:		90.43 %
Epoch 1669 of 2000 took 0.099s
  training loss:		0.153424
  validation loss:		0.483069
  validation accuracy:		90.98 %
Epoch 1670 of 2000 took 0.097s
  training loss:		0.154748
  validation loss:		0.497202
  validation accuracy:		90.65 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.162040
  validation loss:		0.480331
  validation accuracy:		90.22 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.154546
  validation loss:		0.493759
  validation accuracy:		90.87 %
Epoch 1673 of 2000 took 0.097s
  training loss:		0.151472
  validation loss:		0.494905
  validation accuracy:		90.98 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.153848
  validation loss:		0.495102
  validation accuracy:		90.00 %
Epoch 1675 of 2000 took 0.097s
  training loss:		0.154244
  validation loss:		0.493096
  validation accuracy:		90.11 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.148195
  validation loss:		0.481989
  validation accuracy:		90.43 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.161250
  validation loss:		0.481554
  validation accuracy:		90.87 %
Epoch 1678 of 2000 took 0.097s
  training loss:		0.149981
  validation loss:		0.482171
  validation accuracy:		90.11 %
Epoch 1679 of 2000 took 0.097s
  training loss:		0.159130
  validation loss:		0.482204
  validation accuracy:		89.89 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.154824
  validation loss:		0.479638
  validation accuracy:		90.22 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.154474
  validation loss:		0.484264
  validation accuracy:		90.00 %
Epoch 1682 of 2000 took 0.097s
  training loss:		0.159765
  validation loss:		0.504086
  validation accuracy:		90.43 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.155353
  validation loss:		0.502955
  validation accuracy:		89.78 %
Epoch 1684 of 2000 took 0.097s
  training loss:		0.147971
  validation loss:		0.486974
  validation accuracy:		90.76 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.155094
  validation loss:		0.497182
  validation accuracy:		90.87 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.153843
  validation loss:		0.533048
  validation accuracy:		89.13 %
Epoch 1687 of 2000 took 0.097s
  training loss:		0.150354
  validation loss:		0.503070
  validation accuracy:		90.33 %
Epoch 1688 of 2000 took 0.097s
  training loss:		0.159649
  validation loss:		0.490202
  validation accuracy:		90.33 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.146850
  validation loss:		0.503989
  validation accuracy:		90.98 %
Epoch 1690 of 2000 took 0.097s
  training loss:		0.155155
  validation loss:		0.477667
  validation accuracy:		90.76 %
Epoch 1691 of 2000 took 0.097s
  training loss:		0.154332
  validation loss:		0.512767
  validation accuracy:		90.54 %
Epoch 1692 of 2000 took 0.097s
  training loss:		0.156267
  validation loss:		0.518124
  validation accuracy:		89.89 %
Epoch 1693 of 2000 took 0.097s
  training loss:		0.152871
  validation loss:		0.536417
  validation accuracy:		89.02 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.149799
  validation loss:		0.501605
  validation accuracy:		90.22 %
Epoch 1695 of 2000 took 0.097s
  training loss:		0.160307
  validation loss:		0.482990
  validation accuracy:		90.87 %
Epoch 1696 of 2000 took 0.097s
  training loss:		0.154450
  validation loss:		0.508666
  validation accuracy:		90.33 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.158767
  validation loss:		0.478576
  validation accuracy:		90.65 %
Epoch 1698 of 2000 took 0.097s
  training loss:		0.146164
  validation loss:		0.483781
  validation accuracy:		90.87 %
Epoch 1699 of 2000 took 0.097s
  training loss:		0.150184
  validation loss:		0.502064
  validation accuracy:		90.87 %
Epoch 1700 of 2000 took 0.097s
  training loss:		0.154745
  validation loss:		0.487822
  validation accuracy:		90.65 %
Epoch 1701 of 2000 took 0.101s
  training loss:		0.156329
  validation loss:		0.518401
  validation accuracy:		90.11 %
Epoch 1702 of 2000 took 0.103s
  training loss:		0.156267
  validation loss:		0.556617
  validation accuracy:		88.15 %
Epoch 1703 of 2000 took 0.107s
  training loss:		0.150980
  validation loss:		0.500084
  validation accuracy:		90.98 %
Epoch 1704 of 2000 took 0.139s
  training loss:		0.155391
  validation loss:		0.483997
  validation accuracy:		90.65 %
Epoch 1705 of 2000 took 0.097s
  training loss:		0.161868
  validation loss:		0.513025
  validation accuracy:		90.33 %
Epoch 1706 of 2000 took 0.100s
  training loss:		0.148073
  validation loss:		0.489440
  validation accuracy:		90.22 %
Epoch 1707 of 2000 took 0.100s
  training loss:		0.158017
  validation loss:		0.495263
  validation accuracy:		90.98 %
Epoch 1708 of 2000 took 0.104s
  training loss:		0.151477
  validation loss:		0.494428
  validation accuracy:		90.22 %
Epoch 1709 of 2000 took 0.101s
  training loss:		0.161568
  validation loss:		0.510135
  validation accuracy:		90.54 %
Epoch 1710 of 2000 took 0.097s
  training loss:		0.160788
  validation loss:		0.505046
  validation accuracy:		90.76 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.150388
  validation loss:		0.482977
  validation accuracy:		90.54 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.153457
  validation loss:		0.496910
  validation accuracy:		90.76 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.159835
  validation loss:		0.524415
  validation accuracy:		89.13 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.156971
  validation loss:		0.537401
  validation accuracy:		89.35 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.149627
  validation loss:		0.493656
  validation accuracy:		90.87 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.152593
  validation loss:		0.521953
  validation accuracy:		90.22 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.154129
  validation loss:		0.522422
  validation accuracy:		90.33 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.165730
  validation loss:		0.504847
  validation accuracy:		90.65 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.153408
  validation loss:		0.491737
  validation accuracy:		90.65 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.154702
  validation loss:		0.503901
  validation accuracy:		90.76 %
Epoch 1721 of 2000 took 0.097s
  training loss:		0.152873
  validation loss:		0.502848
  validation accuracy:		90.76 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.156521
  validation loss:		0.536496
  validation accuracy:		89.57 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.159035
  validation loss:		0.531028
  validation accuracy:		90.11 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.157160
  validation loss:		0.503862
  validation accuracy:		90.00 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.156610
  validation loss:		0.488566
  validation accuracy:		90.98 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.158899
  validation loss:		0.487444
  validation accuracy:		90.65 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.152916
  validation loss:		0.498066
  validation accuracy:		90.76 %
Epoch 1728 of 2000 took 0.096s
  training loss:		0.155455
  validation loss:		0.519437
  validation accuracy:		90.33 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.155696
  validation loss:		0.481577
  validation accuracy:		90.65 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.151828
  validation loss:		0.507467
  validation accuracy:		90.43 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.166044
  validation loss:		0.522852
  validation accuracy:		90.11 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.154319
  validation loss:		0.488676
  validation accuracy:		90.98 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.151932
  validation loss:		0.483297
  validation accuracy:		90.87 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.145855
  validation loss:		0.513144
  validation accuracy:		89.89 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.149418
  validation loss:		0.498033
  validation accuracy:		90.54 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.151138
  validation loss:		0.513023
  validation accuracy:		90.54 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.151570
  validation loss:		0.496458
  validation accuracy:		90.43 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.157646
  validation loss:		0.492399
  validation accuracy:		90.65 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.150917
  validation loss:		0.517645
  validation accuracy:		90.00 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.152899
  validation loss:		0.489342
  validation accuracy:		90.54 %
Epoch 1741 of 2000 took 0.097s
  training loss:		0.150537
  validation loss:		0.504399
  validation accuracy:		90.65 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.157044
  validation loss:		0.518139
  validation accuracy:		89.67 %
Epoch 1743 of 2000 took 0.098s
  training loss:		0.161181
  validation loss:		0.510241
  validation accuracy:		90.65 %
Epoch 1744 of 2000 took 0.147s
  training loss:		0.156625
  validation loss:		0.488587
  validation accuracy:		90.33 %
Epoch 1745 of 2000 took 0.164s
  training loss:		0.157294
  validation loss:		0.524343
  validation accuracy:		90.22 %
Epoch 1746 of 2000 took 0.164s
  training loss:		0.154996
  validation loss:		0.476271
  validation accuracy:		91.09 %
Epoch 1747 of 2000 took 0.164s
  training loss:		0.157390
  validation loss:		0.492696
  validation accuracy:		90.33 %
Epoch 1748 of 2000 took 0.164s
  training loss:		0.147665
  validation loss:		0.524170
  validation accuracy:		89.57 %
Epoch 1749 of 2000 took 0.122s
  training loss:		0.154224
  validation loss:		0.531390
  validation accuracy:		90.11 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.147876
  validation loss:		0.497411
  validation accuracy:		90.76 %
Epoch 1751 of 2000 took 0.099s
  training loss:		0.152316
  validation loss:		0.511655
  validation accuracy:		90.76 %
Epoch 1752 of 2000 took 0.103s
  training loss:		0.152812
  validation loss:		0.502448
  validation accuracy:		90.33 %
Epoch 1753 of 2000 took 0.104s
  training loss:		0.150142
  validation loss:		0.515992
  validation accuracy:		90.33 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.154285
  validation loss:		0.513919
  validation accuracy:		90.11 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.154686
  validation loss:		0.517161
  validation accuracy:		90.43 %
Epoch 1756 of 2000 took 0.098s
  training loss:		0.153971
  validation loss:		0.511240
  validation accuracy:		90.65 %
Epoch 1757 of 2000 took 0.099s
  training loss:		0.151328
  validation loss:		0.497718
  validation accuracy:		90.33 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.155092
  validation loss:		0.498083
  validation accuracy:		90.54 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.152405
  validation loss:		0.526161
  validation accuracy:		89.89 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.150251
  validation loss:		0.506879
  validation accuracy:		90.76 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.152738
  validation loss:		0.525555
  validation accuracy:		89.67 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.150219
  validation loss:		0.483804
  validation accuracy:		90.43 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.157097
  validation loss:		0.508764
  validation accuracy:		89.78 %
Epoch 1764 of 2000 took 0.099s
  training loss:		0.157508
  validation loss:		0.523706
  validation accuracy:		90.11 %
Epoch 1765 of 2000 took 0.104s
  training loss:		0.146898
  validation loss:		0.505085
  validation accuracy:		90.65 %
Epoch 1766 of 2000 took 0.099s
  training loss:		0.156271
  validation loss:		0.510520
  validation accuracy:		90.00 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.153142
  validation loss:		0.514491
  validation accuracy:		90.22 %
Epoch 1768 of 2000 took 0.100s
  training loss:		0.154699
  validation loss:		0.493502
  validation accuracy:		90.65 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.150635
  validation loss:		0.507963
  validation accuracy:		90.11 %
Epoch 1770 of 2000 took 0.097s
  training loss:		0.147992
  validation loss:		0.515161
  validation accuracy:		90.22 %
Epoch 1771 of 2000 took 0.097s
  training loss:		0.155511
  validation loss:		0.499905
  validation accuracy:		90.76 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.155354
  validation loss:		0.518483
  validation accuracy:		90.00 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.153774
  validation loss:		0.498084
  validation accuracy:		90.43 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.154429
  validation loss:		0.504219
  validation accuracy:		90.11 %
Epoch 1775 of 2000 took 0.097s
  training loss:		0.154310
  validation loss:		0.500699
  validation accuracy:		90.76 %
Epoch 1776 of 2000 took 0.097s
  training loss:		0.147526
  validation loss:		0.586492
  validation accuracy:		88.91 %
Epoch 1777 of 2000 took 0.097s
  training loss:		0.157391
  validation loss:		0.493959
  validation accuracy:		90.22 %
Epoch 1778 of 2000 took 0.097s
  training loss:		0.156059
  validation loss:		0.548239
  validation accuracy:		90.22 %
Epoch 1779 of 2000 took 0.097s
  training loss:		0.155874
  validation loss:		0.514558
  validation accuracy:		89.67 %
Epoch 1780 of 2000 took 0.097s
  training loss:		0.155710
  validation loss:		0.536854
  validation accuracy:		90.00 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.151483
  validation loss:		0.503654
  validation accuracy:		90.87 %
Epoch 1782 of 2000 took 0.097s
  training loss:		0.151645
  validation loss:		0.504041
  validation accuracy:		90.65 %
Epoch 1783 of 2000 took 0.097s
  training loss:		0.157360
  validation loss:		0.537224
  validation accuracy:		90.11 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.156857
  validation loss:		0.525907
  validation accuracy:		90.22 %
Epoch 1785 of 2000 took 0.097s
  training loss:		0.148920
  validation loss:		0.509004
  validation accuracy:		90.76 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.156812
  validation loss:		0.515107
  validation accuracy:		90.43 %
Epoch 1787 of 2000 took 0.097s
  training loss:		0.149522
  validation loss:		0.495756
  validation accuracy:		90.65 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.151940
  validation loss:		0.527394
  validation accuracy:		90.22 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.157280
  validation loss:		0.511475
  validation accuracy:		90.33 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.149738
  validation loss:		0.492460
  validation accuracy:		90.22 %
Epoch 1791 of 2000 took 0.097s
  training loss:		0.153551
  validation loss:		0.498268
  validation accuracy:		90.54 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.152307
  validation loss:		0.506504
  validation accuracy:		90.65 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.152602
  validation loss:		0.519884
  validation accuracy:		90.33 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.155838
  validation loss:		0.514411
  validation accuracy:		90.65 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.153914
  validation loss:		0.512528
  validation accuracy:		90.65 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.148693
  validation loss:		0.500043
  validation accuracy:		90.54 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.148879
  validation loss:		0.512055
  validation accuracy:		90.54 %
Epoch 1798 of 2000 took 0.097s
  training loss:		0.151878
  validation loss:		0.534915
  validation accuracy:		90.11 %
Epoch 1799 of 2000 took 0.097s
  training loss:		0.149432
  validation loss:		0.549656
  validation accuracy:		89.78 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.153589
  validation loss:		0.515089
  validation accuracy:		89.78 %
Epoch 1801 of 2000 took 0.097s
  training loss:		0.154220
  validation loss:		0.522564
  validation accuracy:		90.65 %
Epoch 1802 of 2000 took 0.097s
  training loss:		0.149298
  validation loss:		0.523471
  validation accuracy:		90.65 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.144317
  validation loss:		0.524314
  validation accuracy:		90.22 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.156633
  validation loss:		0.528007
  validation accuracy:		90.54 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.158419
  validation loss:		0.508872
  validation accuracy:		90.65 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.148359
  validation loss:		0.511333
  validation accuracy:		90.43 %
Epoch 1807 of 2000 took 0.097s
  training loss:		0.157790
  validation loss:		0.530901
  validation accuracy:		89.67 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.147738
  validation loss:		0.522312
  validation accuracy:		90.87 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.159183
  validation loss:		0.520599
  validation accuracy:		89.89 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.153872
  validation loss:		0.510850
  validation accuracy:		90.22 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.158113
  validation loss:		0.541170
  validation accuracy:		89.89 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.151391
  validation loss:		0.523685
  validation accuracy:		90.54 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.148355
  validation loss:		0.505870
  validation accuracy:		90.54 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.153386
  validation loss:		0.509126
  validation accuracy:		90.76 %
Epoch 1815 of 2000 took 0.097s
  training loss:		0.155839
  validation loss:		0.531647
  validation accuracy:		90.54 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.154050
  validation loss:		0.518031
  validation accuracy:		90.76 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.149650
  validation loss:		0.517849
  validation accuracy:		90.11 %
Epoch 1818 of 2000 took 0.097s
  training loss:		0.150919
  validation loss:		0.527725
  validation accuracy:		90.22 %
Epoch 1819 of 2000 took 0.097s
  training loss:		0.152584
  validation loss:		0.523555
  validation accuracy:		90.54 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.152096
  validation loss:		0.523166
  validation accuracy:		89.89 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.149216
  validation loss:		0.531601
  validation accuracy:		90.00 %
Epoch 1822 of 2000 took 0.097s
  training loss:		0.151114
  validation loss:		0.541461
  validation accuracy:		90.11 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.150423
  validation loss:		0.527530
  validation accuracy:		89.78 %
Epoch 1824 of 2000 took 0.097s
  training loss:		0.143272
  validation loss:		0.519871
  validation accuracy:		90.65 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.155502
  validation loss:		0.545778
  validation accuracy:		89.46 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.150275
  validation loss:		0.520562
  validation accuracy:		90.65 %
Epoch 1827 of 2000 took 0.097s
  training loss:		0.151869
  validation loss:		0.527507
  validation accuracy:		90.54 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.150827
  validation loss:		0.511206
  validation accuracy:		90.65 %
Epoch 1829 of 2000 took 0.097s
  training loss:		0.153604
  validation loss:		0.543241
  validation accuracy:		90.00 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.150335
  validation loss:		0.501912
  validation accuracy:		90.54 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.148161
  validation loss:		0.537749
  validation accuracy:		89.67 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.151931
  validation loss:		0.524662
  validation accuracy:		90.76 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.152409
  validation loss:		0.555163
  validation accuracy:		89.67 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.152842
  validation loss:		0.523487
  validation accuracy:		90.54 %
Epoch 1835 of 2000 took 0.097s
  training loss:		0.151068
  validation loss:		0.509978
  validation accuracy:		90.54 %
Epoch 1836 of 2000 took 0.097s
  training loss:		0.155520
  validation loss:		0.546418
  validation accuracy:		90.54 %
Epoch 1837 of 2000 took 0.097s
  training loss:		0.147627
  validation loss:		0.540491
  validation accuracy:		89.57 %
Epoch 1838 of 2000 took 0.097s
  training loss:		0.155710
  validation loss:		0.531611
  validation accuracy:		90.11 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.146182
  validation loss:		0.519743
  validation accuracy:		90.65 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.152353
  validation loss:		0.526362
  validation accuracy:		90.98 %
Epoch 1841 of 2000 took 0.097s
  training loss:		0.151704
  validation loss:		0.519661
  validation accuracy:		90.65 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.148942
  validation loss:		0.517076
  validation accuracy:		90.65 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.155231
  validation loss:		0.511965
  validation accuracy:		90.65 %
Epoch 1844 of 2000 took 0.097s
  training loss:		0.151655
  validation loss:		0.522602
  validation accuracy:		90.22 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.158225
  validation loss:		0.513827
  validation accuracy:		90.76 %
Epoch 1846 of 2000 took 0.097s
  training loss:		0.149481
  validation loss:		0.571786
  validation accuracy:		89.67 %
Epoch 1847 of 2000 took 0.097s
  training loss:		0.153580
  validation loss:		0.504589
  validation accuracy:		90.65 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.162224
  validation loss:		0.538423
  validation accuracy:		90.33 %
Epoch 1849 of 2000 took 0.097s
  training loss:		0.150214
  validation loss:		0.524678
  validation accuracy:		90.54 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.150463
  validation loss:		0.551463
  validation accuracy:		89.78 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.149562
  validation loss:		0.532965
  validation accuracy:		90.22 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.154571
  validation loss:		0.552634
  validation accuracy:		89.57 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.147295
  validation loss:		0.509172
  validation accuracy:		90.76 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.150573
  validation loss:		0.514005
  validation accuracy:		90.76 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.149629
  validation loss:		0.512999
  validation accuracy:		90.65 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.149343
  validation loss:		0.539954
  validation accuracy:		90.33 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.155009
  validation loss:		0.538720
  validation accuracy:		90.33 %
Epoch 1858 of 2000 took 0.097s
  training loss:		0.146537
  validation loss:		0.538887
  validation accuracy:		90.33 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.149747
  validation loss:		0.501803
  validation accuracy:		90.65 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.144926
  validation loss:		0.574223
  validation accuracy:		89.46 %
Epoch 1861 of 2000 took 0.097s
  training loss:		0.156935
  validation loss:		0.548368
  validation accuracy:		89.57 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.151111
  validation loss:		0.533268
  validation accuracy:		90.43 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.146279
  validation loss:		0.546939
  validation accuracy:		89.78 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.150852
  validation loss:		0.551248
  validation accuracy:		89.89 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.156423
  validation loss:		0.518234
  validation accuracy:		90.76 %
Epoch 1866 of 2000 took 0.097s
  training loss:		0.146764
  validation loss:		0.541760
  validation accuracy:		90.33 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.153545
  validation loss:		0.550216
  validation accuracy:		89.57 %
Epoch 1868 of 2000 took 0.097s
  training loss:		0.151098
  validation loss:		0.518788
  validation accuracy:		90.65 %
Epoch 1869 of 2000 took 0.097s
  training loss:		0.150651
  validation loss:		0.522519
  validation accuracy:		90.43 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.157086
  validation loss:		0.503983
  validation accuracy:		90.76 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.151193
  validation loss:		0.542182
  validation accuracy:		90.65 %
Epoch 1872 of 2000 took 0.097s
  training loss:		0.149888
  validation loss:		0.537971
  validation accuracy:		90.43 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.157008
  validation loss:		0.519593
  validation accuracy:		90.65 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.148172
  validation loss:		0.533523
  validation accuracy:		90.65 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.147016
  validation loss:		0.509942
  validation accuracy:		90.65 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.150435
  validation loss:		0.543561
  validation accuracy:		90.33 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.153009
  validation loss:		0.545622
  validation accuracy:		89.78 %
Epoch 1878 of 2000 took 0.097s
  training loss:		0.147799
  validation loss:		0.540484
  validation accuracy:		90.43 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.155895
  validation loss:		0.520483
  validation accuracy:		90.54 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.153790
  validation loss:		0.541231
  validation accuracy:		90.11 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.150378
  validation loss:		0.549209
  validation accuracy:		89.89 %
Epoch 1882 of 2000 took 0.097s
  training loss:		0.144677
  validation loss:		0.536601
  validation accuracy:		90.43 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.155914
  validation loss:		0.524148
  validation accuracy:		90.54 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.145518
  validation loss:		0.533297
  validation accuracy:		90.33 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.149381
  validation loss:		0.528209
  validation accuracy:		90.33 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.149952
  validation loss:		0.541655
  validation accuracy:		90.54 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.152175
  validation loss:		0.529406
  validation accuracy:		90.00 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.153714
  validation loss:		0.531908
  validation accuracy:		90.43 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.146519
  validation loss:		0.512035
  validation accuracy:		90.65 %
Epoch 1890 of 2000 took 0.097s
  training loss:		0.153711
  validation loss:		0.525974
  validation accuracy:		90.00 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.156755
  validation loss:		0.542791
  validation accuracy:		90.33 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.146995
  validation loss:		0.524190
  validation accuracy:		90.76 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.150979
  validation loss:		0.519189
  validation accuracy:		90.76 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.150025
  validation loss:		0.508729
  validation accuracy:		90.65 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.147943
  validation loss:		0.550605
  validation accuracy:		89.46 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.150028
  validation loss:		0.526416
  validation accuracy:		90.65 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.141599
  validation loss:		0.519936
  validation accuracy:		90.54 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.153908
  validation loss:		0.529975
  validation accuracy:		90.54 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.148820
  validation loss:		0.538971
  validation accuracy:		90.22 %
Epoch 1900 of 2000 took 0.097s
  training loss:		0.144537
  validation loss:		0.529769
  validation accuracy:		90.87 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.154266
  validation loss:		0.553564
  validation accuracy:		90.22 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.152909
  validation loss:		0.535927
  validation accuracy:		90.65 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.150947
  validation loss:		0.528648
  validation accuracy:		90.87 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.148696
  validation loss:		0.527717
  validation accuracy:		90.43 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.148365
  validation loss:		0.546231
  validation accuracy:		89.67 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.167929
  validation loss:		0.530494
  validation accuracy:		90.00 %
Epoch 1907 of 2000 took 0.097s
  training loss:		0.147051
  validation loss:		0.529542
  validation accuracy:		90.76 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.152774
  validation loss:		0.537367
  validation accuracy:		90.11 %
Epoch 1909 of 2000 took 0.097s
  training loss:		0.149669
  validation loss:		0.553733
  validation accuracy:		90.33 %
Epoch 1910 of 2000 took 0.097s
  training loss:		0.148598
  validation loss:		0.539551
  validation accuracy:		90.22 %
Epoch 1911 of 2000 took 0.097s
  training loss:		0.151395
  validation loss:		0.528255
  validation accuracy:		90.43 %
Epoch 1912 of 2000 took 0.097s
  training loss:		0.151690
  validation loss:		0.551268
  validation accuracy:		90.22 %
Epoch 1913 of 2000 took 0.097s
  training loss:		0.156670
  validation loss:		0.538098
  validation accuracy:		90.65 %
Epoch 1914 of 2000 took 0.097s
  training loss:		0.152135
  validation loss:		0.564918
  validation accuracy:		89.57 %
Epoch 1915 of 2000 took 0.097s
  training loss:		0.165601
  validation loss:		0.534527
  validation accuracy:		90.43 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.151139
  validation loss:		0.558016
  validation accuracy:		89.46 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.151919
  validation loss:		0.561833
  validation accuracy:		90.11 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.156050
  validation loss:		0.555638
  validation accuracy:		90.00 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.149921
  validation loss:		0.549838
  validation accuracy:		89.67 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.141453
  validation loss:		0.535608
  validation accuracy:		90.33 %
Epoch 1921 of 2000 took 0.097s
  training loss:		0.153652
  validation loss:		0.574094
  validation accuracy:		89.67 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.152632
  validation loss:		0.524951
  validation accuracy:		90.76 %
Epoch 1923 of 2000 took 0.097s
  training loss:		0.151417
  validation loss:		0.531831
  validation accuracy:		90.43 %
Epoch 1924 of 2000 took 0.097s
  training loss:		0.146704
  validation loss:		0.524343
  validation accuracy:		90.11 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.148686
  validation loss:		0.539351
  validation accuracy:		90.43 %
Epoch 1926 of 2000 took 0.097s
  training loss:		0.147349
  validation loss:		0.513661
  validation accuracy:		90.87 %
Epoch 1927 of 2000 took 0.097s
  training loss:		0.151297
  validation loss:		0.553124
  validation accuracy:		90.33 %
Epoch 1928 of 2000 took 0.097s
  training loss:		0.149893
  validation loss:		0.591211
  validation accuracy:		89.57 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.149377
  validation loss:		0.582645
  validation accuracy:		89.24 %
Epoch 1930 of 2000 took 0.097s
  training loss:		0.151106
  validation loss:		0.546707
  validation accuracy:		90.54 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.146919
  validation loss:		0.560175
  validation accuracy:		89.67 %
Epoch 1932 of 2000 took 0.097s
  training loss:		0.150629
  validation loss:		0.539748
  validation accuracy:		90.54 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.155456
  validation loss:		0.542043
  validation accuracy:		90.43 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.159719
  validation loss:		0.552513
  validation accuracy:		90.00 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.146774
  validation loss:		0.555158
  validation accuracy:		90.00 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.152766
  validation loss:		0.540032
  validation accuracy:		90.65 %
Epoch 1937 of 2000 took 0.097s
  training loss:		0.150308
  validation loss:		0.536564
  validation accuracy:		90.65 %
Epoch 1938 of 2000 took 0.097s
  training loss:		0.155174
  validation loss:		0.539131
  validation accuracy:		90.65 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.155188
  validation loss:		0.548881
  validation accuracy:		90.00 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.147239
  validation loss:		0.537306
  validation accuracy:		90.65 %
Epoch 1941 of 2000 took 0.097s
  training loss:		0.152604
  validation loss:		0.560457
  validation accuracy:		89.78 %
Epoch 1942 of 2000 took 0.097s
  training loss:		0.157220
  validation loss:		0.568152
  validation accuracy:		90.11 %
Epoch 1943 of 2000 took 0.097s
  training loss:		0.149618
  validation loss:		0.526410
  validation accuracy:		90.43 %
Epoch 1944 of 2000 took 0.097s
  training loss:		0.147606
  validation loss:		0.530778
  validation accuracy:		90.43 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.148541
  validation loss:		0.542276
  validation accuracy:		90.65 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.146110
  validation loss:		0.554132
  validation accuracy:		90.00 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.155259
  validation loss:		0.551928
  validation accuracy:		90.22 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.152896
  validation loss:		0.564888
  validation accuracy:		89.67 %
Epoch 1949 of 2000 took 0.097s
  training loss:		0.151874
  validation loss:		0.551506
  validation accuracy:		90.22 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.150590
  validation loss:		0.545106
  validation accuracy:		90.33 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.149626
  validation loss:		0.551126
  validation accuracy:		90.33 %
Epoch 1952 of 2000 took 0.099s
  training loss:		0.144339
  validation loss:		0.537397
  validation accuracy:		90.54 %
Epoch 1953 of 2000 took 0.097s
  training loss:		0.151316
  validation loss:		0.566884
  validation accuracy:		90.33 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.148809
  validation loss:		0.544978
  validation accuracy:		90.54 %
Epoch 1955 of 2000 took 0.097s
  training loss:		0.145904
  validation loss:		0.538369
  validation accuracy:		90.65 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.150432
  validation loss:		0.545520
  validation accuracy:		90.22 %
Epoch 1957 of 2000 took 0.097s
  training loss:		0.148139
  validation loss:		0.554208
  validation accuracy:		90.33 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.148885
  validation loss:		0.554356
  validation accuracy:		89.78 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.160963
  validation loss:		0.522398
  validation accuracy:		90.87 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.162891
  validation loss:		0.539933
  validation accuracy:		90.76 %
Epoch 1961 of 2000 took 0.097s
  training loss:		0.146456
  validation loss:		0.548680
  validation accuracy:		90.33 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.151790
  validation loss:		0.546944
  validation accuracy:		90.33 %
Epoch 1963 of 2000 took 0.100s
  training loss:		0.142918
  validation loss:		0.533098
  validation accuracy:		90.33 %
Epoch 1964 of 2000 took 0.100s
  training loss:		0.149068
  validation loss:		0.546603
  validation accuracy:		90.65 %
Epoch 1965 of 2000 took 0.101s
  training loss:		0.153134
  validation loss:		0.587409
  validation accuracy:		89.89 %
Epoch 1966 of 2000 took 0.104s
  training loss:		0.150870
  validation loss:		0.548320
  validation accuracy:		90.33 %
Epoch 1967 of 2000 took 0.103s
  training loss:		0.153218
  validation loss:		0.538914
  validation accuracy:		90.43 %
Epoch 1968 of 2000 took 0.103s
  training loss:		0.148387
  validation loss:		0.561461
  validation accuracy:		90.43 %
Epoch 1969 of 2000 took 0.103s
  training loss:		0.144050
  validation loss:		0.536228
  validation accuracy:		90.22 %
Epoch 1970 of 2000 took 0.103s
  training loss:		0.149001
  validation loss:		0.546160
  validation accuracy:		90.54 %
Epoch 1971 of 2000 took 0.103s
  training loss:		0.154096
  validation loss:		0.551331
  validation accuracy:		90.54 %
Epoch 1972 of 2000 took 0.103s
  training loss:		0.148763
  validation loss:		0.537345
  validation accuracy:		90.76 %
Epoch 1973 of 2000 took 0.103s
  training loss:		0.148838
  validation loss:		0.535631
  validation accuracy:		90.33 %
Epoch 1974 of 2000 took 0.103s
  training loss:		0.149390
  validation loss:		0.543334
  validation accuracy:		90.76 %
Epoch 1975 of 2000 took 0.100s
  training loss:		0.148081
  validation loss:		0.573341
  validation accuracy:		90.00 %
Epoch 1976 of 2000 took 0.100s
  training loss:		0.152555
  validation loss:		0.569710
  validation accuracy:		90.22 %
Epoch 1977 of 2000 took 0.100s
  training loss:		0.154750
  validation loss:		0.587838
  validation accuracy:		89.67 %
Epoch 1978 of 2000 took 0.100s
  training loss:		0.160418
  validation loss:		0.564640
  validation accuracy:		90.33 %
Epoch 1979 of 2000 took 0.100s
  training loss:		0.148026
  validation loss:		0.558976
  validation accuracy:		89.78 %
Epoch 1980 of 2000 took 0.100s
  training loss:		0.145966
  validation loss:		0.543945
  validation accuracy:		90.65 %
Epoch 1981 of 2000 took 0.100s
  training loss:		0.145634
  validation loss:		0.538701
  validation accuracy:		90.43 %
Epoch 1982 of 2000 took 0.100s
  training loss:		0.164931
  validation loss:		0.548504
  validation accuracy:		90.54 %
Epoch 1983 of 2000 took 0.100s
  training loss:		0.157462
  validation loss:		0.564848
  validation accuracy:		90.33 %
Epoch 1984 of 2000 took 0.100s
  training loss:		0.153619
  validation loss:		0.545519
  validation accuracy:		90.65 %
Epoch 1985 of 2000 took 0.100s
  training loss:		0.146804
  validation loss:		0.560836
  validation accuracy:		90.00 %
Epoch 1986 of 2000 took 0.100s
  training loss:		0.151307
  validation loss:		0.578924
  validation accuracy:		90.33 %
Epoch 1987 of 2000 took 0.100s
  training loss:		0.152764
  validation loss:		0.553789
  validation accuracy:		90.33 %
Epoch 1988 of 2000 took 0.100s
  training loss:		0.150172
  validation loss:		0.581480
  validation accuracy:		89.13 %
Epoch 1989 of 2000 took 0.100s
  training loss:		0.151684
  validation loss:		0.561465
  validation accuracy:		90.22 %
Epoch 1990 of 2000 took 0.100s
  training loss:		0.151279
  validation loss:		0.594559
  validation accuracy:		88.70 %
Epoch 1991 of 2000 took 0.100s
  training loss:		0.149968
  validation loss:		0.563109
  validation accuracy:		90.33 %
Epoch 1992 of 2000 took 0.100s
  training loss:		0.154534
  validation loss:		0.560035
  validation accuracy:		90.00 %
Epoch 1993 of 2000 took 0.100s
  training loss:		0.149870
  validation loss:		0.541251
  validation accuracy:		90.65 %
Epoch 1994 of 2000 took 0.100s
  training loss:		0.157561
  validation loss:		0.556266
  validation accuracy:		90.76 %
Epoch 1995 of 2000 took 0.100s
  training loss:		0.149004
  validation loss:		0.564555
  validation accuracy:		89.89 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.146854
  validation loss:		0.542872
  validation accuracy:		90.65 %
Epoch 1997 of 2000 took 0.100s
  training loss:		0.150416
  validation loss:		0.547384
  validation accuracy:		90.54 %
Epoch 1998 of 2000 took 0.100s
  training loss:		0.142262
  validation loss:		0.557692
  validation accuracy:		90.65 %
Epoch 1999 of 2000 took 0.100s
  training loss:		0.140307
  validation loss:		0.565588
  validation accuracy:		90.22 %
Epoch 2000 of 2000 took 0.100s
  training loss:		0.148975
  validation loss:		0.548483
  validation accuracy:		90.65 %
Final results:
  test loss:			1.045976
  test accuracy:		81.52 %
