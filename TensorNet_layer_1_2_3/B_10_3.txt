Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.106s
  training loss:		2.989306
  validation loss:		2.970722
  validation accuracy:		10.76 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.960134
  validation loss:		2.931905
  validation accuracy:		9.02 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.924717
  validation loss:		2.890404
  validation accuracy:		12.50 %
Epoch 4 of 2000 took 0.095s
  training loss:		2.888818
  validation loss:		2.849096
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.095s
  training loss:		2.852523
  validation loss:		2.807436
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.095s
  training loss:		2.814411
  validation loss:		2.764160
  validation accuracy:		12.83 %
Epoch 7 of 2000 took 0.095s
  training loss:		2.776263
  validation loss:		2.718773
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.732857
  validation loss:		2.670915
  validation accuracy:		12.83 %
Epoch 9 of 2000 took 0.095s
  training loss:		2.692111
  validation loss:		2.620899
  validation accuracy:		12.83 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.645028
  validation loss:		2.569028
  validation accuracy:		12.83 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.599134
  validation loss:		2.515886
  validation accuracy:		12.83 %
Epoch 12 of 2000 took 0.095s
  training loss:		2.551717
  validation loss:		2.462196
  validation accuracy:		12.83 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.499612
  validation loss:		2.409816
  validation accuracy:		12.83 %
Epoch 14 of 2000 took 0.095s
  training loss:		2.454777
  validation loss:		2.361620
  validation accuracy:		12.83 %
Epoch 15 of 2000 took 0.095s
  training loss:		2.415021
  validation loss:		2.321802
  validation accuracy:		12.83 %
Epoch 16 of 2000 took 0.095s
  training loss:		2.381241
  validation loss:		2.294034
  validation accuracy:		12.39 %
Epoch 17 of 2000 took 0.095s
  training loss:		2.356145
  validation loss:		2.277161
  validation accuracy:		13.15 %
Epoch 18 of 2000 took 0.095s
  training loss:		2.338492
  validation loss:		2.267731
  validation accuracy:		14.24 %
Epoch 19 of 2000 took 0.095s
  training loss:		2.326588
  validation loss:		2.262912
  validation accuracy:		14.46 %
Epoch 20 of 2000 took 0.095s
  training loss:		2.316629
  validation loss:		2.258437
  validation accuracy:		15.00 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.311170
  validation loss:		2.254258
  validation accuracy:		14.46 %
Epoch 22 of 2000 took 0.095s
  training loss:		2.307509
  validation loss:		2.250749
  validation accuracy:		13.59 %
Epoch 23 of 2000 took 0.095s
  training loss:		2.303775
  validation loss:		2.250283
  validation accuracy:		14.57 %
Epoch 24 of 2000 took 0.095s
  training loss:		2.300633
  validation loss:		2.248012
  validation accuracy:		11.20 %
Epoch 25 of 2000 took 0.095s
  training loss:		2.299240
  validation loss:		2.245004
  validation accuracy:		13.26 %
Epoch 26 of 2000 took 0.095s
  training loss:		2.298504
  validation loss:		2.246609
  validation accuracy:		12.28 %
Epoch 27 of 2000 took 0.095s
  training loss:		2.297208
  validation loss:		2.243659
  validation accuracy:		15.11 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.295854
  validation loss:		2.243651
  validation accuracy:		13.26 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.295420
  validation loss:		2.243821
  validation accuracy:		18.37 %
Epoch 30 of 2000 took 0.095s
  training loss:		2.294674
  validation loss:		2.244349
  validation accuracy:		11.63 %
Epoch 31 of 2000 took 0.095s
  training loss:		2.294095
  validation loss:		2.243182
  validation accuracy:		15.98 %
Epoch 32 of 2000 took 0.095s
  training loss:		2.292880
  validation loss:		2.239983
  validation accuracy:		15.76 %
Epoch 33 of 2000 took 0.095s
  training loss:		2.293284
  validation loss:		2.243423
  validation accuracy:		13.59 %
Epoch 34 of 2000 took 0.099s
  training loss:		2.291681
  validation loss:		2.239902
  validation accuracy:		12.17 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.291151
  validation loss:		2.239536
  validation accuracy:		16.30 %
Epoch 36 of 2000 took 0.096s
  training loss:		2.290258
  validation loss:		2.237239
  validation accuracy:		12.39 %
Epoch 37 of 2000 took 0.096s
  training loss:		2.290564
  validation loss:		2.237477
  validation accuracy:		12.61 %
Epoch 38 of 2000 took 0.095s
  training loss:		2.290108
  validation loss:		2.238740
  validation accuracy:		14.13 %
Epoch 39 of 2000 took 0.095s
  training loss:		2.289450
  validation loss:		2.239992
  validation accuracy:		12.83 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.289083
  validation loss:		2.236518
  validation accuracy:		12.83 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.288975
  validation loss:		2.238877
  validation accuracy:		20.43 %
Epoch 42 of 2000 took 0.096s
  training loss:		2.288637
  validation loss:		2.233671
  validation accuracy:		13.48 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.288053
  validation loss:		2.233435
  validation accuracy:		15.76 %
Epoch 44 of 2000 took 0.097s
  training loss:		2.287188
  validation loss:		2.237798
  validation accuracy:		13.26 %
Epoch 45 of 2000 took 0.096s
  training loss:		2.287663
  validation loss:		2.236735
  validation accuracy:		17.50 %
Epoch 46 of 2000 took 0.096s
  training loss:		2.285169
  validation loss:		2.233427
  validation accuracy:		17.07 %
Epoch 47 of 2000 took 0.096s
  training loss:		2.286726
  validation loss:		2.232344
  validation accuracy:		15.43 %
Epoch 48 of 2000 took 0.096s
  training loss:		2.285958
  validation loss:		2.230192
  validation accuracy:		16.41 %
Epoch 49 of 2000 took 0.097s
  training loss:		2.285104
  validation loss:		2.234038
  validation accuracy:		17.83 %
Epoch 50 of 2000 took 0.097s
  training loss:		2.285122
  validation loss:		2.234245
  validation accuracy:		19.24 %
Epoch 51 of 2000 took 0.097s
  training loss:		2.283161
  validation loss:		2.229025
  validation accuracy:		15.87 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.283870
  validation loss:		2.226917
  validation accuracy:		17.72 %
Epoch 53 of 2000 took 0.096s
  training loss:		2.282535
  validation loss:		2.231281
  validation accuracy:		20.33 %
Epoch 54 of 2000 took 0.096s
  training loss:		2.282182
  validation loss:		2.230563
  validation accuracy:		18.15 %
Epoch 55 of 2000 took 0.097s
  training loss:		2.281319
  validation loss:		2.228544
  validation accuracy:		15.22 %
Epoch 56 of 2000 took 0.096s
  training loss:		2.282112
  validation loss:		2.222766
  validation accuracy:		15.65 %
Epoch 57 of 2000 took 0.096s
  training loss:		2.280902
  validation loss:		2.227808
  validation accuracy:		18.48 %
Epoch 58 of 2000 took 0.096s
  training loss:		2.280044
  validation loss:		2.229965
  validation accuracy:		21.09 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.279848
  validation loss:		2.228191
  validation accuracy:		20.11 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.278967
  validation loss:		2.222022
  validation accuracy:		19.35 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.276844
  validation loss:		2.224225
  validation accuracy:		26.09 %
Epoch 62 of 2000 took 0.096s
  training loss:		2.277222
  validation loss:		2.222698
  validation accuracy:		19.13 %
Epoch 63 of 2000 took 0.096s
  training loss:		2.275324
  validation loss:		2.221020
  validation accuracy:		21.74 %
Epoch 64 of 2000 took 0.096s
  training loss:		2.275409
  validation loss:		2.221312
  validation accuracy:		18.26 %
Epoch 65 of 2000 took 0.096s
  training loss:		2.274937
  validation loss:		2.222371
  validation accuracy:		24.24 %
Epoch 66 of 2000 took 0.096s
  training loss:		2.273684
  validation loss:		2.220200
  validation accuracy:		21.63 %
Epoch 67 of 2000 took 0.096s
  training loss:		2.271637
  validation loss:		2.212856
  validation accuracy:		19.13 %
Epoch 68 of 2000 took 0.096s
  training loss:		2.272668
  validation loss:		2.216400
  validation accuracy:		19.13 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.270236
  validation loss:		2.217189
  validation accuracy:		21.74 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.268929
  validation loss:		2.212341
  validation accuracy:		25.33 %
Epoch 71 of 2000 took 0.096s
  training loss:		2.267880
  validation loss:		2.213510
  validation accuracy:		21.41 %
Epoch 72 of 2000 took 0.096s
  training loss:		2.267320
  validation loss:		2.208927
  validation accuracy:		19.35 %
Epoch 73 of 2000 took 0.096s
  training loss:		2.266468
  validation loss:		2.216120
  validation accuracy:		21.85 %
Epoch 74 of 2000 took 0.097s
  training loss:		2.264159
  validation loss:		2.210447
  validation accuracy:		23.48 %
Epoch 75 of 2000 took 0.096s
  training loss:		2.261887
  validation loss:		2.209045
  validation accuracy:		21.30 %
Epoch 76 of 2000 took 0.096s
  training loss:		2.260760
  validation loss:		2.202679
  validation accuracy:		19.24 %
Epoch 77 of 2000 took 0.096s
  training loss:		2.258814
  validation loss:		2.201916
  validation accuracy:		25.76 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.256741
  validation loss:		2.202079
  validation accuracy:		21.63 %
Epoch 79 of 2000 took 0.096s
  training loss:		2.255533
  validation loss:		2.198539
  validation accuracy:		27.39 %
Epoch 80 of 2000 took 0.097s
  training loss:		2.252721
  validation loss:		2.194411
  validation accuracy:		26.85 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.250814
  validation loss:		2.188721
  validation accuracy:		27.39 %
Epoch 82 of 2000 took 0.097s
  training loss:		2.248367
  validation loss:		2.195718
  validation accuracy:		20.33 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.246513
  validation loss:		2.189470
  validation accuracy:		22.50 %
Epoch 84 of 2000 took 0.096s
  training loss:		2.242084
  validation loss:		2.181268
  validation accuracy:		22.93 %
Epoch 85 of 2000 took 0.096s
  training loss:		2.239139
  validation loss:		2.187775
  validation accuracy:		20.11 %
Epoch 86 of 2000 took 0.096s
  training loss:		2.236249
  validation loss:		2.174986
  validation accuracy:		23.59 %
Epoch 87 of 2000 took 0.096s
  training loss:		2.231122
  validation loss:		2.166101
  validation accuracy:		21.85 %
Epoch 88 of 2000 took 0.096s
  training loss:		2.228582
  validation loss:		2.164373
  validation accuracy:		25.22 %
Epoch 89 of 2000 took 0.096s
  training loss:		2.221978
  validation loss:		2.158133
  validation accuracy:		24.13 %
Epoch 90 of 2000 took 0.096s
  training loss:		2.218309
  validation loss:		2.157825
  validation accuracy:		24.78 %
Epoch 91 of 2000 took 0.097s
  training loss:		2.212115
  validation loss:		2.150470
  validation accuracy:		25.11 %
Epoch 92 of 2000 took 0.096s
  training loss:		2.206770
  validation loss:		2.139535
  validation accuracy:		25.22 %
Epoch 93 of 2000 took 0.099s
  training loss:		2.198117
  validation loss:		2.130490
  validation accuracy:		25.54 %
Epoch 94 of 2000 took 0.097s
  training loss:		2.190336
  validation loss:		2.121410
  validation accuracy:		25.43 %
Epoch 95 of 2000 took 0.096s
  training loss:		2.181543
  validation loss:		2.112605
  validation accuracy:		25.33 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.172067
  validation loss:		2.098420
  validation accuracy:		27.07 %
Epoch 97 of 2000 took 0.096s
  training loss:		2.162337
  validation loss:		2.089298
  validation accuracy:		28.04 %
Epoch 98 of 2000 took 0.097s
  training loss:		2.147548
  validation loss:		2.077232
  validation accuracy:		24.67 %
Epoch 99 of 2000 took 0.096s
  training loss:		2.134390
  validation loss:		2.053974
  validation accuracy:		26.63 %
Epoch 100 of 2000 took 0.097s
  training loss:		2.118312
  validation loss:		2.034962
  validation accuracy:		28.15 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.102478
  validation loss:		2.019412
  validation accuracy:		27.39 %
Epoch 102 of 2000 took 0.096s
  training loss:		2.083683
  validation loss:		2.002542
  validation accuracy:		27.83 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.059695
  validation loss:		1.977719
  validation accuracy:		27.07 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.038086
  validation loss:		1.953176
  validation accuracy:		28.04 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.013693
  validation loss:		1.929246
  validation accuracy:		28.15 %
Epoch 106 of 2000 took 0.097s
  training loss:		1.989990
  validation loss:		1.901458
  validation accuracy:		29.35 %
Epoch 107 of 2000 took 0.097s
  training loss:		1.961710
  validation loss:		1.872408
  validation accuracy:		31.30 %
Epoch 108 of 2000 took 0.097s
  training loss:		1.935364
  validation loss:		1.839581
  validation accuracy:		33.37 %
Epoch 109 of 2000 took 0.097s
  training loss:		1.909543
  validation loss:		1.815346
  validation accuracy:		33.59 %
Epoch 110 of 2000 took 0.097s
  training loss:		1.889851
  validation loss:		1.792270
  validation accuracy:		34.89 %
Epoch 111 of 2000 took 0.097s
  training loss:		1.858440
  validation loss:		1.770262
  validation accuracy:		33.26 %
Epoch 112 of 2000 took 0.097s
  training loss:		1.833395
  validation loss:		1.740945
  validation accuracy:		38.91 %
Epoch 113 of 2000 took 0.097s
  training loss:		1.805465
  validation loss:		1.712066
  validation accuracy:		40.43 %
Epoch 114 of 2000 took 0.097s
  training loss:		1.783440
  validation loss:		1.689911
  validation accuracy:		41.63 %
Epoch 115 of 2000 took 0.097s
  training loss:		1.753802
  validation loss:		1.667828
  validation accuracy:		40.65 %
Epoch 116 of 2000 took 0.097s
  training loss:		1.733889
  validation loss:		1.638842
  validation accuracy:		42.93 %
Epoch 117 of 2000 took 0.097s
  training loss:		1.709005
  validation loss:		1.620337
  validation accuracy:		42.93 %
Epoch 118 of 2000 took 0.097s
  training loss:		1.686175
  validation loss:		1.597797
  validation accuracy:		43.70 %
Epoch 119 of 2000 took 0.097s
  training loss:		1.670176
  validation loss:		1.578771
  validation accuracy:		45.33 %
Epoch 120 of 2000 took 0.097s
  training loss:		1.646233
  validation loss:		1.554868
  validation accuracy:		46.41 %
Epoch 121 of 2000 took 0.097s
  training loss:		1.624216
  validation loss:		1.534211
  validation accuracy:		46.96 %
Epoch 122 of 2000 took 0.097s
  training loss:		1.607336
  validation loss:		1.511251
  validation accuracy:		47.17 %
Epoch 123 of 2000 took 0.097s
  training loss:		1.580551
  validation loss:		1.492366
  validation accuracy:		47.83 %
Epoch 124 of 2000 took 0.097s
  training loss:		1.562252
  validation loss:		1.474557
  validation accuracy:		49.78 %
Epoch 125 of 2000 took 0.097s
  training loss:		1.555055
  validation loss:		1.469441
  validation accuracy:		50.76 %
Epoch 126 of 2000 took 0.097s
  training loss:		1.530240
  validation loss:		1.432952
  validation accuracy:		52.07 %
Epoch 127 of 2000 took 0.097s
  training loss:		1.508976
  validation loss:		1.413309
  validation accuracy:		52.17 %
Epoch 128 of 2000 took 0.097s
  training loss:		1.489567
  validation loss:		1.396121
  validation accuracy:		53.80 %
Epoch 129 of 2000 took 0.097s
  training loss:		1.467342
  validation loss:		1.381994
  validation accuracy:		55.65 %
Epoch 130 of 2000 took 0.097s
  training loss:		1.447122
  validation loss:		1.358628
  validation accuracy:		54.78 %
Epoch 131 of 2000 took 0.097s
  training loss:		1.433434
  validation loss:		1.337840
  validation accuracy:		56.74 %
Epoch 132 of 2000 took 0.097s
  training loss:		1.415666
  validation loss:		1.318405
  validation accuracy:		56.96 %
Epoch 133 of 2000 took 0.097s
  training loss:		1.397239
  validation loss:		1.304446
  validation accuracy:		57.72 %
Epoch 134 of 2000 took 0.097s
  training loss:		1.381931
  validation loss:		1.283497
  validation accuracy:		58.70 %
Epoch 135 of 2000 took 0.097s
  training loss:		1.362561
  validation loss:		1.265222
  validation accuracy:		60.43 %
Epoch 136 of 2000 took 0.097s
  training loss:		1.347580
  validation loss:		1.250511
  validation accuracy:		61.41 %
Epoch 137 of 2000 took 0.097s
  training loss:		1.322762
  validation loss:		1.233013
  validation accuracy:		62.50 %
Epoch 138 of 2000 took 0.097s
  training loss:		1.305366
  validation loss:		1.208535
  validation accuracy:		62.28 %
Epoch 139 of 2000 took 0.097s
  training loss:		1.295085
  validation loss:		1.189306
  validation accuracy:		64.67 %
Epoch 140 of 2000 took 0.097s
  training loss:		1.265107
  validation loss:		1.179083
  validation accuracy:		63.15 %
Epoch 141 of 2000 took 0.097s
  training loss:		1.261084
  validation loss:		1.162469
  validation accuracy:		66.09 %
Epoch 142 of 2000 took 0.097s
  training loss:		1.234921
  validation loss:		1.130544
  validation accuracy:		66.30 %
Epoch 143 of 2000 took 0.097s
  training loss:		1.216621
  validation loss:		1.111657
  validation accuracy:		66.96 %
Epoch 144 of 2000 took 0.097s
  training loss:		1.198996
  validation loss:		1.095135
  validation accuracy:		67.28 %
Epoch 145 of 2000 took 0.097s
  training loss:		1.174146
  validation loss:		1.069830
  validation accuracy:		68.15 %
Epoch 146 of 2000 took 0.097s
  training loss:		1.161139
  validation loss:		1.059058
  validation accuracy:		67.93 %
Epoch 147 of 2000 took 0.097s
  training loss:		1.152056
  validation loss:		1.044764
  validation accuracy:		68.80 %
Epoch 148 of 2000 took 0.097s
  training loss:		1.131208
  validation loss:		1.015545
  validation accuracy:		68.48 %
Epoch 149 of 2000 took 0.097s
  training loss:		1.110259
  validation loss:		1.008890
  validation accuracy:		68.70 %
Epoch 150 of 2000 took 0.097s
  training loss:		1.085592
  validation loss:		1.001898
  validation accuracy:		69.78 %
Epoch 151 of 2000 took 0.097s
  training loss:		1.081179
  validation loss:		0.972360
  validation accuracy:		70.65 %
Epoch 152 of 2000 took 0.097s
  training loss:		1.061131
  validation loss:		0.952907
  validation accuracy:		69.57 %
Epoch 153 of 2000 took 0.097s
  training loss:		1.046858
  validation loss:		0.937731
  validation accuracy:		71.52 %
Epoch 154 of 2000 took 0.097s
  training loss:		1.035545
  validation loss:		0.929064
  validation accuracy:		71.63 %
Epoch 155 of 2000 took 0.097s
  training loss:		1.016982
  validation loss:		0.911978
  validation accuracy:		71.74 %
Epoch 156 of 2000 took 0.097s
  training loss:		1.003700
  validation loss:		0.904285
  validation accuracy:		71.96 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.994150
  validation loss:		0.886630
  validation accuracy:		71.85 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.989849
  validation loss:		0.871517
  validation accuracy:		72.72 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.959476
  validation loss:		0.873315
  validation accuracy:		72.28 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.957586
  validation loss:		0.857499
  validation accuracy:		73.15 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.943675
  validation loss:		0.839412
  validation accuracy:		72.83 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.921561
  validation loss:		0.830901
  validation accuracy:		72.61 %
Epoch 163 of 2000 took 0.099s
  training loss:		0.922020
  validation loss:		0.819071
  validation accuracy:		72.83 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.906017
  validation loss:		0.813103
  validation accuracy:		73.59 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.900261
  validation loss:		0.822316
  validation accuracy:		73.80 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.886654
  validation loss:		0.790076
  validation accuracy:		73.80 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.893427
  validation loss:		0.786414
  validation accuracy:		76.09 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.877857
  validation loss:		0.776492
  validation accuracy:		75.00 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.864068
  validation loss:		0.764945
  validation accuracy:		75.22 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.856439
  validation loss:		0.765546
  validation accuracy:		75.00 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.833706
  validation loss:		0.766322
  validation accuracy:		74.78 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.841605
  validation loss:		0.742917
  validation accuracy:		76.96 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.817569
  validation loss:		0.734459
  validation accuracy:		75.43 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.823905
  validation loss:		0.728682
  validation accuracy:		75.87 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.806725
  validation loss:		0.733939
  validation accuracy:		75.87 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.828120
  validation loss:		0.719360
  validation accuracy:		76.74 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.790700
  validation loss:		0.713937
  validation accuracy:		76.52 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.786841
  validation loss:		0.703388
  validation accuracy:		76.41 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.777994
  validation loss:		0.694546
  validation accuracy:		76.63 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.768551
  validation loss:		0.699507
  validation accuracy:		77.72 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.766062
  validation loss:		0.709210
  validation accuracy:		76.52 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.767702
  validation loss:		0.703562
  validation accuracy:		77.28 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.756648
  validation loss:		0.693725
  validation accuracy:		78.04 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.738410
  validation loss:		0.676811
  validation accuracy:		77.39 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.757671
  validation loss:		0.678563
  validation accuracy:		77.83 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.732102
  validation loss:		0.680879
  validation accuracy:		77.28 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.724077
  validation loss:		0.665945
  validation accuracy:		77.39 %
Epoch 188 of 2000 took 0.108s
  training loss:		0.725038
  validation loss:		0.662864
  validation accuracy:		77.72 %
Epoch 189 of 2000 took 0.108s
  training loss:		0.732465
  validation loss:		0.671571
  validation accuracy:		77.39 %
Epoch 190 of 2000 took 0.102s
  training loss:		0.733657
  validation loss:		0.649349
  validation accuracy:		78.26 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.704284
  validation loss:		0.658085
  validation accuracy:		78.59 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.711871
  validation loss:		0.655239
  validation accuracy:		78.15 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.696398
  validation loss:		0.641887
  validation accuracy:		78.70 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.695712
  validation loss:		0.672429
  validation accuracy:		77.28 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.697484
  validation loss:		0.651327
  validation accuracy:		78.91 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.691260
  validation loss:		0.643219
  validation accuracy:		78.70 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.687056
  validation loss:		0.673497
  validation accuracy:		78.26 %
Epoch 198 of 2000 took 0.098s
  training loss:		0.689081
  validation loss:		0.631460
  validation accuracy:		78.70 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.682833
  validation loss:		0.643773
  validation accuracy:		79.24 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.686791
  validation loss:		0.688115
  validation accuracy:		77.28 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.679878
  validation loss:		0.634579
  validation accuracy:		79.13 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.679941
  validation loss:		0.629608
  validation accuracy:		79.13 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.669340
  validation loss:		0.627859
  validation accuracy:		79.02 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.674095
  validation loss:		0.635286
  validation accuracy:		78.37 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.681284
  validation loss:		0.649013
  validation accuracy:		79.02 %
Epoch 206 of 2000 took 0.097s
  training loss:		0.684928
  validation loss:		0.620824
  validation accuracy:		79.13 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.665757
  validation loss:		0.626745
  validation accuracy:		78.80 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.658133
  validation loss:		0.616756
  validation accuracy:		79.02 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.659306
  validation loss:		0.639621
  validation accuracy:		78.80 %
Epoch 210 of 2000 took 0.097s
  training loss:		0.658685
  validation loss:		0.626436
  validation accuracy:		78.70 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.654213
  validation loss:		0.617619
  validation accuracy:		78.48 %
Epoch 212 of 2000 took 0.097s
  training loss:		0.657006
  validation loss:		0.623782
  validation accuracy:		79.02 %
Epoch 213 of 2000 took 0.097s
  training loss:		0.674878
  validation loss:		0.645731
  validation accuracy:		79.24 %
Epoch 214 of 2000 took 0.097s
  training loss:		0.684643
  validation loss:		0.628407
  validation accuracy:		79.02 %
Epoch 215 of 2000 took 0.097s
  training loss:		0.649183
  validation loss:		0.609028
  validation accuracy:		79.13 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.644794
  validation loss:		0.630816
  validation accuracy:		80.00 %
Epoch 217 of 2000 took 0.097s
  training loss:		0.658725
  validation loss:		0.633970
  validation accuracy:		78.37 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.641549
  validation loss:		0.622787
  validation accuracy:		78.48 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.648077
  validation loss:		0.606563
  validation accuracy:		80.11 %
Epoch 220 of 2000 took 0.097s
  training loss:		0.660970
  validation loss:		0.602025
  validation accuracy:		78.91 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.649313
  validation loss:		0.611040
  validation accuracy:		78.59 %
Epoch 222 of 2000 took 0.097s
  training loss:		0.640567
  validation loss:		0.608337
  validation accuracy:		80.00 %
Epoch 223 of 2000 took 0.097s
  training loss:		0.630181
  validation loss:		0.613824
  validation accuracy:		79.13 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.651167
  validation loss:		0.593295
  validation accuracy:		79.89 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.656052
  validation loss:		0.648484
  validation accuracy:		77.61 %
Epoch 226 of 2000 took 0.096s
  training loss:		0.638439
  validation loss:		0.615332
  validation accuracy:		80.00 %
Epoch 227 of 2000 took 0.096s
  training loss:		0.626873
  validation loss:		0.592865
  validation accuracy:		80.22 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.634986
  validation loss:		0.629480
  validation accuracy:		79.35 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.638887
  validation loss:		0.602292
  validation accuracy:		79.78 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.623282
  validation loss:		0.606622
  validation accuracy:		79.13 %
Epoch 231 of 2000 took 0.096s
  training loss:		0.629774
  validation loss:		0.596673
  validation accuracy:		80.22 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.621069
  validation loss:		0.610514
  validation accuracy:		80.00 %
Epoch 233 of 2000 took 0.096s
  training loss:		0.628224
  validation loss:		0.590543
  validation accuracy:		80.11 %
Epoch 234 of 2000 took 0.096s
  training loss:		0.638944
  validation loss:		0.618364
  validation accuracy:		79.89 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.626796
  validation loss:		0.592968
  validation accuracy:		80.43 %
Epoch 236 of 2000 took 0.096s
  training loss:		0.617734
  validation loss:		0.589248
  validation accuracy:		80.65 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.622740
  validation loss:		0.589874
  validation accuracy:		81.09 %
Epoch 238 of 2000 took 0.097s
  training loss:		0.622913
  validation loss:		0.589379
  validation accuracy:		79.78 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.628198
  validation loss:		0.606842
  validation accuracy:		80.98 %
Epoch 240 of 2000 took 0.099s
  training loss:		0.625070
  validation loss:		0.598077
  validation accuracy:		79.67 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.619642
  validation loss:		0.597681
  validation accuracy:		79.78 %
Epoch 242 of 2000 took 0.096s
  training loss:		0.631593
  validation loss:		0.599190
  validation accuracy:		80.43 %
Epoch 243 of 2000 took 0.097s
  training loss:		0.633797
  validation loss:		0.590248
  validation accuracy:		80.76 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.624231
  validation loss:		0.631005
  validation accuracy:		79.02 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.624205
  validation loss:		0.615298
  validation accuracy:		80.54 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.615762
  validation loss:		0.592315
  validation accuracy:		80.76 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.630872
  validation loss:		0.592298
  validation accuracy:		79.89 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.621057
  validation loss:		0.617178
  validation accuracy:		80.11 %
Epoch 249 of 2000 took 0.096s
  training loss:		0.615814
  validation loss:		0.590208
  validation accuracy:		80.54 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.623303
  validation loss:		0.618020
  validation accuracy:		79.24 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.642637
  validation loss:		0.789707
  validation accuracy:		74.35 %
Epoch 252 of 2000 took 0.096s
  training loss:		0.668513
  validation loss:		0.675350
  validation accuracy:		78.48 %
Epoch 253 of 2000 took 0.096s
  training loss:		0.621124
  validation loss:		0.614860
  validation accuracy:		79.78 %
Epoch 254 of 2000 took 0.096s
  training loss:		0.629931
  validation loss:		0.578979
  validation accuracy:		81.09 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.627065
  validation loss:		0.609901
  validation accuracy:		80.22 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.631771
  validation loss:		0.581009
  validation accuracy:		81.63 %
Epoch 257 of 2000 took 0.096s
  training loss:		0.612975
  validation loss:		0.594108
  validation accuracy:		80.22 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.618231
  validation loss:		0.586587
  validation accuracy:		80.43 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.613797
  validation loss:		0.586979
  validation accuracy:		80.54 %
Epoch 260 of 2000 took 0.096s
  training loss:		0.602853
  validation loss:		0.584027
  validation accuracy:		81.09 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.605725
  validation loss:		0.585876
  validation accuracy:		80.65 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.632472
  validation loss:		0.584701
  validation accuracy:		81.63 %
Epoch 263 of 2000 took 0.096s
  training loss:		0.603407
  validation loss:		0.598170
  validation accuracy:		79.57 %
Epoch 264 of 2000 took 0.096s
  training loss:		0.611949
  validation loss:		0.626423
  validation accuracy:		79.67 %
Epoch 265 of 2000 took 0.096s
  training loss:		0.614894
  validation loss:		0.579682
  validation accuracy:		80.87 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.606527
  validation loss:		0.592850
  validation accuracy:		81.41 %
Epoch 267 of 2000 took 0.096s
  training loss:		0.611423
  validation loss:		0.590844
  validation accuracy:		80.00 %
Epoch 268 of 2000 took 0.097s
  training loss:		0.601950
  validation loss:		0.591495
  validation accuracy:		80.43 %
Epoch 269 of 2000 took 0.096s
  training loss:		0.624252
  validation loss:		0.590398
  validation accuracy:		79.57 %
Epoch 270 of 2000 took 0.097s
  training loss:		0.599468
  validation loss:		0.579721
  validation accuracy:		81.20 %
Epoch 271 of 2000 took 0.096s
  training loss:		0.615146
  validation loss:		0.627621
  validation accuracy:		79.24 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.613379
  validation loss:		0.586766
  validation accuracy:		81.09 %
Epoch 273 of 2000 took 0.096s
  training loss:		0.605749
  validation loss:		0.612852
  validation accuracy:		79.89 %
Epoch 274 of 2000 took 0.096s
  training loss:		0.643459
  validation loss:		0.651644
  validation accuracy:		79.24 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.622686
  validation loss:		0.595123
  validation accuracy:		80.76 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.635485
  validation loss:		0.595712
  validation accuracy:		80.33 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.608202
  validation loss:		0.646330
  validation accuracy:		78.91 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.613560
  validation loss:		0.634256
  validation accuracy:		79.24 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.609227
  validation loss:		0.588971
  validation accuracy:		80.87 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.607424
  validation loss:		0.579240
  validation accuracy:		81.63 %
Epoch 281 of 2000 took 0.096s
  training loss:		0.589942
  validation loss:		0.577536
  validation accuracy:		81.20 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.601393
  validation loss:		0.583468
  validation accuracy:		80.87 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.600898
  validation loss:		0.592530
  validation accuracy:		80.65 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.599413
  validation loss:		0.585582
  validation accuracy:		80.11 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.625777
  validation loss:		0.601323
  validation accuracy:		80.76 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.601918
  validation loss:		0.617762
  validation accuracy:		79.35 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.602637
  validation loss:		0.621891
  validation accuracy:		79.35 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.622362
  validation loss:		0.589245
  validation accuracy:		80.76 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.608885
  validation loss:		0.595675
  validation accuracy:		80.22 %
Epoch 290 of 2000 took 0.096s
  training loss:		0.616637
  validation loss:		0.583140
  validation accuracy:		81.09 %
Epoch 291 of 2000 took 0.096s
  training loss:		0.600756
  validation loss:		0.595176
  validation accuracy:		80.43 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.603219
  validation loss:		0.599910
  validation accuracy:		80.65 %
Epoch 293 of 2000 took 0.096s
  training loss:		0.609824
  validation loss:		0.641877
  validation accuracy:		78.70 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.633501
  validation loss:		0.591450
  validation accuracy:		80.98 %
Epoch 295 of 2000 took 0.096s
  training loss:		0.595209
  validation loss:		0.593194
  validation accuracy:		81.09 %
Epoch 296 of 2000 took 0.096s
  training loss:		0.605614
  validation loss:		0.604372
  validation accuracy:		79.89 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.615063
  validation loss:		0.585468
  validation accuracy:		81.09 %
Epoch 298 of 2000 took 0.096s
  training loss:		0.600128
  validation loss:		0.570898
  validation accuracy:		81.74 %
Epoch 299 of 2000 took 0.096s
  training loss:		0.606133
  validation loss:		0.621478
  validation accuracy:		79.24 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.602532
  validation loss:		0.648950
  validation accuracy:		78.59 %
Epoch 301 of 2000 took 0.096s
  training loss:		0.622481
  validation loss:		0.583306
  validation accuracy:		81.09 %
Epoch 302 of 2000 took 0.096s
  training loss:		0.637822
  validation loss:		0.596022
  validation accuracy:		80.98 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.593108
  validation loss:		0.571608
  validation accuracy:		81.96 %
Epoch 304 of 2000 took 0.096s
  training loss:		0.584976
  validation loss:		0.594594
  validation accuracy:		80.11 %
Epoch 305 of 2000 took 0.096s
  training loss:		0.609720
  validation loss:		0.584867
  validation accuracy:		80.76 %
Epoch 306 of 2000 took 0.096s
  training loss:		0.601975
  validation loss:		0.587492
  validation accuracy:		80.76 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.596556
  validation loss:		0.573081
  validation accuracy:		81.41 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.605546
  validation loss:		0.605479
  validation accuracy:		79.78 %
Epoch 309 of 2000 took 0.096s
  training loss:		0.612333
  validation loss:		0.578537
  validation accuracy:		82.07 %
Epoch 310 of 2000 took 0.096s
  training loss:		0.593261
  validation loss:		0.586853
  validation accuracy:		80.33 %
Epoch 311 of 2000 took 0.096s
  training loss:		0.592208
  validation loss:		0.605019
  validation accuracy:		80.65 %
Epoch 312 of 2000 took 0.096s
  training loss:		0.613250
  validation loss:		0.586223
  validation accuracy:		80.54 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.601601
  validation loss:		0.609207
  validation accuracy:		79.89 %
Epoch 314 of 2000 took 0.096s
  training loss:		0.620431
  validation loss:		0.575775
  validation accuracy:		81.30 %
Epoch 315 of 2000 took 0.096s
  training loss:		0.584593
  validation loss:		0.608728
  validation accuracy:		80.43 %
Epoch 316 of 2000 took 0.096s
  training loss:		0.598998
  validation loss:		0.582796
  validation accuracy:		80.98 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.585762
  validation loss:		0.574527
  validation accuracy:		81.63 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.599505
  validation loss:		0.573646
  validation accuracy:		81.41 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.590076
  validation loss:		0.626383
  validation accuracy:		78.70 %
Epoch 320 of 2000 took 0.096s
  training loss:		0.606639
  validation loss:		0.585468
  validation accuracy:		79.46 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.595611
  validation loss:		0.611914
  validation accuracy:		80.43 %
Epoch 322 of 2000 took 0.096s
  training loss:		0.600336
  validation loss:		0.577808
  validation accuracy:		81.09 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.593738
  validation loss:		0.577140
  validation accuracy:		80.33 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.606740
  validation loss:		0.570247
  validation accuracy:		81.74 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.599976
  validation loss:		0.595273
  validation accuracy:		80.11 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.612656
  validation loss:		0.597387
  validation accuracy:		79.67 %
Epoch 327 of 2000 took 0.096s
  training loss:		0.593472
  validation loss:		0.578820
  validation accuracy:		80.22 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.588999
  validation loss:		0.607384
  validation accuracy:		79.24 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.590330
  validation loss:		0.587964
  validation accuracy:		81.09 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.618000
  validation loss:		0.568843
  validation accuracy:		81.52 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.590864
  validation loss:		0.584732
  validation accuracy:		79.24 %
Epoch 332 of 2000 took 0.103s
  training loss:		0.602277
  validation loss:		0.594663
  validation accuracy:		80.65 %
Epoch 333 of 2000 took 0.134s
  training loss:		0.588116
  validation loss:		0.600492
  validation accuracy:		79.35 %
Epoch 334 of 2000 took 0.114s
  training loss:		0.586845
  validation loss:		0.573619
  validation accuracy:		80.87 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.593691
  validation loss:		0.588762
  validation accuracy:		80.98 %
Epoch 336 of 2000 took 0.100s
  training loss:		0.635284
  validation loss:		0.655954
  validation accuracy:		78.37 %
Epoch 337 of 2000 took 0.101s
  training loss:		0.603367
  validation loss:		0.573487
  validation accuracy:		80.98 %
Epoch 338 of 2000 took 0.099s
  training loss:		0.582046
  validation loss:		0.584704
  validation accuracy:		80.87 %
Epoch 339 of 2000 took 0.098s
  training loss:		0.589662
  validation loss:		0.573093
  validation accuracy:		80.87 %
Epoch 340 of 2000 took 0.096s
  training loss:		0.583793
  validation loss:		0.586755
  validation accuracy:		81.30 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.607325
  validation loss:		0.611062
  validation accuracy:		80.43 %
Epoch 342 of 2000 took 0.096s
  training loss:		0.611336
  validation loss:		0.579838
  validation accuracy:		80.00 %
Epoch 343 of 2000 took 0.096s
  training loss:		0.590349
  validation loss:		0.584699
  validation accuracy:		79.67 %
Epoch 344 of 2000 took 0.096s
  training loss:		0.600476
  validation loss:		0.575539
  validation accuracy:		80.43 %
Epoch 345 of 2000 took 0.096s
  training loss:		0.607794
  validation loss:		0.594764
  validation accuracy:		80.87 %
Epoch 346 of 2000 took 0.096s
  training loss:		0.603126
  validation loss:		0.680656
  validation accuracy:		77.39 %
Epoch 347 of 2000 took 0.096s
  training loss:		0.612975
  validation loss:		0.606688
  validation accuracy:		80.00 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.582106
  validation loss:		0.568449
  validation accuracy:		81.52 %
Epoch 349 of 2000 took 0.097s
  training loss:		0.587366
  validation loss:		0.580413
  validation accuracy:		80.76 %
Epoch 350 of 2000 took 0.096s
  training loss:		0.586897
  validation loss:		0.585626
  validation accuracy:		80.11 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.593713
  validation loss:		0.608773
  validation accuracy:		79.13 %
Epoch 352 of 2000 took 0.096s
  training loss:		0.582326
  validation loss:		0.568099
  validation accuracy:		80.76 %
Epoch 353 of 2000 took 0.097s
  training loss:		0.580155
  validation loss:		0.586377
  validation accuracy:		81.09 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.600019
  validation loss:		0.593671
  validation accuracy:		80.54 %
Epoch 355 of 2000 took 0.096s
  training loss:		0.589566
  validation loss:		0.628983
  validation accuracy:		79.02 %
Epoch 356 of 2000 took 0.096s
  training loss:		0.592608
  validation loss:		0.646635
  validation accuracy:		77.72 %
Epoch 357 of 2000 took 0.096s
  training loss:		0.595206
  validation loss:		0.571998
  validation accuracy:		80.98 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.577778
  validation loss:		0.573692
  validation accuracy:		81.41 %
Epoch 359 of 2000 took 0.096s
  training loss:		0.602493
  validation loss:		0.621059
  validation accuracy:		78.15 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.593820
  validation loss:		0.574484
  validation accuracy:		80.22 %
Epoch 361 of 2000 took 0.096s
  training loss:		0.605793
  validation loss:		0.574426
  validation accuracy:		80.22 %
Epoch 362 of 2000 took 0.096s
  training loss:		0.593476
  validation loss:		0.586484
  validation accuracy:		80.22 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.577107
  validation loss:		0.572877
  validation accuracy:		80.54 %
Epoch 364 of 2000 took 0.096s
  training loss:		0.582782
  validation loss:		0.559953
  validation accuracy:		81.96 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.600791
  validation loss:		0.598036
  validation accuracy:		79.13 %
Epoch 366 of 2000 took 0.096s
  training loss:		0.600230
  validation loss:		0.563610
  validation accuracy:		81.74 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.585886
  validation loss:		0.575638
  validation accuracy:		80.33 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.584949
  validation loss:		0.575352
  validation accuracy:		80.65 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.583626
  validation loss:		0.586697
  validation accuracy:		79.67 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.580278
  validation loss:		0.569460
  validation accuracy:		81.63 %
Epoch 371 of 2000 took 0.096s
  training loss:		0.581532
  validation loss:		0.579979
  validation accuracy:		80.11 %
Epoch 372 of 2000 took 0.098s
  training loss:		0.601054
  validation loss:		0.590472
  validation accuracy:		79.78 %
Epoch 373 of 2000 took 0.096s
  training loss:		0.577059
  validation loss:		0.578297
  validation accuracy:		79.67 %
Epoch 374 of 2000 took 0.096s
  training loss:		0.581992
  validation loss:		0.615967
  validation accuracy:		77.83 %
Epoch 375 of 2000 took 0.096s
  training loss:		0.586654
  validation loss:		0.571073
  validation accuracy:		80.43 %
Epoch 376 of 2000 took 0.096s
  training loss:		0.575003
  validation loss:		0.608015
  validation accuracy:		79.67 %
Epoch 377 of 2000 took 0.096s
  training loss:		0.585774
  validation loss:		0.589004
  validation accuracy:		80.22 %
Epoch 378 of 2000 took 0.096s
  training loss:		0.587842
  validation loss:		0.562996
  validation accuracy:		81.52 %
Epoch 379 of 2000 took 0.096s
  training loss:		0.592055
  validation loss:		0.558736
  validation accuracy:		82.28 %
Epoch 380 of 2000 took 0.096s
  training loss:		0.583286
  validation loss:		0.581832
  validation accuracy:		80.65 %
Epoch 381 of 2000 took 0.096s
  training loss:		0.595773
  validation loss:		0.595710
  validation accuracy:		78.80 %
Epoch 382 of 2000 took 0.096s
  training loss:		0.583795
  validation loss:		0.562791
  validation accuracy:		82.17 %
Epoch 383 of 2000 took 0.096s
  training loss:		0.582641
  validation loss:		0.564359
  validation accuracy:		81.20 %
Epoch 384 of 2000 took 0.096s
  training loss:		0.589534
  validation loss:		0.612024
  validation accuracy:		78.26 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.628478
  validation loss:		0.574194
  validation accuracy:		81.85 %
Epoch 386 of 2000 took 0.096s
  training loss:		0.579797
  validation loss:		0.557563
  validation accuracy:		82.39 %
Epoch 387 of 2000 took 0.096s
  training loss:		0.587011
  validation loss:		0.573307
  validation accuracy:		80.11 %
Epoch 388 of 2000 took 0.096s
  training loss:		0.579999
  validation loss:		0.575694
  validation accuracy:		82.07 %
Epoch 389 of 2000 took 0.096s
  training loss:		0.581579
  validation loss:		0.560699
  validation accuracy:		81.41 %
Epoch 390 of 2000 took 0.096s
  training loss:		0.603094
  validation loss:		0.565411
  validation accuracy:		80.98 %
Epoch 391 of 2000 took 0.096s
  training loss:		0.602860
  validation loss:		0.601288
  validation accuracy:		78.48 %
Epoch 392 of 2000 took 0.096s
  training loss:		0.587588
  validation loss:		0.574912
  validation accuracy:		80.11 %
Epoch 393 of 2000 took 0.096s
  training loss:		0.609307
  validation loss:		0.560133
  validation accuracy:		81.74 %
Epoch 394 of 2000 took 0.096s
  training loss:		0.579865
  validation loss:		0.585533
  validation accuracy:		79.46 %
Epoch 395 of 2000 took 0.096s
  training loss:		0.575087
  validation loss:		0.568754
  validation accuracy:		80.76 %
Epoch 396 of 2000 took 0.096s
  training loss:		0.582002
  validation loss:		0.582803
  validation accuracy:		79.67 %
Epoch 397 of 2000 took 0.096s
  training loss:		0.594740
  validation loss:		0.588419
  validation accuracy:		81.63 %
Epoch 398 of 2000 took 0.096s
  training loss:		0.582096
  validation loss:		0.562911
  validation accuracy:		81.85 %
Epoch 399 of 2000 took 0.096s
  training loss:		0.608312
  validation loss:		0.567577
  validation accuracy:		82.17 %
Epoch 400 of 2000 took 0.099s
  training loss:		0.576388
  validation loss:		0.600229
  validation accuracy:		78.91 %
Epoch 401 of 2000 took 0.104s
  training loss:		0.584803
  validation loss:		0.613537
  validation accuracy:		78.59 %
Epoch 402 of 2000 took 0.105s
  training loss:		0.602686
  validation loss:		0.563749
  validation accuracy:		81.52 %
Epoch 403 of 2000 took 0.099s
  training loss:		0.586066
  validation loss:		0.574564
  validation accuracy:		80.22 %
Epoch 404 of 2000 took 0.096s
  training loss:		0.583873
  validation loss:		0.596620
  validation accuracy:		78.91 %
Epoch 405 of 2000 took 0.096s
  training loss:		0.590472
  validation loss:		0.575126
  validation accuracy:		80.65 %
Epoch 406 of 2000 took 0.096s
  training loss:		0.586879
  validation loss:		0.567645
  validation accuracy:		81.96 %
Epoch 407 of 2000 took 0.096s
  training loss:		0.579141
  validation loss:		0.565271
  validation accuracy:		80.22 %
Epoch 408 of 2000 took 0.096s
  training loss:		0.578118
  validation loss:		0.574974
  validation accuracy:		79.89 %
Epoch 409 of 2000 took 0.096s
  training loss:		0.573336
  validation loss:		0.562265
  validation accuracy:		81.30 %
Epoch 410 of 2000 took 0.096s
  training loss:		0.580319
  validation loss:		0.583411
  validation accuracy:		79.02 %
Epoch 411 of 2000 took 0.096s
  training loss:		0.571616
  validation loss:		0.567825
  validation accuracy:		80.43 %
Epoch 412 of 2000 took 0.096s
  training loss:		0.580804
  validation loss:		0.568578
  validation accuracy:		80.33 %
Epoch 413 of 2000 took 0.100s
  training loss:		0.582296
  validation loss:		0.592811
  validation accuracy:		79.67 %
Epoch 414 of 2000 took 0.098s
  training loss:		0.582495
  validation loss:		0.560666
  validation accuracy:		81.41 %
Epoch 415 of 2000 took 0.096s
  training loss:		0.584793
  validation loss:		0.555154
  validation accuracy:		81.52 %
Epoch 416 of 2000 took 0.098s
  training loss:		0.593093
  validation loss:		0.593892
  validation accuracy:		80.11 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.578312
  validation loss:		0.573180
  validation accuracy:		80.54 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.580810
  validation loss:		0.569317
  validation accuracy:		82.28 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.591864
  validation loss:		0.575243
  validation accuracy:		79.89 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.571820
  validation loss:		0.602312
  validation accuracy:		78.26 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.575101
  validation loss:		0.586871
  validation accuracy:		79.13 %
Epoch 422 of 2000 took 0.097s
  training loss:		0.577953
  validation loss:		0.596462
  validation accuracy:		80.33 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.567706
  validation loss:		0.552629
  validation accuracy:		81.74 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.580572
  validation loss:		0.569311
  validation accuracy:		79.78 %
Epoch 425 of 2000 took 0.097s
  training loss:		0.584668
  validation loss:		0.596441
  validation accuracy:		79.02 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.581256
  validation loss:		0.595396
  validation accuracy:		80.43 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.610515
  validation loss:		0.554920
  validation accuracy:		82.50 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.588753
  validation loss:		0.585337
  validation accuracy:		79.02 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.592257
  validation loss:		0.549770
  validation accuracy:		82.17 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.598747
  validation loss:		0.570935
  validation accuracy:		81.09 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.575240
  validation loss:		0.551899
  validation accuracy:		81.85 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.573622
  validation loss:		0.553689
  validation accuracy:		81.85 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.570846
  validation loss:		0.560696
  validation accuracy:		80.87 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.568373
  validation loss:		0.554789
  validation accuracy:		80.87 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.562603
  validation loss:		0.584696
  validation accuracy:		79.13 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.581415
  validation loss:		0.593989
  validation accuracy:		81.09 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.571262
  validation loss:		0.552792
  validation accuracy:		81.63 %
Epoch 438 of 2000 took 0.097s
  training loss:		0.586153
  validation loss:		0.569201
  validation accuracy:		79.89 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.567304
  validation loss:		0.559418
  validation accuracy:		81.20 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.565249
  validation loss:		0.557423
  validation accuracy:		80.65 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.586294
  validation loss:		0.567002
  validation accuracy:		79.78 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.578791
  validation loss:		0.547402
  validation accuracy:		82.17 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.573053
  validation loss:		0.648222
  validation accuracy:		78.80 %
Epoch 444 of 2000 took 0.099s
  training loss:		0.589987
  validation loss:		0.558049
  validation accuracy:		80.54 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.596110
  validation loss:		0.710927
  validation accuracy:		77.28 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.600490
  validation loss:		0.559637
  validation accuracy:		80.22 %
Epoch 447 of 2000 took 0.098s
  training loss:		0.567003
  validation loss:		0.554781
  validation accuracy:		80.65 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.587078
  validation loss:		0.592102
  validation accuracy:		81.09 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.584137
  validation loss:		0.549676
  validation accuracy:		81.52 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.573781
  validation loss:		0.562530
  validation accuracy:		80.22 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.570851
  validation loss:		0.545889
  validation accuracy:		81.96 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.569208
  validation loss:		0.554157
  validation accuracy:		80.65 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.567925
  validation loss:		0.548541
  validation accuracy:		81.30 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.573270
  validation loss:		0.582357
  validation accuracy:		79.46 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.574201
  validation loss:		0.559911
  validation accuracy:		81.09 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.576502
  validation loss:		0.576977
  validation accuracy:		81.20 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.573984
  validation loss:		0.551803
  validation accuracy:		81.20 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.561572
  validation loss:		0.575983
  validation accuracy:		80.00 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.580260
  validation loss:		0.563971
  validation accuracy:		81.09 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.569483
  validation loss:		0.552389
  validation accuracy:		81.20 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.582546
  validation loss:		0.555893
  validation accuracy:		80.54 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.572537
  validation loss:		0.550224
  validation accuracy:		81.41 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.570465
  validation loss:		0.551238
  validation accuracy:		81.09 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.570043
  validation loss:		0.566431
  validation accuracy:		80.54 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.564960
  validation loss:		0.561332
  validation accuracy:		80.22 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.574239
  validation loss:		0.548181
  validation accuracy:		81.30 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.584948
  validation loss:		0.552176
  validation accuracy:		80.87 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.570128
  validation loss:		0.541896
  validation accuracy:		82.72 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.579026
  validation loss:		0.555501
  validation accuracy:		80.87 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.562703
  validation loss:		0.619367
  validation accuracy:		80.43 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.586461
  validation loss:		0.549690
  validation accuracy:		81.63 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.578650
  validation loss:		0.542233
  validation accuracy:		82.61 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.583934
  validation loss:		0.552222
  validation accuracy:		81.96 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.562555
  validation loss:		0.585378
  validation accuracy:		79.35 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.573142
  validation loss:		0.545678
  validation accuracy:		82.07 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.564742
  validation loss:		0.557125
  validation accuracy:		81.52 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.553889
  validation loss:		0.557186
  validation accuracy:		81.09 %
Epoch 478 of 2000 took 0.098s
  training loss:		0.557939
  validation loss:		0.548576
  validation accuracy:		80.98 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.570486
  validation loss:		0.545299
  validation accuracy:		81.85 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.561862
  validation loss:		0.555075
  validation accuracy:		80.87 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.566012
  validation loss:		0.568462
  validation accuracy:		80.00 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.555074
  validation loss:		0.548493
  validation accuracy:		81.85 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.568847
  validation loss:		0.571550
  validation accuracy:		81.41 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.573420
  validation loss:		0.613329
  validation accuracy:		80.22 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.577906
  validation loss:		0.548164
  validation accuracy:		81.09 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.557582
  validation loss:		0.581032
  validation accuracy:		81.09 %
Epoch 487 of 2000 took 0.097s
  training loss:		0.582336
  validation loss:		0.555281
  validation accuracy:		81.63 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.558343
  validation loss:		0.550589
  validation accuracy:		81.30 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.556109
  validation loss:		0.548348
  validation accuracy:		81.09 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.570778
  validation loss:		0.586754
  validation accuracy:		81.09 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.572173
  validation loss:		0.555762
  validation accuracy:		81.74 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.565516
  validation loss:		0.561267
  validation accuracy:		80.33 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.561180
  validation loss:		0.544573
  validation accuracy:		81.63 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.571031
  validation loss:		0.542801
  validation accuracy:		81.52 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.562243
  validation loss:		0.538182
  validation accuracy:		81.96 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.554718
  validation loss:		0.564988
  validation accuracy:		80.33 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.565024
  validation loss:		0.553386
  validation accuracy:		81.52 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.552833
  validation loss:		0.538834
  validation accuracy:		81.41 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.558634
  validation loss:		0.554900
  validation accuracy:		80.98 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.561470
  validation loss:		0.541480
  validation accuracy:		82.28 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.568060
  validation loss:		0.576673
  validation accuracy:		81.20 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.563879
  validation loss:		0.574141
  validation accuracy:		80.00 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.576818
  validation loss:		0.547013
  validation accuracy:		81.52 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.560222
  validation loss:		0.552270
  validation accuracy:		81.09 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.548518
  validation loss:		0.544517
  validation accuracy:		82.07 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.558714
  validation loss:		0.570164
  validation accuracy:		81.09 %
Epoch 507 of 2000 took 0.097s
  training loss:		0.563782
  validation loss:		0.545400
  validation accuracy:		81.96 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.555060
  validation loss:		0.577040
  validation accuracy:		80.87 %
Epoch 509 of 2000 took 0.098s
  training loss:		0.560660
  validation loss:		0.568024
  validation accuracy:		81.20 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.569101
  validation loss:		0.558882
  validation accuracy:		82.07 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.567222
  validation loss:		0.570122
  validation accuracy:		81.09 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.574786
  validation loss:		0.571428
  validation accuracy:		80.98 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.557552
  validation loss:		0.557582
  validation accuracy:		81.20 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.563379
  validation loss:		0.550311
  validation accuracy:		81.30 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.564366
  validation loss:		0.547123
  validation accuracy:		81.41 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.560279
  validation loss:		0.557360
  validation accuracy:		81.20 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.552255
  validation loss:		0.556605
  validation accuracy:		81.63 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.554355
  validation loss:		0.543341
  validation accuracy:		81.41 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.562159
  validation loss:		0.560598
  validation accuracy:		81.20 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.571937
  validation loss:		0.541637
  validation accuracy:		81.96 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.554605
  validation loss:		0.545807
  validation accuracy:		81.74 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.552425
  validation loss:		0.579211
  validation accuracy:		79.89 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.554475
  validation loss:		0.546427
  validation accuracy:		81.52 %
Epoch 524 of 2000 took 0.098s
  training loss:		0.541069
  validation loss:		0.537661
  validation accuracy:		82.28 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.568286
  validation loss:		0.551580
  validation accuracy:		81.63 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.547489
  validation loss:		0.546612
  validation accuracy:		81.85 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.554981
  validation loss:		0.547917
  validation accuracy:		81.20 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.562707
  validation loss:		0.570441
  validation accuracy:		80.65 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.560629
  validation loss:		0.535416
  validation accuracy:		82.28 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.557052
  validation loss:		0.532920
  validation accuracy:		82.72 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.547704
  validation loss:		0.546229
  validation accuracy:		81.63 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.562425
  validation loss:		0.534288
  validation accuracy:		82.28 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.557126
  validation loss:		0.545977
  validation accuracy:		81.63 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.556555
  validation loss:		0.555383
  validation accuracy:		80.87 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.557719
  validation loss:		0.550746
  validation accuracy:		81.41 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.559230
  validation loss:		0.561044
  validation accuracy:		81.20 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.551521
  validation loss:		0.552881
  validation accuracy:		81.74 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.559241
  validation loss:		0.537871
  validation accuracy:		81.96 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.554068
  validation loss:		0.576605
  validation accuracy:		80.22 %
Epoch 540 of 2000 took 0.098s
  training loss:		0.561981
  validation loss:		0.540126
  validation accuracy:		81.85 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.549550
  validation loss:		0.553810
  validation accuracy:		81.41 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.560142
  validation loss:		0.554467
  validation accuracy:		80.98 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.550532
  validation loss:		0.542203
  validation accuracy:		81.63 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.573287
  validation loss:		0.540996
  validation accuracy:		81.85 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.559268
  validation loss:		0.546240
  validation accuracy:		81.74 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.546987
  validation loss:		0.548073
  validation accuracy:		81.52 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.551699
  validation loss:		0.558007
  validation accuracy:		81.41 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.555938
  validation loss:		0.536577
  validation accuracy:		82.17 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.557168
  validation loss:		0.558789
  validation accuracy:		81.41 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.555350
  validation loss:		0.556621
  validation accuracy:		80.98 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.550614
  validation loss:		0.540568
  validation accuracy:		81.96 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.565477
  validation loss:		0.529605
  validation accuracy:		82.83 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.560317
  validation loss:		0.532252
  validation accuracy:		82.61 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.570284
  validation loss:		0.578737
  validation accuracy:		80.22 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.554948
  validation loss:		0.534353
  validation accuracy:		82.07 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.558852
  validation loss:		0.538442
  validation accuracy:		81.74 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.557215
  validation loss:		0.573621
  validation accuracy:		81.41 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.562327
  validation loss:		0.543700
  validation accuracy:		82.17 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.552007
  validation loss:		0.548995
  validation accuracy:		81.52 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.550382
  validation loss:		0.552946
  validation accuracy:		81.30 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.558689
  validation loss:		0.558549
  validation accuracy:		81.52 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.549666
  validation loss:		0.556795
  validation accuracy:		80.87 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.566890
  validation loss:		0.590527
  validation accuracy:		80.98 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.574923
  validation loss:		0.536596
  validation accuracy:		82.28 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.564659
  validation loss:		0.562317
  validation accuracy:		80.98 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.568215
  validation loss:		0.529685
  validation accuracy:		82.50 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.554769
  validation loss:		0.543637
  validation accuracy:		82.28 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.553213
  validation loss:		0.559933
  validation accuracy:		81.09 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.546148
  validation loss:		0.535670
  validation accuracy:		82.61 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.547446
  validation loss:		0.537572
  validation accuracy:		82.07 %
Epoch 571 of 2000 took 0.098s
  training loss:		0.552180
  validation loss:		0.605729
  validation accuracy:		79.13 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.559346
  validation loss:		0.549545
  validation accuracy:		81.52 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.546727
  validation loss:		0.541452
  validation accuracy:		81.85 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.560968
  validation loss:		0.532921
  validation accuracy:		82.61 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.545019
  validation loss:		0.559769
  validation accuracy:		80.76 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.548609
  validation loss:		0.535269
  validation accuracy:		82.61 %
Epoch 577 of 2000 took 0.099s
  training loss:		0.567217
  validation loss:		0.558667
  validation accuracy:		81.09 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.554763
  validation loss:		0.544042
  validation accuracy:		81.30 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.561280
  validation loss:		0.579652
  validation accuracy:		80.33 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.563427
  validation loss:		0.583820
  validation accuracy:		79.46 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.584853
  validation loss:		0.541727
  validation accuracy:		82.07 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.554886
  validation loss:		0.563980
  validation accuracy:		80.54 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.550280
  validation loss:		0.541894
  validation accuracy:		82.17 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.553091
  validation loss:		0.538070
  validation accuracy:		82.28 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.563081
  validation loss:		0.537178
  validation accuracy:		82.07 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.563915
  validation loss:		0.551195
  validation accuracy:		80.87 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.551932
  validation loss:		0.549824
  validation accuracy:		81.09 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.572658
  validation loss:		0.534467
  validation accuracy:		82.39 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.561299
  validation loss:		0.537980
  validation accuracy:		81.85 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.553534
  validation loss:		0.547389
  validation accuracy:		82.50 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.553682
  validation loss:		0.543378
  validation accuracy:		81.20 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.564346
  validation loss:		0.554620
  validation accuracy:		80.76 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.559230
  validation loss:		0.540845
  validation accuracy:		81.85 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.560688
  validation loss:		0.566412
  validation accuracy:		80.98 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.551355
  validation loss:		0.536267
  validation accuracy:		81.85 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.556567
  validation loss:		0.533543
  validation accuracy:		82.07 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.548994
  validation loss:		0.563883
  validation accuracy:		80.65 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.557401
  validation loss:		0.552100
  validation accuracy:		81.52 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.549260
  validation loss:		0.533900
  validation accuracy:		82.39 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.553107
  validation loss:		0.537426
  validation accuracy:		81.85 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.547338
  validation loss:		0.529573
  validation accuracy:		82.28 %
Epoch 602 of 2000 took 0.098s
  training loss:		0.559600
  validation loss:		0.572384
  validation accuracy:		81.52 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.565915
  validation loss:		0.583218
  validation accuracy:		80.22 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.564451
  validation loss:		0.539445
  validation accuracy:		82.07 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.561733
  validation loss:		0.550142
  validation accuracy:		81.96 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.541156
  validation loss:		0.550563
  validation accuracy:		81.20 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.554072
  validation loss:		0.549822
  validation accuracy:		80.54 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.555394
  validation loss:		0.540907
  validation accuracy:		82.07 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.554097
  validation loss:		0.534153
  validation accuracy:		82.28 %
Epoch 610 of 2000 took 0.097s
  training loss:		0.556227
  validation loss:		0.540073
  validation accuracy:		82.50 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.550919
  validation loss:		0.530426
  validation accuracy:		82.61 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.548070
  validation loss:		0.529108
  validation accuracy:		82.39 %
Epoch 613 of 2000 took 0.097s
  training loss:		0.543374
  validation loss:		0.563401
  validation accuracy:		81.52 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.547071
  validation loss:		0.556556
  validation accuracy:		81.63 %
Epoch 615 of 2000 took 0.097s
  training loss:		0.549667
  validation loss:		0.532243
  validation accuracy:		82.07 %
Epoch 616 of 2000 took 0.097s
  training loss:		0.551721
  validation loss:		0.578298
  validation accuracy:		81.20 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.559430
  validation loss:		0.530087
  validation accuracy:		82.28 %
Epoch 618 of 2000 took 0.099s
  training loss:		0.541734
  validation loss:		0.538376
  validation accuracy:		82.39 %
Epoch 619 of 2000 took 0.100s
  training loss:		0.561141
  validation loss:		0.542864
  validation accuracy:		81.30 %
Epoch 620 of 2000 took 0.100s
  training loss:		0.557785
  validation loss:		0.552438
  validation accuracy:		81.74 %
Epoch 621 of 2000 took 0.100s
  training loss:		0.557174
  validation loss:		0.530085
  validation accuracy:		82.61 %
Epoch 622 of 2000 took 0.100s
  training loss:		0.550350
  validation loss:		0.540257
  validation accuracy:		81.41 %
Epoch 623 of 2000 took 0.100s
  training loss:		0.546373
  validation loss:		0.547399
  validation accuracy:		81.74 %
Epoch 624 of 2000 took 0.100s
  training loss:		0.564351
  validation loss:		0.547075
  validation accuracy:		81.74 %
Epoch 625 of 2000 took 0.100s
  training loss:		0.553395
  validation loss:		0.542477
  validation accuracy:		81.96 %
Epoch 626 of 2000 took 0.100s
  training loss:		0.546941
  validation loss:		0.533261
  validation accuracy:		81.74 %
Epoch 627 of 2000 took 0.100s
  training loss:		0.553393
  validation loss:		0.537611
  validation accuracy:		81.20 %
Epoch 628 of 2000 took 0.100s
  training loss:		0.552878
  validation loss:		0.581897
  validation accuracy:		81.09 %
Epoch 629 of 2000 took 0.100s
  training loss:		0.553001
  validation loss:		0.542062
  validation accuracy:		82.07 %
Epoch 630 of 2000 took 0.100s
  training loss:		0.555490
  validation loss:		0.563501
  validation accuracy:		80.87 %
Epoch 631 of 2000 took 0.100s
  training loss:		0.557598
  validation loss:		0.560326
  validation accuracy:		81.52 %
Epoch 632 of 2000 took 0.100s
  training loss:		0.545979
  validation loss:		0.549342
  validation accuracy:		81.52 %
Epoch 633 of 2000 took 0.101s
  training loss:		0.550317
  validation loss:		0.546057
  validation accuracy:		81.96 %
Epoch 634 of 2000 took 0.100s
  training loss:		0.556731
  validation loss:		0.564529
  validation accuracy:		81.30 %
Epoch 635 of 2000 took 0.100s
  training loss:		0.550981
  validation loss:		0.565679
  validation accuracy:		81.09 %
Epoch 636 of 2000 took 0.100s
  training loss:		0.564692
  validation loss:		0.535563
  validation accuracy:		82.50 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.555517
  validation loss:		0.558831
  validation accuracy:		81.41 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.543724
  validation loss:		0.529708
  validation accuracy:		82.28 %
Epoch 639 of 2000 took 0.100s
  training loss:		0.556641
  validation loss:		0.534455
  validation accuracy:		82.07 %
Epoch 640 of 2000 took 0.100s
  training loss:		0.552160
  validation loss:		0.548524
  validation accuracy:		81.85 %
Epoch 641 of 2000 took 0.100s
  training loss:		0.561894
  validation loss:		0.539208
  validation accuracy:		82.07 %
Epoch 642 of 2000 took 0.100s
  training loss:		0.548177
  validation loss:		0.559407
  validation accuracy:		81.30 %
Epoch 643 of 2000 took 0.100s
  training loss:		0.555961
  validation loss:		0.543142
  validation accuracy:		81.63 %
Epoch 644 of 2000 took 0.100s
  training loss:		0.552999
  validation loss:		0.551016
  validation accuracy:		81.63 %
Epoch 645 of 2000 took 0.100s
  training loss:		0.557261
  validation loss:		0.530384
  validation accuracy:		82.28 %
Epoch 646 of 2000 took 0.100s
  training loss:		0.538745
  validation loss:		0.527768
  validation accuracy:		82.61 %
Epoch 647 of 2000 took 0.100s
  training loss:		0.550077
  validation loss:		0.546001
  validation accuracy:		82.28 %
Epoch 648 of 2000 took 0.100s
  training loss:		0.551022
  validation loss:		0.554327
  validation accuracy:		81.63 %
Epoch 649 of 2000 took 0.100s
  training loss:		0.543746
  validation loss:		0.551893
  validation accuracy:		81.41 %
Epoch 650 of 2000 took 0.100s
  training loss:		0.546327
  validation loss:		0.563804
  validation accuracy:		81.09 %
Epoch 651 of 2000 took 0.100s
  training loss:		0.555286
  validation loss:		0.578018
  validation accuracy:		81.09 %
Epoch 652 of 2000 took 0.100s
  training loss:		0.563511
  validation loss:		0.548351
  validation accuracy:		81.52 %
Epoch 653 of 2000 took 0.100s
  training loss:		0.550272
  validation loss:		0.536837
  validation accuracy:		82.83 %
Epoch 654 of 2000 took 0.100s
  training loss:		0.551136
  validation loss:		0.540154
  validation accuracy:		82.07 %
Epoch 655 of 2000 took 0.100s
  training loss:		0.551152
  validation loss:		0.529187
  validation accuracy:		82.28 %
Epoch 656 of 2000 took 0.100s
  training loss:		0.542597
  validation loss:		0.528113
  validation accuracy:		82.17 %
Epoch 657 of 2000 took 0.101s
  training loss:		0.553742
  validation loss:		0.561504
  validation accuracy:		81.20 %
Epoch 658 of 2000 took 0.103s
  training loss:		0.556005
  validation loss:		0.538290
  validation accuracy:		81.63 %
Epoch 659 of 2000 took 0.103s
  training loss:		0.565054
  validation loss:		0.533571
  validation accuracy:		82.50 %
Epoch 660 of 2000 took 0.103s
  training loss:		0.552444
  validation loss:		0.531530
  validation accuracy:		82.28 %
Epoch 661 of 2000 took 0.103s
  training loss:		0.545443
  validation loss:		0.535022
  validation accuracy:		81.85 %
Epoch 662 of 2000 took 0.103s
  training loss:		0.558454
  validation loss:		0.564379
  validation accuracy:		81.63 %
Epoch 663 of 2000 took 0.104s
  training loss:		0.546695
  validation loss:		0.535954
  validation accuracy:		82.07 %
Epoch 664 of 2000 took 0.103s
  training loss:		0.551335
  validation loss:		0.533986
  validation accuracy:		82.72 %
Epoch 665 of 2000 took 0.103s
  training loss:		0.544204
  validation loss:		0.532388
  validation accuracy:		82.28 %
Epoch 666 of 2000 took 0.103s
  training loss:		0.553531
  validation loss:		0.566548
  validation accuracy:		81.41 %
Epoch 667 of 2000 took 0.103s
  training loss:		0.545793
  validation loss:		0.546838
  validation accuracy:		81.85 %
Epoch 668 of 2000 took 0.103s
  training loss:		0.560416
  validation loss:		0.553309
  validation accuracy:		81.30 %
Epoch 669 of 2000 took 0.103s
  training loss:		0.548644
  validation loss:		0.545522
  validation accuracy:		81.85 %
Epoch 670 of 2000 took 0.103s
  training loss:		0.546586
  validation loss:		0.558358
  validation accuracy:		81.41 %
Epoch 671 of 2000 took 0.103s
  training loss:		0.547885
  validation loss:		0.528316
  validation accuracy:		82.83 %
Epoch 672 of 2000 took 0.103s
  training loss:		0.542094
  validation loss:		0.536623
  validation accuracy:		82.17 %
Epoch 673 of 2000 took 0.103s
  training loss:		0.556117
  validation loss:		0.546331
  validation accuracy:		82.50 %
Epoch 674 of 2000 took 0.103s
  training loss:		0.547614
  validation loss:		0.535087
  validation accuracy:		82.17 %
Epoch 675 of 2000 took 0.103s
  training loss:		0.562850
  validation loss:		0.587013
  validation accuracy:		79.46 %
Epoch 676 of 2000 took 0.103s
  training loss:		0.556057
  validation loss:		0.551725
  validation accuracy:		81.63 %
Epoch 677 of 2000 took 0.103s
  training loss:		0.547937
  validation loss:		0.538009
  validation accuracy:		82.28 %
Epoch 678 of 2000 took 0.103s
  training loss:		0.549269
  validation loss:		0.586272
  validation accuracy:		80.22 %
Epoch 679 of 2000 took 0.103s
  training loss:		0.550016
  validation loss:		0.541819
  validation accuracy:		81.96 %
Epoch 680 of 2000 took 0.103s
  training loss:		0.544134
  validation loss:		0.536949
  validation accuracy:		82.07 %
Epoch 681 of 2000 took 0.103s
  training loss:		0.558559
  validation loss:		0.562004
  validation accuracy:		81.30 %
Epoch 682 of 2000 took 0.103s
  training loss:		0.555799
  validation loss:		0.539529
  validation accuracy:		81.63 %
Epoch 683 of 2000 took 0.103s
  training loss:		0.554754
  validation loss:		0.550180
  validation accuracy:		80.76 %
Epoch 684 of 2000 took 0.103s
  training loss:		0.550533
  validation loss:		0.535216
  validation accuracy:		81.96 %
Epoch 685 of 2000 took 0.103s
  training loss:		0.564091
  validation loss:		0.552684
  validation accuracy:		81.96 %
Epoch 686 of 2000 took 0.103s
  training loss:		0.542155
  validation loss:		0.538212
  validation accuracy:		81.96 %
Epoch 687 of 2000 took 0.100s
  training loss:		0.557672
  validation loss:		0.533168
  validation accuracy:		82.17 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.546530
  validation loss:		0.532927
  validation accuracy:		81.41 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.545929
  validation loss:		0.529131
  validation accuracy:		82.50 %
Epoch 690 of 2000 took 0.100s
  training loss:		0.549037
  validation loss:		0.532001
  validation accuracy:		81.74 %
Epoch 691 of 2000 took 0.100s
  training loss:		0.544362
  validation loss:		0.539861
  validation accuracy:		82.61 %
Epoch 692 of 2000 took 0.101s
  training loss:		0.539450
  validation loss:		0.566478
  validation accuracy:		80.98 %
Epoch 693 of 2000 took 0.100s
  training loss:		0.553053
  validation loss:		0.547384
  validation accuracy:		82.39 %
Epoch 694 of 2000 took 0.100s
  training loss:		0.561850
  validation loss:		0.526139
  validation accuracy:		82.28 %
Epoch 695 of 2000 took 0.100s
  training loss:		0.543891
  validation loss:		0.540302
  validation accuracy:		81.41 %
Epoch 696 of 2000 took 0.099s
  training loss:		0.546318
  validation loss:		0.535938
  validation accuracy:		81.41 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.544519
  validation loss:		0.536857
  validation accuracy:		82.17 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.545729
  validation loss:		0.554424
  validation accuracy:		81.30 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.566226
  validation loss:		0.546295
  validation accuracy:		82.07 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.553417
  validation loss:		0.545672
  validation accuracy:		81.63 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.543492
  validation loss:		0.539835
  validation accuracy:		81.96 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.552447
  validation loss:		0.580074
  validation accuracy:		80.87 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.551611
  validation loss:		0.527081
  validation accuracy:		81.74 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.548408
  validation loss:		0.531468
  validation accuracy:		81.74 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.550065
  validation loss:		0.539664
  validation accuracy:		81.41 %
Epoch 706 of 2000 took 0.097s
  training loss:		0.545261
  validation loss:		0.539134
  validation accuracy:		82.17 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.545530
  validation loss:		0.533221
  validation accuracy:		82.28 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.550833
  validation loss:		0.526370
  validation accuracy:		82.39 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.560135
  validation loss:		0.543931
  validation accuracy:		81.85 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.544191
  validation loss:		0.540972
  validation accuracy:		81.85 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.541225
  validation loss:		0.532953
  validation accuracy:		82.39 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.544022
  validation loss:		0.556923
  validation accuracy:		81.41 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.550674
  validation loss:		0.624703
  validation accuracy:		80.33 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.546932
  validation loss:		0.540753
  validation accuracy:		82.07 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.543041
  validation loss:		0.546868
  validation accuracy:		81.74 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.544100
  validation loss:		0.532254
  validation accuracy:		82.39 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.546847
  validation loss:		0.530475
  validation accuracy:		81.41 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.550816
  validation loss:		0.553837
  validation accuracy:		81.96 %
Epoch 719 of 2000 took 0.097s
  training loss:		0.533196
  validation loss:		0.555256
  validation accuracy:		81.74 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.540417
  validation loss:		0.560016
  validation accuracy:		80.65 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.541352
  validation loss:		0.531129
  validation accuracy:		82.28 %
Epoch 722 of 2000 took 0.097s
  training loss:		0.543535
  validation loss:		0.543623
  validation accuracy:		81.96 %
Epoch 723 of 2000 took 0.098s
  training loss:		0.537521
  validation loss:		0.542440
  validation accuracy:		82.07 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.546402
  validation loss:		0.538239
  validation accuracy:		81.96 %
Epoch 725 of 2000 took 0.097s
  training loss:		0.549708
  validation loss:		0.547265
  validation accuracy:		82.07 %
Epoch 726 of 2000 took 0.097s
  training loss:		0.539580
  validation loss:		0.560689
  validation accuracy:		81.30 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.553250
  validation loss:		0.546780
  validation accuracy:		81.63 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.536656
  validation loss:		0.529974
  validation accuracy:		82.28 %
Epoch 729 of 2000 took 0.097s
  training loss:		0.542550
  validation loss:		0.532611
  validation accuracy:		81.85 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.540225
  validation loss:		0.528306
  validation accuracy:		82.39 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.542817
  validation loss:		0.540082
  validation accuracy:		82.28 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.541919
  validation loss:		0.539185
  validation accuracy:		82.39 %
Epoch 733 of 2000 took 0.097s
  training loss:		0.547423
  validation loss:		0.548144
  validation accuracy:		81.96 %
Epoch 734 of 2000 took 0.099s
  training loss:		0.534737
  validation loss:		0.532612
  validation accuracy:		82.72 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.541059
  validation loss:		0.534337
  validation accuracy:		82.07 %
Epoch 736 of 2000 took 0.097s
  training loss:		0.543118
  validation loss:		0.550617
  validation accuracy:		81.09 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.548966
  validation loss:		0.559055
  validation accuracy:		81.20 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.551767
  validation loss:		0.546821
  validation accuracy:		82.17 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.548358
  validation loss:		0.525345
  validation accuracy:		82.17 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.548080
  validation loss:		0.521677
  validation accuracy:		82.61 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.539271
  validation loss:		0.557463
  validation accuracy:		81.30 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.542716
  validation loss:		0.543997
  validation accuracy:		81.74 %
Epoch 743 of 2000 took 0.097s
  training loss:		0.547783
  validation loss:		0.531349
  validation accuracy:		81.96 %
Epoch 744 of 2000 took 0.097s
  training loss:		0.533384
  validation loss:		0.527498
  validation accuracy:		82.50 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.551886
  validation loss:		0.534269
  validation accuracy:		82.50 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.539313
  validation loss:		0.575993
  validation accuracy:		81.20 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.542048
  validation loss:		0.533219
  validation accuracy:		82.50 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.538922
  validation loss:		0.551995
  validation accuracy:		81.52 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.544302
  validation loss:		0.535699
  validation accuracy:		82.61 %
Epoch 750 of 2000 took 0.097s
  training loss:		0.544043
  validation loss:		0.532901
  validation accuracy:		81.52 %
Epoch 751 of 2000 took 0.097s
  training loss:		0.545516
  validation loss:		0.549281
  validation accuracy:		81.74 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.542437
  validation loss:		0.571903
  validation accuracy:		81.41 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.536137
  validation loss:		0.539172
  validation accuracy:		82.07 %
Epoch 754 of 2000 took 0.098s
  training loss:		0.539886
  validation loss:		0.533669
  validation accuracy:		82.50 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.539248
  validation loss:		0.526748
  validation accuracy:		82.72 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.540915
  validation loss:		0.543137
  validation accuracy:		82.28 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.541139
  validation loss:		0.544565
  validation accuracy:		81.74 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.538612
  validation loss:		0.525597
  validation accuracy:		82.28 %
Epoch 759 of 2000 took 0.097s
  training loss:		0.549404
  validation loss:		0.537359
  validation accuracy:		82.61 %
Epoch 760 of 2000 took 0.097s
  training loss:		0.542608
  validation loss:		0.520380
  validation accuracy:		82.50 %
Epoch 761 of 2000 took 0.097s
  training loss:		0.534615
  validation loss:		0.524899
  validation accuracy:		82.28 %
Epoch 762 of 2000 took 0.097s
  training loss:		0.530458
  validation loss:		0.525413
  validation accuracy:		82.61 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.543610
  validation loss:		0.529806
  validation accuracy:		82.50 %
Epoch 764 of 2000 took 0.097s
  training loss:		0.536878
  validation loss:		0.546027
  validation accuracy:		81.74 %
Epoch 765 of 2000 took 0.097s
  training loss:		0.540764
  validation loss:		0.538920
  validation accuracy:		81.52 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.527905
  validation loss:		0.561204
  validation accuracy:		81.30 %
Epoch 767 of 2000 took 0.097s
  training loss:		0.543364
  validation loss:		0.530112
  validation accuracy:		82.83 %
Epoch 768 of 2000 took 0.097s
  training loss:		0.541669
  validation loss:		0.564712
  validation accuracy:		81.52 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.539682
  validation loss:		0.522962
  validation accuracy:		82.50 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.541163
  validation loss:		0.521946
  validation accuracy:		83.04 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.536758
  validation loss:		0.527299
  validation accuracy:		82.17 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.537115
  validation loss:		0.526268
  validation accuracy:		82.72 %
Epoch 773 of 2000 took 0.097s
  training loss:		0.550016
  validation loss:		0.533895
  validation accuracy:		81.85 %
Epoch 774 of 2000 took 0.097s
  training loss:		0.539468
  validation loss:		0.527995
  validation accuracy:		82.93 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.527249
  validation loss:		0.529384
  validation accuracy:		81.85 %
Epoch 776 of 2000 took 0.097s
  training loss:		0.532976
  validation loss:		0.530984
  validation accuracy:		82.28 %
Epoch 777 of 2000 took 0.097s
  training loss:		0.531348
  validation loss:		0.524307
  validation accuracy:		82.50 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.537923
  validation loss:		0.524154
  validation accuracy:		82.28 %
Epoch 779 of 2000 took 0.097s
  training loss:		0.528773
  validation loss:		0.544130
  validation accuracy:		82.07 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.544145
  validation loss:		0.530617
  validation accuracy:		82.50 %
Epoch 781 of 2000 took 0.097s
  training loss:		0.532989
  validation loss:		0.532108
  validation accuracy:		82.07 %
Epoch 782 of 2000 took 0.097s
  training loss:		0.528377
  validation loss:		0.521316
  validation accuracy:		82.61 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.539261
  validation loss:		0.527129
  validation accuracy:		82.28 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.529537
  validation loss:		0.515014
  validation accuracy:		82.83 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.528921
  validation loss:		0.537968
  validation accuracy:		81.74 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.520848
  validation loss:		0.511448
  validation accuracy:		83.26 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.530509
  validation loss:		0.525128
  validation accuracy:		81.85 %
Epoch 788 of 2000 took 0.097s
  training loss:		0.523326
  validation loss:		0.530217
  validation accuracy:		82.50 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.529888
  validation loss:		0.529030
  validation accuracy:		82.28 %
Epoch 790 of 2000 took 0.097s
  training loss:		0.532254
  validation loss:		0.556347
  validation accuracy:		80.65 %
Epoch 791 of 2000 took 0.097s
  training loss:		0.535451
  validation loss:		0.536054
  validation accuracy:		81.96 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.520389
  validation loss:		0.531824
  validation accuracy:		82.07 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.532111
  validation loss:		0.522163
  validation accuracy:		82.83 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.519337
  validation loss:		0.519660
  validation accuracy:		82.39 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.522169
  validation loss:		0.591040
  validation accuracy:		80.22 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.530452
  validation loss:		0.518290
  validation accuracy:		82.83 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.526664
  validation loss:		0.538485
  validation accuracy:		81.74 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.530330
  validation loss:		0.524105
  validation accuracy:		82.07 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.535749
  validation loss:		0.564571
  validation accuracy:		80.54 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.532004
  validation loss:		0.539707
  validation accuracy:		81.96 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.514192
  validation loss:		0.517206
  validation accuracy:		82.50 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.527119
  validation loss:		0.511532
  validation accuracy:		83.15 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.520179
  validation loss:		0.527125
  validation accuracy:		81.96 %
Epoch 804 of 2000 took 0.097s
  training loss:		0.517330
  validation loss:		0.533478
  validation accuracy:		81.74 %
Epoch 805 of 2000 took 0.097s
  training loss:		0.515595
  validation loss:		0.524517
  validation accuracy:		81.96 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.525686
  validation loss:		0.510732
  validation accuracy:		82.83 %
Epoch 807 of 2000 took 0.097s
  training loss:		0.510162
  validation loss:		0.516682
  validation accuracy:		83.37 %
Epoch 808 of 2000 took 0.097s
  training loss:		0.515732
  validation loss:		0.512687
  validation accuracy:		82.61 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.523182
  validation loss:		0.506834
  validation accuracy:		83.59 %
Epoch 810 of 2000 took 0.097s
  training loss:		0.516333
  validation loss:		0.505493
  validation accuracy:		83.26 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.516874
  validation loss:		0.518212
  validation accuracy:		83.37 %
Epoch 812 of 2000 took 0.097s
  training loss:		0.512246
  validation loss:		0.506256
  validation accuracy:		83.70 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.511345
  validation loss:		0.510071
  validation accuracy:		82.72 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.525574
  validation loss:		0.513011
  validation accuracy:		82.83 %
Epoch 815 of 2000 took 0.097s
  training loss:		0.508078
  validation loss:		0.501080
  validation accuracy:		83.70 %
Epoch 816 of 2000 took 0.097s
  training loss:		0.508325
  validation loss:		0.506356
  validation accuracy:		83.37 %
Epoch 817 of 2000 took 0.098s
  training loss:		0.525157
  validation loss:		0.524627
  validation accuracy:		81.85 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.511461
  validation loss:		0.510791
  validation accuracy:		82.61 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.512392
  validation loss:		0.498168
  validation accuracy:		84.46 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.501210
  validation loss:		0.502519
  validation accuracy:		83.59 %
Epoch 821 of 2000 took 0.097s
  training loss:		0.504165
  validation loss:		0.511906
  validation accuracy:		82.61 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.511992
  validation loss:		0.501407
  validation accuracy:		82.93 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.500364
  validation loss:		0.518134
  validation accuracy:		82.28 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.507941
  validation loss:		0.492108
  validation accuracy:		84.35 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.498269
  validation loss:		0.504808
  validation accuracy:		83.37 %
Epoch 826 of 2000 took 0.097s
  training loss:		0.493471
  validation loss:		0.494656
  validation accuracy:		83.80 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.495555
  validation loss:		0.488482
  validation accuracy:		84.46 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.496996
  validation loss:		0.513184
  validation accuracy:		83.59 %
Epoch 829 of 2000 took 0.097s
  training loss:		0.487387
  validation loss:		0.490229
  validation accuracy:		84.67 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.487683
  validation loss:		0.487330
  validation accuracy:		84.24 %
Epoch 831 of 2000 took 0.098s
  training loss:		0.495177
  validation loss:		0.482338
  validation accuracy:		84.24 %
Epoch 832 of 2000 took 0.097s
  training loss:		0.493162
  validation loss:		0.498990
  validation accuracy:		83.91 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.490968
  validation loss:		0.483268
  validation accuracy:		84.78 %
Epoch 834 of 2000 took 0.097s
  training loss:		0.482331
  validation loss:		0.506658
  validation accuracy:		83.59 %
Epoch 835 of 2000 took 0.097s
  training loss:		0.485878
  validation loss:		0.498676
  validation accuracy:		84.35 %
Epoch 836 of 2000 took 0.097s
  training loss:		0.475668
  validation loss:		0.500836
  validation accuracy:		83.80 %
Epoch 837 of 2000 took 0.097s
  training loss:		0.485963
  validation loss:		0.501281
  validation accuracy:		83.80 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.487747
  validation loss:		0.502158
  validation accuracy:		83.80 %
Epoch 839 of 2000 took 0.097s
  training loss:		0.480809
  validation loss:		0.485089
  validation accuracy:		84.89 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.484869
  validation loss:		0.474367
  validation accuracy:		85.22 %
Epoch 841 of 2000 took 0.097s
  training loss:		0.475212
  validation loss:		0.479439
  validation accuracy:		84.89 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.470992
  validation loss:		0.479235
  validation accuracy:		85.33 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.475144
  validation loss:		0.479719
  validation accuracy:		84.78 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.476884
  validation loss:		0.477980
  validation accuracy:		85.65 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.469753
  validation loss:		0.515470
  validation accuracy:		82.61 %
Epoch 846 of 2000 took 0.097s
  training loss:		0.475131
  validation loss:		0.490957
  validation accuracy:		83.48 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.465620
  validation loss:		0.470085
  validation accuracy:		84.67 %
Epoch 848 of 2000 took 0.098s
  training loss:		0.466739
  validation loss:		0.485590
  validation accuracy:		85.00 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.476310
  validation loss:		0.476934
  validation accuracy:		84.35 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.459968
  validation loss:		0.490479
  validation accuracy:		84.24 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.466764
  validation loss:		0.477486
  validation accuracy:		84.57 %
Epoch 852 of 2000 took 0.097s
  training loss:		0.463558
  validation loss:		0.476354
  validation accuracy:		85.11 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.456689
  validation loss:		0.468801
  validation accuracy:		84.67 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.466903
  validation loss:		0.508326
  validation accuracy:		82.83 %
Epoch 855 of 2000 took 0.097s
  training loss:		0.459003
  validation loss:		0.464435
  validation accuracy:		85.65 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.458004
  validation loss:		0.472641
  validation accuracy:		84.67 %
Epoch 857 of 2000 took 0.097s
  training loss:		0.455680
  validation loss:		0.468337
  validation accuracy:		84.78 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.457752
  validation loss:		0.470900
  validation accuracy:		84.78 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.447730
  validation loss:		0.465395
  validation accuracy:		85.00 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.459207
  validation loss:		0.465007
  validation accuracy:		85.33 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.458260
  validation loss:		0.463424
  validation accuracy:		85.54 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.451019
  validation loss:		0.463541
  validation accuracy:		84.67 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.459794
  validation loss:		0.485567
  validation accuracy:		84.78 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.455025
  validation loss:		0.463770
  validation accuracy:		85.43 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.456215
  validation loss:		0.468329
  validation accuracy:		85.00 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.443706
  validation loss:		0.463903
  validation accuracy:		85.65 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.448958
  validation loss:		0.458570
  validation accuracy:		85.65 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.450834
  validation loss:		0.467415
  validation accuracy:		85.11 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.441090
  validation loss:		0.451758
  validation accuracy:		85.98 %
Epoch 870 of 2000 took 0.097s
  training loss:		0.450520
  validation loss:		0.460257
  validation accuracy:		85.76 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.450560
  validation loss:		0.452524
  validation accuracy:		85.87 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.441481
  validation loss:		0.461185
  validation accuracy:		84.89 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.444027
  validation loss:		0.461110
  validation accuracy:		85.43 %
Epoch 874 of 2000 took 0.097s
  training loss:		0.431482
  validation loss:		0.483659
  validation accuracy:		83.91 %
Epoch 875 of 2000 took 0.097s
  training loss:		0.440107
  validation loss:		0.455731
  validation accuracy:		85.22 %
Epoch 876 of 2000 took 0.097s
  training loss:		0.445657
  validation loss:		0.453108
  validation accuracy:		85.54 %
Epoch 877 of 2000 took 0.097s
  training loss:		0.441300
  validation loss:		0.451651
  validation accuracy:		85.54 %
Epoch 878 of 2000 took 0.097s
  training loss:		0.445357
  validation loss:		0.452278
  validation accuracy:		85.65 %
Epoch 879 of 2000 took 0.098s
  training loss:		0.438029
  validation loss:		0.455097
  validation accuracy:		85.43 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.436184
  validation loss:		0.478770
  validation accuracy:		84.35 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.456623
  validation loss:		0.458260
  validation accuracy:		85.76 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.434115
  validation loss:		0.460361
  validation accuracy:		85.00 %
Epoch 883 of 2000 took 0.097s
  training loss:		0.434043
  validation loss:		0.449737
  validation accuracy:		85.43 %
Epoch 884 of 2000 took 0.097s
  training loss:		0.432226
  validation loss:		0.455751
  validation accuracy:		85.65 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.424169
  validation loss:		0.459336
  validation accuracy:		85.11 %
Epoch 886 of 2000 took 0.097s
  training loss:		0.426836
  validation loss:		0.461360
  validation accuracy:		84.89 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.433685
  validation loss:		0.447138
  validation accuracy:		85.98 %
Epoch 888 of 2000 took 0.097s
  training loss:		0.430685
  validation loss:		0.463210
  validation accuracy:		84.89 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.432671
  validation loss:		0.466352
  validation accuracy:		84.46 %
Epoch 890 of 2000 took 0.097s
  training loss:		0.426860
  validation loss:		0.453420
  validation accuracy:		85.65 %
Epoch 891 of 2000 took 0.097s
  training loss:		0.424755
  validation loss:		0.456056
  validation accuracy:		85.43 %
Epoch 892 of 2000 took 0.097s
  training loss:		0.426271
  validation loss:		0.439749
  validation accuracy:		85.65 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.425087
  validation loss:		0.451029
  validation accuracy:		85.65 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.425379
  validation loss:		0.444076
  validation accuracy:		85.65 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.419730
  validation loss:		0.443291
  validation accuracy:		85.76 %
Epoch 896 of 2000 took 0.097s
  training loss:		0.423886
  validation loss:		0.461664
  validation accuracy:		85.87 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.426679
  validation loss:		0.453975
  validation accuracy:		85.54 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.418486
  validation loss:		0.443411
  validation accuracy:		86.20 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.414675
  validation loss:		0.434213
  validation accuracy:		86.20 %
Epoch 900 of 2000 took 0.097s
  training loss:		0.417647
  validation loss:		0.457558
  validation accuracy:		85.11 %
Epoch 901 of 2000 took 0.097s
  training loss:		0.420161
  validation loss:		0.475442
  validation accuracy:		83.70 %
Epoch 902 of 2000 took 0.097s
  training loss:		0.419431
  validation loss:		0.448567
  validation accuracy:		85.98 %
Epoch 903 of 2000 took 0.097s
  training loss:		0.407783
  validation loss:		0.457143
  validation accuracy:		84.78 %
Epoch 904 of 2000 took 0.097s
  training loss:		0.413169
  validation loss:		0.441878
  validation accuracy:		85.43 %
Epoch 905 of 2000 took 0.097s
  training loss:		0.415937
  validation loss:		0.442354
  validation accuracy:		85.76 %
Epoch 906 of 2000 took 0.097s
  training loss:		0.412447
  validation loss:		0.460380
  validation accuracy:		85.00 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.416856
  validation loss:		0.453061
  validation accuracy:		85.22 %
Epoch 908 of 2000 took 0.097s
  training loss:		0.416150
  validation loss:		0.436439
  validation accuracy:		86.30 %
Epoch 909 of 2000 took 0.097s
  training loss:		0.409390
  validation loss:		0.454426
  validation accuracy:		85.43 %
Epoch 910 of 2000 took 0.098s
  training loss:		0.412679
  validation loss:		0.450481
  validation accuracy:		85.00 %
Epoch 911 of 2000 took 0.097s
  training loss:		0.405698
  validation loss:		0.439362
  validation accuracy:		85.87 %
Epoch 912 of 2000 took 0.097s
  training loss:		0.408621
  validation loss:		0.475727
  validation accuracy:		84.89 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.414624
  validation loss:		0.461031
  validation accuracy:		84.78 %
Epoch 914 of 2000 took 0.097s
  training loss:		0.411742
  validation loss:		0.446503
  validation accuracy:		85.98 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.402192
  validation loss:		0.432922
  validation accuracy:		86.52 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.402233
  validation loss:		0.454254
  validation accuracy:		85.65 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.404061
  validation loss:		0.423196
  validation accuracy:		86.20 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.407514
  validation loss:		0.449680
  validation accuracy:		85.54 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.403382
  validation loss:		0.440859
  validation accuracy:		85.87 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.395809
  validation loss:		0.434282
  validation accuracy:		86.30 %
Epoch 921 of 2000 took 0.097s
  training loss:		0.400505
  validation loss:		0.438514
  validation accuracy:		86.41 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.393518
  validation loss:		0.445377
  validation accuracy:		85.65 %
Epoch 923 of 2000 took 0.097s
  training loss:		0.393431
  validation loss:		0.447434
  validation accuracy:		85.65 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.403807
  validation loss:		0.445628
  validation accuracy:		85.98 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.394200
  validation loss:		0.430289
  validation accuracy:		86.41 %
Epoch 926 of 2000 took 0.099s
  training loss:		0.392832
  validation loss:		0.442320
  validation accuracy:		86.30 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.396587
  validation loss:		0.444516
  validation accuracy:		85.76 %
Epoch 928 of 2000 took 0.097s
  training loss:		0.388347
  validation loss:		0.434545
  validation accuracy:		86.20 %
Epoch 929 of 2000 took 0.097s
  training loss:		0.395483
  validation loss:		0.423677
  validation accuracy:		86.52 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.394490
  validation loss:		0.427845
  validation accuracy:		86.63 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.392157
  validation loss:		0.440473
  validation accuracy:		85.87 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.386130
  validation loss:		0.437145
  validation accuracy:		86.20 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.378264
  validation loss:		0.445317
  validation accuracy:		85.87 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.379870
  validation loss:		0.448297
  validation accuracy:		85.65 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.377559
  validation loss:		0.417326
  validation accuracy:		86.96 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.383503
  validation loss:		0.438298
  validation accuracy:		86.52 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.379755
  validation loss:		0.417621
  validation accuracy:		86.52 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.387813
  validation loss:		0.429262
  validation accuracy:		86.09 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.382134
  validation loss:		0.435452
  validation accuracy:		86.09 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.392731
  validation loss:		0.425132
  validation accuracy:		86.52 %
Epoch 941 of 2000 took 0.098s
  training loss:		0.381526
  validation loss:		0.428955
  validation accuracy:		86.41 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.385073
  validation loss:		0.438587
  validation accuracy:		86.52 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.379309
  validation loss:		0.420191
  validation accuracy:		86.85 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.383847
  validation loss:		0.417867
  validation accuracy:		86.30 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.378457
  validation loss:		0.421071
  validation accuracy:		86.85 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.375054
  validation loss:		0.410064
  validation accuracy:		86.96 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.383667
  validation loss:		0.434246
  validation accuracy:		86.85 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.373475
  validation loss:		0.429759
  validation accuracy:		86.52 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.373999
  validation loss:		0.431188
  validation accuracy:		86.52 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.372706
  validation loss:		0.419941
  validation accuracy:		86.74 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.371419
  validation loss:		0.435832
  validation accuracy:		85.98 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.375138
  validation loss:		0.439689
  validation accuracy:		86.20 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.373883
  validation loss:		0.425128
  validation accuracy:		86.74 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.364930
  validation loss:		0.426478
  validation accuracy:		86.63 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.372860
  validation loss:		0.425128
  validation accuracy:		86.74 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.367088
  validation loss:		0.441115
  validation accuracy:		86.41 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.376009
  validation loss:		0.419760
  validation accuracy:		87.28 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.368943
  validation loss:		0.417748
  validation accuracy:		87.17 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.362956
  validation loss:		0.438304
  validation accuracy:		85.76 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.366300
  validation loss:		0.423472
  validation accuracy:		86.41 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.365693
  validation loss:		0.411746
  validation accuracy:		87.28 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.362341
  validation loss:		0.429893
  validation accuracy:		86.20 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.360535
  validation loss:		0.429028
  validation accuracy:		86.85 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.372014
  validation loss:		0.419440
  validation accuracy:		87.17 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.366746
  validation loss:		0.435356
  validation accuracy:		86.63 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.362929
  validation loss:		0.422943
  validation accuracy:		86.85 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.363871
  validation loss:		0.421061
  validation accuracy:		87.17 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.364363
  validation loss:		0.415300
  validation accuracy:		86.85 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.358922
  validation loss:		0.440753
  validation accuracy:		86.74 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.360086
  validation loss:		0.419846
  validation accuracy:		86.85 %
Epoch 971 of 2000 took 0.097s
  training loss:		0.362603
  validation loss:		0.420965
  validation accuracy:		86.85 %
Epoch 972 of 2000 took 0.098s
  training loss:		0.364775
  validation loss:		0.432917
  validation accuracy:		86.41 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.355205
  validation loss:		0.408940
  validation accuracy:		87.39 %
Epoch 974 of 2000 took 0.097s
  training loss:		0.356196
  validation loss:		0.413120
  validation accuracy:		86.74 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.355355
  validation loss:		0.446808
  validation accuracy:		85.65 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.355758
  validation loss:		0.412399
  validation accuracy:		87.28 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.355132
  validation loss:		0.421398
  validation accuracy:		86.52 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.351629
  validation loss:		0.409730
  validation accuracy:		87.28 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.358983
  validation loss:		0.440234
  validation accuracy:		85.54 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.351440
  validation loss:		0.425779
  validation accuracy:		86.74 %
Epoch 981 of 2000 took 0.097s
  training loss:		0.355471
  validation loss:		0.415970
  validation accuracy:		86.74 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.357805
  validation loss:		0.406148
  validation accuracy:		87.17 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.352858
  validation loss:		0.417591
  validation accuracy:		87.07 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.360681
  validation loss:		0.416398
  validation accuracy:		86.63 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.349266
  validation loss:		0.416686
  validation accuracy:		87.07 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.352779
  validation loss:		0.409051
  validation accuracy:		86.74 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.344936
  validation loss:		0.404940
  validation accuracy:		87.50 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.355399
  validation loss:		0.428926
  validation accuracy:		86.85 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.351317
  validation loss:		0.413386
  validation accuracy:		86.96 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.344638
  validation loss:		0.437991
  validation accuracy:		86.20 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.351745
  validation loss:		0.427457
  validation accuracy:		85.98 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.354546
  validation loss:		0.421863
  validation accuracy:		86.74 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.343895
  validation loss:		0.404686
  validation accuracy:		87.07 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.348091
  validation loss:		0.448381
  validation accuracy:		86.20 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.347712
  validation loss:		0.413000
  validation accuracy:		86.85 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.343679
  validation loss:		0.400747
  validation accuracy:		86.85 %
Epoch 997 of 2000 took 0.100s
  training loss:		0.345569
  validation loss:		0.418663
  validation accuracy:		87.07 %
Epoch 998 of 2000 took 0.100s
  training loss:		0.346189
  validation loss:		0.419075
  validation accuracy:		86.85 %
Epoch 999 of 2000 took 0.100s
  training loss:		0.347056
  validation loss:		0.403150
  validation accuracy:		86.96 %
Epoch 1000 of 2000 took 0.100s
  training loss:		0.348233
  validation loss:		0.410122
  validation accuracy:		86.85 %
Epoch 1001 of 2000 took 0.100s
  training loss:		0.347759
  validation loss:		0.399934
  validation accuracy:		87.17 %
Epoch 1002 of 2000 took 0.100s
  training loss:		0.344131
  validation loss:		0.410633
  validation accuracy:		87.07 %
Epoch 1003 of 2000 took 0.101s
  training loss:		0.341120
  validation loss:		0.405599
  validation accuracy:		87.39 %
Epoch 1004 of 2000 took 0.100s
  training loss:		0.340250
  validation loss:		0.426483
  validation accuracy:		87.07 %
Epoch 1005 of 2000 took 0.100s
  training loss:		0.343744
  validation loss:		0.407400
  validation accuracy:		87.07 %
Epoch 1006 of 2000 took 0.100s
  training loss:		0.344757
  validation loss:		0.427987
  validation accuracy:		86.63 %
Epoch 1007 of 2000 took 0.100s
  training loss:		0.344467
  validation loss:		0.429516
  validation accuracy:		87.17 %
Epoch 1008 of 2000 took 0.100s
  training loss:		0.345396
  validation loss:		0.403059
  validation accuracy:		86.85 %
Epoch 1009 of 2000 took 0.100s
  training loss:		0.347420
  validation loss:		0.411259
  validation accuracy:		87.39 %
Epoch 1010 of 2000 took 0.100s
  training loss:		0.344345
  validation loss:		0.409415
  validation accuracy:		87.07 %
Epoch 1011 of 2000 took 0.100s
  training loss:		0.338019
  validation loss:		0.426166
  validation accuracy:		87.28 %
Epoch 1012 of 2000 took 0.100s
  training loss:		0.345336
  validation loss:		0.410220
  validation accuracy:		86.85 %
Epoch 1013 of 2000 took 0.100s
  training loss:		0.340029
  validation loss:		0.404925
  validation accuracy:		87.72 %
Epoch 1014 of 2000 took 0.100s
  training loss:		0.338956
  validation loss:		0.406380
  validation accuracy:		87.28 %
Epoch 1015 of 2000 took 0.100s
  training loss:		0.337503
  validation loss:		0.416639
  validation accuracy:		87.07 %
Epoch 1016 of 2000 took 0.100s
  training loss:		0.348760
  validation loss:		0.424275
  validation accuracy:		86.96 %
Epoch 1017 of 2000 took 0.100s
  training loss:		0.343279
  validation loss:		0.412839
  validation accuracy:		87.07 %
Epoch 1018 of 2000 took 0.098s
  training loss:		0.343639
  validation loss:		0.415643
  validation accuracy:		87.28 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.339325
  validation loss:		0.424592
  validation accuracy:		87.28 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.339412
  validation loss:		0.412202
  validation accuracy:		86.74 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.337940
  validation loss:		0.413282
  validation accuracy:		86.74 %
Epoch 1022 of 2000 took 0.097s
  training loss:		0.336757
  validation loss:		0.399697
  validation accuracy:		87.50 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.348883
  validation loss:		0.419583
  validation accuracy:		86.85 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.337853
  validation loss:		0.409362
  validation accuracy:		87.17 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.342269
  validation loss:		0.417634
  validation accuracy:		87.28 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.338735
  validation loss:		0.408943
  validation accuracy:		87.28 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.330693
  validation loss:		0.405914
  validation accuracy:		87.39 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.332746
  validation loss:		0.406365
  validation accuracy:		87.39 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.332929
  validation loss:		0.431342
  validation accuracy:		86.09 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.336626
  validation loss:		0.396984
  validation accuracy:		88.04 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.341642
  validation loss:		0.401895
  validation accuracy:		87.17 %
Epoch 1032 of 2000 took 0.097s
  training loss:		0.338570
  validation loss:		0.449277
  validation accuracy:		86.09 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.342059
  validation loss:		0.422661
  validation accuracy:		85.98 %
Epoch 1034 of 2000 took 0.098s
  training loss:		0.334956
  validation loss:		0.442478
  validation accuracy:		85.98 %
Epoch 1035 of 2000 took 0.097s
  training loss:		0.341240
  validation loss:		0.419269
  validation accuracy:		87.39 %
Epoch 1036 of 2000 took 0.097s
  training loss:		0.335615
  validation loss:		0.398885
  validation accuracy:		86.96 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.329060
  validation loss:		0.401295
  validation accuracy:		87.39 %
Epoch 1038 of 2000 took 0.097s
  training loss:		0.336079
  validation loss:		0.443887
  validation accuracy:		86.20 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.335765
  validation loss:		0.408968
  validation accuracy:		87.28 %
Epoch 1040 of 2000 took 0.097s
  training loss:		0.332763
  validation loss:		0.406096
  validation accuracy:		87.50 %
Epoch 1041 of 2000 took 0.097s
  training loss:		0.330964
  validation loss:		0.417116
  validation accuracy:		86.96 %
Epoch 1042 of 2000 took 0.097s
  training loss:		0.331828
  validation loss:		0.404860
  validation accuracy:		86.74 %
Epoch 1043 of 2000 took 0.097s
  training loss:		0.330470
  validation loss:		0.401996
  validation accuracy:		87.28 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.334273
  validation loss:		0.401187
  validation accuracy:		87.28 %
Epoch 1045 of 2000 took 0.097s
  training loss:		0.331667
  validation loss:		0.405295
  validation accuracy:		86.52 %
Epoch 1046 of 2000 took 0.097s
  training loss:		0.335891
  validation loss:		0.422752
  validation accuracy:		86.85 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.332245
  validation loss:		0.416987
  validation accuracy:		87.17 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.336653
  validation loss:		0.396408
  validation accuracy:		87.83 %
Epoch 1049 of 2000 took 0.097s
  training loss:		0.333258
  validation loss:		0.401250
  validation accuracy:		87.61 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.328788
  validation loss:		0.410919
  validation accuracy:		87.17 %
Epoch 1051 of 2000 took 0.097s
  training loss:		0.330200
  validation loss:		0.425206
  validation accuracy:		86.96 %
Epoch 1052 of 2000 took 0.097s
  training loss:		0.333287
  validation loss:		0.412141
  validation accuracy:		86.63 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.332808
  validation loss:		0.427788
  validation accuracy:		86.09 %
Epoch 1054 of 2000 took 0.097s
  training loss:		0.328810
  validation loss:		0.391163
  validation accuracy:		87.39 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.331490
  validation loss:		0.397037
  validation accuracy:		87.72 %
Epoch 1056 of 2000 took 0.097s
  training loss:		0.330550
  validation loss:		0.408377
  validation accuracy:		87.17 %
Epoch 1057 of 2000 took 0.097s
  training loss:		0.330284
  validation loss:		0.415799
  validation accuracy:		86.96 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.331846
  validation loss:		0.435942
  validation accuracy:		85.76 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.330387
  validation loss:		0.394937
  validation accuracy:		87.50 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.328543
  validation loss:		0.407757
  validation accuracy:		86.85 %
Epoch 1061 of 2000 took 0.097s
  training loss:		0.328601
  validation loss:		0.422432
  validation accuracy:		86.63 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.328194
  validation loss:		0.399427
  validation accuracy:		87.17 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.326381
  validation loss:		0.409602
  validation accuracy:		86.85 %
Epoch 1064 of 2000 took 0.097s
  training loss:		0.329619
  validation loss:		0.390246
  validation accuracy:		87.39 %
Epoch 1065 of 2000 took 0.098s
  training loss:		0.325443
  validation loss:		0.395953
  validation accuracy:		87.61 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.323859
  validation loss:		0.426573
  validation accuracy:		86.96 %
Epoch 1067 of 2000 took 0.097s
  training loss:		0.325232
  validation loss:		0.395989
  validation accuracy:		87.17 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.324395
  validation loss:		0.397276
  validation accuracy:		87.61 %
Epoch 1069 of 2000 took 0.097s
  training loss:		0.327652
  validation loss:		0.393532
  validation accuracy:		87.50 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.329870
  validation loss:		0.409691
  validation accuracy:		87.17 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.330950
  validation loss:		0.433655
  validation accuracy:		86.52 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.330618
  validation loss:		0.427885
  validation accuracy:		86.63 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.329183
  validation loss:		0.394066
  validation accuracy:		87.39 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.325764
  validation loss:		0.399511
  validation accuracy:		87.17 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.327146
  validation loss:		0.393179
  validation accuracy:		87.83 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.318091
  validation loss:		0.410988
  validation accuracy:		87.28 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.319271
  validation loss:		0.398263
  validation accuracy:		87.72 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.328750
  validation loss:		0.405004
  validation accuracy:		87.39 %
Epoch 1079 of 2000 took 0.097s
  training loss:		0.314910
  validation loss:		0.399689
  validation accuracy:		87.28 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.321078
  validation loss:		0.393981
  validation accuracy:		87.50 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.322753
  validation loss:		0.409907
  validation accuracy:		87.28 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.326510
  validation loss:		0.414798
  validation accuracy:		87.17 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.326906
  validation loss:		0.406370
  validation accuracy:		86.74 %
Epoch 1084 of 2000 took 0.097s
  training loss:		0.327540
  validation loss:		0.396094
  validation accuracy:		87.17 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.327678
  validation loss:		0.406334
  validation accuracy:		86.85 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.325663
  validation loss:		0.408964
  validation accuracy:		86.52 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.320707
  validation loss:		0.410890
  validation accuracy:		87.28 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.318868
  validation loss:		0.406892
  validation accuracy:		86.85 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.332904
  validation loss:		0.400601
  validation accuracy:		87.50 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.314296
  validation loss:		0.403962
  validation accuracy:		86.85 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.319574
  validation loss:		0.398520
  validation accuracy:		86.74 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.319066
  validation loss:		0.391891
  validation accuracy:		86.63 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.329526
  validation loss:		0.406771
  validation accuracy:		86.30 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.327252
  validation loss:		0.412588
  validation accuracy:		86.41 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.323190
  validation loss:		0.418456
  validation accuracy:		85.87 %
Epoch 1096 of 2000 took 0.098s
  training loss:		0.317952
  validation loss:		0.405487
  validation accuracy:		87.28 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.320239
  validation loss:		0.409992
  validation accuracy:		86.96 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.323297
  validation loss:		0.433732
  validation accuracy:		86.63 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.315836
  validation loss:		0.391098
  validation accuracy:		88.26 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.328427
  validation loss:		0.412893
  validation accuracy:		87.39 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.319373
  validation loss:		0.453907
  validation accuracy:		85.98 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.316976
  validation loss:		0.405851
  validation accuracy:		86.63 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.324560
  validation loss:		0.404431
  validation accuracy:		86.96 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.330875
  validation loss:		0.398772
  validation accuracy:		86.96 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.316602
  validation loss:		0.409157
  validation accuracy:		87.39 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.318304
  validation loss:		0.401441
  validation accuracy:		87.07 %
Epoch 1107 of 2000 took 0.097s
  training loss:		0.318380
  validation loss:		0.395435
  validation accuracy:		87.07 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.322425
  validation loss:		0.420059
  validation accuracy:		86.52 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.315112
  validation loss:		0.398076
  validation accuracy:		87.17 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.318559
  validation loss:		0.413031
  validation accuracy:		86.74 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.323513
  validation loss:		0.409913
  validation accuracy:		86.96 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.315508
  validation loss:		0.391349
  validation accuracy:		87.61 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.317215
  validation loss:		0.407485
  validation accuracy:		86.96 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.323870
  validation loss:		0.395822
  validation accuracy:		86.52 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.315924
  validation loss:		0.382116
  validation accuracy:		87.72 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.316122
  validation loss:		0.462396
  validation accuracy:		85.00 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.320935
  validation loss:		0.388600
  validation accuracy:		87.83 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.319077
  validation loss:		0.416941
  validation accuracy:		86.41 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.320994
  validation loss:		0.406449
  validation accuracy:		87.28 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.314237
  validation loss:		0.394775
  validation accuracy:		87.17 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.312022
  validation loss:		0.390423
  validation accuracy:		88.37 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.311416
  validation loss:		0.393034
  validation accuracy:		86.96 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.317331
  validation loss:		0.389877
  validation accuracy:		87.07 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.317774
  validation loss:		0.396033
  validation accuracy:		87.28 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.314342
  validation loss:		0.385695
  validation accuracy:		87.61 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.316970
  validation loss:		0.422370
  validation accuracy:		86.41 %
Epoch 1127 of 2000 took 0.098s
  training loss:		0.308429
  validation loss:		0.407996
  validation accuracy:		86.74 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.313784
  validation loss:		0.386840
  validation accuracy:		87.17 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.318090
  validation loss:		0.402641
  validation accuracy:		87.72 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.309168
  validation loss:		0.386659
  validation accuracy:		87.50 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.316471
  validation loss:		0.415494
  validation accuracy:		86.74 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.319691
  validation loss:		0.390133
  validation accuracy:		87.07 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.316157
  validation loss:		0.383961
  validation accuracy:		87.93 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.309481
  validation loss:		0.382660
  validation accuracy:		87.72 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.313212
  validation loss:		0.395365
  validation accuracy:		86.96 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.308073
  validation loss:		0.408821
  validation accuracy:		86.96 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.317060
  validation loss:		0.420245
  validation accuracy:		86.41 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.311490
  validation loss:		0.400656
  validation accuracy:		87.07 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.314538
  validation loss:		0.390109
  validation accuracy:		87.28 %
Epoch 1140 of 2000 took 0.101s
  training loss:		0.310664
  validation loss:		0.404023
  validation accuracy:		86.52 %
Epoch 1141 of 2000 took 0.103s
  training loss:		0.308680
  validation loss:		0.383930
  validation accuracy:		88.26 %
Epoch 1142 of 2000 took 0.100s
  training loss:		0.307565
  validation loss:		0.404851
  validation accuracy:		86.74 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.307266
  validation loss:		0.431126
  validation accuracy:		86.20 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.317484
  validation loss:		0.395948
  validation accuracy:		87.17 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.309613
  validation loss:		0.387175
  validation accuracy:		87.07 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.313130
  validation loss:		0.383319
  validation accuracy:		88.26 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.316603
  validation loss:		0.407383
  validation accuracy:		87.39 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.316059
  validation loss:		0.388697
  validation accuracy:		87.39 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.311432
  validation loss:		0.410163
  validation accuracy:		87.93 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.311027
  validation loss:		0.388075
  validation accuracy:		87.17 %
Epoch 1151 of 2000 took 0.100s
  training loss:		0.305895
  validation loss:		0.418828
  validation accuracy:		87.39 %
Epoch 1152 of 2000 took 0.100s
  training loss:		0.319990
  validation loss:		0.425586
  validation accuracy:		86.41 %
Epoch 1153 of 2000 took 0.100s
  training loss:		0.309390
  validation loss:		0.385821
  validation accuracy:		88.04 %
Epoch 1154 of 2000 took 0.100s
  training loss:		0.313202
  validation loss:		0.450691
  validation accuracy:		85.54 %
Epoch 1155 of 2000 took 0.100s
  training loss:		0.311381
  validation loss:		0.380825
  validation accuracy:		87.50 %
Epoch 1156 of 2000 took 0.102s
  training loss:		0.312963
  validation loss:		0.406553
  validation accuracy:		87.07 %
Epoch 1157 of 2000 took 0.100s
  training loss:		0.313291
  validation loss:		0.383068
  validation accuracy:		88.37 %
Epoch 1158 of 2000 took 0.101s
  training loss:		0.314788
  validation loss:		0.398835
  validation accuracy:		87.17 %
Epoch 1159 of 2000 took 0.105s
  training loss:		0.305621
  validation loss:		0.404150
  validation accuracy:		87.17 %
Epoch 1160 of 2000 took 0.108s
  training loss:		0.317161
  validation loss:		0.418115
  validation accuracy:		86.30 %
Epoch 1161 of 2000 took 0.111s
  training loss:		0.312863
  validation loss:		0.394225
  validation accuracy:		87.61 %
Epoch 1162 of 2000 took 0.145s
  training loss:		0.308829
  validation loss:		0.410499
  validation accuracy:		87.07 %
Epoch 1163 of 2000 took 0.104s
  training loss:		0.311961
  validation loss:		0.417606
  validation accuracy:		87.07 %
Epoch 1164 of 2000 took 0.102s
  training loss:		0.309239
  validation loss:		0.388474
  validation accuracy:		87.93 %
Epoch 1165 of 2000 took 0.106s
  training loss:		0.322864
  validation loss:		0.384175
  validation accuracy:		87.83 %
Epoch 1166 of 2000 took 0.108s
  training loss:		0.312399
  validation loss:		0.437813
  validation accuracy:		85.98 %
Epoch 1167 of 2000 took 0.104s
  training loss:		0.306330
  validation loss:		0.405722
  validation accuracy:		87.07 %
Epoch 1168 of 2000 took 0.105s
  training loss:		0.308375
  validation loss:		0.400397
  validation accuracy:		87.17 %
Epoch 1169 of 2000 took 0.103s
  training loss:		0.302512
  validation loss:		0.392316
  validation accuracy:		86.96 %
Epoch 1170 of 2000 took 0.100s
  training loss:		0.309956
  validation loss:		0.440264
  validation accuracy:		86.41 %
Epoch 1171 of 2000 took 0.101s
  training loss:		0.311733
  validation loss:		0.394293
  validation accuracy:		87.28 %
Epoch 1172 of 2000 took 0.100s
  training loss:		0.311002
  validation loss:		0.387782
  validation accuracy:		86.74 %
Epoch 1173 of 2000 took 0.101s
  training loss:		0.313416
  validation loss:		0.387180
  validation accuracy:		87.93 %
Epoch 1174 of 2000 took 0.103s
  training loss:		0.303812
  validation loss:		0.415289
  validation accuracy:		86.96 %
Epoch 1175 of 2000 took 0.102s
  training loss:		0.306522
  validation loss:		0.395130
  validation accuracy:		87.72 %
Epoch 1176 of 2000 took 0.101s
  training loss:		0.307482
  validation loss:		0.410452
  validation accuracy:		87.28 %
Epoch 1177 of 2000 took 0.100s
  training loss:		0.310708
  validation loss:		0.376008
  validation accuracy:		88.26 %
Epoch 1178 of 2000 took 0.101s
  training loss:		0.309084
  validation loss:		0.389938
  validation accuracy:		87.50 %
Epoch 1179 of 2000 took 0.100s
  training loss:		0.308929
  validation loss:		0.387968
  validation accuracy:		87.83 %
Epoch 1180 of 2000 took 0.101s
  training loss:		0.311766
  validation loss:		0.393086
  validation accuracy:		87.61 %
Epoch 1181 of 2000 took 0.101s
  training loss:		0.307322
  validation loss:		0.397252
  validation accuracy:		87.28 %
Epoch 1182 of 2000 took 0.101s
  training loss:		0.308490
  validation loss:		0.399484
  validation accuracy:		87.50 %
Epoch 1183 of 2000 took 0.101s
  training loss:		0.304720
  validation loss:		0.387437
  validation accuracy:		86.96 %
Epoch 1184 of 2000 took 0.101s
  training loss:		0.309265
  validation loss:		0.409038
  validation accuracy:		87.07 %
Epoch 1185 of 2000 took 0.101s
  training loss:		0.309726
  validation loss:		0.389268
  validation accuracy:		87.61 %
Epoch 1186 of 2000 took 0.101s
  training loss:		0.302067
  validation loss:		0.419156
  validation accuracy:		86.85 %
Epoch 1187 of 2000 took 0.102s
  training loss:		0.308429
  validation loss:		0.403202
  validation accuracy:		86.96 %
Epoch 1188 of 2000 took 0.100s
  training loss:		0.305363
  validation loss:		0.410026
  validation accuracy:		87.17 %
Epoch 1189 of 2000 took 0.101s
  training loss:		0.309573
  validation loss:		0.381622
  validation accuracy:		87.28 %
Epoch 1190 of 2000 took 0.101s
  training loss:		0.304465
  validation loss:		0.390029
  validation accuracy:		87.17 %
Epoch 1191 of 2000 took 0.101s
  training loss:		0.299107
  validation loss:		0.404398
  validation accuracy:		87.39 %
Epoch 1192 of 2000 took 0.101s
  training loss:		0.312511
  validation loss:		0.404003
  validation accuracy:		87.39 %
Epoch 1193 of 2000 took 0.100s
  training loss:		0.307502
  validation loss:		0.385658
  validation accuracy:		87.72 %
Epoch 1194 of 2000 took 0.101s
  training loss:		0.304199
  validation loss:		0.404834
  validation accuracy:		87.28 %
Epoch 1195 of 2000 took 0.101s
  training loss:		0.305884
  validation loss:		0.384346
  validation accuracy:		87.61 %
Epoch 1196 of 2000 took 0.101s
  training loss:		0.301891
  validation loss:		0.377634
  validation accuracy:		88.59 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.301875
  validation loss:		0.402853
  validation accuracy:		87.17 %
Epoch 1198 of 2000 took 0.101s
  training loss:		0.307175
  validation loss:		0.374860
  validation accuracy:		88.48 %
Epoch 1199 of 2000 took 0.101s
  training loss:		0.308612
  validation loss:		0.384709
  validation accuracy:		87.28 %
Epoch 1200 of 2000 took 0.101s
  training loss:		0.296374
  validation loss:		0.378322
  validation accuracy:		88.59 %
Epoch 1201 of 2000 took 0.103s
  training loss:		0.304123
  validation loss:		0.405796
  validation accuracy:		87.28 %
Epoch 1202 of 2000 took 0.109s
  training loss:		0.302923
  validation loss:		0.386761
  validation accuracy:		87.72 %
Epoch 1203 of 2000 took 0.162s
  training loss:		0.299499
  validation loss:		0.400724
  validation accuracy:		87.39 %
Epoch 1204 of 2000 took 0.165s
  training loss:		0.295040
  validation loss:		0.413831
  validation accuracy:		86.96 %
Epoch 1205 of 2000 took 0.165s
  training loss:		0.310625
  validation loss:		0.393415
  validation accuracy:		87.28 %
Epoch 1206 of 2000 took 0.165s
  training loss:		0.298874
  validation loss:		0.391345
  validation accuracy:		87.83 %
Epoch 1207 of 2000 took 0.165s
  training loss:		0.295089
  validation loss:		0.417794
  validation accuracy:		87.17 %
Epoch 1208 of 2000 took 0.165s
  training loss:		0.305478
  validation loss:		0.397920
  validation accuracy:		87.17 %
Epoch 1209 of 2000 took 0.161s
  training loss:		0.301241
  validation loss:		0.391816
  validation accuracy:		87.39 %
Epoch 1210 of 2000 took 0.165s
  training loss:		0.305004
  validation loss:		0.375460
  validation accuracy:		88.15 %
Epoch 1211 of 2000 took 0.165s
  training loss:		0.304960
  validation loss:		0.395177
  validation accuracy:		87.39 %
Epoch 1212 of 2000 took 0.181s
  training loss:		0.308467
  validation loss:		0.378685
  validation accuracy:		87.93 %
Epoch 1213 of 2000 took 0.165s
  training loss:		0.311087
  validation loss:		0.431669
  validation accuracy:		86.96 %
Epoch 1214 of 2000 took 0.165s
  training loss:		0.309449
  validation loss:		0.396160
  validation accuracy:		87.72 %
Epoch 1215 of 2000 took 0.165s
  training loss:		0.315028
  validation loss:		0.453466
  validation accuracy:		86.09 %
Epoch 1216 of 2000 took 0.165s
  training loss:		0.305858
  validation loss:		0.385420
  validation accuracy:		87.50 %
Epoch 1217 of 2000 took 0.165s
  training loss:		0.302966
  validation loss:		0.384033
  validation accuracy:		87.61 %
Epoch 1218 of 2000 took 0.165s
  training loss:		0.302855
  validation loss:		0.439040
  validation accuracy:		86.41 %
Epoch 1219 of 2000 took 0.165s
  training loss:		0.310138
  validation loss:		0.377316
  validation accuracy:		87.83 %
Epoch 1220 of 2000 took 0.165s
  training loss:		0.295897
  validation loss:		0.412411
  validation accuracy:		86.85 %
Epoch 1221 of 2000 took 0.165s
  training loss:		0.294978
  validation loss:		0.429015
  validation accuracy:		86.41 %
Epoch 1222 of 2000 took 0.165s
  training loss:		0.299504
  validation loss:		0.418261
  validation accuracy:		86.74 %
Epoch 1223 of 2000 took 0.181s
  training loss:		0.298096
  validation loss:		0.382849
  validation accuracy:		87.83 %
Epoch 1224 of 2000 took 0.165s
  training loss:		0.303231
  validation loss:		0.446686
  validation accuracy:		85.65 %
Epoch 1225 of 2000 took 0.165s
  training loss:		0.307012
  validation loss:		0.381473
  validation accuracy:		88.04 %
Epoch 1226 of 2000 took 0.165s
  training loss:		0.300794
  validation loss:		0.388058
  validation accuracy:		87.50 %
Epoch 1227 of 2000 took 0.165s
  training loss:		0.293651
  validation loss:		0.373668
  validation accuracy:		88.15 %
Epoch 1228 of 2000 took 0.165s
  training loss:		0.293671
  validation loss:		0.454805
  validation accuracy:		85.65 %
Epoch 1229 of 2000 took 0.165s
  training loss:		0.301932
  validation loss:		0.371943
  validation accuracy:		88.48 %
Epoch 1230 of 2000 took 0.165s
  training loss:		0.304178
  validation loss:		0.403920
  validation accuracy:		87.39 %
Epoch 1231 of 2000 took 0.165s
  training loss:		0.296330
  validation loss:		0.384366
  validation accuracy:		87.72 %
Epoch 1232 of 2000 took 0.165s
  training loss:		0.299620
  validation loss:		0.420897
  validation accuracy:		87.07 %
Epoch 1233 of 2000 took 0.165s
  training loss:		0.298064
  validation loss:		0.405898
  validation accuracy:		86.96 %
Epoch 1234 of 2000 took 0.165s
  training loss:		0.304381
  validation loss:		0.373047
  validation accuracy:		88.15 %
Epoch 1235 of 2000 took 0.181s
  training loss:		0.296717
  validation loss:		0.377816
  validation accuracy:		87.72 %
Epoch 1236 of 2000 took 0.165s
  training loss:		0.293612
  validation loss:		0.385317
  validation accuracy:		87.83 %
Epoch 1237 of 2000 took 0.165s
  training loss:		0.299581
  validation loss:		0.377965
  validation accuracy:		87.50 %
Epoch 1238 of 2000 took 0.165s
  training loss:		0.295101
  validation loss:		0.399883
  validation accuracy:		87.50 %
Epoch 1239 of 2000 took 0.165s
  training loss:		0.293687
  validation loss:		0.395510
  validation accuracy:		87.39 %
Epoch 1240 of 2000 took 0.165s
  training loss:		0.303160
  validation loss:		0.389694
  validation accuracy:		87.50 %
Epoch 1241 of 2000 took 0.165s
  training loss:		0.295520
  validation loss:		0.387337
  validation accuracy:		87.72 %
Epoch 1242 of 2000 took 0.165s
  training loss:		0.300518
  validation loss:		0.387815
  validation accuracy:		87.72 %
Epoch 1243 of 2000 took 0.165s
  training loss:		0.296139
  validation loss:		0.388253
  validation accuracy:		87.61 %
Epoch 1244 of 2000 took 0.165s
  training loss:		0.301750
  validation loss:		0.388543
  validation accuracy:		87.50 %
Epoch 1245 of 2000 took 0.165s
  training loss:		0.304877
  validation loss:		0.385073
  validation accuracy:		88.80 %
Epoch 1246 of 2000 took 0.165s
  training loss:		0.289669
  validation loss:		0.421220
  validation accuracy:		86.85 %
Epoch 1247 of 2000 took 0.165s
  training loss:		0.299336
  validation loss:		0.401604
  validation accuracy:		87.28 %
Epoch 1248 of 2000 took 0.165s
  training loss:		0.297811
  validation loss:		0.413129
  validation accuracy:		87.07 %
Epoch 1249 of 2000 took 0.165s
  training loss:		0.294584
  validation loss:		0.385238
  validation accuracy:		87.50 %
Epoch 1250 of 2000 took 0.213s
  training loss:		0.293069
  validation loss:		0.375797
  validation accuracy:		87.72 %
Epoch 1251 of 2000 took 0.331s
  training loss:		0.307889
  validation loss:		0.414545
  validation accuracy:		86.85 %
Epoch 1252 of 2000 took 0.208s
  training loss:		0.295213
  validation loss:		0.408228
  validation accuracy:		87.17 %
Epoch 1253 of 2000 took 0.166s
  training loss:		0.297454
  validation loss:		0.373884
  validation accuracy:		88.04 %
Epoch 1254 of 2000 took 0.165s
  training loss:		0.297410
  validation loss:		0.378342
  validation accuracy:		88.26 %
Epoch 1255 of 2000 took 0.166s
  training loss:		0.295369
  validation loss:		0.402172
  validation accuracy:		87.39 %
Epoch 1256 of 2000 took 0.166s
  training loss:		0.294031
  validation loss:		0.393388
  validation accuracy:		87.28 %
Epoch 1257 of 2000 took 0.166s
  training loss:		0.294889
  validation loss:		0.377422
  validation accuracy:		87.61 %
Epoch 1258 of 2000 took 0.165s
  training loss:		0.294635
  validation loss:		0.397519
  validation accuracy:		87.17 %
Epoch 1259 of 2000 took 0.166s
  training loss:		0.294464
  validation loss:		0.389492
  validation accuracy:		87.61 %
Epoch 1260 of 2000 took 0.165s
  training loss:		0.286813
  validation loss:		0.407094
  validation accuracy:		86.74 %
Epoch 1261 of 2000 took 0.166s
  training loss:		0.294771
  validation loss:		0.370963
  validation accuracy:		87.93 %
Epoch 1262 of 2000 took 0.166s
  training loss:		0.291770
  validation loss:		0.398782
  validation accuracy:		87.07 %
Epoch 1263 of 2000 took 0.166s
  training loss:		0.290004
  validation loss:		0.372994
  validation accuracy:		87.72 %
Epoch 1264 of 2000 took 0.166s
  training loss:		0.289106
  validation loss:		0.373198
  validation accuracy:		88.26 %
Epoch 1265 of 2000 took 0.166s
  training loss:		0.303382
  validation loss:		0.372569
  validation accuracy:		87.61 %
Epoch 1266 of 2000 took 0.166s
  training loss:		0.301110
  validation loss:		0.374510
  validation accuracy:		88.04 %
Epoch 1267 of 2000 took 0.165s
  training loss:		0.291675
  validation loss:		0.407339
  validation accuracy:		86.52 %
Epoch 1268 of 2000 took 0.166s
  training loss:		0.291262
  validation loss:		0.374494
  validation accuracy:		88.37 %
Epoch 1269 of 2000 took 0.166s
  training loss:		0.299918
  validation loss:		0.397081
  validation accuracy:		87.39 %
Epoch 1270 of 2000 took 0.165s
  training loss:		0.289352
  validation loss:		0.390309
  validation accuracy:		87.07 %
Epoch 1271 of 2000 took 0.165s
  training loss:		0.295757
  validation loss:		0.385790
  validation accuracy:		87.50 %
Epoch 1272 of 2000 took 0.165s
  training loss:		0.291996
  validation loss:		0.368783
  validation accuracy:		88.15 %
Epoch 1273 of 2000 took 0.166s
  training loss:		0.299653
  validation loss:		0.381263
  validation accuracy:		87.50 %
Epoch 1274 of 2000 took 0.165s
  training loss:		0.293324
  validation loss:		0.406204
  validation accuracy:		87.39 %
Epoch 1275 of 2000 took 0.165s
  training loss:		0.290927
  validation loss:		0.392466
  validation accuracy:		86.96 %
Epoch 1276 of 2000 took 0.166s
  training loss:		0.299817
  validation loss:		0.369091
  validation accuracy:		88.04 %
Epoch 1277 of 2000 took 0.166s
  training loss:		0.290165
  validation loss:		0.379636
  validation accuracy:		88.15 %
Epoch 1278 of 2000 took 0.165s
  training loss:		0.294195
  validation loss:		0.391279
  validation accuracy:		87.28 %
Epoch 1279 of 2000 took 0.165s
  training loss:		0.296413
  validation loss:		0.425772
  validation accuracy:		86.63 %
Epoch 1280 of 2000 took 0.166s
  training loss:		0.292490
  validation loss:		0.382669
  validation accuracy:		87.61 %
Epoch 1281 of 2000 took 0.165s
  training loss:		0.290141
  validation loss:		0.375887
  validation accuracy:		87.39 %
Epoch 1282 of 2000 took 0.164s
  training loss:		0.296454
  validation loss:		0.380363
  validation accuracy:		87.28 %
Epoch 1283 of 2000 took 0.168s
  training loss:		0.291686
  validation loss:		0.393727
  validation accuracy:		87.07 %
Epoch 1284 of 2000 took 0.166s
  training loss:		0.293891
  validation loss:		0.368494
  validation accuracy:		87.93 %
Epoch 1285 of 2000 took 0.169s
  training loss:		0.291827
  validation loss:		0.405822
  validation accuracy:		87.17 %
Epoch 1286 of 2000 took 0.170s
  training loss:		0.309774
  validation loss:		0.392344
  validation accuracy:		87.39 %
Epoch 1287 of 2000 took 0.166s
  training loss:		0.293052
  validation loss:		0.384859
  validation accuracy:		87.50 %
Epoch 1288 of 2000 took 0.168s
  training loss:		0.282570
  validation loss:		0.398894
  validation accuracy:		87.72 %
Epoch 1289 of 2000 took 0.172s
  training loss:		0.296297
  validation loss:		0.432738
  validation accuracy:		86.52 %
Epoch 1290 of 2000 took 0.166s
  training loss:		0.298244
  validation loss:		0.387996
  validation accuracy:		87.72 %
Epoch 1291 of 2000 took 0.167s
  training loss:		0.294457
  validation loss:		0.375532
  validation accuracy:		87.61 %
Epoch 1292 of 2000 took 0.167s
  training loss:		0.291757
  validation loss:		0.406101
  validation accuracy:		87.39 %
Epoch 1293 of 2000 took 0.166s
  training loss:		0.288573
  validation loss:		0.409341
  validation accuracy:		86.85 %
Epoch 1294 of 2000 took 0.171s
  training loss:		0.296445
  validation loss:		0.411860
  validation accuracy:		87.07 %
Epoch 1295 of 2000 took 0.168s
  training loss:		0.293918
  validation loss:		0.378684
  validation accuracy:		87.61 %
Epoch 1296 of 2000 took 0.166s
  training loss:		0.292290
  validation loss:		0.373292
  validation accuracy:		88.59 %
Epoch 1297 of 2000 took 0.170s
  training loss:		0.311789
  validation loss:		0.368555
  validation accuracy:		88.04 %
Epoch 1298 of 2000 took 0.170s
  training loss:		0.291806
  validation loss:		0.399274
  validation accuracy:		87.28 %
Epoch 1299 of 2000 took 0.166s
  training loss:		0.290327
  validation loss:		0.396783
  validation accuracy:		87.50 %
Epoch 1300 of 2000 took 0.168s
  training loss:		0.290679
  validation loss:		0.386788
  validation accuracy:		88.04 %
Epoch 1301 of 2000 took 0.166s
  training loss:		0.285612
  validation loss:		0.371730
  validation accuracy:		87.93 %
Epoch 1302 of 2000 took 0.168s
  training loss:		0.290349
  validation loss:		0.400224
  validation accuracy:		87.28 %
Epoch 1303 of 2000 took 0.170s
  training loss:		0.291485
  validation loss:		0.406494
  validation accuracy:		86.96 %
Epoch 1304 of 2000 took 0.166s
  training loss:		0.286543
  validation loss:		0.391251
  validation accuracy:		87.61 %
Epoch 1305 of 2000 took 0.166s
  training loss:		0.286151
  validation loss:		0.374560
  validation accuracy:		87.72 %
Epoch 1306 of 2000 took 0.169s
  training loss:		0.290259
  validation loss:		0.390009
  validation accuracy:		87.61 %
Epoch 1307 of 2000 took 0.169s
  training loss:		0.304626
  validation loss:		0.381448
  validation accuracy:		87.83 %
Epoch 1308 of 2000 took 0.166s
  training loss:		0.284167
  validation loss:		0.404654
  validation accuracy:		87.28 %
Epoch 1309 of 2000 took 0.167s
  training loss:		0.299368
  validation loss:		0.368912
  validation accuracy:		87.61 %
Epoch 1310 of 2000 took 0.167s
  training loss:		0.289781
  validation loss:		0.374790
  validation accuracy:		88.37 %
Epoch 1311 of 2000 took 0.166s
  training loss:		0.289218
  validation loss:		0.377049
  validation accuracy:		87.50 %
Epoch 1312 of 2000 took 0.171s
  training loss:		0.295040
  validation loss:		0.385749
  validation accuracy:		87.61 %
Epoch 1313 of 2000 took 0.168s
  training loss:		0.287431
  validation loss:		0.382146
  validation accuracy:		87.72 %
Epoch 1314 of 2000 took 0.166s
  training loss:		0.286722
  validation loss:		0.393904
  validation accuracy:		87.50 %
Epoch 1315 of 2000 took 0.169s
  training loss:		0.283207
  validation loss:		0.403530
  validation accuracy:		87.07 %
Epoch 1316 of 2000 took 0.170s
  training loss:		0.278734
  validation loss:		0.366750
  validation accuracy:		88.37 %
Epoch 1317 of 2000 took 0.166s
  training loss:		0.284683
  validation loss:		0.385364
  validation accuracy:		87.72 %
Epoch 1318 of 2000 took 0.168s
  training loss:		0.288689
  validation loss:		0.383239
  validation accuracy:		87.83 %
Epoch 1319 of 2000 took 0.166s
  training loss:		0.288207
  validation loss:		0.428910
  validation accuracy:		86.41 %
Epoch 1320 of 2000 took 0.168s
  training loss:		0.290782
  validation loss:		0.371161
  validation accuracy:		88.15 %
Epoch 1321 of 2000 took 0.167s
  training loss:		0.284751
  validation loss:		0.376521
  validation accuracy:		87.28 %
Epoch 1322 of 2000 took 0.167s
  training loss:		0.287045
  validation loss:		0.378727
  validation accuracy:		87.61 %
Epoch 1323 of 2000 took 0.167s
  training loss:		0.289014
  validation loss:		0.369014
  validation accuracy:		88.15 %
Epoch 1324 of 2000 took 0.171s
  training loss:		0.295341
  validation loss:		0.369280
  validation accuracy:		88.59 %
Epoch 1325 of 2000 took 0.166s
  training loss:		0.287807
  validation loss:		0.384655
  validation accuracy:		88.04 %
Epoch 1326 of 2000 took 0.166s
  training loss:		0.288136
  validation loss:		0.396254
  validation accuracy:		87.39 %
Epoch 1327 of 2000 took 0.166s
  training loss:		0.284241
  validation loss:		0.372873
  validation accuracy:		87.50 %
Epoch 1328 of 2000 took 0.168s
  training loss:		0.282434
  validation loss:		0.406978
  validation accuracy:		86.96 %
Epoch 1329 of 2000 took 0.166s
  training loss:		0.282153
  validation loss:		0.393000
  validation accuracy:		87.39 %
Epoch 1330 of 2000 took 0.168s
  training loss:		0.282799
  validation loss:		0.375627
  validation accuracy:		87.72 %
Epoch 1331 of 2000 took 0.170s
  training loss:		0.281079
  validation loss:		0.380064
  validation accuracy:		87.39 %
Epoch 1332 of 2000 took 0.166s
  training loss:		0.290027
  validation loss:		0.379041
  validation accuracy:		87.50 %
Epoch 1333 of 2000 took 0.171s
  training loss:		0.284018
  validation loss:		0.407546
  validation accuracy:		87.17 %
Epoch 1334 of 2000 took 0.172s
  training loss:		0.292052
  validation loss:		0.372572
  validation accuracy:		87.72 %
Epoch 1335 of 2000 took 0.167s
  training loss:		0.283290
  validation loss:		0.374680
  validation accuracy:		87.83 %
Epoch 1336 of 2000 took 0.167s
  training loss:		0.290163
  validation loss:		0.396775
  validation accuracy:		87.61 %
Epoch 1337 of 2000 took 0.167s
  training loss:		0.285400
  validation loss:		0.366703
  validation accuracy:		87.93 %
Epoch 1338 of 2000 took 0.166s
  training loss:		0.283756
  validation loss:		0.399385
  validation accuracy:		87.61 %
Epoch 1339 of 2000 took 0.171s
  training loss:		0.294222
  validation loss:		0.406961
  validation accuracy:		87.07 %
Epoch 1340 of 2000 took 0.168s
  training loss:		0.292507
  validation loss:		0.375874
  validation accuracy:		88.04 %
Epoch 1341 of 2000 took 0.168s
  training loss:		0.281176
  validation loss:		0.403081
  validation accuracy:		87.28 %
Epoch 1342 of 2000 took 0.194s
  training loss:		0.286970
  validation loss:		0.367676
  validation accuracy:		88.26 %
Epoch 1343 of 2000 took 0.168s
  training loss:		0.286664
  validation loss:		0.377563
  validation accuracy:		87.83 %
Epoch 1344 of 2000 took 0.171s
  training loss:		0.285826
  validation loss:		0.386011
  validation accuracy:		87.50 %
Epoch 1345 of 2000 took 0.167s
  training loss:		0.284790
  validation loss:		0.403829
  validation accuracy:		87.07 %
Epoch 1346 of 2000 took 0.262s
  training loss:		0.289876
  validation loss:		0.421308
  validation accuracy:		87.07 %
Epoch 1347 of 2000 took 0.112s
  training loss:		0.283244
  validation loss:		0.422458
  validation accuracy:		86.74 %
Epoch 1348 of 2000 took 0.105s
  training loss:		0.286779
  validation loss:		0.366814
  validation accuracy:		88.37 %
Epoch 1349 of 2000 took 0.108s
  training loss:		0.280416
  validation loss:		0.399158
  validation accuracy:		87.39 %
Epoch 1350 of 2000 took 0.113s
  training loss:		0.284232
  validation loss:		0.373280
  validation accuracy:		88.91 %
Epoch 1351 of 2000 took 0.110s
  training loss:		0.282436
  validation loss:		0.381836
  validation accuracy:		88.04 %
Epoch 1352 of 2000 took 0.110s
  training loss:		0.289928
  validation loss:		0.385506
  validation accuracy:		87.83 %
Epoch 1353 of 2000 took 0.104s
  training loss:		0.279993
  validation loss:		0.403853
  validation accuracy:		87.07 %
Epoch 1354 of 2000 took 0.107s
  training loss:		0.286968
  validation loss:		0.422282
  validation accuracy:		86.52 %
Epoch 1355 of 2000 took 0.111s
  training loss:		0.284456
  validation loss:		0.402816
  validation accuracy:		87.39 %
Epoch 1356 of 2000 took 0.105s
  training loss:		0.288525
  validation loss:		0.378276
  validation accuracy:		88.04 %
Epoch 1357 of 2000 took 0.107s
  training loss:		0.277380
  validation loss:		0.378015
  validation accuracy:		88.26 %
Epoch 1358 of 2000 took 0.112s
  training loss:		0.281527
  validation loss:		0.366544
  validation accuracy:		88.15 %
Epoch 1359 of 2000 took 0.106s
  training loss:		0.282887
  validation loss:		0.370258
  validation accuracy:		88.15 %
Epoch 1360 of 2000 took 0.107s
  training loss:		0.278100
  validation loss:		0.422578
  validation accuracy:		86.85 %
Epoch 1361 of 2000 took 0.105s
  training loss:		0.273018
  validation loss:		0.418224
  validation accuracy:		86.52 %
Epoch 1362 of 2000 took 0.107s
  training loss:		0.284533
  validation loss:		0.368072
  validation accuracy:		88.37 %
Epoch 1363 of 2000 took 0.115s
  training loss:		0.283984
  validation loss:		0.404249
  validation accuracy:		86.96 %
Epoch 1364 of 2000 took 0.110s
  training loss:		0.284856
  validation loss:		0.374973
  validation accuracy:		88.04 %
Epoch 1365 of 2000 took 0.108s
  training loss:		0.280054
  validation loss:		0.370485
  validation accuracy:		88.59 %
Epoch 1366 of 2000 took 0.114s
  training loss:		0.278275
  validation loss:		0.399540
  validation accuracy:		87.28 %
Epoch 1367 of 2000 took 0.109s
  training loss:		0.277776
  validation loss:		0.374358
  validation accuracy:		88.26 %
Epoch 1368 of 2000 took 0.109s
  training loss:		0.285736
  validation loss:		0.389129
  validation accuracy:		88.26 %
Epoch 1369 of 2000 took 0.108s
  training loss:		0.278213
  validation loss:		0.366931
  validation accuracy:		88.70 %
Epoch 1370 of 2000 took 0.109s
  training loss:		0.285632
  validation loss:		0.387367
  validation accuracy:		87.93 %
Epoch 1371 of 2000 took 0.111s
  training loss:		0.281292
  validation loss:		0.377358
  validation accuracy:		88.15 %
Epoch 1372 of 2000 took 0.109s
  training loss:		0.283333
  validation loss:		0.373302
  validation accuracy:		88.37 %
Epoch 1373 of 2000 took 0.108s
  training loss:		0.287862
  validation loss:		0.389059
  validation accuracy:		87.83 %
Epoch 1374 of 2000 took 0.112s
  training loss:		0.290079
  validation loss:		0.368827
  validation accuracy:		88.15 %
Epoch 1375 of 2000 took 0.109s
  training loss:		0.283556
  validation loss:		0.373816
  validation accuracy:		87.61 %
Epoch 1376 of 2000 took 0.109s
  training loss:		0.279539
  validation loss:		0.371085
  validation accuracy:		88.37 %
Epoch 1377 of 2000 took 0.108s
  training loss:		0.277392
  validation loss:		0.372695
  validation accuracy:		88.26 %
Epoch 1378 of 2000 took 0.108s
  training loss:		0.280657
  validation loss:		0.384011
  validation accuracy:		87.83 %
Epoch 1379 of 2000 took 0.112s
  training loss:		0.285343
  validation loss:		0.397424
  validation accuracy:		87.39 %
Epoch 1380 of 2000 took 0.109s
  training loss:		0.279588
  validation loss:		0.366940
  validation accuracy:		88.37 %
Epoch 1381 of 2000 took 0.105s
  training loss:		0.282736
  validation loss:		0.377680
  validation accuracy:		87.93 %
Epoch 1382 of 2000 took 0.103s
  training loss:		0.275667
  validation loss:		0.400645
  validation accuracy:		87.72 %
Epoch 1383 of 2000 took 0.103s
  training loss:		0.284778
  validation loss:		0.391322
  validation accuracy:		87.83 %
Epoch 1384 of 2000 took 0.103s
  training loss:		0.284394
  validation loss:		0.385520
  validation accuracy:		87.93 %
Epoch 1385 of 2000 took 0.103s
  training loss:		0.276636
  validation loss:		0.364606
  validation accuracy:		88.70 %
Epoch 1386 of 2000 took 0.104s
  training loss:		0.283438
  validation loss:		0.366720
  validation accuracy:		88.15 %
Epoch 1387 of 2000 took 0.103s
  training loss:		0.286113
  validation loss:		0.366110
  validation accuracy:		88.48 %
Epoch 1388 of 2000 took 0.103s
  training loss:		0.276366
  validation loss:		0.384183
  validation accuracy:		87.72 %
Epoch 1389 of 2000 took 0.103s
  training loss:		0.279780
  validation loss:		0.368392
  validation accuracy:		88.26 %
Epoch 1390 of 2000 took 0.103s
  training loss:		0.274576
  validation loss:		0.372413
  validation accuracy:		88.37 %
Epoch 1391 of 2000 took 0.103s
  training loss:		0.279893
  validation loss:		0.389533
  validation accuracy:		87.61 %
Epoch 1392 of 2000 took 0.103s
  training loss:		0.284862
  validation loss:		0.366128
  validation accuracy:		88.70 %
Epoch 1393 of 2000 took 0.103s
  training loss:		0.284949
  validation loss:		0.390073
  validation accuracy:		88.26 %
Epoch 1394 of 2000 took 0.103s
  training loss:		0.283798
  validation loss:		0.374701
  validation accuracy:		88.48 %
Epoch 1395 of 2000 took 0.103s
  training loss:		0.279584
  validation loss:		0.382757
  validation accuracy:		87.72 %
Epoch 1396 of 2000 took 0.103s
  training loss:		0.278381
  validation loss:		0.386650
  validation accuracy:		87.61 %
Epoch 1397 of 2000 took 0.103s
  training loss:		0.281439
  validation loss:		0.383967
  validation accuracy:		88.04 %
Epoch 1398 of 2000 took 0.103s
  training loss:		0.279166
  validation loss:		0.383243
  validation accuracy:		87.72 %
Epoch 1399 of 2000 took 0.103s
  training loss:		0.280534
  validation loss:		0.404747
  validation accuracy:		87.28 %
Epoch 1400 of 2000 took 0.103s
  training loss:		0.276058
  validation loss:		0.372701
  validation accuracy:		88.37 %
Epoch 1401 of 2000 took 0.103s
  training loss:		0.278276
  validation loss:		0.382133
  validation accuracy:		87.61 %
Epoch 1402 of 2000 took 0.103s
  training loss:		0.280965
  validation loss:		0.384354
  validation accuracy:		87.93 %
Epoch 1403 of 2000 took 0.103s
  training loss:		0.283632
  validation loss:		0.381045
  validation accuracy:		87.72 %
Epoch 1404 of 2000 took 0.103s
  training loss:		0.282955
  validation loss:		0.377976
  validation accuracy:		88.15 %
Epoch 1405 of 2000 took 0.104s
  training loss:		0.278118
  validation loss:		0.374724
  validation accuracy:		88.37 %
Epoch 1406 of 2000 took 0.103s
  training loss:		0.273198
  validation loss:		0.377812
  validation accuracy:		88.15 %
Epoch 1407 of 2000 took 0.103s
  training loss:		0.277547
  validation loss:		0.369996
  validation accuracy:		88.59 %
Epoch 1408 of 2000 took 0.103s
  training loss:		0.279407
  validation loss:		0.379951
  validation accuracy:		88.48 %
Epoch 1409 of 2000 took 0.103s
  training loss:		0.277048
  validation loss:		0.389923
  validation accuracy:		88.15 %
Epoch 1410 of 2000 took 0.103s
  training loss:		0.274707
  validation loss:		0.399664
  validation accuracy:		87.17 %
Epoch 1411 of 2000 took 0.103s
  training loss:		0.275853
  validation loss:		0.378198
  validation accuracy:		87.83 %
Epoch 1412 of 2000 took 0.103s
  training loss:		0.281277
  validation loss:		0.373337
  validation accuracy:		89.35 %
Epoch 1413 of 2000 took 0.103s
  training loss:		0.278256
  validation loss:		0.400435
  validation accuracy:		87.28 %
Epoch 1414 of 2000 took 0.103s
  training loss:		0.286391
  validation loss:		0.365742
  validation accuracy:		88.37 %
Epoch 1415 of 2000 took 0.102s
  training loss:		0.280357
  validation loss:		0.379592
  validation accuracy:		87.72 %
Epoch 1416 of 2000 took 0.100s
  training loss:		0.280291
  validation loss:		0.366926
  validation accuracy:		88.59 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.275616
  validation loss:		0.369284
  validation accuracy:		88.37 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.267617
  validation loss:		0.396855
  validation accuracy:		87.39 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.289826
  validation loss:		0.369503
  validation accuracy:		88.48 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.275401
  validation loss:		0.381750
  validation accuracy:		87.61 %
Epoch 1421 of 2000 took 0.097s
  training loss:		0.276244
  validation loss:		0.413959
  validation accuracy:		86.52 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.282605
  validation loss:		0.397535
  validation accuracy:		87.50 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.280613
  validation loss:		0.371544
  validation accuracy:		88.70 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.284449
  validation loss:		0.369660
  validation accuracy:		88.37 %
Epoch 1425 of 2000 took 0.097s
  training loss:		0.277629
  validation loss:		0.393704
  validation accuracy:		87.61 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.280557
  validation loss:		0.364808
  validation accuracy:		88.70 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.276883
  validation loss:		0.365308
  validation accuracy:		88.59 %
Epoch 1428 of 2000 took 0.097s
  training loss:		0.271653
  validation loss:		0.381479
  validation accuracy:		88.37 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.273488
  validation loss:		0.375950
  validation accuracy:		88.70 %
Epoch 1430 of 2000 took 0.097s
  training loss:		0.283124
  validation loss:		0.368330
  validation accuracy:		88.37 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.280427
  validation loss:		0.380419
  validation accuracy:		87.93 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.280944
  validation loss:		0.385186
  validation accuracy:		87.83 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.272134
  validation loss:		0.377437
  validation accuracy:		87.93 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.277438
  validation loss:		0.364078
  validation accuracy:		88.59 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.279653
  validation loss:		0.372928
  validation accuracy:		88.26 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.281909
  validation loss:		0.427855
  validation accuracy:		86.30 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.280962
  validation loss:		0.415023
  validation accuracy:		87.17 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.275646
  validation loss:		0.371233
  validation accuracy:		88.48 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.271579
  validation loss:		0.387928
  validation accuracy:		87.93 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.273660
  validation loss:		0.368231
  validation accuracy:		88.80 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.279900
  validation loss:		0.379730
  validation accuracy:		88.04 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.278184
  validation loss:		0.362802
  validation accuracy:		89.57 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.281664
  validation loss:		0.369371
  validation accuracy:		88.15 %
Epoch 1444 of 2000 took 0.100s
  training loss:		0.272276
  validation loss:		0.400150
  validation accuracy:		87.39 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.273627
  validation loss:		0.365023
  validation accuracy:		89.24 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.279402
  validation loss:		0.374069
  validation accuracy:		88.59 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.284388
  validation loss:		0.381180
  validation accuracy:		88.15 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.284066
  validation loss:		0.378972
  validation accuracy:		88.37 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.282295
  validation loss:		0.374821
  validation accuracy:		88.26 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.276541
  validation loss:		0.412725
  validation accuracy:		86.63 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.276020
  validation loss:		0.360675
  validation accuracy:		89.02 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.275440
  validation loss:		0.370001
  validation accuracy:		88.37 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.275601
  validation loss:		0.375518
  validation accuracy:		88.48 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.270420
  validation loss:		0.370119
  validation accuracy:		88.48 %
Epoch 1455 of 2000 took 0.096s
  training loss:		0.270798
  validation loss:		0.377182
  validation accuracy:		88.26 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.273944
  validation loss:		0.397411
  validation accuracy:		87.28 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.277367
  validation loss:		0.370222
  validation accuracy:		88.26 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.276789
  validation loss:		0.360517
  validation accuracy:		89.46 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.274133
  validation loss:		0.372146
  validation accuracy:		88.26 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.278367
  validation loss:		0.414554
  validation accuracy:		86.85 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.275141
  validation loss:		0.404584
  validation accuracy:		87.17 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.280501
  validation loss:		0.384527
  validation accuracy:		87.93 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.272735
  validation loss:		0.366161
  validation accuracy:		88.80 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.275587
  validation loss:		0.365210
  validation accuracy:		88.26 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.272514
  validation loss:		0.367089
  validation accuracy:		88.48 %
Epoch 1466 of 2000 took 0.097s
  training loss:		0.278189
  validation loss:		0.363465
  validation accuracy:		88.59 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.280399
  validation loss:		0.390629
  validation accuracy:		88.04 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.276123
  validation loss:		0.369300
  validation accuracy:		88.15 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.273451
  validation loss:		0.368347
  validation accuracy:		88.15 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.269645
  validation loss:		0.362032
  validation accuracy:		89.13 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.281750
  validation loss:		0.403976
  validation accuracy:		87.50 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.273089
  validation loss:		0.377330
  validation accuracy:		88.26 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.274829
  validation loss:		0.426122
  validation accuracy:		86.30 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.279205
  validation loss:		0.360283
  validation accuracy:		89.24 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.280334
  validation loss:		0.399683
  validation accuracy:		87.07 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.274725
  validation loss:		0.361110
  validation accuracy:		89.24 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.277851
  validation loss:		0.377170
  validation accuracy:		88.59 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.277743
  validation loss:		0.382892
  validation accuracy:		87.93 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.274070
  validation loss:		0.368921
  validation accuracy:		88.26 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.277724
  validation loss:		0.385363
  validation accuracy:		87.61 %
Epoch 1481 of 2000 took 0.096s
  training loss:		0.269894
  validation loss:		0.395956
  validation accuracy:		87.61 %
Epoch 1482 of 2000 took 0.097s
  training loss:		0.275986
  validation loss:		0.374982
  validation accuracy:		88.48 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.271338
  validation loss:		0.385236
  validation accuracy:		88.37 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.276352
  validation loss:		0.368409
  validation accuracy:		88.37 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.282969
  validation loss:		0.371815
  validation accuracy:		88.48 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.272356
  validation loss:		0.390042
  validation accuracy:		88.04 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.280233
  validation loss:		0.381868
  validation accuracy:		88.48 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.268267
  validation loss:		0.384505
  validation accuracy:		88.26 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.272076
  validation loss:		0.371733
  validation accuracy:		88.04 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.273107
  validation loss:		0.368915
  validation accuracy:		88.26 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.275840
  validation loss:		0.384862
  validation accuracy:		88.04 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.264449
  validation loss:		0.366583
  validation accuracy:		88.80 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.285333
  validation loss:		0.364808
  validation accuracy:		88.59 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.266884
  validation loss:		0.359593
  validation accuracy:		88.91 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.275867
  validation loss:		0.388889
  validation accuracy:		87.39 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.272755
  validation loss:		0.368379
  validation accuracy:		88.37 %
Epoch 1497 of 2000 took 0.097s
  training loss:		0.265435
  validation loss:		0.379745
  validation accuracy:		88.26 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.276025
  validation loss:		0.368443
  validation accuracy:		88.26 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.272718
  validation loss:		0.369248
  validation accuracy:		88.26 %
Epoch 1500 of 2000 took 0.096s
  training loss:		0.266472
  validation loss:		0.374916
  validation accuracy:		88.48 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.271805
  validation loss:		0.388133
  validation accuracy:		87.83 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.272572
  validation loss:		0.370514
  validation accuracy:		88.91 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.261416
  validation loss:		0.379924
  validation accuracy:		88.59 %
Epoch 1504 of 2000 took 0.096s
  training loss:		0.268177
  validation loss:		0.410372
  validation accuracy:		87.28 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.276581
  validation loss:		0.368092
  validation accuracy:		88.80 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.276138
  validation loss:		0.368852
  validation accuracy:		88.48 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.273867
  validation loss:		0.400122
  validation accuracy:		87.72 %
Epoch 1508 of 2000 took 0.097s
  training loss:		0.276673
  validation loss:		0.383640
  validation accuracy:		88.04 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.266431
  validation loss:		0.363256
  validation accuracy:		88.80 %
Epoch 1510 of 2000 took 0.096s
  training loss:		0.272267
  validation loss:		0.364029
  validation accuracy:		88.59 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.270638
  validation loss:		0.370859
  validation accuracy:		88.59 %
Epoch 1512 of 2000 took 0.096s
  training loss:		0.276876
  validation loss:		0.364357
  validation accuracy:		88.48 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.268388
  validation loss:		0.370575
  validation accuracy:		88.59 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.278481
  validation loss:		0.386806
  validation accuracy:		88.15 %
Epoch 1515 of 2000 took 0.096s
  training loss:		0.270557
  validation loss:		0.386292
  validation accuracy:		88.37 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.272098
  validation loss:		0.376629
  validation accuracy:		88.15 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.267606
  validation loss:		0.379778
  validation accuracy:		88.15 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.271289
  validation loss:		0.381101
  validation accuracy:		88.26 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.275196
  validation loss:		0.386884
  validation accuracy:		88.37 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.270466
  validation loss:		0.376379
  validation accuracy:		88.70 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.273169
  validation loss:		0.367103
  validation accuracy:		88.91 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.271763
  validation loss:		0.380520
  validation accuracy:		88.59 %
Epoch 1523 of 2000 took 0.096s
  training loss:		0.276135
  validation loss:		0.375101
  validation accuracy:		88.59 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.268034
  validation loss:		0.370488
  validation accuracy:		88.70 %
Epoch 1525 of 2000 took 0.096s
  training loss:		0.272974
  validation loss:		0.368550
  validation accuracy:		88.59 %
Epoch 1526 of 2000 took 0.097s
  training loss:		0.268938
  validation loss:		0.385020
  validation accuracy:		88.04 %
Epoch 1527 of 2000 took 0.096s
  training loss:		0.279383
  validation loss:		0.394070
  validation accuracy:		87.93 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.275241
  validation loss:		0.361584
  validation accuracy:		88.70 %
Epoch 1529 of 2000 took 0.097s
  training loss:		0.270785
  validation loss:		0.382470
  validation accuracy:		88.59 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.272063
  validation loss:		0.386974
  validation accuracy:		88.04 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.276293
  validation loss:		0.388407
  validation accuracy:		87.50 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.267519
  validation loss:		0.390990
  validation accuracy:		88.04 %
Epoch 1533 of 2000 took 0.096s
  training loss:		0.278636
  validation loss:		0.381059
  validation accuracy:		88.37 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.279058
  validation loss:		0.398354
  validation accuracy:		88.26 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.275552
  validation loss:		0.378937
  validation accuracy:		87.72 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.280274
  validation loss:		0.378912
  validation accuracy:		88.70 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.268693
  validation loss:		0.361873
  validation accuracy:		89.02 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.265985
  validation loss:		0.389850
  validation accuracy:		88.37 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.268898
  validation loss:		0.371792
  validation accuracy:		88.26 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.270698
  validation loss:		0.381956
  validation accuracy:		88.59 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.273337
  validation loss:		0.368871
  validation accuracy:		88.80 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.270609
  validation loss:		0.404734
  validation accuracy:		87.39 %
Epoch 1543 of 2000 took 0.096s
  training loss:		0.274067
  validation loss:		0.378068
  validation accuracy:		87.61 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.266859
  validation loss:		0.369429
  validation accuracy:		88.59 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.274239
  validation loss:		0.376866
  validation accuracy:		87.93 %
Epoch 1546 of 2000 took 0.096s
  training loss:		0.272375
  validation loss:		0.377433
  validation accuracy:		88.15 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.266904
  validation loss:		0.394135
  validation accuracy:		87.39 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.276028
  validation loss:		0.370638
  validation accuracy:		88.48 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.274197
  validation loss:		0.371438
  validation accuracy:		88.70 %
Epoch 1550 of 2000 took 0.096s
  training loss:		0.266331
  validation loss:		0.391812
  validation accuracy:		88.04 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.276939
  validation loss:		0.378339
  validation accuracy:		88.70 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.271747
  validation loss:		0.363608
  validation accuracy:		89.02 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.265275
  validation loss:		0.377719
  validation accuracy:		88.70 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.277058
  validation loss:		0.377482
  validation accuracy:		87.83 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.274067
  validation loss:		0.388730
  validation accuracy:		88.48 %
Epoch 1556 of 2000 took 0.096s
  training loss:		0.269876
  validation loss:		0.386718
  validation accuracy:		88.70 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.264381
  validation loss:		0.374143
  validation accuracy:		88.37 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.268569
  validation loss:		0.361012
  validation accuracy:		89.13 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.266507
  validation loss:		0.364387
  validation accuracy:		88.80 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.271420
  validation loss:		0.363336
  validation accuracy:		88.59 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.270909
  validation loss:		0.361084
  validation accuracy:		89.13 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.258565
  validation loss:		0.373838
  validation accuracy:		87.83 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.272132
  validation loss:		0.368738
  validation accuracy:		88.26 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.277229
  validation loss:		0.387716
  validation accuracy:		88.48 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.273174
  validation loss:		0.371083
  validation accuracy:		88.48 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.271146
  validation loss:		0.364605
  validation accuracy:		88.80 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.263882
  validation loss:		0.378874
  validation accuracy:		88.26 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.276556
  validation loss:		0.374902
  validation accuracy:		88.04 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.273529
  validation loss:		0.367243
  validation accuracy:		88.91 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.274073
  validation loss:		0.362312
  validation accuracy:		89.13 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.268615
  validation loss:		0.366425
  validation accuracy:		88.80 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.265225
  validation loss:		0.377751
  validation accuracy:		88.70 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.268462
  validation loss:		0.371100
  validation accuracy:		88.70 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.272693
  validation loss:		0.365675
  validation accuracy:		88.80 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.271702
  validation loss:		0.374203
  validation accuracy:		88.70 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.269834
  validation loss:		0.398503
  validation accuracy:		88.59 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.271389
  validation loss:		0.411686
  validation accuracy:		87.61 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.275803
  validation loss:		0.396337
  validation accuracy:		87.83 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.268972
  validation loss:		0.373747
  validation accuracy:		88.59 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.271618
  validation loss:		0.396416
  validation accuracy:		87.72 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.269806
  validation loss:		0.377733
  validation accuracy:		87.93 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.267507
  validation loss:		0.372801
  validation accuracy:		88.80 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.262918
  validation loss:		0.359663
  validation accuracy:		89.35 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.268052
  validation loss:		0.372296
  validation accuracy:		88.80 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.267886
  validation loss:		0.370419
  validation accuracy:		89.24 %
Epoch 1586 of 2000 took 0.097s
  training loss:		0.267823
  validation loss:		0.380103
  validation accuracy:		88.48 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.266176
  validation loss:		0.364367
  validation accuracy:		89.35 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.272429
  validation loss:		0.360508
  validation accuracy:		88.80 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.269306
  validation loss:		0.373754
  validation accuracy:		88.37 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.263984
  validation loss:		0.409057
  validation accuracy:		87.72 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.268390
  validation loss:		0.386390
  validation accuracy:		88.48 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.269412
  validation loss:		0.374132
  validation accuracy:		88.80 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.269797
  validation loss:		0.373640
  validation accuracy:		88.26 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.261285
  validation loss:		0.363303
  validation accuracy:		88.48 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.264726
  validation loss:		0.378300
  validation accuracy:		88.26 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.269065
  validation loss:		0.393410
  validation accuracy:		87.83 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.272407
  validation loss:		0.368023
  validation accuracy:		88.80 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.269411
  validation loss:		0.375050
  validation accuracy:		88.37 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.273316
  validation loss:		0.380649
  validation accuracy:		88.48 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.271171
  validation loss:		0.365339
  validation accuracy:		89.02 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.269837
  validation loss:		0.371460
  validation accuracy:		88.59 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.267988
  validation loss:		0.362194
  validation accuracy:		88.70 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.262763
  validation loss:		0.364184
  validation accuracy:		88.80 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.273244
  validation loss:		0.388736
  validation accuracy:		87.93 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.269598
  validation loss:		0.379676
  validation accuracy:		88.15 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.273528
  validation loss:		0.367797
  validation accuracy:		88.91 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.269556
  validation loss:		0.371375
  validation accuracy:		88.80 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.269750
  validation loss:		0.370831
  validation accuracy:		87.93 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.268561
  validation loss:		0.382749
  validation accuracy:		88.59 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.269196
  validation loss:		0.369452
  validation accuracy:		88.48 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.267211
  validation loss:		0.382739
  validation accuracy:		87.72 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.271150
  validation loss:		0.363000
  validation accuracy:		89.13 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.266955
  validation loss:		0.367230
  validation accuracy:		88.91 %
Epoch 1614 of 2000 took 0.096s
  training loss:		0.262693
  validation loss:		0.378270
  validation accuracy:		87.72 %
Epoch 1615 of 2000 took 0.096s
  training loss:		0.264387
  validation loss:		0.375370
  validation accuracy:		87.93 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.266284
  validation loss:		0.377252
  validation accuracy:		88.70 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.267917
  validation loss:		0.406289
  validation accuracy:		88.37 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.258550
  validation loss:		0.364165
  validation accuracy:		88.70 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.275527
  validation loss:		0.363912
  validation accuracy:		88.80 %
Epoch 1620 of 2000 took 0.096s
  training loss:		0.265502
  validation loss:		0.365856
  validation accuracy:		88.59 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.269070
  validation loss:		0.388562
  validation accuracy:		88.37 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.267662
  validation loss:		0.376908
  validation accuracy:		88.37 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.267266
  validation loss:		0.370513
  validation accuracy:		88.26 %
Epoch 1624 of 2000 took 0.096s
  training loss:		0.262437
  validation loss:		0.361265
  validation accuracy:		89.67 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.272079
  validation loss:		0.380138
  validation accuracy:		88.37 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.263020
  validation loss:		0.380510
  validation accuracy:		88.59 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.268041
  validation loss:		0.375711
  validation accuracy:		88.59 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.275631
  validation loss:		0.383666
  validation accuracy:		88.91 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.262232
  validation loss:		0.378007
  validation accuracy:		88.48 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.267831
  validation loss:		0.370921
  validation accuracy:		88.91 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.270864
  validation loss:		0.370506
  validation accuracy:		88.70 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.264538
  validation loss:		0.373792
  validation accuracy:		88.37 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.267708
  validation loss:		0.369758
  validation accuracy:		88.37 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.271584
  validation loss:		0.378633
  validation accuracy:		88.70 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.262264
  validation loss:		0.410015
  validation accuracy:		88.37 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.264361
  validation loss:		0.378007
  validation accuracy:		88.70 %
Epoch 1637 of 2000 took 0.096s
  training loss:		0.271169
  validation loss:		0.383312
  validation accuracy:		87.93 %
Epoch 1638 of 2000 took 0.096s
  training loss:		0.261159
  validation loss:		0.380797
  validation accuracy:		88.04 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.263641
  validation loss:		0.359388
  validation accuracy:		89.57 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.264413
  validation loss:		0.361871
  validation accuracy:		89.24 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.265812
  validation loss:		0.381086
  validation accuracy:		88.80 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.270343
  validation loss:		0.373085
  validation accuracy:		88.59 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.263413
  validation loss:		0.384314
  validation accuracy:		87.72 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.274311
  validation loss:		0.391077
  validation accuracy:		87.72 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.270673
  validation loss:		0.371503
  validation accuracy:		88.59 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.262596
  validation loss:		0.386816
  validation accuracy:		88.80 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.264968
  validation loss:		0.382841
  validation accuracy:		87.83 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.265768
  validation loss:		0.374154
  validation accuracy:		88.70 %
Epoch 1649 of 2000 took 0.098s
  training loss:		0.266865
  validation loss:		0.367577
  validation accuracy:		88.70 %
Epoch 1650 of 2000 took 0.097s
  training loss:		0.273803
  validation loss:		0.389450
  validation accuracy:		88.04 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.269582
  validation loss:		0.379600
  validation accuracy:		88.04 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.258489
  validation loss:		0.405604
  validation accuracy:		88.80 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.261710
  validation loss:		0.368528
  validation accuracy:		88.48 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.266075
  validation loss:		0.383044
  validation accuracy:		88.70 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.268706
  validation loss:		0.384125
  validation accuracy:		88.04 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.263843
  validation loss:		0.383456
  validation accuracy:		88.80 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.267055
  validation loss:		0.371700
  validation accuracy:		88.37 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.271911
  validation loss:		0.370708
  validation accuracy:		88.37 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.264441
  validation loss:		0.374662
  validation accuracy:		88.70 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.269121
  validation loss:		0.363642
  validation accuracy:		89.46 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.270724
  validation loss:		0.369846
  validation accuracy:		88.91 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.263870
  validation loss:		0.397142
  validation accuracy:		87.93 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.269635
  validation loss:		0.363077
  validation accuracy:		89.13 %
Epoch 1664 of 2000 took 0.097s
  training loss:		0.265804
  validation loss:		0.366777
  validation accuracy:		88.70 %
Epoch 1665 of 2000 took 0.097s
  training loss:		0.268423
  validation loss:		0.371258
  validation accuracy:		88.59 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.262571
  validation loss:		0.377849
  validation accuracy:		88.37 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.269628
  validation loss:		0.364953
  validation accuracy:		89.02 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.270735
  validation loss:		0.363776
  validation accuracy:		88.91 %
Epoch 1669 of 2000 took 0.096s
  training loss:		0.264094
  validation loss:		0.382029
  validation accuracy:		87.72 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.266762
  validation loss:		0.373455
  validation accuracy:		88.26 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.277043
  validation loss:		0.383064
  validation accuracy:		88.70 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.264551
  validation loss:		0.390136
  validation accuracy:		88.91 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.265237
  validation loss:		0.373721
  validation accuracy:		88.70 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.261760
  validation loss:		0.387196
  validation accuracy:		89.02 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.264027
  validation loss:		0.376259
  validation accuracy:		88.15 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.267439
  validation loss:		0.371238
  validation accuracy:		88.37 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.263327
  validation loss:		0.379963
  validation accuracy:		88.80 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.266566
  validation loss:		0.365619
  validation accuracy:		89.02 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.262884
  validation loss:		0.393857
  validation accuracy:		88.70 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.266417
  validation loss:		0.375342
  validation accuracy:		88.48 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.267722
  validation loss:		0.372693
  validation accuracy:		88.70 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.261909
  validation loss:		0.372838
  validation accuracy:		88.70 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.268560
  validation loss:		0.386653
  validation accuracy:		88.70 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.263632
  validation loss:		0.399125
  validation accuracy:		87.93 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.270801
  validation loss:		0.371248
  validation accuracy:		88.70 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.267913
  validation loss:		0.379572
  validation accuracy:		88.48 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.259489
  validation loss:		0.364077
  validation accuracy:		89.13 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.262687
  validation loss:		0.399428
  validation accuracy:		87.39 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.267566
  validation loss:		0.367352
  validation accuracy:		88.80 %
Epoch 1690 of 2000 took 0.097s
  training loss:		0.259949
  validation loss:		0.376213
  validation accuracy:		88.80 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.256139
  validation loss:		0.407327
  validation accuracy:		88.48 %
Epoch 1692 of 2000 took 0.097s
  training loss:		0.258607
  validation loss:		0.377331
  validation accuracy:		88.26 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.260803
  validation loss:		0.401412
  validation accuracy:		88.15 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.264430
  validation loss:		0.379127
  validation accuracy:		88.59 %
Epoch 1695 of 2000 took 0.097s
  training loss:		0.263229
  validation loss:		0.366291
  validation accuracy:		89.46 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.267050
  validation loss:		0.387546
  validation accuracy:		87.83 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.261695
  validation loss:		0.366524
  validation accuracy:		88.91 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.261314
  validation loss:		0.390192
  validation accuracy:		88.48 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.266864
  validation loss:		0.368703
  validation accuracy:		88.80 %
Epoch 1700 of 2000 took 0.096s
  training loss:		0.270753
  validation loss:		0.366300
  validation accuracy:		89.13 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.264322
  validation loss:		0.378068
  validation accuracy:		88.37 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.262647
  validation loss:		0.367417
  validation accuracy:		88.91 %
Epoch 1703 of 2000 took 0.096s
  training loss:		0.270381
  validation loss:		0.377894
  validation accuracy:		88.80 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.259347
  validation loss:		0.367333
  validation accuracy:		89.78 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.264045
  validation loss:		0.372700
  validation accuracy:		88.59 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.264682
  validation loss:		0.396490
  validation accuracy:		88.48 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.265803
  validation loss:		0.381534
  validation accuracy:		88.26 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.264681
  validation loss:		0.371758
  validation accuracy:		88.80 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.268858
  validation loss:		0.365163
  validation accuracy:		89.02 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.268463
  validation loss:		0.373889
  validation accuracy:		88.48 %
Epoch 1711 of 2000 took 0.096s
  training loss:		0.264063
  validation loss:		0.368731
  validation accuracy:		88.70 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.260087
  validation loss:		0.376600
  validation accuracy:		88.26 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.260337
  validation loss:		0.379927
  validation accuracy:		88.37 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.261296
  validation loss:		0.376252
  validation accuracy:		88.37 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.265685
  validation loss:		0.380132
  validation accuracy:		88.04 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.271034
  validation loss:		0.380189
  validation accuracy:		88.70 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.262660
  validation loss:		0.365649
  validation accuracy:		88.91 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.262168
  validation loss:		0.380244
  validation accuracy:		88.80 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.273458
  validation loss:		0.384620
  validation accuracy:		88.37 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.265905
  validation loss:		0.393756
  validation accuracy:		88.37 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.261580
  validation loss:		0.371344
  validation accuracy:		88.59 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.268075
  validation loss:		0.361200
  validation accuracy:		89.46 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.265639
  validation loss:		0.365876
  validation accuracy:		88.91 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.263710
  validation loss:		0.369419
  validation accuracy:		88.70 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.266126
  validation loss:		0.373361
  validation accuracy:		88.37 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.264609
  validation loss:		0.371839
  validation accuracy:		89.13 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.265674
  validation loss:		0.392467
  validation accuracy:		88.59 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.270611
  validation loss:		0.364647
  validation accuracy:		88.91 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.262720
  validation loss:		0.375494
  validation accuracy:		89.02 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.265335
  validation loss:		0.400486
  validation accuracy:		87.50 %
Epoch 1731 of 2000 took 0.096s
  training loss:		0.258762
  validation loss:		0.406626
  validation accuracy:		88.48 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.266862
  validation loss:		0.369148
  validation accuracy:		88.70 %
Epoch 1733 of 2000 took 0.097s
  training loss:		0.270165
  validation loss:		0.374446
  validation accuracy:		88.48 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.262382
  validation loss:		0.397122
  validation accuracy:		88.80 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.269781
  validation loss:		0.369375
  validation accuracy:		88.04 %
Epoch 1736 of 2000 took 0.097s
  training loss:		0.266282
  validation loss:		0.377940
  validation accuracy:		88.37 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.256735
  validation loss:		0.367729
  validation accuracy:		88.91 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.264634
  validation loss:		0.363878
  validation accuracy:		88.91 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.262088
  validation loss:		0.380203
  validation accuracy:		88.59 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.261601
  validation loss:		0.372206
  validation accuracy:		88.70 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.264656
  validation loss:		0.398609
  validation accuracy:		87.39 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.264102
  validation loss:		0.369352
  validation accuracy:		89.24 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.266955
  validation loss:		0.393064
  validation accuracy:		89.13 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.270703
  validation loss:		0.424887
  validation accuracy:		87.39 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.265286
  validation loss:		0.387748
  validation accuracy:		88.15 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.267892
  validation loss:		0.368996
  validation accuracy:		88.70 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.267286
  validation loss:		0.382906
  validation accuracy:		88.91 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.264919
  validation loss:		0.370207
  validation accuracy:		88.37 %
Epoch 1749 of 2000 took 0.096s
  training loss:		0.272567
  validation loss:		0.369992
  validation accuracy:		88.91 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.264392
  validation loss:		0.361192
  validation accuracy:		89.02 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.260089
  validation loss:		0.364371
  validation accuracy:		88.91 %
Epoch 1752 of 2000 took 0.096s
  training loss:		0.262942
  validation loss:		0.376320
  validation accuracy:		89.02 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.263138
  validation loss:		0.400653
  validation accuracy:		88.04 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.270295
  validation loss:		0.378533
  validation accuracy:		88.59 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.262189
  validation loss:		0.400928
  validation accuracy:		87.83 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.262694
  validation loss:		0.365787
  validation accuracy:		88.80 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.261776
  validation loss:		0.365075
  validation accuracy:		89.46 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.262841
  validation loss:		0.380601
  validation accuracy:		88.70 %
Epoch 1759 of 2000 took 0.097s
  training loss:		0.264316
  validation loss:		0.385084
  validation accuracy:		87.93 %
Epoch 1760 of 2000 took 0.097s
  training loss:		0.263883
  validation loss:		0.400883
  validation accuracy:		89.02 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.265487
  validation loss:		0.365155
  validation accuracy:		89.13 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.261080
  validation loss:		0.362440
  validation accuracy:		89.35 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.261105
  validation loss:		0.412071
  validation accuracy:		87.72 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.262690
  validation loss:		0.383634
  validation accuracy:		88.15 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.256331
  validation loss:		0.363874
  validation accuracy:		89.13 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.258538
  validation loss:		0.378170
  validation accuracy:		88.80 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.259630
  validation loss:		0.387464
  validation accuracy:		89.13 %
Epoch 1768 of 2000 took 0.097s
  training loss:		0.261281
  validation loss:		0.386965
  validation accuracy:		88.70 %
Epoch 1769 of 2000 took 0.096s
  training loss:		0.259723
  validation loss:		0.380575
  validation accuracy:		87.93 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.269531
  validation loss:		0.382309
  validation accuracy:		88.15 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.269674
  validation loss:		0.365860
  validation accuracy:		89.46 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.261695
  validation loss:		0.389598
  validation accuracy:		88.59 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.271122
  validation loss:		0.401695
  validation accuracy:		87.72 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.267630
  validation loss:		0.365271
  validation accuracy:		89.67 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.271021
  validation loss:		0.367939
  validation accuracy:		89.57 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.259656
  validation loss:		0.368731
  validation accuracy:		89.13 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.262997
  validation loss:		0.370508
  validation accuracy:		88.37 %
Epoch 1778 of 2000 took 0.097s
  training loss:		0.261475
  validation loss:		0.368075
  validation accuracy:		89.13 %
Epoch 1779 of 2000 took 0.097s
  training loss:		0.255033
  validation loss:		0.386708
  validation accuracy:		88.15 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.258973
  validation loss:		0.378029
  validation accuracy:		88.59 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.265595
  validation loss:		0.375810
  validation accuracy:		88.26 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.262832
  validation loss:		0.377876
  validation accuracy:		88.91 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.254272
  validation loss:		0.369305
  validation accuracy:		89.13 %
Epoch 1784 of 2000 took 0.096s
  training loss:		0.258980
  validation loss:		0.372720
  validation accuracy:		89.24 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.262815
  validation loss:		0.372711
  validation accuracy:		88.48 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.265889
  validation loss:		0.376372
  validation accuracy:		88.80 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.258244
  validation loss:		0.382398
  validation accuracy:		87.93 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.265115
  validation loss:		0.383114
  validation accuracy:		88.80 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.265729
  validation loss:		0.409449
  validation accuracy:		87.72 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.268136
  validation loss:		0.376651
  validation accuracy:		88.80 %
Epoch 1791 of 2000 took 0.097s
  training loss:		0.260918
  validation loss:		0.376906
  validation accuracy:		88.26 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.257133
  validation loss:		0.379490
  validation accuracy:		89.35 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.256973
  validation loss:		0.378238
  validation accuracy:		88.26 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.262921
  validation loss:		0.382785
  validation accuracy:		88.59 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.267323
  validation loss:		0.370658
  validation accuracy:		88.70 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.264523
  validation loss:		0.386411
  validation accuracy:		88.80 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.265965
  validation loss:		0.405247
  validation accuracy:		88.04 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.259029
  validation loss:		0.367882
  validation accuracy:		88.70 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.264779
  validation loss:		0.391971
  validation accuracy:		88.26 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.255605
  validation loss:		0.381141
  validation accuracy:		88.91 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.258095
  validation loss:		0.374787
  validation accuracy:		88.80 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.263099
  validation loss:		0.371927
  validation accuracy:		89.02 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.261099
  validation loss:		0.375765
  validation accuracy:		88.80 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.260781
  validation loss:		0.398233
  validation accuracy:		88.80 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.261121
  validation loss:		0.365529
  validation accuracy:		89.13 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.255178
  validation loss:		0.365620
  validation accuracy:		88.91 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.263433
  validation loss:		0.391449
  validation accuracy:		87.93 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.266578
  validation loss:		0.368485
  validation accuracy:		89.57 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.264155
  validation loss:		0.365660
  validation accuracy:		89.13 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.267033
  validation loss:		0.413474
  validation accuracy:		88.37 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.278254
  validation loss:		0.387027
  validation accuracy:		88.15 %
Epoch 1812 of 2000 took 0.099s
  training loss:		0.267961
  validation loss:		0.367609
  validation accuracy:		89.57 %
Epoch 1813 of 2000 took 0.099s
  training loss:		0.258152
  validation loss:		0.373437
  validation accuracy:		89.35 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.260734
  validation loss:		0.378225
  validation accuracy:		88.80 %
Epoch 1815 of 2000 took 0.099s
  training loss:		0.256493
  validation loss:		0.375673
  validation accuracy:		88.91 %
Epoch 1816 of 2000 took 0.100s
  training loss:		0.257375
  validation loss:		0.371242
  validation accuracy:		88.91 %
Epoch 1817 of 2000 took 0.099s
  training loss:		0.256762
  validation loss:		0.383196
  validation accuracy:		88.48 %
Epoch 1818 of 2000 took 0.099s
  training loss:		0.258742
  validation loss:		0.396965
  validation accuracy:		88.59 %
Epoch 1819 of 2000 took 0.100s
  training loss:		0.262619
  validation loss:		0.372592
  validation accuracy:		88.91 %
Epoch 1820 of 2000 took 0.100s
  training loss:		0.257801
  validation loss:		0.376473
  validation accuracy:		88.91 %
Epoch 1821 of 2000 took 0.100s
  training loss:		0.259549
  validation loss:		0.376932
  validation accuracy:		88.48 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.264725
  validation loss:		0.378016
  validation accuracy:		88.80 %
Epoch 1823 of 2000 took 0.099s
  training loss:		0.263055
  validation loss:		0.374714
  validation accuracy:		88.59 %
Epoch 1824 of 2000 took 0.099s
  training loss:		0.264794
  validation loss:		0.380381
  validation accuracy:		88.91 %
Epoch 1825 of 2000 took 0.099s
  training loss:		0.261907
  validation loss:		0.367513
  validation accuracy:		88.80 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.267359
  validation loss:		0.386253
  validation accuracy:		88.15 %
Epoch 1827 of 2000 took 0.099s
  training loss:		0.265129
  validation loss:		0.382162
  validation accuracy:		88.70 %
Epoch 1828 of 2000 took 0.099s
  training loss:		0.267503
  validation loss:		0.373264
  validation accuracy:		88.80 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.263039
  validation loss:		0.378664
  validation accuracy:		88.80 %
Epoch 1830 of 2000 took 0.099s
  training loss:		0.266643
  validation loss:		0.391258
  validation accuracy:		88.15 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.273292
  validation loss:		0.374302
  validation accuracy:		88.91 %
Epoch 1832 of 2000 took 0.099s
  training loss:		0.258701
  validation loss:		0.363007
  validation accuracy:		88.91 %
Epoch 1833 of 2000 took 0.099s
  training loss:		0.257109
  validation loss:		0.426062
  validation accuracy:		87.17 %
Epoch 1834 of 2000 took 0.099s
  training loss:		0.266099
  validation loss:		0.373127
  validation accuracy:		89.24 %
Epoch 1835 of 2000 took 0.099s
  training loss:		0.262188
  validation loss:		0.397122
  validation accuracy:		87.93 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.257851
  validation loss:		0.361304
  validation accuracy:		89.24 %
Epoch 1837 of 2000 took 0.099s
  training loss:		0.262399
  validation loss:		0.374418
  validation accuracy:		88.80 %
Epoch 1838 of 2000 took 0.099s
  training loss:		0.264327
  validation loss:		0.367743
  validation accuracy:		88.91 %
Epoch 1839 of 2000 took 0.100s
  training loss:		0.257431
  validation loss:		0.378812
  validation accuracy:		88.37 %
Epoch 1840 of 2000 took 0.099s
  training loss:		0.260475
  validation loss:		0.369465
  validation accuracy:		89.02 %
Epoch 1841 of 2000 took 0.099s
  training loss:		0.258233
  validation loss:		0.379271
  validation accuracy:		88.80 %
Epoch 1842 of 2000 took 0.099s
  training loss:		0.255887
  validation loss:		0.370122
  validation accuracy:		88.59 %
Epoch 1843 of 2000 took 0.099s
  training loss:		0.267329
  validation loss:		0.393225
  validation accuracy:		88.37 %
Epoch 1844 of 2000 took 0.099s
  training loss:		0.264209
  validation loss:		0.366466
  validation accuracy:		88.80 %
Epoch 1845 of 2000 took 0.099s
  training loss:		0.267420
  validation loss:		0.386852
  validation accuracy:		88.15 %
Epoch 1846 of 2000 took 0.099s
  training loss:		0.267737
  validation loss:		0.383232
  validation accuracy:		88.80 %
Epoch 1847 of 2000 took 0.099s
  training loss:		0.261890
  validation loss:		0.370434
  validation accuracy:		89.35 %
Epoch 1848 of 2000 took 0.099s
  training loss:		0.264521
  validation loss:		0.377458
  validation accuracy:		88.59 %
Epoch 1849 of 2000 took 0.099s
  training loss:		0.265325
  validation loss:		0.369128
  validation accuracy:		89.46 %
Epoch 1850 of 2000 took 0.099s
  training loss:		0.270599
  validation loss:		0.370916
  validation accuracy:		88.80 %
Epoch 1851 of 2000 took 0.099s
  training loss:		0.262602
  validation loss:		0.372578
  validation accuracy:		88.91 %
Epoch 1852 of 2000 took 0.100s
  training loss:		0.266912
  validation loss:		0.373798
  validation accuracy:		89.35 %
Epoch 1853 of 2000 took 0.099s
  training loss:		0.259427
  validation loss:		0.367266
  validation accuracy:		89.13 %
Epoch 1854 of 2000 took 0.099s
  training loss:		0.257746
  validation loss:		0.373698
  validation accuracy:		88.91 %
Epoch 1855 of 2000 took 0.099s
  training loss:		0.265676
  validation loss:		0.401916
  validation accuracy:		88.80 %
Epoch 1856 of 2000 took 0.099s
  training loss:		0.261351
  validation loss:		0.368114
  validation accuracy:		88.91 %
Epoch 1857 of 2000 took 0.099s
  training loss:		0.267434
  validation loss:		0.363015
  validation accuracy:		89.02 %
Epoch 1858 of 2000 took 0.099s
  training loss:		0.261402
  validation loss:		0.376693
  validation accuracy:		88.80 %
Epoch 1859 of 2000 took 0.100s
  training loss:		0.263469
  validation loss:		0.390239
  validation accuracy:		88.59 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.255347
  validation loss:		0.369177
  validation accuracy:		89.02 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.259738
  validation loss:		0.368592
  validation accuracy:		89.13 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.257550
  validation loss:		0.378380
  validation accuracy:		88.48 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.261028
  validation loss:		0.369187
  validation accuracy:		88.91 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.265543
  validation loss:		0.368179
  validation accuracy:		89.35 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.259518
  validation loss:		0.386512
  validation accuracy:		89.24 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.258217
  validation loss:		0.375078
  validation accuracy:		88.91 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.262833
  validation loss:		0.383000
  validation accuracy:		89.13 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.262873
  validation loss:		0.430685
  validation accuracy:		86.52 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.259013
  validation loss:		0.381367
  validation accuracy:		88.26 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.266494
  validation loss:		0.368603
  validation accuracy:		88.70 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.257098
  validation loss:		0.372291
  validation accuracy:		89.46 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.264015
  validation loss:		0.408210
  validation accuracy:		87.93 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.255111
  validation loss:		0.370180
  validation accuracy:		89.13 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.260177
  validation loss:		0.383796
  validation accuracy:		89.13 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.268397
  validation loss:		0.384401
  validation accuracy:		88.37 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.259607
  validation loss:		0.379926
  validation accuracy:		89.02 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.255032
  validation loss:		0.399886
  validation accuracy:		88.48 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.254670
  validation loss:		0.401408
  validation accuracy:		88.59 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.255952
  validation loss:		0.384938
  validation accuracy:		88.59 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.265471
  validation loss:		0.392552
  validation accuracy:		88.70 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.266282
  validation loss:		0.372947
  validation accuracy:		89.24 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.262561
  validation loss:		0.365219
  validation accuracy:		89.02 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.256992
  validation loss:		0.368666
  validation accuracy:		89.02 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.259936
  validation loss:		0.372972
  validation accuracy:		89.24 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.258719
  validation loss:		0.364501
  validation accuracy:		89.02 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.267867
  validation loss:		0.378860
  validation accuracy:		88.91 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.262806
  validation loss:		0.382125
  validation accuracy:		88.59 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.258985
  validation loss:		0.367856
  validation accuracy:		88.70 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.253347
  validation loss:		0.382731
  validation accuracy:		88.26 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.258733
  validation loss:		0.371939
  validation accuracy:		89.35 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.261126
  validation loss:		0.369208
  validation accuracy:		89.24 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.259962
  validation loss:		0.372177
  validation accuracy:		89.13 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.256882
  validation loss:		0.374883
  validation accuracy:		88.59 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.260744
  validation loss:		0.373265
  validation accuracy:		89.57 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.268318
  validation loss:		0.378377
  validation accuracy:		88.59 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.263744
  validation loss:		0.405689
  validation accuracy:		87.93 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.264665
  validation loss:		0.381016
  validation accuracy:		88.70 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.259671
  validation loss:		0.364629
  validation accuracy:		89.24 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.258197
  validation loss:		0.397201
  validation accuracy:		88.48 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.258472
  validation loss:		0.373618
  validation accuracy:		88.91 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.259267
  validation loss:		0.388820
  validation accuracy:		88.15 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.259838
  validation loss:		0.380823
  validation accuracy:		88.70 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.258671
  validation loss:		0.382541
  validation accuracy:		88.48 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.260497
  validation loss:		0.384494
  validation accuracy:		88.59 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.261709
  validation loss:		0.370579
  validation accuracy:		88.59 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.266623
  validation loss:		0.368686
  validation accuracy:		89.24 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.260354
  validation loss:		0.400962
  validation accuracy:		88.26 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.258186
  validation loss:		0.381739
  validation accuracy:		88.91 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.267666
  validation loss:		0.377055
  validation accuracy:		88.91 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.262992
  validation loss:		0.392218
  validation accuracy:		88.04 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.263810
  validation loss:		0.373373
  validation accuracy:		88.91 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.262498
  validation loss:		0.378368
  validation accuracy:		88.80 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.260939
  validation loss:		0.376807
  validation accuracy:		88.80 %
Epoch 1914 of 2000 took 0.097s
  training loss:		0.264269
  validation loss:		0.384825
  validation accuracy:		89.02 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.253401
  validation loss:		0.377562
  validation accuracy:		88.70 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.261069
  validation loss:		0.386901
  validation accuracy:		88.91 %
Epoch 1917 of 2000 took 0.103s
  training loss:		0.255671
  validation loss:		0.414543
  validation accuracy:		87.93 %
Epoch 1918 of 2000 took 0.106s
  training loss:		0.251764
  validation loss:		0.384869
  validation accuracy:		88.48 %
Epoch 1919 of 2000 took 0.107s
  training loss:		0.259930
  validation loss:		0.371288
  validation accuracy:		88.59 %
Epoch 1920 of 2000 took 0.106s
  training loss:		0.257289
  validation loss:		0.408651
  validation accuracy:		87.72 %
Epoch 1921 of 2000 took 0.099s
  training loss:		0.260819
  validation loss:		0.385418
  validation accuracy:		88.80 %
Epoch 1922 of 2000 took 0.099s
  training loss:		0.259557
  validation loss:		0.380718
  validation accuracy:		88.59 %
Epoch 1923 of 2000 took 0.099s
  training loss:		0.263134
  validation loss:		0.387674
  validation accuracy:		88.80 %
Epoch 1924 of 2000 took 0.099s
  training loss:		0.260793
  validation loss:		0.376503
  validation accuracy:		89.02 %
Epoch 1925 of 2000 took 0.099s
  training loss:		0.262055
  validation loss:		0.375082
  validation accuracy:		88.59 %
Epoch 1926 of 2000 took 0.099s
  training loss:		0.260610
  validation loss:		0.395208
  validation accuracy:		88.91 %
Epoch 1927 of 2000 took 0.099s
  training loss:		0.264607
  validation loss:		0.379537
  validation accuracy:		88.91 %
Epoch 1928 of 2000 took 0.099s
  training loss:		0.264349
  validation loss:		0.374771
  validation accuracy:		89.02 %
Epoch 1929 of 2000 took 0.099s
  training loss:		0.269460
  validation loss:		0.410782
  validation accuracy:		88.04 %
Epoch 1930 of 2000 took 0.099s
  training loss:		0.263620
  validation loss:		0.382056
  validation accuracy:		89.35 %
Epoch 1931 of 2000 took 0.099s
  training loss:		0.261759
  validation loss:		0.378098
  validation accuracy:		88.59 %
Epoch 1932 of 2000 took 0.099s
  training loss:		0.251870
  validation loss:		0.383822
  validation accuracy:		88.80 %
Epoch 1933 of 2000 took 0.099s
  training loss:		0.257166
  validation loss:		0.375576
  validation accuracy:		88.48 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.254402
  validation loss:		0.376047
  validation accuracy:		89.24 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.256185
  validation loss:		0.371987
  validation accuracy:		89.35 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.267524
  validation loss:		0.394096
  validation accuracy:		89.02 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.258490
  validation loss:		0.378990
  validation accuracy:		88.80 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.262500
  validation loss:		0.365367
  validation accuracy:		89.46 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.256696
  validation loss:		0.403779
  validation accuracy:		87.83 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.262074
  validation loss:		0.371941
  validation accuracy:		89.35 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.257995
  validation loss:		0.384670
  validation accuracy:		89.13 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.261686
  validation loss:		0.401069
  validation accuracy:		87.83 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.258927
  validation loss:		0.367747
  validation accuracy:		89.02 %
Epoch 1944 of 2000 took 0.097s
  training loss:		0.263636
  validation loss:		0.382048
  validation accuracy:		88.80 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.259399
  validation loss:		0.388119
  validation accuracy:		88.37 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.267699
  validation loss:		0.372882
  validation accuracy:		88.70 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.258433
  validation loss:		0.380949
  validation accuracy:		88.59 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.266428
  validation loss:		0.385459
  validation accuracy:		89.13 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.257600
  validation loss:		0.378243
  validation accuracy:		89.24 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.254247
  validation loss:		0.382484
  validation accuracy:		88.70 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.256111
  validation loss:		0.372465
  validation accuracy:		89.02 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.259574
  validation loss:		0.377776
  validation accuracy:		88.80 %
Epoch 1953 of 2000 took 0.097s
  training loss:		0.262501
  validation loss:		0.386857
  validation accuracy:		89.13 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.259589
  validation loss:		0.378864
  validation accuracy:		89.46 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.258842
  validation loss:		0.369680
  validation accuracy:		89.02 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.260359
  validation loss:		0.375074
  validation accuracy:		89.13 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.252760
  validation loss:		0.372064
  validation accuracy:		89.35 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.256360
  validation loss:		0.378555
  validation accuracy:		88.91 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.262331
  validation loss:		0.381301
  validation accuracy:		88.80 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.253083
  validation loss:		0.390813
  validation accuracy:		88.37 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.258649
  validation loss:		0.402608
  validation accuracy:		89.02 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.256854
  validation loss:		0.373004
  validation accuracy:		89.13 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.255569
  validation loss:		0.386481
  validation accuracy:		88.15 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.263121
  validation loss:		0.378884
  validation accuracy:		89.13 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.265042
  validation loss:		0.376760
  validation accuracy:		88.80 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.260929
  validation loss:		0.382519
  validation accuracy:		89.24 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.262249
  validation loss:		0.377429
  validation accuracy:		88.70 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.257395
  validation loss:		0.375166
  validation accuracy:		89.46 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.263815
  validation loss:		0.391425
  validation accuracy:		88.26 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.256457
  validation loss:		0.376012
  validation accuracy:		88.91 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.259316
  validation loss:		0.369330
  validation accuracy:		89.02 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.256690
  validation loss:		0.386618
  validation accuracy:		89.02 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.267362
  validation loss:		0.395130
  validation accuracy:		89.13 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.256154
  validation loss:		0.369536
  validation accuracy:		88.91 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.263762
  validation loss:		0.390604
  validation accuracy:		87.93 %
Epoch 1976 of 2000 took 0.097s
  training loss:		0.255312
  validation loss:		0.389025
  validation accuracy:		88.80 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.253363
  validation loss:		0.393817
  validation accuracy:		88.37 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.259435
  validation loss:		0.377541
  validation accuracy:		89.02 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.263202
  validation loss:		0.380551
  validation accuracy:		89.35 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.267603
  validation loss:		0.375431
  validation accuracy:		88.80 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.261887
  validation loss:		0.376834
  validation accuracy:		88.80 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.262003
  validation loss:		0.381464
  validation accuracy:		88.80 %
Epoch 1983 of 2000 took 0.097s
  training loss:		0.267699
  validation loss:		0.379947
  validation accuracy:		89.13 %
Epoch 1984 of 2000 took 0.097s
  training loss:		0.260549
  validation loss:		0.368413
  validation accuracy:		88.91 %
Epoch 1985 of 2000 took 0.097s
  training loss:		0.261437
  validation loss:		0.404146
  validation accuracy:		88.91 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.261069
  validation loss:		0.397126
  validation accuracy:		88.80 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.265031
  validation loss:		0.417230
  validation accuracy:		87.83 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.266746
  validation loss:		0.383286
  validation accuracy:		89.13 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.263545
  validation loss:		0.386019
  validation accuracy:		88.70 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.261963
  validation loss:		0.384358
  validation accuracy:		88.15 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.257426
  validation loss:		0.387127
  validation accuracy:		88.15 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.257423
  validation loss:		0.388382
  validation accuracy:		88.26 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.256447
  validation loss:		0.382188
  validation accuracy:		88.91 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.261933
  validation loss:		0.391312
  validation accuracy:		88.26 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.255157
  validation loss:		0.368546
  validation accuracy:		89.13 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.255665
  validation loss:		0.375581
  validation accuracy:		88.91 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.257942
  validation loss:		0.374657
  validation accuracy:		89.13 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.263051
  validation loss:		0.391729
  validation accuracy:		88.59 %
Epoch 1999 of 2000 took 0.097s
  training loss:		0.259933
  validation loss:		0.368518
  validation accuracy:		88.91 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.259283
  validation loss:		0.390074
  validation accuracy:		88.59 %
Final results:
  test loss:			0.738445
  test accuracy:		79.94 %
