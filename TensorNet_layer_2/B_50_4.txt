Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.042s
  training loss:		2.933009
  validation loss:		2.787501
  validation accuracy:		14.13 %
Epoch 2 of 2000 took 0.042s
  training loss:		2.708445
  validation loss:		2.480341
  validation accuracy:		13.80 %
Epoch 3 of 2000 took 0.041s
  training loss:		2.487052
  validation loss:		2.273478
  validation accuracy:		19.89 %
Epoch 4 of 2000 took 0.039s
  training loss:		2.341917
  validation loss:		2.230448
  validation accuracy:		18.80 %
Epoch 5 of 2000 took 0.039s
  training loss:		2.283558
  validation loss:		2.227916
  validation accuracy:		32.50 %
Epoch 6 of 2000 took 0.038s
  training loss:		2.254775
  validation loss:		2.184019
  validation accuracy:		34.13 %
Epoch 7 of 2000 took 0.038s
  training loss:		2.236065
  validation loss:		2.172479
  validation accuracy:		47.61 %
Epoch 8 of 2000 took 0.038s
  training loss:		2.217317
  validation loss:		2.154632
  validation accuracy:		55.98 %
Epoch 9 of 2000 took 0.038s
  training loss:		2.196267
  validation loss:		2.123054
  validation accuracy:		49.78 %
Epoch 10 of 2000 took 0.038s
  training loss:		2.177204
  validation loss:		2.112789
  validation accuracy:		52.28 %
Epoch 11 of 2000 took 0.039s
  training loss:		2.152303
  validation loss:		2.074677
  validation accuracy:		63.91 %
Epoch 12 of 2000 took 0.039s
  training loss:		2.119225
  validation loss:		2.040879
  validation accuracy:		60.11 %
Epoch 13 of 2000 took 0.039s
  training loss:		2.086135
  validation loss:		1.999694
  validation accuracy:		59.13 %
Epoch 14 of 2000 took 0.038s
  training loss:		2.045724
  validation loss:		1.959968
  validation accuracy:		70.87 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.995156
  validation loss:		1.896681
  validation accuracy:		71.30 %
Epoch 16 of 2000 took 0.039s
  training loss:		1.937686
  validation loss:		1.831010
  validation accuracy:		74.13 %
Epoch 17 of 2000 took 0.039s
  training loss:		1.865927
  validation loss:		1.754099
  validation accuracy:		71.85 %
Epoch 18 of 2000 took 0.039s
  training loss:		1.792771
  validation loss:		1.671102
  validation accuracy:		74.46 %
Epoch 19 of 2000 took 0.037s
  training loss:		1.705367
  validation loss:		1.563512
  validation accuracy:		76.96 %
Epoch 20 of 2000 took 0.036s
  training loss:		1.618785
  validation loss:		1.483036
  validation accuracy:		80.00 %
Epoch 21 of 2000 took 0.036s
  training loss:		1.525568
  validation loss:		1.388299
  validation accuracy:		84.46 %
Epoch 22 of 2000 took 0.036s
  training loss:		1.435704
  validation loss:		1.297143
  validation accuracy:		84.24 %
Epoch 23 of 2000 took 0.036s
  training loss:		1.348881
  validation loss:		1.199821
  validation accuracy:		85.22 %
Epoch 24 of 2000 took 0.036s
  training loss:		1.268636
  validation loss:		1.125618
  validation accuracy:		85.54 %
Epoch 25 of 2000 took 0.036s
  training loss:		1.192902
  validation loss:		1.054822
  validation accuracy:		86.41 %
Epoch 26 of 2000 took 0.037s
  training loss:		1.120564
  validation loss:		0.979766
  validation accuracy:		86.74 %
Epoch 27 of 2000 took 0.036s
  training loss:		1.055536
  validation loss:		0.926064
  validation accuracy:		87.07 %
Epoch 28 of 2000 took 0.036s
  training loss:		0.991344
  validation loss:		0.855428
  validation accuracy:		87.39 %
Epoch 29 of 2000 took 0.037s
  training loss:		0.932644
  validation loss:		0.809527
  validation accuracy:		88.15 %
Epoch 30 of 2000 took 0.038s
  training loss:		0.882757
  validation loss:		0.758594
  validation accuracy:		87.83 %
Epoch 31 of 2000 took 0.037s
  training loss:		0.828423
  validation loss:		0.713237
  validation accuracy:		87.93 %
Epoch 32 of 2000 took 0.037s
  training loss:		0.782810
  validation loss:		0.671684
  validation accuracy:		88.48 %
Epoch 33 of 2000 took 0.038s
  training loss:		0.737745
  validation loss:		0.641979
  validation accuracy:		88.59 %
Epoch 34 of 2000 took 0.037s
  training loss:		0.700127
  validation loss:		0.600114
  validation accuracy:		89.02 %
Epoch 35 of 2000 took 0.037s
  training loss:		0.663167
  validation loss:		0.557489
  validation accuracy:		89.35 %
Epoch 36 of 2000 took 0.037s
  training loss:		0.629424
  validation loss:		0.547242
  validation accuracy:		90.33 %
Epoch 37 of 2000 took 0.037s
  training loss:		0.597682
  validation loss:		0.520835
  validation accuracy:		88.37 %
Epoch 38 of 2000 took 0.038s
  training loss:		0.574583
  validation loss:		0.490468
  validation accuracy:		89.89 %
Epoch 39 of 2000 took 0.038s
  training loss:		0.542872
  validation loss:		0.478033
  validation accuracy:		90.33 %
Epoch 40 of 2000 took 0.037s
  training loss:		0.521940
  validation loss:		0.454093
  validation accuracy:		90.33 %
Epoch 41 of 2000 took 0.036s
  training loss:		0.504204
  validation loss:		0.443692
  validation accuracy:		91.20 %
Epoch 42 of 2000 took 0.037s
  training loss:		0.486652
  validation loss:		0.416480
  validation accuracy:		91.85 %
Epoch 43 of 2000 took 0.037s
  training loss:		0.471872
  validation loss:		0.414270
  validation accuracy:		90.22 %
Epoch 44 of 2000 took 0.036s
  training loss:		0.452164
  validation loss:		0.398397
  validation accuracy:		91.85 %
Epoch 45 of 2000 took 0.036s
  training loss:		0.438302
  validation loss:		0.382712
  validation accuracy:		92.07 %
Epoch 46 of 2000 took 0.036s
  training loss:		0.421150
  validation loss:		0.385331
  validation accuracy:		91.20 %
Epoch 47 of 2000 took 0.037s
  training loss:		0.416474
  validation loss:		0.367477
  validation accuracy:		92.07 %
Epoch 48 of 2000 took 0.036s
  training loss:		0.395064
  validation loss:		0.363562
  validation accuracy:		91.30 %
Epoch 49 of 2000 took 0.036s
  training loss:		0.389033
  validation loss:		0.340361
  validation accuracy:		92.72 %
Epoch 50 of 2000 took 0.036s
  training loss:		0.379539
  validation loss:		0.355513
  validation accuracy:		91.20 %
Epoch 51 of 2000 took 0.037s
  training loss:		0.369725
  validation loss:		0.342916
  validation accuracy:		92.07 %
Epoch 52 of 2000 took 0.036s
  training loss:		0.359644
  validation loss:		0.336518
  validation accuracy:		92.28 %
Epoch 53 of 2000 took 0.037s
  training loss:		0.359183
  validation loss:		0.326522
  validation accuracy:		92.50 %
Epoch 54 of 2000 took 0.036s
  training loss:		0.343894
  validation loss:		0.312909
  validation accuracy:		92.83 %
Epoch 55 of 2000 took 0.036s
  training loss:		0.338801
  validation loss:		0.317111
  validation accuracy:		92.39 %
Epoch 56 of 2000 took 0.036s
  training loss:		0.330259
  validation loss:		0.311961
  validation accuracy:		92.07 %
Epoch 57 of 2000 took 0.037s
  training loss:		0.328757
  validation loss:		0.298107
  validation accuracy:		93.04 %
Epoch 58 of 2000 took 0.039s
  training loss:		0.320060
  validation loss:		0.304805
  validation accuracy:		92.28 %
Epoch 59 of 2000 took 0.040s
  training loss:		0.312895
  validation loss:		0.287653
  validation accuracy:		93.15 %
Epoch 60 of 2000 took 0.038s
  training loss:		0.306914
  validation loss:		0.288058
  validation accuracy:		93.26 %
Epoch 61 of 2000 took 0.037s
  training loss:		0.298074
  validation loss:		0.279825
  validation accuracy:		93.48 %
Epoch 62 of 2000 took 0.038s
  training loss:		0.295780
  validation loss:		0.274574
  validation accuracy:		93.48 %
Epoch 63 of 2000 took 0.039s
  training loss:		0.288930
  validation loss:		0.277429
  validation accuracy:		93.48 %
Epoch 64 of 2000 took 0.040s
  training loss:		0.286611
  validation loss:		0.276995
  validation accuracy:		93.04 %
Epoch 65 of 2000 took 0.039s
  training loss:		0.281052
  validation loss:		0.267440
  validation accuracy:		93.70 %
Epoch 66 of 2000 took 0.038s
  training loss:		0.281763
  validation loss:		0.270423
  validation accuracy:		93.48 %
Epoch 67 of 2000 took 0.038s
  training loss:		0.274809
  validation loss:		0.272826
  validation accuracy:		92.93 %
Epoch 68 of 2000 took 0.039s
  training loss:		0.269186
  validation loss:		0.262231
  validation accuracy:		93.80 %
Epoch 69 of 2000 took 0.039s
  training loss:		0.267594
  validation loss:		0.258959
  validation accuracy:		93.48 %
Epoch 70 of 2000 took 0.039s
  training loss:		0.259380
  validation loss:		0.251326
  validation accuracy:		94.13 %
Epoch 71 of 2000 took 0.039s
  training loss:		0.256021
  validation loss:		0.259576
  validation accuracy:		93.37 %
Epoch 72 of 2000 took 0.038s
  training loss:		0.251372
  validation loss:		0.255611
  validation accuracy:		93.59 %
Epoch 73 of 2000 took 0.039s
  training loss:		0.252812
  validation loss:		0.247659
  validation accuracy:		94.13 %
Epoch 74 of 2000 took 0.039s
  training loss:		0.250031
  validation loss:		0.250458
  validation accuracy:		93.80 %
Epoch 75 of 2000 took 0.039s
  training loss:		0.245517
  validation loss:		0.251429
  validation accuracy:		93.26 %
Epoch 76 of 2000 took 0.039s
  training loss:		0.237969
  validation loss:		0.247048
  validation accuracy:		93.70 %
Epoch 77 of 2000 took 0.038s
  training loss:		0.242088
  validation loss:		0.250355
  validation accuracy:		93.59 %
Epoch 78 of 2000 took 0.038s
  training loss:		0.235334
  validation loss:		0.237723
  validation accuracy:		94.13 %
Epoch 79 of 2000 took 0.038s
  training loss:		0.235203
  validation loss:		0.243491
  validation accuracy:		93.70 %
Epoch 80 of 2000 took 0.038s
  training loss:		0.233947
  validation loss:		0.239631
  validation accuracy:		93.48 %
Epoch 81 of 2000 took 0.037s
  training loss:		0.223082
  validation loss:		0.246301
  validation accuracy:		93.15 %
Epoch 82 of 2000 took 0.037s
  training loss:		0.223394
  validation loss:		0.240107
  validation accuracy:		93.80 %
Epoch 83 of 2000 took 0.037s
  training loss:		0.219171
  validation loss:		0.245836
  validation accuracy:		93.26 %
Epoch 84 of 2000 took 0.037s
  training loss:		0.220133
  validation loss:		0.235505
  validation accuracy:		93.80 %
Epoch 85 of 2000 took 0.037s
  training loss:		0.222357
  validation loss:		0.241994
  validation accuracy:		93.59 %
Epoch 86 of 2000 took 0.036s
  training loss:		0.216526
  validation loss:		0.237533
  validation accuracy:		93.91 %
Epoch 87 of 2000 took 0.036s
  training loss:		0.214248
  validation loss:		0.227552
  validation accuracy:		94.35 %
Epoch 88 of 2000 took 0.036s
  training loss:		0.212895
  validation loss:		0.238205
  validation accuracy:		93.37 %
Epoch 89 of 2000 took 0.036s
  training loss:		0.213180
  validation loss:		0.217611
  validation accuracy:		94.46 %
Epoch 90 of 2000 took 0.036s
  training loss:		0.212482
  validation loss:		0.232966
  validation accuracy:		93.80 %
Epoch 91 of 2000 took 0.036s
  training loss:		0.209527
  validation loss:		0.237029
  validation accuracy:		93.15 %
Epoch 92 of 2000 took 0.036s
  training loss:		0.204246
  validation loss:		0.223771
  validation accuracy:		94.24 %
Epoch 93 of 2000 took 0.037s
  training loss:		0.203726
  validation loss:		0.220319
  validation accuracy:		94.57 %
Epoch 94 of 2000 took 0.036s
  training loss:		0.203791
  validation loss:		0.227008
  validation accuracy:		94.24 %
Epoch 95 of 2000 took 0.037s
  training loss:		0.198080
  validation loss:		0.223842
  validation accuracy:		94.35 %
Epoch 96 of 2000 took 0.038s
  training loss:		0.197621
  validation loss:		0.222073
  validation accuracy:		94.02 %
Epoch 97 of 2000 took 0.037s
  training loss:		0.197379
  validation loss:		0.233481
  validation accuracy:		93.70 %
Epoch 98 of 2000 took 0.039s
  training loss:		0.196911
  validation loss:		0.229116
  validation accuracy:		93.80 %
Epoch 99 of 2000 took 0.040s
  training loss:		0.193808
  validation loss:		0.213092
  validation accuracy:		94.57 %
Epoch 100 of 2000 took 0.038s
  training loss:		0.192511
  validation loss:		0.224820
  validation accuracy:		93.91 %
Epoch 101 of 2000 took 0.040s
  training loss:		0.194078
  validation loss:		0.222684
  validation accuracy:		94.13 %
Epoch 102 of 2000 took 0.040s
  training loss:		0.189495
  validation loss:		0.226413
  validation accuracy:		93.91 %
Epoch 103 of 2000 took 0.038s
  training loss:		0.187251
  validation loss:		0.210852
  validation accuracy:		94.57 %
Epoch 104 of 2000 took 0.038s
  training loss:		0.184215
  validation loss:		0.216025
  validation accuracy:		94.57 %
Epoch 105 of 2000 took 0.038s
  training loss:		0.185460
  validation loss:		0.214493
  validation accuracy:		94.35 %
Epoch 106 of 2000 took 0.038s
  training loss:		0.185318
  validation loss:		0.225236
  validation accuracy:		94.13 %
Epoch 107 of 2000 took 0.038s
  training loss:		0.181248
  validation loss:		0.225722
  validation accuracy:		94.02 %
Epoch 108 of 2000 took 0.038s
  training loss:		0.182440
  validation loss:		0.216334
  validation accuracy:		94.24 %
Epoch 109 of 2000 took 0.038s
  training loss:		0.179092
  validation loss:		0.220727
  validation accuracy:		94.24 %
Epoch 110 of 2000 took 0.038s
  training loss:		0.177230
  validation loss:		0.211416
  validation accuracy:		94.57 %
Epoch 111 of 2000 took 0.038s
  training loss:		0.176372
  validation loss:		0.224069
  validation accuracy:		93.91 %
Epoch 112 of 2000 took 0.038s
  training loss:		0.176617
  validation loss:		0.212182
  validation accuracy:		94.13 %
Epoch 113 of 2000 took 0.038s
  training loss:		0.172576
  validation loss:		0.222235
  validation accuracy:		93.70 %
Epoch 114 of 2000 took 0.038s
  training loss:		0.174667
  validation loss:		0.223055
  validation accuracy:		94.02 %
Epoch 115 of 2000 took 0.038s
  training loss:		0.172417
  validation loss:		0.225519
  validation accuracy:		93.91 %
Epoch 116 of 2000 took 0.038s
  training loss:		0.165838
  validation loss:		0.221828
  validation accuracy:		93.80 %
Epoch 117 of 2000 took 0.038s
  training loss:		0.171653
  validation loss:		0.220555
  validation accuracy:		93.48 %
Epoch 118 of 2000 took 0.038s
  training loss:		0.166664
  validation loss:		0.206332
  validation accuracy:		94.57 %
Epoch 119 of 2000 took 0.038s
  training loss:		0.168294
  validation loss:		0.214488
  validation accuracy:		94.46 %
Epoch 120 of 2000 took 0.038s
  training loss:		0.167111
  validation loss:		0.201895
  validation accuracy:		94.57 %
Epoch 121 of 2000 took 0.038s
  training loss:		0.164247
  validation loss:		0.218409
  validation accuracy:		94.02 %
Epoch 122 of 2000 took 0.038s
  training loss:		0.162618
  validation loss:		0.219520
  validation accuracy:		94.13 %
Epoch 123 of 2000 took 0.038s
  training loss:		0.164766
  validation loss:		0.218631
  validation accuracy:		94.35 %
Epoch 124 of 2000 took 0.038s
  training loss:		0.162084
  validation loss:		0.214527
  validation accuracy:		94.02 %
Epoch 125 of 2000 took 0.038s
  training loss:		0.160140
  validation loss:		0.198236
  validation accuracy:		94.78 %
Epoch 126 of 2000 took 0.038s
  training loss:		0.160885
  validation loss:		0.220764
  validation accuracy:		93.91 %
Epoch 127 of 2000 took 0.041s
  training loss:		0.160096
  validation loss:		0.211882
  validation accuracy:		94.57 %
Epoch 128 of 2000 took 0.038s
  training loss:		0.157870
  validation loss:		0.213879
  validation accuracy:		94.13 %
Epoch 129 of 2000 took 0.038s
  training loss:		0.156355
  validation loss:		0.225125
  validation accuracy:		93.80 %
Epoch 130 of 2000 took 0.038s
  training loss:		0.157421
  validation loss:		0.220178
  validation accuracy:		93.91 %
Epoch 131 of 2000 took 0.038s
  training loss:		0.158672
  validation loss:		0.212148
  validation accuracy:		94.24 %
Epoch 132 of 2000 took 0.038s
  training loss:		0.156617
  validation loss:		0.208873
  validation accuracy:		94.24 %
Epoch 133 of 2000 took 0.038s
  training loss:		0.155591
  validation loss:		0.205404
  validation accuracy:		94.67 %
Epoch 134 of 2000 took 0.038s
  training loss:		0.153984
  validation loss:		0.211488
  validation accuracy:		94.67 %
Epoch 135 of 2000 took 0.038s
  training loss:		0.147680
  validation loss:		0.202890
  validation accuracy:		94.46 %
Epoch 136 of 2000 took 0.038s
  training loss:		0.152143
  validation loss:		0.215884
  validation accuracy:		94.24 %
Epoch 137 of 2000 took 0.038s
  training loss:		0.149910
  validation loss:		0.207343
  validation accuracy:		94.46 %
Epoch 138 of 2000 took 0.038s
  training loss:		0.148877
  validation loss:		0.226346
  validation accuracy:		93.91 %
Epoch 139 of 2000 took 0.038s
  training loss:		0.147156
  validation loss:		0.209708
  validation accuracy:		94.46 %
Epoch 140 of 2000 took 0.038s
  training loss:		0.147903
  validation loss:		0.215982
  validation accuracy:		94.46 %
Epoch 141 of 2000 took 0.038s
  training loss:		0.151154
  validation loss:		0.219321
  validation accuracy:		93.91 %
Epoch 142 of 2000 took 0.038s
  training loss:		0.147014
  validation loss:		0.210768
  validation accuracy:		94.24 %
Epoch 143 of 2000 took 0.038s
  training loss:		0.146838
  validation loss:		0.206015
  validation accuracy:		94.35 %
Epoch 144 of 2000 took 0.038s
  training loss:		0.144927
  validation loss:		0.208811
  validation accuracy:		94.24 %
Epoch 145 of 2000 took 0.038s
  training loss:		0.147136
  validation loss:		0.209563
  validation accuracy:		94.67 %
Epoch 146 of 2000 took 0.038s
  training loss:		0.137736
  validation loss:		0.221273
  validation accuracy:		93.91 %
Epoch 147 of 2000 took 0.038s
  training loss:		0.146801
  validation loss:		0.222749
  validation accuracy:		94.24 %
Epoch 148 of 2000 took 0.038s
  training loss:		0.139731
  validation loss:		0.208927
  validation accuracy:		94.57 %
Epoch 149 of 2000 took 0.038s
  training loss:		0.143036
  validation loss:		0.206261
  validation accuracy:		94.89 %
Epoch 150 of 2000 took 0.038s
  training loss:		0.143619
  validation loss:		0.210326
  validation accuracy:		94.46 %
Epoch 151 of 2000 took 0.038s
  training loss:		0.136889
  validation loss:		0.209325
  validation accuracy:		94.78 %
Epoch 152 of 2000 took 0.038s
  training loss:		0.141459
  validation loss:		0.214694
  validation accuracy:		94.57 %
Epoch 153 of 2000 took 0.038s
  training loss:		0.136670
  validation loss:		0.216744
  validation accuracy:		94.24 %
Epoch 154 of 2000 took 0.038s
  training loss:		0.136699
  validation loss:		0.202342
  validation accuracy:		95.00 %
Epoch 155 of 2000 took 0.038s
  training loss:		0.138869
  validation loss:		0.221442
  validation accuracy:		94.24 %
Epoch 156 of 2000 took 0.038s
  training loss:		0.137374
  validation loss:		0.215449
  validation accuracy:		94.35 %
Epoch 157 of 2000 took 0.038s
  training loss:		0.137811
  validation loss:		0.209102
  validation accuracy:		94.78 %
Epoch 158 of 2000 took 0.038s
  training loss:		0.138289
  validation loss:		0.210686
  validation accuracy:		94.57 %
Epoch 159 of 2000 took 0.038s
  training loss:		0.134625
  validation loss:		0.213992
  validation accuracy:		94.13 %
Epoch 160 of 2000 took 0.038s
  training loss:		0.135125
  validation loss:		0.229104
  validation accuracy:		93.80 %
Epoch 161 of 2000 took 0.038s
  training loss:		0.133712
  validation loss:		0.212743
  validation accuracy:		94.67 %
Epoch 162 of 2000 took 0.038s
  training loss:		0.133577
  validation loss:		0.212639
  validation accuracy:		94.67 %
Epoch 163 of 2000 took 0.038s
  training loss:		0.134323
  validation loss:		0.219197
  validation accuracy:		94.46 %
Epoch 164 of 2000 took 0.038s
  training loss:		0.134661
  validation loss:		0.228722
  validation accuracy:		94.13 %
Epoch 165 of 2000 took 0.038s
  training loss:		0.132528
  validation loss:		0.217606
  validation accuracy:		94.24 %
Epoch 166 of 2000 took 0.038s
  training loss:		0.131049
  validation loss:		0.208325
  validation accuracy:		94.67 %
Epoch 167 of 2000 took 0.038s
  training loss:		0.131614
  validation loss:		0.206652
  validation accuracy:		94.57 %
Epoch 168 of 2000 took 0.038s
  training loss:		0.129148
  validation loss:		0.216331
  validation accuracy:		94.46 %
Epoch 169 of 2000 took 0.038s
  training loss:		0.131207
  validation loss:		0.219170
  validation accuracy:		93.80 %
Epoch 170 of 2000 took 0.038s
  training loss:		0.130811
  validation loss:		0.206933
  validation accuracy:		94.78 %
Epoch 171 of 2000 took 0.038s
  training loss:		0.131718
  validation loss:		0.234053
  validation accuracy:		94.24 %
Epoch 172 of 2000 took 0.039s
  training loss:		0.126398
  validation loss:		0.214536
  validation accuracy:		94.46 %
Epoch 173 of 2000 took 0.038s
  training loss:		0.128516
  validation loss:		0.203024
  validation accuracy:		94.78 %
Epoch 174 of 2000 took 0.038s
  training loss:		0.125045
  validation loss:		0.209929
  validation accuracy:		94.78 %
Epoch 175 of 2000 took 0.038s
  training loss:		0.122756
  validation loss:		0.213208
  validation accuracy:		94.67 %
Epoch 176 of 2000 took 0.038s
  training loss:		0.124842
  validation loss:		0.212249
  validation accuracy:		94.67 %
Epoch 177 of 2000 took 0.038s
  training loss:		0.123471
  validation loss:		0.206517
  validation accuracy:		94.89 %
Epoch 178 of 2000 took 0.038s
  training loss:		0.124147
  validation loss:		0.207154
  validation accuracy:		94.67 %
Epoch 179 of 2000 took 0.038s
  training loss:		0.122878
  validation loss:		0.213790
  validation accuracy:		94.89 %
Epoch 180 of 2000 took 0.038s
  training loss:		0.121398
  validation loss:		0.208474
  validation accuracy:		94.89 %
Epoch 181 of 2000 took 0.038s
  training loss:		0.124310
  validation loss:		0.243909
  validation accuracy:		93.59 %
Epoch 182 of 2000 took 0.038s
  training loss:		0.121722
  validation loss:		0.205790
  validation accuracy:		94.89 %
Epoch 183 of 2000 took 0.038s
  training loss:		0.117970
  validation loss:		0.208871
  validation accuracy:		94.78 %
Epoch 184 of 2000 took 0.038s
  training loss:		0.122263
  validation loss:		0.218082
  validation accuracy:		94.57 %
Epoch 185 of 2000 took 0.040s
  training loss:		0.119550
  validation loss:		0.208257
  validation accuracy:		94.67 %
Epoch 186 of 2000 took 0.038s
  training loss:		0.119056
  validation loss:		0.200520
  validation accuracy:		95.00 %
Epoch 187 of 2000 took 0.042s
  training loss:		0.118905
  validation loss:		0.216622
  validation accuracy:		94.78 %
Epoch 188 of 2000 took 0.091s
  training loss:		0.120161
  validation loss:		0.206387
  validation accuracy:		94.67 %
Epoch 189 of 2000 took 0.092s
  training loss:		0.114694
  validation loss:		0.217429
  validation accuracy:		94.57 %
Epoch 190 of 2000 took 0.064s
  training loss:		0.116423
  validation loss:		0.234448
  validation accuracy:		94.13 %
Epoch 191 of 2000 took 0.088s
  training loss:		0.120287
  validation loss:		0.213711
  validation accuracy:		94.67 %
Epoch 192 of 2000 took 0.130s
  training loss:		0.114280
  validation loss:		0.206344
  validation accuracy:		94.89 %
Epoch 193 of 2000 took 0.057s
  training loss:		0.115546
  validation loss:		0.213801
  validation accuracy:		94.67 %
Epoch 194 of 2000 took 0.102s
  training loss:		0.115266
  validation loss:		0.221160
  validation accuracy:		94.46 %
Epoch 195 of 2000 took 0.088s
  training loss:		0.117191
  validation loss:		0.223184
  validation accuracy:		94.46 %
Epoch 196 of 2000 took 0.083s
  training loss:		0.113816
  validation loss:		0.221987
  validation accuracy:		94.24 %
Epoch 197 of 2000 took 0.099s
  training loss:		0.112711
  validation loss:		0.221657
  validation accuracy:		94.24 %
Epoch 198 of 2000 took 0.089s
  training loss:		0.115012
  validation loss:		0.223608
  validation accuracy:		94.46 %
Epoch 199 of 2000 took 0.099s
  training loss:		0.115322
  validation loss:		0.218786
  validation accuracy:		94.24 %
Epoch 200 of 2000 took 0.080s
  training loss:		0.111914
  validation loss:		0.218750
  validation accuracy:		94.67 %
Epoch 201 of 2000 took 0.056s
  training loss:		0.112595
  validation loss:		0.224378
  validation accuracy:		94.13 %
Epoch 202 of 2000 took 0.048s
  training loss:		0.112075
  validation loss:		0.231622
  validation accuracy:		94.46 %
Epoch 203 of 2000 took 0.048s
  training loss:		0.112329
  validation loss:		0.224275
  validation accuracy:		94.24 %
Epoch 204 of 2000 took 0.048s
  training loss:		0.112308
  validation loss:		0.204788
  validation accuracy:		95.22 %
Epoch 205 of 2000 took 0.048s
  training loss:		0.111897
  validation loss:		0.231126
  validation accuracy:		94.46 %
Epoch 206 of 2000 took 0.047s
  training loss:		0.111596
  validation loss:		0.223606
  validation accuracy:		94.46 %
Epoch 207 of 2000 took 0.064s
  training loss:		0.113718
  validation loss:		0.220333
  validation accuracy:		94.57 %
Epoch 208 of 2000 took 0.048s
  training loss:		0.109638
  validation loss:		0.219724
  validation accuracy:		94.35 %
Epoch 209 of 2000 took 0.047s
  training loss:		0.110591
  validation loss:		0.210152
  validation accuracy:		95.00 %
Epoch 210 of 2000 took 0.047s
  training loss:		0.111274
  validation loss:		0.206240
  validation accuracy:		95.00 %
Epoch 211 of 2000 took 0.065s
  training loss:		0.107490
  validation loss:		0.218938
  validation accuracy:		94.35 %
Epoch 212 of 2000 took 0.090s
  training loss:		0.111178
  validation loss:		0.213826
  validation accuracy:		94.57 %
Epoch 213 of 2000 took 0.045s
  training loss:		0.107023
  validation loss:		0.224057
  validation accuracy:		94.24 %
Epoch 214 of 2000 took 0.047s
  training loss:		0.110217
  validation loss:		0.223631
  validation accuracy:		94.46 %
Epoch 215 of 2000 took 0.047s
  training loss:		0.109561
  validation loss:		0.223944
  validation accuracy:		94.13 %
Epoch 216 of 2000 took 0.047s
  training loss:		0.107116
  validation loss:		0.219047
  validation accuracy:		94.67 %
Epoch 217 of 2000 took 0.048s
  training loss:		0.104456
  validation loss:		0.218634
  validation accuracy:		94.57 %
Epoch 218 of 2000 took 0.048s
  training loss:		0.107666
  validation loss:		0.216410
  validation accuracy:		94.57 %
Epoch 219 of 2000 took 0.047s
  training loss:		0.103522
  validation loss:		0.214138
  validation accuracy:		94.89 %
Epoch 220 of 2000 took 0.047s
  training loss:		0.104255
  validation loss:		0.214524
  validation accuracy:		94.67 %
Epoch 221 of 2000 took 0.048s
  training loss:		0.103053
  validation loss:		0.218282
  validation accuracy:		94.89 %
Epoch 222 of 2000 took 0.053s
  training loss:		0.106266
  validation loss:		0.226241
  validation accuracy:		94.35 %
Epoch 223 of 2000 took 0.047s
  training loss:		0.104805
  validation loss:		0.217936
  validation accuracy:		94.78 %
Epoch 224 of 2000 took 0.047s
  training loss:		0.104213
  validation loss:		0.221195
  validation accuracy:		94.57 %
Epoch 225 of 2000 took 0.047s
  training loss:		0.103653
  validation loss:		0.214633
  validation accuracy:		95.00 %
Epoch 226 of 2000 took 0.047s
  training loss:		0.102574
  validation loss:		0.215063
  validation accuracy:		94.57 %
Epoch 227 of 2000 took 0.051s
  training loss:		0.101312
  validation loss:		0.226021
  validation accuracy:		94.67 %
Epoch 228 of 2000 took 0.047s
  training loss:		0.100464
  validation loss:		0.215023
  validation accuracy:		95.11 %
Epoch 229 of 2000 took 0.047s
  training loss:		0.100895
  validation loss:		0.231334
  validation accuracy:		94.57 %
Epoch 230 of 2000 took 0.047s
  training loss:		0.102923
  validation loss:		0.209050
  validation accuracy:		94.67 %
Epoch 231 of 2000 took 0.047s
  training loss:		0.102669
  validation loss:		0.224026
  validation accuracy:		94.89 %
Epoch 232 of 2000 took 0.047s
  training loss:		0.099652
  validation loss:		0.227043
  validation accuracy:		94.46 %
Epoch 233 of 2000 took 0.047s
  training loss:		0.099079
  validation loss:		0.220930
  validation accuracy:		94.24 %
Epoch 234 of 2000 took 0.047s
  training loss:		0.101689
  validation loss:		0.231838
  validation accuracy:		94.13 %
Epoch 235 of 2000 took 0.048s
  training loss:		0.101066
  validation loss:		0.222641
  validation accuracy:		94.57 %
Epoch 236 of 2000 took 0.047s
  training loss:		0.100834
  validation loss:		0.224415
  validation accuracy:		94.67 %
Epoch 237 of 2000 took 0.047s
  training loss:		0.099152
  validation loss:		0.225014
  validation accuracy:		94.46 %
Epoch 238 of 2000 took 0.047s
  training loss:		0.099373
  validation loss:		0.226275
  validation accuracy:		94.57 %
Epoch 239 of 2000 took 0.047s
  training loss:		0.099817
  validation loss:		0.216802
  validation accuracy:		94.89 %
Epoch 240 of 2000 took 0.047s
  training loss:		0.096161
  validation loss:		0.228772
  validation accuracy:		94.13 %
Epoch 241 of 2000 took 0.047s
  training loss:		0.097151
  validation loss:		0.215373
  validation accuracy:		95.00 %
Epoch 242 of 2000 took 0.047s
  training loss:		0.097495
  validation loss:		0.234534
  validation accuracy:		93.91 %
Epoch 243 of 2000 took 0.048s
  training loss:		0.095988
  validation loss:		0.215609
  validation accuracy:		94.89 %
Epoch 244 of 2000 took 0.047s
  training loss:		0.094928
  validation loss:		0.226851
  validation accuracy:		94.46 %
Epoch 245 of 2000 took 0.047s
  training loss:		0.095690
  validation loss:		0.227046
  validation accuracy:		94.35 %
Epoch 246 of 2000 took 0.047s
  training loss:		0.094990
  validation loss:		0.221370
  validation accuracy:		94.78 %
Epoch 247 of 2000 took 0.047s
  training loss:		0.095834
  validation loss:		0.237915
  validation accuracy:		94.13 %
Epoch 248 of 2000 took 0.047s
  training loss:		0.095001
  validation loss:		0.222427
  validation accuracy:		94.67 %
Epoch 249 of 2000 took 0.047s
  training loss:		0.097085
  validation loss:		0.230204
  validation accuracy:		94.35 %
Epoch 250 of 2000 took 0.047s
  training loss:		0.095301
  validation loss:		0.217912
  validation accuracy:		94.46 %
Epoch 251 of 2000 took 0.048s
  training loss:		0.096974
  validation loss:		0.235246
  validation accuracy:		94.24 %
Epoch 252 of 2000 took 0.047s
  training loss:		0.092317
  validation loss:		0.240039
  validation accuracy:		94.24 %
Epoch 253 of 2000 took 0.047s
  training loss:		0.091858
  validation loss:		0.236052
  validation accuracy:		94.35 %
Epoch 254 of 2000 took 0.047s
  training loss:		0.093802
  validation loss:		0.236536
  validation accuracy:		94.02 %
Epoch 255 of 2000 took 0.047s
  training loss:		0.093283
  validation loss:		0.225388
  validation accuracy:		94.89 %
Epoch 256 of 2000 took 0.047s
  training loss:		0.090990
  validation loss:		0.233555
  validation accuracy:		94.35 %
Epoch 257 of 2000 took 0.047s
  training loss:		0.091325
  validation loss:		0.229109
  validation accuracy:		94.46 %
Epoch 258 of 2000 took 0.047s
  training loss:		0.090110
  validation loss:		0.233636
  validation accuracy:		94.13 %
Epoch 259 of 2000 took 0.047s
  training loss:		0.092951
  validation loss:		0.230249
  validation accuracy:		94.35 %
Epoch 260 of 2000 took 0.047s
  training loss:		0.092021
  validation loss:		0.226418
  validation accuracy:		94.57 %
Epoch 261 of 2000 took 0.047s
  training loss:		0.091732
  validation loss:		0.241701
  validation accuracy:		94.13 %
Epoch 262 of 2000 took 0.047s
  training loss:		0.088507
  validation loss:		0.225837
  validation accuracy:		94.67 %
Epoch 263 of 2000 took 0.047s
  training loss:		0.088493
  validation loss:		0.235968
  validation accuracy:		94.13 %
Epoch 264 of 2000 took 0.047s
  training loss:		0.088344
  validation loss:		0.231918
  validation accuracy:		94.46 %
Epoch 265 of 2000 took 0.047s
  training loss:		0.087543
  validation loss:		0.227722
  validation accuracy:		94.13 %
Epoch 266 of 2000 took 0.047s
  training loss:		0.086347
  validation loss:		0.235801
  validation accuracy:		94.46 %
Epoch 267 of 2000 took 0.047s
  training loss:		0.092309
  validation loss:		0.240725
  validation accuracy:		93.80 %
Epoch 268 of 2000 took 0.047s
  training loss:		0.090455
  validation loss:		0.228201
  validation accuracy:		94.57 %
Epoch 269 of 2000 took 0.047s
  training loss:		0.087501
  validation loss:		0.229308
  validation accuracy:		94.35 %
Epoch 270 of 2000 took 0.047s
  training loss:		0.087105
  validation loss:		0.227745
  validation accuracy:		94.57 %
Epoch 271 of 2000 took 0.047s
  training loss:		0.085198
  validation loss:		0.224276
  validation accuracy:		94.89 %
Epoch 272 of 2000 took 0.048s
  training loss:		0.090726
  validation loss:		0.230431
  validation accuracy:		94.46 %
Epoch 273 of 2000 took 0.047s
  training loss:		0.088644
  validation loss:		0.226262
  validation accuracy:		94.57 %
Epoch 274 of 2000 took 0.047s
  training loss:		0.088894
  validation loss:		0.236284
  validation accuracy:		93.91 %
Epoch 275 of 2000 took 0.047s
  training loss:		0.087749
  validation loss:		0.234003
  validation accuracy:		94.13 %
Epoch 276 of 2000 took 0.047s
  training loss:		0.084344
  validation loss:		0.225614
  validation accuracy:		94.24 %
Epoch 277 of 2000 took 0.047s
  training loss:		0.083162
  validation loss:		0.242250
  validation accuracy:		93.48 %
Epoch 278 of 2000 took 0.047s
  training loss:		0.086787
  validation loss:		0.236128
  validation accuracy:		93.59 %
Epoch 279 of 2000 took 0.047s
  training loss:		0.085641
  validation loss:		0.229120
  validation accuracy:		93.91 %
Epoch 280 of 2000 took 0.047s
  training loss:		0.083753
  validation loss:		0.231000
  validation accuracy:		94.13 %
Epoch 281 of 2000 took 0.047s
  training loss:		0.084541
  validation loss:		0.234644
  validation accuracy:		94.24 %
Epoch 282 of 2000 took 0.047s
  training loss:		0.080111
  validation loss:		0.244277
  validation accuracy:		94.24 %
Epoch 283 of 2000 took 0.047s
  training loss:		0.082287
  validation loss:		0.233880
  validation accuracy:		94.46 %
Epoch 284 of 2000 took 0.047s
  training loss:		0.084252
  validation loss:		0.240645
  validation accuracy:		93.91 %
Epoch 285 of 2000 took 0.047s
  training loss:		0.084265
  validation loss:		0.230738
  validation accuracy:		94.24 %
Epoch 286 of 2000 took 0.047s
  training loss:		0.086232
  validation loss:		0.240326
  validation accuracy:		94.13 %
Epoch 287 of 2000 took 0.047s
  training loss:		0.084206
  validation loss:		0.226290
  validation accuracy:		94.24 %
Epoch 288 of 2000 took 0.047s
  training loss:		0.082159
  validation loss:		0.243364
  validation accuracy:		93.80 %
Epoch 289 of 2000 took 0.046s
  training loss:		0.083422
  validation loss:		0.238638
  validation accuracy:		94.02 %
Epoch 290 of 2000 took 0.038s
  training loss:		0.082060
  validation loss:		0.231428
  validation accuracy:		94.13 %
Epoch 291 of 2000 took 0.038s
  training loss:		0.083060
  validation loss:		0.227062
  validation accuracy:		94.67 %
Epoch 292 of 2000 took 0.037s
  training loss:		0.081673
  validation loss:		0.236498
  validation accuracy:		94.24 %
Epoch 293 of 2000 took 0.037s
  training loss:		0.082080
  validation loss:		0.236484
  validation accuracy:		94.46 %
Epoch 294 of 2000 took 0.038s
  training loss:		0.084510
  validation loss:		0.233841
  validation accuracy:		94.46 %
Epoch 295 of 2000 took 0.038s
  training loss:		0.079857
  validation loss:		0.237740
  validation accuracy:		94.02 %
Epoch 296 of 2000 took 0.038s
  training loss:		0.080703
  validation loss:		0.248015
  validation accuracy:		93.59 %
Epoch 297 of 2000 took 0.039s
  training loss:		0.082597
  validation loss:		0.236199
  validation accuracy:		93.91 %
Epoch 298 of 2000 took 0.040s
  training loss:		0.078157
  validation loss:		0.235657
  validation accuracy:		94.57 %
Epoch 299 of 2000 took 0.039s
  training loss:		0.081611
  validation loss:		0.240759
  validation accuracy:		93.91 %
Epoch 300 of 2000 took 0.040s
  training loss:		0.079966
  validation loss:		0.249683
  validation accuracy:		93.59 %
Epoch 301 of 2000 took 0.040s
  training loss:		0.080268
  validation loss:		0.230156
  validation accuracy:		94.57 %
Epoch 302 of 2000 took 0.039s
  training loss:		0.076253
  validation loss:		0.237933
  validation accuracy:		94.02 %
Epoch 303 of 2000 took 0.039s
  training loss:		0.076591
  validation loss:		0.239085
  validation accuracy:		94.13 %
Epoch 304 of 2000 took 0.038s
  training loss:		0.080112
  validation loss:		0.242732
  validation accuracy:		94.02 %
Epoch 305 of 2000 took 0.038s
  training loss:		0.074622
  validation loss:		0.236128
  validation accuracy:		94.24 %
Epoch 306 of 2000 took 0.040s
  training loss:		0.075421
  validation loss:		0.242188
  validation accuracy:		93.91 %
Epoch 307 of 2000 took 0.043s
  training loss:		0.078636
  validation loss:		0.257176
  validation accuracy:		93.37 %
Epoch 308 of 2000 took 0.041s
  training loss:		0.074908
  validation loss:		0.232931
  validation accuracy:		93.91 %
Epoch 309 of 2000 took 0.038s
  training loss:		0.079688
  validation loss:		0.250652
  validation accuracy:		94.24 %
Epoch 310 of 2000 took 0.038s
  training loss:		0.077296
  validation loss:		0.252239
  validation accuracy:		93.04 %
Epoch 311 of 2000 took 0.045s
  training loss:		0.076539
  validation loss:		0.242592
  validation accuracy:		93.91 %
Epoch 312 of 2000 took 0.057s
  training loss:		0.076875
  validation loss:		0.249465
  validation accuracy:		93.80 %
Epoch 313 of 2000 took 0.056s
  training loss:		0.077733
  validation loss:		0.251243
  validation accuracy:		94.02 %
Epoch 314 of 2000 took 0.055s
  training loss:		0.075046
  validation loss:		0.267193
  validation accuracy:		92.93 %
Epoch 315 of 2000 took 0.056s
  training loss:		0.077365
  validation loss:		0.247868
  validation accuracy:		93.80 %
Epoch 316 of 2000 took 0.056s
  training loss:		0.076453
  validation loss:		0.243871
  validation accuracy:		93.91 %
Epoch 317 of 2000 took 0.055s
  training loss:		0.075745
  validation loss:		0.247829
  validation accuracy:		93.70 %
Epoch 318 of 2000 took 0.057s
  training loss:		0.076040
  validation loss:		0.225974
  validation accuracy:		94.67 %
Epoch 319 of 2000 took 0.058s
  training loss:		0.073132
  validation loss:		0.237901
  validation accuracy:		94.02 %
Epoch 320 of 2000 took 0.058s
  training loss:		0.075276
  validation loss:		0.235741
  validation accuracy:		94.13 %
Epoch 321 of 2000 took 0.057s
  training loss:		0.073442
  validation loss:		0.237183
  validation accuracy:		94.13 %
Epoch 322 of 2000 took 0.056s
  training loss:		0.072579
  validation loss:		0.251380
  validation accuracy:		94.02 %
Epoch 323 of 2000 took 0.057s
  training loss:		0.073215
  validation loss:		0.248103
  validation accuracy:		94.02 %
Epoch 324 of 2000 took 0.056s
  training loss:		0.073777
  validation loss:		0.249415
  validation accuracy:		93.91 %
Epoch 325 of 2000 took 0.057s
  training loss:		0.074539
  validation loss:		0.247659
  validation accuracy:		93.91 %
Epoch 326 of 2000 took 0.056s
  training loss:		0.070914
  validation loss:		0.253776
  validation accuracy:		93.59 %
Epoch 327 of 2000 took 0.059s
  training loss:		0.073758
  validation loss:		0.254048
  validation accuracy:		93.80 %
Epoch 328 of 2000 took 0.057s
  training loss:		0.071446
  validation loss:		0.243399
  validation accuracy:		93.80 %
Epoch 329 of 2000 took 0.057s
  training loss:		0.070658
  validation loss:		0.240553
  validation accuracy:		94.67 %
Epoch 330 of 2000 took 0.056s
  training loss:		0.071772
  validation loss:		0.240732
  validation accuracy:		93.80 %
Epoch 331 of 2000 took 0.056s
  training loss:		0.070682
  validation loss:		0.250335
  validation accuracy:		94.35 %
Epoch 332 of 2000 took 0.058s
  training loss:		0.073926
  validation loss:		0.250315
  validation accuracy:		93.91 %
Epoch 333 of 2000 took 0.056s
  training loss:		0.071422
  validation loss:		0.244089
  validation accuracy:		94.02 %
Epoch 334 of 2000 took 0.057s
  training loss:		0.071197
  validation loss:		0.248175
  validation accuracy:		93.59 %
Epoch 335 of 2000 took 0.058s
  training loss:		0.072805
  validation loss:		0.254328
  validation accuracy:		93.48 %
Epoch 336 of 2000 took 0.057s
  training loss:		0.072234
  validation loss:		0.238206
  validation accuracy:		94.46 %
Epoch 337 of 2000 took 0.057s
  training loss:		0.070056
  validation loss:		0.245807
  validation accuracy:		94.24 %
Epoch 338 of 2000 took 0.057s
  training loss:		0.070120
  validation loss:		0.248566
  validation accuracy:		93.91 %
Epoch 339 of 2000 took 0.057s
  training loss:		0.070425
  validation loss:		0.248744
  validation accuracy:		94.02 %
Epoch 340 of 2000 took 0.056s
  training loss:		0.069719
  validation loss:		0.252844
  validation accuracy:		94.02 %
Epoch 341 of 2000 took 0.057s
  training loss:		0.072500
  validation loss:		0.258209
  validation accuracy:		93.80 %
Epoch 342 of 2000 took 0.057s
  training loss:		0.069704
  validation loss:		0.245298
  validation accuracy:		94.13 %
Epoch 343 of 2000 took 0.057s
  training loss:		0.069986
  validation loss:		0.253965
  validation accuracy:		93.59 %
Epoch 344 of 2000 took 0.057s
  training loss:		0.069782
  validation loss:		0.256215
  validation accuracy:		93.80 %
Epoch 345 of 2000 took 0.056s
  training loss:		0.068827
  validation loss:		0.259885
  validation accuracy:		93.37 %
Epoch 346 of 2000 took 0.057s
  training loss:		0.069996
  validation loss:		0.248912
  validation accuracy:		93.70 %
Epoch 347 of 2000 took 0.057s
  training loss:		0.069800
  validation loss:		0.247141
  validation accuracy:		94.24 %
Epoch 348 of 2000 took 0.056s
  training loss:		0.067474
  validation loss:		0.259744
  validation accuracy:		93.59 %
Epoch 349 of 2000 took 0.057s
  training loss:		0.067794
  validation loss:		0.258379
  validation accuracy:		93.48 %
Epoch 350 of 2000 took 0.057s
  training loss:		0.068703
  validation loss:		0.250477
  validation accuracy:		93.80 %
Epoch 351 of 2000 took 0.057s
  training loss:		0.069463
  validation loss:		0.243147
  validation accuracy:		93.91 %
Epoch 352 of 2000 took 0.058s
  training loss:		0.066147
  validation loss:		0.260037
  validation accuracy:		93.59 %
Epoch 353 of 2000 took 0.057s
  training loss:		0.067650
  validation loss:		0.265557
  validation accuracy:		93.48 %
Epoch 354 of 2000 took 0.056s
  training loss:		0.068198
  validation loss:		0.255687
  validation accuracy:		93.48 %
Epoch 355 of 2000 took 0.057s
  training loss:		0.067436
  validation loss:		0.261007
  validation accuracy:		93.70 %
Epoch 356 of 2000 took 0.056s
  training loss:		0.067044
  validation loss:		0.253132
  validation accuracy:		93.70 %
Epoch 357 of 2000 took 0.056s
  training loss:		0.062952
  validation loss:		0.252420
  validation accuracy:		93.80 %
Epoch 358 of 2000 took 0.057s
  training loss:		0.063183
  validation loss:		0.249486
  validation accuracy:		93.48 %
Epoch 359 of 2000 took 0.057s
  training loss:		0.064758
  validation loss:		0.251040
  validation accuracy:		93.59 %
Epoch 360 of 2000 took 0.056s
  training loss:		0.065816
  validation loss:		0.261382
  validation accuracy:		93.80 %
Epoch 361 of 2000 took 0.057s
  training loss:		0.067323
  validation loss:		0.256988
  validation accuracy:		93.91 %
Epoch 362 of 2000 took 0.058s
  training loss:		0.066273
  validation loss:		0.254143
  validation accuracy:		93.80 %
Epoch 363 of 2000 took 0.058s
  training loss:		0.064535
  validation loss:		0.260303
  validation accuracy:		93.48 %
Epoch 364 of 2000 took 0.056s
  training loss:		0.067330
  validation loss:		0.249252
  validation accuracy:		93.80 %
Epoch 365 of 2000 took 0.057s
  training loss:		0.065159
  validation loss:		0.244286
  validation accuracy:		94.35 %
Epoch 366 of 2000 took 0.059s
  training loss:		0.063545
  validation loss:		0.267283
  validation accuracy:		93.70 %
Epoch 367 of 2000 took 0.056s
  training loss:		0.065000
  validation loss:		0.244851
  validation accuracy:		94.02 %
Epoch 368 of 2000 took 0.057s
  training loss:		0.064891
  validation loss:		0.260077
  validation accuracy:		93.26 %
Epoch 369 of 2000 took 0.059s
  training loss:		0.064164
  validation loss:		0.258776
  validation accuracy:		93.70 %
Epoch 370 of 2000 took 0.058s
  training loss:		0.063472
  validation loss:		0.254991
  validation accuracy:		94.02 %
Epoch 371 of 2000 took 0.058s
  training loss:		0.064343
  validation loss:		0.253401
  validation accuracy:		93.91 %
Epoch 372 of 2000 took 0.058s
  training loss:		0.065155
  validation loss:		0.255282
  validation accuracy:		93.70 %
Epoch 373 of 2000 took 0.058s
  training loss:		0.064403
  validation loss:		0.253030
  validation accuracy:		93.80 %
Epoch 374 of 2000 took 0.058s
  training loss:		0.063172
  validation loss:		0.254548
  validation accuracy:		93.91 %
Epoch 375 of 2000 took 0.058s
  training loss:		0.060193
  validation loss:		0.254110
  validation accuracy:		93.70 %
Epoch 376 of 2000 took 0.058s
  training loss:		0.061433
  validation loss:		0.254871
  validation accuracy:		93.80 %
Epoch 377 of 2000 took 0.058s
  training loss:		0.062776
  validation loss:		0.252302
  validation accuracy:		93.80 %
Epoch 378 of 2000 took 0.058s
  training loss:		0.063380
  validation loss:		0.274992
  validation accuracy:		93.15 %
Epoch 379 of 2000 took 0.059s
  training loss:		0.062840
  validation loss:		0.266478
  validation accuracy:		93.48 %
Epoch 380 of 2000 took 0.058s
  training loss:		0.059571
  validation loss:		0.252297
  validation accuracy:		93.59 %
Epoch 381 of 2000 took 0.058s
  training loss:		0.062950
  validation loss:		0.256028
  validation accuracy:		94.02 %
Epoch 382 of 2000 took 0.055s
  training loss:		0.062066
  validation loss:		0.276931
  validation accuracy:		93.15 %
Epoch 383 of 2000 took 0.057s
  training loss:		0.062440
  validation loss:		0.271444
  validation accuracy:		93.15 %
Epoch 384 of 2000 took 0.057s
  training loss:		0.061120
  validation loss:		0.261366
  validation accuracy:		93.70 %
Epoch 385 of 2000 took 0.057s
  training loss:		0.060576
  validation loss:		0.262906
  validation accuracy:		93.48 %
Epoch 386 of 2000 took 0.057s
  training loss:		0.059245
  validation loss:		0.268155
  validation accuracy:		93.48 %
Epoch 387 of 2000 took 0.057s
  training loss:		0.062241
  validation loss:		0.257923
  validation accuracy:		93.70 %
Epoch 388 of 2000 took 0.057s
  training loss:		0.059015
  validation loss:		0.269946
  validation accuracy:		93.59 %
Epoch 389 of 2000 took 0.057s
  training loss:		0.059338
  validation loss:		0.257022
  validation accuracy:		93.48 %
Epoch 390 of 2000 took 0.057s
  training loss:		0.059220
  validation loss:		0.273931
  validation accuracy:		93.15 %
Epoch 391 of 2000 took 0.057s
  training loss:		0.058656
  validation loss:		0.259464
  validation accuracy:		94.13 %
Epoch 392 of 2000 took 0.057s
  training loss:		0.060522
  validation loss:		0.275237
  validation accuracy:		93.26 %
Epoch 393 of 2000 took 0.057s
  training loss:		0.059890
  validation loss:		0.267635
  validation accuracy:		93.70 %
Epoch 394 of 2000 took 0.057s
  training loss:		0.060278
  validation loss:		0.258841
  validation accuracy:		93.70 %
Epoch 395 of 2000 took 0.057s
  training loss:		0.059569
  validation loss:		0.260364
  validation accuracy:		93.80 %
Epoch 396 of 2000 took 0.057s
  training loss:		0.058839
  validation loss:		0.268341
  validation accuracy:		93.59 %
Epoch 397 of 2000 took 0.057s
  training loss:		0.059198
  validation loss:		0.259133
  validation accuracy:		93.70 %
Epoch 398 of 2000 took 0.056s
  training loss:		0.057978
  validation loss:		0.261219
  validation accuracy:		93.59 %
Epoch 399 of 2000 took 0.057s
  training loss:		0.058631
  validation loss:		0.263974
  validation accuracy:		93.70 %
Epoch 400 of 2000 took 0.057s
  training loss:		0.058988
  validation loss:		0.280046
  validation accuracy:		93.37 %
Epoch 401 of 2000 took 0.057s
  training loss:		0.058538
  validation loss:		0.263153
  validation accuracy:		93.70 %
Epoch 402 of 2000 took 0.057s
  training loss:		0.056354
  validation loss:		0.264050
  validation accuracy:		93.70 %
Epoch 403 of 2000 took 0.057s
  training loss:		0.056889
  validation loss:		0.274230
  validation accuracy:		93.37 %
Epoch 404 of 2000 took 0.057s
  training loss:		0.057187
  validation loss:		0.279112
  validation accuracy:		93.26 %
Epoch 405 of 2000 took 0.057s
  training loss:		0.056563
  validation loss:		0.277078
  validation accuracy:		93.59 %
Epoch 406 of 2000 took 0.057s
  training loss:		0.055997
  validation loss:		0.271832
  validation accuracy:		93.04 %
Epoch 407 of 2000 took 0.057s
  training loss:		0.057886
  validation loss:		0.270434
  validation accuracy:		93.59 %
Epoch 408 of 2000 took 0.057s
  training loss:		0.058134
  validation loss:		0.280118
  validation accuracy:		93.26 %
Epoch 409 of 2000 took 0.057s
  training loss:		0.057580
  validation loss:		0.282785
  validation accuracy:		92.83 %
Epoch 410 of 2000 took 0.058s
  training loss:		0.058033
  validation loss:		0.266316
  validation accuracy:		93.59 %
Epoch 411 of 2000 took 0.055s
  training loss:		0.055946
  validation loss:		0.286295
  validation accuracy:		92.72 %
Epoch 412 of 2000 took 0.058s
  training loss:		0.056476
  validation loss:		0.276046
  validation accuracy:		93.04 %
Epoch 413 of 2000 took 0.058s
  training loss:		0.057188
  validation loss:		0.268541
  validation accuracy:		93.70 %
Epoch 414 of 2000 took 0.056s
  training loss:		0.053179
  validation loss:		0.270542
  validation accuracy:		93.48 %
Epoch 415 of 2000 took 0.058s
  training loss:		0.054549
  validation loss:		0.264513
  validation accuracy:		93.80 %
Epoch 416 of 2000 took 0.057s
  training loss:		0.055636
  validation loss:		0.272946
  validation accuracy:		93.04 %
Epoch 417 of 2000 took 0.059s
  training loss:		0.056270
  validation loss:		0.285096
  validation accuracy:		93.26 %
Epoch 418 of 2000 took 0.057s
  training loss:		0.055061
  validation loss:		0.274072
  validation accuracy:		93.48 %
Epoch 419 of 2000 took 0.059s
  training loss:		0.054591
  validation loss:		0.274819
  validation accuracy:		93.48 %
Epoch 420 of 2000 took 0.057s
  training loss:		0.054799
  validation loss:		0.268432
  validation accuracy:		93.70 %
Epoch 421 of 2000 took 0.056s
  training loss:		0.053647
  validation loss:		0.277531
  validation accuracy:		93.48 %
Epoch 422 of 2000 took 0.059s
  training loss:		0.055212
  validation loss:		0.278823
  validation accuracy:		93.59 %
Epoch 423 of 2000 took 0.057s
  training loss:		0.054226
  validation loss:		0.268779
  validation accuracy:		93.80 %
Epoch 424 of 2000 took 0.059s
  training loss:		0.054675
  validation loss:		0.276372
  validation accuracy:		93.48 %
Epoch 425 of 2000 took 0.057s
  training loss:		0.053133
  validation loss:		0.291026
  validation accuracy:		92.83 %
Epoch 426 of 2000 took 0.056s
  training loss:		0.053764
  validation loss:		0.266908
  validation accuracy:		93.70 %
Epoch 427 of 2000 took 0.059s
  training loss:		0.052950
  validation loss:		0.281082
  validation accuracy:		93.15 %
Epoch 428 of 2000 took 0.058s
  training loss:		0.053996
  validation loss:		0.272747
  validation accuracy:		93.59 %
Epoch 429 of 2000 took 0.059s
  training loss:		0.053263
  validation loss:		0.285310
  validation accuracy:		93.48 %
Epoch 430 of 2000 took 0.059s
  training loss:		0.053690
  validation loss:		0.279529
  validation accuracy:		93.37 %
Epoch 431 of 2000 took 0.059s
  training loss:		0.054476
  validation loss:		0.276399
  validation accuracy:		93.48 %
Epoch 432 of 2000 took 0.058s
  training loss:		0.053557
  validation loss:		0.279148
  validation accuracy:		93.26 %
Epoch 433 of 2000 took 0.058s
  training loss:		0.051881
  validation loss:		0.275553
  validation accuracy:		93.70 %
Epoch 434 of 2000 took 0.059s
  training loss:		0.053550
  validation loss:		0.267355
  validation accuracy:		93.48 %
Epoch 435 of 2000 took 0.058s
  training loss:		0.055367
  validation loss:		0.278284
  validation accuracy:		93.37 %
Epoch 436 of 2000 took 0.058s
  training loss:		0.050148
  validation loss:		0.276144
  validation accuracy:		93.59 %
Epoch 437 of 2000 took 0.058s
  training loss:		0.050490
  validation loss:		0.274481
  validation accuracy:		93.48 %
Epoch 438 of 2000 took 0.058s
  training loss:		0.053810
  validation loss:		0.276075
  validation accuracy:		93.04 %
Epoch 439 of 2000 took 0.058s
  training loss:		0.051871
  validation loss:		0.270419
  validation accuracy:		93.70 %
Epoch 440 of 2000 took 0.058s
  training loss:		0.048748
  validation loss:		0.285036
  validation accuracy:		93.26 %
Epoch 441 of 2000 took 0.058s
  training loss:		0.051175
  validation loss:		0.275610
  validation accuracy:		93.59 %
Epoch 442 of 2000 took 0.058s
  training loss:		0.049532
  validation loss:		0.296850
  validation accuracy:		93.04 %
Epoch 443 of 2000 took 0.058s
  training loss:		0.051662
  validation loss:		0.291615
  validation accuracy:		93.15 %
Epoch 444 of 2000 took 0.058s
  training loss:		0.052342
  validation loss:		0.283842
  validation accuracy:		93.26 %
Epoch 445 of 2000 took 0.059s
  training loss:		0.051530
  validation loss:		0.271582
  validation accuracy:		94.02 %
Epoch 446 of 2000 took 0.058s
  training loss:		0.050385
  validation loss:		0.284136
  validation accuracy:		93.26 %
Epoch 447 of 2000 took 0.057s
  training loss:		0.051927
  validation loss:		0.271986
  validation accuracy:		93.80 %
Epoch 448 of 2000 took 0.057s
  training loss:		0.050249
  validation loss:		0.291526
  validation accuracy:		92.93 %
Epoch 449 of 2000 took 0.057s
  training loss:		0.049297
  validation loss:		0.290633
  validation accuracy:		93.15 %
Epoch 450 of 2000 took 0.057s
  training loss:		0.050997
  validation loss:		0.279611
  validation accuracy:		93.26 %
Epoch 451 of 2000 took 0.058s
  training loss:		0.050996
  validation loss:		0.283662
  validation accuracy:		93.04 %
Epoch 452 of 2000 took 0.057s
  training loss:		0.047668
  validation loss:		0.286022
  validation accuracy:		93.48 %
Epoch 453 of 2000 took 0.057s
  training loss:		0.048083
  validation loss:		0.284496
  validation accuracy:		93.37 %
Epoch 454 of 2000 took 0.057s
  training loss:		0.050114
  validation loss:		0.282824
  validation accuracy:		93.59 %
Epoch 455 of 2000 took 0.057s
  training loss:		0.049382
  validation loss:		0.294495
  validation accuracy:		93.26 %
Epoch 456 of 2000 took 0.057s
  training loss:		0.048861
  validation loss:		0.280496
  validation accuracy:		93.48 %
Epoch 457 of 2000 took 0.057s
  training loss:		0.050794
  validation loss:		0.303926
  validation accuracy:		92.83 %
Epoch 458 of 2000 took 0.057s
  training loss:		0.048246
  validation loss:		0.302992
  validation accuracy:		93.15 %
Epoch 459 of 2000 took 0.057s
  training loss:		0.046815
  validation loss:		0.296283
  validation accuracy:		93.48 %
Epoch 460 of 2000 took 0.057s
  training loss:		0.048195
  validation loss:		0.278198
  validation accuracy:		93.37 %
Epoch 461 of 2000 took 0.056s
  training loss:		0.049544
  validation loss:		0.283410
  validation accuracy:		93.59 %
Epoch 462 of 2000 took 0.058s
  training loss:		0.047834
  validation loss:		0.292822
  validation accuracy:		93.37 %
Epoch 463 of 2000 took 0.057s
  training loss:		0.047798
  validation loss:		0.280238
  validation accuracy:		93.04 %
Epoch 464 of 2000 took 0.057s
  training loss:		0.047955
  validation loss:		0.298471
  validation accuracy:		93.15 %
Epoch 465 of 2000 took 0.057s
  training loss:		0.047908
  validation loss:		0.292740
  validation accuracy:		92.93 %
Epoch 466 of 2000 took 0.058s
  training loss:		0.047553
  validation loss:		0.296228
  validation accuracy:		93.04 %
Epoch 467 of 2000 took 0.058s
  training loss:		0.047236
  validation loss:		0.286546
  validation accuracy:		92.93 %
Epoch 468 of 2000 took 0.057s
  training loss:		0.048260
  validation loss:		0.288051
  validation accuracy:		93.37 %
Epoch 469 of 2000 took 0.057s
  training loss:		0.046488
  validation loss:		0.290775
  validation accuracy:		92.83 %
Epoch 470 of 2000 took 0.058s
  training loss:		0.046434
  validation loss:		0.293135
  validation accuracy:		93.26 %
Epoch 471 of 2000 took 0.057s
  training loss:		0.046492
  validation loss:		0.301762
  validation accuracy:		92.72 %
Epoch 472 of 2000 took 0.057s
  training loss:		0.046797
  validation loss:		0.287603
  validation accuracy:		93.48 %
Epoch 473 of 2000 took 0.057s
  training loss:		0.046637
  validation loss:		0.293557
  validation accuracy:		93.26 %
Epoch 474 of 2000 took 0.058s
  training loss:		0.046888
  validation loss:		0.298446
  validation accuracy:		93.04 %
Epoch 475 of 2000 took 0.058s
  training loss:		0.045790
  validation loss:		0.286341
  validation accuracy:		93.59 %
Epoch 476 of 2000 took 0.058s
  training loss:		0.046256
  validation loss:		0.296741
  validation accuracy:		93.15 %
Epoch 477 of 2000 took 0.058s
  training loss:		0.046408
  validation loss:		0.304237
  validation accuracy:		93.26 %
Epoch 478 of 2000 took 0.058s
  training loss:		0.045317
  validation loss:		0.302624
  validation accuracy:		93.15 %
Epoch 479 of 2000 took 0.058s
  training loss:		0.045651
  validation loss:		0.282958
  validation accuracy:		93.48 %
Epoch 480 of 2000 took 0.057s
  training loss:		0.046713
  validation loss:		0.285602
  validation accuracy:		93.37 %
Epoch 481 of 2000 took 0.057s
  training loss:		0.044922
  validation loss:		0.304687
  validation accuracy:		93.26 %
Epoch 482 of 2000 took 0.057s
  training loss:		0.043589
  validation loss:		0.284720
  validation accuracy:		93.26 %
Epoch 483 of 2000 took 0.057s
  training loss:		0.043977
  validation loss:		0.305347
  validation accuracy:		93.26 %
Epoch 484 of 2000 took 0.057s
  training loss:		0.045319
  validation loss:		0.288897
  validation accuracy:		93.37 %
Epoch 485 of 2000 took 0.057s
  training loss:		0.046375
  validation loss:		0.296775
  validation accuracy:		93.26 %
Epoch 486 of 2000 took 0.058s
  training loss:		0.044515
  validation loss:		0.292814
  validation accuracy:		93.37 %
Epoch 487 of 2000 took 0.058s
  training loss:		0.044276
  validation loss:		0.314569
  validation accuracy:		93.15 %
Epoch 488 of 2000 took 0.057s
  training loss:		0.044807
  validation loss:		0.299257
  validation accuracy:		93.26 %
Epoch 489 of 2000 took 0.057s
  training loss:		0.044201
  validation loss:		0.303216
  validation accuracy:		93.04 %
Epoch 490 of 2000 took 0.057s
  training loss:		0.042398
  validation loss:		0.290434
  validation accuracy:		93.37 %
Epoch 491 of 2000 took 0.057s
  training loss:		0.045962
  validation loss:		0.297863
  validation accuracy:		93.26 %
Epoch 492 of 2000 took 0.057s
  training loss:		0.043377
  validation loss:		0.305085
  validation accuracy:		93.26 %
Epoch 493 of 2000 took 0.058s
  training loss:		0.042889
  validation loss:		0.293845
  validation accuracy:		93.26 %
Epoch 494 of 2000 took 0.057s
  training loss:		0.044183
  validation loss:		0.309547
  validation accuracy:		92.72 %
Epoch 495 of 2000 took 0.057s
  training loss:		0.044894
  validation loss:		0.297876
  validation accuracy:		93.37 %
Epoch 496 of 2000 took 0.057s
  training loss:		0.044001
  validation loss:		0.288249
  validation accuracy:		93.37 %
Epoch 497 of 2000 took 0.057s
  training loss:		0.044986
  validation loss:		0.304724
  validation accuracy:		92.61 %
Epoch 498 of 2000 took 0.057s
  training loss:		0.044217
  validation loss:		0.308244
  validation accuracy:		92.93 %
Epoch 499 of 2000 took 0.057s
  training loss:		0.042181
  validation loss:		0.324796
  validation accuracy:		92.50 %
Epoch 500 of 2000 took 0.057s
  training loss:		0.043744
  validation loss:		0.333790
  validation accuracy:		92.50 %
Epoch 501 of 2000 took 0.057s
  training loss:		0.043417
  validation loss:		0.295650
  validation accuracy:		93.37 %
Epoch 502 of 2000 took 0.057s
  training loss:		0.042867
  validation loss:		0.295606
  validation accuracy:		93.15 %
Epoch 503 of 2000 took 0.057s
  training loss:		0.042930
  validation loss:		0.308788
  validation accuracy:		93.04 %
Epoch 504 of 2000 took 0.057s
  training loss:		0.040560
  validation loss:		0.285151
  validation accuracy:		93.37 %
Epoch 505 of 2000 took 0.057s
  training loss:		0.043509
  validation loss:		0.305127
  validation accuracy:		92.72 %
Epoch 506 of 2000 took 0.057s
  training loss:		0.041754
  validation loss:		0.319917
  validation accuracy:		92.72 %
Epoch 507 of 2000 took 0.057s
  training loss:		0.042649
  validation loss:		0.302608
  validation accuracy:		93.37 %
Epoch 508 of 2000 took 0.057s
  training loss:		0.041375
  validation loss:		0.299082
  validation accuracy:		93.48 %
Epoch 509 of 2000 took 0.057s
  training loss:		0.041822
  validation loss:		0.294613
  validation accuracy:		93.59 %
Epoch 510 of 2000 took 0.058s
  training loss:		0.041421
  validation loss:		0.298583
  validation accuracy:		93.04 %
Epoch 511 of 2000 took 0.057s
  training loss:		0.042253
  validation loss:		0.296015
  validation accuracy:		93.04 %
Epoch 512 of 2000 took 0.058s
  training loss:		0.041362
  validation loss:		0.296501
  validation accuracy:		93.04 %
Epoch 513 of 2000 took 0.057s
  training loss:		0.041321
  validation loss:		0.299287
  validation accuracy:		93.04 %
Epoch 514 of 2000 took 0.057s
  training loss:		0.041171
  validation loss:		0.315947
  validation accuracy:		93.26 %
Epoch 515 of 2000 took 0.057s
  training loss:		0.041889
  validation loss:		0.302594
  validation accuracy:		92.93 %
Epoch 516 of 2000 took 0.057s
  training loss:		0.038786
  validation loss:		0.289375
  validation accuracy:		93.48 %
Epoch 517 of 2000 took 0.057s
  training loss:		0.042109
  validation loss:		0.298065
  validation accuracy:		93.59 %
Epoch 518 of 2000 took 0.058s
  training loss:		0.039701
  validation loss:		0.302358
  validation accuracy:		93.15 %
Epoch 519 of 2000 took 0.057s
  training loss:		0.039978
  validation loss:		0.307184
  validation accuracy:		93.37 %
Epoch 520 of 2000 took 0.056s
  training loss:		0.039031
  validation loss:		0.308621
  validation accuracy:		92.83 %
Epoch 521 of 2000 took 0.057s
  training loss:		0.040620
  validation loss:		0.312607
  validation accuracy:		92.72 %
Epoch 522 of 2000 took 0.056s
  training loss:		0.039782
  validation loss:		0.307239
  validation accuracy:		93.04 %
Epoch 523 of 2000 took 0.056s
  training loss:		0.038448
  validation loss:		0.329032
  validation accuracy:		92.72 %
Epoch 524 of 2000 took 0.059s
  training loss:		0.041388
  validation loss:		0.311996
  validation accuracy:		92.72 %
Epoch 525 of 2000 took 0.056s
  training loss:		0.039528
  validation loss:		0.318957
  validation accuracy:		93.15 %
Epoch 526 of 2000 took 0.057s
  training loss:		0.039017
  validation loss:		0.302178
  validation accuracy:		93.04 %
Epoch 527 of 2000 took 0.056s
  training loss:		0.039482
  validation loss:		0.301538
  validation accuracy:		93.15 %
Epoch 528 of 2000 took 0.058s
  training loss:		0.039017
  validation loss:		0.308076
  validation accuracy:		92.93 %
Epoch 529 of 2000 took 0.059s
  training loss:		0.039427
  validation loss:		0.312920
  validation accuracy:		93.04 %
Epoch 530 of 2000 took 0.058s
  training loss:		0.039221
  validation loss:		0.300905
  validation accuracy:		92.93 %
Epoch 531 of 2000 took 0.057s
  training loss:		0.036759
  validation loss:		0.306301
  validation accuracy:		92.93 %
Epoch 532 of 2000 took 0.058s
  training loss:		0.039240
  validation loss:		0.303317
  validation accuracy:		93.15 %
Epoch 533 of 2000 took 0.056s
  training loss:		0.039911
  validation loss:		0.312477
  validation accuracy:		93.37 %
Epoch 534 of 2000 took 0.058s
  training loss:		0.038607
  validation loss:		0.302654
  validation accuracy:		93.26 %
Epoch 535 of 2000 took 0.058s
  training loss:		0.037357
  validation loss:		0.310216
  validation accuracy:		93.37 %
Epoch 536 of 2000 took 0.059s
  training loss:		0.037585
  validation loss:		0.313711
  validation accuracy:		92.72 %
Epoch 537 of 2000 took 0.058s
  training loss:		0.038943
  validation loss:		0.325086
  validation accuracy:		92.93 %
Epoch 538 of 2000 took 0.058s
  training loss:		0.039191
  validation loss:		0.310357
  validation accuracy:		93.04 %
Epoch 539 of 2000 took 0.058s
  training loss:		0.037979
  validation loss:		0.316214
  validation accuracy:		93.15 %
Epoch 540 of 2000 took 0.059s
  training loss:		0.038219
  validation loss:		0.328640
  validation accuracy:		92.93 %
Epoch 541 of 2000 took 0.057s
  training loss:		0.037854
  validation loss:		0.320320
  validation accuracy:		92.61 %
Epoch 542 of 2000 took 0.059s
  training loss:		0.039252
  validation loss:		0.332519
  validation accuracy:		92.61 %
Epoch 543 of 2000 took 0.057s
  training loss:		0.038559
  validation loss:		0.333700
  validation accuracy:		92.83 %
Epoch 544 of 2000 took 0.058s
  training loss:		0.038320
  validation loss:		0.315413
  validation accuracy:		92.93 %
Epoch 545 of 2000 took 0.058s
  training loss:		0.037623
  validation loss:		0.312933
  validation accuracy:		93.04 %
Epoch 546 of 2000 took 0.057s
  training loss:		0.038012
  validation loss:		0.321846
  validation accuracy:		92.83 %
Epoch 547 of 2000 took 0.058s
  training loss:		0.038203
  validation loss:		0.318099
  validation accuracy:		93.15 %
Epoch 548 of 2000 took 0.057s
  training loss:		0.037294
  validation loss:		0.323491
  validation accuracy:		93.04 %
Epoch 549 of 2000 took 0.058s
  training loss:		0.035296
  validation loss:		0.314793
  validation accuracy:		92.93 %
Epoch 550 of 2000 took 0.057s
  training loss:		0.037303
  validation loss:		0.325826
  validation accuracy:		92.83 %
Epoch 551 of 2000 took 0.057s
  training loss:		0.034984
  validation loss:		0.313920
  validation accuracy:		93.04 %
Epoch 552 of 2000 took 0.057s
  training loss:		0.035613
  validation loss:		0.312428
  validation accuracy:		93.04 %
Epoch 553 of 2000 took 0.057s
  training loss:		0.036604
  validation loss:		0.321799
  validation accuracy:		92.83 %
Epoch 554 of 2000 took 0.057s
  training loss:		0.036904
  validation loss:		0.319878
  validation accuracy:		92.93 %
Epoch 555 of 2000 took 0.057s
  training loss:		0.036199
  validation loss:		0.321865
  validation accuracy:		93.04 %
Epoch 556 of 2000 took 0.058s
  training loss:		0.036386
  validation loss:		0.324010
  validation accuracy:		92.93 %
Epoch 557 of 2000 took 0.058s
  training loss:		0.035455
  validation loss:		0.334403
  validation accuracy:		92.93 %
Epoch 558 of 2000 took 0.057s
  training loss:		0.035565
  validation loss:		0.316649
  validation accuracy:		92.93 %
Epoch 559 of 2000 took 0.057s
  training loss:		0.036296
  validation loss:		0.315221
  validation accuracy:		93.15 %
Epoch 560 of 2000 took 0.057s
  training loss:		0.036308
  validation loss:		0.314645
  validation accuracy:		92.93 %
Epoch 561 of 2000 took 0.057s
  training loss:		0.035183
  validation loss:		0.330837
  validation accuracy:		92.83 %
Epoch 562 of 2000 took 0.058s
  training loss:		0.036549
  validation loss:		0.319704
  validation accuracy:		93.15 %
Epoch 563 of 2000 took 0.058s
  training loss:		0.035068
  validation loss:		0.335199
  validation accuracy:		92.72 %
Epoch 564 of 2000 took 0.058s
  training loss:		0.034410
  validation loss:		0.316594
  validation accuracy:		92.83 %
Epoch 565 of 2000 took 0.058s
  training loss:		0.035570
  validation loss:		0.331825
  validation accuracy:		92.61 %
Epoch 566 of 2000 took 0.058s
  training loss:		0.035637
  validation loss:		0.346737
  validation accuracy:		92.93 %
Epoch 567 of 2000 took 0.058s
  training loss:		0.035255
  validation loss:		0.314659
  validation accuracy:		93.37 %
Epoch 568 of 2000 took 0.058s
  training loss:		0.034432
  validation loss:		0.323233
  validation accuracy:		93.04 %
Epoch 569 of 2000 took 0.057s
  training loss:		0.035659
  validation loss:		0.325180
  validation accuracy:		93.04 %
Epoch 570 of 2000 took 0.057s
  training loss:		0.033562
  validation loss:		0.310671
  validation accuracy:		93.26 %
Epoch 571 of 2000 took 0.057s
  training loss:		0.031853
  validation loss:		0.317381
  validation accuracy:		93.15 %
Epoch 572 of 2000 took 0.057s
  training loss:		0.034066
  validation loss:		0.328368
  validation accuracy:		92.50 %
Epoch 573 of 2000 took 0.058s
  training loss:		0.033904
  validation loss:		0.348525
  validation accuracy:		92.39 %
Epoch 574 of 2000 took 0.057s
  training loss:		0.034059
  validation loss:		0.320939
  validation accuracy:		93.04 %
Epoch 575 of 2000 took 0.057s
  training loss:		0.035460
  validation loss:		0.328546
  validation accuracy:		93.04 %
Epoch 576 of 2000 took 0.057s
  training loss:		0.034300
  validation loss:		0.329674
  validation accuracy:		93.15 %
Epoch 577 of 2000 took 0.057s
  training loss:		0.032989
  validation loss:		0.332808
  validation accuracy:		92.61 %
Epoch 578 of 2000 took 0.057s
  training loss:		0.032850
  validation loss:		0.329114
  validation accuracy:		92.93 %
Epoch 579 of 2000 took 0.057s
  training loss:		0.033810
  validation loss:		0.333081
  validation accuracy:		92.72 %
Epoch 580 of 2000 took 0.057s
  training loss:		0.034002
  validation loss:		0.338603
  validation accuracy:		92.83 %
Epoch 581 of 2000 took 0.057s
  training loss:		0.034389
  validation loss:		0.334799
  validation accuracy:		92.72 %
Epoch 582 of 2000 took 0.057s
  training loss:		0.033819
  validation loss:		0.329061
  validation accuracy:		93.04 %
Epoch 583 of 2000 took 0.057s
  training loss:		0.034836
  validation loss:		0.344390
  validation accuracy:		92.72 %
Epoch 584 of 2000 took 0.057s
  training loss:		0.033107
  validation loss:		0.331727
  validation accuracy:		92.83 %
Epoch 585 of 2000 took 0.057s
  training loss:		0.033075
  validation loss:		0.342366
  validation accuracy:		92.72 %
Epoch 586 of 2000 took 0.058s
  training loss:		0.032432
  validation loss:		0.327247
  validation accuracy:		92.93 %
Epoch 587 of 2000 took 0.057s
  training loss:		0.032794
  validation loss:		0.341686
  validation accuracy:		92.83 %
Epoch 588 of 2000 took 0.057s
  training loss:		0.033183
  validation loss:		0.345359
  validation accuracy:		92.93 %
Epoch 589 of 2000 took 0.058s
  training loss:		0.033372
  validation loss:		0.341058
  validation accuracy:		92.61 %
Epoch 590 of 2000 took 0.057s
  training loss:		0.032850
  validation loss:		0.327646
  validation accuracy:		93.15 %
Epoch 591 of 2000 took 0.057s
  training loss:		0.032333
  validation loss:		0.328298
  validation accuracy:		92.93 %
Epoch 592 of 2000 took 0.057s
  training loss:		0.032593
  validation loss:		0.334244
  validation accuracy:		92.93 %
Epoch 593 of 2000 took 0.060s
  training loss:		0.031161
  validation loss:		0.330293
  validation accuracy:		92.83 %
Epoch 594 of 2000 took 0.057s
  training loss:		0.033134
  validation loss:		0.342613
  validation accuracy:		93.26 %
Epoch 595 of 2000 took 0.057s
  training loss:		0.032604
  validation loss:		0.338963
  validation accuracy:		92.83 %
Epoch 596 of 2000 took 0.057s
  training loss:		0.030244
  validation loss:		0.332677
  validation accuracy:		93.04 %
Epoch 597 of 2000 took 0.057s
  training loss:		0.032361
  validation loss:		0.337585
  validation accuracy:		92.83 %
Epoch 598 of 2000 took 0.057s
  training loss:		0.032558
  validation loss:		0.331090
  validation accuracy:		92.93 %
Epoch 599 of 2000 took 0.056s
  training loss:		0.032154
  validation loss:		0.326519
  validation accuracy:		93.04 %
Epoch 600 of 2000 took 0.057s
  training loss:		0.031429
  validation loss:		0.347697
  validation accuracy:		92.93 %
Epoch 601 of 2000 took 0.057s
  training loss:		0.032485
  validation loss:		0.326711
  validation accuracy:		92.83 %
Epoch 602 of 2000 took 0.057s
  training loss:		0.032343
  validation loss:		0.330441
  validation accuracy:		92.83 %
Epoch 603 of 2000 took 0.057s
  training loss:		0.032127
  validation loss:		0.347334
  validation accuracy:		92.93 %
Epoch 604 of 2000 took 0.057s
  training loss:		0.031106
  validation loss:		0.329192
  validation accuracy:		93.04 %
Epoch 605 of 2000 took 0.057s
  training loss:		0.030475
  validation loss:		0.335191
  validation accuracy:		92.93 %
Epoch 606 of 2000 took 0.056s
  training loss:		0.030963
  validation loss:		0.338270
  validation accuracy:		93.04 %
Epoch 607 of 2000 took 0.056s
  training loss:		0.031028
  validation loss:		0.352271
  validation accuracy:		93.04 %
Epoch 608 of 2000 took 0.057s
  training loss:		0.031361
  validation loss:		0.343056
  validation accuracy:		92.83 %
Epoch 609 of 2000 took 0.057s
  training loss:		0.031487
  validation loss:		0.345187
  validation accuracy:		92.61 %
Epoch 610 of 2000 took 0.057s
  training loss:		0.030148
  validation loss:		0.346155
  validation accuracy:		92.93 %
Epoch 611 of 2000 took 0.057s
  training loss:		0.030651
  validation loss:		0.349614
  validation accuracy:		92.72 %
Epoch 612 of 2000 took 0.057s
  training loss:		0.030455
  validation loss:		0.342147
  validation accuracy:		92.83 %
Epoch 613 of 2000 took 0.057s
  training loss:		0.029648
  validation loss:		0.350183
  validation accuracy:		92.93 %
Epoch 614 of 2000 took 0.057s
  training loss:		0.029808
  validation loss:		0.355495
  validation accuracy:		92.50 %
Epoch 615 of 2000 took 0.057s
  training loss:		0.030630
  validation loss:		0.342225
  validation accuracy:		92.72 %
Epoch 616 of 2000 took 0.057s
  training loss:		0.029893
  validation loss:		0.348787
  validation accuracy:		93.04 %
Epoch 617 of 2000 took 0.057s
  training loss:		0.029513
  validation loss:		0.353027
  validation accuracy:		92.93 %
Epoch 618 of 2000 took 0.057s
  training loss:		0.028272
  validation loss:		0.343667
  validation accuracy:		92.61 %
Epoch 619 of 2000 took 0.056s
  training loss:		0.029695
  validation loss:		0.347938
  validation accuracy:		92.93 %
Epoch 620 of 2000 took 0.056s
  training loss:		0.030665
  validation loss:		0.335380
  validation accuracy:		92.50 %
Epoch 621 of 2000 took 0.057s
  training loss:		0.028671
  validation loss:		0.345065
  validation accuracy:		92.83 %
Epoch 622 of 2000 took 0.057s
  training loss:		0.028645
  validation loss:		0.344181
  validation accuracy:		92.93 %
Epoch 623 of 2000 took 0.057s
  training loss:		0.029693
  validation loss:		0.350163
  validation accuracy:		92.72 %
Epoch 624 of 2000 took 0.057s
  training loss:		0.029870
  validation loss:		0.348406
  validation accuracy:		92.72 %
Epoch 625 of 2000 took 0.056s
  training loss:		0.028653
  validation loss:		0.336212
  validation accuracy:		92.93 %
Epoch 626 of 2000 took 0.057s
  training loss:		0.029631
  validation loss:		0.340944
  validation accuracy:		93.04 %
Epoch 627 of 2000 took 0.057s
  training loss:		0.030073
  validation loss:		0.354250
  validation accuracy:		92.28 %
Epoch 628 of 2000 took 0.055s
  training loss:		0.028725
  validation loss:		0.342596
  validation accuracy:		93.26 %
Epoch 629 of 2000 took 0.057s
  training loss:		0.028811
  validation loss:		0.351797
  validation accuracy:		92.61 %
Epoch 630 of 2000 took 0.057s
  training loss:		0.028893
  validation loss:		0.350862
  validation accuracy:		92.93 %
Epoch 631 of 2000 took 0.057s
  training loss:		0.028560
  validation loss:		0.333035
  validation accuracy:		93.26 %
Epoch 632 of 2000 took 0.057s
  training loss:		0.028670
  validation loss:		0.353600
  validation accuracy:		92.72 %
Epoch 633 of 2000 took 0.057s
  training loss:		0.029140
  validation loss:		0.354363
  validation accuracy:		92.93 %
Epoch 634 of 2000 took 0.057s
  training loss:		0.029064
  validation loss:		0.354146
  validation accuracy:		92.93 %
Epoch 635 of 2000 took 0.057s
  training loss:		0.028782
  validation loss:		0.349184
  validation accuracy:		92.83 %
Epoch 636 of 2000 took 0.057s
  training loss:		0.028573
  validation loss:		0.352386
  validation accuracy:		92.93 %
Epoch 637 of 2000 took 0.057s
  training loss:		0.026744
  validation loss:		0.348664
  validation accuracy:		92.50 %
Epoch 638 of 2000 took 0.057s
  training loss:		0.029424
  validation loss:		0.355436
  validation accuracy:		93.04 %
Epoch 639 of 2000 took 0.056s
  training loss:		0.028516
  validation loss:		0.354428
  validation accuracy:		92.61 %
Epoch 640 of 2000 took 0.057s
  training loss:		0.029133
  validation loss:		0.344894
  validation accuracy:		92.83 %
Epoch 641 of 2000 took 0.056s
  training loss:		0.029049
  validation loss:		0.356896
  validation accuracy:		92.72 %
Epoch 642 of 2000 took 0.057s
  training loss:		0.027111
  validation loss:		0.356026
  validation accuracy:		92.83 %
Epoch 643 of 2000 took 0.057s
  training loss:		0.027527
  validation loss:		0.344439
  validation accuracy:		92.93 %
Epoch 644 of 2000 took 0.057s
  training loss:		0.028848
  validation loss:		0.373148
  validation accuracy:		92.93 %
Epoch 645 of 2000 took 0.057s
  training loss:		0.029291
  validation loss:		0.361624
  validation accuracy:		92.83 %
Epoch 646 of 2000 took 0.057s
  training loss:		0.028284
  validation loss:		0.357884
  validation accuracy:		92.83 %
Epoch 647 of 2000 took 0.056s
  training loss:		0.027453
  validation loss:		0.348188
  validation accuracy:		93.04 %
Epoch 648 of 2000 took 0.057s
  training loss:		0.027692
  validation loss:		0.352155
  validation accuracy:		93.04 %
Epoch 649 of 2000 took 0.057s
  training loss:		0.026492
  validation loss:		0.360977
  validation accuracy:		92.83 %
Epoch 650 of 2000 took 0.057s
  training loss:		0.027803
  validation loss:		0.352102
  validation accuracy:		92.93 %
Epoch 651 of 2000 took 0.057s
  training loss:		0.027668
  validation loss:		0.350515
  validation accuracy:		92.83 %
Epoch 652 of 2000 took 0.057s
  training loss:		0.027723
  validation loss:		0.370475
  validation accuracy:		92.50 %
Epoch 653 of 2000 took 0.056s
  training loss:		0.027941
  validation loss:		0.357463
  validation accuracy:		92.72 %
Epoch 654 of 2000 took 0.057s
  training loss:		0.028189
  validation loss:		0.367597
  validation accuracy:		92.72 %
Epoch 655 of 2000 took 0.057s
  training loss:		0.027889
  validation loss:		0.361687
  validation accuracy:		92.83 %
Epoch 656 of 2000 took 0.057s
  training loss:		0.027640
  validation loss:		0.348037
  validation accuracy:		92.93 %
Epoch 657 of 2000 took 0.055s
  training loss:		0.027013
  validation loss:		0.357295
  validation accuracy:		92.72 %
Epoch 658 of 2000 took 0.057s
  training loss:		0.026448
  validation loss:		0.341206
  validation accuracy:		93.37 %
Epoch 659 of 2000 took 0.057s
  training loss:		0.027097
  validation loss:		0.358917
  validation accuracy:		92.72 %
Epoch 660 of 2000 took 0.055s
  training loss:		0.026277
  validation loss:		0.364201
  validation accuracy:		92.72 %
Epoch 661 of 2000 took 0.057s
  training loss:		0.026676
  validation loss:		0.362450
  validation accuracy:		92.83 %
Epoch 662 of 2000 took 0.057s
  training loss:		0.026863
  validation loss:		0.370671
  validation accuracy:		92.61 %
Epoch 663 of 2000 took 0.056s
  training loss:		0.026894
  validation loss:		0.366264
  validation accuracy:		92.93 %
Epoch 664 of 2000 took 0.057s
  training loss:		0.026553
  validation loss:		0.358383
  validation accuracy:		92.93 %
Epoch 665 of 2000 took 0.057s
  training loss:		0.026040
  validation loss:		0.359747
  validation accuracy:		92.72 %
Epoch 666 of 2000 took 0.057s
  training loss:		0.026608
  validation loss:		0.359376
  validation accuracy:		92.50 %
Epoch 667 of 2000 took 0.057s
  training loss:		0.026341
  validation loss:		0.351640
  validation accuracy:		93.04 %
Epoch 668 of 2000 took 0.057s
  training loss:		0.026650
  validation loss:		0.361163
  validation accuracy:		92.83 %
Epoch 669 of 2000 took 0.057s
  training loss:		0.025387
  validation loss:		0.360274
  validation accuracy:		92.83 %
Epoch 670 of 2000 took 0.057s
  training loss:		0.026322
  validation loss:		0.357013
  validation accuracy:		92.72 %
Epoch 671 of 2000 took 0.057s
  training loss:		0.024804
  validation loss:		0.366735
  validation accuracy:		92.61 %
Epoch 672 of 2000 took 0.057s
  training loss:		0.026429
  validation loss:		0.353277
  validation accuracy:		92.72 %
Epoch 673 of 2000 took 0.057s
  training loss:		0.026452
  validation loss:		0.378142
  validation accuracy:		92.93 %
Epoch 674 of 2000 took 0.057s
  training loss:		0.025408
  validation loss:		0.348017
  validation accuracy:		93.15 %
Epoch 675 of 2000 took 0.056s
  training loss:		0.026404
  validation loss:		0.362878
  validation accuracy:		92.72 %
Epoch 676 of 2000 took 0.057s
  training loss:		0.025573
  validation loss:		0.361364
  validation accuracy:		92.83 %
Epoch 677 of 2000 took 0.057s
  training loss:		0.025441
  validation loss:		0.360216
  validation accuracy:		92.83 %
Epoch 678 of 2000 took 0.057s
  training loss:		0.024188
  validation loss:		0.380070
  validation accuracy:		92.17 %
Epoch 679 of 2000 took 0.057s
  training loss:		0.026186
  validation loss:		0.366356
  validation accuracy:		92.28 %
Epoch 680 of 2000 took 0.057s
  training loss:		0.024914
  validation loss:		0.374698
  validation accuracy:		92.61 %
Epoch 681 of 2000 took 0.057s
  training loss:		0.025451
  validation loss:		0.370161
  validation accuracy:		92.93 %
Epoch 682 of 2000 took 0.057s
  training loss:		0.024606
  validation loss:		0.365435
  validation accuracy:		92.93 %
Epoch 683 of 2000 took 0.057s
  training loss:		0.024334
  validation loss:		0.373578
  validation accuracy:		92.61 %
Epoch 684 of 2000 took 0.057s
  training loss:		0.025224
  validation loss:		0.362826
  validation accuracy:		92.83 %
Epoch 685 of 2000 took 0.057s
  training loss:		0.025053
  validation loss:		0.377377
  validation accuracy:		92.61 %
Epoch 686 of 2000 took 0.057s
  training loss:		0.025522
  validation loss:		0.382237
  validation accuracy:		92.28 %
Epoch 687 of 2000 took 0.057s
  training loss:		0.025943
  validation loss:		0.376572
  validation accuracy:		92.72 %
Epoch 688 of 2000 took 0.057s
  training loss:		0.023947
  validation loss:		0.377371
  validation accuracy:		92.61 %
Epoch 689 of 2000 took 0.057s
  training loss:		0.025443
  validation loss:		0.384156
  validation accuracy:		92.39 %
Epoch 690 of 2000 took 0.057s
  training loss:		0.024337
  validation loss:		0.361846
  validation accuracy:		93.04 %
Epoch 691 of 2000 took 0.057s
  training loss:		0.025263
  validation loss:		0.380958
  validation accuracy:		92.61 %
Epoch 692 of 2000 took 0.056s
  training loss:		0.024550
  validation loss:		0.375003
  validation accuracy:		92.61 %
Epoch 693 of 2000 took 0.058s
  training loss:		0.023578
  validation loss:		0.367239
  validation accuracy:		92.61 %
Epoch 694 of 2000 took 0.057s
  training loss:		0.024904
  validation loss:		0.369729
  validation accuracy:		92.83 %
Epoch 695 of 2000 took 0.055s
  training loss:		0.024887
  validation loss:		0.382788
  validation accuracy:		92.72 %
Epoch 696 of 2000 took 0.056s
  training loss:		0.023772
  validation loss:		0.382967
  validation accuracy:		92.39 %
Epoch 697 of 2000 took 0.057s
  training loss:		0.023770
  validation loss:		0.369676
  validation accuracy:		92.83 %
Epoch 698 of 2000 took 0.057s
  training loss:		0.023717
  validation loss:		0.373015
  validation accuracy:		92.61 %
Epoch 699 of 2000 took 0.056s
  training loss:		0.025115
  validation loss:		0.363497
  validation accuracy:		92.93 %
Epoch 700 of 2000 took 0.056s
  training loss:		0.023985
  validation loss:		0.367801
  validation accuracy:		92.83 %
Epoch 701 of 2000 took 0.057s
  training loss:		0.024635
  validation loss:		0.390564
  validation accuracy:		92.39 %
Epoch 702 of 2000 took 0.057s
  training loss:		0.024131
  validation loss:		0.381745
  validation accuracy:		92.93 %
Epoch 703 of 2000 took 0.057s
  training loss:		0.023659
  validation loss:		0.399342
  validation accuracy:		92.28 %
Epoch 704 of 2000 took 0.056s
  training loss:		0.024001
  validation loss:		0.376813
  validation accuracy:		92.83 %
Epoch 705 of 2000 took 0.057s
  training loss:		0.024005
  validation loss:		0.374498
  validation accuracy:		92.61 %
Epoch 706 of 2000 took 0.057s
  training loss:		0.023415
  validation loss:		0.394407
  validation accuracy:		92.07 %
Epoch 707 of 2000 took 0.057s
  training loss:		0.023823
  validation loss:		0.372244
  validation accuracy:		92.83 %
Epoch 708 of 2000 took 0.055s
  training loss:		0.023337
  validation loss:		0.380506
  validation accuracy:		92.50 %
Epoch 709 of 2000 took 0.055s
  training loss:		0.022991
  validation loss:		0.388273
  validation accuracy:		92.72 %
Epoch 710 of 2000 took 0.057s
  training loss:		0.023880
  validation loss:		0.372697
  validation accuracy:		92.72 %
Epoch 711 of 2000 took 0.057s
  training loss:		0.022174
  validation loss:		0.385876
  validation accuracy:		92.17 %
Epoch 712 of 2000 took 0.057s
  training loss:		0.023688
  validation loss:		0.381621
  validation accuracy:		92.39 %
Epoch 713 of 2000 took 0.057s
  training loss:		0.022621
  validation loss:		0.379773
  validation accuracy:		92.83 %
Epoch 714 of 2000 took 0.059s
  training loss:		0.022923
  validation loss:		0.377853
  validation accuracy:		92.61 %
Epoch 715 of 2000 took 0.056s
  training loss:		0.023679
  validation loss:		0.375729
  validation accuracy:		92.83 %
Epoch 716 of 2000 took 0.056s
  training loss:		0.022945
  validation loss:		0.384240
  validation accuracy:		92.61 %
Epoch 717 of 2000 took 0.056s
  training loss:		0.022950
  validation loss:		0.374829
  validation accuracy:		92.72 %
Epoch 718 of 2000 took 0.056s
  training loss:		0.023044
  validation loss:		0.390014
  validation accuracy:		92.50 %
Epoch 719 of 2000 took 0.056s
  training loss:		0.022536
  validation loss:		0.382350
  validation accuracy:		92.61 %
Epoch 720 of 2000 took 0.056s
  training loss:		0.022022
  validation loss:		0.383737
  validation accuracy:		92.72 %
Epoch 721 of 2000 took 0.059s
  training loss:		0.022740
  validation loss:		0.377458
  validation accuracy:		92.72 %
Epoch 722 of 2000 took 0.057s
  training loss:		0.022541
  validation loss:		0.368967
  validation accuracy:		93.04 %
Epoch 723 of 2000 took 0.058s
  training loss:		0.022719
  validation loss:		0.399082
  validation accuracy:		92.50 %
Epoch 724 of 2000 took 0.056s
  training loss:		0.022730
  validation loss:		0.392421
  validation accuracy:		91.96 %
Epoch 725 of 2000 took 0.058s
  training loss:		0.023477
  validation loss:		0.390881
  validation accuracy:		92.72 %
Epoch 726 of 2000 took 0.058s
  training loss:		0.022518
  validation loss:		0.390447
  validation accuracy:		92.61 %
Epoch 727 of 2000 took 0.058s
  training loss:		0.021753
  validation loss:		0.394089
  validation accuracy:		92.72 %
Epoch 728 of 2000 took 0.057s
  training loss:		0.023093
  validation loss:		0.393768
  validation accuracy:		92.39 %
Epoch 729 of 2000 took 0.059s
  training loss:		0.021060
  validation loss:		0.377133
  validation accuracy:		92.83 %
Epoch 730 of 2000 took 0.058s
  training loss:		0.022551
  validation loss:		0.377490
  validation accuracy:		92.72 %
Epoch 731 of 2000 took 0.059s
  training loss:		0.022166
  validation loss:		0.382276
  validation accuracy:		92.93 %
Epoch 732 of 2000 took 0.058s
  training loss:		0.022522
  validation loss:		0.378464
  validation accuracy:		92.83 %
Epoch 733 of 2000 took 0.059s
  training loss:		0.021953
  validation loss:		0.387027
  validation accuracy:		92.61 %
Epoch 734 of 2000 took 0.058s
  training loss:		0.022009
  validation loss:		0.411932
  validation accuracy:		92.07 %
Epoch 735 of 2000 took 0.057s
  training loss:		0.020604
  validation loss:		0.394358
  validation accuracy:		92.61 %
Epoch 736 of 2000 took 0.059s
  training loss:		0.021468
  validation loss:		0.394192
  validation accuracy:		92.17 %
Epoch 737 of 2000 took 0.058s
  training loss:		0.021647
  validation loss:		0.381191
  validation accuracy:		92.83 %
Epoch 738 of 2000 took 0.058s
  training loss:		0.021293
  validation loss:		0.392888
  validation accuracy:		92.39 %
Epoch 739 of 2000 took 0.058s
  training loss:		0.020812
  validation loss:		0.389501
  validation accuracy:		92.72 %
Epoch 740 of 2000 took 0.058s
  training loss:		0.021683
  validation loss:		0.399559
  validation accuracy:		92.50 %
Epoch 741 of 2000 took 0.057s
  training loss:		0.020951
  validation loss:		0.377146
  validation accuracy:		92.83 %
Epoch 742 of 2000 took 0.057s
  training loss:		0.021641
  validation loss:		0.396284
  validation accuracy:		92.17 %
Epoch 743 of 2000 took 0.057s
  training loss:		0.021465
  validation loss:		0.403996
  validation accuracy:		92.50 %
Epoch 744 of 2000 took 0.057s
  training loss:		0.021829
  validation loss:		0.390501
  validation accuracy:		92.72 %
Epoch 745 of 2000 took 0.057s
  training loss:		0.022030
  validation loss:		0.400768
  validation accuracy:		92.39 %
Epoch 746 of 2000 took 0.057s
  training loss:		0.021272
  validation loss:		0.379786
  validation accuracy:		92.50 %
Epoch 747 of 2000 took 0.057s
  training loss:		0.021530
  validation loss:		0.385023
  validation accuracy:		92.72 %
Epoch 748 of 2000 took 0.057s
  training loss:		0.020797
  validation loss:		0.414012
  validation accuracy:		92.28 %
Epoch 749 of 2000 took 0.057s
  training loss:		0.020178
  validation loss:		0.384117
  validation accuracy:		92.72 %
Epoch 750 of 2000 took 0.058s
  training loss:		0.021300
  validation loss:		0.389351
  validation accuracy:		92.61 %
Epoch 751 of 2000 took 0.058s
  training loss:		0.020666
  validation loss:		0.386433
  validation accuracy:		92.83 %
Epoch 752 of 2000 took 0.058s
  training loss:		0.021030
  validation loss:		0.407839
  validation accuracy:		92.17 %
Epoch 753 of 2000 took 0.056s
  training loss:		0.020632
  validation loss:		0.386390
  validation accuracy:		92.07 %
Epoch 754 of 2000 took 0.058s
  training loss:		0.021240
  validation loss:		0.402379
  validation accuracy:		92.28 %
Epoch 755 of 2000 took 0.058s
  training loss:		0.020555
  validation loss:		0.397152
  validation accuracy:		92.50 %
Epoch 756 of 2000 took 0.057s
  training loss:		0.020855
  validation loss:		0.403809
  validation accuracy:		92.50 %
Epoch 757 of 2000 took 0.057s
  training loss:		0.019888
  validation loss:		0.401841
  validation accuracy:		92.50 %
Epoch 758 of 2000 took 0.057s
  training loss:		0.020815
  validation loss:		0.386231
  validation accuracy:		92.72 %
Epoch 759 of 2000 took 0.057s
  training loss:		0.018580
  validation loss:		0.394700
  validation accuracy:		92.50 %
Epoch 760 of 2000 took 0.057s
  training loss:		0.018746
  validation loss:		0.396523
  validation accuracy:		92.50 %
Epoch 761 of 2000 took 0.057s
  training loss:		0.019726
  validation loss:		0.405047
  validation accuracy:		92.28 %
Epoch 762 of 2000 took 0.057s
  training loss:		0.019912
  validation loss:		0.387288
  validation accuracy:		92.83 %
Epoch 763 of 2000 took 0.057s
  training loss:		0.020357
  validation loss:		0.384095
  validation accuracy:		92.93 %
Epoch 764 of 2000 took 0.057s
  training loss:		0.020619
  validation loss:		0.397593
  validation accuracy:		92.39 %
Epoch 765 of 2000 took 0.057s
  training loss:		0.020094
  validation loss:		0.390647
  validation accuracy:		92.61 %
Epoch 766 of 2000 took 0.057s
  training loss:		0.019727
  validation loss:		0.393635
  validation accuracy:		92.39 %
Epoch 767 of 2000 took 0.057s
  training loss:		0.020632
  validation loss:		0.401267
  validation accuracy:		92.50 %
Epoch 768 of 2000 took 0.057s
  training loss:		0.019467
  validation loss:		0.417561
  validation accuracy:		92.07 %
Epoch 769 of 2000 took 0.057s
  training loss:		0.019517
  validation loss:		0.404991
  validation accuracy:		92.50 %
Epoch 770 of 2000 took 0.057s
  training loss:		0.019422
  validation loss:		0.390464
  validation accuracy:		92.39 %
Epoch 771 of 2000 took 0.057s
  training loss:		0.020109
  validation loss:		0.411779
  validation accuracy:		92.28 %
Epoch 772 of 2000 took 0.057s
  training loss:		0.020398
  validation loss:		0.397773
  validation accuracy:		92.72 %
Epoch 773 of 2000 took 0.057s
  training loss:		0.019732
  validation loss:		0.394936
  validation accuracy:		92.61 %
Epoch 774 of 2000 took 0.057s
  training loss:		0.020100
  validation loss:		0.411241
  validation accuracy:		92.28 %
Epoch 775 of 2000 took 0.057s
  training loss:		0.019673
  validation loss:		0.391486
  validation accuracy:		92.50 %
Epoch 776 of 2000 took 0.057s
  training loss:		0.019281
  validation loss:		0.408622
  validation accuracy:		92.61 %
Epoch 777 of 2000 took 0.057s
  training loss:		0.019833
  validation loss:		0.408960
  validation accuracy:		92.61 %
Epoch 778 of 2000 took 0.057s
  training loss:		0.019034
  validation loss:		0.416132
  validation accuracy:		92.39 %
Epoch 779 of 2000 took 0.057s
  training loss:		0.018846
  validation loss:		0.411809
  validation accuracy:		92.28 %
Epoch 780 of 2000 took 0.057s
  training loss:		0.018760
  validation loss:		0.391733
  validation accuracy:		92.93 %
Epoch 781 of 2000 took 0.057s
  training loss:		0.019399
  validation loss:		0.400584
  validation accuracy:		92.61 %
Epoch 782 of 2000 took 0.058s
  training loss:		0.019341
  validation loss:		0.390128
  validation accuracy:		92.72 %
Epoch 783 of 2000 took 0.056s
  training loss:		0.019106
  validation loss:		0.407312
  validation accuracy:		92.61 %
Epoch 784 of 2000 took 0.059s
  training loss:		0.019134
  validation loss:		0.396299
  validation accuracy:		92.39 %
Epoch 785 of 2000 took 0.056s
  training loss:		0.018696
  validation loss:		0.413688
  validation accuracy:		92.61 %
Epoch 786 of 2000 took 0.056s
  training loss:		0.019275
  validation loss:		0.410661
  validation accuracy:		92.61 %
Epoch 787 of 2000 took 0.057s
  training loss:		0.019109
  validation loss:		0.408555
  validation accuracy:		92.28 %
Epoch 788 of 2000 took 0.059s
  training loss:		0.019299
  validation loss:		0.407616
  validation accuracy:		92.61 %
Epoch 789 of 2000 took 0.059s
  training loss:		0.018737
  validation loss:		0.411149
  validation accuracy:		91.85 %
Epoch 790 of 2000 took 0.060s
  training loss:		0.018946
  validation loss:		0.404206
  validation accuracy:		92.28 %
Epoch 791 of 2000 took 0.058s
  training loss:		0.018577
  validation loss:		0.401782
  validation accuracy:		92.61 %
Epoch 792 of 2000 took 0.059s
  training loss:		0.018085
  validation loss:		0.417785
  validation accuracy:		92.50 %
Epoch 793 of 2000 took 0.057s
  training loss:		0.019139
  validation loss:		0.407961
  validation accuracy:		91.96 %
Epoch 794 of 2000 took 0.057s
  training loss:		0.018871
  validation loss:		0.405153
  validation accuracy:		92.39 %
Epoch 795 of 2000 took 0.058s
  training loss:		0.018646
  validation loss:		0.415773
  validation accuracy:		92.17 %
Epoch 796 of 2000 took 0.058s
  training loss:		0.018009
  validation loss:		0.409084
  validation accuracy:		92.72 %
Epoch 797 of 2000 took 0.058s
  training loss:		0.017977
  validation loss:		0.412469
  validation accuracy:		92.50 %
Epoch 798 of 2000 took 0.058s
  training loss:		0.019200
  validation loss:		0.416560
  validation accuracy:		92.28 %
Epoch 799 of 2000 took 0.058s
  training loss:		0.017339
  validation loss:		0.411251
  validation accuracy:		92.07 %
Epoch 800 of 2000 took 0.058s
  training loss:		0.018299
  validation loss:		0.422210
  validation accuracy:		92.61 %
Epoch 801 of 2000 took 0.059s
  training loss:		0.018200
  validation loss:		0.411181
  validation accuracy:		92.17 %
Epoch 802 of 2000 took 0.057s
  training loss:		0.018429
  validation loss:		0.406248
  validation accuracy:		92.39 %
Epoch 803 of 2000 took 0.059s
  training loss:		0.018250
  validation loss:		0.421942
  validation accuracy:		92.28 %
Epoch 804 of 2000 took 0.057s
  training loss:		0.018323
  validation loss:		0.427163
  validation accuracy:		92.28 %
Epoch 805 of 2000 took 0.057s
  training loss:		0.017938
  validation loss:		0.407269
  validation accuracy:		92.17 %
Epoch 806 of 2000 took 0.057s
  training loss:		0.017482
  validation loss:		0.422019
  validation accuracy:		92.28 %
Epoch 807 of 2000 took 0.057s
  training loss:		0.016969
  validation loss:		0.404180
  validation accuracy:		92.17 %
Epoch 808 of 2000 took 0.057s
  training loss:		0.018846
  validation loss:		0.415672
  validation accuracy:		92.28 %
Epoch 809 of 2000 took 0.057s
  training loss:		0.017920
  validation loss:		0.411407
  validation accuracy:		92.28 %
Epoch 810 of 2000 took 0.057s
  training loss:		0.017879
  validation loss:		0.415641
  validation accuracy:		92.39 %
Epoch 811 of 2000 took 0.057s
  training loss:		0.017543
  validation loss:		0.404878
  validation accuracy:		92.83 %
Epoch 812 of 2000 took 0.058s
  training loss:		0.017267
  validation loss:		0.412178
  validation accuracy:		92.07 %
Epoch 813 of 2000 took 0.057s
  training loss:		0.017627
  validation loss:		0.423322
  validation accuracy:		92.17 %
Epoch 814 of 2000 took 0.057s
  training loss:		0.017723
  validation loss:		0.422960
  validation accuracy:		92.17 %
Epoch 815 of 2000 took 0.057s
  training loss:		0.016017
  validation loss:		0.434078
  validation accuracy:		92.39 %
Epoch 816 of 2000 took 0.057s
  training loss:		0.017155
  validation loss:		0.432150
  validation accuracy:		92.28 %
Epoch 817 of 2000 took 0.057s
  training loss:		0.017574
  validation loss:		0.419228
  validation accuracy:		92.61 %
Epoch 818 of 2000 took 0.057s
  training loss:		0.017065
  validation loss:		0.420558
  validation accuracy:		91.96 %
Epoch 819 of 2000 took 0.057s
  training loss:		0.016429
  validation loss:		0.417012
  validation accuracy:		92.39 %
Epoch 820 of 2000 took 0.057s
  training loss:		0.017680
  validation loss:		0.420289
  validation accuracy:		92.50 %
Epoch 821 of 2000 took 0.057s
  training loss:		0.017594
  validation loss:		0.425202
  validation accuracy:		91.85 %
Epoch 822 of 2000 took 0.057s
  training loss:		0.017064
  validation loss:		0.417096
  validation accuracy:		92.50 %
Epoch 823 of 2000 took 0.057s
  training loss:		0.017314
  validation loss:		0.415455
  validation accuracy:		91.96 %
Epoch 824 of 2000 took 0.058s
  training loss:		0.017717
  validation loss:		0.419988
  validation accuracy:		92.28 %
Epoch 825 of 2000 took 0.057s
  training loss:		0.017135
  validation loss:		0.422592
  validation accuracy:		92.39 %
Epoch 826 of 2000 took 0.057s
  training loss:		0.017671
  validation loss:		0.418889
  validation accuracy:		92.28 %
Epoch 827 of 2000 took 0.057s
  training loss:		0.016679
  validation loss:		0.426709
  validation accuracy:		91.96 %
Epoch 828 of 2000 took 0.057s
  training loss:		0.017076
  validation loss:		0.436608
  validation accuracy:		92.07 %
Epoch 829 of 2000 took 0.057s
  training loss:		0.017196
  validation loss:		0.421302
  validation accuracy:		92.39 %
Epoch 830 of 2000 took 0.057s
  training loss:		0.016867
  validation loss:		0.433840
  validation accuracy:		92.07 %
Epoch 831 of 2000 took 0.057s
  training loss:		0.016698
  validation loss:		0.410041
  validation accuracy:		92.17 %
Epoch 832 of 2000 took 0.057s
  training loss:		0.016803
  validation loss:		0.428158
  validation accuracy:		92.28 %
Epoch 833 of 2000 took 0.058s
  training loss:		0.016646
  validation loss:		0.439311
  validation accuracy:		92.28 %
Epoch 834 of 2000 took 0.058s
  training loss:		0.016796
  validation loss:		0.419675
  validation accuracy:		92.07 %
Epoch 835 of 2000 took 0.057s
  training loss:		0.017049
  validation loss:		0.418090
  validation accuracy:		92.39 %
Epoch 836 of 2000 took 0.058s
  training loss:		0.016015
  validation loss:		0.414580
  validation accuracy:		92.07 %
Epoch 837 of 2000 took 0.058s
  training loss:		0.016697
  validation loss:		0.413931
  validation accuracy:		92.28 %
Epoch 838 of 2000 took 0.058s
  training loss:		0.017659
  validation loss:		0.424108
  validation accuracy:		91.96 %
Epoch 839 of 2000 took 0.058s
  training loss:		0.016683
  validation loss:		0.425320
  validation accuracy:		91.96 %
Epoch 840 of 2000 took 0.058s
  training loss:		0.016154
  validation loss:		0.436481
  validation accuracy:		92.17 %
Epoch 841 of 2000 took 0.057s
  training loss:		0.016448
  validation loss:		0.439509
  validation accuracy:		92.28 %
Epoch 842 of 2000 took 0.058s
  training loss:		0.016770
  validation loss:		0.440119
  validation accuracy:		92.39 %
Epoch 843 of 2000 took 0.060s
  training loss:		0.016794
  validation loss:		0.438754
  validation accuracy:		91.96 %
Epoch 844 of 2000 took 0.059s
  training loss:		0.016318
  validation loss:		0.429700
  validation accuracy:		91.74 %
Epoch 845 of 2000 took 0.059s
  training loss:		0.016192
  validation loss:		0.432252
  validation accuracy:		92.07 %
Epoch 846 of 2000 took 0.055s
  training loss:		0.016061
  validation loss:		0.425745
  validation accuracy:		92.28 %
Epoch 847 of 2000 took 0.058s
  training loss:		0.016661
  validation loss:		0.440416
  validation accuracy:		92.39 %
Epoch 848 of 2000 took 0.057s
  training loss:		0.016210
  validation loss:		0.427796
  validation accuracy:		92.07 %
Epoch 849 of 2000 took 0.057s
  training loss:		0.015709
  validation loss:		0.416182
  validation accuracy:		92.39 %
Epoch 850 of 2000 took 0.055s
  training loss:		0.016484
  validation loss:		0.421405
  validation accuracy:		92.28 %
Epoch 851 of 2000 took 0.057s
  training loss:		0.015683
  validation loss:		0.435036
  validation accuracy:		92.50 %
Epoch 852 of 2000 took 0.057s
  training loss:		0.015236
  validation loss:		0.428815
  validation accuracy:		92.39 %
Epoch 853 of 2000 took 0.057s
  training loss:		0.015345
  validation loss:		0.437209
  validation accuracy:		91.96 %
Epoch 854 of 2000 took 0.057s
  training loss:		0.015033
  validation loss:		0.443568
  validation accuracy:		92.17 %
Epoch 855 of 2000 took 0.057s
  training loss:		0.015702
  validation loss:		0.435486
  validation accuracy:		92.28 %
Epoch 856 of 2000 took 0.056s
  training loss:		0.015523
  validation loss:		0.440293
  validation accuracy:		92.17 %
Epoch 857 of 2000 took 0.057s
  training loss:		0.015603
  validation loss:		0.433758
  validation accuracy:		92.28 %
Epoch 858 of 2000 took 0.056s
  training loss:		0.014974
  validation loss:		0.441972
  validation accuracy:		92.28 %
Epoch 859 of 2000 took 0.057s
  training loss:		0.015262
  validation loss:		0.443675
  validation accuracy:		92.17 %
Epoch 860 of 2000 took 0.056s
  training loss:		0.015198
  validation loss:		0.442494
  validation accuracy:		92.17 %
Epoch 861 of 2000 took 0.057s
  training loss:		0.015658
  validation loss:		0.429968
  validation accuracy:		92.17 %
Epoch 862 of 2000 took 0.057s
  training loss:		0.015708
  validation loss:		0.421640
  validation accuracy:		92.39 %
Epoch 863 of 2000 took 0.057s
  training loss:		0.015687
  validation loss:		0.433515
  validation accuracy:		92.17 %
Epoch 864 of 2000 took 0.057s
  training loss:		0.016138
  validation loss:		0.436743
  validation accuracy:		92.17 %
Epoch 865 of 2000 took 0.057s
  training loss:		0.015149
  validation loss:		0.426397
  validation accuracy:		92.28 %
Epoch 866 of 2000 took 0.057s
  training loss:		0.015970
  validation loss:		0.432898
  validation accuracy:		92.07 %
Epoch 867 of 2000 took 0.057s
  training loss:		0.015475
  validation loss:		0.434935
  validation accuracy:		91.96 %
Epoch 868 of 2000 took 0.057s
  training loss:		0.015320
  validation loss:		0.431133
  validation accuracy:		91.96 %
Epoch 869 of 2000 took 0.057s
  training loss:		0.015159
  validation loss:		0.442945
  validation accuracy:		92.17 %
Epoch 870 of 2000 took 0.055s
  training loss:		0.015469
  validation loss:		0.454958
  validation accuracy:		92.28 %
Epoch 871 of 2000 took 0.057s
  training loss:		0.015384
  validation loss:		0.454743
  validation accuracy:		92.28 %
Epoch 872 of 2000 took 0.056s
  training loss:		0.015631
  validation loss:		0.448372
  validation accuracy:		92.17 %
Epoch 873 of 2000 took 0.057s
  training loss:		0.014833
  validation loss:		0.430828
  validation accuracy:		91.96 %
Epoch 874 of 2000 took 0.057s
  training loss:		0.015077
  validation loss:		0.432939
  validation accuracy:		92.17 %
Epoch 875 of 2000 took 0.057s
  training loss:		0.015317
  validation loss:		0.441322
  validation accuracy:		92.07 %
Epoch 876 of 2000 took 0.057s
  training loss:		0.014606
  validation loss:		0.438308
  validation accuracy:		92.07 %
Epoch 877 of 2000 took 0.057s
  training loss:		0.014916
  validation loss:		0.443008
  validation accuracy:		91.85 %
Epoch 878 of 2000 took 0.057s
  training loss:		0.014720
  validation loss:		0.442388
  validation accuracy:		92.50 %
Epoch 879 of 2000 took 0.057s
  training loss:		0.014877
  validation loss:		0.435548
  validation accuracy:		92.17 %
Epoch 880 of 2000 took 0.057s
  training loss:		0.014995
  validation loss:		0.439115
  validation accuracy:		92.07 %
Epoch 881 of 2000 took 0.057s
  training loss:		0.015252
  validation loss:		0.442577
  validation accuracy:		91.96 %
Epoch 882 of 2000 took 0.057s
  training loss:		0.014703
  validation loss:		0.458702
  validation accuracy:		92.17 %
Epoch 883 of 2000 took 0.057s
  training loss:		0.014749
  validation loss:		0.441017
  validation accuracy:		92.17 %
Epoch 884 of 2000 took 0.057s
  training loss:		0.015077
  validation loss:		0.433339
  validation accuracy:		92.07 %
Epoch 885 of 2000 took 0.057s
  training loss:		0.014621
  validation loss:		0.456665
  validation accuracy:		92.28 %
Epoch 886 of 2000 took 0.057s
  training loss:		0.014774
  validation loss:		0.439712
  validation accuracy:		92.07 %
Epoch 887 of 2000 took 0.057s
  training loss:		0.014695
  validation loss:		0.463484
  validation accuracy:		92.17 %
Epoch 888 of 2000 took 0.057s
  training loss:		0.014756
  validation loss:		0.437344
  validation accuracy:		92.28 %
Epoch 889 of 2000 took 0.058s
  training loss:		0.014077
  validation loss:		0.448404
  validation accuracy:		91.96 %
Epoch 890 of 2000 took 0.055s
  training loss:		0.014174
  validation loss:		0.430760
  validation accuracy:		92.39 %
Epoch 891 of 2000 took 0.056s
  training loss:		0.014924
  validation loss:		0.454039
  validation accuracy:		91.85 %
Epoch 892 of 2000 took 0.058s
  training loss:		0.014440
  validation loss:		0.460159
  validation accuracy:		92.17 %
Epoch 893 of 2000 took 0.057s
  training loss:		0.014416
  validation loss:		0.457199
  validation accuracy:		91.96 %
Epoch 894 of 2000 took 0.057s
  training loss:		0.014213
  validation loss:		0.439506
  validation accuracy:		92.28 %
Epoch 895 of 2000 took 0.058s
  training loss:		0.014620
  validation loss:		0.447693
  validation accuracy:		92.28 %
Epoch 896 of 2000 took 0.057s
  training loss:		0.014257
  validation loss:		0.443325
  validation accuracy:		92.17 %
Epoch 897 of 2000 took 0.058s
  training loss:		0.014172
  validation loss:		0.448683
  validation accuracy:		91.96 %
Epoch 898 of 2000 took 0.057s
  training loss:		0.014202
  validation loss:		0.445756
  validation accuracy:		92.28 %
Epoch 899 of 2000 took 0.058s
  training loss:		0.014312
  validation loss:		0.440514
  validation accuracy:		92.17 %
Epoch 900 of 2000 took 0.055s
  training loss:		0.014261
  validation loss:		0.451301
  validation accuracy:		91.96 %
Epoch 901 of 2000 took 0.056s
  training loss:		0.013903
  validation loss:		0.453933
  validation accuracy:		92.07 %
Epoch 902 of 2000 took 0.058s
  training loss:		0.014051
  validation loss:		0.446218
  validation accuracy:		92.28 %
Epoch 903 of 2000 took 0.057s
  training loss:		0.014484
  validation loss:		0.457673
  validation accuracy:		92.17 %
Epoch 904 of 2000 took 0.057s
  training loss:		0.014681
  validation loss:		0.446160
  validation accuracy:		92.07 %
Epoch 905 of 2000 took 0.057s
  training loss:		0.014220
  validation loss:		0.445227
  validation accuracy:		92.17 %
Epoch 906 of 2000 took 0.059s
  training loss:		0.013464
  validation loss:		0.444907
  validation accuracy:		92.07 %
Epoch 907 of 2000 took 0.057s
  training loss:		0.014026
  validation loss:		0.449296
  validation accuracy:		92.07 %
Epoch 908 of 2000 took 0.058s
  training loss:		0.014138
  validation loss:		0.448993
  validation accuracy:		91.96 %
Epoch 909 of 2000 took 0.057s
  training loss:		0.013828
  validation loss:		0.450722
  validation accuracy:		92.28 %
Epoch 910 of 2000 took 0.059s
  training loss:		0.013517
  validation loss:		0.459209
  validation accuracy:		92.17 %
Epoch 911 of 2000 took 0.058s
  training loss:		0.014376
  validation loss:		0.470131
  validation accuracy:		91.96 %
Epoch 912 of 2000 took 0.059s
  training loss:		0.013918
  validation loss:		0.449138
  validation accuracy:		91.96 %
Epoch 913 of 2000 took 0.059s
  training loss:		0.013289
  validation loss:		0.447556
  validation accuracy:		92.17 %
Epoch 914 of 2000 took 0.059s
  training loss:		0.013676
  validation loss:		0.453453
  validation accuracy:		91.85 %
Epoch 915 of 2000 took 0.058s
  training loss:		0.013934
  validation loss:		0.457152
  validation accuracy:		92.07 %
Epoch 916 of 2000 took 0.059s
  training loss:		0.013485
  validation loss:		0.463421
  validation accuracy:		92.28 %
Epoch 917 of 2000 took 0.058s
  training loss:		0.013553
  validation loss:		0.470389
  validation accuracy:		92.39 %
Epoch 918 of 2000 took 0.058s
  training loss:		0.013214
  validation loss:		0.447522
  validation accuracy:		91.96 %
Epoch 919 of 2000 took 0.058s
  training loss:		0.013280
  validation loss:		0.468262
  validation accuracy:		92.17 %
Epoch 920 of 2000 took 0.058s
  training loss:		0.013110
  validation loss:		0.458923
  validation accuracy:		91.74 %
Epoch 921 of 2000 took 0.058s
  training loss:		0.013193
  validation loss:		0.447700
  validation accuracy:		92.72 %
Epoch 922 of 2000 took 0.058s
  training loss:		0.013682
  validation loss:		0.457845
  validation accuracy:		92.17 %
Epoch 923 of 2000 took 0.058s
  training loss:		0.013367
  validation loss:		0.459548
  validation accuracy:		91.96 %
Epoch 924 of 2000 took 0.058s
  training loss:		0.013295
  validation loss:		0.454249
  validation accuracy:		91.96 %
Epoch 925 of 2000 took 0.057s
  training loss:		0.013491
  validation loss:		0.460662
  validation accuracy:		91.74 %
Epoch 926 of 2000 took 0.057s
  training loss:		0.012867
  validation loss:		0.451156
  validation accuracy:		92.07 %
Epoch 927 of 2000 took 0.057s
  training loss:		0.013596
  validation loss:		0.456711
  validation accuracy:		92.28 %
Epoch 928 of 2000 took 0.057s
  training loss:		0.013346
  validation loss:		0.449562
  validation accuracy:		91.96 %
Epoch 929 of 2000 took 0.057s
  training loss:		0.013028
  validation loss:		0.469410
  validation accuracy:		92.07 %
Epoch 930 of 2000 took 0.057s
  training loss:		0.012892
  validation loss:		0.463659
  validation accuracy:		91.74 %
Epoch 931 of 2000 took 0.057s
  training loss:		0.013423
  validation loss:		0.460339
  validation accuracy:		91.85 %
Epoch 932 of 2000 took 0.057s
  training loss:		0.012806
  validation loss:		0.456816
  validation accuracy:		91.74 %
Epoch 933 of 2000 took 0.057s
  training loss:		0.012652
  validation loss:		0.477110
  validation accuracy:		91.96 %
Epoch 934 of 2000 took 0.057s
  training loss:		0.012923
  validation loss:		0.464619
  validation accuracy:		91.63 %
Epoch 935 of 2000 took 0.057s
  training loss:		0.012426
  validation loss:		0.470576
  validation accuracy:		92.17 %
Epoch 936 of 2000 took 0.057s
  training loss:		0.013052
  validation loss:		0.472199
  validation accuracy:		92.28 %
Epoch 937 of 2000 took 0.060s
  training loss:		0.012781
  validation loss:		0.463525
  validation accuracy:		91.96 %
Epoch 938 of 2000 took 0.057s
  training loss:		0.012801
  validation loss:		0.470487
  validation accuracy:		91.74 %
Epoch 939 of 2000 took 0.058s
  training loss:		0.012758
  validation loss:		0.460859
  validation accuracy:		92.39 %
Epoch 940 of 2000 took 0.057s
  training loss:		0.012724
  validation loss:		0.465729
  validation accuracy:		91.85 %
Epoch 941 of 2000 took 0.057s
  training loss:		0.012558
  validation loss:		0.465905
  validation accuracy:		92.28 %
Epoch 942 of 2000 took 0.057s
  training loss:		0.012577
  validation loss:		0.460565
  validation accuracy:		91.63 %
Epoch 943 of 2000 took 0.055s
  training loss:		0.012865
  validation loss:		0.457002
  validation accuracy:		91.85 %
Epoch 944 of 2000 took 0.057s
  training loss:		0.012877
  validation loss:		0.475719
  validation accuracy:		91.74 %
Epoch 945 of 2000 took 0.055s
  training loss:		0.012619
  validation loss:		0.466233
  validation accuracy:		92.07 %
Epoch 946 of 2000 took 0.057s
  training loss:		0.012460
  validation loss:		0.465118
  validation accuracy:		91.74 %
Epoch 947 of 2000 took 0.057s
  training loss:		0.012846
  validation loss:		0.460133
  validation accuracy:		91.85 %
Epoch 948 of 2000 took 0.057s
  training loss:		0.012401
  validation loss:		0.474138
  validation accuracy:		92.07 %
Epoch 949 of 2000 took 0.057s
  training loss:		0.012623
  validation loss:		0.468192
  validation accuracy:		91.74 %
Epoch 950 of 2000 took 0.057s
  training loss:		0.012366
  validation loss:		0.480915
  validation accuracy:		91.85 %
Epoch 951 of 2000 took 0.057s
  training loss:		0.012345
  validation loss:		0.460139
  validation accuracy:		92.39 %
Epoch 952 of 2000 took 0.057s
  training loss:		0.012346
  validation loss:		0.461136
  validation accuracy:		91.96 %
Epoch 953 of 2000 took 0.057s
  training loss:		0.013118
  validation loss:		0.458361
  validation accuracy:		91.85 %
Epoch 954 of 2000 took 0.057s
  training loss:		0.012265
  validation loss:		0.454605
  validation accuracy:		91.96 %
Epoch 955 of 2000 took 0.057s
  training loss:		0.012166
  validation loss:		0.475900
  validation accuracy:		91.85 %
Epoch 956 of 2000 took 0.055s
  training loss:		0.012350
  validation loss:		0.475217
  validation accuracy:		92.07 %
Epoch 957 of 2000 took 0.057s
  training loss:		0.012181
  validation loss:		0.469644
  validation accuracy:		91.85 %
Epoch 958 of 2000 took 0.056s
  training loss:		0.012275
  validation loss:		0.458385
  validation accuracy:		92.07 %
Epoch 959 of 2000 took 0.057s
  training loss:		0.012787
  validation loss:		0.471924
  validation accuracy:		91.96 %
Epoch 960 of 2000 took 0.055s
  training loss:		0.011994
  validation loss:		0.463306
  validation accuracy:		91.85 %
Epoch 961 of 2000 took 0.057s
  training loss:		0.012514
  validation loss:		0.467618
  validation accuracy:		92.07 %
Epoch 962 of 2000 took 0.056s
  training loss:		0.012188
  validation loss:		0.474088
  validation accuracy:		91.74 %
Epoch 963 of 2000 took 0.056s
  training loss:		0.011901
  validation loss:		0.480365
  validation accuracy:		92.07 %
Epoch 964 of 2000 took 0.057s
  training loss:		0.012455
  validation loss:		0.469786
  validation accuracy:		91.85 %
Epoch 965 of 2000 took 0.057s
  training loss:		0.011961
  validation loss:		0.461924
  validation accuracy:		91.96 %
Epoch 966 of 2000 took 0.057s
  training loss:		0.012140
  validation loss:		0.465915
  validation accuracy:		91.74 %
Epoch 967 of 2000 took 0.057s
  training loss:		0.011795
  validation loss:		0.469857
  validation accuracy:		91.96 %
Epoch 968 of 2000 took 0.055s
  training loss:		0.011269
  validation loss:		0.484370
  validation accuracy:		92.07 %
Epoch 969 of 2000 took 0.057s
  training loss:		0.011587
  validation loss:		0.467122
  validation accuracy:		91.85 %
Epoch 970 of 2000 took 0.056s
  training loss:		0.011936
  validation loss:		0.480774
  validation accuracy:		91.85 %
Epoch 971 of 2000 took 0.057s
  training loss:		0.011750
  validation loss:		0.472818
  validation accuracy:		91.74 %
Epoch 972 of 2000 took 0.057s
  training loss:		0.011682
  validation loss:		0.477449
  validation accuracy:		91.74 %
Epoch 973 of 2000 took 0.057s
  training loss:		0.012209
  validation loss:		0.485062
  validation accuracy:		91.63 %
Epoch 974 of 2000 took 0.057s
  training loss:		0.011384
  validation loss:		0.480112
  validation accuracy:		91.63 %
Epoch 975 of 2000 took 0.057s
  training loss:		0.012118
  validation loss:		0.476034
  validation accuracy:		91.74 %
Epoch 976 of 2000 took 0.057s
  training loss:		0.011884
  validation loss:		0.484807
  validation accuracy:		91.85 %
Epoch 977 of 2000 took 0.057s
  training loss:		0.011822
  validation loss:		0.472983
  validation accuracy:		91.74 %
Epoch 978 of 2000 took 0.058s
  training loss:		0.011704
  validation loss:		0.469448
  validation accuracy:		92.07 %
Epoch 979 of 2000 took 0.056s
  training loss:		0.011540
  validation loss:		0.469859
  validation accuracy:		91.85 %
Epoch 980 of 2000 took 0.055s
  training loss:		0.011547
  validation loss:		0.471258
  validation accuracy:		91.74 %
Epoch 981 of 2000 took 0.056s
  training loss:		0.011339
  validation loss:		0.475523
  validation accuracy:		91.74 %
Epoch 982 of 2000 took 0.057s
  training loss:		0.011618
  validation loss:		0.499637
  validation accuracy:		91.52 %
Epoch 983 of 2000 took 0.056s
  training loss:		0.011384
  validation loss:		0.484288
  validation accuracy:		92.07 %
Epoch 984 of 2000 took 0.058s
  training loss:		0.011843
  validation loss:		0.468968
  validation accuracy:		91.85 %
Epoch 985 of 2000 took 0.057s
  training loss:		0.011902
  validation loss:		0.479423
  validation accuracy:		91.85 %
Epoch 986 of 2000 took 0.058s
  training loss:		0.011156
  validation loss:		0.479506
  validation accuracy:		91.74 %
Epoch 987 of 2000 took 0.058s
  training loss:		0.011801
  validation loss:		0.487392
  validation accuracy:		91.96 %
Epoch 988 of 2000 took 0.058s
  training loss:		0.012062
  validation loss:		0.490795
  validation accuracy:		91.96 %
Epoch 989 of 2000 took 0.058s
  training loss:		0.011629
  validation loss:		0.499002
  validation accuracy:		91.85 %
Epoch 990 of 2000 took 0.057s
  training loss:		0.011298
  validation loss:		0.474022
  validation accuracy:		91.63 %
Epoch 991 of 2000 took 0.058s
  training loss:		0.011775
  validation loss:		0.480198
  validation accuracy:		91.85 %
Epoch 992 of 2000 took 0.058s
  training loss:		0.011647
  validation loss:		0.484535
  validation accuracy:		91.74 %
Epoch 993 of 2000 took 0.058s
  training loss:		0.011374
  validation loss:		0.479097
  validation accuracy:		91.74 %
Epoch 994 of 2000 took 0.057s
  training loss:		0.011407
  validation loss:		0.477067
  validation accuracy:		91.96 %
Epoch 995 of 2000 took 0.057s
  training loss:		0.011244
  validation loss:		0.489234
  validation accuracy:		91.74 %
Epoch 996 of 2000 took 0.057s
  training loss:		0.010868
  validation loss:		0.489548
  validation accuracy:		91.74 %
Epoch 997 of 2000 took 0.059s
  training loss:		0.011303
  validation loss:		0.483568
  validation accuracy:		91.85 %
Epoch 998 of 2000 took 0.058s
  training loss:		0.011446
  validation loss:		0.483880
  validation accuracy:		91.85 %
Epoch 999 of 2000 took 0.059s
  training loss:		0.011271
  validation loss:		0.494045
  validation accuracy:		91.85 %
Epoch 1000 of 2000 took 0.057s
  training loss:		0.011273
  validation loss:		0.490086
  validation accuracy:		91.52 %
Epoch 1001 of 2000 took 0.057s
  training loss:		0.011091
  validation loss:		0.481661
  validation accuracy:		91.74 %
Epoch 1002 of 2000 took 0.059s
  training loss:		0.010899
  validation loss:		0.487096
  validation accuracy:		91.85 %
Epoch 1003 of 2000 took 0.057s
  training loss:		0.011478
  validation loss:		0.495838
  validation accuracy:		91.63 %
Epoch 1004 of 2000 took 0.057s
  training loss:		0.011282
  validation loss:		0.479850
  validation accuracy:		91.74 %
Epoch 1005 of 2000 took 0.056s
  training loss:		0.010910
  validation loss:		0.478247
  validation accuracy:		91.74 %
Epoch 1006 of 2000 took 0.057s
  training loss:		0.010736
  validation loss:		0.482761
  validation accuracy:		91.96 %
Epoch 1007 of 2000 took 0.058s
  training loss:		0.010818
  validation loss:		0.485957
  validation accuracy:		91.63 %
Epoch 1008 of 2000 took 0.057s
  training loss:		0.010732
  validation loss:		0.479137
  validation accuracy:		91.96 %
Epoch 1009 of 2000 took 0.057s
  training loss:		0.010334
  validation loss:		0.484393
  validation accuracy:		91.85 %
Epoch 1010 of 2000 took 0.057s
  training loss:		0.010902
  validation loss:		0.493467
  validation accuracy:		91.74 %
Epoch 1011 of 2000 took 0.056s
  training loss:		0.011174
  validation loss:		0.504528
  validation accuracy:		92.28 %
Epoch 1012 of 2000 took 0.058s
  training loss:		0.010529
  validation loss:		0.483561
  validation accuracy:		91.74 %
Epoch 1013 of 2000 took 0.057s
  training loss:		0.010766
  validation loss:		0.475390
  validation accuracy:		91.85 %
Epoch 1014 of 2000 took 0.057s
  training loss:		0.010814
  validation loss:		0.489960
  validation accuracy:		91.96 %
Epoch 1015 of 2000 took 0.058s
  training loss:		0.010845
  validation loss:		0.501158
  validation accuracy:		91.52 %
Epoch 1016 of 2000 took 0.056s
  training loss:		0.010851
  validation loss:		0.491629
  validation accuracy:		92.07 %
Epoch 1017 of 2000 took 0.056s
  training loss:		0.010911
  validation loss:		0.484784
  validation accuracy:		91.96 %
Epoch 1018 of 2000 took 0.056s
  training loss:		0.010958
  validation loss:		0.484774
  validation accuracy:		91.85 %
Epoch 1019 of 2000 took 0.055s
  training loss:		0.010932
  validation loss:		0.499192
  validation accuracy:		91.74 %
Epoch 1020 of 2000 took 0.057s
  training loss:		0.010695
  validation loss:		0.486510
  validation accuracy:		91.74 %
Epoch 1021 of 2000 took 0.058s
  training loss:		0.010922
  validation loss:		0.480221
  validation accuracy:		91.74 %
Epoch 1022 of 2000 took 0.057s
  training loss:		0.010634
  validation loss:		0.491760
  validation accuracy:		91.63 %
Epoch 1023 of 2000 took 0.057s
  training loss:		0.010588
  validation loss:		0.480772
  validation accuracy:		91.85 %
Epoch 1024 of 2000 took 0.058s
  training loss:		0.011351
  validation loss:		0.479714
  validation accuracy:		91.96 %
Epoch 1025 of 2000 took 0.058s
  training loss:		0.010516
  validation loss:		0.488441
  validation accuracy:		91.85 %
Epoch 1026 of 2000 took 0.057s
  training loss:		0.010131
  validation loss:		0.478754
  validation accuracy:		91.74 %
Epoch 1027 of 2000 took 0.057s
  training loss:		0.010494
  validation loss:		0.493253
  validation accuracy:		91.74 %
Epoch 1028 of 2000 took 0.058s
  training loss:		0.010628
  validation loss:		0.483963
  validation accuracy:		91.74 %
Epoch 1029 of 2000 took 0.059s
  training loss:		0.010590
  validation loss:		0.499607
  validation accuracy:		91.74 %
Epoch 1030 of 2000 took 0.057s
  training loss:		0.010554
  validation loss:		0.495667
  validation accuracy:		91.96 %
Epoch 1031 of 2000 took 0.058s
  training loss:		0.010807
  validation loss:		0.501303
  validation accuracy:		91.20 %
Epoch 1032 of 2000 took 0.059s
  training loss:		0.010121
  validation loss:		0.485972
  validation accuracy:		91.85 %
Epoch 1033 of 2000 took 0.059s
  training loss:		0.010349
  validation loss:		0.495477
  validation accuracy:		91.63 %
Epoch 1034 of 2000 took 0.059s
  training loss:		0.010384
  validation loss:		0.508939
  validation accuracy:		91.41 %
Epoch 1035 of 2000 took 0.057s
  training loss:		0.010478
  validation loss:		0.502270
  validation accuracy:		91.96 %
Epoch 1036 of 2000 took 0.059s
  training loss:		0.010310
  validation loss:		0.492806
  validation accuracy:		91.74 %
Epoch 1037 of 2000 took 0.058s
  training loss:		0.010091
  validation loss:		0.486715
  validation accuracy:		91.63 %
Epoch 1038 of 2000 took 0.059s
  training loss:		0.009551
  validation loss:		0.492507
  validation accuracy:		91.63 %
Epoch 1039 of 2000 took 0.056s
  training loss:		0.010400
  validation loss:		0.495878
  validation accuracy:		91.74 %
Epoch 1040 of 2000 took 0.058s
  training loss:		0.010159
  validation loss:		0.499682
  validation accuracy:		91.74 %
Epoch 1041 of 2000 took 0.057s
  training loss:		0.010107
  validation loss:		0.492390
  validation accuracy:		91.52 %
Epoch 1042 of 2000 took 0.057s
  training loss:		0.010101
  validation loss:		0.499988
  validation accuracy:		91.63 %
Epoch 1043 of 2000 took 0.056s
  training loss:		0.010175
  validation loss:		0.497087
  validation accuracy:		91.85 %
Epoch 1044 of 2000 took 0.057s
  training loss:		0.010310
  validation loss:		0.500503
  validation accuracy:		91.85 %
Epoch 1045 of 2000 took 0.059s
  training loss:		0.010118
  validation loss:		0.491588
  validation accuracy:		91.63 %
Epoch 1046 of 2000 took 0.058s
  training loss:		0.010197
  validation loss:		0.507672
  validation accuracy:		91.74 %
Epoch 1047 of 2000 took 0.059s
  training loss:		0.010033
  validation loss:		0.493252
  validation accuracy:		91.85 %
Epoch 1048 of 2000 took 0.055s
  training loss:		0.010043
  validation loss:		0.488004
  validation accuracy:		91.96 %
Epoch 1049 of 2000 took 0.056s
  training loss:		0.009734
  validation loss:		0.500398
  validation accuracy:		91.74 %
Epoch 1050 of 2000 took 0.057s
  training loss:		0.009968
  validation loss:		0.504231
  validation accuracy:		91.52 %
Epoch 1051 of 2000 took 0.058s
  training loss:		0.009971
  validation loss:		0.496274
  validation accuracy:		91.85 %
Epoch 1052 of 2000 took 0.057s
  training loss:		0.009908
  validation loss:		0.501127
  validation accuracy:		91.74 %
Epoch 1053 of 2000 took 0.056s
  training loss:		0.009868
  validation loss:		0.495951
  validation accuracy:		91.74 %
Epoch 1054 of 2000 took 0.057s
  training loss:		0.009693
  validation loss:		0.491091
  validation accuracy:		92.07 %
Epoch 1055 of 2000 took 0.059s
  training loss:		0.009636
  validation loss:		0.497906
  validation accuracy:		91.41 %
Epoch 1056 of 2000 took 0.057s
  training loss:		0.009596
  validation loss:		0.495232
  validation accuracy:		91.85 %
Epoch 1057 of 2000 took 0.059s
  training loss:		0.009904
  validation loss:		0.498796
  validation accuracy:		91.74 %
Epoch 1058 of 2000 took 0.058s
  training loss:		0.009471
  validation loss:		0.494037
  validation accuracy:		91.85 %
Epoch 1059 of 2000 took 0.058s
  training loss:		0.009937
  validation loss:		0.494397
  validation accuracy:		91.96 %
Epoch 1060 of 2000 took 0.058s
  training loss:		0.009799
  validation loss:		0.501172
  validation accuracy:		91.74 %
Epoch 1061 of 2000 took 0.059s
  training loss:		0.009318
  validation loss:		0.507579
  validation accuracy:		91.52 %
Epoch 1062 of 2000 took 0.057s
  training loss:		0.009769
  validation loss:		0.496754
  validation accuracy:		91.85 %
Epoch 1063 of 2000 took 0.059s
  training loss:		0.009766
  validation loss:		0.494752
  validation accuracy:		91.85 %
Epoch 1064 of 2000 took 0.057s
  training loss:		0.009332
  validation loss:		0.505076
  validation accuracy:		91.41 %
Epoch 1065 of 2000 took 0.057s
  training loss:		0.009178
  validation loss:		0.492235
  validation accuracy:		91.74 %
Epoch 1066 of 2000 took 0.058s
  training loss:		0.009667
  validation loss:		0.513868
  validation accuracy:		91.74 %
Epoch 1067 of 2000 took 0.057s
  training loss:		0.009355
  validation loss:		0.499913
  validation accuracy:		91.74 %
Epoch 1068 of 2000 took 0.058s
  training loss:		0.009238
  validation loss:		0.507905
  validation accuracy:		91.41 %
Epoch 1069 of 2000 took 0.058s
  training loss:		0.009723
  validation loss:		0.516352
  validation accuracy:		91.63 %
Epoch 1070 of 2000 took 0.058s
  training loss:		0.009449
  validation loss:		0.494713
  validation accuracy:		91.63 %
Epoch 1071 of 2000 took 0.058s
  training loss:		0.009582
  validation loss:		0.501888
  validation accuracy:		91.96 %
Epoch 1072 of 2000 took 0.057s
  training loss:		0.009218
  validation loss:		0.498853
  validation accuracy:		91.63 %
Epoch 1073 of 2000 took 0.057s
  training loss:		0.009180
  validation loss:		0.504726
  validation accuracy:		91.63 %
Epoch 1074 of 2000 took 0.057s
  training loss:		0.009158
  validation loss:		0.498691
  validation accuracy:		91.63 %
Epoch 1075 of 2000 took 0.057s
  training loss:		0.009285
  validation loss:		0.508156
  validation accuracy:		91.85 %
Epoch 1076 of 2000 took 0.057s
  training loss:		0.009503
  validation loss:		0.498687
  validation accuracy:		91.74 %
Epoch 1077 of 2000 took 0.057s
  training loss:		0.009517
  validation loss:		0.504095
  validation accuracy:		91.74 %
Epoch 1078 of 2000 took 0.057s
  training loss:		0.009365
  validation loss:		0.499270
  validation accuracy:		91.85 %
Epoch 1079 of 2000 took 0.057s
  training loss:		0.009459
  validation loss:		0.502926
  validation accuracy:		91.74 %
Epoch 1080 of 2000 took 0.057s
  training loss:		0.009494
  validation loss:		0.510389
  validation accuracy:		92.07 %
Epoch 1081 of 2000 took 0.057s
  training loss:		0.009483
  validation loss:		0.506476
  validation accuracy:		91.52 %
Epoch 1082 of 2000 took 0.057s
  training loss:		0.009466
  validation loss:		0.502987
  validation accuracy:		91.96 %
Epoch 1083 of 2000 took 0.057s
  training loss:		0.009181
  validation loss:		0.508738
  validation accuracy:		91.52 %
Epoch 1084 of 2000 took 0.057s
  training loss:		0.009240
  validation loss:		0.512857
  validation accuracy:		91.96 %
Epoch 1085 of 2000 took 0.057s
  training loss:		0.009477
  validation loss:		0.509649
  validation accuracy:		91.74 %
Epoch 1086 of 2000 took 0.058s
  training loss:		0.008998
  validation loss:		0.504612
  validation accuracy:		91.85 %
Epoch 1087 of 2000 took 0.058s
  training loss:		0.009129
  validation loss:		0.506908
  validation accuracy:		91.85 %
Epoch 1088 of 2000 took 0.058s
  training loss:		0.009447
  validation loss:		0.507238
  validation accuracy:		91.85 %
Epoch 1089 of 2000 took 0.058s
  training loss:		0.009201
  validation loss:		0.500037
  validation accuracy:		91.63 %
Epoch 1090 of 2000 took 0.057s
  training loss:		0.009128
  validation loss:		0.508899
  validation accuracy:		91.96 %
Epoch 1091 of 2000 took 0.057s
  training loss:		0.009238
  validation loss:		0.508388
  validation accuracy:		91.85 %
Epoch 1092 of 2000 took 0.057s
  training loss:		0.009028
  validation loss:		0.506120
  validation accuracy:		91.63 %
Epoch 1093 of 2000 took 0.057s
  training loss:		0.009590
  validation loss:		0.514959
  validation accuracy:		91.63 %
Epoch 1094 of 2000 took 0.057s
  training loss:		0.009181
  validation loss:		0.507368
  validation accuracy:		91.41 %
Epoch 1095 of 2000 took 0.057s
  training loss:		0.009125
  validation loss:		0.515721
  validation accuracy:		91.74 %
Epoch 1096 of 2000 took 0.057s
  training loss:		0.009143
  validation loss:		0.513238
  validation accuracy:		91.63 %
Epoch 1097 of 2000 took 0.057s
  training loss:		0.008994
  validation loss:		0.502052
  validation accuracy:		91.63 %
Epoch 1098 of 2000 took 0.057s
  training loss:		0.009327
  validation loss:		0.500184
  validation accuracy:		91.85 %
Epoch 1099 of 2000 took 0.057s
  training loss:		0.008759
  validation loss:		0.510742
  validation accuracy:		91.63 %
Epoch 1100 of 2000 took 0.057s
  training loss:		0.008654
  validation loss:		0.523850
  validation accuracy:		91.96 %
Epoch 1101 of 2000 took 0.057s
  training loss:		0.009056
  validation loss:		0.507218
  validation accuracy:		91.85 %
Epoch 1102 of 2000 took 0.057s
  training loss:		0.008785
  validation loss:		0.516347
  validation accuracy:		91.63 %
Epoch 1103 of 2000 took 0.057s
  training loss:		0.009018
  validation loss:		0.511732
  validation accuracy:		91.74 %
Epoch 1104 of 2000 took 0.057s
  training loss:		0.008741
  validation loss:		0.511255
  validation accuracy:		91.74 %
Epoch 1105 of 2000 took 0.057s
  training loss:		0.009138
  validation loss:		0.513287
  validation accuracy:		91.85 %
Epoch 1106 of 2000 took 0.057s
  training loss:		0.008772
  validation loss:		0.510089
  validation accuracy:		91.85 %
Epoch 1107 of 2000 took 0.057s
  training loss:		0.008970
  validation loss:		0.526083
  validation accuracy:		91.09 %
Epoch 1108 of 2000 took 0.057s
  training loss:		0.009046
  validation loss:		0.504724
  validation accuracy:		91.85 %
Epoch 1109 of 2000 took 0.057s
  training loss:		0.008927
  validation loss:		0.523095
  validation accuracy:		91.63 %
Epoch 1110 of 2000 took 0.057s
  training loss:		0.008677
  validation loss:		0.515137
  validation accuracy:		91.74 %
Epoch 1111 of 2000 took 0.057s
  training loss:		0.008797
  validation loss:		0.513451
  validation accuracy:		91.63 %
Epoch 1112 of 2000 took 0.057s
  training loss:		0.008612
  validation loss:		0.515846
  validation accuracy:		91.85 %
Epoch 1113 of 2000 took 0.057s
  training loss:		0.008528
  validation loss:		0.529918
  validation accuracy:		91.41 %
Epoch 1114 of 2000 took 0.057s
  training loss:		0.008771
  validation loss:		0.506122
  validation accuracy:		91.85 %
Epoch 1115 of 2000 took 0.058s
  training loss:		0.008765
  validation loss:		0.523706
  validation accuracy:		91.52 %
Epoch 1116 of 2000 took 0.057s
  training loss:		0.008415
  validation loss:		0.511951
  validation accuracy:		91.74 %
Epoch 1117 of 2000 took 0.058s
  training loss:		0.008576
  validation loss:		0.514917
  validation accuracy:		91.74 %
Epoch 1118 of 2000 took 0.058s
  training loss:		0.008663
  validation loss:		0.518404
  validation accuracy:		91.85 %
Epoch 1119 of 2000 took 0.058s
  training loss:		0.008518
  validation loss:		0.521000
  validation accuracy:		91.63 %
Epoch 1120 of 2000 took 0.058s
  training loss:		0.008458
  validation loss:		0.519247
  validation accuracy:		91.63 %
Epoch 1121 of 2000 took 0.058s
  training loss:		0.008641
  validation loss:		0.511670
  validation accuracy:		91.74 %
Epoch 1122 of 2000 took 0.058s
  training loss:		0.008534
  validation loss:		0.513020
  validation accuracy:		91.96 %
Epoch 1123 of 2000 took 0.058s
  training loss:		0.008507
  validation loss:		0.523455
  validation accuracy:		91.63 %
Epoch 1124 of 2000 took 0.058s
  training loss:		0.008593
  validation loss:		0.526877
  validation accuracy:		91.63 %
Epoch 1125 of 2000 took 0.058s
  training loss:		0.008375
  validation loss:		0.519433
  validation accuracy:		91.74 %
Epoch 1126 of 2000 took 0.058s
  training loss:		0.007988
  validation loss:		0.525014
  validation accuracy:		91.74 %
Epoch 1127 of 2000 took 0.058s
  training loss:		0.008346
  validation loss:		0.522478
  validation accuracy:		91.74 %
Epoch 1128 of 2000 took 0.058s
  training loss:		0.008511
  validation loss:		0.522768
  validation accuracy:		91.85 %
Epoch 1129 of 2000 took 0.058s
  training loss:		0.008440
  validation loss:		0.515179
  validation accuracy:		91.96 %
Epoch 1130 of 2000 took 0.058s
  training loss:		0.008428
  validation loss:		0.514562
  validation accuracy:		91.85 %
Epoch 1131 of 2000 took 0.058s
  training loss:		0.008328
  validation loss:		0.523703
  validation accuracy:		91.74 %
Epoch 1132 of 2000 took 0.058s
  training loss:		0.008354
  validation loss:		0.531552
  validation accuracy:		91.74 %
Epoch 1133 of 2000 took 0.058s
  training loss:		0.008285
  validation loss:		0.518789
  validation accuracy:		91.41 %
Epoch 1134 of 2000 took 0.058s
  training loss:		0.008268
  validation loss:		0.524735
  validation accuracy:		91.52 %
Epoch 1135 of 2000 took 0.058s
  training loss:		0.008444
  validation loss:		0.521442
  validation accuracy:		91.74 %
Epoch 1136 of 2000 took 0.058s
  training loss:		0.008119
  validation loss:		0.518142
  validation accuracy:		91.74 %
Epoch 1137 of 2000 took 0.058s
  training loss:		0.008642
  validation loss:		0.525681
  validation accuracy:		91.74 %
Epoch 1138 of 2000 took 0.057s
  training loss:		0.008272
  validation loss:		0.526434
  validation accuracy:		91.74 %
Epoch 1139 of 2000 took 0.059s
  training loss:		0.008024
  validation loss:		0.523987
  validation accuracy:		91.30 %
Epoch 1140 of 2000 took 0.058s
  training loss:		0.008001
  validation loss:		0.526587
  validation accuracy:		91.85 %
Epoch 1141 of 2000 took 0.075s
  training loss:		0.008465
  validation loss:		0.521221
  validation accuracy:		91.52 %
Epoch 1142 of 2000 took 0.069s
  training loss:		0.008346
  validation loss:		0.516648
  validation accuracy:		91.85 %
Epoch 1143 of 2000 took 0.064s
  training loss:		0.008509
  validation loss:		0.521360
  validation accuracy:		91.74 %
Epoch 1144 of 2000 took 0.064s
  training loss:		0.008213
  validation loss:		0.527202
  validation accuracy:		91.74 %
Epoch 1145 of 2000 took 0.064s
  training loss:		0.008136
  validation loss:		0.528503
  validation accuracy:		91.74 %
Epoch 1146 of 2000 took 0.063s
  training loss:		0.008267
  validation loss:		0.521778
  validation accuracy:		91.52 %
Epoch 1147 of 2000 took 0.064s
  training loss:		0.008291
  validation loss:		0.549796
  validation accuracy:		91.41 %
Epoch 1148 of 2000 took 0.062s
  training loss:		0.008107
  validation loss:		0.521617
  validation accuracy:		91.85 %
Epoch 1149 of 2000 took 0.063s
  training loss:		0.008056
  validation loss:		0.530089
  validation accuracy:		91.52 %
Epoch 1150 of 2000 took 0.065s
  training loss:		0.008165
  validation loss:		0.522732
  validation accuracy:		91.74 %
Epoch 1151 of 2000 took 0.063s
  training loss:		0.008069
  validation loss:		0.533369
  validation accuracy:		91.74 %
Epoch 1152 of 2000 took 0.064s
  training loss:		0.007955
  validation loss:		0.546070
  validation accuracy:		91.52 %
Epoch 1153 of 2000 took 0.060s
  training loss:		0.007954
  validation loss:		0.531478
  validation accuracy:		91.74 %
Epoch 1154 of 2000 took 0.057s
  training loss:		0.008271
  validation loss:		0.528391
  validation accuracy:		91.74 %
Epoch 1155 of 2000 took 0.057s
  training loss:		0.008233
  validation loss:		0.517746
  validation accuracy:		91.85 %
Epoch 1156 of 2000 took 0.057s
  training loss:		0.007765
  validation loss:		0.533177
  validation accuracy:		91.41 %
Epoch 1157 of 2000 took 0.057s
  training loss:		0.007589
  validation loss:		0.533822
  validation accuracy:		91.63 %
Epoch 1158 of 2000 took 0.057s
  training loss:		0.007936
  validation loss:		0.529095
  validation accuracy:		91.74 %
Epoch 1159 of 2000 took 0.057s
  training loss:		0.007972
  validation loss:		0.535696
  validation accuracy:		91.63 %
Epoch 1160 of 2000 took 0.057s
  training loss:		0.007999
  validation loss:		0.527760
  validation accuracy:		91.63 %
Epoch 1161 of 2000 took 0.057s
  training loss:		0.007903
  validation loss:		0.530894
  validation accuracy:		91.85 %
Epoch 1162 of 2000 took 0.059s
  training loss:		0.007755
  validation loss:		0.532455
  validation accuracy:		91.52 %
Epoch 1163 of 2000 took 0.058s
  training loss:		0.007706
  validation loss:		0.540384
  validation accuracy:		91.52 %
Epoch 1164 of 2000 took 0.059s
  training loss:		0.007872
  validation loss:		0.531092
  validation accuracy:		91.96 %
Epoch 1165 of 2000 took 0.059s
  training loss:		0.007777
  validation loss:		0.539855
  validation accuracy:		91.30 %
Epoch 1166 of 2000 took 0.060s
  training loss:		0.007698
  validation loss:		0.531055
  validation accuracy:		91.74 %
Epoch 1167 of 2000 took 0.058s
  training loss:		0.007657
  validation loss:		0.521179
  validation accuracy:		91.63 %
Epoch 1168 of 2000 took 0.058s
  training loss:		0.007826
  validation loss:		0.517951
  validation accuracy:		91.74 %
Epoch 1169 of 2000 took 0.058s
  training loss:		0.007862
  validation loss:		0.529640
  validation accuracy:		91.74 %
Epoch 1170 of 2000 took 0.058s
  training loss:		0.007510
  validation loss:		0.526121
  validation accuracy:		91.85 %
Epoch 1171 of 2000 took 0.058s
  training loss:		0.007715
  validation loss:		0.525876
  validation accuracy:		91.74 %
Epoch 1172 of 2000 took 0.058s
  training loss:		0.007544
  validation loss:		0.535847
  validation accuracy:		91.85 %
Epoch 1173 of 2000 took 0.058s
  training loss:		0.007682
  validation loss:		0.528898
  validation accuracy:		91.74 %
Epoch 1174 of 2000 took 0.059s
  training loss:		0.008033
  validation loss:		0.532914
  validation accuracy:		91.85 %
Epoch 1175 of 2000 took 0.059s
  training loss:		0.007777
  validation loss:		0.537548
  validation accuracy:		91.63 %
Epoch 1176 of 2000 took 0.058s
  training loss:		0.007616
  validation loss:		0.527388
  validation accuracy:		91.52 %
Epoch 1177 of 2000 took 0.059s
  training loss:		0.007609
  validation loss:		0.528092
  validation accuracy:		91.74 %
Epoch 1178 of 2000 took 0.058s
  training loss:		0.007571
  validation loss:		0.535700
  validation accuracy:		91.74 %
Epoch 1179 of 2000 took 0.058s
  training loss:		0.007699
  validation loss:		0.529097
  validation accuracy:		91.85 %
Epoch 1180 of 2000 took 0.058s
  training loss:		0.007353
  validation loss:		0.540450
  validation accuracy:		91.85 %
Epoch 1181 of 2000 took 0.058s
  training loss:		0.007647
  validation loss:		0.540655
  validation accuracy:		91.63 %
Epoch 1182 of 2000 took 0.058s
  training loss:		0.007864
  validation loss:		0.535898
  validation accuracy:		91.85 %
Epoch 1183 of 2000 took 0.058s
  training loss:		0.007587
  validation loss:		0.524453
  validation accuracy:		91.85 %
Epoch 1184 of 2000 took 0.058s
  training loss:		0.007864
  validation loss:		0.536079
  validation accuracy:		91.85 %
Epoch 1185 of 2000 took 0.058s
  training loss:		0.007491
  validation loss:		0.537539
  validation accuracy:		91.41 %
Epoch 1186 of 2000 took 0.058s
  training loss:		0.007655
  validation loss:		0.549332
  validation accuracy:		91.52 %
Epoch 1187 of 2000 took 0.058s
  training loss:		0.007708
  validation loss:		0.543019
  validation accuracy:		91.85 %
Epoch 1188 of 2000 took 0.058s
  training loss:		0.007516
  validation loss:		0.527541
  validation accuracy:		91.96 %
Epoch 1189 of 2000 took 0.058s
  training loss:		0.007565
  validation loss:		0.551818
  validation accuracy:		91.63 %
Epoch 1190 of 2000 took 0.058s
  training loss:		0.007728
  validation loss:		0.533210
  validation accuracy:		91.74 %
Epoch 1191 of 2000 took 0.058s
  training loss:		0.007554
  validation loss:		0.539140
  validation accuracy:		91.74 %
Epoch 1192 of 2000 took 0.058s
  training loss:		0.007356
  validation loss:		0.537088
  validation accuracy:		91.74 %
Epoch 1193 of 2000 took 0.058s
  training loss:		0.007427
  validation loss:		0.538237
  validation accuracy:		91.74 %
Epoch 1194 of 2000 took 0.058s
  training loss:		0.007376
  validation loss:		0.547971
  validation accuracy:		91.74 %
Epoch 1195 of 2000 took 0.058s
  training loss:		0.007191
  validation loss:		0.528009
  validation accuracy:		91.96 %
Epoch 1196 of 2000 took 0.058s
  training loss:		0.007546
  validation loss:		0.541391
  validation accuracy:		91.85 %
Epoch 1197 of 2000 took 0.058s
  training loss:		0.007375
  validation loss:		0.534459
  validation accuracy:		91.74 %
Epoch 1198 of 2000 took 0.058s
  training loss:		0.007367
  validation loss:		0.545355
  validation accuracy:		91.74 %
Epoch 1199 of 2000 took 0.058s
  training loss:		0.007279
  validation loss:		0.537411
  validation accuracy:		91.74 %
Epoch 1200 of 2000 took 0.058s
  training loss:		0.007518
  validation loss:		0.531756
  validation accuracy:		91.85 %
Epoch 1201 of 2000 took 0.058s
  training loss:		0.007355
  validation loss:		0.540980
  validation accuracy:		91.74 %
Epoch 1202 of 2000 took 0.058s
  training loss:		0.007422
  validation loss:		0.537634
  validation accuracy:		91.74 %
Epoch 1203 of 2000 took 0.058s
  training loss:		0.007258
  validation loss:		0.538271
  validation accuracy:		91.85 %
Epoch 1204 of 2000 took 0.058s
  training loss:		0.007181
  validation loss:		0.543533
  validation accuracy:		91.74 %
Epoch 1205 of 2000 took 0.059s
  training loss:		0.007054
  validation loss:		0.542841
  validation accuracy:		91.85 %
Epoch 1206 of 2000 took 0.059s
  training loss:		0.007119
  validation loss:		0.545195
  validation accuracy:		91.74 %
Epoch 1207 of 2000 took 0.058s
  training loss:		0.007178
  validation loss:		0.540168
  validation accuracy:		91.74 %
Epoch 1208 of 2000 took 0.058s
  training loss:		0.007251
  validation loss:		0.533836
  validation accuracy:		91.85 %
Epoch 1209 of 2000 took 0.059s
  training loss:		0.007393
  validation loss:		0.542526
  validation accuracy:		91.20 %
Epoch 1210 of 2000 took 0.058s
  training loss:		0.007007
  validation loss:		0.522404
  validation accuracy:		91.96 %
Epoch 1211 of 2000 took 0.059s
  training loss:		0.007527
  validation loss:		0.544137
  validation accuracy:		91.74 %
Epoch 1212 of 2000 took 0.058s
  training loss:		0.007104
  validation loss:		0.536331
  validation accuracy:		91.63 %
Epoch 1213 of 2000 took 0.058s
  training loss:		0.007103
  validation loss:		0.544126
  validation accuracy:		91.74 %
Epoch 1214 of 2000 took 0.058s
  training loss:		0.006845
  validation loss:		0.548948
  validation accuracy:		91.63 %
Epoch 1215 of 2000 took 0.059s
  training loss:		0.007130
  validation loss:		0.553456
  validation accuracy:		91.63 %
Epoch 1216 of 2000 took 0.058s
  training loss:		0.007023
  validation loss:		0.550447
  validation accuracy:		91.52 %
Epoch 1217 of 2000 took 0.059s
  training loss:		0.007060
  validation loss:		0.546948
  validation accuracy:		91.74 %
Epoch 1218 of 2000 took 0.059s
  training loss:		0.006805
  validation loss:		0.538481
  validation accuracy:		91.85 %
Epoch 1219 of 2000 took 0.058s
  training loss:		0.007230
  validation loss:		0.553652
  validation accuracy:		91.85 %
Epoch 1220 of 2000 took 0.058s
  training loss:		0.007132
  validation loss:		0.544655
  validation accuracy:		91.74 %
Epoch 1221 of 2000 took 0.058s
  training loss:		0.006850
  validation loss:		0.541014
  validation accuracy:		91.85 %
Epoch 1222 of 2000 took 0.058s
  training loss:		0.007036
  validation loss:		0.543339
  validation accuracy:		91.74 %
Epoch 1223 of 2000 took 0.059s
  training loss:		0.006787
  validation loss:		0.544039
  validation accuracy:		91.63 %
Epoch 1224 of 2000 took 0.059s
  training loss:		0.007142
  validation loss:		0.548436
  validation accuracy:		91.74 %
Epoch 1225 of 2000 took 0.059s
  training loss:		0.007087
  validation loss:		0.542291
  validation accuracy:		91.63 %
Epoch 1226 of 2000 took 0.058s
  training loss:		0.006966
  validation loss:		0.552937
  validation accuracy:		91.63 %
Epoch 1227 of 2000 took 0.058s
  training loss:		0.006909
  validation loss:		0.540598
  validation accuracy:		91.85 %
Epoch 1228 of 2000 took 0.059s
  training loss:		0.006732
  validation loss:		0.549896
  validation accuracy:		91.20 %
Epoch 1229 of 2000 took 0.059s
  training loss:		0.006729
  validation loss:		0.559379
  validation accuracy:		91.63 %
Epoch 1230 of 2000 took 0.059s
  training loss:		0.007004
  validation loss:		0.545622
  validation accuracy:		91.85 %
Epoch 1231 of 2000 took 0.059s
  training loss:		0.006899
  validation loss:		0.539165
  validation accuracy:		91.74 %
Epoch 1232 of 2000 took 0.058s
  training loss:		0.006976
  validation loss:		0.548412
  validation accuracy:		91.74 %
Epoch 1233 of 2000 took 0.059s
  training loss:		0.006969
  validation loss:		0.554995
  validation accuracy:		91.41 %
Epoch 1234 of 2000 took 0.059s
  training loss:		0.006778
  validation loss:		0.548618
  validation accuracy:		91.63 %
Epoch 1235 of 2000 took 0.058s
  training loss:		0.006833
  validation loss:		0.545636
  validation accuracy:		91.74 %
Epoch 1236 of 2000 took 0.058s
  training loss:		0.006613
  validation loss:		0.548508
  validation accuracy:		91.85 %
Epoch 1237 of 2000 took 0.058s
  training loss:		0.006867
  validation loss:		0.543360
  validation accuracy:		91.85 %
Epoch 1238 of 2000 took 0.058s
  training loss:		0.006801
  validation loss:		0.558165
  validation accuracy:		91.52 %
Epoch 1239 of 2000 took 0.058s
  training loss:		0.006922
  validation loss:		0.554837
  validation accuracy:		91.74 %
Epoch 1240 of 2000 took 0.058s
  training loss:		0.006686
  validation loss:		0.551852
  validation accuracy:		91.85 %
Epoch 1241 of 2000 took 0.059s
  training loss:		0.006720
  validation loss:		0.542200
  validation accuracy:		91.85 %
Epoch 1242 of 2000 took 0.059s
  training loss:		0.006824
  validation loss:		0.552653
  validation accuracy:		91.20 %
Epoch 1243 of 2000 took 0.058s
  training loss:		0.006792
  validation loss:		0.549483
  validation accuracy:		91.74 %
Epoch 1244 of 2000 took 0.059s
  training loss:		0.006703
  validation loss:		0.552973
  validation accuracy:		91.85 %
Epoch 1245 of 2000 took 0.058s
  training loss:		0.006720
  validation loss:		0.557149
  validation accuracy:		91.41 %
Epoch 1246 of 2000 took 0.058s
  training loss:		0.006930
  validation loss:		0.551619
  validation accuracy:		91.74 %
Epoch 1247 of 2000 took 0.058s
  training loss:		0.007031
  validation loss:		0.549736
  validation accuracy:		91.74 %
Epoch 1248 of 2000 took 0.058s
  training loss:		0.006644
  validation loss:		0.549611
  validation accuracy:		91.74 %
Epoch 1249 of 2000 took 0.058s
  training loss:		0.006536
  validation loss:		0.543047
  validation accuracy:		91.63 %
Epoch 1250 of 2000 took 0.058s
  training loss:		0.006732
  validation loss:		0.549240
  validation accuracy:		91.74 %
Epoch 1251 of 2000 took 0.058s
  training loss:		0.006656
  validation loss:		0.550113
  validation accuracy:		91.74 %
Epoch 1252 of 2000 took 0.058s
  training loss:		0.006989
  validation loss:		0.555147
  validation accuracy:		91.85 %
Epoch 1253 of 2000 took 0.058s
  training loss:		0.006477
  validation loss:		0.545024
  validation accuracy:		91.63 %
Epoch 1254 of 2000 took 0.058s
  training loss:		0.006636
  validation loss:		0.554959
  validation accuracy:		91.74 %
Epoch 1255 of 2000 took 0.058s
  training loss:		0.006483
  validation loss:		0.558796
  validation accuracy:		91.63 %
Epoch 1256 of 2000 took 0.058s
  training loss:		0.006456
  validation loss:		0.556491
  validation accuracy:		91.63 %
Epoch 1257 of 2000 took 0.057s
  training loss:		0.006552
  validation loss:		0.553168
  validation accuracy:		91.20 %
Epoch 1258 of 2000 took 0.057s
  training loss:		0.006413
  validation loss:		0.563578
  validation accuracy:		91.63 %
Epoch 1259 of 2000 took 0.057s
  training loss:		0.006725
  validation loss:		0.566268
  validation accuracy:		91.41 %
Epoch 1260 of 2000 took 0.058s
  training loss:		0.006591
  validation loss:		0.557065
  validation accuracy:		91.85 %
Epoch 1261 of 2000 took 0.056s
  training loss:		0.006577
  validation loss:		0.548933
  validation accuracy:		91.41 %
Epoch 1262 of 2000 took 0.055s
  training loss:		0.006429
  validation loss:		0.552684
  validation accuracy:		91.74 %
Epoch 1263 of 2000 took 0.057s
  training loss:		0.006585
  validation loss:		0.566737
  validation accuracy:		91.63 %
Epoch 1264 of 2000 took 0.057s
  training loss:		0.006641
  validation loss:		0.557375
  validation accuracy:		91.52 %
Epoch 1265 of 2000 took 0.057s
  training loss:		0.006664
  validation loss:		0.556647
  validation accuracy:		91.63 %
Epoch 1266 of 2000 took 0.057s
  training loss:		0.006465
  validation loss:		0.556923
  validation accuracy:		91.63 %
Epoch 1267 of 2000 took 0.057s
  training loss:		0.006569
  validation loss:		0.567791
  validation accuracy:		91.74 %
Epoch 1268 of 2000 took 0.057s
  training loss:		0.006590
  validation loss:		0.560047
  validation accuracy:		91.63 %
Epoch 1269 of 2000 took 0.057s
  training loss:		0.006316
  validation loss:		0.557485
  validation accuracy:		91.74 %
Epoch 1270 of 2000 took 0.057s
  training loss:		0.006375
  validation loss:		0.555638
  validation accuracy:		91.74 %
Epoch 1271 of 2000 took 0.056s
  training loss:		0.006486
  validation loss:		0.552340
  validation accuracy:		91.30 %
Epoch 1272 of 2000 took 0.056s
  training loss:		0.006402
  validation loss:		0.556275
  validation accuracy:		91.74 %
Epoch 1273 of 2000 took 0.057s
  training loss:		0.006193
  validation loss:		0.553529
  validation accuracy:		91.74 %
Epoch 1274 of 2000 took 0.057s
  training loss:		0.006403
  validation loss:		0.565203
  validation accuracy:		91.63 %
Epoch 1275 of 2000 took 0.055s
  training loss:		0.006180
  validation loss:		0.560166
  validation accuracy:		91.63 %
Epoch 1276 of 2000 took 0.057s
  training loss:		0.006516
  validation loss:		0.553219
  validation accuracy:		91.63 %
Epoch 1277 of 2000 took 0.057s
  training loss:		0.006313
  validation loss:		0.555999
  validation accuracy:		91.74 %
Epoch 1278 of 2000 took 0.057s
  training loss:		0.006164
  validation loss:		0.558748
  validation accuracy:		91.30 %
Epoch 1279 of 2000 took 0.055s
  training loss:		0.006443
  validation loss:		0.556344
  validation accuracy:		91.96 %
Epoch 1280 of 2000 took 0.058s
  training loss:		0.006316
  validation loss:		0.561920
  validation accuracy:		91.52 %
Epoch 1281 of 2000 took 0.057s
  training loss:		0.006339
  validation loss:		0.551924
  validation accuracy:		91.63 %
Epoch 1282 of 2000 took 0.057s
  training loss:		0.006339
  validation loss:		0.562914
  validation accuracy:		91.41 %
Epoch 1283 of 2000 took 0.057s
  training loss:		0.006183
  validation loss:		0.564234
  validation accuracy:		91.85 %
Epoch 1284 of 2000 took 0.057s
  training loss:		0.006280
  validation loss:		0.556923
  validation accuracy:		91.85 %
Epoch 1285 of 2000 took 0.057s
  training loss:		0.006096
  validation loss:		0.564828
  validation accuracy:		91.63 %
Epoch 1286 of 2000 took 0.057s
  training loss:		0.006220
  validation loss:		0.564245
  validation accuracy:		91.52 %
Epoch 1287 of 2000 took 0.057s
  training loss:		0.006301
  validation loss:		0.568607
  validation accuracy:		91.52 %
Epoch 1288 of 2000 took 0.057s
  training loss:		0.006160
  validation loss:		0.571871
  validation accuracy:		91.52 %
Epoch 1289 of 2000 took 0.057s
  training loss:		0.006409
  validation loss:		0.560882
  validation accuracy:		91.85 %
Epoch 1290 of 2000 took 0.057s
  training loss:		0.006206
  validation loss:		0.559111
  validation accuracy:		91.85 %
Epoch 1291 of 2000 took 0.057s
  training loss:		0.006065
  validation loss:		0.559514
  validation accuracy:		91.96 %
Epoch 1292 of 2000 took 0.057s
  training loss:		0.006218
  validation loss:		0.558282
  validation accuracy:		91.74 %
Epoch 1293 of 2000 took 0.057s
  training loss:		0.006128
  validation loss:		0.564461
  validation accuracy:		91.85 %
Epoch 1294 of 2000 took 0.057s
  training loss:		0.006059
  validation loss:		0.552114
  validation accuracy:		91.74 %
Epoch 1295 of 2000 took 0.057s
  training loss:		0.005984
  validation loss:		0.558856
  validation accuracy:		91.74 %
Epoch 1296 of 2000 took 0.057s
  training loss:		0.006086
  validation loss:		0.559045
  validation accuracy:		91.52 %
Epoch 1297 of 2000 took 0.057s
  training loss:		0.006176
  validation loss:		0.560309
  validation accuracy:		91.74 %
Epoch 1298 of 2000 took 0.057s
  training loss:		0.005947
  validation loss:		0.557383
  validation accuracy:		91.85 %
Epoch 1299 of 2000 took 0.057s
  training loss:		0.006152
  validation loss:		0.559038
  validation accuracy:		91.52 %
Epoch 1300 of 2000 took 0.057s
  training loss:		0.005924
  validation loss:		0.565474
  validation accuracy:		91.74 %
Epoch 1301 of 2000 took 0.057s
  training loss:		0.006140
  validation loss:		0.565349
  validation accuracy:		91.74 %
Epoch 1302 of 2000 took 0.057s
  training loss:		0.006020
  validation loss:		0.557507
  validation accuracy:		91.63 %
Epoch 1303 of 2000 took 0.057s
  training loss:		0.005829
  validation loss:		0.561632
  validation accuracy:		91.63 %
Epoch 1304 of 2000 took 0.057s
  training loss:		0.006143
  validation loss:		0.554330
  validation accuracy:		91.85 %
Epoch 1305 of 2000 took 0.058s
  training loss:		0.006034
  validation loss:		0.567536
  validation accuracy:		91.74 %
Epoch 1306 of 2000 took 0.057s
  training loss:		0.006032
  validation loss:		0.561352
  validation accuracy:		91.74 %
Epoch 1307 of 2000 took 0.057s
  training loss:		0.005973
  validation loss:		0.562506
  validation accuracy:		91.52 %
Epoch 1308 of 2000 took 0.057s
  training loss:		0.006091
  validation loss:		0.566944
  validation accuracy:		91.63 %
Epoch 1309 of 2000 took 0.058s
  training loss:		0.006187
  validation loss:		0.575791
  validation accuracy:		91.74 %
Epoch 1310 of 2000 took 0.058s
  training loss:		0.006015
  validation loss:		0.559380
  validation accuracy:		91.74 %
Epoch 1311 of 2000 took 0.058s
  training loss:		0.005893
  validation loss:		0.583521
  validation accuracy:		91.20 %
Epoch 1312 of 2000 took 0.058s
  training loss:		0.006339
  validation loss:		0.571726
  validation accuracy:		91.74 %
Epoch 1313 of 2000 took 0.058s
  training loss:		0.006109
  validation loss:		0.566969
  validation accuracy:		91.52 %
Epoch 1314 of 2000 took 0.058s
  training loss:		0.006071
  validation loss:		0.565662
  validation accuracy:		91.74 %
Epoch 1315 of 2000 took 0.058s
  training loss:		0.006079
  validation loss:		0.564066
  validation accuracy:		91.63 %
Epoch 1316 of 2000 took 0.058s
  training loss:		0.006103
  validation loss:		0.574850
  validation accuracy:		91.74 %
Epoch 1317 of 2000 took 0.058s
  training loss:		0.006146
  validation loss:		0.566421
  validation accuracy:		91.74 %
Epoch 1318 of 2000 took 0.058s
  training loss:		0.005929
  validation loss:		0.575211
  validation accuracy:		91.63 %
Epoch 1319 of 2000 took 0.058s
  training loss:		0.005899
  validation loss:		0.569271
  validation accuracy:		91.63 %
Epoch 1320 of 2000 took 0.057s
  training loss:		0.005735
  validation loss:		0.562074
  validation accuracy:		91.74 %
Epoch 1321 of 2000 took 0.057s
  training loss:		0.005869
  validation loss:		0.572826
  validation accuracy:		91.85 %
Epoch 1322 of 2000 took 0.057s
  training loss:		0.005875
  validation loss:		0.569924
  validation accuracy:		91.30 %
Epoch 1323 of 2000 took 0.057s
  training loss:		0.005865
  validation loss:		0.570737
  validation accuracy:		91.74 %
Epoch 1324 of 2000 took 0.058s
  training loss:		0.005900
  validation loss:		0.568269
  validation accuracy:		91.74 %
Epoch 1325 of 2000 took 0.057s
  training loss:		0.005789
  validation loss:		0.560333
  validation accuracy:		91.74 %
Epoch 1326 of 2000 took 0.057s
  training loss:		0.006110
  validation loss:		0.569408
  validation accuracy:		91.52 %
Epoch 1327 of 2000 took 0.057s
  training loss:		0.005802
  validation loss:		0.564177
  validation accuracy:		91.74 %
Epoch 1328 of 2000 took 0.057s
  training loss:		0.005863
  validation loss:		0.574719
  validation accuracy:		91.52 %
Epoch 1329 of 2000 took 0.058s
  training loss:		0.006050
  validation loss:		0.586888
  validation accuracy:		91.52 %
Epoch 1330 of 2000 took 0.056s
  training loss:		0.005924
  validation loss:		0.564908
  validation accuracy:		91.63 %
Epoch 1331 of 2000 took 0.058s
  training loss:		0.005975
  validation loss:		0.571787
  validation accuracy:		91.74 %
Epoch 1332 of 2000 took 0.057s
  training loss:		0.005709
  validation loss:		0.566899
  validation accuracy:		91.63 %
Epoch 1333 of 2000 took 0.057s
  training loss:		0.005837
  validation loss:		0.579588
  validation accuracy:		91.52 %
Epoch 1334 of 2000 took 0.057s
  training loss:		0.005956
  validation loss:		0.579314
  validation accuracy:		91.30 %
Epoch 1335 of 2000 took 0.057s
  training loss:		0.005656
  validation loss:		0.571391
  validation accuracy:		91.74 %
Epoch 1336 of 2000 took 0.057s
  training loss:		0.005894
  validation loss:		0.559743
  validation accuracy:		91.52 %
Epoch 1337 of 2000 took 0.057s
  training loss:		0.006139
  validation loss:		0.568574
  validation accuracy:		91.41 %
Epoch 1338 of 2000 took 0.057s
  training loss:		0.005674
  validation loss:		0.584210
  validation accuracy:		91.74 %
Epoch 1339 of 2000 took 0.057s
  training loss:		0.005869
  validation loss:		0.577575
  validation accuracy:		91.52 %
Epoch 1340 of 2000 took 0.057s
  training loss:		0.005807
  validation loss:		0.580014
  validation accuracy:		91.52 %
Epoch 1341 of 2000 took 0.057s
  training loss:		0.005459
  validation loss:		0.563987
  validation accuracy:		91.52 %
Epoch 1342 of 2000 took 0.057s
  training loss:		0.006020
  validation loss:		0.578703
  validation accuracy:		91.74 %
Epoch 1343 of 2000 took 0.057s
  training loss:		0.005867
  validation loss:		0.571174
  validation accuracy:		91.74 %
Epoch 1344 of 2000 took 0.058s
  training loss:		0.005494
  validation loss:		0.581218
  validation accuracy:		91.30 %
Epoch 1345 of 2000 took 0.058s
  training loss:		0.005578
  validation loss:		0.573186
  validation accuracy:		91.74 %
Epoch 1346 of 2000 took 0.058s
  training loss:		0.005612
  validation loss:		0.575334
  validation accuracy:		91.63 %
Epoch 1347 of 2000 took 0.058s
  training loss:		0.005615
  validation loss:		0.572766
  validation accuracy:		91.41 %
Epoch 1348 of 2000 took 0.058s
  training loss:		0.005586
  validation loss:		0.573141
  validation accuracy:		91.74 %
Epoch 1349 of 2000 took 0.058s
  training loss:		0.005552
  validation loss:		0.575194
  validation accuracy:		91.85 %
Epoch 1350 of 2000 took 0.058s
  training loss:		0.005686
  validation loss:		0.573627
  validation accuracy:		91.74 %
Epoch 1351 of 2000 took 0.057s
  training loss:		0.005615
  validation loss:		0.574124
  validation accuracy:		91.74 %
Epoch 1352 of 2000 took 0.056s
  training loss:		0.005503
  validation loss:		0.577874
  validation accuracy:		91.63 %
Epoch 1353 of 2000 took 0.056s
  training loss:		0.005431
  validation loss:		0.578832
  validation accuracy:		91.96 %
Epoch 1354 of 2000 took 0.058s
  training loss:		0.005659
  validation loss:		0.580539
  validation accuracy:		91.20 %
Epoch 1355 of 2000 took 0.057s
  training loss:		0.005507
  validation loss:		0.570852
  validation accuracy:		91.96 %
Epoch 1356 of 2000 took 0.057s
  training loss:		0.005441
  validation loss:		0.586544
  validation accuracy:		91.52 %
Epoch 1357 of 2000 took 0.055s
  training loss:		0.005568
  validation loss:		0.576760
  validation accuracy:		91.30 %
Epoch 1358 of 2000 took 0.055s
  training loss:		0.005419
  validation loss:		0.581459
  validation accuracy:		91.74 %
Epoch 1359 of 2000 took 0.057s
  training loss:		0.005548
  validation loss:		0.575008
  validation accuracy:		91.74 %
Epoch 1360 of 2000 took 0.057s
  training loss:		0.005394
  validation loss:		0.571290
  validation accuracy:		91.63 %
Epoch 1361 of 2000 took 0.057s
  training loss:		0.005452
  validation loss:		0.589604
  validation accuracy:		91.52 %
Epoch 1362 of 2000 took 0.057s
  training loss:		0.005379
  validation loss:		0.582607
  validation accuracy:		91.52 %
Epoch 1363 of 2000 took 0.056s
  training loss:		0.005546
  validation loss:		0.593441
  validation accuracy:		91.74 %
Epoch 1364 of 2000 took 0.056s
  training loss:		0.005554
  validation loss:		0.586467
  validation accuracy:		91.63 %
Epoch 1365 of 2000 took 0.057s
  training loss:		0.005534
  validation loss:		0.571346
  validation accuracy:		91.85 %
Epoch 1366 of 2000 took 0.057s
  training loss:		0.005517
  validation loss:		0.578033
  validation accuracy:		91.85 %
Epoch 1367 of 2000 took 0.056s
  training loss:		0.005472
  validation loss:		0.581494
  validation accuracy:		91.74 %
Epoch 1368 of 2000 took 0.057s
  training loss:		0.005595
  validation loss:		0.577045
  validation accuracy:		91.85 %
Epoch 1369 of 2000 took 0.057s
  training loss:		0.005576
  validation loss:		0.582100
  validation accuracy:		91.52 %
Epoch 1370 of 2000 took 0.057s
  training loss:		0.005418
  validation loss:		0.576728
  validation accuracy:		91.41 %
Epoch 1371 of 2000 took 0.056s
  training loss:		0.005405
  validation loss:		0.585877
  validation accuracy:		91.74 %
Epoch 1372 of 2000 took 0.057s
  training loss:		0.005464
  validation loss:		0.576268
  validation accuracy:		91.74 %
Epoch 1373 of 2000 took 0.057s
  training loss:		0.005283
  validation loss:		0.587506
  validation accuracy:		91.52 %
Epoch 1374 of 2000 took 0.057s
  training loss:		0.005339
  validation loss:		0.581974
  validation accuracy:		91.74 %
Epoch 1375 of 2000 took 0.057s
  training loss:		0.005444
  validation loss:		0.592332
  validation accuracy:		91.63 %
Epoch 1376 of 2000 took 0.057s
  training loss:		0.005470
  validation loss:		0.582655
  validation accuracy:		91.52 %
Epoch 1377 of 2000 took 0.057s
  training loss:		0.005400
  validation loss:		0.583892
  validation accuracy:		91.52 %
Epoch 1378 of 2000 took 0.057s
  training loss:		0.005331
  validation loss:		0.584623
  validation accuracy:		91.63 %
Epoch 1379 of 2000 took 0.056s
  training loss:		0.005556
  validation loss:		0.579266
  validation accuracy:		91.74 %
Epoch 1380 of 2000 took 0.057s
  training loss:		0.005202
  validation loss:		0.591556
  validation accuracy:		91.63 %
Epoch 1381 of 2000 took 0.055s
  training loss:		0.005408
  validation loss:		0.584084
  validation accuracy:		91.63 %
Epoch 1382 of 2000 took 0.057s
  training loss:		0.005351
  validation loss:		0.580017
  validation accuracy:		91.63 %
Epoch 1383 of 2000 took 0.056s
  training loss:		0.005213
  validation loss:		0.584006
  validation accuracy:		91.74 %
Epoch 1384 of 2000 took 0.057s
  training loss:		0.005348
  validation loss:		0.580118
  validation accuracy:		91.74 %
Epoch 1385 of 2000 took 0.057s
  training loss:		0.005400
  validation loss:		0.590785
  validation accuracy:		91.30 %
Epoch 1386 of 2000 took 0.057s
  training loss:		0.005110
  validation loss:		0.586782
  validation accuracy:		91.63 %
Epoch 1387 of 2000 took 0.057s
  training loss:		0.005465
  validation loss:		0.587916
  validation accuracy:		91.74 %
Epoch 1388 of 2000 took 0.057s
  training loss:		0.005282
  validation loss:		0.582389
  validation accuracy:		91.52 %
Epoch 1389 of 2000 took 0.057s
  training loss:		0.005292
  validation loss:		0.590479
  validation accuracy:		91.30 %
Epoch 1390 of 2000 took 0.057s
  training loss:		0.005303
  validation loss:		0.582114
  validation accuracy:		91.85 %
Epoch 1391 of 2000 took 0.057s
  training loss:		0.005326
  validation loss:		0.579320
  validation accuracy:		91.63 %
Epoch 1392 of 2000 took 0.056s
  training loss:		0.005320
  validation loss:		0.587172
  validation accuracy:		91.63 %
Epoch 1393 of 2000 took 0.057s
  training loss:		0.005185
  validation loss:		0.589836
  validation accuracy:		91.63 %
Epoch 1394 of 2000 took 0.057s
  training loss:		0.005320
  validation loss:		0.577990
  validation accuracy:		91.41 %
Epoch 1395 of 2000 took 0.056s
  training loss:		0.005157
  validation loss:		0.586393
  validation accuracy:		91.52 %
Epoch 1396 of 2000 took 0.057s
  training loss:		0.005092
  validation loss:		0.594017
  validation accuracy:		91.63 %
Epoch 1397 of 2000 took 0.056s
  training loss:		0.005153
  validation loss:		0.583592
  validation accuracy:		91.85 %
Epoch 1398 of 2000 took 0.057s
  training loss:		0.005265
  validation loss:		0.588014
  validation accuracy:		91.63 %
Epoch 1399 of 2000 took 0.057s
  training loss:		0.005069
  validation loss:		0.585718
  validation accuracy:		91.74 %
Epoch 1400 of 2000 took 0.057s
  training loss:		0.005189
  validation loss:		0.589191
  validation accuracy:		91.74 %
Epoch 1401 of 2000 took 0.057s
  training loss:		0.005473
  validation loss:		0.589374
  validation accuracy:		91.52 %
Epoch 1402 of 2000 took 0.057s
  training loss:		0.005175
  validation loss:		0.587870
  validation accuracy:		91.74 %
Epoch 1403 of 2000 took 0.057s
  training loss:		0.005222
  validation loss:		0.593671
  validation accuracy:		91.74 %
Epoch 1404 of 2000 took 0.057s
  training loss:		0.005063
  validation loss:		0.580703
  validation accuracy:		91.74 %
Epoch 1405 of 2000 took 0.056s
  training loss:		0.005307
  validation loss:		0.588477
  validation accuracy:		91.74 %
Epoch 1406 of 2000 took 0.057s
  training loss:		0.005333
  validation loss:		0.584709
  validation accuracy:		91.85 %
Epoch 1407 of 2000 took 0.057s
  training loss:		0.005077
  validation loss:		0.597113
  validation accuracy:		91.63 %
Epoch 1408 of 2000 took 0.056s
  training loss:		0.005109
  validation loss:		0.581931
  validation accuracy:		91.74 %
Epoch 1409 of 2000 took 0.057s
  training loss:		0.005149
  validation loss:		0.591147
  validation accuracy:		91.63 %
Epoch 1410 of 2000 took 0.057s
  training loss:		0.005142
  validation loss:		0.593499
  validation accuracy:		91.63 %
Epoch 1411 of 2000 took 0.056s
  training loss:		0.005117
  validation loss:		0.592063
  validation accuracy:		91.63 %
Epoch 1412 of 2000 took 0.057s
  training loss:		0.005093
  validation loss:		0.590847
  validation accuracy:		91.20 %
Epoch 1413 of 2000 took 0.055s
  training loss:		0.005042
  validation loss:		0.588163
  validation accuracy:		91.85 %
Epoch 1414 of 2000 took 0.058s
  training loss:		0.005153
  validation loss:		0.588289
  validation accuracy:		91.63 %
Epoch 1415 of 2000 took 0.058s
  training loss:		0.004961
  validation loss:		0.602131
  validation accuracy:		91.20 %
Epoch 1416 of 2000 took 0.057s
  training loss:		0.005063
  validation loss:		0.588541
  validation accuracy:		91.74 %
Epoch 1417 of 2000 took 0.057s
  training loss:		0.004889
  validation loss:		0.591304
  validation accuracy:		91.63 %
Epoch 1418 of 2000 took 0.057s
  training loss:		0.005043
  validation loss:		0.595139
  validation accuracy:		91.52 %
Epoch 1419 of 2000 took 0.057s
  training loss:		0.005194
  validation loss:		0.587855
  validation accuracy:		91.63 %
Epoch 1420 of 2000 took 0.056s
  training loss:		0.005140
  validation loss:		0.583215
  validation accuracy:		91.85 %
Epoch 1421 of 2000 took 0.057s
  training loss:		0.005109
  validation loss:		0.592758
  validation accuracy:		91.20 %
Epoch 1422 of 2000 took 0.057s
  training loss:		0.005149
  validation loss:		0.587177
  validation accuracy:		91.63 %
Epoch 1423 of 2000 took 0.057s
  training loss:		0.004953
  validation loss:		0.596161
  validation accuracy:		91.30 %
Epoch 1424 of 2000 took 0.057s
  training loss:		0.004968
  validation loss:		0.591414
  validation accuracy:		91.41 %
Epoch 1425 of 2000 took 0.057s
  training loss:		0.004955
  validation loss:		0.589163
  validation accuracy:		91.85 %
Epoch 1426 of 2000 took 0.057s
  training loss:		0.004981
  validation loss:		0.597185
  validation accuracy:		91.63 %
Epoch 1427 of 2000 took 0.057s
  training loss:		0.004838
  validation loss:		0.594212
  validation accuracy:		91.63 %
Epoch 1428 of 2000 took 0.055s
  training loss:		0.004925
  validation loss:		0.592130
  validation accuracy:		91.63 %
Epoch 1429 of 2000 took 0.056s
  training loss:		0.004975
  validation loss:		0.594293
  validation accuracy:		91.52 %
Epoch 1430 of 2000 took 0.057s
  training loss:		0.004928
  validation loss:		0.595657
  validation accuracy:		91.30 %
Epoch 1431 of 2000 took 0.057s
  training loss:		0.005010
  validation loss:		0.596940
  validation accuracy:		91.52 %
Epoch 1432 of 2000 took 0.057s
  training loss:		0.004914
  validation loss:		0.590772
  validation accuracy:		91.85 %
Epoch 1433 of 2000 took 0.057s
  training loss:		0.004875
  validation loss:		0.596198
  validation accuracy:		91.52 %
Epoch 1434 of 2000 took 0.057s
  training loss:		0.004896
  validation loss:		0.592434
  validation accuracy:		91.63 %
Epoch 1435 of 2000 took 0.055s
  training loss:		0.004918
  validation loss:		0.599884
  validation accuracy:		91.41 %
Epoch 1436 of 2000 took 0.055s
  training loss:		0.004948
  validation loss:		0.589658
  validation accuracy:		91.63 %
Epoch 1437 of 2000 took 0.057s
  training loss:		0.005019
  validation loss:		0.586826
  validation accuracy:		91.74 %
Epoch 1438 of 2000 took 0.057s
  training loss:		0.004998
  validation loss:		0.593945
  validation accuracy:		91.52 %
Epoch 1439 of 2000 took 0.057s
  training loss:		0.004939
  validation loss:		0.594680
  validation accuracy:		91.52 %
Epoch 1440 of 2000 took 0.057s
  training loss:		0.004868
  validation loss:		0.595681
  validation accuracy:		91.85 %
Epoch 1441 of 2000 took 0.057s
  training loss:		0.004857
  validation loss:		0.595625
  validation accuracy:		91.63 %
Epoch 1442 of 2000 took 0.057s
  training loss:		0.004679
  validation loss:		0.593059
  validation accuracy:		91.74 %
Epoch 1443 of 2000 took 0.056s
  training loss:		0.004777
  validation loss:		0.588019
  validation accuracy:		91.63 %
Epoch 1444 of 2000 took 0.057s
  training loss:		0.004876
  validation loss:		0.593491
  validation accuracy:		91.85 %
Epoch 1445 of 2000 took 0.057s
  training loss:		0.004957
  validation loss:		0.592960
  validation accuracy:		91.74 %
Epoch 1446 of 2000 took 0.057s
  training loss:		0.004797
  validation loss:		0.590944
  validation accuracy:		91.63 %
Epoch 1447 of 2000 took 0.056s
  training loss:		0.004711
  validation loss:		0.603780
  validation accuracy:		91.52 %
Epoch 1448 of 2000 took 0.057s
  training loss:		0.004725
  validation loss:		0.597749
  validation accuracy:		91.63 %
Epoch 1449 of 2000 took 0.057s
  training loss:		0.004762
  validation loss:		0.596415
  validation accuracy:		91.63 %
Epoch 1450 of 2000 took 0.058s
  training loss:		0.004811
  validation loss:		0.600140
  validation accuracy:		91.52 %
Epoch 1451 of 2000 took 0.058s
  training loss:		0.004654
  validation loss:		0.594168
  validation accuracy:		91.63 %
Epoch 1452 of 2000 took 0.058s
  training loss:		0.004755
  validation loss:		0.596934
  validation accuracy:		91.52 %
Epoch 1453 of 2000 took 0.058s
  training loss:		0.004775
  validation loss:		0.591870
  validation accuracy:		91.85 %
Epoch 1454 of 2000 took 0.058s
  training loss:		0.004887
  validation loss:		0.599905
  validation accuracy:		91.41 %
Epoch 1455 of 2000 took 0.058s
  training loss:		0.004682
  validation loss:		0.591321
  validation accuracy:		91.85 %
Epoch 1456 of 2000 took 0.058s
  training loss:		0.004778
  validation loss:		0.590569
  validation accuracy:		91.52 %
Epoch 1457 of 2000 took 0.057s
  training loss:		0.004791
  validation loss:		0.598096
  validation accuracy:		91.63 %
Epoch 1458 of 2000 took 0.060s
  training loss:		0.004700
  validation loss:		0.603554
  validation accuracy:		91.52 %
Epoch 1459 of 2000 took 0.059s
  training loss:		0.004842
  validation loss:		0.599169
  validation accuracy:		91.41 %
Epoch 1460 of 2000 took 0.056s
  training loss:		0.004655
  validation loss:		0.604693
  validation accuracy:		91.63 %
Epoch 1461 of 2000 took 0.056s
  training loss:		0.004677
  validation loss:		0.594560
  validation accuracy:		91.52 %
Epoch 1462 of 2000 took 0.057s
  training loss:		0.004739
  validation loss:		0.597414
  validation accuracy:		91.85 %
Epoch 1463 of 2000 took 0.058s
  training loss:		0.004782
  validation loss:		0.602673
  validation accuracy:		91.74 %
Epoch 1464 of 2000 took 0.057s
  training loss:		0.004609
  validation loss:		0.595994
  validation accuracy:		91.63 %
Epoch 1465 of 2000 took 0.059s
  training loss:		0.004872
  validation loss:		0.599804
  validation accuracy:		91.63 %
Epoch 1466 of 2000 took 0.057s
  training loss:		0.004675
  validation loss:		0.605672
  validation accuracy:		91.63 %
Epoch 1467 of 2000 took 0.058s
  training loss:		0.004640
  validation loss:		0.599062
  validation accuracy:		91.52 %
Epoch 1468 of 2000 took 0.057s
  training loss:		0.004743
  validation loss:		0.601167
  validation accuracy:		91.63 %
Epoch 1469 of 2000 took 0.059s
  training loss:		0.004814
  validation loss:		0.605730
  validation accuracy:		91.52 %
Epoch 1470 of 2000 took 0.058s
  training loss:		0.004678
  validation loss:		0.601539
  validation accuracy:		91.63 %
Epoch 1471 of 2000 took 0.058s
  training loss:		0.004796
  validation loss:		0.602034
  validation accuracy:		91.30 %
Epoch 1472 of 2000 took 0.057s
  training loss:		0.004604
  validation loss:		0.598182
  validation accuracy:		91.74 %
Epoch 1473 of 2000 took 0.057s
  training loss:		0.004790
  validation loss:		0.598445
  validation accuracy:		91.74 %
Epoch 1474 of 2000 took 0.056s
  training loss:		0.004602
  validation loss:		0.599563
  validation accuracy:		91.52 %
Epoch 1475 of 2000 took 0.059s
  training loss:		0.004545
  validation loss:		0.600614
  validation accuracy:		91.74 %
Epoch 1476 of 2000 took 0.058s
  training loss:		0.004665
  validation loss:		0.602643
  validation accuracy:		91.63 %
Epoch 1477 of 2000 took 0.059s
  training loss:		0.004816
  validation loss:		0.594109
  validation accuracy:		91.85 %
Epoch 1478 of 2000 took 0.058s
  training loss:		0.004716
  validation loss:		0.617353
  validation accuracy:		91.41 %
Epoch 1479 of 2000 took 0.059s
  training loss:		0.004642
  validation loss:		0.608483
  validation accuracy:		91.74 %
Epoch 1480 of 2000 took 0.057s
  training loss:		0.004656
  validation loss:		0.604444
  validation accuracy:		91.52 %
Epoch 1481 of 2000 took 0.057s
  training loss:		0.004593
  validation loss:		0.612596
  validation accuracy:		91.30 %
Epoch 1482 of 2000 took 0.059s
  training loss:		0.004580
  validation loss:		0.601327
  validation accuracy:		91.74 %
Epoch 1483 of 2000 took 0.057s
  training loss:		0.004563
  validation loss:		0.598298
  validation accuracy:		91.63 %
Epoch 1484 of 2000 took 0.058s
  training loss:		0.004662
  validation loss:		0.607505
  validation accuracy:		91.63 %
Epoch 1485 of 2000 took 0.057s
  training loss:		0.004504
  validation loss:		0.611984
  validation accuracy:		91.52 %
Epoch 1486 of 2000 took 0.057s
  training loss:		0.004520
  validation loss:		0.590385
  validation accuracy:		91.74 %
Epoch 1487 of 2000 took 0.057s
  training loss:		0.004664
  validation loss:		0.613162
  validation accuracy:		91.63 %
Epoch 1488 of 2000 took 0.057s
  training loss:		0.004559
  validation loss:		0.603747
  validation accuracy:		91.74 %
Epoch 1489 of 2000 took 0.058s
  training loss:		0.004578
  validation loss:		0.612302
  validation accuracy:		91.52 %
Epoch 1490 of 2000 took 0.057s
  training loss:		0.004488
  validation loss:		0.604800
  validation accuracy:		91.63 %
Epoch 1491 of 2000 took 0.057s
  training loss:		0.004542
  validation loss:		0.612042
  validation accuracy:		91.74 %
Epoch 1492 of 2000 took 0.058s
  training loss:		0.004576
  validation loss:		0.608528
  validation accuracy:		91.52 %
Epoch 1493 of 2000 took 0.057s
  training loss:		0.004386
  validation loss:		0.601162
  validation accuracy:		91.85 %
Epoch 1494 of 2000 took 0.058s
  training loss:		0.004449
  validation loss:		0.607703
  validation accuracy:		91.52 %
Epoch 1495 of 2000 took 0.057s
  training loss:		0.004544
  validation loss:		0.600868
  validation accuracy:		91.63 %
Epoch 1496 of 2000 took 0.057s
  training loss:		0.004385
  validation loss:		0.600713
  validation accuracy:		91.85 %
Epoch 1497 of 2000 took 0.057s
  training loss:		0.004344
  validation loss:		0.610072
  validation accuracy:		91.52 %
Epoch 1498 of 2000 took 0.057s
  training loss:		0.004352
  validation loss:		0.599919
  validation accuracy:		91.85 %
Epoch 1499 of 2000 took 0.057s
  training loss:		0.004452
  validation loss:		0.607157
  validation accuracy:		91.41 %
Epoch 1500 of 2000 took 0.057s
  training loss:		0.004458
  validation loss:		0.606059
  validation accuracy:		91.63 %
Epoch 1501 of 2000 took 0.057s
  training loss:		0.004441
  validation loss:		0.604084
  validation accuracy:		91.41 %
Epoch 1502 of 2000 took 0.058s
  training loss:		0.004590
  validation loss:		0.610291
  validation accuracy:		91.52 %
Epoch 1503 of 2000 took 0.062s
  training loss:		0.004377
  validation loss:		0.613215
  validation accuracy:		91.52 %
Epoch 1504 of 2000 took 0.057s
  training loss:		0.004472
  validation loss:		0.614260
  validation accuracy:		91.52 %
Epoch 1505 of 2000 took 0.056s
  training loss:		0.004433
  validation loss:		0.600257
  validation accuracy:		91.52 %
Epoch 1506 of 2000 took 0.057s
  training loss:		0.004535
  validation loss:		0.601620
  validation accuracy:		91.41 %
Epoch 1507 of 2000 took 0.058s
  training loss:		0.004456
  validation loss:		0.611410
  validation accuracy:		91.52 %
Epoch 1508 of 2000 took 0.056s
  training loss:		0.004390
  validation loss:		0.605816
  validation accuracy:		91.74 %
Epoch 1509 of 2000 took 0.056s
  training loss:		0.004439
  validation loss:		0.612163
  validation accuracy:		91.63 %
Epoch 1510 of 2000 took 0.056s
  training loss:		0.004319
  validation loss:		0.607762
  validation accuracy:		91.63 %
Epoch 1511 of 2000 took 0.055s
  training loss:		0.004350
  validation loss:		0.605029
  validation accuracy:		91.41 %
Epoch 1512 of 2000 took 0.055s
  training loss:		0.004433
  validation loss:		0.600142
  validation accuracy:		91.74 %
Epoch 1513 of 2000 took 0.055s
  training loss:		0.004445
  validation loss:		0.612095
  validation accuracy:		91.63 %
Epoch 1514 of 2000 took 0.055s
  training loss:		0.004271
  validation loss:		0.614491
  validation accuracy:		91.52 %
Epoch 1515 of 2000 took 0.056s
  training loss:		0.004381
  validation loss:		0.605700
  validation accuracy:		91.30 %
Epoch 1516 of 2000 took 0.056s
  training loss:		0.004163
  validation loss:		0.607909
  validation accuracy:		91.63 %
Epoch 1517 of 2000 took 0.058s
  training loss:		0.004416
  validation loss:		0.621408
  validation accuracy:		91.74 %
Epoch 1518 of 2000 took 0.059s
  training loss:		0.004462
  validation loss:		0.604896
  validation accuracy:		91.30 %
Epoch 1519 of 2000 took 0.056s
  training loss:		0.004357
  validation loss:		0.617802
  validation accuracy:		91.63 %
Epoch 1520 of 2000 took 0.057s
  training loss:		0.004209
  validation loss:		0.605259
  validation accuracy:		91.74 %
Epoch 1521 of 2000 took 0.059s
  training loss:		0.004345
  validation loss:		0.619785
  validation accuracy:		91.52 %
Epoch 1522 of 2000 took 0.057s
  training loss:		0.004405
  validation loss:		0.613346
  validation accuracy:		91.85 %
Epoch 1523 of 2000 took 0.060s
  training loss:		0.004303
  validation loss:		0.606378
  validation accuracy:		91.74 %
Epoch 1524 of 2000 took 0.058s
  training loss:		0.004388
  validation loss:		0.617357
  validation accuracy:		91.41 %
Epoch 1525 of 2000 took 0.057s
  training loss:		0.004420
  validation loss:		0.612347
  validation accuracy:		91.52 %
Epoch 1526 of 2000 took 0.059s
  training loss:		0.004268
  validation loss:		0.612646
  validation accuracy:		91.74 %
Epoch 1527 of 2000 took 0.058s
  training loss:		0.004429
  validation loss:		0.605099
  validation accuracy:		91.74 %
Epoch 1528 of 2000 took 0.059s
  training loss:		0.004330
  validation loss:		0.615242
  validation accuracy:		91.63 %
Epoch 1529 of 2000 took 0.058s
  training loss:		0.004309
  validation loss:		0.610743
  validation accuracy:		91.63 %
Epoch 1530 of 2000 took 0.058s
  training loss:		0.004305
  validation loss:		0.613384
  validation accuracy:		91.52 %
Epoch 1531 of 2000 took 0.059s
  training loss:		0.004048
  validation loss:		0.618618
  validation accuracy:		91.63 %
Epoch 1532 of 2000 took 0.059s
  training loss:		0.004242
  validation loss:		0.619533
  validation accuracy:		91.30 %
Epoch 1533 of 2000 took 0.058s
  training loss:		0.004291
  validation loss:		0.620255
  validation accuracy:		91.63 %
Epoch 1534 of 2000 took 0.057s
  training loss:		0.004298
  validation loss:		0.610247
  validation accuracy:		91.52 %
Epoch 1535 of 2000 took 0.060s
  training loss:		0.004373
  validation loss:		0.614859
  validation accuracy:		91.74 %
Epoch 1536 of 2000 took 0.058s
  training loss:		0.004243
  validation loss:		0.614912
  validation accuracy:		91.63 %
Epoch 1537 of 2000 took 0.058s
  training loss:		0.004182
  validation loss:		0.617885
  validation accuracy:		91.30 %
Epoch 1538 of 2000 took 0.058s
  training loss:		0.004277
  validation loss:		0.616675
  validation accuracy:		91.63 %
Epoch 1539 of 2000 took 0.058s
  training loss:		0.004252
  validation loss:		0.616132
  validation accuracy:		91.85 %
Epoch 1540 of 2000 took 0.058s
  training loss:		0.004127
  validation loss:		0.615796
  validation accuracy:		91.41 %
Epoch 1541 of 2000 took 0.058s
  training loss:		0.004282
  validation loss:		0.609027
  validation accuracy:		91.63 %
Epoch 1542 of 2000 took 0.058s
  training loss:		0.004135
  validation loss:		0.613787
  validation accuracy:		91.74 %
Epoch 1543 of 2000 took 0.058s
  training loss:		0.004221
  validation loss:		0.610759
  validation accuracy:		91.63 %
Epoch 1544 of 2000 took 0.058s
  training loss:		0.004233
  validation loss:		0.609926
  validation accuracy:		91.63 %
Epoch 1545 of 2000 took 0.058s
  training loss:		0.004022
  validation loss:		0.621536
  validation accuracy:		91.74 %
Epoch 1546 of 2000 took 0.058s
  training loss:		0.004172
  validation loss:		0.609799
  validation accuracy:		91.52 %
Epoch 1547 of 2000 took 0.058s
  training loss:		0.004199
  validation loss:		0.613112
  validation accuracy:		91.74 %
Epoch 1548 of 2000 took 0.058s
  training loss:		0.004063
  validation loss:		0.619374
  validation accuracy:		91.30 %
Epoch 1549 of 2000 took 0.058s
  training loss:		0.004180
  validation loss:		0.619177
  validation accuracy:		91.74 %
Epoch 1550 of 2000 took 0.058s
  training loss:		0.004151
  validation loss:		0.622107
  validation accuracy:		91.30 %
Epoch 1551 of 2000 took 0.058s
  training loss:		0.004169
  validation loss:		0.620325
  validation accuracy:		91.74 %
Epoch 1552 of 2000 took 0.058s
  training loss:		0.003975
  validation loss:		0.623119
  validation accuracy:		91.52 %
Epoch 1553 of 2000 took 0.058s
  training loss:		0.004110
  validation loss:		0.617024
  validation accuracy:		91.74 %
Epoch 1554 of 2000 took 0.059s
  training loss:		0.004129
  validation loss:		0.612399
  validation accuracy:		91.63 %
Epoch 1555 of 2000 took 0.058s
  training loss:		0.004204
  validation loss:		0.611578
  validation accuracy:		91.74 %
Epoch 1556 of 2000 took 0.058s
  training loss:		0.004172
  validation loss:		0.620911
  validation accuracy:		91.63 %
Epoch 1557 of 2000 took 0.058s
  training loss:		0.004152
  validation loss:		0.623469
  validation accuracy:		91.30 %
Epoch 1558 of 2000 took 0.058s
  training loss:		0.004080
  validation loss:		0.618481
  validation accuracy:		91.41 %
Epoch 1559 of 2000 took 0.058s
  training loss:		0.004047
  validation loss:		0.617269
  validation accuracy:		91.74 %
Epoch 1560 of 2000 took 0.058s
  training loss:		0.004071
  validation loss:		0.622842
  validation accuracy:		91.52 %
Epoch 1561 of 2000 took 0.058s
  training loss:		0.004150
  validation loss:		0.627025
  validation accuracy:		91.30 %
Epoch 1562 of 2000 took 0.058s
  training loss:		0.004236
  validation loss:		0.620642
  validation accuracy:		91.63 %
Epoch 1563 of 2000 took 0.058s
  training loss:		0.004114
  validation loss:		0.616751
  validation accuracy:		91.52 %
Epoch 1564 of 2000 took 0.058s
  training loss:		0.004094
  validation loss:		0.624613
  validation accuracy:		91.63 %
Epoch 1565 of 2000 took 0.058s
  training loss:		0.004021
  validation loss:		0.612859
  validation accuracy:		91.74 %
Epoch 1566 of 2000 took 0.058s
  training loss:		0.004007
  validation loss:		0.621439
  validation accuracy:		91.41 %
Epoch 1567 of 2000 took 0.058s
  training loss:		0.004035
  validation loss:		0.618207
  validation accuracy:		91.63 %
Epoch 1568 of 2000 took 0.058s
  training loss:		0.004036
  validation loss:		0.626654
  validation accuracy:		91.52 %
Epoch 1569 of 2000 took 0.058s
  training loss:		0.004142
  validation loss:		0.618679
  validation accuracy:		91.41 %
Epoch 1570 of 2000 took 0.058s
  training loss:		0.003975
  validation loss:		0.614574
  validation accuracy:		91.41 %
Epoch 1571 of 2000 took 0.058s
  training loss:		0.004094
  validation loss:		0.624478
  validation accuracy:		91.41 %
Epoch 1572 of 2000 took 0.058s
  training loss:		0.003966
  validation loss:		0.613532
  validation accuracy:		91.74 %
Epoch 1573 of 2000 took 0.058s
  training loss:		0.003955
  validation loss:		0.620767
  validation accuracy:		91.52 %
Epoch 1574 of 2000 took 0.057s
  training loss:		0.003988
  validation loss:		0.617772
  validation accuracy:		91.74 %
Epoch 1575 of 2000 took 0.057s
  training loss:		0.003952
  validation loss:		0.616993
  validation accuracy:		91.52 %
Epoch 1576 of 2000 took 0.057s
  training loss:		0.004036
  validation loss:		0.616409
  validation accuracy:		91.74 %
Epoch 1577 of 2000 took 0.057s
  training loss:		0.003970
  validation loss:		0.628218
  validation accuracy:		91.52 %
Epoch 1578 of 2000 took 0.058s
  training loss:		0.003968
  validation loss:		0.616615
  validation accuracy:		91.74 %
Epoch 1579 of 2000 took 0.057s
  training loss:		0.003999
  validation loss:		0.621870
  validation accuracy:		91.63 %
Epoch 1580 of 2000 took 0.057s
  training loss:		0.003955
  validation loss:		0.627329
  validation accuracy:		91.52 %
Epoch 1581 of 2000 took 0.057s
  training loss:		0.003982
  validation loss:		0.623099
  validation accuracy:		91.52 %
Epoch 1582 of 2000 took 0.057s
  training loss:		0.003885
  validation loss:		0.624954
  validation accuracy:		91.41 %
Epoch 1583 of 2000 took 0.057s
  training loss:		0.004029
  validation loss:		0.627424
  validation accuracy:		91.52 %
Epoch 1584 of 2000 took 0.057s
  training loss:		0.003900
  validation loss:		0.618848
  validation accuracy:		91.74 %
Epoch 1585 of 2000 took 0.057s
  training loss:		0.004063
  validation loss:		0.626976
  validation accuracy:		91.63 %
Epoch 1586 of 2000 took 0.057s
  training loss:		0.003934
  validation loss:		0.622716
  validation accuracy:		91.74 %
Epoch 1587 of 2000 took 0.057s
  training loss:		0.003870
  validation loss:		0.627388
  validation accuracy:		91.52 %
Epoch 1588 of 2000 took 0.058s
  training loss:		0.003823
  validation loss:		0.624002
  validation accuracy:		91.52 %
Epoch 1589 of 2000 took 0.057s
  training loss:		0.003947
  validation loss:		0.625712
  validation accuracy:		91.52 %
Epoch 1590 of 2000 took 0.057s
  training loss:		0.003819
  validation loss:		0.623694
  validation accuracy:		91.41 %
Epoch 1591 of 2000 took 0.057s
  training loss:		0.003877
  validation loss:		0.628839
  validation accuracy:		91.52 %
Epoch 1592 of 2000 took 0.057s
  training loss:		0.003893
  validation loss:		0.623856
  validation accuracy:		91.74 %
Epoch 1593 of 2000 took 0.057s
  training loss:		0.003889
  validation loss:		0.620801
  validation accuracy:		91.63 %
Epoch 1594 of 2000 took 0.057s
  training loss:		0.003973
  validation loss:		0.627767
  validation accuracy:		91.52 %
Epoch 1595 of 2000 took 0.057s
  training loss:		0.003926
  validation loss:		0.625498
  validation accuracy:		91.74 %
Epoch 1596 of 2000 took 0.058s
  training loss:		0.003827
  validation loss:		0.623878
  validation accuracy:		91.63 %
Epoch 1597 of 2000 took 0.057s
  training loss:		0.003918
  validation loss:		0.616262
  validation accuracy:		91.63 %
Epoch 1598 of 2000 took 0.057s
  training loss:		0.003962
  validation loss:		0.620171
  validation accuracy:		91.63 %
Epoch 1599 of 2000 took 0.057s
  training loss:		0.003891
  validation loss:		0.622661
  validation accuracy:		91.74 %
Epoch 1600 of 2000 took 0.057s
  training loss:		0.003734
  validation loss:		0.626320
  validation accuracy:		91.30 %
Epoch 1601 of 2000 took 0.057s
  training loss:		0.003883
  validation loss:		0.619538
  validation accuracy:		91.63 %
Epoch 1602 of 2000 took 0.057s
  training loss:		0.003944
  validation loss:		0.622019
  validation accuracy:		91.74 %
Epoch 1603 of 2000 took 0.057s
  training loss:		0.003933
  validation loss:		0.630775
  validation accuracy:		91.63 %
Epoch 1604 of 2000 took 0.057s
  training loss:		0.003902
  validation loss:		0.629501
  validation accuracy:		91.52 %
Epoch 1605 of 2000 took 0.058s
  training loss:		0.003921
  validation loss:		0.623831
  validation accuracy:		91.63 %
Epoch 1606 of 2000 took 0.058s
  training loss:		0.003818
  validation loss:		0.624194
  validation accuracy:		91.74 %
Epoch 1607 of 2000 took 0.058s
  training loss:		0.003942
  validation loss:		0.628208
  validation accuracy:		91.74 %
Epoch 1608 of 2000 took 0.058s
  training loss:		0.003896
  validation loss:		0.626205
  validation accuracy:		91.63 %
Epoch 1609 of 2000 took 0.058s
  training loss:		0.003793
  validation loss:		0.630881
  validation accuracy:		91.41 %
Epoch 1610 of 2000 took 0.058s
  training loss:		0.003946
  validation loss:		0.618352
  validation accuracy:		91.52 %
Epoch 1611 of 2000 took 0.058s
  training loss:		0.004037
  validation loss:		0.626594
  validation accuracy:		91.63 %
Epoch 1612 of 2000 took 0.058s
  training loss:		0.003953
  validation loss:		0.623817
  validation accuracy:		91.74 %
Epoch 1613 of 2000 took 0.058s
  training loss:		0.003895
  validation loss:		0.629065
  validation accuracy:		91.63 %
Epoch 1614 of 2000 took 0.058s
  training loss:		0.003794
  validation loss:		0.626506
  validation accuracy:		91.74 %
Epoch 1615 of 2000 took 0.058s
  training loss:		0.003881
  validation loss:		0.624858
  validation accuracy:		91.74 %
Epoch 1616 of 2000 took 0.057s
  training loss:		0.003862
  validation loss:		0.627968
  validation accuracy:		91.63 %
Epoch 1617 of 2000 took 0.057s
  training loss:		0.003880
  validation loss:		0.626949
  validation accuracy:		91.85 %
Epoch 1618 of 2000 took 0.057s
  training loss:		0.003889
  validation loss:		0.618816
  validation accuracy:		91.63 %
Epoch 1619 of 2000 took 0.058s
  training loss:		0.003806
  validation loss:		0.637426
  validation accuracy:		91.52 %
Epoch 1620 of 2000 took 0.057s
  training loss:		0.003760
  validation loss:		0.626064
  validation accuracy:		91.63 %
Epoch 1621 of 2000 took 0.057s
  training loss:		0.003767
  validation loss:		0.628606
  validation accuracy:		91.74 %
Epoch 1622 of 2000 took 0.057s
  training loss:		0.003897
  validation loss:		0.628479
  validation accuracy:		91.52 %
Epoch 1623 of 2000 took 0.057s
  training loss:		0.003718
  validation loss:		0.631188
  validation accuracy:		91.63 %
Epoch 1624 of 2000 took 0.057s
  training loss:		0.003838
  validation loss:		0.627744
  validation accuracy:		91.74 %
Epoch 1625 of 2000 took 0.057s
  training loss:		0.003731
  validation loss:		0.628666
  validation accuracy:		91.63 %
Epoch 1626 of 2000 took 0.058s
  training loss:		0.003883
  validation loss:		0.628913
  validation accuracy:		91.52 %
Epoch 1627 of 2000 took 0.057s
  training loss:		0.003683
  validation loss:		0.626102
  validation accuracy:		91.74 %
Epoch 1628 of 2000 took 0.057s
  training loss:		0.003823
  validation loss:		0.631657
  validation accuracy:		91.63 %
Epoch 1629 of 2000 took 0.057s
  training loss:		0.003773
  validation loss:		0.633438
  validation accuracy:		91.63 %
Epoch 1630 of 2000 took 0.057s
  training loss:		0.003849
  validation loss:		0.635165
  validation accuracy:		91.41 %
Epoch 1631 of 2000 took 0.058s
  training loss:		0.003602
  validation loss:		0.630328
  validation accuracy:		91.63 %
Epoch 1632 of 2000 took 0.058s
  training loss:		0.003825
  validation loss:		0.638774
  validation accuracy:		91.41 %
Epoch 1633 of 2000 took 0.058s
  training loss:		0.003701
  validation loss:		0.637316
  validation accuracy:		91.63 %
Epoch 1634 of 2000 took 0.058s
  training loss:		0.003686
  validation loss:		0.629896
  validation accuracy:		91.63 %
Epoch 1635 of 2000 took 0.058s
  training loss:		0.003626
  validation loss:		0.633705
  validation accuracy:		91.63 %
Epoch 1636 of 2000 took 0.058s
  training loss:		0.003713
  validation loss:		0.622612
  validation accuracy:		91.52 %
Epoch 1637 of 2000 took 0.057s
  training loss:		0.003688
  validation loss:		0.637354
  validation accuracy:		91.63 %
Epoch 1638 of 2000 took 0.057s
  training loss:		0.003639
  validation loss:		0.631551
  validation accuracy:		91.74 %
Epoch 1639 of 2000 took 0.057s
  training loss:		0.003764
  validation loss:		0.636703
  validation accuracy:		91.41 %
Epoch 1640 of 2000 took 0.057s
  training loss:		0.003617
  validation loss:		0.635648
  validation accuracy:		91.63 %
Epoch 1641 of 2000 took 0.058s
  training loss:		0.003734
  validation loss:		0.630711
  validation accuracy:		91.63 %
Epoch 1642 of 2000 took 0.058s
  training loss:		0.003640
  validation loss:		0.632491
  validation accuracy:		91.52 %
Epoch 1643 of 2000 took 0.058s
  training loss:		0.003634
  validation loss:		0.633204
  validation accuracy:		91.52 %
Epoch 1644 of 2000 took 0.058s
  training loss:		0.003795
  validation loss:		0.631080
  validation accuracy:		91.74 %
Epoch 1645 of 2000 took 0.058s
  training loss:		0.003626
  validation loss:		0.637462
  validation accuracy:		91.52 %
Epoch 1646 of 2000 took 0.057s
  training loss:		0.003792
  validation loss:		0.632075
  validation accuracy:		91.74 %
Epoch 1647 of 2000 took 0.057s
  training loss:		0.003621
  validation loss:		0.637536
  validation accuracy:		91.52 %
Epoch 1648 of 2000 took 0.057s
  training loss:		0.003651
  validation loss:		0.629279
  validation accuracy:		91.74 %
Epoch 1649 of 2000 took 0.057s
  training loss:		0.003553
  validation loss:		0.633972
  validation accuracy:		91.63 %
Epoch 1650 of 2000 took 0.057s
  training loss:		0.003614
  validation loss:		0.633407
  validation accuracy:		91.52 %
Epoch 1651 of 2000 took 0.057s
  training loss:		0.003708
  validation loss:		0.632485
  validation accuracy:		91.63 %
Epoch 1652 of 2000 took 0.057s
  training loss:		0.003647
  validation loss:		0.629782
  validation accuracy:		91.63 %
Epoch 1653 of 2000 took 0.057s
  training loss:		0.003642
  validation loss:		0.640933
  validation accuracy:		91.41 %
Epoch 1654 of 2000 took 0.057s
  training loss:		0.003563
  validation loss:		0.627882
  validation accuracy:		91.74 %
Epoch 1655 of 2000 took 0.057s
  training loss:		0.003679
  validation loss:		0.635725
  validation accuracy:		91.52 %
Epoch 1656 of 2000 took 0.057s
  training loss:		0.003635
  validation loss:		0.639404
  validation accuracy:		91.41 %
Epoch 1657 of 2000 took 0.057s
  training loss:		0.003667
  validation loss:		0.637206
  validation accuracy:		91.63 %
Epoch 1658 of 2000 took 0.057s
  training loss:		0.003627
  validation loss:		0.629258
  validation accuracy:		91.63 %
Epoch 1659 of 2000 took 0.057s
  training loss:		0.003648
  validation loss:		0.631517
  validation accuracy:		91.63 %
Epoch 1660 of 2000 took 0.057s
  training loss:		0.003686
  validation loss:		0.633104
  validation accuracy:		91.63 %
Epoch 1661 of 2000 took 0.057s
  training loss:		0.003466
  validation loss:		0.632996
  validation accuracy:		91.63 %
Epoch 1662 of 2000 took 0.057s
  training loss:		0.003630
  validation loss:		0.633878
  validation accuracy:		91.74 %
Epoch 1663 of 2000 took 0.057s
  training loss:		0.003627
  validation loss:		0.650584
  validation accuracy:		91.09 %
Epoch 1664 of 2000 took 0.057s
  training loss:		0.003669
  validation loss:		0.636107
  validation accuracy:		91.74 %
Epoch 1665 of 2000 took 0.057s
  training loss:		0.003598
  validation loss:		0.629713
  validation accuracy:		91.52 %
Epoch 1666 of 2000 took 0.058s
  training loss:		0.003735
  validation loss:		0.633426
  validation accuracy:		91.74 %
Epoch 1667 of 2000 took 0.057s
  training loss:		0.003624
  validation loss:		0.642446
  validation accuracy:		91.41 %
Epoch 1668 of 2000 took 0.057s
  training loss:		0.003538
  validation loss:		0.635296
  validation accuracy:		91.30 %
Epoch 1669 of 2000 took 0.057s
  training loss:		0.003553
  validation loss:		0.646485
  validation accuracy:		91.30 %
Epoch 1670 of 2000 took 0.057s
  training loss:		0.003633
  validation loss:		0.645509
  validation accuracy:		91.41 %
Epoch 1671 of 2000 took 0.058s
  training loss:		0.003676
  validation loss:		0.631475
  validation accuracy:		91.74 %
Epoch 1672 of 2000 took 0.058s
  training loss:		0.003559
  validation loss:		0.630600
  validation accuracy:		91.52 %
Epoch 1673 of 2000 took 0.058s
  training loss:		0.003570
  validation loss:		0.636890
  validation accuracy:		91.63 %
Epoch 1674 of 2000 took 0.058s
  training loss:		0.003536
  validation loss:		0.646509
  validation accuracy:		91.41 %
Epoch 1675 of 2000 took 0.058s
  training loss:		0.003462
  validation loss:		0.636830
  validation accuracy:		91.74 %
Epoch 1676 of 2000 took 0.058s
  training loss:		0.003554
  validation loss:		0.634899
  validation accuracy:		91.63 %
Epoch 1677 of 2000 took 0.058s
  training loss:		0.003555
  validation loss:		0.639313
  validation accuracy:		91.63 %
Epoch 1678 of 2000 took 0.058s
  training loss:		0.003558
  validation loss:		0.647712
  validation accuracy:		91.20 %
Epoch 1679 of 2000 took 0.058s
  training loss:		0.003507
  validation loss:		0.635668
  validation accuracy:		91.63 %
Epoch 1680 of 2000 took 0.058s
  training loss:		0.003632
  validation loss:		0.645522
  validation accuracy:		91.20 %
Epoch 1681 of 2000 took 0.058s
  training loss:		0.003667
  validation loss:		0.645344
  validation accuracy:		91.41 %
Epoch 1682 of 2000 took 0.058s
  training loss:		0.003430
  validation loss:		0.639431
  validation accuracy:		91.74 %
Epoch 1683 of 2000 took 0.058s
  training loss:		0.003475
  validation loss:		0.643002
  validation accuracy:		91.63 %
Epoch 1684 of 2000 took 0.058s
  training loss:		0.003495
  validation loss:		0.638492
  validation accuracy:		91.74 %
Epoch 1685 of 2000 took 0.058s
  training loss:		0.003493
  validation loss:		0.637227
  validation accuracy:		91.74 %
Epoch 1686 of 2000 took 0.058s
  training loss:		0.003554
  validation loss:		0.632540
  validation accuracy:		91.52 %
Epoch 1687 of 2000 took 0.058s
  training loss:		0.003575
  validation loss:		0.633157
  validation accuracy:		91.52 %
Epoch 1688 of 2000 took 0.058s
  training loss:		0.003494
  validation loss:		0.644396
  validation accuracy:		91.52 %
Epoch 1689 of 2000 took 0.058s
  training loss:		0.003456
  validation loss:		0.635354
  validation accuracy:		91.63 %
Epoch 1690 of 2000 took 0.058s
  training loss:		0.003433
  validation loss:		0.648190
  validation accuracy:		91.63 %
Epoch 1691 of 2000 took 0.058s
  training loss:		0.003462
  validation loss:		0.642900
  validation accuracy:		91.63 %
Epoch 1692 of 2000 took 0.058s
  training loss:		0.003494
  validation loss:		0.646750
  validation accuracy:		91.30 %
Epoch 1693 of 2000 took 0.058s
  training loss:		0.003370
  validation loss:		0.638888
  validation accuracy:		91.63 %
Epoch 1694 of 2000 took 0.057s
  training loss:		0.003509
  validation loss:		0.648073
  validation accuracy:		91.52 %
Epoch 1695 of 2000 took 0.059s
  training loss:		0.003452
  validation loss:		0.642655
  validation accuracy:		91.63 %
Epoch 1696 of 2000 took 0.057s
  training loss:		0.003493
  validation loss:		0.640853
  validation accuracy:		91.63 %
Epoch 1697 of 2000 took 0.057s
  training loss:		0.003519
  validation loss:		0.646289
  validation accuracy:		91.63 %
Epoch 1698 of 2000 took 0.057s
  training loss:		0.003462
  validation loss:		0.646191
  validation accuracy:		91.74 %
Epoch 1699 of 2000 took 0.057s
  training loss:		0.003499
  validation loss:		0.639024
  validation accuracy:		91.85 %
Epoch 1700 of 2000 took 0.057s
  training loss:		0.003487
  validation loss:		0.640022
  validation accuracy:		91.52 %
Epoch 1701 of 2000 took 0.057s
  training loss:		0.003427
  validation loss:		0.644125
  validation accuracy:		91.63 %
Epoch 1702 of 2000 took 0.057s
  training loss:		0.003374
  validation loss:		0.645229
  validation accuracy:		91.63 %
Epoch 1703 of 2000 took 0.057s
  training loss:		0.003346
  validation loss:		0.643727
  validation accuracy:		91.63 %
Epoch 1704 of 2000 took 0.057s
  training loss:		0.003426
  validation loss:		0.644050
  validation accuracy:		91.63 %
Epoch 1705 of 2000 took 0.057s
  training loss:		0.003319
  validation loss:		0.649943
  validation accuracy:		91.63 %
Epoch 1706 of 2000 took 0.057s
  training loss:		0.003510
  validation loss:		0.646534
  validation accuracy:		91.74 %
Epoch 1707 of 2000 took 0.058s
  training loss:		0.003451
  validation loss:		0.645836
  validation accuracy:		91.63 %
Epoch 1708 of 2000 took 0.056s
  training loss:		0.003384
  validation loss:		0.648589
  validation accuracy:		91.41 %
Epoch 1709 of 2000 took 0.059s
  training loss:		0.003471
  validation loss:		0.642612
  validation accuracy:		91.63 %
Epoch 1710 of 2000 took 0.057s
  training loss:		0.003362
  validation loss:		0.649295
  validation accuracy:		91.30 %
Epoch 1711 of 2000 took 0.058s
  training loss:		0.003325
  validation loss:		0.634085
  validation accuracy:		91.63 %
Epoch 1712 of 2000 took 0.058s
  training loss:		0.003350
  validation loss:		0.659537
  validation accuracy:		91.30 %
Epoch 1713 of 2000 took 0.058s
  training loss:		0.003413
  validation loss:		0.638463
  validation accuracy:		91.63 %
Epoch 1714 of 2000 took 0.059s
  training loss:		0.003374
  validation loss:		0.648578
  validation accuracy:		91.41 %
Epoch 1715 of 2000 took 0.056s
  training loss:		0.003399
  validation loss:		0.647421
  validation accuracy:		91.63 %
Epoch 1716 of 2000 took 0.059s
  training loss:		0.003345
  validation loss:		0.644643
  validation accuracy:		91.63 %
Epoch 1717 of 2000 took 0.058s
  training loss:		0.003396
  validation loss:		0.644930
  validation accuracy:		91.63 %
Epoch 1718 of 2000 took 0.057s
  training loss:		0.003297
  validation loss:		0.648363
  validation accuracy:		91.63 %
Epoch 1719 of 2000 took 0.058s
  training loss:		0.003324
  validation loss:		0.645520
  validation accuracy:		91.74 %
Epoch 1720 of 2000 took 0.058s
  training loss:		0.003247
  validation loss:		0.648345
  validation accuracy:		91.52 %
Epoch 1721 of 2000 took 0.058s
  training loss:		0.003389
  validation loss:		0.646191
  validation accuracy:		91.63 %
Epoch 1722 of 2000 took 0.059s
  training loss:		0.003464
  validation loss:		0.653721
  validation accuracy:		91.09 %
Epoch 1723 of 2000 took 0.057s
  training loss:		0.003362
  validation loss:		0.640360
  validation accuracy:		91.52 %
Epoch 1724 of 2000 took 0.058s
  training loss:		0.003372
  validation loss:		0.647388
  validation accuracy:		91.74 %
Epoch 1725 of 2000 took 0.056s
  training loss:		0.003325
  validation loss:		0.647107
  validation accuracy:		91.30 %
Epoch 1726 of 2000 took 0.056s
  training loss:		0.003381
  validation loss:		0.641797
  validation accuracy:		91.63 %
Epoch 1727 of 2000 took 0.059s
  training loss:		0.003362
  validation loss:		0.650062
  validation accuracy:		91.63 %
Epoch 1728 of 2000 took 0.058s
  training loss:		0.003269
  validation loss:		0.652189
  validation accuracy:		91.63 %
Epoch 1729 of 2000 took 0.059s
  training loss:		0.003335
  validation loss:		0.656212
  validation accuracy:		91.09 %
Epoch 1730 of 2000 took 0.058s
  training loss:		0.003350
  validation loss:		0.640833
  validation accuracy:		91.63 %
Epoch 1731 of 2000 took 0.058s
  training loss:		0.003303
  validation loss:		0.651343
  validation accuracy:		91.52 %
Epoch 1732 of 2000 took 0.058s
  training loss:		0.003295
  validation loss:		0.655901
  validation accuracy:		91.30 %
Epoch 1733 of 2000 took 0.058s
  training loss:		0.003283
  validation loss:		0.643735
  validation accuracy:		91.63 %
Epoch 1734 of 2000 took 0.058s
  training loss:		0.003266
  validation loss:		0.641194
  validation accuracy:		91.52 %
Epoch 1735 of 2000 took 0.058s
  training loss:		0.003365
  validation loss:		0.647346
  validation accuracy:		91.63 %
Epoch 1736 of 2000 took 0.058s
  training loss:		0.003377
  validation loss:		0.651564
  validation accuracy:		91.63 %
Epoch 1737 of 2000 took 0.058s
  training loss:		0.003247
  validation loss:		0.651917
  validation accuracy:		91.41 %
Epoch 1738 of 2000 took 0.058s
  training loss:		0.003293
  validation loss:		0.647317
  validation accuracy:		91.63 %
Epoch 1739 of 2000 took 0.058s
  training loss:		0.003258
  validation loss:		0.649325
  validation accuracy:		91.52 %
Epoch 1740 of 2000 took 0.058s
  training loss:		0.003247
  validation loss:		0.647641
  validation accuracy:		91.74 %
Epoch 1741 of 2000 took 0.057s
  training loss:		0.003237
  validation loss:		0.649424
  validation accuracy:		91.52 %
Epoch 1742 of 2000 took 0.057s
  training loss:		0.003290
  validation loss:		0.647755
  validation accuracy:		91.63 %
Epoch 1743 of 2000 took 0.057s
  training loss:		0.003198
  validation loss:		0.641040
  validation accuracy:		91.74 %
Epoch 1744 of 2000 took 0.057s
  training loss:		0.003330
  validation loss:		0.648335
  validation accuracy:		91.63 %
Epoch 1745 of 2000 took 0.057s
  training loss:		0.003185
  validation loss:		0.649218
  validation accuracy:		91.63 %
Epoch 1746 of 2000 took 0.057s
  training loss:		0.003300
  validation loss:		0.657675
  validation accuracy:		91.41 %
Epoch 1747 of 2000 took 0.057s
  training loss:		0.003158
  validation loss:		0.644568
  validation accuracy:		91.63 %
Epoch 1748 of 2000 took 0.057s
  training loss:		0.003220
  validation loss:		0.653031
  validation accuracy:		91.63 %
Epoch 1749 of 2000 took 0.057s
  training loss:		0.003124
  validation loss:		0.654652
  validation accuracy:		91.52 %
Epoch 1750 of 2000 took 0.057s
  training loss:		0.003283
  validation loss:		0.650601
  validation accuracy:		91.41 %
Epoch 1751 of 2000 took 0.057s
  training loss:		0.003323
  validation loss:		0.648834
  validation accuracy:		91.74 %
Epoch 1752 of 2000 took 0.057s
  training loss:		0.003329
  validation loss:		0.648688
  validation accuracy:		91.52 %
Epoch 1753 of 2000 took 0.057s
  training loss:		0.003273
  validation loss:		0.649831
  validation accuracy:		91.63 %
Epoch 1754 of 2000 took 0.057s
  training loss:		0.003186
  validation loss:		0.647090
  validation accuracy:		91.63 %
Epoch 1755 of 2000 took 0.057s
  training loss:		0.003186
  validation loss:		0.656916
  validation accuracy:		91.41 %
Epoch 1756 of 2000 took 0.057s
  training loss:		0.003163
  validation loss:		0.646483
  validation accuracy:		91.74 %
Epoch 1757 of 2000 took 0.058s
  training loss:		0.003216
  validation loss:		0.657529
  validation accuracy:		91.09 %
Epoch 1758 of 2000 took 0.057s
  training loss:		0.003194
  validation loss:		0.652906
  validation accuracy:		91.63 %
Epoch 1759 of 2000 took 0.057s
  training loss:		0.003137
  validation loss:		0.654037
  validation accuracy:		91.63 %
Epoch 1760 of 2000 took 0.057s
  training loss:		0.003217
  validation loss:		0.658881
  validation accuracy:		91.30 %
Epoch 1761 of 2000 took 0.057s
  training loss:		0.003180
  validation loss:		0.660307
  validation accuracy:		91.41 %
Epoch 1762 of 2000 took 0.058s
  training loss:		0.003194
  validation loss:		0.659792
  validation accuracy:		91.52 %
Epoch 1763 of 2000 took 0.058s
  training loss:		0.003209
  validation loss:		0.652396
  validation accuracy:		91.63 %
Epoch 1764 of 2000 took 0.058s
  training loss:		0.003148
  validation loss:		0.653055
  validation accuracy:		91.63 %
Epoch 1765 of 2000 took 0.058s
  training loss:		0.003201
  validation loss:		0.650610
  validation accuracy:		91.63 %
Epoch 1766 of 2000 took 0.057s
  training loss:		0.003167
  validation loss:		0.651880
  validation accuracy:		91.74 %
Epoch 1767 of 2000 took 0.057s
  training loss:		0.003160
  validation loss:		0.655475
  validation accuracy:		91.52 %
Epoch 1768 of 2000 took 0.057s
  training loss:		0.003121
  validation loss:		0.651391
  validation accuracy:		91.63 %
Epoch 1769 of 2000 took 0.057s
  training loss:		0.003230
  validation loss:		0.655456
  validation accuracy:		91.74 %
Epoch 1770 of 2000 took 0.057s
  training loss:		0.003233
  validation loss:		0.656248
  validation accuracy:		91.63 %
Epoch 1771 of 2000 took 0.057s
  training loss:		0.003171
  validation loss:		0.655347
  validation accuracy:		91.52 %
Epoch 1772 of 2000 took 0.057s
  training loss:		0.003160
  validation loss:		0.651822
  validation accuracy:		91.63 %
Epoch 1773 of 2000 took 0.057s
  training loss:		0.003125
  validation loss:		0.655363
  validation accuracy:		91.63 %
Epoch 1774 of 2000 took 0.057s
  training loss:		0.003045
  validation loss:		0.654887
  validation accuracy:		91.41 %
Epoch 1775 of 2000 took 0.057s
  training loss:		0.003059
  validation loss:		0.650607
  validation accuracy:		91.63 %
Epoch 1776 of 2000 took 0.057s
  training loss:		0.003118
  validation loss:		0.658197
  validation accuracy:		91.41 %
Epoch 1777 of 2000 took 0.057s
  training loss:		0.003067
  validation loss:		0.654397
  validation accuracy:		91.63 %
Epoch 1778 of 2000 took 0.057s
  training loss:		0.003157
  validation loss:		0.660518
  validation accuracy:		91.63 %
Epoch 1779 of 2000 took 0.057s
  training loss:		0.003191
  validation loss:		0.654011
  validation accuracy:		91.52 %
Epoch 1780 of 2000 took 0.057s
  training loss:		0.003164
  validation loss:		0.656904
  validation accuracy:		91.52 %
Epoch 1781 of 2000 took 0.057s
  training loss:		0.003108
  validation loss:		0.654367
  validation accuracy:		91.63 %
Epoch 1782 of 2000 took 0.058s
  training loss:		0.003144
  validation loss:		0.659275
  validation accuracy:		91.52 %
Epoch 1783 of 2000 took 0.057s
  training loss:		0.003068
  validation loss:		0.661909
  validation accuracy:		91.41 %
Epoch 1784 of 2000 took 0.057s
  training loss:		0.003110
  validation loss:		0.652224
  validation accuracy:		91.52 %
Epoch 1785 of 2000 took 0.057s
  training loss:		0.003088
  validation loss:		0.655298
  validation accuracy:		91.63 %
Epoch 1786 of 2000 took 0.057s
  training loss:		0.003033
  validation loss:		0.658973
  validation accuracy:		91.41 %
Epoch 1787 of 2000 took 0.057s
  training loss:		0.003080
  validation loss:		0.648695
  validation accuracy:		91.85 %
Epoch 1788 of 2000 took 0.057s
  training loss:		0.003103
  validation loss:		0.663821
  validation accuracy:		91.52 %
Epoch 1789 of 2000 took 0.057s
  training loss:		0.003054
  validation loss:		0.656778
  validation accuracy:		91.52 %
Epoch 1790 of 2000 took 0.057s
  training loss:		0.003102
  validation loss:		0.654072
  validation accuracy:		91.63 %
Epoch 1791 of 2000 took 0.057s
  training loss:		0.003062
  validation loss:		0.665011
  validation accuracy:		91.30 %
Epoch 1792 of 2000 took 0.057s
  training loss:		0.003162
  validation loss:		0.653846
  validation accuracy:		91.41 %
Epoch 1793 of 2000 took 0.057s
  training loss:		0.003131
  validation loss:		0.654817
  validation accuracy:		91.63 %
Epoch 1794 of 2000 took 0.057s
  training loss:		0.003070
  validation loss:		0.660897
  validation accuracy:		91.74 %
Epoch 1795 of 2000 took 0.057s
  training loss:		0.003053
  validation loss:		0.653821
  validation accuracy:		91.74 %
Epoch 1796 of 2000 took 0.057s
  training loss:		0.003115
  validation loss:		0.653933
  validation accuracy:		91.74 %
Epoch 1797 of 2000 took 0.058s
  training loss:		0.003122
  validation loss:		0.659587
  validation accuracy:		91.30 %
Epoch 1798 of 2000 took 0.058s
  training loss:		0.003191
  validation loss:		0.655550
  validation accuracy:		91.63 %
Epoch 1799 of 2000 took 0.058s
  training loss:		0.003094
  validation loss:		0.664485
  validation accuracy:		91.52 %
Epoch 1800 of 2000 took 0.058s
  training loss:		0.003088
  validation loss:		0.664068
  validation accuracy:		91.41 %
Epoch 1801 of 2000 took 0.058s
  training loss:		0.003049
  validation loss:		0.665118
  validation accuracy:		91.30 %
Epoch 1802 of 2000 took 0.058s
  training loss:		0.003074
  validation loss:		0.657055
  validation accuracy:		91.63 %
Epoch 1803 of 2000 took 0.058s
  training loss:		0.003028
  validation loss:		0.657703
  validation accuracy:		91.63 %
Epoch 1804 of 2000 took 0.058s
  training loss:		0.003024
  validation loss:		0.664915
  validation accuracy:		91.20 %
Epoch 1805 of 2000 took 0.058s
  training loss:		0.003045
  validation loss:		0.657176
  validation accuracy:		91.41 %
Epoch 1806 of 2000 took 0.058s
  training loss:		0.003062
  validation loss:		0.651668
  validation accuracy:		91.63 %
Epoch 1807 of 2000 took 0.058s
  training loss:		0.003095
  validation loss:		0.666115
  validation accuracy:		91.30 %
Epoch 1808 of 2000 took 0.058s
  training loss:		0.003084
  validation loss:		0.652718
  validation accuracy:		91.63 %
Epoch 1809 of 2000 took 0.058s
  training loss:		0.003033
  validation loss:		0.667583
  validation accuracy:		91.20 %
Epoch 1810 of 2000 took 0.058s
  training loss:		0.002916
  validation loss:		0.658038
  validation accuracy:		91.63 %
Epoch 1811 of 2000 took 0.057s
  training loss:		0.003070
  validation loss:		0.656889
  validation accuracy:		91.63 %
Epoch 1812 of 2000 took 0.057s
  training loss:		0.003114
  validation loss:		0.663205
  validation accuracy:		91.74 %
Epoch 1813 of 2000 took 0.057s
  training loss:		0.003073
  validation loss:		0.668437
  validation accuracy:		91.52 %
Epoch 1814 of 2000 took 0.057s
  training loss:		0.003037
  validation loss:		0.654699
  validation accuracy:		91.52 %
Epoch 1815 of 2000 took 0.058s
  training loss:		0.003038
  validation loss:		0.667478
  validation accuracy:		91.41 %
Epoch 1816 of 2000 took 0.058s
  training loss:		0.003062
  validation loss:		0.660499
  validation accuracy:		91.52 %
Epoch 1817 of 2000 took 0.058s
  training loss:		0.002964
  validation loss:		0.663146
  validation accuracy:		91.30 %
Epoch 1818 of 2000 took 0.058s
  training loss:		0.002993
  validation loss:		0.660554
  validation accuracy:		91.63 %
Epoch 1819 of 2000 took 0.058s
  training loss:		0.002931
  validation loss:		0.663581
  validation accuracy:		91.41 %
Epoch 1820 of 2000 took 0.057s
  training loss:		0.003016
  validation loss:		0.667871
  validation accuracy:		91.41 %
Epoch 1821 of 2000 took 0.057s
  training loss:		0.002944
  validation loss:		0.657929
  validation accuracy:		91.41 %
Epoch 1822 of 2000 took 0.057s
  training loss:		0.002978
  validation loss:		0.662898
  validation accuracy:		91.63 %
Epoch 1823 of 2000 took 0.057s
  training loss:		0.002989
  validation loss:		0.665123
  validation accuracy:		91.52 %
Epoch 1824 of 2000 took 0.057s
  training loss:		0.002934
  validation loss:		0.661157
  validation accuracy:		91.52 %
Epoch 1825 of 2000 took 0.057s
  training loss:		0.003029
  validation loss:		0.659452
  validation accuracy:		91.52 %
Epoch 1826 of 2000 took 0.057s
  training loss:		0.002947
  validation loss:		0.662693
  validation accuracy:		91.63 %
Epoch 1827 of 2000 took 0.057s
  training loss:		0.003004
  validation loss:		0.667565
  validation accuracy:		91.30 %
Epoch 1828 of 2000 took 0.057s
  training loss:		0.002848
  validation loss:		0.662538
  validation accuracy:		91.63 %
Epoch 1829 of 2000 took 0.057s
  training loss:		0.002933
  validation loss:		0.670452
  validation accuracy:		90.98 %
Epoch 1830 of 2000 took 0.057s
  training loss:		0.002920
  validation loss:		0.660866
  validation accuracy:		91.63 %
Epoch 1831 of 2000 took 0.057s
  training loss:		0.002930
  validation loss:		0.664256
  validation accuracy:		91.63 %
Epoch 1832 of 2000 took 0.057s
  training loss:		0.002863
  validation loss:		0.667913
  validation accuracy:		91.41 %
Epoch 1833 of 2000 took 0.057s
  training loss:		0.002987
  validation loss:		0.662514
  validation accuracy:		91.52 %
Epoch 1834 of 2000 took 0.057s
  training loss:		0.002942
  validation loss:		0.666182
  validation accuracy:		91.63 %
Epoch 1835 of 2000 took 0.058s
  training loss:		0.002888
  validation loss:		0.664585
  validation accuracy:		91.63 %
Epoch 1836 of 2000 took 0.057s
  training loss:		0.002933
  validation loss:		0.667320
  validation accuracy:		90.98 %
Epoch 1837 of 2000 took 0.057s
  training loss:		0.002869
  validation loss:		0.662842
  validation accuracy:		91.74 %
Epoch 1838 of 2000 took 0.058s
  training loss:		0.002959
  validation loss:		0.670921
  validation accuracy:		91.52 %
Epoch 1839 of 2000 took 0.058s
  training loss:		0.003008
  validation loss:		0.664840
  validation accuracy:		91.63 %
Epoch 1840 of 2000 took 0.057s
  training loss:		0.002962
  validation loss:		0.664162
  validation accuracy:		91.41 %
Epoch 1841 of 2000 took 0.057s
  training loss:		0.002908
  validation loss:		0.667703
  validation accuracy:		91.52 %
Epoch 1842 of 2000 took 0.057s
  training loss:		0.002853
  validation loss:		0.667122
  validation accuracy:		91.41 %
Epoch 1843 of 2000 took 0.057s
  training loss:		0.002897
  validation loss:		0.670410
  validation accuracy:		91.41 %
Epoch 1844 of 2000 took 0.057s
  training loss:		0.002867
  validation loss:		0.667169
  validation accuracy:		91.41 %
Epoch 1845 of 2000 took 0.057s
  training loss:		0.002878
  validation loss:		0.667114
  validation accuracy:		91.41 %
Epoch 1846 of 2000 took 0.057s
  training loss:		0.002934
  validation loss:		0.664680
  validation accuracy:		91.63 %
Epoch 1847 of 2000 took 0.057s
  training loss:		0.002956
  validation loss:		0.669614
  validation accuracy:		91.63 %
Epoch 1848 of 2000 took 0.057s
  training loss:		0.002875
  validation loss:		0.664472
  validation accuracy:		91.63 %
Epoch 1849 of 2000 took 0.057s
  training loss:		0.002896
  validation loss:		0.665935
  validation accuracy:		91.63 %
Epoch 1850 of 2000 took 0.057s
  training loss:		0.002929
  validation loss:		0.672443
  validation accuracy:		91.30 %
Epoch 1851 of 2000 took 0.057s
  training loss:		0.002877
  validation loss:		0.667464
  validation accuracy:		91.63 %
Epoch 1852 of 2000 took 0.057s
  training loss:		0.002898
  validation loss:		0.664983
  validation accuracy:		91.41 %
Epoch 1853 of 2000 took 0.058s
  training loss:		0.002862
  validation loss:		0.673107
  validation accuracy:		91.20 %
Epoch 1854 of 2000 took 0.057s
  training loss:		0.002933
  validation loss:		0.671065
  validation accuracy:		91.30 %
Epoch 1855 of 2000 took 0.057s
  training loss:		0.002854
  validation loss:		0.675034
  validation accuracy:		91.41 %
Epoch 1856 of 2000 took 0.057s
  training loss:		0.002775
  validation loss:		0.660611
  validation accuracy:		91.63 %
Epoch 1857 of 2000 took 0.057s
  training loss:		0.002961
  validation loss:		0.666977
  validation accuracy:		91.52 %
Epoch 1858 of 2000 took 0.057s
  training loss:		0.002858
  validation loss:		0.666996
  validation accuracy:		91.52 %
Epoch 1859 of 2000 took 0.057s
  training loss:		0.002821
  validation loss:		0.670110
  validation accuracy:		91.41 %
Epoch 1860 of 2000 took 0.057s
  training loss:		0.002881
  validation loss:		0.665015
  validation accuracy:		91.63 %
Epoch 1861 of 2000 took 0.057s
  training loss:		0.002764
  validation loss:		0.669927
  validation accuracy:		91.41 %
Epoch 1862 of 2000 took 0.057s
  training loss:		0.002804
  validation loss:		0.665532
  validation accuracy:		91.52 %
Epoch 1863 of 2000 took 0.057s
  training loss:		0.002732
  validation loss:		0.669271
  validation accuracy:		91.63 %
Epoch 1864 of 2000 took 0.057s
  training loss:		0.002746
  validation loss:		0.669182
  validation accuracy:		91.52 %
Epoch 1865 of 2000 took 0.057s
  training loss:		0.002749
  validation loss:		0.665714
  validation accuracy:		91.41 %
Epoch 1866 of 2000 took 0.057s
  training loss:		0.002804
  validation loss:		0.668623
  validation accuracy:		91.63 %
Epoch 1867 of 2000 took 0.057s
  training loss:		0.002830
  validation loss:		0.669813
  validation accuracy:		91.52 %
Epoch 1868 of 2000 took 0.059s
  training loss:		0.002851
  validation loss:		0.671627
  validation accuracy:		91.52 %
Epoch 1869 of 2000 took 0.057s
  training loss:		0.002831
  validation loss:		0.664567
  validation accuracy:		91.63 %
Epoch 1870 of 2000 took 0.057s
  training loss:		0.002874
  validation loss:		0.669922
  validation accuracy:		91.52 %
Epoch 1871 of 2000 took 0.057s
  training loss:		0.002854
  validation loss:		0.669559
  validation accuracy:		91.52 %
Epoch 1872 of 2000 took 0.057s
  training loss:		0.002803
  validation loss:		0.673201
  validation accuracy:		91.41 %
Epoch 1873 of 2000 took 0.057s
  training loss:		0.002856
  validation loss:		0.665655
  validation accuracy:		91.63 %
Epoch 1874 of 2000 took 0.056s
  training loss:		0.002824
  validation loss:		0.669284
  validation accuracy:		91.74 %
Epoch 1875 of 2000 took 0.057s
  training loss:		0.002816
  validation loss:		0.670176
  validation accuracy:		91.52 %
Epoch 1876 of 2000 took 0.055s
  training loss:		0.002846
  validation loss:		0.675430
  validation accuracy:		91.41 %
Epoch 1877 of 2000 took 0.056s
  training loss:		0.002802
  validation loss:		0.673914
  validation accuracy:		91.52 %
Epoch 1878 of 2000 took 0.056s
  training loss:		0.002827
  validation loss:		0.670023
  validation accuracy:		91.63 %
Epoch 1879 of 2000 took 0.057s
  training loss:		0.002774
  validation loss:		0.675672
  validation accuracy:		91.30 %
Epoch 1880 of 2000 took 0.056s
  training loss:		0.002739
  validation loss:		0.672963
  validation accuracy:		91.63 %
Epoch 1881 of 2000 took 0.056s
  training loss:		0.002811
  validation loss:		0.670137
  validation accuracy:		91.63 %
Epoch 1882 of 2000 took 0.059s
  training loss:		0.002799
  validation loss:		0.676393
  validation accuracy:		91.30 %
Epoch 1883 of 2000 took 0.055s
  training loss:		0.002823
  validation loss:		0.670763
  validation accuracy:		91.52 %
Epoch 1884 of 2000 took 0.056s
  training loss:		0.002793
  validation loss:		0.678672
  validation accuracy:		91.30 %
Epoch 1885 of 2000 took 0.056s
  training loss:		0.002764
  validation loss:		0.666058
  validation accuracy:		91.52 %
Epoch 1886 of 2000 took 0.058s
  training loss:		0.002858
  validation loss:		0.668942
  validation accuracy:		91.63 %
Epoch 1887 of 2000 took 0.059s
  training loss:		0.002771
  validation loss:		0.672161
  validation accuracy:		91.20 %
Epoch 1888 of 2000 took 0.057s
  training loss:		0.002854
  validation loss:		0.669176
  validation accuracy:		91.74 %
Epoch 1889 of 2000 took 0.057s
  training loss:		0.002710
  validation loss:		0.678618
  validation accuracy:		91.30 %
Epoch 1890 of 2000 took 0.058s
  training loss:		0.002816
  validation loss:		0.677053
  validation accuracy:		91.63 %
Epoch 1891 of 2000 took 0.057s
  training loss:		0.002735
  validation loss:		0.672162
  validation accuracy:		91.30 %
Epoch 1892 of 2000 took 0.056s
  training loss:		0.002702
  validation loss:		0.674301
  validation accuracy:		91.52 %
Epoch 1893 of 2000 took 0.056s
  training loss:		0.002721
  validation loss:		0.673547
  validation accuracy:		91.63 %
Epoch 1894 of 2000 took 0.056s
  training loss:		0.002730
  validation loss:		0.672062
  validation accuracy:		91.52 %
Epoch 1895 of 2000 took 0.058s
  training loss:		0.002763
  validation loss:		0.673300
  validation accuracy:		91.63 %
Epoch 1896 of 2000 took 0.058s
  training loss:		0.002589
  validation loss:		0.676769
  validation accuracy:		91.41 %
Epoch 1897 of 2000 took 0.057s
  training loss:		0.002743
  validation loss:		0.681518
  validation accuracy:		91.20 %
Epoch 1898 of 2000 took 0.057s
  training loss:		0.002710
  validation loss:		0.664927
  validation accuracy:		91.63 %
Epoch 1899 of 2000 took 0.057s
  training loss:		0.002876
  validation loss:		0.667349
  validation accuracy:		91.63 %
Epoch 1900 of 2000 took 0.058s
  training loss:		0.002778
  validation loss:		0.680232
  validation accuracy:		91.30 %
Epoch 1901 of 2000 took 0.058s
  training loss:		0.002736
  validation loss:		0.674105
  validation accuracy:		91.52 %
Epoch 1902 of 2000 took 0.058s
  training loss:		0.002692
  validation loss:		0.675629
  validation accuracy:		91.52 %
Epoch 1903 of 2000 took 0.059s
  training loss:		0.002755
  validation loss:		0.675351
  validation accuracy:		91.74 %
Epoch 1904 of 2000 took 0.058s
  training loss:		0.002623
  validation loss:		0.678963
  validation accuracy:		91.30 %
Epoch 1905 of 2000 took 0.059s
  training loss:		0.002675
  validation loss:		0.676732
  validation accuracy:		91.41 %
Epoch 1906 of 2000 took 0.058s
  training loss:		0.002746
  validation loss:		0.668395
  validation accuracy:		91.63 %
Epoch 1907 of 2000 took 0.058s
  training loss:		0.002774
  validation loss:		0.671362
  validation accuracy:		91.41 %
Epoch 1908 of 2000 took 0.059s
  training loss:		0.002734
  validation loss:		0.679308
  validation accuracy:		91.41 %
Epoch 1909 of 2000 took 0.058s
  training loss:		0.002726
  validation loss:		0.673314
  validation accuracy:		91.52 %
Epoch 1910 of 2000 took 0.056s
  training loss:		0.002751
  validation loss:		0.675697
  validation accuracy:		91.52 %
Epoch 1911 of 2000 took 0.056s
  training loss:		0.002733
  validation loss:		0.678061
  validation accuracy:		91.41 %
Epoch 1912 of 2000 took 0.058s
  training loss:		0.002708
  validation loss:		0.676036
  validation accuracy:		91.52 %
Epoch 1913 of 2000 took 0.057s
  training loss:		0.002656
  validation loss:		0.684125
  validation accuracy:		91.20 %
Epoch 1914 of 2000 took 0.057s
  training loss:		0.002701
  validation loss:		0.668958
  validation accuracy:		91.63 %
Epoch 1915 of 2000 took 0.056s
  training loss:		0.002773
  validation loss:		0.683420
  validation accuracy:		91.20 %
Epoch 1916 of 2000 took 0.057s
  training loss:		0.002693
  validation loss:		0.676618
  validation accuracy:		91.41 %
Epoch 1917 of 2000 took 0.058s
  training loss:		0.002671
  validation loss:		0.672463
  validation accuracy:		91.20 %
Epoch 1918 of 2000 took 0.057s
  training loss:		0.002623
  validation loss:		0.675603
  validation accuracy:		91.41 %
Epoch 1919 of 2000 took 0.058s
  training loss:		0.002640
  validation loss:		0.684214
  validation accuracy:		91.20 %
Epoch 1920 of 2000 took 0.058s
  training loss:		0.002671
  validation loss:		0.677602
  validation accuracy:		91.63 %
Epoch 1921 of 2000 took 0.056s
  training loss:		0.002706
  validation loss:		0.674101
  validation accuracy:		91.63 %
Epoch 1922 of 2000 took 0.059s
  training loss:		0.002645
  validation loss:		0.683685
  validation accuracy:		90.98 %
Epoch 1923 of 2000 took 0.059s
  training loss:		0.002665
  validation loss:		0.683487
  validation accuracy:		91.52 %
Epoch 1924 of 2000 took 0.056s
  training loss:		0.002692
  validation loss:		0.680586
  validation accuracy:		91.41 %
Epoch 1925 of 2000 took 0.056s
  training loss:		0.002678
  validation loss:		0.677183
  validation accuracy:		91.52 %
Epoch 1926 of 2000 took 0.056s
  training loss:		0.002642
  validation loss:		0.678078
  validation accuracy:		91.41 %
Epoch 1927 of 2000 took 0.060s
  training loss:		0.002650
  validation loss:		0.680690
  validation accuracy:		91.30 %
Epoch 1928 of 2000 took 0.058s
  training loss:		0.002607
  validation loss:		0.676831
  validation accuracy:		91.52 %
Epoch 1929 of 2000 took 0.058s
  training loss:		0.002636
  validation loss:		0.678337
  validation accuracy:		91.52 %
Epoch 1930 of 2000 took 0.057s
  training loss:		0.002669
  validation loss:		0.679184
  validation accuracy:		91.52 %
Epoch 1931 of 2000 took 0.058s
  training loss:		0.002723
  validation loss:		0.680735
  validation accuracy:		91.09 %
Epoch 1932 of 2000 took 0.058s
  training loss:		0.002806
  validation loss:		0.680460
  validation accuracy:		91.30 %
Epoch 1933 of 2000 took 0.058s
  training loss:		0.002678
  validation loss:		0.682225
  validation accuracy:		91.30 %
Epoch 1934 of 2000 took 0.058s
  training loss:		0.002641
  validation loss:		0.677575
  validation accuracy:		91.52 %
Epoch 1935 of 2000 took 0.058s
  training loss:		0.002639
  validation loss:		0.677976
  validation accuracy:		91.52 %
Epoch 1936 of 2000 took 0.057s
  training loss:		0.002628
  validation loss:		0.675837
  validation accuracy:		91.52 %
Epoch 1937 of 2000 took 0.056s
  training loss:		0.002565
  validation loss:		0.680105
  validation accuracy:		91.52 %
Epoch 1938 of 2000 took 0.058s
  training loss:		0.002640
  validation loss:		0.682701
  validation accuracy:		91.20 %
Epoch 1939 of 2000 took 0.058s
  training loss:		0.002658
  validation loss:		0.681534
  validation accuracy:		91.52 %
Epoch 1940 of 2000 took 0.058s
  training loss:		0.002708
  validation loss:		0.688919
  validation accuracy:		91.30 %
Epoch 1941 of 2000 took 0.057s
  training loss:		0.002697
  validation loss:		0.681714
  validation accuracy:		91.63 %
Epoch 1942 of 2000 took 0.057s
  training loss:		0.002647
  validation loss:		0.680799
  validation accuracy:		91.52 %
Epoch 1943 of 2000 took 0.057s
  training loss:		0.002643
  validation loss:		0.681746
  validation accuracy:		91.41 %
Epoch 1944 of 2000 took 0.057s
  training loss:		0.002637
  validation loss:		0.686265
  validation accuracy:		91.09 %
Epoch 1945 of 2000 took 0.057s
  training loss:		0.002618
  validation loss:		0.679808
  validation accuracy:		91.63 %
Epoch 1946 of 2000 took 0.057s
  training loss:		0.002617
  validation loss:		0.684348
  validation accuracy:		91.09 %
Epoch 1947 of 2000 took 0.057s
  training loss:		0.002553
  validation loss:		0.677999
  validation accuracy:		91.52 %
Epoch 1948 of 2000 took 0.057s
  training loss:		0.002599
  validation loss:		0.683216
  validation accuracy:		91.30 %
Epoch 1949 of 2000 took 0.057s
  training loss:		0.002638
  validation loss:		0.677190
  validation accuracy:		91.30 %
Epoch 1950 of 2000 took 0.057s
  training loss:		0.002577
  validation loss:		0.683350
  validation accuracy:		91.41 %
Epoch 1951 of 2000 took 0.057s
  training loss:		0.002615
  validation loss:		0.684739
  validation accuracy:		91.52 %
Epoch 1952 of 2000 took 0.057s
  training loss:		0.002623
  validation loss:		0.684191
  validation accuracy:		91.41 %
Epoch 1953 of 2000 took 0.057s
  training loss:		0.002551
  validation loss:		0.676976
  validation accuracy:		91.52 %
Epoch 1954 of 2000 took 0.057s
  training loss:		0.002635
  validation loss:		0.684021
  validation accuracy:		91.30 %
Epoch 1955 of 2000 took 0.057s
  training loss:		0.002511
  validation loss:		0.682581
  validation accuracy:		91.30 %
Epoch 1956 of 2000 took 0.057s
  training loss:		0.002537
  validation loss:		0.684381
  validation accuracy:		91.41 %
Epoch 1957 of 2000 took 0.057s
  training loss:		0.002580
  validation loss:		0.681666
  validation accuracy:		91.30 %
Epoch 1958 of 2000 took 0.057s
  training loss:		0.002647
  validation loss:		0.688092
  validation accuracy:		91.30 %
Epoch 1959 of 2000 took 0.057s
  training loss:		0.002577
  validation loss:		0.685588
  validation accuracy:		91.30 %
Epoch 1960 of 2000 took 0.057s
  training loss:		0.002542
  validation loss:		0.678843
  validation accuracy:		91.52 %
Epoch 1961 of 2000 took 0.057s
  training loss:		0.002634
  validation loss:		0.686235
  validation accuracy:		91.30 %
Epoch 1962 of 2000 took 0.057s
  training loss:		0.002509
  validation loss:		0.684497
  validation accuracy:		91.41 %
Epoch 1963 of 2000 took 0.057s
  training loss:		0.002587
  validation loss:		0.688290
  validation accuracy:		91.20 %
Epoch 1964 of 2000 took 0.057s
  training loss:		0.002568
  validation loss:		0.682846
  validation accuracy:		91.52 %
Epoch 1965 of 2000 took 0.057s
  training loss:		0.002475
  validation loss:		0.687609
  validation accuracy:		91.30 %
Epoch 1966 of 2000 took 0.058s
  training loss:		0.002512
  validation loss:		0.686735
  validation accuracy:		91.30 %
Epoch 1967 of 2000 took 0.058s
  training loss:		0.002525
  validation loss:		0.677997
  validation accuracy:		91.52 %
Epoch 1968 of 2000 took 0.057s
  training loss:		0.002613
  validation loss:		0.681708
  validation accuracy:		91.63 %
Epoch 1969 of 2000 took 0.057s
  training loss:		0.002503
  validation loss:		0.683090
  validation accuracy:		91.41 %
Epoch 1970 of 2000 took 0.057s
  training loss:		0.002505
  validation loss:		0.690866
  validation accuracy:		91.30 %
Epoch 1971 of 2000 took 0.058s
  training loss:		0.002510
  validation loss:		0.679462
  validation accuracy:		91.63 %
Epoch 1972 of 2000 took 0.058s
  training loss:		0.002568
  validation loss:		0.683834
  validation accuracy:		91.52 %
Epoch 1973 of 2000 took 0.057s
  training loss:		0.002522
  validation loss:		0.687972
  validation accuracy:		91.30 %
Epoch 1974 of 2000 took 0.057s
  training loss:		0.002563
  validation loss:		0.683504
  validation accuracy:		91.63 %
Epoch 1975 of 2000 took 0.058s
  training loss:		0.002557
  validation loss:		0.692307
  validation accuracy:		91.20 %
Epoch 1976 of 2000 took 0.055s
  training loss:		0.002560
  validation loss:		0.684129
  validation accuracy:		91.41 %
Epoch 1977 of 2000 took 0.057s
  training loss:		0.002608
  validation loss:		0.681761
  validation accuracy:		91.41 %
Epoch 1978 of 2000 took 0.057s
  training loss:		0.002567
  validation loss:		0.689089
  validation accuracy:		91.30 %
Epoch 1979 of 2000 took 0.057s
  training loss:		0.002460
  validation loss:		0.692983
  validation accuracy:		91.30 %
Epoch 1980 of 2000 took 0.061s
  training loss:		0.002520
  validation loss:		0.678476
  validation accuracy:		91.41 %
Epoch 1981 of 2000 took 0.058s
  training loss:		0.002579
  validation loss:		0.688594
  validation accuracy:		91.52 %
Epoch 1982 of 2000 took 0.055s
  training loss:		0.002499
  validation loss:		0.689210
  validation accuracy:		91.30 %
Epoch 1983 of 2000 took 0.056s
  training loss:		0.002562
  validation loss:		0.683801
  validation accuracy:		91.52 %
Epoch 1984 of 2000 took 0.058s
  training loss:		0.002527
  validation loss:		0.688225
  validation accuracy:		91.30 %
Epoch 1985 of 2000 took 0.058s
  training loss:		0.002560
  validation loss:		0.685671
  validation accuracy:		91.63 %
Epoch 1986 of 2000 took 0.056s
  training loss:		0.002469
  validation loss:		0.690409
  validation accuracy:		91.20 %
Epoch 1987 of 2000 took 0.058s
  training loss:		0.002426
  validation loss:		0.683540
  validation accuracy:		91.52 %
Epoch 1988 of 2000 took 0.056s
  training loss:		0.002506
  validation loss:		0.689576
  validation accuracy:		91.30 %
Epoch 1989 of 2000 took 0.058s
  training loss:		0.002433
  validation loss:		0.691830
  validation accuracy:		91.20 %
Epoch 1990 of 2000 took 0.058s
  training loss:		0.002502
  validation loss:		0.683013
  validation accuracy:		91.41 %
Epoch 1991 of 2000 took 0.059s
  training loss:		0.002555
  validation loss:		0.685261
  validation accuracy:		91.52 %
Epoch 1992 of 2000 took 0.058s
  training loss:		0.002505
  validation loss:		0.691860
  validation accuracy:		91.30 %
Epoch 1993 of 2000 took 0.057s
  training loss:		0.002526
  validation loss:		0.692466
  validation accuracy:		91.20 %
Epoch 1994 of 2000 took 0.059s
  training loss:		0.002494
  validation loss:		0.689350
  validation accuracy:		91.41 %
Epoch 1995 of 2000 took 0.057s
  training loss:		0.002445
  validation loss:		0.691278
  validation accuracy:		91.30 %
Epoch 1996 of 2000 took 0.059s
  training loss:		0.002498
  validation loss:		0.685208
  validation accuracy:		90.98 %
Epoch 1997 of 2000 took 0.058s
  training loss:		0.002493
  validation loss:		0.689399
  validation accuracy:		91.41 %
Epoch 1998 of 2000 took 0.058s
  training loss:		0.002472
  validation loss:		0.687331
  validation accuracy:		91.41 %
Epoch 1999 of 2000 took 0.057s
  training loss:		0.002472
  validation loss:		0.689434
  validation accuracy:		91.41 %
Epoch 2000 of 2000 took 0.058s
  training loss:		0.002553
  validation loss:		0.684571
  validation accuracy:		91.30 %
Final results:
  test loss:			1.429857
  test accuracy:		83.79 %
