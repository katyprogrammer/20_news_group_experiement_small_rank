Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.112s
  training loss:		2.951939
  validation loss:		2.831413
  validation accuracy:		5.54 %
Epoch 2 of 2000 took 0.097s
  training loss:		2.720451
  validation loss:		2.542013
  validation accuracy:		13.04 %
Epoch 3 of 2000 took 0.092s
  training loss:		2.484949
  validation loss:		2.301000
  validation accuracy:		14.46 %
Epoch 4 of 2000 took 0.091s
  training loss:		2.332183
  validation loss:		2.217800
  validation accuracy:		20.43 %
Epoch 5 of 2000 took 0.100s
  training loss:		2.272011
  validation loss:		2.206352
  validation accuracy:		38.04 %
Epoch 6 of 2000 took 0.090s
  training loss:		2.244198
  validation loss:		2.180354
  validation accuracy:		43.59 %
Epoch 7 of 2000 took 0.092s
  training loss:		2.225896
  validation loss:		2.154079
  validation accuracy:		52.50 %
Epoch 8 of 2000 took 0.100s
  training loss:		2.208141
  validation loss:		2.138344
  validation accuracy:		45.22 %
Epoch 9 of 2000 took 0.051s
  training loss:		2.188175
  validation loss:		2.122322
  validation accuracy:		61.74 %
Epoch 10 of 2000 took 0.047s
  training loss:		2.162707
  validation loss:		2.085406
  validation accuracy:		60.54 %
Epoch 11 of 2000 took 0.047s
  training loss:		2.135806
  validation loss:		2.059753
  validation accuracy:		51.09 %
Epoch 12 of 2000 took 0.047s
  training loss:		2.107514
  validation loss:		2.030594
  validation accuracy:		68.15 %
Epoch 13 of 2000 took 0.064s
  training loss:		2.069008
  validation loss:		1.977265
  validation accuracy:		67.61 %
Epoch 14 of 2000 took 0.089s
  training loss:		2.027258
  validation loss:		1.929429
  validation accuracy:		76.41 %
Epoch 15 of 2000 took 0.093s
  training loss:		1.975931
  validation loss:		1.874979
  validation accuracy:		75.43 %
Epoch 16 of 2000 took 0.098s
  training loss:		1.916051
  validation loss:		1.798953
  validation accuracy:		77.39 %
Epoch 17 of 2000 took 0.097s
  training loss:		1.844248
  validation loss:		1.728959
  validation accuracy:		78.80 %
Epoch 18 of 2000 took 0.055s
  training loss:		1.771713
  validation loss:		1.642506
  validation accuracy:		80.11 %
Epoch 19 of 2000 took 0.047s
  training loss:		1.683991
  validation loss:		1.550625
  validation accuracy:		82.28 %
Epoch 20 of 2000 took 0.047s
  training loss:		1.594016
  validation loss:		1.446430
  validation accuracy:		81.74 %
Epoch 21 of 2000 took 0.066s
  training loss:		1.503284
  validation loss:		1.356677
  validation accuracy:		83.48 %
Epoch 22 of 2000 took 0.063s
  training loss:		1.404627
  validation loss:		1.257664
  validation accuracy:		84.24 %
Epoch 23 of 2000 took 0.102s
  training loss:		1.314180
  validation loss:		1.165455
  validation accuracy:		85.54 %
Epoch 24 of 2000 took 0.047s
  training loss:		1.229563
  validation loss:		1.088068
  validation accuracy:		84.78 %
Epoch 25 of 2000 took 0.047s
  training loss:		1.146293
  validation loss:		1.002693
  validation accuracy:		86.96 %
Epoch 26 of 2000 took 0.046s
  training loss:		1.073896
  validation loss:		0.944858
  validation accuracy:		85.33 %
Epoch 27 of 2000 took 0.047s
  training loss:		0.999047
  validation loss:		0.876177
  validation accuracy:		87.61 %
Epoch 28 of 2000 took 0.047s
  training loss:		0.940743
  validation loss:		0.815409
  validation accuracy:		86.63 %
Epoch 29 of 2000 took 0.054s
  training loss:		0.879993
  validation loss:		0.762094
  validation accuracy:		87.72 %
Epoch 30 of 2000 took 0.076s
  training loss:		0.821866
  validation loss:		0.726265
  validation accuracy:		88.26 %
Epoch 31 of 2000 took 0.055s
  training loss:		0.775215
  validation loss:		0.673145
  validation accuracy:		87.83 %
Epoch 32 of 2000 took 0.093s
  training loss:		0.727733
  validation loss:		0.634941
  validation accuracy:		88.48 %
Epoch 33 of 2000 took 0.047s
  training loss:		0.689621
  validation loss:		0.600977
  validation accuracy:		89.35 %
Epoch 34 of 2000 took 0.047s
  training loss:		0.659788
  validation loss:		0.577410
  validation accuracy:		88.91 %
Epoch 35 of 2000 took 0.046s
  training loss:		0.624718
  validation loss:		0.545587
  validation accuracy:		88.59 %
Epoch 36 of 2000 took 0.047s
  training loss:		0.596380
  validation loss:		0.524148
  validation accuracy:		88.59 %
Epoch 37 of 2000 took 0.047s
  training loss:		0.567457
  validation loss:		0.491229
  validation accuracy:		89.35 %
Epoch 38 of 2000 took 0.076s
  training loss:		0.543282
  validation loss:		0.474220
  validation accuracy:		90.11 %
Epoch 39 of 2000 took 0.097s
  training loss:		0.524120
  validation loss:		0.465035
  validation accuracy:		90.00 %
Epoch 40 of 2000 took 0.063s
  training loss:		0.501533
  validation loss:		0.443605
  validation accuracy:		89.78 %
Epoch 41 of 2000 took 0.063s
  training loss:		0.490996
  validation loss:		0.432204
  validation accuracy:		90.00 %
Epoch 42 of 2000 took 0.064s
  training loss:		0.472377
  validation loss:		0.410944
  validation accuracy:		90.87 %
Epoch 43 of 2000 took 0.047s
  training loss:		0.456548
  validation loss:		0.401931
  validation accuracy:		90.98 %
Epoch 44 of 2000 took 0.047s
  training loss:		0.442427
  validation loss:		0.391696
  validation accuracy:		90.76 %
Epoch 45 of 2000 took 0.046s
  training loss:		0.436815
  validation loss:		0.382188
  validation accuracy:		90.98 %
Epoch 46 of 2000 took 0.046s
  training loss:		0.419920
  validation loss:		0.373883
  validation accuracy:		89.78 %
Epoch 47 of 2000 took 0.046s
  training loss:		0.412079
  validation loss:		0.365210
  validation accuracy:		91.20 %
Epoch 48 of 2000 took 0.046s
  training loss:		0.396939
  validation loss:		0.354770
  validation accuracy:		91.20 %
Epoch 49 of 2000 took 0.047s
  training loss:		0.391241
  validation loss:		0.355945
  validation accuracy:		91.20 %
Epoch 50 of 2000 took 0.046s
  training loss:		0.386363
  validation loss:		0.344894
  validation accuracy:		90.65 %
Epoch 51 of 2000 took 0.046s
  training loss:		0.372278
  validation loss:		0.336645
  validation accuracy:		91.52 %
Epoch 52 of 2000 took 0.047s
  training loss:		0.364416
  validation loss:		0.337063
  validation accuracy:		91.20 %
Epoch 53 of 2000 took 0.046s
  training loss:		0.360025
  validation loss:		0.325344
  validation accuracy:		91.52 %
Epoch 54 of 2000 took 0.047s
  training loss:		0.355738
  validation loss:		0.311421
  validation accuracy:		91.74 %
Epoch 55 of 2000 took 0.046s
  training loss:		0.348609
  validation loss:		0.310997
  validation accuracy:		91.74 %
Epoch 56 of 2000 took 0.047s
  training loss:		0.344578
  validation loss:		0.305032
  validation accuracy:		91.41 %
Epoch 57 of 2000 took 0.064s
  training loss:		0.338152
  validation loss:		0.314165
  validation accuracy:		91.09 %
Epoch 58 of 2000 took 0.057s
  training loss:		0.330050
  validation loss:		0.298099
  validation accuracy:		92.07 %
Epoch 59 of 2000 took 0.068s
  training loss:		0.330308
  validation loss:		0.299486
  validation accuracy:		91.85 %
Epoch 60 of 2000 took 0.047s
  training loss:		0.319888
  validation loss:		0.297270
  validation accuracy:		91.20 %
Epoch 61 of 2000 took 0.046s
  training loss:		0.317319
  validation loss:		0.291782
  validation accuracy:		91.85 %
Epoch 62 of 2000 took 0.047s
  training loss:		0.314038
  validation loss:		0.284494
  validation accuracy:		92.07 %
Epoch 63 of 2000 took 0.047s
  training loss:		0.307794
  validation loss:		0.284467
  validation accuracy:		92.07 %
Epoch 64 of 2000 took 0.073s
  training loss:		0.304036
  validation loss:		0.281788
  validation accuracy:		91.85 %
Epoch 65 of 2000 took 0.096s
  training loss:		0.303190
  validation loss:		0.283893
  validation accuracy:		91.85 %
Epoch 66 of 2000 took 0.090s
  training loss:		0.297889
  validation loss:		0.279142
  validation accuracy:		91.96 %
Epoch 67 of 2000 took 0.140s
  training loss:		0.294815
  validation loss:		0.278909
  validation accuracy:		91.74 %
Epoch 68 of 2000 took 0.100s
  training loss:		0.291578
  validation loss:		0.270237
  validation accuracy:		92.61 %
Epoch 69 of 2000 took 0.046s
  training loss:		0.281408
  validation loss:		0.267301
  validation accuracy:		91.85 %
Epoch 70 of 2000 took 0.042s
  training loss:		0.283916
  validation loss:		0.276499
  validation accuracy:		91.63 %
Epoch 71 of 2000 took 0.036s
  training loss:		0.282725
  validation loss:		0.263541
  validation accuracy:		92.17 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.275279
  validation loss:		0.257862
  validation accuracy:		92.39 %
Epoch 73 of 2000 took 0.036s
  training loss:		0.276265
  validation loss:		0.266128
  validation accuracy:		92.17 %
Epoch 74 of 2000 took 0.036s
  training loss:		0.276046
  validation loss:		0.255029
  validation accuracy:		92.39 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.268477
  validation loss:		0.271020
  validation accuracy:		92.17 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.266010
  validation loss:		0.246314
  validation accuracy:		92.61 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.262725
  validation loss:		0.265570
  validation accuracy:		91.85 %
Epoch 78 of 2000 took 0.036s
  training loss:		0.260400
  validation loss:		0.248710
  validation accuracy:		92.83 %
Epoch 79 of 2000 took 0.036s
  training loss:		0.265723
  validation loss:		0.254819
  validation accuracy:		92.72 %
Epoch 80 of 2000 took 0.036s
  training loss:		0.257981
  validation loss:		0.249276
  validation accuracy:		92.72 %
Epoch 81 of 2000 took 0.036s
  training loss:		0.257251
  validation loss:		0.246478
  validation accuracy:		92.61 %
Epoch 82 of 2000 took 0.037s
  training loss:		0.254243
  validation loss:		0.253945
  validation accuracy:		92.93 %
Epoch 83 of 2000 took 0.037s
  training loss:		0.248480
  validation loss:		0.243483
  validation accuracy:		93.15 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.250147
  validation loss:		0.249474
  validation accuracy:		92.50 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.239140
  validation loss:		0.252605
  validation accuracy:		92.07 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.245733
  validation loss:		0.241828
  validation accuracy:		92.72 %
Epoch 87 of 2000 took 0.036s
  training loss:		0.240545
  validation loss:		0.248303
  validation accuracy:		92.83 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.241543
  validation loss:		0.242144
  validation accuracy:		93.15 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.237532
  validation loss:		0.243837
  validation accuracy:		92.61 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.235782
  validation loss:		0.243978
  validation accuracy:		92.93 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.232490
  validation loss:		0.243087
  validation accuracy:		92.28 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.234042
  validation loss:		0.248295
  validation accuracy:		93.04 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.228469
  validation loss:		0.242842
  validation accuracy:		92.61 %
Epoch 94 of 2000 took 0.039s
  training loss:		0.230664
  validation loss:		0.224075
  validation accuracy:		93.15 %
Epoch 95 of 2000 took 0.040s
  training loss:		0.226279
  validation loss:		0.240837
  validation accuracy:		93.15 %
Epoch 96 of 2000 took 0.037s
  training loss:		0.225659
  validation loss:		0.239707
  validation accuracy:		92.39 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.227619
  validation loss:		0.232682
  validation accuracy:		93.26 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.223525
  validation loss:		0.227032
  validation accuracy:		92.83 %
Epoch 99 of 2000 took 0.039s
  training loss:		0.219048
  validation loss:		0.232579
  validation accuracy:		93.04 %
Epoch 100 of 2000 took 0.053s
  training loss:		0.220076
  validation loss:		0.232072
  validation accuracy:		92.83 %
Epoch 101 of 2000 took 0.058s
  training loss:		0.221145
  validation loss:		0.224477
  validation accuracy:		92.93 %
Epoch 102 of 2000 took 0.058s
  training loss:		0.212181
  validation loss:		0.229551
  validation accuracy:		92.61 %
Epoch 103 of 2000 took 0.059s
  training loss:		0.211270
  validation loss:		0.228454
  validation accuracy:		92.93 %
Epoch 104 of 2000 took 0.059s
  training loss:		0.210063
  validation loss:		0.226881
  validation accuracy:		93.04 %
Epoch 105 of 2000 took 0.059s
  training loss:		0.210242
  validation loss:		0.224851
  validation accuracy:		92.93 %
Epoch 106 of 2000 took 0.059s
  training loss:		0.208399
  validation loss:		0.243642
  validation accuracy:		92.07 %
Epoch 107 of 2000 took 0.059s
  training loss:		0.206496
  validation loss:		0.219784
  validation accuracy:		93.48 %
Epoch 108 of 2000 took 0.059s
  training loss:		0.206700
  validation loss:		0.229933
  validation accuracy:		92.72 %
Epoch 109 of 2000 took 0.059s
  training loss:		0.203541
  validation loss:		0.236255
  validation accuracy:		92.83 %
Epoch 110 of 2000 took 0.059s
  training loss:		0.201298
  validation loss:		0.220797
  validation accuracy:		93.26 %
Epoch 111 of 2000 took 0.059s
  training loss:		0.202304
  validation loss:		0.216654
  validation accuracy:		93.59 %
Epoch 112 of 2000 took 0.059s
  training loss:		0.200117
  validation loss:		0.225292
  validation accuracy:		93.04 %
Epoch 113 of 2000 took 0.059s
  training loss:		0.200326
  validation loss:		0.215835
  validation accuracy:		93.48 %
Epoch 114 of 2000 took 0.059s
  training loss:		0.195603
  validation loss:		0.232651
  validation accuracy:		92.39 %
Epoch 115 of 2000 took 0.059s
  training loss:		0.195045
  validation loss:		0.215714
  validation accuracy:		93.70 %
Epoch 116 of 2000 took 0.058s
  training loss:		0.201316
  validation loss:		0.215328
  validation accuracy:		93.48 %
Epoch 117 of 2000 took 0.059s
  training loss:		0.192018
  validation loss:		0.224089
  validation accuracy:		93.37 %
Epoch 118 of 2000 took 0.059s
  training loss:		0.194612
  validation loss:		0.225787
  validation accuracy:		93.26 %
Epoch 119 of 2000 took 0.059s
  training loss:		0.194456
  validation loss:		0.222054
  validation accuracy:		92.61 %
Epoch 120 of 2000 took 0.059s
  training loss:		0.191810
  validation loss:		0.221748
  validation accuracy:		93.48 %
Epoch 121 of 2000 took 0.059s
  training loss:		0.193035
  validation loss:		0.215116
  validation accuracy:		93.26 %
Epoch 122 of 2000 took 0.059s
  training loss:		0.186826
  validation loss:		0.217549
  validation accuracy:		93.59 %
Epoch 123 of 2000 took 0.059s
  training loss:		0.190124
  validation loss:		0.213696
  validation accuracy:		93.48 %
Epoch 124 of 2000 took 0.059s
  training loss:		0.185272
  validation loss:		0.218509
  validation accuracy:		93.04 %
Epoch 125 of 2000 took 0.059s
  training loss:		0.185506
  validation loss:		0.214020
  validation accuracy:		93.48 %
Epoch 126 of 2000 took 0.058s
  training loss:		0.185215
  validation loss:		0.217867
  validation accuracy:		92.93 %
Epoch 127 of 2000 took 0.059s
  training loss:		0.181563
  validation loss:		0.223468
  validation accuracy:		93.48 %
Epoch 128 of 2000 took 0.059s
  training loss:		0.181967
  validation loss:		0.213265
  validation accuracy:		93.70 %
Epoch 129 of 2000 took 0.059s
  training loss:		0.176744
  validation loss:		0.214176
  validation accuracy:		92.83 %
Epoch 130 of 2000 took 0.059s
  training loss:		0.178446
  validation loss:		0.228776
  validation accuracy:		93.04 %
Epoch 131 of 2000 took 0.059s
  training loss:		0.181467
  validation loss:		0.214934
  validation accuracy:		93.37 %
Epoch 132 of 2000 took 0.059s
  training loss:		0.180638
  validation loss:		0.210412
  validation accuracy:		93.59 %
Epoch 133 of 2000 took 0.059s
  training loss:		0.176907
  validation loss:		0.211325
  validation accuracy:		93.48 %
Epoch 134 of 2000 took 0.059s
  training loss:		0.176659
  validation loss:		0.213919
  validation accuracy:		93.70 %
Epoch 135 of 2000 took 0.059s
  training loss:		0.175315
  validation loss:		0.220787
  validation accuracy:		93.37 %
Epoch 136 of 2000 took 0.057s
  training loss:		0.170035
  validation loss:		0.220568
  validation accuracy:		92.50 %
Epoch 137 of 2000 took 0.058s
  training loss:		0.176644
  validation loss:		0.209611
  validation accuracy:		93.37 %
Epoch 138 of 2000 took 0.055s
  training loss:		0.173577
  validation loss:		0.213195
  validation accuracy:		93.80 %
Epoch 139 of 2000 took 0.055s
  training loss:		0.167538
  validation loss:		0.226476
  validation accuracy:		93.26 %
Epoch 140 of 2000 took 0.056s
  training loss:		0.170416
  validation loss:		0.210932
  validation accuracy:		93.37 %
Epoch 141 of 2000 took 0.056s
  training loss:		0.169353
  validation loss:		0.221431
  validation accuracy:		93.15 %
Epoch 142 of 2000 took 0.056s
  training loss:		0.169836
  validation loss:		0.220770
  validation accuracy:		93.59 %
Epoch 143 of 2000 took 0.057s
  training loss:		0.170657
  validation loss:		0.218688
  validation accuracy:		93.59 %
Epoch 144 of 2000 took 0.057s
  training loss:		0.166543
  validation loss:		0.207225
  validation accuracy:		93.70 %
Epoch 145 of 2000 took 0.057s
  training loss:		0.165748
  validation loss:		0.216150
  validation accuracy:		93.26 %
Epoch 146 of 2000 took 0.057s
  training loss:		0.162800
  validation loss:		0.209012
  validation accuracy:		93.15 %
Epoch 147 of 2000 took 0.057s
  training loss:		0.166569
  validation loss:		0.207486
  validation accuracy:		93.91 %
Epoch 148 of 2000 took 0.057s
  training loss:		0.163998
  validation loss:		0.211962
  validation accuracy:		93.15 %
Epoch 149 of 2000 took 0.057s
  training loss:		0.164191
  validation loss:		0.216983
  validation accuracy:		93.26 %
Epoch 150 of 2000 took 0.056s
  training loss:		0.162424
  validation loss:		0.212380
  validation accuracy:		93.48 %
Epoch 151 of 2000 took 0.057s
  training loss:		0.159970
  validation loss:		0.216346
  validation accuracy:		93.70 %
Epoch 152 of 2000 took 0.056s
  training loss:		0.161248
  validation loss:		0.214255
  validation accuracy:		93.15 %
Epoch 153 of 2000 took 0.056s
  training loss:		0.160669
  validation loss:		0.224577
  validation accuracy:		93.15 %
Epoch 154 of 2000 took 0.055s
  training loss:		0.156925
  validation loss:		0.205019
  validation accuracy:		93.48 %
Epoch 155 of 2000 took 0.056s
  training loss:		0.161320
  validation loss:		0.206659
  validation accuracy:		93.26 %
Epoch 156 of 2000 took 0.054s
  training loss:		0.158133
  validation loss:		0.203471
  validation accuracy:		94.02 %
Epoch 157 of 2000 took 0.055s
  training loss:		0.157506
  validation loss:		0.210431
  validation accuracy:		93.80 %
Epoch 158 of 2000 took 0.055s
  training loss:		0.159938
  validation loss:		0.210212
  validation accuracy:		93.59 %
Epoch 159 of 2000 took 0.055s
  training loss:		0.158114
  validation loss:		0.206478
  validation accuracy:		93.80 %
Epoch 160 of 2000 took 0.055s
  training loss:		0.154590
  validation loss:		0.216443
  validation accuracy:		93.26 %
Epoch 161 of 2000 took 0.056s
  training loss:		0.154280
  validation loss:		0.208140
  validation accuracy:		93.48 %
Epoch 162 of 2000 took 0.056s
  training loss:		0.153626
  validation loss:		0.212392
  validation accuracy:		93.15 %
Epoch 163 of 2000 took 0.055s
  training loss:		0.151796
  validation loss:		0.210694
  validation accuracy:		93.26 %
Epoch 164 of 2000 took 0.054s
  training loss:		0.153123
  validation loss:		0.216272
  validation accuracy:		93.15 %
Epoch 165 of 2000 took 0.057s
  training loss:		0.155341
  validation loss:		0.217332
  validation accuracy:		93.15 %
Epoch 166 of 2000 took 0.057s
  training loss:		0.148922
  validation loss:		0.215941
  validation accuracy:		92.83 %
Epoch 167 of 2000 took 0.054s
  training loss:		0.151469
  validation loss:		0.210104
  validation accuracy:		93.70 %
Epoch 168 of 2000 took 0.055s
  training loss:		0.146754
  validation loss:		0.224545
  validation accuracy:		93.15 %
Epoch 169 of 2000 took 0.055s
  training loss:		0.147787
  validation loss:		0.209921
  validation accuracy:		93.37 %
Epoch 170 of 2000 took 0.056s
  training loss:		0.150151
  validation loss:		0.221264
  validation accuracy:		92.93 %
Epoch 171 of 2000 took 0.052s
  training loss:		0.147736
  validation loss:		0.210078
  validation accuracy:		93.91 %
Epoch 172 of 2000 took 0.054s
  training loss:		0.147000
  validation loss:		0.220563
  validation accuracy:		93.15 %
Epoch 173 of 2000 took 0.056s
  training loss:		0.142679
  validation loss:		0.220502
  validation accuracy:		93.15 %
Epoch 174 of 2000 took 0.057s
  training loss:		0.143127
  validation loss:		0.225206
  validation accuracy:		92.93 %
Epoch 175 of 2000 took 0.057s
  training loss:		0.142556
  validation loss:		0.213751
  validation accuracy:		93.59 %
Epoch 176 of 2000 took 0.057s
  training loss:		0.139501
  validation loss:		0.203700
  validation accuracy:		93.70 %
Epoch 177 of 2000 took 0.055s
  training loss:		0.139574
  validation loss:		0.218116
  validation accuracy:		92.93 %
Epoch 178 of 2000 took 0.056s
  training loss:		0.141001
  validation loss:		0.201754
  validation accuracy:		93.70 %
Epoch 179 of 2000 took 0.056s
  training loss:		0.141355
  validation loss:		0.211178
  validation accuracy:		93.70 %
Epoch 180 of 2000 took 0.055s
  training loss:		0.136780
  validation loss:		0.219105
  validation accuracy:		93.04 %
Epoch 181 of 2000 took 0.056s
  training loss:		0.145148
  validation loss:		0.214555
  validation accuracy:		93.59 %
Epoch 182 of 2000 took 0.055s
  training loss:		0.143062
  validation loss:		0.231611
  validation accuracy:		92.72 %
Epoch 183 of 2000 took 0.055s
  training loss:		0.141957
  validation loss:		0.209416
  validation accuracy:		93.70 %
Epoch 184 of 2000 took 0.056s
  training loss:		0.140389
  validation loss:		0.212048
  validation accuracy:		93.59 %
Epoch 185 of 2000 took 0.058s
  training loss:		0.138996
  validation loss:		0.213345
  validation accuracy:		93.15 %
Epoch 186 of 2000 took 0.058s
  training loss:		0.136692
  validation loss:		0.220888
  validation accuracy:		92.83 %
Epoch 187 of 2000 took 0.057s
  training loss:		0.136234
  validation loss:		0.218226
  validation accuracy:		93.26 %
Epoch 188 of 2000 took 0.055s
  training loss:		0.136960
  validation loss:		0.224658
  validation accuracy:		92.93 %
Epoch 189 of 2000 took 0.055s
  training loss:		0.139178
  validation loss:		0.214698
  validation accuracy:		93.37 %
Epoch 190 of 2000 took 0.057s
  training loss:		0.135713
  validation loss:		0.213305
  validation accuracy:		93.48 %
Epoch 191 of 2000 took 0.055s
  training loss:		0.137215
  validation loss:		0.215809
  validation accuracy:		93.48 %
Epoch 192 of 2000 took 0.056s
  training loss:		0.133857
  validation loss:		0.209137
  validation accuracy:		93.59 %
Epoch 193 of 2000 took 0.059s
  training loss:		0.136701
  validation loss:		0.212011
  validation accuracy:		93.70 %
Epoch 194 of 2000 took 0.058s
  training loss:		0.134449
  validation loss:		0.216410
  validation accuracy:		93.48 %
Epoch 195 of 2000 took 0.055s
  training loss:		0.133859
  validation loss:		0.222946
  validation accuracy:		93.15 %
Epoch 196 of 2000 took 0.057s
  training loss:		0.135026
  validation loss:		0.212851
  validation accuracy:		93.26 %
Epoch 197 of 2000 took 0.054s
  training loss:		0.131365
  validation loss:		0.206169
  validation accuracy:		93.80 %
Epoch 198 of 2000 took 0.059s
  training loss:		0.129539
  validation loss:		0.226607
  validation accuracy:		93.04 %
Epoch 199 of 2000 took 0.058s
  training loss:		0.133237
  validation loss:		0.212628
  validation accuracy:		93.70 %
Epoch 200 of 2000 took 0.055s
  training loss:		0.132357
  validation loss:		0.221263
  validation accuracy:		92.93 %
Epoch 201 of 2000 took 0.057s
  training loss:		0.130556
  validation loss:		0.214127
  validation accuracy:		93.80 %
Epoch 202 of 2000 took 0.055s
  training loss:		0.129583
  validation loss:		0.208527
  validation accuracy:		93.80 %
Epoch 203 of 2000 took 0.056s
  training loss:		0.129220
  validation loss:		0.216576
  validation accuracy:		93.59 %
Epoch 204 of 2000 took 0.058s
  training loss:		0.131905
  validation loss:		0.213572
  validation accuracy:		93.37 %
Epoch 205 of 2000 took 0.058s
  training loss:		0.131507
  validation loss:		0.212041
  validation accuracy:		93.37 %
Epoch 206 of 2000 took 0.055s
  training loss:		0.128648
  validation loss:		0.238921
  validation accuracy:		92.50 %
Epoch 207 of 2000 took 0.058s
  training loss:		0.128411
  validation loss:		0.208021
  validation accuracy:		93.91 %
Epoch 208 of 2000 took 0.058s
  training loss:		0.127030
  validation loss:		0.212402
  validation accuracy:		93.59 %
Epoch 209 of 2000 took 0.058s
  training loss:		0.128332
  validation loss:		0.228401
  validation accuracy:		92.61 %
Epoch 210 of 2000 took 0.058s
  training loss:		0.126151
  validation loss:		0.218049
  validation accuracy:		93.48 %
Epoch 211 of 2000 took 0.058s
  training loss:		0.127075
  validation loss:		0.214063
  validation accuracy:		93.70 %
Epoch 212 of 2000 took 0.058s
  training loss:		0.123558
  validation loss:		0.216498
  validation accuracy:		93.48 %
Epoch 213 of 2000 took 0.058s
  training loss:		0.126353
  validation loss:		0.213346
  validation accuracy:		93.04 %
Epoch 214 of 2000 took 0.058s
  training loss:		0.126091
  validation loss:		0.205749
  validation accuracy:		93.48 %
Epoch 215 of 2000 took 0.058s
  training loss:		0.127634
  validation loss:		0.228354
  validation accuracy:		93.37 %
Epoch 216 of 2000 took 0.058s
  training loss:		0.124451
  validation loss:		0.226065
  validation accuracy:		93.04 %
Epoch 217 of 2000 took 0.058s
  training loss:		0.122799
  validation loss:		0.214903
  validation accuracy:		93.37 %
Epoch 218 of 2000 took 0.058s
  training loss:		0.125320
  validation loss:		0.221941
  validation accuracy:		93.80 %
Epoch 219 of 2000 took 0.059s
  training loss:		0.122081
  validation loss:		0.218938
  validation accuracy:		93.48 %
Epoch 220 of 2000 took 0.056s
  training loss:		0.123955
  validation loss:		0.208244
  validation accuracy:		93.70 %
Epoch 221 of 2000 took 0.058s
  training loss:		0.123444
  validation loss:		0.220897
  validation accuracy:		93.15 %
Epoch 222 of 2000 took 0.058s
  training loss:		0.121712
  validation loss:		0.220955
  validation accuracy:		93.48 %
Epoch 223 of 2000 took 0.058s
  training loss:		0.119087
  validation loss:		0.226224
  validation accuracy:		93.37 %
Epoch 224 of 2000 took 0.058s
  training loss:		0.120069
  validation loss:		0.222089
  validation accuracy:		93.26 %
Epoch 225 of 2000 took 0.058s
  training loss:		0.119973
  validation loss:		0.213239
  validation accuracy:		93.80 %
Epoch 226 of 2000 took 0.056s
  training loss:		0.119663
  validation loss:		0.218176
  validation accuracy:		93.37 %
Epoch 227 of 2000 took 0.057s
  training loss:		0.119484
  validation loss:		0.214130
  validation accuracy:		93.59 %
Epoch 228 of 2000 took 0.058s
  training loss:		0.118663
  validation loss:		0.213780
  validation accuracy:		93.26 %
Epoch 229 of 2000 took 0.056s
  training loss:		0.118649
  validation loss:		0.224620
  validation accuracy:		93.70 %
Epoch 230 of 2000 took 0.056s
  training loss:		0.121147
  validation loss:		0.219748
  validation accuracy:		93.37 %
Epoch 231 of 2000 took 0.056s
  training loss:		0.118532
  validation loss:		0.223256
  validation accuracy:		93.26 %
Epoch 232 of 2000 took 0.056s
  training loss:		0.114138
  validation loss:		0.229066
  validation accuracy:		92.83 %
Epoch 233 of 2000 took 0.056s
  training loss:		0.116984
  validation loss:		0.224784
  validation accuracy:		93.26 %
Epoch 234 of 2000 took 0.059s
  training loss:		0.115035
  validation loss:		0.207939
  validation accuracy:		93.91 %
Epoch 235 of 2000 took 0.058s
  training loss:		0.118985
  validation loss:		0.229225
  validation accuracy:		93.04 %
Epoch 236 of 2000 took 0.057s
  training loss:		0.111576
  validation loss:		0.216791
  validation accuracy:		93.70 %
Epoch 237 of 2000 took 0.057s
  training loss:		0.113412
  validation loss:		0.234124
  validation accuracy:		92.61 %
Epoch 238 of 2000 took 0.054s
  training loss:		0.116719
  validation loss:		0.221887
  validation accuracy:		93.26 %
Epoch 239 of 2000 took 0.059s
  training loss:		0.113524
  validation loss:		0.221361
  validation accuracy:		93.48 %
Epoch 240 of 2000 took 0.055s
  training loss:		0.111864
  validation loss:		0.222507
  validation accuracy:		93.37 %
Epoch 241 of 2000 took 0.056s
  training loss:		0.111387
  validation loss:		0.217972
  validation accuracy:		93.59 %
Epoch 242 of 2000 took 0.055s
  training loss:		0.108384
  validation loss:		0.220118
  validation accuracy:		93.37 %
Epoch 243 of 2000 took 0.057s
  training loss:		0.114552
  validation loss:		0.212555
  validation accuracy:		93.59 %
Epoch 244 of 2000 took 0.054s
  training loss:		0.110836
  validation loss:		0.228076
  validation accuracy:		92.61 %
Epoch 245 of 2000 took 0.058s
  training loss:		0.109835
  validation loss:		0.223039
  validation accuracy:		93.59 %
Epoch 246 of 2000 took 0.054s
  training loss:		0.112491
  validation loss:		0.224012
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.056s
  training loss:		0.117102
  validation loss:		0.223032
  validation accuracy:		93.15 %
Epoch 248 of 2000 took 0.055s
  training loss:		0.111486
  validation loss:		0.214658
  validation accuracy:		93.48 %
Epoch 249 of 2000 took 0.057s
  training loss:		0.113605
  validation loss:		0.218690
  validation accuracy:		93.37 %
Epoch 250 of 2000 took 0.054s
  training loss:		0.110801
  validation loss:		0.236442
  validation accuracy:		92.72 %
Epoch 251 of 2000 took 0.057s
  training loss:		0.109230
  validation loss:		0.223443
  validation accuracy:		93.70 %
Epoch 252 of 2000 took 0.058s
  training loss:		0.107563
  validation loss:		0.232962
  validation accuracy:		92.72 %
Epoch 253 of 2000 took 0.058s
  training loss:		0.110780
  validation loss:		0.219659
  validation accuracy:		93.59 %
Epoch 254 of 2000 took 0.058s
  training loss:		0.110045
  validation loss:		0.217624
  validation accuracy:		93.80 %
Epoch 255 of 2000 took 0.058s
  training loss:		0.110657
  validation loss:		0.226942
  validation accuracy:		93.59 %
Epoch 256 of 2000 took 0.057s
  training loss:		0.109285
  validation loss:		0.215070
  validation accuracy:		93.59 %
Epoch 257 of 2000 took 0.058s
  training loss:		0.110208
  validation loss:		0.222924
  validation accuracy:		93.48 %
Epoch 258 of 2000 took 0.058s
  training loss:		0.105204
  validation loss:		0.220196
  validation accuracy:		93.48 %
Epoch 259 of 2000 took 0.058s
  training loss:		0.109642
  validation loss:		0.222189
  validation accuracy:		93.59 %
Epoch 260 of 2000 took 0.058s
  training loss:		0.106257
  validation loss:		0.221485
  validation accuracy:		93.26 %
Epoch 261 of 2000 took 0.058s
  training loss:		0.104497
  validation loss:		0.218245
  validation accuracy:		94.02 %
Epoch 262 of 2000 took 0.058s
  training loss:		0.103772
  validation loss:		0.217558
  validation accuracy:		93.37 %
Epoch 263 of 2000 took 0.058s
  training loss:		0.108216
  validation loss:		0.223344
  validation accuracy:		93.26 %
Epoch 264 of 2000 took 0.058s
  training loss:		0.107741
  validation loss:		0.223534
  validation accuracy:		93.26 %
Epoch 265 of 2000 took 0.056s
  training loss:		0.104718
  validation loss:		0.217576
  validation accuracy:		93.80 %
Epoch 266 of 2000 took 0.055s
  training loss:		0.102678
  validation loss:		0.222846
  validation accuracy:		93.80 %
Epoch 267 of 2000 took 0.057s
  training loss:		0.105223
  validation loss:		0.228066
  validation accuracy:		92.83 %
Epoch 268 of 2000 took 0.058s
  training loss:		0.101348
  validation loss:		0.222984
  validation accuracy:		93.80 %
Epoch 269 of 2000 took 0.055s
  training loss:		0.103551
  validation loss:		0.218246
  validation accuracy:		93.26 %
Epoch 270 of 2000 took 0.055s
  training loss:		0.101045
  validation loss:		0.230561
  validation accuracy:		93.26 %
Epoch 271 of 2000 took 0.055s
  training loss:		0.103821
  validation loss:		0.219658
  validation accuracy:		93.48 %
Epoch 272 of 2000 took 0.055s
  training loss:		0.102735
  validation loss:		0.232638
  validation accuracy:		93.04 %
Epoch 273 of 2000 took 0.055s
  training loss:		0.102394
  validation loss:		0.228671
  validation accuracy:		92.83 %
Epoch 274 of 2000 took 0.052s
  training loss:		0.101755
  validation loss:		0.221202
  validation accuracy:		93.59 %
Epoch 275 of 2000 took 0.054s
  training loss:		0.102093
  validation loss:		0.225451
  validation accuracy:		93.15 %
Epoch 276 of 2000 took 0.058s
  training loss:		0.102676
  validation loss:		0.226425
  validation accuracy:		93.04 %
Epoch 277 of 2000 took 0.057s
  training loss:		0.099761
  validation loss:		0.222011
  validation accuracy:		93.48 %
Epoch 278 of 2000 took 0.055s
  training loss:		0.101191
  validation loss:		0.225153
  validation accuracy:		93.15 %
Epoch 279 of 2000 took 0.056s
  training loss:		0.101466
  validation loss:		0.221411
  validation accuracy:		93.04 %
Epoch 280 of 2000 took 0.055s
  training loss:		0.101199
  validation loss:		0.218225
  validation accuracy:		93.37 %
Epoch 281 of 2000 took 0.055s
  training loss:		0.097292
  validation loss:		0.227657
  validation accuracy:		93.26 %
Epoch 282 of 2000 took 0.055s
  training loss:		0.100603
  validation loss:		0.223335
  validation accuracy:		93.37 %
Epoch 283 of 2000 took 0.056s
  training loss:		0.101952
  validation loss:		0.233595
  validation accuracy:		92.50 %
Epoch 284 of 2000 took 0.056s
  training loss:		0.099316
  validation loss:		0.229327
  validation accuracy:		93.48 %
Epoch 285 of 2000 took 0.056s
  training loss:		0.098380
  validation loss:		0.226090
  validation accuracy:		93.48 %
Epoch 286 of 2000 took 0.056s
  training loss:		0.096948
  validation loss:		0.227043
  validation accuracy:		92.93 %
Epoch 287 of 2000 took 0.058s
  training loss:		0.099220
  validation loss:		0.230728
  validation accuracy:		92.72 %
Epoch 288 of 2000 took 0.058s
  training loss:		0.098674
  validation loss:		0.242246
  validation accuracy:		92.93 %
Epoch 289 of 2000 took 0.058s
  training loss:		0.095003
  validation loss:		0.237754
  validation accuracy:		92.72 %
Epoch 290 of 2000 took 0.058s
  training loss:		0.100566
  validation loss:		0.221730
  validation accuracy:		93.15 %
Epoch 291 of 2000 took 0.058s
  training loss:		0.097356
  validation loss:		0.225932
  validation accuracy:		93.48 %
Epoch 292 of 2000 took 0.058s
  training loss:		0.098782
  validation loss:		0.223984
  validation accuracy:		93.15 %
Epoch 293 of 2000 took 0.058s
  training loss:		0.096761
  validation loss:		0.235871
  validation accuracy:		93.70 %
Epoch 294 of 2000 took 0.058s
  training loss:		0.095894
  validation loss:		0.239121
  validation accuracy:		92.72 %
Epoch 295 of 2000 took 0.058s
  training loss:		0.096592
  validation loss:		0.232623
  validation accuracy:		92.93 %
Epoch 296 of 2000 took 0.058s
  training loss:		0.094763
  validation loss:		0.227163
  validation accuracy:		93.15 %
Epoch 297 of 2000 took 0.058s
  training loss:		0.095823
  validation loss:		0.227364
  validation accuracy:		93.04 %
Epoch 298 of 2000 took 0.058s
  training loss:		0.094596
  validation loss:		0.229622
  validation accuracy:		93.15 %
Epoch 299 of 2000 took 0.058s
  training loss:		0.092902
  validation loss:		0.225051
  validation accuracy:		93.04 %
Epoch 300 of 2000 took 0.057s
  training loss:		0.094398
  validation loss:		0.226413
  validation accuracy:		93.15 %
Epoch 301 of 2000 took 0.057s
  training loss:		0.096673
  validation loss:		0.228164
  validation accuracy:		93.04 %
Epoch 302 of 2000 took 0.057s
  training loss:		0.093030
  validation loss:		0.236593
  validation accuracy:		92.93 %
Epoch 303 of 2000 took 0.057s
  training loss:		0.092298
  validation loss:		0.220059
  validation accuracy:		93.59 %
Epoch 304 of 2000 took 0.057s
  training loss:		0.092977
  validation loss:		0.223057
  validation accuracy:		93.37 %
Epoch 305 of 2000 took 0.057s
  training loss:		0.090192
  validation loss:		0.231637
  validation accuracy:		92.93 %
Epoch 306 of 2000 took 0.057s
  training loss:		0.094728
  validation loss:		0.224300
  validation accuracy:		93.48 %
Epoch 307 of 2000 took 0.057s
  training loss:		0.096142
  validation loss:		0.232045
  validation accuracy:		92.50 %
Epoch 308 of 2000 took 0.057s
  training loss:		0.091553
  validation loss:		0.239892
  validation accuracy:		93.26 %
Epoch 309 of 2000 took 0.057s
  training loss:		0.094967
  validation loss:		0.235085
  validation accuracy:		93.04 %
Epoch 310 of 2000 took 0.057s
  training loss:		0.093861
  validation loss:		0.236333
  validation accuracy:		92.83 %
Epoch 311 of 2000 took 0.057s
  training loss:		0.090802
  validation loss:		0.225077
  validation accuracy:		93.37 %
Epoch 312 of 2000 took 0.057s
  training loss:		0.090426
  validation loss:		0.226484
  validation accuracy:		93.70 %
Epoch 313 of 2000 took 0.057s
  training loss:		0.091882
  validation loss:		0.241434
  validation accuracy:		92.83 %
Epoch 314 of 2000 took 0.058s
  training loss:		0.091903
  validation loss:		0.245695
  validation accuracy:		92.50 %
Epoch 315 of 2000 took 0.058s
  training loss:		0.091196
  validation loss:		0.225974
  validation accuracy:		93.37 %
Epoch 316 of 2000 took 0.058s
  training loss:		0.091327
  validation loss:		0.216975
  validation accuracy:		93.48 %
Epoch 317 of 2000 took 0.058s
  training loss:		0.087321
  validation loss:		0.223653
  validation accuracy:		93.48 %
Epoch 318 of 2000 took 0.058s
  training loss:		0.087817
  validation loss:		0.217333
  validation accuracy:		93.48 %
Epoch 319 of 2000 took 0.058s
  training loss:		0.089821
  validation loss:		0.236203
  validation accuracy:		92.93 %
Epoch 320 of 2000 took 0.058s
  training loss:		0.089240
  validation loss:		0.224975
  validation accuracy:		93.37 %
Epoch 321 of 2000 took 0.059s
  training loss:		0.089502
  validation loss:		0.238219
  validation accuracy:		93.37 %
Epoch 322 of 2000 took 0.058s
  training loss:		0.085233
  validation loss:		0.231929
  validation accuracy:		93.26 %
Epoch 323 of 2000 took 0.058s
  training loss:		0.089411
  validation loss:		0.238069
  validation accuracy:		92.93 %
Epoch 324 of 2000 took 0.058s
  training loss:		0.091248
  validation loss:		0.226027
  validation accuracy:		93.26 %
Epoch 325 of 2000 took 0.058s
  training loss:		0.088627
  validation loss:		0.226650
  validation accuracy:		93.70 %
Epoch 326 of 2000 took 0.058s
  training loss:		0.086097
  validation loss:		0.245547
  validation accuracy:		92.39 %
Epoch 327 of 2000 took 0.058s
  training loss:		0.088760
  validation loss:		0.244217
  validation accuracy:		93.48 %
Epoch 328 of 2000 took 0.058s
  training loss:		0.088155
  validation loss:		0.253136
  validation accuracy:		92.39 %
Epoch 329 of 2000 took 0.058s
  training loss:		0.084327
  validation loss:		0.230355
  validation accuracy:		93.04 %
Epoch 330 of 2000 took 0.058s
  training loss:		0.087100
  validation loss:		0.236843
  validation accuracy:		92.72 %
Epoch 331 of 2000 took 0.058s
  training loss:		0.088013
  validation loss:		0.231687
  validation accuracy:		93.15 %
Epoch 332 of 2000 took 0.058s
  training loss:		0.085414
  validation loss:		0.236884
  validation accuracy:		93.48 %
Epoch 333 of 2000 took 0.057s
  training loss:		0.084552
  validation loss:		0.227850
  validation accuracy:		93.15 %
Epoch 334 of 2000 took 0.056s
  training loss:		0.086533
  validation loss:		0.232619
  validation accuracy:		93.59 %
Epoch 335 of 2000 took 0.056s
  training loss:		0.085499
  validation loss:		0.233964
  validation accuracy:		93.04 %
Epoch 336 of 2000 took 0.057s
  training loss:		0.082786
  validation loss:		0.233403
  validation accuracy:		93.26 %
Epoch 337 of 2000 took 0.056s
  training loss:		0.082550
  validation loss:		0.229989
  validation accuracy:		93.04 %
Epoch 338 of 2000 took 0.057s
  training loss:		0.084166
  validation loss:		0.252990
  validation accuracy:		92.50 %
Epoch 339 of 2000 took 0.057s
  training loss:		0.088404
  validation loss:		0.248556
  validation accuracy:		93.04 %
Epoch 340 of 2000 took 0.057s
  training loss:		0.085104
  validation loss:		0.254024
  validation accuracy:		91.96 %
Epoch 341 of 2000 took 0.055s
  training loss:		0.087471
  validation loss:		0.236149
  validation accuracy:		92.61 %
Epoch 342 of 2000 took 0.056s
  training loss:		0.085688
  validation loss:		0.247890
  validation accuracy:		92.28 %
Epoch 343 of 2000 took 0.056s
  training loss:		0.084835
  validation loss:		0.245133
  validation accuracy:		92.72 %
Epoch 344 of 2000 took 0.056s
  training loss:		0.082667
  validation loss:		0.233451
  validation accuracy:		93.48 %
Epoch 345 of 2000 took 0.056s
  training loss:		0.081747
  validation loss:		0.234113
  validation accuracy:		93.15 %
Epoch 346 of 2000 took 0.054s
  training loss:		0.080874
  validation loss:		0.245837
  validation accuracy:		92.83 %
Epoch 347 of 2000 took 0.053s
  training loss:		0.081501
  validation loss:		0.244418
  validation accuracy:		92.83 %
Epoch 348 of 2000 took 0.057s
  training loss:		0.082363
  validation loss:		0.233861
  validation accuracy:		92.93 %
Epoch 349 of 2000 took 0.054s
  training loss:		0.080360
  validation loss:		0.228944
  validation accuracy:		93.59 %
Epoch 350 of 2000 took 0.056s
  training loss:		0.079694
  validation loss:		0.253131
  validation accuracy:		92.39 %
Epoch 351 of 2000 took 0.054s
  training loss:		0.081937
  validation loss:		0.243047
  validation accuracy:		92.61 %
Epoch 352 of 2000 took 0.056s
  training loss:		0.077191
  validation loss:		0.238711
  validation accuracy:		93.04 %
Epoch 353 of 2000 took 0.055s
  training loss:		0.079481
  validation loss:		0.249649
  validation accuracy:		92.50 %
Epoch 354 of 2000 took 0.056s
  training loss:		0.078660
  validation loss:		0.233514
  validation accuracy:		93.59 %
Epoch 355 of 2000 took 0.057s
  training loss:		0.083959
  validation loss:		0.245467
  validation accuracy:		92.93 %
Epoch 356 of 2000 took 0.055s
  training loss:		0.080657
  validation loss:		0.254963
  validation accuracy:		92.83 %
Epoch 357 of 2000 took 0.056s
  training loss:		0.078787
  validation loss:		0.244161
  validation accuracy:		93.37 %
Epoch 358 of 2000 took 0.057s
  training loss:		0.083532
  validation loss:		0.241717
  validation accuracy:		93.26 %
Epoch 359 of 2000 took 0.057s
  training loss:		0.080098
  validation loss:		0.236945
  validation accuracy:		93.48 %
Epoch 360 of 2000 took 0.055s
  training loss:		0.082923
  validation loss:		0.242959
  validation accuracy:		92.72 %
Epoch 361 of 2000 took 0.055s
  training loss:		0.076197
  validation loss:		0.236432
  validation accuracy:		93.48 %
Epoch 362 of 2000 took 0.055s
  training loss:		0.078182
  validation loss:		0.253104
  validation accuracy:		92.50 %
Epoch 363 of 2000 took 0.055s
  training loss:		0.078490
  validation loss:		0.265177
  validation accuracy:		92.72 %
Epoch 364 of 2000 took 0.056s
  training loss:		0.080545
  validation loss:		0.238631
  validation accuracy:		92.83 %
Epoch 365 of 2000 took 0.056s
  training loss:		0.079144
  validation loss:		0.254618
  validation accuracy:		92.61 %
Epoch 366 of 2000 took 0.057s
  training loss:		0.077152
  validation loss:		0.245688
  validation accuracy:		92.39 %
Epoch 367 of 2000 took 0.057s
  training loss:		0.079731
  validation loss:		0.249199
  validation accuracy:		92.93 %
Epoch 368 of 2000 took 0.057s
  training loss:		0.075868
  validation loss:		0.231103
  validation accuracy:		93.59 %
Epoch 369 of 2000 took 0.055s
  training loss:		0.075910
  validation loss:		0.241803
  validation accuracy:		93.15 %
Epoch 370 of 2000 took 0.057s
  training loss:		0.077113
  validation loss:		0.254341
  validation accuracy:		92.61 %
Epoch 371 of 2000 took 0.055s
  training loss:		0.077292
  validation loss:		0.251153
  validation accuracy:		92.83 %
Epoch 372 of 2000 took 0.055s
  training loss:		0.078798
  validation loss:		0.254223
  validation accuracy:		92.28 %
Epoch 373 of 2000 took 0.055s
  training loss:		0.077028
  validation loss:		0.240764
  validation accuracy:		92.93 %
Epoch 374 of 2000 took 0.057s
  training loss:		0.075927
  validation loss:		0.238009
  validation accuracy:		93.37 %
Epoch 375 of 2000 took 0.057s
  training loss:		0.077000
  validation loss:		0.244044
  validation accuracy:		93.26 %
Epoch 376 of 2000 took 0.057s
  training loss:		0.075267
  validation loss:		0.249899
  validation accuracy:		92.61 %
Epoch 377 of 2000 took 0.057s
  training loss:		0.075889
  validation loss:		0.252269
  validation accuracy:		92.50 %
Epoch 378 of 2000 took 0.057s
  training loss:		0.072883
  validation loss:		0.256606
  validation accuracy:		92.72 %
Epoch 379 of 2000 took 0.057s
  training loss:		0.074176
  validation loss:		0.246097
  validation accuracy:		92.50 %
Epoch 380 of 2000 took 0.055s
  training loss:		0.076734
  validation loss:		0.242691
  validation accuracy:		93.26 %
Epoch 381 of 2000 took 0.057s
  training loss:		0.074246
  validation loss:		0.251063
  validation accuracy:		92.83 %
Epoch 382 of 2000 took 0.057s
  training loss:		0.074664
  validation loss:		0.253974
  validation accuracy:		92.61 %
Epoch 383 of 2000 took 0.057s
  training loss:		0.074462
  validation loss:		0.242553
  validation accuracy:		92.61 %
Epoch 384 of 2000 took 0.055s
  training loss:		0.073997
  validation loss:		0.242754
  validation accuracy:		93.48 %
Epoch 385 of 2000 took 0.057s
  training loss:		0.072087
  validation loss:		0.248128
  validation accuracy:		92.72 %
Epoch 386 of 2000 took 0.057s
  training loss:		0.073344
  validation loss:		0.251086
  validation accuracy:		92.83 %
Epoch 387 of 2000 took 0.057s
  training loss:		0.073315
  validation loss:		0.251641
  validation accuracy:		93.26 %
Epoch 388 of 2000 took 0.057s
  training loss:		0.071444
  validation loss:		0.244444
  validation accuracy:		93.15 %
Epoch 389 of 2000 took 0.055s
  training loss:		0.073898
  validation loss:		0.259147
  validation accuracy:		93.37 %
Epoch 390 of 2000 took 0.057s
  training loss:		0.069736
  validation loss:		0.274728
  validation accuracy:		92.17 %
Epoch 391 of 2000 took 0.057s
  training loss:		0.076375
  validation loss:		0.248209
  validation accuracy:		93.04 %
Epoch 392 of 2000 took 0.057s
  training loss:		0.068756
  validation loss:		0.253941
  validation accuracy:		92.83 %
Epoch 393 of 2000 took 0.057s
  training loss:		0.072375
  validation loss:		0.253405
  validation accuracy:		92.93 %
Epoch 394 of 2000 took 0.056s
  training loss:		0.073519
  validation loss:		0.243283
  validation accuracy:		92.83 %
Epoch 395 of 2000 took 0.057s
  training loss:		0.071732
  validation loss:		0.237787
  validation accuracy:		93.26 %
Epoch 396 of 2000 took 0.057s
  training loss:		0.072253
  validation loss:		0.238544
  validation accuracy:		93.37 %
Epoch 397 of 2000 took 0.055s
  training loss:		0.071764
  validation loss:		0.268886
  validation accuracy:		92.07 %
Epoch 398 of 2000 took 0.057s
  training loss:		0.070020
  validation loss:		0.265605
  validation accuracy:		92.50 %
Epoch 399 of 2000 took 0.057s
  training loss:		0.071900
  validation loss:		0.245752
  validation accuracy:		93.26 %
Epoch 400 of 2000 took 0.057s
  training loss:		0.071696
  validation loss:		0.245833
  validation accuracy:		93.15 %
Epoch 401 of 2000 took 0.056s
  training loss:		0.072628
  validation loss:		0.260342
  validation accuracy:		93.15 %
Epoch 402 of 2000 took 0.057s
  training loss:		0.070647
  validation loss:		0.255321
  validation accuracy:		92.93 %
Epoch 403 of 2000 took 0.056s
  training loss:		0.068575
  validation loss:		0.254787
  validation accuracy:		93.26 %
Epoch 404 of 2000 took 0.057s
  training loss:		0.069748
  validation loss:		0.254443
  validation accuracy:		92.39 %
Epoch 405 of 2000 took 0.057s
  training loss:		0.070329
  validation loss:		0.255794
  validation accuracy:		92.83 %
Epoch 406 of 2000 took 0.057s
  training loss:		0.070351
  validation loss:		0.263874
  validation accuracy:		92.50 %
Epoch 407 of 2000 took 0.057s
  training loss:		0.067522
  validation loss:		0.256458
  validation accuracy:		93.04 %
Epoch 408 of 2000 took 0.057s
  training loss:		0.069107
  validation loss:		0.269267
  validation accuracy:		92.61 %
Epoch 409 of 2000 took 0.057s
  training loss:		0.067465
  validation loss:		0.260362
  validation accuracy:		92.61 %
Epoch 410 of 2000 took 0.057s
  training loss:		0.070663
  validation loss:		0.257974
  validation accuracy:		93.04 %
Epoch 411 of 2000 took 0.057s
  training loss:		0.067128
  validation loss:		0.268724
  validation accuracy:		92.61 %
Epoch 412 of 2000 took 0.057s
  training loss:		0.069215
  validation loss:		0.280938
  validation accuracy:		92.39 %
Epoch 413 of 2000 took 0.057s
  training loss:		0.070457
  validation loss:		0.251788
  validation accuracy:		92.93 %
Epoch 414 of 2000 took 0.057s
  training loss:		0.067088
  validation loss:		0.254792
  validation accuracy:		93.48 %
Epoch 415 of 2000 took 0.057s
  training loss:		0.068995
  validation loss:		0.259286
  validation accuracy:		92.83 %
Epoch 416 of 2000 took 0.056s
  training loss:		0.066216
  validation loss:		0.252257
  validation accuracy:		93.26 %
Epoch 417 of 2000 took 0.057s
  training loss:		0.066135
  validation loss:		0.268332
  validation accuracy:		93.26 %
Epoch 418 of 2000 took 0.056s
  training loss:		0.066828
  validation loss:		0.275451
  validation accuracy:		92.17 %
Epoch 419 of 2000 took 0.056s
  training loss:		0.066946
  validation loss:		0.261916
  validation accuracy:		92.93 %
Epoch 420 of 2000 took 0.056s
  training loss:		0.066322
  validation loss:		0.251081
  validation accuracy:		92.83 %
Epoch 421 of 2000 took 0.057s
  training loss:		0.066170
  validation loss:		0.252546
  validation accuracy:		93.48 %
Epoch 422 of 2000 took 0.057s
  training loss:		0.067686
  validation loss:		0.267901
  validation accuracy:		92.72 %
Epoch 423 of 2000 took 0.058s
  training loss:		0.063897
  validation loss:		0.256018
  validation accuracy:		92.83 %
Epoch 424 of 2000 took 0.057s
  training loss:		0.066564
  validation loss:		0.257597
  validation accuracy:		92.93 %
Epoch 425 of 2000 took 0.055s
  training loss:		0.067211
  validation loss:		0.277815
  validation accuracy:		92.07 %
Epoch 426 of 2000 took 0.057s
  training loss:		0.067108
  validation loss:		0.270722
  validation accuracy:		92.61 %
Epoch 427 of 2000 took 0.056s
  training loss:		0.062683
  validation loss:		0.263456
  validation accuracy:		92.83 %
Epoch 428 of 2000 took 0.055s
  training loss:		0.067135
  validation loss:		0.286999
  validation accuracy:		92.07 %
Epoch 429 of 2000 took 0.056s
  training loss:		0.065662
  validation loss:		0.280774
  validation accuracy:		92.07 %
Epoch 430 of 2000 took 0.056s
  training loss:		0.066725
  validation loss:		0.258363
  validation accuracy:		93.04 %
Epoch 431 of 2000 took 0.054s
  training loss:		0.066240
  validation loss:		0.261300
  validation accuracy:		93.15 %
Epoch 432 of 2000 took 0.057s
  training loss:		0.064250
  validation loss:		0.258266
  validation accuracy:		93.15 %
Epoch 433 of 2000 took 0.057s
  training loss:		0.065385
  validation loss:		0.259831
  validation accuracy:		93.15 %
Epoch 434 of 2000 took 0.056s
  training loss:		0.063552
  validation loss:		0.281143
  validation accuracy:		92.72 %
Epoch 435 of 2000 took 0.056s
  training loss:		0.064791
  validation loss:		0.262533
  validation accuracy:		92.72 %
Epoch 436 of 2000 took 0.056s
  training loss:		0.063713
  validation loss:		0.271051
  validation accuracy:		92.83 %
Epoch 437 of 2000 took 0.057s
  training loss:		0.064809
  validation loss:		0.271063
  validation accuracy:		92.50 %
Epoch 438 of 2000 took 0.055s
  training loss:		0.065129
  validation loss:		0.267755
  validation accuracy:		92.72 %
Epoch 439 of 2000 took 0.057s
  training loss:		0.064652
  validation loss:		0.265838
  validation accuracy:		92.93 %
Epoch 440 of 2000 took 0.057s
  training loss:		0.063983
  validation loss:		0.267241
  validation accuracy:		92.83 %
Epoch 441 of 2000 took 0.056s
  training loss:		0.061218
  validation loss:		0.272820
  validation accuracy:		92.93 %
Epoch 442 of 2000 took 0.056s
  training loss:		0.063581
  validation loss:		0.265635
  validation accuracy:		93.04 %
Epoch 443 of 2000 took 0.057s
  training loss:		0.062914
  validation loss:		0.280806
  validation accuracy:		92.39 %
Epoch 444 of 2000 took 0.055s
  training loss:		0.061529
  validation loss:		0.253311
  validation accuracy:		93.26 %
Epoch 445 of 2000 took 0.057s
  training loss:		0.063177
  validation loss:		0.268262
  validation accuracy:		92.72 %
Epoch 446 of 2000 took 0.058s
  training loss:		0.062674
  validation loss:		0.266995
  validation accuracy:		93.04 %
Epoch 447 of 2000 took 0.058s
  training loss:		0.063037
  validation loss:		0.285016
  validation accuracy:		92.39 %
Epoch 448 of 2000 took 0.056s
  training loss:		0.062495
  validation loss:		0.280373
  validation accuracy:		92.61 %
Epoch 449 of 2000 took 0.057s
  training loss:		0.062489
  validation loss:		0.262240
  validation accuracy:		93.26 %
Epoch 450 of 2000 took 0.055s
  training loss:		0.060410
  validation loss:		0.259780
  validation accuracy:		93.26 %
Epoch 451 of 2000 took 0.059s
  training loss:		0.064306
  validation loss:		0.266194
  validation accuracy:		93.26 %
Epoch 452 of 2000 took 0.057s
  training loss:		0.062706
  validation loss:		0.263743
  validation accuracy:		93.48 %
Epoch 453 of 2000 took 0.057s
  training loss:		0.060999
  validation loss:		0.260760
  validation accuracy:		93.26 %
Epoch 454 of 2000 took 0.057s
  training loss:		0.060973
  validation loss:		0.263464
  validation accuracy:		93.04 %
Epoch 455 of 2000 took 0.057s
  training loss:		0.060586
  validation loss:		0.283307
  validation accuracy:		92.61 %
Epoch 456 of 2000 took 0.058s
  training loss:		0.061229
  validation loss:		0.276835
  validation accuracy:		92.72 %
Epoch 457 of 2000 took 0.058s
  training loss:		0.060006
  validation loss:		0.273340
  validation accuracy:		92.93 %
Epoch 458 of 2000 took 0.056s
  training loss:		0.061917
  validation loss:		0.276268
  validation accuracy:		92.83 %
Epoch 459 of 2000 took 0.057s
  training loss:		0.059602
  validation loss:		0.267696
  validation accuracy:		92.72 %
Epoch 460 of 2000 took 0.057s
  training loss:		0.059749
  validation loss:		0.271410
  validation accuracy:		92.93 %
Epoch 461 of 2000 took 0.056s
  training loss:		0.060355
  validation loss:		0.261349
  validation accuracy:		93.04 %
Epoch 462 of 2000 took 0.056s
  training loss:		0.059956
  validation loss:		0.279610
  validation accuracy:		92.61 %
Epoch 463 of 2000 took 0.057s
  training loss:		0.059290
  validation loss:		0.265933
  validation accuracy:		93.04 %
Epoch 464 of 2000 took 0.057s
  training loss:		0.058934
  validation loss:		0.265341
  validation accuracy:		93.48 %
Epoch 465 of 2000 took 0.056s
  training loss:		0.059533
  validation loss:		0.288711
  validation accuracy:		91.85 %
Epoch 466 of 2000 took 0.057s
  training loss:		0.057985
  validation loss:		0.263597
  validation accuracy:		92.93 %
Epoch 467 of 2000 took 0.055s
  training loss:		0.060236
  validation loss:		0.285808
  validation accuracy:		92.61 %
Epoch 468 of 2000 took 0.056s
  training loss:		0.058706
  validation loss:		0.269094
  validation accuracy:		92.93 %
Epoch 469 of 2000 took 0.056s
  training loss:		0.059519
  validation loss:		0.274366
  validation accuracy:		93.15 %
Epoch 470 of 2000 took 0.055s
  training loss:		0.057342
  validation loss:		0.276916
  validation accuracy:		92.72 %
Epoch 471 of 2000 took 0.056s
  training loss:		0.058219
  validation loss:		0.276053
  validation accuracy:		93.04 %
Epoch 472 of 2000 took 0.056s
  training loss:		0.061369
  validation loss:		0.269172
  validation accuracy:		93.26 %
Epoch 473 of 2000 took 0.056s
  training loss:		0.059012
  validation loss:		0.275767
  validation accuracy:		92.93 %
Epoch 474 of 2000 took 0.054s
  training loss:		0.057091
  validation loss:		0.291417
  validation accuracy:		92.50 %
Epoch 475 of 2000 took 0.057s
  training loss:		0.056840
  validation loss:		0.290066
  validation accuracy:		91.85 %
Epoch 476 of 2000 took 0.056s
  training loss:		0.058711
  validation loss:		0.284494
  validation accuracy:		92.39 %
Epoch 477 of 2000 took 0.055s
  training loss:		0.056480
  validation loss:		0.274701
  validation accuracy:		92.28 %
Epoch 478 of 2000 took 0.055s
  training loss:		0.057614
  validation loss:		0.262788
  validation accuracy:		93.48 %
Epoch 479 of 2000 took 0.056s
  training loss:		0.057707
  validation loss:		0.277169
  validation accuracy:		92.72 %
Epoch 480 of 2000 took 0.056s
  training loss:		0.057414
  validation loss:		0.280577
  validation accuracy:		93.04 %
Epoch 481 of 2000 took 0.056s
  training loss:		0.055391
  validation loss:		0.270701
  validation accuracy:		93.04 %
Epoch 482 of 2000 took 0.055s
  training loss:		0.054634
  validation loss:		0.284869
  validation accuracy:		92.39 %
Epoch 483 of 2000 took 0.057s
  training loss:		0.056728
  validation loss:		0.277827
  validation accuracy:		93.15 %
Epoch 484 of 2000 took 0.058s
  training loss:		0.056648
  validation loss:		0.276545
  validation accuracy:		93.04 %
Epoch 485 of 2000 took 0.058s
  training loss:		0.058036
  validation loss:		0.285484
  validation accuracy:		92.61 %
Epoch 486 of 2000 took 0.058s
  training loss:		0.055882
  validation loss:		0.271787
  validation accuracy:		92.83 %
Epoch 487 of 2000 took 0.058s
  training loss:		0.057674
  validation loss:		0.291958
  validation accuracy:		92.39 %
Epoch 488 of 2000 took 0.055s
  training loss:		0.054347
  validation loss:		0.263908
  validation accuracy:		93.48 %
Epoch 489 of 2000 took 0.057s
  training loss:		0.056870
  validation loss:		0.280086
  validation accuracy:		92.83 %
Epoch 490 of 2000 took 0.057s
  training loss:		0.055314
  validation loss:		0.288715
  validation accuracy:		92.72 %
Epoch 491 of 2000 took 0.057s
  training loss:		0.056434
  validation loss:		0.283048
  validation accuracy:		92.83 %
Epoch 492 of 2000 took 0.057s
  training loss:		0.056613
  validation loss:		0.298239
  validation accuracy:		91.96 %
Epoch 493 of 2000 took 0.057s
  training loss:		0.056620
  validation loss:		0.285494
  validation accuracy:		92.61 %
Epoch 494 of 2000 took 0.058s
  training loss:		0.054718
  validation loss:		0.295678
  validation accuracy:		92.07 %
Epoch 495 of 2000 took 0.058s
  training loss:		0.055973
  validation loss:		0.289841
  validation accuracy:		92.28 %
Epoch 496 of 2000 took 0.057s
  training loss:		0.053817
  validation loss:		0.299669
  validation accuracy:		92.50 %
Epoch 497 of 2000 took 0.057s
  training loss:		0.053767
  validation loss:		0.280329
  validation accuracy:		93.26 %
Epoch 498 of 2000 took 0.057s
  training loss:		0.052669
  validation loss:		0.287509
  validation accuracy:		92.61 %
Epoch 499 of 2000 took 0.057s
  training loss:		0.055915
  validation loss:		0.295114
  validation accuracy:		92.28 %
Epoch 500 of 2000 took 0.057s
  training loss:		0.055326
  validation loss:		0.296787
  validation accuracy:		92.07 %
Epoch 501 of 2000 took 0.057s
  training loss:		0.054245
  validation loss:		0.306088
  validation accuracy:		92.28 %
Epoch 502 of 2000 took 0.057s
  training loss:		0.052493
  validation loss:		0.285721
  validation accuracy:		93.15 %
Epoch 503 of 2000 took 0.057s
  training loss:		0.054152
  validation loss:		0.285028
  validation accuracy:		92.83 %
Epoch 504 of 2000 took 0.057s
  training loss:		0.051972
  validation loss:		0.287310
  validation accuracy:		92.72 %
Epoch 505 of 2000 took 0.058s
  training loss:		0.053549
  validation loss:		0.299375
  validation accuracy:		92.28 %
Epoch 506 of 2000 took 0.057s
  training loss:		0.053859
  validation loss:		0.285872
  validation accuracy:		92.61 %
Epoch 507 of 2000 took 0.057s
  training loss:		0.052998
  validation loss:		0.263644
  validation accuracy:		93.48 %
Epoch 508 of 2000 took 0.058s
  training loss:		0.055352
  validation loss:		0.293484
  validation accuracy:		92.61 %
Epoch 509 of 2000 took 0.057s
  training loss:		0.053575
  validation loss:		0.287440
  validation accuracy:		92.83 %
Epoch 510 of 2000 took 0.057s
  training loss:		0.052432
  validation loss:		0.296164
  validation accuracy:		92.83 %
Epoch 511 of 2000 took 0.057s
  training loss:		0.053174
  validation loss:		0.303308
  validation accuracy:		91.96 %
Epoch 512 of 2000 took 0.058s
  training loss:		0.053749
  validation loss:		0.293269
  validation accuracy:		92.39 %
Epoch 513 of 2000 took 0.057s
  training loss:		0.050637
  validation loss:		0.273083
  validation accuracy:		93.48 %
Epoch 514 of 2000 took 0.057s
  training loss:		0.052466
  validation loss:		0.279486
  validation accuracy:		93.15 %
Epoch 515 of 2000 took 0.057s
  training loss:		0.049167
  validation loss:		0.284818
  validation accuracy:		92.83 %
Epoch 516 of 2000 took 0.057s
  training loss:		0.051111
  validation loss:		0.281264
  validation accuracy:		93.15 %
Epoch 517 of 2000 took 0.055s
  training loss:		0.051868
  validation loss:		0.282925
  validation accuracy:		92.61 %
Epoch 518 of 2000 took 0.055s
  training loss:		0.052551
  validation loss:		0.287831
  validation accuracy:		92.83 %
Epoch 519 of 2000 took 0.055s
  training loss:		0.051345
  validation loss:		0.279611
  validation accuracy:		93.70 %
Epoch 520 of 2000 took 0.057s
  training loss:		0.050936
  validation loss:		0.280887
  validation accuracy:		93.15 %
Epoch 521 of 2000 took 0.056s
  training loss:		0.050136
  validation loss:		0.284852
  validation accuracy:		92.93 %
Epoch 522 of 2000 took 0.057s
  training loss:		0.047677
  validation loss:		0.290654
  validation accuracy:		92.61 %
Epoch 523 of 2000 took 0.056s
  training loss:		0.051672
  validation loss:		0.283980
  validation accuracy:		93.15 %
Epoch 524 of 2000 took 0.057s
  training loss:		0.051385
  validation loss:		0.274889
  validation accuracy:		93.70 %
Epoch 525 of 2000 took 0.056s
  training loss:		0.050293
  validation loss:		0.284896
  validation accuracy:		93.04 %
Epoch 526 of 2000 took 0.057s
  training loss:		0.050727
  validation loss:		0.292832
  validation accuracy:		92.61 %
Epoch 527 of 2000 took 0.057s
  training loss:		0.049624
  validation loss:		0.288472
  validation accuracy:		93.15 %
Epoch 528 of 2000 took 0.055s
  training loss:		0.049859
  validation loss:		0.286948
  validation accuracy:		93.26 %
Epoch 529 of 2000 took 0.055s
  training loss:		0.049682
  validation loss:		0.301814
  validation accuracy:		92.28 %
Epoch 530 of 2000 took 0.055s
  training loss:		0.052840
  validation loss:		0.287069
  validation accuracy:		93.15 %
Epoch 531 of 2000 took 0.055s
  training loss:		0.049800
  validation loss:		0.289111
  validation accuracy:		93.04 %
Epoch 532 of 2000 took 0.055s
  training loss:		0.049240
  validation loss:		0.296278
  validation accuracy:		92.83 %
Epoch 533 of 2000 took 0.055s
  training loss:		0.050334
  validation loss:		0.299504
  validation accuracy:		92.61 %
Epoch 534 of 2000 took 0.057s
  training loss:		0.049566
  validation loss:		0.299545
  validation accuracy:		92.17 %
Epoch 535 of 2000 took 0.054s
  training loss:		0.050890
  validation loss:		0.315944
  validation accuracy:		91.74 %
Epoch 536 of 2000 took 0.054s
  training loss:		0.049198
  validation loss:		0.280535
  validation accuracy:		93.04 %
Epoch 537 of 2000 took 0.054s
  training loss:		0.049588
  validation loss:		0.306009
  validation accuracy:		92.39 %
Epoch 538 of 2000 took 0.057s
  training loss:		0.048077
  validation loss:		0.289916
  validation accuracy:		92.93 %
Epoch 539 of 2000 took 0.054s
  training loss:		0.048733
  validation loss:		0.285624
  validation accuracy:		93.15 %
Epoch 540 of 2000 took 0.056s
  training loss:		0.046835
  validation loss:		0.296953
  validation accuracy:		93.04 %
Epoch 541 of 2000 took 0.054s
  training loss:		0.048294
  validation loss:		0.303354
  validation accuracy:		92.50 %
Epoch 542 of 2000 took 0.057s
  training loss:		0.048302
  validation loss:		0.285261
  validation accuracy:		93.37 %
Epoch 543 of 2000 took 0.058s
  training loss:		0.046766
  validation loss:		0.299807
  validation accuracy:		92.72 %
Epoch 544 of 2000 took 0.058s
  training loss:		0.046639
  validation loss:		0.298845
  validation accuracy:		92.93 %
Epoch 545 of 2000 took 0.057s
  training loss:		0.048084
  validation loss:		0.302072
  validation accuracy:		92.83 %
Epoch 546 of 2000 took 0.057s
  training loss:		0.048172
  validation loss:		0.300296
  validation accuracy:		92.39 %
Epoch 547 of 2000 took 0.054s
  training loss:		0.047557
  validation loss:		0.301046
  validation accuracy:		92.83 %
Epoch 548 of 2000 took 0.056s
  training loss:		0.044596
  validation loss:		0.301693
  validation accuracy:		92.93 %
Epoch 549 of 2000 took 0.057s
  training loss:		0.048287
  validation loss:		0.290114
  validation accuracy:		92.93 %
Epoch 550 of 2000 took 0.057s
  training loss:		0.048442
  validation loss:		0.296584
  validation accuracy:		92.93 %
Epoch 551 of 2000 took 0.057s
  training loss:		0.046528
  validation loss:		0.284710
  validation accuracy:		93.04 %
Epoch 552 of 2000 took 0.057s
  training loss:		0.047049
  validation loss:		0.289113
  validation accuracy:		93.04 %
Epoch 553 of 2000 took 0.057s
  training loss:		0.048556
  validation loss:		0.291565
  validation accuracy:		92.83 %
Epoch 554 of 2000 took 0.057s
  training loss:		0.046244
  validation loss:		0.305929
  validation accuracy:		92.61 %
Epoch 555 of 2000 took 0.057s
  training loss:		0.046966
  validation loss:		0.318327
  validation accuracy:		92.39 %
Epoch 556 of 2000 took 0.057s
  training loss:		0.045678
  validation loss:		0.302420
  validation accuracy:		92.61 %
Epoch 557 of 2000 took 0.057s
  training loss:		0.045950
  validation loss:		0.298389
  validation accuracy:		93.04 %
Epoch 558 of 2000 took 0.058s
  training loss:		0.044458
  validation loss:		0.309963
  validation accuracy:		92.50 %
Epoch 559 of 2000 took 0.057s
  training loss:		0.046089
  validation loss:		0.317631
  validation accuracy:		92.93 %
Epoch 560 of 2000 took 0.057s
  training loss:		0.044464
  validation loss:		0.296676
  validation accuracy:		93.04 %
Epoch 561 of 2000 took 0.057s
  training loss:		0.046764
  validation loss:		0.310313
  validation accuracy:		92.50 %
Epoch 562 of 2000 took 0.057s
  training loss:		0.047059
  validation loss:		0.314295
  validation accuracy:		92.17 %
Epoch 563 of 2000 took 0.057s
  training loss:		0.045454
  validation loss:		0.306571
  validation accuracy:		92.83 %
Epoch 564 of 2000 took 0.057s
  training loss:		0.046459
  validation loss:		0.305585
  validation accuracy:		92.72 %
Epoch 565 of 2000 took 0.057s
  training loss:		0.043957
  validation loss:		0.295657
  validation accuracy:		92.83 %
Epoch 566 of 2000 took 0.057s
  training loss:		0.045536
  validation loss:		0.307613
  validation accuracy:		92.50 %
Epoch 567 of 2000 took 0.057s
  training loss:		0.045222
  validation loss:		0.298783
  validation accuracy:		92.61 %
Epoch 568 of 2000 took 0.057s
  training loss:		0.044890
  validation loss:		0.307177
  validation accuracy:		93.04 %
Epoch 569 of 2000 took 0.057s
  training loss:		0.045572
  validation loss:		0.312319
  validation accuracy:		92.28 %
Epoch 570 of 2000 took 0.057s
  training loss:		0.044110
  validation loss:		0.321357
  validation accuracy:		92.28 %
Epoch 571 of 2000 took 0.057s
  training loss:		0.044835
  validation loss:		0.313286
  validation accuracy:		92.50 %
Epoch 572 of 2000 took 0.058s
  training loss:		0.044775
  validation loss:		0.317239
  validation accuracy:		92.28 %
Epoch 573 of 2000 took 0.057s
  training loss:		0.044170
  validation loss:		0.302043
  validation accuracy:		93.26 %
Epoch 574 of 2000 took 0.057s
  training loss:		0.042652
  validation loss:		0.312953
  validation accuracy:		92.83 %
Epoch 575 of 2000 took 0.056s
  training loss:		0.043851
  validation loss:		0.315565
  validation accuracy:		92.50 %
Epoch 576 of 2000 took 0.057s
  training loss:		0.044788
  validation loss:		0.303095
  validation accuracy:		92.83 %
Epoch 577 of 2000 took 0.055s
  training loss:		0.043138
  validation loss:		0.313268
  validation accuracy:		92.61 %
Epoch 578 of 2000 took 0.057s
  training loss:		0.043094
  validation loss:		0.311029
  validation accuracy:		92.72 %
Epoch 579 of 2000 took 0.057s
  training loss:		0.044304
  validation loss:		0.306264
  validation accuracy:		92.83 %
Epoch 580 of 2000 took 0.057s
  training loss:		0.043756
  validation loss:		0.303337
  validation accuracy:		93.04 %
Epoch 581 of 2000 took 0.057s
  training loss:		0.042996
  validation loss:		0.308752
  validation accuracy:		92.72 %
Epoch 582 of 2000 took 0.057s
  training loss:		0.044371
  validation loss:		0.303265
  validation accuracy:		93.04 %
Epoch 583 of 2000 took 0.057s
  training loss:		0.045490
  validation loss:		0.311416
  validation accuracy:		92.61 %
Epoch 584 of 2000 took 0.057s
  training loss:		0.043190
  validation loss:		0.315529
  validation accuracy:		92.50 %
Epoch 585 of 2000 took 0.057s
  training loss:		0.044713
  validation loss:		0.317727
  validation accuracy:		92.50 %
Epoch 586 of 2000 took 0.057s
  training loss:		0.044385
  validation loss:		0.324702
  validation accuracy:		92.93 %
Epoch 587 of 2000 took 0.057s
  training loss:		0.044683
  validation loss:		0.312176
  validation accuracy:		92.83 %
Epoch 588 of 2000 took 0.056s
  training loss:		0.043442
  validation loss:		0.309375
  validation accuracy:		92.61 %
Epoch 589 of 2000 took 0.057s
  training loss:		0.041609
  validation loss:		0.311803
  validation accuracy:		92.39 %
Epoch 590 of 2000 took 0.057s
  training loss:		0.040781
  validation loss:		0.306172
  validation accuracy:		92.72 %
Epoch 591 of 2000 took 0.057s
  training loss:		0.042546
  validation loss:		0.319816
  validation accuracy:		92.50 %
Epoch 592 of 2000 took 0.056s
  training loss:		0.042304
  validation loss:		0.317036
  validation accuracy:		92.72 %
Epoch 593 of 2000 took 0.057s
  training loss:		0.043208
  validation loss:		0.303219
  validation accuracy:		92.72 %
Epoch 594 of 2000 took 0.056s
  training loss:		0.042364
  validation loss:		0.314563
  validation accuracy:		92.50 %
Epoch 595 of 2000 took 0.057s
  training loss:		0.042629
  validation loss:		0.306738
  validation accuracy:		93.15 %
Epoch 596 of 2000 took 0.056s
  training loss:		0.044587
  validation loss:		0.303711
  validation accuracy:		92.93 %
Epoch 597 of 2000 took 0.057s
  training loss:		0.040686
  validation loss:		0.328195
  validation accuracy:		92.50 %
Epoch 598 of 2000 took 0.057s
  training loss:		0.044950
  validation loss:		0.314202
  validation accuracy:		92.61 %
Epoch 599 of 2000 took 0.057s
  training loss:		0.040836
  validation loss:		0.321489
  validation accuracy:		92.61 %
Epoch 600 of 2000 took 0.057s
  training loss:		0.042368
  validation loss:		0.310012
  validation accuracy:		93.04 %
Epoch 601 of 2000 took 0.056s
  training loss:		0.041604
  validation loss:		0.329529
  validation accuracy:		92.07 %
Epoch 602 of 2000 took 0.057s
  training loss:		0.043273
  validation loss:		0.319951
  validation accuracy:		92.72 %
Epoch 603 of 2000 took 0.058s
  training loss:		0.040121
  validation loss:		0.321338
  validation accuracy:		92.28 %
Epoch 604 of 2000 took 0.058s
  training loss:		0.041605
  validation loss:		0.314413
  validation accuracy:		92.93 %
Epoch 605 of 2000 took 0.057s
  training loss:		0.041774
  validation loss:		0.319651
  validation accuracy:		92.39 %
Epoch 606 of 2000 took 0.060s
  training loss:		0.041356
  validation loss:		0.326392
  validation accuracy:		92.72 %
Epoch 607 of 2000 took 0.056s
  training loss:		0.040899
  validation loss:		0.316716
  validation accuracy:		92.50 %
Epoch 608 of 2000 took 0.055s
  training loss:		0.038720
  validation loss:		0.316796
  validation accuracy:		92.61 %
Epoch 609 of 2000 took 0.056s
  training loss:		0.042047
  validation loss:		0.311129
  validation accuracy:		93.04 %
Epoch 610 of 2000 took 0.057s
  training loss:		0.039684
  validation loss:		0.319414
  validation accuracy:		92.61 %
Epoch 611 of 2000 took 0.056s
  training loss:		0.040025
  validation loss:		0.319058
  validation accuracy:		92.93 %
Epoch 612 of 2000 took 0.056s
  training loss:		0.039900
  validation loss:		0.313317
  validation accuracy:		92.83 %
Epoch 613 of 2000 took 0.055s
  training loss:		0.040175
  validation loss:		0.312127
  validation accuracy:		92.72 %
Epoch 614 of 2000 took 0.057s
  training loss:		0.037824
  validation loss:		0.323407
  validation accuracy:		92.93 %
Epoch 615 of 2000 took 0.058s
  training loss:		0.040563
  validation loss:		0.306017
  validation accuracy:		93.04 %
Epoch 616 of 2000 took 0.058s
  training loss:		0.036857
  validation loss:		0.317373
  validation accuracy:		93.04 %
Epoch 617 of 2000 took 0.059s
  training loss:		0.039191
  validation loss:		0.328823
  validation accuracy:		92.39 %
Epoch 618 of 2000 took 0.059s
  training loss:		0.038708
  validation loss:		0.327977
  validation accuracy:		92.39 %
Epoch 619 of 2000 took 0.059s
  training loss:		0.039353
  validation loss:		0.314218
  validation accuracy:		93.15 %
Epoch 620 of 2000 took 0.058s
  training loss:		0.039525
  validation loss:		0.319148
  validation accuracy:		93.04 %
Epoch 621 of 2000 took 0.059s
  training loss:		0.038753
  validation loss:		0.306408
  validation accuracy:		93.04 %
Epoch 622 of 2000 took 0.058s
  training loss:		0.039342
  validation loss:		0.334944
  validation accuracy:		92.28 %
Epoch 623 of 2000 took 0.059s
  training loss:		0.040091
  validation loss:		0.315804
  validation accuracy:		92.93 %
Epoch 624 of 2000 took 0.059s
  training loss:		0.040049
  validation loss:		0.331048
  validation accuracy:		92.72 %
Epoch 625 of 2000 took 0.059s
  training loss:		0.037931
  validation loss:		0.318822
  validation accuracy:		92.83 %
Epoch 626 of 2000 took 0.059s
  training loss:		0.037821
  validation loss:		0.331407
  validation accuracy:		92.61 %
Epoch 627 of 2000 took 0.059s
  training loss:		0.039485
  validation loss:		0.332700
  validation accuracy:		92.28 %
Epoch 628 of 2000 took 0.059s
  training loss:		0.039020
  validation loss:		0.329776
  validation accuracy:		92.50 %
Epoch 629 of 2000 took 0.058s
  training loss:		0.038040
  validation loss:		0.340379
  validation accuracy:		92.61 %
Epoch 630 of 2000 took 0.058s
  training loss:		0.039477
  validation loss:		0.318150
  validation accuracy:		92.93 %
Epoch 631 of 2000 took 0.057s
  training loss:		0.039788
  validation loss:		0.322881
  validation accuracy:		92.50 %
Epoch 632 of 2000 took 0.055s
  training loss:		0.038217
  validation loss:		0.330369
  validation accuracy:		92.83 %
Epoch 633 of 2000 took 0.057s
  training loss:		0.037992
  validation loss:		0.318087
  validation accuracy:		93.04 %
Epoch 634 of 2000 took 0.056s
  training loss:		0.037429
  validation loss:		0.327242
  validation accuracy:		92.17 %
Epoch 635 of 2000 took 0.057s
  training loss:		0.037288
  validation loss:		0.322355
  validation accuracy:		93.04 %
Epoch 636 of 2000 took 0.057s
  training loss:		0.037560
  validation loss:		0.331106
  validation accuracy:		92.72 %
Epoch 637 of 2000 took 0.057s
  training loss:		0.039043
  validation loss:		0.336424
  validation accuracy:		92.50 %
Epoch 638 of 2000 took 0.056s
  training loss:		0.036755
  validation loss:		0.330014
  validation accuracy:		92.72 %
Epoch 639 of 2000 took 0.058s
  training loss:		0.038498
  validation loss:		0.314629
  validation accuracy:		93.04 %
Epoch 640 of 2000 took 0.057s
  training loss:		0.037050
  validation loss:		0.318555
  validation accuracy:		92.83 %
Epoch 641 of 2000 took 0.057s
  training loss:		0.036933
  validation loss:		0.328650
  validation accuracy:		92.39 %
Epoch 642 of 2000 took 0.057s
  training loss:		0.035661
  validation loss:		0.328568
  validation accuracy:		92.39 %
Epoch 643 of 2000 took 0.057s
  training loss:		0.038740
  validation loss:		0.336837
  validation accuracy:		92.39 %
Epoch 644 of 2000 took 0.057s
  training loss:		0.038041
  validation loss:		0.328545
  validation accuracy:		92.61 %
Epoch 645 of 2000 took 0.057s
  training loss:		0.037221
  validation loss:		0.343746
  validation accuracy:		92.61 %
Epoch 646 of 2000 took 0.057s
  training loss:		0.036196
  validation loss:		0.352943
  validation accuracy:		92.17 %
Epoch 647 of 2000 took 0.057s
  training loss:		0.036358
  validation loss:		0.337616
  validation accuracy:		92.83 %
Epoch 648 of 2000 took 0.057s
  training loss:		0.037474
  validation loss:		0.332953
  validation accuracy:		92.17 %
Epoch 649 of 2000 took 0.058s
  training loss:		0.036913
  validation loss:		0.347228
  validation accuracy:		92.39 %
Epoch 650 of 2000 took 0.057s
  training loss:		0.035250
  validation loss:		0.344991
  validation accuracy:		91.96 %
Epoch 651 of 2000 took 0.057s
  training loss:		0.038303
  validation loss:		0.343876
  validation accuracy:		92.39 %
Epoch 652 of 2000 took 0.058s
  training loss:		0.036284
  validation loss:		0.348774
  validation accuracy:		92.83 %
Epoch 653 of 2000 took 0.058s
  training loss:		0.036588
  validation loss:		0.334556
  validation accuracy:		92.72 %
Epoch 654 of 2000 took 0.054s
  training loss:		0.036771
  validation loss:		0.334368
  validation accuracy:		92.28 %
Epoch 655 of 2000 took 0.058s
  training loss:		0.035266
  validation loss:		0.335217
  validation accuracy:		92.61 %
Epoch 656 of 2000 took 0.057s
  training loss:		0.036983
  validation loss:		0.339484
  validation accuracy:		92.61 %
Epoch 657 of 2000 took 0.057s
  training loss:		0.036607
  validation loss:		0.327510
  validation accuracy:		92.83 %
Epoch 658 of 2000 took 0.057s
  training loss:		0.035474
  validation loss:		0.319774
  validation accuracy:		92.93 %
Epoch 659 of 2000 took 0.057s
  training loss:		0.034524
  validation loss:		0.343040
  validation accuracy:		92.17 %
Epoch 660 of 2000 took 0.057s
  training loss:		0.035340
  validation loss:		0.321346
  validation accuracy:		92.93 %
Epoch 661 of 2000 took 0.057s
  training loss:		0.034612
  validation loss:		0.347615
  validation accuracy:		92.39 %
Epoch 662 of 2000 took 0.057s
  training loss:		0.035435
  validation loss:		0.335773
  validation accuracy:		92.61 %
Epoch 663 of 2000 took 0.058s
  training loss:		0.036158
  validation loss:		0.340969
  validation accuracy:		92.07 %
Epoch 664 of 2000 took 0.057s
  training loss:		0.035599
  validation loss:		0.348651
  validation accuracy:		92.61 %
Epoch 665 of 2000 took 0.057s
  training loss:		0.034916
  validation loss:		0.330141
  validation accuracy:		92.72 %
Epoch 666 of 2000 took 0.058s
  training loss:		0.035831
  validation loss:		0.348466
  validation accuracy:		92.28 %
Epoch 667 of 2000 took 0.057s
  training loss:		0.034574
  validation loss:		0.327734
  validation accuracy:		92.39 %
Epoch 668 of 2000 took 0.057s
  training loss:		0.034597
  validation loss:		0.334623
  validation accuracy:		92.72 %
Epoch 669 of 2000 took 0.057s
  training loss:		0.034521
  validation loss:		0.336028
  validation accuracy:		92.28 %
Epoch 670 of 2000 took 0.057s
  training loss:		0.033934
  validation loss:		0.326580
  validation accuracy:		93.04 %
Epoch 671 of 2000 took 0.057s
  training loss:		0.033492
  validation loss:		0.340603
  validation accuracy:		92.50 %
Epoch 672 of 2000 took 0.057s
  training loss:		0.034303
  validation loss:		0.356803
  validation accuracy:		91.74 %
Epoch 673 of 2000 took 0.057s
  training loss:		0.035134
  validation loss:		0.342266
  validation accuracy:		92.28 %
Epoch 674 of 2000 took 0.057s
  training loss:		0.034282
  validation loss:		0.347425
  validation accuracy:		92.39 %
Epoch 675 of 2000 took 0.057s
  training loss:		0.034198
  validation loss:		0.349359
  validation accuracy:		92.28 %
Epoch 676 of 2000 took 0.057s
  training loss:		0.035045
  validation loss:		0.341346
  validation accuracy:		92.39 %
Epoch 677 of 2000 took 0.058s
  training loss:		0.034671
  validation loss:		0.343059
  validation accuracy:		92.61 %
Epoch 678 of 2000 took 0.057s
  training loss:		0.034916
  validation loss:		0.368251
  validation accuracy:		92.07 %
Epoch 679 of 2000 took 0.057s
  training loss:		0.033248
  validation loss:		0.346180
  validation accuracy:		92.17 %
Epoch 680 of 2000 took 0.058s
  training loss:		0.034105
  validation loss:		0.343641
  validation accuracy:		92.50 %
Epoch 681 of 2000 took 0.057s
  training loss:		0.034514
  validation loss:		0.346874
  validation accuracy:		92.50 %
Epoch 682 of 2000 took 0.057s
  training loss:		0.032867
  validation loss:		0.353162
  validation accuracy:		91.96 %
Epoch 683 of 2000 took 0.057s
  training loss:		0.030925
  validation loss:		0.349436
  validation accuracy:		92.07 %
Epoch 684 of 2000 took 0.058s
  training loss:		0.034205
  validation loss:		0.342312
  validation accuracy:		92.50 %
Epoch 685 of 2000 took 0.058s
  training loss:		0.034113
  validation loss:		0.341706
  validation accuracy:		92.39 %
Epoch 686 of 2000 took 0.058s
  training loss:		0.032745
  validation loss:		0.341258
  validation accuracy:		92.72 %
Epoch 687 of 2000 took 0.058s
  training loss:		0.034151
  validation loss:		0.353828
  validation accuracy:		92.28 %
Epoch 688 of 2000 took 0.058s
  training loss:		0.031456
  validation loss:		0.336119
  validation accuracy:		92.61 %
Epoch 689 of 2000 took 0.058s
  training loss:		0.033387
  validation loss:		0.339350
  validation accuracy:		92.83 %
Epoch 690 of 2000 took 0.058s
  training loss:		0.033295
  validation loss:		0.344160
  validation accuracy:		92.50 %
Epoch 691 of 2000 took 0.057s
  training loss:		0.033395
  validation loss:		0.362369
  validation accuracy:		92.50 %
Epoch 692 of 2000 took 0.058s
  training loss:		0.033438
  validation loss:		0.344421
  validation accuracy:		92.50 %
Epoch 693 of 2000 took 0.057s
  training loss:		0.033070
  validation loss:		0.345327
  validation accuracy:		92.39 %
Epoch 694 of 2000 took 0.057s
  training loss:		0.033236
  validation loss:		0.351574
  validation accuracy:		92.28 %
Epoch 695 of 2000 took 0.057s
  training loss:		0.031750
  validation loss:		0.349972
  validation accuracy:		92.39 %
Epoch 696 of 2000 took 0.057s
  training loss:		0.032217
  validation loss:		0.339634
  validation accuracy:		92.93 %
Epoch 697 of 2000 took 0.057s
  training loss:		0.031240
  validation loss:		0.346939
  validation accuracy:		92.72 %
Epoch 698 of 2000 took 0.057s
  training loss:		0.031784
  validation loss:		0.350968
  validation accuracy:		92.50 %
Epoch 699 of 2000 took 0.057s
  training loss:		0.031768
  validation loss:		0.360138
  validation accuracy:		92.17 %
Epoch 700 of 2000 took 0.058s
  training loss:		0.032658
  validation loss:		0.353037
  validation accuracy:		92.50 %
Epoch 701 of 2000 took 0.057s
  training loss:		0.032342
  validation loss:		0.343228
  validation accuracy:		92.72 %
Epoch 702 of 2000 took 0.058s
  training loss:		0.030725
  validation loss:		0.354188
  validation accuracy:		92.50 %
Epoch 703 of 2000 took 0.058s
  training loss:		0.031287
  validation loss:		0.351194
  validation accuracy:		91.85 %
Epoch 704 of 2000 took 0.058s
  training loss:		0.031008
  validation loss:		0.364657
  validation accuracy:		92.50 %
Epoch 705 of 2000 took 0.058s
  training loss:		0.030742
  validation loss:		0.374143
  validation accuracy:		91.74 %
Epoch 706 of 2000 took 0.058s
  training loss:		0.030534
  validation loss:		0.362892
  validation accuracy:		92.28 %
Epoch 707 of 2000 took 0.058s
  training loss:		0.032630
  validation loss:		0.372152
  validation accuracy:		92.07 %
Epoch 708 of 2000 took 0.058s
  training loss:		0.031332
  validation loss:		0.349921
  validation accuracy:		92.61 %
Epoch 709 of 2000 took 0.058s
  training loss:		0.029383
  validation loss:		0.349263
  validation accuracy:		92.61 %
Epoch 710 of 2000 took 0.058s
  training loss:		0.030113
  validation loss:		0.337170
  validation accuracy:		93.04 %
Epoch 711 of 2000 took 0.058s
  training loss:		0.032689
  validation loss:		0.357576
  validation accuracy:		92.50 %
Epoch 712 of 2000 took 0.058s
  training loss:		0.030992
  validation loss:		0.359353
  validation accuracy:		92.83 %
Epoch 713 of 2000 took 0.058s
  training loss:		0.031465
  validation loss:		0.360338
  validation accuracy:		92.39 %
Epoch 714 of 2000 took 0.058s
  training loss:		0.031326
  validation loss:		0.344155
  validation accuracy:		92.72 %
Epoch 715 of 2000 took 0.058s
  training loss:		0.030608
  validation loss:		0.363232
  validation accuracy:		92.61 %
Epoch 716 of 2000 took 0.057s
  training loss:		0.030479
  validation loss:		0.362206
  validation accuracy:		92.83 %
Epoch 717 of 2000 took 0.057s
  training loss:		0.032437
  validation loss:		0.358669
  validation accuracy:		92.50 %
Epoch 718 of 2000 took 0.058s
  training loss:		0.029434
  validation loss:		0.356416
  validation accuracy:		92.50 %
Epoch 719 of 2000 took 0.058s
  training loss:		0.028410
  validation loss:		0.349814
  validation accuracy:		93.04 %
Epoch 720 of 2000 took 0.058s
  training loss:		0.031368
  validation loss:		0.366949
  validation accuracy:		92.39 %
Epoch 721 of 2000 took 0.058s
  training loss:		0.030420
  validation loss:		0.362274
  validation accuracy:		92.61 %
Epoch 722 of 2000 took 0.058s
  training loss:		0.028937
  validation loss:		0.348921
  validation accuracy:		92.61 %
Epoch 723 of 2000 took 0.058s
  training loss:		0.030261
  validation loss:		0.345473
  validation accuracy:		92.93 %
Epoch 724 of 2000 took 0.058s
  training loss:		0.030216
  validation loss:		0.357513
  validation accuracy:		92.28 %
Epoch 725 of 2000 took 0.058s
  training loss:		0.029458
  validation loss:		0.351416
  validation accuracy:		92.83 %
Epoch 726 of 2000 took 0.058s
  training loss:		0.029194
  validation loss:		0.355470
  validation accuracy:		92.83 %
Epoch 727 of 2000 took 0.057s
  training loss:		0.029744
  validation loss:		0.346112
  validation accuracy:		92.72 %
Epoch 728 of 2000 took 0.057s
  training loss:		0.030346
  validation loss:		0.342934
  validation accuracy:		92.83 %
Epoch 729 of 2000 took 0.057s
  training loss:		0.030299
  validation loss:		0.364909
  validation accuracy:		92.28 %
Epoch 730 of 2000 took 0.057s
  training loss:		0.028514
  validation loss:		0.359578
  validation accuracy:		92.61 %
Epoch 731 of 2000 took 0.057s
  training loss:		0.029955
  validation loss:		0.373362
  validation accuracy:		92.61 %
Epoch 732 of 2000 took 0.057s
  training loss:		0.028978
  validation loss:		0.352942
  validation accuracy:		92.61 %
Epoch 733 of 2000 took 0.058s
  training loss:		0.028484
  validation loss:		0.351273
  validation accuracy:		92.61 %
Epoch 734 of 2000 took 0.057s
  training loss:		0.029498
  validation loss:		0.364227
  validation accuracy:		92.61 %
Epoch 735 of 2000 took 0.057s
  training loss:		0.028878
  validation loss:		0.360313
  validation accuracy:		92.72 %
Epoch 736 of 2000 took 0.057s
  training loss:		0.029610
  validation loss:		0.354801
  validation accuracy:		92.72 %
Epoch 737 of 2000 took 0.058s
  training loss:		0.029091
  validation loss:		0.357547
  validation accuracy:		92.50 %
Epoch 738 of 2000 took 0.057s
  training loss:		0.028465
  validation loss:		0.357562
  validation accuracy:		92.72 %
Epoch 739 of 2000 took 0.058s
  training loss:		0.028557
  validation loss:		0.365114
  validation accuracy:		92.50 %
Epoch 740 of 2000 took 0.057s
  training loss:		0.029021
  validation loss:		0.362075
  validation accuracy:		92.39 %
Epoch 741 of 2000 took 0.057s
  training loss:		0.026985
  validation loss:		0.360953
  validation accuracy:		92.50 %
Epoch 742 of 2000 took 0.057s
  training loss:		0.029887
  validation loss:		0.351898
  validation accuracy:		92.72 %
Epoch 743 of 2000 took 0.057s
  training loss:		0.029659
  validation loss:		0.376619
  validation accuracy:		92.50 %
Epoch 744 of 2000 took 0.057s
  training loss:		0.027082
  validation loss:		0.354475
  validation accuracy:		92.83 %
Epoch 745 of 2000 took 0.057s
  training loss:		0.027087
  validation loss:		0.371395
  validation accuracy:		92.17 %
Epoch 746 of 2000 took 0.057s
  training loss:		0.028309
  validation loss:		0.350961
  validation accuracy:		92.93 %
Epoch 747 of 2000 took 0.057s
  training loss:		0.028106
  validation loss:		0.366906
  validation accuracy:		92.50 %
Epoch 748 of 2000 took 0.057s
  training loss:		0.028355
  validation loss:		0.364038
  validation accuracy:		92.61 %
Epoch 749 of 2000 took 0.057s
  training loss:		0.028001
  validation loss:		0.383150
  validation accuracy:		92.28 %
Epoch 750 of 2000 took 0.057s
  training loss:		0.028262
  validation loss:		0.359431
  validation accuracy:		92.72 %
Epoch 751 of 2000 took 0.057s
  training loss:		0.028541
  validation loss:		0.380004
  validation accuracy:		92.39 %
Epoch 752 of 2000 took 0.057s
  training loss:		0.027525
  validation loss:		0.374089
  validation accuracy:		92.50 %
Epoch 753 of 2000 took 0.057s
  training loss:		0.027304
  validation loss:		0.379977
  validation accuracy:		92.50 %
Epoch 754 of 2000 took 0.058s
  training loss:		0.027956
  validation loss:		0.352216
  validation accuracy:		92.83 %
Epoch 755 of 2000 took 0.057s
  training loss:		0.026946
  validation loss:		0.377991
  validation accuracy:		92.28 %
Epoch 756 of 2000 took 0.057s
  training loss:		0.027190
  validation loss:		0.371993
  validation accuracy:		92.61 %
Epoch 757 of 2000 took 0.058s
  training loss:		0.029084
  validation loss:		0.366793
  validation accuracy:		92.72 %
Epoch 758 of 2000 took 0.057s
  training loss:		0.027168
  validation loss:		0.383825
  validation accuracy:		92.72 %
Epoch 759 of 2000 took 0.057s
  training loss:		0.027959
  validation loss:		0.357367
  validation accuracy:		92.72 %
Epoch 760 of 2000 took 0.057s
  training loss:		0.028819
  validation loss:		0.368983
  validation accuracy:		92.28 %
Epoch 761 of 2000 took 0.055s
  training loss:		0.027890
  validation loss:		0.387911
  validation accuracy:		92.39 %
Epoch 762 of 2000 took 0.054s
  training loss:		0.027622
  validation loss:		0.373647
  validation accuracy:		92.61 %
Epoch 763 of 2000 took 0.057s
  training loss:		0.025952
  validation loss:		0.391847
  validation accuracy:		91.96 %
Epoch 764 of 2000 took 0.057s
  training loss:		0.027009
  validation loss:		0.384466
  validation accuracy:		92.28 %
Epoch 765 of 2000 took 0.057s
  training loss:		0.026019
  validation loss:		0.365846
  validation accuracy:		92.61 %
Epoch 766 of 2000 took 0.056s
  training loss:		0.026926
  validation loss:		0.357132
  validation accuracy:		92.83 %
Epoch 767 of 2000 took 0.057s
  training loss:		0.027902
  validation loss:		0.384263
  validation accuracy:		92.50 %
Epoch 768 of 2000 took 0.056s
  training loss:		0.024222
  validation loss:		0.369719
  validation accuracy:		92.39 %
Epoch 769 of 2000 took 0.055s
  training loss:		0.026562
  validation loss:		0.369815
  validation accuracy:		92.72 %
Epoch 770 of 2000 took 0.057s
  training loss:		0.027194
  validation loss:		0.391465
  validation accuracy:		92.39 %
Epoch 771 of 2000 took 0.057s
  training loss:		0.027367
  validation loss:		0.377396
  validation accuracy:		92.50 %
Epoch 772 of 2000 took 0.057s
  training loss:		0.026966
  validation loss:		0.371078
  validation accuracy:		92.50 %
Epoch 773 of 2000 took 0.057s
  training loss:		0.025449
  validation loss:		0.373316
  validation accuracy:		92.61 %
Epoch 774 of 2000 took 0.057s
  training loss:		0.026568
  validation loss:		0.364609
  validation accuracy:		93.04 %
Epoch 775 of 2000 took 0.057s
  training loss:		0.025944
  validation loss:		0.373304
  validation accuracy:		92.50 %
Epoch 776 of 2000 took 0.057s
  training loss:		0.026681
  validation loss:		0.364014
  validation accuracy:		92.50 %
Epoch 777 of 2000 took 0.055s
  training loss:		0.026720
  validation loss:		0.378736
  validation accuracy:		92.83 %
Epoch 778 of 2000 took 0.056s
  training loss:		0.025459
  validation loss:		0.389762
  validation accuracy:		92.61 %
Epoch 779 of 2000 took 0.057s
  training loss:		0.025949
  validation loss:		0.369585
  validation accuracy:		92.93 %
Epoch 780 of 2000 took 0.055s
  training loss:		0.025945
  validation loss:		0.374156
  validation accuracy:		92.72 %
Epoch 781 of 2000 took 0.056s
  training loss:		0.024535
  validation loss:		0.373523
  validation accuracy:		92.72 %
Epoch 782 of 2000 took 0.055s
  training loss:		0.025613
  validation loss:		0.380668
  validation accuracy:		92.61 %
Epoch 783 of 2000 took 0.054s
  training loss:		0.025207
  validation loss:		0.378730
  validation accuracy:		92.72 %
Epoch 784 of 2000 took 0.055s
  training loss:		0.025159
  validation loss:		0.390845
  validation accuracy:		92.17 %
Epoch 785 of 2000 took 0.054s
  training loss:		0.025299
  validation loss:		0.375231
  validation accuracy:		92.61 %
Epoch 786 of 2000 took 0.056s
  training loss:		0.026397
  validation loss:		0.383477
  validation accuracy:		92.39 %
Epoch 787 of 2000 took 0.054s
  training loss:		0.025997
  validation loss:		0.398415
  validation accuracy:		91.96 %
Epoch 788 of 2000 took 0.054s
  training loss:		0.025661
  validation loss:		0.383021
  validation accuracy:		92.39 %
Epoch 789 of 2000 took 0.055s
  training loss:		0.024335
  validation loss:		0.389254
  validation accuracy:		92.39 %
Epoch 790 of 2000 took 0.056s
  training loss:		0.024430
  validation loss:		0.389730
  validation accuracy:		92.50 %
Epoch 791 of 2000 took 0.055s
  training loss:		0.024482
  validation loss:		0.379805
  validation accuracy:		93.04 %
Epoch 792 of 2000 took 0.055s
  training loss:		0.024410
  validation loss:		0.384483
  validation accuracy:		92.39 %
Epoch 793 of 2000 took 0.054s
  training loss:		0.025700
  validation loss:		0.373704
  validation accuracy:		92.39 %
Epoch 794 of 2000 took 0.056s
  training loss:		0.024713
  validation loss:		0.376027
  validation accuracy:		92.39 %
Epoch 795 of 2000 took 0.055s
  training loss:		0.024214
  validation loss:		0.372725
  validation accuracy:		92.50 %
Epoch 796 of 2000 took 0.056s
  training loss:		0.025237
  validation loss:		0.373217
  validation accuracy:		92.28 %
Epoch 797 of 2000 took 0.057s
  training loss:		0.026383
  validation loss:		0.382368
  validation accuracy:		92.61 %
Epoch 798 of 2000 took 0.057s
  training loss:		0.025623
  validation loss:		0.385958
  validation accuracy:		92.72 %
Epoch 799 of 2000 took 0.057s
  training loss:		0.024600
  validation loss:		0.393111
  validation accuracy:		92.28 %
Epoch 800 of 2000 took 0.057s
  training loss:		0.024619
  validation loss:		0.389030
  validation accuracy:		92.61 %
Epoch 801 of 2000 took 0.057s
  training loss:		0.024134
  validation loss:		0.377431
  validation accuracy:		92.61 %
Epoch 802 of 2000 took 0.057s
  training loss:		0.023836
  validation loss:		0.397408
  validation accuracy:		92.61 %
Epoch 803 of 2000 took 0.057s
  training loss:		0.023364
  validation loss:		0.375014
  validation accuracy:		92.83 %
Epoch 804 of 2000 took 0.057s
  training loss:		0.024832
  validation loss:		0.392252
  validation accuracy:		92.39 %
Epoch 805 of 2000 took 0.057s
  training loss:		0.023964
  validation loss:		0.398578
  validation accuracy:		91.85 %
Epoch 806 of 2000 took 0.057s
  training loss:		0.024528
  validation loss:		0.389881
  validation accuracy:		92.28 %
Epoch 807 of 2000 took 0.058s
  training loss:		0.023785
  validation loss:		0.391071
  validation accuracy:		92.61 %
Epoch 808 of 2000 took 0.058s
  training loss:		0.023676
  validation loss:		0.380184
  validation accuracy:		92.72 %
Epoch 809 of 2000 took 0.058s
  training loss:		0.023636
  validation loss:		0.392911
  validation accuracy:		92.28 %
Epoch 810 of 2000 took 0.055s
  training loss:		0.023051
  validation loss:		0.407398
  validation accuracy:		92.07 %
Epoch 811 of 2000 took 0.056s
  training loss:		0.024101
  validation loss:		0.387688
  validation accuracy:		92.61 %
Epoch 812 of 2000 took 0.056s
  training loss:		0.022194
  validation loss:		0.400597
  validation accuracy:		92.17 %
Epoch 813 of 2000 took 0.057s
  training loss:		0.023841
  validation loss:		0.393445
  validation accuracy:		92.72 %
Epoch 814 of 2000 took 0.057s
  training loss:		0.022901
  validation loss:		0.406229
  validation accuracy:		91.96 %
Epoch 815 of 2000 took 0.057s
  training loss:		0.023205
  validation loss:		0.411236
  validation accuracy:		92.39 %
Epoch 816 of 2000 took 0.057s
  training loss:		0.023594
  validation loss:		0.392180
  validation accuracy:		92.07 %
Epoch 817 of 2000 took 0.057s
  training loss:		0.024647
  validation loss:		0.392206
  validation accuracy:		92.72 %
Epoch 818 of 2000 took 0.057s
  training loss:		0.022882
  validation loss:		0.385710
  validation accuracy:		92.72 %
Epoch 819 of 2000 took 0.057s
  training loss:		0.023444
  validation loss:		0.378618
  validation accuracy:		92.83 %
Epoch 820 of 2000 took 0.058s
  training loss:		0.023318
  validation loss:		0.394981
  validation accuracy:		92.61 %
Epoch 821 of 2000 took 0.057s
  training loss:		0.022886
  validation loss:		0.394580
  validation accuracy:		92.50 %
Epoch 822 of 2000 took 0.057s
  training loss:		0.022878
  validation loss:		0.391738
  validation accuracy:		92.61 %
Epoch 823 of 2000 took 0.057s
  training loss:		0.022986
  validation loss:		0.386978
  validation accuracy:		92.61 %
Epoch 824 of 2000 took 0.057s
  training loss:		0.022425
  validation loss:		0.385281
  validation accuracy:		92.61 %
Epoch 825 of 2000 took 0.057s
  training loss:		0.023614
  validation loss:		0.400275
  validation accuracy:		92.50 %
Epoch 826 of 2000 took 0.057s
  training loss:		0.022902
  validation loss:		0.383365
  validation accuracy:		92.72 %
Epoch 827 of 2000 took 0.057s
  training loss:		0.022358
  validation loss:		0.388955
  validation accuracy:		92.72 %
Epoch 828 of 2000 took 0.057s
  training loss:		0.023342
  validation loss:		0.385241
  validation accuracy:		92.61 %
Epoch 829 of 2000 took 0.057s
  training loss:		0.021753
  validation loss:		0.390358
  validation accuracy:		92.50 %
Epoch 830 of 2000 took 0.056s
  training loss:		0.023303
  validation loss:		0.392346
  validation accuracy:		92.72 %
Epoch 831 of 2000 took 0.057s
  training loss:		0.022318
  validation loss:		0.405369
  validation accuracy:		92.50 %
Epoch 832 of 2000 took 0.057s
  training loss:		0.023120
  validation loss:		0.392718
  validation accuracy:		92.50 %
Epoch 833 of 2000 took 0.057s
  training loss:		0.022400
  validation loss:		0.392437
  validation accuracy:		92.72 %
Epoch 834 of 2000 took 0.057s
  training loss:		0.021983
  validation loss:		0.398895
  validation accuracy:		92.61 %
Epoch 835 of 2000 took 0.057s
  training loss:		0.021833
  validation loss:		0.397410
  validation accuracy:		92.39 %
Epoch 836 of 2000 took 0.057s
  training loss:		0.021934
  validation loss:		0.397265
  validation accuracy:		92.50 %
Epoch 837 of 2000 took 0.057s
  training loss:		0.022126
  validation loss:		0.387551
  validation accuracy:		92.72 %
Epoch 838 of 2000 took 0.057s
  training loss:		0.021853
  validation loss:		0.399495
  validation accuracy:		92.50 %
Epoch 839 of 2000 took 0.057s
  training loss:		0.021537
  validation loss:		0.410945
  validation accuracy:		92.61 %
Epoch 840 of 2000 took 0.057s
  training loss:		0.022894
  validation loss:		0.388942
  validation accuracy:		92.61 %
Epoch 841 of 2000 took 0.057s
  training loss:		0.020197
  validation loss:		0.394568
  validation accuracy:		92.72 %
Epoch 842 of 2000 took 0.056s
  training loss:		0.021964
  validation loss:		0.400029
  validation accuracy:		92.61 %
Epoch 843 of 2000 took 0.055s
  training loss:		0.022713
  validation loss:		0.393447
  validation accuracy:		92.72 %
Epoch 844 of 2000 took 0.056s
  training loss:		0.022640
  validation loss:		0.392601
  validation accuracy:		92.72 %
Epoch 845 of 2000 took 0.056s
  training loss:		0.021715
  validation loss:		0.399159
  validation accuracy:		92.39 %
Epoch 846 of 2000 took 0.055s
  training loss:		0.020798
  validation loss:		0.411314
  validation accuracy:		92.61 %
Epoch 847 of 2000 took 0.056s
  training loss:		0.022010
  validation loss:		0.388324
  validation accuracy:		92.50 %
Epoch 848 of 2000 took 0.057s
  training loss:		0.021528
  validation loss:		0.386508
  validation accuracy:		92.61 %
Epoch 849 of 2000 took 0.056s
  training loss:		0.022304
  validation loss:		0.388326
  validation accuracy:		92.72 %
Epoch 850 of 2000 took 0.056s
  training loss:		0.020435
  validation loss:		0.404563
  validation accuracy:		92.28 %
Epoch 851 of 2000 took 0.056s
  training loss:		0.021715
  validation loss:		0.397826
  validation accuracy:		92.61 %
Epoch 852 of 2000 took 0.056s
  training loss:		0.021520
  validation loss:		0.396112
  validation accuracy:		92.72 %
Epoch 853 of 2000 took 0.053s
  training loss:		0.021450
  validation loss:		0.395207
  validation accuracy:		92.50 %
Epoch 854 of 2000 took 0.057s
  training loss:		0.021904
  validation loss:		0.402119
  validation accuracy:		92.50 %
Epoch 855 of 2000 took 0.054s
  training loss:		0.020613
  validation loss:		0.399376
  validation accuracy:		92.61 %
Epoch 856 of 2000 took 0.055s
  training loss:		0.021071
  validation loss:		0.418639
  validation accuracy:		91.85 %
Epoch 857 of 2000 took 0.057s
  training loss:		0.021316
  validation loss:		0.385505
  validation accuracy:		92.72 %
Epoch 858 of 2000 took 0.057s
  training loss:		0.020448
  validation loss:		0.395532
  validation accuracy:		92.50 %
Epoch 859 of 2000 took 0.054s
  training loss:		0.020221
  validation loss:		0.412806
  validation accuracy:		92.17 %
Epoch 860 of 2000 took 0.056s
  training loss:		0.020682
  validation loss:		0.396315
  validation accuracy:		92.83 %
Epoch 861 of 2000 took 0.055s
  training loss:		0.021299
  validation loss:		0.407379
  validation accuracy:		92.83 %
Epoch 862 of 2000 took 0.056s
  training loss:		0.020200
  validation loss:		0.391742
  validation accuracy:		92.72 %
Epoch 863 of 2000 took 0.060s
  training loss:		0.020268
  validation loss:		0.403314
  validation accuracy:		92.72 %
Epoch 864 of 2000 took 0.055s
  training loss:		0.020459
  validation loss:		0.405717
  validation accuracy:		92.72 %
Epoch 865 of 2000 took 0.055s
  training loss:		0.020399
  validation loss:		0.393472
  validation accuracy:		92.50 %
Epoch 866 of 2000 took 0.057s
  training loss:		0.021176
  validation loss:		0.405631
  validation accuracy:		92.72 %
Epoch 867 of 2000 took 0.057s
  training loss:		0.021613
  validation loss:		0.408921
  validation accuracy:		92.50 %
Epoch 868 of 2000 took 0.059s
  training loss:		0.019177
  validation loss:		0.391032
  validation accuracy:		92.72 %
Epoch 869 of 2000 took 0.059s
  training loss:		0.020621
  validation loss:		0.404371
  validation accuracy:		92.61 %
Epoch 870 of 2000 took 0.054s
  training loss:		0.020891
  validation loss:		0.408039
  validation accuracy:		92.72 %
Epoch 871 of 2000 took 0.056s
  training loss:		0.020797
  validation loss:		0.405359
  validation accuracy:		92.50 %
Epoch 872 of 2000 took 0.055s
  training loss:		0.019033
  validation loss:		0.400304
  validation accuracy:		92.50 %
Epoch 873 of 2000 took 0.056s
  training loss:		0.019999
  validation loss:		0.416972
  validation accuracy:		92.61 %
Epoch 874 of 2000 took 0.056s
  training loss:		0.020256
  validation loss:		0.423736
  validation accuracy:		92.50 %
Epoch 875 of 2000 took 0.059s
  training loss:		0.020481
  validation loss:		0.407631
  validation accuracy:		92.61 %
Epoch 876 of 2000 took 0.058s
  training loss:		0.019574
  validation loss:		0.418030
  validation accuracy:		92.50 %
Epoch 877 of 2000 took 0.058s
  training loss:		0.019835
  validation loss:		0.412336
  validation accuracy:		92.39 %
Epoch 878 of 2000 took 0.057s
  training loss:		0.019299
  validation loss:		0.418546
  validation accuracy:		92.39 %
Epoch 879 of 2000 took 0.057s
  training loss:		0.019885
  validation loss:		0.430744
  validation accuracy:		92.50 %
Epoch 880 of 2000 took 0.057s
  training loss:		0.019418
  validation loss:		0.418593
  validation accuracy:		92.39 %
Epoch 881 of 2000 took 0.057s
  training loss:		0.019419
  validation loss:		0.407047
  validation accuracy:		92.17 %
Epoch 882 of 2000 took 0.057s
  training loss:		0.020023
  validation loss:		0.403365
  validation accuracy:		92.61 %
Epoch 883 of 2000 took 0.057s
  training loss:		0.019907
  validation loss:		0.414985
  validation accuracy:		92.39 %
Epoch 884 of 2000 took 0.057s
  training loss:		0.019309
  validation loss:		0.421669
  validation accuracy:		92.39 %
Epoch 885 of 2000 took 0.056s
  training loss:		0.019278
  validation loss:		0.407721
  validation accuracy:		92.83 %
Epoch 886 of 2000 took 0.057s
  training loss:		0.019880
  validation loss:		0.409830
  validation accuracy:		92.72 %
Epoch 887 of 2000 took 0.058s
  training loss:		0.019685
  validation loss:		0.406786
  validation accuracy:		92.72 %
Epoch 888 of 2000 took 0.057s
  training loss:		0.019970
  validation loss:		0.407459
  validation accuracy:		92.61 %
Epoch 889 of 2000 took 0.057s
  training loss:		0.018937
  validation loss:		0.427927
  validation accuracy:		92.50 %
Epoch 890 of 2000 took 0.056s
  training loss:		0.019792
  validation loss:		0.404876
  validation accuracy:		92.50 %
Epoch 891 of 2000 took 0.057s
  training loss:		0.019388
  validation loss:		0.423720
  validation accuracy:		92.50 %
Epoch 892 of 2000 took 0.057s
  training loss:		0.018911
  validation loss:		0.419319
  validation accuracy:		92.50 %
Epoch 893 of 2000 took 0.056s
  training loss:		0.019830
  validation loss:		0.413249
  validation accuracy:		92.72 %
Epoch 894 of 2000 took 0.056s
  training loss:		0.019622
  validation loss:		0.423523
  validation accuracy:		92.50 %
Epoch 895 of 2000 took 0.057s
  training loss:		0.019084
  validation loss:		0.404643
  validation accuracy:		92.50 %
Epoch 896 of 2000 took 0.057s
  training loss:		0.018822
  validation loss:		0.415285
  validation accuracy:		92.72 %
Epoch 897 of 2000 took 0.057s
  training loss:		0.018931
  validation loss:		0.413758
  validation accuracy:		92.39 %
Epoch 898 of 2000 took 0.056s
  training loss:		0.018893
  validation loss:		0.417174
  validation accuracy:		92.72 %
Epoch 899 of 2000 took 0.057s
  training loss:		0.019111
  validation loss:		0.415123
  validation accuracy:		92.39 %
Epoch 900 of 2000 took 0.057s
  training loss:		0.019028
  validation loss:		0.413622
  validation accuracy:		92.50 %
Epoch 901 of 2000 took 0.057s
  training loss:		0.018270
  validation loss:		0.419332
  validation accuracy:		92.39 %
Epoch 902 of 2000 took 0.056s
  training loss:		0.019081
  validation loss:		0.419973
  validation accuracy:		92.72 %
Epoch 903 of 2000 took 0.057s
  training loss:		0.018374
  validation loss:		0.425863
  validation accuracy:		92.50 %
Epoch 904 of 2000 took 0.057s
  training loss:		0.018668
  validation loss:		0.408481
  validation accuracy:		92.72 %
Epoch 905 of 2000 took 0.056s
  training loss:		0.018125
  validation loss:		0.415687
  validation accuracy:		92.61 %
Epoch 906 of 2000 took 0.056s
  training loss:		0.018199
  validation loss:		0.405788
  validation accuracy:		92.72 %
Epoch 907 of 2000 took 0.057s
  training loss:		0.019450
  validation loss:		0.416643
  validation accuracy:		92.61 %
Epoch 908 of 2000 took 0.057s
  training loss:		0.018125
  validation loss:		0.419554
  validation accuracy:		92.39 %
Epoch 909 of 2000 took 0.057s
  training loss:		0.018999
  validation loss:		0.410070
  validation accuracy:		92.72 %
Epoch 910 of 2000 took 0.056s
  training loss:		0.018564
  validation loss:		0.435607
  validation accuracy:		92.28 %
Epoch 911 of 2000 took 0.057s
  training loss:		0.019254
  validation loss:		0.421846
  validation accuracy:		92.61 %
Epoch 912 of 2000 took 0.055s
  training loss:		0.018940
  validation loss:		0.419451
  validation accuracy:		92.39 %
Epoch 913 of 2000 took 0.055s
  training loss:		0.018331
  validation loss:		0.414195
  validation accuracy:		92.61 %
Epoch 914 of 2000 took 0.056s
  training loss:		0.018395
  validation loss:		0.419738
  validation accuracy:		92.39 %
Epoch 915 of 2000 took 0.055s
  training loss:		0.018157
  validation loss:		0.423152
  validation accuracy:		92.93 %
Epoch 916 of 2000 took 0.056s
  training loss:		0.018023
  validation loss:		0.420386
  validation accuracy:		92.50 %
Epoch 917 of 2000 took 0.056s
  training loss:		0.018860
  validation loss:		0.419758
  validation accuracy:		92.61 %
Epoch 918 of 2000 took 0.058s
  training loss:		0.018584
  validation loss:		0.425536
  validation accuracy:		92.61 %
Epoch 919 of 2000 took 0.057s
  training loss:		0.018740
  validation loss:		0.431298
  validation accuracy:		92.83 %
Epoch 920 of 2000 took 0.057s
  training loss:		0.017914
  validation loss:		0.411515
  validation accuracy:		92.61 %
Epoch 921 of 2000 took 0.053s
  training loss:		0.017850
  validation loss:		0.430670
  validation accuracy:		92.61 %
Epoch 922 of 2000 took 0.057s
  training loss:		0.018043
  validation loss:		0.424420
  validation accuracy:		92.61 %
Epoch 923 of 2000 took 0.055s
  training loss:		0.017940
  validation loss:		0.415025
  validation accuracy:		92.83 %
Epoch 924 of 2000 took 0.056s
  training loss:		0.017872
  validation loss:		0.425216
  validation accuracy:		92.39 %
Epoch 925 of 2000 took 0.057s
  training loss:		0.017314
  validation loss:		0.418388
  validation accuracy:		92.83 %
Epoch 926 of 2000 took 0.054s
  training loss:		0.017663
  validation loss:		0.419693
  validation accuracy:		92.83 %
Epoch 927 of 2000 took 0.056s
  training loss:		0.018171
  validation loss:		0.435429
  validation accuracy:		92.61 %
Epoch 928 of 2000 took 0.054s
  training loss:		0.017586
  validation loss:		0.431776
  validation accuracy:		92.61 %
Epoch 929 of 2000 took 0.056s
  training loss:		0.017063
  validation loss:		0.432085
  validation accuracy:		92.50 %
Epoch 930 of 2000 took 0.058s
  training loss:		0.017116
  validation loss:		0.422254
  validation accuracy:		92.61 %
Epoch 931 of 2000 took 0.058s
  training loss:		0.017130
  validation loss:		0.418403
  validation accuracy:		92.83 %
Epoch 932 of 2000 took 0.057s
  training loss:		0.017310
  validation loss:		0.436090
  validation accuracy:		92.50 %
Epoch 933 of 2000 took 0.054s
  training loss:		0.017287
  validation loss:		0.425080
  validation accuracy:		92.61 %
Epoch 934 of 2000 took 0.056s
  training loss:		0.016981
  validation loss:		0.428056
  validation accuracy:		92.72 %
Epoch 935 of 2000 took 0.057s
  training loss:		0.017404
  validation loss:		0.424381
  validation accuracy:		92.61 %
Epoch 936 of 2000 took 0.057s
  training loss:		0.017937
  validation loss:		0.435148
  validation accuracy:		92.28 %
Epoch 937 of 2000 took 0.057s
  training loss:		0.017344
  validation loss:		0.431979
  validation accuracy:		92.17 %
Epoch 938 of 2000 took 0.057s
  training loss:		0.018226
  validation loss:		0.437810
  validation accuracy:		92.39 %
Epoch 939 of 2000 took 0.057s
  training loss:		0.016677
  validation loss:		0.441454
  validation accuracy:		92.50 %
Epoch 940 of 2000 took 0.057s
  training loss:		0.016615
  validation loss:		0.415252
  validation accuracy:		92.50 %
Epoch 941 of 2000 took 0.055s
  training loss:		0.017103
  validation loss:		0.440898
  validation accuracy:		92.61 %
Epoch 942 of 2000 took 0.054s
  training loss:		0.017914
  validation loss:		0.436950
  validation accuracy:		92.28 %
Epoch 943 of 2000 took 0.056s
  training loss:		0.016184
  validation loss:		0.434495
  validation accuracy:		92.72 %
Epoch 944 of 2000 took 0.057s
  training loss:		0.016643
  validation loss:		0.430001
  validation accuracy:		92.61 %
Epoch 945 of 2000 took 0.057s
  training loss:		0.017113
  validation loss:		0.412074
  validation accuracy:		92.83 %
Epoch 946 of 2000 took 0.057s
  training loss:		0.016727
  validation loss:		0.439489
  validation accuracy:		92.61 %
Epoch 947 of 2000 took 0.056s
  training loss:		0.017039
  validation loss:		0.440441
  validation accuracy:		92.61 %
Epoch 948 of 2000 took 0.057s
  training loss:		0.016719
  validation loss:		0.428707
  validation accuracy:		92.28 %
Epoch 949 of 2000 took 0.057s
  training loss:		0.016522
  validation loss:		0.422197
  validation accuracy:		92.72 %
Epoch 950 of 2000 took 0.057s
  training loss:		0.016015
  validation loss:		0.423254
  validation accuracy:		92.61 %
Epoch 951 of 2000 took 0.057s
  training loss:		0.016804
  validation loss:		0.443422
  validation accuracy:		92.28 %
Epoch 952 of 2000 took 0.057s
  training loss:		0.016455
  validation loss:		0.438564
  validation accuracy:		92.72 %
Epoch 953 of 2000 took 0.057s
  training loss:		0.016123
  validation loss:		0.424385
  validation accuracy:		92.50 %
Epoch 954 of 2000 took 0.057s
  training loss:		0.016258
  validation loss:		0.440612
  validation accuracy:		92.28 %
Epoch 955 of 2000 took 0.057s
  training loss:		0.016505
  validation loss:		0.446107
  validation accuracy:		92.39 %
Epoch 956 of 2000 took 0.056s
  training loss:		0.016223
  validation loss:		0.423295
  validation accuracy:		92.72 %
Epoch 957 of 2000 took 0.057s
  training loss:		0.017008
  validation loss:		0.442052
  validation accuracy:		92.17 %
Epoch 958 of 2000 took 0.057s
  training loss:		0.016717
  validation loss:		0.438706
  validation accuracy:		92.50 %
Epoch 959 of 2000 took 0.057s
  training loss:		0.016134
  validation loss:		0.432053
  validation accuracy:		92.50 %
Epoch 960 of 2000 took 0.057s
  training loss:		0.016480
  validation loss:		0.454456
  validation accuracy:		92.17 %
Epoch 961 of 2000 took 0.057s
  training loss:		0.016483
  validation loss:		0.432676
  validation accuracy:		92.83 %
Epoch 962 of 2000 took 0.057s
  training loss:		0.015443
  validation loss:		0.456405
  validation accuracy:		92.17 %
Epoch 963 of 2000 took 0.057s
  training loss:		0.016012
  validation loss:		0.438361
  validation accuracy:		92.61 %
Epoch 964 of 2000 took 0.057s
  training loss:		0.016249
  validation loss:		0.449905
  validation accuracy:		92.17 %
Epoch 965 of 2000 took 0.055s
  training loss:		0.016081
  validation loss:		0.445424
  validation accuracy:		92.50 %
Epoch 966 of 2000 took 0.056s
  training loss:		0.015912
  validation loss:		0.449461
  validation accuracy:		92.50 %
Epoch 967 of 2000 took 0.056s
  training loss:		0.015651
  validation loss:		0.437742
  validation accuracy:		92.72 %
Epoch 968 of 2000 took 0.056s
  training loss:		0.016322
  validation loss:		0.454510
  validation accuracy:		92.50 %
Epoch 969 of 2000 took 0.055s
  training loss:		0.016055
  validation loss:		0.430888
  validation accuracy:		92.61 %
Epoch 970 of 2000 took 0.056s
  training loss:		0.015760
  validation loss:		0.430634
  validation accuracy:		92.72 %
Epoch 971 of 2000 took 0.055s
  training loss:		0.014976
  validation loss:		0.435808
  validation accuracy:		92.72 %
Epoch 972 of 2000 took 0.053s
  training loss:		0.015651
  validation loss:		0.427742
  validation accuracy:		92.72 %
Epoch 973 of 2000 took 0.055s
  training loss:		0.016492
  validation loss:		0.436377
  validation accuracy:		92.72 %
Epoch 974 of 2000 took 0.054s
  training loss:		0.015664
  validation loss:		0.445611
  validation accuracy:		92.50 %
Epoch 975 of 2000 took 0.056s
  training loss:		0.016101
  validation loss:		0.441569
  validation accuracy:		92.61 %
Epoch 976 of 2000 took 0.054s
  training loss:		0.015234
  validation loss:		0.441941
  validation accuracy:		92.61 %
Epoch 977 of 2000 took 0.055s
  training loss:		0.015422
  validation loss:		0.443020
  validation accuracy:		92.61 %
Epoch 978 of 2000 took 0.056s
  training loss:		0.015520
  validation loss:		0.451774
  validation accuracy:		92.50 %
Epoch 979 of 2000 took 0.054s
  training loss:		0.014828
  validation loss:		0.436147
  validation accuracy:		92.72 %
Epoch 980 of 2000 took 0.056s
  training loss:		0.015098
  validation loss:		0.439306
  validation accuracy:		92.83 %
Epoch 981 of 2000 took 0.055s
  training loss:		0.015909
  validation loss:		0.446524
  validation accuracy:		92.61 %
Epoch 982 of 2000 took 0.056s
  training loss:		0.015287
  validation loss:		0.441318
  validation accuracy:		92.50 %
Epoch 983 of 2000 took 0.057s
  training loss:		0.015244
  validation loss:		0.446504
  validation accuracy:		92.72 %
Epoch 984 of 2000 took 0.054s
  training loss:		0.015094
  validation loss:		0.440830
  validation accuracy:		92.50 %
Epoch 985 of 2000 took 0.055s
  training loss:		0.015321
  validation loss:		0.446414
  validation accuracy:		92.50 %
Epoch 986 of 2000 took 0.056s
  training loss:		0.015124
  validation loss:		0.440495
  validation accuracy:		92.83 %
Epoch 987 of 2000 took 0.055s
  training loss:		0.014349
  validation loss:		0.443163
  validation accuracy:		92.83 %
Epoch 988 of 2000 took 0.057s
  training loss:		0.014967
  validation loss:		0.449257
  validation accuracy:		92.72 %
Epoch 989 of 2000 took 0.079s
  training loss:		0.014974
  validation loss:		0.446043
  validation accuracy:		92.39 %
Epoch 990 of 2000 took 0.068s
  training loss:		0.015437
  validation loss:		0.448697
  validation accuracy:		92.72 %
Epoch 991 of 2000 took 0.064s
  training loss:		0.014721
  validation loss:		0.443354
  validation accuracy:		92.83 %
Epoch 992 of 2000 took 0.065s
  training loss:		0.015353
  validation loss:		0.447539
  validation accuracy:		92.72 %
Epoch 993 of 2000 took 0.064s
  training loss:		0.014924
  validation loss:		0.431466
  validation accuracy:		92.72 %
Epoch 994 of 2000 took 0.062s
  training loss:		0.015402
  validation loss:		0.452794
  validation accuracy:		92.61 %
Epoch 995 of 2000 took 0.064s
  training loss:		0.015226
  validation loss:		0.434738
  validation accuracy:		92.72 %
Epoch 996 of 2000 took 0.064s
  training loss:		0.014850
  validation loss:		0.436346
  validation accuracy:		92.72 %
Epoch 997 of 2000 took 0.063s
  training loss:		0.014728
  validation loss:		0.458688
  validation accuracy:		92.50 %
Epoch 998 of 2000 took 0.064s
  training loss:		0.015087
  validation loss:		0.462412
  validation accuracy:		92.39 %
Epoch 999 of 2000 took 0.064s
  training loss:		0.014905
  validation loss:		0.455290
  validation accuracy:		92.72 %
Epoch 1000 of 2000 took 0.063s
  training loss:		0.014896
  validation loss:		0.447270
  validation accuracy:		92.83 %
Epoch 1001 of 2000 took 0.059s
  training loss:		0.014605
  validation loss:		0.455115
  validation accuracy:		92.39 %
Epoch 1002 of 2000 took 0.059s
  training loss:		0.014694
  validation loss:		0.453089
  validation accuracy:		92.61 %
Epoch 1003 of 2000 took 0.059s
  training loss:		0.014668
  validation loss:		0.448179
  validation accuracy:		92.93 %
Epoch 1004 of 2000 took 0.059s
  training loss:		0.014913
  validation loss:		0.462659
  validation accuracy:		92.50 %
Epoch 1005 of 2000 took 0.059s
  training loss:		0.014147
  validation loss:		0.450890
  validation accuracy:		92.72 %
Epoch 1006 of 2000 took 0.059s
  training loss:		0.014181
  validation loss:		0.452072
  validation accuracy:		92.83 %
Epoch 1007 of 2000 took 0.059s
  training loss:		0.013491
  validation loss:		0.451430
  validation accuracy:		92.72 %
Epoch 1008 of 2000 took 0.059s
  training loss:		0.013869
  validation loss:		0.435624
  validation accuracy:		92.83 %
Epoch 1009 of 2000 took 0.059s
  training loss:		0.014191
  validation loss:		0.446051
  validation accuracy:		92.61 %
Epoch 1010 of 2000 took 0.059s
  training loss:		0.014376
  validation loss:		0.437563
  validation accuracy:		92.50 %
Epoch 1011 of 2000 took 0.058s
  training loss:		0.015308
  validation loss:		0.457333
  validation accuracy:		92.61 %
Epoch 1012 of 2000 took 0.059s
  training loss:		0.014251
  validation loss:		0.461611
  validation accuracy:		92.50 %
Epoch 1013 of 2000 took 0.059s
  training loss:		0.014115
  validation loss:		0.471620
  validation accuracy:		92.50 %
Epoch 1014 of 2000 took 0.059s
  training loss:		0.014538
  validation loss:		0.457280
  validation accuracy:		92.72 %
Epoch 1015 of 2000 took 0.059s
  training loss:		0.013914
  validation loss:		0.447698
  validation accuracy:		92.72 %
Epoch 1016 of 2000 took 0.059s
  training loss:		0.014515
  validation loss:		0.443877
  validation accuracy:		92.50 %
Epoch 1017 of 2000 took 0.059s
  training loss:		0.014425
  validation loss:		0.446517
  validation accuracy:		92.83 %
Epoch 1018 of 2000 took 0.059s
  training loss:		0.013736
  validation loss:		0.454737
  validation accuracy:		92.83 %
Epoch 1019 of 2000 took 0.059s
  training loss:		0.014542
  validation loss:		0.454567
  validation accuracy:		92.39 %
Epoch 1020 of 2000 took 0.059s
  training loss:		0.014655
  validation loss:		0.454064
  validation accuracy:		92.39 %
Epoch 1021 of 2000 took 0.059s
  training loss:		0.013974
  validation loss:		0.452013
  validation accuracy:		92.72 %
Epoch 1022 of 2000 took 0.059s
  training loss:		0.013750
  validation loss:		0.453477
  validation accuracy:		92.61 %
Epoch 1023 of 2000 took 0.059s
  training loss:		0.014413
  validation loss:		0.460923
  validation accuracy:		92.39 %
Epoch 1024 of 2000 took 0.059s
  training loss:		0.013766
  validation loss:		0.456685
  validation accuracy:		92.39 %
Epoch 1025 of 2000 took 0.059s
  training loss:		0.013997
  validation loss:		0.460248
  validation accuracy:		92.50 %
Epoch 1026 of 2000 took 0.059s
  training loss:		0.013631
  validation loss:		0.454992
  validation accuracy:		92.61 %
Epoch 1027 of 2000 took 0.059s
  training loss:		0.013593
  validation loss:		0.465464
  validation accuracy:		92.83 %
Epoch 1028 of 2000 took 0.059s
  training loss:		0.013917
  validation loss:		0.446642
  validation accuracy:		92.72 %
Epoch 1029 of 2000 took 0.059s
  training loss:		0.013699
  validation loss:		0.450063
  validation accuracy:		92.83 %
Epoch 1030 of 2000 took 0.059s
  training loss:		0.013884
  validation loss:		0.449787
  validation accuracy:		92.83 %
Epoch 1031 of 2000 took 0.059s
  training loss:		0.013078
  validation loss:		0.453465
  validation accuracy:		92.39 %
Epoch 1032 of 2000 took 0.059s
  training loss:		0.013788
  validation loss:		0.471825
  validation accuracy:		92.28 %
Epoch 1033 of 2000 took 0.059s
  training loss:		0.013590
  validation loss:		0.457906
  validation accuracy:		92.93 %
Epoch 1034 of 2000 took 0.059s
  training loss:		0.013507
  validation loss:		0.455110
  validation accuracy:		92.93 %
Epoch 1035 of 2000 took 0.060s
  training loss:		0.013794
  validation loss:		0.453896
  validation accuracy:		92.72 %
Epoch 1036 of 2000 took 0.059s
  training loss:		0.014147
  validation loss:		0.455373
  validation accuracy:		92.72 %
Epoch 1037 of 2000 took 0.060s
  training loss:		0.013659
  validation loss:		0.468516
  validation accuracy:		92.39 %
Epoch 1038 of 2000 took 0.059s
  training loss:		0.013526
  validation loss:		0.459105
  validation accuracy:		92.39 %
Epoch 1039 of 2000 took 0.059s
  training loss:		0.014272
  validation loss:		0.449289
  validation accuracy:		92.61 %
Epoch 1040 of 2000 took 0.059s
  training loss:		0.013547
  validation loss:		0.464317
  validation accuracy:		92.83 %
Epoch 1041 of 2000 took 0.059s
  training loss:		0.013932
  validation loss:		0.457260
  validation accuracy:		92.83 %
Epoch 1042 of 2000 took 0.059s
  training loss:		0.013471
  validation loss:		0.472570
  validation accuracy:		92.72 %
Epoch 1043 of 2000 took 0.059s
  training loss:		0.013062
  validation loss:		0.458757
  validation accuracy:		92.83 %
Epoch 1044 of 2000 took 0.059s
  training loss:		0.013419
  validation loss:		0.454730
  validation accuracy:		92.61 %
Epoch 1045 of 2000 took 0.059s
  training loss:		0.013417
  validation loss:		0.470191
  validation accuracy:		92.39 %
Epoch 1046 of 2000 took 0.059s
  training loss:		0.013053
  validation loss:		0.451578
  validation accuracy:		92.50 %
Epoch 1047 of 2000 took 0.059s
  training loss:		0.013221
  validation loss:		0.462702
  validation accuracy:		92.83 %
Epoch 1048 of 2000 took 0.059s
  training loss:		0.013503
  validation loss:		0.461118
  validation accuracy:		92.93 %
Epoch 1049 of 2000 took 0.059s
  training loss:		0.013195
  validation loss:		0.468390
  validation accuracy:		92.39 %
Epoch 1050 of 2000 took 0.059s
  training loss:		0.013462
  validation loss:		0.460855
  validation accuracy:		92.83 %
Epoch 1051 of 2000 took 0.059s
  training loss:		0.012793
  validation loss:		0.469119
  validation accuracy:		92.83 %
Epoch 1052 of 2000 took 0.059s
  training loss:		0.012902
  validation loss:		0.470500
  validation accuracy:		92.72 %
Epoch 1053 of 2000 took 0.059s
  training loss:		0.012791
  validation loss:		0.461312
  validation accuracy:		92.61 %
Epoch 1054 of 2000 took 0.059s
  training loss:		0.012664
  validation loss:		0.458612
  validation accuracy:		92.72 %
Epoch 1055 of 2000 took 0.059s
  training loss:		0.011867
  validation loss:		0.469716
  validation accuracy:		92.50 %
Epoch 1056 of 2000 took 0.058s
  training loss:		0.012530
  validation loss:		0.461187
  validation accuracy:		92.50 %
Epoch 1057 of 2000 took 0.059s
  training loss:		0.012813
  validation loss:		0.471509
  validation accuracy:		92.61 %
Epoch 1058 of 2000 took 0.059s
  training loss:		0.013476
  validation loss:		0.470106
  validation accuracy:		92.61 %
Epoch 1059 of 2000 took 0.059s
  training loss:		0.012967
  validation loss:		0.456716
  validation accuracy:		92.72 %
Epoch 1060 of 2000 took 0.059s
  training loss:		0.012306
  validation loss:		0.461454
  validation accuracy:		92.72 %
Epoch 1061 of 2000 took 0.058s
  training loss:		0.012421
  validation loss:		0.465747
  validation accuracy:		92.50 %
Epoch 1062 of 2000 took 0.058s
  training loss:		0.012718
  validation loss:		0.464935
  validation accuracy:		92.72 %
Epoch 1063 of 2000 took 0.059s
  training loss:		0.012675
  validation loss:		0.459712
  validation accuracy:		92.72 %
Epoch 1064 of 2000 took 0.059s
  training loss:		0.012871
  validation loss:		0.469850
  validation accuracy:		92.72 %
Epoch 1065 of 2000 took 0.059s
  training loss:		0.012329
  validation loss:		0.460236
  validation accuracy:		92.83 %
Epoch 1066 of 2000 took 0.059s
  training loss:		0.012843
  validation loss:		0.475948
  validation accuracy:		92.50 %
Epoch 1067 of 2000 took 0.058s
  training loss:		0.012800
  validation loss:		0.466559
  validation accuracy:		92.83 %
Epoch 1068 of 2000 took 0.058s
  training loss:		0.012527
  validation loss:		0.465151
  validation accuracy:		92.72 %
Epoch 1069 of 2000 took 0.059s
  training loss:		0.012812
  validation loss:		0.470188
  validation accuracy:		92.93 %
Epoch 1070 of 2000 took 0.059s
  training loss:		0.012419
  validation loss:		0.470768
  validation accuracy:		92.61 %
Epoch 1071 of 2000 took 0.059s
  training loss:		0.012904
  validation loss:		0.469452
  validation accuracy:		92.72 %
Epoch 1072 of 2000 took 0.059s
  training loss:		0.012970
  validation loss:		0.469318
  validation accuracy:		92.50 %
Epoch 1073 of 2000 took 0.059s
  training loss:		0.012381
  validation loss:		0.462933
  validation accuracy:		92.61 %
Epoch 1074 of 2000 took 0.059s
  training loss:		0.012367
  validation loss:		0.459998
  validation accuracy:		92.39 %
Epoch 1075 of 2000 took 0.059s
  training loss:		0.012550
  validation loss:		0.473094
  validation accuracy:		92.61 %
Epoch 1076 of 2000 took 0.058s
  training loss:		0.012255
  validation loss:		0.477381
  validation accuracy:		92.50 %
Epoch 1077 of 2000 took 0.059s
  training loss:		0.012332
  validation loss:		0.473343
  validation accuracy:		92.50 %
Epoch 1078 of 2000 took 0.059s
  training loss:		0.012344
  validation loss:		0.472937
  validation accuracy:		92.72 %
Epoch 1079 of 2000 took 0.059s
  training loss:		0.012197
  validation loss:		0.472913
  validation accuracy:		92.50 %
Epoch 1080 of 2000 took 0.059s
  training loss:		0.012383
  validation loss:		0.480988
  validation accuracy:		92.39 %
Epoch 1081 of 2000 took 0.059s
  training loss:		0.012672
  validation loss:		0.478366
  validation accuracy:		92.61 %
Epoch 1082 of 2000 took 0.059s
  training loss:		0.012736
  validation loss:		0.478962
  validation accuracy:		92.61 %
Epoch 1083 of 2000 took 0.059s
  training loss:		0.011923
  validation loss:		0.466266
  validation accuracy:		92.61 %
Epoch 1084 of 2000 took 0.058s
  training loss:		0.012467
  validation loss:		0.483678
  validation accuracy:		92.39 %
Epoch 1085 of 2000 took 0.058s
  training loss:		0.011551
  validation loss:		0.467400
  validation accuracy:		92.61 %
Epoch 1086 of 2000 took 0.059s
  training loss:		0.012266
  validation loss:		0.471429
  validation accuracy:		92.28 %
Epoch 1087 of 2000 took 0.059s
  training loss:		0.012367
  validation loss:		0.470431
  validation accuracy:		92.72 %
Epoch 1088 of 2000 took 0.059s
  training loss:		0.012233
  validation loss:		0.483636
  validation accuracy:		92.61 %
Epoch 1089 of 2000 took 0.058s
  training loss:		0.012036
  validation loss:		0.470979
  validation accuracy:		92.93 %
Epoch 1090 of 2000 took 0.059s
  training loss:		0.012557
  validation loss:		0.477087
  validation accuracy:		92.72 %
Epoch 1091 of 2000 took 0.059s
  training loss:		0.012274
  validation loss:		0.472741
  validation accuracy:		92.83 %
Epoch 1092 of 2000 took 0.058s
  training loss:		0.011495
  validation loss:		0.470490
  validation accuracy:		92.50 %
Epoch 1093 of 2000 took 0.058s
  training loss:		0.012193
  validation loss:		0.473626
  validation accuracy:		92.72 %
Epoch 1094 of 2000 took 0.058s
  training loss:		0.012507
  validation loss:		0.475116
  validation accuracy:		92.83 %
Epoch 1095 of 2000 took 0.059s
  training loss:		0.012235
  validation loss:		0.481745
  validation accuracy:		92.83 %
Epoch 1096 of 2000 took 0.059s
  training loss:		0.011317
  validation loss:		0.473790
  validation accuracy:		92.72 %
Epoch 1097 of 2000 took 0.059s
  training loss:		0.011470
  validation loss:		0.479417
  validation accuracy:		92.72 %
Epoch 1098 of 2000 took 0.059s
  training loss:		0.011405
  validation loss:		0.479201
  validation accuracy:		92.72 %
Epoch 1099 of 2000 took 0.059s
  training loss:		0.011149
  validation loss:		0.471876
  validation accuracy:		92.72 %
Epoch 1100 of 2000 took 0.059s
  training loss:		0.011639
  validation loss:		0.470363
  validation accuracy:		92.83 %
Epoch 1101 of 2000 took 0.058s
  training loss:		0.011696
  validation loss:		0.472959
  validation accuracy:		92.83 %
Epoch 1102 of 2000 took 0.057s
  training loss:		0.011556
  validation loss:		0.468844
  validation accuracy:		92.50 %
Epoch 1103 of 2000 took 0.057s
  training loss:		0.011435
  validation loss:		0.478584
  validation accuracy:		92.61 %
Epoch 1104 of 2000 took 0.057s
  training loss:		0.011471
  validation loss:		0.481400
  validation accuracy:		92.72 %
Epoch 1105 of 2000 took 0.056s
  training loss:		0.012020
  validation loss:		0.467488
  validation accuracy:		92.61 %
Epoch 1106 of 2000 took 0.056s
  training loss:		0.011587
  validation loss:		0.479071
  validation accuracy:		92.61 %
Epoch 1107 of 2000 took 0.057s
  training loss:		0.011452
  validation loss:		0.483298
  validation accuracy:		92.39 %
Epoch 1108 of 2000 took 0.057s
  training loss:		0.011619
  validation loss:		0.477567
  validation accuracy:		92.61 %
Epoch 1109 of 2000 took 0.057s
  training loss:		0.011758
  validation loss:		0.477915
  validation accuracy:		92.50 %
Epoch 1110 of 2000 took 0.056s
  training loss:		0.011746
  validation loss:		0.482690
  validation accuracy:		92.50 %
Epoch 1111 of 2000 took 0.057s
  training loss:		0.010614
  validation loss:		0.465270
  validation accuracy:		92.61 %
Epoch 1112 of 2000 took 0.057s
  training loss:		0.011515
  validation loss:		0.480800
  validation accuracy:		92.61 %
Epoch 1113 of 2000 took 0.057s
  training loss:		0.011316
  validation loss:		0.482088
  validation accuracy:		92.39 %
Epoch 1114 of 2000 took 0.057s
  training loss:		0.012166
  validation loss:		0.472055
  validation accuracy:		92.61 %
Epoch 1115 of 2000 took 0.057s
  training loss:		0.011210
  validation loss:		0.490195
  validation accuracy:		92.50 %
Epoch 1116 of 2000 took 0.057s
  training loss:		0.010900
  validation loss:		0.486054
  validation accuracy:		92.50 %
Epoch 1117 of 2000 took 0.057s
  training loss:		0.010920
  validation loss:		0.484196
  validation accuracy:		92.39 %
Epoch 1118 of 2000 took 0.057s
  training loss:		0.010717
  validation loss:		0.485630
  validation accuracy:		92.50 %
Epoch 1119 of 2000 took 0.057s
  training loss:		0.011198
  validation loss:		0.476335
  validation accuracy:		92.61 %
Epoch 1120 of 2000 took 0.057s
  training loss:		0.011202
  validation loss:		0.486592
  validation accuracy:		92.28 %
Epoch 1121 of 2000 took 0.057s
  training loss:		0.011452
  validation loss:		0.481810
  validation accuracy:		92.39 %
Epoch 1122 of 2000 took 0.057s
  training loss:		0.010885
  validation loss:		0.486088
  validation accuracy:		92.83 %
Epoch 1123 of 2000 took 0.057s
  training loss:		0.011454
  validation loss:		0.483056
  validation accuracy:		92.61 %
Epoch 1124 of 2000 took 0.056s
  training loss:		0.011312
  validation loss:		0.474223
  validation accuracy:		92.72 %
Epoch 1125 of 2000 took 0.057s
  training loss:		0.011084
  validation loss:		0.489727
  validation accuracy:		92.61 %
Epoch 1126 of 2000 took 0.057s
  training loss:		0.011097
  validation loss:		0.481732
  validation accuracy:		92.50 %
Epoch 1127 of 2000 took 0.057s
  training loss:		0.011144
  validation loss:		0.484749
  validation accuracy:		92.61 %
Epoch 1128 of 2000 took 0.056s
  training loss:		0.011111
  validation loss:		0.485927
  validation accuracy:		92.50 %
Epoch 1129 of 2000 took 0.056s
  training loss:		0.011113
  validation loss:		0.480688
  validation accuracy:		92.61 %
Epoch 1130 of 2000 took 0.057s
  training loss:		0.011096
  validation loss:		0.476736
  validation accuracy:		92.50 %
Epoch 1131 of 2000 took 0.056s
  training loss:		0.011029
  validation loss:		0.479699
  validation accuracy:		92.50 %
Epoch 1132 of 2000 took 0.055s
  training loss:		0.011345
  validation loss:		0.492207
  validation accuracy:		92.39 %
Epoch 1133 of 2000 took 0.054s
  training loss:		0.010601
  validation loss:		0.480526
  validation accuracy:		92.61 %
Epoch 1134 of 2000 took 0.054s
  training loss:		0.010927
  validation loss:		0.483649
  validation accuracy:		92.50 %
Epoch 1135 of 2000 took 0.056s
  training loss:		0.010777
  validation loss:		0.485411
  validation accuracy:		92.50 %
Epoch 1136 of 2000 took 0.057s
  training loss:		0.010488
  validation loss:		0.479895
  validation accuracy:		92.72 %
Epoch 1137 of 2000 took 0.057s
  training loss:		0.011115
  validation loss:		0.482476
  validation accuracy:		92.39 %
Epoch 1138 of 2000 took 0.056s
  training loss:		0.010942
  validation loss:		0.485711
  validation accuracy:		92.83 %
Epoch 1139 of 2000 took 0.054s
  training loss:		0.010737
  validation loss:		0.484618
  validation accuracy:		92.83 %
Epoch 1140 of 2000 took 0.056s
  training loss:		0.010774
  validation loss:		0.492619
  validation accuracy:		92.50 %
Epoch 1141 of 2000 took 0.054s
  training loss:		0.010755
  validation loss:		0.478793
  validation accuracy:		92.50 %
Epoch 1142 of 2000 took 0.056s
  training loss:		0.010543
  validation loss:		0.473494
  validation accuracy:		92.72 %
Epoch 1143 of 2000 took 0.054s
  training loss:		0.010682
  validation loss:		0.484587
  validation accuracy:		92.50 %
Epoch 1144 of 2000 took 0.054s
  training loss:		0.010767
  validation loss:		0.492358
  validation accuracy:		92.61 %
Epoch 1145 of 2000 took 0.057s
  training loss:		0.010670
  validation loss:		0.487685
  validation accuracy:		92.50 %
Epoch 1146 of 2000 took 0.057s
  training loss:		0.010272
  validation loss:		0.489598
  validation accuracy:		92.50 %
Epoch 1147 of 2000 took 0.057s
  training loss:		0.010382
  validation loss:		0.480975
  validation accuracy:		92.50 %
Epoch 1148 of 2000 took 0.057s
  training loss:		0.010405
  validation loss:		0.496293
  validation accuracy:		92.50 %
Epoch 1149 of 2000 took 0.054s
  training loss:		0.010802
  validation loss:		0.478055
  validation accuracy:		92.72 %
Epoch 1150 of 2000 took 0.057s
  training loss:		0.010402
  validation loss:		0.494103
  validation accuracy:		92.50 %
Epoch 1151 of 2000 took 0.057s
  training loss:		0.010330
  validation loss:		0.482691
  validation accuracy:		92.61 %
Epoch 1152 of 2000 took 0.057s
  training loss:		0.010136
  validation loss:		0.489023
  validation accuracy:		92.50 %
Epoch 1153 of 2000 took 0.058s
  training loss:		0.010277
  validation loss:		0.487771
  validation accuracy:		92.61 %
Epoch 1154 of 2000 took 0.058s
  training loss:		0.010095
  validation loss:		0.496840
  validation accuracy:		92.28 %
Epoch 1155 of 2000 took 0.057s
  training loss:		0.010683
  validation loss:		0.494898
  validation accuracy:		92.61 %
Epoch 1156 of 2000 took 0.057s
  training loss:		0.010286
  validation loss:		0.486194
  validation accuracy:		92.61 %
Epoch 1157 of 2000 took 0.056s
  training loss:		0.010403
  validation loss:		0.498942
  validation accuracy:		92.50 %
Epoch 1158 of 2000 took 0.058s
  training loss:		0.010491
  validation loss:		0.490206
  validation accuracy:		92.61 %
Epoch 1159 of 2000 took 0.057s
  training loss:		0.010098
  validation loss:		0.496358
  validation accuracy:		92.50 %
Epoch 1160 of 2000 took 0.055s
  training loss:		0.010405
  validation loss:		0.503433
  validation accuracy:		92.39 %
Epoch 1161 of 2000 took 0.056s
  training loss:		0.010261
  validation loss:		0.486897
  validation accuracy:		92.50 %
Epoch 1162 of 2000 took 0.057s
  training loss:		0.010056
  validation loss:		0.504220
  validation accuracy:		92.17 %
Epoch 1163 of 2000 took 0.057s
  training loss:		0.010375
  validation loss:		0.495574
  validation accuracy:		92.61 %
Epoch 1164 of 2000 took 0.056s
  training loss:		0.009913
  validation loss:		0.482938
  validation accuracy:		92.61 %
Epoch 1165 of 2000 took 0.056s
  training loss:		0.010156
  validation loss:		0.502016
  validation accuracy:		92.17 %
Epoch 1166 of 2000 took 0.056s
  training loss:		0.010022
  validation loss:		0.501300
  validation accuracy:		92.39 %
Epoch 1167 of 2000 took 0.055s
  training loss:		0.010039
  validation loss:		0.493217
  validation accuracy:		92.61 %
Epoch 1168 of 2000 took 0.056s
  training loss:		0.010239
  validation loss:		0.498977
  validation accuracy:		92.39 %
Epoch 1169 of 2000 took 0.056s
  training loss:		0.010136
  validation loss:		0.495141
  validation accuracy:		92.61 %
Epoch 1170 of 2000 took 0.056s
  training loss:		0.009926
  validation loss:		0.487064
  validation accuracy:		92.72 %
Epoch 1171 of 2000 took 0.055s
  training loss:		0.010166
  validation loss:		0.494301
  validation accuracy:		92.39 %
Epoch 1172 of 2000 took 0.056s
  training loss:		0.010108
  validation loss:		0.491843
  validation accuracy:		92.61 %
Epoch 1173 of 2000 took 0.054s
  training loss:		0.010403
  validation loss:		0.492307
  validation accuracy:		92.83 %
Epoch 1174 of 2000 took 0.056s
  training loss:		0.009862
  validation loss:		0.502773
  validation accuracy:		92.39 %
Epoch 1175 of 2000 took 0.055s
  training loss:		0.009717
  validation loss:		0.490649
  validation accuracy:		92.50 %
Epoch 1176 of 2000 took 0.056s
  training loss:		0.010241
  validation loss:		0.488927
  validation accuracy:		92.50 %
Epoch 1177 of 2000 took 0.054s
  training loss:		0.010187
  validation loss:		0.493777
  validation accuracy:		92.28 %
Epoch 1178 of 2000 took 0.056s
  training loss:		0.010091
  validation loss:		0.487304
  validation accuracy:		92.50 %
Epoch 1179 of 2000 took 0.054s
  training loss:		0.009894
  validation loss:		0.500247
  validation accuracy:		92.39 %
Epoch 1180 of 2000 took 0.056s
  training loss:		0.009712
  validation loss:		0.498174
  validation accuracy:		92.50 %
Epoch 1181 of 2000 took 0.056s
  training loss:		0.009221
  validation loss:		0.483396
  validation accuracy:		92.39 %
Epoch 1182 of 2000 took 0.054s
  training loss:		0.009906
  validation loss:		0.513461
  validation accuracy:		92.17 %
Epoch 1183 of 2000 took 0.057s
  training loss:		0.009973
  validation loss:		0.494633
  validation accuracy:		92.50 %
Epoch 1184 of 2000 took 0.058s
  training loss:		0.009465
  validation loss:		0.487972
  validation accuracy:		92.50 %
Epoch 1185 of 2000 took 0.057s
  training loss:		0.009569
  validation loss:		0.499227
  validation accuracy:		92.28 %
Epoch 1186 of 2000 took 0.057s
  training loss:		0.010167
  validation loss:		0.499120
  validation accuracy:		92.39 %
Epoch 1187 of 2000 took 0.058s
  training loss:		0.009854
  validation loss:		0.496312
  validation accuracy:		92.50 %
Epoch 1188 of 2000 took 0.058s
  training loss:		0.009646
  validation loss:		0.506262
  validation accuracy:		92.50 %
Epoch 1189 of 2000 took 0.057s
  training loss:		0.009481
  validation loss:		0.497112
  validation accuracy:		92.39 %
Epoch 1190 of 2000 took 0.054s
  training loss:		0.009485
  validation loss:		0.496255
  validation accuracy:		92.61 %
Epoch 1191 of 2000 took 0.056s
  training loss:		0.009382
  validation loss:		0.506412
  validation accuracy:		92.39 %
Epoch 1192 of 2000 took 0.057s
  training loss:		0.009852
  validation loss:		0.507842
  validation accuracy:		92.28 %
Epoch 1193 of 2000 took 0.057s
  training loss:		0.009747
  validation loss:		0.509062
  validation accuracy:		92.50 %
Epoch 1194 of 2000 took 0.057s
  training loss:		0.009670
  validation loss:		0.498941
  validation accuracy:		92.50 %
Epoch 1195 of 2000 took 0.057s
  training loss:		0.009272
  validation loss:		0.509215
  validation accuracy:		92.39 %
Epoch 1196 of 2000 took 0.058s
  training loss:		0.009616
  validation loss:		0.505353
  validation accuracy:		92.39 %
Epoch 1197 of 2000 took 0.057s
  training loss:		0.009437
  validation loss:		0.511846
  validation accuracy:		92.50 %
Epoch 1198 of 2000 took 0.057s
  training loss:		0.009455
  validation loss:		0.488204
  validation accuracy:		92.83 %
Epoch 1199 of 2000 took 0.057s
  training loss:		0.009663
  validation loss:		0.506844
  validation accuracy:		92.50 %
Epoch 1200 of 2000 took 0.057s
  training loss:		0.008957
  validation loss:		0.492647
  validation accuracy:		92.72 %
Epoch 1201 of 2000 took 0.058s
  training loss:		0.009194
  validation loss:		0.498147
  validation accuracy:		92.50 %
Epoch 1202 of 2000 took 0.058s
  training loss:		0.009480
  validation loss:		0.509991
  validation accuracy:		92.17 %
Epoch 1203 of 2000 took 0.057s
  training loss:		0.009298
  validation loss:		0.512563
  validation accuracy:		92.07 %
Epoch 1204 of 2000 took 0.057s
  training loss:		0.009761
  validation loss:		0.503719
  validation accuracy:		92.72 %
Epoch 1205 of 2000 took 0.057s
  training loss:		0.009408
  validation loss:		0.498177
  validation accuracy:		92.50 %
Epoch 1206 of 2000 took 0.057s
  training loss:		0.009819
  validation loss:		0.506821
  validation accuracy:		92.50 %
Epoch 1207 of 2000 took 0.057s
  training loss:		0.009119
  validation loss:		0.507530
  validation accuracy:		92.28 %
Epoch 1208 of 2000 took 0.057s
  training loss:		0.009639
  validation loss:		0.502003
  validation accuracy:		92.50 %
Epoch 1209 of 2000 took 0.057s
  training loss:		0.009293
  validation loss:		0.502520
  validation accuracy:		92.61 %
Epoch 1210 of 2000 took 0.057s
  training loss:		0.008698
  validation loss:		0.507174
  validation accuracy:		92.39 %
Epoch 1211 of 2000 took 0.057s
  training loss:		0.009679
  validation loss:		0.512236
  validation accuracy:		92.50 %
Epoch 1212 of 2000 took 0.057s
  training loss:		0.009423
  validation loss:		0.501321
  validation accuracy:		92.50 %
Epoch 1213 of 2000 took 0.057s
  training loss:		0.009532
  validation loss:		0.507113
  validation accuracy:		92.39 %
Epoch 1214 of 2000 took 0.057s
  training loss:		0.009568
  validation loss:		0.498754
  validation accuracy:		92.61 %
Epoch 1215 of 2000 took 0.057s
  training loss:		0.009324
  validation loss:		0.517344
  validation accuracy:		92.17 %
Epoch 1216 of 2000 took 0.057s
  training loss:		0.009452
  validation loss:		0.514759
  validation accuracy:		92.39 %
Epoch 1217 of 2000 took 0.057s
  training loss:		0.009223
  validation loss:		0.511160
  validation accuracy:		92.50 %
Epoch 1218 of 2000 took 0.057s
  training loss:		0.009043
  validation loss:		0.507272
  validation accuracy:		92.61 %
Epoch 1219 of 2000 took 0.057s
  training loss:		0.009313
  validation loss:		0.517254
  validation accuracy:		92.61 %
Epoch 1220 of 2000 took 0.057s
  training loss:		0.009053
  validation loss:		0.503480
  validation accuracy:		92.61 %
Epoch 1221 of 2000 took 0.057s
  training loss:		0.008978
  validation loss:		0.502425
  validation accuracy:		92.50 %
Epoch 1222 of 2000 took 0.058s
  training loss:		0.009154
  validation loss:		0.511533
  validation accuracy:		92.50 %
Epoch 1223 of 2000 took 0.058s
  training loss:		0.009072
  validation loss:		0.498345
  validation accuracy:		92.61 %
Epoch 1224 of 2000 took 0.057s
  training loss:		0.009136
  validation loss:		0.507926
  validation accuracy:		92.50 %
Epoch 1225 of 2000 took 0.057s
  training loss:		0.009191
  validation loss:		0.511842
  validation accuracy:		92.39 %
Epoch 1226 of 2000 took 0.057s
  training loss:		0.008752
  validation loss:		0.514104
  validation accuracy:		92.28 %
Epoch 1227 of 2000 took 0.055s
  training loss:		0.009117
  validation loss:		0.507311
  validation accuracy:		92.50 %
Epoch 1228 of 2000 took 0.054s
  training loss:		0.008962
  validation loss:		0.518529
  validation accuracy:		92.39 %
Epoch 1229 of 2000 took 0.055s
  training loss:		0.009068
  validation loss:		0.502588
  validation accuracy:		92.50 %
Epoch 1230 of 2000 took 0.057s
  training loss:		0.008856
  validation loss:		0.517161
  validation accuracy:		92.50 %
Epoch 1231 of 2000 took 0.057s
  training loss:		0.008510
  validation loss:		0.516807
  validation accuracy:		92.39 %
Epoch 1232 of 2000 took 0.057s
  training loss:		0.008710
  validation loss:		0.507663
  validation accuracy:		92.61 %
Epoch 1233 of 2000 took 0.057s
  training loss:		0.008504
  validation loss:		0.511262
  validation accuracy:		92.28 %
Epoch 1234 of 2000 took 0.057s
  training loss:		0.008868
  validation loss:		0.508969
  validation accuracy:		92.50 %
Epoch 1235 of 2000 took 0.057s
  training loss:		0.008597
  validation loss:		0.514137
  validation accuracy:		92.28 %
Epoch 1236 of 2000 took 0.057s
  training loss:		0.008523
  validation loss:		0.502276
  validation accuracy:		92.39 %
Epoch 1237 of 2000 took 0.057s
  training loss:		0.009078
  validation loss:		0.519906
  validation accuracy:		92.28 %
Epoch 1238 of 2000 took 0.057s
  training loss:		0.008621
  validation loss:		0.519268
  validation accuracy:		92.61 %
Epoch 1239 of 2000 took 0.057s
  training loss:		0.008605
  validation loss:		0.528525
  validation accuracy:		92.28 %
Epoch 1240 of 2000 took 0.057s
  training loss:		0.008716
  validation loss:		0.511798
  validation accuracy:		92.39 %
Epoch 1241 of 2000 took 0.055s
  training loss:		0.008705
  validation loss:		0.516294
  validation accuracy:		92.39 %
Epoch 1242 of 2000 took 0.057s
  training loss:		0.008831
  validation loss:		0.507733
  validation accuracy:		92.72 %
Epoch 1243 of 2000 took 0.057s
  training loss:		0.008396
  validation loss:		0.512775
  validation accuracy:		92.50 %
Epoch 1244 of 2000 took 0.056s
  training loss:		0.008557
  validation loss:		0.504144
  validation accuracy:		92.50 %
Epoch 1245 of 2000 took 0.057s
  training loss:		0.008667
  validation loss:		0.525050
  validation accuracy:		92.39 %
Epoch 1246 of 2000 took 0.057s
  training loss:		0.008723
  validation loss:		0.501365
  validation accuracy:		92.72 %
Epoch 1247 of 2000 took 0.057s
  training loss:		0.008272
  validation loss:		0.519841
  validation accuracy:		92.28 %
Epoch 1248 of 2000 took 0.055s
  training loss:		0.008819
  validation loss:		0.514531
  validation accuracy:		92.39 %
Epoch 1249 of 2000 took 0.057s
  training loss:		0.008463
  validation loss:		0.512827
  validation accuracy:		92.50 %
Epoch 1250 of 2000 took 0.057s
  training loss:		0.008496
  validation loss:		0.509133
  validation accuracy:		92.50 %
Epoch 1251 of 2000 took 0.057s
  training loss:		0.008496
  validation loss:		0.514841
  validation accuracy:		92.39 %
Epoch 1252 of 2000 took 0.057s
  training loss:		0.008501
  validation loss:		0.514128
  validation accuracy:		92.50 %
Epoch 1253 of 2000 took 0.057s
  training loss:		0.008064
  validation loss:		0.518869
  validation accuracy:		92.39 %
Epoch 1254 of 2000 took 0.057s
  training loss:		0.008473
  validation loss:		0.506590
  validation accuracy:		92.28 %
Epoch 1255 of 2000 took 0.057s
  training loss:		0.008406
  validation loss:		0.510361
  validation accuracy:		92.28 %
Epoch 1256 of 2000 took 0.057s
  training loss:		0.008278
  validation loss:		0.512388
  validation accuracy:		92.50 %
Epoch 1257 of 2000 took 0.057s
  training loss:		0.008265
  validation loss:		0.519010
  validation accuracy:		92.50 %
Epoch 1258 of 2000 took 0.057s
  training loss:		0.008293
  validation loss:		0.512374
  validation accuracy:		92.50 %
Epoch 1259 of 2000 took 0.057s
  training loss:		0.008366
  validation loss:		0.512187
  validation accuracy:		92.39 %
Epoch 1260 of 2000 took 0.057s
  training loss:		0.008138
  validation loss:		0.516558
  validation accuracy:		92.28 %
Epoch 1261 of 2000 took 0.057s
  training loss:		0.008585
  validation loss:		0.518781
  validation accuracy:		92.39 %
Epoch 1262 of 2000 took 0.057s
  training loss:		0.008225
  validation loss:		0.518087
  validation accuracy:		92.39 %
Epoch 1263 of 2000 took 0.057s
  training loss:		0.008057
  validation loss:		0.519462
  validation accuracy:		92.39 %
Epoch 1264 of 2000 took 0.057s
  training loss:		0.008462
  validation loss:		0.518042
  validation accuracy:		92.39 %
Epoch 1265 of 2000 took 0.056s
  training loss:		0.008331
  validation loss:		0.521571
  validation accuracy:		92.28 %
Epoch 1266 of 2000 took 0.057s
  training loss:		0.008286
  validation loss:		0.516364
  validation accuracy:		92.50 %
Epoch 1267 of 2000 took 0.057s
  training loss:		0.008024
  validation loss:		0.528015
  validation accuracy:		92.39 %
Epoch 1268 of 2000 took 0.057s
  training loss:		0.007863
  validation loss:		0.514343
  validation accuracy:		92.61 %
Epoch 1269 of 2000 took 0.055s
  training loss:		0.008364
  validation loss:		0.515738
  validation accuracy:		92.61 %
Epoch 1270 of 2000 took 0.057s
  training loss:		0.008111
  validation loss:		0.515643
  validation accuracy:		92.50 %
Epoch 1271 of 2000 took 0.057s
  training loss:		0.008042
  validation loss:		0.511107
  validation accuracy:		92.72 %
Epoch 1272 of 2000 took 0.057s
  training loss:		0.008209
  validation loss:		0.540332
  validation accuracy:		92.28 %
Epoch 1273 of 2000 took 0.057s
  training loss:		0.008275
  validation loss:		0.525886
  validation accuracy:		92.39 %
Epoch 1274 of 2000 took 0.057s
  training loss:		0.008291
  validation loss:		0.520595
  validation accuracy:		92.61 %
Epoch 1275 of 2000 took 0.058s
  training loss:		0.008027
  validation loss:		0.519785
  validation accuracy:		92.50 %
Epoch 1276 of 2000 took 0.059s
  training loss:		0.008191
  validation loss:		0.521067
  validation accuracy:		92.39 %
Epoch 1277 of 2000 took 0.059s
  training loss:		0.007659
  validation loss:		0.520229
  validation accuracy:		92.50 %
Epoch 1278 of 2000 took 0.059s
  training loss:		0.007818
  validation loss:		0.519005
  validation accuracy:		92.50 %
Epoch 1279 of 2000 took 0.059s
  training loss:		0.007808
  validation loss:		0.521554
  validation accuracy:		92.61 %
Epoch 1280 of 2000 took 0.059s
  training loss:		0.007852
  validation loss:		0.529852
  validation accuracy:		92.28 %
Epoch 1281 of 2000 took 0.058s
  training loss:		0.008289
  validation loss:		0.518967
  validation accuracy:		92.50 %
Epoch 1282 of 2000 took 0.057s
  training loss:		0.007841
  validation loss:		0.532835
  validation accuracy:		92.28 %
Epoch 1283 of 2000 took 0.057s
  training loss:		0.007931
  validation loss:		0.531440
  validation accuracy:		92.28 %
Epoch 1284 of 2000 took 0.057s
  training loss:		0.007894
  validation loss:		0.511425
  validation accuracy:		92.61 %
Epoch 1285 of 2000 took 0.057s
  training loss:		0.007984
  validation loss:		0.525689
  validation accuracy:		92.50 %
Epoch 1286 of 2000 took 0.057s
  training loss:		0.008491
  validation loss:		0.527770
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.057s
  training loss:		0.007655
  validation loss:		0.533267
  validation accuracy:		92.28 %
Epoch 1288 of 2000 took 0.057s
  training loss:		0.008211
  validation loss:		0.531518
  validation accuracy:		92.39 %
Epoch 1289 of 2000 took 0.057s
  training loss:		0.007949
  validation loss:		0.531338
  validation accuracy:		92.28 %
Epoch 1290 of 2000 took 0.057s
  training loss:		0.008097
  validation loss:		0.535284
  validation accuracy:		92.28 %
Epoch 1291 of 2000 took 0.057s
  training loss:		0.007681
  validation loss:		0.510552
  validation accuracy:		92.83 %
Epoch 1292 of 2000 took 0.057s
  training loss:		0.007805
  validation loss:		0.527621
  validation accuracy:		92.17 %
Epoch 1293 of 2000 took 0.056s
  training loss:		0.007604
  validation loss:		0.528036
  validation accuracy:		92.50 %
Epoch 1294 of 2000 took 0.057s
  training loss:		0.007744
  validation loss:		0.526886
  validation accuracy:		92.39 %
Epoch 1295 of 2000 took 0.057s
  training loss:		0.007794
  validation loss:		0.522606
  validation accuracy:		92.61 %
Epoch 1296 of 2000 took 0.057s
  training loss:		0.007560
  validation loss:		0.543581
  validation accuracy:		92.17 %
Epoch 1297 of 2000 took 0.057s
  training loss:		0.007803
  validation loss:		0.530463
  validation accuracy:		92.50 %
Epoch 1298 of 2000 took 0.057s
  training loss:		0.007836
  validation loss:		0.523043
  validation accuracy:		92.61 %
Epoch 1299 of 2000 took 0.056s
  training loss:		0.007573
  validation loss:		0.524364
  validation accuracy:		92.50 %
Epoch 1300 of 2000 took 0.057s
  training loss:		0.007719
  validation loss:		0.530936
  validation accuracy:		92.28 %
Epoch 1301 of 2000 took 0.057s
  training loss:		0.007831
  validation loss:		0.526011
  validation accuracy:		92.50 %
Epoch 1302 of 2000 took 0.057s
  training loss:		0.007758
  validation loss:		0.524597
  validation accuracy:		92.39 %
Epoch 1303 of 2000 took 0.057s
  training loss:		0.007524
  validation loss:		0.524513
  validation accuracy:		92.39 %
Epoch 1304 of 2000 took 0.057s
  training loss:		0.007559
  validation loss:		0.523159
  validation accuracy:		92.61 %
Epoch 1305 of 2000 took 0.057s
  training loss:		0.007481
  validation loss:		0.525195
  validation accuracy:		92.39 %
Epoch 1306 of 2000 took 0.057s
  training loss:		0.007594
  validation loss:		0.523165
  validation accuracy:		92.61 %
Epoch 1307 of 2000 took 0.057s
  training loss:		0.007438
  validation loss:		0.532196
  validation accuracy:		92.39 %
Epoch 1308 of 2000 took 0.057s
  training loss:		0.007828
  validation loss:		0.519598
  validation accuracy:		92.61 %
Epoch 1309 of 2000 took 0.057s
  training loss:		0.007573
  validation loss:		0.529842
  validation accuracy:		92.39 %
Epoch 1310 of 2000 took 0.057s
  training loss:		0.007490
  validation loss:		0.539397
  validation accuracy:		92.28 %
Epoch 1311 of 2000 took 0.056s
  training loss:		0.007467
  validation loss:		0.527908
  validation accuracy:		92.50 %
Epoch 1312 of 2000 took 0.057s
  training loss:		0.007640
  validation loss:		0.533191
  validation accuracy:		92.28 %
Epoch 1313 of 2000 took 0.057s
  training loss:		0.007499
  validation loss:		0.526024
  validation accuracy:		92.39 %
Epoch 1314 of 2000 took 0.057s
  training loss:		0.007561
  validation loss:		0.523280
  validation accuracy:		92.39 %
Epoch 1315 of 2000 took 0.057s
  training loss:		0.007422
  validation loss:		0.523237
  validation accuracy:		92.61 %
Epoch 1316 of 2000 took 0.057s
  training loss:		0.007171
  validation loss:		0.523344
  validation accuracy:		92.61 %
Epoch 1317 of 2000 took 0.055s
  training loss:		0.007598
  validation loss:		0.541124
  validation accuracy:		92.07 %
Epoch 1318 of 2000 took 0.057s
  training loss:		0.007485
  validation loss:		0.534008
  validation accuracy:		92.50 %
Epoch 1319 of 2000 took 0.057s
  training loss:		0.007099
  validation loss:		0.523863
  validation accuracy:		92.39 %
Epoch 1320 of 2000 took 0.057s
  training loss:		0.007568
  validation loss:		0.538250
  validation accuracy:		92.17 %
Epoch 1321 of 2000 took 0.057s
  training loss:		0.007139
  validation loss:		0.529444
  validation accuracy:		92.50 %
Epoch 1322 of 2000 took 0.057s
  training loss:		0.007291
  validation loss:		0.529362
  validation accuracy:		92.50 %
Epoch 1323 of 2000 took 0.057s
  training loss:		0.007416
  validation loss:		0.539871
  validation accuracy:		92.39 %
Epoch 1324 of 2000 took 0.057s
  training loss:		0.007312
  validation loss:		0.530324
  validation accuracy:		92.39 %
Epoch 1325 of 2000 took 0.055s
  training loss:		0.007397
  validation loss:		0.532161
  validation accuracy:		92.39 %
Epoch 1326 of 2000 took 0.057s
  training loss:		0.007076
  validation loss:		0.536619
  validation accuracy:		92.61 %
Epoch 1327 of 2000 took 0.057s
  training loss:		0.007377
  validation loss:		0.531569
  validation accuracy:		92.39 %
Epoch 1328 of 2000 took 0.056s
  training loss:		0.007473
  validation loss:		0.533043
  validation accuracy:		92.39 %
Epoch 1329 of 2000 took 0.057s
  training loss:		0.006988
  validation loss:		0.534855
  validation accuracy:		92.39 %
Epoch 1330 of 2000 took 0.057s
  training loss:		0.007281
  validation loss:		0.529802
  validation accuracy:		92.50 %
Epoch 1331 of 2000 took 0.057s
  training loss:		0.007385
  validation loss:		0.529499
  validation accuracy:		92.39 %
Epoch 1332 of 2000 took 0.058s
  training loss:		0.007322
  validation loss:		0.527343
  validation accuracy:		92.61 %
Epoch 1333 of 2000 took 0.058s
  training loss:		0.007140
  validation loss:		0.525771
  validation accuracy:		92.50 %
Epoch 1334 of 2000 took 0.058s
  training loss:		0.007203
  validation loss:		0.533530
  validation accuracy:		92.50 %
Epoch 1335 of 2000 took 0.058s
  training loss:		0.007015
  validation loss:		0.535398
  validation accuracy:		92.28 %
Epoch 1336 of 2000 took 0.058s
  training loss:		0.007017
  validation loss:		0.533435
  validation accuracy:		92.61 %
Epoch 1337 of 2000 took 0.058s
  training loss:		0.007051
  validation loss:		0.529549
  validation accuracy:		92.39 %
Epoch 1338 of 2000 took 0.058s
  training loss:		0.007152
  validation loss:		0.519163
  validation accuracy:		92.72 %
Epoch 1339 of 2000 took 0.058s
  training loss:		0.007093
  validation loss:		0.534035
  validation accuracy:		92.39 %
Epoch 1340 of 2000 took 0.057s
  training loss:		0.007244
  validation loss:		0.539181
  validation accuracy:		92.50 %
Epoch 1341 of 2000 took 0.057s
  training loss:		0.006951
  validation loss:		0.527148
  validation accuracy:		92.50 %
Epoch 1342 of 2000 took 0.057s
  training loss:		0.007251
  validation loss:		0.534387
  validation accuracy:		92.50 %
Epoch 1343 of 2000 took 0.057s
  training loss:		0.007041
  validation loss:		0.523105
  validation accuracy:		92.61 %
Epoch 1344 of 2000 took 0.059s
  training loss:		0.007127
  validation loss:		0.536507
  validation accuracy:		92.50 %
Epoch 1345 of 2000 took 0.056s
  training loss:		0.007078
  validation loss:		0.544198
  validation accuracy:		92.28 %
Epoch 1346 of 2000 took 0.057s
  training loss:		0.007042
  validation loss:		0.540141
  validation accuracy:		92.39 %
Epoch 1347 of 2000 took 0.057s
  training loss:		0.007000
  validation loss:		0.532253
  validation accuracy:		92.61 %
Epoch 1348 of 2000 took 0.057s
  training loss:		0.006922
  validation loss:		0.535933
  validation accuracy:		92.50 %
Epoch 1349 of 2000 took 0.057s
  training loss:		0.007078
  validation loss:		0.541558
  validation accuracy:		92.39 %
Epoch 1350 of 2000 took 0.056s
  training loss:		0.006706
  validation loss:		0.542245
  validation accuracy:		92.39 %
Epoch 1351 of 2000 took 0.056s
  training loss:		0.007122
  validation loss:		0.537758
  validation accuracy:		92.50 %
Epoch 1352 of 2000 took 0.057s
  training loss:		0.006855
  validation loss:		0.544775
  validation accuracy:		92.39 %
Epoch 1353 of 2000 took 0.061s
  training loss:		0.006879
  validation loss:		0.525788
  validation accuracy:		92.61 %
Epoch 1354 of 2000 took 0.058s
  training loss:		0.007007
  validation loss:		0.549788
  validation accuracy:		92.28 %
Epoch 1355 of 2000 took 0.057s
  training loss:		0.006979
  validation loss:		0.535159
  validation accuracy:		92.50 %
Epoch 1356 of 2000 took 0.057s
  training loss:		0.006838
  validation loss:		0.540521
  validation accuracy:		92.50 %
Epoch 1357 of 2000 took 0.057s
  training loss:		0.006912
  validation loss:		0.533928
  validation accuracy:		92.61 %
Epoch 1358 of 2000 took 0.057s
  training loss:		0.006746
  validation loss:		0.545294
  validation accuracy:		92.39 %
Epoch 1359 of 2000 took 0.056s
  training loss:		0.006775
  validation loss:		0.544908
  validation accuracy:		92.28 %
Epoch 1360 of 2000 took 0.057s
  training loss:		0.006797
  validation loss:		0.542512
  validation accuracy:		92.28 %
Epoch 1361 of 2000 took 0.056s
  training loss:		0.006943
  validation loss:		0.535415
  validation accuracy:		92.61 %
Epoch 1362 of 2000 took 0.056s
  training loss:		0.006630
  validation loss:		0.548063
  validation accuracy:		92.28 %
Epoch 1363 of 2000 took 0.057s
  training loss:		0.006768
  validation loss:		0.537505
  validation accuracy:		92.39 %
Epoch 1364 of 2000 took 0.056s
  training loss:		0.006757
  validation loss:		0.537419
  validation accuracy:		92.50 %
Epoch 1365 of 2000 took 0.055s
  training loss:		0.006765
  validation loss:		0.544940
  validation accuracy:		92.28 %
Epoch 1366 of 2000 took 0.054s
  training loss:		0.006781
  validation loss:		0.547358
  validation accuracy:		92.39 %
Epoch 1367 of 2000 took 0.059s
  training loss:		0.006920
  validation loss:		0.550626
  validation accuracy:		92.50 %
Epoch 1368 of 2000 took 0.057s
  training loss:		0.006800
  validation loss:		0.552613
  validation accuracy:		92.28 %
Epoch 1369 of 2000 took 0.054s
  training loss:		0.006923
  validation loss:		0.537270
  validation accuracy:		92.39 %
Epoch 1370 of 2000 took 0.055s
  training loss:		0.006787
  validation loss:		0.533751
  validation accuracy:		92.61 %
Epoch 1371 of 2000 took 0.054s
  training loss:		0.006814
  validation loss:		0.546038
  validation accuracy:		92.39 %
Epoch 1372 of 2000 took 0.055s
  training loss:		0.006750
  validation loss:		0.545322
  validation accuracy:		92.39 %
Epoch 1373 of 2000 took 0.054s
  training loss:		0.006860
  validation loss:		0.546871
  validation accuracy:		92.28 %
Epoch 1374 of 2000 took 0.056s
  training loss:		0.006820
  validation loss:		0.538068
  validation accuracy:		92.39 %
Epoch 1375 of 2000 took 0.054s
  training loss:		0.006556
  validation loss:		0.550389
  validation accuracy:		92.39 %
Epoch 1376 of 2000 took 0.056s
  training loss:		0.006698
  validation loss:		0.554503
  validation accuracy:		92.39 %
Epoch 1377 of 2000 took 0.056s
  training loss:		0.006785
  validation loss:		0.541742
  validation accuracy:		92.28 %
Epoch 1378 of 2000 took 0.054s
  training loss:		0.006831
  validation loss:		0.540632
  validation accuracy:		92.50 %
Epoch 1379 of 2000 took 0.056s
  training loss:		0.006695
  validation loss:		0.542739
  validation accuracy:		92.39 %
Epoch 1380 of 2000 took 0.053s
  training loss:		0.006533
  validation loss:		0.549823
  validation accuracy:		92.28 %
Epoch 1381 of 2000 took 0.057s
  training loss:		0.006793
  validation loss:		0.545719
  validation accuracy:		92.39 %
Epoch 1382 of 2000 took 0.054s
  training loss:		0.006509
  validation loss:		0.538670
  validation accuracy:		92.39 %
Epoch 1383 of 2000 took 0.056s
  training loss:		0.006634
  validation loss:		0.533954
  validation accuracy:		92.61 %
Epoch 1384 of 2000 took 0.057s
  training loss:		0.006580
  validation loss:		0.549478
  validation accuracy:		92.39 %
Epoch 1385 of 2000 took 0.058s
  training loss:		0.006870
  validation loss:		0.544069
  validation accuracy:		92.50 %
Epoch 1386 of 2000 took 0.057s
  training loss:		0.006575
  validation loss:		0.551703
  validation accuracy:		92.17 %
Epoch 1387 of 2000 took 0.057s
  training loss:		0.006726
  validation loss:		0.557787
  validation accuracy:		92.28 %
Epoch 1388 of 2000 took 0.057s
  training loss:		0.006627
  validation loss:		0.535548
  validation accuracy:		92.39 %
Epoch 1389 of 2000 took 0.057s
  training loss:		0.006667
  validation loss:		0.541920
  validation accuracy:		92.39 %
Epoch 1390 of 2000 took 0.057s
  training loss:		0.006641
  validation loss:		0.532034
  validation accuracy:		92.61 %
Epoch 1391 of 2000 took 0.058s
  training loss:		0.006843
  validation loss:		0.543620
  validation accuracy:		92.61 %
Epoch 1392 of 2000 took 0.057s
  training loss:		0.006452
  validation loss:		0.542194
  validation accuracy:		92.50 %
Epoch 1393 of 2000 took 0.057s
  training loss:		0.006456
  validation loss:		0.543496
  validation accuracy:		92.28 %
Epoch 1394 of 2000 took 0.057s
  training loss:		0.006421
  validation loss:		0.547736
  validation accuracy:		92.50 %
Epoch 1395 of 2000 took 0.058s
  training loss:		0.006615
  validation loss:		0.551617
  validation accuracy:		92.28 %
Epoch 1396 of 2000 took 0.057s
  training loss:		0.006514
  validation loss:		0.545363
  validation accuracy:		92.39 %
Epoch 1397 of 2000 took 0.057s
  training loss:		0.006279
  validation loss:		0.548344
  validation accuracy:		92.39 %
Epoch 1398 of 2000 took 0.058s
  training loss:		0.006565
  validation loss:		0.543314
  validation accuracy:		92.61 %
Epoch 1399 of 2000 took 0.057s
  training loss:		0.006060
  validation loss:		0.555402
  validation accuracy:		92.39 %
Epoch 1400 of 2000 took 0.057s
  training loss:		0.006503
  validation loss:		0.541783
  validation accuracy:		92.39 %
Epoch 1401 of 2000 took 0.057s
  training loss:		0.006390
  validation loss:		0.546840
  validation accuracy:		92.39 %
Epoch 1402 of 2000 took 0.058s
  training loss:		0.006393
  validation loss:		0.555322
  validation accuracy:		92.28 %
Epoch 1403 of 2000 took 0.057s
  training loss:		0.006331
  validation loss:		0.552029
  validation accuracy:		92.39 %
Epoch 1404 of 2000 took 0.057s
  training loss:		0.006388
  validation loss:		0.553576
  validation accuracy:		92.28 %
Epoch 1405 of 2000 took 0.057s
  training loss:		0.006412
  validation loss:		0.552895
  validation accuracy:		92.39 %
Epoch 1406 of 2000 took 0.057s
  training loss:		0.006305
  validation loss:		0.558456
  validation accuracy:		92.28 %
Epoch 1407 of 2000 took 0.056s
  training loss:		0.006379
  validation loss:		0.547571
  validation accuracy:		92.50 %
Epoch 1408 of 2000 took 0.055s
  training loss:		0.006149
  validation loss:		0.550110
  validation accuracy:		92.39 %
Epoch 1409 of 2000 took 0.055s
  training loss:		0.006189
  validation loss:		0.557628
  validation accuracy:		92.39 %
Epoch 1410 of 2000 took 0.057s
  training loss:		0.006147
  validation loss:		0.546434
  validation accuracy:		92.39 %
Epoch 1411 of 2000 took 0.057s
  training loss:		0.006400
  validation loss:		0.545733
  validation accuracy:		92.50 %
Epoch 1412 of 2000 took 0.057s
  training loss:		0.006405
  validation loss:		0.549454
  validation accuracy:		92.39 %
Epoch 1413 of 2000 took 0.057s
  training loss:		0.006216
  validation loss:		0.552461
  validation accuracy:		92.39 %
Epoch 1414 of 2000 took 0.057s
  training loss:		0.006260
  validation loss:		0.552916
  validation accuracy:		92.39 %
Epoch 1415 of 2000 took 0.057s
  training loss:		0.006167
  validation loss:		0.551147
  validation accuracy:		92.28 %
Epoch 1416 of 2000 took 0.057s
  training loss:		0.006242
  validation loss:		0.549052
  validation accuracy:		92.39 %
Epoch 1417 of 2000 took 0.057s
  training loss:		0.006073
  validation loss:		0.560985
  validation accuracy:		92.28 %
Epoch 1418 of 2000 took 0.055s
  training loss:		0.006474
  validation loss:		0.560147
  validation accuracy:		92.39 %
Epoch 1419 of 2000 took 0.057s
  training loss:		0.006291
  validation loss:		0.545394
  validation accuracy:		92.61 %
Epoch 1420 of 2000 took 0.057s
  training loss:		0.006485
  validation loss:		0.551283
  validation accuracy:		92.61 %
Epoch 1421 of 2000 took 0.057s
  training loss:		0.006302
  validation loss:		0.556442
  validation accuracy:		92.39 %
Epoch 1422 of 2000 took 0.057s
  training loss:		0.006169
  validation loss:		0.545248
  validation accuracy:		92.72 %
Epoch 1423 of 2000 took 0.057s
  training loss:		0.006175
  validation loss:		0.554058
  validation accuracy:		92.39 %
Epoch 1424 of 2000 took 0.057s
  training loss:		0.006178
  validation loss:		0.556015
  validation accuracy:		92.39 %
Epoch 1425 of 2000 took 0.057s
  training loss:		0.006084
  validation loss:		0.543015
  validation accuracy:		92.72 %
Epoch 1426 of 2000 took 0.057s
  training loss:		0.006120
  validation loss:		0.560769
  validation accuracy:		92.17 %
Epoch 1427 of 2000 took 0.057s
  training loss:		0.006032
  validation loss:		0.561381
  validation accuracy:		92.28 %
Epoch 1428 of 2000 took 0.057s
  training loss:		0.006229
  validation loss:		0.550796
  validation accuracy:		92.50 %
Epoch 1429 of 2000 took 0.057s
  training loss:		0.005923
  validation loss:		0.559861
  validation accuracy:		92.39 %
Epoch 1430 of 2000 took 0.057s
  training loss:		0.006160
  validation loss:		0.550740
  validation accuracy:		92.50 %
Epoch 1431 of 2000 took 0.055s
  training loss:		0.006389
  validation loss:		0.552922
  validation accuracy:		92.39 %
Epoch 1432 of 2000 took 0.058s
  training loss:		0.006125
  validation loss:		0.552355
  validation accuracy:		92.50 %
Epoch 1433 of 2000 took 0.057s
  training loss:		0.006131
  validation loss:		0.553038
  validation accuracy:		92.39 %
Epoch 1434 of 2000 took 0.056s
  training loss:		0.006403
  validation loss:		0.552014
  validation accuracy:		92.72 %
Epoch 1435 of 2000 took 0.057s
  training loss:		0.006079
  validation loss:		0.557005
  validation accuracy:		92.39 %
Epoch 1436 of 2000 took 0.057s
  training loss:		0.005934
  validation loss:		0.563085
  validation accuracy:		92.39 %
Epoch 1437 of 2000 took 0.057s
  training loss:		0.006058
  validation loss:		0.558735
  validation accuracy:		92.39 %
Epoch 1438 of 2000 took 0.057s
  training loss:		0.005832
  validation loss:		0.561687
  validation accuracy:		92.39 %
Epoch 1439 of 2000 took 0.057s
  training loss:		0.005981
  validation loss:		0.553560
  validation accuracy:		92.61 %
Epoch 1440 of 2000 took 0.057s
  training loss:		0.005808
  validation loss:		0.560748
  validation accuracy:		92.28 %
Epoch 1441 of 2000 took 0.057s
  training loss:		0.005994
  validation loss:		0.550836
  validation accuracy:		92.50 %
Epoch 1442 of 2000 took 0.057s
  training loss:		0.005930
  validation loss:		0.558686
  validation accuracy:		92.39 %
Epoch 1443 of 2000 took 0.057s
  training loss:		0.005943
  validation loss:		0.557319
  validation accuracy:		92.39 %
Epoch 1444 of 2000 took 0.057s
  training loss:		0.005892
  validation loss:		0.563585
  validation accuracy:		92.28 %
Epoch 1445 of 2000 took 0.057s
  training loss:		0.005913
  validation loss:		0.554493
  validation accuracy:		92.50 %
Epoch 1446 of 2000 took 0.057s
  training loss:		0.005972
  validation loss:		0.545499
  validation accuracy:		92.50 %
Epoch 1447 of 2000 took 0.057s
  training loss:		0.005847
  validation loss:		0.560209
  validation accuracy:		92.39 %
Epoch 1448 of 2000 took 0.057s
  training loss:		0.006002
  validation loss:		0.552452
  validation accuracy:		92.39 %
Epoch 1449 of 2000 took 0.056s
  training loss:		0.005906
  validation loss:		0.559376
  validation accuracy:		92.39 %
Epoch 1450 of 2000 took 0.055s
  training loss:		0.006021
  validation loss:		0.555150
  validation accuracy:		92.28 %
Epoch 1451 of 2000 took 0.057s
  training loss:		0.005981
  validation loss:		0.558300
  validation accuracy:		92.50 %
Epoch 1452 of 2000 took 0.057s
  training loss:		0.005573
  validation loss:		0.567512
  validation accuracy:		92.28 %
Epoch 1453 of 2000 took 0.057s
  training loss:		0.006002
  validation loss:		0.564200
  validation accuracy:		92.39 %
Epoch 1454 of 2000 took 0.057s
  training loss:		0.005903
  validation loss:		0.559574
  validation accuracy:		92.39 %
Epoch 1455 of 2000 took 0.057s
  training loss:		0.005798
  validation loss:		0.555804
  validation accuracy:		92.50 %
Epoch 1456 of 2000 took 0.057s
  training loss:		0.005935
  validation loss:		0.556669
  validation accuracy:		92.50 %
Epoch 1457 of 2000 took 0.056s
  training loss:		0.005996
  validation loss:		0.563281
  validation accuracy:		92.39 %
Epoch 1458 of 2000 took 0.057s
  training loss:		0.005688
  validation loss:		0.566921
  validation accuracy:		92.39 %
Epoch 1459 of 2000 took 0.056s
  training loss:		0.005882
  validation loss:		0.570617
  validation accuracy:		92.17 %
Epoch 1460 of 2000 took 0.057s
  training loss:		0.005769
  validation loss:		0.552706
  validation accuracy:		92.61 %
Epoch 1461 of 2000 took 0.057s
  training loss:		0.005725
  validation loss:		0.573781
  validation accuracy:		92.17 %
Epoch 1462 of 2000 took 0.056s
  training loss:		0.005883
  validation loss:		0.558327
  validation accuracy:		92.28 %
Epoch 1463 of 2000 took 0.058s
  training loss:		0.005904
  validation loss:		0.565951
  validation accuracy:		92.28 %
Epoch 1464 of 2000 took 0.058s
  training loss:		0.005812
  validation loss:		0.561540
  validation accuracy:		92.39 %
Epoch 1465 of 2000 took 0.057s
  training loss:		0.005560
  validation loss:		0.565278
  validation accuracy:		92.39 %
Epoch 1466 of 2000 took 0.055s
  training loss:		0.005710
  validation loss:		0.564108
  validation accuracy:		92.28 %
Epoch 1467 of 2000 took 0.056s
  training loss:		0.005898
  validation loss:		0.555244
  validation accuracy:		92.39 %
Epoch 1468 of 2000 took 0.056s
  training loss:		0.006065
  validation loss:		0.561166
  validation accuracy:		92.39 %
Epoch 1469 of 2000 took 0.056s
  training loss:		0.005708
  validation loss:		0.557772
  validation accuracy:		92.50 %
Epoch 1470 of 2000 took 0.056s
  training loss:		0.005629
  validation loss:		0.558994
  validation accuracy:		92.50 %
Epoch 1471 of 2000 took 0.057s
  training loss:		0.005585
  validation loss:		0.563429
  validation accuracy:		92.39 %
Epoch 1472 of 2000 took 0.055s
  training loss:		0.005534
  validation loss:		0.555816
  validation accuracy:		92.72 %
Epoch 1473 of 2000 took 0.054s
  training loss:		0.005647
  validation loss:		0.563158
  validation accuracy:		92.50 %
Epoch 1474 of 2000 took 0.056s
  training loss:		0.005575
  validation loss:		0.565202
  validation accuracy:		92.61 %
Epoch 1475 of 2000 took 0.057s
  training loss:		0.005712
  validation loss:		0.552664
  validation accuracy:		92.50 %
Epoch 1476 of 2000 took 0.055s
  training loss:		0.005715
  validation loss:		0.564683
  validation accuracy:		92.28 %
Epoch 1477 of 2000 took 0.055s
  training loss:		0.005598
  validation loss:		0.564247
  validation accuracy:		92.39 %
Epoch 1478 of 2000 took 0.055s
  training loss:		0.005819
  validation loss:		0.570239
  validation accuracy:		92.50 %
Epoch 1479 of 2000 took 0.056s
  training loss:		0.005630
  validation loss:		0.566949
  validation accuracy:		92.39 %
Epoch 1480 of 2000 took 0.057s
  training loss:		0.005694
  validation loss:		0.566823
  validation accuracy:		92.50 %
Epoch 1481 of 2000 took 0.057s
  training loss:		0.005575
  validation loss:		0.562524
  validation accuracy:		92.39 %
Epoch 1482 of 2000 took 0.055s
  training loss:		0.005767
  validation loss:		0.569897
  validation accuracy:		92.39 %
Epoch 1483 of 2000 took 0.056s
  training loss:		0.005681
  validation loss:		0.562919
  validation accuracy:		92.50 %
Epoch 1484 of 2000 took 0.057s
  training loss:		0.005612
  validation loss:		0.558515
  validation accuracy:		92.39 %
Epoch 1485 of 2000 took 0.058s
  training loss:		0.005686
  validation loss:		0.556369
  validation accuracy:		92.28 %
Epoch 1486 of 2000 took 0.057s
  training loss:		0.005625
  validation loss:		0.558139
  validation accuracy:		92.50 %
Epoch 1487 of 2000 took 0.057s
  training loss:		0.005508
  validation loss:		0.570203
  validation accuracy:		92.28 %
Epoch 1488 of 2000 took 0.058s
  training loss:		0.005577
  validation loss:		0.561073
  validation accuracy:		92.39 %
Epoch 1489 of 2000 took 0.057s
  training loss:		0.005650
  validation loss:		0.568922
  validation accuracy:		92.39 %
Epoch 1490 of 2000 took 0.058s
  training loss:		0.005500
  validation loss:		0.562036
  validation accuracy:		92.50 %
Epoch 1491 of 2000 took 0.057s
  training loss:		0.005394
  validation loss:		0.570868
  validation accuracy:		92.28 %
Epoch 1492 of 2000 took 0.057s
  training loss:		0.005335
  validation loss:		0.562621
  validation accuracy:		92.50 %
Epoch 1493 of 2000 took 0.057s
  training loss:		0.005341
  validation loss:		0.575115
  validation accuracy:		92.28 %
Epoch 1494 of 2000 took 0.057s
  training loss:		0.005519
  validation loss:		0.568304
  validation accuracy:		92.28 %
Epoch 1495 of 2000 took 0.057s
  training loss:		0.005430
  validation loss:		0.563643
  validation accuracy:		92.39 %
Epoch 1496 of 2000 took 0.057s
  training loss:		0.005502
  validation loss:		0.566009
  validation accuracy:		92.39 %
Epoch 1497 of 2000 took 0.057s
  training loss:		0.005488
  validation loss:		0.570554
  validation accuracy:		92.39 %
Epoch 1498 of 2000 took 0.057s
  training loss:		0.005572
  validation loss:		0.575979
  validation accuracy:		92.28 %
Epoch 1499 of 2000 took 0.057s
  training loss:		0.005625
  validation loss:		0.564180
  validation accuracy:		92.39 %
Epoch 1500 of 2000 took 0.057s
  training loss:		0.005415
  validation loss:		0.576385
  validation accuracy:		92.28 %
Epoch 1501 of 2000 took 0.059s
  training loss:		0.005522
  validation loss:		0.572670
  validation accuracy:		92.39 %
Epoch 1502 of 2000 took 0.056s
  training loss:		0.005363
  validation loss:		0.580770
  validation accuracy:		92.17 %
Epoch 1503 of 2000 took 0.057s
  training loss:		0.005575
  validation loss:		0.565707
  validation accuracy:		92.39 %
Epoch 1504 of 2000 took 0.055s
  training loss:		0.005320
  validation loss:		0.569709
  validation accuracy:		92.28 %
Epoch 1505 of 2000 took 0.055s
  training loss:		0.005396
  validation loss:		0.567037
  validation accuracy:		92.39 %
Epoch 1506 of 2000 took 0.055s
  training loss:		0.005364
  validation loss:		0.575056
  validation accuracy:		92.39 %
Epoch 1507 of 2000 took 0.057s
  training loss:		0.005346
  validation loss:		0.568019
  validation accuracy:		92.50 %
Epoch 1508 of 2000 took 0.057s
  training loss:		0.005493
  validation loss:		0.571777
  validation accuracy:		92.50 %
Epoch 1509 of 2000 took 0.057s
  training loss:		0.005324
  validation loss:		0.581375
  validation accuracy:		92.17 %
Epoch 1510 of 2000 took 0.057s
  training loss:		0.005255
  validation loss:		0.566878
  validation accuracy:		92.50 %
Epoch 1511 of 2000 took 0.057s
  training loss:		0.005317
  validation loss:		0.578470
  validation accuracy:		92.50 %
Epoch 1512 of 2000 took 0.057s
  training loss:		0.005251
  validation loss:		0.562041
  validation accuracy:		92.39 %
Epoch 1513 of 2000 took 0.057s
  training loss:		0.005377
  validation loss:		0.567365
  validation accuracy:		92.50 %
Epoch 1514 of 2000 took 0.057s
  training loss:		0.005176
  validation loss:		0.568640
  validation accuracy:		92.28 %
Epoch 1515 of 2000 took 0.057s
  training loss:		0.005432
  validation loss:		0.574657
  validation accuracy:		92.39 %
Epoch 1516 of 2000 took 0.055s
  training loss:		0.005153
  validation loss:		0.575151
  validation accuracy:		92.39 %
Epoch 1517 of 2000 took 0.057s
  training loss:		0.005259
  validation loss:		0.569550
  validation accuracy:		92.28 %
Epoch 1518 of 2000 took 0.057s
  training loss:		0.005289
  validation loss:		0.566908
  validation accuracy:		92.39 %
Epoch 1519 of 2000 took 0.057s
  training loss:		0.005063
  validation loss:		0.569475
  validation accuracy:		92.39 %
Epoch 1520 of 2000 took 0.057s
  training loss:		0.005052
  validation loss:		0.563484
  validation accuracy:		92.61 %
Epoch 1521 of 2000 took 0.057s
  training loss:		0.005301
  validation loss:		0.572925
  validation accuracy:		92.50 %
Epoch 1522 of 2000 took 0.056s
  training loss:		0.005082
  validation loss:		0.572729
  validation accuracy:		92.61 %
Epoch 1523 of 2000 took 0.057s
  training loss:		0.005184
  validation loss:		0.571312
  validation accuracy:		92.50 %
Epoch 1524 of 2000 took 0.056s
  training loss:		0.005129
  validation loss:		0.572190
  validation accuracy:		92.39 %
Epoch 1525 of 2000 took 0.057s
  training loss:		0.005142
  validation loss:		0.577891
  validation accuracy:		92.39 %
Epoch 1526 of 2000 took 0.057s
  training loss:		0.005098
  validation loss:		0.572927
  validation accuracy:		92.50 %
Epoch 1527 of 2000 took 0.057s
  training loss:		0.005166
  validation loss:		0.573530
  validation accuracy:		92.50 %
Epoch 1528 of 2000 took 0.057s
  training loss:		0.005234
  validation loss:		0.573382
  validation accuracy:		92.39 %
Epoch 1529 of 2000 took 0.057s
  training loss:		0.005279
  validation loss:		0.573526
  validation accuracy:		92.28 %
Epoch 1530 of 2000 took 0.057s
  training loss:		0.005326
  validation loss:		0.573681
  validation accuracy:		92.61 %
Epoch 1531 of 2000 took 0.057s
  training loss:		0.005194
  validation loss:		0.586523
  validation accuracy:		92.17 %
Epoch 1532 of 2000 took 0.057s
  training loss:		0.005121
  validation loss:		0.569760
  validation accuracy:		92.50 %
Epoch 1533 of 2000 took 0.057s
  training loss:		0.005282
  validation loss:		0.579904
  validation accuracy:		92.39 %
Epoch 1534 of 2000 took 0.055s
  training loss:		0.005353
  validation loss:		0.575533
  validation accuracy:		92.28 %
Epoch 1535 of 2000 took 0.055s
  training loss:		0.005331
  validation loss:		0.580192
  validation accuracy:		92.39 %
Epoch 1536 of 2000 took 0.056s
  training loss:		0.005202
  validation loss:		0.571539
  validation accuracy:		92.61 %
Epoch 1537 of 2000 took 0.055s
  training loss:		0.005171
  validation loss:		0.584163
  validation accuracy:		92.17 %
Epoch 1538 of 2000 took 0.053s
  training loss:		0.005091
  validation loss:		0.574403
  validation accuracy:		92.39 %
Epoch 1539 of 2000 took 0.055s
  training loss:		0.004973
  validation loss:		0.586244
  validation accuracy:		92.28 %
Epoch 1540 of 2000 took 0.056s
  training loss:		0.005279
  validation loss:		0.576198
  validation accuracy:		92.61 %
Epoch 1541 of 2000 took 0.054s
  training loss:		0.005015
  validation loss:		0.569637
  validation accuracy:		92.61 %
Epoch 1542 of 2000 took 0.055s
  training loss:		0.005180
  validation loss:		0.575104
  validation accuracy:		92.50 %
Epoch 1543 of 2000 took 0.054s
  training loss:		0.005231
  validation loss:		0.580819
  validation accuracy:		92.39 %
Epoch 1544 of 2000 took 0.056s
  training loss:		0.005224
  validation loss:		0.587609
  validation accuracy:		92.39 %
Epoch 1545 of 2000 took 0.054s
  training loss:		0.005128
  validation loss:		0.582518
  validation accuracy:		92.50 %
Epoch 1546 of 2000 took 0.056s
  training loss:		0.005022
  validation loss:		0.574571
  validation accuracy:		92.28 %
Epoch 1547 of 2000 took 0.054s
  training loss:		0.004999
  validation loss:		0.584017
  validation accuracy:		92.50 %
Epoch 1548 of 2000 took 0.058s
  training loss:		0.005091
  validation loss:		0.584379
  validation accuracy:		92.39 %
Epoch 1549 of 2000 took 0.057s
  training loss:		0.005268
  validation loss:		0.579736
  validation accuracy:		92.50 %
Epoch 1550 of 2000 took 0.055s
  training loss:		0.005008
  validation loss:		0.576144
  validation accuracy:		92.50 %
Epoch 1551 of 2000 took 0.056s
  training loss:		0.005113
  validation loss:		0.578074
  validation accuracy:		92.39 %
Epoch 1552 of 2000 took 0.055s
  training loss:		0.004903
  validation loss:		0.577613
  validation accuracy:		92.39 %
Epoch 1553 of 2000 took 0.056s
  training loss:		0.005171
  validation loss:		0.572126
  validation accuracy:		92.61 %
Epoch 1554 of 2000 took 0.058s
  training loss:		0.005049
  validation loss:		0.580931
  validation accuracy:		92.39 %
Epoch 1555 of 2000 took 0.057s
  training loss:		0.004945
  validation loss:		0.578979
  validation accuracy:		92.39 %
Epoch 1556 of 2000 took 0.056s
  training loss:		0.004992
  validation loss:		0.576973
  validation accuracy:		92.28 %
Epoch 1557 of 2000 took 0.058s
  training loss:		0.005048
  validation loss:		0.584404
  validation accuracy:		92.39 %
Epoch 1558 of 2000 took 0.058s
  training loss:		0.005001
  validation loss:		0.578938
  validation accuracy:		92.39 %
Epoch 1559 of 2000 took 0.058s
  training loss:		0.004960
  validation loss:		0.568124
  validation accuracy:		92.39 %
Epoch 1560 of 2000 took 0.058s
  training loss:		0.005016
  validation loss:		0.580085
  validation accuracy:		92.50 %
Epoch 1561 of 2000 took 0.058s
  training loss:		0.004901
  validation loss:		0.575858
  validation accuracy:		92.39 %
Epoch 1562 of 2000 took 0.058s
  training loss:		0.005002
  validation loss:		0.572267
  validation accuracy:		92.39 %
Epoch 1563 of 2000 took 0.058s
  training loss:		0.004828
  validation loss:		0.579857
  validation accuracy:		92.39 %
Epoch 1564 of 2000 took 0.058s
  training loss:		0.004902
  validation loss:		0.576757
  validation accuracy:		92.39 %
Epoch 1565 of 2000 took 0.057s
  training loss:		0.004902
  validation loss:		0.581699
  validation accuracy:		92.39 %
Epoch 1566 of 2000 took 0.055s
  training loss:		0.004906
  validation loss:		0.578351
  validation accuracy:		92.39 %
Epoch 1567 of 2000 took 0.055s
  training loss:		0.004958
  validation loss:		0.580959
  validation accuracy:		92.39 %
Epoch 1568 of 2000 took 0.057s
  training loss:		0.004849
  validation loss:		0.578215
  validation accuracy:		92.39 %
Epoch 1569 of 2000 took 0.057s
  training loss:		0.004747
  validation loss:		0.579074
  validation accuracy:		92.50 %
Epoch 1570 of 2000 took 0.057s
  training loss:		0.004958
  validation loss:		0.579631
  validation accuracy:		92.28 %
Epoch 1571 of 2000 took 0.057s
  training loss:		0.004812
  validation loss:		0.581414
  validation accuracy:		92.28 %
Epoch 1572 of 2000 took 0.056s
  training loss:		0.004803
  validation loss:		0.584844
  validation accuracy:		92.50 %
Epoch 1573 of 2000 took 0.056s
  training loss:		0.004904
  validation loss:		0.585025
  validation accuracy:		92.50 %
Epoch 1574 of 2000 took 0.056s
  training loss:		0.004820
  validation loss:		0.592363
  validation accuracy:		92.17 %
Epoch 1575 of 2000 took 0.056s
  training loss:		0.004781
  validation loss:		0.576836
  validation accuracy:		92.50 %
Epoch 1576 of 2000 took 0.055s
  training loss:		0.004811
  validation loss:		0.589946
  validation accuracy:		92.50 %
Epoch 1577 of 2000 took 0.055s
  training loss:		0.004842
  validation loss:		0.572189
  validation accuracy:		92.72 %
Epoch 1578 of 2000 took 0.054s
  training loss:		0.004941
  validation loss:		0.578866
  validation accuracy:		92.50 %
Epoch 1579 of 2000 took 0.055s
  training loss:		0.004611
  validation loss:		0.578818
  validation accuracy:		92.50 %
Epoch 1580 of 2000 took 0.058s
  training loss:		0.004729
  validation loss:		0.586463
  validation accuracy:		92.39 %
Epoch 1581 of 2000 took 0.058s
  training loss:		0.004832
  validation loss:		0.578204
  validation accuracy:		92.50 %
Epoch 1582 of 2000 took 0.057s
  training loss:		0.004925
  validation loss:		0.575061
  validation accuracy:		92.61 %
Epoch 1583 of 2000 took 0.057s
  training loss:		0.004983
  validation loss:		0.586288
  validation accuracy:		92.39 %
Epoch 1584 of 2000 took 0.055s
  training loss:		0.004862
  validation loss:		0.586517
  validation accuracy:		92.50 %
Epoch 1585 of 2000 took 0.055s
  training loss:		0.004612
  validation loss:		0.583995
  validation accuracy:		92.50 %
Epoch 1586 of 2000 took 0.055s
  training loss:		0.004695
  validation loss:		0.574889
  validation accuracy:		92.50 %
Epoch 1587 of 2000 took 0.056s
  training loss:		0.004755
  validation loss:		0.588097
  validation accuracy:		92.50 %
Epoch 1588 of 2000 took 0.055s
  training loss:		0.004761
  validation loss:		0.584412
  validation accuracy:		92.50 %
Epoch 1589 of 2000 took 0.056s
  training loss:		0.004729
  validation loss:		0.584398
  validation accuracy:		92.50 %
Epoch 1590 of 2000 took 0.055s
  training loss:		0.004670
  validation loss:		0.587800
  validation accuracy:		92.50 %
Epoch 1591 of 2000 took 0.056s
  training loss:		0.004792
  validation loss:		0.583399
  validation accuracy:		92.39 %
Epoch 1592 of 2000 took 0.055s
  training loss:		0.004521
  validation loss:		0.583908
  validation accuracy:		92.61 %
Epoch 1593 of 2000 took 0.057s
  training loss:		0.004679
  validation loss:		0.589846
  validation accuracy:		92.39 %
Epoch 1594 of 2000 took 0.058s
  training loss:		0.004599
  validation loss:		0.578500
  validation accuracy:		92.50 %
Epoch 1595 of 2000 took 0.057s
  training loss:		0.004753
  validation loss:		0.590253
  validation accuracy:		92.39 %
Epoch 1596 of 2000 took 0.055s
  training loss:		0.004618
  validation loss:		0.589583
  validation accuracy:		92.17 %
Epoch 1597 of 2000 took 0.056s
  training loss:		0.004830
  validation loss:		0.582576
  validation accuracy:		92.50 %
Epoch 1598 of 2000 took 0.058s
  training loss:		0.004533
  validation loss:		0.591535
  validation accuracy:		92.28 %
Epoch 1599 of 2000 took 0.058s
  training loss:		0.004671
  validation loss:		0.581554
  validation accuracy:		92.28 %
Epoch 1600 of 2000 took 0.058s
  training loss:		0.004492
  validation loss:		0.588497
  validation accuracy:		92.50 %
Epoch 1601 of 2000 took 0.058s
  training loss:		0.004667
  validation loss:		0.593730
  validation accuracy:		92.39 %
Epoch 1602 of 2000 took 0.056s
  training loss:		0.004687
  validation loss:		0.584290
  validation accuracy:		92.39 %
Epoch 1603 of 2000 took 0.057s
  training loss:		0.004700
  validation loss:		0.589316
  validation accuracy:		92.39 %
Epoch 1604 of 2000 took 0.056s
  training loss:		0.004719
  validation loss:		0.595622
  validation accuracy:		92.28 %
Epoch 1605 of 2000 took 0.057s
  training loss:		0.004834
  validation loss:		0.585930
  validation accuracy:		92.39 %
Epoch 1606 of 2000 took 0.057s
  training loss:		0.004615
  validation loss:		0.577300
  validation accuracy:		92.39 %
Epoch 1607 of 2000 took 0.057s
  training loss:		0.004620
  validation loss:		0.586919
  validation accuracy:		92.39 %
Epoch 1608 of 2000 took 0.056s
  training loss:		0.004577
  validation loss:		0.590523
  validation accuracy:		92.50 %
Epoch 1609 of 2000 took 0.056s
  training loss:		0.004627
  validation loss:		0.595191
  validation accuracy:		92.39 %
Epoch 1610 of 2000 took 0.056s
  training loss:		0.004649
  validation loss:		0.589947
  validation accuracy:		92.39 %
Epoch 1611 of 2000 took 0.056s
  training loss:		0.004547
  validation loss:		0.586990
  validation accuracy:		92.50 %
Epoch 1612 of 2000 took 0.056s
  training loss:		0.004615
  validation loss:		0.586676
  validation accuracy:		92.61 %
Epoch 1613 of 2000 took 0.055s
  training loss:		0.004554
  validation loss:		0.584552
  validation accuracy:		92.39 %
Epoch 1614 of 2000 took 0.056s
  training loss:		0.004497
  validation loss:		0.591826
  validation accuracy:		92.39 %
Epoch 1615 of 2000 took 0.055s
  training loss:		0.004583
  validation loss:		0.588574
  validation accuracy:		92.50 %
Epoch 1616 of 2000 took 0.058s
  training loss:		0.004577
  validation loss:		0.585611
  validation accuracy:		92.28 %
Epoch 1617 of 2000 took 0.058s
  training loss:		0.004529
  validation loss:		0.587098
  validation accuracy:		92.39 %
Epoch 1618 of 2000 took 0.057s
  training loss:		0.004478
  validation loss:		0.589294
  validation accuracy:		92.61 %
Epoch 1619 of 2000 took 0.056s
  training loss:		0.004426
  validation loss:		0.587939
  validation accuracy:		92.50 %
Epoch 1620 of 2000 took 0.058s
  training loss:		0.004543
  validation loss:		0.594739
  validation accuracy:		92.50 %
Epoch 1621 of 2000 took 0.058s
  training loss:		0.004571
  validation loss:		0.587425
  validation accuracy:		92.39 %
Epoch 1622 of 2000 took 0.057s
  training loss:		0.004533
  validation loss:		0.587070
  validation accuracy:		92.50 %
Epoch 1623 of 2000 took 0.058s
  training loss:		0.004485
  validation loss:		0.592763
  validation accuracy:		92.28 %
Epoch 1624 of 2000 took 0.056s
  training loss:		0.004358
  validation loss:		0.593542
  validation accuracy:		92.50 %
Epoch 1625 of 2000 took 0.054s
  training loss:		0.004610
  validation loss:		0.600186
  validation accuracy:		92.28 %
Epoch 1626 of 2000 took 0.056s
  training loss:		0.004649
  validation loss:		0.586228
  validation accuracy:		92.50 %
Epoch 1627 of 2000 took 0.057s
  training loss:		0.004464
  validation loss:		0.586774
  validation accuracy:		92.61 %
Epoch 1628 of 2000 took 0.056s
  training loss:		0.004396
  validation loss:		0.581771
  validation accuracy:		92.50 %
Epoch 1629 of 2000 took 0.055s
  training loss:		0.004561
  validation loss:		0.596639
  validation accuracy:		92.50 %
Epoch 1630 of 2000 took 0.053s
  training loss:		0.004515
  validation loss:		0.587074
  validation accuracy:		92.50 %
Epoch 1631 of 2000 took 0.057s
  training loss:		0.004507
  validation loss:		0.592136
  validation accuracy:		92.61 %
Epoch 1632 of 2000 took 0.057s
  training loss:		0.004525
  validation loss:		0.589385
  validation accuracy:		92.39 %
Epoch 1633 of 2000 took 0.054s
  training loss:		0.004399
  validation loss:		0.590183
  validation accuracy:		92.50 %
Epoch 1634 of 2000 took 0.056s
  training loss:		0.004598
  validation loss:		0.591313
  validation accuracy:		92.50 %
Epoch 1635 of 2000 took 0.057s
  training loss:		0.004340
  validation loss:		0.592373
  validation accuracy:		92.39 %
Epoch 1636 of 2000 took 0.055s
  training loss:		0.004359
  validation loss:		0.597163
  validation accuracy:		92.28 %
Epoch 1637 of 2000 took 0.055s
  training loss:		0.004442
  validation loss:		0.590142
  validation accuracy:		92.28 %
Epoch 1638 of 2000 took 0.057s
  training loss:		0.004325
  validation loss:		0.592185
  validation accuracy:		92.50 %
Epoch 1639 of 2000 took 0.057s
  training loss:		0.004442
  validation loss:		0.597003
  validation accuracy:		92.50 %
Epoch 1640 of 2000 took 0.056s
  training loss:		0.004245
  validation loss:		0.593596
  validation accuracy:		92.39 %
Epoch 1641 of 2000 took 0.054s
  training loss:		0.004556
  validation loss:		0.588110
  validation accuracy:		92.39 %
Epoch 1642 of 2000 took 0.056s
  training loss:		0.004337
  validation loss:		0.596258
  validation accuracy:		92.50 %
Epoch 1643 of 2000 took 0.054s
  training loss:		0.004334
  validation loss:		0.596629
  validation accuracy:		92.28 %
Epoch 1644 of 2000 took 0.056s
  training loss:		0.004362
  validation loss:		0.591901
  validation accuracy:		92.39 %
Epoch 1645 of 2000 took 0.057s
  training loss:		0.004399
  validation loss:		0.588960
  validation accuracy:		92.39 %
Epoch 1646 of 2000 took 0.057s
  training loss:		0.004427
  validation loss:		0.598682
  validation accuracy:		92.39 %
Epoch 1647 of 2000 took 0.057s
  training loss:		0.004371
  validation loss:		0.594454
  validation accuracy:		92.39 %
Epoch 1648 of 2000 took 0.057s
  training loss:		0.004429
  validation loss:		0.600282
  validation accuracy:		92.39 %
Epoch 1649 of 2000 took 0.057s
  training loss:		0.004255
  validation loss:		0.599952
  validation accuracy:		92.39 %
Epoch 1650 of 2000 took 0.057s
  training loss:		0.004468
  validation loss:		0.591554
  validation accuracy:		92.28 %
Epoch 1651 of 2000 took 0.058s
  training loss:		0.004259
  validation loss:		0.596113
  validation accuracy:		92.50 %
Epoch 1652 of 2000 took 0.058s
  training loss:		0.004339
  validation loss:		0.589205
  validation accuracy:		92.72 %
Epoch 1653 of 2000 took 0.058s
  training loss:		0.004212
  validation loss:		0.600426
  validation accuracy:		92.50 %
Epoch 1654 of 2000 took 0.058s
  training loss:		0.004248
  validation loss:		0.597817
  validation accuracy:		92.61 %
Epoch 1655 of 2000 took 0.057s
  training loss:		0.004320
  validation loss:		0.596926
  validation accuracy:		92.39 %
Epoch 1656 of 2000 took 0.057s
  training loss:		0.004220
  validation loss:		0.600022
  validation accuracy:		92.50 %
Epoch 1657 of 2000 took 0.057s
  training loss:		0.004247
  validation loss:		0.603258
  validation accuracy:		92.39 %
Epoch 1658 of 2000 took 0.057s
  training loss:		0.004241
  validation loss:		0.596717
  validation accuracy:		92.50 %
Epoch 1659 of 2000 took 0.057s
  training loss:		0.004273
  validation loss:		0.598796
  validation accuracy:		92.28 %
Epoch 1660 of 2000 took 0.057s
  training loss:		0.004172
  validation loss:		0.586800
  validation accuracy:		92.39 %
Epoch 1661 of 2000 took 0.057s
  training loss:		0.004302
  validation loss:		0.596807
  validation accuracy:		92.28 %
Epoch 1662 of 2000 took 0.057s
  training loss:		0.004307
  validation loss:		0.594773
  validation accuracy:		92.50 %
Epoch 1663 of 2000 took 0.057s
  training loss:		0.004197
  validation loss:		0.587294
  validation accuracy:		92.39 %
Epoch 1664 of 2000 took 0.057s
  training loss:		0.004397
  validation loss:		0.598650
  validation accuracy:		92.50 %
Epoch 1665 of 2000 took 0.058s
  training loss:		0.004267
  validation loss:		0.592929
  validation accuracy:		92.50 %
Epoch 1666 of 2000 took 0.057s
  training loss:		0.004244
  validation loss:		0.603868
  validation accuracy:		92.50 %
Epoch 1667 of 2000 took 0.056s
  training loss:		0.004448
  validation loss:		0.597205
  validation accuracy:		92.61 %
Epoch 1668 of 2000 took 0.054s
  training loss:		0.004222
  validation loss:		0.603382
  validation accuracy:		92.28 %
Epoch 1669 of 2000 took 0.056s
  training loss:		0.004238
  validation loss:		0.594028
  validation accuracy:		92.61 %
Epoch 1670 of 2000 took 0.057s
  training loss:		0.004196
  validation loss:		0.596509
  validation accuracy:		92.39 %
Epoch 1671 of 2000 took 0.056s
  training loss:		0.004125
  validation loss:		0.596973
  validation accuracy:		92.28 %
Epoch 1672 of 2000 took 0.057s
  training loss:		0.004228
  validation loss:		0.593809
  validation accuracy:		92.61 %
Epoch 1673 of 2000 took 0.057s
  training loss:		0.004174
  validation loss:		0.602634
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.057s
  training loss:		0.004265
  validation loss:		0.601204
  validation accuracy:		92.28 %
Epoch 1675 of 2000 took 0.056s
  training loss:		0.004189
  validation loss:		0.593082
  validation accuracy:		92.39 %
Epoch 1676 of 2000 took 0.057s
  training loss:		0.004184
  validation loss:		0.602161
  validation accuracy:		92.39 %
Epoch 1677 of 2000 took 0.057s
  training loss:		0.004116
  validation loss:		0.595915
  validation accuracy:		92.28 %
Epoch 1678 of 2000 took 0.057s
  training loss:		0.004047
  validation loss:		0.600650
  validation accuracy:		92.28 %
Epoch 1679 of 2000 took 0.057s
  training loss:		0.004161
  validation loss:		0.602588
  validation accuracy:		92.28 %
Epoch 1680 of 2000 took 0.057s
  training loss:		0.004260
  validation loss:		0.603319
  validation accuracy:		92.50 %
Epoch 1681 of 2000 took 0.057s
  training loss:		0.003979
  validation loss:		0.598215
  validation accuracy:		92.61 %
Epoch 1682 of 2000 took 0.057s
  training loss:		0.004095
  validation loss:		0.601437
  validation accuracy:		92.28 %
Epoch 1683 of 2000 took 0.057s
  training loss:		0.004047
  validation loss:		0.601648
  validation accuracy:		92.50 %
Epoch 1684 of 2000 took 0.056s
  training loss:		0.004120
  validation loss:		0.596480
  validation accuracy:		92.39 %
Epoch 1685 of 2000 took 0.057s
  training loss:		0.004267
  validation loss:		0.605560
  validation accuracy:		92.17 %
Epoch 1686 of 2000 took 0.057s
  training loss:		0.004127
  validation loss:		0.598591
  validation accuracy:		92.50 %
Epoch 1687 of 2000 took 0.057s
  training loss:		0.004118
  validation loss:		0.593298
  validation accuracy:		92.39 %
Epoch 1688 of 2000 took 0.057s
  training loss:		0.004334
  validation loss:		0.600027
  validation accuracy:		92.28 %
Epoch 1689 of 2000 took 0.057s
  training loss:		0.004035
  validation loss:		0.600687
  validation accuracy:		92.39 %
Epoch 1690 of 2000 took 0.057s
  training loss:		0.004119
  validation loss:		0.602681
  validation accuracy:		92.50 %
Epoch 1691 of 2000 took 0.057s
  training loss:		0.004102
  validation loss:		0.598204
  validation accuracy:		92.28 %
Epoch 1692 of 2000 took 0.055s
  training loss:		0.004114
  validation loss:		0.598946
  validation accuracy:		92.61 %
Epoch 1693 of 2000 took 0.057s
  training loss:		0.004225
  validation loss:		0.608618
  validation accuracy:		92.50 %
Epoch 1694 of 2000 took 0.055s
  training loss:		0.004061
  validation loss:		0.602506
  validation accuracy:		92.61 %
Epoch 1695 of 2000 took 0.057s
  training loss:		0.004051
  validation loss:		0.607718
  validation accuracy:		92.39 %
Epoch 1696 of 2000 took 0.057s
  training loss:		0.004044
  validation loss:		0.606740
  validation accuracy:		92.50 %
Epoch 1697 of 2000 took 0.057s
  training loss:		0.004096
  validation loss:		0.605293
  validation accuracy:		92.39 %
Epoch 1698 of 2000 took 0.057s
  training loss:		0.003926
  validation loss:		0.599971
  validation accuracy:		92.61 %
Epoch 1699 of 2000 took 0.057s
  training loss:		0.004041
  validation loss:		0.608714
  validation accuracy:		92.28 %
Epoch 1700 of 2000 took 0.055s
  training loss:		0.003973
  validation loss:		0.608038
  validation accuracy:		92.50 %
Epoch 1701 of 2000 took 0.057s
  training loss:		0.003980
  validation loss:		0.604729
  validation accuracy:		92.50 %
Epoch 1702 of 2000 took 0.055s
  training loss:		0.004059
  validation loss:		0.603007
  validation accuracy:		92.50 %
Epoch 1703 of 2000 took 0.056s
  training loss:		0.004040
  validation loss:		0.606765
  validation accuracy:		92.28 %
Epoch 1704 of 2000 took 0.056s
  training loss:		0.003986
  validation loss:		0.606067
  validation accuracy:		92.61 %
Epoch 1705 of 2000 took 0.056s
  training loss:		0.004001
  validation loss:		0.600377
  validation accuracy:		92.39 %
Epoch 1706 of 2000 took 0.057s
  training loss:		0.003990
  validation loss:		0.604652
  validation accuracy:		92.61 %
Epoch 1707 of 2000 took 0.056s
  training loss:		0.004089
  validation loss:		0.610806
  validation accuracy:		92.17 %
Epoch 1708 of 2000 took 0.056s
  training loss:		0.003903
  validation loss:		0.606341
  validation accuracy:		92.50 %
Epoch 1709 of 2000 took 0.056s
  training loss:		0.003947
  validation loss:		0.603961
  validation accuracy:		92.39 %
Epoch 1710 of 2000 took 0.057s
  training loss:		0.004041
  validation loss:		0.607369
  validation accuracy:		92.39 %
Epoch 1711 of 2000 took 0.055s
  training loss:		0.003915
  validation loss:		0.610431
  validation accuracy:		92.50 %
Epoch 1712 of 2000 took 0.055s
  training loss:		0.003920
  validation loss:		0.607917
  validation accuracy:		92.50 %
Epoch 1713 of 2000 took 0.055s
  training loss:		0.004038
  validation loss:		0.608017
  validation accuracy:		92.39 %
Epoch 1714 of 2000 took 0.057s
  training loss:		0.003890
  validation loss:		0.606783
  validation accuracy:		92.28 %
Epoch 1715 of 2000 took 0.056s
  training loss:		0.004071
  validation loss:		0.601989
  validation accuracy:		92.39 %
Epoch 1716 of 2000 took 0.057s
  training loss:		0.003934
  validation loss:		0.600487
  validation accuracy:		92.39 %
Epoch 1717 of 2000 took 0.056s
  training loss:		0.003982
  validation loss:		0.609387
  validation accuracy:		92.50 %
Epoch 1718 of 2000 took 0.055s
  training loss:		0.003830
  validation loss:		0.604469
  validation accuracy:		92.50 %
Epoch 1719 of 2000 took 0.058s
  training loss:		0.004040
  validation loss:		0.597124
  validation accuracy:		92.39 %
Epoch 1720 of 2000 took 0.056s
  training loss:		0.003944
  validation loss:		0.606397
  validation accuracy:		92.50 %
Epoch 1721 of 2000 took 0.056s
  training loss:		0.003955
  validation loss:		0.606850
  validation accuracy:		92.28 %
Epoch 1722 of 2000 took 0.057s
  training loss:		0.003989
  validation loss:		0.612003
  validation accuracy:		92.61 %
Epoch 1723 of 2000 took 0.057s
  training loss:		0.003876
  validation loss:		0.604324
  validation accuracy:		92.39 %
Epoch 1724 of 2000 took 0.058s
  training loss:		0.003807
  validation loss:		0.600869
  validation accuracy:		92.28 %
Epoch 1725 of 2000 took 0.058s
  training loss:		0.003882
  validation loss:		0.605222
  validation accuracy:		92.50 %
Epoch 1726 of 2000 took 0.057s
  training loss:		0.003848
  validation loss:		0.615946
  validation accuracy:		92.50 %
Epoch 1727 of 2000 took 0.057s
  training loss:		0.003842
  validation loss:		0.602438
  validation accuracy:		92.61 %
Epoch 1728 of 2000 took 0.054s
  training loss:		0.004026
  validation loss:		0.605613
  validation accuracy:		92.50 %
Epoch 1729 of 2000 took 0.056s
  training loss:		0.003904
  validation loss:		0.612015
  validation accuracy:		92.50 %
Epoch 1730 of 2000 took 0.055s
  training loss:		0.003942
  validation loss:		0.604189
  validation accuracy:		92.39 %
Epoch 1731 of 2000 took 0.056s
  training loss:		0.003874
  validation loss:		0.607177
  validation accuracy:		92.39 %
Epoch 1732 of 2000 took 0.058s
  training loss:		0.003779
  validation loss:		0.613373
  validation accuracy:		92.28 %
Epoch 1733 of 2000 took 0.057s
  training loss:		0.003995
  validation loss:		0.607011
  validation accuracy:		92.50 %
Epoch 1734 of 2000 took 0.057s
  training loss:		0.003878
  validation loss:		0.613435
  validation accuracy:		92.50 %
Epoch 1735 of 2000 took 0.056s
  training loss:		0.003841
  validation loss:		0.605361
  validation accuracy:		92.39 %
Epoch 1736 of 2000 took 0.056s
  training loss:		0.003702
  validation loss:		0.604546
  validation accuracy:		92.50 %
Epoch 1737 of 2000 took 0.057s
  training loss:		0.003899
  validation loss:		0.610998
  validation accuracy:		92.28 %
Epoch 1738 of 2000 took 0.058s
  training loss:		0.003888
  validation loss:		0.609900
  validation accuracy:		92.61 %
Epoch 1739 of 2000 took 0.059s
  training loss:		0.003751
  validation loss:		0.607683
  validation accuracy:		92.39 %
Epoch 1740 of 2000 took 0.059s
  training loss:		0.003763
  validation loss:		0.620423
  validation accuracy:		92.28 %
Epoch 1741 of 2000 took 0.058s
  training loss:		0.003694
  validation loss:		0.611563
  validation accuracy:		92.50 %
Epoch 1742 of 2000 took 0.059s
  training loss:		0.003787
  validation loss:		0.610368
  validation accuracy:		92.61 %
Epoch 1743 of 2000 took 0.058s
  training loss:		0.003854
  validation loss:		0.610374
  validation accuracy:		92.39 %
Epoch 1744 of 2000 took 0.059s
  training loss:		0.003844
  validation loss:		0.609699
  validation accuracy:		92.28 %
Epoch 1745 of 2000 took 0.058s
  training loss:		0.003742
  validation loss:		0.610947
  validation accuracy:		92.61 %
Epoch 1746 of 2000 took 0.058s
  training loss:		0.003901
  validation loss:		0.611354
  validation accuracy:		92.28 %
Epoch 1747 of 2000 took 0.058s
  training loss:		0.003735
  validation loss:		0.607873
  validation accuracy:		92.28 %
Epoch 1748 of 2000 took 0.059s
  training loss:		0.003844
  validation loss:		0.609938
  validation accuracy:		92.28 %
Epoch 1749 of 2000 took 0.058s
  training loss:		0.003767
  validation loss:		0.608565
  validation accuracy:		92.50 %
Epoch 1750 of 2000 took 0.059s
  training loss:		0.003803
  validation loss:		0.618811
  validation accuracy:		92.50 %
Epoch 1751 of 2000 took 0.057s
  training loss:		0.003860
  validation loss:		0.609631
  validation accuracy:		92.61 %
Epoch 1752 of 2000 took 0.057s
  training loss:		0.003771
  validation loss:		0.607543
  validation accuracy:		92.39 %
Epoch 1753 of 2000 took 0.055s
  training loss:		0.003764
  validation loss:		0.610198
  validation accuracy:		92.28 %
Epoch 1754 of 2000 took 0.057s
  training loss:		0.003680
  validation loss:		0.612189
  validation accuracy:		92.50 %
Epoch 1755 of 2000 took 0.057s
  training loss:		0.003633
  validation loss:		0.613583
  validation accuracy:		92.28 %
Epoch 1756 of 2000 took 0.057s
  training loss:		0.003789
  validation loss:		0.608678
  validation accuracy:		92.39 %
Epoch 1757 of 2000 took 0.057s
  training loss:		0.003820
  validation loss:		0.608652
  validation accuracy:		92.61 %
Epoch 1758 of 2000 took 0.057s
  training loss:		0.003766
  validation loss:		0.613651
  validation accuracy:		92.39 %
Epoch 1759 of 2000 took 0.057s
  training loss:		0.003671
  validation loss:		0.617186
  validation accuracy:		92.39 %
Epoch 1760 of 2000 took 0.057s
  training loss:		0.003717
  validation loss:		0.606995
  validation accuracy:		92.39 %
Epoch 1761 of 2000 took 0.057s
  training loss:		0.003771
  validation loss:		0.615722
  validation accuracy:		92.28 %
Epoch 1762 of 2000 took 0.057s
  training loss:		0.003632
  validation loss:		0.616331
  validation accuracy:		92.50 %
Epoch 1763 of 2000 took 0.057s
  training loss:		0.003686
  validation loss:		0.610375
  validation accuracy:		92.50 %
Epoch 1764 of 2000 took 0.057s
  training loss:		0.003740
  validation loss:		0.618862
  validation accuracy:		92.50 %
Epoch 1765 of 2000 took 0.057s
  training loss:		0.003765
  validation loss:		0.612879
  validation accuracy:		92.39 %
Epoch 1766 of 2000 took 0.057s
  training loss:		0.003761
  validation loss:		0.613681
  validation accuracy:		92.39 %
Epoch 1767 of 2000 took 0.057s
  training loss:		0.003648
  validation loss:		0.613796
  validation accuracy:		92.61 %
Epoch 1768 of 2000 took 0.057s
  training loss:		0.003735
  validation loss:		0.611108
  validation accuracy:		92.61 %
Epoch 1769 of 2000 took 0.057s
  training loss:		0.003637
  validation loss:		0.620509
  validation accuracy:		92.39 %
Epoch 1770 of 2000 took 0.056s
  training loss:		0.003723
  validation loss:		0.612697
  validation accuracy:		92.61 %
Epoch 1771 of 2000 took 0.057s
  training loss:		0.003670
  validation loss:		0.612112
  validation accuracy:		92.39 %
Epoch 1772 of 2000 took 0.057s
  training loss:		0.003608
  validation loss:		0.612181
  validation accuracy:		92.39 %
Epoch 1773 of 2000 took 0.057s
  training loss:		0.003552
  validation loss:		0.611489
  validation accuracy:		92.39 %
Epoch 1774 of 2000 took 0.057s
  training loss:		0.003714
  validation loss:		0.611422
  validation accuracy:		92.39 %
Epoch 1775 of 2000 took 0.057s
  training loss:		0.003565
  validation loss:		0.612404
  validation accuracy:		92.50 %
Epoch 1776 of 2000 took 0.057s
  training loss:		0.003588
  validation loss:		0.617829
  validation accuracy:		92.39 %
Epoch 1777 of 2000 took 0.057s
  training loss:		0.003609
  validation loss:		0.620713
  validation accuracy:		92.28 %
Epoch 1778 of 2000 took 0.057s
  training loss:		0.003723
  validation loss:		0.613368
  validation accuracy:		92.61 %
Epoch 1779 of 2000 took 0.057s
  training loss:		0.003748
  validation loss:		0.611630
  validation accuracy:		92.39 %
Epoch 1780 of 2000 took 0.057s
  training loss:		0.003635
  validation loss:		0.616592
  validation accuracy:		92.39 %
Epoch 1781 of 2000 took 0.056s
  training loss:		0.003638
  validation loss:		0.611213
  validation accuracy:		92.50 %
Epoch 1782 of 2000 took 0.057s
  training loss:		0.003571
  validation loss:		0.615291
  validation accuracy:		92.39 %
Epoch 1783 of 2000 took 0.057s
  training loss:		0.003645
  validation loss:		0.614992
  validation accuracy:		92.50 %
Epoch 1784 of 2000 took 0.057s
  training loss:		0.003689
  validation loss:		0.617406
  validation accuracy:		92.39 %
Epoch 1785 of 2000 took 0.057s
  training loss:		0.003574
  validation loss:		0.616508
  validation accuracy:		92.50 %
Epoch 1786 of 2000 took 0.057s
  training loss:		0.003634
  validation loss:		0.612615
  validation accuracy:		92.39 %
Epoch 1787 of 2000 took 0.057s
  training loss:		0.003604
  validation loss:		0.610998
  validation accuracy:		92.39 %
Epoch 1788 of 2000 took 0.057s
  training loss:		0.003576
  validation loss:		0.617648
  validation accuracy:		92.50 %
Epoch 1789 of 2000 took 0.057s
  training loss:		0.003569
  validation loss:		0.624939
  validation accuracy:		92.39 %
Epoch 1790 of 2000 took 0.057s
  training loss:		0.003561
  validation loss:		0.621594
  validation accuracy:		92.61 %
Epoch 1791 of 2000 took 0.057s
  training loss:		0.003555
  validation loss:		0.615306
  validation accuracy:		92.39 %
Epoch 1792 of 2000 took 0.057s
  training loss:		0.003569
  validation loss:		0.618143
  validation accuracy:		92.39 %
Epoch 1793 of 2000 took 0.056s
  training loss:		0.003665
  validation loss:		0.612121
  validation accuracy:		92.39 %
Epoch 1794 of 2000 took 0.057s
  training loss:		0.003613
  validation loss:		0.618264
  validation accuracy:		92.28 %
Epoch 1795 of 2000 took 0.057s
  training loss:		0.003518
  validation loss:		0.612396
  validation accuracy:		92.61 %
Epoch 1796 of 2000 took 0.057s
  training loss:		0.003552
  validation loss:		0.619469
  validation accuracy:		92.50 %
Epoch 1797 of 2000 took 0.057s
  training loss:		0.003600
  validation loss:		0.613388
  validation accuracy:		92.39 %
Epoch 1798 of 2000 took 0.057s
  training loss:		0.003581
  validation loss:		0.621225
  validation accuracy:		92.28 %
Epoch 1799 of 2000 took 0.057s
  training loss:		0.003559
  validation loss:		0.620084
  validation accuracy:		92.61 %
Epoch 1800 of 2000 took 0.057s
  training loss:		0.003630
  validation loss:		0.615302
  validation accuracy:		92.39 %
Epoch 1801 of 2000 took 0.056s
  training loss:		0.003483
  validation loss:		0.618705
  validation accuracy:		92.61 %
Epoch 1802 of 2000 took 0.057s
  training loss:		0.003522
  validation loss:		0.613672
  validation accuracy:		92.39 %
Epoch 1803 of 2000 took 0.057s
  training loss:		0.003554
  validation loss:		0.619814
  validation accuracy:		92.39 %
Epoch 1804 of 2000 took 0.057s
  training loss:		0.003549
  validation loss:		0.621627
  validation accuracy:		92.61 %
Epoch 1805 of 2000 took 0.057s
  training loss:		0.003489
  validation loss:		0.616962
  validation accuracy:		92.61 %
Epoch 1806 of 2000 took 0.057s
  training loss:		0.003556
  validation loss:		0.618603
  validation accuracy:		92.39 %
Epoch 1807 of 2000 took 0.056s
  training loss:		0.003521
  validation loss:		0.624097
  validation accuracy:		92.50 %
Epoch 1808 of 2000 took 0.057s
  training loss:		0.003479
  validation loss:		0.624644
  validation accuracy:		92.50 %
Epoch 1809 of 2000 took 0.057s
  training loss:		0.003497
  validation loss:		0.618179
  validation accuracy:		92.61 %
Epoch 1810 of 2000 took 0.057s
  training loss:		0.003637
  validation loss:		0.623699
  validation accuracy:		92.50 %
Epoch 1811 of 2000 took 0.057s
  training loss:		0.003496
  validation loss:		0.618141
  validation accuracy:		92.39 %
Epoch 1812 of 2000 took 0.057s
  training loss:		0.003485
  validation loss:		0.621859
  validation accuracy:		92.39 %
Epoch 1813 of 2000 took 0.057s
  training loss:		0.003477
  validation loss:		0.616232
  validation accuracy:		92.50 %
Epoch 1814 of 2000 took 0.057s
  training loss:		0.003601
  validation loss:		0.616791
  validation accuracy:		92.28 %
Epoch 1815 of 2000 took 0.057s
  training loss:		0.003584
  validation loss:		0.624143
  validation accuracy:		92.50 %
Epoch 1816 of 2000 took 0.057s
  training loss:		0.003436
  validation loss:		0.620205
  validation accuracy:		92.61 %
Epoch 1817 of 2000 took 0.057s
  training loss:		0.003411
  validation loss:		0.622069
  validation accuracy:		92.61 %
Epoch 1818 of 2000 took 0.057s
  training loss:		0.003467
  validation loss:		0.622521
  validation accuracy:		92.39 %
Epoch 1819 of 2000 took 0.057s
  training loss:		0.003396
  validation loss:		0.622102
  validation accuracy:		92.39 %
Epoch 1820 of 2000 took 0.056s
  training loss:		0.003469
  validation loss:		0.619768
  validation accuracy:		92.39 %
Epoch 1821 of 2000 took 0.059s
  training loss:		0.003505
  validation loss:		0.624426
  validation accuracy:		92.50 %
Epoch 1822 of 2000 took 0.057s
  training loss:		0.003498
  validation loss:		0.624891
  validation accuracy:		92.61 %
Epoch 1823 of 2000 took 0.057s
  training loss:		0.003414
  validation loss:		0.619994
  validation accuracy:		92.50 %
Epoch 1824 of 2000 took 0.057s
  training loss:		0.003331
  validation loss:		0.623066
  validation accuracy:		92.61 %
Epoch 1825 of 2000 took 0.057s
  training loss:		0.003485
  validation loss:		0.614011
  validation accuracy:		92.28 %
Epoch 1826 of 2000 took 0.057s
  training loss:		0.003468
  validation loss:		0.629631
  validation accuracy:		92.61 %
Epoch 1827 of 2000 took 0.057s
  training loss:		0.003432
  validation loss:		0.624567
  validation accuracy:		92.39 %
Epoch 1828 of 2000 took 0.057s
  training loss:		0.003445
  validation loss:		0.616561
  validation accuracy:		92.39 %
Epoch 1829 of 2000 took 0.057s
  training loss:		0.003378
  validation loss:		0.620894
  validation accuracy:		92.61 %
Epoch 1830 of 2000 took 0.057s
  training loss:		0.003436
  validation loss:		0.625359
  validation accuracy:		92.39 %
Epoch 1831 of 2000 took 0.057s
  training loss:		0.003383
  validation loss:		0.614793
  validation accuracy:		92.61 %
Epoch 1832 of 2000 took 0.057s
  training loss:		0.003510
  validation loss:		0.620375
  validation accuracy:		92.61 %
Epoch 1833 of 2000 took 0.057s
  training loss:		0.003379
  validation loss:		0.626387
  validation accuracy:		92.39 %
Epoch 1834 of 2000 took 0.057s
  training loss:		0.003340
  validation loss:		0.621548
  validation accuracy:		92.50 %
Epoch 1835 of 2000 took 0.055s
  training loss:		0.003412
  validation loss:		0.628733
  validation accuracy:		92.61 %
Epoch 1836 of 2000 took 0.054s
  training loss:		0.003391
  validation loss:		0.622465
  validation accuracy:		92.28 %
Epoch 1837 of 2000 took 0.055s
  training loss:		0.003419
  validation loss:		0.618886
  validation accuracy:		92.39 %
Epoch 1838 of 2000 took 0.056s
  training loss:		0.003291
  validation loss:		0.624388
  validation accuracy:		92.61 %
Epoch 1839 of 2000 took 0.055s
  training loss:		0.003537
  validation loss:		0.617531
  validation accuracy:		92.61 %
Epoch 1840 of 2000 took 0.055s
  training loss:		0.003472
  validation loss:		0.620115
  validation accuracy:		92.39 %
Epoch 1841 of 2000 took 0.055s
  training loss:		0.003470
  validation loss:		0.626122
  validation accuracy:		92.61 %
Epoch 1842 of 2000 took 0.055s
  training loss:		0.003417
  validation loss:		0.621706
  validation accuracy:		92.39 %
Epoch 1843 of 2000 took 0.056s
  training loss:		0.003312
  validation loss:		0.633710
  validation accuracy:		92.50 %
Epoch 1844 of 2000 took 0.054s
  training loss:		0.003360
  validation loss:		0.629594
  validation accuracy:		92.39 %
Epoch 1845 of 2000 took 0.056s
  training loss:		0.003356
  validation loss:		0.625124
  validation accuracy:		92.61 %
Epoch 1846 of 2000 took 0.055s
  training loss:		0.003358
  validation loss:		0.622289
  validation accuracy:		92.28 %
Epoch 1847 of 2000 took 0.056s
  training loss:		0.003406
  validation loss:		0.624746
  validation accuracy:		92.50 %
Epoch 1848 of 2000 took 0.054s
  training loss:		0.003388
  validation loss:		0.626295
  validation accuracy:		92.39 %
Epoch 1849 of 2000 took 0.056s
  training loss:		0.003290
  validation loss:		0.620144
  validation accuracy:		92.50 %
Epoch 1850 of 2000 took 0.054s
  training loss:		0.003352
  validation loss:		0.633448
  validation accuracy:		92.61 %
Epoch 1851 of 2000 took 0.056s
  training loss:		0.003348
  validation loss:		0.631896
  validation accuracy:		92.50 %
Epoch 1852 of 2000 took 0.054s
  training loss:		0.003357
  validation loss:		0.625900
  validation accuracy:		92.39 %
Epoch 1853 of 2000 took 0.056s
  training loss:		0.003275
  validation loss:		0.624351
  validation accuracy:		92.39 %
Epoch 1854 of 2000 took 0.057s
  training loss:		0.003424
  validation loss:		0.630670
  validation accuracy:		92.39 %
Epoch 1855 of 2000 took 0.055s
  training loss:		0.003282
  validation loss:		0.626899
  validation accuracy:		92.50 %
Epoch 1856 of 2000 took 0.055s
  training loss:		0.003356
  validation loss:		0.625764
  validation accuracy:		92.50 %
Epoch 1857 of 2000 took 0.057s
  training loss:		0.003344
  validation loss:		0.628459
  validation accuracy:		92.39 %
Epoch 1858 of 2000 took 0.057s
  training loss:		0.003142
  validation loss:		0.634012
  validation accuracy:		92.50 %
Epoch 1859 of 2000 took 0.057s
  training loss:		0.003329
  validation loss:		0.629928
  validation accuracy:		92.50 %
Epoch 1860 of 2000 took 0.057s
  training loss:		0.003340
  validation loss:		0.626631
  validation accuracy:		92.50 %
Epoch 1861 of 2000 took 0.057s
  training loss:		0.003281
  validation loss:		0.630382
  validation accuracy:		92.50 %
Epoch 1862 of 2000 took 0.058s
  training loss:		0.003353
  validation loss:		0.627093
  validation accuracy:		92.39 %
Epoch 1863 of 2000 took 0.058s
  training loss:		0.003297
  validation loss:		0.631050
  validation accuracy:		92.50 %
Epoch 1864 of 2000 took 0.058s
  training loss:		0.003294
  validation loss:		0.624812
  validation accuracy:		92.50 %
Epoch 1865 of 2000 took 0.058s
  training loss:		0.003332
  validation loss:		0.627681
  validation accuracy:		92.61 %
Epoch 1866 of 2000 took 0.058s
  training loss:		0.003232
  validation loss:		0.628035
  validation accuracy:		92.50 %
Epoch 1867 of 2000 took 0.057s
  training loss:		0.003306
  validation loss:		0.632547
  validation accuracy:		92.50 %
Epoch 1868 of 2000 took 0.058s
  training loss:		0.003236
  validation loss:		0.631044
  validation accuracy:		92.50 %
Epoch 1869 of 2000 took 0.057s
  training loss:		0.003247
  validation loss:		0.628021
  validation accuracy:		92.50 %
Epoch 1870 of 2000 took 0.055s
  training loss:		0.003287
  validation loss:		0.627695
  validation accuracy:		92.61 %
Epoch 1871 of 2000 took 0.055s
  training loss:		0.003260
  validation loss:		0.629459
  validation accuracy:		92.39 %
Epoch 1872 of 2000 took 0.055s
  training loss:		0.003265
  validation loss:		0.633809
  validation accuracy:		92.50 %
Epoch 1873 of 2000 took 0.057s
  training loss:		0.003291
  validation loss:		0.628374
  validation accuracy:		92.50 %
Epoch 1874 of 2000 took 0.057s
  training loss:		0.003221
  validation loss:		0.632476
  validation accuracy:		92.39 %
Epoch 1875 of 2000 took 0.057s
  training loss:		0.003221
  validation loss:		0.621980
  validation accuracy:		92.39 %
Epoch 1876 of 2000 took 0.057s
  training loss:		0.003283
  validation loss:		0.637127
  validation accuracy:		92.39 %
Epoch 1877 of 2000 took 0.057s
  training loss:		0.003260
  validation loss:		0.631670
  validation accuracy:		92.28 %
Epoch 1878 of 2000 took 0.057s
  training loss:		0.003255
  validation loss:		0.625285
  validation accuracy:		92.61 %
Epoch 1879 of 2000 took 0.057s
  training loss:		0.003259
  validation loss:		0.628890
  validation accuracy:		92.61 %
Epoch 1880 of 2000 took 0.057s
  training loss:		0.003247
  validation loss:		0.625009
  validation accuracy:		92.50 %
Epoch 1881 of 2000 took 0.056s
  training loss:		0.003275
  validation loss:		0.628746
  validation accuracy:		92.39 %
Epoch 1882 of 2000 took 0.055s
  training loss:		0.003167
  validation loss:		0.635508
  validation accuracy:		92.39 %
Epoch 1883 of 2000 took 0.056s
  training loss:		0.003147
  validation loss:		0.631151
  validation accuracy:		92.39 %
Epoch 1884 of 2000 took 0.056s
  training loss:		0.003190
  validation loss:		0.624350
  validation accuracy:		92.50 %
Epoch 1885 of 2000 took 0.056s
  training loss:		0.003209
  validation loss:		0.630756
  validation accuracy:		92.50 %
Epoch 1886 of 2000 took 0.056s
  training loss:		0.003163
  validation loss:		0.637284
  validation accuracy:		92.61 %
Epoch 1887 of 2000 took 0.055s
  training loss:		0.003170
  validation loss:		0.628418
  validation accuracy:		92.50 %
Epoch 1888 of 2000 took 0.056s
  training loss:		0.003251
  validation loss:		0.629687
  validation accuracy:		92.39 %
Epoch 1889 of 2000 took 0.055s
  training loss:		0.003310
  validation loss:		0.633612
  validation accuracy:		92.50 %
Epoch 1890 of 2000 took 0.056s
  training loss:		0.003242
  validation loss:		0.627821
  validation accuracy:		92.50 %
Epoch 1891 of 2000 took 0.055s
  training loss:		0.003211
  validation loss:		0.639784
  validation accuracy:		92.61 %
Epoch 1892 of 2000 took 0.053s
  training loss:		0.003150
  validation loss:		0.628695
  validation accuracy:		92.39 %
Epoch 1893 of 2000 took 0.055s
  training loss:		0.003186
  validation loss:		0.640164
  validation accuracy:		92.50 %
Epoch 1894 of 2000 took 0.054s
  training loss:		0.003170
  validation loss:		0.629983
  validation accuracy:		92.39 %
Epoch 1895 of 2000 took 0.056s
  training loss:		0.003155
  validation loss:		0.631988
  validation accuracy:		92.50 %
Epoch 1896 of 2000 took 0.055s
  training loss:		0.003145
  validation loss:		0.626174
  validation accuracy:		92.50 %
Epoch 1897 of 2000 took 0.056s
  training loss:		0.003214
  validation loss:		0.633229
  validation accuracy:		92.61 %
Epoch 1898 of 2000 took 0.055s
  training loss:		0.003274
  validation loss:		0.634728
  validation accuracy:		92.50 %
Epoch 1899 of 2000 took 0.056s
  training loss:		0.003171
  validation loss:		0.635020
  validation accuracy:		92.39 %
Epoch 1900 of 2000 took 0.053s
  training loss:		0.003114
  validation loss:		0.630317
  validation accuracy:		92.39 %
Epoch 1901 of 2000 took 0.057s
  training loss:		0.003068
  validation loss:		0.630615
  validation accuracy:		92.50 %
Epoch 1902 of 2000 took 0.055s
  training loss:		0.003125
  validation loss:		0.633888
  validation accuracy:		92.50 %
Epoch 1903 of 2000 took 0.056s
  training loss:		0.003192
  validation loss:		0.633251
  validation accuracy:		92.61 %
Epoch 1904 of 2000 took 0.054s
  training loss:		0.003156
  validation loss:		0.631464
  validation accuracy:		92.50 %
Epoch 1905 of 2000 took 0.057s
  training loss:		0.003185
  validation loss:		0.634312
  validation accuracy:		92.39 %
Epoch 1906 of 2000 took 0.057s
  training loss:		0.003120
  validation loss:		0.629595
  validation accuracy:		92.50 %
Epoch 1907 of 2000 took 0.057s
  training loss:		0.003198
  validation loss:		0.631633
  validation accuracy:		92.50 %
Epoch 1908 of 2000 took 0.057s
  training loss:		0.003097
  validation loss:		0.638599
  validation accuracy:		92.50 %
Epoch 1909 of 2000 took 0.057s
  training loss:		0.003096
  validation loss:		0.635059
  validation accuracy:		92.39 %
Epoch 1910 of 2000 took 0.057s
  training loss:		0.003068
  validation loss:		0.639808
  validation accuracy:		92.39 %
Epoch 1911 of 2000 took 0.057s
  training loss:		0.003133
  validation loss:		0.634134
  validation accuracy:		92.50 %
Epoch 1912 of 2000 took 0.057s
  training loss:		0.003039
  validation loss:		0.638357
  validation accuracy:		92.50 %
Epoch 1913 of 2000 took 0.057s
  training loss:		0.003015
  validation loss:		0.634174
  validation accuracy:		92.50 %
Epoch 1914 of 2000 took 0.057s
  training loss:		0.003051
  validation loss:		0.635991
  validation accuracy:		92.50 %
Epoch 1915 of 2000 took 0.057s
  training loss:		0.003095
  validation loss:		0.636789
  validation accuracy:		92.39 %
Epoch 1916 of 2000 took 0.057s
  training loss:		0.003088
  validation loss:		0.635990
  validation accuracy:		92.50 %
Epoch 1917 of 2000 took 0.055s
  training loss:		0.003077
  validation loss:		0.632406
  validation accuracy:		92.50 %
Epoch 1918 of 2000 took 0.055s
  training loss:		0.003060
  validation loss:		0.636824
  validation accuracy:		92.39 %
Epoch 1919 of 2000 took 0.055s
  training loss:		0.003132
  validation loss:		0.632944
  validation accuracy:		92.50 %
Epoch 1920 of 2000 took 0.057s
  training loss:		0.003023
  validation loss:		0.636567
  validation accuracy:		92.39 %
Epoch 1921 of 2000 took 0.056s
  training loss:		0.002990
  validation loss:		0.637485
  validation accuracy:		92.50 %
Epoch 1922 of 2000 took 0.055s
  training loss:		0.003140
  validation loss:		0.632796
  validation accuracy:		92.50 %
Epoch 1923 of 2000 took 0.055s
  training loss:		0.003095
  validation loss:		0.635857
  validation accuracy:		92.61 %
Epoch 1924 of 2000 took 0.056s
  training loss:		0.003015
  validation loss:		0.633106
  validation accuracy:		92.39 %
Epoch 1925 of 2000 took 0.057s
  training loss:		0.003063
  validation loss:		0.636125
  validation accuracy:		92.39 %
Epoch 1926 of 2000 took 0.057s
  training loss:		0.003018
  validation loss:		0.636969
  validation accuracy:		92.50 %
Epoch 1927 of 2000 took 0.057s
  training loss:		0.003069
  validation loss:		0.639950
  validation accuracy:		92.61 %
Epoch 1928 of 2000 took 0.057s
  training loss:		0.003072
  validation loss:		0.635530
  validation accuracy:		92.50 %
Epoch 1929 of 2000 took 0.057s
  training loss:		0.002973
  validation loss:		0.636719
  validation accuracy:		92.50 %
Epoch 1930 of 2000 took 0.057s
  training loss:		0.003070
  validation loss:		0.634972
  validation accuracy:		92.39 %
Epoch 1931 of 2000 took 0.057s
  training loss:		0.003111
  validation loss:		0.637944
  validation accuracy:		92.50 %
Epoch 1932 of 2000 took 0.057s
  training loss:		0.002974
  validation loss:		0.635467
  validation accuracy:		92.39 %
Epoch 1933 of 2000 took 0.057s
  training loss:		0.003017
  validation loss:		0.635920
  validation accuracy:		92.50 %
Epoch 1934 of 2000 took 0.057s
  training loss:		0.002954
  validation loss:		0.635981
  validation accuracy:		92.50 %
Epoch 1935 of 2000 took 0.057s
  training loss:		0.002962
  validation loss:		0.644132
  validation accuracy:		92.61 %
Epoch 1936 of 2000 took 0.057s
  training loss:		0.003020
  validation loss:		0.641645
  validation accuracy:		92.39 %
Epoch 1937 of 2000 took 0.057s
  training loss:		0.003003
  validation loss:		0.633731
  validation accuracy:		92.39 %
Epoch 1938 of 2000 took 0.057s
  training loss:		0.003023
  validation loss:		0.645359
  validation accuracy:		92.28 %
Epoch 1939 of 2000 took 0.057s
  training loss:		0.003039
  validation loss:		0.640162
  validation accuracy:		92.50 %
Epoch 1940 of 2000 took 0.057s
  training loss:		0.002990
  validation loss:		0.638688
  validation accuracy:		92.61 %
Epoch 1941 of 2000 took 0.057s
  training loss:		0.002963
  validation loss:		0.638803
  validation accuracy:		92.50 %
Epoch 1942 of 2000 took 0.057s
  training loss:		0.003015
  validation loss:		0.639960
  validation accuracy:		92.50 %
Epoch 1943 of 2000 took 0.057s
  training loss:		0.003011
  validation loss:		0.641241
  validation accuracy:		92.39 %
Epoch 1944 of 2000 took 0.057s
  training loss:		0.002948
  validation loss:		0.639291
  validation accuracy:		92.61 %
Epoch 1945 of 2000 took 0.057s
  training loss:		0.002995
  validation loss:		0.639289
  validation accuracy:		92.50 %
Epoch 1946 of 2000 took 0.057s
  training loss:		0.002933
  validation loss:		0.636462
  validation accuracy:		92.50 %
Epoch 1947 of 2000 took 0.057s
  training loss:		0.003030
  validation loss:		0.632769
  validation accuracy:		92.50 %
Epoch 1948 of 2000 took 0.057s
  training loss:		0.003015
  validation loss:		0.642499
  validation accuracy:		92.61 %
Epoch 1949 of 2000 took 0.057s
  training loss:		0.002915
  validation loss:		0.641978
  validation accuracy:		92.50 %
Epoch 1950 of 2000 took 0.057s
  training loss:		0.002913
  validation loss:		0.633241
  validation accuracy:		92.50 %
Epoch 1951 of 2000 took 0.057s
  training loss:		0.002942
  validation loss:		0.638897
  validation accuracy:		92.50 %
Epoch 1952 of 2000 took 0.057s
  training loss:		0.002903
  validation loss:		0.637381
  validation accuracy:		92.61 %
Epoch 1953 of 2000 took 0.057s
  training loss:		0.002970
  validation loss:		0.643259
  validation accuracy:		92.39 %
Epoch 1954 of 2000 took 0.057s
  training loss:		0.003008
  validation loss:		0.635737
  validation accuracy:		92.61 %
Epoch 1955 of 2000 took 0.055s
  training loss:		0.002861
  validation loss:		0.640720
  validation accuracy:		92.39 %
Epoch 1956 of 2000 took 0.057s
  training loss:		0.003036
  validation loss:		0.639977
  validation accuracy:		92.50 %
Epoch 1957 of 2000 took 0.057s
  training loss:		0.002933
  validation loss:		0.646325
  validation accuracy:		92.61 %
Epoch 1958 of 2000 took 0.057s
  training loss:		0.002953
  validation loss:		0.634732
  validation accuracy:		92.50 %
Epoch 1959 of 2000 took 0.057s
  training loss:		0.002968
  validation loss:		0.639267
  validation accuracy:		92.50 %
Epoch 1960 of 2000 took 0.056s
  training loss:		0.002973
  validation loss:		0.638927
  validation accuracy:		92.39 %
Epoch 1961 of 2000 took 0.057s
  training loss:		0.002882
  validation loss:		0.638553
  validation accuracy:		92.61 %
Epoch 1962 of 2000 took 0.057s
  training loss:		0.002898
  validation loss:		0.636681
  validation accuracy:		92.50 %
Epoch 1963 of 2000 took 0.057s
  training loss:		0.002777
  validation loss:		0.647816
  validation accuracy:		92.61 %
Epoch 1964 of 2000 took 0.057s
  training loss:		0.003030
  validation loss:		0.633003
  validation accuracy:		92.61 %
Epoch 1965 of 2000 took 0.057s
  training loss:		0.002897
  validation loss:		0.646569
  validation accuracy:		92.50 %
Epoch 1966 of 2000 took 0.057s
  training loss:		0.002951
  validation loss:		0.643984
  validation accuracy:		92.50 %
Epoch 1967 of 2000 took 0.057s
  training loss:		0.002935
  validation loss:		0.648212
  validation accuracy:		92.61 %
Epoch 1968 of 2000 took 0.057s
  training loss:		0.002987
  validation loss:		0.635643
  validation accuracy:		92.50 %
Epoch 1969 of 2000 took 0.057s
  training loss:		0.002996
  validation loss:		0.640911
  validation accuracy:		92.61 %
Epoch 1970 of 2000 took 0.057s
  training loss:		0.002949
  validation loss:		0.638900
  validation accuracy:		92.50 %
Epoch 1971 of 2000 took 0.057s
  training loss:		0.002969
  validation loss:		0.644395
  validation accuracy:		92.50 %
Epoch 1972 of 2000 took 0.057s
  training loss:		0.002917
  validation loss:		0.644352
  validation accuracy:		92.50 %
Epoch 1973 of 2000 took 0.057s
  training loss:		0.002872
  validation loss:		0.643473
  validation accuracy:		92.50 %
Epoch 1974 of 2000 took 0.057s
  training loss:		0.002964
  validation loss:		0.641337
  validation accuracy:		92.50 %
Epoch 1975 of 2000 took 0.057s
  training loss:		0.002916
  validation loss:		0.647157
  validation accuracy:		92.39 %
Epoch 1976 of 2000 took 0.057s
  training loss:		0.002885
  validation loss:		0.647314
  validation accuracy:		92.61 %
Epoch 1977 of 2000 took 0.057s
  training loss:		0.002866
  validation loss:		0.641737
  validation accuracy:		92.61 %
Epoch 1978 of 2000 took 0.057s
  training loss:		0.002885
  validation loss:		0.641436
  validation accuracy:		92.39 %
Epoch 1979 of 2000 took 0.057s
  training loss:		0.002912
  validation loss:		0.642472
  validation accuracy:		92.50 %
Epoch 1980 of 2000 took 0.057s
  training loss:		0.002887
  validation loss:		0.648634
  validation accuracy:		92.61 %
Epoch 1981 of 2000 took 0.057s
  training loss:		0.002912
  validation loss:		0.638143
  validation accuracy:		92.39 %
Epoch 1982 of 2000 took 0.057s
  training loss:		0.002865
  validation loss:		0.641651
  validation accuracy:		92.39 %
Epoch 1983 of 2000 took 0.057s
  training loss:		0.002860
  validation loss:		0.645729
  validation accuracy:		92.61 %
Epoch 1984 of 2000 took 0.057s
  training loss:		0.002849
  validation loss:		0.638486
  validation accuracy:		92.50 %
Epoch 1985 of 2000 took 0.058s
  training loss:		0.002874
  validation loss:		0.642051
  validation accuracy:		92.50 %
Epoch 1986 of 2000 took 0.058s
  training loss:		0.002845
  validation loss:		0.641216
  validation accuracy:		92.50 %
Epoch 1987 of 2000 took 0.058s
  training loss:		0.002735
  validation loss:		0.645532
  validation accuracy:		92.39 %
Epoch 1988 of 2000 took 0.058s
  training loss:		0.002869
  validation loss:		0.642090
  validation accuracy:		92.50 %
Epoch 1989 of 2000 took 0.057s
  training loss:		0.002828
  validation loss:		0.649948
  validation accuracy:		92.50 %
Epoch 1990 of 2000 took 0.057s
  training loss:		0.002898
  validation loss:		0.641318
  validation accuracy:		92.61 %
Epoch 1991 of 2000 took 0.057s
  training loss:		0.002876
  validation loss:		0.638971
  validation accuracy:		92.50 %
Epoch 1992 of 2000 took 0.058s
  training loss:		0.002875
  validation loss:		0.647201
  validation accuracy:		92.50 %
Epoch 1993 of 2000 took 0.057s
  training loss:		0.002836
  validation loss:		0.645929
  validation accuracy:		92.61 %
Epoch 1994 of 2000 took 0.056s
  training loss:		0.002873
  validation loss:		0.649306
  validation accuracy:		92.28 %
Epoch 1995 of 2000 took 0.056s
  training loss:		0.002839
  validation loss:		0.643844
  validation accuracy:		92.50 %
Epoch 1996 of 2000 took 0.057s
  training loss:		0.002875
  validation loss:		0.644493
  validation accuracy:		92.61 %
Epoch 1997 of 2000 took 0.056s
  training loss:		0.002768
  validation loss:		0.649072
  validation accuracy:		92.39 %
Epoch 1998 of 2000 took 0.056s
  training loss:		0.002885
  validation loss:		0.642055
  validation accuracy:		92.50 %
Epoch 1999 of 2000 took 0.056s
  training loss:		0.002767
  validation loss:		0.643222
  validation accuracy:		92.50 %
Epoch 2000 of 2000 took 0.056s
  training loss:		0.002811
  validation loss:		0.641675
  validation accuracy:		92.39 %
Final results:
  test loss:			1.406609
  test accuracy:		84.38 %
