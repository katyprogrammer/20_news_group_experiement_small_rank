Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.047s
  training loss:		3.029155
  validation loss:		2.607296
  validation accuracy:		20.33 %
Epoch 2 of 2000 took 0.041s
  training loss:		2.430370
  validation loss:		2.137925
  validation accuracy:		28.48 %
Epoch 3 of 2000 took 0.039s
  training loss:		2.165029
  validation loss:		1.970098
  validation accuracy:		31.20 %
Epoch 4 of 2000 took 0.039s
  training loss:		1.999656
  validation loss:		1.819774
  validation accuracy:		35.76 %
Epoch 5 of 2000 took 0.039s
  training loss:		1.907590
  validation loss:		1.769667
  validation accuracy:		36.41 %
Epoch 6 of 2000 took 0.038s
  training loss:		1.831676
  validation loss:		1.689309
  validation accuracy:		39.57 %
Epoch 7 of 2000 took 0.038s
  training loss:		1.763841
  validation loss:		1.647249
  validation accuracy:		42.93 %
Epoch 8 of 2000 took 0.039s
  training loss:		1.704552
  validation loss:		1.577586
  validation accuracy:		46.85 %
Epoch 9 of 2000 took 0.038s
  training loss:		1.645509
  validation loss:		1.517528
  validation accuracy:		46.52 %
Epoch 10 of 2000 took 0.038s
  training loss:		1.578098
  validation loss:		1.449687
  validation accuracy:		51.30 %
Epoch 11 of 2000 took 0.038s
  training loss:		1.504485
  validation loss:		1.402705
  validation accuracy:		52.61 %
Epoch 12 of 2000 took 0.038s
  training loss:		1.439433
  validation loss:		1.338028
  validation accuracy:		55.00 %
Epoch 13 of 2000 took 0.052s
  training loss:		1.373466
  validation loss:		1.271004
  validation accuracy:		57.83 %
Epoch 14 of 2000 took 0.046s
  training loss:		1.305346
  validation loss:		1.206970
  validation accuracy:		58.37 %
Epoch 15 of 2000 took 0.041s
  training loss:		1.250400
  validation loss:		1.159591
  validation accuracy:		60.11 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.187920
  validation loss:		1.092062
  validation accuracy:		61.85 %
Epoch 17 of 2000 took 0.036s
  training loss:		1.137412
  validation loss:		1.054208
  validation accuracy:		63.59 %
Epoch 18 of 2000 took 0.035s
  training loss:		1.089398
  validation loss:		1.021847
  validation accuracy:		63.70 %
Epoch 19 of 2000 took 0.035s
  training loss:		1.041029
  validation loss:		0.983542
  validation accuracy:		64.89 %
Epoch 20 of 2000 took 0.035s
  training loss:		1.003412
  validation loss:		0.941917
  validation accuracy:		65.76 %
Epoch 21 of 2000 took 0.035s
  training loss:		0.964203
  validation loss:		0.923312
  validation accuracy:		66.85 %
Epoch 22 of 2000 took 0.035s
  training loss:		0.934901
  validation loss:		0.904102
  validation accuracy:		66.74 %
Epoch 23 of 2000 took 0.035s
  training loss:		0.917860
  validation loss:		0.863420
  validation accuracy:		68.15 %
Epoch 24 of 2000 took 0.035s
  training loss:		0.884502
  validation loss:		0.837105
  validation accuracy:		69.13 %
Epoch 25 of 2000 took 0.035s
  training loss:		0.864826
  validation loss:		0.823239
  validation accuracy:		69.67 %
Epoch 26 of 2000 took 0.035s
  training loss:		0.843006
  validation loss:		0.805719
  validation accuracy:		71.20 %
Epoch 27 of 2000 took 0.035s
  training loss:		0.820384
  validation loss:		0.782048
  validation accuracy:		71.20 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.799116
  validation loss:		0.770569
  validation accuracy:		71.20 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.785509
  validation loss:		0.787401
  validation accuracy:		72.07 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.768637
  validation loss:		0.742286
  validation accuracy:		73.26 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.750691
  validation loss:		0.732346
  validation accuracy:		72.50 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.734859
  validation loss:		0.714929
  validation accuracy:		74.57 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.722393
  validation loss:		0.698290
  validation accuracy:		74.57 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.706969
  validation loss:		0.695165
  validation accuracy:		75.43 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.691847
  validation loss:		0.689973
  validation accuracy:		76.41 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.682062
  validation loss:		0.668247
  validation accuracy:		77.28 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.667918
  validation loss:		0.642545
  validation accuracy:		78.70 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.649078
  validation loss:		0.637276
  validation accuracy:		78.70 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.627919
  validation loss:		0.618383
  validation accuracy:		79.35 %
Epoch 40 of 2000 took 0.036s
  training loss:		0.625504
  validation loss:		0.619849
  validation accuracy:		80.22 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.610383
  validation loss:		0.596310
  validation accuracy:		80.76 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.598546
  validation loss:		0.590887
  validation accuracy:		81.30 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.587375
  validation loss:		0.566144
  validation accuracy:		83.15 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.586060
  validation loss:		0.574396
  validation accuracy:		81.85 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.569645
  validation loss:		0.564281
  validation accuracy:		82.17 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.557348
  validation loss:		0.557823
  validation accuracy:		82.83 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.541945
  validation loss:		0.561495
  validation accuracy:		82.28 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.537604
  validation loss:		0.557918
  validation accuracy:		82.93 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.536732
  validation loss:		0.543362
  validation accuracy:		83.70 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.524909
  validation loss:		0.523454
  validation accuracy:		84.24 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.516700
  validation loss:		0.516050
  validation accuracy:		84.46 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.517697
  validation loss:		0.524231
  validation accuracy:		83.91 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.520519
  validation loss:		0.524028
  validation accuracy:		83.59 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.497940
  validation loss:		0.520373
  validation accuracy:		84.24 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.505840
  validation loss:		0.512380
  validation accuracy:		84.02 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.494015
  validation loss:		0.512430
  validation accuracy:		84.24 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.512886
  validation loss:		0.547212
  validation accuracy:		83.04 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.492750
  validation loss:		0.490298
  validation accuracy:		85.33 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.499381
  validation loss:		0.530171
  validation accuracy:		83.59 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.506733
  validation loss:		0.509385
  validation accuracy:		84.57 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.481477
  validation loss:		0.507898
  validation accuracy:		84.35 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.497058
  validation loss:		0.485958
  validation accuracy:		85.76 %
Epoch 63 of 2000 took 0.038s
  training loss:		0.467910
  validation loss:		0.482124
  validation accuracy:		85.65 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.462830
  validation loss:		0.487220
  validation accuracy:		86.20 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.458908
  validation loss:		0.476232
  validation accuracy:		85.43 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.478093
  validation loss:		0.474894
  validation accuracy:		85.87 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.457541
  validation loss:		0.463967
  validation accuracy:		86.41 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.459080
  validation loss:		0.474872
  validation accuracy:		85.98 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.450427
  validation loss:		0.461342
  validation accuracy:		86.30 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.463034
  validation loss:		0.511325
  validation accuracy:		84.24 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.443159
  validation loss:		0.495489
  validation accuracy:		85.33 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.435499
  validation loss:		0.471683
  validation accuracy:		86.41 %
Epoch 73 of 2000 took 0.036s
  training loss:		0.458351
  validation loss:		0.497408
  validation accuracy:		85.22 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.442914
  validation loss:		0.483609
  validation accuracy:		85.54 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.435037
  validation loss:		0.450752
  validation accuracy:		86.63 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.460208
  validation loss:		0.480068
  validation accuracy:		86.09 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.428200
  validation loss:		0.452536
  validation accuracy:		86.63 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.425109
  validation loss:		0.448178
  validation accuracy:		87.07 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.462274
  validation loss:		0.481209
  validation accuracy:		86.41 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.419336
  validation loss:		0.447424
  validation accuracy:		87.50 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.413192
  validation loss:		0.461491
  validation accuracy:		87.07 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.420903
  validation loss:		0.445946
  validation accuracy:		87.17 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.432911
  validation loss:		0.489418
  validation accuracy:		85.00 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.421302
  validation loss:		0.456339
  validation accuracy:		87.07 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.416219
  validation loss:		0.443043
  validation accuracy:		87.07 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.410057
  validation loss:		0.451808
  validation accuracy:		87.39 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.407749
  validation loss:		0.453562
  validation accuracy:		87.72 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.424349
  validation loss:		0.446152
  validation accuracy:		87.61 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.414008
  validation loss:		0.498638
  validation accuracy:		85.11 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.406538
  validation loss:		0.430039
  validation accuracy:		87.61 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.397104
  validation loss:		0.445816
  validation accuracy:		87.50 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.396597
  validation loss:		0.429969
  validation accuracy:		87.39 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.408567
  validation loss:		0.441791
  validation accuracy:		87.07 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.393048
  validation loss:		0.431856
  validation accuracy:		87.83 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.414183
  validation loss:		0.427870
  validation accuracy:		87.72 %
Epoch 96 of 2000 took 0.036s
  training loss:		0.399253
  validation loss:		0.455568
  validation accuracy:		86.30 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.391629
  validation loss:		0.424009
  validation accuracy:		87.72 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.395087
  validation loss:		0.419231
  validation accuracy:		87.50 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.395253
  validation loss:		0.454111
  validation accuracy:		86.63 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.403406
  validation loss:		0.415234
  validation accuracy:		88.04 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.390006
  validation loss:		0.424247
  validation accuracy:		87.83 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.394261
  validation loss:		0.439082
  validation accuracy:		87.83 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.385372
  validation loss:		0.450227
  validation accuracy:		87.39 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.385051
  validation loss:		0.431391
  validation accuracy:		87.93 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.379662
  validation loss:		0.421240
  validation accuracy:		88.48 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.399394
  validation loss:		0.422230
  validation accuracy:		87.93 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.388331
  validation loss:		0.434287
  validation accuracy:		87.93 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.400312
  validation loss:		0.418648
  validation accuracy:		87.61 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.398229
  validation loss:		0.448877
  validation accuracy:		87.61 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.378599
  validation loss:		0.441339
  validation accuracy:		87.83 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.378791
  validation loss:		0.418516
  validation accuracy:		88.04 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.379280
  validation loss:		0.428592
  validation accuracy:		88.26 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.380878
  validation loss:		0.413860
  validation accuracy:		88.37 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.383876
  validation loss:		0.428911
  validation accuracy:		88.04 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.378943
  validation loss:		0.424531
  validation accuracy:		87.07 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.390198
  validation loss:		0.430770
  validation accuracy:		87.93 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.375762
  validation loss:		0.423162
  validation accuracy:		88.04 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.376220
  validation loss:		0.442721
  validation accuracy:		88.15 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.368687
  validation loss:		0.427280
  validation accuracy:		87.93 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.364312
  validation loss:		0.461881
  validation accuracy:		86.74 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.371301
  validation loss:		0.427798
  validation accuracy:		88.70 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.375153
  validation loss:		0.415777
  validation accuracy:		87.72 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.373820
  validation loss:		0.434346
  validation accuracy:		87.72 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.365534
  validation loss:		0.433291
  validation accuracy:		87.83 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.363192
  validation loss:		0.415440
  validation accuracy:		88.26 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.366072
  validation loss:		0.420068
  validation accuracy:		89.02 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.359483
  validation loss:		0.418852
  validation accuracy:		87.50 %
Epoch 128 of 2000 took 0.036s
  training loss:		0.388282
  validation loss:		0.412302
  validation accuracy:		88.48 %
Epoch 129 of 2000 took 0.036s
  training loss:		0.374754
  validation loss:		0.427431
  validation accuracy:		87.39 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.369794
  validation loss:		0.431076
  validation accuracy:		88.70 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.359916
  validation loss:		0.411782
  validation accuracy:		88.48 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.367248
  validation loss:		0.448176
  validation accuracy:		86.85 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.360346
  validation loss:		0.414398
  validation accuracy:		88.15 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.374998
  validation loss:		0.404046
  validation accuracy:		88.37 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.350554
  validation loss:		0.421919
  validation accuracy:		88.59 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.365290
  validation loss:		0.444025
  validation accuracy:		87.83 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.362376
  validation loss:		0.416150
  validation accuracy:		88.80 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.367598
  validation loss:		0.401430
  validation accuracy:		89.13 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.348285
  validation loss:		0.415650
  validation accuracy:		88.91 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.372956
  validation loss:		0.447107
  validation accuracy:		87.61 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.379755
  validation loss:		0.418014
  validation accuracy:		88.91 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.355415
  validation loss:		0.422433
  validation accuracy:		87.72 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.358813
  validation loss:		0.430842
  validation accuracy:		87.17 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.361452
  validation loss:		0.400670
  validation accuracy:		88.80 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.358045
  validation loss:		0.450197
  validation accuracy:		87.07 %
Epoch 146 of 2000 took 0.036s
  training loss:		0.352865
  validation loss:		0.408244
  validation accuracy:		87.72 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.393243
  validation loss:		0.402575
  validation accuracy:		88.37 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.348206
  validation loss:		0.419835
  validation accuracy:		88.04 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.354533
  validation loss:		0.419792
  validation accuracy:		89.02 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.357762
  validation loss:		0.412739
  validation accuracy:		88.59 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.361500
  validation loss:		0.475494
  validation accuracy:		85.76 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.356320
  validation loss:		0.415270
  validation accuracy:		89.35 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.344724
  validation loss:		0.419341
  validation accuracy:		88.48 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.352265
  validation loss:		0.405469
  validation accuracy:		88.48 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.350817
  validation loss:		0.402794
  validation accuracy:		89.02 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.344839
  validation loss:		0.394154
  validation accuracy:		89.13 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.342388
  validation loss:		0.397900
  validation accuracy:		89.24 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.348249
  validation loss:		0.401085
  validation accuracy:		89.35 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.340975
  validation loss:		0.411155
  validation accuracy:		88.37 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.356467
  validation loss:		0.413433
  validation accuracy:		88.48 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.340011
  validation loss:		0.399479
  validation accuracy:		88.80 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.346104
  validation loss:		0.416747
  validation accuracy:		88.59 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.339945
  validation loss:		0.415521
  validation accuracy:		87.61 %
Epoch 164 of 2000 took 0.036s
  training loss:		0.363576
  validation loss:		0.407197
  validation accuracy:		88.48 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.334175
  validation loss:		0.407048
  validation accuracy:		89.02 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.338358
  validation loss:		0.405435
  validation accuracy:		88.70 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.339988
  validation loss:		0.401095
  validation accuracy:		88.80 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.381682
  validation loss:		0.392161
  validation accuracy:		89.35 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.334005
  validation loss:		0.433608
  validation accuracy:		86.85 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.362780
  validation loss:		0.413862
  validation accuracy:		87.61 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.337571
  validation loss:		0.416199
  validation accuracy:		88.37 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.343343
  validation loss:		0.425061
  validation accuracy:		88.04 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.343279
  validation loss:		0.397896
  validation accuracy:		89.35 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.342536
  validation loss:		0.444598
  validation accuracy:		87.07 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.340786
  validation loss:		0.410320
  validation accuracy:		88.26 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.334214
  validation loss:		0.408434
  validation accuracy:		88.59 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.339867
  validation loss:		0.405936
  validation accuracy:		88.37 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.342668
  validation loss:		0.433715
  validation accuracy:		88.26 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.335880
  validation loss:		0.481324
  validation accuracy:		85.65 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.337250
  validation loss:		0.406838
  validation accuracy:		88.91 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.346968
  validation loss:		0.397384
  validation accuracy:		89.24 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.334944
  validation loss:		0.414842
  validation accuracy:		88.80 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.345507
  validation loss:		0.424659
  validation accuracy:		87.93 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.341772
  validation loss:		0.411014
  validation accuracy:		88.80 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.332240
  validation loss:		0.413047
  validation accuracy:		88.59 %
Epoch 186 of 2000 took 0.036s
  training loss:		0.332502
  validation loss:		0.404647
  validation accuracy:		88.04 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.340524
  validation loss:		0.430402
  validation accuracy:		86.96 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.341515
  validation loss:		0.459150
  validation accuracy:		87.61 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.331863
  validation loss:		0.426148
  validation accuracy:		87.28 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.331292
  validation loss:		0.421855
  validation accuracy:		87.61 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.331917
  validation loss:		0.409264
  validation accuracy:		88.70 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.347046
  validation loss:		0.423530
  validation accuracy:		87.83 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.328990
  validation loss:		0.407161
  validation accuracy:		88.91 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.325894
  validation loss:		0.388734
  validation accuracy:		89.46 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.332662
  validation loss:		0.403855
  validation accuracy:		88.80 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.330158
  validation loss:		0.426080
  validation accuracy:		87.83 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.327817
  validation loss:		0.409833
  validation accuracy:		88.04 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.324159
  validation loss:		0.413210
  validation accuracy:		88.04 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.331384
  validation loss:		0.404555
  validation accuracy:		88.59 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.349847
  validation loss:		0.408074
  validation accuracy:		88.70 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.326902
  validation loss:		0.407735
  validation accuracy:		88.59 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.327283
  validation loss:		0.412086
  validation accuracy:		89.02 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.329665
  validation loss:		0.412220
  validation accuracy:		87.93 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.326804
  validation loss:		0.430135
  validation accuracy:		87.28 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.325333
  validation loss:		0.408673
  validation accuracy:		88.37 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.331015
  validation loss:		0.434966
  validation accuracy:		87.17 %
Epoch 207 of 2000 took 0.036s
  training loss:		0.324129
  validation loss:		0.404114
  validation accuracy:		88.70 %
Epoch 208 of 2000 took 0.036s
  training loss:		0.336039
  validation loss:		0.421851
  validation accuracy:		87.72 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.321664
  validation loss:		0.431690
  validation accuracy:		87.17 %
Epoch 210 of 2000 took 0.036s
  training loss:		0.328342
  validation loss:		0.427075
  validation accuracy:		87.93 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.322282
  validation loss:		0.416178
  validation accuracy:		88.04 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.322375
  validation loss:		0.398837
  validation accuracy:		88.80 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.326532
  validation loss:		0.416713
  validation accuracy:		87.83 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.328051
  validation loss:		0.402434
  validation accuracy:		88.80 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.326488
  validation loss:		0.414536
  validation accuracy:		88.04 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.322438
  validation loss:		0.399967
  validation accuracy:		88.80 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.314031
  validation loss:		0.408023
  validation accuracy:		88.48 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.330034
  validation loss:		0.421180
  validation accuracy:		87.83 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.331254
  validation loss:		0.397741
  validation accuracy:		89.02 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.317235
  validation loss:		0.414188
  validation accuracy:		87.61 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.343034
  validation loss:		0.428403
  validation accuracy:		88.37 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.327831
  validation loss:		0.401266
  validation accuracy:		88.80 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.321209
  validation loss:		0.404178
  validation accuracy:		88.26 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.324076
  validation loss:		0.393824
  validation accuracy:		89.13 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.333958
  validation loss:		0.419634
  validation accuracy:		87.83 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.320978
  validation loss:		0.446762
  validation accuracy:		86.41 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.319520
  validation loss:		0.406751
  validation accuracy:		88.59 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.314889
  validation loss:		0.420980
  validation accuracy:		87.50 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.320608
  validation loss:		0.443744
  validation accuracy:		86.96 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.323193
  validation loss:		0.428062
  validation accuracy:		87.83 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.310901
  validation loss:		0.428334
  validation accuracy:		87.61 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.317467
  validation loss:		0.417973
  validation accuracy:		87.83 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.326469
  validation loss:		0.421399
  validation accuracy:		87.07 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.316196
  validation loss:		0.428855
  validation accuracy:		88.59 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.330477
  validation loss:		0.414812
  validation accuracy:		87.83 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.329288
  validation loss:		0.412968
  validation accuracy:		87.93 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.316561
  validation loss:		0.433189
  validation accuracy:		87.61 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.320299
  validation loss:		0.419892
  validation accuracy:		87.61 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.325246
  validation loss:		0.397044
  validation accuracy:		89.13 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.313974
  validation loss:		0.427541
  validation accuracy:		86.74 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.311500
  validation loss:		0.411220
  validation accuracy:		88.04 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.315075
  validation loss:		0.402141
  validation accuracy:		88.80 %
Epoch 243 of 2000 took 0.036s
  training loss:		0.316912
  validation loss:		0.416727
  validation accuracy:		87.83 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.310702
  validation loss:		0.413763
  validation accuracy:		87.83 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.322296
  validation loss:		0.426985
  validation accuracy:		87.72 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.315202
  validation loss:		0.426883
  validation accuracy:		87.83 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.312150
  validation loss:		0.414782
  validation accuracy:		87.83 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.308795
  validation loss:		0.397947
  validation accuracy:		88.59 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.308173
  validation loss:		0.415779
  validation accuracy:		88.91 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.322428
  validation loss:		0.433739
  validation accuracy:		87.83 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.313160
  validation loss:		0.412567
  validation accuracy:		88.15 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.313415
  validation loss:		0.411416
  validation accuracy:		87.83 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.315210
  validation loss:		0.405177
  validation accuracy:		88.59 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.312195
  validation loss:		0.420826
  validation accuracy:		88.37 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.321768
  validation loss:		0.426662
  validation accuracy:		87.61 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.308047
  validation loss:		0.402634
  validation accuracy:		88.48 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.313583
  validation loss:		0.395218
  validation accuracy:		89.13 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.307603
  validation loss:		0.418050
  validation accuracy:		87.93 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.312753
  validation loss:		0.413083
  validation accuracy:		88.26 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.320732
  validation loss:		0.418283
  validation accuracy:		87.72 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.308030
  validation loss:		0.406135
  validation accuracy:		88.37 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.315234
  validation loss:		0.398326
  validation accuracy:		88.91 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.310331
  validation loss:		0.416258
  validation accuracy:		88.04 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.307491
  validation loss:		0.421340
  validation accuracy:		87.61 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.319397
  validation loss:		0.417979
  validation accuracy:		87.61 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.303746
  validation loss:		0.415584
  validation accuracy:		87.83 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.312552
  validation loss:		0.427466
  validation accuracy:		87.72 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.313097
  validation loss:		0.419411
  validation accuracy:		87.93 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.306800
  validation loss:		0.403868
  validation accuracy:		88.04 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.311582
  validation loss:		0.416708
  validation accuracy:		87.17 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.314936
  validation loss:		0.421638
  validation accuracy:		88.48 %
Epoch 272 of 2000 took 0.036s
  training loss:		0.310305
  validation loss:		0.423693
  validation accuracy:		87.28 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.314594
  validation loss:		0.417663
  validation accuracy:		88.15 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.309145
  validation loss:		0.416455
  validation accuracy:		87.93 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.304177
  validation loss:		0.415977
  validation accuracy:		88.70 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.307304
  validation loss:		0.415890
  validation accuracy:		88.15 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.309168
  validation loss:		0.414858
  validation accuracy:		87.93 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.306873
  validation loss:		0.441077
  validation accuracy:		87.93 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.302326
  validation loss:		0.440142
  validation accuracy:		87.07 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.307429
  validation loss:		0.411972
  validation accuracy:		88.15 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.293697
  validation loss:		0.438538
  validation accuracy:		87.07 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.315961
  validation loss:		0.418756
  validation accuracy:		87.72 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.308005
  validation loss:		0.444035
  validation accuracy:		86.52 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.309802
  validation loss:		0.417620
  validation accuracy:		88.04 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.310052
  validation loss:		0.404533
  validation accuracy:		88.70 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.311370
  validation loss:		0.399692
  validation accuracy:		88.80 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.296526
  validation loss:		0.399055
  validation accuracy:		88.80 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.306375
  validation loss:		0.427328
  validation accuracy:		87.93 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.306263
  validation loss:		0.408711
  validation accuracy:		88.37 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.307339
  validation loss:		0.410451
  validation accuracy:		88.37 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.301880
  validation loss:		0.406271
  validation accuracy:		88.15 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.305132
  validation loss:		0.412222
  validation accuracy:		87.93 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.307791
  validation loss:		0.414373
  validation accuracy:		87.93 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.299342
  validation loss:		0.401023
  validation accuracy:		88.59 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.302000
  validation loss:		0.399188
  validation accuracy:		88.80 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.297329
  validation loss:		0.409121
  validation accuracy:		87.93 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.298985
  validation loss:		0.417288
  validation accuracy:		87.72 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.305924
  validation loss:		0.425026
  validation accuracy:		87.61 %
Epoch 299 of 2000 took 0.036s
  training loss:		0.304383
  validation loss:		0.411759
  validation accuracy:		87.83 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.299751
  validation loss:		0.417131
  validation accuracy:		87.83 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.305110
  validation loss:		0.402701
  validation accuracy:		88.80 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.302326
  validation loss:		0.406389
  validation accuracy:		87.93 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.310254
  validation loss:		0.465059
  validation accuracy:		86.74 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.307286
  validation loss:		0.421181
  validation accuracy:		87.83 %
Epoch 305 of 2000 took 0.036s
  training loss:		0.298320
  validation loss:		0.442801
  validation accuracy:		87.39 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.310889
  validation loss:		0.404813
  validation accuracy:		88.59 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.306364
  validation loss:		0.422910
  validation accuracy:		87.93 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.302373
  validation loss:		0.417233
  validation accuracy:		88.15 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.298971
  validation loss:		0.409445
  validation accuracy:		88.04 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.296970
  validation loss:		0.431658
  validation accuracy:		87.93 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.300436
  validation loss:		0.429892
  validation accuracy:		86.85 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.293810
  validation loss:		0.430207
  validation accuracy:		88.04 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.313640
  validation loss:		0.413316
  validation accuracy:		88.15 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.295587
  validation loss:		0.419096
  validation accuracy:		88.37 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.307831
  validation loss:		0.424408
  validation accuracy:		87.39 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.309790
  validation loss:		0.423496
  validation accuracy:		88.04 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.306249
  validation loss:		0.423749
  validation accuracy:		88.15 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.300380
  validation loss:		0.419417
  validation accuracy:		87.93 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.300965
  validation loss:		0.416861
  validation accuracy:		87.72 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.303625
  validation loss:		0.422799
  validation accuracy:		87.72 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.289713
  validation loss:		0.413515
  validation accuracy:		87.72 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.297110
  validation loss:		0.402433
  validation accuracy:		88.48 %
Epoch 323 of 2000 took 0.036s
  training loss:		0.298223
  validation loss:		0.408614
  validation accuracy:		88.26 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.305870
  validation loss:		0.422080
  validation accuracy:		88.04 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.295992
  validation loss:		0.422544
  validation accuracy:		88.15 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.293523
  validation loss:		0.409311
  validation accuracy:		87.93 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.297166
  validation loss:		0.425055
  validation accuracy:		88.37 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.302347
  validation loss:		0.419325
  validation accuracy:		88.04 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.301986
  validation loss:		0.427638
  validation accuracy:		88.04 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.300758
  validation loss:		0.425292
  validation accuracy:		87.61 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.293896
  validation loss:		0.431583
  validation accuracy:		87.28 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.291097
  validation loss:		0.434505
  validation accuracy:		86.85 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.296411
  validation loss:		0.420769
  validation accuracy:		87.83 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.299203
  validation loss:		0.421581
  validation accuracy:		88.26 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.295622
  validation loss:		0.419636
  validation accuracy:		87.83 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.295978
  validation loss:		0.422900
  validation accuracy:		88.37 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.306420
  validation loss:		0.442455
  validation accuracy:		86.74 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.294583
  validation loss:		0.427752
  validation accuracy:		87.50 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.295707
  validation loss:		0.435509
  validation accuracy:		86.52 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.298120
  validation loss:		0.406123
  validation accuracy:		88.04 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.301268
  validation loss:		0.408975
  validation accuracy:		88.59 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.305196
  validation loss:		0.418021
  validation accuracy:		87.72 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.299406
  validation loss:		0.449158
  validation accuracy:		86.85 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.298798
  validation loss:		0.418749
  validation accuracy:		87.83 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.296937
  validation loss:		0.422253
  validation accuracy:		87.61 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.295177
  validation loss:		0.424787
  validation accuracy:		87.39 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.305078
  validation loss:		0.436243
  validation accuracy:		88.04 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.318127
  validation loss:		0.414751
  validation accuracy:		88.04 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.298803
  validation loss:		0.468532
  validation accuracy:		86.20 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.303398
  validation loss:		0.429551
  validation accuracy:		87.50 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.291311
  validation loss:		0.435809
  validation accuracy:		86.85 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.295748
  validation loss:		0.411187
  validation accuracy:		88.04 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.298310
  validation loss:		0.434405
  validation accuracy:		87.50 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.289330
  validation loss:		0.417598
  validation accuracy:		87.72 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.293683
  validation loss:		0.424831
  validation accuracy:		88.37 %
Epoch 356 of 2000 took 0.036s
  training loss:		0.292054
  validation loss:		0.446323
  validation accuracy:		87.61 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.295181
  validation loss:		0.412722
  validation accuracy:		88.15 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.312273
  validation loss:		0.436581
  validation accuracy:		87.61 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.295536
  validation loss:		0.417560
  validation accuracy:		87.72 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.300992
  validation loss:		0.429182
  validation accuracy:		87.17 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.302176
  validation loss:		0.408390
  validation accuracy:		88.15 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.289963
  validation loss:		0.437256
  validation accuracy:		86.96 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.293897
  validation loss:		0.420194
  validation accuracy:		88.15 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.302317
  validation loss:		0.425827
  validation accuracy:		88.04 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.292221
  validation loss:		0.427868
  validation accuracy:		88.04 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.302109
  validation loss:		0.434678
  validation accuracy:		87.50 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.293406
  validation loss:		0.441905
  validation accuracy:		87.50 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.293521
  validation loss:		0.449903
  validation accuracy:		86.52 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.291806
  validation loss:		0.419356
  validation accuracy:		87.72 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.285468
  validation loss:		0.422768
  validation accuracy:		87.93 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.291339
  validation loss:		0.414639
  validation accuracy:		87.50 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.299747
  validation loss:		0.434504
  validation accuracy:		87.28 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.293061
  validation loss:		0.451498
  validation accuracy:		86.63 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.289972
  validation loss:		0.455262
  validation accuracy:		86.85 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.294102
  validation loss:		0.438229
  validation accuracy:		87.17 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.311420
  validation loss:		0.421900
  validation accuracy:		87.28 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.297381
  validation loss:		0.422679
  validation accuracy:		87.83 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.284672
  validation loss:		0.440786
  validation accuracy:		86.63 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.290297
  validation loss:		0.417911
  validation accuracy:		88.26 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.295250
  validation loss:		0.429560
  validation accuracy:		86.63 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.291162
  validation loss:		0.430155
  validation accuracy:		87.72 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.293313
  validation loss:		0.442620
  validation accuracy:		87.17 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.299703
  validation loss:		0.425235
  validation accuracy:		87.50 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.292243
  validation loss:		0.430184
  validation accuracy:		86.52 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.301470
  validation loss:		0.416933
  validation accuracy:		87.72 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.306038
  validation loss:		0.449089
  validation accuracy:		86.74 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.290346
  validation loss:		0.409551
  validation accuracy:		88.48 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.295099
  validation loss:		0.429292
  validation accuracy:		87.61 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.290439
  validation loss:		0.442135
  validation accuracy:		86.96 %
Epoch 390 of 2000 took 0.036s
  training loss:		0.291243
  validation loss:		0.426301
  validation accuracy:		87.61 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.290551
  validation loss:		0.431168
  validation accuracy:		86.85 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.287785
  validation loss:		0.429155
  validation accuracy:		86.63 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.296272
  validation loss:		0.419384
  validation accuracy:		88.04 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.299726
  validation loss:		0.426118
  validation accuracy:		87.17 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.290099
  validation loss:		0.425664
  validation accuracy:		87.07 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.292718
  validation loss:		0.433240
  validation accuracy:		87.50 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.289863
  validation loss:		0.433884
  validation accuracy:		87.50 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.285422
  validation loss:		0.413324
  validation accuracy:		88.04 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.289979
  validation loss:		0.422184
  validation accuracy:		87.17 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.291041
  validation loss:		0.434650
  validation accuracy:		86.74 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.297870
  validation loss:		0.446574
  validation accuracy:		87.07 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.296967
  validation loss:		0.414778
  validation accuracy:		87.93 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.292837
  validation loss:		0.426083
  validation accuracy:		87.07 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.290302
  validation loss:		0.429532
  validation accuracy:		87.50 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.286827
  validation loss:		0.434791
  validation accuracy:		87.39 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.292472
  validation loss:		0.426719
  validation accuracy:		87.50 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.286282
  validation loss:		0.427662
  validation accuracy:		87.28 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.296542
  validation loss:		0.440116
  validation accuracy:		86.30 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.295043
  validation loss:		0.420286
  validation accuracy:		87.61 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.281467
  validation loss:		0.445084
  validation accuracy:		86.85 %
Epoch 411 of 2000 took 0.036s
  training loss:		0.287916
  validation loss:		0.409364
  validation accuracy:		88.04 %
Epoch 412 of 2000 took 0.036s
  training loss:		0.288641
  validation loss:		0.428139
  validation accuracy:		87.07 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.291889
  validation loss:		0.428372
  validation accuracy:		87.17 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.287474
  validation loss:		0.419235
  validation accuracy:		87.50 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.287324
  validation loss:		0.429569
  validation accuracy:		86.20 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.296220
  validation loss:		0.430006
  validation accuracy:		87.28 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.288363
  validation loss:		0.426769
  validation accuracy:		88.59 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.293008
  validation loss:		0.497581
  validation accuracy:		85.33 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.288047
  validation loss:		0.438065
  validation accuracy:		87.39 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.288426
  validation loss:		0.415707
  validation accuracy:		87.93 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.302182
  validation loss:		0.419026
  validation accuracy:		87.72 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.284274
  validation loss:		0.412535
  validation accuracy:		88.26 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.287091
  validation loss:		0.415877
  validation accuracy:		88.26 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.290567
  validation loss:		0.416252
  validation accuracy:		87.50 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.287751
  validation loss:		0.431737
  validation accuracy:		86.63 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.286647
  validation loss:		0.438336
  validation accuracy:		86.96 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.297100
  validation loss:		0.425538
  validation accuracy:		87.28 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.287692
  validation loss:		0.443232
  validation accuracy:		87.17 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.291045
  validation loss:		0.421735
  validation accuracy:		87.07 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.288495
  validation loss:		0.427363
  validation accuracy:		87.39 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.287130
  validation loss:		0.414086
  validation accuracy:		88.37 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.296526
  validation loss:		0.436339
  validation accuracy:		86.85 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.294603
  validation loss:		0.473452
  validation accuracy:		85.98 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.291894
  validation loss:		0.417227
  validation accuracy:		88.26 %
Epoch 435 of 2000 took 0.036s
  training loss:		0.285053
  validation loss:		0.422708
  validation accuracy:		87.72 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.288474
  validation loss:		0.419216
  validation accuracy:		87.17 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.285644
  validation loss:		0.424800
  validation accuracy:		86.74 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.284692
  validation loss:		0.430123
  validation accuracy:		87.17 %
Epoch 439 of 2000 took 0.037s
  training loss:		0.284954
  validation loss:		0.427780
  validation accuracy:		86.96 %
Epoch 440 of 2000 took 0.036s
  training loss:		0.288050
  validation loss:		0.408025
  validation accuracy:		88.04 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.287535
  validation loss:		0.421973
  validation accuracy:		87.61 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.289462
  validation loss:		0.419706
  validation accuracy:		87.72 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.291122
  validation loss:		0.448013
  validation accuracy:		86.63 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.296425
  validation loss:		0.411767
  validation accuracy:		87.72 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.282933
  validation loss:		0.411255
  validation accuracy:		87.83 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.287344
  validation loss:		0.434103
  validation accuracy:		87.39 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.281929
  validation loss:		0.413425
  validation accuracy:		87.83 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.289965
  validation loss:		0.458306
  validation accuracy:		86.09 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.290857
  validation loss:		0.428100
  validation accuracy:		87.50 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.285488
  validation loss:		0.440067
  validation accuracy:		86.30 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.281284
  validation loss:		0.402525
  validation accuracy:		88.04 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.290948
  validation loss:		0.450069
  validation accuracy:		86.52 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.280777
  validation loss:		0.442165
  validation accuracy:		86.63 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.286054
  validation loss:		0.439629
  validation accuracy:		87.39 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.283818
  validation loss:		0.421439
  validation accuracy:		87.72 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.285989
  validation loss:		0.440751
  validation accuracy:		86.09 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.281904
  validation loss:		0.427131
  validation accuracy:		87.28 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.286570
  validation loss:		0.449605
  validation accuracy:		86.96 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.287004
  validation loss:		0.423420
  validation accuracy:		87.61 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.287501
  validation loss:		0.420097
  validation accuracy:		87.50 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.283003
  validation loss:		0.437589
  validation accuracy:		86.41 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.285986
  validation loss:		0.429790
  validation accuracy:		86.30 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.295650
  validation loss:		0.443483
  validation accuracy:		87.07 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.283986
  validation loss:		0.409137
  validation accuracy:		87.61 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.287127
  validation loss:		0.440632
  validation accuracy:		86.96 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.286962
  validation loss:		0.445594
  validation accuracy:		86.09 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.306150
  validation loss:		0.426484
  validation accuracy:		87.07 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.291371
  validation loss:		0.441482
  validation accuracy:		86.74 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.286191
  validation loss:		0.437845
  validation accuracy:		87.17 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.280693
  validation loss:		0.446985
  validation accuracy:		86.09 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.287242
  validation loss:		0.416980
  validation accuracy:		87.72 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.291291
  validation loss:		0.431322
  validation accuracy:		86.63 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.293409
  validation loss:		0.427276
  validation accuracy:		87.61 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.286219
  validation loss:		0.428466
  validation accuracy:		87.28 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.280869
  validation loss:		0.434392
  validation accuracy:		86.96 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.286420
  validation loss:		0.423601
  validation accuracy:		87.50 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.283175
  validation loss:		0.435823
  validation accuracy:		87.07 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.282640
  validation loss:		0.444328
  validation accuracy:		86.52 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.288549
  validation loss:		0.440736
  validation accuracy:		86.52 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.285877
  validation loss:		0.430798
  validation accuracy:		87.28 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.286553
  validation loss:		0.418809
  validation accuracy:		88.04 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.283558
  validation loss:		0.448003
  validation accuracy:		86.74 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.283513
  validation loss:		0.444922
  validation accuracy:		87.28 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.284572
  validation loss:		0.437538
  validation accuracy:		87.07 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.282064
  validation loss:		0.426127
  validation accuracy:		86.52 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.288068
  validation loss:		0.430559
  validation accuracy:		87.17 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.290683
  validation loss:		0.418807
  validation accuracy:		86.74 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.286624
  validation loss:		0.425219
  validation accuracy:		87.72 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.282501
  validation loss:		0.422555
  validation accuracy:		87.61 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.282362
  validation loss:		0.425875
  validation accuracy:		86.52 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.277597
  validation loss:		0.429703
  validation accuracy:		87.39 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.290014
  validation loss:		0.442402
  validation accuracy:		86.20 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.284206
  validation loss:		0.436041
  validation accuracy:		86.96 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.291784
  validation loss:		0.440188
  validation accuracy:		86.20 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.284601
  validation loss:		0.415202
  validation accuracy:		87.17 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.286871
  validation loss:		0.430775
  validation accuracy:		86.96 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.284010
  validation loss:		0.425711
  validation accuracy:		86.85 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.285482
  validation loss:		0.436874
  validation accuracy:		86.96 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.285023
  validation loss:		0.425347
  validation accuracy:		86.63 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.275294
  validation loss:		0.432435
  validation accuracy:		86.96 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.287766
  validation loss:		0.440801
  validation accuracy:		86.20 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.282489
  validation loss:		0.416490
  validation accuracy:		87.72 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.277607
  validation loss:		0.440744
  validation accuracy:		87.39 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.288015
  validation loss:		0.418206
  validation accuracy:		87.93 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.285669
  validation loss:		0.431552
  validation accuracy:		87.61 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.287825
  validation loss:		0.424966
  validation accuracy:		87.50 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.278752
  validation loss:		0.434320
  validation accuracy:		87.61 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.282216
  validation loss:		0.415984
  validation accuracy:		87.83 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.278481
  validation loss:		0.448783
  validation accuracy:		86.09 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.281330
  validation loss:		0.427334
  validation accuracy:		87.07 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.295817
  validation loss:		0.427981
  validation accuracy:		86.96 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.283410
  validation loss:		0.446173
  validation accuracy:		86.52 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.286409
  validation loss:		0.428915
  validation accuracy:		87.17 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.278420
  validation loss:		0.430916
  validation accuracy:		87.72 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.285634
  validation loss:		0.456521
  validation accuracy:		85.98 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.289196
  validation loss:		0.433387
  validation accuracy:		86.63 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.279290
  validation loss:		0.452079
  validation accuracy:		86.63 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.270476
  validation loss:		0.444531
  validation accuracy:		86.85 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.278359
  validation loss:		0.445814
  validation accuracy:		86.20 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.282878
  validation loss:		0.454675
  validation accuracy:		86.63 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.282398
  validation loss:		0.431661
  validation accuracy:		86.41 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.278805
  validation loss:		0.426062
  validation accuracy:		88.26 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.282273
  validation loss:		0.409539
  validation accuracy:		87.50 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.284186
  validation loss:		0.424578
  validation accuracy:		87.28 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.279631
  validation loss:		0.428666
  validation accuracy:		86.63 %
Epoch 526 of 2000 took 0.036s
  training loss:		0.284736
  validation loss:		0.429391
  validation accuracy:		86.85 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.278995
  validation loss:		0.419166
  validation accuracy:		86.96 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.292091
  validation loss:		0.427374
  validation accuracy:		88.26 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.275906
  validation loss:		0.415265
  validation accuracy:		87.50 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.284118
  validation loss:		0.433981
  validation accuracy:		86.52 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.278688
  validation loss:		0.421202
  validation accuracy:		87.28 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.282097
  validation loss:		0.425164
  validation accuracy:		87.28 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.279652
  validation loss:		0.447836
  validation accuracy:		86.96 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.283759
  validation loss:		0.424631
  validation accuracy:		87.93 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.280486
  validation loss:		0.442436
  validation accuracy:		86.30 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.285375
  validation loss:		0.487161
  validation accuracy:		85.65 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.284074
  validation loss:		0.426989
  validation accuracy:		87.50 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.287244
  validation loss:		0.417009
  validation accuracy:		87.83 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.284104
  validation loss:		0.430070
  validation accuracy:		87.17 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.285095
  validation loss:		0.422700
  validation accuracy:		87.28 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.283875
  validation loss:		0.416092
  validation accuracy:		87.72 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.278850
  validation loss:		0.430052
  validation accuracy:		86.96 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.281396
  validation loss:		0.458923
  validation accuracy:		85.98 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.286177
  validation loss:		0.426783
  validation accuracy:		86.96 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.283450
  validation loss:		0.430108
  validation accuracy:		88.15 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.289439
  validation loss:		0.443055
  validation accuracy:		86.41 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.287352
  validation loss:		0.435708
  validation accuracy:		87.28 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.276181
  validation loss:		0.436120
  validation accuracy:		87.28 %
Epoch 549 of 2000 took 0.036s
  training loss:		0.268622
  validation loss:		0.452280
  validation accuracy:		86.52 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.286470
  validation loss:		0.441559
  validation accuracy:		86.85 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.282192
  validation loss:		0.440239
  validation accuracy:		86.52 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.286330
  validation loss:		0.454285
  validation accuracy:		86.09 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.282455
  validation loss:		0.436775
  validation accuracy:		86.74 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.278385
  validation loss:		0.429879
  validation accuracy:		87.07 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.275974
  validation loss:		0.446409
  validation accuracy:		86.63 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.292802
  validation loss:		0.473258
  validation accuracy:		85.87 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.283321
  validation loss:		0.431462
  validation accuracy:		87.93 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.281877
  validation loss:		0.422779
  validation accuracy:		87.17 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.279848
  validation loss:		0.461933
  validation accuracy:		86.30 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.292591
  validation loss:		0.451194
  validation accuracy:		86.85 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.283702
  validation loss:		0.446114
  validation accuracy:		86.09 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.282614
  validation loss:		0.437427
  validation accuracy:		87.39 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.281060
  validation loss:		0.438911
  validation accuracy:		86.52 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.277907
  validation loss:		0.451796
  validation accuracy:		86.63 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.270394
  validation loss:		0.437541
  validation accuracy:		87.39 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.282412
  validation loss:		0.444435
  validation accuracy:		87.28 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.275865
  validation loss:		0.438947
  validation accuracy:		87.83 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.279766
  validation loss:		0.450529
  validation accuracy:		86.96 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.281038
  validation loss:		0.447507
  validation accuracy:		86.63 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.274349
  validation loss:		0.433800
  validation accuracy:		86.74 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.284238
  validation loss:		0.452395
  validation accuracy:		85.98 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.283227
  validation loss:		0.414655
  validation accuracy:		87.83 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.276402
  validation loss:		0.426408
  validation accuracy:		86.85 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.281826
  validation loss:		0.434362
  validation accuracy:		87.93 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.279723
  validation loss:		0.439193
  validation accuracy:		86.63 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.282283
  validation loss:		0.428410
  validation accuracy:		88.48 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.278002
  validation loss:		0.433587
  validation accuracy:		86.85 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.283271
  validation loss:		0.479422
  validation accuracy:		85.33 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.283142
  validation loss:		0.426805
  validation accuracy:		87.17 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.281854
  validation loss:		0.453062
  validation accuracy:		86.41 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.275419
  validation loss:		0.431893
  validation accuracy:		87.50 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.278211
  validation loss:		0.440106
  validation accuracy:		86.74 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.280210
  validation loss:		0.424890
  validation accuracy:		87.61 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.276696
  validation loss:		0.432126
  validation accuracy:		86.96 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.278289
  validation loss:		0.433095
  validation accuracy:		87.50 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.278865
  validation loss:		0.448767
  validation accuracy:		86.52 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.281952
  validation loss:		0.447957
  validation accuracy:		86.09 %
Epoch 588 of 2000 took 0.036s
  training loss:		0.277767
  validation loss:		0.424864
  validation accuracy:		87.72 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.281802
  validation loss:		0.420601
  validation accuracy:		87.50 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.281778
  validation loss:		0.443967
  validation accuracy:		87.39 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.276026
  validation loss:		0.454242
  validation accuracy:		86.52 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.279562
  validation loss:		0.440289
  validation accuracy:		87.07 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.275540
  validation loss:		0.418721
  validation accuracy:		87.39 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.275443
  validation loss:		0.441716
  validation accuracy:		87.39 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.281752
  validation loss:		0.433042
  validation accuracy:		86.52 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.278368
  validation loss:		0.427709
  validation accuracy:		86.96 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.280520
  validation loss:		0.427242
  validation accuracy:		87.61 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.283952
  validation loss:		0.454514
  validation accuracy:		85.87 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.279444
  validation loss:		0.434466
  validation accuracy:		86.52 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.285704
  validation loss:		0.462630
  validation accuracy:		85.98 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.290091
  validation loss:		0.451857
  validation accuracy:		87.61 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.276899
  validation loss:		0.434687
  validation accuracy:		86.96 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.283477
  validation loss:		0.430728
  validation accuracy:		86.96 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.286067
  validation loss:		0.419523
  validation accuracy:		87.50 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.281152
  validation loss:		0.457331
  validation accuracy:		86.74 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.282451
  validation loss:		0.438583
  validation accuracy:		87.28 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.278215
  validation loss:		0.414946
  validation accuracy:		87.50 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.279227
  validation loss:		0.422331
  validation accuracy:		87.83 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.274518
  validation loss:		0.428788
  validation accuracy:		86.96 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.281021
  validation loss:		0.427748
  validation accuracy:		86.74 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.274395
  validation loss:		0.450924
  validation accuracy:		86.85 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.282328
  validation loss:		0.427823
  validation accuracy:		86.74 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.279356
  validation loss:		0.440018
  validation accuracy:		86.63 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.281199
  validation loss:		0.445792
  validation accuracy:		86.20 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.275017
  validation loss:		0.437682
  validation accuracy:		86.96 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.274237
  validation loss:		0.465018
  validation accuracy:		85.76 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.284716
  validation loss:		0.428755
  validation accuracy:		87.72 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.277519
  validation loss:		0.432352
  validation accuracy:		86.41 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.271170
  validation loss:		0.430861
  validation accuracy:		87.17 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.272015
  validation loss:		0.424336
  validation accuracy:		86.85 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.268672
  validation loss:		0.429090
  validation accuracy:		87.72 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.271532
  validation loss:		0.448144
  validation accuracy:		86.52 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.274327
  validation loss:		0.433618
  validation accuracy:		87.72 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.284042
  validation loss:		0.454882
  validation accuracy:		86.74 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.277785
  validation loss:		0.423215
  validation accuracy:		87.39 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.282039
  validation loss:		0.444146
  validation accuracy:		87.39 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.283797
  validation loss:		0.463452
  validation accuracy:		86.20 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.284075
  validation loss:		0.442374
  validation accuracy:		87.07 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.283896
  validation loss:		0.427922
  validation accuracy:		87.28 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.277350
  validation loss:		0.418093
  validation accuracy:		88.04 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.277384
  validation loss:		0.442454
  validation accuracy:		87.07 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.283837
  validation loss:		0.426536
  validation accuracy:		88.37 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.273340
  validation loss:		0.430399
  validation accuracy:		87.72 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.281499
  validation loss:		0.431903
  validation accuracy:		87.72 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.273882
  validation loss:		0.414697
  validation accuracy:		87.39 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.279900
  validation loss:		0.433220
  validation accuracy:		86.96 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.280932
  validation loss:		0.438074
  validation accuracy:		86.85 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.271886
  validation loss:		0.440450
  validation accuracy:		87.39 %
Epoch 639 of 2000 took 0.036s
  training loss:		0.276805
  validation loss:		0.440122
  validation accuracy:		87.61 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.274587
  validation loss:		0.445325
  validation accuracy:		86.74 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.283051
  validation loss:		0.451170
  validation accuracy:		87.07 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.279986
  validation loss:		0.441482
  validation accuracy:		86.96 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.280216
  validation loss:		0.451113
  validation accuracy:		87.28 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.282499
  validation loss:		0.460882
  validation accuracy:		85.98 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.280702
  validation loss:		0.433668
  validation accuracy:		87.39 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.279947
  validation loss:		0.432540
  validation accuracy:		87.61 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.275419
  validation loss:		0.432396
  validation accuracy:		88.04 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.278629
  validation loss:		0.432410
  validation accuracy:		86.96 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.276891
  validation loss:		0.459497
  validation accuracy:		86.63 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.280371
  validation loss:		0.450782
  validation accuracy:		86.74 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.275890
  validation loss:		0.427969
  validation accuracy:		87.61 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.276643
  validation loss:		0.443888
  validation accuracy:		86.96 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.277066
  validation loss:		0.444873
  validation accuracy:		87.07 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.278717
  validation loss:		0.433068
  validation accuracy:		87.17 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.271781
  validation loss:		0.418863
  validation accuracy:		86.96 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.277319
  validation loss:		0.454069
  validation accuracy:		86.52 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.269398
  validation loss:		0.455546
  validation accuracy:		86.96 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.270984
  validation loss:		0.449254
  validation accuracy:		87.28 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.277461
  validation loss:		0.438976
  validation accuracy:		87.61 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.276316
  validation loss:		0.433273
  validation accuracy:		86.85 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.273378
  validation loss:		0.437859
  validation accuracy:		86.63 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.282466
  validation loss:		0.425072
  validation accuracy:		86.96 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.269682
  validation loss:		0.454012
  validation accuracy:		86.63 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.274474
  validation loss:		0.436904
  validation accuracy:		86.85 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.273724
  validation loss:		0.440605
  validation accuracy:		87.39 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.274532
  validation loss:		0.448102
  validation accuracy:		87.28 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.271121
  validation loss:		0.430642
  validation accuracy:		87.72 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.278099
  validation loss:		0.440189
  validation accuracy:		87.17 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.272370
  validation loss:		0.416857
  validation accuracy:		87.17 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.275897
  validation loss:		0.442605
  validation accuracy:		86.52 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.284249
  validation loss:		0.432160
  validation accuracy:		87.72 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.277611
  validation loss:		0.450107
  validation accuracy:		86.74 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.273226
  validation loss:		0.454277
  validation accuracy:		86.30 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.278698
  validation loss:		0.439026
  validation accuracy:		86.52 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.274566
  validation loss:		0.438700
  validation accuracy:		87.07 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.282409
  validation loss:		0.455688
  validation accuracy:		87.07 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.278324
  validation loss:		0.441686
  validation accuracy:		86.96 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.270911
  validation loss:		0.451708
  validation accuracy:		87.39 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.270897
  validation loss:		0.441211
  validation accuracy:		87.17 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.274393
  validation loss:		0.445851
  validation accuracy:		86.41 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.273120
  validation loss:		0.416539
  validation accuracy:		87.61 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.278993
  validation loss:		0.437375
  validation accuracy:		87.07 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.277248
  validation loss:		0.432083
  validation accuracy:		87.28 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.274156
  validation loss:		0.445894
  validation accuracy:		86.20 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.278608
  validation loss:		0.439133
  validation accuracy:		87.07 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.268816
  validation loss:		0.470264
  validation accuracy:		85.76 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.280078
  validation loss:		0.437937
  validation accuracy:		86.85 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.271268
  validation loss:		0.433511
  validation accuracy:		86.85 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.274774
  validation loss:		0.442364
  validation accuracy:		87.17 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.274148
  validation loss:		0.438393
  validation accuracy:		87.61 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.276803
  validation loss:		0.427644
  validation accuracy:		86.96 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.274860
  validation loss:		0.430262
  validation accuracy:		87.72 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.272254
  validation loss:		0.424479
  validation accuracy:		87.28 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.276491
  validation loss:		0.437036
  validation accuracy:		86.63 %
Epoch 695 of 2000 took 0.036s
  training loss:		0.269765
  validation loss:		0.442845
  validation accuracy:		87.17 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.271631
  validation loss:		0.437800
  validation accuracy:		86.52 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.274798
  validation loss:		0.443556
  validation accuracy:		87.28 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.274992
  validation loss:		0.466005
  validation accuracy:		86.41 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.271005
  validation loss:		0.454409
  validation accuracy:		86.41 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.277935
  validation loss:		0.450926
  validation accuracy:		86.52 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.274509
  validation loss:		0.422987
  validation accuracy:		87.83 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.271797
  validation loss:		0.439944
  validation accuracy:		87.17 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.269222
  validation loss:		0.442947
  validation accuracy:		86.85 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.276366
  validation loss:		0.450264
  validation accuracy:		86.85 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.275677
  validation loss:		0.430060
  validation accuracy:		87.28 %
Epoch 706 of 2000 took 0.036s
  training loss:		0.271613
  validation loss:		0.437055
  validation accuracy:		87.07 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.274643
  validation loss:		0.439052
  validation accuracy:		87.07 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.266744
  validation loss:		0.421497
  validation accuracy:		87.93 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.272239
  validation loss:		0.436558
  validation accuracy:		87.61 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.274835
  validation loss:		0.445056
  validation accuracy:		86.63 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.273543
  validation loss:		0.437252
  validation accuracy:		86.41 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.270279
  validation loss:		0.437685
  validation accuracy:		87.17 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.272998
  validation loss:		0.445316
  validation accuracy:		87.72 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.277587
  validation loss:		0.455037
  validation accuracy:		86.30 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.270878
  validation loss:		0.444435
  validation accuracy:		87.50 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.275885
  validation loss:		0.437829
  validation accuracy:		87.39 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.268476
  validation loss:		0.434078
  validation accuracy:		86.74 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.273495
  validation loss:		0.438578
  validation accuracy:		87.39 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.282503
  validation loss:		0.426779
  validation accuracy:		87.50 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.273774
  validation loss:		0.427884
  validation accuracy:		87.72 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.277925
  validation loss:		0.458024
  validation accuracy:		86.52 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.268835
  validation loss:		0.431805
  validation accuracy:		87.07 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.275741
  validation loss:		0.455698
  validation accuracy:		86.96 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.275124
  validation loss:		0.417232
  validation accuracy:		88.15 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.275811
  validation loss:		0.429272
  validation accuracy:		87.07 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.273757
  validation loss:		0.437162
  validation accuracy:		87.50 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.273756
  validation loss:		0.430258
  validation accuracy:		87.72 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.268710
  validation loss:		0.436115
  validation accuracy:		87.50 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.275298
  validation loss:		0.441354
  validation accuracy:		87.17 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.272868
  validation loss:		0.441301
  validation accuracy:		87.39 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.276114
  validation loss:		0.431795
  validation accuracy:		87.72 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.268415
  validation loss:		0.414048
  validation accuracy:		87.83 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.274258
  validation loss:		0.440484
  validation accuracy:		87.28 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.273768
  validation loss:		0.456138
  validation accuracy:		86.96 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.272486
  validation loss:		0.450216
  validation accuracy:		86.74 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.273862
  validation loss:		0.434131
  validation accuracy:		86.63 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.271923
  validation loss:		0.444372
  validation accuracy:		86.52 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.273586
  validation loss:		0.448517
  validation accuracy:		87.07 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.275975
  validation loss:		0.431578
  validation accuracy:		86.74 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.279623
  validation loss:		0.431779
  validation accuracy:		87.61 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.268938
  validation loss:		0.421480
  validation accuracy:		87.72 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.270506
  validation loss:		0.428942
  validation accuracy:		87.07 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.269911
  validation loss:		0.433592
  validation accuracy:		86.63 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.275669
  validation loss:		0.448003
  validation accuracy:		87.07 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.274020
  validation loss:		0.427325
  validation accuracy:		87.50 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.282287
  validation loss:		0.436240
  validation accuracy:		87.07 %
Epoch 747 of 2000 took 0.036s
  training loss:		0.274148
  validation loss:		0.455568
  validation accuracy:		86.52 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.271073
  validation loss:		0.434147
  validation accuracy:		87.39 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.274341
  validation loss:		0.433255
  validation accuracy:		86.63 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.274628
  validation loss:		0.449100
  validation accuracy:		87.07 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.272322
  validation loss:		0.446916
  validation accuracy:		86.96 %
Epoch 752 of 2000 took 0.036s
  training loss:		0.273136
  validation loss:		0.440515
  validation accuracy:		87.17 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.264341
  validation loss:		0.422776
  validation accuracy:		86.85 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.272523
  validation loss:		0.432620
  validation accuracy:		86.74 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.273725
  validation loss:		0.428371
  validation accuracy:		87.50 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.272024
  validation loss:		0.444269
  validation accuracy:		86.63 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.279978
  validation loss:		0.447278
  validation accuracy:		87.61 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.277285
  validation loss:		0.440990
  validation accuracy:		87.61 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.274131
  validation loss:		0.416080
  validation accuracy:		88.04 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.274109
  validation loss:		0.434357
  validation accuracy:		87.72 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.276985
  validation loss:		0.440616
  validation accuracy:		87.39 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.269614
  validation loss:		0.461282
  validation accuracy:		86.74 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.275491
  validation loss:		0.437061
  validation accuracy:		87.39 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.268847
  validation loss:		0.441729
  validation accuracy:		87.28 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.279388
  validation loss:		0.454914
  validation accuracy:		87.39 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.273146
  validation loss:		0.454007
  validation accuracy:		86.20 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.277233
  validation loss:		0.445304
  validation accuracy:		87.39 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.275290
  validation loss:		0.433481
  validation accuracy:		87.61 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.274465
  validation loss:		0.429807
  validation accuracy:		87.28 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.271128
  validation loss:		0.443503
  validation accuracy:		87.28 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.273452
  validation loss:		0.431483
  validation accuracy:		86.96 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.275206
  validation loss:		0.430347
  validation accuracy:		86.85 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.266327
  validation loss:		0.441631
  validation accuracy:		87.07 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.275738
  validation loss:		0.456522
  validation accuracy:		86.85 %
Epoch 775 of 2000 took 0.036s
  training loss:		0.276882
  validation loss:		0.435168
  validation accuracy:		87.28 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.276721
  validation loss:		0.437772
  validation accuracy:		86.41 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.272306
  validation loss:		0.424917
  validation accuracy:		86.96 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.272573
  validation loss:		0.436538
  validation accuracy:		87.28 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.271008
  validation loss:		0.436138
  validation accuracy:		87.07 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.270679
  validation loss:		0.434100
  validation accuracy:		87.17 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.275290
  validation loss:		0.453794
  validation accuracy:		87.07 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.277488
  validation loss:		0.441434
  validation accuracy:		86.52 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.268959
  validation loss:		0.424764
  validation accuracy:		87.17 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.284561
  validation loss:		0.446086
  validation accuracy:		86.41 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.274087
  validation loss:		0.441153
  validation accuracy:		86.96 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.273350
  validation loss:		0.450588
  validation accuracy:		86.96 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.269235
  validation loss:		0.455201
  validation accuracy:		87.50 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.273775
  validation loss:		0.451228
  validation accuracy:		87.28 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.276620
  validation loss:		0.425802
  validation accuracy:		87.07 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.267149
  validation loss:		0.427913
  validation accuracy:		87.17 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.272800
  validation loss:		0.433271
  validation accuracy:		87.83 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.271718
  validation loss:		0.443495
  validation accuracy:		87.28 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.273837
  validation loss:		0.451540
  validation accuracy:		86.85 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.272852
  validation loss:		0.441106
  validation accuracy:		87.07 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.274310
  validation loss:		0.429688
  validation accuracy:		87.07 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.269324
  validation loss:		0.433931
  validation accuracy:		87.72 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.273060
  validation loss:		0.430000
  validation accuracy:		86.63 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.265621
  validation loss:		0.430901
  validation accuracy:		86.96 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.278831
  validation loss:		0.437138
  validation accuracy:		87.39 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.277218
  validation loss:		0.445047
  validation accuracy:		86.41 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.273869
  validation loss:		0.456566
  validation accuracy:		86.96 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.272890
  validation loss:		0.443823
  validation accuracy:		87.07 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.272001
  validation loss:		0.441633
  validation accuracy:		87.07 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.267273
  validation loss:		0.425096
  validation accuracy:		87.93 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.272644
  validation loss:		0.446394
  validation accuracy:		87.17 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.272212
  validation loss:		0.418894
  validation accuracy:		87.28 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.270672
  validation loss:		0.445339
  validation accuracy:		87.17 %
Epoch 808 of 2000 took 0.036s
  training loss:		0.277501
  validation loss:		0.437911
  validation accuracy:		87.72 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.271116
  validation loss:		0.427976
  validation accuracy:		88.04 %
Epoch 810 of 2000 took 0.037s
  training loss:		0.272562
  validation loss:		0.422679
  validation accuracy:		88.15 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.270515
  validation loss:		0.463620
  validation accuracy:		86.52 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.271840
  validation loss:		0.432177
  validation accuracy:		87.07 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.274362
  validation loss:		0.454293
  validation accuracy:		86.63 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.277695
  validation loss:		0.438222
  validation accuracy:		86.85 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.268117
  validation loss:		0.419028
  validation accuracy:		87.83 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.271902
  validation loss:		0.440803
  validation accuracy:		86.96 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.272398
  validation loss:		0.425445
  validation accuracy:		87.17 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.273181
  validation loss:		0.444089
  validation accuracy:		87.17 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.278328
  validation loss:		0.444935
  validation accuracy:		86.96 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.268189
  validation loss:		0.435312
  validation accuracy:		87.07 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.275369
  validation loss:		0.429985
  validation accuracy:		86.85 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.270444
  validation loss:		0.449017
  validation accuracy:		86.41 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.270309
  validation loss:		0.420679
  validation accuracy:		88.15 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.273355
  validation loss:		0.437430
  validation accuracy:		87.07 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.269688
  validation loss:		0.416574
  validation accuracy:		87.07 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.270504
  validation loss:		0.422315
  validation accuracy:		87.83 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.269837
  validation loss:		0.441863
  validation accuracy:		86.74 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.269115
  validation loss:		0.420701
  validation accuracy:		87.28 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.273590
  validation loss:		0.423023
  validation accuracy:		87.50 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.275237
  validation loss:		0.427603
  validation accuracy:		87.83 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.269116
  validation loss:		0.445165
  validation accuracy:		86.85 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.271666
  validation loss:		0.418004
  validation accuracy:		87.83 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.263390
  validation loss:		0.436917
  validation accuracy:		86.74 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.271188
  validation loss:		0.433507
  validation accuracy:		87.72 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.268902
  validation loss:		0.460015
  validation accuracy:		87.28 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.270839
  validation loss:		0.428461
  validation accuracy:		87.61 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.269917
  validation loss:		0.432144
  validation accuracy:		87.07 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.278963
  validation loss:		0.459256
  validation accuracy:		86.30 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.277247
  validation loss:		0.446941
  validation accuracy:		87.28 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.276024
  validation loss:		0.436422
  validation accuracy:		87.39 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.273966
  validation loss:		0.426729
  validation accuracy:		86.96 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.276347
  validation loss:		0.439508
  validation accuracy:		86.85 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.267249
  validation loss:		0.429631
  validation accuracy:		87.07 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.268846
  validation loss:		0.412067
  validation accuracy:		87.93 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.271860
  validation loss:		0.466622
  validation accuracy:		86.74 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.268015
  validation loss:		0.440174
  validation accuracy:		87.07 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.273146
  validation loss:		0.464100
  validation accuracy:		86.63 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.269600
  validation loss:		0.443747
  validation accuracy:		87.50 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.269061
  validation loss:		0.466566
  validation accuracy:		86.63 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.274686
  validation loss:		0.424935
  validation accuracy:		87.72 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.273009
  validation loss:		0.434660
  validation accuracy:		87.50 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.269922
  validation loss:		0.428536
  validation accuracy:		87.28 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.273601
  validation loss:		0.441949
  validation accuracy:		86.96 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.272508
  validation loss:		0.429638
  validation accuracy:		87.28 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.279535
  validation loss:		0.422407
  validation accuracy:		87.83 %
Epoch 856 of 2000 took 0.036s
  training loss:		0.271588
  validation loss:		0.459663
  validation accuracy:		86.96 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.268580
  validation loss:		0.438069
  validation accuracy:		86.96 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.269176
  validation loss:		0.434959
  validation accuracy:		88.04 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.263507
  validation loss:		0.439042
  validation accuracy:		87.28 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.272562
  validation loss:		0.413674
  validation accuracy:		87.39 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.270948
  validation loss:		0.464647
  validation accuracy:		86.41 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.273815
  validation loss:		0.457494
  validation accuracy:		85.98 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.267153
  validation loss:		0.450459
  validation accuracy:		87.28 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.275339
  validation loss:		0.453541
  validation accuracy:		86.63 %
Epoch 865 of 2000 took 0.036s
  training loss:		0.273375
  validation loss:		0.462478
  validation accuracy:		86.74 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.269796
  validation loss:		0.455224
  validation accuracy:		86.85 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.266176
  validation loss:		0.465370
  validation accuracy:		86.74 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.271596
  validation loss:		0.429653
  validation accuracy:		88.04 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.272301
  validation loss:		0.442364
  validation accuracy:		87.28 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.266348
  validation loss:		0.469974
  validation accuracy:		86.52 %
Epoch 871 of 2000 took 0.036s
  training loss:		0.269639
  validation loss:		0.460646
  validation accuracy:		86.85 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.278143
  validation loss:		0.433926
  validation accuracy:		87.61 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.269778
  validation loss:		0.442257
  validation accuracy:		87.17 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.269726
  validation loss:		0.455389
  validation accuracy:		86.96 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.272531
  validation loss:		0.440970
  validation accuracy:		87.07 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.271289
  validation loss:		0.450493
  validation accuracy:		87.61 %
Epoch 877 of 2000 took 0.036s
  training loss:		0.273555
  validation loss:		0.432289
  validation accuracy:		87.17 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.273706
  validation loss:		0.421510
  validation accuracy:		87.17 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.265274
  validation loss:		0.421050
  validation accuracy:		88.26 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.268959
  validation loss:		0.455043
  validation accuracy:		87.07 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.271346
  validation loss:		0.437010
  validation accuracy:		87.93 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.274669
  validation loss:		0.442408
  validation accuracy:		87.07 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.271429
  validation loss:		0.444348
  validation accuracy:		86.96 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.278360
  validation loss:		0.425880
  validation accuracy:		87.39 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.263443
  validation loss:		0.429853
  validation accuracy:		86.96 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.275870
  validation loss:		0.422528
  validation accuracy:		87.17 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.272268
  validation loss:		0.434634
  validation accuracy:		87.07 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.275591
  validation loss:		0.447543
  validation accuracy:		87.07 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.270298
  validation loss:		0.444138
  validation accuracy:		87.17 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.268160
  validation loss:		0.421097
  validation accuracy:		87.28 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.273515
  validation loss:		0.449759
  validation accuracy:		87.28 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.272155
  validation loss:		0.414304
  validation accuracy:		87.61 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.268118
  validation loss:		0.414977
  validation accuracy:		87.61 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.274018
  validation loss:		0.425904
  validation accuracy:		87.07 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.270337
  validation loss:		0.447029
  validation accuracy:		87.28 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.273604
  validation loss:		0.452852
  validation accuracy:		87.17 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.279065
  validation loss:		0.483766
  validation accuracy:		86.20 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.273481
  validation loss:		0.419361
  validation accuracy:		87.83 %
Epoch 899 of 2000 took 0.036s
  training loss:		0.264303
  validation loss:		0.436707
  validation accuracy:		87.39 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.276693
  validation loss:		0.430762
  validation accuracy:		87.50 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.271926
  validation loss:		0.437843
  validation accuracy:		87.39 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.268126
  validation loss:		0.427762
  validation accuracy:		88.04 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.266042
  validation loss:		0.464489
  validation accuracy:		86.63 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.265001
  validation loss:		0.447726
  validation accuracy:		87.17 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.271151
  validation loss:		0.439343
  validation accuracy:		87.39 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.270129
  validation loss:		0.445065
  validation accuracy:		87.28 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.265072
  validation loss:		0.437656
  validation accuracy:		87.72 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.272520
  validation loss:		0.427894
  validation accuracy:		87.93 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.271975
  validation loss:		0.426556
  validation accuracy:		87.50 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.273953
  validation loss:		0.432952
  validation accuracy:		87.28 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.264095
  validation loss:		0.437330
  validation accuracy:		87.83 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.270927
  validation loss:		0.467105
  validation accuracy:		86.52 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.265024
  validation loss:		0.445617
  validation accuracy:		87.50 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.270120
  validation loss:		0.428734
  validation accuracy:		87.39 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.267505
  validation loss:		0.448675
  validation accuracy:		86.30 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.271245
  validation loss:		0.454922
  validation accuracy:		86.85 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.270312
  validation loss:		0.442858
  validation accuracy:		86.96 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.269228
  validation loss:		0.443241
  validation accuracy:		87.28 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.272491
  validation loss:		0.440659
  validation accuracy:		87.72 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.264326
  validation loss:		0.421482
  validation accuracy:		87.61 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.264659
  validation loss:		0.432992
  validation accuracy:		87.17 %
Epoch 922 of 2000 took 0.036s
  training loss:		0.271192
  validation loss:		0.442826
  validation accuracy:		87.39 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.270822
  validation loss:		0.436035
  validation accuracy:		87.72 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.271747
  validation loss:		0.446415
  validation accuracy:		86.96 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.279270
  validation loss:		0.417737
  validation accuracy:		87.72 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.270779
  validation loss:		0.429876
  validation accuracy:		87.61 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.261984
  validation loss:		0.430227
  validation accuracy:		88.15 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.269081
  validation loss:		0.442463
  validation accuracy:		87.07 %
Epoch 929 of 2000 took 0.036s
  training loss:		0.277649
  validation loss:		0.425855
  validation accuracy:		87.17 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.270806
  validation loss:		0.424774
  validation accuracy:		87.50 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.272609
  validation loss:		0.459742
  validation accuracy:		87.17 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.272530
  validation loss:		0.424640
  validation accuracy:		87.39 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.269743
  validation loss:		0.433714
  validation accuracy:		87.07 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.273193
  validation loss:		0.460680
  validation accuracy:		86.74 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.271535
  validation loss:		0.432202
  validation accuracy:		87.17 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.264609
  validation loss:		0.411087
  validation accuracy:		87.50 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.275107
  validation loss:		0.440288
  validation accuracy:		87.28 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.266479
  validation loss:		0.437114
  validation accuracy:		87.28 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.272853
  validation loss:		0.435926
  validation accuracy:		87.50 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.265680
  validation loss:		0.441068
  validation accuracy:		86.41 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.269733
  validation loss:		0.439723
  validation accuracy:		87.61 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.271391
  validation loss:		0.436686
  validation accuracy:		87.28 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.274793
  validation loss:		0.427501
  validation accuracy:		87.61 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.267225
  validation loss:		0.439470
  validation accuracy:		86.74 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.275215
  validation loss:		0.424989
  validation accuracy:		87.83 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.268690
  validation loss:		0.443817
  validation accuracy:		87.07 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.267193
  validation loss:		0.424338
  validation accuracy:		88.37 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.270572
  validation loss:		0.430844
  validation accuracy:		87.07 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.271112
  validation loss:		0.441351
  validation accuracy:		87.83 %
Epoch 950 of 2000 took 0.036s
  training loss:		0.268570
  validation loss:		0.426681
  validation accuracy:		87.72 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.267930
  validation loss:		0.432242
  validation accuracy:		88.15 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.265003
  validation loss:		0.421112
  validation accuracy:		88.26 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.264600
  validation loss:		0.426777
  validation accuracy:		87.39 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.270137
  validation loss:		0.426290
  validation accuracy:		87.39 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.268137
  validation loss:		0.422581
  validation accuracy:		88.26 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.262968
  validation loss:		0.428088
  validation accuracy:		87.93 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.263720
  validation loss:		0.435650
  validation accuracy:		87.28 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.277809
  validation loss:		0.435152
  validation accuracy:		86.74 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.274990
  validation loss:		0.446028
  validation accuracy:		87.28 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.271147
  validation loss:		0.440878
  validation accuracy:		87.39 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.268045
  validation loss:		0.425553
  validation accuracy:		88.26 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.264075
  validation loss:		0.428715
  validation accuracy:		87.50 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.268671
  validation loss:		0.433377
  validation accuracy:		88.04 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.268504
  validation loss:		0.428225
  validation accuracy:		87.17 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.266996
  validation loss:		0.426678
  validation accuracy:		87.39 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.267771
  validation loss:		0.423773
  validation accuracy:		87.72 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.265608
  validation loss:		0.435086
  validation accuracy:		87.61 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.268750
  validation loss:		0.427607
  validation accuracy:		88.04 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.266541
  validation loss:		0.446875
  validation accuracy:		87.17 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.267138
  validation loss:		0.442737
  validation accuracy:		87.28 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.272911
  validation loss:		0.431474
  validation accuracy:		87.93 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.264017
  validation loss:		0.423597
  validation accuracy:		88.04 %
Epoch 973 of 2000 took 0.036s
  training loss:		0.265108
  validation loss:		0.431055
  validation accuracy:		87.50 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.264965
  validation loss:		0.449407
  validation accuracy:		87.39 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.270567
  validation loss:		0.429598
  validation accuracy:		87.72 %
Epoch 976 of 2000 took 0.036s
  training loss:		0.268093
  validation loss:		0.432860
  validation accuracy:		87.39 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.273504
  validation loss:		0.447732
  validation accuracy:		87.39 %
Epoch 978 of 2000 took 0.036s
  training loss:		0.268132
  validation loss:		0.420671
  validation accuracy:		87.93 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.264736
  validation loss:		0.438915
  validation accuracy:		87.28 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.266890
  validation loss:		0.439511
  validation accuracy:		86.85 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.266544
  validation loss:		0.444997
  validation accuracy:		86.41 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.272933
  validation loss:		0.422779
  validation accuracy:		87.50 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.266466
  validation loss:		0.444025
  validation accuracy:		87.50 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.264639
  validation loss:		0.445099
  validation accuracy:		87.50 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.269333
  validation loss:		0.432417
  validation accuracy:		87.39 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.269783
  validation loss:		0.444065
  validation accuracy:		87.50 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.268880
  validation loss:		0.434984
  validation accuracy:		87.93 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.269019
  validation loss:		0.438426
  validation accuracy:		87.17 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.273924
  validation loss:		0.457285
  validation accuracy:		87.17 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.264550
  validation loss:		0.423486
  validation accuracy:		87.39 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.274460
  validation loss:		0.424204
  validation accuracy:		87.50 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.273626
  validation loss:		0.422709
  validation accuracy:		87.39 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.265379
  validation loss:		0.464156
  validation accuracy:		86.41 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.270101
  validation loss:		0.438796
  validation accuracy:		87.17 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.264742
  validation loss:		0.415343
  validation accuracy:		87.72 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.267038
  validation loss:		0.437512
  validation accuracy:		87.39 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.269833
  validation loss:		0.445963
  validation accuracy:		87.39 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.272253
  validation loss:		0.440582
  validation accuracy:		87.17 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.264083
  validation loss:		0.445900
  validation accuracy:		87.28 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.271339
  validation loss:		0.434643
  validation accuracy:		87.50 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.266784
  validation loss:		0.438349
  validation accuracy:		86.96 %
Epoch 1002 of 2000 took 0.036s
  training loss:		0.270067
  validation loss:		0.440939
  validation accuracy:		87.28 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.275629
  validation loss:		0.415660
  validation accuracy:		87.93 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.272417
  validation loss:		0.421969
  validation accuracy:		87.93 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.267281
  validation loss:		0.440000
  validation accuracy:		87.39 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.268066
  validation loss:		0.423099
  validation accuracy:		87.39 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.269870
  validation loss:		0.432416
  validation accuracy:		87.50 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.270670
  validation loss:		0.450998
  validation accuracy:		86.41 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.269885
  validation loss:		0.446786
  validation accuracy:		87.17 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.275251
  validation loss:		0.429307
  validation accuracy:		87.50 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.272061
  validation loss:		0.423786
  validation accuracy:		87.39 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.261802
  validation loss:		0.424154
  validation accuracy:		88.04 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.270920
  validation loss:		0.419664
  validation accuracy:		88.26 %
Epoch 1014 of 2000 took 0.036s
  training loss:		0.272752
  validation loss:		0.431920
  validation accuracy:		87.61 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.259613
  validation loss:		0.425546
  validation accuracy:		87.39 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.264235
  validation loss:		0.446366
  validation accuracy:		87.28 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.265135
  validation loss:		0.445961
  validation accuracy:		87.50 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.266237
  validation loss:		0.481147
  validation accuracy:		85.98 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.267616
  validation loss:		0.457285
  validation accuracy:		86.85 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.268518
  validation loss:		0.424628
  validation accuracy:		87.39 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.268750
  validation loss:		0.458683
  validation accuracy:		86.74 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.273117
  validation loss:		0.437360
  validation accuracy:		87.07 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.265044
  validation loss:		0.440669
  validation accuracy:		87.17 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.270292
  validation loss:		0.446438
  validation accuracy:		87.61 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.273302
  validation loss:		0.436152
  validation accuracy:		87.83 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.275911
  validation loss:		0.431190
  validation accuracy:		87.72 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.269784
  validation loss:		0.450222
  validation accuracy:		86.30 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.271779
  validation loss:		0.454476
  validation accuracy:		87.28 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.272486
  validation loss:		0.416868
  validation accuracy:		87.83 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.266761
  validation loss:		0.431992
  validation accuracy:		87.50 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.265729
  validation loss:		0.440914
  validation accuracy:		87.07 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.267681
  validation loss:		0.438067
  validation accuracy:		87.50 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.273700
  validation loss:		0.430031
  validation accuracy:		87.50 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.267346
  validation loss:		0.435376
  validation accuracy:		87.17 %
Epoch 1035 of 2000 took 0.036s
  training loss:		0.269525
  validation loss:		0.426860
  validation accuracy:		88.15 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.266579
  validation loss:		0.433000
  validation accuracy:		86.96 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.270462
  validation loss:		0.453742
  validation accuracy:		86.96 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.268050
  validation loss:		0.450371
  validation accuracy:		86.74 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.276012
  validation loss:		0.440341
  validation accuracy:		87.39 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.268047
  validation loss:		0.458405
  validation accuracy:		86.96 %
Epoch 1041 of 2000 took 0.036s
  training loss:		0.265046
  validation loss:		0.443761
  validation accuracy:		87.07 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.264079
  validation loss:		0.441039
  validation accuracy:		87.39 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.268477
  validation loss:		0.442941
  validation accuracy:		86.96 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.267780
  validation loss:		0.430732
  validation accuracy:		87.72 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.260509
  validation loss:		0.448132
  validation accuracy:		87.17 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.272191
  validation loss:		0.437716
  validation accuracy:		87.50 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.267550
  validation loss:		0.464462
  validation accuracy:		86.74 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.266760
  validation loss:		0.446774
  validation accuracy:		87.50 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.270027
  validation loss:		0.458310
  validation accuracy:		86.96 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.263386
  validation loss:		0.427117
  validation accuracy:		87.39 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.276442
  validation loss:		0.438762
  validation accuracy:		87.50 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.267971
  validation loss:		0.471350
  validation accuracy:		86.30 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.265390
  validation loss:		0.436655
  validation accuracy:		87.17 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.271849
  validation loss:		0.425786
  validation accuracy:		87.39 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.266232
  validation loss:		0.413382
  validation accuracy:		88.26 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.263352
  validation loss:		0.451476
  validation accuracy:		87.50 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.269672
  validation loss:		0.448941
  validation accuracy:		87.17 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.263911
  validation loss:		0.448125
  validation accuracy:		86.63 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.268387
  validation loss:		0.440562
  validation accuracy:		87.61 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.271468
  validation loss:		0.449348
  validation accuracy:		86.85 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.267142
  validation loss:		0.435891
  validation accuracy:		87.61 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.266609
  validation loss:		0.417488
  validation accuracy:		87.83 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.267915
  validation loss:		0.424172
  validation accuracy:		87.50 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.269740
  validation loss:		0.443579
  validation accuracy:		87.50 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.277492
  validation loss:		0.432224
  validation accuracy:		87.72 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.270641
  validation loss:		0.421973
  validation accuracy:		87.72 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.271568
  validation loss:		0.437376
  validation accuracy:		87.39 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.270779
  validation loss:		0.454547
  validation accuracy:		87.07 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.267831
  validation loss:		0.443317
  validation accuracy:		87.50 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.272553
  validation loss:		0.434278
  validation accuracy:		87.83 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.267058
  validation loss:		0.427472
  validation accuracy:		88.26 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.268087
  validation loss:		0.446593
  validation accuracy:		87.50 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.270311
  validation loss:		0.439204
  validation accuracy:		87.72 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.265027
  validation loss:		0.429898
  validation accuracy:		87.72 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.267379
  validation loss:		0.459472
  validation accuracy:		86.52 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.268700
  validation loss:		0.436756
  validation accuracy:		87.28 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.272174
  validation loss:		0.425177
  validation accuracy:		88.04 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.268496
  validation loss:		0.424491
  validation accuracy:		87.72 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.266279
  validation loss:		0.433102
  validation accuracy:		87.72 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.259348
  validation loss:		0.426853
  validation accuracy:		87.17 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.263640
  validation loss:		0.426238
  validation accuracy:		87.72 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.269070
  validation loss:		0.418618
  validation accuracy:		88.37 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.270950
  validation loss:		0.424960
  validation accuracy:		88.26 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.262429
  validation loss:		0.451556
  validation accuracy:		87.17 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.275892
  validation loss:		0.427630
  validation accuracy:		87.72 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.271568
  validation loss:		0.471614
  validation accuracy:		85.98 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.266570
  validation loss:		0.430900
  validation accuracy:		88.04 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.264825
  validation loss:		0.436525
  validation accuracy:		87.61 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.263713
  validation loss:		0.444807
  validation accuracy:		87.17 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.268905
  validation loss:		0.446783
  validation accuracy:		86.09 %
Epoch 1091 of 2000 took 0.036s
  training loss:		0.268083
  validation loss:		0.445433
  validation accuracy:		87.50 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.266351
  validation loss:		0.429322
  validation accuracy:		87.93 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.264358
  validation loss:		0.436049
  validation accuracy:		87.39 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.273957
  validation loss:		0.436189
  validation accuracy:		87.93 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.265633
  validation loss:		0.447907
  validation accuracy:		86.30 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.269559
  validation loss:		0.458277
  validation accuracy:		86.20 %
Epoch 1097 of 2000 took 0.036s
  training loss:		0.263136
  validation loss:		0.460105
  validation accuracy:		86.41 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.265935
  validation loss:		0.439119
  validation accuracy:		87.28 %
Epoch 1099 of 2000 took 0.037s
  training loss:		0.277388
  validation loss:		0.466959
  validation accuracy:		86.85 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.264802
  validation loss:		0.439121
  validation accuracy:		87.50 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.269260
  validation loss:		0.446307
  validation accuracy:		86.85 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.262977
  validation loss:		0.422587
  validation accuracy:		88.15 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.267635
  validation loss:		0.437909
  validation accuracy:		87.17 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.271324
  validation loss:		0.461268
  validation accuracy:		86.41 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.271197
  validation loss:		0.430147
  validation accuracy:		87.17 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.272370
  validation loss:		0.438206
  validation accuracy:		87.50 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.258305
  validation loss:		0.439504
  validation accuracy:		87.39 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.267260
  validation loss:		0.433888
  validation accuracy:		87.72 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.262591
  validation loss:		0.424578
  validation accuracy:		87.17 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.264833
  validation loss:		0.432047
  validation accuracy:		87.72 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.260092
  validation loss:		0.439014
  validation accuracy:		87.83 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.259235
  validation loss:		0.423720
  validation accuracy:		87.83 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.263178
  validation loss:		0.471581
  validation accuracy:		86.85 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.278186
  validation loss:		0.446808
  validation accuracy:		87.50 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.263489
  validation loss:		0.436184
  validation accuracy:		87.07 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.271904
  validation loss:		0.439753
  validation accuracy:		87.28 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.269356
  validation loss:		0.456349
  validation accuracy:		87.39 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.264728
  validation loss:		0.442733
  validation accuracy:		86.96 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.262190
  validation loss:		0.445831
  validation accuracy:		87.39 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.269691
  validation loss:		0.418565
  validation accuracy:		87.50 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.266595
  validation loss:		0.433671
  validation accuracy:		87.28 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.268300
  validation loss:		0.425438
  validation accuracy:		87.72 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.268587
  validation loss:		0.450752
  validation accuracy:		87.39 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.269777
  validation loss:		0.450263
  validation accuracy:		86.63 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.263497
  validation loss:		0.442884
  validation accuracy:		87.07 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.272537
  validation loss:		0.434905
  validation accuracy:		87.39 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.279145
  validation loss:		0.433373
  validation accuracy:		87.83 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.261676
  validation loss:		0.433495
  validation accuracy:		87.50 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.266802
  validation loss:		0.442282
  validation accuracy:		87.17 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.262619
  validation loss:		0.445468
  validation accuracy:		86.41 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.268612
  validation loss:		0.420923
  validation accuracy:		88.37 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.261485
  validation loss:		0.453920
  validation accuracy:		87.17 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.265385
  validation loss:		0.434309
  validation accuracy:		87.93 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.267721
  validation loss:		0.438051
  validation accuracy:		86.96 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.264285
  validation loss:		0.420987
  validation accuracy:		88.26 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.268013
  validation loss:		0.435943
  validation accuracy:		87.72 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.270668
  validation loss:		0.425907
  validation accuracy:		87.72 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.264959
  validation loss:		0.434419
  validation accuracy:		87.83 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.268467
  validation loss:		0.452771
  validation accuracy:		87.17 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.268248
  validation loss:		0.449467
  validation accuracy:		86.96 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.261256
  validation loss:		0.445216
  validation accuracy:		87.39 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.268229
  validation loss:		0.428864
  validation accuracy:		87.83 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.267801
  validation loss:		0.428756
  validation accuracy:		87.93 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.257530
  validation loss:		0.429882
  validation accuracy:		87.50 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.271612
  validation loss:		0.433535
  validation accuracy:		87.83 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.269845
  validation loss:		0.419109
  validation accuracy:		88.15 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.261941
  validation loss:		0.423505
  validation accuracy:		88.15 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.265907
  validation loss:		0.464560
  validation accuracy:		86.52 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.267780
  validation loss:		0.428196
  validation accuracy:		87.61 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.269325
  validation loss:		0.420279
  validation accuracy:		87.61 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.271518
  validation loss:		0.437820
  validation accuracy:		87.28 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.267822
  validation loss:		0.435047
  validation accuracy:		87.50 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.267958
  validation loss:		0.439730
  validation accuracy:		86.74 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.265665
  validation loss:		0.436710
  validation accuracy:		87.07 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.267362
  validation loss:		0.445121
  validation accuracy:		87.28 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.269008
  validation loss:		0.428568
  validation accuracy:		87.83 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.264045
  validation loss:		0.425233
  validation accuracy:		87.50 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.272277
  validation loss:		0.447794
  validation accuracy:		87.50 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.267876
  validation loss:		0.447449
  validation accuracy:		86.30 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.266207
  validation loss:		0.450359
  validation accuracy:		86.74 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.273495
  validation loss:		0.449850
  validation accuracy:		87.39 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.263314
  validation loss:		0.490097
  validation accuracy:		85.98 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.265651
  validation loss:		0.428403
  validation accuracy:		88.26 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.264568
  validation loss:		0.444434
  validation accuracy:		87.50 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.261641
  validation loss:		0.440621
  validation accuracy:		87.07 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.265052
  validation loss:		0.444803
  validation accuracy:		85.98 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.265749
  validation loss:		0.416281
  validation accuracy:		88.15 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.270169
  validation loss:		0.438711
  validation accuracy:		87.50 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.262778
  validation loss:		0.427461
  validation accuracy:		87.50 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.259008
  validation loss:		0.417106
  validation accuracy:		88.70 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.268539
  validation loss:		0.462002
  validation accuracy:		87.17 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.269045
  validation loss:		0.449817
  validation accuracy:		87.50 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.267668
  validation loss:		0.431832
  validation accuracy:		87.72 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.260481
  validation loss:		0.432537
  validation accuracy:		87.72 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.271542
  validation loss:		0.431865
  validation accuracy:		87.61 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.268443
  validation loss:		0.441364
  validation accuracy:		87.17 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.268997
  validation loss:		0.427450
  validation accuracy:		88.26 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.265329
  validation loss:		0.432994
  validation accuracy:		87.61 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.270219
  validation loss:		0.436126
  validation accuracy:		87.61 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.269494
  validation loss:		0.420470
  validation accuracy:		87.72 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.262736
  validation loss:		0.432140
  validation accuracy:		87.07 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.266604
  validation loss:		0.429031
  validation accuracy:		87.61 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.271096
  validation loss:		0.430187
  validation accuracy:		87.83 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.265946
  validation loss:		0.419069
  validation accuracy:		88.48 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.259555
  validation loss:		0.428295
  validation accuracy:		88.04 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.263893
  validation loss:		0.435243
  validation accuracy:		87.17 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.273459
  validation loss:		0.433375
  validation accuracy:		87.72 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.263818
  validation loss:		0.411113
  validation accuracy:		88.15 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.261387
  validation loss:		0.435109
  validation accuracy:		87.83 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.264789
  validation loss:		0.423930
  validation accuracy:		87.93 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.268021
  validation loss:		0.439913
  validation accuracy:		87.39 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.268763
  validation loss:		0.439606
  validation accuracy:		87.50 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.271554
  validation loss:		0.429607
  validation accuracy:		88.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.267590
  validation loss:		0.437982
  validation accuracy:		87.61 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.269879
  validation loss:		0.437819
  validation accuracy:		86.85 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.266607
  validation loss:		0.430670
  validation accuracy:		87.50 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.266956
  validation loss:		0.419269
  validation accuracy:		87.93 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.268106
  validation loss:		0.438599
  validation accuracy:		87.28 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.264398
  validation loss:		0.437979
  validation accuracy:		87.28 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.266121
  validation loss:		0.439952
  validation accuracy:		87.72 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.268985
  validation loss:		0.423952
  validation accuracy:		87.72 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.265553
  validation loss:		0.435801
  validation accuracy:		87.50 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.266326
  validation loss:		0.437939
  validation accuracy:		87.07 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.263827
  validation loss:		0.423535
  validation accuracy:		87.39 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.271271
  validation loss:		0.431512
  validation accuracy:		87.61 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.266599
  validation loss:		0.415211
  validation accuracy:		88.59 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.271150
  validation loss:		0.446813
  validation accuracy:		86.41 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.263466
  validation loss:		0.423992
  validation accuracy:		88.15 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.268419
  validation loss:		0.437348
  validation accuracy:		87.61 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.266189
  validation loss:		0.436992
  validation accuracy:		87.50 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.269754
  validation loss:		0.432252
  validation accuracy:		87.83 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.269049
  validation loss:		0.458745
  validation accuracy:		87.28 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.270521
  validation loss:		0.432216
  validation accuracy:		87.83 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.264988
  validation loss:		0.449310
  validation accuracy:		87.17 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.266550
  validation loss:		0.430934
  validation accuracy:		87.17 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.268939
  validation loss:		0.437030
  validation accuracy:		87.28 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.258178
  validation loss:		0.437112
  validation accuracy:		87.17 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.266851
  validation loss:		0.440492
  validation accuracy:		87.17 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.263314
  validation loss:		0.439349
  validation accuracy:		87.72 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.263995
  validation loss:		0.428678
  validation accuracy:		87.83 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.266689
  validation loss:		0.445971
  validation accuracy:		87.83 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.262607
  validation loss:		0.423220
  validation accuracy:		87.61 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.267007
  validation loss:		0.432892
  validation accuracy:		87.72 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.267241
  validation loss:		0.439116
  validation accuracy:		87.50 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.258751
  validation loss:		0.476023
  validation accuracy:		86.41 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.265059
  validation loss:		0.421333
  validation accuracy:		88.15 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.265879
  validation loss:		0.454264
  validation accuracy:		87.39 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.266074
  validation loss:		0.452449
  validation accuracy:		87.39 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.264445
  validation loss:		0.440218
  validation accuracy:		87.50 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.273029
  validation loss:		0.457833
  validation accuracy:		86.96 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.262851
  validation loss:		0.424464
  validation accuracy:		88.15 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.263130
  validation loss:		0.429257
  validation accuracy:		87.83 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.268539
  validation loss:		0.449916
  validation accuracy:		86.20 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.267891
  validation loss:		0.456981
  validation accuracy:		85.87 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.266850
  validation loss:		0.425463
  validation accuracy:		87.72 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.264071
  validation loss:		0.434521
  validation accuracy:		87.17 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.267231
  validation loss:		0.463764
  validation accuracy:		86.30 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.274248
  validation loss:		0.449565
  validation accuracy:		86.41 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.261299
  validation loss:		0.437564
  validation accuracy:		87.17 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.265736
  validation loss:		0.435213
  validation accuracy:		87.50 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.270150
  validation loss:		0.425649
  validation accuracy:		88.15 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.268021
  validation loss:		0.429575
  validation accuracy:		86.96 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.261429
  validation loss:		0.422892
  validation accuracy:		87.72 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.265269
  validation loss:		0.456700
  validation accuracy:		87.17 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.262238
  validation loss:		0.426383
  validation accuracy:		87.61 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.264361
  validation loss:		0.441214
  validation accuracy:		87.39 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.265492
  validation loss:		0.435594
  validation accuracy:		87.17 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.270851
  validation loss:		0.431140
  validation accuracy:		87.61 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.271219
  validation loss:		0.477079
  validation accuracy:		86.63 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.265011
  validation loss:		0.434348
  validation accuracy:		87.50 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.263341
  validation loss:		0.459709
  validation accuracy:		87.72 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.268234
  validation loss:		0.433472
  validation accuracy:		87.61 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.264563
  validation loss:		0.425937
  validation accuracy:		87.72 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.257491
  validation loss:		0.417938
  validation accuracy:		87.72 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.267314
  validation loss:		0.428105
  validation accuracy:		87.61 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.267447
  validation loss:		0.447440
  validation accuracy:		87.28 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.270805
  validation loss:		0.420633
  validation accuracy:		88.59 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.267137
  validation loss:		0.425661
  validation accuracy:		87.72 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.263952
  validation loss:		0.427132
  validation accuracy:		87.93 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.266448
  validation loss:		0.447876
  validation accuracy:		87.17 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.268698
  validation loss:		0.428398
  validation accuracy:		87.50 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.271702
  validation loss:		0.451821
  validation accuracy:		86.74 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.268420
  validation loss:		0.456910
  validation accuracy:		87.61 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.263285
  validation loss:		0.425076
  validation accuracy:		88.04 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.268655
  validation loss:		0.439483
  validation accuracy:		87.28 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.266050
  validation loss:		0.436435
  validation accuracy:		87.50 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.268435
  validation loss:		0.446307
  validation accuracy:		87.28 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.264176
  validation loss:		0.425798
  validation accuracy:		88.26 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.261464
  validation loss:		0.427679
  validation accuracy:		88.15 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.271333
  validation loss:		0.459956
  validation accuracy:		86.85 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.257952
  validation loss:		0.417387
  validation accuracy:		88.15 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.266954
  validation loss:		0.470875
  validation accuracy:		86.30 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.265052
  validation loss:		0.424110
  validation accuracy:		87.72 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.261903
  validation loss:		0.439831
  validation accuracy:		87.17 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.265530
  validation loss:		0.450299
  validation accuracy:		87.28 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.267027
  validation loss:		0.431582
  validation accuracy:		87.93 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.266171
  validation loss:		0.435307
  validation accuracy:		87.50 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.271286
  validation loss:		0.433150
  validation accuracy:		87.39 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.264989
  validation loss:		0.459852
  validation accuracy:		87.17 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.269173
  validation loss:		0.424510
  validation accuracy:		88.91 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.269011
  validation loss:		0.425521
  validation accuracy:		87.50 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.268155
  validation loss:		0.448373
  validation accuracy:		87.17 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.262260
  validation loss:		0.462123
  validation accuracy:		86.41 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.267886
  validation loss:		0.437298
  validation accuracy:		87.17 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.268671
  validation loss:		0.447813
  validation accuracy:		86.96 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.274370
  validation loss:		0.437596
  validation accuracy:		87.39 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.265451
  validation loss:		0.458056
  validation accuracy:		86.85 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.263852
  validation loss:		0.424754
  validation accuracy:		87.72 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.262761
  validation loss:		0.425164
  validation accuracy:		87.93 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.260077
  validation loss:		0.428432
  validation accuracy:		87.50 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.269998
  validation loss:		0.431794
  validation accuracy:		87.83 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.264991
  validation loss:		0.461814
  validation accuracy:		85.98 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.269401
  validation loss:		0.422960
  validation accuracy:		87.72 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.265731
  validation loss:		0.452807
  validation accuracy:		87.39 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.265931
  validation loss:		0.422821
  validation accuracy:		88.04 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.262906
  validation loss:		0.439681
  validation accuracy:		87.39 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.262074
  validation loss:		0.441617
  validation accuracy:		87.07 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.266617
  validation loss:		0.422373
  validation accuracy:		87.93 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.269419
  validation loss:		0.428791
  validation accuracy:		87.72 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.270705
  validation loss:		0.418473
  validation accuracy:		88.15 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.267238
  validation loss:		0.429991
  validation accuracy:		87.61 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.267089
  validation loss:		0.426101
  validation accuracy:		87.83 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.265238
  validation loss:		0.444716
  validation accuracy:		87.17 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.268538
  validation loss:		0.454883
  validation accuracy:		86.63 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.266911
  validation loss:		0.443795
  validation accuracy:		87.28 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.265312
  validation loss:		0.431021
  validation accuracy:		87.83 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.269029
  validation loss:		0.431581
  validation accuracy:		87.39 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.267834
  validation loss:		0.450028
  validation accuracy:		87.07 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.259423
  validation loss:		0.435521
  validation accuracy:		87.50 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.264190
  validation loss:		0.443763
  validation accuracy:		86.96 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.267259
  validation loss:		0.432827
  validation accuracy:		87.61 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.262788
  validation loss:		0.433347
  validation accuracy:		87.83 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.269975
  validation loss:		0.441736
  validation accuracy:		87.50 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.266215
  validation loss:		0.426724
  validation accuracy:		88.15 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.260619
  validation loss:		0.448532
  validation accuracy:		86.96 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.267776
  validation loss:		0.435075
  validation accuracy:		87.50 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.266698
  validation loss:		0.418609
  validation accuracy:		88.15 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.271035
  validation loss:		0.430328
  validation accuracy:		88.15 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.265930
  validation loss:		0.429887
  validation accuracy:		87.72 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.266250
  validation loss:		0.440467
  validation accuracy:		86.30 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.272545
  validation loss:		0.453433
  validation accuracy:		86.96 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.260371
  validation loss:		0.443464
  validation accuracy:		86.85 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.268471
  validation loss:		0.441656
  validation accuracy:		87.28 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.267903
  validation loss:		0.440472
  validation accuracy:		86.85 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.261088
  validation loss:		0.437570
  validation accuracy:		87.50 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.268368
  validation loss:		0.455878
  validation accuracy:		85.54 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.266719
  validation loss:		0.429437
  validation accuracy:		87.93 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.267983
  validation loss:		0.434518
  validation accuracy:		87.83 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.262998
  validation loss:		0.413182
  validation accuracy:		88.04 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.265126
  validation loss:		0.443394
  validation accuracy:		87.61 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.265460
  validation loss:		0.438518
  validation accuracy:		87.93 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.268892
  validation loss:		0.432500
  validation accuracy:		87.50 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.265768
  validation loss:		0.425857
  validation accuracy:		87.61 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.266263
  validation loss:		0.418532
  validation accuracy:		87.93 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.260767
  validation loss:		0.441817
  validation accuracy:		86.96 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.267647
  validation loss:		0.438635
  validation accuracy:		87.72 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.265923
  validation loss:		0.428646
  validation accuracy:		87.72 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.266576
  validation loss:		0.426815
  validation accuracy:		87.61 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.264904
  validation loss:		0.425952
  validation accuracy:		88.04 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.255337
  validation loss:		0.455406
  validation accuracy:		87.50 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.266257
  validation loss:		0.431048
  validation accuracy:		87.83 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.261172
  validation loss:		0.451104
  validation accuracy:		87.39 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.263350
  validation loss:		0.437928
  validation accuracy:		87.17 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.259272
  validation loss:		0.457858
  validation accuracy:		86.85 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.263219
  validation loss:		0.419555
  validation accuracy:		87.39 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.267030
  validation loss:		0.417653
  validation accuracy:		87.93 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.265438
  validation loss:		0.443891
  validation accuracy:		86.74 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.263957
  validation loss:		0.429594
  validation accuracy:		87.72 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.265728
  validation loss:		0.443448
  validation accuracy:		86.63 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.267254
  validation loss:		0.423442
  validation accuracy:		87.93 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.265915
  validation loss:		0.441792
  validation accuracy:		87.61 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.268976
  validation loss:		0.431377
  validation accuracy:		87.28 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.261991
  validation loss:		0.452325
  validation accuracy:		86.74 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.267797
  validation loss:		0.473753
  validation accuracy:		86.41 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.266724
  validation loss:		0.451512
  validation accuracy:		87.07 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.261427
  validation loss:		0.437091
  validation accuracy:		87.61 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.260866
  validation loss:		0.463053
  validation accuracy:		86.85 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.263057
  validation loss:		0.431725
  validation accuracy:		87.61 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.263702
  validation loss:		0.445765
  validation accuracy:		87.39 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.257980
  validation loss:		0.433213
  validation accuracy:		87.50 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.264730
  validation loss:		0.425884
  validation accuracy:		88.15 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.264299
  validation loss:		0.441403
  validation accuracy:		87.39 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.266639
  validation loss:		0.418946
  validation accuracy:		88.48 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.264669
  validation loss:		0.442135
  validation accuracy:		87.72 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.266028
  validation loss:		0.443583
  validation accuracy:		87.39 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.263364
  validation loss:		0.438968
  validation accuracy:		87.17 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.259589
  validation loss:		0.451046
  validation accuracy:		87.50 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.270761
  validation loss:		0.454199
  validation accuracy:		87.07 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.265960
  validation loss:		0.416244
  validation accuracy:		87.39 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.264484
  validation loss:		0.461246
  validation accuracy:		86.63 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.265052
  validation loss:		0.431797
  validation accuracy:		88.26 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.258839
  validation loss:		0.452863
  validation accuracy:		87.07 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.261655
  validation loss:		0.445699
  validation accuracy:		86.85 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.265963
  validation loss:		0.431760
  validation accuracy:		87.17 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.271461
  validation loss:		0.432824
  validation accuracy:		88.04 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.259589
  validation loss:		0.425761
  validation accuracy:		87.83 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.262791
  validation loss:		0.445192
  validation accuracy:		87.50 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.270653
  validation loss:		0.454367
  validation accuracy:		87.28 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.266279
  validation loss:		0.453898
  validation accuracy:		87.28 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.263791
  validation loss:		0.455681
  validation accuracy:		87.28 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.266359
  validation loss:		0.457407
  validation accuracy:		86.96 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.261257
  validation loss:		0.430061
  validation accuracy:		87.50 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.271787
  validation loss:		0.432960
  validation accuracy:		87.28 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.259828
  validation loss:		0.442802
  validation accuracy:		87.83 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.267402
  validation loss:		0.440938
  validation accuracy:		87.07 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.263149
  validation loss:		0.415886
  validation accuracy:		88.04 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.269029
  validation loss:		0.436837
  validation accuracy:		87.50 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.264770
  validation loss:		0.462159
  validation accuracy:		87.07 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.269683
  validation loss:		0.444476
  validation accuracy:		86.96 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.262692
  validation loss:		0.447059
  validation accuracy:		86.96 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.265464
  validation loss:		0.439501
  validation accuracy:		87.17 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.261106
  validation loss:		0.453045
  validation accuracy:		87.17 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.262261
  validation loss:		0.433963
  validation accuracy:		87.93 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.261883
  validation loss:		0.431119
  validation accuracy:		87.28 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.269815
  validation loss:		0.430140
  validation accuracy:		87.61 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.263331
  validation loss:		0.458059
  validation accuracy:		87.39 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.266907
  validation loss:		0.435939
  validation accuracy:		87.72 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.262010
  validation loss:		0.427705
  validation accuracy:		87.39 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.260769
  validation loss:		0.479139
  validation accuracy:		85.76 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.261175
  validation loss:		0.449436
  validation accuracy:		87.83 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.259893
  validation loss:		0.413545
  validation accuracy:		88.80 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.267968
  validation loss:		0.447203
  validation accuracy:		87.17 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.263414
  validation loss:		0.442859
  validation accuracy:		87.17 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.265144
  validation loss:		0.440790
  validation accuracy:		86.85 %
Epoch 1405 of 2000 took 0.037s
  training loss:		0.266158
  validation loss:		0.437418
  validation accuracy:		87.83 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.265723
  validation loss:		0.444389
  validation accuracy:		86.96 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.263837
  validation loss:		0.429781
  validation accuracy:		87.39 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.263073
  validation loss:		0.418244
  validation accuracy:		88.91 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.266378
  validation loss:		0.452671
  validation accuracy:		86.85 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.265122
  validation loss:		0.446846
  validation accuracy:		87.72 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.265464
  validation loss:		0.427142
  validation accuracy:		88.04 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.261148
  validation loss:		0.434565
  validation accuracy:		87.93 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.263001
  validation loss:		0.425441
  validation accuracy:		88.37 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.262344
  validation loss:		0.451361
  validation accuracy:		87.39 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.263962
  validation loss:		0.422186
  validation accuracy:		88.59 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.267040
  validation loss:		0.434083
  validation accuracy:		87.72 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.264156
  validation loss:		0.427380
  validation accuracy:		88.37 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.260318
  validation loss:		0.411226
  validation accuracy:		88.70 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.266667
  validation loss:		0.451085
  validation accuracy:		87.50 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.259694
  validation loss:		0.446289
  validation accuracy:		86.96 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.265904
  validation loss:		0.437199
  validation accuracy:		87.17 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.263319
  validation loss:		0.444345
  validation accuracy:		86.74 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.269922
  validation loss:		0.444284
  validation accuracy:		87.50 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.266716
  validation loss:		0.422543
  validation accuracy:		88.04 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.263568
  validation loss:		0.428450
  validation accuracy:		87.72 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.267511
  validation loss:		0.421539
  validation accuracy:		87.93 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.264856
  validation loss:		0.439604
  validation accuracy:		87.07 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.265400
  validation loss:		0.416252
  validation accuracy:		88.80 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.262701
  validation loss:		0.450388
  validation accuracy:		87.72 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.263476
  validation loss:		0.457057
  validation accuracy:		86.74 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.268311
  validation loss:		0.430244
  validation accuracy:		88.48 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.263340
  validation loss:		0.432477
  validation accuracy:		87.83 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.263371
  validation loss:		0.428464
  validation accuracy:		87.61 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.264585
  validation loss:		0.427952
  validation accuracy:		87.93 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.265233
  validation loss:		0.445011
  validation accuracy:		87.39 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.258443
  validation loss:		0.454415
  validation accuracy:		87.07 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.270137
  validation loss:		0.419613
  validation accuracy:		87.93 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.265209
  validation loss:		0.446698
  validation accuracy:		87.39 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.265749
  validation loss:		0.433405
  validation accuracy:		87.28 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.267055
  validation loss:		0.433888
  validation accuracy:		87.28 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.262372
  validation loss:		0.445118
  validation accuracy:		87.39 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.265757
  validation loss:		0.435452
  validation accuracy:		87.61 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.268417
  validation loss:		0.418410
  validation accuracy:		87.72 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.267339
  validation loss:		0.455251
  validation accuracy:		88.04 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.261197
  validation loss:		0.441149
  validation accuracy:		87.50 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.260325
  validation loss:		0.430153
  validation accuracy:		88.26 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.268012
  validation loss:		0.446186
  validation accuracy:		87.28 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.268500
  validation loss:		0.435939
  validation accuracy:		87.28 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.260599
  validation loss:		0.457520
  validation accuracy:		87.72 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.262615
  validation loss:		0.434081
  validation accuracy:		87.83 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.268599
  validation loss:		0.416527
  validation accuracy:		88.04 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.262998
  validation loss:		0.420410
  validation accuracy:		87.93 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.265919
  validation loss:		0.441773
  validation accuracy:		87.72 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.265644
  validation loss:		0.437196
  validation accuracy:		88.15 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.263377
  validation loss:		0.434282
  validation accuracy:		88.04 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.267571
  validation loss:		0.441853
  validation accuracy:		87.50 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.260856
  validation loss:		0.428572
  validation accuracy:		87.28 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.262819
  validation loss:		0.428475
  validation accuracy:		87.93 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.263970
  validation loss:		0.426512
  validation accuracy:		88.04 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.264843
  validation loss:		0.425786
  validation accuracy:		88.15 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.265408
  validation loss:		0.444077
  validation accuracy:		87.72 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.266402
  validation loss:		0.463165
  validation accuracy:		86.85 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.262154
  validation loss:		0.428689
  validation accuracy:		87.61 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.268917
  validation loss:		0.416254
  validation accuracy:		88.15 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.263011
  validation loss:		0.428839
  validation accuracy:		88.15 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.269288
  validation loss:		0.433723
  validation accuracy:		87.28 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.263260
  validation loss:		0.434155
  validation accuracy:		88.15 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.261351
  validation loss:		0.433201
  validation accuracy:		87.28 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.269345
  validation loss:		0.423218
  validation accuracy:		87.07 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.267498
  validation loss:		0.443915
  validation accuracy:		86.96 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.264101
  validation loss:		0.440763
  validation accuracy:		87.07 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.266486
  validation loss:		0.442585
  validation accuracy:		87.72 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.259054
  validation loss:		0.440798
  validation accuracy:		87.93 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.266971
  validation loss:		0.438282
  validation accuracy:		86.63 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.263440
  validation loss:		0.451248
  validation accuracy:		87.07 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.260628
  validation loss:		0.455140
  validation accuracy:		86.63 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.264279
  validation loss:		0.421091
  validation accuracy:		88.04 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.270170
  validation loss:		0.454653
  validation accuracy:		86.52 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.263265
  validation loss:		0.442952
  validation accuracy:		86.74 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.266138
  validation loss:		0.470651
  validation accuracy:		87.17 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.266238
  validation loss:		0.429437
  validation accuracy:		87.83 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.264847
  validation loss:		0.425284
  validation accuracy:		87.72 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.267475
  validation loss:		0.442701
  validation accuracy:		86.74 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.266820
  validation loss:		0.418696
  validation accuracy:		88.15 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.261220
  validation loss:		0.443939
  validation accuracy:		87.28 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.264815
  validation loss:		0.451783
  validation accuracy:		86.74 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.264560
  validation loss:		0.406770
  validation accuracy:		88.91 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.264839
  validation loss:		0.430616
  validation accuracy:		88.37 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.264289
  validation loss:		0.425834
  validation accuracy:		87.72 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.270350
  validation loss:		0.423272
  validation accuracy:		88.04 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.262050
  validation loss:		0.417680
  validation accuracy:		87.93 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.262066
  validation loss:		0.418070
  validation accuracy:		88.15 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.260574
  validation loss:		0.426758
  validation accuracy:		87.93 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.258927
  validation loss:		0.446093
  validation accuracy:		87.93 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.263234
  validation loss:		0.416641
  validation accuracy:		88.04 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.263748
  validation loss:		0.430873
  validation accuracy:		87.50 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.259105
  validation loss:		0.452460
  validation accuracy:		86.41 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.272133
  validation loss:		0.441162
  validation accuracy:		88.04 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.271350
  validation loss:		0.434557
  validation accuracy:		87.39 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.263958
  validation loss:		0.429925
  validation accuracy:		87.83 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.269650
  validation loss:		0.426374
  validation accuracy:		88.15 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.260743
  validation loss:		0.423674
  validation accuracy:		87.72 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.258079
  validation loss:		0.440539
  validation accuracy:		87.28 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.267209
  validation loss:		0.441085
  validation accuracy:		87.17 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.263828
  validation loss:		0.449070
  validation accuracy:		86.41 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.257453
  validation loss:		0.431324
  validation accuracy:		88.04 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.267485
  validation loss:		0.441203
  validation accuracy:		87.17 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.264727
  validation loss:		0.434494
  validation accuracy:		87.07 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.261574
  validation loss:		0.437026
  validation accuracy:		87.39 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.262517
  validation loss:		0.454470
  validation accuracy:		86.09 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.262179
  validation loss:		0.441474
  validation accuracy:		87.17 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.264929
  validation loss:		0.432020
  validation accuracy:		88.04 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.263759
  validation loss:		0.449121
  validation accuracy:		86.96 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.261055
  validation loss:		0.422824
  validation accuracy:		88.80 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.266916
  validation loss:		0.444547
  validation accuracy:		87.83 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.265034
  validation loss:		0.424248
  validation accuracy:		88.15 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.257858
  validation loss:		0.441522
  validation accuracy:		86.85 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.264161
  validation loss:		0.449696
  validation accuracy:		87.72 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.262588
  validation loss:		0.427487
  validation accuracy:		88.15 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.266444
  validation loss:		0.452983
  validation accuracy:		86.52 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.262320
  validation loss:		0.425062
  validation accuracy:		87.72 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.257545
  validation loss:		0.435940
  validation accuracy:		87.50 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.264685
  validation loss:		0.445778
  validation accuracy:		86.63 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.261170
  validation loss:		0.444574
  validation accuracy:		88.04 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.267303
  validation loss:		0.438366
  validation accuracy:		87.72 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.264058
  validation loss:		0.427159
  validation accuracy:		88.04 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.265786
  validation loss:		0.448858
  validation accuracy:		87.50 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.263756
  validation loss:		0.433498
  validation accuracy:		87.28 %
Epoch 1529 of 2000 took 0.036s
  training loss:		0.263726
  validation loss:		0.440953
  validation accuracy:		87.50 %
Epoch 1530 of 2000 took 0.036s
  training loss:		0.256910
  validation loss:		0.439587
  validation accuracy:		86.63 %
Epoch 1531 of 2000 took 0.036s
  training loss:		0.261281
  validation loss:		0.430025
  validation accuracy:		87.72 %
Epoch 1532 of 2000 took 0.036s
  training loss:		0.265368
  validation loss:		0.435805
  validation accuracy:		87.61 %
Epoch 1533 of 2000 took 0.036s
  training loss:		0.264827
  validation loss:		0.449117
  validation accuracy:		87.17 %
Epoch 1534 of 2000 took 0.036s
  training loss:		0.262760
  validation loss:		0.423487
  validation accuracy:		88.26 %
Epoch 1535 of 2000 took 0.036s
  training loss:		0.259401
  validation loss:		0.428061
  validation accuracy:		87.83 %
Epoch 1536 of 2000 took 0.036s
  training loss:		0.262137
  validation loss:		0.460022
  validation accuracy:		87.50 %
Epoch 1537 of 2000 took 0.036s
  training loss:		0.265355
  validation loss:		0.456209
  validation accuracy:		87.07 %
Epoch 1538 of 2000 took 0.036s
  training loss:		0.266801
  validation loss:		0.441545
  validation accuracy:		88.04 %
Epoch 1539 of 2000 took 0.036s
  training loss:		0.261754
  validation loss:		0.418364
  validation accuracy:		87.50 %
Epoch 1540 of 2000 took 0.036s
  training loss:		0.266546
  validation loss:		0.453649
  validation accuracy:		87.61 %
Epoch 1541 of 2000 took 0.036s
  training loss:		0.259528
  validation loss:		0.450227
  validation accuracy:		88.15 %
Epoch 1542 of 2000 took 0.036s
  training loss:		0.268822
  validation loss:		0.424713
  validation accuracy:		88.37 %
Epoch 1543 of 2000 took 0.036s
  training loss:		0.265670
  validation loss:		0.451914
  validation accuracy:		86.74 %
Epoch 1544 of 2000 took 0.036s
  training loss:		0.264613
  validation loss:		0.453960
  validation accuracy:		86.74 %
Epoch 1545 of 2000 took 0.036s
  training loss:		0.265052
  validation loss:		0.428775
  validation accuracy:		87.72 %
Epoch 1546 of 2000 took 0.036s
  training loss:		0.254099
  validation loss:		0.450140
  validation accuracy:		87.50 %
Epoch 1547 of 2000 took 0.036s
  training loss:		0.268720
  validation loss:		0.417641
  validation accuracy:		89.02 %
Epoch 1548 of 2000 took 0.036s
  training loss:		0.268014
  validation loss:		0.449387
  validation accuracy:		87.17 %
Epoch 1549 of 2000 took 0.036s
  training loss:		0.265575
  validation loss:		0.455031
  validation accuracy:		87.72 %
Epoch 1550 of 2000 took 0.036s
  training loss:		0.269953
  validation loss:		0.442558
  validation accuracy:		87.72 %
Epoch 1551 of 2000 took 0.036s
  training loss:		0.261988
  validation loss:		0.449402
  validation accuracy:		87.72 %
Epoch 1552 of 2000 took 0.036s
  training loss:		0.264512
  validation loss:		0.450309
  validation accuracy:		87.28 %
Epoch 1553 of 2000 took 0.036s
  training loss:		0.259748
  validation loss:		0.430134
  validation accuracy:		87.61 %
Epoch 1554 of 2000 took 0.036s
  training loss:		0.263807
  validation loss:		0.442128
  validation accuracy:		87.17 %
Epoch 1555 of 2000 took 0.036s
  training loss:		0.264834
  validation loss:		0.427682
  validation accuracy:		88.15 %
Epoch 1556 of 2000 took 0.036s
  training loss:		0.260114
  validation loss:		0.453747
  validation accuracy:		87.07 %
Epoch 1557 of 2000 took 0.036s
  training loss:		0.262616
  validation loss:		0.437014
  validation accuracy:		87.83 %
Epoch 1558 of 2000 took 0.036s
  training loss:		0.260714
  validation loss:		0.428723
  validation accuracy:		88.04 %
Epoch 1559 of 2000 took 0.036s
  training loss:		0.264477
  validation loss:		0.441407
  validation accuracy:		87.17 %
Epoch 1560 of 2000 took 0.036s
  training loss:		0.263826
  validation loss:		0.470899
  validation accuracy:		86.30 %
Epoch 1561 of 2000 took 0.036s
  training loss:		0.265474
  validation loss:		0.440102
  validation accuracy:		87.72 %
Epoch 1562 of 2000 took 0.036s
  training loss:		0.264917
  validation loss:		0.416064
  validation accuracy:		87.83 %
Epoch 1563 of 2000 took 0.036s
  training loss:		0.260895
  validation loss:		0.443993
  validation accuracy:		86.63 %
Epoch 1564 of 2000 took 0.036s
  training loss:		0.266829
  validation loss:		0.435075
  validation accuracy:		87.61 %
Epoch 1565 of 2000 took 0.036s
  training loss:		0.265328
  validation loss:		0.445160
  validation accuracy:		87.17 %
Epoch 1566 of 2000 took 0.036s
  training loss:		0.267685
  validation loss:		0.431182
  validation accuracy:		87.72 %
Epoch 1567 of 2000 took 0.036s
  training loss:		0.258421
  validation loss:		0.419318
  validation accuracy:		89.02 %
Epoch 1568 of 2000 took 0.036s
  training loss:		0.264970
  validation loss:		0.436140
  validation accuracy:		87.93 %
Epoch 1569 of 2000 took 0.036s
  training loss:		0.268063
  validation loss:		0.437370
  validation accuracy:		87.72 %
Epoch 1570 of 2000 took 0.036s
  training loss:		0.266142
  validation loss:		0.416431
  validation accuracy:		88.15 %
Epoch 1571 of 2000 took 0.036s
  training loss:		0.267044
  validation loss:		0.456823
  validation accuracy:		86.63 %
Epoch 1572 of 2000 took 0.036s
  training loss:		0.267482
  validation loss:		0.443764
  validation accuracy:		88.04 %
Epoch 1573 of 2000 took 0.036s
  training loss:		0.262073
  validation loss:		0.439165
  validation accuracy:		87.28 %
Epoch 1574 of 2000 took 0.036s
  training loss:		0.260702
  validation loss:		0.459226
  validation accuracy:		87.39 %
Epoch 1575 of 2000 took 0.036s
  training loss:		0.271285
  validation loss:		0.422687
  validation accuracy:		87.50 %
Epoch 1576 of 2000 took 0.036s
  training loss:		0.261950
  validation loss:		0.417650
  validation accuracy:		88.48 %
Epoch 1577 of 2000 took 0.036s
  training loss:		0.273988
  validation loss:		0.447867
  validation accuracy:		86.74 %
Epoch 1578 of 2000 took 0.036s
  training loss:		0.269029
  validation loss:		0.434393
  validation accuracy:		88.15 %
Epoch 1579 of 2000 took 0.036s
  training loss:		0.263605
  validation loss:		0.423474
  validation accuracy:		87.61 %
Epoch 1580 of 2000 took 0.036s
  training loss:		0.262729
  validation loss:		0.433580
  validation accuracy:		87.39 %
Epoch 1581 of 2000 took 0.036s
  training loss:		0.258198
  validation loss:		0.417028
  validation accuracy:		88.26 %
Epoch 1582 of 2000 took 0.036s
  training loss:		0.262077
  validation loss:		0.430142
  validation accuracy:		87.07 %
Epoch 1583 of 2000 took 0.036s
  training loss:		0.260630
  validation loss:		0.466200
  validation accuracy:		85.54 %
Epoch 1584 of 2000 took 0.036s
  training loss:		0.267866
  validation loss:		0.418491
  validation accuracy:		88.26 %
Epoch 1585 of 2000 took 0.036s
  training loss:		0.264743
  validation loss:		0.421658
  validation accuracy:		87.17 %
Epoch 1586 of 2000 took 0.036s
  training loss:		0.259690
  validation loss:		0.430421
  validation accuracy:		87.72 %
Epoch 1587 of 2000 took 0.036s
  training loss:		0.262413
  validation loss:		0.434341
  validation accuracy:		87.50 %
Epoch 1588 of 2000 took 0.036s
  training loss:		0.259839
  validation loss:		0.444844
  validation accuracy:		87.28 %
Epoch 1589 of 2000 took 0.036s
  training loss:		0.259059
  validation loss:		0.443741
  validation accuracy:		87.17 %
Epoch 1590 of 2000 took 0.036s
  training loss:		0.261213
  validation loss:		0.413169
  validation accuracy:		88.70 %
Epoch 1591 of 2000 took 0.036s
  training loss:		0.265249
  validation loss:		0.427380
  validation accuracy:		87.93 %
Epoch 1592 of 2000 took 0.036s
  training loss:		0.259601
  validation loss:		0.439297
  validation accuracy:		87.28 %
Epoch 1593 of 2000 took 0.036s
  training loss:		0.260030
  validation loss:		0.437853
  validation accuracy:		88.15 %
Epoch 1594 of 2000 took 0.036s
  training loss:		0.261475
  validation loss:		0.430688
  validation accuracy:		87.72 %
Epoch 1595 of 2000 took 0.036s
  training loss:		0.266610
  validation loss:		0.430179
  validation accuracy:		88.26 %
Epoch 1596 of 2000 took 0.036s
  training loss:		0.263876
  validation loss:		0.434809
  validation accuracy:		86.96 %
Epoch 1597 of 2000 took 0.036s
  training loss:		0.264688
  validation loss:		0.436204
  validation accuracy:		87.39 %
Epoch 1598 of 2000 took 0.036s
  training loss:		0.264618
  validation loss:		0.444041
  validation accuracy:		87.83 %
Epoch 1599 of 2000 took 0.036s
  training loss:		0.267847
  validation loss:		0.413575
  validation accuracy:		88.37 %
Epoch 1600 of 2000 took 0.036s
  training loss:		0.263162
  validation loss:		0.423986
  validation accuracy:		87.83 %
Epoch 1601 of 2000 took 0.036s
  training loss:		0.258115
  validation loss:		0.455916
  validation accuracy:		87.28 %
Epoch 1602 of 2000 took 0.036s
  training loss:		0.263606
  validation loss:		0.464875
  validation accuracy:		87.17 %
Epoch 1603 of 2000 took 0.036s
  training loss:		0.263514
  validation loss:		0.431606
  validation accuracy:		87.83 %
Epoch 1604 of 2000 took 0.036s
  training loss:		0.258386
  validation loss:		0.426030
  validation accuracy:		87.50 %
Epoch 1605 of 2000 took 0.036s
  training loss:		0.256531
  validation loss:		0.434644
  validation accuracy:		87.72 %
Epoch 1606 of 2000 took 0.036s
  training loss:		0.262820
  validation loss:		0.437242
  validation accuracy:		87.93 %
Epoch 1607 of 2000 took 0.036s
  training loss:		0.267266
  validation loss:		0.433243
  validation accuracy:		88.15 %
Epoch 1608 of 2000 took 0.036s
  training loss:		0.261465
  validation loss:		0.419933
  validation accuracy:		88.26 %
Epoch 1609 of 2000 took 0.036s
  training loss:		0.261675
  validation loss:		0.421834
  validation accuracy:		88.26 %
Epoch 1610 of 2000 took 0.036s
  training loss:		0.268216
  validation loss:		0.465883
  validation accuracy:		87.17 %
Epoch 1611 of 2000 took 0.036s
  training loss:		0.262315
  validation loss:		0.437332
  validation accuracy:		87.61 %
Epoch 1612 of 2000 took 0.036s
  training loss:		0.264652
  validation loss:		0.446416
  validation accuracy:		87.39 %
Epoch 1613 of 2000 took 0.036s
  training loss:		0.261445
  validation loss:		0.420574
  validation accuracy:		88.26 %
Epoch 1614 of 2000 took 0.036s
  training loss:		0.260279
  validation loss:		0.426175
  validation accuracy:		88.04 %
Epoch 1615 of 2000 took 0.036s
  training loss:		0.265210
  validation loss:		0.435442
  validation accuracy:		87.61 %
Epoch 1616 of 2000 took 0.036s
  training loss:		0.264796
  validation loss:		0.442515
  validation accuracy:		87.72 %
Epoch 1617 of 2000 took 0.036s
  training loss:		0.260626
  validation loss:		0.432578
  validation accuracy:		88.04 %
Epoch 1618 of 2000 took 0.036s
  training loss:		0.260628
  validation loss:		0.438072
  validation accuracy:		88.04 %
Epoch 1619 of 2000 took 0.036s
  training loss:		0.263214
  validation loss:		0.442206
  validation accuracy:		87.28 %
Epoch 1620 of 2000 took 0.036s
  training loss:		0.264400
  validation loss:		0.425706
  validation accuracy:		88.37 %
Epoch 1621 of 2000 took 0.036s
  training loss:		0.261248
  validation loss:		0.414746
  validation accuracy:		87.83 %
Epoch 1622 of 2000 took 0.036s
  training loss:		0.261999
  validation loss:		0.467970
  validation accuracy:		87.07 %
Epoch 1623 of 2000 took 0.036s
  training loss:		0.260243
  validation loss:		0.414473
  validation accuracy:		88.70 %
Epoch 1624 of 2000 took 0.036s
  training loss:		0.266303
  validation loss:		0.423614
  validation accuracy:		88.04 %
Epoch 1625 of 2000 took 0.036s
  training loss:		0.262117
  validation loss:		0.426046
  validation accuracy:		88.15 %
Epoch 1626 of 2000 took 0.036s
  training loss:		0.261582
  validation loss:		0.426055
  validation accuracy:		88.15 %
Epoch 1627 of 2000 took 0.036s
  training loss:		0.262470
  validation loss:		0.438486
  validation accuracy:		86.96 %
Epoch 1628 of 2000 took 0.036s
  training loss:		0.264547
  validation loss:		0.439463
  validation accuracy:		86.96 %
Epoch 1629 of 2000 took 0.036s
  training loss:		0.261981
  validation loss:		0.463937
  validation accuracy:		87.61 %
Epoch 1630 of 2000 took 0.036s
  training loss:		0.260467
  validation loss:		0.418461
  validation accuracy:		88.15 %
Epoch 1631 of 2000 took 0.036s
  training loss:		0.261855
  validation loss:		0.430469
  validation accuracy:		88.04 %
Epoch 1632 of 2000 took 0.036s
  training loss:		0.269301
  validation loss:		0.423814
  validation accuracy:		87.93 %
Epoch 1633 of 2000 took 0.036s
  training loss:		0.265494
  validation loss:		0.444296
  validation accuracy:		88.15 %
Epoch 1634 of 2000 took 0.036s
  training loss:		0.266986
  validation loss:		0.434229
  validation accuracy:		87.61 %
Epoch 1635 of 2000 took 0.036s
  training loss:		0.257554
  validation loss:		0.433718
  validation accuracy:		87.83 %
Epoch 1636 of 2000 took 0.036s
  training loss:		0.259683
  validation loss:		0.430271
  validation accuracy:		88.04 %
Epoch 1637 of 2000 took 0.036s
  training loss:		0.262612
  validation loss:		0.423973
  validation accuracy:		88.15 %
Epoch 1638 of 2000 took 0.036s
  training loss:		0.256808
  validation loss:		0.433817
  validation accuracy:		87.50 %
Epoch 1639 of 2000 took 0.036s
  training loss:		0.256741
  validation loss:		0.429114
  validation accuracy:		87.61 %
Epoch 1640 of 2000 took 0.036s
  training loss:		0.261555
  validation loss:		0.428353
  validation accuracy:		87.83 %
Epoch 1641 of 2000 took 0.036s
  training loss:		0.265050
  validation loss:		0.425634
  validation accuracy:		88.04 %
Epoch 1642 of 2000 took 0.036s
  training loss:		0.265654
  validation loss:		0.436240
  validation accuracy:		87.39 %
Epoch 1643 of 2000 took 0.036s
  training loss:		0.263550
  validation loss:		0.431730
  validation accuracy:		87.83 %
Epoch 1644 of 2000 took 0.036s
  training loss:		0.269166
  validation loss:		0.453519
  validation accuracy:		87.28 %
Epoch 1645 of 2000 took 0.036s
  training loss:		0.263568
  validation loss:		0.458049
  validation accuracy:		87.28 %
Epoch 1646 of 2000 took 0.036s
  training loss:		0.262264
  validation loss:		0.418150
  validation accuracy:		88.04 %
Epoch 1647 of 2000 took 0.036s
  training loss:		0.261269
  validation loss:		0.449952
  validation accuracy:		87.50 %
Epoch 1648 of 2000 took 0.036s
  training loss:		0.268590
  validation loss:		0.432296
  validation accuracy:		87.50 %
Epoch 1649 of 2000 took 0.036s
  training loss:		0.263479
  validation loss:		0.445486
  validation accuracy:		87.93 %
Epoch 1650 of 2000 took 0.036s
  training loss:		0.263625
  validation loss:		0.445648
  validation accuracy:		86.85 %
Epoch 1651 of 2000 took 0.036s
  training loss:		0.262704
  validation loss:		0.431042
  validation accuracy:		87.50 %
Epoch 1652 of 2000 took 0.036s
  training loss:		0.265885
  validation loss:		0.451980
  validation accuracy:		87.28 %
Epoch 1653 of 2000 took 0.036s
  training loss:		0.261958
  validation loss:		0.448486
  validation accuracy:		86.85 %
Epoch 1654 of 2000 took 0.036s
  training loss:		0.262004
  validation loss:		0.425423
  validation accuracy:		88.15 %
Epoch 1655 of 2000 took 0.036s
  training loss:		0.264259
  validation loss:		0.439825
  validation accuracy:		87.72 %
Epoch 1656 of 2000 took 0.036s
  training loss:		0.266534
  validation loss:		0.435424
  validation accuracy:		87.50 %
Epoch 1657 of 2000 took 0.036s
  training loss:		0.262843
  validation loss:		0.430889
  validation accuracy:		88.15 %
Epoch 1658 of 2000 took 0.036s
  training loss:		0.269659
  validation loss:		0.423748
  validation accuracy:		87.93 %
Epoch 1659 of 2000 took 0.036s
  training loss:		0.258280
  validation loss:		0.426074
  validation accuracy:		87.83 %
Epoch 1660 of 2000 took 0.036s
  training loss:		0.258693
  validation loss:		0.419964
  validation accuracy:		88.59 %
Epoch 1661 of 2000 took 0.036s
  training loss:		0.270305
  validation loss:		0.424364
  validation accuracy:		88.15 %
Epoch 1662 of 2000 took 0.036s
  training loss:		0.260016
  validation loss:		0.421888
  validation accuracy:		87.93 %
Epoch 1663 of 2000 took 0.036s
  training loss:		0.263663
  validation loss:		0.432135
  validation accuracy:		87.83 %
Epoch 1664 of 2000 took 0.036s
  training loss:		0.265285
  validation loss:		0.448823
  validation accuracy:		87.17 %
Epoch 1665 of 2000 took 0.036s
  training loss:		0.266044
  validation loss:		0.456592
  validation accuracy:		86.96 %
Epoch 1666 of 2000 took 0.036s
  training loss:		0.265986
  validation loss:		0.426394
  validation accuracy:		87.72 %
Epoch 1667 of 2000 took 0.036s
  training loss:		0.264758
  validation loss:		0.428975
  validation accuracy:		87.83 %
Epoch 1668 of 2000 took 0.036s
  training loss:		0.265899
  validation loss:		0.429320
  validation accuracy:		88.04 %
Epoch 1669 of 2000 took 0.036s
  training loss:		0.257560
  validation loss:		0.433748
  validation accuracy:		88.37 %
Epoch 1670 of 2000 took 0.036s
  training loss:		0.266312
  validation loss:		0.430450
  validation accuracy:		87.28 %
Epoch 1671 of 2000 took 0.036s
  training loss:		0.264583
  validation loss:		0.417740
  validation accuracy:		87.83 %
Epoch 1672 of 2000 took 0.036s
  training loss:		0.257156
  validation loss:		0.435706
  validation accuracy:		88.04 %
Epoch 1673 of 2000 took 0.036s
  training loss:		0.261832
  validation loss:		0.433263
  validation accuracy:		87.72 %
Epoch 1674 of 2000 took 0.036s
  training loss:		0.258493
  validation loss:		0.427734
  validation accuracy:		88.26 %
Epoch 1675 of 2000 took 0.036s
  training loss:		0.262327
  validation loss:		0.422133
  validation accuracy:		87.83 %
Epoch 1676 of 2000 took 0.036s
  training loss:		0.261747
  validation loss:		0.441524
  validation accuracy:		87.17 %
Epoch 1677 of 2000 took 0.036s
  training loss:		0.269424
  validation loss:		0.445465
  validation accuracy:		87.17 %
Epoch 1678 of 2000 took 0.036s
  training loss:		0.260419
  validation loss:		0.438618
  validation accuracy:		87.17 %
Epoch 1679 of 2000 took 0.036s
  training loss:		0.263949
  validation loss:		0.445876
  validation accuracy:		87.39 %
Epoch 1680 of 2000 took 0.036s
  training loss:		0.269483
  validation loss:		0.444090
  validation accuracy:		87.39 %
Epoch 1681 of 2000 took 0.036s
  training loss:		0.263799
  validation loss:		0.443497
  validation accuracy:		88.04 %
Epoch 1682 of 2000 took 0.036s
  training loss:		0.267285
  validation loss:		0.416609
  validation accuracy:		88.26 %
Epoch 1683 of 2000 took 0.036s
  training loss:		0.266368
  validation loss:		0.429728
  validation accuracy:		88.04 %
Epoch 1684 of 2000 took 0.036s
  training loss:		0.256643
  validation loss:		0.434349
  validation accuracy:		88.04 %
Epoch 1685 of 2000 took 0.036s
  training loss:		0.256426
  validation loss:		0.419207
  validation accuracy:		88.37 %
Epoch 1686 of 2000 took 0.036s
  training loss:		0.255961
  validation loss:		0.460666
  validation accuracy:		87.72 %
Epoch 1687 of 2000 took 0.036s
  training loss:		0.265932
  validation loss:		0.421280
  validation accuracy:		88.04 %
Epoch 1688 of 2000 took 0.036s
  training loss:		0.261573
  validation loss:		0.427380
  validation accuracy:		87.83 %
Epoch 1689 of 2000 took 0.036s
  training loss:		0.265450
  validation loss:		0.443880
  validation accuracy:		87.72 %
Epoch 1690 of 2000 took 0.036s
  training loss:		0.266402
  validation loss:		0.435082
  validation accuracy:		87.72 %
Epoch 1691 of 2000 took 0.036s
  training loss:		0.264919
  validation loss:		0.439535
  validation accuracy:		87.83 %
Epoch 1692 of 2000 took 0.036s
  training loss:		0.260319
  validation loss:		0.409442
  validation accuracy:		88.37 %
Epoch 1693 of 2000 took 0.036s
  training loss:		0.259441
  validation loss:		0.442829
  validation accuracy:		88.15 %
Epoch 1694 of 2000 took 0.036s
  training loss:		0.264491
  validation loss:		0.439816
  validation accuracy:		87.72 %
Epoch 1695 of 2000 took 0.036s
  training loss:		0.263890
  validation loss:		0.428528
  validation accuracy:		87.93 %
Epoch 1696 of 2000 took 0.036s
  training loss:		0.261862
  validation loss:		0.444235
  validation accuracy:		88.04 %
Epoch 1697 of 2000 took 0.036s
  training loss:		0.259945
  validation loss:		0.436467
  validation accuracy:		87.39 %
Epoch 1698 of 2000 took 0.036s
  training loss:		0.262818
  validation loss:		0.430454
  validation accuracy:		88.15 %
Epoch 1699 of 2000 took 0.036s
  training loss:		0.267315
  validation loss:		0.439439
  validation accuracy:		87.17 %
Epoch 1700 of 2000 took 0.036s
  training loss:		0.267808
  validation loss:		0.435018
  validation accuracy:		88.26 %
Epoch 1701 of 2000 took 0.036s
  training loss:		0.262840
  validation loss:		0.439359
  validation accuracy:		88.15 %
Epoch 1702 of 2000 took 0.036s
  training loss:		0.265754
  validation loss:		0.421848
  validation accuracy:		87.93 %
Epoch 1703 of 2000 took 0.036s
  training loss:		0.257661
  validation loss:		0.421973
  validation accuracy:		88.37 %
Epoch 1704 of 2000 took 0.036s
  training loss:		0.267407
  validation loss:		0.434520
  validation accuracy:		87.83 %
Epoch 1705 of 2000 took 0.036s
  training loss:		0.260225
  validation loss:		0.409097
  validation accuracy:		88.70 %
Epoch 1706 of 2000 took 0.036s
  training loss:		0.259624
  validation loss:		0.446527
  validation accuracy:		87.07 %
Epoch 1707 of 2000 took 0.036s
  training loss:		0.257406
  validation loss:		0.437831
  validation accuracy:		87.83 %
Epoch 1708 of 2000 took 0.036s
  training loss:		0.267437
  validation loss:		0.428657
  validation accuracy:		87.93 %
Epoch 1709 of 2000 took 0.036s
  training loss:		0.264337
  validation loss:		0.436674
  validation accuracy:		87.72 %
Epoch 1710 of 2000 took 0.036s
  training loss:		0.261740
  validation loss:		0.436034
  validation accuracy:		87.83 %
Epoch 1711 of 2000 took 0.036s
  training loss:		0.259968
  validation loss:		0.438547
  validation accuracy:		87.61 %
Epoch 1712 of 2000 took 0.036s
  training loss:		0.262099
  validation loss:		0.439561
  validation accuracy:		87.50 %
Epoch 1713 of 2000 took 0.036s
  training loss:		0.260221
  validation loss:		0.422751
  validation accuracy:		88.26 %
Epoch 1714 of 2000 took 0.036s
  training loss:		0.266134
  validation loss:		0.429434
  validation accuracy:		88.15 %
Epoch 1715 of 2000 took 0.036s
  training loss:		0.256527
  validation loss:		0.439629
  validation accuracy:		88.04 %
Epoch 1716 of 2000 took 0.036s
  training loss:		0.259478
  validation loss:		0.449027
  validation accuracy:		87.17 %
Epoch 1717 of 2000 took 0.036s
  training loss:		0.263436
  validation loss:		0.453177
  validation accuracy:		87.50 %
Epoch 1718 of 2000 took 0.036s
  training loss:		0.264242
  validation loss:		0.409427
  validation accuracy:		88.48 %
Epoch 1719 of 2000 took 0.036s
  training loss:		0.264964
  validation loss:		0.433152
  validation accuracy:		87.93 %
Epoch 1720 of 2000 took 0.036s
  training loss:		0.260390
  validation loss:		0.436642
  validation accuracy:		87.83 %
Epoch 1721 of 2000 took 0.036s
  training loss:		0.259704
  validation loss:		0.430042
  validation accuracy:		88.15 %
Epoch 1722 of 2000 took 0.036s
  training loss:		0.267633
  validation loss:		0.418045
  validation accuracy:		88.59 %
Epoch 1723 of 2000 took 0.036s
  training loss:		0.266653
  validation loss:		0.425865
  validation accuracy:		88.26 %
Epoch 1724 of 2000 took 0.036s
  training loss:		0.263974
  validation loss:		0.430055
  validation accuracy:		87.61 %
Epoch 1725 of 2000 took 0.036s
  training loss:		0.258950
  validation loss:		0.435136
  validation accuracy:		88.26 %
Epoch 1726 of 2000 took 0.036s
  training loss:		0.263052
  validation loss:		0.430853
  validation accuracy:		88.26 %
Epoch 1727 of 2000 took 0.036s
  training loss:		0.258242
  validation loss:		0.437146
  validation accuracy:		87.28 %
Epoch 1728 of 2000 took 0.036s
  training loss:		0.259131
  validation loss:		0.444366
  validation accuracy:		87.61 %
Epoch 1729 of 2000 took 0.036s
  training loss:		0.259842
  validation loss:		0.445224
  validation accuracy:		87.83 %
Epoch 1730 of 2000 took 0.036s
  training loss:		0.259555
  validation loss:		0.414327
  validation accuracy:		88.70 %
Epoch 1731 of 2000 took 0.036s
  training loss:		0.257522
  validation loss:		0.413690
  validation accuracy:		88.59 %
Epoch 1732 of 2000 took 0.036s
  training loss:		0.263950
  validation loss:		0.419206
  validation accuracy:		88.26 %
Epoch 1733 of 2000 took 0.036s
  training loss:		0.266501
  validation loss:		0.437172
  validation accuracy:		87.93 %
Epoch 1734 of 2000 took 0.036s
  training loss:		0.261285
  validation loss:		0.444466
  validation accuracy:		87.28 %
Epoch 1735 of 2000 took 0.036s
  training loss:		0.260247
  validation loss:		0.442361
  validation accuracy:		87.83 %
Epoch 1736 of 2000 took 0.036s
  training loss:		0.259034
  validation loss:		0.413416
  validation accuracy:		88.37 %
Epoch 1737 of 2000 took 0.036s
  training loss:		0.258517
  validation loss:		0.425584
  validation accuracy:		87.93 %
Epoch 1738 of 2000 took 0.036s
  training loss:		0.259257
  validation loss:		0.439691
  validation accuracy:		87.61 %
Epoch 1739 of 2000 took 0.036s
  training loss:		0.258343
  validation loss:		0.464265
  validation accuracy:		86.96 %
Epoch 1740 of 2000 took 0.036s
  training loss:		0.264754
  validation loss:		0.440822
  validation accuracy:		87.83 %
Epoch 1741 of 2000 took 0.036s
  training loss:		0.263699
  validation loss:		0.434345
  validation accuracy:		87.28 %
Epoch 1742 of 2000 took 0.036s
  training loss:		0.263143
  validation loss:		0.428614
  validation accuracy:		88.04 %
Epoch 1743 of 2000 took 0.036s
  training loss:		0.263014
  validation loss:		0.445832
  validation accuracy:		87.83 %
Epoch 1744 of 2000 took 0.036s
  training loss:		0.268371
  validation loss:		0.439044
  validation accuracy:		88.48 %
Epoch 1745 of 2000 took 0.036s
  training loss:		0.262740
  validation loss:		0.428163
  validation accuracy:		87.93 %
Epoch 1746 of 2000 took 0.036s
  training loss:		0.264486
  validation loss:		0.412959
  validation accuracy:		88.70 %
Epoch 1747 of 2000 took 0.036s
  training loss:		0.260030
  validation loss:		0.436411
  validation accuracy:		87.61 %
Epoch 1748 of 2000 took 0.036s
  training loss:		0.257338
  validation loss:		0.436538
  validation accuracy:		87.50 %
Epoch 1749 of 2000 took 0.036s
  training loss:		0.263629
  validation loss:		0.430089
  validation accuracy:		87.07 %
Epoch 1750 of 2000 took 0.036s
  training loss:		0.258446
  validation loss:		0.433276
  validation accuracy:		87.07 %
Epoch 1751 of 2000 took 0.036s
  training loss:		0.261678
  validation loss:		0.429011
  validation accuracy:		87.72 %
Epoch 1752 of 2000 took 0.036s
  training loss:		0.263162
  validation loss:		0.435457
  validation accuracy:		87.61 %
Epoch 1753 of 2000 took 0.036s
  training loss:		0.259373
  validation loss:		0.423498
  validation accuracy:		87.83 %
Epoch 1754 of 2000 took 0.036s
  training loss:		0.257209
  validation loss:		0.431193
  validation accuracy:		88.26 %
Epoch 1755 of 2000 took 0.036s
  training loss:		0.265434
  validation loss:		0.430405
  validation accuracy:		87.61 %
Epoch 1756 of 2000 took 0.036s
  training loss:		0.264650
  validation loss:		0.427879
  validation accuracy:		88.15 %
Epoch 1757 of 2000 took 0.036s
  training loss:		0.260687
  validation loss:		0.427882
  validation accuracy:		88.15 %
Epoch 1758 of 2000 took 0.036s
  training loss:		0.261185
  validation loss:		0.458873
  validation accuracy:		86.74 %
Epoch 1759 of 2000 took 0.036s
  training loss:		0.263982
  validation loss:		0.448802
  validation accuracy:		86.74 %
Epoch 1760 of 2000 took 0.036s
  training loss:		0.264422
  validation loss:		0.426290
  validation accuracy:		88.37 %
Epoch 1761 of 2000 took 0.036s
  training loss:		0.263212
  validation loss:		0.427293
  validation accuracy:		88.48 %
Epoch 1762 of 2000 took 0.036s
  training loss:		0.261277
  validation loss:		0.449995
  validation accuracy:		87.93 %
Epoch 1763 of 2000 took 0.036s
  training loss:		0.265443
  validation loss:		0.442330
  validation accuracy:		87.72 %
Epoch 1764 of 2000 took 0.036s
  training loss:		0.260951
  validation loss:		0.418525
  validation accuracy:		87.61 %
Epoch 1765 of 2000 took 0.036s
  training loss:		0.268289
  validation loss:		0.462177
  validation accuracy:		86.85 %
Epoch 1766 of 2000 took 0.036s
  training loss:		0.259480
  validation loss:		0.429342
  validation accuracy:		87.61 %
Epoch 1767 of 2000 took 0.036s
  training loss:		0.261213
  validation loss:		0.415340
  validation accuracy:		88.48 %
Epoch 1768 of 2000 took 0.036s
  training loss:		0.262433
  validation loss:		0.456132
  validation accuracy:		87.07 %
Epoch 1769 of 2000 took 0.036s
  training loss:		0.264639
  validation loss:		0.435243
  validation accuracy:		87.28 %
Epoch 1770 of 2000 took 0.036s
  training loss:		0.260111
  validation loss:		0.443528
  validation accuracy:		87.17 %
Epoch 1771 of 2000 took 0.036s
  training loss:		0.263683
  validation loss:		0.430095
  validation accuracy:		87.61 %
Epoch 1772 of 2000 took 0.036s
  training loss:		0.252804
  validation loss:		0.457754
  validation accuracy:		86.96 %
Epoch 1773 of 2000 took 0.036s
  training loss:		0.262032
  validation loss:		0.439417
  validation accuracy:		88.26 %
Epoch 1774 of 2000 took 0.036s
  training loss:		0.254843
  validation loss:		0.448468
  validation accuracy:		87.83 %
Epoch 1775 of 2000 took 0.036s
  training loss:		0.256535
  validation loss:		0.438458
  validation accuracy:		88.26 %
Epoch 1776 of 2000 took 0.036s
  training loss:		0.258759
  validation loss:		0.424414
  validation accuracy:		87.93 %
Epoch 1777 of 2000 took 0.036s
  training loss:		0.263418
  validation loss:		0.424298
  validation accuracy:		88.48 %
Epoch 1778 of 2000 took 0.036s
  training loss:		0.261578
  validation loss:		0.449777
  validation accuracy:		87.28 %
Epoch 1779 of 2000 took 0.036s
  training loss:		0.263254
  validation loss:		0.440074
  validation accuracy:		88.26 %
Epoch 1780 of 2000 took 0.036s
  training loss:		0.257832
  validation loss:		0.411422
  validation accuracy:		88.48 %
Epoch 1781 of 2000 took 0.036s
  training loss:		0.263368
  validation loss:		0.443309
  validation accuracy:		87.39 %
Epoch 1782 of 2000 took 0.036s
  training loss:		0.256822
  validation loss:		0.414706
  validation accuracy:		88.15 %
Epoch 1783 of 2000 took 0.036s
  training loss:		0.258837
  validation loss:		0.420790
  validation accuracy:		88.59 %
Epoch 1784 of 2000 took 0.036s
  training loss:		0.260558
  validation loss:		0.432102
  validation accuracy:		87.50 %
Epoch 1785 of 2000 took 0.036s
  training loss:		0.258549
  validation loss:		0.416308
  validation accuracy:		88.59 %
Epoch 1786 of 2000 took 0.036s
  training loss:		0.263067
  validation loss:		0.420717
  validation accuracy:		88.26 %
Epoch 1787 of 2000 took 0.036s
  training loss:		0.257366
  validation loss:		0.427141
  validation accuracy:		88.37 %
Epoch 1788 of 2000 took 0.036s
  training loss:		0.265568
  validation loss:		0.431377
  validation accuracy:		87.17 %
Epoch 1789 of 2000 took 0.036s
  training loss:		0.260428
  validation loss:		0.452329
  validation accuracy:		87.39 %
Epoch 1790 of 2000 took 0.036s
  training loss:		0.251195
  validation loss:		0.458319
  validation accuracy:		87.39 %
Epoch 1791 of 2000 took 0.036s
  training loss:		0.261437
  validation loss:		0.441167
  validation accuracy:		87.28 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.266046
  validation loss:		0.421016
  validation accuracy:		88.70 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.263157
  validation loss:		0.427923
  validation accuracy:		88.15 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.252168
  validation loss:		0.411531
  validation accuracy:		89.02 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.260683
  validation loss:		0.431308
  validation accuracy:		88.26 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.258781
  validation loss:		0.429181
  validation accuracy:		88.04 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.254691
  validation loss:		0.429547
  validation accuracy:		88.26 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.254258
  validation loss:		0.440505
  validation accuracy:		87.93 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.263198
  validation loss:		0.439487
  validation accuracy:		87.83 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.264968
  validation loss:		0.431398
  validation accuracy:		88.04 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.256014
  validation loss:		0.453805
  validation accuracy:		87.17 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.262203
  validation loss:		0.434336
  validation accuracy:		87.17 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.257764
  validation loss:		0.425242
  validation accuracy:		88.48 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.254505
  validation loss:		0.436183
  validation accuracy:		87.83 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.255471
  validation loss:		0.422328
  validation accuracy:		88.59 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.258606
  validation loss:		0.418596
  validation accuracy:		88.59 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.261618
  validation loss:		0.454544
  validation accuracy:		87.93 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.261450
  validation loss:		0.433588
  validation accuracy:		88.04 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.261955
  validation loss:		0.445074
  validation accuracy:		87.28 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.260470
  validation loss:		0.426062
  validation accuracy:		88.48 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.264289
  validation loss:		0.446954
  validation accuracy:		87.17 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.259165
  validation loss:		0.426614
  validation accuracy:		88.59 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.265458
  validation loss:		0.420693
  validation accuracy:		88.59 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.263570
  validation loss:		0.423689
  validation accuracy:		88.26 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.259975
  validation loss:		0.441641
  validation accuracy:		88.04 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.265635
  validation loss:		0.427171
  validation accuracy:		88.15 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.256549
  validation loss:		0.436402
  validation accuracy:		87.93 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.264092
  validation loss:		0.426048
  validation accuracy:		88.26 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.258001
  validation loss:		0.445143
  validation accuracy:		86.74 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.257515
  validation loss:		0.436838
  validation accuracy:		88.37 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.262089
  validation loss:		0.422166
  validation accuracy:		87.93 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.263117
  validation loss:		0.434196
  validation accuracy:		87.83 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.262504
  validation loss:		0.431928
  validation accuracy:		87.61 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.256893
  validation loss:		0.461926
  validation accuracy:		86.52 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.259665
  validation loss:		0.423299
  validation accuracy:		88.37 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.267266
  validation loss:		0.421923
  validation accuracy:		88.04 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.258107
  validation loss:		0.413325
  validation accuracy:		88.59 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.251098
  validation loss:		0.460495
  validation accuracy:		87.39 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.262286
  validation loss:		0.435011
  validation accuracy:		87.61 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.263710
  validation loss:		0.426130
  validation accuracy:		87.93 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.264589
  validation loss:		0.427825
  validation accuracy:		88.37 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.258067
  validation loss:		0.422914
  validation accuracy:		88.37 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.259829
  validation loss:		0.426936
  validation accuracy:		87.39 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.259893
  validation loss:		0.444111
  validation accuracy:		87.07 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.263769
  validation loss:		0.453625
  validation accuracy:		87.17 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.260413
  validation loss:		0.441189
  validation accuracy:		87.93 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.256745
  validation loss:		0.429445
  validation accuracy:		88.59 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.256736
  validation loss:		0.431809
  validation accuracy:		88.37 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.258372
  validation loss:		0.446650
  validation accuracy:		87.39 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.260786
  validation loss:		0.452943
  validation accuracy:		87.28 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.261645
  validation loss:		0.450066
  validation accuracy:		87.61 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.265136
  validation loss:		0.431904
  validation accuracy:		88.37 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.259123
  validation loss:		0.424305
  validation accuracy:		88.37 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.258160
  validation loss:		0.423944
  validation accuracy:		88.37 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.257781
  validation loss:		0.431597
  validation accuracy:		87.72 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.259658
  validation loss:		0.437750
  validation accuracy:		88.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.261163
  validation loss:		0.432667
  validation accuracy:		87.72 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.262643
  validation loss:		0.418270
  validation accuracy:		88.59 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.257803
  validation loss:		0.413726
  validation accuracy:		88.48 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.265236
  validation loss:		0.423771
  validation accuracy:		87.50 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.260476
  validation loss:		0.440199
  validation accuracy:		87.07 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.258745
  validation loss:		0.425968
  validation accuracy:		88.48 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.255306
  validation loss:		0.456253
  validation accuracy:		87.39 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.260294
  validation loss:		0.436701
  validation accuracy:		87.50 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.262086
  validation loss:		0.443346
  validation accuracy:		86.85 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.261544
  validation loss:		0.452391
  validation accuracy:		87.50 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.260053
  validation loss:		0.468915
  validation accuracy:		86.20 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.259176
  validation loss:		0.458891
  validation accuracy:		88.04 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.255893
  validation loss:		0.459607
  validation accuracy:		86.41 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.264525
  validation loss:		0.443117
  validation accuracy:		87.61 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.256074
  validation loss:		0.435658
  validation accuracy:		88.04 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.262281
  validation loss:		0.445558
  validation accuracy:		86.96 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.256462
  validation loss:		0.445908
  validation accuracy:		87.72 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.257318
  validation loss:		0.456824
  validation accuracy:		88.04 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.257080
  validation loss:		0.439936
  validation accuracy:		87.72 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.256559
  validation loss:		0.420588
  validation accuracy:		88.59 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.265897
  validation loss:		0.431492
  validation accuracy:		88.37 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.261358
  validation loss:		0.441563
  validation accuracy:		87.17 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.257748
  validation loss:		0.466337
  validation accuracy:		86.96 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.262673
  validation loss:		0.455297
  validation accuracy:		86.85 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.257750
  validation loss:		0.434460
  validation accuracy:		88.26 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.254973
  validation loss:		0.441453
  validation accuracy:		87.07 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.259630
  validation loss:		0.429190
  validation accuracy:		88.37 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.252236
  validation loss:		0.430622
  validation accuracy:		88.26 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.266252
  validation loss:		0.460315
  validation accuracy:		87.93 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.264712
  validation loss:		0.415916
  validation accuracy:		88.70 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.261844
  validation loss:		0.437815
  validation accuracy:		88.04 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.261810
  validation loss:		0.448793
  validation accuracy:		87.83 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.264823
  validation loss:		0.416112
  validation accuracy:		88.70 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.255325
  validation loss:		0.443270
  validation accuracy:		87.39 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.256140
  validation loss:		0.454376
  validation accuracy:		87.39 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.255189
  validation loss:		0.441356
  validation accuracy:		87.93 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.254761
  validation loss:		0.439462
  validation accuracy:		87.93 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.258401
  validation loss:		0.439988
  validation accuracy:		87.93 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.254712
  validation loss:		0.436816
  validation accuracy:		88.59 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.259453
  validation loss:		0.424679
  validation accuracy:		88.37 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.255396
  validation loss:		0.459680
  validation accuracy:		87.83 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.258375
  validation loss:		0.430390
  validation accuracy:		88.04 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.259873
  validation loss:		0.432259
  validation accuracy:		86.63 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.254144
  validation loss:		0.432881
  validation accuracy:		87.72 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.259394
  validation loss:		0.426921
  validation accuracy:		88.26 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.254904
  validation loss:		0.417776
  validation accuracy:		88.26 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.256378
  validation loss:		0.421690
  validation accuracy:		88.70 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.258850
  validation loss:		0.451911
  validation accuracy:		87.93 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.247435
  validation loss:		0.438657
  validation accuracy:		87.83 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.256695
  validation loss:		0.432198
  validation accuracy:		87.17 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.253329
  validation loss:		0.454611
  validation accuracy:		87.07 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.253542
  validation loss:		0.425391
  validation accuracy:		87.50 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.258767
  validation loss:		0.448879
  validation accuracy:		87.93 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.251162
  validation loss:		0.438126
  validation accuracy:		86.96 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.262942
  validation loss:		0.436493
  validation accuracy:		88.26 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.257779
  validation loss:		0.440514
  validation accuracy:		87.28 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.258374
  validation loss:		0.427563
  validation accuracy:		88.04 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.256475
  validation loss:		0.418628
  validation accuracy:		88.37 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.257504
  validation loss:		0.439814
  validation accuracy:		88.37 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.261724
  validation loss:		0.420245
  validation accuracy:		88.70 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.255522
  validation loss:		0.422274
  validation accuracy:		88.37 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.249740
  validation loss:		0.457176
  validation accuracy:		87.61 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.258991
  validation loss:		0.424679
  validation accuracy:		87.17 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.260196
  validation loss:		0.437323
  validation accuracy:		87.72 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.254918
  validation loss:		0.426670
  validation accuracy:		88.70 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.258103
  validation loss:		0.453977
  validation accuracy:		87.39 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.256317
  validation loss:		0.434739
  validation accuracy:		88.15 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.263292
  validation loss:		0.416195
  validation accuracy:		88.37 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.259220
  validation loss:		0.439540
  validation accuracy:		87.17 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.256946
  validation loss:		0.435779
  validation accuracy:		88.15 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.259858
  validation loss:		0.425504
  validation accuracy:		88.15 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.254652
  validation loss:		0.416893
  validation accuracy:		87.83 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.261437
  validation loss:		0.412667
  validation accuracy:		88.04 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.256580
  validation loss:		0.444225
  validation accuracy:		87.17 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.254917
  validation loss:		0.422637
  validation accuracy:		88.48 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.259936
  validation loss:		0.431527
  validation accuracy:		88.04 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.258979
  validation loss:		0.421568
  validation accuracy:		88.48 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.261851
  validation loss:		0.427474
  validation accuracy:		88.37 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.255582
  validation loss:		0.435747
  validation accuracy:		87.93 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.253273
  validation loss:		0.451131
  validation accuracy:		87.83 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.254268
  validation loss:		0.453812
  validation accuracy:		87.39 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.259495
  validation loss:		0.443370
  validation accuracy:		87.72 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.258793
  validation loss:		0.431031
  validation accuracy:		88.48 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.258466
  validation loss:		0.431905
  validation accuracy:		87.39 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.256941
  validation loss:		0.424967
  validation accuracy:		87.39 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.257877
  validation loss:		0.422023
  validation accuracy:		88.48 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.257237
  validation loss:		0.429273
  validation accuracy:		88.48 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.257250
  validation loss:		0.428894
  validation accuracy:		88.15 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.255632
  validation loss:		0.430607
  validation accuracy:		88.15 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.255675
  validation loss:		0.432666
  validation accuracy:		86.96 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.255328
  validation loss:		0.417582
  validation accuracy:		88.26 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.251494
  validation loss:		0.438883
  validation accuracy:		87.50 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.261001
  validation loss:		0.423084
  validation accuracy:		88.59 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.254293
  validation loss:		0.431117
  validation accuracy:		88.26 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.259102
  validation loss:		0.417168
  validation accuracy:		88.04 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.256860
  validation loss:		0.428211
  validation accuracy:		88.26 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.256608
  validation loss:		0.431205
  validation accuracy:		88.15 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.260027
  validation loss:		0.449664
  validation accuracy:		87.50 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.260294
  validation loss:		0.422362
  validation accuracy:		88.48 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.251576
  validation loss:		0.426239
  validation accuracy:		88.04 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.252568
  validation loss:		0.445080
  validation accuracy:		87.72 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.252128
  validation loss:		0.427460
  validation accuracy:		88.70 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.255979
  validation loss:		0.417008
  validation accuracy:		88.70 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.253683
  validation loss:		0.427990
  validation accuracy:		88.04 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.252718
  validation loss:		0.416246
  validation accuracy:		87.93 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.254259
  validation loss:		0.422177
  validation accuracy:		88.37 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.256957
  validation loss:		0.423099
  validation accuracy:		88.04 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.249407
  validation loss:		0.424819
  validation accuracy:		88.04 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.256099
  validation loss:		0.433001
  validation accuracy:		88.04 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.249007
  validation loss:		0.413566
  validation accuracy:		89.02 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.254967
  validation loss:		0.436384
  validation accuracy:		88.37 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.254053
  validation loss:		0.461048
  validation accuracy:		87.50 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.255289
  validation loss:		0.433922
  validation accuracy:		87.83 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.251101
  validation loss:		0.418909
  validation accuracy:		88.80 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.255277
  validation loss:		0.432754
  validation accuracy:		87.83 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.260307
  validation loss:		0.424968
  validation accuracy:		87.93 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.257283
  validation loss:		0.445818
  validation accuracy:		87.72 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.259605
  validation loss:		0.434031
  validation accuracy:		88.04 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.250663
  validation loss:		0.440107
  validation accuracy:		88.37 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.253335
  validation loss:		0.456800
  validation accuracy:		87.50 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.253695
  validation loss:		0.414560
  validation accuracy:		88.15 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.251343
  validation loss:		0.421848
  validation accuracy:		87.93 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.252102
  validation loss:		0.439126
  validation accuracy:		87.07 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.258052
  validation loss:		0.421110
  validation accuracy:		88.15 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.255974
  validation loss:		0.449660
  validation accuracy:		88.26 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.257177
  validation loss:		0.431278
  validation accuracy:		88.37 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.257171
  validation loss:		0.428045
  validation accuracy:		88.15 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.255518
  validation loss:		0.426310
  validation accuracy:		88.15 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.254855
  validation loss:		0.442784
  validation accuracy:		87.07 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.250708
  validation loss:		0.411603
  validation accuracy:		88.15 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.247898
  validation loss:		0.428992
  validation accuracy:		88.48 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.253057
  validation loss:		0.434838
  validation accuracy:		87.07 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.257814
  validation loss:		0.419110
  validation accuracy:		88.15 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.252176
  validation loss:		0.433082
  validation accuracy:		87.50 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.250596
  validation loss:		0.430062
  validation accuracy:		87.28 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.257108
  validation loss:		0.431954
  validation accuracy:		88.70 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.257405
  validation loss:		0.443278
  validation accuracy:		87.50 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.262013
  validation loss:		0.434479
  validation accuracy:		87.93 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.250406
  validation loss:		0.430064
  validation accuracy:		87.17 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.254820
  validation loss:		0.427226
  validation accuracy:		88.37 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.251830
  validation loss:		0.423464
  validation accuracy:		87.83 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.258689
  validation loss:		0.449240
  validation accuracy:		87.61 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.249980
  validation loss:		0.434982
  validation accuracy:		88.70 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.255814
  validation loss:		0.416446
  validation accuracy:		87.83 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.252770
  validation loss:		0.441814
  validation accuracy:		87.28 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.254730
  validation loss:		0.425908
  validation accuracy:		87.61 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.257089
  validation loss:		0.420716
  validation accuracy:		88.15 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.250592
  validation loss:		0.435665
  validation accuracy:		87.93 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.248688
  validation loss:		0.423760
  validation accuracy:		88.04 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.256159
  validation loss:		0.425762
  validation accuracy:		87.93 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.249945
  validation loss:		0.420985
  validation accuracy:		87.93 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.250987
  validation loss:		0.417129
  validation accuracy:		88.48 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.251366
  validation loss:		0.412946
  validation accuracy:		88.91 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.257133
  validation loss:		0.449325
  validation accuracy:		87.72 %
Final results:
  test loss:			0.767956
  test accuracy:		79.78 %
