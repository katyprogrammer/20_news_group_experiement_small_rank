Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.071s
  training loss:		3.001464
  validation loss:		2.222225
  validation accuracy:		30.22 %
Epoch 2 of 2000 took 0.082s
  training loss:		1.915930
  validation loss:		1.548751
  validation accuracy:		48.70 %
Epoch 3 of 2000 took 0.067s
  training loss:		1.514985
  validation loss:		1.358297
  validation accuracy:		54.67 %
Epoch 4 of 2000 took 0.058s
  training loss:		1.394231
  validation loss:		1.263505
  validation accuracy:		58.37 %
Epoch 5 of 2000 took 0.051s
  training loss:		1.306235
  validation loss:		1.183501
  validation accuracy:		60.22 %
Epoch 6 of 2000 took 0.048s
  training loss:		1.248077
  validation loss:		1.126833
  validation accuracy:		62.50 %
Epoch 7 of 2000 took 0.050s
  training loss:		1.188093
  validation loss:		1.084208
  validation accuracy:		62.50 %
Epoch 8 of 2000 took 0.051s
  training loss:		1.132692
  validation loss:		1.014598
  validation accuracy:		65.65 %
Epoch 9 of 2000 took 0.049s
  training loss:		1.081824
  validation loss:		0.975940
  validation accuracy:		66.41 %
Epoch 10 of 2000 took 0.051s
  training loss:		1.035612
  validation loss:		0.947478
  validation accuracy:		68.80 %
Epoch 11 of 2000 took 0.049s
  training loss:		0.992068
  validation loss:		0.908009
  validation accuracy:		68.70 %
Epoch 12 of 2000 took 0.050s
  training loss:		0.956406
  validation loss:		0.877074
  validation accuracy:		70.00 %
Epoch 13 of 2000 took 0.045s
  training loss:		0.912006
  validation loss:		0.826536
  validation accuracy:		72.17 %
Epoch 14 of 2000 took 0.035s
  training loss:		0.868194
  validation loss:		0.793222
  validation accuracy:		74.02 %
Epoch 15 of 2000 took 0.035s
  training loss:		0.839296
  validation loss:		0.770949
  validation accuracy:		74.57 %
Epoch 16 of 2000 took 0.035s
  training loss:		0.806118
  validation loss:		0.745574
  validation accuracy:		75.98 %
Epoch 17 of 2000 took 0.035s
  training loss:		0.775593
  validation loss:		0.741368
  validation accuracy:		75.87 %
Epoch 18 of 2000 took 0.035s
  training loss:		0.751949
  validation loss:		0.686790
  validation accuracy:		78.91 %
Epoch 19 of 2000 took 0.036s
  training loss:		0.717143
  validation loss:		0.674339
  validation accuracy:		78.59 %
Epoch 20 of 2000 took 0.035s
  training loss:		0.693628
  validation loss:		0.644819
  validation accuracy:		78.48 %
Epoch 21 of 2000 took 0.035s
  training loss:		0.663941
  validation loss:		0.624246
  validation accuracy:		79.89 %
Epoch 22 of 2000 took 0.035s
  training loss:		0.648204
  validation loss:		0.602482
  validation accuracy:		81.09 %
Epoch 23 of 2000 took 0.035s
  training loss:		0.630493
  validation loss:		0.589188
  validation accuracy:		80.33 %
Epoch 24 of 2000 took 0.036s
  training loss:		0.610552
  validation loss:		0.569403
  validation accuracy:		81.52 %
Epoch 25 of 2000 took 0.035s
  training loss:		0.589093
  validation loss:		0.559430
  validation accuracy:		82.17 %
Epoch 26 of 2000 took 0.035s
  training loss:		0.573868
  validation loss:		0.539972
  validation accuracy:		82.61 %
Epoch 27 of 2000 took 0.035s
  training loss:		0.567575
  validation loss:		0.532828
  validation accuracy:		82.83 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.546960
  validation loss:		0.521724
  validation accuracy:		83.37 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.528731
  validation loss:		0.500242
  validation accuracy:		84.02 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.527961
  validation loss:		0.501459
  validation accuracy:		84.24 %
Epoch 31 of 2000 took 0.036s
  training loss:		0.511857
  validation loss:		0.496355
  validation accuracy:		83.70 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.496487
  validation loss:		0.497125
  validation accuracy:		84.35 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.489202
  validation loss:		0.472998
  validation accuracy:		84.35 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.483371
  validation loss:		0.473042
  validation accuracy:		85.11 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.473620
  validation loss:		0.452180
  validation accuracy:		85.87 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.463564
  validation loss:		0.463048
  validation accuracy:		84.89 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.455605
  validation loss:		0.435872
  validation accuracy:		86.30 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.453959
  validation loss:		0.438772
  validation accuracy:		86.09 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.441148
  validation loss:		0.433566
  validation accuracy:		86.30 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.431633
  validation loss:		0.420723
  validation accuracy:		86.41 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.430714
  validation loss:		0.442171
  validation accuracy:		86.30 %
Epoch 42 of 2000 took 0.036s
  training loss:		0.424551
  validation loss:		0.427898
  validation accuracy:		86.96 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.415141
  validation loss:		0.416700
  validation accuracy:		86.41 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.411520
  validation loss:		0.412901
  validation accuracy:		87.28 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.403309
  validation loss:		0.404130
  validation accuracy:		87.50 %
Epoch 46 of 2000 took 0.036s
  training loss:		0.397625
  validation loss:		0.403830
  validation accuracy:		87.61 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.389815
  validation loss:		0.397811
  validation accuracy:		87.83 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.393609
  validation loss:		0.391358
  validation accuracy:		87.93 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.382779
  validation loss:		0.384994
  validation accuracy:		88.15 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.375861
  validation loss:		0.396987
  validation accuracy:		87.61 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.375954
  validation loss:		0.394507
  validation accuracy:		88.26 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.371551
  validation loss:		0.376964
  validation accuracy:		88.15 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.365462
  validation loss:		0.390273
  validation accuracy:		88.48 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.356943
  validation loss:		0.364119
  validation accuracy:		88.80 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.365726
  validation loss:		0.370558
  validation accuracy:		89.02 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.359377
  validation loss:		0.368591
  validation accuracy:		88.91 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.351497
  validation loss:		0.378762
  validation accuracy:		88.70 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.347294
  validation loss:		0.370063
  validation accuracy:		88.59 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.342549
  validation loss:		0.369075
  validation accuracy:		88.80 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.338542
  validation loss:		0.355998
  validation accuracy:		89.35 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.338539
  validation loss:		0.360296
  validation accuracy:		89.13 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.332359
  validation loss:		0.366597
  validation accuracy:		88.70 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.336279
  validation loss:		0.347938
  validation accuracy:		89.46 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.324473
  validation loss:		0.352988
  validation accuracy:		89.67 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.326728
  validation loss:		0.349341
  validation accuracy:		89.02 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.329005
  validation loss:		0.340116
  validation accuracy:		89.89 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.320033
  validation loss:		0.344863
  validation accuracy:		89.89 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.310885
  validation loss:		0.366156
  validation accuracy:		88.80 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.316557
  validation loss:		0.339053
  validation accuracy:		89.78 %
Epoch 70 of 2000 took 0.036s
  training loss:		0.308489
  validation loss:		0.349916
  validation accuracy:		89.46 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.312917
  validation loss:		0.342276
  validation accuracy:		89.46 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.305351
  validation loss:		0.342146
  validation accuracy:		89.46 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.306968
  validation loss:		0.339857
  validation accuracy:		89.57 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.297635
  validation loss:		0.331880
  validation accuracy:		90.11 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.296849
  validation loss:		0.343546
  validation accuracy:		89.67 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.300063
  validation loss:		0.331217
  validation accuracy:		90.11 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.300512
  validation loss:		0.329569
  validation accuracy:		89.78 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.294267
  validation loss:		0.323050
  validation accuracy:		90.54 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.292352
  validation loss:		0.331897
  validation accuracy:		90.22 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.286218
  validation loss:		0.318347
  validation accuracy:		90.54 %
Epoch 81 of 2000 took 0.036s
  training loss:		0.287246
  validation loss:		0.320484
  validation accuracy:		90.54 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.284328
  validation loss:		0.317763
  validation accuracy:		90.22 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.282083
  validation loss:		0.317974
  validation accuracy:		90.43 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.278769
  validation loss:		0.322465
  validation accuracy:		90.33 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.277527
  validation loss:		0.322634
  validation accuracy:		90.11 %
Epoch 86 of 2000 took 0.036s
  training loss:		0.278415
  validation loss:		0.303584
  validation accuracy:		90.87 %
Epoch 87 of 2000 took 0.039s
  training loss:		0.273100
  validation loss:		0.318764
  validation accuracy:		90.22 %
Epoch 88 of 2000 took 0.036s
  training loss:		0.271868
  validation loss:		0.309581
  validation accuracy:		90.98 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.273352
  validation loss:		0.312223
  validation accuracy:		91.20 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.268352
  validation loss:		0.312349
  validation accuracy:		90.76 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.268014
  validation loss:		0.319575
  validation accuracy:		90.43 %
Epoch 92 of 2000 took 0.036s
  training loss:		0.262476
  validation loss:		0.321565
  validation accuracy:		90.43 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.268248
  validation loss:		0.312691
  validation accuracy:		90.98 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.263282
  validation loss:		0.308942
  validation accuracy:		91.20 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.261691
  validation loss:		0.308051
  validation accuracy:		90.54 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.262700
  validation loss:		0.310856
  validation accuracy:		91.20 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.256344
  validation loss:		0.303529
  validation accuracy:		91.52 %
Epoch 98 of 2000 took 0.036s
  training loss:		0.259822
  validation loss:		0.308210
  validation accuracy:		90.43 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.259109
  validation loss:		0.307708
  validation accuracy:		91.20 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.256982
  validation loss:		0.307521
  validation accuracy:		90.76 %
Epoch 101 of 2000 took 0.036s
  training loss:		0.249396
  validation loss:		0.303577
  validation accuracy:		91.09 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.252586
  validation loss:		0.315799
  validation accuracy:		90.33 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.248301
  validation loss:		0.301205
  validation accuracy:		90.98 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.243721
  validation loss:		0.293343
  validation accuracy:		91.30 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.248572
  validation loss:		0.303338
  validation accuracy:		91.09 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.244766
  validation loss:		0.295509
  validation accuracy:		91.09 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.245594
  validation loss:		0.321300
  validation accuracy:		90.00 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.241375
  validation loss:		0.302455
  validation accuracy:		91.09 %
Epoch 109 of 2000 took 0.036s
  training loss:		0.239338
  validation loss:		0.308381
  validation accuracy:		90.98 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.234973
  validation loss:		0.292980
  validation accuracy:		91.41 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.238826
  validation loss:		0.295537
  validation accuracy:		91.30 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.234343
  validation loss:		0.306066
  validation accuracy:		90.98 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.232740
  validation loss:		0.298735
  validation accuracy:		91.30 %
Epoch 114 of 2000 took 0.036s
  training loss:		0.232278
  validation loss:		0.291280
  validation accuracy:		91.30 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.231902
  validation loss:		0.303383
  validation accuracy:		90.43 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.232756
  validation loss:		0.310217
  validation accuracy:		90.65 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.229220
  validation loss:		0.296099
  validation accuracy:		91.20 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.224651
  validation loss:		0.297425
  validation accuracy:		91.09 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.225381
  validation loss:		0.295825
  validation accuracy:		91.20 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.227378
  validation loss:		0.295371
  validation accuracy:		91.09 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.224014
  validation loss:		0.290082
  validation accuracy:		90.76 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.220826
  validation loss:		0.300649
  validation accuracy:		90.87 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.219358
  validation loss:		0.307451
  validation accuracy:		90.54 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.222737
  validation loss:		0.292799
  validation accuracy:		91.41 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.215345
  validation loss:		0.290139
  validation accuracy:		91.20 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.219609
  validation loss:		0.287508
  validation accuracy:		91.30 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.221104
  validation loss:		0.286838
  validation accuracy:		91.09 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.215231
  validation loss:		0.291054
  validation accuracy:		90.98 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.212710
  validation loss:		0.282585
  validation accuracy:		91.52 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.216697
  validation loss:		0.291156
  validation accuracy:		90.76 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.213812
  validation loss:		0.283212
  validation accuracy:		91.20 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.210540
  validation loss:		0.285433
  validation accuracy:		91.09 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.210788
  validation loss:		0.291721
  validation accuracy:		90.98 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.216452
  validation loss:		0.287025
  validation accuracy:		91.30 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.206439
  validation loss:		0.289416
  validation accuracy:		90.54 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.210365
  validation loss:		0.293792
  validation accuracy:		91.09 %
Epoch 137 of 2000 took 0.036s
  training loss:		0.207116
  validation loss:		0.288517
  validation accuracy:		90.87 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.213186
  validation loss:		0.284858
  validation accuracy:		91.30 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.205870
  validation loss:		0.289303
  validation accuracy:		90.87 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.201392
  validation loss:		0.277569
  validation accuracy:		91.41 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.210198
  validation loss:		0.297319
  validation accuracy:		91.09 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.200080
  validation loss:		0.276547
  validation accuracy:		91.52 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.201925
  validation loss:		0.282700
  validation accuracy:		90.98 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.203931
  validation loss:		0.300016
  validation accuracy:		90.22 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.202005
  validation loss:		0.289154
  validation accuracy:		90.76 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.197233
  validation loss:		0.286330
  validation accuracy:		91.30 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.195974
  validation loss:		0.287962
  validation accuracy:		90.98 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.200938
  validation loss:		0.290504
  validation accuracy:		90.76 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.197377
  validation loss:		0.288113
  validation accuracy:		91.09 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.196611
  validation loss:		0.286753
  validation accuracy:		91.20 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.194979
  validation loss:		0.291852
  validation accuracy:		90.65 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.196480
  validation loss:		0.286220
  validation accuracy:		90.98 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.187773
  validation loss:		0.286854
  validation accuracy:		90.87 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.191420
  validation loss:		0.279262
  validation accuracy:		90.65 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.189426
  validation loss:		0.279495
  validation accuracy:		90.87 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.187066
  validation loss:		0.285132
  validation accuracy:		90.76 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.190121
  validation loss:		0.277634
  validation accuracy:		91.41 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.185715
  validation loss:		0.279370
  validation accuracy:		90.87 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.189389
  validation loss:		0.280629
  validation accuracy:		91.20 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.183033
  validation loss:		0.280648
  validation accuracy:		90.98 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.184593
  validation loss:		0.282321
  validation accuracy:		90.87 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.187087
  validation loss:		0.284222
  validation accuracy:		91.09 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.181806
  validation loss:		0.289644
  validation accuracy:		90.76 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.185557
  validation loss:		0.288676
  validation accuracy:		90.54 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.183756
  validation loss:		0.277599
  validation accuracy:		91.41 %
Epoch 166 of 2000 took 0.036s
  training loss:		0.185130
  validation loss:		0.284734
  validation accuracy:		90.87 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.183054
  validation loss:		0.282283
  validation accuracy:		90.76 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.180177
  validation loss:		0.279004
  validation accuracy:		91.52 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.180331
  validation loss:		0.283298
  validation accuracy:		90.76 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.182924
  validation loss:		0.281197
  validation accuracy:		90.98 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.179919
  validation loss:		0.282386
  validation accuracy:		90.87 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.183188
  validation loss:		0.275137
  validation accuracy:		91.20 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.178209
  validation loss:		0.274906
  validation accuracy:		90.54 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.176695
  validation loss:		0.274401
  validation accuracy:		91.41 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.178850
  validation loss:		0.281096
  validation accuracy:		90.76 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.176793
  validation loss:		0.273201
  validation accuracy:		91.20 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.179242
  validation loss:		0.277905
  validation accuracy:		90.98 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.175458
  validation loss:		0.270198
  validation accuracy:		91.96 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.171173
  validation loss:		0.277528
  validation accuracy:		90.76 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.171402
  validation loss:		0.292707
  validation accuracy:		90.98 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.173698
  validation loss:		0.284040
  validation accuracy:		90.98 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.172936
  validation loss:		0.275899
  validation accuracy:		90.98 %
Epoch 183 of 2000 took 0.036s
  training loss:		0.172679
  validation loss:		0.262502
  validation accuracy:		91.52 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.165726
  validation loss:		0.281390
  validation accuracy:		90.87 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.169044
  validation loss:		0.272555
  validation accuracy:		91.09 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.172144
  validation loss:		0.272754
  validation accuracy:		90.87 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.164331
  validation loss:		0.273759
  validation accuracy:		91.52 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.163245
  validation loss:		0.270176
  validation accuracy:		91.09 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.163087
  validation loss:		0.268651
  validation accuracy:		91.41 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.166149
  validation loss:		0.279556
  validation accuracy:		91.09 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.169524
  validation loss:		0.292660
  validation accuracy:		90.54 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.166568
  validation loss:		0.276718
  validation accuracy:		90.98 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.163887
  validation loss:		0.291708
  validation accuracy:		90.87 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.166170
  validation loss:		0.285303
  validation accuracy:		90.76 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.162312
  validation loss:		0.263936
  validation accuracy:		91.30 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.162134
  validation loss:		0.280440
  validation accuracy:		90.76 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.160331
  validation loss:		0.270504
  validation accuracy:		91.52 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.161016
  validation loss:		0.269873
  validation accuracy:		91.41 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.160953
  validation loss:		0.270580
  validation accuracy:		91.63 %
Epoch 200 of 2000 took 0.036s
  training loss:		0.160958
  validation loss:		0.268562
  validation accuracy:		91.30 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.165434
  validation loss:		0.278872
  validation accuracy:		90.87 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.156378
  validation loss:		0.266864
  validation accuracy:		91.63 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.152814
  validation loss:		0.274764
  validation accuracy:		91.30 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.156844
  validation loss:		0.270900
  validation accuracy:		91.41 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.150068
  validation loss:		0.277577
  validation accuracy:		91.09 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.155588
  validation loss:		0.268278
  validation accuracy:		91.41 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.158033
  validation loss:		0.283680
  validation accuracy:		90.76 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.157952
  validation loss:		0.276780
  validation accuracy:		91.30 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.157645
  validation loss:		0.280519
  validation accuracy:		90.76 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.154365
  validation loss:		0.278644
  validation accuracy:		91.20 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.152165
  validation loss:		0.278525
  validation accuracy:		90.98 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.151840
  validation loss:		0.264038
  validation accuracy:		91.85 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.151680
  validation loss:		0.277120
  validation accuracy:		91.09 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.150355
  validation loss:		0.276121
  validation accuracy:		91.30 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.153056
  validation loss:		0.274999
  validation accuracy:		91.30 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.147199
  validation loss:		0.284975
  validation accuracy:		90.65 %
Epoch 217 of 2000 took 0.036s
  training loss:		0.149427
  validation loss:		0.283453
  validation accuracy:		90.87 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.150004
  validation loss:		0.273064
  validation accuracy:		91.30 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.149173
  validation loss:		0.272313
  validation accuracy:		91.41 %
Epoch 220 of 2000 took 0.036s
  training loss:		0.148256
  validation loss:		0.264790
  validation accuracy:		91.41 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.148351
  validation loss:		0.274977
  validation accuracy:		91.09 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.147022
  validation loss:		0.271832
  validation accuracy:		91.41 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.143983
  validation loss:		0.276569
  validation accuracy:		91.20 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.146788
  validation loss:		0.282279
  validation accuracy:		91.52 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.142859
  validation loss:		0.285140
  validation accuracy:		91.09 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.146022
  validation loss:		0.272099
  validation accuracy:		91.63 %
Epoch 227 of 2000 took 0.036s
  training loss:		0.143394
  validation loss:		0.276768
  validation accuracy:		91.52 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.144643
  validation loss:		0.265396
  validation accuracy:		91.63 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.147048
  validation loss:		0.283489
  validation accuracy:		90.76 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.143451
  validation loss:		0.263855
  validation accuracy:		91.74 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.138109
  validation loss:		0.267186
  validation accuracy:		91.74 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.140422
  validation loss:		0.262173
  validation accuracy:		92.07 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.147396
  validation loss:		0.272428
  validation accuracy:		91.63 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.144257
  validation loss:		0.285146
  validation accuracy:		91.20 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.143650
  validation loss:		0.273248
  validation accuracy:		91.30 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.139087
  validation loss:		0.268018
  validation accuracy:		92.07 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.138962
  validation loss:		0.268046
  validation accuracy:		91.41 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.141576
  validation loss:		0.278194
  validation accuracy:		91.30 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.137577
  validation loss:		0.271909
  validation accuracy:		91.63 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.139341
  validation loss:		0.287634
  validation accuracy:		91.41 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.140049
  validation loss:		0.282759
  validation accuracy:		91.20 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.140506
  validation loss:		0.273608
  validation accuracy:		91.41 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.136062
  validation loss:		0.272690
  validation accuracy:		91.41 %
Epoch 244 of 2000 took 0.041s
  training loss:		0.135899
  validation loss:		0.281339
  validation accuracy:		91.63 %
Epoch 245 of 2000 took 0.036s
  training loss:		0.137591
  validation loss:		0.283353
  validation accuracy:		91.30 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.135212
  validation loss:		0.270197
  validation accuracy:		91.52 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.134053
  validation loss:		0.259003
  validation accuracy:		92.07 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.133261
  validation loss:		0.277054
  validation accuracy:		91.85 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.137870
  validation loss:		0.284525
  validation accuracy:		91.20 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.136026
  validation loss:		0.273416
  validation accuracy:		91.74 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.136707
  validation loss:		0.285393
  validation accuracy:		91.52 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.132247
  validation loss:		0.281045
  validation accuracy:		91.30 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.133612
  validation loss:		0.279429
  validation accuracy:		91.52 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.133013
  validation loss:		0.276356
  validation accuracy:		91.52 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.130938
  validation loss:		0.278411
  validation accuracy:		91.30 %
Epoch 256 of 2000 took 0.036s
  training loss:		0.133705
  validation loss:		0.276743
  validation accuracy:		91.85 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.131433
  validation loss:		0.279861
  validation accuracy:		91.63 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.132327
  validation loss:		0.277033
  validation accuracy:		91.41 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.131365
  validation loss:		0.279427
  validation accuracy:		91.52 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.127928
  validation loss:		0.269624
  validation accuracy:		91.63 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.129781
  validation loss:		0.279030
  validation accuracy:		91.41 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.130100
  validation loss:		0.277699
  validation accuracy:		92.17 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.129042
  validation loss:		0.266264
  validation accuracy:		92.07 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.127848
  validation loss:		0.273986
  validation accuracy:		91.74 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.127453
  validation loss:		0.275371
  validation accuracy:		91.52 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.125442
  validation loss:		0.280439
  validation accuracy:		91.74 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.128375
  validation loss:		0.279974
  validation accuracy:		91.63 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.127404
  validation loss:		0.283785
  validation accuracy:		92.07 %
Epoch 269 of 2000 took 0.037s
  training loss:		0.124743
  validation loss:		0.277625
  validation accuracy:		91.96 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.127651
  validation loss:		0.271679
  validation accuracy:		92.07 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.127604
  validation loss:		0.277589
  validation accuracy:		91.96 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.125076
  validation loss:		0.279690
  validation accuracy:		91.85 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.127856
  validation loss:		0.281746
  validation accuracy:		91.74 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.123903
  validation loss:		0.274990
  validation accuracy:		91.85 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.125239
  validation loss:		0.273576
  validation accuracy:		91.85 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.121685
  validation loss:		0.281801
  validation accuracy:		91.52 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.123273
  validation loss:		0.278183
  validation accuracy:		91.74 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.123539
  validation loss:		0.278374
  validation accuracy:		91.63 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.123703
  validation loss:		0.271845
  validation accuracy:		92.17 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.121465
  validation loss:		0.302415
  validation accuracy:		90.98 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.121414
  validation loss:		0.283548
  validation accuracy:		91.63 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.120385
  validation loss:		0.279898
  validation accuracy:		91.63 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.121939
  validation loss:		0.284786
  validation accuracy:		91.85 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.121415
  validation loss:		0.276509
  validation accuracy:		91.85 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.119880
  validation loss:		0.277998
  validation accuracy:		91.85 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.119191
  validation loss:		0.280577
  validation accuracy:		91.74 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.122189
  validation loss:		0.289265
  validation accuracy:		91.52 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.121555
  validation loss:		0.280000
  validation accuracy:		91.74 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.118337
  validation loss:		0.274136
  validation accuracy:		91.96 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.117818
  validation loss:		0.300425
  validation accuracy:		91.41 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.119646
  validation loss:		0.271971
  validation accuracy:		92.28 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.117986
  validation loss:		0.292376
  validation accuracy:		91.41 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.116875
  validation loss:		0.274367
  validation accuracy:		91.85 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.117954
  validation loss:		0.276344
  validation accuracy:		92.07 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.117660
  validation loss:		0.286310
  validation accuracy:		91.41 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.114344
  validation loss:		0.283380
  validation accuracy:		91.63 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.114969
  validation loss:		0.285502
  validation accuracy:		91.96 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.115431
  validation loss:		0.277052
  validation accuracy:		91.85 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.115116
  validation loss:		0.275811
  validation accuracy:		91.74 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.115115
  validation loss:		0.277449
  validation accuracy:		91.96 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.117026
  validation loss:		0.287557
  validation accuracy:		92.07 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.116269
  validation loss:		0.283792
  validation accuracy:		91.96 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.110993
  validation loss:		0.282164
  validation accuracy:		91.96 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.114933
  validation loss:		0.286411
  validation accuracy:		91.63 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.110283
  validation loss:		0.289137
  validation accuracy:		91.74 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.114757
  validation loss:		0.282985
  validation accuracy:		91.63 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.110063
  validation loss:		0.290343
  validation accuracy:		91.63 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.110733
  validation loss:		0.279439
  validation accuracy:		91.85 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.114000
  validation loss:		0.286086
  validation accuracy:		91.52 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.112592
  validation loss:		0.280440
  validation accuracy:		91.85 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.109733
  validation loss:		0.280186
  validation accuracy:		91.85 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.110951
  validation loss:		0.291630
  validation accuracy:		91.52 %
Epoch 313 of 2000 took 0.036s
  training loss:		0.109350
  validation loss:		0.274275
  validation accuracy:		92.39 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.112241
  validation loss:		0.291548
  validation accuracy:		91.52 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.109771
  validation loss:		0.290226
  validation accuracy:		91.74 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.106350
  validation loss:		0.277213
  validation accuracy:		91.96 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.109225
  validation loss:		0.278458
  validation accuracy:		91.85 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.109176
  validation loss:		0.276732
  validation accuracy:		92.07 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.109273
  validation loss:		0.286901
  validation accuracy:		91.85 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.109983
  validation loss:		0.293258
  validation accuracy:		91.74 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.106752
  validation loss:		0.280311
  validation accuracy:		91.74 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.104148
  validation loss:		0.283478
  validation accuracy:		91.85 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.107332
  validation loss:		0.278374
  validation accuracy:		91.63 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.107441
  validation loss:		0.290890
  validation accuracy:		91.96 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.109449
  validation loss:		0.282702
  validation accuracy:		91.96 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.104857
  validation loss:		0.280613
  validation accuracy:		92.07 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.104192
  validation loss:		0.282764
  validation accuracy:		92.07 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.104219
  validation loss:		0.288618
  validation accuracy:		91.85 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.106163
  validation loss:		0.280141
  validation accuracy:		92.07 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.106507
  validation loss:		0.287224
  validation accuracy:		92.07 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.102760
  validation loss:		0.294123
  validation accuracy:		92.07 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.103160
  validation loss:		0.285845
  validation accuracy:		91.74 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.102567
  validation loss:		0.287669
  validation accuracy:		91.52 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.104895
  validation loss:		0.288418
  validation accuracy:		91.41 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.106555
  validation loss:		0.284539
  validation accuracy:		91.96 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.100763
  validation loss:		0.283107
  validation accuracy:		91.96 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.100662
  validation loss:		0.289685
  validation accuracy:		91.74 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.101717
  validation loss:		0.302087
  validation accuracy:		91.63 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.101898
  validation loss:		0.284508
  validation accuracy:		91.52 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.104124
  validation loss:		0.284232
  validation accuracy:		92.17 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.100482
  validation loss:		0.306169
  validation accuracy:		91.52 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.099226
  validation loss:		0.275852
  validation accuracy:		92.17 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.099800
  validation loss:		0.301355
  validation accuracy:		91.74 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.100968
  validation loss:		0.286527
  validation accuracy:		91.96 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.100123
  validation loss:		0.284467
  validation accuracy:		91.63 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.100194
  validation loss:		0.280212
  validation accuracy:		92.07 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.101161
  validation loss:		0.292524
  validation accuracy:		91.96 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.100412
  validation loss:		0.283313
  validation accuracy:		92.17 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.098177
  validation loss:		0.293861
  validation accuracy:		91.74 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.098984
  validation loss:		0.294130
  validation accuracy:		91.96 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.100147
  validation loss:		0.284506
  validation accuracy:		92.28 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.095768
  validation loss:		0.294527
  validation accuracy:		91.63 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.097330
  validation loss:		0.303668
  validation accuracy:		91.52 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.098203
  validation loss:		0.282126
  validation accuracy:		92.07 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.094883
  validation loss:		0.297862
  validation accuracy:		91.74 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.098008
  validation loss:		0.298790
  validation accuracy:		91.52 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.094122
  validation loss:		0.306098
  validation accuracy:		91.41 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.097534
  validation loss:		0.285972
  validation accuracy:		92.07 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.096926
  validation loss:		0.286074
  validation accuracy:		91.96 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.096246
  validation loss:		0.290260
  validation accuracy:		92.07 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.095870
  validation loss:		0.294107
  validation accuracy:		91.96 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.092465
  validation loss:		0.291319
  validation accuracy:		91.63 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.091509
  validation loss:		0.293976
  validation accuracy:		91.85 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.095345
  validation loss:		0.292515
  validation accuracy:		91.74 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.095201
  validation loss:		0.290644
  validation accuracy:		91.96 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.095678
  validation loss:		0.299483
  validation accuracy:		91.41 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.093016
  validation loss:		0.290420
  validation accuracy:		91.85 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.095141
  validation loss:		0.283072
  validation accuracy:		92.07 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.094308
  validation loss:		0.296344
  validation accuracy:		91.74 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.095796
  validation loss:		0.293400
  validation accuracy:		92.07 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.092498
  validation loss:		0.294254
  validation accuracy:		91.74 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.090830
  validation loss:		0.306708
  validation accuracy:		91.52 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.091091
  validation loss:		0.286910
  validation accuracy:		92.28 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.092064
  validation loss:		0.295439
  validation accuracy:		91.74 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.092707
  validation loss:		0.308724
  validation accuracy:		91.74 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.092547
  validation loss:		0.295788
  validation accuracy:		91.96 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.092463
  validation loss:		0.303906
  validation accuracy:		91.41 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.090403
  validation loss:		0.294704
  validation accuracy:		91.63 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.092661
  validation loss:		0.303709
  validation accuracy:		91.52 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.092154
  validation loss:		0.316828
  validation accuracy:		91.41 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.092433
  validation loss:		0.289278
  validation accuracy:		92.17 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.085039
  validation loss:		0.291547
  validation accuracy:		92.17 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.089258
  validation loss:		0.300524
  validation accuracy:		92.07 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.093008
  validation loss:		0.297434
  validation accuracy:		91.74 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.089090
  validation loss:		0.303034
  validation accuracy:		92.17 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.091100
  validation loss:		0.309092
  validation accuracy:		91.63 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.090545
  validation loss:		0.300782
  validation accuracy:		91.74 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.088670
  validation loss:		0.293995
  validation accuracy:		92.17 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.087832
  validation loss:		0.306661
  validation accuracy:		91.63 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.090441
  validation loss:		0.309184
  validation accuracy:		91.52 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.088604
  validation loss:		0.303364
  validation accuracy:		91.85 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.087583
  validation loss:		0.302507
  validation accuracy:		91.41 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.089531
  validation loss:		0.297209
  validation accuracy:		91.85 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.087562
  validation loss:		0.292661
  validation accuracy:		92.07 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.088058
  validation loss:		0.306898
  validation accuracy:		91.85 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.085489
  validation loss:		0.298343
  validation accuracy:		91.63 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.086606
  validation loss:		0.302466
  validation accuracy:		91.85 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.086308
  validation loss:		0.282639
  validation accuracy:		92.28 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.088282
  validation loss:		0.306105
  validation accuracy:		91.74 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.086634
  validation loss:		0.320412
  validation accuracy:		91.20 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.087712
  validation loss:		0.301777
  validation accuracy:		92.07 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.086988
  validation loss:		0.297954
  validation accuracy:		91.85 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.086988
  validation loss:		0.298633
  validation accuracy:		91.85 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.085604
  validation loss:		0.309046
  validation accuracy:		91.41 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.085097
  validation loss:		0.306208
  validation accuracy:		91.63 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.085043
  validation loss:		0.298803
  validation accuracy:		92.17 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.085819
  validation loss:		0.311175
  validation accuracy:		91.74 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.082601
  validation loss:		0.296914
  validation accuracy:		92.39 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.086708
  validation loss:		0.299470
  validation accuracy:		92.07 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.084761
  validation loss:		0.304355
  validation accuracy:		91.74 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.080605
  validation loss:		0.294676
  validation accuracy:		92.28 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.083442
  validation loss:		0.295835
  validation accuracy:		92.07 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.080877
  validation loss:		0.301625
  validation accuracy:		92.07 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.082400
  validation loss:		0.312766
  validation accuracy:		91.63 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.083443
  validation loss:		0.303009
  validation accuracy:		91.96 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.082306
  validation loss:		0.313754
  validation accuracy:		91.52 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.083885
  validation loss:		0.306585
  validation accuracy:		91.63 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.081590
  validation loss:		0.304061
  validation accuracy:		91.96 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.081631
  validation loss:		0.297411
  validation accuracy:		92.17 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.083445
  validation loss:		0.308428
  validation accuracy:		91.52 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.080039
  validation loss:		0.299961
  validation accuracy:		92.07 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.082332
  validation loss:		0.309335
  validation accuracy:		92.07 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.079309
  validation loss:		0.304516
  validation accuracy:		91.52 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.077773
  validation loss:		0.307546
  validation accuracy:		91.74 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.081392
  validation loss:		0.310615
  validation accuracy:		91.63 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.082957
  validation loss:		0.311061
  validation accuracy:		91.41 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.077373
  validation loss:		0.299442
  validation accuracy:		92.07 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.081970
  validation loss:		0.313068
  validation accuracy:		91.09 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.079987
  validation loss:		0.312069
  validation accuracy:		91.41 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.079521
  validation loss:		0.307897
  validation accuracy:		91.74 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.079619
  validation loss:		0.315337
  validation accuracy:		91.20 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.077509
  validation loss:		0.309342
  validation accuracy:		91.63 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.081524
  validation loss:		0.295317
  validation accuracy:		92.17 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.081893
  validation loss:		0.305551
  validation accuracy:		91.96 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.080441
  validation loss:		0.308065
  validation accuracy:		91.52 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.078943
  validation loss:		0.306835
  validation accuracy:		91.74 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.076473
  validation loss:		0.313788
  validation accuracy:		91.63 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.079164
  validation loss:		0.311731
  validation accuracy:		92.17 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.075938
  validation loss:		0.310314
  validation accuracy:		91.74 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.078138
  validation loss:		0.321173
  validation accuracy:		91.96 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.077747
  validation loss:		0.308433
  validation accuracy:		91.63 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.074921
  validation loss:		0.311725
  validation accuracy:		91.74 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.077572
  validation loss:		0.319382
  validation accuracy:		91.41 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.078019
  validation loss:		0.311776
  validation accuracy:		91.74 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.081381
  validation loss:		0.298058
  validation accuracy:		92.07 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.077655
  validation loss:		0.324689
  validation accuracy:		91.41 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.074220
  validation loss:		0.307517
  validation accuracy:		91.96 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.076925
  validation loss:		0.307312
  validation accuracy:		91.74 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.076277
  validation loss:		0.311123
  validation accuracy:		91.74 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.074305
  validation loss:		0.315069
  validation accuracy:		91.41 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.076809
  validation loss:		0.313940
  validation accuracy:		91.74 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.076967
  validation loss:		0.316472
  validation accuracy:		91.74 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.074033
  validation loss:		0.314278
  validation accuracy:		91.74 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.075582
  validation loss:		0.300124
  validation accuracy:		92.39 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.077960
  validation loss:		0.312215
  validation accuracy:		91.96 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.073908
  validation loss:		0.333816
  validation accuracy:		91.52 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.075014
  validation loss:		0.309955
  validation accuracy:		91.41 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.072368
  validation loss:		0.315244
  validation accuracy:		91.85 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.070944
  validation loss:		0.320671
  validation accuracy:		91.63 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.074048
  validation loss:		0.320507
  validation accuracy:		91.96 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.071973
  validation loss:		0.308092
  validation accuracy:		91.85 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.073696
  validation loss:		0.325525
  validation accuracy:		91.41 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.074503
  validation loss:		0.321283
  validation accuracy:		91.52 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.073356
  validation loss:		0.315161
  validation accuracy:		92.07 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.073860
  validation loss:		0.315223
  validation accuracy:		91.85 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.069679
  validation loss:		0.326075
  validation accuracy:		91.52 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.072303
  validation loss:		0.318298
  validation accuracy:		91.41 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.074271
  validation loss:		0.326859
  validation accuracy:		91.30 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.073889
  validation loss:		0.313981
  validation accuracy:		91.74 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.072405
  validation loss:		0.330076
  validation accuracy:		91.41 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.071919
  validation loss:		0.320840
  validation accuracy:		91.74 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.072816
  validation loss:		0.316899
  validation accuracy:		91.63 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.071299
  validation loss:		0.323393
  validation accuracy:		91.30 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.071830
  validation loss:		0.312844
  validation accuracy:		92.07 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.071655
  validation loss:		0.322885
  validation accuracy:		91.41 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.072232
  validation loss:		0.321955
  validation accuracy:		91.74 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.070325
  validation loss:		0.320984
  validation accuracy:		91.63 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.070316
  validation loss:		0.320900
  validation accuracy:		91.63 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.069080
  validation loss:		0.317123
  validation accuracy:		92.07 %
Epoch 480 of 2000 took 0.037s
  training loss:		0.071187
  validation loss:		0.309812
  validation accuracy:		91.96 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.069616
  validation loss:		0.314679
  validation accuracy:		91.63 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.071346
  validation loss:		0.316776
  validation accuracy:		91.74 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.069949
  validation loss:		0.324890
  validation accuracy:		91.63 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.069892
  validation loss:		0.320872
  validation accuracy:		91.52 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.068586
  validation loss:		0.324695
  validation accuracy:		91.52 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.070437
  validation loss:		0.335114
  validation accuracy:		91.52 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.070787
  validation loss:		0.313323
  validation accuracy:		91.96 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.066676
  validation loss:		0.332658
  validation accuracy:		91.41 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.067800
  validation loss:		0.326121
  validation accuracy:		91.41 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.066890
  validation loss:		0.326431
  validation accuracy:		91.52 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.067717
  validation loss:		0.330516
  validation accuracy:		91.63 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.068255
  validation loss:		0.331322
  validation accuracy:		91.30 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.070683
  validation loss:		0.322934
  validation accuracy:		91.63 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.068256
  validation loss:		0.327718
  validation accuracy:		91.41 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.069225
  validation loss:		0.326740
  validation accuracy:		91.52 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.066039
  validation loss:		0.326968
  validation accuracy:		91.30 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.067680
  validation loss:		0.321502
  validation accuracy:		91.85 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.065848
  validation loss:		0.315737
  validation accuracy:		91.63 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.067552
  validation loss:		0.321777
  validation accuracy:		91.63 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.066088
  validation loss:		0.333481
  validation accuracy:		91.63 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.066764
  validation loss:		0.334985
  validation accuracy:		91.09 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.064622
  validation loss:		0.326866
  validation accuracy:		91.63 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.067126
  validation loss:		0.319169
  validation accuracy:		91.96 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.064901
  validation loss:		0.319866
  validation accuracy:		92.28 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.065890
  validation loss:		0.340872
  validation accuracy:		91.41 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.066629
  validation loss:		0.328046
  validation accuracy:		91.63 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.063505
  validation loss:		0.327776
  validation accuracy:		91.63 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.067708
  validation loss:		0.323135
  validation accuracy:		91.52 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.064792
  validation loss:		0.327714
  validation accuracy:		92.07 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.063025
  validation loss:		0.331621
  validation accuracy:		91.30 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.064995
  validation loss:		0.333720
  validation accuracy:		91.09 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.065356
  validation loss:		0.324407
  validation accuracy:		92.39 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.063010
  validation loss:		0.327436
  validation accuracy:		91.41 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.065374
  validation loss:		0.325657
  validation accuracy:		92.17 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.063682
  validation loss:		0.328291
  validation accuracy:		91.74 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.065539
  validation loss:		0.339534
  validation accuracy:		91.30 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.065016
  validation loss:		0.331356
  validation accuracy:		91.41 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.062759
  validation loss:		0.337709
  validation accuracy:		92.17 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.063241
  validation loss:		0.331017
  validation accuracy:		91.41 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.061849
  validation loss:		0.333007
  validation accuracy:		91.63 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.063590
  validation loss:		0.346084
  validation accuracy:		91.30 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.064226
  validation loss:		0.323878
  validation accuracy:		91.85 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.061424
  validation loss:		0.349822
  validation accuracy:		91.09 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.063060
  validation loss:		0.330573
  validation accuracy:		91.74 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.063288
  validation loss:		0.329859
  validation accuracy:		91.63 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.060578
  validation loss:		0.344022
  validation accuracy:		90.98 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.062270
  validation loss:		0.335949
  validation accuracy:		91.41 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.063633
  validation loss:		0.341856
  validation accuracy:		91.63 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.062602
  validation loss:		0.339155
  validation accuracy:		91.41 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.060756
  validation loss:		0.348640
  validation accuracy:		91.30 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.060949
  validation loss:		0.348150
  validation accuracy:		91.09 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.061397
  validation loss:		0.328154
  validation accuracy:		91.85 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.057929
  validation loss:		0.329974
  validation accuracy:		91.85 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.061694
  validation loss:		0.341139
  validation accuracy:		91.30 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.059574
  validation loss:		0.339976
  validation accuracy:		91.63 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.060723
  validation loss:		0.325607
  validation accuracy:		92.17 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.059035
  validation loss:		0.338590
  validation accuracy:		91.30 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.059185
  validation loss:		0.338138
  validation accuracy:		91.52 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.059938
  validation loss:		0.339837
  validation accuracy:		91.52 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.059159
  validation loss:		0.342278
  validation accuracy:		91.52 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.058624
  validation loss:		0.338243
  validation accuracy:		91.63 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.059136
  validation loss:		0.341215
  validation accuracy:		91.41 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.061393
  validation loss:		0.338186
  validation accuracy:		91.63 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.058820
  validation loss:		0.328021
  validation accuracy:		91.74 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.060082
  validation loss:		0.344391
  validation accuracy:		91.20 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.058481
  validation loss:		0.334648
  validation accuracy:		91.41 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.057009
  validation loss:		0.337464
  validation accuracy:		91.96 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.061381
  validation loss:		0.345671
  validation accuracy:		91.09 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.059735
  validation loss:		0.336658
  validation accuracy:		91.41 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.059959
  validation loss:		0.335187
  validation accuracy:		91.85 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.058733
  validation loss:		0.347482
  validation accuracy:		91.30 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.058891
  validation loss:		0.341294
  validation accuracy:		91.41 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.059031
  validation loss:		0.345008
  validation accuracy:		91.20 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.056300
  validation loss:		0.361537
  validation accuracy:		90.87 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.059341
  validation loss:		0.350458
  validation accuracy:		91.20 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.058834
  validation loss:		0.347275
  validation accuracy:		91.85 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.056332
  validation loss:		0.346524
  validation accuracy:		91.30 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.059938
  validation loss:		0.344215
  validation accuracy:		91.52 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.058287
  validation loss:		0.344999
  validation accuracy:		91.30 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.058715
  validation loss:		0.336987
  validation accuracy:		91.85 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.054192
  validation loss:		0.340370
  validation accuracy:		91.63 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.058043
  validation loss:		0.351615
  validation accuracy:		91.30 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.057157
  validation loss:		0.338362
  validation accuracy:		91.96 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.054388
  validation loss:		0.349477
  validation accuracy:		91.30 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.058339
  validation loss:		0.355958
  validation accuracy:		91.30 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.056954
  validation loss:		0.345697
  validation accuracy:		91.41 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.057376
  validation loss:		0.338805
  validation accuracy:		92.28 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.054468
  validation loss:		0.342537
  validation accuracy:		91.85 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.055954
  validation loss:		0.345483
  validation accuracy:		91.74 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.054450
  validation loss:		0.347817
  validation accuracy:		91.30 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.056850
  validation loss:		0.358360
  validation accuracy:		91.52 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.056136
  validation loss:		0.338899
  validation accuracy:		91.74 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.055095
  validation loss:		0.344617
  validation accuracy:		91.96 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.055588
  validation loss:		0.358355
  validation accuracy:		91.30 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.054935
  validation loss:		0.352239
  validation accuracy:		91.30 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.055189
  validation loss:		0.348957
  validation accuracy:		91.85 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.054784
  validation loss:		0.349450
  validation accuracy:		91.63 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.054266
  validation loss:		0.345393
  validation accuracy:		91.41 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.052213
  validation loss:		0.349837
  validation accuracy:		91.63 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.055084
  validation loss:		0.341032
  validation accuracy:		91.63 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.055519
  validation loss:		0.339398
  validation accuracy:		92.17 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.055241
  validation loss:		0.340192
  validation accuracy:		91.96 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.053356
  validation loss:		0.354990
  validation accuracy:		91.41 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.054247
  validation loss:		0.356862
  validation accuracy:		91.63 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.052917
  validation loss:		0.349674
  validation accuracy:		91.96 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.053533
  validation loss:		0.352761
  validation accuracy:		91.20 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.053879
  validation loss:		0.363134
  validation accuracy:		91.52 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.052685
  validation loss:		0.353010
  validation accuracy:		91.20 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.053676
  validation loss:		0.356309
  validation accuracy:		91.85 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.054589
  validation loss:		0.359201
  validation accuracy:		91.52 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.053335
  validation loss:		0.353521
  validation accuracy:		91.74 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.054455
  validation loss:		0.356278
  validation accuracy:		91.63 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.053570
  validation loss:		0.347492
  validation accuracy:		91.85 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.052571
  validation loss:		0.355354
  validation accuracy:		91.52 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.050787
  validation loss:		0.353993
  validation accuracy:		91.63 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.048938
  validation loss:		0.363580
  validation accuracy:		91.63 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.053398
  validation loss:		0.342893
  validation accuracy:		92.07 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.051471
  validation loss:		0.369962
  validation accuracy:		91.74 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.052516
  validation loss:		0.353993
  validation accuracy:		91.41 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.051434
  validation loss:		0.357478
  validation accuracy:		91.96 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.052113
  validation loss:		0.352482
  validation accuracy:		91.63 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.050331
  validation loss:		0.365525
  validation accuracy:		91.74 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.050792
  validation loss:		0.351175
  validation accuracy:		91.85 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.052029
  validation loss:		0.361360
  validation accuracy:		91.52 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.052169
  validation loss:		0.358444
  validation accuracy:		91.85 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.053679
  validation loss:		0.363074
  validation accuracy:		91.85 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.051139
  validation loss:		0.362674
  validation accuracy:		91.63 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.049370
  validation loss:		0.374605
  validation accuracy:		91.20 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.051296
  validation loss:		0.359766
  validation accuracy:		91.85 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.050985
  validation loss:		0.359074
  validation accuracy:		91.85 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.050681
  validation loss:		0.364960
  validation accuracy:		91.52 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.049561
  validation loss:		0.362266
  validation accuracy:		91.30 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.049989
  validation loss:		0.360756
  validation accuracy:		91.85 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.049428
  validation loss:		0.361342
  validation accuracy:		91.74 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.050287
  validation loss:		0.353076
  validation accuracy:		91.63 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.048808
  validation loss:		0.369008
  validation accuracy:		91.63 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.049418
  validation loss:		0.353449
  validation accuracy:		91.85 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.047322
  validation loss:		0.355189
  validation accuracy:		91.63 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.049405
  validation loss:		0.356745
  validation accuracy:		91.74 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.046001
  validation loss:		0.374640
  validation accuracy:		91.41 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.050553
  validation loss:		0.346359
  validation accuracy:		91.85 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.048684
  validation loss:		0.369559
  validation accuracy:		91.30 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.049785
  validation loss:		0.365879
  validation accuracy:		91.96 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.050605
  validation loss:		0.368265
  validation accuracy:		91.41 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.047769
  validation loss:		0.349473
  validation accuracy:		92.07 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.045291
  validation loss:		0.355020
  validation accuracy:		91.96 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.048332
  validation loss:		0.371474
  validation accuracy:		91.74 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.046833
  validation loss:		0.360372
  validation accuracy:		91.52 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.048170
  validation loss:		0.365082
  validation accuracy:		91.74 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.048543
  validation loss:		0.365921
  validation accuracy:		91.30 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.048842
  validation loss:		0.353845
  validation accuracy:		91.96 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.047241
  validation loss:		0.374735
  validation accuracy:		91.30 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.047973
  validation loss:		0.370508
  validation accuracy:		91.74 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.048445
  validation loss:		0.363497
  validation accuracy:		91.63 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.047272
  validation loss:		0.363912
  validation accuracy:		91.41 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.044745
  validation loss:		0.360271
  validation accuracy:		91.96 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.048309
  validation loss:		0.375208
  validation accuracy:		91.41 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.046514
  validation loss:		0.374394
  validation accuracy:		91.20 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.048049
  validation loss:		0.349520
  validation accuracy:		91.74 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.049317
  validation loss:		0.357035
  validation accuracy:		91.85 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.046988
  validation loss:		0.367584
  validation accuracy:		91.96 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.047849
  validation loss:		0.373730
  validation accuracy:		91.52 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.046650
  validation loss:		0.369366
  validation accuracy:		91.63 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.046373
  validation loss:		0.371442
  validation accuracy:		91.52 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.047661
  validation loss:		0.381015
  validation accuracy:		91.52 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.045967
  validation loss:		0.362840
  validation accuracy:		91.85 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.045542
  validation loss:		0.374479
  validation accuracy:		91.74 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.045451
  validation loss:		0.367340
  validation accuracy:		91.63 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.042503
  validation loss:		0.377011
  validation accuracy:		91.74 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.044469
  validation loss:		0.366462
  validation accuracy:		91.52 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.044621
  validation loss:		0.390728
  validation accuracy:		90.98 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.044590
  validation loss:		0.372316
  validation accuracy:		92.07 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.044408
  validation loss:		0.366213
  validation accuracy:		91.96 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.045771
  validation loss:		0.369713
  validation accuracy:		91.52 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.043263
  validation loss:		0.374651
  validation accuracy:		91.52 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.045367
  validation loss:		0.366530
  validation accuracy:		91.96 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.043394
  validation loss:		0.376081
  validation accuracy:		92.07 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.045765
  validation loss:		0.376767
  validation accuracy:		91.85 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.044698
  validation loss:		0.387027
  validation accuracy:		91.20 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.044733
  validation loss:		0.367907
  validation accuracy:		91.96 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.045794
  validation loss:		0.381960
  validation accuracy:		91.63 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.045865
  validation loss:		0.380512
  validation accuracy:		91.63 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.043423
  validation loss:		0.377954
  validation accuracy:		91.52 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.043086
  validation loss:		0.372186
  validation accuracy:		91.85 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.044724
  validation loss:		0.375519
  validation accuracy:		91.74 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.041875
  validation loss:		0.375208
  validation accuracy:		91.41 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.043680
  validation loss:		0.381271
  validation accuracy:		91.85 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.044327
  validation loss:		0.380351
  validation accuracy:		91.52 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.045159
  validation loss:		0.389683
  validation accuracy:		91.30 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.044610
  validation loss:		0.379103
  validation accuracy:		91.96 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.041779
  validation loss:		0.386884
  validation accuracy:		91.52 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.040971
  validation loss:		0.392106
  validation accuracy:		91.41 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.042990
  validation loss:		0.378031
  validation accuracy:		91.52 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.041692
  validation loss:		0.400686
  validation accuracy:		90.98 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.042096
  validation loss:		0.383202
  validation accuracy:		92.17 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.043403
  validation loss:		0.380216
  validation accuracy:		91.85 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.042349
  validation loss:		0.382861
  validation accuracy:		91.74 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.042308
  validation loss:		0.389710
  validation accuracy:		91.41 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.042511
  validation loss:		0.383172
  validation accuracy:		91.41 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.041961
  validation loss:		0.379631
  validation accuracy:		91.85 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.042753
  validation loss:		0.386323
  validation accuracy:		91.96 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.043813
  validation loss:		0.388968
  validation accuracy:		91.74 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.040897
  validation loss:		0.390298
  validation accuracy:		91.52 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.042762
  validation loss:		0.390707
  validation accuracy:		91.41 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.042314
  validation loss:		0.376895
  validation accuracy:		91.74 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.041145
  validation loss:		0.388642
  validation accuracy:		91.74 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.040183
  validation loss:		0.379803
  validation accuracy:		91.74 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.039717
  validation loss:		0.382845
  validation accuracy:		91.85 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.042310
  validation loss:		0.390960
  validation accuracy:		91.41 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.042620
  validation loss:		0.390801
  validation accuracy:		91.74 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.042112
  validation loss:		0.374579
  validation accuracy:		91.96 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.042565
  validation loss:		0.389581
  validation accuracy:		91.85 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.040757
  validation loss:		0.380703
  validation accuracy:		91.96 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.040994
  validation loss:		0.378206
  validation accuracy:		91.74 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.041939
  validation loss:		0.391443
  validation accuracy:		91.30 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.041737
  validation loss:		0.375825
  validation accuracy:		91.74 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.039144
  validation loss:		0.384946
  validation accuracy:		91.85 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.039173
  validation loss:		0.385626
  validation accuracy:		91.52 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.041819
  validation loss:		0.393764
  validation accuracy:		91.63 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.040185
  validation loss:		0.396700
  validation accuracy:		91.30 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.040350
  validation loss:		0.392368
  validation accuracy:		91.63 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.040991
  validation loss:		0.387062
  validation accuracy:		91.96 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.038527
  validation loss:		0.393980
  validation accuracy:		91.74 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.040367
  validation loss:		0.393015
  validation accuracy:		91.52 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.040513
  validation loss:		0.396126
  validation accuracy:		91.96 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.036859
  validation loss:		0.404284
  validation accuracy:		91.20 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.039698
  validation loss:		0.397230
  validation accuracy:		91.52 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.037762
  validation loss:		0.395190
  validation accuracy:		91.74 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.038172
  validation loss:		0.400442
  validation accuracy:		91.41 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.038656
  validation loss:		0.391184
  validation accuracy:		91.74 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.038742
  validation loss:		0.398656
  validation accuracy:		91.85 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.039280
  validation loss:		0.392806
  validation accuracy:		91.52 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.038605
  validation loss:		0.407432
  validation accuracy:		90.98 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.038858
  validation loss:		0.397991
  validation accuracy:		91.74 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.036944
  validation loss:		0.393408
  validation accuracy:		91.74 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.038525
  validation loss:		0.396777
  validation accuracy:		91.74 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.038595
  validation loss:		0.387134
  validation accuracy:		91.96 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.038087
  validation loss:		0.404027
  validation accuracy:		91.85 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.037479
  validation loss:		0.394746
  validation accuracy:		91.63 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.037209
  validation loss:		0.408631
  validation accuracy:		91.52 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.037916
  validation loss:		0.393422
  validation accuracy:		91.74 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.037271
  validation loss:		0.393241
  validation accuracy:		91.85 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.036279
  validation loss:		0.399234
  validation accuracy:		91.52 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.037082
  validation loss:		0.390014
  validation accuracy:		91.85 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.039196
  validation loss:		0.396564
  validation accuracy:		91.63 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.036388
  validation loss:		0.392197
  validation accuracy:		91.85 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.037495
  validation loss:		0.398746
  validation accuracy:		92.07 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.037269
  validation loss:		0.407129
  validation accuracy:		91.74 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.036813
  validation loss:		0.411200
  validation accuracy:		91.41 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.036126
  validation loss:		0.400733
  validation accuracy:		91.96 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.036975
  validation loss:		0.407262
  validation accuracy:		91.09 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.037353
  validation loss:		0.386984
  validation accuracy:		91.74 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.036359
  validation loss:		0.396739
  validation accuracy:		91.63 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.036694
  validation loss:		0.407389
  validation accuracy:		91.20 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.036195
  validation loss:		0.393679
  validation accuracy:		92.17 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.036076
  validation loss:		0.396686
  validation accuracy:		91.52 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.036441
  validation loss:		0.400715
  validation accuracy:		91.74 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.035071
  validation loss:		0.398502
  validation accuracy:		91.85 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.036805
  validation loss:		0.400648
  validation accuracy:		91.85 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.033694
  validation loss:		0.401094
  validation accuracy:		91.41 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.036010
  validation loss:		0.413327
  validation accuracy:		91.85 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.034593
  validation loss:		0.412160
  validation accuracy:		91.41 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.035610
  validation loss:		0.408752
  validation accuracy:		91.52 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.035312
  validation loss:		0.410010
  validation accuracy:		91.74 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.035568
  validation loss:		0.408021
  validation accuracy:		91.63 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.036262
  validation loss:		0.402072
  validation accuracy:		91.74 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.035936
  validation loss:		0.404999
  validation accuracy:		91.74 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.036405
  validation loss:		0.398292
  validation accuracy:		92.07 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.036415
  validation loss:		0.419093
  validation accuracy:		91.63 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.035070
  validation loss:		0.432622
  validation accuracy:		90.87 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.036426
  validation loss:		0.404084
  validation accuracy:		91.74 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.034657
  validation loss:		0.415222
  validation accuracy:		91.85 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.034322
  validation loss:		0.405883
  validation accuracy:		91.74 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.033414
  validation loss:		0.413276
  validation accuracy:		91.30 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.032814
  validation loss:		0.403376
  validation accuracy:		92.07 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.033394
  validation loss:		0.406756
  validation accuracy:		91.74 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.035296
  validation loss:		0.400515
  validation accuracy:		91.41 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.035267
  validation loss:		0.411111
  validation accuracy:		91.74 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.032338
  validation loss:		0.434668
  validation accuracy:		90.98 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.034782
  validation loss:		0.404470
  validation accuracy:		91.85 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.035269
  validation loss:		0.419274
  validation accuracy:		91.09 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.032997
  validation loss:		0.408176
  validation accuracy:		91.63 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.034498
  validation loss:		0.406144
  validation accuracy:		91.85 %
Epoch 764 of 2000 took 0.037s
  training loss:		0.034913
  validation loss:		0.416781
  validation accuracy:		91.20 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.033868
  validation loss:		0.417287
  validation accuracy:		91.41 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.033661
  validation loss:		0.404706
  validation accuracy:		91.52 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.033532
  validation loss:		0.423521
  validation accuracy:		91.30 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.034849
  validation loss:		0.424986
  validation accuracy:		91.52 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.033936
  validation loss:		0.414637
  validation accuracy:		91.30 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.031652
  validation loss:		0.434412
  validation accuracy:		91.30 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.032869
  validation loss:		0.402751
  validation accuracy:		91.41 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.032950
  validation loss:		0.417550
  validation accuracy:		91.52 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.033561
  validation loss:		0.421778
  validation accuracy:		91.52 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.033046
  validation loss:		0.407930
  validation accuracy:		91.74 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.031355
  validation loss:		0.419784
  validation accuracy:		91.52 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.032630
  validation loss:		0.406461
  validation accuracy:		91.85 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.032959
  validation loss:		0.419064
  validation accuracy:		91.30 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.032580
  validation loss:		0.422651
  validation accuracy:		91.74 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.033546
  validation loss:		0.410881
  validation accuracy:		91.63 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.032917
  validation loss:		0.413886
  validation accuracy:		91.74 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.032434
  validation loss:		0.426220
  validation accuracy:		91.20 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.031876
  validation loss:		0.421925
  validation accuracy:		91.74 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.032245
  validation loss:		0.426054
  validation accuracy:		91.74 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.032249
  validation loss:		0.421581
  validation accuracy:		91.52 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.032345
  validation loss:		0.424666
  validation accuracy:		91.30 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.030665
  validation loss:		0.428297
  validation accuracy:		91.41 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.031722
  validation loss:		0.430165
  validation accuracy:		91.85 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.032022
  validation loss:		0.423390
  validation accuracy:		91.41 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.031987
  validation loss:		0.427466
  validation accuracy:		91.20 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.031894
  validation loss:		0.423654
  validation accuracy:		91.63 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.031674
  validation loss:		0.419616
  validation accuracy:		91.52 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.030454
  validation loss:		0.435734
  validation accuracy:		91.30 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.031056
  validation loss:		0.425333
  validation accuracy:		91.52 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.032009
  validation loss:		0.423589
  validation accuracy:		91.74 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.031321
  validation loss:		0.417613
  validation accuracy:		91.63 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.030719
  validation loss:		0.432965
  validation accuracy:		91.74 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.031181
  validation loss:		0.429980
  validation accuracy:		91.30 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.031135
  validation loss:		0.425602
  validation accuracy:		91.41 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.031250
  validation loss:		0.425897
  validation accuracy:		91.52 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.030039
  validation loss:		0.433794
  validation accuracy:		91.52 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.030839
  validation loss:		0.427012
  validation accuracy:		91.63 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.030121
  validation loss:		0.424966
  validation accuracy:		91.63 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.029677
  validation loss:		0.429320
  validation accuracy:		91.52 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.030476
  validation loss:		0.430367
  validation accuracy:		91.30 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.029936
  validation loss:		0.423900
  validation accuracy:		91.63 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.029785
  validation loss:		0.414149
  validation accuracy:		91.63 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.030243
  validation loss:		0.420549
  validation accuracy:		91.63 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.027922
  validation loss:		0.415651
  validation accuracy:		91.63 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.029784
  validation loss:		0.414094
  validation accuracy:		91.63 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.030495
  validation loss:		0.427473
  validation accuracy:		91.41 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.029654
  validation loss:		0.426312
  validation accuracy:		91.52 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.030085
  validation loss:		0.424358
  validation accuracy:		91.74 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.029302
  validation loss:		0.428160
  validation accuracy:		91.52 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.029182
  validation loss:		0.440518
  validation accuracy:		91.63 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.028385
  validation loss:		0.423413
  validation accuracy:		91.96 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.028437
  validation loss:		0.430622
  validation accuracy:		91.41 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.028609
  validation loss:		0.437382
  validation accuracy:		91.41 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.028672
  validation loss:		0.438902
  validation accuracy:		91.52 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.029926
  validation loss:		0.434328
  validation accuracy:		91.52 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.028477
  validation loss:		0.441727
  validation accuracy:		91.63 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.028744
  validation loss:		0.430824
  validation accuracy:		91.52 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.029100
  validation loss:		0.426706
  validation accuracy:		91.52 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.029252
  validation loss:		0.440836
  validation accuracy:		91.52 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.028753
  validation loss:		0.459300
  validation accuracy:		91.30 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.028534
  validation loss:		0.440555
  validation accuracy:		91.41 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.027525
  validation loss:		0.438317
  validation accuracy:		91.52 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.029332
  validation loss:		0.458922
  validation accuracy:		90.98 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.029213
  validation loss:		0.433515
  validation accuracy:		91.30 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.027247
  validation loss:		0.430826
  validation accuracy:		91.63 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.027895
  validation loss:		0.426696
  validation accuracy:		91.63 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.028142
  validation loss:		0.418585
  validation accuracy:		91.74 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.030158
  validation loss:		0.435640
  validation accuracy:		91.85 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.028024
  validation loss:		0.430404
  validation accuracy:		91.63 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.028603
  validation loss:		0.438170
  validation accuracy:		91.74 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.027711
  validation loss:		0.438724
  validation accuracy:		91.63 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.028586
  validation loss:		0.445697
  validation accuracy:		91.52 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.028468
  validation loss:		0.443530
  validation accuracy:		91.63 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.028243
  validation loss:		0.432949
  validation accuracy:		91.52 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.027340
  validation loss:		0.440332
  validation accuracy:		91.63 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.027598
  validation loss:		0.440833
  validation accuracy:		91.41 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.027421
  validation loss:		0.429246
  validation accuracy:		91.52 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.027368
  validation loss:		0.443134
  validation accuracy:		91.52 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.028087
  validation loss:		0.447671
  validation accuracy:		91.74 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.027409
  validation loss:		0.433189
  validation accuracy:		91.63 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.027297
  validation loss:		0.446021
  validation accuracy:		91.52 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.026573
  validation loss:		0.442428
  validation accuracy:		91.74 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.027159
  validation loss:		0.443806
  validation accuracy:		91.41 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.027410
  validation loss:		0.434633
  validation accuracy:		91.52 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.026723
  validation loss:		0.443121
  validation accuracy:		91.52 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.026772
  validation loss:		0.447099
  validation accuracy:		91.63 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.027135
  validation loss:		0.443945
  validation accuracy:		91.74 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.025767
  validation loss:		0.446373
  validation accuracy:		91.74 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.026973
  validation loss:		0.434628
  validation accuracy:		91.52 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.026343
  validation loss:		0.438857
  validation accuracy:		91.63 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.026239
  validation loss:		0.455512
  validation accuracy:		91.30 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.026156
  validation loss:		0.439741
  validation accuracy:		92.07 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.026210
  validation loss:		0.426415
  validation accuracy:		91.52 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.026075
  validation loss:		0.445562
  validation accuracy:		91.85 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.025722
  validation loss:		0.444182
  validation accuracy:		91.63 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.025868
  validation loss:		0.455906
  validation accuracy:		91.41 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.025574
  validation loss:		0.430818
  validation accuracy:		91.63 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.025598
  validation loss:		0.443567
  validation accuracy:		91.52 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.026105
  validation loss:		0.443619
  validation accuracy:		91.63 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.025190
  validation loss:		0.459269
  validation accuracy:		91.74 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.026374
  validation loss:		0.438617
  validation accuracy:		91.63 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.025033
  validation loss:		0.446651
  validation accuracy:		91.63 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.023337
  validation loss:		0.451954
  validation accuracy:		91.41 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.025540
  validation loss:		0.449454
  validation accuracy:		91.85 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.025115
  validation loss:		0.441972
  validation accuracy:		91.52 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.025441
  validation loss:		0.441612
  validation accuracy:		91.52 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.025900
  validation loss:		0.440868
  validation accuracy:		91.52 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.023863
  validation loss:		0.456324
  validation accuracy:		91.41 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.025150
  validation loss:		0.450192
  validation accuracy:		91.74 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.024512
  validation loss:		0.459229
  validation accuracy:		91.63 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.025167
  validation loss:		0.456554
  validation accuracy:		91.41 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.024616
  validation loss:		0.451983
  validation accuracy:		91.63 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.024515
  validation loss:		0.462129
  validation accuracy:		91.85 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.025132
  validation loss:		0.452343
  validation accuracy:		91.74 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.024063
  validation loss:		0.461977
  validation accuracy:		91.52 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.024606
  validation loss:		0.451645
  validation accuracy:		91.63 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.024598
  validation loss:		0.447839
  validation accuracy:		91.41 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.024188
  validation loss:		0.455155
  validation accuracy:		91.52 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.023044
  validation loss:		0.466460
  validation accuracy:		91.63 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.023518
  validation loss:		0.451267
  validation accuracy:		91.63 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.023125
  validation loss:		0.456942
  validation accuracy:		91.63 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.024480
  validation loss:		0.443083
  validation accuracy:		91.63 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.023368
  validation loss:		0.450619
  validation accuracy:		91.63 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.024063
  validation loss:		0.444795
  validation accuracy:		91.41 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.024656
  validation loss:		0.454279
  validation accuracy:		91.63 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.023362
  validation loss:		0.454480
  validation accuracy:		91.96 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.022774
  validation loss:		0.453109
  validation accuracy:		91.74 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.024100
  validation loss:		0.457040
  validation accuracy:		91.52 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.023432
  validation loss:		0.453304
  validation accuracy:		91.63 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.023052
  validation loss:		0.445547
  validation accuracy:		91.52 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.023504
  validation loss:		0.458538
  validation accuracy:		91.74 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.024004
  validation loss:		0.457877
  validation accuracy:		91.52 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.023359
  validation loss:		0.457756
  validation accuracy:		91.63 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.023188
  validation loss:		0.451454
  validation accuracy:		91.63 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.022600
  validation loss:		0.457944
  validation accuracy:		91.63 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.023649
  validation loss:		0.458991
  validation accuracy:		91.96 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.023599
  validation loss:		0.444381
  validation accuracy:		91.63 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.023063
  validation loss:		0.453818
  validation accuracy:		91.85 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.023627
  validation loss:		0.463318
  validation accuracy:		91.52 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.023255
  validation loss:		0.458110
  validation accuracy:		91.74 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.022821
  validation loss:		0.463663
  validation accuracy:		91.63 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.023355
  validation loss:		0.454184
  validation accuracy:		91.52 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.023044
  validation loss:		0.461136
  validation accuracy:		91.63 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.023172
  validation loss:		0.448583
  validation accuracy:		91.52 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.022517
  validation loss:		0.455956
  validation accuracy:		91.85 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.023099
  validation loss:		0.454880
  validation accuracy:		91.74 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.021969
  validation loss:		0.467773
  validation accuracy:		91.52 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.023048
  validation loss:		0.481000
  validation accuracy:		91.30 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.022546
  validation loss:		0.459487
  validation accuracy:		91.52 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.022666
  validation loss:		0.480499
  validation accuracy:		91.30 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.023236
  validation loss:		0.473472
  validation accuracy:		91.41 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.022357
  validation loss:		0.474151
  validation accuracy:		91.63 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.022053
  validation loss:		0.460567
  validation accuracy:		91.52 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.021615
  validation loss:		0.464612
  validation accuracy:		91.52 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.022633
  validation loss:		0.462219
  validation accuracy:		91.63 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.021973
  validation loss:		0.464105
  validation accuracy:		91.52 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.021921
  validation loss:		0.453161
  validation accuracy:		91.74 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.022003
  validation loss:		0.460965
  validation accuracy:		91.74 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.021509
  validation loss:		0.461668
  validation accuracy:		91.74 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.021404
  validation loss:		0.464708
  validation accuracy:		91.63 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.021926
  validation loss:		0.457233
  validation accuracy:		91.74 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.022114
  validation loss:		0.464871
  validation accuracy:		91.63 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.022330
  validation loss:		0.479403
  validation accuracy:		91.63 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.021492
  validation loss:		0.462097
  validation accuracy:		91.63 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.020262
  validation loss:		0.463246
  validation accuracy:		91.74 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.021026
  validation loss:		0.466634
  validation accuracy:		91.74 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.020823
  validation loss:		0.481065
  validation accuracy:		91.41 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.020637
  validation loss:		0.466332
  validation accuracy:		91.96 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.021130
  validation loss:		0.473751
  validation accuracy:		91.63 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.021229
  validation loss:		0.454146
  validation accuracy:		91.63 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.020483
  validation loss:		0.476260
  validation accuracy:		91.74 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.021127
  validation loss:		0.468108
  validation accuracy:		91.85 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.021237
  validation loss:		0.472225
  validation accuracy:		91.96 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.020400
  validation loss:		0.463870
  validation accuracy:		91.74 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.021097
  validation loss:		0.481547
  validation accuracy:		91.52 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.020751
  validation loss:		0.459337
  validation accuracy:		91.85 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.021277
  validation loss:		0.476376
  validation accuracy:		91.96 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.019902
  validation loss:		0.465569
  validation accuracy:		91.52 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.020288
  validation loss:		0.468694
  validation accuracy:		91.85 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.020854
  validation loss:		0.476803
  validation accuracy:		91.85 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.020250
  validation loss:		0.466709
  validation accuracy:		91.63 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.020437
  validation loss:		0.468533
  validation accuracy:		91.96 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.020214
  validation loss:		0.468222
  validation accuracy:		91.74 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.019992
  validation loss:		0.476306
  validation accuracy:		91.52 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.019828
  validation loss:		0.471561
  validation accuracy:		91.85 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.020052
  validation loss:		0.471327
  validation accuracy:		91.85 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.019853
  validation loss:		0.481602
  validation accuracy:		91.63 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.020165
  validation loss:		0.467504
  validation accuracy:		91.96 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.020895
  validation loss:		0.483672
  validation accuracy:		91.52 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.019947
  validation loss:		0.478775
  validation accuracy:		91.52 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.020252
  validation loss:		0.482794
  validation accuracy:		91.63 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.019432
  validation loss:		0.484383
  validation accuracy:		91.63 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.020148
  validation loss:		0.467996
  validation accuracy:		91.63 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.020572
  validation loss:		0.475801
  validation accuracy:		91.85 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.019078
  validation loss:		0.486592
  validation accuracy:		91.74 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.019536
  validation loss:		0.477890
  validation accuracy:		91.63 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.019781
  validation loss:		0.480746
  validation accuracy:		91.74 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.018716
  validation loss:		0.475829
  validation accuracy:		91.74 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.018946
  validation loss:		0.474809
  validation accuracy:		91.74 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.020035
  validation loss:		0.487364
  validation accuracy:		91.96 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.019308
  validation loss:		0.478677
  validation accuracy:		91.52 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.019212
  validation loss:		0.471881
  validation accuracy:		91.74 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.019424
  validation loss:		0.483182
  validation accuracy:		91.74 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.019602
  validation loss:		0.475854
  validation accuracy:		91.85 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.019373
  validation loss:		0.485549
  validation accuracy:		91.85 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.019107
  validation loss:		0.476118
  validation accuracy:		91.74 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.019033
  validation loss:		0.475496
  validation accuracy:		91.85 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.018939
  validation loss:		0.489591
  validation accuracy:		91.74 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.019313
  validation loss:		0.477527
  validation accuracy:		91.74 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.018794
  validation loss:		0.485258
  validation accuracy:		91.74 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.018629
  validation loss:		0.490049
  validation accuracy:		91.52 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.018671
  validation loss:		0.486724
  validation accuracy:		91.63 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.018471
  validation loss:		0.512447
  validation accuracy:		91.41 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.019839
  validation loss:		0.495995
  validation accuracy:		91.30 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.018198
  validation loss:		0.487411
  validation accuracy:		91.74 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.018261
  validation loss:		0.474432
  validation accuracy:		91.85 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.017041
  validation loss:		0.479056
  validation accuracy:		91.63 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.019066
  validation loss:		0.491916
  validation accuracy:		91.74 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.018234
  validation loss:		0.491857
  validation accuracy:		91.52 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.017426
  validation loss:		0.485295
  validation accuracy:		91.74 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.018130
  validation loss:		0.477476
  validation accuracy:		91.96 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.018174
  validation loss:		0.483337
  validation accuracy:		91.85 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.018156
  validation loss:		0.475297
  validation accuracy:		91.74 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.018363
  validation loss:		0.486841
  validation accuracy:		91.96 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.017424
  validation loss:		0.482362
  validation accuracy:		91.74 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.018015
  validation loss:		0.480369
  validation accuracy:		91.63 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.018246
  validation loss:		0.495100
  validation accuracy:		91.74 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016837
  validation loss:		0.490771
  validation accuracy:		91.63 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.018131
  validation loss:		0.483176
  validation accuracy:		91.96 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016968
  validation loss:		0.493083
  validation accuracy:		91.74 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.018228
  validation loss:		0.488073
  validation accuracy:		91.63 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.018582
  validation loss:		0.491904
  validation accuracy:		91.63 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.017347
  validation loss:		0.485029
  validation accuracy:		91.74 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.017775
  validation loss:		0.481510
  validation accuracy:		91.96 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.018169
  validation loss:		0.476657
  validation accuracy:		91.74 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.018055
  validation loss:		0.476825
  validation accuracy:		91.85 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.017382
  validation loss:		0.497306
  validation accuracy:		91.63 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.017792
  validation loss:		0.492018
  validation accuracy:		91.52 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.017294
  validation loss:		0.499434
  validation accuracy:		91.30 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.017481
  validation loss:		0.494450
  validation accuracy:		91.63 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.017488
  validation loss:		0.486987
  validation accuracy:		91.74 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.016332
  validation loss:		0.491574
  validation accuracy:		91.52 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.016949
  validation loss:		0.483490
  validation accuracy:		91.74 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.017218
  validation loss:		0.502233
  validation accuracy:		91.63 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.017003
  validation loss:		0.485187
  validation accuracy:		91.85 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.016927
  validation loss:		0.502415
  validation accuracy:		91.74 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.017427
  validation loss:		0.492707
  validation accuracy:		91.74 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.017164
  validation loss:		0.490769
  validation accuracy:		91.52 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.017253
  validation loss:		0.499530
  validation accuracy:		91.85 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.017104
  validation loss:		0.491425
  validation accuracy:		91.74 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.016315
  validation loss:		0.495506
  validation accuracy:		91.74 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.016264
  validation loss:		0.494351
  validation accuracy:		91.63 %
Epoch 1017 of 2000 took 0.036s
  training loss:		0.016894
  validation loss:		0.503921
  validation accuracy:		91.41 %
Epoch 1018 of 2000 took 0.037s
  training loss:		0.017124
  validation loss:		0.494169
  validation accuracy:		91.85 %
Epoch 1019 of 2000 took 0.037s
  training loss:		0.016359
  validation loss:		0.504325
  validation accuracy:		91.63 %
Epoch 1020 of 2000 took 0.037s
  training loss:		0.016298
  validation loss:		0.492809
  validation accuracy:		91.41 %
Epoch 1021 of 2000 took 0.036s
  training loss:		0.017297
  validation loss:		0.500763
  validation accuracy:		91.52 %
Epoch 1022 of 2000 took 0.036s
  training loss:		0.016910
  validation loss:		0.514788
  validation accuracy:		91.85 %
Epoch 1023 of 2000 took 0.036s
  training loss:		0.016120
  validation loss:		0.507540
  validation accuracy:		91.52 %
Epoch 1024 of 2000 took 0.036s
  training loss:		0.016457
  validation loss:		0.486926
  validation accuracy:		91.96 %
Epoch 1025 of 2000 took 0.037s
  training loss:		0.016969
  validation loss:		0.505484
  validation accuracy:		91.74 %
Epoch 1026 of 2000 took 0.037s
  training loss:		0.016598
  validation loss:		0.516791
  validation accuracy:		91.41 %
Epoch 1027 of 2000 took 0.037s
  training loss:		0.016083
  validation loss:		0.492513
  validation accuracy:		91.74 %
Epoch 1028 of 2000 took 0.036s
  training loss:		0.016747
  validation loss:		0.508446
  validation accuracy:		91.52 %
Epoch 1029 of 2000 took 0.036s
  training loss:		0.017103
  validation loss:		0.503303
  validation accuracy:		91.63 %
Epoch 1030 of 2000 took 0.036s
  training loss:		0.016215
  validation loss:		0.498464
  validation accuracy:		91.74 %
Epoch 1031 of 2000 took 0.036s
  training loss:		0.016194
  validation loss:		0.505995
  validation accuracy:		91.63 %
Epoch 1032 of 2000 took 0.036s
  training loss:		0.016838
  validation loss:		0.501333
  validation accuracy:		91.74 %
Epoch 1033 of 2000 took 0.036s
  training loss:		0.015947
  validation loss:		0.494260
  validation accuracy:		91.74 %
Epoch 1034 of 2000 took 0.036s
  training loss:		0.016073
  validation loss:		0.498517
  validation accuracy:		91.41 %
Epoch 1035 of 2000 took 0.036s
  training loss:		0.016145
  validation loss:		0.495920
  validation accuracy:		91.96 %
Epoch 1036 of 2000 took 0.036s
  training loss:		0.016106
  validation loss:		0.511468
  validation accuracy:		91.63 %
Epoch 1037 of 2000 took 0.036s
  training loss:		0.016025
  validation loss:		0.511000
  validation accuracy:		91.41 %
Epoch 1038 of 2000 took 0.036s
  training loss:		0.015979
  validation loss:		0.502604
  validation accuracy:		91.85 %
Epoch 1039 of 2000 took 0.036s
  training loss:		0.015521
  validation loss:		0.503477
  validation accuracy:		91.96 %
Epoch 1040 of 2000 took 0.036s
  training loss:		0.015848
  validation loss:		0.507750
  validation accuracy:		91.52 %
Epoch 1041 of 2000 took 0.036s
  training loss:		0.015541
  validation loss:		0.498449
  validation accuracy:		91.85 %
Epoch 1042 of 2000 took 0.036s
  training loss:		0.015493
  validation loss:		0.505878
  validation accuracy:		91.52 %
Epoch 1043 of 2000 took 0.036s
  training loss:		0.015733
  validation loss:		0.485133
  validation accuracy:		92.07 %
Epoch 1044 of 2000 took 0.037s
  training loss:		0.015876
  validation loss:		0.514340
  validation accuracy:		91.41 %
Epoch 1045 of 2000 took 0.036s
  training loss:		0.015327
  validation loss:		0.506228
  validation accuracy:		91.85 %
Epoch 1046 of 2000 took 0.036s
  training loss:		0.014765
  validation loss:		0.505848
  validation accuracy:		91.52 %
Epoch 1047 of 2000 took 0.036s
  training loss:		0.015262
  validation loss:		0.505634
  validation accuracy:		91.63 %
Epoch 1048 of 2000 took 0.036s
  training loss:		0.014881
  validation loss:		0.500334
  validation accuracy:		91.85 %
Epoch 1049 of 2000 took 0.036s
  training loss:		0.014904
  validation loss:		0.519881
  validation accuracy:		91.52 %
Epoch 1050 of 2000 took 0.036s
  training loss:		0.015403
  validation loss:		0.520891
  validation accuracy:		91.52 %
Epoch 1051 of 2000 took 0.036s
  training loss:		0.015272
  validation loss:		0.506331
  validation accuracy:		91.85 %
Epoch 1052 of 2000 took 0.036s
  training loss:		0.015276
  validation loss:		0.499340
  validation accuracy:		91.74 %
Epoch 1053 of 2000 took 0.036s
  training loss:		0.015348
  validation loss:		0.497547
  validation accuracy:		91.63 %
Epoch 1054 of 2000 took 0.036s
  training loss:		0.015316
  validation loss:		0.504701
  validation accuracy:		91.74 %
Epoch 1055 of 2000 took 0.036s
  training loss:		0.014775
  validation loss:		0.512865
  validation accuracy:		91.63 %
Epoch 1056 of 2000 took 0.036s
  training loss:		0.014968
  validation loss:		0.521249
  validation accuracy:		91.74 %
Epoch 1057 of 2000 took 0.036s
  training loss:		0.013757
  validation loss:		0.502809
  validation accuracy:		91.74 %
Epoch 1058 of 2000 took 0.036s
  training loss:		0.015265
  validation loss:		0.504919
  validation accuracy:		91.74 %
Epoch 1059 of 2000 took 0.036s
  training loss:		0.015120
  validation loss:		0.518431
  validation accuracy:		91.52 %
Epoch 1060 of 2000 took 0.036s
  training loss:		0.013949
  validation loss:		0.520680
  validation accuracy:		91.63 %
Epoch 1061 of 2000 took 0.036s
  training loss:		0.014833
  validation loss:		0.511204
  validation accuracy:		91.96 %
Epoch 1062 of 2000 took 0.036s
  training loss:		0.014588
  validation loss:		0.509805
  validation accuracy:		91.74 %
Epoch 1063 of 2000 took 0.036s
  training loss:		0.014139
  validation loss:		0.504641
  validation accuracy:		91.63 %
Epoch 1064 of 2000 took 0.036s
  training loss:		0.015012
  validation loss:		0.514429
  validation accuracy:		91.41 %
Epoch 1065 of 2000 took 0.036s
  training loss:		0.015142
  validation loss:		0.513813
  validation accuracy:		92.07 %
Epoch 1066 of 2000 took 0.036s
  training loss:		0.014809
  validation loss:		0.510811
  validation accuracy:		91.63 %
Epoch 1067 of 2000 took 0.036s
  training loss:		0.014454
  validation loss:		0.525136
  validation accuracy:		91.63 %
Epoch 1068 of 2000 took 0.036s
  training loss:		0.014083
  validation loss:		0.524574
  validation accuracy:		91.41 %
Epoch 1069 of 2000 took 0.036s
  training loss:		0.014309
  validation loss:		0.517999
  validation accuracy:		91.63 %
Epoch 1070 of 2000 took 0.036s
  training loss:		0.014121
  validation loss:		0.518187
  validation accuracy:		91.20 %
Epoch 1071 of 2000 took 0.036s
  training loss:		0.014001
  validation loss:		0.523639
  validation accuracy:		91.41 %
Epoch 1072 of 2000 took 0.036s
  training loss:		0.014471
  validation loss:		0.523488
  validation accuracy:		91.63 %
Epoch 1073 of 2000 took 0.036s
  training loss:		0.014718
  validation loss:		0.512095
  validation accuracy:		91.30 %
Epoch 1074 of 2000 took 0.036s
  training loss:		0.014156
  validation loss:		0.515906
  validation accuracy:		91.52 %
Epoch 1075 of 2000 took 0.036s
  training loss:		0.015090
  validation loss:		0.512678
  validation accuracy:		91.74 %
Epoch 1076 of 2000 took 0.036s
  training loss:		0.013686
  validation loss:		0.530843
  validation accuracy:		91.52 %
Epoch 1077 of 2000 took 0.036s
  training loss:		0.014422
  validation loss:		0.529257
  validation accuracy:		91.63 %
Epoch 1078 of 2000 took 0.036s
  training loss:		0.014172
  validation loss:		0.527137
  validation accuracy:		91.30 %
Epoch 1079 of 2000 took 0.036s
  training loss:		0.014384
  validation loss:		0.523006
  validation accuracy:		91.52 %
Epoch 1080 of 2000 took 0.036s
  training loss:		0.013962
  validation loss:		0.518469
  validation accuracy:		91.41 %
Epoch 1081 of 2000 took 0.036s
  training loss:		0.013823
  validation loss:		0.517625
  validation accuracy:		91.74 %
Epoch 1082 of 2000 took 0.036s
  training loss:		0.013664
  validation loss:		0.523159
  validation accuracy:		91.63 %
Epoch 1083 of 2000 took 0.036s
  training loss:		0.013364
  validation loss:		0.517591
  validation accuracy:		91.52 %
Epoch 1084 of 2000 took 0.036s
  training loss:		0.014000
  validation loss:		0.525171
  validation accuracy:		91.74 %
Epoch 1085 of 2000 took 0.036s
  training loss:		0.013921
  validation loss:		0.506298
  validation accuracy:		91.74 %
Epoch 1086 of 2000 took 0.036s
  training loss:		0.013763
  validation loss:		0.513224
  validation accuracy:		91.63 %
Epoch 1087 of 2000 took 0.036s
  training loss:		0.014085
  validation loss:		0.514079
  validation accuracy:		91.74 %
Epoch 1088 of 2000 took 0.036s
  training loss:		0.013690
  validation loss:		0.529146
  validation accuracy:		91.52 %
Epoch 1089 of 2000 took 0.036s
  training loss:		0.013789
  validation loss:		0.527095
  validation accuracy:		91.63 %
Epoch 1090 of 2000 took 0.036s
  training loss:		0.013985
  validation loss:		0.519310
  validation accuracy:		91.30 %
Epoch 1091 of 2000 took 0.036s
  training loss:		0.013869
  validation loss:		0.537362
  validation accuracy:		91.63 %
Epoch 1092 of 2000 took 0.036s
  training loss:		0.013916
  validation loss:		0.513228
  validation accuracy:		91.74 %
Epoch 1093 of 2000 took 0.036s
  training loss:		0.013532
  validation loss:		0.525219
  validation accuracy:		91.63 %
Epoch 1094 of 2000 took 0.036s
  training loss:		0.013256
  validation loss:		0.520201
  validation accuracy:		91.74 %
Epoch 1095 of 2000 took 0.036s
  training loss:		0.013993
  validation loss:		0.525266
  validation accuracy:		91.74 %
Epoch 1096 of 2000 took 0.036s
  training loss:		0.013393
  validation loss:		0.536342
  validation accuracy:		91.20 %
Epoch 1097 of 2000 took 0.036s
  training loss:		0.014022
  validation loss:		0.520221
  validation accuracy:		91.74 %
Epoch 1098 of 2000 took 0.036s
  training loss:		0.013523
  validation loss:		0.527255
  validation accuracy:		91.63 %
Epoch 1099 of 2000 took 0.036s
  training loss:		0.012915
  validation loss:		0.525273
  validation accuracy:		91.63 %
Epoch 1100 of 2000 took 0.036s
  training loss:		0.013578
  validation loss:		0.514280
  validation accuracy:		91.63 %
Epoch 1101 of 2000 took 0.036s
  training loss:		0.013403
  validation loss:		0.511204
  validation accuracy:		91.85 %
Epoch 1102 of 2000 took 0.038s
  training loss:		0.013467
  validation loss:		0.523045
  validation accuracy:		91.52 %
Epoch 1103 of 2000 took 0.036s
  training loss:		0.013054
  validation loss:		0.521473
  validation accuracy:		91.85 %
Epoch 1104 of 2000 took 0.036s
  training loss:		0.013103
  validation loss:		0.525049
  validation accuracy:		91.85 %
Epoch 1105 of 2000 took 0.036s
  training loss:		0.012929
  validation loss:		0.530024
  validation accuracy:		91.63 %
Epoch 1106 of 2000 took 0.036s
  training loss:		0.013295
  validation loss:		0.525519
  validation accuracy:		91.63 %
Epoch 1107 of 2000 took 0.036s
  training loss:		0.013185
  validation loss:		0.523679
  validation accuracy:		91.52 %
Epoch 1108 of 2000 took 0.036s
  training loss:		0.013243
  validation loss:		0.524612
  validation accuracy:		91.74 %
Epoch 1109 of 2000 took 0.036s
  training loss:		0.012859
  validation loss:		0.529660
  validation accuracy:		91.30 %
Epoch 1110 of 2000 took 0.036s
  training loss:		0.013112
  validation loss:		0.528633
  validation accuracy:		91.74 %
Epoch 1111 of 2000 took 0.036s
  training loss:		0.012618
  validation loss:		0.527557
  validation accuracy:		91.74 %
Epoch 1112 of 2000 took 0.036s
  training loss:		0.012932
  validation loss:		0.530957
  validation accuracy:		91.63 %
Epoch 1113 of 2000 took 0.036s
  training loss:		0.012811
  validation loss:		0.515797
  validation accuracy:		92.17 %
Epoch 1114 of 2000 took 0.036s
  training loss:		0.013084
  validation loss:		0.525341
  validation accuracy:		91.63 %
Epoch 1115 of 2000 took 0.036s
  training loss:		0.012518
  validation loss:		0.530650
  validation accuracy:		91.85 %
Epoch 1116 of 2000 took 0.036s
  training loss:		0.012738
  validation loss:		0.532377
  validation accuracy:		91.52 %
Epoch 1117 of 2000 took 0.036s
  training loss:		0.012348
  validation loss:		0.519473
  validation accuracy:		91.85 %
Epoch 1118 of 2000 took 0.036s
  training loss:		0.012574
  validation loss:		0.523192
  validation accuracy:		91.63 %
Epoch 1119 of 2000 took 0.036s
  training loss:		0.012850
  validation loss:		0.525141
  validation accuracy:		91.74 %
Epoch 1120 of 2000 took 0.036s
  training loss:		0.012729
  validation loss:		0.524417
  validation accuracy:		91.74 %
Epoch 1121 of 2000 took 0.036s
  training loss:		0.012578
  validation loss:		0.540973
  validation accuracy:		91.63 %
Epoch 1122 of 2000 took 0.036s
  training loss:		0.013008
  validation loss:		0.529758
  validation accuracy:		91.41 %
Epoch 1123 of 2000 took 0.036s
  training loss:		0.013062
  validation loss:		0.523768
  validation accuracy:		91.74 %
Epoch 1124 of 2000 took 0.036s
  training loss:		0.012619
  validation loss:		0.536670
  validation accuracy:		91.52 %
Epoch 1125 of 2000 took 0.036s
  training loss:		0.012200
  validation loss:		0.536286
  validation accuracy:		91.52 %
Epoch 1126 of 2000 took 0.036s
  training loss:		0.012488
  validation loss:		0.533625
  validation accuracy:		91.85 %
Epoch 1127 of 2000 took 0.036s
  training loss:		0.012629
  validation loss:		0.528961
  validation accuracy:		91.63 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.012062
  validation loss:		0.535001
  validation accuracy:		91.74 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.011807
  validation loss:		0.529073
  validation accuracy:		91.74 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.012198
  validation loss:		0.531753
  validation accuracy:		91.63 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.012044
  validation loss:		0.540102
  validation accuracy:		91.63 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.012372
  validation loss:		0.533787
  validation accuracy:		91.74 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.012185
  validation loss:		0.532973
  validation accuracy:		91.63 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.012494
  validation loss:		0.529633
  validation accuracy:		91.63 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011985
  validation loss:		0.530993
  validation accuracy:		91.85 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.012449
  validation loss:		0.540983
  validation accuracy:		91.52 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.011967
  validation loss:		0.548838
  validation accuracy:		91.52 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.012044
  validation loss:		0.553012
  validation accuracy:		91.52 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011962
  validation loss:		0.536736
  validation accuracy:		91.63 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011849
  validation loss:		0.546939
  validation accuracy:		91.63 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.011990
  validation loss:		0.530587
  validation accuracy:		91.52 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.011848
  validation loss:		0.535407
  validation accuracy:		91.85 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.011430
  validation loss:		0.541450
  validation accuracy:		91.63 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.011753
  validation loss:		0.533242
  validation accuracy:		91.74 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.012131
  validation loss:		0.536883
  validation accuracy:		91.63 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.011802
  validation loss:		0.533758
  validation accuracy:		91.74 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.011610
  validation loss:		0.539989
  validation accuracy:		91.63 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.011567
  validation loss:		0.539606
  validation accuracy:		91.85 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.011770
  validation loss:		0.533139
  validation accuracy:		91.85 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.011548
  validation loss:		0.542704
  validation accuracy:		91.52 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.011531
  validation loss:		0.527396
  validation accuracy:		91.63 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.011691
  validation loss:		0.549340
  validation accuracy:		91.63 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.011409
  validation loss:		0.546027
  validation accuracy:		91.41 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.011362
  validation loss:		0.545864
  validation accuracy:		91.85 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.011412
  validation loss:		0.550978
  validation accuracy:		91.63 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.011154
  validation loss:		0.539691
  validation accuracy:		91.52 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.011638
  validation loss:		0.544020
  validation accuracy:		91.63 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011246
  validation loss:		0.541246
  validation accuracy:		91.85 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.011652
  validation loss:		0.533471
  validation accuracy:		91.96 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.011652
  validation loss:		0.535836
  validation accuracy:		91.85 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.011085
  validation loss:		0.535452
  validation accuracy:		91.74 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.010657
  validation loss:		0.544792
  validation accuracy:		91.52 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.011556
  validation loss:		0.535087
  validation accuracy:		91.74 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.011445
  validation loss:		0.548683
  validation accuracy:		91.63 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.010725
  validation loss:		0.545434
  validation accuracy:		91.63 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.011447
  validation loss:		0.540296
  validation accuracy:		91.74 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.011555
  validation loss:		0.542164
  validation accuracy:		91.63 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.011075
  validation loss:		0.540905
  validation accuracy:		91.85 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.011078
  validation loss:		0.551309
  validation accuracy:		91.63 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.010880
  validation loss:		0.551615
  validation accuracy:		91.74 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.010969
  validation loss:		0.551380
  validation accuracy:		91.52 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.011859
  validation loss:		0.543495
  validation accuracy:		91.74 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.010894
  validation loss:		0.550284
  validation accuracy:		91.63 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.011804
  validation loss:		0.542317
  validation accuracy:		91.74 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010714
  validation loss:		0.547406
  validation accuracy:		91.74 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.010784
  validation loss:		0.551649
  validation accuracy:		91.85 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.010634
  validation loss:		0.530575
  validation accuracy:		91.96 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.011307
  validation loss:		0.549788
  validation accuracy:		91.74 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.010862
  validation loss:		0.546734
  validation accuracy:		91.52 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.010752
  validation loss:		0.548773
  validation accuracy:		91.74 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.011244
  validation loss:		0.538080
  validation accuracy:		91.63 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.010713
  validation loss:		0.546548
  validation accuracy:		91.85 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.011200
  validation loss:		0.550054
  validation accuracy:		91.30 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010931
  validation loss:		0.569083
  validation accuracy:		91.52 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010652
  validation loss:		0.549999
  validation accuracy:		91.52 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.010421
  validation loss:		0.553411
  validation accuracy:		91.52 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.010887
  validation loss:		0.550519
  validation accuracy:		91.63 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.010704
  validation loss:		0.553279
  validation accuracy:		91.41 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.010637
  validation loss:		0.555798
  validation accuracy:		91.96 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.010133
  validation loss:		0.560741
  validation accuracy:		91.63 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.010377
  validation loss:		0.553918
  validation accuracy:		91.74 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.010272
  validation loss:		0.561204
  validation accuracy:		91.63 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.010300
  validation loss:		0.559231
  validation accuracy:		91.30 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.010526
  validation loss:		0.558080
  validation accuracy:		91.63 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.010305
  validation loss:		0.548208
  validation accuracy:		91.74 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.010322
  validation loss:		0.566610
  validation accuracy:		91.74 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.010286
  validation loss:		0.557623
  validation accuracy:		91.63 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.009991
  validation loss:		0.548859
  validation accuracy:		91.85 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.010211
  validation loss:		0.550518
  validation accuracy:		91.85 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.010255
  validation loss:		0.570492
  validation accuracy:		91.63 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.010509
  validation loss:		0.554746
  validation accuracy:		91.52 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.010234
  validation loss:		0.562469
  validation accuracy:		91.41 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.010275
  validation loss:		0.551380
  validation accuracy:		91.74 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.009927
  validation loss:		0.565514
  validation accuracy:		91.74 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.010022
  validation loss:		0.556321
  validation accuracy:		91.74 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.010046
  validation loss:		0.556202
  validation accuracy:		91.85 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.010119
  validation loss:		0.563465
  validation accuracy:		91.52 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.010044
  validation loss:		0.575773
  validation accuracy:		91.41 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.010403
  validation loss:		0.560040
  validation accuracy:		91.52 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.010192
  validation loss:		0.554525
  validation accuracy:		91.96 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.009782
  validation loss:		0.551715
  validation accuracy:		91.85 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.009991
  validation loss:		0.550953
  validation accuracy:		91.96 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.010064
  validation loss:		0.568169
  validation accuracy:		91.63 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.009873
  validation loss:		0.559852
  validation accuracy:		91.63 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009879
  validation loss:		0.557692
  validation accuracy:		91.85 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.009782
  validation loss:		0.561119
  validation accuracy:		91.63 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.009759
  validation loss:		0.570749
  validation accuracy:		91.63 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.009748
  validation loss:		0.554518
  validation accuracy:		91.85 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.009997
  validation loss:		0.560400
  validation accuracy:		91.52 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009834
  validation loss:		0.562786
  validation accuracy:		91.63 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.009710
  validation loss:		0.564028
  validation accuracy:		91.74 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.009623
  validation loss:		0.561459
  validation accuracy:		91.85 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.009217
  validation loss:		0.561852
  validation accuracy:		91.85 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.009640
  validation loss:		0.565191
  validation accuracy:		91.63 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009685
  validation loss:		0.579173
  validation accuracy:		91.52 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009588
  validation loss:		0.562061
  validation accuracy:		91.85 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.009518
  validation loss:		0.567819
  validation accuracy:		91.52 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009991
  validation loss:		0.562700
  validation accuracy:		91.74 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.009137
  validation loss:		0.564570
  validation accuracy:		91.74 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.009734
  validation loss:		0.559235
  validation accuracy:		91.85 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009449
  validation loss:		0.575379
  validation accuracy:		91.52 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.009570
  validation loss:		0.561596
  validation accuracy:		91.74 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.009635
  validation loss:		0.562638
  validation accuracy:		91.96 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009282
  validation loss:		0.562311
  validation accuracy:		91.63 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.009327
  validation loss:		0.571718
  validation accuracy:		91.74 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.009328
  validation loss:		0.557951
  validation accuracy:		91.74 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009783
  validation loss:		0.561872
  validation accuracy:		91.96 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.009062
  validation loss:		0.575598
  validation accuracy:		91.63 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009273
  validation loss:		0.562049
  validation accuracy:		91.96 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.008836
  validation loss:		0.566285
  validation accuracy:		91.63 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.009200
  validation loss:		0.564286
  validation accuracy:		91.63 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.008985
  validation loss:		0.566166
  validation accuracy:		91.85 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.009281
  validation loss:		0.573965
  validation accuracy:		91.63 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.009261
  validation loss:		0.568963
  validation accuracy:		91.63 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009214
  validation loss:		0.569663
  validation accuracy:		91.85 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.009244
  validation loss:		0.563720
  validation accuracy:		91.96 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.008929
  validation loss:		0.569429
  validation accuracy:		91.85 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.009085
  validation loss:		0.577703
  validation accuracy:		91.52 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.009207
  validation loss:		0.560477
  validation accuracy:		91.96 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.008795
  validation loss:		0.571073
  validation accuracy:		91.85 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.009049
  validation loss:		0.561182
  validation accuracy:		91.85 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009053
  validation loss:		0.581465
  validation accuracy:		91.63 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.009112
  validation loss:		0.572064
  validation accuracy:		91.74 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.008598
  validation loss:		0.585989
  validation accuracy:		91.63 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.009243
  validation loss:		0.572074
  validation accuracy:		91.52 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.009243
  validation loss:		0.566858
  validation accuracy:		91.85 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.008422
  validation loss:		0.579619
  validation accuracy:		91.74 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.008602
  validation loss:		0.579510
  validation accuracy:		91.52 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.008924
  validation loss:		0.576432
  validation accuracy:		91.52 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.008865
  validation loss:		0.592055
  validation accuracy:		91.52 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.009003
  validation loss:		0.571205
  validation accuracy:		91.74 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.008703
  validation loss:		0.566919
  validation accuracy:		91.96 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.008829
  validation loss:		0.577156
  validation accuracy:		91.74 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.008455
  validation loss:		0.572707
  validation accuracy:		91.74 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.008960
  validation loss:		0.569173
  validation accuracy:		91.74 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.008642
  validation loss:		0.578817
  validation accuracy:		91.96 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.008493
  validation loss:		0.567966
  validation accuracy:		91.85 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008570
  validation loss:		0.577373
  validation accuracy:		91.96 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.008830
  validation loss:		0.581785
  validation accuracy:		91.63 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.008832
  validation loss:		0.581994
  validation accuracy:		91.63 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008697
  validation loss:		0.570340
  validation accuracy:		91.85 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008290
  validation loss:		0.566100
  validation accuracy:		91.85 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008148
  validation loss:		0.569857
  validation accuracy:		91.85 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.008434
  validation loss:		0.577984
  validation accuracy:		91.85 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008612
  validation loss:		0.563402
  validation accuracy:		91.96 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008668
  validation loss:		0.568779
  validation accuracy:		91.74 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.008588
  validation loss:		0.583174
  validation accuracy:		91.74 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.008200
  validation loss:		0.584908
  validation accuracy:		91.63 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008596
  validation loss:		0.580434
  validation accuracy:		91.63 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008448
  validation loss:		0.569563
  validation accuracy:		91.74 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.008593
  validation loss:		0.580282
  validation accuracy:		91.96 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008342
  validation loss:		0.573067
  validation accuracy:		91.96 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.008436
  validation loss:		0.577620
  validation accuracy:		91.85 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008595
  validation loss:		0.575991
  validation accuracy:		91.52 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008580
  validation loss:		0.588874
  validation accuracy:		91.63 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.008403
  validation loss:		0.583506
  validation accuracy:		91.74 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.008181
  validation loss:		0.581327
  validation accuracy:		91.74 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.008318
  validation loss:		0.588309
  validation accuracy:		91.52 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.008369
  validation loss:		0.584105
  validation accuracy:		91.63 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.008101
  validation loss:		0.581231
  validation accuracy:		91.52 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.008378
  validation loss:		0.577724
  validation accuracy:		91.85 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008170
  validation loss:		0.576058
  validation accuracy:		91.85 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.007882
  validation loss:		0.582631
  validation accuracy:		92.07 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.008547
  validation loss:		0.582667
  validation accuracy:		91.52 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.008298
  validation loss:		0.585351
  validation accuracy:		91.74 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.008064
  validation loss:		0.579885
  validation accuracy:		91.52 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.582982
  validation accuracy:		91.74 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.008224
  validation loss:		0.583291
  validation accuracy:		91.74 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.008095
  validation loss:		0.583311
  validation accuracy:		91.63 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.008266
  validation loss:		0.591007
  validation accuracy:		91.74 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.008133
  validation loss:		0.587757
  validation accuracy:		91.63 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.007919
  validation loss:		0.579235
  validation accuracy:		91.96 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.007688
  validation loss:		0.593362
  validation accuracy:		91.63 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.007983
  validation loss:		0.584377
  validation accuracy:		91.63 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.008376
  validation loss:		0.585185
  validation accuracy:		91.63 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.008034
  validation loss:		0.587294
  validation accuracy:		91.74 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.008057
  validation loss:		0.573813
  validation accuracy:		91.85 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.008422
  validation loss:		0.581863
  validation accuracy:		91.74 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.007637
  validation loss:		0.596839
  validation accuracy:		91.85 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.007685
  validation loss:		0.587943
  validation accuracy:		91.63 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.007985
  validation loss:		0.590239
  validation accuracy:		92.07 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.007848
  validation loss:		0.580281
  validation accuracy:		91.85 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.007969
  validation loss:		0.591280
  validation accuracy:		91.74 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.007856
  validation loss:		0.590302
  validation accuracy:		91.74 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.007756
  validation loss:		0.580374
  validation accuracy:		91.96 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.007921
  validation loss:		0.586843
  validation accuracy:		91.85 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.007833
  validation loss:		0.593960
  validation accuracy:		91.74 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.008080
  validation loss:		0.592744
  validation accuracy:		91.96 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.007904
  validation loss:		0.592687
  validation accuracy:		91.96 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.007834
  validation loss:		0.583575
  validation accuracy:		91.85 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.007517
  validation loss:		0.590006
  validation accuracy:		91.74 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.007774
  validation loss:		0.584642
  validation accuracy:		91.63 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007617
  validation loss:		0.585678
  validation accuracy:		91.96 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.007861
  validation loss:		0.586631
  validation accuracy:		91.85 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.007714
  validation loss:		0.592884
  validation accuracy:		91.74 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.007866
  validation loss:		0.581608
  validation accuracy:		91.96 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.007744
  validation loss:		0.589248
  validation accuracy:		91.96 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.007581
  validation loss:		0.595608
  validation accuracy:		91.85 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.007642
  validation loss:		0.608142
  validation accuracy:		91.74 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.007449
  validation loss:		0.590335
  validation accuracy:		91.74 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.007740
  validation loss:		0.585712
  validation accuracy:		91.85 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.007548
  validation loss:		0.587369
  validation accuracy:		91.85 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.007513
  validation loss:		0.595168
  validation accuracy:		91.63 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007666
  validation loss:		0.609959
  validation accuracy:		91.74 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.007672
  validation loss:		0.593370
  validation accuracy:		91.74 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.007299
  validation loss:		0.595428
  validation accuracy:		91.74 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007368
  validation loss:		0.592300
  validation accuracy:		91.96 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007269
  validation loss:		0.591383
  validation accuracy:		91.63 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.007483
  validation loss:		0.589536
  validation accuracy:		91.96 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007228
  validation loss:		0.603665
  validation accuracy:		91.74 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.007357
  validation loss:		0.600199
  validation accuracy:		91.74 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.007227
  validation loss:		0.599159
  validation accuracy:		91.74 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007387
  validation loss:		0.598586
  validation accuracy:		91.85 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.007544
  validation loss:		0.592944
  validation accuracy:		91.85 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007646
  validation loss:		0.603165
  validation accuracy:		91.63 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.007246
  validation loss:		0.603770
  validation accuracy:		91.63 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.007222
  validation loss:		0.609074
  validation accuracy:		91.63 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.007405
  validation loss:		0.586320
  validation accuracy:		91.85 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.007314
  validation loss:		0.599403
  validation accuracy:		91.63 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.007309
  validation loss:		0.603453
  validation accuracy:		91.52 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.007413
  validation loss:		0.597745
  validation accuracy:		91.74 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.006971
  validation loss:		0.600356
  validation accuracy:		91.74 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007353
  validation loss:		0.606392
  validation accuracy:		91.63 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.007157
  validation loss:		0.601730
  validation accuracy:		91.63 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.007173
  validation loss:		0.609656
  validation accuracy:		91.74 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.007318
  validation loss:		0.600695
  validation accuracy:		91.74 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.006895
  validation loss:		0.598642
  validation accuracy:		91.85 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.006930
  validation loss:		0.592757
  validation accuracy:		91.96 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.006816
  validation loss:		0.607012
  validation accuracy:		91.52 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007255
  validation loss:		0.603350
  validation accuracy:		91.52 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.007003
  validation loss:		0.613652
  validation accuracy:		91.85 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.007188
  validation loss:		0.611935
  validation accuracy:		91.63 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.007043
  validation loss:		0.603626
  validation accuracy:		91.74 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.006906
  validation loss:		0.606365
  validation accuracy:		91.52 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.006870
  validation loss:		0.604074
  validation accuracy:		91.96 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.007113
  validation loss:		0.599941
  validation accuracy:		91.96 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.007344
  validation loss:		0.600188
  validation accuracy:		91.96 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.006965
  validation loss:		0.602402
  validation accuracy:		91.74 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.006765
  validation loss:		0.600116
  validation accuracy:		91.85 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.006772
  validation loss:		0.599174
  validation accuracy:		91.63 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.006970
  validation loss:		0.603389
  validation accuracy:		91.52 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.006763
  validation loss:		0.611386
  validation accuracy:		91.74 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.006940
  validation loss:		0.606990
  validation accuracy:		91.63 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.007029
  validation loss:		0.606078
  validation accuracy:		91.63 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.006736
  validation loss:		0.595453
  validation accuracy:		91.63 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.006826
  validation loss:		0.613345
  validation accuracy:		91.74 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.006659
  validation loss:		0.610263
  validation accuracy:		91.63 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.006748
  validation loss:		0.611284
  validation accuracy:		91.74 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.006918
  validation loss:		0.606792
  validation accuracy:		91.74 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.006852
  validation loss:		0.607529
  validation accuracy:		91.52 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.007038
  validation loss:		0.606291
  validation accuracy:		91.52 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.006534
  validation loss:		0.611052
  validation accuracy:		91.74 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.006769
  validation loss:		0.606359
  validation accuracy:		91.85 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.006695
  validation loss:		0.606393
  validation accuracy:		91.63 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.006446
  validation loss:		0.608549
  validation accuracy:		91.96 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.006682
  validation loss:		0.605427
  validation accuracy:		91.63 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006609
  validation loss:		0.620580
  validation accuracy:		91.85 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.006747
  validation loss:		0.611800
  validation accuracy:		91.52 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006823
  validation loss:		0.619277
  validation accuracy:		91.85 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.006652
  validation loss:		0.604794
  validation accuracy:		91.96 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.006681
  validation loss:		0.604372
  validation accuracy:		91.96 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.006779
  validation loss:		0.600354
  validation accuracy:		91.96 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.006453
  validation loss:		0.627669
  validation accuracy:		91.85 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006739
  validation loss:		0.610485
  validation accuracy:		91.74 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.006614
  validation loss:		0.614834
  validation accuracy:		91.52 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006661
  validation loss:		0.595774
  validation accuracy:		91.74 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.006453
  validation loss:		0.611937
  validation accuracy:		91.85 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.006325
  validation loss:		0.607159
  validation accuracy:		91.63 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006603
  validation loss:		0.615750
  validation accuracy:		91.74 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.609081
  validation accuracy:		91.74 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.006478
  validation loss:		0.617811
  validation accuracy:		91.63 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.006434
  validation loss:		0.610251
  validation accuracy:		91.85 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.006343
  validation loss:		0.613398
  validation accuracy:		91.74 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.006495
  validation loss:		0.615197
  validation accuracy:		91.74 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.006381
  validation loss:		0.616829
  validation accuracy:		91.63 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.006369
  validation loss:		0.620766
  validation accuracy:		91.63 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006412
  validation loss:		0.605062
  validation accuracy:		91.85 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.006549
  validation loss:		0.618597
  validation accuracy:		91.63 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006305
  validation loss:		0.622070
  validation accuracy:		91.74 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.006384
  validation loss:		0.615215
  validation accuracy:		91.52 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006237
  validation loss:		0.609067
  validation accuracy:		91.74 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006507
  validation loss:		0.613476
  validation accuracy:		91.63 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.006420
  validation loss:		0.619852
  validation accuracy:		91.74 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.006358
  validation loss:		0.621662
  validation accuracy:		91.85 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.006279
  validation loss:		0.619065
  validation accuracy:		91.63 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.006260
  validation loss:		0.617440
  validation accuracy:		91.74 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006260
  validation loss:		0.615691
  validation accuracy:		91.74 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.006212
  validation loss:		0.609511
  validation accuracy:		91.96 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.006435
  validation loss:		0.616878
  validation accuracy:		91.63 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006290
  validation loss:		0.629725
  validation accuracy:		91.63 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.006130
  validation loss:		0.611766
  validation accuracy:		91.85 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.006363
  validation loss:		0.626904
  validation accuracy:		91.63 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.006103
  validation loss:		0.616846
  validation accuracy:		91.63 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.006095
  validation loss:		0.619521
  validation accuracy:		91.85 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.006061
  validation loss:		0.623665
  validation accuracy:		91.52 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006131
  validation loss:		0.616157
  validation accuracy:		91.85 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.006206
  validation loss:		0.616750
  validation accuracy:		91.74 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.626785
  validation accuracy:		91.74 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.006329
  validation loss:		0.615147
  validation accuracy:		91.85 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.006208
  validation loss:		0.611153
  validation accuracy:		91.63 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006205
  validation loss:		0.624345
  validation accuracy:		91.74 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.006062
  validation loss:		0.618548
  validation accuracy:		91.63 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.006236
  validation loss:		0.619139
  validation accuracy:		91.63 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.006009
  validation loss:		0.614751
  validation accuracy:		91.85 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.006233
  validation loss:		0.620280
  validation accuracy:		91.74 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.005954
  validation loss:		0.614489
  validation accuracy:		91.85 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.006050
  validation loss:		0.629559
  validation accuracy:		91.63 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006082
  validation loss:		0.615080
  validation accuracy:		91.96 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.006079
  validation loss:		0.634531
  validation accuracy:		91.63 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.005988
  validation loss:		0.613308
  validation accuracy:		91.74 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.006293
  validation loss:		0.630258
  validation accuracy:		91.52 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.006067
  validation loss:		0.626726
  validation accuracy:		91.74 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.005875
  validation loss:		0.620665
  validation accuracy:		91.52 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.005925
  validation loss:		0.620140
  validation accuracy:		91.85 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.006077
  validation loss:		0.617148
  validation accuracy:		92.07 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.005983
  validation loss:		0.616726
  validation accuracy:		91.85 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.005928
  validation loss:		0.624463
  validation accuracy:		91.63 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.006066
  validation loss:		0.630800
  validation accuracy:		91.85 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006015
  validation loss:		0.633801
  validation accuracy:		91.63 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.006046
  validation loss:		0.622748
  validation accuracy:		91.85 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.005667
  validation loss:		0.634957
  validation accuracy:		91.41 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.005699
  validation loss:		0.617013
  validation accuracy:		91.96 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.006088
  validation loss:		0.631288
  validation accuracy:		91.63 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.006036
  validation loss:		0.617078
  validation accuracy:		91.52 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.005985
  validation loss:		0.627325
  validation accuracy:		91.74 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.005957
  validation loss:		0.626713
  validation accuracy:		91.74 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.005903
  validation loss:		0.622960
  validation accuracy:		91.85 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.005702
  validation loss:		0.624700
  validation accuracy:		91.74 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.005598
  validation loss:		0.626473
  validation accuracy:		91.52 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.005675
  validation loss:		0.619787
  validation accuracy:		91.85 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.005836
  validation loss:		0.623040
  validation accuracy:		91.96 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.005638
  validation loss:		0.632681
  validation accuracy:		91.63 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.005624
  validation loss:		0.626698
  validation accuracy:		91.85 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.005836
  validation loss:		0.621958
  validation accuracy:		91.96 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.005657
  validation loss:		0.613223
  validation accuracy:		91.63 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.005942
  validation loss:		0.638573
  validation accuracy:		91.74 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.005946
  validation loss:		0.633540
  validation accuracy:		91.74 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.005736
  validation loss:		0.632006
  validation accuracy:		91.63 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.005585
  validation loss:		0.619073
  validation accuracy:		91.74 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.005627
  validation loss:		0.626071
  validation accuracy:		91.63 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.005745
  validation loss:		0.628116
  validation accuracy:		91.74 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.005738
  validation loss:		0.644295
  validation accuracy:		91.63 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.005759
  validation loss:		0.626193
  validation accuracy:		91.52 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.005777
  validation loss:		0.625482
  validation accuracy:		91.96 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.005764
  validation loss:		0.629031
  validation accuracy:		91.63 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.005637
  validation loss:		0.639686
  validation accuracy:		91.63 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.005660
  validation loss:		0.637484
  validation accuracy:		91.74 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.005439
  validation loss:		0.623906
  validation accuracy:		91.74 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.005639
  validation loss:		0.634183
  validation accuracy:		91.63 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.005448
  validation loss:		0.633190
  validation accuracy:		91.63 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.005430
  validation loss:		0.635978
  validation accuracy:		91.63 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.005686
  validation loss:		0.630292
  validation accuracy:		91.74 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.005522
  validation loss:		0.637998
  validation accuracy:		91.41 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.005450
  validation loss:		0.631629
  validation accuracy:		91.85 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.005571
  validation loss:		0.620881
  validation accuracy:		91.85 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005578
  validation loss:		0.633225
  validation accuracy:		91.63 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005473
  validation loss:		0.633623
  validation accuracy:		91.74 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005488
  validation loss:		0.627729
  validation accuracy:		91.85 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005537
  validation loss:		0.634814
  validation accuracy:		91.52 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005541
  validation loss:		0.634419
  validation accuracy:		91.63 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.005349
  validation loss:		0.631581
  validation accuracy:		91.85 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005306
  validation loss:		0.627964
  validation accuracy:		91.74 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.005390
  validation loss:		0.643995
  validation accuracy:		91.41 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.005454
  validation loss:		0.629445
  validation accuracy:		91.74 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005379
  validation loss:		0.640512
  validation accuracy:		91.52 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.005358
  validation loss:		0.628159
  validation accuracy:		91.63 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005539
  validation loss:		0.634917
  validation accuracy:		91.63 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005242
  validation loss:		0.651825
  validation accuracy:		91.63 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005405
  validation loss:		0.634734
  validation accuracy:		91.63 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.005383
  validation loss:		0.639551
  validation accuracy:		91.63 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005296
  validation loss:		0.645732
  validation accuracy:		91.63 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.005537
  validation loss:		0.636377
  validation accuracy:		91.74 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005395
  validation loss:		0.640548
  validation accuracy:		91.74 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.005367
  validation loss:		0.647723
  validation accuracy:		91.52 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.005394
  validation loss:		0.641219
  validation accuracy:		91.63 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005500
  validation loss:		0.635698
  validation accuracy:		91.63 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.005287
  validation loss:		0.639458
  validation accuracy:		91.63 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005290
  validation loss:		0.645128
  validation accuracy:		91.41 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.005295
  validation loss:		0.636386
  validation accuracy:		91.74 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.005255
  validation loss:		0.633227
  validation accuracy:		91.74 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005247
  validation loss:		0.648490
  validation accuracy:		91.52 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.005434
  validation loss:		0.637586
  validation accuracy:		91.63 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.005067
  validation loss:		0.640090
  validation accuracy:		91.63 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005100
  validation loss:		0.640611
  validation accuracy:		91.63 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005034
  validation loss:		0.640972
  validation accuracy:		91.85 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.005335
  validation loss:		0.623769
  validation accuracy:		91.85 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.005377
  validation loss:		0.648028
  validation accuracy:		91.63 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.005282
  validation loss:		0.635054
  validation accuracy:		91.63 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.005267
  validation loss:		0.649790
  validation accuracy:		91.74 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.005188
  validation loss:		0.647206
  validation accuracy:		91.63 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.005335
  validation loss:		0.643484
  validation accuracy:		91.63 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.005177
  validation loss:		0.641709
  validation accuracy:		91.74 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.005109
  validation loss:		0.652304
  validation accuracy:		91.63 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.005296
  validation loss:		0.651675
  validation accuracy:		91.52 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.005239
  validation loss:		0.644536
  validation accuracy:		91.52 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.005092
  validation loss:		0.631012
  validation accuracy:		91.74 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005281
  validation loss:		0.637064
  validation accuracy:		91.74 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.005085
  validation loss:		0.647028
  validation accuracy:		91.74 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.005111
  validation loss:		0.648063
  validation accuracy:		91.30 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005119
  validation loss:		0.647976
  validation accuracy:		91.74 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.005204
  validation loss:		0.644945
  validation accuracy:		91.52 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.005159
  validation loss:		0.644273
  validation accuracy:		91.74 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.005000
  validation loss:		0.641984
  validation accuracy:		91.63 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.005092
  validation loss:		0.639509
  validation accuracy:		91.85 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005063
  validation loss:		0.643163
  validation accuracy:		91.74 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005167
  validation loss:		0.645823
  validation accuracy:		91.63 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005007
  validation loss:		0.653497
  validation accuracy:		91.74 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.005155
  validation loss:		0.645069
  validation accuracy:		91.52 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005004
  validation loss:		0.645867
  validation accuracy:		91.63 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.004958
  validation loss:		0.646242
  validation accuracy:		91.63 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.004915
  validation loss:		0.652053
  validation accuracy:		91.74 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.004994
  validation loss:		0.647320
  validation accuracy:		91.63 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005052
  validation loss:		0.653092
  validation accuracy:		91.63 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005111
  validation loss:		0.642716
  validation accuracy:		91.63 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.005067
  validation loss:		0.645399
  validation accuracy:		91.52 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.004809
  validation loss:		0.651327
  validation accuracy:		91.63 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.005068
  validation loss:		0.652196
  validation accuracy:		91.63 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005016
  validation loss:		0.644742
  validation accuracy:		91.74 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005146
  validation loss:		0.642558
  validation accuracy:		91.85 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.004959
  validation loss:		0.649816
  validation accuracy:		91.63 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.004871
  validation loss:		0.651351
  validation accuracy:		91.63 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.004990
  validation loss:		0.655015
  validation accuracy:		91.63 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.004898
  validation loss:		0.650718
  validation accuracy:		91.63 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.653376
  validation accuracy:		91.52 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.005012
  validation loss:		0.648531
  validation accuracy:		91.85 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.004986
  validation loss:		0.639359
  validation accuracy:		91.74 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.650743
  validation accuracy:		91.63 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.004900
  validation loss:		0.644300
  validation accuracy:		91.74 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.004646
  validation loss:		0.651358
  validation accuracy:		91.52 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.004770
  validation loss:		0.650896
  validation accuracy:		91.63 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.004988
  validation loss:		0.650370
  validation accuracy:		91.74 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.004898
  validation loss:		0.651094
  validation accuracy:		91.85 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.004948
  validation loss:		0.645814
  validation accuracy:		91.74 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.004905
  validation loss:		0.661402
  validation accuracy:		91.74 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.004874
  validation loss:		0.653604
  validation accuracy:		91.63 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.004901
  validation loss:		0.642891
  validation accuracy:		91.74 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.004750
  validation loss:		0.666561
  validation accuracy:		91.52 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.004894
  validation loss:		0.649245
  validation accuracy:		91.85 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.652276
  validation accuracy:		91.52 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.004788
  validation loss:		0.660720
  validation accuracy:		91.63 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.651163
  validation accuracy:		91.52 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.004702
  validation loss:		0.656915
  validation accuracy:		91.63 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.004784
  validation loss:		0.652797
  validation accuracy:		91.63 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.004747
  validation loss:		0.662129
  validation accuracy:		91.52 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.004826
  validation loss:		0.653743
  validation accuracy:		91.52 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.004696
  validation loss:		0.653791
  validation accuracy:		91.74 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.004669
  validation loss:		0.652865
  validation accuracy:		91.63 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.004662
  validation loss:		0.659991
  validation accuracy:		91.52 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.004799
  validation loss:		0.659672
  validation accuracy:		91.63 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.004616
  validation loss:		0.652786
  validation accuracy:		91.74 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.004737
  validation loss:		0.658748
  validation accuracy:		91.63 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.657085
  validation accuracy:		91.63 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.004741
  validation loss:		0.652630
  validation accuracy:		91.74 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.004678
  validation loss:		0.653441
  validation accuracy:		91.74 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.004542
  validation loss:		0.650473
  validation accuracy:		91.74 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.004675
  validation loss:		0.653940
  validation accuracy:		91.74 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.004609
  validation loss:		0.658872
  validation accuracy:		91.63 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.004695
  validation loss:		0.660779
  validation accuracy:		91.52 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.004581
  validation loss:		0.663453
  validation accuracy:		91.52 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.004667
  validation loss:		0.649394
  validation accuracy:		91.74 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004731
  validation loss:		0.656432
  validation accuracy:		91.63 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.004607
  validation loss:		0.659672
  validation accuracy:		91.63 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.004632
  validation loss:		0.653006
  validation accuracy:		91.74 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.004613
  validation loss:		0.654677
  validation accuracy:		91.74 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.004438
  validation loss:		0.663723
  validation accuracy:		91.63 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004401
  validation loss:		0.669468
  validation accuracy:		91.30 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.004634
  validation loss:		0.658781
  validation accuracy:		91.74 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.004561
  validation loss:		0.659894
  validation accuracy:		91.63 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004543
  validation loss:		0.655628
  validation accuracy:		91.85 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004388
  validation loss:		0.664866
  validation accuracy:		91.52 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004512
  validation loss:		0.657807
  validation accuracy:		91.74 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004709
  validation loss:		0.655289
  validation accuracy:		91.63 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.662809
  validation accuracy:		91.52 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.004508
  validation loss:		0.658665
  validation accuracy:		91.74 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.662057
  validation accuracy:		91.52 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004544
  validation loss:		0.659772
  validation accuracy:		91.63 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.004385
  validation loss:		0.652639
  validation accuracy:		91.74 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004381
  validation loss:		0.659747
  validation accuracy:		91.63 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.004506
  validation loss:		0.665909
  validation accuracy:		91.52 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004438
  validation loss:		0.662642
  validation accuracy:		91.74 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.648572
  validation accuracy:		91.74 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.004555
  validation loss:		0.664701
  validation accuracy:		91.63 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.004460
  validation loss:		0.659801
  validation accuracy:		91.74 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004474
  validation loss:		0.661267
  validation accuracy:		91.63 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.651958
  validation accuracy:		91.74 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004394
  validation loss:		0.668664
  validation accuracy:		91.52 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004460
  validation loss:		0.661996
  validation accuracy:		91.63 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.004372
  validation loss:		0.663394
  validation accuracy:		91.63 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004373
  validation loss:		0.662925
  validation accuracy:		91.63 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004442
  validation loss:		0.663721
  validation accuracy:		91.52 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004484
  validation loss:		0.657736
  validation accuracy:		91.74 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004421
  validation loss:		0.666705
  validation accuracy:		91.52 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004532
  validation loss:		0.670841
  validation accuracy:		91.52 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004484
  validation loss:		0.657961
  validation accuracy:		91.74 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.667495
  validation accuracy:		91.52 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004451
  validation loss:		0.659301
  validation accuracy:		91.74 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.004406
  validation loss:		0.673500
  validation accuracy:		91.52 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.004365
  validation loss:		0.666764
  validation accuracy:		91.52 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004354
  validation loss:		0.659503
  validation accuracy:		91.74 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004391
  validation loss:		0.665769
  validation accuracy:		91.63 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004225
  validation loss:		0.666200
  validation accuracy:		91.52 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004331
  validation loss:		0.670217
  validation accuracy:		91.63 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004297
  validation loss:		0.661634
  validation accuracy:		91.74 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004309
  validation loss:		0.671542
  validation accuracy:		91.52 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004280
  validation loss:		0.675853
  validation accuracy:		91.52 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004408
  validation loss:		0.673424
  validation accuracy:		91.52 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004269
  validation loss:		0.660318
  validation accuracy:		91.74 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.669592
  validation accuracy:		91.52 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004321
  validation loss:		0.663044
  validation accuracy:		91.74 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004274
  validation loss:		0.668088
  validation accuracy:		91.74 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004282
  validation loss:		0.671564
  validation accuracy:		91.52 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.666714
  validation accuracy:		91.63 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004294
  validation loss:		0.668563
  validation accuracy:		91.74 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.004142
  validation loss:		0.663886
  validation accuracy:		91.74 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004158
  validation loss:		0.668384
  validation accuracy:		91.74 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.671499
  validation accuracy:		91.74 %
Epoch 1647 of 2000 took 0.037s
  training loss:		0.004178
  validation loss:		0.669681
  validation accuracy:		91.52 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004193
  validation loss:		0.672154
  validation accuracy:		91.63 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.004162
  validation loss:		0.673165
  validation accuracy:		91.52 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004045
  validation loss:		0.663040
  validation accuracy:		91.74 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.004273
  validation loss:		0.669875
  validation accuracy:		91.74 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004123
  validation loss:		0.671860
  validation accuracy:		91.74 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004099
  validation loss:		0.675888
  validation accuracy:		91.52 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.666097
  validation accuracy:		91.85 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004243
  validation loss:		0.680013
  validation accuracy:		91.52 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004129
  validation loss:		0.669869
  validation accuracy:		91.74 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004149
  validation loss:		0.674982
  validation accuracy:		91.52 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.004222
  validation loss:		0.667192
  validation accuracy:		91.74 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.004195
  validation loss:		0.672826
  validation accuracy:		91.52 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004036
  validation loss:		0.672540
  validation accuracy:		91.63 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004149
  validation loss:		0.669105
  validation accuracy:		91.74 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.003978
  validation loss:		0.676541
  validation accuracy:		91.52 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004109
  validation loss:		0.679869
  validation accuracy:		91.52 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004024
  validation loss:		0.675268
  validation accuracy:		91.52 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004089
  validation loss:		0.682080
  validation accuracy:		91.52 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004168
  validation loss:		0.668252
  validation accuracy:		91.74 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004031
  validation loss:		0.673174
  validation accuracy:		91.74 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004018
  validation loss:		0.669435
  validation accuracy:		91.74 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.674148
  validation accuracy:		91.41 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.003973
  validation loss:		0.670947
  validation accuracy:		91.74 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004098
  validation loss:		0.672110
  validation accuracy:		91.74 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.003894
  validation loss:		0.681598
  validation accuracy:		91.52 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004068
  validation loss:		0.666921
  validation accuracy:		91.74 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004181
  validation loss:		0.674482
  validation accuracy:		91.74 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.004035
  validation loss:		0.677481
  validation accuracy:		91.41 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.003994
  validation loss:		0.679168
  validation accuracy:		91.52 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.003967
  validation loss:		0.667127
  validation accuracy:		91.74 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.004012
  validation loss:		0.683798
  validation accuracy:		91.52 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.003927
  validation loss:		0.672291
  validation accuracy:		91.74 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004042
  validation loss:		0.674861
  validation accuracy:		91.74 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004044
  validation loss:		0.668786
  validation accuracy:		91.74 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.003971
  validation loss:		0.680283
  validation accuracy:		91.52 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.003863
  validation loss:		0.679812
  validation accuracy:		91.52 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004111
  validation loss:		0.672998
  validation accuracy:		91.74 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.003960
  validation loss:		0.675742
  validation accuracy:		91.74 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.004052
  validation loss:		0.672864
  validation accuracy:		91.74 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.003902
  validation loss:		0.686534
  validation accuracy:		91.52 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.003968
  validation loss:		0.669170
  validation accuracy:		91.74 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.003972
  validation loss:		0.676334
  validation accuracy:		91.74 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.003926
  validation loss:		0.676780
  validation accuracy:		91.52 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.003868
  validation loss:		0.682800
  validation accuracy:		91.63 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004081
  validation loss:		0.678281
  validation accuracy:		91.52 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.677665
  validation accuracy:		91.74 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.003984
  validation loss:		0.674393
  validation accuracy:		91.74 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.003896
  validation loss:		0.674287
  validation accuracy:		91.74 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.003768
  validation loss:		0.678421
  validation accuracy:		91.63 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.003990
  validation loss:		0.680820
  validation accuracy:		91.52 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.673523
  validation accuracy:		91.74 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.003825
  validation loss:		0.672021
  validation accuracy:		91.74 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.003935
  validation loss:		0.684599
  validation accuracy:		91.52 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.003728
  validation loss:		0.679688
  validation accuracy:		91.52 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.003880
  validation loss:		0.673266
  validation accuracy:		91.74 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.003889
  validation loss:		0.684038
  validation accuracy:		91.41 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.003751
  validation loss:		0.679126
  validation accuracy:		91.52 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.003863
  validation loss:		0.678447
  validation accuracy:		91.74 %
Epoch 1706 of 2000 took 0.036s
  training loss:		0.003850
  validation loss:		0.690768
  validation accuracy:		91.52 %
Epoch 1707 of 2000 took 0.037s
  training loss:		0.003878
  validation loss:		0.673376
  validation accuracy:		91.74 %
Epoch 1708 of 2000 took 0.036s
  training loss:		0.003826
  validation loss:		0.669991
  validation accuracy:		91.74 %
Epoch 1709 of 2000 took 0.036s
  training loss:		0.003882
  validation loss:		0.685291
  validation accuracy:		91.52 %
Epoch 1710 of 2000 took 0.036s
  training loss:		0.003765
  validation loss:		0.679153
  validation accuracy:		91.74 %
Epoch 1711 of 2000 took 0.036s
  training loss:		0.003769
  validation loss:		0.680191
  validation accuracy:		91.63 %
Epoch 1712 of 2000 took 0.036s
  training loss:		0.003918
  validation loss:		0.689010
  validation accuracy:		91.52 %
Epoch 1713 of 2000 took 0.037s
  training loss:		0.004008
  validation loss:		0.671834
  validation accuracy:		91.74 %
Epoch 1714 of 2000 took 0.036s
  training loss:		0.003765
  validation loss:		0.682672
  validation accuracy:		91.63 %
Epoch 1715 of 2000 took 0.036s
  training loss:		0.003741
  validation loss:		0.678969
  validation accuracy:		91.74 %
Epoch 1716 of 2000 took 0.036s
  training loss:		0.003796
  validation loss:		0.685661
  validation accuracy:		91.52 %
Epoch 1717 of 2000 took 0.036s
  training loss:		0.003858
  validation loss:		0.679490
  validation accuracy:		91.74 %
Epoch 1718 of 2000 took 0.036s
  training loss:		0.003731
  validation loss:		0.683639
  validation accuracy:		91.52 %
Epoch 1719 of 2000 took 0.036s
  training loss:		0.003895
  validation loss:		0.672123
  validation accuracy:		91.74 %
Epoch 1720 of 2000 took 0.036s
  training loss:		0.003827
  validation loss:		0.685886
  validation accuracy:		91.52 %
Epoch 1721 of 2000 took 0.037s
  training loss:		0.003803
  validation loss:		0.682426
  validation accuracy:		91.74 %
Epoch 1722 of 2000 took 0.036s
  training loss:		0.003860
  validation loss:		0.677781
  validation accuracy:		91.74 %
Epoch 1723 of 2000 took 0.036s
  training loss:		0.003655
  validation loss:		0.685933
  validation accuracy:		91.63 %
Epoch 1724 of 2000 took 0.036s
  training loss:		0.003754
  validation loss:		0.686668
  validation accuracy:		91.52 %
Epoch 1725 of 2000 took 0.036s
  training loss:		0.003791
  validation loss:		0.682098
  validation accuracy:		91.63 %
Epoch 1726 of 2000 took 0.036s
  training loss:		0.003667
  validation loss:		0.680996
  validation accuracy:		91.74 %
Epoch 1727 of 2000 took 0.036s
  training loss:		0.003735
  validation loss:		0.686303
  validation accuracy:		91.52 %
Epoch 1728 of 2000 took 0.036s
  training loss:		0.003759
  validation loss:		0.686077
  validation accuracy:		91.52 %
Epoch 1729 of 2000 took 0.036s
  training loss:		0.003499
  validation loss:		0.681003
  validation accuracy:		91.63 %
Epoch 1730 of 2000 took 0.037s
  training loss:		0.003740
  validation loss:		0.679055
  validation accuracy:		91.74 %
Epoch 1731 of 2000 took 0.036s
  training loss:		0.003812
  validation loss:		0.688633
  validation accuracy:		91.52 %
Epoch 1732 of 2000 took 0.036s
  training loss:		0.003623
  validation loss:		0.682154
  validation accuracy:		91.74 %
Epoch 1733 of 2000 took 0.036s
  training loss:		0.003838
  validation loss:		0.687565
  validation accuracy:		91.74 %
Epoch 1734 of 2000 took 0.036s
  training loss:		0.003765
  validation loss:		0.679277
  validation accuracy:		91.74 %
Epoch 1735 of 2000 took 0.036s
  training loss:		0.003748
  validation loss:		0.680668
  validation accuracy:		91.74 %
Epoch 1736 of 2000 took 0.036s
  training loss:		0.003651
  validation loss:		0.679152
  validation accuracy:		91.74 %
Epoch 1737 of 2000 took 0.036s
  training loss:		0.003684
  validation loss:		0.690756
  validation accuracy:		91.52 %
Epoch 1738 of 2000 took 0.036s
  training loss:		0.003695
  validation loss:		0.681434
  validation accuracy:		91.74 %
Epoch 1739 of 2000 took 0.036s
  training loss:		0.003724
  validation loss:		0.687083
  validation accuracy:		91.52 %
Epoch 1740 of 2000 took 0.036s
  training loss:		0.003752
  validation loss:		0.683929
  validation accuracy:		91.74 %
Epoch 1741 of 2000 took 0.036s
  training loss:		0.003687
  validation loss:		0.684204
  validation accuracy:		91.63 %
Epoch 1742 of 2000 took 0.036s
  training loss:		0.003668
  validation loss:		0.687225
  validation accuracy:		91.52 %
Epoch 1743 of 2000 took 0.036s
  training loss:		0.003671
  validation loss:		0.685217
  validation accuracy:		91.74 %
Epoch 1744 of 2000 took 0.036s
  training loss:		0.003676
  validation loss:		0.692505
  validation accuracy:		91.41 %
Epoch 1745 of 2000 took 0.036s
  training loss:		0.003737
  validation loss:		0.686599
  validation accuracy:		91.74 %
Epoch 1746 of 2000 took 0.036s
  training loss:		0.003574
  validation loss:		0.686912
  validation accuracy:		91.74 %
Epoch 1747 of 2000 took 0.036s
  training loss:		0.003649
  validation loss:		0.685045
  validation accuracy:		91.74 %
Epoch 1748 of 2000 took 0.036s
  training loss:		0.003624
  validation loss:		0.685020
  validation accuracy:		91.74 %
Epoch 1749 of 2000 took 0.036s
  training loss:		0.003633
  validation loss:		0.695395
  validation accuracy:		91.52 %
Epoch 1750 of 2000 took 0.036s
  training loss:		0.003599
  validation loss:		0.682780
  validation accuracy:		91.63 %
Epoch 1751 of 2000 took 0.036s
  training loss:		0.003632
  validation loss:		0.690820
  validation accuracy:		91.74 %
Epoch 1752 of 2000 took 0.036s
  training loss:		0.003553
  validation loss:		0.684736
  validation accuracy:		91.74 %
Epoch 1753 of 2000 took 0.036s
  training loss:		0.003563
  validation loss:		0.692147
  validation accuracy:		91.41 %
Epoch 1754 of 2000 took 0.036s
  training loss:		0.003627
  validation loss:		0.689340
  validation accuracy:		91.74 %
Epoch 1755 of 2000 took 0.036s
  training loss:		0.003545
  validation loss:		0.689328
  validation accuracy:		91.52 %
Epoch 1756 of 2000 took 0.036s
  training loss:		0.003552
  validation loss:		0.682610
  validation accuracy:		91.74 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.003573
  validation loss:		0.689832
  validation accuracy:		91.74 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.003525
  validation loss:		0.682283
  validation accuracy:		91.74 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.003575
  validation loss:		0.697221
  validation accuracy:		91.41 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.003464
  validation loss:		0.680090
  validation accuracy:		91.74 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.686903
  validation accuracy:		91.74 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.003409
  validation loss:		0.684626
  validation accuracy:		91.74 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.003471
  validation loss:		0.691307
  validation accuracy:		91.41 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003464
  validation loss:		0.690845
  validation accuracy:		91.52 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003469
  validation loss:		0.691128
  validation accuracy:		91.74 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.003396
  validation loss:		0.697062
  validation accuracy:		91.52 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003514
  validation loss:		0.689838
  validation accuracy:		91.52 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.003676
  validation loss:		0.688294
  validation accuracy:		91.63 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.003553
  validation loss:		0.690708
  validation accuracy:		91.52 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.003492
  validation loss:		0.687979
  validation accuracy:		91.74 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003376
  validation loss:		0.690528
  validation accuracy:		91.63 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.003470
  validation loss:		0.697541
  validation accuracy:		91.52 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003527
  validation loss:		0.694492
  validation accuracy:		91.41 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.003511
  validation loss:		0.689253
  validation accuracy:		91.74 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.003463
  validation loss:		0.693425
  validation accuracy:		91.52 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003545
  validation loss:		0.694510
  validation accuracy:		91.52 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.700183
  validation accuracy:		91.52 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003416
  validation loss:		0.686243
  validation accuracy:		91.74 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.003450
  validation loss:		0.690359
  validation accuracy:		91.74 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.003457
  validation loss:		0.691588
  validation accuracy:		91.63 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.003476
  validation loss:		0.692382
  validation accuracy:		91.52 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.003487
  validation loss:		0.689456
  validation accuracy:		91.74 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003573
  validation loss:		0.695632
  validation accuracy:		91.52 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.003359
  validation loss:		0.693575
  validation accuracy:		91.74 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003526
  validation loss:		0.696481
  validation accuracy:		91.52 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.003510
  validation loss:		0.695646
  validation accuracy:		91.74 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003403
  validation loss:		0.690885
  validation accuracy:		91.63 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003496
  validation loss:		0.700977
  validation accuracy:		91.41 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003404
  validation loss:		0.690569
  validation accuracy:		91.74 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003408
  validation loss:		0.696587
  validation accuracy:		91.63 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003376
  validation loss:		0.697083
  validation accuracy:		91.52 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003356
  validation loss:		0.697960
  validation accuracy:		91.63 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003302
  validation loss:		0.691398
  validation accuracy:		91.74 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003543
  validation loss:		0.687370
  validation accuracy:		91.85 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003346
  validation loss:		0.692267
  validation accuracy:		91.74 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003407
  validation loss:		0.686669
  validation accuracy:		91.74 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.003499
  validation loss:		0.699473
  validation accuracy:		91.52 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003465
  validation loss:		0.692754
  validation accuracy:		91.63 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003308
  validation loss:		0.698810
  validation accuracy:		91.63 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003436
  validation loss:		0.697333
  validation accuracy:		91.52 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003370
  validation loss:		0.700967
  validation accuracy:		91.41 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.003352
  validation loss:		0.703414
  validation accuracy:		91.52 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003405
  validation loss:		0.703901
  validation accuracy:		91.52 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003340
  validation loss:		0.686751
  validation accuracy:		91.85 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003384
  validation loss:		0.698661
  validation accuracy:		91.74 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003439
  validation loss:		0.703939
  validation accuracy:		91.52 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.694661
  validation accuracy:		91.74 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003446
  validation loss:		0.690309
  validation accuracy:		91.74 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003257
  validation loss:		0.708082
  validation accuracy:		91.41 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003355
  validation loss:		0.700595
  validation accuracy:		91.74 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003308
  validation loss:		0.693066
  validation accuracy:		91.85 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003216
  validation loss:		0.696735
  validation accuracy:		91.63 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003258
  validation loss:		0.707890
  validation accuracy:		91.41 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003320
  validation loss:		0.695115
  validation accuracy:		91.74 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003197
  validation loss:		0.712608
  validation accuracy:		91.41 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003292
  validation loss:		0.695479
  validation accuracy:		91.85 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003289
  validation loss:		0.697678
  validation accuracy:		91.52 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003340
  validation loss:		0.702010
  validation accuracy:		91.63 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003189
  validation loss:		0.695293
  validation accuracy:		91.85 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003239
  validation loss:		0.699548
  validation accuracy:		91.63 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003268
  validation loss:		0.703167
  validation accuracy:		91.52 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003246
  validation loss:		0.700907
  validation accuracy:		91.63 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003356
  validation loss:		0.695539
  validation accuracy:		91.74 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003284
  validation loss:		0.696739
  validation accuracy:		91.74 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003321
  validation loss:		0.699913
  validation accuracy:		91.63 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003263
  validation loss:		0.698379
  validation accuracy:		91.63 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003195
  validation loss:		0.698487
  validation accuracy:		91.74 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003249
  validation loss:		0.707204
  validation accuracy:		91.63 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003312
  validation loss:		0.703992
  validation accuracy:		91.52 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003338
  validation loss:		0.699786
  validation accuracy:		91.63 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003221
  validation loss:		0.702067
  validation accuracy:		91.52 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003260
  validation loss:		0.707736
  validation accuracy:		91.52 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003242
  validation loss:		0.694706
  validation accuracy:		91.74 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003226
  validation loss:		0.708459
  validation accuracy:		91.41 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003242
  validation loss:		0.699273
  validation accuracy:		91.74 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003202
  validation loss:		0.707153
  validation accuracy:		91.52 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003168
  validation loss:		0.702090
  validation accuracy:		91.74 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003084
  validation loss:		0.697647
  validation accuracy:		91.74 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003246
  validation loss:		0.703771
  validation accuracy:		91.52 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003190
  validation loss:		0.704781
  validation accuracy:		91.63 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003176
  validation loss:		0.706733
  validation accuracy:		91.52 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003128
  validation loss:		0.711432
  validation accuracy:		91.52 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003214
  validation loss:		0.702870
  validation accuracy:		91.63 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003093
  validation loss:		0.702051
  validation accuracy:		91.74 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003087
  validation loss:		0.706253
  validation accuracy:		91.52 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003156
  validation loss:		0.707654
  validation accuracy:		91.63 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003110
  validation loss:		0.698130
  validation accuracy:		91.74 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003173
  validation loss:		0.710595
  validation accuracy:		91.52 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003162
  validation loss:		0.706476
  validation accuracy:		91.41 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003224
  validation loss:		0.705345
  validation accuracy:		91.74 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003204
  validation loss:		0.704975
  validation accuracy:		91.74 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003212
  validation loss:		0.703350
  validation accuracy:		91.63 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003067
  validation loss:		0.711725
  validation accuracy:		91.52 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003179
  validation loss:		0.706797
  validation accuracy:		91.63 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003135
  validation loss:		0.702440
  validation accuracy:		91.74 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003111
  validation loss:		0.702520
  validation accuracy:		91.63 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003079
  validation loss:		0.699508
  validation accuracy:		91.85 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003166
  validation loss:		0.707998
  validation accuracy:		91.52 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003108
  validation loss:		0.707993
  validation accuracy:		91.52 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003173
  validation loss:		0.704900
  validation accuracy:		91.63 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003104
  validation loss:		0.703503
  validation accuracy:		91.74 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003120
  validation loss:		0.710608
  validation accuracy:		91.63 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003060
  validation loss:		0.706172
  validation accuracy:		91.63 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003087
  validation loss:		0.716132
  validation accuracy:		91.30 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003308
  validation loss:		0.713931
  validation accuracy:		91.30 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003144
  validation loss:		0.699734
  validation accuracy:		91.85 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003075
  validation loss:		0.719373
  validation accuracy:		91.41 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003110
  validation loss:		0.702566
  validation accuracy:		91.74 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003154
  validation loss:		0.710100
  validation accuracy:		91.63 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003109
  validation loss:		0.703677
  validation accuracy:		91.63 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003019
  validation loss:		0.707957
  validation accuracy:		91.63 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003056
  validation loss:		0.708727
  validation accuracy:		91.52 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003044
  validation loss:		0.714931
  validation accuracy:		91.52 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.002990
  validation loss:		0.707233
  validation accuracy:		91.85 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003060
  validation loss:		0.710162
  validation accuracy:		91.63 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003061
  validation loss:		0.708471
  validation accuracy:		91.63 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003014
  validation loss:		0.708495
  validation accuracy:		91.63 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003088
  validation loss:		0.713728
  validation accuracy:		91.63 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003135
  validation loss:		0.705805
  validation accuracy:		91.63 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003076
  validation loss:		0.715816
  validation accuracy:		91.52 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003079
  validation loss:		0.712186
  validation accuracy:		91.52 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003076
  validation loss:		0.709066
  validation accuracy:		91.63 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.002983
  validation loss:		0.712251
  validation accuracy:		91.63 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003031
  validation loss:		0.709835
  validation accuracy:		91.63 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003011
  validation loss:		0.708411
  validation accuracy:		91.74 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.002913
  validation loss:		0.713496
  validation accuracy:		91.52 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.002951
  validation loss:		0.704373
  validation accuracy:		91.74 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003031
  validation loss:		0.711297
  validation accuracy:		91.63 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003098
  validation loss:		0.709437
  validation accuracy:		91.74 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.002970
  validation loss:		0.713207
  validation accuracy:		91.63 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003051
  validation loss:		0.714982
  validation accuracy:		91.41 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.002969
  validation loss:		0.712066
  validation accuracy:		91.63 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.002901
  validation loss:		0.714065
  validation accuracy:		91.63 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.002958
  validation loss:		0.709037
  validation accuracy:		91.63 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003006
  validation loss:		0.713847
  validation accuracy:		91.63 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.002929
  validation loss:		0.712402
  validation accuracy:		91.74 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.002925
  validation loss:		0.713174
  validation accuracy:		91.52 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.002935
  validation loss:		0.711937
  validation accuracy:		91.63 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.002893
  validation loss:		0.710776
  validation accuracy:		91.74 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003002
  validation loss:		0.718612
  validation accuracy:		91.41 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.002972
  validation loss:		0.714202
  validation accuracy:		91.63 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.002981
  validation loss:		0.712246
  validation accuracy:		91.74 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.002928
  validation loss:		0.721459
  validation accuracy:		91.41 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.002972
  validation loss:		0.709024
  validation accuracy:		91.85 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.002929
  validation loss:		0.711762
  validation accuracy:		91.74 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.002999
  validation loss:		0.712646
  validation accuracy:		91.74 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.002964
  validation loss:		0.711765
  validation accuracy:		91.74 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003031
  validation loss:		0.711053
  validation accuracy:		91.85 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.002946
  validation loss:		0.720696
  validation accuracy:		91.52 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.002925
  validation loss:		0.711671
  validation accuracy:		91.63 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.002943
  validation loss:		0.713009
  validation accuracy:		91.74 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.002867
  validation loss:		0.715371
  validation accuracy:		91.63 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.002840
  validation loss:		0.712069
  validation accuracy:		91.74 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.002891
  validation loss:		0.715180
  validation accuracy:		91.63 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.002873
  validation loss:		0.714387
  validation accuracy:		91.63 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.002885
  validation loss:		0.718019
  validation accuracy:		91.63 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.002872
  validation loss:		0.719232
  validation accuracy:		91.52 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.002925
  validation loss:		0.720616
  validation accuracy:		91.63 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.002783
  validation loss:		0.716569
  validation accuracy:		91.63 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.002831
  validation loss:		0.715161
  validation accuracy:		91.63 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.002790
  validation loss:		0.716029
  validation accuracy:		91.63 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.002863
  validation loss:		0.712313
  validation accuracy:		91.74 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.002846
  validation loss:		0.718449
  validation accuracy:		91.63 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.002907
  validation loss:		0.714204
  validation accuracy:		91.74 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.002894
  validation loss:		0.726245
  validation accuracy:		91.52 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.002922
  validation loss:		0.716566
  validation accuracy:		91.41 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.002869
  validation loss:		0.713893
  validation accuracy:		91.74 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.002874
  validation loss:		0.712665
  validation accuracy:		91.63 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.002832
  validation loss:		0.714465
  validation accuracy:		91.63 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.002885
  validation loss:		0.713678
  validation accuracy:		91.74 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.002859
  validation loss:		0.719923
  validation accuracy:		91.74 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.002817
  validation loss:		0.721261
  validation accuracy:		91.52 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.002885
  validation loss:		0.717954
  validation accuracy:		91.52 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.002824
  validation loss:		0.717081
  validation accuracy:		91.74 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.002869
  validation loss:		0.722009
  validation accuracy:		91.63 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.002901
  validation loss:		0.721145
  validation accuracy:		91.52 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.002803
  validation loss:		0.722505
  validation accuracy:		91.41 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.002809
  validation loss:		0.717926
  validation accuracy:		91.63 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.002775
  validation loss:		0.717650
  validation accuracy:		91.52 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.002821
  validation loss:		0.716849
  validation accuracy:		91.74 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.002901
  validation loss:		0.712406
  validation accuracy:		91.85 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.002910
  validation loss:		0.717763
  validation accuracy:		91.63 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.002855
  validation loss:		0.722252
  validation accuracy:		91.63 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.002870
  validation loss:		0.721573
  validation accuracy:		91.63 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.002791
  validation loss:		0.725013
  validation accuracy:		91.63 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.002787
  validation loss:		0.721401
  validation accuracy:		91.63 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.002869
  validation loss:		0.715404
  validation accuracy:		91.74 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.002824
  validation loss:		0.724921
  validation accuracy:		91.41 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.002775
  validation loss:		0.718718
  validation accuracy:		91.74 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.002748
  validation loss:		0.721123
  validation accuracy:		91.74 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.002740
  validation loss:		0.728627
  validation accuracy:		91.41 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.002795
  validation loss:		0.726607
  validation accuracy:		91.41 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.002767
  validation loss:		0.720849
  validation accuracy:		91.74 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.002705
  validation loss:		0.720710
  validation accuracy:		91.52 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.002678
  validation loss:		0.718828
  validation accuracy:		91.74 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.002815
  validation loss:		0.728453
  validation accuracy:		91.63 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.002737
  validation loss:		0.721920
  validation accuracy:		91.74 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.002734
  validation loss:		0.725624
  validation accuracy:		91.52 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.002798
  validation loss:		0.724581
  validation accuracy:		91.52 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.002666
  validation loss:		0.722086
  validation accuracy:		91.74 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.002692
  validation loss:		0.718582
  validation accuracy:		91.74 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.002764
  validation loss:		0.726279
  validation accuracy:		91.41 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.002665
  validation loss:		0.718337
  validation accuracy:		91.85 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.002760
  validation loss:		0.722261
  validation accuracy:		91.74 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.002706
  validation loss:		0.722064
  validation accuracy:		91.74 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.002660
  validation loss:		0.718932
  validation accuracy:		91.74 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.002737
  validation loss:		0.723936
  validation accuracy:		91.63 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.002662
  validation loss:		0.718727
  validation accuracy:		91.63 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.002747
  validation loss:		0.732205
  validation accuracy:		91.52 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.002771
  validation loss:		0.728656
  validation accuracy:		91.63 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.002744
  validation loss:		0.722484
  validation accuracy:		91.74 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.002705
  validation loss:		0.732539
  validation accuracy:		91.41 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.002710
  validation loss:		0.719574
  validation accuracy:		91.74 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.002688
  validation loss:		0.723076
  validation accuracy:		91.63 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.002702
  validation loss:		0.727746
  validation accuracy:		91.41 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.002678
  validation loss:		0.722478
  validation accuracy:		91.74 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.002689
  validation loss:		0.732111
  validation accuracy:		91.52 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.002659
  validation loss:		0.730751
  validation accuracy:		91.41 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.002708
  validation loss:		0.726350
  validation accuracy:		91.74 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.002720
  validation loss:		0.729671
  validation accuracy:		91.52 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.002606
  validation loss:		0.726371
  validation accuracy:		91.74 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.002696
  validation loss:		0.719623
  validation accuracy:		91.74 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.002693
  validation loss:		0.725276
  validation accuracy:		91.52 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.002658
  validation loss:		0.727989
  validation accuracy:		91.74 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.002635
  validation loss:		0.727899
  validation accuracy:		91.41 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.002647
  validation loss:		0.724631
  validation accuracy:		91.74 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.002629
  validation loss:		0.730491
  validation accuracy:		91.52 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.002677
  validation loss:		0.727155
  validation accuracy:		91.74 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.002677
  validation loss:		0.726541
  validation accuracy:		91.63 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.002654
  validation loss:		0.734322
  validation accuracy:		91.41 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.002657
  validation loss:		0.721146
  validation accuracy:		91.74 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.002581
  validation loss:		0.729041
  validation accuracy:		91.74 %
Epoch 1993 of 2000 took 0.036s
  training loss:		0.002686
  validation loss:		0.724148
  validation accuracy:		91.74 %
Epoch 1994 of 2000 took 0.036s
  training loss:		0.002616
  validation loss:		0.725898
  validation accuracy:		91.63 %
Epoch 1995 of 2000 took 0.036s
  training loss:		0.002673
  validation loss:		0.731293
  validation accuracy:		91.63 %
Epoch 1996 of 2000 took 0.036s
  training loss:		0.002516
  validation loss:		0.726571
  validation accuracy:		91.74 %
Epoch 1997 of 2000 took 0.036s
  training loss:		0.002608
  validation loss:		0.729970
  validation accuracy:		91.52 %
Epoch 1998 of 2000 took 0.036s
  training loss:		0.002686
  validation loss:		0.726536
  validation accuracy:		91.74 %
Epoch 1999 of 2000 took 0.036s
  training loss:		0.002566
  validation loss:		0.726647
  validation accuracy:		91.63 %
Epoch 2000 of 2000 took 0.036s
  training loss:		0.002662
  validation loss:		0.732025
  validation accuracy:		91.63 %
Final results:
  test loss:			1.666649
  test accuracy:		83.01 %
