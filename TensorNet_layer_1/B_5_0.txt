Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.054s
  training loss:		2.956215
  validation loss:		2.845690
  validation accuracy:		14.57 %
Epoch 2 of 2000 took 0.045s
  training loss:		2.796968
  validation loss:		2.622342
  validation accuracy:		13.15 %
Epoch 3 of 2000 took 0.041s
  training loss:		2.616612
  validation loss:		2.412864
  validation accuracy:		13.15 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.460528
  validation loss:		2.273931
  validation accuracy:		18.26 %
Epoch 5 of 2000 took 0.037s
  training loss:		2.354326
  validation loss:		2.221089
  validation accuracy:		33.48 %
Epoch 6 of 2000 took 0.050s
  training loss:		2.289514
  validation loss:		2.208548
  validation accuracy:		41.96 %
Epoch 7 of 2000 took 0.054s
  training loss:		2.255541
  validation loss:		2.189598
  validation accuracy:		40.87 %
Epoch 8 of 2000 took 0.045s
  training loss:		2.229893
  validation loss:		2.153155
  validation accuracy:		52.28 %
Epoch 9 of 2000 took 0.042s
  training loss:		2.210653
  validation loss:		2.135373
  validation accuracy:		49.02 %
Epoch 10 of 2000 took 0.041s
  training loss:		2.193223
  validation loss:		2.122424
  validation accuracy:		51.74 %
Epoch 11 of 2000 took 0.041s
  training loss:		2.174279
  validation loss:		2.098436
  validation accuracy:		50.22 %
Epoch 12 of 2000 took 0.041s
  training loss:		2.153463
  validation loss:		2.068621
  validation accuracy:		53.37 %
Epoch 13 of 2000 took 0.041s
  training loss:		2.129378
  validation loss:		2.044902
  validation accuracy:		55.33 %
Epoch 14 of 2000 took 0.042s
  training loss:		2.107624
  validation loss:		2.024519
  validation accuracy:		52.93 %
Epoch 15 of 2000 took 0.042s
  training loss:		2.081291
  validation loss:		1.986453
  validation accuracy:		52.61 %
Epoch 16 of 2000 took 0.041s
  training loss:		2.053406
  validation loss:		1.961159
  validation accuracy:		52.83 %
Epoch 17 of 2000 took 0.041s
  training loss:		2.022218
  validation loss:		1.929247
  validation accuracy:		52.17 %
Epoch 18 of 2000 took 0.041s
  training loss:		1.991113
  validation loss:		1.887883
  validation accuracy:		56.63 %
Epoch 19 of 2000 took 0.041s
  training loss:		1.953662
  validation loss:		1.855601
  validation accuracy:		53.91 %
Epoch 20 of 2000 took 0.041s
  training loss:		1.915080
  validation loss:		1.808636
  validation accuracy:		55.22 %
Epoch 21 of 2000 took 0.041s
  training loss:		1.871627
  validation loss:		1.766304
  validation accuracy:		55.98 %
Epoch 22 of 2000 took 0.041s
  training loss:		1.829327
  validation loss:		1.722394
  validation accuracy:		59.02 %
Epoch 23 of 2000 took 0.041s
  training loss:		1.780965
  validation loss:		1.665804
  validation accuracy:		57.61 %
Epoch 24 of 2000 took 0.041s
  training loss:		1.731841
  validation loss:		1.611248
  validation accuracy:		60.54 %
Epoch 25 of 2000 took 0.041s
  training loss:		1.684397
  validation loss:		1.573602
  validation accuracy:		59.78 %
Epoch 26 of 2000 took 0.041s
  training loss:		1.633179
  validation loss:		1.516564
  validation accuracy:		61.96 %
Epoch 27 of 2000 took 0.041s
  training loss:		1.587565
  validation loss:		1.470514
  validation accuracy:		65.11 %
Epoch 28 of 2000 took 0.041s
  training loss:		1.537584
  validation loss:		1.416130
  validation accuracy:		64.89 %
Epoch 29 of 2000 took 0.042s
  training loss:		1.484848
  validation loss:		1.371120
  validation accuracy:		64.35 %
Epoch 30 of 2000 took 0.042s
  training loss:		1.434721
  validation loss:		1.323619
  validation accuracy:		68.04 %
Epoch 31 of 2000 took 0.040s
  training loss:		1.388939
  validation loss:		1.273201
  validation accuracy:		69.35 %
Epoch 32 of 2000 took 0.037s
  training loss:		1.340670
  validation loss:		1.235963
  validation accuracy:		70.11 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.302958
  validation loss:		1.191127
  validation accuracy:		68.59 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.259333
  validation loss:		1.158223
  validation accuracy:		72.83 %
Epoch 35 of 2000 took 0.035s
  training loss:		1.220436
  validation loss:		1.109013
  validation accuracy:		73.04 %
Epoch 36 of 2000 took 0.035s
  training loss:		1.178443
  validation loss:		1.076721
  validation accuracy:		74.02 %
Epoch 37 of 2000 took 0.035s
  training loss:		1.137487
  validation loss:		1.035976
  validation accuracy:		73.91 %
Epoch 38 of 2000 took 0.035s
  training loss:		1.095567
  validation loss:		1.004036
  validation accuracy:		75.54 %
Epoch 39 of 2000 took 0.035s
  training loss:		1.067005
  validation loss:		0.972036
  validation accuracy:		76.09 %
Epoch 40 of 2000 took 0.035s
  training loss:		1.030088
  validation loss:		0.950027
  validation accuracy:		77.17 %
Epoch 41 of 2000 took 0.036s
  training loss:		1.001569
  validation loss:		0.907352
  validation accuracy:		78.59 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.976079
  validation loss:		0.883010
  validation accuracy:		77.17 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.947830
  validation loss:		0.854611
  validation accuracy:		79.67 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.917385
  validation loss:		0.833128
  validation accuracy:		79.57 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.885702
  validation loss:		0.810531
  validation accuracy:		80.65 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.855681
  validation loss:		0.783317
  validation accuracy:		80.98 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.833089
  validation loss:		0.760651
  validation accuracy:		80.65 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.816727
  validation loss:		0.742678
  validation accuracy:		81.74 %
Epoch 49 of 2000 took 0.036s
  training loss:		0.789394
  validation loss:		0.728505
  validation accuracy:		81.96 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.768299
  validation loss:		0.698358
  validation accuracy:		83.26 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.745141
  validation loss:		0.666114
  validation accuracy:		83.70 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.724199
  validation loss:		0.652229
  validation accuracy:		83.91 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.702021
  validation loss:		0.644883
  validation accuracy:		83.59 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.689491
  validation loss:		0.624006
  validation accuracy:		84.78 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.666006
  validation loss:		0.616216
  validation accuracy:		83.59 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.651474
  validation loss:		0.596772
  validation accuracy:		85.65 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.637065
  validation loss:		0.577324
  validation accuracy:		86.30 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.620190
  validation loss:		0.573247
  validation accuracy:		86.30 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.603489
  validation loss:		0.545157
  validation accuracy:		86.96 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.589927
  validation loss:		0.541265
  validation accuracy:		86.30 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.575113
  validation loss:		0.518838
  validation accuracy:		87.17 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.561214
  validation loss:		0.511247
  validation accuracy:		86.74 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.547189
  validation loss:		0.496660
  validation accuracy:		87.39 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.532836
  validation loss:		0.494269
  validation accuracy:		87.28 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.522570
  validation loss:		0.481878
  validation accuracy:		88.04 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.515496
  validation loss:		0.469555
  validation accuracy:		87.83 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.510013
  validation loss:		0.459573
  validation accuracy:		87.93 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.492497
  validation loss:		0.464124
  validation accuracy:		88.48 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.489802
  validation loss:		0.443346
  validation accuracy:		88.70 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.475832
  validation loss:		0.437083
  validation accuracy:		88.48 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.462065
  validation loss:		0.427549
  validation accuracy:		89.02 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.462935
  validation loss:		0.424390
  validation accuracy:		89.46 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.451054
  validation loss:		0.415154
  validation accuracy:		89.13 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.442911
  validation loss:		0.412935
  validation accuracy:		89.13 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.434983
  validation loss:		0.399736
  validation accuracy:		89.57 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.428254
  validation loss:		0.400270
  validation accuracy:		89.67 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.426337
  validation loss:		0.392339
  validation accuracy:		90.22 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.416319
  validation loss:		0.387079
  validation accuracy:		90.00 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.411912
  validation loss:		0.379523
  validation accuracy:		90.54 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.399782
  validation loss:		0.377017
  validation accuracy:		90.33 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.400134
  validation loss:		0.364737
  validation accuracy:		90.65 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.389346
  validation loss:		0.361107
  validation accuracy:		90.65 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.387278
  validation loss:		0.351606
  validation accuracy:		90.87 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.379891
  validation loss:		0.361076
  validation accuracy:		90.98 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.376675
  validation loss:		0.357140
  validation accuracy:		91.30 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.374299
  validation loss:		0.353133
  validation accuracy:		91.52 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.372277
  validation loss:		0.348931
  validation accuracy:		91.41 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.364660
  validation loss:		0.341055
  validation accuracy:		91.30 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.357237
  validation loss:		0.337137
  validation accuracy:		91.96 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.359305
  validation loss:		0.336666
  validation accuracy:		91.41 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.349234
  validation loss:		0.331897
  validation accuracy:		92.39 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.350940
  validation loss:		0.324671
  validation accuracy:		91.09 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.342533
  validation loss:		0.318237
  validation accuracy:		92.07 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.332836
  validation loss:		0.320795
  validation accuracy:		92.50 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.336044
  validation loss:		0.323213
  validation accuracy:		91.96 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.329604
  validation loss:		0.319532
  validation accuracy:		92.17 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.326398
  validation loss:		0.315474
  validation accuracy:		92.50 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.320756
  validation loss:		0.302555
  validation accuracy:		92.50 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.322026
  validation loss:		0.302614
  validation accuracy:		92.50 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.321697
  validation loss:		0.302709
  validation accuracy:		92.39 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.315621
  validation loss:		0.296449
  validation accuracy:		92.28 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.310501
  validation loss:		0.300216
  validation accuracy:		92.17 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.308922
  validation loss:		0.295808
  validation accuracy:		92.61 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.307082
  validation loss:		0.288557
  validation accuracy:		92.61 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.299331
  validation loss:		0.298961
  validation accuracy:		92.72 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.304659
  validation loss:		0.283504
  validation accuracy:		92.72 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.294510
  validation loss:		0.284890
  validation accuracy:		92.72 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.291680
  validation loss:		0.283284
  validation accuracy:		92.72 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.292662
  validation loss:		0.286348
  validation accuracy:		92.93 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.284452
  validation loss:		0.277198
  validation accuracy:		92.50 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.285580
  validation loss:		0.280836
  validation accuracy:		92.61 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.283819
  validation loss:		0.275143
  validation accuracy:		92.93 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.282699
  validation loss:		0.271276
  validation accuracy:		93.04 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.284300
  validation loss:		0.276273
  validation accuracy:		93.04 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.271726
  validation loss:		0.266226
  validation accuracy:		92.72 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.275675
  validation loss:		0.279910
  validation accuracy:		92.39 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.273792
  validation loss:		0.269766
  validation accuracy:		92.72 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.270237
  validation loss:		0.269112
  validation accuracy:		93.04 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.268540
  validation loss:		0.262529
  validation accuracy:		93.26 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.265838
  validation loss:		0.260876
  validation accuracy:		92.93 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.262335
  validation loss:		0.254663
  validation accuracy:		92.93 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.264372
  validation loss:		0.269518
  validation accuracy:		92.83 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.259104
  validation loss:		0.264405
  validation accuracy:		93.26 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.254643
  validation loss:		0.254913
  validation accuracy:		93.37 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.253276
  validation loss:		0.267439
  validation accuracy:		93.04 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.254123
  validation loss:		0.257024
  validation accuracy:		93.04 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.250920
  validation loss:		0.261808
  validation accuracy:		92.50 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.252286
  validation loss:		0.250481
  validation accuracy:		93.26 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.249603
  validation loss:		0.252014
  validation accuracy:		93.48 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.250322
  validation loss:		0.250260
  validation accuracy:		93.48 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.247729
  validation loss:		0.258565
  validation accuracy:		93.15 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.241965
  validation loss:		0.251944
  validation accuracy:		93.26 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.240209
  validation loss:		0.257156
  validation accuracy:		93.37 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.235242
  validation loss:		0.249821
  validation accuracy:		93.15 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.238062
  validation loss:		0.247550
  validation accuracy:		93.37 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.240655
  validation loss:		0.242894
  validation accuracy:		93.26 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.235357
  validation loss:		0.237268
  validation accuracy:		93.48 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.234393
  validation loss:		0.242737
  validation accuracy:		93.80 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.238088
  validation loss:		0.236323
  validation accuracy:		93.26 %
Epoch 140 of 2000 took 0.038s
  training loss:		0.231520
  validation loss:		0.246778
  validation accuracy:		93.15 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.229398
  validation loss:		0.245260
  validation accuracy:		93.70 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.222870
  validation loss:		0.242531
  validation accuracy:		93.37 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.224102
  validation loss:		0.245711
  validation accuracy:		93.26 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.221626
  validation loss:		0.242107
  validation accuracy:		92.83 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.223524
  validation loss:		0.242567
  validation accuracy:		93.37 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.220437
  validation loss:		0.233393
  validation accuracy:		93.70 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.218160
  validation loss:		0.236278
  validation accuracy:		93.48 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.218314
  validation loss:		0.238286
  validation accuracy:		93.59 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.219323
  validation loss:		0.236476
  validation accuracy:		93.59 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.220417
  validation loss:		0.233284
  validation accuracy:		93.80 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.222496
  validation loss:		0.236691
  validation accuracy:		93.80 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.214239
  validation loss:		0.226233
  validation accuracy:		93.91 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.215061
  validation loss:		0.232262
  validation accuracy:		93.70 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.210573
  validation loss:		0.232888
  validation accuracy:		93.59 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.211332
  validation loss:		0.230710
  validation accuracy:		93.48 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.206853
  validation loss:		0.230589
  validation accuracy:		93.70 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.205985
  validation loss:		0.232736
  validation accuracy:		93.37 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.206042
  validation loss:		0.231735
  validation accuracy:		93.59 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.203455
  validation loss:		0.230240
  validation accuracy:		93.70 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.208351
  validation loss:		0.228637
  validation accuracy:		93.80 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.203618
  validation loss:		0.229322
  validation accuracy:		93.70 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.202122
  validation loss:		0.223547
  validation accuracy:		93.80 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.200717
  validation loss:		0.233472
  validation accuracy:		93.26 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.202126
  validation loss:		0.220232
  validation accuracy:		93.70 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.201055
  validation loss:		0.226416
  validation accuracy:		93.59 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.196978
  validation loss:		0.224769
  validation accuracy:		93.80 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.196231
  validation loss:		0.221541
  validation accuracy:		93.80 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.197225
  validation loss:		0.225833
  validation accuracy:		93.70 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.192100
  validation loss:		0.224355
  validation accuracy:		93.48 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.195347
  validation loss:		0.222113
  validation accuracy:		93.91 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.198127
  validation loss:		0.225409
  validation accuracy:		93.70 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.189854
  validation loss:		0.220006
  validation accuracy:		93.80 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.189457
  validation loss:		0.222943
  validation accuracy:		93.59 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.190213
  validation loss:		0.218527
  validation accuracy:		94.02 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.193321
  validation loss:		0.224240
  validation accuracy:		93.59 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.188441
  validation loss:		0.219985
  validation accuracy:		93.80 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.186513
  validation loss:		0.231316
  validation accuracy:		93.37 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.189445
  validation loss:		0.217858
  validation accuracy:		93.91 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.182412
  validation loss:		0.229950
  validation accuracy:		93.48 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.187710
  validation loss:		0.216823
  validation accuracy:		93.80 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.187552
  validation loss:		0.221714
  validation accuracy:		93.59 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.177762
  validation loss:		0.217870
  validation accuracy:		93.59 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.183193
  validation loss:		0.220770
  validation accuracy:		93.48 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.184749
  validation loss:		0.219124
  validation accuracy:		93.37 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.181004
  validation loss:		0.214042
  validation accuracy:		93.91 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.179696
  validation loss:		0.215446
  validation accuracy:		93.80 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.180670
  validation loss:		0.223893
  validation accuracy:		93.37 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.179512
  validation loss:		0.213419
  validation accuracy:		94.13 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.180501
  validation loss:		0.218468
  validation accuracy:		93.37 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.171619
  validation loss:		0.212688
  validation accuracy:		93.37 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.175208
  validation loss:		0.216040
  validation accuracy:		93.48 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.178486
  validation loss:		0.211048
  validation accuracy:		93.70 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.176247
  validation loss:		0.209255
  validation accuracy:		94.02 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.173359
  validation loss:		0.211770
  validation accuracy:		93.80 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.168821
  validation loss:		0.219206
  validation accuracy:		93.70 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.174345
  validation loss:		0.213756
  validation accuracy:		93.70 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.172102
  validation loss:		0.219387
  validation accuracy:		93.70 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.171269
  validation loss:		0.209553
  validation accuracy:		93.70 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.167932
  validation loss:		0.213670
  validation accuracy:		93.70 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.170469
  validation loss:		0.228785
  validation accuracy:		93.48 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.169929
  validation loss:		0.211692
  validation accuracy:		93.48 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.169758
  validation loss:		0.213468
  validation accuracy:		93.59 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.165966
  validation loss:		0.217982
  validation accuracy:		93.80 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.162469
  validation loss:		0.209267
  validation accuracy:		93.48 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.165938
  validation loss:		0.210969
  validation accuracy:		93.59 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.162735
  validation loss:		0.212322
  validation accuracy:		93.26 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.164006
  validation loss:		0.211140
  validation accuracy:		93.91 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.160701
  validation loss:		0.220668
  validation accuracy:		93.37 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.163038
  validation loss:		0.212638
  validation accuracy:		93.59 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.165073
  validation loss:		0.215649
  validation accuracy:		93.70 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.162193
  validation loss:		0.210367
  validation accuracy:		93.80 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.164106
  validation loss:		0.205878
  validation accuracy:		94.24 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.157291
  validation loss:		0.210756
  validation accuracy:		93.59 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.162067
  validation loss:		0.211745
  validation accuracy:		93.70 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.159912
  validation loss:		0.212342
  validation accuracy:		93.80 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.154644
  validation loss:		0.214378
  validation accuracy:		93.80 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.157092
  validation loss:		0.210234
  validation accuracy:		93.59 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.158437
  validation loss:		0.209918
  validation accuracy:		93.80 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.153141
  validation loss:		0.209345
  validation accuracy:		93.59 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.151886
  validation loss:		0.206984
  validation accuracy:		93.59 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.153582
  validation loss:		0.221130
  validation accuracy:		93.59 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.153151
  validation loss:		0.210146
  validation accuracy:		93.91 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.152777
  validation loss:		0.208687
  validation accuracy:		93.70 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.153833
  validation loss:		0.208443
  validation accuracy:		93.70 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.152712
  validation loss:		0.216768
  validation accuracy:		93.59 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.154165
  validation loss:		0.213594
  validation accuracy:		94.02 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.151381
  validation loss:		0.210383
  validation accuracy:		93.70 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.155631
  validation loss:		0.215374
  validation accuracy:		93.80 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.151622
  validation loss:		0.209489
  validation accuracy:		93.70 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.150963
  validation loss:		0.207164
  validation accuracy:		93.80 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.147761
  validation loss:		0.213124
  validation accuracy:		93.48 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.146676
  validation loss:		0.211040
  validation accuracy:		94.02 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.149353
  validation loss:		0.208828
  validation accuracy:		93.91 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.146276
  validation loss:		0.213037
  validation accuracy:		93.80 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.148329
  validation loss:		0.210206
  validation accuracy:		93.70 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.146580
  validation loss:		0.207729
  validation accuracy:		93.91 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.146109
  validation loss:		0.209110
  validation accuracy:		93.59 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.145265
  validation loss:		0.206229
  validation accuracy:		93.91 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.146064
  validation loss:		0.205964
  validation accuracy:		93.59 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.146752
  validation loss:		0.202320
  validation accuracy:		93.91 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.145417
  validation loss:		0.208928
  validation accuracy:		93.91 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.138499
  validation loss:		0.214764
  validation accuracy:		93.48 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.143658
  validation loss:		0.211033
  validation accuracy:		93.70 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.141943
  validation loss:		0.210059
  validation accuracy:		93.91 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.141094
  validation loss:		0.209642
  validation accuracy:		93.70 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.140568
  validation loss:		0.208669
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.143090
  validation loss:		0.203720
  validation accuracy:		93.80 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.142174
  validation loss:		0.207681
  validation accuracy:		93.59 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.139340
  validation loss:		0.206693
  validation accuracy:		93.80 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.135801
  validation loss:		0.210754
  validation accuracy:		93.70 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.137878
  validation loss:		0.207357
  validation accuracy:		93.70 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.137718
  validation loss:		0.211947
  validation accuracy:		93.37 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.140351
  validation loss:		0.211627
  validation accuracy:		93.59 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.138899
  validation loss:		0.209770
  validation accuracy:		93.80 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.139234
  validation loss:		0.205025
  validation accuracy:		93.91 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.132624
  validation loss:		0.210912
  validation accuracy:		93.80 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.136006
  validation loss:		0.212432
  validation accuracy:		93.48 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.136820
  validation loss:		0.204713
  validation accuracy:		93.70 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.134959
  validation loss:		0.210540
  validation accuracy:		93.70 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.136428
  validation loss:		0.206820
  validation accuracy:		93.70 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.135331
  validation loss:		0.204246
  validation accuracy:		93.91 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.134984
  validation loss:		0.208455
  validation accuracy:		93.59 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.133100
  validation loss:		0.199095
  validation accuracy:		93.80 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.134525
  validation loss:		0.207139
  validation accuracy:		93.70 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.132305
  validation loss:		0.204204
  validation accuracy:		93.70 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.133859
  validation loss:		0.208578
  validation accuracy:		93.48 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.133434
  validation loss:		0.204070
  validation accuracy:		93.80 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.132378
  validation loss:		0.208073
  validation accuracy:		93.70 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.130368
  validation loss:		0.207139
  validation accuracy:		93.48 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.129099
  validation loss:		0.205082
  validation accuracy:		93.80 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.132409
  validation loss:		0.211192
  validation accuracy:		93.26 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.129032
  validation loss:		0.200938
  validation accuracy:		93.91 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.131127
  validation loss:		0.213903
  validation accuracy:		93.70 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.131392
  validation loss:		0.208306
  validation accuracy:		93.70 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.130778
  validation loss:		0.205595
  validation accuracy:		93.70 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.127977
  validation loss:		0.209480
  validation accuracy:		93.37 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.127272
  validation loss:		0.203513
  validation accuracy:		93.70 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.126856
  validation loss:		0.207705
  validation accuracy:		93.26 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.127793
  validation loss:		0.215957
  validation accuracy:		93.59 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.125380
  validation loss:		0.210188
  validation accuracy:		93.48 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.124040
  validation loss:		0.205261
  validation accuracy:		93.80 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.121063
  validation loss:		0.204114
  validation accuracy:		93.59 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.125384
  validation loss:		0.212061
  validation accuracy:		93.26 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.125680
  validation loss:		0.205995
  validation accuracy:		93.91 %
Epoch 285 of 2000 took 0.036s
  training loss:		0.127909
  validation loss:		0.207969
  validation accuracy:		93.80 %
Epoch 286 of 2000 took 0.036s
  training loss:		0.124854
  validation loss:		0.205031
  validation accuracy:		93.80 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.124259
  validation loss:		0.208832
  validation accuracy:		93.59 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.121752
  validation loss:		0.202557
  validation accuracy:		93.59 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.121625
  validation loss:		0.205478
  validation accuracy:		93.91 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.122223
  validation loss:		0.206652
  validation accuracy:		93.70 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.120894
  validation loss:		0.209933
  validation accuracy:		93.91 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.123301
  validation loss:		0.207532
  validation accuracy:		93.70 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.120430
  validation loss:		0.209756
  validation accuracy:		93.80 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.122937
  validation loss:		0.209394
  validation accuracy:		93.70 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.122329
  validation loss:		0.201925
  validation accuracy:		93.59 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.115918
  validation loss:		0.206303
  validation accuracy:		93.59 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.121703
  validation loss:		0.204328
  validation accuracy:		93.80 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.119840
  validation loss:		0.205317
  validation accuracy:		94.13 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.120609
  validation loss:		0.207893
  validation accuracy:		93.59 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.121927
  validation loss:		0.205684
  validation accuracy:		93.91 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.118496
  validation loss:		0.215052
  validation accuracy:		93.26 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.117714
  validation loss:		0.205198
  validation accuracy:		93.70 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.119012
  validation loss:		0.207892
  validation accuracy:		93.59 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.115914
  validation loss:		0.201501
  validation accuracy:		93.91 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.119923
  validation loss:		0.205131
  validation accuracy:		93.48 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.112056
  validation loss:		0.211938
  validation accuracy:		93.70 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.118550
  validation loss:		0.203625
  validation accuracy:		94.13 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.114866
  validation loss:		0.203496
  validation accuracy:		93.80 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.116643
  validation loss:		0.214778
  validation accuracy:		92.93 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.118002
  validation loss:		0.210144
  validation accuracy:		93.48 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.116291
  validation loss:		0.208043
  validation accuracy:		93.48 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.117037
  validation loss:		0.207553
  validation accuracy:		93.48 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.115410
  validation loss:		0.210752
  validation accuracy:		93.70 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.111456
  validation loss:		0.211809
  validation accuracy:		93.26 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.116378
  validation loss:		0.211234
  validation accuracy:		93.59 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.110200
  validation loss:		0.207054
  validation accuracy:		93.59 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.116569
  validation loss:		0.212132
  validation accuracy:		93.37 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.115499
  validation loss:		0.211451
  validation accuracy:		93.37 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.114558
  validation loss:		0.214132
  validation accuracy:		93.70 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.113653
  validation loss:		0.210416
  validation accuracy:		93.26 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.113407
  validation loss:		0.207442
  validation accuracy:		93.48 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.108298
  validation loss:		0.208636
  validation accuracy:		93.59 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.109504
  validation loss:		0.212857
  validation accuracy:		93.59 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.111716
  validation loss:		0.208199
  validation accuracy:		93.91 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.107588
  validation loss:		0.210072
  validation accuracy:		93.37 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.113011
  validation loss:		0.206221
  validation accuracy:		93.80 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.111287
  validation loss:		0.212912
  validation accuracy:		94.02 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.109462
  validation loss:		0.211540
  validation accuracy:		93.37 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.110369
  validation loss:		0.206947
  validation accuracy:		93.59 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.107211
  validation loss:		0.208888
  validation accuracy:		93.70 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.110455
  validation loss:		0.212310
  validation accuracy:		93.48 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.106451
  validation loss:		0.216582
  validation accuracy:		93.70 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.109940
  validation loss:		0.211580
  validation accuracy:		93.15 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.106782
  validation loss:		0.215160
  validation accuracy:		93.26 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.109016
  validation loss:		0.202781
  validation accuracy:		93.59 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.107349
  validation loss:		0.213608
  validation accuracy:		93.15 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.109073
  validation loss:		0.205509
  validation accuracy:		93.80 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.106645
  validation loss:		0.211596
  validation accuracy:		93.48 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.107680
  validation loss:		0.210433
  validation accuracy:		93.37 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.108121
  validation loss:		0.205190
  validation accuracy:		93.59 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.107176
  validation loss:		0.217505
  validation accuracy:		93.70 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.107262
  validation loss:		0.210305
  validation accuracy:		93.59 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.106892
  validation loss:		0.211686
  validation accuracy:		93.26 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.104322
  validation loss:		0.212035
  validation accuracy:		93.91 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.104683
  validation loss:		0.215295
  validation accuracy:		93.26 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.104480
  validation loss:		0.210659
  validation accuracy:		93.91 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.107010
  validation loss:		0.217990
  validation accuracy:		93.26 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.104168
  validation loss:		0.211264
  validation accuracy:		93.59 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.101994
  validation loss:		0.211397
  validation accuracy:		93.59 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.102383
  validation loss:		0.219586
  validation accuracy:		93.15 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.104249
  validation loss:		0.209290
  validation accuracy:		94.13 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.105580
  validation loss:		0.213067
  validation accuracy:		93.48 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.102095
  validation loss:		0.211827
  validation accuracy:		93.26 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.103806
  validation loss:		0.209358
  validation accuracy:		93.59 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.104045
  validation loss:		0.212184
  validation accuracy:		93.80 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.100744
  validation loss:		0.210846
  validation accuracy:		93.26 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.098401
  validation loss:		0.210834
  validation accuracy:		93.26 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.101766
  validation loss:		0.213893
  validation accuracy:		93.80 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.102641
  validation loss:		0.209052
  validation accuracy:		93.37 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.101479
  validation loss:		0.208584
  validation accuracy:		93.70 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.098620
  validation loss:		0.217151
  validation accuracy:		93.04 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.102771
  validation loss:		0.207560
  validation accuracy:		94.13 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.097836
  validation loss:		0.210210
  validation accuracy:		93.48 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.099315
  validation loss:		0.210671
  validation accuracy:		93.80 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.099604
  validation loss:		0.211517
  validation accuracy:		93.48 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.101577
  validation loss:		0.215961
  validation accuracy:		93.26 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.100920
  validation loss:		0.216376
  validation accuracy:		93.26 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.096794
  validation loss:		0.213461
  validation accuracy:		93.48 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.097473
  validation loss:		0.210468
  validation accuracy:		93.70 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.096910
  validation loss:		0.210398
  validation accuracy:		93.48 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.097650
  validation loss:		0.217401
  validation accuracy:		93.37 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.098049
  validation loss:		0.214723
  validation accuracy:		93.48 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.096400
  validation loss:		0.218246
  validation accuracy:		93.37 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.097714
  validation loss:		0.209264
  validation accuracy:		93.70 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.096331
  validation loss:		0.214723
  validation accuracy:		93.48 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.099415
  validation loss:		0.205229
  validation accuracy:		93.80 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.097792
  validation loss:		0.212668
  validation accuracy:		93.70 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.095564
  validation loss:		0.222530
  validation accuracy:		93.04 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.092002
  validation loss:		0.212919
  validation accuracy:		93.70 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.092137
  validation loss:		0.217697
  validation accuracy:		93.26 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.092767
  validation loss:		0.212308
  validation accuracy:		93.70 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.095426
  validation loss:		0.218924
  validation accuracy:		93.91 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.096935
  validation loss:		0.216965
  validation accuracy:		93.80 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.096570
  validation loss:		0.214128
  validation accuracy:		93.59 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.092990
  validation loss:		0.216922
  validation accuracy:		93.37 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.093048
  validation loss:		0.217228
  validation accuracy:		93.37 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.093762
  validation loss:		0.221460
  validation accuracy:		93.26 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.092182
  validation loss:		0.211050
  validation accuracy:		93.48 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.095936
  validation loss:		0.218316
  validation accuracy:		93.48 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.092135
  validation loss:		0.213203
  validation accuracy:		93.48 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.094294
  validation loss:		0.216654
  validation accuracy:		93.70 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.088622
  validation loss:		0.213049
  validation accuracy:		93.59 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.091036
  validation loss:		0.214265
  validation accuracy:		93.80 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.091981
  validation loss:		0.215324
  validation accuracy:		93.37 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.092482
  validation loss:		0.217417
  validation accuracy:		93.59 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.089292
  validation loss:		0.221381
  validation accuracy:		93.70 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.090749
  validation loss:		0.221070
  validation accuracy:		93.15 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.089998
  validation loss:		0.224541
  validation accuracy:		93.26 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.092365
  validation loss:		0.221828
  validation accuracy:		93.04 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.091190
  validation loss:		0.218311
  validation accuracy:		93.70 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.090392
  validation loss:		0.217507
  validation accuracy:		93.48 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.091140
  validation loss:		0.216691
  validation accuracy:		93.59 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.092263
  validation loss:		0.218147
  validation accuracy:		93.48 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.087400
  validation loss:		0.216278
  validation accuracy:		94.02 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.090023
  validation loss:		0.221822
  validation accuracy:		93.48 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.091367
  validation loss:		0.219256
  validation accuracy:		93.37 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.087129
  validation loss:		0.215246
  validation accuracy:		93.91 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.090443
  validation loss:		0.227777
  validation accuracy:		93.04 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.090227
  validation loss:		0.216690
  validation accuracy:		93.59 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.088487
  validation loss:		0.216241
  validation accuracy:		93.91 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.087742
  validation loss:		0.219818
  validation accuracy:		93.26 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.088410
  validation loss:		0.219773
  validation accuracy:		93.59 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.088668
  validation loss:		0.217846
  validation accuracy:		93.80 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.088058
  validation loss:		0.220598
  validation accuracy:		93.26 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.090071
  validation loss:		0.215017
  validation accuracy:		93.48 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.086438
  validation loss:		0.219838
  validation accuracy:		93.37 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.087326
  validation loss:		0.215138
  validation accuracy:		93.48 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.084441
  validation loss:		0.222606
  validation accuracy:		93.37 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.087206
  validation loss:		0.219754
  validation accuracy:		93.48 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.086645
  validation loss:		0.220598
  validation accuracy:		93.37 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.083565
  validation loss:		0.218660
  validation accuracy:		93.80 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.085153
  validation loss:		0.221870
  validation accuracy:		93.37 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.084293
  validation loss:		0.222026
  validation accuracy:		93.48 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.085390
  validation loss:		0.221595
  validation accuracy:		93.26 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.082996
  validation loss:		0.226980
  validation accuracy:		93.48 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.085735
  validation loss:		0.225178
  validation accuracy:		93.26 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.086049
  validation loss:		0.223580
  validation accuracy:		93.26 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.085123
  validation loss:		0.221471
  validation accuracy:		93.48 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.083066
  validation loss:		0.219994
  validation accuracy:		93.48 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.083614
  validation loss:		0.223610
  validation accuracy:		93.26 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.081750
  validation loss:		0.219486
  validation accuracy:		93.48 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.084829
  validation loss:		0.224025
  validation accuracy:		93.37 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.080981
  validation loss:		0.226841
  validation accuracy:		93.15 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.082368
  validation loss:		0.223293
  validation accuracy:		93.37 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.085061
  validation loss:		0.221778
  validation accuracy:		93.48 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.084123
  validation loss:		0.219533
  validation accuracy:		93.91 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.084099
  validation loss:		0.225814
  validation accuracy:		93.15 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.082482
  validation loss:		0.227098
  validation accuracy:		93.48 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.084059
  validation loss:		0.223110
  validation accuracy:		93.37 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.080705
  validation loss:		0.218105
  validation accuracy:		93.48 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.082882
  validation loss:		0.221982
  validation accuracy:		93.48 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.081709
  validation loss:		0.222827
  validation accuracy:		93.91 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.078528
  validation loss:		0.225643
  validation accuracy:		93.15 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.079647
  validation loss:		0.232954
  validation accuracy:		93.26 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.078728
  validation loss:		0.220953
  validation accuracy:		93.80 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.081048
  validation loss:		0.228244
  validation accuracy:		93.04 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.079261
  validation loss:		0.223243
  validation accuracy:		93.48 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.079804
  validation loss:		0.230083
  validation accuracy:		93.26 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.078575
  validation loss:		0.230161
  validation accuracy:		93.37 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.082439
  validation loss:		0.231581
  validation accuracy:		93.04 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.079978
  validation loss:		0.224183
  validation accuracy:		93.70 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.080523
  validation loss:		0.225458
  validation accuracy:		93.15 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.079123
  validation loss:		0.232647
  validation accuracy:		93.15 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.078071
  validation loss:		0.222698
  validation accuracy:		93.37 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.079755
  validation loss:		0.234395
  validation accuracy:		93.37 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.078330
  validation loss:		0.227222
  validation accuracy:		93.48 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.078124
  validation loss:		0.228483
  validation accuracy:		93.59 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.077631
  validation loss:		0.223836
  validation accuracy:		93.48 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.078863
  validation loss:		0.226354
  validation accuracy:		93.04 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.079111
  validation loss:		0.226567
  validation accuracy:		93.37 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.076761
  validation loss:		0.227033
  validation accuracy:		93.37 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.076754
  validation loss:		0.226650
  validation accuracy:		93.37 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.075682
  validation loss:		0.223770
  validation accuracy:		93.37 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.077165
  validation loss:		0.234276
  validation accuracy:		93.26 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.078189
  validation loss:		0.232454
  validation accuracy:		93.04 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.078231
  validation loss:		0.228600
  validation accuracy:		93.26 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.075247
  validation loss:		0.231818
  validation accuracy:		93.26 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.074401
  validation loss:		0.225981
  validation accuracy:		93.37 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.076516
  validation loss:		0.221196
  validation accuracy:		93.59 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.077480
  validation loss:		0.230700
  validation accuracy:		93.37 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.076022
  validation loss:		0.229761
  validation accuracy:		93.04 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.075275
  validation loss:		0.228409
  validation accuracy:		93.26 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.076787
  validation loss:		0.226172
  validation accuracy:		93.59 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.075957
  validation loss:		0.226646
  validation accuracy:		93.37 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.076848
  validation loss:		0.227920
  validation accuracy:		93.26 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.077220
  validation loss:		0.231380
  validation accuracy:		93.15 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.073262
  validation loss:		0.227368
  validation accuracy:		93.15 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.074466
  validation loss:		0.223937
  validation accuracy:		93.37 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.074686
  validation loss:		0.229447
  validation accuracy:		93.26 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.075506
  validation loss:		0.242191
  validation accuracy:		93.15 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.074869
  validation loss:		0.235203
  validation accuracy:		93.26 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.070938
  validation loss:		0.228888
  validation accuracy:		93.26 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.073701
  validation loss:		0.227880
  validation accuracy:		93.26 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.074448
  validation loss:		0.227647
  validation accuracy:		93.48 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.073459
  validation loss:		0.233384
  validation accuracy:		93.04 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.072008
  validation loss:		0.237818
  validation accuracy:		93.48 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.070483
  validation loss:		0.235084
  validation accuracy:		93.15 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.074684
  validation loss:		0.235909
  validation accuracy:		93.26 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.073776
  validation loss:		0.236620
  validation accuracy:		93.15 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.073837
  validation loss:		0.234105
  validation accuracy:		93.48 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.072803
  validation loss:		0.235989
  validation accuracy:		93.04 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.073341
  validation loss:		0.237385
  validation accuracy:		93.15 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.072139
  validation loss:		0.233157
  validation accuracy:		93.04 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.072737
  validation loss:		0.227563
  validation accuracy:		93.04 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.072530
  validation loss:		0.229061
  validation accuracy:		93.37 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.071218
  validation loss:		0.235698
  validation accuracy:		93.26 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.070881
  validation loss:		0.227061
  validation accuracy:		93.26 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.071504
  validation loss:		0.241164
  validation accuracy:		93.04 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.073235
  validation loss:		0.234478
  validation accuracy:		93.04 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.071285
  validation loss:		0.233638
  validation accuracy:		93.26 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.068886
  validation loss:		0.240807
  validation accuracy:		93.70 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.070326
  validation loss:		0.232361
  validation accuracy:		93.48 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.072734
  validation loss:		0.228129
  validation accuracy:		93.15 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.071476
  validation loss:		0.231819
  validation accuracy:		93.15 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.068030
  validation loss:		0.240488
  validation accuracy:		93.15 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.070372
  validation loss:		0.230710
  validation accuracy:		93.48 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.069504
  validation loss:		0.239853
  validation accuracy:		93.04 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.070720
  validation loss:		0.232305
  validation accuracy:		93.26 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.069560
  validation loss:		0.241503
  validation accuracy:		93.26 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.068845
  validation loss:		0.242425
  validation accuracy:		93.26 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.069986
  validation loss:		0.240314
  validation accuracy:		93.04 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.069189
  validation loss:		0.233941
  validation accuracy:		93.15 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.068902
  validation loss:		0.235443
  validation accuracy:		93.26 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.069662
  validation loss:		0.232137
  validation accuracy:		93.04 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.068820
  validation loss:		0.234511
  validation accuracy:		93.59 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.068209
  validation loss:		0.233003
  validation accuracy:		93.26 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.067174
  validation loss:		0.238257
  validation accuracy:		93.37 %
Epoch 518 of 2000 took 0.037s
  training loss:		0.067381
  validation loss:		0.241350
  validation accuracy:		93.26 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.066872
  validation loss:		0.232264
  validation accuracy:		93.26 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.066814
  validation loss:		0.229057
  validation accuracy:		93.04 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.068122
  validation loss:		0.237718
  validation accuracy:		93.15 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.065971
  validation loss:		0.233011
  validation accuracy:		93.48 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.068619
  validation loss:		0.241017
  validation accuracy:		93.15 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.067490
  validation loss:		0.240568
  validation accuracy:		93.15 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.068784
  validation loss:		0.233985
  validation accuracy:		93.37 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.066553
  validation loss:		0.237343
  validation accuracy:		93.37 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.065328
  validation loss:		0.240378
  validation accuracy:		93.26 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.066908
  validation loss:		0.237763
  validation accuracy:		93.37 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.065703
  validation loss:		0.245186
  validation accuracy:		93.04 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.066993
  validation loss:		0.242464
  validation accuracy:		93.15 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.066522
  validation loss:		0.239673
  validation accuracy:		93.15 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.065456
  validation loss:		0.245519
  validation accuracy:		93.37 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.065190
  validation loss:		0.243690
  validation accuracy:		93.37 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.064506
  validation loss:		0.237070
  validation accuracy:		93.26 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.065220
  validation loss:		0.239271
  validation accuracy:		93.04 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.063231
  validation loss:		0.241375
  validation accuracy:		93.04 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.065151
  validation loss:		0.251898
  validation accuracy:		93.04 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.065508
  validation loss:		0.238631
  validation accuracy:		93.04 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.062490
  validation loss:		0.232824
  validation accuracy:		93.48 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.066508
  validation loss:		0.241460
  validation accuracy:		93.15 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.061909
  validation loss:		0.250671
  validation accuracy:		93.15 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.065783
  validation loss:		0.239541
  validation accuracy:		93.15 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.062132
  validation loss:		0.244064
  validation accuracy:		93.15 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.064852
  validation loss:		0.243966
  validation accuracy:		93.37 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.063740
  validation loss:		0.243713
  validation accuracy:		93.37 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.062627
  validation loss:		0.247296
  validation accuracy:		93.37 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.064086
  validation loss:		0.240067
  validation accuracy:		93.04 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.063229
  validation loss:		0.247467
  validation accuracy:		93.26 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.061945
  validation loss:		0.240095
  validation accuracy:		93.37 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.062649
  validation loss:		0.239426
  validation accuracy:		93.15 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.063629
  validation loss:		0.241578
  validation accuracy:		93.15 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.060623
  validation loss:		0.243033
  validation accuracy:		93.15 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.061383
  validation loss:		0.254775
  validation accuracy:		93.59 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.062965
  validation loss:		0.244283
  validation accuracy:		93.15 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.061940
  validation loss:		0.240629
  validation accuracy:		93.15 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.060623
  validation loss:		0.242274
  validation accuracy:		93.15 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.062970
  validation loss:		0.239679
  validation accuracy:		93.15 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.062246
  validation loss:		0.247929
  validation accuracy:		92.93 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.061870
  validation loss:		0.245254
  validation accuracy:		93.26 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.061410
  validation loss:		0.240141
  validation accuracy:		93.48 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.060026
  validation loss:		0.248010
  validation accuracy:		93.26 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.059706
  validation loss:		0.243398
  validation accuracy:		93.37 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.061668
  validation loss:		0.254366
  validation accuracy:		93.26 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.060712
  validation loss:		0.243134
  validation accuracy:		93.04 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.059603
  validation loss:		0.246109
  validation accuracy:		92.93 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.060323
  validation loss:		0.247947
  validation accuracy:		93.37 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.059987
  validation loss:		0.247864
  validation accuracy:		93.37 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.059990
  validation loss:		0.244528
  validation accuracy:		93.37 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.058182
  validation loss:		0.244758
  validation accuracy:		93.15 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.058814
  validation loss:		0.249640
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.059651
  validation loss:		0.246812
  validation accuracy:		93.15 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.058406
  validation loss:		0.243257
  validation accuracy:		93.15 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.060631
  validation loss:		0.251025
  validation accuracy:		93.15 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.059295
  validation loss:		0.243913
  validation accuracy:		93.37 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.057739
  validation loss:		0.249204
  validation accuracy:		93.15 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.058441
  validation loss:		0.247700
  validation accuracy:		93.15 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.057883
  validation loss:		0.250124
  validation accuracy:		93.15 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.058757
  validation loss:		0.248466
  validation accuracy:		93.26 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.058490
  validation loss:		0.246031
  validation accuracy:		93.04 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.059042
  validation loss:		0.251008
  validation accuracy:		93.04 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.060025
  validation loss:		0.246196
  validation accuracy:		93.15 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.058209
  validation loss:		0.244330
  validation accuracy:		93.04 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.058613
  validation loss:		0.257959
  validation accuracy:		93.26 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.057824
  validation loss:		0.255050
  validation accuracy:		93.37 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.056433
  validation loss:		0.242798
  validation accuracy:		93.26 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.057722
  validation loss:		0.248428
  validation accuracy:		93.15 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.056185
  validation loss:		0.250493
  validation accuracy:		93.04 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.056514
  validation loss:		0.251341
  validation accuracy:		93.15 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.058855
  validation loss:		0.246183
  validation accuracy:		93.59 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.058359
  validation loss:		0.245441
  validation accuracy:		93.15 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.057095
  validation loss:		0.244270
  validation accuracy:		93.37 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.056973
  validation loss:		0.249209
  validation accuracy:		93.04 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.056030
  validation loss:		0.260485
  validation accuracy:		93.37 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.056427
  validation loss:		0.246380
  validation accuracy:		93.15 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.056657
  validation loss:		0.251124
  validation accuracy:		93.37 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.056932
  validation loss:		0.251197
  validation accuracy:		93.15 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.055964
  validation loss:		0.251536
  validation accuracy:		93.15 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.057097
  validation loss:		0.252093
  validation accuracy:		93.26 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.055944
  validation loss:		0.255980
  validation accuracy:		93.26 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.054192
  validation loss:		0.246217
  validation accuracy:		93.04 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.055796
  validation loss:		0.248529
  validation accuracy:		93.37 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.053609
  validation loss:		0.250539
  validation accuracy:		93.04 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.055465
  validation loss:		0.247561
  validation accuracy:		93.15 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.053349
  validation loss:		0.254335
  validation accuracy:		93.26 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.053394
  validation loss:		0.246405
  validation accuracy:		93.37 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.054851
  validation loss:		0.249421
  validation accuracy:		93.37 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.052671
  validation loss:		0.253626
  validation accuracy:		93.15 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.054916
  validation loss:		0.250185
  validation accuracy:		93.15 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.053641
  validation loss:		0.255480
  validation accuracy:		93.15 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.055157
  validation loss:		0.254273
  validation accuracy:		93.37 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.054758
  validation loss:		0.254021
  validation accuracy:		93.26 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.054093
  validation loss:		0.255766
  validation accuracy:		93.26 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.055557
  validation loss:		0.257742
  validation accuracy:		93.15 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.053476
  validation loss:		0.257627
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.052685
  validation loss:		0.254578
  validation accuracy:		93.26 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.055126
  validation loss:		0.254979
  validation accuracy:		93.48 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.051430
  validation loss:		0.254231
  validation accuracy:		93.04 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.053945
  validation loss:		0.253416
  validation accuracy:		93.15 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.051068
  validation loss:		0.257613
  validation accuracy:		93.26 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.052442
  validation loss:		0.254325
  validation accuracy:		93.15 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.053994
  validation loss:		0.256592
  validation accuracy:		93.26 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.052638
  validation loss:		0.253494
  validation accuracy:		93.48 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.053910
  validation loss:		0.257228
  validation accuracy:		93.37 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.049809
  validation loss:		0.258945
  validation accuracy:		93.37 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.051882
  validation loss:		0.268376
  validation accuracy:		93.48 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.054419
  validation loss:		0.257028
  validation accuracy:		93.37 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.053030
  validation loss:		0.259757
  validation accuracy:		93.26 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.052433
  validation loss:		0.255309
  validation accuracy:		93.04 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.052386
  validation loss:		0.259001
  validation accuracy:		93.26 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.050428
  validation loss:		0.258300
  validation accuracy:		93.26 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.051170
  validation loss:		0.257436
  validation accuracy:		93.15 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.050903
  validation loss:		0.259533
  validation accuracy:		93.48 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.051503
  validation loss:		0.260992
  validation accuracy:		93.26 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.050766
  validation loss:		0.257369
  validation accuracy:		93.48 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.050553
  validation loss:		0.259075
  validation accuracy:		93.26 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.051949
  validation loss:		0.258754
  validation accuracy:		93.37 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.051743
  validation loss:		0.260211
  validation accuracy:		93.15 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.049925
  validation loss:		0.260282
  validation accuracy:		93.15 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.050096
  validation loss:		0.262243
  validation accuracy:		93.37 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.050972
  validation loss:		0.260063
  validation accuracy:		93.26 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.051930
  validation loss:		0.263168
  validation accuracy:		93.26 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.050077
  validation loss:		0.260257
  validation accuracy:		93.26 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.049163
  validation loss:		0.263855
  validation accuracy:		93.26 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.051050
  validation loss:		0.262942
  validation accuracy:		93.37 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.050545
  validation loss:		0.255978
  validation accuracy:		93.15 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.049305
  validation loss:		0.261109
  validation accuracy:		93.37 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.049665
  validation loss:		0.259797
  validation accuracy:		93.26 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.050175
  validation loss:		0.263708
  validation accuracy:		93.15 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.048323
  validation loss:		0.258566
  validation accuracy:		93.26 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.049785
  validation loss:		0.260792
  validation accuracy:		93.37 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.049795
  validation loss:		0.262062
  validation accuracy:		93.70 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.050310
  validation loss:		0.262088
  validation accuracy:		93.04 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.050678
  validation loss:		0.261618
  validation accuracy:		93.26 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.049703
  validation loss:		0.264528
  validation accuracy:		93.15 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.048851
  validation loss:		0.264678
  validation accuracy:		93.37 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.049589
  validation loss:		0.263382
  validation accuracy:		93.26 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.048970
  validation loss:		0.265865
  validation accuracy:		93.37 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.048749
  validation loss:		0.262019
  validation accuracy:		93.15 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.048573
  validation loss:		0.267343
  validation accuracy:		93.26 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.047613
  validation loss:		0.263901
  validation accuracy:		93.37 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.048625
  validation loss:		0.266255
  validation accuracy:		93.26 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.047211
  validation loss:		0.269021
  validation accuracy:		93.37 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.049128
  validation loss:		0.273280
  validation accuracy:		92.93 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.046783
  validation loss:		0.263649
  validation accuracy:		93.37 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.048652
  validation loss:		0.262072
  validation accuracy:		93.26 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.047654
  validation loss:		0.270882
  validation accuracy:		93.37 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.048047
  validation loss:		0.264408
  validation accuracy:		93.04 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.047860
  validation loss:		0.270521
  validation accuracy:		93.37 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.044132
  validation loss:		0.271777
  validation accuracy:		93.59 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.048281
  validation loss:		0.267755
  validation accuracy:		93.26 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.047818
  validation loss:		0.272843
  validation accuracy:		93.15 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.047442
  validation loss:		0.270521
  validation accuracy:		93.26 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.047111
  validation loss:		0.268867
  validation accuracy:		93.15 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.046149
  validation loss:		0.270532
  validation accuracy:		93.37 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.047880
  validation loss:		0.269508
  validation accuracy:		93.26 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.046990
  validation loss:		0.264748
  validation accuracy:		93.26 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.044890
  validation loss:		0.265162
  validation accuracy:		93.37 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.046959
  validation loss:		0.266992
  validation accuracy:		93.37 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.046235
  validation loss:		0.271548
  validation accuracy:		93.26 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.046741
  validation loss:		0.279827
  validation accuracy:		92.93 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.047058
  validation loss:		0.271156
  validation accuracy:		93.04 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.045539
  validation loss:		0.262681
  validation accuracy:		93.59 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.046284
  validation loss:		0.270403
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.045950
  validation loss:		0.269965
  validation accuracy:		93.26 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.042818
  validation loss:		0.274041
  validation accuracy:		93.26 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.046520
  validation loss:		0.270442
  validation accuracy:		93.04 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.045999
  validation loss:		0.268347
  validation accuracy:		93.37 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.044166
  validation loss:		0.268286
  validation accuracy:		93.15 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.045522
  validation loss:		0.270361
  validation accuracy:		93.37 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.044718
  validation loss:		0.271922
  validation accuracy:		93.26 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.044487
  validation loss:		0.279512
  validation accuracy:		92.72 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.044823
  validation loss:		0.266434
  validation accuracy:		93.37 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.045166
  validation loss:		0.271295
  validation accuracy:		93.48 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.044703
  validation loss:		0.267106
  validation accuracy:		93.26 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.044083
  validation loss:		0.273827
  validation accuracy:		93.15 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.042854
  validation loss:		0.277131
  validation accuracy:		93.26 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.044161
  validation loss:		0.272497
  validation accuracy:		93.15 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.043252
  validation loss:		0.273263
  validation accuracy:		93.37 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.043592
  validation loss:		0.275483
  validation accuracy:		93.26 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.044386
  validation loss:		0.271651
  validation accuracy:		93.26 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.045677
  validation loss:		0.275677
  validation accuracy:		93.26 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.043610
  validation loss:		0.285204
  validation accuracy:		93.04 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.044713
  validation loss:		0.273063
  validation accuracy:		93.15 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.042366
  validation loss:		0.267312
  validation accuracy:		93.37 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.044296
  validation loss:		0.276815
  validation accuracy:		93.15 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.041732
  validation loss:		0.277814
  validation accuracy:		93.15 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.043677
  validation loss:		0.276226
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.041805
  validation loss:		0.274249
  validation accuracy:		93.37 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.041880
  validation loss:		0.277516
  validation accuracy:		93.37 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.043759
  validation loss:		0.276064
  validation accuracy:		93.37 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.042113
  validation loss:		0.281875
  validation accuracy:		93.15 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.042855
  validation loss:		0.279466
  validation accuracy:		93.15 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.041950
  validation loss:		0.275074
  validation accuracy:		93.26 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.042146
  validation loss:		0.275394
  validation accuracy:		93.37 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.044054
  validation loss:		0.278026
  validation accuracy:		93.37 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.041941
  validation loss:		0.275461
  validation accuracy:		93.37 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.040764
  validation loss:		0.277972
  validation accuracy:		93.26 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.041750
  validation loss:		0.281292
  validation accuracy:		93.04 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.042787
  validation loss:		0.278995
  validation accuracy:		93.37 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.042545
  validation loss:		0.276746
  validation accuracy:		93.48 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.039698
  validation loss:		0.281259
  validation accuracy:		93.15 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.042284
  validation loss:		0.275667
  validation accuracy:		93.26 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.041291
  validation loss:		0.274216
  validation accuracy:		93.37 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.039393
  validation loss:		0.284466
  validation accuracy:		93.15 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.040396
  validation loss:		0.284211
  validation accuracy:		92.72 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.042923
  validation loss:		0.286663
  validation accuracy:		93.26 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.039438
  validation loss:		0.282556
  validation accuracy:		93.26 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.041270
  validation loss:		0.282034
  validation accuracy:		93.15 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.039046
  validation loss:		0.280420
  validation accuracy:		93.15 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.038818
  validation loss:		0.276588
  validation accuracy:		93.48 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.041044
  validation loss:		0.279817
  validation accuracy:		93.04 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.039894
  validation loss:		0.283192
  validation accuracy:		93.26 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.039530
  validation loss:		0.276377
  validation accuracy:		93.37 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.040196
  validation loss:		0.279245
  validation accuracy:		93.37 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.039592
  validation loss:		0.289517
  validation accuracy:		92.83 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.041304
  validation loss:		0.285187
  validation accuracy:		93.15 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.040427
  validation loss:		0.283806
  validation accuracy:		93.15 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.040440
  validation loss:		0.287374
  validation accuracy:		93.37 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.039612
  validation loss:		0.285021
  validation accuracy:		93.15 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.039106
  validation loss:		0.282185
  validation accuracy:		93.37 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.039914
  validation loss:		0.284431
  validation accuracy:		93.48 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.038854
  validation loss:		0.279468
  validation accuracy:		93.15 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.040073
  validation loss:		0.283973
  validation accuracy:		93.37 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.037480
  validation loss:		0.282833
  validation accuracy:		93.26 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.040122
  validation loss:		0.277882
  validation accuracy:		93.37 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.037872
  validation loss:		0.294779
  validation accuracy:		93.04 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.040088
  validation loss:		0.284031
  validation accuracy:		93.26 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.037663
  validation loss:		0.290748
  validation accuracy:		92.93 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.039381
  validation loss:		0.280797
  validation accuracy:		93.04 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.038332
  validation loss:		0.286108
  validation accuracy:		93.04 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.038665
  validation loss:		0.280295
  validation accuracy:		93.26 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.038917
  validation loss:		0.288680
  validation accuracy:		93.37 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.037677
  validation loss:		0.282724
  validation accuracy:		93.15 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.038709
  validation loss:		0.286829
  validation accuracy:		93.15 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.038131
  validation loss:		0.287872
  validation accuracy:		93.15 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.037890
  validation loss:		0.281995
  validation accuracy:		93.37 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.037571
  validation loss:		0.286674
  validation accuracy:		93.15 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.037937
  validation loss:		0.289029
  validation accuracy:		93.59 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.038303
  validation loss:		0.287707
  validation accuracy:		93.15 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.038515
  validation loss:		0.284958
  validation accuracy:		92.93 %
Epoch 761 of 2000 took 0.036s
  training loss:		0.039200
  validation loss:		0.292869
  validation accuracy:		92.93 %
Epoch 762 of 2000 took 0.036s
  training loss:		0.038411
  validation loss:		0.284747
  validation accuracy:		93.26 %
Epoch 763 of 2000 took 0.036s
  training loss:		0.038130
  validation loss:		0.289995
  validation accuracy:		93.15 %
Epoch 764 of 2000 took 0.036s
  training loss:		0.036448
  validation loss:		0.288642
  validation accuracy:		92.93 %
Epoch 765 of 2000 took 0.036s
  training loss:		0.037350
  validation loss:		0.287886
  validation accuracy:		93.48 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.036900
  validation loss:		0.287006
  validation accuracy:		93.26 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.036834
  validation loss:		0.286324
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.036593
  validation loss:		0.291521
  validation accuracy:		93.37 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.034917
  validation loss:		0.291280
  validation accuracy:		92.83 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.034726
  validation loss:		0.297049
  validation accuracy:		93.04 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.035923
  validation loss:		0.290116
  validation accuracy:		93.26 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.037261
  validation loss:		0.289090
  validation accuracy:		93.15 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.037516
  validation loss:		0.293027
  validation accuracy:		93.15 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.036083
  validation loss:		0.284920
  validation accuracy:		93.26 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.036794
  validation loss:		0.289066
  validation accuracy:		93.37 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.036707
  validation loss:		0.289038
  validation accuracy:		93.26 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.035716
  validation loss:		0.292598
  validation accuracy:		93.37 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.035760
  validation loss:		0.289061
  validation accuracy:		93.26 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.036893
  validation loss:		0.292214
  validation accuracy:		93.48 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.035005
  validation loss:		0.292144
  validation accuracy:		93.04 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.035885
  validation loss:		0.292228
  validation accuracy:		93.26 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.036776
  validation loss:		0.295612
  validation accuracy:		93.26 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.035203
  validation loss:		0.289422
  validation accuracy:		93.26 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.034959
  validation loss:		0.292042
  validation accuracy:		93.15 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.034650
  validation loss:		0.293766
  validation accuracy:		93.37 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.033648
  validation loss:		0.292081
  validation accuracy:		93.26 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.035046
  validation loss:		0.293205
  validation accuracy:		93.26 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.035595
  validation loss:		0.290224
  validation accuracy:		93.48 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.034551
  validation loss:		0.296821
  validation accuracy:		93.15 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.034318
  validation loss:		0.292040
  validation accuracy:		93.26 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.035528
  validation loss:		0.293420
  validation accuracy:		93.26 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.034136
  validation loss:		0.302488
  validation accuracy:		93.26 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.035825
  validation loss:		0.292520
  validation accuracy:		93.26 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.034767
  validation loss:		0.300660
  validation accuracy:		93.04 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.034939
  validation loss:		0.294282
  validation accuracy:		93.48 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.033565
  validation loss:		0.291487
  validation accuracy:		93.37 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.034714
  validation loss:		0.297641
  validation accuracy:		93.15 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.035379
  validation loss:		0.290897
  validation accuracy:		93.26 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.032435
  validation loss:		0.302774
  validation accuracy:		93.15 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.034662
  validation loss:		0.293557
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.033657
  validation loss:		0.296968
  validation accuracy:		93.15 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.034043
  validation loss:		0.297424
  validation accuracy:		93.04 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.033701
  validation loss:		0.297686
  validation accuracy:		93.37 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.032614
  validation loss:		0.293416
  validation accuracy:		93.37 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.034375
  validation loss:		0.294369
  validation accuracy:		93.26 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.032730
  validation loss:		0.299656
  validation accuracy:		93.04 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.034003
  validation loss:		0.293018
  validation accuracy:		93.26 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.033521
  validation loss:		0.297596
  validation accuracy:		92.83 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.033270
  validation loss:		0.304640
  validation accuracy:		93.04 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.032604
  validation loss:		0.302339
  validation accuracy:		93.48 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.033145
  validation loss:		0.299298
  validation accuracy:		93.04 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.032059
  validation loss:		0.300090
  validation accuracy:		93.48 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.032104
  validation loss:		0.300292
  validation accuracy:		93.04 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.032794
  validation loss:		0.300710
  validation accuracy:		93.04 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.033301
  validation loss:		0.296893
  validation accuracy:		93.26 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.032687
  validation loss:		0.299759
  validation accuracy:		93.37 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.032342
  validation loss:		0.296460
  validation accuracy:		93.26 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.032222
  validation loss:		0.300490
  validation accuracy:		93.26 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.031940
  validation loss:		0.310915
  validation accuracy:		93.04 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.031517
  validation loss:		0.300599
  validation accuracy:		93.15 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.032072
  validation loss:		0.300301
  validation accuracy:		93.37 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.033033
  validation loss:		0.302888
  validation accuracy:		93.04 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.032716
  validation loss:		0.296699
  validation accuracy:		93.37 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.033315
  validation loss:		0.299190
  validation accuracy:		93.37 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.031473
  validation loss:		0.308359
  validation accuracy:		93.15 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.032545
  validation loss:		0.303557
  validation accuracy:		93.26 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.032090
  validation loss:		0.299686
  validation accuracy:		92.93 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.032020
  validation loss:		0.303827
  validation accuracy:		93.26 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.032254
  validation loss:		0.304253
  validation accuracy:		93.37 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.030655
  validation loss:		0.299043
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.031639
  validation loss:		0.297191
  validation accuracy:		93.26 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.029711
  validation loss:		0.302648
  validation accuracy:		93.26 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.030429
  validation loss:		0.305717
  validation accuracy:		93.15 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.031286
  validation loss:		0.306956
  validation accuracy:		93.15 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.032082
  validation loss:		0.308793
  validation accuracy:		93.04 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.031316
  validation loss:		0.299595
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.031006
  validation loss:		0.309069
  validation accuracy:		93.15 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.031805
  validation loss:		0.311951
  validation accuracy:		93.15 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.030339
  validation loss:		0.302645
  validation accuracy:		93.15 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.031017
  validation loss:		0.306046
  validation accuracy:		93.26 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.029903
  validation loss:		0.310037
  validation accuracy:		93.15 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.030205
  validation loss:		0.309231
  validation accuracy:		93.04 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.029777
  validation loss:		0.300253
  validation accuracy:		93.48 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.030565
  validation loss:		0.313269
  validation accuracy:		93.04 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.031932
  validation loss:		0.307661
  validation accuracy:		93.48 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.030454
  validation loss:		0.310362
  validation accuracy:		93.04 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.029446
  validation loss:		0.308505
  validation accuracy:		93.04 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.030292
  validation loss:		0.307581
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.030406
  validation loss:		0.312392
  validation accuracy:		93.04 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.029061
  validation loss:		0.309259
  validation accuracy:		93.26 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.028944
  validation loss:		0.305379
  validation accuracy:		93.37 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.029232
  validation loss:		0.314436
  validation accuracy:		93.04 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.030675
  validation loss:		0.313925
  validation accuracy:		93.15 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.030338
  validation loss:		0.309723
  validation accuracy:		93.37 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.028993
  validation loss:		0.305559
  validation accuracy:		93.26 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.028534
  validation loss:		0.308986
  validation accuracy:		93.70 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.029673
  validation loss:		0.312213
  validation accuracy:		93.37 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.029972
  validation loss:		0.305459
  validation accuracy:		93.04 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.030254
  validation loss:		0.308152
  validation accuracy:		93.26 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.028978
  validation loss:		0.311510
  validation accuracy:		93.37 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.029592
  validation loss:		0.308018
  validation accuracy:		93.04 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.030014
  validation loss:		0.304114
  validation accuracy:		93.59 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.028565
  validation loss:		0.312686
  validation accuracy:		93.15 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.028226
  validation loss:		0.311455
  validation accuracy:		93.04 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.028690
  validation loss:		0.310103
  validation accuracy:		93.26 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.027694
  validation loss:		0.309291
  validation accuracy:		93.48 %
Epoch 867 of 2000 took 0.037s
  training loss:		0.027199
  validation loss:		0.308917
  validation accuracy:		93.04 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.028727
  validation loss:		0.320224
  validation accuracy:		93.15 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.028201
  validation loss:		0.309070
  validation accuracy:		93.26 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.029007
  validation loss:		0.314114
  validation accuracy:		93.26 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.028379
  validation loss:		0.321489
  validation accuracy:		92.93 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.027723
  validation loss:		0.311836
  validation accuracy:		93.04 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.028782
  validation loss:		0.314429
  validation accuracy:		93.04 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.027936
  validation loss:		0.307273
  validation accuracy:		93.48 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.028863
  validation loss:		0.313395
  validation accuracy:		92.93 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.028916
  validation loss:		0.313245
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.028770
  validation loss:		0.314536
  validation accuracy:		93.37 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.028092
  validation loss:		0.315932
  validation accuracy:		92.93 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.028202
  validation loss:		0.316644
  validation accuracy:		93.26 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.027432
  validation loss:		0.313003
  validation accuracy:		93.37 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.026416
  validation loss:		0.315867
  validation accuracy:		93.15 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.027123
  validation loss:		0.315443
  validation accuracy:		93.59 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.027859
  validation loss:		0.312827
  validation accuracy:		93.37 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.027740
  validation loss:		0.315006
  validation accuracy:		92.93 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.027599
  validation loss:		0.319597
  validation accuracy:		93.15 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.027624
  validation loss:		0.320427
  validation accuracy:		93.15 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.027160
  validation loss:		0.314382
  validation accuracy:		93.26 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.027396
  validation loss:		0.311043
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.027147
  validation loss:		0.318448
  validation accuracy:		93.37 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.026648
  validation loss:		0.321417
  validation accuracy:		93.04 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.027810
  validation loss:		0.320673
  validation accuracy:		93.26 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.026845
  validation loss:		0.316259
  validation accuracy:		93.26 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.026713
  validation loss:		0.323006
  validation accuracy:		93.15 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.026704
  validation loss:		0.325987
  validation accuracy:		93.26 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.026766
  validation loss:		0.324545
  validation accuracy:		93.15 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.026153
  validation loss:		0.317223
  validation accuracy:		93.15 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.026728
  validation loss:		0.315918
  validation accuracy:		93.48 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.026536
  validation loss:		0.312673
  validation accuracy:		93.48 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.025685
  validation loss:		0.318966
  validation accuracy:		93.15 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.026517
  validation loss:		0.321283
  validation accuracy:		93.26 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.026443
  validation loss:		0.319406
  validation accuracy:		93.37 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.026406
  validation loss:		0.321125
  validation accuracy:		93.26 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.025352
  validation loss:		0.324200
  validation accuracy:		93.26 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.025363
  validation loss:		0.315596
  validation accuracy:		93.37 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.026436
  validation loss:		0.321127
  validation accuracy:		93.59 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.026281
  validation loss:		0.318692
  validation accuracy:		93.37 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.025824
  validation loss:		0.319644
  validation accuracy:		93.15 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.025467
  validation loss:		0.324390
  validation accuracy:		93.26 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.025938
  validation loss:		0.317276
  validation accuracy:		93.26 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.026026
  validation loss:		0.320252
  validation accuracy:		93.48 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.025571
  validation loss:		0.318995
  validation accuracy:		93.15 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.026276
  validation loss:		0.325898
  validation accuracy:		93.37 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.026189
  validation loss:		0.323699
  validation accuracy:		93.04 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.026310
  validation loss:		0.322248
  validation accuracy:		93.26 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.024757
  validation loss:		0.329193
  validation accuracy:		93.37 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.025445
  validation loss:		0.327906
  validation accuracy:		93.26 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.025538
  validation loss:		0.322896
  validation accuracy:		93.37 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.025680
  validation loss:		0.325548
  validation accuracy:		93.15 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.025305
  validation loss:		0.326061
  validation accuracy:		93.26 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.025308
  validation loss:		0.326083
  validation accuracy:		93.26 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.025542
  validation loss:		0.327332
  validation accuracy:		93.15 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.025345
  validation loss:		0.329984
  validation accuracy:		93.26 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.025486
  validation loss:		0.327431
  validation accuracy:		93.37 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.024991
  validation loss:		0.325397
  validation accuracy:		93.26 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.025356
  validation loss:		0.323643
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.025058
  validation loss:		0.323372
  validation accuracy:		93.37 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.023612
  validation loss:		0.324483
  validation accuracy:		93.15 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.023800
  validation loss:		0.329839
  validation accuracy:		93.15 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.024631
  validation loss:		0.328196
  validation accuracy:		93.26 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.024318
  validation loss:		0.328203
  validation accuracy:		93.26 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.023227
  validation loss:		0.326352
  validation accuracy:		93.15 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.024828
  validation loss:		0.321743
  validation accuracy:		93.15 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.024500
  validation loss:		0.326953
  validation accuracy:		93.37 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.024078
  validation loss:		0.333093
  validation accuracy:		93.15 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.023836
  validation loss:		0.326757
  validation accuracy:		93.04 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.024686
  validation loss:		0.332141
  validation accuracy:		93.04 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.024484
  validation loss:		0.327466
  validation accuracy:		93.15 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.024404
  validation loss:		0.327001
  validation accuracy:		93.37 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.023792
  validation loss:		0.328465
  validation accuracy:		93.59 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.024290
  validation loss:		0.327230
  validation accuracy:		93.26 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.023341
  validation loss:		0.329752
  validation accuracy:		93.37 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.023311
  validation loss:		0.329888
  validation accuracy:		93.37 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.024084
  validation loss:		0.334383
  validation accuracy:		93.04 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.023812
  validation loss:		0.329903
  validation accuracy:		93.26 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.023372
  validation loss:		0.332558
  validation accuracy:		93.26 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.023803
  validation loss:		0.331838
  validation accuracy:		93.15 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.023176
  validation loss:		0.328334
  validation accuracy:		93.37 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.024016
  validation loss:		0.334741
  validation accuracy:		93.15 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.024044
  validation loss:		0.332860
  validation accuracy:		93.26 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.024263
  validation loss:		0.331385
  validation accuracy:		93.15 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.023487
  validation loss:		0.337566
  validation accuracy:		93.15 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.022997
  validation loss:		0.332923
  validation accuracy:		93.26 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.023246
  validation loss:		0.330635
  validation accuracy:		93.26 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.022654
  validation loss:		0.333697
  validation accuracy:		93.26 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.022999
  validation loss:		0.331837
  validation accuracy:		93.04 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.023437
  validation loss:		0.332727
  validation accuracy:		93.26 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.022711
  validation loss:		0.335300
  validation accuracy:		93.15 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.023125
  validation loss:		0.334364
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.022397
  validation loss:		0.333922
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.022220
  validation loss:		0.331188
  validation accuracy:		92.83 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.023187
  validation loss:		0.335954
  validation accuracy:		93.15 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.023215
  validation loss:		0.335656
  validation accuracy:		93.26 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.022415
  validation loss:		0.333388
  validation accuracy:		93.48 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.022835
  validation loss:		0.331619
  validation accuracy:		93.37 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.022860
  validation loss:		0.335642
  validation accuracy:		93.26 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.022732
  validation loss:		0.337940
  validation accuracy:		93.26 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.023038
  validation loss:		0.335517
  validation accuracy:		93.15 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.022645
  validation loss:		0.337150
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.021938
  validation loss:		0.335678
  validation accuracy:		93.15 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.022726
  validation loss:		0.332044
  validation accuracy:		93.37 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.022429
  validation loss:		0.338072
  validation accuracy:		93.15 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.022068
  validation loss:		0.338921
  validation accuracy:		93.15 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.021277
  validation loss:		0.333591
  validation accuracy:		93.37 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.022627
  validation loss:		0.339236
  validation accuracy:		93.15 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.021271
  validation loss:		0.339164
  validation accuracy:		93.04 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.021945
  validation loss:		0.338163
  validation accuracy:		93.15 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.022023
  validation loss:		0.340003
  validation accuracy:		93.15 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.021595
  validation loss:		0.336395
  validation accuracy:		93.48 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.022172
  validation loss:		0.338129
  validation accuracy:		93.48 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.022246
  validation loss:		0.340673
  validation accuracy:		93.26 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.021554
  validation loss:		0.340697
  validation accuracy:		93.26 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.021866
  validation loss:		0.338191
  validation accuracy:		93.15 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.021154
  validation loss:		0.338036
  validation accuracy:		93.26 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.021561
  validation loss:		0.339917
  validation accuracy:		93.04 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.021769
  validation loss:		0.338224
  validation accuracy:		93.26 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.021914
  validation loss:		0.339092
  validation accuracy:		93.26 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.020509
  validation loss:		0.340310
  validation accuracy:		93.26 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.019782
  validation loss:		0.339282
  validation accuracy:		93.04 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.021913
  validation loss:		0.343017
  validation accuracy:		93.15 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.021343
  validation loss:		0.341701
  validation accuracy:		93.15 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.021120
  validation loss:		0.342450
  validation accuracy:		93.59 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.021033
  validation loss:		0.341029
  validation accuracy:		93.26 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.020218
  validation loss:		0.343561
  validation accuracy:		93.26 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.021022
  validation loss:		0.346319
  validation accuracy:		93.26 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.021133
  validation loss:		0.346965
  validation accuracy:		93.26 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.020017
  validation loss:		0.347129
  validation accuracy:		93.04 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.020600
  validation loss:		0.339728
  validation accuracy:		93.26 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.020817
  validation loss:		0.343835
  validation accuracy:		93.15 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.020263
  validation loss:		0.341403
  validation accuracy:		93.15 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.020377
  validation loss:		0.343274
  validation accuracy:		93.15 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.020716
  validation loss:		0.343540
  validation accuracy:		93.26 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.020075
  validation loss:		0.344379
  validation accuracy:		93.37 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.020510
  validation loss:		0.349104
  validation accuracy:		93.04 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.020581
  validation loss:		0.348906
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.020953
  validation loss:		0.348284
  validation accuracy:		93.26 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.020925
  validation loss:		0.345660
  validation accuracy:		93.15 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.020694
  validation loss:		0.344790
  validation accuracy:		93.26 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.020453
  validation loss:		0.345782
  validation accuracy:		93.15 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.019813
  validation loss:		0.343561
  validation accuracy:		92.83 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.020522
  validation loss:		0.349291
  validation accuracy:		93.04 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.020648
  validation loss:		0.343326
  validation accuracy:		93.15 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.019912
  validation loss:		0.342411
  validation accuracy:		93.48 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.020359
  validation loss:		0.346899
  validation accuracy:		93.15 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.020271
  validation loss:		0.349782
  validation accuracy:		93.04 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.019965
  validation loss:		0.347855
  validation accuracy:		93.15 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.020022
  validation loss:		0.349513
  validation accuracy:		93.15 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.020012
  validation loss:		0.345700
  validation accuracy:		93.26 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.019184
  validation loss:		0.349962
  validation accuracy:		93.04 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.018036
  validation loss:		0.347611
  validation accuracy:		93.26 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.020152
  validation loss:		0.345075
  validation accuracy:		93.15 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.019972
  validation loss:		0.346410
  validation accuracy:		93.26 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.020131
  validation loss:		0.344891
  validation accuracy:		93.26 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.019396
  validation loss:		0.348131
  validation accuracy:		93.15 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.019184
  validation loss:		0.346993
  validation accuracy:		93.04 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.018609
  validation loss:		0.352774
  validation accuracy:		93.15 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.019368
  validation loss:		0.348176
  validation accuracy:		93.04 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.019842
  validation loss:		0.353301
  validation accuracy:		93.04 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.019254
  validation loss:		0.352746
  validation accuracy:		93.26 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.018905
  validation loss:		0.348502
  validation accuracy:		93.15 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.018801
  validation loss:		0.354376
  validation accuracy:		93.26 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.019489
  validation loss:		0.355190
  validation accuracy:		93.04 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.019153
  validation loss:		0.350105
  validation accuracy:		93.04 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.018720
  validation loss:		0.347375
  validation accuracy:		93.48 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.019102
  validation loss:		0.353905
  validation accuracy:		93.26 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.018409
  validation loss:		0.353736
  validation accuracy:		93.04 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.018496
  validation loss:		0.352652
  validation accuracy:		93.15 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.019382
  validation loss:		0.348287
  validation accuracy:		93.15 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.018888
  validation loss:		0.351515
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.018508
  validation loss:		0.356553
  validation accuracy:		93.26 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.018816
  validation loss:		0.360539
  validation accuracy:		93.15 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.019049
  validation loss:		0.350248
  validation accuracy:		93.04 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.018292
  validation loss:		0.355021
  validation accuracy:		93.15 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.018226
  validation loss:		0.357186
  validation accuracy:		92.93 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.018373
  validation loss:		0.354580
  validation accuracy:		93.26 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.018564
  validation loss:		0.352304
  validation accuracy:		93.04 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.017529
  validation loss:		0.347240
  validation accuracy:		93.37 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.018898
  validation loss:		0.351827
  validation accuracy:		93.04 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.017450
  validation loss:		0.357608
  validation accuracy:		93.15 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.017926
  validation loss:		0.363563
  validation accuracy:		93.04 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.018723
  validation loss:		0.353673
  validation accuracy:		93.26 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.017771
  validation loss:		0.355569
  validation accuracy:		93.04 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.018517
  validation loss:		0.358577
  validation accuracy:		93.15 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.017077
  validation loss:		0.352860
  validation accuracy:		93.15 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.017603
  validation loss:		0.359979
  validation accuracy:		92.93 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.017749
  validation loss:		0.357057
  validation accuracy:		93.04 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.018416
  validation loss:		0.356809
  validation accuracy:		93.15 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.018336
  validation loss:		0.355776
  validation accuracy:		93.15 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.018196
  validation loss:		0.356413
  validation accuracy:		93.15 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.017926
  validation loss:		0.359118
  validation accuracy:		93.15 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.018297
  validation loss:		0.358763
  validation accuracy:		93.15 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.017899
  validation loss:		0.356121
  validation accuracy:		93.04 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.017531
  validation loss:		0.353077
  validation accuracy:		93.37 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.017929
  validation loss:		0.357430
  validation accuracy:		93.15 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.017274
  validation loss:		0.358091
  validation accuracy:		92.93 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.017492
  validation loss:		0.358306
  validation accuracy:		93.04 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.017447
  validation loss:		0.353498
  validation accuracy:		93.26 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.017354
  validation loss:		0.362682
  validation accuracy:		93.15 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.018155
  validation loss:		0.358965
  validation accuracy:		93.15 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.017866
  validation loss:		0.357533
  validation accuracy:		93.04 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.017692
  validation loss:		0.360975
  validation accuracy:		93.04 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.017397
  validation loss:		0.362637
  validation accuracy:		93.04 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.018210
  validation loss:		0.359674
  validation accuracy:		93.04 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.017167
  validation loss:		0.357174
  validation accuracy:		93.04 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.017284
  validation loss:		0.367538
  validation accuracy:		93.04 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.017057
  validation loss:		0.362181
  validation accuracy:		93.04 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.017273
  validation loss:		0.359893
  validation accuracy:		93.04 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.017435
  validation loss:		0.361327
  validation accuracy:		93.04 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.016847
  validation loss:		0.364191
  validation accuracy:		93.15 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.017035
  validation loss:		0.368546
  validation accuracy:		93.15 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.016563
  validation loss:		0.360846
  validation accuracy:		93.15 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.017352
  validation loss:		0.366985
  validation accuracy:		93.15 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.016787
  validation loss:		0.363517
  validation accuracy:		93.04 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.017486
  validation loss:		0.363951
  validation accuracy:		93.15 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.016921
  validation loss:		0.359046
  validation accuracy:		93.04 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.016138
  validation loss:		0.361648
  validation accuracy:		93.15 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.017081
  validation loss:		0.363281
  validation accuracy:		93.04 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.016613
  validation loss:		0.367888
  validation accuracy:		93.04 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.016733
  validation loss:		0.363431
  validation accuracy:		93.04 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.017647
  validation loss:		0.363633
  validation accuracy:		93.15 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.016564
  validation loss:		0.362790
  validation accuracy:		93.04 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.016703
  validation loss:		0.368213
  validation accuracy:		93.04 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.016726
  validation loss:		0.366663
  validation accuracy:		93.04 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.016706
  validation loss:		0.368580
  validation accuracy:		93.04 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.016553
  validation loss:		0.363485
  validation accuracy:		93.04 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.015947
  validation loss:		0.369428
  validation accuracy:		93.04 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.016505
  validation loss:		0.362973
  validation accuracy:		93.15 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.016523
  validation loss:		0.367319
  validation accuracy:		93.15 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.016105
  validation loss:		0.368358
  validation accuracy:		93.04 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.016807
  validation loss:		0.369355
  validation accuracy:		93.04 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.016233
  validation loss:		0.369482
  validation accuracy:		93.15 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.016318
  validation loss:		0.363987
  validation accuracy:		93.15 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.016047
  validation loss:		0.369770
  validation accuracy:		93.04 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.015806
  validation loss:		0.367590
  validation accuracy:		93.15 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.016330
  validation loss:		0.372919
  validation accuracy:		93.04 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.016631
  validation loss:		0.376044
  validation accuracy:		93.15 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.015351
  validation loss:		0.369551
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.016451
  validation loss:		0.370515
  validation accuracy:		93.15 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.015792
  validation loss:		0.371487
  validation accuracy:		93.04 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.016392
  validation loss:		0.370606
  validation accuracy:		93.04 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.016183
  validation loss:		0.368798
  validation accuracy:		93.15 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.016034
  validation loss:		0.373985
  validation accuracy:		92.93 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.016058
  validation loss:		0.367185
  validation accuracy:		93.15 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.016163
  validation loss:		0.368399
  validation accuracy:		92.93 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.016283
  validation loss:		0.365414
  validation accuracy:		93.04 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.015475
  validation loss:		0.369888
  validation accuracy:		93.15 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.015382
  validation loss:		0.371505
  validation accuracy:		93.04 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.014623
  validation loss:		0.376947
  validation accuracy:		93.04 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.015925
  validation loss:		0.367944
  validation accuracy:		93.04 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.014942
  validation loss:		0.373684
  validation accuracy:		93.15 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.015320
  validation loss:		0.376248
  validation accuracy:		92.83 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.015841
  validation loss:		0.370645
  validation accuracy:		93.04 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.015399
  validation loss:		0.368414
  validation accuracy:		93.04 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.015158
  validation loss:		0.366906
  validation accuracy:		92.93 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.015045
  validation loss:		0.367551
  validation accuracy:		93.37 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.015694
  validation loss:		0.373561
  validation accuracy:		92.83 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.014769
  validation loss:		0.373281
  validation accuracy:		92.93 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.015687
  validation loss:		0.369783
  validation accuracy:		93.04 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.014327
  validation loss:		0.376009
  validation accuracy:		93.15 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.015271
  validation loss:		0.371905
  validation accuracy:		92.93 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.015682
  validation loss:		0.370419
  validation accuracy:		93.04 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.015231
  validation loss:		0.375462
  validation accuracy:		93.04 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.014922
  validation loss:		0.374861
  validation accuracy:		93.04 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.014648
  validation loss:		0.375346
  validation accuracy:		93.04 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.015479
  validation loss:		0.373817
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.014496
  validation loss:		0.378592
  validation accuracy:		92.93 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.015321
  validation loss:		0.378974
  validation accuracy:		93.15 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.015413
  validation loss:		0.378921
  validation accuracy:		93.26 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.015081
  validation loss:		0.373348
  validation accuracy:		92.93 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.015012
  validation loss:		0.373409
  validation accuracy:		93.04 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.014717
  validation loss:		0.377313
  validation accuracy:		92.93 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.015143
  validation loss:		0.375949
  validation accuracy:		93.15 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.015308
  validation loss:		0.380757
  validation accuracy:		93.04 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.015165
  validation loss:		0.375136
  validation accuracy:		93.04 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.015064
  validation loss:		0.381116
  validation accuracy:		92.93 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.014716
  validation loss:		0.373029
  validation accuracy:		93.04 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.014617
  validation loss:		0.384309
  validation accuracy:		93.15 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.014989
  validation loss:		0.378809
  validation accuracy:		93.04 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.014659
  validation loss:		0.380669
  validation accuracy:		93.15 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.015271
  validation loss:		0.379453
  validation accuracy:		93.15 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.014625
  validation loss:		0.379149
  validation accuracy:		93.15 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.014514
  validation loss:		0.377934
  validation accuracy:		93.26 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.014720
  validation loss:		0.373585
  validation accuracy:		93.04 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.014498
  validation loss:		0.375066
  validation accuracy:		93.04 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.014711
  validation loss:		0.376855
  validation accuracy:		93.15 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.013428
  validation loss:		0.382880
  validation accuracy:		93.04 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.014477
  validation loss:		0.380290
  validation accuracy:		93.04 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.014365
  validation loss:		0.379712
  validation accuracy:		92.93 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.014228
  validation loss:		0.377672
  validation accuracy:		93.15 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.014301
  validation loss:		0.381194
  validation accuracy:		93.04 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.013610
  validation loss:		0.378360
  validation accuracy:		93.15 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.014051
  validation loss:		0.382667
  validation accuracy:		93.04 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.014250
  validation loss:		0.378767
  validation accuracy:		93.04 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.014505
  validation loss:		0.381164
  validation accuracy:		93.04 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.013906
  validation loss:		0.379217
  validation accuracy:		92.93 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.014424
  validation loss:		0.377419
  validation accuracy:		93.04 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.014065
  validation loss:		0.381701
  validation accuracy:		93.04 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.014000
  validation loss:		0.380312
  validation accuracy:		92.83 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.014011
  validation loss:		0.387055
  validation accuracy:		93.15 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.014544
  validation loss:		0.389207
  validation accuracy:		93.04 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.013920
  validation loss:		0.385065
  validation accuracy:		92.93 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.014300
  validation loss:		0.383714
  validation accuracy:		92.93 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.013731
  validation loss:		0.389055
  validation accuracy:		93.26 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.013727
  validation loss:		0.381847
  validation accuracy:		93.15 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.013819
  validation loss:		0.379557
  validation accuracy:		93.15 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.014229
  validation loss:		0.379667
  validation accuracy:		93.04 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.013823
  validation loss:		0.384227
  validation accuracy:		92.93 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.013736
  validation loss:		0.384078
  validation accuracy:		93.04 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.013996
  validation loss:		0.391152
  validation accuracy:		93.04 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.013911
  validation loss:		0.390599
  validation accuracy:		92.93 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.013970
  validation loss:		0.389657
  validation accuracy:		92.93 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.014133
  validation loss:		0.386273
  validation accuracy:		93.15 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.013411
  validation loss:		0.385651
  validation accuracy:		93.04 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.013518
  validation loss:		0.382206
  validation accuracy:		92.93 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.013286
  validation loss:		0.385427
  validation accuracy:		93.04 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.013171
  validation loss:		0.387834
  validation accuracy:		93.26 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.012681
  validation loss:		0.386873
  validation accuracy:		93.04 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.013587
  validation loss:		0.384721
  validation accuracy:		93.26 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.013738
  validation loss:		0.389477
  validation accuracy:		93.04 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.013553
  validation loss:		0.390094
  validation accuracy:		93.04 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.013614
  validation loss:		0.383637
  validation accuracy:		93.15 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.013626
  validation loss:		0.391294
  validation accuracy:		93.04 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.013282
  validation loss:		0.387504
  validation accuracy:		93.15 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.013567
  validation loss:		0.387109
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.013469
  validation loss:		0.387614
  validation accuracy:		93.26 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.013381
  validation loss:		0.387436
  validation accuracy:		92.93 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.013255
  validation loss:		0.384018
  validation accuracy:		93.04 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.013419
  validation loss:		0.386463
  validation accuracy:		92.93 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.012845
  validation loss:		0.385316
  validation accuracy:		92.93 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.013165
  validation loss:		0.387335
  validation accuracy:		92.93 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.012504
  validation loss:		0.382615
  validation accuracy:		92.93 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.013320
  validation loss:		0.389639
  validation accuracy:		93.04 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.012865
  validation loss:		0.388909
  validation accuracy:		92.93 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.013118
  validation loss:		0.388975
  validation accuracy:		92.93 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.013363
  validation loss:		0.390521
  validation accuracy:		93.15 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.012467
  validation loss:		0.390423
  validation accuracy:		93.04 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.012366
  validation loss:		0.390653
  validation accuracy:		92.93 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.013025
  validation loss:		0.391801
  validation accuracy:		93.04 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.013132
  validation loss:		0.392708
  validation accuracy:		92.93 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.012188
  validation loss:		0.388274
  validation accuracy:		93.04 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.012605
  validation loss:		0.394804
  validation accuracy:		93.04 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.013070
  validation loss:		0.389719
  validation accuracy:		93.15 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.012149
  validation loss:		0.393125
  validation accuracy:		92.83 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.012550
  validation loss:		0.391291
  validation accuracy:		93.04 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.012578
  validation loss:		0.387681
  validation accuracy:		92.93 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.012633
  validation loss:		0.390584
  validation accuracy:		92.93 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.013052
  validation loss:		0.391858
  validation accuracy:		93.15 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.012591
  validation loss:		0.394115
  validation accuracy:		92.93 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.012139
  validation loss:		0.392974
  validation accuracy:		93.04 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.012896
  validation loss:		0.392380
  validation accuracy:		93.15 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.012552
  validation loss:		0.395937
  validation accuracy:		92.93 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.012440
  validation loss:		0.392708
  validation accuracy:		93.15 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.011964
  validation loss:		0.390554
  validation accuracy:		93.04 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.012631
  validation loss:		0.393103
  validation accuracy:		93.04 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.012133
  validation loss:		0.392126
  validation accuracy:		92.93 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.012232
  validation loss:		0.398200
  validation accuracy:		93.04 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.012544
  validation loss:		0.395841
  validation accuracy:		93.04 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.012380
  validation loss:		0.399330
  validation accuracy:		93.04 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.012294
  validation loss:		0.393066
  validation accuracy:		92.93 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.012583
  validation loss:		0.389509
  validation accuracy:		93.04 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.012566
  validation loss:		0.389994
  validation accuracy:		93.15 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.012256
  validation loss:		0.394012
  validation accuracy:		93.04 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.011646
  validation loss:		0.402158
  validation accuracy:		92.93 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.012382
  validation loss:		0.397164
  validation accuracy:		93.04 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.012228
  validation loss:		0.389198
  validation accuracy:		93.15 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.012435
  validation loss:		0.393644
  validation accuracy:		92.93 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.011579
  validation loss:		0.394009
  validation accuracy:		92.83 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.012141
  validation loss:		0.397949
  validation accuracy:		92.93 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.011942
  validation loss:		0.398045
  validation accuracy:		93.04 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.012203
  validation loss:		0.398475
  validation accuracy:		92.93 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.011973
  validation loss:		0.398760
  validation accuracy:		92.93 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.012063
  validation loss:		0.395133
  validation accuracy:		93.15 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.012056
  validation loss:		0.402835
  validation accuracy:		93.04 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.012122
  validation loss:		0.400510
  validation accuracy:		92.83 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.011201
  validation loss:		0.396624
  validation accuracy:		93.15 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.012046
  validation loss:		0.401224
  validation accuracy:		93.04 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.011816
  validation loss:		0.401540
  validation accuracy:		92.93 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.012204
  validation loss:		0.398921
  validation accuracy:		92.83 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.011758
  validation loss:		0.392788
  validation accuracy:		93.26 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.012400
  validation loss:		0.396523
  validation accuracy:		92.83 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.012225
  validation loss:		0.397638
  validation accuracy:		92.93 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.011542
  validation loss:		0.404698
  validation accuracy:		92.93 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.011499
  validation loss:		0.397768
  validation accuracy:		93.04 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.011200
  validation loss:		0.402449
  validation accuracy:		93.04 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.011710
  validation loss:		0.397242
  validation accuracy:		92.93 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.011856
  validation loss:		0.407105
  validation accuracy:		93.04 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.012145
  validation loss:		0.403725
  validation accuracy:		92.93 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.012304
  validation loss:		0.400352
  validation accuracy:		93.15 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.011483
  validation loss:		0.396629
  validation accuracy:		93.26 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.011192
  validation loss:		0.406378
  validation accuracy:		93.04 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.011336
  validation loss:		0.404034
  validation accuracy:		93.04 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.011715
  validation loss:		0.397586
  validation accuracy:		93.04 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.012049
  validation loss:		0.396877
  validation accuracy:		92.93 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.010701
  validation loss:		0.404683
  validation accuracy:		93.04 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.011157
  validation loss:		0.408357
  validation accuracy:		92.93 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.011703
  validation loss:		0.401258
  validation accuracy:		93.04 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.011188
  validation loss:		0.403069
  validation accuracy:		92.93 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.011384
  validation loss:		0.408720
  validation accuracy:		93.04 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.011213
  validation loss:		0.402214
  validation accuracy:		92.93 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.011581
  validation loss:		0.400485
  validation accuracy:		93.04 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.011357
  validation loss:		0.408632
  validation accuracy:		93.04 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.010629
  validation loss:		0.405559
  validation accuracy:		93.04 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.011530
  validation loss:		0.402897
  validation accuracy:		92.93 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.011167
  validation loss:		0.402977
  validation accuracy:		92.93 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.011035
  validation loss:		0.402464
  validation accuracy:		93.26 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.011337
  validation loss:		0.407504
  validation accuracy:		92.93 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.011183
  validation loss:		0.400741
  validation accuracy:		93.04 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.011175
  validation loss:		0.406898
  validation accuracy:		93.04 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.010893
  validation loss:		0.403686
  validation accuracy:		92.83 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.010541
  validation loss:		0.404807
  validation accuracy:		92.93 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.011053
  validation loss:		0.407297
  validation accuracy:		93.04 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.010853
  validation loss:		0.409045
  validation accuracy:		93.04 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.011236
  validation loss:		0.411116
  validation accuracy:		92.83 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.010737
  validation loss:		0.407920
  validation accuracy:		93.04 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.010636
  validation loss:		0.408899
  validation accuracy:		92.93 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.010798
  validation loss:		0.406067
  validation accuracy:		92.93 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.010706
  validation loss:		0.405679
  validation accuracy:		93.04 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.010864
  validation loss:		0.408603
  validation accuracy:		93.04 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.010771
  validation loss:		0.410336
  validation accuracy:		92.93 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.010727
  validation loss:		0.403739
  validation accuracy:		92.93 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.010864
  validation loss:		0.409002
  validation accuracy:		93.15 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.010687
  validation loss:		0.408477
  validation accuracy:		92.72 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.010959
  validation loss:		0.411774
  validation accuracy:		92.93 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.010994
  validation loss:		0.405761
  validation accuracy:		93.04 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.010601
  validation loss:		0.407079
  validation accuracy:		93.15 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.010709
  validation loss:		0.406891
  validation accuracy:		92.72 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.010752
  validation loss:		0.409634
  validation accuracy:		93.04 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.010366
  validation loss:		0.405567
  validation accuracy:		92.83 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.010695
  validation loss:		0.407675
  validation accuracy:		93.04 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.010518
  validation loss:		0.408591
  validation accuracy:		93.04 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.010212
  validation loss:		0.404780
  validation accuracy:		93.15 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.010279
  validation loss:		0.412794
  validation accuracy:		93.04 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.010444
  validation loss:		0.407275
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.010492
  validation loss:		0.406636
  validation accuracy:		92.83 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.010598
  validation loss:		0.413280
  validation accuracy:		92.83 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.010656
  validation loss:		0.406540
  validation accuracy:		92.93 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.010180
  validation loss:		0.413273
  validation accuracy:		92.83 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.010446
  validation loss:		0.412945
  validation accuracy:		92.93 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.009696
  validation loss:		0.410979
  validation accuracy:		93.04 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.010163
  validation loss:		0.410464
  validation accuracy:		92.83 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.010294
  validation loss:		0.408800
  validation accuracy:		92.93 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.010313
  validation loss:		0.413149
  validation accuracy:		92.93 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.010192
  validation loss:		0.407381
  validation accuracy:		92.93 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.010458
  validation loss:		0.411754
  validation accuracy:		92.83 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.010249
  validation loss:		0.410621
  validation accuracy:		92.83 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.010219
  validation loss:		0.412625
  validation accuracy:		93.04 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.009966
  validation loss:		0.414082
  validation accuracy:		93.04 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.010085
  validation loss:		0.412649
  validation accuracy:		92.83 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.010088
  validation loss:		0.416981
  validation accuracy:		92.93 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.010147
  validation loss:		0.409550
  validation accuracy:		92.61 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.010080
  validation loss:		0.415656
  validation accuracy:		93.04 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.010147
  validation loss:		0.417477
  validation accuracy:		92.93 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.010184
  validation loss:		0.415732
  validation accuracy:		93.04 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.010450
  validation loss:		0.413402
  validation accuracy:		92.72 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.010385
  validation loss:		0.411022
  validation accuracy:		92.61 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.010267
  validation loss:		0.413631
  validation accuracy:		93.04 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.010180
  validation loss:		0.416093
  validation accuracy:		92.93 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.009766
  validation loss:		0.418349
  validation accuracy:		92.93 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.010239
  validation loss:		0.414900
  validation accuracy:		92.72 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.009869
  validation loss:		0.415862
  validation accuracy:		92.83 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.009998
  validation loss:		0.419550
  validation accuracy:		93.04 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.009957
  validation loss:		0.413018
  validation accuracy:		93.04 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.010049
  validation loss:		0.414858
  validation accuracy:		92.93 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.009998
  validation loss:		0.417274
  validation accuracy:		92.83 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.009636
  validation loss:		0.415237
  validation accuracy:		92.93 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.009596
  validation loss:		0.416401
  validation accuracy:		92.83 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.010013
  validation loss:		0.416699
  validation accuracy:		93.04 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.009593
  validation loss:		0.415338
  validation accuracy:		92.72 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.009874
  validation loss:		0.416867
  validation accuracy:		92.83 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.009685
  validation loss:		0.419192
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.009786
  validation loss:		0.415588
  validation accuracy:		92.83 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.009594
  validation loss:		0.416757
  validation accuracy:		92.72 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.009363
  validation loss:		0.418898
  validation accuracy:		92.93 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.009755
  validation loss:		0.415434
  validation accuracy:		92.93 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.009686
  validation loss:		0.420894
  validation accuracy:		93.26 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.009980
  validation loss:		0.419809
  validation accuracy:		92.93 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.009764
  validation loss:		0.414776
  validation accuracy:		92.61 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.009416
  validation loss:		0.420280
  validation accuracy:		92.93 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.009143
  validation loss:		0.416741
  validation accuracy:		92.72 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.009979
  validation loss:		0.417085
  validation accuracy:		92.72 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.009735
  validation loss:		0.424096
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.008932
  validation loss:		0.422961
  validation accuracy:		92.93 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.009542
  validation loss:		0.422728
  validation accuracy:		92.93 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.009873
  validation loss:		0.422084
  validation accuracy:		92.72 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.009777
  validation loss:		0.422820
  validation accuracy:		92.83 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.009192
  validation loss:		0.417400
  validation accuracy:		92.72 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.009380
  validation loss:		0.423613
  validation accuracy:		92.83 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.009383
  validation loss:		0.418420
  validation accuracy:		92.83 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.009427
  validation loss:		0.419852
  validation accuracy:		92.72 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.009307
  validation loss:		0.424691
  validation accuracy:		93.04 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.009257
  validation loss:		0.417428
  validation accuracy:		92.72 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.009061
  validation loss:		0.423283
  validation accuracy:		92.83 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.009206
  validation loss:		0.420520
  validation accuracy:		92.72 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.009222
  validation loss:		0.419716
  validation accuracy:		92.83 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.009219
  validation loss:		0.419483
  validation accuracy:		92.72 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.009163
  validation loss:		0.420350
  validation accuracy:		92.72 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.009129
  validation loss:		0.420722
  validation accuracy:		92.61 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.009087
  validation loss:		0.426994
  validation accuracy:		92.93 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.009456
  validation loss:		0.425656
  validation accuracy:		92.93 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.009323
  validation loss:		0.426826
  validation accuracy:		92.83 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.009254
  validation loss:		0.423792
  validation accuracy:		92.83 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.009237
  validation loss:		0.423158
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.008977
  validation loss:		0.423278
  validation accuracy:		92.83 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.009117
  validation loss:		0.419170
  validation accuracy:		92.72 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.008962
  validation loss:		0.419085
  validation accuracy:		93.04 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.009169
  validation loss:		0.421513
  validation accuracy:		92.93 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.008842
  validation loss:		0.424471
  validation accuracy:		92.83 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.008693
  validation loss:		0.425067
  validation accuracy:		92.72 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.008942
  validation loss:		0.423822
  validation accuracy:		92.83 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.009054
  validation loss:		0.422874
  validation accuracy:		92.72 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.008823
  validation loss:		0.427545
  validation accuracy:		92.83 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.008751
  validation loss:		0.431804
  validation accuracy:		92.83 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.009040
  validation loss:		0.426625
  validation accuracy:		92.72 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.008611
  validation loss:		0.431598
  validation accuracy:		92.83 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.009113
  validation loss:		0.422891
  validation accuracy:		93.04 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.009035
  validation loss:		0.418455
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.009067
  validation loss:		0.429329
  validation accuracy:		92.72 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.008634
  validation loss:		0.430991
  validation accuracy:		92.72 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.008765
  validation loss:		0.427633
  validation accuracy:		92.93 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.008553
  validation loss:		0.428251
  validation accuracy:		92.83 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.008823
  validation loss:		0.429738
  validation accuracy:		92.72 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.008762
  validation loss:		0.422147
  validation accuracy:		92.93 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.008546
  validation loss:		0.426765
  validation accuracy:		92.83 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.008613
  validation loss:		0.429419
  validation accuracy:		92.83 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.008292
  validation loss:		0.427582
  validation accuracy:		93.04 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.008829
  validation loss:		0.428191
  validation accuracy:		93.04 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.008808
  validation loss:		0.431611
  validation accuracy:		92.93 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.008708
  validation loss:		0.427325
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.008887
  validation loss:		0.427102
  validation accuracy:		92.72 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.008058
  validation loss:		0.432735
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.008712
  validation loss:		0.429947
  validation accuracy:		92.72 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.008861
  validation loss:		0.426601
  validation accuracy:		92.83 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.008458
  validation loss:		0.427525
  validation accuracy:		92.61 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.008440
  validation loss:		0.428431
  validation accuracy:		92.72 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.008813
  validation loss:		0.430191
  validation accuracy:		92.61 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.008758
  validation loss:		0.436283
  validation accuracy:		92.93 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.008905
  validation loss:		0.427524
  validation accuracy:		92.72 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.008578
  validation loss:		0.427717
  validation accuracy:		92.83 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.008426
  validation loss:		0.427584
  validation accuracy:		92.72 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.008748
  validation loss:		0.428591
  validation accuracy:		92.83 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.008476
  validation loss:		0.429505
  validation accuracy:		92.72 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.008301
  validation loss:		0.435184
  validation accuracy:		92.72 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.008853
  validation loss:		0.433583
  validation accuracy:		92.93 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.008518
  validation loss:		0.432089
  validation accuracy:		92.61 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.008302
  validation loss:		0.428768
  validation accuracy:		92.61 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.008309
  validation loss:		0.437694
  validation accuracy:		92.72 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.008376
  validation loss:		0.434665
  validation accuracy:		92.93 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.008320
  validation loss:		0.433059
  validation accuracy:		92.72 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.008405
  validation loss:		0.435616
  validation accuracy:		92.93 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.008142
  validation loss:		0.430981
  validation accuracy:		92.72 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.008024
  validation loss:		0.432907
  validation accuracy:		92.61 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.008378
  validation loss:		0.428180
  validation accuracy:		92.93 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.008104
  validation loss:		0.430237
  validation accuracy:		92.72 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.008509
  validation loss:		0.433315
  validation accuracy:		92.83 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.008076
  validation loss:		0.435167
  validation accuracy:		92.83 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.008305
  validation loss:		0.431596
  validation accuracy:		92.83 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.007991
  validation loss:		0.436961
  validation accuracy:		92.83 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.008276
  validation loss:		0.430619
  validation accuracy:		92.61 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.008097
  validation loss:		0.433852
  validation accuracy:		92.72 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.008084
  validation loss:		0.441529
  validation accuracy:		92.72 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.008138
  validation loss:		0.435923
  validation accuracy:		92.72 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.008250
  validation loss:		0.432784
  validation accuracy:		92.72 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.008082
  validation loss:		0.438167
  validation accuracy:		92.61 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.008105
  validation loss:		0.433203
  validation accuracy:		92.61 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.007747
  validation loss:		0.431780
  validation accuracy:		92.93 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.007886
  validation loss:		0.437762
  validation accuracy:		92.72 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.008077
  validation loss:		0.438508
  validation accuracy:		92.72 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.008062
  validation loss:		0.437493
  validation accuracy:		92.72 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.008071
  validation loss:		0.442154
  validation accuracy:		92.93 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.007780
  validation loss:		0.438670
  validation accuracy:		92.61 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.008081
  validation loss:		0.437735
  validation accuracy:		92.61 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.007941
  validation loss:		0.435285
  validation accuracy:		92.72 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.008267
  validation loss:		0.435929
  validation accuracy:		92.72 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.007831
  validation loss:		0.442676
  validation accuracy:		92.83 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.007963
  validation loss:		0.438963
  validation accuracy:		92.83 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.008308
  validation loss:		0.439672
  validation accuracy:		92.72 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.007842
  validation loss:		0.439946
  validation accuracy:		92.72 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.007703
  validation loss:		0.439156
  validation accuracy:		92.72 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.008011
  validation loss:		0.439528
  validation accuracy:		92.61 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.007724
  validation loss:		0.434936
  validation accuracy:		92.72 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.007755
  validation loss:		0.436531
  validation accuracy:		92.72 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007850
  validation loss:		0.438018
  validation accuracy:		92.83 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.007687
  validation loss:		0.441934
  validation accuracy:		92.72 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.007878
  validation loss:		0.432658
  validation accuracy:		92.72 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.007780
  validation loss:		0.440174
  validation accuracy:		92.93 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.007797
  validation loss:		0.437890
  validation accuracy:		92.72 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.007702
  validation loss:		0.436995
  validation accuracy:		92.83 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.007940
  validation loss:		0.438852
  validation accuracy:		92.61 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.007397
  validation loss:		0.438590
  validation accuracy:		92.72 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.007760
  validation loss:		0.441700
  validation accuracy:		92.72 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007756
  validation loss:		0.440658
  validation accuracy:		92.61 %
Epoch 1461 of 2000 took 0.037s
  training loss:		0.007779
  validation loss:		0.440132
  validation accuracy:		92.61 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.007571
  validation loss:		0.444411
  validation accuracy:		92.72 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.007850
  validation loss:		0.443821
  validation accuracy:		92.83 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.007756
  validation loss:		0.442921
  validation accuracy:		92.72 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.007415
  validation loss:		0.438271
  validation accuracy:		92.72 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.007189
  validation loss:		0.437000
  validation accuracy:		92.83 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.007792
  validation loss:		0.439499
  validation accuracy:		92.72 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.007423
  validation loss:		0.436526
  validation accuracy:		92.72 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.007351
  validation loss:		0.444748
  validation accuracy:		92.72 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007494
  validation loss:		0.441706
  validation accuracy:		92.93 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.007342
  validation loss:		0.440926
  validation accuracy:		92.61 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.007552
  validation loss:		0.450066
  validation accuracy:		92.83 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007372
  validation loss:		0.442026
  validation accuracy:		92.61 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007408
  validation loss:		0.441449
  validation accuracy:		92.83 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.007562
  validation loss:		0.443598
  validation accuracy:		92.72 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.007335
  validation loss:		0.441597
  validation accuracy:		92.83 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.007423
  validation loss:		0.443147
  validation accuracy:		92.83 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.007454
  validation loss:		0.442368
  validation accuracy:		92.61 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.007247
  validation loss:		0.437766
  validation accuracy:		92.61 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.007527
  validation loss:		0.445774
  validation accuracy:		92.83 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.006842
  validation loss:		0.444838
  validation accuracy:		92.83 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.007326
  validation loss:		0.443059
  validation accuracy:		92.61 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.007156
  validation loss:		0.443054
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.007471
  validation loss:		0.443740
  validation accuracy:		92.72 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.007356
  validation loss:		0.447735
  validation accuracy:		92.93 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.007066
  validation loss:		0.440438
  validation accuracy:		92.83 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.007131
  validation loss:		0.444327
  validation accuracy:		92.83 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.007409
  validation loss:		0.446039
  validation accuracy:		92.83 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.007462
  validation loss:		0.453044
  validation accuracy:		92.83 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.007681
  validation loss:		0.445458
  validation accuracy:		92.72 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.007056
  validation loss:		0.446073
  validation accuracy:		92.93 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.006818
  validation loss:		0.443173
  validation accuracy:		92.61 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.007299
  validation loss:		0.445587
  validation accuracy:		92.72 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.007201
  validation loss:		0.448023
  validation accuracy:		92.61 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.007071
  validation loss:		0.441417
  validation accuracy:		92.83 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.007309
  validation loss:		0.447627
  validation accuracy:		92.61 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.007127
  validation loss:		0.450143
  validation accuracy:		92.61 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.007190
  validation loss:		0.450690
  validation accuracy:		92.72 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.007509
  validation loss:		0.448081
  validation accuracy:		92.72 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.007183
  validation loss:		0.446267
  validation accuracy:		92.72 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.007287
  validation loss:		0.448139
  validation accuracy:		92.61 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.007075
  validation loss:		0.449176
  validation accuracy:		92.72 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.007225
  validation loss:		0.450491
  validation accuracy:		92.72 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.007011
  validation loss:		0.448060
  validation accuracy:		92.72 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.006980
  validation loss:		0.446127
  validation accuracy:		92.61 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.006917
  validation loss:		0.453054
  validation accuracy:		92.72 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.007108
  validation loss:		0.446525
  validation accuracy:		92.50 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.007117
  validation loss:		0.448379
  validation accuracy:		92.61 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.006901
  validation loss:		0.449018
  validation accuracy:		92.72 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.006973
  validation loss:		0.450289
  validation accuracy:		92.61 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.007057
  validation loss:		0.445176
  validation accuracy:		92.72 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.006780
  validation loss:		0.447932
  validation accuracy:		92.61 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.006768
  validation loss:		0.449510
  validation accuracy:		92.72 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.006946
  validation loss:		0.446573
  validation accuracy:		92.61 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.006784
  validation loss:		0.452787
  validation accuracy:		92.61 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.007138
  validation loss:		0.449427
  validation accuracy:		92.72 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.006904
  validation loss:		0.449881
  validation accuracy:		92.61 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.006875
  validation loss:		0.451131
  validation accuracy:		92.72 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.006733
  validation loss:		0.449888
  validation accuracy:		92.72 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.006813
  validation loss:		0.450619
  validation accuracy:		92.61 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.006914
  validation loss:		0.453633
  validation accuracy:		92.72 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.006578
  validation loss:		0.449228
  validation accuracy:		92.61 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.006709
  validation loss:		0.457481
  validation accuracy:		92.83 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.006961
  validation loss:		0.454572
  validation accuracy:		92.61 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.007334
  validation loss:		0.451965
  validation accuracy:		92.72 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.006862
  validation loss:		0.452490
  validation accuracy:		92.61 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.007448
  validation loss:		0.453053
  validation accuracy:		92.61 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.006984
  validation loss:		0.454980
  validation accuracy:		92.61 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.006814
  validation loss:		0.451336
  validation accuracy:		92.61 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.006842
  validation loss:		0.454825
  validation accuracy:		92.72 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006776
  validation loss:		0.452876
  validation accuracy:		92.83 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.006669
  validation loss:		0.450862
  validation accuracy:		92.61 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.006615
  validation loss:		0.454205
  validation accuracy:		92.72 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006701
  validation loss:		0.457157
  validation accuracy:		92.93 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.007066
  validation loss:		0.452812
  validation accuracy:		92.72 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.006858
  validation loss:		0.448851
  validation accuracy:		92.72 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.006566
  validation loss:		0.452777
  validation accuracy:		92.72 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.006650
  validation loss:		0.453711
  validation accuracy:		92.83 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006730
  validation loss:		0.453464
  validation accuracy:		92.61 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.006624
  validation loss:		0.453028
  validation accuracy:		92.61 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006695
  validation loss:		0.456033
  validation accuracy:		92.72 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.006366
  validation loss:		0.451635
  validation accuracy:		92.72 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.006640
  validation loss:		0.453382
  validation accuracy:		92.72 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.006526
  validation loss:		0.454150
  validation accuracy:		92.61 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006609
  validation loss:		0.456545
  validation accuracy:		92.61 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.006476
  validation loss:		0.457771
  validation accuracy:		92.72 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006641
  validation loss:		0.458611
  validation accuracy:		92.50 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006485
  validation loss:		0.458441
  validation accuracy:		92.61 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.006753
  validation loss:		0.454152
  validation accuracy:		92.72 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006299
  validation loss:		0.457269
  validation accuracy:		92.83 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.006619
  validation loss:		0.458160
  validation accuracy:		92.61 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006665
  validation loss:		0.453630
  validation accuracy:		92.50 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.006544
  validation loss:		0.457698
  validation accuracy:		92.93 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006442
  validation loss:		0.457425
  validation accuracy:		92.61 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006502
  validation loss:		0.458967
  validation accuracy:		92.61 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.006352
  validation loss:		0.457409
  validation accuracy:		92.61 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006394
  validation loss:		0.456543
  validation accuracy:		92.72 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006000
  validation loss:		0.455302
  validation accuracy:		92.83 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.006593
  validation loss:		0.454781
  validation accuracy:		92.72 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006347
  validation loss:		0.462733
  validation accuracy:		92.72 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.006198
  validation loss:		0.461138
  validation accuracy:		92.61 %
Epoch 1562 of 2000 took 0.036s
  training loss:		0.006407
  validation loss:		0.459802
  validation accuracy:		92.83 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.006284
  validation loss:		0.459252
  validation accuracy:		92.61 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.006584
  validation loss:		0.457219
  validation accuracy:		92.72 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.006386
  validation loss:		0.462891
  validation accuracy:		92.72 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.006221
  validation loss:		0.458271
  validation accuracy:		92.83 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.006548
  validation loss:		0.454886
  validation accuracy:		92.72 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006454
  validation loss:		0.458562
  validation accuracy:		92.83 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006188
  validation loss:		0.457711
  validation accuracy:		92.72 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.006275
  validation loss:		0.464428
  validation accuracy:		92.61 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.006240
  validation loss:		0.460315
  validation accuracy:		92.72 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.006163
  validation loss:		0.463573
  validation accuracy:		92.61 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.006319
  validation loss:		0.462133
  validation accuracy:		92.93 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006299
  validation loss:		0.459768
  validation accuracy:		92.61 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.006285
  validation loss:		0.465000
  validation accuracy:		92.72 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.006441
  validation loss:		0.459179
  validation accuracy:		92.61 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.006399
  validation loss:		0.460927
  validation accuracy:		92.83 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005948
  validation loss:		0.462807
  validation accuracy:		92.61 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.006164
  validation loss:		0.461711
  validation accuracy:		92.72 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.006048
  validation loss:		0.461784
  validation accuracy:		92.61 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.006006
  validation loss:		0.456826
  validation accuracy:		92.72 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.006311
  validation loss:		0.463127
  validation accuracy:		92.61 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.006078
  validation loss:		0.460136
  validation accuracy:		92.50 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.006029
  validation loss:		0.464776
  validation accuracy:		92.61 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.006168
  validation loss:		0.463523
  validation accuracy:		92.72 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.006029
  validation loss:		0.461206
  validation accuracy:		92.61 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.006064
  validation loss:		0.461725
  validation accuracy:		92.72 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.006100
  validation loss:		0.460607
  validation accuracy:		92.61 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.005796
  validation loss:		0.461548
  validation accuracy:		92.83 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.006002
  validation loss:		0.463446
  validation accuracy:		92.72 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.006089
  validation loss:		0.462023
  validation accuracy:		92.72 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.006082
  validation loss:		0.462973
  validation accuracy:		92.72 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.005908
  validation loss:		0.462670
  validation accuracy:		92.61 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006099
  validation loss:		0.464344
  validation accuracy:		92.61 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005777
  validation loss:		0.460587
  validation accuracy:		92.61 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.005943
  validation loss:		0.461470
  validation accuracy:		92.61 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.006004
  validation loss:		0.470101
  validation accuracy:		92.61 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.006118
  validation loss:		0.464502
  validation accuracy:		92.72 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.005901
  validation loss:		0.458636
  validation accuracy:		92.72 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.005989
  validation loss:		0.463741
  validation accuracy:		92.61 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.006044
  validation loss:		0.468650
  validation accuracy:		92.61 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.005943
  validation loss:		0.466622
  validation accuracy:		92.83 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005738
  validation loss:		0.461016
  validation accuracy:		92.72 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005981
  validation loss:		0.470422
  validation accuracy:		92.72 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005914
  validation loss:		0.465702
  validation accuracy:		92.61 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.005774
  validation loss:		0.464066
  validation accuracy:		92.72 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.006028
  validation loss:		0.468779
  validation accuracy:		92.93 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.006131
  validation loss:		0.468411
  validation accuracy:		92.61 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005938
  validation loss:		0.467833
  validation accuracy:		92.61 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.005924
  validation loss:		0.466424
  validation accuracy:		92.61 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.005862
  validation loss:		0.464897
  validation accuracy:		92.83 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005869
  validation loss:		0.471939
  validation accuracy:		92.72 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.006075
  validation loss:		0.469760
  validation accuracy:		92.83 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.005900
  validation loss:		0.468328
  validation accuracy:		92.93 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.005830
  validation loss:		0.467947
  validation accuracy:		92.72 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.005675
  validation loss:		0.471399
  validation accuracy:		92.83 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.005866
  validation loss:		0.468090
  validation accuracy:		92.72 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005867
  validation loss:		0.463843
  validation accuracy:		92.61 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.005863
  validation loss:		0.469709
  validation accuracy:		92.61 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.005981
  validation loss:		0.468703
  validation accuracy:		92.72 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005619
  validation loss:		0.471305
  validation accuracy:		92.72 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.005739
  validation loss:		0.470759
  validation accuracy:		92.61 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.005771
  validation loss:		0.466675
  validation accuracy:		92.72 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.005807
  validation loss:		0.473947
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.005788
  validation loss:		0.471465
  validation accuracy:		92.72 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.005667
  validation loss:		0.466885
  validation accuracy:		92.72 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005807
  validation loss:		0.474988
  validation accuracy:		92.72 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005682
  validation loss:		0.468034
  validation accuracy:		92.72 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.005778
  validation loss:		0.474422
  validation accuracy:		92.72 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.005709
  validation loss:		0.473886
  validation accuracy:		92.83 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005923
  validation loss:		0.470228
  validation accuracy:		92.83 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005673
  validation loss:		0.468383
  validation accuracy:		92.61 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.005611
  validation loss:		0.471747
  validation accuracy:		92.72 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.005755
  validation loss:		0.468159
  validation accuracy:		92.72 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005613
  validation loss:		0.468838
  validation accuracy:		92.72 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005571
  validation loss:		0.476614
  validation accuracy:		92.61 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005724
  validation loss:		0.472443
  validation accuracy:		92.61 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.005579
  validation loss:		0.469137
  validation accuracy:		92.72 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005566
  validation loss:		0.469687
  validation accuracy:		92.72 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005703
  validation loss:		0.471302
  validation accuracy:		92.72 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.005697
  validation loss:		0.471910
  validation accuracy:		92.72 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005703
  validation loss:		0.474567
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005676
  validation loss:		0.472015
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005572
  validation loss:		0.471596
  validation accuracy:		92.72 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.475663
  validation accuracy:		92.61 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.005464
  validation loss:		0.472895
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.005514
  validation loss:		0.472488
  validation accuracy:		92.72 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.005473
  validation loss:		0.474479
  validation accuracy:		92.72 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005671
  validation loss:		0.477074
  validation accuracy:		92.93 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005482
  validation loss:		0.472464
  validation accuracy:		92.72 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005539
  validation loss:		0.474390
  validation accuracy:		92.72 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005509
  validation loss:		0.472917
  validation accuracy:		92.83 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005750
  validation loss:		0.473717
  validation accuracy:		92.61 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005695
  validation loss:		0.473851
  validation accuracy:		92.61 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.005330
  validation loss:		0.474941
  validation accuracy:		92.72 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.005469
  validation loss:		0.474407
  validation accuracy:		92.72 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005371
  validation loss:		0.469899
  validation accuracy:		92.72 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005468
  validation loss:		0.476687
  validation accuracy:		92.83 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005357
  validation loss:		0.473815
  validation accuracy:		92.72 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005523
  validation loss:		0.473957
  validation accuracy:		92.72 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.005287
  validation loss:		0.470959
  validation accuracy:		92.93 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.005594
  validation loss:		0.471473
  validation accuracy:		92.72 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005539
  validation loss:		0.478705
  validation accuracy:		92.72 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.005499
  validation loss:		0.475100
  validation accuracy:		92.72 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.005540
  validation loss:		0.472630
  validation accuracy:		92.72 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.005299
  validation loss:		0.478041
  validation accuracy:		92.72 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.005475
  validation loss:		0.477892
  validation accuracy:		92.72 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005361
  validation loss:		0.477813
  validation accuracy:		92.83 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005289
  validation loss:		0.477174
  validation accuracy:		92.72 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005323
  validation loss:		0.481512
  validation accuracy:		92.61 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005347
  validation loss:		0.478495
  validation accuracy:		92.72 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005314
  validation loss:		0.478993
  validation accuracy:		92.61 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.005315
  validation loss:		0.479960
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.005325
  validation loss:		0.476925
  validation accuracy:		92.72 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005370
  validation loss:		0.479617
  validation accuracy:		92.61 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005471
  validation loss:		0.475691
  validation accuracy:		92.72 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.005253
  validation loss:		0.476895
  validation accuracy:		92.83 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005215
  validation loss:		0.474968
  validation accuracy:		92.83 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.005203
  validation loss:		0.477258
  validation accuracy:		92.72 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005288
  validation loss:		0.474747
  validation accuracy:		92.72 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.005164
  validation loss:		0.483300
  validation accuracy:		92.72 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.005263
  validation loss:		0.478674
  validation accuracy:		92.72 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005313
  validation loss:		0.486265
  validation accuracy:		92.72 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.005159
  validation loss:		0.478210
  validation accuracy:		92.72 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.005261
  validation loss:		0.475830
  validation accuracy:		92.72 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005151
  validation loss:		0.477264
  validation accuracy:		92.61 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.005404
  validation loss:		0.478356
  validation accuracy:		92.72 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005410
  validation loss:		0.479680
  validation accuracy:		92.72 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.005060
  validation loss:		0.477865
  validation accuracy:		92.72 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005377
  validation loss:		0.483610
  validation accuracy:		92.83 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.005267
  validation loss:		0.483825
  validation accuracy:		92.72 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.005117
  validation loss:		0.476857
  validation accuracy:		92.72 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.005354
  validation loss:		0.474303
  validation accuracy:		92.83 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.005072
  validation loss:		0.481033
  validation accuracy:		92.83 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.005066
  validation loss:		0.479543
  validation accuracy:		92.72 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.005158
  validation loss:		0.483339
  validation accuracy:		92.83 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.005284
  validation loss:		0.481615
  validation accuracy:		92.61 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.005263
  validation loss:		0.480456
  validation accuracy:		92.72 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005111
  validation loss:		0.483060
  validation accuracy:		92.83 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.005069
  validation loss:		0.479292
  validation accuracy:		92.72 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004917
  validation loss:		0.484614
  validation accuracy:		92.72 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.005090
  validation loss:		0.479971
  validation accuracy:		92.72 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005176
  validation loss:		0.484981
  validation accuracy:		92.72 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.005023
  validation loss:		0.484642
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004987
  validation loss:		0.480478
  validation accuracy:		92.72 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004757
  validation loss:		0.481756
  validation accuracy:		92.83 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.005063
  validation loss:		0.482415
  validation accuracy:		92.83 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.005110
  validation loss:		0.480653
  validation accuracy:		92.72 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004955
  validation loss:		0.487254
  validation accuracy:		92.72 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005137
  validation loss:		0.482883
  validation accuracy:		92.72 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004988
  validation loss:		0.483028
  validation accuracy:		92.83 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004870
  validation loss:		0.481296
  validation accuracy:		92.72 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.005012
  validation loss:		0.486092
  validation accuracy:		92.61 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.005127
  validation loss:		0.484716
  validation accuracy:		92.72 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004880
  validation loss:		0.487897
  validation accuracy:		92.72 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004946
  validation loss:		0.480618
  validation accuracy:		92.72 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004920
  validation loss:		0.489523
  validation accuracy:		92.72 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.005153
  validation loss:		0.482036
  validation accuracy:		92.72 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004838
  validation loss:		0.482631
  validation accuracy:		92.72 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005024
  validation loss:		0.488609
  validation accuracy:		92.61 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004802
  validation loss:		0.483452
  validation accuracy:		92.72 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004953
  validation loss:		0.485362
  validation accuracy:		92.72 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004913
  validation loss:		0.485410
  validation accuracy:		92.72 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.005001
  validation loss:		0.482965
  validation accuracy:		92.93 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004806
  validation loss:		0.484797
  validation accuracy:		92.72 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004884
  validation loss:		0.482638
  validation accuracy:		92.72 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004898
  validation loss:		0.487720
  validation accuracy:		92.61 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004973
  validation loss:		0.487876
  validation accuracy:		92.72 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004942
  validation loss:		0.484001
  validation accuracy:		92.83 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004981
  validation loss:		0.488334
  validation accuracy:		92.83 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004938
  validation loss:		0.486902
  validation accuracy:		92.83 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004796
  validation loss:		0.485105
  validation accuracy:		92.83 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004822
  validation loss:		0.486679
  validation accuracy:		92.72 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004742
  validation loss:		0.485550
  validation accuracy:		92.72 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004796
  validation loss:		0.488166
  validation accuracy:		92.72 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004838
  validation loss:		0.482833
  validation accuracy:		92.72 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004962
  validation loss:		0.482033
  validation accuracy:		92.72 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004851
  validation loss:		0.487589
  validation accuracy:		92.72 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004805
  validation loss:		0.486488
  validation accuracy:		92.72 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004793
  validation loss:		0.487103
  validation accuracy:		92.61 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004718
  validation loss:		0.488153
  validation accuracy:		92.72 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004706
  validation loss:		0.488699
  validation accuracy:		92.72 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004688
  validation loss:		0.491528
  validation accuracy:		92.61 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004834
  validation loss:		0.489742
  validation accuracy:		92.83 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004841
  validation loss:		0.488356
  validation accuracy:		92.72 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004696
  validation loss:		0.486070
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004743
  validation loss:		0.491234
  validation accuracy:		92.61 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004618
  validation loss:		0.486507
  validation accuracy:		92.72 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004826
  validation loss:		0.490370
  validation accuracy:		92.72 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004886
  validation loss:		0.490863
  validation accuracy:		92.83 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004763
  validation loss:		0.485891
  validation accuracy:		92.72 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004856
  validation loss:		0.489719
  validation accuracy:		92.83 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.493215
  validation accuracy:		92.50 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004553
  validation loss:		0.487398
  validation accuracy:		92.72 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004726
  validation loss:		0.491055
  validation accuracy:		92.83 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004764
  validation loss:		0.495540
  validation accuracy:		92.61 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004774
  validation loss:		0.488998
  validation accuracy:		92.61 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004630
  validation loss:		0.486354
  validation accuracy:		92.83 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004703
  validation loss:		0.490735
  validation accuracy:		92.61 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004781
  validation loss:		0.490714
  validation accuracy:		92.83 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004725
  validation loss:		0.489135
  validation accuracy:		92.83 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004720
  validation loss:		0.495550
  validation accuracy:		92.72 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004721
  validation loss:		0.491319
  validation accuracy:		92.72 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004542
  validation loss:		0.491620
  validation accuracy:		92.72 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004712
  validation loss:		0.488767
  validation accuracy:		92.83 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004682
  validation loss:		0.492444
  validation accuracy:		92.61 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004556
  validation loss:		0.491193
  validation accuracy:		92.61 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004555
  validation loss:		0.492720
  validation accuracy:		92.72 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004451
  validation loss:		0.492691
  validation accuracy:		92.50 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004700
  validation loss:		0.493606
  validation accuracy:		92.83 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004637
  validation loss:		0.493043
  validation accuracy:		92.72 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004615
  validation loss:		0.496210
  validation accuracy:		92.61 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004503
  validation loss:		0.490503
  validation accuracy:		92.61 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004550
  validation loss:		0.496254
  validation accuracy:		92.61 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004589
  validation loss:		0.488202
  validation accuracy:		92.83 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004695
  validation loss:		0.494987
  validation accuracy:		92.61 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004572
  validation loss:		0.491793
  validation accuracy:		92.72 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004474
  validation loss:		0.494289
  validation accuracy:		92.72 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004477
  validation loss:		0.493360
  validation accuracy:		92.72 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004592
  validation loss:		0.489411
  validation accuracy:		92.72 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004516
  validation loss:		0.496288
  validation accuracy:		92.72 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004485
  validation loss:		0.493271
  validation accuracy:		92.61 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004602
  validation loss:		0.490963
  validation accuracy:		92.72 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004632
  validation loss:		0.490503
  validation accuracy:		92.72 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004663
  validation loss:		0.489162
  validation accuracy:		92.83 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004758
  validation loss:		0.489133
  validation accuracy:		92.72 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004586
  validation loss:		0.494231
  validation accuracy:		92.72 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004548
  validation loss:		0.491590
  validation accuracy:		92.72 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004495
  validation loss:		0.493310
  validation accuracy:		92.61 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.493134
  validation accuracy:		92.72 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004525
  validation loss:		0.495236
  validation accuracy:		92.61 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004341
  validation loss:		0.495251
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004350
  validation loss:		0.494832
  validation accuracy:		92.72 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004624
  validation loss:		0.494471
  validation accuracy:		92.83 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004485
  validation loss:		0.497266
  validation accuracy:		92.61 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004549
  validation loss:		0.498061
  validation accuracy:		92.72 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004340
  validation loss:		0.494509
  validation accuracy:		92.61 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004366
  validation loss:		0.495990
  validation accuracy:		92.61 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004375
  validation loss:		0.497621
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004241
  validation loss:		0.494231
  validation accuracy:		92.72 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.497328
  validation accuracy:		92.50 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004428
  validation loss:		0.494683
  validation accuracy:		92.72 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004376
  validation loss:		0.496797
  validation accuracy:		92.72 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004406
  validation loss:		0.496409
  validation accuracy:		92.83 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004364
  validation loss:		0.497009
  validation accuracy:		92.72 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004136
  validation loss:		0.496087
  validation accuracy:		92.72 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004325
  validation loss:		0.499046
  validation accuracy:		92.72 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004300
  validation loss:		0.498380
  validation accuracy:		92.61 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004285
  validation loss:		0.498157
  validation accuracy:		92.61 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004422
  validation loss:		0.497078
  validation accuracy:		92.72 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004365
  validation loss:		0.497730
  validation accuracy:		92.61 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.004335
  validation loss:		0.498575
  validation accuracy:		92.61 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004287
  validation loss:		0.499004
  validation accuracy:		92.61 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004229
  validation loss:		0.499734
  validation accuracy:		92.61 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004344
  validation loss:		0.497023
  validation accuracy:		92.83 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004260
  validation loss:		0.497729
  validation accuracy:		92.83 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004333
  validation loss:		0.494300
  validation accuracy:		92.72 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004210
  validation loss:		0.502490
  validation accuracy:		92.72 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004360
  validation loss:		0.499049
  validation accuracy:		92.61 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004330
  validation loss:		0.499390
  validation accuracy:		92.72 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004294
  validation loss:		0.495863
  validation accuracy:		92.83 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004375
  validation loss:		0.498374
  validation accuracy:		92.72 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.500748
  validation accuracy:		92.61 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004373
  validation loss:		0.498148
  validation accuracy:		92.72 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.503227
  validation accuracy:		92.61 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.004237
  validation loss:		0.499021
  validation accuracy:		92.72 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004207
  validation loss:		0.503017
  validation accuracy:		92.61 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.004341
  validation loss:		0.500998
  validation accuracy:		92.61 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004232
  validation loss:		0.500241
  validation accuracy:		92.61 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.004204
  validation loss:		0.499428
  validation accuracy:		92.61 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.004218
  validation loss:		0.501881
  validation accuracy:		92.50 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004183
  validation loss:		0.497719
  validation accuracy:		92.83 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.004162
  validation loss:		0.502700
  validation accuracy:		92.50 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.004087
  validation loss:		0.501825
  validation accuracy:		92.83 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.004098
  validation loss:		0.499394
  validation accuracy:		92.50 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.004326
  validation loss:		0.498916
  validation accuracy:		92.72 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004244
  validation loss:		0.500348
  validation accuracy:		92.72 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.004190
  validation loss:		0.504981
  validation accuracy:		92.50 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.004202
  validation loss:		0.503024
  validation accuracy:		92.61 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.499991
  validation accuracy:		92.83 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.004161
  validation loss:		0.503950
  validation accuracy:		92.61 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.004108
  validation loss:		0.499585
  validation accuracy:		92.83 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.004201
  validation loss:		0.502141
  validation accuracy:		92.72 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.004111
  validation loss:		0.505419
  validation accuracy:		92.72 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.004192
  validation loss:		0.499769
  validation accuracy:		92.72 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.004288
  validation loss:		0.503260
  validation accuracy:		92.83 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.004144
  validation loss:		0.502749
  validation accuracy:		92.72 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.004067
  validation loss:		0.500469
  validation accuracy:		92.72 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004129
  validation loss:		0.501759
  validation accuracy:		92.83 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.004054
  validation loss:		0.503333
  validation accuracy:		92.61 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.004089
  validation loss:		0.503659
  validation accuracy:		92.72 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.004117
  validation loss:		0.506927
  validation accuracy:		92.72 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.004168
  validation loss:		0.503569
  validation accuracy:		92.72 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.004100
  validation loss:		0.502430
  validation accuracy:		92.61 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003976
  validation loss:		0.505671
  validation accuracy:		92.61 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003958
  validation loss:		0.505362
  validation accuracy:		92.72 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003936
  validation loss:		0.506644
  validation accuracy:		92.50 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.004235
  validation loss:		0.503476
  validation accuracy:		92.61 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.504988
  validation accuracy:		92.61 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.504331
  validation accuracy:		92.83 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.004086
  validation loss:		0.504390
  validation accuracy:		92.61 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.004072
  validation loss:		0.505570
  validation accuracy:		92.61 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.004218
  validation loss:		0.506016
  validation accuracy:		92.72 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.004096
  validation loss:		0.507201
  validation accuracy:		92.61 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.506828
  validation accuracy:		92.61 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.004014
  validation loss:		0.505338
  validation accuracy:		92.61 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003967
  validation loss:		0.510472
  validation accuracy:		92.50 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003994
  validation loss:		0.506023
  validation accuracy:		92.72 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003974
  validation loss:		0.510065
  validation accuracy:		92.50 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003957
  validation loss:		0.503413
  validation accuracy:		92.72 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.004034
  validation loss:		0.507822
  validation accuracy:		92.61 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.004134
  validation loss:		0.508026
  validation accuracy:		92.61 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.004049
  validation loss:		0.508339
  validation accuracy:		92.72 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.004022
  validation loss:		0.507667
  validation accuracy:		92.83 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003986
  validation loss:		0.504449
  validation accuracy:		92.61 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003985
  validation loss:		0.509143
  validation accuracy:		92.61 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003896
  validation loss:		0.510122
  validation accuracy:		92.61 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003904
  validation loss:		0.504360
  validation accuracy:		92.61 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.004079
  validation loss:		0.508358
  validation accuracy:		92.50 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003920
  validation loss:		0.507713
  validation accuracy:		92.72 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003930
  validation loss:		0.507417
  validation accuracy:		92.61 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003808
  validation loss:		0.507312
  validation accuracy:		92.61 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003977
  validation loss:		0.508475
  validation accuracy:		92.50 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003883
  validation loss:		0.509320
  validation accuracy:		92.72 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003933
  validation loss:		0.511288
  validation accuracy:		92.61 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003985
  validation loss:		0.510103
  validation accuracy:		92.50 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003984
  validation loss:		0.511423
  validation accuracy:		92.72 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003965
  validation loss:		0.506275
  validation accuracy:		92.61 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003965
  validation loss:		0.510099
  validation accuracy:		92.61 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003982
  validation loss:		0.510805
  validation accuracy:		92.50 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.506843
  validation accuracy:		92.61 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.508390
  validation accuracy:		92.61 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.510766
  validation accuracy:		92.61 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003780
  validation loss:		0.505149
  validation accuracy:		92.72 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.510402
  validation accuracy:		92.72 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003807
  validation loss:		0.511882
  validation accuracy:		92.50 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003893
  validation loss:		0.507533
  validation accuracy:		92.72 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003739
  validation loss:		0.513107
  validation accuracy:		92.61 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.507955
  validation accuracy:		92.61 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003901
  validation loss:		0.509600
  validation accuracy:		92.61 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003799
  validation loss:		0.508794
  validation accuracy:		92.50 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003724
  validation loss:		0.511283
  validation accuracy:		92.72 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003773
  validation loss:		0.509747
  validation accuracy:		92.61 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003714
  validation loss:		0.513120
  validation accuracy:		92.50 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.004016
  validation loss:		0.506564
  validation accuracy:		92.83 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003810
  validation loss:		0.513473
  validation accuracy:		92.50 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.507957
  validation accuracy:		92.72 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003802
  validation loss:		0.511656
  validation accuracy:		92.50 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003829
  validation loss:		0.509087
  validation accuracy:		92.50 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003720
  validation loss:		0.507274
  validation accuracy:		92.61 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003763
  validation loss:		0.515869
  validation accuracy:		92.72 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003719
  validation loss:		0.510954
  validation accuracy:		92.72 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.508888
  validation accuracy:		92.83 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.512804
  validation accuracy:		92.50 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003848
  validation loss:		0.514570
  validation accuracy:		92.61 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003879
  validation loss:		0.506890
  validation accuracy:		92.72 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.513413
  validation accuracy:		92.50 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.512566
  validation accuracy:		92.72 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003823
  validation loss:		0.515147
  validation accuracy:		92.50 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003787
  validation loss:		0.511400
  validation accuracy:		92.61 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003781
  validation loss:		0.515864
  validation accuracy:		92.39 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.512928
  validation accuracy:		92.50 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003712
  validation loss:		0.516471
  validation accuracy:		92.50 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003644
  validation loss:		0.513510
  validation accuracy:		92.50 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003761
  validation loss:		0.515336
  validation accuracy:		92.50 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.516544
  validation accuracy:		92.61 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003742
  validation loss:		0.512218
  validation accuracy:		92.61 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003762
  validation loss:		0.514229
  validation accuracy:		92.61 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003681
  validation loss:		0.513153
  validation accuracy:		92.83 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003761
  validation loss:		0.511944
  validation accuracy:		92.72 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003742
  validation loss:		0.515855
  validation accuracy:		92.50 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003761
  validation loss:		0.514959
  validation accuracy:		92.61 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003630
  validation loss:		0.510661
  validation accuracy:		92.72 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.517599
  validation accuracy:		92.50 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.513586
  validation accuracy:		92.39 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003697
  validation loss:		0.513409
  validation accuracy:		92.61 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003677
  validation loss:		0.515338
  validation accuracy:		92.61 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003657
  validation loss:		0.513040
  validation accuracy:		92.61 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003659
  validation loss:		0.514445
  validation accuracy:		92.50 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003550
  validation loss:		0.514594
  validation accuracy:		92.50 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003652
  validation loss:		0.514429
  validation accuracy:		92.61 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003651
  validation loss:		0.520189
  validation accuracy:		92.61 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003609
  validation loss:		0.511355
  validation accuracy:		92.61 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003840
  validation loss:		0.515655
  validation accuracy:		92.61 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003674
  validation loss:		0.517366
  validation accuracy:		92.50 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003807
  validation loss:		0.519034
  validation accuracy:		92.50 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003615
  validation loss:		0.517885
  validation accuracy:		92.61 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003701
  validation loss:		0.519592
  validation accuracy:		92.50 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003582
  validation loss:		0.517089
  validation accuracy:		92.39 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003565
  validation loss:		0.514830
  validation accuracy:		92.61 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003531
  validation loss:		0.515013
  validation accuracy:		92.61 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003604
  validation loss:		0.516229
  validation accuracy:		92.50 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003501
  validation loss:		0.518377
  validation accuracy:		92.39 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003562
  validation loss:		0.520928
  validation accuracy:		92.50 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003687
  validation loss:		0.516289
  validation accuracy:		92.39 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003488
  validation loss:		0.517757
  validation accuracy:		92.50 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003630
  validation loss:		0.516538
  validation accuracy:		92.83 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003588
  validation loss:		0.516616
  validation accuracy:		92.39 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003570
  validation loss:		0.517311
  validation accuracy:		92.61 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003602
  validation loss:		0.519362
  validation accuracy:		92.39 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003601
  validation loss:		0.515202
  validation accuracy:		92.72 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003465
  validation loss:		0.517255
  validation accuracy:		92.50 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003524
  validation loss:		0.518182
  validation accuracy:		92.61 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003539
  validation loss:		0.522546
  validation accuracy:		92.39 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003524
  validation loss:		0.516770
  validation accuracy:		92.72 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003566
  validation loss:		0.516278
  validation accuracy:		92.50 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003537
  validation loss:		0.521567
  validation accuracy:		92.61 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003382
  validation loss:		0.517235
  validation accuracy:		92.50 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003594
  validation loss:		0.518985
  validation accuracy:		92.50 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003587
  validation loss:		0.517728
  validation accuracy:		92.39 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003641
  validation loss:		0.520263
  validation accuracy:		92.50 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003499
  validation loss:		0.523580
  validation accuracy:		92.50 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003529
  validation loss:		0.520340
  validation accuracy:		92.61 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003360
  validation loss:		0.522683
  validation accuracy:		92.61 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003535
  validation loss:		0.519652
  validation accuracy:		92.61 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003496
  validation loss:		0.519762
  validation accuracy:		92.61 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003340
  validation loss:		0.520086
  validation accuracy:		92.61 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003437
  validation loss:		0.519101
  validation accuracy:		92.50 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003479
  validation loss:		0.519210
  validation accuracy:		92.39 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003541
  validation loss:		0.519443
  validation accuracy:		92.61 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003489
  validation loss:		0.521014
  validation accuracy:		92.50 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003367
  validation loss:		0.520259
  validation accuracy:		92.61 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003370
  validation loss:		0.523716
  validation accuracy:		92.50 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003521
  validation loss:		0.520307
  validation accuracy:		92.39 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003563
  validation loss:		0.523840
  validation accuracy:		92.50 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003428
  validation loss:		0.519533
  validation accuracy:		92.50 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003459
  validation loss:		0.520449
  validation accuracy:		92.50 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003560
  validation loss:		0.522866
  validation accuracy:		92.50 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.523463
  validation accuracy:		92.61 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003368
  validation loss:		0.522645
  validation accuracy:		92.50 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003383
  validation loss:		0.521588
  validation accuracy:		92.50 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003502
  validation loss:		0.524301
  validation accuracy:		92.50 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003342
  validation loss:		0.520451
  validation accuracy:		92.61 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003439
  validation loss:		0.523768
  validation accuracy:		92.50 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003462
  validation loss:		0.522778
  validation accuracy:		92.61 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003470
  validation loss:		0.520998
  validation accuracy:		92.50 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003472
  validation loss:		0.523771
  validation accuracy:		92.50 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003477
  validation loss:		0.525592
  validation accuracy:		92.61 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.524969
  validation accuracy:		92.39 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003406
  validation loss:		0.528833
  validation accuracy:		92.50 %
Final results:
  test loss:			1.263118
  test accuracy:		84.10 %
