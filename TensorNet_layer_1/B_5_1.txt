Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.056s
  training loss:		2.935060
  validation loss:		2.835134
  validation accuracy:		21.52 %
Epoch 2 of 2000 took 0.045s
  training loss:		2.754933
  validation loss:		2.609988
  validation accuracy:		18.59 %
Epoch 3 of 2000 took 0.041s
  training loss:		2.553385
  validation loss:		2.400517
  validation accuracy:		21.20 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.395364
  validation loss:		2.258947
  validation accuracy:		24.02 %
Epoch 5 of 2000 took 0.058s
  training loss:		2.303380
  validation loss:		2.198653
  validation accuracy:		42.61 %
Epoch 6 of 2000 took 0.072s
  training loss:		2.252551
  validation loss:		2.177356
  validation accuracy:		42.07 %
Epoch 7 of 2000 took 0.055s
  training loss:		2.224328
  validation loss:		2.159242
  validation accuracy:		39.78 %
Epoch 8 of 2000 took 0.046s
  training loss:		2.200653
  validation loss:		2.129700
  validation accuracy:		53.37 %
Epoch 9 of 2000 took 0.043s
  training loss:		2.178385
  validation loss:		2.103623
  validation accuracy:		46.85 %
Epoch 10 of 2000 took 0.044s
  training loss:		2.157727
  validation loss:		2.072845
  validation accuracy:		48.26 %
Epoch 11 of 2000 took 0.043s
  training loss:		2.136276
  validation loss:		2.058708
  validation accuracy:		50.65 %
Epoch 12 of 2000 took 0.044s
  training loss:		2.108998
  validation loss:		2.028782
  validation accuracy:		45.43 %
Epoch 13 of 2000 took 0.044s
  training loss:		2.081937
  validation loss:		1.994858
  validation accuracy:		47.61 %
Epoch 14 of 2000 took 0.044s
  training loss:		2.052905
  validation loss:		1.964249
  validation accuracy:		48.59 %
Epoch 15 of 2000 took 0.044s
  training loss:		2.021376
  validation loss:		1.923509
  validation accuracy:		52.83 %
Epoch 16 of 2000 took 0.044s
  training loss:		1.987364
  validation loss:		1.897644
  validation accuracy:		51.85 %
Epoch 17 of 2000 took 0.044s
  training loss:		1.950386
  validation loss:		1.850648
  validation accuracy:		55.54 %
Epoch 18 of 2000 took 0.058s
  training loss:		1.912846
  validation loss:		1.811451
  validation accuracy:		55.54 %
Epoch 19 of 2000 took 0.051s
  training loss:		1.872998
  validation loss:		1.770771
  validation accuracy:		57.28 %
Epoch 20 of 2000 took 0.044s
  training loss:		1.830147
  validation loss:		1.723907
  validation accuracy:		57.93 %
Epoch 21 of 2000 took 0.042s
  training loss:		1.790407
  validation loss:		1.685651
  validation accuracy:		57.50 %
Epoch 22 of 2000 took 0.042s
  training loss:		1.740853
  validation loss:		1.627858
  validation accuracy:		60.00 %
Epoch 23 of 2000 took 0.041s
  training loss:		1.696057
  validation loss:		1.590960
  validation accuracy:		60.22 %
Epoch 24 of 2000 took 0.041s
  training loss:		1.647435
  validation loss:		1.543931
  validation accuracy:		61.85 %
Epoch 25 of 2000 took 0.041s
  training loss:		1.609403
  validation loss:		1.501630
  validation accuracy:		63.70 %
Epoch 26 of 2000 took 0.042s
  training loss:		1.558345
  validation loss:		1.457346
  validation accuracy:		64.24 %
Epoch 27 of 2000 took 0.042s
  training loss:		1.520108
  validation loss:		1.420878
  validation accuracy:		64.46 %
Epoch 28 of 2000 took 0.041s
  training loss:		1.469199
  validation loss:		1.374692
  validation accuracy:		67.93 %
Epoch 29 of 2000 took 0.042s
  training loss:		1.428483
  validation loss:		1.331212
  validation accuracy:		67.93 %
Epoch 30 of 2000 took 0.041s
  training loss:		1.384497
  validation loss:		1.286650
  validation accuracy:		68.48 %
Epoch 31 of 2000 took 0.041s
  training loss:		1.345685
  validation loss:		1.248039
  validation accuracy:		68.48 %
Epoch 32 of 2000 took 0.041s
  training loss:		1.303403
  validation loss:		1.210791
  validation accuracy:		68.59 %
Epoch 33 of 2000 took 0.042s
  training loss:		1.262666
  validation loss:		1.173405
  validation accuracy:		70.11 %
Epoch 34 of 2000 took 0.041s
  training loss:		1.218515
  validation loss:		1.133927
  validation accuracy:		70.43 %
Epoch 35 of 2000 took 0.041s
  training loss:		1.184567
  validation loss:		1.096637
  validation accuracy:		70.87 %
Epoch 36 of 2000 took 0.042s
  training loss:		1.150212
  validation loss:		1.072020
  validation accuracy:		71.09 %
Epoch 37 of 2000 took 0.041s
  training loss:		1.118491
  validation loss:		1.030575
  validation accuracy:		72.93 %
Epoch 38 of 2000 took 0.042s
  training loss:		1.076999
  validation loss:		0.997180
  validation accuracy:		73.59 %
Epoch 39 of 2000 took 0.041s
  training loss:		1.048611
  validation loss:		0.964159
  validation accuracy:		74.24 %
Epoch 40 of 2000 took 0.039s
  training loss:		1.016063
  validation loss:		0.938364
  validation accuracy:		75.76 %
Epoch 41 of 2000 took 0.036s
  training loss:		0.980593
  validation loss:		0.919565
  validation accuracy:		76.09 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.953654
  validation loss:		0.884990
  validation accuracy:		77.39 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.928859
  validation loss:		0.868313
  validation accuracy:		78.15 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.903491
  validation loss:		0.824241
  validation accuracy:		79.24 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.872334
  validation loss:		0.805836
  validation accuracy:		79.57 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.847559
  validation loss:		0.782456
  validation accuracy:		80.33 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.826611
  validation loss:		0.763258
  validation accuracy:		81.41 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.795684
  validation loss:		0.737799
  validation accuracy:		81.20 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.777889
  validation loss:		0.713640
  validation accuracy:		82.28 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.745496
  validation loss:		0.693178
  validation accuracy:		83.04 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.733875
  validation loss:		0.680095
  validation accuracy:		82.93 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.711712
  validation loss:		0.653893
  validation accuracy:		83.37 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.692387
  validation loss:		0.639040
  validation accuracy:		84.24 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.672264
  validation loss:		0.615556
  validation accuracy:		84.57 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.651351
  validation loss:		0.601449
  validation accuracy:		84.78 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.638647
  validation loss:		0.591378
  validation accuracy:		85.22 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.622991
  validation loss:		0.574721
  validation accuracy:		85.87 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.604386
  validation loss:		0.551938
  validation accuracy:		86.74 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.595660
  validation loss:		0.545904
  validation accuracy:		86.63 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.577000
  validation loss:		0.530182
  validation accuracy:		86.96 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.560603
  validation loss:		0.511196
  validation accuracy:		87.39 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.550888
  validation loss:		0.503968
  validation accuracy:		88.04 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.535009
  validation loss:		0.496778
  validation accuracy:		88.26 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.524602
  validation loss:		0.481398
  validation accuracy:		87.93 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.510498
  validation loss:		0.480293
  validation accuracy:		87.93 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.498256
  validation loss:		0.464015
  validation accuracy:		88.91 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.492328
  validation loss:		0.452116
  validation accuracy:		88.59 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.478460
  validation loss:		0.449749
  validation accuracy:		89.02 %
Epoch 69 of 2000 took 0.037s
  training loss:		0.468445
  validation loss:		0.436611
  validation accuracy:		89.57 %
Epoch 70 of 2000 took 0.036s
  training loss:		0.458574
  validation loss:		0.428993
  validation accuracy:		89.35 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.455816
  validation loss:		0.431419
  validation accuracy:		89.24 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.435655
  validation loss:		0.424323
  validation accuracy:		89.35 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.432533
  validation loss:		0.400213
  validation accuracy:		90.43 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.430193
  validation loss:		0.402906
  validation accuracy:		90.00 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.423060
  validation loss:		0.388326
  validation accuracy:		90.33 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.410864
  validation loss:		0.392335
  validation accuracy:		89.89 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.398824
  validation loss:		0.378455
  validation accuracy:		90.54 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.401174
  validation loss:		0.373663
  validation accuracy:		90.76 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.396709
  validation loss:		0.372853
  validation accuracy:		90.76 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.388085
  validation loss:		0.372406
  validation accuracy:		90.65 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.374459
  validation loss:		0.360346
  validation accuracy:		90.65 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.379410
  validation loss:		0.357800
  validation accuracy:		90.76 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.371251
  validation loss:		0.351266
  validation accuracy:		91.20 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.365492
  validation loss:		0.345528
  validation accuracy:		90.98 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.359687
  validation loss:		0.340751
  validation accuracy:		91.30 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.354007
  validation loss:		0.334770
  validation accuracy:		91.41 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.346830
  validation loss:		0.338362
  validation accuracy:		91.52 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.348258
  validation loss:		0.337414
  validation accuracy:		91.41 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.343329
  validation loss:		0.324715
  validation accuracy:		91.30 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.338987
  validation loss:		0.338142
  validation accuracy:		90.98 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.335436
  validation loss:		0.320624
  validation accuracy:		91.74 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.328409
  validation loss:		0.317008
  validation accuracy:		91.85 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.324960
  validation loss:		0.315594
  validation accuracy:		91.30 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.323283
  validation loss:		0.311299
  validation accuracy:		91.85 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.321418
  validation loss:		0.309092
  validation accuracy:		91.85 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.315717
  validation loss:		0.311891
  validation accuracy:		91.30 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.313122
  validation loss:		0.312667
  validation accuracy:		91.52 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.317927
  validation loss:		0.311067
  validation accuracy:		91.52 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.307107
  validation loss:		0.306899
  validation accuracy:		91.74 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.300929
  validation loss:		0.302649
  validation accuracy:		91.52 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.300317
  validation loss:		0.294321
  validation accuracy:		92.07 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.299465
  validation loss:		0.297437
  validation accuracy:		91.96 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.291272
  validation loss:		0.288926
  validation accuracy:		91.96 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.292694
  validation loss:		0.292059
  validation accuracy:		92.17 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.288938
  validation loss:		0.285830
  validation accuracy:		92.28 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.289560
  validation loss:		0.284526
  validation accuracy:		92.17 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.286769
  validation loss:		0.290423
  validation accuracy:		91.41 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.283188
  validation loss:		0.286100
  validation accuracy:		91.96 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.282024
  validation loss:		0.287037
  validation accuracy:		91.96 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.279877
  validation loss:		0.284863
  validation accuracy:		91.85 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.281175
  validation loss:		0.281198
  validation accuracy:		91.96 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.277910
  validation loss:		0.279421
  validation accuracy:		91.74 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.270531
  validation loss:		0.272908
  validation accuracy:		92.17 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.269909
  validation loss:		0.275546
  validation accuracy:		91.74 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.267413
  validation loss:		0.274366
  validation accuracy:		91.74 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.266988
  validation loss:		0.272423
  validation accuracy:		91.96 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.268976
  validation loss:		0.273009
  validation accuracy:		91.63 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.261653
  validation loss:		0.264039
  validation accuracy:		92.28 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.267223
  validation loss:		0.263326
  validation accuracy:		92.07 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.262590
  validation loss:		0.268478
  validation accuracy:		92.07 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.257304
  validation loss:		0.257746
  validation accuracy:		92.28 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.251208
  validation loss:		0.262834
  validation accuracy:		92.07 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.253621
  validation loss:		0.269046
  validation accuracy:		91.85 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.257203
  validation loss:		0.273087
  validation accuracy:		91.96 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.253453
  validation loss:		0.267967
  validation accuracy:		92.07 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.253216
  validation loss:		0.264980
  validation accuracy:		91.85 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.242330
  validation loss:		0.258029
  validation accuracy:		92.28 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.245942
  validation loss:		0.256643
  validation accuracy:		92.72 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.243954
  validation loss:		0.253372
  validation accuracy:		92.50 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.249261
  validation loss:		0.263185
  validation accuracy:		91.52 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.240546
  validation loss:		0.255128
  validation accuracy:		91.96 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.244091
  validation loss:		0.258550
  validation accuracy:		92.17 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.243718
  validation loss:		0.255813
  validation accuracy:		92.17 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.240253
  validation loss:		0.254284
  validation accuracy:		92.39 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.237311
  validation loss:		0.254094
  validation accuracy:		92.28 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.238778
  validation loss:		0.243669
  validation accuracy:		92.93 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.238626
  validation loss:		0.250196
  validation accuracy:		92.39 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.233418
  validation loss:		0.252668
  validation accuracy:		92.07 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.231044
  validation loss:		0.256293
  validation accuracy:		91.85 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.228111
  validation loss:		0.250122
  validation accuracy:		92.28 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.228230
  validation loss:		0.247427
  validation accuracy:		92.39 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.229980
  validation loss:		0.243488
  validation accuracy:		92.28 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.228364
  validation loss:		0.241115
  validation accuracy:		92.93 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.224298
  validation loss:		0.246584
  validation accuracy:		92.17 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.225540
  validation loss:		0.247373
  validation accuracy:		92.28 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.219061
  validation loss:		0.246303
  validation accuracy:		92.61 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.222982
  validation loss:		0.256523
  validation accuracy:		91.96 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.219631
  validation loss:		0.238045
  validation accuracy:		92.83 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.220556
  validation loss:		0.243823
  validation accuracy:		92.28 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.219957
  validation loss:		0.235509
  validation accuracy:		92.83 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.221902
  validation loss:		0.237984
  validation accuracy:		93.04 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.218261
  validation loss:		0.236003
  validation accuracy:		92.72 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.216789
  validation loss:		0.234739
  validation accuracy:		92.83 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.214307
  validation loss:		0.238029
  validation accuracy:		92.61 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.209587
  validation loss:		0.239484
  validation accuracy:		92.72 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.210717
  validation loss:		0.238785
  validation accuracy:		92.50 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.212420
  validation loss:		0.244746
  validation accuracy:		92.39 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.212559
  validation loss:		0.241803
  validation accuracy:		92.28 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.210147
  validation loss:		0.244502
  validation accuracy:		92.39 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.214348
  validation loss:		0.241996
  validation accuracy:		92.07 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.205527
  validation loss:		0.234710
  validation accuracy:		92.83 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.205752
  validation loss:		0.239296
  validation accuracy:		92.28 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.202912
  validation loss:		0.235402
  validation accuracy:		93.04 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.201001
  validation loss:		0.231409
  validation accuracy:		92.93 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.204594
  validation loss:		0.240440
  validation accuracy:		92.28 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.202093
  validation loss:		0.227132
  validation accuracy:		92.93 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.201853
  validation loss:		0.237083
  validation accuracy:		92.28 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.199082
  validation loss:		0.237705
  validation accuracy:		92.83 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.203215
  validation loss:		0.238534
  validation accuracy:		92.39 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.199332
  validation loss:		0.228215
  validation accuracy:		93.15 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.198492
  validation loss:		0.226093
  validation accuracy:		92.93 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.199969
  validation loss:		0.226706
  validation accuracy:		93.15 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.196320
  validation loss:		0.226694
  validation accuracy:		93.04 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.198068
  validation loss:		0.228019
  validation accuracy:		92.83 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.194150
  validation loss:		0.235190
  validation accuracy:		92.50 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.193862
  validation loss:		0.234416
  validation accuracy:		92.28 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.188260
  validation loss:		0.228253
  validation accuracy:		92.61 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.191170
  validation loss:		0.230318
  validation accuracy:		92.50 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.189386
  validation loss:		0.229824
  validation accuracy:		92.50 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.190162
  validation loss:		0.225142
  validation accuracy:		93.04 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.195268
  validation loss:		0.235902
  validation accuracy:		92.50 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.187244
  validation loss:		0.227990
  validation accuracy:		92.72 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.189187
  validation loss:		0.226142
  validation accuracy:		92.93 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.187361
  validation loss:		0.224090
  validation accuracy:		93.15 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.187971
  validation loss:		0.225521
  validation accuracy:		93.26 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.185272
  validation loss:		0.229201
  validation accuracy:		92.61 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.185786
  validation loss:		0.226044
  validation accuracy:		92.93 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.186775
  validation loss:		0.228723
  validation accuracy:		92.72 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.180069
  validation loss:		0.222303
  validation accuracy:		93.26 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.181695
  validation loss:		0.230074
  validation accuracy:		92.50 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.180164
  validation loss:		0.221016
  validation accuracy:		93.37 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.184075
  validation loss:		0.225154
  validation accuracy:		93.04 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.183932
  validation loss:		0.222963
  validation accuracy:		92.83 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.182608
  validation loss:		0.225158
  validation accuracy:		92.93 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.182488
  validation loss:		0.231663
  validation accuracy:		92.61 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.177435
  validation loss:		0.217688
  validation accuracy:		93.04 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.178202
  validation loss:		0.213722
  validation accuracy:		93.15 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.177670
  validation loss:		0.217894
  validation accuracy:		93.04 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.174350
  validation loss:		0.236500
  validation accuracy:		92.17 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.176040
  validation loss:		0.222492
  validation accuracy:		92.83 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.175147
  validation loss:		0.219907
  validation accuracy:		93.26 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.177186
  validation loss:		0.214387
  validation accuracy:		93.15 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.172161
  validation loss:		0.224650
  validation accuracy:		92.93 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.171869
  validation loss:		0.213386
  validation accuracy:		93.37 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.173915
  validation loss:		0.227801
  validation accuracy:		92.72 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.176254
  validation loss:		0.231498
  validation accuracy:		92.39 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.171081
  validation loss:		0.224541
  validation accuracy:		92.93 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.168332
  validation loss:		0.219026
  validation accuracy:		92.72 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.169174
  validation loss:		0.224942
  validation accuracy:		92.72 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.169226
  validation loss:		0.218704
  validation accuracy:		93.04 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.164789
  validation loss:		0.223908
  validation accuracy:		92.61 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.170038
  validation loss:		0.218660
  validation accuracy:		93.04 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.167760
  validation loss:		0.216318
  validation accuracy:		93.15 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.165966
  validation loss:		0.222429
  validation accuracy:		92.61 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.163943
  validation loss:		0.226281
  validation accuracy:		92.39 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.167724
  validation loss:		0.216460
  validation accuracy:		93.59 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.165895
  validation loss:		0.213227
  validation accuracy:		93.15 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.167356
  validation loss:		0.223398
  validation accuracy:		92.83 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.165787
  validation loss:		0.217651
  validation accuracy:		93.26 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.164341
  validation loss:		0.224479
  validation accuracy:		93.04 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.163532
  validation loss:		0.216226
  validation accuracy:		92.93 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.160813
  validation loss:		0.218970
  validation accuracy:		92.61 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.159815
  validation loss:		0.216253
  validation accuracy:		93.59 %
Epoch 224 of 2000 took 0.037s
  training loss:		0.159292
  validation loss:		0.217735
  validation accuracy:		93.26 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.160146
  validation loss:		0.232212
  validation accuracy:		92.50 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.160844
  validation loss:		0.212435
  validation accuracy:		92.93 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.160188
  validation loss:		0.220647
  validation accuracy:		92.83 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.161239
  validation loss:		0.215585
  validation accuracy:		93.15 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.161614
  validation loss:		0.215476
  validation accuracy:		93.26 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.161899
  validation loss:		0.220884
  validation accuracy:		92.61 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.156429
  validation loss:		0.223608
  validation accuracy:		92.83 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.157396
  validation loss:		0.213371
  validation accuracy:		93.37 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.157064
  validation loss:		0.224441
  validation accuracy:		92.07 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.157875
  validation loss:		0.211827
  validation accuracy:		93.04 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.158989
  validation loss:		0.218731
  validation accuracy:		92.61 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.157951
  validation loss:		0.215498
  validation accuracy:		93.04 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.156227
  validation loss:		0.208121
  validation accuracy:		93.48 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.153720
  validation loss:		0.217767
  validation accuracy:		92.93 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.154206
  validation loss:		0.211728
  validation accuracy:		93.26 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.152406
  validation loss:		0.220965
  validation accuracy:		92.50 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.153419
  validation loss:		0.214718
  validation accuracy:		93.26 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.155137
  validation loss:		0.220615
  validation accuracy:		92.72 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.152031
  validation loss:		0.222044
  validation accuracy:		92.72 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.150956
  validation loss:		0.216712
  validation accuracy:		93.15 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.150425
  validation loss:		0.222249
  validation accuracy:		92.61 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.150990
  validation loss:		0.215097
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.153042
  validation loss:		0.209712
  validation accuracy:		93.59 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.150342
  validation loss:		0.207170
  validation accuracy:		93.37 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.146776
  validation loss:		0.213949
  validation accuracy:		93.26 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.147330
  validation loss:		0.216842
  validation accuracy:		92.83 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.146042
  validation loss:		0.214678
  validation accuracy:		93.26 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.144388
  validation loss:		0.219040
  validation accuracy:		92.72 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.145819
  validation loss:		0.214988
  validation accuracy:		93.15 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.144239
  validation loss:		0.208376
  validation accuracy:		93.37 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.147722
  validation loss:		0.216765
  validation accuracy:		92.93 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.145020
  validation loss:		0.214249
  validation accuracy:		93.15 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.143838
  validation loss:		0.214576
  validation accuracy:		93.04 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.144039
  validation loss:		0.207957
  validation accuracy:		93.26 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.146430
  validation loss:		0.211038
  validation accuracy:		92.93 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.144174
  validation loss:		0.221021
  validation accuracy:		92.61 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.142886
  validation loss:		0.214488
  validation accuracy:		92.93 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.141206
  validation loss:		0.210814
  validation accuracy:		93.26 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.142285
  validation loss:		0.208720
  validation accuracy:		93.26 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.144258
  validation loss:		0.214806
  validation accuracy:		92.83 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.139428
  validation loss:		0.215298
  validation accuracy:		93.04 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.139707
  validation loss:		0.215176
  validation accuracy:		93.15 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.141397
  validation loss:		0.207204
  validation accuracy:		93.37 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.143520
  validation loss:		0.206210
  validation accuracy:		92.93 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.142830
  validation loss:		0.215170
  validation accuracy:		93.26 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.138325
  validation loss:		0.222756
  validation accuracy:		93.04 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.138817
  validation loss:		0.215148
  validation accuracy:		93.37 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.133939
  validation loss:		0.219348
  validation accuracy:		92.72 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.139199
  validation loss:		0.217011
  validation accuracy:		93.04 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.139172
  validation loss:		0.216791
  validation accuracy:		92.72 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.139570
  validation loss:		0.211797
  validation accuracy:		93.37 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.134051
  validation loss:		0.214291
  validation accuracy:		93.26 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.134773
  validation loss:		0.218010
  validation accuracy:		93.04 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.137469
  validation loss:		0.218474
  validation accuracy:		92.72 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.129054
  validation loss:		0.210170
  validation accuracy:		93.37 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.136539
  validation loss:		0.214738
  validation accuracy:		93.37 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.135607
  validation loss:		0.219774
  validation accuracy:		92.93 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.133166
  validation loss:		0.217609
  validation accuracy:		93.37 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.131927
  validation loss:		0.212142
  validation accuracy:		93.15 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.134155
  validation loss:		0.210260
  validation accuracy:		93.15 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.134657
  validation loss:		0.211287
  validation accuracy:		93.26 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.132467
  validation loss:		0.211895
  validation accuracy:		93.26 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.135859
  validation loss:		0.220927
  validation accuracy:		92.50 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.131724
  validation loss:		0.214852
  validation accuracy:		93.15 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.131823
  validation loss:		0.225837
  validation accuracy:		92.72 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.130274
  validation loss:		0.215648
  validation accuracy:		92.93 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.130775
  validation loss:		0.219570
  validation accuracy:		92.83 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.130974
  validation loss:		0.215601
  validation accuracy:		93.37 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.130640
  validation loss:		0.214455
  validation accuracy:		93.48 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.128680
  validation loss:		0.223013
  validation accuracy:		93.04 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.132114
  validation loss:		0.229343
  validation accuracy:		92.50 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.129504
  validation loss:		0.221748
  validation accuracy:		93.15 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.131272
  validation loss:		0.211228
  validation accuracy:		93.26 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.128397
  validation loss:		0.216511
  validation accuracy:		93.37 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.129660
  validation loss:		0.226482
  validation accuracy:		92.72 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.125606
  validation loss:		0.213503
  validation accuracy:		93.26 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.125173
  validation loss:		0.218619
  validation accuracy:		93.26 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.130873
  validation loss:		0.217496
  validation accuracy:		92.93 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.126118
  validation loss:		0.226344
  validation accuracy:		92.93 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.127166
  validation loss:		0.213720
  validation accuracy:		93.26 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.127947
  validation loss:		0.214872
  validation accuracy:		93.15 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.125121
  validation loss:		0.223429
  validation accuracy:		93.04 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.121182
  validation loss:		0.209471
  validation accuracy:		93.26 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.124977
  validation loss:		0.225713
  validation accuracy:		92.83 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.123307
  validation loss:		0.214917
  validation accuracy:		92.93 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.124136
  validation loss:		0.221466
  validation accuracy:		92.93 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.126361
  validation loss:		0.213124
  validation accuracy:		93.48 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.122506
  validation loss:		0.213830
  validation accuracy:		93.26 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.127073
  validation loss:		0.212857
  validation accuracy:		93.59 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.118708
  validation loss:		0.215327
  validation accuracy:		93.37 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.121968
  validation loss:		0.214961
  validation accuracy:		93.26 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.119312
  validation loss:		0.218809
  validation accuracy:		93.26 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.120223
  validation loss:		0.216073
  validation accuracy:		93.59 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.121233
  validation loss:		0.216813
  validation accuracy:		93.15 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.118746
  validation loss:		0.218919
  validation accuracy:		93.04 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.119315
  validation loss:		0.212779
  validation accuracy:		93.26 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.122943
  validation loss:		0.215811
  validation accuracy:		93.37 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.121337
  validation loss:		0.227487
  validation accuracy:		92.93 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.119621
  validation loss:		0.217499
  validation accuracy:		93.15 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.116805
  validation loss:		0.227591
  validation accuracy:		92.72 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.120578
  validation loss:		0.219249
  validation accuracy:		93.48 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.119380
  validation loss:		0.226060
  validation accuracy:		92.93 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.119617
  validation loss:		0.211822
  validation accuracy:		93.70 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.118759
  validation loss:		0.215022
  validation accuracy:		93.26 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.119780
  validation loss:		0.225265
  validation accuracy:		92.83 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.116728
  validation loss:		0.215350
  validation accuracy:		93.48 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.116092
  validation loss:		0.213909
  validation accuracy:		93.48 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.117769
  validation loss:		0.215222
  validation accuracy:		93.59 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.116181
  validation loss:		0.225965
  validation accuracy:		93.04 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.114346
  validation loss:		0.221202
  validation accuracy:		93.15 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.114968
  validation loss:		0.219346
  validation accuracy:		93.37 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.115665
  validation loss:		0.215849
  validation accuracy:		93.48 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.115874
  validation loss:		0.216631
  validation accuracy:		93.37 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.115783
  validation loss:		0.219761
  validation accuracy:		93.37 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.112334
  validation loss:		0.214389
  validation accuracy:		93.37 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.114083
  validation loss:		0.224491
  validation accuracy:		93.04 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.113871
  validation loss:		0.226175
  validation accuracy:		93.04 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.112787
  validation loss:		0.219694
  validation accuracy:		93.48 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.113218
  validation loss:		0.226726
  validation accuracy:		93.04 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.111693
  validation loss:		0.212343
  validation accuracy:		93.59 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.110136
  validation loss:		0.223189
  validation accuracy:		93.26 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.112243
  validation loss:		0.230288
  validation accuracy:		92.93 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.111603
  validation loss:		0.226763
  validation accuracy:		92.93 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.112982
  validation loss:		0.226787
  validation accuracy:		93.04 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.112973
  validation loss:		0.222260
  validation accuracy:		93.04 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.111334
  validation loss:		0.217874
  validation accuracy:		93.37 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.112461
  validation loss:		0.221140
  validation accuracy:		93.37 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.112856
  validation loss:		0.211804
  validation accuracy:		93.48 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.111875
  validation loss:		0.218231
  validation accuracy:		93.48 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.109966
  validation loss:		0.218277
  validation accuracy:		93.48 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.110566
  validation loss:		0.227698
  validation accuracy:		93.15 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.111768
  validation loss:		0.210056
  validation accuracy:		93.59 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.109415
  validation loss:		0.218564
  validation accuracy:		93.37 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.107249
  validation loss:		0.218459
  validation accuracy:		93.48 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.109158
  validation loss:		0.216776
  validation accuracy:		93.15 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.107749
  validation loss:		0.220369
  validation accuracy:		93.15 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.108409
  validation loss:		0.222189
  validation accuracy:		93.37 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.108288
  validation loss:		0.221788
  validation accuracy:		93.15 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.105786
  validation loss:		0.219854
  validation accuracy:		93.59 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.103876
  validation loss:		0.222033
  validation accuracy:		93.15 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.108977
  validation loss:		0.224671
  validation accuracy:		93.26 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.107860
  validation loss:		0.224093
  validation accuracy:		93.04 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.103883
  validation loss:		0.220602
  validation accuracy:		93.26 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.104505
  validation loss:		0.230172
  validation accuracy:		93.04 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.102257
  validation loss:		0.214378
  validation accuracy:		93.48 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.107969
  validation loss:		0.223313
  validation accuracy:		93.26 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.100403
  validation loss:		0.219029
  validation accuracy:		93.48 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.107144
  validation loss:		0.228783
  validation accuracy:		93.26 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.101657
  validation loss:		0.217722
  validation accuracy:		93.59 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.106206
  validation loss:		0.231859
  validation accuracy:		92.83 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.105074
  validation loss:		0.229271
  validation accuracy:		93.04 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.103659
  validation loss:		0.221727
  validation accuracy:		93.26 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.104266
  validation loss:		0.227683
  validation accuracy:		93.37 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.101326
  validation loss:		0.223614
  validation accuracy:		93.48 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.104020
  validation loss:		0.214731
  validation accuracy:		93.59 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.100306
  validation loss:		0.223046
  validation accuracy:		93.37 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.103185
  validation loss:		0.215989
  validation accuracy:		93.59 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.101892
  validation loss:		0.217800
  validation accuracy:		93.48 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.101730
  validation loss:		0.220769
  validation accuracy:		93.48 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.102373
  validation loss:		0.225501
  validation accuracy:		93.15 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.101638
  validation loss:		0.226628
  validation accuracy:		93.15 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.100756
  validation loss:		0.226045
  validation accuracy:		93.26 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.099707
  validation loss:		0.223906
  validation accuracy:		93.37 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.099790
  validation loss:		0.231231
  validation accuracy:		93.04 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.100927
  validation loss:		0.232655
  validation accuracy:		93.15 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.099845
  validation loss:		0.222242
  validation accuracy:		93.37 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.098660
  validation loss:		0.230487
  validation accuracy:		93.26 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.097076
  validation loss:		0.224030
  validation accuracy:		93.26 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.102387
  validation loss:		0.225205
  validation accuracy:		93.26 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.099703
  validation loss:		0.218926
  validation accuracy:		93.48 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.099812
  validation loss:		0.224769
  validation accuracy:		93.48 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.097813
  validation loss:		0.224565
  validation accuracy:		93.48 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.099803
  validation loss:		0.228858
  validation accuracy:		93.37 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.101815
  validation loss:		0.222167
  validation accuracy:		93.59 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.098774
  validation loss:		0.229964
  validation accuracy:		93.15 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.097455
  validation loss:		0.222544
  validation accuracy:		93.48 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.097621
  validation loss:		0.226293
  validation accuracy:		93.15 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.097523
  validation loss:		0.235066
  validation accuracy:		92.93 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.093851
  validation loss:		0.225284
  validation accuracy:		93.59 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.099039
  validation loss:		0.219442
  validation accuracy:		93.59 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.097786
  validation loss:		0.225059
  validation accuracy:		93.59 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.094633
  validation loss:		0.229336
  validation accuracy:		93.26 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.097676
  validation loss:		0.226655
  validation accuracy:		93.37 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.096663
  validation loss:		0.224416
  validation accuracy:		93.59 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.095782
  validation loss:		0.240707
  validation accuracy:		92.83 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.097507
  validation loss:		0.226018
  validation accuracy:		93.26 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.094263
  validation loss:		0.226410
  validation accuracy:		93.37 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.092377
  validation loss:		0.232787
  validation accuracy:		93.26 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.095283
  validation loss:		0.230404
  validation accuracy:		93.26 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.093939
  validation loss:		0.221960
  validation accuracy:		93.48 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.093831
  validation loss:		0.234682
  validation accuracy:		93.26 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.092134
  validation loss:		0.232080
  validation accuracy:		93.26 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.092293
  validation loss:		0.232433
  validation accuracy:		93.59 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.093879
  validation loss:		0.224489
  validation accuracy:		93.37 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.093339
  validation loss:		0.234203
  validation accuracy:		92.83 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.095126
  validation loss:		0.226449
  validation accuracy:		93.15 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.094608
  validation loss:		0.236100
  validation accuracy:		92.83 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.094468
  validation loss:		0.227301
  validation accuracy:		93.37 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.090561
  validation loss:		0.243875
  validation accuracy:		92.72 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.094105
  validation loss:		0.232773
  validation accuracy:		93.04 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.093083
  validation loss:		0.237122
  validation accuracy:		93.04 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.090781
  validation loss:		0.224979
  validation accuracy:		93.48 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.091112
  validation loss:		0.233514
  validation accuracy:		93.04 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.091061
  validation loss:		0.226541
  validation accuracy:		93.37 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.088088
  validation loss:		0.231527
  validation accuracy:		93.59 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.091021
  validation loss:		0.227568
  validation accuracy:		93.26 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.087609
  validation loss:		0.222318
  validation accuracy:		93.48 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.088502
  validation loss:		0.231264
  validation accuracy:		93.26 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.090820
  validation loss:		0.231243
  validation accuracy:		93.04 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.089627
  validation loss:		0.235970
  validation accuracy:		93.04 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.091369
  validation loss:		0.232083
  validation accuracy:		93.59 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.089067
  validation loss:		0.235475
  validation accuracy:		92.93 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.086904
  validation loss:		0.242034
  validation accuracy:		93.04 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.091311
  validation loss:		0.232923
  validation accuracy:		93.26 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.087521
  validation loss:		0.227528
  validation accuracy:		93.37 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.089069
  validation loss:		0.238078
  validation accuracy:		93.26 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.082767
  validation loss:		0.235163
  validation accuracy:		92.93 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.088195
  validation loss:		0.228745
  validation accuracy:		93.37 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.085885
  validation loss:		0.240969
  validation accuracy:		92.93 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.088254
  validation loss:		0.234945
  validation accuracy:		93.15 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.089503
  validation loss:		0.234017
  validation accuracy:		93.04 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.087873
  validation loss:		0.233409
  validation accuracy:		93.04 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.088839
  validation loss:		0.224419
  validation accuracy:		93.37 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.086317
  validation loss:		0.230306
  validation accuracy:		93.37 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.086111
  validation loss:		0.237355
  validation accuracy:		92.93 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.087060
  validation loss:		0.228962
  validation accuracy:		93.37 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.086963
  validation loss:		0.238960
  validation accuracy:		93.15 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.085885
  validation loss:		0.242724
  validation accuracy:		93.26 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.086689
  validation loss:		0.232710
  validation accuracy:		93.15 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.083180
  validation loss:		0.237506
  validation accuracy:		93.48 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.086382
  validation loss:		0.234552
  validation accuracy:		93.04 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.085708
  validation loss:		0.236173
  validation accuracy:		93.26 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.085006
  validation loss:		0.238877
  validation accuracy:		93.15 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.084024
  validation loss:		0.237886
  validation accuracy:		93.26 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.083648
  validation loss:		0.230431
  validation accuracy:		93.26 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.086451
  validation loss:		0.235684
  validation accuracy:		93.15 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.084804
  validation loss:		0.238878
  validation accuracy:		93.04 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.084200
  validation loss:		0.230212
  validation accuracy:		93.26 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.083987
  validation loss:		0.225187
  validation accuracy:		93.70 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.086055
  validation loss:		0.235823
  validation accuracy:		92.93 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.085130
  validation loss:		0.236905
  validation accuracy:		93.15 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.083595
  validation loss:		0.243819
  validation accuracy:		93.04 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.083035
  validation loss:		0.233387
  validation accuracy:		93.04 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.083459
  validation loss:		0.233047
  validation accuracy:		93.15 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.079464
  validation loss:		0.238804
  validation accuracy:		93.15 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.080740
  validation loss:		0.246552
  validation accuracy:		93.04 %
Epoch 471 of 2000 took 0.037s
  training loss:		0.082779
  validation loss:		0.233509
  validation accuracy:		93.37 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.078492
  validation loss:		0.250801
  validation accuracy:		92.93 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.083108
  validation loss:		0.240095
  validation accuracy:		92.83 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.080932
  validation loss:		0.235935
  validation accuracy:		93.26 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.083035
  validation loss:		0.242859
  validation accuracy:		93.04 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.080101
  validation loss:		0.247935
  validation accuracy:		93.04 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.080255
  validation loss:		0.241399
  validation accuracy:		93.04 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.079466
  validation loss:		0.240213
  validation accuracy:		93.59 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.081202
  validation loss:		0.239303
  validation accuracy:		93.15 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.078477
  validation loss:		0.240467
  validation accuracy:		93.15 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.078216
  validation loss:		0.229750
  validation accuracy:		93.59 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.081062
  validation loss:		0.231090
  validation accuracy:		93.48 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.077300
  validation loss:		0.247139
  validation accuracy:		93.04 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.077751
  validation loss:		0.245522
  validation accuracy:		92.93 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.079685
  validation loss:		0.237981
  validation accuracy:		93.37 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.079760
  validation loss:		0.239124
  validation accuracy:		93.15 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.078611
  validation loss:		0.248096
  validation accuracy:		92.93 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.078482
  validation loss:		0.245024
  validation accuracy:		93.37 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.079839
  validation loss:		0.236322
  validation accuracy:		93.37 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.079345
  validation loss:		0.234671
  validation accuracy:		93.15 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.077052
  validation loss:		0.252988
  validation accuracy:		93.04 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.076933
  validation loss:		0.236327
  validation accuracy:		93.37 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.077147
  validation loss:		0.244572
  validation accuracy:		92.93 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.076323
  validation loss:		0.240510
  validation accuracy:		93.04 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.077067
  validation loss:		0.240271
  validation accuracy:		93.04 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.078730
  validation loss:		0.239471
  validation accuracy:		93.15 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.076106
  validation loss:		0.243805
  validation accuracy:		92.93 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.073641
  validation loss:		0.240332
  validation accuracy:		93.26 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.078091
  validation loss:		0.239788
  validation accuracy:		93.15 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.075991
  validation loss:		0.253600
  validation accuracy:		93.26 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.074598
  validation loss:		0.239209
  validation accuracy:		93.15 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.077865
  validation loss:		0.237653
  validation accuracy:		93.37 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.079295
  validation loss:		0.233093
  validation accuracy:		93.48 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.076904
  validation loss:		0.234289
  validation accuracy:		93.59 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.076728
  validation loss:		0.235613
  validation accuracy:		93.26 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.075878
  validation loss:		0.239131
  validation accuracy:		93.48 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.076544
  validation loss:		0.247480
  validation accuracy:		93.26 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.074036
  validation loss:		0.246673
  validation accuracy:		93.26 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.073650
  validation loss:		0.242702
  validation accuracy:		93.15 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.075739
  validation loss:		0.244341
  validation accuracy:		93.26 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.073450
  validation loss:		0.243982
  validation accuracy:		93.04 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.072489
  validation loss:		0.245866
  validation accuracy:		93.26 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.073863
  validation loss:		0.250677
  validation accuracy:		93.37 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.075112
  validation loss:		0.248462
  validation accuracy:		93.26 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.076502
  validation loss:		0.243849
  validation accuracy:		93.15 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.072785
  validation loss:		0.246998
  validation accuracy:		93.15 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.072428
  validation loss:		0.244023
  validation accuracy:		93.15 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.073391
  validation loss:		0.243023
  validation accuracy:		93.37 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.072803
  validation loss:		0.251496
  validation accuracy:		93.15 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.072361
  validation loss:		0.241381
  validation accuracy:		93.37 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.072842
  validation loss:		0.254445
  validation accuracy:		92.83 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.071409
  validation loss:		0.242278
  validation accuracy:		93.37 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.069672
  validation loss:		0.242445
  validation accuracy:		93.37 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.071218
  validation loss:		0.246389
  validation accuracy:		93.04 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.072983
  validation loss:		0.248859
  validation accuracy:		93.59 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.070943
  validation loss:		0.255276
  validation accuracy:		93.15 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.071514
  validation loss:		0.243513
  validation accuracy:		93.59 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.072564
  validation loss:		0.246709
  validation accuracy:		93.04 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.072008
  validation loss:		0.256314
  validation accuracy:		93.37 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.071711
  validation loss:		0.248596
  validation accuracy:		93.37 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.072149
  validation loss:		0.250592
  validation accuracy:		93.37 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.073593
  validation loss:		0.254133
  validation accuracy:		93.04 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.069230
  validation loss:		0.252531
  validation accuracy:		93.26 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.071210
  validation loss:		0.250577
  validation accuracy:		93.59 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.069271
  validation loss:		0.256036
  validation accuracy:		93.37 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.068045
  validation loss:		0.260880
  validation accuracy:		92.93 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.070148
  validation loss:		0.250698
  validation accuracy:		93.15 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.068834
  validation loss:		0.261108
  validation accuracy:		93.15 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.070168
  validation loss:		0.246321
  validation accuracy:		93.48 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.071295
  validation loss:		0.240141
  validation accuracy:		93.37 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.071022
  validation loss:		0.255405
  validation accuracy:		92.83 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.070640
  validation loss:		0.253703
  validation accuracy:		93.26 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.070640
  validation loss:		0.260261
  validation accuracy:		93.59 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.070368
  validation loss:		0.247108
  validation accuracy:		93.26 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.069002
  validation loss:		0.248846
  validation accuracy:		93.04 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.071451
  validation loss:		0.253352
  validation accuracy:		93.37 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.067045
  validation loss:		0.259967
  validation accuracy:		92.72 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.070314
  validation loss:		0.252257
  validation accuracy:		93.37 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.066526
  validation loss:		0.253838
  validation accuracy:		93.37 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.068184
  validation loss:		0.252027
  validation accuracy:		93.04 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.068381
  validation loss:		0.262232
  validation accuracy:		92.50 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.068791
  validation loss:		0.244969
  validation accuracy:		93.26 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.069666
  validation loss:		0.248850
  validation accuracy:		93.48 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.068212
  validation loss:		0.248989
  validation accuracy:		93.15 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.067668
  validation loss:		0.250523
  validation accuracy:		93.37 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.069269
  validation loss:		0.258666
  validation accuracy:		92.61 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.065280
  validation loss:		0.254039
  validation accuracy:		93.26 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.068286
  validation loss:		0.246911
  validation accuracy:		93.37 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.067726
  validation loss:		0.263177
  validation accuracy:		93.48 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.064880
  validation loss:		0.248169
  validation accuracy:		93.04 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.066367
  validation loss:		0.246242
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.067137
  validation loss:		0.255538
  validation accuracy:		93.15 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.065284
  validation loss:		0.261054
  validation accuracy:		93.26 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.066698
  validation loss:		0.256364
  validation accuracy:		93.48 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.065037
  validation loss:		0.258103
  validation accuracy:		93.26 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.066883
  validation loss:		0.255119
  validation accuracy:		93.26 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.066641
  validation loss:		0.251520
  validation accuracy:		93.26 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.067072
  validation loss:		0.256621
  validation accuracy:		93.48 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.064843
  validation loss:		0.263478
  validation accuracy:		93.26 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.064941
  validation loss:		0.254017
  validation accuracy:		93.37 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.066047
  validation loss:		0.264849
  validation accuracy:		93.15 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.065731
  validation loss:		0.250731
  validation accuracy:		93.37 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.064776
  validation loss:		0.272028
  validation accuracy:		92.83 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.064193
  validation loss:		0.264472
  validation accuracy:		92.93 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.064955
  validation loss:		0.262865
  validation accuracy:		93.37 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.064842
  validation loss:		0.256232
  validation accuracy:		93.59 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.064279
  validation loss:		0.257479
  validation accuracy:		93.15 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.064898
  validation loss:		0.257482
  validation accuracy:		93.37 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.061993
  validation loss:		0.263122
  validation accuracy:		93.04 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.064054
  validation loss:		0.266889
  validation accuracy:		93.04 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.063509
  validation loss:		0.259861
  validation accuracy:		93.26 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.062190
  validation loss:		0.270456
  validation accuracy:		93.37 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.063195
  validation loss:		0.276173
  validation accuracy:		92.83 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.064284
  validation loss:		0.261269
  validation accuracy:		93.04 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.062455
  validation loss:		0.266429
  validation accuracy:		93.48 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.062459
  validation loss:		0.262091
  validation accuracy:		93.48 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.061737
  validation loss:		0.254017
  validation accuracy:		93.48 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.061733
  validation loss:		0.275125
  validation accuracy:		92.39 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.064606
  validation loss:		0.250894
  validation accuracy:		93.70 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.063515
  validation loss:		0.259893
  validation accuracy:		93.37 %
Epoch 591 of 2000 took 0.036s
  training loss:		0.060181
  validation loss:		0.254453
  validation accuracy:		93.59 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.060837
  validation loss:		0.263396
  validation accuracy:		93.26 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.060524
  validation loss:		0.266635
  validation accuracy:		93.15 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.061926
  validation loss:		0.267852
  validation accuracy:		93.04 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.062102
  validation loss:		0.261305
  validation accuracy:		93.26 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.062609
  validation loss:		0.280546
  validation accuracy:		92.39 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.061339
  validation loss:		0.267689
  validation accuracy:		93.15 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.061139
  validation loss:		0.265047
  validation accuracy:		93.26 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.061133
  validation loss:		0.267833
  validation accuracy:		93.15 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.060446
  validation loss:		0.261079
  validation accuracy:		93.26 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.059713
  validation loss:		0.262126
  validation accuracy:		93.15 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.060620
  validation loss:		0.255975
  validation accuracy:		93.26 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.060451
  validation loss:		0.269622
  validation accuracy:		93.04 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.058450
  validation loss:		0.262696
  validation accuracy:		93.48 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.060157
  validation loss:		0.270128
  validation accuracy:		93.37 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.059521
  validation loss:		0.265603
  validation accuracy:		92.93 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.059892
  validation loss:		0.261770
  validation accuracy:		93.59 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.060391
  validation loss:		0.270819
  validation accuracy:		93.59 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.057412
  validation loss:		0.263193
  validation accuracy:		93.59 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.059580
  validation loss:		0.276595
  validation accuracy:		92.61 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.059171
  validation loss:		0.264882
  validation accuracy:		92.93 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.059446
  validation loss:		0.278663
  validation accuracy:		93.37 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.058060
  validation loss:		0.258996
  validation accuracy:		93.37 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.059937
  validation loss:		0.266522
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.057683
  validation loss:		0.288031
  validation accuracy:		92.93 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.056716
  validation loss:		0.267680
  validation accuracy:		92.93 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.057400
  validation loss:		0.264222
  validation accuracy:		93.91 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.058467
  validation loss:		0.270426
  validation accuracy:		93.04 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.058221
  validation loss:		0.260692
  validation accuracy:		93.59 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.058056
  validation loss:		0.273340
  validation accuracy:		93.04 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.060021
  validation loss:		0.272868
  validation accuracy:		93.04 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.058826
  validation loss:		0.278910
  validation accuracy:		93.04 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.058778
  validation loss:		0.275918
  validation accuracy:		93.15 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.056750
  validation loss:		0.268685
  validation accuracy:		93.15 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.057654
  validation loss:		0.268457
  validation accuracy:		93.15 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.057408
  validation loss:		0.271154
  validation accuracy:		93.37 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.055498
  validation loss:		0.273283
  validation accuracy:		93.37 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.057514
  validation loss:		0.276025
  validation accuracy:		93.15 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.057844
  validation loss:		0.270054
  validation accuracy:		93.37 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.058029
  validation loss:		0.265727
  validation accuracy:		93.48 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.056743
  validation loss:		0.271515
  validation accuracy:		93.26 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.055476
  validation loss:		0.278719
  validation accuracy:		93.15 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.055948
  validation loss:		0.269803
  validation accuracy:		93.48 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.053884
  validation loss:		0.279194
  validation accuracy:		92.83 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.056524
  validation loss:		0.272089
  validation accuracy:		93.15 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.057256
  validation loss:		0.267407
  validation accuracy:		93.48 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.056060
  validation loss:		0.281991
  validation accuracy:		93.04 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.055991
  validation loss:		0.273194
  validation accuracy:		93.59 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.054941
  validation loss:		0.283053
  validation accuracy:		93.04 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.056659
  validation loss:		0.283600
  validation accuracy:		93.26 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.054826
  validation loss:		0.280333
  validation accuracy:		93.15 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.054941
  validation loss:		0.279098
  validation accuracy:		93.15 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.054785
  validation loss:		0.278275
  validation accuracy:		93.26 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.055742
  validation loss:		0.280124
  validation accuracy:		92.83 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.054964
  validation loss:		0.283124
  validation accuracy:		93.15 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.054605
  validation loss:		0.273027
  validation accuracy:		93.15 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.054302
  validation loss:		0.273055
  validation accuracy:		93.15 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.054068
  validation loss:		0.280759
  validation accuracy:		93.37 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.055313
  validation loss:		0.274187
  validation accuracy:		93.48 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.055161
  validation loss:		0.276345
  validation accuracy:		93.37 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.052756
  validation loss:		0.277063
  validation accuracy:		93.37 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.052955
  validation loss:		0.295727
  validation accuracy:		92.72 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.054304
  validation loss:		0.287839
  validation accuracy:		92.83 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.051809
  validation loss:		0.276680
  validation accuracy:		93.37 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.054997
  validation loss:		0.281605
  validation accuracy:		93.04 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.052746
  validation loss:		0.286040
  validation accuracy:		93.26 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.054627
  validation loss:		0.274994
  validation accuracy:		93.59 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.052681
  validation loss:		0.273181
  validation accuracy:		93.26 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.053814
  validation loss:		0.280556
  validation accuracy:		93.26 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.053610
  validation loss:		0.284639
  validation accuracy:		93.15 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.051912
  validation loss:		0.278051
  validation accuracy:		93.37 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.053421
  validation loss:		0.283752
  validation accuracy:		92.93 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.051849
  validation loss:		0.288582
  validation accuracy:		93.37 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.052756
  validation loss:		0.289039
  validation accuracy:		92.72 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.053116
  validation loss:		0.271227
  validation accuracy:		93.80 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.050801
  validation loss:		0.279231
  validation accuracy:		93.37 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.053429
  validation loss:		0.302643
  validation accuracy:		92.39 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.052756
  validation loss:		0.286281
  validation accuracy:		93.15 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.050643
  validation loss:		0.280120
  validation accuracy:		93.15 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.051088
  validation loss:		0.292637
  validation accuracy:		92.72 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.051694
  validation loss:		0.288265
  validation accuracy:		92.72 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.049576
  validation loss:		0.284493
  validation accuracy:		93.37 %
Epoch 673 of 2000 took 0.036s
  training loss:		0.050327
  validation loss:		0.279891
  validation accuracy:		93.59 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.050813
  validation loss:		0.285279
  validation accuracy:		93.15 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.052015
  validation loss:		0.280541
  validation accuracy:		93.26 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.050451
  validation loss:		0.282946
  validation accuracy:		93.04 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.049746
  validation loss:		0.285960
  validation accuracy:		93.15 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.049928
  validation loss:		0.284514
  validation accuracy:		93.15 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.049856
  validation loss:		0.290493
  validation accuracy:		92.83 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.050681
  validation loss:		0.288269
  validation accuracy:		93.04 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.050412
  validation loss:		0.288707
  validation accuracy:		92.93 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.050767
  validation loss:		0.284722
  validation accuracy:		93.26 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.052069
  validation loss:		0.284839
  validation accuracy:		93.26 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.049553
  validation loss:		0.286127
  validation accuracy:		92.93 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.051520
  validation loss:		0.287329
  validation accuracy:		92.83 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.050349
  validation loss:		0.281409
  validation accuracy:		93.15 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.048034
  validation loss:		0.288653
  validation accuracy:		92.93 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.050607
  validation loss:		0.297196
  validation accuracy:		92.83 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.050517
  validation loss:		0.287981
  validation accuracy:		93.04 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.049094
  validation loss:		0.287513
  validation accuracy:		92.93 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.047599
  validation loss:		0.284797
  validation accuracy:		93.48 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.049641
  validation loss:		0.288241
  validation accuracy:		93.37 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.049082
  validation loss:		0.295429
  validation accuracy:		93.15 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.048425
  validation loss:		0.278491
  validation accuracy:		93.59 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.049453
  validation loss:		0.291441
  validation accuracy:		92.93 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.048210
  validation loss:		0.287834
  validation accuracy:		93.15 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.048517
  validation loss:		0.304075
  validation accuracy:		92.83 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.048169
  validation loss:		0.290414
  validation accuracy:		93.59 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.047172
  validation loss:		0.287497
  validation accuracy:		93.26 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.048468
  validation loss:		0.289670
  validation accuracy:		93.15 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.048925
  validation loss:		0.291837
  validation accuracy:		92.83 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.047196
  validation loss:		0.292363
  validation accuracy:		93.15 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.048859
  validation loss:		0.288663
  validation accuracy:		93.59 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.047940
  validation loss:		0.295156
  validation accuracy:		92.93 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.048089
  validation loss:		0.288388
  validation accuracy:		93.48 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.048432
  validation loss:		0.299773
  validation accuracy:		92.50 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.047449
  validation loss:		0.292665
  validation accuracy:		93.04 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.048347
  validation loss:		0.289171
  validation accuracy:		93.37 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.048540
  validation loss:		0.298359
  validation accuracy:		92.72 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.049156
  validation loss:		0.285382
  validation accuracy:		93.59 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.048026
  validation loss:		0.293708
  validation accuracy:		93.15 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.047485
  validation loss:		0.286469
  validation accuracy:		93.37 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.047744
  validation loss:		0.308808
  validation accuracy:		92.61 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.047258
  validation loss:		0.294391
  validation accuracy:		93.04 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.047598
  validation loss:		0.300505
  validation accuracy:		92.93 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.046702
  validation loss:		0.294156
  validation accuracy:		93.26 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.045306
  validation loss:		0.292126
  validation accuracy:		93.04 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.044405
  validation loss:		0.288900
  validation accuracy:		93.48 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.046874
  validation loss:		0.287780
  validation accuracy:		93.37 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.045827
  validation loss:		0.292888
  validation accuracy:		93.15 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.045859
  validation loss:		0.293928
  validation accuracy:		93.15 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.045841
  validation loss:		0.299598
  validation accuracy:		92.83 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.047526
  validation loss:		0.297393
  validation accuracy:		92.93 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.046401
  validation loss:		0.289339
  validation accuracy:		93.59 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.043629
  validation loss:		0.296654
  validation accuracy:		93.15 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.044166
  validation loss:		0.299802
  validation accuracy:		92.93 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.045741
  validation loss:		0.293627
  validation accuracy:		93.26 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.045109
  validation loss:		0.311558
  validation accuracy:		92.83 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.044971
  validation loss:		0.299738
  validation accuracy:		93.04 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.045408
  validation loss:		0.295604
  validation accuracy:		92.93 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.045328
  validation loss:		0.307917
  validation accuracy:		92.72 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.045367
  validation loss:		0.308232
  validation accuracy:		92.83 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.043559
  validation loss:		0.303312
  validation accuracy:		92.93 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.044751
  validation loss:		0.298953
  validation accuracy:		92.93 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.043322
  validation loss:		0.304535
  validation accuracy:		92.93 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.044973
  validation loss:		0.284952
  validation accuracy:		93.80 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.045420
  validation loss:		0.303183
  validation accuracy:		92.83 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.044680
  validation loss:		0.301519
  validation accuracy:		92.93 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.044600
  validation loss:		0.301954
  validation accuracy:		93.26 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.043804
  validation loss:		0.305347
  validation accuracy:		93.04 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.044788
  validation loss:		0.291946
  validation accuracy:		93.48 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.043961
  validation loss:		0.301220
  validation accuracy:		93.26 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.044158
  validation loss:		0.307670
  validation accuracy:		92.72 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.043524
  validation loss:		0.310535
  validation accuracy:		92.72 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.043499
  validation loss:		0.302751
  validation accuracy:		92.93 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.044480
  validation loss:		0.308960
  validation accuracy:		92.61 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.043740
  validation loss:		0.308530
  validation accuracy:		92.93 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.042906
  validation loss:		0.302976
  validation accuracy:		93.04 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.043291
  validation loss:		0.310583
  validation accuracy:		92.83 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.044369
  validation loss:		0.303183
  validation accuracy:		93.26 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.042685
  validation loss:		0.307909
  validation accuracy:		92.72 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.042461
  validation loss:		0.309117
  validation accuracy:		93.15 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.043558
  validation loss:		0.306437
  validation accuracy:		92.83 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.041933
  validation loss:		0.311337
  validation accuracy:		93.04 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.040215
  validation loss:		0.320068
  validation accuracy:		92.39 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.040893
  validation loss:		0.310039
  validation accuracy:		92.83 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.042837
  validation loss:		0.316185
  validation accuracy:		92.72 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.042226
  validation loss:		0.312007
  validation accuracy:		92.93 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.043113
  validation loss:		0.304867
  validation accuracy:		93.15 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.042312
  validation loss:		0.298474
  validation accuracy:		93.48 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.041411
  validation loss:		0.315044
  validation accuracy:		92.93 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.041991
  validation loss:		0.307689
  validation accuracy:		93.15 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.041435
  validation loss:		0.311411
  validation accuracy:		92.93 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.041674
  validation loss:		0.306341
  validation accuracy:		92.93 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.042605
  validation loss:		0.307425
  validation accuracy:		93.26 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.041932
  validation loss:		0.309803
  validation accuracy:		92.83 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.040308
  validation loss:		0.309872
  validation accuracy:		93.15 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.041880
  validation loss:		0.305843
  validation accuracy:		93.37 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.041742
  validation loss:		0.312608
  validation accuracy:		92.83 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.040515
  validation loss:		0.302472
  validation accuracy:		93.48 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.040679
  validation loss:		0.302250
  validation accuracy:		93.48 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.039615
  validation loss:		0.314953
  validation accuracy:		92.72 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.040824
  validation loss:		0.310465
  validation accuracy:		93.04 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.039507
  validation loss:		0.321698
  validation accuracy:		92.50 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.040979
  validation loss:		0.313467
  validation accuracy:		92.93 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.041623
  validation loss:		0.319585
  validation accuracy:		92.72 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.041132
  validation loss:		0.303242
  validation accuracy:		93.37 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.040477
  validation loss:		0.307840
  validation accuracy:		93.04 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.040902
  validation loss:		0.312170
  validation accuracy:		92.83 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.040331
  validation loss:		0.306260
  validation accuracy:		93.26 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.040459
  validation loss:		0.317799
  validation accuracy:		92.93 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.040621
  validation loss:		0.322218
  validation accuracy:		92.72 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.039114
  validation loss:		0.309624
  validation accuracy:		93.15 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.038799
  validation loss:		0.324710
  validation accuracy:		92.61 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.039915
  validation loss:		0.315056
  validation accuracy:		92.83 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.038660
  validation loss:		0.330027
  validation accuracy:		92.61 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.039287
  validation loss:		0.308446
  validation accuracy:		92.93 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.039090
  validation loss:		0.317377
  validation accuracy:		93.04 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.038832
  validation loss:		0.320272
  validation accuracy:		92.83 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.039412
  validation loss:		0.318656
  validation accuracy:		93.04 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.038079
  validation loss:		0.325882
  validation accuracy:		92.72 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.039245
  validation loss:		0.318297
  validation accuracy:		92.72 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.038802
  validation loss:		0.324879
  validation accuracy:		92.72 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.037514
  validation loss:		0.330652
  validation accuracy:		92.50 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.038929
  validation loss:		0.314293
  validation accuracy:		93.04 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.037835
  validation loss:		0.322760
  validation accuracy:		93.15 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.037410
  validation loss:		0.319061
  validation accuracy:		92.93 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.038148
  validation loss:		0.322274
  validation accuracy:		92.72 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.039098
  validation loss:		0.328157
  validation accuracy:		92.83 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.038546
  validation loss:		0.312062
  validation accuracy:		92.93 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.037902
  validation loss:		0.319803
  validation accuracy:		93.04 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.037518
  validation loss:		0.311177
  validation accuracy:		93.26 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.036779
  validation loss:		0.329325
  validation accuracy:		92.83 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.038764
  validation loss:		0.315166
  validation accuracy:		93.04 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.036812
  validation loss:		0.323321
  validation accuracy:		92.93 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.038597
  validation loss:		0.324431
  validation accuracy:		92.93 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.038051
  validation loss:		0.315927
  validation accuracy:		93.48 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.038243
  validation loss:		0.325073
  validation accuracy:		92.72 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.036389
  validation loss:		0.329985
  validation accuracy:		92.72 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.036693
  validation loss:		0.323292
  validation accuracy:		93.04 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.036905
  validation loss:		0.320412
  validation accuracy:		92.83 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.037349
  validation loss:		0.326363
  validation accuracy:		92.72 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.035124
  validation loss:		0.334050
  validation accuracy:		92.72 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.037550
  validation loss:		0.323763
  validation accuracy:		92.93 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.037592
  validation loss:		0.320412
  validation accuracy:		93.04 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.036920
  validation loss:		0.322538
  validation accuracy:		92.83 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.037014
  validation loss:		0.320042
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.035604
  validation loss:		0.317810
  validation accuracy:		93.26 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.037210
  validation loss:		0.317213
  validation accuracy:		93.04 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.037795
  validation loss:		0.326478
  validation accuracy:		93.15 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.035656
  validation loss:		0.326497
  validation accuracy:		92.83 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.037512
  validation loss:		0.323436
  validation accuracy:		92.83 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.037637
  validation loss:		0.326104
  validation accuracy:		93.04 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.035638
  validation loss:		0.324781
  validation accuracy:		92.93 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.036141
  validation loss:		0.325054
  validation accuracy:		92.93 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.036190
  validation loss:		0.334770
  validation accuracy:		92.50 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.036362
  validation loss:		0.336706
  validation accuracy:		92.83 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.036127
  validation loss:		0.328672
  validation accuracy:		92.83 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.035906
  validation loss:		0.328374
  validation accuracy:		92.72 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.036867
  validation loss:		0.322699
  validation accuracy:		93.26 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.035491
  validation loss:		0.328985
  validation accuracy:		92.93 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.036614
  validation loss:		0.326200
  validation accuracy:		92.93 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.035561
  validation loss:		0.332609
  validation accuracy:		93.04 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.034336
  validation loss:		0.336118
  validation accuracy:		92.61 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.034365
  validation loss:		0.340687
  validation accuracy:		92.83 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.036327
  validation loss:		0.334704
  validation accuracy:		92.83 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.035853
  validation loss:		0.322379
  validation accuracy:		93.26 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.035272
  validation loss:		0.326737
  validation accuracy:		93.15 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.035317
  validation loss:		0.330549
  validation accuracy:		93.15 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.035204
  validation loss:		0.318718
  validation accuracy:		93.26 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.035541
  validation loss:		0.333785
  validation accuracy:		93.04 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.035215
  validation loss:		0.328953
  validation accuracy:		93.26 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.033829
  validation loss:		0.331170
  validation accuracy:		93.26 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.034761
  validation loss:		0.331564
  validation accuracy:		93.15 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.033511
  validation loss:		0.329939
  validation accuracy:		93.04 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.034002
  validation loss:		0.328924
  validation accuracy:		93.15 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.034694
  validation loss:		0.336689
  validation accuracy:		92.93 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.032558
  validation loss:		0.338771
  validation accuracy:		92.93 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.033959
  validation loss:		0.335846
  validation accuracy:		92.61 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.034913
  validation loss:		0.328741
  validation accuracy:		92.72 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.033224
  validation loss:		0.337376
  validation accuracy:		92.93 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.033810
  validation loss:		0.336223
  validation accuracy:		92.83 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.033333
  validation loss:		0.337661
  validation accuracy:		93.15 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.033335
  validation loss:		0.332136
  validation accuracy:		92.83 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.033848
  validation loss:		0.337944
  validation accuracy:		93.04 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.033753
  validation loss:		0.338564
  validation accuracy:		92.72 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.031656
  validation loss:		0.341795
  validation accuracy:		92.72 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.033509
  validation loss:		0.336438
  validation accuracy:		93.04 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.034859
  validation loss:		0.326919
  validation accuracy:		93.04 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.033775
  validation loss:		0.350054
  validation accuracy:		92.61 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.031415
  validation loss:		0.324985
  validation accuracy:		93.37 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.033465
  validation loss:		0.339630
  validation accuracy:		92.83 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.033598
  validation loss:		0.336265
  validation accuracy:		93.15 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.032516
  validation loss:		0.349068
  validation accuracy:		92.72 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.033118
  validation loss:		0.340721
  validation accuracy:		92.93 %
Epoch 866 of 2000 took 0.037s
  training loss:		0.032287
  validation loss:		0.337358
  validation accuracy:		92.93 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.033180
  validation loss:		0.340446
  validation accuracy:		92.93 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.032473
  validation loss:		0.337381
  validation accuracy:		93.04 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.033643
  validation loss:		0.330659
  validation accuracy:		93.26 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.032934
  validation loss:		0.333192
  validation accuracy:		93.04 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.031833
  validation loss:		0.344520
  validation accuracy:		92.72 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.030901
  validation loss:		0.349536
  validation accuracy:		92.72 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.033421
  validation loss:		0.336591
  validation accuracy:		93.04 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.031772
  validation loss:		0.341245
  validation accuracy:		93.15 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.031094
  validation loss:		0.344495
  validation accuracy:		92.83 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.033139
  validation loss:		0.355116
  validation accuracy:		92.28 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.031450
  validation loss:		0.341708
  validation accuracy:		92.93 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.031952
  validation loss:		0.344244
  validation accuracy:		92.93 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.031235
  validation loss:		0.349798
  validation accuracy:		92.93 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.032215
  validation loss:		0.343164
  validation accuracy:		92.93 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.031248
  validation loss:		0.346101
  validation accuracy:		92.83 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.031130
  validation loss:		0.336921
  validation accuracy:		92.93 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.031454
  validation loss:		0.349931
  validation accuracy:		92.83 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.032917
  validation loss:		0.337740
  validation accuracy:		92.93 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.032575
  validation loss:		0.333445
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.030814
  validation loss:		0.357386
  validation accuracy:		92.50 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.030437
  validation loss:		0.356417
  validation accuracy:		92.39 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.030957
  validation loss:		0.346054
  validation accuracy:		92.93 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.030637
  validation loss:		0.338077
  validation accuracy:		93.26 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.031916
  validation loss:		0.344222
  validation accuracy:		92.93 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.031168
  validation loss:		0.352242
  validation accuracy:		92.93 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.030075
  validation loss:		0.357518
  validation accuracy:		93.04 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.030233
  validation loss:		0.347069
  validation accuracy:		92.93 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.028752
  validation loss:		0.351478
  validation accuracy:		93.15 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.031048
  validation loss:		0.354808
  validation accuracy:		92.72 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.030324
  validation loss:		0.346885
  validation accuracy:		93.04 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.030241
  validation loss:		0.355965
  validation accuracy:		92.72 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.029542
  validation loss:		0.351008
  validation accuracy:		92.93 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.030247
  validation loss:		0.352796
  validation accuracy:		93.15 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.030151
  validation loss:		0.355372
  validation accuracy:		92.83 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.028941
  validation loss:		0.360120
  validation accuracy:		92.83 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.030445
  validation loss:		0.361551
  validation accuracy:		92.39 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.030941
  validation loss:		0.349144
  validation accuracy:		92.93 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.030168
  validation loss:		0.348467
  validation accuracy:		92.83 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.028920
  validation loss:		0.361201
  validation accuracy:		92.50 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.030145
  validation loss:		0.353494
  validation accuracy:		92.93 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.030558
  validation loss:		0.358876
  validation accuracy:		92.93 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.030338
  validation loss:		0.350221
  validation accuracy:		93.26 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.029193
  validation loss:		0.350825
  validation accuracy:		92.93 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.029883
  validation loss:		0.358888
  validation accuracy:		92.72 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.029594
  validation loss:		0.355347
  validation accuracy:		92.93 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.030486
  validation loss:		0.349571
  validation accuracy:		93.04 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.029093
  validation loss:		0.354740
  validation accuracy:		92.93 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.028690
  validation loss:		0.353217
  validation accuracy:		92.83 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.027882
  validation loss:		0.363671
  validation accuracy:		92.61 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.028926
  validation loss:		0.356470
  validation accuracy:		93.04 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.029593
  validation loss:		0.352264
  validation accuracy:		92.93 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.029132
  validation loss:		0.361112
  validation accuracy:		93.04 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.028423
  validation loss:		0.358588
  validation accuracy:		93.04 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.028815
  validation loss:		0.354550
  validation accuracy:		92.93 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.028222
  validation loss:		0.352453
  validation accuracy:		92.93 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.028770
  validation loss:		0.364884
  validation accuracy:		92.72 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.029228
  validation loss:		0.359886
  validation accuracy:		92.72 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.028926
  validation loss:		0.355688
  validation accuracy:		92.72 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.028933
  validation loss:		0.363296
  validation accuracy:		92.93 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.027225
  validation loss:		0.358937
  validation accuracy:		92.93 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.026281
  validation loss:		0.368670
  validation accuracy:		92.93 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.029164
  validation loss:		0.376522
  validation accuracy:		92.17 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.027986
  validation loss:		0.374549
  validation accuracy:		92.39 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.029344
  validation loss:		0.358911
  validation accuracy:		93.04 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.027497
  validation loss:		0.360556
  validation accuracy:		92.93 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.028208
  validation loss:		0.361943
  validation accuracy:		92.93 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.028364
  validation loss:		0.354802
  validation accuracy:		92.61 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.028662
  validation loss:		0.362270
  validation accuracy:		93.04 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.027576
  validation loss:		0.376239
  validation accuracy:		92.50 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.028441
  validation loss:		0.359876
  validation accuracy:		93.04 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.028572
  validation loss:		0.371980
  validation accuracy:		92.61 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.028737
  validation loss:		0.364682
  validation accuracy:		92.83 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.027935
  validation loss:		0.358974
  validation accuracy:		92.93 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.027327
  validation loss:		0.364279
  validation accuracy:		93.26 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.027519
  validation loss:		0.360096
  validation accuracy:		93.04 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.028010
  validation loss:		0.375941
  validation accuracy:		92.61 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.027423
  validation loss:		0.362627
  validation accuracy:		93.04 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.026660
  validation loss:		0.364067
  validation accuracy:		93.04 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.027347
  validation loss:		0.357457
  validation accuracy:		92.83 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.028195
  validation loss:		0.374054
  validation accuracy:		92.83 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.026862
  validation loss:		0.375641
  validation accuracy:		92.72 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.025941
  validation loss:		0.363424
  validation accuracy:		92.72 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.025949
  validation loss:		0.365293
  validation accuracy:		93.04 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.027748
  validation loss:		0.383875
  validation accuracy:		92.61 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.026962
  validation loss:		0.361919
  validation accuracy:		92.93 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.026239
  validation loss:		0.370887
  validation accuracy:		92.93 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.026875
  validation loss:		0.366772
  validation accuracy:		92.93 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.026487
  validation loss:		0.362249
  validation accuracy:		92.93 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.026050
  validation loss:		0.382585
  validation accuracy:		92.28 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.027044
  validation loss:		0.370030
  validation accuracy:		92.93 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.027492
  validation loss:		0.357201
  validation accuracy:		93.04 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.026777
  validation loss:		0.367099
  validation accuracy:		92.93 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.025843
  validation loss:		0.374196
  validation accuracy:		92.72 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.026857
  validation loss:		0.372224
  validation accuracy:		92.83 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.026222
  validation loss:		0.371453
  validation accuracy:		92.93 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.025851
  validation loss:		0.369032
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.025772
  validation loss:		0.370412
  validation accuracy:		92.83 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.027549
  validation loss:		0.371211
  validation accuracy:		93.04 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.025959
  validation loss:		0.371383
  validation accuracy:		92.83 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.026308
  validation loss:		0.373643
  validation accuracy:		92.83 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.026018
  validation loss:		0.367805
  validation accuracy:		93.04 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.027101
  validation loss:		0.363323
  validation accuracy:		92.93 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.025269
  validation loss:		0.377954
  validation accuracy:		92.61 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.025560
  validation loss:		0.380494
  validation accuracy:		92.93 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.024949
  validation loss:		0.377161
  validation accuracy:		92.72 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.025373
  validation loss:		0.374339
  validation accuracy:		92.93 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.026614
  validation loss:		0.371404
  validation accuracy:		92.93 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.025693
  validation loss:		0.377482
  validation accuracy:		92.93 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.025511
  validation loss:		0.373867
  validation accuracy:		92.93 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.024781
  validation loss:		0.380923
  validation accuracy:		92.72 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.025124
  validation loss:		0.373674
  validation accuracy:		92.72 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.024247
  validation loss:		0.374140
  validation accuracy:		92.93 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.025311
  validation loss:		0.374846
  validation accuracy:		93.15 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.024643
  validation loss:		0.377065
  validation accuracy:		92.93 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.025592
  validation loss:		0.374106
  validation accuracy:		92.93 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.025985
  validation loss:		0.379319
  validation accuracy:		92.93 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.024976
  validation loss:		0.386485
  validation accuracy:		92.72 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.025167
  validation loss:		0.383741
  validation accuracy:		92.72 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.025064
  validation loss:		0.375669
  validation accuracy:		92.93 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.024166
  validation loss:		0.373202
  validation accuracy:		92.83 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.025512
  validation loss:		0.385855
  validation accuracy:		92.83 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.025139
  validation loss:		0.369904
  validation accuracy:		93.04 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.025174
  validation loss:		0.379578
  validation accuracy:		92.83 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.025171
  validation loss:		0.375847
  validation accuracy:		92.83 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.024335
  validation loss:		0.374867
  validation accuracy:		92.93 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.024709
  validation loss:		0.372415
  validation accuracy:		93.15 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.025942
  validation loss:		0.378024
  validation accuracy:		92.83 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.023843
  validation loss:		0.379408
  validation accuracy:		92.61 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.024427
  validation loss:		0.390134
  validation accuracy:		92.72 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.024493
  validation loss:		0.380562
  validation accuracy:		92.83 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.024103
  validation loss:		0.371210
  validation accuracy:		93.15 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.024005
  validation loss:		0.388991
  validation accuracy:		92.83 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.023692
  validation loss:		0.381447
  validation accuracy:		92.83 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.024361
  validation loss:		0.384371
  validation accuracy:		93.04 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.023668
  validation loss:		0.375747
  validation accuracy:		93.04 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.024257
  validation loss:		0.373801
  validation accuracy:		92.83 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.023912
  validation loss:		0.371596
  validation accuracy:		93.04 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.023426
  validation loss:		0.394131
  validation accuracy:		92.50 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.023003
  validation loss:		0.398118
  validation accuracy:		92.39 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.023897
  validation loss:		0.385569
  validation accuracy:		93.15 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.023583
  validation loss:		0.381479
  validation accuracy:		92.83 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.024111
  validation loss:		0.383604
  validation accuracy:		92.61 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.023795
  validation loss:		0.379460
  validation accuracy:		93.04 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.023137
  validation loss:		0.376915
  validation accuracy:		92.93 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.023950
  validation loss:		0.389092
  validation accuracy:		93.04 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.023398
  validation loss:		0.382248
  validation accuracy:		93.04 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.023196
  validation loss:		0.384067
  validation accuracy:		92.93 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.023242
  validation loss:		0.380144
  validation accuracy:		92.93 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.022717
  validation loss:		0.385723
  validation accuracy:		92.83 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.023222
  validation loss:		0.376950
  validation accuracy:		92.83 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.023479
  validation loss:		0.398522
  validation accuracy:		92.50 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.023228
  validation loss:		0.395336
  validation accuracy:		92.61 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.023853
  validation loss:		0.394829
  validation accuracy:		92.50 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.022522
  validation loss:		0.387124
  validation accuracy:		92.83 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.022607
  validation loss:		0.394155
  validation accuracy:		92.83 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.022808
  validation loss:		0.393104
  validation accuracy:		92.83 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.022978
  validation loss:		0.383933
  validation accuracy:		92.93 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.022080
  validation loss:		0.389998
  validation accuracy:		92.72 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.022800
  validation loss:		0.399877
  validation accuracy:		92.83 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.022804
  validation loss:		0.392497
  validation accuracy:		92.93 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.022469
  validation loss:		0.387998
  validation accuracy:		93.04 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.022445
  validation loss:		0.387470
  validation accuracy:		92.93 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.023101
  validation loss:		0.398518
  validation accuracy:		92.61 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.021511
  validation loss:		0.392780
  validation accuracy:		92.93 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.022888
  validation loss:		0.394605
  validation accuracy:		92.93 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.021680
  validation loss:		0.395888
  validation accuracy:		92.61 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.022047
  validation loss:		0.385432
  validation accuracy:		92.61 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.022756
  validation loss:		0.383107
  validation accuracy:		93.04 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.022377
  validation loss:		0.397663
  validation accuracy:		92.72 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.021968
  validation loss:		0.391053
  validation accuracy:		92.83 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.022185
  validation loss:		0.389648
  validation accuracy:		92.93 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.021762
  validation loss:		0.399101
  validation accuracy:		92.83 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.023079
  validation loss:		0.400258
  validation accuracy:		92.83 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.021526
  validation loss:		0.395938
  validation accuracy:		92.72 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.020664
  validation loss:		0.406064
  validation accuracy:		92.72 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.022072
  validation loss:		0.396240
  validation accuracy:		92.83 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.021383
  validation loss:		0.382163
  validation accuracy:		92.93 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.021460
  validation loss:		0.395541
  validation accuracy:		92.83 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.021640
  validation loss:		0.394353
  validation accuracy:		92.72 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.021850
  validation loss:		0.389108
  validation accuracy:		92.83 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.022039
  validation loss:		0.399525
  validation accuracy:		92.83 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.021628
  validation loss:		0.396402
  validation accuracy:		92.83 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.020995
  validation loss:		0.392979
  validation accuracy:		92.72 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.021497
  validation loss:		0.390748
  validation accuracy:		92.93 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.020813
  validation loss:		0.401267
  validation accuracy:		92.83 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.020829
  validation loss:		0.401952
  validation accuracy:		92.61 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.021982
  validation loss:		0.395145
  validation accuracy:		93.04 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.021362
  validation loss:		0.399991
  validation accuracy:		93.04 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.020986
  validation loss:		0.398919
  validation accuracy:		93.04 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.021165
  validation loss:		0.401273
  validation accuracy:		92.72 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.021144
  validation loss:		0.404922
  validation accuracy:		92.93 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.021573
  validation loss:		0.398587
  validation accuracy:		92.83 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.020491
  validation loss:		0.396227
  validation accuracy:		93.04 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.020912
  validation loss:		0.400832
  validation accuracy:		93.04 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.021158
  validation loss:		0.402622
  validation accuracy:		92.61 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.021444
  validation loss:		0.397274
  validation accuracy:		92.61 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.022305
  validation loss:		0.395413
  validation accuracy:		92.93 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.020704
  validation loss:		0.402241
  validation accuracy:		92.50 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.021160
  validation loss:		0.405280
  validation accuracy:		92.83 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.020318
  validation loss:		0.396904
  validation accuracy:		92.93 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.020398
  validation loss:		0.395762
  validation accuracy:		92.83 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.019848
  validation loss:		0.409557
  validation accuracy:		92.61 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.020686
  validation loss:		0.398378
  validation accuracy:		92.83 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.020421
  validation loss:		0.399346
  validation accuracy:		92.93 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.020334
  validation loss:		0.398775
  validation accuracy:		92.72 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.019741
  validation loss:		0.401209
  validation accuracy:		92.61 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.021343
  validation loss:		0.399644
  validation accuracy:		92.72 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.020692
  validation loss:		0.407305
  validation accuracy:		92.83 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.020565
  validation loss:		0.412284
  validation accuracy:		92.83 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.020096
  validation loss:		0.408379
  validation accuracy:		92.83 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.019289
  validation loss:		0.402051
  validation accuracy:		93.04 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.020276
  validation loss:		0.404466
  validation accuracy:		92.93 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.020581
  validation loss:		0.404948
  validation accuracy:		92.72 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.019150
  validation loss:		0.406815
  validation accuracy:		92.61 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.019538
  validation loss:		0.399478
  validation accuracy:		92.93 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.019516
  validation loss:		0.411829
  validation accuracy:		92.93 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.019351
  validation loss:		0.403746
  validation accuracy:		92.72 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.019843
  validation loss:		0.408577
  validation accuracy:		92.93 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.019968
  validation loss:		0.404800
  validation accuracy:		92.83 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.019389
  validation loss:		0.420256
  validation accuracy:		92.61 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.019585
  validation loss:		0.396765
  validation accuracy:		92.93 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.020424
  validation loss:		0.410333
  validation accuracy:		92.72 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.019819
  validation loss:		0.410861
  validation accuracy:		93.04 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.020213
  validation loss:		0.400285
  validation accuracy:		92.83 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.019101
  validation loss:		0.412525
  validation accuracy:		92.50 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.019188
  validation loss:		0.401480
  validation accuracy:		93.04 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.018998
  validation loss:		0.406368
  validation accuracy:		92.83 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.019821
  validation loss:		0.409353
  validation accuracy:		92.93 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.019865
  validation loss:		0.404021
  validation accuracy:		93.04 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.018142
  validation loss:		0.407673
  validation accuracy:		93.04 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.019326
  validation loss:		0.410257
  validation accuracy:		92.72 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.019141
  validation loss:		0.402108
  validation accuracy:		92.83 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.019871
  validation loss:		0.406877
  validation accuracy:		93.15 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.019497
  validation loss:		0.413456
  validation accuracy:		92.72 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.018746
  validation loss:		0.420090
  validation accuracy:		93.04 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.019267
  validation loss:		0.402607
  validation accuracy:		92.72 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.018666
  validation loss:		0.413903
  validation accuracy:		92.83 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.019204
  validation loss:		0.408799
  validation accuracy:		93.04 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.018637
  validation loss:		0.413759
  validation accuracy:		92.72 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.018761
  validation loss:		0.409229
  validation accuracy:		93.04 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.018573
  validation loss:		0.421832
  validation accuracy:		92.93 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.018851
  validation loss:		0.421091
  validation accuracy:		92.83 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.019066
  validation loss:		0.419947
  validation accuracy:		92.50 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.019310
  validation loss:		0.409409
  validation accuracy:		92.93 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.019354
  validation loss:		0.419445
  validation accuracy:		92.93 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.018483
  validation loss:		0.417602
  validation accuracy:		92.72 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.019096
  validation loss:		0.417754
  validation accuracy:		92.61 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.018183
  validation loss:		0.425270
  validation accuracy:		92.72 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.018175
  validation loss:		0.411296
  validation accuracy:		93.04 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.018461
  validation loss:		0.422617
  validation accuracy:		92.83 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.018922
  validation loss:		0.419352
  validation accuracy:		93.04 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.019069
  validation loss:		0.410215
  validation accuracy:		92.61 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.017878
  validation loss:		0.420052
  validation accuracy:		92.61 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.017774
  validation loss:		0.408715
  validation accuracy:		92.93 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.018651
  validation loss:		0.418396
  validation accuracy:		92.93 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.018281
  validation loss:		0.423675
  validation accuracy:		93.04 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.019009
  validation loss:		0.421101
  validation accuracy:		92.83 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.018188
  validation loss:		0.421029
  validation accuracy:		92.72 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.018312
  validation loss:		0.434904
  validation accuracy:		92.61 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.018944
  validation loss:		0.417716
  validation accuracy:		92.83 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.019205
  validation loss:		0.409504
  validation accuracy:		92.83 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.017858
  validation loss:		0.423496
  validation accuracy:		92.83 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.018111
  validation loss:		0.422079
  validation accuracy:		92.72 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.017850
  validation loss:		0.428643
  validation accuracy:		92.72 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.017806
  validation loss:		0.422826
  validation accuracy:		92.93 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.018036
  validation loss:		0.422252
  validation accuracy:		92.72 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.017809
  validation loss:		0.418458
  validation accuracy:		92.93 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.017703
  validation loss:		0.418945
  validation accuracy:		92.93 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.018384
  validation loss:		0.428572
  validation accuracy:		92.72 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.017099
  validation loss:		0.424916
  validation accuracy:		92.83 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.017743
  validation loss:		0.422032
  validation accuracy:		92.72 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.016454
  validation loss:		0.421534
  validation accuracy:		92.72 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.017554
  validation loss:		0.423866
  validation accuracy:		92.61 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.017334
  validation loss:		0.426110
  validation accuracy:		92.93 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.017085
  validation loss:		0.420112
  validation accuracy:		92.61 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.017942
  validation loss:		0.430240
  validation accuracy:		92.72 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.017796
  validation loss:		0.426476
  validation accuracy:		92.93 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.016924
  validation loss:		0.422416
  validation accuracy:		92.93 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.017534
  validation loss:		0.424402
  validation accuracy:		92.93 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.017465
  validation loss:		0.424668
  validation accuracy:		92.72 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.017017
  validation loss:		0.429874
  validation accuracy:		92.93 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.017219
  validation loss:		0.424648
  validation accuracy:		92.83 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.017110
  validation loss:		0.417743
  validation accuracy:		92.83 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.017284
  validation loss:		0.423513
  validation accuracy:		92.72 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.017477
  validation loss:		0.422688
  validation accuracy:		92.61 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.016855
  validation loss:		0.428660
  validation accuracy:		92.61 %
Epoch 1153 of 2000 took 0.036s
  training loss:		0.016712
  validation loss:		0.425962
  validation accuracy:		92.61 %
Epoch 1154 of 2000 took 0.036s
  training loss:		0.016800
  validation loss:		0.430628
  validation accuracy:		92.72 %
Epoch 1155 of 2000 took 0.036s
  training loss:		0.017438
  validation loss:		0.429605
  validation accuracy:		92.72 %
Epoch 1156 of 2000 took 0.036s
  training loss:		0.017186
  validation loss:		0.437198
  validation accuracy:		92.61 %
Epoch 1157 of 2000 took 0.036s
  training loss:		0.017162
  validation loss:		0.427618
  validation accuracy:		92.39 %
Epoch 1158 of 2000 took 0.053s
  training loss:		0.017663
  validation loss:		0.435392
  validation accuracy:		92.83 %
Epoch 1159 of 2000 took 0.052s
  training loss:		0.016703
  validation loss:		0.427795
  validation accuracy:		92.83 %
Epoch 1160 of 2000 took 0.044s
  training loss:		0.016369
  validation loss:		0.436157
  validation accuracy:		92.72 %
Epoch 1161 of 2000 took 0.040s
  training loss:		0.016815
  validation loss:		0.432985
  validation accuracy:		92.61 %
Epoch 1162 of 2000 took 0.037s
  training loss:		0.016946
  validation loss:		0.427620
  validation accuracy:		92.61 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.016799
  validation loss:		0.436565
  validation accuracy:		92.61 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.017234
  validation loss:		0.429348
  validation accuracy:		92.61 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.017179
  validation loss:		0.428838
  validation accuracy:		92.83 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.017131
  validation loss:		0.435493
  validation accuracy:		92.93 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.017079
  validation loss:		0.431201
  validation accuracy:		92.83 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.016135
  validation loss:		0.430977
  validation accuracy:		92.50 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.016223
  validation loss:		0.428712
  validation accuracy:		93.04 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.015865
  validation loss:		0.423970
  validation accuracy:		92.61 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.017430
  validation loss:		0.439409
  validation accuracy:		92.61 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.016868
  validation loss:		0.433600
  validation accuracy:		92.50 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.016063
  validation loss:		0.435926
  validation accuracy:		92.61 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.016540
  validation loss:		0.433548
  validation accuracy:		92.50 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.015766
  validation loss:		0.425503
  validation accuracy:		92.72 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.016608
  validation loss:		0.425560
  validation accuracy:		92.61 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.016453
  validation loss:		0.428733
  validation accuracy:		92.61 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.016109
  validation loss:		0.435966
  validation accuracy:		92.83 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.016236
  validation loss:		0.453539
  validation accuracy:		92.28 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.017245
  validation loss:		0.432109
  validation accuracy:		92.93 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.015966
  validation loss:		0.430360
  validation accuracy:		92.61 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.015221
  validation loss:		0.429891
  validation accuracy:		92.83 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.015324
  validation loss:		0.447669
  validation accuracy:		92.72 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.015992
  validation loss:		0.440368
  validation accuracy:		92.93 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.016024
  validation loss:		0.433661
  validation accuracy:		92.61 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.016126
  validation loss:		0.437070
  validation accuracy:		92.61 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.016088
  validation loss:		0.443073
  validation accuracy:		92.72 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.016234
  validation loss:		0.435043
  validation accuracy:		92.83 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.015704
  validation loss:		0.440779
  validation accuracy:		92.93 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.015935
  validation loss:		0.433681
  validation accuracy:		92.72 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.014734
  validation loss:		0.441311
  validation accuracy:		93.04 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.015657
  validation loss:		0.433144
  validation accuracy:		92.61 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.015704
  validation loss:		0.435136
  validation accuracy:		92.61 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.015123
  validation loss:		0.442053
  validation accuracy:		92.72 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.015013
  validation loss:		0.445906
  validation accuracy:		92.61 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.015242
  validation loss:		0.438059
  validation accuracy:		92.83 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.015345
  validation loss:		0.440785
  validation accuracy:		92.50 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.015533
  validation loss:		0.438207
  validation accuracy:		92.83 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.016079
  validation loss:		0.445233
  validation accuracy:		92.72 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.015143
  validation loss:		0.445025
  validation accuracy:		92.72 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.015448
  validation loss:		0.443134
  validation accuracy:		92.61 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.015567
  validation loss:		0.444194
  validation accuracy:		92.61 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.014906
  validation loss:		0.441316
  validation accuracy:		92.83 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.015700
  validation loss:		0.440041
  validation accuracy:		92.50 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.016016
  validation loss:		0.445075
  validation accuracy:		92.39 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.015811
  validation loss:		0.446365
  validation accuracy:		92.83 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.015103
  validation loss:		0.445610
  validation accuracy:		92.50 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.015023
  validation loss:		0.439167
  validation accuracy:		92.72 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.015678
  validation loss:		0.438897
  validation accuracy:		92.61 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.015202
  validation loss:		0.443477
  validation accuracy:		92.39 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.015538
  validation loss:		0.445796
  validation accuracy:		92.50 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.014504
  validation loss:		0.452367
  validation accuracy:		92.61 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.014848
  validation loss:		0.440763
  validation accuracy:		92.61 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.015174
  validation loss:		0.444876
  validation accuracy:		92.61 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.015195
  validation loss:		0.455825
  validation accuracy:		92.72 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.015237
  validation loss:		0.439738
  validation accuracy:		92.50 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.014631
  validation loss:		0.439681
  validation accuracy:		92.61 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.014828
  validation loss:		0.446429
  validation accuracy:		92.39 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.015226
  validation loss:		0.443908
  validation accuracy:		92.50 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.015636
  validation loss:		0.447558
  validation accuracy:		92.61 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.014299
  validation loss:		0.446420
  validation accuracy:		92.61 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.014643
  validation loss:		0.454624
  validation accuracy:		92.61 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.014408
  validation loss:		0.455632
  validation accuracy:		92.50 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.014776
  validation loss:		0.445165
  validation accuracy:		92.61 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.014298
  validation loss:		0.454877
  validation accuracy:		92.83 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.014854
  validation loss:		0.448002
  validation accuracy:		92.61 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.015323
  validation loss:		0.447553
  validation accuracy:		92.61 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.014696
  validation loss:		0.454978
  validation accuracy:		92.61 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.014314
  validation loss:		0.448398
  validation accuracy:		92.39 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.014265
  validation loss:		0.451266
  validation accuracy:		92.50 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.013985
  validation loss:		0.449766
  validation accuracy:		92.61 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.014890
  validation loss:		0.448293
  validation accuracy:		92.61 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.014069
  validation loss:		0.442932
  validation accuracy:		92.50 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.014225
  validation loss:		0.443676
  validation accuracy:		92.83 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.015197
  validation loss:		0.446331
  validation accuracy:		92.50 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.014592
  validation loss:		0.457982
  validation accuracy:		92.61 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.014260
  validation loss:		0.456701
  validation accuracy:		92.61 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.014591
  validation loss:		0.456796
  validation accuracy:		92.50 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.014142
  validation loss:		0.450804
  validation accuracy:		92.61 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.014075
  validation loss:		0.450818
  validation accuracy:		92.50 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.014266
  validation loss:		0.452012
  validation accuracy:		92.61 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.014144
  validation loss:		0.451850
  validation accuracy:		92.50 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.013936
  validation loss:		0.445556
  validation accuracy:		92.50 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.013924
  validation loss:		0.451909
  validation accuracy:		92.72 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.014637
  validation loss:		0.446926
  validation accuracy:		92.50 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.013599
  validation loss:		0.459302
  validation accuracy:		92.72 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.014158
  validation loss:		0.456364
  validation accuracy:		92.61 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.014089
  validation loss:		0.444725
  validation accuracy:		92.61 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.013753
  validation loss:		0.447084
  validation accuracy:		92.83 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.014154
  validation loss:		0.454263
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.014053
  validation loss:		0.459915
  validation accuracy:		92.50 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.013593
  validation loss:		0.457535
  validation accuracy:		92.50 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.013811
  validation loss:		0.454749
  validation accuracy:		92.50 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.013211
  validation loss:		0.447787
  validation accuracy:		92.50 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.013457
  validation loss:		0.462837
  validation accuracy:		92.83 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.013564
  validation loss:		0.459800
  validation accuracy:		92.61 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.012822
  validation loss:		0.455048
  validation accuracy:		92.50 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.013793
  validation loss:		0.461382
  validation accuracy:		92.61 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.013333
  validation loss:		0.463471
  validation accuracy:		92.50 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.013596
  validation loss:		0.450481
  validation accuracy:		92.50 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.013799
  validation loss:		0.474430
  validation accuracy:		92.50 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.014204
  validation loss:		0.461304
  validation accuracy:		92.61 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.013302
  validation loss:		0.465207
  validation accuracy:		92.50 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.012525
  validation loss:		0.458847
  validation accuracy:		92.50 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.013211
  validation loss:		0.456179
  validation accuracy:		92.50 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.013452
  validation loss:		0.455735
  validation accuracy:		92.61 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.012987
  validation loss:		0.454299
  validation accuracy:		92.61 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.013173
  validation loss:		0.462424
  validation accuracy:		92.39 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.013314
  validation loss:		0.467710
  validation accuracy:		92.50 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.013224
  validation loss:		0.459343
  validation accuracy:		92.72 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.013217
  validation loss:		0.459341
  validation accuracy:		92.72 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.012937
  validation loss:		0.456207
  validation accuracy:		92.61 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.012767
  validation loss:		0.468731
  validation accuracy:		92.28 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.013737
  validation loss:		0.471316
  validation accuracy:		92.50 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.013018
  validation loss:		0.462122
  validation accuracy:		92.39 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.013468
  validation loss:		0.468536
  validation accuracy:		92.28 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.013027
  validation loss:		0.457652
  validation accuracy:		92.50 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.013114
  validation loss:		0.466063
  validation accuracy:		92.72 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.013265
  validation loss:		0.461321
  validation accuracy:		92.50 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.012905
  validation loss:		0.476488
  validation accuracy:		92.50 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.013526
  validation loss:		0.470016
  validation accuracy:		92.61 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.013289
  validation loss:		0.474578
  validation accuracy:		92.61 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.013182
  validation loss:		0.459218
  validation accuracy:		92.50 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.012970
  validation loss:		0.466599
  validation accuracy:		92.61 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.013012
  validation loss:		0.480981
  validation accuracy:		92.61 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.012940
  validation loss:		0.457615
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.012848
  validation loss:		0.463718
  validation accuracy:		92.61 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.013307
  validation loss:		0.467080
  validation accuracy:		92.72 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.011992
  validation loss:		0.454938
  validation accuracy:		92.72 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.012944
  validation loss:		0.471171
  validation accuracy:		92.28 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.013044
  validation loss:		0.472387
  validation accuracy:		92.39 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.013073
  validation loss:		0.465993
  validation accuracy:		92.50 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.012661
  validation loss:		0.471308
  validation accuracy:		92.50 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.012820
  validation loss:		0.461405
  validation accuracy:		92.50 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.012704
  validation loss:		0.463483
  validation accuracy:		92.61 %
Epoch 1296 of 2000 took 0.036s
  training loss:		0.012724
  validation loss:		0.466755
  validation accuracy:		92.61 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.012661
  validation loss:		0.468510
  validation accuracy:		92.28 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.013015
  validation loss:		0.471990
  validation accuracy:		92.72 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.012135
  validation loss:		0.475487
  validation accuracy:		92.28 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.012558
  validation loss:		0.468825
  validation accuracy:		92.50 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.012490
  validation loss:		0.479169
  validation accuracy:		92.50 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.012352
  validation loss:		0.473253
  validation accuracy:		92.39 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.012238
  validation loss:		0.471422
  validation accuracy:		92.61 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.012334
  validation loss:		0.478820
  validation accuracy:		92.61 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.012610
  validation loss:		0.469634
  validation accuracy:		92.50 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.012513
  validation loss:		0.471161
  validation accuracy:		92.50 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.012980
  validation loss:		0.471520
  validation accuracy:		92.50 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.012281
  validation loss:		0.475924
  validation accuracy:		92.50 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.012054
  validation loss:		0.472953
  validation accuracy:		92.50 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.012838
  validation loss:		0.468886
  validation accuracy:		92.28 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.012441
  validation loss:		0.471629
  validation accuracy:		92.50 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.012436
  validation loss:		0.475492
  validation accuracy:		92.39 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.011997
  validation loss:		0.467301
  validation accuracy:		92.50 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.012643
  validation loss:		0.479924
  validation accuracy:		92.50 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.011784
  validation loss:		0.467949
  validation accuracy:		92.39 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.012510
  validation loss:		0.471365
  validation accuracy:		92.50 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.011518
  validation loss:		0.472723
  validation accuracy:		92.50 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.012113
  validation loss:		0.476997
  validation accuracy:		92.50 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.012090
  validation loss:		0.471108
  validation accuracy:		92.61 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.011881
  validation loss:		0.467795
  validation accuracy:		92.50 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.012366
  validation loss:		0.473937
  validation accuracy:		92.39 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.012015
  validation loss:		0.470104
  validation accuracy:		92.61 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.012459
  validation loss:		0.473978
  validation accuracy:		92.39 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.011902
  validation loss:		0.474192
  validation accuracy:		92.61 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.011953
  validation loss:		0.483819
  validation accuracy:		92.17 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.012227
  validation loss:		0.469923
  validation accuracy:		92.39 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.011660
  validation loss:		0.480732
  validation accuracy:		92.39 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.011864
  validation loss:		0.473565
  validation accuracy:		92.50 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.011882
  validation loss:		0.469579
  validation accuracy:		92.61 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.011714
  validation loss:		0.481086
  validation accuracy:		92.50 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.011776
  validation loss:		0.479130
  validation accuracy:		92.50 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.011804
  validation loss:		0.474950
  validation accuracy:		92.50 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.011707
  validation loss:		0.484821
  validation accuracy:		92.39 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.011762
  validation loss:		0.477801
  validation accuracy:		92.50 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.011569
  validation loss:		0.477797
  validation accuracy:		92.50 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.011748
  validation loss:		0.481083
  validation accuracy:		92.50 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.011550
  validation loss:		0.485601
  validation accuracy:		92.50 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.011604
  validation loss:		0.488513
  validation accuracy:		92.39 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.011606
  validation loss:		0.467571
  validation accuracy:		92.50 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.011785
  validation loss:		0.478002
  validation accuracy:		92.39 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.011265
  validation loss:		0.493267
  validation accuracy:		92.07 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.011827
  validation loss:		0.495917
  validation accuracy:		92.28 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.011682
  validation loss:		0.489499
  validation accuracy:		92.50 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.011528
  validation loss:		0.481938
  validation accuracy:		92.50 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.011587
  validation loss:		0.475779
  validation accuracy:		92.39 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.011139
  validation loss:		0.477504
  validation accuracy:		92.83 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.011200
  validation loss:		0.481498
  validation accuracy:		92.50 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.011372
  validation loss:		0.481372
  validation accuracy:		92.28 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.010751
  validation loss:		0.483154
  validation accuracy:		92.50 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.011249
  validation loss:		0.481137
  validation accuracy:		92.61 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.011362
  validation loss:		0.482400
  validation accuracy:		92.39 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.010960
  validation loss:		0.481244
  validation accuracy:		92.39 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.011495
  validation loss:		0.480352
  validation accuracy:		92.50 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.011064
  validation loss:		0.479536
  validation accuracy:		92.39 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.011113
  validation loss:		0.489295
  validation accuracy:		92.50 %
Epoch 1356 of 2000 took 0.036s
  training loss:		0.011008
  validation loss:		0.488907
  validation accuracy:		92.28 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.011256
  validation loss:		0.487264
  validation accuracy:		92.50 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.011365
  validation loss:		0.488030
  validation accuracy:		92.39 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.010991
  validation loss:		0.483705
  validation accuracy:		92.39 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.011051
  validation loss:		0.484656
  validation accuracy:		92.50 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.010811
  validation loss:		0.481857
  validation accuracy:		92.39 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.010549
  validation loss:		0.475537
  validation accuracy:		92.61 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.010706
  validation loss:		0.483958
  validation accuracy:		92.50 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.010901
  validation loss:		0.475106
  validation accuracy:		92.61 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.011360
  validation loss:		0.496424
  validation accuracy:		92.39 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.010951
  validation loss:		0.475937
  validation accuracy:		92.61 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.010886
  validation loss:		0.491172
  validation accuracy:		92.50 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.010819
  validation loss:		0.489025
  validation accuracy:		92.28 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.011087
  validation loss:		0.488140
  validation accuracy:		92.50 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.010705
  validation loss:		0.487736
  validation accuracy:		92.39 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.011018
  validation loss:		0.487301
  validation accuracy:		92.28 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.010345
  validation loss:		0.480166
  validation accuracy:		92.39 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.010576
  validation loss:		0.487179
  validation accuracy:		92.61 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.011030
  validation loss:		0.477195
  validation accuracy:		92.50 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.011000
  validation loss:		0.480664
  validation accuracy:		92.28 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.011017
  validation loss:		0.499695
  validation accuracy:		92.39 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.010789
  validation loss:		0.489159
  validation accuracy:		92.28 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.010782
  validation loss:		0.483054
  validation accuracy:		92.39 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.010621
  validation loss:		0.495907
  validation accuracy:		92.28 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.010874
  validation loss:		0.503070
  validation accuracy:		92.17 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.011081
  validation loss:		0.487127
  validation accuracy:		92.39 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.010726
  validation loss:		0.488593
  validation accuracy:		92.39 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.010714
  validation loss:		0.486168
  validation accuracy:		92.61 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.010448
  validation loss:		0.489131
  validation accuracy:		92.39 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.010329
  validation loss:		0.484681
  validation accuracy:		92.50 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.010452
  validation loss:		0.489138
  validation accuracy:		92.61 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.010754
  validation loss:		0.496742
  validation accuracy:		92.39 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.010554
  validation loss:		0.489814
  validation accuracy:		92.50 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.010077
  validation loss:		0.483365
  validation accuracy:		92.28 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.010574
  validation loss:		0.500494
  validation accuracy:		92.39 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.010289
  validation loss:		0.504314
  validation accuracy:		92.17 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.010332
  validation loss:		0.494468
  validation accuracy:		92.07 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.010240
  validation loss:		0.484226
  validation accuracy:		92.28 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.009905
  validation loss:		0.486577
  validation accuracy:		92.61 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.010185
  validation loss:		0.484380
  validation accuracy:		92.50 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.010455
  validation loss:		0.495965
  validation accuracy:		92.39 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.010294
  validation loss:		0.494260
  validation accuracy:		92.28 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.010434
  validation loss:		0.497913
  validation accuracy:		92.39 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.010503
  validation loss:		0.493600
  validation accuracy:		92.39 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.010219
  validation loss:		0.495473
  validation accuracy:		92.39 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.010515
  validation loss:		0.499090
  validation accuracy:		92.28 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.010119
  validation loss:		0.496305
  validation accuracy:		92.39 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.010512
  validation loss:		0.503107
  validation accuracy:		92.28 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.010465
  validation loss:		0.498747
  validation accuracy:		92.39 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.010100
  validation loss:		0.494124
  validation accuracy:		92.39 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.009839
  validation loss:		0.507524
  validation accuracy:		92.28 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.010137
  validation loss:		0.493024
  validation accuracy:		92.28 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.010262
  validation loss:		0.496758
  validation accuracy:		92.50 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.009950
  validation loss:		0.492673
  validation accuracy:		92.39 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.010100
  validation loss:		0.497261
  validation accuracy:		92.50 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.010180
  validation loss:		0.506068
  validation accuracy:		92.39 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.010194
  validation loss:		0.502518
  validation accuracy:		92.39 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.009718
  validation loss:		0.502005
  validation accuracy:		92.50 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.010031
  validation loss:		0.499206
  validation accuracy:		92.50 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.009726
  validation loss:		0.490438
  validation accuracy:		92.50 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.009793
  validation loss:		0.500701
  validation accuracy:		92.28 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.009958
  validation loss:		0.497160
  validation accuracy:		92.17 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.009963
  validation loss:		0.500316
  validation accuracy:		92.28 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.009412
  validation loss:		0.504555
  validation accuracy:		92.28 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.009824
  validation loss:		0.502951
  validation accuracy:		92.50 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.009896
  validation loss:		0.496312
  validation accuracy:		92.50 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.009449
  validation loss:		0.506542
  validation accuracy:		92.50 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.009487
  validation loss:		0.499873
  validation accuracy:		92.28 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.009910
  validation loss:		0.500774
  validation accuracy:		92.50 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.009868
  validation loss:		0.506035
  validation accuracy:		92.39 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.010150
  validation loss:		0.509809
  validation accuracy:		92.28 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.009523
  validation loss:		0.502262
  validation accuracy:		92.17 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.009797
  validation loss:		0.507627
  validation accuracy:		92.28 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.009674
  validation loss:		0.503631
  validation accuracy:		92.50 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.009758
  validation loss:		0.498232
  validation accuracy:		92.39 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.009339
  validation loss:		0.502434
  validation accuracy:		92.61 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.009372
  validation loss:		0.492596
  validation accuracy:		92.39 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.009464
  validation loss:		0.504501
  validation accuracy:		92.50 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.009881
  validation loss:		0.500021
  validation accuracy:		92.50 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.009031
  validation loss:		0.521129
  validation accuracy:		92.39 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.009737
  validation loss:		0.507872
  validation accuracy:		92.28 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.009836
  validation loss:		0.501536
  validation accuracy:		92.61 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.009703
  validation loss:		0.499796
  validation accuracy:		92.39 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.009150
  validation loss:		0.506090
  validation accuracy:		92.39 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.009462
  validation loss:		0.501798
  validation accuracy:		92.50 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.009667
  validation loss:		0.510202
  validation accuracy:		92.17 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.008970
  validation loss:		0.514723
  validation accuracy:		92.17 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.009753
  validation loss:		0.512883
  validation accuracy:		92.28 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.009507
  validation loss:		0.501567
  validation accuracy:		92.39 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.009569
  validation loss:		0.507688
  validation accuracy:		92.50 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.009497
  validation loss:		0.509969
  validation accuracy:		92.50 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.009256
  validation loss:		0.500590
  validation accuracy:		92.39 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.009686
  validation loss:		0.515665
  validation accuracy:		92.50 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.009657
  validation loss:		0.515405
  validation accuracy:		92.39 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.009318
  validation loss:		0.511926
  validation accuracy:		92.39 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.009304
  validation loss:		0.502957
  validation accuracy:		92.28 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.009484
  validation loss:		0.499127
  validation accuracy:		92.61 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.009386
  validation loss:		0.508941
  validation accuracy:		92.39 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.009132
  validation loss:		0.498285
  validation accuracy:		92.61 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.009288
  validation loss:		0.516423
  validation accuracy:		92.39 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.009209
  validation loss:		0.512518
  validation accuracy:		92.28 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.009172
  validation loss:		0.506751
  validation accuracy:		92.28 %
Epoch 1458 of 2000 took 0.036s
  training loss:		0.009783
  validation loss:		0.515234
  validation accuracy:		92.17 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.009626
  validation loss:		0.517490
  validation accuracy:		92.50 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.009245
  validation loss:		0.503641
  validation accuracy:		92.50 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.009207
  validation loss:		0.505434
  validation accuracy:		92.28 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.009257
  validation loss:		0.510622
  validation accuracy:		92.28 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.009183
  validation loss:		0.506102
  validation accuracy:		92.39 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.008952
  validation loss:		0.515566
  validation accuracy:		92.39 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.009059
  validation loss:		0.506992
  validation accuracy:		92.61 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.009088
  validation loss:		0.509416
  validation accuracy:		92.50 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.008829
  validation loss:		0.513686
  validation accuracy:		92.17 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.008987
  validation loss:		0.517282
  validation accuracy:		92.39 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.008725
  validation loss:		0.510255
  validation accuracy:		92.17 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.008883
  validation loss:		0.517133
  validation accuracy:		92.28 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.008839
  validation loss:		0.508325
  validation accuracy:		92.39 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.008780
  validation loss:		0.512472
  validation accuracy:		92.50 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.008692
  validation loss:		0.521767
  validation accuracy:		92.28 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.009024
  validation loss:		0.507711
  validation accuracy:		92.39 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.008843
  validation loss:		0.508367
  validation accuracy:		92.61 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.008521
  validation loss:		0.516963
  validation accuracy:		92.28 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.009217
  validation loss:		0.510319
  validation accuracy:		92.50 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.008736
  validation loss:		0.511551
  validation accuracy:		92.50 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.008665
  validation loss:		0.520903
  validation accuracy:		92.39 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.009044
  validation loss:		0.512569
  validation accuracy:		92.39 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.008712
  validation loss:		0.518944
  validation accuracy:		92.28 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.008836
  validation loss:		0.510080
  validation accuracy:		92.39 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.008883
  validation loss:		0.524992
  validation accuracy:		92.39 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.008765
  validation loss:		0.509370
  validation accuracy:		92.50 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.008726
  validation loss:		0.518050
  validation accuracy:		92.50 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.008616
  validation loss:		0.517884
  validation accuracy:		92.50 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.008397
  validation loss:		0.514830
  validation accuracy:		92.39 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.009143
  validation loss:		0.517794
  validation accuracy:		92.39 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.008804
  validation loss:		0.524366
  validation accuracy:		92.17 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.008737
  validation loss:		0.519677
  validation accuracy:		92.39 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.008687
  validation loss:		0.512261
  validation accuracy:		92.39 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.008819
  validation loss:		0.523361
  validation accuracy:		92.50 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.008494
  validation loss:		0.524090
  validation accuracy:		92.28 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.008566
  validation loss:		0.519689
  validation accuracy:		92.28 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.008533
  validation loss:		0.507051
  validation accuracy:		92.61 %
Epoch 1496 of 2000 took 0.037s
  training loss:		0.008948
  validation loss:		0.520687
  validation accuracy:		92.39 %
Epoch 1497 of 2000 took 0.036s
  training loss:		0.008614
  validation loss:		0.519042
  validation accuracy:		92.17 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.008063
  validation loss:		0.514623
  validation accuracy:		92.39 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.008489
  validation loss:		0.520605
  validation accuracy:		92.28 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.008444
  validation loss:		0.521995
  validation accuracy:		92.39 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.008465
  validation loss:		0.517304
  validation accuracy:		92.50 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.008166
  validation loss:		0.526964
  validation accuracy:		92.39 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.008730
  validation loss:		0.520301
  validation accuracy:		92.28 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.008866
  validation loss:		0.523568
  validation accuracy:		92.39 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.008335
  validation loss:		0.521544
  validation accuracy:		92.28 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.008979
  validation loss:		0.521819
  validation accuracy:		92.39 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.008251
  validation loss:		0.531215
  validation accuracy:		92.07 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.008150
  validation loss:		0.519445
  validation accuracy:		92.50 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.008402
  validation loss:		0.514342
  validation accuracy:		92.39 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.008581
  validation loss:		0.517496
  validation accuracy:		92.39 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.007992
  validation loss:		0.517598
  validation accuracy:		92.50 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.008124
  validation loss:		0.528977
  validation accuracy:		92.28 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.008111
  validation loss:		0.517438
  validation accuracy:		92.28 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.008445
  validation loss:		0.526714
  validation accuracy:		92.17 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.008085
  validation loss:		0.524531
  validation accuracy:		92.07 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.008118
  validation loss:		0.517870
  validation accuracy:		92.50 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.008362
  validation loss:		0.525661
  validation accuracy:		92.39 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.008100
  validation loss:		0.523096
  validation accuracy:		92.28 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.008175
  validation loss:		0.522642
  validation accuracy:		92.17 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.008094
  validation loss:		0.527670
  validation accuracy:		92.28 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.008167
  validation loss:		0.522210
  validation accuracy:		92.50 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.008441
  validation loss:		0.521645
  validation accuracy:		92.39 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.008022
  validation loss:		0.521959
  validation accuracy:		92.39 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.008305
  validation loss:		0.527304
  validation accuracy:		92.28 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.008146
  validation loss:		0.529430
  validation accuracy:		92.28 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.008173
  validation loss:		0.528223
  validation accuracy:		92.28 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.008132
  validation loss:		0.526568
  validation accuracy:		92.50 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.007928
  validation loss:		0.526892
  validation accuracy:		92.39 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.008157
  validation loss:		0.527508
  validation accuracy:		92.39 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.008001
  validation loss:		0.523472
  validation accuracy:		92.50 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.008290
  validation loss:		0.524390
  validation accuracy:		92.28 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.008177
  validation loss:		0.521789
  validation accuracy:		92.39 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.008260
  validation loss:		0.521122
  validation accuracy:		92.39 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.007883
  validation loss:		0.532210
  validation accuracy:		92.17 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.008158
  validation loss:		0.527091
  validation accuracy:		92.39 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.008341
  validation loss:		0.517970
  validation accuracy:		92.39 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.008015
  validation loss:		0.524677
  validation accuracy:		92.39 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.007582
  validation loss:		0.529817
  validation accuracy:		92.17 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.008048
  validation loss:		0.527835
  validation accuracy:		92.28 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.007898
  validation loss:		0.530029
  validation accuracy:		92.28 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.008173
  validation loss:		0.534188
  validation accuracy:		92.28 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.007871
  validation loss:		0.544272
  validation accuracy:		92.28 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.008081
  validation loss:		0.531596
  validation accuracy:		92.28 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.007539
  validation loss:		0.527196
  validation accuracy:		92.50 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.007621
  validation loss:		0.532770
  validation accuracy:		92.28 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.007661
  validation loss:		0.530958
  validation accuracy:		92.17 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.007792
  validation loss:		0.531568
  validation accuracy:		92.17 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.007640
  validation loss:		0.536720
  validation accuracy:		92.28 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.007759
  validation loss:		0.527097
  validation accuracy:		92.50 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.007455
  validation loss:		0.538972
  validation accuracy:		92.28 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.007606
  validation loss:		0.530068
  validation accuracy:		92.39 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.007582
  validation loss:		0.535696
  validation accuracy:		92.28 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.007606
  validation loss:		0.535399
  validation accuracy:		92.17 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.007880
  validation loss:		0.531950
  validation accuracy:		92.39 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.007299
  validation loss:		0.529981
  validation accuracy:		92.39 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.007752
  validation loss:		0.525655
  validation accuracy:		92.17 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.007763
  validation loss:		0.531425
  validation accuracy:		92.28 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.007652
  validation loss:		0.531743
  validation accuracy:		92.28 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.007515
  validation loss:		0.534748
  validation accuracy:		92.17 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.007708
  validation loss:		0.544028
  validation accuracy:		92.07 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.007502
  validation loss:		0.536532
  validation accuracy:		92.28 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.007538
  validation loss:		0.535259
  validation accuracy:		92.39 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.007575
  validation loss:		0.542523
  validation accuracy:		92.28 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.007350
  validation loss:		0.535620
  validation accuracy:		92.07 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.007662
  validation loss:		0.541351
  validation accuracy:		92.17 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.007047
  validation loss:		0.535017
  validation accuracy:		92.28 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.007370
  validation loss:		0.535594
  validation accuracy:		92.28 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.007372
  validation loss:		0.532652
  validation accuracy:		92.39 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.007216
  validation loss:		0.538993
  validation accuracy:		92.39 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.007455
  validation loss:		0.545525
  validation accuracy:		92.07 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.007750
  validation loss:		0.535967
  validation accuracy:		92.28 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.007411
  validation loss:		0.528810
  validation accuracy:		92.39 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.007463
  validation loss:		0.541862
  validation accuracy:		92.17 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.007391
  validation loss:		0.545303
  validation accuracy:		92.17 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.007166
  validation loss:		0.544957
  validation accuracy:		92.17 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.007457
  validation loss:		0.538784
  validation accuracy:		92.17 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.007445
  validation loss:		0.538022
  validation accuracy:		92.28 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.007290
  validation loss:		0.533923
  validation accuracy:		92.28 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.007461
  validation loss:		0.536185
  validation accuracy:		92.28 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.007542
  validation loss:		0.530119
  validation accuracy:		92.50 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.007308
  validation loss:		0.535593
  validation accuracy:		92.28 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.007333
  validation loss:		0.543709
  validation accuracy:		92.28 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.007248
  validation loss:		0.539522
  validation accuracy:		92.17 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.007542
  validation loss:		0.534467
  validation accuracy:		92.39 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.007395
  validation loss:		0.540274
  validation accuracy:		92.17 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.007152
  validation loss:		0.530993
  validation accuracy:		92.39 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.007440
  validation loss:		0.536576
  validation accuracy:		92.28 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.007285
  validation loss:		0.532804
  validation accuracy:		92.39 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.007154
  validation loss:		0.539572
  validation accuracy:		92.17 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.007073
  validation loss:		0.541228
  validation accuracy:		92.17 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.007346
  validation loss:		0.544309
  validation accuracy:		92.28 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.007297
  validation loss:		0.536743
  validation accuracy:		92.39 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.007284
  validation loss:		0.540652
  validation accuracy:		92.28 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006873
  validation loss:		0.542183
  validation accuracy:		92.28 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.007407
  validation loss:		0.553985
  validation accuracy:		91.96 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.007053
  validation loss:		0.539220
  validation accuracy:		92.39 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.007174
  validation loss:		0.535672
  validation accuracy:		92.17 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.007320
  validation loss:		0.544195
  validation accuracy:		92.17 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.007204
  validation loss:		0.541679
  validation accuracy:		92.17 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.007231
  validation loss:		0.549389
  validation accuracy:		91.85 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.007108
  validation loss:		0.548949
  validation accuracy:		92.07 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.007015
  validation loss:		0.543807
  validation accuracy:		92.17 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.007108
  validation loss:		0.546436
  validation accuracy:		92.17 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.006964
  validation loss:		0.542448
  validation accuracy:		92.17 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.006922
  validation loss:		0.551040
  validation accuracy:		92.17 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.007110
  validation loss:		0.550418
  validation accuracy:		92.28 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.007189
  validation loss:		0.541338
  validation accuracy:		92.28 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.007002
  validation loss:		0.540196
  validation accuracy:		92.28 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.006641
  validation loss:		0.548882
  validation accuracy:		92.17 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.007115
  validation loss:		0.541106
  validation accuracy:		92.17 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.007199
  validation loss:		0.550287
  validation accuracy:		92.28 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.006913
  validation loss:		0.541065
  validation accuracy:		92.17 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.006780
  validation loss:		0.542368
  validation accuracy:		92.28 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.006870
  validation loss:		0.538522
  validation accuracy:		92.50 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.007075
  validation loss:		0.546576
  validation accuracy:		92.39 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.006905
  validation loss:		0.549671
  validation accuracy:		92.07 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.006893
  validation loss:		0.549018
  validation accuracy:		92.17 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.007170
  validation loss:		0.547546
  validation accuracy:		92.28 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.006922
  validation loss:		0.546165
  validation accuracy:		92.39 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.006929
  validation loss:		0.547666
  validation accuracy:		92.07 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.006951
  validation loss:		0.552165
  validation accuracy:		92.17 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.007191
  validation loss:		0.550907
  validation accuracy:		92.07 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.006555
  validation loss:		0.544688
  validation accuracy:		92.39 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.006710
  validation loss:		0.545251
  validation accuracy:		92.28 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.006745
  validation loss:		0.543576
  validation accuracy:		92.39 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.006992
  validation loss:		0.548128
  validation accuracy:		92.07 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.006725
  validation loss:		0.542632
  validation accuracy:		92.50 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.006740
  validation loss:		0.550769
  validation accuracy:		92.17 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.006586
  validation loss:		0.544460
  validation accuracy:		92.39 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.006715
  validation loss:		0.538066
  validation accuracy:		92.28 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.007256
  validation loss:		0.548679
  validation accuracy:		92.17 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.006583
  validation loss:		0.548655
  validation accuracy:		92.07 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.006768
  validation loss:		0.553442
  validation accuracy:		92.28 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.006907
  validation loss:		0.548050
  validation accuracy:		92.17 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.006684
  validation loss:		0.554748
  validation accuracy:		92.07 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.006673
  validation loss:		0.549532
  validation accuracy:		92.28 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.006767
  validation loss:		0.551974
  validation accuracy:		92.39 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.006826
  validation loss:		0.549950
  validation accuracy:		92.39 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.006599
  validation loss:		0.547790
  validation accuracy:		92.39 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.006764
  validation loss:		0.561824
  validation accuracy:		91.96 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.006751
  validation loss:		0.548565
  validation accuracy:		92.28 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.006545
  validation loss:		0.554626
  validation accuracy:		92.28 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.006616
  validation loss:		0.553154
  validation accuracy:		92.17 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.006924
  validation loss:		0.543918
  validation accuracy:		92.28 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.006678
  validation loss:		0.552535
  validation accuracy:		92.28 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.555937
  validation accuracy:		92.07 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.006675
  validation loss:		0.550126
  validation accuracy:		92.28 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.006729
  validation loss:		0.558460
  validation accuracy:		92.07 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.006680
  validation loss:		0.561067
  validation accuracy:		91.96 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.006670
  validation loss:		0.556252
  validation accuracy:		92.39 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.553713
  validation accuracy:		92.28 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.006624
  validation loss:		0.559412
  validation accuracy:		92.17 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.006703
  validation loss:		0.550827
  validation accuracy:		92.17 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.006565
  validation loss:		0.561279
  validation accuracy:		91.85 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.006572
  validation loss:		0.559222
  validation accuracy:		92.07 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.006634
  validation loss:		0.550844
  validation accuracy:		92.17 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.006610
  validation loss:		0.552679
  validation accuracy:		92.28 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.006561
  validation loss:		0.547503
  validation accuracy:		92.39 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.006536
  validation loss:		0.551357
  validation accuracy:		92.39 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.006782
  validation loss:		0.555396
  validation accuracy:		92.17 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.006326
  validation loss:		0.559509
  validation accuracy:		92.17 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.006454
  validation loss:		0.568979
  validation accuracy:		91.96 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.006436
  validation loss:		0.558381
  validation accuracy:		91.96 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.006700
  validation loss:		0.555484
  validation accuracy:		92.17 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.006294
  validation loss:		0.560580
  validation accuracy:		92.28 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.006290
  validation loss:		0.559716
  validation accuracy:		91.96 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.006437
  validation loss:		0.558016
  validation accuracy:		92.07 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.006288
  validation loss:		0.561662
  validation accuracy:		92.07 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.006376
  validation loss:		0.557511
  validation accuracy:		91.96 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.006375
  validation loss:		0.563761
  validation accuracy:		92.28 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.006281
  validation loss:		0.556013
  validation accuracy:		92.28 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.006503
  validation loss:		0.555306
  validation accuracy:		92.28 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.006638
  validation loss:		0.564270
  validation accuracy:		92.17 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.006380
  validation loss:		0.558493
  validation accuracy:		92.17 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.006436
  validation loss:		0.554664
  validation accuracy:		92.28 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.006247
  validation loss:		0.555485
  validation accuracy:		92.28 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.006381
  validation loss:		0.564269
  validation accuracy:		92.17 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.006604
  validation loss:		0.563120
  validation accuracy:		92.07 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.006102
  validation loss:		0.560801
  validation accuracy:		92.28 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.006205
  validation loss:		0.565181
  validation accuracy:		92.07 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.006328
  validation loss:		0.560831
  validation accuracy:		92.07 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.006269
  validation loss:		0.557387
  validation accuracy:		92.07 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005963
  validation loss:		0.558773
  validation accuracy:		92.07 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.006453
  validation loss:		0.559886
  validation accuracy:		92.17 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.006372
  validation loss:		0.565432
  validation accuracy:		92.07 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.006324
  validation loss:		0.564523
  validation accuracy:		92.07 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.006245
  validation loss:		0.560378
  validation accuracy:		92.17 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.568223
  validation accuracy:		92.17 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.006227
  validation loss:		0.563661
  validation accuracy:		92.17 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005942
  validation loss:		0.563686
  validation accuracy:		91.74 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.006140
  validation loss:		0.562569
  validation accuracy:		92.07 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.006161
  validation loss:		0.560968
  validation accuracy:		92.17 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.006237
  validation loss:		0.560707
  validation accuracy:		92.28 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.006121
  validation loss:		0.561997
  validation accuracy:		92.28 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.006033
  validation loss:		0.564242
  validation accuracy:		92.28 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.006112
  validation loss:		0.560614
  validation accuracy:		92.07 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.006184
  validation loss:		0.569916
  validation accuracy:		92.39 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.006072
  validation loss:		0.562380
  validation accuracy:		92.07 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005932
  validation loss:		0.568382
  validation accuracy:		92.17 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.006053
  validation loss:		0.566243
  validation accuracy:		91.96 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.006203
  validation loss:		0.565950
  validation accuracy:		92.07 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.006034
  validation loss:		0.568987
  validation accuracy:		92.17 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005941
  validation loss:		0.560252
  validation accuracy:		92.39 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.006156
  validation loss:		0.564291
  validation accuracy:		92.28 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.006119
  validation loss:		0.564730
  validation accuracy:		92.39 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.006055
  validation loss:		0.568558
  validation accuracy:		92.28 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.006090
  validation loss:		0.578460
  validation accuracy:		91.85 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.006137
  validation loss:		0.566213
  validation accuracy:		92.17 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.006023
  validation loss:		0.571651
  validation accuracy:		91.96 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005797
  validation loss:		0.571821
  validation accuracy:		91.85 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.006066
  validation loss:		0.561700
  validation accuracy:		92.17 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.005719
  validation loss:		0.573942
  validation accuracy:		92.17 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.006035
  validation loss:		0.563740
  validation accuracy:		92.07 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.006051
  validation loss:		0.569485
  validation accuracy:		92.17 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.005998
  validation loss:		0.565326
  validation accuracy:		92.17 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.005940
  validation loss:		0.568647
  validation accuracy:		92.28 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.005721
  validation loss:		0.570758
  validation accuracy:		92.07 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.005676
  validation loss:		0.563816
  validation accuracy:		92.28 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.005843
  validation loss:		0.569698
  validation accuracy:		92.17 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005756
  validation loss:		0.568119
  validation accuracy:		92.17 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.005761
  validation loss:		0.569329
  validation accuracy:		91.63 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.005961
  validation loss:		0.567165
  validation accuracy:		92.17 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.005877
  validation loss:		0.563217
  validation accuracy:		92.17 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.005934
  validation loss:		0.563863
  validation accuracy:		92.28 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.005823
  validation loss:		0.564581
  validation accuracy:		92.17 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.005924
  validation loss:		0.574312
  validation accuracy:		91.63 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.006073
  validation loss:		0.560987
  validation accuracy:		92.17 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.005833
  validation loss:		0.575366
  validation accuracy:		91.96 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.005834
  validation loss:		0.569304
  validation accuracy:		92.17 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.005701
  validation loss:		0.578413
  validation accuracy:		91.52 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.005945
  validation loss:		0.566900
  validation accuracy:		92.28 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.005588
  validation loss:		0.564788
  validation accuracy:		92.17 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.005716
  validation loss:		0.575886
  validation accuracy:		92.17 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.005896
  validation loss:		0.567429
  validation accuracy:		92.28 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.005833
  validation loss:		0.570489
  validation accuracy:		92.28 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.005653
  validation loss:		0.573436
  validation accuracy:		92.07 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.005982
  validation loss:		0.572047
  validation accuracy:		92.17 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.005653
  validation loss:		0.569946
  validation accuracy:		92.17 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.005819
  validation loss:		0.569407
  validation accuracy:		92.28 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.005839
  validation loss:		0.572911
  validation accuracy:		92.17 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.005734
  validation loss:		0.577879
  validation accuracy:		92.07 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.005704
  validation loss:		0.571703
  validation accuracy:		92.17 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.005814
  validation loss:		0.577966
  validation accuracy:		92.07 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.005381
  validation loss:		0.576359
  validation accuracy:		91.96 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.005871
  validation loss:		0.578604
  validation accuracy:		92.28 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.005753
  validation loss:		0.571641
  validation accuracy:		92.17 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.005809
  validation loss:		0.572014
  validation accuracy:		92.28 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.005619
  validation loss:		0.575473
  validation accuracy:		92.17 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.005766
  validation loss:		0.574480
  validation accuracy:		92.07 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.005662
  validation loss:		0.566206
  validation accuracy:		92.17 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.005435
  validation loss:		0.575346
  validation accuracy:		92.28 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.005574
  validation loss:		0.577520
  validation accuracy:		92.17 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.005594
  validation loss:		0.580528
  validation accuracy:		92.07 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.005624
  validation loss:		0.578901
  validation accuracy:		91.96 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.005712
  validation loss:		0.573176
  validation accuracy:		92.28 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.005496
  validation loss:		0.572844
  validation accuracy:		92.17 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.005405
  validation loss:		0.576440
  validation accuracy:		92.07 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.578396
  validation accuracy:		92.07 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.005640
  validation loss:		0.574838
  validation accuracy:		92.07 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.005465
  validation loss:		0.583121
  validation accuracy:		91.96 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.005622
  validation loss:		0.579050
  validation accuracy:		91.96 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.005738
  validation loss:		0.576308
  validation accuracy:		92.07 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.005555
  validation loss:		0.571578
  validation accuracy:		92.28 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.005528
  validation loss:		0.576394
  validation accuracy:		92.17 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.005480
  validation loss:		0.567544
  validation accuracy:		92.17 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.005711
  validation loss:		0.574840
  validation accuracy:		92.07 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.005555
  validation loss:		0.580511
  validation accuracy:		92.17 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.005348
  validation loss:		0.583571
  validation accuracy:		92.07 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.005588
  validation loss:		0.577152
  validation accuracy:		92.17 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.005236
  validation loss:		0.582604
  validation accuracy:		92.17 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.005668
  validation loss:		0.582350
  validation accuracy:		92.17 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.005772
  validation loss:		0.582211
  validation accuracy:		92.17 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.005341
  validation loss:		0.575144
  validation accuracy:		92.17 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.005703
  validation loss:		0.575140
  validation accuracy:		92.17 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.005542
  validation loss:		0.594390
  validation accuracy:		91.85 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.005571
  validation loss:		0.583894
  validation accuracy:		92.17 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.005365
  validation loss:		0.579081
  validation accuracy:		92.28 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.005484
  validation loss:		0.573235
  validation accuracy:		92.17 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.005521
  validation loss:		0.575099
  validation accuracy:		91.74 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.005464
  validation loss:		0.575489
  validation accuracy:		92.28 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.005494
  validation loss:		0.583876
  validation accuracy:		92.17 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.005311
  validation loss:		0.580847
  validation accuracy:		92.28 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.005398
  validation loss:		0.578193
  validation accuracy:		92.28 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.005553
  validation loss:		0.581572
  validation accuracy:		92.17 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.005308
  validation loss:		0.580740
  validation accuracy:		92.28 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.005348
  validation loss:		0.585872
  validation accuracy:		92.17 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.005329
  validation loss:		0.576209
  validation accuracy:		92.17 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.005315
  validation loss:		0.579256
  validation accuracy:		92.17 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.005373
  validation loss:		0.585877
  validation accuracy:		92.07 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.005300
  validation loss:		0.579331
  validation accuracy:		92.28 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.005233
  validation loss:		0.587928
  validation accuracy:		92.17 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.005531
  validation loss:		0.582957
  validation accuracy:		91.96 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.005075
  validation loss:		0.580516
  validation accuracy:		92.17 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.005292
  validation loss:		0.585929
  validation accuracy:		91.96 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.005333
  validation loss:		0.585002
  validation accuracy:		92.17 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.005076
  validation loss:		0.581096
  validation accuracy:		92.28 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.005190
  validation loss:		0.585501
  validation accuracy:		92.07 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.005128
  validation loss:		0.585987
  validation accuracy:		92.17 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.005212
  validation loss:		0.581029
  validation accuracy:		92.07 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.005102
  validation loss:		0.581803
  validation accuracy:		92.17 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.005134
  validation loss:		0.584650
  validation accuracy:		92.07 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.005406
  validation loss:		0.584376
  validation accuracy:		92.17 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.005230
  validation loss:		0.579772
  validation accuracy:		92.28 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.005202
  validation loss:		0.585776
  validation accuracy:		92.17 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.005231
  validation loss:		0.586110
  validation accuracy:		92.17 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.005277
  validation loss:		0.581471
  validation accuracy:		92.17 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.005141
  validation loss:		0.591276
  validation accuracy:		92.17 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.005267
  validation loss:		0.578981
  validation accuracy:		92.28 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.005313
  validation loss:		0.587621
  validation accuracy:		92.17 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.005288
  validation loss:		0.583239
  validation accuracy:		92.28 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004993
  validation loss:		0.588966
  validation accuracy:		92.07 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.005121
  validation loss:		0.586935
  validation accuracy:		91.74 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.005130
  validation loss:		0.592243
  validation accuracy:		92.07 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.005213
  validation loss:		0.581975
  validation accuracy:		92.07 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004749
  validation loss:		0.590879
  validation accuracy:		92.17 %
Epoch 1816 of 2000 took 0.036s
  training loss:		0.005017
  validation loss:		0.595480
  validation accuracy:		91.96 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.005214
  validation loss:		0.585834
  validation accuracy:		92.17 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.005024
  validation loss:		0.586849
  validation accuracy:		91.96 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.005191
  validation loss:		0.591935
  validation accuracy:		92.17 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.005240
  validation loss:		0.594729
  validation accuracy:		91.96 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004952
  validation loss:		0.586596
  validation accuracy:		92.17 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004963
  validation loss:		0.584057
  validation accuracy:		92.17 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.005233
  validation loss:		0.576857
  validation accuracy:		92.07 %
Epoch 1824 of 2000 took 0.036s
  training loss:		0.005256
  validation loss:		0.587085
  validation accuracy:		92.17 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.005111
  validation loss:		0.593140
  validation accuracy:		91.96 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.004971
  validation loss:		0.586416
  validation accuracy:		92.17 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004908
  validation loss:		0.595194
  validation accuracy:		91.96 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.005013
  validation loss:		0.586627
  validation accuracy:		92.17 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004985
  validation loss:		0.586603
  validation accuracy:		92.17 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.005059
  validation loss:		0.589376
  validation accuracy:		92.39 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.005171
  validation loss:		0.594263
  validation accuracy:		91.85 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004973
  validation loss:		0.586849
  validation accuracy:		92.07 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.004862
  validation loss:		0.591428
  validation accuracy:		92.07 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.005096
  validation loss:		0.591363
  validation accuracy:		92.17 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.004868
  validation loss:		0.595204
  validation accuracy:		92.07 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.594089
  validation accuracy:		92.07 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004998
  validation loss:		0.594012
  validation accuracy:		92.07 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.004805
  validation loss:		0.590933
  validation accuracy:		92.17 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.004861
  validation loss:		0.590406
  validation accuracy:		91.96 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.005090
  validation loss:		0.590370
  validation accuracy:		91.74 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.005081
  validation loss:		0.596879
  validation accuracy:		92.07 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.005001
  validation loss:		0.589052
  validation accuracy:		92.17 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.005009
  validation loss:		0.590025
  validation accuracy:		92.07 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.004901
  validation loss:		0.591591
  validation accuracy:		92.17 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.004888
  validation loss:		0.589445
  validation accuracy:		92.17 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.004886
  validation loss:		0.594181
  validation accuracy:		92.17 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.004939
  validation loss:		0.594772
  validation accuracy:		91.96 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.004940
  validation loss:		0.591883
  validation accuracy:		92.07 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004965
  validation loss:		0.602853
  validation accuracy:		91.41 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.005279
  validation loss:		0.599674
  validation accuracy:		92.07 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.004774
  validation loss:		0.598930
  validation accuracy:		92.07 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.004757
  validation loss:		0.593913
  validation accuracy:		92.07 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.004805
  validation loss:		0.593051
  validation accuracy:		92.17 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.004735
  validation loss:		0.593524
  validation accuracy:		92.07 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.004727
  validation loss:		0.594485
  validation accuracy:		92.17 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.004788
  validation loss:		0.592880
  validation accuracy:		92.17 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.592762
  validation accuracy:		92.17 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.004944
  validation loss:		0.593593
  validation accuracy:		92.17 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.004850
  validation loss:		0.597762
  validation accuracy:		92.07 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.004889
  validation loss:		0.594241
  validation accuracy:		92.07 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.004901
  validation loss:		0.593115
  validation accuracy:		92.17 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.004802
  validation loss:		0.597734
  validation accuracy:		92.07 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.004753
  validation loss:		0.592921
  validation accuracy:		92.07 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.004661
  validation loss:		0.600355
  validation accuracy:		92.07 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.004803
  validation loss:		0.595627
  validation accuracy:		92.28 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.004871
  validation loss:		0.594954
  validation accuracy:		92.07 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.004729
  validation loss:		0.601710
  validation accuracy:		92.07 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.004860
  validation loss:		0.593541
  validation accuracy:		92.17 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.004806
  validation loss:		0.593195
  validation accuracy:		92.17 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.004692
  validation loss:		0.596917
  validation accuracy:		91.96 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.004662
  validation loss:		0.595755
  validation accuracy:		92.17 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.004716
  validation loss:		0.592509
  validation accuracy:		92.28 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.004772
  validation loss:		0.598945
  validation accuracy:		92.17 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.004733
  validation loss:		0.598789
  validation accuracy:		92.17 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.004554
  validation loss:		0.606687
  validation accuracy:		91.96 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.004699
  validation loss:		0.591150
  validation accuracy:		92.07 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.004751
  validation loss:		0.596491
  validation accuracy:		92.17 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.004744
  validation loss:		0.596933
  validation accuracy:		92.17 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.004656
  validation loss:		0.598547
  validation accuracy:		92.07 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.004818
  validation loss:		0.598627
  validation accuracy:		91.96 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.004675
  validation loss:		0.592619
  validation accuracy:		92.17 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.004710
  validation loss:		0.604395
  validation accuracy:		92.07 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.004750
  validation loss:		0.599381
  validation accuracy:		92.07 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.004606
  validation loss:		0.597816
  validation accuracy:		92.17 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.004682
  validation loss:		0.597124
  validation accuracy:		91.96 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.004706
  validation loss:		0.601963
  validation accuracy:		91.96 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.004764
  validation loss:		0.601214
  validation accuracy:		92.17 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.004681
  validation loss:		0.601357
  validation accuracy:		91.96 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.599464
  validation accuracy:		92.17 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.004498
  validation loss:		0.593441
  validation accuracy:		92.07 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.004579
  validation loss:		0.604237
  validation accuracy:		92.07 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.004553
  validation loss:		0.600043
  validation accuracy:		92.07 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.004643
  validation loss:		0.600892
  validation accuracy:		92.07 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.004709
  validation loss:		0.603347
  validation accuracy:		92.17 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.004789
  validation loss:		0.601722
  validation accuracy:		92.17 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.004480
  validation loss:		0.598357
  validation accuracy:		92.17 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.004583
  validation loss:		0.601038
  validation accuracy:		92.07 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.004601
  validation loss:		0.605320
  validation accuracy:		92.07 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.004410
  validation loss:		0.604185
  validation accuracy:		91.96 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.004436
  validation loss:		0.606456
  validation accuracy:		91.74 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.004727
  validation loss:		0.598995
  validation accuracy:		92.17 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.004460
  validation loss:		0.607965
  validation accuracy:		92.07 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.004586
  validation loss:		0.603547
  validation accuracy:		91.96 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.004572
  validation loss:		0.603468
  validation accuracy:		92.07 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.004499
  validation loss:		0.607001
  validation accuracy:		91.85 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.004586
  validation loss:		0.609740
  validation accuracy:		91.96 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.004630
  validation loss:		0.604473
  validation accuracy:		92.17 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.004515
  validation loss:		0.606750
  validation accuracy:		92.07 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.004534
  validation loss:		0.600445
  validation accuracy:		92.17 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.004480
  validation loss:		0.603439
  validation accuracy:		92.17 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.004590
  validation loss:		0.596366
  validation accuracy:		92.07 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.004556
  validation loss:		0.605631
  validation accuracy:		92.17 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.004531
  validation loss:		0.606269
  validation accuracy:		92.07 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.004401
  validation loss:		0.604376
  validation accuracy:		92.07 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.004580
  validation loss:		0.601638
  validation accuracy:		91.96 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.004497
  validation loss:		0.603215
  validation accuracy:		92.17 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.004347
  validation loss:		0.608001
  validation accuracy:		91.85 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.004540
  validation loss:		0.609854
  validation accuracy:		92.07 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.004531
  validation loss:		0.611288
  validation accuracy:		91.85 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.004351
  validation loss:		0.607816
  validation accuracy:		92.17 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.004431
  validation loss:		0.618069
  validation accuracy:		91.96 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.004541
  validation loss:		0.606017
  validation accuracy:		92.07 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.004439
  validation loss:		0.604952
  validation accuracy:		92.17 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.609872
  validation accuracy:		91.85 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.004495
  validation loss:		0.605391
  validation accuracy:		92.17 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.004280
  validation loss:		0.607276
  validation accuracy:		92.17 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.004369
  validation loss:		0.606103
  validation accuracy:		92.07 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.004249
  validation loss:		0.606393
  validation accuracy:		91.96 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.004475
  validation loss:		0.607832
  validation accuracy:		92.17 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.004459
  validation loss:		0.601975
  validation accuracy:		92.17 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.004293
  validation loss:		0.609108
  validation accuracy:		92.17 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.004276
  validation loss:		0.605070
  validation accuracy:		92.17 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.004294
  validation loss:		0.608103
  validation accuracy:		92.17 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.606945
  validation accuracy:		92.17 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.004549
  validation loss:		0.607263
  validation accuracy:		92.17 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.004351
  validation loss:		0.606940
  validation accuracy:		92.07 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.004512
  validation loss:		0.604957
  validation accuracy:		92.07 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.004384
  validation loss:		0.611033
  validation accuracy:		92.17 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.004214
  validation loss:		0.607237
  validation accuracy:		92.07 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.004159
  validation loss:		0.611250
  validation accuracy:		92.07 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.004331
  validation loss:		0.613923
  validation accuracy:		91.85 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.004281
  validation loss:		0.611741
  validation accuracy:		92.07 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.004464
  validation loss:		0.613779
  validation accuracy:		92.07 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.004280
  validation loss:		0.613714
  validation accuracy:		92.07 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.004236
  validation loss:		0.616344
  validation accuracy:		92.17 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.004300
  validation loss:		0.607099
  validation accuracy:		92.07 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.004239
  validation loss:		0.610907
  validation accuracy:		91.85 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.004332
  validation loss:		0.609745
  validation accuracy:		91.85 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.004362
  validation loss:		0.607606
  validation accuracy:		91.96 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.004206
  validation loss:		0.615644
  validation accuracy:		91.74 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.606731
  validation accuracy:		92.07 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.610089
  validation accuracy:		92.07 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.004252
  validation loss:		0.611064
  validation accuracy:		91.96 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.611570
  validation accuracy:		92.07 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.004297
  validation loss:		0.616976
  validation accuracy:		91.96 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.004182
  validation loss:		0.611015
  validation accuracy:		91.96 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.004231
  validation loss:		0.616119
  validation accuracy:		91.96 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.004205
  validation loss:		0.611270
  validation accuracy:		92.17 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.004310
  validation loss:		0.619287
  validation accuracy:		91.85 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.004219
  validation loss:		0.612911
  validation accuracy:		91.96 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.004259
  validation loss:		0.613793
  validation accuracy:		91.96 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.004011
  validation loss:		0.619737
  validation accuracy:		91.85 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.004161
  validation loss:		0.615017
  validation accuracy:		92.07 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.004375
  validation loss:		0.611246
  validation accuracy:		91.96 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.004282
  validation loss:		0.609304
  validation accuracy:		92.07 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.004013
  validation loss:		0.620276
  validation accuracy:		91.52 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.004188
  validation loss:		0.615697
  validation accuracy:		91.96 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.004129
  validation loss:		0.618460
  validation accuracy:		91.96 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.004168
  validation loss:		0.614431
  validation accuracy:		92.17 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.004185
  validation loss:		0.615597
  validation accuracy:		92.07 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.004051
  validation loss:		0.614291
  validation accuracy:		91.85 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.004069
  validation loss:		0.616736
  validation accuracy:		91.96 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.004120
  validation loss:		0.618237
  validation accuracy:		91.96 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.004140
  validation loss:		0.615596
  validation accuracy:		91.74 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.004253
  validation loss:		0.618352
  validation accuracy:		91.85 %
Epoch 1976 of 2000 took 0.036s
  training loss:		0.004074
  validation loss:		0.615477
  validation accuracy:		91.96 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.004304
  validation loss:		0.615146
  validation accuracy:		91.96 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.004203
  validation loss:		0.617763
  validation accuracy:		91.74 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.004132
  validation loss:		0.615672
  validation accuracy:		91.96 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.004052
  validation loss:		0.615236
  validation accuracy:		92.17 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.004091
  validation loss:		0.615159
  validation accuracy:		91.85 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.004250
  validation loss:		0.616296
  validation accuracy:		91.96 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.004100
  validation loss:		0.615673
  validation accuracy:		92.07 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.004034
  validation loss:		0.622168
  validation accuracy:		91.96 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.004127
  validation loss:		0.619133
  validation accuracy:		92.07 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.004092
  validation loss:		0.622289
  validation accuracy:		91.96 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.004035
  validation loss:		0.609222
  validation accuracy:		92.07 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.004124
  validation loss:		0.611984
  validation accuracy:		92.07 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.619878
  validation accuracy:		91.85 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.004132
  validation loss:		0.616778
  validation accuracy:		91.63 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.004066
  validation loss:		0.613978
  validation accuracy:		91.96 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.004004
  validation loss:		0.620987
  validation accuracy:		91.74 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.004076
  validation loss:		0.615913
  validation accuracy:		92.07 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003975
  validation loss:		0.617402
  validation accuracy:		92.07 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.004132
  validation loss:		0.621217
  validation accuracy:		92.17 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.618636
  validation accuracy:		91.96 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.004077
  validation loss:		0.618612
  validation accuracy:		92.17 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.619785
  validation accuracy:		92.07 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.004071
  validation loss:		0.621831
  validation accuracy:		91.74 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003964
  validation loss:		0.618766
  validation accuracy:		92.07 %
Final results:
  test loss:			1.419211
  test accuracy:		83.35 %
