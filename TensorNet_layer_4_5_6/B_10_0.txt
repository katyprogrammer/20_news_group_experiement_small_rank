Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		3.005137
  validation loss:		2.991692
  validation accuracy:		2.83 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.972747
  validation loss:		2.953703
  validation accuracy:		12.61 %
Epoch 3 of 2000 took 0.097s
  training loss:		2.935104
  validation loss:		2.915269
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.898060
  validation loss:		2.878692
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.096s
  training loss:		2.862909
  validation loss:		2.842787
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.098s
  training loss:		2.827225
  validation loss:		2.807143
  validation accuracy:		12.83 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.792574
  validation loss:		2.770388
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.756577
  validation loss:		2.732206
  validation accuracy:		12.83 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.718467
  validation loss:		2.691868
  validation accuracy:		12.83 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.678205
  validation loss:		2.648449
  validation accuracy:		12.83 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.639430
  validation loss:		2.602142
  validation accuracy:		12.83 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.595976
  validation loss:		2.552664
  validation accuracy:		12.83 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.550979
  validation loss:		2.501265
  validation accuracy:		12.83 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.506780
  validation loss:		2.448950
  validation accuracy:		12.83 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.463030
  validation loss:		2.397726
  validation accuracy:		12.83 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.421601
  validation loss:		2.351982
  validation accuracy:		12.83 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.387540
  validation loss:		2.316744
  validation accuracy:		12.83 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.358030
  validation loss:		2.290138
  validation accuracy:		14.78 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.340935
  validation loss:		2.273442
  validation accuracy:		14.46 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.327032
  validation loss:		2.266078
  validation accuracy:		15.33 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.317559
  validation loss:		2.261847
  validation accuracy:		17.39 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.310937
  validation loss:		2.259999
  validation accuracy:		17.61 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.306381
  validation loss:		2.254154
  validation accuracy:		14.78 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.303522
  validation loss:		2.249558
  validation accuracy:		22.50 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.301038
  validation loss:		2.250954
  validation accuracy:		18.70 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.298770
  validation loss:		2.245714
  validation accuracy:		14.57 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.297338
  validation loss:		2.243891
  validation accuracy:		18.04 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.295319
  validation loss:		2.245016
  validation accuracy:		16.20 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.296182
  validation loss:		2.243880
  validation accuracy:		17.83 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.294658
  validation loss:		2.245008
  validation accuracy:		15.87 %
Epoch 31 of 2000 took 0.096s
  training loss:		2.294562
  validation loss:		2.247017
  validation accuracy:		16.20 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.292575
  validation loss:		2.240501
  validation accuracy:		16.41 %
Epoch 33 of 2000 took 0.096s
  training loss:		2.292779
  validation loss:		2.239551
  validation accuracy:		19.02 %
Epoch 34 of 2000 took 0.096s
  training loss:		2.292169
  validation loss:		2.240264
  validation accuracy:		19.13 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.292490
  validation loss:		2.239068
  validation accuracy:		16.30 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.292290
  validation loss:		2.242453
  validation accuracy:		16.41 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.292172
  validation loss:		2.241510
  validation accuracy:		22.07 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.291174
  validation loss:		2.242671
  validation accuracy:		19.78 %
Epoch 39 of 2000 took 0.096s
  training loss:		2.289796
  validation loss:		2.237898
  validation accuracy:		14.35 %
Epoch 40 of 2000 took 0.096s
  training loss:		2.288509
  validation loss:		2.237105
  validation accuracy:		20.00 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.289617
  validation loss:		2.240162
  validation accuracy:		20.76 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.288938
  validation loss:		2.235766
  validation accuracy:		16.74 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.288921
  validation loss:		2.237328
  validation accuracy:		24.02 %
Epoch 44 of 2000 took 0.096s
  training loss:		2.287519
  validation loss:		2.234757
  validation accuracy:		15.00 %
Epoch 45 of 2000 took 0.100s
  training loss:		2.287509
  validation loss:		2.234031
  validation accuracy:		18.26 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.287054
  validation loss:		2.231327
  validation accuracy:		20.43 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.287502
  validation loss:		2.239872
  validation accuracy:		22.28 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.286891
  validation loss:		2.238567
  validation accuracy:		14.24 %
Epoch 49 of 2000 took 0.096s
  training loss:		2.285299
  validation loss:		2.229378
  validation accuracy:		20.65 %
Epoch 50 of 2000 took 0.096s
  training loss:		2.286249
  validation loss:		2.229817
  validation accuracy:		20.22 %
Epoch 51 of 2000 took 0.097s
  training loss:		2.287110
  validation loss:		2.240448
  validation accuracy:		14.78 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.283801
  validation loss:		2.235548
  validation accuracy:		16.63 %
Epoch 53 of 2000 took 0.097s
  training loss:		2.284910
  validation loss:		2.228410
  validation accuracy:		20.00 %
Epoch 54 of 2000 took 0.096s
  training loss:		2.283690
  validation loss:		2.227165
  validation accuracy:		21.85 %
Epoch 55 of 2000 took 0.096s
  training loss:		2.283628
  validation loss:		2.235872
  validation accuracy:		14.89 %
Epoch 56 of 2000 took 0.096s
  training loss:		2.282576
  validation loss:		2.230681
  validation accuracy:		19.02 %
Epoch 57 of 2000 took 0.096s
  training loss:		2.282227
  validation loss:		2.224979
  validation accuracy:		25.00 %
Epoch 58 of 2000 took 0.096s
  training loss:		2.281707
  validation loss:		2.231644
  validation accuracy:		15.65 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.280995
  validation loss:		2.229873
  validation accuracy:		21.85 %
Epoch 60 of 2000 took 0.096s
  training loss:		2.281189
  validation loss:		2.227780
  validation accuracy:		29.67 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.280453
  validation loss:		2.226328
  validation accuracy:		23.15 %
Epoch 62 of 2000 took 0.096s
  training loss:		2.278616
  validation loss:		2.223478
  validation accuracy:		23.91 %
Epoch 63 of 2000 took 0.097s
  training loss:		2.279082
  validation loss:		2.227478
  validation accuracy:		21.52 %
Epoch 64 of 2000 took 0.096s
  training loss:		2.276944
  validation loss:		2.221249
  validation accuracy:		27.28 %
Epoch 65 of 2000 took 0.096s
  training loss:		2.277669
  validation loss:		2.218623
  validation accuracy:		26.30 %
Epoch 66 of 2000 took 0.096s
  training loss:		2.276944
  validation loss:		2.226285
  validation accuracy:		26.63 %
Epoch 67 of 2000 took 0.096s
  training loss:		2.275963
  validation loss:		2.224507
  validation accuracy:		23.80 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.274200
  validation loss:		2.216927
  validation accuracy:		27.72 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.275143
  validation loss:		2.220840
  validation accuracy:		25.11 %
Epoch 70 of 2000 took 0.096s
  training loss:		2.272976
  validation loss:		2.220910
  validation accuracy:		25.76 %
Epoch 71 of 2000 took 0.096s
  training loss:		2.272178
  validation loss:		2.218052
  validation accuracy:		28.91 %
Epoch 72 of 2000 took 0.096s
  training loss:		2.270744
  validation loss:		2.213323
  validation accuracy:		27.61 %
Epoch 73 of 2000 took 0.097s
  training loss:		2.268993
  validation loss:		2.215553
  validation accuracy:		24.35 %
Epoch 74 of 2000 took 0.096s
  training loss:		2.269591
  validation loss:		2.218903
  validation accuracy:		20.65 %
Epoch 75 of 2000 took 0.096s
  training loss:		2.266888
  validation loss:		2.213471
  validation accuracy:		25.87 %
Epoch 76 of 2000 took 0.096s
  training loss:		2.265135
  validation loss:		2.209266
  validation accuracy:		29.35 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.263353
  validation loss:		2.205057
  validation accuracy:		26.09 %
Epoch 78 of 2000 took 0.096s
  training loss:		2.261508
  validation loss:		2.204075
  validation accuracy:		35.00 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.259884
  validation loss:		2.204585
  validation accuracy:		32.39 %
Epoch 80 of 2000 took 0.097s
  training loss:		2.258264
  validation loss:		2.203097
  validation accuracy:		24.78 %
Epoch 81 of 2000 took 0.096s
  training loss:		2.255266
  validation loss:		2.193820
  validation accuracy:		30.11 %
Epoch 82 of 2000 took 0.097s
  training loss:		2.254174
  validation loss:		2.199549
  validation accuracy:		32.17 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.249738
  validation loss:		2.194526
  validation accuracy:		29.13 %
Epoch 84 of 2000 took 0.097s
  training loss:		2.249282
  validation loss:		2.189367
  validation accuracy:		31.09 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.244290
  validation loss:		2.183439
  validation accuracy:		28.15 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.242917
  validation loss:		2.184410
  validation accuracy:		32.50 %
Epoch 87 of 2000 took 0.096s
  training loss:		2.237934
  validation loss:		2.179013
  validation accuracy:		29.89 %
Epoch 88 of 2000 took 0.097s
  training loss:		2.234693
  validation loss:		2.171228
  validation accuracy:		31.74 %
Epoch 89 of 2000 took 0.097s
  training loss:		2.228705
  validation loss:		2.168515
  validation accuracy:		33.04 %
Epoch 90 of 2000 took 0.097s
  training loss:		2.224217
  validation loss:		2.160948
  validation accuracy:		32.61 %
Epoch 91 of 2000 took 0.096s
  training loss:		2.219625
  validation loss:		2.151232
  validation accuracy:		32.50 %
Epoch 92 of 2000 took 0.097s
  training loss:		2.213496
  validation loss:		2.157775
  validation accuracy:		32.17 %
Epoch 93 of 2000 took 0.097s
  training loss:		2.207296
  validation loss:		2.147002
  validation accuracy:		32.61 %
Epoch 94 of 2000 took 0.097s
  training loss:		2.200079
  validation loss:		2.127377
  validation accuracy:		34.67 %
Epoch 95 of 2000 took 0.097s
  training loss:		2.189131
  validation loss:		2.121528
  validation accuracy:		31.74 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.179488
  validation loss:		2.105843
  validation accuracy:		32.28 %
Epoch 97 of 2000 took 0.096s
  training loss:		2.169286
  validation loss:		2.098606
  validation accuracy:		34.24 %
Epoch 98 of 2000 took 0.097s
  training loss:		2.159013
  validation loss:		2.084321
  validation accuracy:		34.24 %
Epoch 99 of 2000 took 0.097s
  training loss:		2.144123
  validation loss:		2.065907
  validation accuracy:		36.30 %
Epoch 100 of 2000 took 0.097s
  training loss:		2.129733
  validation loss:		2.046923
  validation accuracy:		35.11 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.110706
  validation loss:		2.027769
  validation accuracy:		33.37 %
Epoch 102 of 2000 took 0.097s
  training loss:		2.090830
  validation loss:		2.004278
  validation accuracy:		35.54 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.071134
  validation loss:		1.982739
  validation accuracy:		35.43 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.049681
  validation loss:		1.953626
  validation accuracy:		37.07 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.023470
  validation loss:		1.927252
  validation accuracy:		36.63 %
Epoch 106 of 2000 took 0.096s
  training loss:		1.994623
  validation loss:		1.897646
  validation accuracy:		36.96 %
Epoch 107 of 2000 took 0.097s
  training loss:		1.966178
  validation loss:		1.869936
  validation accuracy:		35.65 %
Epoch 108 of 2000 took 0.097s
  training loss:		1.936940
  validation loss:		1.838751
  validation accuracy:		36.85 %
Epoch 109 of 2000 took 0.097s
  training loss:		1.909085
  validation loss:		1.801563
  validation accuracy:		38.59 %
Epoch 110 of 2000 took 0.096s
  training loss:		1.878647
  validation loss:		1.773196
  validation accuracy:		38.15 %
Epoch 111 of 2000 took 0.097s
  training loss:		1.856814
  validation loss:		1.757193
  validation accuracy:		38.48 %
Epoch 112 of 2000 took 0.096s
  training loss:		1.824281
  validation loss:		1.722245
  validation accuracy:		40.76 %
Epoch 113 of 2000 took 0.097s
  training loss:		1.800203
  validation loss:		1.698448
  validation accuracy:		40.43 %
Epoch 114 of 2000 took 0.097s
  training loss:		1.775063
  validation loss:		1.674856
  validation accuracy:		39.46 %
Epoch 115 of 2000 took 0.097s
  training loss:		1.751607
  validation loss:		1.657305
  validation accuracy:		39.02 %
Epoch 116 of 2000 took 0.096s
  training loss:		1.726922
  validation loss:		1.627621
  validation accuracy:		40.98 %
Epoch 117 of 2000 took 0.097s
  training loss:		1.709530
  validation loss:		1.609817
  validation accuracy:		41.41 %
Epoch 118 of 2000 took 0.096s
  training loss:		1.689087
  validation loss:		1.591106
  validation accuracy:		41.96 %
Epoch 119 of 2000 took 0.097s
  training loss:		1.671736
  validation loss:		1.570841
  validation accuracy:		39.89 %
Epoch 120 of 2000 took 0.096s
  training loss:		1.651429
  validation loss:		1.551869
  validation accuracy:		41.63 %
Epoch 121 of 2000 took 0.097s
  training loss:		1.637174
  validation loss:		1.540657
  validation accuracy:		41.20 %
Epoch 122 of 2000 took 0.096s
  training loss:		1.620099
  validation loss:		1.520802
  validation accuracy:		43.48 %
Epoch 123 of 2000 took 0.096s
  training loss:		1.603129
  validation loss:		1.513196
  validation accuracy:		43.70 %
Epoch 124 of 2000 took 0.100s
  training loss:		1.590789
  validation loss:		1.505398
  validation accuracy:		44.89 %
Epoch 125 of 2000 took 0.097s
  training loss:		1.578721
  validation loss:		1.485581
  validation accuracy:		45.11 %
Epoch 126 of 2000 took 0.097s
  training loss:		1.567445
  validation loss:		1.476035
  validation accuracy:		46.20 %
Epoch 127 of 2000 took 0.097s
  training loss:		1.554713
  validation loss:		1.467173
  validation accuracy:		46.52 %
Epoch 128 of 2000 took 0.097s
  training loss:		1.538659
  validation loss:		1.455262
  validation accuracy:		44.35 %
Epoch 129 of 2000 took 0.097s
  training loss:		1.538188
  validation loss:		1.443839
  validation accuracy:		47.93 %
Epoch 130 of 2000 took 0.098s
  training loss:		1.521754
  validation loss:		1.435748
  validation accuracy:		49.13 %
Epoch 131 of 2000 took 0.097s
  training loss:		1.513834
  validation loss:		1.420700
  validation accuracy:		48.26 %
Epoch 132 of 2000 took 0.097s
  training loss:		1.500702
  validation loss:		1.429086
  validation accuracy:		47.28 %
Epoch 133 of 2000 took 0.097s
  training loss:		1.497241
  validation loss:		1.403389
  validation accuracy:		50.22 %
Epoch 134 of 2000 took 0.097s
  training loss:		1.484157
  validation loss:		1.394665
  validation accuracy:		48.48 %
Epoch 135 of 2000 took 0.097s
  training loss:		1.469938
  validation loss:		1.383459
  validation accuracy:		50.87 %
Epoch 136 of 2000 took 0.097s
  training loss:		1.470905
  validation loss:		1.376672
  validation accuracy:		51.63 %
Epoch 137 of 2000 took 0.096s
  training loss:		1.468235
  validation loss:		1.371877
  validation accuracy:		51.09 %
Epoch 138 of 2000 took 0.096s
  training loss:		1.450078
  validation loss:		1.370880
  validation accuracy:		50.98 %
Epoch 139 of 2000 took 0.096s
  training loss:		1.444994
  validation loss:		1.359801
  validation accuracy:		50.54 %
Epoch 140 of 2000 took 0.097s
  training loss:		1.443056
  validation loss:		1.364240
  validation accuracy:		51.09 %
Epoch 141 of 2000 took 0.097s
  training loss:		1.436492
  validation loss:		1.344091
  validation accuracy:		54.13 %
Epoch 142 of 2000 took 0.097s
  training loss:		1.431289
  validation loss:		1.399215
  validation accuracy:		47.72 %
Epoch 143 of 2000 took 0.096s
  training loss:		1.435079
  validation loss:		1.333331
  validation accuracy:		51.63 %
Epoch 144 of 2000 took 0.097s
  training loss:		1.417480
  validation loss:		1.323761
  validation accuracy:		54.02 %
Epoch 145 of 2000 took 0.096s
  training loss:		1.418423
  validation loss:		1.327761
  validation accuracy:		53.70 %
Epoch 146 of 2000 took 0.097s
  training loss:		1.422425
  validation loss:		1.311488
  validation accuracy:		54.78 %
Epoch 147 of 2000 took 0.096s
  training loss:		1.400077
  validation loss:		1.307437
  validation accuracy:		55.11 %
Epoch 148 of 2000 took 0.097s
  training loss:		1.398520
  validation loss:		1.302281
  validation accuracy:		55.87 %
Epoch 149 of 2000 took 0.097s
  training loss:		1.385729
  validation loss:		1.291869
  validation accuracy:		56.85 %
Epoch 150 of 2000 took 0.097s
  training loss:		1.384079
  validation loss:		1.292312
  validation accuracy:		55.98 %
Epoch 151 of 2000 took 0.097s
  training loss:		1.381179
  validation loss:		1.287831
  validation accuracy:		56.30 %
Epoch 152 of 2000 took 0.097s
  training loss:		1.377125
  validation loss:		1.270572
  validation accuracy:		57.83 %
Epoch 153 of 2000 took 0.096s
  training loss:		1.375605
  validation loss:		1.271073
  validation accuracy:		58.15 %
Epoch 154 of 2000 took 0.097s
  training loss:		1.354179
  validation loss:		1.257741
  validation accuracy:		59.24 %
Epoch 155 of 2000 took 0.097s
  training loss:		1.370872
  validation loss:		1.260635
  validation accuracy:		58.70 %
Epoch 156 of 2000 took 0.097s
  training loss:		1.340043
  validation loss:		1.245836
  validation accuracy:		60.11 %
Epoch 157 of 2000 took 0.097s
  training loss:		1.338387
  validation loss:		1.251085
  validation accuracy:		57.28 %
Epoch 158 of 2000 took 0.097s
  training loss:		1.339277
  validation loss:		1.230228
  validation accuracy:		60.76 %
Epoch 159 of 2000 took 0.097s
  training loss:		1.340267
  validation loss:		1.237452
  validation accuracy:		59.78 %
Epoch 160 of 2000 took 0.097s
  training loss:		1.343633
  validation loss:		1.230211
  validation accuracy:		61.09 %
Epoch 161 of 2000 took 0.097s
  training loss:		1.323986
  validation loss:		1.209980
  validation accuracy:		61.41 %
Epoch 162 of 2000 took 0.097s
  training loss:		1.310374
  validation loss:		1.200546
  validation accuracy:		62.61 %
Epoch 163 of 2000 took 0.097s
  training loss:		1.303097
  validation loss:		1.191162
  validation accuracy:		63.37 %
Epoch 164 of 2000 took 0.097s
  training loss:		1.316920
  validation loss:		1.236908
  validation accuracy:		58.15 %
Epoch 165 of 2000 took 0.097s
  training loss:		1.286468
  validation loss:		1.169969
  validation accuracy:		63.48 %
Epoch 166 of 2000 took 0.097s
  training loss:		1.281657
  validation loss:		1.162705
  validation accuracy:		64.13 %
Epoch 167 of 2000 took 0.097s
  training loss:		1.254748
  validation loss:		1.178434
  validation accuracy:		62.28 %
Epoch 168 of 2000 took 0.097s
  training loss:		1.274346
  validation loss:		1.138137
  validation accuracy:		64.89 %
Epoch 169 of 2000 took 0.097s
  training loss:		1.248854
  validation loss:		1.122045
  validation accuracy:		66.09 %
Epoch 170 of 2000 took 0.097s
  training loss:		1.241863
  validation loss:		1.118082
  validation accuracy:		65.98 %
Epoch 171 of 2000 took 0.097s
  training loss:		1.212990
  validation loss:		1.096163
  validation accuracy:		66.20 %
Epoch 172 of 2000 took 0.097s
  training loss:		1.210411
  validation loss:		1.087688
  validation accuracy:		66.52 %
Epoch 173 of 2000 took 0.097s
  training loss:		1.191371
  validation loss:		1.069027
  validation accuracy:		67.17 %
Epoch 174 of 2000 took 0.097s
  training loss:		1.168426
  validation loss:		1.058718
  validation accuracy:		68.04 %
Epoch 175 of 2000 took 0.098s
  training loss:		1.165667
  validation loss:		1.044417
  validation accuracy:		68.70 %
Epoch 176 of 2000 took 0.100s
  training loss:		1.146828
  validation loss:		1.025951
  validation accuracy:		68.70 %
Epoch 177 of 2000 took 0.100s
  training loss:		1.141078
  validation loss:		1.007292
  validation accuracy:		69.35 %
Epoch 178 of 2000 took 0.100s
  training loss:		1.136167
  validation loss:		1.019170
  validation accuracy:		68.04 %
Epoch 179 of 2000 took 0.100s
  training loss:		1.133549
  validation loss:		0.978845
  validation accuracy:		70.65 %
Epoch 180 of 2000 took 0.100s
  training loss:		1.104869
  validation loss:		1.015464
  validation accuracy:		66.85 %
Epoch 181 of 2000 took 0.100s
  training loss:		1.109877
  validation loss:		1.010695
  validation accuracy:		67.50 %
Epoch 182 of 2000 took 0.100s
  training loss:		1.098481
  validation loss:		0.978316
  validation accuracy:		68.91 %
Epoch 183 of 2000 took 0.100s
  training loss:		1.066061
  validation loss:		0.921813
  validation accuracy:		71.74 %
Epoch 184 of 2000 took 0.100s
  training loss:		1.046348
  validation loss:		0.929893
  validation accuracy:		70.76 %
Epoch 185 of 2000 took 0.100s
  training loss:		1.031864
  validation loss:		0.892484
  validation accuracy:		72.39 %
Epoch 186 of 2000 took 0.100s
  training loss:		1.027500
  validation loss:		0.878650
  validation accuracy:		73.04 %
Epoch 187 of 2000 took 0.100s
  training loss:		1.036120
  validation loss:		0.875335
  validation accuracy:		72.50 %
Epoch 188 of 2000 took 0.100s
  training loss:		1.016560
  validation loss:		0.870471
  validation accuracy:		73.37 %
Epoch 189 of 2000 took 0.100s
  training loss:		0.992056
  validation loss:		0.849440
  validation accuracy:		74.67 %
Epoch 190 of 2000 took 0.100s
  training loss:		0.995193
  validation loss:		0.826087
  validation accuracy:		74.24 %
Epoch 191 of 2000 took 0.100s
  training loss:		0.956150
  validation loss:		0.817629
  validation accuracy:		73.80 %
Epoch 192 of 2000 took 0.101s
  training loss:		0.947839
  validation loss:		0.813034
  validation accuracy:		75.43 %
Epoch 193 of 2000 took 0.100s
  training loss:		0.944332
  validation loss:		0.857239
  validation accuracy:		72.17 %
Epoch 194 of 2000 took 0.100s
  training loss:		0.955950
  validation loss:		0.807540
  validation accuracy:		75.33 %
Epoch 195 of 2000 took 0.100s
  training loss:		0.927269
  validation loss:		0.778950
  validation accuracy:		74.57 %
Epoch 196 of 2000 took 0.100s
  training loss:		0.913215
  validation loss:		0.764851
  validation accuracy:		75.00 %
Epoch 197 of 2000 took 0.100s
  training loss:		0.896376
  validation loss:		0.756928
  validation accuracy:		76.09 %
Epoch 198 of 2000 took 0.100s
  training loss:		0.885858
  validation loss:		0.745447
  validation accuracy:		76.20 %
Epoch 199 of 2000 took 0.100s
  training loss:		0.882103
  validation loss:		0.749371
  validation accuracy:		76.41 %
Epoch 200 of 2000 took 0.100s
  training loss:		0.887759
  validation loss:		0.727936
  validation accuracy:		76.63 %
Epoch 201 of 2000 took 0.100s
  training loss:		0.861517
  validation loss:		0.730338
  validation accuracy:		76.74 %
Epoch 202 of 2000 took 0.100s
  training loss:		0.856487
  validation loss:		0.724398
  validation accuracy:		76.63 %
Epoch 203 of 2000 took 0.100s
  training loss:		0.853602
  validation loss:		0.721125
  validation accuracy:		75.87 %
Epoch 204 of 2000 took 0.100s
  training loss:		0.843487
  validation loss:		0.707604
  validation accuracy:		76.85 %
Epoch 205 of 2000 took 0.100s
  training loss:		0.828558
  validation loss:		0.697232
  validation accuracy:		77.17 %
Epoch 206 of 2000 took 0.100s
  training loss:		0.825060
  validation loss:		0.689392
  validation accuracy:		78.37 %
Epoch 207 of 2000 took 0.100s
  training loss:		0.805222
  validation loss:		0.685752
  validation accuracy:		77.39 %
Epoch 208 of 2000 took 0.100s
  training loss:		0.822712
  validation loss:		0.677695
  validation accuracy:		78.15 %
Epoch 209 of 2000 took 0.100s
  training loss:		0.799876
  validation loss:		0.679819
  validation accuracy:		77.61 %
Epoch 210 of 2000 took 0.100s
  training loss:		0.800797
  validation loss:		0.735185
  validation accuracy:		75.65 %
Epoch 211 of 2000 took 0.100s
  training loss:		0.815139
  validation loss:		0.689932
  validation accuracy:		77.17 %
Epoch 212 of 2000 took 0.100s
  training loss:		0.794361
  validation loss:		0.667712
  validation accuracy:		77.93 %
Epoch 213 of 2000 took 0.100s
  training loss:		0.771862
  validation loss:		0.665651
  validation accuracy:		78.37 %
Epoch 214 of 2000 took 0.100s
  training loss:		0.772891
  validation loss:		0.676528
  validation accuracy:		77.72 %
Epoch 215 of 2000 took 0.099s
  training loss:		0.773932
  validation loss:		0.659582
  validation accuracy:		78.48 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.768683
  validation loss:		0.642737
  validation accuracy:		79.67 %
Epoch 217 of 2000 took 0.097s
  training loss:		0.754490
  validation loss:		0.646272
  validation accuracy:		78.15 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.750484
  validation loss:		0.636627
  validation accuracy:		79.46 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.739134
  validation loss:		0.635214
  validation accuracy:		79.46 %
Epoch 220 of 2000 took 0.097s
  training loss:		0.741061
  validation loss:		0.630485
  validation accuracy:		79.89 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.747459
  validation loss:		0.624801
  validation accuracy:		80.00 %
Epoch 222 of 2000 took 0.097s
  training loss:		0.769138
  validation loss:		0.637487
  validation accuracy:		78.70 %
Epoch 223 of 2000 took 0.097s
  training loss:		0.728767
  validation loss:		0.655464
  validation accuracy:		78.37 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.739968
  validation loss:		0.617204
  validation accuracy:		79.67 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.720118
  validation loss:		0.631456
  validation accuracy:		79.24 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.722930
  validation loss:		0.628313
  validation accuracy:		78.80 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.722733
  validation loss:		0.616657
  validation accuracy:		80.00 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.715075
  validation loss:		0.630599
  validation accuracy:		79.02 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.712225
  validation loss:		0.605784
  validation accuracy:		80.22 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.729038
  validation loss:		0.630688
  validation accuracy:		79.02 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.697832
  validation loss:		0.626911
  validation accuracy:		78.91 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.702977
  validation loss:		0.609853
  validation accuracy:		79.78 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.728586
  validation loss:		0.617231
  validation accuracy:		79.57 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.702955
  validation loss:		0.614072
  validation accuracy:		80.00 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.699757
  validation loss:		0.615064
  validation accuracy:		80.22 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.689255
  validation loss:		0.606847
  validation accuracy:		79.78 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.684558
  validation loss:		0.616247
  validation accuracy:		79.67 %
Epoch 238 of 2000 took 0.097s
  training loss:		0.704699
  validation loss:		0.613703
  validation accuracy:		80.00 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.683433
  validation loss:		0.594100
  validation accuracy:		80.54 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.696330
  validation loss:		0.680121
  validation accuracy:		77.28 %
Epoch 241 of 2000 took 0.102s
  training loss:		0.704786
  validation loss:		0.598171
  validation accuracy:		80.22 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.692139
  validation loss:		0.637373
  validation accuracy:		78.04 %
Epoch 243 of 2000 took 0.096s
  training loss:		0.685160
  validation loss:		0.602534
  validation accuracy:		80.00 %
Epoch 244 of 2000 took 0.096s
  training loss:		0.681283
  validation loss:		0.618014
  validation accuracy:		79.57 %
Epoch 245 of 2000 took 0.096s
  training loss:		0.691805
  validation loss:		0.584401
  validation accuracy:		80.76 %
Epoch 246 of 2000 took 0.096s
  training loss:		0.686146
  validation loss:		0.633287
  validation accuracy:		79.24 %
Epoch 247 of 2000 took 0.096s
  training loss:		0.669669
  validation loss:		0.582250
  validation accuracy:		81.30 %
Epoch 248 of 2000 took 0.102s
  training loss:		0.667762
  validation loss:		0.624926
  validation accuracy:		79.13 %
Epoch 249 of 2000 took 0.106s
  training loss:		0.698922
  validation loss:		0.644731
  validation accuracy:		78.48 %
Epoch 250 of 2000 took 0.121s
  training loss:		0.673983
  validation loss:		0.582558
  validation accuracy:		80.33 %
Epoch 251 of 2000 took 0.129s
  training loss:		0.658049
  validation loss:		0.579128
  validation accuracy:		80.76 %
Epoch 252 of 2000 took 0.102s
  training loss:		0.672453
  validation loss:		0.619040
  validation accuracy:		79.57 %
Epoch 253 of 2000 took 0.105s
  training loss:		0.677503
  validation loss:		0.581399
  validation accuracy:		81.30 %
Epoch 254 of 2000 took 0.099s
  training loss:		0.681575
  validation loss:		0.642800
  validation accuracy:		79.02 %
Epoch 255 of 2000 took 0.103s
  training loss:		0.661046
  validation loss:		0.587162
  validation accuracy:		81.63 %
Epoch 256 of 2000 took 0.103s
  training loss:		0.667499
  validation loss:		0.622329
  validation accuracy:		79.57 %
Epoch 257 of 2000 took 0.100s
  training loss:		0.668034
  validation loss:		0.580811
  validation accuracy:		81.09 %
Epoch 258 of 2000 took 0.101s
  training loss:		0.671975
  validation loss:		0.580653
  validation accuracy:		81.09 %
Epoch 259 of 2000 took 0.101s
  training loss:		0.672034
  validation loss:		0.594149
  validation accuracy:		80.33 %
Epoch 260 of 2000 took 0.100s
  training loss:		0.659214
  validation loss:		0.584346
  validation accuracy:		81.41 %
Epoch 261 of 2000 took 0.101s
  training loss:		0.648110
  validation loss:		0.596881
  validation accuracy:		80.54 %
Epoch 262 of 2000 took 0.100s
  training loss:		0.662236
  validation loss:		0.581558
  validation accuracy:		81.20 %
Epoch 263 of 2000 took 0.101s
  training loss:		0.659818
  validation loss:		0.574443
  validation accuracy:		82.17 %
Epoch 264 of 2000 took 0.100s
  training loss:		0.656356
  validation loss:		0.603965
  validation accuracy:		80.22 %
Epoch 265 of 2000 took 0.101s
  training loss:		0.673497
  validation loss:		0.575984
  validation accuracy:		81.96 %
Epoch 266 of 2000 took 0.100s
  training loss:		0.651168
  validation loss:		0.573417
  validation accuracy:		82.17 %
Epoch 267 of 2000 took 0.101s
  training loss:		0.668573
  validation loss:		0.569095
  validation accuracy:		81.96 %
Epoch 268 of 2000 took 0.100s
  training loss:		0.657192
  validation loss:		0.578093
  validation accuracy:		81.74 %
Epoch 269 of 2000 took 0.100s
  training loss:		0.648009
  validation loss:		0.634227
  validation accuracy:		79.24 %
Epoch 270 of 2000 took 0.101s
  training loss:		0.664688
  validation loss:		0.573688
  validation accuracy:		81.96 %
Epoch 271 of 2000 took 0.100s
  training loss:		0.637359
  validation loss:		0.574885
  validation accuracy:		81.96 %
Epoch 272 of 2000 took 0.100s
  training loss:		0.665609
  validation loss:		0.594392
  validation accuracy:		80.33 %
Epoch 273 of 2000 took 0.101s
  training loss:		0.669785
  validation loss:		0.620758
  validation accuracy:		79.57 %
Epoch 274 of 2000 took 0.100s
  training loss:		0.649065
  validation loss:		0.596533
  validation accuracy:		80.54 %
Epoch 275 of 2000 took 0.100s
  training loss:		0.636786
  validation loss:		0.576898
  validation accuracy:		81.63 %
Epoch 276 of 2000 took 0.100s
  training loss:		0.632059
  validation loss:		0.580311
  validation accuracy:		81.41 %
Epoch 277 of 2000 took 0.101s
  training loss:		0.678853
  validation loss:		0.596379
  validation accuracy:		81.20 %
Epoch 278 of 2000 took 0.100s
  training loss:		0.667742
  validation loss:		0.580546
  validation accuracy:		81.96 %
Epoch 279 of 2000 took 0.100s
  training loss:		0.648132
  validation loss:		0.574841
  validation accuracy:		82.28 %
Epoch 280 of 2000 took 0.101s
  training loss:		0.652765
  validation loss:		0.568186
  validation accuracy:		82.50 %
Epoch 281 of 2000 took 0.100s
  training loss:		0.638446
  validation loss:		0.564622
  validation accuracy:		82.39 %
Epoch 282 of 2000 took 0.100s
  training loss:		0.657538
  validation loss:		0.575822
  validation accuracy:		81.74 %
Epoch 283 of 2000 took 0.101s
  training loss:		0.639880
  validation loss:		0.567417
  validation accuracy:		82.17 %
Epoch 284 of 2000 took 0.101s
  training loss:		0.638883
  validation loss:		0.580601
  validation accuracy:		81.85 %
Epoch 285 of 2000 took 0.100s
  training loss:		0.654732
  validation loss:		0.571411
  validation accuracy:		82.61 %
Epoch 286 of 2000 took 0.100s
  training loss:		0.652162
  validation loss:		0.563015
  validation accuracy:		82.61 %
Epoch 287 of 2000 took 0.101s
  training loss:		0.645849
  validation loss:		0.588194
  validation accuracy:		81.96 %
Epoch 288 of 2000 took 0.100s
  training loss:		0.632303
  validation loss:		0.576767
  validation accuracy:		81.20 %
Epoch 289 of 2000 took 0.102s
  training loss:		0.647715
  validation loss:		0.603543
  validation accuracy:		80.43 %
Epoch 290 of 2000 took 0.102s
  training loss:		0.640586
  validation loss:		0.610408
  validation accuracy:		80.11 %
Epoch 291 of 2000 took 0.167s
  training loss:		0.637233
  validation loss:		0.578889
  validation accuracy:		82.07 %
Epoch 292 of 2000 took 0.165s
  training loss:		0.663642
  validation loss:		0.561018
  validation accuracy:		82.83 %
Epoch 293 of 2000 took 0.165s
  training loss:		0.636915
  validation loss:		0.579863
  validation accuracy:		81.09 %
Epoch 294 of 2000 took 0.165s
  training loss:		0.639593
  validation loss:		0.570795
  validation accuracy:		82.39 %
Epoch 295 of 2000 took 0.165s
  training loss:		0.649392
  validation loss:		0.565030
  validation accuracy:		81.74 %
Epoch 296 of 2000 took 0.133s
  training loss:		0.624922
  validation loss:		0.578417
  validation accuracy:		81.74 %
Epoch 297 of 2000 took 0.100s
  training loss:		0.645702
  validation loss:		0.569830
  validation accuracy:		82.17 %
Epoch 298 of 2000 took 0.100s
  training loss:		0.629079
  validation loss:		0.555859
  validation accuracy:		82.72 %
Epoch 299 of 2000 took 0.101s
  training loss:		0.639220
  validation loss:		0.571625
  validation accuracy:		82.17 %
Epoch 300 of 2000 took 0.108s
  training loss:		0.628927
  validation loss:		0.571926
  validation accuracy:		82.61 %
Epoch 301 of 2000 took 0.106s
  training loss:		0.618972
  validation loss:		0.557502
  validation accuracy:		82.93 %
Epoch 302 of 2000 took 0.100s
  training loss:		0.626685
  validation loss:		0.556182
  validation accuracy:		82.72 %
Epoch 303 of 2000 took 0.101s
  training loss:		0.626588
  validation loss:		0.557855
  validation accuracy:		82.50 %
Epoch 304 of 2000 took 0.100s
  training loss:		0.617155
  validation loss:		0.564760
  validation accuracy:		82.50 %
Epoch 305 of 2000 took 0.100s
  training loss:		0.641440
  validation loss:		0.557435
  validation accuracy:		82.72 %
Epoch 306 of 2000 took 0.100s
  training loss:		0.610290
  validation loss:		0.563122
  validation accuracy:		82.39 %
Epoch 307 of 2000 took 0.100s
  training loss:		0.608748
  validation loss:		0.550602
  validation accuracy:		82.83 %
Epoch 308 of 2000 took 0.100s
  training loss:		0.611455
  validation loss:		0.581399
  validation accuracy:		81.41 %
Epoch 309 of 2000 took 0.101s
  training loss:		0.618460
  validation loss:		0.548691
  validation accuracy:		83.15 %
Epoch 310 of 2000 took 0.100s
  training loss:		0.627604
  validation loss:		0.553466
  validation accuracy:		82.61 %
Epoch 311 of 2000 took 0.101s
  training loss:		0.609873
  validation loss:		0.545103
  validation accuracy:		83.48 %
Epoch 312 of 2000 took 0.104s
  training loss:		0.613015
  validation loss:		0.580495
  validation accuracy:		80.54 %
Epoch 313 of 2000 took 0.100s
  training loss:		0.618058
  validation loss:		0.547078
  validation accuracy:		83.15 %
Epoch 314 of 2000 took 0.096s
  training loss:		0.624999
  validation loss:		0.548313
  validation accuracy:		83.26 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.615267
  validation loss:		0.567287
  validation accuracy:		82.83 %
Epoch 316 of 2000 took 0.096s
  training loss:		0.643312
  validation loss:		0.553430
  validation accuracy:		83.15 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.633517
  validation loss:		0.578890
  validation accuracy:		81.96 %
Epoch 318 of 2000 took 0.096s
  training loss:		0.613644
  validation loss:		0.542919
  validation accuracy:		83.15 %
Epoch 319 of 2000 took 0.096s
  training loss:		0.612232
  validation loss:		0.553885
  validation accuracy:		82.83 %
Epoch 320 of 2000 took 0.096s
  training loss:		0.603371
  validation loss:		0.539289
  validation accuracy:		83.15 %
Epoch 321 of 2000 took 0.096s
  training loss:		0.610658
  validation loss:		0.569191
  validation accuracy:		82.83 %
Epoch 322 of 2000 took 0.096s
  training loss:		0.613842
  validation loss:		0.542575
  validation accuracy:		83.04 %
Epoch 323 of 2000 took 0.096s
  training loss:		0.610022
  validation loss:		0.559443
  validation accuracy:		82.50 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.605981
  validation loss:		0.573217
  validation accuracy:		81.41 %
Epoch 325 of 2000 took 0.096s
  training loss:		0.634269
  validation loss:		0.539086
  validation accuracy:		83.15 %
Epoch 326 of 2000 took 0.096s
  training loss:		0.615789
  validation loss:		0.535070
  validation accuracy:		83.26 %
Epoch 327 of 2000 took 0.096s
  training loss:		0.589037
  validation loss:		0.548044
  validation accuracy:		82.93 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.591153
  validation loss:		0.529826
  validation accuracy:		83.26 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.590172
  validation loss:		0.584852
  validation accuracy:		80.87 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.598496
  validation loss:		0.526754
  validation accuracy:		83.70 %
Epoch 331 of 2000 took 0.096s
  training loss:		0.599864
  validation loss:		0.520464
  validation accuracy:		84.02 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.598281
  validation loss:		0.586868
  validation accuracy:		80.87 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.618637
  validation loss:		0.584038
  validation accuracy:		80.98 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.586362
  validation loss:		0.521462
  validation accuracy:		84.02 %
Epoch 335 of 2000 took 0.096s
  training loss:		0.583964
  validation loss:		0.527594
  validation accuracy:		84.02 %
Epoch 336 of 2000 took 0.096s
  training loss:		0.578003
  validation loss:		0.521830
  validation accuracy:		84.46 %
Epoch 337 of 2000 took 0.096s
  training loss:		0.578183
  validation loss:		0.521685
  validation accuracy:		84.46 %
Epoch 338 of 2000 took 0.097s
  training loss:		0.573538
  validation loss:		0.527664
  validation accuracy:		83.59 %
Epoch 339 of 2000 took 0.096s
  training loss:		0.588044
  validation loss:		0.514733
  validation accuracy:		84.78 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.582147
  validation loss:		0.524571
  validation accuracy:		83.48 %
Epoch 341 of 2000 took 0.096s
  training loss:		0.593132
  validation loss:		0.518192
  validation accuracy:		84.13 %
Epoch 342 of 2000 took 0.096s
  training loss:		0.565528
  validation loss:		0.532386
  validation accuracy:		83.59 %
Epoch 343 of 2000 took 0.096s
  training loss:		0.576967
  validation loss:		0.507871
  validation accuracy:		84.46 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.565309
  validation loss:		0.528910
  validation accuracy:		83.37 %
Epoch 345 of 2000 took 0.096s
  training loss:		0.568551
  validation loss:		0.505129
  validation accuracy:		84.35 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.559678
  validation loss:		0.509508
  validation accuracy:		84.35 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.573065
  validation loss:		0.511354
  validation accuracy:		84.46 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.560080
  validation loss:		0.494549
  validation accuracy:		84.57 %
Epoch 349 of 2000 took 0.096s
  training loss:		0.563359
  validation loss:		0.525618
  validation accuracy:		83.80 %
Epoch 350 of 2000 took 0.096s
  training loss:		0.566949
  validation loss:		0.497694
  validation accuracy:		85.22 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.550064
  validation loss:		0.543119
  validation accuracy:		83.04 %
Epoch 352 of 2000 took 0.096s
  training loss:		0.552103
  validation loss:		0.536709
  validation accuracy:		82.61 %
Epoch 353 of 2000 took 0.096s
  training loss:		0.554668
  validation loss:		0.502935
  validation accuracy:		84.46 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.554144
  validation loss:		0.529196
  validation accuracy:		82.83 %
Epoch 355 of 2000 took 0.097s
  training loss:		0.544497
  validation loss:		0.587218
  validation accuracy:		80.54 %
Epoch 356 of 2000 took 0.096s
  training loss:		0.574519
  validation loss:		0.513246
  validation accuracy:		84.24 %
Epoch 357 of 2000 took 0.097s
  training loss:		0.543382
  validation loss:		0.484107
  validation accuracy:		85.43 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.547315
  validation loss:		0.502484
  validation accuracy:		84.46 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.545160
  validation loss:		0.513237
  validation accuracy:		84.13 %
Epoch 360 of 2000 took 0.096s
  training loss:		0.548324
  validation loss:		0.488069
  validation accuracy:		85.11 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.529254
  validation loss:		0.495410
  validation accuracy:		84.89 %
Epoch 362 of 2000 took 0.096s
  training loss:		0.535042
  validation loss:		0.481100
  validation accuracy:		85.33 %
Epoch 363 of 2000 took 0.098s
  training loss:		0.547184
  validation loss:		0.514989
  validation accuracy:		83.48 %
Epoch 364 of 2000 took 0.098s
  training loss:		0.550039
  validation loss:		0.489666
  validation accuracy:		85.22 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.532180
  validation loss:		0.482525
  validation accuracy:		85.43 %
Epoch 366 of 2000 took 0.096s
  training loss:		0.518663
  validation loss:		0.478300
  validation accuracy:		86.30 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.521531
  validation loss:		0.472736
  validation accuracy:		86.41 %
Epoch 368 of 2000 took 0.096s
  training loss:		0.518578
  validation loss:		0.480530
  validation accuracy:		85.33 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.513897
  validation loss:		0.470580
  validation accuracy:		86.09 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.525247
  validation loss:		0.497246
  validation accuracy:		84.89 %
Epoch 371 of 2000 took 0.098s
  training loss:		0.524362
  validation loss:		0.465541
  validation accuracy:		85.87 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.513208
  validation loss:		0.471945
  validation accuracy:		86.41 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.506105
  validation loss:		0.466746
  validation accuracy:		86.52 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.506061
  validation loss:		0.475693
  validation accuracy:		85.33 %
Epoch 375 of 2000 took 0.097s
  training loss:		0.513329
  validation loss:		0.465435
  validation accuracy:		86.09 %
Epoch 376 of 2000 took 0.097s
  training loss:		0.508422
  validation loss:		0.462869
  validation accuracy:		86.41 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.510045
  validation loss:		0.463400
  validation accuracy:		85.87 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.511312
  validation loss:		0.460033
  validation accuracy:		86.20 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.506668
  validation loss:		0.464577
  validation accuracy:		85.98 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.506220
  validation loss:		0.482503
  validation accuracy:		84.67 %
Epoch 381 of 2000 took 0.096s
  training loss:		0.501209
  validation loss:		0.467878
  validation accuracy:		85.65 %
Epoch 382 of 2000 took 0.097s
  training loss:		0.497842
  validation loss:		0.457670
  validation accuracy:		85.98 %
Epoch 383 of 2000 took 0.096s
  training loss:		0.497921
  validation loss:		0.461608
  validation accuracy:		85.11 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.495974
  validation loss:		0.466671
  validation accuracy:		85.76 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.488438
  validation loss:		0.464425
  validation accuracy:		85.33 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.493141
  validation loss:		0.457170
  validation accuracy:		85.76 %
Epoch 387 of 2000 took 0.096s
  training loss:		0.485852
  validation loss:		0.454111
  validation accuracy:		85.87 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.490088
  validation loss:		0.452692
  validation accuracy:		85.76 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.492475
  validation loss:		0.465228
  validation accuracy:		84.89 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.481959
  validation loss:		0.456841
  validation accuracy:		85.54 %
Epoch 391 of 2000 took 0.096s
  training loss:		0.485647
  validation loss:		0.456118
  validation accuracy:		85.43 %
Epoch 392 of 2000 took 0.096s
  training loss:		0.479289
  validation loss:		0.449821
  validation accuracy:		85.87 %
Epoch 393 of 2000 took 0.096s
  training loss:		0.483652
  validation loss:		0.444208
  validation accuracy:		86.30 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.482453
  validation loss:		0.472528
  validation accuracy:		84.78 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.482222
  validation loss:		0.442184
  validation accuracy:		86.09 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.495239
  validation loss:		0.453312
  validation accuracy:		85.54 %
Epoch 397 of 2000 took 0.096s
  training loss:		0.472862
  validation loss:		0.461015
  validation accuracy:		85.43 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.469708
  validation loss:		0.450740
  validation accuracy:		85.43 %
Epoch 399 of 2000 took 0.096s
  training loss:		0.467736
  validation loss:		0.478226
  validation accuracy:		84.89 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.459526
  validation loss:		0.443926
  validation accuracy:		85.87 %
Epoch 401 of 2000 took 0.096s
  training loss:		0.467625
  validation loss:		0.438514
  validation accuracy:		86.20 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.466581
  validation loss:		0.446666
  validation accuracy:		85.43 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.472394
  validation loss:		0.455342
  validation accuracy:		85.11 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.463246
  validation loss:		0.444911
  validation accuracy:		85.98 %
Epoch 405 of 2000 took 0.096s
  training loss:		0.455179
  validation loss:		0.461629
  validation accuracy:		84.24 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.461973
  validation loss:		0.441591
  validation accuracy:		85.87 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.461111
  validation loss:		0.434965
  validation accuracy:		85.98 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.461883
  validation loss:		0.436312
  validation accuracy:		86.30 %
Epoch 409 of 2000 took 0.096s
  training loss:		0.461455
  validation loss:		0.438816
  validation accuracy:		85.98 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.458864
  validation loss:		0.432955
  validation accuracy:		85.98 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.456094
  validation loss:		0.431802
  validation accuracy:		85.54 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.445890
  validation loss:		0.440783
  validation accuracy:		85.54 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.447338
  validation loss:		0.427084
  validation accuracy:		86.09 %
Epoch 414 of 2000 took 0.097s
  training loss:		0.438208
  validation loss:		0.443803
  validation accuracy:		84.67 %
Epoch 415 of 2000 took 0.097s
  training loss:		0.441211
  validation loss:		0.429253
  validation accuracy:		85.87 %
Epoch 416 of 2000 took 0.097s
  training loss:		0.443737
  validation loss:		0.444836
  validation accuracy:		84.89 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.441626
  validation loss:		0.432778
  validation accuracy:		85.65 %
Epoch 418 of 2000 took 0.096s
  training loss:		0.440772
  validation loss:		0.457539
  validation accuracy:		84.24 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.448977
  validation loss:		0.427294
  validation accuracy:		86.30 %
Epoch 420 of 2000 took 0.096s
  training loss:		0.438535
  validation loss:		0.446578
  validation accuracy:		85.87 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.440277
  validation loss:		0.432233
  validation accuracy:		86.52 %
Epoch 422 of 2000 took 0.096s
  training loss:		0.439109
  validation loss:		0.438482
  validation accuracy:		85.11 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.439666
  validation loss:		0.438930
  validation accuracy:		84.67 %
Epoch 424 of 2000 took 0.096s
  training loss:		0.441251
  validation loss:		0.435860
  validation accuracy:		85.33 %
Epoch 425 of 2000 took 0.096s
  training loss:		0.440273
  validation loss:		0.421261
  validation accuracy:		86.09 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.428714
  validation loss:		0.423181
  validation accuracy:		85.76 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.429775
  validation loss:		0.423021
  validation accuracy:		85.54 %
Epoch 428 of 2000 took 0.096s
  training loss:		0.428754
  validation loss:		0.422853
  validation accuracy:		85.76 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.428188
  validation loss:		0.426291
  validation accuracy:		85.54 %
Epoch 430 of 2000 took 0.096s
  training loss:		0.430970
  validation loss:		0.419186
  validation accuracy:		85.87 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.436101
  validation loss:		0.426729
  validation accuracy:		85.87 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.412305
  validation loss:		0.420099
  validation accuracy:		85.87 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.426121
  validation loss:		0.435458
  validation accuracy:		84.46 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.424069
  validation loss:		0.425851
  validation accuracy:		84.67 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.423126
  validation loss:		0.417255
  validation accuracy:		85.65 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.418857
  validation loss:		0.437140
  validation accuracy:		85.33 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.425043
  validation loss:		0.422427
  validation accuracy:		85.22 %
Epoch 438 of 2000 took 0.097s
  training loss:		0.419008
  validation loss:		0.418844
  validation accuracy:		85.87 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.412908
  validation loss:		0.414765
  validation accuracy:		85.98 %
Epoch 440 of 2000 took 0.096s
  training loss:		0.420937
  validation loss:		0.413310
  validation accuracy:		86.30 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.420545
  validation loss:		0.412743
  validation accuracy:		86.41 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.415023
  validation loss:		0.421695
  validation accuracy:		85.65 %
Epoch 443 of 2000 took 0.096s
  training loss:		0.405917
  validation loss:		0.416535
  validation accuracy:		85.65 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.420523
  validation loss:		0.409412
  validation accuracy:		86.30 %
Epoch 445 of 2000 took 0.096s
  training loss:		0.406046
  validation loss:		0.423486
  validation accuracy:		86.52 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.410404
  validation loss:		0.415063
  validation accuracy:		86.09 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.415387
  validation loss:		0.417262
  validation accuracy:		85.43 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.412120
  validation loss:		0.421906
  validation accuracy:		85.76 %
Epoch 449 of 2000 took 0.096s
  training loss:		0.410317
  validation loss:		0.410924
  validation accuracy:		86.09 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.404134
  validation loss:		0.414967
  validation accuracy:		85.65 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.413637
  validation loss:		0.413185
  validation accuracy:		85.43 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.403501
  validation loss:		0.407116
  validation accuracy:		86.41 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.402947
  validation loss:		0.418456
  validation accuracy:		86.30 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.410157
  validation loss:		0.413946
  validation accuracy:		86.09 %
Epoch 455 of 2000 took 0.096s
  training loss:		0.399582
  validation loss:		0.415604
  validation accuracy:		86.52 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.402512
  validation loss:		0.421889
  validation accuracy:		86.30 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.404839
  validation loss:		0.403879
  validation accuracy:		86.20 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.397434
  validation loss:		0.412665
  validation accuracy:		86.41 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.402186
  validation loss:		0.421448
  validation accuracy:		85.11 %
Epoch 460 of 2000 took 0.096s
  training loss:		0.407933
  validation loss:		0.421414
  validation accuracy:		85.87 %
Epoch 461 of 2000 took 0.096s
  training loss:		0.399418
  validation loss:		0.404596
  validation accuracy:		85.87 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.403996
  validation loss:		0.406021
  validation accuracy:		86.85 %
Epoch 463 of 2000 took 0.096s
  training loss:		0.398075
  validation loss:		0.403374
  validation accuracy:		86.30 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.395777
  validation loss:		0.409247
  validation accuracy:		86.52 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.392958
  validation loss:		0.414344
  validation accuracy:		86.09 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.393103
  validation loss:		0.417927
  validation accuracy:		85.11 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.394392
  validation loss:		0.414349
  validation accuracy:		85.98 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.397861
  validation loss:		0.411459
  validation accuracy:		85.65 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.396140
  validation loss:		0.404349
  validation accuracy:		86.30 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.403498
  validation loss:		0.402594
  validation accuracy:		85.76 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.389618
  validation loss:		0.403984
  validation accuracy:		85.43 %
Epoch 472 of 2000 took 0.096s
  training loss:		0.386937
  validation loss:		0.417018
  validation accuracy:		85.11 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.385637
  validation loss:		0.405962
  validation accuracy:		86.85 %
Epoch 474 of 2000 took 0.096s
  training loss:		0.393739
  validation loss:		0.411224
  validation accuracy:		86.09 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.385904
  validation loss:		0.402102
  validation accuracy:		86.41 %
Epoch 476 of 2000 took 0.096s
  training loss:		0.388413
  validation loss:		0.406034
  validation accuracy:		85.76 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.391626
  validation loss:		0.398747
  validation accuracy:		86.20 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.391176
  validation loss:		0.404431
  validation accuracy:		86.96 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.383923
  validation loss:		0.410087
  validation accuracy:		85.98 %
Epoch 480 of 2000 took 0.096s
  training loss:		0.389182
  validation loss:		0.402154
  validation accuracy:		86.09 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.383126
  validation loss:		0.399478
  validation accuracy:		86.74 %
Epoch 482 of 2000 took 0.100s
  training loss:		0.379534
  validation loss:		0.410940
  validation accuracy:		86.41 %
Epoch 483 of 2000 took 0.103s
  training loss:		0.387100
  validation loss:		0.404451
  validation accuracy:		86.41 %
Epoch 484 of 2000 took 0.103s
  training loss:		0.388728
  validation loss:		0.408040
  validation accuracy:		85.98 %
Epoch 485 of 2000 took 0.103s
  training loss:		0.383868
  validation loss:		0.397336
  validation accuracy:		86.63 %
Epoch 486 of 2000 took 0.103s
  training loss:		0.374601
  validation loss:		0.401477
  validation accuracy:		86.85 %
Epoch 487 of 2000 took 0.103s
  training loss:		0.384011
  validation loss:		0.399869
  validation accuracy:		86.09 %
Epoch 488 of 2000 took 0.103s
  training loss:		0.373548
  validation loss:		0.404283
  validation accuracy:		86.09 %
Epoch 489 of 2000 took 0.099s
  training loss:		0.381410
  validation loss:		0.400246
  validation accuracy:		86.63 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.377447
  validation loss:		0.400011
  validation accuracy:		86.41 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.381606
  validation loss:		0.408725
  validation accuracy:		86.30 %
Epoch 492 of 2000 took 0.096s
  training loss:		0.382094
  validation loss:		0.406865
  validation accuracy:		86.41 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.379780
  validation loss:		0.395228
  validation accuracy:		86.85 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.380616
  validation loss:		0.402347
  validation accuracy:		85.65 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.370579
  validation loss:		0.407845
  validation accuracy:		84.89 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.381943
  validation loss:		0.396707
  validation accuracy:		86.20 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.379650
  validation loss:		0.402696
  validation accuracy:		87.28 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.382593
  validation loss:		0.408853
  validation accuracy:		86.30 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.369665
  validation loss:		0.418768
  validation accuracy:		85.87 %
Epoch 500 of 2000 took 0.096s
  training loss:		0.380242
  validation loss:		0.400107
  validation accuracy:		85.87 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.370846
  validation loss:		0.394823
  validation accuracy:		86.41 %
Epoch 502 of 2000 took 0.096s
  training loss:		0.370092
  validation loss:		0.394799
  validation accuracy:		85.76 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.378333
  validation loss:		0.400838
  validation accuracy:		86.30 %
Epoch 504 of 2000 took 0.096s
  training loss:		0.370728
  validation loss:		0.396931
  validation accuracy:		86.63 %
Epoch 505 of 2000 took 0.096s
  training loss:		0.369170
  validation loss:		0.416079
  validation accuracy:		86.30 %
Epoch 506 of 2000 took 0.099s
  training loss:		0.371387
  validation loss:		0.402885
  validation accuracy:		86.20 %
Epoch 507 of 2000 took 0.097s
  training loss:		0.374254
  validation loss:		0.400482
  validation accuracy:		87.07 %
Epoch 508 of 2000 took 0.096s
  training loss:		0.371396
  validation loss:		0.410857
  validation accuracy:		86.63 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.368582
  validation loss:		0.401926
  validation accuracy:		86.63 %
Epoch 510 of 2000 took 0.096s
  training loss:		0.366295
  validation loss:		0.394048
  validation accuracy:		85.87 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.370418
  validation loss:		0.397594
  validation accuracy:		86.63 %
Epoch 512 of 2000 took 0.096s
  training loss:		0.364578
  validation loss:		0.394381
  validation accuracy:		86.63 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.371050
  validation loss:		0.392166
  validation accuracy:		87.07 %
Epoch 514 of 2000 took 0.096s
  training loss:		0.369529
  validation loss:		0.397547
  validation accuracy:		86.74 %
Epoch 515 of 2000 took 0.096s
  training loss:		0.374284
  validation loss:		0.408975
  validation accuracy:		86.52 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.370453
  validation loss:		0.401510
  validation accuracy:		86.63 %
Epoch 517 of 2000 took 0.096s
  training loss:		0.366061
  validation loss:		0.395420
  validation accuracy:		85.87 %
Epoch 518 of 2000 took 0.096s
  training loss:		0.360422
  validation loss:		0.403990
  validation accuracy:		87.39 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.369360
  validation loss:		0.400624
  validation accuracy:		86.41 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.366952
  validation loss:		0.395715
  validation accuracy:		86.74 %
Epoch 521 of 2000 took 0.096s
  training loss:		0.368044
  validation loss:		0.397793
  validation accuracy:		86.52 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.357474
  validation loss:		0.392592
  validation accuracy:		86.74 %
Epoch 523 of 2000 took 0.096s
  training loss:		0.365951
  validation loss:		0.395591
  validation accuracy:		86.63 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.366499
  validation loss:		0.407371
  validation accuracy:		86.52 %
Epoch 525 of 2000 took 0.096s
  training loss:		0.368837
  validation loss:		0.396257
  validation accuracy:		86.96 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.365325
  validation loss:		0.392864
  validation accuracy:		86.74 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.363438
  validation loss:		0.394598
  validation accuracy:		86.74 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.361322
  validation loss:		0.394193
  validation accuracy:		86.41 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.367261
  validation loss:		0.398440
  validation accuracy:		86.74 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.369592
  validation loss:		0.391657
  validation accuracy:		86.63 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.360577
  validation loss:		0.394118
  validation accuracy:		87.39 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.362680
  validation loss:		0.394230
  validation accuracy:		86.52 %
Epoch 533 of 2000 took 0.096s
  training loss:		0.358331
  validation loss:		0.393859
  validation accuracy:		87.17 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.359426
  validation loss:		0.394856
  validation accuracy:		86.52 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.365065
  validation loss:		0.394975
  validation accuracy:		86.74 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.363421
  validation loss:		0.398732
  validation accuracy:		86.09 %
Epoch 537 of 2000 took 0.096s
  training loss:		0.363138
  validation loss:		0.396030
  validation accuracy:		87.17 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.358036
  validation loss:		0.399541
  validation accuracy:		86.85 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.360237
  validation loss:		0.391551
  validation accuracy:		86.63 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.359374
  validation loss:		0.393198
  validation accuracy:		86.52 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.355320
  validation loss:		0.392901
  validation accuracy:		86.85 %
Epoch 542 of 2000 took 0.096s
  training loss:		0.353905
  validation loss:		0.395373
  validation accuracy:		86.09 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.357076
  validation loss:		0.390369
  validation accuracy:		86.52 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.366285
  validation loss:		0.400339
  validation accuracy:		86.85 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.359176
  validation loss:		0.387263
  validation accuracy:		86.96 %
Epoch 546 of 2000 took 0.096s
  training loss:		0.343180
  validation loss:		0.393222
  validation accuracy:		86.74 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.356690
  validation loss:		0.391425
  validation accuracy:		86.41 %
Epoch 548 of 2000 took 0.096s
  training loss:		0.352159
  validation loss:		0.391524
  validation accuracy:		86.85 %
Epoch 549 of 2000 took 0.096s
  training loss:		0.352443
  validation loss:		0.395776
  validation accuracy:		86.74 %
Epoch 550 of 2000 took 0.096s
  training loss:		0.358489
  validation loss:		0.393781
  validation accuracy:		87.17 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.354450
  validation loss:		0.399251
  validation accuracy:		86.09 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.358729
  validation loss:		0.423519
  validation accuracy:		85.98 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.355213
  validation loss:		0.387801
  validation accuracy:		86.74 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.354927
  validation loss:		0.416822
  validation accuracy:		86.96 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.361251
  validation loss:		0.388418
  validation accuracy:		86.20 %
Epoch 556 of 2000 took 0.096s
  training loss:		0.354659
  validation loss:		0.403719
  validation accuracy:		86.52 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.352371
  validation loss:		0.407519
  validation accuracy:		86.52 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.352632
  validation loss:		0.403755
  validation accuracy:		85.87 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.352439
  validation loss:		0.398024
  validation accuracy:		86.74 %
Epoch 560 of 2000 took 0.096s
  training loss:		0.357417
  validation loss:		0.397633
  validation accuracy:		86.74 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.349083
  validation loss:		0.400209
  validation accuracy:		86.30 %
Epoch 562 of 2000 took 0.096s
  training loss:		0.352100
  validation loss:		0.390400
  validation accuracy:		87.28 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.352644
  validation loss:		0.390945
  validation accuracy:		86.20 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.356193
  validation loss:		0.390973
  validation accuracy:		86.30 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.352301
  validation loss:		0.391047
  validation accuracy:		86.52 %
Epoch 566 of 2000 took 0.096s
  training loss:		0.356546
  validation loss:		0.388053
  validation accuracy:		86.74 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.347829
  validation loss:		0.387015
  validation accuracy:		87.17 %
Epoch 568 of 2000 took 0.096s
  training loss:		0.348745
  validation loss:		0.387727
  validation accuracy:		86.74 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.353407
  validation loss:		0.392445
  validation accuracy:		86.52 %
Epoch 570 of 2000 took 0.096s
  training loss:		0.354557
  validation loss:		0.387515
  validation accuracy:		86.30 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.351340
  validation loss:		0.390602
  validation accuracy:		86.96 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.347107
  validation loss:		0.403019
  validation accuracy:		86.41 %
Epoch 573 of 2000 took 0.096s
  training loss:		0.359351
  validation loss:		0.385885
  validation accuracy:		87.17 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.345369
  validation loss:		0.394442
  validation accuracy:		87.28 %
Epoch 575 of 2000 took 0.096s
  training loss:		0.357922
  validation loss:		0.391472
  validation accuracy:		86.09 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.342827
  validation loss:		0.406833
  validation accuracy:		86.63 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.349100
  validation loss:		0.394645
  validation accuracy:		86.85 %
Epoch 578 of 2000 took 0.098s
  training loss:		0.346420
  validation loss:		0.389842
  validation accuracy:		86.41 %
Epoch 579 of 2000 took 0.096s
  training loss:		0.351582
  validation loss:		0.394299
  validation accuracy:		87.39 %
Epoch 580 of 2000 took 0.098s
  training loss:		0.351100
  validation loss:		0.385300
  validation accuracy:		86.85 %
Epoch 581 of 2000 took 0.100s
  training loss:		0.335657
  validation loss:		0.390539
  validation accuracy:		87.07 %
Epoch 582 of 2000 took 0.100s
  training loss:		0.348160
  validation loss:		0.389310
  validation accuracy:		86.85 %
Epoch 583 of 2000 took 0.099s
  training loss:		0.345417
  validation loss:		0.390595
  validation accuracy:		86.30 %
Epoch 584 of 2000 took 0.100s
  training loss:		0.347355
  validation loss:		0.389380
  validation accuracy:		86.30 %
Epoch 585 of 2000 took 0.099s
  training loss:		0.346976
  validation loss:		0.399855
  validation accuracy:		86.20 %
Epoch 586 of 2000 took 0.100s
  training loss:		0.342928
  validation loss:		0.394416
  validation accuracy:		86.20 %
Epoch 587 of 2000 took 0.099s
  training loss:		0.347595
  validation loss:		0.387823
  validation accuracy:		86.52 %
Epoch 588 of 2000 took 0.100s
  training loss:		0.343106
  validation loss:		0.391337
  validation accuracy:		86.20 %
Epoch 589 of 2000 took 0.100s
  training loss:		0.343808
  validation loss:		0.402848
  validation accuracy:		86.09 %
Epoch 590 of 2000 took 0.100s
  training loss:		0.334746
  validation loss:		0.388853
  validation accuracy:		86.41 %
Epoch 591 of 2000 took 0.100s
  training loss:		0.340568
  validation loss:		0.400940
  validation accuracy:		87.50 %
Epoch 592 of 2000 took 0.100s
  training loss:		0.340303
  validation loss:		0.391402
  validation accuracy:		86.52 %
Epoch 593 of 2000 took 0.100s
  training loss:		0.343948
  validation loss:		0.384764
  validation accuracy:		86.52 %
Epoch 594 of 2000 took 0.100s
  training loss:		0.338869
  validation loss:		0.386906
  validation accuracy:		86.52 %
Epoch 595 of 2000 took 0.100s
  training loss:		0.343070
  validation loss:		0.392003
  validation accuracy:		86.52 %
Epoch 596 of 2000 took 0.100s
  training loss:		0.350088
  validation loss:		0.385101
  validation accuracy:		87.39 %
Epoch 597 of 2000 took 0.099s
  training loss:		0.345768
  validation loss:		0.400041
  validation accuracy:		86.96 %
Epoch 598 of 2000 took 0.100s
  training loss:		0.349940
  validation loss:		0.394492
  validation accuracy:		86.52 %
Epoch 599 of 2000 took 0.099s
  training loss:		0.351645
  validation loss:		0.392695
  validation accuracy:		86.41 %
Epoch 600 of 2000 took 0.099s
  training loss:		0.350824
  validation loss:		0.385785
  validation accuracy:		87.72 %
Epoch 601 of 2000 took 0.099s
  training loss:		0.347610
  validation loss:		0.385229
  validation accuracy:		86.63 %
Epoch 602 of 2000 took 0.100s
  training loss:		0.352495
  validation loss:		0.389925
  validation accuracy:		87.39 %
Epoch 603 of 2000 took 0.099s
  training loss:		0.337469
  validation loss:		0.396988
  validation accuracy:		86.63 %
Epoch 604 of 2000 took 0.099s
  training loss:		0.351880
  validation loss:		0.391125
  validation accuracy:		87.61 %
Epoch 605 of 2000 took 0.099s
  training loss:		0.341689
  validation loss:		0.390942
  validation accuracy:		87.50 %
Epoch 606 of 2000 took 0.100s
  training loss:		0.348441
  validation loss:		0.388482
  validation accuracy:		86.52 %
Epoch 607 of 2000 took 0.099s
  training loss:		0.346655
  validation loss:		0.387025
  validation accuracy:		86.74 %
Epoch 608 of 2000 took 0.100s
  training loss:		0.349590
  validation loss:		0.424129
  validation accuracy:		85.76 %
Epoch 609 of 2000 took 0.099s
  training loss:		0.348061
  validation loss:		0.409788
  validation accuracy:		86.41 %
Epoch 610 of 2000 took 0.099s
  training loss:		0.335060
  validation loss:		0.391287
  validation accuracy:		86.30 %
Epoch 611 of 2000 took 0.099s
  training loss:		0.335006
  validation loss:		0.395559
  validation accuracy:		87.17 %
Epoch 612 of 2000 took 0.100s
  training loss:		0.337029
  validation loss:		0.386843
  validation accuracy:		87.28 %
Epoch 613 of 2000 took 0.099s
  training loss:		0.338040
  validation loss:		0.385540
  validation accuracy:		86.52 %
Epoch 614 of 2000 took 0.099s
  training loss:		0.339670
  validation loss:		0.385649
  validation accuracy:		87.07 %
Epoch 615 of 2000 took 0.099s
  training loss:		0.334760
  validation loss:		0.404967
  validation accuracy:		86.74 %
Epoch 616 of 2000 took 0.100s
  training loss:		0.341104
  validation loss:		0.385056
  validation accuracy:		86.74 %
Epoch 617 of 2000 took 0.100s
  training loss:		0.339754
  validation loss:		0.391786
  validation accuracy:		87.17 %
Epoch 618 of 2000 took 0.100s
  training loss:		0.342011
  validation loss:		0.405902
  validation accuracy:		87.07 %
Epoch 619 of 2000 took 0.100s
  training loss:		0.344706
  validation loss:		0.385105
  validation accuracy:		86.74 %
Epoch 620 of 2000 took 0.101s
  training loss:		0.339914
  validation loss:		0.398235
  validation accuracy:		86.74 %
Epoch 621 of 2000 took 0.103s
  training loss:		0.339519
  validation loss:		0.390572
  validation accuracy:		86.41 %
Epoch 622 of 2000 took 0.103s
  training loss:		0.339961
  validation loss:		0.396795
  validation accuracy:		86.41 %
Epoch 623 of 2000 took 0.103s
  training loss:		0.343793
  validation loss:		0.390541
  validation accuracy:		86.41 %
Epoch 624 of 2000 took 0.103s
  training loss:		0.346297
  validation loss:		0.400328
  validation accuracy:		86.30 %
Epoch 625 of 2000 took 0.103s
  training loss:		0.337539
  validation loss:		0.388523
  validation accuracy:		87.28 %
Epoch 626 of 2000 took 0.103s
  training loss:		0.342326
  validation loss:		0.384517
  validation accuracy:		86.52 %
Epoch 627 of 2000 took 0.103s
  training loss:		0.335969
  validation loss:		0.387236
  validation accuracy:		87.07 %
Epoch 628 of 2000 took 0.103s
  training loss:		0.341718
  validation loss:		0.384106
  validation accuracy:		87.17 %
Epoch 629 of 2000 took 0.103s
  training loss:		0.343189
  validation loss:		0.392732
  validation accuracy:		86.63 %
Epoch 630 of 2000 took 0.103s
  training loss:		0.342120
  validation loss:		0.385066
  validation accuracy:		87.07 %
Epoch 631 of 2000 took 0.103s
  training loss:		0.343158
  validation loss:		0.382188
  validation accuracy:		87.72 %
Epoch 632 of 2000 took 0.103s
  training loss:		0.340662
  validation loss:		0.384102
  validation accuracy:		87.28 %
Epoch 633 of 2000 took 0.103s
  training loss:		0.342767
  validation loss:		0.381511
  validation accuracy:		87.39 %
Epoch 634 of 2000 took 0.103s
  training loss:		0.333507
  validation loss:		0.386107
  validation accuracy:		87.93 %
Epoch 635 of 2000 took 0.103s
  training loss:		0.328661
  validation loss:		0.382862
  validation accuracy:		87.07 %
Epoch 636 of 2000 took 0.103s
  training loss:		0.340622
  validation loss:		0.388536
  validation accuracy:		87.17 %
Epoch 637 of 2000 took 0.103s
  training loss:		0.332689
  validation loss:		0.388673
  validation accuracy:		86.96 %
Epoch 638 of 2000 took 0.103s
  training loss:		0.342134
  validation loss:		0.383463
  validation accuracy:		87.50 %
Epoch 639 of 2000 took 0.103s
  training loss:		0.336288
  validation loss:		0.389539
  validation accuracy:		87.93 %
Epoch 640 of 2000 took 0.103s
  training loss:		0.341017
  validation loss:		0.391658
  validation accuracy:		87.17 %
Epoch 641 of 2000 took 0.103s
  training loss:		0.339665
  validation loss:		0.387929
  validation accuracy:		87.39 %
Epoch 642 of 2000 took 0.103s
  training loss:		0.336687
  validation loss:		0.382314
  validation accuracy:		86.85 %
Epoch 643 of 2000 took 0.103s
  training loss:		0.332163
  validation loss:		0.380345
  validation accuracy:		87.39 %
Epoch 644 of 2000 took 0.103s
  training loss:		0.335026
  validation loss:		0.386088
  validation accuracy:		86.74 %
Epoch 645 of 2000 took 0.103s
  training loss:		0.338039
  validation loss:		0.398845
  validation accuracy:		86.96 %
Epoch 646 of 2000 took 0.100s
  training loss:		0.335765
  validation loss:		0.389038
  validation accuracy:		87.72 %
Epoch 647 of 2000 took 0.099s
  training loss:		0.327471
  validation loss:		0.398713
  validation accuracy:		86.85 %
Epoch 648 of 2000 took 0.100s
  training loss:		0.331012
  validation loss:		0.404453
  validation accuracy:		86.63 %
Epoch 649 of 2000 took 0.100s
  training loss:		0.332938
  validation loss:		0.399374
  validation accuracy:		86.96 %
Epoch 650 of 2000 took 0.099s
  training loss:		0.339731
  validation loss:		0.387691
  validation accuracy:		88.15 %
Epoch 651 of 2000 took 0.100s
  training loss:		0.337769
  validation loss:		0.390696
  validation accuracy:		87.28 %
Epoch 652 of 2000 took 0.099s
  training loss:		0.322843
  validation loss:		0.383668
  validation accuracy:		87.39 %
Epoch 653 of 2000 took 0.099s
  training loss:		0.332155
  validation loss:		0.388446
  validation accuracy:		87.28 %
Epoch 654 of 2000 took 0.100s
  training loss:		0.337503
  validation loss:		0.383538
  validation accuracy:		87.07 %
Epoch 655 of 2000 took 0.099s
  training loss:		0.330646
  validation loss:		0.385615
  validation accuracy:		87.17 %
Epoch 656 of 2000 took 0.100s
  training loss:		0.344089
  validation loss:		0.385185
  validation accuracy:		87.61 %
Epoch 657 of 2000 took 0.100s
  training loss:		0.335876
  validation loss:		0.381799
  validation accuracy:		87.39 %
Epoch 658 of 2000 took 0.099s
  training loss:		0.335594
  validation loss:		0.381318
  validation accuracy:		87.83 %
Epoch 659 of 2000 took 0.101s
  training loss:		0.334294
  validation loss:		0.396271
  validation accuracy:		86.85 %
Epoch 660 of 2000 took 0.105s
  training loss:		0.334778
  validation loss:		0.384312
  validation accuracy:		87.83 %
Epoch 661 of 2000 took 0.103s
  training loss:		0.342107
  validation loss:		0.386453
  validation accuracy:		87.50 %
Epoch 662 of 2000 took 0.103s
  training loss:		0.340135
  validation loss:		0.390323
  validation accuracy:		87.28 %
Epoch 663 of 2000 took 0.103s
  training loss:		0.328530
  validation loss:		0.386413
  validation accuracy:		87.50 %
Epoch 664 of 2000 took 0.103s
  training loss:		0.327248
  validation loss:		0.401799
  validation accuracy:		86.85 %
Epoch 665 of 2000 took 0.103s
  training loss:		0.336640
  validation loss:		0.386453
  validation accuracy:		86.96 %
Epoch 666 of 2000 took 0.103s
  training loss:		0.337000
  validation loss:		0.401607
  validation accuracy:		87.28 %
Epoch 667 of 2000 took 0.103s
  training loss:		0.338670
  validation loss:		0.384923
  validation accuracy:		87.50 %
Epoch 668 of 2000 took 0.103s
  training loss:		0.336987
  validation loss:		0.396841
  validation accuracy:		87.93 %
Epoch 669 of 2000 took 0.103s
  training loss:		0.339205
  validation loss:		0.397824
  validation accuracy:		86.63 %
Epoch 670 of 2000 took 0.103s
  training loss:		0.330124
  validation loss:		0.384634
  validation accuracy:		87.72 %
Epoch 671 of 2000 took 0.103s
  training loss:		0.336112
  validation loss:		0.385644
  validation accuracy:		87.39 %
Epoch 672 of 2000 took 0.103s
  training loss:		0.325461
  validation loss:		0.383371
  validation accuracy:		87.39 %
Epoch 673 of 2000 took 0.103s
  training loss:		0.336690
  validation loss:		0.382923
  validation accuracy:		87.17 %
Epoch 674 of 2000 took 0.103s
  training loss:		0.335120
  validation loss:		0.382336
  validation accuracy:		87.83 %
Epoch 675 of 2000 took 0.103s
  training loss:		0.337541
  validation loss:		0.384638
  validation accuracy:		87.28 %
Epoch 676 of 2000 took 0.103s
  training loss:		0.337909
  validation loss:		0.393402
  validation accuracy:		87.17 %
Epoch 677 of 2000 took 0.103s
  training loss:		0.334063
  validation loss:		0.389498
  validation accuracy:		87.61 %
Epoch 678 of 2000 took 0.103s
  training loss:		0.333773
  validation loss:		0.389549
  validation accuracy:		87.39 %
Epoch 679 of 2000 took 0.103s
  training loss:		0.327493
  validation loss:		0.391097
  validation accuracy:		87.39 %
Epoch 680 of 2000 took 0.103s
  training loss:		0.329541
  validation loss:		0.387695
  validation accuracy:		86.85 %
Epoch 681 of 2000 took 0.103s
  training loss:		0.336551
  validation loss:		0.393770
  validation accuracy:		87.07 %
Epoch 682 of 2000 took 0.103s
  training loss:		0.328781
  validation loss:		0.392022
  validation accuracy:		87.72 %
Epoch 683 of 2000 took 0.103s
  training loss:		0.336052
  validation loss:		0.387093
  validation accuracy:		87.39 %
Epoch 684 of 2000 took 0.103s
  training loss:		0.326616
  validation loss:		0.386213
  validation accuracy:		87.28 %
Epoch 685 of 2000 took 0.103s
  training loss:		0.329310
  validation loss:		0.387133
  validation accuracy:		87.39 %
Epoch 686 of 2000 took 0.103s
  training loss:		0.335235
  validation loss:		0.384359
  validation accuracy:		88.04 %
Epoch 687 of 2000 took 0.103s
  training loss:		0.326506
  validation loss:		0.382301
  validation accuracy:		87.61 %
Epoch 688 of 2000 took 0.103s
  training loss:		0.333654
  validation loss:		0.381231
  validation accuracy:		87.72 %
Epoch 689 of 2000 took 0.103s
  training loss:		0.328375
  validation loss:		0.387152
  validation accuracy:		87.39 %
Epoch 690 of 2000 took 0.103s
  training loss:		0.335645
  validation loss:		0.392596
  validation accuracy:		87.07 %
Epoch 691 of 2000 took 0.103s
  training loss:		0.326461
  validation loss:		0.378490
  validation accuracy:		88.15 %
Epoch 692 of 2000 took 0.103s
  training loss:		0.327222
  validation loss:		0.384201
  validation accuracy:		87.93 %
Epoch 693 of 2000 took 0.103s
  training loss:		0.327620
  validation loss:		0.416004
  validation accuracy:		86.30 %
Epoch 694 of 2000 took 0.103s
  training loss:		0.330206
  validation loss:		0.381882
  validation accuracy:		87.61 %
Epoch 695 of 2000 took 0.103s
  training loss:		0.332307
  validation loss:		0.390142
  validation accuracy:		87.61 %
Epoch 696 of 2000 took 0.103s
  training loss:		0.326680
  validation loss:		0.391198
  validation accuracy:		87.61 %
Epoch 697 of 2000 took 0.103s
  training loss:		0.322992
  validation loss:		0.379934
  validation accuracy:		87.39 %
Epoch 698 of 2000 took 0.102s
  training loss:		0.329877
  validation loss:		0.386495
  validation accuracy:		87.39 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.329973
  validation loss:		0.383546
  validation accuracy:		88.04 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.335887
  validation loss:		0.385690
  validation accuracy:		86.96 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.327524
  validation loss:		0.401962
  validation accuracy:		87.39 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.324644
  validation loss:		0.385311
  validation accuracy:		88.04 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.326485
  validation loss:		0.380268
  validation accuracy:		87.17 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.322619
  validation loss:		0.387023
  validation accuracy:		88.26 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.324347
  validation loss:		0.380025
  validation accuracy:		88.37 %
Epoch 706 of 2000 took 0.096s
  training loss:		0.326588
  validation loss:		0.395398
  validation accuracy:		87.07 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.332928
  validation loss:		0.390677
  validation accuracy:		87.93 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.328801
  validation loss:		0.384097
  validation accuracy:		87.39 %
Epoch 709 of 2000 took 0.096s
  training loss:		0.330612
  validation loss:		0.390116
  validation accuracy:		87.28 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.333208
  validation loss:		0.405918
  validation accuracy:		86.85 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.335439
  validation loss:		0.378862
  validation accuracy:		87.93 %
Epoch 712 of 2000 took 0.096s
  training loss:		0.331520
  validation loss:		0.381597
  validation accuracy:		87.17 %
Epoch 713 of 2000 took 0.096s
  training loss:		0.336223
  validation loss:		0.385961
  validation accuracy:		86.52 %
Epoch 714 of 2000 took 0.096s
  training loss:		0.325050
  validation loss:		0.399543
  validation accuracy:		87.28 %
Epoch 715 of 2000 took 0.096s
  training loss:		0.327533
  validation loss:		0.390197
  validation accuracy:		87.39 %
Epoch 716 of 2000 took 0.096s
  training loss:		0.327353
  validation loss:		0.381962
  validation accuracy:		87.50 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.328216
  validation loss:		0.383044
  validation accuracy:		87.72 %
Epoch 718 of 2000 took 0.096s
  training loss:		0.323936
  validation loss:		0.411270
  validation accuracy:		86.96 %
Epoch 719 of 2000 took 0.096s
  training loss:		0.326928
  validation loss:		0.386896
  validation accuracy:		88.26 %
Epoch 720 of 2000 took 0.096s
  training loss:		0.313825
  validation loss:		0.390358
  validation accuracy:		87.28 %
Epoch 721 of 2000 took 0.096s
  training loss:		0.326610
  validation loss:		0.388281
  validation accuracy:		87.93 %
Epoch 722 of 2000 took 0.096s
  training loss:		0.321128
  validation loss:		0.390704
  validation accuracy:		87.50 %
Epoch 723 of 2000 took 0.096s
  training loss:		0.319324
  validation loss:		0.380501
  validation accuracy:		87.28 %
Epoch 724 of 2000 took 0.096s
  training loss:		0.321536
  validation loss:		0.380031
  validation accuracy:		88.15 %
Epoch 725 of 2000 took 0.096s
  training loss:		0.324922
  validation loss:		0.375237
  validation accuracy:		87.83 %
Epoch 726 of 2000 took 0.096s
  training loss:		0.330365
  validation loss:		0.392461
  validation accuracy:		87.39 %
Epoch 727 of 2000 took 0.096s
  training loss:		0.325052
  validation loss:		0.386162
  validation accuracy:		87.17 %
Epoch 728 of 2000 took 0.096s
  training loss:		0.324549
  validation loss:		0.378158
  validation accuracy:		87.28 %
Epoch 729 of 2000 took 0.096s
  training loss:		0.325445
  validation loss:		0.388074
  validation accuracy:		88.70 %
Epoch 730 of 2000 took 0.096s
  training loss:		0.332281
  validation loss:		0.385369
  validation accuracy:		87.50 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.331005
  validation loss:		0.395362
  validation accuracy:		87.72 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.329570
  validation loss:		0.388602
  validation accuracy:		87.39 %
Epoch 733 of 2000 took 0.097s
  training loss:		0.329011
  validation loss:		0.388266
  validation accuracy:		88.26 %
Epoch 734 of 2000 took 0.097s
  training loss:		0.333576
  validation loss:		0.385605
  validation accuracy:		87.39 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.326909
  validation loss:		0.397144
  validation accuracy:		87.39 %
Epoch 736 of 2000 took 0.097s
  training loss:		0.330404
  validation loss:		0.414691
  validation accuracy:		87.07 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.329924
  validation loss:		0.388668
  validation accuracy:		87.39 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.323625
  validation loss:		0.389366
  validation accuracy:		87.50 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.323735
  validation loss:		0.390391
  validation accuracy:		87.93 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.321886
  validation loss:		0.398185
  validation accuracy:		87.61 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.320350
  validation loss:		0.394305
  validation accuracy:		87.61 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.330568
  validation loss:		0.388909
  validation accuracy:		87.61 %
Epoch 743 of 2000 took 0.096s
  training loss:		0.335137
  validation loss:		0.392103
  validation accuracy:		87.61 %
Epoch 744 of 2000 took 0.096s
  training loss:		0.322817
  validation loss:		0.384111
  validation accuracy:		87.83 %
Epoch 745 of 2000 took 0.096s
  training loss:		0.325037
  validation loss:		0.387466
  validation accuracy:		88.26 %
Epoch 746 of 2000 took 0.096s
  training loss:		0.322452
  validation loss:		0.388714
  validation accuracy:		87.39 %
Epoch 747 of 2000 took 0.096s
  training loss:		0.324721
  validation loss:		0.379614
  validation accuracy:		88.04 %
Epoch 748 of 2000 took 0.096s
  training loss:		0.318362
  validation loss:		0.391519
  validation accuracy:		87.61 %
Epoch 749 of 2000 took 0.096s
  training loss:		0.325483
  validation loss:		0.401071
  validation accuracy:		87.83 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.314704
  validation loss:		0.393804
  validation accuracy:		86.63 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.324087
  validation loss:		0.384702
  validation accuracy:		87.72 %
Epoch 752 of 2000 took 0.096s
  training loss:		0.329689
  validation loss:		0.390186
  validation accuracy:		88.37 %
Epoch 753 of 2000 took 0.096s
  training loss:		0.324961
  validation loss:		0.386241
  validation accuracy:		87.28 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.324129
  validation loss:		0.392740
  validation accuracy:		87.17 %
Epoch 755 of 2000 took 0.096s
  training loss:		0.326678
  validation loss:		0.395720
  validation accuracy:		87.72 %
Epoch 756 of 2000 took 0.096s
  training loss:		0.319605
  validation loss:		0.381715
  validation accuracy:		87.93 %
Epoch 757 of 2000 took 0.096s
  training loss:		0.327198
  validation loss:		0.393472
  validation accuracy:		87.39 %
Epoch 758 of 2000 took 0.096s
  training loss:		0.330635
  validation loss:		0.408852
  validation accuracy:		86.96 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.324353
  validation loss:		0.381811
  validation accuracy:		87.93 %
Epoch 760 of 2000 took 0.096s
  training loss:		0.321457
  validation loss:		0.381032
  validation accuracy:		88.80 %
Epoch 761 of 2000 took 0.096s
  training loss:		0.325449
  validation loss:		0.381299
  validation accuracy:		88.04 %
Epoch 762 of 2000 took 0.097s
  training loss:		0.322812
  validation loss:		0.387730
  validation accuracy:		88.26 %
Epoch 763 of 2000 took 0.096s
  training loss:		0.317723
  validation loss:		0.399015
  validation accuracy:		87.28 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.322280
  validation loss:		0.406570
  validation accuracy:		87.17 %
Epoch 765 of 2000 took 0.096s
  training loss:		0.322540
  validation loss:		0.410942
  validation accuracy:		86.96 %
Epoch 766 of 2000 took 0.096s
  training loss:		0.322175
  validation loss:		0.378927
  validation accuracy:		87.93 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.319734
  validation loss:		0.380687
  validation accuracy:		87.83 %
Epoch 768 of 2000 took 0.096s
  training loss:		0.318448
  validation loss:		0.399693
  validation accuracy:		87.28 %
Epoch 769 of 2000 took 0.096s
  training loss:		0.321934
  validation loss:		0.407032
  validation accuracy:		87.17 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.319921
  validation loss:		0.385654
  validation accuracy:		88.04 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.323101
  validation loss:		0.378884
  validation accuracy:		88.37 %
Epoch 772 of 2000 took 0.096s
  training loss:		0.325148
  validation loss:		0.387406
  validation accuracy:		87.72 %
Epoch 773 of 2000 took 0.097s
  training loss:		0.320419
  validation loss:		0.393801
  validation accuracy:		87.83 %
Epoch 774 of 2000 took 0.096s
  training loss:		0.328734
  validation loss:		0.382786
  validation accuracy:		87.93 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.320168
  validation loss:		0.403537
  validation accuracy:		87.50 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.325181
  validation loss:		0.390548
  validation accuracy:		87.61 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.313328
  validation loss:		0.382442
  validation accuracy:		88.15 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.308525
  validation loss:		0.381865
  validation accuracy:		87.83 %
Epoch 779 of 2000 took 0.097s
  training loss:		0.320277
  validation loss:		0.423685
  validation accuracy:		86.74 %
Epoch 780 of 2000 took 0.096s
  training loss:		0.317210
  validation loss:		0.399229
  validation accuracy:		87.83 %
Epoch 781 of 2000 took 0.097s
  training loss:		0.323503
  validation loss:		0.384904
  validation accuracy:		87.61 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.312133
  validation loss:		0.401510
  validation accuracy:		87.83 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.327739
  validation loss:		0.402577
  validation accuracy:		87.39 %
Epoch 784 of 2000 took 0.096s
  training loss:		0.315830
  validation loss:		0.394574
  validation accuracy:		87.28 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.324186
  validation loss:		0.383016
  validation accuracy:		88.15 %
Epoch 786 of 2000 took 0.096s
  training loss:		0.317018
  validation loss:		0.383826
  validation accuracy:		87.72 %
Epoch 787 of 2000 took 0.096s
  training loss:		0.321563
  validation loss:		0.387116
  validation accuracy:		87.28 %
Epoch 788 of 2000 took 0.096s
  training loss:		0.314162
  validation loss:		0.399263
  validation accuracy:		87.39 %
Epoch 789 of 2000 took 0.096s
  training loss:		0.323819
  validation loss:		0.388175
  validation accuracy:		88.04 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.320566
  validation loss:		0.388515
  validation accuracy:		87.72 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.316143
  validation loss:		0.396746
  validation accuracy:		87.83 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.313440
  validation loss:		0.388386
  validation accuracy:		87.50 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.316712
  validation loss:		0.379556
  validation accuracy:		88.37 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.313751
  validation loss:		0.408736
  validation accuracy:		87.50 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.318025
  validation loss:		0.387528
  validation accuracy:		87.72 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.318811
  validation loss:		0.395075
  validation accuracy:		87.61 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.317369
  validation loss:		0.395359
  validation accuracy:		87.93 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.317008
  validation loss:		0.380347
  validation accuracy:		87.93 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.318807
  validation loss:		0.377055
  validation accuracy:		87.93 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.319190
  validation loss:		0.415383
  validation accuracy:		87.83 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.321055
  validation loss:		0.389407
  validation accuracy:		87.50 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.314853
  validation loss:		0.398081
  validation accuracy:		87.72 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.317002
  validation loss:		0.410659
  validation accuracy:		87.39 %
Epoch 804 of 2000 took 0.097s
  training loss:		0.311439
  validation loss:		0.404627
  validation accuracy:		87.28 %
Epoch 805 of 2000 took 0.096s
  training loss:		0.310394
  validation loss:		0.394546
  validation accuracy:		87.83 %
Epoch 806 of 2000 took 0.096s
  training loss:		0.307572
  validation loss:		0.390924
  validation accuracy:		87.93 %
Epoch 807 of 2000 took 0.096s
  training loss:		0.308317
  validation loss:		0.388761
  validation accuracy:		87.72 %
Epoch 808 of 2000 took 0.096s
  training loss:		0.312234
  validation loss:		0.378748
  validation accuracy:		87.93 %
Epoch 809 of 2000 took 0.096s
  training loss:		0.324727
  validation loss:		0.406798
  validation accuracy:		87.72 %
Epoch 810 of 2000 took 0.096s
  training loss:		0.317107
  validation loss:		0.393305
  validation accuracy:		87.93 %
Epoch 811 of 2000 took 0.096s
  training loss:		0.317932
  validation loss:		0.382130
  validation accuracy:		88.15 %
Epoch 812 of 2000 took 0.096s
  training loss:		0.316398
  validation loss:		0.387104
  validation accuracy:		87.83 %
Epoch 813 of 2000 took 0.096s
  training loss:		0.316220
  validation loss:		0.391451
  validation accuracy:		87.93 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.316611
  validation loss:		0.396060
  validation accuracy:		87.72 %
Epoch 815 of 2000 took 0.096s
  training loss:		0.319446
  validation loss:		0.388527
  validation accuracy:		88.04 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.316475
  validation loss:		0.385737
  validation accuracy:		87.83 %
Epoch 817 of 2000 took 0.096s
  training loss:		0.314339
  validation loss:		0.383040
  validation accuracy:		87.50 %
Epoch 818 of 2000 took 0.096s
  training loss:		0.316681
  validation loss:		0.380323
  validation accuracy:		88.15 %
Epoch 819 of 2000 took 0.096s
  training loss:		0.309753
  validation loss:		0.394608
  validation accuracy:		88.15 %
Epoch 820 of 2000 took 0.096s
  training loss:		0.321298
  validation loss:		0.391038
  validation accuracy:		87.83 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.310144
  validation loss:		0.391552
  validation accuracy:		87.93 %
Epoch 822 of 2000 took 0.096s
  training loss:		0.319027
  validation loss:		0.414676
  validation accuracy:		87.50 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.324209
  validation loss:		0.396330
  validation accuracy:		87.28 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.315366
  validation loss:		0.410544
  validation accuracy:		87.28 %
Epoch 825 of 2000 took 0.096s
  training loss:		0.306936
  validation loss:		0.395736
  validation accuracy:		87.50 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.312208
  validation loss:		0.383843
  validation accuracy:		87.61 %
Epoch 827 of 2000 took 0.096s
  training loss:		0.318111
  validation loss:		0.390552
  validation accuracy:		87.83 %
Epoch 828 of 2000 took 0.096s
  training loss:		0.319105
  validation loss:		0.388282
  validation accuracy:		88.37 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.309768
  validation loss:		0.399736
  validation accuracy:		87.61 %
Epoch 830 of 2000 took 0.096s
  training loss:		0.307685
  validation loss:		0.397166
  validation accuracy:		87.83 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.312842
  validation loss:		0.380076
  validation accuracy:		88.04 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.313412
  validation loss:		0.383205
  validation accuracy:		88.26 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.310242
  validation loss:		0.390985
  validation accuracy:		87.61 %
Epoch 834 of 2000 took 0.096s
  training loss:		0.309731
  validation loss:		0.391366
  validation accuracy:		87.83 %
Epoch 835 of 2000 took 0.096s
  training loss:		0.311090
  validation loss:		0.382465
  validation accuracy:		87.83 %
Epoch 836 of 2000 took 0.096s
  training loss:		0.312811
  validation loss:		0.432738
  validation accuracy:		86.30 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.318858
  validation loss:		0.408075
  validation accuracy:		87.17 %
Epoch 838 of 2000 took 0.096s
  training loss:		0.308028
  validation loss:		0.395105
  validation accuracy:		87.39 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.304389
  validation loss:		0.378059
  validation accuracy:		87.83 %
Epoch 840 of 2000 took 0.096s
  training loss:		0.303521
  validation loss:		0.389342
  validation accuracy:		88.04 %
Epoch 841 of 2000 took 0.096s
  training loss:		0.319328
  validation loss:		0.400635
  validation accuracy:		87.83 %
Epoch 842 of 2000 took 0.096s
  training loss:		0.302642
  validation loss:		0.397085
  validation accuracy:		87.93 %
Epoch 843 of 2000 took 0.096s
  training loss:		0.308183
  validation loss:		0.389833
  validation accuracy:		88.26 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.314062
  validation loss:		0.384601
  validation accuracy:		87.72 %
Epoch 845 of 2000 took 0.096s
  training loss:		0.313893
  validation loss:		0.391755
  validation accuracy:		87.61 %
Epoch 846 of 2000 took 0.096s
  training loss:		0.314250
  validation loss:		0.385149
  validation accuracy:		87.72 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.310530
  validation loss:		0.389577
  validation accuracy:		87.83 %
Epoch 848 of 2000 took 0.096s
  training loss:		0.304977
  validation loss:		0.379849
  validation accuracy:		88.15 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.308251
  validation loss:		0.402641
  validation accuracy:		87.50 %
Epoch 850 of 2000 took 0.096s
  training loss:		0.314416
  validation loss:		0.390390
  validation accuracy:		87.83 %
Epoch 851 of 2000 took 0.096s
  training loss:		0.309706
  validation loss:		0.389083
  validation accuracy:		87.93 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.312679
  validation loss:		0.403859
  validation accuracy:		87.28 %
Epoch 853 of 2000 took 0.096s
  training loss:		0.306532
  validation loss:		0.383266
  validation accuracy:		87.72 %
Epoch 854 of 2000 took 0.096s
  training loss:		0.311270
  validation loss:		0.396956
  validation accuracy:		87.93 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.311998
  validation loss:		0.391827
  validation accuracy:		87.72 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.311581
  validation loss:		0.387309
  validation accuracy:		88.04 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.307150
  validation loss:		0.400036
  validation accuracy:		88.26 %
Epoch 858 of 2000 took 0.096s
  training loss:		0.310863
  validation loss:		0.388821
  validation accuracy:		87.83 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.315678
  validation loss:		0.398273
  validation accuracy:		87.39 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.312451
  validation loss:		0.399405
  validation accuracy:		87.83 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.312984
  validation loss:		0.387935
  validation accuracy:		88.26 %
Epoch 862 of 2000 took 0.096s
  training loss:		0.306047
  validation loss:		0.385345
  validation accuracy:		88.37 %
Epoch 863 of 2000 took 0.099s
  training loss:		0.312400
  validation loss:		0.391145
  validation accuracy:		88.48 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.313503
  validation loss:		0.398859
  validation accuracy:		88.04 %
Epoch 865 of 2000 took 0.096s
  training loss:		0.312181
  validation loss:		0.382778
  validation accuracy:		88.48 %
Epoch 866 of 2000 took 0.096s
  training loss:		0.307720
  validation loss:		0.434823
  validation accuracy:		86.96 %
Epoch 867 of 2000 took 0.096s
  training loss:		0.312784
  validation loss:		0.391706
  validation accuracy:		87.83 %
Epoch 868 of 2000 took 0.096s
  training loss:		0.311390
  validation loss:		0.387571
  validation accuracy:		88.26 %
Epoch 869 of 2000 took 0.096s
  training loss:		0.308825
  validation loss:		0.387312
  validation accuracy:		88.04 %
Epoch 870 of 2000 took 0.096s
  training loss:		0.308268
  validation loss:		0.387900
  validation accuracy:		87.93 %
Epoch 871 of 2000 took 0.096s
  training loss:		0.313360
  validation loss:		0.389335
  validation accuracy:		87.83 %
Epoch 872 of 2000 took 0.096s
  training loss:		0.306115
  validation loss:		0.388724
  validation accuracy:		87.93 %
Epoch 873 of 2000 took 0.096s
  training loss:		0.311205
  validation loss:		0.415936
  validation accuracy:		87.50 %
Epoch 874 of 2000 took 0.096s
  training loss:		0.311509
  validation loss:		0.391095
  validation accuracy:		88.15 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.308457
  validation loss:		0.389352
  validation accuracy:		87.83 %
Epoch 876 of 2000 took 0.096s
  training loss:		0.306173
  validation loss:		0.398886
  validation accuracy:		88.04 %
Epoch 877 of 2000 took 0.096s
  training loss:		0.311348
  validation loss:		0.391383
  validation accuracy:		87.83 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.310841
  validation loss:		0.400099
  validation accuracy:		87.72 %
Epoch 879 of 2000 took 0.096s
  training loss:		0.308898
  validation loss:		0.388830
  validation accuracy:		88.37 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.304737
  validation loss:		0.385711
  validation accuracy:		87.93 %
Epoch 881 of 2000 took 0.096s
  training loss:		0.312777
  validation loss:		0.381742
  validation accuracy:		88.15 %
Epoch 882 of 2000 took 0.096s
  training loss:		0.314245
  validation loss:		0.400137
  validation accuracy:		87.50 %
Epoch 883 of 2000 took 0.097s
  training loss:		0.312732
  validation loss:		0.414279
  validation accuracy:		87.72 %
Epoch 884 of 2000 took 0.096s
  training loss:		0.312328
  validation loss:		0.390532
  validation accuracy:		87.61 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.307515
  validation loss:		0.390163
  validation accuracy:		87.83 %
Epoch 886 of 2000 took 0.096s
  training loss:		0.302448
  validation loss:		0.389451
  validation accuracy:		88.15 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.308503
  validation loss:		0.383067
  validation accuracy:		88.48 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.308563
  validation loss:		0.400145
  validation accuracy:		87.83 %
Epoch 889 of 2000 took 0.096s
  training loss:		0.305229
  validation loss:		0.392432
  validation accuracy:		88.26 %
Epoch 890 of 2000 took 0.096s
  training loss:		0.305262
  validation loss:		0.380442
  validation accuracy:		87.83 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.305879
  validation loss:		0.407423
  validation accuracy:		87.28 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.311175
  validation loss:		0.408737
  validation accuracy:		87.07 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.303316
  validation loss:		0.392628
  validation accuracy:		87.93 %
Epoch 894 of 2000 took 0.096s
  training loss:		0.305388
  validation loss:		0.394310
  validation accuracy:		87.50 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.317024
  validation loss:		0.387796
  validation accuracy:		87.93 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.301671
  validation loss:		0.391443
  validation accuracy:		88.15 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.310778
  validation loss:		0.388499
  validation accuracy:		88.04 %
Epoch 898 of 2000 took 0.096s
  training loss:		0.309917
  validation loss:		0.388237
  validation accuracy:		88.04 %
Epoch 899 of 2000 took 0.096s
  training loss:		0.308445
  validation loss:		0.393657
  validation accuracy:		88.48 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.308756
  validation loss:		0.382944
  validation accuracy:		88.26 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.305449
  validation loss:		0.387141
  validation accuracy:		88.37 %
Epoch 902 of 2000 took 0.096s
  training loss:		0.310391
  validation loss:		0.403260
  validation accuracy:		88.59 %
Epoch 903 of 2000 took 0.096s
  training loss:		0.307716
  validation loss:		0.403571
  validation accuracy:		87.39 %
Epoch 904 of 2000 took 0.096s
  training loss:		0.312504
  validation loss:		0.388329
  validation accuracy:		88.26 %
Epoch 905 of 2000 took 0.096s
  training loss:		0.308072
  validation loss:		0.405149
  validation accuracy:		87.72 %
Epoch 906 of 2000 took 0.097s
  training loss:		0.313133
  validation loss:		0.382699
  validation accuracy:		88.15 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.301755
  validation loss:		0.390505
  validation accuracy:		88.04 %
Epoch 908 of 2000 took 0.096s
  training loss:		0.302587
  validation loss:		0.378672
  validation accuracy:		88.37 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.303314
  validation loss:		0.383936
  validation accuracy:		88.15 %
Epoch 910 of 2000 took 0.096s
  training loss:		0.304481
  validation loss:		0.391193
  validation accuracy:		87.93 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.299222
  validation loss:		0.402834
  validation accuracy:		88.15 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.308029
  validation loss:		0.385147
  validation accuracy:		88.26 %
Epoch 913 of 2000 took 0.096s
  training loss:		0.305729
  validation loss:		0.382421
  validation accuracy:		88.15 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.310635
  validation loss:		0.401441
  validation accuracy:		88.15 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.305727
  validation loss:		0.380703
  validation accuracy:		88.26 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.306739
  validation loss:		0.392832
  validation accuracy:		87.72 %
Epoch 917 of 2000 took 0.096s
  training loss:		0.300286
  validation loss:		0.395134
  validation accuracy:		88.37 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.303852
  validation loss:		0.383118
  validation accuracy:		88.37 %
Epoch 919 of 2000 took 0.096s
  training loss:		0.301247
  validation loss:		0.396712
  validation accuracy:		88.48 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.300764
  validation loss:		0.382410
  validation accuracy:		88.15 %
Epoch 921 of 2000 took 0.096s
  training loss:		0.306458
  validation loss:		0.378641
  validation accuracy:		88.48 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.306883
  validation loss:		0.386320
  validation accuracy:		87.72 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.305752
  validation loss:		0.380358
  validation accuracy:		88.48 %
Epoch 924 of 2000 took 0.096s
  training loss:		0.310662
  validation loss:		0.392957
  validation accuracy:		87.83 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.300689
  validation loss:		0.395349
  validation accuracy:		87.93 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.302211
  validation loss:		0.391743
  validation accuracy:		87.83 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.296951
  validation loss:		0.380646
  validation accuracy:		88.15 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.300610
  validation loss:		0.387004
  validation accuracy:		88.04 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.300626
  validation loss:		0.409945
  validation accuracy:		87.61 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.307041
  validation loss:		0.424816
  validation accuracy:		87.17 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.300005
  validation loss:		0.403465
  validation accuracy:		87.50 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.297037
  validation loss:		0.384197
  validation accuracy:		88.37 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.303810
  validation loss:		0.392414
  validation accuracy:		88.48 %
Epoch 934 of 2000 took 0.096s
  training loss:		0.295776
  validation loss:		0.441691
  validation accuracy:		86.30 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.305302
  validation loss:		0.403750
  validation accuracy:		87.50 %
Epoch 936 of 2000 took 0.096s
  training loss:		0.298452
  validation loss:		0.388791
  validation accuracy:		88.15 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.297323
  validation loss:		0.382453
  validation accuracy:		88.15 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.307041
  validation loss:		0.391351
  validation accuracy:		88.26 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.299018
  validation loss:		0.389058
  validation accuracy:		88.37 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.293764
  validation loss:		0.381572
  validation accuracy:		87.93 %
Epoch 941 of 2000 took 0.096s
  training loss:		0.302527
  validation loss:		0.385285
  validation accuracy:		87.93 %
Epoch 942 of 2000 took 0.096s
  training loss:		0.303606
  validation loss:		0.400278
  validation accuracy:		87.50 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.301223
  validation loss:		0.377009
  validation accuracy:		88.26 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.309981
  validation loss:		0.392697
  validation accuracy:		88.37 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.309127
  validation loss:		0.382730
  validation accuracy:		88.48 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.307723
  validation loss:		0.388025
  validation accuracy:		88.15 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.304328
  validation loss:		0.398565
  validation accuracy:		87.93 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.304969
  validation loss:		0.397625
  validation accuracy:		88.15 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.302126
  validation loss:		0.396172
  validation accuracy:		88.04 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.293381
  validation loss:		0.400313
  validation accuracy:		87.83 %
Epoch 951 of 2000 took 0.096s
  training loss:		0.300249
  validation loss:		0.389622
  validation accuracy:		88.37 %
Epoch 952 of 2000 took 0.096s
  training loss:		0.303834
  validation loss:		0.390277
  validation accuracy:		88.04 %
Epoch 953 of 2000 took 0.096s
  training loss:		0.302205
  validation loss:		0.394218
  validation accuracy:		87.83 %
Epoch 954 of 2000 took 0.096s
  training loss:		0.302349
  validation loss:		0.397989
  validation accuracy:		87.61 %
Epoch 955 of 2000 took 0.096s
  training loss:		0.300792
  validation loss:		0.399076
  validation accuracy:		88.04 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.295567
  validation loss:		0.383224
  validation accuracy:		88.37 %
Epoch 957 of 2000 took 0.096s
  training loss:		0.307368
  validation loss:		0.377927
  validation accuracy:		88.48 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.300527
  validation loss:		0.399315
  validation accuracy:		87.61 %
Epoch 959 of 2000 took 0.096s
  training loss:		0.308901
  validation loss:		0.383205
  validation accuracy:		87.93 %
Epoch 960 of 2000 took 0.096s
  training loss:		0.306681
  validation loss:		0.395215
  validation accuracy:		88.37 %
Epoch 961 of 2000 took 0.096s
  training loss:		0.302997
  validation loss:		0.408812
  validation accuracy:		87.50 %
Epoch 962 of 2000 took 0.096s
  training loss:		0.308848
  validation loss:		0.398809
  validation accuracy:		87.83 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.299742
  validation loss:		0.384631
  validation accuracy:		88.26 %
Epoch 964 of 2000 took 0.096s
  training loss:		0.299233
  validation loss:		0.388061
  validation accuracy:		88.37 %
Epoch 965 of 2000 took 0.096s
  training loss:		0.296656
  validation loss:		0.389238
  validation accuracy:		87.93 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.299982
  validation loss:		0.392567
  validation accuracy:		87.93 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.297599
  validation loss:		0.383541
  validation accuracy:		88.37 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.299739
  validation loss:		0.376850
  validation accuracy:		88.37 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.293914
  validation loss:		0.380925
  validation accuracy:		88.37 %
Epoch 970 of 2000 took 0.096s
  training loss:		0.294831
  validation loss:		0.395771
  validation accuracy:		87.72 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.303529
  validation loss:		0.411772
  validation accuracy:		88.37 %
Epoch 972 of 2000 took 0.096s
  training loss:		0.289809
  validation loss:		0.400907
  validation accuracy:		87.39 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.297598
  validation loss:		0.400967
  validation accuracy:		87.93 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.305568
  validation loss:		0.393284
  validation accuracy:		88.48 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.301351
  validation loss:		0.402622
  validation accuracy:		88.04 %
Epoch 976 of 2000 took 0.096s
  training loss:		0.307300
  validation loss:		0.381135
  validation accuracy:		88.26 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.299760
  validation loss:		0.394273
  validation accuracy:		88.04 %
Epoch 978 of 2000 took 0.096s
  training loss:		0.298367
  validation loss:		0.396703
  validation accuracy:		88.37 %
Epoch 979 of 2000 took 0.096s
  training loss:		0.300605
  validation loss:		0.380775
  validation accuracy:		88.04 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.301346
  validation loss:		0.405036
  validation accuracy:		88.15 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.308411
  validation loss:		0.389590
  validation accuracy:		88.04 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.304581
  validation loss:		0.418600
  validation accuracy:		87.17 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.298153
  validation loss:		0.388088
  validation accuracy:		88.04 %
Epoch 984 of 2000 took 0.096s
  training loss:		0.295800
  validation loss:		0.388790
  validation accuracy:		88.26 %
Epoch 985 of 2000 took 0.096s
  training loss:		0.297555
  validation loss:		0.393642
  validation accuracy:		87.61 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.294207
  validation loss:		0.399566
  validation accuracy:		88.15 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.296820
  validation loss:		0.396252
  validation accuracy:		88.26 %
Epoch 988 of 2000 took 0.096s
  training loss:		0.298445
  validation loss:		0.400658
  validation accuracy:		87.28 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.303677
  validation loss:		0.396588
  validation accuracy:		87.83 %
Epoch 990 of 2000 took 0.096s
  training loss:		0.296563
  validation loss:		0.387406
  validation accuracy:		88.26 %
Epoch 991 of 2000 took 0.096s
  training loss:		0.299367
  validation loss:		0.385645
  validation accuracy:		88.15 %
Epoch 992 of 2000 took 0.096s
  training loss:		0.299415
  validation loss:		0.401254
  validation accuracy:		87.39 %
Epoch 993 of 2000 took 0.096s
  training loss:		0.308637
  validation loss:		0.404433
  validation accuracy:		87.93 %
Epoch 994 of 2000 took 0.096s
  training loss:		0.294827
  validation loss:		0.391676
  validation accuracy:		88.04 %
Epoch 995 of 2000 took 0.096s
  training loss:		0.295358
  validation loss:		0.384130
  validation accuracy:		88.15 %
Epoch 996 of 2000 took 0.096s
  training loss:		0.301089
  validation loss:		0.408664
  validation accuracy:		87.61 %
Epoch 997 of 2000 took 0.096s
  training loss:		0.294676
  validation loss:		0.397914
  validation accuracy:		87.28 %
Epoch 998 of 2000 took 0.096s
  training loss:		0.304251
  validation loss:		0.386921
  validation accuracy:		88.26 %
Epoch 999 of 2000 took 0.096s
  training loss:		0.304920
  validation loss:		0.398846
  validation accuracy:		87.83 %
Epoch 1000 of 2000 took 0.096s
  training loss:		0.299180
  validation loss:		0.404740
  validation accuracy:		87.39 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.299218
  validation loss:		0.395858
  validation accuracy:		87.72 %
Epoch 1002 of 2000 took 0.096s
  training loss:		0.298555
  validation loss:		0.390409
  validation accuracy:		88.15 %
Epoch 1003 of 2000 took 0.096s
  training loss:		0.291987
  validation loss:		0.393679
  validation accuracy:		88.26 %
Epoch 1004 of 2000 took 0.096s
  training loss:		0.299198
  validation loss:		0.414903
  validation accuracy:		87.28 %
Epoch 1005 of 2000 took 0.096s
  training loss:		0.301957
  validation loss:		0.397665
  validation accuracy:		87.50 %
Epoch 1006 of 2000 took 0.096s
  training loss:		0.294648
  validation loss:		0.386820
  validation accuracy:		88.26 %
Epoch 1007 of 2000 took 0.096s
  training loss:		0.300628
  validation loss:		0.414849
  validation accuracy:		87.07 %
Epoch 1008 of 2000 took 0.096s
  training loss:		0.303361
  validation loss:		0.391880
  validation accuracy:		87.93 %
Epoch 1009 of 2000 took 0.096s
  training loss:		0.301421
  validation loss:		0.384492
  validation accuracy:		87.93 %
Epoch 1010 of 2000 took 0.096s
  training loss:		0.296610
  validation loss:		0.377185
  validation accuracy:		88.26 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.295363
  validation loss:		0.378963
  validation accuracy:		88.15 %
Epoch 1012 of 2000 took 0.096s
  training loss:		0.294531
  validation loss:		0.384468
  validation accuracy:		88.48 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.293044
  validation loss:		0.383296
  validation accuracy:		88.48 %
Epoch 1014 of 2000 took 0.096s
  training loss:		0.297132
  validation loss:		0.387121
  validation accuracy:		88.37 %
Epoch 1015 of 2000 took 0.096s
  training loss:		0.302652
  validation loss:		0.378222
  validation accuracy:		88.37 %
Epoch 1016 of 2000 took 0.096s
  training loss:		0.300133
  validation loss:		0.395036
  validation accuracy:		88.04 %
Epoch 1017 of 2000 took 0.096s
  training loss:		0.302521
  validation loss:		0.384815
  validation accuracy:		88.80 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.293749
  validation loss:		0.390949
  validation accuracy:		88.15 %
Epoch 1019 of 2000 took 0.096s
  training loss:		0.296318
  validation loss:		0.390653
  validation accuracy:		88.15 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.304103
  validation loss:		0.382968
  validation accuracy:		88.70 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.300305
  validation loss:		0.387341
  validation accuracy:		87.72 %
Epoch 1022 of 2000 took 0.097s
  training loss:		0.294492
  validation loss:		0.397129
  validation accuracy:		87.28 %
Epoch 1023 of 2000 took 0.096s
  training loss:		0.299308
  validation loss:		0.374576
  validation accuracy:		88.48 %
Epoch 1024 of 2000 took 0.096s
  training loss:		0.296394
  validation loss:		0.385855
  validation accuracy:		88.04 %
Epoch 1025 of 2000 took 0.096s
  training loss:		0.294525
  validation loss:		0.391374
  validation accuracy:		88.04 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.290600
  validation loss:		0.400302
  validation accuracy:		87.93 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.295069
  validation loss:		0.409000
  validation accuracy:		87.39 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.295831
  validation loss:		0.404368
  validation accuracy:		87.39 %
Epoch 1029 of 2000 took 0.096s
  training loss:		0.300157
  validation loss:		0.393594
  validation accuracy:		88.04 %
Epoch 1030 of 2000 took 0.100s
  training loss:		0.285321
  validation loss:		0.386621
  validation accuracy:		88.37 %
Epoch 1031 of 2000 took 0.100s
  training loss:		0.302002
  validation loss:		0.393729
  validation accuracy:		87.50 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.297541
  validation loss:		0.404272
  validation accuracy:		87.39 %
Epoch 1033 of 2000 took 0.099s
  training loss:		0.296033
  validation loss:		0.385351
  validation accuracy:		88.48 %
Epoch 1034 of 2000 took 0.099s
  training loss:		0.298290
  validation loss:		0.386614
  validation accuracy:		88.48 %
Epoch 1035 of 2000 took 0.099s
  training loss:		0.294894
  validation loss:		0.397660
  validation accuracy:		87.83 %
Epoch 1036 of 2000 took 0.099s
  training loss:		0.297449
  validation loss:		0.375638
  validation accuracy:		88.48 %
Epoch 1037 of 2000 took 0.099s
  training loss:		0.295515
  validation loss:		0.377988
  validation accuracy:		88.48 %
Epoch 1038 of 2000 took 0.099s
  training loss:		0.299067
  validation loss:		0.419850
  validation accuracy:		86.85 %
Epoch 1039 of 2000 took 0.099s
  training loss:		0.303031
  validation loss:		0.382807
  validation accuracy:		88.70 %
Epoch 1040 of 2000 took 0.099s
  training loss:		0.298956
  validation loss:		0.379277
  validation accuracy:		88.15 %
Epoch 1041 of 2000 took 0.099s
  training loss:		0.298481
  validation loss:		0.394013
  validation accuracy:		87.28 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.295935
  validation loss:		0.392049
  validation accuracy:		88.04 %
Epoch 1043 of 2000 took 0.099s
  training loss:		0.293947
  validation loss:		0.398472
  validation accuracy:		87.83 %
Epoch 1044 of 2000 took 0.099s
  training loss:		0.298290
  validation loss:		0.402534
  validation accuracy:		88.15 %
Epoch 1045 of 2000 took 0.099s
  training loss:		0.303589
  validation loss:		0.394518
  validation accuracy:		88.26 %
Epoch 1046 of 2000 took 0.099s
  training loss:		0.293915
  validation loss:		0.391480
  validation accuracy:		87.93 %
Epoch 1047 of 2000 took 0.099s
  training loss:		0.292284
  validation loss:		0.376315
  validation accuracy:		89.13 %
Epoch 1048 of 2000 took 0.099s
  training loss:		0.290840
  validation loss:		0.390790
  validation accuracy:		87.93 %
Epoch 1049 of 2000 took 0.099s
  training loss:		0.301272
  validation loss:		0.376210
  validation accuracy:		88.80 %
Epoch 1050 of 2000 took 0.099s
  training loss:		0.292586
  validation loss:		0.393322
  validation accuracy:		88.15 %
Epoch 1051 of 2000 took 0.100s
  training loss:		0.296571
  validation loss:		0.392900
  validation accuracy:		88.15 %
Epoch 1052 of 2000 took 0.100s
  training loss:		0.291344
  validation loss:		0.389170
  validation accuracy:		88.26 %
Epoch 1053 of 2000 took 0.099s
  training loss:		0.292726
  validation loss:		0.381692
  validation accuracy:		88.15 %
Epoch 1054 of 2000 took 0.099s
  training loss:		0.290503
  validation loss:		0.398347
  validation accuracy:		87.07 %
Epoch 1055 of 2000 took 0.099s
  training loss:		0.293189
  validation loss:		0.388692
  validation accuracy:		88.26 %
Epoch 1056 of 2000 took 0.099s
  training loss:		0.298679
  validation loss:		0.386528
  validation accuracy:		88.59 %
Epoch 1057 of 2000 took 0.099s
  training loss:		0.295475
  validation loss:		0.383688
  validation accuracy:		88.91 %
Epoch 1058 of 2000 took 0.099s
  training loss:		0.292171
  validation loss:		0.385028
  validation accuracy:		88.80 %
Epoch 1059 of 2000 took 0.099s
  training loss:		0.289745
  validation loss:		0.391669
  validation accuracy:		88.26 %
Epoch 1060 of 2000 took 0.099s
  training loss:		0.290107
  validation loss:		0.372658
  validation accuracy:		89.02 %
Epoch 1061 of 2000 took 0.099s
  training loss:		0.293230
  validation loss:		0.394428
  validation accuracy:		88.04 %
Epoch 1062 of 2000 took 0.100s
  training loss:		0.296917
  validation loss:		0.396559
  validation accuracy:		87.83 %
Epoch 1063 of 2000 took 0.099s
  training loss:		0.305848
  validation loss:		0.407936
  validation accuracy:		88.04 %
Epoch 1064 of 2000 took 0.099s
  training loss:		0.301550
  validation loss:		0.386796
  validation accuracy:		88.59 %
Epoch 1065 of 2000 took 0.100s
  training loss:		0.303160
  validation loss:		0.382728
  validation accuracy:		88.04 %
Epoch 1066 of 2000 took 0.099s
  training loss:		0.293986
  validation loss:		0.381437
  validation accuracy:		88.48 %
Epoch 1067 of 2000 took 0.100s
  training loss:		0.298393
  validation loss:		0.372214
  validation accuracy:		88.59 %
Epoch 1068 of 2000 took 0.099s
  training loss:		0.296056
  validation loss:		0.397184
  validation accuracy:		87.83 %
Epoch 1069 of 2000 took 0.099s
  training loss:		0.291484
  validation loss:		0.397933
  validation accuracy:		87.50 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.308505
  validation loss:		0.390961
  validation accuracy:		88.37 %
Epoch 1071 of 2000 took 0.096s
  training loss:		0.298240
  validation loss:		0.388989
  validation accuracy:		88.37 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.295324
  validation loss:		0.421551
  validation accuracy:		87.72 %
Epoch 1073 of 2000 took 0.096s
  training loss:		0.294671
  validation loss:		0.381077
  validation accuracy:		88.37 %
Epoch 1074 of 2000 took 0.096s
  training loss:		0.299336
  validation loss:		0.374852
  validation accuracy:		88.70 %
Epoch 1075 of 2000 took 0.096s
  training loss:		0.301980
  validation loss:		0.399732
  validation accuracy:		87.83 %
Epoch 1076 of 2000 took 0.096s
  training loss:		0.289448
  validation loss:		0.378589
  validation accuracy:		88.70 %
Epoch 1077 of 2000 took 0.096s
  training loss:		0.290720
  validation loss:		0.409948
  validation accuracy:		87.39 %
Epoch 1078 of 2000 took 0.096s
  training loss:		0.299904
  validation loss:		0.375955
  validation accuracy:		88.70 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.294892
  validation loss:		0.390611
  validation accuracy:		87.83 %
Epoch 1080 of 2000 took 0.096s
  training loss:		0.294431
  validation loss:		0.397487
  validation accuracy:		88.04 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.291888
  validation loss:		0.396122
  validation accuracy:		87.72 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.297536
  validation loss:		0.379225
  validation accuracy:		88.48 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.292146
  validation loss:		0.395943
  validation accuracy:		87.83 %
Epoch 1084 of 2000 took 0.096s
  training loss:		0.294100
  validation loss:		0.387798
  validation accuracy:		88.15 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.302239
  validation loss:		0.374359
  validation accuracy:		88.70 %
Epoch 1086 of 2000 took 0.096s
  training loss:		0.296203
  validation loss:		0.377501
  validation accuracy:		88.37 %
Epoch 1087 of 2000 took 0.096s
  training loss:		0.298698
  validation loss:		0.391077
  validation accuracy:		87.61 %
Epoch 1088 of 2000 took 0.096s
  training loss:		0.294676
  validation loss:		0.381528
  validation accuracy:		88.37 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.293483
  validation loss:		0.377569
  validation accuracy:		88.26 %
Epoch 1090 of 2000 took 0.096s
  training loss:		0.291862
  validation loss:		0.380607
  validation accuracy:		88.26 %
Epoch 1091 of 2000 took 0.096s
  training loss:		0.289689
  validation loss:		0.376372
  validation accuracy:		88.59 %
Epoch 1092 of 2000 took 0.096s
  training loss:		0.290217
  validation loss:		0.383918
  validation accuracy:		88.37 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.292096
  validation loss:		0.395420
  validation accuracy:		87.83 %
Epoch 1094 of 2000 took 0.096s
  training loss:		0.290713
  validation loss:		0.389532
  validation accuracy:		88.15 %
Epoch 1095 of 2000 took 0.096s
  training loss:		0.293547
  validation loss:		0.375640
  validation accuracy:		88.59 %
Epoch 1096 of 2000 took 0.096s
  training loss:		0.294348
  validation loss:		0.386804
  validation accuracy:		88.15 %
Epoch 1097 of 2000 took 0.096s
  training loss:		0.297550
  validation loss:		0.397386
  validation accuracy:		87.50 %
Epoch 1098 of 2000 took 0.101s
  training loss:		0.298402
  validation loss:		0.392068
  validation accuracy:		87.61 %
Epoch 1099 of 2000 took 0.103s
  training loss:		0.296527
  validation loss:		0.393883
  validation accuracy:		86.96 %
Epoch 1100 of 2000 took 0.103s
  training loss:		0.296564
  validation loss:		0.390379
  validation accuracy:		87.61 %
Epoch 1101 of 2000 took 0.103s
  training loss:		0.295907
  validation loss:		0.394022
  validation accuracy:		87.83 %
Epoch 1102 of 2000 took 0.103s
  training loss:		0.293141
  validation loss:		0.382410
  validation accuracy:		88.15 %
Epoch 1103 of 2000 took 0.100s
  training loss:		0.290517
  validation loss:		0.378666
  validation accuracy:		88.37 %
Epoch 1104 of 2000 took 0.096s
  training loss:		0.297179
  validation loss:		0.380352
  validation accuracy:		88.04 %
Epoch 1105 of 2000 took 0.096s
  training loss:		0.293694
  validation loss:		0.376905
  validation accuracy:		88.48 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.291709
  validation loss:		0.391879
  validation accuracy:		87.72 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.291676
  validation loss:		0.371311
  validation accuracy:		88.48 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.299571
  validation loss:		0.388786
  validation accuracy:		88.04 %
Epoch 1109 of 2000 took 0.096s
  training loss:		0.299384
  validation loss:		0.413096
  validation accuracy:		87.72 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.287702
  validation loss:		0.378254
  validation accuracy:		88.48 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.298577
  validation loss:		0.382128
  validation accuracy:		88.37 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.293956
  validation loss:		0.389608
  validation accuracy:		88.59 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.290875
  validation loss:		0.398486
  validation accuracy:		87.39 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.295091
  validation loss:		0.389838
  validation accuracy:		87.61 %
Epoch 1115 of 2000 took 0.096s
  training loss:		0.293977
  validation loss:		0.394083
  validation accuracy:		87.93 %
Epoch 1116 of 2000 took 0.096s
  training loss:		0.290401
  validation loss:		0.397480
  validation accuracy:		87.72 %
Epoch 1117 of 2000 took 0.096s
  training loss:		0.297349
  validation loss:		0.383136
  validation accuracy:		87.93 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.290588
  validation loss:		0.387976
  validation accuracy:		88.04 %
Epoch 1119 of 2000 took 0.096s
  training loss:		0.300095
  validation loss:		0.381561
  validation accuracy:		87.83 %
Epoch 1120 of 2000 took 0.096s
  training loss:		0.295171
  validation loss:		0.394367
  validation accuracy:		87.39 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.290310
  validation loss:		0.378544
  validation accuracy:		88.80 %
Epoch 1122 of 2000 took 0.096s
  training loss:		0.285758
  validation loss:		0.390975
  validation accuracy:		87.93 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.293128
  validation loss:		0.376020
  validation accuracy:		88.59 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.290399
  validation loss:		0.374818
  validation accuracy:		88.48 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.299737
  validation loss:		0.420288
  validation accuracy:		86.96 %
Epoch 1126 of 2000 took 0.096s
  training loss:		0.299012
  validation loss:		0.373191
  validation accuracy:		88.48 %
Epoch 1127 of 2000 took 0.098s
  training loss:		0.290015
  validation loss:		0.384868
  validation accuracy:		88.26 %
Epoch 1128 of 2000 took 0.098s
  training loss:		0.286921
  validation loss:		0.415651
  validation accuracy:		87.83 %
Epoch 1129 of 2000 took 0.096s
  training loss:		0.299203
  validation loss:		0.408340
  validation accuracy:		87.72 %
Epoch 1130 of 2000 took 0.096s
  training loss:		0.286853
  validation loss:		0.390634
  validation accuracy:		88.48 %
Epoch 1131 of 2000 took 0.096s
  training loss:		0.294842
  validation loss:		0.409625
  validation accuracy:		86.96 %
Epoch 1132 of 2000 took 0.096s
  training loss:		0.296138
  validation loss:		0.382717
  validation accuracy:		88.15 %
Epoch 1133 of 2000 took 0.096s
  training loss:		0.294942
  validation loss:		0.387163
  validation accuracy:		88.04 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.293768
  validation loss:		0.384209
  validation accuracy:		87.83 %
Epoch 1135 of 2000 took 0.096s
  training loss:		0.289390
  validation loss:		0.388442
  validation accuracy:		87.83 %
Epoch 1136 of 2000 took 0.096s
  training loss:		0.292280
  validation loss:		0.372643
  validation accuracy:		88.37 %
Epoch 1137 of 2000 took 0.096s
  training loss:		0.292825
  validation loss:		0.376670
  validation accuracy:		88.37 %
Epoch 1138 of 2000 took 0.096s
  training loss:		0.294949
  validation loss:		0.379906
  validation accuracy:		88.48 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.292054
  validation loss:		0.383139
  validation accuracy:		87.83 %
Epoch 1140 of 2000 took 0.096s
  training loss:		0.296291
  validation loss:		0.381281
  validation accuracy:		88.15 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.292951
  validation loss:		0.377794
  validation accuracy:		88.59 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.285505
  validation loss:		0.392115
  validation accuracy:		87.61 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.295380
  validation loss:		0.375784
  validation accuracy:		88.70 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.289587
  validation loss:		0.376139
  validation accuracy:		88.80 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.287652
  validation loss:		0.368597
  validation accuracy:		88.48 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.293120
  validation loss:		0.381804
  validation accuracy:		88.37 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.289261
  validation loss:		0.382240
  validation accuracy:		88.15 %
Epoch 1148 of 2000 took 0.096s
  training loss:		0.287408
  validation loss:		0.378859
  validation accuracy:		88.26 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.294510
  validation loss:		0.377612
  validation accuracy:		88.37 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.294355
  validation loss:		0.389508
  validation accuracy:		87.83 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.291982
  validation loss:		0.381218
  validation accuracy:		88.37 %
Epoch 1152 of 2000 took 0.096s
  training loss:		0.287586
  validation loss:		0.370453
  validation accuracy:		88.59 %
Epoch 1153 of 2000 took 0.101s
  training loss:		0.297257
  validation loss:		0.378212
  validation accuracy:		88.59 %
Epoch 1154 of 2000 took 0.103s
  training loss:		0.296057
  validation loss:		0.389097
  validation accuracy:		87.72 %
Epoch 1155 of 2000 took 0.103s
  training loss:		0.293459
  validation loss:		0.371110
  validation accuracy:		88.48 %
Epoch 1156 of 2000 took 0.103s
  training loss:		0.296305
  validation loss:		0.402759
  validation accuracy:		88.15 %
Epoch 1157 of 2000 took 0.103s
  training loss:		0.289223
  validation loss:		0.390120
  validation accuracy:		87.61 %
Epoch 1158 of 2000 took 0.103s
  training loss:		0.287212
  validation loss:		0.408561
  validation accuracy:		87.72 %
Epoch 1159 of 2000 took 0.103s
  training loss:		0.295953
  validation loss:		0.383706
  validation accuracy:		88.26 %
Epoch 1160 of 2000 took 0.103s
  training loss:		0.294930
  validation loss:		0.377620
  validation accuracy:		88.48 %
Epoch 1161 of 2000 took 0.103s
  training loss:		0.285776
  validation loss:		0.393041
  validation accuracy:		87.50 %
Epoch 1162 of 2000 took 0.103s
  training loss:		0.294255
  validation loss:		0.382686
  validation accuracy:		88.04 %
Epoch 1163 of 2000 took 0.103s
  training loss:		0.293443
  validation loss:		0.375688
  validation accuracy:		88.48 %
Epoch 1164 of 2000 took 0.103s
  training loss:		0.296569
  validation loss:		0.395288
  validation accuracy:		87.39 %
Epoch 1165 of 2000 took 0.103s
  training loss:		0.281229
  validation loss:		0.395785
  validation accuracy:		88.26 %
Epoch 1166 of 2000 took 0.103s
  training loss:		0.294394
  validation loss:		0.373316
  validation accuracy:		88.04 %
Epoch 1167 of 2000 took 0.103s
  training loss:		0.289570
  validation loss:		0.373675
  validation accuracy:		88.70 %
Epoch 1168 of 2000 took 0.103s
  training loss:		0.293352
  validation loss:		0.375765
  validation accuracy:		87.93 %
Epoch 1169 of 2000 took 0.103s
  training loss:		0.291176
  validation loss:		0.379683
  validation accuracy:		88.59 %
Epoch 1170 of 2000 took 0.103s
  training loss:		0.291662
  validation loss:		0.375835
  validation accuracy:		88.37 %
Epoch 1171 of 2000 took 0.103s
  training loss:		0.289316
  validation loss:		0.386229
  validation accuracy:		88.04 %
Epoch 1172 of 2000 took 0.103s
  training loss:		0.291802
  validation loss:		0.370462
  validation accuracy:		88.70 %
Epoch 1173 of 2000 took 0.103s
  training loss:		0.287808
  validation loss:		0.399074
  validation accuracy:		87.83 %
Epoch 1174 of 2000 took 0.103s
  training loss:		0.300749
  validation loss:		0.384815
  validation accuracy:		87.93 %
Epoch 1175 of 2000 took 0.103s
  training loss:		0.286476
  validation loss:		0.375044
  validation accuracy:		88.59 %
Epoch 1176 of 2000 took 0.103s
  training loss:		0.287524
  validation loss:		0.384813
  validation accuracy:		87.83 %
Epoch 1177 of 2000 took 0.103s
  training loss:		0.290238
  validation loss:		0.372305
  validation accuracy:		88.48 %
Epoch 1178 of 2000 took 0.103s
  training loss:		0.284210
  validation loss:		0.378916
  validation accuracy:		88.37 %
Epoch 1179 of 2000 took 0.103s
  training loss:		0.293088
  validation loss:		0.382477
  validation accuracy:		87.72 %
Epoch 1180 of 2000 took 0.103s
  training loss:		0.284888
  validation loss:		0.380741
  validation accuracy:		88.15 %
Epoch 1181 of 2000 took 0.103s
  training loss:		0.289532
  validation loss:		0.384420
  validation accuracy:		87.72 %
Epoch 1182 of 2000 took 0.103s
  training loss:		0.288652
  validation loss:		0.391372
  validation accuracy:		88.37 %
Epoch 1183 of 2000 took 0.103s
  training loss:		0.291095
  validation loss:		0.393111
  validation accuracy:		88.04 %
Epoch 1184 of 2000 took 0.103s
  training loss:		0.289286
  validation loss:		0.404173
  validation accuracy:		86.63 %
Epoch 1185 of 2000 took 0.103s
  training loss:		0.290261
  validation loss:		0.375669
  validation accuracy:		88.59 %
Epoch 1186 of 2000 took 0.103s
  training loss:		0.292546
  validation loss:		0.378327
  validation accuracy:		88.59 %
Epoch 1187 of 2000 took 0.103s
  training loss:		0.287688
  validation loss:		0.396728
  validation accuracy:		87.07 %
Epoch 1188 of 2000 took 0.103s
  training loss:		0.288002
  validation loss:		0.375557
  validation accuracy:		88.48 %
Epoch 1189 of 2000 took 0.103s
  training loss:		0.298440
  validation loss:		0.382986
  validation accuracy:		88.15 %
Epoch 1190 of 2000 took 0.103s
  training loss:		0.284599
  validation loss:		0.383130
  validation accuracy:		88.04 %
Epoch 1191 of 2000 took 0.103s
  training loss:		0.291687
  validation loss:		0.385909
  validation accuracy:		87.61 %
Epoch 1192 of 2000 took 0.098s
  training loss:		0.283986
  validation loss:		0.371453
  validation accuracy:		88.26 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.285507
  validation loss:		0.373998
  validation accuracy:		88.37 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.291588
  validation loss:		0.393549
  validation accuracy:		87.93 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.291540
  validation loss:		0.377628
  validation accuracy:		88.37 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.292696
  validation loss:		0.380099
  validation accuracy:		88.80 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.294501
  validation loss:		0.372894
  validation accuracy:		88.59 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.287858
  validation loss:		0.389579
  validation accuracy:		87.72 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.287579
  validation loss:		0.376065
  validation accuracy:		88.15 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.295331
  validation loss:		0.397530
  validation accuracy:		87.39 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.290144
  validation loss:		0.387171
  validation accuracy:		88.26 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.288531
  validation loss:		0.417028
  validation accuracy:		86.52 %
Epoch 1203 of 2000 took 0.097s
  training loss:		0.295792
  validation loss:		0.392051
  validation accuracy:		87.39 %
Epoch 1204 of 2000 took 0.097s
  training loss:		0.288679
  validation loss:		0.377102
  validation accuracy:		88.37 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.290159
  validation loss:		0.378051
  validation accuracy:		88.04 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.293899
  validation loss:		0.366149
  validation accuracy:		89.13 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.293497
  validation loss:		0.371570
  validation accuracy:		88.26 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.294049
  validation loss:		0.375079
  validation accuracy:		88.70 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.290912
  validation loss:		0.405929
  validation accuracy:		86.74 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.291238
  validation loss:		0.382607
  validation accuracy:		88.26 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.285054
  validation loss:		0.397613
  validation accuracy:		87.28 %
Epoch 1212 of 2000 took 0.096s
  training loss:		0.297783
  validation loss:		0.376421
  validation accuracy:		88.37 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.291508
  validation loss:		0.371657
  validation accuracy:		88.26 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.289596
  validation loss:		0.380570
  validation accuracy:		88.26 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.290054
  validation loss:		0.367851
  validation accuracy:		88.80 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.286869
  validation loss:		0.380242
  validation accuracy:		88.26 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.291277
  validation loss:		0.378583
  validation accuracy:		88.70 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.290079
  validation loss:		0.377378
  validation accuracy:		88.70 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.289515
  validation loss:		0.371457
  validation accuracy:		88.48 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.285663
  validation loss:		0.388288
  validation accuracy:		88.26 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.291467
  validation loss:		0.392839
  validation accuracy:		87.83 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.297223
  validation loss:		0.379102
  validation accuracy:		88.37 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.289243
  validation loss:		0.383751
  validation accuracy:		88.15 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.292346
  validation loss:		0.381439
  validation accuracy:		88.80 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.295953
  validation loss:		0.368782
  validation accuracy:		88.80 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.290500
  validation loss:		0.386493
  validation accuracy:		87.72 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.287591
  validation loss:		0.397470
  validation accuracy:		87.39 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.292080
  validation loss:		0.396302
  validation accuracy:		88.15 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.293491
  validation loss:		0.381979
  validation accuracy:		88.37 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.284166
  validation loss:		0.383739
  validation accuracy:		88.48 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.289908
  validation loss:		0.390156
  validation accuracy:		87.83 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.292502
  validation loss:		0.380835
  validation accuracy:		88.48 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.287523
  validation loss:		0.365875
  validation accuracy:		88.91 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.288487
  validation loss:		0.378161
  validation accuracy:		88.70 %
Epoch 1235 of 2000 took 0.098s
  training loss:		0.291600
  validation loss:		0.367551
  validation accuracy:		89.35 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.278247
  validation loss:		0.372430
  validation accuracy:		88.91 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.289032
  validation loss:		0.395970
  validation accuracy:		87.07 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.295331
  validation loss:		0.368867
  validation accuracy:		88.70 %
Epoch 1239 of 2000 took 0.096s
  training loss:		0.290441
  validation loss:		0.366581
  validation accuracy:		88.91 %
Epoch 1240 of 2000 took 0.096s
  training loss:		0.289753
  validation loss:		0.385816
  validation accuracy:		88.04 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.288691
  validation loss:		0.378751
  validation accuracy:		88.48 %
Epoch 1242 of 2000 took 0.096s
  training loss:		0.285735
  validation loss:		0.400531
  validation accuracy:		87.39 %
Epoch 1243 of 2000 took 0.096s
  training loss:		0.286880
  validation loss:		0.386218
  validation accuracy:		87.83 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.286638
  validation loss:		0.367352
  validation accuracy:		88.80 %
Epoch 1245 of 2000 took 0.096s
  training loss:		0.285702
  validation loss:		0.394756
  validation accuracy:		87.83 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.290107
  validation loss:		0.402193
  validation accuracy:		87.50 %
Epoch 1247 of 2000 took 0.096s
  training loss:		0.296750
  validation loss:		0.385571
  validation accuracy:		88.15 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.289646
  validation loss:		0.406061
  validation accuracy:		86.96 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.298737
  validation loss:		0.416631
  validation accuracy:		86.85 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.291550
  validation loss:		0.372277
  validation accuracy:		89.24 %
Epoch 1251 of 2000 took 0.096s
  training loss:		0.292224
  validation loss:		0.370467
  validation accuracy:		88.70 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.286723
  validation loss:		0.382323
  validation accuracy:		88.15 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.291692
  validation loss:		0.380269
  validation accuracy:		88.80 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.288279
  validation loss:		0.375374
  validation accuracy:		89.02 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.284181
  validation loss:		0.373963
  validation accuracy:		88.15 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.288676
  validation loss:		0.385639
  validation accuracy:		88.26 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.291524
  validation loss:		0.384477
  validation accuracy:		88.15 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.296128
  validation loss:		0.370077
  validation accuracy:		88.91 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.283282
  validation loss:		0.389148
  validation accuracy:		88.37 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.283823
  validation loss:		0.385182
  validation accuracy:		88.48 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.293714
  validation loss:		0.370945
  validation accuracy:		88.15 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.292856
  validation loss:		0.368640
  validation accuracy:		88.59 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.284229
  validation loss:		0.378649
  validation accuracy:		88.59 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.297849
  validation loss:		0.380858
  validation accuracy:		88.26 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.288852
  validation loss:		0.373659
  validation accuracy:		88.59 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.286511
  validation loss:		0.386334
  validation accuracy:		88.15 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.292142
  validation loss:		0.370259
  validation accuracy:		89.35 %
Epoch 1268 of 2000 took 0.096s
  training loss:		0.285521
  validation loss:		0.375664
  validation accuracy:		88.70 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.287471
  validation loss:		0.388472
  validation accuracy:		87.72 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.292858
  validation loss:		0.379885
  validation accuracy:		88.15 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.295335
  validation loss:		0.371331
  validation accuracy:		88.48 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.291812
  validation loss:		0.389194
  validation accuracy:		87.83 %
Epoch 1273 of 2000 took 0.096s
  training loss:		0.285670
  validation loss:		0.370459
  validation accuracy:		88.80 %
Epoch 1274 of 2000 took 0.096s
  training loss:		0.285203
  validation loss:		0.375019
  validation accuracy:		88.04 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.291729
  validation loss:		0.376758
  validation accuracy:		88.04 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.285641
  validation loss:		0.391463
  validation accuracy:		87.83 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.285860
  validation loss:		0.372281
  validation accuracy:		88.59 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.286412
  validation loss:		0.374029
  validation accuracy:		88.80 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.286575
  validation loss:		0.366342
  validation accuracy:		89.13 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.287425
  validation loss:		0.370212
  validation accuracy:		89.35 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.297295
  validation loss:		0.378941
  validation accuracy:		88.59 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.288472
  validation loss:		0.391606
  validation accuracy:		87.83 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.295063
  validation loss:		0.365986
  validation accuracy:		88.15 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.286851
  validation loss:		0.383851
  validation accuracy:		88.26 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.287034
  validation loss:		0.388006
  validation accuracy:		87.61 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.297121
  validation loss:		0.368715
  validation accuracy:		89.02 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.292953
  validation loss:		0.376579
  validation accuracy:		88.37 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.288434
  validation loss:		0.397725
  validation accuracy:		87.72 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.295571
  validation loss:		0.378016
  validation accuracy:		88.48 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.282957
  validation loss:		0.383639
  validation accuracy:		87.93 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.288703
  validation loss:		0.378708
  validation accuracy:		88.37 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.289282
  validation loss:		0.370754
  validation accuracy:		88.91 %
Epoch 1293 of 2000 took 0.096s
  training loss:		0.286766
  validation loss:		0.388174
  validation accuracy:		88.04 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.280177
  validation loss:		0.378382
  validation accuracy:		88.04 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.292754
  validation loss:		0.369299
  validation accuracy:		89.46 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.287945
  validation loss:		0.375385
  validation accuracy:		87.83 %
Epoch 1297 of 2000 took 0.097s
  training loss:		0.284703
  validation loss:		0.376083
  validation accuracy:		88.70 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.282938
  validation loss:		0.387109
  validation accuracy:		88.48 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.293316
  validation loss:		0.376432
  validation accuracy:		88.15 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.285934
  validation loss:		0.385900
  validation accuracy:		88.15 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.282938
  validation loss:		0.376850
  validation accuracy:		88.04 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.293573
  validation loss:		0.391163
  validation accuracy:		88.04 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.287234
  validation loss:		0.384051
  validation accuracy:		87.93 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.291464
  validation loss:		0.370865
  validation accuracy:		89.35 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.287305
  validation loss:		0.373327
  validation accuracy:		88.59 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.287547
  validation loss:		0.373163
  validation accuracy:		88.26 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.290985
  validation loss:		0.377145
  validation accuracy:		87.93 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.289768
  validation loss:		0.376984
  validation accuracy:		88.70 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.292866
  validation loss:		0.398505
  validation accuracy:		87.83 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.291498
  validation loss:		0.380536
  validation accuracy:		88.59 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.283922
  validation loss:		0.376810
  validation accuracy:		87.93 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.292863
  validation loss:		0.381244
  validation accuracy:		87.72 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.281741
  validation loss:		0.385497
  validation accuracy:		88.04 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.284667
  validation loss:		0.378534
  validation accuracy:		88.04 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.291139
  validation loss:		0.374670
  validation accuracy:		88.80 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.294845
  validation loss:		0.393576
  validation accuracy:		88.15 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.293320
  validation loss:		0.381000
  validation accuracy:		88.91 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.284037
  validation loss:		0.387534
  validation accuracy:		87.93 %
Epoch 1319 of 2000 took 0.096s
  training loss:		0.286598
  validation loss:		0.370869
  validation accuracy:		88.80 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.281403
  validation loss:		0.372803
  validation accuracy:		88.48 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.303009
  validation loss:		0.378427
  validation accuracy:		88.70 %
Epoch 1322 of 2000 took 0.096s
  training loss:		0.289511
  validation loss:		0.374329
  validation accuracy:		88.48 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.285418
  validation loss:		0.375540
  validation accuracy:		88.15 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.287356
  validation loss:		0.377864
  validation accuracy:		88.37 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.286630
  validation loss:		0.393282
  validation accuracy:		87.61 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.287920
  validation loss:		0.366036
  validation accuracy:		89.57 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.285100
  validation loss:		0.389996
  validation accuracy:		88.15 %
Epoch 1328 of 2000 took 0.097s
  training loss:		0.289704
  validation loss:		0.384084
  validation accuracy:		88.26 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.285300
  validation loss:		0.390813
  validation accuracy:		87.93 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.293146
  validation loss:		0.373765
  validation accuracy:		89.24 %
Epoch 1331 of 2000 took 0.096s
  training loss:		0.289532
  validation loss:		0.370129
  validation accuracy:		88.37 %
Epoch 1332 of 2000 took 0.096s
  training loss:		0.285182
  validation loss:		0.385922
  validation accuracy:		87.72 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.292086
  validation loss:		0.371370
  validation accuracy:		89.13 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.281775
  validation loss:		0.392136
  validation accuracy:		88.26 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.287612
  validation loss:		0.372652
  validation accuracy:		89.02 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.286127
  validation loss:		0.400163
  validation accuracy:		87.39 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.289722
  validation loss:		0.364735
  validation accuracy:		87.93 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.283293
  validation loss:		0.390894
  validation accuracy:		87.50 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.289327
  validation loss:		0.367695
  validation accuracy:		88.91 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.284775
  validation loss:		0.396661
  validation accuracy:		87.07 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.286214
  validation loss:		0.374768
  validation accuracy:		88.37 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.285778
  validation loss:		0.389440
  validation accuracy:		87.93 %
Epoch 1343 of 2000 took 0.096s
  training loss:		0.292231
  validation loss:		0.401101
  validation accuracy:		87.93 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.287684
  validation loss:		0.389702
  validation accuracy:		88.04 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.289892
  validation loss:		0.373084
  validation accuracy:		88.91 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.282845
  validation loss:		0.374415
  validation accuracy:		88.70 %
Epoch 1347 of 2000 took 0.096s
  training loss:		0.287482
  validation loss:		0.368148
  validation accuracy:		88.26 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.282833
  validation loss:		0.374076
  validation accuracy:		87.93 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.288875
  validation loss:		0.365406
  validation accuracy:		88.48 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.293765
  validation loss:		0.366178
  validation accuracy:		88.37 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.285821
  validation loss:		0.395675
  validation accuracy:		87.39 %
Epoch 1352 of 2000 took 0.096s
  training loss:		0.290549
  validation loss:		0.394561
  validation accuracy:		87.39 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.289284
  validation loss:		0.391998
  validation accuracy:		87.83 %
Epoch 1354 of 2000 took 0.097s
  training loss:		0.289632
  validation loss:		0.399810
  validation accuracy:		87.17 %
Epoch 1355 of 2000 took 0.096s
  training loss:		0.290241
  validation loss:		0.376028
  validation accuracy:		87.93 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.286342
  validation loss:		0.388184
  validation accuracy:		88.26 %
Epoch 1357 of 2000 took 0.096s
  training loss:		0.290684
  validation loss:		0.364425
  validation accuracy:		88.80 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.285674
  validation loss:		0.369641
  validation accuracy:		89.13 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.286924
  validation loss:		0.371982
  validation accuracy:		88.48 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.289523
  validation loss:		0.388802
  validation accuracy:		88.48 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.289585
  validation loss:		0.369944
  validation accuracy:		88.15 %
Epoch 1362 of 2000 took 0.096s
  training loss:		0.287030
  validation loss:		0.384349
  validation accuracy:		88.15 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.286468
  validation loss:		0.391976
  validation accuracy:		88.37 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.285202
  validation loss:		0.372973
  validation accuracy:		88.59 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.288906
  validation loss:		0.409348
  validation accuracy:		87.83 %
Epoch 1366 of 2000 took 0.096s
  training loss:		0.286095
  validation loss:		0.396276
  validation accuracy:		88.04 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.289518
  validation loss:		0.388277
  validation accuracy:		88.15 %
Epoch 1368 of 2000 took 0.096s
  training loss:		0.294177
  validation loss:		0.369410
  validation accuracy:		88.59 %
Epoch 1369 of 2000 took 0.096s
  training loss:		0.291309
  validation loss:		0.383776
  validation accuracy:		88.48 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.293260
  validation loss:		0.387685
  validation accuracy:		88.26 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.289544
  validation loss:		0.380102
  validation accuracy:		87.72 %
Epoch 1372 of 2000 took 0.096s
  training loss:		0.283681
  validation loss:		0.374981
  validation accuracy:		88.15 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.285140
  validation loss:		0.374154
  validation accuracy:		88.48 %
Epoch 1374 of 2000 took 0.097s
  training loss:		0.279872
  validation loss:		0.374718
  validation accuracy:		88.37 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.279265
  validation loss:		0.399975
  validation accuracy:		87.28 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.296275
  validation loss:		0.381017
  validation accuracy:		88.37 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.288176
  validation loss:		0.371219
  validation accuracy:		88.26 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.285255
  validation loss:		0.370124
  validation accuracy:		88.37 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.291811
  validation loss:		0.367861
  validation accuracy:		88.80 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.288871
  validation loss:		0.393525
  validation accuracy:		88.26 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.286062
  validation loss:		0.368833
  validation accuracy:		89.57 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.287271
  validation loss:		0.371536
  validation accuracy:		88.26 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.294681
  validation loss:		0.365752
  validation accuracy:		88.80 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.284473
  validation loss:		0.376040
  validation accuracy:		89.02 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.293694
  validation loss:		0.392058
  validation accuracy:		88.59 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.293561
  validation loss:		0.373232
  validation accuracy:		88.37 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.293707
  validation loss:		0.377717
  validation accuracy:		87.93 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.291391
  validation loss:		0.363824
  validation accuracy:		89.13 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.291198
  validation loss:		0.362397
  validation accuracy:		89.02 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.287715
  validation loss:		0.366964
  validation accuracy:		89.13 %
Epoch 1391 of 2000 took 0.097s
  training loss:		0.286555
  validation loss:		0.373089
  validation accuracy:		88.26 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.286761
  validation loss:		0.377621
  validation accuracy:		88.15 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.292424
  validation loss:		0.376055
  validation accuracy:		88.15 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.277795
  validation loss:		0.366287
  validation accuracy:		88.59 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.292149
  validation loss:		0.380938
  validation accuracy:		88.48 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.287680
  validation loss:		0.364387
  validation accuracy:		89.46 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.286922
  validation loss:		0.374865
  validation accuracy:		88.04 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.285548
  validation loss:		0.387210
  validation accuracy:		88.26 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.282799
  validation loss:		0.408270
  validation accuracy:		87.07 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.287787
  validation loss:		0.373249
  validation accuracy:		88.26 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.285908
  validation loss:		0.376580
  validation accuracy:		88.37 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.286013
  validation loss:		0.388405
  validation accuracy:		88.48 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.280064
  validation loss:		0.373034
  validation accuracy:		88.59 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.290059
  validation loss:		0.372277
  validation accuracy:		88.59 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.292843
  validation loss:		0.373539
  validation accuracy:		88.59 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.291011
  validation loss:		0.371974
  validation accuracy:		89.35 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.285750
  validation loss:		0.379701
  validation accuracy:		88.15 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.285146
  validation loss:		0.396746
  validation accuracy:		87.83 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.284354
  validation loss:		0.377335
  validation accuracy:		87.93 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.287083
  validation loss:		0.374857
  validation accuracy:		88.37 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.284787
  validation loss:		0.376271
  validation accuracy:		88.15 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.278782
  validation loss:		0.368861
  validation accuracy:		88.91 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.283008
  validation loss:		0.378903
  validation accuracy:		87.83 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.287079
  validation loss:		0.378752
  validation accuracy:		88.48 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.286887
  validation loss:		0.384407
  validation accuracy:		87.83 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.292049
  validation loss:		0.373709
  validation accuracy:		88.37 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.287492
  validation loss:		0.371778
  validation accuracy:		88.59 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.279313
  validation loss:		0.374929
  validation accuracy:		88.59 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.289893
  validation loss:		0.376699
  validation accuracy:		88.15 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.284766
  validation loss:		0.372215
  validation accuracy:		88.91 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.279787
  validation loss:		0.373373
  validation accuracy:		89.02 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.287602
  validation loss:		0.382155
  validation accuracy:		88.48 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.282736
  validation loss:		0.368222
  validation accuracy:		88.70 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.289829
  validation loss:		0.369432
  validation accuracy:		89.35 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.282622
  validation loss:		0.364794
  validation accuracy:		89.24 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.295632
  validation loss:		0.385059
  validation accuracy:		88.04 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.287476
  validation loss:		0.372293
  validation accuracy:		88.80 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.284694
  validation loss:		0.378165
  validation accuracy:		88.48 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.284145
  validation loss:		0.381524
  validation accuracy:		88.26 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.293008
  validation loss:		0.370621
  validation accuracy:		87.93 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.288767
  validation loss:		0.367700
  validation accuracy:		89.13 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.281383
  validation loss:		0.379424
  validation accuracy:		88.48 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.292850
  validation loss:		0.375225
  validation accuracy:		88.04 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.289429
  validation loss:		0.371150
  validation accuracy:		88.37 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.281340
  validation loss:		0.368275
  validation accuracy:		88.59 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.285439
  validation loss:		0.366679
  validation accuracy:		88.26 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.286537
  validation loss:		0.396925
  validation accuracy:		88.15 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.288239
  validation loss:		0.368451
  validation accuracy:		89.24 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.282015
  validation loss:		0.375430
  validation accuracy:		88.70 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.283382
  validation loss:		0.391142
  validation accuracy:		87.83 %
Epoch 1441 of 2000 took 0.100s
  training loss:		0.285994
  validation loss:		0.389781
  validation accuracy:		88.37 %
Epoch 1442 of 2000 took 0.100s
  training loss:		0.288868
  validation loss:		0.378394
  validation accuracy:		88.37 %
Epoch 1443 of 2000 took 0.100s
  training loss:		0.287077
  validation loss:		0.383792
  validation accuracy:		88.37 %
Epoch 1444 of 2000 took 0.099s
  training loss:		0.287407
  validation loss:		0.369555
  validation accuracy:		89.02 %
Epoch 1445 of 2000 took 0.099s
  training loss:		0.281529
  validation loss:		0.370120
  validation accuracy:		88.80 %
Epoch 1446 of 2000 took 0.099s
  training loss:		0.284146
  validation loss:		0.364821
  validation accuracy:		89.46 %
Epoch 1447 of 2000 took 0.099s
  training loss:		0.283421
  validation loss:		0.376441
  validation accuracy:		88.59 %
Epoch 1448 of 2000 took 0.100s
  training loss:		0.285741
  validation loss:		0.381510
  validation accuracy:		88.70 %
Epoch 1449 of 2000 took 0.099s
  training loss:		0.285935
  validation loss:		0.367908
  validation accuracy:		88.37 %
Epoch 1450 of 2000 took 0.099s
  training loss:		0.290093
  validation loss:		0.379530
  validation accuracy:		88.48 %
Epoch 1451 of 2000 took 0.099s
  training loss:		0.284146
  validation loss:		0.391642
  validation accuracy:		87.83 %
Epoch 1452 of 2000 took 0.099s
  training loss:		0.285530
  validation loss:		0.369342
  validation accuracy:		89.02 %
Epoch 1453 of 2000 took 0.100s
  training loss:		0.286680
  validation loss:		0.396919
  validation accuracy:		87.61 %
Epoch 1454 of 2000 took 0.099s
  training loss:		0.286421
  validation loss:		0.380548
  validation accuracy:		87.93 %
Epoch 1455 of 2000 took 0.100s
  training loss:		0.295296
  validation loss:		0.380111
  validation accuracy:		88.80 %
Epoch 1456 of 2000 took 0.099s
  training loss:		0.278887
  validation loss:		0.377126
  validation accuracy:		88.15 %
Epoch 1457 of 2000 took 0.099s
  training loss:		0.287244
  validation loss:		0.405978
  validation accuracy:		87.61 %
Epoch 1458 of 2000 took 0.099s
  training loss:		0.284909
  validation loss:		0.378954
  validation accuracy:		89.13 %
Epoch 1459 of 2000 took 0.099s
  training loss:		0.283382
  validation loss:		0.397516
  validation accuracy:		88.48 %
Epoch 1460 of 2000 took 0.099s
  training loss:		0.284998
  validation loss:		0.365745
  validation accuracy:		88.59 %
Epoch 1461 of 2000 took 0.100s
  training loss:		0.284404
  validation loss:		0.380504
  validation accuracy:		88.70 %
Epoch 1462 of 2000 took 0.100s
  training loss:		0.285866
  validation loss:		0.376845
  validation accuracy:		87.93 %
Epoch 1463 of 2000 took 0.100s
  training loss:		0.281996
  validation loss:		0.366539
  validation accuracy:		89.67 %
Epoch 1464 of 2000 took 0.099s
  training loss:		0.282817
  validation loss:		0.372055
  validation accuracy:		88.37 %
Epoch 1465 of 2000 took 0.099s
  training loss:		0.289576
  validation loss:		0.365435
  validation accuracy:		88.91 %
Epoch 1466 of 2000 took 0.099s
  training loss:		0.288485
  validation loss:		0.379458
  validation accuracy:		88.91 %
Epoch 1467 of 2000 took 0.099s
  training loss:		0.284029
  validation loss:		0.368570
  validation accuracy:		88.26 %
Epoch 1468 of 2000 took 0.099s
  training loss:		0.283121
  validation loss:		0.380368
  validation accuracy:		88.37 %
Epoch 1469 of 2000 took 0.099s
  training loss:		0.291024
  validation loss:		0.378372
  validation accuracy:		88.80 %
Epoch 1470 of 2000 took 0.101s
  training loss:		0.285068
  validation loss:		0.370141
  validation accuracy:		89.24 %
Epoch 1471 of 2000 took 0.101s
  training loss:		0.289076
  validation loss:		0.363417
  validation accuracy:		89.13 %
Epoch 1472 of 2000 took 0.099s
  training loss:		0.286226
  validation loss:		0.385611
  validation accuracy:		88.26 %
Epoch 1473 of 2000 took 0.100s
  training loss:		0.290851
  validation loss:		0.364099
  validation accuracy:		88.48 %
Epoch 1474 of 2000 took 0.099s
  training loss:		0.282591
  validation loss:		0.373678
  validation accuracy:		88.59 %
Epoch 1475 of 2000 took 0.100s
  training loss:		0.291555
  validation loss:		0.377360
  validation accuracy:		87.50 %
Epoch 1476 of 2000 took 0.100s
  training loss:		0.286845
  validation loss:		0.397307
  validation accuracy:		88.37 %
Epoch 1477 of 2000 took 0.100s
  training loss:		0.286366
  validation loss:		0.372697
  validation accuracy:		88.48 %
Epoch 1478 of 2000 took 0.100s
  training loss:		0.284782
  validation loss:		0.381961
  validation accuracy:		88.04 %
Epoch 1479 of 2000 took 0.099s
  training loss:		0.286597
  validation loss:		0.364867
  validation accuracy:		89.24 %
Epoch 1480 of 2000 took 0.099s
  training loss:		0.285276
  validation loss:		0.382501
  validation accuracy:		88.59 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.284329
  validation loss:		0.363210
  validation accuracy:		89.24 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.282086
  validation loss:		0.372623
  validation accuracy:		88.37 %
Epoch 1483 of 2000 took 0.097s
  training loss:		0.283748
  validation loss:		0.385086
  validation accuracy:		88.37 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.285430
  validation loss:		0.401091
  validation accuracy:		87.07 %
Epoch 1485 of 2000 took 0.097s
  training loss:		0.287339
  validation loss:		0.374174
  validation accuracy:		88.15 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.282967
  validation loss:		0.370612
  validation accuracy:		88.59 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.283344
  validation loss:		0.364952
  validation accuracy:		89.24 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.289036
  validation loss:		0.363785
  validation accuracy:		88.37 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.288804
  validation loss:		0.373765
  validation accuracy:		88.15 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.287621
  validation loss:		0.362124
  validation accuracy:		89.46 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.285818
  validation loss:		0.374227
  validation accuracy:		88.37 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.281350
  validation loss:		0.418452
  validation accuracy:		87.39 %
Epoch 1493 of 2000 took 0.097s
  training loss:		0.288043
  validation loss:		0.386551
  validation accuracy:		88.04 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.288531
  validation loss:		0.371458
  validation accuracy:		88.80 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.284714
  validation loss:		0.376898
  validation accuracy:		88.37 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.288773
  validation loss:		0.371934
  validation accuracy:		88.80 %
Epoch 1497 of 2000 took 0.096s
  training loss:		0.285035
  validation loss:		0.389997
  validation accuracy:		87.93 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.290758
  validation loss:		0.381164
  validation accuracy:		88.59 %
Epoch 1499 of 2000 took 0.098s
  training loss:		0.286917
  validation loss:		0.392763
  validation accuracy:		88.15 %
Epoch 1500 of 2000 took 0.098s
  training loss:		0.285409
  validation loss:		0.368890
  validation accuracy:		89.13 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.284524
  validation loss:		0.371619
  validation accuracy:		89.35 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.286125
  validation loss:		0.417598
  validation accuracy:		86.96 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.297926
  validation loss:		0.369842
  validation accuracy:		88.48 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.294457
  validation loss:		0.374261
  validation accuracy:		88.26 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.287133
  validation loss:		0.371668
  validation accuracy:		89.24 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.290184
  validation loss:		0.375728
  validation accuracy:		88.37 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.283711
  validation loss:		0.367000
  validation accuracy:		88.48 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.285323
  validation loss:		0.372994
  validation accuracy:		88.48 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.283206
  validation loss:		0.376054
  validation accuracy:		88.80 %
Epoch 1510 of 2000 took 0.096s
  training loss:		0.282143
  validation loss:		0.378509
  validation accuracy:		88.37 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.284008
  validation loss:		0.366977
  validation accuracy:		89.13 %
Epoch 1512 of 2000 took 0.096s
  training loss:		0.286368
  validation loss:		0.381353
  validation accuracy:		88.26 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.281304
  validation loss:		0.382955
  validation accuracy:		88.48 %
Epoch 1514 of 2000 took 0.098s
  training loss:		0.284255
  validation loss:		0.383507
  validation accuracy:		88.15 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.291372
  validation loss:		0.394774
  validation accuracy:		87.61 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.292239
  validation loss:		0.368697
  validation accuracy:		89.13 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.287048
  validation loss:		0.381720
  validation accuracy:		88.59 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.288323
  validation loss:		0.364618
  validation accuracy:		88.70 %
Epoch 1519 of 2000 took 0.097s
  training loss:		0.280540
  validation loss:		0.372551
  validation accuracy:		88.59 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.292782
  validation loss:		0.379549
  validation accuracy:		88.48 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.278935
  validation loss:		0.402640
  validation accuracy:		87.28 %
Epoch 1522 of 2000 took 0.099s
  training loss:		0.288249
  validation loss:		0.371102
  validation accuracy:		89.24 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.282572
  validation loss:		0.369638
  validation accuracy:		88.48 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.279842
  validation loss:		0.375788
  validation accuracy:		88.80 %
Epoch 1525 of 2000 took 0.099s
  training loss:		0.289062
  validation loss:		0.398276
  validation accuracy:		87.72 %
Epoch 1526 of 2000 took 0.099s
  training loss:		0.281051
  validation loss:		0.382213
  validation accuracy:		87.83 %
Epoch 1527 of 2000 took 0.099s
  training loss:		0.279282
  validation loss:		0.371233
  validation accuracy:		89.24 %
Epoch 1528 of 2000 took 0.099s
  training loss:		0.285031
  validation loss:		0.382925
  validation accuracy:		88.26 %
Epoch 1529 of 2000 took 0.099s
  training loss:		0.280198
  validation loss:		0.371206
  validation accuracy:		89.46 %
Epoch 1530 of 2000 took 0.099s
  training loss:		0.282892
  validation loss:		0.396474
  validation accuracy:		87.28 %
Epoch 1531 of 2000 took 0.101s
  training loss:		0.285794
  validation loss:		0.360503
  validation accuracy:		89.67 %
Epoch 1532 of 2000 took 0.100s
  training loss:		0.286625
  validation loss:		0.364888
  validation accuracy:		89.35 %
Epoch 1533 of 2000 took 0.099s
  training loss:		0.288202
  validation loss:		0.373419
  validation accuracy:		88.91 %
Epoch 1534 of 2000 took 0.100s
  training loss:		0.281675
  validation loss:		0.370256
  validation accuracy:		88.70 %
Epoch 1535 of 2000 took 0.099s
  training loss:		0.286874
  validation loss:		0.385567
  validation accuracy:		88.70 %
Epoch 1536 of 2000 took 0.099s
  training loss:		0.284224
  validation loss:		0.389786
  validation accuracy:		88.15 %
Epoch 1537 of 2000 took 0.099s
  training loss:		0.283485
  validation loss:		0.367632
  validation accuracy:		88.91 %
Epoch 1538 of 2000 took 0.099s
  training loss:		0.288330
  validation loss:		0.377976
  validation accuracy:		88.37 %
Epoch 1539 of 2000 took 0.099s
  training loss:		0.289601
  validation loss:		0.377969
  validation accuracy:		88.37 %
Epoch 1540 of 2000 took 0.099s
  training loss:		0.283801
  validation loss:		0.368929
  validation accuracy:		88.91 %
Epoch 1541 of 2000 took 0.099s
  training loss:		0.289830
  validation loss:		0.378181
  validation accuracy:		88.37 %
Epoch 1542 of 2000 took 0.099s
  training loss:		0.290886
  validation loss:		0.367619
  validation accuracy:		88.48 %
Epoch 1543 of 2000 took 0.099s
  training loss:		0.291045
  validation loss:		0.369261
  validation accuracy:		88.80 %
Epoch 1544 of 2000 took 0.100s
  training loss:		0.287502
  validation loss:		0.376462
  validation accuracy:		88.48 %
Epoch 1545 of 2000 took 0.100s
  training loss:		0.282216
  validation loss:		0.382733
  validation accuracy:		87.83 %
Epoch 1546 of 2000 took 0.099s
  training loss:		0.294807
  validation loss:		0.379472
  validation accuracy:		88.37 %
Epoch 1547 of 2000 took 0.099s
  training loss:		0.278504
  validation loss:		0.381329
  validation accuracy:		88.04 %
Epoch 1548 of 2000 took 0.099s
  training loss:		0.284091
  validation loss:		0.371995
  validation accuracy:		88.48 %
Epoch 1549 of 2000 took 0.099s
  training loss:		0.290004
  validation loss:		0.362480
  validation accuracy:		88.80 %
Epoch 1550 of 2000 took 0.099s
  training loss:		0.284280
  validation loss:		0.393443
  validation accuracy:		88.04 %
Epoch 1551 of 2000 took 0.099s
  training loss:		0.274999
  validation loss:		0.390268
  validation accuracy:		87.61 %
Epoch 1552 of 2000 took 0.099s
  training loss:		0.290383
  validation loss:		0.373882
  validation accuracy:		88.48 %
Epoch 1553 of 2000 took 0.099s
  training loss:		0.287030
  validation loss:		0.365666
  validation accuracy:		89.46 %
Epoch 1554 of 2000 took 0.100s
  training loss:		0.285259
  validation loss:		0.378848
  validation accuracy:		88.37 %
Epoch 1555 of 2000 took 0.099s
  training loss:		0.283506
  validation loss:		0.367264
  validation accuracy:		89.13 %
Epoch 1556 of 2000 took 0.099s
  training loss:		0.283972
  validation loss:		0.371589
  validation accuracy:		88.37 %
Epoch 1557 of 2000 took 0.099s
  training loss:		0.286054
  validation loss:		0.386894
  validation accuracy:		88.26 %
Epoch 1558 of 2000 took 0.099s
  training loss:		0.291250
  validation loss:		0.367322
  validation accuracy:		88.70 %
Epoch 1559 of 2000 took 0.100s
  training loss:		0.284598
  validation loss:		0.376045
  validation accuracy:		88.80 %
Epoch 1560 of 2000 took 0.100s
  training loss:		0.281423
  validation loss:		0.366277
  validation accuracy:		88.59 %
Epoch 1561 of 2000 took 0.099s
  training loss:		0.278720
  validation loss:		0.372401
  validation accuracy:		88.04 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.290297
  validation loss:		0.366832
  validation accuracy:		88.70 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.280967
  validation loss:		0.375580
  validation accuracy:		88.91 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.286285
  validation loss:		0.385369
  validation accuracy:		88.48 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.280832
  validation loss:		0.408628
  validation accuracy:		87.72 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.285978
  validation loss:		0.376473
  validation accuracy:		88.48 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.278795
  validation loss:		0.370411
  validation accuracy:		88.59 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.285389
  validation loss:		0.379223
  validation accuracy:		87.93 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.288332
  validation loss:		0.378642
  validation accuracy:		88.26 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.287861
  validation loss:		0.367942
  validation accuracy:		88.80 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.286616
  validation loss:		0.368756
  validation accuracy:		89.24 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.281834
  validation loss:		0.371469
  validation accuracy:		88.91 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.281211
  validation loss:		0.372979
  validation accuracy:		88.37 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.283004
  validation loss:		0.377855
  validation accuracy:		88.80 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.286176
  validation loss:		0.379528
  validation accuracy:		88.70 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.287623
  validation loss:		0.375702
  validation accuracy:		88.70 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.290339
  validation loss:		0.383185
  validation accuracy:		88.04 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.280683
  validation loss:		0.383545
  validation accuracy:		88.91 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.291518
  validation loss:		0.380610
  validation accuracy:		88.15 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.284636
  validation loss:		0.364254
  validation accuracy:		88.80 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.282633
  validation loss:		0.367850
  validation accuracy:		88.91 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.279885
  validation loss:		0.382323
  validation accuracy:		88.59 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.285107
  validation loss:		0.375027
  validation accuracy:		88.80 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.289939
  validation loss:		0.364108
  validation accuracy:		89.13 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.286703
  validation loss:		0.368447
  validation accuracy:		88.70 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.288060
  validation loss:		0.378517
  validation accuracy:		88.59 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.284950
  validation loss:		0.370889
  validation accuracy:		88.70 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.285102
  validation loss:		0.382793
  validation accuracy:		88.15 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.285127
  validation loss:		0.366657
  validation accuracy:		89.24 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.289515
  validation loss:		0.371936
  validation accuracy:		89.02 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.286873
  validation loss:		0.383245
  validation accuracy:		87.93 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.282415
  validation loss:		0.365146
  validation accuracy:		89.24 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.290041
  validation loss:		0.370370
  validation accuracy:		88.26 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.290748
  validation loss:		0.366723
  validation accuracy:		89.02 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.285603
  validation loss:		0.376521
  validation accuracy:		87.93 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.277487
  validation loss:		0.373554
  validation accuracy:		88.91 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.282752
  validation loss:		0.396446
  validation accuracy:		88.37 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.288277
  validation loss:		0.365404
  validation accuracy:		88.80 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.283389
  validation loss:		0.370740
  validation accuracy:		88.48 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.286446
  validation loss:		0.377099
  validation accuracy:		88.91 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.281594
  validation loss:		0.369244
  validation accuracy:		88.91 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.286946
  validation loss:		0.379757
  validation accuracy:		87.83 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.276588
  validation loss:		0.369790
  validation accuracy:		88.26 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.290905
  validation loss:		0.373774
  validation accuracy:		89.02 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.287437
  validation loss:		0.368272
  validation accuracy:		89.02 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.286637
  validation loss:		0.396132
  validation accuracy:		87.83 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.285675
  validation loss:		0.367519
  validation accuracy:		89.13 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.285852
  validation loss:		0.374680
  validation accuracy:		88.70 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.285252
  validation loss:		0.375048
  validation accuracy:		88.70 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.284065
  validation loss:		0.374533
  validation accuracy:		88.37 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.286929
  validation loss:		0.370650
  validation accuracy:		88.80 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.286480
  validation loss:		0.364229
  validation accuracy:		89.13 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.282045
  validation loss:		0.371233
  validation accuracy:		88.48 %
Epoch 1614 of 2000 took 0.096s
  training loss:		0.287867
  validation loss:		0.393008
  validation accuracy:		88.37 %
Epoch 1615 of 2000 took 0.096s
  training loss:		0.280917
  validation loss:		0.377418
  validation accuracy:		88.70 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.283414
  validation loss:		0.380879
  validation accuracy:		88.70 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.280478
  validation loss:		0.363036
  validation accuracy:		89.24 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.280942
  validation loss:		0.372895
  validation accuracy:		88.37 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.281918
  validation loss:		0.382541
  validation accuracy:		88.26 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.285694
  validation loss:		0.369353
  validation accuracy:		89.02 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.281746
  validation loss:		0.368188
  validation accuracy:		88.70 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.281586
  validation loss:		0.372393
  validation accuracy:		88.80 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.290575
  validation loss:		0.378560
  validation accuracy:		88.04 %
Epoch 1624 of 2000 took 0.096s
  training loss:		0.288520
  validation loss:		0.381120
  validation accuracy:		88.26 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.281258
  validation loss:		0.369281
  validation accuracy:		89.24 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.290952
  validation loss:		0.388374
  validation accuracy:		87.83 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.288525
  validation loss:		0.376343
  validation accuracy:		88.48 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.280847
  validation loss:		0.387109
  validation accuracy:		88.37 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.281720
  validation loss:		0.379282
  validation accuracy:		88.70 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.282331
  validation loss:		0.390800
  validation accuracy:		87.72 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.283620
  validation loss:		0.379128
  validation accuracy:		87.83 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.281953
  validation loss:		0.363263
  validation accuracy:		89.02 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.284551
  validation loss:		0.378517
  validation accuracy:		88.15 %
Epoch 1634 of 2000 took 0.096s
  training loss:		0.286580
  validation loss:		0.374665
  validation accuracy:		88.26 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.287080
  validation loss:		0.377545
  validation accuracy:		88.48 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.282162
  validation loss:		0.378890
  validation accuracy:		88.59 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.285672
  validation loss:		0.365292
  validation accuracy:		88.91 %
Epoch 1638 of 2000 took 0.097s
  training loss:		0.295966
  validation loss:		0.383626
  validation accuracy:		88.04 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.279991
  validation loss:		0.386594
  validation accuracy:		88.15 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.285115
  validation loss:		0.364165
  validation accuracy:		88.70 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.276879
  validation loss:		0.361834
  validation accuracy:		89.02 %
Epoch 1642 of 2000 took 0.097s
  training loss:		0.284888
  validation loss:		0.381560
  validation accuracy:		88.59 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.284249
  validation loss:		0.366536
  validation accuracy:		88.91 %
Epoch 1644 of 2000 took 0.098s
  training loss:		0.286183
  validation loss:		0.372031
  validation accuracy:		88.37 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.287702
  validation loss:		0.380491
  validation accuracy:		88.37 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.289715
  validation loss:		0.371906
  validation accuracy:		88.59 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.276773
  validation loss:		0.367406
  validation accuracy:		89.24 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.286112
  validation loss:		0.374031
  validation accuracy:		88.80 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.281480
  validation loss:		0.394387
  validation accuracy:		87.93 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.285787
  validation loss:		0.365704
  validation accuracy:		88.80 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.287032
  validation loss:		0.362361
  validation accuracy:		89.02 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.284313
  validation loss:		0.405268
  validation accuracy:		87.93 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.282458
  validation loss:		0.388453
  validation accuracy:		88.04 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.292399
  validation loss:		0.388173
  validation accuracy:		87.83 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.284309
  validation loss:		0.371059
  validation accuracy:		88.91 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.289977
  validation loss:		0.373881
  validation accuracy:		88.70 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.283787
  validation loss:		0.388116
  validation accuracy:		88.26 %
Epoch 1658 of 2000 took 0.097s
  training loss:		0.282946
  validation loss:		0.386328
  validation accuracy:		88.80 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.281695
  validation loss:		0.363346
  validation accuracy:		89.13 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.282297
  validation loss:		0.382908
  validation accuracy:		88.70 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.284685
  validation loss:		0.392446
  validation accuracy:		88.37 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.284754
  validation loss:		0.365492
  validation accuracy:		88.91 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.280248
  validation loss:		0.379755
  validation accuracy:		88.37 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.287415
  validation loss:		0.370423
  validation accuracy:		88.70 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.280083
  validation loss:		0.379193
  validation accuracy:		88.37 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.288354
  validation loss:		0.370757
  validation accuracy:		89.02 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.286377
  validation loss:		0.367709
  validation accuracy:		88.59 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.285495
  validation loss:		0.387939
  validation accuracy:		88.37 %
Epoch 1669 of 2000 took 0.097s
  training loss:		0.285826
  validation loss:		0.386849
  validation accuracy:		88.15 %
Epoch 1670 of 2000 took 0.097s
  training loss:		0.280050
  validation loss:		0.370274
  validation accuracy:		88.91 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.287380
  validation loss:		0.375851
  validation accuracy:		88.48 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.283078
  validation loss:		0.368441
  validation accuracy:		89.02 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.284132
  validation loss:		0.374707
  validation accuracy:		88.70 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.284761
  validation loss:		0.376776
  validation accuracy:		88.70 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.291478
  validation loss:		0.367033
  validation accuracy:		88.91 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.283469
  validation loss:		0.364104
  validation accuracy:		89.02 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.283557
  validation loss:		0.360707
  validation accuracy:		89.57 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.280708
  validation loss:		0.371223
  validation accuracy:		88.80 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.283936
  validation loss:		0.383990
  validation accuracy:		88.04 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.284807
  validation loss:		0.366983
  validation accuracy:		88.59 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.277130
  validation loss:		0.367244
  validation accuracy:		89.02 %
Epoch 1682 of 2000 took 0.097s
  training loss:		0.287427
  validation loss:		0.371494
  validation accuracy:		88.91 %
Epoch 1683 of 2000 took 0.097s
  training loss:		0.282841
  validation loss:		0.377380
  validation accuracy:		88.04 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.281190
  validation loss:		0.395404
  validation accuracy:		88.04 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.283618
  validation loss:		0.370005
  validation accuracy:		88.48 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.288191
  validation loss:		0.384885
  validation accuracy:		88.48 %
Epoch 1687 of 2000 took 0.097s
  training loss:		0.287726
  validation loss:		0.367856
  validation accuracy:		88.04 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.287102
  validation loss:		0.378568
  validation accuracy:		88.70 %
Epoch 1689 of 2000 took 0.097s
  training loss:		0.283761
  validation loss:		0.379580
  validation accuracy:		88.80 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.280642
  validation loss:		0.383444
  validation accuracy:		88.48 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.285258
  validation loss:		0.377051
  validation accuracy:		88.91 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.284389
  validation loss:		0.366946
  validation accuracy:		88.91 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.278458
  validation loss:		0.368033
  validation accuracy:		88.91 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.279664
  validation loss:		0.371793
  validation accuracy:		88.70 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.280873
  validation loss:		0.383481
  validation accuracy:		87.93 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.280551
  validation loss:		0.393149
  validation accuracy:		88.48 %
Epoch 1697 of 2000 took 0.096s
  training loss:		0.284888
  validation loss:		0.386331
  validation accuracy:		88.59 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.286187
  validation loss:		0.398811
  validation accuracy:		87.28 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.278723
  validation loss:		0.366649
  validation accuracy:		89.35 %
Epoch 1700 of 2000 took 0.096s
  training loss:		0.285563
  validation loss:		0.362212
  validation accuracy:		89.02 %
Epoch 1701 of 2000 took 0.097s
  training loss:		0.279016
  validation loss:		0.358258
  validation accuracy:		89.24 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.288084
  validation loss:		0.368789
  validation accuracy:		89.13 %
Epoch 1703 of 2000 took 0.096s
  training loss:		0.288846
  validation loss:		0.370107
  validation accuracy:		88.80 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.282503
  validation loss:		0.387236
  validation accuracy:		88.04 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.285359
  validation loss:		0.369253
  validation accuracy:		88.91 %
Epoch 1706 of 2000 took 0.098s
  training loss:		0.281874
  validation loss:		0.382590
  validation accuracy:		88.70 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.275206
  validation loss:		0.378630
  validation accuracy:		88.48 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.280976
  validation loss:		0.369191
  validation accuracy:		88.37 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.287206
  validation loss:		0.382284
  validation accuracy:		88.15 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.289697
  validation loss:		0.365540
  validation accuracy:		89.35 %
Epoch 1711 of 2000 took 0.096s
  training loss:		0.286314
  validation loss:		0.376098
  validation accuracy:		88.37 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.284493
  validation loss:		0.385910
  validation accuracy:		87.93 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.276795
  validation loss:		0.373544
  validation accuracy:		88.37 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.289408
  validation loss:		0.374422
  validation accuracy:		88.37 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.284225
  validation loss:		0.379647
  validation accuracy:		88.80 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.288631
  validation loss:		0.370821
  validation accuracy:		88.37 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.284688
  validation loss:		0.364351
  validation accuracy:		89.35 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.282384
  validation loss:		0.367741
  validation accuracy:		89.13 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.285498
  validation loss:		0.375001
  validation accuracy:		88.70 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.280189
  validation loss:		0.371636
  validation accuracy:		88.80 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.284826
  validation loss:		0.370793
  validation accuracy:		89.24 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.288780
  validation loss:		0.365896
  validation accuracy:		89.02 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.285286
  validation loss:		0.368917
  validation accuracy:		89.02 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.290677
  validation loss:		0.368939
  validation accuracy:		88.37 %
Epoch 1725 of 2000 took 0.097s
  training loss:		0.281252
  validation loss:		0.377656
  validation accuracy:		88.80 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.285529
  validation loss:		0.387440
  validation accuracy:		87.93 %
Epoch 1727 of 2000 took 0.096s
  training loss:		0.279816
  validation loss:		0.381617
  validation accuracy:		88.37 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.295837
  validation loss:		0.378959
  validation accuracy:		88.80 %
Epoch 1729 of 2000 took 0.099s
  training loss:		0.283428
  validation loss:		0.369593
  validation accuracy:		89.02 %
Epoch 1730 of 2000 took 0.100s
  training loss:		0.283069
  validation loss:		0.379182
  validation accuracy:		88.26 %
Epoch 1731 of 2000 took 0.099s
  training loss:		0.292601
  validation loss:		0.375759
  validation accuracy:		88.91 %
Epoch 1732 of 2000 took 0.100s
  training loss:		0.276821
  validation loss:		0.370160
  validation accuracy:		88.59 %
Epoch 1733 of 2000 took 0.099s
  training loss:		0.277544
  validation loss:		0.370599
  validation accuracy:		89.13 %
Epoch 1734 of 2000 took 0.099s
  training loss:		0.278582
  validation loss:		0.371057
  validation accuracy:		88.70 %
Epoch 1735 of 2000 took 0.099s
  training loss:		0.284142
  validation loss:		0.377807
  validation accuracy:		89.02 %
Epoch 1736 of 2000 took 0.099s
  training loss:		0.280268
  validation loss:		0.369708
  validation accuracy:		88.91 %
Epoch 1737 of 2000 took 0.099s
  training loss:		0.290615
  validation loss:		0.372023
  validation accuracy:		88.80 %
Epoch 1738 of 2000 took 0.099s
  training loss:		0.282262
  validation loss:		0.367556
  validation accuracy:		89.13 %
Epoch 1739 of 2000 took 0.099s
  training loss:		0.281469
  validation loss:		0.369802
  validation accuracy:		89.13 %
Epoch 1740 of 2000 took 0.099s
  training loss:		0.283655
  validation loss:		0.387480
  validation accuracy:		88.59 %
Epoch 1741 of 2000 took 0.099s
  training loss:		0.282156
  validation loss:		0.379756
  validation accuracy:		88.15 %
Epoch 1742 of 2000 took 0.099s
  training loss:		0.283182
  validation loss:		0.378696
  validation accuracy:		88.48 %
Epoch 1743 of 2000 took 0.099s
  training loss:		0.281203
  validation loss:		0.395874
  validation accuracy:		88.37 %
Epoch 1744 of 2000 took 0.099s
  training loss:		0.285052
  validation loss:		0.364282
  validation accuracy:		88.70 %
Epoch 1745 of 2000 took 0.099s
  training loss:		0.290813
  validation loss:		0.382441
  validation accuracy:		88.59 %
Epoch 1746 of 2000 took 0.099s
  training loss:		0.277588
  validation loss:		0.364024
  validation accuracy:		89.46 %
Epoch 1747 of 2000 took 0.099s
  training loss:		0.285090
  validation loss:		0.366115
  validation accuracy:		89.35 %
Epoch 1748 of 2000 took 0.099s
  training loss:		0.281658
  validation loss:		0.377527
  validation accuracy:		88.80 %
Epoch 1749 of 2000 took 0.099s
  training loss:		0.279998
  validation loss:		0.361222
  validation accuracy:		89.46 %
Epoch 1750 of 2000 took 0.099s
  training loss:		0.286159
  validation loss:		0.369744
  validation accuracy:		88.37 %
Epoch 1751 of 2000 took 0.100s
  training loss:		0.287540
  validation loss:		0.386689
  validation accuracy:		88.04 %
Epoch 1752 of 2000 took 0.099s
  training loss:		0.286812
  validation loss:		0.389166
  validation accuracy:		88.59 %
Epoch 1753 of 2000 took 0.099s
  training loss:		0.277797
  validation loss:		0.370697
  validation accuracy:		88.70 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.281042
  validation loss:		0.401562
  validation accuracy:		87.28 %
Epoch 1755 of 2000 took 0.099s
  training loss:		0.286015
  validation loss:		0.377421
  validation accuracy:		89.13 %
Epoch 1756 of 2000 took 0.099s
  training loss:		0.281211
  validation loss:		0.390370
  validation accuracy:		88.15 %
Epoch 1757 of 2000 took 0.099s
  training loss:		0.287407
  validation loss:		0.364424
  validation accuracy:		88.91 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.282738
  validation loss:		0.380370
  validation accuracy:		88.48 %
Epoch 1759 of 2000 took 0.099s
  training loss:		0.286053
  validation loss:		0.390273
  validation accuracy:		88.48 %
Epoch 1760 of 2000 took 0.099s
  training loss:		0.283099
  validation loss:		0.372401
  validation accuracy:		89.02 %
Epoch 1761 of 2000 took 0.099s
  training loss:		0.288656
  validation loss:		0.375699
  validation accuracy:		89.02 %
Epoch 1762 of 2000 took 0.100s
  training loss:		0.281947
  validation loss:		0.375633
  validation accuracy:		88.91 %
Epoch 1763 of 2000 took 0.100s
  training loss:		0.286946
  validation loss:		0.393770
  validation accuracy:		87.83 %
Epoch 1764 of 2000 took 0.099s
  training loss:		0.287429
  validation loss:		0.373994
  validation accuracy:		89.02 %
Epoch 1765 of 2000 took 0.100s
  training loss:		0.286165
  validation loss:		0.361273
  validation accuracy:		89.35 %
Epoch 1766 of 2000 took 0.099s
  training loss:		0.283151
  validation loss:		0.365177
  validation accuracy:		89.13 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.284772
  validation loss:		0.367848
  validation accuracy:		88.80 %
Epoch 1768 of 2000 took 0.099s
  training loss:		0.284601
  validation loss:		0.379343
  validation accuracy:		88.48 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.279038
  validation loss:		0.382592
  validation accuracy:		88.70 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.285638
  validation loss:		0.363129
  validation accuracy:		88.91 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.280910
  validation loss:		0.360950
  validation accuracy:		88.80 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.290328
  validation loss:		0.378072
  validation accuracy:		88.80 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.282136
  validation loss:		0.366976
  validation accuracy:		88.91 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.282380
  validation loss:		0.380079
  validation accuracy:		88.59 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.283185
  validation loss:		0.387263
  validation accuracy:		88.15 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.278845
  validation loss:		0.378423
  validation accuracy:		88.48 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.286971
  validation loss:		0.395514
  validation accuracy:		88.48 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.281439
  validation loss:		0.375888
  validation accuracy:		88.37 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.279896
  validation loss:		0.382711
  validation accuracy:		88.80 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.284962
  validation loss:		0.371228
  validation accuracy:		88.48 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.283876
  validation loss:		0.371790
  validation accuracy:		89.24 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.285577
  validation loss:		0.369076
  validation accuracy:		89.02 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.277110
  validation loss:		0.377264
  validation accuracy:		88.59 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.282303
  validation loss:		0.360403
  validation accuracy:		89.13 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.282051
  validation loss:		0.370681
  validation accuracy:		89.46 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.285671
  validation loss:		0.377908
  validation accuracy:		89.02 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.282968
  validation loss:		0.377032
  validation accuracy:		88.80 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.277717
  validation loss:		0.369489
  validation accuracy:		88.37 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.282086
  validation loss:		0.371892
  validation accuracy:		89.24 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.285055
  validation loss:		0.378301
  validation accuracy:		89.02 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.280941
  validation loss:		0.378998
  validation accuracy:		88.70 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.284559
  validation loss:		0.376361
  validation accuracy:		89.02 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.285814
  validation loss:		0.367491
  validation accuracy:		89.46 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.280295
  validation loss:		0.367296
  validation accuracy:		88.59 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.275904
  validation loss:		0.390200
  validation accuracy:		87.83 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.279482
  validation loss:		0.380248
  validation accuracy:		88.15 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.284868
  validation loss:		0.375593
  validation accuracy:		89.13 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.283508
  validation loss:		0.381315
  validation accuracy:		88.37 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.282016
  validation loss:		0.368537
  validation accuracy:		89.24 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.284634
  validation loss:		0.375374
  validation accuracy:		88.48 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.278137
  validation loss:		0.378318
  validation accuracy:		88.59 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.284042
  validation loss:		0.372404
  validation accuracy:		89.35 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.283109
  validation loss:		0.389995
  validation accuracy:		88.80 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.277549
  validation loss:		0.374526
  validation accuracy:		88.70 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.281440
  validation loss:		0.369851
  validation accuracy:		89.46 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.282248
  validation loss:		0.391908
  validation accuracy:		88.04 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.284926
  validation loss:		0.367871
  validation accuracy:		88.80 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.290347
  validation loss:		0.375402
  validation accuracy:		88.26 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.279492
  validation loss:		0.376604
  validation accuracy:		88.70 %
Epoch 1810 of 2000 took 0.100s
  training loss:		0.289973
  validation loss:		0.390581
  validation accuracy:		88.04 %
Epoch 1811 of 2000 took 0.099s
  training loss:		0.281349
  validation loss:		0.388410
  validation accuracy:		88.37 %
Epoch 1812 of 2000 took 0.100s
  training loss:		0.285417
  validation loss:		0.389817
  validation accuracy:		88.04 %
Epoch 1813 of 2000 took 0.099s
  training loss:		0.283086
  validation loss:		0.388505
  validation accuracy:		88.37 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.280653
  validation loss:		0.360467
  validation accuracy:		89.46 %
Epoch 1815 of 2000 took 0.099s
  training loss:		0.279620
  validation loss:		0.365739
  validation accuracy:		88.70 %
Epoch 1816 of 2000 took 0.099s
  training loss:		0.288290
  validation loss:		0.356721
  validation accuracy:		89.13 %
Epoch 1817 of 2000 took 0.100s
  training loss:		0.281918
  validation loss:		0.375727
  validation accuracy:		88.59 %
Epoch 1818 of 2000 took 0.099s
  training loss:		0.279292
  validation loss:		0.382255
  validation accuracy:		88.04 %
Epoch 1819 of 2000 took 0.099s
  training loss:		0.285241
  validation loss:		0.377106
  validation accuracy:		89.02 %
Epoch 1820 of 2000 took 0.099s
  training loss:		0.278328
  validation loss:		0.367682
  validation accuracy:		89.13 %
Epoch 1821 of 2000 took 0.099s
  training loss:		0.281751
  validation loss:		0.361750
  validation accuracy:		89.02 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.285249
  validation loss:		0.388949
  validation accuracy:		88.37 %
Epoch 1823 of 2000 took 0.099s
  training loss:		0.285086
  validation loss:		0.370879
  validation accuracy:		89.35 %
Epoch 1824 of 2000 took 0.100s
  training loss:		0.289182
  validation loss:		0.366597
  validation accuracy:		88.59 %
Epoch 1825 of 2000 took 0.099s
  training loss:		0.281162
  validation loss:		0.364489
  validation accuracy:		88.91 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.285951
  validation loss:		0.378830
  validation accuracy:		89.24 %
Epoch 1827 of 2000 took 0.099s
  training loss:		0.286247
  validation loss:		0.364725
  validation accuracy:		89.02 %
Epoch 1828 of 2000 took 0.099s
  training loss:		0.284511
  validation loss:		0.374879
  validation accuracy:		88.15 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.271661
  validation loss:		0.376288
  validation accuracy:		89.02 %
Epoch 1830 of 2000 took 0.099s
  training loss:		0.283333
  validation loss:		0.368034
  validation accuracy:		89.57 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.284310
  validation loss:		0.387146
  validation accuracy:		87.72 %
Epoch 1832 of 2000 took 0.099s
  training loss:		0.283404
  validation loss:		0.408806
  validation accuracy:		87.61 %
Epoch 1833 of 2000 took 0.099s
  training loss:		0.282747
  validation loss:		0.371679
  validation accuracy:		88.80 %
Epoch 1834 of 2000 took 0.099s
  training loss:		0.280682
  validation loss:		0.396485
  validation accuracy:		87.83 %
Epoch 1835 of 2000 took 0.099s
  training loss:		0.284333
  validation loss:		0.377671
  validation accuracy:		89.02 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.287783
  validation loss:		0.365912
  validation accuracy:		88.59 %
Epoch 1837 of 2000 took 0.099s
  training loss:		0.288149
  validation loss:		0.372512
  validation accuracy:		89.24 %
Epoch 1838 of 2000 took 0.099s
  training loss:		0.279552
  validation loss:		0.394970
  validation accuracy:		88.37 %
Epoch 1839 of 2000 took 0.099s
  training loss:		0.283080
  validation loss:		0.382141
  validation accuracy:		88.48 %
Epoch 1840 of 2000 took 0.099s
  training loss:		0.275306
  validation loss:		0.371646
  validation accuracy:		88.70 %
Epoch 1841 of 2000 took 0.099s
  training loss:		0.285560
  validation loss:		0.380961
  validation accuracy:		88.48 %
Epoch 1842 of 2000 took 0.100s
  training loss:		0.282348
  validation loss:		0.383266
  validation accuracy:		88.48 %
Epoch 1843 of 2000 took 0.099s
  training loss:		0.289111
  validation loss:		0.386666
  validation accuracy:		88.15 %
Epoch 1844 of 2000 took 0.099s
  training loss:		0.284973
  validation loss:		0.382931
  validation accuracy:		88.37 %
Epoch 1845 of 2000 took 0.099s
  training loss:		0.273429
  validation loss:		0.379644
  validation accuracy:		88.91 %
Epoch 1846 of 2000 took 0.100s
  training loss:		0.285086
  validation loss:		0.365559
  validation accuracy:		89.13 %
Epoch 1847 of 2000 took 0.100s
  training loss:		0.288247
  validation loss:		0.366946
  validation accuracy:		89.46 %
Epoch 1848 of 2000 took 0.099s
  training loss:		0.284236
  validation loss:		0.370196
  validation accuracy:		88.80 %
Epoch 1849 of 2000 took 0.099s
  training loss:		0.281964
  validation loss:		0.363810
  validation accuracy:		89.13 %
Epoch 1850 of 2000 took 0.099s
  training loss:		0.286836
  validation loss:		0.375278
  validation accuracy:		88.37 %
Epoch 1851 of 2000 took 0.099s
  training loss:		0.282024
  validation loss:		0.374869
  validation accuracy:		89.13 %
Epoch 1852 of 2000 took 0.100s
  training loss:		0.284235
  validation loss:		0.372225
  validation accuracy:		89.13 %
Epoch 1853 of 2000 took 0.099s
  training loss:		0.279517
  validation loss:		0.362423
  validation accuracy:		89.24 %
Epoch 1854 of 2000 took 0.100s
  training loss:		0.278847
  validation loss:		0.359676
  validation accuracy:		89.24 %
Epoch 1855 of 2000 took 0.099s
  training loss:		0.280266
  validation loss:		0.408047
  validation accuracy:		87.83 %
Epoch 1856 of 2000 took 0.099s
  training loss:		0.283319
  validation loss:		0.370571
  validation accuracy:		89.13 %
Epoch 1857 of 2000 took 0.099s
  training loss:		0.280281
  validation loss:		0.371199
  validation accuracy:		89.67 %
Epoch 1858 of 2000 took 0.099s
  training loss:		0.279690
  validation loss:		0.380161
  validation accuracy:		88.59 %
Epoch 1859 of 2000 took 0.099s
  training loss:		0.282636
  validation loss:		0.365313
  validation accuracy:		89.24 %
Epoch 1860 of 2000 took 0.099s
  training loss:		0.285631
  validation loss:		0.368092
  validation accuracy:		89.13 %
Epoch 1861 of 2000 took 0.099s
  training loss:		0.285627
  validation loss:		0.371984
  validation accuracy:		89.02 %
Epoch 1862 of 2000 took 0.100s
  training loss:		0.278945
  validation loss:		0.381596
  validation accuracy:		88.91 %
Epoch 1863 of 2000 took 0.099s
  training loss:		0.291838
  validation loss:		0.367887
  validation accuracy:		89.35 %
Epoch 1864 of 2000 took 0.099s
  training loss:		0.282445
  validation loss:		0.364746
  validation accuracy:		89.24 %
Epoch 1865 of 2000 took 0.099s
  training loss:		0.286920
  validation loss:		0.377791
  validation accuracy:		88.80 %
Epoch 1866 of 2000 took 0.099s
  training loss:		0.284013
  validation loss:		0.372059
  validation accuracy:		89.13 %
Epoch 1867 of 2000 took 0.099s
  training loss:		0.284716
  validation loss:		0.363529
  validation accuracy:		88.80 %
Epoch 1868 of 2000 took 0.099s
  training loss:		0.286472
  validation loss:		0.362385
  validation accuracy:		89.57 %
Epoch 1869 of 2000 took 0.099s
  training loss:		0.281694
  validation loss:		0.384025
  validation accuracy:		88.48 %
Epoch 1870 of 2000 took 0.099s
  training loss:		0.281065
  validation loss:		0.375039
  validation accuracy:		89.35 %
Epoch 1871 of 2000 took 0.099s
  training loss:		0.280052
  validation loss:		0.368529
  validation accuracy:		89.67 %
Epoch 1872 of 2000 took 0.099s
  training loss:		0.287290
  validation loss:		0.370886
  validation accuracy:		88.91 %
Epoch 1873 of 2000 took 0.099s
  training loss:		0.284144
  validation loss:		0.379405
  validation accuracy:		88.80 %
Epoch 1874 of 2000 took 0.099s
  training loss:		0.275596
  validation loss:		0.365382
  validation accuracy:		89.57 %
Epoch 1875 of 2000 took 0.099s
  training loss:		0.283331
  validation loss:		0.413464
  validation accuracy:		87.07 %
Epoch 1876 of 2000 took 0.099s
  training loss:		0.283892
  validation loss:		0.394394
  validation accuracy:		87.93 %
Epoch 1877 of 2000 took 0.099s
  training loss:		0.282134
  validation loss:		0.360710
  validation accuracy:		89.02 %
Epoch 1878 of 2000 took 0.099s
  training loss:		0.280194
  validation loss:		0.370362
  validation accuracy:		89.46 %
Epoch 1879 of 2000 took 0.099s
  training loss:		0.277068
  validation loss:		0.367629
  validation accuracy:		88.59 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.275302
  validation loss:		0.381177
  validation accuracy:		88.48 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.284157
  validation loss:		0.367880
  validation accuracy:		89.13 %
Epoch 1882 of 2000 took 0.103s
  training loss:		0.281073
  validation loss:		0.365832
  validation accuracy:		89.02 %
Epoch 1883 of 2000 took 0.103s
  training loss:		0.281300
  validation loss:		0.374327
  validation accuracy:		89.35 %
Epoch 1884 of 2000 took 0.126s
  training loss:		0.281063
  validation loss:		0.378023
  validation accuracy:		89.13 %
Epoch 1885 of 2000 took 0.117s
  training loss:		0.281764
  validation loss:		0.367604
  validation accuracy:		88.59 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.288792
  validation loss:		0.390335
  validation accuracy:		88.48 %
Epoch 1887 of 2000 took 0.099s
  training loss:		0.281110
  validation loss:		0.367701
  validation accuracy:		89.13 %
Epoch 1888 of 2000 took 0.102s
  training loss:		0.283294
  validation loss:		0.395445
  validation accuracy:		88.59 %
Epoch 1889 of 2000 took 0.100s
  training loss:		0.286765
  validation loss:		0.371952
  validation accuracy:		89.13 %
Epoch 1890 of 2000 took 0.100s
  training loss:		0.280321
  validation loss:		0.373686
  validation accuracy:		89.35 %
Epoch 1891 of 2000 took 0.100s
  training loss:		0.280018
  validation loss:		0.373218
  validation accuracy:		89.13 %
Epoch 1892 of 2000 took 0.097s
  training loss:		0.279121
  validation loss:		0.367546
  validation accuracy:		88.59 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.286886
  validation loss:		0.367188
  validation accuracy:		88.80 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.281855
  validation loss:		0.375253
  validation accuracy:		88.26 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.281275
  validation loss:		0.393022
  validation accuracy:		87.83 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.283937
  validation loss:		0.384605
  validation accuracy:		88.48 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.283467
  validation loss:		0.368683
  validation accuracy:		88.91 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.282639
  validation loss:		0.362968
  validation accuracy:		89.67 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.289391
  validation loss:		0.384003
  validation accuracy:		88.04 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.277585
  validation loss:		0.380877
  validation accuracy:		88.70 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.275349
  validation loss:		0.362682
  validation accuracy:		89.24 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.288150
  validation loss:		0.375109
  validation accuracy:		88.48 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.286389
  validation loss:		0.366803
  validation accuracy:		89.13 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.279237
  validation loss:		0.371751
  validation accuracy:		89.35 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.280165
  validation loss:		0.381295
  validation accuracy:		88.91 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.283003
  validation loss:		0.368545
  validation accuracy:		89.02 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.287856
  validation loss:		0.378626
  validation accuracy:		88.15 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.277089
  validation loss:		0.366239
  validation accuracy:		89.46 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.293454
  validation loss:		0.377542
  validation accuracy:		89.13 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.284246
  validation loss:		0.386590
  validation accuracy:		88.15 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.285584
  validation loss:		0.383033
  validation accuracy:		88.15 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.289427
  validation loss:		0.364758
  validation accuracy:		88.91 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.288859
  validation loss:		0.375562
  validation accuracy:		88.70 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.284095
  validation loss:		0.374555
  validation accuracy:		88.59 %
Epoch 1915 of 2000 took 0.099s
  training loss:		0.285286
  validation loss:		0.379307
  validation accuracy:		89.13 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.286509
  validation loss:		0.368211
  validation accuracy:		88.91 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.283729
  validation loss:		0.364088
  validation accuracy:		89.02 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.285977
  validation loss:		0.367448
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.279863
  validation loss:		0.362971
  validation accuracy:		89.35 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.280556
  validation loss:		0.373347
  validation accuracy:		89.13 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.287447
  validation loss:		0.393188
  validation accuracy:		87.61 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.282706
  validation loss:		0.387945
  validation accuracy:		88.04 %
Epoch 1923 of 2000 took 0.097s
  training loss:		0.289005
  validation loss:		0.373337
  validation accuracy:		89.46 %
Epoch 1924 of 2000 took 0.097s
  training loss:		0.277628
  validation loss:		0.361434
  validation accuracy:		89.02 %
Epoch 1925 of 2000 took 0.147s
  training loss:		0.280883
  validation loss:		0.375879
  validation accuracy:		89.13 %
Epoch 1926 of 2000 took 0.165s
  training loss:		0.284601
  validation loss:		0.373935
  validation accuracy:		89.24 %
Epoch 1927 of 2000 took 0.165s
  training loss:		0.287450
  validation loss:		0.369137
  validation accuracy:		88.80 %
Epoch 1928 of 2000 took 0.165s
  training loss:		0.291954
  validation loss:		0.393446
  validation accuracy:		88.59 %
Epoch 1929 of 2000 took 0.165s
  training loss:		0.281332
  validation loss:		0.375383
  validation accuracy:		89.24 %
Epoch 1930 of 2000 took 0.165s
  training loss:		0.281662
  validation loss:		0.379102
  validation accuracy:		89.02 %
Epoch 1931 of 2000 took 0.165s
  training loss:		0.281034
  validation loss:		0.378336
  validation accuracy:		88.80 %
Epoch 1932 of 2000 took 0.165s
  training loss:		0.281083
  validation loss:		0.367086
  validation accuracy:		88.70 %
Epoch 1933 of 2000 took 0.165s
  training loss:		0.285999
  validation loss:		0.366058
  validation accuracy:		89.46 %
Epoch 1934 of 2000 took 0.165s
  training loss:		0.284137
  validation loss:		0.382798
  validation accuracy:		88.04 %
Epoch 1935 of 2000 took 0.165s
  training loss:		0.281562
  validation loss:		0.377234
  validation accuracy:		88.80 %
Epoch 1936 of 2000 took 0.165s
  training loss:		0.281578
  validation loss:		0.376705
  validation accuracy:		89.13 %
Epoch 1937 of 2000 took 0.165s
  training loss:		0.284513
  validation loss:		0.374411
  validation accuracy:		88.59 %
Epoch 1938 of 2000 took 0.205s
  training loss:		0.283812
  validation loss:		0.378804
  validation accuracy:		88.80 %
Epoch 1939 of 2000 took 0.181s
  training loss:		0.275791
  validation loss:		0.367210
  validation accuracy:		88.91 %
Epoch 1940 of 2000 took 0.195s
  training loss:		0.284711
  validation loss:		0.360822
  validation accuracy:		89.02 %
Epoch 1941 of 2000 took 0.193s
  training loss:		0.289352
  validation loss:		0.366285
  validation accuracy:		89.13 %
Epoch 1942 of 2000 took 0.223s
  training loss:		0.284296
  validation loss:		0.371770
  validation accuracy:		88.80 %
Epoch 1943 of 2000 took 0.199s
  training loss:		0.286775
  validation loss:		0.375147
  validation accuracy:		89.35 %
Epoch 1944 of 2000 took 0.219s
  training loss:		0.282548
  validation loss:		0.382365
  validation accuracy:		88.37 %
Epoch 1945 of 2000 took 0.346s
  training loss:		0.280365
  validation loss:		0.368282
  validation accuracy:		89.35 %
Epoch 1946 of 2000 took 0.173s
  training loss:		0.277155
  validation loss:		0.373258
  validation accuracy:		89.24 %
Epoch 1947 of 2000 took 0.170s
  training loss:		0.282245
  validation loss:		0.371662
  validation accuracy:		89.46 %
Epoch 1948 of 2000 took 0.173s
  training loss:		0.284100
  validation loss:		0.378586
  validation accuracy:		88.70 %
Epoch 1949 of 2000 took 0.171s
  training loss:		0.282248
  validation loss:		0.395330
  validation accuracy:		87.50 %
Epoch 1950 of 2000 took 0.168s
  training loss:		0.287218
  validation loss:		0.387496
  validation accuracy:		87.93 %
Epoch 1951 of 2000 took 0.168s
  training loss:		0.279059
  validation loss:		0.380537
  validation accuracy:		88.48 %
Epoch 1952 of 2000 took 0.168s
  training loss:		0.280245
  validation loss:		0.377677
  validation accuracy:		88.91 %
Epoch 1953 of 2000 took 0.171s
  training loss:		0.281439
  validation loss:		0.369772
  validation accuracy:		89.02 %
Epoch 1954 of 2000 took 0.168s
  training loss:		0.285041
  validation loss:		0.367542
  validation accuracy:		88.48 %
Epoch 1955 of 2000 took 0.168s
  training loss:		0.278434
  validation loss:		0.365514
  validation accuracy:		88.80 %
Epoch 1956 of 2000 took 0.172s
  training loss:		0.286044
  validation loss:		0.363471
  validation accuracy:		89.57 %
Epoch 1957 of 2000 took 0.168s
  training loss:		0.282243
  validation loss:		0.389156
  validation accuracy:		88.48 %
Epoch 1958 of 2000 took 0.168s
  training loss:		0.279456
  validation loss:		0.395444
  validation accuracy:		88.37 %
Epoch 1959 of 2000 took 0.168s
  training loss:		0.286233
  validation loss:		0.379314
  validation accuracy:		88.59 %
Epoch 1960 of 2000 took 0.169s
  training loss:		0.279726
  validation loss:		0.370692
  validation accuracy:		89.13 %
Epoch 1961 of 2000 took 0.170s
  training loss:		0.279442
  validation loss:		0.384401
  validation accuracy:		88.26 %
Epoch 1962 of 2000 took 0.166s
  training loss:		0.285268
  validation loss:		0.380967
  validation accuracy:		88.26 %
Epoch 1963 of 2000 took 0.169s
  training loss:		0.279818
  validation loss:		0.365846
  validation accuracy:		89.57 %
Epoch 1964 of 2000 took 0.186s
  training loss:		0.279806
  validation loss:		0.365061
  validation accuracy:		89.13 %
Epoch 1965 of 2000 took 0.170s
  training loss:		0.281708
  validation loss:		0.373579
  validation accuracy:		89.02 %
Epoch 1966 of 2000 took 0.169s
  training loss:		0.282124
  validation loss:		0.366433
  validation accuracy:		89.78 %
Epoch 1967 of 2000 took 0.172s
  training loss:		0.284310
  validation loss:		0.357563
  validation accuracy:		89.13 %
Epoch 1968 of 2000 took 0.182s
  training loss:		0.282507
  validation loss:		0.367249
  validation accuracy:		89.24 %
Epoch 1969 of 2000 took 0.171s
  training loss:		0.278131
  validation loss:		0.379993
  validation accuracy:		89.13 %
Epoch 1970 of 2000 took 0.171s
  training loss:		0.282474
  validation loss:		0.360382
  validation accuracy:		88.91 %
Epoch 1971 of 2000 took 0.283s
  training loss:		0.285495
  validation loss:		0.365025
  validation accuracy:		89.46 %
Epoch 1972 of 2000 took 0.171s
  training loss:		0.281226
  validation loss:		0.377101
  validation accuracy:		88.26 %
Epoch 1973 of 2000 took 0.254s
  training loss:		0.277382
  validation loss:		0.385641
  validation accuracy:		88.37 %
Epoch 1974 of 2000 took 0.179s
  training loss:		0.272111
  validation loss:		0.392273
  validation accuracy:		88.37 %
Epoch 1975 of 2000 took 0.170s
  training loss:		0.278397
  validation loss:		0.371410
  validation accuracy:		89.35 %
Epoch 1976 of 2000 took 0.167s
  training loss:		0.280284
  validation loss:		0.388881
  validation accuracy:		88.15 %
Epoch 1977 of 2000 took 0.168s
  training loss:		0.279529
  validation loss:		0.374747
  validation accuracy:		88.59 %
Epoch 1978 of 2000 took 0.170s
  training loss:		0.285196
  validation loss:		0.368985
  validation accuracy:		89.24 %
Epoch 1979 of 2000 took 0.167s
  training loss:		0.281107
  validation loss:		0.384013
  validation accuracy:		88.91 %
Epoch 1980 of 2000 took 0.168s
  training loss:		0.278131
  validation loss:		0.372713
  validation accuracy:		89.35 %
Epoch 1981 of 2000 took 0.211s
  training loss:		0.279510
  validation loss:		0.368640
  validation accuracy:		89.24 %
Epoch 1982 of 2000 took 0.174s
  training loss:		0.286373
  validation loss:		0.370290
  validation accuracy:		89.57 %
Epoch 1983 of 2000 took 0.202s
  training loss:		0.281491
  validation loss:		0.374942
  validation accuracy:		89.67 %
Epoch 1984 of 2000 took 0.172s
  training loss:		0.283643
  validation loss:		0.372239
  validation accuracy:		88.70 %
Epoch 1985 of 2000 took 0.171s
  training loss:		0.286141
  validation loss:		0.372072
  validation accuracy:		88.91 %
Epoch 1986 of 2000 took 0.168s
  training loss:		0.277982
  validation loss:		0.375900
  validation accuracy:		89.35 %
Epoch 1987 of 2000 took 0.169s
  training loss:		0.284408
  validation loss:		0.371940
  validation accuracy:		89.13 %
Epoch 1988 of 2000 took 0.167s
  training loss:		0.285182
  validation loss:		0.368818
  validation accuracy:		89.02 %
Epoch 1989 of 2000 took 0.172s
  training loss:		0.280069
  validation loss:		0.390652
  validation accuracy:		88.48 %
Epoch 1990 of 2000 took 0.168s
  training loss:		0.284295
  validation loss:		0.376065
  validation accuracy:		89.13 %
Epoch 1991 of 2000 took 0.167s
  training loss:		0.277118
  validation loss:		0.368481
  validation accuracy:		89.02 %
Epoch 1992 of 2000 took 0.165s
  training loss:		0.275165
  validation loss:		0.372595
  validation accuracy:		89.24 %
Epoch 1993 of 2000 took 0.165s
  training loss:		0.284614
  validation loss:		0.363636
  validation accuracy:		89.57 %
Epoch 1994 of 2000 took 0.165s
  training loss:		0.277114
  validation loss:		0.378413
  validation accuracy:		88.59 %
Epoch 1995 of 2000 took 0.165s
  training loss:		0.281054
  validation loss:		0.384242
  validation accuracy:		88.37 %
Epoch 1996 of 2000 took 0.165s
  training loss:		0.281504
  validation loss:		0.384192
  validation accuracy:		89.02 %
Epoch 1997 of 2000 took 0.165s
  training loss:		0.281277
  validation loss:		0.368815
  validation accuracy:		89.13 %
Epoch 1998 of 2000 took 0.165s
  training loss:		0.280328
  validation loss:		0.377813
  validation accuracy:		88.80 %
Epoch 1999 of 2000 took 0.165s
  training loss:		0.284704
  validation loss:		0.370768
  validation accuracy:		89.02 %
Epoch 2000 of 2000 took 0.181s
  training loss:		0.276948
  validation loss:		0.370372
  validation accuracy:		88.91 %
Final results:
  test loss:			0.720649
  test accuracy:		79.88 %
