Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.104s
  training loss:		2.990061
  validation loss:		2.966194
  validation accuracy:		11.09 %
Epoch 2 of 2000 took 0.099s
  training loss:		2.958157
  validation loss:		2.923897
  validation accuracy:		7.39 %
Epoch 3 of 2000 took 0.100s
  training loss:		2.916001
  validation loss:		2.875498
  validation accuracy:		10.43 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.870090
  validation loss:		2.824324
  validation accuracy:		12.07 %
Epoch 5 of 2000 took 0.099s
  training loss:		2.823023
  validation loss:		2.769501
  validation accuracy:		12.93 %
Epoch 6 of 2000 took 0.100s
  training loss:		2.770790
  validation loss:		2.710218
  validation accuracy:		13.04 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.714946
  validation loss:		2.646105
  validation accuracy:		13.04 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.653876
  validation loss:		2.577774
  validation accuracy:		13.04 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.587934
  validation loss:		2.507030
  validation accuracy:		13.04 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.527094
  validation loss:		2.437092
  validation accuracy:		13.04 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.463818
  validation loss:		2.371371
  validation accuracy:		13.04 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.406797
  validation loss:		2.316210
  validation accuracy:		13.04 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.358482
  validation loss:		2.273788
  validation accuracy:		18.37 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.324815
  validation loss:		2.249539
  validation accuracy:		30.98 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.300877
  validation loss:		2.232349
  validation accuracy:		28.59 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.284718
  validation loss:		2.218792
  validation accuracy:		29.78 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.274020
  validation loss:		2.213479
  validation accuracy:		27.83 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.265274
  validation loss:		2.208958
  validation accuracy:		25.54 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.258254
  validation loss:		2.207513
  validation accuracy:		32.61 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.249612
  validation loss:		2.195848
  validation accuracy:		29.89 %
Epoch 21 of 2000 took 0.101s
  training loss:		2.244353
  validation loss:		2.189693
  validation accuracy:		33.04 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.235489
  validation loss:		2.181135
  validation accuracy:		31.96 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.229036
  validation loss:		2.173065
  validation accuracy:		34.02 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.222124
  validation loss:		2.166517
  validation accuracy:		34.24 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.213464
  validation loss:		2.156998
  validation accuracy:		36.41 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.205684
  validation loss:		2.144634
  validation accuracy:		37.07 %
Epoch 27 of 2000 took 0.098s
  training loss:		2.195785
  validation loss:		2.134285
  validation accuracy:		34.46 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.184715
  validation loss:		2.127264
  validation accuracy:		34.46 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.173060
  validation loss:		2.113952
  validation accuracy:		35.22 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.159850
  validation loss:		2.095674
  validation accuracy:		37.07 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.144064
  validation loss:		2.078341
  validation accuracy:		36.20 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.127476
  validation loss:		2.061409
  validation accuracy:		35.00 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.107257
  validation loss:		2.042022
  validation accuracy:		35.11 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.089021
  validation loss:		2.014864
  validation accuracy:		36.96 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.068799
  validation loss:		1.994049
  validation accuracy:		37.07 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.045439
  validation loss:		1.968287
  validation accuracy:		37.39 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.019467
  validation loss:		1.940643
  validation accuracy:		38.91 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.991274
  validation loss:		1.908531
  validation accuracy:		39.67 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.961706
  validation loss:		1.878206
  validation accuracy:		39.13 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.936179
  validation loss:		1.846884
  validation accuracy:		39.24 %
Epoch 41 of 2000 took 0.101s
  training loss:		1.904215
  validation loss:		1.818530
  validation accuracy:		41.63 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.877016
  validation loss:		1.785283
  validation accuracy:		42.17 %
Epoch 43 of 2000 took 0.097s
  training loss:		1.851115
  validation loss:		1.759806
  validation accuracy:		41.20 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.821759
  validation loss:		1.725654
  validation accuracy:		43.48 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.798277
  validation loss:		1.703210
  validation accuracy:		43.26 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.772523
  validation loss:		1.678872
  validation accuracy:		45.98 %
Epoch 47 of 2000 took 0.100s
  training loss:		1.747935
  validation loss:		1.655637
  validation accuracy:		45.98 %
Epoch 48 of 2000 took 0.100s
  training loss:		1.725864
  validation loss:		1.625631
  validation accuracy:		46.63 %
Epoch 49 of 2000 took 0.100s
  training loss:		1.707953
  validation loss:		1.605262
  validation accuracy:		47.72 %
Epoch 50 of 2000 took 0.100s
  training loss:		1.687261
  validation loss:		1.578772
  validation accuracy:		48.59 %
Epoch 51 of 2000 took 0.100s
  training loss:		1.663806
  validation loss:		1.556881
  validation accuracy:		49.46 %
Epoch 52 of 2000 took 0.100s
  training loss:		1.639200
  validation loss:		1.537427
  validation accuracy:		51.20 %
Epoch 53 of 2000 took 0.098s
  training loss:		1.622057
  validation loss:		1.510377
  validation accuracy:		51.52 %
Epoch 54 of 2000 took 0.097s
  training loss:		1.605533
  validation loss:		1.491997
  validation accuracy:		52.07 %
Epoch 55 of 2000 took 0.097s
  training loss:		1.578702
  validation loss:		1.465263
  validation accuracy:		53.48 %
Epoch 56 of 2000 took 0.097s
  training loss:		1.558694
  validation loss:		1.451700
  validation accuracy:		54.24 %
Epoch 57 of 2000 took 0.101s
  training loss:		1.539989
  validation loss:		1.433523
  validation accuracy:		53.80 %
Epoch 58 of 2000 took 0.098s
  training loss:		1.518097
  validation loss:		1.412494
  validation accuracy:		56.30 %
Epoch 59 of 2000 took 0.097s
  training loss:		1.503461
  validation loss:		1.388559
  validation accuracy:		55.65 %
Epoch 60 of 2000 took 0.097s
  training loss:		1.480336
  validation loss:		1.375261
  validation accuracy:		56.20 %
Epoch 61 of 2000 took 0.097s
  training loss:		1.457053
  validation loss:		1.348267
  validation accuracy:		57.61 %
Epoch 62 of 2000 took 0.097s
  training loss:		1.445156
  validation loss:		1.327300
  validation accuracy:		57.61 %
Epoch 63 of 2000 took 0.097s
  training loss:		1.422298
  validation loss:		1.310867
  validation accuracy:		57.28 %
Epoch 64 of 2000 took 0.097s
  training loss:		1.405087
  validation loss:		1.298208
  validation accuracy:		58.48 %
Epoch 65 of 2000 took 0.097s
  training loss:		1.384332
  validation loss:		1.277987
  validation accuracy:		59.13 %
Epoch 66 of 2000 took 0.097s
  training loss:		1.364227
  validation loss:		1.251520
  validation accuracy:		59.24 %
Epoch 67 of 2000 took 0.097s
  training loss:		1.343401
  validation loss:		1.245356
  validation accuracy:		60.54 %
Epoch 68 of 2000 took 0.097s
  training loss:		1.332853
  validation loss:		1.212387
  validation accuracy:		60.87 %
Epoch 69 of 2000 took 0.097s
  training loss:		1.303932
  validation loss:		1.193547
  validation accuracy:		61.63 %
Epoch 70 of 2000 took 0.097s
  training loss:		1.288490
  validation loss:		1.187535
  validation accuracy:		61.09 %
Epoch 71 of 2000 took 0.101s
  training loss:		1.265354
  validation loss:		1.153804
  validation accuracy:		61.96 %
Epoch 72 of 2000 took 0.098s
  training loss:		1.255773
  validation loss:		1.142565
  validation accuracy:		63.80 %
Epoch 73 of 2000 took 0.097s
  training loss:		1.237058
  validation loss:		1.138930
  validation accuracy:		62.50 %
Epoch 74 of 2000 took 0.097s
  training loss:		1.217772
  validation loss:		1.109798
  validation accuracy:		63.70 %
Epoch 75 of 2000 took 0.097s
  training loss:		1.203453
  validation loss:		1.093689
  validation accuracy:		62.83 %
Epoch 76 of 2000 took 0.097s
  training loss:		1.182126
  validation loss:		1.078439
  validation accuracy:		65.54 %
Epoch 77 of 2000 took 0.097s
  training loss:		1.171954
  validation loss:		1.064144
  validation accuracy:		65.00 %
Epoch 78 of 2000 took 0.097s
  training loss:		1.149771
  validation loss:		1.046869
  validation accuracy:		64.13 %
Epoch 79 of 2000 took 0.097s
  training loss:		1.147822
  validation loss:		1.038801
  validation accuracy:		66.09 %
Epoch 80 of 2000 took 0.097s
  training loss:		1.119520
  validation loss:		1.026652
  validation accuracy:		65.22 %
Epoch 81 of 2000 took 0.097s
  training loss:		1.113268
  validation loss:		1.006979
  validation accuracy:		67.17 %
Epoch 82 of 2000 took 0.097s
  training loss:		1.090047
  validation loss:		0.987171
  validation accuracy:		67.61 %
Epoch 83 of 2000 took 0.097s
  training loss:		1.087944
  validation loss:		0.991562
  validation accuracy:		65.65 %
Epoch 84 of 2000 took 0.101s
  training loss:		1.067446
  validation loss:		0.968852
  validation accuracy:		67.39 %
Epoch 85 of 2000 took 0.098s
  training loss:		1.056792
  validation loss:		0.962442
  validation accuracy:		66.96 %
Epoch 86 of 2000 took 0.097s
  training loss:		1.041997
  validation loss:		0.944036
  validation accuracy:		67.07 %
Epoch 87 of 2000 took 0.097s
  training loss:		1.025762
  validation loss:		0.932582
  validation accuracy:		68.26 %
Epoch 88 of 2000 took 0.097s
  training loss:		1.015715
  validation loss:		0.915250
  validation accuracy:		68.15 %
Epoch 89 of 2000 took 0.098s
  training loss:		1.000656
  validation loss:		0.911198
  validation accuracy:		68.37 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.991060
  validation loss:		0.893916
  validation accuracy:		68.70 %
Epoch 91 of 2000 took 0.097s
  training loss:		0.974874
  validation loss:		0.878806
  validation accuracy:		69.89 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.965095
  validation loss:		0.873586
  validation accuracy:		69.89 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.954259
  validation loss:		0.854079
  validation accuracy:		70.33 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.947426
  validation loss:		0.855215
  validation accuracy:		70.00 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.934402
  validation loss:		0.840591
  validation accuracy:		70.98 %
Epoch 96 of 2000 took 0.102s
  training loss:		0.925185
  validation loss:		0.825451
  validation accuracy:		71.09 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.920873
  validation loss:		0.820326
  validation accuracy:		71.41 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.903695
  validation loss:		0.813966
  validation accuracy:		71.41 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.888073
  validation loss:		0.802059
  validation accuracy:		71.41 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.880592
  validation loss:		0.792154
  validation accuracy:		71.41 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.875395
  validation loss:		0.798554
  validation accuracy:		72.07 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.867969
  validation loss:		0.781698
  validation accuracy:		72.39 %
Epoch 103 of 2000 took 0.097s
  training loss:		0.851653
  validation loss:		0.772755
  validation accuracy:		71.74 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.849127
  validation loss:		0.766459
  validation accuracy:		71.96 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.834785
  validation loss:		0.770650
  validation accuracy:		72.07 %
Epoch 106 of 2000 took 0.098s
  training loss:		0.838034
  validation loss:		0.751135
  validation accuracy:		72.83 %
Epoch 107 of 2000 took 0.099s
  training loss:		0.820400
  validation loss:		0.743234
  validation accuracy:		73.26 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.815019
  validation loss:		0.726522
  validation accuracy:		73.80 %
Epoch 109 of 2000 took 0.097s
  training loss:		0.809415
  validation loss:		0.722662
  validation accuracy:		74.35 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.794658
  validation loss:		0.716947
  validation accuracy:		75.11 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.786061
  validation loss:		0.706938
  validation accuracy:		74.24 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.779533
  validation loss:		0.717306
  validation accuracy:		75.76 %
Epoch 113 of 2000 took 0.097s
  training loss:		0.772341
  validation loss:		0.698317
  validation accuracy:		74.89 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.768889
  validation loss:		0.697144
  validation accuracy:		75.22 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.762336
  validation loss:		0.682311
  validation accuracy:		76.09 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.753007
  validation loss:		0.681920
  validation accuracy:		75.76 %
Epoch 117 of 2000 took 0.101s
  training loss:		0.746900
  validation loss:		0.674371
  validation accuracy:		76.74 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.736970
  validation loss:		0.681210
  validation accuracy:		77.28 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.730667
  validation loss:		0.660865
  validation accuracy:		77.39 %
Epoch 120 of 2000 took 0.098s
  training loss:		0.731026
  validation loss:		0.639981
  validation accuracy:		78.91 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.712487
  validation loss:		0.638045
  validation accuracy:		77.93 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.704525
  validation loss:		0.644368
  validation accuracy:		78.15 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.708363
  validation loss:		0.623113
  validation accuracy:		79.35 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.690933
  validation loss:		0.621804
  validation accuracy:		80.11 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.692034
  validation loss:		0.618620
  validation accuracy:		79.35 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.692553
  validation loss:		0.610041
  validation accuracy:		80.76 %
Epoch 127 of 2000 took 0.101s
  training loss:		0.676939
  validation loss:		0.618931
  validation accuracy:		79.13 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.669657
  validation loss:		0.603449
  validation accuracy:		79.57 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.663885
  validation loss:		0.599225
  validation accuracy:		80.65 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.654825
  validation loss:		0.586724
  validation accuracy:		81.52 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.657970
  validation loss:		0.589771
  validation accuracy:		80.76 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.653737
  validation loss:		0.585253
  validation accuracy:		81.30 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.639104
  validation loss:		0.594383
  validation accuracy:		80.22 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.637638
  validation loss:		0.564467
  validation accuracy:		82.07 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.630196
  validation loss:		0.563685
  validation accuracy:		81.74 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.620907
  validation loss:		0.585773
  validation accuracy:		81.09 %
Epoch 137 of 2000 took 0.101s
  training loss:		0.626609
  validation loss:		0.565553
  validation accuracy:		81.63 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.613425
  validation loss:		0.553317
  validation accuracy:		82.17 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.619693
  validation loss:		0.542107
  validation accuracy:		82.61 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.611839
  validation loss:		0.549118
  validation accuracy:		81.85 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.600363
  validation loss:		0.540427
  validation accuracy:		82.28 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.599679
  validation loss:		0.542712
  validation accuracy:		82.28 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.592890
  validation loss:		0.540887
  validation accuracy:		82.61 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.592408
  validation loss:		0.526426
  validation accuracy:		83.04 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.594743
  validation loss:		0.520155
  validation accuracy:		83.37 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.593626
  validation loss:		0.521020
  validation accuracy:		83.80 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.576791
  validation loss:		0.521820
  validation accuracy:		83.37 %
Epoch 148 of 2000 took 0.101s
  training loss:		0.575751
  validation loss:		0.533546
  validation accuracy:		83.15 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.574329
  validation loss:		0.540650
  validation accuracy:		83.26 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.572477
  validation loss:		0.514820
  validation accuracy:		83.26 %
Epoch 151 of 2000 took 0.098s
  training loss:		0.568225
  validation loss:		0.512839
  validation accuracy:		84.46 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.562522
  validation loss:		0.508905
  validation accuracy:		83.70 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.558356
  validation loss:		0.524371
  validation accuracy:		83.80 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.547130
  validation loss:		0.501014
  validation accuracy:		83.80 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.557347
  validation loss:		0.490961
  validation accuracy:		84.46 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.549771
  validation loss:		0.505074
  validation accuracy:		84.02 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.544600
  validation loss:		0.502862
  validation accuracy:		84.13 %
Epoch 158 of 2000 took 0.101s
  training loss:		0.536553
  validation loss:		0.518072
  validation accuracy:		83.37 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.528071
  validation loss:		0.489777
  validation accuracy:		84.57 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.545502
  validation loss:		0.488090
  validation accuracy:		84.46 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.533314
  validation loss:		0.483967
  validation accuracy:		84.57 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.526002
  validation loss:		0.475151
  validation accuracy:		85.43 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.532320
  validation loss:		0.495342
  validation accuracy:		84.57 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.519687
  validation loss:		0.486542
  validation accuracy:		84.78 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.522403
  validation loss:		0.475148
  validation accuracy:		85.00 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.515655
  validation loss:		0.475473
  validation accuracy:		85.11 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.507586
  validation loss:		0.465396
  validation accuracy:		85.33 %
Epoch 168 of 2000 took 0.101s
  training loss:		0.508484
  validation loss:		0.485382
  validation accuracy:		84.89 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.494126
  validation loss:		0.461318
  validation accuracy:		85.65 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.504504
  validation loss:		0.461029
  validation accuracy:		85.87 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.502716
  validation loss:		0.456912
  validation accuracy:		86.09 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.493083
  validation loss:		0.452020
  validation accuracy:		85.98 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.492592
  validation loss:		0.470117
  validation accuracy:		85.33 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.490197
  validation loss:		0.460449
  validation accuracy:		85.11 %
Epoch 175 of 2000 took 0.098s
  training loss:		0.487342
  validation loss:		0.458607
  validation accuracy:		85.65 %
Epoch 176 of 2000 took 0.102s
  training loss:		0.489790
  validation loss:		0.476751
  validation accuracy:		85.00 %
Epoch 177 of 2000 took 0.103s
  training loss:		0.484462
  validation loss:		0.436268
  validation accuracy:		86.63 %
Epoch 178 of 2000 took 0.107s
  training loss:		0.481818
  validation loss:		0.468278
  validation accuracy:		84.89 %
Epoch 179 of 2000 took 0.104s
  training loss:		0.481227
  validation loss:		0.443713
  validation accuracy:		86.41 %
Epoch 180 of 2000 took 0.103s
  training loss:		0.474330
  validation loss:		0.461051
  validation accuracy:		85.65 %
Epoch 181 of 2000 took 0.103s
  training loss:		0.477465
  validation loss:		0.436834
  validation accuracy:		86.85 %
Epoch 182 of 2000 took 0.104s
  training loss:		0.469413
  validation loss:		0.434770
  validation accuracy:		86.85 %
Epoch 183 of 2000 took 0.103s
  training loss:		0.474141
  validation loss:		0.444133
  validation accuracy:		85.98 %
Epoch 184 of 2000 took 0.103s
  training loss:		0.463092
  validation loss:		0.436584
  validation accuracy:		86.74 %
Epoch 185 of 2000 took 0.103s
  training loss:		0.469166
  validation loss:		0.437553
  validation accuracy:		86.09 %
Epoch 186 of 2000 took 0.103s
  training loss:		0.462027
  validation loss:		0.434051
  validation accuracy:		86.85 %
Epoch 187 of 2000 took 0.103s
  training loss:		0.458346
  validation loss:		0.433492
  validation accuracy:		86.30 %
Epoch 188 of 2000 took 0.108s
  training loss:		0.455092
  validation loss:		0.425983
  validation accuracy:		86.63 %
Epoch 189 of 2000 took 0.103s
  training loss:		0.454375
  validation loss:		0.418246
  validation accuracy:		86.85 %
Epoch 190 of 2000 took 0.103s
  training loss:		0.453596
  validation loss:		0.428662
  validation accuracy:		86.09 %
Epoch 191 of 2000 took 0.103s
  training loss:		0.454364
  validation loss:		0.436373
  validation accuracy:		86.63 %
Epoch 192 of 2000 took 0.103s
  training loss:		0.446279
  validation loss:		0.420829
  validation accuracy:		86.85 %
Epoch 193 of 2000 took 0.103s
  training loss:		0.456945
  validation loss:		0.417049
  validation accuracy:		86.96 %
Epoch 194 of 2000 took 0.103s
  training loss:		0.449461
  validation loss:		0.431216
  validation accuracy:		86.20 %
Epoch 195 of 2000 took 0.103s
  training loss:		0.445877
  validation loss:		0.417766
  validation accuracy:		86.74 %
Epoch 196 of 2000 took 0.103s
  training loss:		0.433267
  validation loss:		0.415445
  validation accuracy:		86.85 %
Epoch 197 of 2000 took 0.103s
  training loss:		0.434625
  validation loss:		0.422452
  validation accuracy:		86.41 %
Epoch 198 of 2000 took 0.108s
  training loss:		0.434673
  validation loss:		0.409160
  validation accuracy:		87.07 %
Epoch 199 of 2000 took 0.103s
  training loss:		0.436921
  validation loss:		0.412726
  validation accuracy:		87.17 %
Epoch 200 of 2000 took 0.103s
  training loss:		0.440827
  validation loss:		0.417491
  validation accuracy:		86.52 %
Epoch 201 of 2000 took 0.101s
  training loss:		0.440375
  validation loss:		0.408482
  validation accuracy:		87.07 %
Epoch 202 of 2000 took 0.104s
  training loss:		0.428804
  validation loss:		0.422550
  validation accuracy:		86.63 %
Epoch 203 of 2000 took 0.169s
  training loss:		0.427433
  validation loss:		0.403887
  validation accuracy:		87.28 %
Epoch 204 of 2000 took 0.104s
  training loss:		0.415696
  validation loss:		0.406441
  validation accuracy:		87.07 %
Epoch 205 of 2000 took 0.100s
  training loss:		0.422110
  validation loss:		0.408656
  validation accuracy:		87.17 %
Epoch 206 of 2000 took 0.102s
  training loss:		0.418033
  validation loss:		0.403101
  validation accuracy:		87.39 %
Epoch 207 of 2000 took 0.111s
  training loss:		0.423180
  validation loss:		0.400460
  validation accuracy:		87.72 %
Epoch 208 of 2000 took 0.099s
  training loss:		0.422934
  validation loss:		0.403395
  validation accuracy:		87.50 %
Epoch 209 of 2000 took 0.098s
  training loss:		0.414912
  validation loss:		0.398630
  validation accuracy:		87.50 %
Epoch 210 of 2000 took 0.097s
  training loss:		0.418031
  validation loss:		0.403055
  validation accuracy:		86.85 %
Epoch 211 of 2000 took 0.096s
  training loss:		0.411406
  validation loss:		0.407510
  validation accuracy:		86.96 %
Epoch 212 of 2000 took 0.096s
  training loss:		0.409816
  validation loss:		0.397359
  validation accuracy:		87.50 %
Epoch 213 of 2000 took 0.096s
  training loss:		0.410552
  validation loss:		0.394294
  validation accuracy:		87.50 %
Epoch 214 of 2000 took 0.097s
  training loss:		0.406545
  validation loss:		0.387418
  validation accuracy:		87.93 %
Epoch 215 of 2000 took 0.097s
  training loss:		0.409421
  validation loss:		0.388113
  validation accuracy:		88.15 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.408792
  validation loss:		0.390830
  validation accuracy:		87.72 %
Epoch 217 of 2000 took 0.099s
  training loss:		0.406577
  validation loss:		0.396711
  validation accuracy:		87.50 %
Epoch 218 of 2000 took 0.096s
  training loss:		0.399440
  validation loss:		0.397796
  validation accuracy:		87.07 %
Epoch 219 of 2000 took 0.096s
  training loss:		0.401295
  validation loss:		0.403011
  validation accuracy:		87.93 %
Epoch 220 of 2000 took 0.096s
  training loss:		0.399121
  validation loss:		0.393013
  validation accuracy:		87.93 %
Epoch 221 of 2000 took 0.096s
  training loss:		0.403262
  validation loss:		0.383975
  validation accuracy:		87.61 %
Epoch 222 of 2000 took 0.096s
  training loss:		0.391226
  validation loss:		0.394824
  validation accuracy:		86.85 %
Epoch 223 of 2000 took 0.096s
  training loss:		0.390461
  validation loss:		0.384446
  validation accuracy:		87.72 %
Epoch 224 of 2000 took 0.096s
  training loss:		0.398116
  validation loss:		0.379555
  validation accuracy:		87.83 %
Epoch 225 of 2000 took 0.096s
  training loss:		0.394736
  validation loss:		0.387718
  validation accuracy:		87.61 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.390655
  validation loss:		0.386412
  validation accuracy:		88.04 %
Epoch 227 of 2000 took 0.099s
  training loss:		0.394016
  validation loss:		0.377436
  validation accuracy:		87.83 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.391756
  validation loss:		0.390001
  validation accuracy:		87.61 %
Epoch 229 of 2000 took 0.096s
  training loss:		0.388442
  validation loss:		0.373616
  validation accuracy:		88.26 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.388817
  validation loss:		0.381819
  validation accuracy:		88.37 %
Epoch 231 of 2000 took 0.096s
  training loss:		0.390886
  validation loss:		0.382713
  validation accuracy:		87.61 %
Epoch 232 of 2000 took 0.096s
  training loss:		0.382045
  validation loss:		0.372952
  validation accuracy:		88.37 %
Epoch 233 of 2000 took 0.096s
  training loss:		0.380887
  validation loss:		0.380373
  validation accuracy:		87.50 %
Epoch 234 of 2000 took 0.096s
  training loss:		0.381391
  validation loss:		0.374252
  validation accuracy:		87.72 %
Epoch 235 of 2000 took 0.096s
  training loss:		0.379556
  validation loss:		0.377743
  validation accuracy:		87.72 %
Epoch 236 of 2000 took 0.096s
  training loss:		0.380305
  validation loss:		0.375537
  validation accuracy:		87.50 %
Epoch 237 of 2000 took 0.098s
  training loss:		0.372261
  validation loss:		0.373370
  validation accuracy:		88.70 %
Epoch 238 of 2000 took 0.098s
  training loss:		0.378058
  validation loss:		0.367528
  validation accuracy:		88.15 %
Epoch 239 of 2000 took 0.096s
  training loss:		0.380066
  validation loss:		0.373280
  validation accuracy:		87.61 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.371391
  validation loss:		0.362475
  validation accuracy:		88.80 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.368745
  validation loss:		0.367845
  validation accuracy:		88.04 %
Epoch 242 of 2000 took 0.098s
  training loss:		0.368417
  validation loss:		0.368874
  validation accuracy:		87.50 %
Epoch 243 of 2000 took 0.132s
  training loss:		0.371158
  validation loss:		0.375945
  validation accuracy:		87.93 %
Epoch 244 of 2000 took 0.113s
  training loss:		0.367922
  validation loss:		0.366886
  validation accuracy:		87.83 %
Epoch 245 of 2000 took 0.106s
  training loss:		0.362857
  validation loss:		0.364266
  validation accuracy:		88.80 %
Epoch 246 of 2000 took 0.105s
  training loss:		0.367442
  validation loss:		0.370828
  validation accuracy:		88.91 %
Epoch 247 of 2000 took 0.106s
  training loss:		0.364989
  validation loss:		0.368636
  validation accuracy:		88.04 %
Epoch 248 of 2000 took 0.105s
  training loss:		0.365234
  validation loss:		0.367773
  validation accuracy:		87.93 %
Epoch 249 of 2000 took 0.106s
  training loss:		0.363611
  validation loss:		0.361888
  validation accuracy:		88.48 %
Epoch 250 of 2000 took 0.108s
  training loss:		0.363953
  validation loss:		0.365420
  validation accuracy:		87.61 %
Epoch 251 of 2000 took 0.106s
  training loss:		0.363172
  validation loss:		0.366454
  validation accuracy:		87.83 %
Epoch 252 of 2000 took 0.106s
  training loss:		0.358513
  validation loss:		0.357750
  validation accuracy:		88.59 %
Epoch 253 of 2000 took 0.105s
  training loss:		0.356247
  validation loss:		0.356435
  validation accuracy:		88.48 %
Epoch 254 of 2000 took 0.105s
  training loss:		0.363305
  validation loss:		0.362316
  validation accuracy:		87.93 %
Epoch 255 of 2000 took 0.105s
  training loss:		0.357896
  validation loss:		0.361953
  validation accuracy:		88.26 %
Epoch 256 of 2000 took 0.105s
  training loss:		0.357654
  validation loss:		0.370073
  validation accuracy:		88.59 %
Epoch 257 of 2000 took 0.105s
  training loss:		0.359564
  validation loss:		0.360422
  validation accuracy:		88.26 %
Epoch 258 of 2000 took 0.105s
  training loss:		0.352806
  validation loss:		0.350407
  validation accuracy:		88.70 %
Epoch 259 of 2000 took 0.105s
  training loss:		0.348191
  validation loss:		0.372603
  validation accuracy:		88.80 %
Epoch 260 of 2000 took 0.105s
  training loss:		0.348637
  validation loss:		0.362001
  validation accuracy:		89.35 %
Epoch 261 of 2000 took 0.105s
  training loss:		0.345619
  validation loss:		0.352983
  validation accuracy:		88.37 %
Epoch 262 of 2000 took 0.105s
  training loss:		0.344817
  validation loss:		0.348964
  validation accuracy:		88.91 %
Epoch 263 of 2000 took 0.105s
  training loss:		0.348943
  validation loss:		0.351877
  validation accuracy:		89.02 %
Epoch 264 of 2000 took 0.105s
  training loss:		0.342200
  validation loss:		0.356128
  validation accuracy:		88.59 %
Epoch 265 of 2000 took 0.105s
  training loss:		0.344901
  validation loss:		0.347949
  validation accuracy:		88.91 %
Epoch 266 of 2000 took 0.108s
  training loss:		0.346091
  validation loss:		0.351670
  validation accuracy:		89.02 %
Epoch 267 of 2000 took 0.105s
  training loss:		0.341921
  validation loss:		0.355279
  validation accuracy:		88.48 %
Epoch 268 of 2000 took 0.105s
  training loss:		0.351315
  validation loss:		0.348244
  validation accuracy:		88.91 %
Epoch 269 of 2000 took 0.105s
  training loss:		0.349898
  validation loss:		0.349438
  validation accuracy:		88.70 %
Epoch 270 of 2000 took 0.105s
  training loss:		0.343356
  validation loss:		0.343513
  validation accuracy:		88.91 %
Epoch 271 of 2000 took 0.105s
  training loss:		0.341632
  validation loss:		0.344714
  validation accuracy:		88.48 %
Epoch 272 of 2000 took 0.105s
  training loss:		0.336379
  validation loss:		0.351939
  validation accuracy:		88.70 %
Epoch 273 of 2000 took 0.105s
  training loss:		0.337509
  validation loss:		0.342536
  validation accuracy:		88.59 %
Epoch 274 of 2000 took 0.105s
  training loss:		0.336088
  validation loss:		0.343602
  validation accuracy:		88.80 %
Epoch 275 of 2000 took 0.105s
  training loss:		0.331163
  validation loss:		0.346356
  validation accuracy:		88.80 %
Epoch 276 of 2000 took 0.105s
  training loss:		0.335179
  validation loss:		0.342637
  validation accuracy:		88.70 %
Epoch 277 of 2000 took 0.105s
  training loss:		0.330054
  validation loss:		0.346111
  validation accuracy:		88.91 %
Epoch 278 of 2000 took 0.105s
  training loss:		0.326959
  validation loss:		0.338613
  validation accuracy:		89.35 %
Epoch 279 of 2000 took 0.105s
  training loss:		0.331517
  validation loss:		0.354907
  validation accuracy:		88.91 %
Epoch 280 of 2000 took 0.105s
  training loss:		0.334359
  validation loss:		0.344165
  validation accuracy:		89.67 %
Epoch 281 of 2000 took 0.105s
  training loss:		0.327816
  validation loss:		0.338367
  validation accuracy:		89.24 %
Epoch 282 of 2000 took 0.105s
  training loss:		0.327009
  validation loss:		0.342369
  validation accuracy:		89.24 %
Epoch 283 of 2000 took 0.105s
  training loss:		0.329339
  validation loss:		0.338627
  validation accuracy:		88.91 %
Epoch 284 of 2000 took 0.105s
  training loss:		0.324913
  validation loss:		0.338222
  validation accuracy:		89.46 %
Epoch 285 of 2000 took 0.105s
  training loss:		0.323521
  validation loss:		0.332964
  validation accuracy:		89.78 %
Epoch 286 of 2000 took 0.105s
  training loss:		0.321163
  validation loss:		0.339108
  validation accuracy:		89.02 %
Epoch 287 of 2000 took 0.108s
  training loss:		0.322026
  validation loss:		0.342993
  validation accuracy:		89.67 %
Epoch 288 of 2000 took 0.105s
  training loss:		0.319272
  validation loss:		0.336526
  validation accuracy:		89.35 %
Epoch 289 of 2000 took 0.105s
  training loss:		0.317009
  validation loss:		0.340243
  validation accuracy:		89.46 %
Epoch 290 of 2000 took 0.105s
  training loss:		0.316337
  validation loss:		0.353282
  validation accuracy:		89.57 %
Epoch 291 of 2000 took 0.105s
  training loss:		0.313832
  validation loss:		0.347191
  validation accuracy:		88.80 %
Epoch 292 of 2000 took 0.105s
  training loss:		0.313558
  validation loss:		0.341390
  validation accuracy:		88.91 %
Epoch 293 of 2000 took 0.105s
  training loss:		0.321733
  validation loss:		0.337598
  validation accuracy:		89.35 %
Epoch 294 of 2000 took 0.105s
  training loss:		0.315963
  validation loss:		0.335882
  validation accuracy:		89.57 %
Epoch 295 of 2000 took 0.105s
  training loss:		0.315119
  validation loss:		0.334492
  validation accuracy:		89.78 %
Epoch 296 of 2000 took 0.105s
  training loss:		0.310910
  validation loss:		0.339055
  validation accuracy:		89.24 %
Epoch 297 of 2000 took 0.105s
  training loss:		0.315267
  validation loss:		0.338728
  validation accuracy:		89.35 %
Epoch 298 of 2000 took 0.105s
  training loss:		0.314733
  validation loss:		0.333348
  validation accuracy:		89.24 %
Epoch 299 of 2000 took 0.105s
  training loss:		0.310439
  validation loss:		0.329257
  validation accuracy:		89.89 %
Epoch 300 of 2000 took 0.105s
  training loss:		0.306857
  validation loss:		0.337927
  validation accuracy:		88.48 %
Epoch 301 of 2000 took 0.105s
  training loss:		0.305869
  validation loss:		0.332918
  validation accuracy:		90.00 %
Epoch 302 of 2000 took 0.105s
  training loss:		0.309412
  validation loss:		0.334212
  validation accuracy:		89.13 %
Epoch 303 of 2000 took 0.105s
  training loss:		0.306223
  validation loss:		0.331857
  validation accuracy:		89.67 %
Epoch 304 of 2000 took 0.105s
  training loss:		0.305687
  validation loss:		0.332299
  validation accuracy:		89.78 %
Epoch 305 of 2000 took 0.105s
  training loss:		0.312745
  validation loss:		0.328788
  validation accuracy:		89.13 %
Epoch 306 of 2000 took 0.105s
  training loss:		0.300890
  validation loss:		0.329342
  validation accuracy:		90.00 %
Epoch 307 of 2000 took 0.105s
  training loss:		0.303298
  validation loss:		0.328414
  validation accuracy:		89.35 %
Epoch 308 of 2000 took 0.105s
  training loss:		0.305647
  validation loss:		0.329106
  validation accuracy:		89.02 %
Epoch 309 of 2000 took 0.105s
  training loss:		0.303277
  validation loss:		0.342420
  validation accuracy:		89.24 %
Epoch 310 of 2000 took 0.105s
  training loss:		0.294967
  validation loss:		0.330025
  validation accuracy:		89.78 %
Epoch 311 of 2000 took 0.105s
  training loss:		0.307952
  validation loss:		0.330291
  validation accuracy:		88.80 %
Epoch 312 of 2000 took 0.105s
  training loss:		0.299889
  validation loss:		0.326466
  validation accuracy:		89.02 %
Epoch 313 of 2000 took 0.105s
  training loss:		0.302848
  validation loss:		0.329449
  validation accuracy:		89.02 %
Epoch 314 of 2000 took 0.108s
  training loss:		0.294769
  validation loss:		0.347460
  validation accuracy:		89.46 %
Epoch 315 of 2000 took 0.105s
  training loss:		0.301483
  validation loss:		0.333085
  validation accuracy:		88.80 %
Epoch 316 of 2000 took 0.105s
  training loss:		0.294275
  validation loss:		0.328052
  validation accuracy:		89.46 %
Epoch 317 of 2000 took 0.105s
  training loss:		0.298698
  validation loss:		0.332378
  validation accuracy:		89.35 %
Epoch 318 of 2000 took 0.105s
  training loss:		0.296784
  validation loss:		0.325291
  validation accuracy:		90.22 %
Epoch 319 of 2000 took 0.105s
  training loss:		0.293378
  validation loss:		0.330403
  validation accuracy:		88.59 %
Epoch 320 of 2000 took 0.105s
  training loss:		0.291770
  validation loss:		0.333578
  validation accuracy:		89.46 %
Epoch 321 of 2000 took 0.105s
  training loss:		0.298898
  validation loss:		0.323069
  validation accuracy:		89.78 %
Epoch 322 of 2000 took 0.105s
  training loss:		0.296021
  validation loss:		0.329154
  validation accuracy:		89.89 %
Epoch 323 of 2000 took 0.105s
  training loss:		0.295627
  validation loss:		0.322316
  validation accuracy:		89.89 %
Epoch 324 of 2000 took 0.105s
  training loss:		0.289566
  validation loss:		0.322750
  validation accuracy:		90.11 %
Epoch 325 of 2000 took 0.105s
  training loss:		0.301329
  validation loss:		0.325573
  validation accuracy:		89.35 %
Epoch 326 of 2000 took 0.105s
  training loss:		0.292624
  validation loss:		0.327684
  validation accuracy:		89.57 %
Epoch 327 of 2000 took 0.105s
  training loss:		0.290735
  validation loss:		0.322150
  validation accuracy:		88.80 %
Epoch 328 of 2000 took 0.105s
  training loss:		0.287550
  validation loss:		0.325781
  validation accuracy:		89.67 %
Epoch 329 of 2000 took 0.105s
  training loss:		0.291361
  validation loss:		0.320952
  validation accuracy:		89.89 %
Epoch 330 of 2000 took 0.105s
  training loss:		0.290826
  validation loss:		0.321900
  validation accuracy:		90.00 %
Epoch 331 of 2000 took 0.105s
  training loss:		0.292302
  validation loss:		0.322466
  validation accuracy:		89.78 %
Epoch 332 of 2000 took 0.105s
  training loss:		0.284583
  validation loss:		0.319505
  validation accuracy:		90.00 %
Epoch 333 of 2000 took 0.105s
  training loss:		0.291289
  validation loss:		0.318059
  validation accuracy:		90.22 %
Epoch 334 of 2000 took 0.105s
  training loss:		0.285834
  validation loss:		0.319878
  validation accuracy:		89.67 %
Epoch 335 of 2000 took 0.105s
  training loss:		0.286743
  validation loss:		0.327621
  validation accuracy:		89.46 %
Epoch 336 of 2000 took 0.105s
  training loss:		0.283323
  validation loss:		0.324823
  validation accuracy:		90.11 %
Epoch 337 of 2000 took 0.105s
  training loss:		0.287609
  validation loss:		0.319263
  validation accuracy:		90.11 %
Epoch 338 of 2000 took 0.105s
  training loss:		0.282862
  validation loss:		0.322206
  validation accuracy:		89.89 %
Epoch 339 of 2000 took 0.105s
  training loss:		0.279901
  validation loss:		0.319345
  validation accuracy:		90.22 %
Epoch 340 of 2000 took 0.105s
  training loss:		0.284085
  validation loss:		0.318377
  validation accuracy:		90.22 %
Epoch 341 of 2000 took 0.105s
  training loss:		0.282364
  validation loss:		0.318844
  validation accuracy:		90.22 %
Epoch 342 of 2000 took 0.105s
  training loss:		0.278250
  validation loss:		0.325648
  validation accuracy:		89.89 %
Epoch 343 of 2000 took 0.105s
  training loss:		0.279884
  validation loss:		0.328030
  validation accuracy:		90.43 %
Epoch 344 of 2000 took 0.105s
  training loss:		0.286466
  validation loss:		0.318849
  validation accuracy:		90.00 %
Epoch 345 of 2000 took 0.105s
  training loss:		0.276648
  validation loss:		0.323059
  validation accuracy:		89.24 %
Epoch 346 of 2000 took 0.105s
  training loss:		0.275066
  validation loss:		0.322015
  validation accuracy:		90.43 %
Epoch 347 of 2000 took 0.105s
  training loss:		0.281957
  validation loss:		0.316390
  validation accuracy:		90.43 %
Epoch 348 of 2000 took 0.105s
  training loss:		0.272878
  validation loss:		0.319069
  validation accuracy:		90.43 %
Epoch 349 of 2000 took 0.108s
  training loss:		0.282208
  validation loss:		0.320258
  validation accuracy:		90.33 %
Epoch 350 of 2000 took 0.105s
  training loss:		0.274445
  validation loss:		0.319859
  validation accuracy:		89.67 %
Epoch 351 of 2000 took 0.105s
  training loss:		0.277244
  validation loss:		0.321262
  validation accuracy:		89.57 %
Epoch 352 of 2000 took 0.105s
  training loss:		0.274910
  validation loss:		0.320100
  validation accuracy:		90.22 %
Epoch 353 of 2000 took 0.105s
  training loss:		0.276092
  validation loss:		0.312636
  validation accuracy:		90.54 %
Epoch 354 of 2000 took 0.105s
  training loss:		0.279740
  validation loss:		0.323576
  validation accuracy:		90.22 %
Epoch 355 of 2000 took 0.105s
  training loss:		0.270984
  validation loss:		0.316967
  validation accuracy:		89.89 %
Epoch 356 of 2000 took 0.105s
  training loss:		0.272977
  validation loss:		0.332184
  validation accuracy:		90.11 %
Epoch 357 of 2000 took 0.105s
  training loss:		0.276083
  validation loss:		0.319553
  validation accuracy:		90.54 %
Epoch 358 of 2000 took 0.105s
  training loss:		0.270061
  validation loss:		0.321600
  validation accuracy:		89.67 %
Epoch 359 of 2000 took 0.105s
  training loss:		0.272778
  validation loss:		0.315287
  validation accuracy:		89.89 %
Epoch 360 of 2000 took 0.105s
  training loss:		0.278442
  validation loss:		0.315539
  validation accuracy:		90.00 %
Epoch 361 of 2000 took 0.105s
  training loss:		0.276399
  validation loss:		0.321849
  validation accuracy:		89.57 %
Epoch 362 of 2000 took 0.105s
  training loss:		0.274935
  validation loss:		0.316006
  validation accuracy:		90.00 %
Epoch 363 of 2000 took 0.105s
  training loss:		0.275163
  validation loss:		0.316790
  validation accuracy:		90.11 %
Epoch 364 of 2000 took 0.105s
  training loss:		0.272561
  validation loss:		0.313452
  validation accuracy:		90.65 %
Epoch 365 of 2000 took 0.105s
  training loss:		0.271080
  validation loss:		0.315435
  validation accuracy:		90.43 %
Epoch 366 of 2000 took 0.105s
  training loss:		0.267438
  validation loss:		0.315527
  validation accuracy:		90.43 %
Epoch 367 of 2000 took 0.105s
  training loss:		0.272509
  validation loss:		0.312656
  validation accuracy:		90.65 %
Epoch 368 of 2000 took 0.105s
  training loss:		0.273168
  validation loss:		0.316652
  validation accuracy:		90.43 %
Epoch 369 of 2000 took 0.105s
  training loss:		0.268641
  validation loss:		0.323436
  validation accuracy:		90.43 %
Epoch 370 of 2000 took 0.105s
  training loss:		0.267618
  validation loss:		0.314291
  validation accuracy:		90.00 %
Epoch 371 of 2000 took 0.105s
  training loss:		0.262647
  validation loss:		0.315645
  validation accuracy:		90.33 %
Epoch 372 of 2000 took 0.105s
  training loss:		0.270668
  validation loss:		0.311773
  validation accuracy:		90.33 %
Epoch 373 of 2000 took 0.105s
  training loss:		0.266383
  validation loss:		0.318810
  validation accuracy:		90.22 %
Epoch 374 of 2000 took 0.105s
  training loss:		0.264705
  validation loss:		0.326032
  validation accuracy:		90.43 %
Epoch 375 of 2000 took 0.105s
  training loss:		0.262851
  validation loss:		0.313849
  validation accuracy:		90.11 %
Epoch 376 of 2000 took 0.105s
  training loss:		0.272766
  validation loss:		0.318915
  validation accuracy:		90.11 %
Epoch 377 of 2000 took 0.105s
  training loss:		0.264180
  validation loss:		0.311983
  validation accuracy:		91.09 %
Epoch 378 of 2000 took 0.105s
  training loss:		0.262619
  validation loss:		0.314165
  validation accuracy:		90.33 %
Epoch 379 of 2000 took 0.105s
  training loss:		0.261877
  validation loss:		0.316991
  validation accuracy:		90.87 %
Epoch 380 of 2000 took 0.105s
  training loss:		0.265423
  validation loss:		0.313012
  validation accuracy:		89.89 %
Epoch 381 of 2000 took 0.105s
  training loss:		0.257643
  validation loss:		0.323057
  validation accuracy:		90.11 %
Epoch 382 of 2000 took 0.105s
  training loss:		0.259229
  validation loss:		0.321848
  validation accuracy:		90.11 %
Epoch 383 of 2000 took 0.105s
  training loss:		0.259061
  validation loss:		0.312821
  validation accuracy:		90.98 %
Epoch 384 of 2000 took 0.105s
  training loss:		0.249574
  validation loss:		0.311064
  validation accuracy:		90.87 %
Epoch 385 of 2000 took 0.105s
  training loss:		0.258904
  validation loss:		0.312986
  validation accuracy:		90.87 %
Epoch 386 of 2000 took 0.105s
  training loss:		0.258427
  validation loss:		0.318903
  validation accuracy:		89.89 %
Epoch 387 of 2000 took 0.105s
  training loss:		0.259496
  validation loss:		0.319907
  validation accuracy:		90.33 %
Epoch 388 of 2000 took 0.105s
  training loss:		0.259377
  validation loss:		0.312430
  validation accuracy:		90.43 %
Epoch 389 of 2000 took 0.105s
  training loss:		0.252275
  validation loss:		0.317973
  validation accuracy:		90.22 %
Epoch 390 of 2000 took 0.105s
  training loss:		0.258137
  validation loss:		0.315330
  validation accuracy:		90.11 %
Epoch 391 of 2000 took 0.105s
  training loss:		0.260727
  validation loss:		0.308194
  validation accuracy:		90.76 %
Epoch 392 of 2000 took 0.105s
  training loss:		0.249076
  validation loss:		0.309057
  validation accuracy:		91.20 %
Epoch 393 of 2000 took 0.105s
  training loss:		0.255821
  validation loss:		0.319714
  validation accuracy:		90.00 %
Epoch 394 of 2000 took 0.105s
  training loss:		0.257688
  validation loss:		0.311085
  validation accuracy:		90.65 %
Epoch 395 of 2000 took 0.108s
  training loss:		0.255268
  validation loss:		0.315119
  validation accuracy:		90.43 %
Epoch 396 of 2000 took 0.105s
  training loss:		0.250383
  validation loss:		0.320767
  validation accuracy:		90.33 %
Epoch 397 of 2000 took 0.105s
  training loss:		0.255292
  validation loss:		0.305292
  validation accuracy:		90.76 %
Epoch 398 of 2000 took 0.105s
  training loss:		0.254257
  validation loss:		0.322205
  validation accuracy:		90.11 %
Epoch 399 of 2000 took 0.105s
  training loss:		0.254651
  validation loss:		0.312699
  validation accuracy:		90.76 %
Epoch 400 of 2000 took 0.105s
  training loss:		0.252110
  validation loss:		0.320474
  validation accuracy:		90.33 %
Epoch 401 of 2000 took 0.105s
  training loss:		0.253248
  validation loss:		0.312647
  validation accuracy:		90.43 %
Epoch 402 of 2000 took 0.105s
  training loss:		0.250500
  validation loss:		0.319075
  validation accuracy:		90.22 %
Epoch 403 of 2000 took 0.105s
  training loss:		0.247844
  validation loss:		0.314135
  validation accuracy:		90.43 %
Epoch 404 of 2000 took 0.105s
  training loss:		0.249603
  validation loss:		0.314295
  validation accuracy:		90.43 %
Epoch 405 of 2000 took 0.105s
  training loss:		0.248770
  validation loss:		0.316042
  validation accuracy:		89.89 %
Epoch 406 of 2000 took 0.105s
  training loss:		0.252056
  validation loss:		0.311996
  validation accuracy:		90.54 %
Epoch 407 of 2000 took 0.105s
  training loss:		0.254572
  validation loss:		0.310977
  validation accuracy:		90.43 %
Epoch 408 of 2000 took 0.105s
  training loss:		0.251880
  validation loss:		0.308262
  validation accuracy:		90.87 %
Epoch 409 of 2000 took 0.105s
  training loss:		0.255350
  validation loss:		0.307423
  validation accuracy:		90.87 %
Epoch 410 of 2000 took 0.105s
  training loss:		0.243607
  validation loss:		0.314885
  validation accuracy:		90.98 %
Epoch 411 of 2000 took 0.105s
  training loss:		0.246999
  validation loss:		0.310078
  validation accuracy:		90.65 %
Epoch 412 of 2000 took 0.105s
  training loss:		0.251370
  validation loss:		0.313966
  validation accuracy:		90.76 %
Epoch 413 of 2000 took 0.105s
  training loss:		0.248400
  validation loss:		0.310968
  validation accuracy:		90.76 %
Epoch 414 of 2000 took 0.105s
  training loss:		0.249123
  validation loss:		0.308570
  validation accuracy:		90.65 %
Epoch 415 of 2000 took 0.105s
  training loss:		0.248591
  validation loss:		0.308946
  validation accuracy:		90.22 %
Epoch 416 of 2000 took 0.105s
  training loss:		0.244817
  validation loss:		0.312383
  validation accuracy:		90.33 %
Epoch 417 of 2000 took 0.105s
  training loss:		0.254646
  validation loss:		0.317152
  validation accuracy:		90.22 %
Epoch 418 of 2000 took 0.105s
  training loss:		0.248849
  validation loss:		0.316010
  validation accuracy:		89.89 %
Epoch 419 of 2000 took 0.105s
  training loss:		0.249092
  validation loss:		0.319338
  validation accuracy:		90.43 %
Epoch 420 of 2000 took 0.105s
  training loss:		0.245703
  validation loss:		0.310024
  validation accuracy:		90.54 %
Epoch 421 of 2000 took 0.105s
  training loss:		0.242505
  validation loss:		0.308055
  validation accuracy:		90.87 %
Epoch 422 of 2000 took 0.105s
  training loss:		0.246718
  validation loss:		0.308662
  validation accuracy:		90.76 %
Epoch 423 of 2000 took 0.105s
  training loss:		0.247134
  validation loss:		0.309096
  validation accuracy:		90.65 %
Epoch 424 of 2000 took 0.105s
  training loss:		0.247013
  validation loss:		0.312336
  validation accuracy:		90.54 %
Epoch 425 of 2000 took 0.105s
  training loss:		0.242772
  validation loss:		0.308940
  validation accuracy:		90.65 %
Epoch 426 of 2000 took 0.105s
  training loss:		0.248895
  validation loss:		0.302223
  validation accuracy:		90.98 %
Epoch 427 of 2000 took 0.105s
  training loss:		0.242311
  validation loss:		0.315124
  validation accuracy:		90.54 %
Epoch 428 of 2000 took 0.105s
  training loss:		0.241465
  validation loss:		0.309513
  validation accuracy:		90.65 %
Epoch 429 of 2000 took 0.105s
  training loss:		0.242274
  validation loss:		0.311160
  validation accuracy:		90.54 %
Epoch 430 of 2000 took 0.105s
  training loss:		0.246135
  validation loss:		0.311627
  validation accuracy:		90.76 %
Epoch 431 of 2000 took 0.105s
  training loss:		0.246008
  validation loss:		0.310286
  validation accuracy:		90.33 %
Epoch 432 of 2000 took 0.105s
  training loss:		0.239935
  validation loss:		0.303210
  validation accuracy:		90.76 %
Epoch 433 of 2000 took 0.105s
  training loss:		0.242940
  validation loss:		0.305864
  validation accuracy:		90.65 %
Epoch 434 of 2000 took 0.105s
  training loss:		0.241273
  validation loss:		0.308839
  validation accuracy:		90.11 %
Epoch 435 of 2000 took 0.105s
  training loss:		0.239535
  validation loss:		0.308368
  validation accuracy:		90.87 %
Epoch 436 of 2000 took 0.105s
  training loss:		0.238142
  validation loss:		0.309231
  validation accuracy:		90.87 %
Epoch 437 of 2000 took 0.105s
  training loss:		0.239554
  validation loss:		0.307382
  validation accuracy:		90.65 %
Epoch 438 of 2000 took 0.105s
  training loss:		0.239890
  validation loss:		0.308996
  validation accuracy:		90.43 %
Epoch 439 of 2000 took 0.105s
  training loss:		0.236868
  validation loss:		0.309441
  validation accuracy:		90.22 %
Epoch 440 of 2000 took 0.105s
  training loss:		0.238249
  validation loss:		0.309318
  validation accuracy:		90.54 %
Epoch 441 of 2000 took 0.105s
  training loss:		0.238277
  validation loss:		0.307084
  validation accuracy:		91.20 %
Epoch 442 of 2000 took 0.105s
  training loss:		0.234662
  validation loss:		0.311035
  validation accuracy:		90.87 %
Epoch 443 of 2000 took 0.105s
  training loss:		0.241479
  validation loss:		0.304916
  validation accuracy:		91.20 %
Epoch 444 of 2000 took 0.105s
  training loss:		0.239204
  validation loss:		0.314812
  validation accuracy:		90.76 %
Epoch 445 of 2000 took 0.105s
  training loss:		0.236274
  validation loss:		0.307771
  validation accuracy:		91.09 %
Epoch 446 of 2000 took 0.105s
  training loss:		0.233529
  validation loss:		0.314395
  validation accuracy:		90.76 %
Epoch 447 of 2000 took 0.105s
  training loss:		0.236610
  validation loss:		0.307684
  validation accuracy:		91.20 %
Epoch 448 of 2000 took 0.105s
  training loss:		0.240022
  validation loss:		0.306424
  validation accuracy:		91.30 %
Epoch 449 of 2000 took 0.105s
  training loss:		0.239648
  validation loss:		0.313444
  validation accuracy:		90.54 %
Epoch 450 of 2000 took 0.105s
  training loss:		0.235811
  validation loss:		0.306033
  validation accuracy:		90.76 %
Epoch 451 of 2000 took 0.105s
  training loss:		0.239824
  validation loss:		0.311927
  validation accuracy:		90.54 %
Epoch 452 of 2000 took 0.105s
  training loss:		0.235512
  validation loss:		0.305633
  validation accuracy:		91.09 %
Epoch 453 of 2000 took 0.105s
  training loss:		0.236256
  validation loss:		0.301951
  validation accuracy:		91.20 %
Epoch 454 of 2000 took 0.105s
  training loss:		0.234128
  validation loss:		0.306724
  validation accuracy:		91.09 %
Epoch 455 of 2000 took 0.108s
  training loss:		0.231579
  validation loss:		0.309862
  validation accuracy:		90.43 %
Epoch 456 of 2000 took 0.105s
  training loss:		0.234995
  validation loss:		0.306844
  validation accuracy:		90.76 %
Epoch 457 of 2000 took 0.105s
  training loss:		0.236343
  validation loss:		0.308931
  validation accuracy:		90.54 %
Epoch 458 of 2000 took 0.105s
  training loss:		0.234064
  validation loss:		0.317636
  validation accuracy:		90.11 %
Epoch 459 of 2000 took 0.105s
  training loss:		0.237742
  validation loss:		0.302285
  validation accuracy:		91.09 %
Epoch 460 of 2000 took 0.105s
  training loss:		0.230466
  validation loss:		0.303697
  validation accuracy:		91.30 %
Epoch 461 of 2000 took 0.105s
  training loss:		0.233161
  validation loss:		0.303049
  validation accuracy:		90.87 %
Epoch 462 of 2000 took 0.105s
  training loss:		0.233968
  validation loss:		0.310113
  validation accuracy:		91.09 %
Epoch 463 of 2000 took 0.105s
  training loss:		0.231201
  validation loss:		0.317640
  validation accuracy:		90.65 %
Epoch 464 of 2000 took 0.105s
  training loss:		0.231921
  validation loss:		0.303400
  validation accuracy:		90.87 %
Epoch 465 of 2000 took 0.105s
  training loss:		0.231806
  validation loss:		0.304479
  validation accuracy:		90.76 %
Epoch 466 of 2000 took 0.105s
  training loss:		0.227537
  validation loss:		0.300827
  validation accuracy:		90.87 %
Epoch 467 of 2000 took 0.105s
  training loss:		0.231529
  validation loss:		0.304104
  validation accuracy:		90.87 %
Epoch 468 of 2000 took 0.105s
  training loss:		0.230592
  validation loss:		0.300576
  validation accuracy:		90.98 %
Epoch 469 of 2000 took 0.105s
  training loss:		0.232887
  validation loss:		0.302877
  validation accuracy:		90.98 %
Epoch 470 of 2000 took 0.105s
  training loss:		0.231631
  validation loss:		0.304699
  validation accuracy:		90.87 %
Epoch 471 of 2000 took 0.105s
  training loss:		0.228508
  validation loss:		0.321609
  validation accuracy:		90.43 %
Epoch 472 of 2000 took 0.105s
  training loss:		0.229965
  validation loss:		0.303517
  validation accuracy:		90.65 %
Epoch 473 of 2000 took 0.105s
  training loss:		0.226255
  validation loss:		0.308135
  validation accuracy:		90.43 %
Epoch 474 of 2000 took 0.105s
  training loss:		0.229385
  validation loss:		0.310540
  validation accuracy:		90.65 %
Epoch 475 of 2000 took 0.105s
  training loss:		0.231473
  validation loss:		0.314737
  validation accuracy:		90.87 %
Epoch 476 of 2000 took 0.105s
  training loss:		0.226542
  validation loss:		0.301728
  validation accuracy:		90.65 %
Epoch 477 of 2000 took 0.105s
  training loss:		0.229470
  validation loss:		0.300533
  validation accuracy:		91.09 %
Epoch 478 of 2000 took 0.105s
  training loss:		0.233230
  validation loss:		0.312013
  validation accuracy:		90.33 %
Epoch 479 of 2000 took 0.105s
  training loss:		0.232478
  validation loss:		0.313648
  validation accuracy:		90.65 %
Epoch 480 of 2000 took 0.105s
  training loss:		0.231140
  validation loss:		0.305014
  validation accuracy:		90.98 %
Epoch 481 of 2000 took 0.105s
  training loss:		0.224917
  validation loss:		0.302232
  validation accuracy:		91.20 %
Epoch 482 of 2000 took 0.105s
  training loss:		0.225295
  validation loss:		0.308964
  validation accuracy:		90.87 %
Epoch 483 of 2000 took 0.105s
  training loss:		0.223404
  validation loss:		0.303883
  validation accuracy:		90.54 %
Epoch 484 of 2000 took 0.105s
  training loss:		0.218677
  validation loss:		0.302405
  validation accuracy:		90.76 %
Epoch 485 of 2000 took 0.105s
  training loss:		0.222632
  validation loss:		0.304667
  validation accuracy:		90.76 %
Epoch 486 of 2000 took 0.105s
  training loss:		0.221562
  validation loss:		0.298816
  validation accuracy:		91.09 %
Epoch 487 of 2000 took 0.105s
  training loss:		0.221877
  validation loss:		0.312553
  validation accuracy:		90.43 %
Epoch 488 of 2000 took 0.105s
  training loss:		0.228213
  validation loss:		0.307674
  validation accuracy:		90.76 %
Epoch 489 of 2000 took 0.105s
  training loss:		0.227301
  validation loss:		0.303614
  validation accuracy:		90.54 %
Epoch 490 of 2000 took 0.105s
  training loss:		0.227141
  validation loss:		0.316989
  validation accuracy:		89.78 %
Epoch 491 of 2000 took 0.105s
  training loss:		0.219837
  validation loss:		0.302536
  validation accuracy:		91.41 %
Epoch 492 of 2000 took 0.105s
  training loss:		0.223962
  validation loss:		0.319110
  validation accuracy:		90.00 %
Epoch 493 of 2000 took 0.105s
  training loss:		0.223541
  validation loss:		0.311291
  validation accuracy:		90.76 %
Epoch 494 of 2000 took 0.105s
  training loss:		0.222496
  validation loss:		0.302652
  validation accuracy:		90.87 %
Epoch 495 of 2000 took 0.105s
  training loss:		0.217403
  validation loss:		0.303975
  validation accuracy:		91.30 %
Epoch 496 of 2000 took 0.105s
  training loss:		0.217254
  validation loss:		0.298942
  validation accuracy:		91.20 %
Epoch 497 of 2000 took 0.105s
  training loss:		0.222961
  validation loss:		0.306107
  validation accuracy:		90.65 %
Epoch 498 of 2000 took 0.105s
  training loss:		0.218671
  validation loss:		0.294310
  validation accuracy:		91.63 %
Epoch 499 of 2000 took 0.105s
  training loss:		0.219785
  validation loss:		0.302698
  validation accuracy:		91.20 %
Epoch 500 of 2000 took 0.105s
  training loss:		0.219808
  validation loss:		0.298705
  validation accuracy:		91.09 %
Epoch 501 of 2000 took 0.105s
  training loss:		0.215813
  validation loss:		0.302242
  validation accuracy:		91.30 %
Epoch 502 of 2000 took 0.105s
  training loss:		0.220302
  validation loss:		0.304313
  validation accuracy:		90.65 %
Epoch 503 of 2000 took 0.105s
  training loss:		0.220264
  validation loss:		0.301284
  validation accuracy:		90.87 %
Epoch 504 of 2000 took 0.105s
  training loss:		0.217221
  validation loss:		0.309609
  validation accuracy:		90.65 %
Epoch 505 of 2000 took 0.105s
  training loss:		0.215542
  validation loss:		0.300988
  validation accuracy:		90.87 %
Epoch 506 of 2000 took 0.105s
  training loss:		0.219881
  validation loss:		0.298609
  validation accuracy:		90.87 %
Epoch 507 of 2000 took 0.105s
  training loss:		0.219898
  validation loss:		0.298556
  validation accuracy:		91.63 %
Epoch 508 of 2000 took 0.105s
  training loss:		0.218772
  validation loss:		0.305548
  validation accuracy:		90.87 %
Epoch 509 of 2000 took 0.105s
  training loss:		0.219668
  validation loss:		0.307541
  validation accuracy:		90.65 %
Epoch 510 of 2000 took 0.105s
  training loss:		0.215420
  validation loss:		0.305851
  validation accuracy:		90.87 %
Epoch 511 of 2000 took 0.105s
  training loss:		0.216533
  validation loss:		0.302655
  validation accuracy:		91.52 %
Epoch 512 of 2000 took 0.105s
  training loss:		0.209320
  validation loss:		0.313318
  validation accuracy:		90.65 %
Epoch 513 of 2000 took 0.105s
  training loss:		0.207813
  validation loss:		0.302249
  validation accuracy:		90.87 %
Epoch 514 of 2000 took 0.105s
  training loss:		0.216051
  validation loss:		0.296590
  validation accuracy:		91.09 %
Epoch 515 of 2000 took 0.105s
  training loss:		0.218753
  validation loss:		0.306239
  validation accuracy:		90.76 %
Epoch 516 of 2000 took 0.105s
  training loss:		0.218779
  validation loss:		0.306884
  validation accuracy:		91.09 %
Epoch 517 of 2000 took 0.105s
  training loss:		0.219908
  validation loss:		0.306559
  validation accuracy:		90.98 %
Epoch 518 of 2000 took 0.105s
  training loss:		0.219822
  validation loss:		0.303739
  validation accuracy:		90.43 %
Epoch 519 of 2000 took 0.105s
  training loss:		0.214795
  validation loss:		0.301277
  validation accuracy:		91.09 %
Epoch 520 of 2000 took 0.105s
  training loss:		0.216269
  validation loss:		0.309465
  validation accuracy:		90.87 %
Epoch 521 of 2000 took 0.105s
  training loss:		0.218563
  validation loss:		0.299574
  validation accuracy:		90.33 %
Epoch 522 of 2000 took 0.105s
  training loss:		0.215521
  validation loss:		0.302773
  validation accuracy:		90.76 %
Epoch 523 of 2000 took 0.105s
  training loss:		0.212596
  validation loss:		0.298646
  validation accuracy:		91.52 %
Epoch 524 of 2000 took 0.105s
  training loss:		0.214992
  validation loss:		0.306651
  validation accuracy:		90.87 %
Epoch 525 of 2000 took 0.105s
  training loss:		0.213420
  validation loss:		0.305310
  validation accuracy:		90.87 %
Epoch 526 of 2000 took 0.105s
  training loss:		0.214358
  validation loss:		0.303224
  validation accuracy:		90.65 %
Epoch 527 of 2000 took 0.105s
  training loss:		0.214418
  validation loss:		0.299353
  validation accuracy:		91.20 %
Epoch 528 of 2000 took 0.105s
  training loss:		0.213818
  validation loss:		0.304076
  validation accuracy:		90.87 %
Epoch 529 of 2000 took 0.105s
  training loss:		0.217537
  validation loss:		0.302814
  validation accuracy:		91.09 %
Epoch 530 of 2000 took 0.105s
  training loss:		0.211365
  validation loss:		0.296993
  validation accuracy:		91.09 %
Epoch 531 of 2000 took 0.105s
  training loss:		0.216388
  validation loss:		0.294873
  validation accuracy:		91.20 %
Epoch 532 of 2000 took 0.105s
  training loss:		0.210915
  validation loss:		0.317963
  validation accuracy:		89.78 %
Epoch 533 of 2000 took 0.108s
  training loss:		0.215645
  validation loss:		0.302227
  validation accuracy:		90.98 %
Epoch 534 of 2000 took 0.105s
  training loss:		0.206531
  validation loss:		0.306242
  validation accuracy:		91.09 %
Epoch 535 of 2000 took 0.105s
  training loss:		0.208156
  validation loss:		0.307933
  validation accuracy:		90.76 %
Epoch 536 of 2000 took 0.105s
  training loss:		0.216454
  validation loss:		0.300756
  validation accuracy:		90.87 %
Epoch 537 of 2000 took 0.105s
  training loss:		0.216878
  validation loss:		0.312157
  validation accuracy:		90.87 %
Epoch 538 of 2000 took 0.106s
  training loss:		0.211220
  validation loss:		0.301791
  validation accuracy:		90.98 %
Epoch 539 of 2000 took 0.104s
  training loss:		0.211001
  validation loss:		0.301534
  validation accuracy:		90.87 %
Epoch 540 of 2000 took 0.106s
  training loss:		0.203252
  validation loss:		0.304670
  validation accuracy:		90.87 %
Epoch 541 of 2000 took 0.112s
  training loss:		0.207627
  validation loss:		0.311659
  validation accuracy:		90.54 %
Epoch 542 of 2000 took 0.105s
  training loss:		0.211812
  validation loss:		0.301267
  validation accuracy:		90.65 %
Epoch 543 of 2000 took 0.100s
  training loss:		0.210721
  validation loss:		0.304487
  validation accuracy:		90.65 %
Epoch 544 of 2000 took 0.101s
  training loss:		0.212951
  validation loss:		0.295726
  validation accuracy:		90.98 %
Epoch 545 of 2000 took 0.104s
  training loss:		0.206414
  validation loss:		0.300681
  validation accuracy:		90.76 %
Epoch 546 of 2000 took 0.106s
  training loss:		0.204165
  validation loss:		0.306281
  validation accuracy:		90.54 %
Epoch 547 of 2000 took 0.104s
  training loss:		0.212748
  validation loss:		0.310809
  validation accuracy:		90.22 %
Epoch 548 of 2000 took 0.103s
  training loss:		0.204138
  validation loss:		0.300989
  validation accuracy:		90.54 %
Epoch 549 of 2000 took 0.103s
  training loss:		0.202563
  validation loss:		0.297894
  validation accuracy:		90.76 %
Epoch 550 of 2000 took 0.104s
  training loss:		0.214250
  validation loss:		0.303227
  validation accuracy:		90.33 %
Epoch 551 of 2000 took 0.100s
  training loss:		0.209724
  validation loss:		0.299067
  validation accuracy:		90.87 %
Epoch 552 of 2000 took 0.100s
  training loss:		0.205984
  validation loss:		0.311095
  validation accuracy:		90.65 %
Epoch 553 of 2000 took 0.104s
  training loss:		0.206698
  validation loss:		0.299125
  validation accuracy:		90.76 %
Epoch 554 of 2000 took 0.102s
  training loss:		0.205973
  validation loss:		0.295180
  validation accuracy:		90.87 %
Epoch 555 of 2000 took 0.100s
  training loss:		0.204612
  validation loss:		0.308210
  validation accuracy:		90.76 %
Epoch 556 of 2000 took 0.103s
  training loss:		0.202164
  validation loss:		0.309586
  validation accuracy:		91.09 %
Epoch 557 of 2000 took 0.103s
  training loss:		0.210262
  validation loss:		0.300557
  validation accuracy:		90.43 %
Epoch 558 of 2000 took 0.103s
  training loss:		0.211987
  validation loss:		0.312428
  validation accuracy:		90.43 %
Epoch 559 of 2000 took 0.103s
  training loss:		0.203259
  validation loss:		0.304145
  validation accuracy:		90.98 %
Epoch 560 of 2000 took 0.103s
  training loss:		0.197352
  validation loss:		0.301623
  validation accuracy:		90.98 %
Epoch 561 of 2000 took 0.102s
  training loss:		0.204992
  validation loss:		0.303199
  validation accuracy:		91.09 %
Epoch 562 of 2000 took 0.103s
  training loss:		0.208207
  validation loss:		0.311811
  validation accuracy:		90.11 %
Epoch 563 of 2000 took 0.102s
  training loss:		0.204880
  validation loss:		0.301011
  validation accuracy:		90.87 %
Epoch 564 of 2000 took 0.102s
  training loss:		0.199734
  validation loss:		0.297570
  validation accuracy:		90.54 %
Epoch 565 of 2000 took 0.102s
  training loss:		0.203397
  validation loss:		0.308112
  validation accuracy:		90.98 %
Epoch 566 of 2000 took 0.102s
  training loss:		0.201879
  validation loss:		0.296556
  validation accuracy:		90.87 %
Epoch 567 of 2000 took 0.102s
  training loss:		0.203854
  validation loss:		0.291289
  validation accuracy:		90.98 %
Epoch 568 of 2000 took 0.102s
  training loss:		0.204612
  validation loss:		0.313271
  validation accuracy:		90.43 %
Epoch 569 of 2000 took 0.103s
  training loss:		0.206320
  validation loss:		0.299639
  validation accuracy:		90.87 %
Epoch 570 of 2000 took 0.103s
  training loss:		0.208919
  validation loss:		0.293954
  validation accuracy:		90.54 %
Epoch 571 of 2000 took 0.102s
  training loss:		0.204254
  validation loss:		0.301783
  validation accuracy:		91.09 %
Epoch 572 of 2000 took 0.102s
  training loss:		0.196068
  validation loss:		0.306463
  validation accuracy:		90.65 %
Epoch 573 of 2000 took 0.102s
  training loss:		0.204552
  validation loss:		0.302202
  validation accuracy:		90.76 %
Epoch 574 of 2000 took 0.102s
  training loss:		0.198252
  validation loss:		0.304352
  validation accuracy:		90.87 %
Epoch 575 of 2000 took 0.102s
  training loss:		0.201691
  validation loss:		0.295389
  validation accuracy:		90.65 %
Epoch 576 of 2000 took 0.102s
  training loss:		0.202511
  validation loss:		0.294516
  validation accuracy:		90.87 %
Epoch 577 of 2000 took 0.102s
  training loss:		0.198717
  validation loss:		0.305146
  validation accuracy:		90.76 %
Epoch 578 of 2000 took 0.102s
  training loss:		0.203547
  validation loss:		0.300843
  validation accuracy:		90.43 %
Epoch 579 of 2000 took 0.103s
  training loss:		0.196856
  validation loss:		0.302892
  validation accuracy:		90.54 %
Epoch 580 of 2000 took 0.102s
  training loss:		0.198886
  validation loss:		0.303546
  validation accuracy:		90.65 %
Epoch 581 of 2000 took 0.102s
  training loss:		0.200728
  validation loss:		0.297519
  validation accuracy:		90.76 %
Epoch 582 of 2000 took 0.102s
  training loss:		0.200640
  validation loss:		0.313615
  validation accuracy:		90.22 %
Epoch 583 of 2000 took 0.102s
  training loss:		0.195813
  validation loss:		0.303861
  validation accuracy:		90.65 %
Epoch 584 of 2000 took 0.102s
  training loss:		0.201949
  validation loss:		0.304009
  validation accuracy:		90.87 %
Epoch 585 of 2000 took 0.102s
  training loss:		0.197522
  validation loss:		0.292981
  validation accuracy:		90.98 %
Epoch 586 of 2000 took 0.103s
  training loss:		0.197545
  validation loss:		0.297964
  validation accuracy:		90.76 %
Epoch 587 of 2000 took 0.102s
  training loss:		0.198364
  validation loss:		0.309766
  validation accuracy:		90.43 %
Epoch 588 of 2000 took 0.102s
  training loss:		0.200364
  validation loss:		0.294618
  validation accuracy:		90.65 %
Epoch 589 of 2000 took 0.103s
  training loss:		0.197066
  validation loss:		0.299301
  validation accuracy:		90.76 %
Epoch 590 of 2000 took 0.102s
  training loss:		0.200805
  validation loss:		0.302163
  validation accuracy:		90.43 %
Epoch 591 of 2000 took 0.102s
  training loss:		0.193698
  validation loss:		0.298668
  validation accuracy:		91.09 %
Epoch 592 of 2000 took 0.102s
  training loss:		0.196953
  validation loss:		0.309300
  validation accuracy:		90.65 %
Epoch 593 of 2000 took 0.102s
  training loss:		0.201493
  validation loss:		0.299766
  validation accuracy:		90.76 %
Epoch 594 of 2000 took 0.103s
  training loss:		0.198776
  validation loss:		0.314521
  validation accuracy:		90.22 %
Epoch 595 of 2000 took 0.102s
  training loss:		0.202395
  validation loss:		0.304216
  validation accuracy:		90.76 %
Epoch 596 of 2000 took 0.102s
  training loss:		0.199050
  validation loss:		0.300180
  validation accuracy:		90.54 %
Epoch 597 of 2000 took 0.103s
  training loss:		0.194624
  validation loss:		0.310904
  validation accuracy:		90.22 %
Epoch 598 of 2000 took 0.102s
  training loss:		0.196415
  validation loss:		0.299037
  validation accuracy:		90.43 %
Epoch 599 of 2000 took 0.103s
  training loss:		0.192754
  validation loss:		0.302526
  validation accuracy:		90.54 %
Epoch 600 of 2000 took 0.102s
  training loss:		0.197193
  validation loss:		0.312364
  validation accuracy:		90.87 %
Epoch 601 of 2000 took 0.102s
  training loss:		0.197962
  validation loss:		0.298605
  validation accuracy:		90.65 %
Epoch 602 of 2000 took 0.102s
  training loss:		0.198927
  validation loss:		0.307559
  validation accuracy:		90.65 %
Epoch 603 of 2000 took 0.102s
  training loss:		0.197692
  validation loss:		0.292958
  validation accuracy:		90.54 %
Epoch 604 of 2000 took 0.102s
  training loss:		0.199551
  validation loss:		0.300686
  validation accuracy:		90.65 %
Epoch 605 of 2000 took 0.102s
  training loss:		0.194024
  validation loss:		0.306094
  validation accuracy:		90.76 %
Epoch 606 of 2000 took 0.102s
  training loss:		0.192575
  validation loss:		0.307525
  validation accuracy:		90.65 %
Epoch 607 of 2000 took 0.102s
  training loss:		0.194689
  validation loss:		0.294843
  validation accuracy:		90.65 %
Epoch 608 of 2000 took 0.102s
  training loss:		0.192671
  validation loss:		0.299638
  validation accuracy:		90.33 %
Epoch 609 of 2000 took 0.103s
  training loss:		0.195284
  validation loss:		0.300161
  validation accuracy:		90.65 %
Epoch 610 of 2000 took 0.102s
  training loss:		0.195457
  validation loss:		0.314600
  validation accuracy:		90.54 %
Epoch 611 of 2000 took 0.102s
  training loss:		0.196054
  validation loss:		0.297791
  validation accuracy:		90.87 %
Epoch 612 of 2000 took 0.103s
  training loss:		0.195294
  validation loss:		0.303636
  validation accuracy:		90.54 %
Epoch 613 of 2000 took 0.102s
  training loss:		0.192632
  validation loss:		0.297612
  validation accuracy:		90.54 %
Epoch 614 of 2000 took 0.102s
  training loss:		0.186146
  validation loss:		0.304493
  validation accuracy:		90.65 %
Epoch 615 of 2000 took 0.103s
  training loss:		0.192060
  validation loss:		0.313671
  validation accuracy:		90.43 %
Epoch 616 of 2000 took 0.103s
  training loss:		0.198213
  validation loss:		0.302195
  validation accuracy:		90.76 %
Epoch 617 of 2000 took 0.102s
  training loss:		0.195490
  validation loss:		0.307428
  validation accuracy:		90.98 %
Epoch 618 of 2000 took 0.102s
  training loss:		0.195589
  validation loss:		0.304577
  validation accuracy:		90.76 %
Epoch 619 of 2000 took 0.102s
  training loss:		0.198153
  validation loss:		0.301422
  validation accuracy:		90.65 %
Epoch 620 of 2000 took 0.103s
  training loss:		0.191790
  validation loss:		0.302427
  validation accuracy:		90.43 %
Epoch 621 of 2000 took 0.102s
  training loss:		0.190513
  validation loss:		0.307079
  validation accuracy:		90.33 %
Epoch 622 of 2000 took 0.102s
  training loss:		0.191111
  validation loss:		0.298769
  validation accuracy:		90.54 %
Epoch 623 of 2000 took 0.102s
  training loss:		0.186420
  validation loss:		0.313505
  validation accuracy:		90.43 %
Epoch 624 of 2000 took 0.102s
  training loss:		0.199947
  validation loss:		0.297236
  validation accuracy:		90.65 %
Epoch 625 of 2000 took 0.102s
  training loss:		0.190429
  validation loss:		0.298692
  validation accuracy:		90.87 %
Epoch 626 of 2000 took 0.102s
  training loss:		0.196116
  validation loss:		0.299675
  validation accuracy:		90.87 %
Epoch 627 of 2000 took 0.103s
  training loss:		0.195059
  validation loss:		0.300303
  validation accuracy:		90.76 %
Epoch 628 of 2000 took 0.102s
  training loss:		0.190474
  validation loss:		0.301258
  validation accuracy:		90.65 %
Epoch 629 of 2000 took 0.102s
  training loss:		0.186551
  validation loss:		0.300720
  validation accuracy:		90.87 %
Epoch 630 of 2000 took 0.102s
  training loss:		0.187679
  validation loss:		0.302752
  validation accuracy:		90.65 %
Epoch 631 of 2000 took 0.102s
  training loss:		0.197075
  validation loss:		0.302156
  validation accuracy:		90.54 %
Epoch 632 of 2000 took 0.102s
  training loss:		0.188706
  validation loss:		0.310975
  validation accuracy:		90.11 %
Epoch 633 of 2000 took 0.102s
  training loss:		0.193511
  validation loss:		0.304285
  validation accuracy:		90.43 %
Epoch 634 of 2000 took 0.103s
  training loss:		0.190782
  validation loss:		0.306723
  validation accuracy:		90.43 %
Epoch 635 of 2000 took 0.102s
  training loss:		0.187458
  validation loss:		0.306851
  validation accuracy:		90.54 %
Epoch 636 of 2000 took 0.105s
  training loss:		0.192175
  validation loss:		0.302758
  validation accuracy:		90.65 %
Epoch 637 of 2000 took 0.103s
  training loss:		0.190558
  validation loss:		0.295092
  validation accuracy:		90.98 %
Epoch 638 of 2000 took 0.103s
  training loss:		0.188057
  validation loss:		0.301883
  validation accuracy:		90.54 %
Epoch 639 of 2000 took 0.103s
  training loss:		0.191014
  validation loss:		0.302885
  validation accuracy:		90.98 %
Epoch 640 of 2000 took 0.102s
  training loss:		0.187635
  validation loss:		0.299257
  validation accuracy:		90.98 %
Epoch 641 of 2000 took 0.102s
  training loss:		0.188722
  validation loss:		0.313046
  validation accuracy:		90.33 %
Epoch 642 of 2000 took 0.103s
  training loss:		0.188190
  validation loss:		0.299151
  validation accuracy:		90.76 %
Epoch 643 of 2000 took 0.102s
  training loss:		0.189352
  validation loss:		0.303943
  validation accuracy:		90.43 %
Epoch 644 of 2000 took 0.102s
  training loss:		0.190345
  validation loss:		0.303480
  validation accuracy:		90.43 %
Epoch 645 of 2000 took 0.103s
  training loss:		0.188570
  validation loss:		0.301785
  validation accuracy:		90.65 %
Epoch 646 of 2000 took 0.103s
  training loss:		0.186655
  validation loss:		0.304774
  validation accuracy:		90.65 %
Epoch 647 of 2000 took 0.102s
  training loss:		0.181181
  validation loss:		0.304940
  validation accuracy:		90.33 %
Epoch 648 of 2000 took 0.102s
  training loss:		0.186657
  validation loss:		0.299470
  validation accuracy:		90.65 %
Epoch 649 of 2000 took 0.103s
  training loss:		0.190971
  validation loss:		0.298746
  validation accuracy:		90.33 %
Epoch 650 of 2000 took 0.102s
  training loss:		0.187580
  validation loss:		0.301879
  validation accuracy:		90.43 %
Epoch 651 of 2000 took 0.102s
  training loss:		0.192476
  validation loss:		0.303881
  validation accuracy:		90.33 %
Epoch 652 of 2000 took 0.102s
  training loss:		0.181975
  validation loss:		0.314345
  validation accuracy:		90.76 %
Epoch 653 of 2000 took 0.102s
  training loss:		0.191847
  validation loss:		0.294835
  validation accuracy:		90.54 %
Epoch 654 of 2000 took 0.102s
  training loss:		0.186871
  validation loss:		0.307914
  validation accuracy:		90.33 %
Epoch 655 of 2000 took 0.102s
  training loss:		0.183220
  validation loss:		0.310433
  validation accuracy:		90.76 %
Epoch 656 of 2000 took 0.102s
  training loss:		0.184922
  validation loss:		0.307284
  validation accuracy:		90.54 %
Epoch 657 of 2000 took 0.102s
  training loss:		0.185460
  validation loss:		0.306280
  validation accuracy:		90.65 %
Epoch 658 of 2000 took 0.103s
  training loss:		0.190289
  validation loss:		0.310808
  validation accuracy:		90.11 %
Epoch 659 of 2000 took 0.102s
  training loss:		0.187644
  validation loss:		0.305181
  validation accuracy:		90.65 %
Epoch 660 of 2000 took 0.102s
  training loss:		0.191531
  validation loss:		0.306090
  validation accuracy:		90.54 %
Epoch 661 of 2000 took 0.102s
  training loss:		0.185113
  validation loss:		0.307653
  validation accuracy:		90.22 %
Epoch 662 of 2000 took 0.102s
  training loss:		0.186159
  validation loss:		0.306734
  validation accuracy:		90.33 %
Epoch 663 of 2000 took 0.103s
  training loss:		0.182726
  validation loss:		0.305630
  validation accuracy:		90.43 %
Epoch 664 of 2000 took 0.102s
  training loss:		0.186426
  validation loss:		0.292185
  validation accuracy:		90.76 %
Epoch 665 of 2000 took 0.102s
  training loss:		0.186114
  validation loss:		0.320245
  validation accuracy:		90.33 %
Epoch 666 of 2000 took 0.103s
  training loss:		0.190218
  validation loss:		0.304110
  validation accuracy:		90.54 %
Epoch 667 of 2000 took 0.103s
  training loss:		0.179481
  validation loss:		0.304870
  validation accuracy:		90.65 %
Epoch 668 of 2000 took 0.102s
  training loss:		0.184659
  validation loss:		0.308253
  validation accuracy:		90.43 %
Epoch 669 of 2000 took 0.102s
  training loss:		0.184146
  validation loss:		0.309141
  validation accuracy:		90.54 %
Epoch 670 of 2000 took 0.102s
  training loss:		0.180991
  validation loss:		0.304672
  validation accuracy:		90.98 %
Epoch 671 of 2000 took 0.102s
  training loss:		0.187879
  validation loss:		0.303677
  validation accuracy:		90.87 %
Epoch 672 of 2000 took 0.102s
  training loss:		0.174583
  validation loss:		0.311241
  validation accuracy:		90.33 %
Epoch 673 of 2000 took 0.103s
  training loss:		0.184753
  validation loss:		0.304257
  validation accuracy:		90.54 %
Epoch 674 of 2000 took 0.103s
  training loss:		0.182452
  validation loss:		0.313127
  validation accuracy:		90.11 %
Epoch 675 of 2000 took 0.102s
  training loss:		0.182678
  validation loss:		0.307510
  validation accuracy:		90.33 %
Epoch 676 of 2000 took 0.102s
  training loss:		0.180783
  validation loss:		0.311813
  validation accuracy:		90.22 %
Epoch 677 of 2000 took 0.103s
  training loss:		0.186547
  validation loss:		0.311020
  validation accuracy:		90.65 %
Epoch 678 of 2000 took 0.102s
  training loss:		0.185367
  validation loss:		0.307331
  validation accuracy:		90.87 %
Epoch 679 of 2000 took 0.102s
  training loss:		0.186672
  validation loss:		0.299679
  validation accuracy:		90.65 %
Epoch 680 of 2000 took 0.102s
  training loss:		0.183027
  validation loss:		0.303238
  validation accuracy:		90.76 %
Epoch 681 of 2000 took 0.102s
  training loss:		0.184313
  validation loss:		0.292912
  validation accuracy:		90.76 %
Epoch 682 of 2000 took 0.102s
  training loss:		0.181448
  validation loss:		0.307290
  validation accuracy:		90.54 %
Epoch 683 of 2000 took 0.102s
  training loss:		0.181975
  validation loss:		0.312138
  validation accuracy:		90.87 %
Epoch 684 of 2000 took 0.102s
  training loss:		0.183748
  validation loss:		0.296099
  validation accuracy:		90.65 %
Epoch 685 of 2000 took 0.102s
  training loss:		0.184186
  validation loss:		0.302675
  validation accuracy:		90.65 %
Epoch 686 of 2000 took 0.102s
  training loss:		0.187201
  validation loss:		0.303877
  validation accuracy:		90.43 %
Epoch 687 of 2000 took 0.103s
  training loss:		0.182011
  validation loss:		0.309266
  validation accuracy:		90.65 %
Epoch 688 of 2000 took 0.102s
  training loss:		0.180632
  validation loss:		0.316614
  validation accuracy:		90.22 %
Epoch 689 of 2000 took 0.102s
  training loss:		0.183044
  validation loss:		0.307341
  validation accuracy:		90.76 %
Epoch 690 of 2000 took 0.102s
  training loss:		0.178596
  validation loss:		0.299467
  validation accuracy:		90.54 %
Epoch 691 of 2000 took 0.102s
  training loss:		0.183750
  validation loss:		0.315015
  validation accuracy:		90.22 %
Epoch 692 of 2000 took 0.102s
  training loss:		0.185303
  validation loss:		0.343022
  validation accuracy:		89.13 %
Epoch 693 of 2000 took 0.102s
  training loss:		0.184369
  validation loss:		0.306841
  validation accuracy:		89.89 %
Epoch 694 of 2000 took 0.102s
  training loss:		0.180989
  validation loss:		0.302976
  validation accuracy:		90.54 %
Epoch 695 of 2000 took 0.102s
  training loss:		0.182065
  validation loss:		0.305981
  validation accuracy:		90.54 %
Epoch 696 of 2000 took 0.102s
  training loss:		0.182429
  validation loss:		0.321004
  validation accuracy:		90.11 %
Epoch 697 of 2000 took 0.103s
  training loss:		0.181089
  validation loss:		0.310068
  validation accuracy:		90.43 %
Epoch 698 of 2000 took 0.102s
  training loss:		0.180215
  validation loss:		0.313254
  validation accuracy:		90.11 %
Epoch 699 of 2000 took 0.102s
  training loss:		0.182469
  validation loss:		0.308833
  validation accuracy:		90.43 %
Epoch 700 of 2000 took 0.102s
  training loss:		0.175980
  validation loss:		0.298014
  validation accuracy:		90.76 %
Epoch 701 of 2000 took 0.102s
  training loss:		0.175880
  validation loss:		0.306761
  validation accuracy:		90.22 %
Epoch 702 of 2000 took 0.102s
  training loss:		0.182290
  validation loss:		0.319630
  validation accuracy:		90.43 %
Epoch 703 of 2000 took 0.102s
  training loss:		0.182105
  validation loss:		0.317527
  validation accuracy:		90.11 %
Epoch 704 of 2000 took 0.103s
  training loss:		0.177580
  validation loss:		0.325016
  validation accuracy:		90.00 %
Epoch 705 of 2000 took 0.102s
  training loss:		0.176354
  validation loss:		0.327041
  validation accuracy:		90.54 %
Epoch 706 of 2000 took 0.103s
  training loss:		0.182515
  validation loss:		0.305726
  validation accuracy:		90.76 %
Epoch 707 of 2000 took 0.102s
  training loss:		0.181747
  validation loss:		0.303594
  validation accuracy:		90.54 %
Epoch 708 of 2000 took 0.102s
  training loss:		0.180777
  validation loss:		0.307181
  validation accuracy:		90.22 %
Epoch 709 of 2000 took 0.102s
  training loss:		0.183416
  validation loss:		0.309807
  validation accuracy:		90.54 %
Epoch 710 of 2000 took 0.103s
  training loss:		0.173167
  validation loss:		0.299109
  validation accuracy:		90.76 %
Epoch 711 of 2000 took 0.102s
  training loss:		0.172474
  validation loss:		0.320406
  validation accuracy:		90.22 %
Epoch 712 of 2000 took 0.103s
  training loss:		0.180437
  validation loss:		0.321051
  validation accuracy:		90.33 %
Epoch 713 of 2000 took 0.102s
  training loss:		0.172311
  validation loss:		0.318725
  validation accuracy:		90.33 %
Epoch 714 of 2000 took 0.099s
  training loss:		0.186200
  validation loss:		0.318864
  validation accuracy:		90.11 %
Epoch 715 of 2000 took 0.096s
  training loss:		0.175056
  validation loss:		0.304763
  validation accuracy:		90.65 %
Epoch 716 of 2000 took 0.096s
  training loss:		0.176758
  validation loss:		0.312007
  validation accuracy:		90.54 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.179713
  validation loss:		0.316493
  validation accuracy:		90.00 %
Epoch 718 of 2000 took 0.096s
  training loss:		0.175973
  validation loss:		0.309959
  validation accuracy:		90.43 %
Epoch 719 of 2000 took 0.096s
  training loss:		0.180427
  validation loss:		0.311013
  validation accuracy:		90.43 %
Epoch 720 of 2000 took 0.096s
  training loss:		0.177463
  validation loss:		0.333915
  validation accuracy:		90.00 %
Epoch 721 of 2000 took 0.096s
  training loss:		0.176948
  validation loss:		0.310309
  validation accuracy:		90.22 %
Epoch 722 of 2000 took 0.096s
  training loss:		0.174745
  validation loss:		0.296590
  validation accuracy:		90.76 %
Epoch 723 of 2000 took 0.096s
  training loss:		0.181354
  validation loss:		0.301398
  validation accuracy:		90.54 %
Epoch 724 of 2000 took 0.096s
  training loss:		0.168287
  validation loss:		0.319843
  validation accuracy:		90.76 %
Epoch 725 of 2000 took 0.096s
  training loss:		0.177617
  validation loss:		0.312385
  validation accuracy:		90.33 %
Epoch 726 of 2000 took 0.096s
  training loss:		0.180065
  validation loss:		0.308291
  validation accuracy:		90.65 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.170381
  validation loss:		0.313747
  validation accuracy:		90.76 %
Epoch 728 of 2000 took 0.096s
  training loss:		0.174602
  validation loss:		0.309186
  validation accuracy:		90.43 %
Epoch 729 of 2000 took 0.096s
  training loss:		0.175305
  validation loss:		0.312953
  validation accuracy:		90.11 %
Epoch 730 of 2000 took 0.096s
  training loss:		0.175822
  validation loss:		0.315821
  validation accuracy:		90.54 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.173062
  validation loss:		0.324795
  validation accuracy:		90.65 %
Epoch 732 of 2000 took 0.096s
  training loss:		0.182448
  validation loss:		0.324242
  validation accuracy:		90.54 %
Epoch 733 of 2000 took 0.096s
  training loss:		0.181700
  validation loss:		0.317196
  validation accuracy:		90.54 %
Epoch 734 of 2000 took 0.099s
  training loss:		0.178211
  validation loss:		0.313884
  validation accuracy:		90.54 %
Epoch 735 of 2000 took 0.098s
  training loss:		0.176107
  validation loss:		0.319586
  validation accuracy:		90.33 %
Epoch 736 of 2000 took 0.096s
  training loss:		0.180355
  validation loss:		0.310796
  validation accuracy:		90.54 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.180192
  validation loss:		0.308089
  validation accuracy:		90.65 %
Epoch 738 of 2000 took 0.096s
  training loss:		0.170867
  validation loss:		0.332463
  validation accuracy:		90.11 %
Epoch 739 of 2000 took 0.096s
  training loss:		0.171547
  validation loss:		0.319241
  validation accuracy:		90.54 %
Epoch 740 of 2000 took 0.096s
  training loss:		0.172894
  validation loss:		0.315607
  validation accuracy:		90.22 %
Epoch 741 of 2000 took 0.096s
  training loss:		0.174840
  validation loss:		0.308463
  validation accuracy:		90.76 %
Epoch 742 of 2000 took 0.096s
  training loss:		0.174878
  validation loss:		0.306458
  validation accuracy:		90.65 %
Epoch 743 of 2000 took 0.096s
  training loss:		0.178206
  validation loss:		0.313760
  validation accuracy:		90.87 %
Epoch 744 of 2000 took 0.096s
  training loss:		0.174529
  validation loss:		0.319709
  validation accuracy:		90.33 %
Epoch 745 of 2000 took 0.096s
  training loss:		0.178535
  validation loss:		0.318451
  validation accuracy:		90.87 %
Epoch 746 of 2000 took 0.096s
  training loss:		0.175976
  validation loss:		0.312916
  validation accuracy:		90.54 %
Epoch 747 of 2000 took 0.096s
  training loss:		0.174380
  validation loss:		0.327807
  validation accuracy:		89.89 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.178677
  validation loss:		0.315000
  validation accuracy:		90.54 %
Epoch 749 of 2000 took 0.096s
  training loss:		0.173019
  validation loss:		0.309599
  validation accuracy:		90.54 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.169748
  validation loss:		0.325171
  validation accuracy:		90.11 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.173695
  validation loss:		0.313526
  validation accuracy:		90.65 %
Epoch 752 of 2000 took 0.096s
  training loss:		0.169825
  validation loss:		0.315682
  validation accuracy:		90.76 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.174729
  validation loss:		0.320528
  validation accuracy:		90.00 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.175802
  validation loss:		0.320018
  validation accuracy:		90.43 %
Epoch 755 of 2000 took 0.096s
  training loss:		0.172223
  validation loss:		0.327010
  validation accuracy:		90.33 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.172180
  validation loss:		0.314491
  validation accuracy:		90.65 %
Epoch 757 of 2000 took 0.096s
  training loss:		0.176866
  validation loss:		0.317894
  validation accuracy:		90.33 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.171300
  validation loss:		0.303593
  validation accuracy:		90.43 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.178275
  validation loss:		0.317917
  validation accuracy:		90.33 %
Epoch 760 of 2000 took 0.096s
  training loss:		0.166868
  validation loss:		0.323607
  validation accuracy:		90.11 %
Epoch 761 of 2000 took 0.096s
  training loss:		0.173616
  validation loss:		0.317497
  validation accuracy:		90.76 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.172520
  validation loss:		0.314552
  validation accuracy:		90.54 %
Epoch 763 of 2000 took 0.096s
  training loss:		0.168439
  validation loss:		0.324263
  validation accuracy:		90.54 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.170457
  validation loss:		0.308183
  validation accuracy:		90.76 %
Epoch 765 of 2000 took 0.097s
  training loss:		0.165816
  validation loss:		0.318983
  validation accuracy:		90.54 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.167840
  validation loss:		0.313292
  validation accuracy:		90.65 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.172445
  validation loss:		0.315217
  validation accuracy:		90.43 %
Epoch 768 of 2000 took 0.097s
  training loss:		0.175829
  validation loss:		0.315205
  validation accuracy:		90.54 %
Epoch 769 of 2000 took 0.096s
  training loss:		0.171565
  validation loss:		0.317512
  validation accuracy:		90.76 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.174550
  validation loss:		0.305506
  validation accuracy:		90.65 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.171585
  validation loss:		0.309289
  validation accuracy:		90.54 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.168647
  validation loss:		0.307592
  validation accuracy:		90.65 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.172446
  validation loss:		0.307280
  validation accuracy:		90.65 %
Epoch 774 of 2000 took 0.099s
  training loss:		0.170127
  validation loss:		0.317451
  validation accuracy:		90.87 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.175172
  validation loss:		0.307625
  validation accuracy:		90.65 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.173710
  validation loss:		0.323080
  validation accuracy:		89.89 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.174683
  validation loss:		0.312914
  validation accuracy:		90.65 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.167093
  validation loss:		0.328958
  validation accuracy:		89.89 %
Epoch 779 of 2000 took 0.097s
  training loss:		0.171673
  validation loss:		0.329447
  validation accuracy:		90.43 %
Epoch 780 of 2000 took 0.096s
  training loss:		0.169622
  validation loss:		0.311178
  validation accuracy:		90.87 %
Epoch 781 of 2000 took 0.096s
  training loss:		0.175506
  validation loss:		0.316925
  validation accuracy:		90.76 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.168228
  validation loss:		0.329024
  validation accuracy:		89.78 %
Epoch 783 of 2000 took 0.096s
  training loss:		0.174466
  validation loss:		0.334461
  validation accuracy:		90.33 %
Epoch 784 of 2000 took 0.096s
  training loss:		0.163641
  validation loss:		0.313465
  validation accuracy:		90.87 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.167959
  validation loss:		0.333359
  validation accuracy:		90.65 %
Epoch 786 of 2000 took 0.096s
  training loss:		0.173038
  validation loss:		0.335540
  validation accuracy:		90.33 %
Epoch 787 of 2000 took 0.096s
  training loss:		0.172656
  validation loss:		0.319518
  validation accuracy:		90.76 %
Epoch 788 of 2000 took 0.096s
  training loss:		0.167488
  validation loss:		0.331744
  validation accuracy:		90.65 %
Epoch 789 of 2000 took 0.096s
  training loss:		0.166779
  validation loss:		0.330604
  validation accuracy:		89.89 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.174864
  validation loss:		0.309982
  validation accuracy:		90.87 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.163624
  validation loss:		0.317357
  validation accuracy:		90.65 %
Epoch 792 of 2000 took 0.096s
  training loss:		0.172687
  validation loss:		0.322854
  validation accuracy:		90.11 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.167396
  validation loss:		0.320507
  validation accuracy:		90.87 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.168157
  validation loss:		0.324413
  validation accuracy:		90.65 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.167422
  validation loss:		0.324184
  validation accuracy:		90.65 %
Epoch 796 of 2000 took 0.096s
  training loss:		0.174162
  validation loss:		0.323518
  validation accuracy:		90.65 %
Epoch 797 of 2000 took 0.098s
  training loss:		0.168024
  validation loss:		0.342368
  validation accuracy:		90.33 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.170910
  validation loss:		0.318061
  validation accuracy:		90.76 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.175468
  validation loss:		0.325682
  validation accuracy:		90.76 %
Epoch 800 of 2000 took 0.096s
  training loss:		0.173759
  validation loss:		0.325186
  validation accuracy:		90.76 %
Epoch 801 of 2000 took 0.096s
  training loss:		0.168537
  validation loss:		0.325389
  validation accuracy:		90.76 %
Epoch 802 of 2000 took 0.096s
  training loss:		0.164625
  validation loss:		0.325231
  validation accuracy:		90.22 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.170193
  validation loss:		0.324649
  validation accuracy:		90.87 %
Epoch 804 of 2000 took 0.096s
  training loss:		0.171574
  validation loss:		0.321585
  validation accuracy:		90.54 %
Epoch 805 of 2000 took 0.096s
  training loss:		0.165215
  validation loss:		0.361115
  validation accuracy:		89.24 %
Epoch 806 of 2000 took 0.096s
  training loss:		0.173907
  validation loss:		0.312498
  validation accuracy:		90.76 %
Epoch 807 of 2000 took 0.096s
  training loss:		0.166637
  validation loss:		0.320524
  validation accuracy:		90.33 %
Epoch 808 of 2000 took 0.096s
  training loss:		0.170266
  validation loss:		0.334172
  validation accuracy:		89.89 %
Epoch 809 of 2000 took 0.096s
  training loss:		0.166172
  validation loss:		0.322446
  validation accuracy:		90.76 %
Epoch 810 of 2000 took 0.097s
  training loss:		0.167875
  validation loss:		0.318658
  validation accuracy:		90.76 %
Epoch 811 of 2000 took 0.096s
  training loss:		0.168443
  validation loss:		0.315915
  validation accuracy:		90.54 %
Epoch 812 of 2000 took 0.096s
  training loss:		0.168442
  validation loss:		0.332700
  validation accuracy:		90.33 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.168112
  validation loss:		0.336007
  validation accuracy:		90.33 %
Epoch 814 of 2000 took 0.096s
  training loss:		0.169896
  validation loss:		0.326304
  validation accuracy:		90.54 %
Epoch 815 of 2000 took 0.096s
  training loss:		0.167740
  validation loss:		0.334570
  validation accuracy:		89.78 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.165068
  validation loss:		0.317506
  validation accuracy:		90.87 %
Epoch 817 of 2000 took 0.096s
  training loss:		0.157839
  validation loss:		0.326338
  validation accuracy:		90.65 %
Epoch 818 of 2000 took 0.096s
  training loss:		0.168562
  validation loss:		0.329573
  validation accuracy:		90.54 %
Epoch 819 of 2000 took 0.096s
  training loss:		0.168704
  validation loss:		0.329482
  validation accuracy:		90.87 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.165061
  validation loss:		0.328196
  validation accuracy:		90.33 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.167404
  validation loss:		0.327585
  validation accuracy:		90.22 %
Epoch 822 of 2000 took 0.096s
  training loss:		0.160796
  validation loss:		0.315760
  validation accuracy:		91.09 %
Epoch 823 of 2000 took 0.096s
  training loss:		0.163618
  validation loss:		0.316872
  validation accuracy:		90.65 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.164378
  validation loss:		0.346373
  validation accuracy:		90.11 %
Epoch 825 of 2000 took 0.096s
  training loss:		0.176185
  validation loss:		0.323540
  validation accuracy:		91.09 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.171008
  validation loss:		0.330398
  validation accuracy:		90.65 %
Epoch 827 of 2000 took 0.096s
  training loss:		0.167693
  validation loss:		0.333193
  validation accuracy:		90.76 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.163344
  validation loss:		0.334308
  validation accuracy:		89.89 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.164014
  validation loss:		0.354626
  validation accuracy:		90.11 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.161639
  validation loss:		0.319500
  validation accuracy:		90.65 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.164420
  validation loss:		0.328134
  validation accuracy:		90.00 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.161604
  validation loss:		0.321424
  validation accuracy:		91.20 %
Epoch 833 of 2000 took 0.096s
  training loss:		0.168060
  validation loss:		0.320042
  validation accuracy:		90.98 %
Epoch 834 of 2000 took 0.096s
  training loss:		0.173720
  validation loss:		0.322378
  validation accuracy:		90.76 %
Epoch 835 of 2000 took 0.096s
  training loss:		0.167233
  validation loss:		0.335762
  validation accuracy:		90.54 %
Epoch 836 of 2000 took 0.097s
  training loss:		0.162101
  validation loss:		0.337317
  validation accuracy:		90.22 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.167671
  validation loss:		0.326552
  validation accuracy:		90.22 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.163722
  validation loss:		0.344728
  validation accuracy:		90.22 %
Epoch 839 of 2000 took 0.097s
  training loss:		0.165116
  validation loss:		0.331280
  validation accuracy:		90.00 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.166339
  validation loss:		0.332423
  validation accuracy:		90.33 %
Epoch 841 of 2000 took 0.097s
  training loss:		0.173504
  validation loss:		0.333379
  validation accuracy:		90.22 %
Epoch 842 of 2000 took 0.096s
  training loss:		0.167529
  validation loss:		0.332082
  validation accuracy:		90.11 %
Epoch 843 of 2000 took 0.096s
  training loss:		0.167963
  validation loss:		0.328696
  validation accuracy:		90.11 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.162332
  validation loss:		0.333294
  validation accuracy:		90.00 %
Epoch 845 of 2000 took 0.096s
  training loss:		0.163417
  validation loss:		0.324773
  validation accuracy:		90.87 %
Epoch 846 of 2000 took 0.096s
  training loss:		0.160730
  validation loss:		0.328256
  validation accuracy:		90.54 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.160399
  validation loss:		0.328654
  validation accuracy:		90.87 %
Epoch 848 of 2000 took 0.096s
  training loss:		0.168952
  validation loss:		0.349398
  validation accuracy:		90.54 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.164793
  validation loss:		0.320572
  validation accuracy:		90.87 %
Epoch 850 of 2000 took 0.096s
  training loss:		0.165880
  validation loss:		0.330055
  validation accuracy:		90.54 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.161221
  validation loss:		0.330534
  validation accuracy:		90.65 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.163571
  validation loss:		0.334446
  validation accuracy:		90.33 %
Epoch 853 of 2000 took 0.096s
  training loss:		0.163672
  validation loss:		0.319793
  validation accuracy:		90.76 %
Epoch 854 of 2000 took 0.096s
  training loss:		0.160669
  validation loss:		0.329548
  validation accuracy:		90.87 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.161764
  validation loss:		0.330686
  validation accuracy:		90.76 %
Epoch 856 of 2000 took 0.096s
  training loss:		0.164571
  validation loss:		0.336448
  validation accuracy:		90.87 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.161836
  validation loss:		0.337989
  validation accuracy:		90.33 %
Epoch 858 of 2000 took 0.096s
  training loss:		0.162772
  validation loss:		0.324619
  validation accuracy:		90.76 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.165279
  validation loss:		0.335957
  validation accuracy:		90.76 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.162324
  validation loss:		0.333592
  validation accuracy:		90.65 %
Epoch 861 of 2000 took 0.096s
  training loss:		0.164533
  validation loss:		0.340615
  validation accuracy:		90.87 %
Epoch 862 of 2000 took 0.096s
  training loss:		0.161844
  validation loss:		0.326799
  validation accuracy:		90.76 %
Epoch 863 of 2000 took 0.096s
  training loss:		0.162320
  validation loss:		0.332620
  validation accuracy:		90.76 %
Epoch 864 of 2000 took 0.096s
  training loss:		0.159497
  validation loss:		0.332151
  validation accuracy:		91.09 %
Epoch 865 of 2000 took 0.096s
  training loss:		0.166716
  validation loss:		0.324556
  validation accuracy:		91.09 %
Epoch 866 of 2000 took 0.096s
  training loss:		0.168870
  validation loss:		0.343772
  validation accuracy:		90.22 %
Epoch 867 of 2000 took 0.096s
  training loss:		0.160888
  validation loss:		0.335245
  validation accuracy:		90.43 %
Epoch 868 of 2000 took 0.096s
  training loss:		0.162159
  validation loss:		0.326423
  validation accuracy:		90.76 %
Epoch 869 of 2000 took 0.096s
  training loss:		0.164639
  validation loss:		0.334583
  validation accuracy:		90.11 %
Epoch 870 of 2000 took 0.096s
  training loss:		0.165350
  validation loss:		0.328028
  validation accuracy:		89.89 %
Epoch 871 of 2000 took 0.096s
  training loss:		0.165389
  validation loss:		0.321958
  validation accuracy:		91.09 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.164931
  validation loss:		0.346201
  validation accuracy:		89.67 %
Epoch 873 of 2000 took 0.096s
  training loss:		0.164864
  validation loss:		0.323727
  validation accuracy:		90.22 %
Epoch 874 of 2000 took 0.096s
  training loss:		0.163906
  validation loss:		0.332023
  validation accuracy:		90.65 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.157183
  validation loss:		0.329297
  validation accuracy:		90.76 %
Epoch 876 of 2000 took 0.096s
  training loss:		0.161237
  validation loss:		0.337988
  validation accuracy:		90.65 %
Epoch 877 of 2000 took 0.097s
  training loss:		0.158498
  validation loss:		0.347655
  validation accuracy:		89.78 %
Epoch 878 of 2000 took 0.097s
  training loss:		0.161685
  validation loss:		0.321791
  validation accuracy:		90.76 %
Epoch 879 of 2000 took 0.097s
  training loss:		0.162230
  validation loss:		0.342750
  validation accuracy:		90.43 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.157473
  validation loss:		0.340507
  validation accuracy:		90.43 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.164310
  validation loss:		0.333821
  validation accuracy:		90.54 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.159741
  validation loss:		0.342350
  validation accuracy:		90.22 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.166831
  validation loss:		0.331964
  validation accuracy:		90.54 %
Epoch 884 of 2000 took 0.096s
  training loss:		0.162655
  validation loss:		0.341040
  validation accuracy:		90.33 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.164549
  validation loss:		0.360007
  validation accuracy:		90.22 %
Epoch 886 of 2000 took 0.097s
  training loss:		0.157386
  validation loss:		0.333439
  validation accuracy:		90.87 %
Epoch 887 of 2000 took 0.096s
  training loss:		0.164153
  validation loss:		0.334603
  validation accuracy:		90.43 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.160330
  validation loss:		0.335696
  validation accuracy:		90.33 %
Epoch 889 of 2000 took 0.096s
  training loss:		0.157496
  validation loss:		0.333707
  validation accuracy:		90.87 %
Epoch 890 of 2000 took 0.097s
  training loss:		0.160132
  validation loss:		0.350242
  validation accuracy:		90.11 %
Epoch 891 of 2000 took 0.097s
  training loss:		0.160507
  validation loss:		0.330668
  validation accuracy:		90.65 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.160269
  validation loss:		0.332731
  validation accuracy:		90.76 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.160495
  validation loss:		0.339127
  validation accuracy:		90.65 %
Epoch 894 of 2000 took 0.096s
  training loss:		0.157417
  validation loss:		0.340614
  validation accuracy:		90.54 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.160268
  validation loss:		0.330136
  validation accuracy:		90.87 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.162712
  validation loss:		0.331323
  validation accuracy:		91.20 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.160944
  validation loss:		0.328568
  validation accuracy:		90.98 %
Epoch 898 of 2000 took 0.096s
  training loss:		0.161456
  validation loss:		0.338933
  validation accuracy:		90.65 %
Epoch 899 of 2000 took 0.096s
  training loss:		0.155836
  validation loss:		0.354337
  validation accuracy:		89.67 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.158890
  validation loss:		0.353920
  validation accuracy:		90.43 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.162600
  validation loss:		0.340478
  validation accuracy:		90.65 %
Epoch 902 of 2000 took 0.097s
  training loss:		0.157419
  validation loss:		0.355051
  validation accuracy:		90.00 %
Epoch 903 of 2000 took 0.097s
  training loss:		0.158806
  validation loss:		0.346947
  validation accuracy:		90.00 %
Epoch 904 of 2000 took 0.096s
  training loss:		0.161854
  validation loss:		0.345308
  validation accuracy:		90.43 %
Epoch 905 of 2000 took 0.097s
  training loss:		0.161848
  validation loss:		0.339488
  validation accuracy:		90.65 %
Epoch 906 of 2000 took 0.096s
  training loss:		0.156052
  validation loss:		0.328938
  validation accuracy:		90.11 %
Epoch 907 of 2000 took 0.096s
  training loss:		0.163899
  validation loss:		0.336496
  validation accuracy:		90.54 %
Epoch 908 of 2000 took 0.096s
  training loss:		0.165469
  validation loss:		0.344051
  validation accuracy:		90.43 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.165280
  validation loss:		0.347632
  validation accuracy:		90.00 %
Epoch 910 of 2000 took 0.096s
  training loss:		0.161666
  validation loss:		0.325172
  validation accuracy:		90.76 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.159671
  validation loss:		0.340472
  validation accuracy:		90.11 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.162593
  validation loss:		0.336992
  validation accuracy:		90.33 %
Epoch 913 of 2000 took 0.096s
  training loss:		0.156986
  validation loss:		0.336726
  validation accuracy:		90.22 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.163010
  validation loss:		0.334943
  validation accuracy:		90.65 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.158409
  validation loss:		0.331182
  validation accuracy:		90.43 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.163033
  validation loss:		0.346688
  validation accuracy:		90.22 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.160791
  validation loss:		0.331748
  validation accuracy:		90.87 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.159590
  validation loss:		0.329804
  validation accuracy:		90.22 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.158375
  validation loss:		0.350143
  validation accuracy:		90.33 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.160898
  validation loss:		0.348826
  validation accuracy:		90.00 %
Epoch 921 of 2000 took 0.097s
  training loss:		0.159184
  validation loss:		0.337570
  validation accuracy:		91.09 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.166602
  validation loss:		0.346597
  validation accuracy:		90.33 %
Epoch 923 of 2000 took 0.097s
  training loss:		0.159086
  validation loss:		0.345042
  validation accuracy:		90.33 %
Epoch 924 of 2000 took 0.096s
  training loss:		0.160827
  validation loss:		0.355112
  validation accuracy:		90.43 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.159396
  validation loss:		0.333675
  validation accuracy:		90.98 %
Epoch 926 of 2000 took 0.096s
  training loss:		0.160446
  validation loss:		0.361410
  validation accuracy:		89.46 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.160544
  validation loss:		0.333058
  validation accuracy:		90.87 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.157240
  validation loss:		0.344823
  validation accuracy:		90.00 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.159193
  validation loss:		0.335290
  validation accuracy:		90.54 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.158130
  validation loss:		0.348081
  validation accuracy:		90.76 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.157382
  validation loss:		0.362516
  validation accuracy:		90.00 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.161839
  validation loss:		0.357703
  validation accuracy:		90.22 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.158035
  validation loss:		0.345452
  validation accuracy:		90.43 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.158575
  validation loss:		0.338093
  validation accuracy:		90.65 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.163260
  validation loss:		0.346216
  validation accuracy:		90.22 %
Epoch 936 of 2000 took 0.096s
  training loss:		0.158552
  validation loss:		0.329903
  validation accuracy:		90.87 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.154672
  validation loss:		0.350187
  validation accuracy:		90.11 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.165417
  validation loss:		0.330995
  validation accuracy:		90.87 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.154231
  validation loss:		0.358223
  validation accuracy:		90.00 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.153909
  validation loss:		0.349063
  validation accuracy:		90.43 %
Epoch 941 of 2000 took 0.096s
  training loss:		0.157457
  validation loss:		0.349979
  validation accuracy:		90.65 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.158193
  validation loss:		0.344729
  validation accuracy:		90.76 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.154911
  validation loss:		0.360856
  validation accuracy:		89.89 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.159027
  validation loss:		0.345757
  validation accuracy:		90.11 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.156612
  validation loss:		0.340585
  validation accuracy:		90.43 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.157627
  validation loss:		0.339196
  validation accuracy:		90.33 %
Epoch 947 of 2000 took 0.096s
  training loss:		0.158396
  validation loss:		0.355810
  validation accuracy:		89.78 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.158911
  validation loss:		0.342874
  validation accuracy:		90.76 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.159720
  validation loss:		0.332918
  validation accuracy:		90.76 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.158316
  validation loss:		0.338182
  validation accuracy:		90.33 %
Epoch 951 of 2000 took 0.096s
  training loss:		0.157764
  validation loss:		0.351109
  validation accuracy:		90.43 %
Epoch 952 of 2000 took 0.096s
  training loss:		0.166986
  validation loss:		0.387944
  validation accuracy:		89.67 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.160974
  validation loss:		0.345969
  validation accuracy:		90.76 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.151937
  validation loss:		0.345267
  validation accuracy:		90.54 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.153586
  validation loss:		0.355318
  validation accuracy:		90.43 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.159584
  validation loss:		0.340675
  validation accuracy:		90.76 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.157068
  validation loss:		0.331554
  validation accuracy:		90.98 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.152993
  validation loss:		0.348957
  validation accuracy:		90.33 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.158121
  validation loss:		0.337416
  validation accuracy:		90.76 %
Epoch 960 of 2000 took 0.099s
  training loss:		0.151860
  validation loss:		0.349054
  validation accuracy:		89.67 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.158329
  validation loss:		0.338940
  validation accuracy:		90.65 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.158017
  validation loss:		0.351918
  validation accuracy:		90.33 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.149127
  validation loss:		0.340473
  validation accuracy:		90.65 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.148457
  validation loss:		0.365063
  validation accuracy:		89.57 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.163001
  validation loss:		0.337593
  validation accuracy:		90.76 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.154148
  validation loss:		0.351097
  validation accuracy:		89.78 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.154499
  validation loss:		0.359814
  validation accuracy:		89.57 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.151196
  validation loss:		0.360570
  validation accuracy:		90.00 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.154526
  validation loss:		0.358661
  validation accuracy:		90.33 %
Epoch 970 of 2000 took 0.096s
  training loss:		0.152778
  validation loss:		0.373698
  validation accuracy:		89.67 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.148448
  validation loss:		0.353099
  validation accuracy:		90.33 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.155566
  validation loss:		0.361490
  validation accuracy:		89.89 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.155601
  validation loss:		0.352007
  validation accuracy:		90.22 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.151613
  validation loss:		0.356276
  validation accuracy:		90.22 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.152901
  validation loss:		0.356740
  validation accuracy:		89.89 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.155242
  validation loss:		0.343538
  validation accuracy:		90.54 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.155142
  validation loss:		0.335612
  validation accuracy:		90.43 %
Epoch 978 of 2000 took 0.096s
  training loss:		0.153235
  validation loss:		0.339498
  validation accuracy:		90.54 %
Epoch 979 of 2000 took 0.096s
  training loss:		0.151898
  validation loss:		0.362026
  validation accuracy:		90.00 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.150239
  validation loss:		0.341919
  validation accuracy:		90.98 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.159567
  validation loss:		0.339391
  validation accuracy:		90.43 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.153047
  validation loss:		0.346573
  validation accuracy:		90.33 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.152403
  validation loss:		0.357447
  validation accuracy:		90.22 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.151430
  validation loss:		0.359860
  validation accuracy:		90.33 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.151176
  validation loss:		0.347131
  validation accuracy:		90.33 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.153275
  validation loss:		0.365391
  validation accuracy:		90.33 %
Epoch 987 of 2000 took 0.096s
  training loss:		0.149666
  validation loss:		0.354121
  validation accuracy:		90.54 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.155016
  validation loss:		0.364869
  validation accuracy:		89.89 %
Epoch 989 of 2000 took 0.096s
  training loss:		0.157342
  validation loss:		0.341725
  validation accuracy:		90.43 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.154486
  validation loss:		0.340305
  validation accuracy:		90.65 %
Epoch 991 of 2000 took 0.096s
  training loss:		0.151217
  validation loss:		0.357088
  validation accuracy:		89.78 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.153110
  validation loss:		0.340514
  validation accuracy:		90.87 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.151104
  validation loss:		0.341277
  validation accuracy:		90.76 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.156831
  validation loss:		0.357553
  validation accuracy:		90.00 %
Epoch 995 of 2000 took 0.096s
  training loss:		0.150167
  validation loss:		0.358414
  validation accuracy:		90.43 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.157665
  validation loss:		0.363156
  validation accuracy:		89.78 %
Epoch 997 of 2000 took 0.096s
  training loss:		0.146637
  validation loss:		0.353568
  validation accuracy:		90.65 %
Epoch 998 of 2000 took 0.096s
  training loss:		0.153057
  validation loss:		0.351167
  validation accuracy:		90.43 %
Epoch 999 of 2000 took 0.096s
  training loss:		0.152409
  validation loss:		0.362086
  validation accuracy:		89.78 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.154059
  validation loss:		0.353895
  validation accuracy:		90.65 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.150496
  validation loss:		0.344773
  validation accuracy:		91.09 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.152951
  validation loss:		0.347678
  validation accuracy:		90.54 %
Epoch 1003 of 2000 took 0.096s
  training loss:		0.150614
  validation loss:		0.344218
  validation accuracy:		90.76 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.152416
  validation loss:		0.341365
  validation accuracy:		90.87 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.158024
  validation loss:		0.370241
  validation accuracy:		89.89 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.160195
  validation loss:		0.365367
  validation accuracy:		90.00 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.153752
  validation loss:		0.363711
  validation accuracy:		89.89 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.148417
  validation loss:		0.348330
  validation accuracy:		91.20 %
Epoch 1009 of 2000 took 0.096s
  training loss:		0.155025
  validation loss:		0.368007
  validation accuracy:		90.22 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.153082
  validation loss:		0.355013
  validation accuracy:		90.00 %
Epoch 1011 of 2000 took 0.096s
  training loss:		0.147136
  validation loss:		0.392450
  validation accuracy:		89.78 %
Epoch 1012 of 2000 took 0.096s
  training loss:		0.152955
  validation loss:		0.346359
  validation accuracy:		90.76 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.151599
  validation loss:		0.349347
  validation accuracy:		90.65 %
Epoch 1014 of 2000 took 0.096s
  training loss:		0.159029
  validation loss:		0.341667
  validation accuracy:		90.76 %
Epoch 1015 of 2000 took 0.097s
  training loss:		0.150458
  validation loss:		0.347627
  validation accuracy:		90.54 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.151307
  validation loss:		0.371082
  validation accuracy:		89.89 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.153559
  validation loss:		0.380979
  validation accuracy:		89.78 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.152147
  validation loss:		0.354301
  validation accuracy:		90.22 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.151471
  validation loss:		0.353778
  validation accuracy:		90.43 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.152697
  validation loss:		0.347691
  validation accuracy:		90.43 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.147053
  validation loss:		0.365025
  validation accuracy:		90.11 %
Epoch 1022 of 2000 took 0.096s
  training loss:		0.150871
  validation loss:		0.352905
  validation accuracy:		90.76 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.151093
  validation loss:		0.358706
  validation accuracy:		90.33 %
Epoch 1024 of 2000 took 0.096s
  training loss:		0.152105
  validation loss:		0.360963
  validation accuracy:		90.43 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.150762
  validation loss:		0.352719
  validation accuracy:		90.43 %
Epoch 1026 of 2000 took 0.096s
  training loss:		0.149490
  validation loss:		0.349293
  validation accuracy:		90.43 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.146979
  validation loss:		0.359280
  validation accuracy:		90.00 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.150944
  validation loss:		0.377793
  validation accuracy:		89.67 %
Epoch 1029 of 2000 took 0.096s
  training loss:		0.153824
  validation loss:		0.360868
  validation accuracy:		89.78 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.152662
  validation loss:		0.345932
  validation accuracy:		90.43 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.145577
  validation loss:		0.368204
  validation accuracy:		89.57 %
Epoch 1032 of 2000 took 0.096s
  training loss:		0.152517
  validation loss:		0.343448
  validation accuracy:		90.87 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.151054
  validation loss:		0.367585
  validation accuracy:		89.57 %
Epoch 1034 of 2000 took 0.096s
  training loss:		0.148231
  validation loss:		0.386016
  validation accuracy:		89.89 %
Epoch 1035 of 2000 took 0.097s
  training loss:		0.153987
  validation loss:		0.341445
  validation accuracy:		91.20 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.150391
  validation loss:		0.357425
  validation accuracy:		90.65 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.144604
  validation loss:		0.358587
  validation accuracy:		90.54 %
Epoch 1038 of 2000 took 0.097s
  training loss:		0.146158
  validation loss:		0.344173
  validation accuracy:		90.54 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.148128
  validation loss:		0.350491
  validation accuracy:		90.00 %
Epoch 1040 of 2000 took 0.096s
  training loss:		0.153916
  validation loss:		0.372356
  validation accuracy:		89.67 %
Epoch 1041 of 2000 took 0.096s
  training loss:		0.147809
  validation loss:		0.372014
  validation accuracy:		89.89 %
Epoch 1042 of 2000 took 0.097s
  training loss:		0.153378
  validation loss:		0.370344
  validation accuracy:		90.00 %
Epoch 1043 of 2000 took 0.097s
  training loss:		0.157316
  validation loss:		0.380939
  validation accuracy:		89.67 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.148550
  validation loss:		0.367263
  validation accuracy:		90.22 %
Epoch 1045 of 2000 took 0.096s
  training loss:		0.148329
  validation loss:		0.375036
  validation accuracy:		89.67 %
Epoch 1046 of 2000 took 0.098s
  training loss:		0.144303
  validation loss:		0.352687
  validation accuracy:		90.65 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.149962
  validation loss:		0.348252
  validation accuracy:		90.65 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.151902
  validation loss:		0.372533
  validation accuracy:		89.67 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.145078
  validation loss:		0.349814
  validation accuracy:		90.98 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.152297
  validation loss:		0.372913
  validation accuracy:		89.89 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.148611
  validation loss:		0.355846
  validation accuracy:		90.43 %
Epoch 1052 of 2000 took 0.096s
  training loss:		0.147804
  validation loss:		0.363157
  validation accuracy:		90.22 %
Epoch 1053 of 2000 took 0.096s
  training loss:		0.149972
  validation loss:		0.370033
  validation accuracy:		90.43 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.150492
  validation loss:		0.347416
  validation accuracy:		90.54 %
Epoch 1055 of 2000 took 0.096s
  training loss:		0.152600
  validation loss:		0.371833
  validation accuracy:		89.78 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.148087
  validation loss:		0.374032
  validation accuracy:		89.78 %
Epoch 1057 of 2000 took 0.096s
  training loss:		0.152067
  validation loss:		0.368624
  validation accuracy:		89.89 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.143878
  validation loss:		0.351775
  validation accuracy:		90.54 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.149611
  validation loss:		0.358354
  validation accuracy:		91.09 %
Epoch 1060 of 2000 took 0.096s
  training loss:		0.147761
  validation loss:		0.368923
  validation accuracy:		90.22 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.148081
  validation loss:		0.362063
  validation accuracy:		90.65 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.144658
  validation loss:		0.355042
  validation accuracy:		90.33 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.146445
  validation loss:		0.370927
  validation accuracy:		89.78 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.149726
  validation loss:		0.390037
  validation accuracy:		90.00 %
Epoch 1065 of 2000 took 0.096s
  training loss:		0.146836
  validation loss:		0.373906
  validation accuracy:		90.43 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.143608
  validation loss:		0.347255
  validation accuracy:		90.76 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.148617
  validation loss:		0.372722
  validation accuracy:		89.67 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.152657
  validation loss:		0.349318
  validation accuracy:		90.43 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.146092
  validation loss:		0.367558
  validation accuracy:		90.00 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.145834
  validation loss:		0.376664
  validation accuracy:		89.78 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.151511
  validation loss:		0.391049
  validation accuracy:		89.46 %
Epoch 1072 of 2000 took 0.096s
  training loss:		0.149827
  validation loss:		0.374767
  validation accuracy:		90.11 %
Epoch 1073 of 2000 took 0.096s
  training loss:		0.149224
  validation loss:		0.361200
  validation accuracy:		90.22 %
Epoch 1074 of 2000 took 0.096s
  training loss:		0.146478
  validation loss:		0.357907
  validation accuracy:		90.65 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.151150
  validation loss:		0.359234
  validation accuracy:		90.54 %
Epoch 1076 of 2000 took 0.096s
  training loss:		0.149905
  validation loss:		0.349096
  validation accuracy:		90.76 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.151612
  validation loss:		0.357418
  validation accuracy:		90.33 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.149681
  validation loss:		0.386560
  validation accuracy:		89.67 %
Epoch 1079 of 2000 took 0.097s
  training loss:		0.141993
  validation loss:		0.370958
  validation accuracy:		89.89 %
Epoch 1080 of 2000 took 0.096s
  training loss:		0.141216
  validation loss:		0.387771
  validation accuracy:		90.00 %
Epoch 1081 of 2000 took 0.096s
  training loss:		0.151947
  validation loss:		0.357320
  validation accuracy:		90.65 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.147966
  validation loss:		0.387673
  validation accuracy:		89.57 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.145825
  validation loss:		0.351686
  validation accuracy:		91.09 %
Epoch 1084 of 2000 took 0.103s
  training loss:		0.143444
  validation loss:		0.384442
  validation accuracy:		90.33 %
Epoch 1085 of 2000 took 0.103s
  training loss:		0.145864
  validation loss:		0.355862
  validation accuracy:		90.87 %
Epoch 1086 of 2000 took 0.103s
  training loss:		0.147350
  validation loss:		0.356077
  validation accuracy:		90.87 %
Epoch 1087 of 2000 took 0.103s
  training loss:		0.144458
  validation loss:		0.361471
  validation accuracy:		90.87 %
Epoch 1088 of 2000 took 0.102s
  training loss:		0.146244
  validation loss:		0.357461
  validation accuracy:		90.98 %
Epoch 1089 of 2000 took 0.100s
  training loss:		0.151609
  validation loss:		0.384442
  validation accuracy:		89.67 %
Epoch 1090 of 2000 took 0.099s
  training loss:		0.152307
  validation loss:		0.376890
  validation accuracy:		90.11 %
Epoch 1091 of 2000 took 0.100s
  training loss:		0.152028
  validation loss:		0.383827
  validation accuracy:		89.57 %
Epoch 1092 of 2000 took 0.100s
  training loss:		0.142952
  validation loss:		0.395371
  validation accuracy:		89.46 %
Epoch 1093 of 2000 took 0.100s
  training loss:		0.150974
  validation loss:		0.362023
  validation accuracy:		90.11 %
Epoch 1094 of 2000 took 0.099s
  training loss:		0.154709
  validation loss:		0.351197
  validation accuracy:		90.65 %
Epoch 1095 of 2000 took 0.100s
  training loss:		0.145117
  validation loss:		0.369088
  validation accuracy:		90.22 %
Epoch 1096 of 2000 took 0.098s
  training loss:		0.146469
  validation loss:		0.373589
  validation accuracy:		90.11 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.140318
  validation loss:		0.349018
  validation accuracy:		90.98 %
Epoch 1098 of 2000 took 0.096s
  training loss:		0.143430
  validation loss:		0.383183
  validation accuracy:		89.67 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.149843
  validation loss:		0.379719
  validation accuracy:		90.11 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.145915
  validation loss:		0.382827
  validation accuracy:		89.67 %
Epoch 1101 of 2000 took 0.096s
  training loss:		0.141700
  validation loss:		0.356296
  validation accuracy:		90.65 %
Epoch 1102 of 2000 took 0.096s
  training loss:		0.149357
  validation loss:		0.362684
  validation accuracy:		90.65 %
Epoch 1103 of 2000 took 0.096s
  training loss:		0.145294
  validation loss:		0.356605
  validation accuracy:		91.09 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.143945
  validation loss:		0.352010
  validation accuracy:		90.65 %
Epoch 1105 of 2000 took 0.096s
  training loss:		0.143720
  validation loss:		0.356591
  validation accuracy:		91.20 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.144418
  validation loss:		0.371203
  validation accuracy:		90.43 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.148495
  validation loss:		0.371940
  validation accuracy:		90.22 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.147894
  validation loss:		0.386754
  validation accuracy:		89.46 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.141758
  validation loss:		0.360075
  validation accuracy:		91.09 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.147104
  validation loss:		0.351984
  validation accuracy:		91.09 %
Epoch 1111 of 2000 took 0.096s
  training loss:		0.139372
  validation loss:		0.384394
  validation accuracy:		89.78 %
Epoch 1112 of 2000 took 0.096s
  training loss:		0.146094
  validation loss:		0.351348
  validation accuracy:		90.98 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.145704
  validation loss:		0.393520
  validation accuracy:		89.35 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.146991
  validation loss:		0.368443
  validation accuracy:		90.65 %
Epoch 1115 of 2000 took 0.096s
  training loss:		0.144588
  validation loss:		0.362262
  validation accuracy:		90.54 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.146816
  validation loss:		0.369514
  validation accuracy:		90.33 %
Epoch 1117 of 2000 took 0.096s
  training loss:		0.149969
  validation loss:		0.360814
  validation accuracy:		91.09 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.143393
  validation loss:		0.359718
  validation accuracy:		90.76 %
Epoch 1119 of 2000 took 0.096s
  training loss:		0.147164
  validation loss:		0.374477
  validation accuracy:		90.54 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.140630
  validation loss:		0.381695
  validation accuracy:		89.57 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.141724
  validation loss:		0.363783
  validation accuracy:		90.43 %
Epoch 1122 of 2000 took 0.096s
  training loss:		0.140931
  validation loss:		0.374828
  validation accuracy:		90.22 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.151905
  validation loss:		0.366035
  validation accuracy:		90.11 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.150899
  validation loss:		0.376590
  validation accuracy:		90.00 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.141001
  validation loss:		0.360496
  validation accuracy:		90.87 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.146164
  validation loss:		0.375646
  validation accuracy:		89.57 %
Epoch 1127 of 2000 took 0.096s
  training loss:		0.142967
  validation loss:		0.399829
  validation accuracy:		89.78 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.149873
  validation loss:		0.371541
  validation accuracy:		89.78 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.140147
  validation loss:		0.376328
  validation accuracy:		90.22 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.143692
  validation loss:		0.364783
  validation accuracy:		90.76 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.132887
  validation loss:		0.382634
  validation accuracy:		89.67 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.136561
  validation loss:		0.382888
  validation accuracy:		89.89 %
Epoch 1133 of 2000 took 0.096s
  training loss:		0.145221
  validation loss:		0.365895
  validation accuracy:		90.33 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.143245
  validation loss:		0.358616
  validation accuracy:		90.22 %
Epoch 1135 of 2000 took 0.096s
  training loss:		0.140988
  validation loss:		0.367969
  validation accuracy:		90.76 %
Epoch 1136 of 2000 took 0.096s
  training loss:		0.146434
  validation loss:		0.367005
  validation accuracy:		90.33 %
Epoch 1137 of 2000 took 0.096s
  training loss:		0.146391
  validation loss:		0.358593
  validation accuracy:		90.43 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.141722
  validation loss:		0.383794
  validation accuracy:		89.78 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.142150
  validation loss:		0.358200
  validation accuracy:		90.87 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.139403
  validation loss:		0.392230
  validation accuracy:		89.78 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.149261
  validation loss:		0.369251
  validation accuracy:		90.22 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.143999
  validation loss:		0.371063
  validation accuracy:		90.33 %
Epoch 1143 of 2000 took 0.096s
  training loss:		0.140545
  validation loss:		0.366689
  validation accuracy:		90.76 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.150886
  validation loss:		0.362139
  validation accuracy:		90.33 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.138793
  validation loss:		0.374817
  validation accuracy:		90.00 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.142626
  validation loss:		0.367597
  validation accuracy:		90.54 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.148692
  validation loss:		0.368143
  validation accuracy:		90.22 %
Epoch 1148 of 2000 took 0.096s
  training loss:		0.141101
  validation loss:		0.355603
  validation accuracy:		90.43 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.137665
  validation loss:		0.349318
  validation accuracy:		90.87 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.141036
  validation loss:		0.393408
  validation accuracy:		89.46 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.142154
  validation loss:		0.386639
  validation accuracy:		89.24 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.143044
  validation loss:		0.363693
  validation accuracy:		90.87 %
Epoch 1153 of 2000 took 0.096s
  training loss:		0.139747
  validation loss:		0.378962
  validation accuracy:		90.00 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.137423
  validation loss:		0.365427
  validation accuracy:		90.65 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.139576
  validation loss:		0.386756
  validation accuracy:		89.78 %
Epoch 1156 of 2000 took 0.096s
  training loss:		0.146413
  validation loss:		0.363557
  validation accuracy:		90.43 %
Epoch 1157 of 2000 took 0.101s
  training loss:		0.143481
  validation loss:		0.369969
  validation accuracy:		90.54 %
Epoch 1158 of 2000 took 0.108s
  training loss:		0.137750
  validation loss:		0.369411
  validation accuracy:		90.33 %
Epoch 1159 of 2000 took 0.113s
  training loss:		0.137004
  validation loss:		0.382170
  validation accuracy:		90.00 %
Epoch 1160 of 2000 took 0.138s
  training loss:		0.142306
  validation loss:		0.384980
  validation accuracy:		89.67 %
Epoch 1161 of 2000 took 0.099s
  training loss:		0.139497
  validation loss:		0.371686
  validation accuracy:		90.22 %
Epoch 1162 of 2000 took 0.098s
  training loss:		0.147972
  validation loss:		0.375952
  validation accuracy:		90.22 %
Epoch 1163 of 2000 took 0.105s
  training loss:		0.136482
  validation loss:		0.361253
  validation accuracy:		91.41 %
Epoch 1164 of 2000 took 0.105s
  training loss:		0.145309
  validation loss:		0.365369
  validation accuracy:		91.20 %
Epoch 1165 of 2000 took 0.103s
  training loss:		0.143685
  validation loss:		0.376006
  validation accuracy:		90.43 %
Epoch 1166 of 2000 took 0.103s
  training loss:		0.145751
  validation loss:		0.383392
  validation accuracy:		89.67 %
Epoch 1167 of 2000 took 0.101s
  training loss:		0.140167
  validation loss:		0.366383
  validation accuracy:		90.87 %
Epoch 1168 of 2000 took 0.100s
  training loss:		0.139386
  validation loss:		0.376683
  validation accuracy:		89.89 %
Epoch 1169 of 2000 took 0.101s
  training loss:		0.136599
  validation loss:		0.379914
  validation accuracy:		90.11 %
Epoch 1170 of 2000 took 0.100s
  training loss:		0.141347
  validation loss:		0.373446
  validation accuracy:		90.22 %
Epoch 1171 of 2000 took 0.101s
  training loss:		0.136609
  validation loss:		0.384208
  validation accuracy:		89.46 %
Epoch 1172 of 2000 took 0.100s
  training loss:		0.139201
  validation loss:		0.366796
  validation accuracy:		90.43 %
Epoch 1173 of 2000 took 0.100s
  training loss:		0.139564
  validation loss:		0.378517
  validation accuracy:		89.78 %
Epoch 1174 of 2000 took 0.100s
  training loss:		0.137329
  validation loss:		0.372453
  validation accuracy:		90.33 %
Epoch 1175 of 2000 took 0.100s
  training loss:		0.136931
  validation loss:		0.369121
  validation accuracy:		90.87 %
Epoch 1176 of 2000 took 0.101s
  training loss:		0.140565
  validation loss:		0.359853
  validation accuracy:		90.87 %
Epoch 1177 of 2000 took 0.100s
  training loss:		0.140379
  validation loss:		0.379678
  validation accuracy:		90.00 %
Epoch 1178 of 2000 took 0.101s
  training loss:		0.136264
  validation loss:		0.386226
  validation accuracy:		89.89 %
Epoch 1179 of 2000 took 0.101s
  training loss:		0.136813
  validation loss:		0.365133
  validation accuracy:		90.43 %
Epoch 1180 of 2000 took 0.101s
  training loss:		0.144835
  validation loss:		0.372522
  validation accuracy:		90.33 %
Epoch 1181 of 2000 took 0.101s
  training loss:		0.137620
  validation loss:		0.372732
  validation accuracy:		90.11 %
Epoch 1182 of 2000 took 0.100s
  training loss:		0.136677
  validation loss:		0.359339
  validation accuracy:		90.76 %
Epoch 1183 of 2000 took 0.101s
  training loss:		0.131043
  validation loss:		0.382121
  validation accuracy:		90.11 %
Epoch 1184 of 2000 took 0.100s
  training loss:		0.135999
  validation loss:		0.383020
  validation accuracy:		89.78 %
Epoch 1185 of 2000 took 0.101s
  training loss:		0.138226
  validation loss:		0.367395
  validation accuracy:		90.76 %
Epoch 1186 of 2000 took 0.101s
  training loss:		0.141418
  validation loss:		0.377342
  validation accuracy:		90.43 %
Epoch 1187 of 2000 took 0.101s
  training loss:		0.141115
  validation loss:		0.386180
  validation accuracy:		89.46 %
Epoch 1188 of 2000 took 0.103s
  training loss:		0.139238
  validation loss:		0.361704
  validation accuracy:		90.65 %
Epoch 1189 of 2000 took 0.103s
  training loss:		0.138073
  validation loss:		0.388127
  validation accuracy:		89.67 %
Epoch 1190 of 2000 took 0.104s
  training loss:		0.142636
  validation loss:		0.363520
  validation accuracy:		90.22 %
Epoch 1191 of 2000 took 0.103s
  training loss:		0.140204
  validation loss:		0.359275
  validation accuracy:		90.54 %
Epoch 1192 of 2000 took 0.104s
  training loss:		0.135786
  validation loss:		0.364617
  validation accuracy:		90.87 %
Epoch 1193 of 2000 took 0.104s
  training loss:		0.137632
  validation loss:		0.386028
  validation accuracy:		89.89 %
Epoch 1194 of 2000 took 0.103s
  training loss:		0.139999
  validation loss:		0.383167
  validation accuracy:		89.89 %
Epoch 1195 of 2000 took 0.104s
  training loss:		0.139160
  validation loss:		0.400824
  validation accuracy:		89.35 %
Epoch 1196 of 2000 took 0.104s
  training loss:		0.145346
  validation loss:		0.356351
  validation accuracy:		90.87 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.140262
  validation loss:		0.362605
  validation accuracy:		90.22 %
Epoch 1198 of 2000 took 0.102s
  training loss:		0.143229
  validation loss:		0.406695
  validation accuracy:		89.24 %
Epoch 1199 of 2000 took 0.105s
  training loss:		0.142170
  validation loss:		0.373749
  validation accuracy:		90.65 %
Epoch 1200 of 2000 took 0.143s
  training loss:		0.137330
  validation loss:		0.372351
  validation accuracy:		90.65 %
Epoch 1201 of 2000 took 0.141s
  training loss:		0.136749
  validation loss:		0.364582
  validation accuracy:		91.20 %
Epoch 1202 of 2000 took 0.164s
  training loss:		0.137865
  validation loss:		0.389361
  validation accuracy:		90.11 %
Epoch 1203 of 2000 took 0.107s
  training loss:		0.137886
  validation loss:		0.382720
  validation accuracy:		90.00 %
Epoch 1204 of 2000 took 0.162s
  training loss:		0.135753
  validation loss:		0.361933
  validation accuracy:		90.87 %
Epoch 1205 of 2000 took 0.116s
  training loss:		0.138002
  validation loss:		0.357078
  validation accuracy:		91.09 %
Epoch 1206 of 2000 took 0.107s
  training loss:		0.141306
  validation loss:		0.362297
  validation accuracy:		90.65 %
Epoch 1207 of 2000 took 0.107s
  training loss:		0.132807
  validation loss:		0.379510
  validation accuracy:		90.11 %
Epoch 1208 of 2000 took 0.107s
  training loss:		0.137826
  validation loss:		0.373161
  validation accuracy:		90.43 %
Epoch 1209 of 2000 took 0.107s
  training loss:		0.143600
  validation loss:		0.383699
  validation accuracy:		90.22 %
Epoch 1210 of 2000 took 0.107s
  training loss:		0.138299
  validation loss:		0.387868
  validation accuracy:		90.98 %
Epoch 1211 of 2000 took 0.107s
  training loss:		0.137043
  validation loss:		0.392760
  validation accuracy:		89.24 %
Epoch 1212 of 2000 took 0.106s
  training loss:		0.139493
  validation loss:		0.378487
  validation accuracy:		90.22 %
Epoch 1213 of 2000 took 0.106s
  training loss:		0.138489
  validation loss:		0.360676
  validation accuracy:		91.74 %
Epoch 1214 of 2000 took 0.106s
  training loss:		0.135871
  validation loss:		0.378275
  validation accuracy:		89.89 %
Epoch 1215 of 2000 took 0.106s
  training loss:		0.138173
  validation loss:		0.393324
  validation accuracy:		90.22 %
Epoch 1216 of 2000 took 0.106s
  training loss:		0.135978
  validation loss:		0.359300
  validation accuracy:		91.09 %
Epoch 1217 of 2000 took 0.106s
  training loss:		0.136771
  validation loss:		0.368379
  validation accuracy:		90.76 %
Epoch 1218 of 2000 took 0.106s
  training loss:		0.134417
  validation loss:		0.379054
  validation accuracy:		90.22 %
Epoch 1219 of 2000 took 0.106s
  training loss:		0.138545
  validation loss:		0.372019
  validation accuracy:		90.43 %
Epoch 1220 of 2000 took 0.106s
  training loss:		0.139113
  validation loss:		0.386221
  validation accuracy:		90.33 %
Epoch 1221 of 2000 took 0.106s
  training loss:		0.139786
  validation loss:		0.385509
  validation accuracy:		90.00 %
Epoch 1222 of 2000 took 0.106s
  training loss:		0.130357
  validation loss:		0.424926
  validation accuracy:		89.67 %
Epoch 1223 of 2000 took 0.106s
  training loss:		0.136389
  validation loss:		0.382936
  validation accuracy:		90.22 %
Epoch 1224 of 2000 took 0.106s
  training loss:		0.138045
  validation loss:		0.363722
  validation accuracy:		90.54 %
Epoch 1225 of 2000 took 0.106s
  training loss:		0.135185
  validation loss:		0.367069
  validation accuracy:		90.76 %
Epoch 1226 of 2000 took 0.106s
  training loss:		0.135112
  validation loss:		0.386179
  validation accuracy:		90.00 %
Epoch 1227 of 2000 took 0.106s
  training loss:		0.135954
  validation loss:		0.372907
  validation accuracy:		90.33 %
Epoch 1228 of 2000 took 0.106s
  training loss:		0.133291
  validation loss:		0.379781
  validation accuracy:		91.09 %
Epoch 1229 of 2000 took 0.106s
  training loss:		0.140923
  validation loss:		0.384513
  validation accuracy:		90.22 %
Epoch 1230 of 2000 took 0.106s
  training loss:		0.134118
  validation loss:		0.402088
  validation accuracy:		89.57 %
Epoch 1231 of 2000 took 0.106s
  training loss:		0.131668
  validation loss:		0.379558
  validation accuracy:		90.87 %
Epoch 1232 of 2000 took 0.106s
  training loss:		0.132052
  validation loss:		0.385271
  validation accuracy:		90.33 %
Epoch 1233 of 2000 took 0.106s
  training loss:		0.137787
  validation loss:		0.381483
  validation accuracy:		90.54 %
Epoch 1234 of 2000 took 0.105s
  training loss:		0.130919
  validation loss:		0.384910
  validation accuracy:		90.54 %
Epoch 1235 of 2000 took 0.105s
  training loss:		0.134751
  validation loss:		0.380355
  validation accuracy:		90.00 %
Epoch 1236 of 2000 took 0.105s
  training loss:		0.136964
  validation loss:		0.369082
  validation accuracy:		90.87 %
Epoch 1237 of 2000 took 0.105s
  training loss:		0.134410
  validation loss:		0.362332
  validation accuracy:		90.65 %
Epoch 1238 of 2000 took 0.105s
  training loss:		0.136192
  validation loss:		0.367949
  validation accuracy:		90.87 %
Epoch 1239 of 2000 took 0.105s
  training loss:		0.135893
  validation loss:		0.369431
  validation accuracy:		90.33 %
Epoch 1240 of 2000 took 0.105s
  training loss:		0.132685
  validation loss:		0.370652
  validation accuracy:		91.30 %
Epoch 1241 of 2000 took 0.105s
  training loss:		0.134929
  validation loss:		0.375203
  validation accuracy:		90.33 %
Epoch 1242 of 2000 took 0.105s
  training loss:		0.131288
  validation loss:		0.398659
  validation accuracy:		89.89 %
Epoch 1243 of 2000 took 0.105s
  training loss:		0.130750
  validation loss:		0.399583
  validation accuracy:		89.67 %
Epoch 1244 of 2000 took 0.105s
  training loss:		0.135057
  validation loss:		0.366398
  validation accuracy:		90.76 %
Epoch 1245 of 2000 took 0.105s
  training loss:		0.128247
  validation loss:		0.370146
  validation accuracy:		90.87 %
Epoch 1246 of 2000 took 0.105s
  training loss:		0.128785
  validation loss:		0.382428
  validation accuracy:		89.78 %
Epoch 1247 of 2000 took 0.105s
  training loss:		0.134741
  validation loss:		0.383763
  validation accuracy:		90.65 %
Epoch 1248 of 2000 took 0.105s
  training loss:		0.130452
  validation loss:		0.402225
  validation accuracy:		90.00 %
Epoch 1249 of 2000 took 0.105s
  training loss:		0.135600
  validation loss:		0.391449
  validation accuracy:		90.54 %
Epoch 1250 of 2000 took 0.105s
  training loss:		0.135116
  validation loss:		0.419787
  validation accuracy:		89.57 %
Epoch 1251 of 2000 took 0.105s
  training loss:		0.134276
  validation loss:		0.361502
  validation accuracy:		90.87 %
Epoch 1252 of 2000 took 0.105s
  training loss:		0.137803
  validation loss:		0.376110
  validation accuracy:		90.54 %
Epoch 1253 of 2000 took 0.105s
  training loss:		0.133171
  validation loss:		0.374867
  validation accuracy:		90.76 %
Epoch 1254 of 2000 took 0.106s
  training loss:		0.138494
  validation loss:		0.370206
  validation accuracy:		91.30 %
Epoch 1255 of 2000 took 0.105s
  training loss:		0.131787
  validation loss:		0.402512
  validation accuracy:		89.89 %
Epoch 1256 of 2000 took 0.105s
  training loss:		0.136975
  validation loss:		0.403300
  validation accuracy:		89.89 %
Epoch 1257 of 2000 took 0.105s
  training loss:		0.139230
  validation loss:		0.381750
  validation accuracy:		90.76 %
Epoch 1258 of 2000 took 0.105s
  training loss:		0.132886
  validation loss:		0.391383
  validation accuracy:		89.89 %
Epoch 1259 of 2000 took 0.105s
  training loss:		0.131170
  validation loss:		0.397946
  validation accuracy:		90.65 %
Epoch 1260 of 2000 took 0.105s
  training loss:		0.139245
  validation loss:		0.393154
  validation accuracy:		90.11 %
Epoch 1261 of 2000 took 0.105s
  training loss:		0.131387
  validation loss:		0.397607
  validation accuracy:		90.22 %
Epoch 1262 of 2000 took 0.105s
  training loss:		0.130843
  validation loss:		0.405896
  validation accuracy:		89.57 %
Epoch 1263 of 2000 took 0.105s
  training loss:		0.136767
  validation loss:		0.389449
  validation accuracy:		90.22 %
Epoch 1264 of 2000 took 0.105s
  training loss:		0.124675
  validation loss:		0.378617
  validation accuracy:		90.87 %
Epoch 1265 of 2000 took 0.105s
  training loss:		0.133817
  validation loss:		0.372181
  validation accuracy:		90.43 %
Epoch 1266 of 2000 took 0.105s
  training loss:		0.128621
  validation loss:		0.389623
  validation accuracy:		90.22 %
Epoch 1267 of 2000 took 0.105s
  training loss:		0.130807
  validation loss:		0.451667
  validation accuracy:		88.70 %
Epoch 1268 of 2000 took 0.105s
  training loss:		0.134310
  validation loss:		0.377921
  validation accuracy:		91.09 %
Epoch 1269 of 2000 took 0.105s
  training loss:		0.129589
  validation loss:		0.376176
  validation accuracy:		90.87 %
Epoch 1270 of 2000 took 0.105s
  training loss:		0.129366
  validation loss:		0.396440
  validation accuracy:		90.11 %
Epoch 1271 of 2000 took 0.105s
  training loss:		0.128658
  validation loss:		0.374605
  validation accuracy:		91.20 %
Epoch 1272 of 2000 took 0.105s
  training loss:		0.129312
  validation loss:		0.385252
  validation accuracy:		90.65 %
Epoch 1273 of 2000 took 0.105s
  training loss:		0.130522
  validation loss:		0.406752
  validation accuracy:		90.11 %
Epoch 1274 of 2000 took 0.105s
  training loss:		0.126566
  validation loss:		0.410901
  validation accuracy:		90.11 %
Epoch 1275 of 2000 took 0.105s
  training loss:		0.135147
  validation loss:		0.379603
  validation accuracy:		90.65 %
Epoch 1276 of 2000 took 0.105s
  training loss:		0.129276
  validation loss:		0.369705
  validation accuracy:		90.76 %
Epoch 1277 of 2000 took 0.105s
  training loss:		0.126522
  validation loss:		0.370076
  validation accuracy:		91.63 %
Epoch 1278 of 2000 took 0.105s
  training loss:		0.124910
  validation loss:		0.378911
  validation accuracy:		90.65 %
Epoch 1279 of 2000 took 0.105s
  training loss:		0.129620
  validation loss:		0.372643
  validation accuracy:		90.98 %
Epoch 1280 of 2000 took 0.105s
  training loss:		0.130889
  validation loss:		0.374300
  validation accuracy:		91.20 %
Epoch 1281 of 2000 took 0.105s
  training loss:		0.126272
  validation loss:		0.369112
  validation accuracy:		91.52 %
Epoch 1282 of 2000 took 0.105s
  training loss:		0.129300
  validation loss:		0.375911
  validation accuracy:		91.09 %
Epoch 1283 of 2000 took 0.106s
  training loss:		0.128227
  validation loss:		0.367480
  validation accuracy:		90.98 %
Epoch 1284 of 2000 took 0.105s
  training loss:		0.123307
  validation loss:		0.379989
  validation accuracy:		90.98 %
Epoch 1285 of 2000 took 0.105s
  training loss:		0.127493
  validation loss:		0.411890
  validation accuracy:		90.22 %
Epoch 1286 of 2000 took 0.105s
  training loss:		0.131934
  validation loss:		0.389813
  validation accuracy:		90.00 %
Epoch 1287 of 2000 took 0.105s
  training loss:		0.127893
  validation loss:		0.385958
  validation accuracy:		91.09 %
Epoch 1288 of 2000 took 0.105s
  training loss:		0.124488
  validation loss:		0.355552
  validation accuracy:		91.09 %
Epoch 1289 of 2000 took 0.105s
  training loss:		0.131856
  validation loss:		0.402951
  validation accuracy:		89.89 %
Epoch 1290 of 2000 took 0.105s
  training loss:		0.123775
  validation loss:		0.380981
  validation accuracy:		90.98 %
Epoch 1291 of 2000 took 0.105s
  training loss:		0.126047
  validation loss:		0.385614
  validation accuracy:		90.43 %
Epoch 1292 of 2000 took 0.105s
  training loss:		0.131774
  validation loss:		0.381871
  validation accuracy:		90.43 %
Epoch 1293 of 2000 took 0.105s
  training loss:		0.129152
  validation loss:		0.371343
  validation accuracy:		91.30 %
Epoch 1294 of 2000 took 0.105s
  training loss:		0.126776
  validation loss:		0.375207
  validation accuracy:		91.30 %
Epoch 1295 of 2000 took 0.105s
  training loss:		0.124798
  validation loss:		0.385967
  validation accuracy:		90.65 %
Epoch 1296 of 2000 took 0.105s
  training loss:		0.125873
  validation loss:		0.397711
  validation accuracy:		90.33 %
Epoch 1297 of 2000 took 0.105s
  training loss:		0.131767
  validation loss:		0.409643
  validation accuracy:		89.67 %
Epoch 1298 of 2000 took 0.105s
  training loss:		0.128321
  validation loss:		0.428771
  validation accuracy:		88.80 %
Epoch 1299 of 2000 took 0.105s
  training loss:		0.127225
  validation loss:		0.412330
  validation accuracy:		89.67 %
Epoch 1300 of 2000 took 0.105s
  training loss:		0.125327
  validation loss:		0.379063
  validation accuracy:		91.20 %
Epoch 1301 of 2000 took 0.105s
  training loss:		0.128771
  validation loss:		0.383865
  validation accuracy:		90.65 %
Epoch 1302 of 2000 took 0.105s
  training loss:		0.127655
  validation loss:		0.380265
  validation accuracy:		90.76 %
Epoch 1303 of 2000 took 0.105s
  training loss:		0.126924
  validation loss:		0.389340
  validation accuracy:		90.98 %
Epoch 1304 of 2000 took 0.105s
  training loss:		0.123987
  validation loss:		0.375273
  validation accuracy:		91.63 %
Epoch 1305 of 2000 took 0.105s
  training loss:		0.132319
  validation loss:		0.389981
  validation accuracy:		90.76 %
Epoch 1306 of 2000 took 0.105s
  training loss:		0.127451
  validation loss:		0.379873
  validation accuracy:		90.76 %
Epoch 1307 of 2000 took 0.105s
  training loss:		0.128305
  validation loss:		0.384964
  validation accuracy:		90.98 %
Epoch 1308 of 2000 took 0.105s
  training loss:		0.130088
  validation loss:		0.382023
  validation accuracy:		90.98 %
Epoch 1309 of 2000 took 0.105s
  training loss:		0.125373
  validation loss:		0.410125
  validation accuracy:		90.43 %
Epoch 1310 of 2000 took 0.105s
  training loss:		0.128169
  validation loss:		0.417110
  validation accuracy:		89.67 %
Epoch 1311 of 2000 took 0.105s
  training loss:		0.129164
  validation loss:		0.410264
  validation accuracy:		90.33 %
Epoch 1312 of 2000 took 0.106s
  training loss:		0.126339
  validation loss:		0.390169
  validation accuracy:		90.76 %
Epoch 1313 of 2000 took 0.105s
  training loss:		0.126552
  validation loss:		0.419665
  validation accuracy:		89.67 %
Epoch 1314 of 2000 took 0.105s
  training loss:		0.122189
  validation loss:		0.369679
  validation accuracy:		91.20 %
Epoch 1315 of 2000 took 0.105s
  training loss:		0.126665
  validation loss:		0.385446
  validation accuracy:		90.98 %
Epoch 1316 of 2000 took 0.105s
  training loss:		0.125851
  validation loss:		0.390643
  validation accuracy:		91.30 %
Epoch 1317 of 2000 took 0.105s
  training loss:		0.123652
  validation loss:		0.392819
  validation accuracy:		90.33 %
Epoch 1318 of 2000 took 0.105s
  training loss:		0.127776
  validation loss:		0.382640
  validation accuracy:		90.87 %
Epoch 1319 of 2000 took 0.105s
  training loss:		0.128399
  validation loss:		0.392893
  validation accuracy:		90.76 %
Epoch 1320 of 2000 took 0.105s
  training loss:		0.125988
  validation loss:		0.401225
  validation accuracy:		90.22 %
Epoch 1321 of 2000 took 0.105s
  training loss:		0.126027
  validation loss:		0.380476
  validation accuracy:		91.30 %
Epoch 1322 of 2000 took 0.105s
  training loss:		0.126369
  validation loss:		0.396217
  validation accuracy:		90.76 %
Epoch 1323 of 2000 took 0.105s
  training loss:		0.126597
  validation loss:		0.371672
  validation accuracy:		91.09 %
Epoch 1324 of 2000 took 0.105s
  training loss:		0.131971
  validation loss:		0.376773
  validation accuracy:		90.87 %
Epoch 1325 of 2000 took 0.105s
  training loss:		0.127659
  validation loss:		0.391984
  validation accuracy:		90.65 %
Epoch 1326 of 2000 took 0.105s
  training loss:		0.124224
  validation loss:		0.370751
  validation accuracy:		91.09 %
Epoch 1327 of 2000 took 0.105s
  training loss:		0.122560
  validation loss:		0.433474
  validation accuracy:		89.89 %
Epoch 1328 of 2000 took 0.105s
  training loss:		0.130710
  validation loss:		0.398119
  validation accuracy:		90.33 %
Epoch 1329 of 2000 took 0.105s
  training loss:		0.121240
  validation loss:		0.384741
  validation accuracy:		91.09 %
Epoch 1330 of 2000 took 0.105s
  training loss:		0.126494
  validation loss:		0.396508
  validation accuracy:		90.98 %
Epoch 1331 of 2000 took 0.105s
  training loss:		0.125489
  validation loss:		0.390280
  validation accuracy:		90.98 %
Epoch 1332 of 2000 took 0.105s
  training loss:		0.122471
  validation loss:		0.380948
  validation accuracy:		90.98 %
Epoch 1333 of 2000 took 0.105s
  training loss:		0.123812
  validation loss:		0.396466
  validation accuracy:		90.54 %
Epoch 1334 of 2000 took 0.105s
  training loss:		0.124440
  validation loss:		0.399090
  validation accuracy:		90.43 %
Epoch 1335 of 2000 took 0.105s
  training loss:		0.126598
  validation loss:		0.390142
  validation accuracy:		90.76 %
Epoch 1336 of 2000 took 0.105s
  training loss:		0.120222
  validation loss:		0.381129
  validation accuracy:		91.30 %
Epoch 1337 of 2000 took 0.138s
  training loss:		0.128955
  validation loss:		0.400274
  validation accuracy:		90.87 %
Epoch 1338 of 2000 took 0.111s
  training loss:		0.128271
  validation loss:		0.399389
  validation accuracy:		90.54 %
Epoch 1339 of 2000 took 0.101s
  training loss:		0.123507
  validation loss:		0.392148
  validation accuracy:		90.87 %
Epoch 1340 of 2000 took 0.104s
  training loss:		0.126180
  validation loss:		0.386486
  validation accuracy:		91.20 %
Epoch 1341 of 2000 took 0.100s
  training loss:		0.121220
  validation loss:		0.396819
  validation accuracy:		90.54 %
Epoch 1342 of 2000 took 0.103s
  training loss:		0.120204
  validation loss:		0.394984
  validation accuracy:		90.76 %
Epoch 1343 of 2000 took 0.103s
  training loss:		0.121063
  validation loss:		0.400910
  validation accuracy:		90.54 %
Epoch 1344 of 2000 took 0.101s
  training loss:		0.121631
  validation loss:		0.377060
  validation accuracy:		91.20 %
Epoch 1345 of 2000 took 0.100s
  training loss:		0.127203
  validation loss:		0.392315
  validation accuracy:		91.20 %
Epoch 1346 of 2000 took 0.100s
  training loss:		0.123924
  validation loss:		0.381790
  validation accuracy:		91.09 %
Epoch 1347 of 2000 took 0.100s
  training loss:		0.126947
  validation loss:		0.384910
  validation accuracy:		91.20 %
Epoch 1348 of 2000 took 0.102s
  training loss:		0.122840
  validation loss:		0.386452
  validation accuracy:		90.98 %
Epoch 1349 of 2000 took 0.102s
  training loss:		0.121029
  validation loss:		0.394273
  validation accuracy:		90.76 %
Epoch 1350 of 2000 took 0.100s
  training loss:		0.123719
  validation loss:		0.402132
  validation accuracy:		90.76 %
Epoch 1351 of 2000 took 0.100s
  training loss:		0.121842
  validation loss:		0.405327
  validation accuracy:		90.87 %
Epoch 1352 of 2000 took 0.100s
  training loss:		0.122362
  validation loss:		0.391467
  validation accuracy:		90.76 %
Epoch 1353 of 2000 took 0.101s
  training loss:		0.119611
  validation loss:		0.388274
  validation accuracy:		91.30 %
Epoch 1354 of 2000 took 0.100s
  training loss:		0.121349
  validation loss:		0.384101
  validation accuracy:		91.20 %
Epoch 1355 of 2000 took 0.101s
  training loss:		0.122740
  validation loss:		0.383546
  validation accuracy:		90.98 %
Epoch 1356 of 2000 took 0.100s
  training loss:		0.122679
  validation loss:		0.391803
  validation accuracy:		90.76 %
Epoch 1357 of 2000 took 0.100s
  training loss:		0.119272
  validation loss:		0.416849
  validation accuracy:		90.65 %
Epoch 1358 of 2000 took 0.100s
  training loss:		0.125830
  validation loss:		0.380955
  validation accuracy:		91.20 %
Epoch 1359 of 2000 took 0.100s
  training loss:		0.121028
  validation loss:		0.387488
  validation accuracy:		91.63 %
Epoch 1360 of 2000 took 0.101s
  training loss:		0.120191
  validation loss:		0.395888
  validation accuracy:		90.98 %
Epoch 1361 of 2000 took 0.100s
  training loss:		0.121579
  validation loss:		0.402734
  validation accuracy:		90.65 %
Epoch 1362 of 2000 took 0.100s
  training loss:		0.120711
  validation loss:		0.384250
  validation accuracy:		91.30 %
Epoch 1363 of 2000 took 0.100s
  training loss:		0.120489
  validation loss:		0.404149
  validation accuracy:		90.98 %
Epoch 1364 of 2000 took 0.100s
  training loss:		0.125532
  validation loss:		0.413623
  validation accuracy:		90.76 %
Epoch 1365 of 2000 took 0.100s
  training loss:		0.123222
  validation loss:		0.403433
  validation accuracy:		90.98 %
Epoch 1366 of 2000 took 0.100s
  training loss:		0.118779
  validation loss:		0.402418
  validation accuracy:		90.76 %
Epoch 1367 of 2000 took 0.101s
  training loss:		0.120575
  validation loss:		0.392704
  validation accuracy:		90.98 %
Epoch 1368 of 2000 took 0.100s
  training loss:		0.122408
  validation loss:		0.379658
  validation accuracy:		91.20 %
Epoch 1369 of 2000 took 0.101s
  training loss:		0.120867
  validation loss:		0.391134
  validation accuracy:		90.87 %
Epoch 1370 of 2000 took 0.102s
  training loss:		0.117174
  validation loss:		0.397324
  validation accuracy:		91.41 %
Epoch 1371 of 2000 took 0.100s
  training loss:		0.123465
  validation loss:		0.406347
  validation accuracy:		90.33 %
Epoch 1372 of 2000 took 0.100s
  training loss:		0.121330
  validation loss:		0.387764
  validation accuracy:		90.87 %
Epoch 1373 of 2000 took 0.101s
  training loss:		0.125193
  validation loss:		0.408054
  validation accuracy:		91.09 %
Epoch 1374 of 2000 took 0.100s
  training loss:		0.117505
  validation loss:		0.372435
  validation accuracy:		91.41 %
Epoch 1375 of 2000 took 0.100s
  training loss:		0.118728
  validation loss:		0.391900
  validation accuracy:		90.76 %
Epoch 1376 of 2000 took 0.102s
  training loss:		0.124116
  validation loss:		0.376851
  validation accuracy:		91.09 %
Epoch 1377 of 2000 took 0.145s
  training loss:		0.117148
  validation loss:		0.391669
  validation accuracy:		91.63 %
Epoch 1378 of 2000 took 0.161s
  training loss:		0.121839
  validation loss:		0.401758
  validation accuracy:		90.43 %
Epoch 1379 of 2000 took 0.101s
  training loss:		0.122311
  validation loss:		0.416971
  validation accuracy:		90.43 %
Epoch 1380 of 2000 took 0.100s
  training loss:		0.118329
  validation loss:		0.388250
  validation accuracy:		91.09 %
Epoch 1381 of 2000 took 0.101s
  training loss:		0.121326
  validation loss:		0.410211
  validation accuracy:		90.65 %
Epoch 1382 of 2000 took 0.102s
  training loss:		0.118977
  validation loss:		0.401144
  validation accuracy:		90.65 %
Epoch 1383 of 2000 took 0.109s
  training loss:		0.112629
  validation loss:		0.399275
  validation accuracy:		90.43 %
Epoch 1384 of 2000 took 0.104s
  training loss:		0.123007
  validation loss:		0.422906
  validation accuracy:		90.43 %
Epoch 1385 of 2000 took 0.100s
  training loss:		0.120166
  validation loss:		0.386544
  validation accuracy:		90.98 %
Epoch 1386 of 2000 took 0.100s
  training loss:		0.119138
  validation loss:		0.399154
  validation accuracy:		91.63 %
Epoch 1387 of 2000 took 0.100s
  training loss:		0.116768
  validation loss:		0.387553
  validation accuracy:		91.41 %
Epoch 1388 of 2000 took 0.101s
  training loss:		0.117935
  validation loss:		0.393689
  validation accuracy:		91.09 %
Epoch 1389 of 2000 took 0.100s
  training loss:		0.118627
  validation loss:		0.400662
  validation accuracy:		91.20 %
Epoch 1390 of 2000 took 0.100s
  training loss:		0.119784
  validation loss:		0.408617
  validation accuracy:		90.87 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.119197
  validation loss:		0.396488
  validation accuracy:		91.30 %
Epoch 1392 of 2000 took 0.100s
  training loss:		0.121874
  validation loss:		0.394774
  validation accuracy:		91.20 %
Epoch 1393 of 2000 took 0.100s
  training loss:		0.118949
  validation loss:		0.422011
  validation accuracy:		90.54 %
Epoch 1394 of 2000 took 0.101s
  training loss:		0.116671
  validation loss:		0.396435
  validation accuracy:		91.30 %
Epoch 1395 of 2000 took 0.104s
  training loss:		0.115354
  validation loss:		0.443293
  validation accuracy:		89.89 %
Epoch 1396 of 2000 took 0.101s
  training loss:		0.119407
  validation loss:		0.402380
  validation accuracy:		91.30 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.117050
  validation loss:		0.418235
  validation accuracy:		90.65 %
Epoch 1398 of 2000 took 0.105s
  training loss:		0.119523
  validation loss:		0.385912
  validation accuracy:		91.09 %
Epoch 1399 of 2000 took 0.103s
  training loss:		0.116153
  validation loss:		0.384306
  validation accuracy:		91.20 %
Epoch 1400 of 2000 took 0.102s
  training loss:		0.118276
  validation loss:		0.393594
  validation accuracy:		91.30 %
Epoch 1401 of 2000 took 0.102s
  training loss:		0.118738
  validation loss:		0.404991
  validation accuracy:		90.98 %
Epoch 1402 of 2000 took 0.102s
  training loss:		0.117423
  validation loss:		0.394926
  validation accuracy:		91.09 %
Epoch 1403 of 2000 took 0.103s
  training loss:		0.114551
  validation loss:		0.430616
  validation accuracy:		90.43 %
Epoch 1404 of 2000 took 0.103s
  training loss:		0.119155
  validation loss:		0.380971
  validation accuracy:		91.41 %
Epoch 1405 of 2000 took 0.102s
  training loss:		0.118739
  validation loss:		0.426430
  validation accuracy:		90.65 %
Epoch 1406 of 2000 took 0.103s
  training loss:		0.109925
  validation loss:		0.414554
  validation accuracy:		90.98 %
Epoch 1407 of 2000 took 0.102s
  training loss:		0.112111
  validation loss:		0.436431
  validation accuracy:		90.43 %
Epoch 1408 of 2000 took 0.103s
  training loss:		0.127693
  validation loss:		0.385314
  validation accuracy:		91.09 %
Epoch 1409 of 2000 took 0.102s
  training loss:		0.116678
  validation loss:		0.398306
  validation accuracy:		90.87 %
Epoch 1410 of 2000 took 0.103s
  training loss:		0.112455
  validation loss:		0.408444
  validation accuracy:		91.09 %
Epoch 1411 of 2000 took 0.103s
  training loss:		0.113487
  validation loss:		0.386535
  validation accuracy:		91.30 %
Epoch 1412 of 2000 took 0.102s
  training loss:		0.117462
  validation loss:		0.409576
  validation accuracy:		90.43 %
Epoch 1413 of 2000 took 0.102s
  training loss:		0.114070
  validation loss:		0.398318
  validation accuracy:		91.09 %
Epoch 1414 of 2000 took 0.103s
  training loss:		0.112242
  validation loss:		0.412424
  validation accuracy:		90.54 %
Epoch 1415 of 2000 took 0.102s
  training loss:		0.114527
  validation loss:		0.447832
  validation accuracy:		89.46 %
Epoch 1416 of 2000 took 0.103s
  training loss:		0.114028
  validation loss:		0.404325
  validation accuracy:		90.87 %
Epoch 1417 of 2000 took 0.103s
  training loss:		0.116034
  validation loss:		0.409784
  validation accuracy:		90.98 %
Epoch 1418 of 2000 took 0.103s
  training loss:		0.114779
  validation loss:		0.398631
  validation accuracy:		91.09 %
Epoch 1419 of 2000 took 0.102s
  training loss:		0.121700
  validation loss:		0.426107
  validation accuracy:		90.43 %
Epoch 1420 of 2000 took 0.102s
  training loss:		0.112842
  validation loss:		0.397782
  validation accuracy:		90.76 %
Epoch 1421 of 2000 took 0.102s
  training loss:		0.120152
  validation loss:		0.405228
  validation accuracy:		91.30 %
Epoch 1422 of 2000 took 0.102s
  training loss:		0.113376
  validation loss:		0.383266
  validation accuracy:		91.09 %
Epoch 1423 of 2000 took 0.102s
  training loss:		0.118225
  validation loss:		0.413943
  validation accuracy:		90.98 %
Epoch 1424 of 2000 took 0.102s
  training loss:		0.120038
  validation loss:		0.431534
  validation accuracy:		90.33 %
Epoch 1425 of 2000 took 0.102s
  training loss:		0.119689
  validation loss:		0.398758
  validation accuracy:		91.09 %
Epoch 1426 of 2000 took 0.103s
  training loss:		0.117412
  validation loss:		0.421301
  validation accuracy:		90.65 %
Epoch 1427 of 2000 took 0.103s
  training loss:		0.116101
  validation loss:		0.422911
  validation accuracy:		90.54 %
Epoch 1428 of 2000 took 0.103s
  training loss:		0.116760
  validation loss:		0.413180
  validation accuracy:		91.09 %
Epoch 1429 of 2000 took 0.102s
  training loss:		0.109877
  validation loss:		0.418404
  validation accuracy:		91.20 %
Epoch 1430 of 2000 took 0.102s
  training loss:		0.117000
  validation loss:		0.423473
  validation accuracy:		91.09 %
Epoch 1431 of 2000 took 0.103s
  training loss:		0.116542
  validation loss:		0.436395
  validation accuracy:		89.78 %
Epoch 1432 of 2000 took 0.103s
  training loss:		0.114325
  validation loss:		0.393427
  validation accuracy:		90.98 %
Epoch 1433 of 2000 took 0.103s
  training loss:		0.113306
  validation loss:		0.392271
  validation accuracy:		91.41 %
Epoch 1434 of 2000 took 0.102s
  training loss:		0.116674
  validation loss:		0.400497
  validation accuracy:		90.87 %
Epoch 1435 of 2000 took 0.103s
  training loss:		0.117451
  validation loss:		0.431584
  validation accuracy:		90.54 %
Epoch 1436 of 2000 took 0.102s
  training loss:		0.112873
  validation loss:		0.394500
  validation accuracy:		91.41 %
Epoch 1437 of 2000 took 0.103s
  training loss:		0.119150
  validation loss:		0.426465
  validation accuracy:		90.54 %
Epoch 1438 of 2000 took 0.102s
  training loss:		0.116805
  validation loss:		0.415037
  validation accuracy:		90.33 %
Epoch 1439 of 2000 took 0.102s
  training loss:		0.112043
  validation loss:		0.427115
  validation accuracy:		90.65 %
Epoch 1440 of 2000 took 0.103s
  training loss:		0.117262
  validation loss:		0.411689
  validation accuracy:		90.76 %
Epoch 1441 of 2000 took 0.102s
  training loss:		0.111553
  validation loss:		0.397112
  validation accuracy:		91.20 %
Epoch 1442 of 2000 took 0.102s
  training loss:		0.118268
  validation loss:		0.411997
  validation accuracy:		91.20 %
Epoch 1443 of 2000 took 0.102s
  training loss:		0.112728
  validation loss:		0.418271
  validation accuracy:		90.98 %
Epoch 1444 of 2000 took 0.102s
  training loss:		0.114662
  validation loss:		0.423692
  validation accuracy:		90.43 %
Epoch 1445 of 2000 took 0.102s
  training loss:		0.114237
  validation loss:		0.399028
  validation accuracy:		91.63 %
Epoch 1446 of 2000 took 0.103s
  training loss:		0.114383
  validation loss:		0.404547
  validation accuracy:		90.98 %
Epoch 1447 of 2000 took 0.103s
  training loss:		0.108453
  validation loss:		0.404246
  validation accuracy:		91.30 %
Epoch 1448 of 2000 took 0.102s
  training loss:		0.107405
  validation loss:		0.387586
  validation accuracy:		91.41 %
Epoch 1449 of 2000 took 0.103s
  training loss:		0.112720
  validation loss:		0.399475
  validation accuracy:		91.09 %
Epoch 1450 of 2000 took 0.103s
  training loss:		0.114513
  validation loss:		0.423165
  validation accuracy:		91.20 %
Epoch 1451 of 2000 took 0.102s
  training loss:		0.116384
  validation loss:		0.424910
  validation accuracy:		91.09 %
Epoch 1452 of 2000 took 0.102s
  training loss:		0.116013
  validation loss:		0.399583
  validation accuracy:		90.76 %
Epoch 1453 of 2000 took 0.102s
  training loss:		0.104809
  validation loss:		0.421298
  validation accuracy:		90.65 %
Epoch 1454 of 2000 took 0.102s
  training loss:		0.109772
  validation loss:		0.408156
  validation accuracy:		90.54 %
Epoch 1455 of 2000 took 0.102s
  training loss:		0.109810
  validation loss:		0.401358
  validation accuracy:		91.20 %
Epoch 1456 of 2000 took 0.103s
  training loss:		0.109514
  validation loss:		0.409178
  validation accuracy:		90.76 %
Epoch 1457 of 2000 took 0.103s
  training loss:		0.108916
  validation loss:		0.403143
  validation accuracy:		91.63 %
Epoch 1458 of 2000 took 0.102s
  training loss:		0.111448
  validation loss:		0.408531
  validation accuracy:		91.20 %
Epoch 1459 of 2000 took 0.102s
  training loss:		0.112132
  validation loss:		0.414321
  validation accuracy:		90.65 %
Epoch 1460 of 2000 took 0.102s
  training loss:		0.115185
  validation loss:		0.400243
  validation accuracy:		91.20 %
Epoch 1461 of 2000 took 0.103s
  training loss:		0.108371
  validation loss:		0.429894
  validation accuracy:		90.65 %
Epoch 1462 of 2000 took 0.103s
  training loss:		0.117346
  validation loss:		0.401974
  validation accuracy:		91.30 %
Epoch 1463 of 2000 took 0.102s
  training loss:		0.110666
  validation loss:		0.399279
  validation accuracy:		90.54 %
Epoch 1464 of 2000 took 0.102s
  training loss:		0.115772
  validation loss:		0.438053
  validation accuracy:		90.54 %
Epoch 1465 of 2000 took 0.102s
  training loss:		0.112647
  validation loss:		0.401903
  validation accuracy:		91.09 %
Epoch 1466 of 2000 took 0.103s
  training loss:		0.111475
  validation loss:		0.429804
  validation accuracy:		90.87 %
Epoch 1467 of 2000 took 0.102s
  training loss:		0.111792
  validation loss:		0.421372
  validation accuracy:		90.76 %
Epoch 1468 of 2000 took 0.102s
  training loss:		0.117184
  validation loss:		0.409728
  validation accuracy:		91.09 %
Epoch 1469 of 2000 took 0.103s
  training loss:		0.108549
  validation loss:		0.417598
  validation accuracy:		90.87 %
Epoch 1470 of 2000 took 0.103s
  training loss:		0.116378
  validation loss:		0.426840
  validation accuracy:		90.76 %
Epoch 1471 of 2000 took 0.102s
  training loss:		0.117603
  validation loss:		0.408068
  validation accuracy:		91.52 %
Epoch 1472 of 2000 took 0.103s
  training loss:		0.113065
  validation loss:		0.465396
  validation accuracy:		89.67 %
Epoch 1473 of 2000 took 0.106s
  training loss:		0.109240
  validation loss:		0.407653
  validation accuracy:		90.87 %
Epoch 1474 of 2000 took 0.103s
  training loss:		0.109034
  validation loss:		0.431455
  validation accuracy:		90.65 %
Epoch 1475 of 2000 took 0.103s
  training loss:		0.102795
  validation loss:		0.415454
  validation accuracy:		91.09 %
Epoch 1476 of 2000 took 0.103s
  training loss:		0.109779
  validation loss:		0.411915
  validation accuracy:		90.98 %
Epoch 1477 of 2000 took 0.103s
  training loss:		0.112814
  validation loss:		0.396446
  validation accuracy:		90.65 %
Epoch 1478 of 2000 took 0.103s
  training loss:		0.104333
  validation loss:		0.432253
  validation accuracy:		90.65 %
Epoch 1479 of 2000 took 0.103s
  training loss:		0.108991
  validation loss:		0.425346
  validation accuracy:		91.09 %
Epoch 1480 of 2000 took 0.103s
  training loss:		0.113356
  validation loss:		0.416865
  validation accuracy:		91.41 %
Epoch 1481 of 2000 took 0.103s
  training loss:		0.104529
  validation loss:		0.407563
  validation accuracy:		91.30 %
Epoch 1482 of 2000 took 0.103s
  training loss:		0.106586
  validation loss:		0.416313
  validation accuracy:		90.87 %
Epoch 1483 of 2000 took 0.103s
  training loss:		0.115180
  validation loss:		0.423280
  validation accuracy:		90.98 %
Epoch 1484 of 2000 took 0.103s
  training loss:		0.110515
  validation loss:		0.436570
  validation accuracy:		90.43 %
Epoch 1485 of 2000 took 0.103s
  training loss:		0.104414
  validation loss:		0.394759
  validation accuracy:		91.20 %
Epoch 1486 of 2000 took 0.104s
  training loss:		0.110582
  validation loss:		0.419018
  validation accuracy:		90.76 %
Epoch 1487 of 2000 took 0.103s
  training loss:		0.105623
  validation loss:		0.427957
  validation accuracy:		90.87 %
Epoch 1488 of 2000 took 0.105s
  training loss:		0.105398
  validation loss:		0.423165
  validation accuracy:		90.98 %
Epoch 1489 of 2000 took 0.103s
  training loss:		0.104193
  validation loss:		0.429087
  validation accuracy:		91.20 %
Epoch 1490 of 2000 took 0.103s
  training loss:		0.106207
  validation loss:		0.424278
  validation accuracy:		91.09 %
Epoch 1491 of 2000 took 0.103s
  training loss:		0.105694
  validation loss:		0.426226
  validation accuracy:		90.87 %
Epoch 1492 of 2000 took 0.103s
  training loss:		0.106099
  validation loss:		0.409541
  validation accuracy:		91.30 %
Epoch 1493 of 2000 took 0.103s
  training loss:		0.113120
  validation loss:		0.398979
  validation accuracy:		91.30 %
Epoch 1494 of 2000 took 0.103s
  training loss:		0.109358
  validation loss:		0.408956
  validation accuracy:		90.98 %
Epoch 1495 of 2000 took 0.103s
  training loss:		0.103003
  validation loss:		0.438209
  validation accuracy:		91.09 %
Epoch 1496 of 2000 took 0.103s
  training loss:		0.110278
  validation loss:		0.439252
  validation accuracy:		90.43 %
Epoch 1497 of 2000 took 0.103s
  training loss:		0.105631
  validation loss:		0.439381
  validation accuracy:		90.65 %
Epoch 1498 of 2000 took 0.103s
  training loss:		0.104507
  validation loss:		0.449765
  validation accuracy:		90.11 %
Epoch 1499 of 2000 took 0.103s
  training loss:		0.108003
  validation loss:		0.425008
  validation accuracy:		90.87 %
Epoch 1500 of 2000 took 0.103s
  training loss:		0.099300
  validation loss:		0.407358
  validation accuracy:		90.98 %
Epoch 1501 of 2000 took 0.103s
  training loss:		0.105151
  validation loss:		0.462488
  validation accuracy:		89.89 %
Epoch 1502 of 2000 took 0.103s
  training loss:		0.113921
  validation loss:		0.447903
  validation accuracy:		90.76 %
Epoch 1503 of 2000 took 0.103s
  training loss:		0.108893
  validation loss:		0.450477
  validation accuracy:		90.22 %
Epoch 1504 of 2000 took 0.103s
  training loss:		0.103811
  validation loss:		0.452683
  validation accuracy:		90.87 %
Epoch 1505 of 2000 took 0.103s
  training loss:		0.106259
  validation loss:		0.406586
  validation accuracy:		91.74 %
Epoch 1506 of 2000 took 0.103s
  training loss:		0.104203
  validation loss:		0.407455
  validation accuracy:		91.30 %
Epoch 1507 of 2000 took 0.103s
  training loss:		0.106634
  validation loss:		0.411705
  validation accuracy:		91.09 %
Epoch 1508 of 2000 took 0.103s
  training loss:		0.105040
  validation loss:		0.427868
  validation accuracy:		91.20 %
Epoch 1509 of 2000 took 0.103s
  training loss:		0.099205
  validation loss:		0.426965
  validation accuracy:		91.20 %
Epoch 1510 of 2000 took 0.103s
  training loss:		0.104989
  validation loss:		0.445787
  validation accuracy:		89.89 %
Epoch 1511 of 2000 took 0.103s
  training loss:		0.111264
  validation loss:		0.423416
  validation accuracy:		90.98 %
Epoch 1512 of 2000 took 0.102s
  training loss:		0.107032
  validation loss:		0.426092
  validation accuracy:		90.54 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.103559
  validation loss:		0.396217
  validation accuracy:		91.09 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.109751
  validation loss:		0.427432
  validation accuracy:		90.87 %
Epoch 1515 of 2000 took 0.096s
  training loss:		0.105977
  validation loss:		0.441906
  validation accuracy:		90.22 %
Epoch 1516 of 2000 took 0.097s
  training loss:		0.106692
  validation loss:		0.452673
  validation accuracy:		90.11 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.113552
  validation loss:		0.428820
  validation accuracy:		91.63 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.106800
  validation loss:		0.419596
  validation accuracy:		91.30 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.113648
  validation loss:		0.420003
  validation accuracy:		91.20 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.104283
  validation loss:		0.426613
  validation accuracy:		91.09 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.109370
  validation loss:		0.415838
  validation accuracy:		91.30 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.100158
  validation loss:		0.394598
  validation accuracy:		91.20 %
Epoch 1523 of 2000 took 0.096s
  training loss:		0.112822
  validation loss:		0.423670
  validation accuracy:		91.20 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.103947
  validation loss:		0.430350
  validation accuracy:		90.65 %
Epoch 1525 of 2000 took 0.096s
  training loss:		0.104899
  validation loss:		0.454739
  validation accuracy:		90.33 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.106895
  validation loss:		0.417222
  validation accuracy:		90.98 %
Epoch 1527 of 2000 took 0.096s
  training loss:		0.103774
  validation loss:		0.440598
  validation accuracy:		90.87 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.107028
  validation loss:		0.460980
  validation accuracy:		90.22 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.111450
  validation loss:		0.434956
  validation accuracy:		91.30 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.104800
  validation loss:		0.408299
  validation accuracy:		91.63 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.106997
  validation loss:		0.448425
  validation accuracy:		90.76 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.106196
  validation loss:		0.473033
  validation accuracy:		89.57 %
Epoch 1533 of 2000 took 0.096s
  training loss:		0.108878
  validation loss:		0.423166
  validation accuracy:		90.98 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.100360
  validation loss:		0.454536
  validation accuracy:		90.54 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.107852
  validation loss:		0.411560
  validation accuracy:		91.41 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.105919
  validation loss:		0.416605
  validation accuracy:		91.20 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.107428
  validation loss:		0.417623
  validation accuracy:		91.20 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.105039
  validation loss:		0.425175
  validation accuracy:		91.20 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.097988
  validation loss:		0.433865
  validation accuracy:		90.54 %
Epoch 1540 of 2000 took 0.096s
  training loss:		0.101408
  validation loss:		0.432976
  validation accuracy:		90.87 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.109787
  validation loss:		0.421443
  validation accuracy:		90.98 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.102437
  validation loss:		0.458650
  validation accuracy:		90.43 %
Epoch 1543 of 2000 took 0.096s
  training loss:		0.109002
  validation loss:		0.421658
  validation accuracy:		91.30 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.101256
  validation loss:		0.403493
  validation accuracy:		91.20 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.104976
  validation loss:		0.455355
  validation accuracy:		90.22 %
Epoch 1546 of 2000 took 0.096s
  training loss:		0.104931
  validation loss:		0.445281
  validation accuracy:		90.65 %
Epoch 1547 of 2000 took 0.097s
  training loss:		0.097914
  validation loss:		0.466901
  validation accuracy:		90.43 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.104946
  validation loss:		0.413085
  validation accuracy:		91.63 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.104110
  validation loss:		0.413292
  validation accuracy:		91.30 %
Epoch 1550 of 2000 took 0.096s
  training loss:		0.099385
  validation loss:		0.435028
  validation accuracy:		90.98 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.099737
  validation loss:		0.488258
  validation accuracy:		89.78 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.102348
  validation loss:		0.437490
  validation accuracy:		90.76 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.100953
  validation loss:		0.436315
  validation accuracy:		91.09 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.109496
  validation loss:		0.420746
  validation accuracy:		91.41 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.106606
  validation loss:		0.431436
  validation accuracy:		90.87 %
Epoch 1556 of 2000 took 0.096s
  training loss:		0.099826
  validation loss:		0.429324
  validation accuracy:		91.09 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.105177
  validation loss:		0.447182
  validation accuracy:		90.54 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.105578
  validation loss:		0.433116
  validation accuracy:		90.87 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.100626
  validation loss:		0.412017
  validation accuracy:		91.52 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.103255
  validation loss:		0.418361
  validation accuracy:		91.20 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.107727
  validation loss:		0.438201
  validation accuracy:		90.87 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.101136
  validation loss:		0.427299
  validation accuracy:		90.98 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.100745
  validation loss:		0.473539
  validation accuracy:		89.89 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.104693
  validation loss:		0.426767
  validation accuracy:		91.52 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.105830
  validation loss:		0.442859
  validation accuracy:		90.98 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.105396
  validation loss:		0.439491
  validation accuracy:		90.98 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.106468
  validation loss:		0.453632
  validation accuracy:		90.43 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.105531
  validation loss:		0.429642
  validation accuracy:		91.20 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.105094
  validation loss:		0.444860
  validation accuracy:		91.09 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.099595
  validation loss:		0.418558
  validation accuracy:		91.20 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.101419
  validation loss:		0.446389
  validation accuracy:		90.43 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.100726
  validation loss:		0.421336
  validation accuracy:		91.41 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.100745
  validation loss:		0.448266
  validation accuracy:		90.87 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.101232
  validation loss:		0.438603
  validation accuracy:		91.09 %
Epoch 1575 of 2000 took 0.095s
  training loss:		0.099420
  validation loss:		0.424857
  validation accuracy:		91.41 %
Epoch 1576 of 2000 took 0.095s
  training loss:		0.102237
  validation loss:		0.431918
  validation accuracy:		90.65 %
Epoch 1577 of 2000 took 0.095s
  training loss:		0.108735
  validation loss:		0.426412
  validation accuracy:		91.20 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.100384
  validation loss:		0.456876
  validation accuracy:		90.65 %
Epoch 1579 of 2000 took 0.095s
  training loss:		0.101341
  validation loss:		0.432186
  validation accuracy:		91.30 %
Epoch 1580 of 2000 took 0.095s
  training loss:		0.099451
  validation loss:		0.422515
  validation accuracy:		91.30 %
Epoch 1581 of 2000 took 0.095s
  training loss:		0.100803
  validation loss:		0.445367
  validation accuracy:		91.30 %
Epoch 1582 of 2000 took 0.095s
  training loss:		0.102203
  validation loss:		0.442450
  validation accuracy:		91.09 %
Epoch 1583 of 2000 took 0.095s
  training loss:		0.104332
  validation loss:		0.426340
  validation accuracy:		91.20 %
Epoch 1584 of 2000 took 0.095s
  training loss:		0.096806
  validation loss:		0.466610
  validation accuracy:		90.22 %
Epoch 1585 of 2000 took 0.095s
  training loss:		0.105707
  validation loss:		0.421143
  validation accuracy:		91.09 %
Epoch 1586 of 2000 took 0.095s
  training loss:		0.099013
  validation loss:		0.437793
  validation accuracy:		91.09 %
Epoch 1587 of 2000 took 0.095s
  training loss:		0.099266
  validation loss:		0.418385
  validation accuracy:		91.20 %
Epoch 1588 of 2000 took 0.095s
  training loss:		0.099774
  validation loss:		0.431104
  validation accuracy:		90.98 %
Epoch 1589 of 2000 took 0.095s
  training loss:		0.100654
  validation loss:		0.431739
  validation accuracy:		91.09 %
Epoch 1590 of 2000 took 0.095s
  training loss:		0.102984
  validation loss:		0.462965
  validation accuracy:		90.54 %
Epoch 1591 of 2000 took 0.095s
  training loss:		0.101137
  validation loss:		0.453170
  validation accuracy:		90.65 %
Epoch 1592 of 2000 took 0.095s
  training loss:		0.099138
  validation loss:		0.441448
  validation accuracy:		91.20 %
Epoch 1593 of 2000 took 0.095s
  training loss:		0.095979
  validation loss:		0.469618
  validation accuracy:		90.00 %
Epoch 1594 of 2000 took 0.095s
  training loss:		0.098791
  validation loss:		0.430897
  validation accuracy:		91.20 %
Epoch 1595 of 2000 took 0.095s
  training loss:		0.095558
  validation loss:		0.433638
  validation accuracy:		90.98 %
Epoch 1596 of 2000 took 0.095s
  training loss:		0.090829
  validation loss:		0.468921
  validation accuracy:		90.33 %
Epoch 1597 of 2000 took 0.098s
  training loss:		0.104820
  validation loss:		0.444908
  validation accuracy:		90.98 %
Epoch 1598 of 2000 took 0.100s
  training loss:		0.101215
  validation loss:		0.423839
  validation accuracy:		90.98 %
Epoch 1599 of 2000 took 0.099s
  training loss:		0.103113
  validation loss:		0.450780
  validation accuracy:		90.54 %
Epoch 1600 of 2000 took 0.099s
  training loss:		0.104173
  validation loss:		0.446817
  validation accuracy:		91.52 %
Epoch 1601 of 2000 took 0.099s
  training loss:		0.100261
  validation loss:		0.431142
  validation accuracy:		90.98 %
Epoch 1602 of 2000 took 0.099s
  training loss:		0.102484
  validation loss:		0.441224
  validation accuracy:		90.65 %
Epoch 1603 of 2000 took 0.099s
  training loss:		0.096261
  validation loss:		0.434929
  validation accuracy:		91.63 %
Epoch 1604 of 2000 took 0.099s
  training loss:		0.095847
  validation loss:		0.478305
  validation accuracy:		90.33 %
Epoch 1605 of 2000 took 0.099s
  training loss:		0.098599
  validation loss:		0.424236
  validation accuracy:		91.20 %
Epoch 1606 of 2000 took 0.099s
  training loss:		0.101019
  validation loss:		0.446408
  validation accuracy:		90.98 %
Epoch 1607 of 2000 took 0.099s
  training loss:		0.095731
  validation loss:		0.432790
  validation accuracy:		90.98 %
Epoch 1608 of 2000 took 0.099s
  training loss:		0.100525
  validation loss:		0.444186
  validation accuracy:		90.87 %
Epoch 1609 of 2000 took 0.099s
  training loss:		0.096217
  validation loss:		0.447147
  validation accuracy:		91.30 %
Epoch 1610 of 2000 took 0.100s
  training loss:		0.102263
  validation loss:		0.486310
  validation accuracy:		90.00 %
Epoch 1611 of 2000 took 0.099s
  training loss:		0.095920
  validation loss:		0.441251
  validation accuracy:		91.30 %
Epoch 1612 of 2000 took 0.099s
  training loss:		0.098087
  validation loss:		0.455512
  validation accuracy:		91.09 %
Epoch 1613 of 2000 took 0.099s
  training loss:		0.097019
  validation loss:		0.451951
  validation accuracy:		91.20 %
Epoch 1614 of 2000 took 0.099s
  training loss:		0.102832
  validation loss:		0.465235
  validation accuracy:		90.33 %
Epoch 1615 of 2000 took 0.099s
  training loss:		0.099298
  validation loss:		0.453720
  validation accuracy:		90.98 %
Epoch 1616 of 2000 took 0.099s
  training loss:		0.097652
  validation loss:		0.438225
  validation accuracy:		91.30 %
Epoch 1617 of 2000 took 0.099s
  training loss:		0.099550
  validation loss:		0.451033
  validation accuracy:		90.87 %
Epoch 1618 of 2000 took 0.099s
  training loss:		0.093177
  validation loss:		0.443310
  validation accuracy:		90.87 %
Epoch 1619 of 2000 took 0.099s
  training loss:		0.098480
  validation loss:		0.447981
  validation accuracy:		91.09 %
Epoch 1620 of 2000 took 0.099s
  training loss:		0.091442
  validation loss:		0.450266
  validation accuracy:		90.87 %
Epoch 1621 of 2000 took 0.099s
  training loss:		0.092516
  validation loss:		0.445997
  validation accuracy:		91.52 %
Epoch 1622 of 2000 took 0.099s
  training loss:		0.111576
  validation loss:		0.408231
  validation accuracy:		91.41 %
Epoch 1623 of 2000 took 0.099s
  training loss:		0.107766
  validation loss:		0.450333
  validation accuracy:		91.20 %
Epoch 1624 of 2000 took 0.099s
  training loss:		0.098309
  validation loss:		0.449248
  validation accuracy:		90.54 %
Epoch 1625 of 2000 took 0.099s
  training loss:		0.099282
  validation loss:		0.428259
  validation accuracy:		91.41 %
Epoch 1626 of 2000 took 0.099s
  training loss:		0.096880
  validation loss:		0.436795
  validation accuracy:		91.20 %
Epoch 1627 of 2000 took 0.099s
  training loss:		0.094087
  validation loss:		0.436542
  validation accuracy:		91.52 %
Epoch 1628 of 2000 took 0.099s
  training loss:		0.096672
  validation loss:		0.432384
  validation accuracy:		91.20 %
Epoch 1629 of 2000 took 0.099s
  training loss:		0.093705
  validation loss:		0.447205
  validation accuracy:		90.54 %
Epoch 1630 of 2000 took 0.099s
  training loss:		0.097216
  validation loss:		0.451101
  validation accuracy:		91.20 %
Epoch 1631 of 2000 took 0.099s
  training loss:		0.096606
  validation loss:		0.427294
  validation accuracy:		91.30 %
Epoch 1632 of 2000 took 0.099s
  training loss:		0.098974
  validation loss:		0.492387
  validation accuracy:		90.11 %
Epoch 1633 of 2000 took 0.099s
  training loss:		0.094537
  validation loss:		0.452698
  validation accuracy:		91.63 %
Epoch 1634 of 2000 took 0.099s
  training loss:		0.105106
  validation loss:		0.445046
  validation accuracy:		90.98 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.096004
  validation loss:		0.440847
  validation accuracy:		90.76 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.095353
  validation loss:		0.439111
  validation accuracy:		91.20 %
Epoch 1637 of 2000 took 0.096s
  training loss:		0.110269
  validation loss:		0.428209
  validation accuracy:		91.52 %
Epoch 1638 of 2000 took 0.096s
  training loss:		0.100956
  validation loss:		0.424448
  validation accuracy:		91.30 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.103900
  validation loss:		0.436053
  validation accuracy:		91.09 %
Epoch 1640 of 2000 took 0.097s
  training loss:		0.099521
  validation loss:		0.447771
  validation accuracy:		90.76 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.092139
  validation loss:		0.448438
  validation accuracy:		91.09 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.089552
  validation loss:		0.461622
  validation accuracy:		91.41 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.094918
  validation loss:		0.465613
  validation accuracy:		91.09 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.096629
  validation loss:		0.437709
  validation accuracy:		90.98 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.097190
  validation loss:		0.449629
  validation accuracy:		91.20 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.096533
  validation loss:		0.453618
  validation accuracy:		90.65 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.092935
  validation loss:		0.492065
  validation accuracy:		90.00 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.093260
  validation loss:		0.454593
  validation accuracy:		91.30 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.092579
  validation loss:		0.467898
  validation accuracy:		90.54 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.100735
  validation loss:		0.463088
  validation accuracy:		90.87 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.093515
  validation loss:		0.442754
  validation accuracy:		91.52 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.101652
  validation loss:		0.454109
  validation accuracy:		90.98 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.092578
  validation loss:		0.487039
  validation accuracy:		90.98 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.090412
  validation loss:		0.446645
  validation accuracy:		91.52 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.090245
  validation loss:		0.466423
  validation accuracy:		91.20 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.103824
  validation loss:		0.506455
  validation accuracy:		89.89 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.095358
  validation loss:		0.444005
  validation accuracy:		91.74 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.090262
  validation loss:		0.448847
  validation accuracy:		91.74 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.092994
  validation loss:		0.443219
  validation accuracy:		91.41 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.098262
  validation loss:		0.506779
  validation accuracy:		89.67 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.096944
  validation loss:		0.465178
  validation accuracy:		91.20 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.097439
  validation loss:		0.479017
  validation accuracy:		90.43 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.096764
  validation loss:		0.465529
  validation accuracy:		90.54 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.096646
  validation loss:		0.468795
  validation accuracy:		89.89 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.099390
  validation loss:		0.440015
  validation accuracy:		91.30 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.098841
  validation loss:		0.474334
  validation accuracy:		90.65 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.098650
  validation loss:		0.464621
  validation accuracy:		90.87 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.099391
  validation loss:		0.524849
  validation accuracy:		90.43 %
Epoch 1669 of 2000 took 0.096s
  training loss:		0.097492
  validation loss:		0.455344
  validation accuracy:		91.09 %
Epoch 1670 of 2000 took 0.097s
  training loss:		0.093304
  validation loss:		0.470507
  validation accuracy:		90.43 %
Epoch 1671 of 2000 took 0.097s
  training loss:		0.092137
  validation loss:		0.461211
  validation accuracy:		90.87 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.097740
  validation loss:		0.453169
  validation accuracy:		91.30 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.091549
  validation loss:		0.459848
  validation accuracy:		90.65 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.090720
  validation loss:		0.516463
  validation accuracy:		90.22 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.101154
  validation loss:		0.510758
  validation accuracy:		90.54 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.091199
  validation loss:		0.438442
  validation accuracy:		91.30 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.088795
  validation loss:		0.474436
  validation accuracy:		91.20 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.092914
  validation loss:		0.479099
  validation accuracy:		90.76 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.089640
  validation loss:		0.497732
  validation accuracy:		90.76 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.089218
  validation loss:		0.472650
  validation accuracy:		90.76 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.092019
  validation loss:		0.454475
  validation accuracy:		91.09 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.089035
  validation loss:		0.487313
  validation accuracy:		90.43 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.096877
  validation loss:		0.431422
  validation accuracy:		91.52 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.093082
  validation loss:		0.457971
  validation accuracy:		91.63 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.093407
  validation loss:		0.471472
  validation accuracy:		90.76 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.092433
  validation loss:		0.509072
  validation accuracy:		90.98 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.089146
  validation loss:		0.449110
  validation accuracy:		91.41 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.090967
  validation loss:		0.459453
  validation accuracy:		91.52 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.094339
  validation loss:		0.434381
  validation accuracy:		91.74 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.093906
  validation loss:		0.465826
  validation accuracy:		90.98 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.092847
  validation loss:		0.436401
  validation accuracy:		91.63 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.102689
  validation loss:		0.487752
  validation accuracy:		90.54 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.094852
  validation loss:		0.496517
  validation accuracy:		90.65 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.096817
  validation loss:		0.465611
  validation accuracy:		91.74 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.089236
  validation loss:		0.455201
  validation accuracy:		91.20 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.088415
  validation loss:		0.476720
  validation accuracy:		91.20 %
Epoch 1697 of 2000 took 0.096s
  training loss:		0.091376
  validation loss:		0.498269
  validation accuracy:		90.54 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.091398
  validation loss:		0.462042
  validation accuracy:		91.41 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.088666
  validation loss:		0.443289
  validation accuracy:		91.30 %
Epoch 1700 of 2000 took 0.096s
  training loss:		0.085866
  validation loss:		0.476325
  validation accuracy:		91.30 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.095163
  validation loss:		0.446358
  validation accuracy:		91.41 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.090938
  validation loss:		0.461811
  validation accuracy:		90.54 %
Epoch 1703 of 2000 took 0.097s
  training loss:		0.089139
  validation loss:		0.466197
  validation accuracy:		90.76 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.090594
  validation loss:		0.463405
  validation accuracy:		91.20 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.094495
  validation loss:		0.469302
  validation accuracy:		91.30 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.093832
  validation loss:		0.494118
  validation accuracy:		91.20 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.103240
  validation loss:		0.486816
  validation accuracy:		90.76 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.091052
  validation loss:		0.457506
  validation accuracy:		91.52 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.086038
  validation loss:		0.499908
  validation accuracy:		91.20 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.091037
  validation loss:		0.482066
  validation accuracy:		90.98 %
Epoch 1711 of 2000 took 0.096s
  training loss:		0.096953
  validation loss:		0.518226
  validation accuracy:		90.43 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.099044
  validation loss:		0.459703
  validation accuracy:		91.20 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.092925
  validation loss:		0.557247
  validation accuracy:		90.00 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.092722
  validation loss:		0.478517
  validation accuracy:		91.09 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.085392
  validation loss:		0.470174
  validation accuracy:		91.09 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.088505
  validation loss:		0.472282
  validation accuracy:		90.87 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.091263
  validation loss:		0.462692
  validation accuracy:		91.52 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.097030
  validation loss:		0.467609
  validation accuracy:		90.54 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.086275
  validation loss:		0.478531
  validation accuracy:		91.20 %
Epoch 1720 of 2000 took 0.098s
  training loss:		0.091147
  validation loss:		0.496034
  validation accuracy:		90.33 %
Epoch 1721 of 2000 took 0.099s
  training loss:		0.087278
  validation loss:		0.459941
  validation accuracy:		91.20 %
Epoch 1722 of 2000 took 0.099s
  training loss:		0.086335
  validation loss:		0.490105
  validation accuracy:		90.87 %
Epoch 1723 of 2000 took 0.099s
  training loss:		0.089767
  validation loss:		0.462666
  validation accuracy:		91.41 %
Epoch 1724 of 2000 took 0.099s
  training loss:		0.089007
  validation loss:		0.484314
  validation accuracy:		91.20 %
Epoch 1725 of 2000 took 0.099s
  training loss:		0.084222
  validation loss:		0.493110
  validation accuracy:		90.98 %
Epoch 1726 of 2000 took 0.099s
  training loss:		0.096496
  validation loss:		0.448982
  validation accuracy:		91.41 %
Epoch 1727 of 2000 took 0.099s
  training loss:		0.090530
  validation loss:		0.479481
  validation accuracy:		91.09 %
Epoch 1728 of 2000 took 0.099s
  training loss:		0.091451
  validation loss:		0.460452
  validation accuracy:		91.20 %
Epoch 1729 of 2000 took 0.099s
  training loss:		0.088334
  validation loss:		0.476444
  validation accuracy:		91.41 %
Epoch 1730 of 2000 took 0.099s
  training loss:		0.091453
  validation loss:		0.491699
  validation accuracy:		90.76 %
Epoch 1731 of 2000 took 0.099s
  training loss:		0.080471
  validation loss:		0.441555
  validation accuracy:		91.63 %
Epoch 1732 of 2000 took 0.099s
  training loss:		0.085276
  validation loss:		0.478252
  validation accuracy:		91.30 %
Epoch 1733 of 2000 took 0.099s
  training loss:		0.088974
  validation loss:		0.485880
  validation accuracy:		90.98 %
Epoch 1734 of 2000 took 0.100s
  training loss:		0.089475
  validation loss:		0.468026
  validation accuracy:		91.74 %
Epoch 1735 of 2000 took 0.099s
  training loss:		0.087115
  validation loss:		0.443982
  validation accuracy:		91.41 %
Epoch 1736 of 2000 took 0.099s
  training loss:		0.081240
  validation loss:		0.481598
  validation accuracy:		91.09 %
Epoch 1737 of 2000 took 0.099s
  training loss:		0.082543
  validation loss:		0.454828
  validation accuracy:		91.30 %
Epoch 1738 of 2000 took 0.099s
  training loss:		0.087727
  validation loss:		0.478532
  validation accuracy:		91.63 %
Epoch 1739 of 2000 took 0.099s
  training loss:		0.082660
  validation loss:		0.473404
  validation accuracy:		91.20 %
Epoch 1740 of 2000 took 0.099s
  training loss:		0.086743
  validation loss:		0.475777
  validation accuracy:		91.41 %
Epoch 1741 of 2000 took 0.099s
  training loss:		0.087837
  validation loss:		0.479765
  validation accuracy:		91.30 %
Epoch 1742 of 2000 took 0.099s
  training loss:		0.080917
  validation loss:		0.479729
  validation accuracy:		91.09 %
Epoch 1743 of 2000 took 0.099s
  training loss:		0.086764
  validation loss:		0.467165
  validation accuracy:		91.30 %
Epoch 1744 of 2000 took 0.099s
  training loss:		0.086640
  validation loss:		0.552976
  validation accuracy:		90.54 %
Epoch 1745 of 2000 took 0.099s
  training loss:		0.094504
  validation loss:		0.477600
  validation accuracy:		91.09 %
Epoch 1746 of 2000 took 0.099s
  training loss:		0.089628
  validation loss:		0.494847
  validation accuracy:		90.87 %
Epoch 1747 of 2000 took 0.099s
  training loss:		0.084766
  validation loss:		0.487290
  validation accuracy:		91.30 %
Epoch 1748 of 2000 took 0.099s
  training loss:		0.087401
  validation loss:		0.499876
  validation accuracy:		91.09 %
Epoch 1749 of 2000 took 0.099s
  training loss:		0.087669
  validation loss:		0.478527
  validation accuracy:		91.41 %
Epoch 1750 of 2000 took 0.099s
  training loss:		0.090957
  validation loss:		0.464495
  validation accuracy:		90.98 %
Epoch 1751 of 2000 took 0.099s
  training loss:		0.095599
  validation loss:		0.483695
  validation accuracy:		91.09 %
Epoch 1752 of 2000 took 0.099s
  training loss:		0.091425
  validation loss:		0.510426
  validation accuracy:		91.09 %
Epoch 1753 of 2000 took 0.099s
  training loss:		0.088301
  validation loss:		0.521087
  validation accuracy:		91.09 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.087020
  validation loss:		0.483536
  validation accuracy:		90.98 %
Epoch 1755 of 2000 took 0.099s
  training loss:		0.084232
  validation loss:		0.522501
  validation accuracy:		90.87 %
Epoch 1756 of 2000 took 0.099s
  training loss:		0.085898
  validation loss:		0.510208
  validation accuracy:		90.98 %
Epoch 1757 of 2000 took 0.099s
  training loss:		0.087914
  validation loss:		0.489988
  validation accuracy:		91.30 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.090730
  validation loss:		0.502072
  validation accuracy:		91.09 %
Epoch 1759 of 2000 took 0.099s
  training loss:		0.087135
  validation loss:		0.499988
  validation accuracy:		91.09 %
Epoch 1760 of 2000 took 0.099s
  training loss:		0.091182
  validation loss:		0.481178
  validation accuracy:		90.98 %
Epoch 1761 of 2000 took 0.099s
  training loss:		0.089557
  validation loss:		0.476872
  validation accuracy:		91.74 %
Epoch 1762 of 2000 took 0.099s
  training loss:		0.095202
  validation loss:		0.513809
  validation accuracy:		90.76 %
Epoch 1763 of 2000 took 0.099s
  training loss:		0.089303
  validation loss:		0.490550
  validation accuracy:		90.98 %
Epoch 1764 of 2000 took 0.099s
  training loss:		0.086653
  validation loss:		0.493427
  validation accuracy:		91.41 %
Epoch 1765 of 2000 took 0.099s
  training loss:		0.087128
  validation loss:		0.520666
  validation accuracy:		91.20 %
Epoch 1766 of 2000 took 0.099s
  training loss:		0.086637
  validation loss:		0.503054
  validation accuracy:		90.65 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.083993
  validation loss:		0.513184
  validation accuracy:		90.87 %
Epoch 1768 of 2000 took 0.099s
  training loss:		0.085137
  validation loss:		0.558588
  validation accuracy:		89.89 %
Epoch 1769 of 2000 took 0.099s
  training loss:		0.087093
  validation loss:		0.515414
  validation accuracy:		90.33 %
Epoch 1770 of 2000 took 0.099s
  training loss:		0.087389
  validation loss:		0.514595
  validation accuracy:		90.43 %
Epoch 1771 of 2000 took 0.099s
  training loss:		0.089304
  validation loss:		0.477709
  validation accuracy:		91.52 %
Epoch 1772 of 2000 took 0.099s
  training loss:		0.086716
  validation loss:		0.489190
  validation accuracy:		90.98 %
Epoch 1773 of 2000 took 0.099s
  training loss:		0.084368
  validation loss:		0.556105
  validation accuracy:		90.87 %
Epoch 1774 of 2000 took 0.099s
  training loss:		0.088790
  validation loss:		0.529382
  validation accuracy:		90.76 %
Epoch 1775 of 2000 took 0.099s
  training loss:		0.084144
  validation loss:		0.486850
  validation accuracy:		91.30 %
Epoch 1776 of 2000 took 0.099s
  training loss:		0.086792
  validation loss:		0.511444
  validation accuracy:		91.09 %
Epoch 1777 of 2000 took 0.099s
  training loss:		0.082399
  validation loss:		0.471629
  validation accuracy:		90.87 %
Epoch 1778 of 2000 took 0.099s
  training loss:		0.087866
  validation loss:		0.472678
  validation accuracy:		90.98 %
Epoch 1779 of 2000 took 0.099s
  training loss:		0.087238
  validation loss:		0.505506
  validation accuracy:		90.98 %
Epoch 1780 of 2000 took 0.099s
  training loss:		0.079265
  validation loss:		0.519731
  validation accuracy:		91.20 %
Epoch 1781 of 2000 took 0.099s
  training loss:		0.084410
  validation loss:		0.466497
  validation accuracy:		91.20 %
Epoch 1782 of 2000 took 0.099s
  training loss:		0.085410
  validation loss:		0.498756
  validation accuracy:		91.41 %
Epoch 1783 of 2000 took 0.099s
  training loss:		0.081551
  validation loss:		0.499547
  validation accuracy:		91.09 %
Epoch 1784 of 2000 took 0.099s
  training loss:		0.080472
  validation loss:		0.497104
  validation accuracy:		91.09 %
Epoch 1785 of 2000 took 0.099s
  training loss:		0.078794
  validation loss:		0.504264
  validation accuracy:		91.09 %
Epoch 1786 of 2000 took 0.099s
  training loss:		0.082709
  validation loss:		0.478592
  validation accuracy:		91.30 %
Epoch 1787 of 2000 took 0.099s
  training loss:		0.076492
  validation loss:		0.486858
  validation accuracy:		91.30 %
Epoch 1788 of 2000 took 0.099s
  training loss:		0.083334
  validation loss:		0.494377
  validation accuracy:		91.41 %
Epoch 1789 of 2000 took 0.099s
  training loss:		0.092710
  validation loss:		0.474471
  validation accuracy:		91.41 %
Epoch 1790 of 2000 took 0.099s
  training loss:		0.078338
  validation loss:		0.490591
  validation accuracy:		90.87 %
Epoch 1791 of 2000 took 0.099s
  training loss:		0.080164
  validation loss:		0.517145
  validation accuracy:		91.20 %
Epoch 1792 of 2000 took 0.099s
  training loss:		0.086178
  validation loss:		0.518307
  validation accuracy:		90.98 %
Epoch 1793 of 2000 took 0.099s
  training loss:		0.081390
  validation loss:		0.497569
  validation accuracy:		91.09 %
Epoch 1794 of 2000 took 0.099s
  training loss:		0.086443
  validation loss:		0.516639
  validation accuracy:		91.30 %
Epoch 1795 of 2000 took 0.100s
  training loss:		0.085254
  validation loss:		0.468086
  validation accuracy:		91.30 %
Epoch 1796 of 2000 took 0.099s
  training loss:		0.090755
  validation loss:		0.524714
  validation accuracy:		90.76 %
Epoch 1797 of 2000 took 0.099s
  training loss:		0.081738
  validation loss:		0.520101
  validation accuracy:		90.76 %
Epoch 1798 of 2000 took 0.099s
  training loss:		0.080918
  validation loss:		0.533873
  validation accuracy:		91.09 %
Epoch 1799 of 2000 took 0.099s
  training loss:		0.083151
  validation loss:		0.493112
  validation accuracy:		90.98 %
Epoch 1800 of 2000 took 0.099s
  training loss:		0.082147
  validation loss:		0.505075
  validation accuracy:		90.98 %
Epoch 1801 of 2000 took 0.099s
  training loss:		0.083707
  validation loss:		0.464709
  validation accuracy:		91.85 %
Epoch 1802 of 2000 took 0.099s
  training loss:		0.091891
  validation loss:		0.511487
  validation accuracy:		90.87 %
Epoch 1803 of 2000 took 0.099s
  training loss:		0.086483
  validation loss:		0.523688
  validation accuracy:		90.87 %
Epoch 1804 of 2000 took 0.099s
  training loss:		0.086753
  validation loss:		0.502402
  validation accuracy:		91.41 %
Epoch 1805 of 2000 took 0.099s
  training loss:		0.081067
  validation loss:		0.495668
  validation accuracy:		91.63 %
Epoch 1806 of 2000 took 0.099s
  training loss:		0.084328
  validation loss:		0.507154
  validation accuracy:		91.09 %
Epoch 1807 of 2000 took 0.099s
  training loss:		0.086079
  validation loss:		0.491035
  validation accuracy:		91.30 %
Epoch 1808 of 2000 took 0.099s
  training loss:		0.083525
  validation loss:		0.517849
  validation accuracy:		90.65 %
Epoch 1809 of 2000 took 0.099s
  training loss:		0.080083
  validation loss:		0.573658
  validation accuracy:		90.76 %
Epoch 1810 of 2000 took 0.099s
  training loss:		0.090443
  validation loss:		0.512175
  validation accuracy:		90.65 %
Epoch 1811 of 2000 took 0.099s
  training loss:		0.083237
  validation loss:		0.524867
  validation accuracy:		90.98 %
Epoch 1812 of 2000 took 0.099s
  training loss:		0.083263
  validation loss:		0.542317
  validation accuracy:		90.76 %
Epoch 1813 of 2000 took 0.099s
  training loss:		0.080518
  validation loss:		0.540400
  validation accuracy:		90.54 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.088524
  validation loss:		0.543678
  validation accuracy:		90.11 %
Epoch 1815 of 2000 took 0.099s
  training loss:		0.084118
  validation loss:		0.523558
  validation accuracy:		91.20 %
Epoch 1816 of 2000 took 0.099s
  training loss:		0.077261
  validation loss:		0.540890
  validation accuracy:		90.87 %
Epoch 1817 of 2000 took 0.099s
  training loss:		0.074226
  validation loss:		0.500216
  validation accuracy:		91.30 %
Epoch 1818 of 2000 took 0.099s
  training loss:		0.081632
  validation loss:		0.503981
  validation accuracy:		90.87 %
Epoch 1819 of 2000 took 0.099s
  training loss:		0.078701
  validation loss:		0.495543
  validation accuracy:		91.41 %
Epoch 1820 of 2000 took 0.099s
  training loss:		0.089534
  validation loss:		0.549611
  validation accuracy:		90.98 %
Epoch 1821 of 2000 took 0.099s
  training loss:		0.084177
  validation loss:		0.476307
  validation accuracy:		91.30 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.089506
  validation loss:		0.535047
  validation accuracy:		90.76 %
Epoch 1823 of 2000 took 0.099s
  training loss:		0.081725
  validation loss:		0.509415
  validation accuracy:		91.63 %
Epoch 1824 of 2000 took 0.099s
  training loss:		0.080679
  validation loss:		0.484782
  validation accuracy:		90.98 %
Epoch 1825 of 2000 took 0.100s
  training loss:		0.089774
  validation loss:		0.483882
  validation accuracy:		91.09 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.085396
  validation loss:		0.549914
  validation accuracy:		90.98 %
Epoch 1827 of 2000 took 0.099s
  training loss:		0.084225
  validation loss:		0.552166
  validation accuracy:		90.65 %
Epoch 1828 of 2000 took 0.099s
  training loss:		0.089921
  validation loss:		0.514642
  validation accuracy:		90.98 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.077735
  validation loss:		0.517788
  validation accuracy:		90.98 %
Epoch 1830 of 2000 took 0.099s
  training loss:		0.082192
  validation loss:		0.512305
  validation accuracy:		91.41 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.079420
  validation loss:		0.489961
  validation accuracy:		90.98 %
Epoch 1832 of 2000 took 0.099s
  training loss:		0.078058
  validation loss:		0.501504
  validation accuracy:		90.54 %
Epoch 1833 of 2000 took 0.099s
  training loss:		0.079839
  validation loss:		0.525876
  validation accuracy:		90.65 %
Epoch 1834 of 2000 took 0.099s
  training loss:		0.089807
  validation loss:		0.515723
  validation accuracy:		91.20 %
Epoch 1835 of 2000 took 0.099s
  training loss:		0.085546
  validation loss:		0.534476
  validation accuracy:		90.76 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.074122
  validation loss:		0.544540
  validation accuracy:		90.98 %
Epoch 1837 of 2000 took 0.099s
  training loss:		0.081800
  validation loss:		0.490930
  validation accuracy:		90.87 %
Epoch 1838 of 2000 took 0.099s
  training loss:		0.079179
  validation loss:		0.533071
  validation accuracy:		91.30 %
Epoch 1839 of 2000 took 0.099s
  training loss:		0.083920
  validation loss:		0.548987
  validation accuracy:		90.98 %
Epoch 1840 of 2000 took 0.100s
  training loss:		0.079776
  validation loss:		0.551018
  validation accuracy:		90.87 %
Epoch 1841 of 2000 took 0.100s
  training loss:		0.081230
  validation loss:		0.535793
  validation accuracy:		90.98 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.079344
  validation loss:		0.524299
  validation accuracy:		91.20 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.085520
  validation loss:		0.512916
  validation accuracy:		91.41 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.086504
  validation loss:		0.546244
  validation accuracy:		91.20 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.076810
  validation loss:		0.492530
  validation accuracy:		91.74 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.088163
  validation loss:		0.536340
  validation accuracy:		90.65 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.081967
  validation loss:		0.528482
  validation accuracy:		90.98 %
Epoch 1848 of 2000 took 0.096s
  training loss:		0.080124
  validation loss:		0.479666
  validation accuracy:		91.63 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.083830
  validation loss:		0.533238
  validation accuracy:		90.98 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.078468
  validation loss:		0.520822
  validation accuracy:		91.09 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.081657
  validation loss:		0.524548
  validation accuracy:		90.98 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.081285
  validation loss:		0.540798
  validation accuracy:		90.98 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.077341
  validation loss:		0.530177
  validation accuracy:		91.41 %
Epoch 1854 of 2000 took 0.096s
  training loss:		0.078046
  validation loss:		0.488523
  validation accuracy:		91.63 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.074667
  validation loss:		0.526132
  validation accuracy:		91.30 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.084666
  validation loss:		0.511322
  validation accuracy:		91.20 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.082197
  validation loss:		0.493718
  validation accuracy:		92.28 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.076591
  validation loss:		0.493985
  validation accuracy:		91.52 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.078511
  validation loss:		0.508360
  validation accuracy:		91.30 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.084290
  validation loss:		0.543103
  validation accuracy:		90.98 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.075173
  validation loss:		0.526206
  validation accuracy:		90.87 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.077274
  validation loss:		0.510857
  validation accuracy:		91.74 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.087891
  validation loss:		0.554661
  validation accuracy:		91.30 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.084628
  validation loss:		0.550904
  validation accuracy:		91.09 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.074920
  validation loss:		0.508264
  validation accuracy:		91.20 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.079612
  validation loss:		0.528659
  validation accuracy:		91.09 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.073507
  validation loss:		0.521068
  validation accuracy:		91.09 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.078425
  validation loss:		0.518216
  validation accuracy:		91.96 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.081024
  validation loss:		0.555323
  validation accuracy:		90.98 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.084577
  validation loss:		0.510360
  validation accuracy:		90.98 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.085303
  validation loss:		0.530486
  validation accuracy:		90.76 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.081564
  validation loss:		0.526320
  validation accuracy:		91.41 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.076833
  validation loss:		0.520480
  validation accuracy:		91.41 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.080459
  validation loss:		0.547491
  validation accuracy:		91.52 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.088933
  validation loss:		0.543371
  validation accuracy:		91.30 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.083741
  validation loss:		0.504868
  validation accuracy:		91.30 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.073042
  validation loss:		0.544284
  validation accuracy:		91.41 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.078268
  validation loss:		0.531012
  validation accuracy:		91.63 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.082414
  validation loss:		0.521984
  validation accuracy:		91.20 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.081987
  validation loss:		0.540426
  validation accuracy:		91.41 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.078246
  validation loss:		0.573619
  validation accuracy:		90.00 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.081033
  validation loss:		0.519910
  validation accuracy:		91.52 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.079671
  validation loss:		0.542175
  validation accuracy:		91.52 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.074751
  validation loss:		0.544012
  validation accuracy:		91.41 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.078929
  validation loss:		0.529287
  validation accuracy:		91.30 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.077563
  validation loss:		0.506208
  validation accuracy:		92.17 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.083423
  validation loss:		0.542803
  validation accuracy:		90.87 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.076555
  validation loss:		0.502552
  validation accuracy:		91.63 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.075373
  validation loss:		0.573070
  validation accuracy:		91.20 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.075887
  validation loss:		0.529983
  validation accuracy:		91.63 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.083675
  validation loss:		0.544937
  validation accuracy:		91.09 %
Epoch 1892 of 2000 took 0.098s
  training loss:		0.076659
  validation loss:		0.542299
  validation accuracy:		91.09 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.075081
  validation loss:		0.534909
  validation accuracy:		91.52 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.076052
  validation loss:		0.535931
  validation accuracy:		91.85 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.080915
  validation loss:		0.549801
  validation accuracy:		90.76 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.083312
  validation loss:		0.595347
  validation accuracy:		90.76 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.083373
  validation loss:		0.537472
  validation accuracy:		91.30 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.077261
  validation loss:		0.569246
  validation accuracy:		91.63 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.072055
  validation loss:		0.581620
  validation accuracy:		90.43 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.079488
  validation loss:		0.516835
  validation accuracy:		91.09 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.086438
  validation loss:		0.576308
  validation accuracy:		90.87 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.075362
  validation loss:		0.573069
  validation accuracy:		90.98 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.072779
  validation loss:		0.586569
  validation accuracy:		90.54 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.083273
  validation loss:		0.519140
  validation accuracy:		91.30 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.075602
  validation loss:		0.618192
  validation accuracy:		90.98 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.081537
  validation loss:		0.554131
  validation accuracy:		91.41 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.074970
  validation loss:		0.613874
  validation accuracy:		90.43 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.085029
  validation loss:		0.517212
  validation accuracy:		90.98 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.076631
  validation loss:		0.555044
  validation accuracy:		90.87 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.075716
  validation loss:		0.539353
  validation accuracy:		91.63 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.078216
  validation loss:		0.564925
  validation accuracy:		90.54 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.080414
  validation loss:		0.544078
  validation accuracy:		91.52 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.077294
  validation loss:		0.625821
  validation accuracy:		89.78 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.078106
  validation loss:		0.523570
  validation accuracy:		91.52 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.074434
  validation loss:		0.559921
  validation accuracy:		91.20 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.080998
  validation loss:		0.522443
  validation accuracy:		91.52 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.076291
  validation loss:		0.573729
  validation accuracy:		90.87 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.081053
  validation loss:		0.655448
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.100870
  validation loss:		0.518895
  validation accuracy:		92.07 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.072873
  validation loss:		0.542332
  validation accuracy:		91.52 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.073612
  validation loss:		0.548637
  validation accuracy:		90.87 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.078171
  validation loss:		0.561309
  validation accuracy:		91.09 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.078583
  validation loss:		0.615096
  validation accuracy:		91.09 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.074161
  validation loss:		0.537711
  validation accuracy:		91.52 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.083063
  validation loss:		0.547726
  validation accuracy:		91.30 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.077331
  validation loss:		0.534580
  validation accuracy:		91.52 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.072976
  validation loss:		0.539438
  validation accuracy:		91.41 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.077933
  validation loss:		0.567227
  validation accuracy:		91.96 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.088174
  validation loss:		0.547229
  validation accuracy:		91.30 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.068587
  validation loss:		0.550174
  validation accuracy:		91.52 %
Epoch 1931 of 2000 took 0.096s
  training loss:		0.069692
  validation loss:		0.543728
  validation accuracy:		91.41 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.073746
  validation loss:		0.566730
  validation accuracy:		91.20 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.090501
  validation loss:		0.555775
  validation accuracy:		91.30 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.073268
  validation loss:		0.569477
  validation accuracy:		91.09 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.071356
  validation loss:		0.543765
  validation accuracy:		91.74 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.072307
  validation loss:		0.546339
  validation accuracy:		90.98 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.072508
  validation loss:		0.600056
  validation accuracy:		90.98 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.072048
  validation loss:		0.580007
  validation accuracy:		91.20 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.075145
  validation loss:		0.599109
  validation accuracy:		90.43 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.075617
  validation loss:		0.586584
  validation accuracy:		90.76 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.069609
  validation loss:		0.584093
  validation accuracy:		91.52 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.098641
  validation loss:		0.546362
  validation accuracy:		91.41 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.075334
  validation loss:		0.556093
  validation accuracy:		91.30 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.070814
  validation loss:		0.593541
  validation accuracy:		90.33 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.078237
  validation loss:		0.562105
  validation accuracy:		90.98 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.077022
  validation loss:		0.556392
  validation accuracy:		91.30 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.082082
  validation loss:		0.636666
  validation accuracy:		90.98 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.085851
  validation loss:		0.536716
  validation accuracy:		91.41 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.072095
  validation loss:		0.528432
  validation accuracy:		91.41 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.076279
  validation loss:		0.564238
  validation accuracy:		91.09 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.069356
  validation loss:		0.638883
  validation accuracy:		90.33 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.079969
  validation loss:		0.570073
  validation accuracy:		91.52 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.076900
  validation loss:		0.547490
  validation accuracy:		91.52 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.081098
  validation loss:		0.593191
  validation accuracy:		91.20 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.081653
  validation loss:		0.606202
  validation accuracy:		91.30 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.074731
  validation loss:		0.555829
  validation accuracy:		90.65 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.082512
  validation loss:		0.679845
  validation accuracy:		90.54 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.079731
  validation loss:		0.589273
  validation accuracy:		90.98 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.074323
  validation loss:		0.524866
  validation accuracy:		91.41 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.085849
  validation loss:		0.587488
  validation accuracy:		90.98 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.073035
  validation loss:		0.562263
  validation accuracy:		91.30 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.075764
  validation loss:		0.584650
  validation accuracy:		91.41 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.069831
  validation loss:		0.562007
  validation accuracy:		91.63 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.073566
  validation loss:		0.569060
  validation accuracy:		91.30 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.068061
  validation loss:		0.567154
  validation accuracy:		91.30 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.070933
  validation loss:		0.600130
  validation accuracy:		91.30 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.072230
  validation loss:		0.566997
  validation accuracy:		91.09 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.069020
  validation loss:		0.591152
  validation accuracy:		90.98 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.071784
  validation loss:		0.563440
  validation accuracy:		91.41 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.071225
  validation loss:		0.590370
  validation accuracy:		91.20 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.069904
  validation loss:		0.567104
  validation accuracy:		91.30 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.075629
  validation loss:		0.587450
  validation accuracy:		90.98 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.071851
  validation loss:		0.561466
  validation accuracy:		91.41 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.065360
  validation loss:		0.579996
  validation accuracy:		91.41 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.069130
  validation loss:		0.566938
  validation accuracy:		91.74 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.070188
  validation loss:		0.609339
  validation accuracy:		90.54 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.071548
  validation loss:		0.584793
  validation accuracy:		91.41 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.068115
  validation loss:		0.600588
  validation accuracy:		91.52 %
Epoch 1979 of 2000 took 0.097s
  training loss:		0.071869
  validation loss:		0.628114
  validation accuracy:		90.87 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.068222
  validation loss:		0.567376
  validation accuracy:		91.85 %
Epoch 1981 of 2000 took 0.097s
  training loss:		0.085256
  validation loss:		0.575705
  validation accuracy:		90.54 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.077118
  validation loss:		0.582300
  validation accuracy:		91.41 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.072834
  validation loss:		0.569051
  validation accuracy:		91.52 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.091433
  validation loss:		0.506734
  validation accuracy:		92.07 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.076331
  validation loss:		0.604017
  validation accuracy:		91.63 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.070834
  validation loss:		0.626679
  validation accuracy:		90.87 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.068610
  validation loss:		0.573822
  validation accuracy:		90.98 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.083580
  validation loss:		0.608378
  validation accuracy:		90.98 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.067394
  validation loss:		0.589776
  validation accuracy:		90.98 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.073763
  validation loss:		0.601864
  validation accuracy:		90.98 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.067326
  validation loss:		0.615446
  validation accuracy:		91.20 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.075972
  validation loss:		0.598451
  validation accuracy:		90.76 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.093388
  validation loss:		0.576155
  validation accuracy:		91.09 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.074208
  validation loss:		0.620794
  validation accuracy:		90.76 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.076585
  validation loss:		0.601095
  validation accuracy:		91.09 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.072814
  validation loss:		0.595339
  validation accuracy:		90.76 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.072556
  validation loss:		0.566183
  validation accuracy:		91.09 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.068517
  validation loss:		0.596616
  validation accuracy:		90.65 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.074860
  validation loss:		0.608876
  validation accuracy:		90.65 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.067945
  validation loss:		0.635440
  validation accuracy:		90.54 %
Final results:
  test loss:			1.452891
  test accuracy:		81.40 %
