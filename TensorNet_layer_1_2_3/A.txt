Loading data...
#train = 4636, #test = 3855, #valid = 1154
Building model and compiling functions...
Starting training...
Epoch 1 of 2000 took 0.103s
  training loss:		2.985747
  validation loss:		2.961082
  validation accuracy:		14.52 %
Epoch 2 of 2000 took 0.100s
  training loss:		2.954335
  validation loss:		2.910148
  validation accuracy:		11.83 %
Epoch 3 of 2000 took 0.100s
  training loss:		2.914350
  validation loss:		2.854614
  validation accuracy:		11.62 %
Epoch 4 of 2000 took 0.100s
  training loss:		2.872487
  validation loss:		2.796052
  validation accuracy:		11.83 %
Epoch 5 of 2000 took 0.100s
  training loss:		2.824139
  validation loss:		2.735631
  validation accuracy:		11.93 %
Epoch 6 of 2000 took 0.100s
  training loss:		2.772557
  validation loss:		2.670458
  validation accuracy:		12.03 %
Epoch 7 of 2000 took 0.100s
  training loss:		2.713918
  validation loss:		2.601226
  validation accuracy:		11.93 %
Epoch 8 of 2000 took 0.100s
  training loss:		2.650100
  validation loss:		2.530847
  validation accuracy:		11.93 %
Epoch 9 of 2000 took 0.100s
  training loss:		2.579822
  validation loss:		2.464610
  validation accuracy:		11.93 %
Epoch 10 of 2000 took 0.100s
  training loss:		2.510443
  validation loss:		2.409108
  validation accuracy:		11.93 %
Epoch 11 of 2000 took 0.100s
  training loss:		2.445910
  validation loss:		2.371653
  validation accuracy:		11.93 %
Epoch 12 of 2000 took 0.100s
  training loss:		2.393240
  validation loss:		2.347740
  validation accuracy:		11.10 %
Epoch 13 of 2000 took 0.100s
  training loss:		2.356159
  validation loss:		2.335214
  validation accuracy:		9.54 %
Epoch 14 of 2000 took 0.100s
  training loss:		2.332006
  validation loss:		2.325546
  validation accuracy:		10.79 %
Epoch 15 of 2000 took 0.100s
  training loss:		2.317650
  validation loss:		2.315579
  validation accuracy:		14.11 %
Epoch 16 of 2000 took 0.100s
  training loss:		2.309247
  validation loss:		2.303777
  validation accuracy:		16.49 %
Epoch 17 of 2000 took 0.100s
  training loss:		2.303171
  validation loss:		2.301066
  validation accuracy:		18.46 %
Epoch 18 of 2000 took 0.100s
  training loss:		2.299922
  validation loss:		2.299176
  validation accuracy:		14.52 %
Epoch 19 of 2000 took 0.101s
  training loss:		2.296316
  validation loss:		2.295226
  validation accuracy:		14.52 %
Epoch 20 of 2000 took 0.101s
  training loss:		2.293310
  validation loss:		2.296164
  validation accuracy:		15.66 %
Epoch 21 of 2000 took 0.101s
  training loss:		2.291063
  validation loss:		2.292934
  validation accuracy:		17.43 %
Epoch 22 of 2000 took 0.101s
  training loss:		2.289991
  validation loss:		2.291437
  validation accuracy:		17.32 %
Epoch 23 of 2000 took 0.101s
  training loss:		2.288014
  validation loss:		2.286794
  validation accuracy:		18.46 %
Epoch 24 of 2000 took 0.101s
  training loss:		2.286817
  validation loss:		2.286061
  validation accuracy:		16.29 %
Epoch 25 of 2000 took 0.101s
  training loss:		2.284575
  validation loss:		2.279592
  validation accuracy:		18.67 %
Epoch 26 of 2000 took 0.101s
  training loss:		2.282433
  validation loss:		2.291844
  validation accuracy:		10.17 %
Epoch 27 of 2000 took 0.101s
  training loss:		2.280951
  validation loss:		2.283744
  validation accuracy:		17.63 %
Epoch 28 of 2000 took 0.101s
  training loss:		2.279100
  validation loss:		2.280916
  validation accuracy:		16.80 %
Epoch 29 of 2000 took 0.101s
  training loss:		2.277593
  validation loss:		2.279321
  validation accuracy:		18.36 %
Epoch 30 of 2000 took 0.102s
  training loss:		2.275903
  validation loss:		2.274865
  validation accuracy:		19.71 %
Epoch 31 of 2000 took 0.101s
  training loss:		2.274460
  validation loss:		2.276881
  validation accuracy:		19.50 %
Epoch 32 of 2000 took 0.101s
  training loss:		2.273071
  validation loss:		2.271395
  validation accuracy:		18.57 %
Epoch 33 of 2000 took 0.101s
  training loss:		2.271064
  validation loss:		2.270889
  validation accuracy:		20.12 %
Epoch 34 of 2000 took 0.101s
  training loss:		2.269856
  validation loss:		2.271297
  validation accuracy:		21.47 %
Epoch 35 of 2000 took 0.101s
  training loss:		2.267260
  validation loss:		2.264474
  validation accuracy:		19.09 %
Epoch 36 of 2000 took 0.101s
  training loss:		2.266074
  validation loss:		2.263189
  validation accuracy:		19.40 %
Epoch 37 of 2000 took 0.101s
  training loss:		2.264294
  validation loss:		2.267364
  validation accuracy:		18.67 %
Epoch 38 of 2000 took 0.101s
  training loss:		2.261036
  validation loss:		2.261375
  validation accuracy:		21.68 %
Epoch 39 of 2000 took 0.103s
  training loss:		2.259880
  validation loss:		2.260565
  validation accuracy:		17.53 %
Epoch 40 of 2000 took 0.101s
  training loss:		2.257552
  validation loss:		2.257095
  validation accuracy:		22.72 %
Epoch 41 of 2000 took 0.101s
  training loss:		2.255049
  validation loss:		2.255196
  validation accuracy:		22.20 %
Epoch 42 of 2000 took 0.101s
  training loss:		2.251968
  validation loss:		2.253969
  validation accuracy:		23.24 %
Epoch 43 of 2000 took 0.101s
  training loss:		2.248744
  validation loss:		2.253849
  validation accuracy:		18.26 %
Epoch 44 of 2000 took 0.101s
  training loss:		2.245263
  validation loss:		2.253309
  validation accuracy:		21.06 %
Epoch 45 of 2000 took 0.101s
  training loss:		2.242725
  validation loss:		2.240401
  validation accuracy:		26.35 %
Epoch 46 of 2000 took 0.101s
  training loss:		2.239544
  validation loss:		2.232123
  validation accuracy:		24.38 %
Epoch 47 of 2000 took 0.101s
  training loss:		2.234323
  validation loss:		2.241351
  validation accuracy:		25.83 %
Epoch 48 of 2000 took 0.101s
  training loss:		2.230417
  validation loss:		2.232637
  validation accuracy:		25.21 %
Epoch 49 of 2000 took 0.101s
  training loss:		2.226575
  validation loss:		2.227999
  validation accuracy:		25.41 %
Epoch 50 of 2000 took 0.101s
  training loss:		2.221512
  validation loss:		2.232565
  validation accuracy:		16.39 %
Epoch 51 of 2000 took 0.101s
  training loss:		2.216349
  validation loss:		2.220522
  validation accuracy:		26.14 %
Epoch 52 of 2000 took 0.101s
  training loss:		2.211182
  validation loss:		2.213857
  validation accuracy:		28.84 %
Epoch 53 of 2000 took 0.101s
  training loss:		2.204912
  validation loss:		2.211731
  validation accuracy:		24.59 %
Epoch 54 of 2000 took 0.101s
  training loss:		2.199080
  validation loss:		2.200454
  validation accuracy:		23.13 %
Epoch 55 of 2000 took 0.101s
  training loss:		2.190095
  validation loss:		2.205278
  validation accuracy:		20.33 %
Epoch 56 of 2000 took 0.101s
  training loss:		2.182224
  validation loss:		2.187006
  validation accuracy:		27.59 %
Epoch 57 of 2000 took 0.101s
  training loss:		2.173685
  validation loss:		2.176278
  validation accuracy:		28.11 %
Epoch 58 of 2000 took 0.101s
  training loss:		2.163201
  validation loss:		2.179283
  validation accuracy:		25.41 %
Epoch 59 of 2000 took 0.101s
  training loss:		2.153864
  validation loss:		2.162426
  validation accuracy:		26.97 %
Epoch 60 of 2000 took 0.102s
  training loss:		2.140155
  validation loss:		2.148967
  validation accuracy:		31.12 %
Epoch 61 of 2000 took 0.101s
  training loss:		2.125510
  validation loss:		2.137674
  validation accuracy:		31.85 %
Epoch 62 of 2000 took 0.101s
  training loss:		2.111579
  validation loss:		2.123797
  validation accuracy:		27.80 %
Epoch 63 of 2000 took 0.102s
  training loss:		2.097302
  validation loss:		2.114178
  validation accuracy:		29.05 %
Epoch 64 of 2000 took 0.101s
  training loss:		2.077948
  validation loss:		2.092461
  validation accuracy:		30.71 %
Epoch 65 of 2000 took 0.104s
  training loss:		2.059413
  validation loss:		2.082989
  validation accuracy:		31.22 %
Epoch 66 of 2000 took 0.107s
  training loss:		2.039561
  validation loss:		2.068653
  validation accuracy:		31.22 %
Epoch 67 of 2000 took 0.107s
  training loss:		2.019459
  validation loss:		2.049155
  validation accuracy:		31.33 %
Epoch 68 of 2000 took 0.107s
  training loss:		1.997909
  validation loss:		2.038006
  validation accuracy:		32.16 %
Epoch 69 of 2000 took 0.108s
  training loss:		1.974959
  validation loss:		2.005945
  validation accuracy:		34.02 %
Epoch 70 of 2000 took 0.105s
  training loss:		1.950143
  validation loss:		1.987177
  validation accuracy:		36.31 %
Epoch 71 of 2000 took 0.104s
  training loss:		1.928651
  validation loss:		1.971338
  validation accuracy:		31.95 %
Epoch 72 of 2000 took 0.101s
  training loss:		1.907342
  validation loss:		1.950490
  validation accuracy:		35.37 %
Epoch 73 of 2000 took 0.101s
  training loss:		1.878799
  validation loss:		1.934863
  validation accuracy:		36.20 %
Epoch 74 of 2000 took 0.101s
  training loss:		1.857980
  validation loss:		1.921680
  validation accuracy:		36.20 %
Epoch 75 of 2000 took 0.102s
  training loss:		1.841304
  validation loss:		1.901450
  validation accuracy:		38.38 %
Epoch 76 of 2000 took 0.101s
  training loss:		1.816467
  validation loss:		1.884438
  validation accuracy:		38.38 %
Epoch 77 of 2000 took 0.101s
  training loss:		1.796897
  validation loss:		1.877814
  validation accuracy:		36.10 %
Epoch 78 of 2000 took 0.101s
  training loss:		1.782090
  validation loss:		1.852564
  validation accuracy:		37.66 %
Epoch 79 of 2000 took 0.101s
  training loss:		1.762651
  validation loss:		1.845380
  validation accuracy:		38.90 %
Epoch 80 of 2000 took 0.101s
  training loss:		1.740515
  validation loss:		1.822058
  validation accuracy:		40.35 %
Epoch 81 of 2000 took 0.101s
  training loss:		1.722487
  validation loss:		1.814709
  validation accuracy:		39.32 %
Epoch 82 of 2000 took 0.101s
  training loss:		1.700078
  validation loss:		1.786541
  validation accuracy:		40.87 %
Epoch 83 of 2000 took 0.101s
  training loss:		1.692643
  validation loss:		1.776972
  validation accuracy:		39.94 %
Epoch 84 of 2000 took 0.101s
  training loss:		1.669719
  validation loss:		1.758358
  validation accuracy:		42.53 %
Epoch 85 of 2000 took 0.101s
  training loss:		1.654389
  validation loss:		1.763273
  validation accuracy:		39.42 %
Epoch 86 of 2000 took 0.101s
  training loss:		1.636549
  validation loss:		1.739089
  validation accuracy:		44.09 %
Epoch 87 of 2000 took 0.101s
  training loss:		1.614678
  validation loss:		1.709681
  validation accuracy:		44.61 %
Epoch 88 of 2000 took 0.101s
  training loss:		1.604912
  validation loss:		1.687047
  validation accuracy:		44.29 %
Epoch 89 of 2000 took 0.103s
  training loss:		1.580276
  validation loss:		1.685396
  validation accuracy:		40.46 %
Epoch 90 of 2000 took 0.101s
  training loss:		1.558874
  validation loss:		1.651030
  validation accuracy:		45.95 %
Epoch 91 of 2000 took 0.101s
  training loss:		1.538582
  validation loss:		1.635746
  validation accuracy:		44.61 %
Epoch 92 of 2000 took 0.101s
  training loss:		1.516159
  validation loss:		1.618685
  validation accuracy:		44.92 %
Epoch 93 of 2000 took 0.101s
  training loss:		1.497672
  validation loss:		1.608842
  validation accuracy:		45.95 %
Epoch 94 of 2000 took 0.101s
  training loss:		1.475504
  validation loss:		1.564153
  validation accuracy:		45.75 %
Epoch 95 of 2000 took 0.101s
  training loss:		1.444430
  validation loss:		1.542825
  validation accuracy:		45.12 %
Epoch 96 of 2000 took 0.101s
  training loss:		1.420234
  validation loss:		1.514349
  validation accuracy:		47.20 %
Epoch 97 of 2000 took 0.101s
  training loss:		1.384816
  validation loss:		1.483267
  validation accuracy:		48.03 %
Epoch 98 of 2000 took 0.101s
  training loss:		1.360533
  validation loss:		1.458306
  validation accuracy:		49.69 %
Epoch 99 of 2000 took 0.101s
  training loss:		1.326748
  validation loss:		1.431750
  validation accuracy:		48.44 %
Epoch 100 of 2000 took 0.101s
  training loss:		1.298006
  validation loss:		1.408345
  validation accuracy:		49.59 %
Epoch 101 of 2000 took 0.101s
  training loss:		1.261907
  validation loss:		1.373302
  validation accuracy:		50.00 %
Epoch 102 of 2000 took 0.108s
  training loss:		1.240318
  validation loss:		1.360343
  validation accuracy:		50.62 %
Epoch 103 of 2000 took 0.108s
  training loss:		1.209858
  validation loss:		1.335497
  validation accuracy:		50.73 %
Epoch 104 of 2000 took 0.107s
  training loss:		1.185992
  validation loss:		1.298764
  validation accuracy:		52.07 %
Epoch 105 of 2000 took 0.108s
  training loss:		1.161495
  validation loss:		1.275155
  validation accuracy:		51.14 %
Epoch 106 of 2000 took 0.107s
  training loss:		1.131871
  validation loss:		1.257935
  validation accuracy:		52.18 %
Epoch 107 of 2000 took 0.108s
  training loss:		1.119859
  validation loss:		1.240487
  validation accuracy:		52.49 %
Epoch 108 of 2000 took 0.105s
  training loss:		1.101532
  validation loss:		1.211832
  validation accuracy:		52.39 %
Epoch 109 of 2000 took 0.104s
  training loss:		1.075021
  validation loss:		1.203444
  validation accuracy:		53.63 %
Epoch 110 of 2000 took 0.101s
  training loss:		1.067259
  validation loss:		1.227460
  validation accuracy:		52.28 %
Epoch 111 of 2000 took 0.101s
  training loss:		1.047213
  validation loss:		1.169083
  validation accuracy:		54.88 %
Epoch 112 of 2000 took 0.101s
  training loss:		1.028269
  validation loss:		1.152127
  validation accuracy:		53.53 %
Epoch 113 of 2000 took 0.101s
  training loss:		1.018819
  validation loss:		1.140554
  validation accuracy:		54.88 %
Epoch 114 of 2000 took 0.101s
  training loss:		1.001399
  validation loss:		1.140674
  validation accuracy:		55.50 %
Epoch 115 of 2000 took 0.101s
  training loss:		0.992925
  validation loss:		1.138920
  validation accuracy:		54.36 %
Epoch 116 of 2000 took 0.101s
  training loss:		0.973489
  validation loss:		1.122912
  validation accuracy:		56.95 %
Epoch 117 of 2000 took 0.101s
  training loss:		0.963006
  validation loss:		1.115232
  validation accuracy:		55.71 %
Epoch 118 of 2000 took 0.101s
  training loss:		0.954211
  validation loss:		1.114451
  validation accuracy:		56.43 %
Epoch 119 of 2000 took 0.102s
  training loss:		0.950028
  validation loss:		1.076091
  validation accuracy:		57.47 %
Epoch 120 of 2000 took 0.101s
  training loss:		0.931599
  validation loss:		1.075199
  validation accuracy:		58.09 %
Epoch 121 of 2000 took 0.101s
  training loss:		0.920337
  validation loss:		1.068387
  validation accuracy:		58.82 %
Epoch 122 of 2000 took 0.101s
  training loss:		0.914249
  validation loss:		1.057268
  validation accuracy:		58.61 %
Epoch 123 of 2000 took 0.101s
  training loss:		0.913083
  validation loss:		1.049996
  validation accuracy:		58.30 %
Epoch 124 of 2000 took 0.101s
  training loss:		0.905439
  validation loss:		1.068542
  validation accuracy:		58.71 %
Epoch 125 of 2000 took 0.101s
  training loss:		0.898788
  validation loss:		1.035288
  validation accuracy:		59.96 %
Epoch 126 of 2000 took 0.101s
  training loss:		0.893450
  validation loss:		1.035763
  validation accuracy:		60.27 %
Epoch 127 of 2000 took 0.101s
  training loss:		0.879643
  validation loss:		1.043593
  validation accuracy:		60.48 %
Epoch 128 of 2000 took 0.101s
  training loss:		0.874014
  validation loss:		1.038019
  validation accuracy:		59.23 %
Epoch 129 of 2000 took 0.101s
  training loss:		0.869908
  validation loss:		1.019046
  validation accuracy:		60.37 %
Epoch 130 of 2000 took 0.101s
  training loss:		0.864624
  validation loss:		1.035779
  validation accuracy:		59.96 %
Epoch 131 of 2000 took 0.101s
  training loss:		0.865107
  validation loss:		1.005115
  validation accuracy:		61.41 %
Epoch 132 of 2000 took 0.101s
  training loss:		0.855905
  validation loss:		1.006201
  validation accuracy:		62.66 %
Epoch 133 of 2000 took 0.101s
  training loss:		0.856239
  validation loss:		1.010613
  validation accuracy:		62.03 %
Epoch 134 of 2000 took 0.101s
  training loss:		0.857727
  validation loss:		1.017574
  validation accuracy:		61.20 %
Epoch 135 of 2000 took 0.101s
  training loss:		0.848227
  validation loss:		0.993156
  validation accuracy:		62.14 %
Epoch 136 of 2000 took 0.101s
  training loss:		0.838562
  validation loss:		0.996336
  validation accuracy:		62.97 %
Epoch 137 of 2000 took 0.102s
  training loss:		0.833731
  validation loss:		0.990501
  validation accuracy:		63.59 %
Epoch 138 of 2000 took 0.101s
  training loss:		0.818829
  validation loss:		0.980291
  validation accuracy:		63.17 %
Epoch 139 of 2000 took 0.101s
  training loss:		0.823624
  validation loss:		0.978545
  validation accuracy:		64.32 %
Epoch 140 of 2000 took 0.101s
  training loss:		0.808800
  validation loss:		1.000494
  validation accuracy:		62.03 %
Epoch 141 of 2000 took 0.101s
  training loss:		0.832222
  validation loss:		1.021769
  validation accuracy:		61.72 %
Epoch 142 of 2000 took 0.101s
  training loss:		0.823316
  validation loss:		1.010113
  validation accuracy:		62.34 %
Epoch 143 of 2000 took 0.101s
  training loss:		0.807030
  validation loss:		0.970568
  validation accuracy:		64.21 %
Epoch 144 of 2000 took 0.101s
  training loss:		0.804834
  validation loss:		0.979303
  validation accuracy:		63.69 %
Epoch 145 of 2000 took 0.108s
  training loss:		0.796107
  validation loss:		0.967086
  validation accuracy:		64.94 %
Epoch 146 of 2000 took 0.111s
  training loss:		0.793512
  validation loss:		0.969372
  validation accuracy:		64.42 %
Epoch 147 of 2000 took 0.111s
  training loss:		0.791830
  validation loss:		0.969265
  validation accuracy:		64.83 %
Epoch 148 of 2000 took 0.112s
  training loss:		0.803677
  validation loss:		0.977155
  validation accuracy:		63.80 %
Epoch 149 of 2000 took 0.178s
  training loss:		0.796084
  validation loss:		0.958313
  validation accuracy:		65.46 %
Epoch 150 of 2000 took 0.106s
  training loss:		0.790253
  validation loss:		0.950491
  validation accuracy:		65.46 %
Epoch 151 of 2000 took 0.108s
  training loss:		0.779089
  validation loss:		0.986611
  validation accuracy:		63.69 %
Epoch 152 of 2000 took 0.102s
  training loss:		0.786602
  validation loss:		0.966490
  validation accuracy:		64.52 %
Epoch 153 of 2000 took 0.106s
  training loss:		0.803865
  validation loss:		0.968597
  validation accuracy:		66.08 %
Epoch 154 of 2000 took 0.107s
  training loss:		0.793883
  validation loss:		0.943278
  validation accuracy:		66.80 %
Epoch 155 of 2000 took 0.105s
  training loss:		0.779835
  validation loss:		0.941447
  validation accuracy:		66.18 %
Epoch 156 of 2000 took 0.105s
  training loss:		0.767341
  validation loss:		0.956059
  validation accuracy:		65.56 %
Epoch 157 of 2000 took 0.105s
  training loss:		0.780849
  validation loss:		0.982615
  validation accuracy:		65.46 %
Epoch 158 of 2000 took 0.105s
  training loss:		0.798815
  validation loss:		0.946196
  validation accuracy:		65.87 %
Epoch 159 of 2000 took 0.112s
  training loss:		0.759663
  validation loss:		0.936411
  validation accuracy:		66.08 %
Epoch 160 of 2000 took 0.104s
  training loss:		0.763429
  validation loss:		0.979706
  validation accuracy:		64.63 %
Epoch 161 of 2000 took 0.104s
  training loss:		0.773008
  validation loss:		0.937415
  validation accuracy:		66.80 %
Epoch 162 of 2000 took 0.104s
  training loss:		0.767431
  validation loss:		0.947457
  validation accuracy:		65.87 %
Epoch 163 of 2000 took 0.104s
  training loss:		0.821723
  validation loss:		0.973073
  validation accuracy:		64.11 %
Epoch 164 of 2000 took 0.104s
  training loss:		0.763175
  validation loss:		0.935273
  validation accuracy:		66.70 %
Epoch 165 of 2000 took 0.104s
  training loss:		0.749767
  validation loss:		0.926430
  validation accuracy:		67.01 %
Epoch 166 of 2000 took 0.102s
  training loss:		0.756203
  validation loss:		0.975822
  validation accuracy:		64.83 %
Epoch 167 of 2000 took 0.101s
  training loss:		0.761399
  validation loss:		0.948608
  validation accuracy:		66.49 %
Epoch 168 of 2000 took 0.101s
  training loss:		0.748457
  validation loss:		0.924828
  validation accuracy:		67.12 %
Epoch 169 of 2000 took 0.101s
  training loss:		0.759745
  validation loss:		0.928605
  validation accuracy:		66.80 %
Epoch 170 of 2000 took 0.101s
  training loss:		0.756674
  validation loss:		0.917335
  validation accuracy:		67.12 %
Epoch 171 of 2000 took 0.101s
  training loss:		0.735124
  validation loss:		0.922935
  validation accuracy:		67.84 %
Epoch 172 of 2000 took 0.101s
  training loss:		0.739834
  validation loss:		0.920125
  validation accuracy:		67.43 %
Epoch 173 of 2000 took 0.101s
  training loss:		0.744760
  validation loss:		0.944938
  validation accuracy:		66.18 %
Epoch 174 of 2000 took 0.101s
  training loss:		0.722555
  validation loss:		0.943630
  validation accuracy:		65.66 %
Epoch 175 of 2000 took 0.102s
  training loss:		0.746606
  validation loss:		0.906203
  validation accuracy:		68.46 %
Epoch 176 of 2000 took 0.102s
  training loss:		0.725159
  validation loss:		0.900548
  validation accuracy:		68.46 %
Epoch 177 of 2000 took 0.101s
  training loss:		0.728115
  validation loss:		0.895586
  validation accuracy:		68.46 %
Epoch 178 of 2000 took 0.101s
  training loss:		0.722875
  validation loss:		0.900589
  validation accuracy:		68.88 %
Epoch 179 of 2000 took 0.101s
  training loss:		0.743961
  validation loss:		0.902007
  validation accuracy:		67.95 %
Epoch 180 of 2000 took 0.101s
  training loss:		0.726824
  validation loss:		0.901150
  validation accuracy:		68.57 %
Epoch 181 of 2000 took 0.101s
  training loss:		0.719001
  validation loss:		0.893768
  validation accuracy:		68.57 %
Epoch 182 of 2000 took 0.101s
  training loss:		0.712183
  validation loss:		0.906123
  validation accuracy:		68.46 %
Epoch 183 of 2000 took 0.101s
  training loss:		0.703888
  validation loss:		0.885782
  validation accuracy:		68.98 %
Epoch 184 of 2000 took 0.101s
  training loss:		0.705620
  validation loss:		0.902780
  validation accuracy:		69.09 %
Epoch 185 of 2000 took 0.101s
  training loss:		0.711672
  validation loss:		0.879053
  validation accuracy:		69.19 %
Epoch 186 of 2000 took 0.102s
  training loss:		0.702923
  validation loss:		0.890897
  validation accuracy:		69.09 %
Epoch 187 of 2000 took 0.101s
  training loss:		0.707746
  validation loss:		0.870295
  validation accuracy:		69.09 %
Epoch 188 of 2000 took 0.101s
  training loss:		0.701973
  validation loss:		0.887292
  validation accuracy:		69.61 %
Epoch 189 of 2000 took 0.101s
  training loss:		0.680654
  validation loss:		0.877338
  validation accuracy:		69.40 %
Epoch 190 of 2000 took 0.101s
  training loss:		0.686890
  validation loss:		0.915339
  validation accuracy:		67.63 %
Epoch 191 of 2000 took 0.101s
  training loss:		0.701515
  validation loss:		0.862222
  validation accuracy:		69.50 %
Epoch 192 of 2000 took 0.101s
  training loss:		0.698290
  validation loss:		0.887818
  validation accuracy:		69.19 %
Epoch 193 of 2000 took 0.101s
  training loss:		0.688181
  validation loss:		0.889640
  validation accuracy:		69.19 %
Epoch 194 of 2000 took 0.101s
  training loss:		0.681431
  validation loss:		0.855404
  validation accuracy:		70.02 %
Epoch 195 of 2000 took 0.101s
  training loss:		0.680694
  validation loss:		0.876195
  validation accuracy:		69.09 %
Epoch 196 of 2000 took 0.101s
  training loss:		0.679480
  validation loss:		0.881773
  validation accuracy:		69.50 %
Epoch 197 of 2000 took 0.101s
  training loss:		0.672400
  validation loss:		0.846759
  validation accuracy:		70.85 %
Epoch 198 of 2000 took 0.101s
  training loss:		0.676381
  validation loss:		0.855475
  validation accuracy:		70.95 %
Epoch 199 of 2000 took 0.101s
  training loss:		0.663349
  validation loss:		0.841263
  validation accuracy:		70.33 %
Epoch 200 of 2000 took 0.101s
  training loss:		0.656267
  validation loss:		0.832422
  validation accuracy:		70.64 %
Epoch 201 of 2000 took 0.101s
  training loss:		0.661308
  validation loss:		0.836565
  validation accuracy:		71.06 %
Epoch 202 of 2000 took 0.101s
  training loss:		0.650278
  validation loss:		0.841803
  validation accuracy:		71.27 %
Epoch 203 of 2000 took 0.101s
  training loss:		0.654768
  validation loss:		0.844115
  validation accuracy:		71.27 %
Epoch 204 of 2000 took 0.101s
  training loss:		0.651898
  validation loss:		0.827532
  validation accuracy:		71.27 %
Epoch 205 of 2000 took 0.101s
  training loss:		0.636471
  validation loss:		0.810427
  validation accuracy:		71.89 %
Epoch 206 of 2000 took 0.102s
  training loss:		0.651060
  validation loss:		0.841429
  validation accuracy:		70.75 %
Epoch 207 of 2000 took 0.101s
  training loss:		0.639644
  validation loss:		0.821082
  validation accuracy:		71.89 %
Epoch 208 of 2000 took 0.101s
  training loss:		0.632215
  validation loss:		0.803765
  validation accuracy:		71.47 %
Epoch 209 of 2000 took 0.104s
  training loss:		0.624937
  validation loss:		0.831185
  validation accuracy:		71.06 %
Epoch 210 of 2000 took 0.104s
  training loss:		0.631316
  validation loss:		0.803851
  validation accuracy:		72.30 %
Epoch 211 of 2000 took 0.102s
  training loss:		0.619959
  validation loss:		0.798897
  validation accuracy:		72.51 %
Epoch 212 of 2000 took 0.101s
  training loss:		0.610448
  validation loss:		0.782948
  validation accuracy:		72.51 %
Epoch 213 of 2000 took 0.103s
  training loss:		0.612294
  validation loss:		0.779064
  validation accuracy:		73.55 %
Epoch 214 of 2000 took 0.101s
  training loss:		0.611582
  validation loss:		0.777166
  validation accuracy:		72.93 %
Epoch 215 of 2000 took 0.101s
  training loss:		0.608622
  validation loss:		0.772649
  validation accuracy:		73.13 %
Epoch 216 of 2000 took 0.101s
  training loss:		0.608996
  validation loss:		0.767871
  validation accuracy:		73.24 %
Epoch 217 of 2000 took 0.101s
  training loss:		0.599854
  validation loss:		0.763074
  validation accuracy:		73.34 %
Epoch 218 of 2000 took 0.101s
  training loss:		0.597079
  validation loss:		0.774888
  validation accuracy:		73.24 %
Epoch 219 of 2000 took 0.101s
  training loss:		0.595362
  validation loss:		0.769139
  validation accuracy:		72.72 %
Epoch 220 of 2000 took 0.101s
  training loss:		0.586524
  validation loss:		0.749996
  validation accuracy:		74.27 %
Epoch 221 of 2000 took 0.101s
  training loss:		0.577637
  validation loss:		0.750256
  validation accuracy:		74.17 %
Epoch 222 of 2000 took 0.101s
  training loss:		0.587298
  validation loss:		0.753239
  validation accuracy:		73.86 %
Epoch 223 of 2000 took 0.101s
  training loss:		0.580597
  validation loss:		0.771559
  validation accuracy:		74.69 %
Epoch 224 of 2000 took 0.101s
  training loss:		0.576263
  validation loss:		0.799816
  validation accuracy:		73.13 %
Epoch 225 of 2000 took 0.101s
  training loss:		0.583891
  validation loss:		0.740258
  validation accuracy:		74.27 %
Epoch 226 of 2000 took 0.101s
  training loss:		0.577232
  validation loss:		0.727919
  validation accuracy:		75.52 %
Epoch 227 of 2000 took 0.101s
  training loss:		0.563753
  validation loss:		0.740403
  validation accuracy:		75.41 %
Epoch 228 of 2000 took 0.101s
  training loss:		0.562784
  validation loss:		0.721802
  validation accuracy:		75.62 %
Epoch 229 of 2000 took 0.101s
  training loss:		0.565215
  validation loss:		0.717478
  validation accuracy:		75.62 %
Epoch 230 of 2000 took 0.101s
  training loss:		0.564472
  validation loss:		0.741559
  validation accuracy:		74.48 %
Epoch 231 of 2000 took 0.101s
  training loss:		0.562176
  validation loss:		0.716084
  validation accuracy:		75.93 %
Epoch 232 of 2000 took 0.101s
  training loss:		0.549021
  validation loss:		0.711506
  validation accuracy:		76.04 %
Epoch 233 of 2000 took 0.101s
  training loss:		0.555851
  validation loss:		0.705410
  validation accuracy:		75.83 %
Epoch 234 of 2000 took 0.101s
  training loss:		0.551943
  validation loss:		0.701645
  validation accuracy:		76.24 %
Epoch 235 of 2000 took 0.101s
  training loss:		0.545965
  validation loss:		0.707428
  validation accuracy:		76.56 %
Epoch 236 of 2000 took 0.102s
  training loss:		0.544612
  validation loss:		0.715159
  validation accuracy:		75.93 %
Epoch 237 of 2000 took 0.101s
  training loss:		0.542372
  validation loss:		0.706463
  validation accuracy:		76.24 %
Epoch 238 of 2000 took 0.101s
  training loss:		0.537244
  validation loss:		0.689815
  validation accuracy:		76.87 %
Epoch 239 of 2000 took 0.101s
  training loss:		0.528964
  validation loss:		0.687607
  validation accuracy:		77.07 %
Epoch 240 of 2000 took 0.101s
  training loss:		0.532319
  validation loss:		0.686846
  validation accuracy:		76.56 %
Epoch 241 of 2000 took 0.101s
  training loss:		0.534705
  validation loss:		0.681851
  validation accuracy:		77.07 %
Epoch 242 of 2000 took 0.101s
  training loss:		0.532787
  validation loss:		0.689666
  validation accuracy:		76.66 %
Epoch 243 of 2000 took 0.101s
  training loss:		0.524223
  validation loss:		0.677547
  validation accuracy:		76.97 %
Epoch 244 of 2000 took 0.101s
  training loss:		0.522992
  validation loss:		0.701509
  validation accuracy:		75.52 %
Epoch 245 of 2000 took 0.101s
  training loss:		0.528413
  validation loss:		0.673664
  validation accuracy:		76.87 %
Epoch 246 of 2000 took 0.101s
  training loss:		0.533440
  validation loss:		0.688124
  validation accuracy:		75.62 %
Epoch 247 of 2000 took 0.101s
  training loss:		0.520002
  validation loss:		0.672350
  validation accuracy:		76.66 %
Epoch 248 of 2000 took 0.101s
  training loss:		0.518642
  validation loss:		0.665566
  validation accuracy:		77.59 %
Epoch 249 of 2000 took 0.101s
  training loss:		0.508867
  validation loss:		0.668998
  validation accuracy:		76.56 %
Epoch 250 of 2000 took 0.101s
  training loss:		0.510364
  validation loss:		0.673553
  validation accuracy:		76.66 %
Epoch 251 of 2000 took 0.101s
  training loss:		0.511768
  validation loss:		0.682136
  validation accuracy:		75.62 %
Epoch 252 of 2000 took 0.101s
  training loss:		0.507715
  validation loss:		0.662066
  validation accuracy:		77.70 %
Epoch 253 of 2000 took 0.102s
  training loss:		0.511290
  validation loss:		0.657215
  validation accuracy:		77.80 %
Epoch 254 of 2000 took 0.101s
  training loss:		0.510170
  validation loss:		0.659403
  validation accuracy:		77.07 %
Epoch 255 of 2000 took 0.101s
  training loss:		0.503946
  validation loss:		0.655177
  validation accuracy:		77.39 %
Epoch 256 of 2000 took 0.101s
  training loss:		0.494963
  validation loss:		0.665860
  validation accuracy:		76.97 %
Epoch 257 of 2000 took 0.101s
  training loss:		0.498637
  validation loss:		0.650291
  validation accuracy:		78.11 %
Epoch 258 of 2000 took 0.101s
  training loss:		0.494608
  validation loss:		0.665436
  validation accuracy:		75.93 %
Epoch 259 of 2000 took 0.101s
  training loss:		0.498783
  validation loss:		0.643871
  validation accuracy:		78.11 %
Epoch 260 of 2000 took 0.101s
  training loss:		0.491153
  validation loss:		0.649330
  validation accuracy:		77.70 %
Epoch 261 of 2000 took 0.101s
  training loss:		0.491675
  validation loss:		0.643337
  validation accuracy:		77.39 %
Epoch 262 of 2000 took 0.101s
  training loss:		0.493538
  validation loss:		0.646129
  validation accuracy:		77.18 %
Epoch 263 of 2000 took 0.101s
  training loss:		0.487030
  validation loss:		0.656861
  validation accuracy:		76.24 %
Epoch 264 of 2000 took 0.101s
  training loss:		0.499199
  validation loss:		0.646042
  validation accuracy:		78.01 %
Epoch 265 of 2000 took 0.101s
  training loss:		0.493377
  validation loss:		0.636812
  validation accuracy:		78.42 %
Epoch 266 of 2000 took 0.147s
  training loss:		0.486463
  validation loss:		0.646535
  validation accuracy:		77.59 %
Epoch 267 of 2000 took 0.115s
  training loss:		0.482295
  validation loss:		0.633104
  validation accuracy:		78.32 %
Epoch 268 of 2000 took 0.109s
  training loss:		0.477688
  validation loss:		0.648146
  validation accuracy:		77.70 %
Epoch 269 of 2000 took 0.108s
  training loss:		0.484706
  validation loss:		0.643608
  validation accuracy:		76.56 %
Epoch 270 of 2000 took 0.103s
  training loss:		0.479160
  validation loss:		0.637207
  validation accuracy:		78.73 %
Epoch 271 of 2000 took 0.106s
  training loss:		0.475850
  validation loss:		0.644821
  validation accuracy:		77.28 %
Epoch 272 of 2000 took 0.106s
  training loss:		0.471721
  validation loss:		0.629404
  validation accuracy:		78.53 %
Epoch 273 of 2000 took 0.105s
  training loss:		0.475053
  validation loss:		0.633019
  validation accuracy:		77.49 %
Epoch 274 of 2000 took 0.105s
  training loss:		0.467676
  validation loss:		0.632925
  validation accuracy:		77.80 %
Epoch 275 of 2000 took 0.105s
  training loss:		0.476115
  validation loss:		0.625637
  validation accuracy:		78.42 %
Epoch 276 of 2000 took 0.105s
  training loss:		0.477205
  validation loss:		0.641990
  validation accuracy:		77.18 %
Epoch 277 of 2000 took 0.105s
  training loss:		0.472082
  validation loss:		0.619893
  validation accuracy:		79.05 %
Epoch 278 of 2000 took 0.105s
  training loss:		0.470800
  validation loss:		0.630854
  validation accuracy:		78.53 %
Epoch 279 of 2000 took 0.104s
  training loss:		0.468141
  validation loss:		0.619107
  validation accuracy:		78.73 %
Epoch 280 of 2000 took 0.105s
  training loss:		0.463096
  validation loss:		0.617076
  validation accuracy:		78.94 %
Epoch 281 of 2000 took 0.105s
  training loss:		0.478689
  validation loss:		0.616053
  validation accuracy:		79.36 %
Epoch 282 of 2000 took 0.105s
  training loss:		0.462149
  validation loss:		0.622106
  validation accuracy:		79.15 %
Epoch 283 of 2000 took 0.106s
  training loss:		0.465235
  validation loss:		0.638079
  validation accuracy:		77.90 %
Epoch 284 of 2000 took 0.105s
  training loss:		0.463163
  validation loss:		0.629438
  validation accuracy:		78.32 %
Epoch 285 of 2000 took 0.106s
  training loss:		0.459630
  validation loss:		0.620976
  validation accuracy:		77.90 %
Epoch 286 of 2000 took 0.105s
  training loss:		0.457481
  validation loss:		0.616272
  validation accuracy:		79.56 %
Epoch 287 of 2000 took 0.105s
  training loss:		0.462683
  validation loss:		0.613917
  validation accuracy:		78.84 %
Epoch 288 of 2000 took 0.106s
  training loss:		0.451947
  validation loss:		0.619864
  validation accuracy:		78.94 %
Epoch 289 of 2000 took 0.105s
  training loss:		0.455162
  validation loss:		0.624624
  validation accuracy:		78.53 %
Epoch 290 of 2000 took 0.105s
  training loss:		0.445369
  validation loss:		0.635676
  validation accuracy:		77.59 %
Epoch 291 of 2000 took 0.106s
  training loss:		0.458192
  validation loss:		0.615826
  validation accuracy:		78.94 %
Epoch 292 of 2000 took 0.106s
  training loss:		0.458577
  validation loss:		0.613152
  validation accuracy:		79.67 %
Epoch 293 of 2000 took 0.105s
  training loss:		0.449074
  validation loss:		0.616738
  validation accuracy:		79.25 %
Epoch 294 of 2000 took 0.106s
  training loss:		0.457578
  validation loss:		0.606488
  validation accuracy:		80.08 %
Epoch 295 of 2000 took 0.106s
  training loss:		0.455766
  validation loss:		0.620439
  validation accuracy:		78.53 %
Epoch 296 of 2000 took 0.105s
  training loss:		0.455719
  validation loss:		0.603594
  validation accuracy:		79.05 %
Epoch 297 of 2000 took 0.105s
  training loss:		0.450060
  validation loss:		0.609541
  validation accuracy:		79.77 %
Epoch 298 of 2000 took 0.108s
  training loss:		0.443336
  validation loss:		0.619168
  validation accuracy:		78.94 %
Epoch 299 of 2000 took 0.108s
  training loss:		0.450692
  validation loss:		0.607463
  validation accuracy:		79.25 %
Epoch 300 of 2000 took 0.104s
  training loss:		0.455826
  validation loss:		0.601060
  validation accuracy:		79.88 %
Epoch 301 of 2000 took 0.103s
  training loss:		0.448143
  validation loss:		0.601805
  validation accuracy:		79.36 %
Epoch 302 of 2000 took 0.101s
  training loss:		0.452947
  validation loss:		0.617502
  validation accuracy:		77.90 %
Epoch 303 of 2000 took 0.103s
  training loss:		0.455186
  validation loss:		0.630502
  validation accuracy:		77.49 %
Epoch 304 of 2000 took 0.105s
  training loss:		0.441025
  validation loss:		0.605930
  validation accuracy:		79.77 %
Epoch 305 of 2000 took 0.104s
  training loss:		0.438222
  validation loss:		0.611690
  validation accuracy:		79.46 %
Epoch 306 of 2000 took 0.105s
  training loss:		0.444312
  validation loss:		0.611805
  validation accuracy:		79.05 %
Epoch 307 of 2000 took 0.105s
  training loss:		0.437636
  validation loss:		0.600954
  validation accuracy:		79.46 %
Epoch 308 of 2000 took 0.110s
  training loss:		0.445685
  validation loss:		0.603386
  validation accuracy:		80.08 %
Epoch 309 of 2000 took 0.104s
  training loss:		0.443115
  validation loss:		0.604767
  validation accuracy:		79.46 %
Epoch 310 of 2000 took 0.100s
  training loss:		0.434771
  validation loss:		0.598140
  validation accuracy:		79.98 %
Epoch 311 of 2000 took 0.100s
  training loss:		0.433831
  validation loss:		0.602706
  validation accuracy:		79.88 %
Epoch 312 of 2000 took 0.100s
  training loss:		0.438187
  validation loss:		0.612949
  validation accuracy:		79.56 %
Epoch 313 of 2000 took 0.100s
  training loss:		0.444744
  validation loss:		0.619180
  validation accuracy:		78.84 %
Epoch 314 of 2000 took 0.100s
  training loss:		0.437162
  validation loss:		0.596658
  validation accuracy:		79.98 %
Epoch 315 of 2000 took 0.100s
  training loss:		0.441034
  validation loss:		0.627000
  validation accuracy:		77.59 %
Epoch 316 of 2000 took 0.100s
  training loss:		0.435889
  validation loss:		0.596503
  validation accuracy:		79.88 %
Epoch 317 of 2000 took 0.100s
  training loss:		0.439007
  validation loss:		0.591099
  validation accuracy:		80.29 %
Epoch 318 of 2000 took 0.100s
  training loss:		0.433309
  validation loss:		0.595714
  validation accuracy:		80.39 %
Epoch 319 of 2000 took 0.103s
  training loss:		0.447759
  validation loss:		0.594545
  validation accuracy:		80.81 %
Epoch 320 of 2000 took 0.103s
  training loss:		0.436841
  validation loss:		0.594605
  validation accuracy:		80.50 %
Epoch 321 of 2000 took 0.101s
  training loss:		0.431090
  validation loss:		0.596527
  validation accuracy:		80.19 %
Epoch 322 of 2000 took 0.102s
  training loss:		0.438703
  validation loss:		0.593846
  validation accuracy:		79.77 %
Epoch 323 of 2000 took 0.102s
  training loss:		0.432274
  validation loss:		0.604096
  validation accuracy:		80.60 %
Epoch 324 of 2000 took 0.101s
  training loss:		0.437372
  validation loss:		0.593110
  validation accuracy:		80.81 %
Epoch 325 of 2000 took 0.101s
  training loss:		0.443274
  validation loss:		0.587677
  validation accuracy:		80.60 %
Epoch 326 of 2000 took 0.101s
  training loss:		0.428862
  validation loss:		0.588932
  validation accuracy:		80.39 %
Epoch 327 of 2000 took 0.101s
  training loss:		0.430930
  validation loss:		0.604931
  validation accuracy:		78.94 %
Epoch 328 of 2000 took 0.103s
  training loss:		0.430241
  validation loss:		0.591419
  validation accuracy:		80.08 %
Epoch 329 of 2000 took 0.101s
  training loss:		0.423375
  validation loss:		0.622743
  validation accuracy:		78.63 %
Epoch 330 of 2000 took 0.101s
  training loss:		0.433509
  validation loss:		0.601415
  validation accuracy:		80.50 %
Epoch 331 of 2000 took 0.101s
  training loss:		0.421012
  validation loss:		0.586681
  validation accuracy:		80.50 %
Epoch 332 of 2000 took 0.101s
  training loss:		0.419595
  validation loss:		0.597539
  validation accuracy:		79.56 %
Epoch 333 of 2000 took 0.101s
  training loss:		0.420924
  validation loss:		0.591366
  validation accuracy:		80.60 %
Epoch 334 of 2000 took 0.101s
  training loss:		0.433029
  validation loss:		0.590412
  validation accuracy:		80.50 %
Epoch 335 of 2000 took 0.101s
  training loss:		0.428222
  validation loss:		0.585269
  validation accuracy:		80.50 %
Epoch 336 of 2000 took 0.101s
  training loss:		0.428976
  validation loss:		0.591683
  validation accuracy:		80.60 %
Epoch 337 of 2000 took 0.101s
  training loss:		0.413751
  validation loss:		0.587406
  validation accuracy:		79.77 %
Epoch 338 of 2000 took 0.101s
  training loss:		0.413639
  validation loss:		0.588931
  validation accuracy:		80.50 %
Epoch 339 of 2000 took 0.101s
  training loss:		0.426373
  validation loss:		0.584653
  validation accuracy:		80.81 %
Epoch 340 of 2000 took 0.101s
  training loss:		0.422103
  validation loss:		0.582086
  validation accuracy:		80.39 %
Epoch 341 of 2000 took 0.101s
  training loss:		0.419674
  validation loss:		0.592023
  validation accuracy:		80.29 %
Epoch 342 of 2000 took 0.101s
  training loss:		0.414883
  validation loss:		0.601330
  validation accuracy:		79.98 %
Epoch 343 of 2000 took 0.101s
  training loss:		0.415770
  validation loss:		0.590834
  validation accuracy:		80.91 %
Epoch 344 of 2000 took 0.101s
  training loss:		0.416215
  validation loss:		0.590156
  validation accuracy:		81.12 %
Epoch 345 of 2000 took 0.101s
  training loss:		0.414838
  validation loss:		0.593362
  validation accuracy:		79.56 %
Epoch 346 of 2000 took 0.101s
  training loss:		0.418712
  validation loss:		0.587961
  validation accuracy:		80.39 %
Epoch 347 of 2000 took 0.101s
  training loss:		0.413298
  validation loss:		0.594702
  validation accuracy:		80.08 %
Epoch 348 of 2000 took 0.101s
  training loss:		0.416999
  validation loss:		0.589299
  validation accuracy:		81.02 %
Epoch 349 of 2000 took 0.101s
  training loss:		0.416185
  validation loss:		0.586126
  validation accuracy:		80.29 %
Epoch 350 of 2000 took 0.101s
  training loss:		0.417000
  validation loss:		0.589417
  validation accuracy:		79.67 %
Epoch 351 of 2000 took 0.101s
  training loss:		0.415549
  validation loss:		0.586935
  validation accuracy:		81.54 %
Epoch 352 of 2000 took 0.101s
  training loss:		0.416485
  validation loss:		0.608271
  validation accuracy:		79.05 %
Epoch 353 of 2000 took 0.102s
  training loss:		0.413345
  validation loss:		0.591108
  validation accuracy:		80.50 %
Epoch 354 of 2000 took 0.101s
  training loss:		0.412204
  validation loss:		0.583194
  validation accuracy:		81.22 %
Epoch 355 of 2000 took 0.101s
  training loss:		0.424709
  validation loss:		0.584995
  validation accuracy:		81.33 %
Epoch 356 of 2000 took 0.101s
  training loss:		0.411843
  validation loss:		0.600951
  validation accuracy:		80.19 %
Epoch 357 of 2000 took 0.101s
  training loss:		0.413133
  validation loss:		0.583568
  validation accuracy:		81.85 %
Epoch 358 of 2000 took 0.101s
  training loss:		0.413746
  validation loss:		0.582688
  validation accuracy:		80.29 %
Epoch 359 of 2000 took 0.101s
  training loss:		0.417866
  validation loss:		0.583572
  validation accuracy:		79.88 %
Epoch 360 of 2000 took 0.101s
  training loss:		0.415689
  validation loss:		0.580727
  validation accuracy:		81.22 %
Epoch 361 of 2000 took 0.101s
  training loss:		0.417092
  validation loss:		0.582226
  validation accuracy:		80.81 %
Epoch 362 of 2000 took 0.101s
  training loss:		0.412714
  validation loss:		0.584943
  validation accuracy:		80.91 %
Epoch 363 of 2000 took 0.101s
  training loss:		0.402953
  validation loss:		0.576305
  validation accuracy:		80.81 %
Epoch 364 of 2000 took 0.101s
  training loss:		0.405895
  validation loss:		0.581722
  validation accuracy:		80.60 %
Epoch 365 of 2000 took 0.101s
  training loss:		0.405562
  validation loss:		0.596307
  validation accuracy:		80.08 %
Epoch 366 of 2000 took 0.101s
  training loss:		0.417105
  validation loss:		0.587777
  validation accuracy:		80.71 %
Epoch 367 of 2000 took 0.101s
  training loss:		0.410874
  validation loss:		0.590365
  validation accuracy:		79.88 %
Epoch 368 of 2000 took 0.101s
  training loss:		0.414353
  validation loss:		0.592578
  validation accuracy:		79.56 %
Epoch 369 of 2000 took 0.101s
  training loss:		0.411649
  validation loss:		0.582447
  validation accuracy:		80.39 %
Epoch 370 of 2000 took 0.101s
  training loss:		0.407990
  validation loss:		0.579549
  validation accuracy:		81.43 %
Epoch 371 of 2000 took 0.101s
  training loss:		0.402752
  validation loss:		0.578995
  validation accuracy:		80.50 %
Epoch 372 of 2000 took 0.101s
  training loss:		0.403221
  validation loss:		0.580296
  validation accuracy:		79.88 %
Epoch 373 of 2000 took 0.101s
  training loss:		0.408703
  validation loss:		0.575121
  validation accuracy:		81.22 %
Epoch 374 of 2000 took 0.101s
  training loss:		0.405556
  validation loss:		0.599269
  validation accuracy:		79.88 %
Epoch 375 of 2000 took 0.101s
  training loss:		0.406800
  validation loss:		0.587652
  validation accuracy:		80.50 %
Epoch 376 of 2000 took 0.101s
  training loss:		0.405056
  validation loss:		0.585413
  validation accuracy:		79.46 %
Epoch 377 of 2000 took 0.101s
  training loss:		0.404989
  validation loss:		0.582901
  validation accuracy:		81.64 %
Epoch 378 of 2000 took 0.101s
  training loss:		0.402582
  validation loss:		0.587534
  validation accuracy:		79.56 %
Epoch 379 of 2000 took 0.101s
  training loss:		0.399711
  validation loss:		0.579798
  validation accuracy:		80.91 %
Epoch 380 of 2000 took 0.101s
  training loss:		0.394988
  validation loss:		0.588636
  validation accuracy:		79.36 %
Epoch 381 of 2000 took 0.102s
  training loss:		0.402492
  validation loss:		0.596365
  validation accuracy:		80.81 %
Epoch 382 of 2000 took 0.102s
  training loss:		0.406302
  validation loss:		0.585860
  validation accuracy:		80.91 %
Epoch 383 of 2000 took 0.101s
  training loss:		0.407833
  validation loss:		0.583517
  validation accuracy:		81.12 %
Epoch 384 of 2000 took 0.101s
  training loss:		0.402900
  validation loss:		0.576684
  validation accuracy:		80.60 %
Epoch 385 of 2000 took 0.101s
  training loss:		0.398721
  validation loss:		0.619481
  validation accuracy:		78.73 %
Epoch 386 of 2000 took 0.101s
  training loss:		0.403979
  validation loss:		0.572387
  validation accuracy:		81.64 %
Epoch 387 of 2000 took 0.101s
  training loss:		0.406860
  validation loss:		0.595730
  validation accuracy:		79.67 %
Epoch 388 of 2000 took 0.101s
  training loss:		0.400351
  validation loss:		0.571463
  validation accuracy:		82.05 %
Epoch 389 of 2000 took 0.101s
  training loss:		0.399848
  validation loss:		0.579608
  validation accuracy:		81.54 %
Epoch 390 of 2000 took 0.101s
  training loss:		0.405642
  validation loss:		0.593859
  validation accuracy:		80.39 %
Epoch 391 of 2000 took 0.101s
  training loss:		0.402474
  validation loss:		0.580811
  validation accuracy:		81.54 %
Epoch 392 of 2000 took 0.101s
  training loss:		0.394417
  validation loss:		0.572208
  validation accuracy:		81.74 %
Epoch 393 of 2000 took 0.101s
  training loss:		0.394179
  validation loss:		0.576871
  validation accuracy:		80.60 %
Epoch 394 of 2000 took 0.101s
  training loss:		0.396180
  validation loss:		0.582875
  validation accuracy:		80.81 %
Epoch 395 of 2000 took 0.101s
  training loss:		0.396342
  validation loss:		0.576585
  validation accuracy:		81.22 %
Epoch 396 of 2000 took 0.101s
  training loss:		0.394553
  validation loss:		0.599737
  validation accuracy:		80.50 %
Epoch 397 of 2000 took 0.101s
  training loss:		0.400537
  validation loss:		0.583538
  validation accuracy:		80.50 %
Epoch 398 of 2000 took 0.101s
  training loss:		0.392194
  validation loss:		0.574770
  validation accuracy:		80.71 %
Epoch 399 of 2000 took 0.101s
  training loss:		0.393252
  validation loss:		0.572981
  validation accuracy:		81.22 %
Epoch 400 of 2000 took 0.101s
  training loss:		0.395651
  validation loss:		0.574081
  validation accuracy:		81.33 %
Epoch 401 of 2000 took 0.101s
  training loss:		0.388003
  validation loss:		0.580700
  validation accuracy:		81.02 %
Epoch 402 of 2000 took 0.101s
  training loss:		0.395400
  validation loss:		0.589295
  validation accuracy:		80.29 %
Epoch 403 of 2000 took 0.101s
  training loss:		0.395488
  validation loss:		0.624525
  validation accuracy:		79.15 %
Epoch 404 of 2000 took 0.101s
  training loss:		0.396082
  validation loss:		0.569681
  validation accuracy:		81.43 %
Epoch 405 of 2000 took 0.101s
  training loss:		0.392954
  validation loss:		0.580774
  validation accuracy:		79.88 %
Epoch 406 of 2000 took 0.101s
  training loss:		0.396911
  validation loss:		0.574714
  validation accuracy:		80.39 %
Epoch 407 of 2000 took 0.101s
  training loss:		0.387120
  validation loss:		0.578121
  validation accuracy:		80.71 %
Epoch 408 of 2000 took 0.101s
  training loss:		0.391003
  validation loss:		0.572949
  validation accuracy:		81.22 %
Epoch 409 of 2000 took 0.101s
  training loss:		0.390445
  validation loss:		0.579469
  validation accuracy:		80.81 %
Epoch 410 of 2000 took 0.101s
  training loss:		0.389031
  validation loss:		0.572969
  validation accuracy:		81.54 %
Epoch 411 of 2000 took 0.101s
  training loss:		0.387808
  validation loss:		0.571833
  validation accuracy:		81.22 %
Epoch 412 of 2000 took 0.102s
  training loss:		0.385444
  validation loss:		0.582706
  validation accuracy:		80.50 %
Epoch 413 of 2000 took 0.101s
  training loss:		0.389328
  validation loss:		0.576968
  validation accuracy:		80.91 %
Epoch 414 of 2000 took 0.101s
  training loss:		0.395370
  validation loss:		0.569303
  validation accuracy:		81.33 %
Epoch 415 of 2000 took 0.101s
  training loss:		0.381802
  validation loss:		0.574420
  validation accuracy:		81.12 %
Epoch 416 of 2000 took 0.101s
  training loss:		0.386256
  validation loss:		0.583908
  validation accuracy:		80.39 %
Epoch 417 of 2000 took 0.101s
  training loss:		0.389698
  validation loss:		0.575386
  validation accuracy:		81.02 %
Epoch 418 of 2000 took 0.101s
  training loss:		0.388755
  validation loss:		0.580575
  validation accuracy:		80.91 %
Epoch 419 of 2000 took 0.101s
  training loss:		0.391925
  validation loss:		0.585380
  validation accuracy:		80.39 %
Epoch 420 of 2000 took 0.101s
  training loss:		0.390909
  validation loss:		0.581252
  validation accuracy:		79.98 %
Epoch 421 of 2000 took 0.101s
  training loss:		0.391776
  validation loss:		0.572787
  validation accuracy:		80.71 %
Epoch 422 of 2000 took 0.101s
  training loss:		0.392583
  validation loss:		0.576864
  validation accuracy:		81.02 %
Epoch 423 of 2000 took 0.101s
  training loss:		0.381176
  validation loss:		0.576163
  validation accuracy:		80.50 %
Epoch 424 of 2000 took 0.101s
  training loss:		0.380390
  validation loss:		0.570252
  validation accuracy:		81.43 %
Epoch 425 of 2000 took 0.101s
  training loss:		0.390571
  validation loss:		0.568632
  validation accuracy:		81.12 %
Epoch 426 of 2000 took 0.101s
  training loss:		0.391842
  validation loss:		0.582788
  validation accuracy:		80.81 %
Epoch 427 of 2000 took 0.101s
  training loss:		0.384791
  validation loss:		0.567253
  validation accuracy:		81.54 %
Epoch 428 of 2000 took 0.101s
  training loss:		0.391503
  validation loss:		0.579285
  validation accuracy:		81.54 %
Epoch 429 of 2000 took 0.101s
  training loss:		0.390073
  validation loss:		0.569234
  validation accuracy:		80.91 %
Epoch 430 of 2000 took 0.101s
  training loss:		0.385618
  validation loss:		0.574594
  validation accuracy:		81.02 %
Epoch 431 of 2000 took 0.101s
  training loss:		0.388183
  validation loss:		0.569494
  validation accuracy:		81.12 %
Epoch 432 of 2000 took 0.101s
  training loss:		0.382913
  validation loss:		0.573487
  validation accuracy:		81.64 %
Epoch 433 of 2000 took 0.101s
  training loss:		0.376710
  validation loss:		0.594632
  validation accuracy:		79.98 %
Epoch 434 of 2000 took 0.101s
  training loss:		0.380989
  validation loss:		0.578669
  validation accuracy:		81.43 %
Epoch 435 of 2000 took 0.101s
  training loss:		0.384173
  validation loss:		0.578705
  validation accuracy:		81.02 %
Epoch 436 of 2000 took 0.101s
  training loss:		0.374968
  validation loss:		0.569816
  validation accuracy:		81.22 %
Epoch 437 of 2000 took 0.101s
  training loss:		0.380860
  validation loss:		0.571426
  validation accuracy:		79.98 %
Epoch 438 of 2000 took 0.101s
  training loss:		0.381481
  validation loss:		0.582363
  validation accuracy:		80.39 %
Epoch 439 of 2000 took 0.101s
  training loss:		0.382713
  validation loss:		0.569139
  validation accuracy:		81.33 %
Epoch 440 of 2000 took 0.101s
  training loss:		0.377227
  validation loss:		0.571452
  validation accuracy:		81.22 %
Epoch 441 of 2000 took 0.101s
  training loss:		0.378599
  validation loss:		0.567452
  validation accuracy:		80.71 %
Epoch 442 of 2000 took 0.102s
  training loss:		0.380761
  validation loss:		0.580145
  validation accuracy:		80.60 %
Epoch 443 of 2000 took 0.101s
  training loss:		0.371972
  validation loss:		0.575436
  validation accuracy:		80.71 %
Epoch 444 of 2000 took 0.101s
  training loss:		0.373875
  validation loss:		0.570636
  validation accuracy:		80.91 %
Epoch 445 of 2000 took 0.101s
  training loss:		0.376464
  validation loss:		0.591460
  validation accuracy:		80.81 %
Epoch 446 of 2000 took 0.101s
  training loss:		0.378133
  validation loss:		0.577037
  validation accuracy:		79.67 %
Epoch 447 of 2000 took 0.101s
  training loss:		0.379837
  validation loss:		0.585628
  validation accuracy:		80.81 %
Epoch 448 of 2000 took 0.101s
  training loss:		0.373099
  validation loss:		0.603014
  validation accuracy:		79.88 %
Epoch 449 of 2000 took 0.101s
  training loss:		0.382507
  validation loss:		0.568787
  validation accuracy:		81.95 %
Epoch 450 of 2000 took 0.101s
  training loss:		0.368958
  validation loss:		0.573213
  validation accuracy:		80.71 %
Epoch 451 of 2000 took 0.101s
  training loss:		0.379326
  validation loss:		0.581462
  validation accuracy:		79.88 %
Epoch 452 of 2000 took 0.101s
  training loss:		0.374796
  validation loss:		0.571421
  validation accuracy:		81.43 %
Epoch 453 of 2000 took 0.101s
  training loss:		0.381655
  validation loss:		0.570461
  validation accuracy:		80.81 %
Epoch 454 of 2000 took 0.101s
  training loss:		0.368121
  validation loss:		0.572479
  validation accuracy:		80.91 %
Epoch 455 of 2000 took 0.101s
  training loss:		0.378905
  validation loss:		0.590816
  validation accuracy:		80.71 %
Epoch 456 of 2000 took 0.103s
  training loss:		0.378398
  validation loss:		0.593761
  validation accuracy:		79.56 %
Epoch 457 of 2000 took 0.101s
  training loss:		0.379425
  validation loss:		0.574981
  validation accuracy:		80.50 %
Epoch 458 of 2000 took 0.101s
  training loss:		0.372632
  validation loss:		0.570046
  validation accuracy:		80.91 %
Epoch 459 of 2000 took 0.101s
  training loss:		0.374200
  validation loss:		0.568994
  validation accuracy:		81.02 %
Epoch 460 of 2000 took 0.101s
  training loss:		0.378165
  validation loss:		0.573892
  validation accuracy:		80.50 %
Epoch 461 of 2000 took 0.101s
  training loss:		0.378924
  validation loss:		0.566533
  validation accuracy:		81.54 %
Epoch 462 of 2000 took 0.101s
  training loss:		0.372100
  validation loss:		0.566234
  validation accuracy:		81.22 %
Epoch 463 of 2000 took 0.101s
  training loss:		0.369921
  validation loss:		0.579412
  validation accuracy:		80.60 %
Epoch 464 of 2000 took 0.101s
  training loss:		0.381698
  validation loss:		0.562963
  validation accuracy:		81.54 %
Epoch 465 of 2000 took 0.101s
  training loss:		0.366776
  validation loss:		0.579222
  validation accuracy:		80.71 %
Epoch 466 of 2000 took 0.101s
  training loss:		0.377524
  validation loss:		0.574913
  validation accuracy:		80.50 %
Epoch 467 of 2000 took 0.101s
  training loss:		0.372316
  validation loss:		0.567113
  validation accuracy:		81.02 %
Epoch 468 of 2000 took 0.101s
  training loss:		0.370052
  validation loss:		0.579862
  validation accuracy:		80.39 %
Epoch 469 of 2000 took 0.101s
  training loss:		0.374238
  validation loss:		0.576237
  validation accuracy:		81.02 %
Epoch 470 of 2000 took 0.101s
  training loss:		0.368399
  validation loss:		0.578574
  validation accuracy:		81.12 %
Epoch 471 of 2000 took 0.101s
  training loss:		0.370374
  validation loss:		0.570788
  validation accuracy:		81.02 %
Epoch 472 of 2000 took 0.102s
  training loss:		0.370346
  validation loss:		0.600699
  validation accuracy:		80.39 %
Epoch 473 of 2000 took 0.101s
  training loss:		0.377636
  validation loss:		0.564863
  validation accuracy:		81.22 %
Epoch 474 of 2000 took 0.101s
  training loss:		0.365535
  validation loss:		0.576576
  validation accuracy:		80.91 %
Epoch 475 of 2000 took 0.101s
  training loss:		0.368666
  validation loss:		0.587180
  validation accuracy:		79.98 %
Epoch 476 of 2000 took 0.101s
  training loss:		0.377092
  validation loss:		0.568783
  validation accuracy:		80.81 %
Epoch 477 of 2000 took 0.101s
  training loss:		0.362716
  validation loss:		0.589452
  validation accuracy:		80.60 %
Epoch 478 of 2000 took 0.101s
  training loss:		0.366417
  validation loss:		0.563224
  validation accuracy:		81.33 %
Epoch 479 of 2000 took 0.101s
  training loss:		0.356076
  validation loss:		0.574215
  validation accuracy:		80.60 %
Epoch 480 of 2000 took 0.102s
  training loss:		0.369396
  validation loss:		0.563661
  validation accuracy:		80.19 %
Epoch 481 of 2000 took 0.101s
  training loss:		0.376479
  validation loss:		0.574088
  validation accuracy:		80.91 %
Epoch 482 of 2000 took 0.101s
  training loss:		0.368867
  validation loss:		0.567209
  validation accuracy:		81.22 %
Epoch 483 of 2000 took 0.101s
  training loss:		0.362422
  validation loss:		0.565828
  validation accuracy:		80.81 %
Epoch 484 of 2000 took 0.101s
  training loss:		0.369750
  validation loss:		0.568291
  validation accuracy:		80.91 %
Epoch 485 of 2000 took 0.101s
  training loss:		0.366143
  validation loss:		0.564832
  validation accuracy:		81.43 %
Epoch 486 of 2000 took 0.101s
  training loss:		0.366366
  validation loss:		0.569456
  validation accuracy:		80.08 %
Epoch 487 of 2000 took 0.101s
  training loss:		0.366216
  validation loss:		0.567004
  validation accuracy:		80.71 %
Epoch 488 of 2000 took 0.101s
  training loss:		0.361666
  validation loss:		0.569401
  validation accuracy:		80.60 %
Epoch 489 of 2000 took 0.101s
  training loss:		0.366088
  validation loss:		0.566975
  validation accuracy:		81.74 %
Epoch 490 of 2000 took 0.101s
  training loss:		0.371090
  validation loss:		0.567198
  validation accuracy:		80.60 %
Epoch 491 of 2000 took 0.101s
  training loss:		0.367279
  validation loss:		0.559191
  validation accuracy:		81.02 %
Epoch 492 of 2000 took 0.101s
  training loss:		0.363860
  validation loss:		0.570427
  validation accuracy:		80.71 %
Epoch 493 of 2000 took 0.101s
  training loss:		0.354040
  validation loss:		0.567554
  validation accuracy:		81.85 %
Epoch 494 of 2000 took 0.101s
  training loss:		0.357470
  validation loss:		0.578149
  validation accuracy:		80.91 %
Epoch 495 of 2000 took 0.101s
  training loss:		0.363748
  validation loss:		0.570863
  validation accuracy:		80.81 %
Epoch 496 of 2000 took 0.101s
  training loss:		0.369099
  validation loss:		0.558880
  validation accuracy:		81.33 %
Epoch 497 of 2000 took 0.101s
  training loss:		0.361975
  validation loss:		0.563619
  validation accuracy:		81.22 %
Epoch 498 of 2000 took 0.101s
  training loss:		0.367915
  validation loss:		0.561886
  validation accuracy:		80.81 %
Epoch 499 of 2000 took 0.101s
  training loss:		0.365031
  validation loss:		0.569397
  validation accuracy:		81.43 %
Epoch 500 of 2000 took 0.101s
  training loss:		0.358182
  validation loss:		0.565344
  validation accuracy:		81.12 %
Epoch 501 of 2000 took 0.101s
  training loss:		0.363335
  validation loss:		0.569474
  validation accuracy:		80.91 %
Epoch 502 of 2000 took 0.102s
  training loss:		0.361463
  validation loss:		0.565139
  validation accuracy:		80.39 %
Epoch 503 of 2000 took 0.101s
  training loss:		0.362173
  validation loss:		0.564170
  validation accuracy:		80.81 %
Epoch 504 of 2000 took 0.101s
  training loss:		0.351179
  validation loss:		0.564972
  validation accuracy:		81.33 %
Epoch 505 of 2000 took 0.101s
  training loss:		0.363808
  validation loss:		0.567892
  validation accuracy:		80.71 %
Epoch 506 of 2000 took 0.101s
  training loss:		0.359756
  validation loss:		0.559509
  validation accuracy:		81.64 %
Epoch 507 of 2000 took 0.101s
  training loss:		0.358002
  validation loss:		0.569768
  validation accuracy:		81.02 %
Epoch 508 of 2000 took 0.101s
  training loss:		0.361990
  validation loss:		0.566115
  validation accuracy:		81.95 %
Epoch 509 of 2000 took 0.101s
  training loss:		0.356667
  validation loss:		0.576274
  validation accuracy:		79.98 %
Epoch 510 of 2000 took 0.101s
  training loss:		0.363026
  validation loss:		0.576431
  validation accuracy:		80.71 %
Epoch 511 of 2000 took 0.101s
  training loss:		0.364334
  validation loss:		0.556967
  validation accuracy:		81.12 %
Epoch 512 of 2000 took 0.101s
  training loss:		0.351281
  validation loss:		0.580795
  validation accuracy:		80.71 %
Epoch 513 of 2000 took 0.101s
  training loss:		0.356273
  validation loss:		0.566683
  validation accuracy:		81.43 %
Epoch 514 of 2000 took 0.101s
  training loss:		0.356133
  validation loss:		0.569142
  validation accuracy:		81.02 %
Epoch 515 of 2000 took 0.101s
  training loss:		0.354364
  validation loss:		0.562500
  validation accuracy:		81.12 %
Epoch 516 of 2000 took 0.101s
  training loss:		0.359847
  validation loss:		0.578487
  validation accuracy:		80.39 %
Epoch 517 of 2000 took 0.101s
  training loss:		0.351507
  validation loss:		0.569787
  validation accuracy:		80.91 %
Epoch 518 of 2000 took 0.101s
  training loss:		0.350920
  validation loss:		0.558430
  validation accuracy:		81.74 %
Epoch 519 of 2000 took 0.101s
  training loss:		0.345161
  validation loss:		0.572104
  validation accuracy:		80.50 %
Epoch 520 of 2000 took 0.101s
  training loss:		0.354872
  validation loss:		0.574514
  validation accuracy:		80.71 %
Epoch 521 of 2000 took 0.101s
  training loss:		0.356806
  validation loss:		0.588608
  validation accuracy:		80.91 %
Epoch 522 of 2000 took 0.101s
  training loss:		0.354903
  validation loss:		0.571835
  validation accuracy:		81.54 %
Epoch 523 of 2000 took 0.101s
  training loss:		0.355783
  validation loss:		0.568205
  validation accuracy:		81.02 %
Epoch 524 of 2000 took 0.101s
  training loss:		0.353425
  validation loss:		0.577506
  validation accuracy:		80.39 %
Epoch 525 of 2000 took 0.101s
  training loss:		0.355105
  validation loss:		0.575536
  validation accuracy:		81.33 %
Epoch 526 of 2000 took 0.101s
  training loss:		0.353934
  validation loss:		0.563076
  validation accuracy:		81.33 %
Epoch 527 of 2000 took 0.101s
  training loss:		0.355785
  validation loss:		0.554958
  validation accuracy:		81.74 %
Epoch 528 of 2000 took 0.101s
  training loss:		0.347610
  validation loss:		0.561337
  validation accuracy:		81.43 %
Epoch 529 of 2000 took 0.101s
  training loss:		0.343237
  validation loss:		0.596498
  validation accuracy:		79.98 %
Epoch 530 of 2000 took 0.101s
  training loss:		0.349194
  validation loss:		0.559014
  validation accuracy:		81.64 %
Epoch 531 of 2000 took 0.102s
  training loss:		0.349202
  validation loss:		0.563473
  validation accuracy:		80.60 %
Epoch 532 of 2000 took 0.101s
  training loss:		0.354521
  validation loss:		0.561101
  validation accuracy:		81.64 %
Epoch 533 of 2000 took 0.101s
  training loss:		0.347823
  validation loss:		0.578888
  validation accuracy:		81.33 %
Epoch 534 of 2000 took 0.101s
  training loss:		0.345607
  validation loss:		0.555167
  validation accuracy:		81.85 %
Epoch 535 of 2000 took 0.101s
  training loss:		0.354148
  validation loss:		0.568537
  validation accuracy:		81.22 %
Epoch 536 of 2000 took 0.101s
  training loss:		0.350148
  validation loss:		0.577995
  validation accuracy:		81.12 %
Epoch 537 of 2000 took 0.101s
  training loss:		0.341487
  validation loss:		0.604252
  validation accuracy:		80.50 %
Epoch 538 of 2000 took 0.101s
  training loss:		0.349875
  validation loss:		0.558531
  validation accuracy:		80.50 %
Epoch 539 of 2000 took 0.101s
  training loss:		0.351659
  validation loss:		0.567624
  validation accuracy:		81.54 %
Epoch 540 of 2000 took 0.101s
  training loss:		0.340825
  validation loss:		0.576599
  validation accuracy:		81.22 %
Epoch 541 of 2000 took 0.101s
  training loss:		0.346933
  validation loss:		0.572696
  validation accuracy:		80.91 %
Epoch 542 of 2000 took 0.101s
  training loss:		0.341258
  validation loss:		0.571701
  validation accuracy:		81.54 %
Epoch 543 of 2000 took 0.101s
  training loss:		0.346125
  validation loss:		0.569355
  validation accuracy:		80.81 %
Epoch 544 of 2000 took 0.101s
  training loss:		0.352921
  validation loss:		0.569539
  validation accuracy:		81.22 %
Epoch 545 of 2000 took 0.101s
  training loss:		0.347590
  validation loss:		0.570368
  validation accuracy:		80.39 %
Epoch 546 of 2000 took 0.101s
  training loss:		0.356149
  validation loss:		0.574907
  validation accuracy:		81.33 %
Epoch 547 of 2000 took 0.101s
  training loss:		0.346626
  validation loss:		0.568696
  validation accuracy:		80.81 %
Epoch 548 of 2000 took 0.101s
  training loss:		0.350760
  validation loss:		0.583723
  validation accuracy:		80.71 %
Epoch 549 of 2000 took 0.101s
  training loss:		0.356634
  validation loss:		0.565062
  validation accuracy:		81.33 %
Epoch 550 of 2000 took 0.101s
  training loss:		0.338801
  validation loss:		0.569592
  validation accuracy:		81.74 %
Epoch 551 of 2000 took 0.101s
  training loss:		0.346666
  validation loss:		0.575550
  validation accuracy:		82.05 %
Epoch 552 of 2000 took 0.101s
  training loss:		0.348992
  validation loss:		0.569979
  validation accuracy:		81.64 %
Epoch 553 of 2000 took 0.101s
  training loss:		0.345661
  validation loss:		0.555490
  validation accuracy:		81.12 %
Epoch 554 of 2000 took 0.101s
  training loss:		0.345883
  validation loss:		0.562674
  validation accuracy:		81.22 %
Epoch 555 of 2000 took 0.101s
  training loss:		0.339755
  validation loss:		0.552946
  validation accuracy:		81.54 %
Epoch 556 of 2000 took 0.101s
  training loss:		0.344291
  validation loss:		0.555944
  validation accuracy:		81.54 %
Epoch 557 of 2000 took 0.101s
  training loss:		0.343515
  validation loss:		0.571937
  validation accuracy:		80.91 %
Epoch 558 of 2000 took 0.101s
  training loss:		0.344495
  validation loss:		0.568647
  validation accuracy:		81.22 %
Epoch 559 of 2000 took 0.101s
  training loss:		0.344886
  validation loss:		0.567801
  validation accuracy:		81.02 %
Epoch 560 of 2000 took 0.101s
  training loss:		0.346043
  validation loss:		0.564785
  validation accuracy:		81.02 %
Epoch 561 of 2000 took 0.102s
  training loss:		0.343691
  validation loss:		0.566817
  validation accuracy:		80.81 %
Epoch 562 of 2000 took 0.101s
  training loss:		0.341501
  validation loss:		0.551454
  validation accuracy:		82.05 %
Epoch 563 of 2000 took 0.101s
  training loss:		0.342490
  validation loss:		0.557390
  validation accuracy:		81.43 %
Epoch 564 of 2000 took 0.101s
  training loss:		0.339491
  validation loss:		0.585320
  validation accuracy:		80.60 %
Epoch 565 of 2000 took 0.101s
  training loss:		0.341102
  validation loss:		0.559902
  validation accuracy:		81.12 %
Epoch 566 of 2000 took 0.101s
  training loss:		0.333303
  validation loss:		0.564116
  validation accuracy:		81.12 %
Epoch 567 of 2000 took 0.101s
  training loss:		0.348670
  validation loss:		0.571850
  validation accuracy:		80.60 %
Epoch 568 of 2000 took 0.103s
  training loss:		0.333489
  validation loss:		0.562564
  validation accuracy:		81.02 %
Epoch 569 of 2000 took 0.104s
  training loss:		0.342742
  validation loss:		0.574373
  validation accuracy:		81.74 %
Epoch 570 of 2000 took 0.101s
  training loss:		0.341826
  validation loss:		0.575114
  validation accuracy:		81.12 %
Epoch 571 of 2000 took 0.101s
  training loss:		0.331090
  validation loss:		0.551773
  validation accuracy:		81.74 %
Epoch 572 of 2000 took 0.101s
  training loss:		0.340406
  validation loss:		0.558651
  validation accuracy:		81.33 %
Epoch 573 of 2000 took 0.101s
  training loss:		0.337397
  validation loss:		0.568337
  validation accuracy:		81.12 %
Epoch 574 of 2000 took 0.101s
  training loss:		0.329486
  validation loss:		0.563082
  validation accuracy:		80.81 %
Epoch 575 of 2000 took 0.101s
  training loss:		0.336138
  validation loss:		0.555130
  validation accuracy:		81.95 %
Epoch 576 of 2000 took 0.101s
  training loss:		0.336632
  validation loss:		0.565694
  validation accuracy:		81.02 %
Epoch 577 of 2000 took 0.101s
  training loss:		0.333515
  validation loss:		0.582118
  validation accuracy:		81.12 %
Epoch 578 of 2000 took 0.101s
  training loss:		0.344975
  validation loss:		0.555308
  validation accuracy:		81.54 %
Epoch 579 of 2000 took 0.102s
  training loss:		0.341044
  validation loss:		0.562269
  validation accuracy:		81.85 %
Epoch 580 of 2000 took 0.101s
  training loss:		0.337117
  validation loss:		0.612100
  validation accuracy:		79.77 %
Epoch 581 of 2000 took 0.101s
  training loss:		0.341215
  validation loss:		0.575934
  validation accuracy:		81.02 %
Epoch 582 of 2000 took 0.101s
  training loss:		0.338823
  validation loss:		0.560891
  validation accuracy:		81.64 %
Epoch 583 of 2000 took 0.101s
  training loss:		0.338490
  validation loss:		0.556026
  validation accuracy:		82.47 %
Epoch 584 of 2000 took 0.101s
  training loss:		0.336680
  validation loss:		0.574818
  validation accuracy:		80.71 %
Epoch 585 of 2000 took 0.101s
  training loss:		0.338574
  validation loss:		0.568321
  validation accuracy:		81.64 %
Epoch 586 of 2000 took 0.101s
  training loss:		0.341308
  validation loss:		0.562523
  validation accuracy:		81.02 %
Epoch 587 of 2000 took 0.101s
  training loss:		0.333718
  validation loss:		0.558380
  validation accuracy:		81.54 %
Epoch 588 of 2000 took 0.101s
  training loss:		0.334902
  validation loss:		0.566951
  validation accuracy:		81.64 %
Epoch 589 of 2000 took 0.101s
  training loss:		0.336830
  validation loss:		0.572576
  validation accuracy:		81.12 %
Epoch 590 of 2000 took 0.101s
  training loss:		0.332481
  validation loss:		0.564023
  validation accuracy:		81.54 %
Epoch 591 of 2000 took 0.102s
  training loss:		0.331760
  validation loss:		0.561125
  validation accuracy:		81.85 %
Epoch 592 of 2000 took 0.101s
  training loss:		0.332191
  validation loss:		0.553296
  validation accuracy:		82.47 %
Epoch 593 of 2000 took 0.101s
  training loss:		0.342876
  validation loss:		0.562048
  validation accuracy:		82.05 %
Epoch 594 of 2000 took 0.101s
  training loss:		0.326697
  validation loss:		0.556711
  validation accuracy:		81.54 %
Epoch 595 of 2000 took 0.101s
  training loss:		0.336433
  validation loss:		0.562945
  validation accuracy:		81.74 %
Epoch 596 of 2000 took 0.101s
  training loss:		0.340158
  validation loss:		0.558245
  validation accuracy:		81.12 %
Epoch 597 of 2000 took 0.103s
  training loss:		0.339072
  validation loss:		0.559875
  validation accuracy:		81.74 %
Epoch 598 of 2000 took 0.103s
  training loss:		0.339212
  validation loss:		0.567988
  validation accuracy:		80.60 %
Epoch 599 of 2000 took 0.101s
  training loss:		0.335982
  validation loss:		0.555571
  validation accuracy:		81.95 %
Epoch 600 of 2000 took 0.101s
  training loss:		0.337461
  validation loss:		0.557223
  validation accuracy:		81.95 %
Epoch 601 of 2000 took 0.101s
  training loss:		0.331161
  validation loss:		0.556625
  validation accuracy:		81.54 %
Epoch 602 of 2000 took 0.102s
  training loss:		0.336160
  validation loss:		0.568585
  validation accuracy:		81.43 %
Epoch 603 of 2000 took 0.101s
  training loss:		0.328567
  validation loss:		0.557898
  validation accuracy:		82.26 %
Epoch 604 of 2000 took 0.101s
  training loss:		0.333042
  validation loss:		0.570144
  validation accuracy:		81.64 %
Epoch 605 of 2000 took 0.101s
  training loss:		0.336050
  validation loss:		0.571154
  validation accuracy:		81.33 %
Epoch 606 of 2000 took 0.101s
  training loss:		0.329400
  validation loss:		0.570417
  validation accuracy:		81.54 %
Epoch 607 of 2000 took 0.105s
  training loss:		0.332728
  validation loss:		0.553348
  validation accuracy:		81.95 %
Epoch 608 of 2000 took 0.104s
  training loss:		0.335640
  validation loss:		0.570068
  validation accuracy:		81.43 %
Epoch 609 of 2000 took 0.104s
  training loss:		0.325796
  validation loss:		0.558478
  validation accuracy:		81.85 %
Epoch 610 of 2000 took 0.104s
  training loss:		0.325740
  validation loss:		0.575268
  validation accuracy:		81.64 %
Epoch 611 of 2000 took 0.104s
  training loss:		0.331064
  validation loss:		0.560741
  validation accuracy:		81.64 %
Epoch 612 of 2000 took 0.104s
  training loss:		0.333804
  validation loss:		0.570922
  validation accuracy:		81.74 %
Epoch 613 of 2000 took 0.104s
  training loss:		0.328650
  validation loss:		0.563298
  validation accuracy:		81.54 %
Epoch 614 of 2000 took 0.104s
  training loss:		0.323875
  validation loss:		0.560711
  validation accuracy:		81.85 %
Epoch 615 of 2000 took 0.104s
  training loss:		0.328626
  validation loss:		0.560679
  validation accuracy:		81.74 %
Epoch 616 of 2000 took 0.104s
  training loss:		0.325088
  validation loss:		0.580182
  validation accuracy:		80.91 %
Epoch 617 of 2000 took 0.104s
  training loss:		0.331015
  validation loss:		0.559680
  validation accuracy:		81.33 %
Epoch 618 of 2000 took 0.104s
  training loss:		0.325259
  validation loss:		0.555235
  validation accuracy:		81.74 %
Epoch 619 of 2000 took 0.104s
  training loss:		0.331818
  validation loss:		0.558919
  validation accuracy:		82.16 %
Epoch 620 of 2000 took 0.105s
  training loss:		0.326362
  validation loss:		0.556919
  validation accuracy:		82.26 %
Epoch 621 of 2000 took 0.104s
  training loss:		0.321299
  validation loss:		0.559710
  validation accuracy:		81.74 %
Epoch 622 of 2000 took 0.104s
  training loss:		0.325729
  validation loss:		0.559188
  validation accuracy:		81.64 %
Epoch 623 of 2000 took 0.104s
  training loss:		0.325943
  validation loss:		0.570968
  validation accuracy:		81.85 %
Epoch 624 of 2000 took 0.104s
  training loss:		0.322966
  validation loss:		0.570613
  validation accuracy:		81.74 %
Epoch 625 of 2000 took 0.104s
  training loss:		0.327952
  validation loss:		0.557950
  validation accuracy:		81.85 %
Epoch 626 of 2000 took 0.104s
  training loss:		0.326621
  validation loss:		0.554372
  validation accuracy:		82.26 %
Epoch 627 of 2000 took 0.104s
  training loss:		0.328595
  validation loss:		0.558489
  validation accuracy:		82.37 %
Epoch 628 of 2000 took 0.104s
  training loss:		0.322546
  validation loss:		0.580311
  validation accuracy:		81.43 %
Epoch 629 of 2000 took 0.104s
  training loss:		0.320185
  validation loss:		0.568631
  validation accuracy:		81.95 %
Epoch 630 of 2000 took 0.104s
  training loss:		0.317878
  validation loss:		0.560031
  validation accuracy:		81.64 %
Epoch 631 of 2000 took 0.104s
  training loss:		0.328148
  validation loss:		0.556016
  validation accuracy:		82.05 %
Epoch 632 of 2000 took 0.104s
  training loss:		0.328309
  validation loss:		0.563050
  validation accuracy:		81.22 %
Epoch 633 of 2000 took 0.104s
  training loss:		0.328755
  validation loss:		0.556958
  validation accuracy:		81.95 %
Epoch 634 of 2000 took 0.104s
  training loss:		0.324509
  validation loss:		0.556660
  validation accuracy:		82.26 %
Epoch 635 of 2000 took 0.104s
  training loss:		0.330980
  validation loss:		0.558315
  validation accuracy:		82.05 %
Epoch 636 of 2000 took 0.104s
  training loss:		0.327317
  validation loss:		0.567059
  validation accuracy:		82.26 %
Epoch 637 of 2000 took 0.104s
  training loss:		0.322446
  validation loss:		0.564953
  validation accuracy:		81.64 %
Epoch 638 of 2000 took 0.104s
  training loss:		0.324010
  validation loss:		0.570997
  validation accuracy:		81.64 %
Epoch 639 of 2000 took 0.104s
  training loss:		0.322703
  validation loss:		0.556618
  validation accuracy:		82.05 %
Epoch 640 of 2000 took 0.104s
  training loss:		0.319061
  validation loss:		0.561737
  validation accuracy:		81.85 %
Epoch 641 of 2000 took 0.104s
  training loss:		0.324884
  validation loss:		0.567120
  validation accuracy:		81.54 %
Epoch 642 of 2000 took 0.105s
  training loss:		0.328462
  validation loss:		0.563573
  validation accuracy:		82.16 %
Epoch 643 of 2000 took 0.104s
  training loss:		0.330741
  validation loss:		0.557206
  validation accuracy:		81.85 %
Epoch 644 of 2000 took 0.104s
  training loss:		0.323306
  validation loss:		0.559325
  validation accuracy:		81.85 %
Epoch 645 of 2000 took 0.109s
  training loss:		0.323395
  validation loss:		0.578090
  validation accuracy:		81.54 %
Epoch 646 of 2000 took 0.111s
  training loss:		0.317874
  validation loss:		0.560290
  validation accuracy:		82.16 %
Epoch 647 of 2000 took 0.111s
  training loss:		0.324626
  validation loss:		0.561320
  validation accuracy:		82.26 %
Epoch 648 of 2000 took 0.111s
  training loss:		0.327108
  validation loss:		0.556439
  validation accuracy:		82.05 %
Epoch 649 of 2000 took 0.111s
  training loss:		0.327931
  validation loss:		0.565790
  validation accuracy:		82.16 %
Epoch 650 of 2000 took 0.111s
  training loss:		0.318825
  validation loss:		0.568072
  validation accuracy:		82.05 %
Epoch 651 of 2000 took 0.111s
  training loss:		0.318216
  validation loss:		0.574278
  validation accuracy:		81.54 %
Epoch 652 of 2000 took 0.111s
  training loss:		0.322322
  validation loss:		0.582067
  validation accuracy:		81.43 %
Epoch 653 of 2000 took 0.111s
  training loss:		0.324973
  validation loss:		0.558541
  validation accuracy:		82.57 %
Epoch 654 of 2000 took 0.111s
  training loss:		0.317111
  validation loss:		0.565863
  validation accuracy:		81.74 %
Epoch 655 of 2000 took 0.111s
  training loss:		0.316672
  validation loss:		0.557487
  validation accuracy:		82.16 %
Epoch 656 of 2000 took 0.111s
  training loss:		0.322131
  validation loss:		0.552507
  validation accuracy:		82.37 %
Epoch 657 of 2000 took 0.111s
  training loss:		0.314280
  validation loss:		0.567922
  validation accuracy:		81.85 %
Epoch 658 of 2000 took 0.111s
  training loss:		0.321919
  validation loss:		0.558214
  validation accuracy:		81.85 %
Epoch 659 of 2000 took 0.111s
  training loss:		0.315537
  validation loss:		0.570070
  validation accuracy:		81.85 %
Epoch 660 of 2000 took 0.111s
  training loss:		0.321287
  validation loss:		0.565391
  validation accuracy:		82.26 %
Epoch 661 of 2000 took 0.111s
  training loss:		0.317036
  validation loss:		0.577110
  validation accuracy:		81.22 %
Epoch 662 of 2000 took 0.111s
  training loss:		0.316318
  validation loss:		0.556782
  validation accuracy:		82.16 %
Epoch 663 of 2000 took 0.111s
  training loss:		0.319785
  validation loss:		0.562922
  validation accuracy:		81.54 %
Epoch 664 of 2000 took 0.111s
  training loss:		0.321236
  validation loss:		0.562546
  validation accuracy:		82.68 %
Epoch 665 of 2000 took 0.111s
  training loss:		0.322457
  validation loss:		0.554848
  validation accuracy:		82.47 %
Epoch 666 of 2000 took 0.111s
  training loss:		0.313981
  validation loss:		0.576943
  validation accuracy:		81.54 %
Epoch 667 of 2000 took 0.111s
  training loss:		0.308052
  validation loss:		0.565878
  validation accuracy:		81.54 %
Epoch 668 of 2000 took 0.111s
  training loss:		0.323526
  validation loss:		0.555331
  validation accuracy:		82.26 %
Epoch 669 of 2000 took 0.111s
  training loss:		0.315866
  validation loss:		0.571730
  validation accuracy:		81.33 %
Epoch 670 of 2000 took 0.111s
  training loss:		0.316842
  validation loss:		0.561871
  validation accuracy:		81.95 %
Epoch 671 of 2000 took 0.111s
  training loss:		0.321642
  validation loss:		0.563202
  validation accuracy:		82.26 %
Epoch 672 of 2000 took 0.111s
  training loss:		0.314388
  validation loss:		0.559763
  validation accuracy:		82.05 %
Epoch 673 of 2000 took 0.111s
  training loss:		0.315427
  validation loss:		0.567489
  validation accuracy:		81.54 %
Epoch 674 of 2000 took 0.111s
  training loss:		0.317622
  validation loss:		0.563919
  validation accuracy:		81.33 %
Epoch 675 of 2000 took 0.111s
  training loss:		0.315350
  validation loss:		0.554210
  validation accuracy:		82.68 %
Epoch 676 of 2000 took 0.111s
  training loss:		0.311025
  validation loss:		0.578525
  validation accuracy:		81.95 %
Epoch 677 of 2000 took 0.111s
  training loss:		0.311662
  validation loss:		0.570799
  validation accuracy:		81.85 %
Epoch 678 of 2000 took 0.111s
  training loss:		0.318521
  validation loss:		0.557676
  validation accuracy:		81.74 %
Epoch 679 of 2000 took 0.111s
  training loss:		0.314526
  validation loss:		0.559826
  validation accuracy:		82.68 %
Epoch 680 of 2000 took 0.111s
  training loss:		0.313753
  validation loss:		0.566209
  validation accuracy:		81.64 %
Epoch 681 of 2000 took 0.108s
  training loss:		0.313643
  validation loss:		0.568424
  validation accuracy:		81.95 %
Epoch 682 of 2000 took 0.108s
  training loss:		0.311474
  validation loss:		0.560098
  validation accuracy:		82.05 %
Epoch 683 of 2000 took 0.108s
  training loss:		0.319619
  validation loss:		0.567765
  validation accuracy:		81.95 %
Epoch 684 of 2000 took 0.108s
  training loss:		0.312187
  validation loss:		0.567392
  validation accuracy:		82.16 %
Epoch 685 of 2000 took 0.108s
  training loss:		0.310402
  validation loss:		0.563594
  validation accuracy:		81.74 %
Epoch 686 of 2000 took 0.108s
  training loss:		0.308954
  validation loss:		0.569062
  validation accuracy:		81.54 %
Epoch 687 of 2000 took 0.108s
  training loss:		0.316410
  validation loss:		0.563019
  validation accuracy:		82.26 %
Epoch 688 of 2000 took 0.108s
  training loss:		0.311740
  validation loss:		0.568660
  validation accuracy:		82.37 %
Epoch 689 of 2000 took 0.108s
  training loss:		0.312964
  validation loss:		0.569943
  validation accuracy:		81.22 %
Epoch 690 of 2000 took 0.108s
  training loss:		0.316803
  validation loss:		0.555015
  validation accuracy:		82.16 %
Epoch 691 of 2000 took 0.108s
  training loss:		0.314902
  validation loss:		0.563819
  validation accuracy:		82.05 %
Epoch 692 of 2000 took 0.108s
  training loss:		0.314669
  validation loss:		0.566829
  validation accuracy:		82.05 %
Epoch 693 of 2000 took 0.108s
  training loss:		0.311786
  validation loss:		0.567134
  validation accuracy:		81.95 %
Epoch 694 of 2000 took 0.108s
  training loss:		0.319273
  validation loss:		0.562542
  validation accuracy:		81.74 %
Epoch 695 of 2000 took 0.108s
  training loss:		0.310117
  validation loss:		0.564801
  validation accuracy:		82.16 %
Epoch 696 of 2000 took 0.106s
  training loss:		0.316145
  validation loss:		0.579231
  validation accuracy:		81.64 %
Epoch 697 of 2000 took 0.106s
  training loss:		0.312655
  validation loss:		0.568894
  validation accuracy:		81.74 %
Epoch 698 of 2000 took 0.107s
  training loss:		0.313622
  validation loss:		0.570034
  validation accuracy:		81.74 %
Epoch 699 of 2000 took 0.106s
  training loss:		0.314895
  validation loss:		0.561005
  validation accuracy:		81.95 %
Epoch 700 of 2000 took 0.107s
  training loss:		0.306234
  validation loss:		0.565192
  validation accuracy:		81.54 %
Epoch 701 of 2000 took 0.108s
  training loss:		0.307792
  validation loss:		0.558741
  validation accuracy:		82.26 %
Epoch 702 of 2000 took 0.108s
  training loss:		0.312009
  validation loss:		0.561138
  validation accuracy:		81.74 %
Epoch 703 of 2000 took 0.108s
  training loss:		0.305284
  validation loss:		0.582626
  validation accuracy:		81.54 %
Epoch 704 of 2000 took 0.108s
  training loss:		0.316757
  validation loss:		0.577084
  validation accuracy:		81.64 %
Epoch 705 of 2000 took 0.108s
  training loss:		0.307698
  validation loss:		0.562513
  validation accuracy:		81.85 %
Epoch 706 of 2000 took 0.108s
  training loss:		0.313505
  validation loss:		0.562676
  validation accuracy:		82.05 %
Epoch 707 of 2000 took 0.108s
  training loss:		0.313109
  validation loss:		0.558524
  validation accuracy:		81.95 %
Epoch 708 of 2000 took 0.108s
  training loss:		0.312882
  validation loss:		0.584720
  validation accuracy:		80.71 %
Epoch 709 of 2000 took 0.108s
  training loss:		0.315144
  validation loss:		0.563277
  validation accuracy:		81.64 %
Epoch 710 of 2000 took 0.108s
  training loss:		0.315577
  validation loss:		0.561328
  validation accuracy:		82.16 %
Epoch 711 of 2000 took 0.108s
  training loss:		0.307453
  validation loss:		0.573417
  validation accuracy:		82.05 %
Epoch 712 of 2000 took 0.109s
  training loss:		0.306965
  validation loss:		0.582600
  validation accuracy:		81.22 %
Epoch 713 of 2000 took 0.111s
  training loss:		0.307424
  validation loss:		0.588912
  validation accuracy:		81.33 %
Epoch 714 of 2000 took 0.111s
  training loss:		0.310210
  validation loss:		0.575609
  validation accuracy:		81.85 %
Epoch 715 of 2000 took 0.111s
  training loss:		0.307258
  validation loss:		0.557296
  validation accuracy:		82.47 %
Epoch 716 of 2000 took 0.108s
  training loss:		0.306397
  validation loss:		0.565634
  validation accuracy:		81.95 %
Epoch 717 of 2000 took 0.108s
  training loss:		0.313145
  validation loss:		0.561349
  validation accuracy:		82.57 %
Epoch 718 of 2000 took 0.106s
  training loss:		0.303602
  validation loss:		0.556463
  validation accuracy:		82.05 %
Epoch 719 of 2000 took 0.104s
  training loss:		0.308027
  validation loss:		0.583974
  validation accuracy:		81.33 %
Epoch 720 of 2000 took 0.105s
  training loss:		0.308138
  validation loss:		0.566445
  validation accuracy:		82.05 %
Epoch 721 of 2000 took 0.104s
  training loss:		0.312532
  validation loss:		0.574699
  validation accuracy:		81.43 %
Epoch 722 of 2000 took 0.104s
  training loss:		0.309679
  validation loss:		0.582291
  validation accuracy:		81.12 %
Epoch 723 of 2000 took 0.104s
  training loss:		0.309841
  validation loss:		0.568079
  validation accuracy:		81.33 %
Epoch 724 of 2000 took 0.104s
  training loss:		0.306932
  validation loss:		0.565133
  validation accuracy:		81.95 %
Epoch 725 of 2000 took 0.104s
  training loss:		0.311207
  validation loss:		0.601816
  validation accuracy:		80.81 %
Epoch 726 of 2000 took 0.104s
  training loss:		0.306769
  validation loss:		0.577954
  validation accuracy:		82.16 %
Epoch 727 of 2000 took 0.104s
  training loss:		0.306550
  validation loss:		0.564030
  validation accuracy:		82.37 %
Epoch 728 of 2000 took 0.104s
  training loss:		0.303969
  validation loss:		0.566483
  validation accuracy:		82.16 %
Epoch 729 of 2000 took 0.104s
  training loss:		0.304125
  validation loss:		0.562693
  validation accuracy:		81.54 %
Epoch 730 of 2000 took 0.104s
  training loss:		0.307779
  validation loss:		0.561661
  validation accuracy:		81.85 %
Epoch 731 of 2000 took 0.104s
  training loss:		0.305680
  validation loss:		0.565018
  validation accuracy:		82.05 %
Epoch 732 of 2000 took 0.105s
  training loss:		0.304280
  validation loss:		0.584314
  validation accuracy:		80.91 %
Epoch 733 of 2000 took 0.104s
  training loss:		0.306608
  validation loss:		0.581589
  validation accuracy:		81.12 %
Epoch 734 of 2000 took 0.104s
  training loss:		0.300666
  validation loss:		0.565391
  validation accuracy:		81.95 %
Epoch 735 of 2000 took 0.104s
  training loss:		0.303702
  validation loss:		0.571803
  validation accuracy:		81.95 %
Epoch 736 of 2000 took 0.104s
  training loss:		0.303192
  validation loss:		0.559821
  validation accuracy:		82.26 %
Epoch 737 of 2000 took 0.104s
  training loss:		0.307665
  validation loss:		0.581060
  validation accuracy:		81.33 %
Epoch 738 of 2000 took 0.104s
  training loss:		0.304294
  validation loss:		0.577838
  validation accuracy:		82.16 %
Epoch 739 of 2000 took 0.104s
  training loss:		0.311110
  validation loss:		0.569322
  validation accuracy:		81.95 %
Epoch 740 of 2000 took 0.104s
  training loss:		0.298370
  validation loss:		0.575699
  validation accuracy:		82.26 %
Epoch 741 of 2000 took 0.104s
  training loss:		0.306011
  validation loss:		0.557121
  validation accuracy:		82.37 %
Epoch 742 of 2000 took 0.104s
  training loss:		0.304323
  validation loss:		0.576129
  validation accuracy:		81.64 %
Epoch 743 of 2000 took 0.104s
  training loss:		0.301464
  validation loss:		0.564927
  validation accuracy:		81.95 %
Epoch 744 of 2000 took 0.104s
  training loss:		0.301070
  validation loss:		0.572465
  validation accuracy:		81.95 %
Epoch 745 of 2000 took 0.106s
  training loss:		0.303587
  validation loss:		0.571823
  validation accuracy:		81.95 %
Epoch 746 of 2000 took 0.104s
  training loss:		0.305612
  validation loss:		0.563335
  validation accuracy:		81.85 %
Epoch 747 of 2000 took 0.104s
  training loss:		0.303737
  validation loss:		0.578006
  validation accuracy:		81.64 %
Epoch 748 of 2000 took 0.104s
  training loss:		0.303128
  validation loss:		0.560455
  validation accuracy:		82.47 %
Epoch 749 of 2000 took 0.104s
  training loss:		0.308226
  validation loss:		0.590765
  validation accuracy:		81.85 %
Epoch 750 of 2000 took 0.104s
  training loss:		0.305544
  validation loss:		0.578593
  validation accuracy:		81.85 %
Epoch 751 of 2000 took 0.104s
  training loss:		0.312325
  validation loss:		0.562937
  validation accuracy:		81.43 %
Epoch 752 of 2000 took 0.104s
  training loss:		0.296346
  validation loss:		0.565650
  validation accuracy:		81.43 %
Epoch 753 of 2000 took 0.104s
  training loss:		0.299645
  validation loss:		0.577616
  validation accuracy:		81.95 %
Epoch 754 of 2000 took 0.104s
  training loss:		0.305011
  validation loss:		0.569524
  validation accuracy:		81.43 %
Epoch 755 of 2000 took 0.104s
  training loss:		0.291817
  validation loss:		0.568738
  validation accuracy:		81.64 %
Epoch 756 of 2000 took 0.104s
  training loss:		0.301352
  validation loss:		0.567033
  validation accuracy:		81.95 %
Epoch 757 of 2000 took 0.101s
  training loss:		0.300704
  validation loss:		0.560585
  validation accuracy:		82.68 %
Epoch 758 of 2000 took 0.101s
  training loss:		0.305035
  validation loss:		0.567986
  validation accuracy:		82.47 %
Epoch 759 of 2000 took 0.101s
  training loss:		0.309477
  validation loss:		0.585170
  validation accuracy:		81.43 %
Epoch 760 of 2000 took 0.101s
  training loss:		0.301292
  validation loss:		0.571046
  validation accuracy:		81.95 %
Epoch 761 of 2000 took 0.102s
  training loss:		0.298201
  validation loss:		0.575733
  validation accuracy:		81.64 %
Epoch 762 of 2000 took 0.101s
  training loss:		0.303959
  validation loss:		0.559193
  validation accuracy:		82.68 %
Epoch 763 of 2000 took 0.101s
  training loss:		0.305552
  validation loss:		0.590626
  validation accuracy:		81.85 %
Epoch 764 of 2000 took 0.101s
  training loss:		0.297836
  validation loss:		0.568976
  validation accuracy:		81.74 %
Epoch 765 of 2000 took 0.101s
  training loss:		0.306059
  validation loss:		0.577221
  validation accuracy:		81.54 %
Epoch 766 of 2000 took 0.101s
  training loss:		0.304136
  validation loss:		0.575972
  validation accuracy:		81.95 %
Epoch 767 of 2000 took 0.101s
  training loss:		0.300491
  validation loss:		0.563820
  validation accuracy:		81.74 %
Epoch 768 of 2000 took 0.101s
  training loss:		0.295260
  validation loss:		0.583566
  validation accuracy:		81.33 %
Epoch 769 of 2000 took 0.101s
  training loss:		0.299617
  validation loss:		0.565616
  validation accuracy:		81.74 %
Epoch 770 of 2000 took 0.101s
  training loss:		0.297448
  validation loss:		0.571079
  validation accuracy:		81.54 %
Epoch 771 of 2000 took 0.101s
  training loss:		0.299557
  validation loss:		0.577017
  validation accuracy:		82.05 %
Epoch 772 of 2000 took 0.101s
  training loss:		0.297634
  validation loss:		0.576125
  validation accuracy:		81.54 %
Epoch 773 of 2000 took 0.104s
  training loss:		0.303258
  validation loss:		0.565145
  validation accuracy:		81.95 %
Epoch 774 of 2000 took 0.108s
  training loss:		0.298477
  validation loss:		0.569965
  validation accuracy:		81.85 %
Epoch 775 of 2000 took 0.108s
  training loss:		0.298601
  validation loss:		0.565259
  validation accuracy:		82.05 %
Epoch 776 of 2000 took 0.107s
  training loss:		0.298464
  validation loss:		0.575967
  validation accuracy:		81.85 %
Epoch 777 of 2000 took 0.108s
  training loss:		0.290590
  validation loss:		0.576168
  validation accuracy:		81.85 %
Epoch 778 of 2000 took 0.108s
  training loss:		0.293111
  validation loss:		0.571460
  validation accuracy:		81.54 %
Epoch 779 of 2000 took 0.107s
  training loss:		0.292087
  validation loss:		0.581057
  validation accuracy:		81.95 %
Epoch 780 of 2000 took 0.108s
  training loss:		0.301142
  validation loss:		0.573623
  validation accuracy:		81.95 %
Epoch 781 of 2000 took 0.108s
  training loss:		0.296829
  validation loss:		0.570132
  validation accuracy:		81.54 %
Epoch 782 of 2000 took 0.108s
  training loss:		0.303302
  validation loss:		0.581239
  validation accuracy:		82.37 %
Epoch 783 of 2000 took 0.107s
  training loss:		0.292682
  validation loss:		0.569412
  validation accuracy:		81.64 %
Epoch 784 of 2000 took 0.108s
  training loss:		0.305070
  validation loss:		0.577096
  validation accuracy:		81.43 %
Epoch 785 of 2000 took 0.107s
  training loss:		0.299967
  validation loss:		0.570850
  validation accuracy:		81.95 %
Epoch 786 of 2000 took 0.105s
  training loss:		0.299202
  validation loss:		0.564388
  validation accuracy:		81.95 %
Epoch 787 of 2000 took 0.101s
  training loss:		0.297980
  validation loss:		0.578012
  validation accuracy:		81.22 %
Epoch 788 of 2000 took 0.101s
  training loss:		0.296805
  validation loss:		0.565471
  validation accuracy:		81.85 %
Epoch 789 of 2000 took 0.101s
  training loss:		0.296844
  validation loss:		0.571212
  validation accuracy:		82.05 %
Epoch 790 of 2000 took 0.102s
  training loss:		0.296420
  validation loss:		0.569763
  validation accuracy:		81.95 %
Epoch 791 of 2000 took 0.101s
  training loss:		0.290342
  validation loss:		0.569076
  validation accuracy:		81.95 %
Epoch 792 of 2000 took 0.101s
  training loss:		0.298155
  validation loss:		0.578851
  validation accuracy:		82.05 %
Epoch 793 of 2000 took 0.101s
  training loss:		0.294807
  validation loss:		0.572956
  validation accuracy:		81.74 %
Epoch 794 of 2000 took 0.101s
  training loss:		0.294961
  validation loss:		0.581813
  validation accuracy:		81.12 %
Epoch 795 of 2000 took 0.101s
  training loss:		0.293694
  validation loss:		0.592140
  validation accuracy:		80.91 %
Epoch 796 of 2000 took 0.101s
  training loss:		0.295678
  validation loss:		0.572560
  validation accuracy:		81.22 %
Epoch 797 of 2000 took 0.101s
  training loss:		0.301783
  validation loss:		0.580391
  validation accuracy:		81.64 %
Epoch 798 of 2000 took 0.101s
  training loss:		0.295003
  validation loss:		0.571164
  validation accuracy:		81.64 %
Epoch 799 of 2000 took 0.101s
  training loss:		0.293239
  validation loss:		0.577665
  validation accuracy:		81.33 %
Epoch 800 of 2000 took 0.101s
  training loss:		0.293183
  validation loss:		0.583927
  validation accuracy:		82.37 %
Epoch 801 of 2000 took 0.101s
  training loss:		0.299208
  validation loss:		0.566456
  validation accuracy:		81.85 %
Epoch 802 of 2000 took 0.101s
  training loss:		0.294572
  validation loss:		0.566821
  validation accuracy:		81.95 %
Epoch 803 of 2000 took 0.101s
  training loss:		0.298629
  validation loss:		0.577612
  validation accuracy:		82.26 %
Epoch 804 of 2000 took 0.101s
  training loss:		0.299643
  validation loss:		0.582475
  validation accuracy:		81.22 %
Epoch 805 of 2000 took 0.101s
  training loss:		0.299802
  validation loss:		0.574599
  validation accuracy:		81.95 %
Epoch 806 of 2000 took 0.101s
  training loss:		0.291651
  validation loss:		0.577397
  validation accuracy:		82.05 %
Epoch 807 of 2000 took 0.101s
  training loss:		0.294132
  validation loss:		0.574288
  validation accuracy:		81.95 %
Epoch 808 of 2000 took 0.101s
  training loss:		0.294242
  validation loss:		0.578562
  validation accuracy:		81.74 %
Epoch 809 of 2000 took 0.101s
  training loss:		0.289051
  validation loss:		0.570211
  validation accuracy:		81.95 %
Epoch 810 of 2000 took 0.101s
  training loss:		0.295323
  validation loss:		0.569278
  validation accuracy:		82.37 %
Epoch 811 of 2000 took 0.101s
  training loss:		0.298222
  validation loss:		0.569018
  validation accuracy:		81.85 %
Epoch 812 of 2000 took 0.101s
  training loss:		0.298942
  validation loss:		0.569721
  validation accuracy:		82.05 %
Epoch 813 of 2000 took 0.101s
  training loss:		0.294662
  validation loss:		0.572730
  validation accuracy:		82.05 %
Epoch 814 of 2000 took 0.101s
  training loss:		0.296823
  validation loss:		0.570823
  validation accuracy:		81.74 %
Epoch 815 of 2000 took 0.101s
  training loss:		0.280770
  validation loss:		0.572332
  validation accuracy:		81.85 %
Epoch 816 of 2000 took 0.101s
  training loss:		0.292629
  validation loss:		0.567990
  validation accuracy:		81.54 %
Epoch 817 of 2000 took 0.101s
  training loss:		0.293312
  validation loss:		0.575168
  validation accuracy:		82.37 %
Epoch 818 of 2000 took 0.101s
  training loss:		0.290665
  validation loss:		0.581082
  validation accuracy:		82.16 %
Epoch 819 of 2000 took 0.101s
  training loss:		0.299122
  validation loss:		0.577878
  validation accuracy:		82.16 %
Epoch 820 of 2000 took 0.102s
  training loss:		0.292212
  validation loss:		0.579184
  validation accuracy:		81.33 %
Epoch 821 of 2000 took 0.101s
  training loss:		0.286259
  validation loss:		0.573229
  validation accuracy:		81.95 %
Epoch 822 of 2000 took 0.101s
  training loss:		0.294517
  validation loss:		0.568548
  validation accuracy:		82.47 %
Epoch 823 of 2000 took 0.107s
  training loss:		0.294234
  validation loss:		0.573021
  validation accuracy:		82.16 %
Epoch 824 of 2000 took 0.105s
  training loss:		0.290909
  validation loss:		0.580943
  validation accuracy:		82.05 %
Epoch 825 of 2000 took 0.105s
  training loss:		0.290264
  validation loss:		0.585029
  validation accuracy:		81.54 %
Epoch 826 of 2000 took 0.104s
  training loss:		0.293716
  validation loss:		0.566385
  validation accuracy:		82.47 %
Epoch 827 of 2000 took 0.101s
  training loss:		0.292599
  validation loss:		0.571331
  validation accuracy:		81.64 %
Epoch 828 of 2000 took 0.101s
  training loss:		0.289239
  validation loss:		0.575241
  validation accuracy:		81.54 %
Epoch 829 of 2000 took 0.101s
  training loss:		0.295460
  validation loss:		0.569265
  validation accuracy:		81.95 %
Epoch 830 of 2000 took 0.101s
  training loss:		0.289774
  validation loss:		0.611337
  validation accuracy:		81.64 %
Epoch 831 of 2000 took 0.101s
  training loss:		0.290714
  validation loss:		0.565127
  validation accuracy:		81.64 %
Epoch 832 of 2000 took 0.101s
  training loss:		0.289102
  validation loss:		0.571871
  validation accuracy:		81.95 %
Epoch 833 of 2000 took 0.101s
  training loss:		0.290290
  validation loss:		0.576983
  validation accuracy:		82.26 %
Epoch 834 of 2000 took 0.101s
  training loss:		0.291247
  validation loss:		0.576268
  validation accuracy:		81.74 %
Epoch 835 of 2000 took 0.101s
  training loss:		0.293866
  validation loss:		0.589738
  validation accuracy:		81.54 %
Epoch 836 of 2000 took 0.101s
  training loss:		0.293183
  validation loss:		0.565795
  validation accuracy:		82.05 %
Epoch 837 of 2000 took 0.101s
  training loss:		0.287056
  validation loss:		0.580452
  validation accuracy:		81.95 %
Epoch 838 of 2000 took 0.101s
  training loss:		0.286980
  validation loss:		0.576070
  validation accuracy:		81.85 %
Epoch 839 of 2000 took 0.101s
  training loss:		0.283852
  validation loss:		0.580299
  validation accuracy:		81.54 %
Epoch 840 of 2000 took 0.101s
  training loss:		0.288881
  validation loss:		0.578865
  validation accuracy:		81.74 %
Epoch 841 of 2000 took 0.101s
  training loss:		0.290219
  validation loss:		0.575240
  validation accuracy:		81.64 %
Epoch 842 of 2000 took 0.101s
  training loss:		0.288583
  validation loss:		0.569486
  validation accuracy:		81.64 %
Epoch 843 of 2000 took 0.101s
  training loss:		0.292887
  validation loss:		0.575557
  validation accuracy:		81.85 %
Epoch 844 of 2000 took 0.101s
  training loss:		0.293841
  validation loss:		0.567284
  validation accuracy:		81.95 %
Epoch 845 of 2000 took 0.101s
  training loss:		0.289356
  validation loss:		0.588377
  validation accuracy:		81.74 %
Epoch 846 of 2000 took 0.101s
  training loss:		0.285796
  validation loss:		0.583663
  validation accuracy:		81.95 %
Epoch 847 of 2000 took 0.101s
  training loss:		0.283828
  validation loss:		0.570511
  validation accuracy:		81.95 %
Epoch 848 of 2000 took 0.101s
  training loss:		0.284878
  validation loss:		0.586058
  validation accuracy:		81.74 %
Epoch 849 of 2000 took 0.102s
  training loss:		0.288719
  validation loss:		0.586342
  validation accuracy:		82.05 %
Epoch 850 of 2000 took 0.101s
  training loss:		0.285627
  validation loss:		0.567877
  validation accuracy:		81.95 %
Epoch 851 of 2000 took 0.101s
  training loss:		0.291485
  validation loss:		0.586091
  validation accuracy:		81.22 %
Epoch 852 of 2000 took 0.101s
  training loss:		0.290401
  validation loss:		0.584565
  validation accuracy:		82.16 %
Epoch 853 of 2000 took 0.101s
  training loss:		0.288847
  validation loss:		0.573138
  validation accuracy:		81.74 %
Epoch 854 of 2000 took 0.101s
  training loss:		0.285819
  validation loss:		0.578073
  validation accuracy:		81.74 %
Epoch 855 of 2000 took 0.101s
  training loss:		0.286956
  validation loss:		0.583784
  validation accuracy:		81.43 %
Epoch 856 of 2000 took 0.101s
  training loss:		0.280773
  validation loss:		0.574193
  validation accuracy:		81.85 %
Epoch 857 of 2000 took 0.101s
  training loss:		0.281066
  validation loss:		0.588374
  validation accuracy:		81.85 %
Epoch 858 of 2000 took 0.101s
  training loss:		0.289798
  validation loss:		0.575170
  validation accuracy:		81.54 %
Epoch 859 of 2000 took 0.101s
  training loss:		0.282368
  validation loss:		0.568396
  validation accuracy:		81.74 %
Epoch 860 of 2000 took 0.101s
  training loss:		0.283587
  validation loss:		0.570013
  validation accuracy:		82.47 %
Epoch 861 of 2000 took 0.101s
  training loss:		0.284015
  validation loss:		0.587989
  validation accuracy:		81.85 %
Epoch 862 of 2000 took 0.101s
  training loss:		0.294701
  validation loss:		0.587707
  validation accuracy:		82.05 %
Epoch 863 of 2000 took 0.101s
  training loss:		0.284607
  validation loss:		0.577788
  validation accuracy:		81.54 %
Epoch 864 of 2000 took 0.101s
  training loss:		0.284638
  validation loss:		0.577104
  validation accuracy:		81.43 %
Epoch 865 of 2000 took 0.101s
  training loss:		0.283774
  validation loss:		0.570427
  validation accuracy:		81.95 %
Epoch 866 of 2000 took 0.101s
  training loss:		0.285340
  validation loss:		0.574233
  validation accuracy:		82.05 %
Epoch 867 of 2000 took 0.101s
  training loss:		0.284051
  validation loss:		0.579771
  validation accuracy:		82.26 %
Epoch 868 of 2000 took 0.101s
  training loss:		0.286780
  validation loss:		0.586224
  validation accuracy:		81.54 %
Epoch 869 of 2000 took 0.101s
  training loss:		0.283466
  validation loss:		0.599901
  validation accuracy:		81.85 %
Epoch 870 of 2000 took 0.101s
  training loss:		0.278812
  validation loss:		0.576646
  validation accuracy:		81.54 %
Epoch 871 of 2000 took 0.101s
  training loss:		0.280766
  validation loss:		0.578042
  validation accuracy:		81.85 %
Epoch 872 of 2000 took 0.101s
  training loss:		0.282121
  validation loss:		0.581800
  validation accuracy:		81.33 %
Epoch 873 of 2000 took 0.101s
  training loss:		0.283136
  validation loss:		0.581286
  validation accuracy:		81.64 %
Epoch 874 of 2000 took 0.101s
  training loss:		0.284883
  validation loss:		0.579751
  validation accuracy:		81.85 %
Epoch 875 of 2000 took 0.101s
  training loss:		0.277940
  validation loss:		0.574272
  validation accuracy:		82.68 %
Epoch 876 of 2000 took 0.101s
  training loss:		0.286315
  validation loss:		0.587164
  validation accuracy:		81.22 %
Epoch 877 of 2000 took 0.101s
  training loss:		0.282151
  validation loss:		0.583258
  validation accuracy:		82.26 %
Epoch 878 of 2000 took 0.101s
  training loss:		0.285239
  validation loss:		0.573923
  validation accuracy:		81.64 %
Epoch 879 of 2000 took 0.102s
  training loss:		0.283188
  validation loss:		0.575009
  validation accuracy:		82.26 %
Epoch 880 of 2000 took 0.101s
  training loss:		0.283366
  validation loss:		0.574151
  validation accuracy:		81.33 %
Epoch 881 of 2000 took 0.101s
  training loss:		0.285048
  validation loss:		0.581936
  validation accuracy:		81.43 %
Epoch 882 of 2000 took 0.101s
  training loss:		0.281702
  validation loss:		0.574052
  validation accuracy:		82.26 %
Epoch 883 of 2000 took 0.101s
  training loss:		0.282665
  validation loss:		0.578727
  validation accuracy:		81.54 %
Epoch 884 of 2000 took 0.101s
  training loss:		0.275041
  validation loss:		0.580777
  validation accuracy:		81.85 %
Epoch 885 of 2000 took 0.101s
  training loss:		0.281581
  validation loss:		0.585314
  validation accuracy:		82.05 %
Epoch 886 of 2000 took 0.101s
  training loss:		0.285679
  validation loss:		0.576747
  validation accuracy:		82.16 %
Epoch 887 of 2000 took 0.101s
  training loss:		0.281463
  validation loss:		0.578925
  validation accuracy:		81.85 %
Epoch 888 of 2000 took 0.101s
  training loss:		0.283370
  validation loss:		0.578066
  validation accuracy:		81.85 %
Epoch 889 of 2000 took 0.101s
  training loss:		0.283330
  validation loss:		0.577704
  validation accuracy:		81.95 %
Epoch 890 of 2000 took 0.101s
  training loss:		0.279120
  validation loss:		0.574856
  validation accuracy:		81.74 %
Epoch 891 of 2000 took 0.101s
  training loss:		0.280836
  validation loss:		0.581461
  validation accuracy:		82.16 %
Epoch 892 of 2000 took 0.101s
  training loss:		0.279998
  validation loss:		0.577584
  validation accuracy:		82.26 %
Epoch 893 of 2000 took 0.101s
  training loss:		0.277888
  validation loss:		0.584088
  validation accuracy:		81.54 %
Epoch 894 of 2000 took 0.101s
  training loss:		0.282474
  validation loss:		0.571265
  validation accuracy:		81.64 %
Epoch 895 of 2000 took 0.101s
  training loss:		0.278178
  validation loss:		0.582234
  validation accuracy:		81.54 %
Epoch 896 of 2000 took 0.101s
  training loss:		0.280402
  validation loss:		0.577862
  validation accuracy:		81.85 %
Epoch 897 of 2000 took 0.101s
  training loss:		0.276412
  validation loss:		0.579426
  validation accuracy:		81.22 %
Epoch 898 of 2000 took 0.101s
  training loss:		0.276217
  validation loss:		0.580510
  validation accuracy:		81.64 %
Epoch 899 of 2000 took 0.101s
  training loss:		0.277117
  validation loss:		0.579444
  validation accuracy:		81.33 %
Epoch 900 of 2000 took 0.101s
  training loss:		0.275347
  validation loss:		0.583236
  validation accuracy:		81.85 %
Epoch 901 of 2000 took 0.101s
  training loss:		0.282895
  validation loss:		0.584531
  validation accuracy:		81.85 %
Epoch 902 of 2000 took 0.101s
  training loss:		0.278126
  validation loss:		0.580865
  validation accuracy:		81.95 %
Epoch 903 of 2000 took 0.101s
  training loss:		0.271147
  validation loss:		0.570276
  validation accuracy:		81.33 %
Epoch 904 of 2000 took 0.101s
  training loss:		0.276697
  validation loss:		0.568645
  validation accuracy:		81.54 %
Epoch 905 of 2000 took 0.101s
  training loss:		0.283801
  validation loss:		0.594925
  validation accuracy:		81.74 %
Epoch 906 of 2000 took 0.101s
  training loss:		0.277862
  validation loss:		0.574505
  validation accuracy:		82.26 %
Epoch 907 of 2000 took 0.101s
  training loss:		0.282200
  validation loss:		0.577956
  validation accuracy:		81.54 %
Epoch 908 of 2000 took 0.101s
  training loss:		0.274641
  validation loss:		0.573558
  validation accuracy:		82.16 %
Epoch 909 of 2000 took 0.102s
  training loss:		0.283132
  validation loss:		0.582713
  validation accuracy:		82.26 %
Epoch 910 of 2000 took 0.101s
  training loss:		0.274702
  validation loss:		0.600085
  validation accuracy:		81.64 %
Epoch 911 of 2000 took 0.101s
  training loss:		0.278682
  validation loss:		0.582811
  validation accuracy:		81.54 %
Epoch 912 of 2000 took 0.101s
  training loss:		0.279755
  validation loss:		0.591887
  validation accuracy:		81.95 %
Epoch 913 of 2000 took 0.101s
  training loss:		0.279808
  validation loss:		0.600140
  validation accuracy:		81.85 %
Epoch 914 of 2000 took 0.103s
  training loss:		0.279761
  validation loss:		0.578206
  validation accuracy:		81.74 %
Epoch 915 of 2000 took 0.106s
  training loss:		0.281281
  validation loss:		0.585138
  validation accuracy:		82.05 %
Epoch 916 of 2000 took 0.104s
  training loss:		0.278133
  validation loss:		0.575749
  validation accuracy:		82.05 %
Epoch 917 of 2000 took 0.104s
  training loss:		0.274205
  validation loss:		0.581286
  validation accuracy:		81.43 %
Epoch 918 of 2000 took 0.104s
  training loss:		0.275741
  validation loss:		0.576210
  validation accuracy:		82.26 %
Epoch 919 of 2000 took 0.104s
  training loss:		0.277937
  validation loss:		0.596081
  validation accuracy:		81.74 %
Epoch 920 of 2000 took 0.104s
  training loss:		0.281156
  validation loss:		0.591089
  validation accuracy:		81.64 %
Epoch 921 of 2000 took 0.104s
  training loss:		0.272522
  validation loss:		0.585061
  validation accuracy:		81.54 %
Epoch 922 of 2000 took 0.104s
  training loss:		0.273493
  validation loss:		0.576564
  validation accuracy:		81.64 %
Epoch 923 of 2000 took 0.104s
  training loss:		0.273492
  validation loss:		0.580429
  validation accuracy:		81.85 %
Epoch 924 of 2000 took 0.104s
  training loss:		0.274116
  validation loss:		0.585841
  validation accuracy:		81.74 %
Epoch 925 of 2000 took 0.104s
  training loss:		0.278498
  validation loss:		0.575380
  validation accuracy:		82.88 %
Epoch 926 of 2000 took 0.104s
  training loss:		0.277884
  validation loss:		0.585916
  validation accuracy:		82.57 %
Epoch 927 of 2000 took 0.104s
  training loss:		0.276734
  validation loss:		0.605346
  validation accuracy:		81.95 %
Epoch 928 of 2000 took 0.104s
  training loss:		0.264734
  validation loss:		0.577026
  validation accuracy:		81.74 %
Epoch 929 of 2000 took 0.104s
  training loss:		0.274346
  validation loss:		0.574500
  validation accuracy:		82.47 %
Epoch 930 of 2000 took 0.104s
  training loss:		0.273837
  validation loss:		0.574593
  validation accuracy:		82.57 %
Epoch 931 of 2000 took 0.104s
  training loss:		0.271081
  validation loss:		0.587987
  validation accuracy:		81.43 %
Epoch 932 of 2000 took 0.104s
  training loss:		0.277852
  validation loss:		0.591818
  validation accuracy:		81.74 %
Epoch 933 of 2000 took 0.104s
  training loss:		0.277710
  validation loss:		0.577017
  validation accuracy:		81.95 %
Epoch 934 of 2000 took 0.104s
  training loss:		0.266041
  validation loss:		0.586351
  validation accuracy:		81.33 %
Epoch 935 of 2000 took 0.104s
  training loss:		0.271735
  validation loss:		0.579692
  validation accuracy:		81.85 %
Epoch 936 of 2000 took 0.104s
  training loss:		0.270841
  validation loss:		0.586423
  validation accuracy:		81.85 %
Epoch 937 of 2000 took 0.104s
  training loss:		0.275993
  validation loss:		0.582254
  validation accuracy:		81.33 %
Epoch 938 of 2000 took 0.105s
  training loss:		0.277451
  validation loss:		0.578265
  validation accuracy:		82.47 %
Epoch 939 of 2000 took 0.104s
  training loss:		0.278707
  validation loss:		0.583686
  validation accuracy:		81.43 %
Epoch 940 of 2000 took 0.104s
  training loss:		0.278043
  validation loss:		0.591063
  validation accuracy:		81.74 %
Epoch 941 of 2000 took 0.104s
  training loss:		0.274136
  validation loss:		0.588317
  validation accuracy:		82.16 %
Epoch 942 of 2000 took 0.104s
  training loss:		0.270960
  validation loss:		0.576773
  validation accuracy:		82.16 %
Epoch 943 of 2000 took 0.104s
  training loss:		0.272169
  validation loss:		0.569977
  validation accuracy:		81.74 %
Epoch 944 of 2000 took 0.104s
  training loss:		0.273994
  validation loss:		0.580658
  validation accuracy:		82.16 %
Epoch 945 of 2000 took 0.104s
  training loss:		0.268911
  validation loss:		0.604672
  validation accuracy:		81.43 %
Epoch 946 of 2000 took 0.104s
  training loss:		0.272087
  validation loss:		0.574391
  validation accuracy:		82.37 %
Epoch 947 of 2000 took 0.104s
  training loss:		0.275843
  validation loss:		0.592612
  validation accuracy:		81.95 %
Epoch 948 of 2000 took 0.104s
  training loss:		0.272025
  validation loss:		0.577115
  validation accuracy:		82.57 %
Epoch 949 of 2000 took 0.105s
  training loss:		0.267794
  validation loss:		0.597799
  validation accuracy:		81.85 %
Epoch 950 of 2000 took 0.104s
  training loss:		0.273691
  validation loss:		0.587743
  validation accuracy:		81.54 %
Epoch 951 of 2000 took 0.104s
  training loss:		0.272130
  validation loss:		0.622897
  validation accuracy:		82.05 %
Epoch 952 of 2000 took 0.104s
  training loss:		0.279841
  validation loss:		0.589140
  validation accuracy:		81.95 %
Epoch 953 of 2000 took 0.105s
  training loss:		0.275167
  validation loss:		0.597603
  validation accuracy:		81.85 %
Epoch 954 of 2000 took 0.104s
  training loss:		0.273358
  validation loss:		0.598785
  validation accuracy:		80.91 %
Epoch 955 of 2000 took 0.104s
  training loss:		0.271957
  validation loss:		0.587247
  validation accuracy:		81.95 %
Epoch 956 of 2000 took 0.104s
  training loss:		0.268955
  validation loss:		0.576345
  validation accuracy:		82.26 %
Epoch 957 of 2000 took 0.104s
  training loss:		0.274532
  validation loss:		0.583843
  validation accuracy:		81.64 %
Epoch 958 of 2000 took 0.104s
  training loss:		0.267084
  validation loss:		0.590229
  validation accuracy:		81.85 %
Epoch 959 of 2000 took 0.104s
  training loss:		0.268087
  validation loss:		0.581110
  validation accuracy:		81.95 %
Epoch 960 of 2000 took 0.104s
  training loss:		0.274121
  validation loss:		0.581426
  validation accuracy:		82.05 %
Epoch 961 of 2000 took 0.104s
  training loss:		0.266017
  validation loss:		0.583762
  validation accuracy:		81.85 %
Epoch 962 of 2000 took 0.104s
  training loss:		0.275366
  validation loss:		0.594696
  validation accuracy:		82.16 %
Epoch 963 of 2000 took 0.104s
  training loss:		0.270313
  validation loss:		0.581847
  validation accuracy:		82.26 %
Epoch 964 of 2000 took 0.105s
  training loss:		0.270191
  validation loss:		0.584923
  validation accuracy:		82.37 %
Epoch 965 of 2000 took 0.104s
  training loss:		0.267448
  validation loss:		0.572046
  validation accuracy:		82.05 %
Epoch 966 of 2000 took 0.104s
  training loss:		0.272897
  validation loss:		0.585060
  validation accuracy:		81.74 %
Epoch 967 of 2000 took 0.105s
  training loss:		0.268466
  validation loss:		0.596172
  validation accuracy:		81.85 %
Epoch 968 of 2000 took 0.104s
  training loss:		0.264820
  validation loss:		0.581969
  validation accuracy:		82.78 %
Epoch 969 of 2000 took 0.104s
  training loss:		0.263998
  validation loss:		0.583682
  validation accuracy:		81.95 %
Epoch 970 of 2000 took 0.104s
  training loss:		0.268871
  validation loss:		0.592914
  validation accuracy:		81.85 %
Epoch 971 of 2000 took 0.104s
  training loss:		0.267896
  validation loss:		0.577791
  validation accuracy:		81.95 %
Epoch 972 of 2000 took 0.104s
  training loss:		0.269340
  validation loss:		0.584958
  validation accuracy:		82.05 %
Epoch 973 of 2000 took 0.105s
  training loss:		0.270104
  validation loss:		0.596142
  validation accuracy:		81.74 %
Epoch 974 of 2000 took 0.104s
  training loss:		0.265346
  validation loss:		0.584768
  validation accuracy:		82.47 %
Epoch 975 of 2000 took 0.105s
  training loss:		0.264494
  validation loss:		0.580113
  validation accuracy:		81.95 %
Epoch 976 of 2000 took 0.104s
  training loss:		0.265843
  validation loss:		0.579778
  validation accuracy:		82.26 %
Epoch 977 of 2000 took 0.104s
  training loss:		0.266937
  validation loss:		0.578086
  validation accuracy:		81.64 %
Epoch 978 of 2000 took 0.104s
  training loss:		0.267066
  validation loss:		0.588146
  validation accuracy:		82.05 %
Epoch 979 of 2000 took 0.104s
  training loss:		0.261309
  validation loss:		0.591394
  validation accuracy:		81.12 %
Epoch 980 of 2000 took 0.104s
  training loss:		0.266138
  validation loss:		0.587757
  validation accuracy:		81.64 %
Epoch 981 of 2000 took 0.104s
  training loss:		0.263047
  validation loss:		0.602106
  validation accuracy:		81.54 %
Epoch 982 of 2000 took 0.104s
  training loss:		0.271073
  validation loss:		0.593142
  validation accuracy:		81.43 %
Epoch 983 of 2000 took 0.104s
  training loss:		0.265135
  validation loss:		0.584425
  validation accuracy:		82.05 %
Epoch 984 of 2000 took 0.104s
  training loss:		0.266030
  validation loss:		0.600326
  validation accuracy:		81.43 %
Epoch 985 of 2000 took 0.104s
  training loss:		0.261994
  validation loss:		0.579094
  validation accuracy:		81.95 %
Epoch 986 of 2000 took 0.104s
  training loss:		0.265099
  validation loss:		0.596489
  validation accuracy:		81.54 %
Epoch 987 of 2000 took 0.104s
  training loss:		0.267479
  validation loss:		0.590961
  validation accuracy:		82.05 %
Epoch 988 of 2000 took 0.104s
  training loss:		0.265495
  validation loss:		0.603127
  validation accuracy:		81.95 %
Epoch 989 of 2000 took 0.104s
  training loss:		0.270838
  validation loss:		0.585549
  validation accuracy:		82.68 %
Epoch 990 of 2000 took 0.104s
  training loss:		0.268416
  validation loss:		0.586918
  validation accuracy:		82.26 %
Epoch 991 of 2000 took 0.105s
  training loss:		0.265123
  validation loss:		0.591819
  validation accuracy:		81.95 %
Epoch 992 of 2000 took 0.105s
  training loss:		0.264801
  validation loss:		0.577358
  validation accuracy:		81.54 %
Epoch 993 of 2000 took 0.105s
  training loss:		0.258402
  validation loss:		0.589876
  validation accuracy:		82.16 %
Epoch 994 of 2000 took 0.104s
  training loss:		0.263098
  validation loss:		0.617796
  validation accuracy:		81.74 %
Epoch 995 of 2000 took 0.104s
  training loss:		0.263252
  validation loss:		0.589693
  validation accuracy:		81.74 %
Epoch 996 of 2000 took 0.105s
  training loss:		0.258980
  validation loss:		0.592429
  validation accuracy:		82.16 %
Epoch 997 of 2000 took 0.104s
  training loss:		0.262535
  validation loss:		0.587338
  validation accuracy:		81.12 %
Epoch 998 of 2000 took 0.104s
  training loss:		0.260091
  validation loss:		0.584007
  validation accuracy:		82.05 %
Epoch 999 of 2000 took 0.104s
  training loss:		0.261271
  validation loss:		0.607577
  validation accuracy:		81.95 %
Epoch 1000 of 2000 took 0.104s
  training loss:		0.262369
  validation loss:		0.596248
  validation accuracy:		81.12 %
Epoch 1001 of 2000 took 0.104s
  training loss:		0.262808
  validation loss:		0.588883
  validation accuracy:		81.85 %
Epoch 1002 of 2000 took 0.104s
  training loss:		0.259711
  validation loss:		0.582470
  validation accuracy:		81.74 %
Epoch 1003 of 2000 took 0.104s
  training loss:		0.263804
  validation loss:		0.595668
  validation accuracy:		81.64 %
Epoch 1004 of 2000 took 0.104s
  training loss:		0.254391
  validation loss:		0.593509
  validation accuracy:		81.85 %
Epoch 1005 of 2000 took 0.104s
  training loss:		0.262632
  validation loss:		0.602416
  validation accuracy:		81.85 %
Epoch 1006 of 2000 took 0.104s
  training loss:		0.266112
  validation loss:		0.590214
  validation accuracy:		81.85 %
Epoch 1007 of 2000 took 0.104s
  training loss:		0.269610
  validation loss:		0.583201
  validation accuracy:		81.33 %
Epoch 1008 of 2000 took 0.104s
  training loss:		0.263748
  validation loss:		0.586763
  validation accuracy:		81.85 %
Epoch 1009 of 2000 took 0.104s
  training loss:		0.265525
  validation loss:		0.592902
  validation accuracy:		82.16 %
Epoch 1010 of 2000 took 0.104s
  training loss:		0.267420
  validation loss:		0.587680
  validation accuracy:		82.05 %
Epoch 1011 of 2000 took 0.104s
  training loss:		0.261806
  validation loss:		0.594928
  validation accuracy:		82.37 %
Epoch 1012 of 2000 took 0.104s
  training loss:		0.264602
  validation loss:		0.585392
  validation accuracy:		81.33 %
Epoch 1013 of 2000 took 0.104s
  training loss:		0.264891
  validation loss:		0.607222
  validation accuracy:		82.57 %
Epoch 1014 of 2000 took 0.104s
  training loss:		0.260582
  validation loss:		0.625813
  validation accuracy:		82.57 %
Epoch 1015 of 2000 took 0.104s
  training loss:		0.262506
  validation loss:		0.613753
  validation accuracy:		82.26 %
Epoch 1016 of 2000 took 0.104s
  training loss:		0.261123
  validation loss:		0.591780
  validation accuracy:		81.54 %
Epoch 1017 of 2000 took 0.104s
  training loss:		0.255821
  validation loss:		0.614165
  validation accuracy:		81.85 %
Epoch 1018 of 2000 took 0.104s
  training loss:		0.266391
  validation loss:		0.603631
  validation accuracy:		81.54 %
Epoch 1019 of 2000 took 0.104s
  training loss:		0.261104
  validation loss:		0.591311
  validation accuracy:		81.85 %
Epoch 1020 of 2000 took 0.104s
  training loss:		0.260353
  validation loss:		0.591469
  validation accuracy:		81.54 %
Epoch 1021 of 2000 took 0.104s
  training loss:		0.256493
  validation loss:		0.600562
  validation accuracy:		82.37 %
Epoch 1022 of 2000 took 0.104s
  training loss:		0.262681
  validation loss:		0.591169
  validation accuracy:		81.64 %
Epoch 1023 of 2000 took 0.104s
  training loss:		0.258666
  validation loss:		0.598839
  validation accuracy:		81.54 %
Epoch 1024 of 2000 took 0.104s
  training loss:		0.263356
  validation loss:		0.598019
  validation accuracy:		82.05 %
Epoch 1025 of 2000 took 0.105s
  training loss:		0.263377
  validation loss:		0.599223
  validation accuracy:		82.05 %
Epoch 1026 of 2000 took 0.105s
  training loss:		0.257173
  validation loss:		0.606171
  validation accuracy:		82.68 %
Epoch 1027 of 2000 took 0.104s
  training loss:		0.262183
  validation loss:		0.604099
  validation accuracy:		81.74 %
Epoch 1028 of 2000 took 0.104s
  training loss:		0.259612
  validation loss:		0.589928
  validation accuracy:		81.22 %
Epoch 1029 of 2000 took 0.102s
  training loss:		0.258681
  validation loss:		0.585582
  validation accuracy:		81.95 %
Epoch 1030 of 2000 took 0.101s
  training loss:		0.255579
  validation loss:		0.589408
  validation accuracy:		82.57 %
Epoch 1031 of 2000 took 0.104s
  training loss:		0.257880
  validation loss:		0.589938
  validation accuracy:		82.26 %
Epoch 1032 of 2000 took 0.101s
  training loss:		0.258147
  validation loss:		0.608150
  validation accuracy:		82.78 %
Epoch 1033 of 2000 took 0.101s
  training loss:		0.258967
  validation loss:		0.595454
  validation accuracy:		82.88 %
Epoch 1034 of 2000 took 0.101s
  training loss:		0.255228
  validation loss:		0.596583
  validation accuracy:		81.95 %
Epoch 1035 of 2000 took 0.101s
  training loss:		0.258144
  validation loss:		0.597519
  validation accuracy:		81.64 %
Epoch 1036 of 2000 took 0.101s
  training loss:		0.256833
  validation loss:		0.588950
  validation accuracy:		82.68 %
Epoch 1037 of 2000 took 0.101s
  training loss:		0.253231
  validation loss:		0.616676
  validation accuracy:		81.74 %
Epoch 1038 of 2000 took 0.101s
  training loss:		0.258835
  validation loss:		0.590718
  validation accuracy:		82.68 %
Epoch 1039 of 2000 took 0.101s
  training loss:		0.266754
  validation loss:		0.589362
  validation accuracy:		82.26 %
Epoch 1040 of 2000 took 0.101s
  training loss:		0.255845
  validation loss:		0.599798
  validation accuracy:		81.74 %
Epoch 1041 of 2000 took 0.101s
  training loss:		0.259036
  validation loss:		0.603336
  validation accuracy:		81.54 %
Epoch 1042 of 2000 took 0.101s
  training loss:		0.254902
  validation loss:		0.607422
  validation accuracy:		81.95 %
Epoch 1043 of 2000 took 0.101s
  training loss:		0.253989
  validation loss:		0.597183
  validation accuracy:		82.05 %
Epoch 1044 of 2000 took 0.101s
  training loss:		0.252418
  validation loss:		0.607359
  validation accuracy:		81.64 %
Epoch 1045 of 2000 took 0.101s
  training loss:		0.255542
  validation loss:		0.603431
  validation accuracy:		81.54 %
Epoch 1046 of 2000 took 0.101s
  training loss:		0.255042
  validation loss:		0.593948
  validation accuracy:		82.05 %
Epoch 1047 of 2000 took 0.101s
  training loss:		0.255356
  validation loss:		0.599653
  validation accuracy:		82.05 %
Epoch 1048 of 2000 took 0.101s
  training loss:		0.256696
  validation loss:		0.592041
  validation accuracy:		82.37 %
Epoch 1049 of 2000 took 0.101s
  training loss:		0.258501
  validation loss:		0.599959
  validation accuracy:		82.16 %
Epoch 1050 of 2000 took 0.101s
  training loss:		0.254494
  validation loss:		0.610262
  validation accuracy:		81.95 %
Epoch 1051 of 2000 took 0.101s
  training loss:		0.257760
  validation loss:		0.589202
  validation accuracy:		82.37 %
Epoch 1052 of 2000 took 0.101s
  training loss:		0.249633
  validation loss:		0.601734
  validation accuracy:		81.43 %
Epoch 1053 of 2000 took 0.101s
  training loss:		0.250493
  validation loss:		0.607039
  validation accuracy:		81.85 %
Epoch 1054 of 2000 took 0.102s
  training loss:		0.256150
  validation loss:		0.585911
  validation accuracy:		82.37 %
Epoch 1055 of 2000 took 0.101s
  training loss:		0.252060
  validation loss:		0.593375
  validation accuracy:		81.54 %
Epoch 1056 of 2000 took 0.101s
  training loss:		0.257954
  validation loss:		0.611924
  validation accuracy:		82.37 %
Epoch 1057 of 2000 took 0.101s
  training loss:		0.254802
  validation loss:		0.604856
  validation accuracy:		82.57 %
Epoch 1058 of 2000 took 0.101s
  training loss:		0.256469
  validation loss:		0.611691
  validation accuracy:		82.47 %
Epoch 1059 of 2000 took 0.101s
  training loss:		0.253608
  validation loss:		0.588564
  validation accuracy:		82.05 %
Epoch 1060 of 2000 took 0.101s
  training loss:		0.257468
  validation loss:		0.606369
  validation accuracy:		82.37 %
Epoch 1061 of 2000 took 0.101s
  training loss:		0.259774
  validation loss:		0.593580
  validation accuracy:		82.05 %
Epoch 1062 of 2000 took 0.101s
  training loss:		0.255125
  validation loss:		0.597755
  validation accuracy:		81.54 %
Epoch 1063 of 2000 took 0.101s
  training loss:		0.258445
  validation loss:		0.616728
  validation accuracy:		82.16 %
Epoch 1064 of 2000 took 0.101s
  training loss:		0.256397
  validation loss:		0.602139
  validation accuracy:		81.64 %
Epoch 1065 of 2000 took 0.101s
  training loss:		0.256876
  validation loss:		0.608499
  validation accuracy:		82.68 %
Epoch 1066 of 2000 took 0.101s
  training loss:		0.250130
  validation loss:		0.590643
  validation accuracy:		82.37 %
Epoch 1067 of 2000 took 0.101s
  training loss:		0.256870
  validation loss:		0.598662
  validation accuracy:		82.99 %
Epoch 1068 of 2000 took 0.101s
  training loss:		0.257682
  validation loss:		0.612333
  validation accuracy:		82.68 %
Epoch 1069 of 2000 took 0.101s
  training loss:		0.248167
  validation loss:		0.608712
  validation accuracy:		83.09 %
Epoch 1070 of 2000 took 0.101s
  training loss:		0.255933
  validation loss:		0.617897
  validation accuracy:		83.30 %
Epoch 1071 of 2000 took 0.101s
  training loss:		0.251784
  validation loss:		0.615906
  validation accuracy:		82.68 %
Epoch 1072 of 2000 took 0.101s
  training loss:		0.246110
  validation loss:		0.597455
  validation accuracy:		82.16 %
Epoch 1073 of 2000 took 0.101s
  training loss:		0.254844
  validation loss:		0.622363
  validation accuracy:		82.99 %
Epoch 1074 of 2000 took 0.101s
  training loss:		0.253495
  validation loss:		0.608101
  validation accuracy:		82.05 %
Epoch 1075 of 2000 took 0.101s
  training loss:		0.251795
  validation loss:		0.606032
  validation accuracy:		82.57 %
Epoch 1076 of 2000 took 0.101s
  training loss:		0.255103
  validation loss:		0.614055
  validation accuracy:		81.12 %
Epoch 1077 of 2000 took 0.101s
  training loss:		0.250056
  validation loss:		0.597837
  validation accuracy:		82.88 %
Epoch 1078 of 2000 took 0.101s
  training loss:		0.251542
  validation loss:		0.609810
  validation accuracy:		81.22 %
Epoch 1079 of 2000 took 0.101s
  training loss:		0.249823
  validation loss:		0.614483
  validation accuracy:		82.47 %
Epoch 1080 of 2000 took 0.101s
  training loss:		0.251175
  validation loss:		0.607972
  validation accuracy:		82.05 %
Epoch 1081 of 2000 took 0.101s
  training loss:		0.243969
  validation loss:		0.612549
  validation accuracy:		82.37 %
Epoch 1082 of 2000 took 0.101s
  training loss:		0.248233
  validation loss:		0.601346
  validation accuracy:		81.74 %
Epoch 1083 of 2000 took 0.101s
  training loss:		0.248738
  validation loss:		0.606524
  validation accuracy:		81.85 %
Epoch 1084 of 2000 took 0.102s
  training loss:		0.254756
  validation loss:		0.601587
  validation accuracy:		82.37 %
Epoch 1085 of 2000 took 0.101s
  training loss:		0.247704
  validation loss:		0.605380
  validation accuracy:		82.47 %
Epoch 1086 of 2000 took 0.101s
  training loss:		0.250200
  validation loss:		0.606802
  validation accuracy:		82.78 %
Epoch 1087 of 2000 took 0.101s
  training loss:		0.254132
  validation loss:		0.608479
  validation accuracy:		82.68 %
Epoch 1088 of 2000 took 0.101s
  training loss:		0.252235
  validation loss:		0.593289
  validation accuracy:		82.47 %
Epoch 1089 of 2000 took 0.101s
  training loss:		0.252417
  validation loss:		0.595913
  validation accuracy:		81.95 %
Epoch 1090 of 2000 took 0.101s
  training loss:		0.249188
  validation loss:		0.606963
  validation accuracy:		83.09 %
Epoch 1091 of 2000 took 0.101s
  training loss:		0.248563
  validation loss:		0.628782
  validation accuracy:		81.74 %
Epoch 1092 of 2000 took 0.101s
  training loss:		0.254773
  validation loss:		0.609263
  validation accuracy:		82.05 %
Epoch 1093 of 2000 took 0.101s
  training loss:		0.254699
  validation loss:		0.602818
  validation accuracy:		82.16 %
Epoch 1094 of 2000 took 0.101s
  training loss:		0.248775
  validation loss:		0.609744
  validation accuracy:		81.74 %
Epoch 1095 of 2000 took 0.101s
  training loss:		0.249258
  validation loss:		0.601664
  validation accuracy:		82.68 %
Epoch 1096 of 2000 took 0.101s
  training loss:		0.249807
  validation loss:		0.633199
  validation accuracy:		82.05 %
Epoch 1097 of 2000 took 0.101s
  training loss:		0.246816
  validation loss:		0.607730
  validation accuracy:		82.47 %
Epoch 1098 of 2000 took 0.101s
  training loss:		0.250153
  validation loss:		0.613640
  validation accuracy:		81.64 %
Epoch 1099 of 2000 took 0.101s
  training loss:		0.245575
  validation loss:		0.603158
  validation accuracy:		81.54 %
Epoch 1100 of 2000 took 0.103s
  training loss:		0.250812
  validation loss:		0.603929
  validation accuracy:		82.57 %
Epoch 1101 of 2000 took 0.101s
  training loss:		0.251466
  validation loss:		0.601548
  validation accuracy:		82.37 %
Epoch 1102 of 2000 took 0.101s
  training loss:		0.244508
  validation loss:		0.617222
  validation accuracy:		82.99 %
Epoch 1103 of 2000 took 0.101s
  training loss:		0.253988
  validation loss:		0.599323
  validation accuracy:		81.43 %
Epoch 1104 of 2000 took 0.101s
  training loss:		0.244454
  validation loss:		0.610446
  validation accuracy:		83.09 %
Epoch 1105 of 2000 took 0.101s
  training loss:		0.244311
  validation loss:		0.605012
  validation accuracy:		81.95 %
Epoch 1106 of 2000 took 0.101s
  training loss:		0.242431
  validation loss:		0.624623
  validation accuracy:		82.05 %
Epoch 1107 of 2000 took 0.101s
  training loss:		0.249035
  validation loss:		0.617605
  validation accuracy:		82.26 %
Epoch 1108 of 2000 took 0.101s
  training loss:		0.244379
  validation loss:		0.610749
  validation accuracy:		82.68 %
Epoch 1109 of 2000 took 0.101s
  training loss:		0.246392
  validation loss:		0.615090
  validation accuracy:		82.37 %
Epoch 1110 of 2000 took 0.101s
  training loss:		0.247254
  validation loss:		0.604680
  validation accuracy:		82.16 %
Epoch 1111 of 2000 took 0.101s
  training loss:		0.247667
  validation loss:		0.606754
  validation accuracy:		82.05 %
Epoch 1112 of 2000 took 0.101s
  training loss:		0.245702
  validation loss:		0.614492
  validation accuracy:		81.33 %
Epoch 1113 of 2000 took 0.101s
  training loss:		0.242103
  validation loss:		0.625991
  validation accuracy:		82.47 %
Epoch 1114 of 2000 took 0.102s
  training loss:		0.244127
  validation loss:		0.608618
  validation accuracy:		82.99 %
Epoch 1115 of 2000 took 0.101s
  training loss:		0.240114
  validation loss:		0.616080
  validation accuracy:		81.64 %
Epoch 1116 of 2000 took 0.101s
  training loss:		0.252232
  validation loss:		0.623782
  validation accuracy:		82.37 %
Epoch 1117 of 2000 took 0.101s
  training loss:		0.248741
  validation loss:		0.619446
  validation accuracy:		82.05 %
Epoch 1118 of 2000 took 0.101s
  training loss:		0.246870
  validation loss:		0.609025
  validation accuracy:		82.37 %
Epoch 1119 of 2000 took 0.101s
  training loss:		0.243917
  validation loss:		0.614404
  validation accuracy:		82.88 %
Epoch 1120 of 2000 took 0.101s
  training loss:		0.248659
  validation loss:		0.605076
  validation accuracy:		82.26 %
Epoch 1121 of 2000 took 0.101s
  training loss:		0.241055
  validation loss:		0.608264
  validation accuracy:		82.47 %
Epoch 1122 of 2000 took 0.101s
  training loss:		0.246819
  validation loss:		0.640542
  validation accuracy:		82.57 %
Epoch 1123 of 2000 took 0.101s
  training loss:		0.248907
  validation loss:		0.607402
  validation accuracy:		81.85 %
Epoch 1124 of 2000 took 0.101s
  training loss:		0.244904
  validation loss:		0.611615
  validation accuracy:		82.99 %
Epoch 1125 of 2000 took 0.101s
  training loss:		0.247818
  validation loss:		0.617740
  validation accuracy:		82.47 %
Epoch 1126 of 2000 took 0.101s
  training loss:		0.241738
  validation loss:		0.603239
  validation accuracy:		82.05 %
Epoch 1127 of 2000 took 0.101s
  training loss:		0.241714
  validation loss:		0.609426
  validation accuracy:		82.68 %
Epoch 1128 of 2000 took 0.101s
  training loss:		0.243592
  validation loss:		0.604729
  validation accuracy:		82.05 %
Epoch 1129 of 2000 took 0.101s
  training loss:		0.249484
  validation loss:		0.609856
  validation accuracy:		81.74 %
Epoch 1130 of 2000 took 0.101s
  training loss:		0.242500
  validation loss:		0.629053
  validation accuracy:		81.95 %
Epoch 1131 of 2000 took 0.101s
  training loss:		0.243639
  validation loss:		0.611080
  validation accuracy:		82.26 %
Epoch 1132 of 2000 took 0.101s
  training loss:		0.244421
  validation loss:		0.615211
  validation accuracy:		82.99 %
Epoch 1133 of 2000 took 0.101s
  training loss:		0.247386
  validation loss:		0.612825
  validation accuracy:		82.57 %
Epoch 1134 of 2000 took 0.101s
  training loss:		0.237008
  validation loss:		0.600919
  validation accuracy:		82.26 %
Epoch 1135 of 2000 took 0.101s
  training loss:		0.244206
  validation loss:		0.608606
  validation accuracy:		82.26 %
Epoch 1136 of 2000 took 0.101s
  training loss:		0.239373
  validation loss:		0.612575
  validation accuracy:		82.26 %
Epoch 1137 of 2000 took 0.101s
  training loss:		0.244936
  validation loss:		0.628235
  validation accuracy:		83.51 %
Epoch 1138 of 2000 took 0.101s
  training loss:		0.249886
  validation loss:		0.617346
  validation accuracy:		82.37 %
Epoch 1139 of 2000 took 0.101s
  training loss:		0.243626
  validation loss:		0.616288
  validation accuracy:		82.99 %
Epoch 1140 of 2000 took 0.101s
  training loss:		0.241700
  validation loss:		0.602286
  validation accuracy:		82.37 %
Epoch 1141 of 2000 took 0.101s
  training loss:		0.240247
  validation loss:		0.616913
  validation accuracy:		82.57 %
Epoch 1142 of 2000 took 0.101s
  training loss:		0.235625
  validation loss:		0.615355
  validation accuracy:		82.26 %
Epoch 1143 of 2000 took 0.101s
  training loss:		0.238512
  validation loss:		0.612803
  validation accuracy:		82.47 %
Epoch 1144 of 2000 took 0.102s
  training loss:		0.241330
  validation loss:		0.615382
  validation accuracy:		81.85 %
Epoch 1145 of 2000 took 0.101s
  training loss:		0.243880
  validation loss:		0.617342
  validation accuracy:		82.68 %
Epoch 1146 of 2000 took 0.101s
  training loss:		0.239087
  validation loss:		0.608237
  validation accuracy:		82.16 %
Epoch 1147 of 2000 took 0.103s
  training loss:		0.239330
  validation loss:		0.633008
  validation accuracy:		82.47 %
Epoch 1148 of 2000 took 0.104s
  training loss:		0.242159
  validation loss:		0.626324
  validation accuracy:		82.05 %
Epoch 1149 of 2000 took 0.104s
  training loss:		0.241420
  validation loss:		0.637794
  validation accuracy:		82.68 %
Epoch 1150 of 2000 took 0.107s
  training loss:		0.240347
  validation loss:		0.612514
  validation accuracy:		82.47 %
Epoch 1151 of 2000 took 0.108s
  training loss:		0.242361
  validation loss:		0.605727
  validation accuracy:		82.05 %
Epoch 1152 of 2000 took 0.107s
  training loss:		0.239789
  validation loss:		0.627443
  validation accuracy:		82.68 %
Epoch 1153 of 2000 took 0.104s
  training loss:		0.241501
  validation loss:		0.620196
  validation accuracy:		82.16 %
Epoch 1154 of 2000 took 0.104s
  training loss:		0.237827
  validation loss:		0.638282
  validation accuracy:		82.37 %
Epoch 1155 of 2000 took 0.104s
  training loss:		0.240209
  validation loss:		0.618698
  validation accuracy:		82.68 %
Epoch 1156 of 2000 took 0.104s
  training loss:		0.246319
  validation loss:		0.628499
  validation accuracy:		82.78 %
Epoch 1157 of 2000 took 0.104s
  training loss:		0.236596
  validation loss:		0.637911
  validation accuracy:		81.85 %
Epoch 1158 of 2000 took 0.104s
  training loss:		0.233267
  validation loss:		0.615421
  validation accuracy:		82.57 %
Epoch 1159 of 2000 took 0.105s
  training loss:		0.238081
  validation loss:		0.616876
  validation accuracy:		81.85 %
Epoch 1160 of 2000 took 0.104s
  training loss:		0.243232
  validation loss:		0.641544
  validation accuracy:		82.16 %
Epoch 1161 of 2000 took 0.104s
  training loss:		0.231413
  validation loss:		0.618996
  validation accuracy:		82.47 %
Epoch 1162 of 2000 took 0.104s
  training loss:		0.235774
  validation loss:		0.632054
  validation accuracy:		82.26 %
Epoch 1163 of 2000 took 0.104s
  training loss:		0.236909
  validation loss:		0.635251
  validation accuracy:		82.47 %
Epoch 1164 of 2000 took 0.104s
  training loss:		0.239197
  validation loss:		0.638546
  validation accuracy:		81.74 %
Epoch 1165 of 2000 took 0.104s
  training loss:		0.239984
  validation loss:		0.623059
  validation accuracy:		82.88 %
Epoch 1166 of 2000 took 0.104s
  training loss:		0.241409
  validation loss:		0.634025
  validation accuracy:		81.64 %
Epoch 1167 of 2000 took 0.104s
  training loss:		0.244826
  validation loss:		0.619548
  validation accuracy:		82.16 %
Epoch 1168 of 2000 took 0.104s
  training loss:		0.234883
  validation loss:		0.618482
  validation accuracy:		82.37 %
Epoch 1169 of 2000 took 0.104s
  training loss:		0.236549
  validation loss:		0.615682
  validation accuracy:		81.74 %
Epoch 1170 of 2000 took 0.104s
  training loss:		0.234569
  validation loss:		0.615120
  validation accuracy:		82.47 %
Epoch 1171 of 2000 took 0.104s
  training loss:		0.233740
  validation loss:		0.621789
  validation accuracy:		81.85 %
Epoch 1172 of 2000 took 0.104s
  training loss:		0.240061
  validation loss:		0.626935
  validation accuracy:		82.05 %
Epoch 1173 of 2000 took 0.105s
  training loss:		0.242795
  validation loss:		0.618035
  validation accuracy:		82.99 %
Epoch 1174 of 2000 took 0.104s
  training loss:		0.236324
  validation loss:		0.645426
  validation accuracy:		81.95 %
Epoch 1175 of 2000 took 0.104s
  training loss:		0.238091
  validation loss:		0.618738
  validation accuracy:		82.16 %
Epoch 1176 of 2000 took 0.104s
  training loss:		0.235825
  validation loss:		0.629530
  validation accuracy:		82.88 %
Epoch 1177 of 2000 took 0.104s
  training loss:		0.241421
  validation loss:		0.643120
  validation accuracy:		82.05 %
Epoch 1178 of 2000 took 0.104s
  training loss:		0.236761
  validation loss:		0.619738
  validation accuracy:		81.85 %
Epoch 1179 of 2000 took 0.104s
  training loss:		0.237264
  validation loss:		0.634468
  validation accuracy:		82.37 %
Epoch 1180 of 2000 took 0.104s
  training loss:		0.226108
  validation loss:		0.659554
  validation accuracy:		82.99 %
Epoch 1181 of 2000 took 0.104s
  training loss:		0.237442
  validation loss:		0.632136
  validation accuracy:		82.57 %
Epoch 1182 of 2000 took 0.104s
  training loss:		0.232630
  validation loss:		0.618924
  validation accuracy:		82.37 %
Epoch 1183 of 2000 took 0.104s
  training loss:		0.235032
  validation loss:		0.619156
  validation accuracy:		82.16 %
Epoch 1184 of 2000 took 0.104s
  training loss:		0.237156
  validation loss:		0.617912
  validation accuracy:		82.05 %
Epoch 1185 of 2000 took 0.103s
  training loss:		0.234396
  validation loss:		0.616576
  validation accuracy:		82.26 %
Epoch 1186 of 2000 took 0.101s
  training loss:		0.236265
  validation loss:		0.644568
  validation accuracy:		82.37 %
Epoch 1187 of 2000 took 0.101s
  training loss:		0.238299
  validation loss:		0.642255
  validation accuracy:		82.57 %
Epoch 1188 of 2000 took 0.101s
  training loss:		0.229819
  validation loss:		0.628500
  validation accuracy:		82.78 %
Epoch 1189 of 2000 took 0.101s
  training loss:		0.239990
  validation loss:		0.637263
  validation accuracy:		83.20 %
Epoch 1190 of 2000 took 0.101s
  training loss:		0.234924
  validation loss:		0.636923
  validation accuracy:		82.88 %
Epoch 1191 of 2000 took 0.101s
  training loss:		0.239385
  validation loss:		0.621086
  validation accuracy:		82.57 %
Epoch 1192 of 2000 took 0.101s
  training loss:		0.237372
  validation loss:		0.635904
  validation accuracy:		82.68 %
Epoch 1193 of 2000 took 0.101s
  training loss:		0.232516
  validation loss:		0.625519
  validation accuracy:		82.37 %
Epoch 1194 of 2000 took 0.101s
  training loss:		0.237177
  validation loss:		0.637169
  validation accuracy:		83.09 %
Epoch 1195 of 2000 took 0.101s
  training loss:		0.236527
  validation loss:		0.637379
  validation accuracy:		81.64 %
Epoch 1196 of 2000 took 0.101s
  training loss:		0.235862
  validation loss:		0.644049
  validation accuracy:		82.47 %
Epoch 1197 of 2000 took 0.101s
  training loss:		0.237459
  validation loss:		0.661183
  validation accuracy:		81.54 %
Epoch 1198 of 2000 took 0.101s
  training loss:		0.232487
  validation loss:		0.638413
  validation accuracy:		82.57 %
Epoch 1199 of 2000 took 0.101s
  training loss:		0.234986
  validation loss:		0.623051
  validation accuracy:		82.47 %
Epoch 1200 of 2000 took 0.101s
  training loss:		0.235492
  validation loss:		0.625918
  validation accuracy:		81.95 %
Epoch 1201 of 2000 took 0.101s
  training loss:		0.230972
  validation loss:		0.630603
  validation accuracy:		82.05 %
Epoch 1202 of 2000 took 0.102s
  training loss:		0.228367
  validation loss:		0.636333
  validation accuracy:		82.05 %
Epoch 1203 of 2000 took 0.101s
  training loss:		0.230320
  validation loss:		0.632387
  validation accuracy:		82.99 %
Epoch 1204 of 2000 took 0.101s
  training loss:		0.233805
  validation loss:		0.640300
  validation accuracy:		82.37 %
Epoch 1205 of 2000 took 0.101s
  training loss:		0.235451
  validation loss:		0.637046
  validation accuracy:		82.26 %
Epoch 1206 of 2000 took 0.101s
  training loss:		0.230231
  validation loss:		0.641041
  validation accuracy:		82.47 %
Epoch 1207 of 2000 took 0.101s
  training loss:		0.234047
  validation loss:		0.638481
  validation accuracy:		81.95 %
Epoch 1208 of 2000 took 0.101s
  training loss:		0.230130
  validation loss:		0.635051
  validation accuracy:		81.64 %
Epoch 1209 of 2000 took 0.101s
  training loss:		0.224412
  validation loss:		0.650928
  validation accuracy:		82.99 %
Epoch 1210 of 2000 took 0.101s
  training loss:		0.232289
  validation loss:		0.632840
  validation accuracy:		81.74 %
Epoch 1211 of 2000 took 0.101s
  training loss:		0.229587
  validation loss:		0.635995
  validation accuracy:		81.33 %
Epoch 1212 of 2000 took 0.101s
  training loss:		0.229861
  validation loss:		0.618916
  validation accuracy:		82.16 %
Epoch 1213 of 2000 took 0.101s
  training loss:		0.229924
  validation loss:		0.634784
  validation accuracy:		82.57 %
Epoch 1214 of 2000 took 0.101s
  training loss:		0.225986
  validation loss:		0.636346
  validation accuracy:		82.47 %
Epoch 1215 of 2000 took 0.101s
  training loss:		0.226073
  validation loss:		0.633073
  validation accuracy:		82.26 %
Epoch 1216 of 2000 took 0.101s
  training loss:		0.225574
  validation loss:		0.632672
  validation accuracy:		82.05 %
Epoch 1217 of 2000 took 0.101s
  training loss:		0.233874
  validation loss:		0.638649
  validation accuracy:		82.37 %
Epoch 1218 of 2000 took 0.101s
  training loss:		0.236156
  validation loss:		0.654251
  validation accuracy:		82.68 %
Epoch 1219 of 2000 took 0.101s
  training loss:		0.229017
  validation loss:		0.633651
  validation accuracy:		81.74 %
Epoch 1220 of 2000 took 0.101s
  training loss:		0.230916
  validation loss:		0.639843
  validation accuracy:		82.26 %
Epoch 1221 of 2000 took 0.101s
  training loss:		0.233616
  validation loss:		0.629928
  validation accuracy:		81.85 %
Epoch 1222 of 2000 took 0.101s
  training loss:		0.226975
  validation loss:		0.629011
  validation accuracy:		82.05 %
Epoch 1223 of 2000 took 0.101s
  training loss:		0.228705
  validation loss:		0.628285
  validation accuracy:		82.47 %
Epoch 1224 of 2000 took 0.101s
  training loss:		0.228018
  validation loss:		0.663090
  validation accuracy:		82.78 %
Epoch 1225 of 2000 took 0.103s
  training loss:		0.234200
  validation loss:		0.639259
  validation accuracy:		81.95 %
Epoch 1226 of 2000 took 0.104s
  training loss:		0.232774
  validation loss:		0.636284
  validation accuracy:		82.57 %
Epoch 1227 of 2000 took 0.104s
  training loss:		0.233547
  validation loss:		0.647066
  validation accuracy:		82.26 %
Epoch 1228 of 2000 took 0.104s
  training loss:		0.230235
  validation loss:		0.661304
  validation accuracy:		82.26 %
Epoch 1229 of 2000 took 0.104s
  training loss:		0.230120
  validation loss:		0.643770
  validation accuracy:		82.37 %
Epoch 1230 of 2000 took 0.104s
  training loss:		0.229213
  validation loss:		0.648182
  validation accuracy:		82.57 %
Epoch 1231 of 2000 took 0.104s
  training loss:		0.229368
  validation loss:		0.639989
  validation accuracy:		82.16 %
Epoch 1232 of 2000 took 0.105s
  training loss:		0.229413
  validation loss:		0.637330
  validation accuracy:		82.26 %
Epoch 1233 of 2000 took 0.104s
  training loss:		0.224657
  validation loss:		0.649996
  validation accuracy:		81.85 %
Epoch 1234 of 2000 took 0.104s
  training loss:		0.228502
  validation loss:		0.642639
  validation accuracy:		82.99 %
Epoch 1235 of 2000 took 0.104s
  training loss:		0.231697
  validation loss:		0.653889
  validation accuracy:		82.26 %
Epoch 1236 of 2000 took 0.104s
  training loss:		0.231206
  validation loss:		0.649274
  validation accuracy:		82.88 %
Epoch 1237 of 2000 took 0.104s
  training loss:		0.226225
  validation loss:		0.637255
  validation accuracy:		81.95 %
Epoch 1238 of 2000 took 0.104s
  training loss:		0.234968
  validation loss:		0.633569
  validation accuracy:		82.16 %
Epoch 1239 of 2000 took 0.104s
  training loss:		0.227893
  validation loss:		0.648363
  validation accuracy:		82.68 %
Epoch 1240 of 2000 took 0.104s
  training loss:		0.221843
  validation loss:		0.631329
  validation accuracy:		82.37 %
Epoch 1241 of 2000 took 0.104s
  training loss:		0.228236
  validation loss:		0.632060
  validation accuracy:		82.05 %
Epoch 1242 of 2000 took 0.104s
  training loss:		0.218471
  validation loss:		0.666075
  validation accuracy:		82.16 %
Epoch 1243 of 2000 took 0.104s
  training loss:		0.227141
  validation loss:		0.644194
  validation accuracy:		82.47 %
Epoch 1244 of 2000 took 0.104s
  training loss:		0.228402
  validation loss:		0.644475
  validation accuracy:		82.26 %
Epoch 1245 of 2000 took 0.104s
  training loss:		0.229767
  validation loss:		0.655242
  validation accuracy:		82.47 %
Epoch 1246 of 2000 took 0.104s
  training loss:		0.229757
  validation loss:		0.638989
  validation accuracy:		81.85 %
Epoch 1247 of 2000 took 0.104s
  training loss:		0.225653
  validation loss:		0.659087
  validation accuracy:		82.26 %
Epoch 1248 of 2000 took 0.104s
  training loss:		0.225421
  validation loss:		0.645848
  validation accuracy:		82.16 %
Epoch 1249 of 2000 took 0.104s
  training loss:		0.221739
  validation loss:		0.666750
  validation accuracy:		82.57 %
Epoch 1250 of 2000 took 0.104s
  training loss:		0.228754
  validation loss:		0.638368
  validation accuracy:		82.37 %
Epoch 1251 of 2000 took 0.104s
  training loss:		0.227162
  validation loss:		0.678571
  validation accuracy:		82.47 %
Epoch 1252 of 2000 took 0.104s
  training loss:		0.225008
  validation loss:		0.643482
  validation accuracy:		82.47 %
Epoch 1253 of 2000 took 0.104s
  training loss:		0.228853
  validation loss:		0.648402
  validation accuracy:		82.37 %
Epoch 1254 of 2000 took 0.104s
  training loss:		0.233213
  validation loss:		0.636967
  validation accuracy:		81.95 %
Epoch 1255 of 2000 took 0.104s
  training loss:		0.228812
  validation loss:		0.646633
  validation accuracy:		82.16 %
Epoch 1256 of 2000 took 0.105s
  training loss:		0.229421
  validation loss:		0.655528
  validation accuracy:		81.74 %
Epoch 1257 of 2000 took 0.104s
  training loss:		0.230312
  validation loss:		0.661481
  validation accuracy:		81.85 %
Epoch 1258 of 2000 took 0.104s
  training loss:		0.221822
  validation loss:		0.653384
  validation accuracy:		81.95 %
Epoch 1259 of 2000 took 0.104s
  training loss:		0.224682
  validation loss:		0.644447
  validation accuracy:		81.85 %
Epoch 1260 of 2000 took 0.105s
  training loss:		0.225211
  validation loss:		0.653269
  validation accuracy:		81.85 %
Epoch 1261 of 2000 took 0.105s
  training loss:		0.228079
  validation loss:		0.644160
  validation accuracy:		82.47 %
Epoch 1262 of 2000 took 0.104s
  training loss:		0.225274
  validation loss:		0.655574
  validation accuracy:		81.85 %
Epoch 1263 of 2000 took 0.104s
  training loss:		0.227117
  validation loss:		0.662632
  validation accuracy:		81.64 %
Epoch 1264 of 2000 took 0.104s
  training loss:		0.225830
  validation loss:		0.653661
  validation accuracy:		82.26 %
Epoch 1265 of 2000 took 0.104s
  training loss:		0.229952
  validation loss:		0.654226
  validation accuracy:		82.99 %
Epoch 1266 of 2000 took 0.104s
  training loss:		0.224990
  validation loss:		0.654077
  validation accuracy:		82.99 %
Epoch 1267 of 2000 took 0.106s
  training loss:		0.220920
  validation loss:		0.646513
  validation accuracy:		82.57 %
Epoch 1268 of 2000 took 0.104s
  training loss:		0.224445
  validation loss:		0.651727
  validation accuracy:		82.26 %
Epoch 1269 of 2000 took 0.104s
  training loss:		0.231689
  validation loss:		0.655440
  validation accuracy:		82.26 %
Epoch 1270 of 2000 took 0.104s
  training loss:		0.221771
  validation loss:		0.687751
  validation accuracy:		82.37 %
Epoch 1271 of 2000 took 0.104s
  training loss:		0.228843
  validation loss:		0.649375
  validation accuracy:		82.26 %
Epoch 1272 of 2000 took 0.104s
  training loss:		0.224536
  validation loss:		0.646814
  validation accuracy:		82.78 %
Epoch 1273 of 2000 took 0.104s
  training loss:		0.225631
  validation loss:		0.677852
  validation accuracy:		81.85 %
Epoch 1274 of 2000 took 0.104s
  training loss:		0.222225
  validation loss:		0.654336
  validation accuracy:		82.26 %
Epoch 1275 of 2000 took 0.104s
  training loss:		0.227655
  validation loss:		0.671297
  validation accuracy:		82.26 %
Epoch 1276 of 2000 took 0.104s
  training loss:		0.226488
  validation loss:		0.661804
  validation accuracy:		82.57 %
Epoch 1277 of 2000 took 0.104s
  training loss:		0.225073
  validation loss:		0.647288
  validation accuracy:		81.85 %
Epoch 1278 of 2000 took 0.104s
  training loss:		0.220709
  validation loss:		0.655800
  validation accuracy:		81.95 %
Epoch 1279 of 2000 took 0.104s
  training loss:		0.225354
  validation loss:		0.656565
  validation accuracy:		83.09 %
Epoch 1280 of 2000 took 0.104s
  training loss:		0.221285
  validation loss:		0.668451
  validation accuracy:		82.78 %
Epoch 1281 of 2000 took 0.104s
  training loss:		0.225353
  validation loss:		0.660340
  validation accuracy:		81.95 %
Epoch 1282 of 2000 took 0.104s
  training loss:		0.227154
  validation loss:		0.662282
  validation accuracy:		81.64 %
Epoch 1283 of 2000 took 0.104s
  training loss:		0.217141
  validation loss:		0.649207
  validation accuracy:		81.95 %
Epoch 1284 of 2000 took 0.104s
  training loss:		0.221679
  validation loss:		0.656415
  validation accuracy:		81.95 %
Epoch 1285 of 2000 took 0.104s
  training loss:		0.223281
  validation loss:		0.668268
  validation accuracy:		82.47 %
Epoch 1286 of 2000 took 0.104s
  training loss:		0.219194
  validation loss:		0.654389
  validation accuracy:		81.85 %
Epoch 1287 of 2000 took 0.104s
  training loss:		0.225793
  validation loss:		0.664642
  validation accuracy:		82.57 %
Epoch 1288 of 2000 took 0.104s
  training loss:		0.215349
  validation loss:		0.665504
  validation accuracy:		81.85 %
Epoch 1289 of 2000 took 0.105s
  training loss:		0.216717
  validation loss:		0.662972
  validation accuracy:		82.05 %
Epoch 1290 of 2000 took 0.104s
  training loss:		0.223562
  validation loss:		0.678367
  validation accuracy:		82.88 %
Epoch 1291 of 2000 took 0.104s
  training loss:		0.223603
  validation loss:		0.650013
  validation accuracy:		82.37 %
Epoch 1292 of 2000 took 0.104s
  training loss:		0.226492
  validation loss:		0.679325
  validation accuracy:		82.37 %
Epoch 1293 of 2000 took 0.104s
  training loss:		0.230254
  validation loss:		0.649916
  validation accuracy:		82.57 %
Epoch 1294 of 2000 took 0.104s
  training loss:		0.215015
  validation loss:		0.652462
  validation accuracy:		81.95 %
Epoch 1295 of 2000 took 0.104s
  training loss:		0.220761
  validation loss:		0.673104
  validation accuracy:		82.68 %
Epoch 1296 of 2000 took 0.104s
  training loss:		0.216510
  validation loss:		0.669408
  validation accuracy:		82.47 %
Epoch 1297 of 2000 took 0.104s
  training loss:		0.223610
  validation loss:		0.651424
  validation accuracy:		82.26 %
Epoch 1298 of 2000 took 0.104s
  training loss:		0.219701
  validation loss:		0.654588
  validation accuracy:		82.05 %
Epoch 1299 of 2000 took 0.105s
  training loss:		0.219130
  validation loss:		0.652879
  validation accuracy:		82.68 %
Epoch 1300 of 2000 took 0.104s
  training loss:		0.223824
  validation loss:		0.661662
  validation accuracy:		82.26 %
Epoch 1301 of 2000 took 0.104s
  training loss:		0.218838
  validation loss:		0.653325
  validation accuracy:		82.26 %
Epoch 1302 of 2000 took 0.106s
  training loss:		0.224674
  validation loss:		0.656902
  validation accuracy:		82.05 %
Epoch 1303 of 2000 took 0.108s
  training loss:		0.224030
  validation loss:		0.658194
  validation accuracy:		82.05 %
Epoch 1304 of 2000 took 0.108s
  training loss:		0.222263
  validation loss:		0.660170
  validation accuracy:		82.26 %
Epoch 1305 of 2000 took 0.107s
  training loss:		0.220967
  validation loss:		0.674186
  validation accuracy:		81.85 %
Epoch 1306 of 2000 took 0.104s
  training loss:		0.226590
  validation loss:		0.675335
  validation accuracy:		82.47 %
Epoch 1307 of 2000 took 0.104s
  training loss:		0.222669
  validation loss:		0.672568
  validation accuracy:		82.78 %
Epoch 1308 of 2000 took 0.104s
  training loss:		0.226619
  validation loss:		0.670944
  validation accuracy:		82.16 %
Epoch 1309 of 2000 took 0.104s
  training loss:		0.217278
  validation loss:		0.675299
  validation accuracy:		82.16 %
Epoch 1310 of 2000 took 0.104s
  training loss:		0.223054
  validation loss:		0.656772
  validation accuracy:		82.05 %
Epoch 1311 of 2000 took 0.104s
  training loss:		0.225241
  validation loss:		0.655386
  validation accuracy:		81.64 %
Epoch 1312 of 2000 took 0.104s
  training loss:		0.219399
  validation loss:		0.667457
  validation accuracy:		82.05 %
Epoch 1313 of 2000 took 0.104s
  training loss:		0.220188
  validation loss:		0.668367
  validation accuracy:		81.54 %
Epoch 1314 of 2000 took 0.104s
  training loss:		0.219996
  validation loss:		0.670113
  validation accuracy:		82.26 %
Epoch 1315 of 2000 took 0.104s
  training loss:		0.225428
  validation loss:		0.663735
  validation accuracy:		82.05 %
Epoch 1316 of 2000 took 0.104s
  training loss:		0.220329
  validation loss:		0.663031
  validation accuracy:		82.37 %
Epoch 1317 of 2000 took 0.104s
  training loss:		0.219671
  validation loss:		0.669772
  validation accuracy:		82.26 %
Epoch 1318 of 2000 took 0.105s
  training loss:		0.224375
  validation loss:		0.692168
  validation accuracy:		82.05 %
Epoch 1319 of 2000 took 0.104s
  training loss:		0.222580
  validation loss:		0.674220
  validation accuracy:		82.78 %
Epoch 1320 of 2000 took 0.104s
  training loss:		0.217733
  validation loss:		0.673433
  validation accuracy:		82.47 %
Epoch 1321 of 2000 took 0.104s
  training loss:		0.219583
  validation loss:		0.663385
  validation accuracy:		82.47 %
Epoch 1322 of 2000 took 0.104s
  training loss:		0.221003
  validation loss:		0.662302
  validation accuracy:		82.57 %
Epoch 1323 of 2000 took 0.104s
  training loss:		0.218763
  validation loss:		0.686637
  validation accuracy:		82.05 %
Epoch 1324 of 2000 took 0.104s
  training loss:		0.221623
  validation loss:		0.690920
  validation accuracy:		82.47 %
Epoch 1325 of 2000 took 0.104s
  training loss:		0.217095
  validation loss:		0.667032
  validation accuracy:		82.16 %
Epoch 1326 of 2000 took 0.104s
  training loss:		0.222866
  validation loss:		0.683330
  validation accuracy:		82.78 %
Epoch 1327 of 2000 took 0.104s
  training loss:		0.218565
  validation loss:		0.664405
  validation accuracy:		82.68 %
Epoch 1328 of 2000 took 0.104s
  training loss:		0.212752
  validation loss:		0.664162
  validation accuracy:		82.26 %
Epoch 1329 of 2000 took 0.104s
  training loss:		0.223830
  validation loss:		0.673514
  validation accuracy:		82.37 %
Epoch 1330 of 2000 took 0.105s
  training loss:		0.219698
  validation loss:		0.664568
  validation accuracy:		82.26 %
Epoch 1331 of 2000 took 0.104s
  training loss:		0.216929
  validation loss:		0.674402
  validation accuracy:		82.37 %
Epoch 1332 of 2000 took 0.107s
  training loss:		0.226500
  validation loss:		0.663457
  validation accuracy:		81.43 %
Epoch 1333 of 2000 took 0.105s
  training loss:		0.219556
  validation loss:		0.686915
  validation accuracy:		81.85 %
Epoch 1334 of 2000 took 0.104s
  training loss:		0.217400
  validation loss:		0.681296
  validation accuracy:		82.37 %
Epoch 1335 of 2000 took 0.104s
  training loss:		0.210617
  validation loss:		0.668185
  validation accuracy:		81.64 %
Epoch 1336 of 2000 took 0.104s
  training loss:		0.222712
  validation loss:		0.675900
  validation accuracy:		82.26 %
Epoch 1337 of 2000 took 0.104s
  training loss:		0.215419
  validation loss:		0.680754
  validation accuracy:		82.26 %
Epoch 1338 of 2000 took 0.104s
  training loss:		0.215589
  validation loss:		0.674478
  validation accuracy:		82.47 %
Epoch 1339 of 2000 took 0.104s
  training loss:		0.222891
  validation loss:		0.670286
  validation accuracy:		82.47 %
Epoch 1340 of 2000 took 0.104s
  training loss:		0.218490
  validation loss:		0.669039
  validation accuracy:		81.85 %
Epoch 1341 of 2000 took 0.104s
  training loss:		0.213648
  validation loss:		0.665205
  validation accuracy:		82.26 %
Epoch 1342 of 2000 took 0.104s
  training loss:		0.215688
  validation loss:		0.664094
  validation accuracy:		81.85 %
Epoch 1343 of 2000 took 0.104s
  training loss:		0.216815
  validation loss:		0.688094
  validation accuracy:		82.05 %
Epoch 1344 of 2000 took 0.104s
  training loss:		0.219095
  validation loss:		0.686284
  validation accuracy:		82.57 %
Epoch 1345 of 2000 took 0.104s
  training loss:		0.219387
  validation loss:		0.669225
  validation accuracy:		82.16 %
Epoch 1346 of 2000 took 0.104s
  training loss:		0.218684
  validation loss:		0.678406
  validation accuracy:		82.16 %
Epoch 1347 of 2000 took 0.105s
  training loss:		0.217811
  validation loss:		0.663863
  validation accuracy:		82.05 %
Epoch 1348 of 2000 took 0.104s
  training loss:		0.215852
  validation loss:		0.682123
  validation accuracy:		81.54 %
Epoch 1349 of 2000 took 0.104s
  training loss:		0.220129
  validation loss:		0.688856
  validation accuracy:		82.37 %
Epoch 1350 of 2000 took 0.104s
  training loss:		0.218070
  validation loss:		0.677224
  validation accuracy:		82.05 %
Epoch 1351 of 2000 took 0.104s
  training loss:		0.219791
  validation loss:		0.683150
  validation accuracy:		82.16 %
Epoch 1352 of 2000 took 0.104s
  training loss:		0.213830
  validation loss:		0.667618
  validation accuracy:		82.47 %
Epoch 1353 of 2000 took 0.104s
  training loss:		0.212423
  validation loss:		0.679478
  validation accuracy:		82.88 %
Epoch 1354 of 2000 took 0.104s
  training loss:		0.219810
  validation loss:		0.685249
  validation accuracy:		82.47 %
Epoch 1355 of 2000 took 0.104s
  training loss:		0.217716
  validation loss:		0.679441
  validation accuracy:		82.16 %
Epoch 1356 of 2000 took 0.104s
  training loss:		0.217261
  validation loss:		0.680899
  validation accuracy:		82.57 %
Epoch 1357 of 2000 took 0.104s
  training loss:		0.215043
  validation loss:		0.668345
  validation accuracy:		82.16 %
Epoch 1358 of 2000 took 0.104s
  training loss:		0.223444
  validation loss:		0.670616
  validation accuracy:		82.26 %
Epoch 1359 of 2000 took 0.104s
  training loss:		0.216407
  validation loss:		0.693907
  validation accuracy:		81.74 %
Epoch 1360 of 2000 took 0.105s
  training loss:		0.217887
  validation loss:		0.686019
  validation accuracy:		82.05 %
Epoch 1361 of 2000 took 0.104s
  training loss:		0.219646
  validation loss:		0.678472
  validation accuracy:		82.05 %
Epoch 1362 of 2000 took 0.104s
  training loss:		0.217638
  validation loss:		0.681081
  validation accuracy:		82.37 %
Epoch 1363 of 2000 took 0.104s
  training loss:		0.211597
  validation loss:		0.687940
  validation accuracy:		82.16 %
Epoch 1364 of 2000 took 0.104s
  training loss:		0.216302
  validation loss:		0.686771
  validation accuracy:		82.16 %
Epoch 1365 of 2000 took 0.104s
  training loss:		0.215722
  validation loss:		0.685733
  validation accuracy:		82.57 %
Epoch 1366 of 2000 took 0.104s
  training loss:		0.218167
  validation loss:		0.674352
  validation accuracy:		82.16 %
Epoch 1367 of 2000 took 0.104s
  training loss:		0.216027
  validation loss:		0.696977
  validation accuracy:		82.05 %
Epoch 1368 of 2000 took 0.104s
  training loss:		0.215548
  validation loss:		0.692792
  validation accuracy:		81.85 %
Epoch 1369 of 2000 took 0.104s
  training loss:		0.214209
  validation loss:		0.673799
  validation accuracy:		82.47 %
Epoch 1370 of 2000 took 0.104s
  training loss:		0.211201
  validation loss:		0.677566
  validation accuracy:		82.37 %
Epoch 1371 of 2000 took 0.104s
  training loss:		0.211012
  validation loss:		0.687827
  validation accuracy:		81.54 %
Epoch 1372 of 2000 took 0.106s
  training loss:		0.217069
  validation loss:		0.682492
  validation accuracy:		81.95 %
Epoch 1373 of 2000 took 0.108s
  training loss:		0.210991
  validation loss:		0.672464
  validation accuracy:		81.95 %
Epoch 1374 of 2000 took 0.108s
  training loss:		0.217987
  validation loss:		0.676428
  validation accuracy:		82.05 %
Epoch 1375 of 2000 took 0.108s
  training loss:		0.216728
  validation loss:		0.685704
  validation accuracy:		81.64 %
Epoch 1376 of 2000 took 0.105s
  training loss:		0.207955
  validation loss:		0.702110
  validation accuracy:		82.16 %
Epoch 1377 of 2000 took 0.104s
  training loss:		0.219898
  validation loss:		0.691881
  validation accuracy:		82.16 %
Epoch 1378 of 2000 took 0.104s
  training loss:		0.216986
  validation loss:		0.697426
  validation accuracy:		82.16 %
Epoch 1379 of 2000 took 0.104s
  training loss:		0.212617
  validation loss:		0.698102
  validation accuracy:		81.74 %
Epoch 1380 of 2000 took 0.104s
  training loss:		0.208077
  validation loss:		0.701624
  validation accuracy:		81.64 %
Epoch 1381 of 2000 took 0.104s
  training loss:		0.211195
  validation loss:		0.691093
  validation accuracy:		81.95 %
Epoch 1382 of 2000 took 0.104s
  training loss:		0.210861
  validation loss:		0.685585
  validation accuracy:		82.26 %
Epoch 1383 of 2000 took 0.104s
  training loss:		0.217219
  validation loss:		0.695755
  validation accuracy:		81.95 %
Epoch 1384 of 2000 took 0.104s
  training loss:		0.216832
  validation loss:		0.691446
  validation accuracy:		82.47 %
Epoch 1385 of 2000 took 0.104s
  training loss:		0.221210
  validation loss:		0.695393
  validation accuracy:		81.95 %
Epoch 1386 of 2000 took 0.104s
  training loss:		0.215804
  validation loss:		0.701106
  validation accuracy:		82.05 %
Epoch 1387 of 2000 took 0.104s
  training loss:		0.215705
  validation loss:		0.680912
  validation accuracy:		82.05 %
Epoch 1388 of 2000 took 0.104s
  training loss:		0.213036
  validation loss:		0.694853
  validation accuracy:		82.26 %
Epoch 1389 of 2000 took 0.104s
  training loss:		0.220086
  validation loss:		0.699358
  validation accuracy:		81.74 %
Epoch 1390 of 2000 took 0.104s
  training loss:		0.209341
  validation loss:		0.695381
  validation accuracy:		81.85 %
Epoch 1391 of 2000 took 0.104s
  training loss:		0.213539
  validation loss:		0.679678
  validation accuracy:		82.16 %
Epoch 1392 of 2000 took 0.104s
  training loss:		0.216840
  validation loss:		0.699264
  validation accuracy:		82.16 %
Epoch 1393 of 2000 took 0.104s
  training loss:		0.209757
  validation loss:		0.694794
  validation accuracy:		82.37 %
Epoch 1394 of 2000 took 0.104s
  training loss:		0.212773
  validation loss:		0.705120
  validation accuracy:		81.64 %
Epoch 1395 of 2000 took 0.104s
  training loss:		0.213758
  validation loss:		0.692650
  validation accuracy:		81.95 %
Epoch 1396 of 2000 took 0.104s
  training loss:		0.212861
  validation loss:		0.691530
  validation accuracy:		81.95 %
Epoch 1397 of 2000 took 0.104s
  training loss:		0.216288
  validation loss:		0.699598
  validation accuracy:		82.99 %
Epoch 1398 of 2000 took 0.104s
  training loss:		0.219971
  validation loss:		0.693136
  validation accuracy:		82.37 %
Epoch 1399 of 2000 took 0.104s
  training loss:		0.211261
  validation loss:		0.695969
  validation accuracy:		81.54 %
Epoch 1400 of 2000 took 0.104s
  training loss:		0.213523
  validation loss:		0.712438
  validation accuracy:		82.99 %
Epoch 1401 of 2000 took 0.104s
  training loss:		0.218242
  validation loss:		0.702368
  validation accuracy:		82.05 %
Epoch 1402 of 2000 took 0.104s
  training loss:		0.207855
  validation loss:		0.682608
  validation accuracy:		82.05 %
Epoch 1403 of 2000 took 0.104s
  training loss:		0.213605
  validation loss:		0.691699
  validation accuracy:		82.37 %
Epoch 1404 of 2000 took 0.104s
  training loss:		0.211818
  validation loss:		0.680962
  validation accuracy:		81.85 %
Epoch 1405 of 2000 took 0.105s
  training loss:		0.214212
  validation loss:		0.686390
  validation accuracy:		81.85 %
Epoch 1406 of 2000 took 0.104s
  training loss:		0.209375
  validation loss:		0.721016
  validation accuracy:		81.95 %
Epoch 1407 of 2000 took 0.104s
  training loss:		0.215698
  validation loss:		0.716556
  validation accuracy:		82.26 %
Epoch 1408 of 2000 took 0.104s
  training loss:		0.216781
  validation loss:		0.691200
  validation accuracy:		81.85 %
Epoch 1409 of 2000 took 0.104s
  training loss:		0.214870
  validation loss:		0.699178
  validation accuracy:		82.68 %
Epoch 1410 of 2000 took 0.104s
  training loss:		0.209773
  validation loss:		0.691536
  validation accuracy:		82.37 %
Epoch 1411 of 2000 took 0.104s
  training loss:		0.214480
  validation loss:		0.709119
  validation accuracy:		81.74 %
Epoch 1412 of 2000 took 0.104s
  training loss:		0.210915
  validation loss:		0.691969
  validation accuracy:		81.85 %
Epoch 1413 of 2000 took 0.104s
  training loss:		0.217504
  validation loss:		0.706549
  validation accuracy:		82.05 %
Epoch 1414 of 2000 took 0.104s
  training loss:		0.206832
  validation loss:		0.685487
  validation accuracy:		82.16 %
Epoch 1415 of 2000 took 0.106s
  training loss:		0.215540
  validation loss:		0.691238
  validation accuracy:		82.05 %
Epoch 1416 of 2000 took 0.104s
  training loss:		0.212293
  validation loss:		0.697534
  validation accuracy:		82.16 %
Epoch 1417 of 2000 took 0.102s
  training loss:		0.210296
  validation loss:		0.696977
  validation accuracy:		82.37 %
Epoch 1418 of 2000 took 0.101s
  training loss:		0.211211
  validation loss:		0.699857
  validation accuracy:		82.88 %
Epoch 1419 of 2000 took 0.101s
  training loss:		0.210357
  validation loss:		0.697125
  validation accuracy:		81.74 %
Epoch 1420 of 2000 took 0.101s
  training loss:		0.209870
  validation loss:		0.696705
  validation accuracy:		82.16 %
Epoch 1421 of 2000 took 0.101s
  training loss:		0.211753
  validation loss:		0.695386
  validation accuracy:		82.57 %
Epoch 1422 of 2000 took 0.101s
  training loss:		0.218191
  validation loss:		0.694062
  validation accuracy:		81.95 %
Epoch 1423 of 2000 took 0.101s
  training loss:		0.210427
  validation loss:		0.698367
  validation accuracy:		82.37 %
Epoch 1424 of 2000 took 0.101s
  training loss:		0.215171
  validation loss:		0.706374
  validation accuracy:		81.85 %
Epoch 1425 of 2000 took 0.101s
  training loss:		0.210093
  validation loss:		0.701856
  validation accuracy:		81.74 %
Epoch 1426 of 2000 took 0.101s
  training loss:		0.208278
  validation loss:		0.694381
  validation accuracy:		81.85 %
Epoch 1427 of 2000 took 0.101s
  training loss:		0.203292
  validation loss:		0.720397
  validation accuracy:		81.95 %
Epoch 1428 of 2000 took 0.101s
  training loss:		0.216259
  validation loss:		0.696424
  validation accuracy:		82.16 %
Epoch 1429 of 2000 took 0.101s
  training loss:		0.207271
  validation loss:		0.739369
  validation accuracy:		82.47 %
Epoch 1430 of 2000 took 0.101s
  training loss:		0.215403
  validation loss:		0.702312
  validation accuracy:		82.26 %
Epoch 1431 of 2000 took 0.101s
  training loss:		0.212094
  validation loss:		0.697514
  validation accuracy:		82.26 %
Epoch 1432 of 2000 took 0.101s
  training loss:		0.206055
  validation loss:		0.695529
  validation accuracy:		82.37 %
Epoch 1433 of 2000 took 0.101s
  training loss:		0.210578
  validation loss:		0.709017
  validation accuracy:		81.54 %
Epoch 1434 of 2000 took 0.102s
  training loss:		0.214240
  validation loss:		0.710378
  validation accuracy:		82.16 %
Epoch 1435 of 2000 took 0.101s
  training loss:		0.206192
  validation loss:		0.698955
  validation accuracy:		81.85 %
Epoch 1436 of 2000 took 0.101s
  training loss:		0.210215
  validation loss:		0.707461
  validation accuracy:		82.26 %
Epoch 1437 of 2000 took 0.101s
  training loss:		0.206445
  validation loss:		0.701524
  validation accuracy:		82.57 %
Epoch 1438 of 2000 took 0.101s
  training loss:		0.216675
  validation loss:		0.740619
  validation accuracy:		82.47 %
Epoch 1439 of 2000 took 0.101s
  training loss:		0.203715
  validation loss:		0.701774
  validation accuracy:		82.57 %
Epoch 1440 of 2000 took 0.101s
  training loss:		0.208673
  validation loss:		0.711322
  validation accuracy:		82.05 %
Epoch 1441 of 2000 took 0.103s
  training loss:		0.211860
  validation loss:		0.721332
  validation accuracy:		81.74 %
Epoch 1442 of 2000 took 0.104s
  training loss:		0.212745
  validation loss:		0.704781
  validation accuracy:		82.16 %
Epoch 1443 of 2000 took 0.104s
  training loss:		0.206411
  validation loss:		0.697345
  validation accuracy:		82.47 %
Epoch 1444 of 2000 took 0.104s
  training loss:		0.210082
  validation loss:		0.707637
  validation accuracy:		82.16 %
Epoch 1445 of 2000 took 0.104s
  training loss:		0.208388
  validation loss:		0.703140
  validation accuracy:		82.16 %
Epoch 1446 of 2000 took 0.104s
  training loss:		0.211554
  validation loss:		0.706058
  validation accuracy:		82.37 %
Epoch 1447 of 2000 took 0.104s
  training loss:		0.212041
  validation loss:		0.717926
  validation accuracy:		81.74 %
Epoch 1448 of 2000 took 0.104s
  training loss:		0.212919
  validation loss:		0.718232
  validation accuracy:		82.26 %
Epoch 1449 of 2000 took 0.104s
  training loss:		0.204509
  validation loss:		0.702101
  validation accuracy:		82.26 %
Epoch 1450 of 2000 took 0.104s
  training loss:		0.203269
  validation loss:		0.707832
  validation accuracy:		81.74 %
Epoch 1451 of 2000 took 0.104s
  training loss:		0.204067
  validation loss:		0.704861
  validation accuracy:		81.74 %
Epoch 1452 of 2000 took 0.104s
  training loss:		0.214492
  validation loss:		0.704032
  validation accuracy:		82.16 %
Epoch 1453 of 2000 took 0.103s
  training loss:		0.211978
  validation loss:		0.705011
  validation accuracy:		81.95 %
Epoch 1454 of 2000 took 0.101s
  training loss:		0.210816
  validation loss:		0.713545
  validation accuracy:		82.88 %
Epoch 1455 of 2000 took 0.101s
  training loss:		0.208270
  validation loss:		0.708553
  validation accuracy:		81.95 %
Epoch 1456 of 2000 took 0.101s
  training loss:		0.208098
  validation loss:		0.725999
  validation accuracy:		81.85 %
Epoch 1457 of 2000 took 0.101s
  training loss:		0.204435
  validation loss:		0.699420
  validation accuracy:		81.95 %
Epoch 1458 of 2000 took 0.101s
  training loss:		0.210314
  validation loss:		0.697787
  validation accuracy:		81.85 %
Epoch 1459 of 2000 took 0.101s
  training loss:		0.210971
  validation loss:		0.704186
  validation accuracy:		82.05 %
Epoch 1460 of 2000 took 0.101s
  training loss:		0.210116
  validation loss:		0.720607
  validation accuracy:		82.37 %
Epoch 1461 of 2000 took 0.101s
  training loss:		0.207129
  validation loss:		0.705357
  validation accuracy:		81.54 %
Epoch 1462 of 2000 took 0.101s
  training loss:		0.208852
  validation loss:		0.720628
  validation accuracy:		81.64 %
Epoch 1463 of 2000 took 0.102s
  training loss:		0.210531
  validation loss:		0.706567
  validation accuracy:		82.16 %
Epoch 1464 of 2000 took 0.101s
  training loss:		0.211661
  validation loss:		0.701839
  validation accuracy:		81.85 %
Epoch 1465 of 2000 took 0.101s
  training loss:		0.205837
  validation loss:		0.705590
  validation accuracy:		81.64 %
Epoch 1466 of 2000 took 0.101s
  training loss:		0.206376
  validation loss:		0.722996
  validation accuracy:		82.05 %
Epoch 1467 of 2000 took 0.101s
  training loss:		0.212842
  validation loss:		0.701840
  validation accuracy:		81.95 %
Epoch 1468 of 2000 took 0.101s
  training loss:		0.211249
  validation loss:		0.720750
  validation accuracy:		81.74 %
Epoch 1469 of 2000 took 0.101s
  training loss:		0.211719
  validation loss:		0.708521
  validation accuracy:		81.74 %
Epoch 1470 of 2000 took 0.101s
  training loss:		0.205810
  validation loss:		0.727413
  validation accuracy:		81.85 %
Epoch 1471 of 2000 took 0.101s
  training loss:		0.210891
  validation loss:		0.713106
  validation accuracy:		81.95 %
Epoch 1472 of 2000 took 0.101s
  training loss:		0.201365
  validation loss:		0.706230
  validation accuracy:		81.54 %
Epoch 1473 of 2000 took 0.101s
  training loss:		0.205833
  validation loss:		0.728702
  validation accuracy:		81.95 %
Epoch 1474 of 2000 took 0.101s
  training loss:		0.206752
  validation loss:		0.710754
  validation accuracy:		82.26 %
Epoch 1475 of 2000 took 0.101s
  training loss:		0.213382
  validation loss:		0.711972
  validation accuracy:		82.05 %
Epoch 1476 of 2000 took 0.101s
  training loss:		0.205335
  validation loss:		0.713764
  validation accuracy:		82.57 %
Epoch 1477 of 2000 took 0.101s
  training loss:		0.203132
  validation loss:		0.706326
  validation accuracy:		81.74 %
Epoch 1478 of 2000 took 0.101s
  training loss:		0.210533
  validation loss:		0.703996
  validation accuracy:		82.47 %
Epoch 1479 of 2000 took 0.101s
  training loss:		0.205012
  validation loss:		0.720710
  validation accuracy:		81.64 %
Epoch 1480 of 2000 took 0.101s
  training loss:		0.204914
  validation loss:		0.716881
  validation accuracy:		82.26 %
Epoch 1481 of 2000 took 0.101s
  training loss:		0.205952
  validation loss:		0.709237
  validation accuracy:		81.54 %
Epoch 1482 of 2000 took 0.101s
  training loss:		0.203974
  validation loss:		0.729022
  validation accuracy:		81.74 %
Epoch 1483 of 2000 took 0.101s
  training loss:		0.207653
  validation loss:		0.720776
  validation accuracy:		81.95 %
Epoch 1484 of 2000 took 0.101s
  training loss:		0.203219
  validation loss:		0.716330
  validation accuracy:		82.05 %
Epoch 1485 of 2000 took 0.102s
  training loss:		0.209023
  validation loss:		0.711089
  validation accuracy:		82.37 %
Epoch 1486 of 2000 took 0.101s
  training loss:		0.206458
  validation loss:		0.714399
  validation accuracy:		81.74 %
Epoch 1487 of 2000 took 0.101s
  training loss:		0.205495
  validation loss:		0.740324
  validation accuracy:		81.12 %
Epoch 1488 of 2000 took 0.101s
  training loss:		0.205861
  validation loss:		0.738992
  validation accuracy:		81.64 %
Epoch 1489 of 2000 took 0.101s
  training loss:		0.216416
  validation loss:		0.723779
  validation accuracy:		81.12 %
Epoch 1490 of 2000 took 0.101s
  training loss:		0.204904
  validation loss:		0.716557
  validation accuracy:		82.37 %
Epoch 1491 of 2000 took 0.101s
  training loss:		0.212153
  validation loss:		0.724817
  validation accuracy:		82.05 %
Epoch 1492 of 2000 took 0.101s
  training loss:		0.212718
  validation loss:		0.707077
  validation accuracy:		81.74 %
Epoch 1493 of 2000 took 0.102s
  training loss:		0.208991
  validation loss:		0.707291
  validation accuracy:		81.95 %
Epoch 1494 of 2000 took 0.101s
  training loss:		0.213124
  validation loss:		0.708601
  validation accuracy:		81.95 %
Epoch 1495 of 2000 took 0.101s
  training loss:		0.203932
  validation loss:		0.717027
  validation accuracy:		82.16 %
Epoch 1496 of 2000 took 0.101s
  training loss:		0.205300
  validation loss:		0.718396
  validation accuracy:		81.85 %
Epoch 1497 of 2000 took 0.101s
  training loss:		0.208322
  validation loss:		0.742672
  validation accuracy:		81.74 %
Epoch 1498 of 2000 took 0.102s
  training loss:		0.211119
  validation loss:		0.726487
  validation accuracy:		81.85 %
Epoch 1499 of 2000 took 0.104s
  training loss:		0.203500
  validation loss:		0.722391
  validation accuracy:		81.12 %
Epoch 1500 of 2000 took 0.103s
  training loss:		0.204528
  validation loss:		0.714358
  validation accuracy:		81.95 %
Epoch 1501 of 2000 took 0.101s
  training loss:		0.199887
  validation loss:		0.724662
  validation accuracy:		81.54 %
Epoch 1502 of 2000 took 0.104s
  training loss:		0.206622
  validation loss:		0.720124
  validation accuracy:		82.26 %
Epoch 1503 of 2000 took 0.105s
  training loss:		0.206182
  validation loss:		0.753587
  validation accuracy:		81.95 %
Epoch 1504 of 2000 took 0.105s
  training loss:		0.207499
  validation loss:		0.716834
  validation accuracy:		81.02 %
Epoch 1505 of 2000 took 0.104s
  training loss:		0.205361
  validation loss:		0.738007
  validation accuracy:		81.64 %
Epoch 1506 of 2000 took 0.104s
  training loss:		0.212363
  validation loss:		0.715845
  validation accuracy:		81.64 %
Epoch 1507 of 2000 took 0.103s
  training loss:		0.205297
  validation loss:		0.723213
  validation accuracy:		81.85 %
Epoch 1508 of 2000 took 0.101s
  training loss:		0.210273
  validation loss:		0.722382
  validation accuracy:		81.74 %
Epoch 1509 of 2000 took 0.101s
  training loss:		0.209552
  validation loss:		0.723968
  validation accuracy:		81.33 %
Epoch 1510 of 2000 took 0.101s
  training loss:		0.206571
  validation loss:		0.724281
  validation accuracy:		82.16 %
Epoch 1511 of 2000 took 0.102s
  training loss:		0.206078
  validation loss:		0.742100
  validation accuracy:		81.74 %
Epoch 1512 of 2000 took 0.101s
  training loss:		0.203328
  validation loss:		0.726731
  validation accuracy:		82.37 %
Epoch 1513 of 2000 took 0.101s
  training loss:		0.209786
  validation loss:		0.725714
  validation accuracy:		81.74 %
Epoch 1514 of 2000 took 0.101s
  training loss:		0.207386
  validation loss:		0.726634
  validation accuracy:		81.95 %
Epoch 1515 of 2000 took 0.101s
  training loss:		0.202845
  validation loss:		0.722552
  validation accuracy:		81.74 %
Epoch 1516 of 2000 took 0.101s
  training loss:		0.204806
  validation loss:		0.722662
  validation accuracy:		81.85 %
Epoch 1517 of 2000 took 0.101s
  training loss:		0.204319
  validation loss:		0.725491
  validation accuracy:		81.64 %
Epoch 1518 of 2000 took 0.101s
  training loss:		0.210884
  validation loss:		0.725028
  validation accuracy:		81.74 %
Epoch 1519 of 2000 took 0.101s
  training loss:		0.204469
  validation loss:		0.730583
  validation accuracy:		81.85 %
Epoch 1520 of 2000 took 0.101s
  training loss:		0.198057
  validation loss:		0.721766
  validation accuracy:		81.64 %
Epoch 1521 of 2000 took 0.101s
  training loss:		0.202871
  validation loss:		0.728033
  validation accuracy:		81.95 %
Epoch 1522 of 2000 took 0.101s
  training loss:		0.210836
  validation loss:		0.712781
  validation accuracy:		81.64 %
Epoch 1523 of 2000 took 0.102s
  training loss:		0.206972
  validation loss:		0.725769
  validation accuracy:		81.95 %
Epoch 1524 of 2000 took 0.101s
  training loss:		0.200822
  validation loss:		0.724542
  validation accuracy:		81.74 %
Epoch 1525 of 2000 took 0.101s
  training loss:		0.201311
  validation loss:		0.739309
  validation accuracy:		81.54 %
Epoch 1526 of 2000 took 0.101s
  training loss:		0.206598
  validation loss:		0.749051
  validation accuracy:		81.74 %
Epoch 1527 of 2000 took 0.101s
  training loss:		0.210872
  validation loss:		0.736211
  validation accuracy:		81.43 %
Epoch 1528 of 2000 took 0.101s
  training loss:		0.201334
  validation loss:		0.731274
  validation accuracy:		81.74 %
Epoch 1529 of 2000 took 0.101s
  training loss:		0.199543
  validation loss:		0.735720
  validation accuracy:		81.74 %
Epoch 1530 of 2000 took 0.101s
  training loss:		0.208921
  validation loss:		0.724904
  validation accuracy:		81.85 %
Epoch 1531 of 2000 took 0.101s
  training loss:		0.200690
  validation loss:		0.740276
  validation accuracy:		81.33 %
Epoch 1532 of 2000 took 0.101s
  training loss:		0.204099
  validation loss:		0.730090
  validation accuracy:		82.05 %
Epoch 1533 of 2000 took 0.101s
  training loss:		0.202808
  validation loss:		0.731799
  validation accuracy:		82.05 %
Epoch 1534 of 2000 took 0.101s
  training loss:		0.209503
  validation loss:		0.746613
  validation accuracy:		81.74 %
Epoch 1535 of 2000 took 0.101s
  training loss:		0.202258
  validation loss:		0.738437
  validation accuracy:		82.05 %
Epoch 1536 of 2000 took 0.101s
  training loss:		0.207787
  validation loss:		0.726641
  validation accuracy:		81.74 %
Epoch 1537 of 2000 took 0.101s
  training loss:		0.203645
  validation loss:		0.753018
  validation accuracy:		81.85 %
Epoch 1538 of 2000 took 0.101s
  training loss:		0.206163
  validation loss:		0.736818
  validation accuracy:		81.74 %
Epoch 1539 of 2000 took 0.101s
  training loss:		0.199314
  validation loss:		0.749786
  validation accuracy:		81.64 %
Epoch 1540 of 2000 took 0.101s
  training loss:		0.207126
  validation loss:		0.727412
  validation accuracy:		81.95 %
Epoch 1541 of 2000 took 0.101s
  training loss:		0.203709
  validation loss:		0.724003
  validation accuracy:		81.64 %
Epoch 1542 of 2000 took 0.101s
  training loss:		0.205782
  validation loss:		0.727661
  validation accuracy:		81.54 %
Epoch 1543 of 2000 took 0.101s
  training loss:		0.206642
  validation loss:		0.754592
  validation accuracy:		81.95 %
Epoch 1544 of 2000 took 0.101s
  training loss:		0.204904
  validation loss:		0.741488
  validation accuracy:		81.85 %
Epoch 1545 of 2000 took 0.101s
  training loss:		0.204714
  validation loss:		0.733119
  validation accuracy:		81.85 %
Epoch 1546 of 2000 took 0.101s
  training loss:		0.203959
  validation loss:		0.740560
  validation accuracy:		81.43 %
Epoch 1547 of 2000 took 0.102s
  training loss:		0.202893
  validation loss:		0.734158
  validation accuracy:		81.95 %
Epoch 1548 of 2000 took 0.101s
  training loss:		0.202403
  validation loss:		0.741001
  validation accuracy:		81.74 %
Epoch 1549 of 2000 took 0.101s
  training loss:		0.204183
  validation loss:		0.728952
  validation accuracy:		81.33 %
Epoch 1550 of 2000 took 0.101s
  training loss:		0.204149
  validation loss:		0.740060
  validation accuracy:		81.74 %
Epoch 1551 of 2000 took 0.102s
  training loss:		0.201041
  validation loss:		0.746861
  validation accuracy:		81.22 %
Epoch 1552 of 2000 took 0.102s
  training loss:		0.204941
  validation loss:		0.730148
  validation accuracy:		81.85 %
Epoch 1553 of 2000 took 0.102s
  training loss:		0.203296
  validation loss:		0.738255
  validation accuracy:		81.74 %
Epoch 1554 of 2000 took 0.101s
  training loss:		0.209970
  validation loss:		0.742677
  validation accuracy:		81.74 %
Epoch 1555 of 2000 took 0.105s
  training loss:		0.202179
  validation loss:		0.730417
  validation accuracy:		81.64 %
Epoch 1556 of 2000 took 0.107s
  training loss:		0.205277
  validation loss:		0.730185
  validation accuracy:		81.64 %
Epoch 1557 of 2000 took 0.107s
  training loss:		0.207476
  validation loss:		0.739442
  validation accuracy:		81.33 %
Epoch 1558 of 2000 took 0.101s
  training loss:		0.201827
  validation loss:		0.741016
  validation accuracy:		81.64 %
Epoch 1559 of 2000 took 0.101s
  training loss:		0.201762
  validation loss:		0.749684
  validation accuracy:		81.95 %
Epoch 1560 of 2000 took 0.101s
  training loss:		0.195059
  validation loss:		0.738261
  validation accuracy:		81.64 %
Epoch 1561 of 2000 took 0.101s
  training loss:		0.206193
  validation loss:		0.753790
  validation accuracy:		81.33 %
Epoch 1562 of 2000 took 0.101s
  training loss:		0.209016
  validation loss:		0.745279
  validation accuracy:		82.37 %
Epoch 1563 of 2000 took 0.101s
  training loss:		0.200601
  validation loss:		0.755120
  validation accuracy:		81.54 %
Epoch 1564 of 2000 took 0.101s
  training loss:		0.203776
  validation loss:		0.759411
  validation accuracy:		81.85 %
Epoch 1565 of 2000 took 0.101s
  training loss:		0.208967
  validation loss:		0.760022
  validation accuracy:		81.43 %
Epoch 1566 of 2000 took 0.101s
  training loss:		0.201567
  validation loss:		0.744244
  validation accuracy:		81.22 %
Epoch 1567 of 2000 took 0.101s
  training loss:		0.205103
  validation loss:		0.735211
  validation accuracy:		81.43 %
Epoch 1568 of 2000 took 0.101s
  training loss:		0.200671
  validation loss:		0.744691
  validation accuracy:		82.37 %
Epoch 1569 of 2000 took 0.101s
  training loss:		0.201606
  validation loss:		0.741626
  validation accuracy:		81.85 %
Epoch 1570 of 2000 took 0.101s
  training loss:		0.197165
  validation loss:		0.753569
  validation accuracy:		81.43 %
Epoch 1571 of 2000 took 0.101s
  training loss:		0.207660
  validation loss:		0.741765
  validation accuracy:		81.43 %
Epoch 1572 of 2000 took 0.101s
  training loss:		0.208035
  validation loss:		0.745453
  validation accuracy:		81.43 %
Epoch 1573 of 2000 took 0.101s
  training loss:		0.213832
  validation loss:		0.775672
  validation accuracy:		81.85 %
Epoch 1574 of 2000 took 0.101s
  training loss:		0.211044
  validation loss:		0.749923
  validation accuracy:		82.47 %
Epoch 1575 of 2000 took 0.101s
  training loss:		0.205523
  validation loss:		0.735397
  validation accuracy:		81.85 %
Epoch 1576 of 2000 took 0.101s
  training loss:		0.200118
  validation loss:		0.740308
  validation accuracy:		81.95 %
Epoch 1577 of 2000 took 0.101s
  training loss:		0.194483
  validation loss:		0.748703
  validation accuracy:		81.22 %
Epoch 1578 of 2000 took 0.101s
  training loss:		0.202081
  validation loss:		0.746940
  validation accuracy:		81.95 %
Epoch 1579 of 2000 took 0.101s
  training loss:		0.201520
  validation loss:		0.740663
  validation accuracy:		80.81 %
Epoch 1580 of 2000 took 0.101s
  training loss:		0.206589
  validation loss:		0.745380
  validation accuracy:		81.74 %
Epoch 1581 of 2000 took 0.101s
  training loss:		0.200791
  validation loss:		0.753832
  validation accuracy:		81.43 %
Epoch 1582 of 2000 took 0.102s
  training loss:		0.201757
  validation loss:		0.765684
  validation accuracy:		81.22 %
Epoch 1583 of 2000 took 0.101s
  training loss:		0.199180
  validation loss:		0.753041
  validation accuracy:		81.33 %
Epoch 1584 of 2000 took 0.101s
  training loss:		0.204297
  validation loss:		0.752093
  validation accuracy:		81.85 %
Epoch 1585 of 2000 took 0.101s
  training loss:		0.203427
  validation loss:		0.756975
  validation accuracy:		81.85 %
Epoch 1586 of 2000 took 0.101s
  training loss:		0.202297
  validation loss:		0.754368
  validation accuracy:		81.95 %
Epoch 1587 of 2000 took 0.101s
  training loss:		0.202193
  validation loss:		0.756292
  validation accuracy:		81.54 %
Epoch 1588 of 2000 took 0.101s
  training loss:		0.203890
  validation loss:		0.752873
  validation accuracy:		81.33 %
Epoch 1589 of 2000 took 0.101s
  training loss:		0.199999
  validation loss:		0.759028
  validation accuracy:		81.64 %
Epoch 1590 of 2000 took 0.101s
  training loss:		0.195090
  validation loss:		0.754713
  validation accuracy:		81.85 %
Epoch 1591 of 2000 took 0.101s
  training loss:		0.198948
  validation loss:		0.759884
  validation accuracy:		81.64 %
Epoch 1592 of 2000 took 0.101s
  training loss:		0.201228
  validation loss:		0.743450
  validation accuracy:		80.91 %
Epoch 1593 of 2000 took 0.101s
  training loss:		0.205418
  validation loss:		0.757118
  validation accuracy:		81.85 %
Epoch 1594 of 2000 took 0.101s
  training loss:		0.202761
  validation loss:		0.760147
  validation accuracy:		81.74 %
Epoch 1595 of 2000 took 0.101s
  training loss:		0.198610
  validation loss:		0.741938
  validation accuracy:		80.91 %
Epoch 1596 of 2000 took 0.101s
  training loss:		0.205732
  validation loss:		0.758326
  validation accuracy:		81.74 %
Epoch 1597 of 2000 took 0.101s
  training loss:		0.202473
  validation loss:		0.756920
  validation accuracy:		81.74 %
Epoch 1598 of 2000 took 0.101s
  training loss:		0.200939
  validation loss:		0.755886
  validation accuracy:		81.95 %
Epoch 1599 of 2000 took 0.101s
  training loss:		0.203496
  validation loss:		0.752732
  validation accuracy:		81.74 %
Epoch 1600 of 2000 took 0.101s
  training loss:		0.203393
  validation loss:		0.766832
  validation accuracy:		81.95 %
Epoch 1601 of 2000 took 0.101s
  training loss:		0.204589
  validation loss:		0.749745
  validation accuracy:		81.64 %
Epoch 1602 of 2000 took 0.101s
  training loss:		0.198347
  validation loss:		0.762139
  validation accuracy:		81.22 %
Epoch 1603 of 2000 took 0.101s
  training loss:		0.199188
  validation loss:		0.753818
  validation accuracy:		82.05 %
Epoch 1604 of 2000 took 0.101s
  training loss:		0.197573
  validation loss:		0.749342
  validation accuracy:		81.12 %
Epoch 1605 of 2000 took 0.101s
  training loss:		0.199756
  validation loss:		0.754077
  validation accuracy:		81.02 %
Epoch 1606 of 2000 took 0.101s
  training loss:		0.202151
  validation loss:		0.748077
  validation accuracy:		81.74 %
Epoch 1607 of 2000 took 0.101s
  training loss:		0.198357
  validation loss:		0.766981
  validation accuracy:		82.05 %
Epoch 1608 of 2000 took 0.101s
  training loss:		0.210071
  validation loss:		0.779094
  validation accuracy:		81.74 %
Epoch 1609 of 2000 took 0.101s
  training loss:		0.210482
  validation loss:		0.750489
  validation accuracy:		81.64 %
Epoch 1610 of 2000 took 0.101s
  training loss:		0.207858
  validation loss:		0.747096
  validation accuracy:		81.22 %
Epoch 1611 of 2000 took 0.101s
  training loss:		0.203674
  validation loss:		0.749883
  validation accuracy:		81.74 %
Epoch 1612 of 2000 took 0.102s
  training loss:		0.198450
  validation loss:		0.762455
  validation accuracy:		81.85 %
Epoch 1613 of 2000 took 0.101s
  training loss:		0.199608
  validation loss:		0.743613
  validation accuracy:		81.85 %
Epoch 1614 of 2000 took 0.101s
  training loss:		0.207262
  validation loss:		0.764219
  validation accuracy:		81.33 %
Epoch 1615 of 2000 took 0.101s
  training loss:		0.203300
  validation loss:		0.742219
  validation accuracy:		81.64 %
Epoch 1616 of 2000 took 0.101s
  training loss:		0.202904
  validation loss:		0.754721
  validation accuracy:		82.05 %
Epoch 1617 of 2000 took 0.101s
  training loss:		0.203652
  validation loss:		0.749053
  validation accuracy:		81.43 %
Epoch 1618 of 2000 took 0.101s
  training loss:		0.202782
  validation loss:		0.750870
  validation accuracy:		81.43 %
Epoch 1619 of 2000 took 0.101s
  training loss:		0.209316
  validation loss:		0.767652
  validation accuracy:		81.54 %
Epoch 1620 of 2000 took 0.101s
  training loss:		0.201807
  validation loss:		0.764336
  validation accuracy:		81.85 %
Epoch 1621 of 2000 took 0.101s
  training loss:		0.200710
  validation loss:		0.756932
  validation accuracy:		81.95 %
Epoch 1622 of 2000 took 0.101s
  training loss:		0.198858
  validation loss:		0.763339
  validation accuracy:		82.05 %
Epoch 1623 of 2000 took 0.101s
  training loss:		0.200760
  validation loss:		0.762177
  validation accuracy:		81.64 %
Epoch 1624 of 2000 took 0.101s
  training loss:		0.200099
  validation loss:		0.775965
  validation accuracy:		81.22 %
Epoch 1625 of 2000 took 0.102s
  training loss:		0.205850
  validation loss:		0.746449
  validation accuracy:		81.64 %
Epoch 1626 of 2000 took 0.102s
  training loss:		0.204917
  validation loss:		0.765863
  validation accuracy:		81.54 %
Epoch 1627 of 2000 took 0.101s
  training loss:		0.197622
  validation loss:		0.771986
  validation accuracy:		82.05 %
Epoch 1628 of 2000 took 0.101s
  training loss:		0.204694
  validation loss:		0.754382
  validation accuracy:		81.22 %
Epoch 1629 of 2000 took 0.101s
  training loss:		0.200152
  validation loss:		0.753335
  validation accuracy:		81.64 %
Epoch 1630 of 2000 took 0.101s
  training loss:		0.201273
  validation loss:		0.754227
  validation accuracy:		81.95 %
Epoch 1631 of 2000 took 0.101s
  training loss:		0.196441
  validation loss:		0.768581
  validation accuracy:		82.05 %
Epoch 1632 of 2000 took 0.101s
  training loss:		0.197883
  validation loss:		0.756233
  validation accuracy:		81.95 %
Epoch 1633 of 2000 took 0.101s
  training loss:		0.198929
  validation loss:		0.788412
  validation accuracy:		81.43 %
Epoch 1634 of 2000 took 0.101s
  training loss:		0.200258
  validation loss:		0.751654
  validation accuracy:		80.91 %
Epoch 1635 of 2000 took 0.101s
  training loss:		0.200406
  validation loss:		0.759791
  validation accuracy:		81.22 %
Epoch 1636 of 2000 took 0.101s
  training loss:		0.191251
  validation loss:		0.772829
  validation accuracy:		81.33 %
Epoch 1637 of 2000 took 0.101s
  training loss:		0.200754
  validation loss:		0.757784
  validation accuracy:		81.12 %
Epoch 1638 of 2000 took 0.101s
  training loss:		0.198520
  validation loss:		0.754682
  validation accuracy:		81.33 %
Epoch 1639 of 2000 took 0.101s
  training loss:		0.201713
  validation loss:		0.759673
  validation accuracy:		82.37 %
Epoch 1640 of 2000 took 0.101s
  training loss:		0.204941
  validation loss:		0.774918
  validation accuracy:		81.64 %
Epoch 1641 of 2000 took 0.101s
  training loss:		0.200669
  validation loss:		0.760749
  validation accuracy:		81.64 %
Epoch 1642 of 2000 took 0.102s
  training loss:		0.197356
  validation loss:		0.755288
  validation accuracy:		81.54 %
Epoch 1643 of 2000 took 0.101s
  training loss:		0.200943
  validation loss:		0.767905
  validation accuracy:		81.43 %
Epoch 1644 of 2000 took 0.101s
  training loss:		0.198743
  validation loss:		0.764837
  validation accuracy:		81.54 %
Epoch 1645 of 2000 took 0.101s
  training loss:		0.197571
  validation loss:		0.775203
  validation accuracy:		81.74 %
Epoch 1646 of 2000 took 0.101s
  training loss:		0.205841
  validation loss:		0.756608
  validation accuracy:		80.60 %
Epoch 1647 of 2000 took 0.101s
  training loss:		0.199607
  validation loss:		0.775962
  validation accuracy:		81.74 %
Epoch 1648 of 2000 took 0.101s
  training loss:		0.203019
  validation loss:		0.784315
  validation accuracy:		81.64 %
Epoch 1649 of 2000 took 0.101s
  training loss:		0.206675
  validation loss:		0.778332
  validation accuracy:		80.71 %
Epoch 1650 of 2000 took 0.101s
  training loss:		0.206041
  validation loss:		0.768067
  validation accuracy:		81.02 %
Epoch 1651 of 2000 took 0.101s
  training loss:		0.199529
  validation loss:		0.755845
  validation accuracy:		81.33 %
Epoch 1652 of 2000 took 0.101s
  training loss:		0.199083
  validation loss:		0.770156
  validation accuracy:		81.54 %
Epoch 1653 of 2000 took 0.101s
  training loss:		0.197939
  validation loss:		0.756560
  validation accuracy:		81.43 %
Epoch 1654 of 2000 took 0.101s
  training loss:		0.206873
  validation loss:		0.768213
  validation accuracy:		81.33 %
Epoch 1655 of 2000 took 0.101s
  training loss:		0.206648
  validation loss:		0.759965
  validation accuracy:		81.64 %
Epoch 1656 of 2000 took 0.101s
  training loss:		0.199656
  validation loss:		0.761558
  validation accuracy:		81.33 %
Epoch 1657 of 2000 took 0.101s
  training loss:		0.199706
  validation loss:		0.774326
  validation accuracy:		81.54 %
Epoch 1658 of 2000 took 0.101s
  training loss:		0.201341
  validation loss:		0.785532
  validation accuracy:		81.64 %
Epoch 1659 of 2000 took 0.101s
  training loss:		0.200128
  validation loss:		0.760626
  validation accuracy:		82.05 %
Epoch 1660 of 2000 took 0.102s
  training loss:		0.192848
  validation loss:		0.757413
  validation accuracy:		80.81 %
Epoch 1661 of 2000 took 0.101s
  training loss:		0.202529
  validation loss:		0.773739
  validation accuracy:		81.22 %
Epoch 1662 of 2000 took 0.101s
  training loss:		0.197196
  validation loss:		0.787998
  validation accuracy:		81.54 %
Epoch 1663 of 2000 took 0.101s
  training loss:		0.204165
  validation loss:		0.768466
  validation accuracy:		81.95 %
Epoch 1664 of 2000 took 0.101s
  training loss:		0.199096
  validation loss:		0.757587
  validation accuracy:		81.22 %
Epoch 1665 of 2000 took 0.101s
  training loss:		0.193202
  validation loss:		0.755159
  validation accuracy:		81.64 %
Epoch 1666 of 2000 took 0.101s
  training loss:		0.197527
  validation loss:		0.807818
  validation accuracy:		81.33 %
Epoch 1667 of 2000 took 0.101s
  training loss:		0.199491
  validation loss:		0.778740
  validation accuracy:		81.74 %
Epoch 1668 of 2000 took 0.101s
  training loss:		0.201940
  validation loss:		0.773855
  validation accuracy:		81.43 %
Epoch 1669 of 2000 took 0.101s
  training loss:		0.201494
  validation loss:		0.777762
  validation accuracy:		81.64 %
Epoch 1670 of 2000 took 0.101s
  training loss:		0.194173
  validation loss:		0.762076
  validation accuracy:		81.54 %
Epoch 1671 of 2000 took 0.101s
  training loss:		0.199795
  validation loss:		0.771029
  validation accuracy:		81.33 %
Epoch 1672 of 2000 took 0.102s
  training loss:		0.201614
  validation loss:		0.772584
  validation accuracy:		81.74 %
Epoch 1673 of 2000 took 0.101s
  training loss:		0.195535
  validation loss:		0.777356
  validation accuracy:		81.64 %
Epoch 1674 of 2000 took 0.101s
  training loss:		0.198632
  validation loss:		0.774628
  validation accuracy:		82.16 %
Epoch 1675 of 2000 took 0.103s
  training loss:		0.200212
  validation loss:		0.793231
  validation accuracy:		81.54 %
Epoch 1676 of 2000 took 0.101s
  training loss:		0.196489
  validation loss:		0.768563
  validation accuracy:		82.05 %
Epoch 1677 of 2000 took 0.101s
  training loss:		0.197408
  validation loss:		0.768513
  validation accuracy:		82.16 %
Epoch 1678 of 2000 took 0.101s
  training loss:		0.206094
  validation loss:		0.769196
  validation accuracy:		81.43 %
Epoch 1679 of 2000 took 0.101s
  training loss:		0.200630
  validation loss:		0.763292
  validation accuracy:		81.12 %
Epoch 1680 of 2000 took 0.101s
  training loss:		0.198171
  validation loss:		0.783340
  validation accuracy:		81.33 %
Epoch 1681 of 2000 took 0.101s
  training loss:		0.201991
  validation loss:		0.788585
  validation accuracy:		81.43 %
Epoch 1682 of 2000 took 0.101s
  training loss:		0.194963
  validation loss:		0.772252
  validation accuracy:		81.43 %
Epoch 1683 of 2000 took 0.101s
  training loss:		0.201498
  validation loss:		0.772576
  validation accuracy:		81.33 %
Epoch 1684 of 2000 took 0.101s
  training loss:		0.198798
  validation loss:		0.773223
  validation accuracy:		81.95 %
Epoch 1685 of 2000 took 0.101s
  training loss:		0.199347
  validation loss:		0.796194
  validation accuracy:		81.64 %
Epoch 1686 of 2000 took 0.101s
  training loss:		0.200139
  validation loss:		0.780600
  validation accuracy:		81.64 %
Epoch 1687 of 2000 took 0.101s
  training loss:		0.199775
  validation loss:		0.770741
  validation accuracy:		81.64 %
Epoch 1688 of 2000 took 0.101s
  training loss:		0.203646
  validation loss:		0.773650
  validation accuracy:		80.91 %
Epoch 1689 of 2000 took 0.101s
  training loss:		0.198188
  validation loss:		0.784833
  validation accuracy:		81.85 %
Epoch 1690 of 2000 took 0.101s
  training loss:		0.193740
  validation loss:		0.778789
  validation accuracy:		81.85 %
Epoch 1691 of 2000 took 0.101s
  training loss:		0.199250
  validation loss:		0.794936
  validation accuracy:		81.64 %
Epoch 1692 of 2000 took 0.101s
  training loss:		0.194732
  validation loss:		0.779833
  validation accuracy:		81.54 %
Epoch 1693 of 2000 took 0.101s
  training loss:		0.198416
  validation loss:		0.771998
  validation accuracy:		81.33 %
Epoch 1694 of 2000 took 0.101s
  training loss:		0.193805
  validation loss:		0.792309
  validation accuracy:		80.91 %
Epoch 1695 of 2000 took 0.101s
  training loss:		0.196970
  validation loss:		0.791504
  validation accuracy:		81.12 %
Epoch 1696 of 2000 took 0.101s
  training loss:		0.199558
  validation loss:		0.780183
  validation accuracy:		80.91 %
Epoch 1697 of 2000 took 0.101s
  training loss:		0.192659
  validation loss:		0.783695
  validation accuracy:		81.54 %
Epoch 1698 of 2000 took 0.101s
  training loss:		0.197144
  validation loss:		0.778265
  validation accuracy:		81.33 %
Epoch 1699 of 2000 took 0.101s
  training loss:		0.201588
  validation loss:		0.791144
  validation accuracy:		81.22 %
Epoch 1700 of 2000 took 0.101s
  training loss:		0.202001
  validation loss:		0.770203
  validation accuracy:		81.22 %
Epoch 1701 of 2000 took 0.101s
  training loss:		0.196754
  validation loss:		0.791494
  validation accuracy:		81.85 %
Epoch 1702 of 2000 took 0.102s
  training loss:		0.193278
  validation loss:		0.778539
  validation accuracy:		81.33 %
Epoch 1703 of 2000 took 0.101s
  training loss:		0.206594
  validation loss:		0.781086
  validation accuracy:		80.81 %
Epoch 1704 of 2000 took 0.104s
  training loss:		0.199340
  validation loss:		0.786801
  validation accuracy:		81.33 %
Epoch 1705 of 2000 took 0.101s
  training loss:		0.201342
  validation loss:		0.777388
  validation accuracy:		81.02 %
Epoch 1706 of 2000 took 0.101s
  training loss:		0.192146
  validation loss:		0.765995
  validation accuracy:		81.12 %
Epoch 1707 of 2000 took 0.101s
  training loss:		0.197509
  validation loss:		0.774209
  validation accuracy:		81.95 %
Epoch 1708 of 2000 took 0.101s
  training loss:		0.196166
  validation loss:		0.791198
  validation accuracy:		81.43 %
Epoch 1709 of 2000 took 0.101s
  training loss:		0.192368
  validation loss:		0.790357
  validation accuracy:		82.16 %
Epoch 1710 of 2000 took 0.101s
  training loss:		0.196617
  validation loss:		0.783708
  validation accuracy:		81.85 %
Epoch 1711 of 2000 took 0.101s
  training loss:		0.200112
  validation loss:		0.769060
  validation accuracy:		81.85 %
Epoch 1712 of 2000 took 0.101s
  training loss:		0.199870
  validation loss:		0.785931
  validation accuracy:		81.43 %
Epoch 1713 of 2000 took 0.101s
  training loss:		0.198977
  validation loss:		0.787068
  validation accuracy:		81.02 %
Epoch 1714 of 2000 took 0.101s
  training loss:		0.207074
  validation loss:		0.784307
  validation accuracy:		81.74 %
Epoch 1715 of 2000 took 0.101s
  training loss:		0.193165
  validation loss:		0.798008
  validation accuracy:		81.74 %
Epoch 1716 of 2000 took 0.101s
  training loss:		0.189738
  validation loss:		0.782544
  validation accuracy:		81.95 %
Epoch 1717 of 2000 took 0.101s
  training loss:		0.194427
  validation loss:		0.775894
  validation accuracy:		81.54 %
Epoch 1718 of 2000 took 0.101s
  training loss:		0.191503
  validation loss:		0.782878
  validation accuracy:		81.43 %
Epoch 1719 of 2000 took 0.101s
  training loss:		0.198976
  validation loss:		0.784718
  validation accuracy:		81.22 %
Epoch 1720 of 2000 took 0.101s
  training loss:		0.198915
  validation loss:		0.770875
  validation accuracy:		81.54 %
Epoch 1721 of 2000 took 0.101s
  training loss:		0.202953
  validation loss:		0.793981
  validation accuracy:		80.60 %
Epoch 1722 of 2000 took 0.101s
  training loss:		0.193611
  validation loss:		0.803028
  validation accuracy:		81.54 %
Epoch 1723 of 2000 took 0.101s
  training loss:		0.195772
  validation loss:		0.781000
  validation accuracy:		80.60 %
Epoch 1724 of 2000 took 0.101s
  training loss:		0.198016
  validation loss:		0.806581
  validation accuracy:		81.12 %
Epoch 1725 of 2000 took 0.101s
  training loss:		0.192751
  validation loss:		0.781532
  validation accuracy:		81.43 %
Epoch 1726 of 2000 took 0.101s
  training loss:		0.197779
  validation loss:		0.783917
  validation accuracy:		81.64 %
Epoch 1727 of 2000 took 0.101s
  training loss:		0.189269
  validation loss:		0.792990
  validation accuracy:		81.85 %
Epoch 1728 of 2000 took 0.101s
  training loss:		0.196379
  validation loss:		0.803400
  validation accuracy:		81.22 %
Epoch 1729 of 2000 took 0.101s
  training loss:		0.197738
  validation loss:		0.791879
  validation accuracy:		81.54 %
Epoch 1730 of 2000 took 0.101s
  training loss:		0.198149
  validation loss:		0.805887
  validation accuracy:		81.12 %
Epoch 1731 of 2000 took 0.102s
  training loss:		0.193857
  validation loss:		0.793549
  validation accuracy:		81.33 %
Epoch 1732 of 2000 took 0.101s
  training loss:		0.190729
  validation loss:		0.796255
  validation accuracy:		81.12 %
Epoch 1733 of 2000 took 0.101s
  training loss:		0.197606
  validation loss:		0.795534
  validation accuracy:		81.22 %
Epoch 1734 of 2000 took 0.101s
  training loss:		0.196498
  validation loss:		0.784579
  validation accuracy:		81.43 %
Epoch 1735 of 2000 took 0.101s
  training loss:		0.192725
  validation loss:		0.788350
  validation accuracy:		80.71 %
Epoch 1736 of 2000 took 0.101s
  training loss:		0.199632
  validation loss:		0.808219
  validation accuracy:		81.64 %
Epoch 1737 of 2000 took 0.101s
  training loss:		0.202267
  validation loss:		0.794168
  validation accuracy:		81.02 %
Epoch 1738 of 2000 took 0.101s
  training loss:		0.205747
  validation loss:		0.779745
  validation accuracy:		81.02 %
Epoch 1739 of 2000 took 0.101s
  training loss:		0.200900
  validation loss:		0.792674
  validation accuracy:		81.02 %
Epoch 1740 of 2000 took 0.101s
  training loss:		0.192287
  validation loss:		0.782204
  validation accuracy:		81.33 %
Epoch 1741 of 2000 took 0.101s
  training loss:		0.198011
  validation loss:		0.796942
  validation accuracy:		81.74 %
Epoch 1742 of 2000 took 0.101s
  training loss:		0.201615
  validation loss:		0.782397
  validation accuracy:		81.12 %
Epoch 1743 of 2000 took 0.101s
  training loss:		0.200016
  validation loss:		0.788796
  validation accuracy:		80.81 %
Epoch 1744 of 2000 took 0.101s
  training loss:		0.197286
  validation loss:		0.793407
  validation accuracy:		80.81 %
Epoch 1745 of 2000 took 0.101s
  training loss:		0.193156
  validation loss:		0.796084
  validation accuracy:		81.12 %
Epoch 1746 of 2000 took 0.101s
  training loss:		0.199945
  validation loss:		0.787799
  validation accuracy:		81.54 %
Epoch 1747 of 2000 took 0.101s
  training loss:		0.202140
  validation loss:		0.789615
  validation accuracy:		80.91 %
Epoch 1748 of 2000 took 0.101s
  training loss:		0.194954
  validation loss:		0.786754
  validation accuracy:		81.43 %
Epoch 1749 of 2000 took 0.101s
  training loss:		0.195319
  validation loss:		0.789030
  validation accuracy:		81.33 %
Epoch 1750 of 2000 took 0.101s
  training loss:		0.203425
  validation loss:		0.800692
  validation accuracy:		81.22 %
Epoch 1751 of 2000 took 0.101s
  training loss:		0.199086
  validation loss:		0.798509
  validation accuracy:		81.33 %
Epoch 1752 of 2000 took 0.101s
  training loss:		0.193403
  validation loss:		0.816023
  validation accuracy:		81.54 %
Epoch 1753 of 2000 took 0.101s
  training loss:		0.191637
  validation loss:		0.796750
  validation accuracy:		81.22 %
Epoch 1754 of 2000 took 0.101s
  training loss:		0.197715
  validation loss:		0.802016
  validation accuracy:		81.64 %
Epoch 1755 of 2000 took 0.101s
  training loss:		0.193213
  validation loss:		0.799944
  validation accuracy:		81.43 %
Epoch 1756 of 2000 took 0.101s
  training loss:		0.197177
  validation loss:		0.822229
  validation accuracy:		80.91 %
Epoch 1757 of 2000 took 0.101s
  training loss:		0.193816
  validation loss:		0.792441
  validation accuracy:		81.43 %
Epoch 1758 of 2000 took 0.101s
  training loss:		0.194600
  validation loss:		0.787439
  validation accuracy:		81.43 %
Epoch 1759 of 2000 took 0.101s
  training loss:		0.194465
  validation loss:		0.810367
  validation accuracy:		81.33 %
Epoch 1760 of 2000 took 0.101s
  training loss:		0.196330
  validation loss:		0.805253
  validation accuracy:		81.02 %
Epoch 1761 of 2000 took 0.102s
  training loss:		0.204122
  validation loss:		0.818930
  validation accuracy:		81.22 %
Epoch 1762 of 2000 took 0.101s
  training loss:		0.195609
  validation loss:		0.789641
  validation accuracy:		81.22 %
Epoch 1763 of 2000 took 0.101s
  training loss:		0.192519
  validation loss:		0.793505
  validation accuracy:		80.81 %
Epoch 1764 of 2000 took 0.101s
  training loss:		0.195808
  validation loss:		0.800580
  validation accuracy:		81.64 %
Epoch 1765 of 2000 took 0.101s
  training loss:		0.191812
  validation loss:		0.791065
  validation accuracy:		81.43 %
Epoch 1766 of 2000 took 0.101s
  training loss:		0.200677
  validation loss:		0.792631
  validation accuracy:		82.05 %
Epoch 1767 of 2000 took 0.101s
  training loss:		0.193100
  validation loss:		0.811678
  validation accuracy:		82.26 %
Epoch 1768 of 2000 took 0.101s
  training loss:		0.199234
  validation loss:		0.787029
  validation accuracy:		81.22 %
Epoch 1769 of 2000 took 0.101s
  training loss:		0.200150
  validation loss:		0.796355
  validation accuracy:		81.33 %
Epoch 1770 of 2000 took 0.101s
  training loss:		0.190138
  validation loss:		0.807045
  validation accuracy:		81.54 %
Epoch 1771 of 2000 took 0.101s
  training loss:		0.189594
  validation loss:		0.800914
  validation accuracy:		81.43 %
Epoch 1772 of 2000 took 0.101s
  training loss:		0.199056
  validation loss:		0.808457
  validation accuracy:		81.54 %
Epoch 1773 of 2000 took 0.101s
  training loss:		0.198725
  validation loss:		0.813895
  validation accuracy:		81.74 %
Epoch 1774 of 2000 took 0.101s
  training loss:		0.197520
  validation loss:		0.798183
  validation accuracy:		81.85 %
Epoch 1775 of 2000 took 0.101s
  training loss:		0.200475
  validation loss:		0.812137
  validation accuracy:		80.81 %
Epoch 1776 of 2000 took 0.101s
  training loss:		0.198771
  validation loss:		0.816917
  validation accuracy:		81.54 %
Epoch 1777 of 2000 took 0.101s
  training loss:		0.194022
  validation loss:		0.798794
  validation accuracy:		81.22 %
Epoch 1778 of 2000 took 0.101s
  training loss:		0.190223
  validation loss:		0.792542
  validation accuracy:		81.54 %
Epoch 1779 of 2000 took 0.101s
  training loss:		0.192749
  validation loss:		0.798955
  validation accuracy:		81.43 %
Epoch 1780 of 2000 took 0.101s
  training loss:		0.190113
  validation loss:		0.800916
  validation accuracy:		81.33 %
Epoch 1781 of 2000 took 0.101s
  training loss:		0.196889
  validation loss:		0.812407
  validation accuracy:		81.54 %
Epoch 1782 of 2000 took 0.101s
  training loss:		0.196104
  validation loss:		0.784121
  validation accuracy:		81.12 %
Epoch 1783 of 2000 took 0.101s
  training loss:		0.194317
  validation loss:		0.794730
  validation accuracy:		81.12 %
Epoch 1784 of 2000 took 0.101s
  training loss:		0.189514
  validation loss:		0.802552
  validation accuracy:		81.74 %
Epoch 1785 of 2000 took 0.101s
  training loss:		0.198945
  validation loss:		0.801070
  validation accuracy:		81.54 %
Epoch 1786 of 2000 took 0.102s
  training loss:		0.200296
  validation loss:		0.805242
  validation accuracy:		81.43 %
Epoch 1787 of 2000 took 0.101s
  training loss:		0.190606
  validation loss:		0.799512
  validation accuracy:		81.74 %
Epoch 1788 of 2000 took 0.101s
  training loss:		0.189732
  validation loss:		0.794374
  validation accuracy:		81.54 %
Epoch 1789 of 2000 took 0.101s
  training loss:		0.195905
  validation loss:		0.805968
  validation accuracy:		81.85 %
Epoch 1790 of 2000 took 0.101s
  training loss:		0.195475
  validation loss:		0.801678
  validation accuracy:		80.91 %
Epoch 1791 of 2000 took 0.102s
  training loss:		0.194306
  validation loss:		0.819492
  validation accuracy:		81.22 %
Epoch 1792 of 2000 took 0.101s
  training loss:		0.192181
  validation loss:		0.797428
  validation accuracy:		81.22 %
Epoch 1793 of 2000 took 0.101s
  training loss:		0.194944
  validation loss:		0.803151
  validation accuracy:		81.22 %
Epoch 1794 of 2000 took 0.101s
  training loss:		0.197322
  validation loss:		0.811435
  validation accuracy:		81.12 %
Epoch 1795 of 2000 took 0.101s
  training loss:		0.195129
  validation loss:		0.809387
  validation accuracy:		81.02 %
Epoch 1796 of 2000 took 0.101s
  training loss:		0.196591
  validation loss:		0.803497
  validation accuracy:		81.85 %
Epoch 1797 of 2000 took 0.101s
  training loss:		0.190862
  validation loss:		0.808655
  validation accuracy:		81.64 %
Epoch 1798 of 2000 took 0.101s
  training loss:		0.191616
  validation loss:		0.806114
  validation accuracy:		81.54 %
Epoch 1799 of 2000 took 0.101s
  training loss:		0.190390
  validation loss:		0.803888
  validation accuracy:		81.02 %
Epoch 1800 of 2000 took 0.101s
  training loss:		0.191391
  validation loss:		0.809453
  validation accuracy:		81.33 %
Epoch 1801 of 2000 took 0.101s
  training loss:		0.199414
  validation loss:		0.816681
  validation accuracy:		81.12 %
Epoch 1802 of 2000 took 0.101s
  training loss:		0.191540
  validation loss:		0.808028
  validation accuracy:		81.22 %
Epoch 1803 of 2000 took 0.101s
  training loss:		0.192840
  validation loss:		0.802587
  validation accuracy:		81.12 %
Epoch 1804 of 2000 took 0.101s
  training loss:		0.200585
  validation loss:		0.800248
  validation accuracy:		80.50 %
Epoch 1805 of 2000 took 0.101s
  training loss:		0.197580
  validation loss:		0.805466
  validation accuracy:		81.12 %
Epoch 1806 of 2000 took 0.101s
  training loss:		0.194587
  validation loss:		0.827418
  validation accuracy:		81.54 %
Epoch 1807 of 2000 took 0.101s
  training loss:		0.200245
  validation loss:		0.821137
  validation accuracy:		81.12 %
Epoch 1808 of 2000 took 0.101s
  training loss:		0.192441
  validation loss:		0.802695
  validation accuracy:		81.74 %
Epoch 1809 of 2000 took 0.101s
  training loss:		0.190269
  validation loss:		0.803459
  validation accuracy:		80.71 %
Epoch 1810 of 2000 took 0.101s
  training loss:		0.195313
  validation loss:		0.801612
  validation accuracy:		81.43 %
Epoch 1811 of 2000 took 0.101s
  training loss:		0.189323
  validation loss:		0.813642
  validation accuracy:		81.33 %
Epoch 1812 of 2000 took 0.101s
  training loss:		0.188879
  validation loss:		0.810866
  validation accuracy:		81.22 %
Epoch 1813 of 2000 took 0.101s
  training loss:		0.191427
  validation loss:		0.811918
  validation accuracy:		81.54 %
Epoch 1814 of 2000 took 0.101s
  training loss:		0.200251
  validation loss:		0.826712
  validation accuracy:		80.91 %
Epoch 1815 of 2000 took 0.101s
  training loss:		0.191121
  validation loss:		0.831676
  validation accuracy:		81.33 %
Epoch 1816 of 2000 took 0.101s
  training loss:		0.189883
  validation loss:		0.812739
  validation accuracy:		81.43 %
Epoch 1817 of 2000 took 0.101s
  training loss:		0.193607
  validation loss:		0.807250
  validation accuracy:		81.33 %
Epoch 1818 of 2000 took 0.101s
  training loss:		0.187864
  validation loss:		0.800087
  validation accuracy:		80.71 %
Epoch 1819 of 2000 took 0.101s
  training loss:		0.193092
  validation loss:		0.800225
  validation accuracy:		81.12 %
Epoch 1820 of 2000 took 0.101s
  training loss:		0.208985
  validation loss:		0.796558
  validation accuracy:		81.22 %
Epoch 1821 of 2000 took 0.102s
  training loss:		0.192064
  validation loss:		0.815721
  validation accuracy:		80.50 %
Epoch 1822 of 2000 took 0.101s
  training loss:		0.200940
  validation loss:		0.819376
  validation accuracy:		81.64 %
Epoch 1823 of 2000 took 0.101s
  training loss:		0.195451
  validation loss:		0.815575
  validation accuracy:		80.91 %
Epoch 1824 of 2000 took 0.101s
  training loss:		0.195095
  validation loss:		0.826352
  validation accuracy:		80.60 %
Epoch 1825 of 2000 took 0.101s
  training loss:		0.194350
  validation loss:		0.805509
  validation accuracy:		81.12 %
Epoch 1826 of 2000 took 0.101s
  training loss:		0.189463
  validation loss:		0.814774
  validation accuracy:		81.64 %
Epoch 1827 of 2000 took 0.101s
  training loss:		0.195867
  validation loss:		0.800923
  validation accuracy:		81.02 %
Epoch 1828 of 2000 took 0.101s
  training loss:		0.202117
  validation loss:		0.809199
  validation accuracy:		81.74 %
Epoch 1829 of 2000 took 0.101s
  training loss:		0.198118
  validation loss:		0.803725
  validation accuracy:		81.02 %
Epoch 1830 of 2000 took 0.101s
  training loss:		0.192585
  validation loss:		0.801078
  validation accuracy:		81.02 %
Epoch 1831 of 2000 took 0.101s
  training loss:		0.195250
  validation loss:		0.804129
  validation accuracy:		80.91 %
Epoch 1832 of 2000 took 0.101s
  training loss:		0.188999
  validation loss:		0.822799
  validation accuracy:		81.22 %
Epoch 1833 of 2000 took 0.101s
  training loss:		0.192818
  validation loss:		0.822460
  validation accuracy:		81.43 %
Epoch 1834 of 2000 took 0.101s
  training loss:		0.194261
  validation loss:		0.813234
  validation accuracy:		81.12 %
Epoch 1835 of 2000 took 0.101s
  training loss:		0.191357
  validation loss:		0.819526
  validation accuracy:		81.22 %
Epoch 1836 of 2000 took 0.101s
  training loss:		0.197292
  validation loss:		0.840788
  validation accuracy:		81.54 %
Epoch 1837 of 2000 took 0.101s
  training loss:		0.198026
  validation loss:		0.810036
  validation accuracy:		81.02 %
Epoch 1838 of 2000 took 0.101s
  training loss:		0.195988
  validation loss:		0.805404
  validation accuracy:		80.71 %
Epoch 1839 of 2000 took 0.101s
  training loss:		0.194491
  validation loss:		0.807129
  validation accuracy:		80.91 %
Epoch 1840 of 2000 took 0.101s
  training loss:		0.191481
  validation loss:		0.819904
  validation accuracy:		81.43 %
Epoch 1841 of 2000 took 0.101s
  training loss:		0.190205
  validation loss:		0.816369
  validation accuracy:		81.74 %
Epoch 1842 of 2000 took 0.101s
  training loss:		0.194385
  validation loss:		0.804242
  validation accuracy:		80.91 %
Epoch 1843 of 2000 took 0.101s
  training loss:		0.197831
  validation loss:		0.810923
  validation accuracy:		81.12 %
Epoch 1844 of 2000 took 0.102s
  training loss:		0.199617
  validation loss:		0.801109
  validation accuracy:		81.74 %
Epoch 1845 of 2000 took 0.101s
  training loss:		0.189796
  validation loss:		0.819549
  validation accuracy:		81.02 %
Epoch 1846 of 2000 took 0.101s
  training loss:		0.193041
  validation loss:		0.822257
  validation accuracy:		80.81 %
Epoch 1847 of 2000 took 0.101s
  training loss:		0.194388
  validation loss:		0.816069
  validation accuracy:		81.22 %
Epoch 1848 of 2000 took 0.101s
  training loss:		0.201738
  validation loss:		0.813492
  validation accuracy:		81.12 %
Epoch 1849 of 2000 took 0.101s
  training loss:		0.189679
  validation loss:		0.817586
  validation accuracy:		80.91 %
Epoch 1850 of 2000 took 0.101s
  training loss:		0.191394
  validation loss:		0.804108
  validation accuracy:		81.22 %
Epoch 1851 of 2000 took 0.104s
  training loss:		0.194639
  validation loss:		0.810613
  validation accuracy:		80.91 %
Epoch 1852 of 2000 took 0.105s
  training loss:		0.190412
  validation loss:		0.814803
  validation accuracy:		81.74 %
Epoch 1853 of 2000 took 0.108s
  training loss:		0.191760
  validation loss:		0.809276
  validation accuracy:		81.02 %
Epoch 1854 of 2000 took 0.108s
  training loss:		0.189446
  validation loss:		0.829200
  validation accuracy:		81.54 %
Epoch 1855 of 2000 took 0.108s
  training loss:		0.196738
  validation loss:		0.807467
  validation accuracy:		80.60 %
Epoch 1856 of 2000 took 0.108s
  training loss:		0.195098
  validation loss:		0.800738
  validation accuracy:		81.02 %
Epoch 1857 of 2000 took 0.108s
  training loss:		0.203319
  validation loss:		0.807396
  validation accuracy:		80.50 %
Epoch 1858 of 2000 took 0.108s
  training loss:		0.198172
  validation loss:		0.811550
  validation accuracy:		81.02 %
Epoch 1859 of 2000 took 0.108s
  training loss:		0.185511
  validation loss:		0.823945
  validation accuracy:		81.12 %
Epoch 1860 of 2000 took 0.108s
  training loss:		0.188986
  validation loss:		0.820485
  validation accuracy:		80.81 %
Epoch 1861 of 2000 took 0.108s
  training loss:		0.193458
  validation loss:		0.824810
  validation accuracy:		81.54 %
Epoch 1862 of 2000 took 0.108s
  training loss:		0.195532
  validation loss:		0.819831
  validation accuracy:		81.12 %
Epoch 1863 of 2000 took 0.108s
  training loss:		0.183672
  validation loss:		0.819952
  validation accuracy:		81.43 %
Epoch 1864 of 2000 took 0.107s
  training loss:		0.199303
  validation loss:		0.810736
  validation accuracy:		80.91 %
Epoch 1865 of 2000 took 0.108s
  training loss:		0.195976
  validation loss:		0.825786
  validation accuracy:		81.74 %
Epoch 1866 of 2000 took 0.107s
  training loss:		0.191410
  validation loss:		0.801127
  validation accuracy:		81.33 %
Epoch 1867 of 2000 took 0.108s
  training loss:		0.194496
  validation loss:		0.824383
  validation accuracy:		80.60 %
Epoch 1868 of 2000 took 0.107s
  training loss:		0.190196
  validation loss:		0.806045
  validation accuracy:		80.91 %
Epoch 1869 of 2000 took 0.108s
  training loss:		0.194706
  validation loss:		0.813149
  validation accuracy:		81.22 %
Epoch 1870 of 2000 took 0.108s
  training loss:		0.188031
  validation loss:		0.814984
  validation accuracy:		81.22 %
Epoch 1871 of 2000 took 0.108s
  training loss:		0.187090
  validation loss:		0.815971
  validation accuracy:		81.12 %
Epoch 1872 of 2000 took 0.108s
  training loss:		0.188668
  validation loss:		0.824332
  validation accuracy:		81.43 %
Epoch 1873 of 2000 took 0.108s
  training loss:		0.191475
  validation loss:		0.816603
  validation accuracy:		81.43 %
Epoch 1874 of 2000 took 0.108s
  training loss:		0.185498
  validation loss:		0.826180
  validation accuracy:		80.91 %
Epoch 1875 of 2000 took 0.108s
  training loss:		0.187518
  validation loss:		0.825909
  validation accuracy:		81.02 %
Epoch 1876 of 2000 took 0.108s
  training loss:		0.195029
  validation loss:		0.807843
  validation accuracy:		81.22 %
Epoch 1877 of 2000 took 0.108s
  training loss:		0.193463
  validation loss:		0.824023
  validation accuracy:		80.91 %
Epoch 1878 of 2000 took 0.108s
  training loss:		0.195086
  validation loss:		0.829489
  validation accuracy:		81.54 %
Epoch 1879 of 2000 took 0.105s
  training loss:		0.192523
  validation loss:		0.808861
  validation accuracy:		80.91 %
Epoch 1880 of 2000 took 0.104s
  training loss:		0.187861
  validation loss:		0.818286
  validation accuracy:		81.64 %
Epoch 1881 of 2000 took 0.104s
  training loss:		0.190783
  validation loss:		0.837990
  validation accuracy:		81.22 %
Epoch 1882 of 2000 took 0.104s
  training loss:		0.186318
  validation loss:		0.839474
  validation accuracy:		80.60 %
Epoch 1883 of 2000 took 0.104s
  training loss:		0.187809
  validation loss:		0.813793
  validation accuracy:		81.02 %
Epoch 1884 of 2000 took 0.105s
  training loss:		0.185353
  validation loss:		0.820348
  validation accuracy:		80.91 %
Epoch 1885 of 2000 took 0.105s
  training loss:		0.189088
  validation loss:		0.822697
  validation accuracy:		81.64 %
Epoch 1886 of 2000 took 0.104s
  training loss:		0.190380
  validation loss:		0.832519
  validation accuracy:		80.91 %
Epoch 1887 of 2000 took 0.104s
  training loss:		0.191959
  validation loss:		0.818708
  validation accuracy:		81.02 %
Epoch 1888 of 2000 took 0.103s
  training loss:		0.187200
  validation loss:		0.820968
  validation accuracy:		80.71 %
Epoch 1889 of 2000 took 0.104s
  training loss:		0.190319
  validation loss:		0.810713
  validation accuracy:		80.81 %
Epoch 1890 of 2000 took 0.104s
  training loss:		0.195180
  validation loss:		0.833241
  validation accuracy:		81.12 %
Epoch 1891 of 2000 took 0.104s
  training loss:		0.184332
  validation loss:		0.833724
  validation accuracy:		81.43 %
Epoch 1892 of 2000 took 0.104s
  training loss:		0.197384
  validation loss:		0.832241
  validation accuracy:		81.74 %
Epoch 1893 of 2000 took 0.104s
  training loss:		0.193532
  validation loss:		0.817895
  validation accuracy:		81.64 %
Epoch 1894 of 2000 took 0.104s
  training loss:		0.188812
  validation loss:		0.850257
  validation accuracy:		81.43 %
Epoch 1895 of 2000 took 0.102s
  training loss:		0.192091
  validation loss:		0.824872
  validation accuracy:		80.81 %
Epoch 1896 of 2000 took 0.101s
  training loss:		0.194460
  validation loss:		0.831867
  validation accuracy:		81.74 %
Epoch 1897 of 2000 took 0.101s
  training loss:		0.193347
  validation loss:		0.823872
  validation accuracy:		81.54 %
Epoch 1898 of 2000 took 0.101s
  training loss:		0.185963
  validation loss:		0.826203
  validation accuracy:		81.22 %
Epoch 1899 of 2000 took 0.101s
  training loss:		0.190225
  validation loss:		0.824010
  validation accuracy:		81.43 %
Epoch 1900 of 2000 took 0.101s
  training loss:		0.190139
  validation loss:		0.856004
  validation accuracy:		81.43 %
Epoch 1901 of 2000 took 0.101s
  training loss:		0.194482
  validation loss:		0.813221
  validation accuracy:		80.71 %
Epoch 1902 of 2000 took 0.101s
  training loss:		0.195085
  validation loss:		0.821727
  validation accuracy:		80.91 %
Epoch 1903 of 2000 took 0.101s
  training loss:		0.187915
  validation loss:		0.820773
  validation accuracy:		80.71 %
Epoch 1904 of 2000 took 0.101s
  training loss:		0.188056
  validation loss:		0.814673
  validation accuracy:		81.12 %
Epoch 1905 of 2000 took 0.101s
  training loss:		0.199269
  validation loss:		0.829539
  validation accuracy:		81.43 %
Epoch 1906 of 2000 took 0.101s
  training loss:		0.196313
  validation loss:		0.843502
  validation accuracy:		81.64 %
Epoch 1907 of 2000 took 0.101s
  training loss:		0.190477
  validation loss:		0.812222
  validation accuracy:		81.02 %
Epoch 1908 of 2000 took 0.102s
  training loss:		0.195908
  validation loss:		0.821809
  validation accuracy:		80.81 %
Epoch 1909 of 2000 took 0.101s
  training loss:		0.195534
  validation loss:		0.841573
  validation accuracy:		81.33 %
Epoch 1910 of 2000 took 0.101s
  training loss:		0.194524
  validation loss:		0.823899
  validation accuracy:		80.81 %
Epoch 1911 of 2000 took 0.101s
  training loss:		0.196726
  validation loss:		0.821129
  validation accuracy:		81.95 %
Epoch 1912 of 2000 took 0.101s
  training loss:		0.190867
  validation loss:		0.825537
  validation accuracy:		80.71 %
Epoch 1913 of 2000 took 0.101s
  training loss:		0.194893
  validation loss:		0.812839
  validation accuracy:		81.12 %
Epoch 1914 of 2000 took 0.101s
  training loss:		0.193644
  validation loss:		0.837189
  validation accuracy:		80.91 %
Epoch 1915 of 2000 took 0.101s
  training loss:		0.190089
  validation loss:		0.832989
  validation accuracy:		81.22 %
Epoch 1916 of 2000 took 0.101s
  training loss:		0.188941
  validation loss:		0.822253
  validation accuracy:		81.12 %
Epoch 1917 of 2000 took 0.101s
  training loss:		0.193989
  validation loss:		0.821579
  validation accuracy:		81.22 %
Epoch 1918 of 2000 took 0.101s
  training loss:		0.187033
  validation loss:		0.828707
  validation accuracy:		81.54 %
Epoch 1919 of 2000 took 0.101s
  training loss:		0.182477
  validation loss:		0.822968
  validation accuracy:		80.81 %
Epoch 1920 of 2000 took 0.101s
  training loss:		0.188283
  validation loss:		0.848839
  validation accuracy:		81.12 %
Epoch 1921 of 2000 took 0.101s
  training loss:		0.187094
  validation loss:		0.824101
  validation accuracy:		81.74 %
Epoch 1922 of 2000 took 0.101s
  training loss:		0.186300
  validation loss:		0.832162
  validation accuracy:		81.74 %
Epoch 1923 of 2000 took 0.101s
  training loss:		0.185519
  validation loss:		0.830686
  validation accuracy:		80.81 %
Epoch 1924 of 2000 took 0.101s
  training loss:		0.182229
  validation loss:		0.816407
  validation accuracy:		81.22 %
Epoch 1925 of 2000 took 0.101s
  training loss:		0.190622
  validation loss:		0.831431
  validation accuracy:		81.54 %
Epoch 1926 of 2000 took 0.101s
  training loss:		0.189701
  validation loss:		0.834303
  validation accuracy:		81.43 %
Epoch 1927 of 2000 took 0.101s
  training loss:		0.186304
  validation loss:		0.829090
  validation accuracy:		81.22 %
Epoch 1928 of 2000 took 0.102s
  training loss:		0.187058
  validation loss:		0.828202
  validation accuracy:		81.85 %
Epoch 1929 of 2000 took 0.104s
  training loss:		0.187700
  validation loss:		0.866163
  validation accuracy:		80.71 %
Epoch 1930 of 2000 took 0.104s
  training loss:		0.189203
  validation loss:		0.836053
  validation accuracy:		81.22 %
Epoch 1931 of 2000 took 0.104s
  training loss:		0.192082
  validation loss:		0.824317
  validation accuracy:		81.02 %
Epoch 1932 of 2000 took 0.104s
  training loss:		0.199169
  validation loss:		0.841841
  validation accuracy:		80.91 %
Epoch 1933 of 2000 took 0.104s
  training loss:		0.189646
  validation loss:		0.835372
  validation accuracy:		81.12 %
Epoch 1934 of 2000 took 0.104s
  training loss:		0.188173
  validation loss:		0.845714
  validation accuracy:		80.91 %
Epoch 1935 of 2000 took 0.104s
  training loss:		0.193636
  validation loss:		0.824411
  validation accuracy:		80.71 %
Epoch 1936 of 2000 took 0.104s
  training loss:		0.190015
  validation loss:		0.830374
  validation accuracy:		81.64 %
Epoch 1937 of 2000 took 0.105s
  training loss:		0.188976
  validation loss:		0.828510
  validation accuracy:		81.22 %
Epoch 1938 of 2000 took 0.104s
  training loss:		0.185001
  validation loss:		0.838359
  validation accuracy:		81.22 %
Epoch 1939 of 2000 took 0.104s
  training loss:		0.181357
  validation loss:		0.851081
  validation accuracy:		80.81 %
Epoch 1940 of 2000 took 0.104s
  training loss:		0.183790
  validation loss:		0.835316
  validation accuracy:		80.91 %
Epoch 1941 of 2000 took 0.104s
  training loss:		0.190273
  validation loss:		0.831721
  validation accuracy:		81.43 %
Epoch 1942 of 2000 took 0.104s
  training loss:		0.185901
  validation loss:		0.844887
  validation accuracy:		81.22 %
Epoch 1943 of 2000 took 0.104s
  training loss:		0.189317
  validation loss:		0.849030
  validation accuracy:		80.29 %
Epoch 1944 of 2000 took 0.104s
  training loss:		0.194113
  validation loss:		0.827056
  validation accuracy:		81.02 %
Epoch 1945 of 2000 took 0.104s
  training loss:		0.186623
  validation loss:		0.837843
  validation accuracy:		80.81 %
Epoch 1946 of 2000 took 0.104s
  training loss:		0.194866
  validation loss:		0.821925
  validation accuracy:		81.43 %
Epoch 1947 of 2000 took 0.104s
  training loss:		0.185900
  validation loss:		0.841971
  validation accuracy:		80.71 %
Epoch 1948 of 2000 took 0.104s
  training loss:		0.186437
  validation loss:		0.833289
  validation accuracy:		81.33 %
Epoch 1949 of 2000 took 0.104s
  training loss:		0.194714
  validation loss:		0.828879
  validation accuracy:		80.81 %
Epoch 1950 of 2000 took 0.104s
  training loss:		0.194084
  validation loss:		0.836969
  validation accuracy:		81.74 %
Epoch 1951 of 2000 took 0.104s
  training loss:		0.192398
  validation loss:		0.842169
  validation accuracy:		81.43 %
Epoch 1952 of 2000 took 0.104s
  training loss:		0.189525
  validation loss:		0.830513
  validation accuracy:		81.02 %
Epoch 1953 of 2000 took 0.104s
  training loss:		0.188047
  validation loss:		0.839700
  validation accuracy:		81.02 %
Epoch 1954 of 2000 took 0.104s
  training loss:		0.189020
  validation loss:		0.833859
  validation accuracy:		80.71 %
Epoch 1955 of 2000 took 0.104s
  training loss:		0.190745
  validation loss:		0.848802
  validation accuracy:		81.12 %
Epoch 1956 of 2000 took 0.104s
  training loss:		0.188886
  validation loss:		0.851605
  validation accuracy:		80.81 %
Epoch 1957 of 2000 took 0.104s
  training loss:		0.192677
  validation loss:		0.831615
  validation accuracy:		81.33 %
Epoch 1958 of 2000 took 0.104s
  training loss:		0.186676
  validation loss:		0.826277
  validation accuracy:		81.12 %
Epoch 1959 of 2000 took 0.104s
  training loss:		0.183635
  validation loss:		0.839583
  validation accuracy:		80.50 %
Epoch 1960 of 2000 took 0.104s
  training loss:		0.185429
  validation loss:		0.838266
  validation accuracy:		81.64 %
Epoch 1961 of 2000 took 0.104s
  training loss:		0.182402
  validation loss:		0.826793
  validation accuracy:		81.85 %
Epoch 1962 of 2000 took 0.104s
  training loss:		0.191507
  validation loss:		0.836007
  validation accuracy:		81.02 %
Epoch 1963 of 2000 took 0.104s
  training loss:		0.182184
  validation loss:		0.832176
  validation accuracy:		80.81 %
Epoch 1964 of 2000 took 0.104s
  training loss:		0.189423
  validation loss:		0.825489
  validation accuracy:		81.54 %
Epoch 1965 of 2000 took 0.104s
  training loss:		0.188413
  validation loss:		0.829218
  validation accuracy:		81.12 %
Epoch 1966 of 2000 took 0.105s
  training loss:		0.190149
  validation loss:		0.839943
  validation accuracy:		80.81 %
Epoch 1967 of 2000 took 0.101s
  training loss:		0.190298
  validation loss:		0.828934
  validation accuracy:		80.91 %
Epoch 1968 of 2000 took 0.101s
  training loss:		0.183659
  validation loss:		0.846396
  validation accuracy:		80.71 %
Epoch 1969 of 2000 took 0.101s
  training loss:		0.189758
  validation loss:		0.838113
  validation accuracy:		81.22 %
Epoch 1970 of 2000 took 0.101s
  training loss:		0.192135
  validation loss:		0.857842
  validation accuracy:		81.22 %
Epoch 1971 of 2000 took 0.101s
  training loss:		0.193958
  validation loss:		0.849262
  validation accuracy:		81.33 %
Epoch 1972 of 2000 took 0.101s
  training loss:		0.189147
  validation loss:		0.850103
  validation accuracy:		80.60 %
Epoch 1973 of 2000 took 0.103s
  training loss:		0.184947
  validation loss:		0.836693
  validation accuracy:		80.91 %
Epoch 1974 of 2000 took 0.101s
  training loss:		0.194519
  validation loss:		0.830945
  validation accuracy:		81.22 %
Epoch 1975 of 2000 took 0.101s
  training loss:		0.187927
  validation loss:		0.835951
  validation accuracy:		82.05 %
Epoch 1976 of 2000 took 0.101s
  training loss:		0.193076
  validation loss:		0.858086
  validation accuracy:		81.43 %
Epoch 1977 of 2000 took 0.101s
  training loss:		0.182806
  validation loss:		0.861304
  validation accuracy:		81.54 %
Epoch 1978 of 2000 took 0.101s
  training loss:		0.186966
  validation loss:		0.835197
  validation accuracy:		81.12 %
Epoch 1979 of 2000 took 0.101s
  training loss:		0.194436
  validation loss:		0.827572
  validation accuracy:		80.71 %
Epoch 1980 of 2000 took 0.101s
  training loss:		0.190862
  validation loss:		0.836193
  validation accuracy:		81.12 %
Epoch 1981 of 2000 took 0.101s
  training loss:		0.197904
  validation loss:		0.887053
  validation accuracy:		81.43 %
Epoch 1982 of 2000 took 0.101s
  training loss:		0.193281
  validation loss:		0.837585
  validation accuracy:		81.74 %
Epoch 1983 of 2000 took 0.101s
  training loss:		0.184895
  validation loss:		0.825548
  validation accuracy:		81.02 %
Epoch 1984 of 2000 took 0.101s
  training loss:		0.191492
  validation loss:		0.827328
  validation accuracy:		81.02 %
Epoch 1985 of 2000 took 0.101s
  training loss:		0.194175
  validation loss:		0.841808
  validation accuracy:		81.64 %
Epoch 1986 of 2000 took 0.101s
  training loss:		0.189989
  validation loss:		0.830298
  validation accuracy:		81.54 %
Epoch 1987 of 2000 took 0.101s
  training loss:		0.189501
  validation loss:		0.844540
  validation accuracy:		81.02 %
Epoch 1988 of 2000 took 0.101s
  training loss:		0.187897
  validation loss:		0.836207
  validation accuracy:		80.81 %
Epoch 1989 of 2000 took 0.101s
  training loss:		0.195131
  validation loss:		0.851312
  validation accuracy:		81.33 %
Epoch 1990 of 2000 took 0.101s
  training loss:		0.189903
  validation loss:		0.838762
  validation accuracy:		80.71 %
Epoch 1991 of 2000 took 0.101s
  training loss:		0.191804
  validation loss:		0.837833
  validation accuracy:		80.91 %
Epoch 1992 of 2000 took 0.101s
  training loss:		0.191858
  validation loss:		0.841880
  validation accuracy:		81.12 %
Epoch 1993 of 2000 took 0.101s
  training loss:		0.186688
  validation loss:		0.852337
  validation accuracy:		81.22 %
Epoch 1994 of 2000 took 0.101s
  training loss:		0.192546
  validation loss:		0.870756
  validation accuracy:		80.29 %
Epoch 1995 of 2000 took 0.101s
  training loss:		0.189519
  validation loss:		0.854788
  validation accuracy:		80.71 %
Epoch 1996 of 2000 took 0.102s
  training loss:		0.188449
  validation loss:		0.841882
  validation accuracy:		80.91 %
Epoch 1997 of 2000 took 0.101s
  training loss:		0.193050
  validation loss:		0.830554
  validation accuracy:		81.12 %
Epoch 1998 of 2000 took 0.101s
  training loss:		0.187067
  validation loss:		0.839251
  validation accuracy:		80.81 %
Epoch 1999 of 2000 took 0.101s
  training loss:		0.180093
  validation loss:		0.836130
  validation accuracy:		81.43 %
Epoch 2000 of 2000 took 0.101s
  training loss:		0.186403
  validation loss:		0.871916
  validation accuracy:		80.81 %
Final results:
  test loss:			1.292510
  test accuracy:		75.28 %
