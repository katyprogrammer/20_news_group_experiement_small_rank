Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.046s
  training loss:		2.957967
  validation loss:		2.863336
  validation accuracy:		13.04 %
Epoch 2 of 2000 took 0.043s
  training loss:		2.791770
  validation loss:		2.647828
  validation accuracy:		13.04 %
Epoch 3 of 2000 took 0.043s
  training loss:		2.606582
  validation loss:		2.446187
  validation accuracy:		13.04 %
Epoch 4 of 2000 took 0.043s
  training loss:		2.455662
  validation loss:		2.306152
  validation accuracy:		13.26 %
Epoch 5 of 2000 took 0.043s
  training loss:		2.358614
  validation loss:		2.249440
  validation accuracy:		23.37 %
Epoch 6 of 2000 took 0.043s
  training loss:		2.308681
  validation loss:		2.239163
  validation accuracy:		31.96 %
Epoch 7 of 2000 took 0.043s
  training loss:		2.284539
  validation loss:		2.224433
  validation accuracy:		29.13 %
Epoch 8 of 2000 took 0.041s
  training loss:		2.270548
  validation loss:		2.206197
  validation accuracy:		41.41 %
Epoch 9 of 2000 took 0.041s
  training loss:		2.260292
  validation loss:		2.204343
  validation accuracy:		55.43 %
Epoch 10 of 2000 took 0.041s
  training loss:		2.249715
  validation loss:		2.187368
  validation accuracy:		35.87 %
Epoch 11 of 2000 took 0.041s
  training loss:		2.240343
  validation loss:		2.176709
  validation accuracy:		40.87 %
Epoch 12 of 2000 took 0.041s
  training loss:		2.232563
  validation loss:		2.173972
  validation accuracy:		31.96 %
Epoch 13 of 2000 took 0.041s
  training loss:		2.223879
  validation loss:		2.161434
  validation accuracy:		42.72 %
Epoch 14 of 2000 took 0.041s
  training loss:		2.211707
  validation loss:		2.144660
  validation accuracy:		54.67 %
Epoch 15 of 2000 took 0.041s
  training loss:		2.201463
  validation loss:		2.133101
  validation accuracy:		43.80 %
Epoch 16 of 2000 took 0.041s
  training loss:		2.191437
  validation loss:		2.131262
  validation accuracy:		50.11 %
Epoch 17 of 2000 took 0.041s
  training loss:		2.176843
  validation loss:		2.101284
  validation accuracy:		40.43 %
Epoch 18 of 2000 took 0.044s
  training loss:		2.161887
  validation loss:		2.090433
  validation accuracy:		50.33 %
Epoch 19 of 2000 took 0.042s
  training loss:		2.149210
  validation loss:		2.076544
  validation accuracy:		53.37 %
Epoch 20 of 2000 took 0.042s
  training loss:		2.132281
  validation loss:		2.051982
  validation accuracy:		55.54 %
Epoch 21 of 2000 took 0.042s
  training loss:		2.115066
  validation loss:		2.039907
  validation accuracy:		52.61 %
Epoch 22 of 2000 took 0.042s
  training loss:		2.096434
  validation loss:		2.023027
  validation accuracy:		52.50 %
Epoch 23 of 2000 took 0.042s
  training loss:		2.073174
  validation loss:		1.982353
  validation accuracy:		56.30 %
Epoch 24 of 2000 took 0.042s
  training loss:		2.053031
  validation loss:		1.968169
  validation accuracy:		54.13 %
Epoch 25 of 2000 took 0.040s
  training loss:		2.029815
  validation loss:		1.945421
  validation accuracy:		53.26 %
Epoch 26 of 2000 took 0.037s
  training loss:		2.002701
  validation loss:		1.914108
  validation accuracy:		58.59 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.982036
  validation loss:		1.884391
  validation accuracy:		60.33 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.950221
  validation loss:		1.857924
  validation accuracy:		62.39 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.919601
  validation loss:		1.822562
  validation accuracy:		62.93 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.888445
  validation loss:		1.785096
  validation accuracy:		61.85 %
Epoch 31 of 2000 took 0.035s
  training loss:		1.858645
  validation loss:		1.747197
  validation accuracy:		65.54 %
Epoch 32 of 2000 took 0.035s
  training loss:		1.822386
  validation loss:		1.715427
  validation accuracy:		67.50 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.791934
  validation loss:		1.679131
  validation accuracy:		68.80 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.751583
  validation loss:		1.639672
  validation accuracy:		71.52 %
Epoch 35 of 2000 took 0.036s
  training loss:		1.716357
  validation loss:		1.598337
  validation accuracy:		72.07 %
Epoch 36 of 2000 took 0.036s
  training loss:		1.678545
  validation loss:		1.555317
  validation accuracy:		73.15 %
Epoch 37 of 2000 took 0.036s
  training loss:		1.638373
  validation loss:		1.514544
  validation accuracy:		73.48 %
Epoch 38 of 2000 took 0.036s
  training loss:		1.596902
  validation loss:		1.470213
  validation accuracy:		75.65 %
Epoch 39 of 2000 took 0.036s
  training loss:		1.547997
  validation loss:		1.420114
  validation accuracy:		77.39 %
Epoch 40 of 2000 took 0.036s
  training loss:		1.503627
  validation loss:		1.367670
  validation accuracy:		77.50 %
Epoch 41 of 2000 took 0.036s
  training loss:		1.451282
  validation loss:		1.326737
  validation accuracy:		78.26 %
Epoch 42 of 2000 took 0.036s
  training loss:		1.407497
  validation loss:		1.274313
  validation accuracy:		79.24 %
Epoch 43 of 2000 took 0.036s
  training loss:		1.356075
  validation loss:		1.224601
  validation accuracy:		78.59 %
Epoch 44 of 2000 took 0.036s
  training loss:		1.307475
  validation loss:		1.174643
  validation accuracy:		80.98 %
Epoch 45 of 2000 took 0.036s
  training loss:		1.261337
  validation loss:		1.134422
  validation accuracy:		80.98 %
Epoch 46 of 2000 took 0.036s
  training loss:		1.225017
  validation loss:		1.081965
  validation accuracy:		81.52 %
Epoch 47 of 2000 took 0.036s
  training loss:		1.173159
  validation loss:		1.048575
  validation accuracy:		81.96 %
Epoch 48 of 2000 took 0.036s
  training loss:		1.131310
  validation loss:		1.014486
  validation accuracy:		79.57 %
Epoch 49 of 2000 took 0.036s
  training loss:		1.089954
  validation loss:		0.973786
  validation accuracy:		82.17 %
Epoch 50 of 2000 took 0.036s
  training loss:		1.052702
  validation loss:		0.933442
  validation accuracy:		83.15 %
Epoch 51 of 2000 took 0.036s
  training loss:		1.015551
  validation loss:		0.892293
  validation accuracy:		84.13 %
Epoch 52 of 2000 took 0.036s
  training loss:		0.980359
  validation loss:		0.873699
  validation accuracy:		83.59 %
Epoch 53 of 2000 took 0.036s
  training loss:		0.951282
  validation loss:		0.842355
  validation accuracy:		84.13 %
Epoch 54 of 2000 took 0.036s
  training loss:		0.919246
  validation loss:		0.815291
  validation accuracy:		84.57 %
Epoch 55 of 2000 took 0.036s
  training loss:		0.882489
  validation loss:		0.786933
  validation accuracy:		85.00 %
Epoch 56 of 2000 took 0.036s
  training loss:		0.859041
  validation loss:		0.757407
  validation accuracy:		85.43 %
Epoch 57 of 2000 took 0.036s
  training loss:		0.830739
  validation loss:		0.736650
  validation accuracy:		85.65 %
Epoch 58 of 2000 took 0.036s
  training loss:		0.799469
  validation loss:		0.727395
  validation accuracy:		85.00 %
Epoch 59 of 2000 took 0.036s
  training loss:		0.773888
  validation loss:		0.694884
  validation accuracy:		85.11 %
Epoch 60 of 2000 took 0.036s
  training loss:		0.756387
  validation loss:		0.666863
  validation accuracy:		87.39 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.731285
  validation loss:		0.650997
  validation accuracy:		86.09 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.708221
  validation loss:		0.632371
  validation accuracy:		86.41 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.679344
  validation loss:		0.613025
  validation accuracy:		86.96 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.667379
  validation loss:		0.587880
  validation accuracy:		87.39 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.643743
  validation loss:		0.582350
  validation accuracy:		87.39 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.620862
  validation loss:		0.565434
  validation accuracy:		87.28 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.611018
  validation loss:		0.550014
  validation accuracy:		88.04 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.589275
  validation loss:		0.536652
  validation accuracy:		87.93 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.576399
  validation loss:		0.512637
  validation accuracy:		88.70 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.554460
  validation loss:		0.511364
  validation accuracy:		88.70 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.544634
  validation loss:		0.491171
  validation accuracy:		88.91 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.531622
  validation loss:		0.483965
  validation accuracy:		88.59 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.508611
  validation loss:		0.477332
  validation accuracy:		89.13 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.500759
  validation loss:		0.454965
  validation accuracy:		89.67 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.488115
  validation loss:		0.451162
  validation accuracy:		89.67 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.479609
  validation loss:		0.446544
  validation accuracy:		90.00 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.461155
  validation loss:		0.427882
  validation accuracy:		89.78 %
Epoch 78 of 2000 took 0.037s
  training loss:		0.456646
  validation loss:		0.412654
  validation accuracy:		90.54 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.445097
  validation loss:		0.413134
  validation accuracy:		89.78 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.432652
  validation loss:		0.397902
  validation accuracy:		90.54 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.423733
  validation loss:		0.389334
  validation accuracy:		90.87 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.411420
  validation loss:		0.384700
  validation accuracy:		90.98 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.405500
  validation loss:		0.375459
  validation accuracy:		91.09 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.396211
  validation loss:		0.375081
  validation accuracy:		90.98 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.391780
  validation loss:		0.367296
  validation accuracy:		90.98 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.381143
  validation loss:		0.360028
  validation accuracy:		91.52 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.372976
  validation loss:		0.358870
  validation accuracy:		91.30 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.368245
  validation loss:		0.344490
  validation accuracy:		91.20 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.362006
  validation loss:		0.343295
  validation accuracy:		91.20 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.355224
  validation loss:		0.347446
  validation accuracy:		91.09 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.349258
  validation loss:		0.337327
  validation accuracy:		91.09 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.343692
  validation loss:		0.333771
  validation accuracy:		91.09 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.339421
  validation loss:		0.319814
  validation accuracy:		92.07 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.331401
  validation loss:		0.321809
  validation accuracy:		91.63 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.326798
  validation loss:		0.313524
  validation accuracy:		92.17 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.325605
  validation loss:		0.316069
  validation accuracy:		91.52 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.317304
  validation loss:		0.314603
  validation accuracy:		91.85 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.317643
  validation loss:		0.298476
  validation accuracy:		92.17 %
Epoch 99 of 2000 took 0.036s
  training loss:		0.311030
  validation loss:		0.298829
  validation accuracy:		92.17 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.307736
  validation loss:		0.310385
  validation accuracy:		91.85 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.301446
  validation loss:		0.292337
  validation accuracy:		92.17 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.301087
  validation loss:		0.287561
  validation accuracy:		92.28 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.293476
  validation loss:		0.293893
  validation accuracy:		92.17 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.288173
  validation loss:		0.299107
  validation accuracy:		92.07 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.289930
  validation loss:		0.291460
  validation accuracy:		91.96 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.286197
  validation loss:		0.283607
  validation accuracy:		92.28 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.278516
  validation loss:		0.275117
  validation accuracy:		92.28 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.275508
  validation loss:		0.283211
  validation accuracy:		92.28 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.274571
  validation loss:		0.281270
  validation accuracy:		92.28 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.274870
  validation loss:		0.278113
  validation accuracy:		92.07 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.267440
  validation loss:		0.267067
  validation accuracy:		92.72 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.265189
  validation loss:		0.264728
  validation accuracy:		92.72 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.265347
  validation loss:		0.260156
  validation accuracy:		92.61 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.257285
  validation loss:		0.264274
  validation accuracy:		92.39 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.264525
  validation loss:		0.257697
  validation accuracy:		92.39 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.255380
  validation loss:		0.258162
  validation accuracy:		92.61 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.256128
  validation loss:		0.258564
  validation accuracy:		92.61 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.254822
  validation loss:		0.264030
  validation accuracy:		92.50 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.251476
  validation loss:		0.257131
  validation accuracy:		92.83 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.251540
  validation loss:		0.258613
  validation accuracy:		92.39 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.244630
  validation loss:		0.248863
  validation accuracy:		93.04 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.244874
  validation loss:		0.255833
  validation accuracy:		92.72 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.244490
  validation loss:		0.259051
  validation accuracy:		92.39 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.242260
  validation loss:		0.251851
  validation accuracy:		92.83 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.243189
  validation loss:		0.246837
  validation accuracy:		92.93 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.237916
  validation loss:		0.250027
  validation accuracy:		92.61 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.234243
  validation loss:		0.253496
  validation accuracy:		92.83 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.234515
  validation loss:		0.241688
  validation accuracy:		92.93 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.230215
  validation loss:		0.248805
  validation accuracy:		92.61 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.232839
  validation loss:		0.250852
  validation accuracy:		92.83 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.228912
  validation loss:		0.243459
  validation accuracy:		92.93 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.230368
  validation loss:		0.243234
  validation accuracy:		93.04 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.220752
  validation loss:		0.245285
  validation accuracy:		92.93 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.223652
  validation loss:		0.241082
  validation accuracy:		92.83 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.220094
  validation loss:		0.237760
  validation accuracy:		93.26 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.221844
  validation loss:		0.232589
  validation accuracy:		92.93 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.220769
  validation loss:		0.235297
  validation accuracy:		93.15 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.219948
  validation loss:		0.239356
  validation accuracy:		93.26 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.217011
  validation loss:		0.230921
  validation accuracy:		93.26 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.212310
  validation loss:		0.231668
  validation accuracy:		93.15 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.213650
  validation loss:		0.237216
  validation accuracy:		92.83 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.211129
  validation loss:		0.228632
  validation accuracy:		93.37 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.209398
  validation loss:		0.228205
  validation accuracy:		93.26 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.211466
  validation loss:		0.237575
  validation accuracy:		93.04 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.209256
  validation loss:		0.230464
  validation accuracy:		93.48 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.211823
  validation loss:		0.227903
  validation accuracy:		93.26 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.201685
  validation loss:		0.227220
  validation accuracy:		93.48 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.209031
  validation loss:		0.228083
  validation accuracy:		93.59 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.206571
  validation loss:		0.228154
  validation accuracy:		92.93 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.202355
  validation loss:		0.225435
  validation accuracy:		93.37 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.201317
  validation loss:		0.236253
  validation accuracy:		93.15 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.200109
  validation loss:		0.228190
  validation accuracy:		93.48 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.201809
  validation loss:		0.227136
  validation accuracy:		93.37 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.197479
  validation loss:		0.223981
  validation accuracy:		93.48 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.198213
  validation loss:		0.222792
  validation accuracy:		93.59 %
Epoch 156 of 2000 took 0.036s
  training loss:		0.190476
  validation loss:		0.221028
  validation accuracy:		93.59 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.194221
  validation loss:		0.231070
  validation accuracy:		93.59 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.194972
  validation loss:		0.221475
  validation accuracy:		93.80 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.196702
  validation loss:		0.217542
  validation accuracy:		93.80 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.196617
  validation loss:		0.219396
  validation accuracy:		93.70 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.195254
  validation loss:		0.218192
  validation accuracy:		93.26 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.190437
  validation loss:		0.218653
  validation accuracy:		93.48 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.189723
  validation loss:		0.218324
  validation accuracy:		93.70 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.187773
  validation loss:		0.221879
  validation accuracy:		93.59 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.190692
  validation loss:		0.221482
  validation accuracy:		93.59 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.188702
  validation loss:		0.218103
  validation accuracy:		93.59 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.190404
  validation loss:		0.230097
  validation accuracy:		93.15 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.185639
  validation loss:		0.218345
  validation accuracy:		93.59 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.186644
  validation loss:		0.220409
  validation accuracy:		93.37 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.186086
  validation loss:		0.224724
  validation accuracy:		93.80 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.185201
  validation loss:		0.213320
  validation accuracy:		93.70 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.179487
  validation loss:		0.218182
  validation accuracy:		93.48 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.180531
  validation loss:		0.211815
  validation accuracy:		93.80 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.181061
  validation loss:		0.219272
  validation accuracy:		93.91 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.178242
  validation loss:		0.213542
  validation accuracy:		93.70 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.180007
  validation loss:		0.217803
  validation accuracy:		93.59 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.178310
  validation loss:		0.225578
  validation accuracy:		93.48 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.180630
  validation loss:		0.216024
  validation accuracy:		93.48 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.179155
  validation loss:		0.214576
  validation accuracy:		93.59 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.177686
  validation loss:		0.212198
  validation accuracy:		93.80 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.174557
  validation loss:		0.226749
  validation accuracy:		93.48 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.171837
  validation loss:		0.221774
  validation accuracy:		93.80 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.175608
  validation loss:		0.223373
  validation accuracy:		93.70 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.172533
  validation loss:		0.212730
  validation accuracy:		93.59 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.174542
  validation loss:		0.210219
  validation accuracy:		93.59 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.174254
  validation loss:		0.216810
  validation accuracy:		93.15 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.173697
  validation loss:		0.212111
  validation accuracy:		93.70 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.168922
  validation loss:		0.215712
  validation accuracy:		93.80 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.168562
  validation loss:		0.218829
  validation accuracy:		93.59 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.170025
  validation loss:		0.216169
  validation accuracy:		93.80 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.163258
  validation loss:		0.218710
  validation accuracy:		93.48 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.166059
  validation loss:		0.219408
  validation accuracy:		93.37 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.166286
  validation loss:		0.210516
  validation accuracy:		94.02 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.167381
  validation loss:		0.213532
  validation accuracy:		93.59 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.167129
  validation loss:		0.213037
  validation accuracy:		93.80 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.163375
  validation loss:		0.213731
  validation accuracy:		93.59 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.166397
  validation loss:		0.212793
  validation accuracy:		93.59 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.162041
  validation loss:		0.219891
  validation accuracy:		93.37 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.165096
  validation loss:		0.207045
  validation accuracy:		94.13 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.161237
  validation loss:		0.205352
  validation accuracy:		94.02 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.164955
  validation loss:		0.211684
  validation accuracy:		93.70 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.159333
  validation loss:		0.206068
  validation accuracy:		93.91 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.162205
  validation loss:		0.211210
  validation accuracy:		93.48 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.162484
  validation loss:		0.210272
  validation accuracy:		93.59 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.157005
  validation loss:		0.204530
  validation accuracy:		94.13 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.160352
  validation loss:		0.211746
  validation accuracy:		93.91 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.157352
  validation loss:		0.213743
  validation accuracy:		93.48 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.159204
  validation loss:		0.215607
  validation accuracy:		93.26 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.159999
  validation loss:		0.206136
  validation accuracy:		93.80 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.158407
  validation loss:		0.215893
  validation accuracy:		93.91 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.154250
  validation loss:		0.212636
  validation accuracy:		93.48 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.157086
  validation loss:		0.203761
  validation accuracy:		93.91 %
Epoch 213 of 2000 took 0.036s
  training loss:		0.154578
  validation loss:		0.206023
  validation accuracy:		93.91 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.153972
  validation loss:		0.208679
  validation accuracy:		94.02 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.153139
  validation loss:		0.203333
  validation accuracy:		93.80 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.155613
  validation loss:		0.208289
  validation accuracy:		93.70 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.149882
  validation loss:		0.205847
  validation accuracy:		94.13 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.149668
  validation loss:		0.215925
  validation accuracy:		93.80 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.154638
  validation loss:		0.208574
  validation accuracy:		93.91 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.153133
  validation loss:		0.211582
  validation accuracy:		93.59 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.152578
  validation loss:		0.213147
  validation accuracy:		93.80 %
Epoch 222 of 2000 took 0.036s
  training loss:		0.150209
  validation loss:		0.206132
  validation accuracy:		93.59 %
Epoch 223 of 2000 took 0.036s
  training loss:		0.150880
  validation loss:		0.213736
  validation accuracy:		94.02 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.152596
  validation loss:		0.213337
  validation accuracy:		93.70 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.146698
  validation loss:		0.212939
  validation accuracy:		93.70 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.147057
  validation loss:		0.209145
  validation accuracy:		93.91 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.149459
  validation loss:		0.207908
  validation accuracy:		93.70 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.145724
  validation loss:		0.215336
  validation accuracy:		93.70 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.144051
  validation loss:		0.206058
  validation accuracy:		94.02 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.145287
  validation loss:		0.211873
  validation accuracy:		93.80 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.149333
  validation loss:		0.209499
  validation accuracy:		94.02 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.145350
  validation loss:		0.210079
  validation accuracy:		93.59 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.147537
  validation loss:		0.203834
  validation accuracy:		94.02 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.143280
  validation loss:		0.206204
  validation accuracy:		94.24 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.139899
  validation loss:		0.206553
  validation accuracy:		94.24 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.145337
  validation loss:		0.213703
  validation accuracy:		93.80 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.142381
  validation loss:		0.209105
  validation accuracy:		94.02 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.138644
  validation loss:		0.211524
  validation accuracy:		94.13 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.144336
  validation loss:		0.206560
  validation accuracy:		94.02 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.141992
  validation loss:		0.209295
  validation accuracy:		93.80 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.140125
  validation loss:		0.213969
  validation accuracy:		93.04 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.141145
  validation loss:		0.209602
  validation accuracy:		93.91 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.139582
  validation loss:		0.200396
  validation accuracy:		94.02 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.140065
  validation loss:		0.212917
  validation accuracy:		93.48 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.140787
  validation loss:		0.208650
  validation accuracy:		93.91 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.139177
  validation loss:		0.213008
  validation accuracy:		93.80 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.138641
  validation loss:		0.203524
  validation accuracy:		93.48 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.138681
  validation loss:		0.211457
  validation accuracy:		93.91 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.137993
  validation loss:		0.210956
  validation accuracy:		93.59 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.140717
  validation loss:		0.203888
  validation accuracy:		93.91 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.135242
  validation loss:		0.207746
  validation accuracy:		93.80 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.138592
  validation loss:		0.205148
  validation accuracy:		93.70 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.141309
  validation loss:		0.221701
  validation accuracy:		93.59 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.135970
  validation loss:		0.205104
  validation accuracy:		94.02 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.139019
  validation loss:		0.206010
  validation accuracy:		94.02 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.132191
  validation loss:		0.206899
  validation accuracy:		93.80 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.135337
  validation loss:		0.205216
  validation accuracy:		93.91 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.133275
  validation loss:		0.211532
  validation accuracy:		93.26 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.132557
  validation loss:		0.207978
  validation accuracy:		94.24 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.131516
  validation loss:		0.203064
  validation accuracy:		94.13 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.134881
  validation loss:		0.211433
  validation accuracy:		93.91 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.129570
  validation loss:		0.207189
  validation accuracy:		93.80 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.131480
  validation loss:		0.214139
  validation accuracy:		93.59 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.130269
  validation loss:		0.209805
  validation accuracy:		93.80 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.131760
  validation loss:		0.204090
  validation accuracy:		94.13 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.129812
  validation loss:		0.212166
  validation accuracy:		94.02 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.128975
  validation loss:		0.205918
  validation accuracy:		94.02 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.131856
  validation loss:		0.206887
  validation accuracy:		94.13 %
Epoch 269 of 2000 took 0.036s
  training loss:		0.126309
  validation loss:		0.219206
  validation accuracy:		93.80 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.128511
  validation loss:		0.207936
  validation accuracy:		94.02 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.129898
  validation loss:		0.213725
  validation accuracy:		93.26 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.126085
  validation loss:		0.207101
  validation accuracy:		93.48 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.124867
  validation loss:		0.209271
  validation accuracy:		93.80 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.131474
  validation loss:		0.206157
  validation accuracy:		93.91 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.127489
  validation loss:		0.210028
  validation accuracy:		93.91 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.128973
  validation loss:		0.213528
  validation accuracy:		93.91 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.126919
  validation loss:		0.211273
  validation accuracy:		94.02 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.125105
  validation loss:		0.206953
  validation accuracy:		94.24 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.124551
  validation loss:		0.207658
  validation accuracy:		94.02 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.122927
  validation loss:		0.204298
  validation accuracy:		94.02 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.124772
  validation loss:		0.211886
  validation accuracy:		93.26 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.124025
  validation loss:		0.205275
  validation accuracy:		93.70 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.126277
  validation loss:		0.214657
  validation accuracy:		94.13 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.124446
  validation loss:		0.212687
  validation accuracy:		93.91 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.126564
  validation loss:		0.205473
  validation accuracy:		94.35 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.117351
  validation loss:		0.205822
  validation accuracy:		94.13 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.122935
  validation loss:		0.206527
  validation accuracy:		94.35 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.120184
  validation loss:		0.215312
  validation accuracy:		93.59 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.122112
  validation loss:		0.215548
  validation accuracy:		93.59 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.122092
  validation loss:		0.207580
  validation accuracy:		93.91 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.119731
  validation loss:		0.204432
  validation accuracy:		94.24 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.121710
  validation loss:		0.207615
  validation accuracy:		94.35 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.115982
  validation loss:		0.209740
  validation accuracy:		93.80 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.120955
  validation loss:		0.204499
  validation accuracy:		94.13 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.122033
  validation loss:		0.205813
  validation accuracy:		94.46 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.118933
  validation loss:		0.208576
  validation accuracy:		93.70 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.118878
  validation loss:		0.212159
  validation accuracy:		93.91 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.120457
  validation loss:		0.210189
  validation accuracy:		93.80 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.121723
  validation loss:		0.210890
  validation accuracy:		93.48 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.119733
  validation loss:		0.207187
  validation accuracy:		93.91 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.116868
  validation loss:		0.210739
  validation accuracy:		93.91 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.117320
  validation loss:		0.206559
  validation accuracy:		93.91 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.114974
  validation loss:		0.211542
  validation accuracy:		94.02 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.115052
  validation loss:		0.204715
  validation accuracy:		94.24 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.120130
  validation loss:		0.207225
  validation accuracy:		93.80 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.114450
  validation loss:		0.212616
  validation accuracy:		94.02 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.117847
  validation loss:		0.205046
  validation accuracy:		94.24 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.115897
  validation loss:		0.212227
  validation accuracy:		93.70 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.114577
  validation loss:		0.209841
  validation accuracy:		93.80 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.115076
  validation loss:		0.205520
  validation accuracy:		94.24 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.114359
  validation loss:		0.211270
  validation accuracy:		93.70 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.113407
  validation loss:		0.213161
  validation accuracy:		94.02 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.112241
  validation loss:		0.209718
  validation accuracy:		93.70 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.112618
  validation loss:		0.214300
  validation accuracy:		93.48 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.116128
  validation loss:		0.206594
  validation accuracy:		93.80 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.111185
  validation loss:		0.216264
  validation accuracy:		93.48 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.111793
  validation loss:		0.206227
  validation accuracy:		93.91 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.114512
  validation loss:		0.214285
  validation accuracy:		93.48 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.112584
  validation loss:		0.210072
  validation accuracy:		94.02 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.109517
  validation loss:		0.212573
  validation accuracy:		93.59 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.114288
  validation loss:		0.211993
  validation accuracy:		93.59 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.110596
  validation loss:		0.217339
  validation accuracy:		93.59 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.112580
  validation loss:		0.215934
  validation accuracy:		93.59 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.112019
  validation loss:		0.214197
  validation accuracy:		93.70 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.108444
  validation loss:		0.213573
  validation accuracy:		93.48 %
Epoch 326 of 2000 took 0.036s
  training loss:		0.112493
  validation loss:		0.213114
  validation accuracy:		93.48 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.109404
  validation loss:		0.214417
  validation accuracy:		93.70 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.109298
  validation loss:		0.211319
  validation accuracy:		93.70 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.109106
  validation loss:		0.209031
  validation accuracy:		93.48 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.109656
  validation loss:		0.209382
  validation accuracy:		93.80 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.111269
  validation loss:		0.214079
  validation accuracy:		93.37 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.107938
  validation loss:		0.216523
  validation accuracy:		93.37 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.110204
  validation loss:		0.211452
  validation accuracy:		93.91 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.110340
  validation loss:		0.217319
  validation accuracy:		93.59 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.108119
  validation loss:		0.217486
  validation accuracy:		93.37 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.108048
  validation loss:		0.209666
  validation accuracy:		93.80 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.110347
  validation loss:		0.210233
  validation accuracy:		93.59 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.107621
  validation loss:		0.213906
  validation accuracy:		93.59 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.106780
  validation loss:		0.216935
  validation accuracy:		93.59 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.102374
  validation loss:		0.211074
  validation accuracy:		93.91 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.103609
  validation loss:		0.216801
  validation accuracy:		93.37 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.108037
  validation loss:		0.218131
  validation accuracy:		93.59 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.105245
  validation loss:		0.218246
  validation accuracy:		93.59 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.103106
  validation loss:		0.215293
  validation accuracy:		93.26 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.104121
  validation loss:		0.217745
  validation accuracy:		93.26 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.103164
  validation loss:		0.217129
  validation accuracy:		93.48 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.100746
  validation loss:		0.221263
  validation accuracy:		93.26 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.103964
  validation loss:		0.218101
  validation accuracy:		93.70 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.103492
  validation loss:		0.217400
  validation accuracy:		93.48 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.102444
  validation loss:		0.219340
  validation accuracy:		93.59 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.104212
  validation loss:		0.213939
  validation accuracy:		93.59 %
Epoch 352 of 2000 took 0.036s
  training loss:		0.100269
  validation loss:		0.221074
  validation accuracy:		93.26 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.104424
  validation loss:		0.213203
  validation accuracy:		93.70 %
Epoch 354 of 2000 took 0.036s
  training loss:		0.101939
  validation loss:		0.219188
  validation accuracy:		93.37 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.101669
  validation loss:		0.220123
  validation accuracy:		93.37 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.103268
  validation loss:		0.217819
  validation accuracy:		93.48 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.097735
  validation loss:		0.217014
  validation accuracy:		93.48 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.102822
  validation loss:		0.224623
  validation accuracy:		93.70 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.102618
  validation loss:		0.214439
  validation accuracy:		93.91 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.100099
  validation loss:		0.217204
  validation accuracy:		93.37 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.100665
  validation loss:		0.222087
  validation accuracy:		93.48 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.101094
  validation loss:		0.218490
  validation accuracy:		93.37 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.098614
  validation loss:		0.220884
  validation accuracy:		93.37 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.100467
  validation loss:		0.212548
  validation accuracy:		93.59 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.101540
  validation loss:		0.218873
  validation accuracy:		93.70 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.102108
  validation loss:		0.217487
  validation accuracy:		93.80 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.098575
  validation loss:		0.220123
  validation accuracy:		93.80 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.095367
  validation loss:		0.214188
  validation accuracy:		93.80 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.098942
  validation loss:		0.218111
  validation accuracy:		93.80 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.099178
  validation loss:		0.214678
  validation accuracy:		94.02 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.097798
  validation loss:		0.216969
  validation accuracy:		93.48 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.098659
  validation loss:		0.216106
  validation accuracy:		93.70 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.094374
  validation loss:		0.219843
  validation accuracy:		93.59 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.099499
  validation loss:		0.222000
  validation accuracy:		93.59 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.097186
  validation loss:		0.220804
  validation accuracy:		93.48 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.098846
  validation loss:		0.220627
  validation accuracy:		93.59 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.096091
  validation loss:		0.218824
  validation accuracy:		93.70 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.094643
  validation loss:		0.229128
  validation accuracy:		93.26 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.096426
  validation loss:		0.213849
  validation accuracy:		93.37 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.096344
  validation loss:		0.216598
  validation accuracy:		93.91 %
Epoch 381 of 2000 took 0.036s
  training loss:		0.094780
  validation loss:		0.218307
  validation accuracy:		93.48 %
Epoch 382 of 2000 took 0.036s
  training loss:		0.093678
  validation loss:		0.217031
  validation accuracy:		93.91 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.092038
  validation loss:		0.218417
  validation accuracy:		93.48 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.093424
  validation loss:		0.223071
  validation accuracy:		93.26 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.093636
  validation loss:		0.226459
  validation accuracy:		93.48 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.091781
  validation loss:		0.221015
  validation accuracy:		93.70 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.094111
  validation loss:		0.218252
  validation accuracy:		93.59 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.094369
  validation loss:		0.221833
  validation accuracy:		93.37 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.093675
  validation loss:		0.216751
  validation accuracy:		93.59 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.094421
  validation loss:		0.223665
  validation accuracy:		93.48 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.090057
  validation loss:		0.221603
  validation accuracy:		93.48 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.091131
  validation loss:		0.220346
  validation accuracy:		93.48 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.094049
  validation loss:		0.219905
  validation accuracy:		93.48 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.093110
  validation loss:		0.225337
  validation accuracy:		93.26 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.091654
  validation loss:		0.220681
  validation accuracy:		93.48 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.089962
  validation loss:		0.224020
  validation accuracy:		93.48 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.091234
  validation loss:		0.226625
  validation accuracy:		93.26 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.088868
  validation loss:		0.216092
  validation accuracy:		93.48 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.089476
  validation loss:		0.222292
  validation accuracy:		93.59 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.090042
  validation loss:		0.222328
  validation accuracy:		93.59 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.089829
  validation loss:		0.221910
  validation accuracy:		93.37 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.089470
  validation loss:		0.217750
  validation accuracy:		93.70 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.090802
  validation loss:		0.219571
  validation accuracy:		93.59 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.089491
  validation loss:		0.224882
  validation accuracy:		93.48 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.089290
  validation loss:		0.228209
  validation accuracy:		93.15 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.091238
  validation loss:		0.219381
  validation accuracy:		93.48 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.088629
  validation loss:		0.226251
  validation accuracy:		93.48 %
Epoch 408 of 2000 took 0.036s
  training loss:		0.088894
  validation loss:		0.224782
  validation accuracy:		93.37 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.088286
  validation loss:		0.220786
  validation accuracy:		93.59 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.085459
  validation loss:		0.225452
  validation accuracy:		93.37 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.086005
  validation loss:		0.215723
  validation accuracy:		93.70 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.089179
  validation loss:		0.224972
  validation accuracy:		93.15 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.087284
  validation loss:		0.229135
  validation accuracy:		93.15 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.087832
  validation loss:		0.218445
  validation accuracy:		93.70 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.089293
  validation loss:		0.224587
  validation accuracy:		93.26 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.085772
  validation loss:		0.221722
  validation accuracy:		93.70 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.086954
  validation loss:		0.222427
  validation accuracy:		93.70 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.085507
  validation loss:		0.228843
  validation accuracy:		93.26 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.084120
  validation loss:		0.229154
  validation accuracy:		93.15 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.087812
  validation loss:		0.228114
  validation accuracy:		93.48 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.085368
  validation loss:		0.225685
  validation accuracy:		93.59 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.087405
  validation loss:		0.226261
  validation accuracy:		93.26 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.086443
  validation loss:		0.232726
  validation accuracy:		93.48 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.087483
  validation loss:		0.222708
  validation accuracy:		93.48 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.085421
  validation loss:		0.230391
  validation accuracy:		93.59 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.081989
  validation loss:		0.225541
  validation accuracy:		93.04 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.084421
  validation loss:		0.226189
  validation accuracy:		93.48 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.084017
  validation loss:		0.234968
  validation accuracy:		93.26 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.087025
  validation loss:		0.234275
  validation accuracy:		93.15 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.084607
  validation loss:		0.236219
  validation accuracy:		93.15 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.085005
  validation loss:		0.229516
  validation accuracy:		93.70 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.082142
  validation loss:		0.228383
  validation accuracy:		93.48 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.083201
  validation loss:		0.231304
  validation accuracy:		93.48 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.082964
  validation loss:		0.228767
  validation accuracy:		93.26 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.085648
  validation loss:		0.229547
  validation accuracy:		93.37 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.083873
  validation loss:		0.224061
  validation accuracy:		93.59 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.080512
  validation loss:		0.228627
  validation accuracy:		93.37 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.079913
  validation loss:		0.229305
  validation accuracy:		93.26 %
Epoch 439 of 2000 took 0.036s
  training loss:		0.083422
  validation loss:		0.230086
  validation accuracy:		93.37 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.081449
  validation loss:		0.227637
  validation accuracy:		93.80 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.079181
  validation loss:		0.227038
  validation accuracy:		93.59 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.082005
  validation loss:		0.232612
  validation accuracy:		93.37 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.082621
  validation loss:		0.230331
  validation accuracy:		93.37 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.080818
  validation loss:		0.232333
  validation accuracy:		93.70 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.082237
  validation loss:		0.232734
  validation accuracy:		93.48 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.081381
  validation loss:		0.233456
  validation accuracy:		93.48 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.077293
  validation loss:		0.228804
  validation accuracy:		93.15 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.081614
  validation loss:		0.229309
  validation accuracy:		93.59 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.079618
  validation loss:		0.227063
  validation accuracy:		93.37 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.081941
  validation loss:		0.231843
  validation accuracy:		93.59 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.078627
  validation loss:		0.229972
  validation accuracy:		93.37 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.078571
  validation loss:		0.228475
  validation accuracy:		93.26 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.079009
  validation loss:		0.231112
  validation accuracy:		93.70 %
Epoch 454 of 2000 took 0.037s
  training loss:		0.079025
  validation loss:		0.230781
  validation accuracy:		93.48 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.079604
  validation loss:		0.230229
  validation accuracy:		93.70 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.075154
  validation loss:		0.242673
  validation accuracy:		93.37 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.078652
  validation loss:		0.226900
  validation accuracy:		93.48 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.079204
  validation loss:		0.227889
  validation accuracy:		93.37 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.077407
  validation loss:		0.234004
  validation accuracy:		93.48 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.078341
  validation loss:		0.232337
  validation accuracy:		93.59 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.079537
  validation loss:		0.233079
  validation accuracy:		93.26 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.075844
  validation loss:		0.232944
  validation accuracy:		93.37 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.078149
  validation loss:		0.231937
  validation accuracy:		93.48 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.075861
  validation loss:		0.239233
  validation accuracy:		93.70 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.079352
  validation loss:		0.232005
  validation accuracy:		93.70 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.076340
  validation loss:		0.233459
  validation accuracy:		93.48 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.076842
  validation loss:		0.233115
  validation accuracy:		93.59 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.075299
  validation loss:		0.233304
  validation accuracy:		93.26 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.072052
  validation loss:		0.235921
  validation accuracy:		93.26 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.075852
  validation loss:		0.232943
  validation accuracy:		93.26 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.077278
  validation loss:		0.231967
  validation accuracy:		93.70 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.076490
  validation loss:		0.230757
  validation accuracy:		93.37 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.077855
  validation loss:		0.231246
  validation accuracy:		93.48 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.075358
  validation loss:		0.245486
  validation accuracy:		93.48 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.074533
  validation loss:		0.235832
  validation accuracy:		93.26 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.073041
  validation loss:		0.237202
  validation accuracy:		93.37 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.074509
  validation loss:		0.239146
  validation accuracy:		93.48 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.075620
  validation loss:		0.235218
  validation accuracy:		93.37 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.072494
  validation loss:		0.242105
  validation accuracy:		93.37 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.075022
  validation loss:		0.238630
  validation accuracy:		93.48 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.072746
  validation loss:		0.232598
  validation accuracy:		93.59 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.073223
  validation loss:		0.236639
  validation accuracy:		93.37 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.073587
  validation loss:		0.235960
  validation accuracy:		93.37 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.073918
  validation loss:		0.232787
  validation accuracy:		93.48 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.074096
  validation loss:		0.238190
  validation accuracy:		93.70 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.070608
  validation loss:		0.237337
  validation accuracy:		93.48 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.070979
  validation loss:		0.245103
  validation accuracy:		93.37 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.073402
  validation loss:		0.235387
  validation accuracy:		93.26 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.073546
  validation loss:		0.234635
  validation accuracy:		93.26 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.069784
  validation loss:		0.229881
  validation accuracy:		93.70 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.072510
  validation loss:		0.234516
  validation accuracy:		93.59 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.070929
  validation loss:		0.242113
  validation accuracy:		93.37 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.071787
  validation loss:		0.241008
  validation accuracy:		93.37 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.073045
  validation loss:		0.242973
  validation accuracy:		93.26 %
Epoch 495 of 2000 took 0.036s
  training loss:		0.072833
  validation loss:		0.236537
  validation accuracy:		93.80 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.072970
  validation loss:		0.237526
  validation accuracy:		93.59 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.070821
  validation loss:		0.232738
  validation accuracy:		93.26 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.070327
  validation loss:		0.236925
  validation accuracy:		93.59 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.071237
  validation loss:		0.236111
  validation accuracy:		93.48 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.072934
  validation loss:		0.245412
  validation accuracy:		93.26 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.073365
  validation loss:		0.244184
  validation accuracy:		93.70 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.073120
  validation loss:		0.242135
  validation accuracy:		93.37 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.070800
  validation loss:		0.239494
  validation accuracy:		93.15 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.071172
  validation loss:		0.237060
  validation accuracy:		93.48 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.070388
  validation loss:		0.240277
  validation accuracy:		93.37 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.069397
  validation loss:		0.234310
  validation accuracy:		93.15 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.070311
  validation loss:		0.241530
  validation accuracy:		93.48 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.072422
  validation loss:		0.233173
  validation accuracy:		93.70 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.068959
  validation loss:		0.239891
  validation accuracy:		93.26 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.066661
  validation loss:		0.237820
  validation accuracy:		93.80 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.071083
  validation loss:		0.242028
  validation accuracy:		93.37 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.070892
  validation loss:		0.250650
  validation accuracy:		93.15 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.070424
  validation loss:		0.238606
  validation accuracy:		93.26 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.067139
  validation loss:		0.236083
  validation accuracy:		93.80 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.068838
  validation loss:		0.244230
  validation accuracy:		93.48 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.067932
  validation loss:		0.240678
  validation accuracy:		93.26 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.068740
  validation loss:		0.242388
  validation accuracy:		93.26 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.069579
  validation loss:		0.236409
  validation accuracy:		93.37 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.070308
  validation loss:		0.240777
  validation accuracy:		93.59 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.068533
  validation loss:		0.242648
  validation accuracy:		93.04 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.065476
  validation loss:		0.247466
  validation accuracy:		93.26 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.066644
  validation loss:		0.238798
  validation accuracy:		93.37 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.065527
  validation loss:		0.245713
  validation accuracy:		93.15 %
Epoch 524 of 2000 took 0.036s
  training loss:		0.066855
  validation loss:		0.240145
  validation accuracy:		93.59 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.066750
  validation loss:		0.242396
  validation accuracy:		93.37 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.066115
  validation loss:		0.246608
  validation accuracy:		93.15 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.063951
  validation loss:		0.243983
  validation accuracy:		93.15 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.065811
  validation loss:		0.246042
  validation accuracy:		93.37 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.066229
  validation loss:		0.242711
  validation accuracy:		93.37 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.065298
  validation loss:		0.240099
  validation accuracy:		93.59 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.066813
  validation loss:		0.254694
  validation accuracy:		93.15 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.064474
  validation loss:		0.241790
  validation accuracy:		93.26 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.064622
  validation loss:		0.252792
  validation accuracy:		93.26 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.065067
  validation loss:		0.244972
  validation accuracy:		93.48 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.064976
  validation loss:		0.248238
  validation accuracy:		93.59 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.065008
  validation loss:		0.246003
  validation accuracy:		93.26 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.065299
  validation loss:		0.243833
  validation accuracy:		93.37 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.064949
  validation loss:		0.245025
  validation accuracy:		93.48 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.065862
  validation loss:		0.241652
  validation accuracy:		93.37 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.063183
  validation loss:		0.249281
  validation accuracy:		93.37 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.062921
  validation loss:		0.246075
  validation accuracy:		93.37 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.063721
  validation loss:		0.244481
  validation accuracy:		93.48 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.063733
  validation loss:		0.242440
  validation accuracy:		93.48 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.064001
  validation loss:		0.246644
  validation accuracy:		93.48 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.063255
  validation loss:		0.247149
  validation accuracy:		93.48 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.064198
  validation loss:		0.253192
  validation accuracy:		93.70 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.064637
  validation loss:		0.247754
  validation accuracy:		93.59 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.064453
  validation loss:		0.248410
  validation accuracy:		93.15 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.060128
  validation loss:		0.242010
  validation accuracy:		93.37 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.061787
  validation loss:		0.250954
  validation accuracy:		93.15 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.063776
  validation loss:		0.251720
  validation accuracy:		93.26 %
Epoch 552 of 2000 took 0.036s
  training loss:		0.061808
  validation loss:		0.245415
  validation accuracy:		93.15 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.062894
  validation loss:		0.254487
  validation accuracy:		93.15 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.062798
  validation loss:		0.242146
  validation accuracy:		93.70 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.062887
  validation loss:		0.247491
  validation accuracy:		93.48 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.063395
  validation loss:		0.245032
  validation accuracy:		93.59 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.061696
  validation loss:		0.247935
  validation accuracy:		93.26 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.058439
  validation loss:		0.249935
  validation accuracy:		93.37 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.062525
  validation loss:		0.249167
  validation accuracy:		93.37 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.061716
  validation loss:		0.247901
  validation accuracy:		93.37 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.061723
  validation loss:		0.251379
  validation accuracy:		93.15 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.062752
  validation loss:		0.250818
  validation accuracy:		93.26 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.059576
  validation loss:		0.244943
  validation accuracy:		93.37 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.059607
  validation loss:		0.248203
  validation accuracy:		93.37 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.061196
  validation loss:		0.246652
  validation accuracy:		93.26 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.059924
  validation loss:		0.250996
  validation accuracy:		93.37 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.061502
  validation loss:		0.255211
  validation accuracy:		93.04 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.060200
  validation loss:		0.254855
  validation accuracy:		93.04 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.060896
  validation loss:		0.248621
  validation accuracy:		93.48 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.062546
  validation loss:		0.249866
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.059509
  validation loss:		0.247978
  validation accuracy:		93.48 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.059921
  validation loss:		0.247457
  validation accuracy:		93.15 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.058483
  validation loss:		0.250804
  validation accuracy:		93.48 %
Epoch 574 of 2000 took 0.036s
  training loss:		0.057618
  validation loss:		0.245508
  validation accuracy:		93.59 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.059954
  validation loss:		0.254551
  validation accuracy:		93.15 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.060529
  validation loss:		0.245787
  validation accuracy:		93.80 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.058903
  validation loss:		0.252954
  validation accuracy:		93.48 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.056008
  validation loss:		0.255783
  validation accuracy:		93.26 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.057506
  validation loss:		0.252985
  validation accuracy:		93.37 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.059035
  validation loss:		0.259455
  validation accuracy:		93.37 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.057230
  validation loss:		0.251498
  validation accuracy:		93.48 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.059114
  validation loss:		0.253090
  validation accuracy:		93.48 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.057975
  validation loss:		0.254115
  validation accuracy:		93.04 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.058854
  validation loss:		0.250614
  validation accuracy:		93.37 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.058253
  validation loss:		0.260607
  validation accuracy:		93.37 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.058306
  validation loss:		0.254939
  validation accuracy:		93.37 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.057071
  validation loss:		0.255435
  validation accuracy:		93.26 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.054579
  validation loss:		0.252202
  validation accuracy:		93.15 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.056681
  validation loss:		0.254557
  validation accuracy:		93.37 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.057925
  validation loss:		0.261307
  validation accuracy:		93.15 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.058518
  validation loss:		0.247553
  validation accuracy:		93.48 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.056681
  validation loss:		0.257344
  validation accuracy:		93.15 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.058080
  validation loss:		0.251354
  validation accuracy:		93.37 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.057957
  validation loss:		0.255707
  validation accuracy:		93.04 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.055539
  validation loss:		0.254299
  validation accuracy:		93.26 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.054893
  validation loss:		0.254689
  validation accuracy:		93.26 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.055501
  validation loss:		0.253016
  validation accuracy:		93.70 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.057933
  validation loss:		0.260728
  validation accuracy:		93.04 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.055725
  validation loss:		0.262634
  validation accuracy:		93.15 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.055147
  validation loss:		0.256029
  validation accuracy:		93.37 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.055896
  validation loss:		0.258320
  validation accuracy:		93.37 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.054843
  validation loss:		0.257393
  validation accuracy:		93.15 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.056972
  validation loss:		0.253898
  validation accuracy:		93.48 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.055398
  validation loss:		0.260723
  validation accuracy:		93.26 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.053914
  validation loss:		0.259362
  validation accuracy:		93.26 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.057215
  validation loss:		0.255827
  validation accuracy:		93.37 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.054131
  validation loss:		0.254530
  validation accuracy:		93.26 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.055672
  validation loss:		0.261183
  validation accuracy:		93.15 %
Epoch 609 of 2000 took 0.036s
  training loss:		0.053250
  validation loss:		0.261491
  validation accuracy:		93.15 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.054047
  validation loss:		0.261733
  validation accuracy:		93.37 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.051980
  validation loss:		0.263297
  validation accuracy:		93.37 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.053977
  validation loss:		0.261387
  validation accuracy:		93.37 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.052719
  validation loss:		0.257029
  validation accuracy:		93.26 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.054108
  validation loss:		0.270830
  validation accuracy:		93.26 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.055245
  validation loss:		0.263195
  validation accuracy:		93.15 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.055212
  validation loss:		0.260697
  validation accuracy:		93.15 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.054215
  validation loss:		0.261248
  validation accuracy:		93.15 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.050260
  validation loss:		0.261976
  validation accuracy:		93.48 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.052178
  validation loss:		0.255805
  validation accuracy:		93.48 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.052578
  validation loss:		0.274246
  validation accuracy:		93.26 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.053646
  validation loss:		0.261162
  validation accuracy:		93.04 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.054463
  validation loss:		0.261119
  validation accuracy:		93.37 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.053561
  validation loss:		0.259192
  validation accuracy:		93.48 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.054799
  validation loss:		0.265198
  validation accuracy:		93.48 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.053841
  validation loss:		0.257219
  validation accuracy:		93.26 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.053245
  validation loss:		0.262939
  validation accuracy:		93.26 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.051926
  validation loss:		0.264168
  validation accuracy:		93.15 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.052866
  validation loss:		0.265185
  validation accuracy:		93.15 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.052254
  validation loss:		0.260493
  validation accuracy:		93.26 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.051042
  validation loss:		0.263022
  validation accuracy:		93.26 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.052296
  validation loss:		0.266293
  validation accuracy:		93.15 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.051460
  validation loss:		0.260114
  validation accuracy:		93.48 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.051267
  validation loss:		0.263690
  validation accuracy:		93.15 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.051005
  validation loss:		0.262198
  validation accuracy:		93.37 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.051873
  validation loss:		0.259650
  validation accuracy:		93.04 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.051351
  validation loss:		0.263991
  validation accuracy:		93.26 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.051127
  validation loss:		0.269528
  validation accuracy:		93.26 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.050460
  validation loss:		0.267911
  validation accuracy:		93.04 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.052260
  validation loss:		0.264030
  validation accuracy:		93.15 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.050772
  validation loss:		0.265957
  validation accuracy:		92.93 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.050326
  validation loss:		0.264496
  validation accuracy:		93.37 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.049692
  validation loss:		0.268644
  validation accuracy:		93.59 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.050678
  validation loss:		0.266151
  validation accuracy:		93.04 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.050725
  validation loss:		0.263958
  validation accuracy:		93.04 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.050214
  validation loss:		0.265404
  validation accuracy:		93.37 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.049425
  validation loss:		0.262088
  validation accuracy:		93.37 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.050504
  validation loss:		0.266654
  validation accuracy:		93.15 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.049594
  validation loss:		0.263739
  validation accuracy:		93.37 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.049698
  validation loss:		0.266280
  validation accuracy:		93.04 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.050396
  validation loss:		0.262306
  validation accuracy:		93.15 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.051040
  validation loss:		0.263720
  validation accuracy:		93.37 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.051412
  validation loss:		0.263908
  validation accuracy:		93.37 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.047897
  validation loss:		0.265733
  validation accuracy:		93.26 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.050096
  validation loss:		0.266344
  validation accuracy:		93.48 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.048912
  validation loss:		0.268760
  validation accuracy:		93.15 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.048671
  validation loss:		0.272915
  validation accuracy:		93.37 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.050286
  validation loss:		0.274977
  validation accuracy:		92.83 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.050980
  validation loss:		0.275263
  validation accuracy:		93.26 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.049761
  validation loss:		0.266997
  validation accuracy:		93.15 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.048376
  validation loss:		0.276189
  validation accuracy:		93.37 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.048771
  validation loss:		0.268441
  validation accuracy:		93.04 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.048072
  validation loss:		0.270257
  validation accuracy:		93.48 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.047120
  validation loss:		0.270681
  validation accuracy:		93.15 %
Epoch 664 of 2000 took 0.036s
  training loss:		0.047561
  validation loss:		0.262533
  validation accuracy:		93.37 %
Epoch 665 of 2000 took 0.036s
  training loss:		0.049718
  validation loss:		0.272974
  validation accuracy:		93.15 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.047431
  validation loss:		0.271501
  validation accuracy:		92.83 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.049477
  validation loss:		0.267189
  validation accuracy:		93.04 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.047012
  validation loss:		0.270465
  validation accuracy:		93.26 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.045195
  validation loss:		0.269123
  validation accuracy:		93.26 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.047146
  validation loss:		0.269986
  validation accuracy:		93.26 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.046533
  validation loss:		0.268015
  validation accuracy:		93.15 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.046726
  validation loss:		0.265147
  validation accuracy:		93.37 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.048561
  validation loss:		0.279099
  validation accuracy:		93.26 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.045533
  validation loss:		0.278029
  validation accuracy:		93.37 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.050247
  validation loss:		0.274181
  validation accuracy:		93.15 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.047300
  validation loss:		0.268350
  validation accuracy:		93.37 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.046444
  validation loss:		0.267161
  validation accuracy:		93.37 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.046918
  validation loss:		0.270574
  validation accuracy:		93.15 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.046916
  validation loss:		0.272523
  validation accuracy:		93.15 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.045524
  validation loss:		0.273751
  validation accuracy:		92.93 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.047367
  validation loss:		0.269697
  validation accuracy:		93.26 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.047679
  validation loss:		0.276095
  validation accuracy:		93.26 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.045425
  validation loss:		0.275276
  validation accuracy:		93.26 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.047101
  validation loss:		0.276418
  validation accuracy:		93.04 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.045056
  validation loss:		0.275757
  validation accuracy:		92.93 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.045555
  validation loss:		0.271593
  validation accuracy:		93.15 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.047229
  validation loss:		0.280245
  validation accuracy:		93.04 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.045998
  validation loss:		0.272977
  validation accuracy:		93.15 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.043570
  validation loss:		0.274324
  validation accuracy:		92.83 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.044392
  validation loss:		0.279093
  validation accuracy:		93.26 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.043666
  validation loss:		0.273283
  validation accuracy:		93.48 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.044313
  validation loss:		0.279074
  validation accuracy:		93.15 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.046175
  validation loss:		0.273071
  validation accuracy:		93.04 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.046375
  validation loss:		0.277302
  validation accuracy:		93.26 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.045250
  validation loss:		0.285021
  validation accuracy:		93.26 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.045327
  validation loss:		0.275928
  validation accuracy:		93.04 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.045738
  validation loss:		0.273649
  validation accuracy:		93.15 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.041628
  validation loss:		0.283253
  validation accuracy:		93.37 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.044621
  validation loss:		0.276256
  validation accuracy:		92.93 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.043429
  validation loss:		0.273017
  validation accuracy:		92.93 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.042600
  validation loss:		0.271247
  validation accuracy:		93.04 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.044905
  validation loss:		0.277671
  validation accuracy:		92.93 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.044477
  validation loss:		0.277329
  validation accuracy:		93.26 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.044256
  validation loss:		0.282700
  validation accuracy:		93.26 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.042947
  validation loss:		0.274757
  validation accuracy:		93.15 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.043044
  validation loss:		0.275256
  validation accuracy:		93.04 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.043109
  validation loss:		0.287321
  validation accuracy:		93.26 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.043529
  validation loss:		0.272806
  validation accuracy:		93.37 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.041925
  validation loss:		0.278779
  validation accuracy:		92.93 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.043754
  validation loss:		0.276360
  validation accuracy:		93.26 %
Epoch 711 of 2000 took 0.036s
  training loss:		0.043042
  validation loss:		0.280969
  validation accuracy:		93.04 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.042083
  validation loss:		0.281290
  validation accuracy:		93.26 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.043991
  validation loss:		0.277709
  validation accuracy:		92.93 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.042621
  validation loss:		0.278021
  validation accuracy:		93.26 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.042728
  validation loss:		0.281368
  validation accuracy:		93.26 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.042258
  validation loss:		0.298268
  validation accuracy:		93.26 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.043721
  validation loss:		0.274646
  validation accuracy:		93.04 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.043035
  validation loss:		0.286498
  validation accuracy:		93.15 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.042836
  validation loss:		0.277527
  validation accuracy:		93.26 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.041526
  validation loss:		0.276453
  validation accuracy:		93.26 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.040978
  validation loss:		0.282101
  validation accuracy:		93.04 %
Epoch 722 of 2000 took 0.036s
  training loss:		0.040875
  validation loss:		0.280475
  validation accuracy:		92.93 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.042162
  validation loss:		0.278352
  validation accuracy:		92.93 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.041053
  validation loss:		0.279491
  validation accuracy:		92.93 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.041813
  validation loss:		0.281317
  validation accuracy:		93.04 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.041327
  validation loss:		0.277090
  validation accuracy:		93.37 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.040876
  validation loss:		0.279254
  validation accuracy:		93.15 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.042241
  validation loss:		0.275965
  validation accuracy:		93.04 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.042141
  validation loss:		0.281753
  validation accuracy:		93.26 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.041159
  validation loss:		0.277715
  validation accuracy:		93.04 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.041709
  validation loss:		0.281705
  validation accuracy:		93.37 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.040325
  validation loss:		0.277092
  validation accuracy:		93.04 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.042953
  validation loss:		0.279097
  validation accuracy:		93.04 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.040275
  validation loss:		0.284195
  validation accuracy:		93.04 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.041840
  validation loss:		0.279220
  validation accuracy:		93.26 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.040021
  validation loss:		0.278735
  validation accuracy:		93.15 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.039918
  validation loss:		0.286125
  validation accuracy:		93.04 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.038294
  validation loss:		0.275859
  validation accuracy:		93.15 %
Epoch 739 of 2000 took 0.036s
  training loss:		0.041771
  validation loss:		0.283342
  validation accuracy:		93.15 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.039555
  validation loss:		0.294435
  validation accuracy:		93.48 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.040554
  validation loss:		0.279238
  validation accuracy:		93.37 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.040344
  validation loss:		0.286101
  validation accuracy:		93.26 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.041840
  validation loss:		0.292471
  validation accuracy:		93.15 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.040085
  validation loss:		0.284637
  validation accuracy:		93.15 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.039100
  validation loss:		0.284648
  validation accuracy:		93.26 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.039755
  validation loss:		0.290165
  validation accuracy:		93.26 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.037570
  validation loss:		0.284229
  validation accuracy:		92.93 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.039991
  validation loss:		0.282790
  validation accuracy:		93.04 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.040551
  validation loss:		0.285501
  validation accuracy:		93.04 %
Epoch 750 of 2000 took 0.036s
  training loss:		0.039419
  validation loss:		0.283405
  validation accuracy:		93.37 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.039410
  validation loss:		0.301329
  validation accuracy:		93.37 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.039562
  validation loss:		0.292970
  validation accuracy:		93.04 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.038364
  validation loss:		0.295920
  validation accuracy:		93.48 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.040270
  validation loss:		0.286382
  validation accuracy:		93.15 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.039234
  validation loss:		0.292492
  validation accuracy:		93.37 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.038405
  validation loss:		0.283372
  validation accuracy:		93.26 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.039801
  validation loss:		0.292564
  validation accuracy:		93.15 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.039025
  validation loss:		0.291726
  validation accuracy:		93.04 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.037766
  validation loss:		0.288028
  validation accuracy:		93.15 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.037737
  validation loss:		0.284482
  validation accuracy:		93.04 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.037890
  validation loss:		0.291854
  validation accuracy:		93.04 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.037896
  validation loss:		0.284133
  validation accuracy:		93.37 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.038806
  validation loss:		0.284642
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.039348
  validation loss:		0.287140
  validation accuracy:		93.04 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.037330
  validation loss:		0.291016
  validation accuracy:		93.04 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.037270
  validation loss:		0.288380
  validation accuracy:		93.26 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.037692
  validation loss:		0.289238
  validation accuracy:		93.26 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.037887
  validation loss:		0.290611
  validation accuracy:		93.15 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.037849
  validation loss:		0.295591
  validation accuracy:		93.26 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.038113
  validation loss:		0.291223
  validation accuracy:		93.04 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.037028
  validation loss:		0.295852
  validation accuracy:		93.26 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.037456
  validation loss:		0.297106
  validation accuracy:		93.04 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.038075
  validation loss:		0.288557
  validation accuracy:		93.15 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.036209
  validation loss:		0.294611
  validation accuracy:		93.59 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.038608
  validation loss:		0.298677
  validation accuracy:		93.04 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.037641
  validation loss:		0.292613
  validation accuracy:		93.04 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.036820
  validation loss:		0.288891
  validation accuracy:		93.15 %
Epoch 778 of 2000 took 0.036s
  training loss:		0.036004
  validation loss:		0.297751
  validation accuracy:		93.15 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.037385
  validation loss:		0.287816
  validation accuracy:		93.04 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.036723
  validation loss:		0.295111
  validation accuracy:		93.26 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.036171
  validation loss:		0.297690
  validation accuracy:		93.04 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.035967
  validation loss:		0.294578
  validation accuracy:		93.26 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.036165
  validation loss:		0.291980
  validation accuracy:		93.37 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.037806
  validation loss:		0.297945
  validation accuracy:		93.26 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.037366
  validation loss:		0.288266
  validation accuracy:		93.15 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.035719
  validation loss:		0.294980
  validation accuracy:		93.26 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.036954
  validation loss:		0.289170
  validation accuracy:		93.26 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.035358
  validation loss:		0.288672
  validation accuracy:		93.26 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.035106
  validation loss:		0.296752
  validation accuracy:		92.93 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.035908
  validation loss:		0.295102
  validation accuracy:		93.15 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.035265
  validation loss:		0.289847
  validation accuracy:		93.26 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.035113
  validation loss:		0.290754
  validation accuracy:		93.26 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.035398
  validation loss:		0.292354
  validation accuracy:		93.15 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.036321
  validation loss:		0.293201
  validation accuracy:		93.26 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.033960
  validation loss:		0.297861
  validation accuracy:		93.15 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.035827
  validation loss:		0.297030
  validation accuracy:		93.15 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.035555
  validation loss:		0.292558
  validation accuracy:		93.15 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.035837
  validation loss:		0.293123
  validation accuracy:		93.15 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.034605
  validation loss:		0.294363
  validation accuracy:		92.93 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.035028
  validation loss:		0.298152
  validation accuracy:		93.04 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.035332
  validation loss:		0.295257
  validation accuracy:		93.15 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.036086
  validation loss:		0.288813
  validation accuracy:		93.26 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.035218
  validation loss:		0.294337
  validation accuracy:		93.26 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.033855
  validation loss:		0.300658
  validation accuracy:		93.26 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.034506
  validation loss:		0.291115
  validation accuracy:		93.15 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.035338
  validation loss:		0.295558
  validation accuracy:		93.15 %
Epoch 807 of 2000 took 0.036s
  training loss:		0.034050
  validation loss:		0.307616
  validation accuracy:		93.26 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.034713
  validation loss:		0.307751
  validation accuracy:		93.04 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.035048
  validation loss:		0.299722
  validation accuracy:		93.15 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.033481
  validation loss:		0.289093
  validation accuracy:		93.26 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.034470
  validation loss:		0.309042
  validation accuracy:		93.04 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.034526
  validation loss:		0.296716
  validation accuracy:		93.15 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.034935
  validation loss:		0.304145
  validation accuracy:		93.04 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.033925
  validation loss:		0.300000
  validation accuracy:		93.15 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.033458
  validation loss:		0.302244
  validation accuracy:		93.26 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.034330
  validation loss:		0.303213
  validation accuracy:		93.04 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.032826
  validation loss:		0.294756
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.034369
  validation loss:		0.303841
  validation accuracy:		93.26 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.033440
  validation loss:		0.299504
  validation accuracy:		93.15 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.033149
  validation loss:		0.303264
  validation accuracy:		93.26 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.033162
  validation loss:		0.300878
  validation accuracy:		93.37 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.033825
  validation loss:		0.298744
  validation accuracy:		93.26 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.033290
  validation loss:		0.303747
  validation accuracy:		93.04 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.032993
  validation loss:		0.297242
  validation accuracy:		93.15 %
Epoch 825 of 2000 took 0.037s
  training loss:		0.032843
  validation loss:		0.307073
  validation accuracy:		93.15 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.033473
  validation loss:		0.301758
  validation accuracy:		93.15 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.032616
  validation loss:		0.300912
  validation accuracy:		93.15 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.032151
  validation loss:		0.301289
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.036s
  training loss:		0.032231
  validation loss:		0.305583
  validation accuracy:		92.93 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.031878
  validation loss:		0.314391
  validation accuracy:		93.26 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.032688
  validation loss:		0.302938
  validation accuracy:		93.26 %
Epoch 832 of 2000 took 0.036s
  training loss:		0.033176
  validation loss:		0.296516
  validation accuracy:		93.15 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.032891
  validation loss:		0.297443
  validation accuracy:		93.15 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.033398
  validation loss:		0.301422
  validation accuracy:		93.04 %
Epoch 835 of 2000 took 0.036s
  training loss:		0.032258
  validation loss:		0.305156
  validation accuracy:		93.26 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.030463
  validation loss:		0.300407
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.036s
  training loss:		0.032926
  validation loss:		0.301558
  validation accuracy:		93.15 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.032160
  validation loss:		0.295516
  validation accuracy:		93.15 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.032544
  validation loss:		0.305034
  validation accuracy:		93.04 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.032127
  validation loss:		0.301620
  validation accuracy:		93.26 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.032153
  validation loss:		0.311104
  validation accuracy:		93.04 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.030652
  validation loss:		0.306512
  validation accuracy:		92.93 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.031026
  validation loss:		0.298701
  validation accuracy:		93.15 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.031312
  validation loss:		0.302010
  validation accuracy:		93.26 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.031551
  validation loss:		0.304575
  validation accuracy:		93.26 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.031110
  validation loss:		0.299963
  validation accuracy:		93.15 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.032288
  validation loss:		0.307855
  validation accuracy:		93.26 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.030713
  validation loss:		0.302861
  validation accuracy:		93.04 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.031933
  validation loss:		0.307076
  validation accuracy:		93.04 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.032025
  validation loss:		0.301046
  validation accuracy:		93.15 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.029602
  validation loss:		0.297256
  validation accuracy:		93.48 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.030940
  validation loss:		0.310947
  validation accuracy:		93.15 %
Epoch 853 of 2000 took 0.036s
  training loss:		0.030460
  validation loss:		0.300311
  validation accuracy:		93.04 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.029773
  validation loss:		0.305064
  validation accuracy:		93.26 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.031520
  validation loss:		0.302141
  validation accuracy:		93.04 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.031014
  validation loss:		0.306672
  validation accuracy:		93.26 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.030906
  validation loss:		0.314562
  validation accuracy:		92.83 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.030405
  validation loss:		0.306981
  validation accuracy:		93.26 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.030890
  validation loss:		0.308863
  validation accuracy:		93.15 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.030166
  validation loss:		0.308354
  validation accuracy:		93.26 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.030664
  validation loss:		0.307355
  validation accuracy:		93.04 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.030226
  validation loss:		0.315394
  validation accuracy:		93.26 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.030753
  validation loss:		0.312290
  validation accuracy:		93.04 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.030045
  validation loss:		0.312206
  validation accuracy:		93.04 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.029284
  validation loss:		0.312534
  validation accuracy:		93.26 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.029520
  validation loss:		0.314798
  validation accuracy:		93.04 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.031153
  validation loss:		0.312883
  validation accuracy:		93.15 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.030679
  validation loss:		0.309659
  validation accuracy:		93.26 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.030102
  validation loss:		0.311240
  validation accuracy:		93.15 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.029282
  validation loss:		0.318979
  validation accuracy:		93.37 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.030489
  validation loss:		0.310731
  validation accuracy:		93.26 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.029846
  validation loss:		0.309375
  validation accuracy:		92.93 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.030415
  validation loss:		0.307928
  validation accuracy:		93.15 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.028036
  validation loss:		0.318449
  validation accuracy:		93.26 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.029507
  validation loss:		0.328301
  validation accuracy:		93.37 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.029573
  validation loss:		0.309455
  validation accuracy:		93.04 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.029558
  validation loss:		0.309840
  validation accuracy:		93.04 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.029969
  validation loss:		0.308066
  validation accuracy:		93.15 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.028485
  validation loss:		0.316198
  validation accuracy:		93.04 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.029868
  validation loss:		0.305018
  validation accuracy:		93.26 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.029652
  validation loss:		0.306350
  validation accuracy:		93.15 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.026904
  validation loss:		0.310995
  validation accuracy:		93.15 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.029131
  validation loss:		0.315037
  validation accuracy:		93.04 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.029627
  validation loss:		0.313512
  validation accuracy:		93.15 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.029157
  validation loss:		0.317481
  validation accuracy:		93.15 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.029269
  validation loss:		0.311541
  validation accuracy:		93.26 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.027455
  validation loss:		0.315314
  validation accuracy:		93.04 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.028961
  validation loss:		0.317724
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.027333
  validation loss:		0.310343
  validation accuracy:		93.26 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.028066
  validation loss:		0.314024
  validation accuracy:		93.04 %
Epoch 891 of 2000 took 0.036s
  training loss:		0.028250
  validation loss:		0.321018
  validation accuracy:		93.37 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.028596
  validation loss:		0.320706
  validation accuracy:		93.15 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.026970
  validation loss:		0.314254
  validation accuracy:		93.15 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.027733
  validation loss:		0.320799
  validation accuracy:		93.15 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.027884
  validation loss:		0.311534
  validation accuracy:		93.26 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.028538
  validation loss:		0.320675
  validation accuracy:		93.15 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.027826
  validation loss:		0.317998
  validation accuracy:		93.15 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.028067
  validation loss:		0.309968
  validation accuracy:		93.37 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.028226
  validation loss:		0.312573
  validation accuracy:		93.26 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.028247
  validation loss:		0.307814
  validation accuracy:		93.26 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.027457
  validation loss:		0.311925
  validation accuracy:		93.04 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.025621
  validation loss:		0.320552
  validation accuracy:		93.15 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.026632
  validation loss:		0.320812
  validation accuracy:		93.04 %
Epoch 904 of 2000 took 0.036s
  training loss:		0.027175
  validation loss:		0.311128
  validation accuracy:		93.26 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.028189
  validation loss:		0.318730
  validation accuracy:		93.15 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.027751
  validation loss:		0.318192
  validation accuracy:		93.26 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.026951
  validation loss:		0.323356
  validation accuracy:		93.37 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.027355
  validation loss:		0.320653
  validation accuracy:		92.93 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.026271
  validation loss:		0.313356
  validation accuracy:		93.15 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.026843
  validation loss:		0.328947
  validation accuracy:		93.26 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.027451
  validation loss:		0.312210
  validation accuracy:		93.15 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.027473
  validation loss:		0.317741
  validation accuracy:		93.26 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.026662
  validation loss:		0.314098
  validation accuracy:		93.26 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.026511
  validation loss:		0.317504
  validation accuracy:		93.37 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.027093
  validation loss:		0.329430
  validation accuracy:		93.37 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.027104
  validation loss:		0.318553
  validation accuracy:		93.15 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.026555
  validation loss:		0.321999
  validation accuracy:		93.26 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.025551
  validation loss:		0.317566
  validation accuracy:		93.15 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.026719
  validation loss:		0.317806
  validation accuracy:		93.26 %
Epoch 920 of 2000 took 0.036s
  training loss:		0.026950
  validation loss:		0.324379
  validation accuracy:		93.15 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.026291
  validation loss:		0.327182
  validation accuracy:		93.48 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.025371
  validation loss:		0.318192
  validation accuracy:		93.15 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.028106
  validation loss:		0.319299
  validation accuracy:		93.15 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.026662
  validation loss:		0.322340
  validation accuracy:		93.15 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.025941
  validation loss:		0.316230
  validation accuracy:		93.04 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.025043
  validation loss:		0.318627
  validation accuracy:		93.04 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.024946
  validation loss:		0.325072
  validation accuracy:		93.15 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.026443
  validation loss:		0.324058
  validation accuracy:		93.15 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.025554
  validation loss:		0.327973
  validation accuracy:		93.15 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.025277
  validation loss:		0.322857
  validation accuracy:		93.04 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.026331
  validation loss:		0.321997
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.026147
  validation loss:		0.327154
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.025876
  validation loss:		0.323243
  validation accuracy:		93.26 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.026004
  validation loss:		0.317808
  validation accuracy:		93.15 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.024524
  validation loss:		0.328703
  validation accuracy:		93.15 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.025268
  validation loss:		0.324022
  validation accuracy:		93.15 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.025633
  validation loss:		0.317125
  validation accuracy:		93.26 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.025056
  validation loss:		0.329562
  validation accuracy:		93.15 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.025630
  validation loss:		0.326088
  validation accuracy:		93.04 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.024890
  validation loss:		0.325181
  validation accuracy:		93.04 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.025542
  validation loss:		0.328643
  validation accuracy:		93.04 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.025659
  validation loss:		0.323706
  validation accuracy:		93.26 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.024828
  validation loss:		0.327213
  validation accuracy:		93.26 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.025040
  validation loss:		0.325736
  validation accuracy:		93.37 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.024878
  validation loss:		0.330511
  validation accuracy:		93.15 %
Epoch 946 of 2000 took 0.036s
  training loss:		0.024253
  validation loss:		0.326749
  validation accuracy:		93.37 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.024545
  validation loss:		0.321780
  validation accuracy:		93.26 %
Epoch 948 of 2000 took 0.036s
  training loss:		0.025006
  validation loss:		0.327054
  validation accuracy:		93.15 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.024763
  validation loss:		0.325189
  validation accuracy:		93.26 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.024748
  validation loss:		0.324267
  validation accuracy:		93.15 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.024762
  validation loss:		0.328660
  validation accuracy:		93.04 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.024126
  validation loss:		0.327560
  validation accuracy:		92.93 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.025968
  validation loss:		0.323983
  validation accuracy:		93.04 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.024262
  validation loss:		0.336661
  validation accuracy:		93.26 %
Epoch 955 of 2000 took 0.036s
  training loss:		0.023796
  validation loss:		0.330832
  validation accuracy:		93.15 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.024442
  validation loss:		0.326274
  validation accuracy:		93.15 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.024273
  validation loss:		0.330469
  validation accuracy:		92.93 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.024154
  validation loss:		0.328752
  validation accuracy:		93.04 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.024474
  validation loss:		0.331982
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.023900
  validation loss:		0.336574
  validation accuracy:		93.15 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.024698
  validation loss:		0.327761
  validation accuracy:		93.26 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.023637
  validation loss:		0.328516
  validation accuracy:		93.37 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.023762
  validation loss:		0.326905
  validation accuracy:		93.26 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.023300
  validation loss:		0.332636
  validation accuracy:		93.26 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.023124
  validation loss:		0.336969
  validation accuracy:		93.37 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.023194
  validation loss:		0.336761
  validation accuracy:		93.26 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.024222
  validation loss:		0.332710
  validation accuracy:		93.04 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.024144
  validation loss:		0.333514
  validation accuracy:		93.15 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.024154
  validation loss:		0.326010
  validation accuracy:		93.26 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.023964
  validation loss:		0.329364
  validation accuracy:		93.04 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.023589
  validation loss:		0.323173
  validation accuracy:		93.37 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.024669
  validation loss:		0.331522
  validation accuracy:		93.04 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.023832
  validation loss:		0.326119
  validation accuracy:		93.15 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.024403
  validation loss:		0.327242
  validation accuracy:		93.15 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.023598
  validation loss:		0.328476
  validation accuracy:		93.15 %
Epoch 976 of 2000 took 0.036s
  training loss:		0.022050
  validation loss:		0.339399
  validation accuracy:		93.26 %
Epoch 977 of 2000 took 0.036s
  training loss:		0.023237
  validation loss:		0.323360
  validation accuracy:		93.37 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.023557
  validation loss:		0.333545
  validation accuracy:		93.15 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.023882
  validation loss:		0.330036
  validation accuracy:		93.04 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.022598
  validation loss:		0.335053
  validation accuracy:		92.93 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.023933
  validation loss:		0.334730
  validation accuracy:		93.26 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.023248
  validation loss:		0.335642
  validation accuracy:		92.93 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.022778
  validation loss:		0.337542
  validation accuracy:		93.26 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.022763
  validation loss:		0.338811
  validation accuracy:		93.15 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.022720
  validation loss:		0.330190
  validation accuracy:		93.26 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.022580
  validation loss:		0.339162
  validation accuracy:		92.93 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.022287
  validation loss:		0.340767
  validation accuracy:		93.48 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.023193
  validation loss:		0.336803
  validation accuracy:		93.26 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.020689
  validation loss:		0.335292
  validation accuracy:		92.93 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.022448
  validation loss:		0.332588
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.022077
  validation loss:		0.336076
  validation accuracy:		93.26 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.022753
  validation loss:		0.342983
  validation accuracy:		93.26 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.022807
  validation loss:		0.339059
  validation accuracy:		92.93 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.022714
  validation loss:		0.344517
  validation accuracy:		93.26 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.021442
  validation loss:		0.342650
  validation accuracy:		92.93 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.022145
  validation loss:		0.334454
  validation accuracy:		93.15 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.021071
  validation loss:		0.335426
  validation accuracy:		93.37 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.022242
  validation loss:		0.338542
  validation accuracy:		93.15 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.022619
  validation loss:		0.339968
  validation accuracy:		93.59 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.022666
  validation loss:		0.341464
  validation accuracy:		93.04 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.021416
  validation loss:		0.324995
  validation accuracy:		93.37 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.022188
  validation loss:		0.333418
  validation accuracy:		93.15 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.023324
  validation loss:		0.332623
  validation accuracy:		93.15 %
Epoch 1004 of 2000 took 0.036s
  training loss:		0.022021
  validation loss:		0.337542
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.036s
  training loss:		0.021366
  validation loss:		0.334751
  validation accuracy:		93.15 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.021719
  validation loss:		0.329301
  validation accuracy:		93.37 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.021744
  validation loss:		0.337398
  validation accuracy:		93.15 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.020894
  validation loss:		0.343031
  validation accuracy:		93.15 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.022031
  validation loss:		0.337380
  validation accuracy:		92.93 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.021591
  validation loss:		0.343809
  validation accuracy:		93.04 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.021624
  validation loss:		0.338398
  validation accuracy:		92.93 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.021405
  validation loss:		0.329943
  validation accuracy:		93.15 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.021805
  validation loss:		0.340720
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.021656
  validation loss:		0.334322
  validation accuracy:		93.15 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.021810
  validation loss:		0.344995
  validation accuracy:		92.93 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.021633
  validation loss:		0.332216
  validation accuracy:		93.26 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.020829
  validation loss:		0.343759
  validation accuracy:		93.04 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.022371
  validation loss:		0.347995
  validation accuracy:		92.83 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.021239
  validation loss:		0.340735
  validation accuracy:		92.93 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.021113
  validation loss:		0.348524
  validation accuracy:		93.26 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.021129
  validation loss:		0.337591
  validation accuracy:		93.15 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.020641
  validation loss:		0.336882
  validation accuracy:		93.26 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.020673
  validation loss:		0.336323
  validation accuracy:		93.15 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.019986
  validation loss:		0.330844
  validation accuracy:		93.15 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.020714
  validation loss:		0.342851
  validation accuracy:		93.04 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.020958
  validation loss:		0.339235
  validation accuracy:		93.26 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.020522
  validation loss:		0.343521
  validation accuracy:		93.15 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.020537
  validation loss:		0.341723
  validation accuracy:		92.93 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.018257
  validation loss:		0.342775
  validation accuracy:		93.26 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.020709
  validation loss:		0.344037
  validation accuracy:		93.04 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.020601
  validation loss:		0.338000
  validation accuracy:		93.37 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.020182
  validation loss:		0.349835
  validation accuracy:		92.93 %
Epoch 1033 of 2000 took 0.036s
  training loss:		0.020232
  validation loss:		0.344404
  validation accuracy:		93.15 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.021883
  validation loss:		0.343205
  validation accuracy:		93.37 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.020000
  validation loss:		0.345403
  validation accuracy:		92.93 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.020235
  validation loss:		0.342485
  validation accuracy:		92.93 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.020499
  validation loss:		0.343367
  validation accuracy:		93.04 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.020532
  validation loss:		0.348043
  validation accuracy:		92.93 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.020323
  validation loss:		0.341629
  validation accuracy:		93.15 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.019741
  validation loss:		0.346521
  validation accuracy:		93.04 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.020611
  validation loss:		0.349495
  validation accuracy:		92.93 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.020054
  validation loss:		0.351670
  validation accuracy:		93.15 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.019782
  validation loss:		0.344199
  validation accuracy:		93.26 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.019416
  validation loss:		0.346384
  validation accuracy:		93.04 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.019657
  validation loss:		0.346617
  validation accuracy:		93.04 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.019166
  validation loss:		0.342170
  validation accuracy:		93.26 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.019531
  validation loss:		0.353674
  validation accuracy:		93.26 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.019339
  validation loss:		0.345953
  validation accuracy:		93.15 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.019484
  validation loss:		0.347296
  validation accuracy:		92.93 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.019578
  validation loss:		0.342987
  validation accuracy:		93.26 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.019936
  validation loss:		0.356728
  validation accuracy:		93.04 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.019867
  validation loss:		0.356253
  validation accuracy:		93.26 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.019297
  validation loss:		0.348340
  validation accuracy:		92.93 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.019642
  validation loss:		0.352850
  validation accuracy:		93.15 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.019535
  validation loss:		0.349788
  validation accuracy:		93.15 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.019951
  validation loss:		0.347098
  validation accuracy:		93.04 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.019801
  validation loss:		0.345353
  validation accuracy:		93.15 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.018883
  validation loss:		0.344675
  validation accuracy:		93.26 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.019260
  validation loss:		0.347571
  validation accuracy:		93.15 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.018772
  validation loss:		0.351179
  validation accuracy:		93.04 %
Epoch 1061 of 2000 took 0.036s
  training loss:		0.018324
  validation loss:		0.353127
  validation accuracy:		93.15 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.018363
  validation loss:		0.357356
  validation accuracy:		93.04 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.018334
  validation loss:		0.352143
  validation accuracy:		93.15 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.019456
  validation loss:		0.345488
  validation accuracy:		93.37 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.018989
  validation loss:		0.354025
  validation accuracy:		92.93 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.019471
  validation loss:		0.347933
  validation accuracy:		92.93 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.017010
  validation loss:		0.345750
  validation accuracy:		93.26 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.019022
  validation loss:		0.343722
  validation accuracy:		93.15 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.019211
  validation loss:		0.358762
  validation accuracy:		92.72 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.018494
  validation loss:		0.354569
  validation accuracy:		93.04 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.019103
  validation loss:		0.345896
  validation accuracy:		93.15 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.018193
  validation loss:		0.347004
  validation accuracy:		93.48 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.019199
  validation loss:		0.348455
  validation accuracy:		93.04 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.017592
  validation loss:		0.357038
  validation accuracy:		93.15 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.018649
  validation loss:		0.353146
  validation accuracy:		93.04 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.018685
  validation loss:		0.352609
  validation accuracy:		93.26 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.018573
  validation loss:		0.354394
  validation accuracy:		92.83 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.018528
  validation loss:		0.353919
  validation accuracy:		93.04 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.018234
  validation loss:		0.349408
  validation accuracy:		93.26 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.018736
  validation loss:		0.356275
  validation accuracy:		92.93 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.018500
  validation loss:		0.349297
  validation accuracy:		93.15 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.018298
  validation loss:		0.355016
  validation accuracy:		93.37 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.018352
  validation loss:		0.342498
  validation accuracy:		93.26 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.018529
  validation loss:		0.352127
  validation accuracy:		93.26 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.018803
  validation loss:		0.351843
  validation accuracy:		93.15 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.018151
  validation loss:		0.351332
  validation accuracy:		93.26 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.017490
  validation loss:		0.353774
  validation accuracy:		93.04 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.018121
  validation loss:		0.346556
  validation accuracy:		93.26 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.017583
  validation loss:		0.359510
  validation accuracy:		92.93 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.017418
  validation loss:		0.353499
  validation accuracy:		92.83 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.017817
  validation loss:		0.358671
  validation accuracy:		93.04 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.017603
  validation loss:		0.355903
  validation accuracy:		92.83 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.017536
  validation loss:		0.356389
  validation accuracy:		92.83 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.018042
  validation loss:		0.356688
  validation accuracy:		93.48 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.018079
  validation loss:		0.352751
  validation accuracy:		93.04 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.016631
  validation loss:		0.353725
  validation accuracy:		92.93 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.017350
  validation loss:		0.349369
  validation accuracy:		93.04 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.017817
  validation loss:		0.355333
  validation accuracy:		93.04 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.017455
  validation loss:		0.350881
  validation accuracy:		93.26 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.017803
  validation loss:		0.354022
  validation accuracy:		92.93 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.017215
  validation loss:		0.353583
  validation accuracy:		93.04 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.017474
  validation loss:		0.355006
  validation accuracy:		93.04 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.017126
  validation loss:		0.355916
  validation accuracy:		93.26 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.017222
  validation loss:		0.357614
  validation accuracy:		93.26 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.017389
  validation loss:		0.363610
  validation accuracy:		92.93 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.016450
  validation loss:		0.356595
  validation accuracy:		92.83 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.017234
  validation loss:		0.355979
  validation accuracy:		93.04 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.016986
  validation loss:		0.353744
  validation accuracy:		93.15 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.017273
  validation loss:		0.360173
  validation accuracy:		93.04 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.017279
  validation loss:		0.351357
  validation accuracy:		93.37 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.017355
  validation loss:		0.357797
  validation accuracy:		93.26 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.016976
  validation loss:		0.364789
  validation accuracy:		92.93 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.016835
  validation loss:		0.354659
  validation accuracy:		93.04 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.017179
  validation loss:		0.357788
  validation accuracy:		93.26 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.017178
  validation loss:		0.354128
  validation accuracy:		93.26 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.017340
  validation loss:		0.359487
  validation accuracy:		93.26 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.015917
  validation loss:		0.354899
  validation accuracy:		93.37 %
Epoch 1118 of 2000 took 0.036s
  training loss:		0.016612
  validation loss:		0.353845
  validation accuracy:		93.15 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.017132
  validation loss:		0.357036
  validation accuracy:		93.15 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.016686
  validation loss:		0.368706
  validation accuracy:		92.93 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.016865
  validation loss:		0.350975
  validation accuracy:		93.26 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.016347
  validation loss:		0.360438
  validation accuracy:		93.26 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.016559
  validation loss:		0.359850
  validation accuracy:		92.83 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.016582
  validation loss:		0.356686
  validation accuracy:		92.93 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.016432
  validation loss:		0.356794
  validation accuracy:		93.26 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.015932
  validation loss:		0.357331
  validation accuracy:		93.15 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.016000
  validation loss:		0.360765
  validation accuracy:		93.04 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.016590
  validation loss:		0.363466
  validation accuracy:		93.15 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.016718
  validation loss:		0.355992
  validation accuracy:		93.26 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.016637
  validation loss:		0.353553
  validation accuracy:		93.26 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.016356
  validation loss:		0.359806
  validation accuracy:		93.26 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.016260
  validation loss:		0.366178
  validation accuracy:		92.93 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.016408
  validation loss:		0.365353
  validation accuracy:		93.04 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.015565
  validation loss:		0.358038
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.014816
  validation loss:		0.358035
  validation accuracy:		93.04 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.015899
  validation loss:		0.364369
  validation accuracy:		93.15 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.015477
  validation loss:		0.365275
  validation accuracy:		92.93 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.016599
  validation loss:		0.365044
  validation accuracy:		92.93 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.015946
  validation loss:		0.357492
  validation accuracy:		93.26 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.016394
  validation loss:		0.365666
  validation accuracy:		92.83 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.016265
  validation loss:		0.359675
  validation accuracy:		93.04 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.015863
  validation loss:		0.353512
  validation accuracy:		93.26 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.015954
  validation loss:		0.360984
  validation accuracy:		93.26 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.015723
  validation loss:		0.365920
  validation accuracy:		93.04 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.015132
  validation loss:		0.365000
  validation accuracy:		92.83 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.015477
  validation loss:		0.362477
  validation accuracy:		93.04 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.015325
  validation loss:		0.377040
  validation accuracy:		92.83 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.015940
  validation loss:		0.357846
  validation accuracy:		93.15 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.015832
  validation loss:		0.364088
  validation accuracy:		93.26 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.016513
  validation loss:		0.361024
  validation accuracy:		93.15 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.015273
  validation loss:		0.370984
  validation accuracy:		92.93 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.015495
  validation loss:		0.362254
  validation accuracy:		93.04 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.015421
  validation loss:		0.369940
  validation accuracy:		92.83 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.015717
  validation loss:		0.366014
  validation accuracy:		93.04 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.016062
  validation loss:		0.359753
  validation accuracy:		93.26 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.014151
  validation loss:		0.358098
  validation accuracy:		93.26 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.015017
  validation loss:		0.368300
  validation accuracy:		92.93 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.014862
  validation loss:		0.367268
  validation accuracy:		92.93 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.014568
  validation loss:		0.368811
  validation accuracy:		93.15 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.014948
  validation loss:		0.372870
  validation accuracy:		93.04 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.015273
  validation loss:		0.361520
  validation accuracy:		93.26 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.015340
  validation loss:		0.357715
  validation accuracy:		93.15 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.015180
  validation loss:		0.362914
  validation accuracy:		93.37 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.015310
  validation loss:		0.357415
  validation accuracy:		93.48 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.014872
  validation loss:		0.365032
  validation accuracy:		92.93 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.014835
  validation loss:		0.369322
  validation accuracy:		93.04 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.015841
  validation loss:		0.376251
  validation accuracy:		92.72 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.015103
  validation loss:		0.371116
  validation accuracy:		92.83 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.014823
  validation loss:		0.366027
  validation accuracy:		93.15 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.014846
  validation loss:		0.365136
  validation accuracy:		93.04 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.015090
  validation loss:		0.369941
  validation accuracy:		93.15 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.015072
  validation loss:		0.362321
  validation accuracy:		93.15 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.015319
  validation loss:		0.363261
  validation accuracy:		93.04 %
Epoch 1174 of 2000 took 0.036s
  training loss:		0.014165
  validation loss:		0.370953
  validation accuracy:		92.93 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.014960
  validation loss:		0.365640
  validation accuracy:		93.26 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.015044
  validation loss:		0.374597
  validation accuracy:		92.83 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.015650
  validation loss:		0.376469
  validation accuracy:		92.83 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.015040
  validation loss:		0.367160
  validation accuracy:		93.15 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.014822
  validation loss:		0.360649
  validation accuracy:		93.26 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.014442
  validation loss:		0.368997
  validation accuracy:		93.15 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.014355
  validation loss:		0.371447
  validation accuracy:		93.04 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.015357
  validation loss:		0.371499
  validation accuracy:		92.93 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.015056
  validation loss:		0.384095
  validation accuracy:		92.72 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.014827
  validation loss:		0.370251
  validation accuracy:		93.04 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.013744
  validation loss:		0.363569
  validation accuracy:		93.04 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.013775
  validation loss:		0.364873
  validation accuracy:		93.26 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.014062
  validation loss:		0.378900
  validation accuracy:		92.83 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.014780
  validation loss:		0.365803
  validation accuracy:		93.15 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.014697
  validation loss:		0.368255
  validation accuracy:		93.15 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.014406
  validation loss:		0.372678
  validation accuracy:		93.15 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.014667
  validation loss:		0.373840
  validation accuracy:		92.93 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.014634
  validation loss:		0.373051
  validation accuracy:		92.93 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.014102
  validation loss:		0.372427
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.014374
  validation loss:		0.371237
  validation accuracy:		93.04 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.014167
  validation loss:		0.366553
  validation accuracy:		93.26 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.013956
  validation loss:		0.374643
  validation accuracy:		92.93 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.013501
  validation loss:		0.371040
  validation accuracy:		93.15 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.014027
  validation loss:		0.371817
  validation accuracy:		92.93 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.013996
  validation loss:		0.366952
  validation accuracy:		93.26 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.014234
  validation loss:		0.372028
  validation accuracy:		93.04 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.014364
  validation loss:		0.375969
  validation accuracy:		92.93 %
Epoch 1202 of 2000 took 0.036s
  training loss:		0.013272
  validation loss:		0.366101
  validation accuracy:		93.26 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.013717
  validation loss:		0.376872
  validation accuracy:		93.04 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.014005
  validation loss:		0.378961
  validation accuracy:		92.93 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.013750
  validation loss:		0.377762
  validation accuracy:		92.93 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.013804
  validation loss:		0.376176
  validation accuracy:		92.72 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.013580
  validation loss:		0.373421
  validation accuracy:		92.93 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.013468
  validation loss:		0.378204
  validation accuracy:		93.04 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.013624
  validation loss:		0.364632
  validation accuracy:		93.15 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.014183
  validation loss:		0.377383
  validation accuracy:		93.15 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.013433
  validation loss:		0.370783
  validation accuracy:		92.93 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.013566
  validation loss:		0.378312
  validation accuracy:		92.93 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.014288
  validation loss:		0.370806
  validation accuracy:		93.15 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.013741
  validation loss:		0.375967
  validation accuracy:		93.15 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.013697
  validation loss:		0.371582
  validation accuracy:		93.26 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.013458
  validation loss:		0.373881
  validation accuracy:		92.93 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.013072
  validation loss:		0.380182
  validation accuracy:		93.04 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.013221
  validation loss:		0.376260
  validation accuracy:		93.04 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.013524
  validation loss:		0.375124
  validation accuracy:		93.04 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.013036
  validation loss:		0.381615
  validation accuracy:		93.04 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.013263
  validation loss:		0.380777
  validation accuracy:		93.15 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.012889
  validation loss:		0.370242
  validation accuracy:		93.04 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.012704
  validation loss:		0.380082
  validation accuracy:		92.93 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.013283
  validation loss:		0.385489
  validation accuracy:		92.72 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.013271
  validation loss:		0.381354
  validation accuracy:		92.93 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.012957
  validation loss:		0.373555
  validation accuracy:		93.15 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.013491
  validation loss:		0.376803
  validation accuracy:		93.15 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.012758
  validation loss:		0.385611
  validation accuracy:		92.72 %
Epoch 1229 of 2000 took 0.036s
  training loss:		0.013126
  validation loss:		0.382398
  validation accuracy:		93.04 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.013072
  validation loss:		0.377833
  validation accuracy:		92.72 %
Epoch 1231 of 2000 took 0.036s
  training loss:		0.012990
  validation loss:		0.377684
  validation accuracy:		93.15 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.013220
  validation loss:		0.377442
  validation accuracy:		93.26 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.012830
  validation loss:		0.380422
  validation accuracy:		92.93 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.012772
  validation loss:		0.386879
  validation accuracy:		92.93 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.013263
  validation loss:		0.376553
  validation accuracy:		93.04 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.012318
  validation loss:		0.377016
  validation accuracy:		93.15 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.013193
  validation loss:		0.378726
  validation accuracy:		92.93 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.011715
  validation loss:		0.382998
  validation accuracy:		92.83 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.012640
  validation loss:		0.380943
  validation accuracy:		92.83 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.012774
  validation loss:		0.380487
  validation accuracy:		93.04 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.012928
  validation loss:		0.379421
  validation accuracy:		93.04 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.012993
  validation loss:		0.389397
  validation accuracy:		92.83 %
Epoch 1243 of 2000 took 0.036s
  training loss:		0.012890
  validation loss:		0.373507
  validation accuracy:		93.26 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.012968
  validation loss:		0.383324
  validation accuracy:		92.83 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.012469
  validation loss:		0.376297
  validation accuracy:		93.15 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.012168
  validation loss:		0.384052
  validation accuracy:		92.93 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.012496
  validation loss:		0.390215
  validation accuracy:		92.72 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.012927
  validation loss:		0.391167
  validation accuracy:		92.83 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.012321
  validation loss:		0.374469
  validation accuracy:		93.26 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.012443
  validation loss:		0.387652
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.012395
  validation loss:		0.382421
  validation accuracy:		92.83 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.013034
  validation loss:		0.381360
  validation accuracy:		93.04 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.012578
  validation loss:		0.391047
  validation accuracy:		92.72 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.012278
  validation loss:		0.384354
  validation accuracy:		92.72 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.012530
  validation loss:		0.373582
  validation accuracy:		93.26 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.012574
  validation loss:		0.374557
  validation accuracy:		93.26 %
Epoch 1257 of 2000 took 0.036s
  training loss:		0.011965
  validation loss:		0.392171
  validation accuracy:		92.72 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.012260
  validation loss:		0.382307
  validation accuracy:		92.93 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.012241
  validation loss:		0.385487
  validation accuracy:		93.04 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.012612
  validation loss:		0.386114
  validation accuracy:		92.93 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.012396
  validation loss:		0.383223
  validation accuracy:		92.93 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.011487
  validation loss:		0.384902
  validation accuracy:		93.04 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.012322
  validation loss:		0.383441
  validation accuracy:		92.72 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.012086
  validation loss:		0.379971
  validation accuracy:		93.15 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.012076
  validation loss:		0.378293
  validation accuracy:		93.15 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.011679
  validation loss:		0.390267
  validation accuracy:		92.83 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.011951
  validation loss:		0.384255
  validation accuracy:		92.93 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.011904
  validation loss:		0.391596
  validation accuracy:		92.83 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.011499
  validation loss:		0.385110
  validation accuracy:		92.93 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.012044
  validation loss:		0.390319
  validation accuracy:		92.61 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.012080
  validation loss:		0.390594
  validation accuracy:		92.83 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.011615
  validation loss:		0.391404
  validation accuracy:		92.72 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.012112
  validation loss:		0.389627
  validation accuracy:		92.72 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.011568
  validation loss:		0.383138
  validation accuracy:		93.15 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.011816
  validation loss:		0.397132
  validation accuracy:		92.72 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.011622
  validation loss:		0.380488
  validation accuracy:		93.04 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.012040
  validation loss:		0.387386
  validation accuracy:		92.83 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.011870
  validation loss:		0.381856
  validation accuracy:		92.83 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.011922
  validation loss:		0.389314
  validation accuracy:		93.15 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.011439
  validation loss:		0.391165
  validation accuracy:		93.04 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.012373
  validation loss:		0.385514
  validation accuracy:		93.04 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.011452
  validation loss:		0.392873
  validation accuracy:		92.72 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.011697
  validation loss:		0.386032
  validation accuracy:		92.83 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.011511
  validation loss:		0.397819
  validation accuracy:		92.61 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.011672
  validation loss:		0.385055
  validation accuracy:		92.93 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.010953
  validation loss:		0.388751
  validation accuracy:		93.15 %
Epoch 1287 of 2000 took 0.036s
  training loss:		0.011302
  validation loss:		0.389734
  validation accuracy:		93.26 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.011407
  validation loss:		0.390253
  validation accuracy:		92.83 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.011451
  validation loss:		0.388740
  validation accuracy:		93.15 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.011433
  validation loss:		0.399701
  validation accuracy:		92.83 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.011429
  validation loss:		0.394404
  validation accuracy:		92.72 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.011358
  validation loss:		0.396670
  validation accuracy:		92.83 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.011578
  validation loss:		0.386670
  validation accuracy:		93.04 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.011143
  validation loss:		0.388638
  validation accuracy:		93.04 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.011189
  validation loss:		0.395052
  validation accuracy:		93.15 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.011200
  validation loss:		0.393404
  validation accuracy:		93.04 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.011438
  validation loss:		0.384326
  validation accuracy:		93.15 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.011087
  validation loss:		0.385414
  validation accuracy:		93.04 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.011446
  validation loss:		0.389254
  validation accuracy:		92.83 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.011493
  validation loss:		0.382795
  validation accuracy:		93.15 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.011129
  validation loss:		0.393054
  validation accuracy:		92.93 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.011228
  validation loss:		0.395033
  validation accuracy:		92.83 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.010627
  validation loss:		0.394695
  validation accuracy:		92.83 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.011091
  validation loss:		0.387116
  validation accuracy:		93.04 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.011233
  validation loss:		0.397111
  validation accuracy:		92.83 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.010594
  validation loss:		0.382724
  validation accuracy:		93.26 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.011285
  validation loss:		0.393860
  validation accuracy:		92.93 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.011048
  validation loss:		0.398098
  validation accuracy:		92.93 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.011180
  validation loss:		0.397396
  validation accuracy:		93.04 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.011013
  validation loss:		0.386153
  validation accuracy:		93.15 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.010823
  validation loss:		0.402700
  validation accuracy:		92.93 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.010956
  validation loss:		0.396363
  validation accuracy:		92.93 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.011041
  validation loss:		0.391552
  validation accuracy:		93.04 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.010477
  validation loss:		0.397641
  validation accuracy:		93.04 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.011516
  validation loss:		0.394105
  validation accuracy:		92.83 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.010229
  validation loss:		0.391979
  validation accuracy:		93.15 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.010489
  validation loss:		0.390566
  validation accuracy:		92.93 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.010647
  validation loss:		0.399845
  validation accuracy:		93.04 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.010788
  validation loss:		0.404783
  validation accuracy:		92.61 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.011089
  validation loss:		0.392684
  validation accuracy:		93.04 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.010184
  validation loss:		0.401089
  validation accuracy:		92.83 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.010282
  validation loss:		0.385263
  validation accuracy:		93.04 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.010413
  validation loss:		0.390773
  validation accuracy:		93.15 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.010840
  validation loss:		0.401208
  validation accuracy:		92.61 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.010810
  validation loss:		0.392568
  validation accuracy:		93.04 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.010978
  validation loss:		0.403241
  validation accuracy:		92.72 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.010951
  validation loss:		0.398030
  validation accuracy:		92.93 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.010438
  validation loss:		0.405216
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.010597
  validation loss:		0.396661
  validation accuracy:		92.93 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.010403
  validation loss:		0.395362
  validation accuracy:		92.93 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.010683
  validation loss:		0.391019
  validation accuracy:		93.04 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.010222
  validation loss:		0.402811
  validation accuracy:		93.04 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.010352
  validation loss:		0.397496
  validation accuracy:		92.72 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.010008
  validation loss:		0.392744
  validation accuracy:		92.93 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.010726
  validation loss:		0.400124
  validation accuracy:		93.15 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.010341
  validation loss:		0.407201
  validation accuracy:		92.72 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.010343
  validation loss:		0.399990
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.010316
  validation loss:		0.398095
  validation accuracy:		93.04 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.010444
  validation loss:		0.401022
  validation accuracy:		93.15 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.010593
  validation loss:		0.396661
  validation accuracy:		92.93 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.009885
  validation loss:		0.394227
  validation accuracy:		92.93 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.010021
  validation loss:		0.395634
  validation accuracy:		93.15 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.010021
  validation loss:		0.395326
  validation accuracy:		93.04 %
Epoch 1344 of 2000 took 0.036s
  training loss:		0.010689
  validation loss:		0.395359
  validation accuracy:		93.04 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.009757
  validation loss:		0.409076
  validation accuracy:		92.72 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.010252
  validation loss:		0.404116
  validation accuracy:		92.83 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.009669
  validation loss:		0.406839
  validation accuracy:		92.72 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.009971
  validation loss:		0.397389
  validation accuracy:		93.04 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.009896
  validation loss:		0.406086
  validation accuracy:		92.93 %
Epoch 1350 of 2000 took 0.036s
  training loss:		0.010422
  validation loss:		0.401173
  validation accuracy:		93.04 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.010636
  validation loss:		0.393726
  validation accuracy:		93.04 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.010071
  validation loss:		0.407457
  validation accuracy:		92.83 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.010086
  validation loss:		0.398456
  validation accuracy:		93.04 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.010197
  validation loss:		0.391831
  validation accuracy:		93.15 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.010090
  validation loss:		0.399060
  validation accuracy:		93.15 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.010091
  validation loss:		0.395333
  validation accuracy:		93.04 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.009643
  validation loss:		0.399147
  validation accuracy:		93.15 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.010030
  validation loss:		0.401780
  validation accuracy:		93.04 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.009781
  validation loss:		0.416149
  validation accuracy:		92.72 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.009890
  validation loss:		0.394721
  validation accuracy:		92.93 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.010220
  validation loss:		0.397571
  validation accuracy:		92.83 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.009939
  validation loss:		0.402738
  validation accuracy:		92.83 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.010055
  validation loss:		0.404526
  validation accuracy:		92.83 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.009883
  validation loss:		0.405368
  validation accuracy:		93.15 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.010022
  validation loss:		0.403516
  validation accuracy:		92.93 %
Epoch 1366 of 2000 took 0.036s
  training loss:		0.009621
  validation loss:		0.400678
  validation accuracy:		93.26 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.009717
  validation loss:		0.404909
  validation accuracy:		93.04 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.009706
  validation loss:		0.405022
  validation accuracy:		93.04 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.009446
  validation loss:		0.400163
  validation accuracy:		92.83 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.009900
  validation loss:		0.394431
  validation accuracy:		93.15 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.009890
  validation loss:		0.413221
  validation accuracy:		92.93 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.009758
  validation loss:		0.400042
  validation accuracy:		93.04 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.009331
  validation loss:		0.406440
  validation accuracy:		93.04 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.009409
  validation loss:		0.405690
  validation accuracy:		93.04 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.009275
  validation loss:		0.400898
  validation accuracy:		93.04 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.009253
  validation loss:		0.404677
  validation accuracy:		93.04 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.009272
  validation loss:		0.395829
  validation accuracy:		93.04 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.009466
  validation loss:		0.403069
  validation accuracy:		92.93 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.009342
  validation loss:		0.406089
  validation accuracy:		92.93 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.009693
  validation loss:		0.400605
  validation accuracy:		92.93 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.009563
  validation loss:		0.401211
  validation accuracy:		93.04 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.009483
  validation loss:		0.406608
  validation accuracy:		92.83 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.009577
  validation loss:		0.406482
  validation accuracy:		93.04 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.009154
  validation loss:		0.400141
  validation accuracy:		93.04 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.009004
  validation loss:		0.414196
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.009518
  validation loss:		0.410242
  validation accuracy:		92.93 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.009278
  validation loss:		0.403778
  validation accuracy:		93.15 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.009528
  validation loss:		0.400692
  validation accuracy:		93.04 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.009273
  validation loss:		0.410492
  validation accuracy:		92.93 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.009310
  validation loss:		0.414264
  validation accuracy:		92.93 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.009177
  validation loss:		0.399082
  validation accuracy:		92.93 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.009344
  validation loss:		0.401925
  validation accuracy:		93.26 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.009200
  validation loss:		0.412365
  validation accuracy:		93.26 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.009552
  validation loss:		0.411133
  validation accuracy:		92.83 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.008940
  validation loss:		0.406884
  validation accuracy:		92.93 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.008962
  validation loss:		0.407524
  validation accuracy:		93.26 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.009252
  validation loss:		0.403892
  validation accuracy:		92.93 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.009308
  validation loss:		0.402443
  validation accuracy:		93.04 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.008404
  validation loss:		0.411913
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.036s
  training loss:		0.009135
  validation loss:		0.410446
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.009320
  validation loss:		0.405542
  validation accuracy:		92.93 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.009173
  validation loss:		0.410658
  validation accuracy:		93.04 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.008987
  validation loss:		0.402467
  validation accuracy:		93.04 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.008975
  validation loss:		0.408531
  validation accuracy:		92.93 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.008898
  validation loss:		0.411074
  validation accuracy:		92.93 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.008663
  validation loss:		0.404107
  validation accuracy:		93.26 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.009119
  validation loss:		0.412502
  validation accuracy:		93.04 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.008995
  validation loss:		0.401127
  validation accuracy:		93.26 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.008700
  validation loss:		0.408751
  validation accuracy:		93.15 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.009166
  validation loss:		0.403609
  validation accuracy:		92.93 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.009224
  validation loss:		0.412459
  validation accuracy:		92.93 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.008869
  validation loss:		0.412410
  validation accuracy:		93.15 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.008873
  validation loss:		0.413821
  validation accuracy:		92.93 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.008593
  validation loss:		0.408705
  validation accuracy:		92.93 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.008875
  validation loss:		0.398166
  validation accuracy:		93.26 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.009114
  validation loss:		0.413543
  validation accuracy:		92.83 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.008405
  validation loss:		0.414872
  validation accuracy:		93.04 %
Epoch 1418 of 2000 took 0.036s
  training loss:		0.008565
  validation loss:		0.408023
  validation accuracy:		93.04 %
Epoch 1419 of 2000 took 0.036s
  training loss:		0.008644
  validation loss:		0.413955
  validation accuracy:		93.04 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.008501
  validation loss:		0.408376
  validation accuracy:		93.15 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.008523
  validation loss:		0.420610
  validation accuracy:		92.93 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.008709
  validation loss:		0.409345
  validation accuracy:		92.93 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.008546
  validation loss:		0.414043
  validation accuracy:		93.15 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.008736
  validation loss:		0.413404
  validation accuracy:		92.93 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.008552
  validation loss:		0.405009
  validation accuracy:		93.15 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.008608
  validation loss:		0.408560
  validation accuracy:		93.04 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.008708
  validation loss:		0.411523
  validation accuracy:		92.93 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.008610
  validation loss:		0.411461
  validation accuracy:		93.04 %
Epoch 1429 of 2000 took 0.036s
  training loss:		0.008299
  validation loss:		0.415374
  validation accuracy:		93.04 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.008384
  validation loss:		0.408549
  validation accuracy:		93.15 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.008875
  validation loss:		0.415435
  validation accuracy:		93.04 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.008567
  validation loss:		0.415294
  validation accuracy:		93.04 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.008616
  validation loss:		0.411592
  validation accuracy:		92.93 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.008835
  validation loss:		0.409679
  validation accuracy:		93.26 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.008544
  validation loss:		0.412674
  validation accuracy:		93.04 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.008596
  validation loss:		0.410839
  validation accuracy:		93.04 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.008351
  validation loss:		0.415454
  validation accuracy:		92.93 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.008322
  validation loss:		0.409845
  validation accuracy:		93.04 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.008466
  validation loss:		0.419215
  validation accuracy:		92.93 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.008419
  validation loss:		0.410558
  validation accuracy:		93.04 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.008393
  validation loss:		0.413298
  validation accuracy:		92.93 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.008396
  validation loss:		0.419193
  validation accuracy:		93.04 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.008262
  validation loss:		0.410076
  validation accuracy:		92.93 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.008772
  validation loss:		0.416198
  validation accuracy:		93.15 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.008316
  validation loss:		0.413009
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.008285
  validation loss:		0.414918
  validation accuracy:		93.15 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.008272
  validation loss:		0.420165
  validation accuracy:		92.93 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.008333
  validation loss:		0.410218
  validation accuracy:		93.04 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.008278
  validation loss:		0.415682
  validation accuracy:		93.04 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.008173
  validation loss:		0.420096
  validation accuracy:		92.83 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007976
  validation loss:		0.417519
  validation accuracy:		93.15 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.008187
  validation loss:		0.420909
  validation accuracy:		93.04 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.007976
  validation loss:		0.409484
  validation accuracy:		92.93 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.008436
  validation loss:		0.414613
  validation accuracy:		93.15 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.008108
  validation loss:		0.424392
  validation accuracy:		92.72 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.008104
  validation loss:		0.418261
  validation accuracy:		93.04 %
Epoch 1457 of 2000 took 0.036s
  training loss:		0.007856
  validation loss:		0.416036
  validation accuracy:		92.83 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.007822
  validation loss:		0.421792
  validation accuracy:		92.83 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.008142
  validation loss:		0.415492
  validation accuracy:		93.04 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007716
  validation loss:		0.412952
  validation accuracy:		93.04 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.007988
  validation loss:		0.415454
  validation accuracy:		93.26 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.008128
  validation loss:		0.414775
  validation accuracy:		93.15 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.008337
  validation loss:		0.417574
  validation accuracy:		93.04 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.007908
  validation loss:		0.417226
  validation accuracy:		93.26 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.008222
  validation loss:		0.424872
  validation accuracy:		92.93 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.008168
  validation loss:		0.419426
  validation accuracy:		93.04 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.008068
  validation loss:		0.411087
  validation accuracy:		93.15 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.007831
  validation loss:		0.417108
  validation accuracy:		92.93 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.008068
  validation loss:		0.429830
  validation accuracy:		92.83 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007835
  validation loss:		0.414606
  validation accuracy:		92.93 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.008051
  validation loss:		0.421118
  validation accuracy:		93.26 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.008040
  validation loss:		0.412672
  validation accuracy:		93.04 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007844
  validation loss:		0.419897
  validation accuracy:		93.04 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007897
  validation loss:		0.419108
  validation accuracy:		92.93 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.007722
  validation loss:		0.417433
  validation accuracy:		93.04 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.007878
  validation loss:		0.417650
  validation accuracy:		93.15 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.007763
  validation loss:		0.426118
  validation accuracy:		92.83 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.007810
  validation loss:		0.422104
  validation accuracy:		93.15 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.007848
  validation loss:		0.417122
  validation accuracy:		93.04 %
Epoch 1480 of 2000 took 0.036s
  training loss:		0.007469
  validation loss:		0.422199
  validation accuracy:		93.26 %
Epoch 1481 of 2000 took 0.036s
  training loss:		0.007779
  validation loss:		0.424526
  validation accuracy:		93.04 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.007867
  validation loss:		0.423596
  validation accuracy:		93.04 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.007719
  validation loss:		0.418466
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.007644
  validation loss:		0.424871
  validation accuracy:		93.15 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.007729
  validation loss:		0.417814
  validation accuracy:		93.15 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.007828
  validation loss:		0.416318
  validation accuracy:		92.93 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.007515
  validation loss:		0.426391
  validation accuracy:		92.83 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.007957
  validation loss:		0.419142
  validation accuracy:		93.15 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.007723
  validation loss:		0.415718
  validation accuracy:		93.15 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.007886
  validation loss:		0.414146
  validation accuracy:		93.15 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.007599
  validation loss:		0.424798
  validation accuracy:		93.04 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.007817
  validation loss:		0.419646
  validation accuracy:		93.04 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.007653
  validation loss:		0.417943
  validation accuracy:		92.93 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.007544
  validation loss:		0.420190
  validation accuracy:		92.93 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.007462
  validation loss:		0.423781
  validation accuracy:		93.15 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.007512
  validation loss:		0.412882
  validation accuracy:		93.04 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.007858
  validation loss:		0.424859
  validation accuracy:		93.04 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.007566
  validation loss:		0.424899
  validation accuracy:		92.93 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.007751
  validation loss:		0.421541
  validation accuracy:		92.93 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.007294
  validation loss:		0.422214
  validation accuracy:		92.93 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.007586
  validation loss:		0.418016
  validation accuracy:		92.93 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.007635
  validation loss:		0.425549
  validation accuracy:		93.15 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.007000
  validation loss:		0.431571
  validation accuracy:		93.15 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.007382
  validation loss:		0.413310
  validation accuracy:		93.04 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.007716
  validation loss:		0.425356
  validation accuracy:		93.04 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.007541
  validation loss:		0.425774
  validation accuracy:		93.15 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.007440
  validation loss:		0.423258
  validation accuracy:		93.04 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.007371
  validation loss:		0.432957
  validation accuracy:		93.04 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.007511
  validation loss:		0.430999
  validation accuracy:		93.04 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.007478
  validation loss:		0.420970
  validation accuracy:		92.93 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.007354
  validation loss:		0.418711
  validation accuracy:		93.26 %
Epoch 1512 of 2000 took 0.036s
  training loss:		0.006988
  validation loss:		0.427553
  validation accuracy:		92.93 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.007066
  validation loss:		0.430359
  validation accuracy:		93.04 %
Epoch 1514 of 2000 took 0.036s
  training loss:		0.007150
  validation loss:		0.430397
  validation accuracy:		93.15 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.007470
  validation loss:		0.423006
  validation accuracy:		93.04 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.007398
  validation loss:		0.426641
  validation accuracy:		92.93 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.007100
  validation loss:		0.424668
  validation accuracy:		93.15 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.007224
  validation loss:		0.420096
  validation accuracy:		93.04 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.007131
  validation loss:		0.424225
  validation accuracy:		93.04 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.007490
  validation loss:		0.427108
  validation accuracy:		93.26 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.007305
  validation loss:		0.430346
  validation accuracy:		93.04 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.007167
  validation loss:		0.432308
  validation accuracy:		93.15 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.007059
  validation loss:		0.419809
  validation accuracy:		93.15 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.007168
  validation loss:		0.427974
  validation accuracy:		93.04 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.007411
  validation loss:		0.429212
  validation accuracy:		93.04 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.006922
  validation loss:		0.417601
  validation accuracy:		93.04 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.006816
  validation loss:		0.429805
  validation accuracy:		92.83 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.007053
  validation loss:		0.430236
  validation accuracy:		92.93 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.007231
  validation loss:		0.425946
  validation accuracy:		93.04 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.007040
  validation loss:		0.437688
  validation accuracy:		93.04 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006795
  validation loss:		0.422690
  validation accuracy:		92.83 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.007121
  validation loss:		0.422893
  validation accuracy:		92.83 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.007069
  validation loss:		0.430315
  validation accuracy:		93.04 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.007071
  validation loss:		0.426288
  validation accuracy:		92.72 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.007225
  validation loss:		0.422094
  validation accuracy:		92.83 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.007040
  validation loss:		0.425461
  validation accuracy:		93.04 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.007012
  validation loss:		0.429288
  validation accuracy:		92.93 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.007100
  validation loss:		0.430852
  validation accuracy:		93.15 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006888
  validation loss:		0.431595
  validation accuracy:		93.37 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.007153
  validation loss:		0.427459
  validation accuracy:		93.26 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006921
  validation loss:		0.425579
  validation accuracy:		93.15 %
Epoch 1542 of 2000 took 0.036s
  training loss:		0.006833
  validation loss:		0.426819
  validation accuracy:		92.83 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.006757
  validation loss:		0.427718
  validation accuracy:		93.15 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.007146
  validation loss:		0.432508
  validation accuracy:		92.93 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006898
  validation loss:		0.431014
  validation accuracy:		93.04 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.006725
  validation loss:		0.425957
  validation accuracy:		92.93 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006895
  validation loss:		0.434547
  validation accuracy:		93.04 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006791
  validation loss:		0.426000
  validation accuracy:		93.15 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.006774
  validation loss:		0.426745
  validation accuracy:		92.93 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006847
  validation loss:		0.430523
  validation accuracy:		92.83 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.006842
  validation loss:		0.438444
  validation accuracy:		92.83 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006764
  validation loss:		0.421817
  validation accuracy:		92.83 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.006843
  validation loss:		0.438787
  validation accuracy:		93.15 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006739
  validation loss:		0.429310
  validation accuracy:		92.83 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006670
  validation loss:		0.433975
  validation accuracy:		93.04 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.006840
  validation loss:		0.425509
  validation accuracy:		92.93 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006949
  validation loss:		0.430876
  validation accuracy:		92.93 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006733
  validation loss:		0.436773
  validation accuracy:		93.26 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.006679
  validation loss:		0.436206
  validation accuracy:		93.15 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006663
  validation loss:		0.433786
  validation accuracy:		93.15 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.006483
  validation loss:		0.435394
  validation accuracy:		92.93 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.006599
  validation loss:		0.437736
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.006669
  validation loss:		0.429660
  validation accuracy:		92.93 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.006835
  validation loss:		0.430953
  validation accuracy:		92.93 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.006866
  validation loss:		0.430986
  validation accuracy:		92.83 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.007051
  validation loss:		0.436862
  validation accuracy:		93.26 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.006483
  validation loss:		0.434558
  validation accuracy:		93.04 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006675
  validation loss:		0.429736
  validation accuracy:		92.93 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006534
  validation loss:		0.436414
  validation accuracy:		93.04 %
Epoch 1570 of 2000 took 0.036s
  training loss:		0.006392
  validation loss:		0.428942
  validation accuracy:		92.93 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.006611
  validation loss:		0.437739
  validation accuracy:		93.04 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.434454
  validation accuracy:		92.83 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.006813
  validation loss:		0.433765
  validation accuracy:		92.93 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006663
  validation loss:		0.437542
  validation accuracy:		92.93 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.436757
  validation accuracy:		93.26 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.006563
  validation loss:		0.434169
  validation accuracy:		92.93 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.006538
  validation loss:		0.427732
  validation accuracy:		93.04 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.006434
  validation loss:		0.427239
  validation accuracy:		92.93 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.006495
  validation loss:		0.433003
  validation accuracy:		93.04 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.006433
  validation loss:		0.433367
  validation accuracy:		92.93 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.006500
  validation loss:		0.434638
  validation accuracy:		92.83 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.006535
  validation loss:		0.429757
  validation accuracy:		92.93 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.006484
  validation loss:		0.433206
  validation accuracy:		92.83 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.006176
  validation loss:		0.431815
  validation accuracy:		93.15 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.006395
  validation loss:		0.432905
  validation accuracy:		92.93 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.006685
  validation loss:		0.440090
  validation accuracy:		93.15 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.006498
  validation loss:		0.432123
  validation accuracy:		92.93 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.006494
  validation loss:		0.431034
  validation accuracy:		93.04 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.006427
  validation loss:		0.445382
  validation accuracy:		93.15 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.006343
  validation loss:		0.431546
  validation accuracy:		92.93 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.435740
  validation accuracy:		93.15 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.006214
  validation loss:		0.442360
  validation accuracy:		92.93 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.006447
  validation loss:		0.435929
  validation accuracy:		92.72 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006323
  validation loss:		0.435519
  validation accuracy:		92.83 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.006340
  validation loss:		0.437431
  validation accuracy:		93.04 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.006428
  validation loss:		0.445271
  validation accuracy:		92.93 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.006420
  validation loss:		0.437006
  validation accuracy:		92.83 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.006242
  validation loss:		0.438585
  validation accuracy:		93.04 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.006322
  validation loss:		0.438206
  validation accuracy:		93.26 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.006228
  validation loss:		0.433832
  validation accuracy:		92.93 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.006233
  validation loss:		0.433725
  validation accuracy:		92.83 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.006131
  validation loss:		0.430963
  validation accuracy:		92.93 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.006172
  validation loss:		0.437556
  validation accuracy:		93.26 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.006257
  validation loss:		0.433846
  validation accuracy:		92.72 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.006359
  validation loss:		0.438182
  validation accuracy:		92.93 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.006182
  validation loss:		0.434325
  validation accuracy:		92.83 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.006228
  validation loss:		0.434666
  validation accuracy:		93.15 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.006273
  validation loss:		0.438448
  validation accuracy:		92.93 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.440654
  validation accuracy:		93.26 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.006123
  validation loss:		0.432698
  validation accuracy:		92.72 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.006148
  validation loss:		0.439435
  validation accuracy:		92.83 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.006116
  validation loss:		0.434460
  validation accuracy:		93.15 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.006016
  validation loss:		0.442151
  validation accuracy:		92.93 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.006157
  validation loss:		0.434077
  validation accuracy:		92.83 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.006009
  validation loss:		0.438792
  validation accuracy:		93.26 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.006112
  validation loss:		0.438241
  validation accuracy:		92.93 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.006052
  validation loss:		0.445806
  validation accuracy:		93.04 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.006185
  validation loss:		0.434965
  validation accuracy:		92.72 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.006247
  validation loss:		0.437066
  validation accuracy:		92.93 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.006141
  validation loss:		0.444689
  validation accuracy:		92.93 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005944
  validation loss:		0.432657
  validation accuracy:		92.93 %
Epoch 1622 of 2000 took 0.036s
  training loss:		0.006073
  validation loss:		0.436182
  validation accuracy:		92.83 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.006287
  validation loss:		0.431417
  validation accuracy:		92.83 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.006181
  validation loss:		0.437919
  validation accuracy:		92.83 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.006076
  validation loss:		0.438152
  validation accuracy:		92.72 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.006150
  validation loss:		0.445096
  validation accuracy:		92.93 %
Epoch 1627 of 2000 took 0.036s
  training loss:		0.005972
  validation loss:		0.437610
  validation accuracy:		92.83 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.006147
  validation loss:		0.437152
  validation accuracy:		93.04 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.005836
  validation loss:		0.436509
  validation accuracy:		92.83 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.006018
  validation loss:		0.442153
  validation accuracy:		92.72 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005989
  validation loss:		0.443679
  validation accuracy:		93.04 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005971
  validation loss:		0.439968
  validation accuracy:		92.93 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.005962
  validation loss:		0.441281
  validation accuracy:		93.15 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.005753
  validation loss:		0.439467
  validation accuracy:		92.93 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005854
  validation loss:		0.439483
  validation accuracy:		93.26 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005933
  validation loss:		0.445234
  validation accuracy:		92.93 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005973
  validation loss:		0.436858
  validation accuracy:		92.93 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.005915
  validation loss:		0.442476
  validation accuracy:		92.93 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005895
  validation loss:		0.436225
  validation accuracy:		92.72 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005865
  validation loss:		0.438582
  validation accuracy:		92.93 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.006090
  validation loss:		0.440106
  validation accuracy:		92.93 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005915
  validation loss:		0.441923
  validation accuracy:		93.04 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005885
  validation loss:		0.439117
  validation accuracy:		93.15 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005623
  validation loss:		0.443248
  validation accuracy:		92.93 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.005846
  validation loss:		0.443666
  validation accuracy:		92.83 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.005713
  validation loss:		0.438296
  validation accuracy:		92.83 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.005898
  validation loss:		0.439758
  validation accuracy:		92.83 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.005738
  validation loss:		0.438798
  validation accuracy:		92.72 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005711
  validation loss:		0.441832
  validation accuracy:		92.93 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005796
  validation loss:		0.445901
  validation accuracy:		93.04 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005817
  validation loss:		0.438769
  validation accuracy:		92.83 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005744
  validation loss:		0.444467
  validation accuracy:		92.93 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005914
  validation loss:		0.445776
  validation accuracy:		92.93 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005710
  validation loss:		0.448015
  validation accuracy:		92.93 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.005842
  validation loss:		0.441936
  validation accuracy:		93.04 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.005731
  validation loss:		0.448464
  validation accuracy:		93.04 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005552
  validation loss:		0.439593
  validation accuracy:		93.04 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005724
  validation loss:		0.450903
  validation accuracy:		92.83 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005776
  validation loss:		0.443448
  validation accuracy:		92.93 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005772
  validation loss:		0.446745
  validation accuracy:		93.04 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.005661
  validation loss:		0.440189
  validation accuracy:		92.83 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.005706
  validation loss:		0.445158
  validation accuracy:		93.04 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005756
  validation loss:		0.451679
  validation accuracy:		93.04 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.005809
  validation loss:		0.444800
  validation accuracy:		93.04 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.005845
  validation loss:		0.445716
  validation accuracy:		92.93 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.005628
  validation loss:		0.446947
  validation accuracy:		93.26 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.005674
  validation loss:		0.446007
  validation accuracy:		92.93 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005593
  validation loss:		0.441932
  validation accuracy:		92.93 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005634
  validation loss:		0.448104
  validation accuracy:		92.83 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005742
  validation loss:		0.445272
  validation accuracy:		93.15 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005510
  validation loss:		0.446657
  validation accuracy:		92.83 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005575
  validation loss:		0.444126
  validation accuracy:		93.04 %
Epoch 1673 of 2000 took 0.036s
  training loss:		0.005585
  validation loss:		0.446699
  validation accuracy:		92.83 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.005510
  validation loss:		0.446186
  validation accuracy:		92.72 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005439
  validation loss:		0.447870
  validation accuracy:		92.93 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005439
  validation loss:		0.442525
  validation accuracy:		92.83 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.005778
  validation loss:		0.443511
  validation accuracy:		92.72 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005518
  validation loss:		0.448914
  validation accuracy:		92.93 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.005528
  validation loss:		0.444339
  validation accuracy:		92.93 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005415
  validation loss:		0.448655
  validation accuracy:		93.04 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.005552
  validation loss:		0.448084
  validation accuracy:		92.93 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.005524
  validation loss:		0.448685
  validation accuracy:		93.04 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005521
  validation loss:		0.446855
  validation accuracy:		92.93 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.005443
  validation loss:		0.447158
  validation accuracy:		92.93 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.005406
  validation loss:		0.444395
  validation accuracy:		93.04 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005402
  validation loss:		0.446359
  validation accuracy:		93.04 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.005278
  validation loss:		0.449224
  validation accuracy:		92.93 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005322
  validation loss:		0.447687
  validation accuracy:		93.04 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.005425
  validation loss:		0.451218
  validation accuracy:		92.83 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005632
  validation loss:		0.451596
  validation accuracy:		93.15 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.005486
  validation loss:		0.444465
  validation accuracy:		92.93 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.005259
  validation loss:		0.447292
  validation accuracy:		92.83 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.005347
  validation loss:		0.449766
  validation accuracy:		93.04 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.005364
  validation loss:		0.452539
  validation accuracy:		93.15 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.005199
  validation loss:		0.449127
  validation accuracy:		92.93 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.005360
  validation loss:		0.455350
  validation accuracy:		92.83 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.005384
  validation loss:		0.443833
  validation accuracy:		93.15 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.005346
  validation loss:		0.446952
  validation accuracy:		93.04 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005546
  validation loss:		0.448978
  validation accuracy:		93.04 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.005380
  validation loss:		0.443818
  validation accuracy:		92.93 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.005412
  validation loss:		0.457002
  validation accuracy:		92.93 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.005473
  validation loss:		0.452331
  validation accuracy:		93.15 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005279
  validation loss:		0.452177
  validation accuracy:		93.04 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.005375
  validation loss:		0.454693
  validation accuracy:		92.83 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.005279
  validation loss:		0.454525
  validation accuracy:		93.04 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.005311
  validation loss:		0.452673
  validation accuracy:		92.83 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.005190
  validation loss:		0.443312
  validation accuracy:		92.93 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.005314
  validation loss:		0.453134
  validation accuracy:		93.04 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.005411
  validation loss:		0.444728
  validation accuracy:		93.15 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005222
  validation loss:		0.455594
  validation accuracy:		93.04 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.005289
  validation loss:		0.454159
  validation accuracy:		92.93 %
Epoch 1712 of 2000 took 0.036s
  training loss:		0.005208
  validation loss:		0.448189
  validation accuracy:		92.83 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.005279
  validation loss:		0.452636
  validation accuracy:		93.04 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.005388
  validation loss:		0.448445
  validation accuracy:		93.04 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.005304
  validation loss:		0.448183
  validation accuracy:		93.04 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.005190
  validation loss:		0.451032
  validation accuracy:		92.83 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.005311
  validation loss:		0.450440
  validation accuracy:		92.93 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.005159
  validation loss:		0.445356
  validation accuracy:		92.93 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.005133
  validation loss:		0.455928
  validation accuracy:		93.04 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005154
  validation loss:		0.452498
  validation accuracy:		93.04 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.005269
  validation loss:		0.454223
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.005031
  validation loss:		0.453552
  validation accuracy:		93.04 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.005203
  validation loss:		0.452277
  validation accuracy:		92.83 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.005369
  validation loss:		0.449495
  validation accuracy:		93.04 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.005058
  validation loss:		0.451781
  validation accuracy:		92.83 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.005513
  validation loss:		0.455059
  validation accuracy:		92.72 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.005117
  validation loss:		0.447574
  validation accuracy:		92.93 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004937
  validation loss:		0.454006
  validation accuracy:		92.93 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.005240
  validation loss:		0.451387
  validation accuracy:		92.93 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.005124
  validation loss:		0.444651
  validation accuracy:		92.93 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.005157
  validation loss:		0.460544
  validation accuracy:		92.93 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.005145
  validation loss:		0.450553
  validation accuracy:		93.04 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004982
  validation loss:		0.458642
  validation accuracy:		93.04 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.005155
  validation loss:		0.455711
  validation accuracy:		93.15 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.005008
  validation loss:		0.448423
  validation accuracy:		93.04 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.005056
  validation loss:		0.450877
  validation accuracy:		92.83 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.005087
  validation loss:		0.458725
  validation accuracy:		93.04 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.005270
  validation loss:		0.456481
  validation accuracy:		92.93 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.005260
  validation loss:		0.457848
  validation accuracy:		92.93 %
Epoch 1740 of 2000 took 0.036s
  training loss:		0.005050
  validation loss:		0.451793
  validation accuracy:		92.93 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004900
  validation loss:		0.458396
  validation accuracy:		92.93 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.005015
  validation loss:		0.446957
  validation accuracy:		92.83 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.005091
  validation loss:		0.453145
  validation accuracy:		92.83 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.005044
  validation loss:		0.450705
  validation accuracy:		93.04 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.005158
  validation loss:		0.458803
  validation accuracy:		92.93 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.005016
  validation loss:		0.456662
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004979
  validation loss:		0.454802
  validation accuracy:		93.04 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004915
  validation loss:		0.456878
  validation accuracy:		92.93 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004903
  validation loss:		0.449330
  validation accuracy:		92.93 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.005046
  validation loss:		0.456624
  validation accuracy:		92.93 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.005058
  validation loss:		0.455110
  validation accuracy:		92.93 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004889
  validation loss:		0.456345
  validation accuracy:		92.93 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.005007
  validation loss:		0.459289
  validation accuracy:		92.93 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004870
  validation loss:		0.458963
  validation accuracy:		92.93 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004958
  validation loss:		0.461950
  validation accuracy:		92.83 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004990
  validation loss:		0.458331
  validation accuracy:		93.15 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004887
  validation loss:		0.458084
  validation accuracy:		93.15 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004882
  validation loss:		0.459489
  validation accuracy:		92.83 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004830
  validation loss:		0.460927
  validation accuracy:		92.93 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004948
  validation loss:		0.453146
  validation accuracy:		92.83 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004945
  validation loss:		0.464333
  validation accuracy:		92.93 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004882
  validation loss:		0.458506
  validation accuracy:		92.83 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004915
  validation loss:		0.455178
  validation accuracy:		93.04 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004941
  validation loss:		0.459551
  validation accuracy:		93.04 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004891
  validation loss:		0.462106
  validation accuracy:		93.04 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004994
  validation loss:		0.452402
  validation accuracy:		93.04 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004970
  validation loss:		0.455148
  validation accuracy:		92.83 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004891
  validation loss:		0.460632
  validation accuracy:		92.93 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004851
  validation loss:		0.455479
  validation accuracy:		92.83 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004941
  validation loss:		0.458509
  validation accuracy:		93.15 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004817
  validation loss:		0.458931
  validation accuracy:		92.93 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004773
  validation loss:		0.457791
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004823
  validation loss:		0.461685
  validation accuracy:		93.04 %
Epoch 1774 of 2000 took 0.036s
  training loss:		0.004870
  validation loss:		0.456732
  validation accuracy:		92.83 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004891
  validation loss:		0.455054
  validation accuracy:		93.26 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004811
  validation loss:		0.464500
  validation accuracy:		92.93 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004767
  validation loss:		0.452793
  validation accuracy:		92.93 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004853
  validation loss:		0.461870
  validation accuracy:		92.93 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004689
  validation loss:		0.460904
  validation accuracy:		92.93 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004635
  validation loss:		0.458087
  validation accuracy:		92.83 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004673
  validation loss:		0.460728
  validation accuracy:		92.83 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004636
  validation loss:		0.462820
  validation accuracy:		93.15 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004737
  validation loss:		0.451297
  validation accuracy:		92.83 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004838
  validation loss:		0.459768
  validation accuracy:		92.93 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004755
  validation loss:		0.460093
  validation accuracy:		92.93 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004648
  validation loss:		0.459926
  validation accuracy:		92.93 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004657
  validation loss:		0.467172
  validation accuracy:		92.83 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004694
  validation loss:		0.455128
  validation accuracy:		93.04 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004707
  validation loss:		0.464104
  validation accuracy:		92.93 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004650
  validation loss:		0.461137
  validation accuracy:		92.93 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004613
  validation loss:		0.457721
  validation accuracy:		92.83 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004684
  validation loss:		0.453574
  validation accuracy:		92.83 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004827
  validation loss:		0.463139
  validation accuracy:		92.93 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004643
  validation loss:		0.459202
  validation accuracy:		93.15 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004613
  validation loss:		0.457832
  validation accuracy:		92.93 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004682
  validation loss:		0.458798
  validation accuracy:		92.93 %
Epoch 1797 of 2000 took 0.036s
  training loss:		0.004655
  validation loss:		0.460677
  validation accuracy:		93.04 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004555
  validation loss:		0.455405
  validation accuracy:		92.93 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004604
  validation loss:		0.462202
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.458991
  validation accuracy:		93.04 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004731
  validation loss:		0.461243
  validation accuracy:		92.93 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004476
  validation loss:		0.463259
  validation accuracy:		93.26 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004610
  validation loss:		0.465410
  validation accuracy:		92.83 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004631
  validation loss:		0.464818
  validation accuracy:		93.15 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004549
  validation loss:		0.461625
  validation accuracy:		93.04 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004523
  validation loss:		0.460317
  validation accuracy:		93.15 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004414
  validation loss:		0.459162
  validation accuracy:		92.83 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004534
  validation loss:		0.467142
  validation accuracy:		92.83 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004711
  validation loss:		0.459620
  validation accuracy:		93.15 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004337
  validation loss:		0.466117
  validation accuracy:		92.83 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004458
  validation loss:		0.458232
  validation accuracy:		92.93 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.004662
  validation loss:		0.460256
  validation accuracy:		92.93 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004521
  validation loss:		0.465584
  validation accuracy:		93.04 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004538
  validation loss:		0.464426
  validation accuracy:		93.04 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004467
  validation loss:		0.463868
  validation accuracy:		92.83 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004564
  validation loss:		0.463703
  validation accuracy:		92.83 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004401
  validation loss:		0.462252
  validation accuracy:		92.93 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004493
  validation loss:		0.464084
  validation accuracy:		92.93 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004489
  validation loss:		0.467061
  validation accuracy:		93.04 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004554
  validation loss:		0.461962
  validation accuracy:		92.93 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004653
  validation loss:		0.464261
  validation accuracy:		93.04 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004360
  validation loss:		0.466453
  validation accuracy:		92.93 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.462362
  validation accuracy:		93.04 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004385
  validation loss:		0.468337
  validation accuracy:		93.04 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004603
  validation loss:		0.460931
  validation accuracy:		92.83 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.004436
  validation loss:		0.464793
  validation accuracy:		92.72 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004558
  validation loss:		0.467486
  validation accuracy:		92.83 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.004529
  validation loss:		0.464310
  validation accuracy:		93.15 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004444
  validation loss:		0.466686
  validation accuracy:		93.04 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.461368
  validation accuracy:		92.93 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.004462
  validation loss:		0.461216
  validation accuracy:		93.15 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004508
  validation loss:		0.467916
  validation accuracy:		92.93 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.004292
  validation loss:		0.462409
  validation accuracy:		92.83 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.004302
  validation loss:		0.466888
  validation accuracy:		92.93 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.004468
  validation loss:		0.470536
  validation accuracy:		92.93 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.004425
  validation loss:		0.465549
  validation accuracy:		92.93 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004502
  validation loss:		0.467709
  validation accuracy:		93.15 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.004453
  validation loss:		0.468833
  validation accuracy:		92.93 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.004406
  validation loss:		0.466212
  validation accuracy:		93.04 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.004478
  validation loss:		0.462899
  validation accuracy:		93.04 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.004483
  validation loss:		0.472822
  validation accuracy:		92.83 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.004493
  validation loss:		0.471574
  validation accuracy:		93.04 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.004285
  validation loss:		0.460309
  validation accuracy:		93.04 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.004403
  validation loss:		0.472281
  validation accuracy:		92.93 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.467869
  validation accuracy:		92.83 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.004287
  validation loss:		0.470978
  validation accuracy:		93.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.004487
  validation loss:		0.472142
  validation accuracy:		92.83 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.004220
  validation loss:		0.467033
  validation accuracy:		93.04 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004230
  validation loss:		0.467765
  validation accuracy:		93.15 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.004240
  validation loss:		0.466173
  validation accuracy:		92.83 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.004159
  validation loss:		0.466211
  validation accuracy:		92.93 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.004267
  validation loss:		0.467540
  validation accuracy:		92.83 %
Epoch 1853 of 2000 took 0.036s
  training loss:		0.004236
  validation loss:		0.466308
  validation accuracy:		92.83 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.004321
  validation loss:		0.471034
  validation accuracy:		93.04 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.004318
  validation loss:		0.461105
  validation accuracy:		93.04 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.004171
  validation loss:		0.472147
  validation accuracy:		92.83 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.004190
  validation loss:		0.470744
  validation accuracy:		92.93 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.004294
  validation loss:		0.471978
  validation accuracy:		92.93 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.004067
  validation loss:		0.462960
  validation accuracy:		92.83 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.004331
  validation loss:		0.468370
  validation accuracy:		92.93 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.004264
  validation loss:		0.467650
  validation accuracy:		93.15 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003933
  validation loss:		0.469887
  validation accuracy:		92.93 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.004238
  validation loss:		0.472655
  validation accuracy:		93.04 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.465564
  validation accuracy:		93.04 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.004213
  validation loss:		0.469354
  validation accuracy:		92.93 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.004227
  validation loss:		0.473553
  validation accuracy:		93.04 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.004264
  validation loss:		0.470452
  validation accuracy:		92.83 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.004252
  validation loss:		0.467939
  validation accuracy:		92.93 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.004242
  validation loss:		0.466106
  validation accuracy:		93.04 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.468837
  validation accuracy:		92.93 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.004196
  validation loss:		0.481060
  validation accuracy:		93.04 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.004176
  validation loss:		0.464489
  validation accuracy:		93.15 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.004329
  validation loss:		0.473550
  validation accuracy:		92.93 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003992
  validation loss:		0.470286
  validation accuracy:		92.83 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.004173
  validation loss:		0.467966
  validation accuracy:		93.15 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.004030
  validation loss:		0.474681
  validation accuracy:		92.93 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.004190
  validation loss:		0.469103
  validation accuracy:		92.83 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.467989
  validation accuracy:		93.04 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003945
  validation loss:		0.474153
  validation accuracy:		93.15 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.004071
  validation loss:		0.471006
  validation accuracy:		92.61 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.004213
  validation loss:		0.475910
  validation accuracy:		92.72 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.004133
  validation loss:		0.463964
  validation accuracy:		93.04 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.004243
  validation loss:		0.471068
  validation accuracy:		93.04 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.004122
  validation loss:		0.470308
  validation accuracy:		92.93 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.004100
  validation loss:		0.478244
  validation accuracy:		92.83 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.004104
  validation loss:		0.471650
  validation accuracy:		92.83 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.004157
  validation loss:		0.471459
  validation accuracy:		93.04 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.471174
  validation accuracy:		92.93 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003923
  validation loss:		0.470509
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.004111
  validation loss:		0.472764
  validation accuracy:		93.04 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.004218
  validation loss:		0.474553
  validation accuracy:		92.83 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.004073
  validation loss:		0.468122
  validation accuracy:		93.15 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003986
  validation loss:		0.473610
  validation accuracy:		92.93 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.004009
  validation loss:		0.468557
  validation accuracy:		93.04 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003994
  validation loss:		0.473738
  validation accuracy:		93.04 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.004026
  validation loss:		0.474342
  validation accuracy:		92.83 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003999
  validation loss:		0.476467
  validation accuracy:		92.93 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.004007
  validation loss:		0.472981
  validation accuracy:		93.04 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003925
  validation loss:		0.472024
  validation accuracy:		92.72 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003931
  validation loss:		0.473590
  validation accuracy:		92.83 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.004014
  validation loss:		0.472676
  validation accuracy:		92.93 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.004193
  validation loss:		0.471900
  validation accuracy:		93.15 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.004049
  validation loss:		0.473368
  validation accuracy:		93.04 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003959
  validation loss:		0.479886
  validation accuracy:		92.93 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003906
  validation loss:		0.471838
  validation accuracy:		93.04 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.004016
  validation loss:		0.477475
  validation accuracy:		92.83 %
Epoch 1907 of 2000 took 0.036s
  training loss:		0.004078
  validation loss:		0.474914
  validation accuracy:		93.15 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003951
  validation loss:		0.475131
  validation accuracy:		93.04 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.004076
  validation loss:		0.474750
  validation accuracy:		92.83 %
Epoch 1910 of 2000 took 0.036s
  training loss:		0.003829
  validation loss:		0.474865
  validation accuracy:		92.93 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003804
  validation loss:		0.467974
  validation accuracy:		92.93 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003968
  validation loss:		0.477522
  validation accuracy:		92.93 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003904
  validation loss:		0.480634
  validation accuracy:		92.93 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.004011
  validation loss:		0.476038
  validation accuracy:		92.93 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.004019
  validation loss:		0.473347
  validation accuracy:		93.15 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003953
  validation loss:		0.474340
  validation accuracy:		92.83 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003996
  validation loss:		0.476670
  validation accuracy:		92.93 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003936
  validation loss:		0.472132
  validation accuracy:		92.93 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.004004
  validation loss:		0.479709
  validation accuracy:		92.93 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003802
  validation loss:		0.470987
  validation accuracy:		92.93 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.475605
  validation accuracy:		92.83 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.471831
  validation accuracy:		93.04 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003898
  validation loss:		0.476898
  validation accuracy:		92.93 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003837
  validation loss:		0.472373
  validation accuracy:		93.15 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.004058
  validation loss:		0.476334
  validation accuracy:		93.04 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.474301
  validation accuracy:		93.04 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003767
  validation loss:		0.476745
  validation accuracy:		93.15 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003819
  validation loss:		0.478588
  validation accuracy:		92.83 %
Epoch 1929 of 2000 took 0.036s
  training loss:		0.003887
  validation loss:		0.477397
  validation accuracy:		92.72 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003857
  validation loss:		0.476826
  validation accuracy:		93.04 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003841
  validation loss:		0.472691
  validation accuracy:		93.04 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003942
  validation loss:		0.477240
  validation accuracy:		93.04 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003761
  validation loss:		0.477077
  validation accuracy:		93.04 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003864
  validation loss:		0.479190
  validation accuracy:		93.15 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003950
  validation loss:		0.475325
  validation accuracy:		92.93 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003830
  validation loss:		0.473099
  validation accuracy:		93.04 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003828
  validation loss:		0.478539
  validation accuracy:		92.83 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003872
  validation loss:		0.473909
  validation accuracy:		93.15 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003889
  validation loss:		0.475486
  validation accuracy:		93.15 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003925
  validation loss:		0.477821
  validation accuracy:		93.04 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003818
  validation loss:		0.474513
  validation accuracy:		92.83 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003793
  validation loss:		0.476920
  validation accuracy:		92.83 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003792
  validation loss:		0.474325
  validation accuracy:		93.15 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.478793
  validation accuracy:		92.83 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003779
  validation loss:		0.473220
  validation accuracy:		93.04 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003779
  validation loss:		0.482087
  validation accuracy:		92.93 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003818
  validation loss:		0.478723
  validation accuracy:		93.04 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003836
  validation loss:		0.479339
  validation accuracy:		92.83 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003974
  validation loss:		0.476701
  validation accuracy:		92.93 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003578
  validation loss:		0.479382
  validation accuracy:		93.04 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.483106
  validation accuracy:		93.15 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003735
  validation loss:		0.477469
  validation accuracy:		92.83 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003727
  validation loss:		0.474386
  validation accuracy:		93.04 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003715
  validation loss:		0.477978
  validation accuracy:		92.83 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003832
  validation loss:		0.475543
  validation accuracy:		93.04 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003810
  validation loss:		0.476678
  validation accuracy:		92.93 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003762
  validation loss:		0.475075
  validation accuracy:		93.04 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003685
  validation loss:		0.484568
  validation accuracy:		92.83 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003876
  validation loss:		0.475493
  validation accuracy:		93.04 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003711
  validation loss:		0.480547
  validation accuracy:		93.04 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003685
  validation loss:		0.477390
  validation accuracy:		92.93 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003739
  validation loss:		0.480740
  validation accuracy:		92.93 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003722
  validation loss:		0.475359
  validation accuracy:		92.93 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003654
  validation loss:		0.480939
  validation accuracy:		93.04 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003697
  validation loss:		0.478202
  validation accuracy:		92.93 %
Epoch 1966 of 2000 took 0.036s
  training loss:		0.003764
  validation loss:		0.482279
  validation accuracy:		93.04 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003635
  validation loss:		0.478433
  validation accuracy:		92.93 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.476220
  validation accuracy:		92.93 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003705
  validation loss:		0.481014
  validation accuracy:		93.15 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.475471
  validation accuracy:		92.93 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003768
  validation loss:		0.476386
  validation accuracy:		92.93 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003739
  validation loss:		0.478970
  validation accuracy:		92.93 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.484214
  validation accuracy:		92.93 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003754
  validation loss:		0.480719
  validation accuracy:		93.15 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003789
  validation loss:		0.482842
  validation accuracy:		92.93 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003553
  validation loss:		0.480441
  validation accuracy:		93.15 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003681
  validation loss:		0.484686
  validation accuracy:		92.83 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003575
  validation loss:		0.481191
  validation accuracy:		93.15 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003576
  validation loss:		0.484918
  validation accuracy:		92.93 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.481984
  validation accuracy:		93.04 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003738
  validation loss:		0.485854
  validation accuracy:		92.93 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003698
  validation loss:		0.478002
  validation accuracy:		92.93 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003667
  validation loss:		0.483729
  validation accuracy:		92.93 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003542
  validation loss:		0.481117
  validation accuracy:		92.83 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003639
  validation loss:		0.481172
  validation accuracy:		93.04 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003572
  validation loss:		0.488233
  validation accuracy:		92.83 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003517
  validation loss:		0.484838
  validation accuracy:		92.93 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.486802
  validation accuracy:		93.15 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003575
  validation loss:		0.478428
  validation accuracy:		92.83 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003643
  validation loss:		0.484616
  validation accuracy:		92.93 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003674
  validation loss:		0.484215
  validation accuracy:		92.83 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003505
  validation loss:		0.483265
  validation accuracy:		93.04 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003502
  validation loss:		0.484825
  validation accuracy:		92.83 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003518
  validation loss:		0.480044
  validation accuracy:		92.93 %
Epoch 1995 of 2000 took 0.036s
  training loss:		0.003463
  validation loss:		0.480394
  validation accuracy:		93.04 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003550
  validation loss:		0.486546
  validation accuracy:		92.93 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003525
  validation loss:		0.481902
  validation accuracy:		93.15 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003675
  validation loss:		0.483055
  validation accuracy:		93.04 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003576
  validation loss:		0.480943
  validation accuracy:		92.83 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003545
  validation loss:		0.485885
  validation accuracy:		92.83 %
Final results:
  test loss:			1.183121
  test accuracy:		84.75 %
