Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.105s
  training loss:		2.987463
  validation loss:		2.971277
  validation accuracy:		2.28 %
Epoch 2 of 2000 took 0.103s
  training loss:		2.933502
  validation loss:		2.909750
  validation accuracy:		11.41 %
Epoch 3 of 2000 took 0.104s
  training loss:		2.874075
  validation loss:		2.849936
  validation accuracy:		11.85 %
Epoch 4 of 2000 took 0.104s
  training loss:		2.817790
  validation loss:		2.794791
  validation accuracy:		11.85 %
Epoch 5 of 2000 took 0.108s
  training loss:		2.766981
  validation loss:		2.741060
  validation accuracy:		11.85 %
Epoch 6 of 2000 took 0.104s
  training loss:		2.720676
  validation loss:		2.686738
  validation accuracy:		11.85 %
Epoch 7 of 2000 took 0.104s
  training loss:		2.674342
  validation loss:		2.630723
  validation accuracy:		12.17 %
Epoch 8 of 2000 took 0.103s
  training loss:		2.628731
  validation loss:		2.572072
  validation accuracy:		16.63 %
Epoch 9 of 2000 took 0.103s
  training loss:		2.581215
  validation loss:		2.511664
  validation accuracy:		13.48 %
Epoch 10 of 2000 took 0.103s
  training loss:		2.536777
  validation loss:		2.453346
  validation accuracy:		12.93 %
Epoch 11 of 2000 took 0.103s
  training loss:		2.491693
  validation loss:		2.398021
  validation accuracy:		12.93 %
Epoch 12 of 2000 took 0.104s
  training loss:		2.450472
  validation loss:		2.349870
  validation accuracy:		12.93 %
Epoch 13 of 2000 took 0.103s
  training loss:		2.410123
  validation loss:		2.311054
  validation accuracy:		13.70 %
Epoch 14 of 2000 took 0.104s
  training loss:		2.379139
  validation loss:		2.283650
  validation accuracy:		14.89 %
Epoch 15 of 2000 took 0.103s
  training loss:		2.353646
  validation loss:		2.266586
  validation accuracy:		16.41 %
Epoch 16 of 2000 took 0.104s
  training loss:		2.331005
  validation loss:		2.258890
  validation accuracy:		16.41 %
Epoch 17 of 2000 took 0.104s
  training loss:		2.315025
  validation loss:		2.254763
  validation accuracy:		17.50 %
Epoch 18 of 2000 took 0.105s
  training loss:		2.304164
  validation loss:		2.250653
  validation accuracy:		15.22 %
Epoch 19 of 2000 took 0.107s
  training loss:		2.295455
  validation loss:		2.245288
  validation accuracy:		15.65 %
Epoch 20 of 2000 took 0.104s
  training loss:		2.291778
  validation loss:		2.245788
  validation accuracy:		17.28 %
Epoch 21 of 2000 took 0.104s
  training loss:		2.286299
  validation loss:		2.239264
  validation accuracy:		18.48 %
Epoch 22 of 2000 took 0.104s
  training loss:		2.282192
  validation loss:		2.230911
  validation accuracy:		17.93 %
Epoch 23 of 2000 took 0.103s
  training loss:		2.279348
  validation loss:		2.228277
  validation accuracy:		18.70 %
Epoch 24 of 2000 took 0.103s
  training loss:		2.276905
  validation loss:		2.225455
  validation accuracy:		20.65 %
Epoch 25 of 2000 took 0.104s
  training loss:		2.273647
  validation loss:		2.225039
  validation accuracy:		23.80 %
Epoch 26 of 2000 took 0.104s
  training loss:		2.271445
  validation loss:		2.220908
  validation accuracy:		18.48 %
Epoch 27 of 2000 took 0.104s
  training loss:		2.268764
  validation loss:		2.217272
  validation accuracy:		21.20 %
Epoch 28 of 2000 took 0.107s
  training loss:		2.267069
  validation loss:		2.215804
  validation accuracy:		23.04 %
Epoch 29 of 2000 took 0.104s
  training loss:		2.264887
  validation loss:		2.214551
  validation accuracy:		23.91 %
Epoch 30 of 2000 took 0.103s
  training loss:		2.262605
  validation loss:		2.213418
  validation accuracy:		26.09 %
Epoch 31 of 2000 took 0.104s
  training loss:		2.260852
  validation loss:		2.209043
  validation accuracy:		19.46 %
Epoch 32 of 2000 took 0.104s
  training loss:		2.258353
  validation loss:		2.209050
  validation accuracy:		23.15 %
Epoch 33 of 2000 took 0.104s
  training loss:		2.255251
  validation loss:		2.207055
  validation accuracy:		21.85 %
Epoch 34 of 2000 took 0.104s
  training loss:		2.253234
  validation loss:		2.200688
  validation accuracy:		26.85 %
Epoch 35 of 2000 took 0.104s
  training loss:		2.248639
  validation loss:		2.192067
  validation accuracy:		28.91 %
Epoch 36 of 2000 took 0.104s
  training loss:		2.246949
  validation loss:		2.194816
  validation accuracy:		28.59 %
Epoch 37 of 2000 took 0.104s
  training loss:		2.244230
  validation loss:		2.195025
  validation accuracy:		28.15 %
Epoch 38 of 2000 took 0.104s
  training loss:		2.240563
  validation loss:		2.185310
  validation accuracy:		32.17 %
Epoch 39 of 2000 took 0.108s
  training loss:		2.238187
  validation loss:		2.183954
  validation accuracy:		31.52 %
Epoch 40 of 2000 took 0.104s
  training loss:		2.235360
  validation loss:		2.184173
  validation accuracy:		31.85 %
Epoch 41 of 2000 took 0.104s
  training loss:		2.230590
  validation loss:		2.173681
  validation accuracy:		25.65 %
Epoch 42 of 2000 took 0.104s
  training loss:		2.226884
  validation loss:		2.168398
  validation accuracy:		28.59 %
Epoch 43 of 2000 took 0.104s
  training loss:		2.223798
  validation loss:		2.170790
  validation accuracy:		38.37 %
Epoch 44 of 2000 took 0.103s
  training loss:		2.218581
  validation loss:		2.162830
  validation accuracy:		31.30 %
Epoch 45 of 2000 took 0.104s
  training loss:		2.214705
  validation loss:		2.158477
  validation accuracy:		36.63 %
Epoch 46 of 2000 took 0.103s
  training loss:		2.209023
  validation loss:		2.156175
  validation accuracy:		36.52 %
Epoch 47 of 2000 took 0.104s
  training loss:		2.203100
  validation loss:		2.147020
  validation accuracy:		34.57 %
Epoch 48 of 2000 took 0.104s
  training loss:		2.197217
  validation loss:		2.133463
  validation accuracy:		37.17 %
Epoch 49 of 2000 took 0.104s
  training loss:		2.191330
  validation loss:		2.133000
  validation accuracy:		37.28 %
Epoch 50 of 2000 took 0.107s
  training loss:		2.181859
  validation loss:		2.121332
  validation accuracy:		38.91 %
Epoch 51 of 2000 took 0.104s
  training loss:		2.177454
  validation loss:		2.115227
  validation accuracy:		37.07 %
Epoch 52 of 2000 took 0.104s
  training loss:		2.168733
  validation loss:		2.106098
  validation accuracy:		40.98 %
Epoch 53 of 2000 took 0.103s
  training loss:		2.159162
  validation loss:		2.092485
  validation accuracy:		39.35 %
Epoch 54 of 2000 took 0.104s
  training loss:		2.146724
  validation loss:		2.081267
  validation accuracy:		41.52 %
Epoch 55 of 2000 took 0.104s
  training loss:		2.138553
  validation loss:		2.074730
  validation accuracy:		41.96 %
Epoch 56 of 2000 took 0.104s
  training loss:		2.125898
  validation loss:		2.058854
  validation accuracy:		45.43 %
Epoch 57 of 2000 took 0.104s
  training loss:		2.111736
  validation loss:		2.041003
  validation accuracy:		44.46 %
Epoch 58 of 2000 took 0.104s
  training loss:		2.096919
  validation loss:		2.019471
  validation accuracy:		43.70 %
Epoch 59 of 2000 took 0.104s
  training loss:		2.080882
  validation loss:		2.007143
  validation accuracy:		45.87 %
Epoch 60 of 2000 took 0.104s
  training loss:		2.062898
  validation loss:		1.983461
  validation accuracy:		46.52 %
Epoch 61 of 2000 took 0.104s
  training loss:		2.041850
  validation loss:		1.958951
  validation accuracy:		45.11 %
Epoch 62 of 2000 took 0.103s
  training loss:		2.020859
  validation loss:		1.934512
  validation accuracy:		45.43 %
Epoch 63 of 2000 took 0.107s
  training loss:		1.994046
  validation loss:		1.904987
  validation accuracy:		46.85 %
Epoch 64 of 2000 took 0.104s
  training loss:		1.966854
  validation loss:		1.870991
  validation accuracy:		48.04 %
Epoch 65 of 2000 took 0.103s
  training loss:		1.934897
  validation loss:		1.839400
  validation accuracy:		48.48 %
Epoch 66 of 2000 took 0.104s
  training loss:		1.903755
  validation loss:		1.802852
  validation accuracy:		50.98 %
Epoch 67 of 2000 took 0.104s
  training loss:		1.869258
  validation loss:		1.761865
  validation accuracy:		50.87 %
Epoch 68 of 2000 took 0.104s
  training loss:		1.828612
  validation loss:		1.725292
  validation accuracy:		52.07 %
Epoch 69 of 2000 took 0.103s
  training loss:		1.790495
  validation loss:		1.674762
  validation accuracy:		52.50 %
Epoch 70 of 2000 took 0.104s
  training loss:		1.749569
  validation loss:		1.629235
  validation accuracy:		53.91 %
Epoch 71 of 2000 took 0.103s
  training loss:		1.703339
  validation loss:		1.592736
  validation accuracy:		54.24 %
Epoch 72 of 2000 took 0.104s
  training loss:		1.664870
  validation loss:		1.536166
  validation accuracy:		56.30 %
Epoch 73 of 2000 took 0.103s
  training loss:		1.620000
  validation loss:		1.491074
  validation accuracy:		57.39 %
Epoch 74 of 2000 took 0.104s
  training loss:		1.570569
  validation loss:		1.447374
  validation accuracy:		58.48 %
Epoch 75 of 2000 took 0.104s
  training loss:		1.535946
  validation loss:		1.400382
  validation accuracy:		60.43 %
Epoch 76 of 2000 took 0.103s
  training loss:		1.489843
  validation loss:		1.359115
  validation accuracy:		60.11 %
Epoch 77 of 2000 took 0.109s
  training loss:		1.451637
  validation loss:		1.321787
  validation accuracy:		62.83 %
Epoch 78 of 2000 took 0.104s
  training loss:		1.414950
  validation loss:		1.280653
  validation accuracy:		62.39 %
Epoch 79 of 2000 took 0.104s
  training loss:		1.373774
  validation loss:		1.247439
  validation accuracy:		63.80 %
Epoch 80 of 2000 took 0.103s
  training loss:		1.346714
  validation loss:		1.215061
  validation accuracy:		65.22 %
Epoch 81 of 2000 took 0.103s
  training loss:		1.312509
  validation loss:		1.180958
  validation accuracy:		66.41 %
Epoch 82 of 2000 took 0.103s
  training loss:		1.284485
  validation loss:		1.150325
  validation accuracy:		65.98 %
Epoch 83 of 2000 took 0.103s
  training loss:		1.252707
  validation loss:		1.132029
  validation accuracy:		65.43 %
Epoch 84 of 2000 took 0.104s
  training loss:		1.221259
  validation loss:		1.098659
  validation accuracy:		68.70 %
Epoch 85 of 2000 took 0.103s
  training loss:		1.196837
  validation loss:		1.070319
  validation accuracy:		67.93 %
Epoch 86 of 2000 took 0.103s
  training loss:		1.165316
  validation loss:		1.043741
  validation accuracy:		67.61 %
Epoch 87 of 2000 took 0.104s
  training loss:		1.142320
  validation loss:		1.021186
  validation accuracy:		68.37 %
Epoch 88 of 2000 took 0.103s
  training loss:		1.123822
  validation loss:		0.999237
  validation accuracy:		69.24 %
Epoch 89 of 2000 took 0.105s
  training loss:		1.099268
  validation loss:		0.982200
  validation accuracy:		69.78 %
Epoch 90 of 2000 took 0.103s
  training loss:		1.078262
  validation loss:		0.952497
  validation accuracy:		70.00 %
Epoch 91 of 2000 took 0.104s
  training loss:		1.046680
  validation loss:		0.933347
  validation accuracy:		71.20 %
Epoch 92 of 2000 took 0.104s
  training loss:		1.026739
  validation loss:		0.924959
  validation accuracy:		70.98 %
Epoch 93 of 2000 took 0.107s
  training loss:		1.008282
  validation loss:		0.902626
  validation accuracy:		72.07 %
Epoch 94 of 2000 took 0.104s
  training loss:		0.990968
  validation loss:		0.885324
  validation accuracy:		72.83 %
Epoch 95 of 2000 took 0.104s
  training loss:		0.967107
  validation loss:		0.883773
  validation accuracy:		72.17 %
Epoch 96 of 2000 took 0.104s
  training loss:		0.949531
  validation loss:		0.855223
  validation accuracy:		72.72 %
Epoch 97 of 2000 took 0.104s
  training loss:		0.939931
  validation loss:		0.826605
  validation accuracy:		74.46 %
Epoch 98 of 2000 took 0.104s
  training loss:		0.913623
  validation loss:		0.816687
  validation accuracy:		74.13 %
Epoch 99 of 2000 took 0.104s
  training loss:		0.904189
  validation loss:		0.798191
  validation accuracy:		75.11 %
Epoch 100 of 2000 took 0.103s
  training loss:		0.886935
  validation loss:		0.802474
  validation accuracy:		74.89 %
Epoch 101 of 2000 took 0.103s
  training loss:		0.863994
  validation loss:		0.768746
  validation accuracy:		75.87 %
Epoch 102 of 2000 took 0.103s
  training loss:		0.843308
  validation loss:		0.748525
  validation accuracy:		75.98 %
Epoch 103 of 2000 took 0.104s
  training loss:		0.833520
  validation loss:		0.734126
  validation accuracy:		77.17 %
Epoch 104 of 2000 took 0.104s
  training loss:		0.805643
  validation loss:		0.721572
  validation accuracy:		78.15 %
Epoch 105 of 2000 took 0.103s
  training loss:		0.796018
  validation loss:		0.706833
  validation accuracy:		77.93 %
Epoch 106 of 2000 took 0.105s
  training loss:		0.783658
  validation loss:		0.710705
  validation accuracy:		77.07 %
Epoch 107 of 2000 took 0.104s
  training loss:		0.770590
  validation loss:		0.700907
  validation accuracy:		78.48 %
Epoch 108 of 2000 took 0.104s
  training loss:		0.763952
  validation loss:		0.691460
  validation accuracy:		78.15 %
Epoch 109 of 2000 took 0.104s
  training loss:		0.747085
  validation loss:		0.663444
  validation accuracy:		79.78 %
Epoch 110 of 2000 took 0.107s
  training loss:		0.732279
  validation loss:		0.643774
  validation accuracy:		80.76 %
Epoch 111 of 2000 took 0.104s
  training loss:		0.719047
  validation loss:		0.649431
  validation accuracy:		79.89 %
Epoch 112 of 2000 took 0.103s
  training loss:		0.700579
  validation loss:		0.630737
  validation accuracy:		80.54 %
Epoch 113 of 2000 took 0.103s
  training loss:		0.698723
  validation loss:		0.634484
  validation accuracy:		80.11 %
Epoch 114 of 2000 took 0.103s
  training loss:		0.691099
  validation loss:		0.614402
  validation accuracy:		81.41 %
Epoch 115 of 2000 took 0.103s
  training loss:		0.673371
  validation loss:		0.603997
  validation accuracy:		80.54 %
Epoch 116 of 2000 took 0.104s
  training loss:		0.665297
  validation loss:		0.592604
  validation accuracy:		81.63 %
Epoch 117 of 2000 took 0.104s
  training loss:		0.659030
  validation loss:		0.579950
  validation accuracy:		81.96 %
Epoch 118 of 2000 took 0.104s
  training loss:		0.644020
  validation loss:		0.569139
  validation accuracy:		82.28 %
Epoch 119 of 2000 took 0.103s
  training loss:		0.641127
  validation loss:		0.592894
  validation accuracy:		81.20 %
Epoch 120 of 2000 took 0.103s
  training loss:		0.627464
  validation loss:		0.558083
  validation accuracy:		82.28 %
Epoch 121 of 2000 took 0.103s
  training loss:		0.621885
  validation loss:		0.555103
  validation accuracy:		81.85 %
Epoch 122 of 2000 took 0.104s
  training loss:		0.609778
  validation loss:		0.554696
  validation accuracy:		81.85 %
Epoch 123 of 2000 took 0.103s
  training loss:		0.602002
  validation loss:		0.537025
  validation accuracy:		82.50 %
Epoch 124 of 2000 took 0.104s
  training loss:		0.594119
  validation loss:		0.525917
  validation accuracy:		83.48 %
Epoch 125 of 2000 took 0.104s
  training loss:		0.596337
  validation loss:		0.547399
  validation accuracy:		82.28 %
Epoch 126 of 2000 took 0.104s
  training loss:		0.583907
  validation loss:		0.521232
  validation accuracy:		84.13 %
Epoch 127 of 2000 took 0.104s
  training loss:		0.580359
  validation loss:		0.516725
  validation accuracy:		82.72 %
Epoch 128 of 2000 took 0.104s
  training loss:		0.573838
  validation loss:		0.513805
  validation accuracy:		84.24 %
Epoch 129 of 2000 took 0.107s
  training loss:		0.572506
  validation loss:		0.526923
  validation accuracy:		82.61 %
Epoch 130 of 2000 took 0.104s
  training loss:		0.562895
  validation loss:		0.533617
  validation accuracy:		82.17 %
Epoch 131 of 2000 took 0.103s
  training loss:		0.547909
  validation loss:		0.493379
  validation accuracy:		84.78 %
Epoch 132 of 2000 took 0.104s
  training loss:		0.555878
  validation loss:		0.491426
  validation accuracy:		84.35 %
Epoch 133 of 2000 took 0.104s
  training loss:		0.544337
  validation loss:		0.486449
  validation accuracy:		84.78 %
Epoch 134 of 2000 took 0.104s
  training loss:		0.531816
  validation loss:		0.519214
  validation accuracy:		82.72 %
Epoch 135 of 2000 took 0.105s
  training loss:		0.538111
  validation loss:		0.485213
  validation accuracy:		84.13 %
Epoch 136 of 2000 took 0.104s
  training loss:		0.533994
  validation loss:		0.480851
  validation accuracy:		84.35 %
Epoch 137 of 2000 took 0.104s
  training loss:		0.534970
  validation loss:		0.476858
  validation accuracy:		84.24 %
Epoch 138 of 2000 took 0.103s
  training loss:		0.519801
  validation loss:		0.481730
  validation accuracy:		84.78 %
Epoch 139 of 2000 took 0.103s
  training loss:		0.512502
  validation loss:		0.483586
  validation accuracy:		84.02 %
Epoch 140 of 2000 took 0.103s
  training loss:		0.518099
  validation loss:		0.479160
  validation accuracy:		84.35 %
Epoch 141 of 2000 took 0.104s
  training loss:		0.512620
  validation loss:		0.452945
  validation accuracy:		85.22 %
Epoch 142 of 2000 took 0.103s
  training loss:		0.505463
  validation loss:		0.459301
  validation accuracy:		85.22 %
Epoch 143 of 2000 took 0.104s
  training loss:		0.502963
  validation loss:		0.486985
  validation accuracy:		84.24 %
Epoch 144 of 2000 took 0.103s
  training loss:		0.496761
  validation loss:		0.445081
  validation accuracy:		85.22 %
Epoch 145 of 2000 took 0.104s
  training loss:		0.498802
  validation loss:		0.442687
  validation accuracy:		85.65 %
Epoch 146 of 2000 took 0.103s
  training loss:		0.492672
  validation loss:		0.440687
  validation accuracy:		86.20 %
Epoch 147 of 2000 took 0.104s
  training loss:		0.483404
  validation loss:		0.434779
  validation accuracy:		85.43 %
Epoch 148 of 2000 took 0.104s
  training loss:		0.493985
  validation loss:		0.456372
  validation accuracy:		85.76 %
Epoch 149 of 2000 took 0.107s
  training loss:		0.479332
  validation loss:		0.440081
  validation accuracy:		86.30 %
Epoch 150 of 2000 took 0.104s
  training loss:		0.481665
  validation loss:		0.475971
  validation accuracy:		84.67 %
Epoch 151 of 2000 took 0.104s
  training loss:		0.476140
  validation loss:		0.440853
  validation accuracy:		86.20 %
Epoch 152 of 2000 took 0.104s
  training loss:		0.468072
  validation loss:		0.431955
  validation accuracy:		86.09 %
Epoch 153 of 2000 took 0.103s
  training loss:		0.468939
  validation loss:		0.437703
  validation accuracy:		85.65 %
Epoch 154 of 2000 took 0.104s
  training loss:		0.472147
  validation loss:		0.434977
  validation accuracy:		86.41 %
Epoch 155 of 2000 took 0.103s
  training loss:		0.457823
  validation loss:		0.422284
  validation accuracy:		86.52 %
Epoch 156 of 2000 took 0.104s
  training loss:		0.455410
  validation loss:		0.450027
  validation accuracy:		85.65 %
Epoch 157 of 2000 took 0.104s
  training loss:		0.460856
  validation loss:		0.425904
  validation accuracy:		86.74 %
Epoch 158 of 2000 took 0.103s
  training loss:		0.463670
  validation loss:		0.442881
  validation accuracy:		86.20 %
Epoch 159 of 2000 took 0.103s
  training loss:		0.453486
  validation loss:		0.456569
  validation accuracy:		85.87 %
Epoch 160 of 2000 took 0.103s
  training loss:		0.448253
  validation loss:		0.412301
  validation accuracy:		86.52 %
Epoch 161 of 2000 took 0.103s
  training loss:		0.446835
  validation loss:		0.405043
  validation accuracy:		86.96 %
Epoch 162 of 2000 took 0.104s
  training loss:		0.451061
  validation loss:		0.410048
  validation accuracy:		86.52 %
Epoch 163 of 2000 took 0.103s
  training loss:		0.441228
  validation loss:		0.402410
  validation accuracy:		86.85 %
Epoch 164 of 2000 took 0.104s
  training loss:		0.439299
  validation loss:		0.413245
  validation accuracy:		86.85 %
Epoch 165 of 2000 took 0.103s
  training loss:		0.438806
  validation loss:		0.412431
  validation accuracy:		86.74 %
Epoch 166 of 2000 took 0.104s
  training loss:		0.434502
  validation loss:		0.410861
  validation accuracy:		86.63 %
Epoch 167 of 2000 took 0.103s
  training loss:		0.440678
  validation loss:		0.417274
  validation accuracy:		86.52 %
Epoch 168 of 2000 took 0.103s
  training loss:		0.430866
  validation loss:		0.411634
  validation accuracy:		86.74 %
Epoch 169 of 2000 took 0.103s
  training loss:		0.429451
  validation loss:		0.430753
  validation accuracy:		85.87 %
Epoch 170 of 2000 took 0.103s
  training loss:		0.424157
  validation loss:		0.419940
  validation accuracy:		86.41 %
Epoch 171 of 2000 took 0.104s
  training loss:		0.425454
  validation loss:		0.415052
  validation accuracy:		87.07 %
Epoch 172 of 2000 took 0.107s
  training loss:		0.422085
  validation loss:		0.400444
  validation accuracy:		87.28 %
Epoch 173 of 2000 took 0.104s
  training loss:		0.419602
  validation loss:		0.410973
  validation accuracy:		86.74 %
Epoch 174 of 2000 took 0.104s
  training loss:		0.423505
  validation loss:		0.403964
  validation accuracy:		87.83 %
Epoch 175 of 2000 took 0.104s
  training loss:		0.417407
  validation loss:		0.400222
  validation accuracy:		87.07 %
Epoch 176 of 2000 took 0.104s
  training loss:		0.422442
  validation loss:		0.396997
  validation accuracy:		88.26 %
Epoch 177 of 2000 took 0.103s
  training loss:		0.419858
  validation loss:		0.388042
  validation accuracy:		87.50 %
Epoch 178 of 2000 took 0.103s
  training loss:		0.417333
  validation loss:		0.399726
  validation accuracy:		87.07 %
Epoch 179 of 2000 took 0.104s
  training loss:		0.410781
  validation loss:		0.388142
  validation accuracy:		87.61 %
Epoch 180 of 2000 took 0.104s
  training loss:		0.412280
  validation loss:		0.397380
  validation accuracy:		88.37 %
Epoch 181 of 2000 took 0.104s
  training loss:		0.402312
  validation loss:		0.398965
  validation accuracy:		87.07 %
Epoch 182 of 2000 took 0.103s
  training loss:		0.411625
  validation loss:		0.388187
  validation accuracy:		88.15 %
Epoch 183 of 2000 took 0.104s
  training loss:		0.407477
  validation loss:		0.387136
  validation accuracy:		88.59 %
Epoch 184 of 2000 took 0.104s
  training loss:		0.404503
  validation loss:		0.391554
  validation accuracy:		88.37 %
Epoch 185 of 2000 took 0.104s
  training loss:		0.404337
  validation loss:		0.397690
  validation accuracy:		86.85 %
Epoch 186 of 2000 took 0.104s
  training loss:		0.396998
  validation loss:		0.395552
  validation accuracy:		88.15 %
Epoch 187 of 2000 took 0.103s
  training loss:		0.403347
  validation loss:		0.402258
  validation accuracy:		87.83 %
Epoch 188 of 2000 took 0.104s
  training loss:		0.400764
  validation loss:		0.389916
  validation accuracy:		88.37 %
Epoch 189 of 2000 took 0.104s
  training loss:		0.395572
  validation loss:		0.385046
  validation accuracy:		88.48 %
Epoch 190 of 2000 took 0.103s
  training loss:		0.403218
  validation loss:		0.403216
  validation accuracy:		88.15 %
Epoch 191 of 2000 took 0.104s
  training loss:		0.397389
  validation loss:		0.375743
  validation accuracy:		88.26 %
Epoch 192 of 2000 took 0.103s
  training loss:		0.389237
  validation loss:		0.400398
  validation accuracy:		87.93 %
Epoch 193 of 2000 took 0.105s
  training loss:		0.389157
  validation loss:		0.397289
  validation accuracy:		87.50 %
Epoch 194 of 2000 took 0.103s
  training loss:		0.391490
  validation loss:		0.409685
  validation accuracy:		87.72 %
Epoch 195 of 2000 took 0.104s
  training loss:		0.394929
  validation loss:		0.394242
  validation accuracy:		87.61 %
Epoch 196 of 2000 took 0.103s
  training loss:		0.387740
  validation loss:		0.371207
  validation accuracy:		88.04 %
Epoch 197 of 2000 took 0.107s
  training loss:		0.391331
  validation loss:		0.400825
  validation accuracy:		87.83 %
Epoch 198 of 2000 took 0.104s
  training loss:		0.383173
  validation loss:		0.377546
  validation accuracy:		87.93 %
Epoch 199 of 2000 took 0.104s
  training loss:		0.379373
  validation loss:		0.368612
  validation accuracy:		88.26 %
Epoch 200 of 2000 took 0.103s
  training loss:		0.378689
  validation loss:		0.382190
  validation accuracy:		87.61 %
Epoch 201 of 2000 took 0.104s
  training loss:		0.384431
  validation loss:		0.369689
  validation accuracy:		88.70 %
Epoch 202 of 2000 took 0.103s
  training loss:		0.375915
  validation loss:		0.379074
  validation accuracy:		87.93 %
Epoch 203 of 2000 took 0.104s
  training loss:		0.378253
  validation loss:		0.374757
  validation accuracy:		88.04 %
Epoch 204 of 2000 took 0.103s
  training loss:		0.376526
  validation loss:		0.374758
  validation accuracy:		87.50 %
Epoch 205 of 2000 took 0.104s
  training loss:		0.376976
  validation loss:		0.380360
  validation accuracy:		88.37 %
Epoch 206 of 2000 took 0.103s
  training loss:		0.374652
  validation loss:		0.375222
  validation accuracy:		88.48 %
Epoch 207 of 2000 took 0.103s
  training loss:		0.383843
  validation loss:		0.370183
  validation accuracy:		88.70 %
Epoch 208 of 2000 took 0.104s
  training loss:		0.376492
  validation loss:		0.364424
  validation accuracy:		88.37 %
Epoch 209 of 2000 took 0.103s
  training loss:		0.376315
  validation loss:		0.373360
  validation accuracy:		88.48 %
Epoch 210 of 2000 took 0.104s
  training loss:		0.371917
  validation loss:		0.375854
  validation accuracy:		88.04 %
Epoch 211 of 2000 took 0.104s
  training loss:		0.359803
  validation loss:		0.392762
  validation accuracy:		87.93 %
Epoch 212 of 2000 took 0.104s
  training loss:		0.362202
  validation loss:		0.368146
  validation accuracy:		88.37 %
Epoch 213 of 2000 took 0.104s
  training loss:		0.371809
  validation loss:		0.384427
  validation accuracy:		88.37 %
Epoch 214 of 2000 took 0.104s
  training loss:		0.370460
  validation loss:		0.372974
  validation accuracy:		88.37 %
Epoch 215 of 2000 took 0.104s
  training loss:		0.367083
  validation loss:		0.380592
  validation accuracy:		88.15 %
Epoch 216 of 2000 took 0.103s
  training loss:		0.355847
  validation loss:		0.368359
  validation accuracy:		88.59 %
Epoch 217 of 2000 took 0.103s
  training loss:		0.367536
  validation loss:		0.365163
  validation accuracy:		88.48 %
Epoch 218 of 2000 took 0.104s
  training loss:		0.363282
  validation loss:		0.378331
  validation accuracy:		87.83 %
Epoch 219 of 2000 took 0.104s
  training loss:		0.367908
  validation loss:		0.374463
  validation accuracy:		88.48 %
Epoch 220 of 2000 took 0.104s
  training loss:		0.362344
  validation loss:		0.399629
  validation accuracy:		87.07 %
Epoch 221 of 2000 took 0.104s
  training loss:		0.367264
  validation loss:		0.369235
  validation accuracy:		88.80 %
Epoch 222 of 2000 took 0.105s
  training loss:		0.352980
  validation loss:		0.397745
  validation accuracy:		87.39 %
Epoch 223 of 2000 took 0.104s
  training loss:		0.356979
  validation loss:		0.368770
  validation accuracy:		88.59 %
Epoch 224 of 2000 took 0.104s
  training loss:		0.357444
  validation loss:		0.377039
  validation accuracy:		88.48 %
Epoch 225 of 2000 took 0.107s
  training loss:		0.360195
  validation loss:		0.370488
  validation accuracy:		88.80 %
Epoch 226 of 2000 took 0.104s
  training loss:		0.357123
  validation loss:		0.374246
  validation accuracy:		88.48 %
Epoch 227 of 2000 took 0.103s
  training loss:		0.350886
  validation loss:		0.371490
  validation accuracy:		88.59 %
Epoch 228 of 2000 took 0.104s
  training loss:		0.361443
  validation loss:		0.374300
  validation accuracy:		88.59 %
Epoch 229 of 2000 took 0.103s
  training loss:		0.351994
  validation loss:		0.361544
  validation accuracy:		88.70 %
Epoch 230 of 2000 took 0.104s
  training loss:		0.353901
  validation loss:		0.371730
  validation accuracy:		88.26 %
Epoch 231 of 2000 took 0.103s
  training loss:		0.356265
  validation loss:		0.370196
  validation accuracy:		88.80 %
Epoch 232 of 2000 took 0.104s
  training loss:		0.352818
  validation loss:		0.361948
  validation accuracy:		88.80 %
Epoch 233 of 2000 took 0.103s
  training loss:		0.356966
  validation loss:		0.383759
  validation accuracy:		88.04 %
Epoch 234 of 2000 took 0.104s
  training loss:		0.353884
  validation loss:		0.370008
  validation accuracy:		88.04 %
Epoch 235 of 2000 took 0.104s
  training loss:		0.356390
  validation loss:		0.371343
  validation accuracy:		88.70 %
Epoch 236 of 2000 took 0.104s
  training loss:		0.356416
  validation loss:		0.360606
  validation accuracy:		88.59 %
Epoch 237 of 2000 took 0.104s
  training loss:		0.347487
  validation loss:		0.358005
  validation accuracy:		89.02 %
Epoch 238 of 2000 took 0.104s
  training loss:		0.353561
  validation loss:		0.355335
  validation accuracy:		89.02 %
Epoch 239 of 2000 took 0.104s
  training loss:		0.346367
  validation loss:		0.367126
  validation accuracy:		88.26 %
Epoch 240 of 2000 took 0.104s
  training loss:		0.349839
  validation loss:		0.359020
  validation accuracy:		89.24 %
Epoch 241 of 2000 took 0.104s
  training loss:		0.346612
  validation loss:		0.362151
  validation accuracy:		88.80 %
Epoch 242 of 2000 took 0.104s
  training loss:		0.347084
  validation loss:		0.384592
  validation accuracy:		87.61 %
Epoch 243 of 2000 took 0.102s
  training loss:		0.350386
  validation loss:		0.374516
  validation accuracy:		88.70 %
Epoch 244 of 2000 took 0.110s
  training loss:		0.346546
  validation loss:		0.368577
  validation accuracy:		88.91 %
Epoch 245 of 2000 took 0.106s
  training loss:		0.351235
  validation loss:		0.367055
  validation accuracy:		89.02 %
Epoch 246 of 2000 took 0.100s
  training loss:		0.346621
  validation loss:		0.361820
  validation accuracy:		87.61 %
Epoch 247 of 2000 took 0.100s
  training loss:		0.342551
  validation loss:		0.371117
  validation accuracy:		88.59 %
Epoch 248 of 2000 took 0.100s
  training loss:		0.343105
  validation loss:		0.363955
  validation accuracy:		88.59 %
Epoch 249 of 2000 took 0.100s
  training loss:		0.344662
  validation loss:		0.363943
  validation accuracy:		88.26 %
Epoch 250 of 2000 took 0.100s
  training loss:		0.342111
  validation loss:		0.374094
  validation accuracy:		88.37 %
Epoch 251 of 2000 took 0.101s
  training loss:		0.335191
  validation loss:		0.363923
  validation accuracy:		88.80 %
Epoch 252 of 2000 took 0.104s
  training loss:		0.339989
  validation loss:		0.359479
  validation accuracy:		88.70 %
Epoch 253 of 2000 took 0.101s
  training loss:		0.333665
  validation loss:		0.359056
  validation accuracy:		88.91 %
Epoch 254 of 2000 took 0.100s
  training loss:		0.341784
  validation loss:		0.369453
  validation accuracy:		88.59 %
Epoch 255 of 2000 took 0.105s
  training loss:		0.340400
  validation loss:		0.366712
  validation accuracy:		88.26 %
Epoch 256 of 2000 took 0.101s
  training loss:		0.338537
  validation loss:		0.363931
  validation accuracy:		88.91 %
Epoch 257 of 2000 took 0.100s
  training loss:		0.339914
  validation loss:		0.358478
  validation accuracy:		88.59 %
Epoch 258 of 2000 took 0.100s
  training loss:		0.333822
  validation loss:		0.369843
  validation accuracy:		87.72 %
Epoch 259 of 2000 took 0.100s
  training loss:		0.338624
  validation loss:		0.347938
  validation accuracy:		88.91 %
Epoch 260 of 2000 took 0.100s
  training loss:		0.339722
  validation loss:		0.379004
  validation accuracy:		87.50 %
Epoch 261 of 2000 took 0.100s
  training loss:		0.330822
  validation loss:		0.358530
  validation accuracy:		88.80 %
Epoch 262 of 2000 took 0.100s
  training loss:		0.330884
  validation loss:		0.355562
  validation accuracy:		88.80 %
Epoch 263 of 2000 took 0.100s
  training loss:		0.332579
  validation loss:		0.358693
  validation accuracy:		89.02 %
Epoch 264 of 2000 took 0.100s
  training loss:		0.332724
  validation loss:		0.388828
  validation accuracy:		87.50 %
Epoch 265 of 2000 took 0.100s
  training loss:		0.336212
  validation loss:		0.353586
  validation accuracy:		88.91 %
Epoch 266 of 2000 took 0.100s
  training loss:		0.329878
  validation loss:		0.356986
  validation accuracy:		88.91 %
Epoch 267 of 2000 took 0.100s
  training loss:		0.328304
  validation loss:		0.353761
  validation accuracy:		89.57 %
Epoch 268 of 2000 took 0.100s
  training loss:		0.338048
  validation loss:		0.364574
  validation accuracy:		88.70 %
Epoch 269 of 2000 took 0.100s
  training loss:		0.332141
  validation loss:		0.363633
  validation accuracy:		88.59 %
Epoch 270 of 2000 took 0.100s
  training loss:		0.330314
  validation loss:		0.362760
  validation accuracy:		88.70 %
Epoch 271 of 2000 took 0.100s
  training loss:		0.329436
  validation loss:		0.358954
  validation accuracy:		88.91 %
Epoch 272 of 2000 took 0.100s
  training loss:		0.318631
  validation loss:		0.353940
  validation accuracy:		89.02 %
Epoch 273 of 2000 took 0.099s
  training loss:		0.327919
  validation loss:		0.355147
  validation accuracy:		89.02 %
Epoch 274 of 2000 took 0.097s
  training loss:		0.325615
  validation loss:		0.352410
  validation accuracy:		89.02 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.330315
  validation loss:		0.359138
  validation accuracy:		88.70 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.324214
  validation loss:		0.366149
  validation accuracy:		88.26 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.329752
  validation loss:		0.355642
  validation accuracy:		88.80 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.325072
  validation loss:		0.348281
  validation accuracy:		88.70 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.323546
  validation loss:		0.371079
  validation accuracy:		88.26 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.332129
  validation loss:		0.363389
  validation accuracy:		88.59 %
Epoch 281 of 2000 took 0.098s
  training loss:		0.325130
  validation loss:		0.349027
  validation accuracy:		89.02 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.318212
  validation loss:		0.347748
  validation accuracy:		88.91 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.325534
  validation loss:		0.365379
  validation accuracy:		88.15 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.319761
  validation loss:		0.369805
  validation accuracy:		88.15 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.329018
  validation loss:		0.366230
  validation accuracy:		88.59 %
Epoch 286 of 2000 took 0.100s
  training loss:		0.330993
  validation loss:		0.360031
  validation accuracy:		88.37 %
Epoch 287 of 2000 took 0.103s
  training loss:		0.319850
  validation loss:		0.365411
  validation accuracy:		88.70 %
Epoch 288 of 2000 took 0.103s
  training loss:		0.322296
  validation loss:		0.378351
  validation accuracy:		87.72 %
Epoch 289 of 2000 took 0.104s
  training loss:		0.325515
  validation loss:		0.359684
  validation accuracy:		88.70 %
Epoch 290 of 2000 took 0.106s
  training loss:		0.326126
  validation loss:		0.371155
  validation accuracy:		87.83 %
Epoch 291 of 2000 took 0.103s
  training loss:		0.325313
  validation loss:		0.345380
  validation accuracy:		89.35 %
Epoch 292 of 2000 took 0.100s
  training loss:		0.325823
  validation loss:		0.358829
  validation accuracy:		88.59 %
Epoch 293 of 2000 took 0.100s
  training loss:		0.319476
  validation loss:		0.353506
  validation accuracy:		88.80 %
Epoch 294 of 2000 took 0.100s
  training loss:		0.323576
  validation loss:		0.346611
  validation accuracy:		89.35 %
Epoch 295 of 2000 took 0.100s
  training loss:		0.325521
  validation loss:		0.362354
  validation accuracy:		88.70 %
Epoch 296 of 2000 took 0.100s
  training loss:		0.320813
  validation loss:		0.398118
  validation accuracy:		87.39 %
Epoch 297 of 2000 took 0.100s
  training loss:		0.320969
  validation loss:		0.367610
  validation accuracy:		88.48 %
Epoch 298 of 2000 took 0.100s
  training loss:		0.326207
  validation loss:		0.344920
  validation accuracy:		89.13 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.321715
  validation loss:		0.347616
  validation accuracy:		89.13 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.318187
  validation loss:		0.371351
  validation accuracy:		88.26 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.315152
  validation loss:		0.367395
  validation accuracy:		88.15 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.317133
  validation loss:		0.345812
  validation accuracy:		89.13 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.323284
  validation loss:		0.344110
  validation accuracy:		89.13 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.314626
  validation loss:		0.366876
  validation accuracy:		88.70 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.315893
  validation loss:		0.343057
  validation accuracy:		89.35 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.318417
  validation loss:		0.347872
  validation accuracy:		89.35 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.321666
  validation loss:		0.369197
  validation accuracy:		88.37 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.316459
  validation loss:		0.339536
  validation accuracy:		89.02 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.314468
  validation loss:		0.354493
  validation accuracy:		89.46 %
Epoch 310 of 2000 took 0.097s
  training loss:		0.316186
  validation loss:		0.371301
  validation accuracy:		88.26 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.315993
  validation loss:		0.355604
  validation accuracy:		88.80 %
Epoch 312 of 2000 took 0.098s
  training loss:		0.313498
  validation loss:		0.377316
  validation accuracy:		88.80 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.324541
  validation loss:		0.360527
  validation accuracy:		88.59 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.317954
  validation loss:		0.350848
  validation accuracy:		88.80 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.315708
  validation loss:		0.368741
  validation accuracy:		88.91 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.314014
  validation loss:		0.343175
  validation accuracy:		89.13 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.315758
  validation loss:		0.357377
  validation accuracy:		88.37 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.310094
  validation loss:		0.356590
  validation accuracy:		88.04 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.302533
  validation loss:		0.354542
  validation accuracy:		88.91 %
Epoch 320 of 2000 took 0.097s
  training loss:		0.308014
  validation loss:		0.353230
  validation accuracy:		88.59 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.306585
  validation loss:		0.370979
  validation accuracy:		87.72 %
Epoch 322 of 2000 took 0.097s
  training loss:		0.310303
  validation loss:		0.361900
  validation accuracy:		88.59 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.313934
  validation loss:		0.343487
  validation accuracy:		89.24 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.303318
  validation loss:		0.369001
  validation accuracy:		88.15 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.309393
  validation loss:		0.351732
  validation accuracy:		88.91 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.307806
  validation loss:		0.346507
  validation accuracy:		89.02 %
Epoch 327 of 2000 took 0.097s
  training loss:		0.314407
  validation loss:		0.358586
  validation accuracy:		88.59 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.304422
  validation loss:		0.343316
  validation accuracy:		88.80 %
Epoch 329 of 2000 took 0.100s
  training loss:		0.305189
  validation loss:		0.365096
  validation accuracy:		88.37 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.303095
  validation loss:		0.356812
  validation accuracy:		89.35 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.305586
  validation loss:		0.348482
  validation accuracy:		88.91 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.307120
  validation loss:		0.348759
  validation accuracy:		89.13 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.310447
  validation loss:		0.351694
  validation accuracy:		88.91 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.306690
  validation loss:		0.351559
  validation accuracy:		88.91 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.311119
  validation loss:		0.346019
  validation accuracy:		89.13 %
Epoch 336 of 2000 took 0.097s
  training loss:		0.306338
  validation loss:		0.351108
  validation accuracy:		88.91 %
Epoch 337 of 2000 took 0.097s
  training loss:		0.313653
  validation loss:		0.356816
  validation accuracy:		88.80 %
Epoch 338 of 2000 took 0.097s
  training loss:		0.304154
  validation loss:		0.342068
  validation accuracy:		89.57 %
Epoch 339 of 2000 took 0.097s
  training loss:		0.307958
  validation loss:		0.354466
  validation accuracy:		89.02 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.306719
  validation loss:		0.358040
  validation accuracy:		88.91 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.305248
  validation loss:		0.350602
  validation accuracy:		89.02 %
Epoch 342 of 2000 took 0.097s
  training loss:		0.305516
  validation loss:		0.345909
  validation accuracy:		88.70 %
Epoch 343 of 2000 took 0.098s
  training loss:		0.307123
  validation loss:		0.346834
  validation accuracy:		89.13 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.306307
  validation loss:		0.365887
  validation accuracy:		88.59 %
Epoch 345 of 2000 took 0.097s
  training loss:		0.303065
  validation loss:		0.350715
  validation accuracy:		89.24 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.299772
  validation loss:		0.353096
  validation accuracy:		89.02 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.300424
  validation loss:		0.356166
  validation accuracy:		88.15 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.301059
  validation loss:		0.374756
  validation accuracy:		88.04 %
Epoch 349 of 2000 took 0.097s
  training loss:		0.306642
  validation loss:		0.347273
  validation accuracy:		89.13 %
Epoch 350 of 2000 took 0.097s
  training loss:		0.306886
  validation loss:		0.354141
  validation accuracy:		89.02 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.308543
  validation loss:		0.350748
  validation accuracy:		89.02 %
Epoch 352 of 2000 took 0.097s
  training loss:		0.320206
  validation loss:		0.361890
  validation accuracy:		88.80 %
Epoch 353 of 2000 took 0.097s
  training loss:		0.307030
  validation loss:		0.347159
  validation accuracy:		89.35 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.303139
  validation loss:		0.358314
  validation accuracy:		88.80 %
Epoch 355 of 2000 took 0.097s
  training loss:		0.311554
  validation loss:		0.363804
  validation accuracy:		88.26 %
Epoch 356 of 2000 took 0.097s
  training loss:		0.306764
  validation loss:		0.369374
  validation accuracy:		87.83 %
Epoch 357 of 2000 took 0.097s
  training loss:		0.299758
  validation loss:		0.339405
  validation accuracy:		89.02 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.309997
  validation loss:		0.383367
  validation accuracy:		88.04 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.309919
  validation loss:		0.348960
  validation accuracy:		88.80 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.299732
  validation loss:		0.343191
  validation accuracy:		89.46 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.300939
  validation loss:		0.354774
  validation accuracy:		88.80 %
Epoch 362 of 2000 took 0.097s
  training loss:		0.308967
  validation loss:		0.349375
  validation accuracy:		88.91 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.300785
  validation loss:		0.347786
  validation accuracy:		89.46 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.300361
  validation loss:		0.353511
  validation accuracy:		88.80 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.300307
  validation loss:		0.340457
  validation accuracy:		89.24 %
Epoch 366 of 2000 took 0.097s
  training loss:		0.299595
  validation loss:		0.353555
  validation accuracy:		88.37 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.310839
  validation loss:		0.343379
  validation accuracy:		89.46 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.294997
  validation loss:		0.349696
  validation accuracy:		89.24 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.297606
  validation loss:		0.352026
  validation accuracy:		88.59 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.302163
  validation loss:		0.365089
  validation accuracy:		88.80 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.303713
  validation loss:		0.361665
  validation accuracy:		88.70 %
Epoch 372 of 2000 took 0.099s
  training loss:		0.303338
  validation loss:		0.339510
  validation accuracy:		89.35 %
Epoch 373 of 2000 took 0.098s
  training loss:		0.303561
  validation loss:		0.341497
  validation accuracy:		89.57 %
Epoch 374 of 2000 took 0.098s
  training loss:		0.298671
  validation loss:		0.365320
  validation accuracy:		88.70 %
Epoch 375 of 2000 took 0.097s
  training loss:		0.295765
  validation loss:		0.361683
  validation accuracy:		89.02 %
Epoch 376 of 2000 took 0.097s
  training loss:		0.294269
  validation loss:		0.361791
  validation accuracy:		88.70 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.296011
  validation loss:		0.360252
  validation accuracy:		88.15 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.300195
  validation loss:		0.345894
  validation accuracy:		89.35 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.291862
  validation loss:		0.366037
  validation accuracy:		87.93 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.300163
  validation loss:		0.370390
  validation accuracy:		89.13 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.294606
  validation loss:		0.363248
  validation accuracy:		88.80 %
Epoch 382 of 2000 took 0.097s
  training loss:		0.291423
  validation loss:		0.357591
  validation accuracy:		88.91 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.299831
  validation loss:		0.388554
  validation accuracy:		87.17 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.293837
  validation loss:		0.365787
  validation accuracy:		88.48 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.297768
  validation loss:		0.349553
  validation accuracy:		89.35 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.293417
  validation loss:		0.365877
  validation accuracy:		88.48 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.296750
  validation loss:		0.352440
  validation accuracy:		88.91 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.293265
  validation loss:		0.362488
  validation accuracy:		88.48 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.296561
  validation loss:		0.356172
  validation accuracy:		88.80 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.296757
  validation loss:		0.366948
  validation accuracy:		89.02 %
Epoch 391 of 2000 took 0.097s
  training loss:		0.296546
  validation loss:		0.351291
  validation accuracy:		88.91 %
Epoch 392 of 2000 took 0.097s
  training loss:		0.299882
  validation loss:		0.366357
  validation accuracy:		88.59 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.288203
  validation loss:		0.361247
  validation accuracy:		88.04 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.291921
  validation loss:		0.345080
  validation accuracy:		89.46 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.297491
  validation loss:		0.348029
  validation accuracy:		88.80 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.294514
  validation loss:		0.351381
  validation accuracy:		89.02 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.298115
  validation loss:		0.348538
  validation accuracy:		89.02 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.295642
  validation loss:		0.362258
  validation accuracy:		88.70 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.290282
  validation loss:		0.381048
  validation accuracy:		87.28 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.291717
  validation loss:		0.366985
  validation accuracy:		88.37 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.295362
  validation loss:		0.360686
  validation accuracy:		89.13 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.299304
  validation loss:		0.354902
  validation accuracy:		89.02 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.292425
  validation loss:		0.353016
  validation accuracy:		89.02 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.296957
  validation loss:		0.362532
  validation accuracy:		88.70 %
Epoch 405 of 2000 took 0.098s
  training loss:		0.289233
  validation loss:		0.355204
  validation accuracy:		88.80 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.288480
  validation loss:		0.350149
  validation accuracy:		89.24 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.293756
  validation loss:		0.399009
  validation accuracy:		87.39 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.294816
  validation loss:		0.349202
  validation accuracy:		88.59 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.295129
  validation loss:		0.366857
  validation accuracy:		88.26 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.289972
  validation loss:		0.341953
  validation accuracy:		89.02 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.292189
  validation loss:		0.355629
  validation accuracy:		88.48 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.288201
  validation loss:		0.352170
  validation accuracy:		88.70 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.298142
  validation loss:		0.349339
  validation accuracy:		88.80 %
Epoch 414 of 2000 took 0.098s
  training loss:		0.289825
  validation loss:		0.366017
  validation accuracy:		88.04 %
Epoch 415 of 2000 took 0.100s
  training loss:		0.294602
  validation loss:		0.348670
  validation accuracy:		88.91 %
Epoch 416 of 2000 took 0.100s
  training loss:		0.292002
  validation loss:		0.343528
  validation accuracy:		89.13 %
Epoch 417 of 2000 took 0.100s
  training loss:		0.293791
  validation loss:		0.359195
  validation accuracy:		88.48 %
Epoch 418 of 2000 took 0.100s
  training loss:		0.290935
  validation loss:		0.383148
  validation accuracy:		88.15 %
Epoch 419 of 2000 took 0.100s
  training loss:		0.295774
  validation loss:		0.362229
  validation accuracy:		88.91 %
Epoch 420 of 2000 took 0.100s
  training loss:		0.289592
  validation loss:		0.358596
  validation accuracy:		89.24 %
Epoch 421 of 2000 took 0.100s
  training loss:		0.294524
  validation loss:		0.351951
  validation accuracy:		89.02 %
Epoch 422 of 2000 took 0.100s
  training loss:		0.292523
  validation loss:		0.359923
  validation accuracy:		89.13 %
Epoch 423 of 2000 took 0.101s
  training loss:		0.291173
  validation loss:		0.396914
  validation accuracy:		87.07 %
Epoch 424 of 2000 took 0.102s
  training loss:		0.293738
  validation loss:		0.360970
  validation accuracy:		89.13 %
Epoch 425 of 2000 took 0.100s
  training loss:		0.295035
  validation loss:		0.338240
  validation accuracy:		90.00 %
Epoch 426 of 2000 took 0.100s
  training loss:		0.289751
  validation loss:		0.358783
  validation accuracy:		88.59 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.285503
  validation loss:		0.347659
  validation accuracy:		88.80 %
Epoch 428 of 2000 took 0.100s
  training loss:		0.308082
  validation loss:		0.347899
  validation accuracy:		89.13 %
Epoch 429 of 2000 took 0.100s
  training loss:		0.292686
  validation loss:		0.346082
  validation accuracy:		89.46 %
Epoch 430 of 2000 took 0.100s
  training loss:		0.291774
  validation loss:		0.362344
  validation accuracy:		88.48 %
Epoch 431 of 2000 took 0.100s
  training loss:		0.295693
  validation loss:		0.355299
  validation accuracy:		88.80 %
Epoch 432 of 2000 took 0.100s
  training loss:		0.291268
  validation loss:		0.348554
  validation accuracy:		89.24 %
Epoch 433 of 2000 took 0.100s
  training loss:		0.289630
  validation loss:		0.369477
  validation accuracy:		88.37 %
Epoch 434 of 2000 took 0.100s
  training loss:		0.294056
  validation loss:		0.348583
  validation accuracy:		88.70 %
Epoch 435 of 2000 took 0.101s
  training loss:		0.291477
  validation loss:		0.370194
  validation accuracy:		88.70 %
Epoch 436 of 2000 took 0.100s
  training loss:		0.286181
  validation loss:		0.352954
  validation accuracy:		89.13 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.288601
  validation loss:		0.374049
  validation accuracy:		88.37 %
Epoch 438 of 2000 took 0.100s
  training loss:		0.291716
  validation loss:		0.344986
  validation accuracy:		89.46 %
Epoch 439 of 2000 took 0.100s
  training loss:		0.291332
  validation loss:		0.377491
  validation accuracy:		87.93 %
Epoch 440 of 2000 took 0.100s
  training loss:		0.287440
  validation loss:		0.353355
  validation accuracy:		88.91 %
Epoch 441 of 2000 took 0.100s
  training loss:		0.288599
  validation loss:		0.349910
  validation accuracy:		88.70 %
Epoch 442 of 2000 took 0.100s
  training loss:		0.284675
  validation loss:		0.352544
  validation accuracy:		88.91 %
Epoch 443 of 2000 took 0.100s
  training loss:		0.293681
  validation loss:		0.348310
  validation accuracy:		89.02 %
Epoch 444 of 2000 took 0.100s
  training loss:		0.287181
  validation loss:		0.344267
  validation accuracy:		88.91 %
Epoch 445 of 2000 took 0.100s
  training loss:		0.280973
  validation loss:		0.350505
  validation accuracy:		88.80 %
Epoch 446 of 2000 took 0.100s
  training loss:		0.288157
  validation loss:		0.361955
  validation accuracy:		88.80 %
Epoch 447 of 2000 took 0.100s
  training loss:		0.285573
  validation loss:		0.355601
  validation accuracy:		88.80 %
Epoch 448 of 2000 took 0.100s
  training loss:		0.285441
  validation loss:		0.350476
  validation accuracy:		89.13 %
Epoch 449 of 2000 took 0.100s
  training loss:		0.300668
  validation loss:		0.351200
  validation accuracy:		88.70 %
Epoch 450 of 2000 took 0.100s
  training loss:		0.285630
  validation loss:		0.366831
  validation accuracy:		88.48 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.284948
  validation loss:		0.351767
  validation accuracy:		88.91 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.287801
  validation loss:		0.344082
  validation accuracy:		89.24 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.289638
  validation loss:		0.355378
  validation accuracy:		88.59 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.285358
  validation loss:		0.343574
  validation accuracy:		88.59 %
Epoch 455 of 2000 took 0.099s
  training loss:		0.287944
  validation loss:		0.358158
  validation accuracy:		88.80 %
Epoch 456 of 2000 took 0.100s
  training loss:		0.277258
  validation loss:		0.353538
  validation accuracy:		88.91 %
Epoch 457 of 2000 took 0.100s
  training loss:		0.282124
  validation loss:		0.365702
  validation accuracy:		88.37 %
Epoch 458 of 2000 took 0.100s
  training loss:		0.288787
  validation loss:		0.367610
  validation accuracy:		88.59 %
Epoch 459 of 2000 took 0.100s
  training loss:		0.291938
  validation loss:		0.358502
  validation accuracy:		89.13 %
Epoch 460 of 2000 took 0.100s
  training loss:		0.288542
  validation loss:		0.353477
  validation accuracy:		88.80 %
Epoch 461 of 2000 took 0.100s
  training loss:		0.287121
  validation loss:		0.359386
  validation accuracy:		88.80 %
Epoch 462 of 2000 took 0.100s
  training loss:		0.287255
  validation loss:		0.357377
  validation accuracy:		88.70 %
Epoch 463 of 2000 took 0.100s
  training loss:		0.287924
  validation loss:		0.387800
  validation accuracy:		87.93 %
Epoch 464 of 2000 took 0.100s
  training loss:		0.290098
  validation loss:		0.357259
  validation accuracy:		88.91 %
Epoch 465 of 2000 took 0.101s
  training loss:		0.279878
  validation loss:		0.383188
  validation accuracy:		87.72 %
Epoch 466 of 2000 took 0.100s
  training loss:		0.289648
  validation loss:		0.357305
  validation accuracy:		88.48 %
Epoch 467 of 2000 took 0.100s
  training loss:		0.290725
  validation loss:		0.361314
  validation accuracy:		88.59 %
Epoch 468 of 2000 took 0.100s
  training loss:		0.287871
  validation loss:		0.353211
  validation accuracy:		89.02 %
Epoch 469 of 2000 took 0.100s
  training loss:		0.284159
  validation loss:		0.350031
  validation accuracy:		89.35 %
Epoch 470 of 2000 took 0.100s
  training loss:		0.286097
  validation loss:		0.355618
  validation accuracy:		88.59 %
Epoch 471 of 2000 took 0.100s
  training loss:		0.286481
  validation loss:		0.345215
  validation accuracy:		89.24 %
Epoch 472 of 2000 took 0.100s
  training loss:		0.283808
  validation loss:		0.371563
  validation accuracy:		88.59 %
Epoch 473 of 2000 took 0.100s
  training loss:		0.285516
  validation loss:		0.354605
  validation accuracy:		89.02 %
Epoch 474 of 2000 took 0.100s
  training loss:		0.288675
  validation loss:		0.362044
  validation accuracy:		88.91 %
Epoch 475 of 2000 took 0.100s
  training loss:		0.286408
  validation loss:		0.356901
  validation accuracy:		89.13 %
Epoch 476 of 2000 took 0.100s
  training loss:		0.287909
  validation loss:		0.358690
  validation accuracy:		88.37 %
Epoch 477 of 2000 took 0.100s
  training loss:		0.289133
  validation loss:		0.377183
  validation accuracy:		88.26 %
Epoch 478 of 2000 took 0.100s
  training loss:		0.287480
  validation loss:		0.349550
  validation accuracy:		89.24 %
Epoch 479 of 2000 took 0.100s
  training loss:		0.287355
  validation loss:		0.346430
  validation accuracy:		89.46 %
Epoch 480 of 2000 took 0.100s
  training loss:		0.284066
  validation loss:		0.353818
  validation accuracy:		88.37 %
Epoch 481 of 2000 took 0.100s
  training loss:		0.284061
  validation loss:		0.351906
  validation accuracy:		89.02 %
Epoch 482 of 2000 took 0.100s
  training loss:		0.290990
  validation loss:		0.361356
  validation accuracy:		88.91 %
Epoch 483 of 2000 took 0.100s
  training loss:		0.293213
  validation loss:		0.372351
  validation accuracy:		88.26 %
Epoch 484 of 2000 took 0.103s
  training loss:		0.284133
  validation loss:		0.360712
  validation accuracy:		88.80 %
Epoch 485 of 2000 took 0.100s
  training loss:		0.285234
  validation loss:		0.362779
  validation accuracy:		88.91 %
Epoch 486 of 2000 took 0.100s
  training loss:		0.277930
  validation loss:		0.347644
  validation accuracy:		89.24 %
Epoch 487 of 2000 took 0.100s
  training loss:		0.282613
  validation loss:		0.363174
  validation accuracy:		88.15 %
Epoch 488 of 2000 took 0.100s
  training loss:		0.284338
  validation loss:		0.382223
  validation accuracy:		87.83 %
Epoch 489 of 2000 took 0.101s
  training loss:		0.279689
  validation loss:		0.357593
  validation accuracy:		88.80 %
Epoch 490 of 2000 took 0.100s
  training loss:		0.278466
  validation loss:		0.347154
  validation accuracy:		88.91 %
Epoch 491 of 2000 took 0.100s
  training loss:		0.285776
  validation loss:		0.363048
  validation accuracy:		88.70 %
Epoch 492 of 2000 took 0.100s
  training loss:		0.284539
  validation loss:		0.355871
  validation accuracy:		88.48 %
Epoch 493 of 2000 took 0.100s
  training loss:		0.285979
  validation loss:		0.386930
  validation accuracy:		87.83 %
Epoch 494 of 2000 took 0.100s
  training loss:		0.290877
  validation loss:		0.347919
  validation accuracy:		89.24 %
Epoch 495 of 2000 took 0.101s
  training loss:		0.279683
  validation loss:		0.347401
  validation accuracy:		88.91 %
Epoch 496 of 2000 took 0.100s
  training loss:		0.287313
  validation loss:		0.353275
  validation accuracy:		88.91 %
Epoch 497 of 2000 took 0.100s
  training loss:		0.289581
  validation loss:		0.353203
  validation accuracy:		88.59 %
Epoch 498 of 2000 took 0.100s
  training loss:		0.282481
  validation loss:		0.369002
  validation accuracy:		88.59 %
Epoch 499 of 2000 took 0.100s
  training loss:		0.279299
  validation loss:		0.343023
  validation accuracy:		89.46 %
Epoch 500 of 2000 took 0.100s
  training loss:		0.283376
  validation loss:		0.354382
  validation accuracy:		89.35 %
Epoch 501 of 2000 took 0.100s
  training loss:		0.274246
  validation loss:		0.356762
  validation accuracy:		88.59 %
Epoch 502 of 2000 took 0.100s
  training loss:		0.279316
  validation loss:		0.350263
  validation accuracy:		88.80 %
Epoch 503 of 2000 took 0.100s
  training loss:		0.279539
  validation loss:		0.361971
  validation accuracy:		88.70 %
Epoch 504 of 2000 took 0.100s
  training loss:		0.283164
  validation loss:		0.348905
  validation accuracy:		89.02 %
Epoch 505 of 2000 took 0.100s
  training loss:		0.287594
  validation loss:		0.360902
  validation accuracy:		88.26 %
Epoch 506 of 2000 took 0.100s
  training loss:		0.288783
  validation loss:		0.384932
  validation accuracy:		87.39 %
Epoch 507 of 2000 took 0.100s
  training loss:		0.273195
  validation loss:		0.378250
  validation accuracy:		88.37 %
Epoch 508 of 2000 took 0.100s
  training loss:		0.283155
  validation loss:		0.366954
  validation accuracy:		88.26 %
Epoch 509 of 2000 took 0.100s
  training loss:		0.279712
  validation loss:		0.357044
  validation accuracy:		88.48 %
Epoch 510 of 2000 took 0.100s
  training loss:		0.273788
  validation loss:		0.358996
  validation accuracy:		88.26 %
Epoch 511 of 2000 took 0.100s
  training loss:		0.275430
  validation loss:		0.348012
  validation accuracy:		89.13 %
Epoch 512 of 2000 took 0.100s
  training loss:		0.283126
  validation loss:		0.352268
  validation accuracy:		88.91 %
Epoch 513 of 2000 took 0.100s
  training loss:		0.285626
  validation loss:		0.361358
  validation accuracy:		89.02 %
Epoch 514 of 2000 took 0.100s
  training loss:		0.287536
  validation loss:		0.347726
  validation accuracy:		89.13 %
Epoch 515 of 2000 took 0.102s
  training loss:		0.289751
  validation loss:		0.374821
  validation accuracy:		88.70 %
Epoch 516 of 2000 took 0.104s
  training loss:		0.274778
  validation loss:		0.353150
  validation accuracy:		88.48 %
Epoch 517 of 2000 took 0.103s
  training loss:		0.293377
  validation loss:		0.345316
  validation accuracy:		89.02 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.286310
  validation loss:		0.358965
  validation accuracy:		88.80 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.280212
  validation loss:		0.385842
  validation accuracy:		87.50 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.281821
  validation loss:		0.359469
  validation accuracy:		88.80 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.278493
  validation loss:		0.371976
  validation accuracy:		87.39 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.283559
  validation loss:		0.343266
  validation accuracy:		89.57 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.281739
  validation loss:		0.360915
  validation accuracy:		88.48 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.280425
  validation loss:		0.349475
  validation accuracy:		88.80 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.285125
  validation loss:		0.352925
  validation accuracy:		88.80 %
Epoch 526 of 2000 took 0.098s
  training loss:		0.281324
  validation loss:		0.359859
  validation accuracy:		88.26 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.283852
  validation loss:		0.357477
  validation accuracy:		89.24 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.280350
  validation loss:		0.360886
  validation accuracy:		88.26 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.279435
  validation loss:		0.356053
  validation accuracy:		88.80 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.281181
  validation loss:		0.347594
  validation accuracy:		88.80 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.278043
  validation loss:		0.365015
  validation accuracy:		88.26 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.280877
  validation loss:		0.376650
  validation accuracy:		88.37 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.285045
  validation loss:		0.354488
  validation accuracy:		88.80 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.288138
  validation loss:		0.342527
  validation accuracy:		89.46 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.280392
  validation loss:		0.374130
  validation accuracy:		88.26 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.279866
  validation loss:		0.348258
  validation accuracy:		89.13 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.278679
  validation loss:		0.372186
  validation accuracy:		88.48 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.288256
  validation loss:		0.363817
  validation accuracy:		87.93 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.280134
  validation loss:		0.355887
  validation accuracy:		88.48 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.281577
  validation loss:		0.345362
  validation accuracy:		89.35 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.284541
  validation loss:		0.348507
  validation accuracy:		89.02 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.284888
  validation loss:		0.354606
  validation accuracy:		88.48 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.284091
  validation loss:		0.348438
  validation accuracy:		89.24 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.276675
  validation loss:		0.346578
  validation accuracy:		89.24 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.287150
  validation loss:		0.380874
  validation accuracy:		87.28 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.276746
  validation loss:		0.346705
  validation accuracy:		88.91 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.277140
  validation loss:		0.371042
  validation accuracy:		87.93 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.274065
  validation loss:		0.371008
  validation accuracy:		87.83 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.279884
  validation loss:		0.361596
  validation accuracy:		89.13 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.284770
  validation loss:		0.344629
  validation accuracy:		89.24 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.268579
  validation loss:		0.347981
  validation accuracy:		89.35 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.275901
  validation loss:		0.369219
  validation accuracy:		88.15 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.277268
  validation loss:		0.359835
  validation accuracy:		88.91 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.275210
  validation loss:		0.363673
  validation accuracy:		88.26 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.276907
  validation loss:		0.373465
  validation accuracy:		88.26 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.275690
  validation loss:		0.370358
  validation accuracy:		88.37 %
Epoch 557 of 2000 took 0.101s
  training loss:		0.276369
  validation loss:		0.351905
  validation accuracy:		88.70 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.280818
  validation loss:		0.341413
  validation accuracy:		89.24 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.273728
  validation loss:		0.354772
  validation accuracy:		89.13 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.280244
  validation loss:		0.364891
  validation accuracy:		88.48 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.282136
  validation loss:		0.369134
  validation accuracy:		88.70 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.272870
  validation loss:		0.358572
  validation accuracy:		88.70 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.280112
  validation loss:		0.364827
  validation accuracy:		88.59 %
Epoch 564 of 2000 took 0.098s
  training loss:		0.268639
  validation loss:		0.353911
  validation accuracy:		88.91 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.275505
  validation loss:		0.374099
  validation accuracy:		87.72 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.273909
  validation loss:		0.372032
  validation accuracy:		87.61 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.277350
  validation loss:		0.350712
  validation accuracy:		89.57 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.279575
  validation loss:		0.360751
  validation accuracy:		88.48 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.280691
  validation loss:		0.375075
  validation accuracy:		87.61 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.276584
  validation loss:		0.376533
  validation accuracy:		87.93 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.276730
  validation loss:		0.349728
  validation accuracy:		88.70 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.280314
  validation loss:		0.345566
  validation accuracy:		89.02 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.281358
  validation loss:		0.369529
  validation accuracy:		88.04 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.281163
  validation loss:		0.379075
  validation accuracy:		87.39 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.277860
  validation loss:		0.351289
  validation accuracy:		89.02 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.269215
  validation loss:		0.352964
  validation accuracy:		89.24 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.281983
  validation loss:		0.360669
  validation accuracy:		88.70 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.279029
  validation loss:		0.361667
  validation accuracy:		88.59 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.275779
  validation loss:		0.353765
  validation accuracy:		88.80 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.277415
  validation loss:		0.360077
  validation accuracy:		88.48 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.271511
  validation loss:		0.356634
  validation accuracy:		89.02 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.274831
  validation loss:		0.370202
  validation accuracy:		87.93 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.276631
  validation loss:		0.356921
  validation accuracy:		88.70 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.279468
  validation loss:		0.359581
  validation accuracy:		88.37 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.278767
  validation loss:		0.372558
  validation accuracy:		88.37 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.284140
  validation loss:		0.362875
  validation accuracy:		88.26 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.278138
  validation loss:		0.355863
  validation accuracy:		89.13 %
Epoch 588 of 2000 took 0.098s
  training loss:		0.275527
  validation loss:		0.395983
  validation accuracy:		87.07 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.280931
  validation loss:		0.365127
  validation accuracy:		88.48 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.271897
  validation loss:		0.369394
  validation accuracy:		88.48 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.271774
  validation loss:		0.354700
  validation accuracy:		88.80 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.269548
  validation loss:		0.362879
  validation accuracy:		88.59 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.274467
  validation loss:		0.361602
  validation accuracy:		88.59 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.275915
  validation loss:		0.376457
  validation accuracy:		88.15 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.275625
  validation loss:		0.365030
  validation accuracy:		88.15 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.271729
  validation loss:		0.362190
  validation accuracy:		88.70 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.277219
  validation loss:		0.357396
  validation accuracy:		88.26 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.272258
  validation loss:		0.354278
  validation accuracy:		88.80 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.279841
  validation loss:		0.349855
  validation accuracy:		89.13 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.278121
  validation loss:		0.377026
  validation accuracy:		87.83 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.275113
  validation loss:		0.355600
  validation accuracy:		88.59 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.284661
  validation loss:		0.358028
  validation accuracy:		89.24 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.281410
  validation loss:		0.359719
  validation accuracy:		88.48 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.272842
  validation loss:		0.358200
  validation accuracy:		88.26 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.264757
  validation loss:		0.374170
  validation accuracy:		88.48 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.271852
  validation loss:		0.360624
  validation accuracy:		88.15 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.277893
  validation loss:		0.348243
  validation accuracy:		88.80 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.276801
  validation loss:		0.366333
  validation accuracy:		87.83 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.279345
  validation loss:		0.362272
  validation accuracy:		88.91 %
Epoch 610 of 2000 took 0.097s
  training loss:		0.273143
  validation loss:		0.358972
  validation accuracy:		88.59 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.270916
  validation loss:		0.374219
  validation accuracy:		88.15 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.279767
  validation loss:		0.370189
  validation accuracy:		87.61 %
Epoch 613 of 2000 took 0.097s
  training loss:		0.266766
  validation loss:		0.362518
  validation accuracy:		88.70 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.271313
  validation loss:		0.357021
  validation accuracy:		88.70 %
Epoch 615 of 2000 took 0.097s
  training loss:		0.275783
  validation loss:		0.359538
  validation accuracy:		88.70 %
Epoch 616 of 2000 took 0.097s
  training loss:		0.271811
  validation loss:		0.357612
  validation accuracy:		88.37 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.275908
  validation loss:		0.355422
  validation accuracy:		88.37 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.277742
  validation loss:		0.359140
  validation accuracy:		88.80 %
Epoch 619 of 2000 took 0.098s
  training loss:		0.272775
  validation loss:		0.364195
  validation accuracy:		88.59 %
Epoch 620 of 2000 took 0.097s
  training loss:		0.271699
  validation loss:		0.352706
  validation accuracy:		88.59 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.273978
  validation loss:		0.372658
  validation accuracy:		88.70 %
Epoch 622 of 2000 took 0.097s
  training loss:		0.272984
  validation loss:		0.351922
  validation accuracy:		89.02 %
Epoch 623 of 2000 took 0.097s
  training loss:		0.274489
  validation loss:		0.375109
  validation accuracy:		88.15 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.280445
  validation loss:		0.355190
  validation accuracy:		88.91 %
Epoch 625 of 2000 took 0.097s
  training loss:		0.273859
  validation loss:		0.372728
  validation accuracy:		88.26 %
Epoch 626 of 2000 took 0.097s
  training loss:		0.272605
  validation loss:		0.384054
  validation accuracy:		87.83 %
Epoch 627 of 2000 took 0.097s
  training loss:		0.278423
  validation loss:		0.352714
  validation accuracy:		88.91 %
Epoch 628 of 2000 took 0.097s
  training loss:		0.269018
  validation loss:		0.364713
  validation accuracy:		88.26 %
Epoch 629 of 2000 took 0.097s
  training loss:		0.275730
  validation loss:		0.356620
  validation accuracy:		89.24 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.270568
  validation loss:		0.373703
  validation accuracy:		88.37 %
Epoch 631 of 2000 took 0.097s
  training loss:		0.272045
  validation loss:		0.372744
  validation accuracy:		88.04 %
Epoch 632 of 2000 took 0.097s
  training loss:		0.277442
  validation loss:		0.356611
  validation accuracy:		88.37 %
Epoch 633 of 2000 took 0.097s
  training loss:		0.271903
  validation loss:		0.369235
  validation accuracy:		87.83 %
Epoch 634 of 2000 took 0.097s
  training loss:		0.277161
  validation loss:		0.387291
  validation accuracy:		87.28 %
Epoch 635 of 2000 took 0.097s
  training loss:		0.269957
  validation loss:		0.361529
  validation accuracy:		88.48 %
Epoch 636 of 2000 took 0.097s
  training loss:		0.274148
  validation loss:		0.370247
  validation accuracy:		88.59 %
Epoch 637 of 2000 took 0.097s
  training loss:		0.271269
  validation loss:		0.367916
  validation accuracy:		87.93 %
Epoch 638 of 2000 took 0.097s
  training loss:		0.275530
  validation loss:		0.365775
  validation accuracy:		89.02 %
Epoch 639 of 2000 took 0.097s
  training loss:		0.279006
  validation loss:		0.367990
  validation accuracy:		88.04 %
Epoch 640 of 2000 took 0.097s
  training loss:		0.269965
  validation loss:		0.354673
  validation accuracy:		88.70 %
Epoch 641 of 2000 took 0.097s
  training loss:		0.273613
  validation loss:		0.354929
  validation accuracy:		88.26 %
Epoch 642 of 2000 took 0.097s
  training loss:		0.274830
  validation loss:		0.391532
  validation accuracy:		87.72 %
Epoch 643 of 2000 took 0.097s
  training loss:		0.285920
  validation loss:		0.347171
  validation accuracy:		88.80 %
Epoch 644 of 2000 took 0.097s
  training loss:		0.269649
  validation loss:		0.365563
  validation accuracy:		88.70 %
Epoch 645 of 2000 took 0.097s
  training loss:		0.277174
  validation loss:		0.376383
  validation accuracy:		87.72 %
Epoch 646 of 2000 took 0.097s
  training loss:		0.274235
  validation loss:		0.410508
  validation accuracy:		86.74 %
Epoch 647 of 2000 took 0.099s
  training loss:		0.271824
  validation loss:		0.361248
  validation accuracy:		88.15 %
Epoch 648 of 2000 took 0.097s
  training loss:		0.272943
  validation loss:		0.358649
  validation accuracy:		88.59 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.274821
  validation loss:		0.367588
  validation accuracy:		88.70 %
Epoch 650 of 2000 took 0.098s
  training loss:		0.271938
  validation loss:		0.395662
  validation accuracy:		87.07 %
Epoch 651 of 2000 took 0.097s
  training loss:		0.270994
  validation loss:		0.362358
  validation accuracy:		88.70 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.274637
  validation loss:		0.359011
  validation accuracy:		89.02 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.264915
  validation loss:		0.354766
  validation accuracy:		88.80 %
Epoch 654 of 2000 took 0.097s
  training loss:		0.265515
  validation loss:		0.362229
  validation accuracy:		88.37 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.269781
  validation loss:		0.365194
  validation accuracy:		87.93 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.266209
  validation loss:		0.366273
  validation accuracy:		88.15 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.272621
  validation loss:		0.353130
  validation accuracy:		88.80 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.272928
  validation loss:		0.354508
  validation accuracy:		88.15 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.270627
  validation loss:		0.349109
  validation accuracy:		89.02 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.269311
  validation loss:		0.351333
  validation accuracy:		88.80 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.275971
  validation loss:		0.358641
  validation accuracy:		88.70 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.269337
  validation loss:		0.357279
  validation accuracy:		88.48 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.264972
  validation loss:		0.381596
  validation accuracy:		87.83 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.277008
  validation loss:		0.373758
  validation accuracy:		88.15 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.269007
  validation loss:		0.360990
  validation accuracy:		88.15 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.273905
  validation loss:		0.361700
  validation accuracy:		88.48 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.275619
  validation loss:		0.353141
  validation accuracy:		88.59 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.269331
  validation loss:		0.358858
  validation accuracy:		88.59 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.271483
  validation loss:		0.367444
  validation accuracy:		87.83 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.273740
  validation loss:		0.378155
  validation accuracy:		87.72 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.270150
  validation loss:		0.349182
  validation accuracy:		88.91 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.279013
  validation loss:		0.359111
  validation accuracy:		88.37 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.273281
  validation loss:		0.376710
  validation accuracy:		88.26 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.268586
  validation loss:		0.389801
  validation accuracy:		87.83 %
Epoch 675 of 2000 took 0.097s
  training loss:		0.273622
  validation loss:		0.378790
  validation accuracy:		87.50 %
Epoch 676 of 2000 took 0.097s
  training loss:		0.270410
  validation loss:		0.374804
  validation accuracy:		87.72 %
Epoch 677 of 2000 took 0.097s
  training loss:		0.272823
  validation loss:		0.353546
  validation accuracy:		88.59 %
Epoch 678 of 2000 took 0.097s
  training loss:		0.267055
  validation loss:		0.357614
  validation accuracy:		88.59 %
Epoch 679 of 2000 took 0.097s
  training loss:		0.262184
  validation loss:		0.361090
  validation accuracy:		88.26 %
Epoch 680 of 2000 took 0.097s
  training loss:		0.269075
  validation loss:		0.372610
  validation accuracy:		88.26 %
Epoch 681 of 2000 took 0.098s
  training loss:		0.267305
  validation loss:		0.363139
  validation accuracy:		88.37 %
Epoch 682 of 2000 took 0.097s
  training loss:		0.274906
  validation loss:		0.363030
  validation accuracy:		88.15 %
Epoch 683 of 2000 took 0.097s
  training loss:		0.264336
  validation loss:		0.367625
  validation accuracy:		88.04 %
Epoch 684 of 2000 took 0.097s
  training loss:		0.267492
  validation loss:		0.355491
  validation accuracy:		88.70 %
Epoch 685 of 2000 took 0.097s
  training loss:		0.270549
  validation loss:		0.349947
  validation accuracy:		88.91 %
Epoch 686 of 2000 took 0.097s
  training loss:		0.273939
  validation loss:		0.367101
  validation accuracy:		88.70 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.275615
  validation loss:		0.377395
  validation accuracy:		87.93 %
Epoch 688 of 2000 took 0.097s
  training loss:		0.270959
  validation loss:		0.358978
  validation accuracy:		88.37 %
Epoch 689 of 2000 took 0.097s
  training loss:		0.265229
  validation loss:		0.402794
  validation accuracy:		86.85 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.268785
  validation loss:		0.372031
  validation accuracy:		87.83 %
Epoch 691 of 2000 took 0.097s
  training loss:		0.264871
  validation loss:		0.354974
  validation accuracy:		88.04 %
Epoch 692 of 2000 took 0.097s
  training loss:		0.274022
  validation loss:		0.362957
  validation accuracy:		88.37 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.271870
  validation loss:		0.394542
  validation accuracy:		87.07 %
Epoch 694 of 2000 took 0.097s
  training loss:		0.269027
  validation loss:		0.394418
  validation accuracy:		87.61 %
Epoch 695 of 2000 took 0.097s
  training loss:		0.272057
  validation loss:		0.368494
  validation accuracy:		89.02 %
Epoch 696 of 2000 took 0.097s
  training loss:		0.267288
  validation loss:		0.367155
  validation accuracy:		88.70 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.263747
  validation loss:		0.378177
  validation accuracy:		88.04 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.271985
  validation loss:		0.350641
  validation accuracy:		88.59 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.269887
  validation loss:		0.365603
  validation accuracy:		88.37 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.268016
  validation loss:		0.365943
  validation accuracy:		88.04 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.268919
  validation loss:		0.368908
  validation accuracy:		88.15 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.272408
  validation loss:		0.371223
  validation accuracy:		87.93 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.277746
  validation loss:		0.354146
  validation accuracy:		88.70 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.266996
  validation loss:		0.364803
  validation accuracy:		88.48 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.274606
  validation loss:		0.350907
  validation accuracy:		89.13 %
Epoch 706 of 2000 took 0.097s
  training loss:		0.270221
  validation loss:		0.360424
  validation accuracy:		88.59 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.270586
  validation loss:		0.379579
  validation accuracy:		88.15 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.262373
  validation loss:		0.366649
  validation accuracy:		88.26 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.270356
  validation loss:		0.377799
  validation accuracy:		87.39 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.283776
  validation loss:		0.351988
  validation accuracy:		88.80 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.267543
  validation loss:		0.352133
  validation accuracy:		88.59 %
Epoch 712 of 2000 took 0.098s
  training loss:		0.265710
  validation loss:		0.380265
  validation accuracy:		87.17 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.268274
  validation loss:		0.372038
  validation accuracy:		88.59 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.268794
  validation loss:		0.359280
  validation accuracy:		88.37 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.268632
  validation loss:		0.353917
  validation accuracy:		88.37 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.270171
  validation loss:		0.351169
  validation accuracy:		88.59 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.269794
  validation loss:		0.370671
  validation accuracy:		88.15 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.268144
  validation loss:		0.356596
  validation accuracy:		88.59 %
Epoch 719 of 2000 took 0.097s
  training loss:		0.272526
  validation loss:		0.352528
  validation accuracy:		89.02 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.267593
  validation loss:		0.364917
  validation accuracy:		88.26 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.265291
  validation loss:		0.364486
  validation accuracy:		88.59 %
Epoch 722 of 2000 took 0.097s
  training loss:		0.262278
  validation loss:		0.359533
  validation accuracy:		88.48 %
Epoch 723 of 2000 took 0.097s
  training loss:		0.265626
  validation loss:		0.351129
  validation accuracy:		88.70 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.269328
  validation loss:		0.374457
  validation accuracy:		87.83 %
Epoch 725 of 2000 took 0.097s
  training loss:		0.266437
  validation loss:		0.358026
  validation accuracy:		88.15 %
Epoch 726 of 2000 took 0.097s
  training loss:		0.263706
  validation loss:		0.371739
  validation accuracy:		88.15 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.265093
  validation loss:		0.356382
  validation accuracy:		88.48 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.265451
  validation loss:		0.347690
  validation accuracy:		88.80 %
Epoch 729 of 2000 took 0.097s
  training loss:		0.262698
  validation loss:		0.359295
  validation accuracy:		88.26 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.267905
  validation loss:		0.353435
  validation accuracy:		88.80 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.269929
  validation loss:		0.353264
  validation accuracy:		89.02 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.266030
  validation loss:		0.366058
  validation accuracy:		88.04 %
Epoch 733 of 2000 took 0.097s
  training loss:		0.267822
  validation loss:		0.362476
  validation accuracy:		88.70 %
Epoch 734 of 2000 took 0.097s
  training loss:		0.263221
  validation loss:		0.370505
  validation accuracy:		88.04 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.261955
  validation loss:		0.384927
  validation accuracy:		87.50 %
Epoch 736 of 2000 took 0.097s
  training loss:		0.271835
  validation loss:		0.367046
  validation accuracy:		88.15 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.264153
  validation loss:		0.359350
  validation accuracy:		88.26 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.255279
  validation loss:		0.368388
  validation accuracy:		87.93 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.271682
  validation loss:		0.364340
  validation accuracy:		88.15 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.269481
  validation loss:		0.369632
  validation accuracy:		88.70 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.268155
  validation loss:		0.364166
  validation accuracy:		88.04 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.263372
  validation loss:		0.376165
  validation accuracy:		88.15 %
Epoch 743 of 2000 took 0.098s
  training loss:		0.268704
  validation loss:		0.398230
  validation accuracy:		86.96 %
Epoch 744 of 2000 took 0.097s
  training loss:		0.263594
  validation loss:		0.349014
  validation accuracy:		88.91 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.269857
  validation loss:		0.382860
  validation accuracy:		87.50 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.261663
  validation loss:		0.366256
  validation accuracy:		88.04 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.264434
  validation loss:		0.363671
  validation accuracy:		88.37 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.262569
  validation loss:		0.360673
  validation accuracy:		88.15 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.269822
  validation loss:		0.362996
  validation accuracy:		89.13 %
Epoch 750 of 2000 took 0.097s
  training loss:		0.252404
  validation loss:		0.367773
  validation accuracy:		87.93 %
Epoch 751 of 2000 took 0.097s
  training loss:		0.264795
  validation loss:		0.364239
  validation accuracy:		88.48 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.262882
  validation loss:		0.365368
  validation accuracy:		88.04 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.272920
  validation loss:		0.364179
  validation accuracy:		88.91 %
Epoch 754 of 2000 took 0.098s
  training loss:		0.262162
  validation loss:		0.362821
  validation accuracy:		88.04 %
Epoch 755 of 2000 took 0.098s
  training loss:		0.264620
  validation loss:		0.362904
  validation accuracy:		88.26 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.269761
  validation loss:		0.367892
  validation accuracy:		87.72 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.265065
  validation loss:		0.358619
  validation accuracy:		88.37 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.268859
  validation loss:		0.371956
  validation accuracy:		88.15 %
Epoch 759 of 2000 took 0.097s
  training loss:		0.268848
  validation loss:		0.355435
  validation accuracy:		88.37 %
Epoch 760 of 2000 took 0.097s
  training loss:		0.268343
  validation loss:		0.362203
  validation accuracy:		88.80 %
Epoch 761 of 2000 took 0.097s
  training loss:		0.264277
  validation loss:		0.377821
  validation accuracy:		87.83 %
Epoch 762 of 2000 took 0.097s
  training loss:		0.264774
  validation loss:		0.354277
  validation accuracy:		88.48 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.267106
  validation loss:		0.355719
  validation accuracy:		88.26 %
Epoch 764 of 2000 took 0.097s
  training loss:		0.260497
  validation loss:		0.357970
  validation accuracy:		88.26 %
Epoch 765 of 2000 took 0.097s
  training loss:		0.261946
  validation loss:		0.368746
  validation accuracy:		88.26 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.259953
  validation loss:		0.383653
  validation accuracy:		87.83 %
Epoch 767 of 2000 took 0.097s
  training loss:		0.263670
  validation loss:		0.367492
  validation accuracy:		87.93 %
Epoch 768 of 2000 took 0.097s
  training loss:		0.257094
  validation loss:		0.372040
  validation accuracy:		87.83 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.260145
  validation loss:		0.371757
  validation accuracy:		88.04 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.259537
  validation loss:		0.352875
  validation accuracy:		88.91 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.262924
  validation loss:		0.349119
  validation accuracy:		88.80 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.263665
  validation loss:		0.371080
  validation accuracy:		87.93 %
Epoch 773 of 2000 took 0.097s
  training loss:		0.263531
  validation loss:		0.356842
  validation accuracy:		88.48 %
Epoch 774 of 2000 took 0.098s
  training loss:		0.258392
  validation loss:		0.356038
  validation accuracy:		88.91 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.263766
  validation loss:		0.377206
  validation accuracy:		88.04 %
Epoch 776 of 2000 took 0.097s
  training loss:		0.264249
  validation loss:		0.361147
  validation accuracy:		88.48 %
Epoch 777 of 2000 took 0.097s
  training loss:		0.262580
  validation loss:		0.376956
  validation accuracy:		87.72 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.268364
  validation loss:		0.369361
  validation accuracy:		88.37 %
Epoch 779 of 2000 took 0.098s
  training loss:		0.266656
  validation loss:		0.360574
  validation accuracy:		88.26 %
Epoch 780 of 2000 took 0.098s
  training loss:		0.268759
  validation loss:		0.356967
  validation accuracy:		88.37 %
Epoch 781 of 2000 took 0.097s
  training loss:		0.267015
  validation loss:		0.355486
  validation accuracy:		88.70 %
Epoch 782 of 2000 took 0.097s
  training loss:		0.266443
  validation loss:		0.354740
  validation accuracy:		88.80 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.253972
  validation loss:		0.366024
  validation accuracy:		88.15 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.263012
  validation loss:		0.351649
  validation accuracy:		89.46 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.267266
  validation loss:		0.378067
  validation accuracy:		88.26 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.266032
  validation loss:		0.369565
  validation accuracy:		88.15 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.265429
  validation loss:		0.376129
  validation accuracy:		87.72 %
Epoch 788 of 2000 took 0.097s
  training loss:		0.260679
  validation loss:		0.353143
  validation accuracy:		88.48 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.265272
  validation loss:		0.371186
  validation accuracy:		88.26 %
Epoch 790 of 2000 took 0.097s
  training loss:		0.261891
  validation loss:		0.360389
  validation accuracy:		88.91 %
Epoch 791 of 2000 took 0.097s
  training loss:		0.259697
  validation loss:		0.379655
  validation accuracy:		87.93 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.254838
  validation loss:		0.356082
  validation accuracy:		88.80 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.257918
  validation loss:		0.386159
  validation accuracy:		87.17 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.272132
  validation loss:		0.370966
  validation accuracy:		88.04 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.263007
  validation loss:		0.370974
  validation accuracy:		87.72 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.261928
  validation loss:		0.366469
  validation accuracy:		88.04 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.255976
  validation loss:		0.364484
  validation accuracy:		88.04 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.264782
  validation loss:		0.377356
  validation accuracy:		87.61 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.258040
  validation loss:		0.357742
  validation accuracy:		88.04 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.261456
  validation loss:		0.358292
  validation accuracy:		88.04 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.259537
  validation loss:		0.351729
  validation accuracy:		89.02 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.261786
  validation loss:		0.368898
  validation accuracy:		87.93 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.258475
  validation loss:		0.383751
  validation accuracy:		87.83 %
Epoch 804 of 2000 took 0.097s
  training loss:		0.259636
  validation loss:		0.367344
  validation accuracy:		87.72 %
Epoch 805 of 2000 took 0.098s
  training loss:		0.253301
  validation loss:		0.377050
  validation accuracy:		87.39 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.253657
  validation loss:		0.372087
  validation accuracy:		88.15 %
Epoch 807 of 2000 took 0.097s
  training loss:		0.260230
  validation loss:		0.365086
  validation accuracy:		87.93 %
Epoch 808 of 2000 took 0.097s
  training loss:		0.258164
  validation loss:		0.351597
  validation accuracy:		88.59 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.260186
  validation loss:		0.372907
  validation accuracy:		88.26 %
Epoch 810 of 2000 took 0.097s
  training loss:		0.259048
  validation loss:		0.371195
  validation accuracy:		88.59 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.258205
  validation loss:		0.351258
  validation accuracy:		89.24 %
Epoch 812 of 2000 took 0.097s
  training loss:		0.259951
  validation loss:		0.360411
  validation accuracy:		88.70 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.259985
  validation loss:		0.358886
  validation accuracy:		88.80 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.254455
  validation loss:		0.357164
  validation accuracy:		88.80 %
Epoch 815 of 2000 took 0.097s
  training loss:		0.256351
  validation loss:		0.358349
  validation accuracy:		88.04 %
Epoch 816 of 2000 took 0.097s
  training loss:		0.264419
  validation loss:		0.386348
  validation accuracy:		87.17 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.255576
  validation loss:		0.363424
  validation accuracy:		88.48 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.258674
  validation loss:		0.343865
  validation accuracy:		89.35 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.257329
  validation loss:		0.357643
  validation accuracy:		88.37 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.257900
  validation loss:		0.354398
  validation accuracy:		88.48 %
Epoch 821 of 2000 took 0.097s
  training loss:		0.250549
  validation loss:		0.368340
  validation accuracy:		87.93 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.258431
  validation loss:		0.356018
  validation accuracy:		88.26 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.251824
  validation loss:		0.364684
  validation accuracy:		88.26 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.252823
  validation loss:		0.353470
  validation accuracy:		88.80 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.255235
  validation loss:		0.360648
  validation accuracy:		88.59 %
Epoch 826 of 2000 took 0.097s
  training loss:		0.254877
  validation loss:		0.385301
  validation accuracy:		87.72 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.255225
  validation loss:		0.364194
  validation accuracy:		87.72 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.252563
  validation loss:		0.350140
  validation accuracy:		89.24 %
Epoch 829 of 2000 took 0.097s
  training loss:		0.246967
  validation loss:		0.379609
  validation accuracy:		88.04 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.251250
  validation loss:		0.373835
  validation accuracy:		87.93 %
Epoch 831 of 2000 took 0.097s
  training loss:		0.253887
  validation loss:		0.361214
  validation accuracy:		88.37 %
Epoch 832 of 2000 took 0.097s
  training loss:		0.253520
  validation loss:		0.356814
  validation accuracy:		88.91 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.260075
  validation loss:		0.366962
  validation accuracy:		88.04 %
Epoch 834 of 2000 took 0.097s
  training loss:		0.257239
  validation loss:		0.354314
  validation accuracy:		88.91 %
Epoch 835 of 2000 took 0.097s
  training loss:		0.258164
  validation loss:		0.356047
  validation accuracy:		88.59 %
Epoch 836 of 2000 took 0.098s
  training loss:		0.251772
  validation loss:		0.346989
  validation accuracy:		89.24 %
Epoch 837 of 2000 took 0.097s
  training loss:		0.256000
  validation loss:		0.362069
  validation accuracy:		88.48 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.251721
  validation loss:		0.351290
  validation accuracy:		88.91 %
Epoch 839 of 2000 took 0.097s
  training loss:		0.252518
  validation loss:		0.361998
  validation accuracy:		88.59 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.250803
  validation loss:		0.352351
  validation accuracy:		88.59 %
Epoch 841 of 2000 took 0.097s
  training loss:		0.255078
  validation loss:		0.355909
  validation accuracy:		88.80 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.251075
  validation loss:		0.375728
  validation accuracy:		88.15 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.258151
  validation loss:		0.359378
  validation accuracy:		88.80 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.247531
  validation loss:		0.360325
  validation accuracy:		89.02 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.246640
  validation loss:		0.361087
  validation accuracy:		87.93 %
Epoch 846 of 2000 took 0.097s
  training loss:		0.249573
  validation loss:		0.353572
  validation accuracy:		88.91 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.249534
  validation loss:		0.356569
  validation accuracy:		89.13 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.255410
  validation loss:		0.350578
  validation accuracy:		89.13 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.247840
  validation loss:		0.358895
  validation accuracy:		89.13 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.247188
  validation loss:		0.368098
  validation accuracy:		88.15 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.251825
  validation loss:		0.353788
  validation accuracy:		88.59 %
Epoch 852 of 2000 took 0.097s
  training loss:		0.252201
  validation loss:		0.348048
  validation accuracy:		89.13 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.249640
  validation loss:		0.367297
  validation accuracy:		87.83 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.248709
  validation loss:		0.358847
  validation accuracy:		88.70 %
Epoch 855 of 2000 took 0.097s
  training loss:		0.257726
  validation loss:		0.351499
  validation accuracy:		88.91 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.248553
  validation loss:		0.355365
  validation accuracy:		89.13 %
Epoch 857 of 2000 took 0.097s
  training loss:		0.250816
  validation loss:		0.360222
  validation accuracy:		88.91 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.244826
  validation loss:		0.347408
  validation accuracy:		89.02 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.252557
  validation loss:		0.362714
  validation accuracy:		88.26 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.252151
  validation loss:		0.356681
  validation accuracy:		89.24 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.249216
  validation loss:		0.358173
  validation accuracy:		88.91 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.251366
  validation loss:		0.362731
  validation accuracy:		88.70 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.253931
  validation loss:		0.355416
  validation accuracy:		88.48 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.247239
  validation loss:		0.351957
  validation accuracy:		88.48 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.248650
  validation loss:		0.359069
  validation accuracy:		88.59 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.248890
  validation loss:		0.354427
  validation accuracy:		89.13 %
Epoch 867 of 2000 took 0.098s
  training loss:		0.243264
  validation loss:		0.349675
  validation accuracy:		89.02 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.242111
  validation loss:		0.360029
  validation accuracy:		88.59 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.249661
  validation loss:		0.357857
  validation accuracy:		88.48 %
Epoch 870 of 2000 took 0.097s
  training loss:		0.245898
  validation loss:		0.345583
  validation accuracy:		89.35 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.243873
  validation loss:		0.368244
  validation accuracy:		88.15 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.244375
  validation loss:		0.346648
  validation accuracy:		89.46 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.246462
  validation loss:		0.360893
  validation accuracy:		88.37 %
Epoch 874 of 2000 took 0.097s
  training loss:		0.243631
  validation loss:		0.354300
  validation accuracy:		89.13 %
Epoch 875 of 2000 took 0.097s
  training loss:		0.244183
  validation loss:		0.350998
  validation accuracy:		88.70 %
Epoch 876 of 2000 took 0.097s
  training loss:		0.250781
  validation loss:		0.366094
  validation accuracy:		88.15 %
Epoch 877 of 2000 took 0.097s
  training loss:		0.244390
  validation loss:		0.347479
  validation accuracy:		89.35 %
Epoch 878 of 2000 took 0.097s
  training loss:		0.249726
  validation loss:		0.347172
  validation accuracy:		89.89 %
Epoch 879 of 2000 took 0.097s
  training loss:		0.245607
  validation loss:		0.362644
  validation accuracy:		88.15 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.248560
  validation loss:		0.347986
  validation accuracy:		88.91 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.241039
  validation loss:		0.377597
  validation accuracy:		87.83 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.242025
  validation loss:		0.349415
  validation accuracy:		89.24 %
Epoch 883 of 2000 took 0.098s
  training loss:		0.248807
  validation loss:		0.341530
  validation accuracy:		90.00 %
Epoch 884 of 2000 took 0.098s
  training loss:		0.244999
  validation loss:		0.360875
  validation accuracy:		88.59 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.242569
  validation loss:		0.366741
  validation accuracy:		89.13 %
Epoch 886 of 2000 took 0.097s
  training loss:		0.238743
  validation loss:		0.344648
  validation accuracy:		90.00 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.237138
  validation loss:		0.376462
  validation accuracy:		88.15 %
Epoch 888 of 2000 took 0.097s
  training loss:		0.242968
  validation loss:		0.358205
  validation accuracy:		88.15 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.240490
  validation loss:		0.353748
  validation accuracy:		89.35 %
Epoch 890 of 2000 took 0.097s
  training loss:		0.235834
  validation loss:		0.356648
  validation accuracy:		88.15 %
Epoch 891 of 2000 took 0.097s
  training loss:		0.241989
  validation loss:		0.349974
  validation accuracy:		89.35 %
Epoch 892 of 2000 took 0.097s
  training loss:		0.240884
  validation loss:		0.377566
  validation accuracy:		87.93 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.246855
  validation loss:		0.372904
  validation accuracy:		88.48 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.242609
  validation loss:		0.363291
  validation accuracy:		88.70 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.235987
  validation loss:		0.364457
  validation accuracy:		88.70 %
Epoch 896 of 2000 took 0.097s
  training loss:		0.241590
  validation loss:		0.373133
  validation accuracy:		88.04 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.244362
  validation loss:		0.345517
  validation accuracy:		89.57 %
Epoch 898 of 2000 took 0.098s
  training loss:		0.237811
  validation loss:		0.351146
  validation accuracy:		89.46 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.236906
  validation loss:		0.349712
  validation accuracy:		89.13 %
Epoch 900 of 2000 took 0.097s
  training loss:		0.237741
  validation loss:		0.351532
  validation accuracy:		89.13 %
Epoch 901 of 2000 took 0.097s
  training loss:		0.240009
  validation loss:		0.347734
  validation accuracy:		89.46 %
Epoch 902 of 2000 took 0.100s
  training loss:		0.240851
  validation loss:		0.366414
  validation accuracy:		88.59 %
Epoch 903 of 2000 took 0.101s
  training loss:		0.235995
  validation loss:		0.351476
  validation accuracy:		88.59 %
Epoch 904 of 2000 took 0.100s
  training loss:		0.237772
  validation loss:		0.351307
  validation accuracy:		88.70 %
Epoch 905 of 2000 took 0.100s
  training loss:		0.235228
  validation loss:		0.355969
  validation accuracy:		89.02 %
Epoch 906 of 2000 took 0.100s
  training loss:		0.241927
  validation loss:		0.346170
  validation accuracy:		89.13 %
Epoch 907 of 2000 took 0.100s
  training loss:		0.237081
  validation loss:		0.369359
  validation accuracy:		88.15 %
Epoch 908 of 2000 took 0.099s
  training loss:		0.244290
  validation loss:		0.350395
  validation accuracy:		89.35 %
Epoch 909 of 2000 took 0.097s
  training loss:		0.236911
  validation loss:		0.360419
  validation accuracy:		88.59 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.241379
  validation loss:		0.346735
  validation accuracy:		89.13 %
Epoch 911 of 2000 took 0.097s
  training loss:		0.238168
  validation loss:		0.347985
  validation accuracy:		89.24 %
Epoch 912 of 2000 took 0.097s
  training loss:		0.240417
  validation loss:		0.346169
  validation accuracy:		89.46 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.239451
  validation loss:		0.358176
  validation accuracy:		88.80 %
Epoch 914 of 2000 took 0.097s
  training loss:		0.230066
  validation loss:		0.357386
  validation accuracy:		88.70 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.241351
  validation loss:		0.357308
  validation accuracy:		88.80 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.235562
  validation loss:		0.347966
  validation accuracy:		89.35 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.235762
  validation loss:		0.361855
  validation accuracy:		88.26 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.227537
  validation loss:		0.359489
  validation accuracy:		88.26 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.232780
  validation loss:		0.360907
  validation accuracy:		89.24 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.238283
  validation loss:		0.350893
  validation accuracy:		89.78 %
Epoch 921 of 2000 took 0.097s
  training loss:		0.232016
  validation loss:		0.350457
  validation accuracy:		89.13 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.226891
  validation loss:		0.373610
  validation accuracy:		87.93 %
Epoch 923 of 2000 took 0.097s
  training loss:		0.230918
  validation loss:		0.361310
  validation accuracy:		88.70 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.233594
  validation loss:		0.347422
  validation accuracy:		89.35 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.229574
  validation loss:		0.356944
  validation accuracy:		88.48 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.234150
  validation loss:		0.359690
  validation accuracy:		88.91 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.229206
  validation loss:		0.354975
  validation accuracy:		89.24 %
Epoch 928 of 2000 took 0.097s
  training loss:		0.230402
  validation loss:		0.345793
  validation accuracy:		89.46 %
Epoch 929 of 2000 took 0.098s
  training loss:		0.226996
  validation loss:		0.346814
  validation accuracy:		89.46 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.231113
  validation loss:		0.346321
  validation accuracy:		89.67 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.229026
  validation loss:		0.360452
  validation accuracy:		89.02 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.227924
  validation loss:		0.365105
  validation accuracy:		88.59 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.232518
  validation loss:		0.355106
  validation accuracy:		88.70 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.227667
  validation loss:		0.347060
  validation accuracy:		89.35 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.226670
  validation loss:		0.367463
  validation accuracy:		87.93 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.228907
  validation loss:		0.361475
  validation accuracy:		89.24 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.232465
  validation loss:		0.363681
  validation accuracy:		88.80 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.234272
  validation loss:		0.359427
  validation accuracy:		89.02 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.224998
  validation loss:		0.367919
  validation accuracy:		87.61 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.222719
  validation loss:		0.349642
  validation accuracy:		89.24 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.226895
  validation loss:		0.354635
  validation accuracy:		89.13 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.219802
  validation loss:		0.344605
  validation accuracy:		89.35 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.225651
  validation loss:		0.348635
  validation accuracy:		89.13 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.228775
  validation loss:		0.361560
  validation accuracy:		88.80 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.223815
  validation loss:		0.357545
  validation accuracy:		88.59 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.225857
  validation loss:		0.347307
  validation accuracy:		89.35 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.226861
  validation loss:		0.345604
  validation accuracy:		89.46 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.219088
  validation loss:		0.357021
  validation accuracy:		88.91 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.224956
  validation loss:		0.356660
  validation accuracy:		88.80 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.222760
  validation loss:		0.346878
  validation accuracy:		89.46 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.221211
  validation loss:		0.352898
  validation accuracy:		88.70 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.226198
  validation loss:		0.356864
  validation accuracy:		88.48 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.226975
  validation loss:		0.359213
  validation accuracy:		88.15 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.222672
  validation loss:		0.347821
  validation accuracy:		89.46 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.221694
  validation loss:		0.368121
  validation accuracy:		87.83 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.225403
  validation loss:		0.345454
  validation accuracy:		89.24 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.224266
  validation loss:		0.347208
  validation accuracy:		89.35 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.220181
  validation loss:		0.367623
  validation accuracy:		88.26 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.225609
  validation loss:		0.344559
  validation accuracy:		89.57 %
Epoch 960 of 2000 took 0.098s
  training loss:		0.216441
  validation loss:		0.350561
  validation accuracy:		88.91 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.221246
  validation loss:		0.362698
  validation accuracy:		88.59 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.223303
  validation loss:		0.348969
  validation accuracy:		88.59 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.221763
  validation loss:		0.351358
  validation accuracy:		89.24 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.225017
  validation loss:		0.349399
  validation accuracy:		89.24 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.221655
  validation loss:		0.351910
  validation accuracy:		88.70 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.224327
  validation loss:		0.349438
  validation accuracy:		89.24 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.219142
  validation loss:		0.346243
  validation accuracy:		89.24 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.221953
  validation loss:		0.359273
  validation accuracy:		88.80 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.221229
  validation loss:		0.356334
  validation accuracy:		88.80 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.220293
  validation loss:		0.347196
  validation accuracy:		89.46 %
Epoch 971 of 2000 took 0.097s
  training loss:		0.217162
  validation loss:		0.348078
  validation accuracy:		89.24 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.216999
  validation loss:		0.369375
  validation accuracy:		88.04 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.228704
  validation loss:		0.352964
  validation accuracy:		88.70 %
Epoch 974 of 2000 took 0.097s
  training loss:		0.218293
  validation loss:		0.358409
  validation accuracy:		88.80 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.211493
  validation loss:		0.342858
  validation accuracy:		89.67 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.219565
  validation loss:		0.349120
  validation accuracy:		89.35 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.220028
  validation loss:		0.365218
  validation accuracy:		88.04 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.220040
  validation loss:		0.364489
  validation accuracy:		88.15 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.219314
  validation loss:		0.346904
  validation accuracy:		89.57 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.224121
  validation loss:		0.350325
  validation accuracy:		89.13 %
Epoch 981 of 2000 took 0.097s
  training loss:		0.219922
  validation loss:		0.359415
  validation accuracy:		88.48 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.217395
  validation loss:		0.347742
  validation accuracy:		89.35 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.220625
  validation loss:		0.351651
  validation accuracy:		89.24 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.219402
  validation loss:		0.356909
  validation accuracy:		88.37 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.218832
  validation loss:		0.347658
  validation accuracy:		89.13 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.217764
  validation loss:		0.356117
  validation accuracy:		89.24 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.218775
  validation loss:		0.347850
  validation accuracy:		89.24 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.216880
  validation loss:		0.352144
  validation accuracy:		88.70 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.220538
  validation loss:		0.359556
  validation accuracy:		88.80 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.212182
  validation loss:		0.346341
  validation accuracy:		89.46 %
Epoch 991 of 2000 took 0.098s
  training loss:		0.216963
  validation loss:		0.351843
  validation accuracy:		88.80 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.210442
  validation loss:		0.348090
  validation accuracy:		89.24 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.212781
  validation loss:		0.349786
  validation accuracy:		88.91 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.217813
  validation loss:		0.355106
  validation accuracy:		89.24 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.217923
  validation loss:		0.350241
  validation accuracy:		89.13 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.215627
  validation loss:		0.354070
  validation accuracy:		89.02 %
Epoch 997 of 2000 took 0.097s
  training loss:		0.214481
  validation loss:		0.352454
  validation accuracy:		89.46 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.215880
  validation loss:		0.359079
  validation accuracy:		88.48 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.209665
  validation loss:		0.373392
  validation accuracy:		88.15 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.219774
  validation loss:		0.345880
  validation accuracy:		89.24 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.211238
  validation loss:		0.376886
  validation accuracy:		87.61 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.211597
  validation loss:		0.336285
  validation accuracy:		89.89 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.216309
  validation loss:		0.361798
  validation accuracy:		88.37 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.207281
  validation loss:		0.344111
  validation accuracy:		89.57 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.211684
  validation loss:		0.350265
  validation accuracy:		89.02 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.207688
  validation loss:		0.361984
  validation accuracy:		88.26 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.208115
  validation loss:		0.353214
  validation accuracy:		89.13 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.214006
  validation loss:		0.358667
  validation accuracy:		88.37 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.208494
  validation loss:		0.350584
  validation accuracy:		88.48 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.209481
  validation loss:		0.359004
  validation accuracy:		88.48 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.214246
  validation loss:		0.344813
  validation accuracy:		89.46 %
Epoch 1012 of 2000 took 0.097s
  training loss:		0.206954
  validation loss:		0.343589
  validation accuracy:		89.13 %
Epoch 1013 of 2000 took 0.097s
  training loss:		0.208375
  validation loss:		0.362935
  validation accuracy:		88.26 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.207311
  validation loss:		0.350198
  validation accuracy:		89.67 %
Epoch 1015 of 2000 took 0.097s
  training loss:		0.212555
  validation loss:		0.353335
  validation accuracy:		89.02 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.208856
  validation loss:		0.362951
  validation accuracy:		88.26 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.205526
  validation loss:		0.366667
  validation accuracy:		88.26 %
Epoch 1018 of 2000 took 0.097s
  training loss:		0.212301
  validation loss:		0.365138
  validation accuracy:		87.83 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.209904
  validation loss:		0.345639
  validation accuracy:		89.57 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.211881
  validation loss:		0.347451
  validation accuracy:		89.78 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.209558
  validation loss:		0.346629
  validation accuracy:		89.24 %
Epoch 1022 of 2000 took 0.098s
  training loss:		0.213742
  validation loss:		0.359033
  validation accuracy:		89.13 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.211847
  validation loss:		0.358647
  validation accuracy:		88.80 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.211461
  validation loss:		0.365477
  validation accuracy:		87.93 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.198291
  validation loss:		0.374628
  validation accuracy:		88.15 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.208221
  validation loss:		0.348339
  validation accuracy:		89.35 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.211310
  validation loss:		0.383533
  validation accuracy:		87.93 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.202797
  validation loss:		0.359372
  validation accuracy:		88.48 %
Epoch 1029 of 2000 took 0.098s
  training loss:		0.207690
  validation loss:		0.344941
  validation accuracy:		89.35 %
Epoch 1030 of 2000 took 0.100s
  training loss:		0.202711
  validation loss:		0.358901
  validation accuracy:		88.48 %
Epoch 1031 of 2000 took 0.100s
  training loss:		0.212679
  validation loss:		0.351378
  validation accuracy:		89.02 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.205642
  validation loss:		0.356797
  validation accuracy:		88.80 %
Epoch 1033 of 2000 took 0.100s
  training loss:		0.206777
  validation loss:		0.370043
  validation accuracy:		88.48 %
Epoch 1034 of 2000 took 0.100s
  training loss:		0.210529
  validation loss:		0.362497
  validation accuracy:		89.02 %
Epoch 1035 of 2000 took 0.100s
  training loss:		0.205157
  validation loss:		0.359004
  validation accuracy:		88.37 %
Epoch 1036 of 2000 took 0.100s
  training loss:		0.211623
  validation loss:		0.358579
  validation accuracy:		88.80 %
Epoch 1037 of 2000 took 0.100s
  training loss:		0.207455
  validation loss:		0.362498
  validation accuracy:		88.48 %
Epoch 1038 of 2000 took 0.103s
  training loss:		0.202995
  validation loss:		0.349478
  validation accuracy:		89.35 %
Epoch 1039 of 2000 took 0.100s
  training loss:		0.202311
  validation loss:		0.346423
  validation accuracy:		89.67 %
Epoch 1040 of 2000 took 0.100s
  training loss:		0.204906
  validation loss:		0.350924
  validation accuracy:		89.46 %
Epoch 1041 of 2000 took 0.100s
  training loss:		0.200418
  validation loss:		0.379964
  validation accuracy:		88.48 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.207830
  validation loss:		0.348676
  validation accuracy:		89.24 %
Epoch 1043 of 2000 took 0.100s
  training loss:		0.199771
  validation loss:		0.369588
  validation accuracy:		87.93 %
Epoch 1044 of 2000 took 0.100s
  training loss:		0.205543
  validation loss:		0.359568
  validation accuracy:		88.48 %
Epoch 1045 of 2000 took 0.100s
  training loss:		0.201834
  validation loss:		0.351207
  validation accuracy:		89.35 %
Epoch 1046 of 2000 took 0.100s
  training loss:		0.203521
  validation loss:		0.349300
  validation accuracy:		89.13 %
Epoch 1047 of 2000 took 0.100s
  training loss:		0.201511
  validation loss:		0.353950
  validation accuracy:		88.91 %
Epoch 1048 of 2000 took 0.100s
  training loss:		0.199532
  validation loss:		0.363156
  validation accuracy:		88.26 %
Epoch 1049 of 2000 took 0.100s
  training loss:		0.208034
  validation loss:		0.361011
  validation accuracy:		88.37 %
Epoch 1050 of 2000 took 0.100s
  training loss:		0.197537
  validation loss:		0.357424
  validation accuracy:		88.70 %
Epoch 1051 of 2000 took 0.100s
  training loss:		0.208498
  validation loss:		0.345813
  validation accuracy:		89.57 %
Epoch 1052 of 2000 took 0.100s
  training loss:		0.198415
  validation loss:		0.369373
  validation accuracy:		88.15 %
Epoch 1053 of 2000 took 0.101s
  training loss:		0.196046
  validation loss:		0.348653
  validation accuracy:		89.78 %
Epoch 1054 of 2000 took 0.100s
  training loss:		0.198853
  validation loss:		0.368604
  validation accuracy:		88.37 %
Epoch 1055 of 2000 took 0.100s
  training loss:		0.203600
  validation loss:		0.374314
  validation accuracy:		88.26 %
Epoch 1056 of 2000 took 0.100s
  training loss:		0.204346
  validation loss:		0.370312
  validation accuracy:		87.50 %
Epoch 1057 of 2000 took 0.100s
  training loss:		0.201568
  validation loss:		0.355609
  validation accuracy:		89.46 %
Epoch 1058 of 2000 took 0.100s
  training loss:		0.201973
  validation loss:		0.347327
  validation accuracy:		89.67 %
Epoch 1059 of 2000 took 0.100s
  training loss:		0.197129
  validation loss:		0.365121
  validation accuracy:		88.37 %
Epoch 1060 of 2000 took 0.100s
  training loss:		0.195489
  validation loss:		0.352284
  validation accuracy:		89.13 %
Epoch 1061 of 2000 took 0.100s
  training loss:		0.200150
  validation loss:		0.368723
  validation accuracy:		88.26 %
Epoch 1062 of 2000 took 0.100s
  training loss:		0.198095
  validation loss:		0.375383
  validation accuracy:		87.93 %
Epoch 1063 of 2000 took 0.100s
  training loss:		0.202465
  validation loss:		0.354544
  validation accuracy:		89.02 %
Epoch 1064 of 2000 took 0.100s
  training loss:		0.198735
  validation loss:		0.362871
  validation accuracy:		88.15 %
Epoch 1065 of 2000 took 0.100s
  training loss:		0.200835
  validation loss:		0.364643
  validation accuracy:		88.37 %
Epoch 1066 of 2000 took 0.100s
  training loss:		0.195769
  validation loss:		0.373381
  validation accuracy:		87.39 %
Epoch 1067 of 2000 took 0.100s
  training loss:		0.199483
  validation loss:		0.349281
  validation accuracy:		89.46 %
Epoch 1068 of 2000 took 0.100s
  training loss:		0.197176
  validation loss:		0.348962
  validation accuracy:		88.91 %
Epoch 1069 of 2000 took 0.099s
  training loss:		0.204041
  validation loss:		0.363275
  validation accuracy:		88.80 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.196805
  validation loss:		0.356656
  validation accuracy:		88.70 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.198799
  validation loss:		0.350013
  validation accuracy:		89.13 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.200369
  validation loss:		0.364536
  validation accuracy:		88.15 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.196723
  validation loss:		0.368240
  validation accuracy:		88.48 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.194507
  validation loss:		0.347886
  validation accuracy:		89.35 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.204993
  validation loss:		0.358035
  validation accuracy:		88.70 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.188920
  validation loss:		0.356099
  validation accuracy:		88.70 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.196455
  validation loss:		0.351757
  validation accuracy:		89.13 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.198354
  validation loss:		0.359599
  validation accuracy:		88.70 %
Epoch 1079 of 2000 took 0.097s
  training loss:		0.198402
  validation loss:		0.351022
  validation accuracy:		89.57 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.197582
  validation loss:		0.368756
  validation accuracy:		87.83 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.197623
  validation loss:		0.360013
  validation accuracy:		88.26 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.199046
  validation loss:		0.354956
  validation accuracy:		88.80 %
Epoch 1083 of 2000 took 0.098s
  training loss:		0.195908
  validation loss:		0.350931
  validation accuracy:		89.57 %
Epoch 1084 of 2000 took 0.097s
  training loss:		0.196058
  validation loss:		0.352094
  validation accuracy:		88.70 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.194880
  validation loss:		0.361474
  validation accuracy:		88.37 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.191779
  validation loss:		0.364082
  validation accuracy:		88.80 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.197531
  validation loss:		0.354886
  validation accuracy:		88.48 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.190886
  validation loss:		0.361672
  validation accuracy:		88.04 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.193880
  validation loss:		0.357502
  validation accuracy:		89.13 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.197734
  validation loss:		0.356488
  validation accuracy:		88.48 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.192649
  validation loss:		0.353558
  validation accuracy:		88.91 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.193589
  validation loss:		0.352391
  validation accuracy:		89.57 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.192529
  validation loss:		0.355182
  validation accuracy:		88.48 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.187656
  validation loss:		0.358316
  validation accuracy:		89.13 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.197887
  validation loss:		0.359637
  validation accuracy:		88.59 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.192473
  validation loss:		0.354310
  validation accuracy:		88.70 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.192670
  validation loss:		0.355876
  validation accuracy:		88.70 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.189105
  validation loss:		0.379880
  validation accuracy:		87.50 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.196927
  validation loss:		0.367218
  validation accuracy:		88.80 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.192129
  validation loss:		0.370735
  validation accuracy:		89.24 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.193354
  validation loss:		0.380174
  validation accuracy:		87.93 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.192115
  validation loss:		0.365906
  validation accuracy:		88.80 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.193516
  validation loss:		0.372291
  validation accuracy:		87.83 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.189184
  validation loss:		0.358297
  validation accuracy:		88.80 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.190217
  validation loss:		0.371460
  validation accuracy:		88.26 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.189461
  validation loss:		0.360367
  validation accuracy:		88.26 %
Epoch 1107 of 2000 took 0.097s
  training loss:		0.191789
  validation loss:		0.372101
  validation accuracy:		87.50 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.195779
  validation loss:		0.371054
  validation accuracy:		88.04 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.195081
  validation loss:		0.357741
  validation accuracy:		88.15 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.187517
  validation loss:		0.377096
  validation accuracy:		87.83 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.189679
  validation loss:		0.361196
  validation accuracy:		88.59 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.191635
  validation loss:		0.361723
  validation accuracy:		88.26 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.193068
  validation loss:		0.383495
  validation accuracy:		87.61 %
Epoch 1114 of 2000 took 0.098s
  training loss:		0.194396
  validation loss:		0.363416
  validation accuracy:		88.04 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.191022
  validation loss:		0.359366
  validation accuracy:		89.02 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.193489
  validation loss:		0.379924
  validation accuracy:		87.17 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.191260
  validation loss:		0.360420
  validation accuracy:		88.70 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.192617
  validation loss:		0.399540
  validation accuracy:		86.96 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.186726
  validation loss:		0.351303
  validation accuracy:		88.91 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.189922
  validation loss:		0.367877
  validation accuracy:		88.26 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.191215
  validation loss:		0.362164
  validation accuracy:		88.04 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.194910
  validation loss:		0.360502
  validation accuracy:		88.80 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.185527
  validation loss:		0.362590
  validation accuracy:		87.93 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.189178
  validation loss:		0.360046
  validation accuracy:		89.13 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.186880
  validation loss:		0.372542
  validation accuracy:		87.93 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.183408
  validation loss:		0.359269
  validation accuracy:		89.02 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.190462
  validation loss:		0.362649
  validation accuracy:		88.37 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.187955
  validation loss:		0.389836
  validation accuracy:		88.91 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.190709
  validation loss:		0.363946
  validation accuracy:		88.91 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.189798
  validation loss:		0.369191
  validation accuracy:		88.91 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.187563
  validation loss:		0.364276
  validation accuracy:		88.15 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.188168
  validation loss:		0.353139
  validation accuracy:		89.24 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.186144
  validation loss:		0.372630
  validation accuracy:		88.59 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.186437
  validation loss:		0.367918
  validation accuracy:		88.26 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.187583
  validation loss:		0.404735
  validation accuracy:		87.83 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.187745
  validation loss:		0.356049
  validation accuracy:		88.59 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.185828
  validation loss:		0.394796
  validation accuracy:		87.61 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.194062
  validation loss:		0.381081
  validation accuracy:		87.61 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.185125
  validation loss:		0.362552
  validation accuracy:		89.02 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.181765
  validation loss:		0.348618
  validation accuracy:		89.35 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.188431
  validation loss:		0.384990
  validation accuracy:		87.50 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.185121
  validation loss:		0.382156
  validation accuracy:		88.04 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.187461
  validation loss:		0.369902
  validation accuracy:		88.70 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.187194
  validation loss:		0.366083
  validation accuracy:		88.80 %
Epoch 1145 of 2000 took 0.098s
  training loss:		0.182656
  validation loss:		0.356358
  validation accuracy:		88.70 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.184797
  validation loss:		0.364330
  validation accuracy:		89.46 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.183863
  validation loss:		0.375398
  validation accuracy:		87.50 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.189379
  validation loss:		0.380572
  validation accuracy:		87.83 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.185762
  validation loss:		0.379372
  validation accuracy:		88.80 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.188974
  validation loss:		0.358411
  validation accuracy:		89.02 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.184847
  validation loss:		0.372931
  validation accuracy:		88.70 %
Epoch 1152 of 2000 took 0.098s
  training loss:		0.183857
  validation loss:		0.368520
  validation accuracy:		89.24 %
Epoch 1153 of 2000 took 0.100s
  training loss:		0.184737
  validation loss:		0.369333
  validation accuracy:		88.15 %
Epoch 1154 of 2000 took 0.100s
  training loss:		0.186963
  validation loss:		0.387299
  validation accuracy:		87.72 %
Epoch 1155 of 2000 took 0.100s
  training loss:		0.186283
  validation loss:		0.376706
  validation accuracy:		87.72 %
Epoch 1156 of 2000 took 0.100s
  training loss:		0.183964
  validation loss:		0.360484
  validation accuracy:		88.26 %
Epoch 1157 of 2000 took 0.100s
  training loss:		0.181839
  validation loss:		0.364152
  validation accuracy:		88.37 %
Epoch 1158 of 2000 took 0.100s
  training loss:		0.183288
  validation loss:		0.366124
  validation accuracy:		88.48 %
Epoch 1159 of 2000 took 0.100s
  training loss:		0.184779
  validation loss:		0.385013
  validation accuracy:		88.04 %
Epoch 1160 of 2000 took 0.100s
  training loss:		0.181299
  validation loss:		0.361360
  validation accuracy:		88.15 %
Epoch 1161 of 2000 took 0.100s
  training loss:		0.183095
  validation loss:		0.363256
  validation accuracy:		89.02 %
Epoch 1162 of 2000 took 0.101s
  training loss:		0.183545
  validation loss:		0.383529
  validation accuracy:		87.72 %
Epoch 1163 of 2000 took 0.100s
  training loss:		0.182957
  validation loss:		0.363790
  validation accuracy:		88.59 %
Epoch 1164 of 2000 took 0.100s
  training loss:		0.185720
  validation loss:		0.382552
  validation accuracy:		87.61 %
Epoch 1165 of 2000 took 0.100s
  training loss:		0.182215
  validation loss:		0.364293
  validation accuracy:		88.26 %
Epoch 1166 of 2000 took 0.100s
  training loss:		0.177575
  validation loss:		0.365345
  validation accuracy:		88.37 %
Epoch 1167 of 2000 took 0.100s
  training loss:		0.186538
  validation loss:		0.368673
  validation accuracy:		88.26 %
Epoch 1168 of 2000 took 0.100s
  training loss:		0.188627
  validation loss:		0.370565
  validation accuracy:		89.02 %
Epoch 1169 of 2000 took 0.100s
  training loss:		0.183415
  validation loss:		0.379290
  validation accuracy:		88.48 %
Epoch 1170 of 2000 took 0.100s
  training loss:		0.182546
  validation loss:		0.357715
  validation accuracy:		89.24 %
Epoch 1171 of 2000 took 0.100s
  training loss:		0.184480
  validation loss:		0.367804
  validation accuracy:		88.48 %
Epoch 1172 of 2000 took 0.100s
  training loss:		0.180255
  validation loss:		0.364850
  validation accuracy:		89.35 %
Epoch 1173 of 2000 took 0.100s
  training loss:		0.188850
  validation loss:		0.370705
  validation accuracy:		87.83 %
Epoch 1174 of 2000 took 0.101s
  training loss:		0.181408
  validation loss:		0.364171
  validation accuracy:		88.04 %
Epoch 1175 of 2000 took 0.100s
  training loss:		0.180454
  validation loss:		0.373352
  validation accuracy:		88.26 %
Epoch 1176 of 2000 took 0.101s
  training loss:		0.177890
  validation loss:		0.377859
  validation accuracy:		88.04 %
Epoch 1177 of 2000 took 0.100s
  training loss:		0.185710
  validation loss:		0.369640
  validation accuracy:		88.70 %
Epoch 1178 of 2000 took 0.100s
  training loss:		0.181713
  validation loss:		0.366566
  validation accuracy:		88.37 %
Epoch 1179 of 2000 took 0.100s
  training loss:		0.180063
  validation loss:		0.358320
  validation accuracy:		88.48 %
Epoch 1180 of 2000 took 0.100s
  training loss:		0.182875
  validation loss:		0.374407
  validation accuracy:		87.83 %
Epoch 1181 of 2000 took 0.100s
  training loss:		0.181083
  validation loss:		0.361381
  validation accuracy:		89.13 %
Epoch 1182 of 2000 took 0.100s
  training loss:		0.176030
  validation loss:		0.376223
  validation accuracy:		88.37 %
Epoch 1183 of 2000 took 0.100s
  training loss:		0.179973
  validation loss:		0.375997
  validation accuracy:		88.80 %
Epoch 1184 of 2000 took 0.100s
  training loss:		0.181062
  validation loss:		0.377659
  validation accuracy:		88.48 %
Epoch 1185 of 2000 took 0.100s
  training loss:		0.183378
  validation loss:		0.379548
  validation accuracy:		88.04 %
Epoch 1186 of 2000 took 0.100s
  training loss:		0.177848
  validation loss:		0.368614
  validation accuracy:		89.13 %
Epoch 1187 of 2000 took 0.100s
  training loss:		0.178515
  validation loss:		0.379693
  validation accuracy:		88.48 %
Epoch 1188 of 2000 took 0.100s
  training loss:		0.180244
  validation loss:		0.370591
  validation accuracy:		88.91 %
Epoch 1189 of 2000 took 0.100s
  training loss:		0.175134
  validation loss:		0.357339
  validation accuracy:		89.13 %
Epoch 1190 of 2000 took 0.100s
  training loss:		0.179483
  validation loss:		0.362523
  validation accuracy:		88.48 %
Epoch 1191 of 2000 took 0.100s
  training loss:		0.177186
  validation loss:		0.369372
  validation accuracy:		87.72 %
Epoch 1192 of 2000 took 0.100s
  training loss:		0.177009
  validation loss:		0.366775
  validation accuracy:		88.48 %
Epoch 1193 of 2000 took 0.100s
  training loss:		0.180031
  validation loss:		0.369308
  validation accuracy:		87.83 %
Epoch 1194 of 2000 took 0.100s
  training loss:		0.178056
  validation loss:		0.355995
  validation accuracy:		89.57 %
Epoch 1195 of 2000 took 0.100s
  training loss:		0.178320
  validation loss:		0.403733
  validation accuracy:		87.72 %
Epoch 1196 of 2000 took 0.100s
  training loss:		0.179572
  validation loss:		0.377098
  validation accuracy:		87.83 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.179567
  validation loss:		0.362463
  validation accuracy:		88.91 %
Epoch 1198 of 2000 took 0.100s
  training loss:		0.179338
  validation loss:		0.358559
  validation accuracy:		88.80 %
Epoch 1199 of 2000 took 0.100s
  training loss:		0.181047
  validation loss:		0.355852
  validation accuracy:		89.02 %
Epoch 1200 of 2000 took 0.100s
  training loss:		0.180487
  validation loss:		0.385279
  validation accuracy:		89.24 %
Epoch 1201 of 2000 took 0.100s
  training loss:		0.180616
  validation loss:		0.363122
  validation accuracy:		89.24 %
Epoch 1202 of 2000 took 0.100s
  training loss:		0.183520
  validation loss:		0.363199
  validation accuracy:		88.59 %
Epoch 1203 of 2000 took 0.100s
  training loss:		0.178529
  validation loss:		0.370338
  validation accuracy:		88.37 %
Epoch 1204 of 2000 took 0.100s
  training loss:		0.177929
  validation loss:		0.377355
  validation accuracy:		88.59 %
Epoch 1205 of 2000 took 0.100s
  training loss:		0.177058
  validation loss:		0.379795
  validation accuracy:		88.48 %
Epoch 1206 of 2000 took 0.101s
  training loss:		0.180329
  validation loss:		0.383706
  validation accuracy:		87.50 %
Epoch 1207 of 2000 took 0.100s
  training loss:		0.175178
  validation loss:		0.358405
  validation accuracy:		89.02 %
Epoch 1208 of 2000 took 0.100s
  training loss:		0.176023
  validation loss:		0.365294
  validation accuracy:		88.80 %
Epoch 1209 of 2000 took 0.100s
  training loss:		0.180347
  validation loss:		0.366064
  validation accuracy:		88.48 %
Epoch 1210 of 2000 took 0.100s
  training loss:		0.177043
  validation loss:		0.375272
  validation accuracy:		87.72 %
Epoch 1211 of 2000 took 0.100s
  training loss:		0.176441
  validation loss:		0.380669
  validation accuracy:		88.70 %
Epoch 1212 of 2000 took 0.100s
  training loss:		0.183717
  validation loss:		0.362502
  validation accuracy:		88.70 %
Epoch 1213 of 2000 took 0.100s
  training loss:		0.172849
  validation loss:		0.373799
  validation accuracy:		87.93 %
Epoch 1214 of 2000 took 0.100s
  training loss:		0.170901
  validation loss:		0.368782
  validation accuracy:		88.70 %
Epoch 1215 of 2000 took 0.100s
  training loss:		0.172780
  validation loss:		0.365404
  validation accuracy:		88.15 %
Epoch 1216 of 2000 took 0.100s
  training loss:		0.173828
  validation loss:		0.369724
  validation accuracy:		88.48 %
Epoch 1217 of 2000 took 0.100s
  training loss:		0.176262
  validation loss:		0.383127
  validation accuracy:		88.15 %
Epoch 1218 of 2000 took 0.100s
  training loss:		0.174348
  validation loss:		0.364200
  validation accuracy:		88.48 %
Epoch 1219 of 2000 took 0.100s
  training loss:		0.181872
  validation loss:		0.368983
  validation accuracy:		88.80 %
Epoch 1220 of 2000 took 0.101s
  training loss:		0.174543
  validation loss:		0.362902
  validation accuracy:		88.26 %
Epoch 1221 of 2000 took 0.101s
  training loss:		0.176016
  validation loss:		0.381634
  validation accuracy:		88.15 %
Epoch 1222 of 2000 took 0.100s
  training loss:		0.175652
  validation loss:		0.365237
  validation accuracy:		88.91 %
Epoch 1223 of 2000 took 0.100s
  training loss:		0.178993
  validation loss:		0.384893
  validation accuracy:		88.48 %
Epoch 1224 of 2000 took 0.100s
  training loss:		0.175177
  validation loss:		0.410654
  validation accuracy:		88.04 %
Epoch 1225 of 2000 took 0.100s
  training loss:		0.173861
  validation loss:		0.368174
  validation accuracy:		89.02 %
Epoch 1226 of 2000 took 0.100s
  training loss:		0.173794
  validation loss:		0.364899
  validation accuracy:		88.59 %
Epoch 1227 of 2000 took 0.100s
  training loss:		0.172735
  validation loss:		0.375496
  validation accuracy:		88.37 %
Epoch 1228 of 2000 took 0.100s
  training loss:		0.176392
  validation loss:		0.395141
  validation accuracy:		87.61 %
Epoch 1229 of 2000 took 0.100s
  training loss:		0.176843
  validation loss:		0.367756
  validation accuracy:		88.48 %
Epoch 1230 of 2000 took 0.100s
  training loss:		0.170033
  validation loss:		0.372921
  validation accuracy:		87.93 %
Epoch 1231 of 2000 took 0.100s
  training loss:		0.178052
  validation loss:		0.380059
  validation accuracy:		89.13 %
Epoch 1232 of 2000 took 0.100s
  training loss:		0.175852
  validation loss:		0.376802
  validation accuracy:		89.13 %
Epoch 1233 of 2000 took 0.100s
  training loss:		0.172413
  validation loss:		0.382788
  validation accuracy:		88.48 %
Epoch 1234 of 2000 took 0.100s
  training loss:		0.183000
  validation loss:		0.373256
  validation accuracy:		88.26 %
Epoch 1235 of 2000 took 0.100s
  training loss:		0.174298
  validation loss:		0.376657
  validation accuracy:		88.48 %
Epoch 1236 of 2000 took 0.101s
  training loss:		0.171962
  validation loss:		0.377700
  validation accuracy:		88.26 %
Epoch 1237 of 2000 took 0.100s
  training loss:		0.178990
  validation loss:		0.375994
  validation accuracy:		88.04 %
Epoch 1238 of 2000 took 0.100s
  training loss:		0.171120
  validation loss:		0.365591
  validation accuracy:		89.13 %
Epoch 1239 of 2000 took 0.100s
  training loss:		0.170118
  validation loss:		0.378717
  validation accuracy:		88.37 %
Epoch 1240 of 2000 took 0.100s
  training loss:		0.175362
  validation loss:		0.374161
  validation accuracy:		89.24 %
Epoch 1241 of 2000 took 0.100s
  training loss:		0.171899
  validation loss:		0.385641
  validation accuracy:		87.72 %
Epoch 1242 of 2000 took 0.100s
  training loss:		0.174829
  validation loss:		0.393631
  validation accuracy:		87.93 %
Epoch 1243 of 2000 took 0.100s
  training loss:		0.175755
  validation loss:		0.372754
  validation accuracy:		89.02 %
Epoch 1244 of 2000 took 0.100s
  training loss:		0.180054
  validation loss:		0.369533
  validation accuracy:		88.70 %
Epoch 1245 of 2000 took 0.100s
  training loss:		0.171175
  validation loss:		0.368933
  validation accuracy:		89.02 %
Epoch 1246 of 2000 took 0.100s
  training loss:		0.175080
  validation loss:		0.367307
  validation accuracy:		88.59 %
Epoch 1247 of 2000 took 0.100s
  training loss:		0.170881
  validation loss:		0.370976
  validation accuracy:		88.59 %
Epoch 1248 of 2000 took 0.100s
  training loss:		0.174908
  validation loss:		0.367466
  validation accuracy:		88.26 %
Epoch 1249 of 2000 took 0.100s
  training loss:		0.165388
  validation loss:		0.378202
  validation accuracy:		88.26 %
Epoch 1250 of 2000 took 0.100s
  training loss:		0.167103
  validation loss:		0.379520
  validation accuracy:		88.15 %
Epoch 1251 of 2000 took 0.100s
  training loss:		0.170077
  validation loss:		0.373789
  validation accuracy:		88.80 %
Epoch 1252 of 2000 took 0.100s
  training loss:		0.163956
  validation loss:		0.378358
  validation accuracy:		88.26 %
Epoch 1253 of 2000 took 0.100s
  training loss:		0.171905
  validation loss:		0.372062
  validation accuracy:		88.59 %
Epoch 1254 of 2000 took 0.100s
  training loss:		0.170490
  validation loss:		0.392704
  validation accuracy:		88.70 %
Epoch 1255 of 2000 took 0.100s
  training loss:		0.171361
  validation loss:		0.367537
  validation accuracy:		89.02 %
Epoch 1256 of 2000 took 0.100s
  training loss:		0.165838
  validation loss:		0.364130
  validation accuracy:		88.80 %
Epoch 1257 of 2000 took 0.100s
  training loss:		0.169749
  validation loss:		0.365704
  validation accuracy:		88.70 %
Epoch 1258 of 2000 took 0.100s
  training loss:		0.167463
  validation loss:		0.382911
  validation accuracy:		88.70 %
Epoch 1259 of 2000 took 0.100s
  training loss:		0.169510
  validation loss:		0.380165
  validation accuracy:		88.04 %
Epoch 1260 of 2000 took 0.100s
  training loss:		0.163699
  validation loss:		0.401090
  validation accuracy:		87.61 %
Epoch 1261 of 2000 took 0.100s
  training loss:		0.167573
  validation loss:		0.378440
  validation accuracy:		88.15 %
Epoch 1262 of 2000 took 0.100s
  training loss:		0.175105
  validation loss:		0.380886
  validation accuracy:		87.83 %
Epoch 1263 of 2000 took 0.100s
  training loss:		0.175795
  validation loss:		0.361522
  validation accuracy:		89.67 %
Epoch 1264 of 2000 took 0.100s
  training loss:		0.174313
  validation loss:		0.359036
  validation accuracy:		89.24 %
Epoch 1265 of 2000 took 0.100s
  training loss:		0.172441
  validation loss:		0.372553
  validation accuracy:		89.13 %
Epoch 1266 of 2000 took 0.101s
  training loss:		0.170259
  validation loss:		0.369741
  validation accuracy:		88.59 %
Epoch 1267 of 2000 took 0.100s
  training loss:		0.168511
  validation loss:		0.378947
  validation accuracy:		88.37 %
Epoch 1268 of 2000 took 0.100s
  training loss:		0.170008
  validation loss:		0.386866
  validation accuracy:		88.80 %
Epoch 1269 of 2000 took 0.100s
  training loss:		0.174601
  validation loss:		0.385001
  validation accuracy:		89.13 %
Epoch 1270 of 2000 took 0.100s
  training loss:		0.170067
  validation loss:		0.364617
  validation accuracy:		88.91 %
Epoch 1271 of 2000 took 0.100s
  training loss:		0.176088
  validation loss:		0.365610
  validation accuracy:		88.59 %
Epoch 1272 of 2000 took 0.099s
  training loss:		0.175872
  validation loss:		0.391125
  validation accuracy:		87.83 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.167505
  validation loss:		0.376395
  validation accuracy:		89.35 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.169652
  validation loss:		0.367645
  validation accuracy:		89.13 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.164936
  validation loss:		0.372322
  validation accuracy:		88.91 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.170131
  validation loss:		0.373890
  validation accuracy:		88.91 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.169147
  validation loss:		0.384780
  validation accuracy:		88.59 %
Epoch 1278 of 2000 took 0.097s
  training loss:		0.173115
  validation loss:		0.377750
  validation accuracy:		88.48 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.163681
  validation loss:		0.377093
  validation accuracy:		89.35 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.165411
  validation loss:		0.384476
  validation accuracy:		88.15 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.173902
  validation loss:		0.376699
  validation accuracy:		89.35 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.168516
  validation loss:		0.380726
  validation accuracy:		88.91 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.175024
  validation loss:		0.382027
  validation accuracy:		89.46 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.169697
  validation loss:		0.379402
  validation accuracy:		88.37 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.169060
  validation loss:		0.409914
  validation accuracy:		87.61 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.168643
  validation loss:		0.372026
  validation accuracy:		89.46 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.174352
  validation loss:		0.375750
  validation accuracy:		89.02 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.172760
  validation loss:		0.372838
  validation accuracy:		88.91 %
Epoch 1289 of 2000 took 0.097s
  training loss:		0.170283
  validation loss:		0.382049
  validation accuracy:		88.70 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.166621
  validation loss:		0.390208
  validation accuracy:		88.37 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.162265
  validation loss:		0.372286
  validation accuracy:		88.48 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.168220
  validation loss:		0.390826
  validation accuracy:		88.04 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.169001
  validation loss:		0.378020
  validation accuracy:		89.13 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.166226
  validation loss:		0.378229
  validation accuracy:		88.70 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.169755
  validation loss:		0.371890
  validation accuracy:		88.80 %
Epoch 1296 of 2000 took 0.097s
  training loss:		0.169028
  validation loss:		0.386727
  validation accuracy:		88.15 %
Epoch 1297 of 2000 took 0.098s
  training loss:		0.161879
  validation loss:		0.375471
  validation accuracy:		88.80 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.170375
  validation loss:		0.378462
  validation accuracy:		89.24 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.164190
  validation loss:		0.383414
  validation accuracy:		89.35 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.173134
  validation loss:		0.380894
  validation accuracy:		88.70 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.170020
  validation loss:		0.372684
  validation accuracy:		88.91 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.167693
  validation loss:		0.393483
  validation accuracy:		88.37 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.168493
  validation loss:		0.391599
  validation accuracy:		88.26 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.166896
  validation loss:		0.396262
  validation accuracy:		87.93 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.168243
  validation loss:		0.379604
  validation accuracy:		88.48 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.166535
  validation loss:		0.389317
  validation accuracy:		88.59 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.167207
  validation loss:		0.370289
  validation accuracy:		89.13 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.173451
  validation loss:		0.374459
  validation accuracy:		88.80 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.167647
  validation loss:		0.385769
  validation accuracy:		88.37 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.162602
  validation loss:		0.396703
  validation accuracy:		88.80 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.164279
  validation loss:		0.383421
  validation accuracy:		88.59 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.165375
  validation loss:		0.381190
  validation accuracy:		88.04 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.168223
  validation loss:		0.386449
  validation accuracy:		88.04 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.166736
  validation loss:		0.382614
  validation accuracy:		88.59 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.163621
  validation loss:		0.395841
  validation accuracy:		88.15 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.173886
  validation loss:		0.386719
  validation accuracy:		88.48 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.159583
  validation loss:		0.383133
  validation accuracy:		88.70 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.170134
  validation loss:		0.378278
  validation accuracy:		89.13 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.163894
  validation loss:		0.385245
  validation accuracy:		88.37 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.160232
  validation loss:		0.387430
  validation accuracy:		88.59 %
Epoch 1321 of 2000 took 0.097s
  training loss:		0.164142
  validation loss:		0.388854
  validation accuracy:		89.13 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.161807
  validation loss:		0.380649
  validation accuracy:		88.48 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.168657
  validation loss:		0.379000
  validation accuracy:		89.02 %
Epoch 1324 of 2000 took 0.097s
  training loss:		0.157252
  validation loss:		0.381234
  validation accuracy:		88.80 %
Epoch 1325 of 2000 took 0.097s
  training loss:		0.163385
  validation loss:		0.398462
  validation accuracy:		88.15 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.164083
  validation loss:		0.392895
  validation accuracy:		88.15 %
Epoch 1327 of 2000 took 0.097s
  training loss:		0.164500
  validation loss:		0.398997
  validation accuracy:		88.70 %
Epoch 1328 of 2000 took 0.098s
  training loss:		0.160357
  validation loss:		0.383440
  validation accuracy:		88.70 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.168468
  validation loss:		0.371663
  validation accuracy:		89.24 %
Epoch 1330 of 2000 took 0.097s
  training loss:		0.163541
  validation loss:		0.377696
  validation accuracy:		89.78 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.164123
  validation loss:		0.364845
  validation accuracy:		88.70 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.167193
  validation loss:		0.397323
  validation accuracy:		88.70 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.162873
  validation loss:		0.394962
  validation accuracy:		88.70 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.162444
  validation loss:		0.395480
  validation accuracy:		88.15 %
Epoch 1335 of 2000 took 0.097s
  training loss:		0.165771
  validation loss:		0.379057
  validation accuracy:		88.91 %
Epoch 1336 of 2000 took 0.097s
  training loss:		0.170210
  validation loss:		0.377944
  validation accuracy:		88.48 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.161996
  validation loss:		0.375917
  validation accuracy:		88.80 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.158266
  validation loss:		0.375367
  validation accuracy:		89.02 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.167638
  validation loss:		0.380494
  validation accuracy:		88.48 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.161297
  validation loss:		0.383575
  validation accuracy:		88.48 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.166706
  validation loss:		0.389707
  validation accuracy:		88.70 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.166692
  validation loss:		0.412478
  validation accuracy:		87.50 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.164964
  validation loss:		0.407557
  validation accuracy:		87.72 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.161317
  validation loss:		0.389560
  validation accuracy:		88.15 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.161975
  validation loss:		0.377672
  validation accuracy:		89.24 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.164753
  validation loss:		0.382792
  validation accuracy:		88.80 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.165205
  validation loss:		0.369957
  validation accuracy:		88.91 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.159664
  validation loss:		0.382959
  validation accuracy:		88.70 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.166020
  validation loss:		0.378633
  validation accuracy:		88.70 %
Epoch 1350 of 2000 took 0.097s
  training loss:		0.163470
  validation loss:		0.376980
  validation accuracy:		88.70 %
Epoch 1351 of 2000 took 0.097s
  training loss:		0.159850
  validation loss:		0.372271
  validation accuracy:		89.02 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.161463
  validation loss:		0.378966
  validation accuracy:		89.46 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.165822
  validation loss:		0.386912
  validation accuracy:		88.80 %
Epoch 1354 of 2000 took 0.097s
  training loss:		0.164520
  validation loss:		0.402071
  validation accuracy:		88.48 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.161659
  validation loss:		0.366759
  validation accuracy:		89.24 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.162691
  validation loss:		0.373937
  validation accuracy:		89.35 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.165376
  validation loss:		0.381050
  validation accuracy:		89.35 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.158580
  validation loss:		0.413330
  validation accuracy:		88.37 %
Epoch 1359 of 2000 took 0.098s
  training loss:		0.168238
  validation loss:		0.387345
  validation accuracy:		89.02 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.164667
  validation loss:		0.397574
  validation accuracy:		88.04 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.162308
  validation loss:		0.376741
  validation accuracy:		89.13 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.159700
  validation loss:		0.393930
  validation accuracy:		88.48 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.158157
  validation loss:		0.413950
  validation accuracy:		88.26 %
Epoch 1364 of 2000 took 0.097s
  training loss:		0.162762
  validation loss:		0.387496
  validation accuracy:		89.13 %
Epoch 1365 of 2000 took 0.097s
  training loss:		0.158081
  validation loss:		0.406915
  validation accuracy:		88.15 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.161506
  validation loss:		0.400207
  validation accuracy:		87.93 %
Epoch 1367 of 2000 took 0.097s
  training loss:		0.160362
  validation loss:		0.386228
  validation accuracy:		89.24 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.160412
  validation loss:		0.380948
  validation accuracy:		89.13 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.159908
  validation loss:		0.389415
  validation accuracy:		88.80 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.161811
  validation loss:		0.377391
  validation accuracy:		88.59 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.169155
  validation loss:		0.395241
  validation accuracy:		88.37 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.161696
  validation loss:		0.382457
  validation accuracy:		88.91 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.158656
  validation loss:		0.408559
  validation accuracy:		88.15 %
Epoch 1374 of 2000 took 0.097s
  training loss:		0.159721
  validation loss:		0.396560
  validation accuracy:		87.93 %
Epoch 1375 of 2000 took 0.097s
  training loss:		0.162597
  validation loss:		0.389363
  validation accuracy:		88.70 %
Epoch 1376 of 2000 took 0.097s
  training loss:		0.159403
  validation loss:		0.373487
  validation accuracy:		88.80 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.162540
  validation loss:		0.387469
  validation accuracy:		88.70 %
Epoch 1378 of 2000 took 0.097s
  training loss:		0.155321
  validation loss:		0.395887
  validation accuracy:		88.59 %
Epoch 1379 of 2000 took 0.097s
  training loss:		0.157447
  validation loss:		0.414695
  validation accuracy:		87.61 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.161313
  validation loss:		0.405567
  validation accuracy:		88.48 %
Epoch 1381 of 2000 took 0.097s
  training loss:		0.157118
  validation loss:		0.387050
  validation accuracy:		88.80 %
Epoch 1382 of 2000 took 0.097s
  training loss:		0.155872
  validation loss:		0.396580
  validation accuracy:		88.37 %
Epoch 1383 of 2000 took 0.097s
  training loss:		0.162781
  validation loss:		0.388930
  validation accuracy:		89.46 %
Epoch 1384 of 2000 took 0.097s
  training loss:		0.160843
  validation loss:		0.407200
  validation accuracy:		88.70 %
Epoch 1385 of 2000 took 0.097s
  training loss:		0.162911
  validation loss:		0.383682
  validation accuracy:		88.91 %
Epoch 1386 of 2000 took 0.097s
  training loss:		0.160025
  validation loss:		0.402321
  validation accuracy:		88.48 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.150362
  validation loss:		0.384573
  validation accuracy:		89.02 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.158026
  validation loss:		0.395292
  validation accuracy:		88.37 %
Epoch 1389 of 2000 took 0.097s
  training loss:		0.165505
  validation loss:		0.402759
  validation accuracy:		88.04 %
Epoch 1390 of 2000 took 0.098s
  training loss:		0.157986
  validation loss:		0.384957
  validation accuracy:		88.80 %
Epoch 1391 of 2000 took 0.098s
  training loss:		0.157357
  validation loss:		0.413564
  validation accuracy:		87.50 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.160651
  validation loss:		0.407555
  validation accuracy:		88.91 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.156237
  validation loss:		0.382425
  validation accuracy:		89.35 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.157700
  validation loss:		0.378063
  validation accuracy:		89.13 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.158020
  validation loss:		0.391742
  validation accuracy:		88.80 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.159164
  validation loss:		0.388327
  validation accuracy:		88.91 %
Epoch 1397 of 2000 took 0.097s
  training loss:		0.161370
  validation loss:		0.407471
  validation accuracy:		88.26 %
Epoch 1398 of 2000 took 0.097s
  training loss:		0.155631
  validation loss:		0.408649
  validation accuracy:		88.26 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.157314
  validation loss:		0.388903
  validation accuracy:		88.80 %
Epoch 1400 of 2000 took 0.097s
  training loss:		0.155325
  validation loss:		0.382414
  validation accuracy:		88.80 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.165692
  validation loss:		0.393844
  validation accuracy:		88.48 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.159509
  validation loss:		0.420802
  validation accuracy:		88.59 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.156270
  validation loss:		0.404543
  validation accuracy:		88.15 %
Epoch 1404 of 2000 took 0.097s
  training loss:		0.153153
  validation loss:		0.384563
  validation accuracy:		88.91 %
Epoch 1405 of 2000 took 0.097s
  training loss:		0.157489
  validation loss:		0.390424
  validation accuracy:		88.70 %
Epoch 1406 of 2000 took 0.097s
  training loss:		0.155630
  validation loss:		0.398620
  validation accuracy:		88.48 %
Epoch 1407 of 2000 took 0.097s
  training loss:		0.156628
  validation loss:		0.379439
  validation accuracy:		89.35 %
Epoch 1408 of 2000 took 0.097s
  training loss:		0.156667
  validation loss:		0.408448
  validation accuracy:		88.04 %
Epoch 1409 of 2000 took 0.097s
  training loss:		0.154637
  validation loss:		0.406508
  validation accuracy:		88.15 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.159595
  validation loss:		0.407598
  validation accuracy:		88.15 %
Epoch 1411 of 2000 took 0.097s
  training loss:		0.159801
  validation loss:		0.405935
  validation accuracy:		88.70 %
Epoch 1412 of 2000 took 0.097s
  training loss:		0.158045
  validation loss:		0.387315
  validation accuracy:		88.91 %
Epoch 1413 of 2000 took 0.097s
  training loss:		0.147657
  validation loss:		0.398693
  validation accuracy:		88.04 %
Epoch 1414 of 2000 took 0.097s
  training loss:		0.160349
  validation loss:		0.399384
  validation accuracy:		88.15 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.157371
  validation loss:		0.388346
  validation accuracy:		88.70 %
Epoch 1416 of 2000 took 0.097s
  training loss:		0.148744
  validation loss:		0.397918
  validation accuracy:		89.02 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.149565
  validation loss:		0.387154
  validation accuracy:		89.02 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.156509
  validation loss:		0.403852
  validation accuracy:		88.15 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.154314
  validation loss:		0.422366
  validation accuracy:		87.61 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.163844
  validation loss:		0.390579
  validation accuracy:		88.70 %
Epoch 1421 of 2000 took 0.098s
  training loss:		0.151708
  validation loss:		0.402293
  validation accuracy:		89.02 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.153819
  validation loss:		0.379132
  validation accuracy:		89.02 %
Epoch 1423 of 2000 took 0.097s
  training loss:		0.155934
  validation loss:		0.392476
  validation accuracy:		89.35 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.157456
  validation loss:		0.390381
  validation accuracy:		88.91 %
Epoch 1425 of 2000 took 0.097s
  training loss:		0.157314
  validation loss:		0.410000
  validation accuracy:		88.48 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.160514
  validation loss:		0.398284
  validation accuracy:		88.48 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.158123
  validation loss:		0.396578
  validation accuracy:		88.80 %
Epoch 1428 of 2000 took 0.097s
  training loss:		0.146585
  validation loss:		0.380132
  validation accuracy:		89.02 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.155181
  validation loss:		0.392526
  validation accuracy:		88.59 %
Epoch 1430 of 2000 took 0.097s
  training loss:		0.154530
  validation loss:		0.396890
  validation accuracy:		88.80 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.151133
  validation loss:		0.402922
  validation accuracy:		88.48 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.156753
  validation loss:		0.389843
  validation accuracy:		88.15 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.155374
  validation loss:		0.385170
  validation accuracy:		89.13 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.159134
  validation loss:		0.393901
  validation accuracy:		89.57 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.149554
  validation loss:		0.394055
  validation accuracy:		88.48 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.148883
  validation loss:		0.414718
  validation accuracy:		88.48 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.153453
  validation loss:		0.406752
  validation accuracy:		88.48 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.159319
  validation loss:		0.390921
  validation accuracy:		88.80 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.151946
  validation loss:		0.412079
  validation accuracy:		88.80 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.150073
  validation loss:		0.406368
  validation accuracy:		88.48 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.153623
  validation loss:		0.386261
  validation accuracy:		88.70 %
Epoch 1442 of 2000 took 0.099s
  training loss:		0.150755
  validation loss:		0.399299
  validation accuracy:		88.70 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.157391
  validation loss:		0.395065
  validation accuracy:		89.02 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.153691
  validation loss:		0.399735
  validation accuracy:		88.59 %
Epoch 1445 of 2000 took 0.097s
  training loss:		0.152023
  validation loss:		0.392056
  validation accuracy:		89.02 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.152363
  validation loss:		0.393849
  validation accuracy:		88.48 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.147383
  validation loss:		0.401780
  validation accuracy:		88.26 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.153410
  validation loss:		0.417303
  validation accuracy:		89.02 %
Epoch 1449 of 2000 took 0.097s
  training loss:		0.148887
  validation loss:		0.384549
  validation accuracy:		89.13 %
Epoch 1450 of 2000 took 0.097s
  training loss:		0.155794
  validation loss:		0.387185
  validation accuracy:		88.70 %
Epoch 1451 of 2000 took 0.097s
  training loss:		0.154991
  validation loss:		0.387865
  validation accuracy:		88.59 %
Epoch 1452 of 2000 took 0.098s
  training loss:		0.150717
  validation loss:		0.380505
  validation accuracy:		89.13 %
Epoch 1453 of 2000 took 0.097s
  training loss:		0.154620
  validation loss:		0.402575
  validation accuracy:		89.02 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.151402
  validation loss:		0.403394
  validation accuracy:		88.37 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.149830
  validation loss:		0.400065
  validation accuracy:		88.70 %
Epoch 1456 of 2000 took 0.097s
  training loss:		0.152047
  validation loss:		0.392051
  validation accuracy:		88.80 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.145318
  validation loss:		0.407091
  validation accuracy:		88.70 %
Epoch 1458 of 2000 took 0.097s
  training loss:		0.156141
  validation loss:		0.390636
  validation accuracy:		89.13 %
Epoch 1459 of 2000 took 0.097s
  training loss:		0.151927
  validation loss:		0.401869
  validation accuracy:		89.02 %
Epoch 1460 of 2000 took 0.097s
  training loss:		0.149003
  validation loss:		0.433839
  validation accuracy:		87.93 %
Epoch 1461 of 2000 took 0.097s
  training loss:		0.153584
  validation loss:		0.399840
  validation accuracy:		88.91 %
Epoch 1462 of 2000 took 0.097s
  training loss:		0.149569
  validation loss:		0.402549
  validation accuracy:		88.91 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.156238
  validation loss:		0.393385
  validation accuracy:		88.91 %
Epoch 1464 of 2000 took 0.097s
  training loss:		0.146954
  validation loss:		0.406777
  validation accuracy:		88.26 %
Epoch 1465 of 2000 took 0.097s
  training loss:		0.148445
  validation loss:		0.390683
  validation accuracy:		89.13 %
Epoch 1466 of 2000 took 0.097s
  training loss:		0.150010
  validation loss:		0.425098
  validation accuracy:		88.37 %
Epoch 1467 of 2000 took 0.097s
  training loss:		0.152647
  validation loss:		0.396944
  validation accuracy:		88.59 %
Epoch 1468 of 2000 took 0.097s
  training loss:		0.149401
  validation loss:		0.411660
  validation accuracy:		88.37 %
Epoch 1469 of 2000 took 0.097s
  training loss:		0.151921
  validation loss:		0.396734
  validation accuracy:		88.80 %
Epoch 1470 of 2000 took 0.097s
  training loss:		0.150202
  validation loss:		0.382305
  validation accuracy:		89.46 %
Epoch 1471 of 2000 took 0.097s
  training loss:		0.154899
  validation loss:		0.416445
  validation accuracy:		88.04 %
Epoch 1472 of 2000 took 0.097s
  training loss:		0.152904
  validation loss:		0.396973
  validation accuracy:		88.59 %
Epoch 1473 of 2000 took 0.097s
  training loss:		0.141180
  validation loss:		0.410694
  validation accuracy:		88.70 %
Epoch 1474 of 2000 took 0.097s
  training loss:		0.149524
  validation loss:		0.398949
  validation accuracy:		88.48 %
Epoch 1475 of 2000 took 0.097s
  training loss:		0.150515
  validation loss:		0.397817
  validation accuracy:		89.13 %
Epoch 1476 of 2000 took 0.097s
  training loss:		0.147778
  validation loss:		0.392460
  validation accuracy:		89.13 %
Epoch 1477 of 2000 took 0.097s
  training loss:		0.152494
  validation loss:		0.393828
  validation accuracy:		88.91 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.152511
  validation loss:		0.387770
  validation accuracy:		89.13 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.148691
  validation loss:		0.392909
  validation accuracy:		89.24 %
Epoch 1480 of 2000 took 0.098s
  training loss:		0.148794
  validation loss:		0.398888
  validation accuracy:		89.02 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.154536
  validation loss:		0.403958
  validation accuracy:		88.91 %
Epoch 1482 of 2000 took 0.097s
  training loss:		0.152891
  validation loss:		0.396096
  validation accuracy:		89.24 %
Epoch 1483 of 2000 took 0.098s
  training loss:		0.148494
  validation loss:		0.383244
  validation accuracy:		89.13 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.148074
  validation loss:		0.381980
  validation accuracy:		89.46 %
Epoch 1485 of 2000 took 0.097s
  training loss:		0.143712
  validation loss:		0.394005
  validation accuracy:		88.70 %
Epoch 1486 of 2000 took 0.097s
  training loss:		0.147905
  validation loss:		0.406800
  validation accuracy:		88.91 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.146175
  validation loss:		0.386525
  validation accuracy:		88.80 %
Epoch 1488 of 2000 took 0.097s
  training loss:		0.148158
  validation loss:		0.411853
  validation accuracy:		89.02 %
Epoch 1489 of 2000 took 0.097s
  training loss:		0.147583
  validation loss:		0.405807
  validation accuracy:		88.59 %
Epoch 1490 of 2000 took 0.097s
  training loss:		0.151953
  validation loss:		0.400384
  validation accuracy:		88.59 %
Epoch 1491 of 2000 took 0.097s
  training loss:		0.146809
  validation loss:		0.400228
  validation accuracy:		88.59 %
Epoch 1492 of 2000 took 0.097s
  training loss:		0.145424
  validation loss:		0.385545
  validation accuracy:		89.24 %
Epoch 1493 of 2000 took 0.097s
  training loss:		0.144649
  validation loss:		0.392883
  validation accuracy:		89.13 %
Epoch 1494 of 2000 took 0.097s
  training loss:		0.148186
  validation loss:		0.394068
  validation accuracy:		89.02 %
Epoch 1495 of 2000 took 0.097s
  training loss:		0.143098
  validation loss:		0.408306
  validation accuracy:		88.37 %
Epoch 1496 of 2000 took 0.097s
  training loss:		0.150034
  validation loss:		0.382886
  validation accuracy:		88.70 %
Epoch 1497 of 2000 took 0.097s
  training loss:		0.149109
  validation loss:		0.396258
  validation accuracy:		89.13 %
Epoch 1498 of 2000 took 0.097s
  training loss:		0.143669
  validation loss:		0.400701
  validation accuracy:		88.59 %
Epoch 1499 of 2000 took 0.097s
  training loss:		0.143565
  validation loss:		0.381199
  validation accuracy:		88.91 %
Epoch 1500 of 2000 took 0.097s
  training loss:		0.146613
  validation loss:		0.405754
  validation accuracy:		89.46 %
Epoch 1501 of 2000 took 0.097s
  training loss:		0.148923
  validation loss:		0.394000
  validation accuracy:		89.46 %
Epoch 1502 of 2000 took 0.097s
  training loss:		0.145803
  validation loss:		0.403510
  validation accuracy:		89.46 %
Epoch 1503 of 2000 took 0.097s
  training loss:		0.143043
  validation loss:		0.392230
  validation accuracy:		88.91 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.144199
  validation loss:		0.394924
  validation accuracy:		89.24 %
Epoch 1505 of 2000 took 0.097s
  training loss:		0.142808
  validation loss:		0.386805
  validation accuracy:		89.46 %
Epoch 1506 of 2000 took 0.097s
  training loss:		0.143016
  validation loss:		0.394169
  validation accuracy:		89.35 %
Epoch 1507 of 2000 took 0.097s
  training loss:		0.144100
  validation loss:		0.394237
  validation accuracy:		88.80 %
Epoch 1508 of 2000 took 0.097s
  training loss:		0.144334
  validation loss:		0.402862
  validation accuracy:		89.02 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.142963
  validation loss:		0.390612
  validation accuracy:		88.80 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.144719
  validation loss:		0.383862
  validation accuracy:		88.80 %
Epoch 1511 of 2000 took 0.097s
  training loss:		0.149830
  validation loss:		0.393299
  validation accuracy:		88.37 %
Epoch 1512 of 2000 took 0.097s
  training loss:		0.149774
  validation loss:		0.400445
  validation accuracy:		88.70 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.144134
  validation loss:		0.409985
  validation accuracy:		88.37 %
Epoch 1514 of 2000 took 0.098s
  training loss:		0.145654
  validation loss:		0.397192
  validation accuracy:		88.91 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.145954
  validation loss:		0.419229
  validation accuracy:		88.48 %
Epoch 1516 of 2000 took 0.097s
  training loss:		0.146207
  validation loss:		0.417120
  validation accuracy:		89.02 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.146103
  validation loss:		0.397159
  validation accuracy:		88.91 %
Epoch 1518 of 2000 took 0.097s
  training loss:		0.146665
  validation loss:		0.389989
  validation accuracy:		89.35 %
Epoch 1519 of 2000 took 0.098s
  training loss:		0.147569
  validation loss:		0.398837
  validation accuracy:		89.24 %
Epoch 1520 of 2000 took 0.103s
  training loss:		0.139904
  validation loss:		0.407148
  validation accuracy:		88.48 %
Epoch 1521 of 2000 took 0.103s
  training loss:		0.139604
  validation loss:		0.431565
  validation accuracy:		88.37 %
Epoch 1522 of 2000 took 0.100s
  training loss:		0.146964
  validation loss:		0.392602
  validation accuracy:		89.57 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.140417
  validation loss:		0.379612
  validation accuracy:		89.24 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.144450
  validation loss:		0.389932
  validation accuracy:		89.02 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.142465
  validation loss:		0.421546
  validation accuracy:		88.80 %
Epoch 1526 of 2000 took 0.100s
  training loss:		0.138955
  validation loss:		0.392113
  validation accuracy:		89.78 %
Epoch 1527 of 2000 took 0.100s
  training loss:		0.145761
  validation loss:		0.399924
  validation accuracy:		89.02 %
Epoch 1528 of 2000 took 0.100s
  training loss:		0.138624
  validation loss:		0.409145
  validation accuracy:		88.26 %
Epoch 1529 of 2000 took 0.100s
  training loss:		0.145390
  validation loss:		0.397043
  validation accuracy:		88.91 %
Epoch 1530 of 2000 took 0.100s
  training loss:		0.142972
  validation loss:		0.394301
  validation accuracy:		89.78 %
Epoch 1531 of 2000 took 0.100s
  training loss:		0.141236
  validation loss:		0.397126
  validation accuracy:		89.67 %
Epoch 1532 of 2000 took 0.100s
  training loss:		0.143112
  validation loss:		0.395912
  validation accuracy:		89.35 %
Epoch 1533 of 2000 took 0.100s
  training loss:		0.137756
  validation loss:		0.376819
  validation accuracy:		89.57 %
Epoch 1534 of 2000 took 0.100s
  training loss:		0.138864
  validation loss:		0.387769
  validation accuracy:		89.67 %
Epoch 1535 of 2000 took 0.100s
  training loss:		0.139404
  validation loss:		0.411179
  validation accuracy:		88.37 %
Epoch 1536 of 2000 took 0.100s
  training loss:		0.142535
  validation loss:		0.399419
  validation accuracy:		89.13 %
Epoch 1537 of 2000 took 0.100s
  training loss:		0.144828
  validation loss:		0.407457
  validation accuracy:		89.02 %
Epoch 1538 of 2000 took 0.100s
  training loss:		0.132860
  validation loss:		0.413129
  validation accuracy:		88.48 %
Epoch 1539 of 2000 took 0.100s
  training loss:		0.141532
  validation loss:		0.384211
  validation accuracy:		89.24 %
Epoch 1540 of 2000 took 0.100s
  training loss:		0.145935
  validation loss:		0.410851
  validation accuracy:		88.59 %
Epoch 1541 of 2000 took 0.100s
  training loss:		0.139866
  validation loss:		0.400623
  validation accuracy:		88.91 %
Epoch 1542 of 2000 took 0.100s
  training loss:		0.137727
  validation loss:		0.397046
  validation accuracy:		89.35 %
Epoch 1543 of 2000 took 0.100s
  training loss:		0.142584
  validation loss:		0.410064
  validation accuracy:		89.24 %
Epoch 1544 of 2000 took 0.101s
  training loss:		0.141725
  validation loss:		0.392260
  validation accuracy:		89.35 %
Epoch 1545 of 2000 took 0.100s
  training loss:		0.134945
  validation loss:		0.414698
  validation accuracy:		88.59 %
Epoch 1546 of 2000 took 0.100s
  training loss:		0.142258
  validation loss:		0.379038
  validation accuracy:		89.78 %
Epoch 1547 of 2000 took 0.100s
  training loss:		0.135554
  validation loss:		0.391344
  validation accuracy:		89.35 %
Epoch 1548 of 2000 took 0.100s
  training loss:		0.137957
  validation loss:		0.395081
  validation accuracy:		88.91 %
Epoch 1549 of 2000 took 0.100s
  training loss:		0.139373
  validation loss:		0.405891
  validation accuracy:		89.24 %
Epoch 1550 of 2000 took 0.100s
  training loss:		0.136128
  validation loss:		0.401186
  validation accuracy:		88.70 %
Epoch 1551 of 2000 took 0.100s
  training loss:		0.133499
  validation loss:		0.393745
  validation accuracy:		89.24 %
Epoch 1552 of 2000 took 0.100s
  training loss:		0.135074
  validation loss:		0.405936
  validation accuracy:		88.70 %
Epoch 1553 of 2000 took 0.100s
  training loss:		0.139327
  validation loss:		0.394369
  validation accuracy:		89.46 %
Epoch 1554 of 2000 took 0.100s
  training loss:		0.137466
  validation loss:		0.393470
  validation accuracy:		89.24 %
Epoch 1555 of 2000 took 0.100s
  training loss:		0.140633
  validation loss:		0.407503
  validation accuracy:		88.59 %
Epoch 1556 of 2000 took 0.100s
  training loss:		0.135636
  validation loss:		0.409858
  validation accuracy:		89.13 %
Epoch 1557 of 2000 took 0.100s
  training loss:		0.138793
  validation loss:		0.406190
  validation accuracy:		89.02 %
Epoch 1558 of 2000 took 0.100s
  training loss:		0.137685
  validation loss:		0.401943
  validation accuracy:		88.80 %
Epoch 1559 of 2000 took 0.100s
  training loss:		0.133256
  validation loss:		0.385594
  validation accuracy:		89.35 %
Epoch 1560 of 2000 took 0.097s
  training loss:		0.137254
  validation loss:		0.419289
  validation accuracy:		88.70 %
Epoch 1561 of 2000 took 0.097s
  training loss:		0.133015
  validation loss:		0.393891
  validation accuracy:		89.02 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.138509
  validation loss:		0.388702
  validation accuracy:		89.57 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.137989
  validation loss:		0.416531
  validation accuracy:		89.02 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.140409
  validation loss:		0.387363
  validation accuracy:		89.35 %
Epoch 1565 of 2000 took 0.097s
  training loss:		0.139072
  validation loss:		0.397472
  validation accuracy:		89.13 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.140655
  validation loss:		0.380897
  validation accuracy:		89.89 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.133811
  validation loss:		0.390514
  validation accuracy:		89.24 %
Epoch 1568 of 2000 took 0.099s
  training loss:		0.137763
  validation loss:		0.391872
  validation accuracy:		89.78 %
Epoch 1569 of 2000 took 0.097s
  training loss:		0.139668
  validation loss:		0.428198
  validation accuracy:		88.80 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.140148
  validation loss:		0.425126
  validation accuracy:		89.35 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.134277
  validation loss:		0.420907
  validation accuracy:		88.80 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.132374
  validation loss:		0.391625
  validation accuracy:		89.78 %
Epoch 1573 of 2000 took 0.097s
  training loss:		0.134353
  validation loss:		0.407416
  validation accuracy:		89.89 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.133548
  validation loss:		0.387755
  validation accuracy:		89.57 %
Epoch 1575 of 2000 took 0.098s
  training loss:		0.136596
  validation loss:		0.405924
  validation accuracy:		88.91 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.134716
  validation loss:		0.401417
  validation accuracy:		89.02 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.132520
  validation loss:		0.407748
  validation accuracy:		89.02 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.132776
  validation loss:		0.411871
  validation accuracy:		88.80 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.137990
  validation loss:		0.407050
  validation accuracy:		89.78 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.133461
  validation loss:		0.388671
  validation accuracy:		89.35 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.141291
  validation loss:		0.425674
  validation accuracy:		89.24 %
Epoch 1582 of 2000 took 0.097s
  training loss:		0.134257
  validation loss:		0.402923
  validation accuracy:		89.35 %
Epoch 1583 of 2000 took 0.097s
  training loss:		0.134422
  validation loss:		0.401506
  validation accuracy:		89.13 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.136331
  validation loss:		0.408053
  validation accuracy:		89.24 %
Epoch 1585 of 2000 took 0.097s
  training loss:		0.133488
  validation loss:		0.395739
  validation accuracy:		88.91 %
Epoch 1586 of 2000 took 0.097s
  training loss:		0.138722
  validation loss:		0.414290
  validation accuracy:		89.02 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.141560
  validation loss:		0.407382
  validation accuracy:		89.57 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.129463
  validation loss:		0.387493
  validation accuracy:		89.57 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.131943
  validation loss:		0.401595
  validation accuracy:		90.22 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.134942
  validation loss:		0.379163
  validation accuracy:		90.11 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.134840
  validation loss:		0.389995
  validation accuracy:		89.78 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.131469
  validation loss:		0.421678
  validation accuracy:		89.24 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.135990
  validation loss:		0.394059
  validation accuracy:		89.57 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.129218
  validation loss:		0.419525
  validation accuracy:		89.02 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.130509
  validation loss:		0.381950
  validation accuracy:		89.78 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.133010
  validation loss:		0.413789
  validation accuracy:		88.80 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.128977
  validation loss:		0.397035
  validation accuracy:		89.13 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.132691
  validation loss:		0.411855
  validation accuracy:		88.59 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.133260
  validation loss:		0.416140
  validation accuracy:		89.13 %
Epoch 1600 of 2000 took 0.097s
  training loss:		0.132089
  validation loss:		0.410819
  validation accuracy:		89.57 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.132810
  validation loss:		0.402560
  validation accuracy:		89.24 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.133651
  validation loss:		0.413572
  validation accuracy:		89.24 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.134879
  validation loss:		0.406780
  validation accuracy:		89.24 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.130186
  validation loss:		0.399535
  validation accuracy:		89.35 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.128719
  validation loss:		0.395009
  validation accuracy:		89.67 %
Epoch 1606 of 2000 took 0.098s
  training loss:		0.131425
  validation loss:		0.391657
  validation accuracy:		89.24 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.131504
  validation loss:		0.438008
  validation accuracy:		88.48 %
Epoch 1608 of 2000 took 0.097s
  training loss:		0.134782
  validation loss:		0.403465
  validation accuracy:		89.89 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.133135
  validation loss:		0.388021
  validation accuracy:		89.67 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.131241
  validation loss:		0.435259
  validation accuracy:		89.24 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.133831
  validation loss:		0.426516
  validation accuracy:		89.35 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.129876
  validation loss:		0.400326
  validation accuracy:		89.13 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.130228
  validation loss:		0.403863
  validation accuracy:		89.24 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.130407
  validation loss:		0.405917
  validation accuracy:		89.89 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.127497
  validation loss:		0.420574
  validation accuracy:		89.35 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.130203
  validation loss:		0.414139
  validation accuracy:		89.46 %
Epoch 1617 of 2000 took 0.097s
  training loss:		0.126908
  validation loss:		0.423347
  validation accuracy:		89.24 %
Epoch 1618 of 2000 took 0.097s
  training loss:		0.132392
  validation loss:		0.410568
  validation accuracy:		89.35 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.124973
  validation loss:		0.406838
  validation accuracy:		89.24 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.132235
  validation loss:		0.391021
  validation accuracy:		89.67 %
Epoch 1621 of 2000 took 0.097s
  training loss:		0.126461
  validation loss:		0.417963
  validation accuracy:		88.91 %
Epoch 1622 of 2000 took 0.097s
  training loss:		0.131510
  validation loss:		0.405823
  validation accuracy:		89.78 %
Epoch 1623 of 2000 took 0.097s
  training loss:		0.127819
  validation loss:		0.417716
  validation accuracy:		89.13 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.129016
  validation loss:		0.393603
  validation accuracy:		89.35 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.130164
  validation loss:		0.410076
  validation accuracy:		89.67 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.128391
  validation loss:		0.413947
  validation accuracy:		89.13 %
Epoch 1627 of 2000 took 0.098s
  training loss:		0.124072
  validation loss:		0.401052
  validation accuracy:		89.02 %
Epoch 1628 of 2000 took 0.104s
  training loss:		0.129489
  validation loss:		0.402959
  validation accuracy:		89.02 %
Epoch 1629 of 2000 took 0.104s
  training loss:		0.128536
  validation loss:		0.402668
  validation accuracy:		90.00 %
Epoch 1630 of 2000 took 0.098s
  training loss:		0.131628
  validation loss:		0.399030
  validation accuracy:		89.13 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.124386
  validation loss:		0.406987
  validation accuracy:		89.78 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.126127
  validation loss:		0.408698
  validation accuracy:		89.67 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.124334
  validation loss:		0.401067
  validation accuracy:		89.57 %
Epoch 1634 of 2000 took 0.093s
  training loss:		0.126309
  validation loss:		0.403239
  validation accuracy:		89.78 %
Epoch 1635 of 2000 took 0.093s
  training loss:		0.129509
  validation loss:		0.399058
  validation accuracy:		89.35 %
Epoch 1636 of 2000 took 0.093s
  training loss:		0.129336
  validation loss:		0.416086
  validation accuracy:		89.35 %
Epoch 1637 of 2000 took 0.094s
  training loss:		0.129631
  validation loss:		0.391715
  validation accuracy:		89.78 %
Epoch 1638 of 2000 took 0.093s
  training loss:		0.123000
  validation loss:		0.397329
  validation accuracy:		89.89 %
Epoch 1639 of 2000 took 0.093s
  training loss:		0.127570
  validation loss:		0.397234
  validation accuracy:		89.13 %
Epoch 1640 of 2000 took 0.093s
  training loss:		0.122385
  validation loss:		0.411549
  validation accuracy:		89.67 %
Epoch 1641 of 2000 took 0.093s
  training loss:		0.126221
  validation loss:		0.409094
  validation accuracy:		89.02 %
Epoch 1642 of 2000 took 0.095s
  training loss:		0.123704
  validation loss:		0.398869
  validation accuracy:		89.78 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.125505
  validation loss:		0.403408
  validation accuracy:		89.35 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.121368
  validation loss:		0.414617
  validation accuracy:		89.57 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.128261
  validation loss:		0.429247
  validation accuracy:		88.48 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.131315
  validation loss:		0.391228
  validation accuracy:		90.11 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.128169
  validation loss:		0.405100
  validation accuracy:		89.24 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.130798
  validation loss:		0.391959
  validation accuracy:		89.67 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.125177
  validation loss:		0.391768
  validation accuracy:		90.00 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.126193
  validation loss:		0.432591
  validation accuracy:		88.59 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.125092
  validation loss:		0.393236
  validation accuracy:		89.67 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.123168
  validation loss:		0.408114
  validation accuracy:		89.35 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.125170
  validation loss:		0.431912
  validation accuracy:		89.02 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.125703
  validation loss:		0.409986
  validation accuracy:		89.24 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.124149
  validation loss:		0.388489
  validation accuracy:		90.22 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.126271
  validation loss:		0.408987
  validation accuracy:		89.24 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.121658
  validation loss:		0.391922
  validation accuracy:		90.11 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.126351
  validation loss:		0.425369
  validation accuracy:		89.13 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.124814
  validation loss:		0.396051
  validation accuracy:		89.78 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.126361
  validation loss:		0.407601
  validation accuracy:		90.00 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.127006
  validation loss:		0.419675
  validation accuracy:		90.11 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.125741
  validation loss:		0.411651
  validation accuracy:		89.46 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.119121
  validation loss:		0.412804
  validation accuracy:		89.24 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.119717
  validation loss:		0.406220
  validation accuracy:		89.35 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.124917
  validation loss:		0.421213
  validation accuracy:		89.67 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.124731
  validation loss:		0.432696
  validation accuracy:		89.24 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.125106
  validation loss:		0.398182
  validation accuracy:		89.57 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.121756
  validation loss:		0.398553
  validation accuracy:		89.89 %
Epoch 1669 of 2000 took 0.097s
  training loss:		0.126350
  validation loss:		0.412532
  validation accuracy:		89.46 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.122036
  validation loss:		0.427741
  validation accuracy:		89.24 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.123669
  validation loss:		0.403653
  validation accuracy:		89.35 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.119420
  validation loss:		0.418138
  validation accuracy:		89.24 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.123060
  validation loss:		0.413888
  validation accuracy:		89.46 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.120548
  validation loss:		0.406160
  validation accuracy:		89.67 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.119490
  validation loss:		0.412374
  validation accuracy:		89.46 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.123265
  validation loss:		0.427901
  validation accuracy:		89.46 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.118386
  validation loss:		0.403470
  validation accuracy:		89.89 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.124069
  validation loss:		0.419489
  validation accuracy:		89.57 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.120569
  validation loss:		0.424088
  validation accuracy:		89.35 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.122397
  validation loss:		0.401401
  validation accuracy:		89.46 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.119827
  validation loss:		0.419559
  validation accuracy:		89.46 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.120208
  validation loss:		0.406450
  validation accuracy:		89.13 %
Epoch 1683 of 2000 took 0.094s
  training loss:		0.120478
  validation loss:		0.427744
  validation accuracy:		89.57 %
Epoch 1684 of 2000 took 0.093s
  training loss:		0.122672
  validation loss:		0.409278
  validation accuracy:		89.78 %
Epoch 1685 of 2000 took 0.093s
  training loss:		0.115582
  validation loss:		0.423283
  validation accuracy:		89.78 %
Epoch 1686 of 2000 took 0.093s
  training loss:		0.128141
  validation loss:		0.409739
  validation accuracy:		89.67 %
Epoch 1687 of 2000 took 0.093s
  training loss:		0.120182
  validation loss:		0.438332
  validation accuracy:		89.13 %
Epoch 1688 of 2000 took 0.093s
  training loss:		0.116186
  validation loss:		0.411932
  validation accuracy:		89.67 %
Epoch 1689 of 2000 took 0.093s
  training loss:		0.122455
  validation loss:		0.399049
  validation accuracy:		89.78 %
Epoch 1690 of 2000 took 0.093s
  training loss:		0.117075
  validation loss:		0.402704
  validation accuracy:		89.78 %
Epoch 1691 of 2000 took 0.093s
  training loss:		0.116842
  validation loss:		0.440263
  validation accuracy:		88.80 %
Epoch 1692 of 2000 took 0.093s
  training loss:		0.116060
  validation loss:		0.419669
  validation accuracy:		89.46 %
Epoch 1693 of 2000 took 0.093s
  training loss:		0.122754
  validation loss:		0.407818
  validation accuracy:		89.78 %
Epoch 1694 of 2000 took 0.093s
  training loss:		0.121744
  validation loss:		0.419640
  validation accuracy:		88.91 %
Epoch 1695 of 2000 took 0.093s
  training loss:		0.117490
  validation loss:		0.423958
  validation accuracy:		89.46 %
Epoch 1696 of 2000 took 0.093s
  training loss:		0.117582
  validation loss:		0.418010
  validation accuracy:		89.46 %
Epoch 1697 of 2000 took 0.093s
  training loss:		0.120159
  validation loss:		0.397914
  validation accuracy:		90.22 %
Epoch 1698 of 2000 took 0.093s
  training loss:		0.118491
  validation loss:		0.419235
  validation accuracy:		89.46 %
Epoch 1699 of 2000 took 0.093s
  training loss:		0.119710
  validation loss:		0.411321
  validation accuracy:		90.11 %
Epoch 1700 of 2000 took 0.093s
  training loss:		0.118932
  validation loss:		0.419212
  validation accuracy:		89.35 %
Epoch 1701 of 2000 took 0.094s
  training loss:		0.111278
  validation loss:		0.434743
  validation accuracy:		89.46 %
Epoch 1702 of 2000 took 0.093s
  training loss:		0.116818
  validation loss:		0.424794
  validation accuracy:		89.02 %
Epoch 1703 of 2000 took 0.093s
  training loss:		0.120495
  validation loss:		0.399982
  validation accuracy:		90.43 %
Epoch 1704 of 2000 took 0.093s
  training loss:		0.119249
  validation loss:		0.405319
  validation accuracy:		90.33 %
Epoch 1705 of 2000 took 0.093s
  training loss:		0.122774
  validation loss:		0.426133
  validation accuracy:		89.57 %
Epoch 1706 of 2000 took 0.093s
  training loss:		0.119223
  validation loss:		0.442864
  validation accuracy:		89.46 %
Epoch 1707 of 2000 took 0.093s
  training loss:		0.117188
  validation loss:		0.443166
  validation accuracy:		89.24 %
Epoch 1708 of 2000 took 0.093s
  training loss:		0.115624
  validation loss:		0.415760
  validation accuracy:		89.67 %
Epoch 1709 of 2000 took 0.093s
  training loss:		0.114005
  validation loss:		0.441468
  validation accuracy:		89.46 %
Epoch 1710 of 2000 took 0.095s
  training loss:		0.113607
  validation loss:		0.437795
  validation accuracy:		89.46 %
Epoch 1711 of 2000 took 0.093s
  training loss:		0.120753
  validation loss:		0.430516
  validation accuracy:		89.35 %
Epoch 1712 of 2000 took 0.093s
  training loss:		0.115953
  validation loss:		0.431913
  validation accuracy:		89.57 %
Epoch 1713 of 2000 took 0.093s
  training loss:		0.114658
  validation loss:		0.419123
  validation accuracy:		89.78 %
Epoch 1714 of 2000 took 0.093s
  training loss:		0.118041
  validation loss:		0.438736
  validation accuracy:		89.24 %
Epoch 1715 of 2000 took 0.093s
  training loss:		0.116276
  validation loss:		0.424521
  validation accuracy:		90.00 %
Epoch 1716 of 2000 took 0.093s
  training loss:		0.117179
  validation loss:		0.428715
  validation accuracy:		89.02 %
Epoch 1717 of 2000 took 0.093s
  training loss:		0.110738
  validation loss:		0.412351
  validation accuracy:		90.00 %
Epoch 1718 of 2000 took 0.093s
  training loss:		0.118176
  validation loss:		0.423116
  validation accuracy:		89.57 %
Epoch 1719 of 2000 took 0.093s
  training loss:		0.116248
  validation loss:		0.436792
  validation accuracy:		89.78 %
Epoch 1720 of 2000 took 0.093s
  training loss:		0.114887
  validation loss:		0.416908
  validation accuracy:		90.33 %
Epoch 1721 of 2000 took 0.093s
  training loss:		0.114412
  validation loss:		0.423943
  validation accuracy:		89.78 %
Epoch 1722 of 2000 took 0.093s
  training loss:		0.117740
  validation loss:		0.406319
  validation accuracy:		90.33 %
Epoch 1723 of 2000 took 0.093s
  training loss:		0.115964
  validation loss:		0.403792
  validation accuracy:		90.33 %
Epoch 1724 of 2000 took 0.093s
  training loss:		0.111709
  validation loss:		0.435106
  validation accuracy:		89.24 %
Epoch 1725 of 2000 took 0.093s
  training loss:		0.114097
  validation loss:		0.414065
  validation accuracy:		89.78 %
Epoch 1726 of 2000 took 0.093s
  training loss:		0.114003
  validation loss:		0.417350
  validation accuracy:		89.89 %
Epoch 1727 of 2000 took 0.093s
  training loss:		0.108200
  validation loss:		0.425894
  validation accuracy:		89.67 %
Epoch 1728 of 2000 took 0.093s
  training loss:		0.112114
  validation loss:		0.439013
  validation accuracy:		89.24 %
Epoch 1729 of 2000 took 0.093s
  training loss:		0.115641
  validation loss:		0.423836
  validation accuracy:		89.67 %
Epoch 1730 of 2000 took 0.093s
  training loss:		0.114017
  validation loss:		0.425846
  validation accuracy:		89.67 %
Epoch 1731 of 2000 took 0.093s
  training loss:		0.116326
  validation loss:		0.436914
  validation accuracy:		89.24 %
Epoch 1732 of 2000 took 0.093s
  training loss:		0.118915
  validation loss:		0.430893
  validation accuracy:		89.89 %
Epoch 1733 of 2000 took 0.094s
  training loss:		0.116797
  validation loss:		0.459383
  validation accuracy:		88.70 %
Epoch 1734 of 2000 took 0.093s
  training loss:		0.107818
  validation loss:		0.418878
  validation accuracy:		89.78 %
Epoch 1735 of 2000 took 0.093s
  training loss:		0.116983
  validation loss:		0.423368
  validation accuracy:		89.57 %
Epoch 1736 of 2000 took 0.093s
  training loss:		0.111554
  validation loss:		0.449924
  validation accuracy:		89.35 %
Epoch 1737 of 2000 took 0.093s
  training loss:		0.119085
  validation loss:		0.421896
  validation accuracy:		89.78 %
Epoch 1738 of 2000 took 0.093s
  training loss:		0.113252
  validation loss:		0.426371
  validation accuracy:		89.78 %
Epoch 1739 of 2000 took 0.093s
  training loss:		0.114436
  validation loss:		0.447050
  validation accuracy:		89.57 %
Epoch 1740 of 2000 took 0.093s
  training loss:		0.114310
  validation loss:		0.437848
  validation accuracy:		89.24 %
Epoch 1741 of 2000 took 0.093s
  training loss:		0.113437
  validation loss:		0.428191
  validation accuracy:		89.78 %
Epoch 1742 of 2000 took 0.093s
  training loss:		0.113851
  validation loss:		0.409796
  validation accuracy:		90.33 %
Epoch 1743 of 2000 took 0.093s
  training loss:		0.107988
  validation loss:		0.445831
  validation accuracy:		89.89 %
Epoch 1744 of 2000 took 0.093s
  training loss:		0.110828
  validation loss:		0.424287
  validation accuracy:		89.67 %
Epoch 1745 of 2000 took 0.093s
  training loss:		0.112644
  validation loss:		0.420123
  validation accuracy:		90.11 %
Epoch 1746 of 2000 took 0.093s
  training loss:		0.112893
  validation loss:		0.436965
  validation accuracy:		89.89 %
Epoch 1747 of 2000 took 0.093s
  training loss:		0.116682
  validation loss:		0.427408
  validation accuracy:		89.78 %
Epoch 1748 of 2000 took 0.093s
  training loss:		0.113725
  validation loss:		0.433796
  validation accuracy:		89.57 %
Epoch 1749 of 2000 took 0.093s
  training loss:		0.107944
  validation loss:		0.442993
  validation accuracy:		89.35 %
Epoch 1750 of 2000 took 0.093s
  training loss:		0.116322
  validation loss:		0.406805
  validation accuracy:		90.54 %
Epoch 1751 of 2000 took 0.093s
  training loss:		0.110268
  validation loss:		0.425809
  validation accuracy:		89.67 %
Epoch 1752 of 2000 took 0.093s
  training loss:		0.105231
  validation loss:		0.433892
  validation accuracy:		89.24 %
Epoch 1753 of 2000 took 0.093s
  training loss:		0.113451
  validation loss:		0.422403
  validation accuracy:		89.67 %
Epoch 1754 of 2000 took 0.093s
  training loss:		0.109618
  validation loss:		0.436359
  validation accuracy:		89.78 %
Epoch 1755 of 2000 took 0.093s
  training loss:		0.110694
  validation loss:		0.425996
  validation accuracy:		90.00 %
Epoch 1756 of 2000 took 0.093s
  training loss:		0.111723
  validation loss:		0.419271
  validation accuracy:		90.98 %
Epoch 1757 of 2000 took 0.093s
  training loss:		0.118074
  validation loss:		0.435755
  validation accuracy:		89.78 %
Epoch 1758 of 2000 took 0.093s
  training loss:		0.110951
  validation loss:		0.448558
  validation accuracy:		89.24 %
Epoch 1759 of 2000 took 0.093s
  training loss:		0.108105
  validation loss:		0.434686
  validation accuracy:		89.78 %
Epoch 1760 of 2000 took 0.093s
  training loss:		0.111954
  validation loss:		0.422820
  validation accuracy:		90.22 %
Epoch 1761 of 2000 took 0.093s
  training loss:		0.109368
  validation loss:		0.448161
  validation accuracy:		89.24 %
Epoch 1762 of 2000 took 0.093s
  training loss:		0.114703
  validation loss:		0.429677
  validation accuracy:		89.78 %
Epoch 1763 of 2000 took 0.093s
  training loss:		0.110011
  validation loss:		0.436008
  validation accuracy:		89.67 %
Epoch 1764 of 2000 took 0.093s
  training loss:		0.107534
  validation loss:		0.443301
  validation accuracy:		89.13 %
Epoch 1765 of 2000 took 0.094s
  training loss:		0.112906
  validation loss:		0.446887
  validation accuracy:		89.35 %
Epoch 1766 of 2000 took 0.093s
  training loss:		0.113155
  validation loss:		0.431356
  validation accuracy:		89.89 %
Epoch 1767 of 2000 took 0.093s
  training loss:		0.115197
  validation loss:		0.434759
  validation accuracy:		90.00 %
Epoch 1768 of 2000 took 0.093s
  training loss:		0.104468
  validation loss:		0.448187
  validation accuracy:		89.35 %
Epoch 1769 of 2000 took 0.093s
  training loss:		0.109012
  validation loss:		0.441896
  validation accuracy:		89.78 %
Epoch 1770 of 2000 took 0.093s
  training loss:		0.103629
  validation loss:		0.425715
  validation accuracy:		90.00 %
Epoch 1771 of 2000 took 0.093s
  training loss:		0.113776
  validation loss:		0.444363
  validation accuracy:		89.35 %
Epoch 1772 of 2000 took 0.093s
  training loss:		0.106733
  validation loss:		0.449945
  validation accuracy:		89.24 %
Epoch 1773 of 2000 took 0.093s
  training loss:		0.113519
  validation loss:		0.430938
  validation accuracy:		90.11 %
Epoch 1774 of 2000 took 0.093s
  training loss:		0.111718
  validation loss:		0.448061
  validation accuracy:		89.46 %
Epoch 1775 of 2000 took 0.093s
  training loss:		0.106849
  validation loss:		0.449987
  validation accuracy:		89.24 %
Epoch 1776 of 2000 took 0.093s
  training loss:		0.107108
  validation loss:		0.470467
  validation accuracy:		89.78 %
Epoch 1777 of 2000 took 0.093s
  training loss:		0.107560
  validation loss:		0.449885
  validation accuracy:		89.57 %
Epoch 1778 of 2000 took 0.093s
  training loss:		0.107204
  validation loss:		0.445460
  validation accuracy:		89.67 %
Epoch 1779 of 2000 took 0.093s
  training loss:		0.110198
  validation loss:		0.444251
  validation accuracy:		89.89 %
Epoch 1780 of 2000 took 0.093s
  training loss:		0.104232
  validation loss:		0.441246
  validation accuracy:		90.11 %
Epoch 1781 of 2000 took 0.093s
  training loss:		0.110309
  validation loss:		0.424984
  validation accuracy:		90.33 %
Epoch 1782 of 2000 took 0.093s
  training loss:		0.107083
  validation loss:		0.451669
  validation accuracy:		89.57 %
Epoch 1783 of 2000 took 0.093s
  training loss:		0.108038
  validation loss:		0.448297
  validation accuracy:		89.78 %
Epoch 1784 of 2000 took 0.093s
  training loss:		0.110721
  validation loss:		0.425979
  validation accuracy:		89.89 %
Epoch 1785 of 2000 took 0.093s
  training loss:		0.107761
  validation loss:		0.447486
  validation accuracy:		89.78 %
Epoch 1786 of 2000 took 0.093s
  training loss:		0.108805
  validation loss:		0.453741
  validation accuracy:		90.00 %
Epoch 1787 of 2000 took 0.093s
  training loss:		0.107722
  validation loss:		0.448381
  validation accuracy:		89.89 %
Epoch 1788 of 2000 took 0.093s
  training loss:		0.106058
  validation loss:		0.446730
  validation accuracy:		89.57 %
Epoch 1789 of 2000 took 0.093s
  training loss:		0.109091
  validation loss:		0.452230
  validation accuracy:		89.78 %
Epoch 1790 of 2000 took 0.093s
  training loss:		0.107862
  validation loss:		0.472780
  validation accuracy:		89.46 %
Epoch 1791 of 2000 took 0.093s
  training loss:		0.109536
  validation loss:		0.453308
  validation accuracy:		90.76 %
Epoch 1792 of 2000 took 0.093s
  training loss:		0.111915
  validation loss:		0.448067
  validation accuracy:		89.78 %
Epoch 1793 of 2000 took 0.093s
  training loss:		0.112668
  validation loss:		0.433154
  validation accuracy:		90.00 %
Epoch 1794 of 2000 took 0.094s
  training loss:		0.108754
  validation loss:		0.449100
  validation accuracy:		90.00 %
Epoch 1795 of 2000 took 0.093s
  training loss:		0.106286
  validation loss:		0.440701
  validation accuracy:		89.89 %
Epoch 1796 of 2000 took 0.093s
  training loss:		0.106044
  validation loss:		0.433161
  validation accuracy:		90.22 %
Epoch 1797 of 2000 took 0.093s
  training loss:		0.104271
  validation loss:		0.443915
  validation accuracy:		89.78 %
Epoch 1798 of 2000 took 0.094s
  training loss:		0.108423
  validation loss:		0.456041
  validation accuracy:		89.67 %
Epoch 1799 of 2000 took 0.093s
  training loss:		0.110081
  validation loss:		0.463353
  validation accuracy:		89.35 %
Epoch 1800 of 2000 took 0.093s
  training loss:		0.105835
  validation loss:		0.452763
  validation accuracy:		89.78 %
Epoch 1801 of 2000 took 0.093s
  training loss:		0.106994
  validation loss:		0.430928
  validation accuracy:		90.43 %
Epoch 1802 of 2000 took 0.093s
  training loss:		0.104937
  validation loss:		0.438402
  validation accuracy:		89.78 %
Epoch 1803 of 2000 took 0.093s
  training loss:		0.109958
  validation loss:		0.434547
  validation accuracy:		90.33 %
Epoch 1804 of 2000 took 0.093s
  training loss:		0.102982
  validation loss:		0.441893
  validation accuracy:		90.00 %
Epoch 1805 of 2000 took 0.093s
  training loss:		0.108470
  validation loss:		0.433382
  validation accuracy:		90.11 %
Epoch 1806 of 2000 took 0.093s
  training loss:		0.104351
  validation loss:		0.453843
  validation accuracy:		90.22 %
Epoch 1807 of 2000 took 0.093s
  training loss:		0.106138
  validation loss:		0.458294
  validation accuracy:		90.43 %
Epoch 1808 of 2000 took 0.093s
  training loss:		0.106613
  validation loss:		0.467038
  validation accuracy:		90.11 %
Epoch 1809 of 2000 took 0.093s
  training loss:		0.106450
  validation loss:		0.462815
  validation accuracy:		90.33 %
Epoch 1810 of 2000 took 0.093s
  training loss:		0.104221
  validation loss:		0.427983
  validation accuracy:		90.22 %
Epoch 1811 of 2000 took 0.093s
  training loss:		0.104796
  validation loss:		0.452613
  validation accuracy:		89.78 %
Epoch 1812 of 2000 took 0.093s
  training loss:		0.107164
  validation loss:		0.473801
  validation accuracy:		89.46 %
Epoch 1813 of 2000 took 0.093s
  training loss:		0.103219
  validation loss:		0.455196
  validation accuracy:		89.89 %
Epoch 1814 of 2000 took 0.093s
  training loss:		0.106436
  validation loss:		0.461152
  validation accuracy:		89.46 %
Epoch 1815 of 2000 took 0.093s
  training loss:		0.102171
  validation loss:		0.440178
  validation accuracy:		90.00 %
Epoch 1816 of 2000 took 0.093s
  training loss:		0.102144
  validation loss:		0.446981
  validation accuracy:		90.22 %
Epoch 1817 of 2000 took 0.093s
  training loss:		0.104053
  validation loss:		0.444122
  validation accuracy:		90.11 %
Epoch 1818 of 2000 took 0.093s
  training loss:		0.102220
  validation loss:		0.451088
  validation accuracy:		89.78 %
Epoch 1819 of 2000 took 0.093s
  training loss:		0.102555
  validation loss:		0.469499
  validation accuracy:		88.91 %
Epoch 1820 of 2000 took 0.093s
  training loss:		0.104285
  validation loss:		0.461219
  validation accuracy:		89.13 %
Epoch 1821 of 2000 took 0.093s
  training loss:		0.102831
  validation loss:		0.470624
  validation accuracy:		88.91 %
Epoch 1822 of 2000 took 0.093s
  training loss:		0.099362
  validation loss:		0.456476
  validation accuracy:		90.22 %
Epoch 1823 of 2000 took 0.093s
  training loss:		0.104489
  validation loss:		0.489348
  validation accuracy:		88.48 %
Epoch 1824 of 2000 took 0.093s
  training loss:		0.102955
  validation loss:		0.460409
  validation accuracy:		89.35 %
Epoch 1825 of 2000 took 0.093s
  training loss:		0.103257
  validation loss:		0.447532
  validation accuracy:		89.89 %
Epoch 1826 of 2000 took 0.093s
  training loss:		0.099500
  validation loss:		0.443879
  validation accuracy:		90.00 %
Epoch 1827 of 2000 took 0.093s
  training loss:		0.101550
  validation loss:		0.451793
  validation accuracy:		89.89 %
Epoch 1828 of 2000 took 0.093s
  training loss:		0.102444
  validation loss:		0.458472
  validation accuracy:		89.57 %
Epoch 1829 of 2000 took 0.093s
  training loss:		0.100196
  validation loss:		0.501970
  validation accuracy:		88.91 %
Epoch 1830 of 2000 took 0.094s
  training loss:		0.107439
  validation loss:		0.464921
  validation accuracy:		89.78 %
Epoch 1831 of 2000 took 0.093s
  training loss:		0.101154
  validation loss:		0.459589
  validation accuracy:		89.89 %
Epoch 1832 of 2000 took 0.093s
  training loss:		0.097761
  validation loss:		0.465204
  validation accuracy:		89.35 %
Epoch 1833 of 2000 took 0.093s
  training loss:		0.104448
  validation loss:		0.456062
  validation accuracy:		89.78 %
Epoch 1834 of 2000 took 0.093s
  training loss:		0.103931
  validation loss:		0.445191
  validation accuracy:		90.11 %
Epoch 1835 of 2000 took 0.093s
  training loss:		0.101985
  validation loss:		0.466688
  validation accuracy:		89.67 %
Epoch 1836 of 2000 took 0.093s
  training loss:		0.100584
  validation loss:		0.477773
  validation accuracy:		89.13 %
Epoch 1837 of 2000 took 0.093s
  training loss:		0.102850
  validation loss:		0.461349
  validation accuracy:		89.67 %
Epoch 1838 of 2000 took 0.093s
  training loss:		0.101261
  validation loss:		0.472293
  validation accuracy:		89.67 %
Epoch 1839 of 2000 took 0.093s
  training loss:		0.101884
  validation loss:		0.476559
  validation accuracy:		90.11 %
Epoch 1840 of 2000 took 0.093s
  training loss:		0.102064
  validation loss:		0.447266
  validation accuracy:		90.54 %
Epoch 1841 of 2000 took 0.093s
  training loss:		0.097034
  validation loss:		0.455252
  validation accuracy:		90.11 %
Epoch 1842 of 2000 took 0.093s
  training loss:		0.102453
  validation loss:		0.460834
  validation accuracy:		89.67 %
Epoch 1843 of 2000 took 0.093s
  training loss:		0.098196
  validation loss:		0.468097
  validation accuracy:		89.89 %
Epoch 1844 of 2000 took 0.093s
  training loss:		0.101558
  validation loss:		0.479696
  validation accuracy:		89.57 %
Epoch 1845 of 2000 took 0.093s
  training loss:		0.103073
  validation loss:		0.463441
  validation accuracy:		90.00 %
Epoch 1846 of 2000 took 0.093s
  training loss:		0.101486
  validation loss:		0.456931
  validation accuracy:		90.11 %
Epoch 1847 of 2000 took 0.093s
  training loss:		0.096755
  validation loss:		0.476434
  validation accuracy:		89.57 %
Epoch 1848 of 2000 took 0.093s
  training loss:		0.104371
  validation loss:		0.470711
  validation accuracy:		89.35 %
Epoch 1849 of 2000 took 0.093s
  training loss:		0.099321
  validation loss:		0.476267
  validation accuracy:		90.33 %
Epoch 1850 of 2000 took 0.093s
  training loss:		0.103589
  validation loss:		0.476587
  validation accuracy:		89.46 %
Epoch 1851 of 2000 took 0.093s
  training loss:		0.100016
  validation loss:		0.474675
  validation accuracy:		89.89 %
Epoch 1852 of 2000 took 0.093s
  training loss:		0.101629
  validation loss:		0.497928
  validation accuracy:		89.46 %
Epoch 1853 of 2000 took 0.093s
  training loss:		0.098551
  validation loss:		0.459231
  validation accuracy:		89.67 %
Epoch 1854 of 2000 took 0.093s
  training loss:		0.098111
  validation loss:		0.459110
  validation accuracy:		89.57 %
Epoch 1855 of 2000 took 0.093s
  training loss:		0.104016
  validation loss:		0.466817
  validation accuracy:		89.67 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.097339
  validation loss:		0.453067
  validation accuracy:		90.00 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.097910
  validation loss:		0.470707
  validation accuracy:		89.67 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.100446
  validation loss:		0.474961
  validation accuracy:		89.78 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.092243
  validation loss:		0.498416
  validation accuracy:		88.80 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.097635
  validation loss:		0.461991
  validation accuracy:		90.33 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.103782
  validation loss:		0.484094
  validation accuracy:		90.00 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.095412
  validation loss:		0.475646
  validation accuracy:		89.78 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.102011
  validation loss:		0.458487
  validation accuracy:		90.00 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.100591
  validation loss:		0.473911
  validation accuracy:		90.43 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.099171
  validation loss:		0.485865
  validation accuracy:		89.67 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.093829
  validation loss:		0.490748
  validation accuracy:		89.35 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.096875
  validation loss:		0.483987
  validation accuracy:		90.33 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.097400
  validation loss:		0.474155
  validation accuracy:		89.57 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.096612
  validation loss:		0.464654
  validation accuracy:		89.89 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.098067
  validation loss:		0.478432
  validation accuracy:		89.46 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.095895
  validation loss:		0.477434
  validation accuracy:		89.89 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.093345
  validation loss:		0.461059
  validation accuracy:		90.22 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.095895
  validation loss:		0.472581
  validation accuracy:		89.78 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.098317
  validation loss:		0.484957
  validation accuracy:		89.67 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.093236
  validation loss:		0.458007
  validation accuracy:		90.00 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.090281
  validation loss:		0.474807
  validation accuracy:		89.78 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.091156
  validation loss:		0.472899
  validation accuracy:		89.57 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.102420
  validation loss:		0.484966
  validation accuracy:		90.33 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.097259
  validation loss:		0.471929
  validation accuracy:		90.00 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.098478
  validation loss:		0.479239
  validation accuracy:		90.54 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.097654
  validation loss:		0.468655
  validation accuracy:		89.78 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.100646
  validation loss:		0.477595
  validation accuracy:		90.22 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.091047
  validation loss:		0.467821
  validation accuracy:		90.00 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.092309
  validation loss:		0.476831
  validation accuracy:		89.24 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.097428
  validation loss:		0.472122
  validation accuracy:		89.89 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.095239
  validation loss:		0.500518
  validation accuracy:		89.13 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.092858
  validation loss:		0.505393
  validation accuracy:		89.46 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.097106
  validation loss:		0.477122
  validation accuracy:		89.78 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.094163
  validation loss:		0.487830
  validation accuracy:		89.78 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.098789
  validation loss:		0.518684
  validation accuracy:		88.70 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.098399
  validation loss:		0.477303
  validation accuracy:		89.78 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.091225
  validation loss:		0.499308
  validation accuracy:		89.57 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.096801
  validation loss:		0.473924
  validation accuracy:		89.57 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.094101
  validation loss:		0.481690
  validation accuracy:		90.22 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.097695
  validation loss:		0.477891
  validation accuracy:		89.78 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.088722
  validation loss:		0.501768
  validation accuracy:		89.02 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.098163
  validation loss:		0.487096
  validation accuracy:		89.89 %
Epoch 1898 of 2000 took 0.095s
  training loss:		0.093321
  validation loss:		0.472608
  validation accuracy:		90.11 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.105197
  validation loss:		0.476909
  validation accuracy:		89.46 %
Epoch 1900 of 2000 took 0.099s
  training loss:		0.096295
  validation loss:		0.497594
  validation accuracy:		88.80 %
Epoch 1901 of 2000 took 0.100s
  training loss:		0.090324
  validation loss:		0.482300
  validation accuracy:		89.89 %
Epoch 1902 of 2000 took 0.123s
  training loss:		0.097185
  validation loss:		0.502842
  validation accuracy:		89.35 %
Epoch 1903 of 2000 took 0.123s
  training loss:		0.092921
  validation loss:		0.486159
  validation accuracy:		90.11 %
Epoch 1904 of 2000 took 0.123s
  training loss:		0.093817
  validation loss:		0.488945
  validation accuracy:		89.46 %
Epoch 1905 of 2000 took 0.123s
  training loss:		0.090116
  validation loss:		0.502521
  validation accuracy:		89.13 %
Epoch 1906 of 2000 took 0.123s
  training loss:		0.094559
  validation loss:		0.506416
  validation accuracy:		89.67 %
Epoch 1907 of 2000 took 0.123s
  training loss:		0.094624
  validation loss:		0.488474
  validation accuracy:		90.00 %
Epoch 1908 of 2000 took 0.123s
  training loss:		0.092233
  validation loss:		0.495826
  validation accuracy:		89.57 %
Epoch 1909 of 2000 took 0.123s
  training loss:		0.093385
  validation loss:		0.476178
  validation accuracy:		90.00 %
Epoch 1910 of 2000 took 0.123s
  training loss:		0.091007
  validation loss:		0.483988
  validation accuracy:		89.46 %
Epoch 1911 of 2000 took 0.123s
  training loss:		0.093357
  validation loss:		0.493211
  validation accuracy:		89.67 %
Epoch 1912 of 2000 took 0.123s
  training loss:		0.097666
  validation loss:		0.484340
  validation accuracy:		89.89 %
Epoch 1913 of 2000 took 0.123s
  training loss:		0.097201
  validation loss:		0.518996
  validation accuracy:		89.02 %
Epoch 1914 of 2000 took 0.123s
  training loss:		0.095632
  validation loss:		0.488090
  validation accuracy:		89.78 %
Epoch 1915 of 2000 took 0.123s
  training loss:		0.091901
  validation loss:		0.486171
  validation accuracy:		90.00 %
Epoch 1916 of 2000 took 0.123s
  training loss:		0.093720
  validation loss:		0.495354
  validation accuracy:		89.46 %
Epoch 1917 of 2000 took 0.123s
  training loss:		0.092403
  validation loss:		0.478677
  validation accuracy:		89.78 %
Epoch 1918 of 2000 took 0.123s
  training loss:		0.091992
  validation loss:		0.503988
  validation accuracy:		89.13 %
Epoch 1919 of 2000 took 0.123s
  training loss:		0.087844
  validation loss:		0.490839
  validation accuracy:		90.00 %
Epoch 1920 of 2000 took 0.123s
  training loss:		0.091256
  validation loss:		0.506894
  validation accuracy:		89.13 %
Epoch 1921 of 2000 took 0.123s
  training loss:		0.095512
  validation loss:		0.515638
  validation accuracy:		89.35 %
Epoch 1922 of 2000 took 0.123s
  training loss:		0.093647
  validation loss:		0.488689
  validation accuracy:		90.00 %
Epoch 1923 of 2000 took 0.123s
  training loss:		0.087036
  validation loss:		0.472938
  validation accuracy:		90.33 %
Epoch 1924 of 2000 took 0.123s
  training loss:		0.091174
  validation loss:		0.506069
  validation accuracy:		89.78 %
Epoch 1925 of 2000 took 0.123s
  training loss:		0.088558
  validation loss:		0.509506
  validation accuracy:		89.35 %
Epoch 1926 of 2000 took 0.123s
  training loss:		0.089057
  validation loss:		0.510599
  validation accuracy:		89.46 %
Epoch 1927 of 2000 took 0.123s
  training loss:		0.091242
  validation loss:		0.516774
  validation accuracy:		89.13 %
Epoch 1928 of 2000 took 0.123s
  training loss:		0.091109
  validation loss:		0.497492
  validation accuracy:		89.89 %
Epoch 1929 of 2000 took 0.123s
  training loss:		0.090360
  validation loss:		0.510559
  validation accuracy:		89.24 %
Epoch 1930 of 2000 took 0.123s
  training loss:		0.097824
  validation loss:		0.505814
  validation accuracy:		89.89 %
Epoch 1931 of 2000 took 0.123s
  training loss:		0.092261
  validation loss:		0.520053
  validation accuracy:		89.35 %
Epoch 1932 of 2000 took 0.123s
  training loss:		0.096085
  validation loss:		0.502550
  validation accuracy:		89.78 %
Epoch 1933 of 2000 took 0.123s
  training loss:		0.091439
  validation loss:		0.498085
  validation accuracy:		89.78 %
Epoch 1934 of 2000 took 0.123s
  training loss:		0.088476
  validation loss:		0.518245
  validation accuracy:		89.24 %
Epoch 1935 of 2000 took 0.123s
  training loss:		0.091204
  validation loss:		0.522731
  validation accuracy:		88.80 %
Epoch 1936 of 2000 took 0.123s
  training loss:		0.089692
  validation loss:		0.519577
  validation accuracy:		89.46 %
Epoch 1937 of 2000 took 0.123s
  training loss:		0.097037
  validation loss:		0.528930
  validation accuracy:		89.35 %
Epoch 1938 of 2000 took 0.123s
  training loss:		0.094233
  validation loss:		0.513635
  validation accuracy:		89.24 %
Epoch 1939 of 2000 took 0.123s
  training loss:		0.094475
  validation loss:		0.498980
  validation accuracy:		89.78 %
Epoch 1940 of 2000 took 0.123s
  training loss:		0.088462
  validation loss:		0.517386
  validation accuracy:		89.35 %
Epoch 1941 of 2000 took 0.123s
  training loss:		0.091558
  validation loss:		0.504563
  validation accuracy:		89.46 %
Epoch 1942 of 2000 took 0.117s
  training loss:		0.089547
  validation loss:		0.513167
  validation accuracy:		90.00 %
Epoch 1943 of 2000 took 0.094s
  training loss:		0.088142
  validation loss:		0.512563
  validation accuracy:		89.57 %
Epoch 1944 of 2000 took 0.093s
  training loss:		0.088511
  validation loss:		0.529498
  validation accuracy:		89.78 %
Epoch 1945 of 2000 took 0.094s
  training loss:		0.088830
  validation loss:		0.514219
  validation accuracy:		89.78 %
Epoch 1946 of 2000 took 0.093s
  training loss:		0.091102
  validation loss:		0.498506
  validation accuracy:		90.22 %
Epoch 1947 of 2000 took 0.093s
  training loss:		0.087810
  validation loss:		0.516544
  validation accuracy:		89.13 %
Epoch 1948 of 2000 took 0.093s
  training loss:		0.094972
  validation loss:		0.503723
  validation accuracy:		89.46 %
Epoch 1949 of 2000 took 0.093s
  training loss:		0.087114
  validation loss:		0.523146
  validation accuracy:		88.91 %
Epoch 1950 of 2000 took 0.093s
  training loss:		0.087537
  validation loss:		0.526486
  validation accuracy:		89.46 %
Epoch 1951 of 2000 took 0.093s
  training loss:		0.092942
  validation loss:		0.527762
  validation accuracy:		89.57 %
Epoch 1952 of 2000 took 0.093s
  training loss:		0.087976
  validation loss:		0.516390
  validation accuracy:		89.35 %
Epoch 1953 of 2000 took 0.093s
  training loss:		0.094124
  validation loss:		0.534142
  validation accuracy:		89.67 %
Epoch 1954 of 2000 took 0.093s
  training loss:		0.092430
  validation loss:		0.530249
  validation accuracy:		89.02 %
Epoch 1955 of 2000 took 0.093s
  training loss:		0.087544
  validation loss:		0.494279
  validation accuracy:		90.22 %
Epoch 1956 of 2000 took 0.093s
  training loss:		0.090054
  validation loss:		0.513734
  validation accuracy:		89.57 %
Epoch 1957 of 2000 took 0.093s
  training loss:		0.089991
  validation loss:		0.498523
  validation accuracy:		89.89 %
Epoch 1958 of 2000 took 0.093s
  training loss:		0.085378
  validation loss:		0.511561
  validation accuracy:		89.46 %
Epoch 1959 of 2000 took 0.093s
  training loss:		0.089793
  validation loss:		0.526116
  validation accuracy:		89.46 %
Epoch 1960 of 2000 took 0.093s
  training loss:		0.087399
  validation loss:		0.513076
  validation accuracy:		89.46 %
Epoch 1961 of 2000 took 0.093s
  training loss:		0.089013
  validation loss:		0.539155
  validation accuracy:		89.02 %
Epoch 1962 of 2000 took 0.093s
  training loss:		0.092573
  validation loss:		0.536595
  validation accuracy:		89.46 %
Epoch 1963 of 2000 took 0.093s
  training loss:		0.086749
  validation loss:		0.563849
  validation accuracy:		88.48 %
Epoch 1964 of 2000 took 0.093s
  training loss:		0.089215
  validation loss:		0.497313
  validation accuracy:		90.00 %
Epoch 1965 of 2000 took 0.093s
  training loss:		0.087566
  validation loss:		0.562093
  validation accuracy:		89.02 %
Epoch 1966 of 2000 took 0.093s
  training loss:		0.090052
  validation loss:		0.533287
  validation accuracy:		89.24 %
Epoch 1967 of 2000 took 0.093s
  training loss:		0.090414
  validation loss:		0.498494
  validation accuracy:		90.33 %
Epoch 1968 of 2000 took 0.093s
  training loss:		0.089453
  validation loss:		0.569656
  validation accuracy:		88.80 %
Epoch 1969 of 2000 took 0.093s
  training loss:		0.092943
  validation loss:		0.527343
  validation accuracy:		89.46 %
Epoch 1970 of 2000 took 0.093s
  training loss:		0.083524
  validation loss:		0.527195
  validation accuracy:		89.46 %
Epoch 1971 of 2000 took 0.093s
  training loss:		0.089686
  validation loss:		0.515124
  validation accuracy:		89.89 %
Epoch 1972 of 2000 took 0.093s
  training loss:		0.096230
  validation loss:		0.509264
  validation accuracy:		89.78 %
Epoch 1973 of 2000 took 0.093s
  training loss:		0.084906
  validation loss:		0.554458
  validation accuracy:		88.80 %
Epoch 1974 of 2000 took 0.093s
  training loss:		0.087494
  validation loss:		0.510639
  validation accuracy:		89.89 %
Epoch 1975 of 2000 took 0.093s
  training loss:		0.094817
  validation loss:		0.520711
  validation accuracy:		89.46 %
Epoch 1976 of 2000 took 0.093s
  training loss:		0.084602
  validation loss:		0.539016
  validation accuracy:		88.91 %
Epoch 1977 of 2000 took 0.093s
  training loss:		0.087049
  validation loss:		0.541687
  validation accuracy:		89.35 %
Epoch 1978 of 2000 took 0.094s
  training loss:		0.076525
  validation loss:		0.524121
  validation accuracy:		90.00 %
Epoch 1979 of 2000 took 0.093s
  training loss:		0.088346
  validation loss:		0.514035
  validation accuracy:		89.78 %
Epoch 1980 of 2000 took 0.093s
  training loss:		0.085330
  validation loss:		0.552214
  validation accuracy:		89.13 %
Epoch 1981 of 2000 took 0.093s
  training loss:		0.086424
  validation loss:		0.532057
  validation accuracy:		89.24 %
Epoch 1982 of 2000 took 0.093s
  training loss:		0.087344
  validation loss:		0.528168
  validation accuracy:		90.00 %
Epoch 1983 of 2000 took 0.093s
  training loss:		0.087274
  validation loss:		0.528301
  validation accuracy:		90.11 %
Epoch 1984 of 2000 took 0.093s
  training loss:		0.085086
  validation loss:		0.526660
  validation accuracy:		89.24 %
Epoch 1985 of 2000 took 0.093s
  training loss:		0.082599
  validation loss:		0.513686
  validation accuracy:		89.89 %
Epoch 1986 of 2000 took 0.093s
  training loss:		0.089822
  validation loss:		0.522983
  validation accuracy:		89.78 %
Epoch 1987 of 2000 took 0.093s
  training loss:		0.086113
  validation loss:		0.523340
  validation accuracy:		89.89 %
Epoch 1988 of 2000 took 0.093s
  training loss:		0.084582
  validation loss:		0.522400
  validation accuracy:		89.89 %
Epoch 1989 of 2000 took 0.093s
  training loss:		0.085479
  validation loss:		0.524413
  validation accuracy:		89.67 %
Epoch 1990 of 2000 took 0.093s
  training loss:		0.091380
  validation loss:		0.531354
  validation accuracy:		89.67 %
Epoch 1991 of 2000 took 0.093s
  training loss:		0.082373
  validation loss:		0.517125
  validation accuracy:		90.11 %
Epoch 1992 of 2000 took 0.093s
  training loss:		0.105560
  validation loss:		0.560123
  validation accuracy:		89.67 %
Epoch 1993 of 2000 took 0.093s
  training loss:		0.082931
  validation loss:		0.541718
  validation accuracy:		89.02 %
Epoch 1994 of 2000 took 0.093s
  training loss:		0.081888
  validation loss:		0.534645
  validation accuracy:		90.22 %
Epoch 1995 of 2000 took 0.093s
  training loss:		0.081235
  validation loss:		0.544724
  validation accuracy:		89.46 %
Epoch 1996 of 2000 took 0.093s
  training loss:		0.080942
  validation loss:		0.523966
  validation accuracy:		89.89 %
Epoch 1997 of 2000 took 0.093s
  training loss:		0.083436
  validation loss:		0.517018
  validation accuracy:		90.00 %
Epoch 1998 of 2000 took 0.093s
  training loss:		0.083626
  validation loss:		0.527928
  validation accuracy:		89.78 %
Epoch 1999 of 2000 took 0.093s
  training loss:		0.084034
  validation loss:		0.562917
  validation accuracy:		88.91 %
Epoch 2000 of 2000 took 0.100s
  training loss:		0.083213
  validation loss:		0.558513
  validation accuracy:		89.02 %
Final results:
  test loss:			1.227469
  test accuracy:		80.96 %
