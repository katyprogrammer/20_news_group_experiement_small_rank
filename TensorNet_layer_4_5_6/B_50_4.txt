Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		2.985896
  validation loss:		2.905252
  validation accuracy:		14.67 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.895874
  validation loss:		2.814605
  validation accuracy:		16.09 %
Epoch 3 of 2000 took 0.099s
  training loss:		2.801364
  validation loss:		2.728106
  validation accuracy:		14.35 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.712415
  validation loss:		2.633314
  validation accuracy:		15.54 %
Epoch 5 of 2000 took 0.096s
  training loss:		2.617772
  validation loss:		2.531188
  validation accuracy:		18.04 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.525688
  validation loss:		2.428329
  validation accuracy:		21.30 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.434988
  validation loss:		2.332760
  validation accuracy:		22.50 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.361627
  validation loss:		2.260012
  validation accuracy:		22.39 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.311767
  validation loss:		2.224034
  validation accuracy:		26.30 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.282191
  validation loss:		2.205343
  validation accuracy:		26.30 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.261546
  validation loss:		2.196453
  validation accuracy:		26.41 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.247427
  validation loss:		2.180644
  validation accuracy:		28.48 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.234013
  validation loss:		2.165884
  validation accuracy:		29.78 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.225276
  validation loss:		2.155781
  validation accuracy:		31.63 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.215613
  validation loss:		2.156103
  validation accuracy:		33.91 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.202865
  validation loss:		2.135624
  validation accuracy:		36.20 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.191830
  validation loss:		2.119249
  validation accuracy:		37.17 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.179594
  validation loss:		2.106333
  validation accuracy:		34.78 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.165311
  validation loss:		2.093806
  validation accuracy:		38.04 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.151762
  validation loss:		2.077138
  validation accuracy:		38.80 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.132171
  validation loss:		2.051402
  validation accuracy:		40.11 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.113396
  validation loss:		2.031921
  validation accuracy:		42.50 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.094768
  validation loss:		2.013517
  validation accuracy:		42.93 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.071028
  validation loss:		1.985309
  validation accuracy:		44.57 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.044909
  validation loss:		1.947183
  validation accuracy:		43.91 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.018229
  validation loss:		1.923029
  validation accuracy:		45.43 %
Epoch 27 of 2000 took 0.097s
  training loss:		1.989102
  validation loss:		1.889639
  validation accuracy:		47.83 %
Epoch 28 of 2000 took 0.097s
  training loss:		1.956252
  validation loss:		1.855749
  validation accuracy:		48.59 %
Epoch 29 of 2000 took 0.098s
  training loss:		1.921621
  validation loss:		1.812546
  validation accuracy:		48.26 %
Epoch 30 of 2000 took 0.097s
  training loss:		1.889312
  validation loss:		1.792504
  validation accuracy:		50.33 %
Epoch 31 of 2000 took 0.097s
  training loss:		1.850858
  validation loss:		1.747475
  validation accuracy:		49.35 %
Epoch 32 of 2000 took 0.097s
  training loss:		1.810685
  validation loss:		1.715479
  validation accuracy:		52.28 %
Epoch 33 of 2000 took 0.097s
  training loss:		1.773667
  validation loss:		1.660284
  validation accuracy:		55.00 %
Epoch 34 of 2000 took 0.097s
  training loss:		1.735097
  validation loss:		1.622678
  validation accuracy:		54.35 %
Epoch 35 of 2000 took 0.102s
  training loss:		1.693459
  validation loss:		1.585943
  validation accuracy:		55.98 %
Epoch 36 of 2000 took 0.097s
  training loss:		1.656441
  validation loss:		1.540766
  validation accuracy:		56.63 %
Epoch 37 of 2000 took 0.097s
  training loss:		1.621515
  validation loss:		1.499211
  validation accuracy:		57.83 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.574599
  validation loss:		1.468300
  validation accuracy:		59.57 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.531808
  validation loss:		1.417250
  validation accuracy:		59.13 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.493353
  validation loss:		1.383943
  validation accuracy:		62.72 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.453780
  validation loss:		1.346680
  validation accuracy:		63.59 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.407384
  validation loss:		1.299701
  validation accuracy:		64.78 %
Epoch 43 of 2000 took 0.097s
  training loss:		1.368280
  validation loss:		1.286959
  validation accuracy:		66.74 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.336428
  validation loss:		1.231595
  validation accuracy:		66.96 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.291489
  validation loss:		1.178473
  validation accuracy:		66.20 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.253690
  validation loss:		1.143508
  validation accuracy:		67.72 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.216398
  validation loss:		1.112339
  validation accuracy:		69.57 %
Epoch 48 of 2000 took 0.097s
  training loss:		1.171109
  validation loss:		1.068436
  validation accuracy:		69.02 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.137564
  validation loss:		1.030131
  validation accuracy:		70.43 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.100752
  validation loss:		0.996142
  validation accuracy:		72.17 %
Epoch 51 of 2000 took 0.097s
  training loss:		1.059843
  validation loss:		0.948583
  validation accuracy:		72.83 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.022044
  validation loss:		0.924573
  validation accuracy:		74.24 %
Epoch 53 of 2000 took 0.097s
  training loss:		0.990991
  validation loss:		0.893435
  validation accuracy:		74.13 %
Epoch 54 of 2000 took 0.097s
  training loss:		0.958060
  validation loss:		0.876152
  validation accuracy:		75.65 %
Epoch 55 of 2000 took 0.097s
  training loss:		0.925470
  validation loss:		0.836007
  validation accuracy:		76.20 %
Epoch 56 of 2000 took 0.097s
  training loss:		0.890454
  validation loss:		0.796158
  validation accuracy:		76.63 %
Epoch 57 of 2000 took 0.097s
  training loss:		0.865126
  validation loss:		0.779648
  validation accuracy:		77.17 %
Epoch 58 of 2000 took 0.097s
  training loss:		0.837879
  validation loss:		0.760103
  validation accuracy:		77.39 %
Epoch 59 of 2000 took 0.097s
  training loss:		0.808393
  validation loss:		0.733694
  validation accuracy:		77.39 %
Epoch 60 of 2000 took 0.098s
  training loss:		0.791132
  validation loss:		0.719447
  validation accuracy:		77.50 %
Epoch 61 of 2000 took 0.097s
  training loss:		0.761278
  validation loss:		0.698446
  validation accuracy:		78.70 %
Epoch 62 of 2000 took 0.097s
  training loss:		0.740767
  validation loss:		0.666426
  validation accuracy:		79.46 %
Epoch 63 of 2000 took 0.097s
  training loss:		0.711962
  validation loss:		0.656749
  validation accuracy:		78.70 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.696969
  validation loss:		0.642181
  validation accuracy:		79.24 %
Epoch 65 of 2000 took 0.097s
  training loss:		0.680167
  validation loss:		0.619283
  validation accuracy:		79.78 %
Epoch 66 of 2000 took 0.097s
  training loss:		0.659386
  validation loss:		0.609304
  validation accuracy:		80.54 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.646699
  validation loss:		0.604027
  validation accuracy:		80.76 %
Epoch 68 of 2000 took 0.097s
  training loss:		0.628545
  validation loss:		0.587124
  validation accuracy:		80.98 %
Epoch 69 of 2000 took 0.097s
  training loss:		0.620780
  validation loss:		0.576059
  validation accuracy:		81.09 %
Epoch 70 of 2000 took 0.097s
  training loss:		0.598029
  validation loss:		0.561166
  validation accuracy:		81.52 %
Epoch 71 of 2000 took 0.097s
  training loss:		0.592108
  validation loss:		0.556510
  validation accuracy:		81.96 %
Epoch 72 of 2000 took 0.097s
  training loss:		0.583034
  validation loss:		0.543641
  validation accuracy:		82.07 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.567978
  validation loss:		0.538887
  validation accuracy:		82.28 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.563056
  validation loss:		0.523505
  validation accuracy:		82.17 %
Epoch 75 of 2000 took 0.097s
  training loss:		0.552579
  validation loss:		0.525575
  validation accuracy:		81.63 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.533238
  validation loss:		0.509514
  validation accuracy:		82.72 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.538456
  validation loss:		0.527122
  validation accuracy:		82.39 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.519996
  validation loss:		0.518538
  validation accuracy:		82.50 %
Epoch 79 of 2000 took 0.097s
  training loss:		0.524502
  validation loss:		0.502379
  validation accuracy:		83.80 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.509314
  validation loss:		0.490959
  validation accuracy:		83.04 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.501540
  validation loss:		0.488111
  validation accuracy:		82.72 %
Epoch 82 of 2000 took 0.097s
  training loss:		0.493136
  validation loss:		0.475545
  validation accuracy:		83.37 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.497829
  validation loss:		0.465599
  validation accuracy:		84.46 %
Epoch 84 of 2000 took 0.097s
  training loss:		0.483437
  validation loss:		0.472872
  validation accuracy:		84.13 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.479349
  validation loss:		0.465300
  validation accuracy:		83.37 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.470303
  validation loss:		0.466017
  validation accuracy:		84.13 %
Epoch 87 of 2000 took 0.097s
  training loss:		0.462715
  validation loss:		0.455905
  validation accuracy:		84.13 %
Epoch 88 of 2000 took 0.097s
  training loss:		0.460804
  validation loss:		0.459383
  validation accuracy:		84.13 %
Epoch 89 of 2000 took 0.097s
  training loss:		0.447807
  validation loss:		0.460216
  validation accuracy:		84.24 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.449135
  validation loss:		0.441922
  validation accuracy:		85.22 %
Epoch 91 of 2000 took 0.098s
  training loss:		0.444250
  validation loss:		0.447504
  validation accuracy:		85.00 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.434571
  validation loss:		0.436903
  validation accuracy:		85.00 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.434926
  validation loss:		0.447231
  validation accuracy:		84.57 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.423265
  validation loss:		0.430306
  validation accuracy:		85.65 %
Epoch 95 of 2000 took 0.102s
  training loss:		0.436751
  validation loss:		0.433770
  validation accuracy:		85.43 %
Epoch 96 of 2000 took 0.097s
  training loss:		0.422976
  validation loss:		0.418111
  validation accuracy:		85.98 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.409446
  validation loss:		0.415439
  validation accuracy:		85.98 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.407101
  validation loss:		0.412829
  validation accuracy:		86.41 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.410976
  validation loss:		0.422286
  validation accuracy:		86.30 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.405946
  validation loss:		0.411206
  validation accuracy:		86.41 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.405101
  validation loss:		0.408849
  validation accuracy:		86.85 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.401587
  validation loss:		0.405660
  validation accuracy:		86.63 %
Epoch 103 of 2000 took 0.097s
  training loss:		0.401530
  validation loss:		0.412854
  validation accuracy:		86.52 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.398215
  validation loss:		0.390629
  validation accuracy:		87.72 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.394519
  validation loss:		0.390812
  validation accuracy:		87.39 %
Epoch 106 of 2000 took 0.097s
  training loss:		0.391156
  validation loss:		0.391231
  validation accuracy:		87.28 %
Epoch 107 of 2000 took 0.097s
  training loss:		0.391136
  validation loss:		0.392449
  validation accuracy:		87.28 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.386438
  validation loss:		0.399851
  validation accuracy:		86.85 %
Epoch 109 of 2000 took 0.097s
  training loss:		0.378778
  validation loss:		0.395099
  validation accuracy:		87.50 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.372026
  validation loss:		0.395395
  validation accuracy:		87.39 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.382404
  validation loss:		0.393623
  validation accuracy:		87.50 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.377470
  validation loss:		0.385925
  validation accuracy:		87.93 %
Epoch 113 of 2000 took 0.097s
  training loss:		0.375040
  validation loss:		0.377918
  validation accuracy:		87.93 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.368122
  validation loss:		0.377849
  validation accuracy:		88.37 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.366815
  validation loss:		0.375892
  validation accuracy:		88.80 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.372270
  validation loss:		0.387577
  validation accuracy:		87.93 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.370883
  validation loss:		0.376506
  validation accuracy:		88.26 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.363943
  validation loss:		0.405292
  validation accuracy:		86.52 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.362589
  validation loss:		0.386763
  validation accuracy:		88.26 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.372602
  validation loss:		0.369335
  validation accuracy:		88.37 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.361400
  validation loss:		0.378902
  validation accuracy:		88.48 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.360740
  validation loss:		0.378668
  validation accuracy:		87.83 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.350223
  validation loss:		0.365262
  validation accuracy:		88.70 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.348938
  validation loss:		0.362976
  validation accuracy:		88.48 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.348557
  validation loss:		0.384561
  validation accuracy:		86.52 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.352319
  validation loss:		0.381042
  validation accuracy:		87.61 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.354289
  validation loss:		0.375729
  validation accuracy:		87.83 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.353074
  validation loss:		0.364626
  validation accuracy:		88.48 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.349339
  validation loss:		0.358392
  validation accuracy:		88.26 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.343238
  validation loss:		0.369874
  validation accuracy:		88.59 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.351958
  validation loss:		0.360625
  validation accuracy:		88.70 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.345176
  validation loss:		0.385362
  validation accuracy:		86.63 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.346849
  validation loss:		0.369028
  validation accuracy:		88.37 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.337398
  validation loss:		0.381337
  validation accuracy:		86.74 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.340267
  validation loss:		0.361705
  validation accuracy:		88.04 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.338103
  validation loss:		0.353856
  validation accuracy:		88.48 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.341606
  validation loss:		0.364037
  validation accuracy:		88.26 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.342647
  validation loss:		0.360606
  validation accuracy:		88.15 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.341697
  validation loss:		0.369120
  validation accuracy:		88.26 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.333667
  validation loss:		0.365136
  validation accuracy:		88.37 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.330971
  validation loss:		0.355453
  validation accuracy:		88.48 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.328518
  validation loss:		0.362441
  validation accuracy:		88.26 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.331843
  validation loss:		0.367077
  validation accuracy:		87.72 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.328435
  validation loss:		0.351054
  validation accuracy:		88.70 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.318935
  validation loss:		0.354617
  validation accuracy:		88.70 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.324721
  validation loss:		0.357487
  validation accuracy:		88.59 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.319776
  validation loss:		0.376830
  validation accuracy:		87.07 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.330242
  validation loss:		0.359598
  validation accuracy:		88.48 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.329740
  validation loss:		0.355914
  validation accuracy:		88.70 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.322316
  validation loss:		0.364286
  validation accuracy:		87.93 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.323963
  validation loss:		0.369798
  validation accuracy:		87.61 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.329054
  validation loss:		0.352779
  validation accuracy:		88.70 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.322390
  validation loss:		0.351862
  validation accuracy:		89.02 %
Epoch 154 of 2000 took 0.098s
  training loss:		0.315427
  validation loss:		0.359064
  validation accuracy:		87.72 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.325823
  validation loss:		0.367953
  validation accuracy:		88.15 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.318067
  validation loss:		0.352821
  validation accuracy:		88.80 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.327521
  validation loss:		0.352178
  validation accuracy:		88.59 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.311253
  validation loss:		0.362496
  validation accuracy:		87.72 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.318843
  validation loss:		0.348172
  validation accuracy:		88.48 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.311340
  validation loss:		0.355551
  validation accuracy:		88.59 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.313205
  validation loss:		0.350817
  validation accuracy:		89.13 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.321516
  validation loss:		0.345908
  validation accuracy:		89.13 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.308868
  validation loss:		0.358555
  validation accuracy:		88.15 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.313821
  validation loss:		0.348035
  validation accuracy:		89.02 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.304284
  validation loss:		0.357521
  validation accuracy:		88.59 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.310892
  validation loss:		0.352130
  validation accuracy:		87.93 %
Epoch 167 of 2000 took 0.102s
  training loss:		0.315653
  validation loss:		0.344083
  validation accuracy:		89.02 %
Epoch 168 of 2000 took 0.098s
  training loss:		0.309437
  validation loss:		0.360157
  validation accuracy:		88.59 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.314550
  validation loss:		0.344403
  validation accuracy:		89.46 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.310788
  validation loss:		0.344100
  validation accuracy:		88.70 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.307116
  validation loss:		0.347475
  validation accuracy:		88.48 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.307739
  validation loss:		0.344472
  validation accuracy:		89.13 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.317856
  validation loss:		0.355575
  validation accuracy:		88.48 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.310599
  validation loss:		0.351787
  validation accuracy:		88.26 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.308176
  validation loss:		0.347813
  validation accuracy:		88.04 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.302768
  validation loss:		0.354386
  validation accuracy:		88.80 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.301448
  validation loss:		0.357616
  validation accuracy:		88.15 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.307126
  validation loss:		0.362515
  validation accuracy:		88.04 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.307897
  validation loss:		0.365580
  validation accuracy:		86.74 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.301725
  validation loss:		0.345495
  validation accuracy:		88.59 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.304679
  validation loss:		0.356381
  validation accuracy:		88.26 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.304071
  validation loss:		0.352209
  validation accuracy:		88.37 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.303290
  validation loss:		0.364428
  validation accuracy:		88.04 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.308073
  validation loss:		0.352890
  validation accuracy:		88.70 %
Epoch 185 of 2000 took 0.098s
  training loss:		0.296351
  validation loss:		0.340716
  validation accuracy:		89.78 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.313047
  validation loss:		0.365995
  validation accuracy:		88.04 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.297347
  validation loss:		0.341429
  validation accuracy:		89.78 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.299592
  validation loss:		0.351407
  validation accuracy:		88.59 %
Epoch 189 of 2000 took 0.097s
  training loss:		0.299398
  validation loss:		0.361397
  validation accuracy:		88.15 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.302921
  validation loss:		0.352594
  validation accuracy:		88.59 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.292189
  validation loss:		0.343415
  validation accuracy:		89.24 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.294002
  validation loss:		0.349425
  validation accuracy:		89.46 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.298450
  validation loss:		0.352913
  validation accuracy:		87.61 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.311779
  validation loss:		0.378852
  validation accuracy:		87.07 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.292288
  validation loss:		0.343437
  validation accuracy:		90.00 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.301466
  validation loss:		0.359100
  validation accuracy:		88.37 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.299030
  validation loss:		0.345665
  validation accuracy:		89.57 %
Epoch 198 of 2000 took 0.097s
  training loss:		0.305159
  validation loss:		0.345996
  validation accuracy:		88.70 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.296956
  validation loss:		0.341617
  validation accuracy:		89.67 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.299219
  validation loss:		0.351805
  validation accuracy:		88.80 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.295312
  validation loss:		0.343231
  validation accuracy:		88.70 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.295233
  validation loss:		0.341396
  validation accuracy:		88.91 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.290805
  validation loss:		0.350077
  validation accuracy:		89.13 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.297107
  validation loss:		0.366555
  validation accuracy:		87.17 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.297642
  validation loss:		0.352308
  validation accuracy:		89.35 %
Epoch 206 of 2000 took 0.097s
  training loss:		0.295470
  validation loss:		0.357133
  validation accuracy:		88.15 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.296899
  validation loss:		0.362030
  validation accuracy:		87.61 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.292842
  validation loss:		0.356158
  validation accuracy:		88.37 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.295391
  validation loss:		0.349229
  validation accuracy:		89.13 %
Epoch 210 of 2000 took 0.100s
  training loss:		0.289755
  validation loss:		0.352506
  validation accuracy:		87.28 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.282105
  validation loss:		0.353932
  validation accuracy:		88.37 %
Epoch 212 of 2000 took 0.097s
  training loss:		0.294573
  validation loss:		0.346742
  validation accuracy:		89.46 %
Epoch 213 of 2000 took 0.097s
  training loss:		0.287262
  validation loss:		0.342834
  validation accuracy:		89.13 %
Epoch 214 of 2000 took 0.097s
  training loss:		0.289092
  validation loss:		0.361544
  validation accuracy:		87.93 %
Epoch 215 of 2000 took 0.098s
  training loss:		0.292243
  validation loss:		0.353650
  validation accuracy:		88.48 %
Epoch 216 of 2000 took 0.098s
  training loss:		0.291732
  validation loss:		0.358273
  validation accuracy:		88.70 %
Epoch 217 of 2000 took 0.108s
  training loss:		0.293422
  validation loss:		0.360884
  validation accuracy:		89.24 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.299162
  validation loss:		0.349933
  validation accuracy:		88.80 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.294747
  validation loss:		0.352979
  validation accuracy:		88.59 %
Epoch 220 of 2000 took 0.096s
  training loss:		0.287690
  validation loss:		0.349149
  validation accuracy:		88.59 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.291251
  validation loss:		0.362371
  validation accuracy:		87.83 %
Epoch 222 of 2000 took 0.096s
  training loss:		0.286707
  validation loss:		0.339713
  validation accuracy:		89.35 %
Epoch 223 of 2000 took 0.096s
  training loss:		0.284923
  validation loss:		0.348952
  validation accuracy:		88.70 %
Epoch 224 of 2000 took 0.096s
  training loss:		0.284686
  validation loss:		0.342543
  validation accuracy:		89.13 %
Epoch 225 of 2000 took 0.096s
  training loss:		0.292293
  validation loss:		0.363259
  validation accuracy:		87.93 %
Epoch 226 of 2000 took 0.096s
  training loss:		0.286536
  validation loss:		0.343978
  validation accuracy:		89.67 %
Epoch 227 of 2000 took 0.096s
  training loss:		0.294350
  validation loss:		0.350744
  validation accuracy:		89.02 %
Epoch 228 of 2000 took 0.096s
  training loss:		0.284155
  validation loss:		0.345776
  validation accuracy:		89.46 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.289063
  validation loss:		0.341091
  validation accuracy:		89.67 %
Epoch 230 of 2000 took 0.096s
  training loss:		0.292860
  validation loss:		0.363662
  validation accuracy:		88.26 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.289020
  validation loss:		0.338708
  validation accuracy:		89.78 %
Epoch 232 of 2000 took 0.096s
  training loss:		0.287378
  validation loss:		0.342310
  validation accuracy:		89.02 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.286388
  validation loss:		0.350779
  validation accuracy:		89.46 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.282058
  validation loss:		0.356175
  validation accuracy:		88.26 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.287401
  validation loss:		0.360118
  validation accuracy:		88.70 %
Epoch 236 of 2000 took 0.096s
  training loss:		0.284031
  validation loss:		0.354195
  validation accuracy:		88.48 %
Epoch 237 of 2000 took 0.096s
  training loss:		0.289143
  validation loss:		0.374175
  validation accuracy:		88.04 %
Epoch 238 of 2000 took 0.096s
  training loss:		0.280170
  validation loss:		0.347577
  validation accuracy:		88.80 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.283890
  validation loss:		0.346380
  validation accuracy:		89.13 %
Epoch 240 of 2000 took 0.096s
  training loss:		0.288465
  validation loss:		0.360445
  validation accuracy:		88.26 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.289277
  validation loss:		0.351258
  validation accuracy:		88.37 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.281953
  validation loss:		0.354854
  validation accuracy:		88.37 %
Epoch 243 of 2000 took 0.096s
  training loss:		0.278370
  validation loss:		0.343516
  validation accuracy:		89.46 %
Epoch 244 of 2000 took 0.096s
  training loss:		0.286515
  validation loss:		0.360823
  validation accuracy:		88.91 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.281412
  validation loss:		0.341001
  validation accuracy:		89.57 %
Epoch 246 of 2000 took 0.096s
  training loss:		0.283215
  validation loss:		0.417577
  validation accuracy:		86.52 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.299859
  validation loss:		0.359281
  validation accuracy:		88.37 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.279041
  validation loss:		0.363231
  validation accuracy:		88.26 %
Epoch 249 of 2000 took 0.096s
  training loss:		0.277927
  validation loss:		0.353624
  validation accuracy:		88.48 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.278928
  validation loss:		0.344691
  validation accuracy:		88.91 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.272247
  validation loss:		0.352412
  validation accuracy:		88.80 %
Epoch 252 of 2000 took 0.100s
  training loss:		0.272885
  validation loss:		0.363091
  validation accuracy:		88.37 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.282853
  validation loss:		0.344592
  validation accuracy:		89.02 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.279858
  validation loss:		0.350527
  validation accuracy:		89.46 %
Epoch 255 of 2000 took 0.096s
  training loss:		0.276959
  validation loss:		0.355623
  validation accuracy:		88.70 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.279299
  validation loss:		0.340652
  validation accuracy:		89.46 %
Epoch 257 of 2000 took 0.096s
  training loss:		0.273756
  validation loss:		0.362311
  validation accuracy:		88.37 %
Epoch 258 of 2000 took 0.096s
  training loss:		0.277331
  validation loss:		0.352498
  validation accuracy:		88.59 %
Epoch 259 of 2000 took 0.096s
  training loss:		0.277957
  validation loss:		0.377015
  validation accuracy:		87.93 %
Epoch 260 of 2000 took 0.096s
  training loss:		0.280312
  validation loss:		0.353197
  validation accuracy:		88.70 %
Epoch 261 of 2000 took 0.096s
  training loss:		0.278642
  validation loss:		0.342524
  validation accuracy:		89.57 %
Epoch 262 of 2000 took 0.096s
  training loss:		0.278094
  validation loss:		0.343086
  validation accuracy:		89.57 %
Epoch 263 of 2000 took 0.096s
  training loss:		0.275837
  validation loss:		0.353559
  validation accuracy:		89.35 %
Epoch 264 of 2000 took 0.096s
  training loss:		0.272998
  validation loss:		0.351785
  validation accuracy:		89.46 %
Epoch 265 of 2000 took 0.096s
  training loss:		0.268242
  validation loss:		0.344060
  validation accuracy:		89.35 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.274555
  validation loss:		0.345733
  validation accuracy:		89.24 %
Epoch 267 of 2000 took 0.096s
  training loss:		0.271315
  validation loss:		0.346442
  validation accuracy:		88.80 %
Epoch 268 of 2000 took 0.096s
  training loss:		0.274651
  validation loss:		0.347306
  validation accuracy:		89.46 %
Epoch 269 of 2000 took 0.096s
  training loss:		0.273866
  validation loss:		0.355308
  validation accuracy:		89.24 %
Epoch 270 of 2000 took 0.096s
  training loss:		0.277194
  validation loss:		0.345452
  validation accuracy:		89.02 %
Epoch 271 of 2000 took 0.096s
  training loss:		0.276501
  validation loss:		0.350227
  validation accuracy:		89.13 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.269863
  validation loss:		0.344650
  validation accuracy:		88.91 %
Epoch 273 of 2000 took 0.096s
  training loss:		0.271762
  validation loss:		0.343745
  validation accuracy:		89.46 %
Epoch 274 of 2000 took 0.096s
  training loss:		0.264814
  validation loss:		0.352420
  validation accuracy:		88.70 %
Epoch 275 of 2000 took 0.096s
  training loss:		0.272323
  validation loss:		0.342307
  validation accuracy:		89.35 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.272621
  validation loss:		0.356913
  validation accuracy:		89.02 %
Epoch 277 of 2000 took 0.100s
  training loss:		0.273822
  validation loss:		0.345341
  validation accuracy:		89.02 %
Epoch 278 of 2000 took 0.098s
  training loss:		0.272323
  validation loss:		0.349435
  validation accuracy:		89.13 %
Epoch 279 of 2000 took 0.096s
  training loss:		0.266324
  validation loss:		0.345541
  validation accuracy:		89.24 %
Epoch 280 of 2000 took 0.096s
  training loss:		0.271140
  validation loss:		0.373741
  validation accuracy:		88.04 %
Epoch 281 of 2000 took 0.096s
  training loss:		0.270475
  validation loss:		0.355416
  validation accuracy:		88.59 %
Epoch 282 of 2000 took 0.096s
  training loss:		0.270457
  validation loss:		0.348848
  validation accuracy:		88.59 %
Epoch 283 of 2000 took 0.096s
  training loss:		0.264340
  validation loss:		0.389073
  validation accuracy:		87.83 %
Epoch 284 of 2000 took 0.096s
  training loss:		0.274484
  validation loss:		0.362747
  validation accuracy:		88.48 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.261856
  validation loss:		0.353052
  validation accuracy:		89.02 %
Epoch 286 of 2000 took 0.096s
  training loss:		0.263665
  validation loss:		0.349094
  validation accuracy:		89.13 %
Epoch 287 of 2000 took 0.096s
  training loss:		0.276167
  validation loss:		0.350648
  validation accuracy:		89.35 %
Epoch 288 of 2000 took 0.096s
  training loss:		0.265011
  validation loss:		0.359327
  validation accuracy:		89.13 %
Epoch 289 of 2000 took 0.096s
  training loss:		0.272608
  validation loss:		0.347611
  validation accuracy:		88.70 %
Epoch 290 of 2000 took 0.096s
  training loss:		0.267933
  validation loss:		0.346935
  validation accuracy:		89.35 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.262925
  validation loss:		0.345531
  validation accuracy:		89.35 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.269607
  validation loss:		0.348116
  validation accuracy:		89.35 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.260079
  validation loss:		0.358536
  validation accuracy:		88.70 %
Epoch 294 of 2000 took 0.100s
  training loss:		0.266337
  validation loss:		0.342291
  validation accuracy:		89.24 %
Epoch 295 of 2000 took 0.097s
  training loss:		0.270355
  validation loss:		0.347407
  validation accuracy:		89.46 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.264276
  validation loss:		0.347630
  validation accuracy:		89.24 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.259779
  validation loss:		0.348068
  validation accuracy:		89.13 %
Epoch 298 of 2000 took 0.096s
  training loss:		0.257018
  validation loss:		0.343318
  validation accuracy:		89.35 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.269171
  validation loss:		0.348158
  validation accuracy:		89.57 %
Epoch 300 of 2000 took 0.096s
  training loss:		0.256506
  validation loss:		0.345858
  validation accuracy:		89.24 %
Epoch 301 of 2000 took 0.096s
  training loss:		0.257855
  validation loss:		0.344382
  validation accuracy:		89.67 %
Epoch 302 of 2000 took 0.096s
  training loss:		0.262234
  validation loss:		0.343720
  validation accuracy:		89.57 %
Epoch 303 of 2000 took 0.096s
  training loss:		0.258671
  validation loss:		0.343730
  validation accuracy:		89.35 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.262039
  validation loss:		0.348564
  validation accuracy:		89.02 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.270516
  validation loss:		0.353893
  validation accuracy:		89.13 %
Epoch 306 of 2000 took 0.096s
  training loss:		0.258613
  validation loss:		0.345085
  validation accuracy:		89.13 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.261602
  validation loss:		0.349067
  validation accuracy:		89.78 %
Epoch 308 of 2000 took 0.096s
  training loss:		0.262759
  validation loss:		0.349009
  validation accuracy:		89.24 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.263893
  validation loss:		0.360448
  validation accuracy:		88.80 %
Epoch 310 of 2000 took 0.096s
  training loss:		0.263551
  validation loss:		0.341111
  validation accuracy:		89.24 %
Epoch 311 of 2000 took 0.096s
  training loss:		0.255267
  validation loss:		0.358304
  validation accuracy:		88.48 %
Epoch 312 of 2000 took 0.096s
  training loss:		0.255779
  validation loss:		0.337256
  validation accuracy:		89.57 %
Epoch 313 of 2000 took 0.100s
  training loss:		0.256934
  validation loss:		0.362041
  validation accuracy:		87.83 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.258912
  validation loss:		0.353863
  validation accuracy:		89.02 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.250956
  validation loss:		0.345295
  validation accuracy:		89.46 %
Epoch 316 of 2000 took 0.096s
  training loss:		0.263526
  validation loss:		0.363895
  validation accuracy:		88.15 %
Epoch 317 of 2000 took 0.096s
  training loss:		0.251872
  validation loss:		0.340213
  validation accuracy:		89.67 %
Epoch 318 of 2000 took 0.096s
  training loss:		0.262157
  validation loss:		0.361208
  validation accuracy:		88.48 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.265664
  validation loss:		0.347483
  validation accuracy:		89.02 %
Epoch 320 of 2000 took 0.096s
  training loss:		0.247812
  validation loss:		0.341673
  validation accuracy:		89.57 %
Epoch 321 of 2000 took 0.096s
  training loss:		0.250046
  validation loss:		0.339438
  validation accuracy:		89.57 %
Epoch 322 of 2000 took 0.096s
  training loss:		0.248051
  validation loss:		0.341793
  validation accuracy:		89.24 %
Epoch 323 of 2000 took 0.096s
  training loss:		0.254994
  validation loss:		0.346983
  validation accuracy:		89.24 %
Epoch 324 of 2000 took 0.096s
  training loss:		0.252309
  validation loss:		0.353076
  validation accuracy:		88.80 %
Epoch 325 of 2000 took 0.096s
  training loss:		0.261481
  validation loss:		0.347536
  validation accuracy:		89.57 %
Epoch 326 of 2000 took 0.096s
  training loss:		0.252886
  validation loss:		0.341070
  validation accuracy:		89.24 %
Epoch 327 of 2000 took 0.096s
  training loss:		0.246408
  validation loss:		0.337035
  validation accuracy:		89.67 %
Epoch 328 of 2000 took 0.096s
  training loss:		0.254017
  validation loss:		0.355001
  validation accuracy:		88.91 %
Epoch 329 of 2000 took 0.096s
  training loss:		0.250485
  validation loss:		0.339076
  validation accuracy:		89.67 %
Epoch 330 of 2000 took 0.096s
  training loss:		0.251524
  validation loss:		0.344826
  validation accuracy:		89.35 %
Epoch 331 of 2000 took 0.096s
  training loss:		0.245377
  validation loss:		0.352528
  validation accuracy:		89.24 %
Epoch 332 of 2000 took 0.096s
  training loss:		0.253689
  validation loss:		0.349969
  validation accuracy:		88.80 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.248136
  validation loss:		0.352095
  validation accuracy:		89.24 %
Epoch 334 of 2000 took 0.102s
  training loss:		0.248627
  validation loss:		0.340376
  validation accuracy:		89.67 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.255631
  validation loss:		0.343949
  validation accuracy:		89.46 %
Epoch 336 of 2000 took 0.097s
  training loss:		0.247836
  validation loss:		0.348233
  validation accuracy:		89.24 %
Epoch 337 of 2000 took 0.096s
  training loss:		0.246812
  validation loss:		0.348006
  validation accuracy:		89.13 %
Epoch 338 of 2000 took 0.097s
  training loss:		0.246446
  validation loss:		0.340346
  validation accuracy:		89.13 %
Epoch 339 of 2000 took 0.096s
  training loss:		0.247297
  validation loss:		0.346651
  validation accuracy:		89.13 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.247300
  validation loss:		0.339401
  validation accuracy:		89.35 %
Epoch 341 of 2000 took 0.096s
  training loss:		0.242102
  validation loss:		0.338673
  validation accuracy:		89.67 %
Epoch 342 of 2000 took 0.096s
  training loss:		0.243883
  validation loss:		0.341824
  validation accuracy:		89.24 %
Epoch 343 of 2000 took 0.096s
  training loss:		0.243870
  validation loss:		0.341571
  validation accuracy:		89.78 %
Epoch 344 of 2000 took 0.096s
  training loss:		0.237528
  validation loss:		0.340566
  validation accuracy:		89.57 %
Epoch 345 of 2000 took 0.096s
  training loss:		0.237327
  validation loss:		0.354510
  validation accuracy:		88.70 %
Epoch 346 of 2000 took 0.096s
  training loss:		0.244201
  validation loss:		0.338849
  validation accuracy:		89.46 %
Epoch 347 of 2000 took 0.096s
  training loss:		0.234775
  validation loss:		0.361563
  validation accuracy:		88.59 %
Epoch 348 of 2000 took 0.096s
  training loss:		0.236459
  validation loss:		0.342261
  validation accuracy:		89.67 %
Epoch 349 of 2000 took 0.096s
  training loss:		0.233886
  validation loss:		0.354836
  validation accuracy:		88.80 %
Epoch 350 of 2000 took 0.096s
  training loss:		0.238981
  validation loss:		0.347935
  validation accuracy:		89.57 %
Epoch 351 of 2000 took 0.096s
  training loss:		0.242801
  validation loss:		0.350829
  validation accuracy:		88.80 %
Epoch 352 of 2000 took 0.097s
  training loss:		0.240817
  validation loss:		0.357181
  validation accuracy:		89.02 %
Epoch 353 of 2000 took 0.096s
  training loss:		0.233008
  validation loss:		0.340678
  validation accuracy:		89.78 %
Epoch 354 of 2000 took 0.096s
  training loss:		0.234210
  validation loss:		0.377785
  validation accuracy:		89.35 %
Epoch 355 of 2000 took 0.096s
  training loss:		0.238407
  validation loss:		0.352447
  validation accuracy:		88.91 %
Epoch 356 of 2000 took 0.096s
  training loss:		0.233056
  validation loss:		0.355574
  validation accuracy:		89.02 %
Epoch 357 of 2000 took 0.099s
  training loss:		0.239542
  validation loss:		0.350951
  validation accuracy:		89.13 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.234388
  validation loss:		0.364579
  validation accuracy:		88.70 %
Epoch 359 of 2000 took 0.096s
  training loss:		0.236382
  validation loss:		0.341236
  validation accuracy:		89.57 %
Epoch 360 of 2000 took 0.096s
  training loss:		0.231248
  validation loss:		0.341293
  validation accuracy:		89.57 %
Epoch 361 of 2000 took 0.096s
  training loss:		0.228988
  validation loss:		0.352224
  validation accuracy:		89.13 %
Epoch 362 of 2000 took 0.096s
  training loss:		0.233497
  validation loss:		0.349711
  validation accuracy:		89.24 %
Epoch 363 of 2000 took 0.096s
  training loss:		0.232004
  validation loss:		0.337078
  validation accuracy:		89.46 %
Epoch 364 of 2000 took 0.096s
  training loss:		0.241283
  validation loss:		0.344955
  validation accuracy:		89.57 %
Epoch 365 of 2000 took 0.096s
  training loss:		0.233795
  validation loss:		0.345201
  validation accuracy:		89.24 %
Epoch 366 of 2000 took 0.096s
  training loss:		0.233228
  validation loss:		0.354455
  validation accuracy:		89.02 %
Epoch 367 of 2000 took 0.096s
  training loss:		0.227310
  validation loss:		0.357235
  validation accuracy:		88.70 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.231058
  validation loss:		0.351908
  validation accuracy:		88.91 %
Epoch 369 of 2000 took 0.096s
  training loss:		0.231057
  validation loss:		0.341418
  validation accuracy:		89.35 %
Epoch 370 of 2000 took 0.096s
  training loss:		0.227805
  validation loss:		0.353586
  validation accuracy:		88.91 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.223465
  validation loss:		0.364503
  validation accuracy:		88.70 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.221774
  validation loss:		0.358485
  validation accuracy:		88.59 %
Epoch 373 of 2000 took 0.096s
  training loss:		0.220114
  validation loss:		0.353508
  validation accuracy:		89.02 %
Epoch 374 of 2000 took 0.096s
  training loss:		0.239813
  validation loss:		0.340395
  validation accuracy:		89.24 %
Epoch 375 of 2000 took 0.096s
  training loss:		0.227700
  validation loss:		0.354546
  validation accuracy:		88.70 %
Epoch 376 of 2000 took 0.096s
  training loss:		0.223883
  validation loss:		0.340994
  validation accuracy:		89.35 %
Epoch 377 of 2000 took 0.096s
  training loss:		0.223520
  validation loss:		0.346723
  validation accuracy:		88.91 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.223980
  validation loss:		0.342096
  validation accuracy:		89.46 %
Epoch 379 of 2000 took 0.096s
  training loss:		0.223860
  validation loss:		0.337764
  validation accuracy:		90.00 %
Epoch 380 of 2000 took 0.096s
  training loss:		0.227358
  validation loss:		0.339033
  validation accuracy:		89.78 %
Epoch 381 of 2000 took 0.096s
  training loss:		0.216271
  validation loss:		0.354206
  validation accuracy:		89.24 %
Epoch 382 of 2000 took 0.099s
  training loss:		0.228355
  validation loss:		0.341211
  validation accuracy:		89.46 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.227028
  validation loss:		0.363022
  validation accuracy:		88.48 %
Epoch 384 of 2000 took 0.096s
  training loss:		0.219848
  validation loss:		0.339935
  validation accuracy:		89.57 %
Epoch 385 of 2000 took 0.096s
  training loss:		0.211472
  validation loss:		0.350828
  validation accuracy:		89.35 %
Epoch 386 of 2000 took 0.096s
  training loss:		0.219213
  validation loss:		0.345881
  validation accuracy:		89.13 %
Epoch 387 of 2000 took 0.096s
  training loss:		0.219630
  validation loss:		0.336461
  validation accuracy:		89.35 %
Epoch 388 of 2000 took 0.096s
  training loss:		0.221969
  validation loss:		0.349467
  validation accuracy:		88.91 %
Epoch 389 of 2000 took 0.096s
  training loss:		0.227141
  validation loss:		0.348024
  validation accuracy:		88.91 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.221987
  validation loss:		0.329808
  validation accuracy:		89.57 %
Epoch 391 of 2000 took 0.096s
  training loss:		0.222488
  validation loss:		0.339856
  validation accuracy:		89.35 %
Epoch 392 of 2000 took 0.096s
  training loss:		0.216791
  validation loss:		0.341535
  validation accuracy:		89.46 %
Epoch 393 of 2000 took 0.096s
  training loss:		0.216664
  validation loss:		0.354409
  validation accuracy:		89.35 %
Epoch 394 of 2000 took 0.096s
  training loss:		0.210770
  validation loss:		0.344502
  validation accuracy:		89.46 %
Epoch 395 of 2000 took 0.096s
  training loss:		0.231188
  validation loss:		0.344514
  validation accuracy:		89.57 %
Epoch 396 of 2000 took 0.096s
  training loss:		0.214578
  validation loss:		0.332503
  validation accuracy:		89.78 %
Epoch 397 of 2000 took 0.096s
  training loss:		0.216233
  validation loss:		0.342638
  validation accuracy:		90.11 %
Epoch 398 of 2000 took 0.096s
  training loss:		0.218181
  validation loss:		0.353124
  validation accuracy:		88.91 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.211696
  validation loss:		0.345639
  validation accuracy:		89.46 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.211696
  validation loss:		0.343114
  validation accuracy:		89.13 %
Epoch 401 of 2000 took 0.096s
  training loss:		0.213211
  validation loss:		0.341676
  validation accuracy:		90.00 %
Epoch 402 of 2000 took 0.096s
  training loss:		0.211188
  validation loss:		0.336019
  validation accuracy:		89.57 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.213219
  validation loss:		0.364802
  validation accuracy:		88.80 %
Epoch 404 of 2000 took 0.096s
  training loss:		0.214462
  validation loss:		0.330783
  validation accuracy:		89.46 %
Epoch 405 of 2000 took 0.096s
  training loss:		0.217244
  validation loss:		0.343948
  validation accuracy:		89.02 %
Epoch 406 of 2000 took 0.096s
  training loss:		0.208512
  validation loss:		0.353158
  validation accuracy:		88.59 %
Epoch 407 of 2000 took 0.096s
  training loss:		0.214096
  validation loss:		0.346841
  validation accuracy:		88.91 %
Epoch 408 of 2000 took 0.096s
  training loss:		0.207554
  validation loss:		0.339312
  validation accuracy:		89.24 %
Epoch 409 of 2000 took 0.096s
  training loss:		0.208859
  validation loss:		0.344707
  validation accuracy:		89.13 %
Epoch 410 of 2000 took 0.099s
  training loss:		0.205751
  validation loss:		0.336238
  validation accuracy:		89.57 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.205354
  validation loss:		0.346673
  validation accuracy:		89.13 %
Epoch 412 of 2000 took 0.096s
  training loss:		0.206301
  validation loss:		0.352132
  validation accuracy:		88.48 %
Epoch 413 of 2000 took 0.096s
  training loss:		0.207991
  validation loss:		0.333464
  validation accuracy:		89.78 %
Epoch 414 of 2000 took 0.096s
  training loss:		0.212996
  validation loss:		0.351184
  validation accuracy:		88.91 %
Epoch 415 of 2000 took 0.096s
  training loss:		0.210964
  validation loss:		0.348031
  validation accuracy:		89.35 %
Epoch 416 of 2000 took 0.096s
  training loss:		0.210202
  validation loss:		0.337223
  validation accuracy:		89.35 %
Epoch 417 of 2000 took 0.096s
  training loss:		0.210080
  validation loss:		0.339317
  validation accuracy:		89.57 %
Epoch 418 of 2000 took 0.096s
  training loss:		0.204920
  validation loss:		0.354772
  validation accuracy:		89.13 %
Epoch 419 of 2000 took 0.096s
  training loss:		0.206267
  validation loss:		0.345571
  validation accuracy:		89.24 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.205621
  validation loss:		0.334467
  validation accuracy:		89.35 %
Epoch 421 of 2000 took 0.096s
  training loss:		0.202240
  validation loss:		0.352450
  validation accuracy:		89.02 %
Epoch 422 of 2000 took 0.096s
  training loss:		0.210413
  validation loss:		0.352973
  validation accuracy:		89.46 %
Epoch 423 of 2000 took 0.096s
  training loss:		0.206983
  validation loss:		0.370775
  validation accuracy:		88.59 %
Epoch 424 of 2000 took 0.096s
  training loss:		0.204691
  validation loss:		0.341760
  validation accuracy:		89.67 %
Epoch 425 of 2000 took 0.096s
  training loss:		0.210488
  validation loss:		0.341678
  validation accuracy:		89.35 %
Epoch 426 of 2000 took 0.096s
  training loss:		0.204038
  validation loss:		0.333750
  validation accuracy:		89.67 %
Epoch 427 of 2000 took 0.096s
  training loss:		0.207746
  validation loss:		0.340458
  validation accuracy:		90.22 %
Epoch 428 of 2000 took 0.096s
  training loss:		0.207013
  validation loss:		0.362779
  validation accuracy:		88.70 %
Epoch 429 of 2000 took 0.096s
  training loss:		0.199243
  validation loss:		0.339887
  validation accuracy:		89.46 %
Epoch 430 of 2000 took 0.096s
  training loss:		0.204114
  validation loss:		0.344590
  validation accuracy:		89.35 %
Epoch 431 of 2000 took 0.096s
  training loss:		0.202587
  validation loss:		0.333773
  validation accuracy:		89.67 %
Epoch 432 of 2000 took 0.096s
  training loss:		0.213448
  validation loss:		0.339785
  validation accuracy:		89.78 %
Epoch 433 of 2000 took 0.096s
  training loss:		0.200891
  validation loss:		0.350953
  validation accuracy:		89.02 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.193835
  validation loss:		0.350620
  validation accuracy:		89.35 %
Epoch 435 of 2000 took 0.096s
  training loss:		0.203921
  validation loss:		0.337446
  validation accuracy:		89.67 %
Epoch 436 of 2000 took 0.096s
  training loss:		0.199147
  validation loss:		0.341846
  validation accuracy:		89.35 %
Epoch 437 of 2000 took 0.096s
  training loss:		0.201534
  validation loss:		0.347621
  validation accuracy:		89.02 %
Epoch 438 of 2000 took 0.096s
  training loss:		0.193119
  validation loss:		0.351692
  validation accuracy:		89.02 %
Epoch 439 of 2000 took 0.096s
  training loss:		0.194144
  validation loss:		0.331694
  validation accuracy:		89.78 %
Epoch 440 of 2000 took 0.096s
  training loss:		0.200351
  validation loss:		0.347105
  validation accuracy:		89.67 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.195926
  validation loss:		0.345200
  validation accuracy:		89.24 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.199070
  validation loss:		0.344258
  validation accuracy:		89.67 %
Epoch 443 of 2000 took 0.096s
  training loss:		0.197156
  validation loss:		0.344670
  validation accuracy:		89.24 %
Epoch 444 of 2000 took 0.099s
  training loss:		0.196734
  validation loss:		0.341702
  validation accuracy:		90.11 %
Epoch 445 of 2000 took 0.096s
  training loss:		0.195231
  validation loss:		0.351996
  validation accuracy:		89.24 %
Epoch 446 of 2000 took 0.096s
  training loss:		0.195194
  validation loss:		0.343600
  validation accuracy:		89.35 %
Epoch 447 of 2000 took 0.096s
  training loss:		0.196835
  validation loss:		0.338127
  validation accuracy:		89.67 %
Epoch 448 of 2000 took 0.096s
  training loss:		0.197315
  validation loss:		0.347634
  validation accuracy:		89.35 %
Epoch 449 of 2000 took 0.096s
  training loss:		0.201600
  validation loss:		0.362643
  validation accuracy:		88.91 %
Epoch 450 of 2000 took 0.096s
  training loss:		0.194180
  validation loss:		0.348012
  validation accuracy:		89.67 %
Epoch 451 of 2000 took 0.096s
  training loss:		0.198169
  validation loss:		0.362097
  validation accuracy:		88.80 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.194476
  validation loss:		0.339157
  validation accuracy:		89.67 %
Epoch 453 of 2000 took 0.096s
  training loss:		0.198483
  validation loss:		0.342488
  validation accuracy:		89.89 %
Epoch 454 of 2000 took 0.096s
  training loss:		0.195019
  validation loss:		0.341310
  validation accuracy:		89.78 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.193072
  validation loss:		0.332831
  validation accuracy:		89.78 %
Epoch 456 of 2000 took 0.096s
  training loss:		0.196564
  validation loss:		0.341765
  validation accuracy:		89.46 %
Epoch 457 of 2000 took 0.096s
  training loss:		0.194217
  validation loss:		0.344805
  validation accuracy:		89.57 %
Epoch 458 of 2000 took 0.096s
  training loss:		0.189992
  validation loss:		0.343130
  validation accuracy:		89.57 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.191627
  validation loss:		0.345052
  validation accuracy:		89.78 %
Epoch 460 of 2000 took 0.096s
  training loss:		0.193421
  validation loss:		0.343690
  validation accuracy:		89.78 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.194766
  validation loss:		0.359951
  validation accuracy:		88.59 %
Epoch 462 of 2000 took 0.096s
  training loss:		0.195865
  validation loss:		0.349291
  validation accuracy:		89.24 %
Epoch 463 of 2000 took 0.096s
  training loss:		0.197109
  validation loss:		0.347243
  validation accuracy:		89.78 %
Epoch 464 of 2000 took 0.096s
  training loss:		0.195198
  validation loss:		0.343560
  validation accuracy:		89.67 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.187753
  validation loss:		0.337919
  validation accuracy:		89.67 %
Epoch 466 of 2000 took 0.096s
  training loss:		0.189770
  validation loss:		0.337832
  validation accuracy:		90.11 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.196564
  validation loss:		0.347352
  validation accuracy:		89.78 %
Epoch 468 of 2000 took 0.096s
  training loss:		0.187343
  validation loss:		0.346469
  validation accuracy:		89.89 %
Epoch 469 of 2000 took 0.096s
  training loss:		0.190311
  validation loss:		0.359729
  validation accuracy:		89.13 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.187237
  validation loss:		0.338973
  validation accuracy:		89.78 %
Epoch 471 of 2000 took 0.096s
  training loss:		0.187761
  validation loss:		0.352242
  validation accuracy:		89.46 %
Epoch 472 of 2000 took 0.096s
  training loss:		0.191561
  validation loss:		0.340918
  validation accuracy:		89.57 %
Epoch 473 of 2000 took 0.096s
  training loss:		0.187651
  validation loss:		0.344429
  validation accuracy:		89.46 %
Epoch 474 of 2000 took 0.096s
  training loss:		0.188431
  validation loss:		0.348583
  validation accuracy:		89.78 %
Epoch 475 of 2000 took 0.096s
  training loss:		0.188960
  validation loss:		0.350892
  validation accuracy:		89.35 %
Epoch 476 of 2000 took 0.096s
  training loss:		0.192049
  validation loss:		0.346065
  validation accuracy:		89.78 %
Epoch 477 of 2000 took 0.096s
  training loss:		0.187662
  validation loss:		0.343200
  validation accuracy:		89.67 %
Epoch 478 of 2000 took 0.096s
  training loss:		0.185587
  validation loss:		0.343409
  validation accuracy:		89.78 %
Epoch 479 of 2000 took 0.096s
  training loss:		0.183887
  validation loss:		0.338618
  validation accuracy:		89.57 %
Epoch 480 of 2000 took 0.096s
  training loss:		0.186528
  validation loss:		0.369299
  validation accuracy:		89.13 %
Epoch 481 of 2000 took 0.096s
  training loss:		0.194413
  validation loss:		0.344033
  validation accuracy:		89.78 %
Epoch 482 of 2000 took 0.096s
  training loss:		0.184080
  validation loss:		0.346184
  validation accuracy:		90.00 %
Epoch 483 of 2000 took 0.096s
  training loss:		0.182590
  validation loss:		0.359072
  validation accuracy:		89.67 %
Epoch 484 of 2000 took 0.099s
  training loss:		0.182469
  validation loss:		0.335171
  validation accuracy:		89.67 %
Epoch 485 of 2000 took 0.096s
  training loss:		0.183825
  validation loss:		0.350643
  validation accuracy:		89.89 %
Epoch 486 of 2000 took 0.096s
  training loss:		0.190750
  validation loss:		0.353508
  validation accuracy:		90.11 %
Epoch 487 of 2000 took 0.096s
  training loss:		0.186291
  validation loss:		0.358300
  validation accuracy:		89.46 %
Epoch 488 of 2000 took 0.096s
  training loss:		0.190671
  validation loss:		0.344098
  validation accuracy:		89.89 %
Epoch 489 of 2000 took 0.096s
  training loss:		0.182173
  validation loss:		0.358801
  validation accuracy:		89.67 %
Epoch 490 of 2000 took 0.096s
  training loss:		0.187124
  validation loss:		0.349380
  validation accuracy:		89.35 %
Epoch 491 of 2000 took 0.096s
  training loss:		0.180065
  validation loss:		0.346431
  validation accuracy:		89.78 %
Epoch 492 of 2000 took 0.096s
  training loss:		0.180938
  validation loss:		0.355984
  validation accuracy:		89.35 %
Epoch 493 of 2000 took 0.096s
  training loss:		0.175959
  validation loss:		0.363296
  validation accuracy:		89.02 %
Epoch 494 of 2000 took 0.096s
  training loss:		0.188699
  validation loss:		0.349869
  validation accuracy:		89.24 %
Epoch 495 of 2000 took 0.096s
  training loss:		0.181260
  validation loss:		0.349514
  validation accuracy:		89.35 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.178133
  validation loss:		0.346444
  validation accuracy:		89.46 %
Epoch 497 of 2000 took 0.096s
  training loss:		0.179932
  validation loss:		0.358603
  validation accuracy:		89.89 %
Epoch 498 of 2000 took 0.096s
  training loss:		0.184861
  validation loss:		0.364299
  validation accuracy:		89.57 %
Epoch 499 of 2000 took 0.096s
  training loss:		0.188354
  validation loss:		0.368294
  validation accuracy:		89.02 %
Epoch 500 of 2000 took 0.096s
  training loss:		0.182907
  validation loss:		0.366581
  validation accuracy:		89.89 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.181303
  validation loss:		0.344590
  validation accuracy:		89.67 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.183847
  validation loss:		0.335057
  validation accuracy:		89.67 %
Epoch 503 of 2000 took 0.099s
  training loss:		0.179891
  validation loss:		0.339950
  validation accuracy:		90.00 %
Epoch 504 of 2000 took 0.099s
  training loss:		0.181728
  validation loss:		0.348982
  validation accuracy:		89.57 %
Epoch 505 of 2000 took 0.099s
  training loss:		0.189986
  validation loss:		0.343640
  validation accuracy:		89.89 %
Epoch 506 of 2000 took 0.099s
  training loss:		0.183967
  validation loss:		0.348578
  validation accuracy:		89.67 %
Epoch 507 of 2000 took 0.099s
  training loss:		0.183354
  validation loss:		0.344167
  validation accuracy:		90.11 %
Epoch 508 of 2000 took 0.099s
  training loss:		0.177196
  validation loss:		0.343666
  validation accuracy:		90.11 %
Epoch 509 of 2000 took 0.099s
  training loss:		0.182016
  validation loss:		0.349170
  validation accuracy:		89.57 %
Epoch 510 of 2000 took 0.099s
  training loss:		0.178299
  validation loss:		0.347736
  validation accuracy:		89.67 %
Epoch 511 of 2000 took 0.099s
  training loss:		0.176599
  validation loss:		0.346634
  validation accuracy:		90.11 %
Epoch 512 of 2000 took 0.099s
  training loss:		0.185540
  validation loss:		0.401629
  validation accuracy:		88.48 %
Epoch 513 of 2000 took 0.099s
  training loss:		0.185938
  validation loss:		0.363376
  validation accuracy:		89.46 %
Epoch 514 of 2000 took 0.099s
  training loss:		0.179401
  validation loss:		0.355731
  validation accuracy:		89.35 %
Epoch 515 of 2000 took 0.099s
  training loss:		0.179253
  validation loss:		0.354358
  validation accuracy:		89.89 %
Epoch 516 of 2000 took 0.099s
  training loss:		0.177593
  validation loss:		0.346007
  validation accuracy:		89.67 %
Epoch 517 of 2000 took 0.099s
  training loss:		0.202448
  validation loss:		0.341720
  validation accuracy:		89.89 %
Epoch 518 of 2000 took 0.099s
  training loss:		0.176777
  validation loss:		0.379618
  validation accuracy:		88.70 %
Epoch 519 of 2000 took 0.099s
  training loss:		0.171657
  validation loss:		0.357570
  validation accuracy:		89.46 %
Epoch 520 of 2000 took 0.099s
  training loss:		0.177287
  validation loss:		0.353232
  validation accuracy:		89.35 %
Epoch 521 of 2000 took 0.099s
  training loss:		0.182804
  validation loss:		0.367164
  validation accuracy:		90.33 %
Epoch 522 of 2000 took 0.099s
  training loss:		0.179688
  validation loss:		0.350972
  validation accuracy:		89.24 %
Epoch 523 of 2000 took 0.099s
  training loss:		0.174187
  validation loss:		0.348931
  validation accuracy:		89.78 %
Epoch 524 of 2000 took 0.099s
  training loss:		0.175231
  validation loss:		0.353161
  validation accuracy:		89.57 %
Epoch 525 of 2000 took 0.099s
  training loss:		0.183143
  validation loss:		0.377466
  validation accuracy:		90.11 %
Epoch 526 of 2000 took 0.099s
  training loss:		0.183767
  validation loss:		0.346017
  validation accuracy:		89.35 %
Epoch 527 of 2000 took 0.100s
  training loss:		0.173083
  validation loss:		0.343401
  validation accuracy:		89.89 %
Epoch 528 of 2000 took 0.099s
  training loss:		0.177954
  validation loss:		0.363771
  validation accuracy:		89.24 %
Epoch 529 of 2000 took 0.099s
  training loss:		0.178769
  validation loss:		0.356612
  validation accuracy:		89.24 %
Epoch 530 of 2000 took 0.099s
  training loss:		0.170670
  validation loss:		0.353607
  validation accuracy:		89.78 %
Epoch 531 of 2000 took 0.101s
  training loss:		0.169947
  validation loss:		0.362899
  validation accuracy:		89.46 %
Epoch 532 of 2000 took 0.101s
  training loss:		0.179647
  validation loss:		0.377550
  validation accuracy:		88.91 %
Epoch 533 of 2000 took 0.099s
  training loss:		0.172932
  validation loss:		0.349021
  validation accuracy:		90.22 %
Epoch 534 of 2000 took 0.099s
  training loss:		0.177864
  validation loss:		0.340425
  validation accuracy:		90.22 %
Epoch 535 of 2000 took 0.099s
  training loss:		0.176843
  validation loss:		0.353037
  validation accuracy:		89.89 %
Epoch 536 of 2000 took 0.099s
  training loss:		0.179977
  validation loss:		0.359342
  validation accuracy:		88.91 %
Epoch 537 of 2000 took 0.099s
  training loss:		0.177013
  validation loss:		0.361672
  validation accuracy:		89.89 %
Epoch 538 of 2000 took 0.099s
  training loss:		0.173364
  validation loss:		0.378191
  validation accuracy:		89.24 %
Epoch 539 of 2000 took 0.100s
  training loss:		0.184572
  validation loss:		0.365992
  validation accuracy:		89.67 %
Epoch 540 of 2000 took 0.099s
  training loss:		0.172750
  validation loss:		0.363819
  validation accuracy:		89.02 %
Epoch 541 of 2000 took 0.099s
  training loss:		0.171431
  validation loss:		0.343274
  validation accuracy:		89.78 %
Epoch 542 of 2000 took 0.099s
  training loss:		0.172155
  validation loss:		0.348162
  validation accuracy:		89.89 %
Epoch 543 of 2000 took 0.099s
  training loss:		0.168654
  validation loss:		0.353160
  validation accuracy:		89.78 %
Epoch 544 of 2000 took 0.100s
  training loss:		0.169740
  validation loss:		0.349173
  validation accuracy:		89.67 %
Epoch 545 of 2000 took 0.099s
  training loss:		0.170907
  validation loss:		0.390256
  validation accuracy:		89.13 %
Epoch 546 of 2000 took 0.099s
  training loss:		0.181623
  validation loss:		0.364769
  validation accuracy:		89.46 %
Epoch 547 of 2000 took 0.099s
  training loss:		0.170025
  validation loss:		0.346413
  validation accuracy:		90.54 %
Epoch 548 of 2000 took 0.099s
  training loss:		0.185569
  validation loss:		0.364433
  validation accuracy:		89.35 %
Epoch 549 of 2000 took 0.099s
  training loss:		0.169505
  validation loss:		0.356694
  validation accuracy:		89.13 %
Epoch 550 of 2000 took 0.099s
  training loss:		0.171052
  validation loss:		0.344998
  validation accuracy:		89.67 %
Epoch 551 of 2000 took 0.099s
  training loss:		0.177270
  validation loss:		0.349970
  validation accuracy:		89.46 %
Epoch 552 of 2000 took 0.099s
  training loss:		0.173536
  validation loss:		0.366023
  validation accuracy:		90.22 %
Epoch 553 of 2000 took 0.099s
  training loss:		0.176184
  validation loss:		0.348734
  validation accuracy:		90.11 %
Epoch 554 of 2000 took 0.099s
  training loss:		0.170103
  validation loss:		0.369224
  validation accuracy:		89.02 %
Epoch 555 of 2000 took 0.099s
  training loss:		0.174906
  validation loss:		0.355147
  validation accuracy:		89.57 %
Epoch 556 of 2000 took 0.099s
  training loss:		0.177207
  validation loss:		0.351238
  validation accuracy:		90.11 %
Epoch 557 of 2000 took 0.100s
  training loss:		0.166885
  validation loss:		0.381768
  validation accuracy:		90.22 %
Epoch 558 of 2000 took 0.099s
  training loss:		0.176372
  validation loss:		0.355865
  validation accuracy:		89.35 %
Epoch 559 of 2000 took 0.099s
  training loss:		0.174634
  validation loss:		0.350843
  validation accuracy:		89.67 %
Epoch 560 of 2000 took 0.099s
  training loss:		0.169945
  validation loss:		0.344171
  validation accuracy:		89.78 %
Epoch 561 of 2000 took 0.099s
  training loss:		0.178382
  validation loss:		0.366226
  validation accuracy:		89.78 %
Epoch 562 of 2000 took 0.099s
  training loss:		0.173476
  validation loss:		0.372973
  validation accuracy:		90.00 %
Epoch 563 of 2000 took 0.099s
  training loss:		0.171731
  validation loss:		0.369717
  validation accuracy:		89.24 %
Epoch 564 of 2000 took 0.099s
  training loss:		0.171686
  validation loss:		0.354961
  validation accuracy:		89.57 %
Epoch 565 of 2000 took 0.099s
  training loss:		0.171002
  validation loss:		0.362168
  validation accuracy:		89.78 %
Epoch 566 of 2000 took 0.099s
  training loss:		0.180722
  validation loss:		0.343546
  validation accuracy:		89.89 %
Epoch 567 of 2000 took 0.099s
  training loss:		0.179290
  validation loss:		0.364890
  validation accuracy:		89.35 %
Epoch 568 of 2000 took 0.099s
  training loss:		0.175305
  validation loss:		0.352002
  validation accuracy:		89.67 %
Epoch 569 of 2000 took 0.099s
  training loss:		0.165909
  validation loss:		0.355209
  validation accuracy:		89.78 %
Epoch 570 of 2000 took 0.099s
  training loss:		0.170074
  validation loss:		0.340517
  validation accuracy:		90.00 %
Epoch 571 of 2000 took 0.099s
  training loss:		0.169726
  validation loss:		0.360786
  validation accuracy:		90.00 %
Epoch 572 of 2000 took 0.099s
  training loss:		0.169536
  validation loss:		0.351940
  validation accuracy:		89.78 %
Epoch 573 of 2000 took 0.105s
  training loss:		0.172383
  validation loss:		0.345491
  validation accuracy:		89.67 %
Epoch 574 of 2000 took 0.107s
  training loss:		0.174567
  validation loss:		0.368425
  validation accuracy:		90.00 %
Epoch 575 of 2000 took 0.127s
  training loss:		0.164429
  validation loss:		0.357185
  validation accuracy:		89.78 %
Epoch 576 of 2000 took 0.150s
  training loss:		0.172727
  validation loss:		0.390752
  validation accuracy:		89.78 %
Epoch 577 of 2000 took 0.101s
  training loss:		0.169458
  validation loss:		0.364227
  validation accuracy:		89.67 %
Epoch 578 of 2000 took 0.104s
  training loss:		0.163773
  validation loss:		0.362026
  validation accuracy:		89.67 %
Epoch 579 of 2000 took 0.104s
  training loss:		0.168283
  validation loss:		0.372616
  validation accuracy:		90.11 %
Epoch 580 of 2000 took 0.102s
  training loss:		0.167171
  validation loss:		0.398697
  validation accuracy:		89.67 %
Epoch 581 of 2000 took 0.104s
  training loss:		0.166242
  validation loss:		0.363166
  validation accuracy:		90.00 %
Epoch 582 of 2000 took 0.103s
  training loss:		0.163553
  validation loss:		0.377949
  validation accuracy:		89.78 %
Epoch 583 of 2000 took 0.100s
  training loss:		0.166931
  validation loss:		0.358901
  validation accuracy:		90.11 %
Epoch 584 of 2000 took 0.100s
  training loss:		0.166109
  validation loss:		0.371923
  validation accuracy:		88.80 %
Epoch 585 of 2000 took 0.100s
  training loss:		0.165630
  validation loss:		0.342801
  validation accuracy:		90.22 %
Epoch 586 of 2000 took 0.102s
  training loss:		0.171166
  validation loss:		0.376479
  validation accuracy:		89.24 %
Epoch 587 of 2000 took 0.102s
  training loss:		0.167537
  validation loss:		0.371622
  validation accuracy:		89.24 %
Epoch 588 of 2000 took 0.100s
  training loss:		0.172078
  validation loss:		0.357510
  validation accuracy:		89.89 %
Epoch 589 of 2000 took 0.100s
  training loss:		0.170692
  validation loss:		0.361989
  validation accuracy:		90.00 %
Epoch 590 of 2000 took 0.100s
  training loss:		0.169185
  validation loss:		0.358617
  validation accuracy:		89.57 %
Epoch 591 of 2000 took 0.100s
  training loss:		0.164686
  validation loss:		0.371397
  validation accuracy:		89.67 %
Epoch 592 of 2000 took 0.100s
  training loss:		0.161917
  validation loss:		0.361305
  validation accuracy:		89.24 %
Epoch 593 of 2000 took 0.101s
  training loss:		0.169820
  validation loss:		0.369780
  validation accuracy:		89.67 %
Epoch 594 of 2000 took 0.100s
  training loss:		0.168594
  validation loss:		0.356555
  validation accuracy:		89.57 %
Epoch 595 of 2000 took 0.100s
  training loss:		0.169972
  validation loss:		0.363956
  validation accuracy:		89.46 %
Epoch 596 of 2000 took 0.100s
  training loss:		0.166157
  validation loss:		0.356011
  validation accuracy:		90.00 %
Epoch 597 of 2000 took 0.100s
  training loss:		0.165828
  validation loss:		0.355448
  validation accuracy:		89.89 %
Epoch 598 of 2000 took 0.100s
  training loss:		0.165530
  validation loss:		0.364037
  validation accuracy:		90.11 %
Epoch 599 of 2000 took 0.100s
  training loss:		0.163145
  validation loss:		0.366781
  validation accuracy:		88.80 %
Epoch 600 of 2000 took 0.100s
  training loss:		0.164448
  validation loss:		0.356519
  validation accuracy:		89.35 %
Epoch 601 of 2000 took 0.100s
  training loss:		0.162781
  validation loss:		0.363687
  validation accuracy:		89.46 %
Epoch 602 of 2000 took 0.101s
  training loss:		0.165249
  validation loss:		0.387177
  validation accuracy:		89.13 %
Epoch 603 of 2000 took 0.100s
  training loss:		0.164720
  validation loss:		0.365556
  validation accuracy:		89.46 %
Epoch 604 of 2000 took 0.100s
  training loss:		0.165354
  validation loss:		0.376489
  validation accuracy:		90.00 %
Epoch 605 of 2000 took 0.100s
  training loss:		0.164348
  validation loss:		0.350481
  validation accuracy:		89.35 %
Epoch 606 of 2000 took 0.100s
  training loss:		0.167024
  validation loss:		0.377115
  validation accuracy:		89.57 %
Epoch 607 of 2000 took 0.100s
  training loss:		0.160187
  validation loss:		0.355189
  validation accuracy:		89.57 %
Epoch 608 of 2000 took 0.100s
  training loss:		0.169035
  validation loss:		0.409049
  validation accuracy:		87.50 %
Epoch 609 of 2000 took 0.100s
  training loss:		0.165822
  validation loss:		0.384470
  validation accuracy:		90.00 %
Epoch 610 of 2000 took 0.100s
  training loss:		0.165821
  validation loss:		0.364009
  validation accuracy:		90.11 %
Epoch 611 of 2000 took 0.100s
  training loss:		0.161224
  validation loss:		0.370987
  validation accuracy:		89.67 %
Epoch 612 of 2000 took 0.100s
  training loss:		0.161145
  validation loss:		0.355122
  validation accuracy:		90.00 %
Epoch 613 of 2000 took 0.100s
  training loss:		0.163551
  validation loss:		0.356334
  validation accuracy:		89.89 %
Epoch 614 of 2000 took 0.102s
  training loss:		0.160768
  validation loss:		0.369509
  validation accuracy:		90.11 %
Epoch 615 of 2000 took 0.111s
  training loss:		0.169430
  validation loss:		0.375086
  validation accuracy:		89.78 %
Epoch 616 of 2000 took 0.166s
  training loss:		0.160571
  validation loss:		0.387371
  validation accuracy:		89.46 %
Epoch 617 of 2000 took 0.166s
  training loss:		0.169989
  validation loss:		0.364881
  validation accuracy:		89.89 %
Epoch 618 of 2000 took 0.166s
  training loss:		0.163581
  validation loss:		0.358418
  validation accuracy:		89.89 %
Epoch 619 of 2000 took 0.166s
  training loss:		0.165038
  validation loss:		0.375925
  validation accuracy:		89.89 %
Epoch 620 of 2000 took 0.132s
  training loss:		0.166004
  validation loss:		0.360907
  validation accuracy:		89.78 %
Epoch 621 of 2000 took 0.100s
  training loss:		0.170594
  validation loss:		0.351887
  validation accuracy:		89.67 %
Epoch 622 of 2000 took 0.101s
  training loss:		0.165172
  validation loss:		0.347252
  validation accuracy:		90.33 %
Epoch 623 of 2000 took 0.102s
  training loss:		0.173001
  validation loss:		0.373192
  validation accuracy:		90.33 %
Epoch 624 of 2000 took 0.109s
  training loss:		0.171905
  validation loss:		0.368762
  validation accuracy:		89.57 %
Epoch 625 of 2000 took 0.105s
  training loss:		0.166413
  validation loss:		0.394001
  validation accuracy:		90.00 %
Epoch 626 of 2000 took 0.103s
  training loss:		0.166502
  validation loss:		0.353698
  validation accuracy:		89.89 %
Epoch 627 of 2000 took 0.103s
  training loss:		0.164698
  validation loss:		0.363367
  validation accuracy:		89.57 %
Epoch 628 of 2000 took 0.103s
  training loss:		0.161336
  validation loss:		0.356044
  validation accuracy:		89.67 %
Epoch 629 of 2000 took 0.103s
  training loss:		0.160457
  validation loss:		0.365957
  validation accuracy:		89.24 %
Epoch 630 of 2000 took 0.102s
  training loss:		0.160870
  validation loss:		0.385628
  validation accuracy:		89.13 %
Epoch 631 of 2000 took 0.100s
  training loss:		0.166745
  validation loss:		0.356152
  validation accuracy:		89.67 %
Epoch 632 of 2000 took 0.100s
  training loss:		0.163227
  validation loss:		0.380476
  validation accuracy:		90.11 %
Epoch 633 of 2000 took 0.100s
  training loss:		0.160891
  validation loss:		0.361174
  validation accuracy:		89.57 %
Epoch 634 of 2000 took 0.100s
  training loss:		0.159423
  validation loss:		0.387135
  validation accuracy:		89.46 %
Epoch 635 of 2000 took 0.101s
  training loss:		0.162328
  validation loss:		0.388649
  validation accuracy:		89.89 %
Epoch 636 of 2000 took 0.104s
  training loss:		0.165225
  validation loss:		0.367184
  validation accuracy:		89.67 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.160514
  validation loss:		0.426855
  validation accuracy:		88.48 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.169010
  validation loss:		0.379383
  validation accuracy:		89.35 %
Epoch 639 of 2000 took 0.103s
  training loss:		0.153296
  validation loss:		0.383056
  validation accuracy:		89.13 %
Epoch 640 of 2000 took 0.103s
  training loss:		0.159010
  validation loss:		0.386349
  validation accuracy:		90.00 %
Epoch 641 of 2000 took 0.102s
  training loss:		0.158849
  validation loss:		0.358798
  validation accuracy:		90.43 %
Epoch 642 of 2000 took 0.103s
  training loss:		0.166790
  validation loss:		0.375858
  validation accuracy:		90.11 %
Epoch 643 of 2000 took 0.103s
  training loss:		0.160757
  validation loss:		0.380057
  validation accuracy:		90.22 %
Epoch 644 of 2000 took 0.102s
  training loss:		0.163539
  validation loss:		0.401730
  validation accuracy:		89.46 %
Epoch 645 of 2000 took 0.102s
  training loss:		0.157134
  validation loss:		0.389708
  validation accuracy:		89.35 %
Epoch 646 of 2000 took 0.102s
  training loss:		0.161024
  validation loss:		0.358333
  validation accuracy:		89.78 %
Epoch 647 of 2000 took 0.102s
  training loss:		0.161150
  validation loss:		0.361787
  validation accuracy:		89.89 %
Epoch 648 of 2000 took 0.102s
  training loss:		0.156526
  validation loss:		0.356354
  validation accuracy:		89.89 %
Epoch 649 of 2000 took 0.103s
  training loss:		0.162500
  validation loss:		0.411399
  validation accuracy:		88.80 %
Epoch 650 of 2000 took 0.106s
  training loss:		0.157299
  validation loss:		0.371166
  validation accuracy:		89.78 %
Epoch 651 of 2000 took 0.102s
  training loss:		0.160017
  validation loss:		0.370912
  validation accuracy:		89.57 %
Epoch 652 of 2000 took 0.102s
  training loss:		0.165488
  validation loss:		0.367693
  validation accuracy:		89.57 %
Epoch 653 of 2000 took 0.102s
  training loss:		0.151602
  validation loss:		0.371736
  validation accuracy:		89.35 %
Epoch 654 of 2000 took 0.103s
  training loss:		0.157196
  validation loss:		0.385476
  validation accuracy:		89.02 %
Epoch 655 of 2000 took 0.102s
  training loss:		0.153630
  validation loss:		0.382663
  validation accuracy:		90.11 %
Epoch 656 of 2000 took 0.102s
  training loss:		0.161806
  validation loss:		0.379038
  validation accuracy:		90.43 %
Epoch 657 of 2000 took 0.103s
  training loss:		0.160983
  validation loss:		0.379486
  validation accuracy:		90.43 %
Epoch 658 of 2000 took 0.103s
  training loss:		0.159452
  validation loss:		0.398262
  validation accuracy:		89.02 %
Epoch 659 of 2000 took 0.102s
  training loss:		0.156542
  validation loss:		0.384180
  validation accuracy:		89.13 %
Epoch 660 of 2000 took 0.102s
  training loss:		0.160689
  validation loss:		0.382573
  validation accuracy:		89.67 %
Epoch 661 of 2000 took 0.102s
  training loss:		0.165093
  validation loss:		0.363483
  validation accuracy:		89.89 %
Epoch 662 of 2000 took 0.102s
  training loss:		0.160948
  validation loss:		0.383934
  validation accuracy:		89.24 %
Epoch 663 of 2000 took 0.102s
  training loss:		0.158190
  validation loss:		0.375861
  validation accuracy:		90.54 %
Epoch 664 of 2000 took 0.102s
  training loss:		0.159183
  validation loss:		0.362575
  validation accuracy:		90.00 %
Epoch 665 of 2000 took 0.102s
  training loss:		0.159235
  validation loss:		0.384551
  validation accuracy:		89.24 %
Epoch 666 of 2000 took 0.102s
  training loss:		0.162501
  validation loss:		0.424756
  validation accuracy:		89.46 %
Epoch 667 of 2000 took 0.102s
  training loss:		0.152751
  validation loss:		0.386470
  validation accuracy:		90.00 %
Epoch 668 of 2000 took 0.102s
  training loss:		0.160133
  validation loss:		0.364630
  validation accuracy:		89.57 %
Epoch 669 of 2000 took 0.102s
  training loss:		0.157446
  validation loss:		0.385771
  validation accuracy:		89.67 %
Epoch 670 of 2000 took 0.102s
  training loss:		0.158286
  validation loss:		0.374716
  validation accuracy:		89.24 %
Epoch 671 of 2000 took 0.105s
  training loss:		0.161734
  validation loss:		0.364435
  validation accuracy:		90.11 %
Epoch 672 of 2000 took 0.173s
  training loss:		0.155722
  validation loss:		0.373996
  validation accuracy:		89.35 %
Epoch 673 of 2000 took 0.102s
  training loss:		0.160739
  validation loss:		0.400858
  validation accuracy:		88.80 %
Epoch 674 of 2000 took 0.101s
  training loss:		0.153821
  validation loss:		0.369918
  validation accuracy:		89.67 %
Epoch 675 of 2000 took 0.101s
  training loss:		0.156638
  validation loss:		0.386731
  validation accuracy:		89.35 %
Epoch 676 of 2000 took 0.101s
  training loss:		0.158341
  validation loss:		0.376538
  validation accuracy:		90.22 %
Epoch 677 of 2000 took 0.102s
  training loss:		0.160208
  validation loss:		0.373949
  validation accuracy:		89.57 %
Epoch 678 of 2000 took 0.101s
  training loss:		0.155650
  validation loss:		0.388454
  validation accuracy:		90.00 %
Epoch 679 of 2000 took 0.101s
  training loss:		0.162401
  validation loss:		0.372386
  validation accuracy:		90.22 %
Epoch 680 of 2000 took 0.100s
  training loss:		0.155817
  validation loss:		0.380287
  validation accuracy:		89.67 %
Epoch 681 of 2000 took 0.100s
  training loss:		0.160361
  validation loss:		0.379831
  validation accuracy:		90.00 %
Epoch 682 of 2000 took 0.100s
  training loss:		0.156975
  validation loss:		0.372426
  validation accuracy:		89.67 %
Epoch 683 of 2000 took 0.100s
  training loss:		0.152572
  validation loss:		0.382875
  validation accuracy:		89.78 %
Epoch 684 of 2000 took 0.100s
  training loss:		0.152586
  validation loss:		0.398002
  validation accuracy:		90.11 %
Epoch 685 of 2000 took 0.100s
  training loss:		0.156189
  validation loss:		0.394991
  validation accuracy:		89.57 %
Epoch 686 of 2000 took 0.101s
  training loss:		0.159690
  validation loss:		0.417214
  validation accuracy:		89.67 %
Epoch 687 of 2000 took 0.101s
  training loss:		0.152698
  validation loss:		0.390753
  validation accuracy:		90.22 %
Epoch 688 of 2000 took 0.101s
  training loss:		0.151052
  validation loss:		0.373590
  validation accuracy:		89.67 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.152280
  validation loss:		0.385794
  validation accuracy:		90.22 %
Epoch 690 of 2000 took 0.100s
  training loss:		0.159142
  validation loss:		0.409993
  validation accuracy:		88.37 %
Epoch 691 of 2000 took 0.100s
  training loss:		0.156009
  validation loss:		0.421180
  validation accuracy:		89.67 %
Epoch 692 of 2000 took 0.101s
  training loss:		0.160309
  validation loss:		0.422494
  validation accuracy:		89.13 %
Epoch 693 of 2000 took 0.101s
  training loss:		0.161864
  validation loss:		0.375531
  validation accuracy:		89.78 %
Epoch 694 of 2000 took 0.100s
  training loss:		0.161363
  validation loss:		0.406854
  validation accuracy:		89.24 %
Epoch 695 of 2000 took 0.101s
  training loss:		0.161157
  validation loss:		0.376371
  validation accuracy:		89.67 %
Epoch 696 of 2000 took 0.100s
  training loss:		0.153577
  validation loss:		0.382527
  validation accuracy:		89.57 %
Epoch 697 of 2000 took 0.101s
  training loss:		0.159496
  validation loss:		0.370821
  validation accuracy:		90.11 %
Epoch 698 of 2000 took 0.100s
  training loss:		0.158191
  validation loss:		0.384449
  validation accuracy:		89.78 %
Epoch 699 of 2000 took 0.101s
  training loss:		0.152730
  validation loss:		0.395263
  validation accuracy:		89.02 %
Epoch 700 of 2000 took 0.100s
  training loss:		0.162152
  validation loss:		0.396275
  validation accuracy:		88.91 %
Epoch 701 of 2000 took 0.100s
  training loss:		0.162669
  validation loss:		0.384792
  validation accuracy:		90.00 %
Epoch 702 of 2000 took 0.102s
  training loss:		0.156649
  validation loss:		0.398160
  validation accuracy:		89.35 %
Epoch 703 of 2000 took 0.100s
  training loss:		0.160529
  validation loss:		0.408077
  validation accuracy:		89.02 %
Epoch 704 of 2000 took 0.100s
  training loss:		0.153158
  validation loss:		0.375796
  validation accuracy:		89.78 %
Epoch 705 of 2000 took 0.100s
  training loss:		0.151834
  validation loss:		0.378785
  validation accuracy:		89.46 %
Epoch 706 of 2000 took 0.100s
  training loss:		0.152569
  validation loss:		0.381328
  validation accuracy:		90.22 %
Epoch 707 of 2000 took 0.101s
  training loss:		0.154841
  validation loss:		0.404995
  validation accuracy:		90.11 %
Epoch 708 of 2000 took 0.101s
  training loss:		0.151201
  validation loss:		0.388913
  validation accuracy:		89.13 %
Epoch 709 of 2000 took 0.100s
  training loss:		0.151401
  validation loss:		0.380754
  validation accuracy:		90.33 %
Epoch 710 of 2000 took 0.100s
  training loss:		0.155707
  validation loss:		0.398451
  validation accuracy:		89.78 %
Epoch 711 of 2000 took 0.102s
  training loss:		0.152337
  validation loss:		0.387230
  validation accuracy:		89.78 %
Epoch 712 of 2000 took 0.123s
  training loss:		0.150500
  validation loss:		0.375815
  validation accuracy:		90.87 %
Epoch 713 of 2000 took 0.165s
  training loss:		0.164644
  validation loss:		0.386413
  validation accuracy:		90.11 %
Epoch 714 of 2000 took 0.165s
  training loss:		0.152306
  validation loss:		0.409006
  validation accuracy:		89.57 %
Epoch 715 of 2000 took 0.162s
  training loss:		0.159110
  validation loss:		0.410722
  validation accuracy:		89.57 %
Epoch 716 of 2000 took 0.165s
  training loss:		0.159751
  validation loss:		0.405137
  validation accuracy:		89.46 %
Epoch 717 of 2000 took 0.165s
  training loss:		0.158717
  validation loss:		0.390989
  validation accuracy:		89.02 %
Epoch 718 of 2000 took 0.165s
  training loss:		0.153292
  validation loss:		0.385387
  validation accuracy:		89.24 %
Epoch 719 of 2000 took 0.165s
  training loss:		0.152266
  validation loss:		0.377255
  validation accuracy:		90.22 %
Epoch 720 of 2000 took 0.165s
  training loss:		0.154737
  validation loss:		0.397264
  validation accuracy:		90.00 %
Epoch 721 of 2000 took 0.165s
  training loss:		0.151720
  validation loss:		0.404809
  validation accuracy:		89.89 %
Epoch 722 of 2000 took 0.169s
  training loss:		0.150185
  validation loss:		0.402046
  validation accuracy:		89.24 %
Epoch 723 of 2000 took 0.165s
  training loss:		0.155896
  validation loss:		0.371922
  validation accuracy:		90.87 %
Epoch 724 of 2000 took 0.165s
  training loss:		0.155909
  validation loss:		0.421654
  validation accuracy:		89.24 %
Epoch 725 of 2000 took 0.282s
  training loss:		0.150913
  validation loss:		0.378139
  validation accuracy:		90.11 %
Epoch 726 of 2000 took 0.312s
  training loss:		0.145529
  validation loss:		0.411228
  validation accuracy:		89.57 %
Epoch 727 of 2000 took 0.164s
  training loss:		0.156108
  validation loss:		0.493261
  validation accuracy:		87.17 %
Epoch 728 of 2000 took 0.163s
  training loss:		0.161862
  validation loss:		0.383402
  validation accuracy:		90.00 %
Epoch 729 of 2000 took 0.163s
  training loss:		0.151214
  validation loss:		0.367338
  validation accuracy:		90.11 %
Epoch 730 of 2000 took 0.163s
  training loss:		0.157840
  validation loss:		0.384886
  validation accuracy:		90.54 %
Epoch 731 of 2000 took 0.163s
  training loss:		0.161736
  validation loss:		0.403663
  validation accuracy:		89.24 %
Epoch 732 of 2000 took 0.163s
  training loss:		0.149905
  validation loss:		0.374323
  validation accuracy:		90.43 %
Epoch 733 of 2000 took 0.163s
  training loss:		0.153803
  validation loss:		0.393448
  validation accuracy:		89.57 %
Epoch 734 of 2000 took 0.164s
  training loss:		0.156362
  validation loss:		0.384319
  validation accuracy:		90.00 %
Epoch 735 of 2000 took 0.165s
  training loss:		0.152189
  validation loss:		0.391838
  validation accuracy:		90.00 %
Epoch 736 of 2000 took 0.198s
  training loss:		0.152008
  validation loss:		0.383935
  validation accuracy:		90.00 %
Epoch 737 of 2000 took 0.241s
  training loss:		0.167004
  validation loss:		0.434221
  validation accuracy:		88.91 %
Epoch 738 of 2000 took 0.163s
  training loss:		0.154185
  validation loss:		0.424405
  validation accuracy:		89.35 %
Epoch 739 of 2000 took 0.163s
  training loss:		0.148050
  validation loss:		0.408725
  validation accuracy:		89.89 %
Epoch 740 of 2000 took 0.159s
  training loss:		0.157330
  validation loss:		0.384051
  validation accuracy:		90.11 %
Epoch 741 of 2000 took 0.162s
  training loss:		0.156586
  validation loss:		0.391699
  validation accuracy:		90.33 %
Epoch 742 of 2000 took 0.165s
  training loss:		0.152668
  validation loss:		0.389641
  validation accuracy:		89.24 %
Epoch 743 of 2000 took 0.165s
  training loss:		0.153816
  validation loss:		0.387852
  validation accuracy:		90.22 %
Epoch 744 of 2000 took 0.165s
  training loss:		0.148493
  validation loss:		0.394779
  validation accuracy:		89.46 %
Epoch 745 of 2000 took 0.165s
  training loss:		0.155236
  validation loss:		0.379826
  validation accuracy:		89.57 %
Epoch 746 of 2000 took 0.165s
  training loss:		0.158547
  validation loss:		0.419977
  validation accuracy:		88.91 %
Epoch 747 of 2000 took 0.165s
  training loss:		0.150605
  validation loss:		0.391746
  validation accuracy:		90.11 %
Epoch 748 of 2000 took 0.165s
  training loss:		0.161580
  validation loss:		0.387196
  validation accuracy:		88.91 %
Epoch 749 of 2000 took 0.165s
  training loss:		0.154906
  validation loss:		0.400592
  validation accuracy:		89.78 %
Epoch 750 of 2000 took 0.165s
  training loss:		0.150421
  validation loss:		0.410893
  validation accuracy:		90.11 %
Epoch 751 of 2000 took 0.165s
  training loss:		0.155185
  validation loss:		0.372663
  validation accuracy:		90.11 %
Epoch 752 of 2000 took 0.165s
  training loss:		0.156585
  validation loss:		0.397785
  validation accuracy:		89.02 %
Epoch 753 of 2000 took 0.165s
  training loss:		0.148779
  validation loss:		0.411624
  validation accuracy:		89.67 %
Epoch 754 of 2000 took 0.167s
  training loss:		0.154203
  validation loss:		0.395765
  validation accuracy:		89.13 %
Epoch 755 of 2000 took 0.256s
  training loss:		0.155421
  validation loss:		0.406461
  validation accuracy:		90.11 %
Epoch 756 of 2000 took 0.251s
  training loss:		0.154058
  validation loss:		0.395255
  validation accuracy:		90.00 %
Epoch 757 of 2000 took 0.190s
  training loss:		0.150315
  validation loss:		0.380097
  validation accuracy:		90.00 %
Epoch 758 of 2000 took 0.174s
  training loss:		0.153957
  validation loss:		0.427599
  validation accuracy:		89.13 %
Epoch 759 of 2000 took 0.173s
  training loss:		0.146587
  validation loss:		0.391189
  validation accuracy:		90.22 %
Epoch 760 of 2000 took 0.174s
  training loss:		0.153602
  validation loss:		0.387811
  validation accuracy:		89.57 %
Epoch 761 of 2000 took 0.173s
  training loss:		0.150440
  validation loss:		0.427861
  validation accuracy:		89.02 %
Epoch 762 of 2000 took 0.173s
  training loss:		0.153411
  validation loss:		0.393038
  validation accuracy:		90.00 %
Epoch 763 of 2000 took 0.174s
  training loss:		0.165298
  validation loss:		0.422469
  validation accuracy:		89.35 %
Epoch 764 of 2000 took 0.173s
  training loss:		0.148926
  validation loss:		0.401049
  validation accuracy:		89.35 %
Epoch 765 of 2000 took 0.174s
  training loss:		0.153548
  validation loss:		0.378597
  validation accuracy:		90.65 %
Epoch 766 of 2000 took 0.173s
  training loss:		0.153130
  validation loss:		0.398902
  validation accuracy:		89.78 %
Epoch 767 of 2000 took 0.233s
  training loss:		0.146849
  validation loss:		0.390909
  validation accuracy:		90.33 %
Epoch 768 of 2000 took 0.173s
  training loss:		0.154684
  validation loss:		0.378461
  validation accuracy:		90.11 %
Epoch 769 of 2000 took 0.171s
  training loss:		0.150227
  validation loss:		0.400480
  validation accuracy:		89.78 %
Epoch 770 of 2000 took 0.173s
  training loss:		0.150315
  validation loss:		0.396550
  validation accuracy:		89.67 %
Epoch 771 of 2000 took 0.172s
  training loss:		0.160850
  validation loss:		0.405867
  validation accuracy:		88.37 %
Epoch 772 of 2000 took 0.171s
  training loss:		0.152384
  validation loss:		0.394995
  validation accuracy:		90.33 %
Epoch 773 of 2000 took 0.172s
  training loss:		0.152362
  validation loss:		0.385979
  validation accuracy:		89.35 %
Epoch 774 of 2000 took 0.176s
  training loss:		0.148353
  validation loss:		0.421895
  validation accuracy:		89.57 %
Epoch 775 of 2000 took 0.173s
  training loss:		0.145479
  validation loss:		0.407727
  validation accuracy:		89.02 %
Epoch 776 of 2000 took 0.177s
  training loss:		0.153798
  validation loss:		0.396500
  validation accuracy:		89.46 %
Epoch 777 of 2000 took 0.196s
  training loss:		0.147170
  validation loss:		0.392010
  validation accuracy:		89.57 %
Epoch 778 of 2000 took 0.299s
  training loss:		0.149661
  validation loss:		0.401478
  validation accuracy:		89.89 %
Epoch 779 of 2000 took 0.164s
  training loss:		0.147966
  validation loss:		0.429348
  validation accuracy:		89.02 %
Epoch 780 of 2000 took 0.163s
  training loss:		0.163222
  validation loss:		0.407056
  validation accuracy:		89.89 %
Epoch 781 of 2000 took 0.163s
  training loss:		0.147032
  validation loss:		0.382840
  validation accuracy:		89.89 %
Epoch 782 of 2000 took 0.164s
  training loss:		0.149140
  validation loss:		0.425165
  validation accuracy:		89.89 %
Epoch 783 of 2000 took 0.163s
  training loss:		0.149350
  validation loss:		0.426641
  validation accuracy:		89.13 %
Epoch 784 of 2000 took 0.163s
  training loss:		0.143105
  validation loss:		0.384205
  validation accuracy:		89.67 %
Epoch 785 of 2000 took 0.163s
  training loss:		0.150392
  validation loss:		0.398855
  validation accuracy:		90.22 %
Epoch 786 of 2000 took 0.163s
  training loss:		0.153064
  validation loss:		0.417192
  validation accuracy:		89.35 %
Epoch 787 of 2000 took 0.163s
  training loss:		0.148762
  validation loss:		0.395833
  validation accuracy:		89.67 %
Epoch 788 of 2000 took 0.163s
  training loss:		0.145350
  validation loss:		0.413464
  validation accuracy:		89.46 %
Epoch 789 of 2000 took 0.163s
  training loss:		0.149212
  validation loss:		0.396104
  validation accuracy:		89.35 %
Epoch 790 of 2000 took 0.165s
  training loss:		0.151992
  validation loss:		0.428198
  validation accuracy:		89.57 %
Epoch 791 of 2000 took 0.216s
  training loss:		0.145678
  validation loss:		0.391299
  validation accuracy:		90.11 %
Epoch 792 of 2000 took 0.331s
  training loss:		0.145484
  validation loss:		0.412363
  validation accuracy:		89.57 %
Epoch 793 of 2000 took 0.332s
  training loss:		0.151725
  validation loss:		0.392894
  validation accuracy:		89.89 %
Epoch 794 of 2000 took 0.247s
  training loss:		0.152958
  validation loss:		0.435465
  validation accuracy:		88.91 %
Epoch 795 of 2000 took 0.254s
  training loss:		0.165405
  validation loss:		0.451277
  validation accuracy:		89.02 %
Epoch 796 of 2000 took 0.199s
  training loss:		0.153115
  validation loss:		0.426187
  validation accuracy:		89.67 %
Epoch 797 of 2000 took 0.191s
  training loss:		0.158736
  validation loss:		0.423746
  validation accuracy:		89.35 %
Epoch 798 of 2000 took 0.222s
  training loss:		0.149350
  validation loss:		0.389189
  validation accuracy:		90.00 %
Epoch 799 of 2000 took 0.223s
  training loss:		0.149171
  validation loss:		0.405728
  validation accuracy:		89.57 %
Epoch 800 of 2000 took 0.166s
  training loss:		0.149233
  validation loss:		0.390660
  validation accuracy:		90.22 %
Epoch 801 of 2000 took 0.296s
  training loss:		0.145702
  validation loss:		0.408901
  validation accuracy:		89.67 %
Epoch 802 of 2000 took 0.198s
  training loss:		0.148463
  validation loss:		0.437106
  validation accuracy:		89.78 %
Epoch 803 of 2000 took 0.248s
  training loss:		0.150886
  validation loss:		0.424484
  validation accuracy:		89.13 %
Epoch 804 of 2000 took 0.191s
  training loss:		0.145367
  validation loss:		0.410532
  validation accuracy:		89.24 %
Epoch 805 of 2000 took 0.198s
  training loss:		0.158327
  validation loss:		0.453510
  validation accuracy:		89.02 %
Epoch 806 of 2000 took 0.164s
  training loss:		0.153268
  validation loss:		0.421566
  validation accuracy:		89.57 %
Epoch 807 of 2000 took 0.164s
  training loss:		0.152585
  validation loss:		0.391975
  validation accuracy:		90.00 %
Epoch 808 of 2000 took 0.164s
  training loss:		0.148166
  validation loss:		0.398164
  validation accuracy:		89.46 %
Epoch 809 of 2000 took 0.164s
  training loss:		0.142618
  validation loss:		0.412071
  validation accuracy:		90.22 %
Epoch 810 of 2000 took 0.164s
  training loss:		0.140580
  validation loss:		0.390911
  validation accuracy:		90.22 %
Epoch 811 of 2000 took 0.161s
  training loss:		0.149669
  validation loss:		0.427563
  validation accuracy:		89.46 %
Epoch 812 of 2000 took 0.164s
  training loss:		0.151395
  validation loss:		0.405173
  validation accuracy:		89.57 %
Epoch 813 of 2000 took 0.164s
  training loss:		0.147790
  validation loss:		0.400221
  validation accuracy:		90.00 %
Epoch 814 of 2000 took 0.164s
  training loss:		0.145090
  validation loss:		0.390203
  validation accuracy:		89.89 %
Epoch 815 of 2000 took 0.164s
  training loss:		0.141217
  validation loss:		0.438880
  validation accuracy:		89.13 %
Epoch 816 of 2000 took 0.164s
  training loss:		0.148689
  validation loss:		0.404632
  validation accuracy:		90.33 %
Epoch 817 of 2000 took 0.164s
  training loss:		0.149851
  validation loss:		0.403722
  validation accuracy:		90.00 %
Epoch 818 of 2000 took 0.164s
  training loss:		0.142042
  validation loss:		0.406266
  validation accuracy:		90.11 %
Epoch 819 of 2000 took 0.165s
  training loss:		0.144986
  validation loss:		0.414836
  validation accuracy:		89.89 %
Epoch 820 of 2000 took 0.262s
  training loss:		0.147066
  validation loss:		0.381301
  validation accuracy:		90.33 %
Epoch 821 of 2000 took 0.189s
  training loss:		0.152840
  validation loss:		0.393220
  validation accuracy:		90.43 %
Epoch 822 of 2000 took 0.161s
  training loss:		0.145001
  validation loss:		0.424789
  validation accuracy:		89.67 %
Epoch 823 of 2000 took 0.164s
  training loss:		0.147180
  validation loss:		0.402558
  validation accuracy:		89.89 %
Epoch 824 of 2000 took 0.163s
  training loss:		0.145587
  validation loss:		0.429225
  validation accuracy:		89.24 %
Epoch 825 of 2000 took 0.163s
  training loss:		0.150799
  validation loss:		0.382413
  validation accuracy:		90.54 %
Epoch 826 of 2000 took 0.163s
  training loss:		0.146405
  validation loss:		0.409054
  validation accuracy:		89.24 %
Epoch 827 of 2000 took 0.163s
  training loss:		0.144373
  validation loss:		0.439684
  validation accuracy:		88.80 %
Epoch 828 of 2000 took 0.163s
  training loss:		0.147401
  validation loss:		0.439243
  validation accuracy:		90.00 %
Epoch 829 of 2000 took 0.163s
  training loss:		0.151349
  validation loss:		0.408428
  validation accuracy:		90.33 %
Epoch 830 of 2000 took 0.163s
  training loss:		0.140887
  validation loss:		0.412321
  validation accuracy:		90.00 %
Epoch 831 of 2000 took 0.163s
  training loss:		0.139528
  validation loss:		0.409206
  validation accuracy:		89.67 %
Epoch 832 of 2000 took 0.163s
  training loss:		0.144542
  validation loss:		0.405565
  validation accuracy:		89.02 %
Epoch 833 of 2000 took 0.163s
  training loss:		0.154364
  validation loss:		0.401790
  validation accuracy:		89.57 %
Epoch 834 of 2000 took 0.166s
  training loss:		0.142082
  validation loss:		0.398277
  validation accuracy:		90.11 %
Epoch 835 of 2000 took 0.166s
  training loss:		0.142332
  validation loss:		0.399914
  validation accuracy:		90.43 %
Epoch 836 of 2000 took 0.166s
  training loss:		0.148442
  validation loss:		0.423534
  validation accuracy:		89.78 %
Epoch 837 of 2000 took 0.166s
  training loss:		0.143717
  validation loss:		0.403448
  validation accuracy:		89.35 %
Epoch 838 of 2000 took 0.176s
  training loss:		0.142956
  validation loss:		0.398090
  validation accuracy:		90.43 %
Epoch 839 of 2000 took 0.166s
  training loss:		0.153442
  validation loss:		0.431151
  validation accuracy:		89.78 %
Epoch 840 of 2000 took 0.164s
  training loss:		0.150639
  validation loss:		0.394535
  validation accuracy:		90.43 %
Epoch 841 of 2000 took 0.163s
  training loss:		0.139764
  validation loss:		0.387707
  validation accuracy:		90.22 %
Epoch 842 of 2000 took 0.163s
  training loss:		0.149454
  validation loss:		0.400555
  validation accuracy:		90.22 %
Epoch 843 of 2000 took 0.163s
  training loss:		0.143934
  validation loss:		0.413022
  validation accuracy:		89.35 %
Epoch 844 of 2000 took 0.163s
  training loss:		0.140695
  validation loss:		0.414699
  validation accuracy:		89.89 %
Epoch 845 of 2000 took 0.163s
  training loss:		0.154011
  validation loss:		0.431083
  validation accuracy:		89.24 %
Epoch 846 of 2000 took 0.163s
  training loss:		0.141744
  validation loss:		0.428133
  validation accuracy:		89.02 %
Epoch 847 of 2000 took 0.163s
  training loss:		0.149360
  validation loss:		0.397130
  validation accuracy:		90.76 %
Epoch 848 of 2000 took 0.163s
  training loss:		0.144313
  validation loss:		0.420322
  validation accuracy:		90.00 %
Epoch 849 of 2000 took 0.163s
  training loss:		0.143994
  validation loss:		0.416023
  validation accuracy:		89.57 %
Epoch 850 of 2000 took 0.163s
  training loss:		0.144399
  validation loss:		0.416519
  validation accuracy:		89.89 %
Epoch 851 of 2000 took 0.163s
  training loss:		0.145269
  validation loss:		0.424087
  validation accuracy:		89.78 %
Epoch 852 of 2000 took 0.163s
  training loss:		0.146555
  validation loss:		0.405759
  validation accuracy:		90.22 %
Epoch 853 of 2000 took 0.163s
  training loss:		0.143165
  validation loss:		0.424536
  validation accuracy:		90.00 %
Epoch 854 of 2000 took 0.163s
  training loss:		0.150536
  validation loss:		0.439078
  validation accuracy:		89.35 %
Epoch 855 of 2000 took 0.163s
  training loss:		0.145759
  validation loss:		0.437795
  validation accuracy:		89.13 %
Epoch 856 of 2000 took 0.163s
  training loss:		0.148738
  validation loss:		0.406014
  validation accuracy:		89.78 %
Epoch 857 of 2000 took 0.248s
  training loss:		0.144953
  validation loss:		0.425487
  validation accuracy:		89.78 %
Epoch 858 of 2000 took 0.196s
  training loss:		0.142056
  validation loss:		0.405553
  validation accuracy:		89.67 %
Epoch 859 of 2000 took 0.163s
  training loss:		0.146761
  validation loss:		0.441948
  validation accuracy:		89.78 %
Epoch 860 of 2000 took 0.163s
  training loss:		0.149207
  validation loss:		0.410965
  validation accuracy:		89.46 %
Epoch 861 of 2000 took 0.163s
  training loss:		0.144093
  validation loss:		0.424030
  validation accuracy:		89.24 %
Epoch 862 of 2000 took 0.163s
  training loss:		0.144971
  validation loss:		0.410946
  validation accuracy:		89.24 %
Epoch 863 of 2000 took 0.163s
  training loss:		0.140988
  validation loss:		0.428755
  validation accuracy:		89.57 %
Epoch 864 of 2000 took 0.116s
  training loss:		0.144848
  validation loss:		0.449739
  validation accuracy:		88.80 %
Epoch 865 of 2000 took 0.096s
  training loss:		0.147964
  validation loss:		0.422320
  validation accuracy:		90.00 %
Epoch 866 of 2000 took 0.096s
  training loss:		0.143923
  validation loss:		0.399401
  validation accuracy:		90.54 %
Epoch 867 of 2000 took 0.102s
  training loss:		0.145197
  validation loss:		0.408518
  validation accuracy:		89.67 %
Epoch 868 of 2000 took 0.102s
  training loss:		0.142152
  validation loss:		0.422368
  validation accuracy:		89.13 %
Epoch 869 of 2000 took 0.101s
  training loss:		0.136729
  validation loss:		0.425732
  validation accuracy:		89.35 %
Epoch 870 of 2000 took 0.096s
  training loss:		0.146860
  validation loss:		0.423400
  validation accuracy:		89.46 %
Epoch 871 of 2000 took 0.095s
  training loss:		0.153971
  validation loss:		0.458779
  validation accuracy:		89.35 %
Epoch 872 of 2000 took 0.096s
  training loss:		0.147570
  validation loss:		0.422148
  validation accuracy:		89.24 %
Epoch 873 of 2000 took 0.095s
  training loss:		0.140045
  validation loss:		0.390794
  validation accuracy:		90.43 %
Epoch 874 of 2000 took 0.096s
  training loss:		0.138825
  validation loss:		0.420555
  validation accuracy:		89.46 %
Epoch 875 of 2000 took 0.095s
  training loss:		0.141990
  validation loss:		0.437057
  validation accuracy:		89.57 %
Epoch 876 of 2000 took 0.095s
  training loss:		0.140714
  validation loss:		0.419987
  validation accuracy:		89.67 %
Epoch 877 of 2000 took 0.095s
  training loss:		0.136917
  validation loss:		0.403606
  validation accuracy:		90.11 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.147930
  validation loss:		0.420421
  validation accuracy:		89.35 %
Epoch 879 of 2000 took 0.096s
  training loss:		0.139177
  validation loss:		0.410401
  validation accuracy:		89.89 %
Epoch 880 of 2000 took 0.100s
  training loss:		0.141943
  validation loss:		0.430112
  validation accuracy:		89.24 %
Epoch 881 of 2000 took 0.096s
  training loss:		0.140384
  validation loss:		0.408614
  validation accuracy:		89.89 %
Epoch 882 of 2000 took 0.096s
  training loss:		0.144461
  validation loss:		0.438520
  validation accuracy:		89.24 %
Epoch 883 of 2000 took 0.097s
  training loss:		0.137253
  validation loss:		0.409412
  validation accuracy:		89.78 %
Epoch 884 of 2000 took 0.097s
  training loss:		0.148187
  validation loss:		0.442235
  validation accuracy:		89.78 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.146100
  validation loss:		0.399573
  validation accuracy:		90.22 %
Epoch 886 of 2000 took 0.096s
  training loss:		0.140476
  validation loss:		0.419672
  validation accuracy:		89.89 %
Epoch 887 of 2000 took 0.096s
  training loss:		0.138411
  validation loss:		0.415633
  validation accuracy:		90.00 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.146086
  validation loss:		0.474022
  validation accuracy:		88.48 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.150819
  validation loss:		0.406563
  validation accuracy:		89.78 %
Epoch 890 of 2000 took 0.096s
  training loss:		0.136937
  validation loss:		0.390547
  validation accuracy:		90.54 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.139570
  validation loss:		0.401417
  validation accuracy:		90.33 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.133903
  validation loss:		0.431421
  validation accuracy:		89.89 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.137176
  validation loss:		0.427857
  validation accuracy:		89.46 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.140513
  validation loss:		0.409576
  validation accuracy:		90.22 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.143481
  validation loss:		0.437225
  validation accuracy:		89.57 %
Epoch 896 of 2000 took 0.097s
  training loss:		0.144894
  validation loss:		0.410455
  validation accuracy:		90.11 %
Epoch 897 of 2000 took 0.097s
  training loss:		0.140864
  validation loss:		0.415203
  validation accuracy:		89.46 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.136497
  validation loss:		0.427064
  validation accuracy:		90.00 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.140938
  validation loss:		0.398064
  validation accuracy:		90.65 %
Epoch 900 of 2000 took 0.098s
  training loss:		0.144013
  validation loss:		0.427416
  validation accuracy:		89.78 %
Epoch 901 of 2000 took 0.095s
  training loss:		0.145467
  validation loss:		0.399895
  validation accuracy:		90.43 %
Epoch 902 of 2000 took 0.095s
  training loss:		0.140503
  validation loss:		0.410756
  validation accuracy:		90.33 %
Epoch 903 of 2000 took 0.095s
  training loss:		0.138993
  validation loss:		0.400327
  validation accuracy:		90.22 %
Epoch 904 of 2000 took 0.095s
  training loss:		0.139554
  validation loss:		0.433462
  validation accuracy:		89.46 %
Epoch 905 of 2000 took 0.095s
  training loss:		0.137101
  validation loss:		0.426034
  validation accuracy:		89.57 %
Epoch 906 of 2000 took 0.095s
  training loss:		0.142663
  validation loss:		0.408753
  validation accuracy:		90.11 %
Epoch 907 of 2000 took 0.095s
  training loss:		0.139437
  validation loss:		0.425372
  validation accuracy:		89.46 %
Epoch 908 of 2000 took 0.095s
  training loss:		0.140654
  validation loss:		0.406548
  validation accuracy:		90.33 %
Epoch 909 of 2000 took 0.095s
  training loss:		0.137940
  validation loss:		0.432332
  validation accuracy:		89.02 %
Epoch 910 of 2000 took 0.095s
  training loss:		0.142216
  validation loss:		0.424451
  validation accuracy:		89.78 %
Epoch 911 of 2000 took 0.095s
  training loss:		0.134331
  validation loss:		0.410436
  validation accuracy:		90.22 %
Epoch 912 of 2000 took 0.095s
  training loss:		0.141002
  validation loss:		0.442977
  validation accuracy:		89.35 %
Epoch 913 of 2000 took 0.095s
  training loss:		0.139882
  validation loss:		0.418448
  validation accuracy:		89.57 %
Epoch 914 of 2000 took 0.095s
  training loss:		0.137933
  validation loss:		0.414009
  validation accuracy:		90.00 %
Epoch 915 of 2000 took 0.095s
  training loss:		0.133626
  validation loss:		0.442082
  validation accuracy:		89.67 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.140008
  validation loss:		0.406039
  validation accuracy:		90.33 %
Epoch 917 of 2000 took 0.095s
  training loss:		0.134743
  validation loss:		0.402670
  validation accuracy:		90.54 %
Epoch 918 of 2000 took 0.095s
  training loss:		0.136279
  validation loss:		0.436948
  validation accuracy:		88.80 %
Epoch 919 of 2000 took 0.095s
  training loss:		0.136203
  validation loss:		0.445382
  validation accuracy:		89.02 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.136953
  validation loss:		0.423194
  validation accuracy:		89.67 %
Epoch 921 of 2000 took 0.096s
  training loss:		0.132950
  validation loss:		0.418046
  validation accuracy:		89.89 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.133153
  validation loss:		0.421335
  validation accuracy:		90.22 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.138229
  validation loss:		0.451318
  validation accuracy:		89.57 %
Epoch 924 of 2000 took 0.096s
  training loss:		0.134265
  validation loss:		0.432798
  validation accuracy:		88.70 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.131453
  validation loss:		0.396106
  validation accuracy:		90.76 %
Epoch 926 of 2000 took 0.096s
  training loss:		0.139734
  validation loss:		0.421992
  validation accuracy:		89.67 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.138406
  validation loss:		0.458451
  validation accuracy:		88.91 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.141015
  validation loss:		0.452792
  validation accuracy:		88.59 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.141761
  validation loss:		0.411344
  validation accuracy:		90.33 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.132940
  validation loss:		0.431846
  validation accuracy:		89.89 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.143373
  validation loss:		0.498025
  validation accuracy:		88.48 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.145358
  validation loss:		0.419049
  validation accuracy:		90.22 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.133822
  validation loss:		0.409293
  validation accuracy:		90.11 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.129561
  validation loss:		0.419768
  validation accuracy:		89.24 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.137784
  validation loss:		0.425119
  validation accuracy:		89.57 %
Epoch 936 of 2000 took 0.096s
  training loss:		0.135335
  validation loss:		0.404273
  validation accuracy:		90.54 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.137284
  validation loss:		0.415341
  validation accuracy:		90.00 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.131892
  validation loss:		0.435786
  validation accuracy:		89.13 %
Epoch 939 of 2000 took 0.096s
  training loss:		0.132627
  validation loss:		0.412686
  validation accuracy:		90.54 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.141784
  validation loss:		0.415932
  validation accuracy:		89.78 %
Epoch 941 of 2000 took 0.096s
  training loss:		0.134855
  validation loss:		0.413411
  validation accuracy:		90.00 %
Epoch 942 of 2000 took 0.096s
  training loss:		0.135885
  validation loss:		0.426524
  validation accuracy:		89.67 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.135871
  validation loss:		0.432927
  validation accuracy:		90.11 %
Epoch 944 of 2000 took 0.096s
  training loss:		0.139896
  validation loss:		0.430319
  validation accuracy:		90.11 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.134798
  validation loss:		0.435247
  validation accuracy:		89.67 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.132125
  validation loss:		0.437870
  validation accuracy:		89.78 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.142080
  validation loss:		0.399805
  validation accuracy:		90.43 %
Epoch 948 of 2000 took 0.096s
  training loss:		0.127321
  validation loss:		0.417644
  validation accuracy:		90.11 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.134967
  validation loss:		0.408355
  validation accuracy:		90.22 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.130868
  validation loss:		0.424089
  validation accuracy:		90.11 %
Epoch 951 of 2000 took 0.096s
  training loss:		0.128504
  validation loss:		0.427842
  validation accuracy:		89.78 %
Epoch 952 of 2000 took 0.096s
  training loss:		0.141990
  validation loss:		0.419821
  validation accuracy:		89.78 %
Epoch 953 of 2000 took 0.096s
  training loss:		0.129409
  validation loss:		0.433301
  validation accuracy:		89.89 %
Epoch 954 of 2000 took 0.096s
  training loss:		0.136516
  validation loss:		0.411492
  validation accuracy:		89.89 %
Epoch 955 of 2000 took 0.096s
  training loss:		0.136943
  validation loss:		0.453926
  validation accuracy:		89.67 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.136214
  validation loss:		0.412855
  validation accuracy:		90.00 %
Epoch 957 of 2000 took 0.096s
  training loss:		0.139146
  validation loss:		0.428938
  validation accuracy:		89.57 %
Epoch 958 of 2000 took 0.096s
  training loss:		0.137533
  validation loss:		0.437554
  validation accuracy:		89.13 %
Epoch 959 of 2000 took 0.096s
  training loss:		0.137210
  validation loss:		0.444432
  validation accuracy:		88.91 %
Epoch 960 of 2000 took 0.096s
  training loss:		0.133539
  validation loss:		0.436645
  validation accuracy:		89.67 %
Epoch 961 of 2000 took 0.096s
  training loss:		0.134843
  validation loss:		0.423544
  validation accuracy:		89.78 %
Epoch 962 of 2000 took 0.096s
  training loss:		0.126072
  validation loss:		0.423439
  validation accuracy:		90.22 %
Epoch 963 of 2000 took 0.096s
  training loss:		0.129083
  validation loss:		0.429444
  validation accuracy:		89.89 %
Epoch 964 of 2000 took 0.098s
  training loss:		0.134167
  validation loss:		0.412949
  validation accuracy:		90.22 %
Epoch 965 of 2000 took 0.096s
  training loss:		0.133088
  validation loss:		0.440306
  validation accuracy:		89.24 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.128379
  validation loss:		0.427207
  validation accuracy:		90.00 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.134648
  validation loss:		0.420061
  validation accuracy:		89.89 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.134140
  validation loss:		0.429734
  validation accuracy:		89.67 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.131547
  validation loss:		0.426812
  validation accuracy:		89.78 %
Epoch 970 of 2000 took 0.096s
  training loss:		0.131428
  validation loss:		0.422400
  validation accuracy:		90.11 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.127635
  validation loss:		0.422076
  validation accuracy:		90.54 %
Epoch 972 of 2000 took 0.096s
  training loss:		0.134460
  validation loss:		0.422651
  validation accuracy:		90.11 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.132058
  validation loss:		0.431288
  validation accuracy:		90.11 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.133760
  validation loss:		0.411198
  validation accuracy:		90.22 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.128631
  validation loss:		0.423907
  validation accuracy:		90.00 %
Epoch 976 of 2000 took 0.096s
  training loss:		0.134356
  validation loss:		0.414999
  validation accuracy:		90.11 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.136161
  validation loss:		0.447657
  validation accuracy:		89.13 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.129209
  validation loss:		0.511174
  validation accuracy:		88.04 %
Epoch 979 of 2000 took 0.096s
  training loss:		0.143171
  validation loss:		0.441091
  validation accuracy:		89.24 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.135673
  validation loss:		0.494472
  validation accuracy:		88.59 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.138278
  validation loss:		0.424865
  validation accuracy:		89.67 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.129061
  validation loss:		0.436219
  validation accuracy:		90.00 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.132554
  validation loss:		0.444649
  validation accuracy:		89.13 %
Epoch 984 of 2000 took 0.096s
  training loss:		0.132210
  validation loss:		0.436154
  validation accuracy:		90.11 %
Epoch 985 of 2000 took 0.096s
  training loss:		0.127848
  validation loss:		0.447495
  validation accuracy:		89.24 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.128815
  validation loss:		0.426060
  validation accuracy:		89.78 %
Epoch 987 of 2000 took 0.096s
  training loss:		0.131955
  validation loss:		0.427168
  validation accuracy:		90.00 %
Epoch 988 of 2000 took 0.096s
  training loss:		0.123760
  validation loss:		0.427808
  validation accuracy:		89.78 %
Epoch 989 of 2000 took 0.096s
  training loss:		0.130575
  validation loss:		0.450173
  validation accuracy:		89.78 %
Epoch 990 of 2000 took 0.096s
  training loss:		0.128774
  validation loss:		0.434569
  validation accuracy:		90.22 %
Epoch 991 of 2000 took 0.096s
  training loss:		0.130788
  validation loss:		0.453181
  validation accuracy:		89.57 %
Epoch 992 of 2000 took 0.096s
  training loss:		0.137784
  validation loss:		0.434751
  validation accuracy:		90.11 %
Epoch 993 of 2000 took 0.096s
  training loss:		0.129514
  validation loss:		0.471144
  validation accuracy:		89.02 %
Epoch 994 of 2000 took 0.096s
  training loss:		0.129808
  validation loss:		0.494541
  validation accuracy:		88.37 %
Epoch 995 of 2000 took 0.096s
  training loss:		0.132114
  validation loss:		0.431533
  validation accuracy:		89.78 %
Epoch 996 of 2000 took 0.096s
  training loss:		0.133833
  validation loss:		0.429777
  validation accuracy:		89.67 %
Epoch 997 of 2000 took 0.096s
  training loss:		0.124676
  validation loss:		0.440339
  validation accuracy:		89.89 %
Epoch 998 of 2000 took 0.096s
  training loss:		0.131987
  validation loss:		0.424701
  validation accuracy:		89.57 %
Epoch 999 of 2000 took 0.096s
  training loss:		0.134060
  validation loss:		0.416837
  validation accuracy:		90.76 %
Epoch 1000 of 2000 took 0.096s
  training loss:		0.132929
  validation loss:		0.408898
  validation accuracy:		90.33 %
Epoch 1001 of 2000 took 0.096s
  training loss:		0.128573
  validation loss:		0.435268
  validation accuracy:		89.57 %
Epoch 1002 of 2000 took 0.096s
  training loss:		0.126612
  validation loss:		0.411378
  validation accuracy:		90.65 %
Epoch 1003 of 2000 took 0.096s
  training loss:		0.132503
  validation loss:		0.428518
  validation accuracy:		89.78 %
Epoch 1004 of 2000 took 0.096s
  training loss:		0.120806
  validation loss:		0.414645
  validation accuracy:		90.76 %
Epoch 1005 of 2000 took 0.096s
  training loss:		0.128335
  validation loss:		0.438971
  validation accuracy:		89.78 %
Epoch 1006 of 2000 took 0.096s
  training loss:		0.124934
  validation loss:		0.467506
  validation accuracy:		89.57 %
Epoch 1007 of 2000 took 0.096s
  training loss:		0.130137
  validation loss:		0.443126
  validation accuracy:		89.89 %
Epoch 1008 of 2000 took 0.096s
  training loss:		0.127438
  validation loss:		0.430825
  validation accuracy:		90.00 %
Epoch 1009 of 2000 took 0.096s
  training loss:		0.128822
  validation loss:		0.450620
  validation accuracy:		89.46 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.128733
  validation loss:		0.428067
  validation accuracy:		90.43 %
Epoch 1011 of 2000 took 0.096s
  training loss:		0.127759
  validation loss:		0.426887
  validation accuracy:		90.65 %
Epoch 1012 of 2000 took 0.096s
  training loss:		0.130139
  validation loss:		0.407431
  validation accuracy:		90.65 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.128967
  validation loss:		0.442131
  validation accuracy:		89.67 %
Epoch 1014 of 2000 took 0.096s
  training loss:		0.123297
  validation loss:		0.432056
  validation accuracy:		90.00 %
Epoch 1015 of 2000 took 0.096s
  training loss:		0.126247
  validation loss:		0.423873
  validation accuracy:		90.54 %
Epoch 1016 of 2000 took 0.096s
  training loss:		0.121635
  validation loss:		0.438683
  validation accuracy:		89.46 %
Epoch 1017 of 2000 took 0.096s
  training loss:		0.126382
  validation loss:		0.433372
  validation accuracy:		90.00 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.127034
  validation loss:		0.429996
  validation accuracy:		89.35 %
Epoch 1019 of 2000 took 0.096s
  training loss:		0.132820
  validation loss:		0.451747
  validation accuracy:		89.02 %
Epoch 1020 of 2000 took 0.096s
  training loss:		0.128406
  validation loss:		0.427403
  validation accuracy:		89.78 %
Epoch 1021 of 2000 took 0.096s
  training loss:		0.132020
  validation loss:		0.437033
  validation accuracy:		89.78 %
Epoch 1022 of 2000 took 0.096s
  training loss:		0.125682
  validation loss:		0.410204
  validation accuracy:		91.09 %
Epoch 1023 of 2000 took 0.096s
  training loss:		0.123853
  validation loss:		0.434141
  validation accuracy:		90.33 %
Epoch 1024 of 2000 took 0.096s
  training loss:		0.129945
  validation loss:		0.414025
  validation accuracy:		90.22 %
Epoch 1025 of 2000 took 0.096s
  training loss:		0.127140
  validation loss:		0.425696
  validation accuracy:		90.22 %
Epoch 1026 of 2000 took 0.096s
  training loss:		0.122115
  validation loss:		0.434811
  validation accuracy:		90.00 %
Epoch 1027 of 2000 took 0.096s
  training loss:		0.127774
  validation loss:		0.479210
  validation accuracy:		89.02 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.127754
  validation loss:		0.459880
  validation accuracy:		89.24 %
Epoch 1029 of 2000 took 0.096s
  training loss:		0.129211
  validation loss:		0.437871
  validation accuracy:		89.57 %
Epoch 1030 of 2000 took 0.096s
  training loss:		0.125484
  validation loss:		0.434417
  validation accuracy:		89.35 %
Epoch 1031 of 2000 took 0.096s
  training loss:		0.117864
  validation loss:		0.437789
  validation accuracy:		90.00 %
Epoch 1032 of 2000 took 0.096s
  training loss:		0.127349
  validation loss:		0.426001
  validation accuracy:		90.00 %
Epoch 1033 of 2000 took 0.096s
  training loss:		0.124347
  validation loss:		0.440586
  validation accuracy:		89.78 %
Epoch 1034 of 2000 took 0.096s
  training loss:		0.126974
  validation loss:		0.420732
  validation accuracy:		90.22 %
Epoch 1035 of 2000 took 0.096s
  training loss:		0.123381
  validation loss:		0.454853
  validation accuracy:		89.46 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.127426
  validation loss:		0.430204
  validation accuracy:		89.89 %
Epoch 1037 of 2000 took 0.096s
  training loss:		0.120137
  validation loss:		0.431921
  validation accuracy:		90.00 %
Epoch 1038 of 2000 took 0.096s
  training loss:		0.121854
  validation loss:		0.442295
  validation accuracy:		89.67 %
Epoch 1039 of 2000 took 0.096s
  training loss:		0.118832
  validation loss:		0.435423
  validation accuracy:		90.33 %
Epoch 1040 of 2000 took 0.096s
  training loss:		0.130978
  validation loss:		0.433165
  validation accuracy:		90.11 %
Epoch 1041 of 2000 took 0.097s
  training loss:		0.127876
  validation loss:		0.430491
  validation accuracy:		90.65 %
Epoch 1042 of 2000 took 0.096s
  training loss:		0.122320
  validation loss:		0.407252
  validation accuracy:		90.76 %
Epoch 1043 of 2000 took 0.096s
  training loss:		0.131044
  validation loss:		0.447794
  validation accuracy:		89.57 %
Epoch 1044 of 2000 took 0.096s
  training loss:		0.125507
  validation loss:		0.441919
  validation accuracy:		89.89 %
Epoch 1045 of 2000 took 0.096s
  training loss:		0.128691
  validation loss:		0.416150
  validation accuracy:		90.65 %
Epoch 1046 of 2000 took 0.096s
  training loss:		0.125540
  validation loss:		0.417174
  validation accuracy:		90.43 %
Epoch 1047 of 2000 took 0.096s
  training loss:		0.120418
  validation loss:		0.437348
  validation accuracy:		89.67 %
Epoch 1048 of 2000 took 0.096s
  training loss:		0.120597
  validation loss:		0.423055
  validation accuracy:		90.22 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.122395
  validation loss:		0.441767
  validation accuracy:		90.00 %
Epoch 1050 of 2000 took 0.096s
  training loss:		0.120773
  validation loss:		0.420355
  validation accuracy:		90.54 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.122148
  validation loss:		0.424971
  validation accuracy:		90.22 %
Epoch 1052 of 2000 took 0.096s
  training loss:		0.120281
  validation loss:		0.433540
  validation accuracy:		90.54 %
Epoch 1053 of 2000 took 0.096s
  training loss:		0.131409
  validation loss:		0.435440
  validation accuracy:		90.00 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.122616
  validation loss:		0.433607
  validation accuracy:		90.00 %
Epoch 1055 of 2000 took 0.096s
  training loss:		0.115541
  validation loss:		0.428002
  validation accuracy:		90.22 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.117716
  validation loss:		0.469545
  validation accuracy:		89.67 %
Epoch 1057 of 2000 took 0.096s
  training loss:		0.121610
  validation loss:		0.432740
  validation accuracy:		90.65 %
Epoch 1058 of 2000 took 0.096s
  training loss:		0.123050
  validation loss:		0.437088
  validation accuracy:		90.00 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.120144
  validation loss:		0.414211
  validation accuracy:		90.43 %
Epoch 1060 of 2000 took 0.096s
  training loss:		0.119565
  validation loss:		0.441603
  validation accuracy:		89.89 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.118698
  validation loss:		0.426941
  validation accuracy:		90.22 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.118668
  validation loss:		0.445314
  validation accuracy:		89.57 %
Epoch 1063 of 2000 took 0.096s
  training loss:		0.120556
  validation loss:		0.439182
  validation accuracy:		90.00 %
Epoch 1064 of 2000 took 0.100s
  training loss:		0.123274
  validation loss:		0.434569
  validation accuracy:		90.33 %
Epoch 1065 of 2000 took 0.102s
  training loss:		0.116454
  validation loss:		0.469471
  validation accuracy:		89.24 %
Epoch 1066 of 2000 took 0.103s
  training loss:		0.119399
  validation loss:		0.441500
  validation accuracy:		89.46 %
Epoch 1067 of 2000 took 0.102s
  training loss:		0.125071
  validation loss:		0.445794
  validation accuracy:		89.46 %
Epoch 1068 of 2000 took 0.102s
  training loss:		0.119117
  validation loss:		0.447433
  validation accuracy:		89.78 %
Epoch 1069 of 2000 took 0.102s
  training loss:		0.125970
  validation loss:		0.448374
  validation accuracy:		89.78 %
Epoch 1070 of 2000 took 0.102s
  training loss:		0.119577
  validation loss:		0.437476
  validation accuracy:		90.00 %
Epoch 1071 of 2000 took 0.102s
  training loss:		0.116739
  validation loss:		0.440023
  validation accuracy:		89.89 %
Epoch 1072 of 2000 took 0.103s
  training loss:		0.112064
  validation loss:		0.446970
  validation accuracy:		89.46 %
Epoch 1073 of 2000 took 0.103s
  training loss:		0.116499
  validation loss:		0.441824
  validation accuracy:		90.00 %
Epoch 1074 of 2000 took 0.102s
  training loss:		0.120275
  validation loss:		0.459019
  validation accuracy:		89.57 %
Epoch 1075 of 2000 took 0.102s
  training loss:		0.119745
  validation loss:		0.425975
  validation accuracy:		90.65 %
Epoch 1076 of 2000 took 0.102s
  training loss:		0.126097
  validation loss:		0.434556
  validation accuracy:		90.00 %
Epoch 1077 of 2000 took 0.102s
  training loss:		0.121637
  validation loss:		0.439852
  validation accuracy:		90.00 %
Epoch 1078 of 2000 took 0.102s
  training loss:		0.113016
  validation loss:		0.439820
  validation accuracy:		89.89 %
Epoch 1079 of 2000 took 0.102s
  training loss:		0.121375
  validation loss:		0.440364
  validation accuracy:		89.78 %
Epoch 1080 of 2000 took 0.102s
  training loss:		0.117013
  validation loss:		0.462234
  validation accuracy:		89.89 %
Epoch 1081 of 2000 took 0.102s
  training loss:		0.132301
  validation loss:		0.485961
  validation accuracy:		88.91 %
Epoch 1082 of 2000 took 0.102s
  training loss:		0.119411
  validation loss:		0.453124
  validation accuracy:		89.89 %
Epoch 1083 of 2000 took 0.102s
  training loss:		0.117744
  validation loss:		0.462594
  validation accuracy:		89.13 %
Epoch 1084 of 2000 took 0.102s
  training loss:		0.114686
  validation loss:		0.434129
  validation accuracy:		90.11 %
Epoch 1085 of 2000 took 0.102s
  training loss:		0.120867
  validation loss:		0.426514
  validation accuracy:		90.54 %
Epoch 1086 of 2000 took 0.102s
  training loss:		0.120849
  validation loss:		0.461914
  validation accuracy:		89.46 %
Epoch 1087 of 2000 took 0.102s
  training loss:		0.113991
  validation loss:		0.427202
  validation accuracy:		90.33 %
Epoch 1088 of 2000 took 0.103s
  training loss:		0.120713
  validation loss:		0.450789
  validation accuracy:		89.24 %
Epoch 1089 of 2000 took 0.102s
  training loss:		0.115147
  validation loss:		0.457115
  validation accuracy:		89.35 %
Epoch 1090 of 2000 took 0.102s
  training loss:		0.120125
  validation loss:		0.467178
  validation accuracy:		89.35 %
Epoch 1091 of 2000 took 0.102s
  training loss:		0.120871
  validation loss:		0.457261
  validation accuracy:		89.78 %
Epoch 1092 of 2000 took 0.102s
  training loss:		0.113358
  validation loss:		0.432604
  validation accuracy:		90.43 %
Epoch 1093 of 2000 took 0.102s
  training loss:		0.124364
  validation loss:		0.444880
  validation accuracy:		89.78 %
Epoch 1094 of 2000 took 0.102s
  training loss:		0.121442
  validation loss:		0.431425
  validation accuracy:		90.33 %
Epoch 1095 of 2000 took 0.103s
  training loss:		0.123092
  validation loss:		0.441323
  validation accuracy:		89.67 %
Epoch 1096 of 2000 took 0.102s
  training loss:		0.119400
  validation loss:		0.419604
  validation accuracy:		90.43 %
Epoch 1097 of 2000 took 0.102s
  training loss:		0.114840
  validation loss:		0.447947
  validation accuracy:		90.11 %
Epoch 1098 of 2000 took 0.102s
  training loss:		0.126711
  validation loss:		0.461862
  validation accuracy:		89.35 %
Epoch 1099 of 2000 took 0.103s
  training loss:		0.119924
  validation loss:		0.448103
  validation accuracy:		90.11 %
Epoch 1100 of 2000 took 0.103s
  training loss:		0.123254
  validation loss:		0.450317
  validation accuracy:		89.67 %
Epoch 1101 of 2000 took 0.103s
  training loss:		0.111512
  validation loss:		0.437730
  validation accuracy:		90.87 %
Epoch 1102 of 2000 took 0.102s
  training loss:		0.111764
  validation loss:		0.431769
  validation accuracy:		90.65 %
Epoch 1103 of 2000 took 0.102s
  training loss:		0.114973
  validation loss:		0.445521
  validation accuracy:		89.67 %
Epoch 1104 of 2000 took 0.106s
  training loss:		0.118702
  validation loss:		0.457125
  validation accuracy:		89.57 %
Epoch 1105 of 2000 took 0.154s
  training loss:		0.114352
  validation loss:		0.458681
  validation accuracy:		89.67 %
Epoch 1106 of 2000 took 0.168s
  training loss:		0.119617
  validation loss:		0.500126
  validation accuracy:		89.02 %
Epoch 1107 of 2000 took 0.178s
  training loss:		0.117160
  validation loss:		0.431804
  validation accuracy:		90.33 %
Epoch 1108 of 2000 took 0.179s
  training loss:		0.116274
  validation loss:		0.462549
  validation accuracy:		89.78 %
Epoch 1109 of 2000 took 0.179s
  training loss:		0.115943
  validation loss:		0.436369
  validation accuracy:		90.33 %
Epoch 1110 of 2000 took 0.179s
  training loss:		0.110825
  validation loss:		0.419846
  validation accuracy:		90.65 %
Epoch 1111 of 2000 took 0.178s
  training loss:		0.120822
  validation loss:		0.436000
  validation accuracy:		90.22 %
Epoch 1112 of 2000 took 0.179s
  training loss:		0.112041
  validation loss:		0.455668
  validation accuracy:		89.78 %
Epoch 1113 of 2000 took 0.179s
  training loss:		0.121749
  validation loss:		0.454947
  validation accuracy:		89.89 %
Epoch 1114 of 2000 took 0.179s
  training loss:		0.121240
  validation loss:		0.463504
  validation accuracy:		89.57 %
Epoch 1115 of 2000 took 0.178s
  training loss:		0.113898
  validation loss:		0.430316
  validation accuracy:		90.43 %
Epoch 1116 of 2000 took 0.179s
  training loss:		0.111041
  validation loss:		0.458645
  validation accuracy:		90.22 %
Epoch 1117 of 2000 took 0.179s
  training loss:		0.114724
  validation loss:		0.473596
  validation accuracy:		89.35 %
Epoch 1118 of 2000 took 0.178s
  training loss:		0.116183
  validation loss:		0.467896
  validation accuracy:		89.46 %
Epoch 1119 of 2000 took 0.178s
  training loss:		0.107631
  validation loss:		0.455252
  validation accuracy:		89.89 %
Epoch 1120 of 2000 took 0.179s
  training loss:		0.114298
  validation loss:		0.464467
  validation accuracy:		89.57 %
Epoch 1121 of 2000 took 0.181s
  training loss:		0.114699
  validation loss:		0.435155
  validation accuracy:		90.33 %
Epoch 1122 of 2000 took 0.178s
  training loss:		0.110471
  validation loss:		0.454911
  validation accuracy:		89.67 %
Epoch 1123 of 2000 took 0.179s
  training loss:		0.111850
  validation loss:		0.454833
  validation accuracy:		89.67 %
Epoch 1124 of 2000 took 0.178s
  training loss:		0.109139
  validation loss:		0.438710
  validation accuracy:		90.33 %
Epoch 1125 of 2000 took 0.178s
  training loss:		0.115074
  validation loss:		0.475454
  validation accuracy:		89.13 %
Epoch 1126 of 2000 took 0.159s
  training loss:		0.120464
  validation loss:		0.447098
  validation accuracy:		89.89 %
Epoch 1127 of 2000 took 0.123s
  training loss:		0.111401
  validation loss:		0.446350
  validation accuracy:		90.43 %
Epoch 1128 of 2000 took 0.123s
  training loss:		0.112313
  validation loss:		0.444527
  validation accuracy:		89.78 %
Epoch 1129 of 2000 took 0.123s
  training loss:		0.111811
  validation loss:		0.472301
  validation accuracy:		89.57 %
Epoch 1130 of 2000 took 0.123s
  training loss:		0.112534
  validation loss:		0.459752
  validation accuracy:		90.00 %
Epoch 1131 of 2000 took 0.123s
  training loss:		0.112540
  validation loss:		0.432436
  validation accuracy:		90.87 %
Epoch 1132 of 2000 took 0.123s
  training loss:		0.117115
  validation loss:		0.438577
  validation accuracy:		90.87 %
Epoch 1133 of 2000 took 0.123s
  training loss:		0.113334
  validation loss:		0.501930
  validation accuracy:		88.59 %
Epoch 1134 of 2000 took 0.123s
  training loss:		0.109241
  validation loss:		0.437584
  validation accuracy:		90.11 %
Epoch 1135 of 2000 took 0.123s
  training loss:		0.117884
  validation loss:		0.440519
  validation accuracy:		90.22 %
Epoch 1136 of 2000 took 0.119s
  training loss:		0.124710
  validation loss:		0.433189
  validation accuracy:		90.43 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.108357
  validation loss:		0.478358
  validation accuracy:		89.35 %
Epoch 1138 of 2000 took 0.096s
  training loss:		0.107608
  validation loss:		0.456145
  validation accuracy:		90.00 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.111440
  validation loss:		0.451615
  validation accuracy:		89.89 %
Epoch 1140 of 2000 took 0.096s
  training loss:		0.110837
  validation loss:		0.467508
  validation accuracy:		89.67 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.113286
  validation loss:		0.537483
  validation accuracy:		87.83 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.113488
  validation loss:		0.462937
  validation accuracy:		89.67 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.111185
  validation loss:		0.447463
  validation accuracy:		89.89 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.105764
  validation loss:		0.449426
  validation accuracy:		89.67 %
Epoch 1145 of 2000 took 0.096s
  training loss:		0.111187
  validation loss:		0.437995
  validation accuracy:		90.43 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.108200
  validation loss:		0.464540
  validation accuracy:		89.78 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.106230
  validation loss:		0.452328
  validation accuracy:		89.78 %
Epoch 1148 of 2000 took 0.096s
  training loss:		0.112599
  validation loss:		0.458464
  validation accuracy:		90.22 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.111307
  validation loss:		0.461942
  validation accuracy:		90.11 %
Epoch 1150 of 2000 took 0.096s
  training loss:		0.109772
  validation loss:		0.479402
  validation accuracy:		89.57 %
Epoch 1151 of 2000 took 0.096s
  training loss:		0.110308
  validation loss:		0.446071
  validation accuracy:		90.22 %
Epoch 1152 of 2000 took 0.096s
  training loss:		0.110324
  validation loss:		0.450214
  validation accuracy:		90.22 %
Epoch 1153 of 2000 took 0.096s
  training loss:		0.106770
  validation loss:		0.454141
  validation accuracy:		90.22 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.109201
  validation loss:		0.506693
  validation accuracy:		89.35 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.107900
  validation loss:		0.464538
  validation accuracy:		89.89 %
Epoch 1156 of 2000 took 0.096s
  training loss:		0.108379
  validation loss:		0.462034
  validation accuracy:		90.22 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.104765
  validation loss:		0.462364
  validation accuracy:		90.22 %
Epoch 1158 of 2000 took 0.096s
  training loss:		0.109468
  validation loss:		0.443531
  validation accuracy:		90.76 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.106511
  validation loss:		0.448712
  validation accuracy:		90.43 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.105345
  validation loss:		0.462608
  validation accuracy:		90.00 %
Epoch 1161 of 2000 took 0.096s
  training loss:		0.116943
  validation loss:		0.460505
  validation accuracy:		90.00 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.108608
  validation loss:		0.455806
  validation accuracy:		89.89 %
Epoch 1163 of 2000 took 0.096s
  training loss:		0.107819
  validation loss:		0.494545
  validation accuracy:		89.02 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.108158
  validation loss:		0.455593
  validation accuracy:		90.43 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.107994
  validation loss:		0.469919
  validation accuracy:		90.00 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.107844
  validation loss:		0.475486
  validation accuracy:		89.67 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.105225
  validation loss:		0.471582
  validation accuracy:		89.13 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.104903
  validation loss:		0.465287
  validation accuracy:		90.22 %
Epoch 1169 of 2000 took 0.096s
  training loss:		0.108043
  validation loss:		0.455442
  validation accuracy:		90.11 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.102636
  validation loss:		0.489215
  validation accuracy:		89.35 %
Epoch 1171 of 2000 took 0.096s
  training loss:		0.111402
  validation loss:		0.463399
  validation accuracy:		90.11 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.107322
  validation loss:		0.524075
  validation accuracy:		88.80 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.105764
  validation loss:		0.469975
  validation accuracy:		90.22 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.106803
  validation loss:		0.468622
  validation accuracy:		89.24 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.104432
  validation loss:		0.482934
  validation accuracy:		89.24 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.110168
  validation loss:		0.470283
  validation accuracy:		89.57 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.104173
  validation loss:		0.478955
  validation accuracy:		89.57 %
Epoch 1178 of 2000 took 0.096s
  training loss:		0.104702
  validation loss:		0.489147
  validation accuracy:		89.24 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.109910
  validation loss:		0.483626
  validation accuracy:		89.78 %
Epoch 1180 of 2000 took 0.096s
  training loss:		0.114763
  validation loss:		0.447824
  validation accuracy:		90.98 %
Epoch 1181 of 2000 took 0.096s
  training loss:		0.107186
  validation loss:		0.475838
  validation accuracy:		90.22 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.104623
  validation loss:		0.508302
  validation accuracy:		88.91 %
Epoch 1183 of 2000 took 0.096s
  training loss:		0.104499
  validation loss:		0.462107
  validation accuracy:		89.57 %
Epoch 1184 of 2000 took 0.096s
  training loss:		0.106780
  validation loss:		0.456761
  validation accuracy:		90.00 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.103723
  validation loss:		0.465730
  validation accuracy:		90.00 %
Epoch 1186 of 2000 took 0.096s
  training loss:		0.100847
  validation loss:		0.495547
  validation accuracy:		89.02 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.105035
  validation loss:		0.476747
  validation accuracy:		90.22 %
Epoch 1188 of 2000 took 0.096s
  training loss:		0.102382
  validation loss:		0.501260
  validation accuracy:		89.35 %
Epoch 1189 of 2000 took 0.096s
  training loss:		0.100269
  validation loss:		0.508889
  validation accuracy:		88.70 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.104412
  validation loss:		0.509793
  validation accuracy:		89.02 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.111768
  validation loss:		0.482761
  validation accuracy:		89.67 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.102302
  validation loss:		0.513037
  validation accuracy:		88.91 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.106957
  validation loss:		0.476919
  validation accuracy:		90.11 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.101072
  validation loss:		0.521688
  validation accuracy:		89.35 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.102807
  validation loss:		0.459815
  validation accuracy:		90.43 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.102501
  validation loss:		0.494416
  validation accuracy:		89.78 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.107344
  validation loss:		0.453821
  validation accuracy:		90.33 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.108345
  validation loss:		0.502675
  validation accuracy:		88.80 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.099406
  validation loss:		0.467780
  validation accuracy:		89.57 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.111294
  validation loss:		0.497126
  validation accuracy:		89.78 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.102851
  validation loss:		0.490677
  validation accuracy:		89.35 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.112934
  validation loss:		0.467254
  validation accuracy:		89.67 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.099886
  validation loss:		0.504152
  validation accuracy:		89.35 %
Epoch 1204 of 2000 took 0.096s
  training loss:		0.105621
  validation loss:		0.505921
  validation accuracy:		88.80 %
Epoch 1205 of 2000 took 0.097s
  training loss:		0.102804
  validation loss:		0.502663
  validation accuracy:		89.24 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.102401
  validation loss:		0.472242
  validation accuracy:		90.00 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.104184
  validation loss:		0.519296
  validation accuracy:		88.59 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.101332
  validation loss:		0.474580
  validation accuracy:		90.22 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.103033
  validation loss:		0.464617
  validation accuracy:		90.65 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.105356
  validation loss:		0.498394
  validation accuracy:		89.24 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.106736
  validation loss:		0.483105
  validation accuracy:		89.78 %
Epoch 1212 of 2000 took 0.096s
  training loss:		0.100643
  validation loss:		0.481860
  validation accuracy:		89.78 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.103509
  validation loss:		0.505550
  validation accuracy:		89.35 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.100499
  validation loss:		0.488559
  validation accuracy:		89.24 %
Epoch 1215 of 2000 took 0.096s
  training loss:		0.103220
  validation loss:		0.487469
  validation accuracy:		89.67 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.110533
  validation loss:		0.495208
  validation accuracy:		90.33 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.098859
  validation loss:		0.491068
  validation accuracy:		89.46 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.103135
  validation loss:		0.469149
  validation accuracy:		89.89 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.098301
  validation loss:		0.487795
  validation accuracy:		90.00 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.099943
  validation loss:		0.485600
  validation accuracy:		90.00 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.103312
  validation loss:		0.475559
  validation accuracy:		90.00 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.102743
  validation loss:		0.500911
  validation accuracy:		89.02 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.098270
  validation loss:		0.479056
  validation accuracy:		89.89 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.102081
  validation loss:		0.485233
  validation accuracy:		89.35 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.096191
  validation loss:		0.487350
  validation accuracy:		89.57 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.103092
  validation loss:		0.496576
  validation accuracy:		89.57 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.099191
  validation loss:		0.467027
  validation accuracy:		90.11 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.110875
  validation loss:		0.491282
  validation accuracy:		89.57 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.104154
  validation loss:		0.553861
  validation accuracy:		88.59 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.100834
  validation loss:		0.521147
  validation accuracy:		89.67 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.102161
  validation loss:		0.529028
  validation accuracy:		88.70 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.101415
  validation loss:		0.478721
  validation accuracy:		90.65 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.097850
  validation loss:		0.497449
  validation accuracy:		89.89 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.106492
  validation loss:		0.520494
  validation accuracy:		89.78 %
Epoch 1235 of 2000 took 0.096s
  training loss:		0.100371
  validation loss:		0.492061
  validation accuracy:		90.65 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.100982
  validation loss:		0.468972
  validation accuracy:		90.54 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.099325
  validation loss:		0.508876
  validation accuracy:		89.24 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.097495
  validation loss:		0.484741
  validation accuracy:		90.00 %
Epoch 1239 of 2000 took 0.096s
  training loss:		0.104509
  validation loss:		0.496286
  validation accuracy:		89.57 %
Epoch 1240 of 2000 took 0.096s
  training loss:		0.100577
  validation loss:		0.443867
  validation accuracy:		90.87 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.104137
  validation loss:		0.489976
  validation accuracy:		90.11 %
Epoch 1242 of 2000 took 0.096s
  training loss:		0.096236
  validation loss:		0.478674
  validation accuracy:		90.11 %
Epoch 1243 of 2000 took 0.096s
  training loss:		0.098939
  validation loss:		0.499835
  validation accuracy:		90.11 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.103540
  validation loss:		0.536656
  validation accuracy:		89.13 %
Epoch 1245 of 2000 took 0.096s
  training loss:		0.098981
  validation loss:		0.467937
  validation accuracy:		89.89 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.097307
  validation loss:		0.486216
  validation accuracy:		89.89 %
Epoch 1247 of 2000 took 0.096s
  training loss:		0.102082
  validation loss:		0.509007
  validation accuracy:		89.57 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.104197
  validation loss:		0.544155
  validation accuracy:		89.57 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.101388
  validation loss:		0.478718
  validation accuracy:		90.00 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.096322
  validation loss:		0.525437
  validation accuracy:		89.24 %
Epoch 1251 of 2000 took 0.096s
  training loss:		0.101397
  validation loss:		0.462773
  validation accuracy:		90.98 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.105248
  validation loss:		0.511957
  validation accuracy:		89.67 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.100554
  validation loss:		0.477436
  validation accuracy:		90.65 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.095718
  validation loss:		0.495078
  validation accuracy:		89.89 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.101491
  validation loss:		0.510646
  validation accuracy:		89.57 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.108192
  validation loss:		0.487312
  validation accuracy:		90.00 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.091348
  validation loss:		0.525249
  validation accuracy:		88.91 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.095862
  validation loss:		0.530373
  validation accuracy:		89.57 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.096410
  validation loss:		0.477545
  validation accuracy:		90.11 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.097928
  validation loss:		0.476624
  validation accuracy:		90.33 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.096950
  validation loss:		0.543620
  validation accuracy:		89.02 %
Epoch 1262 of 2000 took 0.096s
  training loss:		0.110385
  validation loss:		0.507154
  validation accuracy:		89.46 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.094456
  validation loss:		0.510747
  validation accuracy:		89.89 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.096126
  validation loss:		0.506137
  validation accuracy:		89.89 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.097379
  validation loss:		0.506486
  validation accuracy:		89.57 %
Epoch 1266 of 2000 took 0.096s
  training loss:		0.090513
  validation loss:		0.485795
  validation accuracy:		89.78 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.098235
  validation loss:		0.517480
  validation accuracy:		89.46 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.095952
  validation loss:		0.489156
  validation accuracy:		90.00 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.094822
  validation loss:		0.570411
  validation accuracy:		89.13 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.099515
  validation loss:		0.516081
  validation accuracy:		89.46 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.094875
  validation loss:		0.499783
  validation accuracy:		90.33 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.106505
  validation loss:		0.492204
  validation accuracy:		90.11 %
Epoch 1273 of 2000 took 0.096s
  training loss:		0.096911
  validation loss:		0.567069
  validation accuracy:		89.24 %
Epoch 1274 of 2000 took 0.096s
  training loss:		0.093239
  validation loss:		0.522819
  validation accuracy:		89.57 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.097438
  validation loss:		0.481414
  validation accuracy:		90.65 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.103040
  validation loss:		0.491659
  validation accuracy:		90.43 %
Epoch 1277 of 2000 took 0.096s
  training loss:		0.092753
  validation loss:		0.505594
  validation accuracy:		89.46 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.099337
  validation loss:		0.510092
  validation accuracy:		89.57 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.091764
  validation loss:		0.517456
  validation accuracy:		89.57 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.096556
  validation loss:		0.506344
  validation accuracy:		89.78 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.098844
  validation loss:		0.508514
  validation accuracy:		89.46 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.095756
  validation loss:		0.488932
  validation accuracy:		90.11 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.091461
  validation loss:		0.498226
  validation accuracy:		90.00 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.093216
  validation loss:		0.482056
  validation accuracy:		90.65 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.097517
  validation loss:		0.474310
  validation accuracy:		90.22 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.093180
  validation loss:		0.559278
  validation accuracy:		88.59 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.097772
  validation loss:		0.526227
  validation accuracy:		89.57 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.098465
  validation loss:		0.556233
  validation accuracy:		89.35 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.093363
  validation loss:		0.506028
  validation accuracy:		90.54 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.102983
  validation loss:		0.515529
  validation accuracy:		89.78 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.093279
  validation loss:		0.497730
  validation accuracy:		90.43 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.099985
  validation loss:		0.533986
  validation accuracy:		89.02 %
Epoch 1293 of 2000 took 0.096s
  training loss:		0.094510
  validation loss:		0.516332
  validation accuracy:		89.78 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.090798
  validation loss:		0.496328
  validation accuracy:		89.57 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.097130
  validation loss:		0.566255
  validation accuracy:		89.67 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.094719
  validation loss:		0.506625
  validation accuracy:		90.33 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.090289
  validation loss:		0.562403
  validation accuracy:		88.91 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.100035
  validation loss:		0.538309
  validation accuracy:		89.67 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.099119
  validation loss:		0.532888
  validation accuracy:		88.70 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.093730
  validation loss:		0.519360
  validation accuracy:		90.11 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.088349
  validation loss:		0.506688
  validation accuracy:		90.11 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.094190
  validation loss:		0.534679
  validation accuracy:		89.35 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.098011
  validation loss:		0.539317
  validation accuracy:		89.13 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.092065
  validation loss:		0.523614
  validation accuracy:		90.00 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.091857
  validation loss:		0.528555
  validation accuracy:		89.46 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.095855
  validation loss:		0.506822
  validation accuracy:		90.43 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.087444
  validation loss:		0.505008
  validation accuracy:		90.43 %
Epoch 1308 of 2000 took 0.096s
  training loss:		0.089175
  validation loss:		0.500599
  validation accuracy:		89.78 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.090403
  validation loss:		0.541557
  validation accuracy:		89.35 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.112684
  validation loss:		0.588043
  validation accuracy:		87.83 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.088758
  validation loss:		0.495997
  validation accuracy:		90.11 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.092288
  validation loss:		0.493852
  validation accuracy:		90.43 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.093786
  validation loss:		0.531095
  validation accuracy:		89.35 %
Epoch 1314 of 2000 took 0.098s
  training loss:		0.089222
  validation loss:		0.535117
  validation accuracy:		89.67 %
Epoch 1315 of 2000 took 0.099s
  training loss:		0.098493
  validation loss:		0.503063
  validation accuracy:		90.33 %
Epoch 1316 of 2000 took 0.099s
  training loss:		0.088103
  validation loss:		0.542970
  validation accuracy:		89.46 %
Epoch 1317 of 2000 took 0.099s
  training loss:		0.087697
  validation loss:		0.559758
  validation accuracy:		89.02 %
Epoch 1318 of 2000 took 0.099s
  training loss:		0.090591
  validation loss:		0.577706
  validation accuracy:		88.91 %
Epoch 1319 of 2000 took 0.099s
  training loss:		0.091190
  validation loss:		0.518204
  validation accuracy:		89.57 %
Epoch 1320 of 2000 took 0.099s
  training loss:		0.095118
  validation loss:		0.539223
  validation accuracy:		89.67 %
Epoch 1321 of 2000 took 0.099s
  training loss:		0.090050
  validation loss:		0.518563
  validation accuracy:		90.00 %
Epoch 1322 of 2000 took 0.100s
  training loss:		0.091154
  validation loss:		0.510703
  validation accuracy:		89.78 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.088089
  validation loss:		0.525488
  validation accuracy:		90.00 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.099926
  validation loss:		0.507177
  validation accuracy:		90.76 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.085500
  validation loss:		0.539057
  validation accuracy:		89.57 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.086525
  validation loss:		0.546477
  validation accuracy:		89.67 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.085777
  validation loss:		0.549222
  validation accuracy:		89.46 %
Epoch 1328 of 2000 took 0.096s
  training loss:		0.104951
  validation loss:		0.531441
  validation accuracy:		89.78 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.084035
  validation loss:		0.503620
  validation accuracy:		90.43 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.093243
  validation loss:		0.526842
  validation accuracy:		90.00 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.088423
  validation loss:		0.522397
  validation accuracy:		89.57 %
Epoch 1332 of 2000 took 0.099s
  training loss:		0.086816
  validation loss:		0.530072
  validation accuracy:		90.11 %
Epoch 1333 of 2000 took 0.099s
  training loss:		0.083125
  validation loss:		0.533939
  validation accuracy:		89.67 %
Epoch 1334 of 2000 took 0.099s
  training loss:		0.082739
  validation loss:		0.545726
  validation accuracy:		89.35 %
Epoch 1335 of 2000 took 0.099s
  training loss:		0.091922
  validation loss:		0.539274
  validation accuracy:		89.57 %
Epoch 1336 of 2000 took 0.099s
  training loss:		0.091066
  validation loss:		0.511527
  validation accuracy:		90.00 %
Epoch 1337 of 2000 took 0.099s
  training loss:		0.082815
  validation loss:		0.520315
  validation accuracy:		89.67 %
Epoch 1338 of 2000 took 0.099s
  training loss:		0.087797
  validation loss:		0.532401
  validation accuracy:		89.35 %
Epoch 1339 of 2000 took 0.099s
  training loss:		0.093042
  validation loss:		0.560130
  validation accuracy:		89.46 %
Epoch 1340 of 2000 took 0.099s
  training loss:		0.094617
  validation loss:		0.511848
  validation accuracy:		90.54 %
Epoch 1341 of 2000 took 0.099s
  training loss:		0.087312
  validation loss:		0.526872
  validation accuracy:		89.78 %
Epoch 1342 of 2000 took 0.099s
  training loss:		0.088587
  validation loss:		0.525326
  validation accuracy:		90.33 %
Epoch 1343 of 2000 took 0.099s
  training loss:		0.086430
  validation loss:		0.511670
  validation accuracy:		90.54 %
Epoch 1344 of 2000 took 0.099s
  training loss:		0.088453
  validation loss:		0.577529
  validation accuracy:		88.80 %
Epoch 1345 of 2000 took 0.099s
  training loss:		0.093311
  validation loss:		0.562961
  validation accuracy:		89.24 %
Epoch 1346 of 2000 took 0.099s
  training loss:		0.079878
  validation loss:		0.509318
  validation accuracy:		90.11 %
Epoch 1347 of 2000 took 0.099s
  training loss:		0.090778
  validation loss:		0.523437
  validation accuracy:		90.00 %
Epoch 1348 of 2000 took 0.099s
  training loss:		0.091111
  validation loss:		0.548473
  validation accuracy:		89.89 %
Epoch 1349 of 2000 took 0.099s
  training loss:		0.090390
  validation loss:		0.586426
  validation accuracy:		89.46 %
Epoch 1350 of 2000 took 0.099s
  training loss:		0.093185
  validation loss:		0.539854
  validation accuracy:		90.00 %
Epoch 1351 of 2000 took 0.099s
  training loss:		0.085319
  validation loss:		0.553624
  validation accuracy:		90.00 %
Epoch 1352 of 2000 took 0.099s
  training loss:		0.089614
  validation loss:		0.518360
  validation accuracy:		90.33 %
Epoch 1353 of 2000 took 0.099s
  training loss:		0.091479
  validation loss:		0.545559
  validation accuracy:		89.67 %
Epoch 1354 of 2000 took 0.099s
  training loss:		0.089127
  validation loss:		0.517759
  validation accuracy:		90.33 %
Epoch 1355 of 2000 took 0.099s
  training loss:		0.083449
  validation loss:		0.533784
  validation accuracy:		90.54 %
Epoch 1356 of 2000 took 0.099s
  training loss:		0.088681
  validation loss:		0.572938
  validation accuracy:		89.46 %
Epoch 1357 of 2000 took 0.099s
  training loss:		0.095481
  validation loss:		0.551927
  validation accuracy:		89.35 %
Epoch 1358 of 2000 took 0.099s
  training loss:		0.091460
  validation loss:		0.526260
  validation accuracy:		90.22 %
Epoch 1359 of 2000 took 0.099s
  training loss:		0.087891
  validation loss:		0.544607
  validation accuracy:		89.57 %
Epoch 1360 of 2000 took 0.099s
  training loss:		0.094588
  validation loss:		0.523047
  validation accuracy:		90.22 %
Epoch 1361 of 2000 took 0.100s
  training loss:		0.085863
  validation loss:		0.550058
  validation accuracy:		89.78 %
Epoch 1362 of 2000 took 0.099s
  training loss:		0.088168
  validation loss:		0.540251
  validation accuracy:		89.67 %
Epoch 1363 of 2000 took 0.099s
  training loss:		0.080084
  validation loss:		0.544223
  validation accuracy:		89.89 %
Epoch 1364 of 2000 took 0.099s
  training loss:		0.085047
  validation loss:		0.523967
  validation accuracy:		90.54 %
Epoch 1365 of 2000 took 0.099s
  training loss:		0.082794
  validation loss:		0.556983
  validation accuracy:		89.67 %
Epoch 1366 of 2000 took 0.099s
  training loss:		0.093201
  validation loss:		0.546262
  validation accuracy:		89.89 %
Epoch 1367 of 2000 took 0.099s
  training loss:		0.081766
  validation loss:		0.561878
  validation accuracy:		90.00 %
Epoch 1368 of 2000 took 0.099s
  training loss:		0.089644
  validation loss:		0.530677
  validation accuracy:		90.22 %
Epoch 1369 of 2000 took 0.099s
  training loss:		0.080436
  validation loss:		0.594575
  validation accuracy:		88.80 %
Epoch 1370 of 2000 took 0.099s
  training loss:		0.083935
  validation loss:		0.537869
  validation accuracy:		90.43 %
Epoch 1371 of 2000 took 0.099s
  training loss:		0.084679
  validation loss:		0.538173
  validation accuracy:		90.00 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.088036
  validation loss:		0.591647
  validation accuracy:		88.80 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.081822
  validation loss:		0.549842
  validation accuracy:		90.00 %
Epoch 1374 of 2000 took 0.096s
  training loss:		0.086035
  validation loss:		0.532269
  validation accuracy:		90.54 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.085546
  validation loss:		0.544794
  validation accuracy:		90.33 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.086728
  validation loss:		0.528325
  validation accuracy:		90.65 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.087226
  validation loss:		0.585925
  validation accuracy:		88.80 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.088650
  validation loss:		0.525422
  validation accuracy:		90.65 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.085794
  validation loss:		0.571467
  validation accuracy:		89.46 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.079080
  validation loss:		0.524547
  validation accuracy:		90.00 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.105839
  validation loss:		0.559592
  validation accuracy:		89.78 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.091774
  validation loss:		0.574464
  validation accuracy:		89.67 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.085048
  validation loss:		0.562147
  validation accuracy:		89.89 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.090399
  validation loss:		0.532547
  validation accuracy:		90.43 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.083167
  validation loss:		0.554939
  validation accuracy:		89.57 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.082133
  validation loss:		0.551386
  validation accuracy:		90.00 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.095084
  validation loss:		0.514460
  validation accuracy:		90.98 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.081984
  validation loss:		0.551005
  validation accuracy:		89.13 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.083942
  validation loss:		0.556305
  validation accuracy:		89.57 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.081310
  validation loss:		0.551284
  validation accuracy:		90.00 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.078098
  validation loss:		0.572221
  validation accuracy:		89.46 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.079586
  validation loss:		0.546129
  validation accuracy:		89.67 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.079570
  validation loss:		0.559260
  validation accuracy:		89.89 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.082506
  validation loss:		0.543986
  validation accuracy:		90.76 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.089382
  validation loss:		0.568670
  validation accuracy:		89.57 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.094299
  validation loss:		0.595794
  validation accuracy:		89.35 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.082458
  validation loss:		0.553511
  validation accuracy:		89.67 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.081998
  validation loss:		0.571542
  validation accuracy:		90.00 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.093437
  validation loss:		0.564604
  validation accuracy:		89.67 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.080362
  validation loss:		0.544575
  validation accuracy:		90.43 %
Epoch 1401 of 2000 took 0.096s
  training loss:		0.082003
  validation loss:		0.574232
  validation accuracy:		89.46 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.078311
  validation loss:		0.560242
  validation accuracy:		91.20 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.077896
  validation loss:		0.561872
  validation accuracy:		90.33 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.083240
  validation loss:		0.556404
  validation accuracy:		90.54 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.084116
  validation loss:		0.590307
  validation accuracy:		89.24 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.083317
  validation loss:		0.613465
  validation accuracy:		89.13 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.084427
  validation loss:		0.591526
  validation accuracy:		89.78 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.097583
  validation loss:		0.536727
  validation accuracy:		89.13 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.081242
  validation loss:		0.589055
  validation accuracy:		89.89 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.081098
  validation loss:		0.566888
  validation accuracy:		90.00 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.085825
  validation loss:		0.553494
  validation accuracy:		90.22 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.082691
  validation loss:		0.550894
  validation accuracy:		89.67 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.090518
  validation loss:		0.614056
  validation accuracy:		89.67 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.085971
  validation loss:		0.572467
  validation accuracy:		90.00 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.078969
  validation loss:		0.563030
  validation accuracy:		89.46 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.076978
  validation loss:		0.593682
  validation accuracy:		89.35 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.083040
  validation loss:		0.577748
  validation accuracy:		90.00 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.080305
  validation loss:		0.623727
  validation accuracy:		89.13 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.088753
  validation loss:		0.625826
  validation accuracy:		88.59 %
Epoch 1420 of 2000 took 0.096s
  training loss:		0.075768
  validation loss:		0.604704
  validation accuracy:		89.67 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.085580
  validation loss:		0.574599
  validation accuracy:		89.46 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.083730
  validation loss:		0.559276
  validation accuracy:		90.22 %
Epoch 1423 of 2000 took 0.097s
  training loss:		0.076308
  validation loss:		0.578670
  validation accuracy:		89.67 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.078188
  validation loss:		0.554340
  validation accuracy:		90.87 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.080843
  validation loss:		0.576673
  validation accuracy:		89.57 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.080292
  validation loss:		0.599933
  validation accuracy:		89.24 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.087466
  validation loss:		0.619666
  validation accuracy:		89.24 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.078199
  validation loss:		0.558788
  validation accuracy:		89.89 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.080624
  validation loss:		0.590272
  validation accuracy:		89.78 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.077082
  validation loss:		0.627712
  validation accuracy:		88.70 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.080415
  validation loss:		0.621486
  validation accuracy:		89.13 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.077808
  validation loss:		0.575743
  validation accuracy:		89.67 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.085435
  validation loss:		0.582922
  validation accuracy:		89.78 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.082732
  validation loss:		0.575353
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.083829
  validation loss:		0.562124
  validation accuracy:		89.89 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.078246
  validation loss:		0.574559
  validation accuracy:		89.13 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.083629
  validation loss:		0.595354
  validation accuracy:		89.46 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.076294
  validation loss:		0.589571
  validation accuracy:		89.89 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.102136
  validation loss:		0.572163
  validation accuracy:		90.43 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.082775
  validation loss:		0.617209
  validation accuracy:		89.24 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.075562
  validation loss:		0.581398
  validation accuracy:		90.33 %
Epoch 1442 of 2000 took 0.096s
  training loss:		0.075417
  validation loss:		0.625872
  validation accuracy:		89.46 %
Epoch 1443 of 2000 took 0.096s
  training loss:		0.082149
  validation loss:		0.559909
  validation accuracy:		90.76 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.079190
  validation loss:		0.586458
  validation accuracy:		90.11 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.089781
  validation loss:		0.570872
  validation accuracy:		89.67 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.073738
  validation loss:		0.598386
  validation accuracy:		90.33 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.076049
  validation loss:		0.590220
  validation accuracy:		89.89 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.077723
  validation loss:		0.667001
  validation accuracy:		87.83 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.074831
  validation loss:		0.592836
  validation accuracy:		90.00 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.077093
  validation loss:		0.599390
  validation accuracy:		89.57 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.074906
  validation loss:		0.581804
  validation accuracy:		89.46 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.082960
  validation loss:		0.614674
  validation accuracy:		89.67 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.080770
  validation loss:		0.616475
  validation accuracy:		88.48 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.242021
  validation loss:		0.595963
  validation accuracy:		89.89 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.078405
  validation loss:		0.537054
  validation accuracy:		90.22 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.086667
  validation loss:		0.572980
  validation accuracy:		89.78 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.076576
  validation loss:		0.570893
  validation accuracy:		89.89 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.076676
  validation loss:		0.580985
  validation accuracy:		90.22 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.075569
  validation loss:		0.601756
  validation accuracy:		88.80 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.078850
  validation loss:		0.660047
  validation accuracy:		88.26 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.081395
  validation loss:		0.576798
  validation accuracy:		90.43 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.078169
  validation loss:		0.592572
  validation accuracy:		90.33 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.074080
  validation loss:		0.572307
  validation accuracy:		90.22 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.078157
  validation loss:		0.592067
  validation accuracy:		89.78 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.076269
  validation loss:		0.566381
  validation accuracy:		90.22 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.076178
  validation loss:		0.560432
  validation accuracy:		90.11 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.071123
  validation loss:		0.618390
  validation accuracy:		90.22 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.077698
  validation loss:		0.597264
  validation accuracy:		89.02 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.079547
  validation loss:		0.604716
  validation accuracy:		89.57 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.077803
  validation loss:		0.616461
  validation accuracy:		90.22 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.087147
  validation loss:		0.673115
  validation accuracy:		89.24 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.089505
  validation loss:		0.592939
  validation accuracy:		90.22 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.074928
  validation loss:		0.612809
  validation accuracy:		89.35 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.080548
  validation loss:		0.592826
  validation accuracy:		90.11 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.070610
  validation loss:		0.620710
  validation accuracy:		89.89 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.079886
  validation loss:		0.619828
  validation accuracy:		89.57 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.068411
  validation loss:		0.589838
  validation accuracy:		90.33 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.073397
  validation loss:		0.590446
  validation accuracy:		90.43 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.067066
  validation loss:		0.613452
  validation accuracy:		90.11 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.071495
  validation loss:		0.610729
  validation accuracy:		89.78 %
Epoch 1481 of 2000 took 0.096s
  training loss:		0.072952
  validation loss:		0.626601
  validation accuracy:		89.35 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.073683
  validation loss:		0.655648
  validation accuracy:		88.80 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.080065
  validation loss:		0.598396
  validation accuracy:		90.65 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.073284
  validation loss:		0.596665
  validation accuracy:		90.43 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.077026
  validation loss:		0.641379
  validation accuracy:		89.24 %
Epoch 1486 of 2000 took 0.097s
  training loss:		0.089847
  validation loss:		0.585066
  validation accuracy:		90.87 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.074667
  validation loss:		0.594624
  validation accuracy:		89.67 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.076709
  validation loss:		0.680059
  validation accuracy:		88.37 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.076936
  validation loss:		0.571759
  validation accuracy:		90.98 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.090172
  validation loss:		0.597225
  validation accuracy:		90.33 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.072774
  validation loss:		0.624102
  validation accuracy:		89.24 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.073834
  validation loss:		0.605186
  validation accuracy:		89.89 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.070912
  validation loss:		0.630489
  validation accuracy:		89.35 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.069306
  validation loss:		0.610728
  validation accuracy:		90.33 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.073668
  validation loss:		0.609238
  validation accuracy:		90.00 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.071619
  validation loss:		0.609068
  validation accuracy:		90.22 %
Epoch 1497 of 2000 took 0.096s
  training loss:		0.069324
  validation loss:		0.606479
  validation accuracy:		90.11 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.078294
  validation loss:		0.676635
  validation accuracy:		88.70 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.078492
  validation loss:		0.657729
  validation accuracy:		89.13 %
Epoch 1500 of 2000 took 0.096s
  training loss:		0.082190
  validation loss:		0.642949
  validation accuracy:		89.35 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.070798
  validation loss:		0.626861
  validation accuracy:		89.13 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.077931
  validation loss:		0.685960
  validation accuracy:		88.91 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.077713
  validation loss:		0.624027
  validation accuracy:		89.24 %
Epoch 1504 of 2000 took 0.096s
  training loss:		0.069370
  validation loss:		0.646320
  validation accuracy:		89.57 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.070223
  validation loss:		0.670490
  validation accuracy:		88.91 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.079766
  validation loss:		0.697106
  validation accuracy:		88.59 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.074345
  validation loss:		0.639883
  validation accuracy:		90.11 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.074446
  validation loss:		0.653443
  validation accuracy:		89.02 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.073031
  validation loss:		0.602321
  validation accuracy:		90.33 %
Epoch 1510 of 2000 took 0.096s
  training loss:		0.080544
  validation loss:		0.613980
  validation accuracy:		89.89 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.072080
  validation loss:		0.629025
  validation accuracy:		89.67 %
Epoch 1512 of 2000 took 0.096s
  training loss:		0.072911
  validation loss:		0.620557
  validation accuracy:		89.78 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.072667
  validation loss:		0.635512
  validation accuracy:		89.57 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.070072
  validation loss:		0.660722
  validation accuracy:		89.24 %
Epoch 1515 of 2000 took 0.096s
  training loss:		0.100021
  validation loss:		0.605336
  validation accuracy:		90.65 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.069928
  validation loss:		0.631507
  validation accuracy:		89.78 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.077983
  validation loss:		0.619720
  validation accuracy:		90.65 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.067622
  validation loss:		0.641171
  validation accuracy:		90.11 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.073723
  validation loss:		0.609509
  validation accuracy:		89.89 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.068379
  validation loss:		0.655951
  validation accuracy:		89.78 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.073930
  validation loss:		0.659666
  validation accuracy:		89.46 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.072490
  validation loss:		0.638730
  validation accuracy:		90.22 %
Epoch 1523 of 2000 took 0.096s
  training loss:		0.073943
  validation loss:		0.645528
  validation accuracy:		89.35 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.067887
  validation loss:		0.656694
  validation accuracy:		89.13 %
Epoch 1525 of 2000 took 0.096s
  training loss:		0.068807
  validation loss:		0.625421
  validation accuracy:		90.43 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.079309
  validation loss:		0.602857
  validation accuracy:		90.76 %
Epoch 1527 of 2000 took 0.096s
  training loss:		0.068704
  validation loss:		0.632337
  validation accuracy:		89.67 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.067258
  validation loss:		0.639428
  validation accuracy:		90.00 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.088495
  validation loss:		0.660421
  validation accuracy:		89.35 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.070738
  validation loss:		0.651226
  validation accuracy:		90.33 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.081496
  validation loss:		0.621277
  validation accuracy:		90.33 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.069180
  validation loss:		0.622761
  validation accuracy:		90.54 %
Epoch 1533 of 2000 took 0.096s
  training loss:		0.072969
  validation loss:		0.626729
  validation accuracy:		89.67 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.066343
  validation loss:		0.635036
  validation accuracy:		90.00 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.063270
  validation loss:		0.668075
  validation accuracy:		89.35 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.071407
  validation loss:		0.654050
  validation accuracy:		89.78 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.064999
  validation loss:		0.635438
  validation accuracy:		90.11 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.073141
  validation loss:		0.671578
  validation accuracy:		89.24 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.066141
  validation loss:		0.645918
  validation accuracy:		90.22 %
Epoch 1540 of 2000 took 0.096s
  training loss:		0.072825
  validation loss:		0.669629
  validation accuracy:		89.78 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.077554
  validation loss:		0.682924
  validation accuracy:		88.80 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.069106
  validation loss:		0.644437
  validation accuracy:		90.00 %
Epoch 1543 of 2000 took 0.096s
  training loss:		0.076356
  validation loss:		0.662188
  validation accuracy:		90.00 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.068430
  validation loss:		0.661336
  validation accuracy:		90.00 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.062593
  validation loss:		0.662779
  validation accuracy:		89.24 %
Epoch 1546 of 2000 took 0.096s
  training loss:		0.065759
  validation loss:		0.647304
  validation accuracy:		89.78 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.072103
  validation loss:		0.657293
  validation accuracy:		89.57 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.062611
  validation loss:		0.621876
  validation accuracy:		90.33 %
Epoch 1549 of 2000 took 0.097s
  training loss:		0.063660
  validation loss:		0.646050
  validation accuracy:		89.46 %
Epoch 1550 of 2000 took 0.098s
  training loss:		0.069425
  validation loss:		0.653245
  validation accuracy:		90.22 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.063626
  validation loss:		0.644805
  validation accuracy:		89.89 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.069884
  validation loss:		0.736268
  validation accuracy:		89.35 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.105853
  validation loss:		0.649348
  validation accuracy:		90.22 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.062881
  validation loss:		0.680801
  validation accuracy:		89.67 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.075579
  validation loss:		0.649634
  validation accuracy:		89.46 %
Epoch 1556 of 2000 took 0.096s
  training loss:		0.071650
  validation loss:		0.633849
  validation accuracy:		90.22 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.070070
  validation loss:		0.629641
  validation accuracy:		90.65 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.087469
  validation loss:		0.720728
  validation accuracy:		88.91 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.069444
  validation loss:		0.627106
  validation accuracy:		90.54 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.070897
  validation loss:		0.655948
  validation accuracy:		89.78 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.069746
  validation loss:		0.649144
  validation accuracy:		90.43 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.067676
  validation loss:		0.667217
  validation accuracy:		89.46 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.070283
  validation loss:		0.723421
  validation accuracy:		88.70 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.073463
  validation loss:		0.650605
  validation accuracy:		90.22 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.071647
  validation loss:		0.644869
  validation accuracy:		90.33 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.063183
  validation loss:		0.651994
  validation accuracy:		89.89 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.065328
  validation loss:		0.650978
  validation accuracy:		90.22 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.072307
  validation loss:		0.659336
  validation accuracy:		89.78 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.074874
  validation loss:		0.705339
  validation accuracy:		89.13 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.068212
  validation loss:		0.675755
  validation accuracy:		90.33 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.072307
  validation loss:		0.703846
  validation accuracy:		89.78 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.072427
  validation loss:		0.671909
  validation accuracy:		89.78 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.068808
  validation loss:		0.630007
  validation accuracy:		90.87 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.062192
  validation loss:		0.651572
  validation accuracy:		90.43 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.062398
  validation loss:		0.637834
  validation accuracy:		90.00 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.070247
  validation loss:		0.675025
  validation accuracy:		89.57 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.066385
  validation loss:		0.728350
  validation accuracy:		88.48 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.064798
  validation loss:		0.681895
  validation accuracy:		90.00 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.063290
  validation loss:		0.666720
  validation accuracy:		89.57 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.065190
  validation loss:		0.647449
  validation accuracy:		90.11 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.067305
  validation loss:		0.712499
  validation accuracy:		89.35 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.071516
  validation loss:		0.686690
  validation accuracy:		89.89 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.066411
  validation loss:		0.700405
  validation accuracy:		89.57 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.070789
  validation loss:		0.750662
  validation accuracy:		88.37 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.064191
  validation loss:		0.721254
  validation accuracy:		89.13 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.070947
  validation loss:		0.677798
  validation accuracy:		90.43 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.065715
  validation loss:		0.672925
  validation accuracy:		90.65 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.074872
  validation loss:		0.697689
  validation accuracy:		89.57 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.072297
  validation loss:		0.859365
  validation accuracy:		87.17 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.071867
  validation loss:		0.693770
  validation accuracy:		89.46 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.065058
  validation loss:		0.714125
  validation accuracy:		88.91 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.064789
  validation loss:		0.693237
  validation accuracy:		90.43 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.061920
  validation loss:		0.684301
  validation accuracy:		89.78 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.063179
  validation loss:		0.695222
  validation accuracy:		89.57 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.072052
  validation loss:		0.663351
  validation accuracy:		90.22 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.067913
  validation loss:		0.689538
  validation accuracy:		90.43 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.064793
  validation loss:		0.730130
  validation accuracy:		89.13 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.059502
  validation loss:		0.779001
  validation accuracy:		88.04 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.065957
  validation loss:		0.674136
  validation accuracy:		90.11 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.067555
  validation loss:		0.675061
  validation accuracy:		89.89 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.061922
  validation loss:		0.681601
  validation accuracy:		90.54 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.346656
  validation loss:		0.879053
  validation accuracy:		89.78 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.250251
  validation loss:		0.658738
  validation accuracy:		89.78 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.066253
  validation loss:		0.612019
  validation accuracy:		90.43 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.065215
  validation loss:		0.667086
  validation accuracy:		89.89 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.064028
  validation loss:		0.657740
  validation accuracy:		89.89 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.068283
  validation loss:		0.638200
  validation accuracy:		89.89 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.074869
  validation loss:		0.635496
  validation accuracy:		90.43 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.072119
  validation loss:		0.683944
  validation accuracy:		90.00 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.073870
  validation loss:		0.662883
  validation accuracy:		90.22 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.062676
  validation loss:		0.660688
  validation accuracy:		90.11 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.063953
  validation loss:		0.645473
  validation accuracy:		90.11 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.104890
  validation loss:		0.662505
  validation accuracy:		90.43 %
Epoch 1614 of 2000 took 0.096s
  training loss:		0.063899
  validation loss:		0.673257
  validation accuracy:		90.33 %
Epoch 1615 of 2000 took 0.096s
  training loss:		0.072378
  validation loss:		0.683454
  validation accuracy:		90.00 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.061184
  validation loss:		0.714288
  validation accuracy:		88.70 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.061319
  validation loss:		0.656745
  validation accuracy:		91.20 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.062552
  validation loss:		0.642796
  validation accuracy:		90.76 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.068203
  validation loss:		0.708993
  validation accuracy:		89.67 %
Epoch 1620 of 2000 took 0.096s
  training loss:		0.079038
  validation loss:		0.657793
  validation accuracy:		89.78 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.066651
  validation loss:		0.641360
  validation accuracy:		90.65 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.062443
  validation loss:		0.710167
  validation accuracy:		89.35 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.060987
  validation loss:		0.662547
  validation accuracy:		90.22 %
Epoch 1624 of 2000 took 0.096s
  training loss:		0.061556
  validation loss:		0.694450
  validation accuracy:		89.78 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.069538
  validation loss:		0.738715
  validation accuracy:		88.48 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.070005
  validation loss:		0.677820
  validation accuracy:		89.78 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.070076
  validation loss:		0.699703
  validation accuracy:		89.02 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.063765
  validation loss:		0.689499
  validation accuracy:		89.02 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.063211
  validation loss:		0.686534
  validation accuracy:		89.67 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.066425
  validation loss:		0.721190
  validation accuracy:		89.13 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.058511
  validation loss:		0.694531
  validation accuracy:		89.89 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.057059
  validation loss:		0.671651
  validation accuracy:		90.11 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.060657
  validation loss:		0.685953
  validation accuracy:		90.00 %
Epoch 1634 of 2000 took 0.096s
  training loss:		0.061983
  validation loss:		0.753958
  validation accuracy:		89.02 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.064965
  validation loss:		0.686194
  validation accuracy:		89.78 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.064126
  validation loss:		0.696518
  validation accuracy:		89.13 %
Epoch 1637 of 2000 took 0.096s
  training loss:		0.059314
  validation loss:		0.686614
  validation accuracy:		90.22 %
Epoch 1638 of 2000 took 0.096s
  training loss:		0.064773
  validation loss:		0.693131
  validation accuracy:		89.35 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.062364
  validation loss:		0.711274
  validation accuracy:		89.67 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.062446
  validation loss:		0.696502
  validation accuracy:		90.00 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.062596
  validation loss:		0.712589
  validation accuracy:		89.78 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.063457
  validation loss:		0.733867
  validation accuracy:		88.26 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.065622
  validation loss:		0.699745
  validation accuracy:		90.00 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.068662
  validation loss:		0.709136
  validation accuracy:		89.35 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.058617
  validation loss:		0.691736
  validation accuracy:		90.11 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.062054
  validation loss:		0.686214
  validation accuracy:		90.33 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.068259
  validation loss:		0.688895
  validation accuracy:		90.00 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.059819
  validation loss:		0.755380
  validation accuracy:		88.91 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.072081
  validation loss:		0.713205
  validation accuracy:		90.00 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.059929
  validation loss:		0.733376
  validation accuracy:		89.46 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.076967
  validation loss:		0.712407
  validation accuracy:		89.89 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.058526
  validation loss:		0.722586
  validation accuracy:		89.57 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.051193
  validation loss:		0.687238
  validation accuracy:		89.89 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.057333
  validation loss:		0.704053
  validation accuracy:		90.33 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.067798
  validation loss:		0.693750
  validation accuracy:		89.78 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.062583
  validation loss:		0.739123
  validation accuracy:		89.78 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.061595
  validation loss:		0.719462
  validation accuracy:		89.57 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.062742
  validation loss:		0.705917
  validation accuracy:		90.00 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.057195
  validation loss:		0.700263
  validation accuracy:		89.89 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.057317
  validation loss:		0.757430
  validation accuracy:		89.13 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.087061
  validation loss:		0.725975
  validation accuracy:		89.89 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.058575
  validation loss:		0.715275
  validation accuracy:		89.67 %
Epoch 1663 of 2000 took 0.101s
  training loss:		0.064915
  validation loss:		0.682057
  validation accuracy:		90.43 %
Epoch 1664 of 2000 took 0.102s
  training loss:		0.054348
  validation loss:		0.755072
  validation accuracy:		89.24 %
Epoch 1665 of 2000 took 0.102s
  training loss:		0.064061
  validation loss:		0.758566
  validation accuracy:		89.13 %
Epoch 1666 of 2000 took 0.102s
  training loss:		0.060576
  validation loss:		0.706713
  validation accuracy:		90.43 %
Epoch 1667 of 2000 took 0.102s
  training loss:		0.056943
  validation loss:		0.726728
  validation accuracy:		89.57 %
Epoch 1668 of 2000 took 0.102s
  training loss:		0.057921
  validation loss:		0.691685
  validation accuracy:		89.78 %
Epoch 1669 of 2000 took 0.102s
  training loss:		0.059764
  validation loss:		0.737378
  validation accuracy:		89.35 %
Epoch 1670 of 2000 took 0.102s
  training loss:		0.066531
  validation loss:		0.757431
  validation accuracy:		89.13 %
Epoch 1671 of 2000 took 0.102s
  training loss:		0.059121
  validation loss:		0.770044
  validation accuracy:		89.67 %
Epoch 1672 of 2000 took 0.102s
  training loss:		0.058878
  validation loss:		0.754282
  validation accuracy:		88.70 %
Epoch 1673 of 2000 took 0.102s
  training loss:		0.052407
  validation loss:		0.714952
  validation accuracy:		90.00 %
Epoch 1674 of 2000 took 0.103s
  training loss:		0.083951
  validation loss:		0.723214
  validation accuracy:		90.00 %
Epoch 1675 of 2000 took 0.102s
  training loss:		0.057225
  validation loss:		0.758054
  validation accuracy:		88.91 %
Epoch 1676 of 2000 took 0.102s
  training loss:		0.063325
  validation loss:		0.717598
  validation accuracy:		89.57 %
Epoch 1677 of 2000 took 0.102s
  training loss:		0.063560
  validation loss:		0.719381
  validation accuracy:		89.89 %
Epoch 1678 of 2000 took 0.102s
  training loss:		0.070268
  validation loss:		0.741441
  validation accuracy:		89.67 %
Epoch 1679 of 2000 took 0.102s
  training loss:		0.057938
  validation loss:		0.749381
  validation accuracy:		89.89 %
Epoch 1680 of 2000 took 0.102s
  training loss:		0.116266
  validation loss:		0.731800
  validation accuracy:		89.89 %
Epoch 1681 of 2000 took 0.102s
  training loss:		0.065478
  validation loss:		0.841013
  validation accuracy:		88.37 %
Epoch 1682 of 2000 took 0.102s
  training loss:		0.062573
  validation loss:		0.692928
  validation accuracy:		90.43 %
Epoch 1683 of 2000 took 0.102s
  training loss:		0.068114
  validation loss:		0.709505
  validation accuracy:		89.89 %
Epoch 1684 of 2000 took 0.102s
  training loss:		0.061580
  validation loss:		0.733306
  validation accuracy:		90.11 %
Epoch 1685 of 2000 took 0.102s
  training loss:		0.054810
  validation loss:		0.688915
  validation accuracy:		90.33 %
Epoch 1686 of 2000 took 0.102s
  training loss:		0.055933
  validation loss:		0.749429
  validation accuracy:		88.70 %
Epoch 1687 of 2000 took 0.102s
  training loss:		0.054478
  validation loss:		0.724954
  validation accuracy:		89.78 %
Epoch 1688 of 2000 took 0.102s
  training loss:		0.065276
  validation loss:		0.738722
  validation accuracy:		89.57 %
Epoch 1689 of 2000 took 0.102s
  training loss:		0.059534
  validation loss:		0.746368
  validation accuracy:		90.00 %
Epoch 1690 of 2000 took 0.102s
  training loss:		0.065718
  validation loss:		0.702741
  validation accuracy:		90.65 %
Epoch 1691 of 2000 took 0.102s
  training loss:		0.060857
  validation loss:		0.746128
  validation accuracy:		89.46 %
Epoch 1692 of 2000 took 0.102s
  training loss:		0.066589
  validation loss:		0.787501
  validation accuracy:		89.13 %
Epoch 1693 of 2000 took 0.102s
  training loss:		0.117363
  validation loss:		0.841383
  validation accuracy:		88.48 %
Epoch 1694 of 2000 took 0.102s
  training loss:		0.072772
  validation loss:		0.769217
  validation accuracy:		89.02 %
Epoch 1695 of 2000 took 0.102s
  training loss:		0.056090
  validation loss:		0.736901
  validation accuracy:		89.46 %
Epoch 1696 of 2000 took 0.102s
  training loss:		0.060869
  validation loss:		0.733722
  validation accuracy:		90.11 %
Epoch 1697 of 2000 took 0.102s
  training loss:		0.064653
  validation loss:		0.756659
  validation accuracy:		89.89 %
Epoch 1698 of 2000 took 0.102s
  training loss:		0.059990
  validation loss:		0.736240
  validation accuracy:		90.00 %
Epoch 1699 of 2000 took 0.102s
  training loss:		0.063235
  validation loss:		0.740281
  validation accuracy:		90.00 %
Epoch 1700 of 2000 took 0.102s
  training loss:		0.061247
  validation loss:		0.777441
  validation accuracy:		89.35 %
Epoch 1701 of 2000 took 0.102s
  training loss:		0.058143
  validation loss:		0.718101
  validation accuracy:		90.00 %
Epoch 1702 of 2000 took 0.100s
  training loss:		0.055403
  validation loss:		0.768782
  validation accuracy:		89.24 %
Epoch 1703 of 2000 took 0.100s
  training loss:		0.059712
  validation loss:		0.781894
  validation accuracy:		88.91 %
Epoch 1704 of 2000 took 0.099s
  training loss:		0.057320
  validation loss:		0.766527
  validation accuracy:		89.13 %
Epoch 1705 of 2000 took 0.099s
  training loss:		0.054377
  validation loss:		0.729511
  validation accuracy:		89.67 %
Epoch 1706 of 2000 took 0.099s
  training loss:		0.060881
  validation loss:		0.736376
  validation accuracy:		90.11 %
Epoch 1707 of 2000 took 0.099s
  training loss:		0.055270
  validation loss:		0.785571
  validation accuracy:		89.02 %
Epoch 1708 of 2000 took 0.099s
  training loss:		0.057291
  validation loss:		0.758205
  validation accuracy:		89.57 %
Epoch 1709 of 2000 took 0.099s
  training loss:		0.052097
  validation loss:		0.745969
  validation accuracy:		89.78 %
Epoch 1710 of 2000 took 0.099s
  training loss:		0.055375
  validation loss:		0.754747
  validation accuracy:		89.78 %
Epoch 1711 of 2000 took 0.099s
  training loss:		0.066833
  validation loss:		0.792411
  validation accuracy:		89.46 %
Epoch 1712 of 2000 took 0.099s
  training loss:		0.936165
  validation loss:		3.220278
  validation accuracy:		76.20 %
Epoch 1713 of 2000 took 0.099s
  training loss:		0.677061
  validation loss:		0.922790
  validation accuracy:		88.59 %
Epoch 1714 of 2000 took 0.099s
  training loss:		0.159442
  validation loss:		0.767044
  validation accuracy:		89.78 %
Epoch 1715 of 2000 took 0.099s
  training loss:		0.113436
  validation loss:		0.705657
  validation accuracy:		90.54 %
Epoch 1716 of 2000 took 0.099s
  training loss:		0.112056
  validation loss:		0.675735
  validation accuracy:		90.87 %
Epoch 1717 of 2000 took 0.099s
  training loss:		0.087392
  validation loss:		0.671719
  validation accuracy:		91.20 %
Epoch 1718 of 2000 took 0.099s
  training loss:		0.078047
  validation loss:		0.691671
  validation accuracy:		90.87 %
Epoch 1719 of 2000 took 0.099s
  training loss:		0.068455
  validation loss:		0.642968
  validation accuracy:		91.30 %
Epoch 1720 of 2000 took 0.099s
  training loss:		0.066683
  validation loss:		0.761389
  validation accuracy:		89.24 %
Epoch 1721 of 2000 took 0.099s
  training loss:		0.080656
  validation loss:		0.672797
  validation accuracy:		90.22 %
Epoch 1722 of 2000 took 0.099s
  training loss:		0.066499
  validation loss:		0.668008
  validation accuracy:		90.43 %
Epoch 1723 of 2000 took 0.099s
  training loss:		0.065905
  validation loss:		0.699029
  validation accuracy:		90.54 %
Epoch 1724 of 2000 took 0.099s
  training loss:		0.063286
  validation loss:		0.663182
  validation accuracy:		90.54 %
Epoch 1725 of 2000 took 0.099s
  training loss:		0.072840
  validation loss:		0.648710
  validation accuracy:		91.52 %
Epoch 1726 of 2000 took 0.099s
  training loss:		0.063304
  validation loss:		0.655567
  validation accuracy:		90.87 %
Epoch 1727 of 2000 took 0.099s
  training loss:		0.060347
  validation loss:		0.694039
  validation accuracy:		89.89 %
Epoch 1728 of 2000 took 0.099s
  training loss:		0.061099
  validation loss:		0.684303
  validation accuracy:		90.54 %
Epoch 1729 of 2000 took 0.099s
  training loss:		0.062797
  validation loss:		0.673583
  validation accuracy:		90.65 %
Epoch 1730 of 2000 took 0.099s
  training loss:		0.059970
  validation loss:		0.689645
  validation accuracy:		90.43 %
Epoch 1731 of 2000 took 0.099s
  training loss:		0.058109
  validation loss:		0.665605
  validation accuracy:		90.65 %
Epoch 1732 of 2000 took 0.099s
  training loss:		0.057559
  validation loss:		0.696224
  validation accuracy:		90.43 %
Epoch 1733 of 2000 took 0.100s
  training loss:		0.056412
  validation loss:		0.703950
  validation accuracy:		90.87 %
Epoch 1734 of 2000 took 0.099s
  training loss:		0.062488
  validation loss:		0.723297
  validation accuracy:		90.00 %
Epoch 1735 of 2000 took 0.099s
  training loss:		0.062891
  validation loss:		0.663043
  validation accuracy:		90.43 %
Epoch 1736 of 2000 took 0.099s
  training loss:		0.055742
  validation loss:		0.698180
  validation accuracy:		90.00 %
Epoch 1737 of 2000 took 0.099s
  training loss:		0.062699
  validation loss:		0.664375
  validation accuracy:		90.65 %
Epoch 1738 of 2000 took 0.099s
  training loss:		0.058263
  validation loss:		0.702955
  validation accuracy:		90.33 %
Epoch 1739 of 2000 took 0.099s
  training loss:		0.058418
  validation loss:		0.664786
  validation accuracy:		90.65 %
Epoch 1740 of 2000 took 0.099s
  training loss:		0.055604
  validation loss:		0.665974
  validation accuracy:		90.54 %
Epoch 1741 of 2000 took 0.099s
  training loss:		0.059256
  validation loss:		0.704439
  validation accuracy:		90.22 %
Epoch 1742 of 2000 took 0.098s
  training loss:		0.056586
  validation loss:		0.693031
  validation accuracy:		90.33 %
Epoch 1743 of 2000 took 0.099s
  training loss:		0.054810
  validation loss:		0.707432
  validation accuracy:		90.22 %
Epoch 1744 of 2000 took 0.099s
  training loss:		0.055597
  validation loss:		0.707868
  validation accuracy:		90.33 %
Epoch 1745 of 2000 took 0.099s
  training loss:		0.055557
  validation loss:		0.743268
  validation accuracy:		89.46 %
Epoch 1746 of 2000 took 0.099s
  training loss:		0.060862
  validation loss:		0.700577
  validation accuracy:		90.43 %
Epoch 1747 of 2000 took 0.099s
  training loss:		0.056919
  validation loss:		0.684574
  validation accuracy:		91.09 %
Epoch 1748 of 2000 took 0.099s
  training loss:		0.053538
  validation loss:		0.730965
  validation accuracy:		89.89 %
Epoch 1749 of 2000 took 0.099s
  training loss:		0.054949
  validation loss:		0.707800
  validation accuracy:		90.11 %
Epoch 1750 of 2000 took 0.099s
  training loss:		0.053755
  validation loss:		0.705450
  validation accuracy:		90.43 %
Epoch 1751 of 2000 took 0.099s
  training loss:		0.055535
  validation loss:		0.679210
  validation accuracy:		90.65 %
Epoch 1752 of 2000 took 0.099s
  training loss:		0.063498
  validation loss:		0.796131
  validation accuracy:		88.70 %
Epoch 1753 of 2000 took 0.099s
  training loss:		0.061729
  validation loss:		0.737647
  validation accuracy:		90.22 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.061230
  validation loss:		0.717100
  validation accuracy:		90.00 %
Epoch 1755 of 2000 took 0.099s
  training loss:		0.067137
  validation loss:		0.725147
  validation accuracy:		90.54 %
Epoch 1756 of 2000 took 0.099s
  training loss:		0.058292
  validation loss:		0.765586
  validation accuracy:		89.02 %
Epoch 1757 of 2000 took 0.099s
  training loss:		0.056253
  validation loss:		0.768818
  validation accuracy:		89.78 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.061387
  validation loss:		0.717661
  validation accuracy:		89.89 %
Epoch 1759 of 2000 took 0.099s
  training loss:		0.054144
  validation loss:		0.682499
  validation accuracy:		91.20 %
Epoch 1760 of 2000 took 0.099s
  training loss:		0.055919
  validation loss:		0.706603
  validation accuracy:		90.11 %
Epoch 1761 of 2000 took 0.099s
  training loss:		0.052562
  validation loss:		0.726452
  validation accuracy:		90.00 %
Epoch 1762 of 2000 took 0.099s
  training loss:		0.059723
  validation loss:		0.707939
  validation accuracy:		90.54 %
Epoch 1763 of 2000 took 0.099s
  training loss:		0.054892
  validation loss:		0.783300
  validation accuracy:		89.35 %
Epoch 1764 of 2000 took 0.100s
  training loss:		0.054116
  validation loss:		0.701130
  validation accuracy:		90.76 %
Epoch 1765 of 2000 took 0.099s
  training loss:		0.053073
  validation loss:		0.754925
  validation accuracy:		89.78 %
Epoch 1766 of 2000 took 0.099s
  training loss:		0.051972
  validation loss:		0.772062
  validation accuracy:		89.02 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.075150
  validation loss:		0.704508
  validation accuracy:		90.65 %
Epoch 1768 of 2000 took 0.099s
  training loss:		0.064408
  validation loss:		0.748414
  validation accuracy:		90.11 %
Epoch 1769 of 2000 took 0.099s
  training loss:		0.057245
  validation loss:		0.728721
  validation accuracy:		90.22 %
Epoch 1770 of 2000 took 0.099s
  training loss:		0.054562
  validation loss:		0.711870
  validation accuracy:		90.11 %
Epoch 1771 of 2000 took 0.099s
  training loss:		0.054697
  validation loss:		0.777910
  validation accuracy:		89.57 %
Epoch 1772 of 2000 took 0.099s
  training loss:		0.052991
  validation loss:		0.709050
  validation accuracy:		90.54 %
Epoch 1773 of 2000 took 0.099s
  training loss:		0.049756
  validation loss:		0.727494
  validation accuracy:		90.43 %
Epoch 1774 of 2000 took 0.099s
  training loss:		0.053098
  validation loss:		0.725073
  validation accuracy:		89.78 %
Epoch 1775 of 2000 took 0.099s
  training loss:		0.056037
  validation loss:		0.727625
  validation accuracy:		90.11 %
Epoch 1776 of 2000 took 0.099s
  training loss:		0.051570
  validation loss:		0.752935
  validation accuracy:		89.24 %
Epoch 1777 of 2000 took 0.099s
  training loss:		0.051628
  validation loss:		0.730182
  validation accuracy:		90.11 %
Epoch 1778 of 2000 took 0.099s
  training loss:		0.056638
  validation loss:		0.744784
  validation accuracy:		90.00 %
Epoch 1779 of 2000 took 0.099s
  training loss:		0.050564
  validation loss:		0.725407
  validation accuracy:		90.76 %
Epoch 1780 of 2000 took 0.099s
  training loss:		0.050018
  validation loss:		0.774913
  validation accuracy:		89.35 %
Epoch 1781 of 2000 took 0.099s
  training loss:		0.059368
  validation loss:		0.772184
  validation accuracy:		89.46 %
Epoch 1782 of 2000 took 0.099s
  training loss:		0.054080
  validation loss:		0.778013
  validation accuracy:		89.67 %
Epoch 1783 of 2000 took 0.099s
  training loss:		0.052240
  validation loss:		0.756597
  validation accuracy:		90.00 %
Epoch 1784 of 2000 took 0.099s
  training loss:		0.058375
  validation loss:		0.750514
  validation accuracy:		90.22 %
Epoch 1785 of 2000 took 0.099s
  training loss:		0.050384
  validation loss:		0.756820
  validation accuracy:		90.11 %
Epoch 1786 of 2000 took 0.099s
  training loss:		0.050131
  validation loss:		0.762539
  validation accuracy:		89.57 %
Epoch 1787 of 2000 took 0.099s
  training loss:		0.048408
  validation loss:		0.797618
  validation accuracy:		89.13 %
Epoch 1788 of 2000 took 0.099s
  training loss:		0.048612
  validation loss:		0.741648
  validation accuracy:		90.00 %
Epoch 1789 of 2000 took 0.099s
  training loss:		0.052772
  validation loss:		0.746368
  validation accuracy:		89.89 %
Epoch 1790 of 2000 took 0.099s
  training loss:		0.063036
  validation loss:		0.779712
  validation accuracy:		89.46 %
Epoch 1791 of 2000 took 0.099s
  training loss:		0.048913
  validation loss:		0.765082
  validation accuracy:		90.22 %
Epoch 1792 of 2000 took 0.099s
  training loss:		0.056402
  validation loss:		0.791441
  validation accuracy:		89.46 %
Epoch 1793 of 2000 took 0.099s
  training loss:		0.051344
  validation loss:		0.779065
  validation accuracy:		89.13 %
Epoch 1794 of 2000 took 0.100s
  training loss:		0.057325
  validation loss:		0.741116
  validation accuracy:		90.22 %
Epoch 1795 of 2000 took 0.099s
  training loss:		0.048811
  validation loss:		0.789642
  validation accuracy:		89.89 %
Epoch 1796 of 2000 took 0.099s
  training loss:		0.055862
  validation loss:		0.735182
  validation accuracy:		90.22 %
Epoch 1797 of 2000 took 0.101s
  training loss:		0.056637
  validation loss:		0.793544
  validation accuracy:		90.11 %
Epoch 1798 of 2000 took 0.099s
  training loss:		0.046554
  validation loss:		0.780235
  validation accuracy:		89.57 %
Epoch 1799 of 2000 took 0.099s
  training loss:		0.050896
  validation loss:		0.749268
  validation accuracy:		90.43 %
Epoch 1800 of 2000 took 0.099s
  training loss:		0.055238
  validation loss:		0.795472
  validation accuracy:		90.00 %
Epoch 1801 of 2000 took 0.099s
  training loss:		0.067696
  validation loss:		0.764173
  validation accuracy:		90.22 %
Epoch 1802 of 2000 took 0.099s
  training loss:		0.057858
  validation loss:		0.768328
  validation accuracy:		90.00 %
Epoch 1803 of 2000 took 0.099s
  training loss:		0.048990
  validation loss:		0.793409
  validation accuracy:		89.46 %
Epoch 1804 of 2000 took 0.099s
  training loss:		0.048226
  validation loss:		0.800032
  validation accuracy:		89.89 %
Epoch 1805 of 2000 took 0.099s
  training loss:		0.052196
  validation loss:		0.812006
  validation accuracy:		89.35 %
Epoch 1806 of 2000 took 0.099s
  training loss:		0.069133
  validation loss:		0.736277
  validation accuracy:		90.54 %
Epoch 1807 of 2000 took 0.099s
  training loss:		0.055195
  validation loss:		0.814972
  validation accuracy:		89.13 %
Epoch 1808 of 2000 took 0.099s
  training loss:		0.051700
  validation loss:		0.772768
  validation accuracy:		89.78 %
Epoch 1809 of 2000 took 0.099s
  training loss:		0.051757
  validation loss:		0.777522
  validation accuracy:		89.46 %
Epoch 1810 of 2000 took 0.099s
  training loss:		0.054260
  validation loss:		0.829171
  validation accuracy:		88.80 %
Epoch 1811 of 2000 took 0.099s
  training loss:		0.049205
  validation loss:		0.791288
  validation accuracy:		89.89 %
Epoch 1812 of 2000 took 0.099s
  training loss:		0.051104
  validation loss:		0.788452
  validation accuracy:		89.89 %
Epoch 1813 of 2000 took 0.099s
  training loss:		0.052566
  validation loss:		0.769341
  validation accuracy:		90.22 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.047699
  validation loss:		0.794027
  validation accuracy:		90.00 %
Epoch 1815 of 2000 took 0.099s
  training loss:		0.050740
  validation loss:		0.808207
  validation accuracy:		89.67 %
Epoch 1816 of 2000 took 0.099s
  training loss:		0.050562
  validation loss:		0.791347
  validation accuracy:		90.11 %
Epoch 1817 of 2000 took 0.099s
  training loss:		0.055183
  validation loss:		0.772399
  validation accuracy:		90.22 %
Epoch 1818 of 2000 took 0.099s
  training loss:		0.057262
  validation loss:		0.806543
  validation accuracy:		89.57 %
Epoch 1819 of 2000 took 0.099s
  training loss:		0.048948
  validation loss:		0.809823
  validation accuracy:		89.46 %
Epoch 1820 of 2000 took 0.099s
  training loss:		0.050031
  validation loss:		0.824313
  validation accuracy:		89.57 %
Epoch 1821 of 2000 took 0.099s
  training loss:		0.049017
  validation loss:		0.778940
  validation accuracy:		90.43 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.157529
  validation loss:		1.762286
  validation accuracy:		84.02 %
Epoch 1823 of 2000 took 0.099s
  training loss:		0.154288
  validation loss:		0.769127
  validation accuracy:		90.54 %
Epoch 1824 of 2000 took 0.099s
  training loss:		0.054334
  validation loss:		0.808058
  validation accuracy:		90.00 %
Epoch 1825 of 2000 took 0.100s
  training loss:		0.050246
  validation loss:		0.775464
  validation accuracy:		89.78 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.049883
  validation loss:		0.810331
  validation accuracy:		89.35 %
Epoch 1827 of 2000 took 0.099s
  training loss:		0.050915
  validation loss:		0.816143
  validation accuracy:		89.02 %
Epoch 1828 of 2000 took 0.099s
  training loss:		0.054980
  validation loss:		0.817803
  validation accuracy:		89.35 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.049260
  validation loss:		0.815614
  validation accuracy:		89.57 %
Epoch 1830 of 2000 took 0.099s
  training loss:		0.046678
  validation loss:		0.797530
  validation accuracy:		90.11 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.052215
  validation loss:		0.811883
  validation accuracy:		89.78 %
Epoch 1832 of 2000 took 0.099s
  training loss:		0.049760
  validation loss:		0.890432
  validation accuracy:		88.59 %
Epoch 1833 of 2000 took 0.099s
  training loss:		0.058215
  validation loss:		0.794476
  validation accuracy:		90.11 %
Epoch 1834 of 2000 took 0.099s
  training loss:		0.051123
  validation loss:		0.833706
  validation accuracy:		88.48 %
Epoch 1835 of 2000 took 0.099s
  training loss:		0.050973
  validation loss:		0.796166
  validation accuracy:		89.57 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.058326
  validation loss:		0.847059
  validation accuracy:		89.13 %
Epoch 1837 of 2000 took 0.099s
  training loss:		0.047894
  validation loss:		0.837182
  validation accuracy:		89.35 %
Epoch 1838 of 2000 took 0.099s
  training loss:		0.061982
  validation loss:		0.798228
  validation accuracy:		89.89 %
Epoch 1839 of 2000 took 0.099s
  training loss:		0.054050
  validation loss:		0.845015
  validation accuracy:		89.13 %
Epoch 1840 of 2000 took 0.099s
  training loss:		0.052780
  validation loss:		0.791335
  validation accuracy:		89.46 %
Epoch 1841 of 2000 took 0.099s
  training loss:		0.053244
  validation loss:		0.807493
  validation accuracy:		90.00 %
Epoch 1842 of 2000 took 0.099s
  training loss:		0.051289
  validation loss:		0.775408
  validation accuracy:		90.33 %
Epoch 1843 of 2000 took 0.099s
  training loss:		0.081584
  validation loss:		0.841965
  validation accuracy:		88.91 %
Epoch 1844 of 2000 took 0.099s
  training loss:		0.055117
  validation loss:		0.863654
  validation accuracy:		88.91 %
Epoch 1845 of 2000 took 0.099s
  training loss:		0.062809
  validation loss:		0.886742
  validation accuracy:		88.59 %
Epoch 1846 of 2000 took 0.099s
  training loss:		0.051019
  validation loss:		0.837470
  validation accuracy:		89.57 %
Epoch 1847 of 2000 took 0.099s
  training loss:		0.048563
  validation loss:		0.815625
  validation accuracy:		89.57 %
Epoch 1848 of 2000 took 0.099s
  training loss:		0.048263
  validation loss:		0.827858
  validation accuracy:		89.67 %
Epoch 1849 of 2000 took 0.099s
  training loss:		0.048647
  validation loss:		0.829889
  validation accuracy:		89.35 %
Epoch 1850 of 2000 took 0.099s
  training loss:		0.045150
  validation loss:		0.851197
  validation accuracy:		89.67 %
Epoch 1851 of 2000 took 0.099s
  training loss:		0.045195
  validation loss:		0.825392
  validation accuracy:		89.57 %
Epoch 1852 of 2000 took 0.099s
  training loss:		0.050134
  validation loss:		0.805867
  validation accuracy:		89.35 %
Epoch 1853 of 2000 took 0.099s
  training loss:		0.051430
  validation loss:		0.826488
  validation accuracy:		89.78 %
Epoch 1854 of 2000 took 0.099s
  training loss:		0.048380
  validation loss:		0.887908
  validation accuracy:		88.70 %
Epoch 1855 of 2000 took 0.100s
  training loss:		0.048492
  validation loss:		0.870472
  validation accuracy:		89.02 %
Epoch 1856 of 2000 took 0.099s
  training loss:		0.054150
  validation loss:		0.830294
  validation accuracy:		89.46 %
Epoch 1857 of 2000 took 0.099s
  training loss:		0.070384
  validation loss:		0.930275
  validation accuracy:		88.91 %
Epoch 1858 of 2000 took 0.099s
  training loss:		0.054618
  validation loss:		0.793803
  validation accuracy:		90.11 %
Epoch 1859 of 2000 took 0.099s
  training loss:		0.057098
  validation loss:		0.832368
  validation accuracy:		89.89 %
Epoch 1860 of 2000 took 0.099s
  training loss:		0.051490
  validation loss:		0.851427
  validation accuracy:		89.13 %
Epoch 1861 of 2000 took 0.099s
  training loss:		0.049716
  validation loss:		0.834327
  validation accuracy:		90.11 %
Epoch 1862 of 2000 took 0.099s
  training loss:		0.047572
  validation loss:		0.802733
  validation accuracy:		89.89 %
Epoch 1863 of 2000 took 0.099s
  training loss:		0.049169
  validation loss:		0.833632
  validation accuracy:		89.46 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.049510
  validation loss:		0.846842
  validation accuracy:		89.78 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.045084
  validation loss:		0.896608
  validation accuracy:		88.80 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.049661
  validation loss:		0.847294
  validation accuracy:		89.24 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.050219
  validation loss:		0.875291
  validation accuracy:		88.80 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.047752
  validation loss:		0.842824
  validation accuracy:		90.00 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.047339
  validation loss:		0.829629
  validation accuracy:		90.11 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.050110
  validation loss:		0.870915
  validation accuracy:		89.78 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.072371
  validation loss:		0.901816
  validation accuracy:		89.24 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.048081
  validation loss:		0.871119
  validation accuracy:		89.24 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.047784
  validation loss:		0.852984
  validation accuracy:		89.78 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.047257
  validation loss:		0.849181
  validation accuracy:		90.00 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.051093
  validation loss:		0.856450
  validation accuracy:		89.24 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.045816
  validation loss:		0.845586
  validation accuracy:		89.78 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.051427
  validation loss:		0.884693
  validation accuracy:		89.24 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.064201
  validation loss:		0.912174
  validation accuracy:		88.48 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.054945
  validation loss:		0.890864
  validation accuracy:		89.57 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.054041
  validation loss:		0.881423
  validation accuracy:		89.78 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.069225
  validation loss:		0.852513
  validation accuracy:		90.00 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.046394
  validation loss:		0.902783
  validation accuracy:		88.91 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.048089
  validation loss:		0.881107
  validation accuracy:		89.46 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.044208
  validation loss:		0.870961
  validation accuracy:		89.02 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.040638
  validation loss:		0.859552
  validation accuracy:		89.89 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.047363
  validation loss:		0.859181
  validation accuracy:		89.89 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.051593
  validation loss:		0.971682
  validation accuracy:		88.37 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.134696
  validation loss:		0.898207
  validation accuracy:		89.57 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.193317
  validation loss:		0.832595
  validation accuracy:		90.43 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.064354
  validation loss:		0.914621
  validation accuracy:		89.46 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.100298
  validation loss:		1.092404
  validation accuracy:		88.15 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.095895
  validation loss:		0.819412
  validation accuracy:		90.76 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.048604
  validation loss:		0.851968
  validation accuracy:		90.11 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.051412
  validation loss:		0.875993
  validation accuracy:		89.67 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.052169
  validation loss:		0.863970
  validation accuracy:		89.78 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.046691
  validation loss:		0.863474
  validation accuracy:		89.67 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.050099
  validation loss:		0.906838
  validation accuracy:		88.80 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.055765
  validation loss:		0.853881
  validation accuracy:		89.89 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.048656
  validation loss:		0.849742
  validation accuracy:		89.78 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.054097
  validation loss:		0.867417
  validation accuracy:		89.78 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.052017
  validation loss:		0.852549
  validation accuracy:		90.00 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.055853
  validation loss:		0.856041
  validation accuracy:		89.89 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.045857
  validation loss:		0.883963
  validation accuracy:		89.13 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.047781
  validation loss:		0.899883
  validation accuracy:		88.48 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.048430
  validation loss:		0.858863
  validation accuracy:		89.57 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.047553
  validation loss:		0.848015
  validation accuracy:		90.00 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.046166
  validation loss:		0.853476
  validation accuracy:		89.89 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.050399
  validation loss:		0.850363
  validation accuracy:		89.89 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.042193
  validation loss:		0.862431
  validation accuracy:		90.22 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.061810
  validation loss:		0.827700
  validation accuracy:		89.89 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.048906
  validation loss:		0.881097
  validation accuracy:		89.46 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.048054
  validation loss:		0.885837
  validation accuracy:		90.22 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.050627
  validation loss:		0.841889
  validation accuracy:		90.54 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.055434
  validation loss:		0.875214
  validation accuracy:		89.35 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.046589
  validation loss:		0.896650
  validation accuracy:		89.24 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.086843
  validation loss:		0.948713
  validation accuracy:		87.72 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.053872
  validation loss:		0.945394
  validation accuracy:		88.80 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.048686
  validation loss:		0.849634
  validation accuracy:		89.89 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.045898
  validation loss:		0.855059
  validation accuracy:		90.43 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.042740
  validation loss:		0.926119
  validation accuracy:		88.59 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.047444
  validation loss:		0.890744
  validation accuracy:		89.78 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.048240
  validation loss:		0.997707
  validation accuracy:		89.46 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.092701
  validation loss:		0.878504
  validation accuracy:		89.67 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.054144
  validation loss:		0.885355
  validation accuracy:		89.67 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.078398
  validation loss:		0.951803
  validation accuracy:		88.91 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.052461
  validation loss:		0.855542
  validation accuracy:		89.89 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.068377
  validation loss:		0.884894
  validation accuracy:		88.91 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.050482
  validation loss:		0.907949
  validation accuracy:		89.02 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.044789
  validation loss:		0.868911
  validation accuracy:		90.65 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.075042
  validation loss:		0.989924
  validation accuracy:		88.48 %
Epoch 1931 of 2000 took 0.098s
  training loss:		0.094672
  validation loss:		0.905028
  validation accuracy:		89.35 %
Epoch 1932 of 2000 took 0.099s
  training loss:		0.044779
  validation loss:		0.906286
  validation accuracy:		89.46 %
Epoch 1933 of 2000 took 0.099s
  training loss:		0.052039
  validation loss:		0.962783
  validation accuracy:		88.59 %
Epoch 1934 of 2000 took 0.099s
  training loss:		0.052523
  validation loss:		0.874101
  validation accuracy:		90.43 %
Epoch 1935 of 2000 took 0.099s
  training loss:		0.043380
  validation loss:		0.866173
  validation accuracy:		90.98 %
Epoch 1936 of 2000 took 0.099s
  training loss:		0.046385
  validation loss:		0.866835
  validation accuracy:		89.67 %
Epoch 1937 of 2000 took 0.099s
  training loss:		0.042149
  validation loss:		0.960282
  validation accuracy:		88.04 %
Epoch 1938 of 2000 took 0.099s
  training loss:		0.050125
  validation loss:		0.899708
  validation accuracy:		89.24 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.046900
  validation loss:		0.865518
  validation accuracy:		90.22 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.050724
  validation loss:		0.885560
  validation accuracy:		89.89 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.041470
  validation loss:		0.896463
  validation accuracy:		89.35 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.054386
  validation loss:		0.909654
  validation accuracy:		89.02 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.044578
  validation loss:		0.929641
  validation accuracy:		88.70 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.056862
  validation loss:		0.890845
  validation accuracy:		90.00 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.044197
  validation loss:		0.888442
  validation accuracy:		90.11 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.053752
  validation loss:		0.878170
  validation accuracy:		90.54 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.041953
  validation loss:		0.918032
  validation accuracy:		89.24 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.046380
  validation loss:		0.914899
  validation accuracy:		89.57 %
Epoch 1949 of 2000 took 0.097s
  training loss:		0.058182
  validation loss:		0.916628
  validation accuracy:		89.13 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.043460
  validation loss:		0.878360
  validation accuracy:		90.22 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.042316
  validation loss:		0.915008
  validation accuracy:		89.67 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.043394
  validation loss:		0.927031
  validation accuracy:		88.70 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.050771
  validation loss:		0.894794
  validation accuracy:		89.78 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.045048
  validation loss:		0.906208
  validation accuracy:		89.89 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.039671
  validation loss:		0.895656
  validation accuracy:		89.89 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.106170
  validation loss:		1.339183
  validation accuracy:		85.11 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.649428
  validation loss:		0.972147
  validation accuracy:		89.46 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.122453
  validation loss:		0.880888
  validation accuracy:		89.35 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.059903
  validation loss:		0.899162
  validation accuracy:		89.46 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.053059
  validation loss:		0.806436
  validation accuracy:		90.65 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.072054
  validation loss:		0.979435
  validation accuracy:		88.59 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.063743
  validation loss:		0.846100
  validation accuracy:		89.89 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.045461
  validation loss:		0.829770
  validation accuracy:		91.09 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.059948
  validation loss:		0.929796
  validation accuracy:		89.78 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.068586
  validation loss:		0.866370
  validation accuracy:		90.76 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.049270
  validation loss:		0.872700
  validation accuracy:		89.13 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.051165
  validation loss:		0.856276
  validation accuracy:		90.33 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.043154
  validation loss:		0.867655
  validation accuracy:		89.46 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.052382
  validation loss:		0.896112
  validation accuracy:		89.57 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.040476
  validation loss:		0.859153
  validation accuracy:		90.22 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.044210
  validation loss:		0.904802
  validation accuracy:		89.02 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.045220
  validation loss:		0.863580
  validation accuracy:		89.89 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.054917
  validation loss:		0.884516
  validation accuracy:		89.46 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.048942
  validation loss:		0.913028
  validation accuracy:		89.24 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.047117
  validation loss:		0.883739
  validation accuracy:		89.46 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.039327
  validation loss:		0.881278
  validation accuracy:		89.57 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.045567
  validation loss:		0.887678
  validation accuracy:		89.24 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.039400
  validation loss:		0.897763
  validation accuracy:		89.89 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.045056
  validation loss:		0.880745
  validation accuracy:		89.89 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.047721
  validation loss:		0.894123
  validation accuracy:		90.11 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.047418
  validation loss:		0.924572
  validation accuracy:		88.80 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.044034
  validation loss:		0.941742
  validation accuracy:		89.13 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.044364
  validation loss:		0.925356
  validation accuracy:		89.13 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.041373
  validation loss:		0.887256
  validation accuracy:		89.89 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.041884
  validation loss:		0.895591
  validation accuracy:		89.67 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.042018
  validation loss:		0.977759
  validation accuracy:		88.48 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.046384
  validation loss:		0.900751
  validation accuracy:		90.00 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.043313
  validation loss:		0.891465
  validation accuracy:		89.78 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.040352
  validation loss:		0.909616
  validation accuracy:		89.57 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.041522
  validation loss:		0.935209
  validation accuracy:		89.46 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.044627
  validation loss:		0.949475
  validation accuracy:		88.59 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.043802
  validation loss:		0.869570
  validation accuracy:		90.11 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.062517
  validation loss:		0.955584
  validation accuracy:		89.13 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.049080
  validation loss:		0.900926
  validation accuracy:		90.11 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.044143
  validation loss:		0.991078
  validation accuracy:		88.37 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.049314
  validation loss:		0.908070
  validation accuracy:		89.57 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.038302
  validation loss:		0.883033
  validation accuracy:		90.22 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.041408
  validation loss:		0.920708
  validation accuracy:		89.78 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.040379
  validation loss:		0.911203
  validation accuracy:		89.57 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.038417
  validation loss:		0.968599
  validation accuracy:		89.02 %
Final results:
  test loss:			2.038985
  test accuracy:		81.06 %
