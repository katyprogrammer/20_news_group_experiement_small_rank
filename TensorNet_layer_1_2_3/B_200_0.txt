Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.104s
  training loss:		2.982046
  validation loss:		2.952359
  validation accuracy:		8.04 %
Epoch 2 of 2000 took 0.097s
  training loss:		2.943041
  validation loss:		2.897571
  validation accuracy:		11.09 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.891751
  validation loss:		2.833712
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.834814
  validation loss:		2.763087
  validation accuracy:		13.91 %
Epoch 5 of 2000 took 0.099s
  training loss:		2.768302
  validation loss:		2.684430
  validation accuracy:		15.00 %
Epoch 6 of 2000 took 0.098s
  training loss:		2.695513
  validation loss:		2.598217
  validation accuracy:		16.74 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.619519
  validation loss:		2.509721
  validation accuracy:		20.98 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.542739
  validation loss:		2.423966
  validation accuracy:		21.85 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.468990
  validation loss:		2.346164
  validation accuracy:		22.83 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.403774
  validation loss:		2.279843
  validation accuracy:		22.93 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.350780
  validation loss:		2.227388
  validation accuracy:		26.96 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.305427
  validation loss:		2.192375
  validation accuracy:		31.20 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.273910
  validation loss:		2.172695
  validation accuracy:		34.89 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.251781
  validation loss:		2.166565
  validation accuracy:		37.28 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.233089
  validation loss:		2.155938
  validation accuracy:		34.67 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.217153
  validation loss:		2.142124
  validation accuracy:		34.24 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.206798
  validation loss:		2.127687
  validation accuracy:		36.74 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.194151
  validation loss:		2.110164
  validation accuracy:		36.74 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.180152
  validation loss:		2.099724
  validation accuracy:		38.26 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.164573
  validation loss:		2.082817
  validation accuracy:		39.13 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.151499
  validation loss:		2.061076
  validation accuracy:		40.87 %
Epoch 22 of 2000 took 0.098s
  training loss:		2.134001
  validation loss:		2.043561
  validation accuracy:		41.85 %
Epoch 23 of 2000 took 0.098s
  training loss:		2.115554
  validation loss:		2.023891
  validation accuracy:		41.41 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.095519
  validation loss:		2.001434
  validation accuracy:		41.30 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.074761
  validation loss:		1.970898
  validation accuracy:		42.07 %
Epoch 26 of 2000 took 0.096s
  training loss:		2.049216
  validation loss:		1.948970
  validation accuracy:		41.74 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.027259
  validation loss:		1.928499
  validation accuracy:		42.39 %
Epoch 28 of 2000 took 0.096s
  training loss:		1.999147
  validation loss:		1.894057
  validation accuracy:		42.07 %
Epoch 29 of 2000 took 0.096s
  training loss:		1.975167
  validation loss:		1.862211
  validation accuracy:		47.17 %
Epoch 30 of 2000 took 0.096s
  training loss:		1.939962
  validation loss:		1.828095
  validation accuracy:		44.89 %
Epoch 31 of 2000 took 0.096s
  training loss:		1.912338
  validation loss:		1.800566
  validation accuracy:		45.76 %
Epoch 32 of 2000 took 0.097s
  training loss:		1.886229
  validation loss:		1.771423
  validation accuracy:		47.83 %
Epoch 33 of 2000 took 0.097s
  training loss:		1.855948
  validation loss:		1.737064
  validation accuracy:		50.00 %
Epoch 34 of 2000 took 0.096s
  training loss:		1.823415
  validation loss:		1.709557
  validation accuracy:		47.28 %
Epoch 35 of 2000 took 0.096s
  training loss:		1.795075
  validation loss:		1.684739
  validation accuracy:		48.26 %
Epoch 36 of 2000 took 0.096s
  training loss:		1.766999
  validation loss:		1.647504
  validation accuracy:		49.57 %
Epoch 37 of 2000 took 0.096s
  training loss:		1.741959
  validation loss:		1.619730
  validation accuracy:		51.52 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.705742
  validation loss:		1.594841
  validation accuracy:		51.41 %
Epoch 39 of 2000 took 0.096s
  training loss:		1.680829
  validation loss:		1.566628
  validation accuracy:		51.41 %
Epoch 40 of 2000 took 0.096s
  training loss:		1.650879
  validation loss:		1.530142
  validation accuracy:		53.59 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.619391
  validation loss:		1.507001
  validation accuracy:		54.13 %
Epoch 42 of 2000 took 0.096s
  training loss:		1.600116
  validation loss:		1.480586
  validation accuracy:		55.98 %
Epoch 43 of 2000 took 0.096s
  training loss:		1.566572
  validation loss:		1.450366
  validation accuracy:		56.63 %
Epoch 44 of 2000 took 0.096s
  training loss:		1.539545
  validation loss:		1.423592
  validation accuracy:		57.07 %
Epoch 45 of 2000 took 0.096s
  training loss:		1.509678
  validation loss:		1.402495
  validation accuracy:		56.63 %
Epoch 46 of 2000 took 0.098s
  training loss:		1.484414
  validation loss:		1.376454
  validation accuracy:		57.83 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.456825
  validation loss:		1.346971
  validation accuracy:		59.02 %
Epoch 48 of 2000 took 0.096s
  training loss:		1.432978
  validation loss:		1.330645
  validation accuracy:		58.37 %
Epoch 49 of 2000 took 0.096s
  training loss:		1.409799
  validation loss:		1.301654
  validation accuracy:		61.20 %
Epoch 50 of 2000 took 0.096s
  training loss:		1.384920
  validation loss:		1.275300
  validation accuracy:		61.52 %
Epoch 51 of 2000 took 0.096s
  training loss:		1.362524
  validation loss:		1.259279
  validation accuracy:		61.09 %
Epoch 52 of 2000 took 0.096s
  training loss:		1.338039
  validation loss:		1.232027
  validation accuracy:		62.28 %
Epoch 53 of 2000 took 0.096s
  training loss:		1.326351
  validation loss:		1.219498
  validation accuracy:		64.13 %
Epoch 54 of 2000 took 0.096s
  training loss:		1.298371
  validation loss:		1.198740
  validation accuracy:		63.04 %
Epoch 55 of 2000 took 0.096s
  training loss:		1.278131
  validation loss:		1.172267
  validation accuracy:		66.20 %
Epoch 56 of 2000 took 0.096s
  training loss:		1.256427
  validation loss:		1.162514
  validation accuracy:		65.87 %
Epoch 57 of 2000 took 0.096s
  training loss:		1.242689
  validation loss:		1.141886
  validation accuracy:		66.63 %
Epoch 58 of 2000 took 0.096s
  training loss:		1.217882
  validation loss:		1.117781
  validation accuracy:		67.50 %
Epoch 59 of 2000 took 0.096s
  training loss:		1.206614
  validation loss:		1.113266
  validation accuracy:		67.28 %
Epoch 60 of 2000 took 0.096s
  training loss:		1.189401
  validation loss:		1.089754
  validation accuracy:		68.59 %
Epoch 61 of 2000 took 0.096s
  training loss:		1.168265
  validation loss:		1.068436
  validation accuracy:		67.61 %
Epoch 62 of 2000 took 0.096s
  training loss:		1.143870
  validation loss:		1.059791
  validation accuracy:		69.57 %
Epoch 63 of 2000 took 0.097s
  training loss:		1.145551
  validation loss:		1.035776
  validation accuracy:		69.89 %
Epoch 64 of 2000 took 0.097s
  training loss:		1.119728
  validation loss:		1.019111
  validation accuracy:		71.20 %
Epoch 65 of 2000 took 0.096s
  training loss:		1.105034
  validation loss:		1.004375
  validation accuracy:		70.87 %
Epoch 66 of 2000 took 0.096s
  training loss:		1.089744
  validation loss:		0.984894
  validation accuracy:		71.41 %
Epoch 67 of 2000 took 0.096s
  training loss:		1.076014
  validation loss:		0.969840
  validation accuracy:		72.50 %
Epoch 68 of 2000 took 0.096s
  training loss:		1.052995
  validation loss:		0.948929
  validation accuracy:		72.39 %
Epoch 69 of 2000 took 0.096s
  training loss:		1.050350
  validation loss:		0.941488
  validation accuracy:		72.17 %
Epoch 70 of 2000 took 0.096s
  training loss:		1.027136
  validation loss:		0.932880
  validation accuracy:		71.63 %
Epoch 71 of 2000 took 0.096s
  training loss:		1.008709
  validation loss:		0.900230
  validation accuracy:		74.02 %
Epoch 72 of 2000 took 0.096s
  training loss:		0.991016
  validation loss:		0.890219
  validation accuracy:		73.91 %
Epoch 73 of 2000 took 0.099s
  training loss:		0.975388
  validation loss:		0.873628
  validation accuracy:		74.67 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.964958
  validation loss:		0.856175
  validation accuracy:		74.24 %
Epoch 75 of 2000 took 0.096s
  training loss:		0.939959
  validation loss:		0.836447
  validation accuracy:		75.33 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.929384
  validation loss:		0.826257
  validation accuracy:		75.11 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.909718
  validation loss:		0.807532
  validation accuracy:		75.76 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.896141
  validation loss:		0.796670
  validation accuracy:		75.98 %
Epoch 79 of 2000 took 0.097s
  training loss:		0.884091
  validation loss:		0.785733
  validation accuracy:		76.30 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.864008
  validation loss:		0.763959
  validation accuracy:		76.74 %
Epoch 81 of 2000 took 0.096s
  training loss:		0.847562
  validation loss:		0.752752
  validation accuracy:		76.52 %
Epoch 82 of 2000 took 0.096s
  training loss:		0.831448
  validation loss:		0.749745
  validation accuracy:		76.74 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.828744
  validation loss:		0.728828
  validation accuracy:		77.93 %
Epoch 84 of 2000 took 0.096s
  training loss:		0.806645
  validation loss:		0.718902
  validation accuracy:		77.28 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.797760
  validation loss:		0.713276
  validation accuracy:		77.61 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.784296
  validation loss:		0.687362
  validation accuracy:		77.72 %
Epoch 87 of 2000 took 0.096s
  training loss:		0.772440
  validation loss:		0.683576
  validation accuracy:		77.50 %
Epoch 88 of 2000 took 0.096s
  training loss:		0.759369
  validation loss:		0.677003
  validation accuracy:		78.26 %
Epoch 89 of 2000 took 0.096s
  training loss:		0.743619
  validation loss:		0.686995
  validation accuracy:		77.17 %
Epoch 90 of 2000 took 0.096s
  training loss:		0.735333
  validation loss:		0.638695
  validation accuracy:		78.91 %
Epoch 91 of 2000 took 0.096s
  training loss:		0.724215
  validation loss:		0.638691
  validation accuracy:		80.00 %
Epoch 92 of 2000 took 0.096s
  training loss:		0.701761
  validation loss:		0.621157
  validation accuracy:		79.35 %
Epoch 93 of 2000 took 0.096s
  training loss:		0.703124
  validation loss:		0.606317
  validation accuracy:		80.22 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.693454
  validation loss:		0.604980
  validation accuracy:		79.89 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.682426
  validation loss:		0.632250
  validation accuracy:		79.78 %
Epoch 96 of 2000 took 0.096s
  training loss:		0.676817
  validation loss:		0.591472
  validation accuracy:		80.87 %
Epoch 97 of 2000 took 0.096s
  training loss:		0.666093
  validation loss:		0.572357
  validation accuracy:		81.74 %
Epoch 98 of 2000 took 0.096s
  training loss:		0.657363
  validation loss:		0.570858
  validation accuracy:		80.65 %
Epoch 99 of 2000 took 0.096s
  training loss:		0.644250
  validation loss:		0.570826
  validation accuracy:		81.30 %
Epoch 100 of 2000 took 0.096s
  training loss:		0.640340
  validation loss:		0.561566
  validation accuracy:		81.30 %
Epoch 101 of 2000 took 0.096s
  training loss:		0.629726
  validation loss:		0.549021
  validation accuracy:		81.85 %
Epoch 102 of 2000 took 0.099s
  training loss:		0.623535
  validation loss:		0.543355
  validation accuracy:		81.85 %
Epoch 103 of 2000 took 0.096s
  training loss:		0.609256
  validation loss:		0.532543
  validation accuracy:		82.50 %
Epoch 104 of 2000 took 0.096s
  training loss:		0.608093
  validation loss:		0.535315
  validation accuracy:		82.39 %
Epoch 105 of 2000 took 0.096s
  training loss:		0.604999
  validation loss:		0.536054
  validation accuracy:		82.39 %
Epoch 106 of 2000 took 0.096s
  training loss:		0.597903
  validation loss:		0.519835
  validation accuracy:		82.83 %
Epoch 107 of 2000 took 0.096s
  training loss:		0.586788
  validation loss:		0.506133
  validation accuracy:		83.48 %
Epoch 108 of 2000 took 0.096s
  training loss:		0.584196
  validation loss:		0.505069
  validation accuracy:		83.80 %
Epoch 109 of 2000 took 0.096s
  training loss:		0.578327
  validation loss:		0.512764
  validation accuracy:		83.04 %
Epoch 110 of 2000 took 0.096s
  training loss:		0.578595
  validation loss:		0.512523
  validation accuracy:		83.04 %
Epoch 111 of 2000 took 0.096s
  training loss:		0.564464
  validation loss:		0.492373
  validation accuracy:		83.91 %
Epoch 112 of 2000 took 0.096s
  training loss:		0.563139
  validation loss:		0.478859
  validation accuracy:		84.35 %
Epoch 113 of 2000 took 0.096s
  training loss:		0.557888
  validation loss:		0.486879
  validation accuracy:		84.24 %
Epoch 114 of 2000 took 0.096s
  training loss:		0.549555
  validation loss:		0.482920
  validation accuracy:		84.35 %
Epoch 115 of 2000 took 0.096s
  training loss:		0.545934
  validation loss:		0.466293
  validation accuracy:		84.78 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.549387
  validation loss:		0.465724
  validation accuracy:		84.67 %
Epoch 117 of 2000 took 0.096s
  training loss:		0.542165
  validation loss:		0.460735
  validation accuracy:		84.89 %
Epoch 118 of 2000 took 0.096s
  training loss:		0.536636
  validation loss:		0.453170
  validation accuracy:		85.11 %
Epoch 119 of 2000 took 0.096s
  training loss:		0.537120
  validation loss:		0.449870
  validation accuracy:		85.43 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.525003
  validation loss:		0.442454
  validation accuracy:		85.54 %
Epoch 121 of 2000 took 0.096s
  training loss:		0.519603
  validation loss:		0.457063
  validation accuracy:		85.33 %
Epoch 122 of 2000 took 0.096s
  training loss:		0.517308
  validation loss:		0.442404
  validation accuracy:		85.76 %
Epoch 123 of 2000 took 0.096s
  training loss:		0.515991
  validation loss:		0.436589
  validation accuracy:		85.33 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.517807
  validation loss:		0.434491
  validation accuracy:		85.43 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.506626
  validation loss:		0.451877
  validation accuracy:		85.00 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.499190
  validation loss:		0.436133
  validation accuracy:		85.33 %
Epoch 127 of 2000 took 0.096s
  training loss:		0.501435
  validation loss:		0.428741
  validation accuracy:		85.54 %
Epoch 128 of 2000 took 0.096s
  training loss:		0.496515
  validation loss:		0.431837
  validation accuracy:		85.87 %
Epoch 129 of 2000 took 0.096s
  training loss:		0.494514
  validation loss:		0.426942
  validation accuracy:		85.76 %
Epoch 130 of 2000 took 0.096s
  training loss:		0.498241
  validation loss:		0.437015
  validation accuracy:		85.33 %
Epoch 131 of 2000 took 0.096s
  training loss:		0.489021
  validation loss:		0.420947
  validation accuracy:		86.30 %
Epoch 132 of 2000 took 0.096s
  training loss:		0.485905
  validation loss:		0.412756
  validation accuracy:		86.52 %
Epoch 133 of 2000 took 0.096s
  training loss:		0.478519
  validation loss:		0.411388
  validation accuracy:		85.98 %
Epoch 134 of 2000 took 0.099s
  training loss:		0.478206
  validation loss:		0.419127
  validation accuracy:		85.65 %
Epoch 135 of 2000 took 0.096s
  training loss:		0.478207
  validation loss:		0.429690
  validation accuracy:		85.11 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.468439
  validation loss:		0.410156
  validation accuracy:		85.98 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.472532
  validation loss:		0.414562
  validation accuracy:		86.09 %
Epoch 138 of 2000 took 0.096s
  training loss:		0.469276
  validation loss:		0.409162
  validation accuracy:		86.74 %
Epoch 139 of 2000 took 0.096s
  training loss:		0.466933
  validation loss:		0.439769
  validation accuracy:		85.00 %
Epoch 140 of 2000 took 0.096s
  training loss:		0.453334
  validation loss:		0.406630
  validation accuracy:		86.52 %
Epoch 141 of 2000 took 0.096s
  training loss:		0.457755
  validation loss:		0.412194
  validation accuracy:		85.76 %
Epoch 142 of 2000 took 0.096s
  training loss:		0.463672
  validation loss:		0.400683
  validation accuracy:		86.20 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.454523
  validation loss:		0.420057
  validation accuracy:		85.33 %
Epoch 144 of 2000 took 0.096s
  training loss:		0.451899
  validation loss:		0.413361
  validation accuracy:		85.43 %
Epoch 145 of 2000 took 0.096s
  training loss:		0.456044
  validation loss:		0.386574
  validation accuracy:		86.96 %
Epoch 146 of 2000 took 0.096s
  training loss:		0.455839
  validation loss:		0.405076
  validation accuracy:		86.09 %
Epoch 147 of 2000 took 0.096s
  training loss:		0.446716
  validation loss:		0.402209
  validation accuracy:		86.30 %
Epoch 148 of 2000 took 0.096s
  training loss:		0.446842
  validation loss:		0.387108
  validation accuracy:		86.96 %
Epoch 149 of 2000 took 0.096s
  training loss:		0.438159
  validation loss:		0.406262
  validation accuracy:		85.22 %
Epoch 150 of 2000 took 0.096s
  training loss:		0.440747
  validation loss:		0.389445
  validation accuracy:		86.74 %
Epoch 151 of 2000 took 0.096s
  training loss:		0.444438
  validation loss:		0.388088
  validation accuracy:		86.96 %
Epoch 152 of 2000 took 0.096s
  training loss:		0.439758
  validation loss:		0.410258
  validation accuracy:		85.98 %
Epoch 153 of 2000 took 0.096s
  training loss:		0.434198
  validation loss:		0.398471
  validation accuracy:		86.09 %
Epoch 154 of 2000 took 0.096s
  training loss:		0.435215
  validation loss:		0.386042
  validation accuracy:		86.30 %
Epoch 155 of 2000 took 0.096s
  training loss:		0.428701
  validation loss:		0.389219
  validation accuracy:		86.96 %
Epoch 156 of 2000 took 0.096s
  training loss:		0.431494
  validation loss:		0.388210
  validation accuracy:		87.17 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.425550
  validation loss:		0.380773
  validation accuracy:		86.96 %
Epoch 158 of 2000 took 0.096s
  training loss:		0.426170
  validation loss:		0.383760
  validation accuracy:		86.74 %
Epoch 159 of 2000 took 0.096s
  training loss:		0.422937
  validation loss:		0.396134
  validation accuracy:		86.20 %
Epoch 160 of 2000 took 0.096s
  training loss:		0.418693
  validation loss:		0.376168
  validation accuracy:		86.85 %
Epoch 161 of 2000 took 0.096s
  training loss:		0.416935
  validation loss:		0.376200
  validation accuracy:		86.85 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.417517
  validation loss:		0.375297
  validation accuracy:		86.63 %
Epoch 163 of 2000 took 0.096s
  training loss:		0.417124
  validation loss:		0.370815
  validation accuracy:		86.74 %
Epoch 164 of 2000 took 0.096s
  training loss:		0.412349
  validation loss:		0.364140
  validation accuracy:		87.17 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.409115
  validation loss:		0.370790
  validation accuracy:		86.85 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.400894
  validation loss:		0.369091
  validation accuracy:		87.07 %
Epoch 167 of 2000 took 0.096s
  training loss:		0.407989
  validation loss:		0.376467
  validation accuracy:		87.39 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.403771
  validation loss:		0.365796
  validation accuracy:		87.28 %
Epoch 169 of 2000 took 0.099s
  training loss:		0.394934
  validation loss:		0.377822
  validation accuracy:		86.41 %
Epoch 170 of 2000 took 0.096s
  training loss:		0.405482
  validation loss:		0.363691
  validation accuracy:		86.96 %
Epoch 171 of 2000 took 0.096s
  training loss:		0.397014
  validation loss:		0.358064
  validation accuracy:		87.50 %
Epoch 172 of 2000 took 0.096s
  training loss:		0.398529
  validation loss:		0.361362
  validation accuracy:		87.50 %
Epoch 173 of 2000 took 0.096s
  training loss:		0.396455
  validation loss:		0.377367
  validation accuracy:		87.17 %
Epoch 174 of 2000 took 0.096s
  training loss:		0.391371
  validation loss:		0.372524
  validation accuracy:		87.07 %
Epoch 175 of 2000 took 0.096s
  training loss:		0.390181
  validation loss:		0.363436
  validation accuracy:		87.50 %
Epoch 176 of 2000 took 0.096s
  training loss:		0.391500
  validation loss:		0.354877
  validation accuracy:		87.61 %
Epoch 177 of 2000 took 0.096s
  training loss:		0.394515
  validation loss:		0.384350
  validation accuracy:		86.96 %
Epoch 178 of 2000 took 0.096s
  training loss:		0.391805
  validation loss:		0.354282
  validation accuracy:		87.61 %
Epoch 179 of 2000 took 0.096s
  training loss:		0.392414
  validation loss:		0.350279
  validation accuracy:		87.07 %
Epoch 180 of 2000 took 0.096s
  training loss:		0.381046
  validation loss:		0.359933
  validation accuracy:		87.39 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.382199
  validation loss:		0.359092
  validation accuracy:		87.07 %
Epoch 182 of 2000 took 0.096s
  training loss:		0.380830
  validation loss:		0.365175
  validation accuracy:		87.07 %
Epoch 183 of 2000 took 0.096s
  training loss:		0.377785
  validation loss:		0.363733
  validation accuracy:		86.30 %
Epoch 184 of 2000 took 0.096s
  training loss:		0.384000
  validation loss:		0.369072
  validation accuracy:		87.17 %
Epoch 185 of 2000 took 0.096s
  training loss:		0.374253
  validation loss:		0.362707
  validation accuracy:		87.50 %
Epoch 186 of 2000 took 0.096s
  training loss:		0.373952
  validation loss:		0.384337
  validation accuracy:		86.74 %
Epoch 187 of 2000 took 0.096s
  training loss:		0.369637
  validation loss:		0.362412
  validation accuracy:		87.50 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.363536
  validation loss:		0.349167
  validation accuracy:		87.83 %
Epoch 189 of 2000 took 0.096s
  training loss:		0.369444
  validation loss:		0.383422
  validation accuracy:		87.07 %
Epoch 190 of 2000 took 0.096s
  training loss:		0.363981
  validation loss:		0.358996
  validation accuracy:		87.50 %
Epoch 191 of 2000 took 0.096s
  training loss:		0.369550
  validation loss:		0.364291
  validation accuracy:		87.17 %
Epoch 192 of 2000 took 0.096s
  training loss:		0.367277
  validation loss:		0.359406
  validation accuracy:		87.61 %
Epoch 193 of 2000 took 0.096s
  training loss:		0.359976
  validation loss:		0.348472
  validation accuracy:		87.72 %
Epoch 194 of 2000 took 0.096s
  training loss:		0.355890
  validation loss:		0.347202
  validation accuracy:		87.61 %
Epoch 195 of 2000 took 0.096s
  training loss:		0.353308
  validation loss:		0.339048
  validation accuracy:		87.83 %
Epoch 196 of 2000 took 0.096s
  training loss:		0.358846
  validation loss:		0.335150
  validation accuracy:		87.83 %
Epoch 197 of 2000 took 0.096s
  training loss:		0.357226
  validation loss:		0.352498
  validation accuracy:		87.93 %
Epoch 198 of 2000 took 0.096s
  training loss:		0.357498
  validation loss:		0.341182
  validation accuracy:		88.04 %
Epoch 199 of 2000 took 0.096s
  training loss:		0.357217
  validation loss:		0.349164
  validation accuracy:		87.83 %
Epoch 200 of 2000 took 0.096s
  training loss:		0.352018
  validation loss:		0.340107
  validation accuracy:		87.83 %
Epoch 201 of 2000 took 0.096s
  training loss:		0.349878
  validation loss:		0.356572
  validation accuracy:		87.72 %
Epoch 202 of 2000 took 0.096s
  training loss:		0.343651
  validation loss:		0.363418
  validation accuracy:		88.15 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.351935
  validation loss:		0.347061
  validation accuracy:		88.04 %
Epoch 204 of 2000 took 0.096s
  training loss:		0.346044
  validation loss:		0.339544
  validation accuracy:		88.26 %
Epoch 205 of 2000 took 0.096s
  training loss:		0.344045
  validation loss:		0.353910
  validation accuracy:		87.83 %
Epoch 206 of 2000 took 0.096s
  training loss:		0.341937
  validation loss:		0.336506
  validation accuracy:		88.26 %
Epoch 207 of 2000 took 0.099s
  training loss:		0.341340
  validation loss:		0.342799
  validation accuracy:		87.93 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.343424
  validation loss:		0.338357
  validation accuracy:		88.59 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.343129
  validation loss:		0.339797
  validation accuracy:		88.26 %
Epoch 210 of 2000 took 0.096s
  training loss:		0.331833
  validation loss:		0.335961
  validation accuracy:		88.15 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.337303
  validation loss:		0.334912
  validation accuracy:		88.37 %
Epoch 212 of 2000 took 0.096s
  training loss:		0.332864
  validation loss:		0.328799
  validation accuracy:		88.70 %
Epoch 213 of 2000 took 0.096s
  training loss:		0.331489
  validation loss:		0.336227
  validation accuracy:		88.26 %
Epoch 214 of 2000 took 0.096s
  training loss:		0.331208
  validation loss:		0.337664
  validation accuracy:		88.37 %
Epoch 215 of 2000 took 0.096s
  training loss:		0.326287
  validation loss:		0.333413
  validation accuracy:		88.70 %
Epoch 216 of 2000 took 0.096s
  training loss:		0.328365
  validation loss:		0.348116
  validation accuracy:		88.15 %
Epoch 217 of 2000 took 0.096s
  training loss:		0.327365
  validation loss:		0.327341
  validation accuracy:		88.91 %
Epoch 218 of 2000 took 0.096s
  training loss:		0.329253
  validation loss:		0.342255
  validation accuracy:		88.37 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.323957
  validation loss:		0.335886
  validation accuracy:		88.37 %
Epoch 220 of 2000 took 0.096s
  training loss:		0.323131
  validation loss:		0.325958
  validation accuracy:		88.04 %
Epoch 221 of 2000 took 0.096s
  training loss:		0.323748
  validation loss:		0.331125
  validation accuracy:		88.80 %
Epoch 222 of 2000 took 0.096s
  training loss:		0.329224
  validation loss:		0.342651
  validation accuracy:		88.70 %
Epoch 223 of 2000 took 0.096s
  training loss:		0.321235
  validation loss:		0.328022
  validation accuracy:		88.70 %
Epoch 224 of 2000 took 0.096s
  training loss:		0.322286
  validation loss:		0.327974
  validation accuracy:		88.80 %
Epoch 225 of 2000 took 0.096s
  training loss:		0.314832
  validation loss:		0.336844
  validation accuracy:		89.02 %
Epoch 226 of 2000 took 0.096s
  training loss:		0.320521
  validation loss:		0.322146
  validation accuracy:		88.80 %
Epoch 227 of 2000 took 0.096s
  training loss:		0.316289
  validation loss:		0.340610
  validation accuracy:		89.02 %
Epoch 228 of 2000 took 0.096s
  training loss:		0.315172
  validation loss:		0.333023
  validation accuracy:		88.70 %
Epoch 229 of 2000 took 0.096s
  training loss:		0.315789
  validation loss:		0.327788
  validation accuracy:		89.02 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.314338
  validation loss:		0.343139
  validation accuracy:		88.70 %
Epoch 231 of 2000 took 0.096s
  training loss:		0.317309
  validation loss:		0.325745
  validation accuracy:		88.70 %
Epoch 232 of 2000 took 0.096s
  training loss:		0.310972
  validation loss:		0.337294
  validation accuracy:		88.15 %
Epoch 233 of 2000 took 0.096s
  training loss:		0.312319
  validation loss:		0.340812
  validation accuracy:		88.37 %
Epoch 234 of 2000 took 0.096s
  training loss:		0.312380
  validation loss:		0.325204
  validation accuracy:		89.02 %
Epoch 235 of 2000 took 0.096s
  training loss:		0.312998
  validation loss:		0.321924
  validation accuracy:		89.46 %
Epoch 236 of 2000 took 0.096s
  training loss:		0.304168
  validation loss:		0.324523
  validation accuracy:		89.13 %
Epoch 237 of 2000 took 0.096s
  training loss:		0.309785
  validation loss:		0.325615
  validation accuracy:		88.80 %
Epoch 238 of 2000 took 0.096s
  training loss:		0.305489
  validation loss:		0.320710
  validation accuracy:		89.24 %
Epoch 239 of 2000 took 0.096s
  training loss:		0.302804
  validation loss:		0.321100
  validation accuracy:		89.46 %
Epoch 240 of 2000 took 0.096s
  training loss:		0.311708
  validation loss:		0.335387
  validation accuracy:		88.48 %
Epoch 241 of 2000 took 0.096s
  training loss:		0.305992
  validation loss:		0.326207
  validation accuracy:		89.57 %
Epoch 242 of 2000 took 0.096s
  training loss:		0.303984
  validation loss:		0.316377
  validation accuracy:		89.46 %
Epoch 243 of 2000 took 0.096s
  training loss:		0.306274
  validation loss:		0.323450
  validation accuracy:		89.02 %
Epoch 244 of 2000 took 0.096s
  training loss:		0.303487
  validation loss:		0.327967
  validation accuracy:		89.13 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.301974
  validation loss:		0.326777
  validation accuracy:		89.13 %
Epoch 246 of 2000 took 0.096s
  training loss:		0.294685
  validation loss:		0.325421
  validation accuracy:		89.67 %
Epoch 247 of 2000 took 0.096s
  training loss:		0.295979
  validation loss:		0.320730
  validation accuracy:		89.24 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.295474
  validation loss:		0.322502
  validation accuracy:		89.24 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.296125
  validation loss:		0.322305
  validation accuracy:		89.13 %
Epoch 250 of 2000 took 0.100s
  training loss:		0.300066
  validation loss:		0.322850
  validation accuracy:		89.02 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.296401
  validation loss:		0.324133
  validation accuracy:		88.91 %
Epoch 252 of 2000 took 0.096s
  training loss:		0.295568
  validation loss:		0.321705
  validation accuracy:		89.78 %
Epoch 253 of 2000 took 0.096s
  training loss:		0.291819
  validation loss:		0.317772
  validation accuracy:		89.02 %
Epoch 254 of 2000 took 0.096s
  training loss:		0.298533
  validation loss:		0.317217
  validation accuracy:		89.46 %
Epoch 255 of 2000 took 0.096s
  training loss:		0.291919
  validation loss:		0.313860
  validation accuracy:		89.67 %
Epoch 256 of 2000 took 0.096s
  training loss:		0.291001
  validation loss:		0.312920
  validation accuracy:		89.24 %
Epoch 257 of 2000 took 0.096s
  training loss:		0.291744
  validation loss:		0.321217
  validation accuracy:		89.67 %
Epoch 258 of 2000 took 0.096s
  training loss:		0.296370
  validation loss:		0.317612
  validation accuracy:		89.67 %
Epoch 259 of 2000 took 0.096s
  training loss:		0.287101
  validation loss:		0.319596
  validation accuracy:		89.89 %
Epoch 260 of 2000 took 0.096s
  training loss:		0.290166
  validation loss:		0.315600
  validation accuracy:		89.67 %
Epoch 261 of 2000 took 0.096s
  training loss:		0.285780
  validation loss:		0.313281
  validation accuracy:		89.78 %
Epoch 262 of 2000 took 0.096s
  training loss:		0.284942
  validation loss:		0.320382
  validation accuracy:		89.46 %
Epoch 263 of 2000 took 0.096s
  training loss:		0.284111
  validation loss:		0.330100
  validation accuracy:		89.35 %
Epoch 264 of 2000 took 0.096s
  training loss:		0.289214
  validation loss:		0.318048
  validation accuracy:		89.24 %
Epoch 265 of 2000 took 0.096s
  training loss:		0.284930
  validation loss:		0.328321
  validation accuracy:		89.57 %
Epoch 266 of 2000 took 0.096s
  training loss:		0.279868
  validation loss:		0.317123
  validation accuracy:		89.67 %
Epoch 267 of 2000 took 0.096s
  training loss:		0.279071
  validation loss:		0.314574
  validation accuracy:		89.35 %
Epoch 268 of 2000 took 0.096s
  training loss:		0.289104
  validation loss:		0.325341
  validation accuracy:		89.67 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.276726
  validation loss:		0.319124
  validation accuracy:		89.46 %
Epoch 270 of 2000 took 0.096s
  training loss:		0.281951
  validation loss:		0.321443
  validation accuracy:		89.67 %
Epoch 271 of 2000 took 0.096s
  training loss:		0.280569
  validation loss:		0.320113
  validation accuracy:		89.67 %
Epoch 272 of 2000 took 0.096s
  training loss:		0.280810
  validation loss:		0.315129
  validation accuracy:		89.78 %
Epoch 273 of 2000 took 0.096s
  training loss:		0.275965
  validation loss:		0.322531
  validation accuracy:		89.46 %
Epoch 274 of 2000 took 0.096s
  training loss:		0.285663
  validation loss:		0.321922
  validation accuracy:		90.43 %
Epoch 275 of 2000 took 0.096s
  training loss:		0.280970
  validation loss:		0.325853
  validation accuracy:		89.57 %
Epoch 276 of 2000 took 0.096s
  training loss:		0.277648
  validation loss:		0.308257
  validation accuracy:		89.89 %
Epoch 277 of 2000 took 0.096s
  training loss:		0.274995
  validation loss:		0.316286
  validation accuracy:		89.89 %
Epoch 278 of 2000 took 0.096s
  training loss:		0.276270
  validation loss:		0.328109
  validation accuracy:		89.78 %
Epoch 279 of 2000 took 0.096s
  training loss:		0.279952
  validation loss:		0.311559
  validation accuracy:		90.22 %
Epoch 280 of 2000 took 0.096s
  training loss:		0.273498
  validation loss:		0.311911
  validation accuracy:		89.78 %
Epoch 281 of 2000 took 0.096s
  training loss:		0.270808
  validation loss:		0.312217
  validation accuracy:		89.89 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.272034
  validation loss:		0.327427
  validation accuracy:		89.78 %
Epoch 283 of 2000 took 0.096s
  training loss:		0.270885
  validation loss:		0.315726
  validation accuracy:		89.57 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.278123
  validation loss:		0.313278
  validation accuracy:		89.78 %
Epoch 285 of 2000 took 0.096s
  training loss:		0.265698
  validation loss:		0.305310
  validation accuracy:		90.11 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.267496
  validation loss:		0.316103
  validation accuracy:		89.78 %
Epoch 287 of 2000 took 0.096s
  training loss:		0.267226
  validation loss:		0.314671
  validation accuracy:		89.57 %
Epoch 288 of 2000 took 0.096s
  training loss:		0.269013
  validation loss:		0.328368
  validation accuracy:		89.67 %
Epoch 289 of 2000 took 0.096s
  training loss:		0.270070
  validation loss:		0.320023
  validation accuracy:		89.78 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.275111
  validation loss:		0.316245
  validation accuracy:		89.78 %
Epoch 291 of 2000 took 0.096s
  training loss:		0.275472
  validation loss:		0.305199
  validation accuracy:		90.43 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.274455
  validation loss:		0.308215
  validation accuracy:		90.43 %
Epoch 293 of 2000 took 0.096s
  training loss:		0.270735
  validation loss:		0.305366
  validation accuracy:		90.54 %
Epoch 294 of 2000 took 0.096s
  training loss:		0.267392
  validation loss:		0.309425
  validation accuracy:		89.78 %
Epoch 295 of 2000 took 0.096s
  training loss:		0.264318
  validation loss:		0.314035
  validation accuracy:		89.78 %
Epoch 296 of 2000 took 0.099s
  training loss:		0.267838
  validation loss:		0.313900
  validation accuracy:		89.78 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.263883
  validation loss:		0.315256
  validation accuracy:		89.89 %
Epoch 298 of 2000 took 0.096s
  training loss:		0.269942
  validation loss:		0.315815
  validation accuracy:		89.67 %
Epoch 299 of 2000 took 0.096s
  training loss:		0.265985
  validation loss:		0.306551
  validation accuracy:		90.22 %
Epoch 300 of 2000 took 0.096s
  training loss:		0.257351
  validation loss:		0.309305
  validation accuracy:		89.89 %
Epoch 301 of 2000 took 0.096s
  training loss:		0.266269
  validation loss:		0.305481
  validation accuracy:		90.00 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.263427
  validation loss:		0.305220
  validation accuracy:		90.33 %
Epoch 303 of 2000 took 0.096s
  training loss:		0.262993
  validation loss:		0.306089
  validation accuracy:		90.11 %
Epoch 304 of 2000 took 0.096s
  training loss:		0.269596
  validation loss:		0.338855
  validation accuracy:		89.35 %
Epoch 305 of 2000 took 0.096s
  training loss:		0.267288
  validation loss:		0.311625
  validation accuracy:		90.11 %
Epoch 306 of 2000 took 0.096s
  training loss:		0.260785
  validation loss:		0.306582
  validation accuracy:		90.33 %
Epoch 307 of 2000 took 0.096s
  training loss:		0.261088
  validation loss:		0.317705
  validation accuracy:		89.78 %
Epoch 308 of 2000 took 0.096s
  training loss:		0.262662
  validation loss:		0.305847
  validation accuracy:		90.54 %
Epoch 309 of 2000 took 0.096s
  training loss:		0.254087
  validation loss:		0.310486
  validation accuracy:		90.00 %
Epoch 310 of 2000 took 0.096s
  training loss:		0.260490
  validation loss:		0.302286
  validation accuracy:		90.43 %
Epoch 311 of 2000 took 0.096s
  training loss:		0.261874
  validation loss:		0.312319
  validation accuracy:		90.11 %
Epoch 312 of 2000 took 0.096s
  training loss:		0.263210
  validation loss:		0.313634
  validation accuracy:		90.43 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.258604
  validation loss:		0.309948
  validation accuracy:		90.33 %
Epoch 314 of 2000 took 0.096s
  training loss:		0.253191
  validation loss:		0.312151
  validation accuracy:		90.11 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.255324
  validation loss:		0.314027
  validation accuracy:		89.89 %
Epoch 316 of 2000 took 0.096s
  training loss:		0.252185
  validation loss:		0.303582
  validation accuracy:		90.33 %
Epoch 317 of 2000 took 0.096s
  training loss:		0.255782
  validation loss:		0.310341
  validation accuracy:		90.87 %
Epoch 318 of 2000 took 0.096s
  training loss:		0.255273
  validation loss:		0.314453
  validation accuracy:		90.22 %
Epoch 319 of 2000 took 0.096s
  training loss:		0.255275
  validation loss:		0.308948
  validation accuracy:		90.65 %
Epoch 320 of 2000 took 0.096s
  training loss:		0.258328
  validation loss:		0.307167
  validation accuracy:		90.76 %
Epoch 321 of 2000 took 0.096s
  training loss:		0.260463
  validation loss:		0.306882
  validation accuracy:		90.43 %
Epoch 322 of 2000 took 0.096s
  training loss:		0.255185
  validation loss:		0.310866
  validation accuracy:		90.00 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.260101
  validation loss:		0.319297
  validation accuracy:		90.43 %
Epoch 324 of 2000 took 0.096s
  training loss:		0.256511
  validation loss:		0.327114
  validation accuracy:		89.89 %
Epoch 325 of 2000 took 0.096s
  training loss:		0.251714
  validation loss:		0.310938
  validation accuracy:		90.11 %
Epoch 326 of 2000 took 0.096s
  training loss:		0.253740
  validation loss:		0.304124
  validation accuracy:		90.65 %
Epoch 327 of 2000 took 0.096s
  training loss:		0.255219
  validation loss:		0.302888
  validation accuracy:		90.65 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.247547
  validation loss:		0.303222
  validation accuracy:		90.33 %
Epoch 329 of 2000 took 0.096s
  training loss:		0.250140
  validation loss:		0.315148
  validation accuracy:		90.00 %
Epoch 330 of 2000 took 0.096s
  training loss:		0.249535
  validation loss:		0.307682
  validation accuracy:		90.76 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.244640
  validation loss:		0.313205
  validation accuracy:		90.33 %
Epoch 332 of 2000 took 0.096s
  training loss:		0.250437
  validation loss:		0.317180
  validation accuracy:		90.65 %
Epoch 333 of 2000 took 0.096s
  training loss:		0.247936
  validation loss:		0.307337
  validation accuracy:		90.65 %
Epoch 334 of 2000 took 0.096s
  training loss:		0.246345
  validation loss:		0.301179
  validation accuracy:		90.76 %
Epoch 335 of 2000 took 0.096s
  training loss:		0.245614
  validation loss:		0.316171
  validation accuracy:		90.11 %
Epoch 336 of 2000 took 0.096s
  training loss:		0.252110
  validation loss:		0.307882
  validation accuracy:		90.33 %
Epoch 337 of 2000 took 0.096s
  training loss:		0.246754
  validation loss:		0.317982
  validation accuracy:		90.33 %
Epoch 338 of 2000 took 0.096s
  training loss:		0.247820
  validation loss:		0.320741
  validation accuracy:		89.89 %
Epoch 339 of 2000 took 0.096s
  training loss:		0.248456
  validation loss:		0.312395
  validation accuracy:		90.54 %
Epoch 340 of 2000 took 0.096s
  training loss:		0.245447
  validation loss:		0.306611
  validation accuracy:		90.65 %
Epoch 341 of 2000 took 0.096s
  training loss:		0.253801
  validation loss:		0.312750
  validation accuracy:		90.87 %
Epoch 342 of 2000 took 0.096s
  training loss:		0.245044
  validation loss:		0.308044
  validation accuracy:		90.54 %
Epoch 343 of 2000 took 0.096s
  training loss:		0.245591
  validation loss:		0.307233
  validation accuracy:		90.87 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.244757
  validation loss:		0.308276
  validation accuracy:		90.43 %
Epoch 345 of 2000 took 0.096s
  training loss:		0.245942
  validation loss:		0.308998
  validation accuracy:		91.09 %
Epoch 346 of 2000 took 0.096s
  training loss:		0.242692
  validation loss:		0.312567
  validation accuracy:		90.54 %
Epoch 347 of 2000 took 0.096s
  training loss:		0.244724
  validation loss:		0.308149
  validation accuracy:		90.43 %
Epoch 348 of 2000 took 0.099s
  training loss:		0.238845
  validation loss:		0.310770
  validation accuracy:		90.54 %
Epoch 349 of 2000 took 0.096s
  training loss:		0.239854
  validation loss:		0.304847
  validation accuracy:		90.87 %
Epoch 350 of 2000 took 0.096s
  training loss:		0.245421
  validation loss:		0.311954
  validation accuracy:		90.11 %
Epoch 351 of 2000 took 0.096s
  training loss:		0.242669
  validation loss:		0.309529
  validation accuracy:		90.43 %
Epoch 352 of 2000 took 0.096s
  training loss:		0.244682
  validation loss:		0.309815
  validation accuracy:		90.98 %
Epoch 353 of 2000 took 0.096s
  training loss:		0.245927
  validation loss:		0.307895
  validation accuracy:		90.65 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.243393
  validation loss:		0.306861
  validation accuracy:		91.09 %
Epoch 355 of 2000 took 0.096s
  training loss:		0.241807
  validation loss:		0.306328
  validation accuracy:		90.98 %
Epoch 356 of 2000 took 0.096s
  training loss:		0.242809
  validation loss:		0.306323
  validation accuracy:		90.87 %
Epoch 357 of 2000 took 0.096s
  training loss:		0.236690
  validation loss:		0.314698
  validation accuracy:		90.87 %
Epoch 358 of 2000 took 0.096s
  training loss:		0.241620
  validation loss:		0.310931
  validation accuracy:		90.22 %
Epoch 359 of 2000 took 0.096s
  training loss:		0.242421
  validation loss:		0.303716
  validation accuracy:		90.65 %
Epoch 360 of 2000 took 0.096s
  training loss:		0.236247
  validation loss:		0.302560
  validation accuracy:		90.98 %
Epoch 361 of 2000 took 0.096s
  training loss:		0.232901
  validation loss:		0.309075
  validation accuracy:		91.09 %
Epoch 362 of 2000 took 0.096s
  training loss:		0.236994
  validation loss:		0.307749
  validation accuracy:		90.87 %
Epoch 363 of 2000 took 0.096s
  training loss:		0.234517
  validation loss:		0.309005
  validation accuracy:		90.43 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.234644
  validation loss:		0.320658
  validation accuracy:		90.22 %
Epoch 365 of 2000 took 0.096s
  training loss:		0.235717
  validation loss:		0.316495
  validation accuracy:		90.22 %
Epoch 366 of 2000 took 0.096s
  training loss:		0.238205
  validation loss:		0.305470
  validation accuracy:		90.76 %
Epoch 367 of 2000 took 0.096s
  training loss:		0.230829
  validation loss:		0.305862
  validation accuracy:		91.09 %
Epoch 368 of 2000 took 0.096s
  training loss:		0.237567
  validation loss:		0.311391
  validation accuracy:		90.65 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.239928
  validation loss:		0.326043
  validation accuracy:		90.11 %
Epoch 370 of 2000 took 0.096s
  training loss:		0.232456
  validation loss:		0.316480
  validation accuracy:		90.76 %
Epoch 371 of 2000 took 0.096s
  training loss:		0.236916
  validation loss:		0.308376
  validation accuracy:		90.87 %
Epoch 372 of 2000 took 0.096s
  training loss:		0.230801
  validation loss:		0.315496
  validation accuracy:		90.87 %
Epoch 373 of 2000 took 0.099s
  training loss:		0.234892
  validation loss:		0.302731
  validation accuracy:		91.09 %
Epoch 374 of 2000 took 0.099s
  training loss:		0.237377
  validation loss:		0.313171
  validation accuracy:		90.76 %
Epoch 375 of 2000 took 0.100s
  training loss:		0.231231
  validation loss:		0.315963
  validation accuracy:		90.65 %
Epoch 376 of 2000 took 0.099s
  training loss:		0.237655
  validation loss:		0.306843
  validation accuracy:		91.30 %
Epoch 377 of 2000 took 0.099s
  training loss:		0.228858
  validation loss:		0.311045
  validation accuracy:		91.09 %
Epoch 378 of 2000 took 0.099s
  training loss:		0.227181
  validation loss:		0.312326
  validation accuracy:		90.87 %
Epoch 379 of 2000 took 0.099s
  training loss:		0.230998
  validation loss:		0.314304
  validation accuracy:		90.54 %
Epoch 380 of 2000 took 0.099s
  training loss:		0.236637
  validation loss:		0.312978
  validation accuracy:		90.87 %
Epoch 381 of 2000 took 0.099s
  training loss:		0.228294
  validation loss:		0.318628
  validation accuracy:		90.33 %
Epoch 382 of 2000 took 0.099s
  training loss:		0.235575
  validation loss:		0.305137
  validation accuracy:		90.98 %
Epoch 383 of 2000 took 0.099s
  training loss:		0.231974
  validation loss:		0.318893
  validation accuracy:		90.76 %
Epoch 384 of 2000 took 0.099s
  training loss:		0.230517
  validation loss:		0.305826
  validation accuracy:		90.98 %
Epoch 385 of 2000 took 0.100s
  training loss:		0.231066
  validation loss:		0.305894
  validation accuracy:		90.76 %
Epoch 386 of 2000 took 0.099s
  training loss:		0.230179
  validation loss:		0.309144
  validation accuracy:		91.20 %
Epoch 387 of 2000 took 0.100s
  training loss:		0.230898
  validation loss:		0.304183
  validation accuracy:		90.76 %
Epoch 388 of 2000 took 0.099s
  training loss:		0.229033
  validation loss:		0.313599
  validation accuracy:		91.09 %
Epoch 389 of 2000 took 0.099s
  training loss:		0.232713
  validation loss:		0.310595
  validation accuracy:		91.09 %
Epoch 390 of 2000 took 0.099s
  training loss:		0.230671
  validation loss:		0.303846
  validation accuracy:		90.76 %
Epoch 391 of 2000 took 0.099s
  training loss:		0.231652
  validation loss:		0.305345
  validation accuracy:		91.30 %
Epoch 392 of 2000 took 0.099s
  training loss:		0.229413
  validation loss:		0.321264
  validation accuracy:		90.76 %
Epoch 393 of 2000 took 0.100s
  training loss:		0.231970
  validation loss:		0.311715
  validation accuracy:		90.87 %
Epoch 394 of 2000 took 0.099s
  training loss:		0.226227
  validation loss:		0.308902
  validation accuracy:		90.87 %
Epoch 395 of 2000 took 0.100s
  training loss:		0.225297
  validation loss:		0.318353
  validation accuracy:		90.65 %
Epoch 396 of 2000 took 0.099s
  training loss:		0.229185
  validation loss:		0.325051
  validation accuracy:		89.89 %
Epoch 397 of 2000 took 0.099s
  training loss:		0.228785
  validation loss:		0.312005
  validation accuracy:		90.76 %
Epoch 398 of 2000 took 0.099s
  training loss:		0.225557
  validation loss:		0.307235
  validation accuracy:		90.65 %
Epoch 399 of 2000 took 0.099s
  training loss:		0.232980
  validation loss:		0.319459
  validation accuracy:		90.33 %
Epoch 400 of 2000 took 0.099s
  training loss:		0.227618
  validation loss:		0.316934
  validation accuracy:		90.43 %
Epoch 401 of 2000 took 0.099s
  training loss:		0.226164
  validation loss:		0.323297
  validation accuracy:		90.54 %
Epoch 402 of 2000 took 0.099s
  training loss:		0.227017
  validation loss:		0.330985
  validation accuracy:		89.67 %
Epoch 403 of 2000 took 0.102s
  training loss:		0.227297
  validation loss:		0.315925
  validation accuracy:		91.20 %
Epoch 404 of 2000 took 0.100s
  training loss:		0.231505
  validation loss:		0.322745
  validation accuracy:		90.87 %
Epoch 405 of 2000 took 0.100s
  training loss:		0.229403
  validation loss:		0.320433
  validation accuracy:		90.11 %
Epoch 406 of 2000 took 0.100s
  training loss:		0.223589
  validation loss:		0.305433
  validation accuracy:		91.09 %
Epoch 407 of 2000 took 0.099s
  training loss:		0.225487
  validation loss:		0.326598
  validation accuracy:		89.89 %
Epoch 408 of 2000 took 0.099s
  training loss:		0.215545
  validation loss:		0.316724
  validation accuracy:		90.33 %
Epoch 409 of 2000 took 0.100s
  training loss:		0.220741
  validation loss:		0.305296
  validation accuracy:		91.20 %
Epoch 410 of 2000 took 0.100s
  training loss:		0.220764
  validation loss:		0.313701
  validation accuracy:		90.76 %
Epoch 411 of 2000 took 0.099s
  training loss:		0.224271
  validation loss:		0.337065
  validation accuracy:		89.24 %
Epoch 412 of 2000 took 0.099s
  training loss:		0.222192
  validation loss:		0.313839
  validation accuracy:		91.09 %
Epoch 413 of 2000 took 0.098s
  training loss:		0.223655
  validation loss:		0.329941
  validation accuracy:		89.57 %
Epoch 414 of 2000 took 0.096s
  training loss:		0.231190
  validation loss:		0.312743
  validation accuracy:		91.09 %
Epoch 415 of 2000 took 0.096s
  training loss:		0.223553
  validation loss:		0.308298
  validation accuracy:		90.87 %
Epoch 416 of 2000 took 0.096s
  training loss:		0.221747
  validation loss:		0.312264
  validation accuracy:		90.98 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.224968
  validation loss:		0.321662
  validation accuracy:		90.11 %
Epoch 418 of 2000 took 0.096s
  training loss:		0.227650
  validation loss:		0.314468
  validation accuracy:		90.76 %
Epoch 419 of 2000 took 0.096s
  training loss:		0.221617
  validation loss:		0.311991
  validation accuracy:		90.76 %
Epoch 420 of 2000 took 0.096s
  training loss:		0.219636
  validation loss:		0.314988
  validation accuracy:		90.54 %
Epoch 421 of 2000 took 0.096s
  training loss:		0.220463
  validation loss:		0.320040
  validation accuracy:		90.54 %
Epoch 422 of 2000 took 0.096s
  training loss:		0.215321
  validation loss:		0.323216
  validation accuracy:		90.00 %
Epoch 423 of 2000 took 0.096s
  training loss:		0.218051
  validation loss:		0.310205
  validation accuracy:		90.65 %
Epoch 424 of 2000 took 0.096s
  training loss:		0.223248
  validation loss:		0.332668
  validation accuracy:		90.22 %
Epoch 425 of 2000 took 0.096s
  training loss:		0.228718
  validation loss:		0.316979
  validation accuracy:		90.54 %
Epoch 426 of 2000 took 0.096s
  training loss:		0.220383
  validation loss:		0.312244
  validation accuracy:		91.09 %
Epoch 427 of 2000 took 0.096s
  training loss:		0.218047
  validation loss:		0.315465
  validation accuracy:		90.76 %
Epoch 428 of 2000 took 0.096s
  training loss:		0.217686
  validation loss:		0.311615
  validation accuracy:		90.98 %
Epoch 429 of 2000 took 0.096s
  training loss:		0.218224
  validation loss:		0.324733
  validation accuracy:		90.54 %
Epoch 430 of 2000 took 0.096s
  training loss:		0.224043
  validation loss:		0.318958
  validation accuracy:		90.43 %
Epoch 431 of 2000 took 0.096s
  training loss:		0.221459
  validation loss:		0.315267
  validation accuracy:		90.65 %
Epoch 432 of 2000 took 0.096s
  training loss:		0.215518
  validation loss:		0.306092
  validation accuracy:		91.09 %
Epoch 433 of 2000 took 0.096s
  training loss:		0.219036
  validation loss:		0.304381
  validation accuracy:		91.41 %
Epoch 434 of 2000 took 0.096s
  training loss:		0.217754
  validation loss:		0.321421
  validation accuracy:		90.33 %
Epoch 435 of 2000 took 0.096s
  training loss:		0.220791
  validation loss:		0.314365
  validation accuracy:		90.76 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.221160
  validation loss:		0.308553
  validation accuracy:		90.98 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.216612
  validation loss:		0.316598
  validation accuracy:		90.33 %
Epoch 438 of 2000 took 0.096s
  training loss:		0.215492
  validation loss:		0.325302
  validation accuracy:		90.22 %
Epoch 439 of 2000 took 0.096s
  training loss:		0.217457
  validation loss:		0.311085
  validation accuracy:		91.20 %
Epoch 440 of 2000 took 0.096s
  training loss:		0.215963
  validation loss:		0.325014
  validation accuracy:		90.54 %
Epoch 441 of 2000 took 0.096s
  training loss:		0.220353
  validation loss:		0.312501
  validation accuracy:		90.65 %
Epoch 442 of 2000 took 0.096s
  training loss:		0.218099
  validation loss:		0.329393
  validation accuracy:		90.43 %
Epoch 443 of 2000 took 0.096s
  training loss:		0.217040
  validation loss:		0.312459
  validation accuracy:		91.20 %
Epoch 444 of 2000 took 0.096s
  training loss:		0.216531
  validation loss:		0.305479
  validation accuracy:		91.09 %
Epoch 445 of 2000 took 0.096s
  training loss:		0.214334
  validation loss:		0.311212
  validation accuracy:		90.98 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.219506
  validation loss:		0.310606
  validation accuracy:		91.41 %
Epoch 447 of 2000 took 0.096s
  training loss:		0.214793
  validation loss:		0.307691
  validation accuracy:		91.20 %
Epoch 448 of 2000 took 0.096s
  training loss:		0.215661
  validation loss:		0.309239
  validation accuracy:		90.87 %
Epoch 449 of 2000 took 0.096s
  training loss:		0.215853
  validation loss:		0.311904
  validation accuracy:		90.65 %
Epoch 450 of 2000 took 0.096s
  training loss:		0.212955
  validation loss:		0.331978
  validation accuracy:		90.00 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.210779
  validation loss:		0.319804
  validation accuracy:		90.76 %
Epoch 452 of 2000 took 0.096s
  training loss:		0.211724
  validation loss:		0.311457
  validation accuracy:		90.65 %
Epoch 453 of 2000 took 0.096s
  training loss:		0.212030
  validation loss:		0.312028
  validation accuracy:		90.87 %
Epoch 454 of 2000 took 0.096s
  training loss:		0.216881
  validation loss:		0.324997
  validation accuracy:		89.89 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.216618
  validation loss:		0.319972
  validation accuracy:		90.54 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.212140
  validation loss:		0.317170
  validation accuracy:		90.54 %
Epoch 457 of 2000 took 0.096s
  training loss:		0.214655
  validation loss:		0.313151
  validation accuracy:		90.98 %
Epoch 458 of 2000 took 0.096s
  training loss:		0.216158
  validation loss:		0.311568
  validation accuracy:		90.76 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.210953
  validation loss:		0.318579
  validation accuracy:		90.43 %
Epoch 460 of 2000 took 0.096s
  training loss:		0.208545
  validation loss:		0.309152
  validation accuracy:		90.76 %
Epoch 461 of 2000 took 0.096s
  training loss:		0.216146
  validation loss:		0.311475
  validation accuracy:		90.65 %
Epoch 462 of 2000 took 0.096s
  training loss:		0.210905
  validation loss:		0.323585
  validation accuracy:		90.22 %
Epoch 463 of 2000 took 0.096s
  training loss:		0.209552
  validation loss:		0.313540
  validation accuracy:		90.87 %
Epoch 464 of 2000 took 0.096s
  training loss:		0.209615
  validation loss:		0.309720
  validation accuracy:		90.87 %
Epoch 465 of 2000 took 0.099s
  training loss:		0.208741
  validation loss:		0.313096
  validation accuracy:		91.20 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.215920
  validation loss:		0.307995
  validation accuracy:		91.41 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.212048
  validation loss:		0.309890
  validation accuracy:		91.52 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.207362
  validation loss:		0.325677
  validation accuracy:		90.00 %
Epoch 469 of 2000 took 0.096s
  training loss:		0.211205
  validation loss:		0.309715
  validation accuracy:		90.65 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.208861
  validation loss:		0.312574
  validation accuracy:		90.87 %
Epoch 471 of 2000 took 0.096s
  training loss:		0.206903
  validation loss:		0.317708
  validation accuracy:		90.54 %
Epoch 472 of 2000 took 0.096s
  training loss:		0.213860
  validation loss:		0.317511
  validation accuracy:		90.98 %
Epoch 473 of 2000 took 0.096s
  training loss:		0.210717
  validation loss:		0.321384
  validation accuracy:		90.33 %
Epoch 474 of 2000 took 0.096s
  training loss:		0.210360
  validation loss:		0.318204
  validation accuracy:		90.54 %
Epoch 475 of 2000 took 0.096s
  training loss:		0.209486
  validation loss:		0.321625
  validation accuracy:		91.09 %
Epoch 476 of 2000 took 0.096s
  training loss:		0.207798
  validation loss:		0.316099
  validation accuracy:		91.52 %
Epoch 477 of 2000 took 0.096s
  training loss:		0.203905
  validation loss:		0.313009
  validation accuracy:		91.09 %
Epoch 478 of 2000 took 0.096s
  training loss:		0.212476
  validation loss:		0.312136
  validation accuracy:		90.76 %
Epoch 479 of 2000 took 0.096s
  training loss:		0.210898
  validation loss:		0.315597
  validation accuracy:		90.87 %
Epoch 480 of 2000 took 0.096s
  training loss:		0.209426
  validation loss:		0.320920
  validation accuracy:		90.54 %
Epoch 481 of 2000 took 0.096s
  training loss:		0.207515
  validation loss:		0.324980
  validation accuracy:		90.43 %
Epoch 482 of 2000 took 0.096s
  training loss:		0.205554
  validation loss:		0.321511
  validation accuracy:		90.54 %
Epoch 483 of 2000 took 0.096s
  training loss:		0.207605
  validation loss:		0.313971
  validation accuracy:		90.54 %
Epoch 484 of 2000 took 0.096s
  training loss:		0.210669
  validation loss:		0.314306
  validation accuracy:		90.65 %
Epoch 485 of 2000 took 0.096s
  training loss:		0.203942
  validation loss:		0.320266
  validation accuracy:		90.33 %
Epoch 486 of 2000 took 0.096s
  training loss:		0.203236
  validation loss:		0.316017
  validation accuracy:		90.54 %
Epoch 487 of 2000 took 0.096s
  training loss:		0.200699
  validation loss:		0.333962
  validation accuracy:		90.33 %
Epoch 488 of 2000 took 0.096s
  training loss:		0.208754
  validation loss:		0.314702
  validation accuracy:		90.43 %
Epoch 489 of 2000 took 0.096s
  training loss:		0.206627
  validation loss:		0.315864
  validation accuracy:		90.43 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.203224
  validation loss:		0.312162
  validation accuracy:		90.98 %
Epoch 491 of 2000 took 0.096s
  training loss:		0.205117
  validation loss:		0.324076
  validation accuracy:		90.87 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.206819
  validation loss:		0.315402
  validation accuracy:		90.98 %
Epoch 493 of 2000 took 0.096s
  training loss:		0.208410
  validation loss:		0.307781
  validation accuracy:		90.87 %
Epoch 494 of 2000 took 0.096s
  training loss:		0.205909
  validation loss:		0.331438
  validation accuracy:		89.78 %
Epoch 495 of 2000 took 0.096s
  training loss:		0.206021
  validation loss:		0.318005
  validation accuracy:		90.98 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.206121
  validation loss:		0.330826
  validation accuracy:		90.00 %
Epoch 497 of 2000 took 0.096s
  training loss:		0.201871
  validation loss:		0.311228
  validation accuracy:		91.20 %
Epoch 498 of 2000 took 0.096s
  training loss:		0.207739
  validation loss:		0.316451
  validation accuracy:		90.87 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.205777
  validation loss:		0.321236
  validation accuracy:		90.54 %
Epoch 500 of 2000 took 0.096s
  training loss:		0.201934
  validation loss:		0.320585
  validation accuracy:		90.00 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.199405
  validation loss:		0.317358
  validation accuracy:		90.65 %
Epoch 502 of 2000 took 0.096s
  training loss:		0.206187
  validation loss:		0.326690
  validation accuracy:		90.33 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.204676
  validation loss:		0.324481
  validation accuracy:		90.76 %
Epoch 504 of 2000 took 0.096s
  training loss:		0.196922
  validation loss:		0.323146
  validation accuracy:		90.54 %
Epoch 505 of 2000 took 0.096s
  training loss:		0.200933
  validation loss:		0.332111
  validation accuracy:		90.00 %
Epoch 506 of 2000 took 0.096s
  training loss:		0.212235
  validation loss:		0.325223
  validation accuracy:		90.22 %
Epoch 507 of 2000 took 0.096s
  training loss:		0.205900
  validation loss:		0.320552
  validation accuracy:		90.87 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.203096
  validation loss:		0.316314
  validation accuracy:		90.43 %
Epoch 509 of 2000 took 0.096s
  training loss:		0.206682
  validation loss:		0.318279
  validation accuracy:		90.54 %
Epoch 510 of 2000 took 0.096s
  training loss:		0.202883
  validation loss:		0.317413
  validation accuracy:		90.65 %
Epoch 511 of 2000 took 0.096s
  training loss:		0.203825
  validation loss:		0.311638
  validation accuracy:		91.09 %
Epoch 512 of 2000 took 0.096s
  training loss:		0.200541
  validation loss:		0.317500
  validation accuracy:		90.98 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.198067
  validation loss:		0.333842
  validation accuracy:		89.35 %
Epoch 514 of 2000 took 0.096s
  training loss:		0.196428
  validation loss:		0.313445
  validation accuracy:		90.98 %
Epoch 515 of 2000 took 0.096s
  training loss:		0.201241
  validation loss:		0.328010
  validation accuracy:		90.22 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.197460
  validation loss:		0.320824
  validation accuracy:		90.43 %
Epoch 517 of 2000 took 0.096s
  training loss:		0.201595
  validation loss:		0.326544
  validation accuracy:		90.00 %
Epoch 518 of 2000 took 0.096s
  training loss:		0.199652
  validation loss:		0.315505
  validation accuracy:		91.20 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.204650
  validation loss:		0.321320
  validation accuracy:		90.76 %
Epoch 520 of 2000 took 0.096s
  training loss:		0.198874
  validation loss:		0.319584
  validation accuracy:		91.20 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.202263
  validation loss:		0.326374
  validation accuracy:		90.33 %
Epoch 522 of 2000 took 0.096s
  training loss:		0.197206
  validation loss:		0.318374
  validation accuracy:		91.20 %
Epoch 523 of 2000 took 0.096s
  training loss:		0.200173
  validation loss:		0.309141
  validation accuracy:		90.98 %
Epoch 524 of 2000 took 0.096s
  training loss:		0.202372
  validation loss:		0.316772
  validation accuracy:		90.65 %
Epoch 525 of 2000 took 0.096s
  training loss:		0.201201
  validation loss:		0.316853
  validation accuracy:		90.76 %
Epoch 526 of 2000 took 0.096s
  training loss:		0.194781
  validation loss:		0.334801
  validation accuracy:		89.67 %
Epoch 527 of 2000 took 0.096s
  training loss:		0.200721
  validation loss:		0.313637
  validation accuracy:		90.98 %
Epoch 528 of 2000 took 0.096s
  training loss:		0.196728
  validation loss:		0.320759
  validation accuracy:		90.76 %
Epoch 529 of 2000 took 0.096s
  training loss:		0.199684
  validation loss:		0.329505
  validation accuracy:		90.33 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.197033
  validation loss:		0.325084
  validation accuracy:		89.78 %
Epoch 531 of 2000 took 0.096s
  training loss:		0.193834
  validation loss:		0.316879
  validation accuracy:		90.54 %
Epoch 532 of 2000 took 0.096s
  training loss:		0.198926
  validation loss:		0.320235
  validation accuracy:		90.43 %
Epoch 533 of 2000 took 0.096s
  training loss:		0.199574
  validation loss:		0.316460
  validation accuracy:		90.76 %
Epoch 534 of 2000 took 0.099s
  training loss:		0.198180
  validation loss:		0.322234
  validation accuracy:		90.54 %
Epoch 535 of 2000 took 0.096s
  training loss:		0.197281
  validation loss:		0.343035
  validation accuracy:		90.22 %
Epoch 536 of 2000 took 0.096s
  training loss:		0.204780
  validation loss:		0.322216
  validation accuracy:		91.30 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.195359
  validation loss:		0.321464
  validation accuracy:		90.54 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.197040
  validation loss:		0.319631
  validation accuracy:		90.76 %
Epoch 539 of 2000 took 0.096s
  training loss:		0.198167
  validation loss:		0.340566
  validation accuracy:		89.78 %
Epoch 540 of 2000 took 0.096s
  training loss:		0.202493
  validation loss:		0.320142
  validation accuracy:		90.43 %
Epoch 541 of 2000 took 0.096s
  training loss:		0.195080
  validation loss:		0.320751
  validation accuracy:		90.33 %
Epoch 542 of 2000 took 0.096s
  training loss:		0.199897
  validation loss:		0.317999
  validation accuracy:		90.54 %
Epoch 543 of 2000 took 0.096s
  training loss:		0.200235
  validation loss:		0.317729
  validation accuracy:		90.87 %
Epoch 544 of 2000 took 0.096s
  training loss:		0.197120
  validation loss:		0.325395
  validation accuracy:		90.33 %
Epoch 545 of 2000 took 0.096s
  training loss:		0.194301
  validation loss:		0.326959
  validation accuracy:		90.33 %
Epoch 546 of 2000 took 0.096s
  training loss:		0.194777
  validation loss:		0.327628
  validation accuracy:		90.00 %
Epoch 547 of 2000 took 0.096s
  training loss:		0.191590
  validation loss:		0.321937
  validation accuracy:		90.11 %
Epoch 548 of 2000 took 0.096s
  training loss:		0.195484
  validation loss:		0.324088
  validation accuracy:		90.54 %
Epoch 549 of 2000 took 0.096s
  training loss:		0.191992
  validation loss:		0.315179
  validation accuracy:		90.43 %
Epoch 550 of 2000 took 0.096s
  training loss:		0.195782
  validation loss:		0.330316
  validation accuracy:		90.65 %
Epoch 551 of 2000 took 0.096s
  training loss:		0.200502
  validation loss:		0.329772
  validation accuracy:		90.11 %
Epoch 552 of 2000 took 0.096s
  training loss:		0.197554
  validation loss:		0.323270
  validation accuracy:		90.43 %
Epoch 553 of 2000 took 0.096s
  training loss:		0.188751
  validation loss:		0.314406
  validation accuracy:		90.87 %
Epoch 554 of 2000 took 0.096s
  training loss:		0.192429
  validation loss:		0.315414
  validation accuracy:		91.20 %
Epoch 555 of 2000 took 0.096s
  training loss:		0.190191
  validation loss:		0.322552
  validation accuracy:		90.87 %
Epoch 556 of 2000 took 0.096s
  training loss:		0.197497
  validation loss:		0.315345
  validation accuracy:		90.87 %
Epoch 557 of 2000 took 0.096s
  training loss:		0.195813
  validation loss:		0.314457
  validation accuracy:		91.20 %
Epoch 558 of 2000 took 0.096s
  training loss:		0.191660
  validation loss:		0.319099
  validation accuracy:		91.41 %
Epoch 559 of 2000 took 0.096s
  training loss:		0.197560
  validation loss:		0.344864
  validation accuracy:		89.67 %
Epoch 560 of 2000 took 0.096s
  training loss:		0.195555
  validation loss:		0.317860
  validation accuracy:		90.65 %
Epoch 561 of 2000 took 0.096s
  training loss:		0.198404
  validation loss:		0.325317
  validation accuracy:		90.33 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.193758
  validation loss:		0.318993
  validation accuracy:		90.43 %
Epoch 563 of 2000 took 0.096s
  training loss:		0.194895
  validation loss:		0.320997
  validation accuracy:		90.65 %
Epoch 564 of 2000 took 0.096s
  training loss:		0.195359
  validation loss:		0.321274
  validation accuracy:		90.98 %
Epoch 565 of 2000 took 0.096s
  training loss:		0.188597
  validation loss:		0.322744
  validation accuracy:		90.43 %
Epoch 566 of 2000 took 0.096s
  training loss:		0.190551
  validation loss:		0.332311
  validation accuracy:		90.33 %
Epoch 567 of 2000 took 0.096s
  training loss:		0.192604
  validation loss:		0.323888
  validation accuracy:		90.98 %
Epoch 568 of 2000 took 0.096s
  training loss:		0.195433
  validation loss:		0.313744
  validation accuracy:		90.87 %
Epoch 569 of 2000 took 0.096s
  training loss:		0.194738
  validation loss:		0.323336
  validation accuracy:		90.43 %
Epoch 570 of 2000 took 0.096s
  training loss:		0.187286
  validation loss:		0.323413
  validation accuracy:		90.54 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.192945
  validation loss:		0.326247
  validation accuracy:		90.11 %
Epoch 572 of 2000 took 0.096s
  training loss:		0.193987
  validation loss:		0.325943
  validation accuracy:		90.00 %
Epoch 573 of 2000 took 0.096s
  training loss:		0.194029
  validation loss:		0.331625
  validation accuracy:		89.89 %
Epoch 574 of 2000 took 0.096s
  training loss:		0.187001
  validation loss:		0.331705
  validation accuracy:		89.78 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.190917
  validation loss:		0.320416
  validation accuracy:		90.43 %
Epoch 576 of 2000 took 0.096s
  training loss:		0.186192
  validation loss:		0.313580
  validation accuracy:		90.65 %
Epoch 577 of 2000 took 0.096s
  training loss:		0.191174
  validation loss:		0.323104
  validation accuracy:		90.65 %
Epoch 578 of 2000 took 0.096s
  training loss:		0.192807
  validation loss:		0.321701
  validation accuracy:		91.20 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.187774
  validation loss:		0.324912
  validation accuracy:		90.33 %
Epoch 580 of 2000 took 0.096s
  training loss:		0.194864
  validation loss:		0.328283
  validation accuracy:		90.22 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.193328
  validation loss:		0.322167
  validation accuracy:		90.87 %
Epoch 582 of 2000 took 0.096s
  training loss:		0.189164
  validation loss:		0.331602
  validation accuracy:		89.46 %
Epoch 583 of 2000 took 0.096s
  training loss:		0.186128
  validation loss:		0.329659
  validation accuracy:		90.00 %
Epoch 584 of 2000 took 0.096s
  training loss:		0.187848
  validation loss:		0.324226
  validation accuracy:		90.22 %
Epoch 585 of 2000 took 0.096s
  training loss:		0.194679
  validation loss:		0.315117
  validation accuracy:		91.09 %
Epoch 586 of 2000 took 0.096s
  training loss:		0.190636
  validation loss:		0.317505
  validation accuracy:		90.33 %
Epoch 587 of 2000 took 0.096s
  training loss:		0.189048
  validation loss:		0.333929
  validation accuracy:		90.11 %
Epoch 588 of 2000 took 0.096s
  training loss:		0.194668
  validation loss:		0.337480
  validation accuracy:		90.22 %
Epoch 589 of 2000 took 0.096s
  training loss:		0.189593
  validation loss:		0.335773
  validation accuracy:		89.57 %
Epoch 590 of 2000 took 0.096s
  training loss:		0.190084
  validation loss:		0.324307
  validation accuracy:		90.22 %
Epoch 591 of 2000 took 0.096s
  training loss:		0.191128
  validation loss:		0.332303
  validation accuracy:		90.33 %
Epoch 592 of 2000 took 0.096s
  training loss:		0.189930
  validation loss:		0.323247
  validation accuracy:		90.33 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.183780
  validation loss:		0.322981
  validation accuracy:		90.00 %
Epoch 594 of 2000 took 0.096s
  training loss:		0.193842
  validation loss:		0.316270
  validation accuracy:		90.76 %
Epoch 595 of 2000 took 0.096s
  training loss:		0.188471
  validation loss:		0.348652
  validation accuracy:		89.13 %
Epoch 596 of 2000 took 0.096s
  training loss:		0.186815
  validation loss:		0.320933
  validation accuracy:		91.30 %
Epoch 597 of 2000 took 0.096s
  training loss:		0.183738
  validation loss:		0.336781
  validation accuracy:		89.67 %
Epoch 598 of 2000 took 0.096s
  training loss:		0.184487
  validation loss:		0.336393
  validation accuracy:		89.57 %
Epoch 599 of 2000 took 0.096s
  training loss:		0.189100
  validation loss:		0.331877
  validation accuracy:		90.43 %
Epoch 600 of 2000 took 0.096s
  training loss:		0.186426
  validation loss:		0.328230
  validation accuracy:		90.33 %
Epoch 601 of 2000 took 0.096s
  training loss:		0.187576
  validation loss:		0.326773
  validation accuracy:		90.11 %
Epoch 602 of 2000 took 0.096s
  training loss:		0.183533
  validation loss:		0.317971
  validation accuracy:		90.87 %
Epoch 603 of 2000 took 0.096s
  training loss:		0.184000
  validation loss:		0.323761
  validation accuracy:		90.87 %
Epoch 604 of 2000 took 0.096s
  training loss:		0.186868
  validation loss:		0.324803
  validation accuracy:		90.76 %
Epoch 605 of 2000 took 0.096s
  training loss:		0.185689
  validation loss:		0.320922
  validation accuracy:		90.54 %
Epoch 606 of 2000 took 0.096s
  training loss:		0.185457
  validation loss:		0.318397
  validation accuracy:		90.98 %
Epoch 607 of 2000 took 0.096s
  training loss:		0.187907
  validation loss:		0.355051
  validation accuracy:		89.13 %
Epoch 608 of 2000 took 0.096s
  training loss:		0.193911
  validation loss:		0.327606
  validation accuracy:		90.76 %
Epoch 609 of 2000 took 0.099s
  training loss:		0.184188
  validation loss:		0.323480
  validation accuracy:		90.76 %
Epoch 610 of 2000 took 0.096s
  training loss:		0.185214
  validation loss:		0.322486
  validation accuracy:		90.65 %
Epoch 611 of 2000 took 0.096s
  training loss:		0.182715
  validation loss:		0.322296
  validation accuracy:		90.43 %
Epoch 612 of 2000 took 0.096s
  training loss:		0.183435
  validation loss:		0.313448
  validation accuracy:		90.98 %
Epoch 613 of 2000 took 0.096s
  training loss:		0.189597
  validation loss:		0.323680
  validation accuracy:		90.76 %
Epoch 614 of 2000 took 0.096s
  training loss:		0.179182
  validation loss:		0.320818
  validation accuracy:		90.76 %
Epoch 615 of 2000 took 0.096s
  training loss:		0.182513
  validation loss:		0.327563
  validation accuracy:		90.43 %
Epoch 616 of 2000 took 0.096s
  training loss:		0.182479
  validation loss:		0.324137
  validation accuracy:		90.43 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.185022
  validation loss:		0.333125
  validation accuracy:		90.54 %
Epoch 618 of 2000 took 0.096s
  training loss:		0.182611
  validation loss:		0.338507
  validation accuracy:		89.78 %
Epoch 619 of 2000 took 0.096s
  training loss:		0.186852
  validation loss:		0.326474
  validation accuracy:		90.22 %
Epoch 620 of 2000 took 0.097s
  training loss:		0.179736
  validation loss:		0.316277
  validation accuracy:		90.87 %
Epoch 621 of 2000 took 0.096s
  training loss:		0.178346
  validation loss:		0.331409
  validation accuracy:		89.89 %
Epoch 622 of 2000 took 0.096s
  training loss:		0.181375
  validation loss:		0.322152
  validation accuracy:		90.87 %
Epoch 623 of 2000 took 0.096s
  training loss:		0.187925
  validation loss:		0.337511
  validation accuracy:		90.11 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.184976
  validation loss:		0.330157
  validation accuracy:		90.11 %
Epoch 625 of 2000 took 0.097s
  training loss:		0.181918
  validation loss:		0.333992
  validation accuracy:		90.33 %
Epoch 626 of 2000 took 0.096s
  training loss:		0.182557
  validation loss:		0.322306
  validation accuracy:		90.65 %
Epoch 627 of 2000 took 0.096s
  training loss:		0.181999
  validation loss:		0.328004
  validation accuracy:		90.98 %
Epoch 628 of 2000 took 0.096s
  training loss:		0.183258
  validation loss:		0.320458
  validation accuracy:		90.98 %
Epoch 629 of 2000 took 0.096s
  training loss:		0.183342
  validation loss:		0.330773
  validation accuracy:		90.33 %
Epoch 630 of 2000 took 0.096s
  training loss:		0.181325
  validation loss:		0.333636
  validation accuracy:		90.33 %
Epoch 631 of 2000 took 0.096s
  training loss:		0.177701
  validation loss:		0.327648
  validation accuracy:		90.43 %
Epoch 632 of 2000 took 0.096s
  training loss:		0.183970
  validation loss:		0.322240
  validation accuracy:		90.65 %
Epoch 633 of 2000 took 0.096s
  training loss:		0.179265
  validation loss:		0.319007
  validation accuracy:		90.65 %
Epoch 634 of 2000 took 0.096s
  training loss:		0.186219
  validation loss:		0.320286
  validation accuracy:		90.54 %
Epoch 635 of 2000 took 0.096s
  training loss:		0.181418
  validation loss:		0.319202
  validation accuracy:		90.87 %
Epoch 636 of 2000 took 0.096s
  training loss:		0.180407
  validation loss:		0.323972
  validation accuracy:		90.65 %
Epoch 637 of 2000 took 0.096s
  training loss:		0.183665
  validation loss:		0.333873
  validation accuracy:		90.22 %
Epoch 638 of 2000 took 0.096s
  training loss:		0.174990
  validation loss:		0.326579
  validation accuracy:		90.65 %
Epoch 639 of 2000 took 0.096s
  training loss:		0.178617
  validation loss:		0.318935
  validation accuracy:		90.98 %
Epoch 640 of 2000 took 0.096s
  training loss:		0.173964
  validation loss:		0.333209
  validation accuracy:		90.11 %
Epoch 641 of 2000 took 0.096s
  training loss:		0.179454
  validation loss:		0.338735
  validation accuracy:		90.00 %
Epoch 642 of 2000 took 0.096s
  training loss:		0.181948
  validation loss:		0.322813
  validation accuracy:		90.98 %
Epoch 643 of 2000 took 0.096s
  training loss:		0.177661
  validation loss:		0.328018
  validation accuracy:		90.65 %
Epoch 644 of 2000 took 0.096s
  training loss:		0.171735
  validation loss:		0.324577
  validation accuracy:		90.87 %
Epoch 645 of 2000 took 0.096s
  training loss:		0.175062
  validation loss:		0.329596
  validation accuracy:		90.11 %
Epoch 646 of 2000 took 0.096s
  training loss:		0.180546
  validation loss:		0.321939
  validation accuracy:		90.87 %
Epoch 647 of 2000 took 0.096s
  training loss:		0.176035
  validation loss:		0.317847
  validation accuracy:		90.76 %
Epoch 648 of 2000 took 0.096s
  training loss:		0.179862
  validation loss:		0.330055
  validation accuracy:		90.98 %
Epoch 649 of 2000 took 0.096s
  training loss:		0.179427
  validation loss:		0.325635
  validation accuracy:		90.43 %
Epoch 650 of 2000 took 0.096s
  training loss:		0.180644
  validation loss:		0.323359
  validation accuracy:		90.87 %
Epoch 651 of 2000 took 0.096s
  training loss:		0.179514
  validation loss:		0.332030
  validation accuracy:		90.22 %
Epoch 652 of 2000 took 0.096s
  training loss:		0.172335
  validation loss:		0.321559
  validation accuracy:		91.09 %
Epoch 653 of 2000 took 0.096s
  training loss:		0.178773
  validation loss:		0.333777
  validation accuracy:		90.22 %
Epoch 654 of 2000 took 0.096s
  training loss:		0.177022
  validation loss:		0.326213
  validation accuracy:		90.76 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.179132
  validation loss:		0.323216
  validation accuracy:		90.54 %
Epoch 656 of 2000 took 0.096s
  training loss:		0.182049
  validation loss:		0.323216
  validation accuracy:		90.65 %
Epoch 657 of 2000 took 0.096s
  training loss:		0.173990
  validation loss:		0.331574
  validation accuracy:		90.22 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.173578
  validation loss:		0.322232
  validation accuracy:		91.30 %
Epoch 659 of 2000 took 0.096s
  training loss:		0.177671
  validation loss:		0.322288
  validation accuracy:		90.54 %
Epoch 660 of 2000 took 0.096s
  training loss:		0.176623
  validation loss:		0.333647
  validation accuracy:		90.22 %
Epoch 661 of 2000 took 0.096s
  training loss:		0.177915
  validation loss:		0.320423
  validation accuracy:		90.54 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.177735
  validation loss:		0.325576
  validation accuracy:		90.98 %
Epoch 663 of 2000 took 0.096s
  training loss:		0.175404
  validation loss:		0.324736
  validation accuracy:		90.65 %
Epoch 664 of 2000 took 0.096s
  training loss:		0.174174
  validation loss:		0.322789
  validation accuracy:		90.65 %
Epoch 665 of 2000 took 0.096s
  training loss:		0.175631
  validation loss:		0.321338
  validation accuracy:		90.65 %
Epoch 666 of 2000 took 0.096s
  training loss:		0.175263
  validation loss:		0.322091
  validation accuracy:		90.87 %
Epoch 667 of 2000 took 0.096s
  training loss:		0.170835
  validation loss:		0.330448
  validation accuracy:		90.98 %
Epoch 668 of 2000 took 0.096s
  training loss:		0.170842
  validation loss:		0.325654
  validation accuracy:		90.76 %
Epoch 669 of 2000 took 0.096s
  training loss:		0.177696
  validation loss:		0.325977
  validation accuracy:		91.74 %
Epoch 670 of 2000 took 0.096s
  training loss:		0.178751
  validation loss:		0.324227
  validation accuracy:		90.76 %
Epoch 671 of 2000 took 0.096s
  training loss:		0.171956
  validation loss:		0.329546
  validation accuracy:		90.54 %
Epoch 672 of 2000 took 0.096s
  training loss:		0.179068
  validation loss:		0.334534
  validation accuracy:		90.11 %
Epoch 673 of 2000 took 0.096s
  training loss:		0.170136
  validation loss:		0.332647
  validation accuracy:		90.43 %
Epoch 674 of 2000 took 0.096s
  training loss:		0.174140
  validation loss:		0.323220
  validation accuracy:		90.65 %
Epoch 675 of 2000 took 0.096s
  training loss:		0.172692
  validation loss:		0.324246
  validation accuracy:		90.65 %
Epoch 676 of 2000 took 0.096s
  training loss:		0.173557
  validation loss:		0.325766
  validation accuracy:		90.65 %
Epoch 677 of 2000 took 0.096s
  training loss:		0.178267
  validation loss:		0.333897
  validation accuracy:		90.11 %
Epoch 678 of 2000 took 0.096s
  training loss:		0.176172
  validation loss:		0.328883
  validation accuracy:		90.33 %
Epoch 679 of 2000 took 0.096s
  training loss:		0.171242
  validation loss:		0.348312
  validation accuracy:		89.78 %
Epoch 680 of 2000 took 0.096s
  training loss:		0.178619
  validation loss:		0.336873
  validation accuracy:		89.67 %
Epoch 681 of 2000 took 0.096s
  training loss:		0.167382
  validation loss:		0.333434
  validation accuracy:		90.33 %
Epoch 682 of 2000 took 0.096s
  training loss:		0.171217
  validation loss:		0.326938
  validation accuracy:		90.54 %
Epoch 683 of 2000 took 0.096s
  training loss:		0.171516
  validation loss:		0.333537
  validation accuracy:		90.11 %
Epoch 684 of 2000 took 0.096s
  training loss:		0.166605
  validation loss:		0.333095
  validation accuracy:		90.76 %
Epoch 685 of 2000 took 0.096s
  training loss:		0.175077
  validation loss:		0.332043
  validation accuracy:		90.11 %
Epoch 686 of 2000 took 0.096s
  training loss:		0.172455
  validation loss:		0.327328
  validation accuracy:		90.33 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.168720
  validation loss:		0.324430
  validation accuracy:		90.54 %
Epoch 688 of 2000 took 0.096s
  training loss:		0.170385
  validation loss:		0.332296
  validation accuracy:		90.33 %
Epoch 689 of 2000 took 0.096s
  training loss:		0.172382
  validation loss:		0.332391
  validation accuracy:		90.87 %
Epoch 690 of 2000 took 0.096s
  training loss:		0.165236
  validation loss:		0.328290
  validation accuracy:		90.43 %
Epoch 691 of 2000 took 0.096s
  training loss:		0.171946
  validation loss:		0.357482
  validation accuracy:		89.35 %
Epoch 692 of 2000 took 0.096s
  training loss:		0.172668
  validation loss:		0.319724
  validation accuracy:		90.98 %
Epoch 693 of 2000 took 0.096s
  training loss:		0.168431
  validation loss:		0.329949
  validation accuracy:		90.22 %
Epoch 694 of 2000 took 0.096s
  training loss:		0.174048
  validation loss:		0.326618
  validation accuracy:		90.43 %
Epoch 695 of 2000 took 0.097s
  training loss:		0.173185
  validation loss:		0.328657
  validation accuracy:		90.65 %
Epoch 696 of 2000 took 0.096s
  training loss:		0.171674
  validation loss:		0.340516
  validation accuracy:		90.00 %
Epoch 697 of 2000 took 0.096s
  training loss:		0.171562
  validation loss:		0.324526
  validation accuracy:		90.87 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.164858
  validation loss:		0.325364
  validation accuracy:		90.65 %
Epoch 699 of 2000 took 0.099s
  training loss:		0.173677
  validation loss:		0.334200
  validation accuracy:		90.98 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.170153
  validation loss:		0.328907
  validation accuracy:		90.33 %
Epoch 701 of 2000 took 0.096s
  training loss:		0.168006
  validation loss:		0.344396
  validation accuracy:		89.78 %
Epoch 702 of 2000 took 0.096s
  training loss:		0.158961
  validation loss:		0.328993
  validation accuracy:		90.43 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.174381
  validation loss:		0.341228
  validation accuracy:		90.22 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.170144
  validation loss:		0.331376
  validation accuracy:		90.54 %
Epoch 705 of 2000 took 0.096s
  training loss:		0.165081
  validation loss:		0.328814
  validation accuracy:		90.43 %
Epoch 706 of 2000 took 0.096s
  training loss:		0.168177
  validation loss:		0.332928
  validation accuracy:		90.11 %
Epoch 707 of 2000 took 0.096s
  training loss:		0.173843
  validation loss:		0.329500
  validation accuracy:		90.87 %
Epoch 708 of 2000 took 0.096s
  training loss:		0.171431
  validation loss:		0.337532
  validation accuracy:		90.22 %
Epoch 709 of 2000 took 0.096s
  training loss:		0.171327
  validation loss:		0.329934
  validation accuracy:		90.43 %
Epoch 710 of 2000 took 0.096s
  training loss:		0.170721
  validation loss:		0.332852
  validation accuracy:		91.20 %
Epoch 711 of 2000 took 0.096s
  training loss:		0.169240
  validation loss:		0.328192
  validation accuracy:		90.43 %
Epoch 712 of 2000 took 0.096s
  training loss:		0.174559
  validation loss:		0.326553
  validation accuracy:		90.87 %
Epoch 713 of 2000 took 0.096s
  training loss:		0.171075
  validation loss:		0.332407
  validation accuracy:		90.43 %
Epoch 714 of 2000 took 0.096s
  training loss:		0.166473
  validation loss:		0.326921
  validation accuracy:		90.65 %
Epoch 715 of 2000 took 0.096s
  training loss:		0.167253
  validation loss:		0.330540
  validation accuracy:		90.65 %
Epoch 716 of 2000 took 0.096s
  training loss:		0.170728
  validation loss:		0.324276
  validation accuracy:		90.76 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.166697
  validation loss:		0.336811
  validation accuracy:		90.33 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.170719
  validation loss:		0.330201
  validation accuracy:		90.54 %
Epoch 719 of 2000 took 0.096s
  training loss:		0.165497
  validation loss:		0.331121
  validation accuracy:		90.33 %
Epoch 720 of 2000 took 0.096s
  training loss:		0.165218
  validation loss:		0.338180
  validation accuracy:		90.43 %
Epoch 721 of 2000 took 0.096s
  training loss:		0.167686
  validation loss:		0.329482
  validation accuracy:		90.87 %
Epoch 722 of 2000 took 0.096s
  training loss:		0.169809
  validation loss:		0.326085
  validation accuracy:		90.65 %
Epoch 723 of 2000 took 0.096s
  training loss:		0.161925
  validation loss:		0.332394
  validation accuracy:		90.54 %
Epoch 724 of 2000 took 0.096s
  training loss:		0.166140
  validation loss:		0.330095
  validation accuracy:		90.87 %
Epoch 725 of 2000 took 0.096s
  training loss:		0.160940
  validation loss:		0.330987
  validation accuracy:		90.76 %
Epoch 726 of 2000 took 0.096s
  training loss:		0.167136
  validation loss:		0.326350
  validation accuracy:		90.98 %
Epoch 727 of 2000 took 0.096s
  training loss:		0.165215
  validation loss:		0.339871
  validation accuracy:		90.76 %
Epoch 728 of 2000 took 0.096s
  training loss:		0.159131
  validation loss:		0.347047
  validation accuracy:		90.11 %
Epoch 729 of 2000 took 0.096s
  training loss:		0.166085
  validation loss:		0.329722
  validation accuracy:		91.09 %
Epoch 730 of 2000 took 0.096s
  training loss:		0.161215
  validation loss:		0.324860
  validation accuracy:		90.76 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.163075
  validation loss:		0.339049
  validation accuracy:		90.22 %
Epoch 732 of 2000 took 0.096s
  training loss:		0.165495
  validation loss:		0.326703
  validation accuracy:		90.98 %
Epoch 733 of 2000 took 0.096s
  training loss:		0.162649
  validation loss:		0.330823
  validation accuracy:		91.09 %
Epoch 734 of 2000 took 0.096s
  training loss:		0.166442
  validation loss:		0.336205
  validation accuracy:		90.43 %
Epoch 735 of 2000 took 0.096s
  training loss:		0.162544
  validation loss:		0.320441
  validation accuracy:		91.09 %
Epoch 736 of 2000 took 0.096s
  training loss:		0.161396
  validation loss:		0.322835
  validation accuracy:		90.87 %
Epoch 737 of 2000 took 0.096s
  training loss:		0.170152
  validation loss:		0.325223
  validation accuracy:		90.87 %
Epoch 738 of 2000 took 0.096s
  training loss:		0.167625
  validation loss:		0.331913
  validation accuracy:		90.87 %
Epoch 739 of 2000 took 0.096s
  training loss:		0.163888
  validation loss:		0.332663
  validation accuracy:		90.65 %
Epoch 740 of 2000 took 0.096s
  training loss:		0.163074
  validation loss:		0.328861
  validation accuracy:		90.65 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.160310
  validation loss:		0.327637
  validation accuracy:		90.54 %
Epoch 742 of 2000 took 0.096s
  training loss:		0.159864
  validation loss:		0.323894
  validation accuracy:		91.20 %
Epoch 743 of 2000 took 0.096s
  training loss:		0.162078
  validation loss:		0.322656
  validation accuracy:		90.87 %
Epoch 744 of 2000 took 0.096s
  training loss:		0.162170
  validation loss:		0.334999
  validation accuracy:		90.11 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.163799
  validation loss:		0.329692
  validation accuracy:		90.87 %
Epoch 746 of 2000 took 0.096s
  training loss:		0.159988
  validation loss:		0.328037
  validation accuracy:		90.87 %
Epoch 747 of 2000 took 0.096s
  training loss:		0.162636
  validation loss:		0.339478
  validation accuracy:		90.54 %
Epoch 748 of 2000 took 0.096s
  training loss:		0.161441
  validation loss:		0.350634
  validation accuracy:		90.00 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.166587
  validation loss:		0.334480
  validation accuracy:		91.63 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.163648
  validation loss:		0.324664
  validation accuracy:		91.30 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.159519
  validation loss:		0.326015
  validation accuracy:		90.76 %
Epoch 752 of 2000 took 0.096s
  training loss:		0.157446
  validation loss:		0.325462
  validation accuracy:		90.98 %
Epoch 753 of 2000 took 0.096s
  training loss:		0.159170
  validation loss:		0.326545
  validation accuracy:		90.98 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.159242
  validation loss:		0.329630
  validation accuracy:		90.98 %
Epoch 755 of 2000 took 0.096s
  training loss:		0.160613
  validation loss:		0.322345
  validation accuracy:		91.09 %
Epoch 756 of 2000 took 0.096s
  training loss:		0.159200
  validation loss:		0.328986
  validation accuracy:		90.54 %
Epoch 757 of 2000 took 0.096s
  training loss:		0.157854
  validation loss:		0.328197
  validation accuracy:		90.98 %
Epoch 758 of 2000 took 0.096s
  training loss:		0.156773
  validation loss:		0.331695
  validation accuracy:		90.76 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.163722
  validation loss:		0.329993
  validation accuracy:		91.30 %
Epoch 760 of 2000 took 0.096s
  training loss:		0.153695
  validation loss:		0.334968
  validation accuracy:		90.76 %
Epoch 761 of 2000 took 0.096s
  training loss:		0.159043
  validation loss:		0.330297
  validation accuracy:		90.87 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.160416
  validation loss:		0.344499
  validation accuracy:		90.00 %
Epoch 763 of 2000 took 0.096s
  training loss:		0.158682
  validation loss:		0.329559
  validation accuracy:		90.65 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.157596
  validation loss:		0.340264
  validation accuracy:		90.54 %
Epoch 765 of 2000 took 0.096s
  training loss:		0.160006
  validation loss:		0.340277
  validation accuracy:		90.65 %
Epoch 766 of 2000 took 0.096s
  training loss:		0.159724
  validation loss:		0.330326
  validation accuracy:		90.43 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.162317
  validation loss:		0.335659
  validation accuracy:		90.33 %
Epoch 768 of 2000 took 0.096s
  training loss:		0.160134
  validation loss:		0.330038
  validation accuracy:		91.20 %
Epoch 769 of 2000 took 0.096s
  training loss:		0.161794
  validation loss:		0.338211
  validation accuracy:		90.54 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.157725
  validation loss:		0.331166
  validation accuracy:		91.41 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.160154
  validation loss:		0.336269
  validation accuracy:		90.54 %
Epoch 772 of 2000 took 0.096s
  training loss:		0.160239
  validation loss:		0.357797
  validation accuracy:		89.78 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.159221
  validation loss:		0.336039
  validation accuracy:		90.54 %
Epoch 774 of 2000 took 0.096s
  training loss:		0.158643
  validation loss:		0.336566
  validation accuracy:		90.65 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.154423
  validation loss:		0.340554
  validation accuracy:		90.43 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.159853
  validation loss:		0.331350
  validation accuracy:		90.98 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.158418
  validation loss:		0.328872
  validation accuracy:		91.09 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.161066
  validation loss:		0.340507
  validation accuracy:		90.33 %
Epoch 779 of 2000 took 0.096s
  training loss:		0.158340
  validation loss:		0.344856
  validation accuracy:		89.67 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.157544
  validation loss:		0.335206
  validation accuracy:		90.98 %
Epoch 781 of 2000 took 0.096s
  training loss:		0.156705
  validation loss:		0.327633
  validation accuracy:		91.09 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.154684
  validation loss:		0.327933
  validation accuracy:		90.98 %
Epoch 783 of 2000 took 0.096s
  training loss:		0.155972
  validation loss:		0.330945
  validation accuracy:		90.87 %
Epoch 784 of 2000 took 0.096s
  training loss:		0.158066
  validation loss:		0.341199
  validation accuracy:		90.65 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.156859
  validation loss:		0.336477
  validation accuracy:		90.54 %
Epoch 786 of 2000 took 0.096s
  training loss:		0.154065
  validation loss:		0.345766
  validation accuracy:		90.11 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.155023
  validation loss:		0.342027
  validation accuracy:		90.65 %
Epoch 788 of 2000 took 0.096s
  training loss:		0.150441
  validation loss:		0.331855
  validation accuracy:		91.30 %
Epoch 789 of 2000 took 0.096s
  training loss:		0.158727
  validation loss:		0.339399
  validation accuracy:		90.65 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.150710
  validation loss:		0.327534
  validation accuracy:		91.30 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.156727
  validation loss:		0.341799
  validation accuracy:		90.54 %
Epoch 792 of 2000 took 0.096s
  training loss:		0.150692
  validation loss:		0.323137
  validation accuracy:		92.07 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.157006
  validation loss:		0.326334
  validation accuracy:		91.52 %
Epoch 794 of 2000 took 0.096s
  training loss:		0.155317
  validation loss:		0.338650
  validation accuracy:		90.54 %
Epoch 795 of 2000 took 0.096s
  training loss:		0.154503
  validation loss:		0.335859
  validation accuracy:		90.87 %
Epoch 796 of 2000 took 0.096s
  training loss:		0.155039
  validation loss:		0.332532
  validation accuracy:		91.20 %
Epoch 797 of 2000 took 0.096s
  training loss:		0.156743
  validation loss:		0.338628
  validation accuracy:		90.87 %
Epoch 798 of 2000 took 0.096s
  training loss:		0.150998
  validation loss:		0.333595
  validation accuracy:		90.87 %
Epoch 799 of 2000 took 0.096s
  training loss:		0.149623
  validation loss:		0.341735
  validation accuracy:		90.65 %
Epoch 800 of 2000 took 0.096s
  training loss:		0.151337
  validation loss:		0.330729
  validation accuracy:		90.87 %
Epoch 801 of 2000 took 0.096s
  training loss:		0.157054
  validation loss:		0.336734
  validation accuracy:		90.87 %
Epoch 802 of 2000 took 0.096s
  training loss:		0.155010
  validation loss:		0.335243
  validation accuracy:		90.76 %
Epoch 803 of 2000 took 0.096s
  training loss:		0.152142
  validation loss:		0.341591
  validation accuracy:		90.33 %
Epoch 804 of 2000 took 0.096s
  training loss:		0.148334
  validation loss:		0.333911
  validation accuracy:		91.09 %
Epoch 805 of 2000 took 0.096s
  training loss:		0.149725
  validation loss:		0.339789
  validation accuracy:		90.65 %
Epoch 806 of 2000 took 0.096s
  training loss:		0.151463
  validation loss:		0.336123
  validation accuracy:		90.54 %
Epoch 807 of 2000 took 0.096s
  training loss:		0.149881
  validation loss:		0.346597
  validation accuracy:		90.76 %
Epoch 808 of 2000 took 0.099s
  training loss:		0.158304
  validation loss:		0.342964
  validation accuracy:		90.65 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.151295
  validation loss:		0.345794
  validation accuracy:		90.43 %
Epoch 810 of 2000 took 0.096s
  training loss:		0.156000
  validation loss:		0.339448
  validation accuracy:		90.54 %
Epoch 811 of 2000 took 0.096s
  training loss:		0.159064
  validation loss:		0.336896
  validation accuracy:		90.54 %
Epoch 812 of 2000 took 0.097s
  training loss:		0.149549
  validation loss:		0.336178
  validation accuracy:		91.30 %
Epoch 813 of 2000 took 0.096s
  training loss:		0.151470
  validation loss:		0.336574
  validation accuracy:		90.76 %
Epoch 814 of 2000 took 0.096s
  training loss:		0.151842
  validation loss:		0.338422
  validation accuracy:		90.76 %
Epoch 815 of 2000 took 0.096s
  training loss:		0.154218
  validation loss:		0.347432
  validation accuracy:		90.22 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.148565
  validation loss:		0.335793
  validation accuracy:		90.87 %
Epoch 817 of 2000 took 0.096s
  training loss:		0.148064
  validation loss:		0.341061
  validation accuracy:		90.87 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.148953
  validation loss:		0.341313
  validation accuracy:		90.76 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.146058
  validation loss:		0.337319
  validation accuracy:		90.54 %
Epoch 820 of 2000 took 0.096s
  training loss:		0.149792
  validation loss:		0.335175
  validation accuracy:		90.76 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.149486
  validation loss:		0.333799
  validation accuracy:		90.98 %
Epoch 822 of 2000 took 0.096s
  training loss:		0.145752
  validation loss:		0.336149
  validation accuracy:		91.20 %
Epoch 823 of 2000 took 0.096s
  training loss:		0.154229
  validation loss:		0.343313
  validation accuracy:		90.76 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.150633
  validation loss:		0.334641
  validation accuracy:		91.30 %
Epoch 825 of 2000 took 0.096s
  training loss:		0.148111
  validation loss:		0.354642
  validation accuracy:		89.89 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.148860
  validation loss:		0.339968
  validation accuracy:		90.54 %
Epoch 827 of 2000 took 0.096s
  training loss:		0.153602
  validation loss:		0.341688
  validation accuracy:		90.43 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.146742
  validation loss:		0.335479
  validation accuracy:		90.98 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.148142
  validation loss:		0.357979
  validation accuracy:		90.22 %
Epoch 830 of 2000 took 0.096s
  training loss:		0.149008
  validation loss:		0.339762
  validation accuracy:		90.43 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.154498
  validation loss:		0.345389
  validation accuracy:		90.54 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.146634
  validation loss:		0.344483
  validation accuracy:		90.33 %
Epoch 833 of 2000 took 0.096s
  training loss:		0.147899
  validation loss:		0.343270
  validation accuracy:		90.54 %
Epoch 834 of 2000 took 0.096s
  training loss:		0.151948
  validation loss:		0.340578
  validation accuracy:		90.65 %
Epoch 835 of 2000 took 0.096s
  training loss:		0.148902
  validation loss:		0.352207
  validation accuracy:		90.54 %
Epoch 836 of 2000 took 0.096s
  training loss:		0.146162
  validation loss:		0.334688
  validation accuracy:		91.63 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.151911
  validation loss:		0.341734
  validation accuracy:		90.54 %
Epoch 838 of 2000 took 0.096s
  training loss:		0.146984
  validation loss:		0.343751
  validation accuracy:		90.43 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.144143
  validation loss:		0.341299
  validation accuracy:		90.65 %
Epoch 840 of 2000 took 0.096s
  training loss:		0.146414
  validation loss:		0.343819
  validation accuracy:		90.76 %
Epoch 841 of 2000 took 0.096s
  training loss:		0.145297
  validation loss:		0.359205
  validation accuracy:		89.78 %
Epoch 842 of 2000 took 0.096s
  training loss:		0.148685
  validation loss:		0.344031
  validation accuracy:		90.54 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.153300
  validation loss:		0.348013
  validation accuracy:		90.43 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.146547
  validation loss:		0.348657
  validation accuracy:		90.54 %
Epoch 845 of 2000 took 0.096s
  training loss:		0.145484
  validation loss:		0.361824
  validation accuracy:		90.33 %
Epoch 846 of 2000 took 0.096s
  training loss:		0.148035
  validation loss:		0.345252
  validation accuracy:		90.76 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.146805
  validation loss:		0.355247
  validation accuracy:		90.43 %
Epoch 848 of 2000 took 0.096s
  training loss:		0.143897
  validation loss:		0.344789
  validation accuracy:		90.98 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.144655
  validation loss:		0.355046
  validation accuracy:		90.33 %
Epoch 850 of 2000 took 0.096s
  training loss:		0.144483
  validation loss:		0.345834
  validation accuracy:		90.54 %
Epoch 851 of 2000 took 0.096s
  training loss:		0.143894
  validation loss:		0.348131
  validation accuracy:		90.33 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.145673
  validation loss:		0.352625
  validation accuracy:		90.65 %
Epoch 853 of 2000 took 0.096s
  training loss:		0.143339
  validation loss:		0.332964
  validation accuracy:		91.09 %
Epoch 854 of 2000 took 0.096s
  training loss:		0.145224
  validation loss:		0.342251
  validation accuracy:		90.65 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.140643
  validation loss:		0.344235
  validation accuracy:		90.54 %
Epoch 856 of 2000 took 0.096s
  training loss:		0.143371
  validation loss:		0.367852
  validation accuracy:		90.22 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.151397
  validation loss:		0.353532
  validation accuracy:		90.00 %
Epoch 858 of 2000 took 0.096s
  training loss:		0.147555
  validation loss:		0.350282
  validation accuracy:		90.00 %
Epoch 859 of 2000 took 0.096s
  training loss:		0.142756
  validation loss:		0.342077
  validation accuracy:		90.54 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.137486
  validation loss:		0.342503
  validation accuracy:		91.09 %
Epoch 861 of 2000 took 0.096s
  training loss:		0.138939
  validation loss:		0.352155
  validation accuracy:		90.00 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.144815
  validation loss:		0.346861
  validation accuracy:		90.43 %
Epoch 863 of 2000 took 0.103s
  training loss:		0.141859
  validation loss:		0.339407
  validation accuracy:		90.87 %
Epoch 864 of 2000 took 0.112s
  training loss:		0.138843
  validation loss:		0.342766
  validation accuracy:		90.65 %
Epoch 865 of 2000 took 0.159s
  training loss:		0.143754
  validation loss:		0.342608
  validation accuracy:		90.87 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.136014
  validation loss:		0.355820
  validation accuracy:		90.33 %
Epoch 867 of 2000 took 0.101s
  training loss:		0.144292
  validation loss:		0.368086
  validation accuracy:		89.67 %
Epoch 868 of 2000 took 0.102s
  training loss:		0.142021
  validation loss:		0.343931
  validation accuracy:		90.98 %
Epoch 869 of 2000 took 0.101s
  training loss:		0.140838
  validation loss:		0.364423
  validation accuracy:		89.78 %
Epoch 870 of 2000 took 0.100s
  training loss:		0.138713
  validation loss:		0.350468
  validation accuracy:		90.33 %
Epoch 871 of 2000 took 0.099s
  training loss:		0.141689
  validation loss:		0.366302
  validation accuracy:		90.33 %
Epoch 872 of 2000 took 0.096s
  training loss:		0.137625
  validation loss:		0.344805
  validation accuracy:		90.65 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.139547
  validation loss:		0.347629
  validation accuracy:		90.54 %
Epoch 874 of 2000 took 0.096s
  training loss:		0.143390
  validation loss:		0.361792
  validation accuracy:		90.00 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.142867
  validation loss:		0.348455
  validation accuracy:		90.54 %
Epoch 876 of 2000 took 0.096s
  training loss:		0.138856
  validation loss:		0.345793
  validation accuracy:		90.76 %
Epoch 877 of 2000 took 0.096s
  training loss:		0.139877
  validation loss:		0.345689
  validation accuracy:		90.98 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.137242
  validation loss:		0.351867
  validation accuracy:		90.43 %
Epoch 879 of 2000 took 0.096s
  training loss:		0.141034
  validation loss:		0.340855
  validation accuracy:		91.09 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.134375
  validation loss:		0.347599
  validation accuracy:		90.54 %
Epoch 881 of 2000 took 0.096s
  training loss:		0.134471
  validation loss:		0.362025
  validation accuracy:		90.33 %
Epoch 882 of 2000 took 0.096s
  training loss:		0.138171
  validation loss:		0.353051
  validation accuracy:		90.43 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.141099
  validation loss:		0.353788
  validation accuracy:		90.65 %
Epoch 884 of 2000 took 0.096s
  training loss:		0.138215
  validation loss:		0.361120
  validation accuracy:		89.78 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.138534
  validation loss:		0.342544
  validation accuracy:		91.30 %
Epoch 886 of 2000 took 0.096s
  training loss:		0.140803
  validation loss:		0.353189
  validation accuracy:		90.65 %
Epoch 887 of 2000 took 0.096s
  training loss:		0.139703
  validation loss:		0.353966
  validation accuracy:		89.89 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.139167
  validation loss:		0.345574
  validation accuracy:		90.87 %
Epoch 889 of 2000 took 0.096s
  training loss:		0.135787
  validation loss:		0.355377
  validation accuracy:		90.98 %
Epoch 890 of 2000 took 0.096s
  training loss:		0.134906
  validation loss:		0.357355
  validation accuracy:		90.33 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.141355
  validation loss:		0.361965
  validation accuracy:		90.33 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.141704
  validation loss:		0.364573
  validation accuracy:		90.33 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.144789
  validation loss:		0.348734
  validation accuracy:		90.87 %
Epoch 894 of 2000 took 0.096s
  training loss:		0.136983
  validation loss:		0.347208
  validation accuracy:		90.65 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.132876
  validation loss:		0.345487
  validation accuracy:		90.65 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.138392
  validation loss:		0.353045
  validation accuracy:		90.54 %
Epoch 897 of 2000 took 0.096s
  training loss:		0.137848
  validation loss:		0.348899
  validation accuracy:		90.76 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.141063
  validation loss:		0.363263
  validation accuracy:		90.65 %
Epoch 899 of 2000 took 0.096s
  training loss:		0.136865
  validation loss:		0.354653
  validation accuracy:		91.30 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.137869
  validation loss:		0.357159
  validation accuracy:		90.65 %
Epoch 901 of 2000 took 0.097s
  training loss:		0.140661
  validation loss:		0.359132
  validation accuracy:		90.87 %
Epoch 902 of 2000 took 0.096s
  training loss:		0.134827
  validation loss:		0.346274
  validation accuracy:		90.65 %
Epoch 903 of 2000 took 0.098s
  training loss:		0.136190
  validation loss:		0.356457
  validation accuracy:		91.85 %
Epoch 904 of 2000 took 0.097s
  training loss:		0.139003
  validation loss:		0.358192
  validation accuracy:		90.76 %
Epoch 905 of 2000 took 0.096s
  training loss:		0.133472
  validation loss:		0.350582
  validation accuracy:		90.76 %
Epoch 906 of 2000 took 0.097s
  training loss:		0.134673
  validation loss:		0.362591
  validation accuracy:		90.33 %
Epoch 907 of 2000 took 0.096s
  training loss:		0.138793
  validation loss:		0.357726
  validation accuracy:		90.33 %
Epoch 908 of 2000 took 0.097s
  training loss:		0.135394
  validation loss:		0.348165
  validation accuracy:		91.09 %
Epoch 909 of 2000 took 0.106s
  training loss:		0.132991
  validation loss:		0.344440
  validation accuracy:		91.52 %
Epoch 910 of 2000 took 0.106s
  training loss:		0.134392
  validation loss:		0.344622
  validation accuracy:		91.63 %
Epoch 911 of 2000 took 0.101s
  training loss:		0.140754
  validation loss:		0.351967
  validation accuracy:		90.76 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.131516
  validation loss:		0.355474
  validation accuracy:		90.33 %
Epoch 913 of 2000 took 0.096s
  training loss:		0.126834
  validation loss:		0.353231
  validation accuracy:		90.65 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.137137
  validation loss:		0.355065
  validation accuracy:		90.54 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.133436
  validation loss:		0.360691
  validation accuracy:		90.54 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.131352
  validation loss:		0.370406
  validation accuracy:		90.22 %
Epoch 917 of 2000 took 0.095s
  training loss:		0.133109
  validation loss:		0.365842
  validation accuracy:		90.33 %
Epoch 918 of 2000 took 0.095s
  training loss:		0.135415
  validation loss:		0.361484
  validation accuracy:		90.87 %
Epoch 919 of 2000 took 0.095s
  training loss:		0.136107
  validation loss:		0.359183
  validation accuracy:		90.54 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.135319
  validation loss:		0.352713
  validation accuracy:		90.87 %
Epoch 921 of 2000 took 0.098s
  training loss:		0.130724
  validation loss:		0.352106
  validation accuracy:		91.09 %
Epoch 922 of 2000 took 0.101s
  training loss:		0.129599
  validation loss:		0.354316
  validation accuracy:		90.65 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.128681
  validation loss:		0.363357
  validation accuracy:		90.43 %
Epoch 924 of 2000 took 0.098s
  training loss:		0.129568
  validation loss:		0.353286
  validation accuracy:		90.87 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.130672
  validation loss:		0.354815
  validation accuracy:		90.22 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.130192
  validation loss:		0.346672
  validation accuracy:		91.41 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.127290
  validation loss:		0.362603
  validation accuracy:		90.33 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.134923
  validation loss:		0.360589
  validation accuracy:		90.33 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.131242
  validation loss:		0.358996
  validation accuracy:		90.65 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.127474
  validation loss:		0.355066
  validation accuracy:		90.54 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.133711
  validation loss:		0.361892
  validation accuracy:		90.54 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.132067
  validation loss:		0.361633
  validation accuracy:		90.33 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.129211
  validation loss:		0.362134
  validation accuracy:		90.33 %
Epoch 934 of 2000 took 0.096s
  training loss:		0.128988
  validation loss:		0.376493
  validation accuracy:		89.67 %
Epoch 935 of 2000 took 0.098s
  training loss:		0.134134
  validation loss:		0.358175
  validation accuracy:		91.09 %
Epoch 936 of 2000 took 0.098s
  training loss:		0.130631
  validation loss:		0.375382
  validation accuracy:		90.76 %
Epoch 937 of 2000 took 0.098s
  training loss:		0.128308
  validation loss:		0.348423
  validation accuracy:		91.09 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.132225
  validation loss:		0.393491
  validation accuracy:		89.57 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.129847
  validation loss:		0.353054
  validation accuracy:		91.63 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.133946
  validation loss:		0.367191
  validation accuracy:		90.22 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.126909
  validation loss:		0.357902
  validation accuracy:		90.43 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.131522
  validation loss:		0.356653
  validation accuracy:		90.87 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.127321
  validation loss:		0.365187
  validation accuracy:		90.00 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.127363
  validation loss:		0.376753
  validation accuracy:		90.87 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.130594
  validation loss:		0.376201
  validation accuracy:		89.78 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.127565
  validation loss:		0.358079
  validation accuracy:		90.98 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.129358
  validation loss:		0.383690
  validation accuracy:		90.43 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.133468
  validation loss:		0.358497
  validation accuracy:		91.09 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.129109
  validation loss:		0.379515
  validation accuracy:		90.43 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.130404
  validation loss:		0.353541
  validation accuracy:		90.87 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.131299
  validation loss:		0.367462
  validation accuracy:		91.09 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.130103
  validation loss:		0.387366
  validation accuracy:		90.11 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.127458
  validation loss:		0.361335
  validation accuracy:		91.20 %
Epoch 954 of 2000 took 0.096s
  training loss:		0.129157
  validation loss:		0.356438
  validation accuracy:		90.76 %
Epoch 955 of 2000 took 0.096s
  training loss:		0.128444
  validation loss:		0.374487
  validation accuracy:		90.33 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.123517
  validation loss:		0.364036
  validation accuracy:		89.89 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.127782
  validation loss:		0.377335
  validation accuracy:		90.00 %
Epoch 958 of 2000 took 0.096s
  training loss:		0.125764
  validation loss:		0.376952
  validation accuracy:		90.33 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.128778
  validation loss:		0.374110
  validation accuracy:		89.46 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.129051
  validation loss:		0.380680
  validation accuracy:		90.22 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.126982
  validation loss:		0.386690
  validation accuracy:		90.33 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.126304
  validation loss:		0.367282
  validation accuracy:		90.54 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.121798
  validation loss:		0.385690
  validation accuracy:		89.57 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.127419
  validation loss:		0.368106
  validation accuracy:		89.89 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.129539
  validation loss:		0.382536
  validation accuracy:		90.43 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.123207
  validation loss:		0.359304
  validation accuracy:		90.87 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.125046
  validation loss:		0.379455
  validation accuracy:		89.89 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.129473
  validation loss:		0.375489
  validation accuracy:		90.22 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.125684
  validation loss:		0.366837
  validation accuracy:		90.87 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.120687
  validation loss:		0.364425
  validation accuracy:		90.65 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.124810
  validation loss:		0.379089
  validation accuracy:		90.54 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.128739
  validation loss:		0.370431
  validation accuracy:		89.89 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.126871
  validation loss:		0.398098
  validation accuracy:		90.33 %
Epoch 974 of 2000 took 0.097s
  training loss:		0.124414
  validation loss:		0.377128
  validation accuracy:		90.43 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.124367
  validation loss:		0.372244
  validation accuracy:		90.87 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.120046
  validation loss:		0.373312
  validation accuracy:		90.87 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.124854
  validation loss:		0.366436
  validation accuracy:		90.33 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.122797
  validation loss:		0.384311
  validation accuracy:		89.89 %
Epoch 979 of 2000 took 0.096s
  training loss:		0.125422
  validation loss:		0.366257
  validation accuracy:		90.98 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.121743
  validation loss:		0.410141
  validation accuracy:		89.24 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.124317
  validation loss:		0.375526
  validation accuracy:		90.11 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.121801
  validation loss:		0.366935
  validation accuracy:		91.09 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.121666
  validation loss:		0.373114
  validation accuracy:		90.33 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.126063
  validation loss:		0.369324
  validation accuracy:		91.09 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.119983
  validation loss:		0.381758
  validation accuracy:		90.22 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.123780
  validation loss:		0.383801
  validation accuracy:		90.43 %
Epoch 987 of 2000 took 0.096s
  training loss:		0.127536
  validation loss:		0.380243
  validation accuracy:		90.33 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.120634
  validation loss:		0.377957
  validation accuracy:		90.33 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.123278
  validation loss:		0.391600
  validation accuracy:		89.46 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.119463
  validation loss:		0.373900
  validation accuracy:		90.65 %
Epoch 991 of 2000 took 0.096s
  training loss:		0.121083
  validation loss:		0.370564
  validation accuracy:		90.54 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.123404
  validation loss:		0.380538
  validation accuracy:		90.22 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.120532
  validation loss:		0.367168
  validation accuracy:		90.98 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.121247
  validation loss:		0.392123
  validation accuracy:		89.78 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.123408
  validation loss:		0.375122
  validation accuracy:		90.00 %
Epoch 996 of 2000 took 0.096s
  training loss:		0.120262
  validation loss:		0.383999
  validation accuracy:		90.65 %
Epoch 997 of 2000 took 0.096s
  training loss:		0.125072
  validation loss:		0.381093
  validation accuracy:		90.98 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.129812
  validation loss:		0.386125
  validation accuracy:		90.87 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.127797
  validation loss:		0.373457
  validation accuracy:		90.76 %
Epoch 1000 of 2000 took 0.096s
  training loss:		0.121342
  validation loss:		0.388118
  validation accuracy:		89.57 %
Epoch 1001 of 2000 took 0.096s
  training loss:		0.119601
  validation loss:		0.383902
  validation accuracy:		90.98 %
Epoch 1002 of 2000 took 0.096s
  training loss:		0.118401
  validation loss:		0.415439
  validation accuracy:		90.00 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.129366
  validation loss:		0.386295
  validation accuracy:		89.78 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.118713
  validation loss:		0.375733
  validation accuracy:		91.09 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.122947
  validation loss:		0.383872
  validation accuracy:		90.00 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.122621
  validation loss:		0.372052
  validation accuracy:		90.43 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.120953
  validation loss:		0.375738
  validation accuracy:		90.43 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.119176
  validation loss:		0.384988
  validation accuracy:		90.43 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.119624
  validation loss:		0.374586
  validation accuracy:		90.54 %
Epoch 1010 of 2000 took 0.096s
  training loss:		0.120060
  validation loss:		0.374738
  validation accuracy:		91.09 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.122688
  validation loss:		0.386580
  validation accuracy:		90.54 %
Epoch 1012 of 2000 took 0.096s
  training loss:		0.124523
  validation loss:		0.386418
  validation accuracy:		90.65 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.115156
  validation loss:		0.388623
  validation accuracy:		90.43 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.119900
  validation loss:		0.378155
  validation accuracy:		90.87 %
Epoch 1015 of 2000 took 0.097s
  training loss:		0.116682
  validation loss:		0.379730
  validation accuracy:		90.98 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.117449
  validation loss:		0.372782
  validation accuracy:		91.20 %
Epoch 1017 of 2000 took 0.096s
  training loss:		0.115694
  validation loss:		0.377699
  validation accuracy:		90.43 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.116658
  validation loss:		0.382078
  validation accuracy:		90.43 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.120882
  validation loss:		0.397433
  validation accuracy:		89.67 %
Epoch 1020 of 2000 took 0.096s
  training loss:		0.120347
  validation loss:		0.373313
  validation accuracy:		90.54 %
Epoch 1021 of 2000 took 0.096s
  training loss:		0.116580
  validation loss:		0.381724
  validation accuracy:		90.43 %
Epoch 1022 of 2000 took 0.096s
  training loss:		0.118205
  validation loss:		0.371595
  validation accuracy:		90.76 %
Epoch 1023 of 2000 took 0.096s
  training loss:		0.121647
  validation loss:		0.383894
  validation accuracy:		90.76 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.118491
  validation loss:		0.379863
  validation accuracy:		90.98 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.118328
  validation loss:		0.404436
  validation accuracy:		89.89 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.120518
  validation loss:		0.375411
  validation accuracy:		90.76 %
Epoch 1027 of 2000 took 0.096s
  training loss:		0.119169
  validation loss:		0.399152
  validation accuracy:		90.43 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.116322
  validation loss:		0.381877
  validation accuracy:		90.22 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.117351
  validation loss:		0.376379
  validation accuracy:		90.76 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.121545
  validation loss:		0.386787
  validation accuracy:		90.43 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.116843
  validation loss:		0.382143
  validation accuracy:		90.65 %
Epoch 1032 of 2000 took 0.097s
  training loss:		0.119048
  validation loss:		0.379367
  validation accuracy:		90.76 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.114206
  validation loss:		0.405910
  validation accuracy:		90.11 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.113721
  validation loss:		0.387114
  validation accuracy:		90.43 %
Epoch 1035 of 2000 took 0.097s
  training loss:		0.115763
  validation loss:		0.385992
  validation accuracy:		90.65 %
Epoch 1036 of 2000 took 0.097s
  training loss:		0.113638
  validation loss:		0.379790
  validation accuracy:		91.20 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.117965
  validation loss:		0.384979
  validation accuracy:		91.09 %
Epoch 1038 of 2000 took 0.097s
  training loss:		0.119399
  validation loss:		0.376822
  validation accuracy:		90.87 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.118011
  validation loss:		0.376709
  validation accuracy:		90.98 %
Epoch 1040 of 2000 took 0.097s
  training loss:		0.116537
  validation loss:		0.393004
  validation accuracy:		90.00 %
Epoch 1041 of 2000 took 0.096s
  training loss:		0.117274
  validation loss:		0.401149
  validation accuracy:		90.65 %
Epoch 1042 of 2000 took 0.097s
  training loss:		0.112806
  validation loss:		0.383728
  validation accuracy:		90.98 %
Epoch 1043 of 2000 took 0.096s
  training loss:		0.114279
  validation loss:		0.391527
  validation accuracy:		90.54 %
Epoch 1044 of 2000 took 0.096s
  training loss:		0.114220
  validation loss:		0.387930
  validation accuracy:		90.76 %
Epoch 1045 of 2000 took 0.097s
  training loss:		0.109924
  validation loss:		0.392867
  validation accuracy:		90.43 %
Epoch 1046 of 2000 took 0.097s
  training loss:		0.120502
  validation loss:		0.404075
  validation accuracy:		89.78 %
Epoch 1047 of 2000 took 0.096s
  training loss:		0.113458
  validation loss:		0.393443
  validation accuracy:		90.43 %
Epoch 1048 of 2000 took 0.096s
  training loss:		0.111453
  validation loss:		0.387379
  validation accuracy:		90.54 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.115043
  validation loss:		0.404850
  validation accuracy:		90.54 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.114973
  validation loss:		0.380737
  validation accuracy:		91.09 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.115128
  validation loss:		0.379330
  validation accuracy:		90.65 %
Epoch 1052 of 2000 took 0.096s
  training loss:		0.110225
  validation loss:		0.391198
  validation accuracy:		90.76 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.116306
  validation loss:		0.404421
  validation accuracy:		90.11 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.118723
  validation loss:		0.391141
  validation accuracy:		90.33 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.116578
  validation loss:		0.385171
  validation accuracy:		90.76 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.117253
  validation loss:		0.410060
  validation accuracy:		90.11 %
Epoch 1057 of 2000 took 0.097s
  training loss:		0.111658
  validation loss:		0.389332
  validation accuracy:		90.54 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.112721
  validation loss:		0.415914
  validation accuracy:		89.78 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.112686
  validation loss:		0.410128
  validation accuracy:		90.54 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.115025
  validation loss:		0.399579
  validation accuracy:		90.65 %
Epoch 1061 of 2000 took 0.097s
  training loss:		0.112762
  validation loss:		0.390917
  validation accuracy:		90.87 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.113600
  validation loss:		0.401160
  validation accuracy:		89.89 %
Epoch 1063 of 2000 took 0.096s
  training loss:		0.113477
  validation loss:		0.416602
  validation accuracy:		89.46 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.110125
  validation loss:		0.397185
  validation accuracy:		90.11 %
Epoch 1065 of 2000 took 0.096s
  training loss:		0.112741
  validation loss:		0.405203
  validation accuracy:		90.11 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.110212
  validation loss:		0.394027
  validation accuracy:		90.76 %
Epoch 1067 of 2000 took 0.097s
  training loss:		0.112353
  validation loss:		0.395731
  validation accuracy:		90.43 %
Epoch 1068 of 2000 took 0.096s
  training loss:		0.115919
  validation loss:		0.401076
  validation accuracy:		90.00 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.111173
  validation loss:		0.403601
  validation accuracy:		90.43 %
Epoch 1070 of 2000 took 0.096s
  training loss:		0.112450
  validation loss:		0.399960
  validation accuracy:		90.22 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.112120
  validation loss:		0.377481
  validation accuracy:		90.98 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.109323
  validation loss:		0.412304
  validation accuracy:		90.11 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.109297
  validation loss:		0.410366
  validation accuracy:		90.43 %
Epoch 1074 of 2000 took 0.096s
  training loss:		0.111122
  validation loss:		0.433918
  validation accuracy:		89.46 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.113316
  validation loss:		0.408569
  validation accuracy:		90.33 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.109296
  validation loss:		0.400480
  validation accuracy:		90.54 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.114050
  validation loss:		0.399789
  validation accuracy:		90.65 %
Epoch 1078 of 2000 took 0.096s
  training loss:		0.110049
  validation loss:		0.403845
  validation accuracy:		90.43 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.110502
  validation loss:		0.400935
  validation accuracy:		90.33 %
Epoch 1080 of 2000 took 0.096s
  training loss:		0.110002
  validation loss:		0.407138
  validation accuracy:		90.22 %
Epoch 1081 of 2000 took 0.096s
  training loss:		0.110672
  validation loss:		0.408316
  validation accuracy:		90.22 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.107275
  validation loss:		0.416630
  validation accuracy:		90.11 %
Epoch 1083 of 2000 took 0.096s
  training loss:		0.110592
  validation loss:		0.409896
  validation accuracy:		90.43 %
Epoch 1084 of 2000 took 0.096s
  training loss:		0.106121
  validation loss:		0.394898
  validation accuracy:		90.76 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.106332
  validation loss:		0.402608
  validation accuracy:		90.76 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.112313
  validation loss:		0.404324
  validation accuracy:		90.54 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.108319
  validation loss:		0.403514
  validation accuracy:		90.43 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.111064
  validation loss:		0.413682
  validation accuracy:		90.11 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.112405
  validation loss:		0.406801
  validation accuracy:		90.33 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.107696
  validation loss:		0.402703
  validation accuracy:		90.76 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.107324
  validation loss:		0.403996
  validation accuracy:		90.22 %
Epoch 1092 of 2000 took 0.099s
  training loss:		0.106833
  validation loss:		0.396573
  validation accuracy:		90.54 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.108310
  validation loss:		0.398235
  validation accuracy:		90.87 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.109470
  validation loss:		0.406046
  validation accuracy:		90.65 %
Epoch 1095 of 2000 took 0.096s
  training loss:		0.109157
  validation loss:		0.391135
  validation accuracy:		91.09 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.110978
  validation loss:		0.396242
  validation accuracy:		90.98 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.102389
  validation loss:		0.398687
  validation accuracy:		90.65 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.112862
  validation loss:		0.416844
  validation accuracy:		90.22 %
Epoch 1099 of 2000 took 0.096s
  training loss:		0.106709
  validation loss:		0.396543
  validation accuracy:		90.87 %
Epoch 1100 of 2000 took 0.096s
  training loss:		0.114714
  validation loss:		0.416246
  validation accuracy:		90.22 %
Epoch 1101 of 2000 took 0.096s
  training loss:		0.109318
  validation loss:		0.401463
  validation accuracy:		90.98 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.106772
  validation loss:		0.399900
  validation accuracy:		90.87 %
Epoch 1103 of 2000 took 0.096s
  training loss:		0.106194
  validation loss:		0.414043
  validation accuracy:		90.33 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.106922
  validation loss:		0.403751
  validation accuracy:		90.43 %
Epoch 1105 of 2000 took 0.096s
  training loss:		0.104880
  validation loss:		0.410504
  validation accuracy:		90.54 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.105265
  validation loss:		0.409751
  validation accuracy:		90.65 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.106713
  validation loss:		0.411661
  validation accuracy:		90.22 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.104273
  validation loss:		0.396818
  validation accuracy:		90.43 %
Epoch 1109 of 2000 took 0.096s
  training loss:		0.106361
  validation loss:		0.424205
  validation accuracy:		90.33 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.107287
  validation loss:		0.426308
  validation accuracy:		90.00 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.104440
  validation loss:		0.404015
  validation accuracy:		91.09 %
Epoch 1112 of 2000 took 0.096s
  training loss:		0.107045
  validation loss:		0.406786
  validation accuracy:		90.98 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.105920
  validation loss:		0.402620
  validation accuracy:		90.98 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.105737
  validation loss:		0.414811
  validation accuracy:		90.54 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.108339
  validation loss:		0.413665
  validation accuracy:		90.33 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.107982
  validation loss:		0.435319
  validation accuracy:		90.00 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.108216
  validation loss:		0.419835
  validation accuracy:		90.54 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.108310
  validation loss:		0.415730
  validation accuracy:		90.33 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.105032
  validation loss:		0.420361
  validation accuracy:		90.65 %
Epoch 1120 of 2000 took 0.096s
  training loss:		0.101634
  validation loss:		0.409353
  validation accuracy:		90.65 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.105226
  validation loss:		0.418786
  validation accuracy:		90.33 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.102600
  validation loss:		0.428597
  validation accuracy:		90.43 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.104421
  validation loss:		0.418407
  validation accuracy:		90.43 %
Epoch 1124 of 2000 took 0.096s
  training loss:		0.108560
  validation loss:		0.409948
  validation accuracy:		90.65 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.105248
  validation loss:		0.399576
  validation accuracy:		91.09 %
Epoch 1126 of 2000 took 0.096s
  training loss:		0.107356
  validation loss:		0.412674
  validation accuracy:		91.20 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.102846
  validation loss:		0.413815
  validation accuracy:		91.20 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.106384
  validation loss:		0.409244
  validation accuracy:		90.65 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.106257
  validation loss:		0.403753
  validation accuracy:		90.87 %
Epoch 1130 of 2000 took 0.096s
  training loss:		0.106194
  validation loss:		0.413445
  validation accuracy:		90.65 %
Epoch 1131 of 2000 took 0.096s
  training loss:		0.104420
  validation loss:		0.408278
  validation accuracy:		90.98 %
Epoch 1132 of 2000 took 0.096s
  training loss:		0.104664
  validation loss:		0.424252
  validation accuracy:		89.89 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.101290
  validation loss:		0.423722
  validation accuracy:		90.22 %
Epoch 1134 of 2000 took 0.096s
  training loss:		0.107920
  validation loss:		0.425175
  validation accuracy:		90.00 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.100248
  validation loss:		0.433173
  validation accuracy:		89.89 %
Epoch 1136 of 2000 took 0.096s
  training loss:		0.098852
  validation loss:		0.418998
  validation accuracy:		90.54 %
Epoch 1137 of 2000 took 0.096s
  training loss:		0.103506
  validation loss:		0.428194
  validation accuracy:		90.43 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.102345
  validation loss:		0.424331
  validation accuracy:		91.09 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.097268
  validation loss:		0.438419
  validation accuracy:		90.00 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.096241
  validation loss:		0.431770
  validation accuracy:		89.89 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.108753
  validation loss:		0.416918
  validation accuracy:		90.33 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.105885
  validation loss:		0.411693
  validation accuracy:		90.43 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.098540
  validation loss:		0.417499
  validation accuracy:		90.65 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.101774
  validation loss:		0.418557
  validation accuracy:		90.65 %
Epoch 1145 of 2000 took 0.096s
  training loss:		0.099197
  validation loss:		0.416173
  validation accuracy:		90.87 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.100459
  validation loss:		0.412256
  validation accuracy:		91.09 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.095385
  validation loss:		0.439756
  validation accuracy:		90.43 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.100344
  validation loss:		0.410775
  validation accuracy:		90.87 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.104876
  validation loss:		0.433075
  validation accuracy:		90.33 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.102788
  validation loss:		0.402770
  validation accuracy:		91.20 %
Epoch 1151 of 2000 took 0.096s
  training loss:		0.103769
  validation loss:		0.427184
  validation accuracy:		90.54 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.099292
  validation loss:		0.429508
  validation accuracy:		90.43 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.102813
  validation loss:		0.431351
  validation accuracy:		90.11 %
Epoch 1154 of 2000 took 0.098s
  training loss:		0.100132
  validation loss:		0.408143
  validation accuracy:		90.98 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.100718
  validation loss:		0.415962
  validation accuracy:		91.20 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.096896
  validation loss:		0.446746
  validation accuracy:		90.33 %
Epoch 1157 of 2000 took 0.097s
  training loss:		0.100388
  validation loss:		0.431934
  validation accuracy:		90.65 %
Epoch 1158 of 2000 took 0.097s
  training loss:		0.098676
  validation loss:		0.424049
  validation accuracy:		90.76 %
Epoch 1159 of 2000 took 0.097s
  training loss:		0.100026
  validation loss:		0.446173
  validation accuracy:		89.78 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.101551
  validation loss:		0.429888
  validation accuracy:		90.22 %
Epoch 1161 of 2000 took 0.096s
  training loss:		0.094232
  validation loss:		0.422943
  validation accuracy:		90.33 %
Epoch 1162 of 2000 took 0.097s
  training loss:		0.099328
  validation loss:		0.425055
  validation accuracy:		90.43 %
Epoch 1163 of 2000 took 0.096s
  training loss:		0.096380
  validation loss:		0.420422
  validation accuracy:		90.98 %
Epoch 1164 of 2000 took 0.097s
  training loss:		0.096624
  validation loss:		0.423082
  validation accuracy:		90.22 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.098792
  validation loss:		0.429949
  validation accuracy:		90.33 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.102638
  validation loss:		0.435835
  validation accuracy:		90.43 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.096141
  validation loss:		0.417006
  validation accuracy:		90.76 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.098318
  validation loss:		0.421874
  validation accuracy:		91.20 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.096046
  validation loss:		0.413349
  validation accuracy:		90.65 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.099636
  validation loss:		0.422134
  validation accuracy:		90.65 %
Epoch 1171 of 2000 took 0.096s
  training loss:		0.099789
  validation loss:		0.421772
  validation accuracy:		90.76 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.097961
  validation loss:		0.417787
  validation accuracy:		91.30 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.097978
  validation loss:		0.422880
  validation accuracy:		90.98 %
Epoch 1174 of 2000 took 0.096s
  training loss:		0.095577
  validation loss:		0.418736
  validation accuracy:		91.09 %
Epoch 1175 of 2000 took 0.097s
  training loss:		0.094803
  validation loss:		0.417268
  validation accuracy:		90.76 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.096586
  validation loss:		0.443571
  validation accuracy:		90.33 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.098526
  validation loss:		0.415858
  validation accuracy:		90.87 %
Epoch 1178 of 2000 took 0.096s
  training loss:		0.097797
  validation loss:		0.426580
  validation accuracy:		90.54 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.094937
  validation loss:		0.440351
  validation accuracy:		90.33 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.094132
  validation loss:		0.418608
  validation accuracy:		90.87 %
Epoch 1181 of 2000 took 0.097s
  training loss:		0.093205
  validation loss:		0.426670
  validation accuracy:		90.43 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.095057
  validation loss:		0.431931
  validation accuracy:		90.54 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.093107
  validation loss:		0.435497
  validation accuracy:		90.76 %
Epoch 1184 of 2000 took 0.096s
  training loss:		0.090462
  validation loss:		0.452079
  validation accuracy:		90.22 %
Epoch 1185 of 2000 took 0.097s
  training loss:		0.093937
  validation loss:		0.446633
  validation accuracy:		90.65 %
Epoch 1186 of 2000 took 0.096s
  training loss:		0.095073
  validation loss:		0.425054
  validation accuracy:		90.98 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.094714
  validation loss:		0.426241
  validation accuracy:		90.54 %
Epoch 1188 of 2000 took 0.096s
  training loss:		0.093944
  validation loss:		0.433599
  validation accuracy:		90.54 %
Epoch 1189 of 2000 took 0.096s
  training loss:		0.093841
  validation loss:		0.423242
  validation accuracy:		91.30 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.096445
  validation loss:		0.447593
  validation accuracy:		90.22 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.093308
  validation loss:		0.428106
  validation accuracy:		91.30 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.095719
  validation loss:		0.438461
  validation accuracy:		90.76 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.092403
  validation loss:		0.432105
  validation accuracy:		90.76 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.095021
  validation loss:		0.444705
  validation accuracy:		90.87 %
Epoch 1195 of 2000 took 0.097s
  training loss:		0.091936
  validation loss:		0.448689
  validation accuracy:		90.54 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.096205
  validation loss:		0.435386
  validation accuracy:		90.11 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.096014
  validation loss:		0.482395
  validation accuracy:		89.78 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.094825
  validation loss:		0.444015
  validation accuracy:		90.87 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.095282
  validation loss:		0.444073
  validation accuracy:		91.20 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.091211
  validation loss:		0.438322
  validation accuracy:		90.98 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.091882
  validation loss:		0.443527
  validation accuracy:		90.76 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.094916
  validation loss:		0.452857
  validation accuracy:		90.43 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.096502
  validation loss:		0.449418
  validation accuracy:		90.11 %
Epoch 1204 of 2000 took 0.097s
  training loss:		0.091433
  validation loss:		0.447164
  validation accuracy:		90.33 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.092782
  validation loss:		0.433831
  validation accuracy:		90.76 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.094758
  validation loss:		0.452840
  validation accuracy:		90.33 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.095065
  validation loss:		0.464525
  validation accuracy:		90.33 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.087589
  validation loss:		0.431703
  validation accuracy:		90.54 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.091523
  validation loss:		0.458560
  validation accuracy:		90.11 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.090317
  validation loss:		0.440679
  validation accuracy:		90.54 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.092156
  validation loss:		0.447112
  validation accuracy:		90.43 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.091375
  validation loss:		0.434450
  validation accuracy:		91.52 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.088663
  validation loss:		0.476533
  validation accuracy:		90.00 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.092850
  validation loss:		0.447489
  validation accuracy:		90.33 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.085551
  validation loss:		0.457671
  validation accuracy:		90.33 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.090525
  validation loss:		0.450318
  validation accuracy:		91.30 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.093189
  validation loss:		0.435551
  validation accuracy:		91.63 %
Epoch 1218 of 2000 took 0.097s
  training loss:		0.100494
  validation loss:		0.431945
  validation accuracy:		91.09 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.092308
  validation loss:		0.460807
  validation accuracy:		90.43 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.089851
  validation loss:		0.448098
  validation accuracy:		90.33 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.087661
  validation loss:		0.468276
  validation accuracy:		90.33 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.092191
  validation loss:		0.459202
  validation accuracy:		90.33 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.091774
  validation loss:		0.447723
  validation accuracy:		90.65 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.086295
  validation loss:		0.451327
  validation accuracy:		90.33 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.093761
  validation loss:		0.460683
  validation accuracy:		90.33 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.092078
  validation loss:		0.469538
  validation accuracy:		89.89 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.094101
  validation loss:		0.464613
  validation accuracy:		90.11 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.089441
  validation loss:		0.445145
  validation accuracy:		91.09 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.089237
  validation loss:		0.481699
  validation accuracy:		90.22 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.087365
  validation loss:		0.443362
  validation accuracy:		90.76 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.087454
  validation loss:		0.453589
  validation accuracy:		90.54 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.087224
  validation loss:		0.461938
  validation accuracy:		90.22 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.089459
  validation loss:		0.443935
  validation accuracy:		91.20 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.083785
  validation loss:		0.440883
  validation accuracy:		90.87 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.091352
  validation loss:		0.439118
  validation accuracy:		91.41 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.089547
  validation loss:		0.438509
  validation accuracy:		91.20 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.088702
  validation loss:		0.451297
  validation accuracy:		91.09 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.087400
  validation loss:		0.478670
  validation accuracy:		89.78 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.086376
  validation loss:		0.453212
  validation accuracy:		91.30 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.091556
  validation loss:		0.453174
  validation accuracy:		90.54 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.091507
  validation loss:		0.480650
  validation accuracy:		90.11 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.085703
  validation loss:		0.434873
  validation accuracy:		91.20 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.089772
  validation loss:		0.460045
  validation accuracy:		90.65 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.088611
  validation loss:		0.453358
  validation accuracy:		90.54 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.086256
  validation loss:		0.454008
  validation accuracy:		91.20 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.083684
  validation loss:		0.449244
  validation accuracy:		91.09 %
Epoch 1247 of 2000 took 0.098s
  training loss:		0.088499
  validation loss:		0.454220
  validation accuracy:		90.87 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.091052
  validation loss:		0.464124
  validation accuracy:		90.43 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.086676
  validation loss:		0.451427
  validation accuracy:		90.22 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.089217
  validation loss:		0.464675
  validation accuracy:		90.76 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.087924
  validation loss:		0.465569
  validation accuracy:		91.09 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.083953
  validation loss:		0.494505
  validation accuracy:		90.00 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.092625
  validation loss:		0.445104
  validation accuracy:		91.74 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.083260
  validation loss:		0.467465
  validation accuracy:		90.22 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.083754
  validation loss:		0.457545
  validation accuracy:		91.09 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.082200
  validation loss:		0.460119
  validation accuracy:		91.09 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.086831
  validation loss:		0.459983
  validation accuracy:		91.09 %
Epoch 1258 of 2000 took 0.097s
  training loss:		0.083196
  validation loss:		0.464304
  validation accuracy:		90.98 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.087810
  validation loss:		0.465866
  validation accuracy:		90.11 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.089406
  validation loss:		0.460004
  validation accuracy:		90.76 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.091338
  validation loss:		0.458251
  validation accuracy:		91.30 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.087458
  validation loss:		0.485917
  validation accuracy:		89.89 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.085918
  validation loss:		0.471149
  validation accuracy:		90.65 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.079399
  validation loss:		0.472415
  validation accuracy:		90.11 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.084406
  validation loss:		0.471292
  validation accuracy:		90.65 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.081845
  validation loss:		0.473741
  validation accuracy:		90.65 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.083234
  validation loss:		0.494843
  validation accuracy:		90.54 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.086748
  validation loss:		0.525778
  validation accuracy:		90.00 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.083019
  validation loss:		0.467299
  validation accuracy:		90.65 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.081213
  validation loss:		0.471735
  validation accuracy:		90.65 %
Epoch 1271 of 2000 took 0.100s
  training loss:		0.085374
  validation loss:		0.478136
  validation accuracy:		90.54 %
Epoch 1272 of 2000 took 0.095s
  training loss:		0.088040
  validation loss:		0.482866
  validation accuracy:		90.22 %
Epoch 1273 of 2000 took 0.095s
  training loss:		0.084080
  validation loss:		0.459026
  validation accuracy:		91.09 %
Epoch 1274 of 2000 took 0.095s
  training loss:		0.080809
  validation loss:		0.471344
  validation accuracy:		90.65 %
Epoch 1275 of 2000 took 0.095s
  training loss:		0.087683
  validation loss:		0.484845
  validation accuracy:		89.78 %
Epoch 1276 of 2000 took 0.095s
  training loss:		0.088133
  validation loss:		0.472327
  validation accuracy:		90.98 %
Epoch 1277 of 2000 took 0.095s
  training loss:		0.081714
  validation loss:		0.470062
  validation accuracy:		90.43 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.082902
  validation loss:		0.466822
  validation accuracy:		91.09 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.083068
  validation loss:		0.478174
  validation accuracy:		91.09 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.081046
  validation loss:		0.484821
  validation accuracy:		90.54 %
Epoch 1281 of 2000 took 0.095s
  training loss:		0.080895
  validation loss:		0.457158
  validation accuracy:		91.30 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.081015
  validation loss:		0.480150
  validation accuracy:		90.54 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.085857
  validation loss:		0.470502
  validation accuracy:		90.87 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.083191
  validation loss:		0.482479
  validation accuracy:		90.98 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.084102
  validation loss:		0.460666
  validation accuracy:		91.63 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.082022
  validation loss:		0.478421
  validation accuracy:		90.43 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.080673
  validation loss:		0.467777
  validation accuracy:		90.76 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.085488
  validation loss:		0.476245
  validation accuracy:		90.11 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.080675
  validation loss:		0.472928
  validation accuracy:		90.43 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.079584
  validation loss:		0.497496
  validation accuracy:		90.87 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.083838
  validation loss:		0.477091
  validation accuracy:		90.65 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.075289
  validation loss:		0.490953
  validation accuracy:		90.43 %
Epoch 1293 of 2000 took 0.096s
  training loss:		0.083264
  validation loss:		0.464785
  validation accuracy:		90.98 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.077349
  validation loss:		0.466372
  validation accuracy:		91.41 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.076885
  validation loss:		0.522461
  validation accuracy:		89.67 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.081283
  validation loss:		0.484603
  validation accuracy:		90.76 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.083009
  validation loss:		0.463117
  validation accuracy:		91.30 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.078548
  validation loss:		0.493480
  validation accuracy:		90.54 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.078877
  validation loss:		0.465135
  validation accuracy:		91.20 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.076466
  validation loss:		0.483702
  validation accuracy:		90.33 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.079691
  validation loss:		0.473487
  validation accuracy:		90.76 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.075248
  validation loss:		0.508903
  validation accuracy:		89.78 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.081958
  validation loss:		0.478786
  validation accuracy:		90.65 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.077896
  validation loss:		0.482643
  validation accuracy:		90.98 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.082526
  validation loss:		0.486409
  validation accuracy:		90.43 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.078561
  validation loss:		0.500767
  validation accuracy:		90.43 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.078286
  validation loss:		0.484907
  validation accuracy:		90.98 %
Epoch 1308 of 2000 took 0.096s
  training loss:		0.084647
  validation loss:		0.490308
  validation accuracy:		90.98 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.080232
  validation loss:		0.481334
  validation accuracy:		90.87 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.076799
  validation loss:		0.502360
  validation accuracy:		90.11 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.080494
  validation loss:		0.497862
  validation accuracy:		90.33 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.075503
  validation loss:		0.476004
  validation accuracy:		91.20 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.079445
  validation loss:		0.503326
  validation accuracy:		90.11 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.078449
  validation loss:		0.481535
  validation accuracy:		91.74 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.083450
  validation loss:		0.499200
  validation accuracy:		90.87 %
Epoch 1316 of 2000 took 0.104s
  training loss:		0.076054
  validation loss:		0.486669
  validation accuracy:		91.20 %
Epoch 1317 of 2000 took 0.105s
  training loss:		0.077164
  validation loss:		0.510072
  validation accuracy:		90.43 %
Epoch 1318 of 2000 took 0.135s
  training loss:		0.081857
  validation loss:		0.495551
  validation accuracy:		90.43 %
Epoch 1319 of 2000 took 0.111s
  training loss:		0.076420
  validation loss:		0.492181
  validation accuracy:		90.33 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.079139
  validation loss:		0.525257
  validation accuracy:		90.00 %
Epoch 1321 of 2000 took 0.099s
  training loss:		0.079097
  validation loss:		0.512756
  validation accuracy:		90.43 %
Epoch 1322 of 2000 took 0.100s
  training loss:		0.081150
  validation loss:		0.468855
  validation accuracy:		91.20 %
Epoch 1323 of 2000 took 0.103s
  training loss:		0.078315
  validation loss:		0.490856
  validation accuracy:		91.09 %
Epoch 1324 of 2000 took 0.102s
  training loss:		0.079393
  validation loss:		0.526652
  validation accuracy:		90.22 %
Epoch 1325 of 2000 took 0.100s
  training loss:		0.075302
  validation loss:		0.516886
  validation accuracy:		90.43 %
Epoch 1326 of 2000 took 0.100s
  training loss:		0.075150
  validation loss:		0.491704
  validation accuracy:		90.76 %
Epoch 1327 of 2000 took 0.100s
  training loss:		0.072998
  validation loss:		0.498288
  validation accuracy:		90.33 %
Epoch 1328 of 2000 took 0.100s
  training loss:		0.076103
  validation loss:		0.508218
  validation accuracy:		90.43 %
Epoch 1329 of 2000 took 0.100s
  training loss:		0.073689
  validation loss:		0.498668
  validation accuracy:		90.65 %
Epoch 1330 of 2000 took 0.100s
  training loss:		0.072704
  validation loss:		0.490631
  validation accuracy:		91.09 %
Epoch 1331 of 2000 took 0.100s
  training loss:		0.071288
  validation loss:		0.496300
  validation accuracy:		90.76 %
Epoch 1332 of 2000 took 0.100s
  training loss:		0.072866
  validation loss:		0.506098
  validation accuracy:		90.43 %
Epoch 1333 of 2000 took 0.100s
  training loss:		0.078752
  validation loss:		0.506245
  validation accuracy:		89.89 %
Epoch 1334 of 2000 took 0.101s
  training loss:		0.077226
  validation loss:		0.489396
  validation accuracy:		90.65 %
Epoch 1335 of 2000 took 0.100s
  training loss:		0.078764
  validation loss:		0.512125
  validation accuracy:		90.65 %
Epoch 1336 of 2000 took 0.100s
  training loss:		0.077650
  validation loss:		0.515188
  validation accuracy:		90.33 %
Epoch 1337 of 2000 took 0.100s
  training loss:		0.077689
  validation loss:		0.521064
  validation accuracy:		90.22 %
Epoch 1338 of 2000 took 0.100s
  training loss:		0.074256
  validation loss:		0.519908
  validation accuracy:		90.22 %
Epoch 1339 of 2000 took 0.101s
  training loss:		0.072388
  validation loss:		0.506132
  validation accuracy:		90.43 %
Epoch 1340 of 2000 took 0.100s
  training loss:		0.081620
  validation loss:		0.539260
  validation accuracy:		90.43 %
Epoch 1341 of 2000 took 0.102s
  training loss:		0.074271
  validation loss:		0.525501
  validation accuracy:		90.33 %
Epoch 1342 of 2000 took 0.105s
  training loss:		0.072470
  validation loss:		0.496213
  validation accuracy:		90.87 %
Epoch 1343 of 2000 took 0.105s
  training loss:		0.077313
  validation loss:		0.510987
  validation accuracy:		90.87 %
Epoch 1344 of 2000 took 0.101s
  training loss:		0.072961
  validation loss:		0.520878
  validation accuracy:		90.65 %
Epoch 1345 of 2000 took 0.101s
  training loss:		0.074884
  validation loss:		0.504021
  validation accuracy:		90.22 %
Epoch 1346 of 2000 took 0.100s
  training loss:		0.075520
  validation loss:		0.496319
  validation accuracy:		91.20 %
Epoch 1347 of 2000 took 0.100s
  training loss:		0.072768
  validation loss:		0.521244
  validation accuracy:		89.89 %
Epoch 1348 of 2000 took 0.101s
  training loss:		0.072873
  validation loss:		0.529981
  validation accuracy:		90.11 %
Epoch 1349 of 2000 took 0.099s
  training loss:		0.072797
  validation loss:		0.494571
  validation accuracy:		91.20 %
Epoch 1350 of 2000 took 0.100s
  training loss:		0.073400
  validation loss:		0.520298
  validation accuracy:		90.76 %
Epoch 1351 of 2000 took 0.100s
  training loss:		0.076283
  validation loss:		0.489558
  validation accuracy:		91.20 %
Epoch 1352 of 2000 took 0.100s
  training loss:		0.072531
  validation loss:		0.510066
  validation accuracy:		90.33 %
Epoch 1353 of 2000 took 0.100s
  training loss:		0.074923
  validation loss:		0.504260
  validation accuracy:		90.87 %
Epoch 1354 of 2000 took 0.101s
  training loss:		0.072167
  validation loss:		0.503811
  validation accuracy:		90.87 %
Epoch 1355 of 2000 took 0.101s
  training loss:		0.073096
  validation loss:		0.485305
  validation accuracy:		91.09 %
Epoch 1356 of 2000 took 0.100s
  training loss:		0.075395
  validation loss:		0.488991
  validation accuracy:		91.20 %
Epoch 1357 of 2000 took 0.103s
  training loss:		0.072405
  validation loss:		0.498905
  validation accuracy:		90.87 %
Epoch 1358 of 2000 took 0.140s
  training loss:		0.071400
  validation loss:		0.479088
  validation accuracy:		91.41 %
Epoch 1359 of 2000 took 0.119s
  training loss:		0.068278
  validation loss:		0.499052
  validation accuracy:		91.09 %
Epoch 1360 of 2000 took 0.100s
  training loss:		0.069902
  validation loss:		0.496668
  validation accuracy:		90.76 %
Epoch 1361 of 2000 took 0.101s
  training loss:		0.072635
  validation loss:		0.488681
  validation accuracy:		91.09 %
Epoch 1362 of 2000 took 0.103s
  training loss:		0.073201
  validation loss:		0.541152
  validation accuracy:		89.89 %
Epoch 1363 of 2000 took 0.111s
  training loss:		0.068259
  validation loss:		0.512001
  validation accuracy:		91.09 %
Epoch 1364 of 2000 took 0.102s
  training loss:		0.069918
  validation loss:		0.503886
  validation accuracy:		91.20 %
Epoch 1365 of 2000 took 0.095s
  training loss:		0.068714
  validation loss:		0.488131
  validation accuracy:		90.98 %
Epoch 1366 of 2000 took 0.096s
  training loss:		0.073495
  validation loss:		0.504756
  validation accuracy:		90.76 %
Epoch 1367 of 2000 took 0.099s
  training loss:		0.071272
  validation loss:		0.513567
  validation accuracy:		90.76 %
Epoch 1368 of 2000 took 0.099s
  training loss:		0.069143
  validation loss:		0.513437
  validation accuracy:		90.54 %
Epoch 1369 of 2000 took 0.100s
  training loss:		0.071229
  validation loss:		0.513722
  validation accuracy:		90.54 %
Epoch 1370 of 2000 took 0.099s
  training loss:		0.069179
  validation loss:		0.551815
  validation accuracy:		90.00 %
Epoch 1371 of 2000 took 0.099s
  training loss:		0.070285
  validation loss:		0.540095
  validation accuracy:		90.11 %
Epoch 1372 of 2000 took 0.099s
  training loss:		0.071095
  validation loss:		0.547022
  validation accuracy:		90.00 %
Epoch 1373 of 2000 took 0.099s
  training loss:		0.065351
  validation loss:		0.509365
  validation accuracy:		91.09 %
Epoch 1374 of 2000 took 0.098s
  training loss:		0.070874
  validation loss:		0.531944
  validation accuracy:		90.43 %
Epoch 1375 of 2000 took 0.097s
  training loss:		0.071302
  validation loss:		0.554570
  validation accuracy:		90.00 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.069291
  validation loss:		0.511537
  validation accuracy:		91.41 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.068249
  validation loss:		0.547281
  validation accuracy:		90.00 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.072044
  validation loss:		0.530018
  validation accuracy:		90.11 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.070157
  validation loss:		0.532246
  validation accuracy:		90.33 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.069732
  validation loss:		0.539487
  validation accuracy:		90.65 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.067852
  validation loss:		0.519484
  validation accuracy:		90.76 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.071734
  validation loss:		0.547962
  validation accuracy:		90.22 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.069285
  validation loss:		0.537026
  validation accuracy:		90.33 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.068313
  validation loss:		0.523056
  validation accuracy:		90.76 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.069020
  validation loss:		0.524479
  validation accuracy:		90.43 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.068096
  validation loss:		0.544624
  validation accuracy:		90.65 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.067787
  validation loss:		0.514631
  validation accuracy:		90.87 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.068120
  validation loss:		0.534757
  validation accuracy:		90.22 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.068883
  validation loss:		0.533892
  validation accuracy:		90.87 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.071587
  validation loss:		0.522598
  validation accuracy:		90.65 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.066098
  validation loss:		0.537345
  validation accuracy:		90.76 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.073859
  validation loss:		0.511103
  validation accuracy:		90.87 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.069258
  validation loss:		0.547512
  validation accuracy:		90.43 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.066647
  validation loss:		0.542170
  validation accuracy:		90.33 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.064912
  validation loss:		0.534810
  validation accuracy:		90.54 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.071361
  validation loss:		0.534628
  validation accuracy:		90.98 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.066771
  validation loss:		0.528876
  validation accuracy:		90.98 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.064413
  validation loss:		0.511623
  validation accuracy:		91.20 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.067422
  validation loss:		0.548440
  validation accuracy:		90.43 %
Epoch 1400 of 2000 took 0.097s
  training loss:		0.065378
  validation loss:		0.535201
  validation accuracy:		90.87 %
Epoch 1401 of 2000 took 0.096s
  training loss:		0.064504
  validation loss:		0.555211
  validation accuracy:		90.33 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.063762
  validation loss:		0.528913
  validation accuracy:		90.87 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.067042
  validation loss:		0.564477
  validation accuracy:		90.43 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.066231
  validation loss:		0.547043
  validation accuracy:		90.65 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.062715
  validation loss:		0.542805
  validation accuracy:		90.76 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.065583
  validation loss:		0.533823
  validation accuracy:		90.65 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.065276
  validation loss:		0.554504
  validation accuracy:		90.76 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.063763
  validation loss:		0.529263
  validation accuracy:		90.76 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.064306
  validation loss:		0.543124
  validation accuracy:		90.65 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.067217
  validation loss:		0.569645
  validation accuracy:		90.76 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.066357
  validation loss:		0.542818
  validation accuracy:		90.22 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.064957
  validation loss:		0.524450
  validation accuracy:		91.09 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.066871
  validation loss:		0.548586
  validation accuracy:		90.43 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.062209
  validation loss:		0.551024
  validation accuracy:		90.54 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.065580
  validation loss:		0.531062
  validation accuracy:		91.30 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.064087
  validation loss:		0.543275
  validation accuracy:		91.09 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.062921
  validation loss:		0.547766
  validation accuracy:		90.54 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.062494
  validation loss:		0.523953
  validation accuracy:		91.09 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.056595
  validation loss:		0.562131
  validation accuracy:		90.65 %
Epoch 1420 of 2000 took 0.096s
  training loss:		0.065129
  validation loss:		0.546671
  validation accuracy:		91.09 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.065680
  validation loss:		0.550010
  validation accuracy:		90.87 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.063793
  validation loss:		0.543160
  validation accuracy:		90.22 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.063862
  validation loss:		0.555124
  validation accuracy:		90.43 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.064607
  validation loss:		0.547814
  validation accuracy:		90.87 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.070695
  validation loss:		0.535382
  validation accuracy:		90.65 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.063525
  validation loss:		0.554329
  validation accuracy:		90.87 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.063099
  validation loss:		0.538545
  validation accuracy:		90.98 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.058094
  validation loss:		0.558139
  validation accuracy:		90.76 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.057648
  validation loss:		0.547009
  validation accuracy:		90.65 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.060978
  validation loss:		0.577884
  validation accuracy:		90.43 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.062948
  validation loss:		0.558007
  validation accuracy:		90.65 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.055730
  validation loss:		0.548580
  validation accuracy:		90.43 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.060387
  validation loss:		0.560679
  validation accuracy:		90.00 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.070414
  validation loss:		0.550816
  validation accuracy:		90.87 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.062435
  validation loss:		0.564902
  validation accuracy:		90.54 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.059759
  validation loss:		0.561070
  validation accuracy:		90.76 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.061750
  validation loss:		0.573129
  validation accuracy:		90.54 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.063485
  validation loss:		0.564181
  validation accuracy:		90.76 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.062584
  validation loss:		0.560041
  validation accuracy:		90.76 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.063368
  validation loss:		0.570804
  validation accuracy:		90.76 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.060322
  validation loss:		0.575275
  validation accuracy:		90.54 %
Epoch 1442 of 2000 took 0.096s
  training loss:		0.061220
  validation loss:		0.557795
  validation accuracy:		90.65 %
Epoch 1443 of 2000 took 0.096s
  training loss:		0.063393
  validation loss:		0.552970
  validation accuracy:		90.98 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.061805
  validation loss:		0.552116
  validation accuracy:		91.30 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.063848
  validation loss:		0.558835
  validation accuracy:		91.09 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.059753
  validation loss:		0.578100
  validation accuracy:		90.33 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.060008
  validation loss:		0.577677
  validation accuracy:		90.22 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.062395
  validation loss:		0.559089
  validation accuracy:		90.87 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.061013
  validation loss:		0.560960
  validation accuracy:		90.54 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.058156
  validation loss:		0.581494
  validation accuracy:		90.43 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.063098
  validation loss:		0.575715
  validation accuracy:		90.43 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.061590
  validation loss:		0.580040
  validation accuracy:		90.22 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.061964
  validation loss:		0.581665
  validation accuracy:		90.22 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.060957
  validation loss:		0.586339
  validation accuracy:		90.54 %
Epoch 1455 of 2000 took 0.096s
  training loss:		0.056611
  validation loss:		0.575980
  validation accuracy:		91.09 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.067659
  validation loss:		0.586301
  validation accuracy:		90.43 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.056558
  validation loss:		0.569165
  validation accuracy:		90.54 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.059640
  validation loss:		0.566675
  validation accuracy:		90.87 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.055255
  validation loss:		0.579606
  validation accuracy:		90.87 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.056238
  validation loss:		0.577563
  validation accuracy:		90.87 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.058777
  validation loss:		0.621886
  validation accuracy:		89.67 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.061105
  validation loss:		0.584986
  validation accuracy:		90.54 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.061625
  validation loss:		0.613822
  validation accuracy:		89.67 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.057768
  validation loss:		0.607631
  validation accuracy:		90.33 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.061510
  validation loss:		0.568353
  validation accuracy:		90.98 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.057037
  validation loss:		0.565246
  validation accuracy:		90.54 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.060940
  validation loss:		0.585381
  validation accuracy:		90.65 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.058348
  validation loss:		0.579585
  validation accuracy:		90.65 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.058497
  validation loss:		0.607978
  validation accuracy:		90.22 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.057645
  validation loss:		0.623732
  validation accuracy:		90.11 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.052700
  validation loss:		0.615730
  validation accuracy:		90.22 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.059887
  validation loss:		0.583130
  validation accuracy:		90.76 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.058965
  validation loss:		0.571934
  validation accuracy:		90.76 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.060033
  validation loss:		0.577062
  validation accuracy:		90.33 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.057539
  validation loss:		0.572805
  validation accuracy:		90.87 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.056934
  validation loss:		0.599160
  validation accuracy:		90.33 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.064074
  validation loss:		0.596499
  validation accuracy:		90.33 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.057522
  validation loss:		0.576174
  validation accuracy:		90.76 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.055986
  validation loss:		0.562253
  validation accuracy:		90.76 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.055428
  validation loss:		0.598300
  validation accuracy:		90.22 %
Epoch 1481 of 2000 took 0.096s
  training loss:		0.060548
  validation loss:		0.575653
  validation accuracy:		90.76 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.055183
  validation loss:		0.598308
  validation accuracy:		90.43 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.059788
  validation loss:		0.574384
  validation accuracy:		90.87 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.052980
  validation loss:		0.607693
  validation accuracy:		90.11 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.053664
  validation loss:		0.592006
  validation accuracy:		90.54 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.051404
  validation loss:		0.606024
  validation accuracy:		90.33 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.054835
  validation loss:		0.602757
  validation accuracy:		90.54 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.061044
  validation loss:		0.601444
  validation accuracy:		90.87 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.052291
  validation loss:		0.596498
  validation accuracy:		90.43 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.053481
  validation loss:		0.643732
  validation accuracy:		89.78 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.057289
  validation loss:		0.627848
  validation accuracy:		90.00 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.053653
  validation loss:		0.602963
  validation accuracy:		90.33 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.053831
  validation loss:		0.625706
  validation accuracy:		90.11 %
Epoch 1494 of 2000 took 0.097s
  training loss:		0.064315
  validation loss:		0.598661
  validation accuracy:		90.76 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.050253
  validation loss:		0.606667
  validation accuracy:		90.22 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.053261
  validation loss:		0.602082
  validation accuracy:		90.43 %
Epoch 1497 of 2000 took 0.096s
  training loss:		0.054028
  validation loss:		0.601753
  validation accuracy:		90.76 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.052946
  validation loss:		0.605038
  validation accuracy:		90.33 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.054180
  validation loss:		0.579195
  validation accuracy:		91.09 %
Epoch 1500 of 2000 took 0.096s
  training loss:		0.054735
  validation loss:		0.583131
  validation accuracy:		90.98 %
Epoch 1501 of 2000 took 0.098s
  training loss:		0.058438
  validation loss:		0.638053
  validation accuracy:		90.22 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.061673
  validation loss:		0.616101
  validation accuracy:		90.22 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.051437
  validation loss:		0.594815
  validation accuracy:		90.43 %
Epoch 1504 of 2000 took 0.096s
  training loss:		0.052171
  validation loss:		0.610830
  validation accuracy:		90.43 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.056638
  validation loss:		0.601653
  validation accuracy:		90.76 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.052178
  validation loss:		0.615433
  validation accuracy:		90.33 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.067865
  validation loss:		0.631051
  validation accuracy:		90.11 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.049695
  validation loss:		0.624542
  validation accuracy:		90.22 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.053647
  validation loss:		0.672865
  validation accuracy:		89.67 %
Epoch 1510 of 2000 took 0.096s
  training loss:		0.059433
  validation loss:		0.605218
  validation accuracy:		90.65 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.050922
  validation loss:		0.588248
  validation accuracy:		91.09 %
Epoch 1512 of 2000 took 0.096s
  training loss:		0.053686
  validation loss:		0.640336
  validation accuracy:		90.33 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.053190
  validation loss:		0.612751
  validation accuracy:		90.43 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.047116
  validation loss:		0.621337
  validation accuracy:		90.11 %
Epoch 1515 of 2000 took 0.096s
  training loss:		0.052779
  validation loss:		0.622571
  validation accuracy:		90.22 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.055804
  validation loss:		0.607393
  validation accuracy:		90.43 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.054151
  validation loss:		0.611682
  validation accuracy:		90.87 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.051632
  validation loss:		0.599797
  validation accuracy:		90.98 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.054210
  validation loss:		0.653521
  validation accuracy:		89.67 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.049684
  validation loss:		0.633883
  validation accuracy:		90.43 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.052726
  validation loss:		0.621413
  validation accuracy:		90.65 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.050444
  validation loss:		0.617267
  validation accuracy:		90.22 %
Epoch 1523 of 2000 took 0.096s
  training loss:		0.053854
  validation loss:		0.614298
  validation accuracy:		90.65 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.046908
  validation loss:		0.631683
  validation accuracy:		90.54 %
Epoch 1525 of 2000 took 0.097s
  training loss:		0.053813
  validation loss:		0.623642
  validation accuracy:		90.87 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.050545
  validation loss:		0.630610
  validation accuracy:		90.65 %
Epoch 1527 of 2000 took 0.096s
  training loss:		0.054749
  validation loss:		0.630949
  validation accuracy:		90.87 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.048374
  validation loss:		0.627231
  validation accuracy:		90.65 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.050911
  validation loss:		0.618349
  validation accuracy:		90.65 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.053282
  validation loss:		0.612552
  validation accuracy:		90.76 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.045995
  validation loss:		0.658357
  validation accuracy:		90.00 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.044123
  validation loss:		0.648411
  validation accuracy:		90.33 %
Epoch 1533 of 2000 took 0.096s
  training loss:		0.048778
  validation loss:		0.630111
  validation accuracy:		90.33 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.048228
  validation loss:		0.636964
  validation accuracy:		90.43 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.047678
  validation loss:		0.615148
  validation accuracy:		90.54 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.046084
  validation loss:		0.638210
  validation accuracy:		90.54 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.049628
  validation loss:		0.637915
  validation accuracy:		90.33 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.046711
  validation loss:		0.638768
  validation accuracy:		90.65 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.048440
  validation loss:		0.673191
  validation accuracy:		90.22 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.058190
  validation loss:		0.649480
  validation accuracy:		90.43 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.049587
  validation loss:		0.637883
  validation accuracy:		90.65 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.047189
  validation loss:		0.630196
  validation accuracy:		90.87 %
Epoch 1543 of 2000 took 0.096s
  training loss:		0.047379
  validation loss:		0.627206
  validation accuracy:		91.09 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.049842
  validation loss:		0.647587
  validation accuracy:		90.65 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.050953
  validation loss:		0.637561
  validation accuracy:		90.11 %
Epoch 1546 of 2000 took 0.096s
  training loss:		0.045004
  validation loss:		0.629083
  validation accuracy:		90.54 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.045665
  validation loss:		0.650488
  validation accuracy:		90.65 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.048270
  validation loss:		0.643813
  validation accuracy:		90.43 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.051635
  validation loss:		0.643565
  validation accuracy:		90.54 %
Epoch 1550 of 2000 took 0.096s
  training loss:		0.046697
  validation loss:		0.676488
  validation accuracy:		89.89 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.045604
  validation loss:		0.655227
  validation accuracy:		90.98 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.048572
  validation loss:		0.638124
  validation accuracy:		90.87 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.048115
  validation loss:		0.640405
  validation accuracy:		90.54 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.049721
  validation loss:		0.629824
  validation accuracy:		90.98 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.044007
  validation loss:		0.665486
  validation accuracy:		90.33 %
Epoch 1556 of 2000 took 0.097s
  training loss:		0.048152
  validation loss:		0.654299
  validation accuracy:		90.76 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.045687
  validation loss:		0.673853
  validation accuracy:		90.65 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.046294
  validation loss:		0.646631
  validation accuracy:		90.54 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.052057
  validation loss:		0.668850
  validation accuracy:		90.33 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.047468
  validation loss:		0.656399
  validation accuracy:		90.54 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.050993
  validation loss:		0.654062
  validation accuracy:		90.33 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.046335
  validation loss:		0.657979
  validation accuracy:		90.54 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.046123
  validation loss:		0.672050
  validation accuracy:		90.65 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.048663
  validation loss:		0.653480
  validation accuracy:		90.76 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.041397
  validation loss:		0.645410
  validation accuracy:		90.65 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.054496
  validation loss:		0.692214
  validation accuracy:		90.11 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.046299
  validation loss:		0.657021
  validation accuracy:		90.87 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.048714
  validation loss:		0.674152
  validation accuracy:		90.43 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.049182
  validation loss:		0.644356
  validation accuracy:		91.09 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.044508
  validation loss:		0.671862
  validation accuracy:		90.65 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.043544
  validation loss:		0.654797
  validation accuracy:		90.87 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.046603
  validation loss:		0.687956
  validation accuracy:		90.33 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.045254
  validation loss:		0.663218
  validation accuracy:		91.09 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.053783
  validation loss:		0.677257
  validation accuracy:		90.65 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.049492
  validation loss:		0.666181
  validation accuracy:		90.54 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.043626
  validation loss:		0.676038
  validation accuracy:		90.33 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.046299
  validation loss:		0.686034
  validation accuracy:		90.65 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.046810
  validation loss:		0.666424
  validation accuracy:		90.65 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.039963
  validation loss:		0.704226
  validation accuracy:		90.22 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.044843
  validation loss:		0.650557
  validation accuracy:		90.65 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.044792
  validation loss:		0.667370
  validation accuracy:		90.65 %
Epoch 1582 of 2000 took 0.100s
  training loss:		0.048580
  validation loss:		0.666234
  validation accuracy:		90.43 %
Epoch 1583 of 2000 took 0.099s
  training loss:		0.041067
  validation loss:		0.667833
  validation accuracy:		90.87 %
Epoch 1584 of 2000 took 0.099s
  training loss:		0.044406
  validation loss:		0.688284
  validation accuracy:		90.65 %
Epoch 1585 of 2000 took 0.099s
  training loss:		0.046908
  validation loss:		0.660158
  validation accuracy:		90.98 %
Epoch 1586 of 2000 took 0.099s
  training loss:		0.058309
  validation loss:		0.708074
  validation accuracy:		90.11 %
Epoch 1587 of 2000 took 0.100s
  training loss:		0.045588
  validation loss:		0.676525
  validation accuracy:		90.76 %
Epoch 1588 of 2000 took 0.100s
  training loss:		0.045001
  validation loss:		0.664385
  validation accuracy:		91.09 %
Epoch 1589 of 2000 took 0.099s
  training loss:		0.042341
  validation loss:		0.710195
  validation accuracy:		90.22 %
Epoch 1590 of 2000 took 0.099s
  training loss:		0.043449
  validation loss:		0.687605
  validation accuracy:		90.33 %
Epoch 1591 of 2000 took 0.099s
  training loss:		0.044359
  validation loss:		0.684353
  validation accuracy:		90.76 %
Epoch 1592 of 2000 took 0.099s
  training loss:		0.043865
  validation loss:		0.701180
  validation accuracy:		90.54 %
Epoch 1593 of 2000 took 0.099s
  training loss:		0.042225
  validation loss:		0.718880
  validation accuracy:		89.89 %
Epoch 1594 of 2000 took 0.099s
  training loss:		0.042196
  validation loss:		0.679334
  validation accuracy:		90.65 %
Epoch 1595 of 2000 took 0.099s
  training loss:		0.041469
  validation loss:		0.666431
  validation accuracy:		91.09 %
Epoch 1596 of 2000 took 0.099s
  training loss:		0.041749
  validation loss:		0.692697
  validation accuracy:		90.43 %
Epoch 1597 of 2000 took 0.099s
  training loss:		0.039185
  validation loss:		0.687696
  validation accuracy:		90.65 %
Epoch 1598 of 2000 took 0.099s
  training loss:		0.039395
  validation loss:		0.709485
  validation accuracy:		90.11 %
Epoch 1599 of 2000 took 0.099s
  training loss:		0.040716
  validation loss:		0.701477
  validation accuracy:		90.65 %
Epoch 1600 of 2000 took 0.099s
  training loss:		0.044143
  validation loss:		0.693500
  validation accuracy:		90.33 %
Epoch 1601 of 2000 took 0.099s
  training loss:		0.039588
  validation loss:		0.678171
  validation accuracy:		90.87 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.041297
  validation loss:		0.706710
  validation accuracy:		90.43 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.039223
  validation loss:		0.663174
  validation accuracy:		91.09 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.041573
  validation loss:		0.714342
  validation accuracy:		90.22 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.043816
  validation loss:		0.705884
  validation accuracy:		90.22 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.043710
  validation loss:		0.689537
  validation accuracy:		90.76 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.042345
  validation loss:		0.714784
  validation accuracy:		90.65 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.046422
  validation loss:		0.676841
  validation accuracy:		90.43 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.052471
  validation loss:		0.752234
  validation accuracy:		90.00 %
Epoch 1610 of 2000 took 0.099s
  training loss:		0.047301
  validation loss:		0.687525
  validation accuracy:		90.65 %
Epoch 1611 of 2000 took 0.100s
  training loss:		0.037861
  validation loss:		0.692693
  validation accuracy:		90.43 %
Epoch 1612 of 2000 took 0.099s
  training loss:		0.038850
  validation loss:		0.709164
  validation accuracy:		90.33 %
Epoch 1613 of 2000 took 0.099s
  training loss:		0.038593
  validation loss:		0.691513
  validation accuracy:		90.98 %
Epoch 1614 of 2000 took 0.099s
  training loss:		0.042593
  validation loss:		0.739267
  validation accuracy:		90.33 %
Epoch 1615 of 2000 took 0.099s
  training loss:		0.047118
  validation loss:		0.685905
  validation accuracy:		90.87 %
Epoch 1616 of 2000 took 0.099s
  training loss:		0.038157
  validation loss:		0.693464
  validation accuracy:		91.09 %
Epoch 1617 of 2000 took 0.099s
  training loss:		0.038683
  validation loss:		0.691784
  validation accuracy:		90.65 %
Epoch 1618 of 2000 took 0.100s
  training loss:		0.044401
  validation loss:		0.718826
  validation accuracy:		90.54 %
Epoch 1619 of 2000 took 0.099s
  training loss:		0.039437
  validation loss:		0.729176
  validation accuracy:		90.43 %
Epoch 1620 of 2000 took 0.099s
  training loss:		0.038953
  validation loss:		0.692860
  validation accuracy:		91.20 %
Epoch 1621 of 2000 took 0.099s
  training loss:		0.039772
  validation loss:		0.714288
  validation accuracy:		90.54 %
Epoch 1622 of 2000 took 0.099s
  training loss:		0.042612
  validation loss:		0.709254
  validation accuracy:		90.33 %
Epoch 1623 of 2000 took 0.099s
  training loss:		0.037642
  validation loss:		0.709183
  validation accuracy:		90.98 %
Epoch 1624 of 2000 took 0.099s
  training loss:		0.039949
  validation loss:		0.709798
  validation accuracy:		90.43 %
Epoch 1625 of 2000 took 0.099s
  training loss:		0.039415
  validation loss:		0.703359
  validation accuracy:		90.76 %
Epoch 1626 of 2000 took 0.099s
  training loss:		0.039817
  validation loss:		0.693434
  validation accuracy:		90.33 %
Epoch 1627 of 2000 took 0.099s
  training loss:		0.041628
  validation loss:		0.684577
  validation accuracy:		91.20 %
Epoch 1628 of 2000 took 0.099s
  training loss:		0.041732
  validation loss:		0.706126
  validation accuracy:		90.87 %
Epoch 1629 of 2000 took 0.099s
  training loss:		0.037180
  validation loss:		0.725243
  validation accuracy:		90.76 %
Epoch 1630 of 2000 took 0.099s
  training loss:		0.038951
  validation loss:		0.710280
  validation accuracy:		90.65 %
Epoch 1631 of 2000 took 0.099s
  training loss:		0.041912
  validation loss:		0.726155
  validation accuracy:		90.33 %
Epoch 1632 of 2000 took 0.099s
  training loss:		0.039416
  validation loss:		0.709245
  validation accuracy:		90.54 %
Epoch 1633 of 2000 took 0.099s
  training loss:		0.036111
  validation loss:		0.703935
  validation accuracy:		90.98 %
Epoch 1634 of 2000 took 0.099s
  training loss:		0.037520
  validation loss:		0.725186
  validation accuracy:		90.87 %
Epoch 1635 of 2000 took 0.099s
  training loss:		0.037811
  validation loss:		0.708482
  validation accuracy:		90.65 %
Epoch 1636 of 2000 took 0.099s
  training loss:		0.044919
  validation loss:		0.730477
  validation accuracy:		90.98 %
Epoch 1637 of 2000 took 0.099s
  training loss:		0.036706
  validation loss:		0.754476
  validation accuracy:		90.54 %
Epoch 1638 of 2000 took 0.099s
  training loss:		0.037372
  validation loss:		0.744151
  validation accuracy:		90.22 %
Epoch 1639 of 2000 took 0.099s
  training loss:		5.364233
  validation loss:		4.767790
  validation accuracy:		73.37 %
Epoch 1640 of 2000 took 0.099s
  training loss:		19.597515
  validation loss:		11.202476
  validation accuracy:		42.93 %
Epoch 1641 of 2000 took 0.099s
  training loss:		32.962292
  validation loss:		2.668616
  validation accuracy:		44.57 %
Epoch 1642 of 2000 took 0.099s
  training loss:		1.671611
  validation loss:		1.357922
  validation accuracy:		61.09 %
Epoch 1643 of 2000 took 0.099s
  training loss:		1.317993
  validation loss:		1.056795
  validation accuracy:		69.35 %
Epoch 1644 of 2000 took 0.099s
  training loss:		1.065976
  validation loss:		0.841247
  validation accuracy:		76.74 %
Epoch 1645 of 2000 took 0.099s
  training loss:		0.925217
  validation loss:		0.755736
  validation accuracy:		80.33 %
Epoch 1646 of 2000 took 0.099s
  training loss:		0.840869
  validation loss:		0.710362
  validation accuracy:		81.52 %
Epoch 1647 of 2000 took 0.099s
  training loss:		0.777395
  validation loss:		0.670951
  validation accuracy:		82.28 %
Epoch 1648 of 2000 took 0.100s
  training loss:		0.738911
  validation loss:		0.632075
  validation accuracy:		84.24 %
Epoch 1649 of 2000 took 0.100s
  training loss:		0.700809
  validation loss:		0.595766
  validation accuracy:		85.00 %
Epoch 1650 of 2000 took 0.098s
  training loss:		0.675304
  validation loss:		0.568934
  validation accuracy:		86.41 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.649162
  validation loss:		0.542361
  validation accuracy:		87.72 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.620649
  validation loss:		0.524104
  validation accuracy:		88.26 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.596823
  validation loss:		0.506749
  validation accuracy:		88.26 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.577305
  validation loss:		0.486744
  validation accuracy:		88.48 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.558803
  validation loss:		0.470127
  validation accuracy:		88.91 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.537121
  validation loss:		0.462792
  validation accuracy:		88.59 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.520454
  validation loss:		0.445554
  validation accuracy:		88.70 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.509718
  validation loss:		0.433862
  validation accuracy:		89.02 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.487202
  validation loss:		0.427429
  validation accuracy:		89.24 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.474206
  validation loss:		0.410427
  validation accuracy:		89.78 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.465219
  validation loss:		0.404208
  validation accuracy:		89.67 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.452373
  validation loss:		0.394036
  validation accuracy:		89.67 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.434922
  validation loss:		0.392040
  validation accuracy:		90.11 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.423270
  validation loss:		0.376020
  validation accuracy:		90.22 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.419417
  validation loss:		0.372603
  validation accuracy:		89.89 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.410327
  validation loss:		0.369987
  validation accuracy:		89.89 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.401486
  validation loss:		0.362747
  validation accuracy:		90.22 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.392507
  validation loss:		0.359735
  validation accuracy:		90.43 %
Epoch 1669 of 2000 took 0.096s
  training loss:		0.381825
  validation loss:		0.354167
  validation accuracy:		90.65 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.373367
  validation loss:		0.352991
  validation accuracy:		90.33 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.369858
  validation loss:		0.358319
  validation accuracy:		90.11 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.361101
  validation loss:		0.339606
  validation accuracy:		90.76 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.353784
  validation loss:		0.345966
  validation accuracy:		90.76 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.347311
  validation loss:		0.334512
  validation accuracy:		90.87 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.343486
  validation loss:		0.333711
  validation accuracy:		90.87 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.331920
  validation loss:		0.326071
  validation accuracy:		90.87 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.333945
  validation loss:		0.324998
  validation accuracy:		90.98 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.322087
  validation loss:		0.319257
  validation accuracy:		91.20 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.317333
  validation loss:		0.326774
  validation accuracy:		90.87 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.315215
  validation loss:		0.323513
  validation accuracy:		90.65 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.313457
  validation loss:		0.319289
  validation accuracy:		90.87 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.306279
  validation loss:		0.315700
  validation accuracy:		90.87 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.301628
  validation loss:		0.314503
  validation accuracy:		90.43 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.299365
  validation loss:		0.312089
  validation accuracy:		90.54 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.296095
  validation loss:		0.313664
  validation accuracy:		90.87 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.286234
  validation loss:		0.312446
  validation accuracy:		90.76 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.289778
  validation loss:		0.310063
  validation accuracy:		90.43 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.282806
  validation loss:		0.302736
  validation accuracy:		91.09 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.279070
  validation loss:		0.310558
  validation accuracy:		90.76 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.280941
  validation loss:		0.303816
  validation accuracy:		90.87 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.270100
  validation loss:		0.302760
  validation accuracy:		90.87 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.277064
  validation loss:		0.305612
  validation accuracy:		90.87 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.271864
  validation loss:		0.298798
  validation accuracy:		91.20 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.267576
  validation loss:		0.298768
  validation accuracy:		91.41 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.271210
  validation loss:		0.303044
  validation accuracy:		90.43 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.258165
  validation loss:		0.300547
  validation accuracy:		90.54 %
Epoch 1697 of 2000 took 0.096s
  training loss:		0.262174
  validation loss:		0.299573
  validation accuracy:		91.20 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.257362
  validation loss:		0.293564
  validation accuracy:		91.30 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.253965
  validation loss:		0.297884
  validation accuracy:		90.98 %
Epoch 1700 of 2000 took 0.096s
  training loss:		0.255053
  validation loss:		0.293560
  validation accuracy:		91.52 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.249487
  validation loss:		0.296219
  validation accuracy:		91.20 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.249079
  validation loss:		0.296764
  validation accuracy:		90.98 %
Epoch 1703 of 2000 took 0.096s
  training loss:		0.251998
  validation loss:		0.290390
  validation accuracy:		91.20 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.247498
  validation loss:		0.285828
  validation accuracy:		92.07 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.246190
  validation loss:		0.291309
  validation accuracy:		91.41 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.247790
  validation loss:		0.293435
  validation accuracy:		91.41 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.244247
  validation loss:		0.299445
  validation accuracy:		91.20 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.241894
  validation loss:		0.290186
  validation accuracy:		91.52 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.241812
  validation loss:		0.282814
  validation accuracy:		92.07 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.237189
  validation loss:		0.293933
  validation accuracy:		91.20 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.237737
  validation loss:		0.287796
  validation accuracy:		91.63 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.237643
  validation loss:		0.285366
  validation accuracy:		91.96 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.236623
  validation loss:		0.288342
  validation accuracy:		91.85 %
Epoch 1714 of 2000 took 0.097s
  training loss:		0.228467
  validation loss:		0.287856
  validation accuracy:		91.96 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.233327
  validation loss:		0.300721
  validation accuracy:		90.98 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.227822
  validation loss:		0.286611
  validation accuracy:		91.74 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.231083
  validation loss:		0.288795
  validation accuracy:		91.74 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.230011
  validation loss:		0.285077
  validation accuracy:		91.74 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.224152
  validation loss:		0.288108
  validation accuracy:		91.41 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.226064
  validation loss:		0.275074
  validation accuracy:		92.28 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.228503
  validation loss:		0.284255
  validation accuracy:		91.41 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.218867
  validation loss:		0.287447
  validation accuracy:		91.63 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.220384
  validation loss:		0.282414
  validation accuracy:		91.74 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.222375
  validation loss:		0.282787
  validation accuracy:		91.74 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.223961
  validation loss:		0.294945
  validation accuracy:		91.20 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.221247
  validation loss:		0.286965
  validation accuracy:		91.52 %
Epoch 1727 of 2000 took 0.096s
  training loss:		0.216554
  validation loss:		0.287895
  validation accuracy:		91.09 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.217698
  validation loss:		0.276221
  validation accuracy:		92.17 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.217051
  validation loss:		0.278530
  validation accuracy:		91.63 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.217151
  validation loss:		0.282415
  validation accuracy:		91.63 %
Epoch 1731 of 2000 took 0.096s
  training loss:		0.216807
  validation loss:		0.277971
  validation accuracy:		92.07 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.209914
  validation loss:		0.282458
  validation accuracy:		91.74 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.212269
  validation loss:		0.282502
  validation accuracy:		91.74 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.211306
  validation loss:		0.275241
  validation accuracy:		92.17 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.210691
  validation loss:		0.271181
  validation accuracy:		92.17 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.208426
  validation loss:		0.291716
  validation accuracy:		91.52 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.209850
  validation loss:		0.288388
  validation accuracy:		91.74 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.207723
  validation loss:		0.277464
  validation accuracy:		91.85 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.204989
  validation loss:		0.273931
  validation accuracy:		91.85 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.207371
  validation loss:		0.286706
  validation accuracy:		91.30 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.204310
  validation loss:		0.278328
  validation accuracy:		91.85 %
Epoch 1742 of 2000 took 0.097s
  training loss:		0.203488
  validation loss:		0.286386
  validation accuracy:		91.41 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.202333
  validation loss:		0.282832
  validation accuracy:		91.85 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.197710
  validation loss:		0.274100
  validation accuracy:		91.85 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.201024
  validation loss:		0.272020
  validation accuracy:		92.28 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.206181
  validation loss:		0.287321
  validation accuracy:		91.63 %
Epoch 1747 of 2000 took 0.097s
  training loss:		0.195800
  validation loss:		0.280571
  validation accuracy:		91.63 %
Epoch 1748 of 2000 took 0.099s
  training loss:		0.196661
  validation loss:		0.280122
  validation accuracy:		91.85 %
Epoch 1749 of 2000 took 0.099s
  training loss:		0.196437
  validation loss:		0.274424
  validation accuracy:		91.96 %
Epoch 1750 of 2000 took 0.099s
  training loss:		0.199885
  validation loss:		0.279820
  validation accuracy:		91.85 %
Epoch 1751 of 2000 took 0.099s
  training loss:		0.198011
  validation loss:		0.275761
  validation accuracy:		91.96 %
Epoch 1752 of 2000 took 0.099s
  training loss:		0.191217
  validation loss:		0.270107
  validation accuracy:		92.17 %
Epoch 1753 of 2000 took 0.099s
  training loss:		0.193153
  validation loss:		0.274728
  validation accuracy:		91.96 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.200266
  validation loss:		0.270678
  validation accuracy:		92.07 %
Epoch 1755 of 2000 took 0.099s
  training loss:		0.195647
  validation loss:		0.267042
  validation accuracy:		92.17 %
Epoch 1756 of 2000 took 0.099s
  training loss:		0.197510
  validation loss:		0.277428
  validation accuracy:		91.85 %
Epoch 1757 of 2000 took 0.099s
  training loss:		0.193251
  validation loss:		0.275642
  validation accuracy:		92.07 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.197614
  validation loss:		0.296398
  validation accuracy:		91.52 %
Epoch 1759 of 2000 took 0.099s
  training loss:		0.195808
  validation loss:		0.287036
  validation accuracy:		91.63 %
Epoch 1760 of 2000 took 0.099s
  training loss:		0.192648
  validation loss:		0.272488
  validation accuracy:		91.96 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.192764
  validation loss:		0.278176
  validation accuracy:		91.63 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.191044
  validation loss:		0.279135
  validation accuracy:		91.63 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.191492
  validation loss:		0.269341
  validation accuracy:		92.17 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.191003
  validation loss:		0.274159
  validation accuracy:		91.85 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.189397
  validation loss:		0.271677
  validation accuracy:		92.17 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.188516
  validation loss:		0.279384
  validation accuracy:		91.63 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.189047
  validation loss:		0.272942
  validation accuracy:		91.96 %
Epoch 1768 of 2000 took 0.096s
  training loss:		0.186645
  validation loss:		0.271420
  validation accuracy:		91.74 %
Epoch 1769 of 2000 took 0.098s
  training loss:		0.185419
  validation loss:		0.268604
  validation accuracy:		92.07 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.184023
  validation loss:		0.271603
  validation accuracy:		91.74 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.183618
  validation loss:		0.270644
  validation accuracy:		92.07 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.185637
  validation loss:		0.281102
  validation accuracy:		91.63 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.182376
  validation loss:		0.282619
  validation accuracy:		91.85 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.185079
  validation loss:		0.276010
  validation accuracy:		91.74 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.185902
  validation loss:		0.278980
  validation accuracy:		91.74 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.183792
  validation loss:		0.276485
  validation accuracy:		92.07 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.182138
  validation loss:		0.267098
  validation accuracy:		92.07 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.176664
  validation loss:		0.265934
  validation accuracy:		91.96 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.181961
  validation loss:		0.264626
  validation accuracy:		92.17 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.178213
  validation loss:		0.273508
  validation accuracy:		92.17 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.182118
  validation loss:		0.269867
  validation accuracy:		91.52 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.176552
  validation loss:		0.271544
  validation accuracy:		91.85 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.176113
  validation loss:		0.274459
  validation accuracy:		91.74 %
Epoch 1784 of 2000 took 0.096s
  training loss:		0.182877
  validation loss:		0.279298
  validation accuracy:		91.63 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.172600
  validation loss:		0.267867
  validation accuracy:		91.85 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.179942
  validation loss:		0.270303
  validation accuracy:		91.85 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.178324
  validation loss:		0.290451
  validation accuracy:		91.52 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.177148
  validation loss:		0.267441
  validation accuracy:		91.96 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.177831
  validation loss:		0.280721
  validation accuracy:		91.52 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.173376
  validation loss:		0.267551
  validation accuracy:		92.07 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.176282
  validation loss:		0.268494
  validation accuracy:		91.74 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.175414
  validation loss:		0.267090
  validation accuracy:		92.28 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.178054
  validation loss:		0.266270
  validation accuracy:		92.07 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.174724
  validation loss:		0.267620
  validation accuracy:		92.07 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.170435
  validation loss:		0.271585
  validation accuracy:		92.07 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.170853
  validation loss:		0.279015
  validation accuracy:		91.74 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.172944
  validation loss:		0.267584
  validation accuracy:		92.28 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.169719
  validation loss:		0.267094
  validation accuracy:		92.17 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.170633
  validation loss:		0.284396
  validation accuracy:		91.85 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.172632
  validation loss:		0.262245
  validation accuracy:		92.17 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.171234
  validation loss:		0.269173
  validation accuracy:		91.63 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.172089
  validation loss:		0.264176
  validation accuracy:		91.96 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.171727
  validation loss:		0.265275
  validation accuracy:		92.07 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.169494
  validation loss:		0.274986
  validation accuracy:		91.85 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.167941
  validation loss:		0.268159
  validation accuracy:		91.96 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.171366
  validation loss:		0.267545
  validation accuracy:		92.17 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.164475
  validation loss:		0.262822
  validation accuracy:		92.17 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.171104
  validation loss:		0.272396
  validation accuracy:		91.63 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.165963
  validation loss:		0.265862
  validation accuracy:		92.07 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.164291
  validation loss:		0.271748
  validation accuracy:		91.96 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.169417
  validation loss:		0.266927
  validation accuracy:		92.07 %
Epoch 1812 of 2000 took 0.096s
  training loss:		0.169261
  validation loss:		0.274531
  validation accuracy:		92.07 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.167431
  validation loss:		0.266492
  validation accuracy:		91.96 %
Epoch 1814 of 2000 took 0.096s
  training loss:		0.166210
  validation loss:		0.267127
  validation accuracy:		91.96 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.165393
  validation loss:		0.278058
  validation accuracy:		91.85 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.165064
  validation loss:		0.271390
  validation accuracy:		91.85 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.162199
  validation loss:		0.269629
  validation accuracy:		92.07 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.161366
  validation loss:		0.262466
  validation accuracy:		92.17 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.157530
  validation loss:		0.263370
  validation accuracy:		92.07 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.162202
  validation loss:		0.265381
  validation accuracy:		92.07 %
Epoch 1821 of 2000 took 0.096s
  training loss:		0.163851
  validation loss:		0.275066
  validation accuracy:		92.07 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.166023
  validation loss:		0.274035
  validation accuracy:		91.85 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.161795
  validation loss:		0.264452
  validation accuracy:		92.17 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.160450
  validation loss:		0.261969
  validation accuracy:		92.28 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.159957
  validation loss:		0.266101
  validation accuracy:		92.17 %
Epoch 1826 of 2000 took 0.096s
  training loss:		0.157533
  validation loss:		0.276256
  validation accuracy:		91.85 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.162835
  validation loss:		0.262432
  validation accuracy:		92.17 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.160715
  validation loss:		0.275292
  validation accuracy:		92.39 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.160432
  validation loss:		0.262337
  validation accuracy:		92.28 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.160768
  validation loss:		0.265881
  validation accuracy:		92.07 %
Epoch 1831 of 2000 took 0.096s
  training loss:		0.160172
  validation loss:		0.261819
  validation accuracy:		92.28 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.157856
  validation loss:		0.265077
  validation accuracy:		92.17 %
Epoch 1833 of 2000 took 0.096s
  training loss:		0.157338
  validation loss:		0.268802
  validation accuracy:		91.85 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.159082
  validation loss:		0.273329
  validation accuracy:		91.63 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.160152
  validation loss:		0.272703
  validation accuracy:		91.85 %
Epoch 1836 of 2000 took 0.097s
  training loss:		0.153625
  validation loss:		0.257668
  validation accuracy:		92.39 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.158336
  validation loss:		0.265376
  validation accuracy:		91.52 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.157700
  validation loss:		0.256472
  validation accuracy:		92.28 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.154657
  validation loss:		0.273390
  validation accuracy:		91.96 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.155942
  validation loss:		0.264172
  validation accuracy:		92.07 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.152645
  validation loss:		0.264179
  validation accuracy:		92.28 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.154087
  validation loss:		0.271134
  validation accuracy:		92.17 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.158392
  validation loss:		0.271473
  validation accuracy:		91.96 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.155865
  validation loss:		0.275030
  validation accuracy:		91.85 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.155407
  validation loss:		0.268774
  validation accuracy:		92.28 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.156566
  validation loss:		0.270257
  validation accuracy:		91.85 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.153676
  validation loss:		0.267672
  validation accuracy:		92.17 %
Epoch 1848 of 2000 took 0.096s
  training loss:		0.154759
  validation loss:		0.265753
  validation accuracy:		92.07 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.151793
  validation loss:		0.274760
  validation accuracy:		92.07 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.152573
  validation loss:		0.273149
  validation accuracy:		92.17 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.153390
  validation loss:		0.275622
  validation accuracy:		91.74 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.150501
  validation loss:		0.275601
  validation accuracy:		91.63 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.152427
  validation loss:		0.261779
  validation accuracy:		92.07 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.150951
  validation loss:		0.264389
  validation accuracy:		92.17 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.151882
  validation loss:		0.271247
  validation accuracy:		91.96 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.151457
  validation loss:		0.261304
  validation accuracy:		92.07 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.149326
  validation loss:		0.261277
  validation accuracy:		92.28 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.150866
  validation loss:		0.267988
  validation accuracy:		91.96 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.149567
  validation loss:		0.267547
  validation accuracy:		91.74 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.151550
  validation loss:		0.274749
  validation accuracy:		91.52 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.147526
  validation loss:		0.264854
  validation accuracy:		92.39 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.148454
  validation loss:		0.266989
  validation accuracy:		92.17 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.149195
  validation loss:		0.261435
  validation accuracy:		91.96 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.148297
  validation loss:		0.272912
  validation accuracy:		91.74 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.147274
  validation loss:		0.272713
  validation accuracy:		91.96 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.146802
  validation loss:		0.261520
  validation accuracy:		92.07 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.146591
  validation loss:		0.264408
  validation accuracy:		91.85 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.147535
  validation loss:		0.258752
  validation accuracy:		92.39 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.146210
  validation loss:		0.270527
  validation accuracy:		91.96 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.144294
  validation loss:		0.272966
  validation accuracy:		91.96 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.144766
  validation loss:		0.269560
  validation accuracy:		92.17 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.145529
  validation loss:		0.270765
  validation accuracy:		91.85 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.144745
  validation loss:		0.278588
  validation accuracy:		91.52 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.145621
  validation loss:		0.262719
  validation accuracy:		92.28 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.146624
  validation loss:		0.270408
  validation accuracy:		91.85 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.143676
  validation loss:		0.263209
  validation accuracy:		92.50 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.145413
  validation loss:		0.262619
  validation accuracy:		92.07 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.146048
  validation loss:		0.269631
  validation accuracy:		91.74 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.144084
  validation loss:		0.271353
  validation accuracy:		91.96 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.145601
  validation loss:		0.261686
  validation accuracy:		92.50 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.141917
  validation loss:		0.270751
  validation accuracy:		91.63 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.144165
  validation loss:		0.265239
  validation accuracy:		92.28 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.143983
  validation loss:		0.277767
  validation accuracy:		92.17 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.143168
  validation loss:		0.267195
  validation accuracy:		92.07 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.143680
  validation loss:		0.267837
  validation accuracy:		91.85 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.146199
  validation loss:		0.262900
  validation accuracy:		92.17 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.142966
  validation loss:		0.274435
  validation accuracy:		91.74 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.140255
  validation loss:		0.269265
  validation accuracy:		91.63 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.141795
  validation loss:		0.270913
  validation accuracy:		92.17 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.142577
  validation loss:		0.263478
  validation accuracy:		92.17 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.140212
  validation loss:		0.263067
  validation accuracy:		92.28 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.139021
  validation loss:		0.259709
  validation accuracy:		92.39 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.142123
  validation loss:		0.268309
  validation accuracy:		92.28 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.139698
  validation loss:		0.264636
  validation accuracy:		91.85 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.141545
  validation loss:		0.280254
  validation accuracy:		92.07 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.141305
  validation loss:		0.262821
  validation accuracy:		92.17 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.136319
  validation loss:		0.257944
  validation accuracy:		92.50 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.134322
  validation loss:		0.287221
  validation accuracy:		91.63 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.138420
  validation loss:		0.268291
  validation accuracy:		92.39 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.140239
  validation loss:		0.272217
  validation accuracy:		91.74 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.136128
  validation loss:		0.260872
  validation accuracy:		92.07 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.138320
  validation loss:		0.264328
  validation accuracy:		92.28 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.138421
  validation loss:		0.266367
  validation accuracy:		92.07 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.137994
  validation loss:		0.261383
  validation accuracy:		92.17 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.134743
  validation loss:		0.257145
  validation accuracy:		92.28 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.139581
  validation loss:		0.268704
  validation accuracy:		91.85 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.137438
  validation loss:		0.265968
  validation accuracy:		92.28 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.131997
  validation loss:		0.266906
  validation accuracy:		92.28 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.137503
  validation loss:		0.266650
  validation accuracy:		92.28 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.134528
  validation loss:		0.263657
  validation accuracy:		91.96 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.137003
  validation loss:		0.262972
  validation accuracy:		92.39 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.138691
  validation loss:		0.263284
  validation accuracy:		92.07 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.134868
  validation loss:		0.273460
  validation accuracy:		92.17 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.134119
  validation loss:		0.270827
  validation accuracy:		91.85 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.129830
  validation loss:		0.272792
  validation accuracy:		92.17 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.133792
  validation loss:		0.265341
  validation accuracy:		91.74 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.133121
  validation loss:		0.276469
  validation accuracy:		92.17 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.133751
  validation loss:		0.267036
  validation accuracy:		92.07 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.132969
  validation loss:		0.267321
  validation accuracy:		92.07 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.132371
  validation loss:		0.268874
  validation accuracy:		91.74 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.132562
  validation loss:		0.258612
  validation accuracy:		91.96 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.133407
  validation loss:		0.272375
  validation accuracy:		92.17 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.132432
  validation loss:		0.272283
  validation accuracy:		91.85 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.130279
  validation loss:		0.290415
  validation accuracy:		91.96 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.133291
  validation loss:		0.283002
  validation accuracy:		91.85 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.133520
  validation loss:		0.266943
  validation accuracy:		91.96 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.130547
  validation loss:		0.272316
  validation accuracy:		92.17 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.129070
  validation loss:		0.259207
  validation accuracy:		91.85 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.132824
  validation loss:		0.275744
  validation accuracy:		91.63 %
Epoch 1930 of 2000 took 0.097s
  training loss:		0.129498
  validation loss:		0.266793
  validation accuracy:		92.17 %
Epoch 1931 of 2000 took 0.096s
  training loss:		0.131870
  validation loss:		0.273751
  validation accuracy:		92.17 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.131444
  validation loss:		0.275676
  validation accuracy:		91.96 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.126104
  validation loss:		0.267278
  validation accuracy:		92.28 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.129356
  validation loss:		0.269733
  validation accuracy:		92.07 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.130838
  validation loss:		0.275582
  validation accuracy:		92.17 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.128455
  validation loss:		0.274480
  validation accuracy:		91.85 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.129249
  validation loss:		0.264093
  validation accuracy:		91.96 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.130181
  validation loss:		0.268604
  validation accuracy:		91.74 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.127442
  validation loss:		0.269923
  validation accuracy:		92.07 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.130762
  validation loss:		0.270452
  validation accuracy:		91.96 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.128691
  validation loss:		0.273025
  validation accuracy:		91.96 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.126622
  validation loss:		0.275112
  validation accuracy:		91.96 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.127528
  validation loss:		0.267871
  validation accuracy:		92.17 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.121637
  validation loss:		0.269546
  validation accuracy:		91.96 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.126247
  validation loss:		0.275302
  validation accuracy:		91.74 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.126089
  validation loss:		0.272199
  validation accuracy:		92.17 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.125716
  validation loss:		0.267906
  validation accuracy:		91.96 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.125071
  validation loss:		0.270588
  validation accuracy:		92.07 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.123168
  validation loss:		0.279955
  validation accuracy:		91.74 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.127587
  validation loss:		0.274675
  validation accuracy:		91.63 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.125705
  validation loss:		0.268584
  validation accuracy:		91.85 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.125865
  validation loss:		0.271978
  validation accuracy:		91.85 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.127417
  validation loss:		0.272541
  validation accuracy:		91.85 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.126408
  validation loss:		0.265862
  validation accuracy:		91.96 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.126953
  validation loss:		0.276515
  validation accuracy:		91.96 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.127248
  validation loss:		0.274697
  validation accuracy:		91.74 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.125559
  validation loss:		0.276197
  validation accuracy:		91.74 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.123655
  validation loss:		0.264956
  validation accuracy:		91.63 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.122200
  validation loss:		0.270765
  validation accuracy:		91.96 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.124022
  validation loss:		0.265020
  validation accuracy:		91.85 %
Epoch 1961 of 2000 took 0.097s
  training loss:		0.124746
  validation loss:		0.264734
  validation accuracy:		91.96 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.123279
  validation loss:		0.274531
  validation accuracy:		91.74 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.124609
  validation loss:		0.263769
  validation accuracy:		91.96 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.120912
  validation loss:		0.266515
  validation accuracy:		91.96 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.123729
  validation loss:		0.279879
  validation accuracy:		91.52 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.119618
  validation loss:		0.278887
  validation accuracy:		91.52 %
Epoch 1967 of 2000 took 0.097s
  training loss:		0.119998
  validation loss:		0.260333
  validation accuracy:		91.74 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.121811
  validation loss:		0.277367
  validation accuracy:		91.74 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.119344
  validation loss:		0.264341
  validation accuracy:		91.85 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.122636
  validation loss:		0.270210
  validation accuracy:		91.96 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.120151
  validation loss:		0.281865
  validation accuracy:		91.41 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.120132
  validation loss:		0.264561
  validation accuracy:		91.85 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.121011
  validation loss:		0.265092
  validation accuracy:		92.17 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.118187
  validation loss:		0.278179
  validation accuracy:		91.74 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.119972
  validation loss:		0.271681
  validation accuracy:		91.74 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.120377
  validation loss:		0.260082
  validation accuracy:		91.96 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.121885
  validation loss:		0.271443
  validation accuracy:		91.63 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.119087
  validation loss:		0.269072
  validation accuracy:		91.96 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.119267
  validation loss:		0.270229
  validation accuracy:		91.96 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.119982
  validation loss:		0.268110
  validation accuracy:		92.07 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.119759
  validation loss:		0.286571
  validation accuracy:		91.63 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.115588
  validation loss:		0.277157
  validation accuracy:		91.41 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.119890
  validation loss:		0.264076
  validation accuracy:		91.63 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.119290
  validation loss:		0.271874
  validation accuracy:		91.63 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.117877
  validation loss:		0.273090
  validation accuracy:		91.74 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.116779
  validation loss:		0.279094
  validation accuracy:		91.41 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.121302
  validation loss:		0.277526
  validation accuracy:		91.85 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.115752
  validation loss:		0.269747
  validation accuracy:		91.74 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.112812
  validation loss:		0.273185
  validation accuracy:		91.63 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.117183
  validation loss:		0.277536
  validation accuracy:		91.52 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.116185
  validation loss:		0.273132
  validation accuracy:		91.63 %
Epoch 1992 of 2000 took 0.097s
  training loss:		0.111113
  validation loss:		0.281870
  validation accuracy:		91.52 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.117724
  validation loss:		0.270817
  validation accuracy:		91.85 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.116663
  validation loss:		0.280148
  validation accuracy:		91.74 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.116087
  validation loss:		0.280014
  validation accuracy:		91.63 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.118359
  validation loss:		0.269934
  validation accuracy:		91.85 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.116649
  validation loss:		0.282001
  validation accuracy:		91.63 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.116343
  validation loss:		0.285165
  validation accuracy:		91.74 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.114149
  validation loss:		0.274234
  validation accuracy:		91.41 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.117553
  validation loss:		0.280777
  validation accuracy:		91.63 %
Final results:
  test loss:			0.726381
  test accuracy:		83.01 %
