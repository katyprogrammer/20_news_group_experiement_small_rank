Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		2.999537
  validation loss:		3.000227
  validation accuracy:		0.00 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.992644
  validation loss:		2.990691
  validation accuracy:		10.76 %
Epoch 3 of 2000 took 0.097s
  training loss:		2.983144
  validation loss:		2.979810
  validation accuracy:		10.76 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.973187
  validation loss:		2.968454
  validation accuracy:		10.76 %
Epoch 5 of 2000 took 0.097s
  training loss:		2.962840
  validation loss:		2.957186
  validation accuracy:		10.76 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.952442
  validation loss:		2.945934
  validation accuracy:		10.76 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.942458
  validation loss:		2.934887
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.932633
  validation loss:		2.923940
  validation accuracy:		12.83 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.922353
  validation loss:		2.913272
  validation accuracy:		12.83 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.913249
  validation loss:		2.902772
  validation accuracy:		12.83 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.903622
  validation loss:		2.892324
  validation accuracy:		12.83 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.894226
  validation loss:		2.882067
  validation accuracy:		12.83 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.885288
  validation loss:		2.871982
  validation accuracy:		12.83 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.876287
  validation loss:		2.861979
  validation accuracy:		12.83 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.867493
  validation loss:		2.852128
  validation accuracy:		12.83 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.858436
  validation loss:		2.842361
  validation accuracy:		12.83 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.849698
  validation loss:		2.832705
  validation accuracy:		12.83 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.840332
  validation loss:		2.823067
  validation accuracy:		12.83 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.832198
  validation loss:		2.813586
  validation accuracy:		12.83 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.823643
  validation loss:		2.804092
  validation accuracy:		12.83 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.815228
  validation loss:		2.794819
  validation accuracy:		12.83 %
Epoch 22 of 2000 took 0.098s
  training loss:		2.806824
  validation loss:		2.785506
  validation accuracy:		12.83 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.798503
  validation loss:		2.776287
  validation accuracy:		12.83 %
Epoch 24 of 2000 took 0.098s
  training loss:		2.789829
  validation loss:		2.767073
  validation accuracy:		12.83 %
Epoch 25 of 2000 took 0.100s
  training loss:		2.781699
  validation loss:		2.757966
  validation accuracy:		12.83 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.774008
  validation loss:		2.748867
  validation accuracy:		12.83 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.765716
  validation loss:		2.739875
  validation accuracy:		12.83 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.757187
  validation loss:		2.730767
  validation accuracy:		12.83 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.750092
  validation loss:		2.721820
  validation accuracy:		12.83 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.741457
  validation loss:		2.712895
  validation accuracy:		12.83 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.734093
  validation loss:		2.703994
  validation accuracy:		12.83 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.725973
  validation loss:		2.695231
  validation accuracy:		12.83 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.717452
  validation loss:		2.686367
  validation accuracy:		12.83 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.709790
  validation loss:		2.677566
  validation accuracy:		12.83 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.702009
  validation loss:		2.668701
  validation accuracy:		12.83 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.694569
  validation loss:		2.659925
  validation accuracy:		12.83 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.686052
  validation loss:		2.651198
  validation accuracy:		12.83 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.678912
  validation loss:		2.642481
  validation accuracy:		12.83 %
Epoch 39 of 2000 took 0.097s
  training loss:		2.670685
  validation loss:		2.633825
  validation accuracy:		12.83 %
Epoch 40 of 2000 took 0.096s
  training loss:		2.662606
  validation loss:		2.625004
  validation accuracy:		12.83 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.655336
  validation loss:		2.616224
  validation accuracy:		12.83 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.647243
  validation loss:		2.607411
  validation accuracy:		12.83 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.639014
  validation loss:		2.598643
  validation accuracy:		12.83 %
Epoch 44 of 2000 took 0.097s
  training loss:		2.632553
  validation loss:		2.589941
  validation accuracy:		12.83 %
Epoch 45 of 2000 took 0.097s
  training loss:		2.625014
  validation loss:		2.581333
  validation accuracy:		12.83 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.615992
  validation loss:		2.572639
  validation accuracy:		12.83 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.607921
  validation loss:		2.563761
  validation accuracy:		12.83 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.600856
  validation loss:		2.555047
  validation accuracy:		12.83 %
Epoch 49 of 2000 took 0.096s
  training loss:		2.592477
  validation loss:		2.546116
  validation accuracy:		12.83 %
Epoch 50 of 2000 took 0.097s
  training loss:		2.585691
  validation loss:		2.537427
  validation accuracy:		12.83 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.576862
  validation loss:		2.528636
  validation accuracy:		12.83 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.569997
  validation loss:		2.519924
  validation accuracy:		12.83 %
Epoch 53 of 2000 took 0.098s
  training loss:		2.560952
  validation loss:		2.511027
  validation accuracy:		12.83 %
Epoch 54 of 2000 took 0.097s
  training loss:		2.553897
  validation loss:		2.502305
  validation accuracy:		12.83 %
Epoch 55 of 2000 took 0.097s
  training loss:		2.544779
  validation loss:		2.493386
  validation accuracy:		12.83 %
Epoch 56 of 2000 took 0.097s
  training loss:		2.537372
  validation loss:		2.484537
  validation accuracy:		12.83 %
Epoch 57 of 2000 took 0.097s
  training loss:		2.528872
  validation loss:		2.475451
  validation accuracy:		12.83 %
Epoch 58 of 2000 took 0.097s
  training loss:		2.521343
  validation loss:		2.466501
  validation accuracy:		12.83 %
Epoch 59 of 2000 took 0.096s
  training loss:		2.513899
  validation loss:		2.457597
  validation accuracy:		12.83 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.504205
  validation loss:		2.448518
  validation accuracy:		12.83 %
Epoch 61 of 2000 took 0.097s
  training loss:		2.497740
  validation loss:		2.439428
  validation accuracy:		12.83 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.487243
  validation loss:		2.430239
  validation accuracy:		12.83 %
Epoch 63 of 2000 took 0.097s
  training loss:		2.480635
  validation loss:		2.421299
  validation accuracy:		12.83 %
Epoch 64 of 2000 took 0.097s
  training loss:		2.474133
  validation loss:		2.412458
  validation accuracy:		12.83 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.465576
  validation loss:		2.403663
  validation accuracy:		12.83 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.456993
  validation loss:		2.394904
  validation accuracy:		12.83 %
Epoch 67 of 2000 took 0.097s
  training loss:		2.449187
  validation loss:		2.386010
  validation accuracy:		12.83 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.441142
  validation loss:		2.377182
  validation accuracy:		12.83 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.433320
  validation loss:		2.368813
  validation accuracy:		12.83 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.424407
  validation loss:		2.360174
  validation accuracy:		12.83 %
Epoch 71 of 2000 took 0.101s
  training loss:		2.415558
  validation loss:		2.351578
  validation accuracy:		12.83 %
Epoch 72 of 2000 took 0.097s
  training loss:		2.408863
  validation loss:		2.343381
  validation accuracy:		12.83 %
Epoch 73 of 2000 took 0.096s
  training loss:		2.401462
  validation loss:		2.335337
  validation accuracy:		12.83 %
Epoch 74 of 2000 took 0.097s
  training loss:		2.394478
  validation loss:		2.327615
  validation accuracy:		12.83 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.384873
  validation loss:		2.320184
  validation accuracy:		12.83 %
Epoch 76 of 2000 took 0.097s
  training loss:		2.379244
  validation loss:		2.313020
  validation accuracy:		12.83 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.372678
  validation loss:		2.306443
  validation accuracy:		12.83 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.367748
  validation loss:		2.300919
  validation accuracy:		12.83 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.359169
  validation loss:		2.295183
  validation accuracy:		12.83 %
Epoch 80 of 2000 took 0.097s
  training loss:		2.354065
  validation loss:		2.290235
  validation accuracy:		12.83 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.349370
  validation loss:		2.285558
  validation accuracy:		12.83 %
Epoch 82 of 2000 took 0.096s
  training loss:		2.343961
  validation loss:		2.281292
  validation accuracy:		12.93 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.338114
  validation loss:		2.277222
  validation accuracy:		13.04 %
Epoch 84 of 2000 took 0.098s
  training loss:		2.335040
  validation loss:		2.274028
  validation accuracy:		13.04 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.329825
  validation loss:		2.270644
  validation accuracy:		13.04 %
Epoch 86 of 2000 took 0.096s
  training loss:		2.327255
  validation loss:		2.268424
  validation accuracy:		13.04 %
Epoch 87 of 2000 took 0.097s
  training loss:		2.323982
  validation loss:		2.265927
  validation accuracy:		13.04 %
Epoch 88 of 2000 took 0.097s
  training loss:		2.322256
  validation loss:		2.264307
  validation accuracy:		13.04 %
Epoch 89 of 2000 took 0.097s
  training loss:		2.319104
  validation loss:		2.263241
  validation accuracy:		13.04 %
Epoch 90 of 2000 took 0.096s
  training loss:		2.317220
  validation loss:		2.262061
  validation accuracy:		13.04 %
Epoch 91 of 2000 took 0.097s
  training loss:		2.314546
  validation loss:		2.260705
  validation accuracy:		13.04 %
Epoch 92 of 2000 took 0.096s
  training loss:		2.313307
  validation loss:		2.259084
  validation accuracy:		13.04 %
Epoch 93 of 2000 took 0.097s
  training loss:		2.310886
  validation loss:		2.257569
  validation accuracy:		13.04 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.309347
  validation loss:		2.256212
  validation accuracy:		12.83 %
Epoch 95 of 2000 took 0.097s
  training loss:		2.307938
  validation loss:		2.255085
  validation accuracy:		12.83 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.306943
  validation loss:		2.254064
  validation accuracy:		12.83 %
Epoch 97 of 2000 took 0.097s
  training loss:		2.306096
  validation loss:		2.253145
  validation accuracy:		12.93 %
Epoch 98 of 2000 took 0.097s
  training loss:		2.305781
  validation loss:		2.252189
  validation accuracy:		12.93 %
Epoch 99 of 2000 took 0.097s
  training loss:		2.304602
  validation loss:		2.252815
  validation accuracy:		12.93 %
Epoch 100 of 2000 took 0.096s
  training loss:		2.303605
  validation loss:		2.252063
  validation accuracy:		14.67 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.302802
  validation loss:		2.251923
  validation accuracy:		12.93 %
Epoch 102 of 2000 took 0.097s
  training loss:		2.302365
  validation loss:		2.250852
  validation accuracy:		12.93 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.302021
  validation loss:		2.250533
  validation accuracy:		12.93 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.301581
  validation loss:		2.250468
  validation accuracy:		12.93 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.301387
  validation loss:		2.250419
  validation accuracy:		13.04 %
Epoch 106 of 2000 took 0.097s
  training loss:		2.299951
  validation loss:		2.249545
  validation accuracy:		13.04 %
Epoch 107 of 2000 took 0.096s
  training loss:		2.299986
  validation loss:		2.248488
  validation accuracy:		13.04 %
Epoch 108 of 2000 took 0.097s
  training loss:		2.299877
  validation loss:		2.248010
  validation accuracy:		13.04 %
Epoch 109 of 2000 took 0.096s
  training loss:		2.300238
  validation loss:		2.248689
  validation accuracy:		12.83 %
Epoch 110 of 2000 took 0.097s
  training loss:		2.300099
  validation loss:		2.249180
  validation accuracy:		13.04 %
Epoch 111 of 2000 took 0.097s
  training loss:		2.298904
  validation loss:		2.248733
  validation accuracy:		12.83 %
Epoch 112 of 2000 took 0.097s
  training loss:		2.298218
  validation loss:		2.248902
  validation accuracy:		12.83 %
Epoch 113 of 2000 took 0.097s
  training loss:		2.298383
  validation loss:		2.247553
  validation accuracy:		13.04 %
Epoch 114 of 2000 took 0.097s
  training loss:		2.298048
  validation loss:		2.245522
  validation accuracy:		13.04 %
Epoch 115 of 2000 took 0.098s
  training loss:		2.297585
  validation loss:		2.245201
  validation accuracy:		12.93 %
Epoch 116 of 2000 took 0.097s
  training loss:		2.298496
  validation loss:		2.245736
  validation accuracy:		12.93 %
Epoch 117 of 2000 took 0.097s
  training loss:		2.297621
  validation loss:		2.246306
  validation accuracy:		12.93 %
Epoch 118 of 2000 took 0.097s
  training loss:		2.297987
  validation loss:		2.247091
  validation accuracy:		12.93 %
Epoch 119 of 2000 took 0.097s
  training loss:		2.297393
  validation loss:		2.247087
  validation accuracy:		12.93 %
Epoch 120 of 2000 took 0.096s
  training loss:		2.297813
  validation loss:		2.247174
  validation accuracy:		13.04 %
Epoch 121 of 2000 took 0.097s
  training loss:		2.296394
  validation loss:		2.247254
  validation accuracy:		12.83 %
Epoch 122 of 2000 took 0.097s
  training loss:		2.297267
  validation loss:		2.246904
  validation accuracy:		12.83 %
Epoch 123 of 2000 took 0.096s
  training loss:		2.296759
  validation loss:		2.246116
  validation accuracy:		12.83 %
Epoch 124 of 2000 took 0.097s
  training loss:		2.296099
  validation loss:		2.245151
  validation accuracy:		12.93 %
Epoch 125 of 2000 took 0.096s
  training loss:		2.296673
  validation loss:		2.244222
  validation accuracy:		12.93 %
Epoch 126 of 2000 took 0.097s
  training loss:		2.297012
  validation loss:		2.245487
  validation accuracy:		13.04 %
Epoch 127 of 2000 took 0.097s
  training loss:		2.296628
  validation loss:		2.245833
  validation accuracy:		13.04 %
Epoch 128 of 2000 took 0.097s
  training loss:		2.296526
  validation loss:		2.246068
  validation accuracy:		13.04 %
Epoch 129 of 2000 took 0.097s
  training loss:		2.295554
  validation loss:		2.244405
  validation accuracy:		12.93 %
Epoch 130 of 2000 took 0.097s
  training loss:		2.295876
  validation loss:		2.244712
  validation accuracy:		12.93 %
Epoch 131 of 2000 took 0.097s
  training loss:		2.295467
  validation loss:		2.244298
  validation accuracy:		13.04 %
Epoch 132 of 2000 took 0.096s
  training loss:		2.296815
  validation loss:		2.244353
  validation accuracy:		13.04 %
Epoch 133 of 2000 took 0.097s
  training loss:		2.295281
  validation loss:		2.245502
  validation accuracy:		13.04 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.296397
  validation loss:		2.245874
  validation accuracy:		12.83 %
Epoch 135 of 2000 took 0.096s
  training loss:		2.296232
  validation loss:		2.246437
  validation accuracy:		12.93 %
Epoch 136 of 2000 took 0.101s
  training loss:		2.295716
  validation loss:		2.246851
  validation accuracy:		13.04 %
Epoch 137 of 2000 took 0.096s
  training loss:		2.295813
  validation loss:		2.243817
  validation accuracy:		12.83 %
Epoch 138 of 2000 took 0.097s
  training loss:		2.296613
  validation loss:		2.243918
  validation accuracy:		12.83 %
Epoch 139 of 2000 took 0.097s
  training loss:		2.295730
  validation loss:		2.245151
  validation accuracy:		12.83 %
Epoch 140 of 2000 took 0.097s
  training loss:		2.295305
  validation loss:		2.244588
  validation accuracy:		12.93 %
Epoch 141 of 2000 took 0.097s
  training loss:		2.296160
  validation loss:		2.245120
  validation accuracy:		12.93 %
Epoch 142 of 2000 took 0.097s
  training loss:		2.296042
  validation loss:		2.247485
  validation accuracy:		12.93 %
Epoch 143 of 2000 took 0.097s
  training loss:		2.295776
  validation loss:		2.244378
  validation accuracy:		12.93 %
Epoch 144 of 2000 took 0.097s
  training loss:		2.294596
  validation loss:		2.244263
  validation accuracy:		12.83 %
Epoch 145 of 2000 took 0.097s
  training loss:		2.294977
  validation loss:		2.243714
  validation accuracy:		13.15 %
Epoch 146 of 2000 took 0.098s
  training loss:		2.295173
  validation loss:		2.242336
  validation accuracy:		13.04 %
Epoch 147 of 2000 took 0.097s
  training loss:		2.296104
  validation loss:		2.243694
  validation accuracy:		13.15 %
Epoch 148 of 2000 took 0.097s
  training loss:		2.295352
  validation loss:		2.246377
  validation accuracy:		12.93 %
Epoch 149 of 2000 took 0.097s
  training loss:		2.296429
  validation loss:		2.247070
  validation accuracy:		12.93 %
Epoch 150 of 2000 took 0.097s
  training loss:		2.295122
  validation loss:		2.245894
  validation accuracy:		12.93 %
Epoch 151 of 2000 took 0.097s
  training loss:		2.295450
  validation loss:		2.245099
  validation accuracy:		12.93 %
Epoch 152 of 2000 took 0.096s
  training loss:		2.295014
  validation loss:		2.244767
  validation accuracy:		13.04 %
Epoch 153 of 2000 took 0.097s
  training loss:		2.295875
  validation loss:		2.244757
  validation accuracy:		12.83 %
Epoch 154 of 2000 took 0.097s
  training loss:		2.295638
  validation loss:		2.246848
  validation accuracy:		12.50 %
Epoch 155 of 2000 took 0.097s
  training loss:		2.294475
  validation loss:		2.243331
  validation accuracy:		13.04 %
Epoch 156 of 2000 took 0.096s
  training loss:		2.295475
  validation loss:		2.242462
  validation accuracy:		13.04 %
Epoch 157 of 2000 took 0.097s
  training loss:		2.295390
  validation loss:		2.244885
  validation accuracy:		13.04 %
Epoch 158 of 2000 took 0.097s
  training loss:		2.294561
  validation loss:		2.244382
  validation accuracy:		12.93 %
Epoch 159 of 2000 took 0.097s
  training loss:		2.295567
  validation loss:		2.243551
  validation accuracy:		12.83 %
Epoch 160 of 2000 took 0.097s
  training loss:		2.294085
  validation loss:		2.245066
  validation accuracy:		13.15 %
Epoch 161 of 2000 took 0.097s
  training loss:		2.295365
  validation loss:		2.244920
  validation accuracy:		12.93 %
Epoch 162 of 2000 took 0.096s
  training loss:		2.294512
  validation loss:		2.244507
  validation accuracy:		12.93 %
Epoch 163 of 2000 took 0.096s
  training loss:		2.294559
  validation loss:		2.242041
  validation accuracy:		13.70 %
Epoch 164 of 2000 took 0.096s
  training loss:		2.294160
  validation loss:		2.241910
  validation accuracy:		12.93 %
Epoch 165 of 2000 took 0.097s
  training loss:		2.294731
  validation loss:		2.243423
  validation accuracy:		14.24 %
Epoch 166 of 2000 took 0.096s
  training loss:		2.294855
  validation loss:		2.244278
  validation accuracy:		12.93 %
Epoch 167 of 2000 took 0.096s
  training loss:		2.295621
  validation loss:		2.244724
  validation accuracy:		14.78 %
Epoch 168 of 2000 took 0.097s
  training loss:		2.294957
  validation loss:		2.245770
  validation accuracy:		13.04 %
Epoch 169 of 2000 took 0.097s
  training loss:		2.295405
  validation loss:		2.245494
  validation accuracy:		13.04 %
Epoch 170 of 2000 took 0.097s
  training loss:		2.294428
  validation loss:		2.245181
  validation accuracy:		12.93 %
Epoch 171 of 2000 took 0.097s
  training loss:		2.294316
  validation loss:		2.243223
  validation accuracy:		12.93 %
Epoch 172 of 2000 took 0.097s
  training loss:		2.294803
  validation loss:		2.244784
  validation accuracy:		12.93 %
Epoch 173 of 2000 took 0.097s
  training loss:		2.294336
  validation loss:		2.243247
  validation accuracy:		12.93 %
Epoch 174 of 2000 took 0.097s
  training loss:		2.294370
  validation loss:		2.242072
  validation accuracy:		13.04 %
Epoch 175 of 2000 took 0.096s
  training loss:		2.295055
  validation loss:		2.245067
  validation accuracy:		13.04 %
Epoch 176 of 2000 took 0.097s
  training loss:		2.293954
  validation loss:		2.243210
  validation accuracy:		13.04 %
Epoch 177 of 2000 took 0.097s
  training loss:		2.295501
  validation loss:		2.243007
  validation accuracy:		12.93 %
Epoch 178 of 2000 took 0.097s
  training loss:		2.296101
  validation loss:		2.247010
  validation accuracy:		12.93 %
Epoch 179 of 2000 took 0.097s
  training loss:		2.295742
  validation loss:		2.247894
  validation accuracy:		12.93 %
Epoch 180 of 2000 took 0.097s
  training loss:		2.295301
  validation loss:		2.247126
  validation accuracy:		12.83 %
Epoch 181 of 2000 took 0.097s
  training loss:		2.294341
  validation loss:		2.246282
  validation accuracy:		12.83 %
Epoch 182 of 2000 took 0.097s
  training loss:		2.294738
  validation loss:		2.241657
  validation accuracy:		12.93 %
Epoch 183 of 2000 took 0.096s
  training loss:		2.294565
  validation loss:		2.242117
  validation accuracy:		13.04 %
Epoch 184 of 2000 took 0.097s
  training loss:		2.295023
  validation loss:		2.242133
  validation accuracy:		13.04 %
Epoch 185 of 2000 took 0.097s
  training loss:		2.294746
  validation loss:		2.244695
  validation accuracy:		12.93 %
Epoch 186 of 2000 took 0.097s
  training loss:		2.294563
  validation loss:		2.245737
  validation accuracy:		12.50 %
Epoch 187 of 2000 took 0.097s
  training loss:		2.295132
  validation loss:		2.244297
  validation accuracy:		12.93 %
Epoch 188 of 2000 took 0.097s
  training loss:		2.294032
  validation loss:		2.244181
  validation accuracy:		12.93 %
Epoch 189 of 2000 took 0.097s
  training loss:		2.295087
  validation loss:		2.245183
  validation accuracy:		13.70 %
Epoch 190 of 2000 took 0.097s
  training loss:		2.294839
  validation loss:		2.244319
  validation accuracy:		14.46 %
Epoch 191 of 2000 took 0.097s
  training loss:		2.294193
  validation loss:		2.244030
  validation accuracy:		13.26 %
Epoch 192 of 2000 took 0.097s
  training loss:		2.294661
  validation loss:		2.243016
  validation accuracy:		16.09 %
Epoch 193 of 2000 took 0.097s
  training loss:		2.294944
  validation loss:		2.244390
  validation accuracy:		12.93 %
Epoch 194 of 2000 took 0.101s
  training loss:		2.294504
  validation loss:		2.244312
  validation accuracy:		12.83 %
Epoch 195 of 2000 took 0.097s
  training loss:		2.294261
  validation loss:		2.244370
  validation accuracy:		12.83 %
Epoch 196 of 2000 took 0.097s
  training loss:		2.294825
  validation loss:		2.243832
  validation accuracy:		12.83 %
Epoch 197 of 2000 took 0.096s
  training loss:		2.294046
  validation loss:		2.243263
  validation accuracy:		12.93 %
Epoch 198 of 2000 took 0.097s
  training loss:		2.295416
  validation loss:		2.244499
  validation accuracy:		12.93 %
Epoch 199 of 2000 took 0.097s
  training loss:		2.295269
  validation loss:		2.247957
  validation accuracy:		12.93 %
Epoch 200 of 2000 took 0.097s
  training loss:		2.295229
  validation loss:		2.246231
  validation accuracy:		12.93 %
Epoch 201 of 2000 took 0.097s
  training loss:		2.295165
  validation loss:		2.246055
  validation accuracy:		12.93 %
Epoch 202 of 2000 took 0.097s
  training loss:		2.294653
  validation loss:		2.243742
  validation accuracy:		12.83 %
Epoch 203 of 2000 took 0.097s
  training loss:		2.295125
  validation loss:		2.246107
  validation accuracy:		12.83 %
Epoch 204 of 2000 took 0.097s
  training loss:		2.294796
  validation loss:		2.245168
  validation accuracy:		12.83 %
Epoch 205 of 2000 took 0.097s
  training loss:		2.295118
  validation loss:		2.246678
  validation accuracy:		12.93 %
Epoch 206 of 2000 took 0.097s
  training loss:		2.294263
  validation loss:		2.243956
  validation accuracy:		12.93 %
Epoch 207 of 2000 took 0.097s
  training loss:		2.295191
  validation loss:		2.243903
  validation accuracy:		13.91 %
Epoch 208 of 2000 took 0.096s
  training loss:		2.294845
  validation loss:		2.243404
  validation accuracy:		13.04 %
Epoch 209 of 2000 took 0.098s
  training loss:		2.293569
  validation loss:		2.244977
  validation accuracy:		12.93 %
Epoch 210 of 2000 took 0.097s
  training loss:		2.295084
  validation loss:		2.244066
  validation accuracy:		12.83 %
Epoch 211 of 2000 took 0.097s
  training loss:		2.294476
  validation loss:		2.242284
  validation accuracy:		12.83 %
Epoch 212 of 2000 took 0.097s
  training loss:		2.295290
  validation loss:		2.244120
  validation accuracy:		12.93 %
Epoch 213 of 2000 took 0.097s
  training loss:		2.295008
  validation loss:		2.247255
  validation accuracy:		13.04 %
Epoch 214 of 2000 took 0.096s
  training loss:		2.293936
  validation loss:		2.245272
  validation accuracy:		13.04 %
Epoch 215 of 2000 took 0.096s
  training loss:		2.294917
  validation loss:		2.242866
  validation accuracy:		15.43 %
Epoch 216 of 2000 took 0.096s
  training loss:		2.295072
  validation loss:		2.245927
  validation accuracy:		12.83 %
Epoch 217 of 2000 took 0.097s
  training loss:		2.293493
  validation loss:		2.244920
  validation accuracy:		12.83 %
Epoch 218 of 2000 took 0.096s
  training loss:		2.295286
  validation loss:		2.243926
  validation accuracy:		12.93 %
Epoch 219 of 2000 took 0.097s
  training loss:		2.293951
  validation loss:		2.241915
  validation accuracy:		14.35 %
Epoch 220 of 2000 took 0.097s
  training loss:		2.295070
  validation loss:		2.242504
  validation accuracy:		13.80 %
Epoch 221 of 2000 took 0.097s
  training loss:		2.294193
  validation loss:		2.245219
  validation accuracy:		12.93 %
Epoch 222 of 2000 took 0.097s
  training loss:		2.293683
  validation loss:		2.243417
  validation accuracy:		12.93 %
Epoch 223 of 2000 took 0.097s
  training loss:		2.295246
  validation loss:		2.243622
  validation accuracy:		12.93 %
Epoch 224 of 2000 took 0.097s
  training loss:		2.293518
  validation loss:		2.240292
  validation accuracy:		12.83 %
Epoch 225 of 2000 took 0.097s
  training loss:		2.294705
  validation loss:		2.243104
  validation accuracy:		13.04 %
Epoch 226 of 2000 took 0.097s
  training loss:		2.294524
  validation loss:		2.244740
  validation accuracy:		12.83 %
Epoch 227 of 2000 took 0.097s
  training loss:		2.294685
  validation loss:		2.246969
  validation accuracy:		12.83 %
Epoch 228 of 2000 took 0.097s
  training loss:		2.294767
  validation loss:		2.247602
  validation accuracy:		12.93 %
Epoch 229 of 2000 took 0.099s
  training loss:		2.295150
  validation loss:		2.244907
  validation accuracy:		12.93 %
Epoch 230 of 2000 took 0.100s
  training loss:		2.294277
  validation loss:		2.243354
  validation accuracy:		13.04 %
Epoch 231 of 2000 took 0.100s
  training loss:		2.294859
  validation loss:		2.242727
  validation accuracy:		8.70 %
Epoch 232 of 2000 took 0.100s
  training loss:		2.294134
  validation loss:		2.242797
  validation accuracy:		14.67 %
Epoch 233 of 2000 took 0.100s
  training loss:		2.294506
  validation loss:		2.242520
  validation accuracy:		12.83 %
Epoch 234 of 2000 took 0.100s
  training loss:		2.294301
  validation loss:		2.242691
  validation accuracy:		12.83 %
Epoch 235 of 2000 took 0.100s
  training loss:		2.293546
  validation loss:		2.244742
  validation accuracy:		13.04 %
Epoch 236 of 2000 took 0.100s
  training loss:		2.294175
  validation loss:		2.244125
  validation accuracy:		13.04 %
Epoch 237 of 2000 took 0.100s
  training loss:		2.294229
  validation loss:		2.243144
  validation accuracy:		13.91 %
Epoch 238 of 2000 took 0.100s
  training loss:		2.294038
  validation loss:		2.242106
  validation accuracy:		12.39 %
Epoch 239 of 2000 took 0.100s
  training loss:		2.293661
  validation loss:		2.241723
  validation accuracy:		12.93 %
Epoch 240 of 2000 took 0.100s
  training loss:		2.294444
  validation loss:		2.242149
  validation accuracy:		12.93 %
Epoch 241 of 2000 took 0.100s
  training loss:		2.293447
  validation loss:		2.240043
  validation accuracy:		15.33 %
Epoch 242 of 2000 took 0.100s
  training loss:		2.293826
  validation loss:		2.240374
  validation accuracy:		12.93 %
Epoch 243 of 2000 took 0.100s
  training loss:		2.294769
  validation loss:		2.242862
  validation accuracy:		13.04 %
Epoch 244 of 2000 took 0.100s
  training loss:		2.294308
  validation loss:		2.247788
  validation accuracy:		13.04 %
Epoch 245 of 2000 took 0.100s
  training loss:		2.293892
  validation loss:		2.246205
  validation accuracy:		12.93 %
Epoch 246 of 2000 took 0.105s
  training loss:		2.294415
  validation loss:		2.242882
  validation accuracy:		13.26 %
Epoch 247 of 2000 took 0.100s
  training loss:		2.293962
  validation loss:		2.240622
  validation accuracy:		13.04 %
Epoch 248 of 2000 took 0.100s
  training loss:		2.294886
  validation loss:		2.243301
  validation accuracy:		13.04 %
Epoch 249 of 2000 took 0.100s
  training loss:		2.294925
  validation loss:		2.243776
  validation accuracy:		12.72 %
Epoch 250 of 2000 took 0.100s
  training loss:		2.293885
  validation loss:		2.244361
  validation accuracy:		12.93 %
Epoch 251 of 2000 took 0.100s
  training loss:		2.293879
  validation loss:		2.245672
  validation accuracy:		15.33 %
Epoch 252 of 2000 took 0.100s
  training loss:		2.293279
  validation loss:		2.241208
  validation accuracy:		12.93 %
Epoch 253 of 2000 took 0.100s
  training loss:		2.295149
  validation loss:		2.242280
  validation accuracy:		12.83 %
Epoch 254 of 2000 took 0.100s
  training loss:		2.293549
  validation loss:		2.243732
  validation accuracy:		13.04 %
Epoch 255 of 2000 took 0.099s
  training loss:		2.293658
  validation loss:		2.240842
  validation accuracy:		13.26 %
Epoch 256 of 2000 took 0.100s
  training loss:		2.294369
  validation loss:		2.242880
  validation accuracy:		12.93 %
Epoch 257 of 2000 took 0.100s
  training loss:		2.293156
  validation loss:		2.241166
  validation accuracy:		12.83 %
Epoch 258 of 2000 took 0.100s
  training loss:		2.294450
  validation loss:		2.242525
  validation accuracy:		15.43 %
Epoch 259 of 2000 took 0.100s
  training loss:		2.293865
  validation loss:		2.242188
  validation accuracy:		15.33 %
Epoch 260 of 2000 took 0.100s
  training loss:		2.293644
  validation loss:		2.240086
  validation accuracy:		12.93 %
Epoch 261 of 2000 took 0.100s
  training loss:		2.294854
  validation loss:		2.245242
  validation accuracy:		12.93 %
Epoch 262 of 2000 took 0.100s
  training loss:		2.294486
  validation loss:		2.244984
  validation accuracy:		12.93 %
Epoch 263 of 2000 took 0.100s
  training loss:		2.293169
  validation loss:		2.240657
  validation accuracy:		12.93 %
Epoch 264 of 2000 took 0.100s
  training loss:		2.294191
  validation loss:		2.243000
  validation accuracy:		13.04 %
Epoch 265 of 2000 took 0.100s
  training loss:		2.294258
  validation loss:		2.244007
  validation accuracy:		12.93 %
Epoch 266 of 2000 took 0.100s
  training loss:		2.294526
  validation loss:		2.244078
  validation accuracy:		12.93 %
Epoch 267 of 2000 took 0.100s
  training loss:		2.294302
  validation loss:		2.244993
  validation accuracy:		12.93 %
Epoch 268 of 2000 took 0.100s
  training loss:		2.294306
  validation loss:		2.242943
  validation accuracy:		13.04 %
Epoch 269 of 2000 took 0.100s
  training loss:		2.294025
  validation loss:		2.242497
  validation accuracy:		13.04 %
Epoch 270 of 2000 took 0.101s
  training loss:		2.293463
  validation loss:		2.242250
  validation accuracy:		14.78 %
Epoch 271 of 2000 took 0.100s
  training loss:		2.294257
  validation loss:		2.242695
  validation accuracy:		12.83 %
Epoch 272 of 2000 took 0.100s
  training loss:		2.294933
  validation loss:		2.246397
  validation accuracy:		12.93 %
Epoch 273 of 2000 took 0.100s
  training loss:		2.294567
  validation loss:		2.246112
  validation accuracy:		15.22 %
Epoch 274 of 2000 took 0.100s
  training loss:		2.293882
  validation loss:		2.244120
  validation accuracy:		12.93 %
Epoch 275 of 2000 took 0.100s
  training loss:		2.293984
  validation loss:		2.242192
  validation accuracy:		12.93 %
Epoch 276 of 2000 took 0.100s
  training loss:		2.294492
  validation loss:		2.245456
  validation accuracy:		13.04 %
Epoch 277 of 2000 took 0.100s
  training loss:		2.294552
  validation loss:		2.243826
  validation accuracy:		12.83 %
Epoch 278 of 2000 took 0.100s
  training loss:		2.294276
  validation loss:		2.245147
  validation accuracy:		13.04 %
Epoch 279 of 2000 took 0.100s
  training loss:		2.294132
  validation loss:		2.242796
  validation accuracy:		12.93 %
Epoch 280 of 2000 took 0.100s
  training loss:		2.294064
  validation loss:		2.242997
  validation accuracy:		12.83 %
Epoch 281 of 2000 took 0.100s
  training loss:		2.294266
  validation loss:		2.240662
  validation accuracy:		12.93 %
Epoch 282 of 2000 took 0.100s
  training loss:		2.293724
  validation loss:		2.240699
  validation accuracy:		12.93 %
Epoch 283 of 2000 took 0.100s
  training loss:		2.294405
  validation loss:		2.244586
  validation accuracy:		13.04 %
Epoch 284 of 2000 took 0.100s
  training loss:		2.293350
  validation loss:		2.241207
  validation accuracy:		15.54 %
Epoch 285 of 2000 took 0.100s
  training loss:		2.294699
  validation loss:		2.246542
  validation accuracy:		12.93 %
Epoch 286 of 2000 took 0.100s
  training loss:		2.293843
  validation loss:		2.244591
  validation accuracy:		12.93 %
Epoch 287 of 2000 took 0.100s
  training loss:		2.294764
  validation loss:		2.244889
  validation accuracy:		14.57 %
Epoch 288 of 2000 took 0.100s
  training loss:		2.293045
  validation loss:		2.242819
  validation accuracy:		15.43 %
Epoch 289 of 2000 took 0.099s
  training loss:		2.293842
  validation loss:		2.242306
  validation accuracy:		15.65 %
Epoch 290 of 2000 took 0.100s
  training loss:		2.293030
  validation loss:		2.240864
  validation accuracy:		12.83 %
Epoch 291 of 2000 took 0.100s
  training loss:		2.295524
  validation loss:		2.239825
  validation accuracy:		13.04 %
Epoch 292 of 2000 took 0.105s
  training loss:		2.294978
  validation loss:		2.248071
  validation accuracy:		12.93 %
Epoch 293 of 2000 took 0.100s
  training loss:		2.293823
  validation loss:		2.244792
  validation accuracy:		12.93 %
Epoch 294 of 2000 took 0.100s
  training loss:		2.293369
  validation loss:		2.241101
  validation accuracy:		12.93 %
Epoch 295 of 2000 took 0.100s
  training loss:		2.293680
  validation loss:		2.241352
  validation accuracy:		13.04 %
Epoch 296 of 2000 took 0.100s
  training loss:		2.294946
  validation loss:		2.241085
  validation accuracy:		12.93 %
Epoch 297 of 2000 took 0.100s
  training loss:		2.293522
  validation loss:		2.243587
  validation accuracy:		15.87 %
Epoch 298 of 2000 took 0.100s
  training loss:		2.294222
  validation loss:		2.243855
  validation accuracy:		12.93 %
Epoch 299 of 2000 took 0.100s
  training loss:		2.293276
  validation loss:		2.241884
  validation accuracy:		12.93 %
Epoch 300 of 2000 took 0.101s
  training loss:		2.293440
  validation loss:		2.242061
  validation accuracy:		13.80 %
Epoch 301 of 2000 took 0.100s
  training loss:		2.293895
  validation loss:		2.240470
  validation accuracy:		12.83 %
Epoch 302 of 2000 took 0.100s
  training loss:		2.294046
  validation loss:		2.242828
  validation accuracy:		12.83 %
Epoch 303 of 2000 took 0.100s
  training loss:		2.294040
  validation loss:		2.242701
  validation accuracy:		13.48 %
Epoch 304 of 2000 took 0.100s
  training loss:		2.294385
  validation loss:		2.245906
  validation accuracy:		12.93 %
Epoch 305 of 2000 took 0.100s
  training loss:		2.293206
  validation loss:		2.242417
  validation accuracy:		13.70 %
Epoch 306 of 2000 took 0.100s
  training loss:		2.294887
  validation loss:		2.240061
  validation accuracy:		12.83 %
Epoch 307 of 2000 took 0.100s
  training loss:		2.294371
  validation loss:		2.245277
  validation accuracy:		12.93 %
Epoch 308 of 2000 took 0.100s
  training loss:		2.294117
  validation loss:		2.244602
  validation accuracy:		12.93 %
Epoch 309 of 2000 took 0.098s
  training loss:		2.293125
  validation loss:		2.241080
  validation accuracy:		12.93 %
Epoch 310 of 2000 took 0.097s
  training loss:		2.294645
  validation loss:		2.242997
  validation accuracy:		13.15 %
Epoch 311 of 2000 took 0.097s
  training loss:		2.294890
  validation loss:		2.246359
  validation accuracy:		12.93 %
Epoch 312 of 2000 took 0.097s
  training loss:		2.294039
  validation loss:		2.246561
  validation accuracy:		12.61 %
Epoch 313 of 2000 took 0.097s
  training loss:		2.293709
  validation loss:		2.241592
  validation accuracy:		12.93 %
Epoch 314 of 2000 took 0.097s
  training loss:		2.293875
  validation loss:		2.241512
  validation accuracy:		14.57 %
Epoch 315 of 2000 took 0.097s
  training loss:		2.293460
  validation loss:		2.242216
  validation accuracy:		13.26 %
Epoch 316 of 2000 took 0.097s
  training loss:		2.293911
  validation loss:		2.244091
  validation accuracy:		13.04 %
Epoch 317 of 2000 took 0.096s
  training loss:		2.293990
  validation loss:		2.241147
  validation accuracy:		12.83 %
Epoch 318 of 2000 took 0.097s
  training loss:		2.293738
  validation loss:		2.241398
  validation accuracy:		12.83 %
Epoch 319 of 2000 took 0.097s
  training loss:		2.292904
  validation loss:		2.240201
  validation accuracy:		12.83 %
Epoch 320 of 2000 took 0.097s
  training loss:		2.293317
  validation loss:		2.244265
  validation accuracy:		13.48 %
Epoch 321 of 2000 took 0.097s
  training loss:		2.293561
  validation loss:		2.245637
  validation accuracy:		12.93 %
Epoch 322 of 2000 took 0.097s
  training loss:		2.293441
  validation loss:		2.243123
  validation accuracy:		12.93 %
Epoch 323 of 2000 took 0.099s
  training loss:		2.293260
  validation loss:		2.241539
  validation accuracy:		12.83 %
Epoch 324 of 2000 took 0.100s
  training loss:		2.293767
  validation loss:		2.242438
  validation accuracy:		13.04 %
Epoch 325 of 2000 took 0.100s
  training loss:		2.294013
  validation loss:		2.240414
  validation accuracy:		12.93 %
Epoch 326 of 2000 took 0.100s
  training loss:		2.293669
  validation loss:		2.243752
  validation accuracy:		12.93 %
Epoch 327 of 2000 took 0.100s
  training loss:		2.293569
  validation loss:		2.243910
  validation accuracy:		12.93 %
Epoch 328 of 2000 took 0.100s
  training loss:		2.293937
  validation loss:		2.246699
  validation accuracy:		16.52 %
Epoch 329 of 2000 took 0.100s
  training loss:		2.293935
  validation loss:		2.243025
  validation accuracy:		12.83 %
Epoch 330 of 2000 took 0.100s
  training loss:		2.293497
  validation loss:		2.241083
  validation accuracy:		12.93 %
Epoch 331 of 2000 took 0.097s
  training loss:		2.294096
  validation loss:		2.241424
  validation accuracy:		14.46 %
Epoch 332 of 2000 took 0.097s
  training loss:		2.293237
  validation loss:		2.240108
  validation accuracy:		13.26 %
Epoch 333 of 2000 took 0.100s
  training loss:		2.293709
  validation loss:		2.239048
  validation accuracy:		12.83 %
Epoch 334 of 2000 took 0.098s
  training loss:		2.294073
  validation loss:		2.242323
  validation accuracy:		16.09 %
Epoch 335 of 2000 took 0.098s
  training loss:		2.294178
  validation loss:		2.244823
  validation accuracy:		12.93 %
Epoch 336 of 2000 took 0.097s
  training loss:		2.294237
  validation loss:		2.244551
  validation accuracy:		13.91 %
Epoch 337 of 2000 took 0.096s
  training loss:		2.293993
  validation loss:		2.245360
  validation accuracy:		12.93 %
Epoch 338 of 2000 took 0.097s
  training loss:		2.293590
  validation loss:		2.242240
  validation accuracy:		13.15 %
Epoch 339 of 2000 took 0.097s
  training loss:		2.293832
  validation loss:		2.241368
  validation accuracy:		13.26 %
Epoch 340 of 2000 took 0.097s
  training loss:		2.293380
  validation loss:		2.241513
  validation accuracy:		13.04 %
Epoch 341 of 2000 took 0.097s
  training loss:		2.293251
  validation loss:		2.240726
  validation accuracy:		12.93 %
Epoch 342 of 2000 took 0.097s
  training loss:		2.293399
  validation loss:		2.240189
  validation accuracy:		12.83 %
Epoch 343 of 2000 took 0.097s
  training loss:		2.294335
  validation loss:		2.242320
  validation accuracy:		13.15 %
Epoch 344 of 2000 took 0.097s
  training loss:		2.294045
  validation loss:		2.244463
  validation accuracy:		16.41 %
Epoch 345 of 2000 took 0.097s
  training loss:		2.293938
  validation loss:		2.244585
  validation accuracy:		12.83 %
Epoch 346 of 2000 took 0.097s
  training loss:		2.292600
  validation loss:		2.240133
  validation accuracy:		12.93 %
Epoch 347 of 2000 took 0.097s
  training loss:		2.293761
  validation loss:		2.240218
  validation accuracy:		12.93 %
Epoch 348 of 2000 took 0.097s
  training loss:		2.293039
  validation loss:		2.241810
  validation accuracy:		12.93 %
Epoch 349 of 2000 took 0.097s
  training loss:		2.294894
  validation loss:		2.240945
  validation accuracy:		12.93 %
Epoch 350 of 2000 took 0.097s
  training loss:		2.293630
  validation loss:		2.244364
  validation accuracy:		12.83 %
Epoch 351 of 2000 took 0.097s
  training loss:		2.293208
  validation loss:		2.241596
  validation accuracy:		12.83 %
Epoch 352 of 2000 took 0.097s
  training loss:		2.293370
  validation loss:		2.243120
  validation accuracy:		12.83 %
Epoch 353 of 2000 took 0.097s
  training loss:		2.294036
  validation loss:		2.244179
  validation accuracy:		13.04 %
Epoch 354 of 2000 took 0.097s
  training loss:		2.293423
  validation loss:		2.241874
  validation accuracy:		14.67 %
Epoch 355 of 2000 took 0.097s
  training loss:		2.293354
  validation loss:		2.241452
  validation accuracy:		12.83 %
Epoch 356 of 2000 took 0.097s
  training loss:		2.293809
  validation loss:		2.242527
  validation accuracy:		12.83 %
Epoch 357 of 2000 took 0.097s
  training loss:		2.293857
  validation loss:		2.244965
  validation accuracy:		12.93 %
Epoch 358 of 2000 took 0.096s
  training loss:		2.294077
  validation loss:		2.244833
  validation accuracy:		13.59 %
Epoch 359 of 2000 took 0.097s
  training loss:		2.292597
  validation loss:		2.241975
  validation accuracy:		17.61 %
Epoch 360 of 2000 took 0.096s
  training loss:		2.294164
  validation loss:		2.244061
  validation accuracy:		12.83 %
Epoch 361 of 2000 took 0.097s
  training loss:		2.293052
  validation loss:		2.240806
  validation accuracy:		16.20 %
Epoch 362 of 2000 took 0.097s
  training loss:		2.292795
  validation loss:		2.238253
  validation accuracy:		12.93 %
Epoch 363 of 2000 took 0.097s
  training loss:		2.294356
  validation loss:		2.239982
  validation accuracy:		12.83 %
Epoch 364 of 2000 took 0.097s
  training loss:		2.292833
  validation loss:		2.243033
  validation accuracy:		12.83 %
Epoch 365 of 2000 took 0.097s
  training loss:		2.293390
  validation loss:		2.245279
  validation accuracy:		14.67 %
Epoch 366 of 2000 took 0.097s
  training loss:		2.293105
  validation loss:		2.244196
  validation accuracy:		12.93 %
Epoch 367 of 2000 took 0.097s
  training loss:		2.293881
  validation loss:		2.242467
  validation accuracy:		13.04 %
Epoch 368 of 2000 took 0.096s
  training loss:		2.294087
  validation loss:		2.243494
  validation accuracy:		13.91 %
Epoch 369 of 2000 took 0.097s
  training loss:		2.293375
  validation loss:		2.243902
  validation accuracy:		13.04 %
Epoch 370 of 2000 took 0.096s
  training loss:		2.293913
  validation loss:		2.241067
  validation accuracy:		12.93 %
Epoch 371 of 2000 took 0.097s
  training loss:		2.293123
  validation loss:		2.243519
  validation accuracy:		12.93 %
Epoch 372 of 2000 took 0.102s
  training loss:		2.293098
  validation loss:		2.243496
  validation accuracy:		13.04 %
Epoch 373 of 2000 took 0.097s
  training loss:		2.293989
  validation loss:		2.242805
  validation accuracy:		13.04 %
Epoch 374 of 2000 took 0.097s
  training loss:		2.293185
  validation loss:		2.239711
  validation accuracy:		12.83 %
Epoch 375 of 2000 took 0.097s
  training loss:		2.294093
  validation loss:		2.240106
  validation accuracy:		12.83 %
Epoch 376 of 2000 took 0.097s
  training loss:		2.293978
  validation loss:		2.244595
  validation accuracy:		13.04 %
Epoch 377 of 2000 took 0.096s
  training loss:		2.292921
  validation loss:		2.243440
  validation accuracy:		12.83 %
Epoch 378 of 2000 took 0.097s
  training loss:		2.292715
  validation loss:		2.241455
  validation accuracy:		14.24 %
Epoch 379 of 2000 took 0.097s
  training loss:		2.293172
  validation loss:		2.241689
  validation accuracy:		12.93 %
Epoch 380 of 2000 took 0.097s
  training loss:		2.293599
  validation loss:		2.242092
  validation accuracy:		12.93 %
Epoch 381 of 2000 took 0.096s
  training loss:		2.293074
  validation loss:		2.240154
  validation accuracy:		13.26 %
Epoch 382 of 2000 took 0.097s
  training loss:		2.294011
  validation loss:		2.243617
  validation accuracy:		12.93 %
Epoch 383 of 2000 took 0.097s
  training loss:		2.293667
  validation loss:		2.243672
  validation accuracy:		13.80 %
Epoch 384 of 2000 took 0.097s
  training loss:		2.293572
  validation loss:		2.244624
  validation accuracy:		16.30 %
Epoch 385 of 2000 took 0.097s
  training loss:		2.293011
  validation loss:		2.240544
  validation accuracy:		14.78 %
Epoch 386 of 2000 took 0.097s
  training loss:		2.293450
  validation loss:		2.242890
  validation accuracy:		12.93 %
Epoch 387 of 2000 took 0.097s
  training loss:		2.292960
  validation loss:		2.243631
  validation accuracy:		12.93 %
Epoch 388 of 2000 took 0.097s
  training loss:		2.293129
  validation loss:		2.242939
  validation accuracy:		16.09 %
Epoch 389 of 2000 took 0.097s
  training loss:		2.293179
  validation loss:		2.241642
  validation accuracy:		14.46 %
Epoch 390 of 2000 took 0.097s
  training loss:		2.293225
  validation loss:		2.240209
  validation accuracy:		12.93 %
Epoch 391 of 2000 took 0.097s
  training loss:		2.293900
  validation loss:		2.243692
  validation accuracy:		12.93 %
Epoch 392 of 2000 took 0.097s
  training loss:		2.294198
  validation loss:		2.243775
  validation accuracy:		13.37 %
Epoch 393 of 2000 took 0.098s
  training loss:		2.292842
  validation loss:		2.242444
  validation accuracy:		16.09 %
Epoch 394 of 2000 took 0.097s
  training loss:		2.293168
  validation loss:		2.238490
  validation accuracy:		20.11 %
Epoch 395 of 2000 took 0.097s
  training loss:		2.293665
  validation loss:		2.240282
  validation accuracy:		12.83 %
Epoch 396 of 2000 took 0.097s
  training loss:		2.293136
  validation loss:		2.243640
  validation accuracy:		12.93 %
Epoch 397 of 2000 took 0.097s
  training loss:		2.293358
  validation loss:		2.244221
  validation accuracy:		15.22 %
Epoch 398 of 2000 took 0.097s
  training loss:		2.292709
  validation loss:		2.238626
  validation accuracy:		12.83 %
Epoch 399 of 2000 took 0.097s
  training loss:		2.293612
  validation loss:		2.242524
  validation accuracy:		13.59 %
Epoch 400 of 2000 took 0.097s
  training loss:		2.292589
  validation loss:		2.242987
  validation accuracy:		12.83 %
Epoch 401 of 2000 took 0.097s
  training loss:		2.292152
  validation loss:		2.240978
  validation accuracy:		13.04 %
Epoch 402 of 2000 took 0.097s
  training loss:		2.293474
  validation loss:		2.238952
  validation accuracy:		14.02 %
Epoch 403 of 2000 took 0.097s
  training loss:		2.293212
  validation loss:		2.241907
  validation accuracy:		13.37 %
Epoch 404 of 2000 took 0.097s
  training loss:		2.294575
  validation loss:		2.242120
  validation accuracy:		16.20 %
Epoch 405 of 2000 took 0.097s
  training loss:		2.293196
  validation loss:		2.241580
  validation accuracy:		12.83 %
Epoch 406 of 2000 took 0.101s
  training loss:		2.292527
  validation loss:		2.240829
  validation accuracy:		12.93 %
Epoch 407 of 2000 took 0.097s
  training loss:		2.294482
  validation loss:		2.241895
  validation accuracy:		13.04 %
Epoch 408 of 2000 took 0.097s
  training loss:		2.292777
  validation loss:		2.242073
  validation accuracy:		17.28 %
Epoch 409 of 2000 took 0.097s
  training loss:		2.293935
  validation loss:		2.246159
  validation accuracy:		12.83 %
Epoch 410 of 2000 took 0.097s
  training loss:		2.293853
  validation loss:		2.242186
  validation accuracy:		13.91 %
Epoch 411 of 2000 took 0.097s
  training loss:		2.293478
  validation loss:		2.241361
  validation accuracy:		16.63 %
Epoch 412 of 2000 took 0.096s
  training loss:		2.292696
  validation loss:		2.244170
  validation accuracy:		12.93 %
Epoch 413 of 2000 took 0.097s
  training loss:		2.293410
  validation loss:		2.240682
  validation accuracy:		15.76 %
Epoch 414 of 2000 took 0.096s
  training loss:		2.293412
  validation loss:		2.243474
  validation accuracy:		17.39 %
Epoch 415 of 2000 took 0.097s
  training loss:		2.293717
  validation loss:		2.245725
  validation accuracy:		12.93 %
Epoch 416 of 2000 took 0.097s
  training loss:		2.293570
  validation loss:		2.241903
  validation accuracy:		13.26 %
Epoch 417 of 2000 took 0.097s
  training loss:		2.292230
  validation loss:		2.237021
  validation accuracy:		12.83 %
Epoch 418 of 2000 took 0.097s
  training loss:		2.292858
  validation loss:		2.238726
  validation accuracy:		12.93 %
Epoch 419 of 2000 took 0.097s
  training loss:		2.291409
  validation loss:		2.238485
  validation accuracy:		14.24 %
Epoch 420 of 2000 took 0.096s
  training loss:		2.293329
  validation loss:		2.240191
  validation accuracy:		12.93 %
Epoch 421 of 2000 took 0.097s
  training loss:		2.291915
  validation loss:		2.238220
  validation accuracy:		12.83 %
Epoch 422 of 2000 took 0.096s
  training loss:		2.293487
  validation loss:		2.240446
  validation accuracy:		12.83 %
Epoch 423 of 2000 took 0.097s
  training loss:		2.292081
  validation loss:		2.241003
  validation accuracy:		12.93 %
Epoch 424 of 2000 took 0.098s
  training loss:		2.293380
  validation loss:		2.244677
  validation accuracy:		13.04 %
Epoch 425 of 2000 took 0.097s
  training loss:		2.292656
  validation loss:		2.241954
  validation accuracy:		12.93 %
Epoch 426 of 2000 took 0.097s
  training loss:		2.292423
  validation loss:		2.240993
  validation accuracy:		15.00 %
Epoch 427 of 2000 took 0.097s
  training loss:		2.293144
  validation loss:		2.241708
  validation accuracy:		12.72 %
Epoch 428 of 2000 took 0.097s
  training loss:		2.292879
  validation loss:		2.241735
  validation accuracy:		12.83 %
Epoch 429 of 2000 took 0.097s
  training loss:		2.292547
  validation loss:		2.240889
  validation accuracy:		13.70 %
Epoch 430 of 2000 took 0.097s
  training loss:		2.292838
  validation loss:		2.241672
  validation accuracy:		12.93 %
Epoch 431 of 2000 took 0.097s
  training loss:		2.293314
  validation loss:		2.241205
  validation accuracy:		12.83 %
Epoch 432 of 2000 took 0.097s
  training loss:		2.293277
  validation loss:		2.244204
  validation accuracy:		12.93 %
Epoch 433 of 2000 took 0.097s
  training loss:		2.292654
  validation loss:		2.242484
  validation accuracy:		13.26 %
Epoch 434 of 2000 took 0.097s
  training loss:		2.293019
  validation loss:		2.240680
  validation accuracy:		12.93 %
Epoch 435 of 2000 took 0.097s
  training loss:		2.293057
  validation loss:		2.241734
  validation accuracy:		12.93 %
Epoch 436 of 2000 took 0.097s
  training loss:		2.292981
  validation loss:		2.239720
  validation accuracy:		13.48 %
Epoch 437 of 2000 took 0.102s
  training loss:		2.292852
  validation loss:		2.242733
  validation accuracy:		13.37 %
Epoch 438 of 2000 took 0.097s
  training loss:		2.293208
  validation loss:		2.241235
  validation accuracy:		12.83 %
Epoch 439 of 2000 took 0.097s
  training loss:		2.293505
  validation loss:		2.240777
  validation accuracy:		17.72 %
Epoch 440 of 2000 took 0.097s
  training loss:		2.293227
  validation loss:		2.242071
  validation accuracy:		12.83 %
Epoch 441 of 2000 took 0.097s
  training loss:		2.293008
  validation loss:		2.244790
  validation accuracy:		12.83 %
Epoch 442 of 2000 took 0.097s
  training loss:		2.292590
  validation loss:		2.241700
  validation accuracy:		12.93 %
Epoch 443 of 2000 took 0.097s
  training loss:		2.292454
  validation loss:		2.239164
  validation accuracy:		12.93 %
Epoch 444 of 2000 took 0.097s
  training loss:		2.292474
  validation loss:		2.239460
  validation accuracy:		12.83 %
Epoch 445 of 2000 took 0.097s
  training loss:		2.293249
  validation loss:		2.242585
  validation accuracy:		12.83 %
Epoch 446 of 2000 took 0.097s
  training loss:		2.292860
  validation loss:		2.243138
  validation accuracy:		13.26 %
Epoch 447 of 2000 took 0.097s
  training loss:		2.292122
  validation loss:		2.239320
  validation accuracy:		12.93 %
Epoch 448 of 2000 took 0.097s
  training loss:		2.292930
  validation loss:		2.237738
  validation accuracy:		13.04 %
Epoch 449 of 2000 took 0.097s
  training loss:		2.292922
  validation loss:		2.241900
  validation accuracy:		12.93 %
Epoch 450 of 2000 took 0.097s
  training loss:		2.293421
  validation loss:		2.238821
  validation accuracy:		14.02 %
Epoch 451 of 2000 took 0.097s
  training loss:		2.291897
  validation loss:		2.242760
  validation accuracy:		17.50 %
Epoch 452 of 2000 took 0.097s
  training loss:		2.293020
  validation loss:		2.244101
  validation accuracy:		12.93 %
Epoch 453 of 2000 took 0.096s
  training loss:		2.292585
  validation loss:		2.242482
  validation accuracy:		15.76 %
Epoch 454 of 2000 took 0.097s
  training loss:		2.292254
  validation loss:		2.240057
  validation accuracy:		16.85 %
Epoch 455 of 2000 took 0.097s
  training loss:		2.292902
  validation loss:		2.241600
  validation accuracy:		12.93 %
Epoch 456 of 2000 took 0.097s
  training loss:		2.291969
  validation loss:		2.240889
  validation accuracy:		16.74 %
Epoch 457 of 2000 took 0.096s
  training loss:		2.292723
  validation loss:		2.240422
  validation accuracy:		12.83 %
Epoch 458 of 2000 took 0.097s
  training loss:		2.292400
  validation loss:		2.237764
  validation accuracy:		12.83 %
Epoch 459 of 2000 took 0.096s
  training loss:		2.292890
  validation loss:		2.242905
  validation accuracy:		13.37 %
Epoch 460 of 2000 took 0.097s
  training loss:		2.291902
  validation loss:		2.240058
  validation accuracy:		12.83 %
Epoch 461 of 2000 took 0.097s
  training loss:		2.292384
  validation loss:		2.241879
  validation accuracy:		13.15 %
Epoch 462 of 2000 took 0.097s
  training loss:		2.292548
  validation loss:		2.241796
  validation accuracy:		12.93 %
Epoch 463 of 2000 took 0.097s
  training loss:		2.292332
  validation loss:		2.240903
  validation accuracy:		12.93 %
Epoch 464 of 2000 took 0.097s
  training loss:		2.291669
  validation loss:		2.239310
  validation accuracy:		12.93 %
Epoch 465 of 2000 took 0.101s
  training loss:		2.292261
  validation loss:		2.240358
  validation accuracy:		13.80 %
Epoch 466 of 2000 took 0.097s
  training loss:		2.292257
  validation loss:		2.241754
  validation accuracy:		20.00 %
Epoch 467 of 2000 took 0.097s
  training loss:		2.291309
  validation loss:		2.238586
  validation accuracy:		13.15 %
Epoch 468 of 2000 took 0.097s
  training loss:		2.291592
  validation loss:		2.239209
  validation accuracy:		12.17 %
Epoch 469 of 2000 took 0.096s
  training loss:		2.292914
  validation loss:		2.238910
  validation accuracy:		12.93 %
Epoch 470 of 2000 took 0.097s
  training loss:		2.293023
  validation loss:		2.239540
  validation accuracy:		12.93 %
Epoch 471 of 2000 took 0.097s
  training loss:		2.291643
  validation loss:		2.243316
  validation accuracy:		13.15 %
Epoch 472 of 2000 took 0.097s
  training loss:		2.291960
  validation loss:		2.238207
  validation accuracy:		15.98 %
Epoch 473 of 2000 took 0.097s
  training loss:		2.290972
  validation loss:		2.237003
  validation accuracy:		17.72 %
Epoch 474 of 2000 took 0.099s
  training loss:		2.291394
  validation loss:		2.238232
  validation accuracy:		16.74 %
Epoch 475 of 2000 took 0.100s
  training loss:		2.291020
  validation loss:		2.241567
  validation accuracy:		12.83 %
Epoch 476 of 2000 took 0.100s
  training loss:		2.291105
  validation loss:		2.238985
  validation accuracy:		12.83 %
Epoch 477 of 2000 took 0.100s
  training loss:		2.293205
  validation loss:		2.239443
  validation accuracy:		12.93 %
Epoch 478 of 2000 took 0.100s
  training loss:		2.292072
  validation loss:		2.239642
  validation accuracy:		12.93 %
Epoch 479 of 2000 took 0.100s
  training loss:		2.292762
  validation loss:		2.243537
  validation accuracy:		13.48 %
Epoch 480 of 2000 took 0.100s
  training loss:		2.290832
  validation loss:		2.239276
  validation accuracy:		12.83 %
Epoch 481 of 2000 took 0.100s
  training loss:		2.292631
  validation loss:		2.239354
  validation accuracy:		12.93 %
Epoch 482 of 2000 took 0.100s
  training loss:		2.290310
  validation loss:		2.237837
  validation accuracy:		12.93 %
Epoch 483 of 2000 took 0.100s
  training loss:		2.292682
  validation loss:		2.238463
  validation accuracy:		12.93 %
Epoch 484 of 2000 took 0.100s
  training loss:		2.291366
  validation loss:		2.240148
  validation accuracy:		13.80 %
Epoch 485 of 2000 took 0.100s
  training loss:		2.292661
  validation loss:		2.244517
  validation accuracy:		16.74 %
Epoch 486 of 2000 took 0.101s
  training loss:		2.291821
  validation loss:		2.240012
  validation accuracy:		12.93 %
Epoch 487 of 2000 took 0.100s
  training loss:		2.291423
  validation loss:		2.239039
  validation accuracy:		13.48 %
Epoch 488 of 2000 took 0.100s
  training loss:		2.292402
  validation loss:		2.239388
  validation accuracy:		13.15 %
Epoch 489 of 2000 took 0.102s
  training loss:		2.291480
  validation loss:		2.239892
  validation accuracy:		13.15 %
Epoch 490 of 2000 took 0.098s
  training loss:		2.292121
  validation loss:		2.240863
  validation accuracy:		13.26 %
Epoch 491 of 2000 took 0.097s
  training loss:		2.292124
  validation loss:		2.239952
  validation accuracy:		12.83 %
Epoch 492 of 2000 took 0.096s
  training loss:		2.292406
  validation loss:		2.239506
  validation accuracy:		12.83 %
Epoch 493 of 2000 took 0.097s
  training loss:		2.292283
  validation loss:		2.243136
  validation accuracy:		13.70 %
Epoch 494 of 2000 took 0.096s
  training loss:		2.291544
  validation loss:		2.241516
  validation accuracy:		12.83 %
Epoch 495 of 2000 took 0.097s
  training loss:		2.291027
  validation loss:		2.237254
  validation accuracy:		12.93 %
Epoch 496 of 2000 took 0.097s
  training loss:		2.290998
  validation loss:		2.236875
  validation accuracy:		13.48 %
Epoch 497 of 2000 took 0.097s
  training loss:		2.291838
  validation loss:		2.238474
  validation accuracy:		12.93 %
Epoch 498 of 2000 took 0.097s
  training loss:		2.291521
  validation loss:		2.239999
  validation accuracy:		14.67 %
Epoch 499 of 2000 took 0.097s
  training loss:		2.291508
  validation loss:		2.239897
  validation accuracy:		12.93 %
Epoch 500 of 2000 took 0.097s
  training loss:		2.290817
  validation loss:		2.236775
  validation accuracy:		12.93 %
Epoch 501 of 2000 took 0.097s
  training loss:		2.291387
  validation loss:		2.236822
  validation accuracy:		19.46 %
Epoch 502 of 2000 took 0.096s
  training loss:		2.291761
  validation loss:		2.239028
  validation accuracy:		12.93 %
Epoch 503 of 2000 took 0.097s
  training loss:		2.291098
  validation loss:		2.241112
  validation accuracy:		12.93 %
Epoch 504 of 2000 took 0.096s
  training loss:		2.290870
  validation loss:		2.240929
  validation accuracy:		13.70 %
Epoch 505 of 2000 took 0.097s
  training loss:		2.291771
  validation loss:		2.239814
  validation accuracy:		19.35 %
Epoch 506 of 2000 took 0.097s
  training loss:		2.291272
  validation loss:		2.240033
  validation accuracy:		12.83 %
Epoch 507 of 2000 took 0.097s
  training loss:		2.291450
  validation loss:		2.239729
  validation accuracy:		12.93 %
Epoch 508 of 2000 took 0.097s
  training loss:		2.290729
  validation loss:		2.238549
  validation accuracy:		12.50 %
Epoch 509 of 2000 took 0.097s
  training loss:		2.291404
  validation loss:		2.238548
  validation accuracy:		12.93 %
Epoch 510 of 2000 took 0.096s
  training loss:		2.290304
  validation loss:		2.238585
  validation accuracy:		12.83 %
Epoch 511 of 2000 took 0.097s
  training loss:		2.291384
  validation loss:		2.236745
  validation accuracy:		12.93 %
Epoch 512 of 2000 took 0.101s
  training loss:		2.291218
  validation loss:		2.239995
  validation accuracy:		14.13 %
Epoch 513 of 2000 took 0.097s
  training loss:		2.291681
  validation loss:		2.241352
  validation accuracy:		13.04 %
Epoch 514 of 2000 took 0.097s
  training loss:		2.290187
  validation loss:		2.234630
  validation accuracy:		12.83 %
Epoch 515 of 2000 took 0.097s
  training loss:		2.290634
  validation loss:		2.236899
  validation accuracy:		18.37 %
Epoch 516 of 2000 took 0.097s
  training loss:		2.291786
  validation loss:		2.239914
  validation accuracy:		12.93 %
Epoch 517 of 2000 took 0.098s
  training loss:		2.291168
  validation loss:		2.237891
  validation accuracy:		12.61 %
Epoch 518 of 2000 took 0.097s
  training loss:		2.291311
  validation loss:		2.241203
  validation accuracy:		12.83 %
Epoch 519 of 2000 took 0.097s
  training loss:		2.291417
  validation loss:		2.240008
  validation accuracy:		13.26 %
Epoch 520 of 2000 took 0.097s
  training loss:		2.291140
  validation loss:		2.238838
  validation accuracy:		13.04 %
Epoch 521 of 2000 took 0.097s
  training loss:		2.291433
  validation loss:		2.238051
  validation accuracy:		11.85 %
Epoch 522 of 2000 took 0.097s
  training loss:		2.290303
  validation loss:		2.236415
  validation accuracy:		12.93 %
Epoch 523 of 2000 took 0.097s
  training loss:		2.290835
  validation loss:		2.239037
  validation accuracy:		12.93 %
Epoch 524 of 2000 took 0.097s
  training loss:		2.290774
  validation loss:		2.238836
  validation accuracy:		12.83 %
Epoch 525 of 2000 took 0.096s
  training loss:		2.289515
  validation loss:		2.240323
  validation accuracy:		13.26 %
Epoch 526 of 2000 took 0.097s
  training loss:		2.291233
  validation loss:		2.238599
  validation accuracy:		17.50 %
Epoch 527 of 2000 took 0.097s
  training loss:		2.290510
  validation loss:		2.237471
  validation accuracy:		13.04 %
Epoch 528 of 2000 took 0.097s
  training loss:		2.290265
  validation loss:		2.241360
  validation accuracy:		12.93 %
Epoch 529 of 2000 took 0.097s
  training loss:		2.291013
  validation loss:		2.241287
  validation accuracy:		13.15 %
Epoch 530 of 2000 took 0.097s
  training loss:		2.290883
  validation loss:		2.238436
  validation accuracy:		18.48 %
Epoch 531 of 2000 took 0.096s
  training loss:		2.290398
  validation loss:		2.235502
  validation accuracy:		14.57 %
Epoch 532 of 2000 took 0.101s
  training loss:		2.291051
  validation loss:		2.237144
  validation accuracy:		14.24 %
Epoch 533 of 2000 took 0.097s
  training loss:		2.290364
  validation loss:		2.240847
  validation accuracy:		12.93 %
Epoch 534 of 2000 took 0.097s
  training loss:		2.289549
  validation loss:		2.237184
  validation accuracy:		14.24 %
Epoch 535 of 2000 took 0.097s
  training loss:		2.290571
  validation loss:		2.236057
  validation accuracy:		13.04 %
Epoch 536 of 2000 took 0.097s
  training loss:		2.289330
  validation loss:		2.233671
  validation accuracy:		12.93 %
Epoch 537 of 2000 took 0.097s
  training loss:		2.289674
  validation loss:		2.234522
  validation accuracy:		16.30 %
Epoch 538 of 2000 took 0.097s
  training loss:		2.290227
  validation loss:		2.237566
  validation accuracy:		19.02 %
Epoch 539 of 2000 took 0.097s
  training loss:		2.289924
  validation loss:		2.236562
  validation accuracy:		18.48 %
Epoch 540 of 2000 took 0.097s
  training loss:		2.290228
  validation loss:		2.238546
  validation accuracy:		12.93 %
Epoch 541 of 2000 took 0.097s
  training loss:		2.289820
  validation loss:		2.238103
  validation accuracy:		13.26 %
Epoch 542 of 2000 took 0.097s
  training loss:		2.289997
  validation loss:		2.237223
  validation accuracy:		12.83 %
Epoch 543 of 2000 took 0.097s
  training loss:		2.289691
  validation loss:		2.238285
  validation accuracy:		17.07 %
Epoch 544 of 2000 took 0.097s
  training loss:		2.289951
  validation loss:		2.236162
  validation accuracy:		13.26 %
Epoch 545 of 2000 took 0.097s
  training loss:		2.289854
  validation loss:		2.234733
  validation accuracy:		12.83 %
Epoch 546 of 2000 took 0.097s
  training loss:		2.288839
  validation loss:		2.237204
  validation accuracy:		18.37 %
Epoch 547 of 2000 took 0.097s
  training loss:		2.290009
  validation loss:		2.236776
  validation accuracy:		13.26 %
Epoch 548 of 2000 took 0.098s
  training loss:		2.290654
  validation loss:		2.238893
  validation accuracy:		18.70 %
Epoch 549 of 2000 took 0.097s
  training loss:		2.289513
  validation loss:		2.236951
  validation accuracy:		12.93 %
Epoch 550 of 2000 took 0.100s
  training loss:		2.288705
  validation loss:		2.234643
  validation accuracy:		13.15 %
Epoch 551 of 2000 took 0.098s
  training loss:		2.289261
  validation loss:		2.236597
  validation accuracy:		19.35 %
Epoch 552 of 2000 took 0.097s
  training loss:		2.290179
  validation loss:		2.239933
  validation accuracy:		12.93 %
Epoch 553 of 2000 took 0.097s
  training loss:		2.289657
  validation loss:		2.233710
  validation accuracy:		13.04 %
Epoch 554 of 2000 took 0.097s
  training loss:		2.288252
  validation loss:		2.232488
  validation accuracy:		12.83 %
Epoch 555 of 2000 took 0.097s
  training loss:		2.288956
  validation loss:		2.234167
  validation accuracy:		13.59 %
Epoch 556 of 2000 took 0.097s
  training loss:		2.289034
  validation loss:		2.237506
  validation accuracy:		13.15 %
Epoch 557 of 2000 took 0.097s
  training loss:		2.290265
  validation loss:		2.240257
  validation accuracy:		12.93 %
Epoch 558 of 2000 took 0.097s
  training loss:		2.288871
  validation loss:		2.233905
  validation accuracy:		12.83 %
Epoch 559 of 2000 took 0.097s
  training loss:		2.289414
  validation loss:		2.235243
  validation accuracy:		15.98 %
Epoch 560 of 2000 took 0.097s
  training loss:		2.288724
  validation loss:		2.233167
  validation accuracy:		12.93 %
Epoch 561 of 2000 took 0.097s
  training loss:		2.288716
  validation loss:		2.236726
  validation accuracy:		12.93 %
Epoch 562 of 2000 took 0.096s
  training loss:		2.289534
  validation loss:		2.237998
  validation accuracy:		17.39 %
Epoch 563 of 2000 took 0.097s
  training loss:		2.288350
  validation loss:		2.234851
  validation accuracy:		15.43 %
Epoch 564 of 2000 took 0.097s
  training loss:		2.289004
  validation loss:		2.234614
  validation accuracy:		13.91 %
Epoch 565 of 2000 took 0.097s
  training loss:		2.288260
  validation loss:		2.236759
  validation accuracy:		13.91 %
Epoch 566 of 2000 took 0.096s
  training loss:		2.289364
  validation loss:		2.238315
  validation accuracy:		13.70 %
Epoch 567 of 2000 took 0.101s
  training loss:		2.288494
  validation loss:		2.234876
  validation accuracy:		14.02 %
Epoch 568 of 2000 took 0.097s
  training loss:		2.289767
  validation loss:		2.235947
  validation accuracy:		17.72 %
Epoch 569 of 2000 took 0.097s
  training loss:		2.288592
  validation loss:		2.237937
  validation accuracy:		12.93 %
Epoch 570 of 2000 took 0.097s
  training loss:		2.289003
  validation loss:		2.238775
  validation accuracy:		12.93 %
Epoch 571 of 2000 took 0.097s
  training loss:		2.288715
  validation loss:		2.234157
  validation accuracy:		12.93 %
Epoch 572 of 2000 took 0.097s
  training loss:		2.287401
  validation loss:		2.232920
  validation accuracy:		12.72 %
Epoch 573 of 2000 took 0.097s
  training loss:		2.288084
  validation loss:		2.230743
  validation accuracy:		12.93 %
Epoch 574 of 2000 took 0.096s
  training loss:		2.289446
  validation loss:		2.237122
  validation accuracy:		13.37 %
Epoch 575 of 2000 took 0.097s
  training loss:		2.288705
  validation loss:		2.238884
  validation accuracy:		13.15 %
Epoch 576 of 2000 took 0.097s
  training loss:		2.288767
  validation loss:		2.237247
  validation accuracy:		12.83 %
Epoch 577 of 2000 took 0.097s
  training loss:		2.288170
  validation loss:		2.233961
  validation accuracy:		12.93 %
Epoch 578 of 2000 took 0.097s
  training loss:		2.287605
  validation loss:		2.234976
  validation accuracy:		14.02 %
Epoch 579 of 2000 took 0.098s
  training loss:		2.287487
  validation loss:		2.232199
  validation accuracy:		14.46 %
Epoch 580 of 2000 took 0.097s
  training loss:		2.288353
  validation loss:		2.233131
  validation accuracy:		12.83 %
Epoch 581 of 2000 took 0.098s
  training loss:		2.287712
  validation loss:		2.233969
  validation accuracy:		13.04 %
Epoch 582 of 2000 took 0.100s
  training loss:		2.288552
  validation loss:		2.238401
  validation accuracy:		19.02 %
Epoch 583 of 2000 took 0.097s
  training loss:		2.287551
  validation loss:		2.234773
  validation accuracy:		13.15 %
Epoch 584 of 2000 took 0.097s
  training loss:		2.287755
  validation loss:		2.232941
  validation accuracy:		12.93 %
Epoch 585 of 2000 took 0.097s
  training loss:		2.288114
  validation loss:		2.233345
  validation accuracy:		12.83 %
Epoch 586 of 2000 took 0.097s
  training loss:		2.287792
  validation loss:		2.236949
  validation accuracy:		13.70 %
Epoch 587 of 2000 took 0.097s
  training loss:		2.287834
  validation loss:		2.235895
  validation accuracy:		14.13 %
Epoch 588 of 2000 took 0.097s
  training loss:		2.287540
  validation loss:		2.233683
  validation accuracy:		13.15 %
Epoch 589 of 2000 took 0.097s
  training loss:		2.287282
  validation loss:		2.234237
  validation accuracy:		13.37 %
Epoch 590 of 2000 took 0.097s
  training loss:		2.285662
  validation loss:		2.229958
  validation accuracy:		13.04 %
Epoch 591 of 2000 took 0.097s
  training loss:		2.287251
  validation loss:		2.230207
  validation accuracy:		12.93 %
Epoch 592 of 2000 took 0.097s
  training loss:		2.287530
  validation loss:		2.234591
  validation accuracy:		13.48 %
Epoch 593 of 2000 took 0.097s
  training loss:		2.286198
  validation loss:		2.232270
  validation accuracy:		15.22 %
Epoch 594 of 2000 took 0.097s
  training loss:		2.286606
  validation loss:		2.235079
  validation accuracy:		12.93 %
Epoch 595 of 2000 took 0.102s
  training loss:		2.286783
  validation loss:		2.231453
  validation accuracy:		12.50 %
Epoch 596 of 2000 took 0.097s
  training loss:		2.287117
  validation loss:		2.235597
  validation accuracy:		12.72 %
Epoch 597 of 2000 took 0.097s
  training loss:		2.286097
  validation loss:		2.235680
  validation accuracy:		12.93 %
Epoch 598 of 2000 took 0.097s
  training loss:		2.286872
  validation loss:		2.232491
  validation accuracy:		14.78 %
Epoch 599 of 2000 took 0.097s
  training loss:		2.286666
  validation loss:		2.233607
  validation accuracy:		14.57 %
Epoch 600 of 2000 took 0.097s
  training loss:		2.287260
  validation loss:		2.235963
  validation accuracy:		13.15 %
Epoch 601 of 2000 took 0.097s
  training loss:		2.285500
  validation loss:		2.230967
  validation accuracy:		12.39 %
Epoch 602 of 2000 took 0.097s
  training loss:		2.286788
  validation loss:		2.234170
  validation accuracy:		12.93 %
Epoch 603 of 2000 took 0.097s
  training loss:		2.286339
  validation loss:		2.234175
  validation accuracy:		12.93 %
Epoch 604 of 2000 took 0.097s
  training loss:		2.285720
  validation loss:		2.233057
  validation accuracy:		13.15 %
Epoch 605 of 2000 took 0.097s
  training loss:		2.285901
  validation loss:		2.232185
  validation accuracy:		15.54 %
Epoch 606 of 2000 took 0.097s
  training loss:		2.285424
  validation loss:		2.233567
  validation accuracy:		14.35 %
Epoch 607 of 2000 took 0.101s
  training loss:		2.286644
  validation loss:		2.232290
  validation accuracy:		12.83 %
Epoch 608 of 2000 took 0.097s
  training loss:		2.286363
  validation loss:		2.234075
  validation accuracy:		13.26 %
Epoch 609 of 2000 took 0.097s
  training loss:		2.286015
  validation loss:		2.235104
  validation accuracy:		13.26 %
Epoch 610 of 2000 took 0.098s
  training loss:		2.285440
  validation loss:		2.234921
  validation accuracy:		14.02 %
Epoch 611 of 2000 took 0.097s
  training loss:		2.285361
  validation loss:		2.232232
  validation accuracy:		12.72 %
Epoch 612 of 2000 took 0.097s
  training loss:		2.285737
  validation loss:		2.230738
  validation accuracy:		15.22 %
Epoch 613 of 2000 took 0.097s
  training loss:		2.284231
  validation loss:		2.229611
  validation accuracy:		13.26 %
Epoch 614 of 2000 took 0.096s
  training loss:		2.284788
  validation loss:		2.231723
  validation accuracy:		12.50 %
Epoch 615 of 2000 took 0.097s
  training loss:		2.283881
  validation loss:		2.230428
  validation accuracy:		14.89 %
Epoch 616 of 2000 took 0.097s
  training loss:		2.285286
  validation loss:		2.227437
  validation accuracy:		12.50 %
Epoch 617 of 2000 took 0.099s
  training loss:		2.284710
  validation loss:		2.230735
  validation accuracy:		13.04 %
Epoch 618 of 2000 took 0.099s
  training loss:		2.284135
  validation loss:		2.230049
  validation accuracy:		14.57 %
Epoch 619 of 2000 took 0.097s
  training loss:		2.284324
  validation loss:		2.230445
  validation accuracy:		13.15 %
Epoch 620 of 2000 took 0.097s
  training loss:		2.284178
  validation loss:		2.231397
  validation accuracy:		14.46 %
Epoch 621 of 2000 took 0.097s
  training loss:		2.284526
  validation loss:		2.230022
  validation accuracy:		12.83 %
Epoch 622 of 2000 took 0.097s
  training loss:		2.283729
  validation loss:		2.230665
  validation accuracy:		15.76 %
Epoch 623 of 2000 took 0.097s
  training loss:		2.283785
  validation loss:		2.229759
  validation accuracy:		14.67 %
Epoch 624 of 2000 took 0.096s
  training loss:		2.282413
  validation loss:		2.226652
  validation accuracy:		18.26 %
Epoch 625 of 2000 took 0.097s
  training loss:		2.283429
  validation loss:		2.227975
  validation accuracy:		14.46 %
Epoch 626 of 2000 took 0.097s
  training loss:		2.283801
  validation loss:		2.226782
  validation accuracy:		13.59 %
Epoch 627 of 2000 took 0.097s
  training loss:		2.282705
  validation loss:		2.229510
  validation accuracy:		14.57 %
Epoch 628 of 2000 took 0.101s
  training loss:		2.282642
  validation loss:		2.229977
  validation accuracy:		14.57 %
Epoch 629 of 2000 took 0.097s
  training loss:		2.282831
  validation loss:		2.226290
  validation accuracy:		13.80 %
Epoch 630 of 2000 took 0.097s
  training loss:		2.282284
  validation loss:		2.226884
  validation accuracy:		13.37 %
Epoch 631 of 2000 took 0.097s
  training loss:		2.281616
  validation loss:		2.227770
  validation accuracy:		15.33 %
Epoch 632 of 2000 took 0.097s
  training loss:		2.280662
  validation loss:		2.223847
  validation accuracy:		14.02 %
Epoch 633 of 2000 took 0.097s
  training loss:		2.282521
  validation loss:		2.224406
  validation accuracy:		12.93 %
Epoch 634 of 2000 took 0.097s
  training loss:		2.280185
  validation loss:		2.225573
  validation accuracy:		12.93 %
Epoch 635 of 2000 took 0.097s
  training loss:		2.281906
  validation loss:		2.226537
  validation accuracy:		13.26 %
Epoch 636 of 2000 took 0.097s
  training loss:		2.281129
  validation loss:		2.229573
  validation accuracy:		14.13 %
Epoch 637 of 2000 took 0.097s
  training loss:		2.281667
  validation loss:		2.226980
  validation accuracy:		14.02 %
Epoch 638 of 2000 took 0.101s
  training loss:		2.280527
  validation loss:		2.225332
  validation accuracy:		13.80 %
Epoch 639 of 2000 took 0.097s
  training loss:		2.280466
  validation loss:		2.225780
  validation accuracy:		13.48 %
Epoch 640 of 2000 took 0.097s
  training loss:		2.280358
  validation loss:		2.226745
  validation accuracy:		13.80 %
Epoch 641 of 2000 took 0.098s
  training loss:		2.280863
  validation loss:		2.225146
  validation accuracy:		14.13 %
Epoch 642 of 2000 took 0.097s
  training loss:		2.280119
  validation loss:		2.225944
  validation accuracy:		14.46 %
Epoch 643 of 2000 took 0.097s
  training loss:		2.279974
  validation loss:		2.225597
  validation accuracy:		14.02 %
Epoch 644 of 2000 took 0.097s
  training loss:		2.280579
  validation loss:		2.224200
  validation accuracy:		12.93 %
Epoch 645 of 2000 took 0.097s
  training loss:		2.280282
  validation loss:		2.229858
  validation accuracy:		15.65 %
Epoch 646 of 2000 took 0.097s
  training loss:		2.279286
  validation loss:		2.225869
  validation accuracy:		14.67 %
Epoch 647 of 2000 took 0.097s
  training loss:		2.278150
  validation loss:		2.222686
  validation accuracy:		12.61 %
Epoch 648 of 2000 took 0.101s
  training loss:		2.278253
  validation loss:		2.221991
  validation accuracy:		12.39 %
Epoch 649 of 2000 took 0.098s
  training loss:		2.278014
  validation loss:		2.223531
  validation accuracy:		13.04 %
Epoch 650 of 2000 took 0.097s
  training loss:		2.277569
  validation loss:		2.224096
  validation accuracy:		13.15 %
Epoch 651 of 2000 took 0.096s
  training loss:		2.277947
  validation loss:		2.221405
  validation accuracy:		14.57 %
Epoch 652 of 2000 took 0.097s
  training loss:		2.276953
  validation loss:		2.221049
  validation accuracy:		13.70 %
Epoch 653 of 2000 took 0.097s
  training loss:		2.276950
  validation loss:		2.219710
  validation accuracy:		13.91 %
Epoch 654 of 2000 took 0.097s
  training loss:		2.276376
  validation loss:		2.221071
  validation accuracy:		14.89 %
Epoch 655 of 2000 took 0.096s
  training loss:		2.276375
  validation loss:		2.222743
  validation accuracy:		14.35 %
Epoch 656 of 2000 took 0.097s
  training loss:		2.275459
  validation loss:		2.221307
  validation accuracy:		13.91 %
Epoch 657 of 2000 took 0.097s
  training loss:		2.275286
  validation loss:		2.216688
  validation accuracy:		14.35 %
Epoch 658 of 2000 took 0.097s
  training loss:		2.275379
  validation loss:		2.219465
  validation accuracy:		13.37 %
Epoch 659 of 2000 took 0.101s
  training loss:		2.275122
  validation loss:		2.217783
  validation accuracy:		14.67 %
Epoch 660 of 2000 took 0.097s
  training loss:		2.275219
  validation loss:		2.221804
  validation accuracy:		14.24 %
Epoch 661 of 2000 took 0.096s
  training loss:		2.273719
  validation loss:		2.222188
  validation accuracy:		15.22 %
Epoch 662 of 2000 took 0.097s
  training loss:		2.272849
  validation loss:		2.218489
  validation accuracy:		13.37 %
Epoch 663 of 2000 took 0.097s
  training loss:		2.272556
  validation loss:		2.216995
  validation accuracy:		12.83 %
Epoch 664 of 2000 took 0.097s
  training loss:		2.272253
  validation loss:		2.215761
  validation accuracy:		14.24 %
Epoch 665 of 2000 took 0.097s
  training loss:		2.270781
  validation loss:		2.214500
  validation accuracy:		14.24 %
Epoch 666 of 2000 took 0.097s
  training loss:		2.269968
  validation loss:		2.213221
  validation accuracy:		14.89 %
Epoch 667 of 2000 took 0.096s
  training loss:		2.270057
  validation loss:		2.213053
  validation accuracy:		15.00 %
Epoch 668 of 2000 took 0.097s
  training loss:		2.268700
  validation loss:		2.213825
  validation accuracy:		14.67 %
Epoch 669 of 2000 took 0.101s
  training loss:		2.268728
  validation loss:		2.212416
  validation accuracy:		15.33 %
Epoch 670 of 2000 took 0.097s
  training loss:		2.266445
  validation loss:		2.208396
  validation accuracy:		14.35 %
Epoch 671 of 2000 took 0.097s
  training loss:		2.266839
  validation loss:		2.207887
  validation accuracy:		14.57 %
Epoch 672 of 2000 took 0.098s
  training loss:		2.265985
  validation loss:		2.205395
  validation accuracy:		15.54 %
Epoch 673 of 2000 took 0.097s
  training loss:		2.265722
  validation loss:		2.207983
  validation accuracy:		14.89 %
Epoch 674 of 2000 took 0.097s
  training loss:		2.262847
  validation loss:		2.205821
  validation accuracy:		15.33 %
Epoch 675 of 2000 took 0.097s
  training loss:		2.262834
  validation loss:		2.203318
  validation accuracy:		14.46 %
Epoch 676 of 2000 took 0.097s
  training loss:		2.262373
  validation loss:		2.204936
  validation accuracy:		14.13 %
Epoch 677 of 2000 took 0.097s
  training loss:		2.260362
  validation loss:		2.204306
  validation accuracy:		14.46 %
Epoch 678 of 2000 took 0.097s
  training loss:		2.257767
  validation loss:		2.199427
  validation accuracy:		14.78 %
Epoch 679 of 2000 took 0.101s
  training loss:		2.257439
  validation loss:		2.195546
  validation accuracy:		14.67 %
Epoch 680 of 2000 took 0.101s
  training loss:		2.256447
  validation loss:		2.195202
  validation accuracy:		16.09 %
Epoch 681 of 2000 took 0.100s
  training loss:		2.253171
  validation loss:		2.193665
  validation accuracy:		15.11 %
Epoch 682 of 2000 took 0.100s
  training loss:		2.251482
  validation loss:		2.191867
  validation accuracy:		14.78 %
Epoch 683 of 2000 took 0.100s
  training loss:		2.249902
  validation loss:		2.189219
  validation accuracy:		14.78 %
Epoch 684 of 2000 took 0.100s
  training loss:		2.247058
  validation loss:		2.185297
  validation accuracy:		15.33 %
Epoch 685 of 2000 took 0.100s
  training loss:		2.244337
  validation loss:		2.181363
  validation accuracy:		15.98 %
Epoch 686 of 2000 took 0.100s
  training loss:		2.241382
  validation loss:		2.178603
  validation accuracy:		16.96 %
Epoch 687 of 2000 took 0.100s
  training loss:		2.238886
  validation loss:		2.173539
  validation accuracy:		16.20 %
Epoch 688 of 2000 took 0.100s
  training loss:		2.234038
  validation loss:		2.170013
  validation accuracy:		16.41 %
Epoch 689 of 2000 took 0.104s
  training loss:		2.230704
  validation loss:		2.165161
  validation accuracy:		16.63 %
Epoch 690 of 2000 took 0.100s
  training loss:		2.224068
  validation loss:		2.159160
  validation accuracy:		17.07 %
Epoch 691 of 2000 took 0.100s
  training loss:		2.218809
  validation loss:		2.150975
  validation accuracy:		17.39 %
Epoch 692 of 2000 took 0.100s
  training loss:		2.211714
  validation loss:		2.143532
  validation accuracy:		18.91 %
Epoch 693 of 2000 took 0.100s
  training loss:		2.204787
  validation loss:		2.133244
  validation accuracy:		19.24 %
Epoch 694 of 2000 took 0.100s
  training loss:		2.197258
  validation loss:		2.124483
  validation accuracy:		19.67 %
Epoch 695 of 2000 took 0.100s
  training loss:		2.186395
  validation loss:		2.112461
  validation accuracy:		19.57 %
Epoch 696 of 2000 took 0.100s
  training loss:		2.174870
  validation loss:		2.098097
  validation accuracy:		20.00 %
Epoch 697 of 2000 took 0.100s
  training loss:		2.164508
  validation loss:		2.083344
  validation accuracy:		19.89 %
Epoch 698 of 2000 took 0.100s
  training loss:		2.148420
  validation loss:		2.067211
  validation accuracy:		20.33 %
Epoch 699 of 2000 took 0.104s
  training loss:		2.136228
  validation loss:		2.050397
  validation accuracy:		20.98 %
Epoch 700 of 2000 took 0.100s
  training loss:		2.121570
  validation loss:		2.031972
  validation accuracy:		20.65 %
Epoch 701 of 2000 took 0.100s
  training loss:		2.107734
  validation loss:		2.014007
  validation accuracy:		21.30 %
Epoch 702 of 2000 took 0.101s
  training loss:		2.089514
  validation loss:		1.995025
  validation accuracy:		20.76 %
Epoch 703 of 2000 took 0.100s
  training loss:		2.072908
  validation loss:		1.975639
  validation accuracy:		21.20 %
Epoch 704 of 2000 took 0.100s
  training loss:		2.055108
  validation loss:		1.955714
  validation accuracy:		21.63 %
Epoch 705 of 2000 took 0.100s
  training loss:		2.036023
  validation loss:		1.936364
  validation accuracy:		21.96 %
Epoch 706 of 2000 took 0.100s
  training loss:		2.021407
  validation loss:		1.916234
  validation accuracy:		21.74 %
Epoch 707 of 2000 took 0.100s
  training loss:		2.003595
  validation loss:		1.896897
  validation accuracy:		22.39 %
Epoch 708 of 2000 took 0.100s
  training loss:		1.989934
  validation loss:		1.878098
  validation accuracy:		22.83 %
Epoch 709 of 2000 took 0.104s
  training loss:		1.971960
  validation loss:		1.859812
  validation accuracy:		23.48 %
Epoch 710 of 2000 took 0.100s
  training loss:		1.954388
  validation loss:		1.840946
  validation accuracy:		22.83 %
Epoch 711 of 2000 took 0.100s
  training loss:		1.940333
  validation loss:		1.823283
  validation accuracy:		24.46 %
Epoch 712 of 2000 took 0.100s
  training loss:		1.920043
  validation loss:		1.804571
  validation accuracy:		24.78 %
Epoch 713 of 2000 took 0.100s
  training loss:		1.907208
  validation loss:		1.785955
  validation accuracy:		25.65 %
Epoch 714 of 2000 took 0.100s
  training loss:		1.889014
  validation loss:		1.767507
  validation accuracy:		26.20 %
Epoch 715 of 2000 took 0.100s
  training loss:		1.870949
  validation loss:		1.748568
  validation accuracy:		25.22 %
Epoch 716 of 2000 took 0.100s
  training loss:		1.857852
  validation loss:		1.734739
  validation accuracy:		24.89 %
Epoch 717 of 2000 took 0.100s
  training loss:		1.838898
  validation loss:		1.714720
  validation accuracy:		28.04 %
Epoch 718 of 2000 took 0.100s
  training loss:		1.823647
  validation loss:		1.698808
  validation accuracy:		29.46 %
Epoch 719 of 2000 took 0.104s
  training loss:		1.809636
  validation loss:		1.682569
  validation accuracy:		30.87 %
Epoch 720 of 2000 took 0.101s
  training loss:		1.797599
  validation loss:		1.667672
  validation accuracy:		32.07 %
Epoch 721 of 2000 took 0.100s
  training loss:		1.783842
  validation loss:		1.654449
  validation accuracy:		32.07 %
Epoch 722 of 2000 took 0.100s
  training loss:		1.767116
  validation loss:		1.642644
  validation accuracy:		32.61 %
Epoch 723 of 2000 took 0.100s
  training loss:		1.759633
  validation loss:		1.629861
  validation accuracy:		34.46 %
Epoch 724 of 2000 took 0.100s
  training loss:		1.747440
  validation loss:		1.617481
  validation accuracy:		34.46 %
Epoch 725 of 2000 took 0.100s
  training loss:		1.736397
  validation loss:		1.607069
  validation accuracy:		34.57 %
Epoch 726 of 2000 took 0.100s
  training loss:		1.723506
  validation loss:		1.597482
  validation accuracy:		34.89 %
Epoch 727 of 2000 took 0.100s
  training loss:		1.712805
  validation loss:		1.591721
  validation accuracy:		34.46 %
Epoch 728 of 2000 took 0.100s
  training loss:		1.702537
  validation loss:		1.581447
  validation accuracy:		34.89 %
Epoch 729 of 2000 took 0.104s
  training loss:		1.695160
  validation loss:		1.569799
  validation accuracy:		35.87 %
Epoch 730 of 2000 took 0.100s
  training loss:		1.683874
  validation loss:		1.565144
  validation accuracy:		35.22 %
Epoch 731 of 2000 took 0.100s
  training loss:		1.677675
  validation loss:		1.551729
  validation accuracy:		36.52 %
Epoch 732 of 2000 took 0.101s
  training loss:		1.663510
  validation loss:		1.544277
  validation accuracy:		37.17 %
Epoch 733 of 2000 took 0.100s
  training loss:		1.656076
  validation loss:		1.535273
  validation accuracy:		37.61 %
Epoch 734 of 2000 took 0.100s
  training loss:		1.647651
  validation loss:		1.532742
  validation accuracy:		36.85 %
Epoch 735 of 2000 took 0.100s
  training loss:		1.636806
  validation loss:		1.519785
  validation accuracy:		38.26 %
Epoch 736 of 2000 took 0.100s
  training loss:		1.624522
  validation loss:		1.511223
  validation accuracy:		38.80 %
Epoch 737 of 2000 took 0.100s
  training loss:		1.622754
  validation loss:		1.504041
  validation accuracy:		38.70 %
Epoch 738 of 2000 took 0.100s
  training loss:		1.608217
  validation loss:		1.498661
  validation accuracy:		39.78 %
Epoch 739 of 2000 took 0.104s
  training loss:		1.600811
  validation loss:		1.494741
  validation accuracy:		38.59 %
Epoch 740 of 2000 took 0.100s
  training loss:		1.591900
  validation loss:		1.482105
  validation accuracy:		40.65 %
Epoch 741 of 2000 took 0.100s
  training loss:		1.584858
  validation loss:		1.474922
  validation accuracy:		40.11 %
Epoch 742 of 2000 took 0.100s
  training loss:		1.577481
  validation loss:		1.468423
  validation accuracy:		40.43 %
Epoch 743 of 2000 took 0.100s
  training loss:		1.573878
  validation loss:		1.460837
  validation accuracy:		40.54 %
Epoch 744 of 2000 took 0.100s
  training loss:		1.562229
  validation loss:		1.452489
  validation accuracy:		41.20 %
Epoch 745 of 2000 took 0.100s
  training loss:		1.548870
  validation loss:		1.443848
  validation accuracy:		42.39 %
Epoch 746 of 2000 took 0.100s
  training loss:		1.546919
  validation loss:		1.438411
  validation accuracy:		41.52 %
Epoch 747 of 2000 took 0.100s
  training loss:		1.541978
  validation loss:		1.431173
  validation accuracy:		42.83 %
Epoch 748 of 2000 took 0.100s
  training loss:		1.529339
  validation loss:		1.427017
  validation accuracy:		44.89 %
Epoch 749 of 2000 took 0.104s
  training loss:		1.523238
  validation loss:		1.417388
  validation accuracy:		45.22 %
Epoch 750 of 2000 took 0.100s
  training loss:		1.515974
  validation loss:		1.416576
  validation accuracy:		45.11 %
Epoch 751 of 2000 took 0.100s
  training loss:		1.506234
  validation loss:		1.404935
  validation accuracy:		44.89 %
Epoch 752 of 2000 took 0.100s
  training loss:		1.511427
  validation loss:		1.398787
  validation accuracy:		45.87 %
Epoch 753 of 2000 took 0.100s
  training loss:		1.492840
  validation loss:		1.392723
  validation accuracy:		45.65 %
Epoch 754 of 2000 took 0.100s
  training loss:		1.492700
  validation loss:		1.386933
  validation accuracy:		45.98 %
Epoch 755 of 2000 took 0.100s
  training loss:		1.484444
  validation loss:		1.386358
  validation accuracy:		45.54 %
Epoch 756 of 2000 took 0.100s
  training loss:		1.478212
  validation loss:		1.376528
  validation accuracy:		46.74 %
Epoch 757 of 2000 took 0.100s
  training loss:		1.469705
  validation loss:		1.390284
  validation accuracy:		46.30 %
Epoch 758 of 2000 took 0.100s
  training loss:		1.462765
  validation loss:		1.367555
  validation accuracy:		47.07 %
Epoch 759 of 2000 took 0.105s
  training loss:		1.457626
  validation loss:		1.369678
  validation accuracy:		47.61 %
Epoch 760 of 2000 took 0.100s
  training loss:		1.464627
  validation loss:		1.363657
  validation accuracy:		47.72 %
Epoch 761 of 2000 took 0.103s
  training loss:		1.448339
  validation loss:		1.358368
  validation accuracy:		48.59 %
Epoch 762 of 2000 took 0.102s
  training loss:		1.445445
  validation loss:		1.346994
  validation accuracy:		49.35 %
Epoch 763 of 2000 took 0.100s
  training loss:		1.436961
  validation loss:		1.342244
  validation accuracy:		49.24 %
Epoch 764 of 2000 took 0.100s
  training loss:		1.434786
  validation loss:		1.339426
  validation accuracy:		49.35 %
Epoch 765 of 2000 took 0.100s
  training loss:		1.435502
  validation loss:		1.362756
  validation accuracy:		47.50 %
Epoch 766 of 2000 took 0.100s
  training loss:		1.421459
  validation loss:		1.329083
  validation accuracy:		50.43 %
Epoch 767 of 2000 took 0.100s
  training loss:		1.420493
  validation loss:		1.327320
  validation accuracy:		50.00 %
Epoch 768 of 2000 took 0.100s
  training loss:		1.422742
  validation loss:		1.321275
  validation accuracy:		50.33 %
Epoch 769 of 2000 took 0.105s
  training loss:		1.408365
  validation loss:		1.322707
  validation accuracy:		51.85 %
Epoch 770 of 2000 took 0.100s
  training loss:		1.415976
  validation loss:		1.340251
  validation accuracy:		49.02 %
Epoch 771 of 2000 took 0.100s
  training loss:		1.415071
  validation loss:		1.310823
  validation accuracy:		51.20 %
Epoch 772 of 2000 took 0.100s
  training loss:		1.414120
  validation loss:		1.307293
  validation accuracy:		51.85 %
Epoch 773 of 2000 took 0.100s
  training loss:		1.401463
  validation loss:		1.325390
  validation accuracy:		51.63 %
Epoch 774 of 2000 took 0.100s
  training loss:		1.412139
  validation loss:		1.309771
  validation accuracy:		53.15 %
Epoch 775 of 2000 took 0.100s
  training loss:		1.390999
  validation loss:		1.297740
  validation accuracy:		52.83 %
Epoch 776 of 2000 took 0.100s
  training loss:		1.382936
  validation loss:		1.297837
  validation accuracy:		51.74 %
Epoch 777 of 2000 took 0.100s
  training loss:		1.386311
  validation loss:		1.292026
  validation accuracy:		53.70 %
Epoch 778 of 2000 took 0.100s
  training loss:		1.374039
  validation loss:		1.288346
  validation accuracy:		53.04 %
Epoch 779 of 2000 took 0.105s
  training loss:		1.389224
  validation loss:		1.302247
  validation accuracy:		53.59 %
Epoch 780 of 2000 took 0.100s
  training loss:		1.382960
  validation loss:		1.286984
  validation accuracy:		52.07 %
Epoch 781 of 2000 took 0.097s
  training loss:		1.416651
  validation loss:		1.290784
  validation accuracy:		52.28 %
Epoch 782 of 2000 took 0.097s
  training loss:		1.368642
  validation loss:		1.279964
  validation accuracy:		53.59 %
Epoch 783 of 2000 took 0.097s
  training loss:		1.363211
  validation loss:		1.274114
  validation accuracy:		53.59 %
Epoch 784 of 2000 took 0.097s
  training loss:		1.365242
  validation loss:		1.270062
  validation accuracy:		54.02 %
Epoch 785 of 2000 took 0.097s
  training loss:		1.362525
  validation loss:		1.294785
  validation accuracy:		51.20 %
Epoch 786 of 2000 took 0.097s
  training loss:		1.363158
  validation loss:		1.265931
  validation accuracy:		55.11 %
Epoch 787 of 2000 took 0.097s
  training loss:		1.362296
  validation loss:		1.263647
  validation accuracy:		55.22 %
Epoch 788 of 2000 took 0.097s
  training loss:		1.426830
  validation loss:		1.268007
  validation accuracy:		54.89 %
Epoch 789 of 2000 took 0.101s
  training loss:		1.383743
  validation loss:		1.524621
  validation accuracy:		39.35 %
Epoch 790 of 2000 took 0.097s
  training loss:		1.441937
  validation loss:		1.430636
  validation accuracy:		44.78 %
Epoch 791 of 2000 took 0.097s
  training loss:		1.443415
  validation loss:		1.271320
  validation accuracy:		55.22 %
Epoch 792 of 2000 took 0.098s
  training loss:		1.355540
  validation loss:		1.269308
  validation accuracy:		55.76 %
Epoch 793 of 2000 took 0.097s
  training loss:		1.353312
  validation loss:		1.276710
  validation accuracy:		52.07 %
Epoch 794 of 2000 took 0.097s
  training loss:		1.350354
  validation loss:		1.275119
  validation accuracy:		55.00 %
Epoch 795 of 2000 took 0.097s
  training loss:		1.343368
  validation loss:		1.252879
  validation accuracy:		56.09 %
Epoch 796 of 2000 took 0.097s
  training loss:		1.389837
  validation loss:		1.409548
  validation accuracy:		44.35 %
Epoch 797 of 2000 took 0.097s
  training loss:		1.400340
  validation loss:		1.342074
  validation accuracy:		50.00 %
Epoch 798 of 2000 took 0.097s
  training loss:		1.389098
  validation loss:		1.322990
  validation accuracy:		50.76 %
Epoch 799 of 2000 took 0.101s
  training loss:		1.356354
  validation loss:		1.257162
  validation accuracy:		55.33 %
Epoch 800 of 2000 took 0.098s
  training loss:		1.349351
  validation loss:		1.246957
  validation accuracy:		56.30 %
Epoch 801 of 2000 took 0.097s
  training loss:		1.342115
  validation loss:		1.250600
  validation accuracy:		56.30 %
Epoch 802 of 2000 took 0.097s
  training loss:		1.365803
  validation loss:		1.315314
  validation accuracy:		51.41 %
Epoch 803 of 2000 took 0.097s
  training loss:		1.348400
  validation loss:		1.309416
  validation accuracy:		51.63 %
Epoch 804 of 2000 took 0.097s
  training loss:		1.453358
  validation loss:		1.302835
  validation accuracy:		52.72 %
Epoch 805 of 2000 took 0.097s
  training loss:		1.374840
  validation loss:		1.249778
  validation accuracy:		56.41 %
Epoch 806 of 2000 took 0.097s
  training loss:		1.328080
  validation loss:		1.261082
  validation accuracy:		55.76 %
Epoch 807 of 2000 took 0.097s
  training loss:		1.398878
  validation loss:		1.310579
  validation accuracy:		51.96 %
Epoch 808 of 2000 took 0.097s
  training loss:		1.327633
  validation loss:		1.255214
  validation accuracy:		55.76 %
Epoch 809 of 2000 took 0.097s
  training loss:		1.321272
  validation loss:		1.248670
  validation accuracy:		56.30 %
Epoch 810 of 2000 took 0.101s
  training loss:		1.323819
  validation loss:		1.237391
  validation accuracy:		57.28 %
Epoch 811 of 2000 took 0.097s
  training loss:		1.337493
  validation loss:		1.258907
  validation accuracy:		53.91 %
Epoch 812 of 2000 took 0.097s
  training loss:		1.316058
  validation loss:		1.240205
  validation accuracy:		56.20 %
Epoch 813 of 2000 took 0.097s
  training loss:		1.318816
  validation loss:		1.232558
  validation accuracy:		56.74 %
Epoch 814 of 2000 took 0.097s
  training loss:		1.366343
  validation loss:		1.294906
  validation accuracy:		52.07 %
Epoch 815 of 2000 took 0.097s
  training loss:		1.383673
  validation loss:		1.271120
  validation accuracy:		55.22 %
Epoch 816 of 2000 took 0.097s
  training loss:		1.410569
  validation loss:		1.304601
  validation accuracy:		52.28 %
Epoch 817 of 2000 took 0.097s
  training loss:		1.339655
  validation loss:		1.247470
  validation accuracy:		57.39 %
Epoch 818 of 2000 took 0.097s
  training loss:		1.325730
  validation loss:		1.286194
  validation accuracy:		52.93 %
Epoch 819 of 2000 took 0.097s
  training loss:		1.372431
  validation loss:		1.236712
  validation accuracy:		56.96 %
Epoch 820 of 2000 took 0.101s
  training loss:		1.332778
  validation loss:		1.233142
  validation accuracy:		56.96 %
Epoch 821 of 2000 took 0.097s
  training loss:		1.312443
  validation loss:		1.230688
  validation accuracy:		56.74 %
Epoch 822 of 2000 took 0.097s
  training loss:		1.319799
  validation loss:		1.237090
  validation accuracy:		56.20 %
Epoch 823 of 2000 took 0.098s
  training loss:		1.308192
  validation loss:		1.226554
  validation accuracy:		57.07 %
Epoch 824 of 2000 took 0.097s
  training loss:		1.325587
  validation loss:		1.285541
  validation accuracy:		53.48 %
Epoch 825 of 2000 took 0.097s
  training loss:		1.360043
  validation loss:		1.244509
  validation accuracy:		56.41 %
Epoch 826 of 2000 took 0.097s
  training loss:		1.379199
  validation loss:		1.248767
  validation accuracy:		56.74 %
Epoch 827 of 2000 took 0.097s
  training loss:		1.310922
  validation loss:		1.247592
  validation accuracy:		56.74 %
Epoch 828 of 2000 took 0.097s
  training loss:		1.323450
  validation loss:		1.243269
  validation accuracy:		55.87 %
Epoch 829 of 2000 took 0.097s
  training loss:		1.322013
  validation loss:		1.284632
  validation accuracy:		53.15 %
Epoch 830 of 2000 took 0.101s
  training loss:		1.312646
  validation loss:		1.245504
  validation accuracy:		55.54 %
Epoch 831 of 2000 took 0.097s
  training loss:		1.323534
  validation loss:		1.293069
  validation accuracy:		52.39 %
Epoch 832 of 2000 took 0.097s
  training loss:		1.599345
  validation loss:		1.395366
  validation accuracy:		47.39 %
Epoch 833 of 2000 took 0.097s
  training loss:		1.350824
  validation loss:		1.256110
  validation accuracy:		56.52 %
Epoch 834 of 2000 took 0.097s
  training loss:		1.314206
  validation loss:		1.248656
  validation accuracy:		55.33 %
Epoch 835 of 2000 took 0.097s
  training loss:		1.312594
  validation loss:		1.259779
  validation accuracy:		54.24 %
Epoch 836 of 2000 took 0.097s
  training loss:		1.321536
  validation loss:		1.222093
  validation accuracy:		58.15 %
Epoch 837 of 2000 took 0.097s
  training loss:		1.317453
  validation loss:		1.239849
  validation accuracy:		55.54 %
Epoch 838 of 2000 took 0.097s
  training loss:		1.305426
  validation loss:		1.222757
  validation accuracy:		57.39 %
Epoch 839 of 2000 took 0.097s
  training loss:		1.305131
  validation loss:		1.234152
  validation accuracy:		56.20 %
Epoch 840 of 2000 took 0.100s
  training loss:		1.305390
  validation loss:		1.235766
  validation accuracy:		57.17 %
Epoch 841 of 2000 took 0.098s
  training loss:		1.342749
  validation loss:		1.241098
  validation accuracy:		56.85 %
Epoch 842 of 2000 took 0.097s
  training loss:		1.298235
  validation loss:		1.242955
  validation accuracy:		56.74 %
Epoch 843 of 2000 took 0.097s
  training loss:		1.370077
  validation loss:		1.227969
  validation accuracy:		58.37 %
Epoch 844 of 2000 took 0.097s
  training loss:		1.299701
  validation loss:		1.224020
  validation accuracy:		57.50 %
Epoch 845 of 2000 took 0.097s
  training loss:		1.297166
  validation loss:		1.224695
  validation accuracy:		56.96 %
Epoch 846 of 2000 took 0.097s
  training loss:		1.332342
  validation loss:		1.225742
  validation accuracy:		57.17 %
Epoch 847 of 2000 took 0.097s
  training loss:		1.324134
  validation loss:		1.248809
  validation accuracy:		56.30 %
Epoch 848 of 2000 took 0.097s
  training loss:		1.351852
  validation loss:		1.226734
  validation accuracy:		56.09 %
Epoch 849 of 2000 took 0.097s
  training loss:		1.312159
  validation loss:		1.231597
  validation accuracy:		57.61 %
Epoch 850 of 2000 took 0.097s
  training loss:		1.313007
  validation loss:		1.227609
  validation accuracy:		56.63 %
Epoch 851 of 2000 took 0.101s
  training loss:		1.306495
  validation loss:		1.275412
  validation accuracy:		53.26 %
Epoch 852 of 2000 took 0.097s
  training loss:		1.342252
  validation loss:		1.263983
  validation accuracy:		54.67 %
Epoch 853 of 2000 took 0.097s
  training loss:		1.330936
  validation loss:		1.273576
  validation accuracy:		54.24 %
Epoch 854 of 2000 took 0.098s
  training loss:		1.369044
  validation loss:		1.292189
  validation accuracy:		52.93 %
Epoch 855 of 2000 took 0.097s
  training loss:		1.309068
  validation loss:		1.278505
  validation accuracy:		54.13 %
Epoch 856 of 2000 took 0.097s
  training loss:		1.363588
  validation loss:		1.223396
  validation accuracy:		57.72 %
Epoch 857 of 2000 took 0.097s
  training loss:		1.306994
  validation loss:		1.235377
  validation accuracy:		56.41 %
Epoch 858 of 2000 took 0.097s
  training loss:		1.322380
  validation loss:		1.231811
  validation accuracy:		57.83 %
Epoch 859 of 2000 took 0.097s
  training loss:		1.336665
  validation loss:		1.222990
  validation accuracy:		58.26 %
Epoch 860 of 2000 took 0.097s
  training loss:		1.302668
  validation loss:		1.221774
  validation accuracy:		57.17 %
Epoch 861 of 2000 took 0.101s
  training loss:		1.306630
  validation loss:		1.221191
  validation accuracy:		57.83 %
Epoch 862 of 2000 took 0.097s
  training loss:		1.351364
  validation loss:		1.338491
  validation accuracy:		49.46 %
Epoch 863 of 2000 took 0.097s
  training loss:		1.339340
  validation loss:		1.226615
  validation accuracy:		58.48 %
Epoch 864 of 2000 took 0.097s
  training loss:		1.308019
  validation loss:		1.318089
  validation accuracy:		51.09 %
Epoch 865 of 2000 took 0.097s
  training loss:		1.323198
  validation loss:		1.222545
  validation accuracy:		57.39 %
Epoch 866 of 2000 took 0.097s
  training loss:		1.293648
  validation loss:		1.225894
  validation accuracy:		56.85 %
Epoch 867 of 2000 took 0.097s
  training loss:		1.308222
  validation loss:		1.274223
  validation accuracy:		52.83 %
Epoch 868 of 2000 took 0.097s
  training loss:		1.339541
  validation loss:		1.284635
  validation accuracy:		53.48 %
Epoch 869 of 2000 took 0.097s
  training loss:		1.315304
  validation loss:		1.225119
  validation accuracy:		58.04 %
Epoch 870 of 2000 took 0.097s
  training loss:		1.296325
  validation loss:		1.219848
  validation accuracy:		58.04 %
Epoch 871 of 2000 took 0.101s
  training loss:		1.299205
  validation loss:		1.227566
  validation accuracy:		56.63 %
Epoch 872 of 2000 took 0.097s
  training loss:		1.333142
  validation loss:		1.222796
  validation accuracy:		57.72 %
Epoch 873 of 2000 took 0.097s
  training loss:		1.314993
  validation loss:		1.238898
  validation accuracy:		56.20 %
Epoch 874 of 2000 took 0.097s
  training loss:		1.312141
  validation loss:		1.220553
  validation accuracy:		58.15 %
Epoch 875 of 2000 took 0.097s
  training loss:		1.326409
  validation loss:		1.234775
  validation accuracy:		57.28 %
Epoch 876 of 2000 took 0.097s
  training loss:		1.328040
  validation loss:		1.221666
  validation accuracy:		56.52 %
Epoch 877 of 2000 took 0.097s
  training loss:		1.324144
  validation loss:		1.222449
  validation accuracy:		57.50 %
Epoch 878 of 2000 took 0.097s
  training loss:		1.308647
  validation loss:		1.304414
  validation accuracy:		51.09 %
Epoch 879 of 2000 took 0.097s
  training loss:		1.299725
  validation loss:		1.234763
  validation accuracy:		56.96 %
Epoch 880 of 2000 took 0.097s
  training loss:		1.308737
  validation loss:		1.258150
  validation accuracy:		55.33 %
Epoch 881 of 2000 took 0.098s
  training loss:		1.303872
  validation loss:		1.222513
  validation accuracy:		57.07 %
Epoch 882 of 2000 took 0.100s
  training loss:		1.333644
  validation loss:		1.258310
  validation accuracy:		55.11 %
Epoch 883 of 2000 took 0.097s
  training loss:		1.322388
  validation loss:		1.221920
  validation accuracy:		58.04 %
Epoch 884 of 2000 took 0.097s
  training loss:		1.295857
  validation loss:		1.233036
  validation accuracy:		57.07 %
Epoch 885 of 2000 took 0.098s
  training loss:		1.311820
  validation loss:		1.266776
  validation accuracy:		54.35 %
Epoch 886 of 2000 took 0.097s
  training loss:		1.420955
  validation loss:		1.227692
  validation accuracy:		57.61 %
Epoch 887 of 2000 took 0.097s
  training loss:		1.309978
  validation loss:		1.231814
  validation accuracy:		56.74 %
Epoch 888 of 2000 took 0.097s
  training loss:		1.302633
  validation loss:		1.219175
  validation accuracy:		58.15 %
Epoch 889 of 2000 took 0.097s
  training loss:		1.312412
  validation loss:		1.271735
  validation accuracy:		53.70 %
Epoch 890 of 2000 took 0.097s
  training loss:		1.341083
  validation loss:		1.236906
  validation accuracy:		56.74 %
Epoch 891 of 2000 took 0.097s
  training loss:		1.301640
  validation loss:		1.250290
  validation accuracy:		56.30 %
Epoch 892 of 2000 took 0.102s
  training loss:		1.348024
  validation loss:		1.223181
  validation accuracy:		57.39 %
Epoch 893 of 2000 took 0.097s
  training loss:		1.290297
  validation loss:		1.216692
  validation accuracy:		57.50 %
Epoch 894 of 2000 took 0.097s
  training loss:		1.299676
  validation loss:		1.219465
  validation accuracy:		57.39 %
Epoch 895 of 2000 took 0.097s
  training loss:		1.291373
  validation loss:		1.214424
  validation accuracy:		57.72 %
Epoch 896 of 2000 took 0.097s
  training loss:		1.287463
  validation loss:		1.242102
  validation accuracy:		56.96 %
Epoch 897 of 2000 took 0.097s
  training loss:		1.312616
  validation loss:		1.218621
  validation accuracy:		57.17 %
Epoch 898 of 2000 took 0.097s
  training loss:		1.312383
  validation loss:		1.279554
  validation accuracy:		53.80 %
Epoch 899 of 2000 took 0.097s
  training loss:		1.316317
  validation loss:		1.226429
  validation accuracy:		57.17 %
Epoch 900 of 2000 took 0.097s
  training loss:		1.319477
  validation loss:		1.289091
  validation accuracy:		52.28 %
Epoch 901 of 2000 took 0.097s
  training loss:		1.303180
  validation loss:		1.220233
  validation accuracy:		57.28 %
Epoch 902 of 2000 took 0.101s
  training loss:		1.332334
  validation loss:		1.224282
  validation accuracy:		56.74 %
Epoch 903 of 2000 took 0.097s
  training loss:		1.320596
  validation loss:		1.279300
  validation accuracy:		53.80 %
Epoch 904 of 2000 took 0.097s
  training loss:		1.315712
  validation loss:		1.239468
  validation accuracy:		57.28 %
Epoch 905 of 2000 took 0.097s
  training loss:		1.295102
  validation loss:		1.219050
  validation accuracy:		56.96 %
Epoch 906 of 2000 took 0.097s
  training loss:		1.286936
  validation loss:		1.229025
  validation accuracy:		57.17 %
Epoch 907 of 2000 took 0.097s
  training loss:		1.297101
  validation loss:		1.218794
  validation accuracy:		56.20 %
Epoch 908 of 2000 took 0.097s
  training loss:		1.287071
  validation loss:		1.222628
  validation accuracy:		57.17 %
Epoch 909 of 2000 took 0.097s
  training loss:		1.311466
  validation loss:		1.220264
  validation accuracy:		57.61 %
Epoch 910 of 2000 took 0.097s
  training loss:		1.306573
  validation loss:		1.217953
  validation accuracy:		57.17 %
Epoch 911 of 2000 took 0.097s
  training loss:		1.298624
  validation loss:		1.249441
  validation accuracy:		56.63 %
Epoch 912 of 2000 took 0.101s
  training loss:		1.301312
  validation loss:		1.221807
  validation accuracy:		57.28 %
Epoch 913 of 2000 took 0.098s
  training loss:		1.334546
  validation loss:		1.289369
  validation accuracy:		52.93 %
Epoch 914 of 2000 took 0.097s
  training loss:		1.302366
  validation loss:		1.226406
  validation accuracy:		56.52 %
Epoch 915 of 2000 took 0.097s
  training loss:		1.302293
  validation loss:		1.243093
  validation accuracy:		57.28 %
Epoch 916 of 2000 took 0.098s
  training loss:		1.327514
  validation loss:		1.235661
  validation accuracy:		56.85 %
Epoch 917 of 2000 took 0.097s
  training loss:		1.309428
  validation loss:		1.247154
  validation accuracy:		56.96 %
Epoch 918 of 2000 took 0.097s
  training loss:		1.305076
  validation loss:		1.229168
  validation accuracy:		56.52 %
Epoch 919 of 2000 took 0.097s
  training loss:		1.304163
  validation loss:		1.218565
  validation accuracy:		56.85 %
Epoch 920 of 2000 took 0.097s
  training loss:		1.297136
  validation loss:		1.275892
  validation accuracy:		53.80 %
Epoch 921 of 2000 took 0.097s
  training loss:		1.292901
  validation loss:		1.214662
  validation accuracy:		56.63 %
Epoch 922 of 2000 took 0.097s
  training loss:		1.290135
  validation loss:		1.216574
  validation accuracy:		57.07 %
Epoch 923 of 2000 took 0.102s
  training loss:		1.296144
  validation loss:		1.223308
  validation accuracy:		55.98 %
Epoch 924 of 2000 took 0.097s
  training loss:		1.297678
  validation loss:		1.255266
  validation accuracy:		56.20 %
Epoch 925 of 2000 took 0.097s
  training loss:		1.303784
  validation loss:		1.238050
  validation accuracy:		57.17 %
Epoch 926 of 2000 took 0.097s
  training loss:		1.300950
  validation loss:		1.217648
  validation accuracy:		56.63 %
Epoch 927 of 2000 took 0.097s
  training loss:		1.314094
  validation loss:		1.221748
  validation accuracy:		55.87 %
Epoch 928 of 2000 took 0.097s
  training loss:		1.302429
  validation loss:		1.215885
  validation accuracy:		56.74 %
Epoch 929 of 2000 took 0.097s
  training loss:		1.282832
  validation loss:		1.214947
  validation accuracy:		55.98 %
Epoch 930 of 2000 took 0.097s
  training loss:		1.294107
  validation loss:		1.224454
  validation accuracy:		56.85 %
Epoch 931 of 2000 took 0.097s
  training loss:		1.297504
  validation loss:		1.214233
  validation accuracy:		56.52 %
Epoch 932 of 2000 took 0.097s
  training loss:		1.315835
  validation loss:		1.279285
  validation accuracy:		53.15 %
Epoch 933 of 2000 took 0.101s
  training loss:		1.328450
  validation loss:		1.225796
  validation accuracy:		55.87 %
Epoch 934 of 2000 took 0.097s
  training loss:		1.285619
  validation loss:		1.218183
  validation accuracy:		56.85 %
Epoch 935 of 2000 took 0.097s
  training loss:		1.294513
  validation loss:		1.306485
  validation accuracy:		51.20 %
Epoch 936 of 2000 took 0.097s
  training loss:		1.306414
  validation loss:		1.216275
  validation accuracy:		57.17 %
Epoch 937 of 2000 took 0.103s
  training loss:		1.293457
  validation loss:		1.216140
  validation accuracy:		56.63 %
Epoch 938 of 2000 took 0.111s
  training loss:		1.287711
  validation loss:		1.262805
  validation accuracy:		54.35 %
Epoch 939 of 2000 took 0.141s
  training loss:		1.302687
  validation loss:		1.247312
  validation accuracy:		57.17 %
Epoch 940 of 2000 took 0.140s
  training loss:		1.302243
  validation loss:		1.215305
  validation accuracy:		56.41 %
Epoch 941 of 2000 took 0.102s
  training loss:		1.289365
  validation loss:		1.214891
  validation accuracy:		57.39 %
Epoch 942 of 2000 took 0.111s
  training loss:		1.286943
  validation loss:		1.216955
  validation accuracy:		56.41 %
Epoch 943 of 2000 took 0.097s
  training loss:		1.290216
  validation loss:		1.213408
  validation accuracy:		56.41 %
Epoch 944 of 2000 took 0.098s
  training loss:		1.284026
  validation loss:		1.210928
  validation accuracy:		56.30 %
Epoch 945 of 2000 took 0.102s
  training loss:		1.305502
  validation loss:		1.290962
  validation accuracy:		52.28 %
Epoch 946 of 2000 took 0.096s
  training loss:		1.296831
  validation loss:		1.219040
  validation accuracy:		56.52 %
Epoch 947 of 2000 took 0.097s
  training loss:		1.283906
  validation loss:		1.215160
  validation accuracy:		56.20 %
Epoch 948 of 2000 took 0.096s
  training loss:		1.282877
  validation loss:		1.218786
  validation accuracy:		56.41 %
Epoch 949 of 2000 took 0.102s
  training loss:		1.280100
  validation loss:		1.211005
  validation accuracy:		56.63 %
Epoch 950 of 2000 took 0.098s
  training loss:		1.298920
  validation loss:		1.225300
  validation accuracy:		56.52 %
Epoch 951 of 2000 took 0.096s
  training loss:		1.340575
  validation loss:		1.215700
  validation accuracy:		56.74 %
Epoch 952 of 2000 took 0.107s
  training loss:		1.289574
  validation loss:		1.218956
  validation accuracy:		57.17 %
Epoch 953 of 2000 took 0.097s
  training loss:		1.277715
  validation loss:		1.245712
  validation accuracy:		54.78 %
Epoch 954 of 2000 took 0.097s
  training loss:		1.297738
  validation loss:		1.207433
  validation accuracy:		55.87 %
Epoch 955 of 2000 took 0.096s
  training loss:		1.288361
  validation loss:		1.209176
  validation accuracy:		56.74 %
Epoch 956 of 2000 took 0.097s
  training loss:		1.281314
  validation loss:		1.216382
  validation accuracy:		56.09 %
Epoch 957 of 2000 took 0.101s
  training loss:		1.285836
  validation loss:		1.205695
  validation accuracy:		56.63 %
Epoch 958 of 2000 took 0.096s
  training loss:		1.287014
  validation loss:		1.270672
  validation accuracy:		54.13 %
Epoch 959 of 2000 took 0.097s
  training loss:		1.286266
  validation loss:		1.209747
  validation accuracy:		56.52 %
Epoch 960 of 2000 took 0.103s
  training loss:		1.270927
  validation loss:		1.206972
  validation accuracy:		56.52 %
Epoch 961 of 2000 took 0.096s
  training loss:		1.284500
  validation loss:		1.209621
  validation accuracy:		56.20 %
Epoch 962 of 2000 took 0.105s
  training loss:		1.274560
  validation loss:		1.221664
  validation accuracy:		56.74 %
Epoch 963 of 2000 took 0.096s
  training loss:		1.308450
  validation loss:		1.207880
  validation accuracy:		56.41 %
Epoch 964 of 2000 took 0.100s
  training loss:		1.294589
  validation loss:		1.208442
  validation accuracy:		57.07 %
Epoch 965 of 2000 took 0.098s
  training loss:		1.283191
  validation loss:		1.208042
  validation accuracy:		56.96 %
Epoch 966 of 2000 took 0.096s
  training loss:		1.285731
  validation loss:		1.205265
  validation accuracy:		56.96 %
Epoch 967 of 2000 took 0.099s
  training loss:		1.285378
  validation loss:		1.206407
  validation accuracy:		56.09 %
Epoch 968 of 2000 took 0.099s
  training loss:		1.278427
  validation loss:		1.207379
  validation accuracy:		56.74 %
Epoch 969 of 2000 took 0.096s
  training loss:		1.278200
  validation loss:		1.220223
  validation accuracy:		56.63 %
Epoch 970 of 2000 took 0.097s
  training loss:		1.272597
  validation loss:		1.236119
  validation accuracy:		54.57 %
Epoch 971 of 2000 took 0.096s
  training loss:		1.289352
  validation loss:		1.220797
  validation accuracy:		56.20 %
Epoch 972 of 2000 took 0.103s
  training loss:		1.289907
  validation loss:		1.213866
  validation accuracy:		55.87 %
Epoch 973 of 2000 took 0.098s
  training loss:		1.308955
  validation loss:		1.250001
  validation accuracy:		55.22 %
Epoch 974 of 2000 took 0.097s
  training loss:		1.304178
  validation loss:		1.204593
  validation accuracy:		57.07 %
Epoch 975 of 2000 took 0.102s
  training loss:		1.295445
  validation loss:		1.225626
  validation accuracy:		55.98 %
Epoch 976 of 2000 took 0.096s
  training loss:		1.280625
  validation loss:		1.201747
  validation accuracy:		57.28 %
Epoch 977 of 2000 took 0.097s
  training loss:		1.277525
  validation loss:		1.200663
  validation accuracy:		56.85 %
Epoch 978 of 2000 took 0.096s
  training loss:		1.281158
  validation loss:		1.201694
  validation accuracy:		56.96 %
Epoch 979 of 2000 took 0.137s
  training loss:		1.291991
  validation loss:		1.207642
  validation accuracy:		56.85 %
Epoch 980 of 2000 took 0.168s
  training loss:		1.269019
  validation loss:		1.201751
  validation accuracy:		57.61 %
Epoch 981 of 2000 took 0.105s
  training loss:		1.302289
  validation loss:		1.247269
  validation accuracy:		53.59 %
Epoch 982 of 2000 took 0.097s
  training loss:		1.273828
  validation loss:		1.196622
  validation accuracy:		57.39 %
Epoch 983 of 2000 took 0.102s
  training loss:		1.263979
  validation loss:		1.203079
  validation accuracy:		56.85 %
Epoch 984 of 2000 took 0.096s
  training loss:		1.278835
  validation loss:		1.201172
  validation accuracy:		57.39 %
Epoch 985 of 2000 took 0.100s
  training loss:		1.261699
  validation loss:		1.193806
  validation accuracy:		57.83 %
Epoch 986 of 2000 took 0.097s
  training loss:		1.266680
  validation loss:		1.193967
  validation accuracy:		58.70 %
Epoch 987 of 2000 took 0.101s
  training loss:		1.264557
  validation loss:		1.195022
  validation accuracy:		58.26 %
Epoch 988 of 2000 took 0.097s
  training loss:		1.270350
  validation loss:		1.197238
  validation accuracy:		57.83 %
Epoch 989 of 2000 took 0.096s
  training loss:		1.267085
  validation loss:		1.187987
  validation accuracy:		58.04 %
Epoch 990 of 2000 took 0.101s
  training loss:		1.266499
  validation loss:		1.213966
  validation accuracy:		57.39 %
Epoch 991 of 2000 took 0.097s
  training loss:		1.274932
  validation loss:		1.187648
  validation accuracy:		58.37 %
Epoch 992 of 2000 took 0.096s
  training loss:		1.261701
  validation loss:		1.187427
  validation accuracy:		58.70 %
Epoch 993 of 2000 took 0.097s
  training loss:		1.263875
  validation loss:		1.186390
  validation accuracy:		59.24 %
Epoch 994 of 2000 took 0.097s
  training loss:		1.269631
  validation loss:		1.196971
  validation accuracy:		58.59 %
Epoch 995 of 2000 took 0.100s
  training loss:		1.257838
  validation loss:		1.187357
  validation accuracy:		57.72 %
Epoch 996 of 2000 took 0.097s
  training loss:		1.250936
  validation loss:		1.182599
  validation accuracy:		58.59 %
Epoch 997 of 2000 took 0.097s
  training loss:		1.257853
  validation loss:		1.179089
  validation accuracy:		58.04 %
Epoch 998 of 2000 took 0.102s
  training loss:		1.245628
  validation loss:		1.178196
  validation accuracy:		58.59 %
Epoch 999 of 2000 took 0.096s
  training loss:		1.262213
  validation loss:		1.262154
  validation accuracy:		53.70 %
Epoch 1000 of 2000 took 0.097s
  training loss:		1.271367
  validation loss:		1.177512
  validation accuracy:		59.35 %
Epoch 1001 of 2000 took 0.096s
  training loss:		1.262532
  validation loss:		1.173205
  validation accuracy:		59.02 %
Epoch 1002 of 2000 took 0.098s
  training loss:		1.243391
  validation loss:		1.170682
  validation accuracy:		58.59 %
Epoch 1003 of 2000 took 0.100s
  training loss:		1.244253
  validation loss:		1.166063
  validation accuracy:		58.91 %
Epoch 1004 of 2000 took 0.096s
  training loss:		1.250185
  validation loss:		1.164936
  validation accuracy:		59.02 %
Epoch 1005 of 2000 took 0.100s
  training loss:		1.236726
  validation loss:		1.167847
  validation accuracy:		58.59 %
Epoch 1006 of 2000 took 0.102s
  training loss:		1.251800
  validation loss:		1.189973
  validation accuracy:		58.80 %
Epoch 1007 of 2000 took 0.096s
  training loss:		1.239232
  validation loss:		1.162673
  validation accuracy:		59.46 %
Epoch 1008 of 2000 took 0.097s
  training loss:		1.234763
  validation loss:		1.155937
  validation accuracy:		59.24 %
Epoch 1009 of 2000 took 0.096s
  training loss:		1.228684
  validation loss:		1.156813
  validation accuracy:		59.02 %
Epoch 1010 of 2000 took 0.101s
  training loss:		1.224815
  validation loss:		1.147401
  validation accuracy:		60.00 %
Epoch 1011 of 2000 took 0.098s
  training loss:		1.225714
  validation loss:		1.150850
  validation accuracy:		60.00 %
Epoch 1012 of 2000 took 0.096s
  training loss:		1.224130
  validation loss:		1.141980
  validation accuracy:		60.65 %
Epoch 1013 of 2000 took 0.101s
  training loss:		1.224117
  validation loss:		1.146962
  validation accuracy:		60.65 %
Epoch 1014 of 2000 took 0.097s
  training loss:		1.218213
  validation loss:		1.131910
  validation accuracy:		60.65 %
Epoch 1015 of 2000 took 0.096s
  training loss:		1.197944
  validation loss:		1.130667
  validation accuracy:		61.63 %
Epoch 1016 of 2000 took 0.096s
  training loss:		1.201216
  validation loss:		1.127573
  validation accuracy:		62.07 %
Epoch 1017 of 2000 took 0.097s
  training loss:		1.209153
  validation loss:		1.123160
  validation accuracy:		60.98 %
Epoch 1018 of 2000 took 0.100s
  training loss:		1.195684
  validation loss:		1.120221
  validation accuracy:		61.30 %
Epoch 1019 of 2000 took 0.097s
  training loss:		1.194486
  validation loss:		1.124114
  validation accuracy:		62.07 %
Epoch 1020 of 2000 took 0.097s
  training loss:		1.188228
  validation loss:		1.101948
  validation accuracy:		62.72 %
Epoch 1021 of 2000 took 0.102s
  training loss:		1.187167
  validation loss:		1.102115
  validation accuracy:		62.39 %
Epoch 1022 of 2000 took 0.096s
  training loss:		1.179163
  validation loss:		1.095105
  validation accuracy:		62.39 %
Epoch 1023 of 2000 took 0.097s
  training loss:		1.172705
  validation loss:		1.087079
  validation accuracy:		63.04 %
Epoch 1024 of 2000 took 0.096s
  training loss:		1.166574
  validation loss:		1.082272
  validation accuracy:		63.26 %
Epoch 1025 of 2000 took 0.098s
  training loss:		1.165724
  validation loss:		1.084235
  validation accuracy:		63.80 %
Epoch 1026 of 2000 took 0.100s
  training loss:		1.168114
  validation loss:		1.084405
  validation accuracy:		63.70 %
Epoch 1027 of 2000 took 0.096s
  training loss:		1.163546
  validation loss:		1.069630
  validation accuracy:		63.70 %
Epoch 1028 of 2000 took 0.098s
  training loss:		1.145729
  validation loss:		1.059866
  validation accuracy:		65.65 %
Epoch 1029 of 2000 took 0.101s
  training loss:		1.140974
  validation loss:		1.060587
  validation accuracy:		64.02 %
Epoch 1030 of 2000 took 0.096s
  training loss:		1.136372
  validation loss:		1.050413
  validation accuracy:		64.46 %
Epoch 1031 of 2000 took 0.097s
  training loss:		1.132555
  validation loss:		1.047420
  validation accuracy:		65.11 %
Epoch 1032 of 2000 took 0.096s
  training loss:		1.121790
  validation loss:		1.047572
  validation accuracy:		64.67 %
Epoch 1033 of 2000 took 0.101s
  training loss:		1.121413
  validation loss:		1.036315
  validation accuracy:		65.65 %
Epoch 1034 of 2000 took 0.098s
  training loss:		1.114595
  validation loss:		1.034225
  validation accuracy:		65.87 %
Epoch 1035 of 2000 took 0.096s
  training loss:		1.108053
  validation loss:		1.032960
  validation accuracy:		65.87 %
Epoch 1036 of 2000 took 0.102s
  training loss:		1.107298
  validation loss:		1.023486
  validation accuracy:		66.85 %
Epoch 1037 of 2000 took 0.099s
  training loss:		1.086261
  validation loss:		1.014655
  validation accuracy:		66.20 %
Epoch 1038 of 2000 took 0.097s
  training loss:		1.082706
  validation loss:		1.037952
  validation accuracy:		62.61 %
Epoch 1039 of 2000 took 0.096s
  training loss:		1.090967
  validation loss:		1.012687
  validation accuracy:		66.52 %
Epoch 1040 of 2000 took 0.097s
  training loss:		1.085888
  validation loss:		1.000797
  validation accuracy:		65.98 %
Epoch 1041 of 2000 took 0.101s
  training loss:		1.078038
  validation loss:		1.012579
  validation accuracy:		66.52 %
Epoch 1042 of 2000 took 0.097s
  training loss:		1.064222
  validation loss:		0.992890
  validation accuracy:		68.15 %
Epoch 1043 of 2000 took 0.097s
  training loss:		1.064042
  validation loss:		0.989098
  validation accuracy:		67.50 %
Epoch 1044 of 2000 took 0.103s
  training loss:		1.066643
  validation loss:		0.985671
  validation accuracy:		68.26 %
Epoch 1045 of 2000 took 0.096s
  training loss:		1.050096
  validation loss:		0.988883
  validation accuracy:		67.72 %
Epoch 1046 of 2000 took 0.097s
  training loss:		1.050915
  validation loss:		0.970389
  validation accuracy:		69.13 %
Epoch 1047 of 2000 took 0.096s
  training loss:		1.042297
  validation loss:		0.973775
  validation accuracy:		68.37 %
Epoch 1048 of 2000 took 0.098s
  training loss:		1.038573
  validation loss:		0.967112
  validation accuracy:		67.83 %
Epoch 1049 of 2000 took 0.099s
  training loss:		1.032993
  validation loss:		0.971553
  validation accuracy:		68.15 %
Epoch 1050 of 2000 took 0.096s
  training loss:		1.028745
  validation loss:		0.953501
  validation accuracy:		69.57 %
Epoch 1051 of 2000 took 0.098s
  training loss:		1.032209
  validation loss:		0.958819
  validation accuracy:		68.26 %
Epoch 1052 of 2000 took 0.101s
  training loss:		1.022444
  validation loss:		0.947782
  validation accuracy:		69.46 %
Epoch 1053 of 2000 took 0.096s
  training loss:		1.019162
  validation loss:		0.946842
  validation accuracy:		70.54 %
Epoch 1054 of 2000 took 0.097s
  training loss:		1.015953
  validation loss:		0.943014
  validation accuracy:		70.33 %
Epoch 1055 of 2000 took 0.096s
  training loss:		1.006735
  validation loss:		0.951839
  validation accuracy:		69.02 %
Epoch 1056 of 2000 took 0.101s
  training loss:		1.026776
  validation loss:		0.945127
  validation accuracy:		69.24 %
Epoch 1057 of 2000 took 0.098s
  training loss:		0.994103
  validation loss:		0.936671
  validation accuracy:		70.11 %
Epoch 1058 of 2000 took 0.096s
  training loss:		0.981716
  validation loss:		0.924012
  validation accuracy:		70.98 %
Epoch 1059 of 2000 took 0.101s
  training loss:		0.989537
  validation loss:		0.933250
  validation accuracy:		69.46 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.979566
  validation loss:		0.911522
  validation accuracy:		70.87 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.974349
  validation loss:		0.919316
  validation accuracy:		70.87 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.965759
  validation loss:		0.911241
  validation accuracy:		71.09 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.967633
  validation loss:		0.918962
  validation accuracy:		70.22 %
Epoch 1064 of 2000 took 0.100s
  training loss:		0.964027
  validation loss:		0.911021
  validation accuracy:		70.54 %
Epoch 1065 of 2000 took 0.097s
  training loss:		0.962341
  validation loss:		0.896038
  validation accuracy:		71.41 %
Epoch 1066 of 2000 took 0.096s
  training loss:		0.951526
  validation loss:		0.907502
  validation accuracy:		69.46 %
Epoch 1067 of 2000 took 0.102s
  training loss:		0.940628
  validation loss:		0.889850
  validation accuracy:		70.87 %
Epoch 1068 of 2000 took 0.096s
  training loss:		0.942770
  validation loss:		0.893011
  validation accuracy:		70.98 %
Epoch 1069 of 2000 took 0.097s
  training loss:		0.934807
  validation loss:		0.873631
  validation accuracy:		72.07 %
Epoch 1070 of 2000 took 0.096s
  training loss:		0.931258
  validation loss:		0.876079
  validation accuracy:		71.20 %
Epoch 1071 of 2000 took 0.098s
  training loss:		0.929241
  validation loss:		0.874560
  validation accuracy:		72.17 %
Epoch 1072 of 2000 took 0.100s
  training loss:		0.920579
  validation loss:		0.869146
  validation accuracy:		72.39 %
Epoch 1073 of 2000 took 0.096s
  training loss:		0.915992
  validation loss:		0.881600
  validation accuracy:		70.98 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.905859
  validation loss:		0.869688
  validation accuracy:		72.07 %
Epoch 1075 of 2000 took 0.102s
  training loss:		0.898225
  validation loss:		0.863817
  validation accuracy:		72.39 %
Epoch 1076 of 2000 took 0.096s
  training loss:		0.901890
  validation loss:		0.853141
  validation accuracy:		72.93 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.888364
  validation loss:		0.852370
  validation accuracy:		72.61 %
Epoch 1078 of 2000 took 0.096s
  training loss:		0.891455
  validation loss:		0.850461
  validation accuracy:		72.28 %
Epoch 1079 of 2000 took 0.100s
  training loss:		0.873878
  validation loss:		0.844196
  validation accuracy:		72.61 %
Epoch 1080 of 2000 took 0.098s
  training loss:		0.883639
  validation loss:		0.851176
  validation accuracy:		72.28 %
Epoch 1081 of 2000 took 0.096s
  training loss:		0.869517
  validation loss:		0.825403
  validation accuracy:		74.46 %
Epoch 1082 of 2000 took 0.101s
  training loss:		0.869172
  validation loss:		0.829796
  validation accuracy:		72.72 %
Epoch 1083 of 2000 took 0.098s
  training loss:		0.856455
  validation loss:		0.841650
  validation accuracy:		73.37 %
Epoch 1084 of 2000 took 0.097s
  training loss:		0.856931
  validation loss:		0.810364
  validation accuracy:		74.78 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.849361
  validation loss:		0.818140
  validation accuracy:		74.57 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.850911
  validation loss:		0.812370
  validation accuracy:		74.24 %
Epoch 1087 of 2000 took 0.100s
  training loss:		0.836699
  validation loss:		0.793612
  validation accuracy:		75.33 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.827028
  validation loss:		0.804743
  validation accuracy:		75.65 %
Epoch 1089 of 2000 took 0.099s
  training loss:		0.826028
  validation loss:		0.811233
  validation accuracy:		75.43 %
Epoch 1090 of 2000 took 0.102s
  training loss:		0.823439
  validation loss:		0.778010
  validation accuracy:		75.76 %
Epoch 1091 of 2000 took 0.096s
  training loss:		0.822998
  validation loss:		0.764754
  validation accuracy:		76.30 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.806131
  validation loss:		0.775384
  validation accuracy:		76.30 %
Epoch 1093 of 2000 took 0.096s
  training loss:		0.808271
  validation loss:		0.764399
  validation accuracy:		76.74 %
Epoch 1094 of 2000 took 0.098s
  training loss:		0.788664
  validation loss:		0.769023
  validation accuracy:		76.85 %
Epoch 1095 of 2000 took 0.100s
  training loss:		0.795924
  validation loss:		0.789135
  validation accuracy:		75.76 %
Epoch 1096 of 2000 took 0.096s
  training loss:		0.788620
  validation loss:		0.742617
  validation accuracy:		76.85 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.791108
  validation loss:		0.740399
  validation accuracy:		77.07 %
Epoch 1098 of 2000 took 0.102s
  training loss:		0.782558
  validation loss:		0.761203
  validation accuracy:		77.39 %
Epoch 1099 of 2000 took 0.096s
  training loss:		0.782666
  validation loss:		0.734198
  validation accuracy:		76.74 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.781792
  validation loss:		0.784453
  validation accuracy:		76.41 %
Epoch 1101 of 2000 took 0.096s
  training loss:		0.767027
  validation loss:		0.742768
  validation accuracy:		77.61 %
Epoch 1102 of 2000 took 0.100s
  training loss:		0.767273
  validation loss:		0.722403
  validation accuracy:		78.37 %
Epoch 1103 of 2000 took 0.098s
  training loss:		0.754901
  validation loss:		0.726672
  validation accuracy:		78.37 %
Epoch 1104 of 2000 took 0.096s
  training loss:		0.758977
  validation loss:		0.765695
  validation accuracy:		76.96 %
Epoch 1105 of 2000 took 0.100s
  training loss:		0.742909
  validation loss:		0.698678
  validation accuracy:		78.59 %
Epoch 1106 of 2000 took 0.098s
  training loss:		0.742168
  validation loss:		0.713842
  validation accuracy:		78.37 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.741490
  validation loss:		0.723792
  validation accuracy:		78.37 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.735424
  validation loss:		0.714255
  validation accuracy:		78.37 %
Epoch 1109 of 2000 took 0.096s
  training loss:		0.738681
  validation loss:		0.681725
  validation accuracy:		79.02 %
Epoch 1110 of 2000 took 0.100s
  training loss:		0.730962
  validation loss:		0.685468
  validation accuracy:		78.80 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.732134
  validation loss:		0.696682
  validation accuracy:		79.35 %
Epoch 1112 of 2000 took 0.096s
  training loss:		0.735252
  validation loss:		0.673226
  validation accuracy:		77.72 %
Epoch 1113 of 2000 took 0.102s
  training loss:		0.728972
  validation loss:		0.674550
  validation accuracy:		79.67 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.719801
  validation loss:		0.674402
  validation accuracy:		79.35 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.707202
  validation loss:		0.670323
  validation accuracy:		80.22 %
Epoch 1116 of 2000 took 0.096s
  training loss:		0.711410
  validation loss:		0.693216
  validation accuracy:		78.80 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.700639
  validation loss:		0.672468
  validation accuracy:		79.67 %
Epoch 1118 of 2000 took 0.101s
  training loss:		0.701103
  validation loss:		0.663036
  validation accuracy:		80.11 %
Epoch 1119 of 2000 took 0.096s
  training loss:		0.700976
  validation loss:		0.650971
  validation accuracy:		79.89 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.696410
  validation loss:		0.660128
  validation accuracy:		79.89 %
Epoch 1121 of 2000 took 0.102s
  training loss:		0.689077
  validation loss:		0.665959
  validation accuracy:		79.57 %
Epoch 1122 of 2000 took 0.096s
  training loss:		0.687923
  validation loss:		0.644008
  validation accuracy:		80.11 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.696913
  validation loss:		0.663188
  validation accuracy:		80.00 %
Epoch 1124 of 2000 took 0.096s
  training loss:		0.681321
  validation loss:		0.635928
  validation accuracy:		79.24 %
Epoch 1125 of 2000 took 0.100s
  training loss:		0.681792
  validation loss:		0.693252
  validation accuracy:		78.91 %
Epoch 1126 of 2000 took 0.098s
  training loss:		0.683323
  validation loss:		0.634793
  validation accuracy:		78.04 %
Epoch 1127 of 2000 took 0.096s
  training loss:		0.690610
  validation loss:		0.653105
  validation accuracy:		76.30 %
Epoch 1128 of 2000 took 0.099s
  training loss:		0.704200
  validation loss:		0.635452
  validation accuracy:		80.87 %
Epoch 1129 of 2000 took 0.099s
  training loss:		0.683945
  validation loss:		0.626383
  validation accuracy:		80.54 %
Epoch 1130 of 2000 took 0.096s
  training loss:		0.673794
  validation loss:		0.705230
  validation accuracy:		78.91 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.678332
  validation loss:		0.637545
  validation accuracy:		76.96 %
Epoch 1132 of 2000 took 0.096s
  training loss:		0.685928
  validation loss:		0.653398
  validation accuracy:		80.00 %
Epoch 1133 of 2000 took 0.101s
  training loss:		0.666857
  validation loss:		0.635477
  validation accuracy:		79.78 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.656480
  validation loss:		0.653205
  validation accuracy:		80.98 %
Epoch 1135 of 2000 took 0.096s
  training loss:		0.661784
  validation loss:		0.614509
  validation accuracy:		80.98 %
Epoch 1136 of 2000 took 0.102s
  training loss:		0.662184
  validation loss:		0.614309
  validation accuracy:		80.43 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.684302
  validation loss:		0.612089
  validation accuracy:		79.89 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.669385
  validation loss:		0.654556
  validation accuracy:		80.33 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.650309
  validation loss:		0.618004
  validation accuracy:		79.78 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.665499
  validation loss:		0.727596
  validation accuracy:		77.07 %
Epoch 1141 of 2000 took 0.101s
  training loss:		0.658192
  validation loss:		0.647141
  validation accuracy:		80.43 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.650604
  validation loss:		0.617720
  validation accuracy:		80.76 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.642174
  validation loss:		0.609817
  validation accuracy:		80.43 %
Epoch 1144 of 2000 took 0.102s
  training loss:		0.640467
  validation loss:		0.615733
  validation accuracy:		80.22 %
Epoch 1145 of 2000 took 0.096s
  training loss:		0.652370
  validation loss:		0.617221
  validation accuracy:		80.76 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.641985
  validation loss:		0.637425
  validation accuracy:		80.33 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.654714
  validation loss:		0.613058
  validation accuracy:		80.87 %
Epoch 1148 of 2000 took 0.099s
  training loss:		0.652215
  validation loss:		0.654253
  validation accuracy:		79.57 %
Epoch 1149 of 2000 took 0.099s
  training loss:		0.658060
  validation loss:		0.601971
  validation accuracy:		81.20 %
Epoch 1150 of 2000 took 0.096s
  training loss:		0.669696
  validation loss:		0.672550
  validation accuracy:		78.70 %
Epoch 1151 of 2000 took 0.099s
  training loss:		0.648399
  validation loss:		0.641268
  validation accuracy:		79.89 %
Epoch 1152 of 2000 took 0.099s
  training loss:		0.640386
  validation loss:		0.625496
  validation accuracy:		80.22 %
Epoch 1153 of 2000 took 0.096s
  training loss:		0.682303
  validation loss:		0.616140
  validation accuracy:		80.65 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.636326
  validation loss:		0.597105
  validation accuracy:		81.20 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.644075
  validation loss:		0.732280
  validation accuracy:		76.52 %
Epoch 1156 of 2000 took 0.101s
  training loss:		0.668678
  validation loss:		0.605322
  validation accuracy:		79.13 %
Epoch 1157 of 2000 took 0.098s
  training loss:		0.643604
  validation loss:		0.617092
  validation accuracy:		80.43 %
Epoch 1158 of 2000 took 0.096s
  training loss:		0.632536
  validation loss:		0.611724
  validation accuracy:		80.54 %
Epoch 1159 of 2000 took 0.102s
  training loss:		0.626527
  validation loss:		0.628159
  validation accuracy:		80.43 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.623382
  validation loss:		0.626987
  validation accuracy:		80.22 %
Epoch 1161 of 2000 took 0.097s
  training loss:		0.625698
  validation loss:		0.595825
  validation accuracy:		80.65 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.623733
  validation loss:		0.603637
  validation accuracy:		81.09 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.624640
  validation loss:		0.639390
  validation accuracy:		79.35 %
Epoch 1164 of 2000 took 0.101s
  training loss:		0.632985
  validation loss:		0.596892
  validation accuracy:		80.11 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.632451
  validation loss:		0.714691
  validation accuracy:		77.39 %
Epoch 1166 of 2000 took 0.097s
  training loss:		0.664983
  validation loss:		0.610071
  validation accuracy:		79.35 %
Epoch 1167 of 2000 took 0.102s
  training loss:		0.645229
  validation loss:		0.610461
  validation accuracy:		80.98 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.619514
  validation loss:		0.684708
  validation accuracy:		78.37 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.644543
  validation loss:		0.630619
  validation accuracy:		80.11 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.615171
  validation loss:		0.621346
  validation accuracy:		80.00 %
Epoch 1171 of 2000 took 0.103s
  training loss:		0.615120
  validation loss:		0.606931
  validation accuracy:		79.02 %
Epoch 1172 of 2000 took 0.098s
  training loss:		0.656861
  validation loss:		0.592820
  validation accuracy:		79.46 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.630159
  validation loss:		0.622701
  validation accuracy:		80.00 %
Epoch 1174 of 2000 took 0.099s
  training loss:		0.623231
  validation loss:		0.598823
  validation accuracy:		79.24 %
Epoch 1175 of 2000 took 0.100s
  training loss:		0.636272
  validation loss:		0.637778
  validation accuracy:		79.78 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.614763
  validation loss:		0.670920
  validation accuracy:		78.70 %
Epoch 1177 of 2000 took 0.097s
  training loss:		0.639150
  validation loss:		0.592131
  validation accuracy:		80.00 %
Epoch 1178 of 2000 took 0.096s
  training loss:		0.626380
  validation loss:		0.592803
  validation accuracy:		80.43 %
Epoch 1179 of 2000 took 0.101s
  training loss:		0.620212
  validation loss:		0.587842
  validation accuracy:		80.11 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.603087
  validation loss:		0.596530
  validation accuracy:		80.65 %
Epoch 1181 of 2000 took 0.096s
  training loss:		0.612556
  validation loss:		0.590412
  validation accuracy:		79.78 %
Epoch 1182 of 2000 took 0.102s
  training loss:		0.641069
  validation loss:		0.610653
  validation accuracy:		80.76 %
Epoch 1183 of 2000 took 0.096s
  training loss:		0.620204
  validation loss:		0.663990
  validation accuracy:		78.59 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.607193
  validation loss:		0.612540
  validation accuracy:		80.33 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.620598
  validation loss:		0.594178
  validation accuracy:		80.22 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.608835
  validation loss:		0.624241
  validation accuracy:		79.35 %
Epoch 1187 of 2000 took 0.100s
  training loss:		0.609552
  validation loss:		0.664333
  validation accuracy:		78.80 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.617472
  validation loss:		0.604646
  validation accuracy:		80.11 %
Epoch 1189 of 2000 took 0.097s
  training loss:		0.620143
  validation loss:		0.637167
  validation accuracy:		80.00 %
Epoch 1190 of 2000 took 0.102s
  training loss:		0.616238
  validation loss:		0.638214
  validation accuracy:		79.78 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.620327
  validation loss:		0.608558
  validation accuracy:		80.22 %
Epoch 1192 of 2000 took 0.097s
  training loss:		0.599601
  validation loss:		0.591157
  validation accuracy:		80.54 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.628747
  validation loss:		0.583112
  validation accuracy:		80.54 %
Epoch 1194 of 2000 took 0.099s
  training loss:		0.617192
  validation loss:		0.731218
  validation accuracy:		76.63 %
Epoch 1195 of 2000 took 0.099s
  training loss:		0.603607
  validation loss:		0.612238
  validation accuracy:		80.22 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.608932
  validation loss:		0.612898
  validation accuracy:		79.67 %
Epoch 1197 of 2000 took 0.099s
  training loss:		0.659644
  validation loss:		0.732581
  validation accuracy:		76.52 %
Epoch 1198 of 2000 took 0.100s
  training loss:		0.610113
  validation loss:		0.692641
  validation accuracy:		77.61 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.636613
  validation loss:		0.601032
  validation accuracy:		80.33 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.620593
  validation loss:		0.588066
  validation accuracy:		80.54 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.604118
  validation loss:		0.637480
  validation accuracy:		79.67 %
Epoch 1202 of 2000 took 0.101s
  training loss:		0.614802
  validation loss:		0.588903
  validation accuracy:		80.65 %
Epoch 1203 of 2000 took 0.097s
  training loss:		0.625046
  validation loss:		0.583749
  validation accuracy:		80.65 %
Epoch 1204 of 2000 took 0.096s
  training loss:		0.606315
  validation loss:		0.587866
  validation accuracy:		80.98 %
Epoch 1205 of 2000 took 0.102s
  training loss:		0.608731
  validation loss:		0.598851
  validation accuracy:		80.33 %
Epoch 1206 of 2000 took 0.097s
  training loss:		0.614850
  validation loss:		0.639772
  validation accuracy:		79.67 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.599840
  validation loss:		0.613304
  validation accuracy:		79.89 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.616315
  validation loss:		0.612791
  validation accuracy:		79.89 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.660903
  validation loss:		0.802027
  validation accuracy:		74.78 %
Epoch 1210 of 2000 took 0.100s
  training loss:		0.660268
  validation loss:		0.589047
  validation accuracy:		80.87 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.619923
  validation loss:		0.599490
  validation accuracy:		80.22 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.589781
  validation loss:		0.598830
  validation accuracy:		80.43 %
Epoch 1213 of 2000 took 0.102s
  training loss:		0.609674
  validation loss:		0.664543
  validation accuracy:		78.04 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.600005
  validation loss:		0.597507
  validation accuracy:		80.76 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.616807
  validation loss:		0.645539
  validation accuracy:		78.91 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.599793
  validation loss:		0.666437
  validation accuracy:		77.93 %
Epoch 1217 of 2000 took 0.098s
  training loss:		0.604697
  validation loss:		0.604157
  validation accuracy:		80.54 %
Epoch 1218 of 2000 took 0.100s
  training loss:		0.606479
  validation loss:		0.618606
  validation accuracy:		80.00 %
Epoch 1219 of 2000 took 0.127s
  training loss:		0.598447
  validation loss:		0.794684
  validation accuracy:		75.00 %
Epoch 1220 of 2000 took 0.098s
  training loss:		0.626179
  validation loss:		0.606212
  validation accuracy:		81.09 %
Epoch 1221 of 2000 took 0.098s
  training loss:		0.614093
  validation loss:		0.594542
  validation accuracy:		80.22 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.595961
  validation loss:		0.591820
  validation accuracy:		80.11 %
Epoch 1223 of 2000 took 0.100s
  training loss:		0.603551
  validation loss:		0.597009
  validation accuracy:		80.11 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.595138
  validation loss:		0.691329
  validation accuracy:		77.39 %
Epoch 1225 of 2000 took 0.099s
  training loss:		0.625857
  validation loss:		0.631931
  validation accuracy:		79.57 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.589884
  validation loss:		0.654171
  validation accuracy:		79.02 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.619372
  validation loss:		0.593677
  validation accuracy:		80.87 %
Epoch 1228 of 2000 took 0.099s
  training loss:		0.597614
  validation loss:		0.622936
  validation accuracy:		79.67 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.615268
  validation loss:		0.680501
  validation accuracy:		77.61 %
Epoch 1230 of 2000 took 0.100s
  training loss:		0.599898
  validation loss:		0.653139
  validation accuracy:		79.02 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.601059
  validation loss:		0.589473
  validation accuracy:		81.20 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.607344
  validation loss:		0.584936
  validation accuracy:		81.09 %
Epoch 1233 of 2000 took 0.098s
  training loss:		0.600975
  validation loss:		0.604159
  validation accuracy:		80.65 %
Epoch 1234 of 2000 took 0.097s
  training loss:		0.629476
  validation loss:		0.584418
  validation accuracy:		80.98 %
Epoch 1235 of 2000 took 0.099s
  training loss:		0.600033
  validation loss:		0.584465
  validation accuracy:		80.65 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.602720
  validation loss:		0.753783
  validation accuracy:		76.20 %
Epoch 1237 of 2000 took 0.100s
  training loss:		0.607139
  validation loss:		0.592816
  validation accuracy:		80.98 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.605207
  validation loss:		0.712602
  validation accuracy:		76.85 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.627714
  validation loss:		0.584138
  validation accuracy:		80.43 %
Epoch 1240 of 2000 took 0.099s
  training loss:		0.590610
  validation loss:		0.659828
  validation accuracy:		78.15 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.619947
  validation loss:		0.597583
  validation accuracy:		80.33 %
Epoch 1242 of 2000 took 0.100s
  training loss:		0.608664
  validation loss:		0.654526
  validation accuracy:		79.02 %
Epoch 1243 of 2000 took 0.096s
  training loss:		0.635264
  validation loss:		0.583356
  validation accuracy:		80.65 %
Epoch 1244 of 2000 took 0.098s
  training loss:		0.601708
  validation loss:		0.601073
  validation accuracy:		80.33 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.594474
  validation loss:		0.657518
  validation accuracy:		78.04 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.605259
  validation loss:		0.597223
  validation accuracy:		80.22 %
Epoch 1247 of 2000 took 0.102s
  training loss:		0.593399
  validation loss:		0.589291
  validation accuracy:		80.11 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.613216
  validation loss:		0.644640
  validation accuracy:		79.13 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.604407
  validation loss:		0.616648
  validation accuracy:		80.33 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.598138
  validation loss:		0.579990
  validation accuracy:		80.98 %
Epoch 1251 of 2000 took 0.098s
  training loss:		0.604311
  validation loss:		0.618322
  validation accuracy:		80.33 %
Epoch 1252 of 2000 took 0.100s
  training loss:		0.598499
  validation loss:		0.624190
  validation accuracy:		79.78 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.595351
  validation loss:		0.635297
  validation accuracy:		79.78 %
Epoch 1254 of 2000 took 0.098s
  training loss:		0.607270
  validation loss:		0.586266
  validation accuracy:		80.65 %
Epoch 1255 of 2000 took 0.101s
  training loss:		0.595812
  validation loss:		0.608142
  validation accuracy:		80.65 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.584267
  validation loss:		0.647337
  validation accuracy:		79.24 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.593547
  validation loss:		0.618417
  validation accuracy:		79.89 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.592396
  validation loss:		0.605894
  validation accuracy:		80.98 %
Epoch 1259 of 2000 took 0.101s
  training loss:		0.609492
  validation loss:		0.584560
  validation accuracy:		80.87 %
Epoch 1260 of 2000 took 0.098s
  training loss:		0.611100
  validation loss:		0.582489
  validation accuracy:		80.76 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.626812
  validation loss:		0.582874
  validation accuracy:		80.98 %
Epoch 1262 of 2000 took 0.102s
  training loss:		0.618937
  validation loss:		0.595117
  validation accuracy:		80.33 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.635904
  validation loss:		0.607979
  validation accuracy:		80.54 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.605226
  validation loss:		0.586250
  validation accuracy:		80.76 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.624440
  validation loss:		0.589181
  validation accuracy:		80.43 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.606757
  validation loss:		0.659655
  validation accuracy:		78.59 %
Epoch 1267 of 2000 took 0.100s
  training loss:		0.588463
  validation loss:		0.593232
  validation accuracy:		80.76 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.595215
  validation loss:		0.641148
  validation accuracy:		79.13 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.600054
  validation loss:		0.639764
  validation accuracy:		80.00 %
Epoch 1270 of 2000 took 0.102s
  training loss:		0.605938
  validation loss:		0.665351
  validation accuracy:		78.91 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.594987
  validation loss:		0.586332
  validation accuracy:		80.76 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.598634
  validation loss:		0.604694
  validation accuracy:		81.09 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.594967
  validation loss:		0.602697
  validation accuracy:		80.76 %
Epoch 1274 of 2000 took 0.099s
  training loss:		0.582799
  validation loss:		0.609420
  validation accuracy:		80.76 %
Epoch 1275 of 2000 took 0.100s
  training loss:		0.612787
  validation loss:		0.587969
  validation accuracy:		80.65 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.608625
  validation loss:		0.584759
  validation accuracy:		80.65 %
Epoch 1277 of 2000 took 0.098s
  training loss:		0.608176
  validation loss:		0.593267
  validation accuracy:		80.54 %
Epoch 1278 of 2000 took 0.100s
  training loss:		0.593208
  validation loss:		0.647533
  validation accuracy:		79.57 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.603734
  validation loss:		0.693717
  validation accuracy:		78.04 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.624297
  validation loss:		0.584947
  validation accuracy:		80.87 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.604851
  validation loss:		0.667743
  validation accuracy:		79.02 %
Epoch 1282 of 2000 took 0.101s
  training loss:		0.595666
  validation loss:		0.593269
  validation accuracy:		80.00 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.610527
  validation loss:		0.587001
  validation accuracy:		80.65 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.603879
  validation loss:		0.590134
  validation accuracy:		80.43 %
Epoch 1285 of 2000 took 0.102s
  training loss:		0.593104
  validation loss:		0.605997
  validation accuracy:		80.76 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.602902
  validation loss:		0.588321
  validation accuracy:		80.76 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.599172
  validation loss:		0.588377
  validation accuracy:		81.52 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.644659
  validation loss:		0.770047
  validation accuracy:		76.09 %
Epoch 1289 of 2000 took 0.097s
  training loss:		0.597514
  validation loss:		0.647069
  validation accuracy:		79.24 %
Epoch 1290 of 2000 took 0.100s
  training loss:		0.601600
  validation loss:		0.594550
  validation accuracy:		81.41 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.594124
  validation loss:		0.646260
  validation accuracy:		79.57 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.589909
  validation loss:		0.663479
  validation accuracy:		78.80 %
Epoch 1293 of 2000 took 0.102s
  training loss:		0.589152
  validation loss:		0.605906
  validation accuracy:		80.43 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.590771
  validation loss:		0.621190
  validation accuracy:		80.54 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.596056
  validation loss:		0.669596
  validation accuracy:		79.13 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.593975
  validation loss:		0.602967
  validation accuracy:		81.09 %
Epoch 1297 of 2000 took 0.098s
  training loss:		0.597628
  validation loss:		0.597792
  validation accuracy:		81.74 %
Epoch 1298 of 2000 took 0.100s
  training loss:		0.590828
  validation loss:		0.597868
  validation accuracy:		80.98 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.593812
  validation loss:		0.639361
  validation accuracy:		79.67 %
Epoch 1300 of 2000 took 0.098s
  training loss:		0.594358
  validation loss:		0.600364
  validation accuracy:		81.20 %
Epoch 1301 of 2000 took 0.101s
  training loss:		0.597996
  validation loss:		0.728616
  validation accuracy:		77.72 %
Epoch 1302 of 2000 took 0.099s
  training loss:		0.605503
  validation loss:		0.604577
  validation accuracy:		80.76 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.625177
  validation loss:		0.762526
  validation accuracy:		76.74 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.597277
  validation loss:		0.581768
  validation accuracy:		80.98 %
Epoch 1305 of 2000 took 0.101s
  training loss:		0.604798
  validation loss:		0.584050
  validation accuracy:		80.87 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.601534
  validation loss:		0.602517
  validation accuracy:		80.98 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.591389
  validation loss:		0.618064
  validation accuracy:		80.22 %
Epoch 1308 of 2000 took 0.102s
  training loss:		0.589275
  validation loss:		0.586980
  validation accuracy:		81.30 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.589023
  validation loss:		0.638664
  validation accuracy:		79.13 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.595531
  validation loss:		0.585835
  validation accuracy:		80.43 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.582238
  validation loss:		0.605873
  validation accuracy:		80.33 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.589396
  validation loss:		0.601847
  validation accuracy:		80.43 %
Epoch 1313 of 2000 took 0.100s
  training loss:		0.597560
  validation loss:		0.594013
  validation accuracy:		80.98 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.617012
  validation loss:		0.582685
  validation accuracy:		80.98 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.581813
  validation loss:		0.613031
  validation accuracy:		80.98 %
Epoch 1316 of 2000 took 0.102s
  training loss:		0.607972
  validation loss:		0.643943
  validation accuracy:		79.02 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.613336
  validation loss:		0.623735
  validation accuracy:		80.00 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.589997
  validation loss:		0.624537
  validation accuracy:		80.65 %
Epoch 1319 of 2000 took 0.096s
  training loss:		0.601169
  validation loss:		0.588962
  validation accuracy:		80.65 %
Epoch 1320 of 2000 took 0.098s
  training loss:		0.594804
  validation loss:		0.606559
  validation accuracy:		81.09 %
Epoch 1321 of 2000 took 0.100s
  training loss:		0.601453
  validation loss:		0.657575
  validation accuracy:		78.70 %
Epoch 1322 of 2000 took 0.096s
  training loss:		0.585058
  validation loss:		0.629552
  validation accuracy:		79.89 %
Epoch 1323 of 2000 took 0.098s
  training loss:		0.605743
  validation loss:		0.649433
  validation accuracy:		77.93 %
Epoch 1324 of 2000 took 0.101s
  training loss:		0.658022
  validation loss:		0.644116
  validation accuracy:		79.57 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.585660
  validation loss:		0.630071
  validation accuracy:		80.33 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.586400
  validation loss:		0.612188
  validation accuracy:		80.22 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.598395
  validation loss:		0.609224
  validation accuracy:		80.54 %
Epoch 1328 of 2000 took 0.101s
  training loss:		0.581493
  validation loss:		0.601783
  validation accuracy:		80.98 %
Epoch 1329 of 2000 took 0.098s
  training loss:		0.588498
  validation loss:		0.627984
  validation accuracy:		80.33 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.592835
  validation loss:		0.602597
  validation accuracy:		81.52 %
Epoch 1331 of 2000 took 0.101s
  training loss:		0.591824
  validation loss:		0.636431
  validation accuracy:		80.00 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.583094
  validation loss:		0.650391
  validation accuracy:		78.70 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.583420
  validation loss:		0.591249
  validation accuracy:		80.65 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.580725
  validation loss:		0.625283
  validation accuracy:		79.89 %
Epoch 1335 of 2000 took 0.097s
  training loss:		0.597321
  validation loss:		0.630208
  validation accuracy:		80.11 %
Epoch 1336 of 2000 took 0.100s
  training loss:		0.586447
  validation loss:		0.582867
  validation accuracy:		81.41 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.586691
  validation loss:		0.722962
  validation accuracy:		77.50 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.603197
  validation loss:		0.591410
  validation accuracy:		81.74 %
Epoch 1339 of 2000 took 0.102s
  training loss:		0.592700
  validation loss:		0.646291
  validation accuracy:		79.46 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.606106
  validation loss:		0.605205
  validation accuracy:		80.65 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.603320
  validation loss:		0.582398
  validation accuracy:		81.09 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.598135
  validation loss:		0.594390
  validation accuracy:		80.98 %
Epoch 1343 of 2000 took 0.098s
  training loss:		0.591232
  validation loss:		0.582447
  validation accuracy:		81.74 %
Epoch 1344 of 2000 took 0.100s
  training loss:		0.591081
  validation loss:		0.601148
  validation accuracy:		82.28 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.590279
  validation loss:		0.587982
  validation accuracy:		81.52 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.598429
  validation loss:		0.614523
  validation accuracy:		80.11 %
Epoch 1347 of 2000 took 0.102s
  training loss:		0.584260
  validation loss:		0.618177
  validation accuracy:		80.33 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.588923
  validation loss:		0.585913
  validation accuracy:		80.76 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.584505
  validation loss:		0.642659
  validation accuracy:		79.78 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.590705
  validation loss:		0.582575
  validation accuracy:		81.74 %
Epoch 1351 of 2000 took 0.101s
  training loss:		0.595067
  validation loss:		0.636875
  validation accuracy:		80.22 %
Epoch 1352 of 2000 took 0.098s
  training loss:		0.598594
  validation loss:		0.590700
  validation accuracy:		80.98 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.589797
  validation loss:		0.597263
  validation accuracy:		81.63 %
Epoch 1354 of 2000 took 0.101s
  training loss:		0.586258
  validation loss:		0.588353
  validation accuracy:		80.87 %
Epoch 1355 of 2000 took 0.098s
  training loss:		0.592863
  validation loss:		0.603109
  validation accuracy:		80.76 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.591278
  validation loss:		0.618939
  validation accuracy:		80.65 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.584643
  validation loss:		0.663804
  validation accuracy:		79.46 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.590787
  validation loss:		0.587496
  validation accuracy:		81.41 %
Epoch 1359 of 2000 took 0.101s
  training loss:		0.581073
  validation loss:		0.619405
  validation accuracy:		80.54 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.594884
  validation loss:		0.581423
  validation accuracy:		81.74 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.589952
  validation loss:		0.589539
  validation accuracy:		80.87 %
Epoch 1362 of 2000 took 0.102s
  training loss:		0.581096
  validation loss:		0.613969
  validation accuracy:		81.20 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.587192
  validation loss:		0.583940
  validation accuracy:		81.41 %
Epoch 1364 of 2000 took 0.097s
  training loss:		0.612706
  validation loss:		0.661489
  validation accuracy:		79.13 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.582605
  validation loss:		0.619347
  validation accuracy:		79.89 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.581763
  validation loss:		0.589441
  validation accuracy:		80.98 %
Epoch 1367 of 2000 took 0.101s
  training loss:		0.593825
  validation loss:		0.602096
  validation accuracy:		81.52 %
Epoch 1368 of 2000 took 0.096s
  training loss:		0.586969
  validation loss:		0.584339
  validation accuracy:		81.30 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.594434
  validation loss:		0.580638
  validation accuracy:		81.30 %
Epoch 1370 of 2000 took 0.102s
  training loss:		0.591199
  validation loss:		0.597396
  validation accuracy:		81.41 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.590864
  validation loss:		0.612888
  validation accuracy:		80.11 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.591804
  validation loss:		0.636606
  validation accuracy:		80.22 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.599557
  validation loss:		0.630705
  validation accuracy:		80.43 %
Epoch 1374 of 2000 took 0.100s
  training loss:		0.586294
  validation loss:		0.584319
  validation accuracy:		81.52 %
Epoch 1375 of 2000 took 0.098s
  training loss:		0.588792
  validation loss:		0.586975
  validation accuracy:		81.09 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.577235
  validation loss:		0.645822
  validation accuracy:		79.24 %
Epoch 1377 of 2000 took 0.100s
  training loss:		0.596613
  validation loss:		0.652446
  validation accuracy:		79.89 %
Epoch 1378 of 2000 took 0.099s
  training loss:		0.593250
  validation loss:		0.598425
  validation accuracy:		81.74 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.573500
  validation loss:		0.601751
  validation accuracy:		81.52 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.584235
  validation loss:		0.630676
  validation accuracy:		81.09 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.577352
  validation loss:		0.621151
  validation accuracy:		80.43 %
Epoch 1382 of 2000 took 0.101s
  training loss:		0.585148
  validation loss:		0.615126
  validation accuracy:		80.22 %
Epoch 1383 of 2000 took 0.097s
  training loss:		0.564372
  validation loss:		0.588037
  validation accuracy:		80.98 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.589019
  validation loss:		0.590890
  validation accuracy:		81.20 %
Epoch 1385 of 2000 took 0.102s
  training loss:		0.579359
  validation loss:		0.606013
  validation accuracy:		81.30 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.615555
  validation loss:		0.623223
  validation accuracy:		80.54 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.580134
  validation loss:		0.697411
  validation accuracy:		78.70 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.586604
  validation loss:		0.628154
  validation accuracy:		80.22 %
Epoch 1389 of 2000 took 0.098s
  training loss:		0.575629
  validation loss:		0.608883
  validation accuracy:		80.00 %
Epoch 1390 of 2000 took 0.100s
  training loss:		0.580238
  validation loss:		0.595136
  validation accuracy:		81.96 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.594153
  validation loss:		0.634806
  validation accuracy:		80.43 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.580249
  validation loss:		0.602030
  validation accuracy:		81.09 %
Epoch 1393 of 2000 took 0.102s
  training loss:		0.591613
  validation loss:		0.635261
  validation accuracy:		80.33 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.586993
  validation loss:		0.612260
  validation accuracy:		80.22 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.586076
  validation loss:		0.599452
  validation accuracy:		81.20 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.584465
  validation loss:		0.638879
  validation accuracy:		80.43 %
Epoch 1397 of 2000 took 0.099s
  training loss:		0.594740
  validation loss:		0.585795
  validation accuracy:		81.74 %
Epoch 1398 of 2000 took 0.098s
  training loss:		0.592618
  validation loss:		0.597397
  validation accuracy:		80.98 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.582086
  validation loss:		0.635579
  validation accuracy:		80.54 %
Epoch 1400 of 2000 took 0.099s
  training loss:		0.580152
  validation loss:		0.647573
  validation accuracy:		80.11 %
Epoch 1401 of 2000 took 0.099s
  training loss:		0.586488
  validation loss:		0.588958
  validation accuracy:		81.52 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.579940
  validation loss:		0.624327
  validation accuracy:		81.30 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.575065
  validation loss:		0.587386
  validation accuracy:		82.07 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.591421
  validation loss:		0.583127
  validation accuracy:		81.96 %
Epoch 1405 of 2000 took 0.101s
  training loss:		0.627558
  validation loss:		0.674285
  validation accuracy:		79.46 %
Epoch 1406 of 2000 took 0.097s
  training loss:		0.578572
  validation loss:		0.630391
  validation accuracy:		81.52 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.582299
  validation loss:		0.629969
  validation accuracy:		80.43 %
Epoch 1408 of 2000 took 0.102s
  training loss:		0.581636
  validation loss:		0.599880
  validation accuracy:		80.65 %
Epoch 1409 of 2000 took 0.097s
  training loss:		0.597484
  validation loss:		0.592116
  validation accuracy:		81.20 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.593938
  validation loss:		0.589246
  validation accuracy:		82.17 %
Epoch 1411 of 2000 took 0.097s
  training loss:		0.587785
  validation loss:		0.589449
  validation accuracy:		81.20 %
Epoch 1412 of 2000 took 0.097s
  training loss:		0.586288
  validation loss:		0.609323
  validation accuracy:		81.30 %
Epoch 1413 of 2000 took 0.100s
  training loss:		0.580971
  validation loss:		0.606915
  validation accuracy:		82.28 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.586091
  validation loss:		0.589174
  validation accuracy:		82.07 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.593090
  validation loss:		0.594708
  validation accuracy:		80.76 %
Epoch 1416 of 2000 took 0.102s
  training loss:		0.578799
  validation loss:		0.638070
  validation accuracy:		80.11 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.600537
  validation loss:		0.739967
  validation accuracy:		77.72 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.590592
  validation loss:		0.624706
  validation accuracy:		81.63 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.575762
  validation loss:		0.605053
  validation accuracy:		80.98 %
Epoch 1420 of 2000 took 0.098s
  training loss:		0.583735
  validation loss:		0.591215
  validation accuracy:		80.76 %
Epoch 1421 of 2000 took 0.099s
  training loss:		0.577284
  validation loss:		0.598514
  validation accuracy:		81.74 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.609283
  validation loss:		0.594114
  validation accuracy:		81.20 %
Epoch 1423 of 2000 took 0.098s
  training loss:		0.572863
  validation loss:		0.616771
  validation accuracy:		80.87 %
Epoch 1424 of 2000 took 0.100s
  training loss:		0.593694
  validation loss:		0.590584
  validation accuracy:		81.09 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.576249
  validation loss:		0.638261
  validation accuracy:		80.43 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.584587
  validation loss:		0.587535
  validation accuracy:		81.52 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.594814
  validation loss:		0.634542
  validation accuracy:		80.54 %
Epoch 1428 of 2000 took 0.101s
  training loss:		0.587503
  validation loss:		0.592136
  validation accuracy:		81.20 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.586937
  validation loss:		0.585990
  validation accuracy:		81.85 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.577420
  validation loss:		0.603509
  validation accuracy:		80.98 %
Epoch 1431 of 2000 took 0.102s
  training loss:		0.590225
  validation loss:		0.592014
  validation accuracy:		80.76 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.582270
  validation loss:		0.587222
  validation accuracy:		82.17 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.579771
  validation loss:		0.605426
  validation accuracy:		80.87 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.588350
  validation loss:		0.601991
  validation accuracy:		81.74 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.578679
  validation loss:		0.593541
  validation accuracy:		82.07 %
Epoch 1436 of 2000 took 0.100s
  training loss:		0.585391
  validation loss:		0.600409
  validation accuracy:		81.63 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.589885
  validation loss:		0.605522
  validation accuracy:		81.85 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.572185
  validation loss:		0.597467
  validation accuracy:		81.63 %
Epoch 1439 of 2000 took 0.102s
  training loss:		0.575471
  validation loss:		0.605367
  validation accuracy:		81.09 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.586154
  validation loss:		0.596778
  validation accuracy:		81.74 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.592198
  validation loss:		0.610637
  validation accuracy:		80.87 %
Epoch 1442 of 2000 took 0.096s
  training loss:		0.591742
  validation loss:		0.591924
  validation accuracy:		82.07 %
Epoch 1443 of 2000 took 0.099s
  training loss:		0.600145
  validation loss:		0.630805
  validation accuracy:		80.76 %
Epoch 1444 of 2000 took 0.099s
  training loss:		0.574445
  validation loss:		0.626415
  validation accuracy:		81.20 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.572497
  validation loss:		0.606640
  validation accuracy:		81.85 %
Epoch 1446 of 2000 took 0.098s
  training loss:		0.580813
  validation loss:		0.603118
  validation accuracy:		82.17 %
Epoch 1447 of 2000 took 0.100s
  training loss:		0.590268
  validation loss:		0.586872
  validation accuracy:		81.96 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.577009
  validation loss:		0.624939
  validation accuracy:		81.20 %
Epoch 1449 of 2000 took 0.097s
  training loss:		0.583627
  validation loss:		0.619419
  validation accuracy:		80.00 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.574990
  validation loss:		0.592677
  validation accuracy:		82.17 %
Epoch 1451 of 2000 took 0.101s
  training loss:		0.570569
  validation loss:		0.589401
  validation accuracy:		82.17 %
Epoch 1452 of 2000 took 0.098s
  training loss:		0.589450
  validation loss:		0.620276
  validation accuracy:		80.76 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.578724
  validation loss:		0.605640
  validation accuracy:		81.20 %
Epoch 1454 of 2000 took 0.101s
  training loss:		0.592088
  validation loss:		0.633754
  validation accuracy:		80.98 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.576899
  validation loss:		0.639251
  validation accuracy:		80.22 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.585043
  validation loss:		0.632847
  validation accuracy:		81.41 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.589837
  validation loss:		0.616187
  validation accuracy:		81.52 %
Epoch 1458 of 2000 took 0.097s
  training loss:		0.592038
  validation loss:		0.617532
  validation accuracy:		81.52 %
Epoch 1459 of 2000 took 0.100s
  training loss:		0.586228
  validation loss:		0.604937
  validation accuracy:		82.39 %
Epoch 1460 of 2000 took 0.097s
  training loss:		0.584134
  validation loss:		0.594234
  validation accuracy:		81.41 %
Epoch 1461 of 2000 took 0.097s
  training loss:		0.573078
  validation loss:		0.633024
  validation accuracy:		80.87 %
Epoch 1462 of 2000 took 0.102s
  training loss:		0.579228
  validation loss:		0.616198
  validation accuracy:		81.52 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.586164
  validation loss:		0.623960
  validation accuracy:		81.20 %
Epoch 1464 of 2000 took 0.097s
  training loss:		0.582679
  validation loss:		0.696109
  validation accuracy:		78.91 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.595271
  validation loss:		0.589291
  validation accuracy:		81.85 %
Epoch 1466 of 2000 took 0.098s
  training loss:		0.582036
  validation loss:		0.588112
  validation accuracy:		81.63 %
Epoch 1467 of 2000 took 0.100s
  training loss:		0.576299
  validation loss:		0.600535
  validation accuracy:		81.41 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.583992
  validation loss:		0.621521
  validation accuracy:		81.41 %
Epoch 1469 of 2000 took 0.098s
  training loss:		0.584959
  validation loss:		0.597066
  validation accuracy:		82.39 %
Epoch 1470 of 2000 took 0.101s
  training loss:		0.578356
  validation loss:		0.645746
  validation accuracy:		79.78 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.585192
  validation loss:		0.645759
  validation accuracy:		79.89 %
Epoch 1472 of 2000 took 0.097s
  training loss:		0.574767
  validation loss:		0.633375
  validation accuracy:		80.33 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.592343
  validation loss:		0.592568
  validation accuracy:		81.74 %
Epoch 1474 of 2000 took 0.101s
  training loss:		0.572010
  validation loss:		0.591836
  validation accuracy:		81.30 %
Epoch 1475 of 2000 took 0.098s
  training loss:		0.581480
  validation loss:		0.710780
  validation accuracy:		78.37 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.583783
  validation loss:		0.596628
  validation accuracy:		81.30 %
Epoch 1477 of 2000 took 0.101s
  training loss:		0.586746
  validation loss:		0.620993
  validation accuracy:		81.52 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.583577
  validation loss:		0.600066
  validation accuracy:		80.98 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.595496
  validation loss:		0.625631
  validation accuracy:		80.43 %
Epoch 1480 of 2000 took 0.097s
  training loss:		0.589474
  validation loss:		0.615125
  validation accuracy:		81.30 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.583177
  validation loss:		0.595124
  validation accuracy:		82.28 %
Epoch 1482 of 2000 took 0.100s
  training loss:		0.587304
  validation loss:		0.608406
  validation accuracy:		82.50 %
Epoch 1483 of 2000 took 0.097s
  training loss:		0.581188
  validation loss:		0.607431
  validation accuracy:		81.30 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.584784
  validation loss:		0.587764
  validation accuracy:		82.07 %
Epoch 1485 of 2000 took 0.103s
  training loss:		0.576736
  validation loss:		0.625558
  validation accuracy:		80.33 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.582266
  validation loss:		0.589606
  validation accuracy:		82.07 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.588345
  validation loss:		0.615771
  validation accuracy:		81.52 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.578223
  validation loss:		0.591703
  validation accuracy:		82.39 %
Epoch 1489 of 2000 took 0.098s
  training loss:		0.607526
  validation loss:		0.589543
  validation accuracy:		81.85 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.583074
  validation loss:		0.586475
  validation accuracy:		81.41 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.573495
  validation loss:		0.614945
  validation accuracy:		81.52 %
Epoch 1492 of 2000 took 0.097s
  training loss:		0.582457
  validation loss:		0.600336
  validation accuracy:		81.74 %
Epoch 1493 of 2000 took 0.102s
  training loss:		0.579812
  validation loss:		0.617446
  validation accuracy:		81.20 %
Epoch 1494 of 2000 took 0.098s
  training loss:		0.580746
  validation loss:		0.673651
  validation accuracy:		78.91 %
Epoch 1495 of 2000 took 0.100s
  training loss:		0.580162
  validation loss:		0.652989
  validation accuracy:		80.11 %
Epoch 1496 of 2000 took 0.099s
  training loss:		0.587364
  validation loss:		0.626964
  validation accuracy:		81.41 %
Epoch 1497 of 2000 took 0.104s
  training loss:		0.579901
  validation loss:		0.589076
  validation accuracy:		81.41 %
Epoch 1498 of 2000 took 0.101s
  training loss:		0.588449
  validation loss:		0.612216
  validation accuracy:		80.43 %
Epoch 1499 of 2000 took 0.099s
  training loss:		0.575103
  validation loss:		0.620222
  validation accuracy:		81.20 %
Epoch 1500 of 2000 took 0.104s
  training loss:		0.597561
  validation loss:		0.590088
  validation accuracy:		80.98 %
Epoch 1501 of 2000 took 0.100s
  training loss:		0.586467
  validation loss:		0.655130
  validation accuracy:		79.67 %
Epoch 1502 of 2000 took 0.100s
  training loss:		0.588665
  validation loss:		0.610770
  validation accuracy:		81.74 %
Epoch 1503 of 2000 took 0.100s
  training loss:		0.603831
  validation loss:		0.661882
  validation accuracy:		79.78 %
Epoch 1504 of 2000 took 0.100s
  training loss:		0.598293
  validation loss:		0.606016
  validation accuracy:		80.98 %
Epoch 1505 of 2000 took 0.103s
  training loss:		0.584045
  validation loss:		0.652182
  validation accuracy:		80.11 %
Epoch 1506 of 2000 took 0.100s
  training loss:		0.584538
  validation loss:		0.635189
  validation accuracy:		80.22 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.579512
  validation loss:		0.602303
  validation accuracy:		81.85 %
Epoch 1508 of 2000 took 0.105s
  training loss:		0.583235
  validation loss:		0.587813
  validation accuracy:		81.85 %
Epoch 1509 of 2000 took 0.099s
  training loss:		0.580896
  validation loss:		0.588065
  validation accuracy:		81.63 %
Epoch 1510 of 2000 took 0.100s
  training loss:		0.576364
  validation loss:		0.600345
  validation accuracy:		82.72 %
Epoch 1511 of 2000 took 0.100s
  training loss:		0.584484
  validation loss:		0.593062
  validation accuracy:		82.07 %
Epoch 1512 of 2000 took 0.103s
  training loss:		0.582433
  validation loss:		0.589951
  validation accuracy:		81.09 %
Epoch 1513 of 2000 took 0.103s
  training loss:		0.585549
  validation loss:		0.604251
  validation accuracy:		81.41 %
Epoch 1514 of 2000 took 0.099s
  training loss:		0.574116
  validation loss:		0.614962
  validation accuracy:		80.98 %
Epoch 1515 of 2000 took 0.100s
  training loss:		0.568850
  validation loss:		0.628625
  validation accuracy:		79.46 %
Epoch 1516 of 2000 took 0.104s
  training loss:		0.581499
  validation loss:		0.613820
  validation accuracy:		81.74 %
Epoch 1517 of 2000 took 0.099s
  training loss:		0.580840
  validation loss:		0.666032
  validation accuracy:		80.22 %
Epoch 1518 of 2000 took 0.100s
  training loss:		0.587488
  validation loss:		0.620164
  validation accuracy:		80.76 %
Epoch 1519 of 2000 took 0.099s
  training loss:		0.572738
  validation loss:		0.602814
  validation accuracy:		82.50 %
Epoch 1520 of 2000 took 0.104s
  training loss:		0.577988
  validation loss:		0.648121
  validation accuracy:		80.22 %
Epoch 1521 of 2000 took 0.101s
  training loss:		0.577444
  validation loss:		0.593348
  validation accuracy:		82.28 %
Epoch 1522 of 2000 took 0.099s
  training loss:		0.568496
  validation loss:		0.612238
  validation accuracy:		81.85 %
Epoch 1523 of 2000 took 0.104s
  training loss:		0.575681
  validation loss:		0.596693
  validation accuracy:		81.41 %
Epoch 1524 of 2000 took 0.101s
  training loss:		0.596459
  validation loss:		0.592267
  validation accuracy:		82.07 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.585062
  validation loss:		0.594492
  validation accuracy:		81.63 %
Epoch 1526 of 2000 took 0.100s
  training loss:		0.565502
  validation loss:		0.596548
  validation accuracy:		81.63 %
Epoch 1527 of 2000 took 0.100s
  training loss:		0.579216
  validation loss:		0.604368
  validation accuracy:		80.98 %
Epoch 1528 of 2000 took 0.103s
  training loss:		0.577038
  validation loss:		0.682260
  validation accuracy:		78.80 %
Epoch 1529 of 2000 took 0.100s
  training loss:		0.576455
  validation loss:		0.638046
  validation accuracy:		80.98 %
Epoch 1530 of 2000 took 0.100s
  training loss:		0.584855
  validation loss:		0.599170
  validation accuracy:		81.63 %
Epoch 1531 of 2000 took 0.106s
  training loss:		0.569977
  validation loss:		0.626329
  validation accuracy:		81.09 %
Epoch 1532 of 2000 took 0.099s
  training loss:		0.577894
  validation loss:		0.694545
  validation accuracy:		78.70 %
Epoch 1533 of 2000 took 0.100s
  training loss:		0.588646
  validation loss:		0.620698
  validation accuracy:		81.41 %
Epoch 1534 of 2000 took 0.099s
  training loss:		0.586234
  validation loss:		0.589458
  validation accuracy:		81.30 %
Epoch 1535 of 2000 took 0.101s
  training loss:		0.582580
  validation loss:		0.630410
  validation accuracy:		79.89 %
Epoch 1536 of 2000 took 0.103s
  training loss:		0.587975
  validation loss:		0.623878
  validation accuracy:		81.20 %
Epoch 1537 of 2000 took 0.099s
  training loss:		0.576581
  validation loss:		0.636357
  validation accuracy:		80.76 %
Epoch 1538 of 2000 took 0.101s
  training loss:		0.579892
  validation loss:		0.601521
  validation accuracy:		81.41 %
Epoch 1539 of 2000 took 0.104s
  training loss:		0.585076
  validation loss:		0.609325
  validation accuracy:		81.41 %
Epoch 1540 of 2000 took 0.099s
  training loss:		0.572743
  validation loss:		0.586409
  validation accuracy:		81.63 %
Epoch 1541 of 2000 took 0.100s
  training loss:		0.587794
  validation loss:		0.620967
  validation accuracy:		80.87 %
Epoch 1542 of 2000 took 0.099s
  training loss:		0.578590
  validation loss:		0.616017
  validation accuracy:		81.20 %
Epoch 1543 of 2000 took 0.104s
  training loss:		0.582100
  validation loss:		0.617363
  validation accuracy:		81.63 %
Epoch 1544 of 2000 took 0.101s
  training loss:		0.575318
  validation loss:		0.623431
  validation accuracy:		81.85 %
Epoch 1545 of 2000 took 0.099s
  training loss:		0.579985
  validation loss:		0.617531
  validation accuracy:		80.87 %
Epoch 1546 of 2000 took 0.105s
  training loss:		0.587049
  validation loss:		0.600807
  validation accuracy:		81.74 %
Epoch 1547 of 2000 took 0.100s
  training loss:		0.565508
  validation loss:		0.598427
  validation accuracy:		82.07 %
Epoch 1548 of 2000 took 0.100s
  training loss:		0.575812
  validation loss:		0.633009
  validation accuracy:		79.89 %
Epoch 1549 of 2000 took 0.099s
  training loss:		0.590080
  validation loss:		0.598679
  validation accuracy:		82.07 %
Epoch 1550 of 2000 took 0.100s
  training loss:		0.587359
  validation loss:		0.623162
  validation accuracy:		81.96 %
Epoch 1551 of 2000 took 0.103s
  training loss:		0.580310
  validation loss:		0.602783
  validation accuracy:		81.74 %
Epoch 1552 of 2000 took 0.100s
  training loss:		0.579633
  validation loss:		0.590513
  validation accuracy:		81.41 %
Epoch 1553 of 2000 took 0.100s
  training loss:		0.577843
  validation loss:		0.604938
  validation accuracy:		81.09 %
Epoch 1554 of 2000 took 0.105s
  training loss:		0.581176
  validation loss:		0.589034
  validation accuracy:		81.85 %
Epoch 1555 of 2000 took 0.099s
  training loss:		0.575439
  validation loss:		0.596625
  validation accuracy:		82.17 %
Epoch 1556 of 2000 took 0.100s
  training loss:		0.587608
  validation loss:		0.607888
  validation accuracy:		81.30 %
Epoch 1557 of 2000 took 0.099s
  training loss:		0.583721
  validation loss:		0.609238
  validation accuracy:		81.52 %
Epoch 1558 of 2000 took 0.102s
  training loss:		0.585309
  validation loss:		0.590818
  validation accuracy:		81.63 %
Epoch 1559 of 2000 took 0.102s
  training loss:		0.602943
  validation loss:		0.626147
  validation accuracy:		80.87 %
Epoch 1560 of 2000 took 0.099s
  training loss:		0.572842
  validation loss:		0.599568
  validation accuracy:		82.07 %
Epoch 1561 of 2000 took 0.101s
  training loss:		0.576089
  validation loss:		0.629567
  validation accuracy:		80.22 %
Epoch 1562 of 2000 took 0.103s
  training loss:		0.577985
  validation loss:		0.600830
  validation accuracy:		81.20 %
Epoch 1563 of 2000 took 0.100s
  training loss:		0.577588
  validation loss:		0.604625
  validation accuracy:		82.28 %
Epoch 1564 of 2000 took 0.100s
  training loss:		0.604439
  validation loss:		0.584266
  validation accuracy:		81.41 %
Epoch 1565 of 2000 took 0.099s
  training loss:		0.586147
  validation loss:		0.640845
  validation accuracy:		80.98 %
Epoch 1566 of 2000 took 0.104s
  training loss:		0.578929
  validation loss:		0.631158
  validation accuracy:		81.52 %
Epoch 1567 of 2000 took 0.101s
  training loss:		0.579644
  validation loss:		0.589263
  validation accuracy:		81.74 %
Epoch 1568 of 2000 took 0.099s
  training loss:		0.582428
  validation loss:		0.589881
  validation accuracy:		82.17 %
Epoch 1569 of 2000 took 0.107s
  training loss:		0.575600
  validation loss:		0.629845
  validation accuracy:		80.76 %
Epoch 1570 of 2000 took 0.099s
  training loss:		0.590274
  validation loss:		0.593353
  validation accuracy:		81.20 %
Epoch 1571 of 2000 took 0.099s
  training loss:		0.584341
  validation loss:		0.608984
  validation accuracy:		81.85 %
Epoch 1572 of 2000 took 0.098s
  training loss:		0.574012
  validation loss:		0.625290
  validation accuracy:		81.30 %
Epoch 1573 of 2000 took 0.099s
  training loss:		0.572041
  validation loss:		0.597872
  validation accuracy:		82.28 %
Epoch 1574 of 2000 took 0.100s
  training loss:		0.582473
  validation loss:		0.605725
  validation accuracy:		81.41 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.574573
  validation loss:		0.584508
  validation accuracy:		81.85 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.596907
  validation loss:		0.602711
  validation accuracy:		81.74 %
Epoch 1577 of 2000 took 0.102s
  training loss:		0.567425
  validation loss:		0.593800
  validation accuracy:		81.74 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.594017
  validation loss:		0.595135
  validation accuracy:		82.07 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.577579
  validation loss:		0.608091
  validation accuracy:		82.07 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.570840
  validation loss:		0.629673
  validation accuracy:		80.76 %
Epoch 1581 of 2000 took 0.098s
  training loss:		0.578539
  validation loss:		0.610008
  validation accuracy:		80.98 %
Epoch 1582 of 2000 took 0.100s
  training loss:		0.572786
  validation loss:		0.614525
  validation accuracy:		81.20 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.586369
  validation loss:		0.641181
  validation accuracy:		81.20 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.574001
  validation loss:		0.613689
  validation accuracy:		82.17 %
Epoch 1585 of 2000 took 0.101s
  training loss:		0.596409
  validation loss:		0.611591
  validation accuracy:		81.85 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.570909
  validation loss:		0.588629
  validation accuracy:		81.41 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.582335
  validation loss:		0.630958
  validation accuracy:		79.89 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.578596
  validation loss:		0.593181
  validation accuracy:		82.07 %
Epoch 1589 of 2000 took 0.100s
  training loss:		0.576364
  validation loss:		0.594980
  validation accuracy:		81.85 %
Epoch 1590 of 2000 took 0.098s
  training loss:		0.583004
  validation loss:		0.594537
  validation accuracy:		81.96 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.576023
  validation loss:		0.609706
  validation accuracy:		81.74 %
Epoch 1592 of 2000 took 0.100s
  training loss:		0.569404
  validation loss:		0.590911
  validation accuracy:		81.52 %
Epoch 1593 of 2000 took 0.098s
  training loss:		0.577912
  validation loss:		0.637310
  validation accuracy:		80.98 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.580277
  validation loss:		0.602555
  validation accuracy:		81.20 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.583266
  validation loss:		0.612563
  validation accuracy:		81.96 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.574898
  validation loss:		0.593144
  validation accuracy:		82.17 %
Epoch 1597 of 2000 took 0.100s
  training loss:		0.572159
  validation loss:		0.620217
  validation accuracy:		80.54 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.579212
  validation loss:		0.607260
  validation accuracy:		80.98 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.574203
  validation loss:		0.606615
  validation accuracy:		82.28 %
Epoch 1600 of 2000 took 0.102s
  training loss:		0.578048
  validation loss:		0.602569
  validation accuracy:		81.85 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.583993
  validation loss:		0.624971
  validation accuracy:		81.20 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.583455
  validation loss:		0.611545
  validation accuracy:		81.09 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.580939
  validation loss:		0.606415
  validation accuracy:		81.63 %
Epoch 1604 of 2000 took 0.098s
  training loss:		0.581775
  validation loss:		0.613630
  validation accuracy:		82.28 %
Epoch 1605 of 2000 took 0.100s
  training loss:		0.578190
  validation loss:		0.602773
  validation accuracy:		81.30 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.588098
  validation loss:		0.640395
  validation accuracy:		80.54 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.579821
  validation loss:		0.595641
  validation accuracy:		82.07 %
Epoch 1608 of 2000 took 0.099s
  training loss:		0.591472
  validation loss:		0.631705
  validation accuracy:		80.98 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.580737
  validation loss:		0.654723
  validation accuracy:		80.11 %
Epoch 1610 of 2000 took 0.100s
  training loss:		0.571142
  validation loss:		0.630276
  validation accuracy:		80.54 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.577708
  validation loss:		0.604445
  validation accuracy:		81.85 %
Epoch 1612 of 2000 took 0.098s
  training loss:		0.574843
  validation loss:		0.614800
  validation accuracy:		81.96 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.587516
  validation loss:		0.617898
  validation accuracy:		80.98 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.582163
  validation loss:		0.671587
  validation accuracy:		79.67 %
Epoch 1615 of 2000 took 0.099s
  training loss:		0.590636
  validation loss:		0.625829
  validation accuracy:		81.30 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.584538
  validation loss:		0.595494
  validation accuracy:		82.07 %
Epoch 1617 of 2000 took 0.100s
  training loss:		0.579223
  validation loss:		0.594829
  validation accuracy:		81.85 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.587636
  validation loss:		0.592303
  validation accuracy:		81.74 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.585431
  validation loss:		0.615650
  validation accuracy:		81.96 %
Epoch 1620 of 2000 took 0.099s
  training loss:		0.575520
  validation loss:		0.593507
  validation accuracy:		82.17 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.578639
  validation loss:		0.626680
  validation accuracy:		80.87 %
Epoch 1622 of 2000 took 0.100s
  training loss:		0.580185
  validation loss:		0.621866
  validation accuracy:		81.09 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.585218
  validation loss:		0.598528
  validation accuracy:		81.85 %
Epoch 1624 of 2000 took 0.098s
  training loss:		0.583577
  validation loss:		0.619628
  validation accuracy:		81.74 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.590351
  validation loss:		0.616068
  validation accuracy:		81.85 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.576840
  validation loss:		0.595202
  validation accuracy:		82.07 %
Epoch 1627 of 2000 took 0.099s
  training loss:		0.591945
  validation loss:		0.637272
  validation accuracy:		81.20 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.580284
  validation loss:		0.650866
  validation accuracy:		80.65 %
Epoch 1629 of 2000 took 0.100s
  training loss:		0.578397
  validation loss:		0.604540
  validation accuracy:		82.50 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.582420
  validation loss:		0.587636
  validation accuracy:		81.30 %
Epoch 1631 of 2000 took 0.097s
  training loss:		0.578762
  validation loss:		0.591450
  validation accuracy:		81.74 %
Epoch 1632 of 2000 took 0.098s
  training loss:		0.574158
  validation loss:		0.627866
  validation accuracy:		80.98 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.580694
  validation loss:		0.627233
  validation accuracy:		81.52 %
Epoch 1634 of 2000 took 0.102s
  training loss:		0.582982
  validation loss:		0.591868
  validation accuracy:		81.74 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.589914
  validation loss:		0.694351
  validation accuracy:		79.35 %
Epoch 1636 of 2000 took 0.097s
  training loss:		0.599149
  validation loss:		0.602280
  validation accuracy:		82.39 %
Epoch 1637 of 2000 took 0.096s
  training loss:		0.581182
  validation loss:		0.619835
  validation accuracy:		82.07 %
Epoch 1638 of 2000 took 0.097s
  training loss:		0.582878
  validation loss:		0.595475
  validation accuracy:		81.85 %
Epoch 1639 of 2000 took 0.101s
  training loss:		0.568873
  validation loss:		0.598391
  validation accuracy:		82.28 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.581703
  validation loss:		0.603135
  validation accuracy:		81.63 %
Epoch 1641 of 2000 took 0.097s
  training loss:		0.587135
  validation loss:		0.585860
  validation accuracy:		81.96 %
Epoch 1642 of 2000 took 0.102s
  training loss:		0.581750
  validation loss:		0.595536
  validation accuracy:		82.07 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.580781
  validation loss:		0.606972
  validation accuracy:		82.50 %
Epoch 1644 of 2000 took 0.097s
  training loss:		0.570691
  validation loss:		0.662085
  validation accuracy:		80.00 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.580222
  validation loss:		0.679188
  validation accuracy:		79.13 %
Epoch 1646 of 2000 took 0.099s
  training loss:		0.579313
  validation loss:		0.614159
  validation accuracy:		81.85 %
Epoch 1647 of 2000 took 0.098s
  training loss:		0.581159
  validation loss:		0.599669
  validation accuracy:		81.63 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.576795
  validation loss:		0.632049
  validation accuracy:		81.30 %
Epoch 1649 of 2000 took 0.099s
  training loss:		0.580585
  validation loss:		0.620328
  validation accuracy:		81.74 %
Epoch 1650 of 2000 took 0.099s
  training loss:		0.575541
  validation loss:		0.606910
  validation accuracy:		81.30 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.579302
  validation loss:		0.589287
  validation accuracy:		81.74 %
Epoch 1652 of 2000 took 0.097s
  training loss:		0.573436
  validation loss:		0.610529
  validation accuracy:		81.52 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.585125
  validation loss:		0.635051
  validation accuracy:		81.85 %
Epoch 1654 of 2000 took 0.101s
  training loss:		0.582951
  validation loss:		0.603388
  validation accuracy:		81.74 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.575842
  validation loss:		0.594281
  validation accuracy:		82.17 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.578647
  validation loss:		0.637249
  validation accuracy:		81.09 %
Epoch 1657 of 2000 took 0.102s
  training loss:		0.583148
  validation loss:		0.610489
  validation accuracy:		81.85 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.577642
  validation loss:		0.593077
  validation accuracy:		81.74 %
Epoch 1659 of 2000 took 0.097s
  training loss:		0.586934
  validation loss:		0.607561
  validation accuracy:		81.96 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.576670
  validation loss:		0.602843
  validation accuracy:		81.96 %
Epoch 1661 of 2000 took 0.097s
  training loss:		0.583320
  validation loss:		0.602298
  validation accuracy:		82.61 %
Epoch 1662 of 2000 took 0.100s
  training loss:		0.569507
  validation loss:		0.620778
  validation accuracy:		81.09 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.572558
  validation loss:		0.621182
  validation accuracy:		81.74 %
Epoch 1664 of 2000 took 0.097s
  training loss:		0.570991
  validation loss:		0.612981
  validation accuracy:		81.96 %
Epoch 1665 of 2000 took 0.102s
  training loss:		0.570960
  validation loss:		0.614027
  validation accuracy:		81.20 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.579622
  validation loss:		0.601814
  validation accuracy:		81.41 %
Epoch 1667 of 2000 took 0.097s
  training loss:		0.588702
  validation loss:		0.594796
  validation accuracy:		82.07 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.582135
  validation loss:		0.614537
  validation accuracy:		81.52 %
Epoch 1669 of 2000 took 0.099s
  training loss:		0.583982
  validation loss:		0.599020
  validation accuracy:		82.61 %
Epoch 1670 of 2000 took 0.099s
  training loss:		0.580732
  validation loss:		0.593433
  validation accuracy:		81.52 %
Epoch 1671 of 2000 took 0.098s
  training loss:		0.591500
  validation loss:		0.589702
  validation accuracy:		81.41 %
Epoch 1672 of 2000 took 0.098s
  training loss:		0.588189
  validation loss:		0.630361
  validation accuracy:		80.98 %
Epoch 1673 of 2000 took 0.099s
  training loss:		0.572366
  validation loss:		0.594790
  validation accuracy:		82.28 %
Epoch 1674 of 2000 took 0.095s
  training loss:		0.565667
  validation loss:		0.621164
  validation accuracy:		81.30 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.571914
  validation loss:		0.621984
  validation accuracy:		81.09 %
Epoch 1676 of 2000 took 0.095s
  training loss:		0.578065
  validation loss:		0.593323
  validation accuracy:		82.28 %
Epoch 1677 of 2000 took 0.100s
  training loss:		0.575894
  validation loss:		0.587206
  validation accuracy:		81.96 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.582541
  validation loss:		0.591381
  validation accuracy:		81.85 %
Epoch 1679 of 2000 took 0.095s
  training loss:		0.582163
  validation loss:		0.605552
  validation accuracy:		81.96 %
Epoch 1680 of 2000 took 0.100s
  training loss:		0.579140
  validation loss:		0.596209
  validation accuracy:		82.17 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.589529
  validation loss:		0.631173
  validation accuracy:		80.65 %
Epoch 1682 of 2000 took 0.095s
  training loss:		0.578738
  validation loss:		0.649978
  validation accuracy:		80.54 %
Epoch 1683 of 2000 took 0.095s
  training loss:		0.579370
  validation loss:		0.621496
  validation accuracy:		81.20 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.575847
  validation loss:		0.613919
  validation accuracy:		81.09 %
Epoch 1685 of 2000 took 0.099s
  training loss:		0.573612
  validation loss:		0.657227
  validation accuracy:		80.43 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.589916
  validation loss:		0.624779
  validation accuracy:		81.09 %
Epoch 1687 of 2000 took 0.095s
  training loss:		0.577209
  validation loss:		0.591997
  validation accuracy:		81.74 %
Epoch 1688 of 2000 took 0.101s
  training loss:		0.581425
  validation loss:		0.595880
  validation accuracy:		81.96 %
Epoch 1689 of 2000 took 0.095s
  training loss:		0.584829
  validation loss:		0.602566
  validation accuracy:		81.74 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.581034
  validation loss:		0.661587
  validation accuracy:		80.11 %
Epoch 1691 of 2000 took 0.095s
  training loss:		0.585478
  validation loss:		0.640465
  validation accuracy:		80.76 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.570339
  validation loss:		0.603556
  validation accuracy:		81.63 %
Epoch 1693 of 2000 took 0.099s
  training loss:		0.579250
  validation loss:		0.605047
  validation accuracy:		81.63 %
Epoch 1694 of 2000 took 0.095s
  training loss:		0.588832
  validation loss:		0.614619
  validation accuracy:		82.17 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.585042
  validation loss:		0.593220
  validation accuracy:		82.07 %
Epoch 1696 of 2000 took 0.102s
  training loss:		0.588409
  validation loss:		0.599051
  validation accuracy:		82.39 %
Epoch 1697 of 2000 took 0.096s
  training loss:		0.580658
  validation loss:		0.626445
  validation accuracy:		79.67 %
Epoch 1698 of 2000 took 0.097s
  training loss:		0.591280
  validation loss:		0.616541
  validation accuracy:		81.09 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.579358
  validation loss:		0.611440
  validation accuracy:		82.39 %
Epoch 1700 of 2000 took 0.099s
  training loss:		0.576469
  validation loss:		0.595075
  validation accuracy:		81.74 %
Epoch 1701 of 2000 took 0.099s
  training loss:		0.574098
  validation loss:		0.612874
  validation accuracy:		82.17 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.600253
  validation loss:		0.685413
  validation accuracy:		79.57 %
Epoch 1703 of 2000 took 0.099s
  training loss:		0.578243
  validation loss:		0.607866
  validation accuracy:		81.30 %
Epoch 1704 of 2000 took 0.100s
  training loss:		0.587652
  validation loss:		0.600406
  validation accuracy:		81.85 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.570655
  validation loss:		0.653049
  validation accuracy:		80.11 %
Epoch 1706 of 2000 took 0.097s
  training loss:		0.579883
  validation loss:		0.594943
  validation accuracy:		82.50 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.578325
  validation loss:		0.639279
  validation accuracy:		81.30 %
Epoch 1708 of 2000 took 0.101s
  training loss:		0.568394
  validation loss:		0.591159
  validation accuracy:		81.52 %
Epoch 1709 of 2000 took 0.097s
  training loss:		0.581492
  validation loss:		0.598186
  validation accuracy:		82.39 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.569893
  validation loss:		0.599707
  validation accuracy:		82.50 %
Epoch 1711 of 2000 took 0.102s
  training loss:		0.583550
  validation loss:		0.592287
  validation accuracy:		81.96 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.581453
  validation loss:		0.631632
  validation accuracy:		81.41 %
Epoch 1713 of 2000 took 0.097s
  training loss:		0.567143
  validation loss:		0.654292
  validation accuracy:		79.89 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.590251
  validation loss:		0.628559
  validation accuracy:		81.52 %
Epoch 1715 of 2000 took 0.097s
  training loss:		0.581447
  validation loss:		0.643907
  validation accuracy:		80.87 %
Epoch 1716 of 2000 took 0.100s
  training loss:		0.579297
  validation loss:		0.628198
  validation accuracy:		80.65 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.570729
  validation loss:		0.608975
  validation accuracy:		81.85 %
Epoch 1718 of 2000 took 0.097s
  training loss:		0.581719
  validation loss:		0.602614
  validation accuracy:		82.72 %
Epoch 1719 of 2000 took 0.102s
  training loss:		0.578676
  validation loss:		0.610774
  validation accuracy:		81.85 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.575825
  validation loss:		0.599632
  validation accuracy:		82.39 %
Epoch 1721 of 2000 took 0.097s
  training loss:		0.574106
  validation loss:		0.616106
  validation accuracy:		82.07 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.571817
  validation loss:		0.616334
  validation accuracy:		81.74 %
Epoch 1723 of 2000 took 0.098s
  training loss:		0.570362
  validation loss:		0.591334
  validation accuracy:		80.98 %
Epoch 1724 of 2000 took 0.100s
  training loss:		0.609761
  validation loss:		0.633687
  validation accuracy:		79.89 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.580575
  validation loss:		0.635351
  validation accuracy:		80.76 %
Epoch 1726 of 2000 took 0.098s
  training loss:		0.576095
  validation loss:		0.593098
  validation accuracy:		82.17 %
Epoch 1727 of 2000 took 0.101s
  training loss:		0.583218
  validation loss:		0.600131
  validation accuracy:		82.72 %
Epoch 1728 of 2000 took 0.096s
  training loss:		0.584259
  validation loss:		0.598862
  validation accuracy:		82.50 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.566074
  validation loss:		0.592704
  validation accuracy:		81.96 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.585403
  validation loss:		0.593919
  validation accuracy:		81.96 %
Epoch 1731 of 2000 took 0.101s
  training loss:		0.582763
  validation loss:		0.634878
  validation accuracy:		81.52 %
Epoch 1732 of 2000 took 0.097s
  training loss:		0.578461
  validation loss:		0.590995
  validation accuracy:		81.20 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.588542
  validation loss:		0.595982
  validation accuracy:		81.96 %
Epoch 1734 of 2000 took 0.101s
  training loss:		0.581286
  validation loss:		0.612579
  validation accuracy:		80.98 %
Epoch 1735 of 2000 took 0.097s
  training loss:		0.570812
  validation loss:		0.613000
  validation accuracy:		81.52 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.578954
  validation loss:		0.639417
  validation accuracy:		80.76 %
Epoch 1737 of 2000 took 0.097s
  training loss:		0.581804
  validation loss:		0.591394
  validation accuracy:		81.96 %
Epoch 1738 of 2000 took 0.097s
  training loss:		0.587109
  validation loss:		0.604445
  validation accuracy:		82.07 %
Epoch 1739 of 2000 took 0.100s
  training loss:		0.575608
  validation loss:		0.607754
  validation accuracy:		81.20 %
Epoch 1740 of 2000 took 0.097s
  training loss:		0.581483
  validation loss:		0.603676
  validation accuracy:		81.63 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.573828
  validation loss:		0.665312
  validation accuracy:		79.57 %
Epoch 1742 of 2000 took 0.102s
  training loss:		0.576343
  validation loss:		0.611998
  validation accuracy:		81.09 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.581431
  validation loss:		0.589579
  validation accuracy:		81.74 %
Epoch 1744 of 2000 took 0.097s
  training loss:		0.579417
  validation loss:		0.622326
  validation accuracy:		81.85 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.581770
  validation loss:		0.615563
  validation accuracy:		81.52 %
Epoch 1746 of 2000 took 0.098s
  training loss:		0.578707
  validation loss:		0.590927
  validation accuracy:		81.96 %
Epoch 1747 of 2000 took 0.100s
  training loss:		0.583782
  validation loss:		0.602819
  validation accuracy:		81.41 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.577433
  validation loss:		0.602049
  validation accuracy:		82.72 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.586432
  validation loss:		0.609428
  validation accuracy:		81.85 %
Epoch 1750 of 2000 took 0.102s
  training loss:		0.569958
  validation loss:		0.638051
  validation accuracy:		80.22 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.577308
  validation loss:		0.599125
  validation accuracy:		81.30 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.580387
  validation loss:		0.646588
  validation accuracy:		80.76 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.575384
  validation loss:		0.624350
  validation accuracy:		80.65 %
Epoch 1754 of 2000 took 0.100s
  training loss:		0.581672
  validation loss:		0.623779
  validation accuracy:		81.20 %
Epoch 1755 of 2000 took 0.098s
  training loss:		0.578066
  validation loss:		0.610826
  validation accuracy:		82.28 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.574694
  validation loss:		0.608806
  validation accuracy:		81.74 %
Epoch 1757 of 2000 took 0.100s
  training loss:		0.577613
  validation loss:		0.596191
  validation accuracy:		82.28 %
Epoch 1758 of 2000 took 0.098s
  training loss:		0.580527
  validation loss:		0.587102
  validation accuracy:		81.09 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.579000
  validation loss:		0.616316
  validation accuracy:		80.76 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.582423
  validation loss:		0.637806
  validation accuracy:		80.98 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.579915
  validation loss:		0.612901
  validation accuracy:		80.98 %
Epoch 1762 of 2000 took 0.100s
  training loss:		0.570544
  validation loss:		0.624275
  validation accuracy:		81.52 %
Epoch 1763 of 2000 took 0.097s
  training loss:		0.577622
  validation loss:		0.621649
  validation accuracy:		81.96 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.582054
  validation loss:		0.619207
  validation accuracy:		81.20 %
Epoch 1765 of 2000 took 0.102s
  training loss:		0.587068
  validation loss:		0.618252
  validation accuracy:		80.87 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.592600
  validation loss:		0.610656
  validation accuracy:		81.74 %
Epoch 1767 of 2000 took 0.097s
  training loss:		0.571275
  validation loss:		0.589800
  validation accuracy:		81.41 %
Epoch 1768 of 2000 took 0.096s
  training loss:		0.582403
  validation loss:		0.614932
  validation accuracy:		81.20 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.578585
  validation loss:		0.608356
  validation accuracy:		81.74 %
Epoch 1770 of 2000 took 0.100s
  training loss:		0.581479
  validation loss:		0.597229
  validation accuracy:		82.07 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.576760
  validation loss:		0.601973
  validation accuracy:		82.07 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.569386
  validation loss:		0.662073
  validation accuracy:		79.89 %
Epoch 1773 of 2000 took 0.102s
  training loss:		0.583493
  validation loss:		0.605188
  validation accuracy:		82.50 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.575171
  validation loss:		0.594880
  validation accuracy:		82.17 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.581806
  validation loss:		0.593120
  validation accuracy:		81.63 %
Epoch 1776 of 2000 took 0.095s
  training loss:		0.577829
  validation loss:		0.594209
  validation accuracy:		81.74 %
Epoch 1777 of 2000 took 0.098s
  training loss:		0.572523
  validation loss:		0.606191
  validation accuracy:		82.39 %
Epoch 1778 of 2000 took 0.099s
  training loss:		0.580610
  validation loss:		0.617813
  validation accuracy:		80.65 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.578823
  validation loss:		0.606471
  validation accuracy:		82.28 %
Epoch 1780 of 2000 took 0.098s
  training loss:		0.579273
  validation loss:		0.595071
  validation accuracy:		81.96 %
Epoch 1781 of 2000 took 0.100s
  training loss:		0.576598
  validation loss:		0.610639
  validation accuracy:		81.30 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.579254
  validation loss:		0.609236
  validation accuracy:		81.96 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.577574
  validation loss:		0.604873
  validation accuracy:		82.39 %
Epoch 1784 of 2000 took 0.096s
  training loss:		0.579233
  validation loss:		0.601087
  validation accuracy:		82.39 %
Epoch 1785 of 2000 took 0.100s
  training loss:		0.576943
  validation loss:		0.620211
  validation accuracy:		81.63 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.574947
  validation loss:		0.600455
  validation accuracy:		82.39 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.568333
  validation loss:		0.617437
  validation accuracy:		81.85 %
Epoch 1788 of 2000 took 0.101s
  training loss:		0.577593
  validation loss:		0.595018
  validation accuracy:		82.17 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.573509
  validation loss:		0.610536
  validation accuracy:		81.85 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.574976
  validation loss:		0.594578
  validation accuracy:		81.96 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.570771
  validation loss:		0.620483
  validation accuracy:		81.52 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.584743
  validation loss:		0.591416
  validation accuracy:		82.07 %
Epoch 1793 of 2000 took 0.100s
  training loss:		0.570108
  validation loss:		0.619780
  validation accuracy:		81.63 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.580504
  validation loss:		0.598797
  validation accuracy:		82.07 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.570989
  validation loss:		0.606695
  validation accuracy:		82.07 %
Epoch 1796 of 2000 took 0.102s
  training loss:		0.588245
  validation loss:		0.661629
  validation accuracy:		80.22 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.577535
  validation loss:		0.620548
  validation accuracy:		81.85 %
Epoch 1798 of 2000 took 0.097s
  training loss:		0.574555
  validation loss:		0.614494
  validation accuracy:		82.28 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.574141
  validation loss:		0.594477
  validation accuracy:		82.17 %
Epoch 1800 of 2000 took 0.098s
  training loss:		0.585491
  validation loss:		0.607086
  validation accuracy:		82.61 %
Epoch 1801 of 2000 took 0.100s
  training loss:		0.583675
  validation loss:		0.595446
  validation accuracy:		81.63 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.584491
  validation loss:		0.632412
  validation accuracy:		81.85 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.573938
  validation loss:		0.607665
  validation accuracy:		82.07 %
Epoch 1804 of 2000 took 0.101s
  training loss:		0.579637
  validation loss:		0.589230
  validation accuracy:		81.74 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.574079
  validation loss:		0.605103
  validation accuracy:		82.07 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.575338
  validation loss:		0.605570
  validation accuracy:		82.83 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.576593
  validation loss:		0.606603
  validation accuracy:		82.50 %
Epoch 1808 of 2000 took 0.100s
  training loss:		0.573348
  validation loss:		0.594165
  validation accuracy:		81.85 %
Epoch 1809 of 2000 took 0.098s
  training loss:		0.581151
  validation loss:		0.611253
  validation accuracy:		81.85 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.578025
  validation loss:		0.623703
  validation accuracy:		81.30 %
Epoch 1811 of 2000 took 0.100s
  training loss:		0.578525
  validation loss:		0.594435
  validation accuracy:		81.74 %
Epoch 1812 of 2000 took 0.098s
  training loss:		0.572067
  validation loss:		0.629041
  validation accuracy:		81.30 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.575962
  validation loss:		0.601414
  validation accuracy:		81.85 %
Epoch 1814 of 2000 took 0.096s
  training loss:		0.586405
  validation loss:		0.615291
  validation accuracy:		81.74 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.581188
  validation loss:		0.617019
  validation accuracy:		81.30 %
Epoch 1816 of 2000 took 0.100s
  training loss:		0.582827
  validation loss:		0.604284
  validation accuracy:		82.39 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.575405
  validation loss:		0.596140
  validation accuracy:		82.07 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.585263
  validation loss:		0.607396
  validation accuracy:		82.39 %
Epoch 1819 of 2000 took 0.102s
  training loss:		0.571132
  validation loss:		0.635896
  validation accuracy:		81.41 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.583526
  validation loss:		0.632012
  validation accuracy:		80.33 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.579665
  validation loss:		0.652028
  validation accuracy:		80.65 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.559201
  validation loss:		0.604893
  validation accuracy:		81.41 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.575655
  validation loss:		0.618355
  validation accuracy:		81.63 %
Epoch 1824 of 2000 took 0.100s
  training loss:		0.578885
  validation loss:		0.613059
  validation accuracy:		82.28 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.573360
  validation loss:		0.617205
  validation accuracy:		82.07 %
Epoch 1826 of 2000 took 0.096s
  training loss:		0.578252
  validation loss:		0.608072
  validation accuracy:		81.63 %
Epoch 1827 of 2000 took 0.102s
  training loss:		0.576360
  validation loss:		0.595034
  validation accuracy:		81.63 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.577581
  validation loss:		0.597049
  validation accuracy:		81.85 %
Epoch 1829 of 2000 took 0.097s
  training loss:		0.583473
  validation loss:		0.607757
  validation accuracy:		81.30 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.587308
  validation loss:		0.606688
  validation accuracy:		81.74 %
Epoch 1831 of 2000 took 0.098s
  training loss:		0.586348
  validation loss:		0.685956
  validation accuracy:		79.46 %
Epoch 1832 of 2000 took 0.099s
  training loss:		0.579988
  validation loss:		0.607069
  validation accuracy:		82.50 %
Epoch 1833 of 2000 took 0.096s
  training loss:		0.574496
  validation loss:		0.603677
  validation accuracy:		82.50 %
Epoch 1834 of 2000 took 0.098s
  training loss:		0.578746
  validation loss:		0.606373
  validation accuracy:		82.50 %
Epoch 1835 of 2000 took 0.100s
  training loss:		0.581940
  validation loss:		0.604835
  validation accuracy:		82.61 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.578059
  validation loss:		0.601957
  validation accuracy:		81.96 %
Epoch 1837 of 2000 took 0.097s
  training loss:		0.574621
  validation loss:		0.602109
  validation accuracy:		82.28 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.574995
  validation loss:		0.632717
  validation accuracy:		81.20 %
Epoch 1839 of 2000 took 0.100s
  training loss:		0.570996
  validation loss:		0.602056
  validation accuracy:		82.07 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.567501
  validation loss:		0.621188
  validation accuracy:		81.09 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.577844
  validation loss:		0.593406
  validation accuracy:		81.85 %
Epoch 1842 of 2000 took 0.101s
  training loss:		0.571633
  validation loss:		0.609225
  validation accuracy:		81.85 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.577563
  validation loss:		0.598092
  validation accuracy:		82.07 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.582536
  validation loss:		0.632845
  validation accuracy:		81.63 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.569814
  validation loss:		0.620545
  validation accuracy:		81.52 %
Epoch 1846 of 2000 took 0.097s
  training loss:		0.574278
  validation loss:		0.595557
  validation accuracy:		81.74 %
Epoch 1847 of 2000 took 0.102s
  training loss:		0.578915
  validation loss:		0.638458
  validation accuracy:		81.30 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.579688
  validation loss:		0.642558
  validation accuracy:		80.98 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.580364
  validation loss:		0.603060
  validation accuracy:		82.17 %
Epoch 1850 of 2000 took 0.102s
  training loss:		0.573690
  validation loss:		0.610098
  validation accuracy:		80.87 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.573697
  validation loss:		0.629470
  validation accuracy:		81.30 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.581454
  validation loss:		0.593339
  validation accuracy:		82.50 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.579849
  validation loss:		0.604245
  validation accuracy:		81.74 %
Epoch 1854 of 2000 took 0.098s
  training loss:		0.572965
  validation loss:		0.587934
  validation accuracy:		81.52 %
Epoch 1855 of 2000 took 0.100s
  training loss:		0.588402
  validation loss:		0.610922
  validation accuracy:		81.96 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.577792
  validation loss:		0.608917
  validation accuracy:		80.98 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.586415
  validation loss:		0.633924
  validation accuracy:		80.65 %
Epoch 1858 of 2000 took 0.101s
  training loss:		0.578388
  validation loss:		0.602922
  validation accuracy:		82.61 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.580533
  validation loss:		0.593788
  validation accuracy:		81.63 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.573066
  validation loss:		0.636138
  validation accuracy:		80.11 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.584777
  validation loss:		0.621439
  validation accuracy:		81.63 %
Epoch 1862 of 2000 took 0.100s
  training loss:		0.577041
  validation loss:		0.617418
  validation accuracy:		81.30 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.577050
  validation loss:		0.635759
  validation accuracy:		81.09 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.582167
  validation loss:		0.589126
  validation accuracy:		81.85 %
Epoch 1865 of 2000 took 0.100s
  training loss:		0.576059
  validation loss:		0.621520
  validation accuracy:		80.54 %
Epoch 1866 of 2000 took 0.098s
  training loss:		0.580413
  validation loss:		0.597840
  validation accuracy:		81.52 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.574429
  validation loss:		0.626831
  validation accuracy:		82.07 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.581421
  validation loss:		0.595214
  validation accuracy:		82.07 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.576461
  validation loss:		0.604139
  validation accuracy:		82.39 %
Epoch 1870 of 2000 took 0.100s
  training loss:		0.590406
  validation loss:		0.633067
  validation accuracy:		81.09 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.578753
  validation loss:		0.611992
  validation accuracy:		80.98 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.592580
  validation loss:		0.603331
  validation accuracy:		82.50 %
Epoch 1873 of 2000 took 0.102s
  training loss:		0.577860
  validation loss:		0.614061
  validation accuracy:		81.20 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.580828
  validation loss:		0.601699
  validation accuracy:		82.17 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.573445
  validation loss:		0.611571
  validation accuracy:		82.50 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.569621
  validation loss:		0.606445
  validation accuracy:		81.41 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.576560
  validation loss:		0.629005
  validation accuracy:		81.63 %
Epoch 1878 of 2000 took 0.100s
  training loss:		0.572994
  validation loss:		0.610359
  validation accuracy:		81.52 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.578206
  validation loss:		0.607345
  validation accuracy:		82.61 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.582082
  validation loss:		0.591129
  validation accuracy:		81.96 %
Epoch 1881 of 2000 took 0.102s
  training loss:		0.577043
  validation loss:		0.609059
  validation accuracy:		82.39 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.585705
  validation loss:		0.588729
  validation accuracy:		81.74 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.577913
  validation loss:		0.614077
  validation accuracy:		82.39 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.568428
  validation loss:		0.645865
  validation accuracy:		80.43 %
Epoch 1885 of 2000 took 0.100s
  training loss:		0.567548
  validation loss:		0.599786
  validation accuracy:		82.28 %
Epoch 1886 of 2000 took 0.098s
  training loss:		0.574656
  validation loss:		0.643856
  validation accuracy:		80.33 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.563686
  validation loss:		0.607853
  validation accuracy:		81.52 %
Epoch 1888 of 2000 took 0.099s
  training loss:		0.573615
  validation loss:		0.625847
  validation accuracy:		81.41 %
Epoch 1889 of 2000 took 0.099s
  training loss:		0.580012
  validation loss:		0.604535
  validation accuracy:		82.28 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.576490
  validation loss:		0.619328
  validation accuracy:		81.30 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.572792
  validation loss:		0.604831
  validation accuracy:		82.17 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.577028
  validation loss:		0.610976
  validation accuracy:		82.72 %
Epoch 1893 of 2000 took 0.100s
  training loss:		0.579131
  validation loss:		0.600960
  validation accuracy:		82.07 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.575721
  validation loss:		0.639603
  validation accuracy:		81.20 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.565923
  validation loss:		0.617449
  validation accuracy:		81.52 %
Epoch 1896 of 2000 took 0.102s
  training loss:		0.580940
  validation loss:		0.607533
  validation accuracy:		81.85 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.577612
  validation loss:		0.598442
  validation accuracy:		81.85 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.574918
  validation loss:		0.658293
  validation accuracy:		79.67 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.583785
  validation loss:		0.614400
  validation accuracy:		81.20 %
Epoch 1900 of 2000 took 0.097s
  training loss:		0.575456
  validation loss:		0.596001
  validation accuracy:		81.74 %
Epoch 1901 of 2000 took 0.100s
  training loss:		0.565165
  validation loss:		0.624896
  validation accuracy:		81.20 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.575243
  validation loss:		0.592834
  validation accuracy:		81.52 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.585730
  validation loss:		0.603001
  validation accuracy:		81.74 %
Epoch 1904 of 2000 took 0.102s
  training loss:		0.574349
  validation loss:		0.620550
  validation accuracy:		81.74 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.567642
  validation loss:		0.622222
  validation accuracy:		81.63 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.578225
  validation loss:		0.618168
  validation accuracy:		81.20 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.576232
  validation loss:		0.607335
  validation accuracy:		82.61 %
Epoch 1908 of 2000 took 0.099s
  training loss:		0.569228
  validation loss:		0.596662
  validation accuracy:		82.07 %
Epoch 1909 of 2000 took 0.098s
  training loss:		0.573177
  validation loss:		0.624631
  validation accuracy:		81.30 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.574907
  validation loss:		0.617542
  validation accuracy:		81.74 %
Epoch 1911 of 2000 took 0.099s
  training loss:		0.574160
  validation loss:		0.596877
  validation accuracy:		82.28 %
Epoch 1912 of 2000 took 0.099s
  training loss:		0.579750
  validation loss:		0.600520
  validation accuracy:		81.85 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.580633
  validation loss:		0.611336
  validation accuracy:		82.72 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.568739
  validation loss:		0.683489
  validation accuracy:		79.46 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.583122
  validation loss:		0.643761
  validation accuracy:		80.76 %
Epoch 1916 of 2000 took 0.100s
  training loss:		0.585784
  validation loss:		0.651312
  validation accuracy:		79.67 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.571526
  validation loss:		0.602802
  validation accuracy:		81.63 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.577906
  validation loss:		0.616897
  validation accuracy:		81.41 %
Epoch 1919 of 2000 took 0.102s
  training loss:		0.577127
  validation loss:		0.622180
  validation accuracy:		81.41 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.575599
  validation loss:		0.601463
  validation accuracy:		81.41 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.573599
  validation loss:		0.598813
  validation accuracy:		81.85 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.569635
  validation loss:		0.604698
  validation accuracy:		81.85 %
Epoch 1923 of 2000 took 0.097s
  training loss:		0.579517
  validation loss:		0.624855
  validation accuracy:		81.74 %
Epoch 1924 of 2000 took 0.100s
  training loss:		0.570087
  validation loss:		0.612237
  validation accuracy:		81.74 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.582490
  validation loss:		0.593762
  validation accuracy:		81.85 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.579927
  validation loss:		0.596736
  validation accuracy:		81.74 %
Epoch 1927 of 2000 took 0.102s
  training loss:		0.574842
  validation loss:		0.627734
  validation accuracy:		81.74 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.577783
  validation loss:		0.600534
  validation accuracy:		82.07 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.575588
  validation loss:		0.591722
  validation accuracy:		81.74 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.576347
  validation loss:		0.612042
  validation accuracy:		82.39 %
Epoch 1931 of 2000 took 0.098s
  training loss:		0.580260
  validation loss:		0.606391
  validation accuracy:		82.07 %
Epoch 1932 of 2000 took 0.099s
  training loss:		0.576460
  validation loss:		0.618604
  validation accuracy:		81.09 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.578147
  validation loss:		0.613736
  validation accuracy:		82.39 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.570919
  validation loss:		0.587798
  validation accuracy:		81.52 %
Epoch 1935 of 2000 took 0.101s
  training loss:		0.579306
  validation loss:		0.593621
  validation accuracy:		81.52 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.585181
  validation loss:		0.622075
  validation accuracy:		81.30 %
Epoch 1937 of 2000 took 0.097s
  training loss:		0.580440
  validation loss:		0.618456
  validation accuracy:		81.85 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.584336
  validation loss:		0.597056
  validation accuracy:		82.39 %
Epoch 1939 of 2000 took 0.101s
  training loss:		0.575675
  validation loss:		0.590934
  validation accuracy:		81.74 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.579755
  validation loss:		0.587405
  validation accuracy:		81.52 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.582537
  validation loss:		0.603709
  validation accuracy:		82.39 %
Epoch 1942 of 2000 took 0.101s
  training loss:		0.577040
  validation loss:		0.606178
  validation accuracy:		81.96 %
Epoch 1943 of 2000 took 0.097s
  training loss:		0.572722
  validation loss:		0.601348
  validation accuracy:		82.39 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.571573
  validation loss:		0.596618
  validation accuracy:		82.28 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.584338
  validation loss:		0.606195
  validation accuracy:		82.72 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.576029
  validation loss:		0.598044
  validation accuracy:		82.28 %
Epoch 1947 of 2000 took 0.100s
  training loss:		0.578504
  validation loss:		0.608575
  validation accuracy:		81.85 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.575978
  validation loss:		0.619192
  validation accuracy:		81.85 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.579508
  validation loss:		0.601629
  validation accuracy:		81.74 %
Epoch 1950 of 2000 took 0.102s
  training loss:		0.577232
  validation loss:		0.642407
  validation accuracy:		80.22 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.571937
  validation loss:		0.603039
  validation accuracy:		82.07 %
Epoch 1952 of 2000 took 0.097s
  training loss:		0.574350
  validation loss:		0.608824
  validation accuracy:		81.85 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.572892
  validation loss:		0.602654
  validation accuracy:		82.39 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.571405
  validation loss:		0.592876
  validation accuracy:		81.96 %
Epoch 1955 of 2000 took 0.100s
  training loss:		0.585833
  validation loss:		0.603760
  validation accuracy:		82.28 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.575111
  validation loss:		0.636912
  validation accuracy:		81.30 %
Epoch 1957 of 2000 took 0.097s
  training loss:		0.580701
  validation loss:		0.605686
  validation accuracy:		82.17 %
Epoch 1958 of 2000 took 0.101s
  training loss:		0.578859
  validation loss:		0.624809
  validation accuracy:		82.17 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.579734
  validation loss:		0.599550
  validation accuracy:		81.96 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.592165
  validation loss:		0.610820
  validation accuracy:		82.50 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.575133
  validation loss:		0.635367
  validation accuracy:		80.00 %
Epoch 1962 of 2000 took 0.100s
  training loss:		0.567404
  validation loss:		0.653433
  validation accuracy:		79.57 %
Epoch 1963 of 2000 took 0.098s
  training loss:		0.573517
  validation loss:		0.620757
  validation accuracy:		81.09 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.573911
  validation loss:		0.613214
  validation accuracy:		81.52 %
Epoch 1965 of 2000 took 0.099s
  training loss:		0.581971
  validation loss:		0.642455
  validation accuracy:		80.87 %
Epoch 1966 of 2000 took 0.099s
  training loss:		0.583879
  validation loss:		0.614342
  validation accuracy:		81.41 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.566909
  validation loss:		0.613017
  validation accuracy:		81.30 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.578192
  validation loss:		0.600138
  validation accuracy:		82.28 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.576947
  validation loss:		0.607304
  validation accuracy:		82.17 %
Epoch 1970 of 2000 took 0.100s
  training loss:		0.569314
  validation loss:		0.612128
  validation accuracy:		81.96 %
Epoch 1971 of 2000 took 0.097s
  training loss:		0.574069
  validation loss:		0.611090
  validation accuracy:		81.41 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.583747
  validation loss:		0.627872
  validation accuracy:		81.30 %
Epoch 1973 of 2000 took 0.102s
  training loss:		0.582085
  validation loss:		0.600650
  validation accuracy:		82.39 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.578921
  validation loss:		0.590241
  validation accuracy:		81.74 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.588408
  validation loss:		0.622871
  validation accuracy:		81.74 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.577311
  validation loss:		0.597064
  validation accuracy:		82.39 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.580523
  validation loss:		0.605362
  validation accuracy:		82.50 %
Epoch 1978 of 2000 took 0.100s
  training loss:		0.561347
  validation loss:		0.620194
  validation accuracy:		81.74 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.581576
  validation loss:		0.644412
  validation accuracy:		80.76 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.580110
  validation loss:		0.612746
  validation accuracy:		82.07 %
Epoch 1981 of 2000 took 0.102s
  training loss:		0.583390
  validation loss:		0.621064
  validation accuracy:		81.96 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.583764
  validation loss:		0.605181
  validation accuracy:		81.63 %
Epoch 1983 of 2000 took 0.097s
  training loss:		0.575279
  validation loss:		0.637406
  validation accuracy:		80.11 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.575962
  validation loss:		0.602255
  validation accuracy:		82.39 %
Epoch 1985 of 2000 took 0.098s
  training loss:		0.586412
  validation loss:		0.594879
  validation accuracy:		82.07 %
Epoch 1986 of 2000 took 0.099s
  training loss:		0.573774
  validation loss:		0.600726
  validation accuracy:		82.28 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.572687
  validation loss:		0.612411
  validation accuracy:		81.85 %
Epoch 1988 of 2000 took 0.098s
  training loss:		0.579758
  validation loss:		0.594314
  validation accuracy:		81.74 %
Epoch 1989 of 2000 took 0.100s
  training loss:		0.583927
  validation loss:		0.636390
  validation accuracy:		80.87 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.576125
  validation loss:		0.609130
  validation accuracy:		81.41 %
Epoch 1991 of 2000 took 0.097s
  training loss:		0.580030
  validation loss:		0.604283
  validation accuracy:		82.39 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.576920
  validation loss:		0.613157
  validation accuracy:		81.41 %
Epoch 1993 of 2000 took 0.101s
  training loss:		0.581269
  validation loss:		0.605208
  validation accuracy:		81.63 %
Epoch 1994 of 2000 took 0.097s
  training loss:		0.585201
  validation loss:		0.618206
  validation accuracy:		81.85 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.570735
  validation loss:		0.596565
  validation accuracy:		82.17 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.584838
  validation loss:		0.681707
  validation accuracy:		79.35 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.577294
  validation loss:		0.606091
  validation accuracy:		82.17 %
Epoch 1998 of 2000 took 0.097s
  training loss:		0.568057
  validation loss:		0.612504
  validation accuracy:		81.85 %
Epoch 1999 of 2000 took 0.098s
  training loss:		0.575277
  validation loss:		0.615410
  validation accuracy:		81.63 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.571165
  validation loss:		0.637021
  validation accuracy:		81.30 %
Final results:
  test loss:			0.867239
  test accuracy:		72.92 %
