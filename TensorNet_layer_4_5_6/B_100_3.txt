Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.100s
  training loss:		2.935714
  validation loss:		2.877642
  validation accuracy:		12.50 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.872837
  validation loss:		2.779499
  validation accuracy:		13.48 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.791134
  validation loss:		2.669445
  validation accuracy:		15.33 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.698056
  validation loss:		2.559705
  validation accuracy:		14.02 %
Epoch 5 of 2000 took 0.096s
  training loss:		2.603599
  validation loss:		2.452114
  validation accuracy:		13.48 %
Epoch 6 of 2000 took 0.096s
  training loss:		2.515792
  validation loss:		2.358179
  validation accuracy:		15.00 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.431345
  validation loss:		2.285108
  validation accuracy:		16.85 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.363692
  validation loss:		2.244638
  validation accuracy:		15.43 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.317527
  validation loss:		2.227054
  validation accuracy:		18.70 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.290501
  validation loss:		2.226113
  validation accuracy:		23.80 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.272566
  validation loss:		2.214959
  validation accuracy:		23.37 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.260043
  validation loss:		2.192236
  validation accuracy:		26.52 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.250169
  validation loss:		2.177618
  validation accuracy:		25.54 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.242643
  validation loss:		2.177662
  validation accuracy:		30.76 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.234831
  validation loss:		2.174763
  validation accuracy:		29.67 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.225777
  validation loss:		2.159394
  validation accuracy:		31.96 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.216727
  validation loss:		2.151485
  validation accuracy:		30.76 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.206102
  validation loss:		2.135137
  validation accuracy:		35.22 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.197160
  validation loss:		2.125948
  validation accuracy:		34.02 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.185782
  validation loss:		2.115479
  validation accuracy:		38.80 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.171455
  validation loss:		2.100064
  validation accuracy:		39.02 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.159087
  validation loss:		2.084901
  validation accuracy:		37.72 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.141628
  validation loss:		2.063662
  validation accuracy:		40.00 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.125101
  validation loss:		2.047114
  validation accuracy:		40.22 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.104387
  validation loss:		2.017840
  validation accuracy:		42.50 %
Epoch 26 of 2000 took 0.096s
  training loss:		2.084209
  validation loss:		1.992331
  validation accuracy:		44.89 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.060376
  validation loss:		1.972381
  validation accuracy:		42.17 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.032587
  validation loss:		1.939012
  validation accuracy:		43.15 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.003850
  validation loss:		1.907009
  validation accuracy:		43.91 %
Epoch 30 of 2000 took 0.096s
  training loss:		1.975901
  validation loss:		1.882845
  validation accuracy:		47.07 %
Epoch 31 of 2000 took 0.096s
  training loss:		1.946586
  validation loss:		1.853079
  validation accuracy:		46.74 %
Epoch 32 of 2000 took 0.097s
  training loss:		1.912493
  validation loss:		1.806194
  validation accuracy:		48.37 %
Epoch 33 of 2000 took 0.096s
  training loss:		1.882566
  validation loss:		1.773157
  validation accuracy:		47.39 %
Epoch 34 of 2000 took 0.097s
  training loss:		1.849934
  validation loss:		1.739401
  validation accuracy:		51.30 %
Epoch 35 of 2000 took 0.096s
  training loss:		1.816975
  validation loss:		1.706014
  validation accuracy:		51.09 %
Epoch 36 of 2000 took 0.096s
  training loss:		1.789449
  validation loss:		1.685497
  validation accuracy:		46.74 %
Epoch 37 of 2000 took 0.097s
  training loss:		1.759557
  validation loss:		1.647582
  validation accuracy:		53.04 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.728907
  validation loss:		1.614311
  validation accuracy:		53.59 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.698655
  validation loss:		1.589187
  validation accuracy:		55.22 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.674099
  validation loss:		1.562848
  validation accuracy:		56.96 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.644602
  validation loss:		1.531439
  validation accuracy:		59.02 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.617867
  validation loss:		1.499624
  validation accuracy:		59.89 %
Epoch 43 of 2000 took 0.100s
  training loss:		1.590867
  validation loss:		1.482155
  validation accuracy:		59.89 %
Epoch 44 of 2000 took 0.098s
  training loss:		1.555641
  validation loss:		1.445949
  validation accuracy:		61.63 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.529926
  validation loss:		1.415510
  validation accuracy:		61.74 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.508895
  validation loss:		1.386481
  validation accuracy:		63.37 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.470833
  validation loss:		1.359697
  validation accuracy:		65.98 %
Epoch 48 of 2000 took 0.097s
  training loss:		1.442427
  validation loss:		1.335085
  validation accuracy:		64.24 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.418815
  validation loss:		1.304750
  validation accuracy:		66.74 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.392331
  validation loss:		1.278910
  validation accuracy:		65.65 %
Epoch 51 of 2000 took 0.097s
  training loss:		1.356330
  validation loss:		1.244641
  validation accuracy:		69.78 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.332035
  validation loss:		1.219494
  validation accuracy:		68.70 %
Epoch 53 of 2000 took 0.097s
  training loss:		1.301911
  validation loss:		1.196946
  validation accuracy:		70.65 %
Epoch 54 of 2000 took 0.097s
  training loss:		1.269427
  validation loss:		1.155804
  validation accuracy:		71.41 %
Epoch 55 of 2000 took 0.097s
  training loss:		1.239443
  validation loss:		1.133618
  validation accuracy:		71.20 %
Epoch 56 of 2000 took 0.097s
  training loss:		1.200336
  validation loss:		1.101019
  validation accuracy:		73.15 %
Epoch 57 of 2000 took 0.097s
  training loss:		1.174778
  validation loss:		1.071717
  validation accuracy:		73.80 %
Epoch 58 of 2000 took 0.097s
  training loss:		1.144806
  validation loss:		1.035644
  validation accuracy:		74.57 %
Epoch 59 of 2000 took 0.097s
  training loss:		1.111316
  validation loss:		1.015194
  validation accuracy:		75.87 %
Epoch 60 of 2000 took 0.097s
  training loss:		1.093649
  validation loss:		0.995170
  validation accuracy:		75.54 %
Epoch 61 of 2000 took 0.097s
  training loss:		1.054953
  validation loss:		0.961214
  validation accuracy:		75.22 %
Epoch 62 of 2000 took 0.097s
  training loss:		1.027775
  validation loss:		0.942450
  validation accuracy:		76.20 %
Epoch 63 of 2000 took 0.098s
  training loss:		1.014128
  validation loss:		0.926025
  validation accuracy:		76.63 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.972299
  validation loss:		0.879729
  validation accuracy:		78.04 %
Epoch 65 of 2000 took 0.097s
  training loss:		0.945696
  validation loss:		0.866060
  validation accuracy:		77.61 %
Epoch 66 of 2000 took 0.097s
  training loss:		0.922568
  validation loss:		0.839903
  validation accuracy:		78.91 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.896259
  validation loss:		0.810837
  validation accuracy:		79.02 %
Epoch 68 of 2000 took 0.097s
  training loss:		0.884265
  validation loss:		0.787259
  validation accuracy:		79.46 %
Epoch 69 of 2000 took 0.097s
  training loss:		0.846963
  validation loss:		0.773138
  validation accuracy:		79.24 %
Epoch 70 of 2000 took 0.097s
  training loss:		0.816451
  validation loss:		0.753476
  validation accuracy:		79.89 %
Epoch 71 of 2000 took 0.097s
  training loss:		0.806191
  validation loss:		0.739037
  validation accuracy:		79.78 %
Epoch 72 of 2000 took 0.097s
  training loss:		0.788135
  validation loss:		0.720333
  validation accuracy:		80.43 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.779473
  validation loss:		0.696173
  validation accuracy:		80.33 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.749485
  validation loss:		0.690102
  validation accuracy:		80.22 %
Epoch 75 of 2000 took 0.097s
  training loss:		0.732898
  validation loss:		0.668385
  validation accuracy:		80.43 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.715740
  validation loss:		0.664354
  validation accuracy:		80.22 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.698427
  validation loss:		0.645256
  validation accuracy:		81.52 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.691431
  validation loss:		0.637773
  validation accuracy:		80.87 %
Epoch 79 of 2000 took 0.097s
  training loss:		0.675508
  validation loss:		0.635327
  validation accuracy:		80.98 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.667783
  validation loss:		0.622443
  validation accuracy:		81.96 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.654231
  validation loss:		0.600425
  validation accuracy:		82.93 %
Epoch 82 of 2000 took 0.097s
  training loss:		0.630905
  validation loss:		0.584507
  validation accuracy:		82.50 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.619480
  validation loss:		0.611009
  validation accuracy:		80.76 %
Epoch 84 of 2000 took 0.097s
  training loss:		0.607782
  validation loss:		0.567195
  validation accuracy:		83.80 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.601244
  validation loss:		0.571334
  validation accuracy:		82.39 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.589216
  validation loss:		0.549750
  validation accuracy:		83.04 %
Epoch 87 of 2000 took 0.097s
  training loss:		0.577350
  validation loss:		0.545865
  validation accuracy:		83.15 %
Epoch 88 of 2000 took 0.097s
  training loss:		0.564687
  validation loss:		0.536784
  validation accuracy:		83.15 %
Epoch 89 of 2000 took 0.097s
  training loss:		0.555897
  validation loss:		0.533334
  validation accuracy:		82.93 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.548877
  validation loss:		0.514123
  validation accuracy:		84.13 %
Epoch 91 of 2000 took 0.097s
  training loss:		0.536592
  validation loss:		0.506759
  validation accuracy:		84.02 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.537442
  validation loss:		0.515002
  validation accuracy:		83.26 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.530212
  validation loss:		0.498776
  validation accuracy:		84.67 %
Epoch 94 of 2000 took 0.098s
  training loss:		0.511692
  validation loss:		0.489654
  validation accuracy:		85.76 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.508042
  validation loss:		0.497597
  validation accuracy:		84.35 %
Epoch 96 of 2000 took 0.097s
  training loss:		0.500229
  validation loss:		0.479221
  validation accuracy:		85.87 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.494912
  validation loss:		0.485645
  validation accuracy:		85.22 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.492568
  validation loss:		0.474196
  validation accuracy:		86.52 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.481069
  validation loss:		0.479290
  validation accuracy:		84.35 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.464724
  validation loss:		0.456895
  validation accuracy:		86.52 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.464190
  validation loss:		0.440130
  validation accuracy:		87.07 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.458966
  validation loss:		0.461550
  validation accuracy:		85.54 %
Epoch 103 of 2000 took 0.097s
  training loss:		0.451113
  validation loss:		0.432057
  validation accuracy:		87.28 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.443642
  validation loss:		0.441219
  validation accuracy:		86.20 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.435414
  validation loss:		0.429099
  validation accuracy:		87.72 %
Epoch 106 of 2000 took 0.097s
  training loss:		0.433272
  validation loss:		0.431291
  validation accuracy:		87.50 %
Epoch 107 of 2000 took 0.097s
  training loss:		0.425774
  validation loss:		0.413148
  validation accuracy:		87.72 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.424567
  validation loss:		0.424046
  validation accuracy:		87.83 %
Epoch 109 of 2000 took 0.098s
  training loss:		0.423909
  validation loss:		0.422202
  validation accuracy:		87.72 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.413968
  validation loss:		0.402926
  validation accuracy:		88.15 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.404253
  validation loss:		0.408829
  validation accuracy:		88.37 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.400874
  validation loss:		0.404734
  validation accuracy:		88.48 %
Epoch 113 of 2000 took 0.097s
  training loss:		0.402884
  validation loss:		0.401585
  validation accuracy:		88.59 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.396991
  validation loss:		0.417215
  validation accuracy:		86.63 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.386861
  validation loss:		0.386924
  validation accuracy:		88.37 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.390351
  validation loss:		0.403067
  validation accuracy:		87.93 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.384367
  validation loss:		0.396141
  validation accuracy:		87.93 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.384794
  validation loss:		0.392179
  validation accuracy:		88.70 %
Epoch 119 of 2000 took 0.101s
  training loss:		0.377598
  validation loss:		0.409972
  validation accuracy:		86.85 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.378467
  validation loss:		0.401083
  validation accuracy:		87.17 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.378816
  validation loss:		0.377580
  validation accuracy:		88.70 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.366220
  validation loss:		0.368147
  validation accuracy:		88.48 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.362596
  validation loss:		0.379631
  validation accuracy:		88.48 %
Epoch 124 of 2000 took 0.098s
  training loss:		0.363197
  validation loss:		0.377752
  validation accuracy:		88.70 %
Epoch 125 of 2000 took 0.098s
  training loss:		0.356044
  validation loss:		0.373363
  validation accuracy:		89.02 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.354427
  validation loss:		0.377584
  validation accuracy:		89.02 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.349681
  validation loss:		0.391627
  validation accuracy:		88.15 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.354540
  validation loss:		0.386621
  validation accuracy:		88.15 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.350861
  validation loss:		0.373819
  validation accuracy:		89.13 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.348271
  validation loss:		0.355798
  validation accuracy:		89.35 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.342424
  validation loss:		0.349946
  validation accuracy:		89.02 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.345056
  validation loss:		0.372329
  validation accuracy:		89.13 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.333852
  validation loss:		0.356463
  validation accuracy:		88.91 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.335100
  validation loss:		0.359650
  validation accuracy:		88.37 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.345633
  validation loss:		0.353512
  validation accuracy:		88.26 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.336229
  validation loss:		0.352984
  validation accuracy:		89.35 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.335171
  validation loss:		0.364072
  validation accuracy:		89.13 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.327742
  validation loss:		0.344271
  validation accuracy:		89.35 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.328654
  validation loss:		0.350045
  validation accuracy:		89.13 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.322842
  validation loss:		0.345111
  validation accuracy:		89.57 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.323785
  validation loss:		0.388347
  validation accuracy:		88.15 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.319477
  validation loss:		0.391154
  validation accuracy:		87.83 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.321335
  validation loss:		0.344389
  validation accuracy:		89.57 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.317433
  validation loss:		0.345383
  validation accuracy:		89.35 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.316225
  validation loss:		0.336788
  validation accuracy:		89.67 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.318115
  validation loss:		0.336343
  validation accuracy:		89.89 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.313497
  validation loss:		0.337744
  validation accuracy:		89.46 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.311866
  validation loss:		0.338192
  validation accuracy:		89.67 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.306265
  validation loss:		0.346770
  validation accuracy:		89.35 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.306878
  validation loss:		0.347178
  validation accuracy:		89.35 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.309013
  validation loss:		0.372609
  validation accuracy:		88.80 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.304348
  validation loss:		0.344894
  validation accuracy:		89.35 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.307253
  validation loss:		0.349317
  validation accuracy:		90.11 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.298734
  validation loss:		0.333306
  validation accuracy:		90.00 %
Epoch 155 of 2000 took 0.098s
  training loss:		0.306141
  validation loss:		0.331892
  validation accuracy:		89.57 %
Epoch 156 of 2000 took 0.098s
  training loss:		0.298968
  validation loss:		0.345882
  validation accuracy:		90.00 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.302075
  validation loss:		0.335964
  validation accuracy:		89.24 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.303506
  validation loss:		0.337100
  validation accuracy:		89.57 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.305050
  validation loss:		0.349845
  validation accuracy:		89.89 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.296483
  validation loss:		0.334124
  validation accuracy:		89.89 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.300278
  validation loss:		0.325635
  validation accuracy:		89.78 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.296924
  validation loss:		0.338802
  validation accuracy:		89.57 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.293772
  validation loss:		0.325622
  validation accuracy:		90.00 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.289636
  validation loss:		0.321397
  validation accuracy:		89.78 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.293045
  validation loss:		0.339221
  validation accuracy:		90.00 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.290046
  validation loss:		0.334352
  validation accuracy:		89.89 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.287077
  validation loss:		0.341471
  validation accuracy:		89.89 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.286180
  validation loss:		0.337681
  validation accuracy:		90.11 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.285646
  validation loss:		0.343515
  validation accuracy:		89.13 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.287973
  validation loss:		0.327924
  validation accuracy:		89.89 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.293131
  validation loss:		0.343243
  validation accuracy:		89.57 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.286508
  validation loss:		0.334121
  validation accuracy:		90.00 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.279329
  validation loss:		0.344911
  validation accuracy:		90.22 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.284369
  validation loss:		0.328207
  validation accuracy:		90.00 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.279621
  validation loss:		0.348567
  validation accuracy:		89.35 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.280746
  validation loss:		0.327583
  validation accuracy:		89.78 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.284978
  validation loss:		0.354032
  validation accuracy:		89.78 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.285171
  validation loss:		0.337667
  validation accuracy:		89.89 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.281716
  validation loss:		0.336270
  validation accuracy:		89.67 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.276204
  validation loss:		0.326312
  validation accuracy:		89.67 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.271776
  validation loss:		0.339628
  validation accuracy:		89.57 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.274199
  validation loss:		0.322877
  validation accuracy:		90.22 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.282409
  validation loss:		0.337184
  validation accuracy:		90.22 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.277029
  validation loss:		0.337335
  validation accuracy:		89.35 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.272277
  validation loss:		0.335161
  validation accuracy:		89.67 %
Epoch 186 of 2000 took 0.098s
  training loss:		0.270444
  validation loss:		0.343301
  validation accuracy:		90.11 %
Epoch 187 of 2000 took 0.098s
  training loss:		0.266321
  validation loss:		0.331018
  validation accuracy:		89.89 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.270110
  validation loss:		0.339013
  validation accuracy:		90.22 %
Epoch 189 of 2000 took 0.097s
  training loss:		0.269717
  validation loss:		0.333646
  validation accuracy:		89.78 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.272228
  validation loss:		0.326172
  validation accuracy:		89.78 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.272503
  validation loss:		0.339527
  validation accuracy:		89.57 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.267466
  validation loss:		0.329300
  validation accuracy:		89.89 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.270663
  validation loss:		0.361671
  validation accuracy:		88.37 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.272906
  validation loss:		0.323962
  validation accuracy:		90.00 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.269625
  validation loss:		0.338420
  validation accuracy:		90.11 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.263859
  validation loss:		0.337925
  validation accuracy:		89.67 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.267467
  validation loss:		0.326631
  validation accuracy:		89.67 %
Epoch 198 of 2000 took 0.097s
  training loss:		0.273522
  validation loss:		0.335723
  validation accuracy:		90.11 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.258594
  validation loss:		0.326316
  validation accuracy:		89.89 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.256838
  validation loss:		0.343531
  validation accuracy:		90.00 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.264897
  validation loss:		0.328957
  validation accuracy:		89.89 %
Epoch 202 of 2000 took 0.099s
  training loss:		0.270151
  validation loss:		0.350250
  validation accuracy:		89.46 %
Epoch 203 of 2000 took 0.100s
  training loss:		0.254771
  validation loss:		0.323895
  validation accuracy:		90.22 %
Epoch 204 of 2000 took 0.100s
  training loss:		0.263860
  validation loss:		0.325610
  validation accuracy:		90.11 %
Epoch 205 of 2000 took 0.100s
  training loss:		0.266509
  validation loss:		0.323923
  validation accuracy:		89.89 %
Epoch 206 of 2000 took 0.100s
  training loss:		0.255826
  validation loss:		0.332641
  validation accuracy:		89.89 %
Epoch 207 of 2000 took 0.100s
  training loss:		0.250114
  validation loss:		0.340694
  validation accuracy:		89.57 %
Epoch 208 of 2000 took 0.100s
  training loss:		0.259027
  validation loss:		0.335741
  validation accuracy:		90.11 %
Epoch 209 of 2000 took 0.100s
  training loss:		0.251973
  validation loss:		0.321787
  validation accuracy:		90.43 %
Epoch 210 of 2000 took 0.100s
  training loss:		0.260111
  validation loss:		0.322307
  validation accuracy:		89.89 %
Epoch 211 of 2000 took 0.100s
  training loss:		0.252144
  validation loss:		0.317601
  validation accuracy:		90.43 %
Epoch 212 of 2000 took 0.100s
  training loss:		0.255815
  validation loss:		0.333984
  validation accuracy:		89.78 %
Epoch 213 of 2000 took 0.100s
  training loss:		0.255512
  validation loss:		0.342049
  validation accuracy:		89.57 %
Epoch 214 of 2000 took 0.100s
  training loss:		0.254586
  validation loss:		0.317986
  validation accuracy:		90.22 %
Epoch 215 of 2000 took 0.100s
  training loss:		0.248512
  validation loss:		0.326664
  validation accuracy:		90.11 %
Epoch 216 of 2000 took 0.100s
  training loss:		0.256096
  validation loss:		0.322901
  validation accuracy:		89.78 %
Epoch 217 of 2000 took 0.101s
  training loss:		0.251179
  validation loss:		0.320651
  validation accuracy:		90.22 %
Epoch 218 of 2000 took 0.100s
  training loss:		0.251028
  validation loss:		0.346405
  validation accuracy:		89.89 %
Epoch 219 of 2000 took 0.100s
  training loss:		0.252629
  validation loss:		0.328377
  validation accuracy:		90.11 %
Epoch 220 of 2000 took 0.100s
  training loss:		0.246395
  validation loss:		0.321864
  validation accuracy:		90.33 %
Epoch 221 of 2000 took 0.100s
  training loss:		0.244958
  validation loss:		0.342409
  validation accuracy:		90.00 %
Epoch 222 of 2000 took 0.100s
  training loss:		0.246892
  validation loss:		0.324882
  validation accuracy:		90.00 %
Epoch 223 of 2000 took 0.103s
  training loss:		0.245791
  validation loss:		0.333988
  validation accuracy:		89.78 %
Epoch 224 of 2000 took 0.101s
  training loss:		0.245631
  validation loss:		0.316842
  validation accuracy:		90.22 %
Epoch 225 of 2000 took 0.100s
  training loss:		0.251487
  validation loss:		0.327484
  validation accuracy:		90.00 %
Epoch 226 of 2000 took 0.100s
  training loss:		0.248890
  validation loss:		0.318698
  validation accuracy:		90.11 %
Epoch 227 of 2000 took 0.100s
  training loss:		0.243811
  validation loss:		0.320850
  validation accuracy:		89.78 %
Epoch 228 of 2000 took 0.100s
  training loss:		0.250741
  validation loss:		0.336048
  validation accuracy:		89.78 %
Epoch 229 of 2000 took 0.100s
  training loss:		0.242235
  validation loss:		0.321091
  validation accuracy:		90.33 %
Epoch 230 of 2000 took 0.100s
  training loss:		0.244595
  validation loss:		0.340350
  validation accuracy:		89.89 %
Epoch 231 of 2000 took 0.100s
  training loss:		0.240528
  validation loss:		0.329616
  validation accuracy:		90.00 %
Epoch 232 of 2000 took 0.100s
  training loss:		0.241136
  validation loss:		0.339324
  validation accuracy:		89.46 %
Epoch 233 of 2000 took 0.100s
  training loss:		0.245630
  validation loss:		0.332379
  validation accuracy:		90.54 %
Epoch 234 of 2000 took 0.100s
  training loss:		0.244539
  validation loss:		0.323705
  validation accuracy:		90.22 %
Epoch 235 of 2000 took 0.100s
  training loss:		0.237774
  validation loss:		0.341776
  validation accuracy:		89.89 %
Epoch 236 of 2000 took 0.100s
  training loss:		0.236353
  validation loss:		0.324403
  validation accuracy:		90.00 %
Epoch 237 of 2000 took 0.100s
  training loss:		0.240250
  validation loss:		0.318944
  validation accuracy:		90.11 %
Epoch 238 of 2000 took 0.100s
  training loss:		0.253731
  validation loss:		0.345535
  validation accuracy:		89.78 %
Epoch 239 of 2000 took 0.100s
  training loss:		0.241411
  validation loss:		0.341104
  validation accuracy:		89.46 %
Epoch 240 of 2000 took 0.100s
  training loss:		0.238050
  validation loss:		0.338006
  validation accuracy:		89.46 %
Epoch 241 of 2000 took 0.101s
  training loss:		0.234467
  validation loss:		0.331901
  validation accuracy:		90.22 %
Epoch 242 of 2000 took 0.104s
  training loss:		0.234276
  validation loss:		0.339479
  validation accuracy:		89.35 %
Epoch 243 of 2000 took 0.103s
  training loss:		0.234600
  validation loss:		0.328534
  validation accuracy:		90.00 %
Epoch 244 of 2000 took 0.103s
  training loss:		0.228372
  validation loss:		0.336449
  validation accuracy:		89.46 %
Epoch 245 of 2000 took 0.103s
  training loss:		0.242204
  validation loss:		0.355152
  validation accuracy:		89.24 %
Epoch 246 of 2000 took 0.104s
  training loss:		0.237389
  validation loss:		0.342819
  validation accuracy:		89.78 %
Epoch 247 of 2000 took 0.104s
  training loss:		0.235845
  validation loss:		0.344970
  validation accuracy:		90.11 %
Epoch 248 of 2000 took 0.104s
  training loss:		0.237797
  validation loss:		0.336468
  validation accuracy:		89.89 %
Epoch 249 of 2000 took 0.103s
  training loss:		0.233749
  validation loss:		0.323131
  validation accuracy:		90.11 %
Epoch 250 of 2000 took 0.104s
  training loss:		0.229153
  validation loss:		0.330750
  validation accuracy:		89.89 %
Epoch 251 of 2000 took 0.103s
  training loss:		0.235252
  validation loss:		0.330303
  validation accuracy:		90.11 %
Epoch 252 of 2000 took 0.103s
  training loss:		0.232517
  validation loss:		0.349951
  validation accuracy:		88.91 %
Epoch 253 of 2000 took 0.103s
  training loss:		0.243230
  validation loss:		0.340938
  validation accuracy:		90.00 %
Epoch 254 of 2000 took 0.104s
  training loss:		0.236473
  validation loss:		0.325111
  validation accuracy:		90.11 %
Epoch 255 of 2000 took 0.103s
  training loss:		0.231527
  validation loss:		0.368426
  validation accuracy:		88.80 %
Epoch 256 of 2000 took 0.104s
  training loss:		0.229933
  validation loss:		0.325168
  validation accuracy:		89.89 %
Epoch 257 of 2000 took 0.103s
  training loss:		0.229352
  validation loss:		0.370830
  validation accuracy:		88.04 %
Epoch 258 of 2000 took 0.104s
  training loss:		0.233777
  validation loss:		0.317738
  validation accuracy:		90.11 %
Epoch 259 of 2000 took 0.103s
  training loss:		0.224286
  validation loss:		0.315998
  validation accuracy:		90.22 %
Epoch 260 of 2000 took 0.104s
  training loss:		0.230625
  validation loss:		0.325975
  validation accuracy:		90.11 %
Epoch 261 of 2000 took 0.103s
  training loss:		0.231084
  validation loss:		0.341165
  validation accuracy:		89.57 %
Epoch 262 of 2000 took 0.104s
  training loss:		0.229215
  validation loss:		0.343445
  validation accuracy:		89.67 %
Epoch 263 of 2000 took 0.103s
  training loss:		0.229803
  validation loss:		0.323921
  validation accuracy:		90.22 %
Epoch 264 of 2000 took 0.103s
  training loss:		0.222425
  validation loss:		0.346788
  validation accuracy:		90.00 %
Epoch 265 of 2000 took 0.103s
  training loss:		0.227646
  validation loss:		0.339936
  validation accuracy:		89.67 %
Epoch 266 of 2000 took 0.104s
  training loss:		0.226784
  validation loss:		0.323338
  validation accuracy:		90.00 %
Epoch 267 of 2000 took 0.103s
  training loss:		0.222153
  validation loss:		0.320509
  validation accuracy:		90.76 %
Epoch 268 of 2000 took 0.103s
  training loss:		0.224574
  validation loss:		0.322015
  validation accuracy:		90.33 %
Epoch 269 of 2000 took 0.103s
  training loss:		0.216318
  validation loss:		0.330981
  validation accuracy:		90.22 %
Epoch 270 of 2000 took 0.102s
  training loss:		0.223076
  validation loss:		0.343707
  validation accuracy:		89.24 %
Epoch 271 of 2000 took 0.100s
  training loss:		0.224164
  validation loss:		0.328208
  validation accuracy:		89.57 %
Epoch 272 of 2000 took 0.100s
  training loss:		0.218254
  validation loss:		0.330990
  validation accuracy:		90.11 %
Epoch 273 of 2000 took 0.100s
  training loss:		0.225879
  validation loss:		0.340105
  validation accuracy:		89.89 %
Epoch 274 of 2000 took 0.100s
  training loss:		0.225667
  validation loss:		0.327001
  validation accuracy:		89.57 %
Epoch 275 of 2000 took 0.100s
  training loss:		0.224369
  validation loss:		0.340948
  validation accuracy:		89.89 %
Epoch 276 of 2000 took 0.101s
  training loss:		0.222047
  validation loss:		0.322199
  validation accuracy:		90.33 %
Epoch 277 of 2000 took 0.100s
  training loss:		0.224145
  validation loss:		0.348450
  validation accuracy:		89.67 %
Epoch 278 of 2000 took 0.100s
  training loss:		0.213883
  validation loss:		0.333019
  validation accuracy:		90.00 %
Epoch 279 of 2000 took 0.100s
  training loss:		0.224066
  validation loss:		0.352778
  validation accuracy:		89.46 %
Epoch 280 of 2000 took 0.099s
  training loss:		0.218112
  validation loss:		0.332766
  validation accuracy:		90.11 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.220532
  validation loss:		0.323934
  validation accuracy:		90.22 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.228404
  validation loss:		0.320790
  validation accuracy:		90.76 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.218458
  validation loss:		0.318666
  validation accuracy:		90.43 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.212801
  validation loss:		0.322504
  validation accuracy:		89.89 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.212298
  validation loss:		0.322981
  validation accuracy:		90.43 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.221113
  validation loss:		0.355292
  validation accuracy:		89.57 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.222488
  validation loss:		0.341499
  validation accuracy:		89.67 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.213100
  validation loss:		0.328826
  validation accuracy:		89.89 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.211522
  validation loss:		0.331495
  validation accuracy:		89.57 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.215477
  validation loss:		0.365102
  validation accuracy:		89.02 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.214526
  validation loss:		0.319463
  validation accuracy:		90.33 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.210100
  validation loss:		0.343310
  validation accuracy:		89.35 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.206615
  validation loss:		0.321981
  validation accuracy:		90.33 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.216588
  validation loss:		0.346948
  validation accuracy:		89.78 %
Epoch 295 of 2000 took 0.097s
  training loss:		0.212186
  validation loss:		0.328365
  validation accuracy:		90.00 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.213622
  validation loss:		0.325806
  validation accuracy:		90.43 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.216718
  validation loss:		0.320518
  validation accuracy:		90.54 %
Epoch 298 of 2000 took 0.097s
  training loss:		0.217804
  validation loss:		0.328855
  validation accuracy:		89.89 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.214212
  validation loss:		0.342245
  validation accuracy:		90.11 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.216245
  validation loss:		0.331992
  validation accuracy:		89.89 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.210982
  validation loss:		0.388346
  validation accuracy:		88.37 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.215772
  validation loss:		0.337222
  validation accuracy:		89.46 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.214036
  validation loss:		0.320422
  validation accuracy:		90.87 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.209920
  validation loss:		0.329919
  validation accuracy:		90.11 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.211606
  validation loss:		0.329137
  validation accuracy:		90.11 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.211873
  validation loss:		0.341330
  validation accuracy:		90.00 %
Epoch 307 of 2000 took 0.098s
  training loss:		0.212988
  validation loss:		0.336113
  validation accuracy:		90.11 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.211463
  validation loss:		0.347071
  validation accuracy:		89.24 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.213064
  validation loss:		0.354916
  validation accuracy:		89.78 %
Epoch 310 of 2000 took 0.097s
  training loss:		0.208332
  validation loss:		0.325256
  validation accuracy:		91.20 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.211365
  validation loss:		0.329017
  validation accuracy:		90.87 %
Epoch 312 of 2000 took 0.097s
  training loss:		0.208511
  validation loss:		0.364624
  validation accuracy:		88.91 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.205759
  validation loss:		0.360957
  validation accuracy:		89.67 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.207712
  validation loss:		0.348546
  validation accuracy:		90.11 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.200613
  validation loss:		0.337521
  validation accuracy:		90.00 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.203209
  validation loss:		0.344892
  validation accuracy:		89.89 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.205180
  validation loss:		0.324735
  validation accuracy:		90.98 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.204299
  validation loss:		0.337916
  validation accuracy:		90.11 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.198514
  validation loss:		0.323617
  validation accuracy:		90.87 %
Epoch 320 of 2000 took 0.097s
  training loss:		0.209169
  validation loss:		0.328975
  validation accuracy:		90.76 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.200680
  validation loss:		0.330872
  validation accuracy:		90.76 %
Epoch 322 of 2000 took 0.097s
  training loss:		0.203826
  validation loss:		0.335289
  validation accuracy:		90.54 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.208043
  validation loss:		0.323588
  validation accuracy:		91.09 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.204368
  validation loss:		0.320882
  validation accuracy:		90.98 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.204301
  validation loss:		0.328580
  validation accuracy:		90.87 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.199850
  validation loss:		0.345362
  validation accuracy:		89.89 %
Epoch 327 of 2000 took 0.097s
  training loss:		0.203867
  validation loss:		0.322138
  validation accuracy:		91.30 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.198285
  validation loss:		0.367362
  validation accuracy:		88.04 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.208176
  validation loss:		0.375365
  validation accuracy:		88.15 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.192178
  validation loss:		0.338696
  validation accuracy:		90.22 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.200021
  validation loss:		0.339881
  validation accuracy:		90.00 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.197794
  validation loss:		0.327367
  validation accuracy:		91.09 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.201211
  validation loss:		0.360831
  validation accuracy:		89.24 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.196957
  validation loss:		0.338194
  validation accuracy:		90.33 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.200075
  validation loss:		0.345901
  validation accuracy:		90.11 %
Epoch 336 of 2000 took 0.097s
  training loss:		0.193970
  validation loss:		0.332313
  validation accuracy:		90.65 %
Epoch 337 of 2000 took 0.101s
  training loss:		0.208517
  validation loss:		0.354743
  validation accuracy:		89.57 %
Epoch 338 of 2000 took 0.098s
  training loss:		0.194537
  validation loss:		0.345363
  validation accuracy:		89.67 %
Epoch 339 of 2000 took 0.097s
  training loss:		0.196781
  validation loss:		0.373601
  validation accuracy:		88.80 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.203203
  validation loss:		0.342955
  validation accuracy:		90.22 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.193010
  validation loss:		0.326437
  validation accuracy:		91.09 %
Epoch 342 of 2000 took 0.097s
  training loss:		0.193403
  validation loss:		0.325307
  validation accuracy:		91.52 %
Epoch 343 of 2000 took 0.097s
  training loss:		0.190795
  validation loss:		0.348313
  validation accuracy:		89.78 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.189139
  validation loss:		0.366327
  validation accuracy:		88.70 %
Epoch 345 of 2000 took 0.097s
  training loss:		0.192985
  validation loss:		0.344249
  validation accuracy:		89.89 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.194176
  validation loss:		0.342017
  validation accuracy:		90.22 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.195894
  validation loss:		0.335843
  validation accuracy:		90.98 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.185806
  validation loss:		0.332817
  validation accuracy:		90.98 %
Epoch 349 of 2000 took 0.097s
  training loss:		0.189546
  validation loss:		0.324029
  validation accuracy:		91.30 %
Epoch 350 of 2000 took 0.097s
  training loss:		0.194587
  validation loss:		0.338126
  validation accuracy:		90.22 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.194080
  validation loss:		0.337872
  validation accuracy:		90.33 %
Epoch 352 of 2000 took 0.097s
  training loss:		0.195504
  validation loss:		0.330468
  validation accuracy:		90.98 %
Epoch 353 of 2000 took 0.097s
  training loss:		0.192837
  validation loss:		0.326520
  validation accuracy:		91.09 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.193812
  validation loss:		0.328123
  validation accuracy:		91.30 %
Epoch 355 of 2000 took 0.097s
  training loss:		0.192693
  validation loss:		0.334144
  validation accuracy:		90.98 %
Epoch 356 of 2000 took 0.097s
  training loss:		0.183544
  validation loss:		0.358770
  validation accuracy:		88.91 %
Epoch 357 of 2000 took 0.097s
  training loss:		0.192937
  validation loss:		0.366759
  validation accuracy:		89.24 %
Epoch 358 of 2000 took 0.098s
  training loss:		0.184688
  validation loss:		0.336043
  validation accuracy:		90.98 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.186231
  validation loss:		0.343952
  validation accuracy:		90.00 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.193221
  validation loss:		0.352182
  validation accuracy:		90.33 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.183770
  validation loss:		0.336449
  validation accuracy:		90.76 %
Epoch 362 of 2000 took 0.097s
  training loss:		0.190712
  validation loss:		0.325995
  validation accuracy:		91.30 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.183566
  validation loss:		0.326265
  validation accuracy:		91.74 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.190452
  validation loss:		0.345283
  validation accuracy:		90.43 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.185564
  validation loss:		0.342808
  validation accuracy:		90.11 %
Epoch 366 of 2000 took 0.097s
  training loss:		0.188257
  validation loss:		0.340155
  validation accuracy:		90.76 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.184510
  validation loss:		0.346649
  validation accuracy:		90.33 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.188912
  validation loss:		0.344018
  validation accuracy:		90.22 %
Epoch 369 of 2000 took 0.098s
  training loss:		0.189977
  validation loss:		0.340678
  validation accuracy:		91.20 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.187931
  validation loss:		0.336210
  validation accuracy:		91.09 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.182223
  validation loss:		0.341583
  validation accuracy:		90.43 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.185074
  validation loss:		0.337179
  validation accuracy:		91.20 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.184181
  validation loss:		0.335682
  validation accuracy:		90.87 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.183933
  validation loss:		0.349629
  validation accuracy:		90.11 %
Epoch 375 of 2000 took 0.097s
  training loss:		0.182593
  validation loss:		0.345255
  validation accuracy:		90.33 %
Epoch 376 of 2000 took 0.097s
  training loss:		0.185320
  validation loss:		0.349849
  validation accuracy:		90.00 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.184039
  validation loss:		0.339509
  validation accuracy:		90.65 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.182678
  validation loss:		0.329026
  validation accuracy:		91.30 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.181668
  validation loss:		0.357198
  validation accuracy:		89.78 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.184846
  validation loss:		0.330473
  validation accuracy:		90.87 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.182150
  validation loss:		0.328766
  validation accuracy:		91.30 %
Epoch 382 of 2000 took 0.097s
  training loss:		0.185109
  validation loss:		0.352243
  validation accuracy:		90.22 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.183756
  validation loss:		0.326669
  validation accuracy:		91.20 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.181284
  validation loss:		0.333321
  validation accuracy:		91.30 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.176935
  validation loss:		0.367328
  validation accuracy:		89.89 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.177549
  validation loss:		0.347542
  validation accuracy:		90.11 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.177307
  validation loss:		0.337398
  validation accuracy:		90.54 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.174852
  validation loss:		0.332418
  validation accuracy:		91.52 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.180179
  validation loss:		0.346232
  validation accuracy:		90.87 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.176798
  validation loss:		0.342590
  validation accuracy:		90.22 %
Epoch 391 of 2000 took 0.097s
  training loss:		0.177897
  validation loss:		0.344900
  validation accuracy:		90.22 %
Epoch 392 of 2000 took 0.097s
  training loss:		0.175654
  validation loss:		0.331199
  validation accuracy:		91.20 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.176843
  validation loss:		0.344406
  validation accuracy:		90.43 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.180900
  validation loss:		0.349776
  validation accuracy:		89.57 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.176121
  validation loss:		0.332553
  validation accuracy:		90.65 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.187622
  validation loss:		0.339867
  validation accuracy:		90.54 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.178788
  validation loss:		0.334358
  validation accuracy:		90.87 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.178329
  validation loss:		0.364991
  validation accuracy:		90.54 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.178077
  validation loss:		0.322512
  validation accuracy:		92.07 %
Epoch 400 of 2000 took 0.098s
  training loss:		0.175128
  validation loss:		0.346119
  validation accuracy:		90.22 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.176753
  validation loss:		0.350211
  validation accuracy:		90.00 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.179688
  validation loss:		0.338125
  validation accuracy:		90.65 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.171990
  validation loss:		0.348889
  validation accuracy:		89.89 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.176315
  validation loss:		0.335750
  validation accuracy:		91.63 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.176291
  validation loss:		0.352362
  validation accuracy:		90.87 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.174428
  validation loss:		0.337933
  validation accuracy:		91.09 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.179581
  validation loss:		0.351524
  validation accuracy:		90.11 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.179510
  validation loss:		0.327280
  validation accuracy:		92.17 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.173007
  validation loss:		0.342132
  validation accuracy:		90.65 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.176682
  validation loss:		0.355535
  validation accuracy:		90.22 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.175176
  validation loss:		0.357226
  validation accuracy:		90.22 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.172496
  validation loss:		0.345100
  validation accuracy:		90.54 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.175347
  validation loss:		0.348469
  validation accuracy:		90.11 %
Epoch 414 of 2000 took 0.098s
  training loss:		0.174531
  validation loss:		0.329225
  validation accuracy:		91.85 %
Epoch 415 of 2000 took 0.097s
  training loss:		0.167287
  validation loss:		0.344344
  validation accuracy:		90.00 %
Epoch 416 of 2000 took 0.097s
  training loss:		0.176216
  validation loss:		0.364847
  validation accuracy:		89.78 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.173014
  validation loss:		0.338462
  validation accuracy:		91.09 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.177750
  validation loss:		0.383732
  validation accuracy:		89.67 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.168806
  validation loss:		0.342910
  validation accuracy:		90.43 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.169315
  validation loss:		0.335521
  validation accuracy:		90.43 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.164241
  validation loss:		0.341396
  validation accuracy:		90.54 %
Epoch 422 of 2000 took 0.097s
  training loss:		0.170489
  validation loss:		0.340527
  validation accuracy:		90.22 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.166288
  validation loss:		0.353960
  validation accuracy:		90.11 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.168752
  validation loss:		0.358600
  validation accuracy:		90.33 %
Epoch 425 of 2000 took 0.097s
  training loss:		0.171529
  validation loss:		0.344157
  validation accuracy:		90.87 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.169146
  validation loss:		0.357920
  validation accuracy:		90.00 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.169657
  validation loss:		0.336265
  validation accuracy:		91.41 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.168392
  validation loss:		0.354256
  validation accuracy:		90.43 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.170127
  validation loss:		0.331896
  validation accuracy:		91.30 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.174840
  validation loss:		0.348542
  validation accuracy:		90.33 %
Epoch 431 of 2000 took 0.098s
  training loss:		0.170138
  validation loss:		0.342138
  validation accuracy:		90.65 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.169095
  validation loss:		0.371379
  validation accuracy:		90.00 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.168420
  validation loss:		0.360271
  validation accuracy:		90.22 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.173991
  validation loss:		0.334774
  validation accuracy:		91.41 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.172112
  validation loss:		0.356133
  validation accuracy:		90.33 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.170437
  validation loss:		0.338355
  validation accuracy:		91.30 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.166723
  validation loss:		0.371620
  validation accuracy:		90.11 %
Epoch 438 of 2000 took 0.097s
  training loss:		0.173298
  validation loss:		0.351011
  validation accuracy:		90.00 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.170275
  validation loss:		0.354466
  validation accuracy:		90.54 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.165611
  validation loss:		0.351625
  validation accuracy:		90.76 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.167451
  validation loss:		0.351406
  validation accuracy:		90.43 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.160027
  validation loss:		0.363761
  validation accuracy:		89.67 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.166280
  validation loss:		0.336142
  validation accuracy:		90.87 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.164917
  validation loss:		0.345160
  validation accuracy:		90.65 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.163265
  validation loss:		0.359588
  validation accuracy:		89.89 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.162925
  validation loss:		0.355737
  validation accuracy:		89.89 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.163245
  validation loss:		0.375057
  validation accuracy:		89.67 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.161083
  validation loss:		0.376286
  validation accuracy:		90.33 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.162864
  validation loss:		0.337033
  validation accuracy:		91.30 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.168501
  validation loss:		0.343127
  validation accuracy:		90.54 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.163904
  validation loss:		0.358570
  validation accuracy:		89.78 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.169256
  validation loss:		0.352962
  validation accuracy:		90.54 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.161543
  validation loss:		0.352372
  validation accuracy:		90.00 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.158508
  validation loss:		0.353020
  validation accuracy:		90.43 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.163350
  validation loss:		0.345003
  validation accuracy:		90.43 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.163263
  validation loss:		0.371972
  validation accuracy:		89.67 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.154129
  validation loss:		0.350455
  validation accuracy:		90.33 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.160605
  validation loss:		0.353777
  validation accuracy:		90.33 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.156026
  validation loss:		0.350762
  validation accuracy:		90.33 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.164716
  validation loss:		0.370035
  validation accuracy:		90.00 %
Epoch 461 of 2000 took 0.098s
  training loss:		0.162759
  validation loss:		0.367750
  validation accuracy:		89.78 %
Epoch 462 of 2000 took 0.098s
  training loss:		0.162454
  validation loss:		0.334389
  validation accuracy:		91.09 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.164718
  validation loss:		0.345591
  validation accuracy:		90.76 %
Epoch 464 of 2000 took 0.099s
  training loss:		0.160695
  validation loss:		0.347809
  validation accuracy:		90.33 %
Epoch 465 of 2000 took 0.098s
  training loss:		0.156567
  validation loss:		0.344291
  validation accuracy:		90.22 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.158591
  validation loss:		0.348564
  validation accuracy:		91.52 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.165720
  validation loss:		0.346862
  validation accuracy:		90.43 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.157774
  validation loss:		0.365537
  validation accuracy:		89.78 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.153859
  validation loss:		0.409261
  validation accuracy:		89.02 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.158950
  validation loss:		0.344138
  validation accuracy:		90.87 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.156401
  validation loss:		0.379727
  validation accuracy:		90.22 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.162286
  validation loss:		0.369771
  validation accuracy:		89.57 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.152641
  validation loss:		0.359049
  validation accuracy:		90.11 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.158769
  validation loss:		0.370492
  validation accuracy:		89.89 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.157630
  validation loss:		0.350805
  validation accuracy:		90.54 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.152575
  validation loss:		0.377649
  validation accuracy:		90.00 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.152037
  validation loss:		0.347745
  validation accuracy:		90.65 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.157620
  validation loss:		0.371682
  validation accuracy:		90.22 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.157608
  validation loss:		0.372095
  validation accuracy:		89.46 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.152525
  validation loss:		0.348420
  validation accuracy:		90.33 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.154987
  validation loss:		0.344970
  validation accuracy:		90.76 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.156775
  validation loss:		0.357211
  validation accuracy:		90.33 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.149777
  validation loss:		0.360301
  validation accuracy:		89.89 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.154813
  validation loss:		0.345149
  validation accuracy:		90.76 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.156024
  validation loss:		0.352866
  validation accuracy:		90.76 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.151670
  validation loss:		0.367473
  validation accuracy:		89.46 %
Epoch 487 of 2000 took 0.097s
  training loss:		0.152443
  validation loss:		0.364160
  validation accuracy:		89.89 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.151880
  validation loss:		0.361396
  validation accuracy:		90.54 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.153304
  validation loss:		0.354757
  validation accuracy:		90.54 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.148139
  validation loss:		0.377546
  validation accuracy:		89.57 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.155861
  validation loss:		0.383747
  validation accuracy:		90.54 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.151459
  validation loss:		0.385514
  validation accuracy:		90.11 %
Epoch 493 of 2000 took 0.098s
  training loss:		0.153516
  validation loss:		0.371522
  validation accuracy:		89.89 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.152826
  validation loss:		0.354184
  validation accuracy:		90.54 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.144448
  validation loss:		0.364523
  validation accuracy:		90.11 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.150213
  validation loss:		0.356497
  validation accuracy:		90.76 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.150230
  validation loss:		0.350460
  validation accuracy:		90.43 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.146329
  validation loss:		0.382545
  validation accuracy:		89.57 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.152642
  validation loss:		0.350354
  validation accuracy:		90.87 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.152560
  validation loss:		0.366069
  validation accuracy:		90.22 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.151765
  validation loss:		0.351789
  validation accuracy:		90.87 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.146812
  validation loss:		0.370099
  validation accuracy:		89.67 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.152123
  validation loss:		0.363281
  validation accuracy:		90.22 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.150908
  validation loss:		0.362654
  validation accuracy:		89.89 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.147196
  validation loss:		0.360701
  validation accuracy:		90.43 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.142012
  validation loss:		0.366605
  validation accuracy:		89.78 %
Epoch 507 of 2000 took 0.097s
  training loss:		0.148570
  validation loss:		0.362122
  validation accuracy:		90.33 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.150121
  validation loss:		0.372815
  validation accuracy:		90.43 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.155001
  validation loss:		0.394990
  validation accuracy:		89.57 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.148264
  validation loss:		0.382027
  validation accuracy:		90.33 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.146421
  validation loss:		0.369950
  validation accuracy:		89.89 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.145495
  validation loss:		0.356726
  validation accuracy:		90.43 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.149388
  validation loss:		0.368412
  validation accuracy:		90.43 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.143936
  validation loss:		0.383004
  validation accuracy:		90.00 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.150931
  validation loss:		0.368979
  validation accuracy:		90.33 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.154897
  validation loss:		0.367531
  validation accuracy:		90.11 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.148064
  validation loss:		0.378692
  validation accuracy:		89.46 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.144568
  validation loss:		0.374649
  validation accuracy:		89.57 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.146985
  validation loss:		0.366870
  validation accuracy:		90.11 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.144282
  validation loss:		0.367762
  validation accuracy:		90.22 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.147895
  validation loss:		0.363201
  validation accuracy:		90.33 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.149923
  validation loss:		0.360750
  validation accuracy:		90.43 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.145376
  validation loss:		0.373150
  validation accuracy:		89.89 %
Epoch 524 of 2000 took 0.098s
  training loss:		0.148135
  validation loss:		0.363992
  validation accuracy:		90.33 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.147129
  validation loss:		0.355060
  validation accuracy:		90.87 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.145844
  validation loss:		0.372977
  validation accuracy:		90.11 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.146995
  validation loss:		0.368212
  validation accuracy:		89.78 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.144997
  validation loss:		0.384280
  validation accuracy:		89.67 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.144586
  validation loss:		0.415755
  validation accuracy:		89.35 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.153931
  validation loss:		0.391152
  validation accuracy:		89.35 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.142566
  validation loss:		0.374280
  validation accuracy:		90.11 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.149090
  validation loss:		0.359887
  validation accuracy:		90.11 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.142816
  validation loss:		0.385466
  validation accuracy:		90.11 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.145770
  validation loss:		0.354175
  validation accuracy:		91.30 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.151746
  validation loss:		0.359468
  validation accuracy:		90.54 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.146362
  validation loss:		0.358636
  validation accuracy:		90.65 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.143490
  validation loss:		0.369095
  validation accuracy:		90.76 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.143794
  validation loss:		0.356553
  validation accuracy:		91.20 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.136645
  validation loss:		0.367596
  validation accuracy:		90.11 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.139771
  validation loss:		0.391629
  validation accuracy:		90.43 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.142852
  validation loss:		0.371181
  validation accuracy:		90.11 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.139644
  validation loss:		0.371350
  validation accuracy:		90.22 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.143808
  validation loss:		0.369915
  validation accuracy:		90.33 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.142753
  validation loss:		0.349071
  validation accuracy:		91.41 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.139945
  validation loss:		0.382625
  validation accuracy:		89.89 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.142325
  validation loss:		0.375431
  validation accuracy:		90.11 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.140012
  validation loss:		0.380086
  validation accuracy:		90.54 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.140937
  validation loss:		0.359375
  validation accuracy:		90.98 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.138397
  validation loss:		0.358929
  validation accuracy:		91.20 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.139685
  validation loss:		0.368662
  validation accuracy:		90.65 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.137828
  validation loss:		0.364016
  validation accuracy:		90.33 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.140200
  validation loss:		0.384161
  validation accuracy:		90.11 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.141552
  validation loss:		0.387270
  validation accuracy:		90.11 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.138843
  validation loss:		0.362585
  validation accuracy:		90.76 %
Epoch 555 of 2000 took 0.098s
  training loss:		0.134916
  validation loss:		0.387377
  validation accuracy:		90.33 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.140744
  validation loss:		0.386795
  validation accuracy:		89.89 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.145799
  validation loss:		0.367238
  validation accuracy:		90.54 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.137792
  validation loss:		0.391633
  validation accuracy:		90.00 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.145713
  validation loss:		0.366843
  validation accuracy:		90.76 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.145895
  validation loss:		0.379858
  validation accuracy:		90.22 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.139300
  validation loss:		0.366966
  validation accuracy:		90.87 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.140754
  validation loss:		0.370670
  validation accuracy:		90.76 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.131717
  validation loss:		0.384698
  validation accuracy:		89.78 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.139699
  validation loss:		0.370160
  validation accuracy:		90.43 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.131900
  validation loss:		0.369528
  validation accuracy:		90.54 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.135937
  validation loss:		0.372951
  validation accuracy:		90.65 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.129340
  validation loss:		0.382706
  validation accuracy:		90.22 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.137198
  validation loss:		0.362600
  validation accuracy:		90.87 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.140485
  validation loss:		0.371937
  validation accuracy:		90.33 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.144777
  validation loss:		0.394392
  validation accuracy:		89.89 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.137930
  validation loss:		0.378292
  validation accuracy:		90.65 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.136618
  validation loss:		0.376846
  validation accuracy:		91.20 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.140695
  validation loss:		0.373283
  validation accuracy:		90.76 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.137736
  validation loss:		0.395516
  validation accuracy:		90.00 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.135450
  validation loss:		0.376795
  validation accuracy:		90.65 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.131762
  validation loss:		0.366934
  validation accuracy:		90.87 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.131130
  validation loss:		0.403919
  validation accuracy:		89.78 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.136626
  validation loss:		0.391500
  validation accuracy:		89.78 %
Epoch 579 of 2000 took 0.098s
  training loss:		0.139307
  validation loss:		0.380446
  validation accuracy:		90.33 %
Epoch 580 of 2000 took 0.100s
  training loss:		0.136524
  validation loss:		0.396923
  validation accuracy:		90.33 %
Epoch 581 of 2000 took 0.100s
  training loss:		0.133363
  validation loss:		0.400056
  validation accuracy:		90.22 %
Epoch 582 of 2000 took 0.100s
  training loss:		0.132676
  validation loss:		0.399833
  validation accuracy:		89.35 %
Epoch 583 of 2000 took 0.100s
  training loss:		0.132211
  validation loss:		0.385897
  validation accuracy:		90.65 %
Epoch 584 of 2000 took 0.100s
  training loss:		0.137045
  validation loss:		0.384225
  validation accuracy:		90.76 %
Epoch 585 of 2000 took 0.100s
  training loss:		0.131595
  validation loss:		0.391820
  validation accuracy:		90.43 %
Epoch 586 of 2000 took 0.101s
  training loss:		0.138115
  validation loss:		0.408003
  validation accuracy:		90.00 %
Epoch 587 of 2000 took 0.100s
  training loss:		0.135789
  validation loss:		0.387433
  validation accuracy:		90.33 %
Epoch 588 of 2000 took 0.100s
  training loss:		0.131481
  validation loss:		0.368669
  validation accuracy:		90.98 %
Epoch 589 of 2000 took 0.100s
  training loss:		0.136415
  validation loss:		0.370778
  validation accuracy:		90.65 %
Epoch 590 of 2000 took 0.100s
  training loss:		0.132693
  validation loss:		0.392727
  validation accuracy:		90.22 %
Epoch 591 of 2000 took 0.100s
  training loss:		0.130503
  validation loss:		0.385068
  validation accuracy:		90.33 %
Epoch 592 of 2000 took 0.100s
  training loss:		0.135902
  validation loss:		0.392704
  validation accuracy:		90.33 %
Epoch 593 of 2000 took 0.100s
  training loss:		0.135607
  validation loss:		0.402381
  validation accuracy:		89.89 %
Epoch 594 of 2000 took 0.100s
  training loss:		0.130999
  validation loss:		0.380483
  validation accuracy:		90.22 %
Epoch 595 of 2000 took 0.100s
  training loss:		0.137172
  validation loss:		0.394163
  validation accuracy:		89.89 %
Epoch 596 of 2000 took 0.100s
  training loss:		0.135801
  validation loss:		0.379727
  validation accuracy:		90.76 %
Epoch 597 of 2000 took 0.100s
  training loss:		0.129045
  validation loss:		0.394335
  validation accuracy:		90.43 %
Epoch 598 of 2000 took 0.100s
  training loss:		0.127924
  validation loss:		0.413609
  validation accuracy:		90.22 %
Epoch 599 of 2000 took 0.100s
  training loss:		0.134897
  validation loss:		0.383198
  validation accuracy:		90.76 %
Epoch 600 of 2000 took 0.100s
  training loss:		0.132838
  validation loss:		0.396792
  validation accuracy:		89.78 %
Epoch 601 of 2000 took 0.098s
  training loss:		0.130708
  validation loss:		0.384355
  validation accuracy:		90.22 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.132031
  validation loss:		0.388770
  validation accuracy:		90.65 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.135275
  validation loss:		0.369865
  validation accuracy:		91.30 %
Epoch 604 of 2000 took 0.100s
  training loss:		0.134274
  validation loss:		0.371973
  validation accuracy:		91.41 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.131905
  validation loss:		0.423943
  validation accuracy:		89.35 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.125134
  validation loss:		0.398539
  validation accuracy:		90.33 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.129397
  validation loss:		0.391892
  validation accuracy:		90.87 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.129355
  validation loss:		0.390319
  validation accuracy:		90.43 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.125332
  validation loss:		0.395596
  validation accuracy:		90.43 %
Epoch 610 of 2000 took 0.097s
  training loss:		0.128778
  validation loss:		0.411022
  validation accuracy:		89.67 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.122813
  validation loss:		0.405293
  validation accuracy:		90.00 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.126649
  validation loss:		0.378198
  validation accuracy:		91.30 %
Epoch 613 of 2000 took 0.097s
  training loss:		0.122718
  validation loss:		0.385800
  validation accuracy:		91.09 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.131315
  validation loss:		0.417631
  validation accuracy:		89.57 %
Epoch 615 of 2000 took 0.097s
  training loss:		0.129746
  validation loss:		0.408494
  validation accuracy:		89.46 %
Epoch 616 of 2000 took 0.098s
  training loss:		0.126838
  validation loss:		0.394087
  validation accuracy:		90.22 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.130206
  validation loss:		0.413592
  validation accuracy:		89.67 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.131890
  validation loss:		0.402037
  validation accuracy:		90.00 %
Epoch 619 of 2000 took 0.097s
  training loss:		0.127283
  validation loss:		0.388602
  validation accuracy:		90.87 %
Epoch 620 of 2000 took 0.097s
  training loss:		0.125481
  validation loss:		0.383927
  validation accuracy:		90.54 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.126240
  validation loss:		0.394776
  validation accuracy:		90.54 %
Epoch 622 of 2000 took 0.097s
  training loss:		0.128345
  validation loss:		0.395008
  validation accuracy:		90.54 %
Epoch 623 of 2000 took 0.097s
  training loss:		0.129588
  validation loss:		0.389773
  validation accuracy:		90.65 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.122192
  validation loss:		0.396939
  validation accuracy:		90.43 %
Epoch 625 of 2000 took 0.097s
  training loss:		0.126232
  validation loss:		0.421253
  validation accuracy:		89.35 %
Epoch 626 of 2000 took 0.097s
  training loss:		0.128919
  validation loss:		0.393094
  validation accuracy:		90.98 %
Epoch 627 of 2000 took 0.097s
  training loss:		0.123931
  validation loss:		0.414457
  validation accuracy:		90.00 %
Epoch 628 of 2000 took 0.097s
  training loss:		0.131813
  validation loss:		0.401258
  validation accuracy:		90.33 %
Epoch 629 of 2000 took 0.097s
  training loss:		0.128764
  validation loss:		0.403867
  validation accuracy:		90.11 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.126381
  validation loss:		0.395396
  validation accuracy:		90.54 %
Epoch 631 of 2000 took 0.097s
  training loss:		0.136662
  validation loss:		0.437802
  validation accuracy:		88.91 %
Epoch 632 of 2000 took 0.097s
  training loss:		0.124926
  validation loss:		0.403171
  validation accuracy:		90.33 %
Epoch 633 of 2000 took 0.097s
  training loss:		0.134124
  validation loss:		0.431175
  validation accuracy:		89.35 %
Epoch 634 of 2000 took 0.097s
  training loss:		0.129710
  validation loss:		0.417371
  validation accuracy:		89.67 %
Epoch 635 of 2000 took 0.097s
  training loss:		0.124876
  validation loss:		0.404542
  validation accuracy:		90.33 %
Epoch 636 of 2000 took 0.097s
  training loss:		0.133851
  validation loss:		0.405512
  validation accuracy:		89.89 %
Epoch 637 of 2000 took 0.097s
  training loss:		0.125681
  validation loss:		0.393924
  validation accuracy:		90.98 %
Epoch 638 of 2000 took 0.097s
  training loss:		0.128184
  validation loss:		0.402844
  validation accuracy:		90.11 %
Epoch 639 of 2000 took 0.097s
  training loss:		0.123358
  validation loss:		0.418182
  validation accuracy:		89.57 %
Epoch 640 of 2000 took 0.097s
  training loss:		0.123818
  validation loss:		0.385974
  validation accuracy:		91.30 %
Epoch 641 of 2000 took 0.097s
  training loss:		0.122495
  validation loss:		0.430916
  validation accuracy:		89.67 %
Epoch 642 of 2000 took 0.097s
  training loss:		0.123933
  validation loss:		0.396623
  validation accuracy:		90.87 %
Epoch 643 of 2000 took 0.097s
  training loss:		0.127269
  validation loss:		0.410521
  validation accuracy:		90.33 %
Epoch 644 of 2000 took 0.097s
  training loss:		0.125147
  validation loss:		0.393141
  validation accuracy:		91.20 %
Epoch 645 of 2000 took 0.097s
  training loss:		0.122822
  validation loss:		0.397717
  validation accuracy:		90.76 %
Epoch 646 of 2000 took 0.097s
  training loss:		0.123049
  validation loss:		0.397579
  validation accuracy:		90.54 %
Epoch 647 of 2000 took 0.098s
  training loss:		0.120718
  validation loss:		0.411168
  validation accuracy:		90.33 %
Epoch 648 of 2000 took 0.098s
  training loss:		0.115735
  validation loss:		0.422730
  validation accuracy:		90.33 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.124525
  validation loss:		0.404620
  validation accuracy:		90.65 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.126696
  validation loss:		0.419333
  validation accuracy:		89.67 %
Epoch 651 of 2000 took 0.097s
  training loss:		0.122302
  validation loss:		0.402333
  validation accuracy:		90.43 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.126172
  validation loss:		0.399104
  validation accuracy:		90.98 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.122099
  validation loss:		0.406280
  validation accuracy:		90.87 %
Epoch 654 of 2000 took 0.097s
  training loss:		0.125845
  validation loss:		0.431055
  validation accuracy:		90.43 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.129385
  validation loss:		0.391725
  validation accuracy:		91.09 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.125729
  validation loss:		0.395910
  validation accuracy:		90.43 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.126007
  validation loss:		0.411911
  validation accuracy:		90.22 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.118635
  validation loss:		0.424518
  validation accuracy:		90.54 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.123192
  validation loss:		0.406566
  validation accuracy:		90.43 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.123412
  validation loss:		0.425459
  validation accuracy:		89.57 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.126595
  validation loss:		0.412978
  validation accuracy:		90.33 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.122256
  validation loss:		0.436302
  validation accuracy:		89.67 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.114457
  validation loss:		0.420568
  validation accuracy:		89.78 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.124670
  validation loss:		0.421038
  validation accuracy:		89.89 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.118605
  validation loss:		0.413109
  validation accuracy:		90.33 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.122792
  validation loss:		0.418566
  validation accuracy:		90.00 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.118481
  validation loss:		0.409060
  validation accuracy:		90.54 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.122315
  validation loss:		0.435971
  validation accuracy:		89.35 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.119101
  validation loss:		0.408296
  validation accuracy:		90.65 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.122717
  validation loss:		0.420579
  validation accuracy:		90.54 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.123862
  validation loss:		0.402733
  validation accuracy:		90.43 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.119092
  validation loss:		0.419242
  validation accuracy:		90.33 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.125886
  validation loss:		0.411931
  validation accuracy:		90.11 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.126485
  validation loss:		0.412772
  validation accuracy:		90.22 %
Epoch 675 of 2000 took 0.097s
  training loss:		0.120832
  validation loss:		0.407695
  validation accuracy:		90.98 %
Epoch 676 of 2000 took 0.097s
  training loss:		0.118412
  validation loss:		0.405253
  validation accuracy:		90.76 %
Epoch 677 of 2000 took 0.097s
  training loss:		0.115725
  validation loss:		0.408809
  validation accuracy:		90.76 %
Epoch 678 of 2000 took 0.097s
  training loss:		0.121036
  validation loss:		0.415452
  validation accuracy:		90.54 %
Epoch 679 of 2000 took 0.098s
  training loss:		0.121296
  validation loss:		0.420491
  validation accuracy:		90.33 %
Epoch 680 of 2000 took 0.097s
  training loss:		0.117894
  validation loss:		0.408239
  validation accuracy:		90.76 %
Epoch 681 of 2000 took 0.097s
  training loss:		0.123332
  validation loss:		0.415962
  validation accuracy:		90.00 %
Epoch 682 of 2000 took 0.097s
  training loss:		0.117634
  validation loss:		0.408126
  validation accuracy:		90.87 %
Epoch 683 of 2000 took 0.097s
  training loss:		0.115314
  validation loss:		0.436857
  validation accuracy:		89.02 %
Epoch 684 of 2000 took 0.097s
  training loss:		0.123077
  validation loss:		0.412897
  validation accuracy:		90.54 %
Epoch 685 of 2000 took 0.097s
  training loss:		0.121286
  validation loss:		0.420013
  validation accuracy:		90.00 %
Epoch 686 of 2000 took 0.097s
  training loss:		0.125924
  validation loss:		0.411747
  validation accuracy:		91.20 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.119260
  validation loss:		0.403859
  validation accuracy:		91.09 %
Epoch 688 of 2000 took 0.097s
  training loss:		0.115563
  validation loss:		0.452113
  validation accuracy:		89.67 %
Epoch 689 of 2000 took 0.097s
  training loss:		0.117187
  validation loss:		0.403428
  validation accuracy:		90.87 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.121470
  validation loss:		0.424915
  validation accuracy:		90.65 %
Epoch 691 of 2000 took 0.097s
  training loss:		0.123370
  validation loss:		0.420750
  validation accuracy:		90.43 %
Epoch 692 of 2000 took 0.097s
  training loss:		0.119839
  validation loss:		0.427794
  validation accuracy:		90.11 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.117425
  validation loss:		0.422468
  validation accuracy:		90.65 %
Epoch 694 of 2000 took 0.097s
  training loss:		0.118958
  validation loss:		0.462184
  validation accuracy:		89.46 %
Epoch 695 of 2000 took 0.097s
  training loss:		0.116328
  validation loss:		0.398354
  validation accuracy:		90.98 %
Epoch 696 of 2000 took 0.097s
  training loss:		0.116348
  validation loss:		0.421325
  validation accuracy:		90.65 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.114426
  validation loss:		0.434340
  validation accuracy:		89.57 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.117461
  validation loss:		0.404708
  validation accuracy:		90.76 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.120660
  validation loss:		0.430830
  validation accuracy:		89.78 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.115455
  validation loss:		0.425263
  validation accuracy:		90.54 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.118842
  validation loss:		0.425686
  validation accuracy:		89.78 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.115037
  validation loss:		0.432846
  validation accuracy:		90.22 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.111904
  validation loss:		0.424137
  validation accuracy:		90.11 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.116655
  validation loss:		0.417465
  validation accuracy:		90.54 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.115230
  validation loss:		0.408612
  validation accuracy:		90.87 %
Epoch 706 of 2000 took 0.097s
  training loss:		0.118676
  validation loss:		0.439405
  validation accuracy:		90.65 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.113647
  validation loss:		0.411985
  validation accuracy:		91.20 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.113957
  validation loss:		0.426696
  validation accuracy:		90.54 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.117955
  validation loss:		0.428052
  validation accuracy:		90.54 %
Epoch 710 of 2000 took 0.098s
  training loss:		0.107064
  validation loss:		0.443046
  validation accuracy:		89.78 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.115208
  validation loss:		0.437872
  validation accuracy:		90.54 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.115430
  validation loss:		0.421146
  validation accuracy:		90.98 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.109743
  validation loss:		0.424201
  validation accuracy:		90.87 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.111987
  validation loss:		0.437932
  validation accuracy:		89.67 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.114664
  validation loss:		0.420067
  validation accuracy:		90.98 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.111578
  validation loss:		0.440888
  validation accuracy:		89.89 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.117330
  validation loss:		0.400730
  validation accuracy:		91.09 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.112861
  validation loss:		0.445158
  validation accuracy:		89.89 %
Epoch 719 of 2000 took 0.097s
  training loss:		0.114259
  validation loss:		0.423196
  validation accuracy:		90.54 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.114442
  validation loss:		0.420898
  validation accuracy:		91.30 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.111423
  validation loss:		0.430516
  validation accuracy:		90.65 %
Epoch 722 of 2000 took 0.099s
  training loss:		0.114354
  validation loss:		0.433086
  validation accuracy:		90.54 %
Epoch 723 of 2000 took 0.104s
  training loss:		0.114410
  validation loss:		0.423519
  validation accuracy:		90.43 %
Epoch 724 of 2000 took 0.103s
  training loss:		0.116809
  validation loss:		0.433748
  validation accuracy:		90.65 %
Epoch 725 of 2000 took 0.098s
  training loss:		0.115214
  validation loss:		0.407517
  validation accuracy:		91.52 %
Epoch 726 of 2000 took 0.097s
  training loss:		0.112160
  validation loss:		0.453312
  validation accuracy:		89.78 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.112466
  validation loss:		0.462276
  validation accuracy:		89.57 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.111681
  validation loss:		0.415285
  validation accuracy:		91.30 %
Epoch 729 of 2000 took 0.097s
  training loss:		0.111803
  validation loss:		0.442926
  validation accuracy:		90.65 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.114182
  validation loss:		0.448857
  validation accuracy:		89.78 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.109848
  validation loss:		0.437147
  validation accuracy:		90.43 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.108841
  validation loss:		0.467357
  validation accuracy:		89.24 %
Epoch 733 of 2000 took 0.099s
  training loss:		0.109397
  validation loss:		0.437009
  validation accuracy:		90.00 %
Epoch 734 of 2000 took 0.100s
  training loss:		0.116401
  validation loss:		0.440858
  validation accuracy:		89.46 %
Epoch 735 of 2000 took 0.100s
  training loss:		0.106365
  validation loss:		0.464367
  validation accuracy:		89.89 %
Epoch 736 of 2000 took 0.100s
  training loss:		0.107975
  validation loss:		0.422050
  validation accuracy:		90.87 %
Epoch 737 of 2000 took 0.100s
  training loss:		0.114583
  validation loss:		0.446222
  validation accuracy:		90.33 %
Epoch 738 of 2000 took 0.100s
  training loss:		0.114587
  validation loss:		0.421419
  validation accuracy:		90.98 %
Epoch 739 of 2000 took 0.100s
  training loss:		0.109283
  validation loss:		0.445957
  validation accuracy:		90.43 %
Epoch 740 of 2000 took 0.101s
  training loss:		0.114694
  validation loss:		0.439399
  validation accuracy:		90.11 %
Epoch 741 of 2000 took 0.103s
  training loss:		0.110477
  validation loss:		0.444991
  validation accuracy:		89.89 %
Epoch 742 of 2000 took 0.107s
  training loss:		0.110656
  validation loss:		0.442079
  validation accuracy:		90.65 %
Epoch 743 of 2000 took 0.111s
  training loss:		0.108788
  validation loss:		0.445159
  validation accuracy:		89.78 %
Epoch 744 of 2000 took 0.136s
  training loss:		0.105978
  validation loss:		0.442063
  validation accuracy:		90.33 %
Epoch 745 of 2000 took 0.116s
  training loss:		0.114264
  validation loss:		0.433433
  validation accuracy:		90.76 %
Epoch 746 of 2000 took 0.102s
  training loss:		0.110544
  validation loss:		0.434478
  validation accuracy:		90.33 %
Epoch 747 of 2000 took 0.106s
  training loss:		0.100722
  validation loss:		0.441005
  validation accuracy:		90.11 %
Epoch 748 of 2000 took 0.107s
  training loss:		0.113322
  validation loss:		0.455536
  validation accuracy:		90.11 %
Epoch 749 of 2000 took 0.106s
  training loss:		0.105932
  validation loss:		0.434372
  validation accuracy:		90.43 %
Epoch 750 of 2000 took 0.105s
  training loss:		0.111439
  validation loss:		0.431878
  validation accuracy:		90.43 %
Epoch 751 of 2000 took 0.104s
  training loss:		0.108051
  validation loss:		0.428879
  validation accuracy:		90.65 %
Epoch 752 of 2000 took 0.102s
  training loss:		0.112021
  validation loss:		0.436305
  validation accuracy:		90.33 %
Epoch 753 of 2000 took 0.101s
  training loss:		0.106482
  validation loss:		0.431152
  validation accuracy:		90.76 %
Epoch 754 of 2000 took 0.101s
  training loss:		0.110403
  validation loss:		0.449294
  validation accuracy:		90.00 %
Epoch 755 of 2000 took 0.101s
  training loss:		0.109888
  validation loss:		0.433056
  validation accuracy:		90.43 %
Epoch 756 of 2000 took 0.102s
  training loss:		0.105512
  validation loss:		0.436454
  validation accuracy:		90.76 %
Epoch 757 of 2000 took 0.107s
  training loss:		0.101949
  validation loss:		0.430986
  validation accuracy:		90.87 %
Epoch 758 of 2000 took 0.101s
  training loss:		0.104898
  validation loss:		0.438167
  validation accuracy:		90.98 %
Epoch 759 of 2000 took 0.101s
  training loss:		0.105844
  validation loss:		0.474643
  validation accuracy:		89.46 %
Epoch 760 of 2000 took 0.101s
  training loss:		0.112183
  validation loss:		0.467133
  validation accuracy:		89.89 %
Epoch 761 of 2000 took 0.101s
  training loss:		0.100656
  validation loss:		0.434735
  validation accuracy:		90.76 %
Epoch 762 of 2000 took 0.101s
  training loss:		0.104090
  validation loss:		0.468612
  validation accuracy:		89.67 %
Epoch 763 of 2000 took 0.101s
  training loss:		0.108078
  validation loss:		0.426911
  validation accuracy:		90.98 %
Epoch 764 of 2000 took 0.102s
  training loss:		0.111355
  validation loss:		0.438488
  validation accuracy:		90.76 %
Epoch 765 of 2000 took 0.100s
  training loss:		0.107593
  validation loss:		0.452023
  validation accuracy:		90.87 %
Epoch 766 of 2000 took 0.101s
  training loss:		0.113797
  validation loss:		0.447924
  validation accuracy:		90.11 %
Epoch 767 of 2000 took 0.101s
  training loss:		0.104950
  validation loss:		0.433330
  validation accuracy:		90.98 %
Epoch 768 of 2000 took 0.101s
  training loss:		0.109059
  validation loss:		0.491987
  validation accuracy:		88.80 %
Epoch 769 of 2000 took 0.102s
  training loss:		0.104983
  validation loss:		0.441630
  validation accuracy:		91.09 %
Epoch 770 of 2000 took 0.101s
  training loss:		0.105690
  validation loss:		0.468294
  validation accuracy:		89.89 %
Epoch 771 of 2000 took 0.101s
  training loss:		0.111263
  validation loss:		0.514628
  validation accuracy:		90.00 %
Epoch 772 of 2000 took 0.100s
  training loss:		0.121490
  validation loss:		0.433955
  validation accuracy:		90.87 %
Epoch 773 of 2000 took 0.101s
  training loss:		0.106415
  validation loss:		0.451548
  validation accuracy:		90.43 %
Epoch 774 of 2000 took 0.101s
  training loss:		0.105663
  validation loss:		0.454622
  validation accuracy:		90.87 %
Epoch 775 of 2000 took 0.101s
  training loss:		0.106720
  validation loss:		0.447618
  validation accuracy:		90.43 %
Epoch 776 of 2000 took 0.101s
  training loss:		0.108110
  validation loss:		0.449694
  validation accuracy:		90.76 %
Epoch 777 of 2000 took 0.101s
  training loss:		0.107035
  validation loss:		0.478053
  validation accuracy:		89.24 %
Epoch 778 of 2000 took 0.101s
  training loss:		0.106999
  validation loss:		0.456473
  validation accuracy:		90.65 %
Epoch 779 of 2000 took 0.101s
  training loss:		0.103120
  validation loss:		0.455757
  validation accuracy:		90.33 %
Epoch 780 of 2000 took 0.101s
  training loss:		0.105600
  validation loss:		0.451982
  validation accuracy:		90.43 %
Epoch 781 of 2000 took 0.101s
  training loss:		0.105060
  validation loss:		0.448012
  validation accuracy:		90.76 %
Epoch 782 of 2000 took 0.101s
  training loss:		0.108669
  validation loss:		0.442125
  validation accuracy:		90.87 %
Epoch 783 of 2000 took 0.103s
  training loss:		0.106249
  validation loss:		0.467796
  validation accuracy:		90.22 %
Epoch 784 of 2000 took 0.101s
  training loss:		0.109994
  validation loss:		0.449322
  validation accuracy:		90.76 %
Epoch 785 of 2000 took 0.160s
  training loss:		0.103922
  validation loss:		0.466349
  validation accuracy:		89.78 %
Epoch 786 of 2000 took 0.162s
  training loss:		0.104698
  validation loss:		0.457034
  validation accuracy:		90.43 %
Epoch 787 of 2000 took 0.165s
  training loss:		0.102101
  validation loss:		0.478856
  validation accuracy:		89.67 %
Epoch 788 of 2000 took 0.165s
  training loss:		0.103215
  validation loss:		0.453748
  validation accuracy:		90.65 %
Epoch 789 of 2000 took 0.165s
  training loss:		0.103291
  validation loss:		0.457670
  validation accuracy:		90.65 %
Epoch 790 of 2000 took 0.165s
  training loss:		0.104975
  validation loss:		0.454308
  validation accuracy:		90.65 %
Epoch 791 of 2000 took 0.161s
  training loss:		0.102963
  validation loss:		0.476633
  validation accuracy:		89.46 %
Epoch 792 of 2000 took 0.166s
  training loss:		0.109047
  validation loss:		0.475039
  validation accuracy:		90.22 %
Epoch 793 of 2000 took 0.166s
  training loss:		0.099917
  validation loss:		0.475093
  validation accuracy:		90.00 %
Epoch 794 of 2000 took 0.165s
  training loss:		0.105195
  validation loss:		0.483608
  validation accuracy:		89.67 %
Epoch 795 of 2000 took 0.165s
  training loss:		0.103552
  validation loss:		0.441878
  validation accuracy:		90.98 %
Epoch 796 of 2000 took 0.165s
  training loss:		0.104368
  validation loss:		0.460089
  validation accuracy:		90.76 %
Epoch 797 of 2000 took 0.165s
  training loss:		0.101641
  validation loss:		0.480591
  validation accuracy:		90.00 %
Epoch 798 of 2000 took 0.232s
  training loss:		0.105587
  validation loss:		0.469541
  validation accuracy:		89.35 %
Epoch 799 of 2000 took 0.330s
  training loss:		0.100959
  validation loss:		0.455231
  validation accuracy:		91.09 %
Epoch 800 of 2000 took 0.201s
  training loss:		0.101575
  validation loss:		0.478537
  validation accuracy:		89.78 %
Epoch 801 of 2000 took 0.322s
  training loss:		0.097487
  validation loss:		0.470355
  validation accuracy:		90.33 %
Epoch 802 of 2000 took 0.166s
  training loss:		0.110642
  validation loss:		0.497842
  validation accuracy:		89.78 %
Epoch 803 of 2000 took 0.166s
  training loss:		0.101750
  validation loss:		0.448993
  validation accuracy:		90.76 %
Epoch 804 of 2000 took 0.166s
  training loss:		0.097973
  validation loss:		0.468243
  validation accuracy:		89.89 %
Epoch 805 of 2000 took 0.166s
  training loss:		0.095921
  validation loss:		0.462095
  validation accuracy:		90.76 %
Epoch 806 of 2000 took 0.166s
  training loss:		0.104142
  validation loss:		0.486915
  validation accuracy:		89.57 %
Epoch 807 of 2000 took 0.166s
  training loss:		0.104388
  validation loss:		0.462808
  validation accuracy:		90.43 %
Epoch 808 of 2000 took 0.166s
  training loss:		0.097419
  validation loss:		0.480899
  validation accuracy:		90.11 %
Epoch 809 of 2000 took 0.166s
  training loss:		0.096608
  validation loss:		0.467760
  validation accuracy:		90.43 %
Epoch 810 of 2000 took 0.166s
  training loss:		0.100580
  validation loss:		0.489755
  validation accuracy:		89.67 %
Epoch 811 of 2000 took 0.166s
  training loss:		0.095502
  validation loss:		0.510231
  validation accuracy:		89.35 %
Epoch 812 of 2000 took 0.166s
  training loss:		0.105055
  validation loss:		0.468454
  validation accuracy:		90.22 %
Epoch 813 of 2000 took 0.244s
  training loss:		0.101427
  validation loss:		0.449845
  validation accuracy:		90.87 %
Epoch 814 of 2000 took 0.217s
  training loss:		0.102134
  validation loss:		0.502745
  validation accuracy:		89.57 %
Epoch 815 of 2000 took 0.165s
  training loss:		0.111494
  validation loss:		0.489558
  validation accuracy:		89.24 %
Epoch 816 of 2000 took 0.165s
  training loss:		0.107919
  validation loss:		0.450878
  validation accuracy:		90.76 %
Epoch 817 of 2000 took 0.165s
  training loss:		0.106587
  validation loss:		0.465112
  validation accuracy:		90.65 %
Epoch 818 of 2000 took 0.165s
  training loss:		0.093602
  validation loss:		0.456067
  validation accuracy:		90.76 %
Epoch 819 of 2000 took 0.166s
  training loss:		0.095296
  validation loss:		0.462009
  validation accuracy:		90.76 %
Epoch 820 of 2000 took 0.165s
  training loss:		0.097288
  validation loss:		0.476023
  validation accuracy:		90.54 %
Epoch 821 of 2000 took 0.166s
  training loss:		0.106466
  validation loss:		0.497865
  validation accuracy:		89.57 %
Epoch 822 of 2000 took 0.165s
  training loss:		0.105997
  validation loss:		0.480321
  validation accuracy:		90.54 %
Epoch 823 of 2000 took 0.166s
  training loss:		0.097121
  validation loss:		0.466700
  validation accuracy:		89.67 %
Epoch 824 of 2000 took 0.166s
  training loss:		0.101032
  validation loss:		0.471122
  validation accuracy:		90.43 %
Epoch 825 of 2000 took 0.165s
  training loss:		0.096920
  validation loss:		0.499986
  validation accuracy:		89.78 %
Epoch 826 of 2000 took 0.178s
  training loss:		0.099735
  validation loss:		0.465533
  validation accuracy:		91.20 %
Epoch 827 of 2000 took 0.191s
  training loss:		0.097069
  validation loss:		0.492300
  validation accuracy:		89.67 %
Epoch 828 of 2000 took 0.192s
  training loss:		0.100472
  validation loss:		0.464736
  validation accuracy:		90.76 %
Epoch 829 of 2000 took 0.213s
  training loss:		0.096408
  validation loss:		0.471867
  validation accuracy:		90.98 %
Epoch 830 of 2000 took 0.167s
  training loss:		0.095960
  validation loss:		0.488801
  validation accuracy:		89.89 %
Epoch 831 of 2000 took 0.165s
  training loss:		0.094133
  validation loss:		0.476914
  validation accuracy:		90.22 %
Epoch 832 of 2000 took 0.165s
  training loss:		0.102749
  validation loss:		0.493501
  validation accuracy:		90.22 %
Epoch 833 of 2000 took 0.165s
  training loss:		0.104952
  validation loss:		0.482167
  validation accuracy:		89.78 %
Epoch 834 of 2000 took 0.165s
  training loss:		0.097496
  validation loss:		0.491190
  validation accuracy:		89.67 %
Epoch 835 of 2000 took 0.165s
  training loss:		0.101565
  validation loss:		0.463923
  validation accuracy:		91.20 %
Epoch 836 of 2000 took 0.165s
  training loss:		0.103051
  validation loss:		0.476399
  validation accuracy:		90.43 %
Epoch 837 of 2000 took 0.166s
  training loss:		0.098704
  validation loss:		0.508213
  validation accuracy:		89.46 %
Epoch 838 of 2000 took 0.192s
  training loss:		0.102869
  validation loss:		0.492153
  validation accuracy:		90.11 %
Epoch 839 of 2000 took 0.192s
  training loss:		0.094973
  validation loss:		0.475353
  validation accuracy:		90.43 %
Epoch 840 of 2000 took 0.182s
  training loss:		0.103951
  validation loss:		0.489572
  validation accuracy:		90.00 %
Epoch 841 of 2000 took 0.166s
  training loss:		0.092282
  validation loss:		0.477075
  validation accuracy:		90.65 %
Epoch 842 of 2000 took 0.165s
  training loss:		0.103959
  validation loss:		0.494327
  validation accuracy:		89.67 %
Epoch 843 of 2000 took 0.165s
  training loss:		0.106166
  validation loss:		0.481430
  validation accuracy:		89.67 %
Epoch 844 of 2000 took 0.166s
  training loss:		0.100832
  validation loss:		0.470415
  validation accuracy:		90.33 %
Epoch 845 of 2000 took 0.166s
  training loss:		0.104055
  validation loss:		0.494309
  validation accuracy:		89.57 %
Epoch 846 of 2000 took 0.165s
  training loss:		0.103019
  validation loss:		0.487179
  validation accuracy:		90.76 %
Epoch 847 of 2000 took 0.165s
  training loss:		0.096982
  validation loss:		0.483443
  validation accuracy:		90.76 %
Epoch 848 of 2000 took 0.165s
  training loss:		0.095665
  validation loss:		0.478782
  validation accuracy:		90.54 %
Epoch 849 of 2000 took 0.190s
  training loss:		0.094851
  validation loss:		0.473338
  validation accuracy:		90.43 %
Epoch 850 of 2000 took 0.192s
  training loss:		0.100068
  validation loss:		0.489331
  validation accuracy:		90.43 %
Epoch 851 of 2000 took 0.191s
  training loss:		0.097524
  validation loss:		0.484113
  validation accuracy:		90.54 %
Epoch 852 of 2000 took 0.166s
  training loss:		0.097506
  validation loss:		0.499356
  validation accuracy:		89.57 %
Epoch 853 of 2000 took 0.165s
  training loss:		0.093304
  validation loss:		0.501484
  validation accuracy:		89.02 %
Epoch 854 of 2000 took 0.165s
  training loss:		0.100077
  validation loss:		0.482834
  validation accuracy:		90.33 %
Epoch 855 of 2000 took 0.165s
  training loss:		0.088908
  validation loss:		0.509764
  validation accuracy:		90.00 %
Epoch 856 of 2000 took 0.165s
  training loss:		0.088244
  validation loss:		0.503019
  validation accuracy:		89.78 %
Epoch 857 of 2000 took 0.165s
  training loss:		0.097433
  validation loss:		0.485046
  validation accuracy:		90.43 %
Epoch 858 of 2000 took 0.165s
  training loss:		0.095220
  validation loss:		0.489153
  validation accuracy:		90.00 %
Epoch 859 of 2000 took 0.166s
  training loss:		0.093287
  validation loss:		0.494993
  validation accuracy:		90.11 %
Epoch 860 of 2000 took 0.190s
  training loss:		0.090268
  validation loss:		0.537196
  validation accuracy:		89.13 %
Epoch 861 of 2000 took 0.187s
  training loss:		0.098724
  validation loss:		0.500529
  validation accuracy:		89.57 %
Epoch 862 of 2000 took 0.204s
  training loss:		0.099083
  validation loss:		0.494806
  validation accuracy:		90.54 %
Epoch 863 of 2000 took 0.196s
  training loss:		0.089825
  validation loss:		0.492975
  validation accuracy:		90.43 %
Epoch 864 of 2000 took 0.200s
  training loss:		0.093502
  validation loss:		0.512019
  validation accuracy:		90.11 %
Epoch 865 of 2000 took 0.192s
  training loss:		0.096372
  validation loss:		0.503554
  validation accuracy:		89.57 %
Epoch 866 of 2000 took 0.207s
  training loss:		0.093277
  validation loss:		0.510597
  validation accuracy:		89.35 %
Epoch 867 of 2000 took 0.210s
  training loss:		0.089527
  validation loss:		0.477884
  validation accuracy:		90.43 %
Epoch 868 of 2000 took 0.197s
  training loss:		0.088243
  validation loss:		0.498120
  validation accuracy:		89.89 %
Epoch 869 of 2000 took 0.198s
  training loss:		0.090724
  validation loss:		0.488699
  validation accuracy:		90.33 %
Epoch 870 of 2000 took 0.246s
  training loss:		0.102748
  validation loss:		0.507310
  validation accuracy:		90.00 %
Epoch 871 of 2000 took 0.197s
  training loss:		0.100185
  validation loss:		0.550987
  validation accuracy:		88.80 %
Epoch 872 of 2000 took 0.192s
  training loss:		0.092735
  validation loss:		0.505702
  validation accuracy:		89.78 %
Epoch 873 of 2000 took 0.210s
  training loss:		0.092406
  validation loss:		0.504314
  validation accuracy:		89.13 %
Epoch 874 of 2000 took 0.206s
  training loss:		0.091087
  validation loss:		0.496954
  validation accuracy:		89.24 %
Epoch 875 of 2000 took 0.196s
  training loss:		0.090645
  validation loss:		0.534372
  validation accuracy:		89.67 %
Epoch 876 of 2000 took 0.197s
  training loss:		0.098663
  validation loss:		0.521427
  validation accuracy:		89.46 %
Epoch 877 of 2000 took 0.192s
  training loss:		0.094463
  validation loss:		0.508783
  validation accuracy:		89.67 %
Epoch 878 of 2000 took 0.202s
  training loss:		0.088212
  validation loss:		0.504911
  validation accuracy:		90.22 %
Epoch 879 of 2000 took 0.251s
  training loss:		0.090500
  validation loss:		0.511649
  validation accuracy:		89.02 %
Epoch 880 of 2000 took 0.225s
  training loss:		0.090007
  validation loss:		0.518196
  validation accuracy:		89.67 %
Epoch 881 of 2000 took 0.241s
  training loss:		0.086180
  validation loss:		0.514453
  validation accuracy:		89.89 %
Epoch 882 of 2000 took 0.241s
  training loss:		0.103735
  validation loss:		0.526554
  validation accuracy:		89.78 %
Epoch 883 of 2000 took 0.203s
  training loss:		0.094010
  validation loss:		0.517962
  validation accuracy:		89.46 %
Epoch 884 of 2000 took 0.191s
  training loss:		0.094743
  validation loss:		0.490684
  validation accuracy:		90.11 %
Epoch 885 of 2000 took 0.202s
  training loss:		0.088880
  validation loss:		0.539530
  validation accuracy:		88.80 %
Epoch 886 of 2000 took 0.193s
  training loss:		0.094978
  validation loss:		0.529993
  validation accuracy:		89.02 %
Epoch 887 of 2000 took 0.193s
  training loss:		0.089844
  validation loss:		0.530114
  validation accuracy:		89.78 %
Epoch 888 of 2000 took 0.220s
  training loss:		0.092399
  validation loss:		0.499257
  validation accuracy:		90.22 %
Epoch 889 of 2000 took 0.197s
  training loss:		0.091385
  validation loss:		0.541369
  validation accuracy:		88.91 %
Epoch 890 of 2000 took 0.200s
  training loss:		0.088822
  validation loss:		0.524343
  validation accuracy:		90.00 %
Epoch 891 of 2000 took 0.195s
  training loss:		0.099484
  validation loss:		0.519537
  validation accuracy:		89.35 %
Epoch 892 of 2000 took 0.200s
  training loss:		0.086111
  validation loss:		0.533920
  validation accuracy:		89.78 %
Epoch 893 of 2000 took 0.194s
  training loss:		0.091857
  validation loss:		0.520047
  validation accuracy:		89.13 %
Epoch 894 of 2000 took 0.192s
  training loss:		0.096098
  validation loss:		0.494195
  validation accuracy:		90.54 %
Epoch 895 of 2000 took 0.392s
  training loss:		0.088161
  validation loss:		0.517338
  validation accuracy:		90.54 %
Epoch 896 of 2000 took 0.180s
  training loss:		0.086465
  validation loss:		0.522754
  validation accuracy:		89.57 %
Epoch 897 of 2000 took 0.231s
  training loss:		0.088301
  validation loss:		0.497680
  validation accuracy:		90.22 %
Epoch 898 of 2000 took 0.198s
  training loss:		0.088171
  validation loss:		0.541643
  validation accuracy:		88.91 %
Epoch 899 of 2000 took 0.196s
  training loss:		0.090886
  validation loss:		0.500984
  validation accuracy:		90.43 %
Epoch 900 of 2000 took 0.199s
  training loss:		0.091748
  validation loss:		0.525525
  validation accuracy:		89.46 %
Epoch 901 of 2000 took 0.191s
  training loss:		0.086443
  validation loss:		0.537666
  validation accuracy:		89.02 %
Epoch 902 of 2000 took 0.207s
  training loss:		0.088014
  validation loss:		0.505750
  validation accuracy:		89.35 %
Epoch 903 of 2000 took 0.209s
  training loss:		0.091604
  validation loss:		0.523703
  validation accuracy:		88.91 %
Epoch 904 of 2000 took 0.197s
  training loss:		0.087257
  validation loss:		0.521088
  validation accuracy:		89.35 %
Epoch 905 of 2000 took 0.213s
  training loss:		0.086564
  validation loss:		0.543882
  validation accuracy:		89.13 %
Epoch 906 of 2000 took 0.194s
  training loss:		0.101338
  validation loss:		0.552600
  validation accuracy:		88.80 %
Epoch 907 of 2000 took 0.201s
  training loss:		0.086540
  validation loss:		0.499001
  validation accuracy:		90.76 %
Epoch 908 of 2000 took 0.192s
  training loss:		0.086145
  validation loss:		0.520578
  validation accuracy:		90.54 %
Epoch 909 of 2000 took 0.201s
  training loss:		0.090309
  validation loss:		0.571407
  validation accuracy:		87.93 %
Epoch 910 of 2000 took 0.389s
  training loss:		0.090057
  validation loss:		0.542570
  validation accuracy:		89.67 %
Epoch 911 of 2000 took 0.166s
  training loss:		0.090982
  validation loss:		0.508836
  validation accuracy:		90.00 %
Epoch 912 of 2000 took 0.166s
  training loss:		0.092146
  validation loss:		0.540554
  validation accuracy:		89.89 %
Epoch 913 of 2000 took 0.159s
  training loss:		0.094403
  validation loss:		0.500663
  validation accuracy:		90.98 %
Epoch 914 of 2000 took 0.108s
  training loss:		0.087572
  validation loss:		0.516948
  validation accuracy:		89.57 %
Epoch 915 of 2000 took 0.105s
  training loss:		0.088697
  validation loss:		0.546452
  validation accuracy:		89.24 %
Epoch 916 of 2000 took 0.111s
  training loss:		0.089680
  validation loss:		0.553657
  validation accuracy:		89.02 %
Epoch 917 of 2000 took 0.113s
  training loss:		0.095111
  validation loss:		0.564193
  validation accuracy:		88.59 %
Epoch 918 of 2000 took 0.110s
  training loss:		0.086303
  validation loss:		0.539596
  validation accuracy:		89.57 %
Epoch 919 of 2000 took 0.109s
  training loss:		0.084860
  validation loss:		0.512031
  validation accuracy:		90.22 %
Epoch 920 of 2000 took 0.105s
  training loss:		0.087821
  validation loss:		0.542597
  validation accuracy:		89.35 %
Epoch 921 of 2000 took 0.110s
  training loss:		0.092380
  validation loss:		0.529573
  validation accuracy:		90.87 %
Epoch 922 of 2000 took 0.110s
  training loss:		0.088214
  validation loss:		0.555362
  validation accuracy:		89.13 %
Epoch 923 of 2000 took 0.105s
  training loss:		0.082738
  validation loss:		0.509569
  validation accuracy:		90.43 %
Epoch 924 of 2000 took 0.109s
  training loss:		0.086144
  validation loss:		0.525277
  validation accuracy:		89.67 %
Epoch 925 of 2000 took 0.111s
  training loss:		0.086756
  validation loss:		0.580596
  validation accuracy:		88.59 %
Epoch 926 of 2000 took 0.106s
  training loss:		0.088641
  validation loss:		0.538802
  validation accuracy:		90.11 %
Epoch 927 of 2000 took 0.108s
  training loss:		0.088103
  validation loss:		0.528804
  validation accuracy:		90.33 %
Epoch 928 of 2000 took 0.105s
  training loss:		0.089116
  validation loss:		0.528265
  validation accuracy:		90.33 %
Epoch 929 of 2000 took 0.110s
  training loss:		0.081975
  validation loss:		0.546960
  validation accuracy:		89.89 %
Epoch 930 of 2000 took 0.115s
  training loss:		0.084747
  validation loss:		0.522042
  validation accuracy:		89.89 %
Epoch 931 of 2000 took 0.109s
  training loss:		0.085667
  validation loss:		0.539127
  validation accuracy:		89.89 %
Epoch 932 of 2000 took 0.108s
  training loss:		0.083303
  validation loss:		0.548020
  validation accuracy:		89.67 %
Epoch 933 of 2000 took 0.114s
  training loss:		0.081952
  validation loss:		0.561381
  validation accuracy:		89.13 %
Epoch 934 of 2000 took 0.108s
  training loss:		0.086217
  validation loss:		0.586051
  validation accuracy:		88.91 %
Epoch 935 of 2000 took 0.110s
  training loss:		0.093650
  validation loss:		0.522867
  validation accuracy:		90.22 %
Epoch 936 of 2000 took 0.108s
  training loss:		0.097597
  validation loss:		0.519563
  validation accuracy:		90.33 %
Epoch 937 of 2000 took 0.111s
  training loss:		0.080866
  validation loss:		0.529056
  validation accuracy:		89.57 %
Epoch 938 of 2000 took 0.112s
  training loss:		0.079857
  validation loss:		0.548024
  validation accuracy:		89.24 %
Epoch 939 of 2000 took 0.108s
  training loss:		0.084850
  validation loss:		0.523717
  validation accuracy:		90.33 %
Epoch 940 of 2000 took 0.110s
  training loss:		0.082900
  validation loss:		0.557175
  validation accuracy:		88.80 %
Epoch 941 of 2000 took 0.113s
  training loss:		0.089736
  validation loss:		0.552088
  validation accuracy:		88.80 %
Epoch 942 of 2000 took 0.109s
  training loss:		0.090941
  validation loss:		0.537959
  validation accuracy:		89.67 %
Epoch 943 of 2000 took 0.110s
  training loss:		0.082865
  validation loss:		0.547701
  validation accuracy:		89.35 %
Epoch 944 of 2000 took 0.108s
  training loss:		0.099133
  validation loss:		0.592515
  validation accuracy:		88.48 %
Epoch 945 of 2000 took 0.111s
  training loss:		0.083509
  validation loss:		0.545928
  validation accuracy:		89.35 %
Epoch 946 of 2000 took 0.112s
  training loss:		0.091873
  validation loss:		0.527068
  validation accuracy:		90.33 %
Epoch 947 of 2000 took 0.112s
  training loss:		0.085206
  validation loss:		0.536613
  validation accuracy:		89.24 %
Epoch 948 of 2000 took 0.129s
  training loss:		0.083886
  validation loss:		0.526985
  validation accuracy:		89.89 %
Epoch 949 of 2000 took 0.103s
  training loss:		0.077171
  validation loss:		0.555390
  validation accuracy:		89.67 %
Epoch 950 of 2000 took 0.103s
  training loss:		0.084097
  validation loss:		0.541133
  validation accuracy:		89.78 %
Epoch 951 of 2000 took 0.103s
  training loss:		0.083232
  validation loss:		0.554146
  validation accuracy:		89.46 %
Epoch 952 of 2000 took 0.110s
  training loss:		0.082430
  validation loss:		0.577708
  validation accuracy:		89.24 %
Epoch 953 of 2000 took 0.103s
  training loss:		0.084165
  validation loss:		0.558231
  validation accuracy:		89.46 %
Epoch 954 of 2000 took 0.103s
  training loss:		0.086785
  validation loss:		0.553457
  validation accuracy:		89.89 %
Epoch 955 of 2000 took 0.103s
  training loss:		0.083511
  validation loss:		0.576006
  validation accuracy:		88.91 %
Epoch 956 of 2000 took 0.103s
  training loss:		0.089421
  validation loss:		0.555580
  validation accuracy:		89.67 %
Epoch 957 of 2000 took 0.103s
  training loss:		0.076957
  validation loss:		0.572373
  validation accuracy:		88.59 %
Epoch 958 of 2000 took 0.103s
  training loss:		0.088271
  validation loss:		0.542028
  validation accuracy:		89.89 %
Epoch 959 of 2000 took 0.103s
  training loss:		0.082238
  validation loss:		0.568785
  validation accuracy:		89.78 %
Epoch 960 of 2000 took 0.103s
  training loss:		0.084768
  validation loss:		0.579192
  validation accuracy:		89.13 %
Epoch 961 of 2000 took 0.103s
  training loss:		0.088181
  validation loss:		0.571044
  validation accuracy:		89.35 %
Epoch 962 of 2000 took 0.103s
  training loss:		0.083363
  validation loss:		0.557540
  validation accuracy:		90.00 %
Epoch 963 of 2000 took 0.103s
  training loss:		0.082216
  validation loss:		0.547502
  validation accuracy:		89.67 %
Epoch 964 of 2000 took 0.103s
  training loss:		0.084129
  validation loss:		0.547090
  validation accuracy:		90.00 %
Epoch 965 of 2000 took 0.103s
  training loss:		0.083583
  validation loss:		0.612706
  validation accuracy:		88.37 %
Epoch 966 of 2000 took 0.103s
  training loss:		0.080356
  validation loss:		0.548639
  validation accuracy:		89.24 %
Epoch 967 of 2000 took 0.103s
  training loss:		0.089993
  validation loss:		0.586528
  validation accuracy:		89.24 %
Epoch 968 of 2000 took 0.103s
  training loss:		0.080216
  validation loss:		0.545448
  validation accuracy:		89.78 %
Epoch 969 of 2000 took 0.103s
  training loss:		0.081317
  validation loss:		0.582942
  validation accuracy:		90.00 %
Epoch 970 of 2000 took 0.103s
  training loss:		0.077428
  validation loss:		0.569599
  validation accuracy:		88.91 %
Epoch 971 of 2000 took 0.104s
  training loss:		0.081335
  validation loss:		0.569544
  validation accuracy:		89.57 %
Epoch 972 of 2000 took 0.103s
  training loss:		0.073280
  validation loss:		0.548106
  validation accuracy:		90.11 %
Epoch 973 of 2000 took 0.103s
  training loss:		0.083786
  validation loss:		0.572527
  validation accuracy:		89.13 %
Epoch 974 of 2000 took 0.103s
  training loss:		0.074223
  validation loss:		0.562394
  validation accuracy:		89.35 %
Epoch 975 of 2000 took 0.103s
  training loss:		0.078124
  validation loss:		0.581070
  validation accuracy:		88.80 %
Epoch 976 of 2000 took 0.103s
  training loss:		0.079873
  validation loss:		0.589142
  validation accuracy:		89.57 %
Epoch 977 of 2000 took 0.103s
  training loss:		0.082483
  validation loss:		0.544480
  validation accuracy:		90.43 %
Epoch 978 of 2000 took 0.103s
  training loss:		0.080188
  validation loss:		0.566095
  validation accuracy:		89.13 %
Epoch 979 of 2000 took 0.103s
  training loss:		0.081420
  validation loss:		0.559897
  validation accuracy:		90.43 %
Epoch 980 of 2000 took 0.103s
  training loss:		0.076245
  validation loss:		0.595166
  validation accuracy:		89.35 %
Epoch 981 of 2000 took 0.109s
  training loss:		0.077745
  validation loss:		0.580191
  validation accuracy:		88.91 %
Epoch 982 of 2000 took 0.100s
  training loss:		0.080413
  validation loss:		0.569816
  validation accuracy:		89.13 %
Epoch 983 of 2000 took 0.101s
  training loss:		0.075922
  validation loss:		0.597632
  validation accuracy:		89.57 %
Epoch 984 of 2000 took 0.098s
  training loss:		0.086556
  validation loss:		0.589624
  validation accuracy:		89.35 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.090246
  validation loss:		0.584741
  validation accuracy:		89.46 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.072005
  validation loss:		0.553523
  validation accuracy:		90.00 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.076837
  validation loss:		0.572978
  validation accuracy:		89.89 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.077055
  validation loss:		0.581926
  validation accuracy:		89.67 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.083730
  validation loss:		0.570924
  validation accuracy:		89.57 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.073340
  validation loss:		0.566525
  validation accuracy:		90.54 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.074981
  validation loss:		0.562052
  validation accuracy:		89.57 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.084747
  validation loss:		0.581592
  validation accuracy:		89.89 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.079743
  validation loss:		0.565866
  validation accuracy:		90.11 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.069131
  validation loss:		0.566649
  validation accuracy:		90.65 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.083880
  validation loss:		0.583770
  validation accuracy:		89.46 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.076946
  validation loss:		0.594108
  validation accuracy:		89.24 %
Epoch 997 of 2000 took 0.097s
  training loss:		0.082566
  validation loss:		0.572568
  validation accuracy:		90.00 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.072240
  validation loss:		0.572160
  validation accuracy:		89.67 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.079517
  validation loss:		0.586238
  validation accuracy:		89.13 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.073910
  validation loss:		0.579341
  validation accuracy:		90.33 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.078388
  validation loss:		0.586801
  validation accuracy:		89.78 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.081076
  validation loss:		0.569061
  validation accuracy:		89.57 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.075887
  validation loss:		0.615594
  validation accuracy:		89.13 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.075692
  validation loss:		0.601144
  validation accuracy:		89.46 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.073121
  validation loss:		0.604851
  validation accuracy:		88.91 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.071704
  validation loss:		0.586952
  validation accuracy:		89.35 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.078912
  validation loss:		0.568249
  validation accuracy:		90.33 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.086570
  validation loss:		0.625869
  validation accuracy:		88.91 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.082843
  validation loss:		0.624342
  validation accuracy:		89.67 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.071548
  validation loss:		0.579779
  validation accuracy:		90.11 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.073743
  validation loss:		0.593224
  validation accuracy:		89.46 %
Epoch 1012 of 2000 took 0.104s
  training loss:		0.079132
  validation loss:		0.605784
  validation accuracy:		89.46 %
Epoch 1013 of 2000 took 0.097s
  training loss:		0.074163
  validation loss:		0.647639
  validation accuracy:		88.91 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.081061
  validation loss:		0.561794
  validation accuracy:		90.33 %
Epoch 1015 of 2000 took 0.097s
  training loss:		0.080164
  validation loss:		0.609177
  validation accuracy:		89.67 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.071313
  validation loss:		0.605489
  validation accuracy:		89.67 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.075534
  validation loss:		0.584075
  validation accuracy:		89.78 %
Epoch 1018 of 2000 took 0.097s
  training loss:		0.072976
  validation loss:		0.601333
  validation accuracy:		89.24 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.076449
  validation loss:		0.596225
  validation accuracy:		89.57 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.081495
  validation loss:		0.637682
  validation accuracy:		88.70 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.079702
  validation loss:		0.590068
  validation accuracy:		89.57 %
Epoch 1022 of 2000 took 0.097s
  training loss:		0.081349
  validation loss:		0.600716
  validation accuracy:		89.78 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.078248
  validation loss:		0.606063
  validation accuracy:		89.78 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.075006
  validation loss:		0.595590
  validation accuracy:		89.89 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.071772
  validation loss:		0.618869
  validation accuracy:		89.02 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.079862
  validation loss:		0.608431
  validation accuracy:		89.89 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.087034
  validation loss:		0.604124
  validation accuracy:		89.35 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.078228
  validation loss:		0.603355
  validation accuracy:		90.00 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.072568
  validation loss:		0.610574
  validation accuracy:		89.13 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.079331
  validation loss:		0.635965
  validation accuracy:		89.13 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.078478
  validation loss:		0.638161
  validation accuracy:		88.59 %
Epoch 1032 of 2000 took 0.097s
  training loss:		0.076610
  validation loss:		0.592195
  validation accuracy:		89.78 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.070709
  validation loss:		0.628950
  validation accuracy:		88.80 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.067914
  validation loss:		0.605643
  validation accuracy:		89.46 %
Epoch 1035 of 2000 took 0.097s
  training loss:		0.068231
  validation loss:		0.628808
  validation accuracy:		89.02 %
Epoch 1036 of 2000 took 0.097s
  training loss:		0.065344
  validation loss:		0.602955
  validation accuracy:		89.35 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.067480
  validation loss:		0.618719
  validation accuracy:		89.35 %
Epoch 1038 of 2000 took 0.097s
  training loss:		0.071166
  validation loss:		0.612795
  validation accuracy:		89.67 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.071834
  validation loss:		0.617168
  validation accuracy:		89.46 %
Epoch 1040 of 2000 took 0.097s
  training loss:		0.071105
  validation loss:		0.608908
  validation accuracy:		89.46 %
Epoch 1041 of 2000 took 0.097s
  training loss:		0.073514
  validation loss:		0.625242
  validation accuracy:		89.13 %
Epoch 1042 of 2000 took 0.097s
  training loss:		0.072550
  validation loss:		0.631318
  validation accuracy:		89.57 %
Epoch 1043 of 2000 took 0.103s
  training loss:		0.075070
  validation loss:		0.617201
  validation accuracy:		89.78 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.076210
  validation loss:		0.606842
  validation accuracy:		89.24 %
Epoch 1045 of 2000 took 0.097s
  training loss:		0.073482
  validation loss:		0.612829
  validation accuracy:		90.00 %
Epoch 1046 of 2000 took 0.097s
  training loss:		0.065615
  validation loss:		0.593800
  validation accuracy:		89.57 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.067699
  validation loss:		0.619656
  validation accuracy:		89.35 %
Epoch 1048 of 2000 took 0.098s
  training loss:		0.074623
  validation loss:		0.632354
  validation accuracy:		88.91 %
Epoch 1049 of 2000 took 0.097s
  training loss:		0.071655
  validation loss:		0.618355
  validation accuracy:		89.46 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.068240
  validation loss:		0.630695
  validation accuracy:		89.24 %
Epoch 1051 of 2000 took 0.097s
  training loss:		0.073279
  validation loss:		0.605545
  validation accuracy:		90.33 %
Epoch 1052 of 2000 took 0.097s
  training loss:		0.076395
  validation loss:		0.653602
  validation accuracy:		88.70 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.072142
  validation loss:		0.585771
  validation accuracy:		90.22 %
Epoch 1054 of 2000 took 0.097s
  training loss:		0.064022
  validation loss:		0.645012
  validation accuracy:		89.67 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.076506
  validation loss:		0.645291
  validation accuracy:		89.13 %
Epoch 1056 of 2000 took 0.097s
  training loss:		0.069856
  validation loss:		0.619091
  validation accuracy:		88.91 %
Epoch 1057 of 2000 took 0.097s
  training loss:		0.070302
  validation loss:		0.638614
  validation accuracy:		89.24 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.078758
  validation loss:		0.611457
  validation accuracy:		89.67 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.067374
  validation loss:		0.633134
  validation accuracy:		89.89 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.070567
  validation loss:		0.626926
  validation accuracy:		89.02 %
Epoch 1061 of 2000 took 0.097s
  training loss:		0.071734
  validation loss:		0.676266
  validation accuracy:		89.35 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.073456
  validation loss:		0.625739
  validation accuracy:		89.35 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.074470
  validation loss:		0.606767
  validation accuracy:		90.22 %
Epoch 1064 of 2000 took 0.097s
  training loss:		0.067045
  validation loss:		0.626508
  validation accuracy:		89.57 %
Epoch 1065 of 2000 took 0.097s
  training loss:		0.065393
  validation loss:		0.617529
  validation accuracy:		89.35 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.074727
  validation loss:		0.647363
  validation accuracy:		89.46 %
Epoch 1067 of 2000 took 0.097s
  training loss:		0.071745
  validation loss:		0.627593
  validation accuracy:		89.78 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.063689
  validation loss:		0.678850
  validation accuracy:		89.13 %
Epoch 1069 of 2000 took 0.097s
  training loss:		0.063612
  validation loss:		0.609572
  validation accuracy:		89.57 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.066106
  validation loss:		0.649849
  validation accuracy:		89.67 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.068388
  validation loss:		0.635523
  validation accuracy:		89.78 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.070441
  validation loss:		0.653718
  validation accuracy:		88.80 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.063604
  validation loss:		0.634127
  validation accuracy:		89.35 %
Epoch 1074 of 2000 took 0.103s
  training loss:		0.063878
  validation loss:		0.639396
  validation accuracy:		89.35 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.063798
  validation loss:		0.660741
  validation accuracy:		88.59 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.063587
  validation loss:		0.650136
  validation accuracy:		89.57 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.061291
  validation loss:		0.633905
  validation accuracy:		89.89 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.063763
  validation loss:		0.619808
  validation accuracy:		90.11 %
Epoch 1079 of 2000 took 0.097s
  training loss:		0.064112
  validation loss:		0.662482
  validation accuracy:		89.67 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.063360
  validation loss:		0.640865
  validation accuracy:		89.35 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.063789
  validation loss:		0.631230
  validation accuracy:		89.67 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.062895
  validation loss:		0.650127
  validation accuracy:		89.89 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.064645
  validation loss:		0.650108
  validation accuracy:		89.35 %
Epoch 1084 of 2000 took 0.097s
  training loss:		0.070368
  validation loss:		0.645252
  validation accuracy:		89.67 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.060947
  validation loss:		0.621365
  validation accuracy:		90.00 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.062608
  validation loss:		0.658662
  validation accuracy:		89.35 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.059360
  validation loss:		0.667380
  validation accuracy:		89.24 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.065752
  validation loss:		0.648658
  validation accuracy:		89.24 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.064879
  validation loss:		0.662045
  validation accuracy:		89.24 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.063180
  validation loss:		0.647710
  validation accuracy:		89.13 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.064462
  validation loss:		0.652120
  validation accuracy:		89.24 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.065569
  validation loss:		0.662028
  validation accuracy:		89.67 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.073477
  validation loss:		0.667872
  validation accuracy:		89.89 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.059446
  validation loss:		0.634774
  validation accuracy:		89.78 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.064808
  validation loss:		0.655532
  validation accuracy:		89.24 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.067584
  validation loss:		0.693471
  validation accuracy:		88.80 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.061095
  validation loss:		0.684051
  validation accuracy:		88.80 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.066248
  validation loss:		0.669096
  validation accuracy:		88.91 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.067727
  validation loss:		0.626633
  validation accuracy:		90.33 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.063163
  validation loss:		0.669358
  validation accuracy:		88.91 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.066886
  validation loss:		0.688237
  validation accuracy:		89.13 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.066080
  validation loss:		0.665694
  validation accuracy:		89.67 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.071276
  validation loss:		0.655231
  validation accuracy:		89.02 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.064670
  validation loss:		0.668298
  validation accuracy:		89.24 %
Epoch 1105 of 2000 took 0.103s
  training loss:		0.065121
  validation loss:		0.659068
  validation accuracy:		89.13 %
Epoch 1106 of 2000 took 0.098s
  training loss:		0.065491
  validation loss:		0.643500
  validation accuracy:		90.00 %
Epoch 1107 of 2000 took 0.097s
  training loss:		0.077031
  validation loss:		0.697367
  validation accuracy:		89.24 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.071568
  validation loss:		0.757024
  validation accuracy:		88.48 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.082497
  validation loss:		0.685780
  validation accuracy:		89.24 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.063283
  validation loss:		0.675407
  validation accuracy:		88.91 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.062749
  validation loss:		0.637984
  validation accuracy:		90.11 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.066847
  validation loss:		0.687418
  validation accuracy:		89.35 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.064921
  validation loss:		0.697034
  validation accuracy:		89.89 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.066678
  validation loss:		0.662009
  validation accuracy:		89.89 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.068923
  validation loss:		0.692379
  validation accuracy:		89.35 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.062425
  validation loss:		0.685224
  validation accuracy:		89.13 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.068999
  validation loss:		0.707231
  validation accuracy:		88.91 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.067686
  validation loss:		0.680168
  validation accuracy:		89.89 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.078112
  validation loss:		0.659441
  validation accuracy:		89.78 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.059109
  validation loss:		0.683942
  validation accuracy:		89.24 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.055312
  validation loss:		0.667071
  validation accuracy:		89.35 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.060203
  validation loss:		0.656363
  validation accuracy:		90.00 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.060897
  validation loss:		0.697902
  validation accuracy:		89.46 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.057815
  validation loss:		0.687057
  validation accuracy:		88.91 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.055407
  validation loss:		0.705290
  validation accuracy:		89.13 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.082331
  validation loss:		0.740200
  validation accuracy:		89.57 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.092702
  validation loss:		0.666443
  validation accuracy:		89.89 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.063733
  validation loss:		0.683356
  validation accuracy:		90.00 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.058975
  validation loss:		0.652574
  validation accuracy:		90.11 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.058604
  validation loss:		0.723163
  validation accuracy:		88.80 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.058161
  validation loss:		0.676463
  validation accuracy:		89.46 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.056140
  validation loss:		0.677526
  validation accuracy:		89.46 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.057941
  validation loss:		0.672806
  validation accuracy:		89.89 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.062711
  validation loss:		0.701566
  validation accuracy:		89.24 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.056932
  validation loss:		0.662275
  validation accuracy:		90.00 %
Epoch 1136 of 2000 took 0.098s
  training loss:		0.061333
  validation loss:		0.689549
  validation accuracy:		89.35 %
Epoch 1137 of 2000 took 0.103s
  training loss:		0.064710
  validation loss:		0.747204
  validation accuracy:		88.37 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.067459
  validation loss:		0.648235
  validation accuracy:		89.57 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.055185
  validation loss:		0.676332
  validation accuracy:		89.78 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.063146
  validation loss:		0.714131
  validation accuracy:		89.35 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.057976
  validation loss:		0.663163
  validation accuracy:		89.24 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.064943
  validation loss:		0.702723
  validation accuracy:		89.57 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.056955
  validation loss:		0.718864
  validation accuracy:		89.02 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.053812
  validation loss:		0.677897
  validation accuracy:		90.11 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.054045
  validation loss:		0.739879
  validation accuracy:		88.59 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.055209
  validation loss:		0.679259
  validation accuracy:		89.57 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.056228
  validation loss:		0.723020
  validation accuracy:		89.13 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.054536
  validation loss:		0.714051
  validation accuracy:		89.67 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.056735
  validation loss:		0.721597
  validation accuracy:		88.70 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.057977
  validation loss:		0.692538
  validation accuracy:		89.35 %
Epoch 1151 of 2000 took 0.098s
  training loss:		0.058884
  validation loss:		0.653534
  validation accuracy:		90.11 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.062346
  validation loss:		0.764658
  validation accuracy:		88.80 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.069514
  validation loss:		0.677247
  validation accuracy:		89.67 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.055478
  validation loss:		0.729901
  validation accuracy:		88.37 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.054222
  validation loss:		0.691680
  validation accuracy:		89.67 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.064561
  validation loss:		0.738866
  validation accuracy:		88.37 %
Epoch 1157 of 2000 took 0.097s
  training loss:		0.055278
  validation loss:		0.677169
  validation accuracy:		89.78 %
Epoch 1158 of 2000 took 0.097s
  training loss:		0.053755
  validation loss:		0.721773
  validation accuracy:		89.46 %
Epoch 1159 of 2000 took 0.097s
  training loss:		0.056411
  validation loss:		0.705601
  validation accuracy:		89.24 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.059955
  validation loss:		0.700149
  validation accuracy:		89.57 %
Epoch 1161 of 2000 took 0.097s
  training loss:		0.055464
  validation loss:		0.745516
  validation accuracy:		89.02 %
Epoch 1162 of 2000 took 0.097s
  training loss:		0.061010
  validation loss:		0.681840
  validation accuracy:		89.67 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.063641
  validation loss:		0.764387
  validation accuracy:		88.48 %
Epoch 1164 of 2000 took 0.097s
  training loss:		0.056582
  validation loss:		0.706879
  validation accuracy:		88.91 %
Epoch 1165 of 2000 took 0.097s
  training loss:		0.057634
  validation loss:		0.688022
  validation accuracy:		90.11 %
Epoch 1166 of 2000 took 0.097s
  training loss:		0.052974
  validation loss:		0.674725
  validation accuracy:		90.33 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.067301
  validation loss:		0.700191
  validation accuracy:		89.46 %
Epoch 1168 of 2000 took 0.098s
  training loss:		0.051925
  validation loss:		0.687006
  validation accuracy:		89.78 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.054028
  validation loss:		0.710479
  validation accuracy:		89.46 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.057203
  validation loss:		0.701460
  validation accuracy:		89.35 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.052356
  validation loss:		0.748789
  validation accuracy:		89.02 %
Epoch 1172 of 2000 took 0.097s
  training loss:		0.063570
  validation loss:		0.704567
  validation accuracy:		89.46 %
Epoch 1173 of 2000 took 0.097s
  training loss:		0.048989
  validation loss:		0.675430
  validation accuracy:		90.00 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.050586
  validation loss:		0.718763
  validation accuracy:		89.57 %
Epoch 1175 of 2000 took 0.097s
  training loss:		0.056217
  validation loss:		0.701348
  validation accuracy:		90.11 %
Epoch 1176 of 2000 took 0.097s
  training loss:		0.058051
  validation loss:		0.729684
  validation accuracy:		89.13 %
Epoch 1177 of 2000 took 0.097s
  training loss:		0.058551
  validation loss:		0.677449
  validation accuracy:		89.67 %
Epoch 1178 of 2000 took 0.097s
  training loss:		0.047958
  validation loss:		0.737296
  validation accuracy:		89.24 %
Epoch 1179 of 2000 took 0.097s
  training loss:		0.054306
  validation loss:		0.758494
  validation accuracy:		88.80 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.058403
  validation loss:		0.702955
  validation accuracy:		89.35 %
Epoch 1181 of 2000 took 0.097s
  training loss:		0.052050
  validation loss:		0.713864
  validation accuracy:		89.13 %
Epoch 1182 of 2000 took 0.097s
  training loss:		0.056218
  validation loss:		0.726593
  validation accuracy:		89.46 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.063424
  validation loss:		0.705537
  validation accuracy:		89.78 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.054843
  validation loss:		0.692819
  validation accuracy:		89.89 %
Epoch 1185 of 2000 took 0.097s
  training loss:		0.047881
  validation loss:		0.761560
  validation accuracy:		88.91 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.050499
  validation loss:		0.704670
  validation accuracy:		89.78 %
Epoch 1187 of 2000 took 0.097s
  training loss:		0.052314
  validation loss:		0.732184
  validation accuracy:		89.46 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.051857
  validation loss:		0.736530
  validation accuracy:		89.89 %
Epoch 1189 of 2000 took 0.101s
  training loss:		0.053967
  validation loss:		0.762457
  validation accuracy:		88.80 %
Epoch 1190 of 2000 took 0.098s
  training loss:		0.050022
  validation loss:		0.755138
  validation accuracy:		89.24 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.053632
  validation loss:		0.746439
  validation accuracy:		89.35 %
Epoch 1192 of 2000 took 0.097s
  training loss:		0.047275
  validation loss:		0.716225
  validation accuracy:		89.46 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.054066
  validation loss:		0.722216
  validation accuracy:		89.13 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.047287
  validation loss:		0.704683
  validation accuracy:		89.67 %
Epoch 1195 of 2000 took 0.097s
  training loss:		0.046185
  validation loss:		0.737698
  validation accuracy:		89.67 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.046734
  validation loss:		0.784767
  validation accuracy:		88.91 %
Epoch 1197 of 2000 took 0.097s
  training loss:		0.051910
  validation loss:		0.785711
  validation accuracy:		88.37 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.056432
  validation loss:		0.746934
  validation accuracy:		89.02 %
Epoch 1199 of 2000 took 0.098s
  training loss:		0.070361
  validation loss:		0.803219
  validation accuracy:		88.48 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.052519
  validation loss:		0.757939
  validation accuracy:		89.46 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.054974
  validation loss:		0.739138
  validation accuracy:		89.78 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.045542
  validation loss:		0.714728
  validation accuracy:		89.78 %
Epoch 1203 of 2000 took 0.097s
  training loss:		0.049079
  validation loss:		0.727576
  validation accuracy:		89.57 %
Epoch 1204 of 2000 took 0.097s
  training loss:		0.055332
  validation loss:		0.703331
  validation accuracy:		89.89 %
Epoch 1205 of 2000 took 0.097s
  training loss:		0.058820
  validation loss:		0.734589
  validation accuracy:		89.67 %
Epoch 1206 of 2000 took 0.097s
  training loss:		0.049054
  validation loss:		0.747319
  validation accuracy:		89.57 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.050515
  validation loss:		0.755883
  validation accuracy:		89.67 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.050172
  validation loss:		0.769930
  validation accuracy:		89.02 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.114980
  validation loss:		1.229732
  validation accuracy:		83.80 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.441156
  validation loss:		0.741973
  validation accuracy:		89.89 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.084129
  validation loss:		0.689969
  validation accuracy:		90.00 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.061798
  validation loss:		0.686111
  validation accuracy:		90.00 %
Epoch 1213 of 2000 took 0.097s
  training loss:		0.063039
  validation loss:		0.717054
  validation accuracy:		89.57 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.058447
  validation loss:		0.690611
  validation accuracy:		90.11 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.051663
  validation loss:		0.716675
  validation accuracy:		90.11 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.048976
  validation loss:		0.714412
  validation accuracy:		90.00 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.045693
  validation loss:		0.744790
  validation accuracy:		89.46 %
Epoch 1218 of 2000 took 0.097s
  training loss:		0.049758
  validation loss:		0.759467
  validation accuracy:		88.91 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.046870
  validation loss:		0.695606
  validation accuracy:		89.46 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.050947
  validation loss:		0.758040
  validation accuracy:		88.91 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.049592
  validation loss:		0.751851
  validation accuracy:		89.24 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.047309
  validation loss:		0.679070
  validation accuracy:		90.33 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.055128
  validation loss:		0.756571
  validation accuracy:		89.35 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.050789
  validation loss:		0.774478
  validation accuracy:		89.35 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.060194
  validation loss:		0.713206
  validation accuracy:		89.78 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.046183
  validation loss:		0.752000
  validation accuracy:		89.46 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.047320
  validation loss:		0.764510
  validation accuracy:		89.35 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.051570
  validation loss:		0.775558
  validation accuracy:		88.91 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.048411
  validation loss:		0.735025
  validation accuracy:		89.57 %
Epoch 1230 of 2000 took 0.098s
  training loss:		0.051416
  validation loss:		0.710679
  validation accuracy:		89.57 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.052376
  validation loss:		0.738283
  validation accuracy:		89.67 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.051803
  validation loss:		0.729892
  validation accuracy:		90.00 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.055850
  validation loss:		0.740772
  validation accuracy:		89.67 %
Epoch 1234 of 2000 took 0.097s
  training loss:		0.044659
  validation loss:		0.757350
  validation accuracy:		89.67 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.041580
  validation loss:		0.746579
  validation accuracy:		89.24 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.045230
  validation loss:		0.710670
  validation accuracy:		90.00 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.051168
  validation loss:		0.726921
  validation accuracy:		90.22 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.050518
  validation loss:		0.685408
  validation accuracy:		90.65 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.046567
  validation loss:		0.712938
  validation accuracy:		89.67 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.046451
  validation loss:		0.727241
  validation accuracy:		90.00 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.043955
  validation loss:		0.716569
  validation accuracy:		89.89 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.044871
  validation loss:		0.731867
  validation accuracy:		89.46 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.046011
  validation loss:		0.764969
  validation accuracy:		89.67 %
Epoch 1244 of 2000 took 0.097s
  training loss:		0.041082
  validation loss:		0.737659
  validation accuracy:		89.46 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.042801
  validation loss:		0.747794
  validation accuracy:		89.78 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.046442
  validation loss:		0.747012
  validation accuracy:		89.57 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.042986
  validation loss:		0.741879
  validation accuracy:		89.46 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.047568
  validation loss:		0.728636
  validation accuracy:		90.22 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.044339
  validation loss:		0.738768
  validation accuracy:		89.35 %
Epoch 1250 of 2000 took 0.097s
  training loss:		0.042930
  validation loss:		0.739430
  validation accuracy:		90.11 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.040466
  validation loss:		0.754449
  validation accuracy:		90.00 %
Epoch 1252 of 2000 took 0.097s
  training loss:		0.042792
  validation loss:		0.775173
  validation accuracy:		89.46 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.044829
  validation loss:		0.739052
  validation accuracy:		90.11 %
Epoch 1254 of 2000 took 0.098s
  training loss:		0.045108
  validation loss:		0.745943
  validation accuracy:		89.35 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.040011
  validation loss:		0.766882
  validation accuracy:		89.57 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.077652
  validation loss:		0.805588
  validation accuracy:		88.48 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.053977
  validation loss:		0.693375
  validation accuracy:		90.33 %
Epoch 1258 of 2000 took 0.097s
  training loss:		0.049950
  validation loss:		0.775744
  validation accuracy:		89.35 %
Epoch 1259 of 2000 took 0.097s
  training loss:		0.044039
  validation loss:		0.761202
  validation accuracy:		89.89 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.049063
  validation loss:		0.772954
  validation accuracy:		89.35 %
Epoch 1261 of 2000 took 0.098s
  training loss:		0.051765
  validation loss:		0.777421
  validation accuracy:		89.13 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.040992
  validation loss:		0.752007
  validation accuracy:		90.00 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.043171
  validation loss:		0.777678
  validation accuracy:		89.02 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.045347
  validation loss:		0.831859
  validation accuracy:		89.13 %
Epoch 1265 of 2000 took 0.097s
  training loss:		0.045894
  validation loss:		0.809223
  validation accuracy:		88.80 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.043380
  validation loss:		0.769487
  validation accuracy:		89.67 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.044823
  validation loss:		0.842482
  validation accuracy:		88.70 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.043551
  validation loss:		0.794790
  validation accuracy:		89.02 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.044185
  validation loss:		0.779693
  validation accuracy:		90.00 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.042275
  validation loss:		0.789308
  validation accuracy:		89.46 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.040007
  validation loss:		0.766005
  validation accuracy:		89.57 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.041759
  validation loss:		0.788932
  validation accuracy:		89.89 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.043799
  validation loss:		0.769703
  validation accuracy:		89.24 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.041235
  validation loss:		0.771409
  validation accuracy:		89.35 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.050456
  validation loss:		0.858801
  validation accuracy:		88.15 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.042117
  validation loss:		0.788130
  validation accuracy:		89.13 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.039713
  validation loss:		0.762088
  validation accuracy:		89.57 %
Epoch 1278 of 2000 took 0.097s
  training loss:		0.049119
  validation loss:		0.799215
  validation accuracy:		88.70 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.041671
  validation loss:		0.803990
  validation accuracy:		89.24 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.042496
  validation loss:		0.813239
  validation accuracy:		89.02 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.039708
  validation loss:		0.816429
  validation accuracy:		88.70 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.040548
  validation loss:		0.800531
  validation accuracy:		89.57 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.040209
  validation loss:		0.776718
  validation accuracy:		89.78 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.037218
  validation loss:		0.773929
  validation accuracy:		90.11 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.040644
  validation loss:		0.777662
  validation accuracy:		89.89 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.041085
  validation loss:		0.787451
  validation accuracy:		89.57 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.039694
  validation loss:		0.823201
  validation accuracy:		89.13 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.036632
  validation loss:		0.795995
  validation accuracy:		89.78 %
Epoch 1289 of 2000 took 0.097s
  training loss:		0.037629
  validation loss:		0.757041
  validation accuracy:		89.89 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.043471
  validation loss:		0.775849
  validation accuracy:		89.89 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.041686
  validation loss:		0.863494
  validation accuracy:		89.46 %
Epoch 1292 of 2000 took 0.098s
  training loss:		0.039414
  validation loss:		0.814994
  validation accuracy:		89.46 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.038829
  validation loss:		0.811690
  validation accuracy:		89.13 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.040298
  validation loss:		0.772407
  validation accuracy:		89.78 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.038589
  validation loss:		0.841828
  validation accuracy:		89.02 %
Epoch 1296 of 2000 took 0.097s
  training loss:		0.034706
  validation loss:		0.832412
  validation accuracy:		89.46 %
Epoch 1297 of 2000 took 0.097s
  training loss:		0.040508
  validation loss:		0.815311
  validation accuracy:		89.24 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.036092
  validation loss:		0.805309
  validation accuracy:		89.13 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.033442
  validation loss:		0.793572
  validation accuracy:		89.24 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.038185
  validation loss:		0.867637
  validation accuracy:		89.02 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.039472
  validation loss:		0.838584
  validation accuracy:		89.13 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.067961
  validation loss:		0.832225
  validation accuracy:		89.02 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.044414
  validation loss:		0.813782
  validation accuracy:		89.57 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.037381
  validation loss:		0.834116
  validation accuracy:		89.46 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.040488
  validation loss:		0.804689
  validation accuracy:		89.57 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.036818
  validation loss:		0.788818
  validation accuracy:		90.00 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.037328
  validation loss:		0.825336
  validation accuracy:		89.78 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.038366
  validation loss:		0.849157
  validation accuracy:		89.02 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.048687
  validation loss:		0.827826
  validation accuracy:		89.67 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.037602
  validation loss:		0.813960
  validation accuracy:		89.57 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.040134
  validation loss:		0.862179
  validation accuracy:		88.48 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.034959
  validation loss:		0.858401
  validation accuracy:		88.91 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.034021
  validation loss:		0.821947
  validation accuracy:		89.35 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.035981
  validation loss:		0.923564
  validation accuracy:		88.04 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.037634
  validation loss:		0.867676
  validation accuracy:		89.35 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.038081
  validation loss:		0.815044
  validation accuracy:		89.67 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.040106
  validation loss:		0.808388
  validation accuracy:		89.67 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.035020
  validation loss:		0.844547
  validation accuracy:		89.46 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.035882
  validation loss:		0.822872
  validation accuracy:		89.89 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.042766
  validation loss:		0.843450
  validation accuracy:		89.57 %
Epoch 1321 of 2000 took 0.097s
  training loss:		0.033724
  validation loss:		0.833334
  validation accuracy:		89.78 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.037789
  validation loss:		0.905598
  validation accuracy:		88.59 %
Epoch 1323 of 2000 took 0.098s
  training loss:		0.040052
  validation loss:		0.827113
  validation accuracy:		89.78 %
Epoch 1324 of 2000 took 0.097s
  training loss:		0.041717
  validation loss:		0.809967
  validation accuracy:		89.89 %
Epoch 1325 of 2000 took 0.097s
  training loss:		0.041434
  validation loss:		0.842491
  validation accuracy:		89.57 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.037261
  validation loss:		0.851726
  validation accuracy:		89.02 %
Epoch 1327 of 2000 took 0.097s
  training loss:		0.035321
  validation loss:		0.879274
  validation accuracy:		88.59 %
Epoch 1328 of 2000 took 0.097s
  training loss:		0.033897
  validation loss:		0.850745
  validation accuracy:		90.00 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.035316
  validation loss:		0.863952
  validation accuracy:		89.78 %
Epoch 1330 of 2000 took 0.097s
  training loss:		0.039412
  validation loss:		0.896161
  validation accuracy:		88.37 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.089039
  validation loss:		0.875233
  validation accuracy:		89.13 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.034865
  validation loss:		0.824290
  validation accuracy:		89.78 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.033638
  validation loss:		0.852565
  validation accuracy:		89.78 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.033388
  validation loss:		0.823846
  validation accuracy:		90.22 %
Epoch 1335 of 2000 took 0.097s
  training loss:		0.036678
  validation loss:		0.817757
  validation accuracy:		89.78 %
Epoch 1336 of 2000 took 0.097s
  training loss:		0.048131
  validation loss:		0.825763
  validation accuracy:		89.89 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.034892
  validation loss:		0.854430
  validation accuracy:		90.11 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.032903
  validation loss:		0.828779
  validation accuracy:		90.11 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.031673
  validation loss:		0.835343
  validation accuracy:		89.67 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.046811
  validation loss:		0.902204
  validation accuracy:		88.48 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.044968
  validation loss:		0.869045
  validation accuracy:		89.13 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.036136
  validation loss:		0.841401
  validation accuracy:		89.46 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.035155
  validation loss:		0.889035
  validation accuracy:		88.70 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.037807
  validation loss:		0.845063
  validation accuracy:		89.57 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.031647
  validation loss:		0.856716
  validation accuracy:		89.35 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.033256
  validation loss:		0.820961
  validation accuracy:		89.78 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.037051
  validation loss:		0.918700
  validation accuracy:		89.02 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.035714
  validation loss:		0.860995
  validation accuracy:		89.24 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.032044
  validation loss:		0.866992
  validation accuracy:		90.00 %
Epoch 1350 of 2000 took 0.097s
  training loss:		0.040732
  validation loss:		0.879241
  validation accuracy:		89.02 %
Epoch 1351 of 2000 took 0.097s
  training loss:		0.036003
  validation loss:		0.881013
  validation accuracy:		89.35 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.035457
  validation loss:		0.902530
  validation accuracy:		89.13 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.035142
  validation loss:		0.850288
  validation accuracy:		89.89 %
Epoch 1354 of 2000 took 0.097s
  training loss:		0.035230
  validation loss:		0.869502
  validation accuracy:		89.02 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.031853
  validation loss:		0.869535
  validation accuracy:		89.35 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.031983
  validation loss:		0.911984
  validation accuracy:		89.02 %
Epoch 1357 of 2000 took 0.098s
  training loss:		0.037187
  validation loss:		0.874536
  validation accuracy:		89.24 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.033088
  validation loss:		0.874666
  validation accuracy:		88.91 %
Epoch 1359 of 2000 took 0.097s
  training loss:		0.033045
  validation loss:		0.838707
  validation accuracy:		89.78 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.033683
  validation loss:		0.849982
  validation accuracy:		90.11 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.029794
  validation loss:		0.890211
  validation accuracy:		89.46 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.032080
  validation loss:		0.886499
  validation accuracy:		89.13 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.030935
  validation loss:		0.851446
  validation accuracy:		89.78 %
Epoch 1364 of 2000 took 0.097s
  training loss:		0.035297
  validation loss:		0.861273
  validation accuracy:		89.57 %
Epoch 1365 of 2000 took 0.097s
  training loss:		0.028625
  validation loss:		0.908451
  validation accuracy:		88.80 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.033909
  validation loss:		0.850838
  validation accuracy:		89.57 %
Epoch 1367 of 2000 took 0.097s
  training loss:		0.035003
  validation loss:		0.914545
  validation accuracy:		89.57 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.033541
  validation loss:		0.851713
  validation accuracy:		89.57 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.033146
  validation loss:		0.873144
  validation accuracy:		89.67 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.029844
  validation loss:		0.933520
  validation accuracy:		88.80 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.034065
  validation loss:		0.934424
  validation accuracy:		88.26 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.035129
  validation loss:		0.872603
  validation accuracy:		89.35 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.029137
  validation loss:		0.869314
  validation accuracy:		89.67 %
Epoch 1374 of 2000 took 0.097s
  training loss:		0.030155
  validation loss:		0.893655
  validation accuracy:		89.35 %
Epoch 1375 of 2000 took 0.097s
  training loss:		0.033118
  validation loss:		0.958956
  validation accuracy:		88.70 %
Epoch 1376 of 2000 took 0.100s
  training loss:		0.030870
  validation loss:		0.924936
  validation accuracy:		89.13 %
Epoch 1377 of 2000 took 0.100s
  training loss:		0.033164
  validation loss:		0.904215
  validation accuracy:		89.57 %
Epoch 1378 of 2000 took 0.100s
  training loss:		0.029619
  validation loss:		0.900825
  validation accuracy:		89.57 %
Epoch 1379 of 2000 took 0.100s
  training loss:		0.038513
  validation loss:		0.922927
  validation accuracy:		89.13 %
Epoch 1380 of 2000 took 0.100s
  training loss:		0.036253
  validation loss:		0.940274
  validation accuracy:		88.80 %
Epoch 1381 of 2000 took 0.100s
  training loss:		0.029656
  validation loss:		0.887708
  validation accuracy:		89.78 %
Epoch 1382 of 2000 took 0.100s
  training loss:		0.030053
  validation loss:		0.891985
  validation accuracy:		89.35 %
Epoch 1383 of 2000 took 0.101s
  training loss:		0.041152
  validation loss:		0.915971
  validation accuracy:		89.35 %
Epoch 1384 of 2000 took 0.100s
  training loss:		0.029316
  validation loss:		0.904286
  validation accuracy:		89.46 %
Epoch 1385 of 2000 took 0.101s
  training loss:		0.046493
  validation loss:		0.935917
  validation accuracy:		89.13 %
Epoch 1386 of 2000 took 0.100s
  training loss:		0.031840
  validation loss:		0.912147
  validation accuracy:		89.67 %
Epoch 1387 of 2000 took 0.100s
  training loss:		0.042533
  validation loss:		0.918294
  validation accuracy:		88.59 %
Epoch 1388 of 2000 took 0.100s
  training loss:		0.028748
  validation loss:		0.905027
  validation accuracy:		89.89 %
Epoch 1389 of 2000 took 0.100s
  training loss:		0.033683
  validation loss:		0.929715
  validation accuracy:		90.00 %
Epoch 1390 of 2000 took 0.100s
  training loss:		0.047098
  validation loss:		0.941118
  validation accuracy:		89.13 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.032597
  validation loss:		0.918102
  validation accuracy:		89.13 %
Epoch 1392 of 2000 took 0.100s
  training loss:		0.030312
  validation loss:		0.881607
  validation accuracy:		90.11 %
Epoch 1393 of 2000 took 0.100s
  training loss:		0.028718
  validation loss:		0.876545
  validation accuracy:		89.46 %
Epoch 1394 of 2000 took 0.100s
  training loss:		0.036098
  validation loss:		0.924040
  validation accuracy:		89.24 %
Epoch 1395 of 2000 took 0.100s
  training loss:		0.038678
  validation loss:		0.954346
  validation accuracy:		88.80 %
Epoch 1396 of 2000 took 0.100s
  training loss:		0.031646
  validation loss:		0.920928
  validation accuracy:		89.13 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.028586
  validation loss:		0.952655
  validation accuracy:		89.35 %
Epoch 1398 of 2000 took 0.100s
  training loss:		0.032517
  validation loss:		0.901576
  validation accuracy:		89.57 %
Epoch 1399 of 2000 took 0.100s
  training loss:		0.026899
  validation loss:		0.948367
  validation accuracy:		88.91 %
Epoch 1400 of 2000 took 0.100s
  training loss:		0.029171
  validation loss:		0.909702
  validation accuracy:		89.89 %
Epoch 1401 of 2000 took 0.100s
  training loss:		0.028666
  validation loss:		0.941466
  validation accuracy:		89.46 %
Epoch 1402 of 2000 took 0.100s
  training loss:		0.026593
  validation loss:		0.912440
  validation accuracy:		90.11 %
Epoch 1403 of 2000 took 0.100s
  training loss:		0.029734
  validation loss:		0.938365
  validation accuracy:		90.00 %
Epoch 1404 of 2000 took 0.100s
  training loss:		0.029336
  validation loss:		0.917870
  validation accuracy:		89.78 %
Epoch 1405 of 2000 took 0.100s
  training loss:		0.029620
  validation loss:		0.963262
  validation accuracy:		89.35 %
Epoch 1406 of 2000 took 0.100s
  training loss:		0.026938
  validation loss:		0.939744
  validation accuracy:		89.67 %
Epoch 1407 of 2000 took 0.100s
  training loss:		0.029370
  validation loss:		1.000578
  validation accuracy:		88.70 %
Epoch 1408 of 2000 took 0.100s
  training loss:		0.030309
  validation loss:		0.937641
  validation accuracy:		89.35 %
Epoch 1409 of 2000 took 0.100s
  training loss:		0.029039
  validation loss:		0.947441
  validation accuracy:		89.67 %
Epoch 1410 of 2000 took 0.100s
  training loss:		0.026818
  validation loss:		0.948684
  validation accuracy:		89.35 %
Epoch 1411 of 2000 took 0.100s
  training loss:		0.027444
  validation loss:		0.901782
  validation accuracy:		89.78 %
Epoch 1412 of 2000 took 0.100s
  training loss:		0.029785
  validation loss:		0.992913
  validation accuracy:		88.91 %
Epoch 1413 of 2000 took 0.100s
  training loss:		0.025357
  validation loss:		0.955643
  validation accuracy:		89.57 %
Epoch 1414 of 2000 took 0.100s
  training loss:		0.027468
  validation loss:		0.945267
  validation accuracy:		89.89 %
Epoch 1415 of 2000 took 0.103s
  training loss:		0.025308
  validation loss:		0.951209
  validation accuracy:		89.13 %
Epoch 1416 of 2000 took 0.100s
  training loss:		0.024766
  validation loss:		0.954070
  validation accuracy:		89.24 %
Epoch 1417 of 2000 took 0.100s
  training loss:		0.027601
  validation loss:		0.958948
  validation accuracy:		89.35 %
Epoch 1418 of 2000 took 0.100s
  training loss:		0.026618
  validation loss:		0.988279
  validation accuracy:		88.80 %
Epoch 1419 of 2000 took 0.100s
  training loss:		0.026595
  validation loss:		0.984784
  validation accuracy:		89.13 %
Epoch 1420 of 2000 took 0.100s
  training loss:		0.023335
  validation loss:		0.971464
  validation accuracy:		88.80 %
Epoch 1421 of 2000 took 0.100s
  training loss:		0.023862
  validation loss:		0.977214
  validation accuracy:		89.13 %
Epoch 1422 of 2000 took 0.100s
  training loss:		0.032839
  validation loss:		0.965535
  validation accuracy:		89.02 %
Epoch 1423 of 2000 took 0.099s
  training loss:		0.025392
  validation loss:		0.923139
  validation accuracy:		89.46 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.029884
  validation loss:		0.949106
  validation accuracy:		89.35 %
Epoch 1425 of 2000 took 0.097s
  training loss:		0.031827
  validation loss:		0.961977
  validation accuracy:		89.67 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.025219
  validation loss:		0.988796
  validation accuracy:		89.13 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.023649
  validation loss:		0.963432
  validation accuracy:		88.91 %
Epoch 1428 of 2000 took 0.097s
  training loss:		0.025656
  validation loss:		0.962823
  validation accuracy:		89.35 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.023520
  validation loss:		0.949882
  validation accuracy:		88.91 %
Epoch 1430 of 2000 took 0.097s
  training loss:		0.027601
  validation loss:		0.927381
  validation accuracy:		89.67 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.022361
  validation loss:		1.007485
  validation accuracy:		89.13 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.026121
  validation loss:		0.981939
  validation accuracy:		89.24 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.024389
  validation loss:		0.990573
  validation accuracy:		89.13 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.022991
  validation loss:		0.938744
  validation accuracy:		89.67 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.023418
  validation loss:		0.955408
  validation accuracy:		89.35 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.027825
  validation loss:		0.967699
  validation accuracy:		89.35 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.024082
  validation loss:		0.957955
  validation accuracy:		89.89 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.029577
  validation loss:		0.974275
  validation accuracy:		89.24 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.022775
  validation loss:		0.987648
  validation accuracy:		89.13 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.023328
  validation loss:		0.964177
  validation accuracy:		89.13 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.024729
  validation loss:		0.975462
  validation accuracy:		89.24 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.024944
  validation loss:		1.012824
  validation accuracy:		89.02 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.022075
  validation loss:		1.008642
  validation accuracy:		89.46 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.029325
  validation loss:		0.997062
  validation accuracy:		89.13 %
Epoch 1445 of 2000 took 0.097s
  training loss:		0.026345
  validation loss:		1.024526
  validation accuracy:		88.91 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.023588
  validation loss:		0.971921
  validation accuracy:		89.89 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.023201
  validation loss:		0.970616
  validation accuracy:		89.46 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.022495
  validation loss:		1.033874
  validation accuracy:		89.02 %
Epoch 1449 of 2000 took 0.097s
  training loss:		0.023293
  validation loss:		1.039815
  validation accuracy:		88.91 %
Epoch 1450 of 2000 took 0.097s
  training loss:		0.022238
  validation loss:		0.969839
  validation accuracy:		89.35 %
Epoch 1451 of 2000 took 0.097s
  training loss:		0.025047
  validation loss:		0.973056
  validation accuracy:		89.35 %
Epoch 1452 of 2000 took 0.097s
  training loss:		0.021702
  validation loss:		0.993354
  validation accuracy:		89.78 %
Epoch 1453 of 2000 took 0.097s
  training loss:		0.023123
  validation loss:		1.007120
  validation accuracy:		88.70 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.028253
  validation loss:		1.000192
  validation accuracy:		89.89 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.020814
  validation loss:		1.062575
  validation accuracy:		88.37 %
Epoch 1456 of 2000 took 0.097s
  training loss:		0.026713
  validation loss:		1.029454
  validation accuracy:		89.35 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.022124
  validation loss:		1.019311
  validation accuracy:		89.13 %
Epoch 1458 of 2000 took 0.097s
  training loss:		0.034466
  validation loss:		1.061580
  validation accuracy:		88.26 %
Epoch 1459 of 2000 took 0.098s
  training loss:		14.277547
  validation loss:		82.272289
  validation accuracy:		44.24 %
Epoch 1460 of 2000 took 0.097s
  training loss:		128.330527
  validation loss:		12.785398
  validation accuracy:		25.98 %
Epoch 1461 of 2000 took 0.097s
  training loss:		5.269961
  validation loss:		1.720666
  validation accuracy:		40.76 %
Epoch 1462 of 2000 took 0.097s
  training loss:		2.187958
  validation loss:		1.840622
  validation accuracy:		35.33 %
Epoch 1463 of 2000 took 0.097s
  training loss:		1.935389
  validation loss:		1.676055
  validation accuracy:		43.70 %
Epoch 1464 of 2000 took 0.097s
  training loss:		1.798541
  validation loss:		1.567553
  validation accuracy:		48.15 %
Epoch 1465 of 2000 took 0.097s
  training loss:		1.679941
  validation loss:		1.523731
  validation accuracy:		53.48 %
Epoch 1466 of 2000 took 0.097s
  training loss:		1.600086
  validation loss:		1.421884
  validation accuracy:		58.70 %
Epoch 1467 of 2000 took 0.097s
  training loss:		1.526072
  validation loss:		1.370040
  validation accuracy:		60.11 %
Epoch 1468 of 2000 took 0.097s
  training loss:		1.464422
  validation loss:		1.310193
  validation accuracy:		62.93 %
Epoch 1469 of 2000 took 0.097s
  training loss:		1.399459
  validation loss:		1.279788
  validation accuracy:		64.02 %
Epoch 1470 of 2000 took 0.097s
  training loss:		1.345312
  validation loss:		1.242609
  validation accuracy:		63.59 %
Epoch 1471 of 2000 took 0.097s
  training loss:		1.296419
  validation loss:		1.189401
  validation accuracy:		68.26 %
Epoch 1472 of 2000 took 0.097s
  training loss:		1.248900
  validation loss:		1.135102
  validation accuracy:		68.15 %
Epoch 1473 of 2000 took 0.097s
  training loss:		1.202129
  validation loss:		1.128607
  validation accuracy:		69.46 %
Epoch 1474 of 2000 took 0.097s
  training loss:		1.162798
  validation loss:		1.057320
  validation accuracy:		70.33 %
Epoch 1475 of 2000 took 0.097s
  training loss:		1.101294
  validation loss:		1.021843
  validation accuracy:		72.28 %
Epoch 1476 of 2000 took 0.097s
  training loss:		1.075935
  validation loss:		0.996341
  validation accuracy:		74.02 %
Epoch 1477 of 2000 took 0.098s
  training loss:		1.015247
  validation loss:		0.938431
  validation accuracy:		75.76 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.983418
  validation loss:		0.912238
  validation accuracy:		75.43 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.946512
  validation loss:		0.864627
  validation accuracy:		75.87 %
Epoch 1480 of 2000 took 0.100s
  training loss:		0.896797
  validation loss:		0.825270
  validation accuracy:		78.48 %
Epoch 1481 of 2000 took 0.107s
  training loss:		0.865542
  validation loss:		0.794458
  validation accuracy:		77.61 %
Epoch 1482 of 2000 took 0.107s
  training loss:		0.838538
  validation loss:		0.794602
  validation accuracy:		78.26 %
Epoch 1483 of 2000 took 0.107s
  training loss:		0.805029
  validation loss:		0.751536
  validation accuracy:		79.24 %
Epoch 1484 of 2000 took 0.100s
  training loss:		0.773486
  validation loss:		0.706994
  validation accuracy:		80.76 %
Epoch 1485 of 2000 took 0.100s
  training loss:		0.750798
  validation loss:		0.703802
  validation accuracy:		80.43 %
Epoch 1486 of 2000 took 0.100s
  training loss:		0.728008
  validation loss:		0.669595
  validation accuracy:		81.20 %
Epoch 1487 of 2000 took 0.100s
  training loss:		0.707382
  validation loss:		0.649748
  validation accuracy:		82.17 %
Epoch 1488 of 2000 took 0.100s
  training loss:		0.688428
  validation loss:		0.646424
  validation accuracy:		82.07 %
Epoch 1489 of 2000 took 0.100s
  training loss:		0.665332
  validation loss:		0.642873
  validation accuracy:		80.87 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.662747
  validation loss:		0.599377
  validation accuracy:		82.39 %
Epoch 1491 of 2000 took 0.100s
  training loss:		0.631028
  validation loss:		0.604680
  validation accuracy:		82.17 %
Epoch 1492 of 2000 took 0.100s
  training loss:		0.615132
  validation loss:		0.575432
  validation accuracy:		83.37 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.590825
  validation loss:		0.560248
  validation accuracy:		83.48 %
Epoch 1494 of 2000 took 0.100s
  training loss:		0.584487
  validation loss:		0.554266
  validation accuracy:		83.70 %
Epoch 1495 of 2000 took 0.100s
  training loss:		0.570031
  validation loss:		0.552673
  validation accuracy:		82.61 %
Epoch 1496 of 2000 took 0.100s
  training loss:		0.556612
  validation loss:		0.526538
  validation accuracy:		83.70 %
Epoch 1497 of 2000 took 0.097s
  training loss:		0.551986
  validation loss:		0.594634
  validation accuracy:		81.09 %
Epoch 1498 of 2000 took 0.097s
  training loss:		0.539668
  validation loss:		0.530910
  validation accuracy:		84.02 %
Epoch 1499 of 2000 took 0.097s
  training loss:		0.519147
  validation loss:		0.497929
  validation accuracy:		85.11 %
Epoch 1500 of 2000 took 0.097s
  training loss:		0.510915
  validation loss:		0.494685
  validation accuracy:		85.11 %
Epoch 1501 of 2000 took 0.097s
  training loss:		0.497830
  validation loss:		0.498036
  validation accuracy:		84.57 %
Epoch 1502 of 2000 took 0.097s
  training loss:		0.492958
  validation loss:		0.486198
  validation accuracy:		84.89 %
Epoch 1503 of 2000 took 0.097s
  training loss:		0.479135
  validation loss:		0.477718
  validation accuracy:		85.22 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.475134
  validation loss:		0.561158
  validation accuracy:		81.63 %
Epoch 1505 of 2000 took 0.097s
  training loss:		0.467160
  validation loss:		0.475078
  validation accuracy:		85.43 %
Epoch 1506 of 2000 took 0.097s
  training loss:		0.470512
  validation loss:		0.456781
  validation accuracy:		85.76 %
Epoch 1507 of 2000 took 0.097s
  training loss:		0.441859
  validation loss:		0.453564
  validation accuracy:		85.87 %
Epoch 1508 of 2000 took 0.098s
  training loss:		0.432783
  validation loss:		0.445500
  validation accuracy:		86.63 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.432697
  validation loss:		0.434556
  validation accuracy:		86.20 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.429840
  validation loss:		0.428785
  validation accuracy:		86.85 %
Epoch 1511 of 2000 took 0.097s
  training loss:		0.427287
  validation loss:		0.436195
  validation accuracy:		86.52 %
Epoch 1512 of 2000 took 0.097s
  training loss:		0.404705
  validation loss:		0.424326
  validation accuracy:		86.85 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.408179
  validation loss:		0.419273
  validation accuracy:		87.28 %
Epoch 1514 of 2000 took 0.097s
  training loss:		0.402106
  validation loss:		0.428972
  validation accuracy:		86.63 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.392876
  validation loss:		0.407328
  validation accuracy:		87.07 %
Epoch 1516 of 2000 took 0.098s
  training loss:		0.392909
  validation loss:		0.415445
  validation accuracy:		86.74 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.373847
  validation loss:		0.402662
  validation accuracy:		87.17 %
Epoch 1518 of 2000 took 0.097s
  training loss:		0.381490
  validation loss:		0.406410
  validation accuracy:		87.72 %
Epoch 1519 of 2000 took 0.097s
  training loss:		0.367162
  validation loss:		0.408484
  validation accuracy:		87.83 %
Epoch 1520 of 2000 took 0.097s
  training loss:		0.361214
  validation loss:		0.411220
  validation accuracy:		87.61 %
Epoch 1521 of 2000 took 0.097s
  training loss:		0.357959
  validation loss:		0.398278
  validation accuracy:		87.39 %
Epoch 1522 of 2000 took 0.097s
  training loss:		0.360081
  validation loss:		0.411169
  validation accuracy:		87.83 %
Epoch 1523 of 2000 took 0.097s
  training loss:		0.352364
  validation loss:		0.386975
  validation accuracy:		88.70 %
Epoch 1524 of 2000 took 0.097s
  training loss:		0.349415
  validation loss:		0.443393
  validation accuracy:		85.54 %
Epoch 1525 of 2000 took 0.097s
  training loss:		0.346090
  validation loss:		0.381770
  validation accuracy:		88.15 %
Epoch 1526 of 2000 took 0.097s
  training loss:		0.350984
  validation loss:		0.385762
  validation accuracy:		88.37 %
Epoch 1527 of 2000 took 0.097s
  training loss:		0.342509
  validation loss:		0.383821
  validation accuracy:		87.93 %
Epoch 1528 of 2000 took 0.097s
  training loss:		0.345148
  validation loss:		0.406832
  validation accuracy:		87.83 %
Epoch 1529 of 2000 took 0.097s
  training loss:		0.346147
  validation loss:		0.375729
  validation accuracy:		88.70 %
Epoch 1530 of 2000 took 0.097s
  training loss:		0.333790
  validation loss:		0.381572
  validation accuracy:		88.37 %
Epoch 1531 of 2000 took 0.097s
  training loss:		0.334424
  validation loss:		0.376952
  validation accuracy:		88.70 %
Epoch 1532 of 2000 took 0.097s
  training loss:		0.328388
  validation loss:		0.370564
  validation accuracy:		88.59 %
Epoch 1533 of 2000 took 0.097s
  training loss:		0.323473
  validation loss:		0.369549
  validation accuracy:		88.70 %
Epoch 1534 of 2000 took 0.097s
  training loss:		0.318711
  validation loss:		0.369742
  validation accuracy:		88.26 %
Epoch 1535 of 2000 took 0.097s
  training loss:		0.315340
  validation loss:		0.367823
  validation accuracy:		88.91 %
Epoch 1536 of 2000 took 0.097s
  training loss:		0.309418
  validation loss:		0.372609
  validation accuracy:		88.15 %
Epoch 1537 of 2000 took 0.097s
  training loss:		0.306426
  validation loss:		0.357617
  validation accuracy:		89.24 %
Epoch 1538 of 2000 took 0.097s
  training loss:		0.305142
  validation loss:		0.377400
  validation accuracy:		89.24 %
Epoch 1539 of 2000 took 0.098s
  training loss:		0.316657
  validation loss:		0.379634
  validation accuracy:		88.70 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.304862
  validation loss:		0.358685
  validation accuracy:		89.13 %
Epoch 1541 of 2000 took 0.097s
  training loss:		0.303957
  validation loss:		0.352380
  validation accuracy:		89.02 %
Epoch 1542 of 2000 took 0.097s
  training loss:		0.301868
  validation loss:		0.359836
  validation accuracy:		88.70 %
Epoch 1543 of 2000 took 0.097s
  training loss:		0.295070
  validation loss:		0.365574
  validation accuracy:		89.35 %
Epoch 1544 of 2000 took 0.097s
  training loss:		0.294155
  validation loss:		0.359784
  validation accuracy:		89.13 %
Epoch 1545 of 2000 took 0.097s
  training loss:		0.285432
  validation loss:		0.359641
  validation accuracy:		89.13 %
Epoch 1546 of 2000 took 0.097s
  training loss:		0.282995
  validation loss:		0.377704
  validation accuracy:		88.70 %
Epoch 1547 of 2000 took 0.097s
  training loss:		0.292209
  validation loss:		0.352304
  validation accuracy:		89.02 %
Epoch 1548 of 2000 took 0.097s
  training loss:		0.282734
  validation loss:		0.365180
  validation accuracy:		87.83 %
Epoch 1549 of 2000 took 0.097s
  training loss:		0.281773
  validation loss:		0.348945
  validation accuracy:		89.24 %
Epoch 1550 of 2000 took 0.097s
  training loss:		0.280680
  validation loss:		0.349776
  validation accuracy:		89.46 %
Epoch 1551 of 2000 took 0.097s
  training loss:		0.278191
  validation loss:		0.341381
  validation accuracy:		89.89 %
Epoch 1552 of 2000 took 0.097s
  training loss:		0.271246
  validation loss:		0.366897
  validation accuracy:		88.59 %
Epoch 1553 of 2000 took 0.097s
  training loss:		0.273963
  validation loss:		0.348977
  validation accuracy:		89.78 %
Epoch 1554 of 2000 took 0.097s
  training loss:		0.273873
  validation loss:		0.364988
  validation accuracy:		89.02 %
Epoch 1555 of 2000 took 0.097s
  training loss:		0.272187
  validation loss:		0.342422
  validation accuracy:		89.02 %
Epoch 1556 of 2000 took 0.097s
  training loss:		0.267088
  validation loss:		0.346347
  validation accuracy:		88.80 %
Epoch 1557 of 2000 took 0.097s
  training loss:		0.269085
  validation loss:		0.335910
  validation accuracy:		89.67 %
Epoch 1558 of 2000 took 0.097s
  training loss:		0.266640
  validation loss:		0.348927
  validation accuracy:		89.24 %
Epoch 1559 of 2000 took 0.097s
  training loss:		0.261139
  validation loss:		0.352543
  validation accuracy:		89.57 %
Epoch 1560 of 2000 took 0.097s
  training loss:		0.259970
  validation loss:		0.343645
  validation accuracy:		90.22 %
Epoch 1561 of 2000 took 0.097s
  training loss:		0.264312
  validation loss:		0.362568
  validation accuracy:		88.91 %
Epoch 1562 of 2000 took 0.098s
  training loss:		0.256295
  validation loss:		0.324413
  validation accuracy:		90.11 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.256194
  validation loss:		0.346705
  validation accuracy:		89.13 %
Epoch 1564 of 2000 took 0.098s
  training loss:		0.260940
  validation loss:		0.355300
  validation accuracy:		89.35 %
Epoch 1565 of 2000 took 0.104s
  training loss:		0.251407
  validation loss:		0.334551
  validation accuracy:		90.11 %
Epoch 1566 of 2000 took 0.109s
  training loss:		0.252904
  validation loss:		0.337382
  validation accuracy:		90.22 %
Epoch 1567 of 2000 took 0.141s
  training loss:		0.247725
  validation loss:		0.363703
  validation accuracy:		89.46 %
Epoch 1568 of 2000 took 0.103s
  training loss:		0.252685
  validation loss:		0.325486
  validation accuracy:		90.22 %
Epoch 1569 of 2000 took 0.099s
  training loss:		0.238122
  validation loss:		0.343662
  validation accuracy:		89.57 %
Epoch 1570 of 2000 took 0.102s
  training loss:		0.247988
  validation loss:		0.332045
  validation accuracy:		89.89 %
Epoch 1571 of 2000 took 0.103s
  training loss:		0.248024
  validation loss:		0.328235
  validation accuracy:		89.13 %
Epoch 1572 of 2000 took 0.102s
  training loss:		0.243877
  validation loss:		0.333224
  validation accuracy:		90.33 %
Epoch 1573 of 2000 took 0.097s
  training loss:		0.238630
  validation loss:		0.332073
  validation accuracy:		90.54 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.247376
  validation loss:		0.345106
  validation accuracy:		89.78 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.242083
  validation loss:		0.324545
  validation accuracy:		90.43 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.237673
  validation loss:		0.321420
  validation accuracy:		90.22 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.236546
  validation loss:		0.340272
  validation accuracy:		89.67 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.236953
  validation loss:		0.323992
  validation accuracy:		90.33 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.231411
  validation loss:		0.337094
  validation accuracy:		89.57 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.228523
  validation loss:		0.326547
  validation accuracy:		90.22 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.231807
  validation loss:		0.321977
  validation accuracy:		90.11 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.230960
  validation loss:		0.321716
  validation accuracy:		90.65 %
Epoch 1583 of 2000 took 0.097s
  training loss:		0.227579
  validation loss:		0.318711
  validation accuracy:		90.76 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.227975
  validation loss:		0.351838
  validation accuracy:		89.46 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.238039
  validation loss:		0.342341
  validation accuracy:		90.22 %
Epoch 1586 of 2000 took 0.097s
  training loss:		0.218475
  validation loss:		0.331769
  validation accuracy:		89.46 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.234896
  validation loss:		0.327403
  validation accuracy:		90.22 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.214407
  validation loss:		0.325252
  validation accuracy:		89.78 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.221520
  validation loss:		0.333735
  validation accuracy:		89.67 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.222849
  validation loss:		0.318131
  validation accuracy:		90.87 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.227907
  validation loss:		0.320189
  validation accuracy:		89.67 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.223971
  validation loss:		0.326732
  validation accuracy:		90.54 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.215784
  validation loss:		0.351261
  validation accuracy:		89.35 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.218741
  validation loss:		0.324364
  validation accuracy:		90.22 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.212978
  validation loss:		0.330777
  validation accuracy:		90.00 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.216521
  validation loss:		0.333455
  validation accuracy:		90.22 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.214708
  validation loss:		0.327227
  validation accuracy:		90.54 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.214318
  validation loss:		0.311879
  validation accuracy:		90.87 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.204616
  validation loss:		0.351151
  validation accuracy:		88.70 %
Epoch 1600 of 2000 took 0.098s
  training loss:		0.214433
  validation loss:		0.322132
  validation accuracy:		90.43 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.211885
  validation loss:		0.317930
  validation accuracy:		90.54 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.206437
  validation loss:		0.327022
  validation accuracy:		90.33 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.206228
  validation loss:		0.314963
  validation accuracy:		91.09 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.206024
  validation loss:		0.314469
  validation accuracy:		90.87 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.206029
  validation loss:		0.314418
  validation accuracy:		90.65 %
Epoch 1606 of 2000 took 0.098s
  training loss:		0.196779
  validation loss:		0.336078
  validation accuracy:		90.43 %
Epoch 1607 of 2000 took 0.144s
  training loss:		0.210753
  validation loss:		0.316045
  validation accuracy:		90.98 %
Epoch 1608 of 2000 took 0.257s
  training loss:		0.205495
  validation loss:		0.316146
  validation accuracy:		90.98 %
Epoch 1609 of 2000 took 0.208s
  training loss:		0.205045
  validation loss:		0.324861
  validation accuracy:		90.11 %
Epoch 1610 of 2000 took 0.210s
  training loss:		0.212967
  validation loss:		0.311786
  validation accuracy:		90.98 %
Epoch 1611 of 2000 took 0.168s
  training loss:		0.205730
  validation loss:		0.314449
  validation accuracy:		91.09 %
Epoch 1612 of 2000 took 0.205s
  training loss:		0.203686
  validation loss:		0.337271
  validation accuracy:		90.22 %
Epoch 1613 of 2000 took 0.165s
  training loss:		0.200854
  validation loss:		0.320793
  validation accuracy:		90.33 %
Epoch 1614 of 2000 took 0.165s
  training loss:		0.196586
  validation loss:		0.321482
  validation accuracy:		89.89 %
Epoch 1615 of 2000 took 0.165s
  training loss:		0.194344
  validation loss:		0.314252
  validation accuracy:		90.54 %
Epoch 1616 of 2000 took 0.165s
  training loss:		0.199015
  validation loss:		0.344881
  validation accuracy:		89.78 %
Epoch 1617 of 2000 took 0.164s
  training loss:		0.195543
  validation loss:		0.314842
  validation accuracy:		90.98 %
Epoch 1618 of 2000 took 0.169s
  training loss:		0.202912
  validation loss:		0.352222
  validation accuracy:		90.22 %
Epoch 1619 of 2000 took 0.163s
  training loss:		0.208630
  validation loss:		0.311749
  validation accuracy:		91.20 %
Epoch 1620 of 2000 took 0.170s
  training loss:		0.193269
  validation loss:		0.324220
  validation accuracy:		90.43 %
Epoch 1621 of 2000 took 0.171s
  training loss:		0.191987
  validation loss:		0.323672
  validation accuracy:		90.43 %
Epoch 1622 of 2000 took 0.168s
  training loss:		0.190658
  validation loss:		0.306438
  validation accuracy:		91.41 %
Epoch 1623 of 2000 took 0.169s
  training loss:		0.193249
  validation loss:		0.336412
  validation accuracy:		90.22 %
Epoch 1624 of 2000 took 0.168s
  training loss:		0.193842
  validation loss:		0.304357
  validation accuracy:		90.87 %
Epoch 1625 of 2000 took 0.188s
  training loss:		0.190496
  validation loss:		0.329602
  validation accuracy:		90.43 %
Epoch 1626 of 2000 took 0.172s
  training loss:		0.186650
  validation loss:		0.338082
  validation accuracy:		89.78 %
Epoch 1627 of 2000 took 0.305s
  training loss:		0.187843
  validation loss:		0.317723
  validation accuracy:		91.20 %
Epoch 1628 of 2000 took 0.247s
  training loss:		0.189886
  validation loss:		0.310350
  validation accuracy:		90.65 %
Epoch 1629 of 2000 took 0.165s
  training loss:		0.191282
  validation loss:		0.306591
  validation accuracy:		91.63 %
Epoch 1630 of 2000 took 0.164s
  training loss:		0.192282
  validation loss:		0.329188
  validation accuracy:		90.22 %
Epoch 1631 of 2000 took 0.171s
  training loss:		0.185982
  validation loss:		0.323074
  validation accuracy:		90.87 %
Epoch 1632 of 2000 took 0.171s
  training loss:		0.183173
  validation loss:		0.318464
  validation accuracy:		91.09 %
Epoch 1633 of 2000 took 0.168s
  training loss:		0.183726
  validation loss:		0.339593
  validation accuracy:		89.24 %
Epoch 1634 of 2000 took 0.172s
  training loss:		0.188120
  validation loss:		0.337377
  validation accuracy:		90.11 %
Epoch 1635 of 2000 took 0.170s
  training loss:		0.184173
  validation loss:		0.331523
  validation accuracy:		90.54 %
Epoch 1636 of 2000 took 0.169s
  training loss:		0.187196
  validation loss:		0.338024
  validation accuracy:		90.22 %
Epoch 1637 of 2000 took 0.173s
  training loss:		0.187636
  validation loss:		0.319559
  validation accuracy:		90.87 %
Epoch 1638 of 2000 took 0.209s
  training loss:		0.184873
  validation loss:		0.320318
  validation accuracy:		91.41 %
Epoch 1639 of 2000 took 0.225s
  training loss:		0.187734
  validation loss:		0.324835
  validation accuracy:		90.54 %
Epoch 1640 of 2000 took 0.200s
  training loss:		0.179222
  validation loss:		0.325359
  validation accuracy:		90.22 %
Epoch 1641 of 2000 took 0.274s
  training loss:		0.184770
  validation loss:		0.311802
  validation accuracy:		90.65 %
Epoch 1642 of 2000 took 0.169s
  training loss:		0.187776
  validation loss:		0.324204
  validation accuracy:		90.76 %
Epoch 1643 of 2000 took 0.172s
  training loss:		0.182270
  validation loss:		0.337022
  validation accuracy:		90.22 %
Epoch 1644 of 2000 took 0.164s
  training loss:		0.188097
  validation loss:		0.313052
  validation accuracy:		90.98 %
Epoch 1645 of 2000 took 0.170s
  training loss:		0.182853
  validation loss:		0.331093
  validation accuracy:		90.33 %
Epoch 1646 of 2000 took 0.168s
  training loss:		0.178658
  validation loss:		0.318095
  validation accuracy:		91.20 %
Epoch 1647 of 2000 took 0.171s
  training loss:		0.179910
  validation loss:		0.321287
  validation accuracy:		90.87 %
Epoch 1648 of 2000 took 0.170s
  training loss:		0.173811
  validation loss:		0.322408
  validation accuracy:		90.22 %
Epoch 1649 of 2000 took 0.168s
  training loss:		0.173179
  validation loss:		0.345008
  validation accuracy:		90.76 %
Epoch 1650 of 2000 took 0.172s
  training loss:		0.180879
  validation loss:		0.331564
  validation accuracy:		89.89 %
Epoch 1651 of 2000 took 0.170s
  training loss:		0.179378
  validation loss:		0.306758
  validation accuracy:		91.74 %
Epoch 1652 of 2000 took 0.169s
  training loss:		0.177942
  validation loss:		0.325116
  validation accuracy:		90.43 %
Epoch 1653 of 2000 took 0.169s
  training loss:		0.178835
  validation loss:		0.320408
  validation accuracy:		90.65 %
Epoch 1654 of 2000 took 0.169s
  training loss:		0.172824
  validation loss:		0.318099
  validation accuracy:		90.65 %
Epoch 1655 of 2000 took 0.170s
  training loss:		0.175271
  validation loss:		0.322053
  validation accuracy:		90.87 %
Epoch 1656 of 2000 took 0.169s
  training loss:		0.176872
  validation loss:		0.341270
  validation accuracy:		90.98 %
Epoch 1657 of 2000 took 0.223s
  training loss:		0.179091
  validation loss:		0.318042
  validation accuracy:		90.98 %
Epoch 1658 of 2000 took 0.230s
  training loss:		0.171590
  validation loss:		0.302405
  validation accuracy:		91.96 %
Epoch 1659 of 2000 took 0.169s
  training loss:		0.178988
  validation loss:		0.331200
  validation accuracy:		90.98 %
Epoch 1660 of 2000 took 0.169s
  training loss:		0.174560
  validation loss:		0.323154
  validation accuracy:		90.43 %
Epoch 1661 of 2000 took 0.169s
  training loss:		0.178506
  validation loss:		0.315989
  validation accuracy:		91.20 %
Epoch 1662 of 2000 took 0.172s
  training loss:		0.173019
  validation loss:		0.318759
  validation accuracy:		91.20 %
Epoch 1663 of 2000 took 0.169s
  training loss:		0.172492
  validation loss:		0.343707
  validation accuracy:		90.43 %
Epoch 1664 of 2000 took 0.170s
  training loss:		0.168772
  validation loss:		0.322229
  validation accuracy:		90.54 %
Epoch 1665 of 2000 took 0.173s
  training loss:		0.177442
  validation loss:		0.311321
  validation accuracy:		90.98 %
Epoch 1666 of 2000 took 0.168s
  training loss:		0.174090
  validation loss:		0.347797
  validation accuracy:		90.43 %
Epoch 1667 of 2000 took 0.226s
  training loss:		0.167838
  validation loss:		0.326851
  validation accuracy:		90.54 %
Epoch 1668 of 2000 took 0.394s
  training loss:		0.169708
  validation loss:		0.315754
  validation accuracy:		91.09 %
Epoch 1669 of 2000 took 0.196s
  training loss:		0.177065
  validation loss:		0.355535
  validation accuracy:		90.11 %
Epoch 1670 of 2000 took 0.334s
  training loss:		0.169877
  validation loss:		0.331919
  validation accuracy:		90.43 %
Epoch 1671 of 2000 took 0.230s
  training loss:		0.167310
  validation loss:		0.312797
  validation accuracy:		91.74 %
Epoch 1672 of 2000 took 0.171s
  training loss:		0.167366
  validation loss:		0.322533
  validation accuracy:		90.87 %
Epoch 1673 of 2000 took 0.246s
  training loss:		0.170098
  validation loss:		0.324104
  validation accuracy:		90.76 %
Epoch 1674 of 2000 took 0.171s
  training loss:		0.169760
  validation loss:		0.351883
  validation accuracy:		90.00 %
Epoch 1675 of 2000 took 0.168s
  training loss:		0.168236
  validation loss:		0.323297
  validation accuracy:		91.09 %
Epoch 1676 of 2000 took 0.171s
  training loss:		0.166700
  validation loss:		0.353505
  validation accuracy:		90.11 %
Epoch 1677 of 2000 took 0.171s
  training loss:		0.165912
  validation loss:		0.339882
  validation accuracy:		90.65 %
Epoch 1678 of 2000 took 0.169s
  training loss:		0.164399
  validation loss:		0.331942
  validation accuracy:		90.43 %
Epoch 1679 of 2000 took 0.168s
  training loss:		0.161147
  validation loss:		0.312448
  validation accuracy:		91.74 %
Epoch 1680 of 2000 took 0.263s
  training loss:		0.169244
  validation loss:		0.324057
  validation accuracy:		90.54 %
Epoch 1681 of 2000 took 0.208s
  training loss:		0.164430
  validation loss:		0.330896
  validation accuracy:		90.43 %
Epoch 1682 of 2000 took 0.201s
  training loss:		0.159414
  validation loss:		0.339107
  validation accuracy:		90.43 %
Epoch 1683 of 2000 took 0.210s
  training loss:		0.164408
  validation loss:		0.325892
  validation accuracy:		90.22 %
Epoch 1684 of 2000 took 0.208s
  training loss:		0.172850
  validation loss:		0.339046
  validation accuracy:		90.76 %
Epoch 1685 of 2000 took 0.208s
  training loss:		0.161504
  validation loss:		0.316507
  validation accuracy:		91.30 %
Epoch 1686 of 2000 took 0.193s
  training loss:		0.161244
  validation loss:		0.334649
  validation accuracy:		90.33 %
Epoch 1687 of 2000 took 0.208s
  training loss:		0.168229
  validation loss:		0.339570
  validation accuracy:		90.54 %
Epoch 1688 of 2000 took 0.203s
  training loss:		0.163421
  validation loss:		0.312579
  validation accuracy:		91.63 %
Epoch 1689 of 2000 took 0.188s
  training loss:		0.166193
  validation loss:		0.344011
  validation accuracy:		90.87 %
Epoch 1690 of 2000 took 0.205s
  training loss:		0.170248
  validation loss:		0.316855
  validation accuracy:		90.87 %
Epoch 1691 of 2000 took 0.191s
  training loss:		0.159897
  validation loss:		0.322015
  validation accuracy:		90.87 %
Epoch 1692 of 2000 took 0.167s
  training loss:		0.163243
  validation loss:		0.351733
  validation accuracy:		89.78 %
Epoch 1693 of 2000 took 0.166s
  training loss:		0.165237
  validation loss:		0.324873
  validation accuracy:		90.33 %
Epoch 1694 of 2000 took 0.170s
  training loss:		0.154242
  validation loss:		0.323981
  validation accuracy:		90.87 %
Epoch 1695 of 2000 took 0.167s
  training loss:		0.158722
  validation loss:		0.330564
  validation accuracy:		90.54 %
Epoch 1696 of 2000 took 0.166s
  training loss:		0.162149
  validation loss:		0.332691
  validation accuracy:		90.76 %
Epoch 1697 of 2000 took 0.170s
  training loss:		0.159360
  validation loss:		0.320782
  validation accuracy:		91.09 %
Epoch 1698 of 2000 took 0.167s
  training loss:		0.162797
  validation loss:		0.332176
  validation accuracy:		91.09 %
Epoch 1699 of 2000 took 0.182s
  training loss:		0.157370
  validation loss:		0.324692
  validation accuracy:		90.98 %
Epoch 1700 of 2000 took 0.166s
  training loss:		0.158732
  validation loss:		0.350173
  validation accuracy:		90.22 %
Epoch 1701 of 2000 took 0.167s
  training loss:		0.155361
  validation loss:		0.311501
  validation accuracy:		90.98 %
Epoch 1702 of 2000 took 0.169s
  training loss:		0.156196
  validation loss:		0.323148
  validation accuracy:		91.20 %
Epoch 1703 of 2000 took 0.166s
  training loss:		0.161652
  validation loss:		0.320705
  validation accuracy:		90.54 %
Epoch 1704 of 2000 took 0.167s
  training loss:		0.156094
  validation loss:		0.337891
  validation accuracy:		90.54 %
Epoch 1705 of 2000 took 0.170s
  training loss:		0.159511
  validation loss:		0.351868
  validation accuracy:		89.78 %
Epoch 1706 of 2000 took 0.175s
  training loss:		0.156740
  validation loss:		0.335041
  validation accuracy:		90.33 %
Epoch 1707 of 2000 took 0.203s
  training loss:		0.153434
  validation loss:		0.321254
  validation accuracy:		91.30 %
Epoch 1708 of 2000 took 0.166s
  training loss:		0.152552
  validation loss:		0.317915
  validation accuracy:		91.30 %
Epoch 1709 of 2000 took 0.170s
  training loss:		0.151136
  validation loss:		0.328665
  validation accuracy:		90.87 %
Epoch 1710 of 2000 took 0.167s
  training loss:		0.157887
  validation loss:		0.324761
  validation accuracy:		90.98 %
Epoch 1711 of 2000 took 0.166s
  training loss:		0.157167
  validation loss:		0.333046
  validation accuracy:		90.22 %
Epoch 1712 of 2000 took 0.171s
  training loss:		0.155546
  validation loss:		0.321398
  validation accuracy:		91.09 %
Epoch 1713 of 2000 took 0.166s
  training loss:		0.154092
  validation loss:		0.323027
  validation accuracy:		90.87 %
Epoch 1714 of 2000 took 0.208s
  training loss:		0.149172
  validation loss:		0.345132
  validation accuracy:		90.54 %
Epoch 1715 of 2000 took 0.166s
  training loss:		0.150675
  validation loss:		0.343199
  validation accuracy:		90.43 %
Epoch 1716 of 2000 took 0.168s
  training loss:		0.155215
  validation loss:		0.336060
  validation accuracy:		90.43 %
Epoch 1717 of 2000 took 0.184s
  training loss:		0.149460
  validation loss:		0.330609
  validation accuracy:		91.20 %
Epoch 1718 of 2000 took 0.166s
  training loss:		0.153679
  validation loss:		0.317058
  validation accuracy:		91.30 %
Epoch 1719 of 2000 took 0.169s
  training loss:		0.150369
  validation loss:		0.317337
  validation accuracy:		91.20 %
Epoch 1720 of 2000 took 0.169s
  training loss:		0.154493
  validation loss:		0.322260
  validation accuracy:		91.30 %
Epoch 1721 of 2000 took 0.166s
  training loss:		0.149274
  validation loss:		0.322509
  validation accuracy:		91.30 %
Epoch 1722 of 2000 took 0.167s
  training loss:		0.146389
  validation loss:		0.338758
  validation accuracy:		90.43 %
Epoch 1723 of 2000 took 0.166s
  training loss:		0.156211
  validation loss:		0.319788
  validation accuracy:		91.09 %
Epoch 1724 of 2000 took 0.168s
  training loss:		0.149468
  validation loss:		0.323054
  validation accuracy:		91.30 %
Epoch 1725 of 2000 took 0.169s
  training loss:		0.148919
  validation loss:		0.373772
  validation accuracy:		89.57 %
Epoch 1726 of 2000 took 0.165s
  training loss:		0.150912
  validation loss:		0.323631
  validation accuracy:		91.41 %
Epoch 1727 of 2000 took 0.165s
  training loss:		0.150249
  validation loss:		0.325524
  validation accuracy:		91.20 %
Epoch 1728 of 2000 took 0.167s
  training loss:		0.147024
  validation loss:		0.369485
  validation accuracy:		89.67 %
Epoch 1729 of 2000 took 0.210s
  training loss:		0.158615
  validation loss:		0.327950
  validation accuracy:		90.98 %
Epoch 1730 of 2000 took 0.166s
  training loss:		0.144178
  validation loss:		0.340955
  validation accuracy:		90.43 %
Epoch 1731 of 2000 took 0.167s
  training loss:		0.158334
  validation loss:		0.336017
  validation accuracy:		90.43 %
Epoch 1732 of 2000 took 0.166s
  training loss:		0.145941
  validation loss:		0.355228
  validation accuracy:		90.43 %
Epoch 1733 of 2000 took 0.170s
  training loss:		0.151106
  validation loss:		0.335395
  validation accuracy:		90.54 %
Epoch 1734 of 2000 took 0.179s
  training loss:		0.147909
  validation loss:		0.333367
  validation accuracy:		91.30 %
Epoch 1735 of 2000 took 0.167s
  training loss:		0.152980
  validation loss:		0.345098
  validation accuracy:		90.22 %
Epoch 1736 of 2000 took 0.171s
  training loss:		0.150122
  validation loss:		0.354156
  validation accuracy:		90.11 %
Epoch 1737 of 2000 took 0.166s
  training loss:		0.149693
  validation loss:		0.334106
  validation accuracy:		90.76 %
Epoch 1738 of 2000 took 0.167s
  training loss:		0.151854
  validation loss:		0.376680
  validation accuracy:		89.57 %
Epoch 1739 of 2000 took 0.166s
  training loss:		0.149265
  validation loss:		0.346576
  validation accuracy:		90.43 %
Epoch 1740 of 2000 took 0.168s
  training loss:		0.146355
  validation loss:		0.326456
  validation accuracy:		90.87 %
Epoch 1741 of 2000 took 0.170s
  training loss:		0.145679
  validation loss:		0.331697
  validation accuracy:		91.41 %
Epoch 1742 of 2000 took 0.166s
  training loss:		0.150269
  validation loss:		0.352422
  validation accuracy:		90.33 %
Epoch 1743 of 2000 took 0.166s
  training loss:		0.150025
  validation loss:		0.359692
  validation accuracy:		89.67 %
Epoch 1744 of 2000 took 0.212s
  training loss:		0.145909
  validation loss:		0.355126
  validation accuracy:		90.54 %
Epoch 1745 of 2000 took 0.166s
  training loss:		0.143260
  validation loss:		0.344823
  validation accuracy:		90.87 %
Epoch 1746 of 2000 took 0.167s
  training loss:		0.146410
  validation loss:		0.347038
  validation accuracy:		90.33 %
Epoch 1747 of 2000 took 0.189s
  training loss:		0.145543
  validation loss:		0.343621
  validation accuracy:		90.43 %
Epoch 1748 of 2000 took 0.179s
  training loss:		0.143886
  validation loss:		0.329946
  validation accuracy:		90.76 %
Epoch 1749 of 2000 took 0.165s
  training loss:		0.153985
  validation loss:		0.343888
  validation accuracy:		90.65 %
Epoch 1750 of 2000 took 0.165s
  training loss:		0.142653
  validation loss:		0.340340
  validation accuracy:		91.09 %
Epoch 1751 of 2000 took 0.165s
  training loss:		0.144117
  validation loss:		0.333007
  validation accuracy:		91.20 %
Epoch 1752 of 2000 took 0.165s
  training loss:		0.143915
  validation loss:		0.340584
  validation accuracy:		90.65 %
Epoch 1753 of 2000 took 0.165s
  training loss:		0.141308
  validation loss:		0.343776
  validation accuracy:		91.20 %
Epoch 1754 of 2000 took 0.165s
  training loss:		0.141321
  validation loss:		0.357577
  validation accuracy:		89.89 %
Epoch 1755 of 2000 took 0.165s
  training loss:		0.142628
  validation loss:		0.326308
  validation accuracy:		91.20 %
Epoch 1756 of 2000 took 0.165s
  training loss:		0.135718
  validation loss:		0.333538
  validation accuracy:		90.65 %
Epoch 1757 of 2000 took 0.165s
  training loss:		0.141168
  validation loss:		0.331701
  validation accuracy:		90.98 %
Epoch 1758 of 2000 took 0.165s
  training loss:		0.141367
  validation loss:		0.325138
  validation accuracy:		91.20 %
Epoch 1759 of 2000 took 0.165s
  training loss:		0.150747
  validation loss:		0.348369
  validation accuracy:		90.76 %
Epoch 1760 of 2000 took 0.165s
  training loss:		0.141610
  validation loss:		0.340940
  validation accuracy:		90.87 %
Epoch 1761 of 2000 took 0.165s
  training loss:		0.144010
  validation loss:		0.340289
  validation accuracy:		90.98 %
Epoch 1762 of 2000 took 0.162s
  training loss:		0.139610
  validation loss:		0.341894
  validation accuracy:		90.54 %
Epoch 1763 of 2000 took 0.162s
  training loss:		0.139978
  validation loss:		0.376039
  validation accuracy:		89.78 %
Epoch 1764 of 2000 took 0.165s
  training loss:		0.141228
  validation loss:		0.343220
  validation accuracy:		90.87 %
Epoch 1765 of 2000 took 0.165s
  training loss:		0.141979
  validation loss:		0.345449
  validation accuracy:		90.22 %
Epoch 1766 of 2000 took 0.165s
  training loss:		0.131509
  validation loss:		0.355399
  validation accuracy:		90.33 %
Epoch 1767 of 2000 took 0.165s
  training loss:		0.141044
  validation loss:		0.347298
  validation accuracy:		90.33 %
Epoch 1768 of 2000 took 0.165s
  training loss:		0.143179
  validation loss:		0.336965
  validation accuracy:		91.09 %
Epoch 1769 of 2000 took 0.165s
  training loss:		0.142848
  validation loss:		0.341386
  validation accuracy:		91.09 %
Epoch 1770 of 2000 took 0.165s
  training loss:		0.139229
  validation loss:		0.366559
  validation accuracy:		90.00 %
Epoch 1771 of 2000 took 0.165s
  training loss:		0.142728
  validation loss:		0.357175
  validation accuracy:		90.22 %
Epoch 1772 of 2000 took 0.165s
  training loss:		0.137314
  validation loss:		0.345769
  validation accuracy:		90.76 %
Epoch 1773 of 2000 took 0.165s
  training loss:		0.141411
  validation loss:		0.343871
  validation accuracy:		91.09 %
Epoch 1774 of 2000 took 0.165s
  training loss:		0.135660
  validation loss:		0.357633
  validation accuracy:		90.33 %
Epoch 1775 of 2000 took 0.165s
  training loss:		0.141468
  validation loss:		0.338643
  validation accuracy:		90.65 %
Epoch 1776 of 2000 took 0.165s
  training loss:		0.143541
  validation loss:		0.350058
  validation accuracy:		90.33 %
Epoch 1777 of 2000 took 0.165s
  training loss:		0.138368
  validation loss:		0.343983
  validation accuracy:		90.87 %
Epoch 1778 of 2000 took 0.163s
  training loss:		0.143935
  validation loss:		0.345406
  validation accuracy:		90.54 %
Epoch 1779 of 2000 took 0.165s
  training loss:		0.140694
  validation loss:		0.330460
  validation accuracy:		90.98 %
Epoch 1780 of 2000 took 0.124s
  training loss:		0.139195
  validation loss:		0.369853
  validation accuracy:		90.00 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.134775
  validation loss:		0.330657
  validation accuracy:		91.30 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.138200
  validation loss:		0.339726
  validation accuracy:		90.65 %
Epoch 1783 of 2000 took 0.104s
  training loss:		0.137164
  validation loss:		0.340221
  validation accuracy:		90.87 %
Epoch 1784 of 2000 took 0.105s
  training loss:		0.132815
  validation loss:		0.340201
  validation accuracy:		90.87 %
Epoch 1785 of 2000 took 0.101s
  training loss:		0.135822
  validation loss:		0.333750
  validation accuracy:		90.98 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.140669
  validation loss:		0.349259
  validation accuracy:		90.76 %
Epoch 1787 of 2000 took 0.100s
  training loss:		0.138828
  validation loss:		0.358505
  validation accuracy:		90.00 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.135684
  validation loss:		0.343729
  validation accuracy:		90.87 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.132024
  validation loss:		0.363084
  validation accuracy:		90.11 %
Epoch 1790 of 2000 took 0.099s
  training loss:		0.133841
  validation loss:		0.349266
  validation accuracy:		90.33 %
Epoch 1791 of 2000 took 0.098s
  training loss:		0.131923
  validation loss:		0.362810
  validation accuracy:		90.11 %
Epoch 1792 of 2000 took 0.095s
  training loss:		0.138135
  validation loss:		0.338603
  validation accuracy:		91.20 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.131521
  validation loss:		0.361822
  validation accuracy:		90.22 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.136827
  validation loss:		0.351965
  validation accuracy:		90.33 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.135932
  validation loss:		0.358649
  validation accuracy:		90.33 %
Epoch 1796 of 2000 took 0.103s
  training loss:		0.132517
  validation loss:		0.374339
  validation accuracy:		90.11 %
Epoch 1797 of 2000 took 0.098s
  training loss:		0.132702
  validation loss:		0.347123
  validation accuracy:		90.87 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.134685
  validation loss:		0.345455
  validation accuracy:		90.54 %
Epoch 1799 of 2000 took 0.100s
  training loss:		0.136822
  validation loss:		0.363964
  validation accuracy:		90.33 %
Epoch 1800 of 2000 took 0.100s
  training loss:		0.124974
  validation loss:		0.369575
  validation accuracy:		90.33 %
Epoch 1801 of 2000 took 0.101s
  training loss:		0.135026
  validation loss:		0.341177
  validation accuracy:		90.65 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.131968
  validation loss:		0.345854
  validation accuracy:		91.09 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.134938
  validation loss:		0.363975
  validation accuracy:		89.89 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.135581
  validation loss:		0.358407
  validation accuracy:		90.33 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.131983
  validation loss:		0.362043
  validation accuracy:		89.67 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.131584
  validation loss:		0.352040
  validation accuracy:		90.54 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.128214
  validation loss:		0.347693
  validation accuracy:		90.00 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.133434
  validation loss:		0.345918
  validation accuracy:		90.33 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.133207
  validation loss:		0.347301
  validation accuracy:		90.54 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.128679
  validation loss:		0.371639
  validation accuracy:		90.43 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.126707
  validation loss:		0.335423
  validation accuracy:		90.76 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.133101
  validation loss:		0.356965
  validation accuracy:		90.76 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.134231
  validation loss:		0.352782
  validation accuracy:		90.43 %
Epoch 1814 of 2000 took 0.096s
  training loss:		0.132580
  validation loss:		0.346723
  validation accuracy:		90.87 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.124786
  validation loss:		0.351122
  validation accuracy:		90.54 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.129619
  validation loss:		0.354033
  validation accuracy:		90.33 %
Epoch 1817 of 2000 took 0.096s
  training loss:		0.129334
  validation loss:		0.357406
  validation accuracy:		89.89 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.128208
  validation loss:		0.350786
  validation accuracy:		90.54 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.126037
  validation loss:		0.354988
  validation accuracy:		90.33 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.124705
  validation loss:		0.362466
  validation accuracy:		90.00 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.130768
  validation loss:		0.391927
  validation accuracy:		90.22 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.133893
  validation loss:		0.375455
  validation accuracy:		90.22 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.126898
  validation loss:		0.356709
  validation accuracy:		90.54 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.136499
  validation loss:		0.356177
  validation accuracy:		89.89 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.128992
  validation loss:		0.372267
  validation accuracy:		89.89 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.123821
  validation loss:		0.352606
  validation accuracy:		90.00 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.127437
  validation loss:		0.370157
  validation accuracy:		89.89 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.126774
  validation loss:		0.377560
  validation accuracy:		90.00 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.125835
  validation loss:		0.362135
  validation accuracy:		90.11 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.122356
  validation loss:		0.349892
  validation accuracy:		90.43 %
Epoch 1831 of 2000 took 0.096s
  training loss:		0.127871
  validation loss:		0.350378
  validation accuracy:		90.33 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.126188
  validation loss:		0.390675
  validation accuracy:		89.35 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.126168
  validation loss:		0.352416
  validation accuracy:		90.43 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.126364
  validation loss:		0.382298
  validation accuracy:		89.78 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.129785
  validation loss:		0.357450
  validation accuracy:		90.00 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.121240
  validation loss:		0.357190
  validation accuracy:		90.22 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.121038
  validation loss:		0.367180
  validation accuracy:		90.00 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.120521
  validation loss:		0.384964
  validation accuracy:		89.89 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.123249
  validation loss:		0.377702
  validation accuracy:		90.33 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.124428
  validation loss:		0.375937
  validation accuracy:		90.00 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.130473
  validation loss:		0.384756
  validation accuracy:		89.67 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.123111
  validation loss:		0.362138
  validation accuracy:		90.43 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.122205
  validation loss:		0.356797
  validation accuracy:		90.00 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.125935
  validation loss:		0.362213
  validation accuracy:		90.00 %
Epoch 1845 of 2000 took 0.098s
  training loss:		0.118663
  validation loss:		0.395039
  validation accuracy:		90.33 %
Epoch 1846 of 2000 took 0.100s
  training loss:		0.129552
  validation loss:		0.370917
  validation accuracy:		89.78 %
Epoch 1847 of 2000 took 0.100s
  training loss:		0.122831
  validation loss:		0.353002
  validation accuracy:		90.33 %
Epoch 1848 of 2000 took 0.100s
  training loss:		0.128185
  validation loss:		0.401980
  validation accuracy:		89.78 %
Epoch 1849 of 2000 took 0.099s
  training loss:		0.129596
  validation loss:		0.368968
  validation accuracy:		90.11 %
Epoch 1850 of 2000 took 0.100s
  training loss:		0.125532
  validation loss:		0.353194
  validation accuracy:		90.54 %
Epoch 1851 of 2000 took 0.100s
  training loss:		0.120854
  validation loss:		0.370193
  validation accuracy:		89.46 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.120146
  validation loss:		0.360632
  validation accuracy:		90.22 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.123842
  validation loss:		0.363880
  validation accuracy:		90.43 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.115679
  validation loss:		0.354330
  validation accuracy:		89.89 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.121661
  validation loss:		0.372251
  validation accuracy:		89.89 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.129813
  validation loss:		0.384810
  validation accuracy:		90.33 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.118335
  validation loss:		0.390014
  validation accuracy:		89.67 %
Epoch 1858 of 2000 took 0.097s
  training loss:		0.126020
  validation loss:		0.366484
  validation accuracy:		90.00 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.119543
  validation loss:		0.389170
  validation accuracy:		90.00 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.122962
  validation loss:		0.389843
  validation accuracy:		90.33 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.122383
  validation loss:		0.379901
  validation accuracy:		90.00 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.125888
  validation loss:		0.365202
  validation accuracy:		90.54 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.120255
  validation loss:		0.386411
  validation accuracy:		90.54 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.115400
  validation loss:		0.368778
  validation accuracy:		90.00 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.118348
  validation loss:		0.369825
  validation accuracy:		89.89 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.114398
  validation loss:		0.371693
  validation accuracy:		89.57 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.123640
  validation loss:		0.352255
  validation accuracy:		90.33 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.118776
  validation loss:		0.366984
  validation accuracy:		90.11 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.119422
  validation loss:		0.355296
  validation accuracy:		90.76 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.120729
  validation loss:		0.371652
  validation accuracy:		90.11 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.119768
  validation loss:		0.373792
  validation accuracy:		90.65 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.125872
  validation loss:		0.389748
  validation accuracy:		89.02 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.121941
  validation loss:		0.404467
  validation accuracy:		89.67 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.118210
  validation loss:		0.378451
  validation accuracy:		89.67 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.120192
  validation loss:		0.377684
  validation accuracy:		90.76 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.114631
  validation loss:		0.379374
  validation accuracy:		90.22 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.121725
  validation loss:		0.396457
  validation accuracy:		90.22 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.114741
  validation loss:		0.364597
  validation accuracy:		90.43 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.113716
  validation loss:		0.371222
  validation accuracy:		89.89 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.117048
  validation loss:		0.366141
  validation accuracy:		90.33 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.115908
  validation loss:		0.364359
  validation accuracy:		90.22 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.116930
  validation loss:		0.372064
  validation accuracy:		90.54 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.115280
  validation loss:		0.359505
  validation accuracy:		90.87 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.114676
  validation loss:		0.372601
  validation accuracy:		90.00 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.123804
  validation loss:		0.377643
  validation accuracy:		90.65 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.117511
  validation loss:		0.382647
  validation accuracy:		89.57 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.111603
  validation loss:		0.410658
  validation accuracy:		89.46 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.124321
  validation loss:		0.365550
  validation accuracy:		90.33 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.115407
  validation loss:		0.380687
  validation accuracy:		89.67 %
Epoch 1890 of 2000 took 0.097s
  training loss:		0.116419
  validation loss:		0.383888
  validation accuracy:		90.33 %
Epoch 1891 of 2000 took 0.095s
  training loss:		0.118792
  validation loss:		0.367229
  validation accuracy:		90.87 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.119643
  validation loss:		0.409249
  validation accuracy:		89.24 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.118738
  validation loss:		0.395398
  validation accuracy:		89.67 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.116882
  validation loss:		0.370537
  validation accuracy:		90.54 %
Epoch 1895 of 2000 took 0.095s
  training loss:		0.114445
  validation loss:		0.389066
  validation accuracy:		90.22 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.111150
  validation loss:		0.380053
  validation accuracy:		90.11 %
Epoch 1897 of 2000 took 0.095s
  training loss:		0.111281
  validation loss:		0.424859
  validation accuracy:		89.02 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.121052
  validation loss:		0.407272
  validation accuracy:		89.89 %
Epoch 1899 of 2000 took 0.095s
  training loss:		0.116391
  validation loss:		0.371132
  validation accuracy:		89.89 %
Epoch 1900 of 2000 took 0.095s
  training loss:		0.119017
  validation loss:		0.376964
  validation accuracy:		89.67 %
Epoch 1901 of 2000 took 0.095s
  training loss:		0.120761
  validation loss:		0.382950
  validation accuracy:		89.89 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.111911
  validation loss:		0.390210
  validation accuracy:		89.89 %
Epoch 1903 of 2000 took 0.095s
  training loss:		0.117490
  validation loss:		0.376663
  validation accuracy:		89.89 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.111139
  validation loss:		0.395772
  validation accuracy:		89.78 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.106913
  validation loss:		0.397843
  validation accuracy:		90.00 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.116709
  validation loss:		0.400393
  validation accuracy:		89.78 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.114149
  validation loss:		0.382428
  validation accuracy:		90.00 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.124169
  validation loss:		0.382922
  validation accuracy:		89.89 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.115612
  validation loss:		0.393658
  validation accuracy:		90.33 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.115779
  validation loss:		0.389607
  validation accuracy:		90.22 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.112477
  validation loss:		0.399932
  validation accuracy:		89.67 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.111122
  validation loss:		0.389201
  validation accuracy:		90.00 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.111073
  validation loss:		0.424714
  validation accuracy:		89.24 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.117690
  validation loss:		0.371861
  validation accuracy:		90.22 %
Epoch 1915 of 2000 took 0.097s
  training loss:		0.111508
  validation loss:		0.389240
  validation accuracy:		90.00 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.117207
  validation loss:		0.383749
  validation accuracy:		90.00 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.114316
  validation loss:		0.416816
  validation accuracy:		90.11 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.112446
  validation loss:		0.374268
  validation accuracy:		90.22 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.114491
  validation loss:		0.380582
  validation accuracy:		90.00 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.113213
  validation loss:		0.422120
  validation accuracy:		89.67 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.110729
  validation loss:		0.375311
  validation accuracy:		90.00 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.110089
  validation loss:		0.405443
  validation accuracy:		89.35 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.114536
  validation loss:		0.380790
  validation accuracy:		90.11 %
Epoch 1924 of 2000 took 0.097s
  training loss:		0.118228
  validation loss:		0.398339
  validation accuracy:		90.00 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.114824
  validation loss:		0.377766
  validation accuracy:		90.33 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.108333
  validation loss:		0.383963
  validation accuracy:		90.11 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.105783
  validation loss:		0.397653
  validation accuracy:		90.22 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.111823
  validation loss:		0.391915
  validation accuracy:		90.11 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.106982
  validation loss:		0.387990
  validation accuracy:		90.43 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.109870
  validation loss:		0.392757
  validation accuracy:		89.78 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.111284
  validation loss:		0.394967
  validation accuracy:		90.43 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.111101
  validation loss:		0.396724
  validation accuracy:		90.43 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.109432
  validation loss:		0.386955
  validation accuracy:		90.00 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.113977
  validation loss:		0.384922
  validation accuracy:		90.54 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.110236
  validation loss:		0.388013
  validation accuracy:		90.33 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.113639
  validation loss:		0.392764
  validation accuracy:		90.22 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.101672
  validation loss:		0.396324
  validation accuracy:		90.11 %
Epoch 1938 of 2000 took 0.097s
  training loss:		0.106092
  validation loss:		0.391086
  validation accuracy:		90.00 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.110745
  validation loss:		0.396785
  validation accuracy:		90.22 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.109689
  validation loss:		0.400528
  validation accuracy:		89.57 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.111549
  validation loss:		0.411527
  validation accuracy:		89.57 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.111318
  validation loss:		0.378674
  validation accuracy:		90.33 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.105930
  validation loss:		0.395950
  validation accuracy:		90.11 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.105774
  validation loss:		0.389400
  validation accuracy:		90.22 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.105436
  validation loss:		0.397212
  validation accuracy:		90.11 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.107094
  validation loss:		0.395187
  validation accuracy:		90.11 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.107969
  validation loss:		0.393746
  validation accuracy:		89.89 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.115983
  validation loss:		0.414051
  validation accuracy:		89.46 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.102503
  validation loss:		0.404639
  validation accuracy:		90.00 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.106120
  validation loss:		0.397831
  validation accuracy:		90.11 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.108221
  validation loss:		0.392267
  validation accuracy:		90.33 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.106828
  validation loss:		0.404605
  validation accuracy:		89.78 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.099649
  validation loss:		0.395468
  validation accuracy:		90.00 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.111421
  validation loss:		0.388354
  validation accuracy:		90.11 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.103565
  validation loss:		0.402477
  validation accuracy:		90.43 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.107463
  validation loss:		0.406731
  validation accuracy:		89.67 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.107586
  validation loss:		0.404736
  validation accuracy:		90.33 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.106031
  validation loss:		0.398093
  validation accuracy:		89.89 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.104505
  validation loss:		0.487156
  validation accuracy:		87.93 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.112570
  validation loss:		0.412531
  validation accuracy:		89.78 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.109426
  validation loss:		0.395449
  validation accuracy:		89.89 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.106391
  validation loss:		0.408764
  validation accuracy:		89.89 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.107019
  validation loss:		0.410060
  validation accuracy:		89.78 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.103203
  validation loss:		0.428295
  validation accuracy:		89.89 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.103869
  validation loss:		0.414540
  validation accuracy:		89.78 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.103385
  validation loss:		0.398238
  validation accuracy:		90.22 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.101026
  validation loss:		0.399194
  validation accuracy:		90.11 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.107863
  validation loss:		0.422165
  validation accuracy:		89.89 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.105760
  validation loss:		0.418878
  validation accuracy:		89.67 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.105562
  validation loss:		0.433172
  validation accuracy:		88.80 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.103617
  validation loss:		0.430057
  validation accuracy:		89.57 %
Epoch 1972 of 2000 took 0.097s
  training loss:		0.105099
  validation loss:		0.400947
  validation accuracy:		90.33 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.099944
  validation loss:		0.451088
  validation accuracy:		89.46 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.106123
  validation loss:		0.404104
  validation accuracy:		90.00 %
Epoch 1975 of 2000 took 0.099s
  training loss:		0.108525
  validation loss:		0.401632
  validation accuracy:		90.22 %
Epoch 1976 of 2000 took 0.103s
  training loss:		0.100619
  validation loss:		0.413382
  validation accuracy:		90.11 %
Epoch 1977 of 2000 took 0.103s
  training loss:		0.104888
  validation loss:		0.404649
  validation accuracy:		89.78 %
Epoch 1978 of 2000 took 0.103s
  training loss:		0.099466
  validation loss:		0.401088
  validation accuracy:		90.22 %
Epoch 1979 of 2000 took 0.103s
  training loss:		0.102274
  validation loss:		0.394538
  validation accuracy:		90.11 %
Epoch 1980 of 2000 took 0.103s
  training loss:		0.100669
  validation loss:		0.396949
  validation accuracy:		89.89 %
Epoch 1981 of 2000 took 0.103s
  training loss:		0.104612
  validation loss:		0.423310
  validation accuracy:		89.89 %
Epoch 1982 of 2000 took 0.103s
  training loss:		0.097015
  validation loss:		0.454516
  validation accuracy:		88.48 %
Epoch 1983 of 2000 took 0.103s
  training loss:		0.100031
  validation loss:		0.438756
  validation accuracy:		89.02 %
Epoch 1984 of 2000 took 0.103s
  training loss:		0.105097
  validation loss:		0.409550
  validation accuracy:		90.11 %
Epoch 1985 of 2000 took 0.103s
  training loss:		0.104752
  validation loss:		0.396527
  validation accuracy:		90.22 %
Epoch 1986 of 2000 took 0.103s
  training loss:		0.113889
  validation loss:		0.436749
  validation accuracy:		89.24 %
Epoch 1987 of 2000 took 0.103s
  training loss:		0.100137
  validation loss:		0.410651
  validation accuracy:		90.22 %
Epoch 1988 of 2000 took 0.103s
  training loss:		0.104768
  validation loss:		0.415455
  validation accuracy:		90.11 %
Epoch 1989 of 2000 took 0.103s
  training loss:		0.095947
  validation loss:		0.413510
  validation accuracy:		90.22 %
Epoch 1990 of 2000 took 0.103s
  training loss:		0.096405
  validation loss:		0.406425
  validation accuracy:		90.22 %
Epoch 1991 of 2000 took 0.103s
  training loss:		0.099289
  validation loss:		0.422807
  validation accuracy:		89.78 %
Epoch 1992 of 2000 took 0.103s
  training loss:		0.101955
  validation loss:		0.421147
  validation accuracy:		89.57 %
Epoch 1993 of 2000 took 0.103s
  training loss:		0.099573
  validation loss:		0.409289
  validation accuracy:		90.22 %
Epoch 1994 of 2000 took 0.103s
  training loss:		0.095535
  validation loss:		0.413372
  validation accuracy:		90.00 %
Epoch 1995 of 2000 took 0.103s
  training loss:		0.102405
  validation loss:		0.411585
  validation accuracy:		90.11 %
Epoch 1996 of 2000 took 0.103s
  training loss:		0.103707
  validation loss:		0.399172
  validation accuracy:		90.22 %
Epoch 1997 of 2000 took 0.103s
  training loss:		0.098140
  validation loss:		0.425510
  validation accuracy:		89.78 %
Epoch 1998 of 2000 took 0.103s
  training loss:		0.102770
  validation loss:		0.414053
  validation accuracy:		90.00 %
Epoch 1999 of 2000 took 0.103s
  training loss:		0.097357
  validation loss:		0.398635
  validation accuracy:		90.22 %
Epoch 2000 of 2000 took 0.103s
  training loss:		0.100476
  validation loss:		0.443188
  validation accuracy:		89.24 %
Final results:
  test loss:			0.845741
  test accuracy:		82.39 %
