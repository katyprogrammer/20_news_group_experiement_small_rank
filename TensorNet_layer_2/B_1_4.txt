Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.047s
  training loss:		2.958040
  validation loss:		2.875160
  validation accuracy:		0.11 %
Epoch 2 of 2000 took 0.040s
  training loss:		2.773146
  validation loss:		2.641419
  validation accuracy:		12.83 %
Epoch 3 of 2000 took 0.039s
  training loss:		2.569205
  validation loss:		2.420642
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.039s
  training loss:		2.408444
  validation loss:		2.276957
  validation accuracy:		24.02 %
Epoch 5 of 2000 took 0.039s
  training loss:		2.328397
  validation loss:		2.247025
  validation accuracy:		14.24 %
Epoch 6 of 2000 took 0.039s
  training loss:		2.299231
  validation loss:		2.246073
  validation accuracy:		38.48 %
Epoch 7 of 2000 took 0.039s
  training loss:		2.287811
  validation loss:		2.232508
  validation accuracy:		15.00 %
Epoch 8 of 2000 took 0.039s
  training loss:		2.280214
  validation loss:		2.222855
  validation accuracy:		19.24 %
Epoch 9 of 2000 took 0.039s
  training loss:		2.277847
  validation loss:		2.223551
  validation accuracy:		31.85 %
Epoch 10 of 2000 took 0.039s
  training loss:		2.271892
  validation loss:		2.220178
  validation accuracy:		27.17 %
Epoch 11 of 2000 took 0.055s
  training loss:		2.268447
  validation loss:		2.208153
  validation accuracy:		33.80 %
Epoch 12 of 2000 took 0.053s
  training loss:		2.263011
  validation loss:		2.212650
  validation accuracy:		28.91 %
Epoch 13 of 2000 took 0.045s
  training loss:		2.258944
  validation loss:		2.208759
  validation accuracy:		27.39 %
Epoch 14 of 2000 took 0.040s
  training loss:		2.254724
  validation loss:		2.189638
  validation accuracy:		35.65 %
Epoch 15 of 2000 took 0.038s
  training loss:		2.250803
  validation loss:		2.203678
  validation accuracy:		34.13 %
Epoch 16 of 2000 took 0.037s
  training loss:		2.245438
  validation loss:		2.195416
  validation accuracy:		42.50 %
Epoch 17 of 2000 took 0.036s
  training loss:		2.240830
  validation loss:		2.185853
  validation accuracy:		48.37 %
Epoch 18 of 2000 took 0.036s
  training loss:		2.233362
  validation loss:		2.174050
  validation accuracy:		41.96 %
Epoch 19 of 2000 took 0.037s
  training loss:		2.228840
  validation loss:		2.164957
  validation accuracy:		56.09 %
Epoch 20 of 2000 took 0.036s
  training loss:		2.222168
  validation loss:		2.161593
  validation accuracy:		62.17 %
Epoch 21 of 2000 took 0.036s
  training loss:		2.215198
  validation loss:		2.156760
  validation accuracy:		68.59 %
Epoch 22 of 2000 took 0.036s
  training loss:		2.206560
  validation loss:		2.157983
  validation accuracy:		66.20 %
Epoch 23 of 2000 took 0.036s
  training loss:		2.197496
  validation loss:		2.127656
  validation accuracy:		57.07 %
Epoch 24 of 2000 took 0.037s
  training loss:		2.187159
  validation loss:		2.121786
  validation accuracy:		57.39 %
Epoch 25 of 2000 took 0.036s
  training loss:		2.177572
  validation loss:		2.125721
  validation accuracy:		61.09 %
Epoch 26 of 2000 took 0.036s
  training loss:		2.167606
  validation loss:		2.100841
  validation accuracy:		66.09 %
Epoch 27 of 2000 took 0.036s
  training loss:		2.154154
  validation loss:		2.087872
  validation accuracy:		68.04 %
Epoch 28 of 2000 took 0.036s
  training loss:		2.140978
  validation loss:		2.074465
  validation accuracy:		63.59 %
Epoch 29 of 2000 took 0.036s
  training loss:		2.124908
  validation loss:		2.053231
  validation accuracy:		76.09 %
Epoch 30 of 2000 took 0.037s
  training loss:		2.103485
  validation loss:		2.027819
  validation accuracy:		65.22 %
Epoch 31 of 2000 took 0.038s
  training loss:		2.085100
  validation loss:		2.011808
  validation accuracy:		75.98 %
Epoch 32 of 2000 took 0.039s
  training loss:		2.061633
  validation loss:		1.979317
  validation accuracy:		74.02 %
Epoch 33 of 2000 took 0.040s
  training loss:		2.035270
  validation loss:		1.947853
  validation accuracy:		74.02 %
Epoch 34 of 2000 took 0.038s
  training loss:		2.004954
  validation loss:		1.917181
  validation accuracy:		82.61 %
Epoch 35 of 2000 took 0.039s
  training loss:		1.969435
  validation loss:		1.874794
  validation accuracy:		80.22 %
Epoch 36 of 2000 took 0.040s
  training loss:		1.930046
  validation loss:		1.832716
  validation accuracy:		78.04 %
Epoch 37 of 2000 took 0.038s
  training loss:		1.885281
  validation loss:		1.770932
  validation accuracy:		83.15 %
Epoch 38 of 2000 took 0.038s
  training loss:		1.830275
  validation loss:		1.721042
  validation accuracy:		86.41 %
Epoch 39 of 2000 took 0.038s
  training loss:		1.772554
  validation loss:		1.656433
  validation accuracy:		84.13 %
Epoch 40 of 2000 took 0.038s
  training loss:		1.713333
  validation loss:		1.593035
  validation accuracy:		84.78 %
Epoch 41 of 2000 took 0.038s
  training loss:		1.651216
  validation loss:		1.525017
  validation accuracy:		85.76 %
Epoch 42 of 2000 took 0.038s
  training loss:		1.586167
  validation loss:		1.458803
  validation accuracy:		84.35 %
Epoch 43 of 2000 took 0.038s
  training loss:		1.524318
  validation loss:		1.392941
  validation accuracy:		85.76 %
Epoch 44 of 2000 took 0.038s
  training loss:		1.456711
  validation loss:		1.322515
  validation accuracy:		87.07 %
Epoch 45 of 2000 took 0.038s
  training loss:		1.394443
  validation loss:		1.267339
  validation accuracy:		85.43 %
Epoch 46 of 2000 took 0.038s
  training loss:		1.334502
  validation loss:		1.205040
  validation accuracy:		85.54 %
Epoch 47 of 2000 took 0.038s
  training loss:		1.278985
  validation loss:		1.151780
  validation accuracy:		84.57 %
Epoch 48 of 2000 took 0.038s
  training loss:		1.225776
  validation loss:		1.100720
  validation accuracy:		82.17 %
Epoch 49 of 2000 took 0.039s
  training loss:		1.174666
  validation loss:		1.047230
  validation accuracy:		85.65 %
Epoch 50 of 2000 took 0.038s
  training loss:		1.123219
  validation loss:		0.996859
  validation accuracy:		85.76 %
Epoch 51 of 2000 took 0.038s
  training loss:		1.076548
  validation loss:		0.953690
  validation accuracy:		84.24 %
Epoch 52 of 2000 took 0.038s
  training loss:		1.037433
  validation loss:		0.919043
  validation accuracy:		85.00 %
Epoch 53 of 2000 took 0.038s
  training loss:		0.990664
  validation loss:		0.883365
  validation accuracy:		84.89 %
Epoch 54 of 2000 took 0.038s
  training loss:		0.961996
  validation loss:		0.843250
  validation accuracy:		86.52 %
Epoch 55 of 2000 took 0.038s
  training loss:		0.928634
  validation loss:		0.827246
  validation accuracy:		83.80 %
Epoch 56 of 2000 took 0.038s
  training loss:		0.896822
  validation loss:		0.789856
  validation accuracy:		85.87 %
Epoch 57 of 2000 took 0.038s
  training loss:		0.868420
  validation loss:		0.764979
  validation accuracy:		85.76 %
Epoch 58 of 2000 took 0.038s
  training loss:		0.836810
  validation loss:		0.739623
  validation accuracy:		85.11 %
Epoch 59 of 2000 took 0.038s
  training loss:		0.812048
  validation loss:		0.718126
  validation accuracy:		85.43 %
Epoch 60 of 2000 took 0.038s
  training loss:		0.785583
  validation loss:		0.696779
  validation accuracy:		86.52 %
Epoch 61 of 2000 took 0.038s
  training loss:		0.765128
  validation loss:		0.686804
  validation accuracy:		85.11 %
Epoch 62 of 2000 took 0.038s
  training loss:		0.742338
  validation loss:		0.648052
  validation accuracy:		86.63 %
Epoch 63 of 2000 took 0.038s
  training loss:		0.727735
  validation loss:		0.646989
  validation accuracy:		85.65 %
Epoch 64 of 2000 took 0.038s
  training loss:		0.707245
  validation loss:		0.628487
  validation accuracy:		85.98 %
Epoch 65 of 2000 took 0.038s
  training loss:		0.688099
  validation loss:		0.600389
  validation accuracy:		86.96 %
Epoch 66 of 2000 took 0.038s
  training loss:		0.669014
  validation loss:		0.609243
  validation accuracy:		85.22 %
Epoch 67 of 2000 took 0.038s
  training loss:		0.653661
  validation loss:		0.585761
  validation accuracy:		85.98 %
Epoch 68 of 2000 took 0.038s
  training loss:		0.634858
  validation loss:		0.572959
  validation accuracy:		86.74 %
Epoch 69 of 2000 took 0.038s
  training loss:		0.619619
  validation loss:		0.568233
  validation accuracy:		86.09 %
Epoch 70 of 2000 took 0.038s
  training loss:		0.609325
  validation loss:		0.543287
  validation accuracy:		87.39 %
Epoch 71 of 2000 took 0.038s
  training loss:		0.593637
  validation loss:		0.539356
  validation accuracy:		86.85 %
Epoch 72 of 2000 took 0.038s
  training loss:		0.581407
  validation loss:		0.534854
  validation accuracy:		86.52 %
Epoch 73 of 2000 took 0.038s
  training loss:		0.565051
  validation loss:		0.522839
  validation accuracy:		86.74 %
Epoch 74 of 2000 took 0.038s
  training loss:		0.559505
  validation loss:		0.500051
  validation accuracy:		88.04 %
Epoch 75 of 2000 took 0.038s
  training loss:		0.542095
  validation loss:		0.488276
  validation accuracy:		88.15 %
Epoch 76 of 2000 took 0.038s
  training loss:		0.532304
  validation loss:		0.512006
  validation accuracy:		85.76 %
Epoch 77 of 2000 took 0.038s
  training loss:		0.516721
  validation loss:		0.481757
  validation accuracy:		87.72 %
Epoch 78 of 2000 took 0.038s
  training loss:		0.510362
  validation loss:		0.466311
  validation accuracy:		88.59 %
Epoch 79 of 2000 took 0.041s
  training loss:		0.502453
  validation loss:		0.472478
  validation accuracy:		87.61 %
Epoch 80 of 2000 took 0.038s
  training loss:		0.493309
  validation loss:		0.458198
  validation accuracy:		88.15 %
Epoch 81 of 2000 took 0.038s
  training loss:		0.485580
  validation loss:		0.454728
  validation accuracy:		88.15 %
Epoch 82 of 2000 took 0.038s
  training loss:		0.468930
  validation loss:		0.445370
  validation accuracy:		88.70 %
Epoch 83 of 2000 took 0.038s
  training loss:		0.465760
  validation loss:		0.439052
  validation accuracy:		88.48 %
Epoch 84 of 2000 took 0.038s
  training loss:		0.461265
  validation loss:		0.430339
  validation accuracy:		88.37 %
Epoch 85 of 2000 took 0.038s
  training loss:		0.455075
  validation loss:		0.424655
  validation accuracy:		88.59 %
Epoch 86 of 2000 took 0.038s
  training loss:		0.443050
  validation loss:		0.407657
  validation accuracy:		89.78 %
Epoch 87 of 2000 took 0.038s
  training loss:		0.436674
  validation loss:		0.399458
  validation accuracy:		89.46 %
Epoch 88 of 2000 took 0.038s
  training loss:		0.435304
  validation loss:		0.402488
  validation accuracy:		89.57 %
Epoch 89 of 2000 took 0.038s
  training loss:		0.421986
  validation loss:		0.400501
  validation accuracy:		89.13 %
Epoch 90 of 2000 took 0.038s
  training loss:		0.414760
  validation loss:		0.401860
  validation accuracy:		88.70 %
Epoch 91 of 2000 took 0.038s
  training loss:		0.412901
  validation loss:		0.386269
  validation accuracy:		89.46 %
Epoch 92 of 2000 took 0.038s
  training loss:		0.400112
  validation loss:		0.373863
  validation accuracy:		89.78 %
Epoch 93 of 2000 took 0.038s
  training loss:		0.394775
  validation loss:		0.379318
  validation accuracy:		89.35 %
Epoch 94 of 2000 took 0.038s
  training loss:		0.390252
  validation loss:		0.370465
  validation accuracy:		90.43 %
Epoch 95 of 2000 took 0.038s
  training loss:		0.388078
  validation loss:		0.374364
  validation accuracy:		89.67 %
Epoch 96 of 2000 took 0.038s
  training loss:		0.375058
  validation loss:		0.395476
  validation accuracy:		88.48 %
Epoch 97 of 2000 took 0.038s
  training loss:		0.376141
  validation loss:		0.372349
  validation accuracy:		89.89 %
Epoch 98 of 2000 took 0.038s
  training loss:		0.369366
  validation loss:		0.347648
  validation accuracy:		90.87 %
Epoch 99 of 2000 took 0.038s
  training loss:		0.364977
  validation loss:		0.355122
  validation accuracy:		90.11 %
Epoch 100 of 2000 took 0.038s
  training loss:		0.354986
  validation loss:		0.344843
  validation accuracy:		90.76 %
Epoch 101 of 2000 took 0.038s
  training loss:		0.357268
  validation loss:		0.354082
  validation accuracy:		90.00 %
Epoch 102 of 2000 took 0.038s
  training loss:		0.346352
  validation loss:		0.347803
  validation accuracy:		90.22 %
Epoch 103 of 2000 took 0.038s
  training loss:		0.345234
  validation loss:		0.340849
  validation accuracy:		90.33 %
Epoch 104 of 2000 took 0.038s
  training loss:		0.334973
  validation loss:		0.333779
  validation accuracy:		90.43 %
Epoch 105 of 2000 took 0.039s
  training loss:		0.334186
  validation loss:		0.328076
  validation accuracy:		90.98 %
Epoch 106 of 2000 took 0.039s
  training loss:		0.326149
  validation loss:		0.327909
  validation accuracy:		90.98 %
Epoch 107 of 2000 took 0.038s
  training loss:		0.329546
  validation loss:		0.330897
  validation accuracy:		91.20 %
Epoch 108 of 2000 took 0.038s
  training loss:		0.320739
  validation loss:		0.329815
  validation accuracy:		90.98 %
Epoch 109 of 2000 took 0.038s
  training loss:		0.317140
  validation loss:		0.327840
  validation accuracy:		91.63 %
Epoch 110 of 2000 took 0.038s
  training loss:		0.319077
  validation loss:		0.313994
  validation accuracy:		91.09 %
Epoch 111 of 2000 took 0.038s
  training loss:		0.306918
  validation loss:		0.307245
  validation accuracy:		92.07 %
Epoch 112 of 2000 took 0.038s
  training loss:		0.311306
  validation loss:		0.311635
  validation accuracy:		91.09 %
Epoch 113 of 2000 took 0.038s
  training loss:		0.311813
  validation loss:		0.304440
  validation accuracy:		91.41 %
Epoch 114 of 2000 took 0.038s
  training loss:		0.298352
  validation loss:		0.305440
  validation accuracy:		91.63 %
Epoch 115 of 2000 took 0.038s
  training loss:		0.297737
  validation loss:		0.312246
  validation accuracy:		91.30 %
Epoch 116 of 2000 took 0.038s
  training loss:		0.298140
  validation loss:		0.295712
  validation accuracy:		91.74 %
Epoch 117 of 2000 took 0.038s
  training loss:		0.294191
  validation loss:		0.294863
  validation accuracy:		91.74 %
Epoch 118 of 2000 took 0.038s
  training loss:		0.291449
  validation loss:		0.289145
  validation accuracy:		91.96 %
Epoch 119 of 2000 took 0.039s
  training loss:		0.287647
  validation loss:		0.298664
  validation accuracy:		91.41 %
Epoch 120 of 2000 took 0.038s
  training loss:		0.286876
  validation loss:		0.305281
  validation accuracy:		91.85 %
Epoch 121 of 2000 took 0.048s
  training loss:		0.286026
  validation loss:		0.295959
  validation accuracy:		91.74 %
Epoch 122 of 2000 took 0.048s
  training loss:		0.282180
  validation loss:		0.288452
  validation accuracy:		91.96 %
Epoch 123 of 2000 took 0.048s
  training loss:		0.273024
  validation loss:		0.281846
  validation accuracy:		91.63 %
Epoch 124 of 2000 took 0.040s
  training loss:		0.274287
  validation loss:		0.273889
  validation accuracy:		92.07 %
Epoch 125 of 2000 took 0.038s
  training loss:		0.269133
  validation loss:		0.271986
  validation accuracy:		91.96 %
Epoch 126 of 2000 took 0.038s
  training loss:		0.270461
  validation loss:		0.286553
  validation accuracy:		92.28 %
Epoch 127 of 2000 took 0.038s
  training loss:		0.262343
  validation loss:		0.267832
  validation accuracy:		92.07 %
Epoch 128 of 2000 took 0.037s
  training loss:		0.260231
  validation loss:		0.274701
  validation accuracy:		91.96 %
Epoch 129 of 2000 took 0.037s
  training loss:		0.264157
  validation loss:		0.258769
  validation accuracy:		92.50 %
Epoch 130 of 2000 took 0.037s
  training loss:		0.262001
  validation loss:		0.264360
  validation accuracy:		92.17 %
Epoch 131 of 2000 took 0.044s
  training loss:		0.255733
  validation loss:		0.263012
  validation accuracy:		92.07 %
Epoch 132 of 2000 took 0.044s
  training loss:		0.255359
  validation loss:		0.267084
  validation accuracy:		92.07 %
Epoch 133 of 2000 took 0.045s
  training loss:		0.251437
  validation loss:		0.259129
  validation accuracy:		92.17 %
Epoch 134 of 2000 took 0.043s
  training loss:		0.250886
  validation loss:		0.274822
  validation accuracy:		92.28 %
Epoch 135 of 2000 took 0.043s
  training loss:		0.249009
  validation loss:		0.264377
  validation accuracy:		92.50 %
Epoch 136 of 2000 took 0.043s
  training loss:		0.244287
  validation loss:		0.266295
  validation accuracy:		92.50 %
Epoch 137 of 2000 took 0.043s
  training loss:		0.247137
  validation loss:		0.270843
  validation accuracy:		92.39 %
Epoch 138 of 2000 took 0.043s
  training loss:		0.245860
  validation loss:		0.264826
  validation accuracy:		92.28 %
Epoch 139 of 2000 took 0.043s
  training loss:		0.243715
  validation loss:		0.254737
  validation accuracy:		92.50 %
Epoch 140 of 2000 took 0.044s
  training loss:		0.236960
  validation loss:		0.255302
  validation accuracy:		92.72 %
Epoch 141 of 2000 took 0.047s
  training loss:		0.244229
  validation loss:		0.256788
  validation accuracy:		92.83 %
Epoch 142 of 2000 took 0.046s
  training loss:		0.238963
  validation loss:		0.245501
  validation accuracy:		92.39 %
Epoch 143 of 2000 took 0.043s
  training loss:		0.234830
  validation loss:		0.263268
  validation accuracy:		92.50 %
Epoch 144 of 2000 took 0.043s
  training loss:		0.240088
  validation loss:		0.242851
  validation accuracy:		92.83 %
Epoch 145 of 2000 took 0.053s
  training loss:		0.229884
  validation loss:		0.250805
  validation accuracy:		92.72 %
Epoch 146 of 2000 took 0.063s
  training loss:		0.232289
  validation loss:		0.248718
  validation accuracy:		92.83 %
Epoch 147 of 2000 took 0.063s
  training loss:		0.230620
  validation loss:		0.247518
  validation accuracy:		92.72 %
Epoch 148 of 2000 took 0.064s
  training loss:		0.231567
  validation loss:		0.270597
  validation accuracy:		92.39 %
Epoch 149 of 2000 took 0.064s
  training loss:		0.222192
  validation loss:		0.245738
  validation accuracy:		92.72 %
Epoch 150 of 2000 took 0.063s
  training loss:		0.226278
  validation loss:		0.252596
  validation accuracy:		93.15 %
Epoch 151 of 2000 took 0.061s
  training loss:		0.218577
  validation loss:		0.251002
  validation accuracy:		92.72 %
Epoch 152 of 2000 took 0.063s
  training loss:		0.222761
  validation loss:		0.234643
  validation accuracy:		93.04 %
Epoch 153 of 2000 took 0.062s
  training loss:		0.224868
  validation loss:		0.238328
  validation accuracy:		92.83 %
Epoch 154 of 2000 took 0.063s
  training loss:		0.218072
  validation loss:		0.247774
  validation accuracy:		93.15 %
Epoch 155 of 2000 took 0.063s
  training loss:		0.218581
  validation loss:		0.228304
  validation accuracy:		93.04 %
Epoch 156 of 2000 took 0.063s
  training loss:		0.212524
  validation loss:		0.237710
  validation accuracy:		92.83 %
Epoch 157 of 2000 took 0.061s
  training loss:		0.210063
  validation loss:		0.244344
  validation accuracy:		92.61 %
Epoch 158 of 2000 took 0.058s
  training loss:		0.215132
  validation loss:		0.237348
  validation accuracy:		93.04 %
Epoch 159 of 2000 took 0.057s
  training loss:		0.212004
  validation loss:		0.255404
  validation accuracy:		92.72 %
Epoch 160 of 2000 took 0.058s
  training loss:		0.209924
  validation loss:		0.235876
  validation accuracy:		92.93 %
Epoch 161 of 2000 took 0.059s
  training loss:		0.206569
  validation loss:		0.232232
  validation accuracy:		93.26 %
Epoch 162 of 2000 took 0.059s
  training loss:		0.213806
  validation loss:		0.233507
  validation accuracy:		92.72 %
Epoch 163 of 2000 took 0.059s
  training loss:		0.209282
  validation loss:		0.242747
  validation accuracy:		93.26 %
Epoch 164 of 2000 took 0.059s
  training loss:		0.204958
  validation loss:		0.233786
  validation accuracy:		93.48 %
Epoch 165 of 2000 took 0.058s
  training loss:		0.210736
  validation loss:		0.227389
  validation accuracy:		93.37 %
Epoch 166 of 2000 took 0.059s
  training loss:		0.205473
  validation loss:		0.232745
  validation accuracy:		93.04 %
Epoch 167 of 2000 took 0.058s
  training loss:		0.202993
  validation loss:		0.237518
  validation accuracy:		93.37 %
Epoch 168 of 2000 took 0.058s
  training loss:		0.203873
  validation loss:		0.230440
  validation accuracy:		93.48 %
Epoch 169 of 2000 took 0.058s
  training loss:		0.202018
  validation loss:		0.238332
  validation accuracy:		93.15 %
Epoch 170 of 2000 took 0.058s
  training loss:		0.202774
  validation loss:		0.238851
  validation accuracy:		93.26 %
Epoch 171 of 2000 took 0.059s
  training loss:		0.203863
  validation loss:		0.223010
  validation accuracy:		93.59 %
Epoch 172 of 2000 took 0.056s
  training loss:		0.193501
  validation loss:		0.222788
  validation accuracy:		93.59 %
Epoch 173 of 2000 took 0.058s
  training loss:		0.196848
  validation loss:		0.249617
  validation accuracy:		92.83 %
Epoch 174 of 2000 took 0.059s
  training loss:		0.197318
  validation loss:		0.222095
  validation accuracy:		93.15 %
Epoch 175 of 2000 took 0.059s
  training loss:		0.193352
  validation loss:		0.240312
  validation accuracy:		93.37 %
Epoch 176 of 2000 took 0.060s
  training loss:		0.196453
  validation loss:		0.224232
  validation accuracy:		93.70 %
Epoch 177 of 2000 took 0.059s
  training loss:		0.194511
  validation loss:		0.220660
  validation accuracy:		93.70 %
Epoch 178 of 2000 took 0.059s
  training loss:		0.192272
  validation loss:		0.235219
  validation accuracy:		93.37 %
Epoch 179 of 2000 took 0.059s
  training loss:		0.194312
  validation loss:		0.237827
  validation accuracy:		93.37 %
Epoch 180 of 2000 took 0.059s
  training loss:		0.190228
  validation loss:		0.222274
  validation accuracy:		93.80 %
Epoch 181 of 2000 took 0.059s
  training loss:		0.191704
  validation loss:		0.226543
  validation accuracy:		93.37 %
Epoch 182 of 2000 took 0.059s
  training loss:		0.189953
  validation loss:		0.227255
  validation accuracy:		93.26 %
Epoch 183 of 2000 took 0.059s
  training loss:		0.185960
  validation loss:		0.220967
  validation accuracy:		93.37 %
Epoch 184 of 2000 took 0.059s
  training loss:		0.188518
  validation loss:		0.214069
  validation accuracy:		94.02 %
Epoch 185 of 2000 took 0.059s
  training loss:		0.188200
  validation loss:		0.223981
  validation accuracy:		93.15 %
Epoch 186 of 2000 took 0.059s
  training loss:		0.185924
  validation loss:		0.215758
  validation accuracy:		93.80 %
Epoch 187 of 2000 took 0.058s
  training loss:		0.186534
  validation loss:		0.214846
  validation accuracy:		93.59 %
Epoch 188 of 2000 took 0.056s
  training loss:		0.184379
  validation loss:		0.219298
  validation accuracy:		93.70 %
Epoch 189 of 2000 took 0.059s
  training loss:		0.186817
  validation loss:		0.225417
  validation accuracy:		93.70 %
Epoch 190 of 2000 took 0.059s
  training loss:		0.180026
  validation loss:		0.212684
  validation accuracy:		93.80 %
Epoch 191 of 2000 took 0.059s
  training loss:		0.181720
  validation loss:		0.217439
  validation accuracy:		93.80 %
Epoch 192 of 2000 took 0.058s
  training loss:		0.178927
  validation loss:		0.240475
  validation accuracy:		93.15 %
Epoch 193 of 2000 took 0.055s
  training loss:		0.182639
  validation loss:		0.222073
  validation accuracy:		93.80 %
Epoch 194 of 2000 took 0.058s
  training loss:		0.177682
  validation loss:		0.216145
  validation accuracy:		93.80 %
Epoch 195 of 2000 took 0.059s
  training loss:		0.178401
  validation loss:		0.226775
  validation accuracy:		93.91 %
Epoch 196 of 2000 took 0.059s
  training loss:		0.177106
  validation loss:		0.203849
  validation accuracy:		94.35 %
Epoch 197 of 2000 took 0.059s
  training loss:		0.180212
  validation loss:		0.227350
  validation accuracy:		93.59 %
Epoch 198 of 2000 took 0.059s
  training loss:		0.173314
  validation loss:		0.218475
  validation accuracy:		93.59 %
Epoch 199 of 2000 took 0.059s
  training loss:		0.176959
  validation loss:		0.210314
  validation accuracy:		93.91 %
Epoch 200 of 2000 took 0.059s
  training loss:		0.170084
  validation loss:		0.206733
  validation accuracy:		93.91 %
Epoch 201 of 2000 took 0.059s
  training loss:		0.173352
  validation loss:		0.210462
  validation accuracy:		94.13 %
Epoch 202 of 2000 took 0.059s
  training loss:		0.172554
  validation loss:		0.216361
  validation accuracy:		93.91 %
Epoch 203 of 2000 took 0.060s
  training loss:		0.173237
  validation loss:		0.216229
  validation accuracy:		94.13 %
Epoch 204 of 2000 took 0.059s
  training loss:		0.171241
  validation loss:		0.212882
  validation accuracy:		94.35 %
Epoch 205 of 2000 took 0.059s
  training loss:		0.172756
  validation loss:		0.216472
  validation accuracy:		94.13 %
Epoch 206 of 2000 took 0.059s
  training loss:		0.169869
  validation loss:		0.209072
  validation accuracy:		93.91 %
Epoch 207 of 2000 took 0.059s
  training loss:		0.167980
  validation loss:		0.216760
  validation accuracy:		94.35 %
Epoch 208 of 2000 took 0.059s
  training loss:		0.170339
  validation loss:		0.215942
  validation accuracy:		94.02 %
Epoch 209 of 2000 took 0.059s
  training loss:		0.166781
  validation loss:		0.221213
  validation accuracy:		93.80 %
Epoch 210 of 2000 took 0.059s
  training loss:		0.162905
  validation loss:		0.205529
  validation accuracy:		94.13 %
Epoch 211 of 2000 took 0.058s
  training loss:		0.166200
  validation loss:		0.205628
  validation accuracy:		94.13 %
Epoch 212 of 2000 took 0.059s
  training loss:		0.165585
  validation loss:		0.208574
  validation accuracy:		94.13 %
Epoch 213 of 2000 took 0.059s
  training loss:		0.165057
  validation loss:		0.207711
  validation accuracy:		93.91 %
Epoch 214 of 2000 took 0.059s
  training loss:		0.162722
  validation loss:		0.210412
  validation accuracy:		94.13 %
Epoch 215 of 2000 took 0.059s
  training loss:		0.163909
  validation loss:		0.202991
  validation accuracy:		94.35 %
Epoch 216 of 2000 took 0.059s
  training loss:		0.162911
  validation loss:		0.203108
  validation accuracy:		94.24 %
Epoch 217 of 2000 took 0.059s
  training loss:		0.161893
  validation loss:		0.201212
  validation accuracy:		94.24 %
Epoch 218 of 2000 took 0.059s
  training loss:		0.160391
  validation loss:		0.208305
  validation accuracy:		93.91 %
Epoch 219 of 2000 took 0.059s
  training loss:		0.159928
  validation loss:		0.208026
  validation accuracy:		94.35 %
Epoch 220 of 2000 took 0.059s
  training loss:		0.159979
  validation loss:		0.201304
  validation accuracy:		94.02 %
Epoch 221 of 2000 took 0.059s
  training loss:		0.158768
  validation loss:		0.215352
  validation accuracy:		93.70 %
Epoch 222 of 2000 took 0.059s
  training loss:		0.161730
  validation loss:		0.203076
  validation accuracy:		94.35 %
Epoch 223 of 2000 took 0.059s
  training loss:		0.158097
  validation loss:		0.203804
  validation accuracy:		94.13 %
Epoch 224 of 2000 took 0.059s
  training loss:		0.158707
  validation loss:		0.207375
  validation accuracy:		94.35 %
Epoch 225 of 2000 took 0.057s
  training loss:		0.157809
  validation loss:		0.201794
  validation accuracy:		94.35 %
Epoch 226 of 2000 took 0.057s
  training loss:		0.158232
  validation loss:		0.219228
  validation accuracy:		93.70 %
Epoch 227 of 2000 took 0.059s
  training loss:		0.155903
  validation loss:		0.205217
  validation accuracy:		94.13 %
Epoch 228 of 2000 took 0.059s
  training loss:		0.153413
  validation loss:		0.198206
  validation accuracy:		94.35 %
Epoch 229 of 2000 took 0.058s
  training loss:		0.156736
  validation loss:		0.212312
  validation accuracy:		93.70 %
Epoch 230 of 2000 took 0.059s
  training loss:		0.156645
  validation loss:		0.203225
  validation accuracy:		94.13 %
Epoch 231 of 2000 took 0.059s
  training loss:		0.155682
  validation loss:		0.213197
  validation accuracy:		94.02 %
Epoch 232 of 2000 took 0.059s
  training loss:		0.151593
  validation loss:		0.214508
  validation accuracy:		94.57 %
Epoch 233 of 2000 took 0.059s
  training loss:		0.152436
  validation loss:		0.217085
  validation accuracy:		94.46 %
Epoch 234 of 2000 took 0.059s
  training loss:		0.153940
  validation loss:		0.205112
  validation accuracy:		94.24 %
Epoch 235 of 2000 took 0.058s
  training loss:		0.151175
  validation loss:		0.201568
  validation accuracy:		94.46 %
Epoch 236 of 2000 took 0.059s
  training loss:		0.151047
  validation loss:		0.207125
  validation accuracy:		94.13 %
Epoch 237 of 2000 took 0.059s
  training loss:		0.151245
  validation loss:		0.206582
  validation accuracy:		94.46 %
Epoch 238 of 2000 took 0.059s
  training loss:		0.152632
  validation loss:		0.207159
  validation accuracy:		93.80 %
Epoch 239 of 2000 took 0.059s
  training loss:		0.149822
  validation loss:		0.211020
  validation accuracy:		94.24 %
Epoch 240 of 2000 took 0.059s
  training loss:		0.148940
  validation loss:		0.197867
  validation accuracy:		94.35 %
Epoch 241 of 2000 took 0.059s
  training loss:		0.147432
  validation loss:		0.217033
  validation accuracy:		94.13 %
Epoch 242 of 2000 took 0.058s
  training loss:		0.148058
  validation loss:		0.206274
  validation accuracy:		94.02 %
Epoch 243 of 2000 took 0.059s
  training loss:		0.150668
  validation loss:		0.213176
  validation accuracy:		94.13 %
Epoch 244 of 2000 took 0.059s
  training loss:		0.146698
  validation loss:		0.199644
  validation accuracy:		94.46 %
Epoch 245 of 2000 took 0.059s
  training loss:		0.146832
  validation loss:		0.211603
  validation accuracy:		94.13 %
Epoch 246 of 2000 took 0.059s
  training loss:		0.148611
  validation loss:		0.208850
  validation accuracy:		94.24 %
Epoch 247 of 2000 took 0.060s
  training loss:		0.141727
  validation loss:		0.199962
  validation accuracy:		94.46 %
Epoch 248 of 2000 took 0.059s
  training loss:		0.145357
  validation loss:		0.213420
  validation accuracy:		94.02 %
Epoch 249 of 2000 took 0.059s
  training loss:		0.148348
  validation loss:		0.200591
  validation accuracy:		94.24 %
Epoch 250 of 2000 took 0.060s
  training loss:		0.145208
  validation loss:		0.224119
  validation accuracy:		93.80 %
Epoch 251 of 2000 took 0.059s
  training loss:		0.146408
  validation loss:		0.210598
  validation accuracy:		94.67 %
Epoch 252 of 2000 took 0.059s
  training loss:		0.146755
  validation loss:		0.196384
  validation accuracy:		94.57 %
Epoch 253 of 2000 took 0.059s
  training loss:		0.142041
  validation loss:		0.211688
  validation accuracy:		94.24 %
Epoch 254 of 2000 took 0.059s
  training loss:		0.141823
  validation loss:		0.199287
  validation accuracy:		94.57 %
Epoch 255 of 2000 took 0.059s
  training loss:		0.144622
  validation loss:		0.206424
  validation accuracy:		94.13 %
Epoch 256 of 2000 took 0.059s
  training loss:		0.141391
  validation loss:		0.210003
  validation accuracy:		93.91 %
Epoch 257 of 2000 took 0.059s
  training loss:		0.142159
  validation loss:		0.206423
  validation accuracy:		94.35 %
Epoch 258 of 2000 took 0.059s
  training loss:		0.144701
  validation loss:		0.208784
  validation accuracy:		94.46 %
Epoch 259 of 2000 took 0.059s
  training loss:		0.140299
  validation loss:		0.207507
  validation accuracy:		94.67 %
Epoch 260 of 2000 took 0.059s
  training loss:		0.139562
  validation loss:		0.202096
  validation accuracy:		94.46 %
Epoch 261 of 2000 took 0.059s
  training loss:		0.140054
  validation loss:		0.214701
  validation accuracy:		93.91 %
Epoch 262 of 2000 took 0.059s
  training loss:		0.137105
  validation loss:		0.213372
  validation accuracy:		94.13 %
Epoch 263 of 2000 took 0.059s
  training loss:		0.136993
  validation loss:		0.209039
  validation accuracy:		94.13 %
Epoch 264 of 2000 took 0.059s
  training loss:		0.138816
  validation loss:		0.206878
  validation accuracy:		94.35 %
Epoch 265 of 2000 took 0.059s
  training loss:		0.138263
  validation loss:		0.204971
  validation accuracy:		94.24 %
Epoch 266 of 2000 took 0.058s
  training loss:		0.138095
  validation loss:		0.189905
  validation accuracy:		94.78 %
Epoch 267 of 2000 took 0.059s
  training loss:		0.136749
  validation loss:		0.203636
  validation accuracy:		94.35 %
Epoch 268 of 2000 took 0.059s
  training loss:		0.134999
  validation loss:		0.198867
  validation accuracy:		94.57 %
Epoch 269 of 2000 took 0.059s
  training loss:		0.137059
  validation loss:		0.206952
  validation accuracy:		94.13 %
Epoch 270 of 2000 took 0.059s
  training loss:		0.131642
  validation loss:		0.209744
  validation accuracy:		94.24 %
Epoch 271 of 2000 took 0.059s
  training loss:		0.137030
  validation loss:		0.206636
  validation accuracy:		93.91 %
Epoch 272 of 2000 took 0.059s
  training loss:		0.132215
  validation loss:		0.209455
  validation accuracy:		94.35 %
Epoch 273 of 2000 took 0.058s
  training loss:		0.132216
  validation loss:		0.196278
  validation accuracy:		94.57 %
Epoch 274 of 2000 took 0.059s
  training loss:		0.133052
  validation loss:		0.211142
  validation accuracy:		94.35 %
Epoch 275 of 2000 took 0.059s
  training loss:		0.135228
  validation loss:		0.227380
  validation accuracy:		93.70 %
Epoch 276 of 2000 took 0.059s
  training loss:		0.136743
  validation loss:		0.197579
  validation accuracy:		94.67 %
Epoch 277 of 2000 took 0.058s
  training loss:		0.135079
  validation loss:		0.194365
  validation accuracy:		94.78 %
Epoch 278 of 2000 took 0.058s
  training loss:		0.130551
  validation loss:		0.212682
  validation accuracy:		94.13 %
Epoch 279 of 2000 took 0.060s
  training loss:		0.129011
  validation loss:		0.196588
  validation accuracy:		94.57 %
Epoch 280 of 2000 took 0.059s
  training loss:		0.125112
  validation loss:		0.196789
  validation accuracy:		94.57 %
Epoch 281 of 2000 took 0.060s
  training loss:		0.128168
  validation loss:		0.220929
  validation accuracy:		93.70 %
Epoch 282 of 2000 took 0.059s
  training loss:		0.130991
  validation loss:		0.199786
  validation accuracy:		94.57 %
Epoch 283 of 2000 took 0.059s
  training loss:		0.130937
  validation loss:		0.198490
  validation accuracy:		94.35 %
Epoch 284 of 2000 took 0.058s
  training loss:		0.127079
  validation loss:		0.206822
  validation accuracy:		94.78 %
Epoch 285 of 2000 took 0.059s
  training loss:		0.131191
  validation loss:		0.198681
  validation accuracy:		94.67 %
Epoch 286 of 2000 took 0.058s
  training loss:		0.128923
  validation loss:		0.206554
  validation accuracy:		94.46 %
Epoch 287 of 2000 took 0.059s
  training loss:		0.130246
  validation loss:		0.200264
  validation accuracy:		94.13 %
Epoch 288 of 2000 took 0.059s
  training loss:		0.129107
  validation loss:		0.210881
  validation accuracy:		94.57 %
Epoch 289 of 2000 took 0.059s
  training loss:		0.128249
  validation loss:		0.217880
  validation accuracy:		94.35 %
Epoch 290 of 2000 took 0.059s
  training loss:		0.126673
  validation loss:		0.209598
  validation accuracy:		93.80 %
Epoch 291 of 2000 took 0.059s
  training loss:		0.126393
  validation loss:		0.204136
  validation accuracy:		94.57 %
Epoch 292 of 2000 took 0.059s
  training loss:		0.127935
  validation loss:		0.205646
  validation accuracy:		94.46 %
Epoch 293 of 2000 took 0.059s
  training loss:		0.125881
  validation loss:		0.210176
  validation accuracy:		94.02 %
Epoch 294 of 2000 took 0.059s
  training loss:		0.126434
  validation loss:		0.202413
  validation accuracy:		94.46 %
Epoch 295 of 2000 took 0.059s
  training loss:		0.124051
  validation loss:		0.198512
  validation accuracy:		94.67 %
Epoch 296 of 2000 took 0.059s
  training loss:		0.127695
  validation loss:		0.203568
  validation accuracy:		94.67 %
Epoch 297 of 2000 took 0.059s
  training loss:		0.126962
  validation loss:		0.202620
  validation accuracy:		94.35 %
Epoch 298 of 2000 took 0.059s
  training loss:		0.121976
  validation loss:		0.206393
  validation accuracy:		94.24 %
Epoch 299 of 2000 took 0.059s
  training loss:		0.125377
  validation loss:		0.198349
  validation accuracy:		94.57 %
Epoch 300 of 2000 took 0.059s
  training loss:		0.122360
  validation loss:		0.192309
  validation accuracy:		94.89 %
Epoch 301 of 2000 took 0.059s
  training loss:		0.123729
  validation loss:		0.202078
  validation accuracy:		94.35 %
Epoch 302 of 2000 took 0.059s
  training loss:		0.120049
  validation loss:		0.193658
  validation accuracy:		94.89 %
Epoch 303 of 2000 took 0.059s
  training loss:		0.122460
  validation loss:		0.238975
  validation accuracy:		92.83 %
Epoch 304 of 2000 took 0.059s
  training loss:		0.125411
  validation loss:		0.211659
  validation accuracy:		94.24 %
Epoch 305 of 2000 took 0.059s
  training loss:		0.120665
  validation loss:		0.214242
  validation accuracy:		94.35 %
Epoch 306 of 2000 took 0.059s
  training loss:		0.123003
  validation loss:		0.202997
  validation accuracy:		94.67 %
Epoch 307 of 2000 took 0.059s
  training loss:		0.119891
  validation loss:		0.201906
  validation accuracy:		94.67 %
Epoch 308 of 2000 took 0.059s
  training loss:		0.118306
  validation loss:		0.203006
  validation accuracy:		94.57 %
Epoch 309 of 2000 took 0.059s
  training loss:		0.118117
  validation loss:		0.200678
  validation accuracy:		94.67 %
Epoch 310 of 2000 took 0.059s
  training loss:		0.117111
  validation loss:		0.206513
  validation accuracy:		94.57 %
Epoch 311 of 2000 took 0.059s
  training loss:		0.114496
  validation loss:		0.194775
  validation accuracy:		94.67 %
Epoch 312 of 2000 took 0.059s
  training loss:		0.119316
  validation loss:		0.203415
  validation accuracy:		94.46 %
Epoch 313 of 2000 took 0.059s
  training loss:		0.118835
  validation loss:		0.197684
  validation accuracy:		94.78 %
Epoch 314 of 2000 took 0.059s
  training loss:		0.116141
  validation loss:		0.200209
  validation accuracy:		94.35 %
Epoch 315 of 2000 took 0.059s
  training loss:		0.115944
  validation loss:		0.201351
  validation accuracy:		94.46 %
Epoch 316 of 2000 took 0.059s
  training loss:		0.118058
  validation loss:		0.206540
  validation accuracy:		94.24 %
Epoch 317 of 2000 took 0.059s
  training loss:		0.116414
  validation loss:		0.218981
  validation accuracy:		93.59 %
Epoch 318 of 2000 took 0.059s
  training loss:		0.115688
  validation loss:		0.208844
  validation accuracy:		94.46 %
Epoch 319 of 2000 took 0.059s
  training loss:		0.115059
  validation loss:		0.200538
  validation accuracy:		94.78 %
Epoch 320 of 2000 took 0.059s
  training loss:		0.116970
  validation loss:		0.192698
  validation accuracy:		94.78 %
Epoch 321 of 2000 took 0.059s
  training loss:		0.114577
  validation loss:		0.201010
  validation accuracy:		94.67 %
Epoch 322 of 2000 took 0.059s
  training loss:		0.116590
  validation loss:		0.209682
  validation accuracy:		93.91 %
Epoch 323 of 2000 took 0.059s
  training loss:		0.113342
  validation loss:		0.201321
  validation accuracy:		94.57 %
Epoch 324 of 2000 took 0.059s
  training loss:		0.116269
  validation loss:		0.194821
  validation accuracy:		94.78 %
Epoch 325 of 2000 took 0.059s
  training loss:		0.116102
  validation loss:		0.200509
  validation accuracy:		94.78 %
Epoch 326 of 2000 took 0.061s
  training loss:		0.115833
  validation loss:		0.197364
  validation accuracy:		94.78 %
Epoch 327 of 2000 took 0.059s
  training loss:		0.111564
  validation loss:		0.202420
  validation accuracy:		94.67 %
Epoch 328 of 2000 took 0.060s
  training loss:		0.114335
  validation loss:		0.195714
  validation accuracy:		94.67 %
Epoch 329 of 2000 took 0.059s
  training loss:		0.112663
  validation loss:		0.205984
  validation accuracy:		94.46 %
Epoch 330 of 2000 took 0.059s
  training loss:		0.111889
  validation loss:		0.210339
  validation accuracy:		94.13 %
Epoch 331 of 2000 took 0.059s
  training loss:		0.111455
  validation loss:		0.196362
  validation accuracy:		94.78 %
Epoch 332 of 2000 took 0.059s
  training loss:		0.111882
  validation loss:		0.208609
  validation accuracy:		94.46 %
Epoch 333 of 2000 took 0.059s
  training loss:		0.113022
  validation loss:		0.214478
  validation accuracy:		94.35 %
Epoch 334 of 2000 took 0.058s
  training loss:		0.111848
  validation loss:		0.215867
  validation accuracy:		93.91 %
Epoch 335 of 2000 took 0.059s
  training loss:		0.112315
  validation loss:		0.211116
  validation accuracy:		94.24 %
Epoch 336 of 2000 took 0.059s
  training loss:		0.109763
  validation loss:		0.210056
  validation accuracy:		94.24 %
Epoch 337 of 2000 took 0.059s
  training loss:		0.111802
  validation loss:		0.203957
  validation accuracy:		94.35 %
Epoch 338 of 2000 took 0.059s
  training loss:		0.109588
  validation loss:		0.208534
  validation accuracy:		94.24 %
Epoch 339 of 2000 took 0.059s
  training loss:		0.110371
  validation loss:		0.203044
  validation accuracy:		94.46 %
Epoch 340 of 2000 took 0.059s
  training loss:		0.110611
  validation loss:		0.209497
  validation accuracy:		94.46 %
Epoch 341 of 2000 took 0.059s
  training loss:		0.110465
  validation loss:		0.205719
  validation accuracy:		94.13 %
Epoch 342 of 2000 took 0.059s
  training loss:		0.112278
  validation loss:		0.196578
  validation accuracy:		94.89 %
Epoch 343 of 2000 took 0.059s
  training loss:		0.107009
  validation loss:		0.205193
  validation accuracy:		94.46 %
Epoch 344 of 2000 took 0.059s
  training loss:		0.100815
  validation loss:		0.206117
  validation accuracy:		94.67 %
Epoch 345 of 2000 took 0.058s
  training loss:		0.113083
  validation loss:		0.207007
  validation accuracy:		94.13 %
Epoch 346 of 2000 took 0.059s
  training loss:		0.107187
  validation loss:		0.211949
  validation accuracy:		94.02 %
Epoch 347 of 2000 took 0.059s
  training loss:		0.106525
  validation loss:		0.198514
  validation accuracy:		94.78 %
Epoch 348 of 2000 took 0.059s
  training loss:		0.108063
  validation loss:		0.211534
  validation accuracy:		94.24 %
Epoch 349 of 2000 took 0.059s
  training loss:		0.106248
  validation loss:		0.216735
  validation accuracy:		93.91 %
Epoch 350 of 2000 took 0.059s
  training loss:		0.105093
  validation loss:		0.217030
  validation accuracy:		93.91 %
Epoch 351 of 2000 took 0.059s
  training loss:		0.102571
  validation loss:		0.195614
  validation accuracy:		95.00 %
Epoch 352 of 2000 took 0.059s
  training loss:		0.107578
  validation loss:		0.201457
  validation accuracy:		94.78 %
Epoch 353 of 2000 took 0.059s
  training loss:		0.105355
  validation loss:		0.207371
  validation accuracy:		94.57 %
Epoch 354 of 2000 took 0.059s
  training loss:		0.104276
  validation loss:		0.204659
  validation accuracy:		94.57 %
Epoch 355 of 2000 took 0.059s
  training loss:		0.104424
  validation loss:		0.194004
  validation accuracy:		94.67 %
Epoch 356 of 2000 took 0.059s
  training loss:		0.106205
  validation loss:		0.201178
  validation accuracy:		94.78 %
Epoch 357 of 2000 took 0.059s
  training loss:		0.105839
  validation loss:		0.200627
  validation accuracy:		94.57 %
Epoch 358 of 2000 took 0.058s
  training loss:		0.103940
  validation loss:		0.210008
  validation accuracy:		94.24 %
Epoch 359 of 2000 took 0.059s
  training loss:		0.106083
  validation loss:		0.202223
  validation accuracy:		94.78 %
Epoch 360 of 2000 took 0.059s
  training loss:		0.104167
  validation loss:		0.201481
  validation accuracy:		94.89 %
Epoch 361 of 2000 took 0.054s
  training loss:		0.103315
  validation loss:		0.218403
  validation accuracy:		94.13 %
Epoch 362 of 2000 took 0.055s
  training loss:		0.104920
  validation loss:		0.215550
  validation accuracy:		94.46 %
Epoch 363 of 2000 took 0.058s
  training loss:		0.102405
  validation loss:		0.215917
  validation accuracy:		94.02 %
Epoch 364 of 2000 took 0.059s
  training loss:		0.104190
  validation loss:		0.210605
  validation accuracy:		94.78 %
Epoch 365 of 2000 took 0.058s
  training loss:		0.103577
  validation loss:		0.216077
  validation accuracy:		94.02 %
Epoch 366 of 2000 took 0.059s
  training loss:		0.104309
  validation loss:		0.205762
  validation accuracy:		94.67 %
Epoch 367 of 2000 took 0.059s
  training loss:		0.098175
  validation loss:		0.207773
  validation accuracy:		94.24 %
Epoch 368 of 2000 took 0.059s
  training loss:		0.103414
  validation loss:		0.209206
  validation accuracy:		94.57 %
Epoch 369 of 2000 took 0.059s
  training loss:		0.101597
  validation loss:		0.202929
  validation accuracy:		94.67 %
Epoch 370 of 2000 took 0.059s
  training loss:		0.102249
  validation loss:		0.202794
  validation accuracy:		94.57 %
Epoch 371 of 2000 took 0.059s
  training loss:		0.101801
  validation loss:		0.201145
  validation accuracy:		95.11 %
Epoch 372 of 2000 took 0.059s
  training loss:		0.099626
  validation loss:		0.197845
  validation accuracy:		94.78 %
Epoch 373 of 2000 took 0.059s
  training loss:		0.100221
  validation loss:		0.208053
  validation accuracy:		94.46 %
Epoch 374 of 2000 took 0.059s
  training loss:		0.100681
  validation loss:		0.211954
  validation accuracy:		94.24 %
Epoch 375 of 2000 took 0.058s
  training loss:		0.099641
  validation loss:		0.206144
  validation accuracy:		94.67 %
Epoch 376 of 2000 took 0.059s
  training loss:		0.098691
  validation loss:		0.211441
  validation accuracy:		94.46 %
Epoch 377 of 2000 took 0.059s
  training loss:		0.099096
  validation loss:		0.204923
  validation accuracy:		94.35 %
Epoch 378 of 2000 took 0.059s
  training loss:		0.097084
  validation loss:		0.212198
  validation accuracy:		94.57 %
Epoch 379 of 2000 took 0.058s
  training loss:		0.099051
  validation loss:		0.208804
  validation accuracy:		94.35 %
Epoch 380 of 2000 took 0.059s
  training loss:		0.099695
  validation loss:		0.205502
  validation accuracy:		94.57 %
Epoch 381 of 2000 took 0.059s
  training loss:		0.098337
  validation loss:		0.220937
  validation accuracy:		93.91 %
Epoch 382 of 2000 took 0.059s
  training loss:		0.098118
  validation loss:		0.198536
  validation accuracy:		95.00 %
Epoch 383 of 2000 took 0.059s
  training loss:		0.098912
  validation loss:		0.210880
  validation accuracy:		94.24 %
Epoch 384 of 2000 took 0.059s
  training loss:		0.097393
  validation loss:		0.215543
  validation accuracy:		94.24 %
Epoch 385 of 2000 took 0.059s
  training loss:		0.095447
  validation loss:		0.210165
  validation accuracy:		94.46 %
Epoch 386 of 2000 took 0.059s
  training loss:		0.098656
  validation loss:		0.215080
  validation accuracy:		94.13 %
Epoch 387 of 2000 took 0.059s
  training loss:		0.096700
  validation loss:		0.215397
  validation accuracy:		94.35 %
Epoch 388 of 2000 took 0.059s
  training loss:		0.097733
  validation loss:		0.210776
  validation accuracy:		94.46 %
Epoch 389 of 2000 took 0.059s
  training loss:		0.095040
  validation loss:		0.224792
  validation accuracy:		93.80 %
Epoch 390 of 2000 took 0.059s
  training loss:		0.094982
  validation loss:		0.214806
  validation accuracy:		93.91 %
Epoch 391 of 2000 took 0.059s
  training loss:		0.095952
  validation loss:		0.212200
  validation accuracy:		94.13 %
Epoch 392 of 2000 took 0.059s
  training loss:		0.093611
  validation loss:		0.212350
  validation accuracy:		94.35 %
Epoch 393 of 2000 took 0.059s
  training loss:		0.095561
  validation loss:		0.206840
  validation accuracy:		95.11 %
Epoch 394 of 2000 took 0.059s
  training loss:		0.095033
  validation loss:		0.219805
  validation accuracy:		93.91 %
Epoch 395 of 2000 took 0.059s
  training loss:		0.094947
  validation loss:		0.202794
  validation accuracy:		95.11 %
Epoch 396 of 2000 took 0.059s
  training loss:		0.096277
  validation loss:		0.212046
  validation accuracy:		94.46 %
Epoch 397 of 2000 took 0.059s
  training loss:		0.092054
  validation loss:		0.221046
  validation accuracy:		93.59 %
Epoch 398 of 2000 took 0.060s
  training loss:		0.094605
  validation loss:		0.205980
  validation accuracy:		94.57 %
Epoch 399 of 2000 took 0.059s
  training loss:		0.092882
  validation loss:		0.215377
  validation accuracy:		94.24 %
Epoch 400 of 2000 took 0.059s
  training loss:		0.092157
  validation loss:		0.209343
  validation accuracy:		94.13 %
Epoch 401 of 2000 took 0.059s
  training loss:		0.093506
  validation loss:		0.211595
  validation accuracy:		94.35 %
Epoch 402 of 2000 took 0.059s
  training loss:		0.090697
  validation loss:		0.214971
  validation accuracy:		94.35 %
Epoch 403 of 2000 took 0.059s
  training loss:		0.092856
  validation loss:		0.215552
  validation accuracy:		94.24 %
Epoch 404 of 2000 took 0.059s
  training loss:		0.094531
  validation loss:		0.213459
  validation accuracy:		94.13 %
Epoch 405 of 2000 took 0.059s
  training loss:		0.091346
  validation loss:		0.224036
  validation accuracy:		93.91 %
Epoch 406 of 2000 took 0.059s
  training loss:		0.091551
  validation loss:		0.197247
  validation accuracy:		94.89 %
Epoch 407 of 2000 took 0.058s
  training loss:		0.089910
  validation loss:		0.210062
  validation accuracy:		94.35 %
Epoch 408 of 2000 took 0.059s
  training loss:		0.090579
  validation loss:		0.207678
  validation accuracy:		95.11 %
Epoch 409 of 2000 took 0.059s
  training loss:		0.091134
  validation loss:		0.204904
  validation accuracy:		95.00 %
Epoch 410 of 2000 took 0.059s
  training loss:		0.091440
  validation loss:		0.209420
  validation accuracy:		94.57 %
Epoch 411 of 2000 took 0.059s
  training loss:		0.088768
  validation loss:		0.205852
  validation accuracy:		95.00 %
Epoch 412 of 2000 took 0.059s
  training loss:		0.089103
  validation loss:		0.206237
  validation accuracy:		94.46 %
Epoch 413 of 2000 took 0.060s
  training loss:		0.087500
  validation loss:		0.208902
  validation accuracy:		94.57 %
Epoch 414 of 2000 took 0.059s
  training loss:		0.089692
  validation loss:		0.210545
  validation accuracy:		94.46 %
Epoch 415 of 2000 took 0.060s
  training loss:		0.091569
  validation loss:		0.212999
  validation accuracy:		94.46 %
Epoch 416 of 2000 took 0.059s
  training loss:		0.091581
  validation loss:		0.221191
  validation accuracy:		93.80 %
Epoch 417 of 2000 took 0.059s
  training loss:		0.089563
  validation loss:		0.210296
  validation accuracy:		94.46 %
Epoch 418 of 2000 took 0.059s
  training loss:		0.088941
  validation loss:		0.214965
  validation accuracy:		94.13 %
Epoch 419 of 2000 took 0.059s
  training loss:		0.088406
  validation loss:		0.211522
  validation accuracy:		94.57 %
Epoch 420 of 2000 took 0.059s
  training loss:		0.088022
  validation loss:		0.209710
  validation accuracy:		94.46 %
Epoch 421 of 2000 took 0.059s
  training loss:		0.088735
  validation loss:		0.216555
  validation accuracy:		94.89 %
Epoch 422 of 2000 took 0.059s
  training loss:		0.087377
  validation loss:		0.212398
  validation accuracy:		94.78 %
Epoch 423 of 2000 took 0.059s
  training loss:		0.088173
  validation loss:		0.215168
  validation accuracy:		94.35 %
Epoch 424 of 2000 took 0.059s
  training loss:		0.085847
  validation loss:		0.212047
  validation accuracy:		94.46 %
Epoch 425 of 2000 took 0.059s
  training loss:		0.087456
  validation loss:		0.217655
  validation accuracy:		94.02 %
Epoch 426 of 2000 took 0.059s
  training loss:		0.087900
  validation loss:		0.206128
  validation accuracy:		94.67 %
Epoch 427 of 2000 took 0.059s
  training loss:		0.088527
  validation loss:		0.208788
  validation accuracy:		95.00 %
Epoch 428 of 2000 took 0.059s
  training loss:		0.086115
  validation loss:		0.215462
  validation accuracy:		94.46 %
Epoch 429 of 2000 took 0.059s
  training loss:		0.086278
  validation loss:		0.220991
  validation accuracy:		94.02 %
Epoch 430 of 2000 took 0.059s
  training loss:		0.086418
  validation loss:		0.213151
  validation accuracy:		94.24 %
Epoch 431 of 2000 took 0.058s
  training loss:		0.083609
  validation loss:		0.211806
  validation accuracy:		94.78 %
Epoch 432 of 2000 took 0.059s
  training loss:		0.085719
  validation loss:		0.222576
  validation accuracy:		94.02 %
Epoch 433 of 2000 took 0.059s
  training loss:		0.086563
  validation loss:		0.202839
  validation accuracy:		94.78 %
Epoch 434 of 2000 took 0.059s
  training loss:		0.086122
  validation loss:		0.214820
  validation accuracy:		94.46 %
Epoch 435 of 2000 took 0.059s
  training loss:		0.083378
  validation loss:		0.222708
  validation accuracy:		93.91 %
Epoch 436 of 2000 took 0.059s
  training loss:		0.083704
  validation loss:		0.219604
  validation accuracy:		94.46 %
Epoch 437 of 2000 took 0.059s
  training loss:		0.085807
  validation loss:		0.227843
  validation accuracy:		93.80 %
Epoch 438 of 2000 took 0.059s
  training loss:		0.085396
  validation loss:		0.208417
  validation accuracy:		94.89 %
Epoch 439 of 2000 took 0.059s
  training loss:		0.084146
  validation loss:		0.212448
  validation accuracy:		94.67 %
Epoch 440 of 2000 took 0.059s
  training loss:		0.085973
  validation loss:		0.221776
  validation accuracy:		94.02 %
Epoch 441 of 2000 took 0.059s
  training loss:		0.083337
  validation loss:		0.209463
  validation accuracy:		94.67 %
Epoch 442 of 2000 took 0.059s
  training loss:		0.084792
  validation loss:		0.210276
  validation accuracy:		95.00 %
Epoch 443 of 2000 took 0.059s
  training loss:		0.082912
  validation loss:		0.216767
  validation accuracy:		94.67 %
Epoch 444 of 2000 took 0.059s
  training loss:		0.086371
  validation loss:		0.215745
  validation accuracy:		94.46 %
Epoch 445 of 2000 took 0.059s
  training loss:		0.083037
  validation loss:		0.224755
  validation accuracy:		94.02 %
Epoch 446 of 2000 took 0.059s
  training loss:		0.081625
  validation loss:		0.216969
  validation accuracy:		94.24 %
Epoch 447 of 2000 took 0.059s
  training loss:		0.082329
  validation loss:		0.215965
  validation accuracy:		94.13 %
Epoch 448 of 2000 took 0.059s
  training loss:		0.082480
  validation loss:		0.220578
  validation accuracy:		94.35 %
Epoch 449 of 2000 took 0.059s
  training loss:		0.081213
  validation loss:		0.211278
  validation accuracy:		94.89 %
Epoch 450 of 2000 took 0.059s
  training loss:		0.081601
  validation loss:		0.220366
  validation accuracy:		94.35 %
Epoch 451 of 2000 took 0.059s
  training loss:		0.080816
  validation loss:		0.214708
  validation accuracy:		94.67 %
Epoch 452 of 2000 took 0.059s
  training loss:		0.082885
  validation loss:		0.208591
  validation accuracy:		94.89 %
Epoch 453 of 2000 took 0.059s
  training loss:		0.079477
  validation loss:		0.213315
  validation accuracy:		94.57 %
Epoch 454 of 2000 took 0.059s
  training loss:		0.079611
  validation loss:		0.215553
  validation accuracy:		94.67 %
Epoch 455 of 2000 took 0.059s
  training loss:		0.082964
  validation loss:		0.219372
  validation accuracy:		94.35 %
Epoch 456 of 2000 took 0.059s
  training loss:		0.080732
  validation loss:		0.231952
  validation accuracy:		93.80 %
Epoch 457 of 2000 took 0.059s
  training loss:		0.081523
  validation loss:		0.215808
  validation accuracy:		94.78 %
Epoch 458 of 2000 took 0.059s
  training loss:		0.080828
  validation loss:		0.216485
  validation accuracy:		94.35 %
Epoch 459 of 2000 took 0.059s
  training loss:		0.080331
  validation loss:		0.226184
  validation accuracy:		94.35 %
Epoch 460 of 2000 took 0.059s
  training loss:		0.080264
  validation loss:		0.223090
  validation accuracy:		94.13 %
Epoch 461 of 2000 took 0.059s
  training loss:		0.079906
  validation loss:		0.217427
  validation accuracy:		94.46 %
Epoch 462 of 2000 took 0.059s
  training loss:		0.081154
  validation loss:		0.212171
  validation accuracy:		94.67 %
Epoch 463 of 2000 took 0.059s
  training loss:		0.078929
  validation loss:		0.217054
  validation accuracy:		94.35 %
Epoch 464 of 2000 took 0.058s
  training loss:		0.080421
  validation loss:		0.226935
  validation accuracy:		94.46 %
Epoch 465 of 2000 took 0.059s
  training loss:		0.077908
  validation loss:		0.213834
  validation accuracy:		94.35 %
Epoch 466 of 2000 took 0.059s
  training loss:		0.080424
  validation loss:		0.224360
  validation accuracy:		94.57 %
Epoch 467 of 2000 took 0.059s
  training loss:		0.079000
  validation loss:		0.214561
  validation accuracy:		94.89 %
Epoch 468 of 2000 took 0.059s
  training loss:		0.078473
  validation loss:		0.214390
  validation accuracy:		94.57 %
Epoch 469 of 2000 took 0.059s
  training loss:		0.079370
  validation loss:		0.222364
  validation accuracy:		94.35 %
Epoch 470 of 2000 took 0.059s
  training loss:		0.078328
  validation loss:		0.219643
  validation accuracy:		94.35 %
Epoch 471 of 2000 took 0.059s
  training loss:		0.078250
  validation loss:		0.222140
  validation accuracy:		94.24 %
Epoch 472 of 2000 took 0.059s
  training loss:		0.075899
  validation loss:		0.208994
  validation accuracy:		95.00 %
Epoch 473 of 2000 took 0.059s
  training loss:		0.077603
  validation loss:		0.219238
  validation accuracy:		94.67 %
Epoch 474 of 2000 took 0.059s
  training loss:		0.075896
  validation loss:		0.228566
  validation accuracy:		94.02 %
Epoch 475 of 2000 took 0.059s
  training loss:		0.076957
  validation loss:		0.222626
  validation accuracy:		94.24 %
Epoch 476 of 2000 took 0.059s
  training loss:		0.073790
  validation loss:		0.236550
  validation accuracy:		93.80 %
Epoch 477 of 2000 took 0.059s
  training loss:		0.076102
  validation loss:		0.219880
  validation accuracy:		94.57 %
Epoch 478 of 2000 took 0.059s
  training loss:		0.077421
  validation loss:		0.227643
  validation accuracy:		94.46 %
Epoch 479 of 2000 took 0.059s
  training loss:		0.076697
  validation loss:		0.221468
  validation accuracy:		94.24 %
Epoch 480 of 2000 took 0.060s
  training loss:		0.074274
  validation loss:		0.225456
  validation accuracy:		93.91 %
Epoch 481 of 2000 took 0.059s
  training loss:		0.075159
  validation loss:		0.225280
  validation accuracy:		94.13 %
Epoch 482 of 2000 took 0.059s
  training loss:		0.074500
  validation loss:		0.221501
  validation accuracy:		94.67 %
Epoch 483 of 2000 took 0.059s
  training loss:		0.073432
  validation loss:		0.212215
  validation accuracy:		94.78 %
Epoch 484 of 2000 took 0.059s
  training loss:		0.074113
  validation loss:		0.221060
  validation accuracy:		94.46 %
Epoch 485 of 2000 took 0.059s
  training loss:		0.076085
  validation loss:		0.232005
  validation accuracy:		94.35 %
Epoch 486 of 2000 took 0.060s
  training loss:		0.073576
  validation loss:		0.230181
  validation accuracy:		93.80 %
Epoch 487 of 2000 took 0.059s
  training loss:		0.076288
  validation loss:		0.226556
  validation accuracy:		94.35 %
Epoch 488 of 2000 took 0.058s
  training loss:		0.074396
  validation loss:		0.210298
  validation accuracy:		94.89 %
Epoch 489 of 2000 took 0.059s
  training loss:		0.071789
  validation loss:		0.227297
  validation accuracy:		94.13 %
Epoch 490 of 2000 took 0.059s
  training loss:		0.075030
  validation loss:		0.230019
  validation accuracy:		94.13 %
Epoch 491 of 2000 took 0.059s
  training loss:		0.074021
  validation loss:		0.222234
  validation accuracy:		94.35 %
Epoch 492 of 2000 took 0.059s
  training loss:		0.072332
  validation loss:		0.215561
  validation accuracy:		94.89 %
Epoch 493 of 2000 took 0.059s
  training loss:		0.072070
  validation loss:		0.230489
  validation accuracy:		93.70 %
Epoch 494 of 2000 took 0.058s
  training loss:		0.071817
  validation loss:		0.225501
  validation accuracy:		94.24 %
Epoch 495 of 2000 took 0.055s
  training loss:		0.073204
  validation loss:		0.230354
  validation accuracy:		94.02 %
Epoch 496 of 2000 took 0.059s
  training loss:		0.074316
  validation loss:		0.235841
  validation accuracy:		94.13 %
Epoch 497 of 2000 took 0.059s
  training loss:		0.072521
  validation loss:		0.231854
  validation accuracy:		93.70 %
Epoch 498 of 2000 took 0.059s
  training loss:		0.070975
  validation loss:		0.217347
  validation accuracy:		94.67 %
Epoch 499 of 2000 took 0.058s
  training loss:		0.069293
  validation loss:		0.231821
  validation accuracy:		93.59 %
Epoch 500 of 2000 took 0.059s
  training loss:		0.071225
  validation loss:		0.221248
  validation accuracy:		94.35 %
Epoch 501 of 2000 took 0.059s
  training loss:		0.071795
  validation loss:		0.220961
  validation accuracy:		94.57 %
Epoch 502 of 2000 took 0.059s
  training loss:		0.069454
  validation loss:		0.237542
  validation accuracy:		93.48 %
Epoch 503 of 2000 took 0.059s
  training loss:		0.073308
  validation loss:		0.222729
  validation accuracy:		94.89 %
Epoch 504 of 2000 took 0.059s
  training loss:		0.071698
  validation loss:		0.212738
  validation accuracy:		94.78 %
Epoch 505 of 2000 took 0.059s
  training loss:		0.070708
  validation loss:		0.224839
  validation accuracy:		94.57 %
Epoch 506 of 2000 took 0.059s
  training loss:		0.068565
  validation loss:		0.231347
  validation accuracy:		94.24 %
Epoch 507 of 2000 took 0.059s
  training loss:		0.069182
  validation loss:		0.216038
  validation accuracy:		94.78 %
Epoch 508 of 2000 took 0.059s
  training loss:		0.070756
  validation loss:		0.230724
  validation accuracy:		94.24 %
Epoch 509 of 2000 took 0.059s
  training loss:		0.069156
  validation loss:		0.229385
  validation accuracy:		94.35 %
Epoch 510 of 2000 took 0.059s
  training loss:		0.071166
  validation loss:		0.236643
  validation accuracy:		93.59 %
Epoch 511 of 2000 took 0.059s
  training loss:		0.070251
  validation loss:		0.241978
  validation accuracy:		94.13 %
Epoch 512 of 2000 took 0.059s
  training loss:		0.070990
  validation loss:		0.232286
  validation accuracy:		94.02 %
Epoch 513 of 2000 took 0.059s
  training loss:		0.070924
  validation loss:		0.227331
  validation accuracy:		94.35 %
Epoch 514 of 2000 took 0.059s
  training loss:		0.071061
  validation loss:		0.217509
  validation accuracy:		94.78 %
Epoch 515 of 2000 took 0.059s
  training loss:		0.070197
  validation loss:		0.231767
  validation accuracy:		94.24 %
Epoch 516 of 2000 took 0.059s
  training loss:		0.068237
  validation loss:		0.236058
  validation accuracy:		94.02 %
Epoch 517 of 2000 took 0.059s
  training loss:		0.069558
  validation loss:		0.238865
  validation accuracy:		93.91 %
Epoch 518 of 2000 took 0.059s
  training loss:		0.069647
  validation loss:		0.238444
  validation accuracy:		94.24 %
Epoch 519 of 2000 took 0.059s
  training loss:		0.065074
  validation loss:		0.214948
  validation accuracy:		94.78 %
Epoch 520 of 2000 took 0.059s
  training loss:		0.069324
  validation loss:		0.236575
  validation accuracy:		93.91 %
Epoch 521 of 2000 took 0.058s
  training loss:		0.067042
  validation loss:		0.234580
  validation accuracy:		94.13 %
Epoch 522 of 2000 took 0.059s
  training loss:		0.067058
  validation loss:		0.223499
  validation accuracy:		94.67 %
Epoch 523 of 2000 took 0.059s
  training loss:		0.067625
  validation loss:		0.225464
  validation accuracy:		94.67 %
Epoch 524 of 2000 took 0.059s
  training loss:		0.068303
  validation loss:		0.224811
  validation accuracy:		94.13 %
Epoch 525 of 2000 took 0.059s
  training loss:		0.068589
  validation loss:		0.240391
  validation accuracy:		93.80 %
Epoch 526 of 2000 took 0.059s
  training loss:		0.065760
  validation loss:		0.234416
  validation accuracy:		94.35 %
Epoch 527 of 2000 took 0.059s
  training loss:		0.067844
  validation loss:		0.226444
  validation accuracy:		94.35 %
Epoch 528 of 2000 took 0.059s
  training loss:		0.066707
  validation loss:		0.228222
  validation accuracy:		94.67 %
Epoch 529 of 2000 took 0.059s
  training loss:		0.067851
  validation loss:		0.221429
  validation accuracy:		94.78 %
Epoch 530 of 2000 took 0.059s
  training loss:		0.067867
  validation loss:		0.222977
  validation accuracy:		94.24 %
Epoch 531 of 2000 took 0.059s
  training loss:		0.069660
  validation loss:		0.227103
  validation accuracy:		94.67 %
Epoch 532 of 2000 took 0.059s
  training loss:		0.063252
  validation loss:		0.231580
  validation accuracy:		94.02 %
Epoch 533 of 2000 took 0.059s
  training loss:		0.067646
  validation loss:		0.233370
  validation accuracy:		94.02 %
Epoch 534 of 2000 took 0.059s
  training loss:		0.067186
  validation loss:		0.231573
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.059s
  training loss:		0.065031
  validation loss:		0.232794
  validation accuracy:		94.35 %
Epoch 536 of 2000 took 0.059s
  training loss:		0.067782
  validation loss:		0.237833
  validation accuracy:		94.13 %
Epoch 537 of 2000 took 0.059s
  training loss:		0.065037
  validation loss:		0.234938
  validation accuracy:		94.35 %
Epoch 538 of 2000 took 0.059s
  training loss:		0.065275
  validation loss:		0.246834
  validation accuracy:		93.80 %
Epoch 539 of 2000 took 0.059s
  training loss:		0.066617
  validation loss:		0.234878
  validation accuracy:		93.70 %
Epoch 540 of 2000 took 0.059s
  training loss:		0.066711
  validation loss:		0.227766
  validation accuracy:		94.24 %
Epoch 541 of 2000 took 0.059s
  training loss:		0.066624
  validation loss:		0.225436
  validation accuracy:		94.67 %
Epoch 542 of 2000 took 0.059s
  training loss:		0.064845
  validation loss:		0.247453
  validation accuracy:		93.37 %
Epoch 543 of 2000 took 0.058s
  training loss:		0.065545
  validation loss:		0.220665
  validation accuracy:		94.67 %
Epoch 544 of 2000 took 0.059s
  training loss:		0.064780
  validation loss:		0.222126
  validation accuracy:		94.78 %
Epoch 545 of 2000 took 0.059s
  training loss:		0.064828
  validation loss:		0.224717
  validation accuracy:		94.67 %
Epoch 546 of 2000 took 0.060s
  training loss:		0.066236
  validation loss:		0.229983
  validation accuracy:		94.13 %
Epoch 547 of 2000 took 0.059s
  training loss:		0.064590
  validation loss:		0.227017
  validation accuracy:		94.67 %
Epoch 548 of 2000 took 0.059s
  training loss:		0.063358
  validation loss:		0.238985
  validation accuracy:		93.59 %
Epoch 549 of 2000 took 0.059s
  training loss:		0.066185
  validation loss:		0.226213
  validation accuracy:		94.67 %
Epoch 550 of 2000 took 0.059s
  training loss:		0.061419
  validation loss:		0.232333
  validation accuracy:		94.35 %
Epoch 551 of 2000 took 0.060s
  training loss:		0.063153
  validation loss:		0.238270
  validation accuracy:		94.13 %
Epoch 552 of 2000 took 0.059s
  training loss:		0.061478
  validation loss:		0.238912
  validation accuracy:		94.02 %
Epoch 553 of 2000 took 0.060s
  training loss:		0.063634
  validation loss:		0.237131
  validation accuracy:		94.02 %
Epoch 554 of 2000 took 0.059s
  training loss:		0.063603
  validation loss:		0.243158
  validation accuracy:		94.02 %
Epoch 555 of 2000 took 0.059s
  training loss:		0.064134
  validation loss:		0.235492
  validation accuracy:		94.35 %
Epoch 556 of 2000 took 0.059s
  training loss:		0.062574
  validation loss:		0.234712
  validation accuracy:		94.24 %
Epoch 557 of 2000 took 0.059s
  training loss:		0.060431
  validation loss:		0.232644
  validation accuracy:		94.13 %
Epoch 558 of 2000 took 0.059s
  training loss:		0.064202
  validation loss:		0.242186
  validation accuracy:		93.91 %
Epoch 559 of 2000 took 0.059s
  training loss:		0.063668
  validation loss:		0.244272
  validation accuracy:		93.91 %
Epoch 560 of 2000 took 0.059s
  training loss:		0.063720
  validation loss:		0.238506
  validation accuracy:		94.24 %
Epoch 561 of 2000 took 0.059s
  training loss:		0.061796
  validation loss:		0.228308
  validation accuracy:		94.13 %
Epoch 562 of 2000 took 0.061s
  training loss:		0.061669
  validation loss:		0.229838
  validation accuracy:		94.46 %
Epoch 563 of 2000 took 0.059s
  training loss:		0.060097
  validation loss:		0.238283
  validation accuracy:		93.59 %
Epoch 564 of 2000 took 0.059s
  training loss:		0.060627
  validation loss:		0.228614
  validation accuracy:		94.46 %
Epoch 565 of 2000 took 0.060s
  training loss:		0.061518
  validation loss:		0.226809
  validation accuracy:		94.57 %
Epoch 566 of 2000 took 0.060s
  training loss:		0.063043
  validation loss:		0.229475
  validation accuracy:		94.35 %
Epoch 567 of 2000 took 0.060s
  training loss:		0.061898
  validation loss:		0.230284
  validation accuracy:		94.57 %
Epoch 568 of 2000 took 0.059s
  training loss:		0.060015
  validation loss:		0.232216
  validation accuracy:		94.57 %
Epoch 569 of 2000 took 0.060s
  training loss:		0.062821
  validation loss:		0.236686
  validation accuracy:		94.02 %
Epoch 570 of 2000 took 0.060s
  training loss:		0.061656
  validation loss:		0.233998
  validation accuracy:		94.13 %
Epoch 571 of 2000 took 0.060s
  training loss:		0.060047
  validation loss:		0.235770
  validation accuracy:		94.02 %
Epoch 572 of 2000 took 0.060s
  training loss:		0.061915
  validation loss:		0.242719
  validation accuracy:		94.02 %
Epoch 573 of 2000 took 0.060s
  training loss:		0.058996
  validation loss:		0.238331
  validation accuracy:		94.13 %
Epoch 574 of 2000 took 0.059s
  training loss:		0.061582
  validation loss:		0.236755
  validation accuracy:		94.13 %
Epoch 575 of 2000 took 0.060s
  training loss:		0.060134
  validation loss:		0.248188
  validation accuracy:		93.91 %
Epoch 576 of 2000 took 0.059s
  training loss:		0.059927
  validation loss:		0.240320
  validation accuracy:		94.02 %
Epoch 577 of 2000 took 0.059s
  training loss:		0.060126
  validation loss:		0.227261
  validation accuracy:		94.57 %
Epoch 578 of 2000 took 0.059s
  training loss:		0.060360
  validation loss:		0.240215
  validation accuracy:		94.02 %
Epoch 579 of 2000 took 0.059s
  training loss:		0.057920
  validation loss:		0.238658
  validation accuracy:		94.02 %
Epoch 580 of 2000 took 0.059s
  training loss:		0.061641
  validation loss:		0.240892
  validation accuracy:		94.24 %
Epoch 581 of 2000 took 0.059s
  training loss:		0.059020
  validation loss:		0.230782
  validation accuracy:		94.46 %
Epoch 582 of 2000 took 0.059s
  training loss:		0.057225
  validation loss:		0.238886
  validation accuracy:		94.46 %
Epoch 583 of 2000 took 0.059s
  training loss:		0.059056
  validation loss:		0.232583
  validation accuracy:		94.46 %
Epoch 584 of 2000 took 0.059s
  training loss:		0.058362
  validation loss:		0.248893
  validation accuracy:		93.70 %
Epoch 585 of 2000 took 0.059s
  training loss:		0.058551
  validation loss:		0.246871
  validation accuracy:		93.80 %
Epoch 586 of 2000 took 0.059s
  training loss:		0.059078
  validation loss:		0.242152
  validation accuracy:		94.02 %
Epoch 587 of 2000 took 0.059s
  training loss:		0.059655
  validation loss:		0.246979
  validation accuracy:		94.13 %
Epoch 588 of 2000 took 0.059s
  training loss:		0.058591
  validation loss:		0.245199
  validation accuracy:		94.24 %
Epoch 589 of 2000 took 0.059s
  training loss:		0.058758
  validation loss:		0.244292
  validation accuracy:		93.91 %
Epoch 590 of 2000 took 0.059s
  training loss:		0.059499
  validation loss:		0.253062
  validation accuracy:		93.91 %
Epoch 591 of 2000 took 0.059s
  training loss:		0.059108
  validation loss:		0.250399
  validation accuracy:		94.13 %
Epoch 592 of 2000 took 0.059s
  training loss:		0.056728
  validation loss:		0.255341
  validation accuracy:		93.80 %
Epoch 593 of 2000 took 0.059s
  training loss:		0.055581
  validation loss:		0.230874
  validation accuracy:		94.35 %
Epoch 594 of 2000 took 0.059s
  training loss:		0.056887
  validation loss:		0.243662
  validation accuracy:		94.24 %
Epoch 595 of 2000 took 0.059s
  training loss:		0.057086
  validation loss:		0.236293
  validation accuracy:		94.13 %
Epoch 596 of 2000 took 0.059s
  training loss:		0.057173
  validation loss:		0.240274
  validation accuracy:		94.13 %
Epoch 597 of 2000 took 0.059s
  training loss:		0.057464
  validation loss:		0.248416
  validation accuracy:		94.13 %
Epoch 598 of 2000 took 0.059s
  training loss:		0.055804
  validation loss:		0.238314
  validation accuracy:		93.91 %
Epoch 599 of 2000 took 0.059s
  training loss:		0.054797
  validation loss:		0.252698
  validation accuracy:		93.91 %
Epoch 600 of 2000 took 0.059s
  training loss:		0.057249
  validation loss:		0.248371
  validation accuracy:		94.02 %
Epoch 601 of 2000 took 0.059s
  training loss:		0.055853
  validation loss:		0.241840
  validation accuracy:		94.13 %
Epoch 602 of 2000 took 0.059s
  training loss:		0.056475
  validation loss:		0.244691
  validation accuracy:		93.91 %
Epoch 603 of 2000 took 0.059s
  training loss:		0.056489
  validation loss:		0.245721
  validation accuracy:		94.13 %
Epoch 604 of 2000 took 0.059s
  training loss:		0.054998
  validation loss:		0.245070
  validation accuracy:		94.02 %
Epoch 605 of 2000 took 0.059s
  training loss:		0.055715
  validation loss:		0.251325
  validation accuracy:		93.80 %
Epoch 606 of 2000 took 0.059s
  training loss:		0.054794
  validation loss:		0.235752
  validation accuracy:		94.35 %
Epoch 607 of 2000 took 0.059s
  training loss:		0.054175
  validation loss:		0.232864
  validation accuracy:		94.46 %
Epoch 608 of 2000 took 0.059s
  training loss:		0.056340
  validation loss:		0.240326
  validation accuracy:		94.35 %
Epoch 609 of 2000 took 0.058s
  training loss:		0.054110
  validation loss:		0.230363
  validation accuracy:		94.67 %
Epoch 610 of 2000 took 0.059s
  training loss:		0.055951
  validation loss:		0.246068
  validation accuracy:		94.35 %
Epoch 611 of 2000 took 0.059s
  training loss:		0.055541
  validation loss:		0.238510
  validation accuracy:		94.02 %
Epoch 612 of 2000 took 0.059s
  training loss:		0.052989
  validation loss:		0.237062
  validation accuracy:		94.24 %
Epoch 613 of 2000 took 0.059s
  training loss:		0.054837
  validation loss:		0.250432
  validation accuracy:		93.91 %
Epoch 614 of 2000 took 0.059s
  training loss:		0.053281
  validation loss:		0.244497
  validation accuracy:		94.13 %
Epoch 615 of 2000 took 0.059s
  training loss:		0.053682
  validation loss:		0.249960
  validation accuracy:		94.02 %
Epoch 616 of 2000 took 0.059s
  training loss:		0.056179
  validation loss:		0.250379
  validation accuracy:		93.80 %
Epoch 617 of 2000 took 0.060s
  training loss:		0.052510
  validation loss:		0.244984
  validation accuracy:		93.91 %
Epoch 618 of 2000 took 0.060s
  training loss:		0.053113
  validation loss:		0.255474
  validation accuracy:		93.80 %
Epoch 619 of 2000 took 0.059s
  training loss:		0.053836
  validation loss:		0.245743
  validation accuracy:		94.02 %
Epoch 620 of 2000 took 0.059s
  training loss:		0.053579
  validation loss:		0.237068
  validation accuracy:		93.80 %
Epoch 621 of 2000 took 0.059s
  training loss:		0.053626
  validation loss:		0.245944
  validation accuracy:		94.35 %
Epoch 622 of 2000 took 0.059s
  training loss:		0.053163
  validation loss:		0.245678
  validation accuracy:		93.91 %
Epoch 623 of 2000 took 0.060s
  training loss:		0.052343
  validation loss:		0.254841
  validation accuracy:		93.70 %
Epoch 624 of 2000 took 0.060s
  training loss:		0.053080
  validation loss:		0.243888
  validation accuracy:		94.13 %
Epoch 625 of 2000 took 0.060s
  training loss:		0.052529
  validation loss:		0.266578
  validation accuracy:		93.26 %
Epoch 626 of 2000 took 0.059s
  training loss:		0.052337
  validation loss:		0.249461
  validation accuracy:		94.02 %
Epoch 627 of 2000 took 0.059s
  training loss:		0.053536
  validation loss:		0.245832
  validation accuracy:		94.02 %
Epoch 628 of 2000 took 0.059s
  training loss:		0.053170
  validation loss:		0.243212
  validation accuracy:		93.91 %
Epoch 629 of 2000 took 0.059s
  training loss:		0.053179
  validation loss:		0.248387
  validation accuracy:		94.24 %
Epoch 630 of 2000 took 0.059s
  training loss:		0.052205
  validation loss:		0.243470
  validation accuracy:		94.02 %
Epoch 631 of 2000 took 0.059s
  training loss:		0.052045
  validation loss:		0.250143
  validation accuracy:		93.91 %
Epoch 632 of 2000 took 0.059s
  training loss:		0.053268
  validation loss:		0.254517
  validation accuracy:		93.70 %
Epoch 633 of 2000 took 0.059s
  training loss:		0.052010
  validation loss:		0.256039
  validation accuracy:		93.91 %
Epoch 634 of 2000 took 0.059s
  training loss:		0.052831
  validation loss:		0.257721
  validation accuracy:		93.91 %
Epoch 635 of 2000 took 0.059s
  training loss:		0.051511
  validation loss:		0.258818
  validation accuracy:		93.80 %
Epoch 636 of 2000 took 0.059s
  training loss:		0.050980
  validation loss:		0.258211
  validation accuracy:		93.59 %
Epoch 637 of 2000 took 0.059s
  training loss:		0.051878
  validation loss:		0.250780
  validation accuracy:		94.13 %
Epoch 638 of 2000 took 0.059s
  training loss:		0.050048
  validation loss:		0.243992
  validation accuracy:		94.02 %
Epoch 639 of 2000 took 0.059s
  training loss:		0.052070
  validation loss:		0.246184
  validation accuracy:		94.02 %
Epoch 640 of 2000 took 0.060s
  training loss:		0.048334
  validation loss:		0.257236
  validation accuracy:		93.70 %
Epoch 641 of 2000 took 0.059s
  training loss:		0.049385
  validation loss:		0.240730
  validation accuracy:		94.02 %
Epoch 642 of 2000 took 0.060s
  training loss:		0.050160
  validation loss:		0.253818
  validation accuracy:		93.80 %
Epoch 643 of 2000 took 0.060s
  training loss:		0.051257
  validation loss:		0.253103
  validation accuracy:		93.80 %
Epoch 644 of 2000 took 0.059s
  training loss:		0.051056
  validation loss:		0.249533
  validation accuracy:		93.80 %
Epoch 645 of 2000 took 0.059s
  training loss:		0.050575
  validation loss:		0.250993
  validation accuracy:		93.70 %
Epoch 646 of 2000 took 0.059s
  training loss:		0.049452
  validation loss:		0.247013
  validation accuracy:		94.02 %
Epoch 647 of 2000 took 0.058s
  training loss:		0.048595
  validation loss:		0.255034
  validation accuracy:		93.91 %
Epoch 648 of 2000 took 0.059s
  training loss:		0.050532
  validation loss:		0.266365
  validation accuracy:		93.70 %
Epoch 649 of 2000 took 0.059s
  training loss:		0.049185
  validation loss:		0.265813
  validation accuracy:		93.70 %
Epoch 650 of 2000 took 0.059s
  training loss:		0.051478
  validation loss:		0.252871
  validation accuracy:		94.02 %
Epoch 651 of 2000 took 0.059s
  training loss:		0.050017
  validation loss:		0.257960
  validation accuracy:		93.80 %
Epoch 652 of 2000 took 0.059s
  training loss:		0.047342
  validation loss:		0.249309
  validation accuracy:		94.02 %
Epoch 653 of 2000 took 0.059s
  training loss:		0.049768
  validation loss:		0.251186
  validation accuracy:		93.91 %
Epoch 654 of 2000 took 0.059s
  training loss:		0.049473
  validation loss:		0.245827
  validation accuracy:		94.02 %
Epoch 655 of 2000 took 0.059s
  training loss:		0.048458
  validation loss:		0.255193
  validation accuracy:		93.80 %
Epoch 656 of 2000 took 0.059s
  training loss:		0.049086
  validation loss:		0.248287
  validation accuracy:		94.24 %
Epoch 657 of 2000 took 0.059s
  training loss:		0.050098
  validation loss:		0.255652
  validation accuracy:		93.80 %
Epoch 658 of 2000 took 0.059s
  training loss:		0.048880
  validation loss:		0.261505
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.059s
  training loss:		0.049164
  validation loss:		0.251644
  validation accuracy:		94.13 %
Epoch 660 of 2000 took 0.059s
  training loss:		0.048579
  validation loss:		0.243638
  validation accuracy:		94.35 %
Epoch 661 of 2000 took 0.059s
  training loss:		0.047783
  validation loss:		0.270780
  validation accuracy:		93.70 %
Epoch 662 of 2000 took 0.059s
  training loss:		0.048994
  validation loss:		0.256426
  validation accuracy:		93.70 %
Epoch 663 of 2000 took 0.059s
  training loss:		0.047993
  validation loss:		0.249982
  validation accuracy:		94.24 %
Epoch 664 of 2000 took 0.059s
  training loss:		0.047526
  validation loss:		0.260430
  validation accuracy:		93.70 %
Epoch 665 of 2000 took 0.059s
  training loss:		0.047920
  validation loss:		0.264756
  validation accuracy:		93.80 %
Epoch 666 of 2000 took 0.059s
  training loss:		0.048858
  validation loss:		0.255868
  validation accuracy:		93.48 %
Epoch 667 of 2000 took 0.059s
  training loss:		0.048710
  validation loss:		0.252899
  validation accuracy:		93.70 %
Epoch 668 of 2000 took 0.059s
  training loss:		0.046894
  validation loss:		0.260465
  validation accuracy:		94.02 %
Epoch 669 of 2000 took 0.059s
  training loss:		0.046833
  validation loss:		0.253860
  validation accuracy:		94.02 %
Epoch 670 of 2000 took 0.059s
  training loss:		0.044524
  validation loss:		0.269946
  validation accuracy:		93.59 %
Epoch 671 of 2000 took 0.059s
  training loss:		0.046849
  validation loss:		0.254792
  validation accuracy:		93.91 %
Epoch 672 of 2000 took 0.059s
  training loss:		0.048112
  validation loss:		0.250067
  validation accuracy:		93.91 %
Epoch 673 of 2000 took 0.059s
  training loss:		0.046652
  validation loss:		0.251277
  validation accuracy:		93.91 %
Epoch 674 of 2000 took 0.059s
  training loss:		0.047794
  validation loss:		0.251848
  validation accuracy:		93.91 %
Epoch 675 of 2000 took 0.059s
  training loss:		0.047891
  validation loss:		0.260519
  validation accuracy:		93.80 %
Epoch 676 of 2000 took 0.059s
  training loss:		0.044766
  validation loss:		0.260715
  validation accuracy:		93.70 %
Epoch 677 of 2000 took 0.059s
  training loss:		0.047399
  validation loss:		0.254528
  validation accuracy:		93.80 %
Epoch 678 of 2000 took 0.059s
  training loss:		0.046484
  validation loss:		0.259916
  validation accuracy:		93.80 %
Epoch 679 of 2000 took 0.059s
  training loss:		0.047035
  validation loss:		0.263100
  validation accuracy:		93.80 %
Epoch 680 of 2000 took 0.059s
  training loss:		0.045864
  validation loss:		0.261677
  validation accuracy:		93.70 %
Epoch 681 of 2000 took 0.059s
  training loss:		0.046729
  validation loss:		0.257434
  validation accuracy:		94.02 %
Epoch 682 of 2000 took 0.059s
  training loss:		0.046702
  validation loss:		0.265248
  validation accuracy:		94.02 %
Epoch 683 of 2000 took 0.059s
  training loss:		0.046349
  validation loss:		0.265191
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.059s
  training loss:		0.045293
  validation loss:		0.263851
  validation accuracy:		93.59 %
Epoch 685 of 2000 took 0.058s
  training loss:		0.047549
  validation loss:		0.269096
  validation accuracy:		93.59 %
Epoch 686 of 2000 took 0.059s
  training loss:		0.042553
  validation loss:		0.260047
  validation accuracy:		93.91 %
Epoch 687 of 2000 took 0.059s
  training loss:		0.045328
  validation loss:		0.259958
  validation accuracy:		93.80 %
Epoch 688 of 2000 took 0.059s
  training loss:		0.045620
  validation loss:		0.268220
  validation accuracy:		93.15 %
Epoch 689 of 2000 took 0.059s
  training loss:		0.045102
  validation loss:		0.258518
  validation accuracy:		93.59 %
Epoch 690 of 2000 took 0.059s
  training loss:		0.044903
  validation loss:		0.265364
  validation accuracy:		93.37 %
Epoch 691 of 2000 took 0.059s
  training loss:		0.044017
  validation loss:		0.265200
  validation accuracy:		93.70 %
Epoch 692 of 2000 took 0.059s
  training loss:		0.045777
  validation loss:		0.256489
  validation accuracy:		93.70 %
Epoch 693 of 2000 took 0.059s
  training loss:		0.045242
  validation loss:		0.267230
  validation accuracy:		93.70 %
Epoch 694 of 2000 took 0.059s
  training loss:		0.043302
  validation loss:		0.268272
  validation accuracy:		93.48 %
Epoch 695 of 2000 took 0.059s
  training loss:		0.043790
  validation loss:		0.267780
  validation accuracy:		93.70 %
Epoch 696 of 2000 took 0.059s
  training loss:		0.042791
  validation loss:		0.257682
  validation accuracy:		94.02 %
Epoch 697 of 2000 took 0.059s
  training loss:		0.045646
  validation loss:		0.266070
  validation accuracy:		93.70 %
Epoch 698 of 2000 took 0.059s
  training loss:		0.044451
  validation loss:		0.268952
  validation accuracy:		94.02 %
Epoch 699 of 2000 took 0.060s
  training loss:		0.045389
  validation loss:		0.272847
  validation accuracy:		93.59 %
Epoch 700 of 2000 took 0.059s
  training loss:		0.043914
  validation loss:		0.271735
  validation accuracy:		93.91 %
Epoch 701 of 2000 took 0.060s
  training loss:		0.042767
  validation loss:		0.272429
  validation accuracy:		93.37 %
Epoch 702 of 2000 took 0.060s
  training loss:		0.044565
  validation loss:		0.281078
  validation accuracy:		93.37 %
Epoch 703 of 2000 took 0.060s
  training loss:		0.044625
  validation loss:		0.273645
  validation accuracy:		93.70 %
Epoch 704 of 2000 took 0.060s
  training loss:		0.044717
  validation loss:		0.273029
  validation accuracy:		93.80 %
Epoch 705 of 2000 took 0.060s
  training loss:		0.044075
  validation loss:		0.265706
  validation accuracy:		93.26 %
Epoch 706 of 2000 took 0.060s
  training loss:		0.043078
  validation loss:		0.276554
  validation accuracy:		93.70 %
Epoch 707 of 2000 took 0.060s
  training loss:		0.043226
  validation loss:		0.271978
  validation accuracy:		93.70 %
Epoch 708 of 2000 took 0.056s
  training loss:		0.042998
  validation loss:		0.267088
  validation accuracy:		93.59 %
Epoch 709 of 2000 took 0.059s
  training loss:		0.044174
  validation loss:		0.260044
  validation accuracy:		93.91 %
Epoch 710 of 2000 took 0.060s
  training loss:		0.041012
  validation loss:		0.260687
  validation accuracy:		93.91 %
Epoch 711 of 2000 took 0.059s
  training loss:		0.043389
  validation loss:		0.271551
  validation accuracy:		93.70 %
Epoch 712 of 2000 took 0.059s
  training loss:		0.043754
  validation loss:		0.261279
  validation accuracy:		94.02 %
Epoch 713 of 2000 took 0.059s
  training loss:		0.041712
  validation loss:		0.264574
  validation accuracy:		93.80 %
Epoch 714 of 2000 took 0.059s
  training loss:		0.043215
  validation loss:		0.268377
  validation accuracy:		93.70 %
Epoch 715 of 2000 took 0.059s
  training loss:		0.041618
  validation loss:		0.264885
  validation accuracy:		93.37 %
Epoch 716 of 2000 took 0.059s
  training loss:		0.041091
  validation loss:		0.282420
  validation accuracy:		93.04 %
Epoch 717 of 2000 took 0.059s
  training loss:		0.042703
  validation loss:		0.269907
  validation accuracy:		93.48 %
Epoch 718 of 2000 took 0.059s
  training loss:		0.041960
  validation loss:		0.277009
  validation accuracy:		93.26 %
Epoch 719 of 2000 took 0.059s
  training loss:		0.042705
  validation loss:		0.271314
  validation accuracy:		93.48 %
Epoch 720 of 2000 took 0.060s
  training loss:		0.041531
  validation loss:		0.270412
  validation accuracy:		93.70 %
Epoch 721 of 2000 took 0.059s
  training loss:		0.041962
  validation loss:		0.275960
  validation accuracy:		93.48 %
Epoch 722 of 2000 took 0.060s
  training loss:		0.042342
  validation loss:		0.268829
  validation accuracy:		93.70 %
Epoch 723 of 2000 took 0.059s
  training loss:		0.042382
  validation loss:		0.260729
  validation accuracy:		93.70 %
Epoch 724 of 2000 took 0.059s
  training loss:		0.041557
  validation loss:		0.264570
  validation accuracy:		93.59 %
Epoch 725 of 2000 took 0.059s
  training loss:		0.041250
  validation loss:		0.284151
  validation accuracy:		93.37 %
Epoch 726 of 2000 took 0.059s
  training loss:		0.040383
  validation loss:		0.272225
  validation accuracy:		93.48 %
Epoch 727 of 2000 took 0.059s
  training loss:		0.040088
  validation loss:		0.260617
  validation accuracy:		93.91 %
Epoch 728 of 2000 took 0.059s
  training loss:		0.041625
  validation loss:		0.274453
  validation accuracy:		93.37 %
Epoch 729 of 2000 took 0.059s
  training loss:		0.041431
  validation loss:		0.273019
  validation accuracy:		93.70 %
Epoch 730 of 2000 took 0.060s
  training loss:		0.040134
  validation loss:		0.276682
  validation accuracy:		93.59 %
Epoch 731 of 2000 took 0.060s
  training loss:		0.041315
  validation loss:		0.265869
  validation accuracy:		93.59 %
Epoch 732 of 2000 took 0.060s
  training loss:		0.040101
  validation loss:		0.278485
  validation accuracy:		93.26 %
Epoch 733 of 2000 took 0.060s
  training loss:		0.040691
  validation loss:		0.271739
  validation accuracy:		93.80 %
Epoch 734 of 2000 took 0.060s
  training loss:		0.040720
  validation loss:		0.276594
  validation accuracy:		93.37 %
Epoch 735 of 2000 took 0.060s
  training loss:		0.039681
  validation loss:		0.271773
  validation accuracy:		93.70 %
Epoch 736 of 2000 took 0.060s
  training loss:		0.039714
  validation loss:		0.269673
  validation accuracy:		93.80 %
Epoch 737 of 2000 took 0.060s
  training loss:		0.039923
  validation loss:		0.271105
  validation accuracy:		93.37 %
Epoch 738 of 2000 took 0.059s
  training loss:		0.040611
  validation loss:		0.289989
  validation accuracy:		93.15 %
Epoch 739 of 2000 took 0.059s
  training loss:		0.041454
  validation loss:		0.271358
  validation accuracy:		93.37 %
Epoch 740 of 2000 took 0.060s
  training loss:		0.040918
  validation loss:		0.284709
  validation accuracy:		93.59 %
Epoch 741 of 2000 took 0.059s
  training loss:		0.039389
  validation loss:		0.276632
  validation accuracy:		93.37 %
Epoch 742 of 2000 took 0.059s
  training loss:		0.040011
  validation loss:		0.290676
  validation accuracy:		93.48 %
Epoch 743 of 2000 took 0.060s
  training loss:		0.039906
  validation loss:		0.280614
  validation accuracy:		93.15 %
Epoch 744 of 2000 took 0.059s
  training loss:		0.039704
  validation loss:		0.296643
  validation accuracy:		93.15 %
Epoch 745 of 2000 took 0.059s
  training loss:		0.040754
  validation loss:		0.267837
  validation accuracy:		94.02 %
Epoch 746 of 2000 took 0.059s
  training loss:		0.039069
  validation loss:		0.295424
  validation accuracy:		92.93 %
Epoch 747 of 2000 took 0.059s
  training loss:		0.039177
  validation loss:		0.279783
  validation accuracy:		93.59 %
Epoch 748 of 2000 took 0.059s
  training loss:		0.037883
  validation loss:		0.278264
  validation accuracy:		93.15 %
Epoch 749 of 2000 took 0.059s
  training loss:		0.039725
  validation loss:		0.275714
  validation accuracy:		93.37 %
Epoch 750 of 2000 took 0.059s
  training loss:		0.037417
  validation loss:		0.282368
  validation accuracy:		93.70 %
Epoch 751 of 2000 took 0.060s
  training loss:		0.039316
  validation loss:		0.286735
  validation accuracy:		93.48 %
Epoch 752 of 2000 took 0.060s
  training loss:		0.038546
  validation loss:		0.275356
  validation accuracy:		93.48 %
Epoch 753 of 2000 took 0.060s
  training loss:		0.039643
  validation loss:		0.272278
  validation accuracy:		93.59 %
Epoch 754 of 2000 took 0.060s
  training loss:		0.040087
  validation loss:		0.281932
  validation accuracy:		93.48 %
Epoch 755 of 2000 took 0.060s
  training loss:		0.037532
  validation loss:		0.277178
  validation accuracy:		93.59 %
Epoch 756 of 2000 took 0.059s
  training loss:		0.036822
  validation loss:		0.288123
  validation accuracy:		93.37 %
Epoch 757 of 2000 took 0.059s
  training loss:		0.037105
  validation loss:		0.292325
  validation accuracy:		93.15 %
Epoch 758 of 2000 took 0.060s
  training loss:		0.038876
  validation loss:		0.282764
  validation accuracy:		93.48 %
Epoch 759 of 2000 took 0.059s
  training loss:		0.038455
  validation loss:		0.272534
  validation accuracy:		93.37 %
Epoch 760 of 2000 took 0.060s
  training loss:		0.038122
  validation loss:		0.272815
  validation accuracy:		93.37 %
Epoch 761 of 2000 took 0.059s
  training loss:		0.038111
  validation loss:		0.276509
  validation accuracy:		93.26 %
Epoch 762 of 2000 took 0.060s
  training loss:		0.039177
  validation loss:		0.291213
  validation accuracy:		93.37 %
Epoch 763 of 2000 took 0.059s
  training loss:		0.038567
  validation loss:		0.290201
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.059s
  training loss:		0.037374
  validation loss:		0.277725
  validation accuracy:		93.48 %
Epoch 765 of 2000 took 0.059s
  training loss:		0.037283
  validation loss:		0.277254
  validation accuracy:		93.37 %
Epoch 766 of 2000 took 0.059s
  training loss:		0.037860
  validation loss:		0.283085
  validation accuracy:		93.48 %
Epoch 767 of 2000 took 0.059s
  training loss:		0.036090
  validation loss:		0.281736
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.060s
  training loss:		0.039017
  validation loss:		0.280208
  validation accuracy:		93.48 %
Epoch 769 of 2000 took 0.060s
  training loss:		0.038480
  validation loss:		0.291850
  validation accuracy:		93.37 %
Epoch 770 of 2000 took 0.060s
  training loss:		0.037318
  validation loss:		0.286812
  validation accuracy:		93.37 %
Epoch 771 of 2000 took 0.059s
  training loss:		0.037300
  validation loss:		0.274139
  validation accuracy:		93.59 %
Epoch 772 of 2000 took 0.059s
  training loss:		0.037164
  validation loss:		0.283606
  validation accuracy:		92.93 %
Epoch 773 of 2000 took 0.059s
  training loss:		0.037753
  validation loss:		0.297866
  validation accuracy:		93.26 %
Epoch 774 of 2000 took 0.059s
  training loss:		0.035678
  validation loss:		0.282416
  validation accuracy:		93.59 %
Epoch 775 of 2000 took 0.059s
  training loss:		0.036737
  validation loss:		0.281053
  validation accuracy:		93.26 %
Epoch 776 of 2000 took 0.059s
  training loss:		0.035028
  validation loss:		0.283141
  validation accuracy:		93.15 %
Epoch 777 of 2000 took 0.058s
  training loss:		0.034323
  validation loss:		0.284037
  validation accuracy:		93.70 %
Epoch 778 of 2000 took 0.059s
  training loss:		0.034668
  validation loss:		0.276573
  validation accuracy:		93.26 %
Epoch 779 of 2000 took 0.059s
  training loss:		0.035873
  validation loss:		0.285202
  validation accuracy:		93.26 %
Epoch 780 of 2000 took 0.059s
  training loss:		0.036324
  validation loss:		0.283914
  validation accuracy:		93.70 %
Epoch 781 of 2000 took 0.059s
  training loss:		0.036132
  validation loss:		0.282356
  validation accuracy:		93.59 %
Epoch 782 of 2000 took 0.059s
  training loss:		0.037090
  validation loss:		0.277830
  validation accuracy:		93.70 %
Epoch 783 of 2000 took 0.059s
  training loss:		0.035208
  validation loss:		0.297321
  validation accuracy:		93.15 %
Epoch 784 of 2000 took 0.059s
  training loss:		0.035513
  validation loss:		0.283695
  validation accuracy:		93.48 %
Epoch 785 of 2000 took 0.059s
  training loss:		0.035249
  validation loss:		0.290438
  validation accuracy:		93.15 %
Epoch 786 of 2000 took 0.059s
  training loss:		0.034907
  validation loss:		0.285868
  validation accuracy:		93.37 %
Epoch 787 of 2000 took 0.059s
  training loss:		0.034946
  validation loss:		0.286894
  validation accuracy:		93.37 %
Epoch 788 of 2000 took 0.059s
  training loss:		0.035691
  validation loss:		0.286540
  validation accuracy:		93.37 %
Epoch 789 of 2000 took 0.059s
  training loss:		0.035567
  validation loss:		0.284202
  validation accuracy:		93.37 %
Epoch 790 of 2000 took 0.059s
  training loss:		0.035446
  validation loss:		0.284428
  validation accuracy:		93.37 %
Epoch 791 of 2000 took 0.059s
  training loss:		0.035818
  validation loss:		0.281452
  validation accuracy:		93.37 %
Epoch 792 of 2000 took 0.059s
  training loss:		0.034599
  validation loss:		0.302140
  validation accuracy:		92.93 %
Epoch 793 of 2000 took 0.059s
  training loss:		0.035984
  validation loss:		0.295756
  validation accuracy:		93.15 %
Epoch 794 of 2000 took 0.059s
  training loss:		0.035309
  validation loss:		0.295009
  validation accuracy:		93.15 %
Epoch 795 of 2000 took 0.059s
  training loss:		0.035913
  validation loss:		0.279879
  validation accuracy:		93.37 %
Epoch 796 of 2000 took 0.059s
  training loss:		0.035159
  validation loss:		0.293025
  validation accuracy:		93.04 %
Epoch 797 of 2000 took 0.059s
  training loss:		0.033719
  validation loss:		0.289971
  validation accuracy:		93.59 %
Epoch 798 of 2000 took 0.059s
  training loss:		0.035353
  validation loss:		0.290553
  validation accuracy:		93.26 %
Epoch 799 of 2000 took 0.059s
  training loss:		0.034905
  validation loss:		0.283639
  validation accuracy:		93.37 %
Epoch 800 of 2000 took 0.059s
  training loss:		0.035577
  validation loss:		0.285562
  validation accuracy:		93.80 %
Epoch 801 of 2000 took 0.060s
  training loss:		0.033756
  validation loss:		0.310251
  validation accuracy:		92.93 %
Epoch 802 of 2000 took 0.059s
  training loss:		0.034732
  validation loss:		0.286680
  validation accuracy:		93.15 %
Epoch 803 of 2000 took 0.059s
  training loss:		0.034880
  validation loss:		0.292492
  validation accuracy:		93.26 %
Epoch 804 of 2000 took 0.059s
  training loss:		0.034179
  validation loss:		0.288915
  validation accuracy:		93.15 %
Epoch 805 of 2000 took 0.059s
  training loss:		0.034766
  validation loss:		0.287435
  validation accuracy:		93.37 %
Epoch 806 of 2000 took 0.059s
  training loss:		0.033334
  validation loss:		0.302071
  validation accuracy:		93.15 %
Epoch 807 of 2000 took 0.059s
  training loss:		0.034402
  validation loss:		0.293464
  validation accuracy:		92.93 %
Epoch 808 of 2000 took 0.059s
  training loss:		0.033760
  validation loss:		0.300075
  validation accuracy:		92.93 %
Epoch 809 of 2000 took 0.059s
  training loss:		0.033727
  validation loss:		0.291675
  validation accuracy:		93.37 %
Epoch 810 of 2000 took 0.059s
  training loss:		0.034140
  validation loss:		0.298269
  validation accuracy:		93.15 %
Epoch 811 of 2000 took 0.059s
  training loss:		0.033442
  validation loss:		0.296305
  validation accuracy:		93.15 %
Epoch 812 of 2000 took 0.059s
  training loss:		0.033750
  validation loss:		0.294692
  validation accuracy:		92.93 %
Epoch 813 of 2000 took 0.059s
  training loss:		0.034139
  validation loss:		0.289116
  validation accuracy:		93.48 %
Epoch 814 of 2000 took 0.059s
  training loss:		0.034685
  validation loss:		0.297422
  validation accuracy:		93.26 %
Epoch 815 of 2000 took 0.059s
  training loss:		0.032980
  validation loss:		0.295174
  validation accuracy:		93.59 %
Epoch 816 of 2000 took 0.059s
  training loss:		0.032970
  validation loss:		0.285113
  validation accuracy:		93.59 %
Epoch 817 of 2000 took 0.058s
  training loss:		0.032876
  validation loss:		0.286488
  validation accuracy:		93.59 %
Epoch 818 of 2000 took 0.059s
  training loss:		0.033076
  validation loss:		0.296849
  validation accuracy:		93.26 %
Epoch 819 of 2000 took 0.059s
  training loss:		0.032480
  validation loss:		0.290332
  validation accuracy:		93.37 %
Epoch 820 of 2000 took 0.059s
  training loss:		0.033557
  validation loss:		0.284348
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.059s
  training loss:		0.032521
  validation loss:		0.301284
  validation accuracy:		93.26 %
Epoch 822 of 2000 took 0.059s
  training loss:		0.033519
  validation loss:		0.298881
  validation accuracy:		93.48 %
Epoch 823 of 2000 took 0.059s
  training loss:		0.032824
  validation loss:		0.296711
  validation accuracy:		93.48 %
Epoch 824 of 2000 took 0.059s
  training loss:		0.033157
  validation loss:		0.300703
  validation accuracy:		93.04 %
Epoch 825 of 2000 took 0.059s
  training loss:		0.032209
  validation loss:		0.291794
  validation accuracy:		93.37 %
Epoch 826 of 2000 took 0.059s
  training loss:		0.030438
  validation loss:		0.300520
  validation accuracy:		93.26 %
Epoch 827 of 2000 took 0.059s
  training loss:		0.031547
  validation loss:		0.304698
  validation accuracy:		92.72 %
Epoch 828 of 2000 took 0.059s
  training loss:		0.033173
  validation loss:		0.294217
  validation accuracy:		93.15 %
Epoch 829 of 2000 took 0.059s
  training loss:		0.033561
  validation loss:		0.297201
  validation accuracy:		93.37 %
Epoch 830 of 2000 took 0.059s
  training loss:		0.033253
  validation loss:		0.292969
  validation accuracy:		93.59 %
Epoch 831 of 2000 took 0.059s
  training loss:		0.032915
  validation loss:		0.290246
  validation accuracy:		93.04 %
Epoch 832 of 2000 took 0.059s
  training loss:		0.032706
  validation loss:		0.298546
  validation accuracy:		93.04 %
Epoch 833 of 2000 took 0.059s
  training loss:		0.031178
  validation loss:		0.285136
  validation accuracy:		93.37 %
Epoch 834 of 2000 took 0.059s
  training loss:		0.031079
  validation loss:		0.292967
  validation accuracy:		93.37 %
Epoch 835 of 2000 took 0.059s
  training loss:		0.032510
  validation loss:		0.295923
  validation accuracy:		92.83 %
Epoch 836 of 2000 took 0.059s
  training loss:		0.031911
  validation loss:		0.300424
  validation accuracy:		93.48 %
Epoch 837 of 2000 took 0.058s
  training loss:		0.031496
  validation loss:		0.293805
  validation accuracy:		93.26 %
Epoch 838 of 2000 took 0.059s
  training loss:		0.032564
  validation loss:		0.300409
  validation accuracy:		93.37 %
Epoch 839 of 2000 took 0.059s
  training loss:		0.032587
  validation loss:		0.305008
  validation accuracy:		92.83 %
Epoch 840 of 2000 took 0.059s
  training loss:		0.029066
  validation loss:		0.298269
  validation accuracy:		93.37 %
Epoch 841 of 2000 took 0.059s
  training loss:		0.030485
  validation loss:		0.304371
  validation accuracy:		93.04 %
Epoch 842 of 2000 took 0.059s
  training loss:		0.031209
  validation loss:		0.293053
  validation accuracy:		93.37 %
Epoch 843 of 2000 took 0.059s
  training loss:		0.029725
  validation loss:		0.300544
  validation accuracy:		93.15 %
Epoch 844 of 2000 took 0.059s
  training loss:		0.030512
  validation loss:		0.301517
  validation accuracy:		93.37 %
Epoch 845 of 2000 took 0.059s
  training loss:		0.031845
  validation loss:		0.295093
  validation accuracy:		93.37 %
Epoch 846 of 2000 took 0.059s
  training loss:		0.030090
  validation loss:		0.302006
  validation accuracy:		93.15 %
Epoch 847 of 2000 took 0.059s
  training loss:		0.030582
  validation loss:		0.307044
  validation accuracy:		93.04 %
Epoch 848 of 2000 took 0.059s
  training loss:		0.031309
  validation loss:		0.305726
  validation accuracy:		93.26 %
Epoch 849 of 2000 took 0.059s
  training loss:		0.032064
  validation loss:		0.295415
  validation accuracy:		93.37 %
Epoch 850 of 2000 took 0.059s
  training loss:		0.031114
  validation loss:		0.300382
  validation accuracy:		93.26 %
Epoch 851 of 2000 took 0.059s
  training loss:		0.031174
  validation loss:		0.300664
  validation accuracy:		93.48 %
Epoch 852 of 2000 took 0.059s
  training loss:		0.030839
  validation loss:		0.306229
  validation accuracy:		93.37 %
Epoch 853 of 2000 took 0.059s
  training loss:		0.029224
  validation loss:		0.295386
  validation accuracy:		93.59 %
Epoch 854 of 2000 took 0.059s
  training loss:		0.030564
  validation loss:		0.310049
  validation accuracy:		93.26 %
Epoch 855 of 2000 took 0.059s
  training loss:		0.030227
  validation loss:		0.311114
  validation accuracy:		92.83 %
Epoch 856 of 2000 took 0.073s
  training loss:		0.030149
  validation loss:		0.300199
  validation accuracy:		93.48 %
Epoch 857 of 2000 took 0.070s
  training loss:		0.029495
  validation loss:		0.315891
  validation accuracy:		92.83 %
Epoch 858 of 2000 took 0.063s
  training loss:		0.029892
  validation loss:		0.299901
  validation accuracy:		93.26 %
Epoch 859 of 2000 took 0.062s
  training loss:		0.030625
  validation loss:		0.304183
  validation accuracy:		93.26 %
Epoch 860 of 2000 took 0.063s
  training loss:		0.030885
  validation loss:		0.302853
  validation accuracy:		93.15 %
Epoch 861 of 2000 took 0.062s
  training loss:		0.029722
  validation loss:		0.308685
  validation accuracy:		93.15 %
Epoch 862 of 2000 took 0.063s
  training loss:		0.031118
  validation loss:		0.301163
  validation accuracy:		93.48 %
Epoch 863 of 2000 took 0.063s
  training loss:		0.029362
  validation loss:		0.323500
  validation accuracy:		92.50 %
Epoch 864 of 2000 took 0.064s
  training loss:		0.029484
  validation loss:		0.296538
  validation accuracy:		93.26 %
Epoch 865 of 2000 took 0.063s
  training loss:		0.028807
  validation loss:		0.298908
  validation accuracy:		93.59 %
Epoch 866 of 2000 took 0.063s
  training loss:		0.029351
  validation loss:		0.306895
  validation accuracy:		93.26 %
Epoch 867 of 2000 took 0.062s
  training loss:		0.029253
  validation loss:		0.308243
  validation accuracy:		93.26 %
Epoch 868 of 2000 took 0.059s
  training loss:		0.029596
  validation loss:		0.307433
  validation accuracy:		92.93 %
Epoch 869 of 2000 took 0.058s
  training loss:		0.030112
  validation loss:		0.300923
  validation accuracy:		93.48 %
Epoch 870 of 2000 took 0.058s
  training loss:		0.029598
  validation loss:		0.308636
  validation accuracy:		93.37 %
Epoch 871 of 2000 took 0.058s
  training loss:		0.029479
  validation loss:		0.314947
  validation accuracy:		92.83 %
Epoch 872 of 2000 took 0.058s
  training loss:		0.028781
  validation loss:		0.319297
  validation accuracy:		92.83 %
Epoch 873 of 2000 took 0.058s
  training loss:		0.029938
  validation loss:		0.308412
  validation accuracy:		93.04 %
Epoch 874 of 2000 took 0.058s
  training loss:		0.028552
  validation loss:		0.310816
  validation accuracy:		92.93 %
Epoch 875 of 2000 took 0.058s
  training loss:		0.028538
  validation loss:		0.309015
  validation accuracy:		93.15 %
Epoch 876 of 2000 took 0.058s
  training loss:		0.028238
  validation loss:		0.301762
  validation accuracy:		93.48 %
Epoch 877 of 2000 took 0.058s
  training loss:		0.027575
  validation loss:		0.311211
  validation accuracy:		92.93 %
Epoch 878 of 2000 took 0.058s
  training loss:		0.027894
  validation loss:		0.306438
  validation accuracy:		92.83 %
Epoch 879 of 2000 took 0.058s
  training loss:		0.029109
  validation loss:		0.315922
  validation accuracy:		92.61 %
Epoch 880 of 2000 took 0.058s
  training loss:		0.028895
  validation loss:		0.309176
  validation accuracy:		93.26 %
Epoch 881 of 2000 took 0.058s
  training loss:		0.028170
  validation loss:		0.309686
  validation accuracy:		93.48 %
Epoch 882 of 2000 took 0.058s
  training loss:		0.027723
  validation loss:		0.307865
  validation accuracy:		93.37 %
Epoch 883 of 2000 took 0.058s
  training loss:		0.028146
  validation loss:		0.315039
  validation accuracy:		93.26 %
Epoch 884 of 2000 took 0.058s
  training loss:		0.029211
  validation loss:		0.309240
  validation accuracy:		93.26 %
Epoch 885 of 2000 took 0.058s
  training loss:		0.028026
  validation loss:		0.307981
  validation accuracy:		93.26 %
Epoch 886 of 2000 took 0.058s
  training loss:		0.027525
  validation loss:		0.310043
  validation accuracy:		93.15 %
Epoch 887 of 2000 took 0.058s
  training loss:		0.028278
  validation loss:		0.316652
  validation accuracy:		92.83 %
Epoch 888 of 2000 took 0.058s
  training loss:		0.028508
  validation loss:		0.322533
  validation accuracy:		92.93 %
Epoch 889 of 2000 took 0.057s
  training loss:		0.028457
  validation loss:		0.305827
  validation accuracy:		92.83 %
Epoch 890 of 2000 took 0.058s
  training loss:		0.027710
  validation loss:		0.311161
  validation accuracy:		93.26 %
Epoch 891 of 2000 took 0.058s
  training loss:		0.027773
  validation loss:		0.318423
  validation accuracy:		92.83 %
Epoch 892 of 2000 took 0.058s
  training loss:		0.027137
  validation loss:		0.316813
  validation accuracy:		92.93 %
Epoch 893 of 2000 took 0.058s
  training loss:		0.028710
  validation loss:		0.311003
  validation accuracy:		93.48 %
Epoch 894 of 2000 took 0.058s
  training loss:		0.027671
  validation loss:		0.316566
  validation accuracy:		92.61 %
Epoch 895 of 2000 took 0.059s
  training loss:		0.026824
  validation loss:		0.327921
  validation accuracy:		92.72 %
Epoch 896 of 2000 took 0.058s
  training loss:		0.026974
  validation loss:		0.316905
  validation accuracy:		92.93 %
Epoch 897 of 2000 took 0.058s
  training loss:		0.027536
  validation loss:		0.315570
  validation accuracy:		92.61 %
Epoch 898 of 2000 took 0.057s
  training loss:		0.027185
  validation loss:		0.315500
  validation accuracy:		92.61 %
Epoch 899 of 2000 took 0.058s
  training loss:		0.027082
  validation loss:		0.308467
  validation accuracy:		93.15 %
Epoch 900 of 2000 took 0.058s
  training loss:		0.028868
  validation loss:		0.323375
  validation accuracy:		92.72 %
Epoch 901 of 2000 took 0.057s
  training loss:		0.028309
  validation loss:		0.316782
  validation accuracy:		92.83 %
Epoch 902 of 2000 took 0.058s
  training loss:		0.027343
  validation loss:		0.308109
  validation accuracy:		92.93 %
Epoch 903 of 2000 took 0.058s
  training loss:		0.026120
  validation loss:		0.314205
  validation accuracy:		93.26 %
Epoch 904 of 2000 took 0.058s
  training loss:		0.027032
  validation loss:		0.311425
  validation accuracy:		93.15 %
Epoch 905 of 2000 took 0.058s
  training loss:		0.026802
  validation loss:		0.321720
  validation accuracy:		93.15 %
Epoch 906 of 2000 took 0.058s
  training loss:		0.024856
  validation loss:		0.319112
  validation accuracy:		92.93 %
Epoch 907 of 2000 took 0.058s
  training loss:		0.025785
  validation loss:		0.333134
  validation accuracy:		92.61 %
Epoch 908 of 2000 took 0.058s
  training loss:		0.027805
  validation loss:		0.321999
  validation accuracy:		93.04 %
Epoch 909 of 2000 took 0.058s
  training loss:		0.027680
  validation loss:		0.316791
  validation accuracy:		93.04 %
Epoch 910 of 2000 took 0.058s
  training loss:		0.027529
  validation loss:		0.320933
  validation accuracy:		92.93 %
Epoch 911 of 2000 took 0.058s
  training loss:		0.026498
  validation loss:		0.314127
  validation accuracy:		93.15 %
Epoch 912 of 2000 took 0.058s
  training loss:		0.026850
  validation loss:		0.319263
  validation accuracy:		92.83 %
Epoch 913 of 2000 took 0.058s
  training loss:		0.026456
  validation loss:		0.321461
  validation accuracy:		92.93 %
Epoch 914 of 2000 took 0.058s
  training loss:		0.026382
  validation loss:		0.312738
  validation accuracy:		93.26 %
Epoch 915 of 2000 took 0.058s
  training loss:		0.025818
  validation loss:		0.307119
  validation accuracy:		93.26 %
Epoch 916 of 2000 took 0.058s
  training loss:		0.026875
  validation loss:		0.325997
  validation accuracy:		92.61 %
Epoch 917 of 2000 took 0.058s
  training loss:		0.026228
  validation loss:		0.322122
  validation accuracy:		92.72 %
Epoch 918 of 2000 took 0.058s
  training loss:		0.026260
  validation loss:		0.310574
  validation accuracy:		93.37 %
Epoch 919 of 2000 took 0.058s
  training loss:		0.026376
  validation loss:		0.324690
  validation accuracy:		92.93 %
Epoch 920 of 2000 took 0.059s
  training loss:		0.025704
  validation loss:		0.330632
  validation accuracy:		92.61 %
Epoch 921 of 2000 took 0.058s
  training loss:		0.026035
  validation loss:		0.320805
  validation accuracy:		92.72 %
Epoch 922 of 2000 took 0.059s
  training loss:		0.024561
  validation loss:		0.328973
  validation accuracy:		92.39 %
Epoch 923 of 2000 took 0.058s
  training loss:		0.026341
  validation loss:		0.314292
  validation accuracy:		93.26 %
Epoch 924 of 2000 took 0.058s
  training loss:		0.024978
  validation loss:		0.327200
  validation accuracy:		92.83 %
Epoch 925 of 2000 took 0.058s
  training loss:		0.025401
  validation loss:		0.319245
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.059s
  training loss:		0.024951
  validation loss:		0.323970
  validation accuracy:		93.26 %
Epoch 927 of 2000 took 0.059s
  training loss:		0.025398
  validation loss:		0.318072
  validation accuracy:		93.15 %
Epoch 928 of 2000 took 0.059s
  training loss:		0.026251
  validation loss:		0.310845
  validation accuracy:		93.37 %
Epoch 929 of 2000 took 0.059s
  training loss:		0.025337
  validation loss:		0.327613
  validation accuracy:		93.04 %
Epoch 930 of 2000 took 0.059s
  training loss:		0.025263
  validation loss:		0.313356
  validation accuracy:		93.37 %
Epoch 931 of 2000 took 0.058s
  training loss:		0.024633
  validation loss:		0.326740
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.059s
  training loss:		0.025129
  validation loss:		0.324108
  validation accuracy:		92.93 %
Epoch 933 of 2000 took 0.059s
  training loss:		0.023741
  validation loss:		0.320012
  validation accuracy:		93.15 %
Epoch 934 of 2000 took 0.059s
  training loss:		0.024936
  validation loss:		0.318441
  validation accuracy:		93.37 %
Epoch 935 of 2000 took 0.059s
  training loss:		0.025551
  validation loss:		0.328811
  validation accuracy:		92.83 %
Epoch 936 of 2000 took 0.059s
  training loss:		0.024439
  validation loss:		0.318986
  validation accuracy:		92.83 %
Epoch 937 of 2000 took 0.059s
  training loss:		0.025197
  validation loss:		0.332771
  validation accuracy:		92.39 %
Epoch 938 of 2000 took 0.059s
  training loss:		0.024968
  validation loss:		0.321845
  validation accuracy:		92.72 %
Epoch 939 of 2000 took 0.059s
  training loss:		0.024498
  validation loss:		0.325010
  validation accuracy:		92.93 %
Epoch 940 of 2000 took 0.059s
  training loss:		0.024475
  validation loss:		0.328675
  validation accuracy:		92.50 %
Epoch 941 of 2000 took 0.060s
  training loss:		0.023022
  validation loss:		0.318578
  validation accuracy:		93.15 %
Epoch 942 of 2000 took 0.060s
  training loss:		0.025093
  validation loss:		0.319760
  validation accuracy:		93.15 %
Epoch 943 of 2000 took 0.059s
  training loss:		0.024400
  validation loss:		0.326273
  validation accuracy:		93.04 %
Epoch 944 of 2000 took 0.059s
  training loss:		0.025508
  validation loss:		0.320722
  validation accuracy:		93.04 %
Epoch 945 of 2000 took 0.060s
  training loss:		0.023381
  validation loss:		0.328020
  validation accuracy:		93.15 %
Epoch 946 of 2000 took 0.059s
  training loss:		0.024063
  validation loss:		0.335945
  validation accuracy:		92.61 %
Epoch 947 of 2000 took 0.059s
  training loss:		0.023198
  validation loss:		0.329167
  validation accuracy:		92.61 %
Epoch 948 of 2000 took 0.059s
  training loss:		0.024014
  validation loss:		0.321793
  validation accuracy:		92.93 %
Epoch 949 of 2000 took 0.059s
  training loss:		0.024546
  validation loss:		0.324367
  validation accuracy:		92.61 %
Epoch 950 of 2000 took 0.060s
  training loss:		0.024220
  validation loss:		0.324688
  validation accuracy:		92.83 %
Epoch 951 of 2000 took 0.059s
  training loss:		0.025044
  validation loss:		0.330667
  validation accuracy:		92.83 %
Epoch 952 of 2000 took 0.059s
  training loss:		0.023796
  validation loss:		0.327782
  validation accuracy:		92.93 %
Epoch 953 of 2000 took 0.059s
  training loss:		0.024313
  validation loss:		0.334197
  validation accuracy:		92.72 %
Epoch 954 of 2000 took 0.059s
  training loss:		0.024075
  validation loss:		0.322109
  validation accuracy:		93.15 %
Epoch 955 of 2000 took 0.059s
  training loss:		0.023627
  validation loss:		0.330157
  validation accuracy:		92.83 %
Epoch 956 of 2000 took 0.059s
  training loss:		0.022470
  validation loss:		0.329312
  validation accuracy:		93.15 %
Epoch 957 of 2000 took 0.059s
  training loss:		0.024186
  validation loss:		0.330615
  validation accuracy:		93.26 %
Epoch 958 of 2000 took 0.059s
  training loss:		0.023554
  validation loss:		0.320962
  validation accuracy:		93.37 %
Epoch 959 of 2000 took 0.059s
  training loss:		0.024496
  validation loss:		0.325339
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.059s
  training loss:		0.023616
  validation loss:		0.337412
  validation accuracy:		92.61 %
Epoch 961 of 2000 took 0.059s
  training loss:		0.023306
  validation loss:		0.336507
  validation accuracy:		92.61 %
Epoch 962 of 2000 took 0.059s
  training loss:		0.022231
  validation loss:		0.334879
  validation accuracy:		92.61 %
Epoch 963 of 2000 took 0.061s
  training loss:		0.023500
  validation loss:		0.327210
  validation accuracy:		93.26 %
Epoch 964 of 2000 took 0.059s
  training loss:		0.024046
  validation loss:		0.330022
  validation accuracy:		92.83 %
Epoch 965 of 2000 took 0.058s
  training loss:		0.023487
  validation loss:		0.333940
  validation accuracy:		93.15 %
Epoch 966 of 2000 took 0.059s
  training loss:		0.023057
  validation loss:		0.337275
  validation accuracy:		92.61 %
Epoch 967 of 2000 took 0.059s
  training loss:		0.022692
  validation loss:		0.328308
  validation accuracy:		93.04 %
Epoch 968 of 2000 took 0.059s
  training loss:		0.022757
  validation loss:		0.346326
  validation accuracy:		92.61 %
Epoch 969 of 2000 took 0.059s
  training loss:		0.022292
  validation loss:		0.333786
  validation accuracy:		92.93 %
Epoch 970 of 2000 took 0.059s
  training loss:		0.022870
  validation loss:		0.331597
  validation accuracy:		93.04 %
Epoch 971 of 2000 took 0.059s
  training loss:		0.023317
  validation loss:		0.341093
  validation accuracy:		92.50 %
Epoch 972 of 2000 took 0.059s
  training loss:		0.023414
  validation loss:		0.342599
  validation accuracy:		92.28 %
Epoch 973 of 2000 took 0.056s
  training loss:		0.023353
  validation loss:		0.333822
  validation accuracy:		92.50 %
Epoch 974 of 2000 took 0.057s
  training loss:		0.022828
  validation loss:		0.334859
  validation accuracy:		92.50 %
Epoch 975 of 2000 took 0.059s
  training loss:		0.023310
  validation loss:		0.332865
  validation accuracy:		92.93 %
Epoch 976 of 2000 took 0.059s
  training loss:		0.022959
  validation loss:		0.332612
  validation accuracy:		93.04 %
Epoch 977 of 2000 took 0.059s
  training loss:		0.022437
  validation loss:		0.341392
  validation accuracy:		92.50 %
Epoch 978 of 2000 took 0.058s
  training loss:		0.022761
  validation loss:		0.354637
  validation accuracy:		92.39 %
Epoch 979 of 2000 took 0.059s
  training loss:		0.022882
  validation loss:		0.329711
  validation accuracy:		92.83 %
Epoch 980 of 2000 took 0.058s
  training loss:		0.022583
  validation loss:		0.343915
  validation accuracy:		92.17 %
Epoch 981 of 2000 took 0.059s
  training loss:		0.022398
  validation loss:		0.342281
  validation accuracy:		92.83 %
Epoch 982 of 2000 took 0.059s
  training loss:		0.023107
  validation loss:		0.339107
  validation accuracy:		93.15 %
Epoch 983 of 2000 took 0.059s
  training loss:		0.022631
  validation loss:		0.345464
  validation accuracy:		92.28 %
Epoch 984 of 2000 took 0.059s
  training loss:		0.022465
  validation loss:		0.350535
  validation accuracy:		92.28 %
Epoch 985 of 2000 took 0.061s
  training loss:		0.022670
  validation loss:		0.345511
  validation accuracy:		92.72 %
Epoch 986 of 2000 took 0.059s
  training loss:		0.023066
  validation loss:		0.347468
  validation accuracy:		92.39 %
Epoch 987 of 2000 took 0.059s
  training loss:		0.022824
  validation loss:		0.336432
  validation accuracy:		93.04 %
Epoch 988 of 2000 took 0.059s
  training loss:		0.021522
  validation loss:		0.336026
  validation accuracy:		93.26 %
Epoch 989 of 2000 took 0.059s
  training loss:		0.022378
  validation loss:		0.333950
  validation accuracy:		92.93 %
Epoch 990 of 2000 took 0.059s
  training loss:		0.021931
  validation loss:		0.344617
  validation accuracy:		92.39 %
Epoch 991 of 2000 took 0.060s
  training loss:		0.021985
  validation loss:		0.340454
  validation accuracy:		92.83 %
Epoch 992 of 2000 took 0.059s
  training loss:		0.021408
  validation loss:		0.340338
  validation accuracy:		92.61 %
Epoch 993 of 2000 took 0.059s
  training loss:		0.022082
  validation loss:		0.343545
  validation accuracy:		92.83 %
Epoch 994 of 2000 took 0.059s
  training loss:		0.022026
  validation loss:		0.339402
  validation accuracy:		92.61 %
Epoch 995 of 2000 took 0.059s
  training loss:		0.021405
  validation loss:		0.335223
  validation accuracy:		92.93 %
Epoch 996 of 2000 took 0.059s
  training loss:		0.021052
  validation loss:		0.333994
  validation accuracy:		93.04 %
Epoch 997 of 2000 took 0.059s
  training loss:		0.021358
  validation loss:		0.347960
  validation accuracy:		92.61 %
Epoch 998 of 2000 took 0.059s
  training loss:		0.021017
  validation loss:		0.345624
  validation accuracy:		92.50 %
Epoch 999 of 2000 took 0.059s
  training loss:		0.021683
  validation loss:		0.358675
  validation accuracy:		92.39 %
Epoch 1000 of 2000 took 0.059s
  training loss:		0.021398
  validation loss:		0.337573
  validation accuracy:		92.72 %
Epoch 1001 of 2000 took 0.059s
  training loss:		0.021337
  validation loss:		0.346476
  validation accuracy:		92.28 %
Epoch 1002 of 2000 took 0.059s
  training loss:		0.021937
  validation loss:		0.355883
  validation accuracy:		92.50 %
Epoch 1003 of 2000 took 0.059s
  training loss:		0.021395
  validation loss:		0.341857
  validation accuracy:		92.61 %
Epoch 1004 of 2000 took 0.059s
  training loss:		0.022067
  validation loss:		0.349095
  validation accuracy:		92.39 %
Epoch 1005 of 2000 took 0.060s
  training loss:		0.021847
  validation loss:		0.347641
  validation accuracy:		92.61 %
Epoch 1006 of 2000 took 0.058s
  training loss:		0.019842
  validation loss:		0.350381
  validation accuracy:		92.50 %
Epoch 1007 of 2000 took 0.059s
  training loss:		0.021097
  validation loss:		0.350414
  validation accuracy:		92.39 %
Epoch 1008 of 2000 took 0.060s
  training loss:		0.021168
  validation loss:		0.343327
  validation accuracy:		92.83 %
Epoch 1009 of 2000 took 0.055s
  training loss:		0.021020
  validation loss:		0.347762
  validation accuracy:		92.61 %
Epoch 1010 of 2000 took 0.057s
  training loss:		0.020856
  validation loss:		0.333019
  validation accuracy:		93.04 %
Epoch 1011 of 2000 took 0.059s
  training loss:		0.020877
  validation loss:		0.352429
  validation accuracy:		92.50 %
Epoch 1012 of 2000 took 0.059s
  training loss:		0.021008
  validation loss:		0.353194
  validation accuracy:		92.72 %
Epoch 1013 of 2000 took 0.059s
  training loss:		0.020801
  validation loss:		0.339691
  validation accuracy:		93.15 %
Epoch 1014 of 2000 took 0.059s
  training loss:		0.021277
  validation loss:		0.344193
  validation accuracy:		92.50 %
Epoch 1015 of 2000 took 0.059s
  training loss:		0.020549
  validation loss:		0.350890
  validation accuracy:		92.61 %
Epoch 1016 of 2000 took 0.058s
  training loss:		0.020654
  validation loss:		0.354580
  validation accuracy:		92.61 %
Epoch 1017 of 2000 took 0.059s
  training loss:		0.019811
  validation loss:		0.349530
  validation accuracy:		92.83 %
Epoch 1018 of 2000 took 0.059s
  training loss:		0.020497
  validation loss:		0.350104
  validation accuracy:		92.83 %
Epoch 1019 of 2000 took 0.059s
  training loss:		0.020980
  validation loss:		0.359660
  validation accuracy:		92.17 %
Epoch 1020 of 2000 took 0.059s
  training loss:		0.020536
  validation loss:		0.351453
  validation accuracy:		92.17 %
Epoch 1021 of 2000 took 0.059s
  training loss:		0.020817
  validation loss:		0.345438
  validation accuracy:		92.39 %
Epoch 1022 of 2000 took 0.059s
  training loss:		0.020251
  validation loss:		0.353892
  validation accuracy:		92.39 %
Epoch 1023 of 2000 took 0.059s
  training loss:		0.020587
  validation loss:		0.354627
  validation accuracy:		92.72 %
Epoch 1024 of 2000 took 0.059s
  training loss:		0.018879
  validation loss:		0.340871
  validation accuracy:		93.04 %
Epoch 1025 of 2000 took 0.059s
  training loss:		0.019448
  validation loss:		0.352890
  validation accuracy:		92.50 %
Epoch 1026 of 2000 took 0.059s
  training loss:		0.019951
  validation loss:		0.355675
  validation accuracy:		92.39 %
Epoch 1027 of 2000 took 0.060s
  training loss:		0.020404
  validation loss:		0.349984
  validation accuracy:		92.50 %
Epoch 1028 of 2000 took 0.060s
  training loss:		0.020718
  validation loss:		0.343416
  validation accuracy:		92.83 %
Epoch 1029 of 2000 took 0.059s
  training loss:		0.019583
  validation loss:		0.346631
  validation accuracy:		92.93 %
Epoch 1030 of 2000 took 0.059s
  training loss:		0.020271
  validation loss:		0.347163
  validation accuracy:		92.72 %
Epoch 1031 of 2000 took 0.059s
  training loss:		0.020123
  validation loss:		0.350680
  validation accuracy:		92.50 %
Epoch 1032 of 2000 took 0.059s
  training loss:		0.018691
  validation loss:		0.353276
  validation accuracy:		92.39 %
Epoch 1033 of 2000 took 0.059s
  training loss:		0.019341
  validation loss:		0.348669
  validation accuracy:		92.72 %
Epoch 1034 of 2000 took 0.059s
  training loss:		0.020119
  validation loss:		0.343878
  validation accuracy:		92.72 %
Epoch 1035 of 2000 took 0.059s
  training loss:		0.019423
  validation loss:		0.354391
  validation accuracy:		92.72 %
Epoch 1036 of 2000 took 0.059s
  training loss:		0.019415
  validation loss:		0.348700
  validation accuracy:		92.83 %
Epoch 1037 of 2000 took 0.059s
  training loss:		0.019646
  validation loss:		0.347695
  validation accuracy:		92.50 %
Epoch 1038 of 2000 took 0.059s
  training loss:		0.019812
  validation loss:		0.348599
  validation accuracy:		92.72 %
Epoch 1039 of 2000 took 0.060s
  training loss:		0.019449
  validation loss:		0.356950
  validation accuracy:		92.72 %
Epoch 1040 of 2000 took 0.060s
  training loss:		0.018990
  validation loss:		0.356087
  validation accuracy:		92.39 %
Epoch 1041 of 2000 took 0.060s
  training loss:		0.019533
  validation loss:		0.351344
  validation accuracy:		92.72 %
Epoch 1042 of 2000 took 0.059s
  training loss:		0.019671
  validation loss:		0.342978
  validation accuracy:		93.04 %
Epoch 1043 of 2000 took 0.059s
  training loss:		0.019634
  validation loss:		0.351557
  validation accuracy:		93.04 %
Epoch 1044 of 2000 took 0.059s
  training loss:		0.018700
  validation loss:		0.354093
  validation accuracy:		92.83 %
Epoch 1045 of 2000 took 0.059s
  training loss:		0.018961
  validation loss:		0.354817
  validation accuracy:		92.72 %
Epoch 1046 of 2000 took 0.059s
  training loss:		0.018935
  validation loss:		0.358106
  validation accuracy:		92.83 %
Epoch 1047 of 2000 took 0.060s
  training loss:		0.018458
  validation loss:		0.349737
  validation accuracy:		92.72 %
Epoch 1048 of 2000 took 0.057s
  training loss:		0.019442
  validation loss:		0.354463
  validation accuracy:		92.28 %
Epoch 1049 of 2000 took 0.055s
  training loss:		0.018888
  validation loss:		0.366445
  validation accuracy:		92.50 %
Epoch 1050 of 2000 took 0.059s
  training loss:		0.018825
  validation loss:		0.363256
  validation accuracy:		92.07 %
Epoch 1051 of 2000 took 0.059s
  training loss:		0.019488
  validation loss:		0.366798
  validation accuracy:		92.50 %
Epoch 1052 of 2000 took 0.059s
  training loss:		0.019352
  validation loss:		0.356727
  validation accuracy:		92.93 %
Epoch 1053 of 2000 took 0.058s
  training loss:		0.018748
  validation loss:		0.349796
  validation accuracy:		92.72 %
Epoch 1054 of 2000 took 0.059s
  training loss:		0.018541
  validation loss:		0.375799
  validation accuracy:		91.96 %
Epoch 1055 of 2000 took 0.059s
  training loss:		0.018891
  validation loss:		0.363895
  validation accuracy:		92.50 %
Epoch 1056 of 2000 took 0.058s
  training loss:		0.019495
  validation loss:		0.362728
  validation accuracy:		92.39 %
Epoch 1057 of 2000 took 0.059s
  training loss:		0.018561
  validation loss:		0.355908
  validation accuracy:		92.61 %
Epoch 1058 of 2000 took 0.059s
  training loss:		0.018258
  validation loss:		0.363173
  validation accuracy:		92.72 %
Epoch 1059 of 2000 took 0.059s
  training loss:		0.018630
  validation loss:		0.353090
  validation accuracy:		92.83 %
Epoch 1060 of 2000 took 0.059s
  training loss:		0.018884
  validation loss:		0.355177
  validation accuracy:		92.61 %
Epoch 1061 of 2000 took 0.058s
  training loss:		0.018114
  validation loss:		0.349944
  validation accuracy:		92.61 %
Epoch 1062 of 2000 took 0.059s
  training loss:		0.018836
  validation loss:		0.353231
  validation accuracy:		93.04 %
Epoch 1063 of 2000 took 0.059s
  training loss:		0.018412
  validation loss:		0.355281
  validation accuracy:		92.83 %
Epoch 1064 of 2000 took 0.059s
  training loss:		0.018454
  validation loss:		0.356461
  validation accuracy:		92.83 %
Epoch 1065 of 2000 took 0.059s
  training loss:		0.018035
  validation loss:		0.353478
  validation accuracy:		92.61 %
Epoch 1066 of 2000 took 0.059s
  training loss:		0.018314
  validation loss:		0.359655
  validation accuracy:		92.72 %
Epoch 1067 of 2000 took 0.059s
  training loss:		0.018322
  validation loss:		0.358451
  validation accuracy:		92.93 %
Epoch 1068 of 2000 took 0.058s
  training loss:		0.017683
  validation loss:		0.364663
  validation accuracy:		92.72 %
Epoch 1069 of 2000 took 0.059s
  training loss:		0.019017
  validation loss:		0.351993
  validation accuracy:		92.72 %
Epoch 1070 of 2000 took 0.059s
  training loss:		0.017306
  validation loss:		0.350013
  validation accuracy:		92.72 %
Epoch 1071 of 2000 took 0.059s
  training loss:		0.017529
  validation loss:		0.364513
  validation accuracy:		92.50 %
Epoch 1072 of 2000 took 0.059s
  training loss:		0.017836
  validation loss:		0.354784
  validation accuracy:		92.83 %
Epoch 1073 of 2000 took 0.059s
  training loss:		0.017700
  validation loss:		0.358540
  validation accuracy:		92.93 %
Epoch 1074 of 2000 took 0.059s
  training loss:		0.016827
  validation loss:		0.364323
  validation accuracy:		93.26 %
Epoch 1075 of 2000 took 0.059s
  training loss:		0.018621
  validation loss:		0.362037
  validation accuracy:		92.50 %
Epoch 1076 of 2000 took 0.059s
  training loss:		0.017425
  validation loss:		0.357464
  validation accuracy:		92.39 %
Epoch 1077 of 2000 took 0.059s
  training loss:		0.017991
  validation loss:		0.362132
  validation accuracy:		93.15 %
Epoch 1078 of 2000 took 0.059s
  training loss:		0.018552
  validation loss:		0.352440
  validation accuracy:		92.83 %
Epoch 1079 of 2000 took 0.059s
  training loss:		0.017051
  validation loss:		0.359653
  validation accuracy:		92.72 %
Epoch 1080 of 2000 took 0.059s
  training loss:		0.018110
  validation loss:		0.363588
  validation accuracy:		92.93 %
Epoch 1081 of 2000 took 0.059s
  training loss:		0.017735
  validation loss:		0.368684
  validation accuracy:		92.39 %
Epoch 1082 of 2000 took 0.059s
  training loss:		0.017666
  validation loss:		0.362615
  validation accuracy:		92.50 %
Epoch 1083 of 2000 took 0.059s
  training loss:		0.017254
  validation loss:		0.369300
  validation accuracy:		92.50 %
Epoch 1084 of 2000 took 0.059s
  training loss:		0.017373
  validation loss:		0.367362
  validation accuracy:		92.50 %
Epoch 1085 of 2000 took 0.059s
  training loss:		0.017649
  validation loss:		0.370685
  validation accuracy:		92.39 %
Epoch 1086 of 2000 took 0.059s
  training loss:		0.017566
  validation loss:		0.363190
  validation accuracy:		92.61 %
Epoch 1087 of 2000 took 0.059s
  training loss:		0.017558
  validation loss:		0.359299
  validation accuracy:		92.83 %
Epoch 1088 of 2000 took 0.059s
  training loss:		0.016599
  validation loss:		0.354201
  validation accuracy:		92.83 %
Epoch 1089 of 2000 took 0.059s
  training loss:		0.016086
  validation loss:		0.375802
  validation accuracy:		92.07 %
Epoch 1090 of 2000 took 0.059s
  training loss:		0.016992
  validation loss:		0.369077
  validation accuracy:		92.83 %
Epoch 1091 of 2000 took 0.059s
  training loss:		0.017677
  validation loss:		0.365065
  validation accuracy:		93.04 %
Epoch 1092 of 2000 took 0.059s
  training loss:		0.016322
  validation loss:		0.353681
  validation accuracy:		92.83 %
Epoch 1093 of 2000 took 0.059s
  training loss:		0.017592
  validation loss:		0.374082
  validation accuracy:		92.17 %
Epoch 1094 of 2000 took 0.059s
  training loss:		0.017797
  validation loss:		0.373303
  validation accuracy:		92.93 %
Epoch 1095 of 2000 took 0.059s
  training loss:		0.017606
  validation loss:		0.371192
  validation accuracy:		92.93 %
Epoch 1096 of 2000 took 0.059s
  training loss:		0.016555
  validation loss:		0.369014
  validation accuracy:		92.39 %
Epoch 1097 of 2000 took 0.059s
  training loss:		0.017541
  validation loss:		0.374542
  validation accuracy:		92.28 %
Epoch 1098 of 2000 took 0.059s
  training loss:		0.017080
  validation loss:		0.356649
  validation accuracy:		92.83 %
Epoch 1099 of 2000 took 0.059s
  training loss:		0.016859
  validation loss:		0.374451
  validation accuracy:		92.17 %
Epoch 1100 of 2000 took 0.058s
  training loss:		0.017106
  validation loss:		0.362332
  validation accuracy:		92.61 %
Epoch 1101 of 2000 took 0.059s
  training loss:		0.016304
  validation loss:		0.370892
  validation accuracy:		92.61 %
Epoch 1102 of 2000 took 0.058s
  training loss:		0.016857
  validation loss:		0.357345
  validation accuracy:		92.72 %
Epoch 1103 of 2000 took 0.059s
  training loss:		0.015941
  validation loss:		0.366989
  validation accuracy:		92.72 %
Epoch 1104 of 2000 took 0.059s
  training loss:		0.016495
  validation loss:		0.371159
  validation accuracy:		92.72 %
Epoch 1105 of 2000 took 0.059s
  training loss:		0.017775
  validation loss:		0.372670
  validation accuracy:		92.93 %
Epoch 1106 of 2000 took 0.059s
  training loss:		0.016790
  validation loss:		0.369997
  validation accuracy:		92.50 %
Epoch 1107 of 2000 took 0.060s
  training loss:		0.016759
  validation loss:		0.372846
  validation accuracy:		92.72 %
Epoch 1108 of 2000 took 0.060s
  training loss:		0.016782
  validation loss:		0.362104
  validation accuracy:		92.72 %
Epoch 1109 of 2000 took 0.059s
  training loss:		0.015257
  validation loss:		0.372572
  validation accuracy:		92.83 %
Epoch 1110 of 2000 took 0.059s
  training loss:		0.016250
  validation loss:		0.364479
  validation accuracy:		92.93 %
Epoch 1111 of 2000 took 0.059s
  training loss:		0.016899
  validation loss:		0.367873
  validation accuracy:		93.04 %
Epoch 1112 of 2000 took 0.059s
  training loss:		0.016357
  validation loss:		0.371190
  validation accuracy:		92.39 %
Epoch 1113 of 2000 took 0.059s
  training loss:		0.016532
  validation loss:		0.365168
  validation accuracy:		92.61 %
Epoch 1114 of 2000 took 0.061s
  training loss:		0.016226
  validation loss:		0.379902
  validation accuracy:		92.72 %
Epoch 1115 of 2000 took 0.058s
  training loss:		0.015969
  validation loss:		0.367008
  validation accuracy:		92.61 %
Epoch 1116 of 2000 took 0.059s
  training loss:		0.016733
  validation loss:		0.372300
  validation accuracy:		92.72 %
Epoch 1117 of 2000 took 0.058s
  training loss:		0.015807
  validation loss:		0.376450
  validation accuracy:		92.28 %
Epoch 1118 of 2000 took 0.059s
  training loss:		0.016331
  validation loss:		0.370540
  validation accuracy:		92.61 %
Epoch 1119 of 2000 took 0.059s
  training loss:		0.016236
  validation loss:		0.367641
  validation accuracy:		92.93 %
Epoch 1120 of 2000 took 0.059s
  training loss:		0.016179
  validation loss:		0.369919
  validation accuracy:		92.50 %
Epoch 1121 of 2000 took 0.059s
  training loss:		0.016230
  validation loss:		0.376446
  validation accuracy:		92.17 %
Epoch 1122 of 2000 took 0.059s
  training loss:		0.016208
  validation loss:		0.375891
  validation accuracy:		92.50 %
Epoch 1123 of 2000 took 0.059s
  training loss:		0.016207
  validation loss:		0.381257
  validation accuracy:		92.50 %
Epoch 1124 of 2000 took 0.059s
  training loss:		0.016366
  validation loss:		0.376422
  validation accuracy:		92.93 %
Epoch 1125 of 2000 took 0.059s
  training loss:		0.015965
  validation loss:		0.370215
  validation accuracy:		92.50 %
Epoch 1126 of 2000 took 0.060s
  training loss:		0.015671
  validation loss:		0.370885
  validation accuracy:		92.61 %
Epoch 1127 of 2000 took 0.060s
  training loss:		0.015950
  validation loss:		0.368382
  validation accuracy:		92.50 %
Epoch 1128 of 2000 took 0.059s
  training loss:		0.015758
  validation loss:		0.372887
  validation accuracy:		92.72 %
Epoch 1129 of 2000 took 0.059s
  training loss:		0.015646
  validation loss:		0.373514
  validation accuracy:		92.39 %
Epoch 1130 of 2000 took 0.059s
  training loss:		0.015371
  validation loss:		0.369462
  validation accuracy:		92.61 %
Epoch 1131 of 2000 took 0.059s
  training loss:		0.015742
  validation loss:		0.375521
  validation accuracy:		92.50 %
Epoch 1132 of 2000 took 0.059s
  training loss:		0.016629
  validation loss:		0.387418
  validation accuracy:		92.50 %
Epoch 1133 of 2000 took 0.059s
  training loss:		0.016186
  validation loss:		0.384078
  validation accuracy:		92.72 %
Epoch 1134 of 2000 took 0.059s
  training loss:		0.015065
  validation loss:		0.374672
  validation accuracy:		92.50 %
Epoch 1135 of 2000 took 0.059s
  training loss:		0.015765
  validation loss:		0.376334
  validation accuracy:		92.72 %
Epoch 1136 of 2000 took 0.059s
  training loss:		0.015542
  validation loss:		0.384925
  validation accuracy:		92.17 %
Epoch 1137 of 2000 took 0.059s
  training loss:		0.014892
  validation loss:		0.377760
  validation accuracy:		92.50 %
Epoch 1138 of 2000 took 0.059s
  training loss:		0.015378
  validation loss:		0.366738
  validation accuracy:		92.72 %
Epoch 1139 of 2000 took 0.059s
  training loss:		0.015547
  validation loss:		0.368660
  validation accuracy:		93.04 %
Epoch 1140 of 2000 took 0.059s
  training loss:		0.015783
  validation loss:		0.379798
  validation accuracy:		92.72 %
Epoch 1141 of 2000 took 0.059s
  training loss:		0.015711
  validation loss:		0.384489
  validation accuracy:		92.61 %
Epoch 1142 of 2000 took 0.059s
  training loss:		0.015667
  validation loss:		0.377714
  validation accuracy:		92.50 %
Epoch 1143 of 2000 took 0.059s
  training loss:		0.015778
  validation loss:		0.376792
  validation accuracy:		92.61 %
Epoch 1144 of 2000 took 0.059s
  training loss:		0.014440
  validation loss:		0.385737
  validation accuracy:		92.39 %
Epoch 1145 of 2000 took 0.059s
  training loss:		0.015290
  validation loss:		0.379138
  validation accuracy:		92.83 %
Epoch 1146 of 2000 took 0.059s
  training loss:		0.014936
  validation loss:		0.377231
  validation accuracy:		92.83 %
Epoch 1147 of 2000 took 0.059s
  training loss:		0.015784
  validation loss:		0.378748
  validation accuracy:		92.93 %
Epoch 1148 of 2000 took 0.059s
  training loss:		0.015150
  validation loss:		0.374183
  validation accuracy:		92.83 %
Epoch 1149 of 2000 took 0.059s
  training loss:		0.015823
  validation loss:		0.379826
  validation accuracy:		92.72 %
Epoch 1150 of 2000 took 0.059s
  training loss:		0.014817
  validation loss:		0.386657
  validation accuracy:		92.83 %
Epoch 1151 of 2000 took 0.059s
  training loss:		0.015460
  validation loss:		0.378155
  validation accuracy:		92.72 %
Epoch 1152 of 2000 took 0.059s
  training loss:		0.015270
  validation loss:		0.383667
  validation accuracy:		92.17 %
Epoch 1153 of 2000 took 0.059s
  training loss:		0.014612
  validation loss:		0.389026
  validation accuracy:		92.50 %
Epoch 1154 of 2000 took 0.059s
  training loss:		0.014857
  validation loss:		0.375249
  validation accuracy:		92.83 %
Epoch 1155 of 2000 took 0.059s
  training loss:		0.014706
  validation loss:		0.392162
  validation accuracy:		92.28 %
Epoch 1156 of 2000 took 0.059s
  training loss:		0.014828
  validation loss:		0.380591
  validation accuracy:		92.72 %
Epoch 1157 of 2000 took 0.059s
  training loss:		0.014352
  validation loss:		0.392546
  validation accuracy:		92.17 %
Epoch 1158 of 2000 took 0.059s
  training loss:		0.015148
  validation loss:		0.385527
  validation accuracy:		92.83 %
Epoch 1159 of 2000 took 0.059s
  training loss:		0.014177
  validation loss:		0.379728
  validation accuracy:		92.50 %
Epoch 1160 of 2000 took 0.059s
  training loss:		0.014686
  validation loss:		0.381736
  validation accuracy:		92.83 %
Epoch 1161 of 2000 took 0.059s
  training loss:		0.013991
  validation loss:		0.380048
  validation accuracy:		92.50 %
Epoch 1162 of 2000 took 0.059s
  training loss:		0.014430
  validation loss:		0.387614
  validation accuracy:		92.28 %
Epoch 1163 of 2000 took 0.059s
  training loss:		0.014443
  validation loss:		0.379775
  validation accuracy:		92.61 %
Epoch 1164 of 2000 took 0.059s
  training loss:		0.014143
  validation loss:		0.386863
  validation accuracy:		92.39 %
Epoch 1165 of 2000 took 0.059s
  training loss:		0.015162
  validation loss:		0.382181
  validation accuracy:		92.61 %
Epoch 1166 of 2000 took 0.059s
  training loss:		0.014271
  validation loss:		0.388392
  validation accuracy:		92.39 %
Epoch 1167 of 2000 took 0.059s
  training loss:		0.015205
  validation loss:		0.381901
  validation accuracy:		92.83 %
Epoch 1168 of 2000 took 0.059s
  training loss:		0.014218
  validation loss:		0.385818
  validation accuracy:		92.50 %
Epoch 1169 of 2000 took 0.059s
  training loss:		0.014654
  validation loss:		0.378456
  validation accuracy:		92.83 %
Epoch 1170 of 2000 took 0.059s
  training loss:		0.014646
  validation loss:		0.378773
  validation accuracy:		92.83 %
Epoch 1171 of 2000 took 0.059s
  training loss:		0.014348
  validation loss:		0.388723
  validation accuracy:		92.61 %
Epoch 1172 of 2000 took 0.059s
  training loss:		0.014678
  validation loss:		0.383326
  validation accuracy:		93.04 %
Epoch 1173 of 2000 took 0.058s
  training loss:		0.014869
  validation loss:		0.392375
  validation accuracy:		92.72 %
Epoch 1174 of 2000 took 0.059s
  training loss:		0.013865
  validation loss:		0.389564
  validation accuracy:		92.28 %
Epoch 1175 of 2000 took 0.059s
  training loss:		0.014240
  validation loss:		0.387053
  validation accuracy:		92.93 %
Epoch 1176 of 2000 took 0.059s
  training loss:		0.013933
  validation loss:		0.385686
  validation accuracy:		92.61 %
Epoch 1177 of 2000 took 0.059s
  training loss:		0.014012
  validation loss:		0.379225
  validation accuracy:		92.39 %
Epoch 1178 of 2000 took 0.059s
  training loss:		0.014214
  validation loss:		0.394494
  validation accuracy:		92.07 %
Epoch 1179 of 2000 took 0.059s
  training loss:		0.014256
  validation loss:		0.389856
  validation accuracy:		92.50 %
Epoch 1180 of 2000 took 0.059s
  training loss:		0.014168
  validation loss:		0.382928
  validation accuracy:		92.83 %
Epoch 1181 of 2000 took 0.059s
  training loss:		0.014359
  validation loss:		0.380585
  validation accuracy:		92.72 %
Epoch 1182 of 2000 took 0.059s
  training loss:		0.014433
  validation loss:		0.388445
  validation accuracy:		92.17 %
Epoch 1183 of 2000 took 0.059s
  training loss:		0.014342
  validation loss:		0.396341
  validation accuracy:		92.61 %
Epoch 1184 of 2000 took 0.059s
  training loss:		0.014086
  validation loss:		0.379305
  validation accuracy:		92.93 %
Epoch 1185 of 2000 took 0.059s
  training loss:		0.014179
  validation loss:		0.392518
  validation accuracy:		92.39 %
Epoch 1186 of 2000 took 0.059s
  training loss:		0.013947
  validation loss:		0.388929
  validation accuracy:		92.28 %
Epoch 1187 of 2000 took 0.059s
  training loss:		0.013979
  validation loss:		0.384973
  validation accuracy:		92.50 %
Epoch 1188 of 2000 took 0.059s
  training loss:		0.013797
  validation loss:		0.387163
  validation accuracy:		92.61 %
Epoch 1189 of 2000 took 0.059s
  training loss:		0.012866
  validation loss:		0.387249
  validation accuracy:		92.61 %
Epoch 1190 of 2000 took 0.059s
  training loss:		0.013868
  validation loss:		0.389066
  validation accuracy:		92.50 %
Epoch 1191 of 2000 took 0.059s
  training loss:		0.013624
  validation loss:		0.386110
  validation accuracy:		92.61 %
Epoch 1192 of 2000 took 0.059s
  training loss:		0.013849
  validation loss:		0.388453
  validation accuracy:		92.39 %
Epoch 1193 of 2000 took 0.059s
  training loss:		0.013429
  validation loss:		0.388005
  validation accuracy:		92.72 %
Epoch 1194 of 2000 took 0.059s
  training loss:		0.013165
  validation loss:		0.389383
  validation accuracy:		92.93 %
Epoch 1195 of 2000 took 0.059s
  training loss:		0.014289
  validation loss:		0.386005
  validation accuracy:		92.72 %
Epoch 1196 of 2000 took 0.059s
  training loss:		0.014156
  validation loss:		0.399033
  validation accuracy:		92.39 %
Epoch 1197 of 2000 took 0.058s
  training loss:		0.013784
  validation loss:		0.392574
  validation accuracy:		92.72 %
Epoch 1198 of 2000 took 0.059s
  training loss:		0.013659
  validation loss:		0.387815
  validation accuracy:		92.93 %
Epoch 1199 of 2000 took 0.059s
  training loss:		0.013791
  validation loss:		0.396429
  validation accuracy:		92.39 %
Epoch 1200 of 2000 took 0.059s
  training loss:		0.014133
  validation loss:		0.395043
  validation accuracy:		92.39 %
Epoch 1201 of 2000 took 0.059s
  training loss:		0.013444
  validation loss:		0.394134
  validation accuracy:		92.50 %
Epoch 1202 of 2000 took 0.059s
  training loss:		0.013240
  validation loss:		0.391493
  validation accuracy:		92.61 %
Epoch 1203 of 2000 took 0.059s
  training loss:		0.013488
  validation loss:		0.396560
  validation accuracy:		92.72 %
Epoch 1204 of 2000 took 0.059s
  training loss:		0.013498
  validation loss:		0.390707
  validation accuracy:		92.61 %
Epoch 1205 of 2000 took 0.059s
  training loss:		0.013248
  validation loss:		0.384270
  validation accuracy:		92.72 %
Epoch 1206 of 2000 took 0.059s
  training loss:		0.013056
  validation loss:		0.397038
  validation accuracy:		92.50 %
Epoch 1207 of 2000 took 0.059s
  training loss:		0.013243
  validation loss:		0.389335
  validation accuracy:		92.93 %
Epoch 1208 of 2000 took 0.059s
  training loss:		0.013436
  validation loss:		0.392865
  validation accuracy:		92.61 %
Epoch 1209 of 2000 took 0.059s
  training loss:		0.012653
  validation loss:		0.396235
  validation accuracy:		92.72 %
Epoch 1210 of 2000 took 0.059s
  training loss:		0.012806
  validation loss:		0.389491
  validation accuracy:		92.61 %
Epoch 1211 of 2000 took 0.059s
  training loss:		0.012981
  validation loss:		0.401915
  validation accuracy:		92.28 %
Epoch 1212 of 2000 took 0.059s
  training loss:		0.013316
  validation loss:		0.394083
  validation accuracy:		92.50 %
Epoch 1213 of 2000 took 0.059s
  training loss:		0.012634
  validation loss:		0.392237
  validation accuracy:		92.50 %
Epoch 1214 of 2000 took 0.059s
  training loss:		0.012930
  validation loss:		0.394096
  validation accuracy:		92.39 %
Epoch 1215 of 2000 took 0.059s
  training loss:		0.012829
  validation loss:		0.391094
  validation accuracy:		92.72 %
Epoch 1216 of 2000 took 0.059s
  training loss:		0.013492
  validation loss:		0.401076
  validation accuracy:		92.50 %
Epoch 1217 of 2000 took 0.058s
  training loss:		0.012573
  validation loss:		0.391971
  validation accuracy:		92.83 %
Epoch 1218 of 2000 took 0.059s
  training loss:		0.012442
  validation loss:		0.397683
  validation accuracy:		92.93 %
Epoch 1219 of 2000 took 0.059s
  training loss:		0.012831
  validation loss:		0.393016
  validation accuracy:		92.61 %
Epoch 1220 of 2000 took 0.059s
  training loss:		0.012821
  validation loss:		0.400228
  validation accuracy:		92.50 %
Epoch 1221 of 2000 took 0.059s
  training loss:		0.012798
  validation loss:		0.406336
  validation accuracy:		92.28 %
Epoch 1222 of 2000 took 0.059s
  training loss:		0.012717
  validation loss:		0.398721
  validation accuracy:		92.50 %
Epoch 1223 of 2000 took 0.059s
  training loss:		0.012853
  validation loss:		0.391732
  validation accuracy:		92.83 %
Epoch 1224 of 2000 took 0.059s
  training loss:		0.013351
  validation loss:		0.393334
  validation accuracy:		92.72 %
Epoch 1225 of 2000 took 0.059s
  training loss:		0.012975
  validation loss:		0.395927
  validation accuracy:		92.39 %
Epoch 1226 of 2000 took 0.059s
  training loss:		0.012554
  validation loss:		0.405297
  validation accuracy:		92.50 %
Epoch 1227 of 2000 took 0.059s
  training loss:		0.012621
  validation loss:		0.397128
  validation accuracy:		92.39 %
Epoch 1228 of 2000 took 0.060s
  training loss:		0.012574
  validation loss:		0.397113
  validation accuracy:		92.72 %
Epoch 1229 of 2000 took 0.058s
  training loss:		0.013159
  validation loss:		0.407600
  validation accuracy:		92.28 %
Epoch 1230 of 2000 took 0.059s
  training loss:		0.013000
  validation loss:		0.401330
  validation accuracy:		92.39 %
Epoch 1231 of 2000 took 0.060s
  training loss:		0.012712
  validation loss:		0.389922
  validation accuracy:		92.83 %
Epoch 1232 of 2000 took 0.059s
  training loss:		0.012632
  validation loss:		0.404454
  validation accuracy:		92.50 %
Epoch 1233 of 2000 took 0.060s
  training loss:		0.012467
  validation loss:		0.400790
  validation accuracy:		92.50 %
Epoch 1234 of 2000 took 0.059s
  training loss:		0.012612
  validation loss:		0.400493
  validation accuracy:		92.61 %
Epoch 1235 of 2000 took 0.059s
  training loss:		0.012483
  validation loss:		0.392438
  validation accuracy:		92.50 %
Epoch 1236 of 2000 took 0.059s
  training loss:		0.012725
  validation loss:		0.398364
  validation accuracy:		92.61 %
Epoch 1237 of 2000 took 0.059s
  training loss:		0.012302
  validation loss:		0.397286
  validation accuracy:		92.61 %
Epoch 1238 of 2000 took 0.059s
  training loss:		0.012063
  validation loss:		0.410792
  validation accuracy:		92.39 %
Epoch 1239 of 2000 took 0.059s
  training loss:		0.011969
  validation loss:		0.395689
  validation accuracy:		92.39 %
Epoch 1240 of 2000 took 0.058s
  training loss:		0.012607
  validation loss:		0.397873
  validation accuracy:		92.61 %
Epoch 1241 of 2000 took 0.059s
  training loss:		0.012368
  validation loss:		0.394321
  validation accuracy:		92.72 %
Epoch 1242 of 2000 took 0.059s
  training loss:		0.011809
  validation loss:		0.401264
  validation accuracy:		92.61 %
Epoch 1243 of 2000 took 0.059s
  training loss:		0.012952
  validation loss:		0.393894
  validation accuracy:		92.83 %
Epoch 1244 of 2000 took 0.059s
  training loss:		0.012676
  validation loss:		0.408108
  validation accuracy:		92.28 %
Epoch 1245 of 2000 took 0.060s
  training loss:		0.011879
  validation loss:		0.408987
  validation accuracy:		92.39 %
Epoch 1246 of 2000 took 0.060s
  training loss:		0.012339
  validation loss:		0.401098
  validation accuracy:		92.50 %
Epoch 1247 of 2000 took 0.060s
  training loss:		0.012593
  validation loss:		0.403452
  validation accuracy:		92.61 %
Epoch 1248 of 2000 took 0.060s
  training loss:		0.012836
  validation loss:		0.395482
  validation accuracy:		92.72 %
Epoch 1249 of 2000 took 0.059s
  training loss:		0.011324
  validation loss:		0.406021
  validation accuracy:		92.72 %
Epoch 1250 of 2000 took 0.059s
  training loss:		0.012154
  validation loss:		0.398031
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.059s
  training loss:		0.012024
  validation loss:		0.400565
  validation accuracy:		92.61 %
Epoch 1252 of 2000 took 0.059s
  training loss:		0.012270
  validation loss:		0.400147
  validation accuracy:		92.61 %
Epoch 1253 of 2000 took 0.059s
  training loss:		0.012038
  validation loss:		0.399974
  validation accuracy:		92.61 %
Epoch 1254 of 2000 took 0.059s
  training loss:		0.012403
  validation loss:		0.413886
  validation accuracy:		92.17 %
Epoch 1255 of 2000 took 0.059s
  training loss:		0.011888
  validation loss:		0.409620
  validation accuracy:		92.39 %
Epoch 1256 of 2000 took 0.059s
  training loss:		0.012080
  validation loss:		0.404124
  validation accuracy:		92.28 %
Epoch 1257 of 2000 took 0.059s
  training loss:		0.012199
  validation loss:		0.402600
  validation accuracy:		92.83 %
Epoch 1258 of 2000 took 0.059s
  training loss:		0.011715
  validation loss:		0.407609
  validation accuracy:		92.28 %
Epoch 1259 of 2000 took 0.059s
  training loss:		0.011637
  validation loss:		0.403838
  validation accuracy:		92.50 %
Epoch 1260 of 2000 took 0.059s
  training loss:		0.011590
  validation loss:		0.394506
  validation accuracy:		92.93 %
Epoch 1261 of 2000 took 0.059s
  training loss:		0.012144
  validation loss:		0.402359
  validation accuracy:		92.72 %
Epoch 1262 of 2000 took 0.059s
  training loss:		0.011875
  validation loss:		0.406680
  validation accuracy:		92.93 %
Epoch 1263 of 2000 took 0.060s
  training loss:		0.011722
  validation loss:		0.406080
  validation accuracy:		92.28 %
Epoch 1264 of 2000 took 0.059s
  training loss:		0.011883
  validation loss:		0.403059
  validation accuracy:		92.50 %
Epoch 1265 of 2000 took 0.059s
  training loss:		0.011652
  validation loss:		0.407011
  validation accuracy:		92.50 %
Epoch 1266 of 2000 took 0.059s
  training loss:		0.011620
  validation loss:		0.414534
  validation accuracy:		92.39 %
Epoch 1267 of 2000 took 0.059s
  training loss:		0.011922
  validation loss:		0.412021
  validation accuracy:		92.61 %
Epoch 1268 of 2000 took 0.059s
  training loss:		0.011520
  validation loss:		0.408525
  validation accuracy:		92.83 %
Epoch 1269 of 2000 took 0.060s
  training loss:		0.011957
  validation loss:		0.404540
  validation accuracy:		92.72 %
Epoch 1270 of 2000 took 0.059s
  training loss:		0.011730
  validation loss:		0.406572
  validation accuracy:		92.72 %
Epoch 1271 of 2000 took 0.060s
  training loss:		0.011180
  validation loss:		0.410732
  validation accuracy:		92.39 %
Epoch 1272 of 2000 took 0.059s
  training loss:		0.011245
  validation loss:		0.403848
  validation accuracy:		92.39 %
Epoch 1273 of 2000 took 0.059s
  training loss:		0.011267
  validation loss:		0.403788
  validation accuracy:		92.72 %
Epoch 1274 of 2000 took 0.059s
  training loss:		0.011104
  validation loss:		0.398951
  validation accuracy:		92.50 %
Epoch 1275 of 2000 took 0.059s
  training loss:		0.011230
  validation loss:		0.406310
  validation accuracy:		92.50 %
Epoch 1276 of 2000 took 0.059s
  training loss:		0.011989
  validation loss:		0.409442
  validation accuracy:		92.39 %
Epoch 1277 of 2000 took 0.059s
  training loss:		0.011315
  validation loss:		0.412176
  validation accuracy:		92.28 %
Epoch 1278 of 2000 took 0.059s
  training loss:		0.011239
  validation loss:		0.406688
  validation accuracy:		92.61 %
Epoch 1279 of 2000 took 0.059s
  training loss:		0.010720
  validation loss:		0.402467
  validation accuracy:		92.61 %
Epoch 1280 of 2000 took 0.059s
  training loss:		0.011436
  validation loss:		0.402945
  validation accuracy:		92.72 %
Epoch 1281 of 2000 took 0.058s
  training loss:		0.011408
  validation loss:		0.413038
  validation accuracy:		92.39 %
Epoch 1282 of 2000 took 0.059s
  training loss:		0.011324
  validation loss:		0.413949
  validation accuracy:		92.39 %
Epoch 1283 of 2000 took 0.059s
  training loss:		0.011687
  validation loss:		0.411168
  validation accuracy:		92.50 %
Epoch 1284 of 2000 took 0.059s
  training loss:		0.011273
  validation loss:		0.400492
  validation accuracy:		92.83 %
Epoch 1285 of 2000 took 0.059s
  training loss:		0.011977
  validation loss:		0.406270
  validation accuracy:		92.61 %
Epoch 1286 of 2000 took 0.059s
  training loss:		0.010708
  validation loss:		0.410999
  validation accuracy:		92.83 %
Epoch 1287 of 2000 took 0.059s
  training loss:		0.011440
  validation loss:		0.409377
  validation accuracy:		92.50 %
Epoch 1288 of 2000 took 0.059s
  training loss:		0.011532
  validation loss:		0.412228
  validation accuracy:		92.72 %
Epoch 1289 of 2000 took 0.059s
  training loss:		0.011267
  validation loss:		0.410300
  validation accuracy:		92.50 %
Epoch 1290 of 2000 took 0.059s
  training loss:		0.010989
  validation loss:		0.412625
  validation accuracy:		92.61 %
Epoch 1291 of 2000 took 0.059s
  training loss:		0.011250
  validation loss:		0.411822
  validation accuracy:		92.72 %
Epoch 1292 of 2000 took 0.059s
  training loss:		0.011319
  validation loss:		0.415031
  validation accuracy:		92.39 %
Epoch 1293 of 2000 took 0.059s
  training loss:		0.011000
  validation loss:		0.422358
  validation accuracy:		92.39 %
Epoch 1294 of 2000 took 0.059s
  training loss:		0.011292
  validation loss:		0.414704
  validation accuracy:		92.50 %
Epoch 1295 of 2000 took 0.059s
  training loss:		0.010955
  validation loss:		0.404015
  validation accuracy:		92.61 %
Epoch 1296 of 2000 took 0.059s
  training loss:		0.011348
  validation loss:		0.409005
  validation accuracy:		92.61 %
Epoch 1297 of 2000 took 0.059s
  training loss:		0.010844
  validation loss:		0.414446
  validation accuracy:		92.72 %
Epoch 1298 of 2000 took 0.059s
  training loss:		0.011264
  validation loss:		0.411344
  validation accuracy:		92.50 %
Epoch 1299 of 2000 took 0.059s
  training loss:		0.010757
  validation loss:		0.415008
  validation accuracy:		92.39 %
Epoch 1300 of 2000 took 0.059s
  training loss:		0.010844
  validation loss:		0.417777
  validation accuracy:		92.39 %
Epoch 1301 of 2000 took 0.059s
  training loss:		0.010911
  validation loss:		0.409932
  validation accuracy:		92.50 %
Epoch 1302 of 2000 took 0.059s
  training loss:		0.011419
  validation loss:		0.404087
  validation accuracy:		92.61 %
Epoch 1303 of 2000 took 0.059s
  training loss:		0.011247
  validation loss:		0.420274
  validation accuracy:		92.39 %
Epoch 1304 of 2000 took 0.059s
  training loss:		0.010592
  validation loss:		0.413614
  validation accuracy:		92.93 %
Epoch 1305 of 2000 took 0.059s
  training loss:		0.010946
  validation loss:		0.414685
  validation accuracy:		92.28 %
Epoch 1306 of 2000 took 0.059s
  training loss:		0.010328
  validation loss:		0.413046
  validation accuracy:		92.50 %
Epoch 1307 of 2000 took 0.059s
  training loss:		0.010631
  validation loss:		0.420222
  validation accuracy:		92.17 %
Epoch 1308 of 2000 took 0.059s
  training loss:		0.010774
  validation loss:		0.417089
  validation accuracy:		92.61 %
Epoch 1309 of 2000 took 0.059s
  training loss:		0.010897
  validation loss:		0.410863
  validation accuracy:		92.61 %
Epoch 1310 of 2000 took 0.059s
  training loss:		0.010671
  validation loss:		0.424457
  validation accuracy:		92.17 %
Epoch 1311 of 2000 took 0.059s
  training loss:		0.010928
  validation loss:		0.410372
  validation accuracy:		92.83 %
Epoch 1312 of 2000 took 0.059s
  training loss:		0.010781
  validation loss:		0.416826
  validation accuracy:		92.17 %
Epoch 1313 of 2000 took 0.058s
  training loss:		0.010419
  validation loss:		0.421028
  validation accuracy:		92.39 %
Epoch 1314 of 2000 took 0.059s
  training loss:		0.010949
  validation loss:		0.425363
  validation accuracy:		92.28 %
Epoch 1315 of 2000 took 0.058s
  training loss:		0.010357
  validation loss:		0.416346
  validation accuracy:		92.50 %
Epoch 1316 of 2000 took 0.059s
  training loss:		0.010544
  validation loss:		0.415684
  validation accuracy:		92.61 %
Epoch 1317 of 2000 took 0.059s
  training loss:		0.010449
  validation loss:		0.418798
  validation accuracy:		92.39 %
Epoch 1318 of 2000 took 0.059s
  training loss:		0.010398
  validation loss:		0.411530
  validation accuracy:		92.50 %
Epoch 1319 of 2000 took 0.059s
  training loss:		0.010542
  validation loss:		0.425231
  validation accuracy:		92.72 %
Epoch 1320 of 2000 took 0.059s
  training loss:		0.009965
  validation loss:		0.422680
  validation accuracy:		92.50 %
Epoch 1321 of 2000 took 0.059s
  training loss:		0.010305
  validation loss:		0.422026
  validation accuracy:		92.28 %
Epoch 1322 of 2000 took 0.059s
  training loss:		0.010543
  validation loss:		0.417180
  validation accuracy:		92.72 %
Epoch 1323 of 2000 took 0.059s
  training loss:		0.010469
  validation loss:		0.414420
  validation accuracy:		92.61 %
Epoch 1324 of 2000 took 0.059s
  training loss:		0.010360
  validation loss:		0.435041
  validation accuracy:		92.61 %
Epoch 1325 of 2000 took 0.059s
  training loss:		0.010718
  validation loss:		0.418167
  validation accuracy:		92.83 %
Epoch 1326 of 2000 took 0.058s
  training loss:		0.010427
  validation loss:		0.416140
  validation accuracy:		92.72 %
Epoch 1327 of 2000 took 0.059s
  training loss:		0.010182
  validation loss:		0.414905
  validation accuracy:		92.61 %
Epoch 1328 of 2000 took 0.059s
  training loss:		0.010467
  validation loss:		0.415960
  validation accuracy:		92.93 %
Epoch 1329 of 2000 took 0.059s
  training loss:		0.010145
  validation loss:		0.419139
  validation accuracy:		92.61 %
Epoch 1330 of 2000 took 0.059s
  training loss:		0.009577
  validation loss:		0.421249
  validation accuracy:		92.39 %
Epoch 1331 of 2000 took 0.058s
  training loss:		0.010620
  validation loss:		0.418565
  validation accuracy:		92.61 %
Epoch 1332 of 2000 took 0.058s
  training loss:		0.010188
  validation loss:		0.420008
  validation accuracy:		92.50 %
Epoch 1333 of 2000 took 0.058s
  training loss:		0.010195
  validation loss:		0.424750
  validation accuracy:		92.28 %
Epoch 1334 of 2000 took 0.058s
  training loss:		0.009859
  validation loss:		0.430925
  validation accuracy:		92.39 %
Epoch 1335 of 2000 took 0.056s
  training loss:		0.010543
  validation loss:		0.428104
  validation accuracy:		92.07 %
Epoch 1336 of 2000 took 0.059s
  training loss:		0.010311
  validation loss:		0.425318
  validation accuracy:		92.39 %
Epoch 1337 of 2000 took 0.057s
  training loss:		0.009822
  validation loss:		0.425756
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.057s
  training loss:		0.009932
  validation loss:		0.416801
  validation accuracy:		92.39 %
Epoch 1339 of 2000 took 0.056s
  training loss:		0.010283
  validation loss:		0.415721
  validation accuracy:		92.50 %
Epoch 1340 of 2000 took 0.057s
  training loss:		0.010125
  validation loss:		0.416475
  validation accuracy:		92.61 %
Epoch 1341 of 2000 took 0.056s
  training loss:		0.009605
  validation loss:		0.423038
  validation accuracy:		92.28 %
Epoch 1342 of 2000 took 0.056s
  training loss:		0.009528
  validation loss:		0.424157
  validation accuracy:		92.39 %
Epoch 1343 of 2000 took 0.060s
  training loss:		0.009235
  validation loss:		0.431500
  validation accuracy:		92.17 %
Epoch 1344 of 2000 took 0.057s
  training loss:		0.010145
  validation loss:		0.423096
  validation accuracy:		92.50 %
Epoch 1345 of 2000 took 0.059s
  training loss:		0.010113
  validation loss:		0.418415
  validation accuracy:		92.83 %
Epoch 1346 of 2000 took 0.058s
  training loss:		0.009948
  validation loss:		0.422696
  validation accuracy:		92.50 %
Epoch 1347 of 2000 took 0.059s
  training loss:		0.009803
  validation loss:		0.425834
  validation accuracy:		92.39 %
Epoch 1348 of 2000 took 0.058s
  training loss:		0.009911
  validation loss:		0.423657
  validation accuracy:		92.28 %
Epoch 1349 of 2000 took 0.058s
  training loss:		0.009433
  validation loss:		0.427028
  validation accuracy:		92.50 %
Epoch 1350 of 2000 took 0.057s
  training loss:		0.009612
  validation loss:		0.426603
  validation accuracy:		92.39 %
Epoch 1351 of 2000 took 0.058s
  training loss:		0.009978
  validation loss:		0.420413
  validation accuracy:		92.61 %
Epoch 1352 of 2000 took 0.059s
  training loss:		0.010084
  validation loss:		0.425742
  validation accuracy:		92.72 %
Epoch 1353 of 2000 took 0.058s
  training loss:		0.009695
  validation loss:		0.427537
  validation accuracy:		92.93 %
Epoch 1354 of 2000 took 0.058s
  training loss:		0.009192
  validation loss:		0.421256
  validation accuracy:		92.28 %
Epoch 1355 of 2000 took 0.058s
  training loss:		0.009666
  validation loss:		0.432929
  validation accuracy:		92.50 %
Epoch 1356 of 2000 took 0.057s
  training loss:		0.009723
  validation loss:		0.420915
  validation accuracy:		92.39 %
Epoch 1357 of 2000 took 0.056s
  training loss:		0.009683
  validation loss:		0.422216
  validation accuracy:		92.72 %
Epoch 1358 of 2000 took 0.059s
  training loss:		0.009306
  validation loss:		0.424253
  validation accuracy:		92.39 %
Epoch 1359 of 2000 took 0.059s
  training loss:		0.009759
  validation loss:		0.428338
  validation accuracy:		92.28 %
Epoch 1360 of 2000 took 0.058s
  training loss:		0.009583
  validation loss:		0.424436
  validation accuracy:		92.50 %
Epoch 1361 of 2000 took 0.058s
  training loss:		0.009593
  validation loss:		0.424578
  validation accuracy:		92.61 %
Epoch 1362 of 2000 took 0.058s
  training loss:		0.009827
  validation loss:		0.427526
  validation accuracy:		92.28 %
Epoch 1363 of 2000 took 0.057s
  training loss:		0.009563
  validation loss:		0.428328
  validation accuracy:		92.50 %
Epoch 1364 of 2000 took 0.058s
  training loss:		0.009358
  validation loss:		0.426434
  validation accuracy:		92.28 %
Epoch 1365 of 2000 took 0.058s
  training loss:		0.009856
  validation loss:		0.423212
  validation accuracy:		92.28 %
Epoch 1366 of 2000 took 0.059s
  training loss:		0.009608
  validation loss:		0.423014
  validation accuracy:		92.72 %
Epoch 1367 of 2000 took 0.058s
  training loss:		0.009509
  validation loss:		0.431206
  validation accuracy:		92.50 %
Epoch 1368 of 2000 took 0.059s
  training loss:		0.009584
  validation loss:		0.435265
  validation accuracy:		92.39 %
Epoch 1369 of 2000 took 0.059s
  training loss:		0.009486
  validation loss:		0.429134
  validation accuracy:		92.61 %
Epoch 1370 of 2000 took 0.058s
  training loss:		0.009573
  validation loss:		0.424480
  validation accuracy:		92.61 %
Epoch 1371 of 2000 took 0.058s
  training loss:		0.009375
  validation loss:		0.429209
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.057s
  training loss:		0.009307
  validation loss:		0.430928
  validation accuracy:		92.28 %
Epoch 1373 of 2000 took 0.058s
  training loss:		0.009248
  validation loss:		0.436044
  validation accuracy:		92.17 %
Epoch 1374 of 2000 took 0.059s
  training loss:		0.009575
  validation loss:		0.430065
  validation accuracy:		92.50 %
Epoch 1375 of 2000 took 0.057s
  training loss:		0.009332
  validation loss:		0.428941
  validation accuracy:		92.61 %
Epoch 1376 of 2000 took 0.057s
  training loss:		0.008821
  validation loss:		0.431321
  validation accuracy:		92.39 %
Epoch 1377 of 2000 took 0.058s
  training loss:		0.009317
  validation loss:		0.432264
  validation accuracy:		92.39 %
Epoch 1378 of 2000 took 0.058s
  training loss:		0.009386
  validation loss:		0.434087
  validation accuracy:		92.28 %
Epoch 1379 of 2000 took 0.059s
  training loss:		0.009049
  validation loss:		0.432524
  validation accuracy:		92.39 %
Epoch 1380 of 2000 took 0.058s
  training loss:		0.009421
  validation loss:		0.429772
  validation accuracy:		92.28 %
Epoch 1381 of 2000 took 0.058s
  training loss:		0.009102
  validation loss:		0.436397
  validation accuracy:		92.39 %
Epoch 1382 of 2000 took 0.059s
  training loss:		0.009313
  validation loss:		0.428563
  validation accuracy:		92.39 %
Epoch 1383 of 2000 took 0.058s
  training loss:		0.009252
  validation loss:		0.437090
  validation accuracy:		92.07 %
Epoch 1384 of 2000 took 0.058s
  training loss:		0.009402
  validation loss:		0.436034
  validation accuracy:		92.39 %
Epoch 1385 of 2000 took 0.058s
  training loss:		0.009020
  validation loss:		0.430683
  validation accuracy:		92.50 %
Epoch 1386 of 2000 took 0.058s
  training loss:		0.009237
  validation loss:		0.433640
  validation accuracy:		92.17 %
Epoch 1387 of 2000 took 0.058s
  training loss:		0.009081
  validation loss:		0.433335
  validation accuracy:		92.50 %
Epoch 1388 of 2000 took 0.058s
  training loss:		0.008971
  validation loss:		0.438431
  validation accuracy:		92.28 %
Epoch 1389 of 2000 took 0.058s
  training loss:		0.009292
  validation loss:		0.444638
  validation accuracy:		92.28 %
Epoch 1390 of 2000 took 0.059s
  training loss:		0.009044
  validation loss:		0.435224
  validation accuracy:		92.83 %
Epoch 1391 of 2000 took 0.058s
  training loss:		0.008915
  validation loss:		0.432870
  validation accuracy:		92.39 %
Epoch 1392 of 2000 took 0.059s
  training loss:		0.008545
  validation loss:		0.435949
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.059s
  training loss:		0.009175
  validation loss:		0.441582
  validation accuracy:		92.28 %
Epoch 1394 of 2000 took 0.058s
  training loss:		0.008964
  validation loss:		0.433260
  validation accuracy:		92.61 %
Epoch 1395 of 2000 took 0.058s
  training loss:		0.008908
  validation loss:		0.440068
  validation accuracy:		92.28 %
Epoch 1396 of 2000 took 0.058s
  training loss:		0.009222
  validation loss:		0.433000
  validation accuracy:		92.50 %
Epoch 1397 of 2000 took 0.059s
  training loss:		0.008887
  validation loss:		0.436504
  validation accuracy:		92.93 %
Epoch 1398 of 2000 took 0.059s
  training loss:		0.008970
  validation loss:		0.441994
  validation accuracy:		92.28 %
Epoch 1399 of 2000 took 0.058s
  training loss:		0.008977
  validation loss:		0.435960
  validation accuracy:		92.50 %
Epoch 1400 of 2000 took 0.059s
  training loss:		0.008776
  validation loss:		0.432737
  validation accuracy:		92.39 %
Epoch 1401 of 2000 took 0.059s
  training loss:		0.008895
  validation loss:		0.443852
  validation accuracy:		92.28 %
Epoch 1402 of 2000 took 0.058s
  training loss:		0.009197
  validation loss:		0.434813
  validation accuracy:		92.28 %
Epoch 1403 of 2000 took 0.058s
  training loss:		0.008886
  validation loss:		0.435460
  validation accuracy:		92.72 %
Epoch 1404 of 2000 took 0.059s
  training loss:		0.008967
  validation loss:		0.438986
  validation accuracy:		92.28 %
Epoch 1405 of 2000 took 0.059s
  training loss:		0.009089
  validation loss:		0.438443
  validation accuracy:		92.39 %
Epoch 1406 of 2000 took 0.059s
  training loss:		0.009009
  validation loss:		0.432015
  validation accuracy:		92.28 %
Epoch 1407 of 2000 took 0.059s
  training loss:		0.008917
  validation loss:		0.444392
  validation accuracy:		92.17 %
Epoch 1408 of 2000 took 0.059s
  training loss:		0.008714
  validation loss:		0.433114
  validation accuracy:		92.39 %
Epoch 1409 of 2000 took 0.059s
  training loss:		0.008675
  validation loss:		0.436591
  validation accuracy:		92.72 %
Epoch 1410 of 2000 took 0.059s
  training loss:		0.008970
  validation loss:		0.442737
  validation accuracy:		92.28 %
Epoch 1411 of 2000 took 0.058s
  training loss:		0.008466
  validation loss:		0.433772
  validation accuracy:		92.61 %
Epoch 1412 of 2000 took 0.057s
  training loss:		0.008742
  validation loss:		0.439263
  validation accuracy:		92.28 %
Epoch 1413 of 2000 took 0.058s
  training loss:		0.008470
  validation loss:		0.442218
  validation accuracy:		92.17 %
Epoch 1414 of 2000 took 0.058s
  training loss:		0.008573
  validation loss:		0.441695
  validation accuracy:		92.39 %
Epoch 1415 of 2000 took 0.059s
  training loss:		0.008804
  validation loss:		0.445698
  validation accuracy:		92.07 %
Epoch 1416 of 2000 took 0.057s
  training loss:		0.008540
  validation loss:		0.436778
  validation accuracy:		92.50 %
Epoch 1417 of 2000 took 0.057s
  training loss:		0.008636
  validation loss:		0.434894
  validation accuracy:		92.50 %
Epoch 1418 of 2000 took 0.057s
  training loss:		0.008529
  validation loss:		0.441968
  validation accuracy:		92.28 %
Epoch 1419 of 2000 took 0.058s
  training loss:		0.008461
  validation loss:		0.444260
  validation accuracy:		92.39 %
Epoch 1420 of 2000 took 0.059s
  training loss:		0.008295
  validation loss:		0.440347
  validation accuracy:		92.61 %
Epoch 1421 of 2000 took 0.058s
  training loss:		0.008674
  validation loss:		0.432312
  validation accuracy:		92.39 %
Epoch 1422 of 2000 took 0.061s
  training loss:		0.008601
  validation loss:		0.445499
  validation accuracy:		92.39 %
Epoch 1423 of 2000 took 0.055s
  training loss:		0.008349
  validation loss:		0.439567
  validation accuracy:		92.50 %
Epoch 1424 of 2000 took 0.057s
  training loss:		0.008338
  validation loss:		0.438209
  validation accuracy:		92.39 %
Epoch 1425 of 2000 took 0.058s
  training loss:		0.008586
  validation loss:		0.438904
  validation accuracy:		92.28 %
Epoch 1426 of 2000 took 0.059s
  training loss:		0.008319
  validation loss:		0.443324
  validation accuracy:		92.39 %
Epoch 1427 of 2000 took 0.058s
  training loss:		0.008348
  validation loss:		0.440596
  validation accuracy:		92.28 %
Epoch 1428 of 2000 took 0.059s
  training loss:		0.008389
  validation loss:		0.445614
  validation accuracy:		92.28 %
Epoch 1429 of 2000 took 0.059s
  training loss:		0.008491
  validation loss:		0.443500
  validation accuracy:		92.39 %
Epoch 1430 of 2000 took 0.058s
  training loss:		0.008260
  validation loss:		0.442682
  validation accuracy:		92.17 %
Epoch 1431 of 2000 took 0.057s
  training loss:		0.008311
  validation loss:		0.442731
  validation accuracy:		92.28 %
Epoch 1432 of 2000 took 0.056s
  training loss:		0.008094
  validation loss:		0.445789
  validation accuracy:		92.28 %
Epoch 1433 of 2000 took 0.058s
  training loss:		0.008336
  validation loss:		0.445907
  validation accuracy:		92.28 %
Epoch 1434 of 2000 took 0.059s
  training loss:		0.008043
  validation loss:		0.439464
  validation accuracy:		92.28 %
Epoch 1435 of 2000 took 0.058s
  training loss:		0.008399
  validation loss:		0.439699
  validation accuracy:		92.61 %
Epoch 1436 of 2000 took 0.058s
  training loss:		0.008244
  validation loss:		0.446663
  validation accuracy:		92.17 %
Epoch 1437 of 2000 took 0.057s
  training loss:		0.008114
  validation loss:		0.446194
  validation accuracy:		92.28 %
Epoch 1438 of 2000 took 0.059s
  training loss:		0.007769
  validation loss:		0.444257
  validation accuracy:		92.50 %
Epoch 1439 of 2000 took 0.059s
  training loss:		0.008130
  validation loss:		0.444335
  validation accuracy:		92.39 %
Epoch 1440 of 2000 took 0.058s
  training loss:		0.008238
  validation loss:		0.445455
  validation accuracy:		92.39 %
Epoch 1441 of 2000 took 0.058s
  training loss:		0.008086
  validation loss:		0.450077
  validation accuracy:		92.28 %
Epoch 1442 of 2000 took 0.059s
  training loss:		0.007942
  validation loss:		0.438666
  validation accuracy:		92.61 %
Epoch 1443 of 2000 took 0.058s
  training loss:		0.008157
  validation loss:		0.454648
  validation accuracy:		92.07 %
Epoch 1444 of 2000 took 0.058s
  training loss:		0.008040
  validation loss:		0.445845
  validation accuracy:		92.28 %
Epoch 1445 of 2000 took 0.057s
  training loss:		0.008318
  validation loss:		0.451556
  validation accuracy:		92.17 %
Epoch 1446 of 2000 took 0.058s
  training loss:		0.008165
  validation loss:		0.443453
  validation accuracy:		92.39 %
Epoch 1447 of 2000 took 0.060s
  training loss:		0.008018
  validation loss:		0.446260
  validation accuracy:		92.28 %
Epoch 1448 of 2000 took 0.058s
  training loss:		0.008245
  validation loss:		0.437763
  validation accuracy:		92.50 %
Epoch 1449 of 2000 took 0.058s
  training loss:		0.008049
  validation loss:		0.450388
  validation accuracy:		92.17 %
Epoch 1450 of 2000 took 0.058s
  training loss:		0.008277
  validation loss:		0.438177
  validation accuracy:		92.50 %
Epoch 1451 of 2000 took 0.058s
  training loss:		0.008266
  validation loss:		0.450958
  validation accuracy:		92.28 %
Epoch 1452 of 2000 took 0.058s
  training loss:		0.007926
  validation loss:		0.447039
  validation accuracy:		92.28 %
Epoch 1453 of 2000 took 0.058s
  training loss:		0.008011
  validation loss:		0.451793
  validation accuracy:		92.28 %
Epoch 1454 of 2000 took 0.058s
  training loss:		0.007420
  validation loss:		0.453605
  validation accuracy:		92.17 %
Epoch 1455 of 2000 took 0.059s
  training loss:		0.008122
  validation loss:		0.453241
  validation accuracy:		92.39 %
Epoch 1456 of 2000 took 0.059s
  training loss:		0.008439
  validation loss:		0.456002
  validation accuracy:		92.28 %
Epoch 1457 of 2000 took 0.058s
  training loss:		0.007877
  validation loss:		0.447634
  validation accuracy:		92.39 %
Epoch 1458 of 2000 took 0.058s
  training loss:		0.007759
  validation loss:		0.450619
  validation accuracy:		92.50 %
Epoch 1459 of 2000 took 0.058s
  training loss:		0.007952
  validation loss:		0.446254
  validation accuracy:		92.39 %
Epoch 1460 of 2000 took 0.058s
  training loss:		0.007734
  validation loss:		0.437024
  validation accuracy:		92.50 %
Epoch 1461 of 2000 took 0.058s
  training loss:		0.007837
  validation loss:		0.451512
  validation accuracy:		92.28 %
Epoch 1462 of 2000 took 0.058s
  training loss:		0.007919
  validation loss:		0.451297
  validation accuracy:		92.39 %
Epoch 1463 of 2000 took 0.058s
  training loss:		0.007855
  validation loss:		0.448194
  validation accuracy:		92.50 %
Epoch 1464 of 2000 took 0.058s
  training loss:		0.007836
  validation loss:		0.445478
  validation accuracy:		92.50 %
Epoch 1465 of 2000 took 0.058s
  training loss:		0.008018
  validation loss:		0.446874
  validation accuracy:		92.39 %
Epoch 1466 of 2000 took 0.058s
  training loss:		0.007803
  validation loss:		0.446066
  validation accuracy:		92.50 %
Epoch 1467 of 2000 took 0.058s
  training loss:		0.007635
  validation loss:		0.452883
  validation accuracy:		92.61 %
Epoch 1468 of 2000 took 0.058s
  training loss:		0.007969
  validation loss:		0.454461
  validation accuracy:		92.39 %
Epoch 1469 of 2000 took 0.058s
  training loss:		0.007780
  validation loss:		0.447386
  validation accuracy:		92.39 %
Epoch 1470 of 2000 took 0.058s
  training loss:		0.007670
  validation loss:		0.451277
  validation accuracy:		92.39 %
Epoch 1471 of 2000 took 0.058s
  training loss:		0.007649
  validation loss:		0.446194
  validation accuracy:		92.28 %
Epoch 1472 of 2000 took 0.058s
  training loss:		0.007608
  validation loss:		0.450242
  validation accuracy:		92.61 %
Epoch 1473 of 2000 took 0.058s
  training loss:		0.007985
  validation loss:		0.448977
  validation accuracy:		92.39 %
Epoch 1474 of 2000 took 0.058s
  training loss:		0.007736
  validation loss:		0.454063
  validation accuracy:		92.39 %
Epoch 1475 of 2000 took 0.058s
  training loss:		0.007808
  validation loss:		0.453636
  validation accuracy:		92.28 %
Epoch 1476 of 2000 took 0.058s
  training loss:		0.007392
  validation loss:		0.448023
  validation accuracy:		92.39 %
Epoch 1477 of 2000 took 0.058s
  training loss:		0.007525
  validation loss:		0.454874
  validation accuracy:		92.28 %
Epoch 1478 of 2000 took 0.058s
  training loss:		0.007527
  validation loss:		0.454011
  validation accuracy:		92.50 %
Epoch 1479 of 2000 took 0.058s
  training loss:		0.007575
  validation loss:		0.451233
  validation accuracy:		92.28 %
Epoch 1480 of 2000 took 0.058s
  training loss:		0.007662
  validation loss:		0.449032
  validation accuracy:		92.61 %
Epoch 1481 of 2000 took 0.058s
  training loss:		0.007705
  validation loss:		0.459605
  validation accuracy:		92.28 %
Epoch 1482 of 2000 took 0.059s
  training loss:		0.007651
  validation loss:		0.446246
  validation accuracy:		92.50 %
Epoch 1483 of 2000 took 0.059s
  training loss:		0.007534
  validation loss:		0.454757
  validation accuracy:		92.28 %
Epoch 1484 of 2000 took 0.058s
  training loss:		0.007722
  validation loss:		0.456361
  validation accuracy:		92.39 %
Epoch 1485 of 2000 took 0.058s
  training loss:		0.007723
  validation loss:		0.463328
  validation accuracy:		92.28 %
Epoch 1486 of 2000 took 0.058s
  training loss:		0.007367
  validation loss:		0.449779
  validation accuracy:		92.50 %
Epoch 1487 of 2000 took 0.058s
  training loss:		0.007233
  validation loss:		0.450014
  validation accuracy:		92.28 %
Epoch 1488 of 2000 took 0.058s
  training loss:		0.007178
  validation loss:		0.451417
  validation accuracy:		92.28 %
Epoch 1489 of 2000 took 0.058s
  training loss:		0.007528
  validation loss:		0.452679
  validation accuracy:		92.39 %
Epoch 1490 of 2000 took 0.058s
  training loss:		0.007466
  validation loss:		0.451337
  validation accuracy:		92.39 %
Epoch 1491 of 2000 took 0.058s
  training loss:		0.007389
  validation loss:		0.455618
  validation accuracy:		92.17 %
Epoch 1492 of 2000 took 0.058s
  training loss:		0.007389
  validation loss:		0.459839
  validation accuracy:		92.28 %
Epoch 1493 of 2000 took 0.058s
  training loss:		0.007462
  validation loss:		0.449689
  validation accuracy:		92.50 %
Epoch 1494 of 2000 took 0.058s
  training loss:		0.007874
  validation loss:		0.455536
  validation accuracy:		92.39 %
Epoch 1495 of 2000 took 0.059s
  training loss:		0.007399
  validation loss:		0.456211
  validation accuracy:		92.39 %
Epoch 1496 of 2000 took 0.058s
  training loss:		0.007500
  validation loss:		0.452844
  validation accuracy:		92.39 %
Epoch 1497 of 2000 took 0.058s
  training loss:		0.007474
  validation loss:		0.454574
  validation accuracy:		92.39 %
Epoch 1498 of 2000 took 0.058s
  training loss:		0.007538
  validation loss:		0.457444
  validation accuracy:		92.17 %
Epoch 1499 of 2000 took 0.059s
  training loss:		0.007530
  validation loss:		0.457712
  validation accuracy:		92.39 %
Epoch 1500 of 2000 took 0.059s
  training loss:		0.007355
  validation loss:		0.456446
  validation accuracy:		92.28 %
Epoch 1501 of 2000 took 0.059s
  training loss:		0.007331
  validation loss:		0.456496
  validation accuracy:		92.50 %
Epoch 1502 of 2000 took 0.059s
  training loss:		0.007332
  validation loss:		0.450884
  validation accuracy:		92.39 %
Epoch 1503 of 2000 took 0.059s
  training loss:		0.007660
  validation loss:		0.459434
  validation accuracy:		92.50 %
Epoch 1504 of 2000 took 0.059s
  training loss:		0.007266
  validation loss:		0.456830
  validation accuracy:		92.17 %
Epoch 1505 of 2000 took 0.058s
  training loss:		0.007347
  validation loss:		0.457913
  validation accuracy:		92.39 %
Epoch 1506 of 2000 took 0.058s
  training loss:		0.007062
  validation loss:		0.459615
  validation accuracy:		92.50 %
Epoch 1507 of 2000 took 0.058s
  training loss:		0.007311
  validation loss:		0.457164
  validation accuracy:		92.39 %
Epoch 1508 of 2000 took 0.058s
  training loss:		0.007331
  validation loss:		0.464398
  validation accuracy:		92.07 %
Epoch 1509 of 2000 took 0.058s
  training loss:		0.007389
  validation loss:		0.448156
  validation accuracy:		92.61 %
Epoch 1510 of 2000 took 0.058s
  training loss:		0.007136
  validation loss:		0.460726
  validation accuracy:		92.39 %
Epoch 1511 of 2000 took 0.058s
  training loss:		0.007273
  validation loss:		0.462990
  validation accuracy:		92.17 %
Epoch 1512 of 2000 took 0.058s
  training loss:		0.007046
  validation loss:		0.454956
  validation accuracy:		92.50 %
Epoch 1513 of 2000 took 0.058s
  training loss:		0.007349
  validation loss:		0.456254
  validation accuracy:		92.28 %
Epoch 1514 of 2000 took 0.058s
  training loss:		0.007264
  validation loss:		0.455763
  validation accuracy:		92.50 %
Epoch 1515 of 2000 took 0.058s
  training loss:		0.007345
  validation loss:		0.459301
  validation accuracy:		92.28 %
Epoch 1516 of 2000 took 0.058s
  training loss:		0.007223
  validation loss:		0.458261
  validation accuracy:		92.39 %
Epoch 1517 of 2000 took 0.058s
  training loss:		0.007043
  validation loss:		0.453300
  validation accuracy:		92.39 %
Epoch 1518 of 2000 took 0.058s
  training loss:		0.006887
  validation loss:		0.458400
  validation accuracy:		92.39 %
Epoch 1519 of 2000 took 0.058s
  training loss:		0.007280
  validation loss:		0.468614
  validation accuracy:		92.28 %
Epoch 1520 of 2000 took 0.059s
  training loss:		0.006908
  validation loss:		0.457661
  validation accuracy:		92.39 %
Epoch 1521 of 2000 took 0.059s
  training loss:		0.006864
  validation loss:		0.451678
  validation accuracy:		92.72 %
Epoch 1522 of 2000 took 0.059s
  training loss:		0.007189
  validation loss:		0.457413
  validation accuracy:		92.39 %
Epoch 1523 of 2000 took 0.058s
  training loss:		0.007027
  validation loss:		0.461901
  validation accuracy:		92.50 %
Epoch 1524 of 2000 took 0.058s
  training loss:		0.006926
  validation loss:		0.460122
  validation accuracy:		92.39 %
Epoch 1525 of 2000 took 0.058s
  training loss:		0.006884
  validation loss:		0.465141
  validation accuracy:		92.28 %
Epoch 1526 of 2000 took 0.058s
  training loss:		0.007006
  validation loss:		0.467269
  validation accuracy:		92.17 %
Epoch 1527 of 2000 took 0.058s
  training loss:		0.006689
  validation loss:		0.459230
  validation accuracy:		92.50 %
Epoch 1528 of 2000 took 0.058s
  training loss:		0.006871
  validation loss:		0.463697
  validation accuracy:		92.28 %
Epoch 1529 of 2000 took 0.058s
  training loss:		0.006962
  validation loss:		0.459972
  validation accuracy:		92.61 %
Epoch 1530 of 2000 took 0.058s
  training loss:		0.006959
  validation loss:		0.459750
  validation accuracy:		92.39 %
Epoch 1531 of 2000 took 0.058s
  training loss:		0.006988
  validation loss:		0.460631
  validation accuracy:		92.39 %
Epoch 1532 of 2000 took 0.058s
  training loss:		0.006991
  validation loss:		0.457783
  validation accuracy:		92.39 %
Epoch 1533 of 2000 took 0.058s
  training loss:		0.007067
  validation loss:		0.451396
  validation accuracy:		92.61 %
Epoch 1534 of 2000 took 0.058s
  training loss:		0.007218
  validation loss:		0.470893
  validation accuracy:		92.17 %
Epoch 1535 of 2000 took 0.058s
  training loss:		0.006774
  validation loss:		0.466726
  validation accuracy:		92.39 %
Epoch 1536 of 2000 took 0.058s
  training loss:		0.006940
  validation loss:		0.461648
  validation accuracy:		92.39 %
Epoch 1537 of 2000 took 0.059s
  training loss:		0.006711
  validation loss:		0.468068
  validation accuracy:		92.17 %
Epoch 1538 of 2000 took 0.058s
  training loss:		0.006877
  validation loss:		0.461344
  validation accuracy:		92.28 %
Epoch 1539 of 2000 took 0.058s
  training loss:		0.006796
  validation loss:		0.465532
  validation accuracy:		92.28 %
Epoch 1540 of 2000 took 0.058s
  training loss:		0.006721
  validation loss:		0.464076
  validation accuracy:		92.28 %
Epoch 1541 of 2000 took 0.058s
  training loss:		0.006905
  validation loss:		0.464505
  validation accuracy:		92.39 %
Epoch 1542 of 2000 took 0.058s
  training loss:		0.006913
  validation loss:		0.469256
  validation accuracy:		92.28 %
Epoch 1543 of 2000 took 0.058s
  training loss:		0.006856
  validation loss:		0.470300
  validation accuracy:		92.17 %
Epoch 1544 of 2000 took 0.058s
  training loss:		0.007182
  validation loss:		0.461365
  validation accuracy:		92.39 %
Epoch 1545 of 2000 took 0.058s
  training loss:		0.006802
  validation loss:		0.458492
  validation accuracy:		92.50 %
Epoch 1546 of 2000 took 0.058s
  training loss:		0.006806
  validation loss:		0.464484
  validation accuracy:		92.17 %
Epoch 1547 of 2000 took 0.058s
  training loss:		0.006658
  validation loss:		0.459224
  validation accuracy:		92.61 %
Epoch 1548 of 2000 took 0.058s
  training loss:		0.006587
  validation loss:		0.470029
  validation accuracy:		92.28 %
Epoch 1549 of 2000 took 0.058s
  training loss:		0.006686
  validation loss:		0.461934
  validation accuracy:		92.39 %
Epoch 1550 of 2000 took 0.058s
  training loss:		0.006512
  validation loss:		0.464390
  validation accuracy:		92.28 %
Epoch 1551 of 2000 took 0.058s
  training loss:		0.006915
  validation loss:		0.465183
  validation accuracy:		92.39 %
Epoch 1552 of 2000 took 0.058s
  training loss:		0.006636
  validation loss:		0.469611
  validation accuracy:		92.28 %
Epoch 1553 of 2000 took 0.058s
  training loss:		0.006601
  validation loss:		0.470378
  validation accuracy:		92.39 %
Epoch 1554 of 2000 took 0.058s
  training loss:		0.006668
  validation loss:		0.464800
  validation accuracy:		92.39 %
Epoch 1555 of 2000 took 0.058s
  training loss:		0.006483
  validation loss:		0.463754
  validation accuracy:		92.39 %
Epoch 1556 of 2000 took 0.058s
  training loss:		0.006510
  validation loss:		0.463164
  validation accuracy:		92.50 %
Epoch 1557 of 2000 took 0.058s
  training loss:		0.006745
  validation loss:		0.467958
  validation accuracy:		92.72 %
Epoch 1558 of 2000 took 0.058s
  training loss:		0.006531
  validation loss:		0.463020
  validation accuracy:		92.50 %
Epoch 1559 of 2000 took 0.058s
  training loss:		0.006774
  validation loss:		0.475177
  validation accuracy:		92.28 %
Epoch 1560 of 2000 took 0.058s
  training loss:		0.006803
  validation loss:		0.468884
  validation accuracy:		92.17 %
Epoch 1561 of 2000 took 0.055s
  training loss:		0.006719
  validation loss:		0.472538
  validation accuracy:		92.28 %
Epoch 1562 of 2000 took 0.058s
  training loss:		0.006524
  validation loss:		0.465714
  validation accuracy:		92.50 %
Epoch 1563 of 2000 took 0.059s
  training loss:		0.006521
  validation loss:		0.464878
  validation accuracy:		92.28 %
Epoch 1564 of 2000 took 0.059s
  training loss:		0.006572
  validation loss:		0.462992
  validation accuracy:		92.61 %
Epoch 1565 of 2000 took 0.059s
  training loss:		0.006564
  validation loss:		0.469358
  validation accuracy:		92.07 %
Epoch 1566 of 2000 took 0.059s
  training loss:		0.006488
  validation loss:		0.462959
  validation accuracy:		92.39 %
Epoch 1567 of 2000 took 0.059s
  training loss:		0.006597
  validation loss:		0.464481
  validation accuracy:		92.28 %
Epoch 1568 of 2000 took 0.059s
  training loss:		0.006459
  validation loss:		0.471992
  validation accuracy:		92.17 %
Epoch 1569 of 2000 took 0.060s
  training loss:		0.006669
  validation loss:		0.468260
  validation accuracy:		92.17 %
Epoch 1570 of 2000 took 0.059s
  training loss:		0.006367
  validation loss:		0.471477
  validation accuracy:		92.28 %
Epoch 1571 of 2000 took 0.059s
  training loss:		0.006428
  validation loss:		0.465570
  validation accuracy:		92.50 %
Epoch 1572 of 2000 took 0.059s
  training loss:		0.006541
  validation loss:		0.468797
  validation accuracy:		92.61 %
Epoch 1573 of 2000 took 0.059s
  training loss:		0.006560
  validation loss:		0.471276
  validation accuracy:		92.28 %
Epoch 1574 of 2000 took 0.059s
  training loss:		0.006527
  validation loss:		0.471301
  validation accuracy:		92.28 %
Epoch 1575 of 2000 took 0.059s
  training loss:		0.006245
  validation loss:		0.479707
  validation accuracy:		92.17 %
Epoch 1576 of 2000 took 0.059s
  training loss:		0.006354
  validation loss:		0.463371
  validation accuracy:		92.39 %
Epoch 1577 of 2000 took 0.059s
  training loss:		0.006242
  validation loss:		0.477020
  validation accuracy:		92.28 %
Epoch 1578 of 2000 took 0.059s
  training loss:		0.006454
  validation loss:		0.462478
  validation accuracy:		92.39 %
Epoch 1579 of 2000 took 0.059s
  training loss:		0.006514
  validation loss:		0.469358
  validation accuracy:		92.39 %
Epoch 1580 of 2000 took 0.059s
  training loss:		0.006325
  validation loss:		0.471324
  validation accuracy:		92.39 %
Epoch 1581 of 2000 took 0.059s
  training loss:		0.006455
  validation loss:		0.476448
  validation accuracy:		92.17 %
Epoch 1582 of 2000 took 0.059s
  training loss:		0.006436
  validation loss:		0.467950
  validation accuracy:		92.39 %
Epoch 1583 of 2000 took 0.059s
  training loss:		0.006419
  validation loss:		0.472248
  validation accuracy:		92.39 %
Epoch 1584 of 2000 took 0.060s
  training loss:		0.006352
  validation loss:		0.472466
  validation accuracy:		92.39 %
Epoch 1585 of 2000 took 0.059s
  training loss:		0.006205
  validation loss:		0.466357
  validation accuracy:		92.50 %
Epoch 1586 of 2000 took 0.059s
  training loss:		0.006073
  validation loss:		0.468825
  validation accuracy:		92.39 %
Epoch 1587 of 2000 took 0.059s
  training loss:		0.006279
  validation loss:		0.470932
  validation accuracy:		92.39 %
Epoch 1588 of 2000 took 0.059s
  training loss:		0.006062
  validation loss:		0.475620
  validation accuracy:		92.17 %
Epoch 1589 of 2000 took 0.059s
  training loss:		0.006325
  validation loss:		0.469903
  validation accuracy:		92.39 %
Epoch 1590 of 2000 took 0.059s
  training loss:		0.006229
  validation loss:		0.478088
  validation accuracy:		92.17 %
Epoch 1591 of 2000 took 0.059s
  training loss:		0.006299
  validation loss:		0.471213
  validation accuracy:		92.61 %
Epoch 1592 of 2000 took 0.059s
  training loss:		0.006211
  validation loss:		0.467255
  validation accuracy:		92.39 %
Epoch 1593 of 2000 took 0.059s
  training loss:		0.006591
  validation loss:		0.469688
  validation accuracy:		92.50 %
Epoch 1594 of 2000 took 0.059s
  training loss:		0.006179
  validation loss:		0.474068
  validation accuracy:		92.28 %
Epoch 1595 of 2000 took 0.059s
  training loss:		0.006210
  validation loss:		0.475843
  validation accuracy:		92.50 %
Epoch 1596 of 2000 took 0.059s
  training loss:		0.006258
  validation loss:		0.466979
  validation accuracy:		92.61 %
Epoch 1597 of 2000 took 0.059s
  training loss:		0.006203
  validation loss:		0.471042
  validation accuracy:		92.50 %
Epoch 1598 of 2000 took 0.060s
  training loss:		0.006132
  validation loss:		0.471992
  validation accuracy:		92.39 %
Epoch 1599 of 2000 took 0.059s
  training loss:		0.006091
  validation loss:		0.474277
  validation accuracy:		92.39 %
Epoch 1600 of 2000 took 0.059s
  training loss:		0.005952
  validation loss:		0.471390
  validation accuracy:		92.39 %
Epoch 1601 of 2000 took 0.060s
  training loss:		0.005892
  validation loss:		0.476454
  validation accuracy:		92.28 %
Epoch 1602 of 2000 took 0.060s
  training loss:		0.006153
  validation loss:		0.468732
  validation accuracy:		92.39 %
Epoch 1603 of 2000 took 0.060s
  training loss:		0.006111
  validation loss:		0.472426
  validation accuracy:		92.39 %
Epoch 1604 of 2000 took 0.060s
  training loss:		0.006392
  validation loss:		0.473580
  validation accuracy:		92.17 %
Epoch 1605 of 2000 took 0.060s
  training loss:		0.006031
  validation loss:		0.478744
  validation accuracy:		92.17 %
Epoch 1606 of 2000 took 0.059s
  training loss:		0.005856
  validation loss:		0.474483
  validation accuracy:		92.39 %
Epoch 1607 of 2000 took 0.060s
  training loss:		0.006218
  validation loss:		0.478625
  validation accuracy:		92.28 %
Epoch 1608 of 2000 took 0.059s
  training loss:		0.006102
  validation loss:		0.478964
  validation accuracy:		92.39 %
Epoch 1609 of 2000 took 0.059s
  training loss:		0.006026
  validation loss:		0.481012
  validation accuracy:		92.17 %
Epoch 1610 of 2000 took 0.059s
  training loss:		0.006027
  validation loss:		0.474481
  validation accuracy:		92.28 %
Epoch 1611 of 2000 took 0.059s
  training loss:		0.006125
  validation loss:		0.476555
  validation accuracy:		92.50 %
Epoch 1612 of 2000 took 0.060s
  training loss:		0.005907
  validation loss:		0.473052
  validation accuracy:		92.28 %
Epoch 1613 of 2000 took 0.060s
  training loss:		0.005910
  validation loss:		0.484618
  validation accuracy:		92.17 %
Epoch 1614 of 2000 took 0.060s
  training loss:		0.006163
  validation loss:		0.476757
  validation accuracy:		92.28 %
Epoch 1615 of 2000 took 0.059s
  training loss:		0.006215
  validation loss:		0.475695
  validation accuracy:		92.39 %
Epoch 1616 of 2000 took 0.059s
  training loss:		0.006067
  validation loss:		0.477659
  validation accuracy:		92.28 %
Epoch 1617 of 2000 took 0.059s
  training loss:		0.005846
  validation loss:		0.471236
  validation accuracy:		92.39 %
Epoch 1618 of 2000 took 0.060s
  training loss:		0.006082
  validation loss:		0.478655
  validation accuracy:		92.28 %
Epoch 1619 of 2000 took 0.059s
  training loss:		0.006039
  validation loss:		0.479234
  validation accuracy:		92.61 %
Epoch 1620 of 2000 took 0.059s
  training loss:		0.005921
  validation loss:		0.472075
  validation accuracy:		92.61 %
Epoch 1621 of 2000 took 0.059s
  training loss:		0.005895
  validation loss:		0.474011
  validation accuracy:		92.61 %
Epoch 1622 of 2000 took 0.059s
  training loss:		0.005852
  validation loss:		0.480634
  validation accuracy:		92.28 %
Epoch 1623 of 2000 took 0.059s
  training loss:		0.006019
  validation loss:		0.473899
  validation accuracy:		92.28 %
Epoch 1624 of 2000 took 0.059s
  training loss:		0.005909
  validation loss:		0.485889
  validation accuracy:		92.28 %
Epoch 1625 of 2000 took 0.059s
  training loss:		0.005986
  validation loss:		0.486382
  validation accuracy:		92.17 %
Epoch 1626 of 2000 took 0.059s
  training loss:		0.006007
  validation loss:		0.481841
  validation accuracy:		92.17 %
Epoch 1627 of 2000 took 0.059s
  training loss:		0.005955
  validation loss:		0.478683
  validation accuracy:		92.39 %
Epoch 1628 of 2000 took 0.059s
  training loss:		0.005841
  validation loss:		0.475682
  validation accuracy:		92.39 %
Epoch 1629 of 2000 took 0.059s
  training loss:		0.005863
  validation loss:		0.476531
  validation accuracy:		92.39 %
Epoch 1630 of 2000 took 0.059s
  training loss:		0.005965
  validation loss:		0.480918
  validation accuracy:		92.17 %
Epoch 1631 of 2000 took 0.059s
  training loss:		0.005946
  validation loss:		0.478723
  validation accuracy:		92.39 %
Epoch 1632 of 2000 took 0.059s
  training loss:		0.005752
  validation loss:		0.484493
  validation accuracy:		92.28 %
Epoch 1633 of 2000 took 0.059s
  training loss:		0.005819
  validation loss:		0.485222
  validation accuracy:		92.61 %
Epoch 1634 of 2000 took 0.059s
  training loss:		0.005896
  validation loss:		0.482349
  validation accuracy:		92.28 %
Epoch 1635 of 2000 took 0.059s
  training loss:		0.005914
  validation loss:		0.484154
  validation accuracy:		92.17 %
Epoch 1636 of 2000 took 0.059s
  training loss:		0.006048
  validation loss:		0.486770
  validation accuracy:		92.28 %
Epoch 1637 of 2000 took 0.059s
  training loss:		0.005873
  validation loss:		0.478403
  validation accuracy:		92.50 %
Epoch 1638 of 2000 took 0.059s
  training loss:		0.005857
  validation loss:		0.476442
  validation accuracy:		92.39 %
Epoch 1639 of 2000 took 0.059s
  training loss:		0.005768
  validation loss:		0.483347
  validation accuracy:		92.28 %
Epoch 1640 of 2000 took 0.059s
  training loss:		0.005567
  validation loss:		0.482893
  validation accuracy:		92.07 %
Epoch 1641 of 2000 took 0.059s
  training loss:		0.005500
  validation loss:		0.483404
  validation accuracy:		92.39 %
Epoch 1642 of 2000 took 0.059s
  training loss:		0.005711
  validation loss:		0.481461
  validation accuracy:		92.28 %
Epoch 1643 of 2000 took 0.059s
  training loss:		0.005743
  validation loss:		0.482716
  validation accuracy:		92.39 %
Epoch 1644 of 2000 took 0.059s
  training loss:		0.005862
  validation loss:		0.487657
  validation accuracy:		92.17 %
Epoch 1645 of 2000 took 0.059s
  training loss:		0.005657
  validation loss:		0.486719
  validation accuracy:		92.39 %
Epoch 1646 of 2000 took 0.059s
  training loss:		0.005671
  validation loss:		0.486001
  validation accuracy:		92.39 %
Epoch 1647 of 2000 took 0.059s
  training loss:		0.005711
  validation loss:		0.474332
  validation accuracy:		92.61 %
Epoch 1648 of 2000 took 0.059s
  training loss:		0.005947
  validation loss:		0.481817
  validation accuracy:		92.61 %
Epoch 1649 of 2000 took 0.059s
  training loss:		0.005896
  validation loss:		0.482882
  validation accuracy:		92.39 %
Epoch 1650 of 2000 took 0.059s
  training loss:		0.005853
  validation loss:		0.482684
  validation accuracy:		92.39 %
Epoch 1651 of 2000 took 0.059s
  training loss:		0.005651
  validation loss:		0.480038
  validation accuracy:		92.61 %
Epoch 1652 of 2000 took 0.059s
  training loss:		0.005777
  validation loss:		0.483869
  validation accuracy:		92.28 %
Epoch 1653 of 2000 took 0.059s
  training loss:		0.005814
  validation loss:		0.483286
  validation accuracy:		92.50 %
Epoch 1654 of 2000 took 0.059s
  training loss:		0.005605
  validation loss:		0.482760
  validation accuracy:		92.61 %
Epoch 1655 of 2000 took 0.059s
  training loss:		0.005655
  validation loss:		0.485379
  validation accuracy:		92.39 %
Epoch 1656 of 2000 took 0.059s
  training loss:		0.005730
  validation loss:		0.489459
  validation accuracy:		92.39 %
Epoch 1657 of 2000 took 0.059s
  training loss:		0.005638
  validation loss:		0.483296
  validation accuracy:		92.50 %
Epoch 1658 of 2000 took 0.059s
  training loss:		0.005636
  validation loss:		0.482913
  validation accuracy:		92.39 %
Epoch 1659 of 2000 took 0.059s
  training loss:		0.005637
  validation loss:		0.485275
  validation accuracy:		92.50 %
Epoch 1660 of 2000 took 0.059s
  training loss:		0.005610
  validation loss:		0.483025
  validation accuracy:		92.28 %
Epoch 1661 of 2000 took 0.059s
  training loss:		0.005706
  validation loss:		0.485248
  validation accuracy:		92.39 %
Epoch 1662 of 2000 took 0.059s
  training loss:		0.005629
  validation loss:		0.483112
  validation accuracy:		92.39 %
Epoch 1663 of 2000 took 0.059s
  training loss:		0.005636
  validation loss:		0.490620
  validation accuracy:		92.17 %
Epoch 1664 of 2000 took 0.059s
  training loss:		0.005579
  validation loss:		0.480371
  validation accuracy:		92.39 %
Epoch 1665 of 2000 took 0.059s
  training loss:		0.005542
  validation loss:		0.484853
  validation accuracy:		92.61 %
Epoch 1666 of 2000 took 0.059s
  training loss:		0.005499
  validation loss:		0.487087
  validation accuracy:		92.28 %
Epoch 1667 of 2000 took 0.059s
  training loss:		0.005569
  validation loss:		0.487084
  validation accuracy:		92.39 %
Epoch 1668 of 2000 took 0.059s
  training loss:		0.005513
  validation loss:		0.491721
  validation accuracy:		92.28 %
Epoch 1669 of 2000 took 0.060s
  training loss:		0.005689
  validation loss:		0.485891
  validation accuracy:		92.39 %
Epoch 1670 of 2000 took 0.060s
  training loss:		0.005303
  validation loss:		0.480434
  validation accuracy:		92.50 %
Epoch 1671 of 2000 took 0.059s
  training loss:		0.005549
  validation loss:		0.485907
  validation accuracy:		92.28 %
Epoch 1672 of 2000 took 0.060s
  training loss:		0.005652
  validation loss:		0.485924
  validation accuracy:		92.28 %
Epoch 1673 of 2000 took 0.059s
  training loss:		0.005530
  validation loss:		0.486608
  validation accuracy:		92.39 %
Epoch 1674 of 2000 took 0.059s
  training loss:		0.005393
  validation loss:		0.486080
  validation accuracy:		92.28 %
Epoch 1675 of 2000 took 0.059s
  training loss:		0.005488
  validation loss:		0.485455
  validation accuracy:		92.39 %
Epoch 1676 of 2000 took 0.059s
  training loss:		0.005310
  validation loss:		0.485456
  validation accuracy:		92.28 %
Epoch 1677 of 2000 took 0.059s
  training loss:		0.005323
  validation loss:		0.484814
  validation accuracy:		92.28 %
Epoch 1678 of 2000 took 0.059s
  training loss:		0.005449
  validation loss:		0.488745
  validation accuracy:		92.39 %
Epoch 1679 of 2000 took 0.059s
  training loss:		0.005311
  validation loss:		0.490677
  validation accuracy:		92.28 %
Epoch 1680 of 2000 took 0.059s
  training loss:		0.005470
  validation loss:		0.486887
  validation accuracy:		92.50 %
Epoch 1681 of 2000 took 0.060s
  training loss:		0.005403
  validation loss:		0.492681
  validation accuracy:		92.17 %
Epoch 1682 of 2000 took 0.060s
  training loss:		0.005321
  validation loss:		0.485563
  validation accuracy:		92.50 %
Epoch 1683 of 2000 took 0.060s
  training loss:		0.005514
  validation loss:		0.490723
  validation accuracy:		92.28 %
Epoch 1684 of 2000 took 0.059s
  training loss:		0.005309
  validation loss:		0.488253
  validation accuracy:		92.39 %
Epoch 1685 of 2000 took 0.059s
  training loss:		0.005467
  validation loss:		0.490834
  validation accuracy:		92.28 %
Epoch 1686 of 2000 took 0.060s
  training loss:		0.005378
  validation loss:		0.486863
  validation accuracy:		92.39 %
Epoch 1687 of 2000 took 0.060s
  training loss:		0.005503
  validation loss:		0.490260
  validation accuracy:		92.39 %
Epoch 1688 of 2000 took 0.060s
  training loss:		0.005487
  validation loss:		0.491896
  validation accuracy:		92.50 %
Epoch 1689 of 2000 took 0.060s
  training loss:		0.005344
  validation loss:		0.492477
  validation accuracy:		92.28 %
Epoch 1690 of 2000 took 0.060s
  training loss:		0.005264
  validation loss:		0.492432
  validation accuracy:		92.39 %
Epoch 1691 of 2000 took 0.060s
  training loss:		0.005484
  validation loss:		0.489307
  validation accuracy:		92.39 %
Epoch 1692 of 2000 took 0.060s
  training loss:		0.005351
  validation loss:		0.490703
  validation accuracy:		92.28 %
Epoch 1693 of 2000 took 0.060s
  training loss:		0.005085
  validation loss:		0.488870
  validation accuracy:		92.50 %
Epoch 1694 of 2000 took 0.060s
  training loss:		0.005277
  validation loss:		0.494206
  validation accuracy:		92.39 %
Epoch 1695 of 2000 took 0.059s
  training loss:		0.005272
  validation loss:		0.485199
  validation accuracy:		92.50 %
Epoch 1696 of 2000 took 0.059s
  training loss:		0.005216
  validation loss:		0.495989
  validation accuracy:		92.28 %
Epoch 1697 of 2000 took 0.060s
  training loss:		0.005222
  validation loss:		0.491654
  validation accuracy:		92.28 %
Epoch 1698 of 2000 took 0.060s
  training loss:		0.005341
  validation loss:		0.491116
  validation accuracy:		92.39 %
Epoch 1699 of 2000 took 0.059s
  training loss:		0.005181
  validation loss:		0.496632
  validation accuracy:		92.17 %
Epoch 1700 of 2000 took 0.059s
  training loss:		0.005298
  validation loss:		0.489880
  validation accuracy:		92.39 %
Epoch 1701 of 2000 took 0.059s
  training loss:		0.005222
  validation loss:		0.484349
  validation accuracy:		92.72 %
Epoch 1702 of 2000 took 0.059s
  training loss:		0.005236
  validation loss:		0.498291
  validation accuracy:		92.28 %
Epoch 1703 of 2000 took 0.059s
  training loss:		0.005402
  validation loss:		0.493831
  validation accuracy:		92.50 %
Epoch 1704 of 2000 took 0.060s
  training loss:		0.005214
  validation loss:		0.498015
  validation accuracy:		92.07 %
Epoch 1705 of 2000 took 0.060s
  training loss:		0.005332
  validation loss:		0.494804
  validation accuracy:		92.39 %
Epoch 1706 of 2000 took 0.060s
  training loss:		0.005159
  validation loss:		0.499412
  validation accuracy:		92.28 %
Epoch 1707 of 2000 took 0.060s
  training loss:		0.005221
  validation loss:		0.491720
  validation accuracy:		92.50 %
Epoch 1708 of 2000 took 0.059s
  training loss:		0.005319
  validation loss:		0.490009
  validation accuracy:		92.50 %
Epoch 1709 of 2000 took 0.059s
  training loss:		0.005248
  validation loss:		0.494328
  validation accuracy:		92.28 %
Epoch 1710 of 2000 took 0.060s
  training loss:		0.005173
  validation loss:		0.487285
  validation accuracy:		92.39 %
Epoch 1711 of 2000 took 0.059s
  training loss:		0.005200
  validation loss:		0.501877
  validation accuracy:		92.17 %
Epoch 1712 of 2000 took 0.060s
  training loss:		0.005107
  validation loss:		0.494671
  validation accuracy:		92.50 %
Epoch 1713 of 2000 took 0.059s
  training loss:		0.005171
  validation loss:		0.490291
  validation accuracy:		92.39 %
Epoch 1714 of 2000 took 0.059s
  training loss:		0.005240
  validation loss:		0.487507
  validation accuracy:		92.39 %
Epoch 1715 of 2000 took 0.060s
  training loss:		0.005020
  validation loss:		0.489970
  validation accuracy:		92.39 %
Epoch 1716 of 2000 took 0.060s
  training loss:		0.005078
  validation loss:		0.496186
  validation accuracy:		92.39 %
Epoch 1717 of 2000 took 0.060s
  training loss:		0.005238
  validation loss:		0.500080
  validation accuracy:		92.17 %
Epoch 1718 of 2000 took 0.059s
  training loss:		0.005309
  validation loss:		0.491492
  validation accuracy:		92.50 %
Epoch 1719 of 2000 took 0.059s
  training loss:		0.005144
  validation loss:		0.489796
  validation accuracy:		92.61 %
Epoch 1720 of 2000 took 0.059s
  training loss:		0.004982
  validation loss:		0.496636
  validation accuracy:		92.39 %
Epoch 1721 of 2000 took 0.059s
  training loss:		0.005145
  validation loss:		0.496388
  validation accuracy:		92.28 %
Epoch 1722 of 2000 took 0.060s
  training loss:		0.004904
  validation loss:		0.490689
  validation accuracy:		92.39 %
Epoch 1723 of 2000 took 0.060s
  training loss:		0.005069
  validation loss:		0.498323
  validation accuracy:		92.28 %
Epoch 1724 of 2000 took 0.060s
  training loss:		0.005107
  validation loss:		0.492506
  validation accuracy:		92.61 %
Epoch 1725 of 2000 took 0.060s
  training loss:		0.005144
  validation loss:		0.501178
  validation accuracy:		92.17 %
Epoch 1726 of 2000 took 0.059s
  training loss:		0.005055
  validation loss:		0.504058
  validation accuracy:		92.17 %
Epoch 1727 of 2000 took 0.060s
  training loss:		0.005168
  validation loss:		0.493986
  validation accuracy:		92.39 %
Epoch 1728 of 2000 took 0.060s
  training loss:		0.004947
  validation loss:		0.496894
  validation accuracy:		92.39 %
Epoch 1729 of 2000 took 0.059s
  training loss:		0.004987
  validation loss:		0.490246
  validation accuracy:		92.50 %
Epoch 1730 of 2000 took 0.059s
  training loss:		0.005022
  validation loss:		0.495335
  validation accuracy:		92.50 %
Epoch 1731 of 2000 took 0.059s
  training loss:		0.005142
  validation loss:		0.501502
  validation accuracy:		92.39 %
Epoch 1732 of 2000 took 0.059s
  training loss:		0.005190
  validation loss:		0.496508
  validation accuracy:		92.39 %
Epoch 1733 of 2000 took 0.059s
  training loss:		0.005120
  validation loss:		0.501807
  validation accuracy:		92.39 %
Epoch 1734 of 2000 took 0.059s
  training loss:		0.005100
  validation loss:		0.496351
  validation accuracy:		92.61 %
Epoch 1735 of 2000 took 0.059s
  training loss:		0.004882
  validation loss:		0.497421
  validation accuracy:		92.39 %
Epoch 1736 of 2000 took 0.059s
  training loss:		0.005011
  validation loss:		0.495805
  validation accuracy:		92.50 %
Epoch 1737 of 2000 took 0.059s
  training loss:		0.004886
  validation loss:		0.497288
  validation accuracy:		92.72 %
Epoch 1738 of 2000 took 0.059s
  training loss:		0.005082
  validation loss:		0.493137
  validation accuracy:		92.39 %
Epoch 1739 of 2000 took 0.059s
  training loss:		0.004838
  validation loss:		0.499294
  validation accuracy:		92.50 %
Epoch 1740 of 2000 took 0.059s
  training loss:		0.004896
  validation loss:		0.496711
  validation accuracy:		92.39 %
Epoch 1741 of 2000 took 0.059s
  training loss:		0.004973
  validation loss:		0.500795
  validation accuracy:		92.39 %
Epoch 1742 of 2000 took 0.059s
  training loss:		0.004867
  validation loss:		0.496702
  validation accuracy:		92.61 %
Epoch 1743 of 2000 took 0.059s
  training loss:		0.005133
  validation loss:		0.497735
  validation accuracy:		92.39 %
Epoch 1744 of 2000 took 0.060s
  training loss:		0.004817
  validation loss:		0.496394
  validation accuracy:		92.39 %
Epoch 1745 of 2000 took 0.059s
  training loss:		0.004708
  validation loss:		0.502364
  validation accuracy:		92.28 %
Epoch 1746 of 2000 took 0.059s
  training loss:		0.004941
  validation loss:		0.499482
  validation accuracy:		92.50 %
Epoch 1747 of 2000 took 0.059s
  training loss:		0.004886
  validation loss:		0.500339
  validation accuracy:		92.28 %
Epoch 1748 of 2000 took 0.059s
  training loss:		0.004840
  validation loss:		0.507213
  validation accuracy:		92.07 %
Epoch 1749 of 2000 took 0.059s
  training loss:		0.004891
  validation loss:		0.494282
  validation accuracy:		92.28 %
Epoch 1750 of 2000 took 0.059s
  training loss:		0.004993
  validation loss:		0.498850
  validation accuracy:		92.39 %
Epoch 1751 of 2000 took 0.061s
  training loss:		0.004843
  validation loss:		0.503916
  validation accuracy:		92.28 %
Epoch 1752 of 2000 took 0.058s
  training loss:		0.004994
  validation loss:		0.495528
  validation accuracy:		92.39 %
Epoch 1753 of 2000 took 0.059s
  training loss:		0.004850
  validation loss:		0.493975
  validation accuracy:		92.50 %
Epoch 1754 of 2000 took 0.059s
  training loss:		0.004835
  validation loss:		0.498427
  validation accuracy:		92.28 %
Epoch 1755 of 2000 took 0.059s
  training loss:		0.004801
  validation loss:		0.505363
  validation accuracy:		92.17 %
Epoch 1756 of 2000 took 0.059s
  training loss:		0.004900
  validation loss:		0.493966
  validation accuracy:		92.61 %
Epoch 1757 of 2000 took 0.059s
  training loss:		0.004898
  validation loss:		0.503085
  validation accuracy:		92.39 %
Epoch 1758 of 2000 took 0.059s
  training loss:		0.004919
  validation loss:		0.499717
  validation accuracy:		92.39 %
Epoch 1759 of 2000 took 0.059s
  training loss:		0.004786
  validation loss:		0.495987
  validation accuracy:		92.28 %
Epoch 1760 of 2000 took 0.059s
  training loss:		0.004821
  validation loss:		0.500858
  validation accuracy:		92.39 %
Epoch 1761 of 2000 took 0.059s
  training loss:		0.005017
  validation loss:		0.504635
  validation accuracy:		92.28 %
Epoch 1762 of 2000 took 0.059s
  training loss:		0.004560
  validation loss:		0.493511
  validation accuracy:		92.39 %
Epoch 1763 of 2000 took 0.059s
  training loss:		0.004821
  validation loss:		0.506168
  validation accuracy:		92.39 %
Epoch 1764 of 2000 took 0.059s
  training loss:		0.004761
  validation loss:		0.503236
  validation accuracy:		92.28 %
Epoch 1765 of 2000 took 0.059s
  training loss:		0.004882
  validation loss:		0.505889
  validation accuracy:		92.17 %
Epoch 1766 of 2000 took 0.059s
  training loss:		0.004742
  validation loss:		0.500304
  validation accuracy:		92.50 %
Epoch 1767 of 2000 took 0.059s
  training loss:		0.004752
  validation loss:		0.499576
  validation accuracy:		92.39 %
Epoch 1768 of 2000 took 0.059s
  training loss:		0.004844
  validation loss:		0.499333
  validation accuracy:		92.50 %
Epoch 1769 of 2000 took 0.059s
  training loss:		0.004824
  validation loss:		0.502905
  validation accuracy:		92.50 %
Epoch 1770 of 2000 took 0.059s
  training loss:		0.004741
  validation loss:		0.503040
  validation accuracy:		92.39 %
Epoch 1771 of 2000 took 0.059s
  training loss:		0.004630
  validation loss:		0.500006
  validation accuracy:		92.39 %
Epoch 1772 of 2000 took 0.059s
  training loss:		0.004702
  validation loss:		0.507631
  validation accuracy:		92.39 %
Epoch 1773 of 2000 took 0.059s
  training loss:		0.004702
  validation loss:		0.502446
  validation accuracy:		92.39 %
Epoch 1774 of 2000 took 0.059s
  training loss:		0.004789
  validation loss:		0.500313
  validation accuracy:		92.39 %
Epoch 1775 of 2000 took 0.059s
  training loss:		0.004720
  validation loss:		0.503291
  validation accuracy:		92.28 %
Epoch 1776 of 2000 took 0.059s
  training loss:		0.004589
  validation loss:		0.505384
  validation accuracy:		92.50 %
Epoch 1777 of 2000 took 0.059s
  training loss:		0.004828
  validation loss:		0.498973
  validation accuracy:		92.50 %
Epoch 1778 of 2000 took 0.059s
  training loss:		0.004628
  validation loss:		0.504917
  validation accuracy:		92.39 %
Epoch 1779 of 2000 took 0.059s
  training loss:		0.004671
  validation loss:		0.504874
  validation accuracy:		92.28 %
Epoch 1780 of 2000 took 0.059s
  training loss:		0.004726
  validation loss:		0.502859
  validation accuracy:		92.39 %
Epoch 1781 of 2000 took 0.058s
  training loss:		0.004747
  validation loss:		0.506333
  validation accuracy:		92.61 %
Epoch 1782 of 2000 took 0.059s
  training loss:		0.004628
  validation loss:		0.505623
  validation accuracy:		92.39 %
Epoch 1783 of 2000 took 0.058s
  training loss:		0.004722
  validation loss:		0.505166
  validation accuracy:		92.17 %
Epoch 1784 of 2000 took 0.059s
  training loss:		0.004724
  validation loss:		0.499592
  validation accuracy:		92.39 %
Epoch 1785 of 2000 took 0.059s
  training loss:		0.004836
  validation loss:		0.502037
  validation accuracy:		92.39 %
Epoch 1786 of 2000 took 0.059s
  training loss:		0.004439
  validation loss:		0.501165
  validation accuracy:		92.28 %
Epoch 1787 of 2000 took 0.059s
  training loss:		0.004565
  validation loss:		0.508814
  validation accuracy:		92.39 %
Epoch 1788 of 2000 took 0.059s
  training loss:		0.004617
  validation loss:		0.504121
  validation accuracy:		92.28 %
Epoch 1789 of 2000 took 0.059s
  training loss:		0.004560
  validation loss:		0.502209
  validation accuracy:		92.50 %
Epoch 1790 of 2000 took 0.059s
  training loss:		0.004574
  validation loss:		0.504040
  validation accuracy:		92.39 %
Epoch 1791 of 2000 took 0.059s
  training loss:		0.004586
  validation loss:		0.509500
  validation accuracy:		92.28 %
Epoch 1792 of 2000 took 0.059s
  training loss:		0.004612
  validation loss:		0.504019
  validation accuracy:		92.39 %
Epoch 1793 of 2000 took 0.059s
  training loss:		0.004757
  validation loss:		0.511369
  validation accuracy:		92.39 %
Epoch 1794 of 2000 took 0.059s
  training loss:		0.004541
  validation loss:		0.499723
  validation accuracy:		92.72 %
Epoch 1795 of 2000 took 0.059s
  training loss:		0.004762
  validation loss:		0.498834
  validation accuracy:		92.61 %
Epoch 1796 of 2000 took 0.059s
  training loss:		0.004744
  validation loss:		0.511601
  validation accuracy:		92.07 %
Epoch 1797 of 2000 took 0.059s
  training loss:		0.004696
  validation loss:		0.502955
  validation accuracy:		92.39 %
Epoch 1798 of 2000 took 0.059s
  training loss:		0.004342
  validation loss:		0.503642
  validation accuracy:		92.61 %
Epoch 1799 of 2000 took 0.059s
  training loss:		0.004640
  validation loss:		0.507151
  validation accuracy:		92.28 %
Epoch 1800 of 2000 took 0.059s
  training loss:		0.004457
  validation loss:		0.509926
  validation accuracy:		92.39 %
Epoch 1801 of 2000 took 0.059s
  training loss:		0.004577
  validation loss:		0.510288
  validation accuracy:		92.28 %
Epoch 1802 of 2000 took 0.059s
  training loss:		0.004441
  validation loss:		0.512038
  validation accuracy:		92.39 %
Epoch 1803 of 2000 took 0.059s
  training loss:		0.004619
  validation loss:		0.503827
  validation accuracy:		92.39 %
Epoch 1804 of 2000 took 0.059s
  training loss:		0.004493
  validation loss:		0.506597
  validation accuracy:		92.39 %
Epoch 1805 of 2000 took 0.059s
  training loss:		0.004413
  validation loss:		0.507223
  validation accuracy:		92.39 %
Epoch 1806 of 2000 took 0.059s
  training loss:		0.004497
  validation loss:		0.499468
  validation accuracy:		92.61 %
Epoch 1807 of 2000 took 0.059s
  training loss:		0.004634
  validation loss:		0.519481
  validation accuracy:		92.07 %
Epoch 1808 of 2000 took 0.059s
  training loss:		0.004447
  validation loss:		0.502652
  validation accuracy:		92.72 %
Epoch 1809 of 2000 took 0.059s
  training loss:		0.004462
  validation loss:		0.508559
  validation accuracy:		92.50 %
Epoch 1810 of 2000 took 0.059s
  training loss:		0.004339
  validation loss:		0.510708
  validation accuracy:		92.39 %
Epoch 1811 of 2000 took 0.059s
  training loss:		0.004385
  validation loss:		0.509499
  validation accuracy:		92.39 %
Epoch 1812 of 2000 took 0.059s
  training loss:		0.004379
  validation loss:		0.500487
  validation accuracy:		92.72 %
Epoch 1813 of 2000 took 0.059s
  training loss:		0.004453
  validation loss:		0.516125
  validation accuracy:		92.07 %
Epoch 1814 of 2000 took 0.059s
  training loss:		0.004510
  validation loss:		0.506979
  validation accuracy:		92.61 %
Epoch 1815 of 2000 took 0.059s
  training loss:		0.004400
  validation loss:		0.503078
  validation accuracy:		92.17 %
Epoch 1816 of 2000 took 0.059s
  training loss:		0.004410
  validation loss:		0.513674
  validation accuracy:		92.28 %
Epoch 1817 of 2000 took 0.059s
  training loss:		0.004386
  validation loss:		0.508797
  validation accuracy:		92.39 %
Epoch 1818 of 2000 took 0.059s
  training loss:		0.004433
  validation loss:		0.501563
  validation accuracy:		92.72 %
Epoch 1819 of 2000 took 0.059s
  training loss:		0.004469
  validation loss:		0.514625
  validation accuracy:		92.39 %
Epoch 1820 of 2000 took 0.059s
  training loss:		0.004581
  validation loss:		0.512508
  validation accuracy:		92.50 %
Epoch 1821 of 2000 took 0.059s
  training loss:		0.004451
  validation loss:		0.506287
  validation accuracy:		92.28 %
Epoch 1822 of 2000 took 0.059s
  training loss:		0.004165
  validation loss:		0.511527
  validation accuracy:		92.61 %
Epoch 1823 of 2000 took 0.059s
  training loss:		0.004396
  validation loss:		0.508242
  validation accuracy:		92.50 %
Epoch 1824 of 2000 took 0.059s
  training loss:		0.004534
  validation loss:		0.509922
  validation accuracy:		92.28 %
Epoch 1825 of 2000 took 0.059s
  training loss:		0.004282
  validation loss:		0.507154
  validation accuracy:		92.39 %
Epoch 1826 of 2000 took 0.059s
  training loss:		0.004357
  validation loss:		0.507695
  validation accuracy:		92.61 %
Epoch 1827 of 2000 took 0.059s
  training loss:		0.004457
  validation loss:		0.508170
  validation accuracy:		92.50 %
Epoch 1828 of 2000 took 0.059s
  training loss:		0.004496
  validation loss:		0.513986
  validation accuracy:		92.50 %
Epoch 1829 of 2000 took 0.059s
  training loss:		0.004380
  validation loss:		0.509042
  validation accuracy:		92.39 %
Epoch 1830 of 2000 took 0.059s
  training loss:		0.004428
  validation loss:		0.512331
  validation accuracy:		92.50 %
Epoch 1831 of 2000 took 0.059s
  training loss:		0.004410
  validation loss:		0.508140
  validation accuracy:		92.50 %
Epoch 1832 of 2000 took 0.059s
  training loss:		0.004376
  validation loss:		0.509373
  validation accuracy:		92.39 %
Epoch 1833 of 2000 took 0.059s
  training loss:		0.004306
  validation loss:		0.512794
  validation accuracy:		92.61 %
Epoch 1834 of 2000 took 0.059s
  training loss:		0.004177
  validation loss:		0.509399
  validation accuracy:		92.28 %
Epoch 1835 of 2000 took 0.059s
  training loss:		0.004324
  validation loss:		0.516262
  validation accuracy:		92.39 %
Epoch 1836 of 2000 took 0.059s
  training loss:		0.004393
  validation loss:		0.517218
  validation accuracy:		92.28 %
Epoch 1837 of 2000 took 0.059s
  training loss:		0.004440
  validation loss:		0.513652
  validation accuracy:		92.39 %
Epoch 1838 of 2000 took 0.059s
  training loss:		0.004251
  validation loss:		0.513023
  validation accuracy:		92.61 %
Epoch 1839 of 2000 took 0.059s
  training loss:		0.004294
  validation loss:		0.511942
  validation accuracy:		92.50 %
Epoch 1840 of 2000 took 0.059s
  training loss:		0.004216
  validation loss:		0.518608
  validation accuracy:		92.28 %
Epoch 1841 of 2000 took 0.059s
  training loss:		0.004293
  validation loss:		0.510286
  validation accuracy:		92.50 %
Epoch 1842 of 2000 took 0.059s
  training loss:		0.004351
  validation loss:		0.508758
  validation accuracy:		92.39 %
Epoch 1843 of 2000 took 0.059s
  training loss:		0.004396
  validation loss:		0.518641
  validation accuracy:		92.17 %
Epoch 1844 of 2000 took 0.059s
  training loss:		0.004460
  validation loss:		0.514559
  validation accuracy:		92.39 %
Epoch 1845 of 2000 took 0.059s
  training loss:		0.004306
  validation loss:		0.513799
  validation accuracy:		92.50 %
Epoch 1846 of 2000 took 0.059s
  training loss:		0.004241
  validation loss:		0.520293
  validation accuracy:		92.28 %
Epoch 1847 of 2000 took 0.059s
  training loss:		0.004392
  validation loss:		0.511482
  validation accuracy:		92.39 %
Epoch 1848 of 2000 took 0.059s
  training loss:		0.004320
  validation loss:		0.512648
  validation accuracy:		92.39 %
Epoch 1849 of 2000 took 0.059s
  training loss:		0.004098
  validation loss:		0.513313
  validation accuracy:		92.39 %
Epoch 1850 of 2000 took 0.060s
  training loss:		0.004335
  validation loss:		0.511988
  validation accuracy:		92.28 %
Epoch 1851 of 2000 took 0.059s
  training loss:		0.004237
  validation loss:		0.514178
  validation accuracy:		92.50 %
Epoch 1852 of 2000 took 0.059s
  training loss:		0.004111
  validation loss:		0.516021
  validation accuracy:		92.50 %
Epoch 1853 of 2000 took 0.059s
  training loss:		0.004292
  validation loss:		0.512693
  validation accuracy:		92.28 %
Epoch 1854 of 2000 took 0.059s
  training loss:		0.004267
  validation loss:		0.519169
  validation accuracy:		92.17 %
Epoch 1855 of 2000 took 0.059s
  training loss:		0.004269
  validation loss:		0.511410
  validation accuracy:		92.39 %
Epoch 1856 of 2000 took 0.059s
  training loss:		0.004246
  validation loss:		0.512512
  validation accuracy:		92.39 %
Epoch 1857 of 2000 took 0.059s
  training loss:		0.004194
  validation loss:		0.509748
  validation accuracy:		92.61 %
Epoch 1858 of 2000 took 0.059s
  training loss:		0.004052
  validation loss:		0.515663
  validation accuracy:		92.50 %
Epoch 1859 of 2000 took 0.059s
  training loss:		0.004215
  validation loss:		0.517742
  validation accuracy:		92.39 %
Epoch 1860 of 2000 took 0.059s
  training loss:		0.004319
  validation loss:		0.511095
  validation accuracy:		92.50 %
Epoch 1861 of 2000 took 0.059s
  training loss:		0.004309
  validation loss:		0.519643
  validation accuracy:		92.50 %
Epoch 1862 of 2000 took 0.059s
  training loss:		0.004154
  validation loss:		0.514487
  validation accuracy:		92.39 %
Epoch 1863 of 2000 took 0.059s
  training loss:		0.004124
  validation loss:		0.513542
  validation accuracy:		92.28 %
Epoch 1864 of 2000 took 0.059s
  training loss:		0.004171
  validation loss:		0.515849
  validation accuracy:		92.39 %
Epoch 1865 of 2000 took 0.059s
  training loss:		0.004238
  validation loss:		0.517683
  validation accuracy:		92.39 %
Epoch 1866 of 2000 took 0.059s
  training loss:		0.004044
  validation loss:		0.508689
  validation accuracy:		92.72 %
Epoch 1867 of 2000 took 0.059s
  training loss:		0.004236
  validation loss:		0.517419
  validation accuracy:		92.39 %
Epoch 1868 of 2000 took 0.059s
  training loss:		0.004075
  validation loss:		0.506788
  validation accuracy:		92.61 %
Epoch 1869 of 2000 took 0.059s
  training loss:		0.004233
  validation loss:		0.524606
  validation accuracy:		92.17 %
Epoch 1870 of 2000 took 0.059s
  training loss:		0.004070
  validation loss:		0.513427
  validation accuracy:		92.39 %
Epoch 1871 of 2000 took 0.059s
  training loss:		0.004113
  validation loss:		0.512482
  validation accuracy:		92.61 %
Epoch 1872 of 2000 took 0.059s
  training loss:		0.004031
  validation loss:		0.518225
  validation accuracy:		92.28 %
Epoch 1873 of 2000 took 0.059s
  training loss:		0.004116
  validation loss:		0.522861
  validation accuracy:		92.50 %
Epoch 1874 of 2000 took 0.060s
  training loss:		0.004219
  validation loss:		0.517787
  validation accuracy:		92.28 %
Epoch 1875 of 2000 took 0.060s
  training loss:		0.004129
  validation loss:		0.515974
  validation accuracy:		92.50 %
Epoch 1876 of 2000 took 0.060s
  training loss:		0.004039
  validation loss:		0.520805
  validation accuracy:		92.50 %
Epoch 1877 of 2000 took 0.059s
  training loss:		0.004092
  validation loss:		0.515572
  validation accuracy:		92.28 %
Epoch 1878 of 2000 took 0.059s
  training loss:		0.004052
  validation loss:		0.521166
  validation accuracy:		92.50 %
Epoch 1879 of 2000 took 0.060s
  training loss:		0.004253
  validation loss:		0.521505
  validation accuracy:		92.50 %
Epoch 1880 of 2000 took 0.060s
  training loss:		0.004123
  validation loss:		0.520565
  validation accuracy:		92.50 %
Epoch 1881 of 2000 took 0.059s
  training loss:		0.004094
  validation loss:		0.524886
  validation accuracy:		92.28 %
Epoch 1882 of 2000 took 0.060s
  training loss:		0.004175
  validation loss:		0.519114
  validation accuracy:		92.50 %
Epoch 1883 of 2000 took 0.060s
  training loss:		0.003993
  validation loss:		0.520297
  validation accuracy:		92.39 %
Epoch 1884 of 2000 took 0.059s
  training loss:		0.004020
  validation loss:		0.518174
  validation accuracy:		92.39 %
Epoch 1885 of 2000 took 0.059s
  training loss:		0.004000
  validation loss:		0.521304
  validation accuracy:		92.50 %
Epoch 1886 of 2000 took 0.059s
  training loss:		0.004152
  validation loss:		0.518448
  validation accuracy:		92.39 %
Epoch 1887 of 2000 took 0.059s
  training loss:		0.004082
  validation loss:		0.514101
  validation accuracy:		92.61 %
Epoch 1888 of 2000 took 0.059s
  training loss:		0.003914
  validation loss:		0.515827
  validation accuracy:		92.39 %
Epoch 1889 of 2000 took 0.059s
  training loss:		0.004007
  validation loss:		0.518582
  validation accuracy:		92.50 %
Epoch 1890 of 2000 took 0.059s
  training loss:		0.004011
  validation loss:		0.520531
  validation accuracy:		92.50 %
Epoch 1891 of 2000 took 0.059s
  training loss:		0.003872
  validation loss:		0.514889
  validation accuracy:		92.72 %
Epoch 1892 of 2000 took 0.059s
  training loss:		0.003977
  validation loss:		0.522998
  validation accuracy:		92.17 %
Epoch 1893 of 2000 took 0.059s
  training loss:		0.004033
  validation loss:		0.518937
  validation accuracy:		92.28 %
Epoch 1894 of 2000 took 0.059s
  training loss:		0.004043
  validation loss:		0.520191
  validation accuracy:		92.39 %
Epoch 1895 of 2000 took 0.059s
  training loss:		0.004013
  validation loss:		0.525250
  validation accuracy:		92.28 %
Epoch 1896 of 2000 took 0.059s
  training loss:		0.004068
  validation loss:		0.517452
  validation accuracy:		92.61 %
Epoch 1897 of 2000 took 0.059s
  training loss:		0.003968
  validation loss:		0.516939
  validation accuracy:		92.61 %
Epoch 1898 of 2000 took 0.059s
  training loss:		0.004059
  validation loss:		0.525056
  validation accuracy:		92.39 %
Epoch 1899 of 2000 took 0.059s
  training loss:		0.003924
  validation loss:		0.517911
  validation accuracy:		92.61 %
Epoch 1900 of 2000 took 0.059s
  training loss:		0.004138
  validation loss:		0.512879
  validation accuracy:		92.61 %
Epoch 1901 of 2000 took 0.059s
  training loss:		0.003901
  validation loss:		0.523445
  validation accuracy:		92.50 %
Epoch 1902 of 2000 took 0.059s
  training loss:		0.004029
  validation loss:		0.522968
  validation accuracy:		92.28 %
Epoch 1903 of 2000 took 0.059s
  training loss:		0.003972
  validation loss:		0.522897
  validation accuracy:		92.39 %
Epoch 1904 of 2000 took 0.059s
  training loss:		0.004005
  validation loss:		0.517973
  validation accuracy:		92.61 %
Epoch 1905 of 2000 took 0.059s
  training loss:		0.003984
  validation loss:		0.509175
  validation accuracy:		92.61 %
Epoch 1906 of 2000 took 0.060s
  training loss:		0.004008
  validation loss:		0.524648
  validation accuracy:		92.50 %
Epoch 1907 of 2000 took 0.060s
  training loss:		0.003938
  validation loss:		0.520334
  validation accuracy:		92.28 %
Epoch 1908 of 2000 took 0.060s
  training loss:		0.003882
  validation loss:		0.521524
  validation accuracy:		92.61 %
Epoch 1909 of 2000 took 0.060s
  training loss:		0.003861
  validation loss:		0.524008
  validation accuracy:		92.61 %
Epoch 1910 of 2000 took 0.060s
  training loss:		0.003802
  validation loss:		0.526121
  validation accuracy:		92.39 %
Epoch 1911 of 2000 took 0.060s
  training loss:		0.003868
  validation loss:		0.523317
  validation accuracy:		92.50 %
Epoch 1912 of 2000 took 0.060s
  training loss:		0.003870
  validation loss:		0.518514
  validation accuracy:		92.28 %
Epoch 1913 of 2000 took 0.060s
  training loss:		0.003743
  validation loss:		0.522328
  validation accuracy:		92.39 %
Epoch 1914 of 2000 took 0.060s
  training loss:		0.003777
  validation loss:		0.525309
  validation accuracy:		92.50 %
Epoch 1915 of 2000 took 0.060s
  training loss:		0.003959
  validation loss:		0.523139
  validation accuracy:		92.39 %
Epoch 1916 of 2000 took 0.060s
  training loss:		0.004011
  validation loss:		0.523881
  validation accuracy:		92.28 %
Epoch 1917 of 2000 took 0.059s
  training loss:		0.003936
  validation loss:		0.524209
  validation accuracy:		92.28 %
Epoch 1918 of 2000 took 0.059s
  training loss:		0.003978
  validation loss:		0.518298
  validation accuracy:		92.72 %
Epoch 1919 of 2000 took 0.059s
  training loss:		0.003848
  validation loss:		0.523403
  validation accuracy:		92.50 %
Epoch 1920 of 2000 took 0.059s
  training loss:		0.003825
  validation loss:		0.517668
  validation accuracy:		92.50 %
Epoch 1921 of 2000 took 0.059s
  training loss:		0.003825
  validation loss:		0.522108
  validation accuracy:		92.28 %
Epoch 1922 of 2000 took 0.059s
  training loss:		0.003939
  validation loss:		0.524527
  validation accuracy:		92.28 %
Epoch 1923 of 2000 took 0.059s
  training loss:		0.003830
  validation loss:		0.521921
  validation accuracy:		92.50 %
Epoch 1924 of 2000 took 0.059s
  training loss:		0.003906
  validation loss:		0.524376
  validation accuracy:		92.39 %
Epoch 1925 of 2000 took 0.060s
  training loss:		0.003927
  validation loss:		0.521368
  validation accuracy:		92.50 %
Epoch 1926 of 2000 took 0.060s
  training loss:		0.003912
  validation loss:		0.524869
  validation accuracy:		92.28 %
Epoch 1927 of 2000 took 0.060s
  training loss:		0.003692
  validation loss:		0.526484
  validation accuracy:		92.61 %
Epoch 1928 of 2000 took 0.060s
  training loss:		0.003900
  validation loss:		0.522902
  validation accuracy:		92.28 %
Epoch 1929 of 2000 took 0.060s
  training loss:		0.003838
  validation loss:		0.522549
  validation accuracy:		92.39 %
Epoch 1930 of 2000 took 0.060s
  training loss:		0.003839
  validation loss:		0.531791
  validation accuracy:		92.28 %
Epoch 1931 of 2000 took 0.059s
  training loss:		0.003870
  validation loss:		0.523858
  validation accuracy:		92.17 %
Epoch 1932 of 2000 took 0.059s
  training loss:		0.003729
  validation loss:		0.524685
  validation accuracy:		92.50 %
Epoch 1933 of 2000 took 0.059s
  training loss:		0.003923
  validation loss:		0.528758
  validation accuracy:		92.17 %
Epoch 1934 of 2000 took 0.059s
  training loss:		0.003530
  validation loss:		0.522649
  validation accuracy:		92.39 %
Epoch 1935 of 2000 took 0.059s
  training loss:		0.003817
  validation loss:		0.521689
  validation accuracy:		92.72 %
Epoch 1936 of 2000 took 0.059s
  training loss:		0.003854
  validation loss:		0.525652
  validation accuracy:		92.28 %
Epoch 1937 of 2000 took 0.059s
  training loss:		0.003812
  validation loss:		0.518826
  validation accuracy:		92.72 %
Epoch 1938 of 2000 took 0.059s
  training loss:		0.003855
  validation loss:		0.523929
  validation accuracy:		92.28 %
Epoch 1939 of 2000 took 0.059s
  training loss:		0.003816
  validation loss:		0.527232
  validation accuracy:		92.61 %
Epoch 1940 of 2000 took 0.059s
  training loss:		0.003824
  validation loss:		0.530806
  validation accuracy:		92.28 %
Epoch 1941 of 2000 took 0.059s
  training loss:		0.003748
  validation loss:		0.522354
  validation accuracy:		92.28 %
Epoch 1942 of 2000 took 0.060s
  training loss:		0.003805
  validation loss:		0.529764
  validation accuracy:		92.39 %
Epoch 1943 of 2000 took 0.060s
  training loss:		0.003741
  validation loss:		0.519089
  validation accuracy:		92.50 %
Epoch 1944 of 2000 took 0.059s
  training loss:		0.003635
  validation loss:		0.524724
  validation accuracy:		92.28 %
Epoch 1945 of 2000 took 0.059s
  training loss:		0.003743
  validation loss:		0.528079
  validation accuracy:		92.39 %
Epoch 1946 of 2000 took 0.059s
  training loss:		0.003816
  validation loss:		0.527689
  validation accuracy:		92.17 %
Epoch 1947 of 2000 took 0.059s
  training loss:		0.003728
  validation loss:		0.522457
  validation accuracy:		92.39 %
Epoch 1948 of 2000 took 0.059s
  training loss:		0.003702
  validation loss:		0.523682
  validation accuracy:		92.93 %
Epoch 1949 of 2000 took 0.059s
  training loss:		0.003676
  validation loss:		0.530196
  validation accuracy:		92.39 %
Epoch 1950 of 2000 took 0.059s
  training loss:		0.003642
  validation loss:		0.533292
  validation accuracy:		92.17 %
Epoch 1951 of 2000 took 0.059s
  training loss:		0.003872
  validation loss:		0.534549
  validation accuracy:		92.39 %
Epoch 1952 of 2000 took 0.059s
  training loss:		0.003731
  validation loss:		0.524508
  validation accuracy:		92.50 %
Epoch 1953 of 2000 took 0.059s
  training loss:		0.003757
  validation loss:		0.526168
  validation accuracy:		92.61 %
Epoch 1954 of 2000 took 0.059s
  training loss:		0.003639
  validation loss:		0.532491
  validation accuracy:		92.39 %
Epoch 1955 of 2000 took 0.059s
  training loss:		0.003598
  validation loss:		0.525556
  validation accuracy:		92.28 %
Epoch 1956 of 2000 took 0.059s
  training loss:		0.003706
  validation loss:		0.521469
  validation accuracy:		92.72 %
Epoch 1957 of 2000 took 0.059s
  training loss:		0.003667
  validation loss:		0.530378
  validation accuracy:		92.61 %
Epoch 1958 of 2000 took 0.059s
  training loss:		0.003682
  validation loss:		0.530368
  validation accuracy:		92.39 %
Epoch 1959 of 2000 took 0.059s
  training loss:		0.003705
  validation loss:		0.526479
  validation accuracy:		92.50 %
Epoch 1960 of 2000 took 0.059s
  training loss:		0.003643
  validation loss:		0.526487
  validation accuracy:		92.39 %
Epoch 1961 of 2000 took 0.058s
  training loss:		0.003774
  validation loss:		0.532899
  validation accuracy:		92.17 %
Epoch 1962 of 2000 took 0.059s
  training loss:		0.003704
  validation loss:		0.528593
  validation accuracy:		92.28 %
Epoch 1963 of 2000 took 0.059s
  training loss:		0.003651
  validation loss:		0.533239
  validation accuracy:		92.50 %
Epoch 1964 of 2000 took 0.059s
  training loss:		0.003636
  validation loss:		0.526643
  validation accuracy:		92.61 %
Epoch 1965 of 2000 took 0.059s
  training loss:		0.003632
  validation loss:		0.529879
  validation accuracy:		92.28 %
Epoch 1966 of 2000 took 0.059s
  training loss:		0.003662
  validation loss:		0.528485
  validation accuracy:		92.39 %
Epoch 1967 of 2000 took 0.059s
  training loss:		0.003680
  validation loss:		0.529717
  validation accuracy:		92.28 %
Epoch 1968 of 2000 took 0.058s
  training loss:		0.003692
  validation loss:		0.531893
  validation accuracy:		92.61 %
Epoch 1969 of 2000 took 0.059s
  training loss:		0.003662
  validation loss:		0.522976
  validation accuracy:		92.61 %
Epoch 1970 of 2000 took 0.059s
  training loss:		0.003710
  validation loss:		0.526574
  validation accuracy:		92.28 %
Epoch 1971 of 2000 took 0.059s
  training loss:		0.003675
  validation loss:		0.532871
  validation accuracy:		92.39 %
Epoch 1972 of 2000 took 0.059s
  training loss:		0.003633
  validation loss:		0.527856
  validation accuracy:		92.72 %
Epoch 1973 of 2000 took 0.059s
  training loss:		0.003599
  validation loss:		0.530627
  validation accuracy:		92.28 %
Epoch 1974 of 2000 took 0.059s
  training loss:		0.003606
  validation loss:		0.528331
  validation accuracy:		92.39 %
Epoch 1975 of 2000 took 0.059s
  training loss:		0.003595
  validation loss:		0.531349
  validation accuracy:		92.50 %
Epoch 1976 of 2000 took 0.059s
  training loss:		0.003623
  validation loss:		0.530713
  validation accuracy:		92.39 %
Epoch 1977 of 2000 took 0.059s
  training loss:		0.003587
  validation loss:		0.528427
  validation accuracy:		92.50 %
Epoch 1978 of 2000 took 0.059s
  training loss:		0.003656
  validation loss:		0.533074
  validation accuracy:		92.39 %
Epoch 1979 of 2000 took 0.059s
  training loss:		0.003609
  validation loss:		0.531391
  validation accuracy:		92.50 %
Epoch 1980 of 2000 took 0.059s
  training loss:		0.003656
  validation loss:		0.534949
  validation accuracy:		92.39 %
Epoch 1981 of 2000 took 0.059s
  training loss:		0.003560
  validation loss:		0.527857
  validation accuracy:		92.61 %
Epoch 1982 of 2000 took 0.058s
  training loss:		0.003507
  validation loss:		0.533718
  validation accuracy:		92.28 %
Epoch 1983 of 2000 took 0.059s
  training loss:		0.003612
  validation loss:		0.534056
  validation accuracy:		92.28 %
Epoch 1984 of 2000 took 0.059s
  training loss:		0.003626
  validation loss:		0.530976
  validation accuracy:		92.50 %
Epoch 1985 of 2000 took 0.059s
  training loss:		0.003517
  validation loss:		0.528519
  validation accuracy:		92.61 %
Epoch 1986 of 2000 took 0.059s
  training loss:		0.003587
  validation loss:		0.535526
  validation accuracy:		92.39 %
Epoch 1987 of 2000 took 0.059s
  training loss:		0.003573
  validation loss:		0.532105
  validation accuracy:		92.72 %
Epoch 1988 of 2000 took 0.059s
  training loss:		0.003596
  validation loss:		0.527330
  validation accuracy:		92.61 %
Epoch 1989 of 2000 took 0.059s
  training loss:		0.003559
  validation loss:		0.536740
  validation accuracy:		92.50 %
Epoch 1990 of 2000 took 0.059s
  training loss:		0.003513
  validation loss:		0.531557
  validation accuracy:		92.72 %
Epoch 1991 of 2000 took 0.060s
  training loss:		0.003564
  validation loss:		0.531715
  validation accuracy:		92.39 %
Epoch 1992 of 2000 took 0.060s
  training loss:		0.003521
  validation loss:		0.532205
  validation accuracy:		92.72 %
Epoch 1993 of 2000 took 0.059s
  training loss:		0.003527
  validation loss:		0.535256
  validation accuracy:		92.28 %
Epoch 1994 of 2000 took 0.060s
  training loss:		0.003513
  validation loss:		0.530644
  validation accuracy:		92.39 %
Epoch 1995 of 2000 took 0.059s
  training loss:		0.003537
  validation loss:		0.536439
  validation accuracy:		92.61 %
Epoch 1996 of 2000 took 0.059s
  training loss:		0.003601
  validation loss:		0.534409
  validation accuracy:		92.39 %
Epoch 1997 of 2000 took 0.059s
  training loss:		0.003453
  validation loss:		0.536479
  validation accuracy:		92.50 %
Epoch 1998 of 2000 took 0.059s
  training loss:		0.003572
  validation loss:		0.531526
  validation accuracy:		92.61 %
Epoch 1999 of 2000 took 0.059s
  training loss:		0.003519
  validation loss:		0.535177
  validation accuracy:		92.39 %
Epoch 2000 of 2000 took 0.059s
  training loss:		0.003523
  validation loss:		0.533293
  validation accuracy:		92.39 %
Final results:
  test loss:			1.207108
  test accuracy:		85.12 %
