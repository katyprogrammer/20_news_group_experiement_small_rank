Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.044s
  training loss:		2.885888
  validation loss:		2.586604
  validation accuracy:		19.46 %
Epoch 2 of 2000 took 0.039s
  training loss:		2.553050
  validation loss:		2.338741
  validation accuracy:		19.78 %
Epoch 3 of 2000 took 0.052s
  training loss:		2.404669
  validation loss:		2.217831
  validation accuracy:		23.26 %
Epoch 4 of 2000 took 0.076s
  training loss:		2.305382
  validation loss:		2.129977
  validation accuracy:		24.67 %
Epoch 5 of 2000 took 0.053s
  training loss:		2.209353
  validation loss:		2.062311
  validation accuracy:		24.57 %
Epoch 6 of 2000 took 0.045s
  training loss:		2.127664
  validation loss:		1.998959
  validation accuracy:		27.61 %
Epoch 7 of 2000 took 0.042s
  training loss:		2.069185
  validation loss:		1.946822
  validation accuracy:		27.83 %
Epoch 8 of 2000 took 0.039s
  training loss:		2.022675
  validation loss:		1.913104
  validation accuracy:		28.26 %
Epoch 9 of 2000 took 0.039s
  training loss:		1.984400
  validation loss:		1.874915
  validation accuracy:		30.22 %
Epoch 10 of 2000 took 0.039s
  training loss:		1.946424
  validation loss:		1.848660
  validation accuracy:		30.00 %
Epoch 11 of 2000 took 0.039s
  training loss:		1.916086
  validation loss:		1.821889
  validation accuracy:		30.76 %
Epoch 12 of 2000 took 0.038s
  training loss:		1.886260
  validation loss:		1.794576
  validation accuracy:		31.74 %
Epoch 13 of 2000 took 0.038s
  training loss:		1.857870
  validation loss:		1.774260
  validation accuracy:		32.83 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.832983
  validation loss:		1.747521
  validation accuracy:		33.70 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.814209
  validation loss:		1.728385
  validation accuracy:		34.78 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.784532
  validation loss:		1.710137
  validation accuracy:		34.89 %
Epoch 17 of 2000 took 0.036s
  training loss:		1.759683
  validation loss:		1.682465
  validation accuracy:		36.74 %
Epoch 18 of 2000 took 0.035s
  training loss:		1.736870
  validation loss:		1.669980
  validation accuracy:		38.70 %
Epoch 19 of 2000 took 0.035s
  training loss:		1.717973
  validation loss:		1.644973
  validation accuracy:		37.72 %
Epoch 20 of 2000 took 0.035s
  training loss:		1.691347
  validation loss:		1.629055
  validation accuracy:		37.28 %
Epoch 21 of 2000 took 0.035s
  training loss:		1.675219
  validation loss:		1.612850
  validation accuracy:		39.46 %
Epoch 22 of 2000 took 0.035s
  training loss:		1.656808
  validation loss:		1.594341
  validation accuracy:		37.93 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.647875
  validation loss:		1.580323
  validation accuracy:		42.39 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.620257
  validation loss:		1.570460
  validation accuracy:		40.54 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.606154
  validation loss:		1.559694
  validation accuracy:		41.30 %
Epoch 26 of 2000 took 0.036s
  training loss:		1.585481
  validation loss:		1.542125
  validation accuracy:		43.04 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.574088
  validation loss:		1.530261
  validation accuracy:		42.93 %
Epoch 28 of 2000 took 0.054s
  training loss:		1.558682
  validation loss:		1.520938
  validation accuracy:		41.85 %
Epoch 29 of 2000 took 0.051s
  training loss:		1.550214
  validation loss:		1.503850
  validation accuracy:		44.78 %
Epoch 30 of 2000 took 0.044s
  training loss:		1.531735
  validation loss:		1.494244
  validation accuracy:		42.93 %
Epoch 31 of 2000 took 0.040s
  training loss:		1.519130
  validation loss:		1.485399
  validation accuracy:		44.24 %
Epoch 32 of 2000 took 0.037s
  training loss:		1.503552
  validation loss:		1.470761
  validation accuracy:		44.46 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.493421
  validation loss:		1.461935
  validation accuracy:		45.98 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.486534
  validation loss:		1.454957
  validation accuracy:		45.87 %
Epoch 35 of 2000 took 0.035s
  training loss:		1.465274
  validation loss:		1.446303
  validation accuracy:		47.72 %
Epoch 36 of 2000 took 0.035s
  training loss:		1.458207
  validation loss:		1.436520
  validation accuracy:		47.83 %
Epoch 37 of 2000 took 0.036s
  training loss:		1.447123
  validation loss:		1.430908
  validation accuracy:		47.28 %
Epoch 38 of 2000 took 0.035s
  training loss:		1.435456
  validation loss:		1.419945
  validation accuracy:		49.13 %
Epoch 39 of 2000 took 0.035s
  training loss:		1.426037
  validation loss:		1.409428
  validation accuracy:		48.37 %
Epoch 40 of 2000 took 0.035s
  training loss:		1.423530
  validation loss:		1.396358
  validation accuracy:		50.11 %
Epoch 41 of 2000 took 0.035s
  training loss:		1.413048
  validation loss:		1.396200
  validation accuracy:		48.59 %
Epoch 42 of 2000 took 0.035s
  training loss:		1.401062
  validation loss:		1.378495
  validation accuracy:		50.22 %
Epoch 43 of 2000 took 0.035s
  training loss:		1.385082
  validation loss:		1.373105
  validation accuracy:		51.09 %
Epoch 44 of 2000 took 0.035s
  training loss:		1.380609
  validation loss:		1.359121
  validation accuracy:		49.89 %
Epoch 45 of 2000 took 0.035s
  training loss:		1.374908
  validation loss:		1.349313
  validation accuracy:		50.87 %
Epoch 46 of 2000 took 0.035s
  training loss:		1.365328
  validation loss:		1.341300
  validation accuracy:		49.24 %
Epoch 47 of 2000 took 0.035s
  training loss:		1.354076
  validation loss:		1.325805
  validation accuracy:		50.76 %
Epoch 48 of 2000 took 0.035s
  training loss:		1.340201
  validation loss:		1.321757
  validation accuracy:		53.04 %
Epoch 49 of 2000 took 0.036s
  training loss:		1.325719
  validation loss:		1.310774
  validation accuracy:		53.04 %
Epoch 50 of 2000 took 0.035s
  training loss:		1.320887
  validation loss:		1.292600
  validation accuracy:		52.07 %
Epoch 51 of 2000 took 0.035s
  training loss:		1.306236
  validation loss:		1.284823
  validation accuracy:		54.02 %
Epoch 52 of 2000 took 0.035s
  training loss:		1.290873
  validation loss:		1.276980
  validation accuracy:		53.48 %
Epoch 53 of 2000 took 0.035s
  training loss:		1.292005
  validation loss:		1.259453
  validation accuracy:		53.48 %
Epoch 54 of 2000 took 0.035s
  training loss:		1.280065
  validation loss:		1.252526
  validation accuracy:		53.04 %
Epoch 55 of 2000 took 0.035s
  training loss:		1.268262
  validation loss:		1.244555
  validation accuracy:		53.48 %
Epoch 56 of 2000 took 0.035s
  training loss:		1.252793
  validation loss:		1.238928
  validation accuracy:		55.43 %
Epoch 57 of 2000 took 0.035s
  training loss:		1.242929
  validation loss:		1.220684
  validation accuracy:		54.57 %
Epoch 58 of 2000 took 0.035s
  training loss:		1.237951
  validation loss:		1.203768
  validation accuracy:		55.65 %
Epoch 59 of 2000 took 0.035s
  training loss:		1.226780
  validation loss:		1.193068
  validation accuracy:		54.89 %
Epoch 60 of 2000 took 0.035s
  training loss:		1.219774
  validation loss:		1.185039
  validation accuracy:		56.30 %
Epoch 61 of 2000 took 0.035s
  training loss:		1.209343
  validation loss:		1.183733
  validation accuracy:		56.52 %
Epoch 62 of 2000 took 0.035s
  training loss:		1.195796
  validation loss:		1.165354
  validation accuracy:		56.30 %
Epoch 63 of 2000 took 0.035s
  training loss:		1.184435
  validation loss:		1.171989
  validation accuracy:		56.96 %
Epoch 64 of 2000 took 0.035s
  training loss:		1.179981
  validation loss:		1.140368
  validation accuracy:		58.59 %
Epoch 65 of 2000 took 0.035s
  training loss:		1.164727
  validation loss:		1.135234
  validation accuracy:		58.80 %
Epoch 66 of 2000 took 0.035s
  training loss:		1.161142
  validation loss:		1.138565
  validation accuracy:		58.15 %
Epoch 67 of 2000 took 0.038s
  training loss:		1.141358
  validation loss:		1.119128
  validation accuracy:		59.89 %
Epoch 68 of 2000 took 0.035s
  training loss:		1.132171
  validation loss:		1.119099
  validation accuracy:		58.37 %
Epoch 69 of 2000 took 0.035s
  training loss:		1.129674
  validation loss:		1.103575
  validation accuracy:		60.43 %
Epoch 70 of 2000 took 0.035s
  training loss:		1.120781
  validation loss:		1.091827
  validation accuracy:		59.67 %
Epoch 71 of 2000 took 0.035s
  training loss:		1.113274
  validation loss:		1.096714
  validation accuracy:		59.78 %
Epoch 72 of 2000 took 0.035s
  training loss:		1.105686
  validation loss:		1.066494
  validation accuracy:		62.07 %
Epoch 73 of 2000 took 0.035s
  training loss:		1.099758
  validation loss:		1.077218
  validation accuracy:		60.54 %
Epoch 74 of 2000 took 0.035s
  training loss:		1.082305
  validation loss:		1.048904
  validation accuracy:		62.39 %
Epoch 75 of 2000 took 0.035s
  training loss:		1.071222
  validation loss:		1.043023
  validation accuracy:		62.17 %
Epoch 76 of 2000 took 0.035s
  training loss:		1.064540
  validation loss:		1.030056
  validation accuracy:		63.04 %
Epoch 77 of 2000 took 0.035s
  training loss:		1.059704
  validation loss:		1.021070
  validation accuracy:		63.80 %
Epoch 78 of 2000 took 0.035s
  training loss:		1.050340
  validation loss:		1.028364
  validation accuracy:		62.28 %
Epoch 79 of 2000 took 0.035s
  training loss:		1.036680
  validation loss:		1.006587
  validation accuracy:		64.35 %
Epoch 80 of 2000 took 0.035s
  training loss:		1.036872
  validation loss:		0.997872
  validation accuracy:		64.57 %
Epoch 81 of 2000 took 0.036s
  training loss:		1.025381
  validation loss:		1.012241
  validation accuracy:		62.83 %
Epoch 82 of 2000 took 0.035s
  training loss:		1.018752
  validation loss:		0.981538
  validation accuracy:		64.89 %
Epoch 83 of 2000 took 0.035s
  training loss:		1.007143
  validation loss:		0.977208
  validation accuracy:		65.11 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.999343
  validation loss:		0.988784
  validation accuracy:		63.70 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.998059
  validation loss:		0.969953
  validation accuracy:		64.02 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.982351
  validation loss:		0.952343
  validation accuracy:		66.30 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.975293
  validation loss:		0.944709
  validation accuracy:		66.30 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.972048
  validation loss:		0.945636
  validation accuracy:		65.00 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.963835
  validation loss:		0.928087
  validation accuracy:		67.50 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.960939
  validation loss:		0.921165
  validation accuracy:		66.96 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.953704
  validation loss:		0.903808
  validation accuracy:		68.59 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.941969
  validation loss:		0.910117
  validation accuracy:		68.04 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.931508
  validation loss:		0.911308
  validation accuracy:		67.07 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.922309
  validation loss:		0.898192
  validation accuracy:		67.83 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.927132
  validation loss:		0.883941
  validation accuracy:		69.13 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.915067
  validation loss:		0.869899
  validation accuracy:		69.46 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.912147
  validation loss:		0.870749
  validation accuracy:		69.46 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.895910
  validation loss:		0.860841
  validation accuracy:		69.78 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.897101
  validation loss:		0.860427
  validation accuracy:		69.67 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.887376
  validation loss:		0.845643
  validation accuracy:		70.87 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.877787
  validation loss:		0.847800
  validation accuracy:		70.76 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.880456
  validation loss:		0.831475
  validation accuracy:		71.41 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.868526
  validation loss:		0.827398
  validation accuracy:		71.41 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.858566
  validation loss:		0.828668
  validation accuracy:		71.63 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.864236
  validation loss:		0.829027
  validation accuracy:		71.30 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.849581
  validation loss:		0.823257
  validation accuracy:		71.52 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.837111
  validation loss:		0.813104
  validation accuracy:		72.61 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.833527
  validation loss:		0.803328
  validation accuracy:		73.04 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.828236
  validation loss:		0.792997
  validation accuracy:		73.59 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.817374
  validation loss:		0.786826
  validation accuracy:		73.59 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.811311
  validation loss:		0.786493
  validation accuracy:		73.48 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.817833
  validation loss:		0.770319
  validation accuracy:		73.91 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.803055
  validation loss:		0.758181
  validation accuracy:		74.46 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.813094
  validation loss:		0.765428
  validation accuracy:		74.57 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.784311
  validation loss:		0.746250
  validation accuracy:		74.78 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.778928
  validation loss:		0.745689
  validation accuracy:		74.35 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.784801
  validation loss:		0.746781
  validation accuracy:		74.57 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.782347
  validation loss:		0.739175
  validation accuracy:		75.76 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.773146
  validation loss:		0.739957
  validation accuracy:		75.65 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.773068
  validation loss:		0.737373
  validation accuracy:		75.87 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.760181
  validation loss:		0.721631
  validation accuracy:		76.20 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.760866
  validation loss:		0.722507
  validation accuracy:		76.85 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.760621
  validation loss:		0.717928
  validation accuracy:		76.30 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.745662
  validation loss:		0.705267
  validation accuracy:		76.96 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.745055
  validation loss:		0.703868
  validation accuracy:		76.96 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.743864
  validation loss:		0.704259
  validation accuracy:		77.28 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.738766
  validation loss:		0.712980
  validation accuracy:		76.41 %
Epoch 128 of 2000 took 0.036s
  training loss:		0.737489
  validation loss:		0.692840
  validation accuracy:		77.72 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.736353
  validation loss:		0.695885
  validation accuracy:		77.93 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.723709
  validation loss:		0.690329
  validation accuracy:		78.37 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.724767
  validation loss:		0.691444
  validation accuracy:		78.15 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.718233
  validation loss:		0.686889
  validation accuracy:		77.83 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.709983
  validation loss:		0.678021
  validation accuracy:		78.70 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.716113
  validation loss:		0.703136
  validation accuracy:		77.50 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.714063
  validation loss:		0.687701
  validation accuracy:		78.15 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.714750
  validation loss:		0.664595
  validation accuracy:		78.91 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.708894
  validation loss:		0.665753
  validation accuracy:		78.91 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.712015
  validation loss:		0.693831
  validation accuracy:		77.50 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.700880
  validation loss:		0.686715
  validation accuracy:		78.37 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.702545
  validation loss:		0.673186
  validation accuracy:		78.91 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.703820
  validation loss:		0.659240
  validation accuracy:		78.59 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.704311
  validation loss:		0.653352
  validation accuracy:		79.24 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.692505
  validation loss:		0.669734
  validation accuracy:		79.46 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.696084
  validation loss:		0.647886
  validation accuracy:		79.46 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.690621
  validation loss:		0.667751
  validation accuracy:		78.80 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.693727
  validation loss:		0.647555
  validation accuracy:		79.46 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.680740
  validation loss:		0.671416
  validation accuracy:		78.91 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.681390
  validation loss:		0.664291
  validation accuracy:		79.13 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.682187
  validation loss:		0.659322
  validation accuracy:		79.13 %
Epoch 150 of 2000 took 0.036s
  training loss:		0.679199
  validation loss:		0.641550
  validation accuracy:		80.00 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.674879
  validation loss:		0.642532
  validation accuracy:		80.33 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.676406
  validation loss:		0.653474
  validation accuracy:		79.67 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.675857
  validation loss:		0.635959
  validation accuracy:		80.54 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.677541
  validation loss:		0.656698
  validation accuracy:		79.57 %
Epoch 155 of 2000 took 0.036s
  training loss:		0.680857
  validation loss:		0.627893
  validation accuracy:		79.78 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.663395
  validation loss:		0.628195
  validation accuracy:		80.87 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.669609
  validation loss:		0.623424
  validation accuracy:		80.22 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.669226
  validation loss:		0.645352
  validation accuracy:		80.11 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.666622
  validation loss:		0.628144
  validation accuracy:		80.22 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.659377
  validation loss:		0.615523
  validation accuracy:		81.20 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.663703
  validation loss:		0.650894
  validation accuracy:		79.02 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.665246
  validation loss:		0.667637
  validation accuracy:		78.48 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.660466
  validation loss:		0.620773
  validation accuracy:		80.65 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.656095
  validation loss:		0.629339
  validation accuracy:		80.43 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.655790
  validation loss:		0.614907
  validation accuracy:		80.98 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.649078
  validation loss:		0.634981
  validation accuracy:		80.54 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.647940
  validation loss:		0.618029
  validation accuracy:		80.87 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.647419
  validation loss:		0.623315
  validation accuracy:		80.65 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.659073
  validation loss:		0.631548
  validation accuracy:		80.33 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.650742
  validation loss:		0.615278
  validation accuracy:		80.43 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.652138
  validation loss:		0.606396
  validation accuracy:		80.65 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.646855
  validation loss:		0.626914
  validation accuracy:		80.43 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.642035
  validation loss:		0.620485
  validation accuracy:		80.33 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.645166
  validation loss:		0.628349
  validation accuracy:		79.78 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.650815
  validation loss:		0.615814
  validation accuracy:		80.98 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.650623
  validation loss:		0.622360
  validation accuracy:		80.65 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.640726
  validation loss:		0.604106
  validation accuracy:		81.09 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.647374
  validation loss:		0.607039
  validation accuracy:		80.87 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.645883
  validation loss:		0.612905
  validation accuracy:		80.65 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.635003
  validation loss:		0.607736
  validation accuracy:		80.33 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.643173
  validation loss:		0.608447
  validation accuracy:		80.76 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.636203
  validation loss:		0.614022
  validation accuracy:		80.76 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.634200
  validation loss:		0.607424
  validation accuracy:		80.11 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.628644
  validation loss:		0.619632
  validation accuracy:		79.89 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.634712
  validation loss:		0.600174
  validation accuracy:		80.98 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.638682
  validation loss:		0.599723
  validation accuracy:		80.98 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.637363
  validation loss:		0.628458
  validation accuracy:		79.46 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.637926
  validation loss:		0.602972
  validation accuracy:		80.43 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.637207
  validation loss:		0.598090
  validation accuracy:		80.76 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.634197
  validation loss:		0.604334
  validation accuracy:		80.65 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.631337
  validation loss:		0.593855
  validation accuracy:		81.09 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.645731
  validation loss:		0.601330
  validation accuracy:		80.43 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.638702
  validation loss:		0.602547
  validation accuracy:		80.54 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.626113
  validation loss:		0.593315
  validation accuracy:		81.09 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.621492
  validation loss:		0.618107
  validation accuracy:		80.43 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.631000
  validation loss:		0.610111
  validation accuracy:		79.35 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.620131
  validation loss:		0.634650
  validation accuracy:		79.57 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.634786
  validation loss:		0.620693
  validation accuracy:		79.57 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.631633
  validation loss:		0.595302
  validation accuracy:		81.41 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.633473
  validation loss:		0.602962
  validation accuracy:		81.09 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.626841
  validation loss:		0.596048
  validation accuracy:		80.65 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.614717
  validation loss:		0.623568
  validation accuracy:		79.67 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.625610
  validation loss:		0.593590
  validation accuracy:		80.98 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.621966
  validation loss:		0.598124
  validation accuracy:		80.54 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.628257
  validation loss:		0.610833
  validation accuracy:		79.67 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.621580
  validation loss:		0.597404
  validation accuracy:		80.11 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.625419
  validation loss:		0.588759
  validation accuracy:		80.98 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.624199
  validation loss:		0.590350
  validation accuracy:		80.98 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.620230
  validation loss:		0.593528
  validation accuracy:		80.54 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.622613
  validation loss:		0.592972
  validation accuracy:		80.87 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.622150
  validation loss:		0.599111
  validation accuracy:		80.76 %
Epoch 212 of 2000 took 0.037s
  training loss:		0.629417
  validation loss:		0.606365
  validation accuracy:		80.54 %
Epoch 213 of 2000 took 0.036s
  training loss:		0.621035
  validation loss:		0.600359
  validation accuracy:		80.11 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.626071
  validation loss:		0.596611
  validation accuracy:		80.54 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.619190
  validation loss:		0.635285
  validation accuracy:		78.59 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.627759
  validation loss:		0.602304
  validation accuracy:		80.76 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.617237
  validation loss:		0.605419
  validation accuracy:		80.54 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.623485
  validation loss:		0.584319
  validation accuracy:		81.30 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.621385
  validation loss:		0.603758
  validation accuracy:		80.76 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.611531
  validation loss:		0.588563
  validation accuracy:		81.85 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.628935
  validation loss:		0.596333
  validation accuracy:		80.76 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.620670
  validation loss:		0.598355
  validation accuracy:		80.87 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.619182
  validation loss:		0.598963
  validation accuracy:		80.33 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.615219
  validation loss:		0.587503
  validation accuracy:		80.65 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.616517
  validation loss:		0.601450
  validation accuracy:		80.87 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.619694
  validation loss:		0.586950
  validation accuracy:		81.85 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.621813
  validation loss:		0.587371
  validation accuracy:		81.20 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.630409
  validation loss:		0.601378
  validation accuracy:		80.22 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.608509
  validation loss:		0.604401
  validation accuracy:		80.87 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.615698
  validation loss:		0.608064
  validation accuracy:		80.43 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.620378
  validation loss:		0.593310
  validation accuracy:		80.87 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.610961
  validation loss:		0.596964
  validation accuracy:		80.22 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.616674
  validation loss:		0.582511
  validation accuracy:		81.52 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.618219
  validation loss:		0.596690
  validation accuracy:		80.87 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.612041
  validation loss:		0.602985
  validation accuracy:		80.98 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.618382
  validation loss:		0.581850
  validation accuracy:		81.63 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.606936
  validation loss:		0.595357
  validation accuracy:		80.54 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.609435
  validation loss:		0.592539
  validation accuracy:		81.09 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.614041
  validation loss:		0.584827
  validation accuracy:		81.09 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.619298
  validation loss:		0.589455
  validation accuracy:		80.65 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.615876
  validation loss:		0.586682
  validation accuracy:		80.87 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.615929
  validation loss:		0.590489
  validation accuracy:		80.76 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.609305
  validation loss:		0.600336
  validation accuracy:		80.11 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.612345
  validation loss:		0.591859
  validation accuracy:		80.87 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.611214
  validation loss:		0.597260
  validation accuracy:		80.87 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.605772
  validation loss:		0.583610
  validation accuracy:		81.30 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.609526
  validation loss:		0.596834
  validation accuracy:		81.09 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.615545
  validation loss:		0.601229
  validation accuracy:		80.76 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.609817
  validation loss:		0.622188
  validation accuracy:		80.22 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.608625
  validation loss:		0.582172
  validation accuracy:		82.61 %
Epoch 251 of 2000 took 0.036s
  training loss:		0.613645
  validation loss:		0.583801
  validation accuracy:		82.93 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.615029
  validation loss:		0.592077
  validation accuracy:		81.30 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.599272
  validation loss:		0.605434
  validation accuracy:		80.54 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.607492
  validation loss:		0.587046
  validation accuracy:		81.30 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.612651
  validation loss:		0.615283
  validation accuracy:		80.22 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.597107
  validation loss:		0.582139
  validation accuracy:		81.30 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.612246
  validation loss:		0.591199
  validation accuracy:		81.85 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.604178
  validation loss:		0.586515
  validation accuracy:		81.30 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.606407
  validation loss:		0.596277
  validation accuracy:		80.98 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.609771
  validation loss:		0.609562
  validation accuracy:		80.11 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.609924
  validation loss:		0.584063
  validation accuracy:		82.39 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.610686
  validation loss:		0.614156
  validation accuracy:		79.78 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.614314
  validation loss:		0.590477
  validation accuracy:		80.98 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.613753
  validation loss:		0.590129
  validation accuracy:		81.20 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.610799
  validation loss:		0.593777
  validation accuracy:		80.76 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.611904
  validation loss:		0.593372
  validation accuracy:		80.98 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.594268
  validation loss:		0.616527
  validation accuracy:		79.89 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.603204
  validation loss:		0.597671
  validation accuracy:		80.87 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.597888
  validation loss:		0.583373
  validation accuracy:		81.63 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.599891
  validation loss:		0.590329
  validation accuracy:		80.87 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.612359
  validation loss:		0.597826
  validation accuracy:		80.54 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.589522
  validation loss:		0.581378
  validation accuracy:		81.74 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.606690
  validation loss:		0.594079
  validation accuracy:		81.30 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.611167
  validation loss:		0.600278
  validation accuracy:		80.33 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.608935
  validation loss:		0.594565
  validation accuracy:		81.20 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.600666
  validation loss:		0.591850
  validation accuracy:		81.30 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.602509
  validation loss:		0.588230
  validation accuracy:		81.74 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.603198
  validation loss:		0.604535
  validation accuracy:		80.43 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.606914
  validation loss:		0.604050
  validation accuracy:		81.41 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.604986
  validation loss:		0.619943
  validation accuracy:		80.43 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.599470
  validation loss:		0.581069
  validation accuracy:		81.52 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.605030
  validation loss:		0.587997
  validation accuracy:		82.39 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.613345
  validation loss:		0.590839
  validation accuracy:		80.98 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.593652
  validation loss:		0.575937
  validation accuracy:		82.72 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.598624
  validation loss:		0.587545
  validation accuracy:		81.96 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.604745
  validation loss:		0.591475
  validation accuracy:		81.09 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.601709
  validation loss:		0.584253
  validation accuracy:		81.41 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.599476
  validation loss:		0.581885
  validation accuracy:		81.74 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.596828
  validation loss:		0.579103
  validation accuracy:		81.63 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.594843
  validation loss:		0.608482
  validation accuracy:		80.65 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.612355
  validation loss:		0.579341
  validation accuracy:		81.74 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.605395
  validation loss:		0.592799
  validation accuracy:		81.85 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.599046
  validation loss:		0.577452
  validation accuracy:		82.72 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.594653
  validation loss:		0.597483
  validation accuracy:		81.41 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.600894
  validation loss:		0.593148
  validation accuracy:		80.87 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.615905
  validation loss:		0.585241
  validation accuracy:		81.20 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.592432
  validation loss:		0.589567
  validation accuracy:		82.28 %
Epoch 298 of 2000 took 0.036s
  training loss:		0.601888
  validation loss:		0.593774
  validation accuracy:		81.52 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.601373
  validation loss:		0.586238
  validation accuracy:		82.50 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.618807
  validation loss:		0.604148
  validation accuracy:		80.43 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.599663
  validation loss:		0.586126
  validation accuracy:		81.52 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.602620
  validation loss:		0.586953
  validation accuracy:		81.30 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.606960
  validation loss:		0.591755
  validation accuracy:		80.76 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.607589
  validation loss:		0.583090
  validation accuracy:		81.96 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.598221
  validation loss:		0.598781
  validation accuracy:		81.74 %
Epoch 306 of 2000 took 0.036s
  training loss:		0.605421
  validation loss:		0.586003
  validation accuracy:		82.07 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.612676
  validation loss:		0.592448
  validation accuracy:		81.41 %
Epoch 308 of 2000 took 0.036s
  training loss:		0.604966
  validation loss:		0.591798
  validation accuracy:		80.98 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.609313
  validation loss:		0.578432
  validation accuracy:		81.96 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.594007
  validation loss:		0.593462
  validation accuracy:		81.41 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.601116
  validation loss:		0.586467
  validation accuracy:		81.30 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.598399
  validation loss:		0.578692
  validation accuracy:		82.07 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.600988
  validation loss:		0.597738
  validation accuracy:		81.63 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.605828
  validation loss:		0.587874
  validation accuracy:		81.41 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.601770
  validation loss:		0.600392
  validation accuracy:		80.65 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.596704
  validation loss:		0.584435
  validation accuracy:		81.85 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.593532
  validation loss:		0.597487
  validation accuracy:		81.09 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.595413
  validation loss:		0.593948
  validation accuracy:		82.17 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.602933
  validation loss:		0.585692
  validation accuracy:		81.20 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.601247
  validation loss:		0.580668
  validation accuracy:		82.83 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.604953
  validation loss:		0.591458
  validation accuracy:		82.17 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.604200
  validation loss:		0.593658
  validation accuracy:		82.07 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.606676
  validation loss:		0.587879
  validation accuracy:		81.63 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.598238
  validation loss:		0.605183
  validation accuracy:		80.33 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.601744
  validation loss:		0.590778
  validation accuracy:		81.41 %
Epoch 326 of 2000 took 0.036s
  training loss:		0.595900
  validation loss:		0.606084
  validation accuracy:		80.22 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.602984
  validation loss:		0.581394
  validation accuracy:		82.50 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.600817
  validation loss:		0.587271
  validation accuracy:		82.07 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.597876
  validation loss:		0.596349
  validation accuracy:		81.63 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.604087
  validation loss:		0.606569
  validation accuracy:		80.76 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.599785
  validation loss:		0.613752
  validation accuracy:		80.22 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.591847
  validation loss:		0.593952
  validation accuracy:		81.85 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.596751
  validation loss:		0.588545
  validation accuracy:		81.41 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.602459
  validation loss:		0.576483
  validation accuracy:		82.83 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.602620
  validation loss:		0.586888
  validation accuracy:		82.07 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.594129
  validation loss:		0.596804
  validation accuracy:		81.41 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.602170
  validation loss:		0.579529
  validation accuracy:		81.63 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.600620
  validation loss:		0.601942
  validation accuracy:		80.98 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.591456
  validation loss:		0.593680
  validation accuracy:		81.20 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.611268
  validation loss:		0.603008
  validation accuracy:		80.87 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.611568
  validation loss:		0.579249
  validation accuracy:		81.85 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.599194
  validation loss:		0.585222
  validation accuracy:		81.52 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.602530
  validation loss:		0.586398
  validation accuracy:		81.20 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.603593
  validation loss:		0.598204
  validation accuracy:		80.54 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.596656
  validation loss:		0.592459
  validation accuracy:		81.20 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.591482
  validation loss:		0.582996
  validation accuracy:		82.07 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.597797
  validation loss:		0.588712
  validation accuracy:		82.17 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.598392
  validation loss:		0.579358
  validation accuracy:		81.85 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.598212
  validation loss:		0.611390
  validation accuracy:		79.89 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.601278
  validation loss:		0.592460
  validation accuracy:		81.09 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.600961
  validation loss:		0.589737
  validation accuracy:		81.09 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.600876
  validation loss:		0.590418
  validation accuracy:		81.74 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.600444
  validation loss:		0.589108
  validation accuracy:		81.30 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.597080
  validation loss:		0.582335
  validation accuracy:		81.52 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.600117
  validation loss:		0.583932
  validation accuracy:		82.07 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.595974
  validation loss:		0.587852
  validation accuracy:		82.39 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.599277
  validation loss:		0.594736
  validation accuracy:		80.87 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.604372
  validation loss:		0.581300
  validation accuracy:		81.85 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.606729
  validation loss:		0.589670
  validation accuracy:		81.20 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.599338
  validation loss:		0.595058
  validation accuracy:		81.52 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.600582
  validation loss:		0.600156
  validation accuracy:		80.43 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.592070
  validation loss:		0.599700
  validation accuracy:		80.65 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.589922
  validation loss:		0.616937
  validation accuracy:		79.89 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.594106
  validation loss:		0.592314
  validation accuracy:		81.41 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.596754
  validation loss:		0.587138
  validation accuracy:		81.41 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.599095
  validation loss:		0.610469
  validation accuracy:		80.98 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.602606
  validation loss:		0.608382
  validation accuracy:		80.43 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.591270
  validation loss:		0.596150
  validation accuracy:		81.20 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.592632
  validation loss:		0.588735
  validation accuracy:		81.74 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.600933
  validation loss:		0.581260
  validation accuracy:		81.74 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.602947
  validation loss:		0.582690
  validation accuracy:		83.04 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.596573
  validation loss:		0.611235
  validation accuracy:		80.76 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.608263
  validation loss:		0.595142
  validation accuracy:		81.63 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.596472
  validation loss:		0.586122
  validation accuracy:		82.07 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.602112
  validation loss:		0.592622
  validation accuracy:		81.74 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.600779
  validation loss:		0.583231
  validation accuracy:		81.74 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.602253
  validation loss:		0.588587
  validation accuracy:		80.98 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.606270
  validation loss:		0.606953
  validation accuracy:		80.33 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.599724
  validation loss:		0.589011
  validation accuracy:		81.96 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.596384
  validation loss:		0.593190
  validation accuracy:		81.30 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.599656
  validation loss:		0.585441
  validation accuracy:		81.85 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.582143
  validation loss:		0.580737
  validation accuracy:		82.28 %
Epoch 383 of 2000 took 0.036s
  training loss:		0.597445
  validation loss:		0.584974
  validation accuracy:		81.52 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.593531
  validation loss:		0.585419
  validation accuracy:		82.17 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.598744
  validation loss:		0.588348
  validation accuracy:		81.96 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.601093
  validation loss:		0.582069
  validation accuracy:		82.07 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.594478
  validation loss:		0.584854
  validation accuracy:		81.20 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.592871
  validation loss:		0.589800
  validation accuracy:		81.74 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.600642
  validation loss:		0.591962
  validation accuracy:		81.74 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.597576
  validation loss:		0.594819
  validation accuracy:		81.30 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.601823
  validation loss:		0.633532
  validation accuracy:		80.54 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.592506
  validation loss:		0.584459
  validation accuracy:		80.98 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.591274
  validation loss:		0.584073
  validation accuracy:		82.17 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.598011
  validation loss:		0.606017
  validation accuracy:		80.65 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.593614
  validation loss:		0.624532
  validation accuracy:		80.33 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.601486
  validation loss:		0.602190
  validation accuracy:		81.09 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.598315
  validation loss:		0.580333
  validation accuracy:		82.07 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.599157
  validation loss:		0.604598
  validation accuracy:		81.09 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.586692
  validation loss:		0.587677
  validation accuracy:		80.98 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.595444
  validation loss:		0.603435
  validation accuracy:		81.09 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.588975
  validation loss:		0.606120
  validation accuracy:		80.87 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.586203
  validation loss:		0.588954
  validation accuracy:		81.52 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.599305
  validation loss:		0.588220
  validation accuracy:		81.09 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.600309
  validation loss:		0.586513
  validation accuracy:		81.74 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.590024
  validation loss:		0.592893
  validation accuracy:		81.30 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.597089
  validation loss:		0.594429
  validation accuracy:		80.87 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.600846
  validation loss:		0.582220
  validation accuracy:		81.74 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.601808
  validation loss:		0.602913
  validation accuracy:		80.65 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.585263
  validation loss:		0.587865
  validation accuracy:		81.30 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.589144
  validation loss:		0.587205
  validation accuracy:		82.07 %
Epoch 411 of 2000 took 0.036s
  training loss:		0.592981
  validation loss:		0.591979
  validation accuracy:		81.20 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.595076
  validation loss:		0.584238
  validation accuracy:		82.07 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.608907
  validation loss:		0.586994
  validation accuracy:		81.52 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.591707
  validation loss:		0.607952
  validation accuracy:		81.41 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.581465
  validation loss:		0.596179
  validation accuracy:		81.30 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.590428
  validation loss:		0.588110
  validation accuracy:		81.52 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.598317
  validation loss:		0.586437
  validation accuracy:		81.85 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.596230
  validation loss:		0.607033
  validation accuracy:		81.09 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.596940
  validation loss:		0.582663
  validation accuracy:		81.41 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.590952
  validation loss:		0.580853
  validation accuracy:		82.39 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.596621
  validation loss:		0.591455
  validation accuracy:		81.63 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.595665
  validation loss:		0.594577
  validation accuracy:		80.87 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.590107
  validation loss:		0.596360
  validation accuracy:		81.09 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.597931
  validation loss:		0.583331
  validation accuracy:		81.63 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.591693
  validation loss:		0.594371
  validation accuracy:		81.41 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.595526
  validation loss:		0.598524
  validation accuracy:		80.76 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.588512
  validation loss:		0.591459
  validation accuracy:		81.30 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.596528
  validation loss:		0.581333
  validation accuracy:		81.41 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.596591
  validation loss:		0.583689
  validation accuracy:		81.96 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.598282
  validation loss:		0.594900
  validation accuracy:		81.52 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.592365
  validation loss:		0.588835
  validation accuracy:		81.52 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.594742
  validation loss:		0.587301
  validation accuracy:		81.85 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.600234
  validation loss:		0.593309
  validation accuracy:		81.74 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.591726
  validation loss:		0.590053
  validation accuracy:		81.20 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.578132
  validation loss:		0.588755
  validation accuracy:		81.74 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.592396
  validation loss:		0.585917
  validation accuracy:		81.52 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.592071
  validation loss:		0.584913
  validation accuracy:		81.63 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.596008
  validation loss:		0.580019
  validation accuracy:		81.74 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.593186
  validation loss:		0.579121
  validation accuracy:		81.74 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.594799
  validation loss:		0.588425
  validation accuracy:		81.30 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.597755
  validation loss:		0.579284
  validation accuracy:		81.85 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.591235
  validation loss:		0.581735
  validation accuracy:		82.61 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.587913
  validation loss:		0.582493
  validation accuracy:		81.63 %
Epoch 444 of 2000 took 0.037s
  training loss:		0.577126
  validation loss:		0.581119
  validation accuracy:		82.17 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.597526
  validation loss:		0.590162
  validation accuracy:		81.63 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.592597
  validation loss:		0.595030
  validation accuracy:		81.85 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.595195
  validation loss:		0.592577
  validation accuracy:		81.41 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.589757
  validation loss:		0.592933
  validation accuracy:		81.41 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.590240
  validation loss:		0.590428
  validation accuracy:		81.30 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.591695
  validation loss:		0.591248
  validation accuracy:		80.98 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.591178
  validation loss:		0.589346
  validation accuracy:		81.85 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.588214
  validation loss:		0.579873
  validation accuracy:		81.63 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.591969
  validation loss:		0.577972
  validation accuracy:		81.74 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.584275
  validation loss:		0.581010
  validation accuracy:		81.74 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.592048
  validation loss:		0.577175
  validation accuracy:		81.63 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.584293
  validation loss:		0.583329
  validation accuracy:		81.85 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.592638
  validation loss:		0.587087
  validation accuracy:		81.74 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.589217
  validation loss:		0.589180
  validation accuracy:		81.96 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.598892
  validation loss:		0.584163
  validation accuracy:		81.74 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.592037
  validation loss:		0.585142
  validation accuracy:		81.96 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.580595
  validation loss:		0.578515
  validation accuracy:		81.74 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.588305
  validation loss:		0.593452
  validation accuracy:		81.20 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.595349
  validation loss:		0.598706
  validation accuracy:		80.33 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.593342
  validation loss:		0.582297
  validation accuracy:		81.52 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.593032
  validation loss:		0.583228
  validation accuracy:		81.85 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.588191
  validation loss:		0.576792
  validation accuracy:		81.30 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.585413
  validation loss:		0.601672
  validation accuracy:		81.30 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.594352
  validation loss:		0.586563
  validation accuracy:		81.52 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.591798
  validation loss:		0.583900
  validation accuracy:		82.07 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.594260
  validation loss:		0.596344
  validation accuracy:		81.52 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.594390
  validation loss:		0.577083
  validation accuracy:		82.07 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.584813
  validation loss:		0.575051
  validation accuracy:		81.74 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.590695
  validation loss:		0.598888
  validation accuracy:		81.41 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.584637
  validation loss:		0.576379
  validation accuracy:		81.74 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.589822
  validation loss:		0.580752
  validation accuracy:		81.52 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.583277
  validation loss:		0.574961
  validation accuracy:		82.28 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.583941
  validation loss:		0.577925
  validation accuracy:		81.30 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.590347
  validation loss:		0.609057
  validation accuracy:		80.87 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.588602
  validation loss:		0.581022
  validation accuracy:		81.85 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.579982
  validation loss:		0.592660
  validation accuracy:		81.85 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.589660
  validation loss:		0.587616
  validation accuracy:		81.20 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.587863
  validation loss:		0.579365
  validation accuracy:		81.30 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.586280
  validation loss:		0.584386
  validation accuracy:		82.07 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.580600
  validation loss:		0.575743
  validation accuracy:		81.41 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.582156
  validation loss:		0.578531
  validation accuracy:		82.07 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.580606
  validation loss:		0.575789
  validation accuracy:		81.52 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.584552
  validation loss:		0.591864
  validation accuracy:		80.87 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.583030
  validation loss:		0.590544
  validation accuracy:		81.96 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.589427
  validation loss:		0.584642
  validation accuracy:		81.96 %
Epoch 490 of 2000 took 0.036s
  training loss:		0.580822
  validation loss:		0.584861
  validation accuracy:		81.52 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.579616
  validation loss:		0.586308
  validation accuracy:		81.63 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.586822
  validation loss:		0.578768
  validation accuracy:		81.85 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.586479
  validation loss:		0.588313
  validation accuracy:		81.52 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.577578
  validation loss:		0.576176
  validation accuracy:		81.85 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.583271
  validation loss:		0.579169
  validation accuracy:		82.07 %
Epoch 496 of 2000 took 0.036s
  training loss:		0.586267
  validation loss:		0.568882
  validation accuracy:		81.30 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.586344
  validation loss:		0.577010
  validation accuracy:		81.52 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.590845
  validation loss:		0.588662
  validation accuracy:		81.96 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.578239
  validation loss:		0.574885
  validation accuracy:		81.85 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.587286
  validation loss:		0.584651
  validation accuracy:		81.63 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.585404
  validation loss:		0.600618
  validation accuracy:		81.41 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.581377
  validation loss:		0.580606
  validation accuracy:		82.07 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.581656
  validation loss:		0.599284
  validation accuracy:		81.41 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.579388
  validation loss:		0.585544
  validation accuracy:		81.41 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.581924
  validation loss:		0.574817
  validation accuracy:		81.74 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.593118
  validation loss:		0.570456
  validation accuracy:		81.30 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.582105
  validation loss:		0.583175
  validation accuracy:		81.63 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.572949
  validation loss:		0.566979
  validation accuracy:		81.41 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.583650
  validation loss:		0.607032
  validation accuracy:		81.09 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.587635
  validation loss:		0.592375
  validation accuracy:		80.65 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.578459
  validation loss:		0.592736
  validation accuracy:		81.85 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.584041
  validation loss:		0.575028
  validation accuracy:		81.85 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.580482
  validation loss:		0.566096
  validation accuracy:		81.85 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.583766
  validation loss:		0.575760
  validation accuracy:		81.85 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.573355
  validation loss:		0.574783
  validation accuracy:		82.07 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.581706
  validation loss:		0.572115
  validation accuracy:		82.17 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.578552
  validation loss:		0.581046
  validation accuracy:		82.07 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.568859
  validation loss:		0.567459
  validation accuracy:		82.07 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.566865
  validation loss:		0.611372
  validation accuracy:		80.76 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.573773
  validation loss:		0.564779
  validation accuracy:		83.15 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.579216
  validation loss:		0.571733
  validation accuracy:		82.07 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.567991
  validation loss:		0.574387
  validation accuracy:		82.28 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.577373
  validation loss:		0.568065
  validation accuracy:		82.17 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.570515
  validation loss:		0.564476
  validation accuracy:		82.83 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.572130
  validation loss:		0.577438
  validation accuracy:		81.96 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.568260
  validation loss:		0.586296
  validation accuracy:		81.85 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.562089
  validation loss:		0.561885
  validation accuracy:		82.83 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.569292
  validation loss:		0.580759
  validation accuracy:		82.07 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.568599
  validation loss:		0.558911
  validation accuracy:		82.39 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.571485
  validation loss:		0.579726
  validation accuracy:		81.85 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.562115
  validation loss:		0.556906
  validation accuracy:		82.72 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.556558
  validation loss:		0.557880
  validation accuracy:		82.17 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.569596
  validation loss:		0.555538
  validation accuracy:		82.50 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.563768
  validation loss:		0.587531
  validation accuracy:		81.52 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.562377
  validation loss:		0.553703
  validation accuracy:		82.83 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.549217
  validation loss:		0.561578
  validation accuracy:		82.28 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.555430
  validation loss:		0.564705
  validation accuracy:		82.07 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.552910
  validation loss:		0.563253
  validation accuracy:		82.39 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.559937
  validation loss:		0.555601
  validation accuracy:		82.93 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.558219
  validation loss:		0.547299
  validation accuracy:		82.61 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.556674
  validation loss:		0.547090
  validation accuracy:		82.61 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.560768
  validation loss:		0.545646
  validation accuracy:		83.26 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.558323
  validation loss:		0.560881
  validation accuracy:		81.74 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.559524
  validation loss:		0.539626
  validation accuracy:		83.26 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.553904
  validation loss:		0.596916
  validation accuracy:		81.20 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.554151
  validation loss:		0.547417
  validation accuracy:		82.93 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.544696
  validation loss:		0.542183
  validation accuracy:		83.04 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.542617
  validation loss:		0.540962
  validation accuracy:		83.04 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.542260
  validation loss:		0.537618
  validation accuracy:		82.93 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.545480
  validation loss:		0.540980
  validation accuracy:		82.83 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.543324
  validation loss:		0.527120
  validation accuracy:		83.48 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.538314
  validation loss:		0.523736
  validation accuracy:		83.37 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.531803
  validation loss:		0.529045
  validation accuracy:		83.80 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.534474
  validation loss:		0.532802
  validation accuracy:		83.59 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.539015
  validation loss:		0.519319
  validation accuracy:		83.48 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.534699
  validation loss:		0.534499
  validation accuracy:		83.26 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.530194
  validation loss:		0.526311
  validation accuracy:		84.35 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.525293
  validation loss:		0.539686
  validation accuracy:		82.17 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.530028
  validation loss:		0.522840
  validation accuracy:		83.37 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.522839
  validation loss:		0.523118
  validation accuracy:		83.48 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.520903
  validation loss:		0.517056
  validation accuracy:		83.80 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.522995
  validation loss:		0.508903
  validation accuracy:		84.46 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.520034
  validation loss:		0.503506
  validation accuracy:		84.24 %
Epoch 564 of 2000 took 0.036s
  training loss:		0.520855
  validation loss:		0.521534
  validation accuracy:		82.93 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.521500
  validation loss:		0.513496
  validation accuracy:		84.13 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.513472
  validation loss:		0.530794
  validation accuracy:		84.24 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.506367
  validation loss:		0.504843
  validation accuracy:		84.46 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.518421
  validation loss:		0.511796
  validation accuracy:		84.57 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.514162
  validation loss:		0.522588
  validation accuracy:		83.37 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.503465
  validation loss:		0.520632
  validation accuracy:		83.59 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.503705
  validation loss:		0.496283
  validation accuracy:		84.57 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.500558
  validation loss:		0.507444
  validation accuracy:		84.46 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.497682
  validation loss:		0.496300
  validation accuracy:		84.89 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.496278
  validation loss:		0.485135
  validation accuracy:		84.35 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.512318
  validation loss:		0.496470
  validation accuracy:		85.22 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.492137
  validation loss:		0.504792
  validation accuracy:		84.24 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.497312
  validation loss:		0.495673
  validation accuracy:		84.78 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.503629
  validation loss:		0.513904
  validation accuracy:		83.59 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.497877
  validation loss:		0.505315
  validation accuracy:		83.91 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.501018
  validation loss:		0.481048
  validation accuracy:		85.65 %
Epoch 581 of 2000 took 0.036s
  training loss:		0.489917
  validation loss:		0.496022
  validation accuracy:		84.24 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.492925
  validation loss:		0.491754
  validation accuracy:		84.67 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.493052
  validation loss:		0.492472
  validation accuracy:		85.00 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.487503
  validation loss:		0.486342
  validation accuracy:		85.43 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.486789
  validation loss:		0.485768
  validation accuracy:		85.33 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.478510
  validation loss:		0.487308
  validation accuracy:		84.67 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.481707
  validation loss:		0.491190
  validation accuracy:		84.78 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.482155
  validation loss:		0.486757
  validation accuracy:		85.43 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.480561
  validation loss:		0.481018
  validation accuracy:		85.00 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.479724
  validation loss:		0.484682
  validation accuracy:		84.78 %
Epoch 591 of 2000 took 0.036s
  training loss:		0.474378
  validation loss:		0.487960
  validation accuracy:		84.57 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.467027
  validation loss:		0.485273
  validation accuracy:		84.57 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.477117
  validation loss:		0.480396
  validation accuracy:		84.78 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.481412
  validation loss:		0.472302
  validation accuracy:		85.65 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.470015
  validation loss:		0.470380
  validation accuracy:		85.11 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.470666
  validation loss:		0.466341
  validation accuracy:		85.87 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.466502
  validation loss:		0.492406
  validation accuracy:		84.13 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.464649
  validation loss:		0.478486
  validation accuracy:		85.00 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.463933
  validation loss:		0.457617
  validation accuracy:		85.76 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.464859
  validation loss:		0.468149
  validation accuracy:		85.00 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.468580
  validation loss:		0.462439
  validation accuracy:		85.54 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.465476
  validation loss:		0.466735
  validation accuracy:		85.11 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.466523
  validation loss:		0.466499
  validation accuracy:		85.00 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.464564
  validation loss:		0.472504
  validation accuracy:		84.89 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.462588
  validation loss:		0.481295
  validation accuracy:		84.89 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.463502
  validation loss:		0.465547
  validation accuracy:		85.98 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.458674
  validation loss:		0.469336
  validation accuracy:		85.22 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.458850
  validation loss:		0.469521
  validation accuracy:		85.43 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.456492
  validation loss:		0.471675
  validation accuracy:		85.22 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.452639
  validation loss:		0.457337
  validation accuracy:		85.87 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.459464
  validation loss:		0.452965
  validation accuracy:		86.30 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.458094
  validation loss:		0.462788
  validation accuracy:		85.22 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.453265
  validation loss:		0.455892
  validation accuracy:		85.43 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.451911
  validation loss:		0.475087
  validation accuracy:		85.43 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.450214
  validation loss:		0.479894
  validation accuracy:		84.78 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.452561
  validation loss:		0.472420
  validation accuracy:		85.11 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.457025
  validation loss:		0.456249
  validation accuracy:		85.22 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.446266
  validation loss:		0.448141
  validation accuracy:		85.98 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.451496
  validation loss:		0.457849
  validation accuracy:		85.87 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.453733
  validation loss:		0.448048
  validation accuracy:		86.30 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.446750
  validation loss:		0.446254
  validation accuracy:		86.41 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.452509
  validation loss:		0.463046
  validation accuracy:		85.33 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.442540
  validation loss:		0.454231
  validation accuracy:		85.54 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.444659
  validation loss:		0.447555
  validation accuracy:		85.87 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.440878
  validation loss:		0.440138
  validation accuracy:		86.20 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.441072
  validation loss:		0.473635
  validation accuracy:		85.65 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.439219
  validation loss:		0.451611
  validation accuracy:		85.76 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.437415
  validation loss:		0.445079
  validation accuracy:		85.98 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.432684
  validation loss:		0.452830
  validation accuracy:		85.33 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.437356
  validation loss:		0.447870
  validation accuracy:		85.98 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.437827
  validation loss:		0.443882
  validation accuracy:		85.65 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.448499
  validation loss:		0.430421
  validation accuracy:		87.28 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.439328
  validation loss:		0.447725
  validation accuracy:		86.30 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.434917
  validation loss:		0.445018
  validation accuracy:		85.87 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.433893
  validation loss:		0.444349
  validation accuracy:		86.09 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.427910
  validation loss:		0.452333
  validation accuracy:		85.76 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.430133
  validation loss:		0.450135
  validation accuracy:		85.22 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.424296
  validation loss:		0.444078
  validation accuracy:		86.52 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.434733
  validation loss:		0.442890
  validation accuracy:		85.65 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.431197
  validation loss:		0.450542
  validation accuracy:		85.22 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.422293
  validation loss:		0.449933
  validation accuracy:		85.76 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.436552
  validation loss:		0.434787
  validation accuracy:		85.87 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.424363
  validation loss:		0.451025
  validation accuracy:		85.98 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.432660
  validation loss:		0.440554
  validation accuracy:		86.20 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.428840
  validation loss:		0.439167
  validation accuracy:		85.76 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.430002
  validation loss:		0.442454
  validation accuracy:		86.09 %
Epoch 647 of 2000 took 0.036s
  training loss:		0.427235
  validation loss:		0.454759
  validation accuracy:		85.22 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.427027
  validation loss:		0.428739
  validation accuracy:		86.85 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.424148
  validation loss:		0.431772
  validation accuracy:		85.98 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.418372
  validation loss:		0.434209
  validation accuracy:		85.98 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.426210
  validation loss:		0.441072
  validation accuracy:		85.76 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.418921
  validation loss:		0.455715
  validation accuracy:		85.65 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.418532
  validation loss:		0.424513
  validation accuracy:		87.72 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.417147
  validation loss:		0.423849
  validation accuracy:		87.83 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.422684
  validation loss:		0.428144
  validation accuracy:		87.50 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.418207
  validation loss:		0.432374
  validation accuracy:		85.87 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.418246
  validation loss:		0.430243
  validation accuracy:		86.41 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.417868
  validation loss:		0.425311
  validation accuracy:		87.17 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.417385
  validation loss:		0.422905
  validation accuracy:		87.39 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.418105
  validation loss:		0.428642
  validation accuracy:		87.07 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.421919
  validation loss:		0.417816
  validation accuracy:		88.04 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.417958
  validation loss:		0.439592
  validation accuracy:		85.76 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.405822
  validation loss:		0.419385
  validation accuracy:		88.04 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.415675
  validation loss:		0.431212
  validation accuracy:		86.63 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.408315
  validation loss:		0.412527
  validation accuracy:		88.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.413720
  validation loss:		0.428333
  validation accuracy:		86.85 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.409802
  validation loss:		0.421400
  validation accuracy:		86.96 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.413409
  validation loss:		0.426025
  validation accuracy:		86.85 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.412478
  validation loss:		0.428138
  validation accuracy:		86.63 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.415270
  validation loss:		0.428983
  validation accuracy:		86.41 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.406941
  validation loss:		0.431020
  validation accuracy:		86.41 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.401323
  validation loss:		0.427841
  validation accuracy:		86.74 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.410167
  validation loss:		0.423173
  validation accuracy:		86.41 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.402743
  validation loss:		0.429375
  validation accuracy:		86.41 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.404931
  validation loss:		0.413829
  validation accuracy:		87.83 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.406071
  validation loss:		0.409601
  validation accuracy:		88.15 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.404013
  validation loss:		0.409654
  validation accuracy:		88.26 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.398229
  validation loss:		0.415720
  validation accuracy:		88.04 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.410741
  validation loss:		0.443226
  validation accuracy:		85.76 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.405394
  validation loss:		0.439044
  validation accuracy:		85.98 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.402439
  validation loss:		0.418268
  validation accuracy:		86.96 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.401997
  validation loss:		0.423164
  validation accuracy:		87.50 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.399173
  validation loss:		0.416618
  validation accuracy:		87.61 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.393888
  validation loss:		0.411528
  validation accuracy:		87.83 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.395499
  validation loss:		0.422107
  validation accuracy:		86.96 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.406058
  validation loss:		0.424504
  validation accuracy:		86.74 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.399798
  validation loss:		0.417733
  validation accuracy:		86.96 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.389936
  validation loss:		0.411079
  validation accuracy:		87.72 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.400363
  validation loss:		0.433831
  validation accuracy:		86.09 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.390432
  validation loss:		0.422068
  validation accuracy:		86.20 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.398312
  validation loss:		0.428336
  validation accuracy:		86.30 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.399039
  validation loss:		0.430783
  validation accuracy:		86.96 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.393112
  validation loss:		0.423155
  validation accuracy:		86.85 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.395212
  validation loss:		0.428904
  validation accuracy:		86.52 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.389343
  validation loss:		0.414753
  validation accuracy:		87.07 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.392218
  validation loss:		0.415747
  validation accuracy:		86.96 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.393549
  validation loss:		0.417772
  validation accuracy:		86.85 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.389796
  validation loss:		0.407767
  validation accuracy:		87.83 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.396796
  validation loss:		0.434929
  validation accuracy:		86.20 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.397477
  validation loss:		0.410257
  validation accuracy:		87.50 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.394630
  validation loss:		0.408522
  validation accuracy:		87.28 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.388354
  validation loss:		0.420858
  validation accuracy:		86.85 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.389363
  validation loss:		0.426994
  validation accuracy:		86.85 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.386194
  validation loss:		0.423695
  validation accuracy:		86.52 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.387373
  validation loss:		0.417523
  validation accuracy:		87.28 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.386618
  validation loss:		0.406961
  validation accuracy:		87.50 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.385659
  validation loss:		0.418042
  validation accuracy:		87.17 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.396234
  validation loss:		0.419416
  validation accuracy:		87.07 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.387018
  validation loss:		0.433448
  validation accuracy:		85.87 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.389451
  validation loss:		0.402560
  validation accuracy:		88.26 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.388519
  validation loss:		0.427794
  validation accuracy:		86.41 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.389679
  validation loss:		0.434103
  validation accuracy:		85.98 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.385045
  validation loss:		0.408231
  validation accuracy:		87.61 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.383409
  validation loss:		0.409727
  validation accuracy:		87.28 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.380651
  validation loss:		0.412498
  validation accuracy:		86.96 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.377073
  validation loss:		0.440220
  validation accuracy:		85.65 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.379527
  validation loss:		0.402961
  validation accuracy:		87.93 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.381349
  validation loss:		0.418917
  validation accuracy:		87.17 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.382818
  validation loss:		0.436253
  validation accuracy:		86.52 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.385399
  validation loss:		0.411371
  validation accuracy:		87.50 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.377747
  validation loss:		0.416291
  validation accuracy:		87.07 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.384360
  validation loss:		0.418899
  validation accuracy:		86.74 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.378247
  validation loss:		0.410020
  validation accuracy:		87.83 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.383728
  validation loss:		0.425337
  validation accuracy:		86.30 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.381021
  validation loss:		0.417711
  validation accuracy:		86.85 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.368304
  validation loss:		0.428546
  validation accuracy:		86.41 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.378819
  validation loss:		0.409346
  validation accuracy:		87.50 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.374036
  validation loss:		0.400336
  validation accuracy:		88.04 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.376861
  validation loss:		0.406849
  validation accuracy:		87.28 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.379294
  validation loss:		0.409972
  validation accuracy:		87.39 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.373448
  validation loss:		0.403980
  validation accuracy:		87.61 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.382768
  validation loss:		0.417489
  validation accuracy:		87.07 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.376896
  validation loss:		0.397220
  validation accuracy:		88.15 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.375386
  validation loss:		0.401071
  validation accuracy:		87.28 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.366166
  validation loss:		0.401338
  validation accuracy:		87.61 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.375640
  validation loss:		0.404681
  validation accuracy:		87.39 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.363623
  validation loss:		0.405855
  validation accuracy:		87.61 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.376478
  validation loss:		0.406832
  validation accuracy:		87.50 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.369547
  validation loss:		0.407251
  validation accuracy:		87.61 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.377998
  validation loss:		0.403459
  validation accuracy:		87.28 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.377523
  validation loss:		0.422589
  validation accuracy:		86.63 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.372768
  validation loss:		0.401620
  validation accuracy:		87.72 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.369920
  validation loss:		0.426515
  validation accuracy:		86.41 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.376960
  validation loss:		0.403606
  validation accuracy:		87.83 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.373348
  validation loss:		0.398282
  validation accuracy:		87.39 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.371262
  validation loss:		0.397379
  validation accuracy:		88.26 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.372967
  validation loss:		0.422411
  validation accuracy:		86.85 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.375170
  validation loss:		0.402832
  validation accuracy:		87.61 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.367420
  validation loss:		0.389495
  validation accuracy:		87.72 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.372118
  validation loss:		0.392461
  validation accuracy:		87.93 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.374288
  validation loss:		0.415803
  validation accuracy:		86.74 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.368529
  validation loss:		0.392518
  validation accuracy:		88.04 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.357827
  validation loss:		0.408663
  validation accuracy:		87.28 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.371003
  validation loss:		0.400477
  validation accuracy:		87.39 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.368466
  validation loss:		0.400689
  validation accuracy:		87.50 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.365519
  validation loss:		0.386184
  validation accuracy:		88.15 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.366471
  validation loss:		0.400044
  validation accuracy:		87.50 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.364766
  validation loss:		0.417363
  validation accuracy:		86.41 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.365783
  validation loss:		0.412929
  validation accuracy:		87.50 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.371609
  validation loss:		0.401259
  validation accuracy:		87.39 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.366362
  validation loss:		0.430603
  validation accuracy:		86.74 %
Epoch 762 of 2000 took 0.036s
  training loss:		0.363280
  validation loss:		0.413649
  validation accuracy:		87.07 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.375466
  validation loss:		0.385676
  validation accuracy:		88.70 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.371785
  validation loss:		0.400013
  validation accuracy:		87.93 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.365785
  validation loss:		0.386036
  validation accuracy:		88.37 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.364907
  validation loss:		0.397755
  validation accuracy:		87.61 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.360056
  validation loss:		0.392634
  validation accuracy:		88.04 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.363392
  validation loss:		0.398571
  validation accuracy:		87.61 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.362738
  validation loss:		0.395862
  validation accuracy:		88.04 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.364566
  validation loss:		0.391380
  validation accuracy:		87.50 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.361905
  validation loss:		0.400054
  validation accuracy:		87.83 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.362284
  validation loss:		0.387600
  validation accuracy:		88.59 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.358899
  validation loss:		0.393107
  validation accuracy:		87.83 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.362192
  validation loss:		0.408600
  validation accuracy:		87.50 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.364022
  validation loss:		0.387879
  validation accuracy:		88.15 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.362300
  validation loss:		0.392905
  validation accuracy:		87.83 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.357900
  validation loss:		0.381787
  validation accuracy:		88.37 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.359752
  validation loss:		0.385500
  validation accuracy:		88.04 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.366278
  validation loss:		0.383062
  validation accuracy:		88.04 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.363793
  validation loss:		0.409877
  validation accuracy:		86.96 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.360716
  validation loss:		0.386022
  validation accuracy:		87.72 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.361575
  validation loss:		0.383694
  validation accuracy:		87.93 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.363071
  validation loss:		0.396085
  validation accuracy:		87.39 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.358378
  validation loss:		0.394710
  validation accuracy:		87.50 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.360393
  validation loss:		0.386302
  validation accuracy:		87.72 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.353504
  validation loss:		0.389589
  validation accuracy:		88.04 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.362042
  validation loss:		0.408932
  validation accuracy:		86.52 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.349374
  validation loss:		0.384378
  validation accuracy:		87.72 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.357515
  validation loss:		0.390175
  validation accuracy:		87.72 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.360865
  validation loss:		0.393839
  validation accuracy:		87.61 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.360199
  validation loss:		0.420634
  validation accuracy:		86.63 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.360972
  validation loss:		0.403584
  validation accuracy:		87.17 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.358104
  validation loss:		0.399880
  validation accuracy:		87.61 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.361004
  validation loss:		0.384013
  validation accuracy:		87.50 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.359097
  validation loss:		0.391193
  validation accuracy:		87.83 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.358859
  validation loss:		0.400200
  validation accuracy:		87.61 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.348192
  validation loss:		0.389808
  validation accuracy:		88.26 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.352561
  validation loss:		0.390968
  validation accuracy:		87.83 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.351565
  validation loss:		0.386031
  validation accuracy:		87.93 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.357410
  validation loss:		0.399066
  validation accuracy:		86.96 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.352023
  validation loss:		0.394047
  validation accuracy:		87.61 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.348417
  validation loss:		0.412559
  validation accuracy:		86.63 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.352760
  validation loss:		0.380123
  validation accuracy:		88.59 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.355865
  validation loss:		0.403347
  validation accuracy:		87.39 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.355530
  validation loss:		0.395947
  validation accuracy:		87.50 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.350089
  validation loss:		0.428289
  validation accuracy:		86.74 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.359067
  validation loss:		0.392558
  validation accuracy:		87.61 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.360483
  validation loss:		0.376456
  validation accuracy:		88.70 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.354063
  validation loss:		0.377286
  validation accuracy:		88.70 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.353614
  validation loss:		0.385529
  validation accuracy:		88.37 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.351512
  validation loss:		0.387687
  validation accuracy:		87.61 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.347692
  validation loss:		0.404707
  validation accuracy:		87.28 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.354544
  validation loss:		0.392898
  validation accuracy:		87.28 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.350524
  validation loss:		0.387200
  validation accuracy:		87.93 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.353464
  validation loss:		0.398566
  validation accuracy:		87.72 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.346411
  validation loss:		0.420592
  validation accuracy:		86.41 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.351445
  validation loss:		0.385604
  validation accuracy:		88.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.350761
  validation loss:		0.374095
  validation accuracy:		88.48 %
Epoch 819 of 2000 took 0.036s
  training loss:		0.356341
  validation loss:		0.385179
  validation accuracy:		88.26 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.353119
  validation loss:		0.379816
  validation accuracy:		88.37 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.353521
  validation loss:		0.385828
  validation accuracy:		87.93 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.352144
  validation loss:		0.373243
  validation accuracy:		88.91 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.349146
  validation loss:		0.385064
  validation accuracy:		87.93 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.346940
  validation loss:		0.383958
  validation accuracy:		88.04 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.349256
  validation loss:		0.386730
  validation accuracy:		87.61 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.348305
  validation loss:		0.383167
  validation accuracy:		88.15 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.345152
  validation loss:		0.388293
  validation accuracy:		87.83 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.346108
  validation loss:		0.382348
  validation accuracy:		88.48 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.357257
  validation loss:		0.412327
  validation accuracy:		86.85 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.346371
  validation loss:		0.385444
  validation accuracy:		88.04 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.348904
  validation loss:		0.404311
  validation accuracy:		87.07 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.339007
  validation loss:		0.391167
  validation accuracy:		87.93 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.344305
  validation loss:		0.403277
  validation accuracy:		87.61 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.350968
  validation loss:		0.390667
  validation accuracy:		87.61 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.335361
  validation loss:		0.381032
  validation accuracy:		87.83 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.347653
  validation loss:		0.398961
  validation accuracy:		87.50 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.346291
  validation loss:		0.378483
  validation accuracy:		88.15 %
Epoch 838 of 2000 took 0.037s
  training loss:		0.353693
  validation loss:		0.404718
  validation accuracy:		87.72 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.338891
  validation loss:		0.383054
  validation accuracy:		88.04 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.348244
  validation loss:		0.403118
  validation accuracy:		87.50 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.347306
  validation loss:		0.398693
  validation accuracy:		87.61 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.339757
  validation loss:		0.377774
  validation accuracy:		88.26 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.343046
  validation loss:		0.383568
  validation accuracy:		88.04 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.337720
  validation loss:		0.389344
  validation accuracy:		87.83 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.339507
  validation loss:		0.381727
  validation accuracy:		88.26 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.345913
  validation loss:		0.381491
  validation accuracy:		88.04 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.339594
  validation loss:		0.393908
  validation accuracy:		88.04 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.340070
  validation loss:		0.387737
  validation accuracy:		87.72 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.341896
  validation loss:		0.390258
  validation accuracy:		87.93 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.350947
  validation loss:		0.390480
  validation accuracy:		88.04 %
Epoch 851 of 2000 took 0.036s
  training loss:		0.347873
  validation loss:		0.390233
  validation accuracy:		88.04 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.339299
  validation loss:		0.378502
  validation accuracy:		88.26 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.343111
  validation loss:		0.384330
  validation accuracy:		88.48 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.339493
  validation loss:		0.397092
  validation accuracy:		87.07 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.343737
  validation loss:		0.392765
  validation accuracy:		87.93 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.341200
  validation loss:		0.394288
  validation accuracy:		87.50 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.340854
  validation loss:		0.393062
  validation accuracy:		87.83 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.339895
  validation loss:		0.389806
  validation accuracy:		88.26 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.343431
  validation loss:		0.379504
  validation accuracy:		88.26 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.345417
  validation loss:		0.406526
  validation accuracy:		86.63 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.339917
  validation loss:		0.395819
  validation accuracy:		87.72 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.339927
  validation loss:		0.372845
  validation accuracy:		89.13 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.340501
  validation loss:		0.390060
  validation accuracy:		88.04 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.337995
  validation loss:		0.424004
  validation accuracy:		87.07 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.346075
  validation loss:		0.384273
  validation accuracy:		88.26 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.339881
  validation loss:		0.384418
  validation accuracy:		87.83 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.338788
  validation loss:		0.379978
  validation accuracy:		87.93 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.339443
  validation loss:		0.381165
  validation accuracy:		88.04 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.336705
  validation loss:		0.386138
  validation accuracy:		88.04 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.342002
  validation loss:		0.369235
  validation accuracy:		88.80 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.346958
  validation loss:		0.409721
  validation accuracy:		87.07 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.338472
  validation loss:		0.390700
  validation accuracy:		88.04 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.344759
  validation loss:		0.391489
  validation accuracy:		87.72 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.334959
  validation loss:		0.377532
  validation accuracy:		88.59 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.338613
  validation loss:		0.376225
  validation accuracy:		88.70 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.330936
  validation loss:		0.383351
  validation accuracy:		87.39 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.330520
  validation loss:		0.386438
  validation accuracy:		88.15 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.340503
  validation loss:		0.375511
  validation accuracy:		88.04 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.347579
  validation loss:		0.388614
  validation accuracy:		88.15 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.339935
  validation loss:		0.386773
  validation accuracy:		87.93 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.340878
  validation loss:		0.398890
  validation accuracy:		87.50 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.337205
  validation loss:		0.374229
  validation accuracy:		88.26 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.343141
  validation loss:		0.406541
  validation accuracy:		88.04 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.333283
  validation loss:		0.393593
  validation accuracy:		87.17 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.331640
  validation loss:		0.397994
  validation accuracy:		87.93 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.341874
  validation loss:		0.386745
  validation accuracy:		88.37 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.331442
  validation loss:		0.418668
  validation accuracy:		87.17 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.343472
  validation loss:		0.373881
  validation accuracy:		88.37 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.336077
  validation loss:		0.377227
  validation accuracy:		88.26 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.341539
  validation loss:		0.395818
  validation accuracy:		87.83 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.340852
  validation loss:		0.377161
  validation accuracy:		88.15 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.327389
  validation loss:		0.380222
  validation accuracy:		88.04 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.337834
  validation loss:		0.408030
  validation accuracy:		87.61 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.330130
  validation loss:		0.382972
  validation accuracy:		87.93 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.329489
  validation loss:		0.392115
  validation accuracy:		87.83 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.329977
  validation loss:		0.395646
  validation accuracy:		87.39 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.335996
  validation loss:		0.390615
  validation accuracy:		87.93 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.335481
  validation loss:		0.377606
  validation accuracy:		88.26 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.327063
  validation loss:		0.383512
  validation accuracy:		88.15 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.335427
  validation loss:		0.377006
  validation accuracy:		88.80 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.334898
  validation loss:		0.381961
  validation accuracy:		87.93 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.336599
  validation loss:		0.379572
  validation accuracy:		88.15 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.332395
  validation loss:		0.393903
  validation accuracy:		88.15 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.333275
  validation loss:		0.393096
  validation accuracy:		87.93 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.338889
  validation loss:		0.389509
  validation accuracy:		87.93 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.338511
  validation loss:		0.385973
  validation accuracy:		87.83 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.337916
  validation loss:		0.373867
  validation accuracy:		88.15 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.329289
  validation loss:		0.384732
  validation accuracy:		88.04 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.327915
  validation loss:		0.391235
  validation accuracy:		87.72 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.333642
  validation loss:		0.373126
  validation accuracy:		89.02 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.331952
  validation loss:		0.381519
  validation accuracy:		88.48 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.338225
  validation loss:		0.379585
  validation accuracy:		88.15 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.329736
  validation loss:		0.375100
  validation accuracy:		88.59 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.329551
  validation loss:		0.389535
  validation accuracy:		87.72 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.335108
  validation loss:		0.377848
  validation accuracy:		88.04 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.333660
  validation loss:		0.370345
  validation accuracy:		88.70 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.333711
  validation loss:		0.407096
  validation accuracy:		87.28 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.329638
  validation loss:		0.392698
  validation accuracy:		88.15 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.329840
  validation loss:		0.400570
  validation accuracy:		87.93 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.333888
  validation loss:		0.380844
  validation accuracy:		88.15 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.334006
  validation loss:		0.409158
  validation accuracy:		87.39 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.329813
  validation loss:		0.368537
  validation accuracy:		89.02 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.331687
  validation loss:		0.386953
  validation accuracy:		88.26 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.341757
  validation loss:		0.384812
  validation accuracy:		88.04 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.333783
  validation loss:		0.367930
  validation accuracy:		89.02 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.329614
  validation loss:		0.378464
  validation accuracy:		88.04 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.331893
  validation loss:		0.382790
  validation accuracy:		87.61 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.332258
  validation loss:		0.388196
  validation accuracy:		87.72 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.332952
  validation loss:		0.380803
  validation accuracy:		88.59 %
Epoch 930 of 2000 took 0.036s
  training loss:		0.331289
  validation loss:		0.391172
  validation accuracy:		87.93 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.326797
  validation loss:		0.390667
  validation accuracy:		87.93 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.331657
  validation loss:		0.385915
  validation accuracy:		87.72 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.331654
  validation loss:		0.396806
  validation accuracy:		87.83 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.333457
  validation loss:		0.405750
  validation accuracy:		87.28 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.333648
  validation loss:		0.381261
  validation accuracy:		88.04 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.332863
  validation loss:		0.372799
  validation accuracy:		88.59 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.334098
  validation loss:		0.389295
  validation accuracy:		87.83 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.325595
  validation loss:		0.385299
  validation accuracy:		88.04 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.328653
  validation loss:		0.378436
  validation accuracy:		88.37 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.333375
  validation loss:		0.381222
  validation accuracy:		88.26 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.328869
  validation loss:		0.373462
  validation accuracy:		88.48 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.327506
  validation loss:		0.374858
  validation accuracy:		88.37 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.331519
  validation loss:		0.375330
  validation accuracy:		88.48 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.326315
  validation loss:		0.400975
  validation accuracy:		87.72 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.325893
  validation loss:		0.395278
  validation accuracy:		87.83 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.326085
  validation loss:		0.398352
  validation accuracy:		87.72 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.328364
  validation loss:		0.376760
  validation accuracy:		88.04 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.328103
  validation loss:		0.387448
  validation accuracy:		88.04 %
Epoch 949 of 2000 took 0.036s
  training loss:		0.327636
  validation loss:		0.384050
  validation accuracy:		88.04 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.329613
  validation loss:		0.384349
  validation accuracy:		87.93 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.327555
  validation loss:		0.366252
  validation accuracy:		89.24 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.330823
  validation loss:		0.391260
  validation accuracy:		87.72 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.323586
  validation loss:		0.405955
  validation accuracy:		87.17 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.320321
  validation loss:		0.406692
  validation accuracy:		88.15 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.338390
  validation loss:		0.379702
  validation accuracy:		88.15 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.324292
  validation loss:		0.367526
  validation accuracy:		89.35 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.326659
  validation loss:		0.399734
  validation accuracy:		87.93 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.325772
  validation loss:		0.374592
  validation accuracy:		88.26 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.322826
  validation loss:		0.383112
  validation accuracy:		88.59 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.331214
  validation loss:		0.375756
  validation accuracy:		88.48 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.326361
  validation loss:		0.373662
  validation accuracy:		88.37 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.325325
  validation loss:		0.368233
  validation accuracy:		89.13 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.330299
  validation loss:		0.404134
  validation accuracy:		87.39 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.325920
  validation loss:		0.396908
  validation accuracy:		87.39 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.326447
  validation loss:		0.377557
  validation accuracy:		88.59 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.323327
  validation loss:		0.370076
  validation accuracy:		89.02 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.316747
  validation loss:		0.397980
  validation accuracy:		87.61 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.326626
  validation loss:		0.380170
  validation accuracy:		87.93 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.327279
  validation loss:		0.385422
  validation accuracy:		87.93 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.316550
  validation loss:		0.400978
  validation accuracy:		87.07 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.325954
  validation loss:		0.372230
  validation accuracy:		89.13 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.330679
  validation loss:		0.383117
  validation accuracy:		88.37 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.328360
  validation loss:		0.390780
  validation accuracy:		88.37 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.329463
  validation loss:		0.390437
  validation accuracy:		87.83 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.326140
  validation loss:		0.388327
  validation accuracy:		87.83 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.330431
  validation loss:		0.379960
  validation accuracy:		88.04 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.326096
  validation loss:		0.382900
  validation accuracy:		88.48 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.329655
  validation loss:		0.421086
  validation accuracy:		86.85 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.328995
  validation loss:		0.385278
  validation accuracy:		88.04 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.329743
  validation loss:		0.370076
  validation accuracy:		89.13 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.323338
  validation loss:		0.372498
  validation accuracy:		88.80 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.329498
  validation loss:		0.390426
  validation accuracy:		87.93 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.324262
  validation loss:		0.388996
  validation accuracy:		87.61 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.316080
  validation loss:		0.391747
  validation accuracy:		87.28 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.327045
  validation loss:		0.380693
  validation accuracy:		88.37 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.327318
  validation loss:		0.372598
  validation accuracy:		88.59 %
Epoch 987 of 2000 took 0.036s
  training loss:		0.314260
  validation loss:		0.382245
  validation accuracy:		88.26 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.326457
  validation loss:		0.372444
  validation accuracy:		88.80 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.326254
  validation loss:		0.378025
  validation accuracy:		88.59 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.321455
  validation loss:		0.383619
  validation accuracy:		88.37 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.327685
  validation loss:		0.389910
  validation accuracy:		88.37 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.329398
  validation loss:		0.380765
  validation accuracy:		88.48 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.320456
  validation loss:		0.373834
  validation accuracy:		88.70 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.318842
  validation loss:		0.374402
  validation accuracy:		88.70 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.324833
  validation loss:		0.372511
  validation accuracy:		89.02 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.323203
  validation loss:		0.391566
  validation accuracy:		87.93 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.320064
  validation loss:		0.366877
  validation accuracy:		89.13 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.321164
  validation loss:		0.399358
  validation accuracy:		87.61 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.315359
  validation loss:		0.390758
  validation accuracy:		88.48 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.324257
  validation loss:		0.395603
  validation accuracy:		87.72 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.316691
  validation loss:		0.378974
  validation accuracy:		88.91 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.324149
  validation loss:		0.380249
  validation accuracy:		88.70 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.320859
  validation loss:		0.372543
  validation accuracy:		88.48 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.317897
  validation loss:		0.382704
  validation accuracy:		88.26 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.325414
  validation loss:		0.386735
  validation accuracy:		88.59 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.318374
  validation loss:		0.379451
  validation accuracy:		88.15 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.325047
  validation loss:		0.381970
  validation accuracy:		88.04 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.319923
  validation loss:		0.405759
  validation accuracy:		87.50 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.323988
  validation loss:		0.378638
  validation accuracy:		88.59 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.326261
  validation loss:		0.371587
  validation accuracy:		89.78 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.320358
  validation loss:		0.375637
  validation accuracy:		88.59 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.318668
  validation loss:		0.375708
  validation accuracy:		88.70 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.324878
  validation loss:		0.370070
  validation accuracy:		89.46 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.317958
  validation loss:		0.366872
  validation accuracy:		89.89 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.316281
  validation loss:		0.383350
  validation accuracy:		88.59 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.323191
  validation loss:		0.368444
  validation accuracy:		89.24 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.320906
  validation loss:		0.377203
  validation accuracy:		88.91 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.326201
  validation loss:		0.390705
  validation accuracy:		88.15 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.322495
  validation loss:		0.376733
  validation accuracy:		88.80 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.317013
  validation loss:		0.388239
  validation accuracy:		87.61 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.323466
  validation loss:		0.386528
  validation accuracy:		88.15 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.321648
  validation loss:		0.376391
  validation accuracy:		88.91 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.317559
  validation loss:		0.362125
  validation accuracy:		89.67 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.316044
  validation loss:		0.380738
  validation accuracy:		88.26 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.313191
  validation loss:		0.373147
  validation accuracy:		89.13 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.318842
  validation loss:		0.370380
  validation accuracy:		89.24 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.313385
  validation loss:		0.368781
  validation accuracy:		89.57 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.311760
  validation loss:		0.369470
  validation accuracy:		89.67 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.308117
  validation loss:		0.378685
  validation accuracy:		88.59 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.316323
  validation loss:		0.383397
  validation accuracy:		88.15 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.319699
  validation loss:		0.368064
  validation accuracy:		89.46 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.319150
  validation loss:		0.390943
  validation accuracy:		88.26 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.315541
  validation loss:		0.385753
  validation accuracy:		88.26 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.317982
  validation loss:		0.377516
  validation accuracy:		88.70 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.317539
  validation loss:		0.386746
  validation accuracy:		87.83 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.312214
  validation loss:		0.375433
  validation accuracy:		88.91 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.316298
  validation loss:		0.380395
  validation accuracy:		88.70 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.320979
  validation loss:		0.368944
  validation accuracy:		89.89 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.317366
  validation loss:		0.403952
  validation accuracy:		87.07 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.321269
  validation loss:		0.372636
  validation accuracy:		89.46 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.313819
  validation loss:		0.386105
  validation accuracy:		88.70 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.318325
  validation loss:		0.388334
  validation accuracy:		88.26 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.318825
  validation loss:		0.382750
  validation accuracy:		88.48 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.319065
  validation loss:		0.377423
  validation accuracy:		89.67 %
Epoch 1045 of 2000 took 0.036s
  training loss:		0.330353
  validation loss:		0.371784
  validation accuracy:		89.24 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.308682
  validation loss:		0.379906
  validation accuracy:		88.59 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.315127
  validation loss:		0.378047
  validation accuracy:		88.80 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.318957
  validation loss:		0.377699
  validation accuracy:		88.59 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.315221
  validation loss:		0.383518
  validation accuracy:		89.13 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.317464
  validation loss:		0.384173
  validation accuracy:		88.70 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.310985
  validation loss:		0.401918
  validation accuracy:		88.04 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.317299
  validation loss:		0.375731
  validation accuracy:		88.70 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.310831
  validation loss:		0.379683
  validation accuracy:		88.91 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.321391
  validation loss:		0.388526
  validation accuracy:		88.37 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.320147
  validation loss:		0.389671
  validation accuracy:		87.39 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.313127
  validation loss:		0.369556
  validation accuracy:		90.00 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.314576
  validation loss:		0.394168
  validation accuracy:		87.61 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.310123
  validation loss:		0.389531
  validation accuracy:		88.70 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.316579
  validation loss:		0.377017
  validation accuracy:		88.91 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.320074
  validation loss:		0.374088
  validation accuracy:		89.02 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.316040
  validation loss:		0.372928
  validation accuracy:		88.91 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.319016
  validation loss:		0.395333
  validation accuracy:		87.61 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.316286
  validation loss:		0.382637
  validation accuracy:		88.37 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.305492
  validation loss:		0.392628
  validation accuracy:		88.48 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.317194
  validation loss:		0.380331
  validation accuracy:		89.67 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.308989
  validation loss:		0.376314
  validation accuracy:		88.80 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.314763
  validation loss:		0.378658
  validation accuracy:		88.15 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.317864
  validation loss:		0.379250
  validation accuracy:		88.80 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.313357
  validation loss:		0.389704
  validation accuracy:		88.37 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.317905
  validation loss:		0.380387
  validation accuracy:		89.24 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.316304
  validation loss:		0.384847
  validation accuracy:		88.80 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.310113
  validation loss:		0.382382
  validation accuracy:		89.13 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.323706
  validation loss:		0.388272
  validation accuracy:		87.83 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.316825
  validation loss:		0.401064
  validation accuracy:		87.61 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.312915
  validation loss:		0.377853
  validation accuracy:		89.35 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.314552
  validation loss:		0.388715
  validation accuracy:		88.91 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.312122
  validation loss:		0.376636
  validation accuracy:		89.13 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.301670
  validation loss:		0.378526
  validation accuracy:		89.02 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.315001
  validation loss:		0.376107
  validation accuracy:		89.57 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.311678
  validation loss:		0.373729
  validation accuracy:		89.13 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.317137
  validation loss:		0.401606
  validation accuracy:		87.28 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.313292
  validation loss:		0.403593
  validation accuracy:		87.17 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.312426
  validation loss:		0.379921
  validation accuracy:		89.24 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.309461
  validation loss:		0.396928
  validation accuracy:		88.26 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.314901
  validation loss:		0.365393
  validation accuracy:		89.57 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.312855
  validation loss:		0.368000
  validation accuracy:		89.57 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.309711
  validation loss:		0.375424
  validation accuracy:		89.02 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.319390
  validation loss:		0.371911
  validation accuracy:		89.02 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.312306
  validation loss:		0.387635
  validation accuracy:		88.15 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.309650
  validation loss:		0.378640
  validation accuracy:		88.70 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.311559
  validation loss:		0.373165
  validation accuracy:		88.80 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.307216
  validation loss:		0.399531
  validation accuracy:		88.26 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.309483
  validation loss:		0.375719
  validation accuracy:		89.67 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.312427
  validation loss:		0.392721
  validation accuracy:		87.83 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.307704
  validation loss:		0.394166
  validation accuracy:		87.39 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.306531
  validation loss:		0.384040
  validation accuracy:		89.13 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.312167
  validation loss:		0.378044
  validation accuracy:		88.80 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.311905
  validation loss:		0.385776
  validation accuracy:		87.93 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.308554
  validation loss:		0.369376
  validation accuracy:		89.67 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.304920
  validation loss:		0.367853
  validation accuracy:		89.13 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.314239
  validation loss:		0.414160
  validation accuracy:		87.07 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.309202
  validation loss:		0.389121
  validation accuracy:		88.37 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.311843
  validation loss:		0.378607
  validation accuracy:		89.02 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.314871
  validation loss:		0.380995
  validation accuracy:		88.70 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.305423
  validation loss:		0.382790
  validation accuracy:		88.59 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.314106
  validation loss:		0.388581
  validation accuracy:		88.59 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.308367
  validation loss:		0.381941
  validation accuracy:		88.80 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.310822
  validation loss:		0.374741
  validation accuracy:		89.78 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.314464
  validation loss:		0.376828
  validation accuracy:		89.13 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.310457
  validation loss:		0.406338
  validation accuracy:		87.61 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.316676
  validation loss:		0.386223
  validation accuracy:		88.80 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.305176
  validation loss:		0.383881
  validation accuracy:		88.80 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.303689
  validation loss:		0.368598
  validation accuracy:		89.67 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.312611
  validation loss:		0.376971
  validation accuracy:		89.02 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.309201
  validation loss:		0.383008
  validation accuracy:		88.70 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.311094
  validation loss:		0.373806
  validation accuracy:		89.35 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.309749
  validation loss:		0.368619
  validation accuracy:		89.78 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.305211
  validation loss:		0.387232
  validation accuracy:		88.59 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.310169
  validation loss:		0.381135
  validation accuracy:		88.70 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.304457
  validation loss:		0.384892
  validation accuracy:		88.59 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.302356
  validation loss:		0.396411
  validation accuracy:		87.72 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.313540
  validation loss:		0.390770
  validation accuracy:		88.70 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.307830
  validation loss:		0.380644
  validation accuracy:		89.02 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.310418
  validation loss:		0.378124
  validation accuracy:		89.24 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.306397
  validation loss:		0.381411
  validation accuracy:		88.26 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.312389
  validation loss:		0.395606
  validation accuracy:		87.61 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.312608
  validation loss:		0.393945
  validation accuracy:		87.93 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.304721
  validation loss:		0.430098
  validation accuracy:		86.85 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.310695
  validation loss:		0.372384
  validation accuracy:		89.24 %
Epoch 1130 of 2000 took 0.036s
  training loss:		0.305472
  validation loss:		0.374449
  validation accuracy:		89.67 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.308746
  validation loss:		0.371270
  validation accuracy:		89.35 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.312663
  validation loss:		0.372196
  validation accuracy:		89.67 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.314088
  validation loss:		0.376483
  validation accuracy:		89.24 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.307420
  validation loss:		0.372104
  validation accuracy:		89.46 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.306006
  validation loss:		0.404536
  validation accuracy:		87.39 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.305528
  validation loss:		0.380028
  validation accuracy:		88.91 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.304052
  validation loss:		0.382245
  validation accuracy:		88.15 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.308566
  validation loss:		0.382899
  validation accuracy:		89.13 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.305629
  validation loss:		0.414564
  validation accuracy:		87.07 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.312348
  validation loss:		0.372645
  validation accuracy:		89.46 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.307724
  validation loss:		0.374264
  validation accuracy:		89.46 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.312695
  validation loss:		0.372385
  validation accuracy:		89.46 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.313313
  validation loss:		0.382409
  validation accuracy:		88.70 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.312303
  validation loss:		0.374446
  validation accuracy:		89.57 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.307513
  validation loss:		0.367793
  validation accuracy:		89.46 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.313635
  validation loss:		0.388214
  validation accuracy:		88.26 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.310173
  validation loss:		0.382826
  validation accuracy:		89.02 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.308508
  validation loss:		0.379110
  validation accuracy:		88.91 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.301433
  validation loss:		0.367292
  validation accuracy:		89.78 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.303095
  validation loss:		0.369702
  validation accuracy:		89.35 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.303512
  validation loss:		0.392038
  validation accuracy:		88.26 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.308800
  validation loss:		0.377555
  validation accuracy:		89.35 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.313971
  validation loss:		0.382575
  validation accuracy:		88.91 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.306676
  validation loss:		0.390332
  validation accuracy:		87.93 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.303728
  validation loss:		0.373661
  validation accuracy:		89.13 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.304384
  validation loss:		0.396742
  validation accuracy:		88.15 %
Epoch 1157 of 2000 took 0.036s
  training loss:		0.303445
  validation loss:		0.407930
  validation accuracy:		87.93 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.302594
  validation loss:		0.371777
  validation accuracy:		90.00 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.308311
  validation loss:		0.399025
  validation accuracy:		88.37 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.305617
  validation loss:		0.397684
  validation accuracy:		88.26 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.311787
  validation loss:		0.386949
  validation accuracy:		88.15 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.308601
  validation loss:		0.392373
  validation accuracy:		89.02 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.310369
  validation loss:		0.386097
  validation accuracy:		88.70 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.309398
  validation loss:		0.391745
  validation accuracy:		88.70 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.303757
  validation loss:		0.399382
  validation accuracy:		88.15 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.309507
  validation loss:		0.391765
  validation accuracy:		88.37 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.299443
  validation loss:		0.373303
  validation accuracy:		89.35 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.303989
  validation loss:		0.383718
  validation accuracy:		88.70 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.299537
  validation loss:		0.372531
  validation accuracy:		89.35 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.310557
  validation loss:		0.377745
  validation accuracy:		89.46 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.301607
  validation loss:		0.400852
  validation accuracy:		88.37 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.305024
  validation loss:		0.371251
  validation accuracy:		89.46 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.298710
  validation loss:		0.386599
  validation accuracy:		88.80 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.304191
  validation loss:		0.375412
  validation accuracy:		89.13 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.305999
  validation loss:		0.387819
  validation accuracy:		88.70 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.307332
  validation loss:		0.383982
  validation accuracy:		88.70 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.306119
  validation loss:		0.375054
  validation accuracy:		89.78 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.307360
  validation loss:		0.389534
  validation accuracy:		88.80 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.305343
  validation loss:		0.377273
  validation accuracy:		89.24 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.310388
  validation loss:		0.379691
  validation accuracy:		88.91 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.302097
  validation loss:		0.376317
  validation accuracy:		89.35 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.302436
  validation loss:		0.399120
  validation accuracy:		88.37 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.304453
  validation loss:		0.389150
  validation accuracy:		88.48 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.305125
  validation loss:		0.392398
  validation accuracy:		88.48 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.308459
  validation loss:		0.391274
  validation accuracy:		88.59 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.299618
  validation loss:		0.378834
  validation accuracy:		89.13 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.308218
  validation loss:		0.397416
  validation accuracy:		88.26 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.300260
  validation loss:		0.375519
  validation accuracy:		89.35 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.310161
  validation loss:		0.380378
  validation accuracy:		88.70 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.306882
  validation loss:		0.382870
  validation accuracy:		88.70 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.302700
  validation loss:		0.377577
  validation accuracy:		89.46 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.309620
  validation loss:		0.378349
  validation accuracy:		89.13 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.307210
  validation loss:		0.383686
  validation accuracy:		88.80 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.301640
  validation loss:		0.399522
  validation accuracy:		88.04 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.315060
  validation loss:		0.377742
  validation accuracy:		89.57 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.312019
  validation loss:		0.433738
  validation accuracy:		87.28 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.312600
  validation loss:		0.410137
  validation accuracy:		87.83 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.304179
  validation loss:		0.383466
  validation accuracy:		89.02 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.304623
  validation loss:		0.395464
  validation accuracy:		88.59 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.308641
  validation loss:		0.393114
  validation accuracy:		88.48 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.303146
  validation loss:		0.406743
  validation accuracy:		88.59 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.304398
  validation loss:		0.375336
  validation accuracy:		89.89 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.312780
  validation loss:		0.385871
  validation accuracy:		89.35 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.306443
  validation loss:		0.380797
  validation accuracy:		89.46 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.298553
  validation loss:		0.373159
  validation accuracy:		89.35 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.306374
  validation loss:		0.384721
  validation accuracy:		88.70 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.307638
  validation loss:		0.373773
  validation accuracy:		89.24 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.300899
  validation loss:		0.399523
  validation accuracy:		88.26 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.302422
  validation loss:		0.374901
  validation accuracy:		89.46 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.304481
  validation loss:		0.405320
  validation accuracy:		88.48 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.301291
  validation loss:		0.386048
  validation accuracy:		88.37 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.303981
  validation loss:		0.373513
  validation accuracy:		88.91 %
Epoch 1213 of 2000 took 0.036s
  training loss:		0.301213
  validation loss:		0.375341
  validation accuracy:		89.02 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.300583
  validation loss:		0.383579
  validation accuracy:		88.80 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.294554
  validation loss:		0.385888
  validation accuracy:		88.91 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.300010
  validation loss:		0.378997
  validation accuracy:		88.70 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.310608
  validation loss:		0.410861
  validation accuracy:		87.93 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.304212
  validation loss:		0.389550
  validation accuracy:		89.02 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.300410
  validation loss:		0.384542
  validation accuracy:		88.80 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.303513
  validation loss:		0.374817
  validation accuracy:		89.35 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.302620
  validation loss:		0.393549
  validation accuracy:		88.37 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.299192
  validation loss:		0.383392
  validation accuracy:		88.91 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.297766
  validation loss:		0.379457
  validation accuracy:		88.80 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.296719
  validation loss:		0.395723
  validation accuracy:		88.59 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.307465
  validation loss:		0.376906
  validation accuracy:		89.24 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.299993
  validation loss:		0.389268
  validation accuracy:		88.70 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.304512
  validation loss:		0.389625
  validation accuracy:		88.80 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.296530
  validation loss:		0.368477
  validation accuracy:		89.57 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.301899
  validation loss:		0.375106
  validation accuracy:		89.02 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.303709
  validation loss:		0.375198
  validation accuracy:		89.13 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.301072
  validation loss:		0.378133
  validation accuracy:		88.91 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.306835
  validation loss:		0.381072
  validation accuracy:		89.24 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.299381
  validation loss:		0.386584
  validation accuracy:		88.48 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.304775
  validation loss:		0.389891
  validation accuracy:		88.80 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.303915
  validation loss:		0.376786
  validation accuracy:		89.46 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.303288
  validation loss:		0.374002
  validation accuracy:		89.57 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.301118
  validation loss:		0.378821
  validation accuracy:		88.59 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.306126
  validation loss:		0.380382
  validation accuracy:		88.80 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.300016
  validation loss:		0.407348
  validation accuracy:		87.72 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.305763
  validation loss:		0.376306
  validation accuracy:		89.02 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.297922
  validation loss:		0.372497
  validation accuracy:		89.46 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.304358
  validation loss:		0.381688
  validation accuracy:		89.02 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.302192
  validation loss:		0.376507
  validation accuracy:		89.24 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.302077
  validation loss:		0.396727
  validation accuracy:		88.70 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.303563
  validation loss:		0.380178
  validation accuracy:		89.35 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.306358
  validation loss:		0.389312
  validation accuracy:		88.80 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.299955
  validation loss:		0.387549
  validation accuracy:		89.02 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.303969
  validation loss:		0.396756
  validation accuracy:		88.59 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.319488
  validation loss:		0.384145
  validation accuracy:		88.80 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.305882
  validation loss:		0.421683
  validation accuracy:		87.61 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.305592
  validation loss:		0.415576
  validation accuracy:		87.83 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.299757
  validation loss:		0.401989
  validation accuracy:		88.37 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.306236
  validation loss:		0.374963
  validation accuracy:		89.78 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.301898
  validation loss:		0.375790
  validation accuracy:		89.46 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.305122
  validation loss:		0.376715
  validation accuracy:		89.24 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.304217
  validation loss:		0.390463
  validation accuracy:		88.70 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.309265
  validation loss:		0.390527
  validation accuracy:		89.24 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.303384
  validation loss:		0.393565
  validation accuracy:		88.80 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.301562
  validation loss:		0.380652
  validation accuracy:		88.48 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.296135
  validation loss:		0.380190
  validation accuracy:		89.46 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.300125
  validation loss:		0.382784
  validation accuracy:		89.35 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.307571
  validation loss:		0.417507
  validation accuracy:		87.93 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.305406
  validation loss:		0.374696
  validation accuracy:		88.80 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.303328
  validation loss:		0.388975
  validation accuracy:		88.70 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.297624
  validation loss:		0.391372
  validation accuracy:		88.80 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.306149
  validation loss:		0.372147
  validation accuracy:		89.57 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.301941
  validation loss:		0.372359
  validation accuracy:		89.13 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.295328
  validation loss:		0.382950
  validation accuracy:		88.80 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.302416
  validation loss:		0.384666
  validation accuracy:		88.80 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.301600
  validation loss:		0.383865
  validation accuracy:		89.02 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.301471
  validation loss:		0.381407
  validation accuracy:		89.02 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.297089
  validation loss:		0.383318
  validation accuracy:		89.13 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.294164
  validation loss:		0.382708
  validation accuracy:		89.02 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.302275
  validation loss:		0.382665
  validation accuracy:		88.80 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.298829
  validation loss:		0.396417
  validation accuracy:		88.37 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.303006
  validation loss:		0.382827
  validation accuracy:		89.02 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.300504
  validation loss:		0.378334
  validation accuracy:		88.70 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.297770
  validation loss:		0.376827
  validation accuracy:		89.35 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.296185
  validation loss:		0.379725
  validation accuracy:		89.35 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.304054
  validation loss:		0.392380
  validation accuracy:		89.02 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.306300
  validation loss:		0.384533
  validation accuracy:		88.37 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.298543
  validation loss:		0.378332
  validation accuracy:		88.91 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.302510
  validation loss:		0.381936
  validation accuracy:		88.70 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.290890
  validation loss:		0.375694
  validation accuracy:		89.46 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.295272
  validation loss:		0.396058
  validation accuracy:		88.91 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.295528
  validation loss:		0.385749
  validation accuracy:		88.59 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.301515
  validation loss:		0.371773
  validation accuracy:		89.13 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.298627
  validation loss:		0.379014
  validation accuracy:		88.80 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.298153
  validation loss:		0.376968
  validation accuracy:		89.24 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.293896
  validation loss:		0.398632
  validation accuracy:		88.37 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.303244
  validation loss:		0.388668
  validation accuracy:		89.02 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.302741
  validation loss:		0.401302
  validation accuracy:		88.37 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.293758
  validation loss:		0.394823
  validation accuracy:		88.91 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.299288
  validation loss:		0.395586
  validation accuracy:		88.80 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.297915
  validation loss:		0.374047
  validation accuracy:		89.46 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.305946
  validation loss:		0.398005
  validation accuracy:		88.48 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.299255
  validation loss:		0.377037
  validation accuracy:		89.57 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.297770
  validation loss:		0.392682
  validation accuracy:		88.37 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.295107
  validation loss:		0.374823
  validation accuracy:		89.46 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.298375
  validation loss:		0.370739
  validation accuracy:		89.89 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.299030
  validation loss:		0.385032
  validation accuracy:		89.02 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.300162
  validation loss:		0.382298
  validation accuracy:		89.24 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.305087
  validation loss:		0.372596
  validation accuracy:		89.35 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.300125
  validation loss:		0.383090
  validation accuracy:		88.80 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.302425
  validation loss:		0.375823
  validation accuracy:		89.35 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.300736
  validation loss:		0.382037
  validation accuracy:		88.91 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.290000
  validation loss:		0.398607
  validation accuracy:		88.59 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.294619
  validation loss:		0.396929
  validation accuracy:		89.02 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.295560
  validation loss:		0.384851
  validation accuracy:		88.91 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.302887
  validation loss:		0.391760
  validation accuracy:		89.13 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.288250
  validation loss:		0.387389
  validation accuracy:		88.59 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.296834
  validation loss:		0.377469
  validation accuracy:		89.57 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.297675
  validation loss:		0.377126
  validation accuracy:		89.02 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.300608
  validation loss:		0.383472
  validation accuracy:		89.13 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.298933
  validation loss:		0.383723
  validation accuracy:		89.24 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.299727
  validation loss:		0.454045
  validation accuracy:		86.74 %
Epoch 1317 of 2000 took 0.036s
  training loss:		0.304453
  validation loss:		0.380944
  validation accuracy:		89.24 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.298293
  validation loss:		0.393337
  validation accuracy:		88.37 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.290701
  validation loss:		0.392289
  validation accuracy:		88.37 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.294442
  validation loss:		0.385333
  validation accuracy:		89.46 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.294724
  validation loss:		0.390294
  validation accuracy:		88.91 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.295895
  validation loss:		0.392996
  validation accuracy:		88.80 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.296929
  validation loss:		0.418036
  validation accuracy:		87.93 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.296613
  validation loss:		0.393435
  validation accuracy:		88.48 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.292547
  validation loss:		0.388449
  validation accuracy:		88.80 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.299113
  validation loss:		0.394151
  validation accuracy:		88.37 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.299857
  validation loss:		0.400331
  validation accuracy:		88.48 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.296724
  validation loss:		0.390908
  validation accuracy:		88.70 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.293088
  validation loss:		0.379080
  validation accuracy:		89.46 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.296995
  validation loss:		0.392488
  validation accuracy:		88.70 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.300412
  validation loss:		0.412527
  validation accuracy:		87.83 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.293982
  validation loss:		0.372971
  validation accuracy:		89.35 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.297329
  validation loss:		0.410599
  validation accuracy:		88.26 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.303639
  validation loss:		0.385522
  validation accuracy:		88.91 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.296419
  validation loss:		0.379923
  validation accuracy:		89.24 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.293491
  validation loss:		0.370154
  validation accuracy:		89.35 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.291337
  validation loss:		0.375654
  validation accuracy:		89.24 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.300237
  validation loss:		0.385075
  validation accuracy:		89.02 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.297765
  validation loss:		0.402189
  validation accuracy:		88.48 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.293812
  validation loss:		0.392499
  validation accuracy:		88.48 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.297877
  validation loss:		0.397372
  validation accuracy:		88.80 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.302361
  validation loss:		0.375379
  validation accuracy:		89.24 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.301771
  validation loss:		0.381469
  validation accuracy:		89.13 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.300008
  validation loss:		0.415050
  validation accuracy:		88.26 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.299094
  validation loss:		0.387730
  validation accuracy:		89.13 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.304864
  validation loss:		0.384172
  validation accuracy:		88.80 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.292354
  validation loss:		0.393527
  validation accuracy:		88.59 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.295713
  validation loss:		0.387888
  validation accuracy:		88.70 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.297539
  validation loss:		0.381211
  validation accuracy:		89.02 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.301186
  validation loss:		0.374105
  validation accuracy:		89.24 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.306946
  validation loss:		0.391369
  validation accuracy:		88.59 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.295955
  validation loss:		0.389324
  validation accuracy:		89.13 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.295819
  validation loss:		0.390003
  validation accuracy:		88.59 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.295522
  validation loss:		0.402494
  validation accuracy:		88.48 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.298827
  validation loss:		0.398247
  validation accuracy:		88.59 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.296665
  validation loss:		0.376806
  validation accuracy:		89.24 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.302885
  validation loss:		0.383208
  validation accuracy:		88.91 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.296112
  validation loss:		0.386661
  validation accuracy:		88.48 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.303843
  validation loss:		0.395235
  validation accuracy:		88.80 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.298851
  validation loss:		0.381011
  validation accuracy:		89.46 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.295288
  validation loss:		0.409999
  validation accuracy:		88.26 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.294360
  validation loss:		0.383980
  validation accuracy:		89.13 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.297949
  validation loss:		0.393414
  validation accuracy:		89.46 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.296145
  validation loss:		0.378269
  validation accuracy:		89.24 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.293052
  validation loss:		0.394875
  validation accuracy:		88.80 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.297957
  validation loss:		0.378259
  validation accuracy:		89.57 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.305300
  validation loss:		0.397334
  validation accuracy:		88.59 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.295241
  validation loss:		0.392266
  validation accuracy:		88.80 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.296196
  validation loss:		0.379251
  validation accuracy:		89.35 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.293685
  validation loss:		0.403898
  validation accuracy:		88.70 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.299033
  validation loss:		0.399906
  validation accuracy:		88.80 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.299062
  validation loss:		0.381555
  validation accuracy:		89.13 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.302775
  validation loss:		0.373384
  validation accuracy:		89.57 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.300221
  validation loss:		0.373498
  validation accuracy:		89.67 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.295856
  validation loss:		0.382628
  validation accuracy:		89.35 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.291505
  validation loss:		0.389606
  validation accuracy:		88.70 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.291440
  validation loss:		0.389012
  validation accuracy:		88.91 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.296906
  validation loss:		0.395398
  validation accuracy:		88.59 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.297950
  validation loss:		0.439661
  validation accuracy:		87.17 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.298050
  validation loss:		0.392973
  validation accuracy:		88.70 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.291441
  validation loss:		0.386497
  validation accuracy:		89.35 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.290409
  validation loss:		0.389661
  validation accuracy:		88.48 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.299114
  validation loss:		0.394418
  validation accuracy:		89.57 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.295470
  validation loss:		0.393401
  validation accuracy:		89.24 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.293942
  validation loss:		0.394257
  validation accuracy:		89.24 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.293481
  validation loss:		0.381519
  validation accuracy:		89.46 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.297450
  validation loss:		0.383764
  validation accuracy:		89.46 %
Epoch 1388 of 2000 took 0.036s
  training loss:		0.294246
  validation loss:		0.384424
  validation accuracy:		89.46 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.297746
  validation loss:		0.386358
  validation accuracy:		88.59 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.293799
  validation loss:		0.389976
  validation accuracy:		88.80 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.296474
  validation loss:		0.383300
  validation accuracy:		89.24 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.298881
  validation loss:		0.390873
  validation accuracy:		88.80 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.292686
  validation loss:		0.405165
  validation accuracy:		87.93 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.294232
  validation loss:		0.400547
  validation accuracy:		88.48 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.295305
  validation loss:		0.394196
  validation accuracy:		89.35 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.302432
  validation loss:		0.404481
  validation accuracy:		88.80 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.301546
  validation loss:		0.380825
  validation accuracy:		88.70 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.288710
  validation loss:		0.381441
  validation accuracy:		89.02 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.296921
  validation loss:		0.416160
  validation accuracy:		87.83 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.298722
  validation loss:		0.393071
  validation accuracy:		88.59 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.294983
  validation loss:		0.385992
  validation accuracy:		88.70 %
Epoch 1402 of 2000 took 0.036s
  training loss:		0.297320
  validation loss:		0.391308
  validation accuracy:		89.13 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.293282
  validation loss:		0.385932
  validation accuracy:		88.70 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.291421
  validation loss:		0.388899
  validation accuracy:		88.70 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.300901
  validation loss:		0.391730
  validation accuracy:		88.59 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.291312
  validation loss:		0.394833
  validation accuracy:		88.59 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.291724
  validation loss:		0.395961
  validation accuracy:		88.70 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.299226
  validation loss:		0.381714
  validation accuracy:		89.67 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.295768
  validation loss:		0.383790
  validation accuracy:		89.46 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.296618
  validation loss:		0.388409
  validation accuracy:		89.46 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.297537
  validation loss:		0.394680
  validation accuracy:		88.80 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.299477
  validation loss:		0.430703
  validation accuracy:		87.93 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.303746
  validation loss:		0.398003
  validation accuracy:		88.48 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.297863
  validation loss:		0.408885
  validation accuracy:		87.83 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.297075
  validation loss:		0.381627
  validation accuracy:		89.46 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.291124
  validation loss:		0.398422
  validation accuracy:		88.70 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.293758
  validation loss:		0.375737
  validation accuracy:		89.35 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.292374
  validation loss:		0.411287
  validation accuracy:		87.61 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.293579
  validation loss:		0.379454
  validation accuracy:		89.02 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.293636
  validation loss:		0.375473
  validation accuracy:		89.24 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.292523
  validation loss:		0.382851
  validation accuracy:		88.80 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.299489
  validation loss:		0.397783
  validation accuracy:		88.59 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.297647
  validation loss:		0.395623
  validation accuracy:		88.37 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.297210
  validation loss:		0.399650
  validation accuracy:		88.37 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.291977
  validation loss:		0.390802
  validation accuracy:		88.04 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.290821
  validation loss:		0.377801
  validation accuracy:		89.46 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.296525
  validation loss:		0.381656
  validation accuracy:		88.91 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.289420
  validation loss:		0.392557
  validation accuracy:		88.48 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.287760
  validation loss:		0.386547
  validation accuracy:		88.48 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.294120
  validation loss:		0.386876
  validation accuracy:		89.35 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.297107
  validation loss:		0.384417
  validation accuracy:		88.80 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.302083
  validation loss:		0.389313
  validation accuracy:		89.78 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.294581
  validation loss:		0.395229
  validation accuracy:		88.80 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.289988
  validation loss:		0.405566
  validation accuracy:		88.59 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.295695
  validation loss:		0.416078
  validation accuracy:		87.72 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.299749
  validation loss:		0.379256
  validation accuracy:		89.02 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.290585
  validation loss:		0.435347
  validation accuracy:		87.17 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.302228
  validation loss:		0.399639
  validation accuracy:		88.80 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.288819
  validation loss:		0.390238
  validation accuracy:		88.48 %
Epoch 1440 of 2000 took 0.036s
  training loss:		0.292894
  validation loss:		0.384444
  validation accuracy:		89.35 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.293987
  validation loss:		0.394559
  validation accuracy:		88.48 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.293046
  validation loss:		0.396149
  validation accuracy:		88.91 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.289291
  validation loss:		0.396762
  validation accuracy:		89.13 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.294004
  validation loss:		0.404386
  validation accuracy:		88.26 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.291192
  validation loss:		0.390374
  validation accuracy:		89.02 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.292065
  validation loss:		0.396164
  validation accuracy:		88.48 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.289512
  validation loss:		0.408122
  validation accuracy:		88.80 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.295148
  validation loss:		0.385517
  validation accuracy:		88.59 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.295296
  validation loss:		0.384571
  validation accuracy:		89.02 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.291001
  validation loss:		0.391375
  validation accuracy:		88.59 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.294160
  validation loss:		0.389626
  validation accuracy:		88.70 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.295394
  validation loss:		0.379973
  validation accuracy:		89.02 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.302263
  validation loss:		0.392097
  validation accuracy:		88.80 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.290837
  validation loss:		0.383322
  validation accuracy:		89.24 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.297177
  validation loss:		0.414629
  validation accuracy:		88.26 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.301586
  validation loss:		0.417385
  validation accuracy:		87.83 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.297683
  validation loss:		0.388470
  validation accuracy:		88.80 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.287175
  validation loss:		0.392930
  validation accuracy:		88.70 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.289369
  validation loss:		0.409079
  validation accuracy:		88.04 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.294111
  validation loss:		0.397990
  validation accuracy:		88.70 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.288645
  validation loss:		0.382593
  validation accuracy:		88.80 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.295941
  validation loss:		0.396728
  validation accuracy:		88.91 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.287104
  validation loss:		0.392194
  validation accuracy:		88.59 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.297552
  validation loss:		0.390003
  validation accuracy:		89.24 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.295163
  validation loss:		0.381801
  validation accuracy:		89.46 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.302836
  validation loss:		0.403682
  validation accuracy:		88.59 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.298096
  validation loss:		0.398434
  validation accuracy:		88.37 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.296037
  validation loss:		0.387493
  validation accuracy:		89.13 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.288997
  validation loss:		0.404051
  validation accuracy:		88.37 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.297315
  validation loss:		0.380018
  validation accuracy:		89.02 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.299402
  validation loss:		0.390499
  validation accuracy:		88.59 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.296113
  validation loss:		0.392561
  validation accuracy:		88.48 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.295008
  validation loss:		0.426653
  validation accuracy:		87.39 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.294603
  validation loss:		0.410206
  validation accuracy:		88.04 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.287352
  validation loss:		0.393721
  validation accuracy:		88.59 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.295902
  validation loss:		0.427299
  validation accuracy:		87.61 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.292826
  validation loss:		0.390544
  validation accuracy:		89.13 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.293059
  validation loss:		0.399842
  validation accuracy:		88.59 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.295487
  validation loss:		0.379257
  validation accuracy:		89.02 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.294798
  validation loss:		0.397006
  validation accuracy:		88.91 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.289633
  validation loss:		0.383210
  validation accuracy:		89.24 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.298082
  validation loss:		0.395237
  validation accuracy:		88.04 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.293363
  validation loss:		0.401739
  validation accuracy:		88.91 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.290383
  validation loss:		0.400282
  validation accuracy:		88.80 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.292244
  validation loss:		0.380738
  validation accuracy:		88.80 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.294021
  validation loss:		0.394854
  validation accuracy:		88.15 %
Epoch 1487 of 2000 took 0.036s
  training loss:		0.288444
  validation loss:		0.401988
  validation accuracy:		88.04 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.289522
  validation loss:		0.399559
  validation accuracy:		88.48 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.297872
  validation loss:		0.392726
  validation accuracy:		88.70 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.305088
  validation loss:		0.390152
  validation accuracy:		89.02 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.295997
  validation loss:		0.393930
  validation accuracy:		88.91 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.295268
  validation loss:		0.399839
  validation accuracy:		88.37 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.291715
  validation loss:		0.406988
  validation accuracy:		88.15 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.298496
  validation loss:		0.389096
  validation accuracy:		88.26 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.291550
  validation loss:		0.416027
  validation accuracy:		87.50 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.295350
  validation loss:		0.403055
  validation accuracy:		88.70 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.297339
  validation loss:		0.423764
  validation accuracy:		87.50 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.292614
  validation loss:		0.412580
  validation accuracy:		88.70 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.297822
  validation loss:		0.401736
  validation accuracy:		88.37 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.299477
  validation loss:		0.393581
  validation accuracy:		88.37 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.284478
  validation loss:		0.388808
  validation accuracy:		88.80 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.298620
  validation loss:		0.418951
  validation accuracy:		87.83 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.296446
  validation loss:		0.410731
  validation accuracy:		88.04 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.290313
  validation loss:		0.407913
  validation accuracy:		88.48 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.288279
  validation loss:		0.430160
  validation accuracy:		86.96 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.292087
  validation loss:		0.392812
  validation accuracy:		88.59 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.288944
  validation loss:		0.387629
  validation accuracy:		89.24 %
Epoch 1508 of 2000 took 0.036s
  training loss:		0.290092
  validation loss:		0.420148
  validation accuracy:		88.15 %
Epoch 1509 of 2000 took 0.036s
  training loss:		0.295364
  validation loss:		0.394980
  validation accuracy:		88.80 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.296480
  validation loss:		0.399247
  validation accuracy:		88.91 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.292759
  validation loss:		0.392396
  validation accuracy:		88.70 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.291761
  validation loss:		0.386819
  validation accuracy:		88.70 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.296523
  validation loss:		0.404417
  validation accuracy:		88.91 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.290508
  validation loss:		0.381573
  validation accuracy:		88.59 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.290757
  validation loss:		0.409763
  validation accuracy:		88.37 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.294212
  validation loss:		0.381186
  validation accuracy:		89.46 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.293232
  validation loss:		0.398944
  validation accuracy:		88.59 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.290920
  validation loss:		0.423737
  validation accuracy:		87.39 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.301371
  validation loss:		0.395281
  validation accuracy:		88.26 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.287515
  validation loss:		0.401321
  validation accuracy:		88.80 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.298860
  validation loss:		0.407559
  validation accuracy:		88.37 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.292346
  validation loss:		0.402941
  validation accuracy:		88.59 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.294532
  validation loss:		0.386541
  validation accuracy:		88.48 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.294240
  validation loss:		0.389773
  validation accuracy:		88.70 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.293184
  validation loss:		0.390006
  validation accuracy:		89.13 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.297301
  validation loss:		0.395044
  validation accuracy:		88.15 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.289827
  validation loss:		0.388953
  validation accuracy:		88.59 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.290917
  validation loss:		0.394081
  validation accuracy:		88.48 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.295975
  validation loss:		0.416669
  validation accuracy:		87.50 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.290764
  validation loss:		0.383851
  validation accuracy:		89.35 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.291654
  validation loss:		0.391057
  validation accuracy:		88.48 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.288993
  validation loss:		0.383619
  validation accuracy:		89.02 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.293857
  validation loss:		0.396597
  validation accuracy:		88.37 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.292518
  validation loss:		0.392905
  validation accuracy:		88.37 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.289791
  validation loss:		0.402239
  validation accuracy:		88.26 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.287699
  validation loss:		0.415597
  validation accuracy:		87.83 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.290530
  validation loss:		0.411949
  validation accuracy:		87.61 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.293675
  validation loss:		0.391114
  validation accuracy:		89.46 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.294313
  validation loss:		0.415605
  validation accuracy:		87.83 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.292897
  validation loss:		0.394117
  validation accuracy:		88.37 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.289288
  validation loss:		0.382319
  validation accuracy:		89.24 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.290693
  validation loss:		0.391307
  validation accuracy:		89.13 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.294590
  validation loss:		0.399654
  validation accuracy:		88.91 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.291302
  validation loss:		0.387502
  validation accuracy:		88.91 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.290847
  validation loss:		0.398513
  validation accuracy:		89.46 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.286835
  validation loss:		0.392819
  validation accuracy:		88.80 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.291329
  validation loss:		0.416737
  validation accuracy:		88.04 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.294004
  validation loss:		0.386495
  validation accuracy:		88.91 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.290843
  validation loss:		0.409588
  validation accuracy:		87.61 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.294404
  validation loss:		0.393032
  validation accuracy:		88.70 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.293126
  validation loss:		0.389745
  validation accuracy:		88.37 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.289278
  validation loss:		0.405894
  validation accuracy:		88.48 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.296692
  validation loss:		0.407262
  validation accuracy:		87.50 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.299773
  validation loss:		0.421617
  validation accuracy:		87.28 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.293806
  validation loss:		0.392193
  validation accuracy:		88.59 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.299652
  validation loss:		0.408703
  validation accuracy:		88.15 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.294928
  validation loss:		0.420686
  validation accuracy:		87.61 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.295029
  validation loss:		0.421608
  validation accuracy:		87.72 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.288146
  validation loss:		0.392053
  validation accuracy:		88.04 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.297133
  validation loss:		0.387660
  validation accuracy:		88.70 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.289369
  validation loss:		0.396614
  validation accuracy:		88.04 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.294533
  validation loss:		0.381739
  validation accuracy:		89.02 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.289526
  validation loss:		0.421258
  validation accuracy:		88.26 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.291022
  validation loss:		0.393357
  validation accuracy:		88.15 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.285127
  validation loss:		0.399024
  validation accuracy:		88.04 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.297084
  validation loss:		0.388911
  validation accuracy:		89.13 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.285245
  validation loss:		0.384644
  validation accuracy:		88.91 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.295371
  validation loss:		0.391341
  validation accuracy:		88.80 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.292862
  validation loss:		0.411929
  validation accuracy:		87.83 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.288339
  validation loss:		0.396467
  validation accuracy:		88.37 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.300022
  validation loss:		0.425723
  validation accuracy:		86.96 %
Epoch 1572 of 2000 took 0.036s
  training loss:		0.290663
  validation loss:		0.396033
  validation accuracy:		88.48 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.287005
  validation loss:		0.396195
  validation accuracy:		88.37 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.296458
  validation loss:		0.425466
  validation accuracy:		87.28 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.293628
  validation loss:		0.398531
  validation accuracy:		88.70 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.284641
  validation loss:		0.393441
  validation accuracy:		88.26 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.287472
  validation loss:		0.395965
  validation accuracy:		88.59 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.292434
  validation loss:		0.387452
  validation accuracy:		88.70 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.300258
  validation loss:		0.403338
  validation accuracy:		88.70 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.291341
  validation loss:		0.386421
  validation accuracy:		88.70 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.293134
  validation loss:		0.396779
  validation accuracy:		89.46 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.289162
  validation loss:		0.394141
  validation accuracy:		88.91 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.289323
  validation loss:		0.399975
  validation accuracy:		88.37 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.290989
  validation loss:		0.391078
  validation accuracy:		88.15 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.287855
  validation loss:		0.417171
  validation accuracy:		88.04 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.294262
  validation loss:		0.388650
  validation accuracy:		88.48 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.289479
  validation loss:		0.394437
  validation accuracy:		88.70 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.294706
  validation loss:		0.412714
  validation accuracy:		88.15 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.287974
  validation loss:		0.393493
  validation accuracy:		88.37 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.290658
  validation loss:		0.385774
  validation accuracy:		89.24 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.302734
  validation loss:		0.399740
  validation accuracy:		88.37 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.294383
  validation loss:		0.397515
  validation accuracy:		88.15 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.280528
  validation loss:		0.389977
  validation accuracy:		88.26 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.296566
  validation loss:		0.400456
  validation accuracy:		88.04 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.289542
  validation loss:		0.411776
  validation accuracy:		87.72 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.291917
  validation loss:		0.393362
  validation accuracy:		88.80 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.285897
  validation loss:		0.416276
  validation accuracy:		87.83 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.290517
  validation loss:		0.442197
  validation accuracy:		86.74 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.293934
  validation loss:		0.387459
  validation accuracy:		88.59 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.289168
  validation loss:		0.401044
  validation accuracy:		88.37 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.297345
  validation loss:		0.383151
  validation accuracy:		89.24 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.296214
  validation loss:		0.402632
  validation accuracy:		88.48 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.292338
  validation loss:		0.412394
  validation accuracy:		87.83 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.288576
  validation loss:		0.404564
  validation accuracy:		87.93 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.284408
  validation loss:		0.387926
  validation accuracy:		88.91 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.290592
  validation loss:		0.385489
  validation accuracy:		89.35 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.293385
  validation loss:		0.411746
  validation accuracy:		87.93 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.290165
  validation loss:		0.404474
  validation accuracy:		88.37 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.288057
  validation loss:		0.399259
  validation accuracy:		89.02 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.286143
  validation loss:		0.389932
  validation accuracy:		88.48 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.286202
  validation loss:		0.393582
  validation accuracy:		88.48 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.291391
  validation loss:		0.392788
  validation accuracy:		88.37 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.290595
  validation loss:		0.433768
  validation accuracy:		87.39 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.293515
  validation loss:		0.397729
  validation accuracy:		88.48 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.285361
  validation loss:		0.408233
  validation accuracy:		88.70 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.292216
  validation loss:		0.420696
  validation accuracy:		87.72 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.293902
  validation loss:		0.402789
  validation accuracy:		88.15 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.290657
  validation loss:		0.395778
  validation accuracy:		87.83 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.290252
  validation loss:		0.412021
  validation accuracy:		88.04 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.290548
  validation loss:		0.412642
  validation accuracy:		87.17 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.288173
  validation loss:		0.409477
  validation accuracy:		88.04 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.288986
  validation loss:		0.405759
  validation accuracy:		88.37 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.284576
  validation loss:		0.399954
  validation accuracy:		88.15 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.291793
  validation loss:		0.392427
  validation accuracy:		88.70 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.292211
  validation loss:		0.403085
  validation accuracy:		88.48 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.295941
  validation loss:		0.404519
  validation accuracy:		88.70 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.287844
  validation loss:		0.396357
  validation accuracy:		88.26 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.288681
  validation loss:		0.388248
  validation accuracy:		88.48 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.292859
  validation loss:		0.402472
  validation accuracy:		88.04 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.288106
  validation loss:		0.413489
  validation accuracy:		88.48 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.284802
  validation loss:		0.394946
  validation accuracy:		88.37 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.290373
  validation loss:		0.392671
  validation accuracy:		89.02 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.284495
  validation loss:		0.416901
  validation accuracy:		87.61 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.288837
  validation loss:		0.430336
  validation accuracy:		87.07 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.290340
  validation loss:		0.397574
  validation accuracy:		88.91 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.292686
  validation loss:		0.414634
  validation accuracy:		88.59 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.288789
  validation loss:		0.411934
  validation accuracy:		87.93 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.287616
  validation loss:		0.415023
  validation accuracy:		87.72 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.286319
  validation loss:		0.413205
  validation accuracy:		87.83 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.289156
  validation loss:		0.413797
  validation accuracy:		88.37 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.297251
  validation loss:		0.402688
  validation accuracy:		88.91 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.292588
  validation loss:		0.391469
  validation accuracy:		88.48 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.291126
  validation loss:		0.391526
  validation accuracy:		88.48 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.289166
  validation loss:		0.392092
  validation accuracy:		88.70 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.294070
  validation loss:		0.421674
  validation accuracy:		86.63 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.288714
  validation loss:		0.394239
  validation accuracy:		88.91 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.288459
  validation loss:		0.395378
  validation accuracy:		88.15 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.287478
  validation loss:		0.401092
  validation accuracy:		88.59 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.293497
  validation loss:		0.396961
  validation accuracy:		88.70 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.287873
  validation loss:		0.404068
  validation accuracy:		88.26 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.285776
  validation loss:		0.422857
  validation accuracy:		87.50 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.285540
  validation loss:		0.403985
  validation accuracy:		87.93 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.289487
  validation loss:		0.419778
  validation accuracy:		87.61 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.289123
  validation loss:		0.387623
  validation accuracy:		89.02 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.289688
  validation loss:		0.406569
  validation accuracy:		87.83 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.291297
  validation loss:		0.405936
  validation accuracy:		88.26 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.290533
  validation loss:		0.393684
  validation accuracy:		89.13 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.296298
  validation loss:		0.394462
  validation accuracy:		88.15 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.287349
  validation loss:		0.432032
  validation accuracy:		86.85 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.286878
  validation loss:		0.406409
  validation accuracy:		88.26 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.289720
  validation loss:		0.408121
  validation accuracy:		87.72 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.289592
  validation loss:		0.413886
  validation accuracy:		88.15 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.288536
  validation loss:		0.394821
  validation accuracy:		88.37 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.285060
  validation loss:		0.439879
  validation accuracy:		86.85 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.290156
  validation loss:		0.421299
  validation accuracy:		87.61 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.289091
  validation loss:		0.413696
  validation accuracy:		88.15 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.292318
  validation loss:		0.395829
  validation accuracy:		88.80 %
Epoch 1668 of 2000 took 0.036s
  training loss:		0.289181
  validation loss:		0.413391
  validation accuracy:		87.39 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.296397
  validation loss:		0.387156
  validation accuracy:		88.80 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.290471
  validation loss:		0.386519
  validation accuracy:		88.59 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.296953
  validation loss:		0.424246
  validation accuracy:		87.50 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.295509
  validation loss:		0.403237
  validation accuracy:		88.04 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.289737
  validation loss:		0.405464
  validation accuracy:		88.37 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.287742
  validation loss:		0.413583
  validation accuracy:		87.61 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.288972
  validation loss:		0.410411
  validation accuracy:		88.48 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.290772
  validation loss:		0.405154
  validation accuracy:		87.72 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.291429
  validation loss:		0.387930
  validation accuracy:		89.13 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.288486
  validation loss:		0.394972
  validation accuracy:		88.37 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.286833
  validation loss:		0.424993
  validation accuracy:		87.39 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.290398
  validation loss:		0.403174
  validation accuracy:		88.26 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.297830
  validation loss:		0.422836
  validation accuracy:		87.83 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.286175
  validation loss:		0.397614
  validation accuracy:		88.59 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.286786
  validation loss:		0.392150
  validation accuracy:		88.91 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.285090
  validation loss:		0.405113
  validation accuracy:		88.26 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.291986
  validation loss:		0.406797
  validation accuracy:		88.15 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.300322
  validation loss:		0.408568
  validation accuracy:		88.37 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.287843
  validation loss:		0.402716
  validation accuracy:		87.83 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.294066
  validation loss:		0.401831
  validation accuracy:		88.15 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.287947
  validation loss:		0.405841
  validation accuracy:		87.83 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.287813
  validation loss:		0.399118
  validation accuracy:		88.91 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.284619
  validation loss:		0.399796
  validation accuracy:		88.26 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.281861
  validation loss:		0.394241
  validation accuracy:		88.70 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.292151
  validation loss:		0.398675
  validation accuracy:		88.80 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.293641
  validation loss:		0.396001
  validation accuracy:		88.04 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.284860
  validation loss:		0.436133
  validation accuracy:		87.39 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.290591
  validation loss:		0.442421
  validation accuracy:		86.85 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.293793
  validation loss:		0.400252
  validation accuracy:		88.80 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.293057
  validation loss:		0.398451
  validation accuracy:		88.37 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.285980
  validation loss:		0.404311
  validation accuracy:		87.61 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.288661
  validation loss:		0.421301
  validation accuracy:		87.61 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.295108
  validation loss:		0.400976
  validation accuracy:		88.04 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.284034
  validation loss:		0.390898
  validation accuracy:		88.91 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.287665
  validation loss:		0.395909
  validation accuracy:		88.15 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.290234
  validation loss:		0.403617
  validation accuracy:		87.72 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.291935
  validation loss:		0.404525
  validation accuracy:		87.72 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.285309
  validation loss:		0.410490
  validation accuracy:		88.80 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.294248
  validation loss:		0.396285
  validation accuracy:		88.70 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.293254
  validation loss:		0.400787
  validation accuracy:		88.37 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.285782
  validation loss:		0.391875
  validation accuracy:		88.37 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.290239
  validation loss:		0.426179
  validation accuracy:		87.83 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.288646
  validation loss:		0.389652
  validation accuracy:		88.70 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.286848
  validation loss:		0.429095
  validation accuracy:		87.39 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.290248
  validation loss:		0.401604
  validation accuracy:		88.70 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.284051
  validation loss:		0.413672
  validation accuracy:		87.61 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.286371
  validation loss:		0.393001
  validation accuracy:		88.37 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.285993
  validation loss:		0.397487
  validation accuracy:		87.83 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.293817
  validation loss:		0.409973
  validation accuracy:		88.04 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.290170
  validation loss:		0.402705
  validation accuracy:		88.37 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.289976
  validation loss:		0.404127
  validation accuracy:		88.26 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.282296
  validation loss:		0.418456
  validation accuracy:		87.72 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.286418
  validation loss:		0.412624
  validation accuracy:		88.37 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.287637
  validation loss:		0.397369
  validation accuracy:		88.59 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.281996
  validation loss:		0.408591
  validation accuracy:		87.93 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.286378
  validation loss:		0.437427
  validation accuracy:		87.17 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.293629
  validation loss:		0.404433
  validation accuracy:		88.15 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.290252
  validation loss:		0.416965
  validation accuracy:		87.93 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.282729
  validation loss:		0.395288
  validation accuracy:		88.48 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.286332
  validation loss:		0.403143
  validation accuracy:		88.70 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.288326
  validation loss:		0.412711
  validation accuracy:		87.39 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.286570
  validation loss:		0.430418
  validation accuracy:		87.83 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.290184
  validation loss:		0.404572
  validation accuracy:		88.80 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.284530
  validation loss:		0.410904
  validation accuracy:		88.15 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.289913
  validation loss:		0.400132
  validation accuracy:		88.91 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.289644
  validation loss:		0.394727
  validation accuracy:		88.48 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.290127
  validation loss:		0.408269
  validation accuracy:		88.26 %
Epoch 1736 of 2000 took 0.036s
  training loss:		0.288966
  validation loss:		0.403974
  validation accuracy:		88.48 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.292489
  validation loss:		0.412193
  validation accuracy:		88.80 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.289590
  validation loss:		0.407316
  validation accuracy:		88.80 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.287455
  validation loss:		0.408993
  validation accuracy:		88.15 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.288974
  validation loss:		0.416096
  validation accuracy:		88.15 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.289246
  validation loss:		0.415443
  validation accuracy:		87.72 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.289593
  validation loss:		0.433946
  validation accuracy:		87.07 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.294075
  validation loss:		0.428170
  validation accuracy:		87.07 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.287467
  validation loss:		0.417591
  validation accuracy:		87.61 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.289699
  validation loss:		0.409423
  validation accuracy:		88.15 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.291989
  validation loss:		0.402482
  validation accuracy:		88.37 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.287604
  validation loss:		0.416289
  validation accuracy:		88.48 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.283968
  validation loss:		0.397494
  validation accuracy:		88.37 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.286982
  validation loss:		0.398149
  validation accuracy:		88.59 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.291480
  validation loss:		0.407240
  validation accuracy:		87.83 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.298739
  validation loss:		0.392913
  validation accuracy:		88.48 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.292308
  validation loss:		0.402695
  validation accuracy:		88.04 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.286603
  validation loss:		0.414891
  validation accuracy:		87.72 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.287801
  validation loss:		0.410348
  validation accuracy:		88.15 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.284166
  validation loss:		0.399023
  validation accuracy:		88.37 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.291726
  validation loss:		0.410609
  validation accuracy:		87.72 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.289489
  validation loss:		0.395113
  validation accuracy:		88.04 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.293687
  validation loss:		0.416052
  validation accuracy:		87.39 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.288006
  validation loss:		0.404859
  validation accuracy:		87.83 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.286518
  validation loss:		0.420146
  validation accuracy:		87.28 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.287472
  validation loss:		0.403167
  validation accuracy:		87.83 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.287272
  validation loss:		0.397755
  validation accuracy:		87.83 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.286207
  validation loss:		0.398930
  validation accuracy:		88.59 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.292674
  validation loss:		0.422366
  validation accuracy:		87.50 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.292959
  validation loss:		0.418326
  validation accuracy:		86.96 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.287056
  validation loss:		0.401610
  validation accuracy:		87.61 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.285019
  validation loss:		0.403266
  validation accuracy:		88.70 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.287391
  validation loss:		0.396178
  validation accuracy:		87.93 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.287235
  validation loss:		0.430508
  validation accuracy:		87.93 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.292416
  validation loss:		0.400895
  validation accuracy:		87.93 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.283591
  validation loss:		0.401986
  validation accuracy:		88.59 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.288091
  validation loss:		0.408814
  validation accuracy:		88.15 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.293117
  validation loss:		0.399571
  validation accuracy:		88.15 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.286930
  validation loss:		0.395762
  validation accuracy:		87.83 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.286816
  validation loss:		0.405752
  validation accuracy:		88.80 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.288028
  validation loss:		0.405715
  validation accuracy:		88.15 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.297278
  validation loss:		0.391238
  validation accuracy:		88.70 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.294981
  validation loss:		0.405961
  validation accuracy:		88.59 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.293680
  validation loss:		0.404476
  validation accuracy:		88.26 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.288420
  validation loss:		0.403533
  validation accuracy:		88.59 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.282215
  validation loss:		0.394363
  validation accuracy:		87.93 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.290337
  validation loss:		0.434327
  validation accuracy:		86.85 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.293826
  validation loss:		0.407541
  validation accuracy:		88.15 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.288745
  validation loss:		0.401069
  validation accuracy:		88.26 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.283623
  validation loss:		0.433762
  validation accuracy:		87.07 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.286296
  validation loss:		0.418754
  validation accuracy:		87.39 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.285407
  validation loss:		0.394411
  validation accuracy:		87.83 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.296880
  validation loss:		0.441594
  validation accuracy:		86.63 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.293670
  validation loss:		0.403985
  validation accuracy:		87.72 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.293197
  validation loss:		0.416847
  validation accuracy:		88.04 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.284854
  validation loss:		0.396231
  validation accuracy:		88.26 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.287799
  validation loss:		0.429199
  validation accuracy:		87.61 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.288327
  validation loss:		0.411039
  validation accuracy:		87.50 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.287083
  validation loss:		0.421340
  validation accuracy:		87.17 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.288772
  validation loss:		0.395781
  validation accuracy:		88.59 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.282807
  validation loss:		0.400642
  validation accuracy:		87.83 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.285841
  validation loss:		0.398656
  validation accuracy:		88.26 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.294516
  validation loss:		0.419619
  validation accuracy:		87.83 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.295715
  validation loss:		0.406338
  validation accuracy:		87.72 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.289789
  validation loss:		0.443118
  validation accuracy:		86.63 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.284330
  validation loss:		0.415152
  validation accuracy:		88.80 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.290686
  validation loss:		0.408680
  validation accuracy:		87.61 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.285583
  validation loss:		0.412534
  validation accuracy:		87.28 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.290244
  validation loss:		0.394826
  validation accuracy:		87.93 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.283857
  validation loss:		0.405988
  validation accuracy:		87.93 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.288411
  validation loss:		0.405141
  validation accuracy:		88.37 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.286623
  validation loss:		0.414942
  validation accuracy:		87.83 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.279057
  validation loss:		0.389043
  validation accuracy:		89.02 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.287403
  validation loss:		0.441743
  validation accuracy:		87.07 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.285833
  validation loss:		0.392965
  validation accuracy:		88.80 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.286695
  validation loss:		0.421450
  validation accuracy:		88.59 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.282870
  validation loss:		0.400896
  validation accuracy:		87.93 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.278378
  validation loss:		0.402925
  validation accuracy:		87.93 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.290236
  validation loss:		0.410898
  validation accuracy:		88.80 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.286069
  validation loss:		0.396024
  validation accuracy:		88.59 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.289728
  validation loss:		0.404198
  validation accuracy:		88.26 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.290709
  validation loss:		0.404368
  validation accuracy:		87.83 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.290461
  validation loss:		0.408600
  validation accuracy:		87.50 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.281246
  validation loss:		0.400683
  validation accuracy:		88.15 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.286318
  validation loss:		0.400071
  validation accuracy:		88.70 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.293388
  validation loss:		0.401629
  validation accuracy:		87.61 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.288600
  validation loss:		0.401482
  validation accuracy:		88.37 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.281844
  validation loss:		0.447657
  validation accuracy:		86.74 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.287257
  validation loss:		0.421514
  validation accuracy:		87.28 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.287396
  validation loss:		0.402690
  validation accuracy:		88.48 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.285839
  validation loss:		0.413885
  validation accuracy:		88.80 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.291606
  validation loss:		0.420102
  validation accuracy:		87.93 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.291884
  validation loss:		0.408030
  validation accuracy:		88.48 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.290980
  validation loss:		0.416901
  validation accuracy:		87.72 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.285713
  validation loss:		0.396671
  validation accuracy:		88.37 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.288309
  validation loss:		0.405526
  validation accuracy:		87.93 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.284821
  validation loss:		0.421096
  validation accuracy:		87.50 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.295895
  validation loss:		0.421334
  validation accuracy:		87.17 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.287876
  validation loss:		0.406603
  validation accuracy:		88.26 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.292635
  validation loss:		0.415462
  validation accuracy:		87.93 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.289207
  validation loss:		0.406895
  validation accuracy:		88.26 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.287373
  validation loss:		0.399895
  validation accuracy:		87.72 %
Epoch 1838 of 2000 took 0.036s
  training loss:		0.287572
  validation loss:		0.408140
  validation accuracy:		87.39 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.286165
  validation loss:		0.413282
  validation accuracy:		87.83 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.284818
  validation loss:		0.418799
  validation accuracy:		88.59 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.285352
  validation loss:		0.424278
  validation accuracy:		87.17 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.291510
  validation loss:		0.410096
  validation accuracy:		87.83 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.290907
  validation loss:		0.406876
  validation accuracy:		88.37 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.283945
  validation loss:		0.403714
  validation accuracy:		88.48 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.284743
  validation loss:		0.412400
  validation accuracy:		88.48 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.287624
  validation loss:		0.419552
  validation accuracy:		87.93 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.281958
  validation loss:		0.429804
  validation accuracy:		87.17 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.286347
  validation loss:		0.412326
  validation accuracy:		88.70 %
Epoch 1849 of 2000 took 0.036s
  training loss:		0.292116
  validation loss:		0.422377
  validation accuracy:		87.28 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.288643
  validation loss:		0.426787
  validation accuracy:		87.28 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.292693
  validation loss:		0.422027
  validation accuracy:		87.28 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.287383
  validation loss:		0.402948
  validation accuracy:		88.04 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.284924
  validation loss:		0.400777
  validation accuracy:		88.26 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.284433
  validation loss:		0.437476
  validation accuracy:		87.61 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.281008
  validation loss:		0.412973
  validation accuracy:		87.50 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.292269
  validation loss:		0.400975
  validation accuracy:		88.26 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.286737
  validation loss:		0.417852
  validation accuracy:		87.17 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.286814
  validation loss:		0.411298
  validation accuracy:		87.50 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.286920
  validation loss:		0.410346
  validation accuracy:		88.04 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.283731
  validation loss:		0.413011
  validation accuracy:		88.59 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.295868
  validation loss:		0.430884
  validation accuracy:		87.07 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.288284
  validation loss:		0.426996
  validation accuracy:		88.04 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.285595
  validation loss:		0.407323
  validation accuracy:		88.15 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.283923
  validation loss:		0.400902
  validation accuracy:		88.04 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.285673
  validation loss:		0.425316
  validation accuracy:		86.96 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.292295
  validation loss:		0.414825
  validation accuracy:		88.37 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.285589
  validation loss:		0.409206
  validation accuracy:		88.04 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.289913
  validation loss:		0.403055
  validation accuracy:		88.48 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.282841
  validation loss:		0.423926
  validation accuracy:		87.61 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.292505
  validation loss:		0.417160
  validation accuracy:		87.39 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.290754
  validation loss:		0.426036
  validation accuracy:		87.28 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.285302
  validation loss:		0.417626
  validation accuracy:		88.59 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.287692
  validation loss:		0.404708
  validation accuracy:		88.15 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.285798
  validation loss:		0.406659
  validation accuracy:		88.37 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.284977
  validation loss:		0.406444
  validation accuracy:		88.04 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.282958
  validation loss:		0.425125
  validation accuracy:		87.72 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.289879
  validation loss:		0.409716
  validation accuracy:		88.59 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.287916
  validation loss:		0.404682
  validation accuracy:		88.26 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.289541
  validation loss:		0.416371
  validation accuracy:		87.93 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.287786
  validation loss:		0.410976
  validation accuracy:		87.72 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.286112
  validation loss:		0.417675
  validation accuracy:		86.96 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.284378
  validation loss:		0.420158
  validation accuracy:		87.61 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.291453
  validation loss:		0.411399
  validation accuracy:		87.39 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.282547
  validation loss:		0.431249
  validation accuracy:		87.28 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.288659
  validation loss:		0.401228
  validation accuracy:		87.93 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.289268
  validation loss:		0.395946
  validation accuracy:		88.04 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.289220
  validation loss:		0.409894
  validation accuracy:		88.37 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.291621
  validation loss:		0.415625
  validation accuracy:		87.61 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.281976
  validation loss:		0.414425
  validation accuracy:		88.59 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.289046
  validation loss:		0.393701
  validation accuracy:		88.37 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.287587
  validation loss:		0.420386
  validation accuracy:		87.39 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.294061
  validation loss:		0.413520
  validation accuracy:		87.07 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.298242
  validation loss:		0.403974
  validation accuracy:		88.37 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.287691
  validation loss:		0.404536
  validation accuracy:		87.50 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.285491
  validation loss:		0.414992
  validation accuracy:		88.59 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.286435
  validation loss:		0.443615
  validation accuracy:		87.07 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.289867
  validation loss:		0.433223
  validation accuracy:		87.83 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.290501
  validation loss:		0.413021
  validation accuracy:		88.37 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.285542
  validation loss:		0.406834
  validation accuracy:		88.26 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.287686
  validation loss:		0.404280
  validation accuracy:		87.72 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.285368
  validation loss:		0.421553
  validation accuracy:		88.26 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.292013
  validation loss:		0.425021
  validation accuracy:		88.15 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.292591
  validation loss:		0.452016
  validation accuracy:		86.63 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.286136
  validation loss:		0.427054
  validation accuracy:		87.50 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.285463
  validation loss:		0.406457
  validation accuracy:		87.28 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.289265
  validation loss:		0.406550
  validation accuracy:		87.72 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.284148
  validation loss:		0.417979
  validation accuracy:		87.72 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.283122
  validation loss:		0.413514
  validation accuracy:		87.72 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.284552
  validation loss:		0.403459
  validation accuracy:		87.83 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.285837
  validation loss:		0.447935
  validation accuracy:		86.74 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.290804
  validation loss:		0.424029
  validation accuracy:		87.17 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.288326
  validation loss:		0.429206
  validation accuracy:		86.85 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.283247
  validation loss:		0.406711
  validation accuracy:		88.04 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.282677
  validation loss:		0.398468
  validation accuracy:		87.72 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.286211
  validation loss:		0.400892
  validation accuracy:		87.83 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.282663
  validation loss:		0.415925
  validation accuracy:		87.83 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.290149
  validation loss:		0.418040
  validation accuracy:		88.26 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.279123
  validation loss:		0.405746
  validation accuracy:		87.72 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.290085
  validation loss:		0.398394
  validation accuracy:		88.37 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.286853
  validation loss:		0.411111
  validation accuracy:		87.50 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.279918
  validation loss:		0.421293
  validation accuracy:		88.04 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.281825
  validation loss:		0.413702
  validation accuracy:		87.17 %
Epoch 1923 of 2000 took 0.036s
  training loss:		0.288375
  validation loss:		0.409517
  validation accuracy:		88.70 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.286937
  validation loss:		0.406994
  validation accuracy:		88.48 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.290142
  validation loss:		0.440660
  validation accuracy:		87.07 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.281511
  validation loss:		0.418186
  validation accuracy:		87.72 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.284012
  validation loss:		0.408834
  validation accuracy:		88.70 %
Epoch 1928 of 2000 took 0.036s
  training loss:		0.285366
  validation loss:		0.411298
  validation accuracy:		87.61 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.291700
  validation loss:		0.418833
  validation accuracy:		87.93 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.288350
  validation loss:		0.432288
  validation accuracy:		87.28 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.286986
  validation loss:		0.409902
  validation accuracy:		88.48 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.283312
  validation loss:		0.401788
  validation accuracy:		87.83 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.285780
  validation loss:		0.412386
  validation accuracy:		87.39 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.288078
  validation loss:		0.404484
  validation accuracy:		87.17 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.296268
  validation loss:		0.402122
  validation accuracy:		88.26 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.285773
  validation loss:		0.404534
  validation accuracy:		87.61 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.289167
  validation loss:		0.412529
  validation accuracy:		87.50 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.283091
  validation loss:		0.412753
  validation accuracy:		88.26 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.291924
  validation loss:		0.409375
  validation accuracy:		88.04 %
Epoch 1940 of 2000 took 0.036s
  training loss:		0.288772
  validation loss:		0.402447
  validation accuracy:		88.26 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.292468
  validation loss:		0.411833
  validation accuracy:		88.26 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.293010
  validation loss:		0.401937
  validation accuracy:		87.83 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.286134
  validation loss:		0.416654
  validation accuracy:		87.61 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.283663
  validation loss:		0.402502
  validation accuracy:		87.83 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.284473
  validation loss:		0.427757
  validation accuracy:		87.72 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.286950
  validation loss:		0.405995
  validation accuracy:		88.15 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.287138
  validation loss:		0.414064
  validation accuracy:		88.04 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.287650
  validation loss:		0.405234
  validation accuracy:		87.83 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.291957
  validation loss:		0.425419
  validation accuracy:		87.07 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.279552
  validation loss:		0.422008
  validation accuracy:		87.61 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.285079
  validation loss:		0.418807
  validation accuracy:		87.72 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.286408
  validation loss:		0.413301
  validation accuracy:		88.37 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.283536
  validation loss:		0.413234
  validation accuracy:		88.37 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.283388
  validation loss:		0.408130
  validation accuracy:		87.72 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.292749
  validation loss:		0.442534
  validation accuracy:		87.83 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.284598
  validation loss:		0.411736
  validation accuracy:		88.15 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.281448
  validation loss:		0.408095
  validation accuracy:		88.26 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.280823
  validation loss:		0.414429
  validation accuracy:		88.37 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.285527
  validation loss:		0.428265
  validation accuracy:		87.83 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.279521
  validation loss:		0.402407
  validation accuracy:		87.72 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.289875
  validation loss:		0.428647
  validation accuracy:		87.39 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.284302
  validation loss:		0.415273
  validation accuracy:		87.72 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.278999
  validation loss:		0.401739
  validation accuracy:		88.48 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.284262
  validation loss:		0.412611
  validation accuracy:		88.37 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.281825
  validation loss:		0.409708
  validation accuracy:		87.39 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.285029
  validation loss:		0.405216
  validation accuracy:		88.15 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.289120
  validation loss:		0.414487
  validation accuracy:		88.37 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.287847
  validation loss:		0.418738
  validation accuracy:		87.93 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.288386
  validation loss:		0.409252
  validation accuracy:		87.61 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.292784
  validation loss:		0.436438
  validation accuracy:		87.28 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.285210
  validation loss:		0.405931
  validation accuracy:		88.04 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.286809
  validation loss:		0.413250
  validation accuracy:		88.15 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.284898
  validation loss:		0.440256
  validation accuracy:		87.17 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.286923
  validation loss:		0.420418
  validation accuracy:		88.26 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.289835
  validation loss:		0.428607
  validation accuracy:		87.61 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.290426
  validation loss:		0.410501
  validation accuracy:		88.37 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.283653
  validation loss:		0.424083
  validation accuracy:		87.93 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.284787
  validation loss:		0.403906
  validation accuracy:		87.93 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.280143
  validation loss:		0.409584
  validation accuracy:		88.26 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.280287
  validation loss:		0.421749
  validation accuracy:		88.26 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.287753
  validation loss:		0.433072
  validation accuracy:		87.17 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.284958
  validation loss:		0.401618
  validation accuracy:		87.93 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.287802
  validation loss:		0.406406
  validation accuracy:		87.83 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.285815
  validation loss:		0.418365
  validation accuracy:		87.28 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.285349
  validation loss:		0.411811
  validation accuracy:		87.39 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.286294
  validation loss:		0.436454
  validation accuracy:		86.96 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.279648
  validation loss:		0.401587
  validation accuracy:		88.37 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.280061
  validation loss:		0.416702
  validation accuracy:		88.37 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.286366
  validation loss:		0.410755
  validation accuracy:		87.17 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.282908
  validation loss:		0.407293
  validation accuracy:		87.83 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.285640
  validation loss:		0.405847
  validation accuracy:		88.37 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.289854
  validation loss:		0.413034
  validation accuracy:		87.39 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.282331
  validation loss:		0.448081
  validation accuracy:		86.85 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.289955
  validation loss:		0.403579
  validation accuracy:		88.37 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.289895
  validation loss:		0.413594
  validation accuracy:		88.48 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.280404
  validation loss:		0.430142
  validation accuracy:		87.28 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.281985
  validation loss:		0.415511
  validation accuracy:		87.39 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.284534
  validation loss:		0.460373
  validation accuracy:		86.41 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.292519
  validation loss:		0.426898
  validation accuracy:		88.04 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.288486
  validation loss:		0.414388
  validation accuracy:		88.04 %
Final results:
  test loss:			0.820820
  test accuracy:		79.60 %
