Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
Starting training...
Epoch 1 of 2000 took 0.105s
  training loss:		2.985126
  validation loss:		2.970711
  validation accuracy:		8.91 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.944765
  validation loss:		2.924470
  validation accuracy:		6.52 %
Epoch 3 of 2000 took 0.095s
  training loss:		2.893452
  validation loss:		2.876064
  validation accuracy:		4.78 %
Epoch 4 of 2000 took 0.095s
  training loss:		2.842287
  validation loss:		2.827280
  validation accuracy:		2.83 %
Epoch 5 of 2000 took 0.095s
  training loss:		2.791454
  validation loss:		2.777761
  validation accuracy:		2.07 %
Epoch 6 of 2000 took 0.095s
  training loss:		2.741136
  validation loss:		2.726675
  validation accuracy:		1.74 %
Epoch 7 of 2000 took 0.095s
  training loss:		2.692158
  validation loss:		2.674446
  validation accuracy:		3.26 %
Epoch 8 of 2000 took 0.095s
  training loss:		2.640800
  validation loss:		2.619680
  validation accuracy:		7.83 %
Epoch 9 of 2000 took 0.095s
  training loss:		2.592993
  validation loss:		2.562808
  validation accuracy:		14.89 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.544079
  validation loss:		2.503649
  validation accuracy:		14.89 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.492657
  validation loss:		2.443959
  validation accuracy:		15.11 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.446457
  validation loss:		2.387954
  validation accuracy:		16.96 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.402619
  validation loss:		2.338122
  validation accuracy:		20.98 %
Epoch 14 of 2000 took 0.099s
  training loss:		2.366705
  validation loss:		2.299230
  validation accuracy:		23.48 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.338689
  validation loss:		2.273593
  validation accuracy:		24.57 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.318314
  validation loss:		2.256486
  validation accuracy:		29.02 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.305058
  validation loss:		2.245734
  validation accuracy:		28.70 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.295067
  validation loss:		2.241431
  validation accuracy:		29.24 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.287921
  validation loss:		2.234992
  validation accuracy:		28.26 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.281177
  validation loss:		2.230491
  validation accuracy:		32.50 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.277422
  validation loss:		2.225829
  validation accuracy:		33.26 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.272781
  validation loss:		2.219487
  validation accuracy:		31.30 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.269837
  validation loss:		2.215686
  validation accuracy:		33.80 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.266069
  validation loss:		2.213852
  validation accuracy:		32.17 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.261854
  validation loss:		2.209236
  validation accuracy:		35.00 %
Epoch 26 of 2000 took 0.096s
  training loss:		2.258959
  validation loss:		2.206814
  validation accuracy:		33.48 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.255615
  validation loss:		2.203747
  validation accuracy:		37.07 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.251858
  validation loss:		2.198604
  validation accuracy:		34.02 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.248747
  validation loss:		2.195549
  validation accuracy:		31.63 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.244499
  validation loss:		2.194950
  validation accuracy:		37.07 %
Epoch 31 of 2000 took 0.096s
  training loss:		2.239966
  validation loss:		2.185885
  validation accuracy:		37.17 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.235955
  validation loss:		2.184858
  validation accuracy:		35.87 %
Epoch 33 of 2000 took 0.096s
  training loss:		2.233013
  validation loss:		2.180367
  validation accuracy:		39.78 %
Epoch 34 of 2000 took 0.099s
  training loss:		2.226521
  validation loss:		2.173828
  validation accuracy:		37.28 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.220766
  validation loss:		2.166905
  validation accuracy:		36.74 %
Epoch 36 of 2000 took 0.096s
  training loss:		2.214475
  validation loss:		2.158179
  validation accuracy:		39.13 %
Epoch 37 of 2000 took 0.096s
  training loss:		2.207557
  validation loss:		2.149527
  validation accuracy:		39.35 %
Epoch 38 of 2000 took 0.096s
  training loss:		2.201669
  validation loss:		2.142994
  validation accuracy:		38.48 %
Epoch 39 of 2000 took 0.096s
  training loss:		2.191976
  validation loss:		2.134670
  validation accuracy:		40.98 %
Epoch 40 of 2000 took 0.096s
  training loss:		2.185243
  validation loss:		2.128468
  validation accuracy:		37.83 %
Epoch 41 of 2000 took 0.096s
  training loss:		2.176719
  validation loss:		2.115965
  validation accuracy:		42.07 %
Epoch 42 of 2000 took 0.096s
  training loss:		2.163477
  validation loss:		2.105420
  validation accuracy:		42.72 %
Epoch 43 of 2000 took 0.096s
  training loss:		2.151985
  validation loss:		2.092580
  validation accuracy:		39.46 %
Epoch 44 of 2000 took 0.096s
  training loss:		2.138052
  validation loss:		2.072391
  validation accuracy:		38.48 %
Epoch 45 of 2000 took 0.096s
  training loss:		2.121045
  validation loss:		2.057884
  validation accuracy:		39.13 %
Epoch 46 of 2000 took 0.096s
  training loss:		2.103213
  validation loss:		2.039215
  validation accuracy:		40.33 %
Epoch 47 of 2000 took 0.096s
  training loss:		2.083522
  validation loss:		2.011137
  validation accuracy:		39.02 %
Epoch 48 of 2000 took 0.096s
  training loss:		2.062081
  validation loss:		1.995147
  validation accuracy:		41.09 %
Epoch 49 of 2000 took 0.096s
  training loss:		2.036968
  validation loss:		1.968681
  validation accuracy:		38.37 %
Epoch 50 of 2000 took 0.096s
  training loss:		2.012578
  validation loss:		1.942345
  validation accuracy:		40.00 %
Epoch 51 of 2000 took 0.096s
  training loss:		1.982036
  validation loss:		1.902902
  validation accuracy:		42.61 %
Epoch 52 of 2000 took 0.096s
  training loss:		1.951678
  validation loss:		1.877282
  validation accuracy:		42.93 %
Epoch 53 of 2000 took 0.096s
  training loss:		1.919565
  validation loss:		1.843152
  validation accuracy:		42.17 %
Epoch 54 of 2000 took 0.096s
  training loss:		1.884464
  validation loss:		1.813193
  validation accuracy:		44.02 %
Epoch 55 of 2000 took 0.096s
  training loss:		1.853855
  validation loss:		1.779942
  validation accuracy:		46.20 %
Epoch 56 of 2000 took 0.096s
  training loss:		1.815852
  validation loss:		1.743916
  validation accuracy:		46.96 %
Epoch 57 of 2000 took 0.096s
  training loss:		1.781754
  validation loss:		1.713507
  validation accuracy:		46.63 %
Epoch 58 of 2000 took 0.096s
  training loss:		1.749864
  validation loss:		1.686756
  validation accuracy:		46.85 %
Epoch 59 of 2000 took 0.096s
  training loss:		1.716721
  validation loss:		1.650234
  validation accuracy:		49.46 %
Epoch 60 of 2000 took 0.096s
  training loss:		1.680767
  validation loss:		1.635698
  validation accuracy:		45.76 %
Epoch 61 of 2000 took 0.096s
  training loss:		1.656640
  validation loss:		1.584817
  validation accuracy:		49.24 %
Epoch 62 of 2000 took 0.098s
  training loss:		1.617291
  validation loss:		1.573770
  validation accuracy:		50.87 %
Epoch 63 of 2000 took 0.097s
  training loss:		1.592360
  validation loss:		1.543992
  validation accuracy:		50.43 %
Epoch 64 of 2000 took 0.097s
  training loss:		1.562144
  validation loss:		1.507274
  validation accuracy:		50.43 %
Epoch 65 of 2000 took 0.096s
  training loss:		1.535510
  validation loss:		1.498578
  validation accuracy:		50.87 %
Epoch 66 of 2000 took 0.096s
  training loss:		1.511185
  validation loss:		1.454235
  validation accuracy:		53.91 %
Epoch 67 of 2000 took 0.096s
  training loss:		1.476935
  validation loss:		1.433681
  validation accuracy:		52.93 %
Epoch 68 of 2000 took 0.096s
  training loss:		1.454567
  validation loss:		1.414054
  validation accuracy:		54.13 %
Epoch 69 of 2000 took 0.096s
  training loss:		1.428894
  validation loss:		1.396492
  validation accuracy:		54.35 %
Epoch 70 of 2000 took 0.096s
  training loss:		1.415708
  validation loss:		1.370038
  validation accuracy:		55.11 %
Epoch 71 of 2000 took 0.096s
  training loss:		1.385450
  validation loss:		1.340835
  validation accuracy:		57.83 %
Epoch 72 of 2000 took 0.096s
  training loss:		1.359604
  validation loss:		1.330281
  validation accuracy:		57.93 %
Epoch 73 of 2000 took 0.096s
  training loss:		1.350393
  validation loss:		1.297307
  validation accuracy:		59.89 %
Epoch 74 of 2000 took 0.096s
  training loss:		1.320627
  validation loss:		1.297692
  validation accuracy:		59.67 %
Epoch 75 of 2000 took 0.096s
  training loss:		1.306955
  validation loss:		1.265900
  validation accuracy:		60.76 %
Epoch 76 of 2000 took 0.096s
  training loss:		1.287448
  validation loss:		1.244310
  validation accuracy:		62.39 %
Epoch 77 of 2000 took 0.096s
  training loss:		1.259090
  validation loss:		1.223929
  validation accuracy:		61.85 %
Epoch 78 of 2000 took 0.096s
  training loss:		1.248502
  validation loss:		1.211096
  validation accuracy:		64.24 %
Epoch 79 of 2000 took 0.096s
  training loss:		1.230742
  validation loss:		1.187524
  validation accuracy:		64.57 %
Epoch 80 of 2000 took 0.096s
  training loss:		1.207904
  validation loss:		1.164927
  validation accuracy:		65.33 %
Epoch 81 of 2000 took 0.096s
  training loss:		1.193623
  validation loss:		1.183265
  validation accuracy:		65.87 %
Epoch 82 of 2000 took 0.096s
  training loss:		1.177032
  validation loss:		1.143848
  validation accuracy:		67.61 %
Epoch 83 of 2000 took 0.096s
  training loss:		1.161669
  validation loss:		1.158333
  validation accuracy:		61.52 %
Epoch 84 of 2000 took 0.096s
  training loss:		1.162541
  validation loss:		1.090080
  validation accuracy:		67.28 %
Epoch 85 of 2000 took 0.096s
  training loss:		1.142763
  validation loss:		1.109234
  validation accuracy:		64.35 %
Epoch 86 of 2000 took 0.096s
  training loss:		1.135854
  validation loss:		1.069944
  validation accuracy:		68.70 %
Epoch 87 of 2000 took 0.096s
  training loss:		1.074581
  validation loss:		1.045608
  validation accuracy:		68.48 %
Epoch 88 of 2000 took 0.096s
  training loss:		1.103355
  validation loss:		1.025077
  validation accuracy:		69.35 %
Epoch 89 of 2000 took 0.096s
  training loss:		1.037505
  validation loss:		1.000696
  validation accuracy:		70.00 %
Epoch 90 of 2000 took 0.096s
  training loss:		1.074905
  validation loss:		1.018543
  validation accuracy:		70.00 %
Epoch 91 of 2000 took 0.096s
  training loss:		1.028741
  validation loss:		0.991738
  validation accuracy:		69.24 %
Epoch 92 of 2000 took 0.096s
  training loss:		1.012546
  validation loss:		0.965083
  validation accuracy:		70.65 %
Epoch 93 of 2000 took 0.096s
  training loss:		0.975594
  validation loss:		0.964950
  validation accuracy:		71.41 %
Epoch 94 of 2000 took 0.096s
  training loss:		0.956449
  validation loss:		0.931198
  validation accuracy:		72.28 %
Epoch 95 of 2000 took 0.096s
  training loss:		0.945299
  validation loss:		0.909987
  validation accuracy:		73.04 %
Epoch 96 of 2000 took 0.099s
  training loss:		0.945505
  validation loss:		0.921439
  validation accuracy:		71.74 %
Epoch 97 of 2000 took 0.096s
  training loss:		0.968207
  validation loss:		0.930419
  validation accuracy:		70.98 %
Epoch 98 of 2000 took 0.096s
  training loss:		0.914194
  validation loss:		0.864007
  validation accuracy:		73.37 %
Epoch 99 of 2000 took 0.096s
  training loss:		0.894738
  validation loss:		0.872617
  validation accuracy:		73.70 %
Epoch 100 of 2000 took 0.096s
  training loss:		0.898867
  validation loss:		0.881965
  validation accuracy:		72.61 %
Epoch 101 of 2000 took 0.096s
  training loss:		0.868385
  validation loss:		0.850557
  validation accuracy:		74.67 %
Epoch 102 of 2000 took 0.096s
  training loss:		0.857531
  validation loss:		0.813246
  validation accuracy:		75.33 %
Epoch 103 of 2000 took 0.096s
  training loss:		0.829121
  validation loss:		0.810384
  validation accuracy:		75.43 %
Epoch 104 of 2000 took 0.096s
  training loss:		0.820025
  validation loss:		0.790443
  validation accuracy:		75.54 %
Epoch 105 of 2000 took 0.096s
  training loss:		0.822909
  validation loss:		0.845475
  validation accuracy:		72.39 %
Epoch 106 of 2000 took 0.096s
  training loss:		0.805382
  validation loss:		0.772821
  validation accuracy:		76.74 %
Epoch 107 of 2000 took 0.096s
  training loss:		0.839792
  validation loss:		0.774503
  validation accuracy:		75.98 %
Epoch 108 of 2000 took 0.096s
  training loss:		0.776696
  validation loss:		0.752383
  validation accuracy:		75.98 %
Epoch 109 of 2000 took 0.096s
  training loss:		0.751811
  validation loss:		0.733205
  validation accuracy:		77.61 %
Epoch 110 of 2000 took 0.096s
  training loss:		0.748225
  validation loss:		0.735763
  validation accuracy:		76.74 %
Epoch 111 of 2000 took 0.096s
  training loss:		0.736933
  validation loss:		0.720504
  validation accuracy:		76.41 %
Epoch 112 of 2000 took 0.096s
  training loss:		0.720294
  validation loss:		0.704213
  validation accuracy:		77.17 %
Epoch 113 of 2000 took 0.096s
  training loss:		0.713195
  validation loss:		0.693322
  validation accuracy:		78.80 %
Epoch 114 of 2000 took 0.096s
  training loss:		0.701728
  validation loss:		0.685224
  validation accuracy:		78.15 %
Epoch 115 of 2000 took 0.096s
  training loss:		0.687491
  validation loss:		0.685690
  validation accuracy:		78.26 %
Epoch 116 of 2000 took 0.096s
  training loss:		0.665415
  validation loss:		0.675399
  validation accuracy:		78.37 %
Epoch 117 of 2000 took 0.096s
  training loss:		0.670226
  validation loss:		0.659967
  validation accuracy:		78.26 %
Epoch 118 of 2000 took 0.096s
  training loss:		0.671693
  validation loss:		0.658320
  validation accuracy:		77.93 %
Epoch 119 of 2000 took 0.096s
  training loss:		0.649792
  validation loss:		0.647180
  validation accuracy:		78.80 %
Epoch 120 of 2000 took 0.096s
  training loss:		0.632886
  validation loss:		0.662376
  validation accuracy:		77.83 %
Epoch 121 of 2000 took 0.096s
  training loss:		0.624697
  validation loss:		0.618585
  validation accuracy:		79.67 %
Epoch 122 of 2000 took 0.096s
  training loss:		0.616544
  validation loss:		0.613866
  validation accuracy:		79.35 %
Epoch 123 of 2000 took 0.096s
  training loss:		0.621979
  validation loss:		0.610627
  validation accuracy:		80.65 %
Epoch 124 of 2000 took 0.096s
  training loss:		0.594206
  validation loss:		0.599059
  validation accuracy:		79.89 %
Epoch 125 of 2000 took 0.096s
  training loss:		0.576473
  validation loss:		0.603261
  validation accuracy:		79.46 %
Epoch 126 of 2000 took 0.096s
  training loss:		0.571954
  validation loss:		0.585153
  validation accuracy:		80.76 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.556395
  validation loss:		0.575981
  validation accuracy:		80.87 %
Epoch 128 of 2000 took 0.096s
  training loss:		0.574090
  validation loss:		0.579806
  validation accuracy:		82.17 %
Epoch 129 of 2000 took 0.096s
  training loss:		0.549427
  validation loss:		0.557818
  validation accuracy:		81.63 %
Epoch 130 of 2000 took 0.096s
  training loss:		0.540622
  validation loss:		0.568298
  validation accuracy:		81.74 %
Epoch 131 of 2000 took 0.096s
  training loss:		0.532196
  validation loss:		0.568103
  validation accuracy:		82.83 %
Epoch 132 of 2000 took 0.096s
  training loss:		0.527015
  validation loss:		0.535928
  validation accuracy:		83.70 %
Epoch 133 of 2000 took 0.096s
  training loss:		0.513756
  validation loss:		0.534349
  validation accuracy:		82.61 %
Epoch 134 of 2000 took 0.096s
  training loss:		0.524187
  validation loss:		0.534888
  validation accuracy:		83.15 %
Epoch 135 of 2000 took 0.096s
  training loss:		0.504776
  validation loss:		0.523431
  validation accuracy:		82.83 %
Epoch 136 of 2000 took 0.096s
  training loss:		0.492098
  validation loss:		0.533961
  validation accuracy:		82.50 %
Epoch 137 of 2000 took 0.099s
  training loss:		0.492633
  validation loss:		0.520051
  validation accuracy:		82.83 %
Epoch 138 of 2000 took 0.096s
  training loss:		0.490683
  validation loss:		0.503506
  validation accuracy:		83.80 %
Epoch 139 of 2000 took 0.096s
  training loss:		0.483522
  validation loss:		0.491983
  validation accuracy:		84.35 %
Epoch 140 of 2000 took 0.096s
  training loss:		0.480465
  validation loss:		0.504831
  validation accuracy:		83.48 %
Epoch 141 of 2000 took 0.096s
  training loss:		0.475880
  validation loss:		0.493339
  validation accuracy:		83.26 %
Epoch 142 of 2000 took 0.096s
  training loss:		0.470636
  validation loss:		0.479830
  validation accuracy:		84.78 %
Epoch 143 of 2000 took 0.096s
  training loss:		0.459904
  validation loss:		0.476767
  validation accuracy:		85.65 %
Epoch 144 of 2000 took 0.096s
  training loss:		0.455934
  validation loss:		0.475565
  validation accuracy:		85.76 %
Epoch 145 of 2000 took 0.096s
  training loss:		0.455525
  validation loss:		0.473360
  validation accuracy:		84.67 %
Epoch 146 of 2000 took 0.096s
  training loss:		0.450193
  validation loss:		0.460116
  validation accuracy:		85.43 %
Epoch 147 of 2000 took 0.096s
  training loss:		0.438814
  validation loss:		0.467505
  validation accuracy:		84.67 %
Epoch 148 of 2000 took 0.096s
  training loss:		0.443151
  validation loss:		0.463601
  validation accuracy:		84.46 %
Epoch 149 of 2000 took 0.096s
  training loss:		0.440578
  validation loss:		0.450482
  validation accuracy:		85.43 %
Epoch 150 of 2000 took 0.096s
  training loss:		0.433517
  validation loss:		0.469927
  validation accuracy:		85.22 %
Epoch 151 of 2000 took 0.096s
  training loss:		0.426707
  validation loss:		0.444753
  validation accuracy:		85.43 %
Epoch 152 of 2000 took 0.096s
  training loss:		0.422230
  validation loss:		0.439723
  validation accuracy:		85.87 %
Epoch 153 of 2000 took 0.096s
  training loss:		0.414594
  validation loss:		0.434092
  validation accuracy:		86.09 %
Epoch 154 of 2000 took 0.096s
  training loss:		0.420383
  validation loss:		0.434491
  validation accuracy:		85.33 %
Epoch 155 of 2000 took 0.096s
  training loss:		0.409415
  validation loss:		0.436561
  validation accuracy:		86.20 %
Epoch 156 of 2000 took 0.096s
  training loss:		0.412872
  validation loss:		0.436849
  validation accuracy:		86.20 %
Epoch 157 of 2000 took 0.096s
  training loss:		0.404588
  validation loss:		0.437336
  validation accuracy:		85.54 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.402898
  validation loss:		0.425881
  validation accuracy:		86.41 %
Epoch 159 of 2000 took 0.096s
  training loss:		0.401269
  validation loss:		0.421286
  validation accuracy:		86.74 %
Epoch 160 of 2000 took 0.096s
  training loss:		0.399004
  validation loss:		0.425092
  validation accuracy:		86.09 %
Epoch 161 of 2000 took 0.096s
  training loss:		0.384030
  validation loss:		0.415219
  validation accuracy:		87.07 %
Epoch 162 of 2000 took 0.096s
  training loss:		0.390309
  validation loss:		0.419920
  validation accuracy:		86.85 %
Epoch 163 of 2000 took 0.096s
  training loss:		0.381013
  validation loss:		0.410057
  validation accuracy:		88.04 %
Epoch 164 of 2000 took 0.096s
  training loss:		0.390279
  validation loss:		0.408437
  validation accuracy:		87.72 %
Epoch 165 of 2000 took 0.096s
  training loss:		0.383557
  validation loss:		0.420291
  validation accuracy:		87.07 %
Epoch 166 of 2000 took 0.096s
  training loss:		0.383606
  validation loss:		0.416455
  validation accuracy:		86.63 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.373517
  validation loss:		0.410081
  validation accuracy:		87.07 %
Epoch 168 of 2000 took 0.096s
  training loss:		0.381852
  validation loss:		0.423601
  validation accuracy:		87.17 %
Epoch 169 of 2000 took 0.096s
  training loss:		0.375627
  validation loss:		0.392961
  validation accuracy:		88.15 %
Epoch 170 of 2000 took 0.096s
  training loss:		0.369001
  validation loss:		0.420554
  validation accuracy:		86.63 %
Epoch 171 of 2000 took 0.096s
  training loss:		0.366769
  validation loss:		0.400601
  validation accuracy:		87.72 %
Epoch 172 of 2000 took 0.096s
  training loss:		0.362937
  validation loss:		0.400992
  validation accuracy:		87.83 %
Epoch 173 of 2000 took 0.096s
  training loss:		0.358737
  validation loss:		0.392640
  validation accuracy:		87.07 %
Epoch 174 of 2000 took 0.096s
  training loss:		0.367911
  validation loss:		0.398938
  validation accuracy:		87.83 %
Epoch 175 of 2000 took 0.096s
  training loss:		0.354352
  validation loss:		0.406299
  validation accuracy:		87.50 %
Epoch 176 of 2000 took 0.096s
  training loss:		0.357943
  validation loss:		0.410484
  validation accuracy:		87.50 %
Epoch 177 of 2000 took 0.096s
  training loss:		0.362203
  validation loss:		0.393961
  validation accuracy:		87.39 %
Epoch 178 of 2000 took 0.096s
  training loss:		0.353791
  validation loss:		0.387531
  validation accuracy:		87.93 %
Epoch 179 of 2000 took 0.096s
  training loss:		0.350288
  validation loss:		0.388278
  validation accuracy:		88.15 %
Epoch 180 of 2000 took 0.096s
  training loss:		0.346200
  validation loss:		0.396459
  validation accuracy:		87.61 %
Epoch 181 of 2000 took 0.096s
  training loss:		0.349001
  validation loss:		0.391309
  validation accuracy:		87.61 %
Epoch 182 of 2000 took 0.096s
  training loss:		0.348094
  validation loss:		0.400544
  validation accuracy:		87.50 %
Epoch 183 of 2000 took 0.096s
  training loss:		0.347910
  validation loss:		0.406660
  validation accuracy:		87.50 %
Epoch 184 of 2000 took 0.096s
  training loss:		0.342629
  validation loss:		0.379384
  validation accuracy:		88.48 %
Epoch 185 of 2000 took 0.098s
  training loss:		0.341686
  validation loss:		0.408393
  validation accuracy:		87.61 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.342526
  validation loss:		0.385544
  validation accuracy:		88.26 %
Epoch 187 of 2000 took 0.096s
  training loss:		0.340901
  validation loss:		0.379648
  validation accuracy:		88.48 %
Epoch 188 of 2000 took 0.096s
  training loss:		0.343283
  validation loss:		0.392970
  validation accuracy:		87.17 %
Epoch 189 of 2000 took 0.096s
  training loss:		0.339779
  validation loss:		0.380218
  validation accuracy:		88.15 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.338135
  validation loss:		0.376069
  validation accuracy:		88.37 %
Epoch 191 of 2000 took 0.096s
  training loss:		0.336396
  validation loss:		0.369966
  validation accuracy:		88.48 %
Epoch 192 of 2000 took 0.096s
  training loss:		0.333007
  validation loss:		0.369177
  validation accuracy:		88.59 %
Epoch 193 of 2000 took 0.096s
  training loss:		0.333530
  validation loss:		0.396930
  validation accuracy:		87.50 %
Epoch 194 of 2000 took 0.096s
  training loss:		0.327027
  validation loss:		0.378144
  validation accuracy:		88.04 %
Epoch 195 of 2000 took 0.096s
  training loss:		0.330890
  validation loss:		0.368488
  validation accuracy:		88.04 %
Epoch 196 of 2000 took 0.096s
  training loss:		0.331497
  validation loss:		0.367791
  validation accuracy:		88.04 %
Epoch 197 of 2000 took 0.096s
  training loss:		0.326968
  validation loss:		0.368686
  validation accuracy:		88.80 %
Epoch 198 of 2000 took 0.096s
  training loss:		0.323685
  validation loss:		0.371430
  validation accuracy:		88.15 %
Epoch 199 of 2000 took 0.096s
  training loss:		0.327084
  validation loss:		0.370205
  validation accuracy:		88.59 %
Epoch 200 of 2000 took 0.096s
  training loss:		0.323294
  validation loss:		0.361439
  validation accuracy:		89.02 %
Epoch 201 of 2000 took 0.096s
  training loss:		0.327111
  validation loss:		0.363282
  validation accuracy:		88.37 %
Epoch 202 of 2000 took 0.096s
  training loss:		0.322963
  validation loss:		0.360901
  validation accuracy:		88.91 %
Epoch 203 of 2000 took 0.096s
  training loss:		0.315480
  validation loss:		0.370809
  validation accuracy:		89.24 %
Epoch 204 of 2000 took 0.096s
  training loss:		0.326675
  validation loss:		0.377788
  validation accuracy:		87.83 %
Epoch 205 of 2000 took 0.096s
  training loss:		0.321451
  validation loss:		0.376040
  validation accuracy:		88.26 %
Epoch 206 of 2000 took 0.096s
  training loss:		0.320048
  validation loss:		0.374621
  validation accuracy:		88.70 %
Epoch 207 of 2000 took 0.096s
  training loss:		0.314251
  validation loss:		0.357945
  validation accuracy:		88.80 %
Epoch 208 of 2000 took 0.096s
  training loss:		0.319417
  validation loss:		0.382079
  validation accuracy:		88.15 %
Epoch 209 of 2000 took 0.096s
  training loss:		0.316456
  validation loss:		0.359134
  validation accuracy:		89.24 %
Epoch 210 of 2000 took 0.096s
  training loss:		0.317692
  validation loss:		0.361308
  validation accuracy:		88.59 %
Epoch 211 of 2000 took 0.096s
  training loss:		0.314232
  validation loss:		0.366799
  validation accuracy:		88.70 %
Epoch 212 of 2000 took 0.096s
  training loss:		0.308334
  validation loss:		0.356856
  validation accuracy:		89.24 %
Epoch 213 of 2000 took 0.096s
  training loss:		0.312012
  validation loss:		0.356220
  validation accuracy:		89.02 %
Epoch 214 of 2000 took 0.096s
  training loss:		0.311198
  validation loss:		0.356552
  validation accuracy:		89.02 %
Epoch 215 of 2000 took 0.096s
  training loss:		0.302624
  validation loss:		0.357285
  validation accuracy:		88.59 %
Epoch 216 of 2000 took 0.096s
  training loss:		0.300341
  validation loss:		0.357659
  validation accuracy:		88.91 %
Epoch 217 of 2000 took 0.096s
  training loss:		0.306041
  validation loss:		0.356852
  validation accuracy:		88.91 %
Epoch 218 of 2000 took 0.096s
  training loss:		0.305867
  validation loss:		0.357686
  validation accuracy:		88.91 %
Epoch 219 of 2000 took 0.096s
  training loss:		0.309930
  validation loss:		0.362147
  validation accuracy:		89.02 %
Epoch 220 of 2000 took 0.096s
  training loss:		0.309564
  validation loss:		0.357765
  validation accuracy:		88.80 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.309400
  validation loss:		0.356549
  validation accuracy:		89.35 %
Epoch 222 of 2000 took 0.096s
  training loss:		0.302992
  validation loss:		0.358383
  validation accuracy:		88.59 %
Epoch 223 of 2000 took 0.096s
  training loss:		0.305018
  validation loss:		0.363992
  validation accuracy:		88.70 %
Epoch 224 of 2000 took 0.096s
  training loss:		0.303129
  validation loss:		0.365856
  validation accuracy:		88.48 %
Epoch 225 of 2000 took 0.096s
  training loss:		0.303602
  validation loss:		0.351378
  validation accuracy:		89.24 %
Epoch 226 of 2000 took 0.096s
  training loss:		0.301011
  validation loss:		0.353919
  validation accuracy:		89.02 %
Epoch 227 of 2000 took 0.096s
  training loss:		0.304073
  validation loss:		0.357260
  validation accuracy:		88.70 %
Epoch 228 of 2000 took 0.096s
  training loss:		0.298804
  validation loss:		0.363247
  validation accuracy:		89.24 %
Epoch 229 of 2000 took 0.096s
  training loss:		0.297087
  validation loss:		0.373690
  validation accuracy:		88.15 %
Epoch 230 of 2000 took 0.096s
  training loss:		0.300692
  validation loss:		0.357248
  validation accuracy:		89.13 %
Epoch 231 of 2000 took 0.096s
  training loss:		0.291103
  validation loss:		0.360558
  validation accuracy:		88.80 %
Epoch 232 of 2000 took 0.096s
  training loss:		0.289977
  validation loss:		0.365453
  validation accuracy:		88.48 %
Epoch 233 of 2000 took 0.096s
  training loss:		0.293455
  validation loss:		0.352411
  validation accuracy:		88.91 %
Epoch 234 of 2000 took 0.096s
  training loss:		0.292919
  validation loss:		0.358421
  validation accuracy:		88.59 %
Epoch 235 of 2000 took 0.096s
  training loss:		0.299850
  validation loss:		0.359869
  validation accuracy:		88.70 %
Epoch 236 of 2000 took 0.096s
  training loss:		0.300104
  validation loss:		0.362287
  validation accuracy:		88.91 %
Epoch 237 of 2000 took 0.096s
  training loss:		0.295828
  validation loss:		0.352449
  validation accuracy:		89.35 %
Epoch 238 of 2000 took 0.096s
  training loss:		0.294090
  validation loss:		0.356048
  validation accuracy:		88.80 %
Epoch 239 of 2000 took 0.096s
  training loss:		0.295175
  validation loss:		0.374197
  validation accuracy:		87.93 %
Epoch 240 of 2000 took 0.096s
  training loss:		0.290213
  validation loss:		0.360438
  validation accuracy:		88.48 %
Epoch 241 of 2000 took 0.096s
  training loss:		0.295916
  validation loss:		0.365754
  validation accuracy:		89.46 %
Epoch 242 of 2000 took 0.096s
  training loss:		0.283459
  validation loss:		0.347262
  validation accuracy:		88.91 %
Epoch 243 of 2000 took 0.096s
  training loss:		0.284238
  validation loss:		0.361723
  validation accuracy:		88.70 %
Epoch 244 of 2000 took 0.098s
  training loss:		0.289008
  validation loss:		0.348482
  validation accuracy:		89.24 %
Epoch 245 of 2000 took 0.096s
  training loss:		0.295382
  validation loss:		0.374066
  validation accuracy:		88.04 %
Epoch 246 of 2000 took 0.096s
  training loss:		0.283883
  validation loss:		0.351275
  validation accuracy:		88.91 %
Epoch 247 of 2000 took 0.096s
  training loss:		0.285777
  validation loss:		0.350059
  validation accuracy:		88.80 %
Epoch 248 of 2000 took 0.096s
  training loss:		0.290118
  validation loss:		0.415031
  validation accuracy:		86.74 %
Epoch 249 of 2000 took 0.096s
  training loss:		0.291110
  validation loss:		0.357845
  validation accuracy:		89.24 %
Epoch 250 of 2000 took 0.096s
  training loss:		0.282027
  validation loss:		0.350468
  validation accuracy:		88.70 %
Epoch 251 of 2000 took 0.096s
  training loss:		0.285035
  validation loss:		0.349528
  validation accuracy:		89.13 %
Epoch 252 of 2000 took 0.096s
  training loss:		0.281826
  validation loss:		0.353119
  validation accuracy:		89.02 %
Epoch 253 of 2000 took 0.096s
  training loss:		0.284650
  validation loss:		0.361343
  validation accuracy:		89.02 %
Epoch 254 of 2000 took 0.096s
  training loss:		0.286507
  validation loss:		0.360861
  validation accuracy:		88.91 %
Epoch 255 of 2000 took 0.096s
  training loss:		0.283302
  validation loss:		0.348945
  validation accuracy:		88.91 %
Epoch 256 of 2000 took 0.096s
  training loss:		0.281315
  validation loss:		0.354248
  validation accuracy:		88.80 %
Epoch 257 of 2000 took 0.096s
  training loss:		0.284591
  validation loss:		0.364771
  validation accuracy:		88.59 %
Epoch 258 of 2000 took 0.096s
  training loss:		0.274560
  validation loss:		0.349989
  validation accuracy:		88.91 %
Epoch 259 of 2000 took 0.096s
  training loss:		0.279877
  validation loss:		0.354659
  validation accuracy:		88.70 %
Epoch 260 of 2000 took 0.098s
  training loss:		0.282633
  validation loss:		0.399323
  validation accuracy:		87.07 %
Epoch 261 of 2000 took 0.098s
  training loss:		0.286791
  validation loss:		0.358948
  validation accuracy:		88.48 %
Epoch 262 of 2000 took 0.096s
  training loss:		0.278540
  validation loss:		0.351203
  validation accuracy:		88.91 %
Epoch 263 of 2000 took 0.096s
  training loss:		0.277048
  validation loss:		0.349240
  validation accuracy:		88.80 %
Epoch 264 of 2000 took 0.096s
  training loss:		0.273159
  validation loss:		0.349108
  validation accuracy:		89.35 %
Epoch 265 of 2000 took 0.096s
  training loss:		0.274129
  validation loss:		0.358072
  validation accuracy:		89.02 %
Epoch 266 of 2000 took 0.096s
  training loss:		0.271691
  validation loss:		0.349957
  validation accuracy:		89.24 %
Epoch 267 of 2000 took 0.096s
  training loss:		0.273044
  validation loss:		0.351942
  validation accuracy:		89.02 %
Epoch 268 of 2000 took 0.096s
  training loss:		0.274830
  validation loss:		0.349389
  validation accuracy:		89.24 %
Epoch 269 of 2000 took 0.096s
  training loss:		0.277797
  validation loss:		0.354322
  validation accuracy:		89.24 %
Epoch 270 of 2000 took 0.096s
  training loss:		0.274738
  validation loss:		0.348285
  validation accuracy:		88.59 %
Epoch 271 of 2000 took 0.096s
  training loss:		0.274193
  validation loss:		0.344985
  validation accuracy:		89.24 %
Epoch 272 of 2000 took 0.096s
  training loss:		0.275581
  validation loss:		0.357173
  validation accuracy:		88.91 %
Epoch 273 of 2000 took 0.096s
  training loss:		0.274861
  validation loss:		0.348497
  validation accuracy:		89.24 %
Epoch 274 of 2000 took 0.096s
  training loss:		0.268465
  validation loss:		0.369590
  validation accuracy:		88.37 %
Epoch 275 of 2000 took 0.096s
  training loss:		0.277300
  validation loss:		0.344525
  validation accuracy:		89.13 %
Epoch 276 of 2000 took 0.096s
  training loss:		0.273564
  validation loss:		0.350553
  validation accuracy:		89.24 %
Epoch 277 of 2000 took 0.096s
  training loss:		0.282989
  validation loss:		0.346860
  validation accuracy:		89.24 %
Epoch 278 of 2000 took 0.096s
  training loss:		0.275356
  validation loss:		0.345139
  validation accuracy:		88.91 %
Epoch 279 of 2000 took 0.096s
  training loss:		0.265786
  validation loss:		0.363973
  validation accuracy:		88.80 %
Epoch 280 of 2000 took 0.096s
  training loss:		0.270456
  validation loss:		0.376404
  validation accuracy:		87.83 %
Epoch 281 of 2000 took 0.096s
  training loss:		0.274517
  validation loss:		0.354041
  validation accuracy:		88.80 %
Epoch 282 of 2000 took 0.096s
  training loss:		0.262511
  validation loss:		0.350013
  validation accuracy:		89.46 %
Epoch 283 of 2000 took 0.096s
  training loss:		0.267022
  validation loss:		0.342707
  validation accuracy:		89.35 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.266251
  validation loss:		0.339231
  validation accuracy:		89.13 %
Epoch 285 of 2000 took 0.096s
  training loss:		0.281590
  validation loss:		0.344836
  validation accuracy:		89.35 %
Epoch 286 of 2000 took 0.096s
  training loss:		0.266559
  validation loss:		0.351408
  validation accuracy:		89.35 %
Epoch 287 of 2000 took 0.096s
  training loss:		0.268395
  validation loss:		0.341367
  validation accuracy:		89.57 %
Epoch 288 of 2000 took 0.096s
  training loss:		0.268137
  validation loss:		0.343618
  validation accuracy:		89.13 %
Epoch 289 of 2000 took 0.096s
  training loss:		0.259588
  validation loss:		0.369101
  validation accuracy:		88.04 %
Epoch 290 of 2000 took 0.098s
  training loss:		0.262523
  validation loss:		0.362658
  validation accuracy:		89.02 %
Epoch 291 of 2000 took 0.096s
  training loss:		0.265694
  validation loss:		0.351935
  validation accuracy:		89.13 %
Epoch 292 of 2000 took 0.096s
  training loss:		0.261686
  validation loss:		0.340886
  validation accuracy:		89.67 %
Epoch 293 of 2000 took 0.096s
  training loss:		0.259684
  validation loss:		0.340671
  validation accuracy:		89.35 %
Epoch 294 of 2000 took 0.096s
  training loss:		0.267831
  validation loss:		0.353878
  validation accuracy:		89.46 %
Epoch 295 of 2000 took 0.096s
  training loss:		0.270005
  validation loss:		0.373601
  validation accuracy:		87.83 %
Epoch 296 of 2000 took 0.096s
  training loss:		0.269394
  validation loss:		0.340708
  validation accuracy:		89.13 %
Epoch 297 of 2000 took 0.096s
  training loss:		0.265458
  validation loss:		0.350449
  validation accuracy:		89.13 %
Epoch 298 of 2000 took 0.096s
  training loss:		0.261042
  validation loss:		0.342224
  validation accuracy:		89.57 %
Epoch 299 of 2000 took 0.096s
  training loss:		0.260160
  validation loss:		0.356560
  validation accuracy:		89.24 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.276022
  validation loss:		0.354554
  validation accuracy:		89.02 %
Epoch 301 of 2000 took 0.100s
  training loss:		0.254151
  validation loss:		0.354926
  validation accuracy:		89.24 %
Epoch 302 of 2000 took 0.099s
  training loss:		0.267560
  validation loss:		0.345137
  validation accuracy:		89.46 %
Epoch 303 of 2000 took 0.099s
  training loss:		0.254236
  validation loss:		0.343466
  validation accuracy:		89.13 %
Epoch 304 of 2000 took 0.099s
  training loss:		0.264499
  validation loss:		0.338949
  validation accuracy:		89.35 %
Epoch 305 of 2000 took 0.099s
  training loss:		0.250257
  validation loss:		0.349167
  validation accuracy:		88.91 %
Epoch 306 of 2000 took 0.099s
  training loss:		0.257868
  validation loss:		0.354424
  validation accuracy:		88.91 %
Epoch 307 of 2000 took 0.099s
  training loss:		0.254478
  validation loss:		0.337035
  validation accuracy:		89.67 %
Epoch 308 of 2000 took 0.099s
  training loss:		0.258087
  validation loss:		0.342591
  validation accuracy:		89.78 %
Epoch 309 of 2000 took 0.099s
  training loss:		0.257526
  validation loss:		0.345167
  validation accuracy:		89.24 %
Epoch 310 of 2000 took 0.099s
  training loss:		0.249942
  validation loss:		0.347128
  validation accuracy:		89.24 %
Epoch 311 of 2000 took 0.099s
  training loss:		0.253292
  validation loss:		0.357379
  validation accuracy:		88.80 %
Epoch 312 of 2000 took 0.099s
  training loss:		0.251875
  validation loss:		0.368603
  validation accuracy:		88.70 %
Epoch 313 of 2000 took 0.099s
  training loss:		0.259143
  validation loss:		0.344400
  validation accuracy:		89.46 %
Epoch 314 of 2000 took 0.102s
  training loss:		0.253207
  validation loss:		0.340042
  validation accuracy:		89.67 %
Epoch 315 of 2000 took 0.100s
  training loss:		0.258323
  validation loss:		0.337940
  validation accuracy:		89.57 %
Epoch 316 of 2000 took 0.099s
  training loss:		0.252797
  validation loss:		0.361252
  validation accuracy:		88.80 %
Epoch 317 of 2000 took 0.099s
  training loss:		0.256484
  validation loss:		0.344376
  validation accuracy:		89.78 %
Epoch 318 of 2000 took 0.099s
  training loss:		0.251119
  validation loss:		0.336818
  validation accuracy:		89.13 %
Epoch 319 of 2000 took 0.099s
  training loss:		0.246977
  validation loss:		0.338663
  validation accuracy:		89.67 %
Epoch 320 of 2000 took 0.099s
  training loss:		0.252978
  validation loss:		0.336974
  validation accuracy:		89.57 %
Epoch 321 of 2000 took 0.099s
  training loss:		0.249817
  validation loss:		0.364613
  validation accuracy:		88.37 %
Epoch 322 of 2000 took 0.099s
  training loss:		0.243888
  validation loss:		0.348881
  validation accuracy:		89.57 %
Epoch 323 of 2000 took 0.099s
  training loss:		0.249002
  validation loss:		0.355939
  validation accuracy:		89.24 %
Epoch 324 of 2000 took 0.099s
  training loss:		0.253094
  validation loss:		0.337953
  validation accuracy:		89.35 %
Epoch 325 of 2000 took 0.099s
  training loss:		0.252652
  validation loss:		0.370250
  validation accuracy:		88.26 %
Epoch 326 of 2000 took 0.099s
  training loss:		0.252669
  validation loss:		0.355977
  validation accuracy:		88.80 %
Epoch 327 of 2000 took 0.099s
  training loss:		0.248250
  validation loss:		0.340507
  validation accuracy:		89.46 %
Epoch 328 of 2000 took 0.099s
  training loss:		0.253894
  validation loss:		0.339507
  validation accuracy:		89.24 %
Epoch 329 of 2000 took 0.099s
  training loss:		0.244282
  validation loss:		0.349130
  validation accuracy:		89.24 %
Epoch 330 of 2000 took 0.099s
  training loss:		0.249057
  validation loss:		0.360066
  validation accuracy:		89.02 %
Epoch 331 of 2000 took 0.099s
  training loss:		0.243897
  validation loss:		0.349254
  validation accuracy:		89.24 %
Epoch 332 of 2000 took 0.099s
  training loss:		0.247643
  validation loss:		0.343683
  validation accuracy:		89.67 %
Epoch 333 of 2000 took 0.099s
  training loss:		0.247674
  validation loss:		0.344710
  validation accuracy:		89.13 %
Epoch 334 of 2000 took 0.099s
  training loss:		0.244190
  validation loss:		0.337272
  validation accuracy:		89.57 %
Epoch 335 of 2000 took 0.099s
  training loss:		0.235722
  validation loss:		0.355677
  validation accuracy:		89.35 %
Epoch 336 of 2000 took 0.099s
  training loss:		0.245120
  validation loss:		0.334402
  validation accuracy:		89.46 %
Epoch 337 of 2000 took 0.099s
  training loss:		0.251122
  validation loss:		0.343613
  validation accuracy:		89.35 %
Epoch 338 of 2000 took 0.099s
  training loss:		0.244598
  validation loss:		0.333244
  validation accuracy:		89.89 %
Epoch 339 of 2000 took 0.099s
  training loss:		0.242348
  validation loss:		0.333564
  validation accuracy:		89.89 %
Epoch 340 of 2000 took 0.100s
  training loss:		0.239868
  validation loss:		0.340455
  validation accuracy:		89.35 %
Epoch 341 of 2000 took 0.104s
  training loss:		0.238955
  validation loss:		0.370701
  validation accuracy:		87.72 %
Epoch 342 of 2000 took 0.106s
  training loss:		0.241437
  validation loss:		0.340817
  validation accuracy:		89.46 %
Epoch 343 of 2000 took 0.106s
  training loss:		0.234772
  validation loss:		0.337959
  validation accuracy:		90.54 %
Epoch 344 of 2000 took 0.106s
  training loss:		0.239499
  validation loss:		0.349537
  validation accuracy:		89.35 %
Epoch 345 of 2000 took 0.106s
  training loss:		0.236750
  validation loss:		0.358270
  validation accuracy:		88.48 %
Epoch 346 of 2000 took 0.106s
  training loss:		0.239328
  validation loss:		0.339408
  validation accuracy:		90.43 %
Epoch 347 of 2000 took 0.106s
  training loss:		0.238115
  validation loss:		0.352772
  validation accuracy:		89.35 %
Epoch 348 of 2000 took 0.106s
  training loss:		0.246398
  validation loss:		0.366437
  validation accuracy:		88.26 %
Epoch 349 of 2000 took 0.106s
  training loss:		0.243581
  validation loss:		0.355012
  validation accuracy:		89.02 %
Epoch 350 of 2000 took 0.106s
  training loss:		0.234425
  validation loss:		0.340523
  validation accuracy:		90.22 %
Epoch 351 of 2000 took 0.106s
  training loss:		0.232970
  validation loss:		0.363782
  validation accuracy:		88.37 %
Epoch 352 of 2000 took 0.106s
  training loss:		0.233814
  validation loss:		0.346091
  validation accuracy:		89.35 %
Epoch 353 of 2000 took 0.106s
  training loss:		0.239889
  validation loss:		0.341155
  validation accuracy:		89.13 %
Epoch 354 of 2000 took 0.106s
  training loss:		0.238638
  validation loss:		0.337056
  validation accuracy:		89.67 %
Epoch 355 of 2000 took 0.106s
  training loss:		0.239913
  validation loss:		0.341749
  validation accuracy:		90.11 %
Epoch 356 of 2000 took 0.106s
  training loss:		0.243231
  validation loss:		0.345906
  validation accuracy:		89.89 %
Epoch 357 of 2000 took 0.106s
  training loss:		0.233356
  validation loss:		0.339405
  validation accuracy:		90.00 %
Epoch 358 of 2000 took 0.106s
  training loss:		0.235849
  validation loss:		0.362173
  validation accuracy:		88.48 %
Epoch 359 of 2000 took 0.106s
  training loss:		0.238611
  validation loss:		0.354454
  validation accuracy:		89.89 %
Epoch 360 of 2000 took 0.106s
  training loss:		0.234004
  validation loss:		0.340820
  validation accuracy:		89.46 %
Epoch 361 of 2000 took 0.106s
  training loss:		0.234566
  validation loss:		0.353401
  validation accuracy:		89.02 %
Epoch 362 of 2000 took 0.106s
  training loss:		0.239562
  validation loss:		0.348301
  validation accuracy:		89.24 %
Epoch 363 of 2000 took 0.106s
  training loss:		0.230242
  validation loss:		0.331106
  validation accuracy:		90.65 %
Epoch 364 of 2000 took 0.106s
  training loss:		0.238014
  validation loss:		0.349258
  validation accuracy:		89.46 %
Epoch 365 of 2000 took 0.106s
  training loss:		0.231238
  validation loss:		0.339958
  validation accuracy:		90.54 %
Epoch 366 of 2000 took 0.106s
  training loss:		0.232564
  validation loss:		0.352497
  validation accuracy:		89.46 %
Epoch 367 of 2000 took 0.106s
  training loss:		0.231670
  validation loss:		0.349415
  validation accuracy:		89.67 %
Epoch 368 of 2000 took 0.106s
  training loss:		0.233214
  validation loss:		0.350216
  validation accuracy:		88.48 %
Epoch 369 of 2000 took 0.106s
  training loss:		0.229230
  validation loss:		0.338658
  validation accuracy:		90.11 %
Epoch 370 of 2000 took 0.106s
  training loss:		0.227562
  validation loss:		0.341034
  validation accuracy:		89.57 %
Epoch 371 of 2000 took 0.106s
  training loss:		0.231257
  validation loss:		0.332453
  validation accuracy:		89.57 %
Epoch 372 of 2000 took 0.106s
  training loss:		0.227977
  validation loss:		0.340260
  validation accuracy:		89.89 %
Epoch 373 of 2000 took 0.106s
  training loss:		0.238094
  validation loss:		0.342230
  validation accuracy:		89.67 %
Epoch 374 of 2000 took 0.106s
  training loss:		0.231176
  validation loss:		0.334696
  validation accuracy:		89.89 %
Epoch 375 of 2000 took 0.106s
  training loss:		0.218179
  validation loss:		0.330150
  validation accuracy:		89.78 %
Epoch 376 of 2000 took 0.106s
  training loss:		0.225602
  validation loss:		0.335494
  validation accuracy:		90.11 %
Epoch 377 of 2000 took 0.106s
  training loss:		0.233321
  validation loss:		0.330816
  validation accuracy:		90.00 %
Epoch 378 of 2000 took 0.105s
  training loss:		0.224657
  validation loss:		0.335541
  validation accuracy:		90.22 %
Epoch 379 of 2000 took 0.102s
  training loss:		0.231935
  validation loss:		0.349119
  validation accuracy:		89.24 %
Epoch 380 of 2000 took 0.102s
  training loss:		0.222575
  validation loss:		0.349125
  validation accuracy:		89.35 %
Epoch 381 of 2000 took 0.102s
  training loss:		0.223080
  validation loss:		0.344428
  validation accuracy:		90.33 %
Epoch 382 of 2000 took 0.102s
  training loss:		0.223075
  validation loss:		0.334848
  validation accuracy:		90.43 %
Epoch 383 of 2000 took 0.102s
  training loss:		0.237535
  validation loss:		0.335138
  validation accuracy:		89.78 %
Epoch 384 of 2000 took 0.102s
  training loss:		0.224277
  validation loss:		0.338367
  validation accuracy:		90.00 %
Epoch 385 of 2000 took 0.102s
  training loss:		0.222264
  validation loss:		0.330282
  validation accuracy:		90.11 %
Epoch 386 of 2000 took 0.102s
  training loss:		0.229994
  validation loss:		0.383662
  validation accuracy:		87.72 %
Epoch 387 of 2000 took 0.102s
  training loss:		0.231055
  validation loss:		0.387295
  validation accuracy:		87.50 %
Epoch 388 of 2000 took 0.102s
  training loss:		0.221904
  validation loss:		0.371822
  validation accuracy:		88.04 %
Epoch 389 of 2000 took 0.102s
  training loss:		0.222557
  validation loss:		0.337633
  validation accuracy:		89.46 %
Epoch 390 of 2000 took 0.102s
  training loss:		0.222250
  validation loss:		0.335366
  validation accuracy:		89.78 %
Epoch 391 of 2000 took 0.102s
  training loss:		0.225839
  validation loss:		0.343083
  validation accuracy:		89.57 %
Epoch 392 of 2000 took 0.102s
  training loss:		0.223014
  validation loss:		0.338758
  validation accuracy:		90.33 %
Epoch 393 of 2000 took 0.105s
  training loss:		0.222812
  validation loss:		0.335977
  validation accuracy:		89.67 %
Epoch 394 of 2000 took 0.102s
  training loss:		0.219340
  validation loss:		0.334888
  validation accuracy:		89.67 %
Epoch 395 of 2000 took 0.102s
  training loss:		0.219375
  validation loss:		0.337597
  validation accuracy:		89.78 %
Epoch 396 of 2000 took 0.102s
  training loss:		0.223134
  validation loss:		0.355235
  validation accuracy:		88.91 %
Epoch 397 of 2000 took 0.102s
  training loss:		0.226384
  validation loss:		0.337606
  validation accuracy:		89.89 %
Epoch 398 of 2000 took 0.102s
  training loss:		0.233867
  validation loss:		0.337663
  validation accuracy:		90.11 %
Epoch 399 of 2000 took 0.102s
  training loss:		0.218304
  validation loss:		0.338269
  validation accuracy:		89.35 %
Epoch 400 of 2000 took 0.103s
  training loss:		0.220998
  validation loss:		0.328169
  validation accuracy:		90.22 %
Epoch 401 of 2000 took 0.102s
  training loss:		0.219803
  validation loss:		0.337014
  validation accuracy:		90.76 %
Epoch 402 of 2000 took 0.103s
  training loss:		0.214166
  validation loss:		0.345876
  validation accuracy:		89.13 %
Epoch 403 of 2000 took 0.103s
  training loss:		0.222478
  validation loss:		0.330812
  validation accuracy:		90.33 %
Epoch 404 of 2000 took 0.102s
  training loss:		0.225999
  validation loss:		0.341377
  validation accuracy:		89.67 %
Epoch 405 of 2000 took 0.102s
  training loss:		0.217467
  validation loss:		0.338392
  validation accuracy:		90.11 %
Epoch 406 of 2000 took 0.102s
  training loss:		0.221744
  validation loss:		0.329235
  validation accuracy:		90.22 %
Epoch 407 of 2000 took 0.102s
  training loss:		0.215254
  validation loss:		0.344929
  validation accuracy:		89.46 %
Epoch 408 of 2000 took 0.102s
  training loss:		0.220083
  validation loss:		0.332101
  validation accuracy:		90.22 %
Epoch 409 of 2000 took 0.102s
  training loss:		0.214835
  validation loss:		0.337552
  validation accuracy:		89.13 %
Epoch 410 of 2000 took 0.103s
  training loss:		0.216586
  validation loss:		0.337570
  validation accuracy:		89.46 %
Epoch 411 of 2000 took 0.103s
  training loss:		0.214983
  validation loss:		0.344871
  validation accuracy:		89.57 %
Epoch 412 of 2000 took 0.106s
  training loss:		0.221047
  validation loss:		0.345878
  validation accuracy:		90.00 %
Epoch 413 of 2000 took 0.106s
  training loss:		0.226266
  validation loss:		0.342003
  validation accuracy:		90.00 %
Epoch 414 of 2000 took 0.106s
  training loss:		0.216407
  validation loss:		0.351033
  validation accuracy:		89.35 %
Epoch 415 of 2000 took 0.104s
  training loss:		0.219150
  validation loss:		0.337973
  validation accuracy:		89.67 %
Epoch 416 of 2000 took 0.102s
  training loss:		0.209862
  validation loss:		0.334158
  validation accuracy:		89.78 %
Epoch 417 of 2000 took 0.102s
  training loss:		0.215899
  validation loss:		0.346228
  validation accuracy:		89.35 %
Epoch 418 of 2000 took 0.099s
  training loss:		0.216125
  validation loss:		0.331196
  validation accuracy:		90.11 %
Epoch 419 of 2000 took 0.099s
  training loss:		0.216844
  validation loss:		0.334330
  validation accuracy:		89.67 %
Epoch 420 of 2000 took 0.099s
  training loss:		0.219756
  validation loss:		0.334935
  validation accuracy:		90.00 %
Epoch 421 of 2000 took 0.099s
  training loss:		0.215396
  validation loss:		0.332761
  validation accuracy:		89.78 %
Epoch 422 of 2000 took 0.099s
  training loss:		0.216056
  validation loss:		0.341126
  validation accuracy:		89.67 %
Epoch 423 of 2000 took 0.099s
  training loss:		0.219688
  validation loss:		0.335379
  validation accuracy:		90.00 %
Epoch 424 of 2000 took 0.099s
  training loss:		0.214044
  validation loss:		0.337293
  validation accuracy:		89.78 %
Epoch 425 of 2000 took 0.099s
  training loss:		0.223337
  validation loss:		0.334331
  validation accuracy:		89.89 %
Epoch 426 of 2000 took 0.099s
  training loss:		0.206298
  validation loss:		0.325800
  validation accuracy:		89.89 %
Epoch 427 of 2000 took 0.099s
  training loss:		0.214987
  validation loss:		0.337055
  validation accuracy:		89.46 %
Epoch 428 of 2000 took 0.099s
  training loss:		0.212798
  validation loss:		0.339315
  validation accuracy:		89.57 %
Epoch 429 of 2000 took 0.099s
  training loss:		0.216237
  validation loss:		0.338950
  validation accuracy:		89.78 %
Epoch 430 of 2000 took 0.099s
  training loss:		0.210913
  validation loss:		0.327683
  validation accuracy:		90.22 %
Epoch 431 of 2000 took 0.099s
  training loss:		0.209798
  validation loss:		0.333224
  validation accuracy:		90.11 %
Epoch 432 of 2000 took 0.100s
  training loss:		0.206813
  validation loss:		0.336997
  validation accuracy:		90.22 %
Epoch 433 of 2000 took 0.099s
  training loss:		0.211559
  validation loss:		0.338481
  validation accuracy:		90.11 %
Epoch 434 of 2000 took 0.099s
  training loss:		0.208468
  validation loss:		0.338641
  validation accuracy:		89.57 %
Epoch 435 of 2000 took 0.099s
  training loss:		0.208238
  validation loss:		0.334885
  validation accuracy:		90.33 %
Epoch 436 of 2000 took 0.099s
  training loss:		0.206198
  validation loss:		0.333635
  validation accuracy:		90.00 %
Epoch 437 of 2000 took 0.099s
  training loss:		0.209560
  validation loss:		0.338557
  validation accuracy:		89.57 %
Epoch 438 of 2000 took 0.099s
  training loss:		0.215390
  validation loss:		0.338187
  validation accuracy:		90.22 %
Epoch 439 of 2000 took 0.099s
  training loss:		0.208402
  validation loss:		0.359026
  validation accuracy:		88.70 %
Epoch 440 of 2000 took 0.099s
  training loss:		0.207797
  validation loss:		0.349399
  validation accuracy:		89.67 %
Epoch 441 of 2000 took 0.099s
  training loss:		0.207352
  validation loss:		0.342878
  validation accuracy:		89.78 %
Epoch 442 of 2000 took 0.099s
  training loss:		0.210388
  validation loss:		0.342212
  validation accuracy:		90.22 %
Epoch 443 of 2000 took 0.099s
  training loss:		0.207765
  validation loss:		0.330099
  validation accuracy:		90.00 %
Epoch 444 of 2000 took 0.099s
  training loss:		0.209327
  validation loss:		0.333283
  validation accuracy:		89.78 %
Epoch 445 of 2000 took 0.099s
  training loss:		0.215123
  validation loss:		0.350157
  validation accuracy:		88.80 %
Epoch 446 of 2000 took 0.099s
  training loss:		0.208658
  validation loss:		0.337912
  validation accuracy:		89.89 %
Epoch 447 of 2000 took 0.099s
  training loss:		0.206697
  validation loss:		0.346642
  validation accuracy:		89.89 %
Epoch 448 of 2000 took 0.099s
  training loss:		0.208519
  validation loss:		0.348982
  validation accuracy:		90.00 %
Epoch 449 of 2000 took 0.099s
  training loss:		0.205084
  validation loss:		0.336241
  validation accuracy:		90.00 %
Epoch 450 of 2000 took 0.099s
  training loss:		0.208658
  validation loss:		0.331250
  validation accuracy:		90.11 %
Epoch 451 of 2000 took 0.099s
  training loss:		0.208775
  validation loss:		0.338853
  validation accuracy:		90.22 %
Epoch 452 of 2000 took 0.099s
  training loss:		0.209137
  validation loss:		0.332782
  validation accuracy:		89.89 %
Epoch 453 of 2000 took 0.099s
  training loss:		0.202041
  validation loss:		0.339490
  validation accuracy:		90.22 %
Epoch 454 of 2000 took 0.099s
  training loss:		0.208355
  validation loss:		0.340965
  validation accuracy:		90.11 %
Epoch 455 of 2000 took 0.099s
  training loss:		0.214650
  validation loss:		0.344293
  validation accuracy:		89.46 %
Epoch 456 of 2000 took 0.099s
  training loss:		0.205522
  validation loss:		0.333819
  validation accuracy:		89.78 %
Epoch 457 of 2000 took 0.099s
  training loss:		0.205318
  validation loss:		0.349032
  validation accuracy:		89.67 %
Epoch 458 of 2000 took 0.098s
  training loss:		0.205563
  validation loss:		0.339244
  validation accuracy:		90.54 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.204892
  validation loss:		0.340617
  validation accuracy:		90.33 %
Epoch 460 of 2000 took 0.096s
  training loss:		0.205966
  validation loss:		0.330224
  validation accuracy:		90.33 %
Epoch 461 of 2000 took 0.096s
  training loss:		0.207176
  validation loss:		0.329497
  validation accuracy:		90.43 %
Epoch 462 of 2000 took 0.096s
  training loss:		0.203175
  validation loss:		0.340054
  validation accuracy:		89.46 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.203053
  validation loss:		0.347187
  validation accuracy:		89.89 %
Epoch 464 of 2000 took 0.096s
  training loss:		0.202450
  validation loss:		0.365217
  validation accuracy:		88.59 %
Epoch 465 of 2000 took 0.096s
  training loss:		0.201839
  validation loss:		0.337576
  validation accuracy:		90.22 %
Epoch 466 of 2000 took 0.096s
  training loss:		0.204929
  validation loss:		0.344081
  validation accuracy:		89.78 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.207036
  validation loss:		0.333620
  validation accuracy:		90.11 %
Epoch 468 of 2000 took 0.096s
  training loss:		0.207259
  validation loss:		0.344020
  validation accuracy:		89.67 %
Epoch 469 of 2000 took 0.096s
  training loss:		0.207770
  validation loss:		0.345109
  validation accuracy:		89.35 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.209925
  validation loss:		0.336945
  validation accuracy:		89.78 %
Epoch 471 of 2000 took 0.096s
  training loss:		0.201400
  validation loss:		0.353444
  validation accuracy:		89.24 %
Epoch 472 of 2000 took 0.096s
  training loss:		0.202358
  validation loss:		0.340977
  validation accuracy:		89.57 %
Epoch 473 of 2000 took 0.096s
  training loss:		0.199885
  validation loss:		0.336087
  validation accuracy:		89.46 %
Epoch 474 of 2000 took 0.096s
  training loss:		0.192308
  validation loss:		0.362045
  validation accuracy:		88.48 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.202526
  validation loss:		0.344191
  validation accuracy:		89.24 %
Epoch 476 of 2000 took 0.102s
  training loss:		0.199018
  validation loss:		0.344044
  validation accuracy:		89.57 %
Epoch 477 of 2000 took 0.102s
  training loss:		0.203680
  validation loss:		0.337521
  validation accuracy:		89.67 %
Epoch 478 of 2000 took 0.102s
  training loss:		0.199243
  validation loss:		0.344010
  validation accuracy:		89.46 %
Epoch 479 of 2000 took 0.102s
  training loss:		0.206016
  validation loss:		0.346063
  validation accuracy:		89.24 %
Epoch 480 of 2000 took 0.102s
  training loss:		0.204780
  validation loss:		0.340071
  validation accuracy:		89.35 %
Epoch 481 of 2000 took 0.102s
  training loss:		0.200414
  validation loss:		0.332314
  validation accuracy:		89.89 %
Epoch 482 of 2000 took 0.102s
  training loss:		0.196122
  validation loss:		0.344767
  validation accuracy:		89.46 %
Epoch 483 of 2000 took 0.102s
  training loss:		0.196789
  validation loss:		0.332890
  validation accuracy:		90.22 %
Epoch 484 of 2000 took 0.102s
  training loss:		0.197637
  validation loss:		0.331617
  validation accuracy:		90.11 %
Epoch 485 of 2000 took 0.102s
  training loss:		0.198721
  validation loss:		0.331513
  validation accuracy:		90.65 %
Epoch 486 of 2000 took 0.102s
  training loss:		0.193847
  validation loss:		0.333236
  validation accuracy:		90.65 %
Epoch 487 of 2000 took 0.102s
  training loss:		0.193208
  validation loss:		0.347805
  validation accuracy:		89.24 %
Epoch 488 of 2000 took 0.102s
  training loss:		0.200907
  validation loss:		0.355698
  validation accuracy:		89.46 %
Epoch 489 of 2000 took 0.100s
  training loss:		0.199775
  validation loss:		0.356804
  validation accuracy:		89.46 %
Epoch 490 of 2000 took 0.099s
  training loss:		0.197289
  validation loss:		0.342797
  validation accuracy:		89.57 %
Epoch 491 of 2000 took 0.096s
  training loss:		0.191639
  validation loss:		0.349162
  validation accuracy:		89.46 %
Epoch 492 of 2000 took 0.096s
  training loss:		0.193858
  validation loss:		0.357664
  validation accuracy:		88.80 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.199589
  validation loss:		0.339906
  validation accuracy:		89.89 %
Epoch 494 of 2000 took 0.096s
  training loss:		0.200750
  validation loss:		0.330903
  validation accuracy:		90.11 %
Epoch 495 of 2000 took 0.096s
  training loss:		0.198966
  validation loss:		0.330341
  validation accuracy:		90.65 %
Epoch 496 of 2000 took 0.096s
  training loss:		0.197922
  validation loss:		0.330223
  validation accuracy:		90.22 %
Epoch 497 of 2000 took 0.096s
  training loss:		0.196890
  validation loss:		0.368737
  validation accuracy:		88.59 %
Epoch 498 of 2000 took 0.096s
  training loss:		0.202579
  validation loss:		0.341910
  validation accuracy:		89.78 %
Epoch 499 of 2000 took 0.096s
  training loss:		0.196573
  validation loss:		0.340006
  validation accuracy:		90.11 %
Epoch 500 of 2000 took 0.096s
  training loss:		0.202750
  validation loss:		0.340684
  validation accuracy:		89.67 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.201665
  validation loss:		0.343585
  validation accuracy:		89.57 %
Epoch 502 of 2000 took 0.096s
  training loss:		0.199462
  validation loss:		0.348828
  validation accuracy:		89.35 %
Epoch 503 of 2000 took 0.096s
  training loss:		0.189026
  validation loss:		0.334391
  validation accuracy:		90.87 %
Epoch 504 of 2000 took 0.096s
  training loss:		0.195533
  validation loss:		0.356779
  validation accuracy:		89.67 %
Epoch 505 of 2000 took 0.096s
  training loss:		0.194758
  validation loss:		0.340045
  validation accuracy:		90.00 %
Epoch 506 of 2000 took 0.096s
  training loss:		0.197135
  validation loss:		0.333686
  validation accuracy:		90.22 %
Epoch 507 of 2000 took 0.096s
  training loss:		0.196303
  validation loss:		0.332893
  validation accuracy:		90.43 %
Epoch 508 of 2000 took 0.096s
  training loss:		0.197824
  validation loss:		0.325069
  validation accuracy:		90.22 %
Epoch 509 of 2000 took 0.096s
  training loss:		0.196217
  validation loss:		0.348937
  validation accuracy:		89.46 %
Epoch 510 of 2000 took 0.096s
  training loss:		0.189170
  validation loss:		0.329618
  validation accuracy:		90.54 %
Epoch 511 of 2000 took 0.096s
  training loss:		0.187326
  validation loss:		0.324421
  validation accuracy:		90.87 %
Epoch 512 of 2000 took 0.096s
  training loss:		0.185090
  validation loss:		0.334035
  validation accuracy:		90.00 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.194303
  validation loss:		0.326157
  validation accuracy:		91.20 %
Epoch 514 of 2000 took 0.096s
  training loss:		0.191199
  validation loss:		0.338915
  validation accuracy:		90.11 %
Epoch 515 of 2000 took 0.096s
  training loss:		0.187712
  validation loss:		0.325066
  validation accuracy:		91.09 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.190022
  validation loss:		0.342308
  validation accuracy:		89.78 %
Epoch 517 of 2000 took 0.096s
  training loss:		0.200570
  validation loss:		0.344653
  validation accuracy:		89.78 %
Epoch 518 of 2000 took 0.096s
  training loss:		0.199688
  validation loss:		0.336179
  validation accuracy:		89.67 %
Epoch 519 of 2000 took 0.096s
  training loss:		0.188294
  validation loss:		0.348331
  validation accuracy:		89.35 %
Epoch 520 of 2000 took 0.096s
  training loss:		0.185852
  validation loss:		0.341566
  validation accuracy:		89.67 %
Epoch 521 of 2000 took 0.096s
  training loss:		0.189921
  validation loss:		0.350378
  validation accuracy:		89.24 %
Epoch 522 of 2000 took 0.096s
  training loss:		0.194515
  validation loss:		0.351329
  validation accuracy:		89.35 %
Epoch 523 of 2000 took 0.096s
  training loss:		0.190720
  validation loss:		0.331826
  validation accuracy:		90.43 %
Epoch 524 of 2000 took 0.096s
  training loss:		0.187315
  validation loss:		0.351146
  validation accuracy:		89.35 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.187219
  validation loss:		0.330352
  validation accuracy:		90.65 %
Epoch 526 of 2000 took 0.096s
  training loss:		0.194169
  validation loss:		0.349354
  validation accuracy:		89.35 %
Epoch 527 of 2000 took 0.096s
  training loss:		0.190835
  validation loss:		0.336968
  validation accuracy:		90.22 %
Epoch 528 of 2000 took 0.102s
  training loss:		0.194704
  validation loss:		0.328384
  validation accuracy:		90.76 %
Epoch 529 of 2000 took 0.100s
  training loss:		0.193986
  validation loss:		0.328733
  validation accuracy:		90.11 %
Epoch 530 of 2000 took 0.100s
  training loss:		0.186181
  validation loss:		0.342898
  validation accuracy:		90.00 %
Epoch 531 of 2000 took 0.100s
  training loss:		0.182503
  validation loss:		0.327451
  validation accuracy:		90.43 %
Epoch 532 of 2000 took 0.096s
  training loss:		0.188533
  validation loss:		0.334684
  validation accuracy:		90.11 %
Epoch 533 of 2000 took 0.096s
  training loss:		0.189807
  validation loss:		0.381911
  validation accuracy:		88.26 %
Epoch 534 of 2000 took 0.096s
  training loss:		0.195023
  validation loss:		0.335670
  validation accuracy:		90.00 %
Epoch 535 of 2000 took 0.096s
  training loss:		0.190940
  validation loss:		0.337722
  validation accuracy:		90.00 %
Epoch 536 of 2000 took 0.096s
  training loss:		0.192540
  validation loss:		0.337743
  validation accuracy:		89.89 %
Epoch 537 of 2000 took 0.096s
  training loss:		0.189579
  validation loss:		0.334820
  validation accuracy:		90.11 %
Epoch 538 of 2000 took 0.096s
  training loss:		0.186646
  validation loss:		0.341647
  validation accuracy:		89.78 %
Epoch 539 of 2000 took 0.096s
  training loss:		0.187029
  validation loss:		0.351562
  validation accuracy:		90.00 %
Epoch 540 of 2000 took 0.096s
  training loss:		0.193611
  validation loss:		0.339399
  validation accuracy:		89.89 %
Epoch 541 of 2000 took 0.096s
  training loss:		0.189587
  validation loss:		0.336640
  validation accuracy:		90.33 %
Epoch 542 of 2000 took 0.096s
  training loss:		0.187616
  validation loss:		0.342827
  validation accuracy:		89.24 %
Epoch 543 of 2000 took 0.096s
  training loss:		0.191661
  validation loss:		0.327463
  validation accuracy:		90.43 %
Epoch 544 of 2000 took 0.096s
  training loss:		0.190601
  validation loss:		0.332839
  validation accuracy:		90.76 %
Epoch 545 of 2000 took 0.096s
  training loss:		0.190168
  validation loss:		0.362345
  validation accuracy:		88.37 %
Epoch 546 of 2000 took 0.096s
  training loss:		0.184971
  validation loss:		0.328387
  validation accuracy:		90.22 %
Epoch 547 of 2000 took 0.096s
  training loss:		0.195417
  validation loss:		0.333499
  validation accuracy:		90.22 %
Epoch 548 of 2000 took 0.096s
  training loss:		0.187481
  validation loss:		0.340427
  validation accuracy:		89.67 %
Epoch 549 of 2000 took 0.096s
  training loss:		0.184327
  validation loss:		0.337015
  validation accuracy:		89.67 %
Epoch 550 of 2000 took 0.096s
  training loss:		0.194051
  validation loss:		0.324447
  validation accuracy:		90.43 %
Epoch 551 of 2000 took 0.096s
  training loss:		0.184355
  validation loss:		0.332096
  validation accuracy:		90.11 %
Epoch 552 of 2000 took 0.096s
  training loss:		0.183023
  validation loss:		0.339578
  validation accuracy:		89.89 %
Epoch 553 of 2000 took 0.096s
  training loss:		0.188403
  validation loss:		0.346409
  validation accuracy:		89.78 %
Epoch 554 of 2000 took 0.096s
  training loss:		0.184672
  validation loss:		0.343440
  validation accuracy:		89.89 %
Epoch 555 of 2000 took 0.096s
  training loss:		0.190741
  validation loss:		0.323918
  validation accuracy:		90.22 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.184391
  validation loss:		0.348077
  validation accuracy:		89.24 %
Epoch 557 of 2000 took 0.096s
  training loss:		0.184481
  validation loss:		0.342803
  validation accuracy:		89.89 %
Epoch 558 of 2000 took 0.096s
  training loss:		0.187978
  validation loss:		0.326768
  validation accuracy:		90.65 %
Epoch 559 of 2000 took 0.096s
  training loss:		0.183025
  validation loss:		0.337999
  validation accuracy:		90.22 %
Epoch 560 of 2000 took 0.096s
  training loss:		0.185144
  validation loss:		0.339766
  validation accuracy:		89.67 %
Epoch 561 of 2000 took 0.096s
  training loss:		0.184176
  validation loss:		0.338848
  validation accuracy:		89.78 %
Epoch 562 of 2000 took 0.096s
  training loss:		0.187706
  validation loss:		0.330329
  validation accuracy:		90.54 %
Epoch 563 of 2000 took 0.096s
  training loss:		0.178454
  validation loss:		0.339033
  validation accuracy:		90.22 %
Epoch 564 of 2000 took 0.096s
  training loss:		0.179847
  validation loss:		0.326694
  validation accuracy:		90.22 %
Epoch 565 of 2000 took 0.096s
  training loss:		0.182653
  validation loss:		0.347283
  validation accuracy:		89.46 %
Epoch 566 of 2000 took 0.096s
  training loss:		0.191811
  validation loss:		0.337228
  validation accuracy:		89.57 %
Epoch 567 of 2000 took 0.096s
  training loss:		0.185309
  validation loss:		0.332593
  validation accuracy:		90.11 %
Epoch 568 of 2000 took 0.096s
  training loss:		0.184780
  validation loss:		0.331601
  validation accuracy:		90.22 %
Epoch 569 of 2000 took 0.096s
  training loss:		0.183177
  validation loss:		0.332554
  validation accuracy:		89.89 %
Epoch 570 of 2000 took 0.096s
  training loss:		0.180092
  validation loss:		0.327829
  validation accuracy:		90.11 %
Epoch 571 of 2000 took 0.096s
  training loss:		0.187346
  validation loss:		0.346765
  validation accuracy:		90.11 %
Epoch 572 of 2000 took 0.096s
  training loss:		0.185537
  validation loss:		0.346700
  validation accuracy:		89.46 %
Epoch 573 of 2000 took 0.096s
  training loss:		0.180991
  validation loss:		0.329878
  validation accuracy:		89.57 %
Epoch 574 of 2000 took 0.096s
  training loss:		0.179548
  validation loss:		0.330435
  validation accuracy:		90.11 %
Epoch 575 of 2000 took 0.096s
  training loss:		0.183692
  validation loss:		0.332119
  validation accuracy:		90.22 %
Epoch 576 of 2000 took 0.096s
  training loss:		0.186102
  validation loss:		0.332589
  validation accuracy:		89.78 %
Epoch 577 of 2000 took 0.096s
  training loss:		0.180530
  validation loss:		0.334759
  validation accuracy:		89.57 %
Epoch 578 of 2000 took 0.096s
  training loss:		0.181430
  validation loss:		0.336724
  validation accuracy:		90.11 %
Epoch 579 of 2000 took 0.096s
  training loss:		0.186554
  validation loss:		0.341892
  validation accuracy:		89.89 %
Epoch 580 of 2000 took 0.096s
  training loss:		0.182022
  validation loss:		0.328958
  validation accuracy:		90.43 %
Epoch 581 of 2000 took 0.096s
  training loss:		0.177316
  validation loss:		0.330355
  validation accuracy:		90.11 %
Epoch 582 of 2000 took 0.096s
  training loss:		0.177322
  validation loss:		0.327277
  validation accuracy:		91.20 %
Epoch 583 of 2000 took 0.096s
  training loss:		0.182391
  validation loss:		0.330967
  validation accuracy:		90.98 %
Epoch 584 of 2000 took 0.096s
  training loss:		0.178917
  validation loss:		0.363455
  validation accuracy:		88.80 %
Epoch 585 of 2000 took 0.096s
  training loss:		0.177174
  validation loss:		0.337679
  validation accuracy:		90.43 %
Epoch 586 of 2000 took 0.096s
  training loss:		0.176579
  validation loss:		0.333288
  validation accuracy:		90.11 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.173802
  validation loss:		0.341098
  validation accuracy:		89.67 %
Epoch 588 of 2000 took 0.096s
  training loss:		0.183308
  validation loss:		0.335460
  validation accuracy:		90.00 %
Epoch 589 of 2000 took 0.096s
  training loss:		0.179830
  validation loss:		0.331797
  validation accuracy:		89.89 %
Epoch 590 of 2000 took 0.096s
  training loss:		0.178426
  validation loss:		0.340358
  validation accuracy:		89.89 %
Epoch 591 of 2000 took 0.096s
  training loss:		0.187145
  validation loss:		0.330612
  validation accuracy:		89.89 %
Epoch 592 of 2000 took 0.096s
  training loss:		0.176872
  validation loss:		0.329013
  validation accuracy:		90.00 %
Epoch 593 of 2000 took 0.096s
  training loss:		0.178971
  validation loss:		0.329617
  validation accuracy:		90.00 %
Epoch 594 of 2000 took 0.096s
  training loss:		0.173659
  validation loss:		0.326840
  validation accuracy:		90.00 %
Epoch 595 of 2000 took 0.096s
  training loss:		0.174282
  validation loss:		0.333195
  validation accuracy:		90.00 %
Epoch 596 of 2000 took 0.096s
  training loss:		0.177579
  validation loss:		0.325013
  validation accuracy:		90.22 %
Epoch 597 of 2000 took 0.096s
  training loss:		0.178305
  validation loss:		0.334728
  validation accuracy:		90.98 %
Epoch 598 of 2000 took 0.096s
  training loss:		0.179765
  validation loss:		0.333619
  validation accuracy:		90.22 %
Epoch 599 of 2000 took 0.096s
  training loss:		0.185906
  validation loss:		0.344401
  validation accuracy:		90.43 %
Epoch 600 of 2000 took 0.096s
  training loss:		0.176590
  validation loss:		0.331465
  validation accuracy:		90.22 %
Epoch 601 of 2000 took 0.096s
  training loss:		0.180265
  validation loss:		0.325532
  validation accuracy:		90.33 %
Epoch 602 of 2000 took 0.096s
  training loss:		0.175133
  validation loss:		0.335153
  validation accuracy:		90.11 %
Epoch 603 of 2000 took 0.096s
  training loss:		0.170551
  validation loss:		0.339322
  validation accuracy:		90.33 %
Epoch 604 of 2000 took 0.096s
  training loss:		0.178087
  validation loss:		0.347381
  validation accuracy:		90.00 %
Epoch 605 of 2000 took 0.096s
  training loss:		0.178977
  validation loss:		0.359099
  validation accuracy:		89.13 %
Epoch 606 of 2000 took 0.096s
  training loss:		0.171573
  validation loss:		0.338347
  validation accuracy:		89.67 %
Epoch 607 of 2000 took 0.096s
  training loss:		0.173552
  validation loss:		0.343600
  validation accuracy:		89.46 %
Epoch 608 of 2000 took 0.096s
  training loss:		0.171632
  validation loss:		0.337081
  validation accuracy:		90.33 %
Epoch 609 of 2000 took 0.096s
  training loss:		0.175635
  validation loss:		0.336567
  validation accuracy:		89.67 %
Epoch 610 of 2000 took 0.096s
  training loss:		0.188912
  validation loss:		0.339175
  validation accuracy:		89.89 %
Epoch 611 of 2000 took 0.098s
  training loss:		0.178325
  validation loss:		0.345546
  validation accuracy:		89.13 %
Epoch 612 of 2000 took 0.096s
  training loss:		0.171418
  validation loss:		0.357691
  validation accuracy:		89.02 %
Epoch 613 of 2000 took 0.096s
  training loss:		0.176355
  validation loss:		0.331444
  validation accuracy:		89.67 %
Epoch 614 of 2000 took 0.096s
  training loss:		0.176673
  validation loss:		0.344780
  validation accuracy:		89.78 %
Epoch 615 of 2000 took 0.096s
  training loss:		0.172151
  validation loss:		0.338268
  validation accuracy:		89.89 %
Epoch 616 of 2000 took 0.096s
  training loss:		0.173617
  validation loss:		0.339910
  validation accuracy:		90.11 %
Epoch 617 of 2000 took 0.096s
  training loss:		0.172322
  validation loss:		0.334275
  validation accuracy:		89.67 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.178156
  validation loss:		0.338141
  validation accuracy:		90.43 %
Epoch 619 of 2000 took 0.096s
  training loss:		0.174958
  validation loss:		0.331333
  validation accuracy:		89.89 %
Epoch 620 of 2000 took 0.096s
  training loss:		0.173722
  validation loss:		0.334559
  validation accuracy:		90.11 %
Epoch 621 of 2000 took 0.096s
  training loss:		0.176628
  validation loss:		0.344443
  validation accuracy:		90.22 %
Epoch 622 of 2000 took 0.096s
  training loss:		0.174489
  validation loss:		0.335455
  validation accuracy:		89.67 %
Epoch 623 of 2000 took 0.096s
  training loss:		0.167899
  validation loss:		0.339382
  validation accuracy:		90.22 %
Epoch 624 of 2000 took 0.099s
  training loss:		0.170801
  validation loss:		0.339499
  validation accuracy:		90.65 %
Epoch 625 of 2000 took 0.099s
  training loss:		0.169903
  validation loss:		0.339868
  validation accuracy:		89.78 %
Epoch 626 of 2000 took 0.099s
  training loss:		0.174016
  validation loss:		0.333980
  validation accuracy:		89.89 %
Epoch 627 of 2000 took 0.099s
  training loss:		0.175456
  validation loss:		0.334376
  validation accuracy:		89.89 %
Epoch 628 of 2000 took 0.099s
  training loss:		0.175110
  validation loss:		0.347437
  validation accuracy:		89.78 %
Epoch 629 of 2000 took 0.099s
  training loss:		0.174414
  validation loss:		0.334040
  validation accuracy:		89.78 %
Epoch 630 of 2000 took 0.099s
  training loss:		0.175562
  validation loss:		0.340341
  validation accuracy:		89.46 %
Epoch 631 of 2000 took 0.099s
  training loss:		0.176235
  validation loss:		0.336899
  validation accuracy:		89.67 %
Epoch 632 of 2000 took 0.099s
  training loss:		0.173770
  validation loss:		0.337996
  validation accuracy:		90.22 %
Epoch 633 of 2000 took 0.099s
  training loss:		0.170588
  validation loss:		0.336467
  validation accuracy:		89.78 %
Epoch 634 of 2000 took 0.099s
  training loss:		0.171322
  validation loss:		0.337527
  validation accuracy:		89.89 %
Epoch 635 of 2000 took 0.099s
  training loss:		0.170452
  validation loss:		0.333521
  validation accuracy:		89.89 %
Epoch 636 of 2000 took 0.099s
  training loss:		0.172579
  validation loss:		0.333109
  validation accuracy:		91.41 %
Epoch 637 of 2000 took 0.099s
  training loss:		0.178681
  validation loss:		0.345382
  validation accuracy:		89.89 %
Epoch 638 of 2000 took 0.099s
  training loss:		0.173905
  validation loss:		0.334133
  validation accuracy:		90.33 %
Epoch 639 of 2000 took 0.099s
  training loss:		0.171620
  validation loss:		0.347630
  validation accuracy:		89.57 %
Epoch 640 of 2000 took 0.099s
  training loss:		0.175828
  validation loss:		0.348368
  validation accuracy:		90.76 %
Epoch 641 of 2000 took 0.099s
  training loss:		0.174953
  validation loss:		0.345234
  validation accuracy:		89.35 %
Epoch 642 of 2000 took 0.099s
  training loss:		0.177658
  validation loss:		0.338071
  validation accuracy:		89.67 %
Epoch 643 of 2000 took 0.099s
  training loss:		0.172148
  validation loss:		0.346589
  validation accuracy:		89.78 %
Epoch 644 of 2000 took 0.099s
  training loss:		0.185108
  validation loss:		0.335526
  validation accuracy:		90.00 %
Epoch 645 of 2000 took 0.099s
  training loss:		0.174294
  validation loss:		0.348248
  validation accuracy:		89.67 %
Epoch 646 of 2000 took 0.099s
  training loss:		0.166031
  validation loss:		0.343419
  validation accuracy:		89.46 %
Epoch 647 of 2000 took 0.099s
  training loss:		0.164309
  validation loss:		0.362739
  validation accuracy:		88.48 %
Epoch 648 of 2000 took 0.099s
  training loss:		0.177171
  validation loss:		0.340432
  validation accuracy:		89.67 %
Epoch 649 of 2000 took 0.100s
  training loss:		0.174992
  validation loss:		0.338855
  validation accuracy:		89.89 %
Epoch 650 of 2000 took 0.099s
  training loss:		0.167007
  validation loss:		0.347657
  validation accuracy:		89.24 %
Epoch 651 of 2000 took 0.099s
  training loss:		0.173728
  validation loss:		0.333481
  validation accuracy:		90.54 %
Epoch 652 of 2000 took 0.099s
  training loss:		0.174529
  validation loss:		0.338726
  validation accuracy:		89.89 %
Epoch 653 of 2000 took 0.099s
  training loss:		0.172084
  validation loss:		0.345910
  validation accuracy:		90.00 %
Epoch 654 of 2000 took 0.099s
  training loss:		0.173464
  validation loss:		0.342582
  validation accuracy:		89.46 %
Epoch 655 of 2000 took 0.099s
  training loss:		0.169159
  validation loss:		0.333107
  validation accuracy:		90.22 %
Epoch 656 of 2000 took 0.099s
  training loss:		0.170027
  validation loss:		0.350867
  validation accuracy:		89.35 %
Epoch 657 of 2000 took 0.099s
  training loss:		0.170282
  validation loss:		0.345847
  validation accuracy:		89.46 %
Epoch 658 of 2000 took 0.099s
  training loss:		0.168232
  validation loss:		0.339173
  validation accuracy:		90.87 %
Epoch 659 of 2000 took 0.099s
  training loss:		0.168839
  validation loss:		0.343512
  validation accuracy:		89.67 %
Epoch 660 of 2000 took 0.099s
  training loss:		0.170695
  validation loss:		0.334486
  validation accuracy:		90.11 %
Epoch 661 of 2000 took 0.099s
  training loss:		0.167519
  validation loss:		0.349625
  validation accuracy:		90.87 %
Epoch 662 of 2000 took 0.099s
  training loss:		0.174041
  validation loss:		0.331964
  validation accuracy:		91.20 %
Epoch 663 of 2000 took 0.099s
  training loss:		0.169058
  validation loss:		0.339690
  validation accuracy:		89.67 %
Epoch 664 of 2000 took 0.100s
  training loss:		0.168824
  validation loss:		0.333476
  validation accuracy:		90.00 %
Epoch 665 of 2000 took 0.099s
  training loss:		0.171672
  validation loss:		0.340043
  validation accuracy:		89.89 %
Epoch 666 of 2000 took 0.099s
  training loss:		0.174432
  validation loss:		0.334256
  validation accuracy:		90.54 %
Epoch 667 of 2000 took 0.099s
  training loss:		0.164941
  validation loss:		0.361577
  validation accuracy:		89.35 %
Epoch 668 of 2000 took 0.099s
  training loss:		0.175790
  validation loss:		0.335768
  validation accuracy:		91.52 %
Epoch 669 of 2000 took 0.099s
  training loss:		0.167260
  validation loss:		0.343206
  validation accuracy:		89.46 %
Epoch 670 of 2000 took 0.099s
  training loss:		0.167163
  validation loss:		0.335127
  validation accuracy:		89.89 %
Epoch 671 of 2000 took 0.099s
  training loss:		0.175416
  validation loss:		0.343588
  validation accuracy:		89.89 %
Epoch 672 of 2000 took 0.099s
  training loss:		0.168257
  validation loss:		0.340502
  validation accuracy:		90.11 %
Epoch 673 of 2000 took 0.099s
  training loss:		0.166876
  validation loss:		0.330083
  validation accuracy:		90.43 %
Epoch 674 of 2000 took 0.099s
  training loss:		0.166885
  validation loss:		0.348902
  validation accuracy:		89.02 %
Epoch 675 of 2000 took 0.099s
  training loss:		0.164359
  validation loss:		0.330533
  validation accuracy:		90.76 %
Epoch 676 of 2000 took 0.100s
  training loss:		0.168349
  validation loss:		0.341463
  validation accuracy:		89.35 %
Epoch 677 of 2000 took 0.099s
  training loss:		0.172488
  validation loss:		0.356509
  validation accuracy:		89.35 %
Epoch 678 of 2000 took 0.099s
  training loss:		0.166450
  validation loss:		0.334434
  validation accuracy:		90.76 %
Epoch 679 of 2000 took 0.100s
  training loss:		0.174623
  validation loss:		0.351437
  validation accuracy:		90.98 %
Epoch 680 of 2000 took 0.099s
  training loss:		0.171844
  validation loss:		0.348219
  validation accuracy:		90.22 %
Epoch 681 of 2000 took 0.099s
  training loss:		0.168848
  validation loss:		0.346088
  validation accuracy:		89.57 %
Epoch 682 of 2000 took 0.099s
  training loss:		0.166777
  validation loss:		0.337179
  validation accuracy:		89.89 %
Epoch 683 of 2000 took 0.099s
  training loss:		0.166566
  validation loss:		0.341371
  validation accuracy:		89.13 %
Epoch 684 of 2000 took 0.099s
  training loss:		0.162318
  validation loss:		0.333728
  validation accuracy:		90.54 %
Epoch 685 of 2000 took 0.099s
  training loss:		0.164537
  validation loss:		0.337031
  validation accuracy:		89.78 %
Epoch 686 of 2000 took 0.099s
  training loss:		0.162967
  validation loss:		0.347976
  validation accuracy:		89.24 %
Epoch 687 of 2000 took 0.099s
  training loss:		0.167867
  validation loss:		0.339577
  validation accuracy:		89.78 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.169820
  validation loss:		0.338188
  validation accuracy:		89.46 %
Epoch 689 of 2000 took 0.099s
  training loss:		0.168043
  validation loss:		0.340671
  validation accuracy:		90.98 %
Epoch 690 of 2000 took 0.099s
  training loss:		0.177937
  validation loss:		0.359817
  validation accuracy:		90.54 %
Epoch 691 of 2000 took 0.099s
  training loss:		0.172553
  validation loss:		0.355826
  validation accuracy:		89.57 %
Epoch 692 of 2000 took 0.099s
  training loss:		0.165472
  validation loss:		0.369583
  validation accuracy:		90.11 %
Epoch 693 of 2000 took 0.099s
  training loss:		0.163435
  validation loss:		0.345358
  validation accuracy:		89.67 %
Epoch 694 of 2000 took 0.099s
  training loss:		0.167103
  validation loss:		0.354198
  validation accuracy:		89.57 %
Epoch 695 of 2000 took 0.099s
  training loss:		0.171373
  validation loss:		0.350579
  validation accuracy:		88.91 %
Epoch 696 of 2000 took 0.099s
  training loss:		0.162272
  validation loss:		0.339545
  validation accuracy:		90.00 %
Epoch 697 of 2000 took 0.099s
  training loss:		0.163506
  validation loss:		0.340962
  validation accuracy:		89.57 %
Epoch 698 of 2000 took 0.099s
  training loss:		0.158934
  validation loss:		0.351934
  validation accuracy:		89.13 %
Epoch 699 of 2000 took 0.099s
  training loss:		0.167634
  validation loss:		0.339602
  validation accuracy:		90.00 %
Epoch 700 of 2000 took 0.099s
  training loss:		0.161274
  validation loss:		0.358655
  validation accuracy:		89.24 %
Epoch 701 of 2000 took 0.099s
  training loss:		0.171818
  validation loss:		0.362481
  validation accuracy:		89.24 %
Epoch 702 of 2000 took 0.099s
  training loss:		0.163191
  validation loss:		0.343261
  validation accuracy:		89.78 %
Epoch 703 of 2000 took 0.099s
  training loss:		0.174391
  validation loss:		0.350736
  validation accuracy:		89.78 %
Epoch 704 of 2000 took 0.099s
  training loss:		0.170319
  validation loss:		0.357592
  validation accuracy:		89.46 %
Epoch 705 of 2000 took 0.099s
  training loss:		0.161180
  validation loss:		0.345908
  validation accuracy:		89.67 %
Epoch 706 of 2000 took 0.099s
  training loss:		0.164737
  validation loss:		0.343527
  validation accuracy:		89.35 %
Epoch 707 of 2000 took 0.100s
  training loss:		0.160646
  validation loss:		0.343563
  validation accuracy:		90.33 %
Epoch 708 of 2000 took 0.099s
  training loss:		0.164633
  validation loss:		0.342163
  validation accuracy:		89.78 %
Epoch 709 of 2000 took 0.099s
  training loss:		0.163039
  validation loss:		0.345216
  validation accuracy:		90.22 %
Epoch 710 of 2000 took 0.099s
  training loss:		0.163269
  validation loss:		0.356431
  validation accuracy:		88.59 %
Epoch 711 of 2000 took 0.099s
  training loss:		0.166364
  validation loss:		0.348232
  validation accuracy:		89.67 %
Epoch 712 of 2000 took 0.099s
  training loss:		0.162380
  validation loss:		0.353018
  validation accuracy:		89.24 %
Epoch 713 of 2000 took 0.099s
  training loss:		0.164159
  validation loss:		0.334042
  validation accuracy:		90.43 %
Epoch 714 of 2000 took 0.099s
  training loss:		0.162571
  validation loss:		0.336209
  validation accuracy:		90.33 %
Epoch 715 of 2000 took 0.099s
  training loss:		0.162236
  validation loss:		0.341724
  validation accuracy:		90.54 %
Epoch 716 of 2000 took 0.099s
  training loss:		0.168206
  validation loss:		0.339295
  validation accuracy:		90.11 %
Epoch 717 of 2000 took 0.099s
  training loss:		0.162444
  validation loss:		0.345140
  validation accuracy:		91.30 %
Epoch 718 of 2000 took 0.099s
  training loss:		0.173741
  validation loss:		0.375722
  validation accuracy:		88.48 %
Epoch 719 of 2000 took 0.099s
  training loss:		0.168182
  validation loss:		0.373915
  validation accuracy:		88.70 %
Epoch 720 of 2000 took 0.099s
  training loss:		0.162454
  validation loss:		0.348079
  validation accuracy:		89.78 %
Epoch 721 of 2000 took 0.099s
  training loss:		0.162791
  validation loss:		0.348315
  validation accuracy:		88.91 %
Epoch 722 of 2000 took 0.099s
  training loss:		0.163034
  validation loss:		0.356316
  validation accuracy:		89.24 %
Epoch 723 of 2000 took 0.099s
  training loss:		0.163190
  validation loss:		0.359221
  validation accuracy:		89.24 %
Epoch 724 of 2000 took 0.099s
  training loss:		0.172917
  validation loss:		0.357476
  validation accuracy:		90.00 %
Epoch 725 of 2000 took 0.099s
  training loss:		0.160229
  validation loss:		0.340556
  validation accuracy:		89.89 %
Epoch 726 of 2000 took 0.099s
  training loss:		0.163415
  validation loss:		0.343287
  validation accuracy:		89.35 %
Epoch 727 of 2000 took 0.099s
  training loss:		0.166922
  validation loss:		0.350771
  validation accuracy:		89.78 %
Epoch 728 of 2000 took 0.099s
  training loss:		0.160630
  validation loss:		0.350604
  validation accuracy:		89.67 %
Epoch 729 of 2000 took 0.099s
  training loss:		0.167868
  validation loss:		0.344672
  validation accuracy:		89.57 %
Epoch 730 of 2000 took 0.099s
  training loss:		0.161802
  validation loss:		0.354462
  validation accuracy:		89.13 %
Epoch 731 of 2000 took 0.099s
  training loss:		0.157727
  validation loss:		0.351969
  validation accuracy:		88.91 %
Epoch 732 of 2000 took 0.099s
  training loss:		0.160481
  validation loss:		0.337067
  validation accuracy:		90.11 %
Epoch 733 of 2000 took 0.099s
  training loss:		0.159030
  validation loss:		0.343493
  validation accuracy:		89.24 %
Epoch 734 of 2000 took 0.099s
  training loss:		0.166810
  validation loss:		0.355793
  validation accuracy:		89.02 %
Epoch 735 of 2000 took 0.099s
  training loss:		0.165695
  validation loss:		0.340491
  validation accuracy:		89.35 %
Epoch 736 of 2000 took 0.099s
  training loss:		0.166326
  validation loss:		0.379989
  validation accuracy:		89.02 %
Epoch 737 of 2000 took 0.099s
  training loss:		0.167979
  validation loss:		0.341139
  validation accuracy:		89.57 %
Epoch 738 of 2000 took 0.099s
  training loss:		0.160879
  validation loss:		0.350628
  validation accuracy:		89.02 %
Epoch 739 of 2000 took 0.099s
  training loss:		0.158941
  validation loss:		0.344276
  validation accuracy:		90.65 %
Epoch 740 of 2000 took 0.100s
  training loss:		0.161584
  validation loss:		0.346141
  validation accuracy:		89.57 %
Epoch 741 of 2000 took 0.099s
  training loss:		0.159579
  validation loss:		0.347650
  validation accuracy:		90.00 %
Epoch 742 of 2000 took 0.100s
  training loss:		0.164092
  validation loss:		0.354140
  validation accuracy:		89.67 %
Epoch 743 of 2000 took 0.099s
  training loss:		0.161835
  validation loss:		0.350174
  validation accuracy:		89.78 %
Epoch 744 of 2000 took 0.099s
  training loss:		0.158621
  validation loss:		0.339893
  validation accuracy:		90.76 %
Epoch 745 of 2000 took 0.096s
  training loss:		0.160842
  validation loss:		0.352074
  validation accuracy:		90.00 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.162605
  validation loss:		0.348775
  validation accuracy:		89.89 %
Epoch 747 of 2000 took 0.098s
  training loss:		0.159492
  validation loss:		0.341649
  validation accuracy:		89.67 %
Epoch 748 of 2000 took 0.096s
  training loss:		0.156987
  validation loss:		0.355737
  validation accuracy:		89.67 %
Epoch 749 of 2000 took 0.096s
  training loss:		0.154868
  validation loss:		0.354392
  validation accuracy:		90.22 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.175856
  validation loss:		0.343602
  validation accuracy:		90.11 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.163019
  validation loss:		0.354820
  validation accuracy:		90.43 %
Epoch 752 of 2000 took 0.096s
  training loss:		0.165261
  validation loss:		0.344110
  validation accuracy:		89.67 %
Epoch 753 of 2000 took 0.099s
  training loss:		0.161148
  validation loss:		0.360855
  validation accuracy:		89.57 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.161186
  validation loss:		0.352273
  validation accuracy:		90.65 %
Epoch 755 of 2000 took 0.096s
  training loss:		0.162607
  validation loss:		0.349935
  validation accuracy:		90.33 %
Epoch 756 of 2000 took 0.096s
  training loss:		0.158443
  validation loss:		0.353820
  validation accuracy:		89.35 %
Epoch 757 of 2000 took 0.096s
  training loss:		0.163159
  validation loss:		0.349541
  validation accuracy:		89.13 %
Epoch 758 of 2000 took 0.096s
  training loss:		0.161025
  validation loss:		0.359682
  validation accuracy:		88.80 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.151878
  validation loss:		0.355750
  validation accuracy:		89.57 %
Epoch 760 of 2000 took 0.096s
  training loss:		0.162170
  validation loss:		0.356314
  validation accuracy:		89.78 %
Epoch 761 of 2000 took 0.096s
  training loss:		0.161472
  validation loss:		0.345592
  validation accuracy:		90.22 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.160272
  validation loss:		0.353964
  validation accuracy:		89.46 %
Epoch 763 of 2000 took 0.096s
  training loss:		0.162930
  validation loss:		0.351443
  validation accuracy:		89.89 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.156114
  validation loss:		0.352098
  validation accuracy:		89.46 %
Epoch 765 of 2000 took 0.096s
  training loss:		0.161051
  validation loss:		0.344826
  validation accuracy:		89.35 %
Epoch 766 of 2000 took 0.096s
  training loss:		0.157531
  validation loss:		0.367059
  validation accuracy:		90.11 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.160397
  validation loss:		0.350593
  validation accuracy:		90.11 %
Epoch 768 of 2000 took 0.096s
  training loss:		0.157602
  validation loss:		0.343810
  validation accuracy:		90.65 %
Epoch 769 of 2000 took 0.096s
  training loss:		0.165410
  validation loss:		0.358002
  validation accuracy:		89.35 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.165528
  validation loss:		0.356219
  validation accuracy:		89.24 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.157382
  validation loss:		0.371734
  validation accuracy:		88.59 %
Epoch 772 of 2000 took 0.096s
  training loss:		0.161115
  validation loss:		0.356726
  validation accuracy:		89.78 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.157529
  validation loss:		0.348718
  validation accuracy:		90.11 %
Epoch 774 of 2000 took 0.096s
  training loss:		0.162194
  validation loss:		0.351972
  validation accuracy:		89.89 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.153781
  validation loss:		0.350049
  validation accuracy:		90.00 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.157907
  validation loss:		0.349992
  validation accuracy:		90.65 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.148558
  validation loss:		0.345634
  validation accuracy:		90.54 %
Epoch 778 of 2000 took 0.096s
  training loss:		0.154467
  validation loss:		0.355728
  validation accuracy:		89.46 %
Epoch 779 of 2000 took 0.096s
  training loss:		0.171292
  validation loss:		0.387239
  validation accuracy:		88.70 %
Epoch 780 of 2000 took 0.096s
  training loss:		0.163001
  validation loss:		0.348467
  validation accuracy:		89.78 %
Epoch 781 of 2000 took 0.096s
  training loss:		0.156620
  validation loss:		0.350428
  validation accuracy:		89.78 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.155757
  validation loss:		0.348547
  validation accuracy:		89.46 %
Epoch 783 of 2000 took 0.096s
  training loss:		0.159399
  validation loss:		0.370077
  validation accuracy:		88.91 %
Epoch 784 of 2000 took 0.096s
  training loss:		0.155672
  validation loss:		0.355233
  validation accuracy:		89.78 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.162875
  validation loss:		0.357219
  validation accuracy:		89.57 %
Epoch 786 of 2000 took 0.096s
  training loss:		0.157046
  validation loss:		0.354977
  validation accuracy:		89.89 %
Epoch 787 of 2000 took 0.096s
  training loss:		0.170902
  validation loss:		0.360077
  validation accuracy:		89.46 %
Epoch 788 of 2000 took 0.096s
  training loss:		0.156383
  validation loss:		0.358908
  validation accuracy:		89.57 %
Epoch 789 of 2000 took 0.096s
  training loss:		0.154725
  validation loss:		0.348009
  validation accuracy:		90.65 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.158087
  validation loss:		0.373716
  validation accuracy:		88.80 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.163769
  validation loss:		0.359347
  validation accuracy:		89.35 %
Epoch 792 of 2000 took 0.096s
  training loss:		0.156545
  validation loss:		0.359028
  validation accuracy:		90.11 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.158380
  validation loss:		0.343139
  validation accuracy:		90.65 %
Epoch 794 of 2000 took 0.096s
  training loss:		0.161626
  validation loss:		0.346320
  validation accuracy:		90.54 %
Epoch 795 of 2000 took 0.096s
  training loss:		0.160934
  validation loss:		0.377232
  validation accuracy:		88.48 %
Epoch 796 of 2000 took 0.096s
  training loss:		0.155157
  validation loss:		0.361924
  validation accuracy:		89.46 %
Epoch 797 of 2000 took 0.096s
  training loss:		0.157708
  validation loss:		0.358811
  validation accuracy:		90.11 %
Epoch 798 of 2000 took 0.096s
  training loss:		0.166949
  validation loss:		0.357977
  validation accuracy:		89.57 %
Epoch 799 of 2000 took 0.096s
  training loss:		0.158600
  validation loss:		0.350876
  validation accuracy:		89.57 %
Epoch 800 of 2000 took 0.096s
  training loss:		0.152955
  validation loss:		0.346420
  validation accuracy:		90.00 %
Epoch 801 of 2000 took 0.096s
  training loss:		0.160529
  validation loss:		0.352777
  validation accuracy:		90.11 %
Epoch 802 of 2000 took 0.096s
  training loss:		0.158229
  validation loss:		0.357917
  validation accuracy:		89.46 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.156512
  validation loss:		0.359880
  validation accuracy:		89.46 %
Epoch 804 of 2000 took 0.096s
  training loss:		0.155236
  validation loss:		0.351382
  validation accuracy:		89.46 %
Epoch 805 of 2000 took 0.096s
  training loss:		0.163381
  validation loss:		0.346741
  validation accuracy:		90.33 %
Epoch 806 of 2000 took 0.096s
  training loss:		0.155173
  validation loss:		0.360084
  validation accuracy:		90.11 %
Epoch 807 of 2000 took 0.096s
  training loss:		0.155737
  validation loss:		0.356315
  validation accuracy:		89.89 %
Epoch 808 of 2000 took 0.096s
  training loss:		0.159178
  validation loss:		0.365470
  validation accuracy:		89.67 %
Epoch 809 of 2000 took 0.096s
  training loss:		0.155514
  validation loss:		0.350991
  validation accuracy:		90.65 %
Epoch 810 of 2000 took 0.096s
  training loss:		0.151183
  validation loss:		0.356853
  validation accuracy:		89.67 %
Epoch 811 of 2000 took 0.096s
  training loss:		0.160255
  validation loss:		0.354671
  validation accuracy:		89.57 %
Epoch 812 of 2000 took 0.096s
  training loss:		0.156389
  validation loss:		0.350811
  validation accuracy:		89.89 %
Epoch 813 of 2000 took 0.096s
  training loss:		0.154585
  validation loss:		0.360776
  validation accuracy:		89.67 %
Epoch 814 of 2000 took 0.096s
  training loss:		0.155940
  validation loss:		0.360998
  validation accuracy:		89.46 %
Epoch 815 of 2000 took 0.096s
  training loss:		0.153765
  validation loss:		0.361258
  validation accuracy:		88.91 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.154007
  validation loss:		0.369513
  validation accuracy:		89.24 %
Epoch 817 of 2000 took 0.096s
  training loss:		0.153303
  validation loss:		0.354365
  validation accuracy:		91.09 %
Epoch 818 of 2000 took 0.096s
  training loss:		0.156039
  validation loss:		0.358625
  validation accuracy:		89.24 %
Epoch 819 of 2000 took 0.096s
  training loss:		0.162373
  validation loss:		0.370509
  validation accuracy:		88.91 %
Epoch 820 of 2000 took 0.096s
  training loss:		0.160519
  validation loss:		0.356297
  validation accuracy:		89.57 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.162440
  validation loss:		0.391706
  validation accuracy:		88.15 %
Epoch 822 of 2000 took 0.096s
  training loss:		0.162587
  validation loss:		0.368228
  validation accuracy:		89.46 %
Epoch 823 of 2000 took 0.096s
  training loss:		0.154442
  validation loss:		0.350488
  validation accuracy:		89.89 %
Epoch 824 of 2000 took 0.096s
  training loss:		0.157624
  validation loss:		0.354146
  validation accuracy:		89.89 %
Epoch 825 of 2000 took 0.096s
  training loss:		0.158043
  validation loss:		0.355535
  validation accuracy:		89.46 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.170710
  validation loss:		0.365564
  validation accuracy:		89.46 %
Epoch 827 of 2000 took 0.096s
  training loss:		0.157490
  validation loss:		0.392868
  validation accuracy:		87.83 %
Epoch 828 of 2000 took 0.096s
  training loss:		0.160460
  validation loss:		0.373763
  validation accuracy:		89.35 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.153625
  validation loss:		0.348859
  validation accuracy:		89.67 %
Epoch 830 of 2000 took 0.096s
  training loss:		0.153577
  validation loss:		0.364805
  validation accuracy:		89.13 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.151323
  validation loss:		0.356019
  validation accuracy:		90.00 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.161799
  validation loss:		0.355489
  validation accuracy:		89.57 %
Epoch 833 of 2000 took 0.096s
  training loss:		0.155215
  validation loss:		0.360227
  validation accuracy:		89.67 %
Epoch 834 of 2000 took 0.097s
  training loss:		0.157322
  validation loss:		0.350144
  validation accuracy:		90.54 %
Epoch 835 of 2000 took 0.096s
  training loss:		0.153975
  validation loss:		0.353937
  validation accuracy:		89.57 %
Epoch 836 of 2000 took 0.096s
  training loss:		0.153507
  validation loss:		0.368995
  validation accuracy:		89.02 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.157382
  validation loss:		0.368458
  validation accuracy:		90.00 %
Epoch 838 of 2000 took 0.096s
  training loss:		0.159327
  validation loss:		0.423536
  validation accuracy:		88.70 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.162187
  validation loss:		0.390778
  validation accuracy:		88.37 %
Epoch 840 of 2000 took 0.096s
  training loss:		0.154429
  validation loss:		0.371633
  validation accuracy:		89.24 %
Epoch 841 of 2000 took 0.096s
  training loss:		0.155650
  validation loss:		0.362956
  validation accuracy:		89.89 %
Epoch 842 of 2000 took 0.096s
  training loss:		0.154378
  validation loss:		0.371699
  validation accuracy:		89.89 %
Epoch 843 of 2000 took 0.096s
  training loss:		0.154807
  validation loss:		0.363075
  validation accuracy:		89.57 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.159593
  validation loss:		0.374113
  validation accuracy:		89.02 %
Epoch 845 of 2000 took 0.096s
  training loss:		0.151943
  validation loss:		0.363962
  validation accuracy:		89.46 %
Epoch 846 of 2000 took 0.096s
  training loss:		0.155469
  validation loss:		0.367050
  validation accuracy:		89.02 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.158216
  validation loss:		0.367636
  validation accuracy:		89.02 %
Epoch 848 of 2000 took 0.096s
  training loss:		0.150858
  validation loss:		0.368262
  validation accuracy:		89.89 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.159051
  validation loss:		0.357434
  validation accuracy:		89.24 %
Epoch 850 of 2000 took 0.096s
  training loss:		0.149222
  validation loss:		0.368405
  validation accuracy:		88.91 %
Epoch 851 of 2000 took 0.096s
  training loss:		0.151116
  validation loss:		0.365948
  validation accuracy:		89.35 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.154910
  validation loss:		0.351992
  validation accuracy:		90.33 %
Epoch 853 of 2000 took 0.096s
  training loss:		0.153155
  validation loss:		0.352823
  validation accuracy:		90.33 %
Epoch 854 of 2000 took 0.096s
  training loss:		0.151873
  validation loss:		0.372864
  validation accuracy:		88.80 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.155892
  validation loss:		0.378949
  validation accuracy:		90.43 %
Epoch 856 of 2000 took 0.096s
  training loss:		0.154499
  validation loss:		0.367650
  validation accuracy:		89.67 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.156269
  validation loss:		0.358521
  validation accuracy:		90.54 %
Epoch 858 of 2000 took 0.096s
  training loss:		0.155208
  validation loss:		0.363667
  validation accuracy:		89.57 %
Epoch 859 of 2000 took 0.096s
  training loss:		0.153418
  validation loss:		0.379429
  validation accuracy:		89.13 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.150046
  validation loss:		0.357104
  validation accuracy:		90.22 %
Epoch 861 of 2000 took 0.096s
  training loss:		0.162994
  validation loss:		0.374404
  validation accuracy:		89.35 %
Epoch 862 of 2000 took 0.096s
  training loss:		0.156690
  validation loss:		0.364062
  validation accuracy:		89.57 %
Epoch 863 of 2000 took 0.096s
  training loss:		0.151103
  validation loss:		0.375263
  validation accuracy:		90.54 %
Epoch 864 of 2000 took 0.096s
  training loss:		0.155802
  validation loss:		0.361557
  validation accuracy:		89.78 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.163557
  validation loss:		0.360927
  validation accuracy:		90.11 %
Epoch 866 of 2000 took 0.096s
  training loss:		0.160101
  validation loss:		0.395733
  validation accuracy:		88.37 %
Epoch 867 of 2000 took 0.096s
  training loss:		0.152849
  validation loss:		0.384467
  validation accuracy:		88.80 %
Epoch 868 of 2000 took 0.096s
  training loss:		0.153984
  validation loss:		0.357144
  validation accuracy:		90.43 %
Epoch 869 of 2000 took 0.099s
  training loss:		0.151427
  validation loss:		0.370210
  validation accuracy:		89.67 %
Epoch 870 of 2000 took 0.099s
  training loss:		0.158742
  validation loss:		0.430128
  validation accuracy:		87.93 %
Epoch 871 of 2000 took 0.099s
  training loss:		0.161177
  validation loss:		0.364057
  validation accuracy:		89.89 %
Epoch 872 of 2000 took 0.103s
  training loss:		0.152282
  validation loss:		0.358722
  validation accuracy:		90.22 %
Epoch 873 of 2000 took 0.102s
  training loss:		0.153688
  validation loss:		0.367256
  validation accuracy:		90.43 %
Epoch 874 of 2000 took 0.102s
  training loss:		0.152016
  validation loss:		0.382120
  validation accuracy:		89.35 %
Epoch 875 of 2000 took 0.099s
  training loss:		0.157547
  validation loss:		0.368600
  validation accuracy:		89.78 %
Epoch 876 of 2000 took 0.099s
  training loss:		0.155944
  validation loss:		0.369324
  validation accuracy:		89.24 %
Epoch 877 of 2000 took 0.099s
  training loss:		0.149495
  validation loss:		0.358893
  validation accuracy:		90.00 %
Epoch 878 of 2000 took 0.099s
  training loss:		0.157693
  validation loss:		0.360171
  validation accuracy:		90.00 %
Epoch 879 of 2000 took 0.099s
  training loss:		0.152400
  validation loss:		0.374979
  validation accuracy:		89.13 %
Epoch 880 of 2000 took 0.099s
  training loss:		0.151294
  validation loss:		0.371978
  validation accuracy:		89.02 %
Epoch 881 of 2000 took 0.099s
  training loss:		0.145759
  validation loss:		0.376845
  validation accuracy:		89.67 %
Epoch 882 of 2000 took 0.099s
  training loss:		0.158439
  validation loss:		0.382379
  validation accuracy:		88.48 %
Epoch 883 of 2000 took 0.099s
  training loss:		0.152604
  validation loss:		0.367940
  validation accuracy:		90.43 %
Epoch 884 of 2000 took 0.099s
  training loss:		0.151515
  validation loss:		0.395770
  validation accuracy:		90.00 %
Epoch 885 of 2000 took 0.099s
  training loss:		0.164584
  validation loss:		0.366909
  validation accuracy:		89.46 %
Epoch 886 of 2000 took 0.099s
  training loss:		0.153242
  validation loss:		0.363000
  validation accuracy:		90.54 %
Epoch 887 of 2000 took 0.099s
  training loss:		0.151575
  validation loss:		0.368695
  validation accuracy:		90.22 %
Epoch 888 of 2000 took 0.099s
  training loss:		0.155232
  validation loss:		0.388885
  validation accuracy:		88.26 %
Epoch 889 of 2000 took 0.099s
  training loss:		0.158183
  validation loss:		0.389459
  validation accuracy:		89.24 %
Epoch 890 of 2000 took 0.099s
  training loss:		0.155148
  validation loss:		0.373469
  validation accuracy:		89.35 %
Epoch 891 of 2000 took 0.099s
  training loss:		0.156253
  validation loss:		0.366960
  validation accuracy:		90.33 %
Epoch 892 of 2000 took 0.099s
  training loss:		0.159986
  validation loss:		0.367428
  validation accuracy:		90.43 %
Epoch 893 of 2000 took 0.099s
  training loss:		0.149422
  validation loss:		0.363704
  validation accuracy:		90.43 %
Epoch 894 of 2000 took 0.099s
  training loss:		0.146557
  validation loss:		0.364630
  validation accuracy:		90.11 %
Epoch 895 of 2000 took 0.099s
  training loss:		0.158266
  validation loss:		0.380769
  validation accuracy:		89.57 %
Epoch 896 of 2000 took 0.100s
  training loss:		0.155383
  validation loss:		0.357785
  validation accuracy:		90.00 %
Epoch 897 of 2000 took 0.099s
  training loss:		0.149280
  validation loss:		0.368333
  validation accuracy:		89.35 %
Epoch 898 of 2000 took 0.099s
  training loss:		0.155061
  validation loss:		0.363922
  validation accuracy:		89.35 %
Epoch 899 of 2000 took 0.099s
  training loss:		0.149524
  validation loss:		0.362315
  validation accuracy:		90.76 %
Epoch 900 of 2000 took 0.099s
  training loss:		0.146312
  validation loss:		0.372259
  validation accuracy:		89.57 %
Epoch 901 of 2000 took 0.099s
  training loss:		0.153735
  validation loss:		0.362430
  validation accuracy:		89.89 %
Epoch 902 of 2000 took 0.099s
  training loss:		0.153984
  validation loss:		0.362274
  validation accuracy:		89.89 %
Epoch 903 of 2000 took 0.099s
  training loss:		0.150153
  validation loss:		0.361012
  validation accuracy:		89.89 %
Epoch 904 of 2000 took 0.099s
  training loss:		0.150475
  validation loss:		0.365009
  validation accuracy:		90.00 %
Epoch 905 of 2000 took 0.099s
  training loss:		0.153717
  validation loss:		0.373330
  validation accuracy:		89.35 %
Epoch 906 of 2000 took 0.099s
  training loss:		0.157714
  validation loss:		0.369250
  validation accuracy:		89.57 %
Epoch 907 of 2000 took 0.099s
  training loss:		0.144812
  validation loss:		0.378929
  validation accuracy:		89.67 %
Epoch 908 of 2000 took 0.099s
  training loss:		0.149122
  validation loss:		0.372678
  validation accuracy:		89.35 %
Epoch 909 of 2000 took 0.097s
  training loss:		0.147908
  validation loss:		0.369065
  validation accuracy:		89.46 %
Epoch 910 of 2000 took 0.096s
  training loss:		0.151506
  validation loss:		0.368708
  validation accuracy:		89.67 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.147708
  validation loss:		0.375084
  validation accuracy:		90.33 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.158586
  validation loss:		0.369125
  validation accuracy:		90.11 %
Epoch 913 of 2000 took 0.096s
  training loss:		0.153074
  validation loss:		0.361283
  validation accuracy:		90.54 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.146813
  validation loss:		0.364876
  validation accuracy:		89.57 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.154940
  validation loss:		0.368343
  validation accuracy:		89.78 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.150362
  validation loss:		0.364106
  validation accuracy:		90.33 %
Epoch 917 of 2000 took 0.096s
  training loss:		0.153891
  validation loss:		0.377029
  validation accuracy:		89.02 %
Epoch 918 of 2000 took 0.096s
  training loss:		0.155259
  validation loss:		0.368445
  validation accuracy:		90.43 %
Epoch 919 of 2000 took 0.096s
  training loss:		0.150664
  validation loss:		0.366467
  validation accuracy:		89.67 %
Epoch 920 of 2000 took 0.096s
  training loss:		0.152123
  validation loss:		0.387464
  validation accuracy:		89.57 %
Epoch 921 of 2000 took 0.096s
  training loss:		0.152337
  validation loss:		0.400061
  validation accuracy:		88.80 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.155657
  validation loss:		0.377928
  validation accuracy:		89.67 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.158301
  validation loss:		0.376430
  validation accuracy:		90.11 %
Epoch 924 of 2000 took 0.096s
  training loss:		0.151983
  validation loss:		0.366788
  validation accuracy:		90.33 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.153145
  validation loss:		0.380946
  validation accuracy:		88.80 %
Epoch 926 of 2000 took 0.096s
  training loss:		0.151668
  validation loss:		0.370233
  validation accuracy:		89.67 %
Epoch 927 of 2000 took 0.100s
  training loss:		0.151048
  validation loss:		0.375700
  validation accuracy:		90.54 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.151525
  validation loss:		0.363284
  validation accuracy:		90.54 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.150475
  validation loss:		0.374364
  validation accuracy:		89.46 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.150834
  validation loss:		0.370311
  validation accuracy:		89.46 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.150498
  validation loss:		0.392056
  validation accuracy:		88.59 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.154855
  validation loss:		0.375893
  validation accuracy:		90.00 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.154099
  validation loss:		0.367542
  validation accuracy:		89.67 %
Epoch 934 of 2000 took 0.096s
  training loss:		0.152205
  validation loss:		0.373583
  validation accuracy:		90.00 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.150598
  validation loss:		0.381770
  validation accuracy:		89.35 %
Epoch 936 of 2000 took 0.096s
  training loss:		0.146633
  validation loss:		0.377472
  validation accuracy:		90.11 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.148222
  validation loss:		0.364157
  validation accuracy:		90.22 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.150443
  validation loss:		0.370922
  validation accuracy:		90.00 %
Epoch 939 of 2000 took 0.096s
  training loss:		0.148174
  validation loss:		0.387958
  validation accuracy:		89.13 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.154704
  validation loss:		0.375021
  validation accuracy:		89.46 %
Epoch 941 of 2000 took 0.096s
  training loss:		0.143015
  validation loss:		0.374989
  validation accuracy:		89.67 %
Epoch 942 of 2000 took 0.096s
  training loss:		0.157324
  validation loss:		0.371928
  validation accuracy:		89.78 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.147265
  validation loss:		0.381322
  validation accuracy:		89.13 %
Epoch 944 of 2000 took 0.096s
  training loss:		0.154133
  validation loss:		0.388552
  validation accuracy:		88.70 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.149407
  validation loss:		0.377571
  validation accuracy:		89.24 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.142191
  validation loss:		0.378096
  validation accuracy:		89.57 %
Epoch 947 of 2000 took 0.096s
  training loss:		0.148640
  validation loss:		0.374002
  validation accuracy:		89.35 %
Epoch 948 of 2000 took 0.096s
  training loss:		0.149142
  validation loss:		0.376729
  validation accuracy:		89.35 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.145834
  validation loss:		0.364664
  validation accuracy:		89.78 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.151405
  validation loss:		0.366445
  validation accuracy:		89.67 %
Epoch 951 of 2000 took 0.098s
  training loss:		0.147834
  validation loss:		0.387224
  validation accuracy:		89.46 %
Epoch 952 of 2000 took 0.099s
  training loss:		0.148089
  validation loss:		0.389940
  validation accuracy:		89.13 %
Epoch 953 of 2000 took 0.099s
  training loss:		0.148678
  validation loss:		0.372025
  validation accuracy:		89.46 %
Epoch 954 of 2000 took 0.099s
  training loss:		0.149997
  validation loss:		0.403529
  validation accuracy:		88.70 %
Epoch 955 of 2000 took 0.099s
  training loss:		0.146679
  validation loss:		0.378347
  validation accuracy:		90.43 %
Epoch 956 of 2000 took 0.099s
  training loss:		0.148496
  validation loss:		0.376458
  validation accuracy:		89.78 %
Epoch 957 of 2000 took 0.099s
  training loss:		0.154422
  validation loss:		0.365038
  validation accuracy:		90.00 %
Epoch 958 of 2000 took 0.100s
  training loss:		0.153423
  validation loss:		0.374278
  validation accuracy:		89.46 %
Epoch 959 of 2000 took 0.099s
  training loss:		0.153672
  validation loss:		0.401672
  validation accuracy:		88.15 %
Epoch 960 of 2000 took 0.099s
  training loss:		0.152162
  validation loss:		0.367136
  validation accuracy:		89.89 %
Epoch 961 of 2000 took 0.099s
  training loss:		0.144972
  validation loss:		0.375658
  validation accuracy:		89.78 %
Epoch 962 of 2000 took 0.099s
  training loss:		0.152769
  validation loss:		0.383731
  validation accuracy:		89.13 %
Epoch 963 of 2000 took 0.099s
  training loss:		0.150807
  validation loss:		0.379279
  validation accuracy:		90.11 %
Epoch 964 of 2000 took 0.099s
  training loss:		0.148454
  validation loss:		0.364998
  validation accuracy:		90.33 %
Epoch 965 of 2000 took 0.099s
  training loss:		0.150712
  validation loss:		0.375390
  validation accuracy:		89.13 %
Epoch 966 of 2000 took 0.099s
  training loss:		0.151421
  validation loss:		0.363719
  validation accuracy:		90.11 %
Epoch 967 of 2000 took 0.099s
  training loss:		0.155330
  validation loss:		0.367170
  validation accuracy:		90.54 %
Epoch 968 of 2000 took 0.099s
  training loss:		0.148145
  validation loss:		0.379467
  validation accuracy:		89.46 %
Epoch 969 of 2000 took 0.099s
  training loss:		0.144129
  validation loss:		0.370287
  validation accuracy:		90.22 %
Epoch 970 of 2000 took 0.099s
  training loss:		0.150444
  validation loss:		0.376715
  validation accuracy:		90.00 %
Epoch 971 of 2000 took 0.099s
  training loss:		0.151669
  validation loss:		0.362340
  validation accuracy:		90.22 %
Epoch 972 of 2000 took 0.099s
  training loss:		0.145947
  validation loss:		0.367111
  validation accuracy:		90.11 %
Epoch 973 of 2000 took 0.099s
  training loss:		0.150644
  validation loss:		0.373859
  validation accuracy:		90.33 %
Epoch 974 of 2000 took 0.099s
  training loss:		0.141593
  validation loss:		0.369621
  validation accuracy:		90.43 %
Epoch 975 of 2000 took 0.099s
  training loss:		0.144052
  validation loss:		0.372692
  validation accuracy:		90.00 %
Epoch 976 of 2000 took 0.099s
  training loss:		0.147062
  validation loss:		0.370845
  validation accuracy:		90.11 %
Epoch 977 of 2000 took 0.099s
  training loss:		0.145930
  validation loss:		0.381991
  validation accuracy:		90.00 %
Epoch 978 of 2000 took 0.099s
  training loss:		0.148303
  validation loss:		0.384354
  validation accuracy:		89.02 %
Epoch 979 of 2000 took 0.099s
  training loss:		0.140908
  validation loss:		0.385522
  validation accuracy:		89.35 %
Epoch 980 of 2000 took 0.099s
  training loss:		0.158857
  validation loss:		0.388320
  validation accuracy:		89.57 %
Epoch 981 of 2000 took 0.099s
  training loss:		0.145639
  validation loss:		0.375053
  validation accuracy:		89.46 %
Epoch 982 of 2000 took 0.099s
  training loss:		0.146414
  validation loss:		0.373018
  validation accuracy:		90.33 %
Epoch 983 of 2000 took 0.099s
  training loss:		0.152841
  validation loss:		0.383780
  validation accuracy:		89.13 %
Epoch 984 of 2000 took 0.100s
  training loss:		0.138039
  validation loss:		0.374051
  validation accuracy:		89.78 %
Epoch 985 of 2000 took 0.099s
  training loss:		0.144202
  validation loss:		0.397616
  validation accuracy:		88.80 %
Epoch 986 of 2000 took 0.099s
  training loss:		0.146941
  validation loss:		0.397321
  validation accuracy:		88.91 %
Epoch 987 of 2000 took 0.099s
  training loss:		0.142412
  validation loss:		0.389478
  validation accuracy:		89.46 %
Epoch 988 of 2000 took 0.100s
  training loss:		0.147429
  validation loss:		0.373276
  validation accuracy:		89.67 %
Epoch 989 of 2000 took 0.099s
  training loss:		0.148732
  validation loss:		0.369758
  validation accuracy:		89.89 %
Epoch 990 of 2000 took 0.099s
  training loss:		0.152517
  validation loss:		0.375277
  validation accuracy:		89.57 %
Epoch 991 of 2000 took 0.099s
  training loss:		0.150562
  validation loss:		0.379278
  validation accuracy:		89.67 %
Epoch 992 of 2000 took 0.099s
  training loss:		0.149124
  validation loss:		0.379826
  validation accuracy:		89.46 %
Epoch 993 of 2000 took 0.099s
  training loss:		0.144816
  validation loss:		0.374601
  validation accuracy:		89.67 %
Epoch 994 of 2000 took 0.099s
  training loss:		0.148480
  validation loss:		0.386915
  validation accuracy:		89.57 %
Epoch 995 of 2000 took 0.099s
  training loss:		0.152322
  validation loss:		0.385719
  validation accuracy:		89.46 %
Epoch 996 of 2000 took 0.099s
  training loss:		0.147532
  validation loss:		0.385600
  validation accuracy:		89.35 %
Epoch 997 of 2000 took 0.099s
  training loss:		0.150425
  validation loss:		0.389181
  validation accuracy:		89.02 %
Epoch 998 of 2000 took 0.099s
  training loss:		0.149534
  validation loss:		0.390545
  validation accuracy:		88.80 %
Epoch 999 of 2000 took 0.099s
  training loss:		0.145855
  validation loss:		0.386903
  validation accuracy:		89.02 %
Epoch 1000 of 2000 took 0.099s
  training loss:		0.147483
  validation loss:		0.387203
  validation accuracy:		89.57 %
Epoch 1001 of 2000 took 0.099s
  training loss:		0.143370
  validation loss:		0.365588
  validation accuracy:		90.22 %
Epoch 1002 of 2000 took 0.099s
  training loss:		0.149239
  validation loss:		0.386048
  validation accuracy:		88.91 %
Epoch 1003 of 2000 took 0.099s
  training loss:		0.147945
  validation loss:		0.393369
  validation accuracy:		89.13 %
Epoch 1004 of 2000 took 0.099s
  training loss:		0.154336
  validation loss:		0.392323
  validation accuracy:		88.80 %
Epoch 1005 of 2000 took 0.099s
  training loss:		0.144964
  validation loss:		0.389177
  validation accuracy:		89.78 %
Epoch 1006 of 2000 took 0.099s
  training loss:		0.146940
  validation loss:		0.386253
  validation accuracy:		89.46 %
Epoch 1007 of 2000 took 0.099s
  training loss:		0.157518
  validation loss:		0.377300
  validation accuracy:		89.78 %
Epoch 1008 of 2000 took 0.099s
  training loss:		0.149940
  validation loss:		0.372163
  validation accuracy:		90.65 %
Epoch 1009 of 2000 took 0.099s
  training loss:		0.147130
  validation loss:		0.390373
  validation accuracy:		89.02 %
Epoch 1010 of 2000 took 0.099s
  training loss:		0.145719
  validation loss:		0.379666
  validation accuracy:		89.89 %
Epoch 1011 of 2000 took 0.099s
  training loss:		0.152406
  validation loss:		0.385986
  validation accuracy:		89.67 %
Epoch 1012 of 2000 took 0.099s
  training loss:		0.148787
  validation loss:		0.371591
  validation accuracy:		90.11 %
Epoch 1013 of 2000 took 0.099s
  training loss:		0.150482
  validation loss:		0.370644
  validation accuracy:		90.11 %
Epoch 1014 of 2000 took 0.099s
  training loss:		0.139325
  validation loss:		0.379391
  validation accuracy:		90.22 %
Epoch 1015 of 2000 took 0.099s
  training loss:		0.155081
  validation loss:		0.381384
  validation accuracy:		90.00 %
Epoch 1016 of 2000 took 0.099s
  training loss:		0.144853
  validation loss:		0.403928
  validation accuracy:		88.80 %
Epoch 1017 of 2000 took 0.099s
  training loss:		0.152938
  validation loss:		0.371848
  validation accuracy:		90.22 %
Epoch 1018 of 2000 took 0.100s
  training loss:		0.144472
  validation loss:		0.385970
  validation accuracy:		89.35 %
Epoch 1019 of 2000 took 0.099s
  training loss:		0.148462
  validation loss:		0.373240
  validation accuracy:		89.78 %
Epoch 1020 of 2000 took 0.099s
  training loss:		0.149688
  validation loss:		0.397117
  validation accuracy:		88.80 %
Epoch 1021 of 2000 took 0.099s
  training loss:		0.147302
  validation loss:		0.374693
  validation accuracy:		89.78 %
Epoch 1022 of 2000 took 0.099s
  training loss:		0.144638
  validation loss:		0.382683
  validation accuracy:		89.35 %
Epoch 1023 of 2000 took 0.099s
  training loss:		0.148488
  validation loss:		0.375321
  validation accuracy:		90.43 %
Epoch 1024 of 2000 took 0.099s
  training loss:		0.139471
  validation loss:		0.412443
  validation accuracy:		88.04 %
Epoch 1025 of 2000 took 0.099s
  training loss:		0.148978
  validation loss:		0.383056
  validation accuracy:		89.67 %
Epoch 1026 of 2000 took 0.099s
  training loss:		0.142865
  validation loss:		0.372708
  validation accuracy:		90.00 %
Epoch 1027 of 2000 took 0.099s
  training loss:		0.150241
  validation loss:		0.375477
  validation accuracy:		89.67 %
Epoch 1028 of 2000 took 0.099s
  training loss:		0.144954
  validation loss:		0.387425
  validation accuracy:		89.67 %
Epoch 1029 of 2000 took 0.099s
  training loss:		0.141779
  validation loss:		0.380807
  validation accuracy:		89.78 %
Epoch 1030 of 2000 took 0.099s
  training loss:		0.146033
  validation loss:		0.385117
  validation accuracy:		90.43 %
Epoch 1031 of 2000 took 0.099s
  training loss:		0.145799
  validation loss:		0.380657
  validation accuracy:		89.46 %
Epoch 1032 of 2000 took 0.101s
  training loss:		0.150796
  validation loss:		0.376322
  validation accuracy:		90.11 %
Epoch 1033 of 2000 took 0.102s
  training loss:		0.154131
  validation loss:		0.380049
  validation accuracy:		90.00 %
Epoch 1034 of 2000 took 0.102s
  training loss:		0.144081
  validation loss:		0.376386
  validation accuracy:		90.00 %
Epoch 1035 of 2000 took 0.102s
  training loss:		0.139195
  validation loss:		0.379616
  validation accuracy:		90.33 %
Epoch 1036 of 2000 took 0.099s
  training loss:		0.140805
  validation loss:		0.372011
  validation accuracy:		90.33 %
Epoch 1037 of 2000 took 0.099s
  training loss:		0.147672
  validation loss:		0.393407
  validation accuracy:		89.13 %
Epoch 1038 of 2000 took 0.099s
  training loss:		0.144613
  validation loss:		0.385246
  validation accuracy:		89.67 %
Epoch 1039 of 2000 took 0.099s
  training loss:		0.143342
  validation loss:		0.411141
  validation accuracy:		88.48 %
Epoch 1040 of 2000 took 0.099s
  training loss:		0.147983
  validation loss:		0.379262
  validation accuracy:		89.67 %
Epoch 1041 of 2000 took 0.099s
  training loss:		0.142063
  validation loss:		0.376228
  validation accuracy:		89.89 %
Epoch 1042 of 2000 took 0.099s
  training loss:		0.144816
  validation loss:		0.402120
  validation accuracy:		88.91 %
Epoch 1043 of 2000 took 0.099s
  training loss:		0.143329
  validation loss:		0.388308
  validation accuracy:		89.57 %
Epoch 1044 of 2000 took 0.099s
  training loss:		0.138193
  validation loss:		0.391440
  validation accuracy:		89.24 %
Epoch 1045 of 2000 took 0.099s
  training loss:		0.145050
  validation loss:		0.379956
  validation accuracy:		90.11 %
Epoch 1046 of 2000 took 0.099s
  training loss:		0.144294
  validation loss:		0.392306
  validation accuracy:		89.13 %
Epoch 1047 of 2000 took 0.099s
  training loss:		0.140969
  validation loss:		0.385535
  validation accuracy:		89.78 %
Epoch 1048 of 2000 took 0.099s
  training loss:		0.147673
  validation loss:		0.388467
  validation accuracy:		89.67 %
Epoch 1049 of 2000 took 0.099s
  training loss:		0.148539
  validation loss:		0.383366
  validation accuracy:		89.78 %
Epoch 1050 of 2000 took 0.099s
  training loss:		0.142005
  validation loss:		0.377173
  validation accuracy:		89.67 %
Epoch 1051 of 2000 took 0.099s
  training loss:		0.149953
  validation loss:		0.413003
  validation accuracy:		88.37 %
Epoch 1052 of 2000 took 0.099s
  training loss:		0.144328
  validation loss:		0.395393
  validation accuracy:		89.13 %
Epoch 1053 of 2000 took 0.099s
  training loss:		0.147838
  validation loss:		0.378223
  validation accuracy:		89.78 %
Epoch 1054 of 2000 took 0.099s
  training loss:		0.142406
  validation loss:		0.405222
  validation accuracy:		89.46 %
Epoch 1055 of 2000 took 0.099s
  training loss:		0.147166
  validation loss:		0.379664
  validation accuracy:		89.57 %
Epoch 1056 of 2000 took 0.099s
  training loss:		0.152181
  validation loss:		0.388807
  validation accuracy:		89.89 %
Epoch 1057 of 2000 took 0.099s
  training loss:		0.146959
  validation loss:		0.389559
  validation accuracy:		89.57 %
Epoch 1058 of 2000 took 0.099s
  training loss:		0.146739
  validation loss:		0.378584
  validation accuracy:		90.54 %
Epoch 1059 of 2000 took 0.099s
  training loss:		0.153300
  validation loss:		0.396146
  validation accuracy:		89.24 %
Epoch 1060 of 2000 took 0.099s
  training loss:		0.147490
  validation loss:		0.380187
  validation accuracy:		90.65 %
Epoch 1061 of 2000 took 0.100s
  training loss:		0.142416
  validation loss:		0.383119
  validation accuracy:		89.67 %
Epoch 1062 of 2000 took 0.099s
  training loss:		0.152947
  validation loss:		0.383458
  validation accuracy:		89.67 %
Epoch 1063 of 2000 took 0.101s
  training loss:		0.150158
  validation loss:		0.407887
  validation accuracy:		89.24 %
Epoch 1064 of 2000 took 0.101s
  training loss:		0.148425
  validation loss:		0.385612
  validation accuracy:		90.00 %
Epoch 1065 of 2000 took 0.099s
  training loss:		0.137109
  validation loss:		0.385356
  validation accuracy:		90.54 %
Epoch 1066 of 2000 took 0.099s
  training loss:		0.141306
  validation loss:		0.390433
  validation accuracy:		89.35 %
Epoch 1067 of 2000 took 0.099s
  training loss:		0.139434
  validation loss:		0.422914
  validation accuracy:		88.04 %
Epoch 1068 of 2000 took 0.099s
  training loss:		0.144642
  validation loss:		0.409926
  validation accuracy:		88.91 %
Epoch 1069 of 2000 took 0.099s
  training loss:		0.148441
  validation loss:		0.408724
  validation accuracy:		88.80 %
Epoch 1070 of 2000 took 0.099s
  training loss:		0.155856
  validation loss:		0.377078
  validation accuracy:		90.22 %
Epoch 1071 of 2000 took 0.099s
  training loss:		0.147713
  validation loss:		0.392241
  validation accuracy:		90.00 %
Epoch 1072 of 2000 took 0.099s
  training loss:		0.142712
  validation loss:		0.381476
  validation accuracy:		90.11 %
Epoch 1073 of 2000 took 0.099s
  training loss:		0.148639
  validation loss:		0.394106
  validation accuracy:		88.91 %
Epoch 1074 of 2000 took 0.099s
  training loss:		0.149729
  validation loss:		0.392548
  validation accuracy:		89.35 %
Epoch 1075 of 2000 took 0.099s
  training loss:		0.145508
  validation loss:		0.382452
  validation accuracy:		89.57 %
Epoch 1076 of 2000 took 0.099s
  training loss:		0.142006
  validation loss:		0.383230
  validation accuracy:		90.87 %
Epoch 1077 of 2000 took 0.099s
  training loss:		0.148592
  validation loss:		0.377239
  validation accuracy:		90.11 %
Epoch 1078 of 2000 took 0.099s
  training loss:		0.146768
  validation loss:		0.392290
  validation accuracy:		89.89 %
Epoch 1079 of 2000 took 0.100s
  training loss:		0.148459
  validation loss:		0.399040
  validation accuracy:		88.91 %
Epoch 1080 of 2000 took 0.099s
  training loss:		0.143536
  validation loss:		0.404174
  validation accuracy:		89.13 %
Epoch 1081 of 2000 took 0.099s
  training loss:		0.146185
  validation loss:		0.408227
  validation accuracy:		88.70 %
Epoch 1082 of 2000 took 0.099s
  training loss:		0.142955
  validation loss:		0.395543
  validation accuracy:		90.76 %
Epoch 1083 of 2000 took 0.099s
  training loss:		0.144036
  validation loss:		0.418546
  validation accuracy:		87.72 %
Epoch 1084 of 2000 took 0.099s
  training loss:		0.152594
  validation loss:		0.406688
  validation accuracy:		88.91 %
Epoch 1085 of 2000 took 0.099s
  training loss:		0.145936
  validation loss:		0.402907
  validation accuracy:		88.91 %
Epoch 1086 of 2000 took 0.099s
  training loss:		0.143074
  validation loss:		0.386980
  validation accuracy:		89.35 %
Epoch 1087 of 2000 took 0.099s
  training loss:		0.144824
  validation loss:		0.396234
  validation accuracy:		90.43 %
Epoch 1088 of 2000 took 0.099s
  training loss:		0.139593
  validation loss:		0.393678
  validation accuracy:		90.11 %
Epoch 1089 of 2000 took 0.099s
  training loss:		0.140821
  validation loss:		0.377489
  validation accuracy:		90.00 %
Epoch 1090 of 2000 took 0.099s
  training loss:		0.141072
  validation loss:		0.386839
  validation accuracy:		89.57 %
Epoch 1091 of 2000 took 0.099s
  training loss:		0.137504
  validation loss:		0.391909
  validation accuracy:		89.35 %
Epoch 1092 of 2000 took 0.099s
  training loss:		0.143292
  validation loss:		0.393694
  validation accuracy:		89.13 %
Epoch 1093 of 2000 took 0.100s
  training loss:		0.146198
  validation loss:		0.404281
  validation accuracy:		89.78 %
Epoch 1094 of 2000 took 0.099s
  training loss:		0.139834
  validation loss:		0.387035
  validation accuracy:		90.11 %
Epoch 1095 of 2000 took 0.099s
  training loss:		0.143345
  validation loss:		0.385315
  validation accuracy:		89.78 %
Epoch 1096 of 2000 took 0.099s
  training loss:		0.145506
  validation loss:		0.400647
  validation accuracy:		89.02 %
Epoch 1097 of 2000 took 0.099s
  training loss:		0.143852
  validation loss:		0.391170
  validation accuracy:		89.46 %
Epoch 1098 of 2000 took 0.099s
  training loss:		0.147320
  validation loss:		0.390804
  validation accuracy:		89.57 %
Epoch 1099 of 2000 took 0.099s
  training loss:		0.144671
  validation loss:		0.398083
  validation accuracy:		89.13 %
Epoch 1100 of 2000 took 0.099s
  training loss:		0.146038
  validation loss:		0.403172
  validation accuracy:		89.35 %
Epoch 1101 of 2000 took 0.099s
  training loss:		0.138256
  validation loss:		0.386023
  validation accuracy:		89.89 %
Epoch 1102 of 2000 took 0.099s
  training loss:		0.135499
  validation loss:		0.386654
  validation accuracy:		90.11 %
Epoch 1103 of 2000 took 0.099s
  training loss:		0.140767
  validation loss:		0.395936
  validation accuracy:		88.91 %
Epoch 1104 of 2000 took 0.099s
  training loss:		0.137336
  validation loss:		0.384204
  validation accuracy:		89.78 %
Epoch 1105 of 2000 took 0.099s
  training loss:		0.141222
  validation loss:		0.393701
  validation accuracy:		89.89 %
Epoch 1106 of 2000 took 0.102s
  training loss:		0.146780
  validation loss:		0.392869
  validation accuracy:		89.57 %
Epoch 1107 of 2000 took 0.102s
  training loss:		0.145572
  validation loss:		0.386840
  validation accuracy:		90.11 %
Epoch 1108 of 2000 took 0.102s
  training loss:		0.147711
  validation loss:		0.398403
  validation accuracy:		90.43 %
Epoch 1109 of 2000 took 0.102s
  training loss:		0.146729
  validation loss:		0.383958
  validation accuracy:		90.33 %
Epoch 1110 of 2000 took 0.099s
  training loss:		0.147044
  validation loss:		0.388066
  validation accuracy:		89.78 %
Epoch 1111 of 2000 took 0.099s
  training loss:		0.145393
  validation loss:		0.388864
  validation accuracy:		89.89 %
Epoch 1112 of 2000 took 0.099s
  training loss:		0.141293
  validation loss:		0.390809
  validation accuracy:		89.89 %
Epoch 1113 of 2000 took 0.099s
  training loss:		0.139373
  validation loss:		0.388571
  validation accuracy:		89.46 %
Epoch 1114 of 2000 took 0.099s
  training loss:		0.157062
  validation loss:		0.397856
  validation accuracy:		89.67 %
Epoch 1115 of 2000 took 0.099s
  training loss:		0.138598
  validation loss:		0.392725
  validation accuracy:		90.11 %
Epoch 1116 of 2000 took 0.099s
  training loss:		0.141308
  validation loss:		0.385017
  validation accuracy:		90.11 %
Epoch 1117 of 2000 took 0.099s
  training loss:		0.141068
  validation loss:		0.386278
  validation accuracy:		89.89 %
Epoch 1118 of 2000 took 0.099s
  training loss:		0.142140
  validation loss:		0.385696
  validation accuracy:		90.11 %
Epoch 1119 of 2000 took 0.099s
  training loss:		0.142851
  validation loss:		0.403250
  validation accuracy:		89.67 %
Epoch 1120 of 2000 took 0.099s
  training loss:		0.147831
  validation loss:		0.400478
  validation accuracy:		89.02 %
Epoch 1121 of 2000 took 0.099s
  training loss:		0.135181
  validation loss:		0.403018
  validation accuracy:		89.67 %
Epoch 1122 of 2000 took 0.099s
  training loss:		0.140442
  validation loss:		0.391515
  validation accuracy:		90.00 %
Epoch 1123 of 2000 took 0.099s
  training loss:		0.150087
  validation loss:		0.405946
  validation accuracy:		90.65 %
Epoch 1124 of 2000 took 0.099s
  training loss:		0.141261
  validation loss:		0.395439
  validation accuracy:		89.24 %
Epoch 1125 of 2000 took 0.099s
  training loss:		0.144597
  validation loss:		0.385814
  validation accuracy:		90.33 %
Epoch 1126 of 2000 took 0.099s
  training loss:		0.147441
  validation loss:		0.394632
  validation accuracy:		89.57 %
Epoch 1127 of 2000 took 0.099s
  training loss:		0.136235
  validation loss:		0.427448
  validation accuracy:		89.35 %
Epoch 1128 of 2000 took 0.099s
  training loss:		0.151169
  validation loss:		0.393902
  validation accuracy:		89.67 %
Epoch 1129 of 2000 took 0.099s
  training loss:		0.144341
  validation loss:		0.411350
  validation accuracy:		89.57 %
Epoch 1130 of 2000 took 0.100s
  training loss:		0.142426
  validation loss:		0.407789
  validation accuracy:		89.57 %
Epoch 1131 of 2000 took 0.101s
  training loss:		0.142209
  validation loss:		0.386490
  validation accuracy:		90.22 %
Epoch 1132 of 2000 took 0.099s
  training loss:		0.140700
  validation loss:		0.388291
  validation accuracy:		90.87 %
Epoch 1133 of 2000 took 0.099s
  training loss:		0.138963
  validation loss:		0.404172
  validation accuracy:		90.33 %
Epoch 1134 of 2000 took 0.099s
  training loss:		0.142764
  validation loss:		0.410464
  validation accuracy:		88.59 %
Epoch 1135 of 2000 took 0.099s
  training loss:		0.144505
  validation loss:		0.399949
  validation accuracy:		89.89 %
Epoch 1136 of 2000 took 0.099s
  training loss:		0.150929
  validation loss:		0.409962
  validation accuracy:		89.13 %
Epoch 1137 of 2000 took 0.099s
  training loss:		0.139083
  validation loss:		0.411217
  validation accuracy:		88.91 %
Epoch 1138 of 2000 took 0.099s
  training loss:		0.140864
  validation loss:		0.404644
  validation accuracy:		89.57 %
Epoch 1139 of 2000 took 0.099s
  training loss:		0.140480
  validation loss:		0.389936
  validation accuracy:		90.33 %
Epoch 1140 of 2000 took 0.099s
  training loss:		0.146681
  validation loss:		0.393523
  validation accuracy:		89.57 %
Epoch 1141 of 2000 took 0.099s
  training loss:		0.144838
  validation loss:		0.396096
  validation accuracy:		90.33 %
Epoch 1142 of 2000 took 0.099s
  training loss:		0.146823
  validation loss:		0.392988
  validation accuracy:		90.00 %
Epoch 1143 of 2000 took 0.099s
  training loss:		0.137348
  validation loss:		0.396287
  validation accuracy:		89.46 %
Epoch 1144 of 2000 took 0.099s
  training loss:		0.152979
  validation loss:		0.396589
  validation accuracy:		90.54 %
Epoch 1145 of 2000 took 0.099s
  training loss:		0.144943
  validation loss:		0.396775
  validation accuracy:		88.91 %
Epoch 1146 of 2000 took 0.099s
  training loss:		0.138420
  validation loss:		0.391452
  validation accuracy:		89.67 %
Epoch 1147 of 2000 took 0.099s
  training loss:		0.139306
  validation loss:		0.394919
  validation accuracy:		89.24 %
Epoch 1148 of 2000 took 0.099s
  training loss:		0.136333
  validation loss:		0.389633
  validation accuracy:		90.54 %
Epoch 1149 of 2000 took 0.099s
  training loss:		0.140973
  validation loss:		0.395942
  validation accuracy:		90.22 %
Epoch 1150 of 2000 took 0.099s
  training loss:		0.147575
  validation loss:		0.393106
  validation accuracy:		89.46 %
Epoch 1151 of 2000 took 0.099s
  training loss:		0.146379
  validation loss:		0.386854
  validation accuracy:		90.00 %
Epoch 1152 of 2000 took 0.099s
  training loss:		0.150424
  validation loss:		0.385056
  validation accuracy:		90.22 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.144141
  validation loss:		0.395490
  validation accuracy:		90.00 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.139295
  validation loss:		0.394803
  validation accuracy:		89.35 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.141317
  validation loss:		0.392370
  validation accuracy:		90.11 %
Epoch 1156 of 2000 took 0.096s
  training loss:		0.138093
  validation loss:		0.418732
  validation accuracy:		90.00 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.149386
  validation loss:		0.383225
  validation accuracy:		89.89 %
Epoch 1158 of 2000 took 0.096s
  training loss:		0.140614
  validation loss:		0.396918
  validation accuracy:		90.33 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.147445
  validation loss:		0.412834
  validation accuracy:		88.48 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.137248
  validation loss:		0.406418
  validation accuracy:		89.78 %
Epoch 1161 of 2000 took 0.096s
  training loss:		0.144191
  validation loss:		0.403537
  validation accuracy:		90.11 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.139988
  validation loss:		0.435097
  validation accuracy:		88.80 %
Epoch 1163 of 2000 took 0.096s
  training loss:		0.149672
  validation loss:		0.393348
  validation accuracy:		89.67 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.142906
  validation loss:		0.388587
  validation accuracy:		89.67 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.143108
  validation loss:		0.389413
  validation accuracy:		90.54 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.140314
  validation loss:		0.404173
  validation accuracy:		89.78 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.139916
  validation loss:		0.404302
  validation accuracy:		90.11 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.139098
  validation loss:		0.394204
  validation accuracy:		90.54 %
Epoch 1169 of 2000 took 0.096s
  training loss:		0.140725
  validation loss:		0.408951
  validation accuracy:		89.02 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.145610
  validation loss:		0.393156
  validation accuracy:		89.46 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.146973
  validation loss:		0.410144
  validation accuracy:		89.67 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.140136
  validation loss:		0.401734
  validation accuracy:		90.22 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.135610
  validation loss:		0.414193
  validation accuracy:		88.48 %
Epoch 1174 of 2000 took 0.096s
  training loss:		0.143354
  validation loss:		0.397289
  validation accuracy:		89.46 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.132786
  validation loss:		0.395780
  validation accuracy:		89.67 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.145356
  validation loss:		0.410668
  validation accuracy:		89.46 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.145333
  validation loss:		0.386690
  validation accuracy:		89.78 %
Epoch 1178 of 2000 took 0.098s
  training loss:		0.148431
  validation loss:		0.406125
  validation accuracy:		89.02 %
Epoch 1179 of 2000 took 0.099s
  training loss:		0.137950
  validation loss:		0.394434
  validation accuracy:		90.11 %
Epoch 1180 of 2000 took 0.099s
  training loss:		0.143531
  validation loss:		0.417406
  validation accuracy:		89.67 %
Epoch 1181 of 2000 took 0.099s
  training loss:		0.147423
  validation loss:		0.415996
  validation accuracy:		88.70 %
Epoch 1182 of 2000 took 0.099s
  training loss:		0.142367
  validation loss:		0.397871
  validation accuracy:		89.35 %
Epoch 1183 of 2000 took 0.099s
  training loss:		0.136098
  validation loss:		0.403552
  validation accuracy:		89.24 %
Epoch 1184 of 2000 took 0.099s
  training loss:		0.137821
  validation loss:		0.392098
  validation accuracy:		90.22 %
Epoch 1185 of 2000 took 0.099s
  training loss:		0.148582
  validation loss:		0.422181
  validation accuracy:		89.13 %
Epoch 1186 of 2000 took 0.099s
  training loss:		0.139894
  validation loss:		0.419006
  validation accuracy:		88.91 %
Epoch 1187 of 2000 took 0.099s
  training loss:		0.135831
  validation loss:		0.397911
  validation accuracy:		89.89 %
Epoch 1188 of 2000 took 0.099s
  training loss:		0.140733
  validation loss:		0.455284
  validation accuracy:		87.72 %
Epoch 1189 of 2000 took 0.099s
  training loss:		0.149459
  validation loss:		0.394600
  validation accuracy:		89.13 %
Epoch 1190 of 2000 took 0.099s
  training loss:		0.141335
  validation loss:		0.396722
  validation accuracy:		89.57 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.140015
  validation loss:		0.398822
  validation accuracy:		90.33 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.142003
  validation loss:		0.412956
  validation accuracy:		88.70 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.149125
  validation loss:		0.399756
  validation accuracy:		89.24 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.131820
  validation loss:		0.413461
  validation accuracy:		89.67 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.139498
  validation loss:		0.415678
  validation accuracy:		88.91 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.132263
  validation loss:		0.393665
  validation accuracy:		89.57 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.142854
  validation loss:		0.404445
  validation accuracy:		89.35 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.138630
  validation loss:		0.411547
  validation accuracy:		89.78 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.144260
  validation loss:		0.410155
  validation accuracy:		90.22 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.138092
  validation loss:		0.405364
  validation accuracy:		89.46 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.144195
  validation loss:		0.394994
  validation accuracy:		89.57 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.138928
  validation loss:		0.391691
  validation accuracy:		90.00 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.133952
  validation loss:		0.390993
  validation accuracy:		89.89 %
Epoch 1204 of 2000 took 0.096s
  training loss:		0.140603
  validation loss:		0.407476
  validation accuracy:		90.22 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.143798
  validation loss:		0.422715
  validation accuracy:		89.13 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.139914
  validation loss:		0.389850
  validation accuracy:		90.00 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.141798
  validation loss:		0.404285
  validation accuracy:		89.57 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.149174
  validation loss:		0.405166
  validation accuracy:		89.13 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.133350
  validation loss:		0.396935
  validation accuracy:		90.00 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.137110
  validation loss:		0.392093
  validation accuracy:		89.67 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.137366
  validation loss:		0.393729
  validation accuracy:		89.57 %
Epoch 1212 of 2000 took 0.096s
  training loss:		0.142044
  validation loss:		0.418048
  validation accuracy:		88.48 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.143111
  validation loss:		0.402519
  validation accuracy:		89.57 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.139346
  validation loss:		0.400182
  validation accuracy:		89.35 %
Epoch 1215 of 2000 took 0.096s
  training loss:		0.136129
  validation loss:		0.404093
  validation accuracy:		89.67 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.142233
  validation loss:		0.462296
  validation accuracy:		87.72 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.146530
  validation loss:		0.401661
  validation accuracy:		90.00 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.139150
  validation loss:		0.422653
  validation accuracy:		89.35 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.140741
  validation loss:		0.401167
  validation accuracy:		89.78 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.137736
  validation loss:		0.404054
  validation accuracy:		89.13 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.137874
  validation loss:		0.399919
  validation accuracy:		89.78 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.140276
  validation loss:		0.402276
  validation accuracy:		90.22 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.133158
  validation loss:		0.418232
  validation accuracy:		89.78 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.145130
  validation loss:		0.414193
  validation accuracy:		89.13 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.137783
  validation loss:		0.398772
  validation accuracy:		89.67 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.138392
  validation loss:		0.419356
  validation accuracy:		88.80 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.136303
  validation loss:		0.397514
  validation accuracy:		90.00 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.142192
  validation loss:		0.425614
  validation accuracy:		89.57 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.153484
  validation loss:		0.403918
  validation accuracy:		89.46 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.136667
  validation loss:		0.416901
  validation accuracy:		88.70 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.129035
  validation loss:		0.397503
  validation accuracy:		89.13 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.137647
  validation loss:		0.406763
  validation accuracy:		89.89 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.139717
  validation loss:		0.418748
  validation accuracy:		89.13 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.142165
  validation loss:		0.402178
  validation accuracy:		89.46 %
Epoch 1235 of 2000 took 0.096s
  training loss:		0.140532
  validation loss:		0.405900
  validation accuracy:		90.11 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.141159
  validation loss:		0.397471
  validation accuracy:		89.13 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.147839
  validation loss:		0.397161
  validation accuracy:		90.43 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.136075
  validation loss:		0.400595
  validation accuracy:		90.11 %
Epoch 1239 of 2000 took 0.099s
  training loss:		0.134243
  validation loss:		0.400076
  validation accuracy:		89.57 %
Epoch 1240 of 2000 took 0.098s
  training loss:		0.137530
  validation loss:		0.410794
  validation accuracy:		90.11 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.148258
  validation loss:		0.396307
  validation accuracy:		89.67 %
Epoch 1242 of 2000 took 0.099s
  training loss:		0.134383
  validation loss:		0.405410
  validation accuracy:		89.46 %
Epoch 1243 of 2000 took 0.099s
  training loss:		0.141307
  validation loss:		0.408427
  validation accuracy:		89.46 %
Epoch 1244 of 2000 took 0.100s
  training loss:		0.133885
  validation loss:		0.390852
  validation accuracy:		89.78 %
Epoch 1245 of 2000 took 0.099s
  training loss:		0.137826
  validation loss:		0.401359
  validation accuracy:		90.11 %
Epoch 1246 of 2000 took 0.098s
  training loss:		0.135109
  validation loss:		0.396243
  validation accuracy:		90.22 %
Epoch 1247 of 2000 took 0.099s
  training loss:		0.141679
  validation loss:		0.403106
  validation accuracy:		89.89 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.139396
  validation loss:		0.398937
  validation accuracy:		89.89 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.142288
  validation loss:		0.394117
  validation accuracy:		89.24 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.137177
  validation loss:		0.421326
  validation accuracy:		89.24 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.141810
  validation loss:		0.411893
  validation accuracy:		89.89 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.131716
  validation loss:		0.405158
  validation accuracy:		89.89 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.135039
  validation loss:		0.414235
  validation accuracy:		90.65 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.142859
  validation loss:		0.438282
  validation accuracy:		87.93 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.137757
  validation loss:		0.426720
  validation accuracy:		89.67 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.137544
  validation loss:		0.408272
  validation accuracy:		89.24 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.138463
  validation loss:		0.405495
  validation accuracy:		89.89 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.132261
  validation loss:		0.409227
  validation accuracy:		89.35 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.137489
  validation loss:		0.399050
  validation accuracy:		89.89 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.137427
  validation loss:		0.404193
  validation accuracy:		90.11 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.139810
  validation loss:		0.407536
  validation accuracy:		90.00 %
Epoch 1262 of 2000 took 0.096s
  training loss:		0.137988
  validation loss:		0.432643
  validation accuracy:		88.59 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.146953
  validation loss:		0.399550
  validation accuracy:		89.24 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.137871
  validation loss:		0.402126
  validation accuracy:		89.57 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.134249
  validation loss:		0.404150
  validation accuracy:		89.24 %
Epoch 1266 of 2000 took 0.096s
  training loss:		0.137296
  validation loss:		0.413667
  validation accuracy:		89.13 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.140287
  validation loss:		0.415991
  validation accuracy:		88.91 %
Epoch 1268 of 2000 took 0.096s
  training loss:		0.136984
  validation loss:		0.407556
  validation accuracy:		89.46 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.139039
  validation loss:		0.405734
  validation accuracy:		89.89 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.145522
  validation loss:		0.408003
  validation accuracy:		89.46 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.133471
  validation loss:		0.436478
  validation accuracy:		88.04 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.135338
  validation loss:		0.418885
  validation accuracy:		90.11 %
Epoch 1273 of 2000 took 0.096s
  training loss:		0.144491
  validation loss:		0.415252
  validation accuracy:		89.78 %
Epoch 1274 of 2000 took 0.096s
  training loss:		0.131325
  validation loss:		0.414218
  validation accuracy:		88.91 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.140004
  validation loss:		0.411386
  validation accuracy:		90.00 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.139136
  validation loss:		0.402504
  validation accuracy:		89.46 %
Epoch 1277 of 2000 took 0.096s
  training loss:		0.135112
  validation loss:		0.432771
  validation accuracy:		88.80 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.140452
  validation loss:		0.408753
  validation accuracy:		89.57 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.147114
  validation loss:		0.399891
  validation accuracy:		89.78 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.142453
  validation loss:		0.422103
  validation accuracy:		89.89 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.138147
  validation loss:		0.443631
  validation accuracy:		88.70 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.133051
  validation loss:		0.399715
  validation accuracy:		90.33 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.136750
  validation loss:		0.403377
  validation accuracy:		89.78 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.134507
  validation loss:		0.409722
  validation accuracy:		89.89 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.135646
  validation loss:		0.403065
  validation accuracy:		89.78 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.135533
  validation loss:		0.417814
  validation accuracy:		90.00 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.142741
  validation loss:		0.395970
  validation accuracy:		89.46 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.133688
  validation loss:		0.405318
  validation accuracy:		89.89 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.133782
  validation loss:		0.403265
  validation accuracy:		89.78 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.135650
  validation loss:		0.411926
  validation accuracy:		89.46 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.140595
  validation loss:		0.394664
  validation accuracy:		89.46 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.134822
  validation loss:		0.396874
  validation accuracy:		90.00 %
Epoch 1293 of 2000 took 0.096s
  training loss:		0.137009
  validation loss:		0.397203
  validation accuracy:		89.89 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.130092
  validation loss:		0.419635
  validation accuracy:		89.35 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.135932
  validation loss:		0.405936
  validation accuracy:		90.33 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.143012
  validation loss:		0.414616
  validation accuracy:		89.57 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.134884
  validation loss:		0.404737
  validation accuracy:		89.78 %
Epoch 1298 of 2000 took 0.100s
  training loss:		0.138411
  validation loss:		0.404796
  validation accuracy:		89.89 %
Epoch 1299 of 2000 took 0.102s
  training loss:		0.137459
  validation loss:		0.397421
  validation accuracy:		89.13 %
Epoch 1300 of 2000 took 0.102s
  training loss:		0.134694
  validation loss:		0.405019
  validation accuracy:		89.57 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.137388
  validation loss:		0.398694
  validation accuracy:		90.00 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.134568
  validation loss:		0.410859
  validation accuracy:		89.57 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.127500
  validation loss:		0.432056
  validation accuracy:		89.57 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.136227
  validation loss:		0.423808
  validation accuracy:		89.02 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.141714
  validation loss:		0.413482
  validation accuracy:		89.57 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.141437
  validation loss:		0.406016
  validation accuracy:		89.67 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.134921
  validation loss:		0.413569
  validation accuracy:		89.89 %
Epoch 1308 of 2000 took 0.096s
  training loss:		0.132323
  validation loss:		0.402654
  validation accuracy:		89.67 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.136854
  validation loss:		0.400850
  validation accuracy:		90.00 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.140856
  validation loss:		0.466752
  validation accuracy:		87.83 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.131789
  validation loss:		0.420174
  validation accuracy:		89.89 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.132430
  validation loss:		0.404585
  validation accuracy:		89.78 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.134971
  validation loss:		0.401111
  validation accuracy:		89.89 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.129765
  validation loss:		0.434461
  validation accuracy:		89.78 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.137189
  validation loss:		0.418225
  validation accuracy:		89.57 %
Epoch 1316 of 2000 took 0.096s
  training loss:		0.140153
  validation loss:		0.410448
  validation accuracy:		90.22 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.143579
  validation loss:		0.408178
  validation accuracy:		88.80 %
Epoch 1318 of 2000 took 0.096s
  training loss:		0.130365
  validation loss:		0.422014
  validation accuracy:		89.67 %
Epoch 1319 of 2000 took 0.096s
  training loss:		0.131527
  validation loss:		0.414527
  validation accuracy:		89.13 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.133890
  validation loss:		0.407208
  validation accuracy:		89.67 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.134251
  validation loss:		0.415965
  validation accuracy:		90.33 %
Epoch 1322 of 2000 took 0.096s
  training loss:		0.139244
  validation loss:		0.424545
  validation accuracy:		88.48 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.135438
  validation loss:		0.407487
  validation accuracy:		90.00 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.140525
  validation loss:		0.426661
  validation accuracy:		88.48 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.135284
  validation loss:		0.421689
  validation accuracy:		89.67 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.133537
  validation loss:		0.401680
  validation accuracy:		90.22 %
Epoch 1327 of 2000 took 0.097s
  training loss:		0.130571
  validation loss:		0.411540
  validation accuracy:		90.22 %
Epoch 1328 of 2000 took 0.096s
  training loss:		0.131821
  validation loss:		0.412851
  validation accuracy:		90.00 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.129552
  validation loss:		0.407297
  validation accuracy:		89.35 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.131325
  validation loss:		0.425158
  validation accuracy:		88.70 %
Epoch 1331 of 2000 took 0.096s
  training loss:		0.138595
  validation loss:		0.404233
  validation accuracy:		89.67 %
Epoch 1332 of 2000 took 0.096s
  training loss:		0.130660
  validation loss:		0.475908
  validation accuracy:		87.61 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.134533
  validation loss:		0.409124
  validation accuracy:		89.46 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.128345
  validation loss:		0.414909
  validation accuracy:		89.89 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.133180
  validation loss:		0.424698
  validation accuracy:		89.57 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.126903
  validation loss:		0.420287
  validation accuracy:		89.46 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.135209
  validation loss:		0.436124
  validation accuracy:		88.91 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.134762
  validation loss:		0.431212
  validation accuracy:		90.00 %
Epoch 1339 of 2000 took 0.096s
  training loss:		0.136870
  validation loss:		0.413824
  validation accuracy:		89.46 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.132145
  validation loss:		0.434320
  validation accuracy:		89.78 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.134946
  validation loss:		0.428339
  validation accuracy:		90.00 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.135558
  validation loss:		0.411149
  validation accuracy:		90.33 %
Epoch 1343 of 2000 took 0.096s
  training loss:		0.133017
  validation loss:		0.423141
  validation accuracy:		89.35 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.128112
  validation loss:		0.412023
  validation accuracy:		90.00 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.129128
  validation loss:		0.403488
  validation accuracy:		89.46 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.134941
  validation loss:		0.460573
  validation accuracy:		88.04 %
Epoch 1347 of 2000 took 0.096s
  training loss:		0.139167
  validation loss:		0.416658
  validation accuracy:		89.89 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.138320
  validation loss:		0.419197
  validation accuracy:		90.11 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.132037
  validation loss:		0.436910
  validation accuracy:		89.46 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.132531
  validation loss:		0.421449
  validation accuracy:		88.91 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.131833
  validation loss:		0.427196
  validation accuracy:		89.46 %
Epoch 1352 of 2000 took 0.096s
  training loss:		0.134067
  validation loss:		0.422854
  validation accuracy:		89.24 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.140385
  validation loss:		0.420272
  validation accuracy:		89.02 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.130297
  validation loss:		0.407960
  validation accuracy:		90.22 %
Epoch 1355 of 2000 took 0.096s
  training loss:		0.133945
  validation loss:		0.426736
  validation accuracy:		89.57 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.134764
  validation loss:		0.405693
  validation accuracy:		89.78 %
Epoch 1357 of 2000 took 0.096s
  training loss:		0.131876
  validation loss:		0.405674
  validation accuracy:		90.11 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.136465
  validation loss:		0.424911
  validation accuracy:		90.11 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.133447
  validation loss:		0.424220
  validation accuracy:		88.91 %
Epoch 1360 of 2000 took 0.096s
  training loss:		0.136883
  validation loss:		0.438738
  validation accuracy:		89.13 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.132625
  validation loss:		0.399177
  validation accuracy:		89.46 %
Epoch 1362 of 2000 took 0.096s
  training loss:		0.127417
  validation loss:		0.413446
  validation accuracy:		90.33 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.123720
  validation loss:		0.418692
  validation accuracy:		89.46 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.129704
  validation loss:		0.405802
  validation accuracy:		89.67 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.134838
  validation loss:		0.410808
  validation accuracy:		90.11 %
Epoch 1366 of 2000 took 0.096s
  training loss:		0.138941
  validation loss:		0.420184
  validation accuracy:		89.57 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.132720
  validation loss:		0.404635
  validation accuracy:		89.46 %
Epoch 1368 of 2000 took 0.096s
  training loss:		0.138086
  validation loss:		0.411831
  validation accuracy:		90.00 %
Epoch 1369 of 2000 took 0.096s
  training loss:		0.126052
  validation loss:		0.424787
  validation accuracy:		90.11 %
Epoch 1370 of 2000 took 0.096s
  training loss:		0.132495
  validation loss:		0.427337
  validation accuracy:		89.78 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.131907
  validation loss:		0.407777
  validation accuracy:		89.78 %
Epoch 1372 of 2000 took 0.098s
  training loss:		0.130924
  validation loss:		0.407541
  validation accuracy:		89.35 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.132333
  validation loss:		0.418511
  validation accuracy:		90.22 %
Epoch 1374 of 2000 took 0.096s
  training loss:		0.134566
  validation loss:		0.421479
  validation accuracy:		89.67 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.136901
  validation loss:		0.429973
  validation accuracy:		89.24 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.131117
  validation loss:		0.413807
  validation accuracy:		89.24 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.133947
  validation loss:		0.413354
  validation accuracy:		89.35 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.133480
  validation loss:		0.411022
  validation accuracy:		89.78 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.128880
  validation loss:		0.422939
  validation accuracy:		89.13 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.125876
  validation loss:		0.411324
  validation accuracy:		89.24 %
Epoch 1381 of 2000 took 0.099s
  training loss:		0.129733
  validation loss:		0.417539
  validation accuracy:		89.89 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.129214
  validation loss:		0.427660
  validation accuracy:		90.11 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.142337
  validation loss:		0.415891
  validation accuracy:		89.67 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.132245
  validation loss:		0.408690
  validation accuracy:		89.46 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.126801
  validation loss:		0.420739
  validation accuracy:		89.35 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.132911
  validation loss:		0.419140
  validation accuracy:		89.67 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.131797
  validation loss:		0.426847
  validation accuracy:		89.24 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.135057
  validation loss:		0.418189
  validation accuracy:		89.35 %
Epoch 1389 of 2000 took 0.097s
  training loss:		0.124330
  validation loss:		0.421268
  validation accuracy:		89.89 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.129811
  validation loss:		0.409197
  validation accuracy:		89.78 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.129812
  validation loss:		0.442343
  validation accuracy:		88.15 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.136339
  validation loss:		0.444424
  validation accuracy:		89.78 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.133145
  validation loss:		0.411210
  validation accuracy:		89.89 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.125799
  validation loss:		0.430448
  validation accuracy:		89.46 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.132339
  validation loss:		0.414991
  validation accuracy:		89.67 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.123705
  validation loss:		0.417955
  validation accuracy:		90.11 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.129430
  validation loss:		0.414858
  validation accuracy:		89.46 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.127868
  validation loss:		0.407844
  validation accuracy:		89.89 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.127442
  validation loss:		0.433627
  validation accuracy:		88.59 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.136594
  validation loss:		0.408024
  validation accuracy:		89.13 %
Epoch 1401 of 2000 took 0.096s
  training loss:		0.135185
  validation loss:		0.417583
  validation accuracy:		89.78 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.133654
  validation loss:		0.410780
  validation accuracy:		89.67 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.131328
  validation loss:		0.418040
  validation accuracy:		89.67 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.133638
  validation loss:		0.419526
  validation accuracy:		89.46 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.126327
  validation loss:		0.413721
  validation accuracy:		89.89 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.134945
  validation loss:		0.413755
  validation accuracy:		89.89 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.132842
  validation loss:		0.417125
  validation accuracy:		89.35 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.126764
  validation loss:		0.409384
  validation accuracy:		90.00 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.131501
  validation loss:		0.417054
  validation accuracy:		89.13 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.130428
  validation loss:		0.412331
  validation accuracy:		89.78 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.125440
  validation loss:		0.431262
  validation accuracy:		89.24 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.135353
  validation loss:		0.420438
  validation accuracy:		89.57 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.127496
  validation loss:		0.455739
  validation accuracy:		88.80 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.134544
  validation loss:		0.405091
  validation accuracy:		89.89 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.134736
  validation loss:		0.430401
  validation accuracy:		89.78 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.131017
  validation loss:		0.427321
  validation accuracy:		90.22 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.133017
  validation loss:		0.417758
  validation accuracy:		88.80 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.128666
  validation loss:		0.411685
  validation accuracy:		89.67 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.129608
  validation loss:		0.416377
  validation accuracy:		89.78 %
Epoch 1420 of 2000 took 0.096s
  training loss:		0.133959
  validation loss:		0.410086
  validation accuracy:		88.80 %
Epoch 1421 of 2000 took 0.097s
  training loss:		0.129844
  validation loss:		0.410737
  validation accuracy:		89.35 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.127967
  validation loss:		0.422711
  validation accuracy:		90.00 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.134568
  validation loss:		0.443357
  validation accuracy:		88.91 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.123896
  validation loss:		0.419064
  validation accuracy:		89.78 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.129111
  validation loss:		0.425517
  validation accuracy:		89.67 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.130012
  validation loss:		0.414452
  validation accuracy:		89.46 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.127380
  validation loss:		0.412811
  validation accuracy:		90.43 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.130024
  validation loss:		0.432168
  validation accuracy:		89.13 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.133297
  validation loss:		0.419480
  validation accuracy:		89.67 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.132230
  validation loss:		0.419036
  validation accuracy:		90.22 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.121521
  validation loss:		0.421794
  validation accuracy:		90.00 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.124900
  validation loss:		0.423602
  validation accuracy:		89.46 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.126964
  validation loss:		0.450717
  validation accuracy:		89.02 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.134444
  validation loss:		0.415565
  validation accuracy:		89.67 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.120468
  validation loss:		0.437834
  validation accuracy:		88.91 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.127884
  validation loss:		0.408827
  validation accuracy:		89.35 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.128693
  validation loss:		0.420584
  validation accuracy:		89.78 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.123336
  validation loss:		0.421724
  validation accuracy:		90.11 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.124555
  validation loss:		0.417669
  validation accuracy:		89.57 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.126917
  validation loss:		0.413280
  validation accuracy:		89.46 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.129082
  validation loss:		0.429043
  validation accuracy:		88.91 %
Epoch 1442 of 2000 took 0.096s
  training loss:		0.132551
  validation loss:		0.432916
  validation accuracy:		89.46 %
Epoch 1443 of 2000 took 0.096s
  training loss:		0.122777
  validation loss:		0.419377
  validation accuracy:		89.46 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.127982
  validation loss:		0.412650
  validation accuracy:		90.11 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.124745
  validation loss:		0.422784
  validation accuracy:		89.67 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.133481
  validation loss:		0.457265
  validation accuracy:		88.37 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.129709
  validation loss:		0.417332
  validation accuracy:		90.00 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.125998
  validation loss:		0.411529
  validation accuracy:		89.89 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.124604
  validation loss:		0.426552
  validation accuracy:		89.24 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.131115
  validation loss:		0.412550
  validation accuracy:		90.22 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.127745
  validation loss:		0.413740
  validation accuracy:		90.22 %
Epoch 1452 of 2000 took 0.097s
  training loss:		0.121312
  validation loss:		0.417582
  validation accuracy:		89.67 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.130412
  validation loss:		0.417193
  validation accuracy:		89.67 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.131522
  validation loss:		0.441287
  validation accuracy:		88.80 %
Epoch 1455 of 2000 took 0.098s
  training loss:		0.119885
  validation loss:		0.427719
  validation accuracy:		89.89 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.126204
  validation loss:		0.425267
  validation accuracy:		89.46 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.121824
  validation loss:		0.428478
  validation accuracy:		89.13 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.127194
  validation loss:		0.430835
  validation accuracy:		89.24 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.128794
  validation loss:		0.418197
  validation accuracy:		88.91 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.125251
  validation loss:		0.423034
  validation accuracy:		90.00 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.127673
  validation loss:		0.417453
  validation accuracy:		89.89 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.124177
  validation loss:		0.444838
  validation accuracy:		89.57 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.123547
  validation loss:		0.415073
  validation accuracy:		89.46 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.125994
  validation loss:		0.412539
  validation accuracy:		89.24 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.125335
  validation loss:		0.431497
  validation accuracy:		89.89 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.125579
  validation loss:		0.412318
  validation accuracy:		89.67 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.130863
  validation loss:		0.419404
  validation accuracy:		90.11 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.122884
  validation loss:		0.426912
  validation accuracy:		89.02 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.122809
  validation loss:		0.425066
  validation accuracy:		89.57 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.121537
  validation loss:		0.417574
  validation accuracy:		89.57 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.122751
  validation loss:		0.428723
  validation accuracy:		90.00 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.121478
  validation loss:		0.420606
  validation accuracy:		90.22 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.127179
  validation loss:		0.417623
  validation accuracy:		89.78 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.128791
  validation loss:		0.429449
  validation accuracy:		89.46 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.123480
  validation loss:		0.421066
  validation accuracy:		89.78 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.127320
  validation loss:		0.426638
  validation accuracy:		89.46 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.118987
  validation loss:		0.433608
  validation accuracy:		89.46 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.126857
  validation loss:		0.418932
  validation accuracy:		89.35 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.119287
  validation loss:		0.419530
  validation accuracy:		90.00 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.119660
  validation loss:		0.414531
  validation accuracy:		89.67 %
Epoch 1481 of 2000 took 0.096s
  training loss:		0.120303
  validation loss:		0.445199
  validation accuracy:		89.02 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.121306
  validation loss:		0.425447
  validation accuracy:		89.89 %
Epoch 1483 of 2000 took 0.097s
  training loss:		0.120330
  validation loss:		0.427727
  validation accuracy:		90.33 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.120741
  validation loss:		0.432109
  validation accuracy:		89.57 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.126260
  validation loss:		0.439700
  validation accuracy:		89.46 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.116327
  validation loss:		0.423166
  validation accuracy:		88.91 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.119342
  validation loss:		0.424519
  validation accuracy:		90.33 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.121053
  validation loss:		0.426087
  validation accuracy:		89.35 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.114613
  validation loss:		0.423945
  validation accuracy:		89.78 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.122557
  validation loss:		0.424471
  validation accuracy:		89.46 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.118431
  validation loss:		0.419117
  validation accuracy:		89.78 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.125483
  validation loss:		0.420388
  validation accuracy:		89.24 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.119886
  validation loss:		0.419752
  validation accuracy:		89.46 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.120691
  validation loss:		0.426888
  validation accuracy:		89.57 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.127409
  validation loss:		0.431984
  validation accuracy:		89.46 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.126226
  validation loss:		0.428199
  validation accuracy:		90.11 %
Epoch 1497 of 2000 took 0.096s
  training loss:		0.115856
  validation loss:		0.423298
  validation accuracy:		89.67 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.118280
  validation loss:		0.425448
  validation accuracy:		89.24 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.121836
  validation loss:		0.470838
  validation accuracy:		88.59 %
Epoch 1500 of 2000 took 0.096s
  training loss:		0.130977
  validation loss:		0.430750
  validation accuracy:		89.89 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.117582
  validation loss:		0.416131
  validation accuracy:		89.46 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.121262
  validation loss:		0.433541
  validation accuracy:		89.89 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.122182
  validation loss:		0.451048
  validation accuracy:		89.13 %
Epoch 1504 of 2000 took 0.096s
  training loss:		0.119096
  validation loss:		0.432569
  validation accuracy:		89.35 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.130329
  validation loss:		0.424177
  validation accuracy:		89.57 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.126430
  validation loss:		0.434200
  validation accuracy:		89.67 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.118520
  validation loss:		0.431221
  validation accuracy:		89.67 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.118923
  validation loss:		0.438128
  validation accuracy:		89.24 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.122549
  validation loss:		0.414170
  validation accuracy:		89.78 %
Epoch 1510 of 2000 took 0.096s
  training loss:		0.119793
  validation loss:		0.417670
  validation accuracy:		89.35 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.122653
  validation loss:		0.426225
  validation accuracy:		89.78 %
Epoch 1512 of 2000 took 0.096s
  training loss:		0.123278
  validation loss:		0.414095
  validation accuracy:		89.35 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.123626
  validation loss:		0.420693
  validation accuracy:		89.89 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.115138
  validation loss:		0.453144
  validation accuracy:		89.13 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.120046
  validation loss:		0.431339
  validation accuracy:		90.11 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.122844
  validation loss:		0.433576
  validation accuracy:		90.33 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.118000
  validation loss:		0.421891
  validation accuracy:		89.67 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.114306
  validation loss:		0.438103
  validation accuracy:		89.89 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.126123
  validation loss:		0.430627
  validation accuracy:		89.24 %
Epoch 1520 of 2000 took 0.096s
  training loss:		0.110365
  validation loss:		0.416191
  validation accuracy:		89.78 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.121137
  validation loss:		0.431883
  validation accuracy:		89.35 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.113467
  validation loss:		0.440548
  validation accuracy:		89.67 %
Epoch 1523 of 2000 took 0.096s
  training loss:		0.121145
  validation loss:		0.423411
  validation accuracy:		90.22 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.119176
  validation loss:		0.422171
  validation accuracy:		89.35 %
Epoch 1525 of 2000 took 0.096s
  training loss:		0.119648
  validation loss:		0.420174
  validation accuracy:		89.57 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.128487
  validation loss:		0.429446
  validation accuracy:		89.78 %
Epoch 1527 of 2000 took 0.096s
  training loss:		0.118863
  validation loss:		0.429085
  validation accuracy:		89.46 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.115532
  validation loss:		0.416300
  validation accuracy:		90.00 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.117188
  validation loss:		0.444200
  validation accuracy:		89.89 %
Epoch 1530 of 2000 took 0.096s
  training loss:		0.111869
  validation loss:		0.431689
  validation accuracy:		89.78 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.114322
  validation loss:		0.449761
  validation accuracy:		88.91 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.120302
  validation loss:		0.422051
  validation accuracy:		89.24 %
Epoch 1533 of 2000 took 0.096s
  training loss:		0.121273
  validation loss:		0.427904
  validation accuracy:		89.46 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.111000
  validation loss:		0.450759
  validation accuracy:		88.91 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.118677
  validation loss:		0.423313
  validation accuracy:		89.89 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.112666
  validation loss:		0.423310
  validation accuracy:		89.67 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.123184
  validation loss:		0.435133
  validation accuracy:		89.13 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.120894
  validation loss:		0.450777
  validation accuracy:		89.89 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.116239
  validation loss:		0.439002
  validation accuracy:		89.02 %
Epoch 1540 of 2000 took 0.096s
  training loss:		0.121145
  validation loss:		0.429706
  validation accuracy:		89.35 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.113480
  validation loss:		0.424111
  validation accuracy:		90.11 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.111497
  validation loss:		0.437632
  validation accuracy:		89.13 %
Epoch 1543 of 2000 took 0.096s
  training loss:		0.114111
  validation loss:		0.435324
  validation accuracy:		89.78 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.117189
  validation loss:		0.449086
  validation accuracy:		89.13 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.118000
  validation loss:		0.439728
  validation accuracy:		89.24 %
Epoch 1546 of 2000 took 0.097s
  training loss:		0.114190
  validation loss:		0.427526
  validation accuracy:		89.35 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.107090
  validation loss:		0.425791
  validation accuracy:		89.46 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.106486
  validation loss:		0.432286
  validation accuracy:		89.24 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.117535
  validation loss:		0.435217
  validation accuracy:		89.57 %
Epoch 1550 of 2000 took 0.096s
  training loss:		0.113391
  validation loss:		0.442021
  validation accuracy:		89.24 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.117394
  validation loss:		0.435227
  validation accuracy:		89.24 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.112267
  validation loss:		0.435662
  validation accuracy:		89.57 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.108801
  validation loss:		0.443757
  validation accuracy:		89.46 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.113661
  validation loss:		0.429787
  validation accuracy:		89.35 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.115474
  validation loss:		0.432193
  validation accuracy:		89.78 %
Epoch 1556 of 2000 took 0.096s
  training loss:		0.113454
  validation loss:		0.426113
  validation accuracy:		89.67 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.117256
  validation loss:		0.432938
  validation accuracy:		89.35 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.114805
  validation loss:		0.429292
  validation accuracy:		90.00 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.113965
  validation loss:		0.442126
  validation accuracy:		89.24 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.114192
  validation loss:		0.439145
  validation accuracy:		89.57 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.116010
  validation loss:		0.433179
  validation accuracy:		89.57 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.110712
  validation loss:		0.427464
  validation accuracy:		89.89 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.108688
  validation loss:		0.425514
  validation accuracy:		89.46 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.104720
  validation loss:		0.439344
  validation accuracy:		89.67 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.110204
  validation loss:		0.428157
  validation accuracy:		89.13 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.114766
  validation loss:		0.423473
  validation accuracy:		89.35 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.114143
  validation loss:		0.428984
  validation accuracy:		89.78 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.115035
  validation loss:		0.429325
  validation accuracy:		89.78 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.108627
  validation loss:		0.441452
  validation accuracy:		89.46 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.115223
  validation loss:		0.451387
  validation accuracy:		89.13 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.113002
  validation loss:		0.441645
  validation accuracy:		89.24 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.108797
  validation loss:		0.457648
  validation accuracy:		88.91 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.116562
  validation loss:		0.431816
  validation accuracy:		90.11 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.115600
  validation loss:		0.437384
  validation accuracy:		89.46 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.106766
  validation loss:		0.435421
  validation accuracy:		89.24 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.112129
  validation loss:		0.445679
  validation accuracy:		89.35 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.106778
  validation loss:		0.443852
  validation accuracy:		89.78 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.113928
  validation loss:		0.437933
  validation accuracy:		89.57 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.111009
  validation loss:		0.441273
  validation accuracy:		89.67 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.112463
  validation loss:		0.434051
  validation accuracy:		89.46 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.105668
  validation loss:		0.440513
  validation accuracy:		89.89 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.108168
  validation loss:		0.452261
  validation accuracy:		89.13 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.111753
  validation loss:		0.436721
  validation accuracy:		89.78 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.116686
  validation loss:		0.427434
  validation accuracy:		89.78 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.110974
  validation loss:		0.447859
  validation accuracy:		89.78 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.105137
  validation loss:		0.447999
  validation accuracy:		89.67 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.111293
  validation loss:		0.449581
  validation accuracy:		89.35 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.107311
  validation loss:		0.431831
  validation accuracy:		89.57 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.108515
  validation loss:		0.447398
  validation accuracy:		89.24 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.110680
  validation loss:		0.473354
  validation accuracy:		89.13 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.110722
  validation loss:		0.443582
  validation accuracy:		89.35 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.107834
  validation loss:		0.433796
  validation accuracy:		89.57 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.110166
  validation loss:		0.429647
  validation accuracy:		89.67 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.116911
  validation loss:		0.436959
  validation accuracy:		89.46 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.109641
  validation loss:		0.433073
  validation accuracy:		89.35 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.107584
  validation loss:		0.454685
  validation accuracy:		89.46 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.104725
  validation loss:		0.430588
  validation accuracy:		90.11 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.111826
  validation loss:		0.451538
  validation accuracy:		89.67 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.107701
  validation loss:		0.440160
  validation accuracy:		89.35 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.106294
  validation loss:		0.434158
  validation accuracy:		89.35 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.103502
  validation loss:		0.434877
  validation accuracy:		89.46 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.104843
  validation loss:		0.458040
  validation accuracy:		89.46 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.110216
  validation loss:		0.469631
  validation accuracy:		88.59 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.110132
  validation loss:		0.441726
  validation accuracy:		89.67 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.106330
  validation loss:		0.467294
  validation accuracy:		89.02 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.109357
  validation loss:		0.443325
  validation accuracy:		89.57 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.109867
  validation loss:		0.451941
  validation accuracy:		89.35 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.111035
  validation loss:		0.441037
  validation accuracy:		89.46 %
Epoch 1609 of 2000 took 0.098s
  training loss:		0.107295
  validation loss:		0.460737
  validation accuracy:		89.24 %
Epoch 1610 of 2000 took 0.099s
  training loss:		0.104348
  validation loss:		0.456244
  validation accuracy:		90.00 %
Epoch 1611 of 2000 took 0.102s
  training loss:		0.105771
  validation loss:		0.454035
  validation accuracy:		89.13 %
Epoch 1612 of 2000 took 0.102s
  training loss:		0.108874
  validation loss:		0.447154
  validation accuracy:		89.67 %
Epoch 1613 of 2000 took 0.102s
  training loss:		0.105973
  validation loss:		0.435752
  validation accuracy:		90.11 %
Epoch 1614 of 2000 took 0.102s
  training loss:		0.104629
  validation loss:		0.443622
  validation accuracy:		89.35 %
Epoch 1615 of 2000 took 0.102s
  training loss:		0.109673
  validation loss:		0.446471
  validation accuracy:		89.46 %
Epoch 1616 of 2000 took 0.102s
  training loss:		0.110040
  validation loss:		0.463210
  validation accuracy:		89.02 %
Epoch 1617 of 2000 took 0.102s
  training loss:		0.103395
  validation loss:		0.439600
  validation accuracy:		89.35 %
Epoch 1618 of 2000 took 0.102s
  training loss:		0.110082
  validation loss:		0.460696
  validation accuracy:		89.13 %
Epoch 1619 of 2000 took 0.102s
  training loss:		0.103210
  validation loss:		0.478078
  validation accuracy:		89.02 %
Epoch 1620 of 2000 took 0.102s
  training loss:		0.105676
  validation loss:		0.454235
  validation accuracy:		89.13 %
Epoch 1621 of 2000 took 0.102s
  training loss:		0.101083
  validation loss:		0.466712
  validation accuracy:		88.80 %
Epoch 1622 of 2000 took 0.102s
  training loss:		0.109346
  validation loss:		0.466265
  validation accuracy:		88.59 %
Epoch 1623 of 2000 took 0.102s
  training loss:		0.103092
  validation loss:		0.462317
  validation accuracy:		89.35 %
Epoch 1624 of 2000 took 0.102s
  training loss:		0.104697
  validation loss:		0.449048
  validation accuracy:		90.11 %
Epoch 1625 of 2000 took 0.102s
  training loss:		0.109250
  validation loss:		0.472721
  validation accuracy:		88.91 %
Epoch 1626 of 2000 took 0.102s
  training loss:		0.107396
  validation loss:		0.475999
  validation accuracy:		88.80 %
Epoch 1627 of 2000 took 0.102s
  training loss:		0.110327
  validation loss:		0.453352
  validation accuracy:		89.78 %
Epoch 1628 of 2000 took 0.102s
  training loss:		0.110953
  validation loss:		0.441078
  validation accuracy:		89.46 %
Epoch 1629 of 2000 took 0.102s
  training loss:		0.102054
  validation loss:		0.450953
  validation accuracy:		89.57 %
Epoch 1630 of 2000 took 0.102s
  training loss:		0.104246
  validation loss:		0.463891
  validation accuracy:		89.13 %
Epoch 1631 of 2000 took 0.102s
  training loss:		0.105844
  validation loss:		0.453650
  validation accuracy:		89.24 %
Epoch 1632 of 2000 took 0.102s
  training loss:		0.102560
  validation loss:		0.481931
  validation accuracy:		89.46 %
Epoch 1633 of 2000 took 0.102s
  training loss:		0.113807
  validation loss:		0.450395
  validation accuracy:		89.35 %
Epoch 1634 of 2000 took 0.102s
  training loss:		0.104880
  validation loss:		0.461478
  validation accuracy:		89.24 %
Epoch 1635 of 2000 took 0.102s
  training loss:		0.096213
  validation loss:		0.448046
  validation accuracy:		89.02 %
Epoch 1636 of 2000 took 0.102s
  training loss:		0.106972
  validation loss:		0.460747
  validation accuracy:		89.57 %
Epoch 1637 of 2000 took 0.102s
  training loss:		0.103652
  validation loss:		0.464891
  validation accuracy:		89.24 %
Epoch 1638 of 2000 took 0.102s
  training loss:		0.104974
  validation loss:		0.447492
  validation accuracy:		89.89 %
Epoch 1639 of 2000 took 0.099s
  training loss:		0.100107
  validation loss:		0.453606
  validation accuracy:		89.24 %
Epoch 1640 of 2000 took 0.099s
  training loss:		0.105643
  validation loss:		0.470368
  validation accuracy:		89.13 %
Epoch 1641 of 2000 took 0.099s
  training loss:		0.109185
  validation loss:		0.448856
  validation accuracy:		89.78 %
Epoch 1642 of 2000 took 0.099s
  training loss:		0.100831
  validation loss:		0.450744
  validation accuracy:		89.46 %
Epoch 1643 of 2000 took 0.099s
  training loss:		0.098866
  validation loss:		0.455881
  validation accuracy:		89.24 %
Epoch 1644 of 2000 took 0.099s
  training loss:		0.100393
  validation loss:		0.443944
  validation accuracy:		89.78 %
Epoch 1645 of 2000 took 0.099s
  training loss:		0.099770
  validation loss:		0.454490
  validation accuracy:		89.78 %
Epoch 1646 of 2000 took 0.099s
  training loss:		0.102678
  validation loss:		0.487074
  validation accuracy:		88.59 %
Epoch 1647 of 2000 took 0.099s
  training loss:		0.102344
  validation loss:		0.448713
  validation accuracy:		89.78 %
Epoch 1648 of 2000 took 0.099s
  training loss:		0.102608
  validation loss:		0.454446
  validation accuracy:		89.35 %
Epoch 1649 of 2000 took 0.098s
  training loss:		0.101322
  validation loss:		0.483272
  validation accuracy:		89.02 %
Epoch 1650 of 2000 took 0.099s
  training loss:		0.105463
  validation loss:		0.441458
  validation accuracy:		89.67 %
Epoch 1651 of 2000 took 0.099s
  training loss:		0.102761
  validation loss:		0.468371
  validation accuracy:		90.22 %
Epoch 1652 of 2000 took 0.099s
  training loss:		0.101386
  validation loss:		0.452338
  validation accuracy:		89.24 %
Epoch 1653 of 2000 took 0.099s
  training loss:		0.094201
  validation loss:		0.451463
  validation accuracy:		90.00 %
Epoch 1654 of 2000 took 0.099s
  training loss:		0.098774
  validation loss:		0.458573
  validation accuracy:		89.57 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.097956
  validation loss:		0.466025
  validation accuracy:		89.57 %
Epoch 1656 of 2000 took 0.097s
  training loss:		0.103091
  validation loss:		0.452050
  validation accuracy:		89.78 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.104455
  validation loss:		0.465997
  validation accuracy:		89.35 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.101535
  validation loss:		0.449984
  validation accuracy:		89.67 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.099988
  validation loss:		0.467470
  validation accuracy:		89.02 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.103211
  validation loss:		0.459383
  validation accuracy:		89.89 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.100010
  validation loss:		0.470212
  validation accuracy:		89.46 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.100603
  validation loss:		0.445861
  validation accuracy:		90.00 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.100709
  validation loss:		0.486016
  validation accuracy:		89.13 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.100321
  validation loss:		0.469926
  validation accuracy:		89.67 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.098185
  validation loss:		0.466292
  validation accuracy:		89.35 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.100444
  validation loss:		0.458872
  validation accuracy:		89.67 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.099081
  validation loss:		0.489100
  validation accuracy:		89.13 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.100607
  validation loss:		0.468578
  validation accuracy:		89.46 %
Epoch 1669 of 2000 took 0.097s
  training loss:		0.100561
  validation loss:		0.466017
  validation accuracy:		89.24 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.097628
  validation loss:		0.464099
  validation accuracy:		89.57 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.101236
  validation loss:		0.458564
  validation accuracy:		89.57 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.101332
  validation loss:		0.467712
  validation accuracy:		89.24 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.092819
  validation loss:		0.468232
  validation accuracy:		89.57 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.100205
  validation loss:		0.479909
  validation accuracy:		89.24 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.106235
  validation loss:		0.460898
  validation accuracy:		89.46 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.103950
  validation loss:		0.464821
  validation accuracy:		90.00 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.096014
  validation loss:		0.452290
  validation accuracy:		89.67 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.096047
  validation loss:		0.466616
  validation accuracy:		90.00 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.100527
  validation loss:		0.461941
  validation accuracy:		90.11 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.105127
  validation loss:		0.467084
  validation accuracy:		89.46 %
Epoch 1681 of 2000 took 0.099s
  training loss:		0.095876
  validation loss:		0.490009
  validation accuracy:		89.13 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.099625
  validation loss:		0.475086
  validation accuracy:		89.67 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.097656
  validation loss:		0.477549
  validation accuracy:		89.13 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.093536
  validation loss:		0.472191
  validation accuracy:		90.00 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.094555
  validation loss:		0.465918
  validation accuracy:		89.57 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.095646
  validation loss:		0.480676
  validation accuracy:		89.46 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.096697
  validation loss:		0.508336
  validation accuracy:		89.24 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.101206
  validation loss:		0.468348
  validation accuracy:		89.89 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.099742
  validation loss:		0.467940
  validation accuracy:		89.57 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.093976
  validation loss:		0.478869
  validation accuracy:		89.13 %
Epoch 1691 of 2000 took 0.099s
  training loss:		0.089374
  validation loss:		0.459024
  validation accuracy:		90.00 %
Epoch 1692 of 2000 took 0.099s
  training loss:		0.091880
  validation loss:		0.470593
  validation accuracy:		89.46 %
Epoch 1693 of 2000 took 0.099s
  training loss:		0.093623
  validation loss:		0.472247
  validation accuracy:		89.57 %
Epoch 1694 of 2000 took 0.099s
  training loss:		0.095011
  validation loss:		0.475303
  validation accuracy:		89.35 %
Epoch 1695 of 2000 took 0.099s
  training loss:		0.100092
  validation loss:		0.472728
  validation accuracy:		89.24 %
Epoch 1696 of 2000 took 0.099s
  training loss:		0.098674
  validation loss:		0.490937
  validation accuracy:		88.80 %
Epoch 1697 of 2000 took 0.099s
  training loss:		0.092183
  validation loss:		0.485587
  validation accuracy:		89.13 %
Epoch 1698 of 2000 took 0.099s
  training loss:		0.095419
  validation loss:		0.486723
  validation accuracy:		89.46 %
Epoch 1699 of 2000 took 0.099s
  training loss:		0.099504
  validation loss:		0.479203
  validation accuracy:		90.00 %
Epoch 1700 of 2000 took 0.099s
  training loss:		0.095461
  validation loss:		0.468693
  validation accuracy:		89.67 %
Epoch 1701 of 2000 took 0.099s
  training loss:		0.094151
  validation loss:		0.459608
  validation accuracy:		89.78 %
Epoch 1702 of 2000 took 0.099s
  training loss:		0.091419
  validation loss:		0.487822
  validation accuracy:		89.02 %
Epoch 1703 of 2000 took 0.099s
  training loss:		0.096958
  validation loss:		0.505749
  validation accuracy:		89.46 %
Epoch 1704 of 2000 took 0.099s
  training loss:		0.096210
  validation loss:		0.475156
  validation accuracy:		89.35 %
Epoch 1705 of 2000 took 0.099s
  training loss:		0.093722
  validation loss:		0.481175
  validation accuracy:		89.57 %
Epoch 1706 of 2000 took 0.099s
  training loss:		0.095593
  validation loss:		0.466228
  validation accuracy:		90.00 %
Epoch 1707 of 2000 took 0.099s
  training loss:		0.101482
  validation loss:		0.474560
  validation accuracy:		89.24 %
Epoch 1708 of 2000 took 0.099s
  training loss:		0.090436
  validation loss:		0.479328
  validation accuracy:		90.00 %
Epoch 1709 of 2000 took 0.099s
  training loss:		0.087032
  validation loss:		0.464856
  validation accuracy:		89.57 %
Epoch 1710 of 2000 took 0.099s
  training loss:		0.098938
  validation loss:		0.535794
  validation accuracy:		88.80 %
Epoch 1711 of 2000 took 0.099s
  training loss:		0.094286
  validation loss:		0.466502
  validation accuracy:		90.00 %
Epoch 1712 of 2000 took 0.099s
  training loss:		0.099970
  validation loss:		0.472410
  validation accuracy:		89.57 %
Epoch 1713 of 2000 took 0.099s
  training loss:		0.094289
  validation loss:		0.483494
  validation accuracy:		89.67 %
Epoch 1714 of 2000 took 0.099s
  training loss:		0.093643
  validation loss:		0.472051
  validation accuracy:		89.24 %
Epoch 1715 of 2000 took 0.099s
  training loss:		0.089140
  validation loss:		0.469996
  validation accuracy:		89.46 %
Epoch 1716 of 2000 took 0.099s
  training loss:		0.089666
  validation loss:		0.490922
  validation accuracy:		89.02 %
Epoch 1717 of 2000 took 0.099s
  training loss:		0.093529
  validation loss:		0.459302
  validation accuracy:		90.11 %
Epoch 1718 of 2000 took 0.099s
  training loss:		0.121468
  validation loss:		0.478881
  validation accuracy:		89.78 %
Epoch 1719 of 2000 took 0.099s
  training loss:		0.089576
  validation loss:		0.490522
  validation accuracy:		89.57 %
Epoch 1720 of 2000 took 0.099s
  training loss:		0.088897
  validation loss:		0.491600
  validation accuracy:		89.46 %
Epoch 1721 of 2000 took 0.099s
  training loss:		0.099509
  validation loss:		0.489377
  validation accuracy:		89.02 %
Epoch 1722 of 2000 took 0.099s
  training loss:		0.088282
  validation loss:		0.473700
  validation accuracy:		89.89 %
Epoch 1723 of 2000 took 0.099s
  training loss:		0.089735
  validation loss:		0.487634
  validation accuracy:		89.57 %
Epoch 1724 of 2000 took 0.099s
  training loss:		0.091820
  validation loss:		0.494255
  validation accuracy:		90.33 %
Epoch 1725 of 2000 took 0.099s
  training loss:		0.091840
  validation loss:		0.501179
  validation accuracy:		89.24 %
Epoch 1726 of 2000 took 0.099s
  training loss:		0.090068
  validation loss:		0.470089
  validation accuracy:		89.78 %
Epoch 1727 of 2000 took 0.099s
  training loss:		0.091181
  validation loss:		0.477300
  validation accuracy:		90.54 %
Epoch 1728 of 2000 took 0.099s
  training loss:		0.091621
  validation loss:		0.485412
  validation accuracy:		89.46 %
Epoch 1729 of 2000 took 0.099s
  training loss:		0.085782
  validation loss:		0.487342
  validation accuracy:		89.35 %
Epoch 1730 of 2000 took 0.099s
  training loss:		0.081598
  validation loss:		0.488275
  validation accuracy:		89.57 %
Epoch 1731 of 2000 took 0.098s
  training loss:		0.093207
  validation loss:		0.487452
  validation accuracy:		89.24 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.083526
  validation loss:		0.505171
  validation accuracy:		89.35 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.098211
  validation loss:		0.511835
  validation accuracy:		88.70 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.091290
  validation loss:		0.479792
  validation accuracy:		89.57 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.089710
  validation loss:		0.501429
  validation accuracy:		90.00 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.102061
  validation loss:		0.492680
  validation accuracy:		89.35 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.098464
  validation loss:		0.484495
  validation accuracy:		90.22 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.084752
  validation loss:		0.503231
  validation accuracy:		89.13 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.092611
  validation loss:		0.478331
  validation accuracy:		90.33 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.089074
  validation loss:		0.475050
  validation accuracy:		90.11 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.091122
  validation loss:		0.486907
  validation accuracy:		89.67 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.087678
  validation loss:		0.515638
  validation accuracy:		89.02 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.089312
  validation loss:		0.504765
  validation accuracy:		89.35 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.093659
  validation loss:		0.489292
  validation accuracy:		89.35 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.099126
  validation loss:		0.502954
  validation accuracy:		89.02 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.097485
  validation loss:		0.493636
  validation accuracy:		89.46 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.087408
  validation loss:		0.470061
  validation accuracy:		90.00 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.095537
  validation loss:		0.495658
  validation accuracy:		89.57 %
Epoch 1749 of 2000 took 0.096s
  training loss:		0.084631
  validation loss:		0.476235
  validation accuracy:		90.43 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.092332
  validation loss:		0.507266
  validation accuracy:		89.02 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.086155
  validation loss:		0.508027
  validation accuracy:		90.11 %
Epoch 1752 of 2000 took 0.096s
  training loss:		0.089441
  validation loss:		0.502131
  validation accuracy:		89.24 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.087637
  validation loss:		0.485749
  validation accuracy:		89.67 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.088347
  validation loss:		0.507520
  validation accuracy:		89.02 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.087625
  validation loss:		0.492451
  validation accuracy:		89.89 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.097584
  validation loss:		0.504059
  validation accuracy:		88.91 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.086592
  validation loss:		0.501093
  validation accuracy:		89.24 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.085418
  validation loss:		0.508423
  validation accuracy:		90.11 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.085857
  validation loss:		0.503882
  validation accuracy:		89.46 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.082738
  validation loss:		0.495972
  validation accuracy:		89.67 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.086600
  validation loss:		0.517865
  validation accuracy:		89.78 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.089736
  validation loss:		0.486299
  validation accuracy:		89.89 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.086729
  validation loss:		0.497009
  validation accuracy:		90.43 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.092584
  validation loss:		0.508019
  validation accuracy:		89.67 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.086723
  validation loss:		0.480421
  validation accuracy:		90.11 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.088248
  validation loss:		0.520112
  validation accuracy:		89.24 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.086488
  validation loss:		0.519040
  validation accuracy:		89.67 %
Epoch 1768 of 2000 took 0.100s
  training loss:		0.086215
  validation loss:		0.490957
  validation accuracy:		89.57 %
Epoch 1769 of 2000 took 0.102s
  training loss:		0.081965
  validation loss:		0.529887
  validation accuracy:		89.02 %
Epoch 1770 of 2000 took 0.097s
  training loss:		0.086320
  validation loss:		0.488865
  validation accuracy:		90.22 %
Epoch 1771 of 2000 took 0.095s
  training loss:		0.087604
  validation loss:		0.504722
  validation accuracy:		89.57 %
Epoch 1772 of 2000 took 0.093s
  training loss:		0.094826
  validation loss:		0.496967
  validation accuracy:		89.57 %
Epoch 1773 of 2000 took 0.093s
  training loss:		0.079517
  validation loss:		0.499240
  validation accuracy:		89.78 %
Epoch 1774 of 2000 took 0.092s
  training loss:		0.088042
  validation loss:		0.492366
  validation accuracy:		89.57 %
Epoch 1775 of 2000 took 0.092s
  training loss:		0.091308
  validation loss:		0.495827
  validation accuracy:		89.78 %
Epoch 1776 of 2000 took 0.093s
  training loss:		0.092413
  validation loss:		0.514507
  validation accuracy:		89.35 %
Epoch 1777 of 2000 took 0.095s
  training loss:		0.085391
  validation loss:		0.507713
  validation accuracy:		89.78 %
Epoch 1778 of 2000 took 0.095s
  training loss:		0.083081
  validation loss:		0.511335
  validation accuracy:		89.78 %
Epoch 1779 of 2000 took 0.095s
  training loss:		0.081112
  validation loss:		0.497188
  validation accuracy:		90.11 %
Epoch 1780 of 2000 took 0.095s
  training loss:		0.083808
  validation loss:		0.498167
  validation accuracy:		90.00 %
Epoch 1781 of 2000 took 0.095s
  training loss:		0.084996
  validation loss:		0.511863
  validation accuracy:		89.89 %
Epoch 1782 of 2000 took 0.095s
  training loss:		0.083916
  validation loss:		0.510387
  validation accuracy:		89.46 %
Epoch 1783 of 2000 took 0.095s
  training loss:		0.088006
  validation loss:		0.534878
  validation accuracy:		89.35 %
Epoch 1784 of 2000 took 0.095s
  training loss:		0.080395
  validation loss:		0.521899
  validation accuracy:		89.02 %
Epoch 1785 of 2000 took 0.108s
  training loss:		0.082671
  validation loss:		0.518096
  validation accuracy:		89.24 %
Epoch 1786 of 2000 took 0.122s
  training loss:		0.079918
  validation loss:		0.511386
  validation accuracy:		89.57 %
Epoch 1787 of 2000 took 0.122s
  training loss:		0.082315
  validation loss:		0.516286
  validation accuracy:		89.57 %
Epoch 1788 of 2000 took 0.122s
  training loss:		0.080790
  validation loss:		0.505452
  validation accuracy:		89.46 %
Epoch 1789 of 2000 took 0.122s
  training loss:		0.081876
  validation loss:		0.494558
  validation accuracy:		89.67 %
Epoch 1790 of 2000 took 0.122s
  training loss:		0.090299
  validation loss:		0.524534
  validation accuracy:		88.70 %
Epoch 1791 of 2000 took 0.122s
  training loss:		0.081542
  validation loss:		0.514810
  validation accuracy:		89.57 %
Epoch 1792 of 2000 took 0.122s
  training loss:		0.081196
  validation loss:		0.499471
  validation accuracy:		90.11 %
Epoch 1793 of 2000 took 0.122s
  training loss:		0.082324
  validation loss:		0.507975
  validation accuracy:		90.22 %
Epoch 1794 of 2000 took 0.119s
  training loss:		0.083997
  validation loss:		0.545838
  validation accuracy:		89.57 %
Epoch 1795 of 2000 took 0.095s
  training loss:		0.082978
  validation loss:		0.519717
  validation accuracy:		89.67 %
Epoch 1796 of 2000 took 0.092s
  training loss:		0.085666
  validation loss:		0.511722
  validation accuracy:		90.00 %
Epoch 1797 of 2000 took 0.092s
  training loss:		0.088687
  validation loss:		0.496100
  validation accuracy:		90.54 %
Epoch 1798 of 2000 took 0.092s
  training loss:		0.087617
  validation loss:		0.510303
  validation accuracy:		90.11 %
Epoch 1799 of 2000 took 0.092s
  training loss:		0.080589
  validation loss:		0.494560
  validation accuracy:		90.22 %
Epoch 1800 of 2000 took 0.092s
  training loss:		0.077112
  validation loss:		0.502585
  validation accuracy:		90.33 %
Epoch 1801 of 2000 took 0.092s
  training loss:		0.082065
  validation loss:		0.537267
  validation accuracy:		89.24 %
Epoch 1802 of 2000 took 0.092s
  training loss:		0.076542
  validation loss:		0.515812
  validation accuracy:		90.22 %
Epoch 1803 of 2000 took 0.092s
  training loss:		0.085410
  validation loss:		0.506891
  validation accuracy:		90.00 %
Epoch 1804 of 2000 took 0.092s
  training loss:		0.081518
  validation loss:		0.515527
  validation accuracy:		89.35 %
Epoch 1805 of 2000 took 0.092s
  training loss:		0.084086
  validation loss:		0.510285
  validation accuracy:		89.78 %
Epoch 1806 of 2000 took 0.092s
  training loss:		0.083155
  validation loss:		0.575180
  validation accuracy:		88.48 %
Epoch 1807 of 2000 took 0.092s
  training loss:		0.087327
  validation loss:		0.513216
  validation accuracy:		90.00 %
Epoch 1808 of 2000 took 0.092s
  training loss:		0.086750
  validation loss:		0.563412
  validation accuracy:		89.46 %
Epoch 1809 of 2000 took 0.092s
  training loss:		0.083914
  validation loss:		0.538209
  validation accuracy:		89.13 %
Epoch 1810 of 2000 took 0.092s
  training loss:		0.089849
  validation loss:		0.549344
  validation accuracy:		88.80 %
Epoch 1811 of 2000 took 0.092s
  training loss:		0.079834
  validation loss:		0.522838
  validation accuracy:		89.67 %
Epoch 1812 of 2000 took 0.092s
  training loss:		0.078128
  validation loss:		0.539062
  validation accuracy:		89.35 %
Epoch 1813 of 2000 took 0.092s
  training loss:		0.084317
  validation loss:		0.528633
  validation accuracy:		89.78 %
Epoch 1814 of 2000 took 0.092s
  training loss:		0.084911
  validation loss:		0.549852
  validation accuracy:		88.48 %
Epoch 1815 of 2000 took 0.092s
  training loss:		0.084753
  validation loss:		0.512687
  validation accuracy:		89.89 %
Epoch 1816 of 2000 took 0.092s
  training loss:		0.077484
  validation loss:		0.542746
  validation accuracy:		89.13 %
Epoch 1817 of 2000 took 0.092s
  training loss:		0.077262
  validation loss:		0.552876
  validation accuracy:		88.80 %
Epoch 1818 of 2000 took 0.092s
  training loss:		0.078771
  validation loss:		0.518538
  validation accuracy:		89.89 %
Epoch 1819 of 2000 took 0.092s
  training loss:		0.081680
  validation loss:		0.527589
  validation accuracy:		90.11 %
Epoch 1820 of 2000 took 0.092s
  training loss:		0.084163
  validation loss:		0.519487
  validation accuracy:		90.65 %
Epoch 1821 of 2000 took 0.092s
  training loss:		0.082413
  validation loss:		0.506703
  validation accuracy:		90.22 %
Epoch 1822 of 2000 took 0.092s
  training loss:		0.076887
  validation loss:		0.508101
  validation accuracy:		90.00 %
Epoch 1823 of 2000 took 0.092s
  training loss:		0.083326
  validation loss:		0.530327
  validation accuracy:		89.57 %
Epoch 1824 of 2000 took 0.093s
  training loss:		0.082678
  validation loss:		0.540895
  validation accuracy:		89.78 %
Epoch 1825 of 2000 took 0.092s
  training loss:		0.081190
  validation loss:		0.537983
  validation accuracy:		89.57 %
Epoch 1826 of 2000 took 0.092s
  training loss:		0.080500
  validation loss:		0.516465
  validation accuracy:		90.00 %
Epoch 1827 of 2000 took 0.092s
  training loss:		0.073447
  validation loss:		0.529292
  validation accuracy:		89.46 %
Epoch 1828 of 2000 took 0.092s
  training loss:		0.079154
  validation loss:		0.540036
  validation accuracy:		89.13 %
Epoch 1829 of 2000 took 0.092s
  training loss:		0.084070
  validation loss:		0.527158
  validation accuracy:		89.13 %
Epoch 1830 of 2000 took 0.092s
  training loss:		0.079592
  validation loss:		0.536804
  validation accuracy:		89.02 %
Epoch 1831 of 2000 took 0.092s
  training loss:		0.082036
  validation loss:		0.531253
  validation accuracy:		89.35 %
Epoch 1832 of 2000 took 0.092s
  training loss:		0.079390
  validation loss:		0.533249
  validation accuracy:		89.35 %
Epoch 1833 of 2000 took 0.092s
  training loss:		0.079600
  validation loss:		0.571444
  validation accuracy:		89.46 %
Epoch 1834 of 2000 took 0.092s
  training loss:		0.084452
  validation loss:		0.536865
  validation accuracy:		89.67 %
Epoch 1835 of 2000 took 0.092s
  training loss:		0.078409
  validation loss:		0.543289
  validation accuracy:		89.57 %
Epoch 1836 of 2000 took 0.092s
  training loss:		0.078286
  validation loss:		0.576568
  validation accuracy:		88.48 %
Epoch 1837 of 2000 took 0.092s
  training loss:		0.077780
  validation loss:		0.582895
  validation accuracy:		89.02 %
Epoch 1838 of 2000 took 0.092s
  training loss:		0.079540
  validation loss:		0.543743
  validation accuracy:		89.46 %
Epoch 1839 of 2000 took 0.092s
  training loss:		0.078109
  validation loss:		0.538389
  validation accuracy:		89.35 %
Epoch 1840 of 2000 took 0.092s
  training loss:		0.075621
  validation loss:		0.548052
  validation accuracy:		89.89 %
Epoch 1841 of 2000 took 0.092s
  training loss:		0.077944
  validation loss:		0.520372
  validation accuracy:		90.65 %
Epoch 1842 of 2000 took 0.092s
  training loss:		0.076384
  validation loss:		0.522727
  validation accuracy:		90.11 %
Epoch 1843 of 2000 took 0.092s
  training loss:		0.071787
  validation loss:		0.555189
  validation accuracy:		89.24 %
Epoch 1844 of 2000 took 0.092s
  training loss:		0.073538
  validation loss:		0.542167
  validation accuracy:		90.33 %
Epoch 1845 of 2000 took 0.092s
  training loss:		0.081832
  validation loss:		0.534239
  validation accuracy:		89.89 %
Epoch 1846 of 2000 took 0.092s
  training loss:		0.075261
  validation loss:		0.556921
  validation accuracy:		89.35 %
Epoch 1847 of 2000 took 0.092s
  training loss:		0.083581
  validation loss:		0.563493
  validation accuracy:		89.46 %
Epoch 1848 of 2000 took 0.092s
  training loss:		0.076170
  validation loss:		0.524489
  validation accuracy:		90.00 %
Epoch 1849 of 2000 took 0.092s
  training loss:		0.085887
  validation loss:		0.571115
  validation accuracy:		88.91 %
Epoch 1850 of 2000 took 0.092s
  training loss:		0.081790
  validation loss:		0.547006
  validation accuracy:		89.46 %
Epoch 1851 of 2000 took 0.092s
  training loss:		0.080256
  validation loss:		0.576592
  validation accuracy:		88.91 %
Epoch 1852 of 2000 took 0.092s
  training loss:		0.082134
  validation loss:		0.545632
  validation accuracy:		89.46 %
Epoch 1853 of 2000 took 0.092s
  training loss:		0.073972
  validation loss:		0.548499
  validation accuracy:		90.11 %
Epoch 1854 of 2000 took 0.092s
  training loss:		0.074320
  validation loss:		0.545511
  validation accuracy:		90.00 %
Epoch 1855 of 2000 took 0.092s
  training loss:		0.074557
  validation loss:		0.535566
  validation accuracy:		89.78 %
Epoch 1856 of 2000 took 0.093s
  training loss:		0.076516
  validation loss:		0.577775
  validation accuracy:		89.02 %
Epoch 1857 of 2000 took 0.092s
  training loss:		0.076610
  validation loss:		0.530331
  validation accuracy:		90.00 %
Epoch 1858 of 2000 took 0.092s
  training loss:		0.076117
  validation loss:		0.543136
  validation accuracy:		89.57 %
Epoch 1859 of 2000 took 0.092s
  training loss:		0.077351
  validation loss:		0.562700
  validation accuracy:		89.78 %
Epoch 1860 of 2000 took 0.092s
  training loss:		0.079008
  validation loss:		0.538387
  validation accuracy:		89.78 %
Epoch 1861 of 2000 took 0.092s
  training loss:		0.075078
  validation loss:		0.547000
  validation accuracy:		89.46 %
Epoch 1862 of 2000 took 0.092s
  training loss:		0.077715
  validation loss:		0.561308
  validation accuracy:		89.57 %
Epoch 1863 of 2000 took 0.092s
  training loss:		0.073864
  validation loss:		0.543796
  validation accuracy:		90.00 %
Epoch 1864 of 2000 took 0.092s
  training loss:		0.083368
  validation loss:		0.564548
  validation accuracy:		89.67 %
Epoch 1865 of 2000 took 0.092s
  training loss:		0.074227
  validation loss:		0.550729
  validation accuracy:		90.43 %
Epoch 1866 of 2000 took 0.092s
  training loss:		0.077283
  validation loss:		0.580406
  validation accuracy:		89.24 %
Epoch 1867 of 2000 took 0.092s
  training loss:		0.074722
  validation loss:		0.551246
  validation accuracy:		90.11 %
Epoch 1868 of 2000 took 0.092s
  training loss:		0.074769
  validation loss:		0.557911
  validation accuracy:		89.46 %
Epoch 1869 of 2000 took 0.092s
  training loss:		0.071038
  validation loss:		0.553893
  validation accuracy:		89.46 %
Epoch 1870 of 2000 took 0.092s
  training loss:		0.070612
  validation loss:		0.557650
  validation accuracy:		89.57 %
Epoch 1871 of 2000 took 0.092s
  training loss:		0.076592
  validation loss:		0.563126
  validation accuracy:		89.13 %
Epoch 1872 of 2000 took 0.092s
  training loss:		0.077815
  validation loss:		0.602957
  validation accuracy:		88.59 %
Epoch 1873 of 2000 took 0.092s
  training loss:		0.078331
  validation loss:		0.575053
  validation accuracy:		89.13 %
Epoch 1874 of 2000 took 0.092s
  training loss:		0.072259
  validation loss:		0.558544
  validation accuracy:		89.13 %
Epoch 1875 of 2000 took 0.092s
  training loss:		0.091007
  validation loss:		0.559684
  validation accuracy:		89.57 %
Epoch 1876 of 2000 took 0.092s
  training loss:		0.074784
  validation loss:		0.593114
  validation accuracy:		88.80 %
Epoch 1877 of 2000 took 0.092s
  training loss:		0.076386
  validation loss:		0.587973
  validation accuracy:		89.02 %
Epoch 1878 of 2000 took 0.092s
  training loss:		0.073121
  validation loss:		0.553557
  validation accuracy:		89.35 %
Epoch 1879 of 2000 took 0.092s
  training loss:		0.078946
  validation loss:		0.547530
  validation accuracy:		90.87 %
Epoch 1880 of 2000 took 0.092s
  training loss:		0.085688
  validation loss:		0.561240
  validation accuracy:		89.46 %
Epoch 1881 of 2000 took 0.092s
  training loss:		0.076423
  validation loss:		0.558273
  validation accuracy:		89.46 %
Epoch 1882 of 2000 took 0.092s
  training loss:		0.072714
  validation loss:		0.569919
  validation accuracy:		89.35 %
Epoch 1883 of 2000 took 0.092s
  training loss:		0.070434
  validation loss:		0.552611
  validation accuracy:		89.78 %
Epoch 1884 of 2000 took 0.092s
  training loss:		0.070317
  validation loss:		0.579155
  validation accuracy:		90.00 %
Epoch 1885 of 2000 took 0.092s
  training loss:		0.074759
  validation loss:		0.565258
  validation accuracy:		89.78 %
Epoch 1886 of 2000 took 0.092s
  training loss:		0.073854
  validation loss:		0.559184
  validation accuracy:		89.67 %
Epoch 1887 of 2000 took 0.092s
  training loss:		0.079989
  validation loss:		0.583015
  validation accuracy:		90.00 %
Epoch 1888 of 2000 took 0.092s
  training loss:		0.074462
  validation loss:		0.569994
  validation accuracy:		89.02 %
Epoch 1889 of 2000 took 0.093s
  training loss:		0.072013
  validation loss:		0.576925
  validation accuracy:		89.13 %
Epoch 1890 of 2000 took 0.092s
  training loss:		0.075354
  validation loss:		0.568793
  validation accuracy:		89.57 %
Epoch 1891 of 2000 took 0.092s
  training loss:		0.072293
  validation loss:		0.551531
  validation accuracy:		90.00 %
Epoch 1892 of 2000 took 0.092s
  training loss:		0.073837
  validation loss:		0.542870
  validation accuracy:		90.00 %
Epoch 1893 of 2000 took 0.092s
  training loss:		0.077130
  validation loss:		0.599708
  validation accuracy:		88.91 %
Epoch 1894 of 2000 took 0.092s
  training loss:		0.079597
  validation loss:		0.627193
  validation accuracy:		88.48 %
Epoch 1895 of 2000 took 0.092s
  training loss:		0.072759
  validation loss:		0.587069
  validation accuracy:		89.02 %
Epoch 1896 of 2000 took 0.092s
  training loss:		0.072941
  validation loss:		0.541502
  validation accuracy:		89.78 %
Epoch 1897 of 2000 took 0.092s
  training loss:		0.066571
  validation loss:		0.576045
  validation accuracy:		89.35 %
Epoch 1898 of 2000 took 0.092s
  training loss:		0.073356
  validation loss:		0.591143
  validation accuracy:		88.91 %
Epoch 1899 of 2000 took 0.092s
  training loss:		0.074739
  validation loss:		0.574232
  validation accuracy:		89.24 %
Epoch 1900 of 2000 took 0.092s
  training loss:		0.069761
  validation loss:		0.566293
  validation accuracy:		90.22 %
Epoch 1901 of 2000 took 0.092s
  training loss:		0.075681
  validation loss:		0.582724
  validation accuracy:		89.13 %
Epoch 1902 of 2000 took 0.092s
  training loss:		0.073341
  validation loss:		0.556721
  validation accuracy:		89.57 %
Epoch 1903 of 2000 took 0.092s
  training loss:		0.067943
  validation loss:		0.583855
  validation accuracy:		89.35 %
Epoch 1904 of 2000 took 0.092s
  training loss:		0.070935
  validation loss:		0.559827
  validation accuracy:		89.78 %
Epoch 1905 of 2000 took 0.092s
  training loss:		0.067894
  validation loss:		0.581567
  validation accuracy:		89.02 %
Epoch 1906 of 2000 took 0.092s
  training loss:		0.070160
  validation loss:		0.565937
  validation accuracy:		89.57 %
Epoch 1907 of 2000 took 0.092s
  training loss:		0.071334
  validation loss:		0.562890
  validation accuracy:		89.57 %
Epoch 1908 of 2000 took 0.092s
  training loss:		0.068616
  validation loss:		0.591467
  validation accuracy:		89.02 %
Epoch 1909 of 2000 took 0.092s
  training loss:		0.070155
  validation loss:		0.561763
  validation accuracy:		89.67 %
Epoch 1910 of 2000 took 0.092s
  training loss:		0.074491
  validation loss:		0.565609
  validation accuracy:		89.57 %
Epoch 1911 of 2000 took 0.092s
  training loss:		0.069849
  validation loss:		0.607767
  validation accuracy:		88.70 %
Epoch 1912 of 2000 took 0.092s
  training loss:		0.068715
  validation loss:		0.616652
  validation accuracy:		89.24 %
Epoch 1913 of 2000 took 0.093s
  training loss:		0.069314
  validation loss:		0.551620
  validation accuracy:		90.43 %
Epoch 1914 of 2000 took 0.092s
  training loss:		0.073732
  validation loss:		0.609023
  validation accuracy:		88.80 %
Epoch 1915 of 2000 took 0.092s
  training loss:		0.066755
  validation loss:		0.577829
  validation accuracy:		90.00 %
Epoch 1916 of 2000 took 0.092s
  training loss:		0.074890
  validation loss:		0.616438
  validation accuracy:		90.22 %
Epoch 1917 of 2000 took 0.092s
  training loss:		0.076361
  validation loss:		0.568288
  validation accuracy:		89.67 %
Epoch 1918 of 2000 took 0.092s
  training loss:		0.067208
  validation loss:		0.570514
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.092s
  training loss:		0.072941
  validation loss:		0.588966
  validation accuracy:		90.33 %
Epoch 1920 of 2000 took 0.092s
  training loss:		0.068315
  validation loss:		0.590287
  validation accuracy:		89.13 %
Epoch 1921 of 2000 took 0.092s
  training loss:		0.076375
  validation loss:		0.636205
  validation accuracy:		88.48 %
Epoch 1922 of 2000 took 0.093s
  training loss:		0.070752
  validation loss:		0.598662
  validation accuracy:		89.46 %
Epoch 1923 of 2000 took 0.092s
  training loss:		0.071150
  validation loss:		0.654184
  validation accuracy:		87.93 %
Epoch 1924 of 2000 took 0.092s
  training loss:		0.075821
  validation loss:		0.578768
  validation accuracy:		90.43 %
Epoch 1925 of 2000 took 0.092s
  training loss:		0.074438
  validation loss:		0.579173
  validation accuracy:		89.35 %
Epoch 1926 of 2000 took 0.092s
  training loss:		0.068906
  validation loss:		0.593118
  validation accuracy:		89.46 %
Epoch 1927 of 2000 took 0.092s
  training loss:		0.066511
  validation loss:		0.597730
  validation accuracy:		89.35 %
Epoch 1928 of 2000 took 0.092s
  training loss:		0.070388
  validation loss:		0.557543
  validation accuracy:		90.11 %
Epoch 1929 of 2000 took 0.092s
  training loss:		0.071876
  validation loss:		0.593435
  validation accuracy:		89.13 %
Epoch 1930 of 2000 took 0.092s
  training loss:		0.072760
  validation loss:		0.583155
  validation accuracy:		89.46 %
Epoch 1931 of 2000 took 0.092s
  training loss:		0.071505
  validation loss:		0.602850
  validation accuracy:		89.13 %
Epoch 1932 of 2000 took 0.092s
  training loss:		0.074777
  validation loss:		0.582371
  validation accuracy:		89.46 %
Epoch 1933 of 2000 took 0.092s
  training loss:		0.080612
  validation loss:		0.595763
  validation accuracy:		89.13 %
Epoch 1934 of 2000 took 0.092s
  training loss:		0.066019
  validation loss:		0.573632
  validation accuracy:		89.78 %
Epoch 1935 of 2000 took 0.092s
  training loss:		0.067299
  validation loss:		0.619750
  validation accuracy:		89.02 %
Epoch 1936 of 2000 took 0.092s
  training loss:		0.070391
  validation loss:		0.587237
  validation accuracy:		90.65 %
Epoch 1937 of 2000 took 0.092s
  training loss:		0.073733
  validation loss:		0.599300
  validation accuracy:		88.91 %
Epoch 1938 of 2000 took 0.092s
  training loss:		0.065102
  validation loss:		0.620279
  validation accuracy:		88.91 %
Epoch 1939 of 2000 took 0.092s
  training loss:		0.067386
  validation loss:		0.573341
  validation accuracy:		90.00 %
Epoch 1940 of 2000 took 0.092s
  training loss:		0.084694
  validation loss:		0.583759
  validation accuracy:		90.00 %
Epoch 1941 of 2000 took 0.092s
  training loss:		0.067350
  validation loss:		0.603369
  validation accuracy:		89.78 %
Epoch 1942 of 2000 took 0.092s
  training loss:		0.067926
  validation loss:		0.595857
  validation accuracy:		89.67 %
Epoch 1943 of 2000 took 0.092s
  training loss:		0.075087
  validation loss:		0.646393
  validation accuracy:		88.37 %
Epoch 1944 of 2000 took 0.092s
  training loss:		0.073258
  validation loss:		0.638903
  validation accuracy:		88.80 %
Epoch 1945 of 2000 took 0.092s
  training loss:		0.071027
  validation loss:		0.592456
  validation accuracy:		89.89 %
Epoch 1946 of 2000 took 0.092s
  training loss:		0.067813
  validation loss:		0.637435
  validation accuracy:		88.91 %
Epoch 1947 of 2000 took 0.092s
  training loss:		0.070561
  validation loss:		0.578445
  validation accuracy:		89.67 %
Epoch 1948 of 2000 took 0.092s
  training loss:		0.068311
  validation loss:		0.642187
  validation accuracy:		88.80 %
Epoch 1949 of 2000 took 0.092s
  training loss:		0.075862
  validation loss:		0.615659
  validation accuracy:		89.57 %
Epoch 1950 of 2000 took 0.092s
  training loss:		0.066991
  validation loss:		0.586132
  validation accuracy:		89.67 %
Epoch 1951 of 2000 took 0.092s
  training loss:		0.062766
  validation loss:		0.602975
  validation accuracy:		90.22 %
Epoch 1952 of 2000 took 0.092s
  training loss:		0.065811
  validation loss:		0.609451
  validation accuracy:		89.46 %
Epoch 1953 of 2000 took 0.092s
  training loss:		0.068534
  validation loss:		0.611414
  validation accuracy:		88.70 %
Epoch 1954 of 2000 took 0.093s
  training loss:		0.062506
  validation loss:		0.617255
  validation accuracy:		88.91 %
Epoch 1955 of 2000 took 0.092s
  training loss:		0.069716
  validation loss:		0.615039
  validation accuracy:		89.35 %
Epoch 1956 of 2000 took 0.092s
  training loss:		0.066369
  validation loss:		0.600421
  validation accuracy:		89.24 %
Epoch 1957 of 2000 took 0.092s
  training loss:		0.068013
  validation loss:		0.599784
  validation accuracy:		89.46 %
Epoch 1958 of 2000 took 0.092s
  training loss:		0.071527
  validation loss:		0.632605
  validation accuracy:		88.91 %
Epoch 1959 of 2000 took 0.092s
  training loss:		0.063616
  validation loss:		0.628129
  validation accuracy:		89.13 %
Epoch 1960 of 2000 took 0.093s
  training loss:		0.065571
  validation loss:		0.626446
  validation accuracy:		89.02 %
Epoch 1961 of 2000 took 0.092s
  training loss:		0.071499
  validation loss:		0.611547
  validation accuracy:		89.57 %
Epoch 1962 of 2000 took 0.092s
  training loss:		0.068055
  validation loss:		0.623539
  validation accuracy:		89.24 %
Epoch 1963 of 2000 took 0.092s
  training loss:		0.062240
  validation loss:		0.608903
  validation accuracy:		90.00 %
Epoch 1964 of 2000 took 0.092s
  training loss:		0.066739
  validation loss:		0.631423
  validation accuracy:		88.70 %
Epoch 1965 of 2000 took 0.092s
  training loss:		0.065470
  validation loss:		0.618183
  validation accuracy:		89.02 %
Epoch 1966 of 2000 took 0.092s
  training loss:		0.066021
  validation loss:		0.619606
  validation accuracy:		89.35 %
Epoch 1967 of 2000 took 0.092s
  training loss:		0.069083
  validation loss:		0.616882
  validation accuracy:		88.91 %
Epoch 1968 of 2000 took 0.092s
  training loss:		0.060669
  validation loss:		0.598648
  validation accuracy:		89.35 %
Epoch 1969 of 2000 took 0.092s
  training loss:		0.068385
  validation loss:		0.653984
  validation accuracy:		88.59 %
Epoch 1970 of 2000 took 0.092s
  training loss:		0.070202
  validation loss:		0.620871
  validation accuracy:		89.13 %
Epoch 1971 of 2000 took 0.092s
  training loss:		0.063255
  validation loss:		0.597515
  validation accuracy:		89.89 %
Epoch 1972 of 2000 took 0.092s
  training loss:		0.064165
  validation loss:		0.604166
  validation accuracy:		89.46 %
Epoch 1973 of 2000 took 0.092s
  training loss:		0.065679
  validation loss:		0.625808
  validation accuracy:		89.57 %
Epoch 1974 of 2000 took 0.092s
  training loss:		0.065569
  validation loss:		0.608011
  validation accuracy:		89.46 %
Epoch 1975 of 2000 took 0.092s
  training loss:		0.065460
  validation loss:		0.607915
  validation accuracy:		89.67 %
Epoch 1976 of 2000 took 0.092s
  training loss:		0.057983
  validation loss:		0.606871
  validation accuracy:		89.67 %
Epoch 1977 of 2000 took 0.092s
  training loss:		0.069257
  validation loss:		0.643334
  validation accuracy:		88.91 %
Epoch 1978 of 2000 took 0.092s
  training loss:		0.061006
  validation loss:		0.593134
  validation accuracy:		90.11 %
Epoch 1979 of 2000 took 0.092s
  training loss:		0.071803
  validation loss:		0.661692
  validation accuracy:		88.70 %
Epoch 1980 of 2000 took 0.092s
  training loss:		0.070920
  validation loss:		0.626381
  validation accuracy:		89.78 %
Epoch 1981 of 2000 took 0.092s
  training loss:		0.067195
  validation loss:		0.647912
  validation accuracy:		88.80 %
Epoch 1982 of 2000 took 0.092s
  training loss:		0.062489
  validation loss:		0.630517
  validation accuracy:		89.35 %
Epoch 1983 of 2000 took 0.092s
  training loss:		0.060478
  validation loss:		0.613084
  validation accuracy:		89.57 %
Epoch 1984 of 2000 took 0.092s
  training loss:		0.069917
  validation loss:		0.703226
  validation accuracy:		87.83 %
Epoch 1985 of 2000 took 0.092s
  training loss:		0.067778
  validation loss:		0.630531
  validation accuracy:		89.02 %
Epoch 1986 of 2000 took 0.095s
  training loss:		0.061579
  validation loss:		0.649740
  validation accuracy:		88.91 %
Epoch 1987 of 2000 took 0.099s
  training loss:		0.062611
  validation loss:		0.616633
  validation accuracy:		89.46 %
Epoch 1988 of 2000 took 0.098s
  training loss:		0.065047
  validation loss:		0.620669
  validation accuracy:		89.89 %
Epoch 1989 of 2000 took 0.098s
  training loss:		0.065569
  validation loss:		0.658297
  validation accuracy:		88.48 %
Epoch 1990 of 2000 took 0.098s
  training loss:		0.066450
  validation loss:		0.663943
  validation accuracy:		89.02 %
Epoch 1991 of 2000 took 0.098s
  training loss:		0.059922
  validation loss:		0.667909
  validation accuracy:		89.02 %
Epoch 1992 of 2000 took 0.098s
  training loss:		0.069594
  validation loss:		0.650466
  validation accuracy:		88.91 %
Epoch 1993 of 2000 took 0.098s
  training loss:		0.059035
  validation loss:		0.654842
  validation accuracy:		89.02 %
Epoch 1994 of 2000 took 0.098s
  training loss:		0.064567
  validation loss:		0.645186
  validation accuracy:		90.00 %
Epoch 1995 of 2000 took 0.098s
  training loss:		0.063329
  validation loss:		0.634519
  validation accuracy:		88.59 %
Epoch 1996 of 2000 took 0.098s
  training loss:		0.070263
  validation loss:		0.679039
  validation accuracy:		88.80 %
Epoch 1997 of 2000 took 0.098s
  training loss:		0.063932
  validation loss:		0.665694
  validation accuracy:		88.26 %
Epoch 1998 of 2000 took 0.098s
  training loss:		0.065133
  validation loss:		0.609574
  validation accuracy:		90.00 %
Epoch 1999 of 2000 took 0.098s
  training loss:		0.066243
  validation loss:		0.622763
  validation accuracy:		89.89 %
Epoch 2000 of 2000 took 0.098s
  training loss:		0.063075
  validation loss:		0.660209
  validation accuracy:		89.24 %
Final results:
  test loss:			1.437964
  test accuracy:		80.37 %
