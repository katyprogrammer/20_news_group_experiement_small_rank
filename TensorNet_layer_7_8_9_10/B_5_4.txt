Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		3.014556
  validation loss:		3.002324
  validation accuracy:		0.00 %
Epoch 2 of 2000 took 0.096s
  training loss:		3.004555
  validation loss:		2.988713
  validation accuracy:		0.00 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.991113
  validation loss:		2.973320
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.977073
  validation loss:		2.957495
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.097s
  training loss:		2.962165
  validation loss:		2.941678
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.096s
  training loss:		2.947952
  validation loss:		2.926264
  validation accuracy:		12.83 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.933749
  validation loss:		2.911038
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.919566
  validation loss:		2.896107
  validation accuracy:		13.04 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.906833
  validation loss:		2.881274
  validation accuracy:		13.04 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.893707
  validation loss:		2.866743
  validation accuracy:		13.04 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.880424
  validation loss:		2.852440
  validation accuracy:		13.04 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.867976
  validation loss:		2.838259
  validation accuracy:		13.04 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.854720
  validation loss:		2.824194
  validation accuracy:		13.04 %
Epoch 14 of 2000 took 0.101s
  training loss:		2.842892
  validation loss:		2.810230
  validation accuracy:		13.04 %
Epoch 15 of 2000 took 0.098s
  training loss:		2.829827
  validation loss:		2.796359
  validation accuracy:		13.04 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.817808
  validation loss:		2.782492
  validation accuracy:		13.04 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.805383
  validation loss:		2.768707
  validation accuracy:		13.04 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.793472
  validation loss:		2.754994
  validation accuracy:		13.04 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.781923
  validation loss:		2.741331
  validation accuracy:		13.04 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.769279
  validation loss:		2.727688
  validation accuracy:		13.04 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.757048
  validation loss:		2.714049
  validation accuracy:		13.04 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.744515
  validation loss:		2.700325
  validation accuracy:		13.04 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.732085
  validation loss:		2.686669
  validation accuracy:		13.04 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.719808
  validation loss:		2.673023
  validation accuracy:		13.04 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.708748
  validation loss:		2.659275
  validation accuracy:		13.04 %
Epoch 26 of 2000 took 0.096s
  training loss:		2.696024
  validation loss:		2.645573
  validation accuracy:		13.04 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.684172
  validation loss:		2.631950
  validation accuracy:		13.04 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.671602
  validation loss:		2.618321
  validation accuracy:		13.04 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.659775
  validation loss:		2.604674
  validation accuracy:		13.04 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.649306
  validation loss:		2.591139
  validation accuracy:		13.04 %
Epoch 31 of 2000 took 0.096s
  training loss:		2.638145
  validation loss:		2.577769
  validation accuracy:		13.04 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.625240
  validation loss:		2.564418
  validation accuracy:		13.04 %
Epoch 33 of 2000 took 0.096s
  training loss:		2.613179
  validation loss:		2.551306
  validation accuracy:		13.04 %
Epoch 34 of 2000 took 0.096s
  training loss:		2.601900
  validation loss:		2.538323
  validation accuracy:		13.04 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.589854
  validation loss:		2.525229
  validation accuracy:		13.04 %
Epoch 36 of 2000 took 0.096s
  training loss:		2.580006
  validation loss:		2.512470
  validation accuracy:		13.04 %
Epoch 37 of 2000 took 0.096s
  training loss:		2.569519
  validation loss:		2.499893
  validation accuracy:		13.04 %
Epoch 38 of 2000 took 0.096s
  training loss:		2.557842
  validation loss:		2.487654
  validation accuracy:		13.04 %
Epoch 39 of 2000 took 0.096s
  training loss:		2.546713
  validation loss:		2.475536
  validation accuracy:		13.04 %
Epoch 40 of 2000 took 0.101s
  training loss:		2.536165
  validation loss:		2.463725
  validation accuracy:		13.04 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.526174
  validation loss:		2.452060
  validation accuracy:		13.04 %
Epoch 42 of 2000 took 0.096s
  training loss:		2.515290
  validation loss:		2.440640
  validation accuracy:		13.04 %
Epoch 43 of 2000 took 0.096s
  training loss:		2.505571
  validation loss:		2.429589
  validation accuracy:		13.04 %
Epoch 44 of 2000 took 0.096s
  training loss:		2.497595
  validation loss:		2.418946
  validation accuracy:		13.04 %
Epoch 45 of 2000 took 0.096s
  training loss:		2.485636
  validation loss:		2.408352
  validation accuracy:		13.04 %
Epoch 46 of 2000 took 0.096s
  training loss:		2.478247
  validation loss:		2.398356
  validation accuracy:		13.04 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.467438
  validation loss:		2.388881
  validation accuracy:		13.04 %
Epoch 48 of 2000 took 0.096s
  training loss:		2.459332
  validation loss:		2.379657
  validation accuracy:		13.04 %
Epoch 49 of 2000 took 0.096s
  training loss:		2.451609
  validation loss:		2.370823
  validation accuracy:		13.04 %
Epoch 50 of 2000 took 0.096s
  training loss:		2.442818
  validation loss:		2.362263
  validation accuracy:		13.04 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.436113
  validation loss:		2.354206
  validation accuracy:		13.04 %
Epoch 52 of 2000 took 0.096s
  training loss:		2.426087
  validation loss:		2.346424
  validation accuracy:		13.04 %
Epoch 53 of 2000 took 0.096s
  training loss:		2.418010
  validation loss:		2.338987
  validation accuracy:		13.04 %
Epoch 54 of 2000 took 0.097s
  training loss:		2.411349
  validation loss:		2.332040
  validation accuracy:		13.04 %
Epoch 55 of 2000 took 0.096s
  training loss:		2.406054
  validation loss:		2.325368
  validation accuracy:		13.04 %
Epoch 56 of 2000 took 0.096s
  training loss:		2.401161
  validation loss:		2.319174
  validation accuracy:		13.04 %
Epoch 57 of 2000 took 0.096s
  training loss:		2.393564
  validation loss:		2.313503
  validation accuracy:		13.04 %
Epoch 58 of 2000 took 0.100s
  training loss:		2.388597
  validation loss:		2.308375
  validation accuracy:		13.04 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.382681
  validation loss:		2.303458
  validation accuracy:		13.04 %
Epoch 60 of 2000 took 0.096s
  training loss:		2.376287
  validation loss:		2.298543
  validation accuracy:		13.04 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.373101
  validation loss:		2.294517
  validation accuracy:		13.04 %
Epoch 62 of 2000 took 0.096s
  training loss:		2.367482
  validation loss:		2.290857
  validation accuracy:		13.04 %
Epoch 63 of 2000 took 0.096s
  training loss:		2.362899
  validation loss:		2.287183
  validation accuracy:		13.04 %
Epoch 64 of 2000 took 0.096s
  training loss:		2.357705
  validation loss:		2.284016
  validation accuracy:		13.04 %
Epoch 65 of 2000 took 0.096s
  training loss:		2.355817
  validation loss:		2.280821
  validation accuracy:		13.04 %
Epoch 66 of 2000 took 0.096s
  training loss:		2.350221
  validation loss:		2.278109
  validation accuracy:		13.04 %
Epoch 67 of 2000 took 0.096s
  training loss:		2.347561
  validation loss:		2.275729
  validation accuracy:		13.04 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.342496
  validation loss:		2.273304
  validation accuracy:		13.04 %
Epoch 69 of 2000 took 0.096s
  training loss:		2.340660
  validation loss:		2.270810
  validation accuracy:		13.04 %
Epoch 70 of 2000 took 0.096s
  training loss:		2.338526
  validation loss:		2.268705
  validation accuracy:		13.04 %
Epoch 71 of 2000 took 0.101s
  training loss:		2.334941
  validation loss:		2.266969
  validation accuracy:		13.04 %
Epoch 72 of 2000 took 0.097s
  training loss:		2.332935
  validation loss:		2.265804
  validation accuracy:		13.04 %
Epoch 73 of 2000 took 0.096s
  training loss:		2.331229
  validation loss:		2.264443
  validation accuracy:		13.04 %
Epoch 74 of 2000 took 0.096s
  training loss:		2.327850
  validation loss:		2.263665
  validation accuracy:		12.61 %
Epoch 75 of 2000 took 0.096s
  training loss:		2.325242
  validation loss:		2.262981
  validation accuracy:		13.04 %
Epoch 76 of 2000 took 0.096s
  training loss:		2.323854
  validation loss:		2.261964
  validation accuracy:		13.04 %
Epoch 77 of 2000 took 0.096s
  training loss:		2.322799
  validation loss:		2.260885
  validation accuracy:		13.04 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.320244
  validation loss:		2.259760
  validation accuracy:		13.04 %
Epoch 79 of 2000 took 0.096s
  training loss:		2.319352
  validation loss:		2.259361
  validation accuracy:		13.04 %
Epoch 80 of 2000 took 0.096s
  training loss:		2.317834
  validation loss:		2.258968
  validation accuracy:		12.72 %
Epoch 81 of 2000 took 0.098s
  training loss:		2.317359
  validation loss:		2.258076
  validation accuracy:		12.93 %
Epoch 82 of 2000 took 0.099s
  training loss:		2.313487
  validation loss:		2.257487
  validation accuracy:		12.61 %
Epoch 83 of 2000 took 0.096s
  training loss:		2.313509
  validation loss:		2.257098
  validation accuracy:		13.04 %
Epoch 84 of 2000 took 0.096s
  training loss:		2.311930
  validation loss:		2.256123
  validation accuracy:		13.04 %
Epoch 85 of 2000 took 0.096s
  training loss:		2.311900
  validation loss:		2.256103
  validation accuracy:		12.72 %
Epoch 86 of 2000 took 0.096s
  training loss:		2.310661
  validation loss:		2.255691
  validation accuracy:		12.61 %
Epoch 87 of 2000 took 0.096s
  training loss:		2.309646
  validation loss:		2.254965
  validation accuracy:		12.50 %
Epoch 88 of 2000 took 0.096s
  training loss:		2.308604
  validation loss:		2.254457
  validation accuracy:		12.93 %
Epoch 89 of 2000 took 0.096s
  training loss:		2.306525
  validation loss:		2.253762
  validation accuracy:		13.48 %
Epoch 90 of 2000 took 0.096s
  training loss:		2.306868
  validation loss:		2.253580
  validation accuracy:		13.70 %
Epoch 91 of 2000 took 0.096s
  training loss:		2.306144
  validation loss:		2.252143
  validation accuracy:		13.70 %
Epoch 92 of 2000 took 0.101s
  training loss:		2.306281
  validation loss:		2.251674
  validation accuracy:		14.13 %
Epoch 93 of 2000 took 0.096s
  training loss:		2.305093
  validation loss:		2.250675
  validation accuracy:		12.72 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.304770
  validation loss:		2.250976
  validation accuracy:		13.04 %
Epoch 95 of 2000 took 0.097s
  training loss:		2.304367
  validation loss:		2.251278
  validation accuracy:		13.04 %
Epoch 96 of 2000 took 0.096s
  training loss:		2.303584
  validation loss:		2.251471
  validation accuracy:		13.04 %
Epoch 97 of 2000 took 0.096s
  training loss:		2.303955
  validation loss:		2.252308
  validation accuracy:		12.72 %
Epoch 98 of 2000 took 0.096s
  training loss:		2.303162
  validation loss:		2.251829
  validation accuracy:		14.35 %
Epoch 99 of 2000 took 0.096s
  training loss:		2.302035
  validation loss:		2.251975
  validation accuracy:		13.70 %
Epoch 100 of 2000 took 0.096s
  training loss:		2.301774
  validation loss:		2.250625
  validation accuracy:		16.09 %
Epoch 101 of 2000 took 0.096s
  training loss:		2.301638
  validation loss:		2.250259
  validation accuracy:		15.22 %
Epoch 102 of 2000 took 0.101s
  training loss:		2.301375
  validation loss:		2.250312
  validation accuracy:		15.22 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.300037
  validation loss:		2.250069
  validation accuracy:		13.59 %
Epoch 104 of 2000 took 0.096s
  training loss:		2.299953
  validation loss:		2.248387
  validation accuracy:		13.04 %
Epoch 105 of 2000 took 0.096s
  training loss:		2.301094
  validation loss:		2.248080
  validation accuracy:		13.15 %
Epoch 106 of 2000 took 0.096s
  training loss:		2.300370
  validation loss:		2.249300
  validation accuracy:		15.43 %
Epoch 107 of 2000 took 0.096s
  training loss:		2.300366
  validation loss:		2.249621
  validation accuracy:		14.24 %
Epoch 108 of 2000 took 0.096s
  training loss:		2.299188
  validation loss:		2.249538
  validation accuracy:		13.59 %
Epoch 109 of 2000 took 0.097s
  training loss:		2.299329
  validation loss:		2.249870
  validation accuracy:		14.24 %
Epoch 110 of 2000 took 0.096s
  training loss:		2.297738
  validation loss:		2.248187
  validation accuracy:		13.70 %
Epoch 111 of 2000 took 0.097s
  training loss:		2.298074
  validation loss:		2.246468
  validation accuracy:		12.07 %
Epoch 112 of 2000 took 0.098s
  training loss:		2.297889
  validation loss:		2.245855
  validation accuracy:		12.72 %
Epoch 113 of 2000 took 0.099s
  training loss:		2.297739
  validation loss:		2.245603
  validation accuracy:		16.41 %
Epoch 114 of 2000 took 0.096s
  training loss:		2.298393
  validation loss:		2.245853
  validation accuracy:		15.87 %
Epoch 115 of 2000 took 0.096s
  training loss:		2.296935
  validation loss:		2.246514
  validation accuracy:		13.04 %
Epoch 116 of 2000 took 0.096s
  training loss:		2.297564
  validation loss:		2.246202
  validation accuracy:		14.57 %
Epoch 117 of 2000 took 0.096s
  training loss:		2.297556
  validation loss:		2.245370
  validation accuracy:		14.89 %
Epoch 118 of 2000 took 0.097s
  training loss:		2.296967
  validation loss:		2.244380
  validation accuracy:		13.15 %
Epoch 119 of 2000 took 0.096s
  training loss:		2.296938
  validation loss:		2.245147
  validation accuracy:		12.28 %
Epoch 120 of 2000 took 0.096s
  training loss:		2.297017
  validation loss:		2.244135
  validation accuracy:		13.04 %
Epoch 121 of 2000 took 0.096s
  training loss:		2.296973
  validation loss:		2.245022
  validation accuracy:		12.61 %
Epoch 122 of 2000 took 0.096s
  training loss:		2.297661
  validation loss:		2.246060
  validation accuracy:		12.50 %
Epoch 123 of 2000 took 0.101s
  training loss:		2.297442
  validation loss:		2.246885
  validation accuracy:		13.04 %
Epoch 124 of 2000 took 0.096s
  training loss:		2.296413
  validation loss:		2.248130
  validation accuracy:		12.72 %
Epoch 125 of 2000 took 0.096s
  training loss:		2.295831
  validation loss:		2.246768
  validation accuracy:		13.80 %
Epoch 126 of 2000 took 0.096s
  training loss:		2.296329
  validation loss:		2.244847
  validation accuracy:		14.57 %
Epoch 127 of 2000 took 0.096s
  training loss:		2.295727
  validation loss:		2.244077
  validation accuracy:		11.96 %
Epoch 128 of 2000 took 0.096s
  training loss:		2.296321
  validation loss:		2.244704
  validation accuracy:		13.04 %
Epoch 129 of 2000 took 0.096s
  training loss:		2.296646
  validation loss:		2.245620
  validation accuracy:		13.15 %
Epoch 130 of 2000 took 0.096s
  training loss:		2.296161
  validation loss:		2.244521
  validation accuracy:		11.85 %
Epoch 131 of 2000 took 0.096s
  training loss:		2.295966
  validation loss:		2.244909
  validation accuracy:		12.93 %
Epoch 132 of 2000 took 0.096s
  training loss:		2.295167
  validation loss:		2.245504
  validation accuracy:		13.04 %
Epoch 133 of 2000 took 0.101s
  training loss:		2.296231
  validation loss:		2.245114
  validation accuracy:		12.93 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.295232
  validation loss:		2.244675
  validation accuracy:		14.35 %
Epoch 135 of 2000 took 0.096s
  training loss:		2.295359
  validation loss:		2.244428
  validation accuracy:		14.46 %
Epoch 136 of 2000 took 0.096s
  training loss:		2.294950
  validation loss:		2.242818
  validation accuracy:		18.04 %
Epoch 137 of 2000 took 0.097s
  training loss:		2.295315
  validation loss:		2.243263
  validation accuracy:		14.57 %
Epoch 138 of 2000 took 0.096s
  training loss:		2.294839
  validation loss:		2.243212
  validation accuracy:		13.15 %
Epoch 139 of 2000 took 0.096s
  training loss:		2.295414
  validation loss:		2.243402
  validation accuracy:		18.37 %
Epoch 140 of 2000 took 0.097s
  training loss:		2.295387
  validation loss:		2.242410
  validation accuracy:		17.17 %
Epoch 141 of 2000 took 0.096s
  training loss:		2.294999
  validation loss:		2.243120
  validation accuracy:		14.67 %
Epoch 142 of 2000 took 0.096s
  training loss:		2.295925
  validation loss:		2.244772
  validation accuracy:		12.93 %
Epoch 143 of 2000 took 0.099s
  training loss:		2.294770
  validation loss:		2.245131
  validation accuracy:		14.57 %
Epoch 144 of 2000 took 0.098s
  training loss:		2.293942
  validation loss:		2.244587
  validation accuracy:		13.04 %
Epoch 145 of 2000 took 0.096s
  training loss:		2.294403
  validation loss:		2.243741
  validation accuracy:		13.04 %
Epoch 146 of 2000 took 0.096s
  training loss:		2.294663
  validation loss:		2.244438
  validation accuracy:		13.15 %
Epoch 147 of 2000 took 0.096s
  training loss:		2.294127
  validation loss:		2.242565
  validation accuracy:		13.80 %
Epoch 148 of 2000 took 0.096s
  training loss:		2.294814
  validation loss:		2.241524
  validation accuracy:		14.46 %
Epoch 149 of 2000 took 0.096s
  training loss:		2.294577
  validation loss:		2.242003
  validation accuracy:		11.96 %
Epoch 150 of 2000 took 0.096s
  training loss:		2.294056
  validation loss:		2.242405
  validation accuracy:		12.93 %
Epoch 151 of 2000 took 0.096s
  training loss:		2.294559
  validation loss:		2.241789
  validation accuracy:		14.35 %
Epoch 152 of 2000 took 0.096s
  training loss:		2.293765
  validation loss:		2.242100
  validation accuracy:		15.00 %
Epoch 153 of 2000 took 0.096s
  training loss:		2.294226
  validation loss:		2.241636
  validation accuracy:		15.65 %
Epoch 154 of 2000 took 0.101s
  training loss:		2.294450
  validation loss:		2.243250
  validation accuracy:		17.50 %
Epoch 155 of 2000 took 0.096s
  training loss:		2.294728
  validation loss:		2.244649
  validation accuracy:		14.13 %
Epoch 156 of 2000 took 0.096s
  training loss:		2.294309
  validation loss:		2.244287
  validation accuracy:		11.96 %
Epoch 157 of 2000 took 0.096s
  training loss:		2.294451
  validation loss:		2.243451
  validation accuracy:		12.83 %
Epoch 158 of 2000 took 0.096s
  training loss:		2.293883
  validation loss:		2.242991
  validation accuracy:		13.15 %
Epoch 159 of 2000 took 0.096s
  training loss:		2.294726
  validation loss:		2.242514
  validation accuracy:		12.93 %
Epoch 160 of 2000 took 0.096s
  training loss:		2.294247
  validation loss:		2.243028
  validation accuracy:		14.02 %
Epoch 161 of 2000 took 0.096s
  training loss:		2.294677
  validation loss:		2.244286
  validation accuracy:		12.50 %
Epoch 162 of 2000 took 0.096s
  training loss:		2.293243
  validation loss:		2.243054
  validation accuracy:		13.04 %
Epoch 163 of 2000 took 0.096s
  training loss:		2.293545
  validation loss:		2.242001
  validation accuracy:		13.04 %
Epoch 164 of 2000 took 0.101s
  training loss:		2.294258
  validation loss:		2.242632
  validation accuracy:		12.93 %
Epoch 165 of 2000 took 0.097s
  training loss:		2.293611
  validation loss:		2.242298
  validation accuracy:		15.65 %
Epoch 166 of 2000 took 0.096s
  training loss:		2.293532
  validation loss:		2.242726
  validation accuracy:		14.02 %
Epoch 167 of 2000 took 0.096s
  training loss:		2.294701
  validation loss:		2.243602
  validation accuracy:		15.11 %
Epoch 168 of 2000 took 0.096s
  training loss:		2.294750
  validation loss:		2.245293
  validation accuracy:		16.30 %
Epoch 169 of 2000 took 0.096s
  training loss:		2.292977
  validation loss:		2.244778
  validation accuracy:		13.04 %
Epoch 170 of 2000 took 0.096s
  training loss:		2.293980
  validation loss:		2.244203
  validation accuracy:		12.93 %
Epoch 171 of 2000 took 0.097s
  training loss:		2.292795
  validation loss:		2.241728
  validation accuracy:		13.04 %
Epoch 172 of 2000 took 0.096s
  training loss:		2.293022
  validation loss:		2.241840
  validation accuracy:		12.93 %
Epoch 173 of 2000 took 0.096s
  training loss:		2.293353
  validation loss:		2.242369
  validation accuracy:		11.74 %
Epoch 174 of 2000 took 0.100s
  training loss:		2.294430
  validation loss:		2.242462
  validation accuracy:		13.04 %
Epoch 175 of 2000 took 0.098s
  training loss:		2.294109
  validation loss:		2.243104
  validation accuracy:		12.93 %
Epoch 176 of 2000 took 0.096s
  training loss:		2.293224
  validation loss:		2.241950
  validation accuracy:		13.15 %
Epoch 177 of 2000 took 0.096s
  training loss:		2.293468
  validation loss:		2.240447
  validation accuracy:		15.76 %
Epoch 178 of 2000 took 0.097s
  training loss:		2.293005
  validation loss:		2.240549
  validation accuracy:		16.20 %
Epoch 179 of 2000 took 0.100s
  training loss:		2.292487
  validation loss:		2.239583
  validation accuracy:		12.83 %
Epoch 180 of 2000 took 0.099s
  training loss:		2.293548
  validation loss:		2.241741
  validation accuracy:		13.04 %
Epoch 181 of 2000 took 0.099s
  training loss:		2.292754
  validation loss:		2.240741
  validation accuracy:		13.15 %
Epoch 182 of 2000 took 0.099s
  training loss:		2.293378
  validation loss:		2.242391
  validation accuracy:		13.91 %
Epoch 183 of 2000 took 0.099s
  training loss:		2.292728
  validation loss:		2.241459
  validation accuracy:		13.04 %
Epoch 184 of 2000 took 0.099s
  training loss:		2.294062
  validation loss:		2.241473
  validation accuracy:		12.28 %
Epoch 185 of 2000 took 0.104s
  training loss:		2.292649
  validation loss:		2.241169
  validation accuracy:		12.07 %
Epoch 186 of 2000 took 0.099s
  training loss:		2.293360
  validation loss:		2.241701
  validation accuracy:		12.93 %
Epoch 187 of 2000 took 0.099s
  training loss:		2.293023
  validation loss:		2.240622
  validation accuracy:		13.48 %
Epoch 188 of 2000 took 0.099s
  training loss:		2.293689
  validation loss:		2.240751
  validation accuracy:		13.15 %
Epoch 189 of 2000 took 0.099s
  training loss:		2.292957
  validation loss:		2.242563
  validation accuracy:		13.48 %
Epoch 190 of 2000 took 0.099s
  training loss:		2.293172
  validation loss:		2.241857
  validation accuracy:		15.22 %
Epoch 191 of 2000 took 0.099s
  training loss:		2.292131
  validation loss:		2.243067
  validation accuracy:		13.15 %
Epoch 192 of 2000 took 0.099s
  training loss:		2.293187
  validation loss:		2.242520
  validation accuracy:		13.04 %
Epoch 193 of 2000 took 0.099s
  training loss:		2.293998
  validation loss:		2.243113
  validation accuracy:		13.15 %
Epoch 194 of 2000 took 0.099s
  training loss:		2.292971
  validation loss:		2.242757
  validation accuracy:		18.26 %
Epoch 195 of 2000 took 0.104s
  training loss:		2.292879
  validation loss:		2.242922
  validation accuracy:		13.15 %
Epoch 196 of 2000 took 0.099s
  training loss:		2.293023
  validation loss:		2.241944
  validation accuracy:		13.26 %
Epoch 197 of 2000 took 0.099s
  training loss:		2.292689
  validation loss:		2.241429
  validation accuracy:		13.15 %
Epoch 198 of 2000 took 0.099s
  training loss:		2.293962
  validation loss:		2.243596
  validation accuracy:		13.04 %
Epoch 199 of 2000 took 0.099s
  training loss:		2.293504
  validation loss:		2.244483
  validation accuracy:		13.15 %
Epoch 200 of 2000 took 0.099s
  training loss:		2.293205
  validation loss:		2.243900
  validation accuracy:		13.04 %
Epoch 201 of 2000 took 0.099s
  training loss:		2.293160
  validation loss:		2.242976
  validation accuracy:		14.35 %
Epoch 202 of 2000 took 0.100s
  training loss:		2.292581
  validation loss:		2.241774
  validation accuracy:		14.35 %
Epoch 203 of 2000 took 0.100s
  training loss:		2.292610
  validation loss:		2.241251
  validation accuracy:		13.04 %
Epoch 204 of 2000 took 0.099s
  training loss:		2.293157
  validation loss:		2.241333
  validation accuracy:		13.48 %
Epoch 205 of 2000 took 0.104s
  training loss:		2.292868
  validation loss:		2.242822
  validation accuracy:		13.91 %
Epoch 206 of 2000 took 0.099s
  training loss:		2.292427
  validation loss:		2.242960
  validation accuracy:		13.26 %
Epoch 207 of 2000 took 0.099s
  training loss:		2.292983
  validation loss:		2.242821
  validation accuracy:		13.15 %
Epoch 208 of 2000 took 0.099s
  training loss:		2.291959
  validation loss:		2.239492
  validation accuracy:		14.46 %
Epoch 209 of 2000 took 0.099s
  training loss:		2.292299
  validation loss:		2.238914
  validation accuracy:		15.33 %
Epoch 210 of 2000 took 0.099s
  training loss:		2.293660
  validation loss:		2.241528
  validation accuracy:		18.91 %
Epoch 211 of 2000 took 0.099s
  training loss:		2.292225
  validation loss:		2.242437
  validation accuracy:		12.93 %
Epoch 212 of 2000 took 0.099s
  training loss:		2.293184
  validation loss:		2.240228
  validation accuracy:		13.15 %
Epoch 213 of 2000 took 0.100s
  training loss:		2.292240
  validation loss:		2.242537
  validation accuracy:		13.04 %
Epoch 214 of 2000 took 0.099s
  training loss:		2.292435
  validation loss:		2.243129
  validation accuracy:		14.67 %
Epoch 215 of 2000 took 0.104s
  training loss:		2.292037
  validation loss:		2.242125
  validation accuracy:		13.04 %
Epoch 216 of 2000 took 0.099s
  training loss:		2.293011
  validation loss:		2.240510
  validation accuracy:		13.59 %
Epoch 217 of 2000 took 0.099s
  training loss:		2.291515
  validation loss:		2.241408
  validation accuracy:		13.04 %
Epoch 218 of 2000 took 0.099s
  training loss:		2.291948
  validation loss:		2.240027
  validation accuracy:		13.26 %
Epoch 219 of 2000 took 0.096s
  training loss:		2.291401
  validation loss:		2.238873
  validation accuracy:		13.91 %
Epoch 220 of 2000 took 0.096s
  training loss:		2.292042
  validation loss:		2.239912
  validation accuracy:		13.15 %
Epoch 221 of 2000 took 0.096s
  training loss:		2.292116
  validation loss:		2.240176
  validation accuracy:		17.17 %
Epoch 222 of 2000 took 0.096s
  training loss:		2.291800
  validation loss:		2.239222
  validation accuracy:		18.37 %
Epoch 223 of 2000 took 0.096s
  training loss:		2.291959
  validation loss:		2.238892
  validation accuracy:		19.78 %
Epoch 224 of 2000 took 0.096s
  training loss:		2.292741
  validation loss:		2.239816
  validation accuracy:		12.17 %
Epoch 225 of 2000 took 0.101s
  training loss:		2.291053
  validation loss:		2.241513
  validation accuracy:		12.93 %
Epoch 226 of 2000 took 0.096s
  training loss:		2.291715
  validation loss:		2.241249
  validation accuracy:		13.04 %
Epoch 227 of 2000 took 0.096s
  training loss:		2.292447
  validation loss:		2.240864
  validation accuracy:		14.89 %
Epoch 228 of 2000 took 0.096s
  training loss:		2.291125
  validation loss:		2.239731
  validation accuracy:		20.00 %
Epoch 229 of 2000 took 0.096s
  training loss:		2.292166
  validation loss:		2.239558
  validation accuracy:		20.22 %
Epoch 230 of 2000 took 0.096s
  training loss:		2.291900
  validation loss:		2.240008
  validation accuracy:		16.41 %
Epoch 231 of 2000 took 0.096s
  training loss:		2.291321
  validation loss:		2.239876
  validation accuracy:		13.04 %
Epoch 232 of 2000 took 0.097s
  training loss:		2.291296
  validation loss:		2.239975
  validation accuracy:		13.26 %
Epoch 233 of 2000 took 0.096s
  training loss:		2.292134
  validation loss:		2.241593
  validation accuracy:		13.04 %
Epoch 234 of 2000 took 0.096s
  training loss:		2.290486
  validation loss:		2.238490
  validation accuracy:		12.93 %
Epoch 235 of 2000 took 0.101s
  training loss:		2.291686
  validation loss:		2.237117
  validation accuracy:		13.04 %
Epoch 236 of 2000 took 0.096s
  training loss:		2.291096
  validation loss:		2.237257
  validation accuracy:		13.91 %
Epoch 237 of 2000 took 0.096s
  training loss:		2.290928
  validation loss:		2.236955
  validation accuracy:		13.15 %
Epoch 238 of 2000 took 0.096s
  training loss:		2.291066
  validation loss:		2.238443
  validation accuracy:		13.04 %
Epoch 239 of 2000 took 0.096s
  training loss:		2.291778
  validation loss:		2.241465
  validation accuracy:		13.26 %
Epoch 240 of 2000 took 0.096s
  training loss:		2.290923
  validation loss:		2.239173
  validation accuracy:		15.33 %
Epoch 241 of 2000 took 0.096s
  training loss:		2.290950
  validation loss:		2.238736
  validation accuracy:		16.74 %
Epoch 242 of 2000 took 0.096s
  training loss:		2.291620
  validation loss:		2.239395
  validation accuracy:		13.04 %
Epoch 243 of 2000 took 0.096s
  training loss:		2.291135
  validation loss:		2.239828
  validation accuracy:		13.15 %
Epoch 244 of 2000 took 0.096s
  training loss:		2.290867
  validation loss:		2.239526
  validation accuracy:		13.37 %
Epoch 245 of 2000 took 0.098s
  training loss:		2.290256
  validation loss:		2.238684
  validation accuracy:		13.04 %
Epoch 246 of 2000 took 0.099s
  training loss:		2.290329
  validation loss:		2.238981
  validation accuracy:		15.11 %
Epoch 247 of 2000 took 0.096s
  training loss:		2.290999
  validation loss:		2.237805
  validation accuracy:		13.15 %
Epoch 248 of 2000 took 0.096s
  training loss:		2.291034
  validation loss:		2.236478
  validation accuracy:		13.04 %
Epoch 249 of 2000 took 0.096s
  training loss:		2.291687
  validation loss:		2.240424
  validation accuracy:		14.46 %
Epoch 250 of 2000 took 0.096s
  training loss:		2.291677
  validation loss:		2.240240
  validation accuracy:		13.26 %
Epoch 251 of 2000 took 0.096s
  training loss:		2.290850
  validation loss:		2.238122
  validation accuracy:		15.65 %
Epoch 252 of 2000 took 0.096s
  training loss:		2.291127
  validation loss:		2.239544
  validation accuracy:		16.52 %
Epoch 253 of 2000 took 0.096s
  training loss:		2.290472
  validation loss:		2.240207
  validation accuracy:		17.28 %
Epoch 254 of 2000 took 0.096s
  training loss:		2.290599
  validation loss:		2.240556
  validation accuracy:		15.11 %
Epoch 255 of 2000 took 0.096s
  training loss:		2.290101
  validation loss:		2.238530
  validation accuracy:		16.74 %
Epoch 256 of 2000 took 0.101s
  training loss:		2.290660
  validation loss:		2.237617
  validation accuracy:		13.26 %
Epoch 257 of 2000 took 0.096s
  training loss:		2.290473
  validation loss:		2.237786
  validation accuracy:		13.04 %
Epoch 258 of 2000 took 0.096s
  training loss:		2.290102
  validation loss:		2.237489
  validation accuracy:		13.59 %
Epoch 259 of 2000 took 0.096s
  training loss:		2.290192
  validation loss:		2.236043
  validation accuracy:		13.26 %
Epoch 260 of 2000 took 0.096s
  training loss:		2.289932
  validation loss:		2.237982
  validation accuracy:		12.83 %
Epoch 261 of 2000 took 0.096s
  training loss:		2.290278
  validation loss:		2.239242
  validation accuracy:		13.04 %
Epoch 262 of 2000 took 0.096s
  training loss:		2.290483
  validation loss:		2.240137
  validation accuracy:		12.93 %
Epoch 263 of 2000 took 0.097s
  training loss:		2.289741
  validation loss:		2.238383
  validation accuracy:		13.26 %
Epoch 264 of 2000 took 0.096s
  training loss:		2.290941
  validation loss:		2.238131
  validation accuracy:		15.76 %
Epoch 265 of 2000 took 0.096s
  training loss:		2.290740
  validation loss:		2.239288
  validation accuracy:		18.48 %
Epoch 266 of 2000 took 0.101s
  training loss:		2.290265
  validation loss:		2.238833
  validation accuracy:		13.04 %
Epoch 267 of 2000 took 0.097s
  training loss:		2.289322
  validation loss:		2.237876
  validation accuracy:		13.04 %
Epoch 268 of 2000 took 0.096s
  training loss:		2.289095
  validation loss:		2.236053
  validation accuracy:		13.04 %
Epoch 269 of 2000 took 0.096s
  training loss:		2.289657
  validation loss:		2.233626
  validation accuracy:		13.15 %
Epoch 270 of 2000 took 0.096s
  training loss:		2.289639
  validation loss:		2.236572
  validation accuracy:		13.70 %
Epoch 271 of 2000 took 0.096s
  training loss:		2.290127
  validation loss:		2.237621
  validation accuracy:		16.09 %
Epoch 272 of 2000 took 0.096s
  training loss:		2.289281
  validation loss:		2.237089
  validation accuracy:		12.83 %
Epoch 273 of 2000 took 0.096s
  training loss:		2.289329
  validation loss:		2.237100
  validation accuracy:		13.48 %
Epoch 274 of 2000 took 0.096s
  training loss:		2.289844
  validation loss:		2.238806
  validation accuracy:		13.15 %
Epoch 275 of 2000 took 0.096s
  training loss:		2.289979
  validation loss:		2.236741
  validation accuracy:		13.48 %
Epoch 276 of 2000 took 0.098s
  training loss:		2.290542
  validation loss:		2.240852
  validation accuracy:		15.65 %
Epoch 277 of 2000 took 0.099s
  training loss:		2.289597
  validation loss:		2.240203
  validation accuracy:		13.70 %
Epoch 278 of 2000 took 0.096s
  training loss:		2.289967
  validation loss:		2.236945
  validation accuracy:		12.93 %
Epoch 279 of 2000 took 0.096s
  training loss:		2.289371
  validation loss:		2.237726
  validation accuracy:		13.15 %
Epoch 280 of 2000 took 0.097s
  training loss:		2.289114
  validation loss:		2.234046
  validation accuracy:		13.15 %
Epoch 281 of 2000 took 0.096s
  training loss:		2.289508
  validation loss:		2.236557
  validation accuracy:		15.11 %
Epoch 282 of 2000 took 0.096s
  training loss:		2.289170
  validation loss:		2.237450
  validation accuracy:		13.91 %
Epoch 283 of 2000 took 0.096s
  training loss:		2.289001
  validation loss:		2.237754
  validation accuracy:		12.83 %
Epoch 284 of 2000 took 0.096s
  training loss:		2.288665
  validation loss:		2.236656
  validation accuracy:		12.93 %
Epoch 285 of 2000 took 0.096s
  training loss:		2.287819
  validation loss:		2.234037
  validation accuracy:		13.15 %
Epoch 286 of 2000 took 0.096s
  training loss:		2.288558
  validation loss:		2.234567
  validation accuracy:		13.59 %
Epoch 287 of 2000 took 0.107s
  training loss:		2.288800
  validation loss:		2.236783
  validation accuracy:		13.70 %
Epoch 288 of 2000 took 0.096s
  training loss:		2.288884
  validation loss:		2.237286
  validation accuracy:		13.59 %
Epoch 289 of 2000 took 0.096s
  training loss:		2.289590
  validation loss:		2.238201
  validation accuracy:		13.04 %
Epoch 290 of 2000 took 0.096s
  training loss:		2.288677
  validation loss:		2.237284
  validation accuracy:		14.24 %
Epoch 291 of 2000 took 0.096s
  training loss:		2.287826
  validation loss:		2.235645
  validation accuracy:		13.04 %
Epoch 292 of 2000 took 0.096s
  training loss:		2.288595
  validation loss:		2.233221
  validation accuracy:		12.93 %
Epoch 293 of 2000 took 0.096s
  training loss:		2.288430
  validation loss:		2.235964
  validation accuracy:		13.26 %
Epoch 294 of 2000 took 0.097s
  training loss:		2.288243
  validation loss:		2.235709
  validation accuracy:		15.00 %
Epoch 295 of 2000 took 0.096s
  training loss:		2.288049
  validation loss:		2.236574
  validation accuracy:		13.15 %
Epoch 296 of 2000 took 0.096s
  training loss:		2.287517
  validation loss:		2.234167
  validation accuracy:		13.48 %
Epoch 297 of 2000 took 0.099s
  training loss:		2.288536
  validation loss:		2.234900
  validation accuracy:		14.67 %
Epoch 298 of 2000 took 0.096s
  training loss:		2.287824
  validation loss:		2.234978
  validation accuracy:		13.59 %
Epoch 299 of 2000 took 0.096s
  training loss:		2.287549
  validation loss:		2.235466
  validation accuracy:		13.26 %
Epoch 300 of 2000 took 0.096s
  training loss:		2.286985
  validation loss:		2.237009
  validation accuracy:		13.26 %
Epoch 301 of 2000 took 0.096s
  training loss:		2.287429
  validation loss:		2.235423
  validation accuracy:		14.78 %
Epoch 302 of 2000 took 0.096s
  training loss:		2.287708
  validation loss:		2.234809
  validation accuracy:		13.48 %
Epoch 303 of 2000 took 0.096s
  training loss:		2.287063
  validation loss:		2.234111
  validation accuracy:		12.93 %
Epoch 304 of 2000 took 0.096s
  training loss:		2.288309
  validation loss:		2.237615
  validation accuracy:		17.93 %
Epoch 305 of 2000 took 0.096s
  training loss:		2.287258
  validation loss:		2.235973
  validation accuracy:		17.07 %
Epoch 306 of 2000 took 0.096s
  training loss:		2.287150
  validation loss:		2.233718
  validation accuracy:		14.35 %
Epoch 307 of 2000 took 0.097s
  training loss:		2.286001
  validation loss:		2.232713
  validation accuracy:		13.04 %
Epoch 308 of 2000 took 0.098s
  training loss:		2.286346
  validation loss:		2.232804
  validation accuracy:		12.61 %
Epoch 309 of 2000 took 0.096s
  training loss:		2.286604
  validation loss:		2.232610
  validation accuracy:		13.70 %
Epoch 310 of 2000 took 0.096s
  training loss:		2.287078
  validation loss:		2.234786
  validation accuracy:		13.59 %
Epoch 311 of 2000 took 0.096s
  training loss:		2.286703
  validation loss:		2.234990
  validation accuracy:		13.48 %
Epoch 312 of 2000 took 0.096s
  training loss:		2.286707
  validation loss:		2.234236
  validation accuracy:		14.13 %
Epoch 313 of 2000 took 0.096s
  training loss:		2.287237
  validation loss:		2.235710
  validation accuracy:		14.35 %
Epoch 314 of 2000 took 0.096s
  training loss:		2.285886
  validation loss:		2.233847
  validation accuracy:		13.15 %
Epoch 315 of 2000 took 0.096s
  training loss:		2.285827
  validation loss:		2.233892
  validation accuracy:		13.15 %
Epoch 316 of 2000 took 0.096s
  training loss:		2.286239
  validation loss:		2.231264
  validation accuracy:		15.00 %
Epoch 317 of 2000 took 0.096s
  training loss:		2.285749
  validation loss:		2.232317
  validation accuracy:		13.70 %
Epoch 318 of 2000 took 0.099s
  training loss:		2.286980
  validation loss:		2.233174
  validation accuracy:		13.26 %
Epoch 319 of 2000 took 0.096s
  training loss:		2.286922
  validation loss:		2.236031
  validation accuracy:		13.15 %
Epoch 320 of 2000 took 0.096s
  training loss:		2.286152
  validation loss:		2.236664
  validation accuracy:		13.48 %
Epoch 321 of 2000 took 0.096s
  training loss:		2.285428
  validation loss:		2.235400
  validation accuracy:		14.24 %
Epoch 322 of 2000 took 0.096s
  training loss:		2.284901
  validation loss:		2.232028
  validation accuracy:		16.41 %
Epoch 323 of 2000 took 0.096s
  training loss:		2.285592
  validation loss:		2.231254
  validation accuracy:		16.74 %
Epoch 324 of 2000 took 0.096s
  training loss:		2.284905
  validation loss:		2.230629
  validation accuracy:		14.57 %
Epoch 325 of 2000 took 0.096s
  training loss:		2.284287
  validation loss:		2.229952
  validation accuracy:		14.24 %
Epoch 326 of 2000 took 0.097s
  training loss:		2.283984
  validation loss:		2.231811
  validation accuracy:		13.48 %
Epoch 327 of 2000 took 0.096s
  training loss:		2.284063
  validation loss:		2.230078
  validation accuracy:		13.59 %
Epoch 328 of 2000 took 0.096s
  training loss:		2.284038
  validation loss:		2.229121
  validation accuracy:		14.46 %
Epoch 329 of 2000 took 0.096s
  training loss:		2.284525
  validation loss:		2.229421
  validation accuracy:		14.57 %
Epoch 330 of 2000 took 0.098s
  training loss:		2.282951
  validation loss:		2.232030
  validation accuracy:		15.54 %
Epoch 331 of 2000 took 0.096s
  training loss:		2.284426
  validation loss:		2.230393
  validation accuracy:		16.52 %
Epoch 332 of 2000 took 0.096s
  training loss:		2.283062
  validation loss:		2.229821
  validation accuracy:		13.91 %
Epoch 333 of 2000 took 0.096s
  training loss:		2.283053
  validation loss:		2.227413
  validation accuracy:		13.04 %
Epoch 334 of 2000 took 0.096s
  training loss:		2.282809
  validation loss:		2.226674
  validation accuracy:		14.13 %
Epoch 335 of 2000 took 0.096s
  training loss:		2.282345
  validation loss:		2.228103
  validation accuracy:		13.15 %
Epoch 336 of 2000 took 0.096s
  training loss:		2.282279
  validation loss:		2.228030
  validation accuracy:		14.57 %
Epoch 337 of 2000 took 0.096s
  training loss:		2.281391
  validation loss:		2.229056
  validation accuracy:		13.91 %
Epoch 338 of 2000 took 0.096s
  training loss:		2.282017
  validation loss:		2.227081
  validation accuracy:		13.59 %
Epoch 339 of 2000 took 0.096s
  training loss:		2.282869
  validation loss:		2.227787
  validation accuracy:		15.11 %
Epoch 340 of 2000 took 0.096s
  training loss:		2.281648
  validation loss:		2.228750
  validation accuracy:		13.70 %
Epoch 341 of 2000 took 0.096s
  training loss:		2.281373
  validation loss:		2.227549
  validation accuracy:		14.67 %
Epoch 342 of 2000 took 0.096s
  training loss:		2.282384
  validation loss:		2.227481
  validation accuracy:		16.09 %
Epoch 343 of 2000 took 0.096s
  training loss:		2.280980
  validation loss:		2.227021
  validation accuracy:		14.67 %
Epoch 344 of 2000 took 0.096s
  training loss:		2.280829
  validation loss:		2.226028
  validation accuracy:		13.70 %
Epoch 345 of 2000 took 0.098s
  training loss:		2.279825
  validation loss:		2.225851
  validation accuracy:		14.67 %
Epoch 346 of 2000 took 0.096s
  training loss:		2.279960
  validation loss:		2.225470
  validation accuracy:		14.24 %
Epoch 347 of 2000 took 0.096s
  training loss:		2.279985
  validation loss:		2.224391
  validation accuracy:		13.37 %
Epoch 348 of 2000 took 0.096s
  training loss:		2.279759
  validation loss:		2.226780
  validation accuracy:		13.48 %
Epoch 349 of 2000 took 0.096s
  training loss:		2.279905
  validation loss:		2.225944
  validation accuracy:		15.22 %
Epoch 350 of 2000 took 0.096s
  training loss:		2.279609
  validation loss:		2.225233
  validation accuracy:		15.00 %
Epoch 351 of 2000 took 0.096s
  training loss:		2.279102
  validation loss:		2.225780
  validation accuracy:		14.13 %
Epoch 352 of 2000 took 0.096s
  training loss:		2.278839
  validation loss:		2.226322
  validation accuracy:		15.00 %
Epoch 353 of 2000 took 0.096s
  training loss:		2.277888
  validation loss:		2.225130
  validation accuracy:		13.48 %
Epoch 354 of 2000 took 0.096s
  training loss:		2.278564
  validation loss:		2.222810
  validation accuracy:		15.22 %
Epoch 355 of 2000 took 0.096s
  training loss:		2.276978
  validation loss:		2.221685
  validation accuracy:		17.39 %
Epoch 356 of 2000 took 0.096s
  training loss:		2.277867
  validation loss:		2.222486
  validation accuracy:		13.15 %
Epoch 357 of 2000 took 0.097s
  training loss:		2.278021
  validation loss:		2.222378
  validation accuracy:		14.13 %
Epoch 358 of 2000 took 0.096s
  training loss:		2.277839
  validation loss:		2.224577
  validation accuracy:		17.93 %
Epoch 359 of 2000 took 0.096s
  training loss:		2.275602
  validation loss:		2.221921
  validation accuracy:		15.54 %
Epoch 360 of 2000 took 0.096s
  training loss:		2.275818
  validation loss:		2.220979
  validation accuracy:		13.80 %
Epoch 361 of 2000 took 0.096s
  training loss:		2.275976
  validation loss:		2.219575
  validation accuracy:		15.65 %
Epoch 362 of 2000 took 0.096s
  training loss:		2.274710
  validation loss:		2.215580
  validation accuracy:		14.35 %
Epoch 363 of 2000 took 0.098s
  training loss:		2.274558
  validation loss:		2.218371
  validation accuracy:		15.54 %
Epoch 364 of 2000 took 0.096s
  training loss:		2.273980
  validation loss:		2.219952
  validation accuracy:		15.43 %
Epoch 365 of 2000 took 0.096s
  training loss:		2.274676
  validation loss:		2.219280
  validation accuracy:		15.54 %
Epoch 366 of 2000 took 0.096s
  training loss:		2.272895
  validation loss:		2.218071
  validation accuracy:		15.76 %
Epoch 367 of 2000 took 0.096s
  training loss:		2.272694
  validation loss:		2.218258
  validation accuracy:		18.15 %
Epoch 368 of 2000 took 0.096s
  training loss:		2.271527
  validation loss:		2.217035
  validation accuracy:		15.65 %
Epoch 369 of 2000 took 0.096s
  training loss:		2.269964
  validation loss:		2.215688
  validation accuracy:		15.11 %
Epoch 370 of 2000 took 0.096s
  training loss:		2.271328
  validation loss:		2.212761
  validation accuracy:		14.57 %
Epoch 371 of 2000 took 0.096s
  training loss:		2.270205
  validation loss:		2.211830
  validation accuracy:		15.33 %
Epoch 372 of 2000 took 0.096s
  training loss:		2.268142
  validation loss:		2.210741
  validation accuracy:		16.85 %
Epoch 373 of 2000 took 0.096s
  training loss:		2.269239
  validation loss:		2.210504
  validation accuracy:		17.93 %
Epoch 374 of 2000 took 0.096s
  training loss:		2.268133
  validation loss:		2.211248
  validation accuracy:		17.07 %
Epoch 375 of 2000 took 0.096s
  training loss:		2.267336
  validation loss:		2.211793
  validation accuracy:		17.28 %
Epoch 376 of 2000 took 0.096s
  training loss:		2.266177
  validation loss:		2.209634
  validation accuracy:		16.09 %
Epoch 377 of 2000 took 0.097s
  training loss:		2.265846
  validation loss:		2.208106
  validation accuracy:		14.67 %
Epoch 378 of 2000 took 0.096s
  training loss:		2.263580
  validation loss:		2.208141
  validation accuracy:		16.74 %
Epoch 379 of 2000 took 0.096s
  training loss:		2.262140
  validation loss:		2.205693
  validation accuracy:		18.15 %
Epoch 380 of 2000 took 0.096s
  training loss:		2.261198
  validation loss:		2.202601
  validation accuracy:		18.26 %
Epoch 381 of 2000 took 0.096s
  training loss:		2.261343
  validation loss:		2.201665
  validation accuracy:		18.37 %
Epoch 382 of 2000 took 0.096s
  training loss:		2.259428
  validation loss:		2.202239
  validation accuracy:		17.28 %
Epoch 383 of 2000 took 0.096s
  training loss:		2.256992
  validation loss:		2.200645
  validation accuracy:		18.37 %
Epoch 384 of 2000 took 0.096s
  training loss:		2.255869
  validation loss:		2.197295
  validation accuracy:		18.37 %
Epoch 385 of 2000 took 0.099s
  training loss:		2.254474
  validation loss:		2.196516
  validation accuracy:		18.37 %
Epoch 386 of 2000 took 0.096s
  training loss:		2.251583
  validation loss:		2.193601
  validation accuracy:		18.70 %
Epoch 387 of 2000 took 0.096s
  training loss:		2.249765
  validation loss:		2.190964
  validation accuracy:		18.80 %
Epoch 388 of 2000 took 0.097s
  training loss:		2.246204
  validation loss:		2.187401
  validation accuracy:		18.37 %
Epoch 389 of 2000 took 0.096s
  training loss:		2.244204
  validation loss:		2.183507
  validation accuracy:		18.48 %
Epoch 390 of 2000 took 0.096s
  training loss:		2.241288
  validation loss:		2.180760
  validation accuracy:		19.24 %
Epoch 391 of 2000 took 0.096s
  training loss:		2.237429
  validation loss:		2.176918
  validation accuracy:		20.54 %
Epoch 392 of 2000 took 0.096s
  training loss:		2.234435
  validation loss:		2.172959
  validation accuracy:		20.76 %
Epoch 393 of 2000 took 0.096s
  training loss:		2.229521
  validation loss:		2.166816
  validation accuracy:		21.63 %
Epoch 394 of 2000 took 0.096s
  training loss:		2.222786
  validation loss:		2.162784
  validation accuracy:		20.87 %
Epoch 395 of 2000 took 0.096s
  training loss:		2.215840
  validation loss:		2.154366
  validation accuracy:		21.52 %
Epoch 396 of 2000 took 0.096s
  training loss:		2.210775
  validation loss:		2.147492
  validation accuracy:		22.50 %
Epoch 397 of 2000 took 0.096s
  training loss:		2.200022
  validation loss:		2.137845
  validation accuracy:		22.72 %
Epoch 398 of 2000 took 0.096s
  training loss:		2.194012
  validation loss:		2.127615
  validation accuracy:		22.93 %
Epoch 399 of 2000 took 0.096s
  training loss:		2.182384
  validation loss:		2.114785
  validation accuracy:		23.15 %
Epoch 400 of 2000 took 0.096s
  training loss:		2.169869
  validation loss:		2.101227
  validation accuracy:		23.26 %
Epoch 401 of 2000 took 0.096s
  training loss:		2.156882
  validation loss:		2.086763
  validation accuracy:		23.37 %
Epoch 402 of 2000 took 0.096s
  training loss:		2.142732
  validation loss:		2.070394
  validation accuracy:		23.59 %
Epoch 403 of 2000 took 0.096s
  training loss:		2.127534
  validation loss:		2.052980
  validation accuracy:		23.70 %
Epoch 404 of 2000 took 0.096s
  training loss:		2.113962
  validation loss:		2.035976
  validation accuracy:		24.24 %
Epoch 405 of 2000 took 0.096s
  training loss:		2.098299
  validation loss:		2.017604
  validation accuracy:		24.13 %
Epoch 406 of 2000 took 0.096s
  training loss:		2.081707
  validation loss:		2.000558
  validation accuracy:		24.35 %
Epoch 407 of 2000 took 0.096s
  training loss:		2.062179
  validation loss:		1.981546
  validation accuracy:		24.02 %
Epoch 408 of 2000 took 0.096s
  training loss:		2.050689
  validation loss:		1.965749
  validation accuracy:		24.78 %
Epoch 409 of 2000 took 0.096s
  training loss:		2.037663
  validation loss:		1.950253
  validation accuracy:		25.00 %
Epoch 410 of 2000 took 0.096s
  training loss:		2.022979
  validation loss:		1.934539
  validation accuracy:		25.22 %
Epoch 411 of 2000 took 0.098s
  training loss:		2.008450
  validation loss:		1.922326
  validation accuracy:		26.63 %
Epoch 412 of 2000 took 0.096s
  training loss:		2.002211
  validation loss:		1.906467
  validation accuracy:		25.65 %
Epoch 413 of 2000 took 0.096s
  training loss:		1.988419
  validation loss:		1.894005
  validation accuracy:		27.07 %
Epoch 414 of 2000 took 0.096s
  training loss:		1.976388
  validation loss:		1.879842
  validation accuracy:		27.28 %
Epoch 415 of 2000 took 0.096s
  training loss:		1.965992
  validation loss:		1.866860
  validation accuracy:		27.61 %
Epoch 416 of 2000 took 0.096s
  training loss:		1.949353
  validation loss:		1.852527
  validation accuracy:		28.26 %
Epoch 417 of 2000 took 0.096s
  training loss:		1.937749
  validation loss:		1.837844
  validation accuracy:		28.91 %
Epoch 418 of 2000 took 0.096s
  training loss:		1.921334
  validation loss:		1.823418
  validation accuracy:		29.24 %
Epoch 419 of 2000 took 0.096s
  training loss:		1.908554
  validation loss:		1.808653
  validation accuracy:		29.67 %
Epoch 420 of 2000 took 0.097s
  training loss:		1.894230
  validation loss:		1.793858
  validation accuracy:		30.65 %
Epoch 421 of 2000 took 0.096s
  training loss:		1.880106
  validation loss:		1.778266
  validation accuracy:		30.87 %
Epoch 422 of 2000 took 0.096s
  training loss:		1.865390
  validation loss:		1.763190
  validation accuracy:		32.17 %
Epoch 423 of 2000 took 0.096s
  training loss:		1.848774
  validation loss:		1.746645
  validation accuracy:		30.98 %
Epoch 424 of 2000 took 0.096s
  training loss:		1.835783
  validation loss:		1.729922
  validation accuracy:		32.17 %
Epoch 425 of 2000 took 0.096s
  training loss:		1.822839
  validation loss:		1.713671
  validation accuracy:		33.70 %
Epoch 426 of 2000 took 0.096s
  training loss:		1.802429
  validation loss:		1.698016
  validation accuracy:		35.00 %
Epoch 427 of 2000 took 0.096s
  training loss:		1.791078
  validation loss:		1.680896
  validation accuracy:		34.67 %
Epoch 428 of 2000 took 0.096s
  training loss:		1.776613
  validation loss:		1.665192
  validation accuracy:		34.67 %
Epoch 429 of 2000 took 0.096s
  training loss:		1.758089
  validation loss:		1.650142
  validation accuracy:		34.67 %
Epoch 430 of 2000 took 0.096s
  training loss:		1.744621
  validation loss:		1.633765
  validation accuracy:		35.33 %
Epoch 431 of 2000 took 0.096s
  training loss:		1.734025
  validation loss:		1.619220
  validation accuracy:		35.54 %
Epoch 432 of 2000 took 0.096s
  training loss:		1.717895
  validation loss:		1.604403
  validation accuracy:		36.85 %
Epoch 433 of 2000 took 0.096s
  training loss:		1.701607
  validation loss:		1.592114
  validation accuracy:		35.65 %
Epoch 434 of 2000 took 0.096s
  training loss:		1.684641
  validation loss:		1.577061
  validation accuracy:		37.93 %
Epoch 435 of 2000 took 0.096s
  training loss:		1.668224
  validation loss:		1.566427
  validation accuracy:		37.72 %
Epoch 436 of 2000 took 0.096s
  training loss:		1.659433
  validation loss:		1.550418
  validation accuracy:		38.26 %
Epoch 437 of 2000 took 0.096s
  training loss:		1.641962
  validation loss:		1.538285
  validation accuracy:		39.35 %
Epoch 438 of 2000 took 0.096s
  training loss:		1.629495
  validation loss:		1.527612
  validation accuracy:		39.78 %
Epoch 439 of 2000 took 0.096s
  training loss:		1.619721
  validation loss:		1.520692
  validation accuracy:		41.52 %
Epoch 440 of 2000 took 0.096s
  training loss:		1.601671
  validation loss:		1.505955
  validation accuracy:		41.41 %
Epoch 441 of 2000 took 0.098s
  training loss:		1.591121
  validation loss:		1.496192
  validation accuracy:		41.74 %
Epoch 442 of 2000 took 0.099s
  training loss:		1.582612
  validation loss:		1.486482
  validation accuracy:		42.83 %
Epoch 443 of 2000 took 0.096s
  training loss:		1.568373
  validation loss:		1.476665
  validation accuracy:		44.13 %
Epoch 444 of 2000 took 0.096s
  training loss:		1.556627
  validation loss:		1.467941
  validation accuracy:		43.70 %
Epoch 445 of 2000 took 0.096s
  training loss:		1.546124
  validation loss:		1.459191
  validation accuracy:		43.91 %
Epoch 446 of 2000 took 0.096s
  training loss:		1.536906
  validation loss:		1.449728
  validation accuracy:		44.57 %
Epoch 447 of 2000 took 0.096s
  training loss:		1.531475
  validation loss:		1.442340
  validation accuracy:		44.57 %
Epoch 448 of 2000 took 0.096s
  training loss:		1.522509
  validation loss:		1.435197
  validation accuracy:		44.57 %
Epoch 449 of 2000 took 0.096s
  training loss:		1.502610
  validation loss:		1.428143
  validation accuracy:		44.78 %
Epoch 450 of 2000 took 0.096s
  training loss:		1.508820
  validation loss:		1.422381
  validation accuracy:		46.20 %
Epoch 451 of 2000 took 0.097s
  training loss:		1.498025
  validation loss:		1.412293
  validation accuracy:		45.22 %
Epoch 452 of 2000 took 0.096s
  training loss:		1.487762
  validation loss:		1.403870
  validation accuracy:		45.54 %
Epoch 453 of 2000 took 0.096s
  training loss:		1.477501
  validation loss:		1.398156
  validation accuracy:		46.09 %
Epoch 454 of 2000 took 0.096s
  training loss:		1.477158
  validation loss:		1.391915
  validation accuracy:		45.76 %
Epoch 455 of 2000 took 0.096s
  training loss:		1.459697
  validation loss:		1.384692
  validation accuracy:		45.87 %
Epoch 456 of 2000 took 0.096s
  training loss:		1.457195
  validation loss:		1.380396
  validation accuracy:		46.20 %
Epoch 457 of 2000 took 0.096s
  training loss:		1.453487
  validation loss:		1.382613
  validation accuracy:		45.54 %
Epoch 458 of 2000 took 0.096s
  training loss:		1.447231
  validation loss:		1.369470
  validation accuracy:		46.63 %
Epoch 459 of 2000 took 0.096s
  training loss:		1.445611
  validation loss:		1.372011
  validation accuracy:		45.54 %
Epoch 460 of 2000 took 0.096s
  training loss:		1.434492
  validation loss:		1.361266
  validation accuracy:		46.63 %
Epoch 461 of 2000 took 0.096s
  training loss:		1.437388
  validation loss:		1.361067
  validation accuracy:		46.96 %
Epoch 462 of 2000 took 0.096s
  training loss:		1.425715
  validation loss:		1.349252
  validation accuracy:		46.74 %
Epoch 463 of 2000 took 0.096s
  training loss:		1.424993
  validation loss:		1.343342
  validation accuracy:		47.07 %
Epoch 464 of 2000 took 0.096s
  training loss:		1.422897
  validation loss:		1.344652
  validation accuracy:		47.39 %
Epoch 465 of 2000 took 0.096s
  training loss:		1.407749
  validation loss:		1.337151
  validation accuracy:		46.63 %
Epoch 466 of 2000 took 0.096s
  training loss:		1.409194
  validation loss:		1.331136
  validation accuracy:		46.85 %
Epoch 467 of 2000 took 0.096s
  training loss:		1.415148
  validation loss:		1.359946
  validation accuracy:		47.72 %
Epoch 468 of 2000 took 0.096s
  training loss:		1.413918
  validation loss:		1.326834
  validation accuracy:		47.28 %
Epoch 469 of 2000 took 0.096s
  training loss:		1.402541
  validation loss:		1.320403
  validation accuracy:		47.17 %
Epoch 470 of 2000 took 0.096s
  training loss:		1.403854
  validation loss:		1.320307
  validation accuracy:		47.83 %
Epoch 471 of 2000 took 0.096s
  training loss:		1.400306
  validation loss:		1.359970
  validation accuracy:		46.96 %
Epoch 472 of 2000 took 0.096s
  training loss:		1.395871
  validation loss:		1.321238
  validation accuracy:		48.15 %
Epoch 473 of 2000 took 0.096s
  training loss:		1.389915
  validation loss:		1.310517
  validation accuracy:		47.72 %
Epoch 474 of 2000 took 0.096s
  training loss:		1.380798
  validation loss:		1.308942
  validation accuracy:		48.15 %
Epoch 475 of 2000 took 0.096s
  training loss:		1.382264
  validation loss:		1.305828
  validation accuracy:		49.02 %
Epoch 476 of 2000 took 0.096s
  training loss:		1.433815
  validation loss:		1.367084
  validation accuracy:		45.87 %
Epoch 477 of 2000 took 0.096s
  training loss:		1.395216
  validation loss:		1.332943
  validation accuracy:		45.33 %
Epoch 478 of 2000 took 0.096s
  training loss:		1.403896
  validation loss:		1.317582
  validation accuracy:		49.02 %
Epoch 479 of 2000 took 0.098s
  training loss:		1.402268
  validation loss:		1.330508
  validation accuracy:		45.11 %
Epoch 480 of 2000 took 0.096s
  training loss:		1.399519
  validation loss:		1.298461
  validation accuracy:		48.37 %
Epoch 481 of 2000 took 0.096s
  training loss:		1.376231
  validation loss:		1.295204
  validation accuracy:		49.46 %
Epoch 482 of 2000 took 0.097s
  training loss:		1.367716
  validation loss:		1.335971
  validation accuracy:		47.83 %
Epoch 483 of 2000 took 0.096s
  training loss:		1.368583
  validation loss:		1.299255
  validation accuracy:		48.59 %
Epoch 484 of 2000 took 0.096s
  training loss:		1.351949
  validation loss:		1.290018
  validation accuracy:		48.70 %
Epoch 485 of 2000 took 0.096s
  training loss:		1.361694
  validation loss:		1.287463
  validation accuracy:		48.91 %
Epoch 486 of 2000 took 0.096s
  training loss:		1.353631
  validation loss:		1.297147
  validation accuracy:		47.72 %
Epoch 487 of 2000 took 0.096s
  training loss:		1.354709
  validation loss:		1.291885
  validation accuracy:		48.48 %
Epoch 488 of 2000 took 0.096s
  training loss:		1.437647
  validation loss:		1.527517
  validation accuracy:		40.11 %
Epoch 489 of 2000 took 0.096s
  training loss:		1.579327
  validation loss:		1.324822
  validation accuracy:		45.65 %
Epoch 490 of 2000 took 0.096s
  training loss:		1.374869
  validation loss:		1.306580
  validation accuracy:		48.04 %
Epoch 491 of 2000 took 0.096s
  training loss:		1.355401
  validation loss:		1.283418
  validation accuracy:		48.80 %
Epoch 492 of 2000 took 0.096s
  training loss:		1.352825
  validation loss:		1.300895
  validation accuracy:		46.63 %
Epoch 493 of 2000 took 0.096s
  training loss:		1.345901
  validation loss:		1.275961
  validation accuracy:		47.83 %
Epoch 494 of 2000 took 0.096s
  training loss:		1.365470
  validation loss:		1.289434
  validation accuracy:		48.26 %
Epoch 495 of 2000 took 0.096s
  training loss:		1.337102
  validation loss:		1.274887
  validation accuracy:		48.59 %
Epoch 496 of 2000 took 0.096s
  training loss:		1.358727
  validation loss:		1.279197
  validation accuracy:		48.70 %
Epoch 497 of 2000 took 0.096s
  training loss:		1.378370
  validation loss:		1.345169
  validation accuracy:		43.91 %
Epoch 498 of 2000 took 0.096s
  training loss:		1.360332
  validation loss:		1.282648
  validation accuracy:		49.35 %
Epoch 499 of 2000 took 0.096s
  training loss:		1.402569
  validation loss:		1.280667
  validation accuracy:		48.91 %
Epoch 500 of 2000 took 0.096s
  training loss:		1.340102
  validation loss:		1.268859
  validation accuracy:		49.46 %
Epoch 501 of 2000 took 0.096s
  training loss:		1.365857
  validation loss:		1.279326
  validation accuracy:		48.26 %
Epoch 502 of 2000 took 0.096s
  training loss:		1.353019
  validation loss:		1.276954
  validation accuracy:		48.59 %
Epoch 503 of 2000 took 0.096s
  training loss:		1.453395
  validation loss:		1.382141
  validation accuracy:		43.37 %
Epoch 504 of 2000 took 0.096s
  training loss:		1.411774
  validation loss:		1.377888
  validation accuracy:		47.17 %
Epoch 505 of 2000 took 0.096s
  training loss:		1.376169
  validation loss:		1.273091
  validation accuracy:		49.02 %
Epoch 506 of 2000 took 0.096s
  training loss:		1.334306
  validation loss:		1.267449
  validation accuracy:		47.83 %
Epoch 507 of 2000 took 0.096s
  training loss:		1.346807
  validation loss:		1.291595
  validation accuracy:		46.96 %
Epoch 508 of 2000 took 0.096s
  training loss:		1.343526
  validation loss:		1.268647
  validation accuracy:		48.15 %
Epoch 509 of 2000 took 0.096s
  training loss:		1.330248
  validation loss:		1.259749
  validation accuracy:		48.59 %
Epoch 510 of 2000 took 0.096s
  training loss:		1.334760
  validation loss:		1.323334
  validation accuracy:		47.83 %
Epoch 511 of 2000 took 0.096s
  training loss:		1.347802
  validation loss:		1.260971
  validation accuracy:		48.59 %
Epoch 512 of 2000 took 0.096s
  training loss:		1.356443
  validation loss:		1.258449
  validation accuracy:		50.00 %
Epoch 513 of 2000 took 0.096s
  training loss:		1.328845
  validation loss:		1.260357
  validation accuracy:		48.70 %
Epoch 514 of 2000 took 0.097s
  training loss:		1.327014
  validation loss:		1.255220
  validation accuracy:		49.57 %
Epoch 515 of 2000 took 0.096s
  training loss:		1.343757
  validation loss:		1.267445
  validation accuracy:		48.91 %
Epoch 516 of 2000 took 0.096s
  training loss:		1.523335
  validation loss:		1.553596
  validation accuracy:		40.33 %
Epoch 517 of 2000 took 0.096s
  training loss:		1.401865
  validation loss:		1.262107
  validation accuracy:		50.00 %
Epoch 518 of 2000 took 0.096s
  training loss:		1.330632
  validation loss:		1.261361
  validation accuracy:		48.70 %
Epoch 519 of 2000 took 0.096s
  training loss:		1.325013
  validation loss:		1.254688
  validation accuracy:		49.24 %
Epoch 520 of 2000 took 0.096s
  training loss:		1.324481
  validation loss:		1.263459
  validation accuracy:		47.83 %
Epoch 521 of 2000 took 0.096s
  training loss:		1.341191
  validation loss:		1.260629
  validation accuracy:		49.02 %
Epoch 522 of 2000 took 0.096s
  training loss:		1.324205
  validation loss:		1.265556
  validation accuracy:		47.72 %
Epoch 523 of 2000 took 0.096s
  training loss:		1.368720
  validation loss:		1.325863
  validation accuracy:		47.28 %
Epoch 524 of 2000 took 0.099s
  training loss:		1.333008
  validation loss:		1.268549
  validation accuracy:		48.04 %
Epoch 525 of 2000 took 0.096s
  training loss:		1.325119
  validation loss:		1.249970
  validation accuracy:		50.11 %
Epoch 526 of 2000 took 0.096s
  training loss:		1.321964
  validation loss:		1.271357
  validation accuracy:		49.67 %
Epoch 527 of 2000 took 0.096s
  training loss:		1.323263
  validation loss:		1.439752
  validation accuracy:		43.80 %
Epoch 528 of 2000 took 0.096s
  training loss:		1.328574
  validation loss:		1.260208
  validation accuracy:		49.89 %
Epoch 529 of 2000 took 0.096s
  training loss:		1.336736
  validation loss:		1.322336
  validation accuracy:		47.93 %
Epoch 530 of 2000 took 0.096s
  training loss:		1.319429
  validation loss:		1.254001
  validation accuracy:		50.33 %
Epoch 531 of 2000 took 0.096s
  training loss:		1.348359
  validation loss:		1.297224
  validation accuracy:		47.61 %
Epoch 532 of 2000 took 0.096s
  training loss:		1.394226
  validation loss:		1.613863
  validation accuracy:		40.33 %
Epoch 533 of 2000 took 0.096s
  training loss:		1.406947
  validation loss:		1.267265
  validation accuracy:		47.72 %
Epoch 534 of 2000 took 0.096s
  training loss:		1.384347
  validation loss:		1.265653
  validation accuracy:		49.89 %
Epoch 535 of 2000 took 0.096s
  training loss:		1.315748
  validation loss:		1.271348
  validation accuracy:		49.57 %
Epoch 536 of 2000 took 0.096s
  training loss:		1.319920
  validation loss:		1.256112
  validation accuracy:		49.02 %
Epoch 537 of 2000 took 0.096s
  training loss:		1.328559
  validation loss:		1.252219
  validation accuracy:		48.15 %
Epoch 538 of 2000 took 0.096s
  training loss:		1.340641
  validation loss:		1.342142
  validation accuracy:		45.54 %
Epoch 539 of 2000 took 0.096s
  training loss:		1.499862
  validation loss:		1.268771
  validation accuracy:		50.11 %
Epoch 540 of 2000 took 0.096s
  training loss:		1.331757
  validation loss:		1.245702
  validation accuracy:		50.11 %
Epoch 541 of 2000 took 0.096s
  training loss:		1.313634
  validation loss:		1.252721
  validation accuracy:		49.57 %
Epoch 542 of 2000 took 0.096s
  training loss:		1.320609
  validation loss:		1.254592
  validation accuracy:		48.59 %
Epoch 543 of 2000 took 0.096s
  training loss:		1.347914
  validation loss:		1.264995
  validation accuracy:		49.46 %
Epoch 544 of 2000 took 0.096s
  training loss:		1.313320
  validation loss:		1.243909
  validation accuracy:		49.46 %
Epoch 545 of 2000 took 0.097s
  training loss:		1.336412
  validation loss:		1.283893
  validation accuracy:		48.04 %
Epoch 546 of 2000 took 0.096s
  training loss:		1.327128
  validation loss:		1.302429
  validation accuracy:		48.91 %
Epoch 547 of 2000 took 0.096s
  training loss:		1.354496
  validation loss:		1.248859
  validation accuracy:		50.11 %
Epoch 548 of 2000 took 0.096s
  training loss:		1.310577
  validation loss:		1.240473
  validation accuracy:		49.67 %
Epoch 549 of 2000 took 0.096s
  training loss:		1.308483
  validation loss:		1.271030
  validation accuracy:		50.22 %
Epoch 550 of 2000 took 0.096s
  training loss:		1.310121
  validation loss:		1.242877
  validation accuracy:		50.65 %
Epoch 551 of 2000 took 0.096s
  training loss:		1.368020
  validation loss:		1.251706
  validation accuracy:		49.02 %
Epoch 552 of 2000 took 0.096s
  training loss:		1.309898
  validation loss:		1.249559
  validation accuracy:		48.91 %
Epoch 553 of 2000 took 0.096s
  training loss:		1.354765
  validation loss:		1.281783
  validation accuracy:		49.13 %
Epoch 554 of 2000 took 0.096s
  training loss:		1.338058
  validation loss:		1.335949
  validation accuracy:		47.07 %
Epoch 555 of 2000 took 0.096s
  training loss:		1.319593
  validation loss:		1.265747
  validation accuracy:		48.04 %
Epoch 556 of 2000 took 0.096s
  training loss:		1.315512
  validation loss:		1.244730
  validation accuracy:		50.00 %
Epoch 557 of 2000 took 0.096s
  training loss:		1.305870
  validation loss:		1.236823
  validation accuracy:		49.89 %
Epoch 558 of 2000 took 0.096s
  training loss:		1.309407
  validation loss:		1.303387
  validation accuracy:		48.91 %
Epoch 559 of 2000 took 0.096s
  training loss:		1.307179
  validation loss:		1.243487
  validation accuracy:		49.89 %
Epoch 560 of 2000 took 0.096s
  training loss:		1.315727
  validation loss:		1.278899
  validation accuracy:		48.91 %
Epoch 561 of 2000 took 0.096s
  training loss:		1.330467
  validation loss:		1.239264
  validation accuracy:		49.78 %
Epoch 562 of 2000 took 0.096s
  training loss:		1.307938
  validation loss:		1.261924
  validation accuracy:		48.48 %
Epoch 563 of 2000 took 0.096s
  training loss:		1.312638
  validation loss:		1.261878
  validation accuracy:		50.43 %
Epoch 564 of 2000 took 0.096s
  training loss:		1.337240
  validation loss:		1.371684
  validation accuracy:		45.98 %
Epoch 565 of 2000 took 0.096s
  training loss:		1.353132
  validation loss:		1.239297
  validation accuracy:		50.33 %
Epoch 566 of 2000 took 0.096s
  training loss:		1.317350
  validation loss:		1.265766
  validation accuracy:		49.89 %
Epoch 567 of 2000 took 0.096s
  training loss:		1.373270
  validation loss:		1.356995
  validation accuracy:		45.11 %
Epoch 568 of 2000 took 0.096s
  training loss:		1.367670
  validation loss:		1.290589
  validation accuracy:		48.59 %
Epoch 569 of 2000 took 0.096s
  training loss:		1.363453
  validation loss:		1.267767
  validation accuracy:		49.02 %
Epoch 570 of 2000 took 0.096s
  training loss:		1.302099
  validation loss:		1.250987
  validation accuracy:		48.48 %
Epoch 571 of 2000 took 0.096s
  training loss:		1.303619
  validation loss:		1.251698
  validation accuracy:		49.57 %
Epoch 572 of 2000 took 0.096s
  training loss:		1.304744
  validation loss:		1.240323
  validation accuracy:		49.46 %
Epoch 573 of 2000 took 0.096s
  training loss:		1.304050
  validation loss:		1.238051
  validation accuracy:		50.54 %
Epoch 574 of 2000 took 0.096s
  training loss:		1.304097
  validation loss:		1.258848
  validation accuracy:		48.80 %
Epoch 575 of 2000 took 0.096s
  training loss:		1.316108
  validation loss:		1.237422
  validation accuracy:		50.76 %
Epoch 576 of 2000 took 0.097s
  training loss:		1.304706
  validation loss:		1.237826
  validation accuracy:		50.43 %
Epoch 577 of 2000 took 0.096s
  training loss:		1.324920
  validation loss:		1.270489
  validation accuracy:		49.67 %
Epoch 578 of 2000 took 0.099s
  training loss:		1.393127
  validation loss:		1.611480
  validation accuracy:		40.76 %
Epoch 579 of 2000 took 0.096s
  training loss:		1.374987
  validation loss:		1.247872
  validation accuracy:		50.33 %
Epoch 580 of 2000 took 0.096s
  training loss:		1.306166
  validation loss:		1.237786
  validation accuracy:		50.65 %
Epoch 581 of 2000 took 0.096s
  training loss:		1.353190
  validation loss:		1.281862
  validation accuracy:		49.89 %
Epoch 582 of 2000 took 0.096s
  training loss:		1.313570
  validation loss:		1.241948
  validation accuracy:		50.00 %
Epoch 583 of 2000 took 0.096s
  training loss:		1.320496
  validation loss:		1.292852
  validation accuracy:		48.80 %
Epoch 584 of 2000 took 0.096s
  training loss:		1.322703
  validation loss:		1.280294
  validation accuracy:		50.11 %
Epoch 585 of 2000 took 0.096s
  training loss:		1.307619
  validation loss:		1.236541
  validation accuracy:		50.22 %
Epoch 586 of 2000 took 0.096s
  training loss:		1.309340
  validation loss:		1.241003
  validation accuracy:		49.78 %
Epoch 587 of 2000 took 0.096s
  training loss:		1.356373
  validation loss:		1.292835
  validation accuracy:		48.37 %
Epoch 588 of 2000 took 0.096s
  training loss:		1.350341
  validation loss:		1.260523
  validation accuracy:		49.24 %
Epoch 589 of 2000 took 0.096s
  training loss:		1.305637
  validation loss:		1.232701
  validation accuracy:		50.54 %
Epoch 590 of 2000 took 0.096s
  training loss:		1.304869
  validation loss:		1.284972
  validation accuracy:		49.57 %
Epoch 591 of 2000 took 0.096s
  training loss:		1.307646
  validation loss:		1.242549
  validation accuracy:		49.24 %
Epoch 592 of 2000 took 0.096s
  training loss:		1.300429
  validation loss:		1.271688
  validation accuracy:		49.02 %
Epoch 593 of 2000 took 0.096s
  training loss:		1.312427
  validation loss:		1.230675
  validation accuracy:		51.09 %
Epoch 594 of 2000 took 0.096s
  training loss:		1.308985
  validation loss:		1.230893
  validation accuracy:		51.63 %
Epoch 595 of 2000 took 0.096s
  training loss:		1.317757
  validation loss:		1.263066
  validation accuracy:		50.11 %
Epoch 596 of 2000 took 0.096s
  training loss:		1.332538
  validation loss:		1.237633
  validation accuracy:		50.76 %
Epoch 597 of 2000 took 0.096s
  training loss:		1.319017
  validation loss:		1.318100
  validation accuracy:		49.24 %
Epoch 598 of 2000 took 0.096s
  training loss:		1.337187
  validation loss:		1.289517
  validation accuracy:		49.78 %
Epoch 599 of 2000 took 0.096s
  training loss:		1.303339
  validation loss:		1.230443
  validation accuracy:		51.41 %
Epoch 600 of 2000 took 0.096s
  training loss:		1.295178
  validation loss:		1.237204
  validation accuracy:		50.65 %
Epoch 601 of 2000 took 0.096s
  training loss:		1.300045
  validation loss:		1.238707
  validation accuracy:		49.78 %
Epoch 602 of 2000 took 0.096s
  training loss:		1.309912
  validation loss:		1.257559
  validation accuracy:		50.11 %
Epoch 603 of 2000 took 0.096s
  training loss:		1.309698
  validation loss:		1.227347
  validation accuracy:		50.65 %
Epoch 604 of 2000 took 0.096s
  training loss:		1.293081
  validation loss:		1.235520
  validation accuracy:		50.22 %
Epoch 605 of 2000 took 0.096s
  training loss:		1.281567
  validation loss:		1.251054
  validation accuracy:		50.00 %
Epoch 606 of 2000 took 0.096s
  training loss:		1.298641
  validation loss:		1.224986
  validation accuracy:		50.65 %
Epoch 607 of 2000 took 0.096s
  training loss:		1.298882
  validation loss:		1.232420
  validation accuracy:		50.98 %
Epoch 608 of 2000 took 0.097s
  training loss:		1.313545
  validation loss:		1.409766
  validation accuracy:		45.65 %
Epoch 609 of 2000 took 0.096s
  training loss:		1.476603
  validation loss:		1.237495
  validation accuracy:		51.20 %
Epoch 610 of 2000 took 0.096s
  training loss:		1.304022
  validation loss:		1.232043
  validation accuracy:		51.09 %
Epoch 611 of 2000 took 0.096s
  training loss:		1.308000
  validation loss:		1.236748
  validation accuracy:		50.76 %
Epoch 612 of 2000 took 0.096s
  training loss:		1.305510
  validation loss:		1.232491
  validation accuracy:		50.76 %
Epoch 613 of 2000 took 0.096s
  training loss:		1.307641
  validation loss:		1.238846
  validation accuracy:		50.65 %
Epoch 614 of 2000 took 0.096s
  training loss:		1.311166
  validation loss:		1.236870
  validation accuracy:		49.89 %
Epoch 615 of 2000 took 0.096s
  training loss:		1.334289
  validation loss:		1.260372
  validation accuracy:		50.00 %
Epoch 616 of 2000 took 0.096s
  training loss:		1.323121
  validation loss:		1.231321
  validation accuracy:		50.54 %
Epoch 617 of 2000 took 0.096s
  training loss:		1.298595
  validation loss:		1.285563
  validation accuracy:		49.46 %
Epoch 618 of 2000 took 0.096s
  training loss:		1.331116
  validation loss:		1.232047
  validation accuracy:		51.41 %
Epoch 619 of 2000 took 0.096s
  training loss:		1.311155
  validation loss:		1.231532
  validation accuracy:		50.87 %
Epoch 620 of 2000 took 0.096s
  training loss:		1.310449
  validation loss:		1.317040
  validation accuracy:		48.91 %
Epoch 621 of 2000 took 0.096s
  training loss:		1.394571
  validation loss:		1.243304
  validation accuracy:		50.87 %
Epoch 622 of 2000 took 0.096s
  training loss:		1.300811
  validation loss:		1.231653
  validation accuracy:		52.50 %
Epoch 623 of 2000 took 0.096s
  training loss:		1.306384
  validation loss:		1.228848
  validation accuracy:		50.65 %
Epoch 624 of 2000 took 0.096s
  training loss:		1.295616
  validation loss:		1.257499
  validation accuracy:		50.87 %
Epoch 625 of 2000 took 0.096s
  training loss:		1.298744
  validation loss:		1.232084
  validation accuracy:		51.41 %
Epoch 626 of 2000 took 0.096s
  training loss:		1.295313
  validation loss:		1.279634
  validation accuracy:		50.54 %
Epoch 627 of 2000 took 0.096s
  training loss:		1.356771
  validation loss:		1.235377
  validation accuracy:		51.20 %
Epoch 628 of 2000 took 0.096s
  training loss:		1.325272
  validation loss:		1.265407
  validation accuracy:		49.89 %
Epoch 629 of 2000 took 0.096s
  training loss:		1.295291
  validation loss:		1.247241
  validation accuracy:		50.43 %
Epoch 630 of 2000 took 0.096s
  training loss:		1.316964
  validation loss:		1.227225
  validation accuracy:		49.89 %
Epoch 631 of 2000 took 0.096s
  training loss:		1.307374
  validation loss:		1.235584
  validation accuracy:		51.30 %
Epoch 632 of 2000 took 0.096s
  training loss:		1.315546
  validation loss:		1.268368
  validation accuracy:		50.65 %
Epoch 633 of 2000 took 0.096s
  training loss:		1.292564
  validation loss:		1.225013
  validation accuracy:		52.39 %
Epoch 634 of 2000 took 0.096s
  training loss:		1.301735
  validation loss:		1.229946
  validation accuracy:		50.98 %
Epoch 635 of 2000 took 0.096s
  training loss:		1.297018
  validation loss:		1.246035
  validation accuracy:		50.43 %
Epoch 636 of 2000 took 0.096s
  training loss:		1.297318
  validation loss:		1.228523
  validation accuracy:		50.76 %
Epoch 637 of 2000 took 0.096s
  training loss:		1.285887
  validation loss:		1.230817
  validation accuracy:		51.52 %
Epoch 638 of 2000 took 0.096s
  training loss:		1.293608
  validation loss:		1.243180
  validation accuracy:		50.65 %
Epoch 639 of 2000 took 0.097s
  training loss:		1.330542
  validation loss:		1.279026
  validation accuracy:		50.65 %
Epoch 640 of 2000 took 0.096s
  training loss:		1.308565
  validation loss:		1.240655
  validation accuracy:		51.41 %
Epoch 641 of 2000 took 0.096s
  training loss:		1.309668
  validation loss:		1.273750
  validation accuracy:		50.11 %
Epoch 642 of 2000 took 0.098s
  training loss:		1.304087
  validation loss:		1.241861
  validation accuracy:		50.43 %
Epoch 643 of 2000 took 0.096s
  training loss:		1.297898
  validation loss:		1.249303
  validation accuracy:		50.54 %
Epoch 644 of 2000 took 0.096s
  training loss:		1.299775
  validation loss:		1.247389
  validation accuracy:		50.76 %
Epoch 645 of 2000 took 0.096s
  training loss:		1.296194
  validation loss:		1.249297
  validation accuracy:		50.65 %
Epoch 646 of 2000 took 0.096s
  training loss:		1.306823
  validation loss:		1.254198
  validation accuracy:		50.11 %
Epoch 647 of 2000 took 0.096s
  training loss:		1.301798
  validation loss:		1.292519
  validation accuracy:		50.65 %
Epoch 648 of 2000 took 0.096s
  training loss:		1.306436
  validation loss:		1.230709
  validation accuracy:		51.41 %
Epoch 649 of 2000 took 0.096s
  training loss:		1.348017
  validation loss:		1.232353
  validation accuracy:		51.63 %
Epoch 650 of 2000 took 0.096s
  training loss:		1.300340
  validation loss:		1.240360
  validation accuracy:		51.63 %
Epoch 651 of 2000 took 0.096s
  training loss:		1.310682
  validation loss:		1.266646
  validation accuracy:		50.76 %
Epoch 652 of 2000 took 0.096s
  training loss:		1.312268
  validation loss:		1.241397
  validation accuracy:		51.09 %
Epoch 653 of 2000 took 0.096s
  training loss:		1.314272
  validation loss:		1.280195
  validation accuracy:		50.11 %
Epoch 654 of 2000 took 0.096s
  training loss:		1.303414
  validation loss:		1.228578
  validation accuracy:		52.28 %
Epoch 655 of 2000 took 0.096s
  training loss:		1.303492
  validation loss:		1.253665
  validation accuracy:		51.20 %
Epoch 656 of 2000 took 0.096s
  training loss:		1.295871
  validation loss:		1.226702
  validation accuracy:		52.39 %
Epoch 657 of 2000 took 0.096s
  training loss:		1.293318
  validation loss:		1.235034
  validation accuracy:		52.61 %
Epoch 658 of 2000 took 0.096s
  training loss:		1.302150
  validation loss:		1.226009
  validation accuracy:		51.30 %
Epoch 659 of 2000 took 0.096s
  training loss:		1.295278
  validation loss:		1.236044
  validation accuracy:		51.85 %
Epoch 660 of 2000 took 0.096s
  training loss:		1.315396
  validation loss:		1.244125
  validation accuracy:		51.96 %
Epoch 661 of 2000 took 0.096s
  training loss:		1.292908
  validation loss:		1.228618
  validation accuracy:		50.87 %
Epoch 662 of 2000 took 0.096s
  training loss:		1.292008
  validation loss:		1.253915
  validation accuracy:		50.33 %
Epoch 663 of 2000 took 0.096s
  training loss:		1.322645
  validation loss:		1.260404
  validation accuracy:		51.30 %
Epoch 664 of 2000 took 0.096s
  training loss:		1.303055
  validation loss:		1.227194
  validation accuracy:		52.17 %
Epoch 665 of 2000 took 0.096s
  training loss:		1.302965
  validation loss:		1.251837
  validation accuracy:		50.98 %
Epoch 666 of 2000 took 0.096s
  training loss:		1.299498
  validation loss:		1.242229
  validation accuracy:		51.74 %
Epoch 667 of 2000 took 0.096s
  training loss:		1.294027
  validation loss:		1.279657
  validation accuracy:		50.76 %
Epoch 668 of 2000 took 0.096s
  training loss:		1.318914
  validation loss:		1.230954
  validation accuracy:		52.83 %
Epoch 669 of 2000 took 0.096s
  training loss:		1.298256
  validation loss:		1.243117
  validation accuracy:		51.52 %
Epoch 670 of 2000 took 0.096s
  training loss:		1.297108
  validation loss:		1.228134
  validation accuracy:		53.04 %
Epoch 671 of 2000 took 0.097s
  training loss:		1.292656
  validation loss:		1.226896
  validation accuracy:		51.30 %
Epoch 672 of 2000 took 0.096s
  training loss:		1.309707
  validation loss:		1.233820
  validation accuracy:		52.72 %
Epoch 673 of 2000 took 0.096s
  training loss:		1.318555
  validation loss:		1.236471
  validation accuracy:		52.17 %
Epoch 674 of 2000 took 0.096s
  training loss:		1.299018
  validation loss:		1.244456
  validation accuracy:		52.61 %
Epoch 675 of 2000 took 0.096s
  training loss:		1.298980
  validation loss:		1.269334
  validation accuracy:		51.20 %
Epoch 676 of 2000 took 0.096s
  training loss:		1.313555
  validation loss:		1.224463
  validation accuracy:		52.83 %
Epoch 677 of 2000 took 0.096s
  training loss:		1.317799
  validation loss:		1.269512
  validation accuracy:		50.98 %
Epoch 678 of 2000 took 0.096s
  training loss:		1.294584
  validation loss:		1.226693
  validation accuracy:		52.72 %
Epoch 679 of 2000 took 0.096s
  training loss:		1.318026
  validation loss:		1.258594
  validation accuracy:		50.87 %
Epoch 680 of 2000 took 0.096s
  training loss:		1.300332
  validation loss:		1.237724
  validation accuracy:		52.39 %
Epoch 681 of 2000 took 0.096s
  training loss:		1.297578
  validation loss:		1.246892
  validation accuracy:		51.52 %
Epoch 682 of 2000 took 0.096s
  training loss:		1.305387
  validation loss:		1.248228
  validation accuracy:		51.85 %
Epoch 683 of 2000 took 0.096s
  training loss:		1.308866
  validation loss:		1.231477
  validation accuracy:		52.50 %
Epoch 684 of 2000 took 0.096s
  training loss:		1.300293
  validation loss:		1.227598
  validation accuracy:		52.83 %
Epoch 685 of 2000 took 0.096s
  training loss:		1.291724
  validation loss:		1.270108
  validation accuracy:		51.09 %
Epoch 686 of 2000 took 0.096s
  training loss:		1.314495
  validation loss:		1.234293
  validation accuracy:		52.39 %
Epoch 687 of 2000 took 0.096s
  training loss:		1.290781
  validation loss:		1.224397
  validation accuracy:		51.96 %
Epoch 688 of 2000 took 0.096s
  training loss:		1.287957
  validation loss:		1.223217
  validation accuracy:		52.93 %
Epoch 689 of 2000 took 0.096s
  training loss:		1.288958
  validation loss:		1.225220
  validation accuracy:		53.26 %
Epoch 690 of 2000 took 0.097s
  training loss:		1.308367
  validation loss:		1.242019
  validation accuracy:		51.63 %
Epoch 691 of 2000 took 0.096s
  training loss:		1.330783
  validation loss:		1.236958
  validation accuracy:		52.50 %
Epoch 692 of 2000 took 0.096s
  training loss:		1.297704
  validation loss:		1.227084
  validation accuracy:		52.83 %
Epoch 693 of 2000 took 0.096s
  training loss:		1.301495
  validation loss:		1.238289
  validation accuracy:		52.50 %
Epoch 694 of 2000 took 0.096s
  training loss:		1.295513
  validation loss:		1.228042
  validation accuracy:		53.26 %
Epoch 695 of 2000 took 0.096s
  training loss:		1.296499
  validation loss:		1.241837
  validation accuracy:		51.96 %
Epoch 696 of 2000 took 0.096s
  training loss:		1.292535
  validation loss:		1.226886
  validation accuracy:		52.72 %
Epoch 697 of 2000 took 0.096s
  training loss:		1.300630
  validation loss:		1.255319
  validation accuracy:		51.96 %
Epoch 698 of 2000 took 0.096s
  training loss:		1.296353
  validation loss:		1.230313
  validation accuracy:		53.70 %
Epoch 699 of 2000 took 0.096s
  training loss:		1.308597
  validation loss:		1.227002
  validation accuracy:		52.61 %
Epoch 700 of 2000 took 0.096s
  training loss:		1.295177
  validation loss:		1.220037
  validation accuracy:		53.04 %
Epoch 701 of 2000 took 0.096s
  training loss:		1.308789
  validation loss:		1.225995
  validation accuracy:		53.59 %
Epoch 702 of 2000 took 0.097s
  training loss:		1.299096
  validation loss:		1.225047
  validation accuracy:		52.72 %
Epoch 703 of 2000 took 0.096s
  training loss:		1.303904
  validation loss:		1.232928
  validation accuracy:		52.93 %
Epoch 704 of 2000 took 0.096s
  training loss:		1.311405
  validation loss:		1.221833
  validation accuracy:		53.48 %
Epoch 705 of 2000 took 0.096s
  training loss:		1.292273
  validation loss:		1.230081
  validation accuracy:		53.37 %
Epoch 706 of 2000 took 0.096s
  training loss:		1.294363
  validation loss:		1.225299
  validation accuracy:		54.02 %
Epoch 707 of 2000 took 0.096s
  training loss:		1.304659
  validation loss:		1.238518
  validation accuracy:		52.07 %
Epoch 708 of 2000 took 0.096s
  training loss:		1.308323
  validation loss:		1.230757
  validation accuracy:		53.70 %
Epoch 709 of 2000 took 0.096s
  training loss:		1.293394
  validation loss:		1.221461
  validation accuracy:		53.37 %
Epoch 710 of 2000 took 0.096s
  training loss:		1.295871
  validation loss:		1.237188
  validation accuracy:		53.04 %
Epoch 711 of 2000 took 0.096s
  training loss:		1.286550
  validation loss:		1.223918
  validation accuracy:		53.80 %
Epoch 712 of 2000 took 0.096s
  training loss:		1.293997
  validation loss:		1.224334
  validation accuracy:		54.35 %
Epoch 713 of 2000 took 0.096s
  training loss:		1.307948
  validation loss:		1.259882
  validation accuracy:		51.30 %
Epoch 714 of 2000 took 0.096s
  training loss:		1.320221
  validation loss:		1.278676
  validation accuracy:		51.20 %
Epoch 715 of 2000 took 0.096s
  training loss:		1.299709
  validation loss:		1.276232
  validation accuracy:		51.41 %
Epoch 716 of 2000 took 0.096s
  training loss:		1.308266
  validation loss:		1.223398
  validation accuracy:		53.70 %
Epoch 717 of 2000 took 0.097s
  training loss:		1.290780
  validation loss:		1.229891
  validation accuracy:		53.70 %
Epoch 718 of 2000 took 0.099s
  training loss:		1.313126
  validation loss:		1.248857
  validation accuracy:		52.07 %
Epoch 719 of 2000 took 0.099s
  training loss:		1.299034
  validation loss:		1.224652
  validation accuracy:		54.24 %
Epoch 720 of 2000 took 0.102s
  training loss:		1.296182
  validation loss:		1.223526
  validation accuracy:		53.15 %
Epoch 721 of 2000 took 0.099s
  training loss:		1.292212
  validation loss:		1.225918
  validation accuracy:		52.39 %
Epoch 722 of 2000 took 0.099s
  training loss:		1.296261
  validation loss:		1.305448
  validation accuracy:		51.09 %
Epoch 723 of 2000 took 0.099s
  training loss:		1.305731
  validation loss:		1.221402
  validation accuracy:		54.02 %
Epoch 724 of 2000 took 0.099s
  training loss:		1.323645
  validation loss:		1.309345
  validation accuracy:		51.09 %
Epoch 725 of 2000 took 0.099s
  training loss:		1.300019
  validation loss:		1.239315
  validation accuracy:		52.93 %
Epoch 726 of 2000 took 0.099s
  training loss:		1.304571
  validation loss:		1.219037
  validation accuracy:		54.24 %
Epoch 727 of 2000 took 0.099s
  training loss:		1.294098
  validation loss:		1.250230
  validation accuracy:		52.72 %
Epoch 728 of 2000 took 0.099s
  training loss:		1.295389
  validation loss:		1.234682
  validation accuracy:		53.48 %
Epoch 729 of 2000 took 0.099s
  training loss:		1.303764
  validation loss:		1.244596
  validation accuracy:		54.13 %
Epoch 730 of 2000 took 0.099s
  training loss:		1.292280
  validation loss:		1.217301
  validation accuracy:		53.80 %
Epoch 731 of 2000 took 0.099s
  training loss:		1.282888
  validation loss:		1.236003
  validation accuracy:		53.48 %
Epoch 732 of 2000 took 0.099s
  training loss:		1.303630
  validation loss:		1.236711
  validation accuracy:		53.04 %
Epoch 733 of 2000 took 0.100s
  training loss:		1.288798
  validation loss:		1.241132
  validation accuracy:		52.93 %
Epoch 734 of 2000 took 0.099s
  training loss:		1.289558
  validation loss:		1.230922
  validation accuracy:		53.37 %
Epoch 735 of 2000 took 0.099s
  training loss:		1.283513
  validation loss:		1.222439
  validation accuracy:		54.35 %
Epoch 736 of 2000 took 0.099s
  training loss:		1.292486
  validation loss:		1.302307
  validation accuracy:		52.93 %
Epoch 737 of 2000 took 0.099s
  training loss:		1.290595
  validation loss:		1.218729
  validation accuracy:		53.80 %
Epoch 738 of 2000 took 0.099s
  training loss:		1.295530
  validation loss:		1.218915
  validation accuracy:		55.22 %
Epoch 739 of 2000 took 0.099s
  training loss:		1.298828
  validation loss:		1.224841
  validation accuracy:		53.37 %
Epoch 740 of 2000 took 0.099s
  training loss:		1.289891
  validation loss:		1.234306
  validation accuracy:		52.50 %
Epoch 741 of 2000 took 0.099s
  training loss:		1.282770
  validation loss:		1.271968
  validation accuracy:		51.20 %
Epoch 742 of 2000 took 0.099s
  training loss:		1.301478
  validation loss:		1.245831
  validation accuracy:		52.17 %
Epoch 743 of 2000 took 0.099s
  training loss:		1.289562
  validation loss:		1.217854
  validation accuracy:		54.13 %
Epoch 744 of 2000 took 0.099s
  training loss:		1.284516
  validation loss:		1.225429
  validation accuracy:		53.70 %
Epoch 745 of 2000 took 0.099s
  training loss:		1.286629
  validation loss:		1.237187
  validation accuracy:		53.04 %
Epoch 746 of 2000 took 0.099s
  training loss:		1.298652
  validation loss:		1.234097
  validation accuracy:		53.80 %
Epoch 747 of 2000 took 0.099s
  training loss:		1.282016
  validation loss:		1.222790
  validation accuracy:		53.91 %
Epoch 748 of 2000 took 0.099s
  training loss:		1.287880
  validation loss:		1.218627
  validation accuracy:		54.46 %
Epoch 749 of 2000 took 0.099s
  training loss:		1.298963
  validation loss:		1.234536
  validation accuracy:		53.26 %
Epoch 750 of 2000 took 0.099s
  training loss:		1.281189
  validation loss:		1.219218
  validation accuracy:		54.35 %
Epoch 751 of 2000 took 0.099s
  training loss:		1.289871
  validation loss:		1.222432
  validation accuracy:		54.57 %
Epoch 752 of 2000 took 0.099s
  training loss:		1.280123
  validation loss:		1.216007
  validation accuracy:		54.24 %
Epoch 753 of 2000 took 0.099s
  training loss:		1.290290
  validation loss:		1.213300
  validation accuracy:		55.98 %
Epoch 754 of 2000 took 0.099s
  training loss:		1.304268
  validation loss:		1.277912
  validation accuracy:		52.50 %
Epoch 755 of 2000 took 0.099s
  training loss:		1.291107
  validation loss:		1.217842
  validation accuracy:		54.57 %
Epoch 756 of 2000 took 0.099s
  training loss:		1.290932
  validation loss:		1.232424
  validation accuracy:		54.35 %
Epoch 757 of 2000 took 0.099s
  training loss:		1.303558
  validation loss:		1.249977
  validation accuracy:		53.04 %
Epoch 758 of 2000 took 0.099s
  training loss:		1.288370
  validation loss:		1.252467
  validation accuracy:		52.28 %
Epoch 759 of 2000 took 0.099s
  training loss:		1.282665
  validation loss:		1.261851
  validation accuracy:		53.15 %
Epoch 760 of 2000 took 0.099s
  training loss:		1.295891
  validation loss:		1.215923
  validation accuracy:		55.00 %
Epoch 761 of 2000 took 0.099s
  training loss:		1.280286
  validation loss:		1.225589
  validation accuracy:		55.00 %
Epoch 762 of 2000 took 0.099s
  training loss:		1.289532
  validation loss:		1.222177
  validation accuracy:		55.43 %
Epoch 763 of 2000 took 0.100s
  training loss:		1.283084
  validation loss:		1.217108
  validation accuracy:		55.65 %
Epoch 764 of 2000 took 0.099s
  training loss:		1.324517
  validation loss:		1.233120
  validation accuracy:		54.67 %
Epoch 765 of 2000 took 0.099s
  training loss:		1.304146
  validation loss:		1.211763
  validation accuracy:		54.67 %
Epoch 766 of 2000 took 0.099s
  training loss:		1.284721
  validation loss:		1.241948
  validation accuracy:		54.02 %
Epoch 767 of 2000 took 0.099s
  training loss:		1.286878
  validation loss:		1.209631
  validation accuracy:		54.57 %
Epoch 768 of 2000 took 0.099s
  training loss:		1.275557
  validation loss:		1.247404
  validation accuracy:		53.15 %
Epoch 769 of 2000 took 0.099s
  training loss:		1.301136
  validation loss:		1.218038
  validation accuracy:		54.89 %
Epoch 770 of 2000 took 0.099s
  training loss:		1.279054
  validation loss:		1.217754
  validation accuracy:		54.78 %
Epoch 771 of 2000 took 0.099s
  training loss:		1.283475
  validation loss:		1.225544
  validation accuracy:		55.00 %
Epoch 772 of 2000 took 0.099s
  training loss:		1.290061
  validation loss:		1.210235
  validation accuracy:		55.76 %
Epoch 773 of 2000 took 0.099s
  training loss:		1.307746
  validation loss:		1.215848
  validation accuracy:		55.65 %
Epoch 774 of 2000 took 0.099s
  training loss:		1.281295
  validation loss:		1.212811
  validation accuracy:		55.33 %
Epoch 775 of 2000 took 0.099s
  training loss:		1.281378
  validation loss:		1.279146
  validation accuracy:		52.72 %
Epoch 776 of 2000 took 0.099s
  training loss:		1.288793
  validation loss:		1.213590
  validation accuracy:		55.65 %
Epoch 777 of 2000 took 0.099s
  training loss:		1.286259
  validation loss:		1.210044
  validation accuracy:		55.98 %
Epoch 778 of 2000 took 0.099s
  training loss:		1.295486
  validation loss:		1.236284
  validation accuracy:		54.67 %
Epoch 779 of 2000 took 0.099s
  training loss:		1.288128
  validation loss:		1.204254
  validation accuracy:		56.41 %
Epoch 780 of 2000 took 0.099s
  training loss:		1.272632
  validation loss:		1.205540
  validation accuracy:		56.20 %
Epoch 781 of 2000 took 0.099s
  training loss:		1.276211
  validation loss:		1.215101
  validation accuracy:		55.98 %
Epoch 782 of 2000 took 0.099s
  training loss:		1.272816
  validation loss:		1.226495
  validation accuracy:		54.13 %
Epoch 783 of 2000 took 0.099s
  training loss:		1.274541
  validation loss:		1.218322
  validation accuracy:		55.76 %
Epoch 784 of 2000 took 0.099s
  training loss:		1.277610
  validation loss:		1.210927
  validation accuracy:		55.22 %
Epoch 785 of 2000 took 0.099s
  training loss:		1.268432
  validation loss:		1.204117
  validation accuracy:		55.76 %
Epoch 786 of 2000 took 0.099s
  training loss:		1.275789
  validation loss:		1.204646
  validation accuracy:		55.98 %
Epoch 787 of 2000 took 0.099s
  training loss:		1.267956
  validation loss:		1.211645
  validation accuracy:		55.22 %
Epoch 788 of 2000 took 0.099s
  training loss:		1.271661
  validation loss:		1.204988
  validation accuracy:		56.63 %
Epoch 789 of 2000 took 0.099s
  training loss:		1.279148
  validation loss:		1.212711
  validation accuracy:		55.11 %
Epoch 790 of 2000 took 0.099s
  training loss:		1.269396
  validation loss:		1.207815
  validation accuracy:		55.87 %
Epoch 791 of 2000 took 0.099s
  training loss:		1.284943
  validation loss:		1.213783
  validation accuracy:		56.20 %
Epoch 792 of 2000 took 0.099s
  training loss:		1.271321
  validation loss:		1.210476
  validation accuracy:		55.98 %
Epoch 793 of 2000 took 0.099s
  training loss:		1.299891
  validation loss:		1.216377
  validation accuracy:		55.11 %
Epoch 794 of 2000 took 0.100s
  training loss:		1.272338
  validation loss:		1.246282
  validation accuracy:		53.91 %
Epoch 795 of 2000 took 0.099s
  training loss:		1.268762
  validation loss:		1.228734
  validation accuracy:		54.13 %
Epoch 796 of 2000 took 0.099s
  training loss:		1.266573
  validation loss:		1.208202
  validation accuracy:		56.30 %
Epoch 797 of 2000 took 0.099s
  training loss:		1.269753
  validation loss:		1.203491
  validation accuracy:		56.09 %
Epoch 798 of 2000 took 0.099s
  training loss:		1.267531
  validation loss:		1.219189
  validation accuracy:		55.00 %
Epoch 799 of 2000 took 0.099s
  training loss:		1.267572
  validation loss:		1.196865
  validation accuracy:		56.63 %
Epoch 800 of 2000 took 0.099s
  training loss:		1.264659
  validation loss:		1.197491
  validation accuracy:		56.63 %
Epoch 801 of 2000 took 0.099s
  training loss:		1.275319
  validation loss:		1.244461
  validation accuracy:		54.78 %
Epoch 802 of 2000 took 0.099s
  training loss:		1.270573
  validation loss:		1.242002
  validation accuracy:		54.57 %
Epoch 803 of 2000 took 0.099s
  training loss:		1.279118
  validation loss:		1.198220
  validation accuracy:		57.28 %
Epoch 804 of 2000 took 0.099s
  training loss:		1.263989
  validation loss:		1.191095
  validation accuracy:		58.37 %
Epoch 805 of 2000 took 0.099s
  training loss:		1.254666
  validation loss:		1.187238
  validation accuracy:		57.28 %
Epoch 806 of 2000 took 0.099s
  training loss:		1.262649
  validation loss:		1.190539
  validation accuracy:		57.17 %
Epoch 807 of 2000 took 0.099s
  training loss:		1.242790
  validation loss:		1.197406
  validation accuracy:		57.17 %
Epoch 808 of 2000 took 0.099s
  training loss:		1.264358
  validation loss:		1.225813
  validation accuracy:		55.00 %
Epoch 809 of 2000 took 0.099s
  training loss:		1.266171
  validation loss:		1.193520
  validation accuracy:		57.07 %
Epoch 810 of 2000 took 0.102s
  training loss:		1.259667
  validation loss:		1.184264
  validation accuracy:		57.93 %
Epoch 811 of 2000 took 0.099s
  training loss:		1.255141
  validation loss:		1.195803
  validation accuracy:		57.07 %
Epoch 812 of 2000 took 0.099s
  training loss:		1.264858
  validation loss:		1.188005
  validation accuracy:		57.17 %
Epoch 813 of 2000 took 0.099s
  training loss:		1.258820
  validation loss:		1.187104
  validation accuracy:		57.50 %
Epoch 814 of 2000 took 0.099s
  training loss:		1.253293
  validation loss:		1.187750
  validation accuracy:		57.50 %
Epoch 815 of 2000 took 0.099s
  training loss:		1.242132
  validation loss:		1.190993
  validation accuracy:		57.07 %
Epoch 816 of 2000 took 0.099s
  training loss:		1.252268
  validation loss:		1.173920
  validation accuracy:		58.70 %
Epoch 817 of 2000 took 0.099s
  training loss:		1.239950
  validation loss:		1.180446
  validation accuracy:		59.67 %
Epoch 818 of 2000 took 0.099s
  training loss:		1.236654
  validation loss:		1.186683
  validation accuracy:		57.50 %
Epoch 819 of 2000 took 0.099s
  training loss:		1.240798
  validation loss:		1.169031
  validation accuracy:		58.26 %
Epoch 820 of 2000 took 0.099s
  training loss:		1.231999
  validation loss:		1.165194
  validation accuracy:		59.13 %
Epoch 821 of 2000 took 0.099s
  training loss:		1.227548
  validation loss:		1.163383
  validation accuracy:		59.57 %
Epoch 822 of 2000 took 0.099s
  training loss:		1.232478
  validation loss:		1.165827
  validation accuracy:		58.48 %
Epoch 823 of 2000 took 0.099s
  training loss:		1.223471
  validation loss:		1.166916
  validation accuracy:		59.24 %
Epoch 824 of 2000 took 0.100s
  training loss:		1.221507
  validation loss:		1.152379
  validation accuracy:		60.76 %
Epoch 825 of 2000 took 0.099s
  training loss:		1.222030
  validation loss:		1.145070
  validation accuracy:		60.33 %
Epoch 826 of 2000 took 0.099s
  training loss:		1.212675
  validation loss:		1.154120
  validation accuracy:		59.89 %
Epoch 827 of 2000 took 0.099s
  training loss:		1.213743
  validation loss:		1.145959
  validation accuracy:		59.78 %
Epoch 828 of 2000 took 0.099s
  training loss:		1.218429
  validation loss:		1.138791
  validation accuracy:		60.33 %
Epoch 829 of 2000 took 0.099s
  training loss:		1.203323
  validation loss:		1.145523
  validation accuracy:		60.33 %
Epoch 830 of 2000 took 0.099s
  training loss:		1.218775
  validation loss:		1.129622
  validation accuracy:		61.74 %
Epoch 831 of 2000 took 0.099s
  training loss:		1.207386
  validation loss:		1.129473
  validation accuracy:		60.87 %
Epoch 832 of 2000 took 0.099s
  training loss:		1.193237
  validation loss:		1.135972
  validation accuracy:		59.57 %
Epoch 833 of 2000 took 0.100s
  training loss:		1.201196
  validation loss:		1.120523
  validation accuracy:		61.52 %
Epoch 834 of 2000 took 0.099s
  training loss:		1.200113
  validation loss:		1.124686
  validation accuracy:		60.54 %
Epoch 835 of 2000 took 0.099s
  training loss:		1.186396
  validation loss:		1.124749
  validation accuracy:		60.43 %
Epoch 836 of 2000 took 0.099s
  training loss:		1.191582
  validation loss:		1.118095
  validation accuracy:		63.26 %
Epoch 837 of 2000 took 0.099s
  training loss:		1.184874
  validation loss:		1.110469
  validation accuracy:		61.85 %
Epoch 838 of 2000 took 0.099s
  training loss:		1.194345
  validation loss:		1.098155
  validation accuracy:		64.02 %
Epoch 839 of 2000 took 0.099s
  training loss:		1.172006
  validation loss:		1.093310
  validation accuracy:		63.48 %
Epoch 840 of 2000 took 0.099s
  training loss:		1.171707
  validation loss:		1.101957
  validation accuracy:		62.39 %
Epoch 841 of 2000 took 0.099s
  training loss:		1.160775
  validation loss:		1.097087
  validation accuracy:		62.39 %
Epoch 842 of 2000 took 0.099s
  training loss:		1.163735
  validation loss:		1.082553
  validation accuracy:		63.91 %
Epoch 843 of 2000 took 0.099s
  training loss:		1.158717
  validation loss:		1.069771
  validation accuracy:		64.02 %
Epoch 844 of 2000 took 0.099s
  training loss:		1.151382
  validation loss:		1.090158
  validation accuracy:		63.70 %
Epoch 845 of 2000 took 0.099s
  training loss:		1.154587
  validation loss:		1.058954
  validation accuracy:		64.57 %
Epoch 846 of 2000 took 0.099s
  training loss:		1.147699
  validation loss:		1.065080
  validation accuracy:		64.89 %
Epoch 847 of 2000 took 0.099s
  training loss:		1.143315
  validation loss:		1.055603
  validation accuracy:		65.00 %
Epoch 848 of 2000 took 0.099s
  training loss:		1.134286
  validation loss:		1.059278
  validation accuracy:		64.67 %
Epoch 849 of 2000 took 0.099s
  training loss:		1.130067
  validation loss:		1.057114
  validation accuracy:		65.00 %
Epoch 850 of 2000 took 0.099s
  training loss:		1.122494
  validation loss:		1.040822
  validation accuracy:		66.41 %
Epoch 851 of 2000 took 0.099s
  training loss:		1.135279
  validation loss:		1.026630
  validation accuracy:		66.41 %
Epoch 852 of 2000 took 0.099s
  training loss:		1.120205
  validation loss:		1.025173
  validation accuracy:		66.52 %
Epoch 853 of 2000 took 0.099s
  training loss:		1.114394
  validation loss:		1.034989
  validation accuracy:		66.09 %
Epoch 854 of 2000 took 0.100s
  training loss:		1.107267
  validation loss:		1.014785
  validation accuracy:		66.63 %
Epoch 855 of 2000 took 0.099s
  training loss:		1.101147
  validation loss:		1.013072
  validation accuracy:		67.39 %
Epoch 856 of 2000 took 0.099s
  training loss:		1.099551
  validation loss:		1.009369
  validation accuracy:		66.96 %
Epoch 857 of 2000 took 0.099s
  training loss:		1.095259
  validation loss:		1.000637
  validation accuracy:		67.93 %
Epoch 858 of 2000 took 0.099s
  training loss:		1.086299
  validation loss:		1.011609
  validation accuracy:		67.72 %
Epoch 859 of 2000 took 0.099s
  training loss:		1.078264
  validation loss:		0.992302
  validation accuracy:		68.91 %
Epoch 860 of 2000 took 0.099s
  training loss:		1.079455
  validation loss:		0.997353
  validation accuracy:		68.26 %
Epoch 861 of 2000 took 0.099s
  training loss:		1.072051
  validation loss:		0.998025
  validation accuracy:		67.93 %
Epoch 862 of 2000 took 0.099s
  training loss:		1.063364
  validation loss:		0.967203
  validation accuracy:		69.24 %
Epoch 863 of 2000 took 0.099s
  training loss:		1.060087
  validation loss:		0.968440
  validation accuracy:		69.46 %
Epoch 864 of 2000 took 0.099s
  training loss:		1.053756
  validation loss:		0.961957
  validation accuracy:		69.13 %
Epoch 865 of 2000 took 0.096s
  training loss:		1.051641
  validation loss:		0.956354
  validation accuracy:		69.57 %
Epoch 866 of 2000 took 0.096s
  training loss:		1.048407
  validation loss:		0.960828
  validation accuracy:		69.35 %
Epoch 867 of 2000 took 0.096s
  training loss:		1.048545
  validation loss:		0.948669
  validation accuracy:		70.00 %
Epoch 868 of 2000 took 0.096s
  training loss:		1.042968
  validation loss:		0.939272
  validation accuracy:		69.78 %
Epoch 869 of 2000 took 0.096s
  training loss:		1.032544
  validation loss:		0.951358
  validation accuracy:		70.54 %
Epoch 870 of 2000 took 0.096s
  training loss:		1.035823
  validation loss:		0.929940
  validation accuracy:		70.65 %
Epoch 871 of 2000 took 0.096s
  training loss:		1.021201
  validation loss:		0.928876
  validation accuracy:		70.98 %
Epoch 872 of 2000 took 0.096s
  training loss:		1.031070
  validation loss:		0.932906
  validation accuracy:		71.63 %
Epoch 873 of 2000 took 0.096s
  training loss:		1.019969
  validation loss:		0.928696
  validation accuracy:		71.30 %
Epoch 874 of 2000 took 0.096s
  training loss:		1.000710
  validation loss:		0.912235
  validation accuracy:		72.72 %
Epoch 875 of 2000 took 0.096s
  training loss:		1.007069
  validation loss:		0.937673
  validation accuracy:		71.20 %
Epoch 876 of 2000 took 0.096s
  training loss:		0.995419
  validation loss:		0.895209
  validation accuracy:		72.50 %
Epoch 877 of 2000 took 0.096s
  training loss:		0.991608
  validation loss:		0.911286
  validation accuracy:		71.63 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.990744
  validation loss:		0.896210
  validation accuracy:		72.28 %
Epoch 879 of 2000 took 0.096s
  training loss:		0.980887
  validation loss:		0.880226
  validation accuracy:		74.02 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.984440
  validation loss:		0.890228
  validation accuracy:		72.72 %
Epoch 881 of 2000 took 0.096s
  training loss:		0.979395
  validation loss:		0.881031
  validation accuracy:		73.48 %
Epoch 882 of 2000 took 0.096s
  training loss:		0.970031
  validation loss:		0.888086
  validation accuracy:		72.93 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.965991
  validation loss:		0.864272
  validation accuracy:		73.70 %
Epoch 884 of 2000 took 0.096s
  training loss:		0.962357
  validation loss:		0.870705
  validation accuracy:		73.80 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.955199
  validation loss:		0.850399
  validation accuracy:		75.11 %
Epoch 886 of 2000 took 0.096s
  training loss:		0.944932
  validation loss:		0.847154
  validation accuracy:		75.00 %
Epoch 887 of 2000 took 0.096s
  training loss:		0.932612
  validation loss:		0.860663
  validation accuracy:		73.80 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.936827
  validation loss:		0.845657
  validation accuracy:		75.11 %
Epoch 889 of 2000 took 0.096s
  training loss:		0.930763
  validation loss:		0.829036
  validation accuracy:		75.76 %
Epoch 890 of 2000 took 0.096s
  training loss:		0.931400
  validation loss:		0.830584
  validation accuracy:		75.22 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.922467
  validation loss:		0.835113
  validation accuracy:		75.98 %
Epoch 892 of 2000 took 0.096s
  training loss:		0.905813
  validation loss:		0.814329
  validation accuracy:		76.09 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.914967
  validation loss:		0.812360
  validation accuracy:		76.41 %
Epoch 894 of 2000 took 0.096s
  training loss:		0.910944
  validation loss:		0.809783
  validation accuracy:		76.20 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.896846
  validation loss:		0.810397
  validation accuracy:		77.50 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.897562
  validation loss:		0.799824
  validation accuracy:		77.07 %
Epoch 897 of 2000 took 0.096s
  training loss:		0.895348
  validation loss:		0.792176
  validation accuracy:		76.74 %
Epoch 898 of 2000 took 0.096s
  training loss:		0.889439
  validation loss:		0.789237
  validation accuracy:		77.07 %
Epoch 899 of 2000 took 0.096s
  training loss:		0.877820
  validation loss:		0.792801
  validation accuracy:		78.26 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.884706
  validation loss:		0.776215
  validation accuracy:		77.17 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.866700
  validation loss:		0.773064
  validation accuracy:		77.93 %
Epoch 902 of 2000 took 0.096s
  training loss:		0.867575
  validation loss:		0.773321
  validation accuracy:		77.83 %
Epoch 903 of 2000 took 0.096s
  training loss:		0.867496
  validation loss:		0.778185
  validation accuracy:		78.70 %
Epoch 904 of 2000 took 0.096s
  training loss:		0.858584
  validation loss:		0.767044
  validation accuracy:		79.13 %
Epoch 905 of 2000 took 0.096s
  training loss:		0.849768
  validation loss:		0.754427
  validation accuracy:		77.61 %
Epoch 906 of 2000 took 0.096s
  training loss:		0.848492
  validation loss:		0.755861
  validation accuracy:		78.80 %
Epoch 907 of 2000 took 0.096s
  training loss:		0.850285
  validation loss:		0.745727
  validation accuracy:		78.70 %
Epoch 908 of 2000 took 0.096s
  training loss:		0.842611
  validation loss:		0.742661
  validation accuracy:		78.48 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.841939
  validation loss:		0.738477
  validation accuracy:		78.59 %
Epoch 910 of 2000 took 0.096s
  training loss:		0.833979
  validation loss:		0.737043
  validation accuracy:		79.24 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.833515
  validation loss:		0.743003
  validation accuracy:		78.80 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.829166
  validation loss:		0.736000
  validation accuracy:		79.46 %
Epoch 913 of 2000 took 0.096s
  training loss:		0.829880
  validation loss:		0.727005
  validation accuracy:		79.24 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.814896
  validation loss:		0.727845
  validation accuracy:		78.91 %
Epoch 915 of 2000 took 0.096s
  training loss:		0.812393
  validation loss:		0.719327
  validation accuracy:		79.46 %
Epoch 916 of 2000 took 0.096s
  training loss:		0.811809
  validation loss:		0.714762
  validation accuracy:		79.89 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.809847
  validation loss:		0.717809
  validation accuracy:		79.35 %
Epoch 918 of 2000 took 0.096s
  training loss:		0.801036
  validation loss:		0.707528
  validation accuracy:		79.24 %
Epoch 919 of 2000 took 0.098s
  training loss:		0.803534
  validation loss:		0.713976
  validation accuracy:		78.70 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.796393
  validation loss:		0.714012
  validation accuracy:		79.13 %
Epoch 921 of 2000 took 0.096s
  training loss:		0.787871
  validation loss:		0.697859
  validation accuracy:		79.46 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.793532
  validation loss:		0.699469
  validation accuracy:		79.13 %
Epoch 923 of 2000 took 0.096s
  training loss:		0.790692
  validation loss:		0.707585
  validation accuracy:		80.33 %
Epoch 924 of 2000 took 0.096s
  training loss:		0.793779
  validation loss:		0.696545
  validation accuracy:		79.57 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.785134
  validation loss:		0.688583
  validation accuracy:		80.22 %
Epoch 926 of 2000 took 0.096s
  training loss:		0.780444
  validation loss:		0.694537
  validation accuracy:		80.00 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.776655
  validation loss:		0.697420
  validation accuracy:		79.78 %
Epoch 928 of 2000 took 0.096s
  training loss:		0.787480
  validation loss:		0.693833
  validation accuracy:		80.22 %
Epoch 929 of 2000 took 0.096s
  training loss:		0.768432
  validation loss:		0.687433
  validation accuracy:		80.00 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.769013
  validation loss:		0.695098
  validation accuracy:		79.78 %
Epoch 931 of 2000 took 0.096s
  training loss:		0.770661
  validation loss:		0.684147
  validation accuracy:		80.00 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.761707
  validation loss:		0.676070
  validation accuracy:		80.22 %
Epoch 933 of 2000 took 0.096s
  training loss:		0.759712
  validation loss:		0.678088
  validation accuracy:		79.13 %
Epoch 934 of 2000 took 0.096s
  training loss:		0.759083
  validation loss:		0.670741
  validation accuracy:		80.33 %
Epoch 935 of 2000 took 0.096s
  training loss:		0.755577
  validation loss:		0.675812
  validation accuracy:		79.67 %
Epoch 936 of 2000 took 0.096s
  training loss:		0.754688
  validation loss:		0.669700
  validation accuracy:		80.22 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.747254
  validation loss:		0.665011
  validation accuracy:		80.43 %
Epoch 938 of 2000 took 0.096s
  training loss:		0.747057
  validation loss:		0.686592
  validation accuracy:		79.24 %
Epoch 939 of 2000 took 0.096s
  training loss:		0.750631
  validation loss:		0.660704
  validation accuracy:		80.76 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.743651
  validation loss:		0.660774
  validation accuracy:		80.87 %
Epoch 941 of 2000 took 0.096s
  training loss:		0.743820
  validation loss:		0.655731
  validation accuracy:		80.43 %
Epoch 942 of 2000 took 0.096s
  training loss:		0.735887
  validation loss:		0.653379
  validation accuracy:		80.54 %
Epoch 943 of 2000 took 0.096s
  training loss:		0.740429
  validation loss:		0.672938
  validation accuracy:		80.65 %
Epoch 944 of 2000 took 0.096s
  training loss:		0.735881
  validation loss:		0.653615
  validation accuracy:		80.43 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.738428
  validation loss:		0.644762
  validation accuracy:		80.65 %
Epoch 946 of 2000 took 0.096s
  training loss:		0.732122
  validation loss:		0.652522
  validation accuracy:		80.33 %
Epoch 947 of 2000 took 0.096s
  training loss:		0.732959
  validation loss:		0.645527
  validation accuracy:		80.65 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.724373
  validation loss:		0.658900
  validation accuracy:		80.87 %
Epoch 949 of 2000 took 0.096s
  training loss:		0.724878
  validation loss:		0.659498
  validation accuracy:		80.22 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.713842
  validation loss:		0.641507
  validation accuracy:		80.76 %
Epoch 951 of 2000 took 0.096s
  training loss:		0.726071
  validation loss:		0.652996
  validation accuracy:		81.20 %
Epoch 952 of 2000 took 0.096s
  training loss:		0.719402
  validation loss:		0.657241
  validation accuracy:		80.33 %
Epoch 953 of 2000 took 0.096s
  training loss:		0.726925
  validation loss:		0.643119
  validation accuracy:		80.76 %
Epoch 954 of 2000 took 0.096s
  training loss:		0.717119
  validation loss:		0.645284
  validation accuracy:		80.98 %
Epoch 955 of 2000 took 0.096s
  training loss:		0.711060
  validation loss:		0.634221
  validation accuracy:		80.76 %
Epoch 956 of 2000 took 0.096s
  training loss:		0.716926
  validation loss:		0.631613
  validation accuracy:		80.65 %
Epoch 957 of 2000 took 0.096s
  training loss:		0.727595
  validation loss:		0.635782
  validation accuracy:		80.87 %
Epoch 958 of 2000 took 0.096s
  training loss:		0.704892
  validation loss:		0.640486
  validation accuracy:		81.52 %
Epoch 959 of 2000 took 0.096s
  training loss:		0.709675
  validation loss:		0.630331
  validation accuracy:		80.87 %
Epoch 960 of 2000 took 0.096s
  training loss:		0.694584
  validation loss:		0.635729
  validation accuracy:		81.41 %
Epoch 961 of 2000 took 0.096s
  training loss:		0.698833
  validation loss:		0.629285
  validation accuracy:		80.87 %
Epoch 962 of 2000 took 0.096s
  training loss:		0.698073
  validation loss:		0.623162
  validation accuracy:		81.09 %
Epoch 963 of 2000 took 0.096s
  training loss:		0.709986
  validation loss:		0.638260
  validation accuracy:		80.87 %
Epoch 964 of 2000 took 0.096s
  training loss:		0.711813
  validation loss:		0.629957
  validation accuracy:		79.89 %
Epoch 965 of 2000 took 0.096s
  training loss:		0.704928
  validation loss:		0.623344
  validation accuracy:		80.54 %
Epoch 966 of 2000 took 0.096s
  training loss:		0.700028
  validation loss:		0.624395
  validation accuracy:		81.20 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.684729
  validation loss:		0.617021
  validation accuracy:		81.41 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.695757
  validation loss:		0.628767
  validation accuracy:		81.20 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.673816
  validation loss:		0.626263
  validation accuracy:		81.63 %
Epoch 970 of 2000 took 0.096s
  training loss:		0.694905
  validation loss:		0.624093
  validation accuracy:		81.52 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.713843
  validation loss:		0.665537
  validation accuracy:		79.67 %
Epoch 972 of 2000 took 0.096s
  training loss:		0.712317
  validation loss:		0.649644
  validation accuracy:		80.22 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.685751
  validation loss:		0.632143
  validation accuracy:		80.54 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.679149
  validation loss:		0.611031
  validation accuracy:		81.20 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.691917
  validation loss:		0.626882
  validation accuracy:		81.09 %
Epoch 976 of 2000 took 0.096s
  training loss:		0.683385
  validation loss:		0.638451
  validation accuracy:		80.22 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.682438
  validation loss:		0.614070
  validation accuracy:		81.09 %
Epoch 978 of 2000 took 0.096s
  training loss:		0.671617
  validation loss:		0.613250
  validation accuracy:		81.41 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.685033
  validation loss:		0.609939
  validation accuracy:		81.41 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.679990
  validation loss:		0.609150
  validation accuracy:		81.09 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.695819
  validation loss:		0.624127
  validation accuracy:		80.65 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.671339
  validation loss:		0.626252
  validation accuracy:		80.98 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.678175
  validation loss:		0.637376
  validation accuracy:		80.76 %
Epoch 984 of 2000 took 0.096s
  training loss:		0.690688
  validation loss:		0.661664
  validation accuracy:		78.91 %
Epoch 985 of 2000 took 0.096s
  training loss:		0.683228
  validation loss:		0.604537
  validation accuracy:		82.07 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.677436
  validation loss:		0.606754
  validation accuracy:		81.63 %
Epoch 987 of 2000 took 0.096s
  training loss:		0.665231
  validation loss:		0.615942
  validation accuracy:		81.30 %
Epoch 988 of 2000 took 0.096s
  training loss:		0.677243
  validation loss:		0.630184
  validation accuracy:		80.54 %
Epoch 989 of 2000 took 0.096s
  training loss:		0.661894
  validation loss:		0.605197
  validation accuracy:		82.28 %
Epoch 990 of 2000 took 0.100s
  training loss:		0.683350
  validation loss:		0.612845
  validation accuracy:		81.63 %
Epoch 991 of 2000 took 0.105s
  training loss:		0.693761
  validation loss:		0.608969
  validation accuracy:		81.63 %
Epoch 992 of 2000 took 0.165s
  training loss:		0.662722
  validation loss:		0.613538
  validation accuracy:		81.52 %
Epoch 993 of 2000 took 0.106s
  training loss:		0.661251
  validation loss:		0.630524
  validation accuracy:		81.09 %
Epoch 994 of 2000 took 0.109s
  training loss:		0.664373
  validation loss:		0.606410
  validation accuracy:		81.52 %
Epoch 995 of 2000 took 0.103s
  training loss:		0.656234
  validation loss:		0.607821
  validation accuracy:		81.52 %
Epoch 996 of 2000 took 0.105s
  training loss:		0.674815
  validation loss:		0.597580
  validation accuracy:		81.20 %
Epoch 997 of 2000 took 0.102s
  training loss:		0.654304
  validation loss:		0.600658
  validation accuracy:		80.87 %
Epoch 998 of 2000 took 0.113s
  training loss:		0.676744
  validation loss:		0.628411
  validation accuracy:		80.11 %
Epoch 999 of 2000 took 0.106s
  training loss:		0.663876
  validation loss:		0.629474
  validation accuracy:		80.65 %
Epoch 1000 of 2000 took 0.101s
  training loss:		0.661518
  validation loss:		0.611628
  validation accuracy:		80.87 %
Epoch 1001 of 2000 took 0.110s
  training loss:		0.668293
  validation loss:		0.599095
  validation accuracy:		81.74 %
Epoch 1002 of 2000 took 0.102s
  training loss:		0.648523
  validation loss:		0.599037
  validation accuracy:		81.74 %
Epoch 1003 of 2000 took 0.105s
  training loss:		0.647562
  validation loss:		0.623055
  validation accuracy:		80.65 %
Epoch 1004 of 2000 took 0.102s
  training loss:		0.662201
  validation loss:		0.612143
  validation accuracy:		80.98 %
Epoch 1005 of 2000 took 0.105s
  training loss:		0.659670
  validation loss:		0.594937
  validation accuracy:		80.76 %
Epoch 1006 of 2000 took 0.108s
  training loss:		0.641553
  validation loss:		0.597971
  validation accuracy:		81.52 %
Epoch 1007 of 2000 took 0.101s
  training loss:		0.641882
  validation loss:		0.596764
  validation accuracy:		81.52 %
Epoch 1008 of 2000 took 0.105s
  training loss:		0.658963
  validation loss:		0.611165
  validation accuracy:		80.65 %
Epoch 1009 of 2000 took 0.107s
  training loss:		0.651240
  validation loss:		0.591752
  validation accuracy:		81.09 %
Epoch 1010 of 2000 took 0.101s
  training loss:		0.647248
  validation loss:		0.618852
  validation accuracy:		81.52 %
Epoch 1011 of 2000 took 0.103s
  training loss:		0.642681
  validation loss:		0.590439
  validation accuracy:		81.30 %
Epoch 1012 of 2000 took 0.101s
  training loss:		0.647050
  validation loss:		0.601352
  validation accuracy:		82.07 %
Epoch 1013 of 2000 took 0.109s
  training loss:		0.633433
  validation loss:		0.595922
  validation accuracy:		81.09 %
Epoch 1014 of 2000 took 0.103s
  training loss:		0.639409
  validation loss:		0.679000
  validation accuracy:		78.70 %
Epoch 1015 of 2000 took 0.102s
  training loss:		0.648564
  validation loss:		0.592443
  validation accuracy:		81.52 %
Epoch 1016 of 2000 took 0.110s
  training loss:		0.645444
  validation loss:		0.672025
  validation accuracy:		78.91 %
Epoch 1017 of 2000 took 0.101s
  training loss:		0.650070
  validation loss:		0.602602
  validation accuracy:		81.41 %
Epoch 1018 of 2000 took 0.104s
  training loss:		0.648729
  validation loss:		0.592167
  validation accuracy:		81.09 %
Epoch 1019 of 2000 took 0.101s
  training loss:		0.646747
  validation loss:		0.605219
  validation accuracy:		80.43 %
Epoch 1020 of 2000 took 0.106s
  training loss:		0.628393
  validation loss:		0.588712
  validation accuracy:		80.76 %
Epoch 1021 of 2000 took 0.107s
  training loss:		0.650450
  validation loss:		0.699303
  validation accuracy:		78.26 %
Epoch 1022 of 2000 took 0.101s
  training loss:		0.640828
  validation loss:		0.625420
  validation accuracy:		80.87 %
Epoch 1023 of 2000 took 0.107s
  training loss:		0.673459
  validation loss:		0.594337
  validation accuracy:		81.09 %
Epoch 1024 of 2000 took 0.106s
  training loss:		0.629725
  validation loss:		0.617372
  validation accuracy:		80.43 %
Epoch 1025 of 2000 took 0.102s
  training loss:		0.632098
  validation loss:		0.602837
  validation accuracy:		81.41 %
Epoch 1026 of 2000 took 0.102s
  training loss:		0.641562
  validation loss:		0.599249
  validation accuracy:		80.98 %
Epoch 1027 of 2000 took 0.102s
  training loss:		0.641751
  validation loss:		0.609416
  validation accuracy:		80.65 %
Epoch 1028 of 2000 took 0.109s
  training loss:		0.664474
  validation loss:		0.594011
  validation accuracy:		80.98 %
Epoch 1029 of 2000 took 0.129s
  training loss:		0.629318
  validation loss:		0.591012
  validation accuracy:		80.87 %
Epoch 1030 of 2000 took 0.157s
  training loss:		0.649382
  validation loss:		0.589428
  validation accuracy:		80.87 %
Epoch 1031 of 2000 took 0.162s
  training loss:		0.622567
  validation loss:		0.589576
  validation accuracy:		81.20 %
Epoch 1032 of 2000 took 0.167s
  training loss:		0.644626
  validation loss:		0.602591
  validation accuracy:		80.54 %
Epoch 1033 of 2000 took 0.136s
  training loss:		0.619180
  validation loss:		0.590084
  validation accuracy:		81.30 %
Epoch 1034 of 2000 took 0.144s
  training loss:		0.622955
  validation loss:		0.597957
  validation accuracy:		80.54 %
Epoch 1035 of 2000 took 0.175s
  training loss:		0.636546
  validation loss:		0.596453
  validation accuracy:		80.65 %
Epoch 1036 of 2000 took 0.136s
  training loss:		0.621998
  validation loss:		0.602762
  validation accuracy:		80.76 %
Epoch 1037 of 2000 took 0.167s
  training loss:		0.629308
  validation loss:		0.588492
  validation accuracy:		81.41 %
Epoch 1038 of 2000 took 0.160s
  training loss:		0.624631
  validation loss:		0.584621
  validation accuracy:		81.41 %
Epoch 1039 of 2000 took 0.151s
  training loss:		0.631352
  validation loss:		0.584482
  validation accuracy:		81.20 %
Epoch 1040 of 2000 took 0.170s
  training loss:		0.623040
  validation loss:		0.594365
  validation accuracy:		81.20 %
Epoch 1041 of 2000 took 0.139s
  training loss:		0.622734
  validation loss:		0.589139
  validation accuracy:		81.30 %
Epoch 1042 of 2000 took 0.173s
  training loss:		0.636693
  validation loss:		0.585506
  validation accuracy:		81.09 %
Epoch 1043 of 2000 took 0.147s
  training loss:		0.627515
  validation loss:		0.590242
  validation accuracy:		80.98 %
Epoch 1044 of 2000 took 0.161s
  training loss:		0.645033
  validation loss:		0.597708
  validation accuracy:		80.33 %
Epoch 1045 of 2000 took 0.172s
  training loss:		0.632221
  validation loss:		0.589678
  validation accuracy:		81.09 %
Epoch 1046 of 2000 took 0.138s
  training loss:		0.627224
  validation loss:		0.586390
  validation accuracy:		81.41 %
Epoch 1047 of 2000 took 0.168s
  training loss:		0.621687
  validation loss:		0.595101
  validation accuracy:		80.98 %
Epoch 1048 of 2000 took 0.136s
  training loss:		0.621738
  validation loss:		0.590989
  validation accuracy:		81.09 %
Epoch 1049 of 2000 took 0.169s
  training loss:		0.631102
  validation loss:		0.614338
  validation accuracy:		80.54 %
Epoch 1050 of 2000 took 0.166s
  training loss:		0.633037
  validation loss:		0.598878
  validation accuracy:		80.87 %
Epoch 1051 of 2000 took 0.144s
  training loss:		0.623080
  validation loss:		0.604169
  validation accuracy:		80.43 %
Epoch 1052 of 2000 took 0.170s
  training loss:		0.621892
  validation loss:		0.606666
  validation accuracy:		80.43 %
Epoch 1053 of 2000 took 0.144s
  training loss:		0.617732
  validation loss:		0.596017
  validation accuracy:		80.98 %
Epoch 1054 of 2000 took 0.167s
  training loss:		0.618544
  validation loss:		0.592951
  validation accuracy:		80.98 %
Epoch 1055 of 2000 took 0.162s
  training loss:		0.624346
  validation loss:		0.607440
  validation accuracy:		80.43 %
Epoch 1056 of 2000 took 0.164s
  training loss:		0.612349
  validation loss:		0.591781
  validation accuracy:		80.76 %
Epoch 1057 of 2000 took 0.165s
  training loss:		0.619121
  validation loss:		0.593713
  validation accuracy:		81.74 %
Epoch 1058 of 2000 took 0.157s
  training loss:		0.646789
  validation loss:		0.596403
  validation accuracy:		80.98 %
Epoch 1059 of 2000 took 0.165s
  training loss:		0.613781
  validation loss:		0.582742
  validation accuracy:		81.74 %
Epoch 1060 of 2000 took 0.157s
  training loss:		0.624376
  validation loss:		0.607779
  validation accuracy:		80.22 %
Epoch 1061 of 2000 took 0.164s
  training loss:		0.607643
  validation loss:		0.585282
  validation accuracy:		81.30 %
Epoch 1062 of 2000 took 0.159s
  training loss:		0.621874
  validation loss:		0.590255
  validation accuracy:		81.09 %
Epoch 1063 of 2000 took 0.164s
  training loss:		0.611878
  validation loss:		0.632841
  validation accuracy:		78.80 %
Epoch 1064 of 2000 took 0.165s
  training loss:		0.622939
  validation loss:		0.588873
  validation accuracy:		81.09 %
Epoch 1065 of 2000 took 0.157s
  training loss:		0.616069
  validation loss:		0.587825
  validation accuracy:		81.74 %
Epoch 1066 of 2000 took 0.165s
  training loss:		0.611715
  validation loss:		0.589224
  validation accuracy:		81.20 %
Epoch 1067 of 2000 took 0.174s
  training loss:		0.603903
  validation loss:		0.586354
  validation accuracy:		81.30 %
Epoch 1068 of 2000 took 0.164s
  training loss:		0.612196
  validation loss:		0.601928
  validation accuracy:		81.20 %
Epoch 1069 of 2000 took 0.159s
  training loss:		0.609705
  validation loss:		0.581546
  validation accuracy:		81.09 %
Epoch 1070 of 2000 took 0.164s
  training loss:		0.612348
  validation loss:		0.612407
  validation accuracy:		80.43 %
Epoch 1071 of 2000 took 0.165s
  training loss:		0.614110
  validation loss:		0.603266
  validation accuracy:		81.09 %
Epoch 1072 of 2000 took 0.157s
  training loss:		0.612053
  validation loss:		0.581292
  validation accuracy:		81.20 %
Epoch 1073 of 2000 took 0.164s
  training loss:		0.596192
  validation loss:		0.587432
  validation accuracy:		81.20 %
Epoch 1074 of 2000 took 0.158s
  training loss:		0.614362
  validation loss:		0.578568
  validation accuracy:		81.41 %
Epoch 1075 of 2000 took 0.164s
  training loss:		0.613903
  validation loss:		0.596613
  validation accuracy:		81.41 %
Epoch 1076 of 2000 took 0.160s
  training loss:		0.610120
  validation loss:		0.613685
  validation accuracy:		79.89 %
Epoch 1077 of 2000 took 0.163s
  training loss:		0.614611
  validation loss:		0.587704
  validation accuracy:		81.09 %
Epoch 1078 of 2000 took 0.165s
  training loss:		0.603921
  validation loss:		0.642467
  validation accuracy:		79.24 %
Epoch 1079 of 2000 took 0.178s
  training loss:		0.620066
  validation loss:		0.598731
  validation accuracy:		81.20 %
Epoch 1080 of 2000 took 0.164s
  training loss:		0.603893
  validation loss:		0.588155
  validation accuracy:		81.63 %
Epoch 1081 of 2000 took 0.161s
  training loss:		0.615408
  validation loss:		0.593867
  validation accuracy:		81.52 %
Epoch 1082 of 2000 took 0.164s
  training loss:		0.622652
  validation loss:		0.580530
  validation accuracy:		81.30 %
Epoch 1083 of 2000 took 0.158s
  training loss:		0.619125
  validation loss:		0.597180
  validation accuracy:		80.98 %
Epoch 1084 of 2000 took 0.164s
  training loss:		0.602738
  validation loss:		0.592138
  validation accuracy:		81.63 %
Epoch 1085 of 2000 took 0.165s
  training loss:		0.605772
  validation loss:		0.597888
  validation accuracy:		81.63 %
Epoch 1086 of 2000 took 0.157s
  training loss:		0.615367
  validation loss:		0.620774
  validation accuracy:		80.00 %
Epoch 1087 of 2000 took 0.165s
  training loss:		0.605202
  validation loss:		0.586046
  validation accuracy:		81.30 %
Epoch 1088 of 2000 took 0.157s
  training loss:		0.607387
  validation loss:		0.590226
  validation accuracy:		81.74 %
Epoch 1089 of 2000 took 0.164s
  training loss:		0.602161
  validation loss:		0.580729
  validation accuracy:		81.30 %
Epoch 1090 of 2000 took 0.159s
  training loss:		0.627405
  validation loss:		0.590977
  validation accuracy:		81.85 %
Epoch 1091 of 2000 took 0.164s
  training loss:		0.599802
  validation loss:		0.591021
  validation accuracy:		81.30 %
Epoch 1092 of 2000 took 0.165s
  training loss:		0.607318
  validation loss:		0.588126
  validation accuracy:		81.30 %
Epoch 1093 of 2000 took 0.157s
  training loss:		0.619961
  validation loss:		0.618203
  validation accuracy:		80.33 %
Epoch 1094 of 2000 took 0.164s
  training loss:		0.644965
  validation loss:		0.581465
  validation accuracy:		81.74 %
Epoch 1095 of 2000 took 0.165s
  training loss:		0.596464
  validation loss:		0.582041
  validation accuracy:		81.09 %
Epoch 1096 of 2000 took 0.157s
  training loss:		0.611622
  validation loss:		0.584116
  validation accuracy:		81.52 %
Epoch 1097 of 2000 took 0.164s
  training loss:		0.598888
  validation loss:		0.585400
  validation accuracy:		80.87 %
Epoch 1098 of 2000 took 0.158s
  training loss:		0.594676
  validation loss:		0.593152
  validation accuracy:		80.98 %
Epoch 1099 of 2000 took 0.164s
  training loss:		0.604878
  validation loss:		0.580361
  validation accuracy:		81.74 %
Epoch 1100 of 2000 took 0.165s
  training loss:		0.602205
  validation loss:		0.586761
  validation accuracy:		81.09 %
Epoch 1101 of 2000 took 0.157s
  training loss:		0.604050
  validation loss:		0.575681
  validation accuracy:		82.07 %
Epoch 1102 of 2000 took 0.212s
  training loss:		0.597791
  validation loss:		0.585516
  validation accuracy:		81.52 %
Epoch 1103 of 2000 took 0.148s
  training loss:		0.597470
  validation loss:		0.584739
  validation accuracy:		81.30 %
Epoch 1104 of 2000 took 0.166s
  training loss:		0.604278
  validation loss:		0.586255
  validation accuracy:		81.96 %
Epoch 1105 of 2000 took 0.206s
  training loss:		0.626634
  validation loss:		0.578658
  validation accuracy:		81.96 %
Epoch 1106 of 2000 took 0.181s
  training loss:		0.606824
  validation loss:		0.584819
  validation accuracy:		81.52 %
Epoch 1107 of 2000 took 0.218s
  training loss:		0.589376
  validation loss:		0.584979
  validation accuracy:		81.09 %
Epoch 1108 of 2000 took 0.135s
  training loss:		0.606446
  validation loss:		0.578797
  validation accuracy:		81.85 %
Epoch 1109 of 2000 took 0.164s
  training loss:		0.606209
  validation loss:		0.584987
  validation accuracy:		81.85 %
Epoch 1110 of 2000 took 0.152s
  training loss:		0.599036
  validation loss:		0.586375
  validation accuracy:		81.30 %
Epoch 1111 of 2000 took 0.146s
  training loss:		0.604162
  validation loss:		0.590962
  validation accuracy:		81.63 %
Epoch 1112 of 2000 took 0.165s
  training loss:		0.603574
  validation loss:		0.624239
  validation accuracy:		79.02 %
Epoch 1113 of 2000 took 0.134s
  training loss:		0.600674
  validation loss:		0.634335
  validation accuracy:		80.54 %
Epoch 1114 of 2000 took 0.164s
  training loss:		0.599223
  validation loss:		0.591121
  validation accuracy:		80.76 %
Epoch 1115 of 2000 took 0.150s
  training loss:		0.605671
  validation loss:		0.596384
  validation accuracy:		80.76 %
Epoch 1116 of 2000 took 0.149s
  training loss:		0.596746
  validation loss:		0.600196
  validation accuracy:		80.00 %
Epoch 1117 of 2000 took 0.164s
  training loss:		0.601272
  validation loss:		0.580078
  validation accuracy:		82.07 %
Epoch 1118 of 2000 took 0.163s
  training loss:		0.597887
  validation loss:		0.581125
  validation accuracy:		81.30 %
Epoch 1119 of 2000 took 0.110s
  training loss:		0.609089
  validation loss:		0.585785
  validation accuracy:		82.17 %
Epoch 1120 of 2000 took 0.164s
  training loss:		0.595127
  validation loss:		0.573449
  validation accuracy:		82.17 %
Epoch 1121 of 2000 took 0.156s
  training loss:		0.597413
  validation loss:		0.604938
  validation accuracy:		80.43 %
Epoch 1122 of 2000 took 0.142s
  training loss:		0.598679
  validation loss:		0.587714
  validation accuracy:		81.20 %
Epoch 1123 of 2000 took 0.165s
  training loss:		0.606935
  validation loss:		0.580173
  validation accuracy:		81.63 %
Epoch 1124 of 2000 took 0.134s
  training loss:		0.596681
  validation loss:		0.577417
  validation accuracy:		81.85 %
Epoch 1125 of 2000 took 0.164s
  training loss:		0.600258
  validation loss:		0.580884
  validation accuracy:		82.17 %
Epoch 1126 of 2000 took 0.154s
  training loss:		0.598498
  validation loss:		0.595419
  validation accuracy:		81.52 %
Epoch 1127 of 2000 took 0.144s
  training loss:		0.599008
  validation loss:		0.593375
  validation accuracy:		82.07 %
Epoch 1128 of 2000 took 0.165s
  training loss:		0.591168
  validation loss:		0.578892
  validation accuracy:		81.74 %
Epoch 1129 of 2000 took 0.123s
  training loss:		0.597191
  validation loss:		0.583328
  validation accuracy:		82.07 %
Epoch 1130 of 2000 took 0.161s
  training loss:		0.592403
  validation loss:		0.624814
  validation accuracy:		79.46 %
Epoch 1131 of 2000 took 0.165s
  training loss:		0.618920
  validation loss:		0.577806
  validation accuracy:		81.74 %
Epoch 1132 of 2000 took 0.134s
  training loss:		0.601766
  validation loss:		0.596514
  validation accuracy:		80.87 %
Epoch 1133 of 2000 took 0.165s
  training loss:		0.600197
  validation loss:		0.581940
  validation accuracy:		82.07 %
Epoch 1134 of 2000 took 0.134s
  training loss:		0.587753
  validation loss:		0.580724
  validation accuracy:		82.07 %
Epoch 1135 of 2000 took 0.164s
  training loss:		0.592045
  validation loss:		0.578448
  validation accuracy:		82.39 %
Epoch 1136 of 2000 took 0.163s
  training loss:		0.587252
  validation loss:		0.595843
  validation accuracy:		81.74 %
Epoch 1137 of 2000 took 0.136s
  training loss:		0.596336
  validation loss:		0.577635
  validation accuracy:		81.74 %
Epoch 1138 of 2000 took 0.169s
  training loss:		0.602520
  validation loss:		0.585089
  validation accuracy:		80.98 %
Epoch 1139 of 2000 took 0.134s
  training loss:		0.609914
  validation loss:		0.589372
  validation accuracy:		81.74 %
Epoch 1140 of 2000 took 0.164s
  training loss:		0.598765
  validation loss:		0.579829
  validation accuracy:		80.65 %
Epoch 1141 of 2000 took 0.159s
  training loss:		0.603370
  validation loss:		0.576834
  validation accuracy:		82.28 %
Epoch 1142 of 2000 took 0.140s
  training loss:		0.593889
  validation loss:		0.599329
  validation accuracy:		80.76 %
Epoch 1143 of 2000 took 0.165s
  training loss:		0.607799
  validation loss:		0.592243
  validation accuracy:		80.87 %
Epoch 1144 of 2000 took 0.134s
  training loss:		0.602049
  validation loss:		0.583549
  validation accuracy:		82.28 %
Epoch 1145 of 2000 took 0.164s
  training loss:		0.599284
  validation loss:		0.576959
  validation accuracy:		82.07 %
Epoch 1146 of 2000 took 0.157s
  training loss:		0.593267
  validation loss:		0.580701
  validation accuracy:		81.85 %
Epoch 1147 of 2000 took 0.142s
  training loss:		0.604700
  validation loss:		0.581496
  validation accuracy:		82.17 %
Epoch 1148 of 2000 took 0.165s
  training loss:		0.595679
  validation loss:		0.575210
  validation accuracy:		81.85 %
Epoch 1149 of 2000 took 0.134s
  training loss:		0.584988
  validation loss:		0.583684
  validation accuracy:		82.50 %
Epoch 1150 of 2000 took 0.164s
  training loss:		0.586158
  validation loss:		0.579905
  validation accuracy:		82.28 %
Epoch 1151 of 2000 took 0.155s
  training loss:		0.599331
  validation loss:		0.595149
  validation accuracy:		80.98 %
Epoch 1152 of 2000 took 0.144s
  training loss:		0.598205
  validation loss:		0.610057
  validation accuracy:		80.76 %
Epoch 1153 of 2000 took 0.165s
  training loss:		0.588755
  validation loss:		0.595216
  validation accuracy:		80.76 %
Epoch 1154 of 2000 took 0.134s
  training loss:		0.592477
  validation loss:		0.586024
  validation accuracy:		81.20 %
Epoch 1155 of 2000 took 0.164s
  training loss:		0.587246
  validation loss:		0.575552
  validation accuracy:		81.96 %
Epoch 1156 of 2000 took 0.152s
  training loss:		0.588149
  validation loss:		0.574961
  validation accuracy:		82.07 %
Epoch 1157 of 2000 took 0.147s
  training loss:		0.593212
  validation loss:		0.578803
  validation accuracy:		81.96 %
Epoch 1158 of 2000 took 0.165s
  training loss:		0.595449
  validation loss:		0.579551
  validation accuracy:		82.28 %
Epoch 1159 of 2000 took 0.134s
  training loss:		0.594371
  validation loss:		0.578490
  validation accuracy:		82.28 %
Epoch 1160 of 2000 took 0.164s
  training loss:		0.602116
  validation loss:		0.610096
  validation accuracy:		80.43 %
Epoch 1161 of 2000 took 0.150s
  training loss:		0.597076
  validation loss:		0.590670
  validation accuracy:		81.63 %
Epoch 1162 of 2000 took 0.149s
  training loss:		0.601587
  validation loss:		0.627537
  validation accuracy:		79.57 %
Epoch 1163 of 2000 took 0.165s
  training loss:		0.599304
  validation loss:		0.592532
  validation accuracy:		81.96 %
Epoch 1164 of 2000 took 0.134s
  training loss:		0.591303
  validation loss:		0.584051
  validation accuracy:		81.52 %
Epoch 1165 of 2000 took 0.164s
  training loss:		0.598739
  validation loss:		0.581325
  validation accuracy:		81.85 %
Epoch 1166 of 2000 took 0.148s
  training loss:		0.594144
  validation loss:		0.599416
  validation accuracy:		81.30 %
Epoch 1167 of 2000 took 0.151s
  training loss:		0.594160
  validation loss:		0.580566
  validation accuracy:		81.74 %
Epoch 1168 of 2000 took 0.165s
  training loss:		0.589068
  validation loss:		0.588014
  validation accuracy:		80.76 %
Epoch 1169 of 2000 took 0.134s
  training loss:		0.588038
  validation loss:		0.577317
  validation accuracy:		82.39 %
Epoch 1170 of 2000 took 0.164s
  training loss:		0.592859
  validation loss:		0.577441
  validation accuracy:		81.96 %
Epoch 1171 of 2000 took 0.145s
  training loss:		0.591649
  validation loss:		0.580697
  validation accuracy:		82.07 %
Epoch 1172 of 2000 took 0.147s
  training loss:		0.607609
  validation loss:		0.599952
  validation accuracy:		81.52 %
Epoch 1173 of 2000 took 0.165s
  training loss:		0.594802
  validation loss:		0.583551
  validation accuracy:		82.17 %
Epoch 1174 of 2000 took 0.133s
  training loss:		0.607593
  validation loss:		0.586970
  validation accuracy:		80.98 %
Epoch 1175 of 2000 took 0.164s
  training loss:		0.587562
  validation loss:		0.574426
  validation accuracy:		82.07 %
Epoch 1176 of 2000 took 0.151s
  training loss:		0.595605
  validation loss:		0.571850
  validation accuracy:		81.74 %
Epoch 1177 of 2000 took 0.148s
  training loss:		0.574402
  validation loss:		0.582357
  validation accuracy:		81.52 %
Epoch 1178 of 2000 took 0.165s
  training loss:		0.588389
  validation loss:		0.579827
  validation accuracy:		82.17 %
Epoch 1179 of 2000 took 0.134s
  training loss:		0.601036
  validation loss:		0.575512
  validation accuracy:		82.39 %
Epoch 1180 of 2000 took 0.164s
  training loss:		0.589333
  validation loss:		0.582455
  validation accuracy:		81.52 %
Epoch 1181 of 2000 took 0.148s
  training loss:		0.591315
  validation loss:		0.595256
  validation accuracy:		81.96 %
Epoch 1182 of 2000 took 0.151s
  training loss:		0.605235
  validation loss:		0.582327
  validation accuracy:		81.41 %
Epoch 1183 of 2000 took 0.165s
  training loss:		0.601682
  validation loss:		0.592792
  validation accuracy:		81.74 %
Epoch 1184 of 2000 took 0.131s
  training loss:		0.596051
  validation loss:		0.579233
  validation accuracy:		81.85 %
Epoch 1185 of 2000 took 0.164s
  training loss:		0.588789
  validation loss:		0.592195
  validation accuracy:		81.74 %
Epoch 1186 of 2000 took 0.148s
  training loss:		0.592270
  validation loss:		0.576113
  validation accuracy:		82.17 %
Epoch 1187 of 2000 took 0.151s
  training loss:		0.589921
  validation loss:		0.574888
  validation accuracy:		82.07 %
Epoch 1188 of 2000 took 0.165s
  training loss:		0.595350
  validation loss:		0.581490
  validation accuracy:		81.52 %
Epoch 1189 of 2000 took 0.134s
  training loss:		0.590311
  validation loss:		0.582697
  validation accuracy:		81.30 %
Epoch 1190 of 2000 took 0.164s
  training loss:		0.584949
  validation loss:		0.579551
  validation accuracy:		81.63 %
Epoch 1191 of 2000 took 0.151s
  training loss:		0.603592
  validation loss:		0.584206
  validation accuracy:		81.09 %
Epoch 1192 of 2000 took 0.148s
  training loss:		0.603541
  validation loss:		0.574279
  validation accuracy:		82.28 %
Epoch 1193 of 2000 took 0.165s
  training loss:		0.598158
  validation loss:		0.580939
  validation accuracy:		81.96 %
Epoch 1194 of 2000 took 0.134s
  training loss:		0.596806
  validation loss:		0.585259
  validation accuracy:		81.41 %
Epoch 1195 of 2000 took 0.164s
  training loss:		0.597057
  validation loss:		0.597948
  validation accuracy:		80.65 %
Epoch 1196 of 2000 took 0.149s
  training loss:		0.596345
  validation loss:		0.582442
  validation accuracy:		81.74 %
Epoch 1197 of 2000 took 0.150s
  training loss:		0.592618
  validation loss:		0.587367
  validation accuracy:		82.07 %
Epoch 1198 of 2000 took 0.165s
  training loss:		0.583447
  validation loss:		0.576583
  validation accuracy:		81.85 %
Epoch 1199 of 2000 took 0.134s
  training loss:		0.588315
  validation loss:		0.584617
  validation accuracy:		81.41 %
Epoch 1200 of 2000 took 0.164s
  training loss:		0.595174
  validation loss:		0.577151
  validation accuracy:		82.50 %
Epoch 1201 of 2000 took 0.146s
  training loss:		0.594222
  validation loss:		0.582586
  validation accuracy:		81.85 %
Epoch 1202 of 2000 took 0.153s
  training loss:		0.594614
  validation loss:		0.579307
  validation accuracy:		82.17 %
Epoch 1203 of 2000 took 0.166s
  training loss:		0.583962
  validation loss:		0.573341
  validation accuracy:		82.07 %
Epoch 1204 of 2000 took 0.134s
  training loss:		0.582093
  validation loss:		0.586235
  validation accuracy:		81.20 %
Epoch 1205 of 2000 took 0.164s
  training loss:		0.581417
  validation loss:		0.578962
  validation accuracy:		82.07 %
Epoch 1206 of 2000 took 0.144s
  training loss:		0.588969
  validation loss:		0.611224
  validation accuracy:		80.00 %
Epoch 1207 of 2000 took 0.155s
  training loss:		0.588216
  validation loss:		0.579781
  validation accuracy:		81.96 %
Epoch 1208 of 2000 took 0.166s
  training loss:		0.600637
  validation loss:		0.623840
  validation accuracy:		80.76 %
Epoch 1209 of 2000 took 0.134s
  training loss:		0.596466
  validation loss:		0.574840
  validation accuracy:		81.85 %
Epoch 1210 of 2000 took 0.164s
  training loss:		0.583761
  validation loss:		0.590544
  validation accuracy:		82.17 %
Epoch 1211 of 2000 took 0.146s
  training loss:		0.591482
  validation loss:		0.574680
  validation accuracy:		82.28 %
Epoch 1212 of 2000 took 0.153s
  training loss:		0.597224
  validation loss:		0.589580
  validation accuracy:		80.76 %
Epoch 1213 of 2000 took 0.165s
  training loss:		0.602946
  validation loss:		0.583635
  validation accuracy:		81.85 %
Epoch 1214 of 2000 took 0.134s
  training loss:		0.605569
  validation loss:		0.585530
  validation accuracy:		81.30 %
Epoch 1215 of 2000 took 0.164s
  training loss:		0.587026
  validation loss:		0.586720
  validation accuracy:		82.17 %
Epoch 1216 of 2000 took 0.143s
  training loss:		0.608200
  validation loss:		0.587239
  validation accuracy:		81.41 %
Epoch 1217 of 2000 took 0.157s
  training loss:		0.594656
  validation loss:		0.578326
  validation accuracy:		82.39 %
Epoch 1218 of 2000 took 0.165s
  training loss:		0.597820
  validation loss:		0.601762
  validation accuracy:		80.87 %
Epoch 1219 of 2000 took 0.134s
  training loss:		0.583118
  validation loss:		0.595528
  validation accuracy:		82.07 %
Epoch 1220 of 2000 took 0.164s
  training loss:		0.596872
  validation loss:		0.584423
  validation accuracy:		81.41 %
Epoch 1221 of 2000 took 0.139s
  training loss:		0.592925
  validation loss:		0.575999
  validation accuracy:		82.61 %
Epoch 1222 of 2000 took 0.160s
  training loss:		0.598792
  validation loss:		0.577850
  validation accuracy:		82.07 %
Epoch 1223 of 2000 took 0.166s
  training loss:		0.577520
  validation loss:		0.577329
  validation accuracy:		81.85 %
Epoch 1224 of 2000 took 0.134s
  training loss:		0.584849
  validation loss:		0.574950
  validation accuracy:		82.61 %
Epoch 1225 of 2000 took 0.165s
  training loss:		0.594717
  validation loss:		0.590583
  validation accuracy:		80.98 %
Epoch 1226 of 2000 took 0.136s
  training loss:		0.595872
  validation loss:		0.597010
  validation accuracy:		80.76 %
Epoch 1227 of 2000 took 0.163s
  training loss:		0.591530
  validation loss:		0.585444
  validation accuracy:		81.63 %
Epoch 1228 of 2000 took 0.166s
  training loss:		0.595486
  validation loss:		0.572660
  validation accuracy:		81.41 %
Epoch 1229 of 2000 took 0.134s
  training loss:		0.600752
  validation loss:		0.604369
  validation accuracy:		81.52 %
Epoch 1230 of 2000 took 0.165s
  training loss:		0.594405
  validation loss:		0.579322
  validation accuracy:		81.96 %
Epoch 1231 of 2000 took 0.136s
  training loss:		0.593846
  validation loss:		0.592727
  validation accuracy:		82.07 %
Epoch 1232 of 2000 took 0.163s
  training loss:		0.585644
  validation loss:		0.578942
  validation accuracy:		81.74 %
Epoch 1233 of 2000 took 0.164s
  training loss:		0.594386
  validation loss:		0.583601
  validation accuracy:		81.63 %
Epoch 1234 of 2000 took 0.136s
  training loss:		0.583586
  validation loss:		0.571013
  validation accuracy:		82.50 %
Epoch 1235 of 2000 took 0.165s
  training loss:		0.591645
  validation loss:		0.579304
  validation accuracy:		81.63 %
Epoch 1236 of 2000 took 0.134s
  training loss:		0.583025
  validation loss:		0.585991
  validation accuracy:		82.17 %
Epoch 1237 of 2000 took 0.164s
  training loss:		0.597965
  validation loss:		0.576404
  validation accuracy:		81.85 %
Epoch 1238 of 2000 took 0.160s
  training loss:		0.596899
  validation loss:		0.575186
  validation accuracy:		81.74 %
Epoch 1239 of 2000 took 0.135s
  training loss:		0.590951
  validation loss:		0.573408
  validation accuracy:		81.85 %
Epoch 1240 of 2000 took 0.169s
  training loss:		0.600086
  validation loss:		0.585606
  validation accuracy:		81.41 %
Epoch 1241 of 2000 took 0.145s
  training loss:		0.587961
  validation loss:		0.588778
  validation accuracy:		80.98 %
Epoch 1242 of 2000 took 0.159s
  training loss:		0.595207
  validation loss:		0.583662
  validation accuracy:		81.74 %
Epoch 1243 of 2000 took 0.168s
  training loss:		0.585103
  validation loss:		0.601494
  validation accuracy:		80.43 %
Epoch 1244 of 2000 took 0.153s
  training loss:		0.583978
  validation loss:		0.575967
  validation accuracy:		82.28 %
Epoch 1245 of 2000 took 0.157s
  training loss:		0.587624
  validation loss:		0.576393
  validation accuracy:		82.50 %
Epoch 1246 of 2000 took 0.170s
  training loss:		0.595070
  validation loss:		0.574364
  validation accuracy:		82.07 %
Epoch 1247 of 2000 took 0.134s
  training loss:		0.593481
  validation loss:		0.576100
  validation accuracy:		81.96 %
Epoch 1248 of 2000 took 0.166s
  training loss:		0.580725
  validation loss:		0.585283
  validation accuracy:		81.63 %
Epoch 1249 of 2000 took 0.150s
  training loss:		0.583010
  validation loss:		0.574438
  validation accuracy:		81.96 %
Epoch 1250 of 2000 took 0.161s
  training loss:		0.598567
  validation loss:		0.571121
  validation accuracy:		82.28 %
Epoch 1251 of 2000 took 0.164s
  training loss:		0.596454
  validation loss:		0.572210
  validation accuracy:		82.28 %
Epoch 1252 of 2000 took 0.169s
  training loss:		0.581934
  validation loss:		0.601912
  validation accuracy:		80.22 %
Epoch 1253 of 2000 took 0.117s
  training loss:		0.602390
  validation loss:		0.586805
  validation accuracy:		81.41 %
Epoch 1254 of 2000 took 0.166s
  training loss:		0.595013
  validation loss:		0.585400
  validation accuracy:		81.41 %
Epoch 1255 of 2000 took 0.166s
  training loss:		0.601831
  validation loss:		0.587294
  validation accuracy:		81.41 %
Epoch 1256 of 2000 took 0.147s
  training loss:		0.580411
  validation loss:		0.573331
  validation accuracy:		82.39 %
Epoch 1257 of 2000 took 0.163s
  training loss:		0.586867
  validation loss:		0.586847
  validation accuracy:		81.74 %
Epoch 1258 of 2000 took 0.167s
  training loss:		0.582409
  validation loss:		0.588765
  validation accuracy:		82.07 %
Epoch 1259 of 2000 took 0.143s
  training loss:		0.589422
  validation loss:		0.583045
  validation accuracy:		81.52 %
Epoch 1260 of 2000 took 0.171s
  training loss:		0.599727
  validation loss:		0.582767
  validation accuracy:		81.85 %
Epoch 1261 of 2000 took 0.163s
  training loss:		0.587920
  validation loss:		0.580119
  validation accuracy:		81.74 %
Epoch 1262 of 2000 took 0.140s
  training loss:		0.593734
  validation loss:		0.589397
  validation accuracy:		81.74 %
Epoch 1263 of 2000 took 0.165s
  training loss:		0.593759
  validation loss:		0.579025
  validation accuracy:		81.85 %
Epoch 1264 of 2000 took 0.158s
  training loss:		0.585496
  validation loss:		0.583168
  validation accuracy:		81.30 %
Epoch 1265 of 2000 took 0.131s
  training loss:		0.596966
  validation loss:		0.586063
  validation accuracy:		81.74 %
Epoch 1266 of 2000 took 0.165s
  training loss:		0.588922
  validation loss:		0.585329
  validation accuracy:		81.09 %
Epoch 1267 of 2000 took 0.154s
  training loss:		0.593741
  validation loss:		0.575404
  validation accuracy:		82.07 %
Epoch 1268 of 2000 took 0.137s
  training loss:		0.585431
  validation loss:		0.584440
  validation accuracy:		81.41 %
Epoch 1269 of 2000 took 0.165s
  training loss:		0.582050
  validation loss:		0.584631
  validation accuracy:		81.74 %
Epoch 1270 of 2000 took 0.158s
  training loss:		0.583813
  validation loss:		0.584893
  validation accuracy:		82.28 %
Epoch 1271 of 2000 took 0.125s
  training loss:		0.593950
  validation loss:		0.573478
  validation accuracy:		82.28 %
Epoch 1272 of 2000 took 0.153s
  training loss:		0.591007
  validation loss:		0.579675
  validation accuracy:		82.17 %
Epoch 1273 of 2000 took 0.168s
  training loss:		0.592336
  validation loss:		0.568969
  validation accuracy:		82.39 %
Epoch 1274 of 2000 took 0.149s
  training loss:		0.591005
  validation loss:		0.571930
  validation accuracy:		81.74 %
Epoch 1275 of 2000 took 0.119s
  training loss:		0.593348
  validation loss:		0.587743
  validation accuracy:		82.07 %
Epoch 1276 of 2000 took 0.171s
  training loss:		0.591915
  validation loss:		0.579477
  validation accuracy:		82.17 %
Epoch 1277 of 2000 took 0.163s
  training loss:		0.590171
  validation loss:		0.578187
  validation accuracy:		81.85 %
Epoch 1278 of 2000 took 0.108s
  training loss:		0.586333
  validation loss:		0.581899
  validation accuracy:		81.96 %
Epoch 1279 of 2000 took 0.160s
  training loss:		0.587459
  validation loss:		0.588702
  validation accuracy:		81.74 %
Epoch 1280 of 2000 took 0.169s
  training loss:		0.591219
  validation loss:		0.596718
  validation accuracy:		80.87 %
Epoch 1281 of 2000 took 0.127s
  training loss:		0.579763
  validation loss:		0.572248
  validation accuracy:		81.63 %
Epoch 1282 of 2000 took 0.166s
  training loss:		0.591681
  validation loss:		0.581406
  validation accuracy:		81.30 %
Epoch 1283 of 2000 took 0.166s
  training loss:		0.597524
  validation loss:		0.573647
  validation accuracy:		82.07 %
Epoch 1284 of 2000 took 0.125s
  training loss:		0.599566
  validation loss:		0.594015
  validation accuracy:		80.87 %
Epoch 1285 of 2000 took 0.170s
  training loss:		0.597229
  validation loss:		0.580176
  validation accuracy:		81.41 %
Epoch 1286 of 2000 took 0.167s
  training loss:		0.595116
  validation loss:		0.581423
  validation accuracy:		81.63 %
Epoch 1287 of 2000 took 0.122s
  training loss:		0.595621
  validation loss:		0.598984
  validation accuracy:		80.98 %
Epoch 1288 of 2000 took 0.165s
  training loss:		0.584321
  validation loss:		0.575732
  validation accuracy:		81.96 %
Epoch 1289 of 2000 took 0.173s
  training loss:		0.590141
  validation loss:		0.584587
  validation accuracy:		81.74 %
Epoch 1290 of 2000 took 0.123s
  training loss:		0.589214
  validation loss:		0.575831
  validation accuracy:		81.96 %
Epoch 1291 of 2000 took 0.165s
  training loss:		0.590231
  validation loss:		0.592332
  validation accuracy:		81.20 %
Epoch 1292 of 2000 took 0.163s
  training loss:		0.588387
  validation loss:		0.576189
  validation accuracy:		82.17 %
Epoch 1293 of 2000 took 0.132s
  training loss:		0.585313
  validation loss:		0.584426
  validation accuracy:		81.52 %
Epoch 1294 of 2000 took 0.164s
  training loss:		0.585613
  validation loss:		0.571511
  validation accuracy:		81.74 %
Epoch 1295 of 2000 took 0.165s
  training loss:		0.595444
  validation loss:		0.578468
  validation accuracy:		82.17 %
Epoch 1296 of 2000 took 0.125s
  training loss:		0.596821
  validation loss:		0.582102
  validation accuracy:		81.52 %
Epoch 1297 of 2000 took 0.167s
  training loss:		0.584156
  validation loss:		0.569832
  validation accuracy:		82.50 %
Epoch 1298 of 2000 took 0.166s
  training loss:		0.592684
  validation loss:		0.574334
  validation accuracy:		82.07 %
Epoch 1299 of 2000 took 0.117s
  training loss:		0.585316
  validation loss:		0.572638
  validation accuracy:		82.07 %
Epoch 1300 of 2000 took 0.172s
  training loss:		0.593642
  validation loss:		0.613448
  validation accuracy:		81.20 %
Epoch 1301 of 2000 took 0.152s
  training loss:		0.588797
  validation loss:		0.572894
  validation accuracy:		82.17 %
Epoch 1302 of 2000 took 0.139s
  training loss:		0.582365
  validation loss:		0.576503
  validation accuracy:		81.85 %
Epoch 1303 of 2000 took 0.165s
  training loss:		0.588136
  validation loss:		0.574327
  validation accuracy:		82.61 %
Epoch 1304 of 2000 took 0.131s
  training loss:		0.583934
  validation loss:		0.572803
  validation accuracy:		82.61 %
Epoch 1305 of 2000 took 0.167s
  training loss:		0.590693
  validation loss:		0.576617
  validation accuracy:		81.96 %
Epoch 1306 of 2000 took 0.163s
  training loss:		0.584110
  validation loss:		0.578030
  validation accuracy:		81.96 %
Epoch 1307 of 2000 took 0.129s
  training loss:		0.585002
  validation loss:		0.573168
  validation accuracy:		82.39 %
Epoch 1308 of 2000 took 0.172s
  training loss:		0.583939
  validation loss:		0.582788
  validation accuracy:		81.41 %
Epoch 1309 of 2000 took 0.137s
  training loss:		0.588332
  validation loss:		0.620949
  validation accuracy:		80.65 %
Epoch 1310 of 2000 took 0.154s
  training loss:		0.585481
  validation loss:		0.574283
  validation accuracy:		82.07 %
Epoch 1311 of 2000 took 0.165s
  training loss:		0.588254
  validation loss:		0.572949
  validation accuracy:		81.85 %
Epoch 1312 of 2000 took 0.130s
  training loss:		0.590539
  validation loss:		0.590151
  validation accuracy:		81.85 %
Epoch 1313 of 2000 took 0.168s
  training loss:		0.581732
  validation loss:		0.581188
  validation accuracy:		81.85 %
Epoch 1314 of 2000 took 0.164s
  training loss:		0.583983
  validation loss:		0.580469
  validation accuracy:		82.07 %
Epoch 1315 of 2000 took 0.128s
  training loss:		0.587312
  validation loss:		0.574292
  validation accuracy:		82.17 %
Epoch 1316 of 2000 took 0.169s
  training loss:		0.580879
  validation loss:		0.574191
  validation accuracy:		82.72 %
Epoch 1317 of 2000 took 0.164s
  training loss:		0.579987
  validation loss:		0.575658
  validation accuracy:		82.17 %
Epoch 1318 of 2000 took 0.126s
  training loss:		0.593159
  validation loss:		0.575634
  validation accuracy:		82.07 %
Epoch 1319 of 2000 took 0.165s
  training loss:		0.588040
  validation loss:		0.578141
  validation accuracy:		81.52 %
Epoch 1320 of 2000 took 0.156s
  training loss:		0.587782
  validation loss:		0.571891
  validation accuracy:		82.39 %
Epoch 1321 of 2000 took 0.142s
  training loss:		0.588900
  validation loss:		0.572100
  validation accuracy:		82.07 %
Epoch 1322 of 2000 took 0.165s
  training loss:		0.600847
  validation loss:		0.574362
  validation accuracy:		82.50 %
Epoch 1323 of 2000 took 0.131s
  training loss:		0.586154
  validation loss:		0.580361
  validation accuracy:		81.85 %
Epoch 1324 of 2000 took 0.168s
  training loss:		0.595850
  validation loss:		0.589109
  validation accuracy:		81.30 %
Epoch 1325 of 2000 took 0.161s
  training loss:		0.594615
  validation loss:		0.595106
  validation accuracy:		81.85 %
Epoch 1326 of 2000 took 0.130s
  training loss:		0.591283
  validation loss:		0.575780
  validation accuracy:		81.96 %
Epoch 1327 of 2000 took 0.165s
  training loss:		0.587191
  validation loss:		0.588444
  validation accuracy:		82.07 %
Epoch 1328 of 2000 took 0.143s
  training loss:		0.583043
  validation loss:		0.579850
  validation accuracy:		81.52 %
Epoch 1329 of 2000 took 0.155s
  training loss:		0.593664
  validation loss:		0.602935
  validation accuracy:		81.20 %
Epoch 1330 of 2000 took 0.165s
  training loss:		0.590161
  validation loss:		0.583636
  validation accuracy:		82.07 %
Epoch 1331 of 2000 took 0.131s
  training loss:		0.585686
  validation loss:		0.577781
  validation accuracy:		82.39 %
Epoch 1332 of 2000 took 0.167s
  training loss:		0.588251
  validation loss:		0.575377
  validation accuracy:		81.96 %
Epoch 1333 of 2000 took 0.149s
  training loss:		0.586260
  validation loss:		0.572723
  validation accuracy:		82.50 %
Epoch 1334 of 2000 took 0.142s
  training loss:		0.592683
  validation loss:		0.603318
  validation accuracy:		80.98 %
Epoch 1335 of 2000 took 0.166s
  training loss:		0.596812
  validation loss:		0.570930
  validation accuracy:		82.28 %
Epoch 1336 of 2000 took 0.131s
  training loss:		0.592479
  validation loss:		0.587886
  validation accuracy:		81.20 %
Epoch 1337 of 2000 took 0.166s
  training loss:		0.581102
  validation loss:		0.575817
  validation accuracy:		81.85 %
Epoch 1338 of 2000 took 0.160s
  training loss:		0.590777
  validation loss:		0.575522
  validation accuracy:		81.96 %
Epoch 1339 of 2000 took 0.137s
  training loss:		0.588084
  validation loss:		0.582998
  validation accuracy:		81.74 %
Epoch 1340 of 2000 took 0.166s
  training loss:		0.582877
  validation loss:		0.577541
  validation accuracy:		81.96 %
Epoch 1341 of 2000 took 0.136s
  training loss:		0.590261
  validation loss:		0.587116
  validation accuracy:		81.74 %
Epoch 1342 of 2000 took 0.155s
  training loss:		0.592709
  validation loss:		0.584175
  validation accuracy:		81.52 %
Epoch 1343 of 2000 took 0.166s
  training loss:		0.589993
  validation loss:		0.580261
  validation accuracy:		82.17 %
Epoch 1344 of 2000 took 0.131s
  training loss:		0.595269
  validation loss:		0.585237
  validation accuracy:		81.30 %
Epoch 1345 of 2000 took 0.166s
  training loss:		0.591731
  validation loss:		0.582431
  validation accuracy:		81.52 %
Epoch 1346 of 2000 took 0.147s
  training loss:		0.589091
  validation loss:		0.590402
  validation accuracy:		81.85 %
Epoch 1347 of 2000 took 0.150s
  training loss:		0.579061
  validation loss:		0.569720
  validation accuracy:		82.28 %
Epoch 1348 of 2000 took 0.165s
  training loss:		0.601654
  validation loss:		0.575848
  validation accuracy:		81.74 %
Epoch 1349 of 2000 took 0.126s
  training loss:		0.585468
  validation loss:		0.578648
  validation accuracy:		81.96 %
Epoch 1350 of 2000 took 0.165s
  training loss:		0.590865
  validation loss:		0.581555
  validation accuracy:		81.85 %
Epoch 1351 of 2000 took 0.159s
  training loss:		0.593952
  validation loss:		0.570778
  validation accuracy:		82.61 %
Epoch 1352 of 2000 took 0.139s
  training loss:		0.586582
  validation loss:		0.578929
  validation accuracy:		82.28 %
Epoch 1353 of 2000 took 0.165s
  training loss:		0.584191
  validation loss:		0.578062
  validation accuracy:		81.96 %
Epoch 1354 of 2000 took 0.134s
  training loss:		0.588200
  validation loss:		0.585260
  validation accuracy:		81.85 %
Epoch 1355 of 2000 took 0.163s
  training loss:		0.586676
  validation loss:		0.576907
  validation accuracy:		81.96 %
Epoch 1356 of 2000 took 0.165s
  training loss:		0.583287
  validation loss:		0.571759
  validation accuracy:		82.39 %
Epoch 1357 of 2000 took 0.126s
  training loss:		0.592014
  validation loss:		0.609546
  validation accuracy:		80.98 %
Epoch 1358 of 2000 took 0.165s
  training loss:		0.584835
  validation loss:		0.574980
  validation accuracy:		82.39 %
Epoch 1359 of 2000 took 0.147s
  training loss:		0.578198
  validation loss:		0.582414
  validation accuracy:		81.63 %
Epoch 1360 of 2000 took 0.151s
  training loss:		0.583197
  validation loss:		0.572177
  validation accuracy:		82.07 %
Epoch 1361 of 2000 took 0.165s
  training loss:		0.579748
  validation loss:		0.580284
  validation accuracy:		81.52 %
Epoch 1362 of 2000 took 0.126s
  training loss:		0.575928
  validation loss:		0.576079
  validation accuracy:		81.96 %
Epoch 1363 of 2000 took 0.170s
  training loss:		0.584174
  validation loss:		0.577795
  validation accuracy:		81.63 %
Epoch 1364 of 2000 took 0.155s
  training loss:		0.587111
  validation loss:		0.575342
  validation accuracy:		81.85 %
Epoch 1365 of 2000 took 0.136s
  training loss:		0.581064
  validation loss:		0.583774
  validation accuracy:		81.63 %
Epoch 1366 of 2000 took 0.165s
  training loss:		0.590092
  validation loss:		0.586196
  validation accuracy:		81.63 %
Epoch 1367 of 2000 took 0.143s
  training loss:		0.591645
  validation loss:		0.571615
  validation accuracy:		82.17 %
Epoch 1368 of 2000 took 0.154s
  training loss:		0.584451
  validation loss:		0.583603
  validation accuracy:		81.96 %
Epoch 1369 of 2000 took 0.165s
  training loss:		0.590894
  validation loss:		0.585915
  validation accuracy:		81.85 %
Epoch 1370 of 2000 took 0.129s
  training loss:		0.593229
  validation loss:		0.589593
  validation accuracy:		81.52 %
Epoch 1371 of 2000 took 0.169s
  training loss:		0.591098
  validation loss:		0.570723
  validation accuracy:		82.07 %
Epoch 1372 of 2000 took 0.150s
  training loss:		0.585684
  validation loss:		0.590232
  validation accuracy:		81.30 %
Epoch 1373 of 2000 took 0.141s
  training loss:		0.591340
  validation loss:		0.574272
  validation accuracy:		82.17 %
Epoch 1374 of 2000 took 0.165s
  training loss:		0.582804
  validation loss:		0.579355
  validation accuracy:		82.39 %
Epoch 1375 of 2000 took 0.132s
  training loss:		0.590308
  validation loss:		0.571045
  validation accuracy:		82.17 %
Epoch 1376 of 2000 took 0.166s
  training loss:		0.575093
  validation loss:		0.586226
  validation accuracy:		81.41 %
Epoch 1377 of 2000 took 0.161s
  training loss:		0.589847
  validation loss:		0.586978
  validation accuracy:		82.07 %
Epoch 1378 of 2000 took 0.134s
  training loss:		0.579890
  validation loss:		0.571992
  validation accuracy:		82.07 %
Epoch 1379 of 2000 took 0.167s
  training loss:		0.577769
  validation loss:		0.600067
  validation accuracy:		81.52 %
Epoch 1380 of 2000 took 0.137s
  training loss:		0.596443
  validation loss:		0.582829
  validation accuracy:		81.96 %
Epoch 1381 of 2000 took 0.154s
  training loss:		0.588055
  validation loss:		0.587369
  validation accuracy:		81.30 %
Epoch 1382 of 2000 took 0.165s
  training loss:		0.586901
  validation loss:		0.573547
  validation accuracy:		81.74 %
Epoch 1383 of 2000 took 0.132s
  training loss:		0.586690
  validation loss:		0.571146
  validation accuracy:		82.17 %
Epoch 1384 of 2000 took 0.166s
  training loss:		0.583977
  validation loss:		0.584282
  validation accuracy:		81.85 %
Epoch 1385 of 2000 took 0.148s
  training loss:		0.586203
  validation loss:		0.569469
  validation accuracy:		82.07 %
Epoch 1386 of 2000 took 0.149s
  training loss:		0.585887
  validation loss:		0.578474
  validation accuracy:		81.52 %
Epoch 1387 of 2000 took 0.166s
  training loss:		0.591220
  validation loss:		0.580182
  validation accuracy:		81.63 %
Epoch 1388 of 2000 took 0.127s
  training loss:		0.587623
  validation loss:		0.580068
  validation accuracy:		81.74 %
Epoch 1389 of 2000 took 0.163s
  training loss:		0.583966
  validation loss:		0.580626
  validation accuracy:		81.74 %
Epoch 1390 of 2000 took 0.164s
  training loss:		0.584469
  validation loss:		0.585855
  validation accuracy:		81.96 %
Epoch 1391 of 2000 took 0.133s
  training loss:		0.580789
  validation loss:		0.571875
  validation accuracy:		82.17 %
Epoch 1392 of 2000 took 0.166s
  training loss:		0.576564
  validation loss:		0.575237
  validation accuracy:		81.85 %
Epoch 1393 of 2000 took 0.141s
  training loss:		0.575812
  validation loss:		0.597831
  validation accuracy:		81.20 %
Epoch 1394 of 2000 took 0.152s
  training loss:		0.574041
  validation loss:		0.571417
  validation accuracy:		82.39 %
Epoch 1395 of 2000 took 0.164s
  training loss:		0.583406
  validation loss:		0.568279
  validation accuracy:		81.96 %
Epoch 1396 of 2000 took 0.123s
  training loss:		0.586851
  validation loss:		0.581661
  validation accuracy:		82.50 %
Epoch 1397 of 2000 took 0.164s
  training loss:		0.595557
  validation loss:		0.585791
  validation accuracy:		81.52 %
Epoch 1398 of 2000 took 0.154s
  training loss:		0.589992
  validation loss:		0.583730
  validation accuracy:		81.63 %
Epoch 1399 of 2000 took 0.132s
  training loss:		0.588511
  validation loss:		0.573525
  validation accuracy:		82.39 %
Epoch 1400 of 2000 took 0.164s
  training loss:		0.585501
  validation loss:		0.577337
  validation accuracy:		81.74 %
Epoch 1401 of 2000 took 0.135s
  training loss:		0.589895
  validation loss:		0.590038
  validation accuracy:		81.63 %
Epoch 1402 of 2000 took 0.151s
  training loss:		0.587707
  validation loss:		0.570243
  validation accuracy:		82.17 %
Epoch 1403 of 2000 took 0.164s
  training loss:		0.581933
  validation loss:		0.581659
  validation accuracy:		82.39 %
Epoch 1404 of 2000 took 0.123s
  training loss:		0.586008
  validation loss:		0.575997
  validation accuracy:		82.07 %
Epoch 1405 of 2000 took 0.164s
  training loss:		0.582633
  validation loss:		0.595919
  validation accuracy:		80.87 %
Epoch 1406 of 2000 took 0.155s
  training loss:		0.584608
  validation loss:		0.580319
  validation accuracy:		81.85 %
Epoch 1407 of 2000 took 0.132s
  training loss:		0.577195
  validation loss:		0.584445
  validation accuracy:		82.07 %
Epoch 1408 of 2000 took 0.164s
  training loss:		0.587317
  validation loss:		0.583999
  validation accuracy:		81.63 %
Epoch 1409 of 2000 took 0.135s
  training loss:		0.592722
  validation loss:		0.570526
  validation accuracy:		81.96 %
Epoch 1410 of 2000 took 0.150s
  training loss:		0.593272
  validation loss:		0.600605
  validation accuracy:		81.30 %
Epoch 1411 of 2000 took 0.164s
  training loss:		0.586937
  validation loss:		0.583311
  validation accuracy:		81.85 %
Epoch 1412 of 2000 took 0.124s
  training loss:		0.595198
  validation loss:		0.576252
  validation accuracy:		82.28 %
Epoch 1413 of 2000 took 0.164s
  training loss:		0.586574
  validation loss:		0.593681
  validation accuracy:		81.30 %
Epoch 1414 of 2000 took 0.155s
  training loss:		0.594196
  validation loss:		0.574613
  validation accuracy:		82.28 %
Epoch 1415 of 2000 took 0.132s
  training loss:		0.591557
  validation loss:		0.601030
  validation accuracy:		80.54 %
Epoch 1416 of 2000 took 0.164s
  training loss:		0.592466
  validation loss:		0.577310
  validation accuracy:		81.74 %
Epoch 1417 of 2000 took 0.135s
  training loss:		0.587668
  validation loss:		0.583614
  validation accuracy:		82.28 %
Epoch 1418 of 2000 took 0.151s
  training loss:		0.580781
  validation loss:		0.579097
  validation accuracy:		81.63 %
Epoch 1419 of 2000 took 0.164s
  training loss:		0.585306
  validation loss:		0.574096
  validation accuracy:		82.50 %
Epoch 1420 of 2000 took 0.123s
  training loss:		0.588947
  validation loss:		0.585049
  validation accuracy:		81.96 %
Epoch 1421 of 2000 took 0.164s
  training loss:		0.593180
  validation loss:		0.596052
  validation accuracy:		81.41 %
Epoch 1422 of 2000 took 0.154s
  training loss:		0.589175
  validation loss:		0.576838
  validation accuracy:		81.96 %
Epoch 1423 of 2000 took 0.133s
  training loss:		0.581874
  validation loss:		0.575053
  validation accuracy:		82.07 %
Epoch 1424 of 2000 took 0.164s
  training loss:		0.582420
  validation loss:		0.577623
  validation accuracy:		81.85 %
Epoch 1425 of 2000 took 0.138s
  training loss:		0.594132
  validation loss:		0.592185
  validation accuracy:		81.41 %
Epoch 1426 of 2000 took 0.148s
  training loss:		0.593754
  validation loss:		0.592731
  validation accuracy:		81.20 %
Epoch 1427 of 2000 took 0.165s
  training loss:		0.582110
  validation loss:		0.574032
  validation accuracy:		82.07 %
Epoch 1428 of 2000 took 0.124s
  training loss:		0.589161
  validation loss:		0.573107
  validation accuracy:		81.96 %
Epoch 1429 of 2000 took 0.164s
  training loss:		0.587891
  validation loss:		0.569167
  validation accuracy:		82.07 %
Epoch 1430 of 2000 took 0.164s
  training loss:		0.592801
  validation loss:		0.575633
  validation accuracy:		81.96 %
Epoch 1431 of 2000 took 0.123s
  training loss:		0.579339
  validation loss:		0.577679
  validation accuracy:		82.28 %
Epoch 1432 of 2000 took 0.164s
  training loss:		0.593852
  validation loss:		0.582226
  validation accuracy:		81.30 %
Epoch 1433 of 2000 took 0.145s
  training loss:		0.584797
  validation loss:		0.569974
  validation accuracy:		81.96 %
Epoch 1434 of 2000 took 0.142s
  training loss:		0.574469
  validation loss:		0.575479
  validation accuracy:		81.96 %
Epoch 1435 of 2000 took 0.164s
  training loss:		0.592315
  validation loss:		0.572691
  validation accuracy:		81.96 %
Epoch 1436 of 2000 took 0.125s
  training loss:		0.588215
  validation loss:		0.587610
  validation accuracy:		80.65 %
Epoch 1437 of 2000 took 0.162s
  training loss:		0.578954
  validation loss:		0.576483
  validation accuracy:		81.74 %
Epoch 1438 of 2000 took 0.164s
  training loss:		0.585563
  validation loss:		0.572016
  validation accuracy:		82.07 %
Epoch 1439 of 2000 took 0.124s
  training loss:		0.592384
  validation loss:		0.581701
  validation accuracy:		81.41 %
Epoch 1440 of 2000 took 0.164s
  training loss:		0.584599
  validation loss:		0.579899
  validation accuracy:		82.17 %
Epoch 1441 of 2000 took 0.144s
  training loss:		0.581926
  validation loss:		0.579838
  validation accuracy:		81.63 %
Epoch 1442 of 2000 took 0.142s
  training loss:		0.586342
  validation loss:		0.587956
  validation accuracy:		81.41 %
Epoch 1443 of 2000 took 0.164s
  training loss:		0.587666
  validation loss:		0.574110
  validation accuracy:		82.17 %
Epoch 1444 of 2000 took 0.125s
  training loss:		0.591401
  validation loss:		0.572616
  validation accuracy:		81.96 %
Epoch 1445 of 2000 took 0.162s
  training loss:		0.584903
  validation loss:		0.573230
  validation accuracy:		82.17 %
Epoch 1446 of 2000 took 0.164s
  training loss:		0.584996
  validation loss:		0.595429
  validation accuracy:		81.52 %
Epoch 1447 of 2000 took 0.124s
  training loss:		0.583648
  validation loss:		0.570746
  validation accuracy:		82.17 %
Epoch 1448 of 2000 took 0.164s
  training loss:		0.571442
  validation loss:		0.584472
  validation accuracy:		81.41 %
Epoch 1449 of 2000 took 0.144s
  training loss:		0.595720
  validation loss:		0.582088
  validation accuracy:		81.63 %
Epoch 1450 of 2000 took 0.143s
  training loss:		0.595149
  validation loss:		0.577348
  validation accuracy:		82.28 %
Epoch 1451 of 2000 took 0.164s
  training loss:		0.585516
  validation loss:		0.586613
  validation accuracy:		82.07 %
Epoch 1452 of 2000 took 0.124s
  training loss:		0.579702
  validation loss:		0.585733
  validation accuracy:		81.20 %
Epoch 1453 of 2000 took 0.163s
  training loss:		0.579369
  validation loss:		0.580807
  validation accuracy:		81.63 %
Epoch 1454 of 2000 took 0.163s
  training loss:		0.590044
  validation loss:		0.580108
  validation accuracy:		81.96 %
Epoch 1455 of 2000 took 0.124s
  training loss:		0.580862
  validation loss:		0.573428
  validation accuracy:		82.39 %
Epoch 1456 of 2000 took 0.164s
  training loss:		0.581712
  validation loss:		0.576132
  validation accuracy:		81.63 %
Epoch 1457 of 2000 took 0.143s
  training loss:		0.584306
  validation loss:		0.569590
  validation accuracy:		82.39 %
Epoch 1458 of 2000 took 0.143s
  training loss:		0.584159
  validation loss:		0.577745
  validation accuracy:		81.74 %
Epoch 1459 of 2000 took 0.164s
  training loss:		0.593138
  validation loss:		0.569745
  validation accuracy:		81.85 %
Epoch 1460 of 2000 took 0.123s
  training loss:		0.585574
  validation loss:		0.585610
  validation accuracy:		81.74 %
Epoch 1461 of 2000 took 0.163s
  training loss:		0.592882
  validation loss:		0.594862
  validation accuracy:		81.41 %
Epoch 1462 of 2000 took 0.162s
  training loss:		0.592404
  validation loss:		0.569709
  validation accuracy:		82.07 %
Epoch 1463 of 2000 took 0.123s
  training loss:		0.583823
  validation loss:		0.584252
  validation accuracy:		81.74 %
Epoch 1464 of 2000 took 0.164s
  training loss:		0.585907
  validation loss:		0.573291
  validation accuracy:		81.63 %
Epoch 1465 of 2000 took 0.144s
  training loss:		0.591693
  validation loss:		0.581282
  validation accuracy:		81.20 %
Epoch 1466 of 2000 took 0.143s
  training loss:		0.588998
  validation loss:		0.576173
  validation accuracy:		81.63 %
Epoch 1467 of 2000 took 0.165s
  training loss:		0.588857
  validation loss:		0.581970
  validation accuracy:		81.74 %
Epoch 1468 of 2000 took 0.130s
  training loss:		0.584491
  validation loss:		0.571042
  validation accuracy:		82.28 %
Epoch 1469 of 2000 took 0.159s
  training loss:		0.585732
  validation loss:		0.587679
  validation accuracy:		82.28 %
Epoch 1470 of 2000 took 0.164s
  training loss:		0.588815
  validation loss:		0.574511
  validation accuracy:		81.85 %
Epoch 1471 of 2000 took 0.122s
  training loss:		0.586156
  validation loss:		0.571732
  validation accuracy:		81.63 %
Epoch 1472 of 2000 took 0.164s
  training loss:		0.586179
  validation loss:		0.576513
  validation accuracy:		82.07 %
Epoch 1473 of 2000 took 0.147s
  training loss:		0.589352
  validation loss:		0.575388
  validation accuracy:		82.28 %
Epoch 1474 of 2000 took 0.139s
  training loss:		0.586714
  validation loss:		0.574279
  validation accuracy:		82.17 %
Epoch 1475 of 2000 took 0.164s
  training loss:		0.590643
  validation loss:		0.584892
  validation accuracy:		81.41 %
Epoch 1476 of 2000 took 0.127s
  training loss:		0.587660
  validation loss:		0.575935
  validation accuracy:		81.52 %
Epoch 1477 of 2000 took 0.160s
  training loss:		0.595561
  validation loss:		0.574347
  validation accuracy:		81.85 %
Epoch 1478 of 2000 took 0.164s
  training loss:		0.580900
  validation loss:		0.576159
  validation accuracy:		81.85 %
Epoch 1479 of 2000 took 0.123s
  training loss:		0.580660
  validation loss:		0.569866
  validation accuracy:		82.28 %
Epoch 1480 of 2000 took 0.164s
  training loss:		0.573425
  validation loss:		0.582361
  validation accuracy:		81.41 %
Epoch 1481 of 2000 took 0.146s
  training loss:		0.587899
  validation loss:		0.581909
  validation accuracy:		81.41 %
Epoch 1482 of 2000 took 0.140s
  training loss:		0.586945
  validation loss:		0.588536
  validation accuracy:		81.63 %
Epoch 1483 of 2000 took 0.164s
  training loss:		0.585505
  validation loss:		0.575381
  validation accuracy:		82.07 %
Epoch 1484 of 2000 took 0.126s
  training loss:		0.595895
  validation loss:		0.571759
  validation accuracy:		82.28 %
Epoch 1485 of 2000 took 0.160s
  training loss:		0.578487
  validation loss:		0.566155
  validation accuracy:		81.85 %
Epoch 1486 of 2000 took 0.164s
  training loss:		0.590081
  validation loss:		0.592220
  validation accuracy:		81.41 %
Epoch 1487 of 2000 took 0.123s
  training loss:		0.596527
  validation loss:		0.571400
  validation accuracy:		81.85 %
Epoch 1488 of 2000 took 0.164s
  training loss:		0.588017
  validation loss:		0.583604
  validation accuracy:		81.85 %
Epoch 1489 of 2000 took 0.146s
  training loss:		0.581381
  validation loss:		0.599157
  validation accuracy:		79.89 %
Epoch 1490 of 2000 took 0.140s
  training loss:		0.572244
  validation loss:		0.569297
  validation accuracy:		82.07 %
Epoch 1491 of 2000 took 0.164s
  training loss:		0.587860
  validation loss:		0.572452
  validation accuracy:		81.63 %
Epoch 1492 of 2000 took 0.127s
  training loss:		0.583724
  validation loss:		0.582457
  validation accuracy:		81.41 %
Epoch 1493 of 2000 took 0.160s
  training loss:		0.588246
  validation loss:		0.598887
  validation accuracy:		80.76 %
Epoch 1494 of 2000 took 0.164s
  training loss:		0.597234
  validation loss:		0.573175
  validation accuracy:		81.96 %
Epoch 1495 of 2000 took 0.123s
  training loss:		0.585106
  validation loss:		0.592578
  validation accuracy:		81.20 %
Epoch 1496 of 2000 took 0.164s
  training loss:		0.592631
  validation loss:		0.573513
  validation accuracy:		81.74 %
Epoch 1497 of 2000 took 0.146s
  training loss:		0.579167
  validation loss:		0.574649
  validation accuracy:		81.96 %
Epoch 1498 of 2000 took 0.140s
  training loss:		0.589684
  validation loss:		0.579796
  validation accuracy:		81.52 %
Epoch 1499 of 2000 took 0.164s
  training loss:		0.588705
  validation loss:		0.574786
  validation accuracy:		82.07 %
Epoch 1500 of 2000 took 0.127s
  training loss:		0.590545
  validation loss:		0.565683
  validation accuracy:		82.28 %
Epoch 1501 of 2000 took 0.159s
  training loss:		0.579415
  validation loss:		0.575899
  validation accuracy:		81.41 %
Epoch 1502 of 2000 took 0.164s
  training loss:		0.581562
  validation loss:		0.589339
  validation accuracy:		81.30 %
Epoch 1503 of 2000 took 0.123s
  training loss:		0.581478
  validation loss:		0.584241
  validation accuracy:		81.41 %
Epoch 1504 of 2000 took 0.164s
  training loss:		0.580688
  validation loss:		0.570160
  validation accuracy:		82.17 %
Epoch 1505 of 2000 took 0.146s
  training loss:		0.586214
  validation loss:		0.576986
  validation accuracy:		81.52 %
Epoch 1506 of 2000 took 0.139s
  training loss:		0.590138
  validation loss:		0.582014
  validation accuracy:		81.20 %
Epoch 1507 of 2000 took 0.164s
  training loss:		0.581026
  validation loss:		0.575966
  validation accuracy:		81.74 %
Epoch 1508 of 2000 took 0.127s
  training loss:		0.593171
  validation loss:		0.587170
  validation accuracy:		80.98 %
Epoch 1509 of 2000 took 0.159s
  training loss:		0.574661
  validation loss:		0.566355
  validation accuracy:		81.85 %
Epoch 1510 of 2000 took 0.164s
  training loss:		0.579319
  validation loss:		0.588145
  validation accuracy:		81.20 %
Epoch 1511 of 2000 took 0.123s
  training loss:		0.581850
  validation loss:		0.572066
  validation accuracy:		81.63 %
Epoch 1512 of 2000 took 0.164s
  training loss:		0.588080
  validation loss:		0.578936
  validation accuracy:		81.96 %
Epoch 1513 of 2000 took 0.146s
  training loss:		0.577484
  validation loss:		0.568117
  validation accuracy:		82.28 %
Epoch 1514 of 2000 took 0.139s
  training loss:		0.584398
  validation loss:		0.571177
  validation accuracy:		82.28 %
Epoch 1515 of 2000 took 0.164s
  training loss:		0.589704
  validation loss:		0.593898
  validation accuracy:		81.63 %
Epoch 1516 of 2000 took 0.127s
  training loss:		0.593199
  validation loss:		0.569170
  validation accuracy:		81.96 %
Epoch 1517 of 2000 took 0.159s
  training loss:		0.586040
  validation loss:		0.578038
  validation accuracy:		81.74 %
Epoch 1518 of 2000 took 0.164s
  training loss:		0.590355
  validation loss:		0.574959
  validation accuracy:		82.17 %
Epoch 1519 of 2000 took 0.123s
  training loss:		0.590703
  validation loss:		0.572973
  validation accuracy:		82.17 %
Epoch 1520 of 2000 took 0.164s
  training loss:		0.588933
  validation loss:		0.564916
  validation accuracy:		81.96 %
Epoch 1521 of 2000 took 0.146s
  training loss:		0.590583
  validation loss:		0.566224
  validation accuracy:		81.85 %
Epoch 1522 of 2000 took 0.139s
  training loss:		0.589114
  validation loss:		0.588661
  validation accuracy:		81.30 %
Epoch 1523 of 2000 took 0.164s
  training loss:		0.585769
  validation loss:		0.574403
  validation accuracy:		81.96 %
Epoch 1524 of 2000 took 0.127s
  training loss:		0.585986
  validation loss:		0.573484
  validation accuracy:		82.17 %
Epoch 1525 of 2000 took 0.158s
  training loss:		0.582990
  validation loss:		0.582599
  validation accuracy:		81.85 %
Epoch 1526 of 2000 took 0.164s
  training loss:		0.594924
  validation loss:		0.576474
  validation accuracy:		82.07 %
Epoch 1527 of 2000 took 0.123s
  training loss:		0.593051
  validation loss:		0.579417
  validation accuracy:		82.07 %
Epoch 1528 of 2000 took 0.164s
  training loss:		0.594430
  validation loss:		0.574907
  validation accuracy:		81.63 %
Epoch 1529 of 2000 took 0.147s
  training loss:		0.589313
  validation loss:		0.573975
  validation accuracy:		81.63 %
Epoch 1530 of 2000 took 0.140s
  training loss:		0.576302
  validation loss:		0.577736
  validation accuracy:		81.30 %
Epoch 1531 of 2000 took 0.164s
  training loss:		0.594487
  validation loss:		0.569391
  validation accuracy:		81.85 %
Epoch 1532 of 2000 took 0.127s
  training loss:		0.585128
  validation loss:		0.572809
  validation accuracy:		81.74 %
Epoch 1533 of 2000 took 0.159s
  training loss:		0.581133
  validation loss:		0.579354
  validation accuracy:		81.85 %
Epoch 1534 of 2000 took 0.164s
  training loss:		0.581573
  validation loss:		0.571621
  validation accuracy:		81.85 %
Epoch 1535 of 2000 took 0.124s
  training loss:		0.583294
  validation loss:		0.570645
  validation accuracy:		82.28 %
Epoch 1536 of 2000 took 0.164s
  training loss:		0.584893
  validation loss:		0.575249
  validation accuracy:		81.85 %
Epoch 1537 of 2000 took 0.161s
  training loss:		0.575678
  validation loss:		0.570519
  validation accuracy:		81.74 %
Epoch 1538 of 2000 took 0.163s
  training loss:		0.596552
  validation loss:		0.573397
  validation accuracy:		82.07 %
Epoch 1539 of 2000 took 0.164s
  training loss:		0.585554
  validation loss:		0.587361
  validation accuracy:		81.74 %
Epoch 1540 of 2000 took 0.161s
  training loss:		0.593772
  validation loss:		0.579929
  validation accuracy:		81.41 %
Epoch 1541 of 2000 took 0.164s
  training loss:		0.589300
  validation loss:		0.586756
  validation accuracy:		82.07 %
Epoch 1542 of 2000 took 0.161s
  training loss:		0.583634
  validation loss:		0.588046
  validation accuracy:		81.20 %
Epoch 1543 of 2000 took 0.163s
  training loss:		0.584014
  validation loss:		0.569324
  validation accuracy:		82.17 %
Epoch 1544 of 2000 took 0.163s
  training loss:		0.580593
  validation loss:		0.584111
  validation accuracy:		81.96 %
Epoch 1545 of 2000 took 0.161s
  training loss:		0.591220
  validation loss:		0.579464
  validation accuracy:		81.96 %
Epoch 1546 of 2000 took 0.164s
  training loss:		0.583334
  validation loss:		0.587888
  validation accuracy:		80.65 %
Epoch 1547 of 2000 took 0.161s
  training loss:		0.587658
  validation loss:		0.572798
  validation accuracy:		81.74 %
Epoch 1548 of 2000 took 0.164s
  training loss:		0.584995
  validation loss:		0.570928
  validation accuracy:		82.07 %
Epoch 1549 of 2000 took 0.162s
  training loss:		0.583162
  validation loss:		0.576212
  validation accuracy:		81.52 %
Epoch 1550 of 2000 took 0.163s
  training loss:		0.587949
  validation loss:		0.581106
  validation accuracy:		81.96 %
Epoch 1551 of 2000 took 0.164s
  training loss:		0.583836
  validation loss:		0.574688
  validation accuracy:		82.17 %
Epoch 1552 of 2000 took 0.161s
  training loss:		0.591179
  validation loss:		0.584557
  validation accuracy:		81.52 %
Epoch 1553 of 2000 took 0.164s
  training loss:		0.587335
  validation loss:		0.579103
  validation accuracy:		81.20 %
Epoch 1554 of 2000 took 0.161s
  training loss:		0.592707
  validation loss:		0.572021
  validation accuracy:		81.96 %
Epoch 1555 of 2000 took 0.165s
  training loss:		0.588426
  validation loss:		0.584278
  validation accuracy:		81.41 %
Epoch 1556 of 2000 took 0.170s
  training loss:		0.590610
  validation loss:		0.573820
  validation accuracy:		81.85 %
Epoch 1557 of 2000 took 0.161s
  training loss:		0.578925
  validation loss:		0.577060
  validation accuracy:		81.96 %
Epoch 1558 of 2000 took 0.164s
  training loss:		0.578337
  validation loss:		0.587423
  validation accuracy:		80.65 %
Epoch 1559 of 2000 took 0.161s
  training loss:		0.588501
  validation loss:		0.575948
  validation accuracy:		81.74 %
Epoch 1560 of 2000 took 0.164s
  training loss:		0.585426
  validation loss:		0.570415
  validation accuracy:		82.28 %
Epoch 1561 of 2000 took 0.166s
  training loss:		0.587772
  validation loss:		0.579446
  validation accuracy:		81.30 %
Epoch 1562 of 2000 took 0.161s
  training loss:		0.586934
  validation loss:		0.569467
  validation accuracy:		81.85 %
Epoch 1563 of 2000 took 0.164s
  training loss:		0.589198
  validation loss:		0.565744
  validation accuracy:		81.85 %
Epoch 1564 of 2000 took 0.161s
  training loss:		0.580706
  validation loss:		0.582839
  validation accuracy:		81.30 %
Epoch 1565 of 2000 took 0.165s
  training loss:		0.581064
  validation loss:		0.570751
  validation accuracy:		81.74 %
Epoch 1566 of 2000 took 0.165s
  training loss:		0.574417
  validation loss:		0.571230
  validation accuracy:		81.85 %
Epoch 1567 of 2000 took 0.161s
  training loss:		0.584705
  validation loss:		0.574503
  validation accuracy:		81.85 %
Epoch 1568 of 2000 took 0.164s
  training loss:		0.591289
  validation loss:		0.575386
  validation accuracy:		81.63 %
Epoch 1569 of 2000 took 0.161s
  training loss:		0.582072
  validation loss:		0.576364
  validation accuracy:		81.52 %
Epoch 1570 of 2000 took 0.166s
  training loss:		0.583894
  validation loss:		0.594429
  validation accuracy:		81.96 %
Epoch 1571 of 2000 took 0.162s
  training loss:		0.585879
  validation loss:		0.586508
  validation accuracy:		81.63 %
Epoch 1572 of 2000 took 0.163s
  training loss:		0.583901
  validation loss:		0.575473
  validation accuracy:		81.96 %
Epoch 1573 of 2000 took 0.164s
  training loss:		0.582819
  validation loss:		0.580121
  validation accuracy:		81.09 %
Epoch 1574 of 2000 took 0.161s
  training loss:		0.586164
  validation loss:		0.569468
  validation accuracy:		81.85 %
Epoch 1575 of 2000 took 0.167s
  training loss:		0.578226
  validation loss:		0.576524
  validation accuracy:		82.07 %
Epoch 1576 of 2000 took 0.161s
  training loss:		0.584053
  validation loss:		0.589707
  validation accuracy:		80.33 %
Epoch 1577 of 2000 took 0.164s
  training loss:		0.590483
  validation loss:		0.566924
  validation accuracy:		81.74 %
Epoch 1578 of 2000 took 0.164s
  training loss:		0.583912
  validation loss:		0.569884
  validation accuracy:		81.85 %
Epoch 1579 of 2000 took 0.162s
  training loss:		0.585612
  validation loss:		0.572862
  validation accuracy:		82.07 %
Epoch 1580 of 2000 took 0.167s
  training loss:		0.583783
  validation loss:		0.566680
  validation accuracy:		81.96 %
Epoch 1581 of 2000 took 0.161s
  training loss:		0.579292
  validation loss:		0.575979
  validation accuracy:		81.96 %
Epoch 1582 of 2000 took 0.164s
  training loss:		0.582848
  validation loss:		0.570737
  validation accuracy:		81.85 %
Epoch 1583 of 2000 took 0.162s
  training loss:		0.583631
  validation loss:		0.590858
  validation accuracy:		81.96 %
Epoch 1584 of 2000 took 0.163s
  training loss:		0.589671
  validation loss:		0.583803
  validation accuracy:		82.17 %
Epoch 1585 of 2000 took 0.167s
  training loss:		0.594781
  validation loss:		0.584710
  validation accuracy:		81.41 %
Epoch 1586 of 2000 took 0.161s
  training loss:		0.588256
  validation loss:		0.569705
  validation accuracy:		81.96 %
Epoch 1587 of 2000 took 0.164s
  training loss:		0.579711
  validation loss:		0.579735
  validation accuracy:		80.98 %
Epoch 1588 of 2000 took 0.161s
  training loss:		0.591549
  validation loss:		0.569591
  validation accuracy:		81.96 %
Epoch 1589 of 2000 took 0.164s
  training loss:		0.584991
  validation loss:		0.600567
  validation accuracy:		80.22 %
Epoch 1590 of 2000 took 0.165s
  training loss:		0.588464
  validation loss:		0.578683
  validation accuracy:		81.96 %
Epoch 1591 of 2000 took 0.161s
  training loss:		0.583705
  validation loss:		0.567381
  validation accuracy:		81.96 %
Epoch 1592 of 2000 took 0.165s
  training loss:		0.589205
  validation loss:		0.569987
  validation accuracy:		81.96 %
Epoch 1593 of 2000 took 0.161s
  training loss:		0.581453
  validation loss:		0.594933
  validation accuracy:		80.00 %
Epoch 1594 of 2000 took 0.165s
  training loss:		0.580389
  validation loss:		0.603202
  validation accuracy:		79.57 %
Epoch 1595 of 2000 took 0.162s
  training loss:		0.589336
  validation loss:		0.571201
  validation accuracy:		81.85 %
Epoch 1596 of 2000 took 0.163s
  training loss:		0.587534
  validation loss:		0.593275
  validation accuracy:		80.87 %
Epoch 1597 of 2000 took 0.164s
  training loss:		0.586305
  validation loss:		0.567365
  validation accuracy:		81.52 %
Epoch 1598 of 2000 took 0.161s
  training loss:		0.583291
  validation loss:		0.571351
  validation accuracy:		81.63 %
Epoch 1599 of 2000 took 0.166s
  training loss:		0.588739
  validation loss:		0.583327
  validation accuracy:		82.07 %
Epoch 1600 of 2000 took 0.161s
  training loss:		0.590467
  validation loss:		0.569366
  validation accuracy:		82.17 %
Epoch 1601 of 2000 took 0.163s
  training loss:		0.587977
  validation loss:		0.572605
  validation accuracy:		81.96 %
Epoch 1602 of 2000 took 0.164s
  training loss:		0.577830
  validation loss:		0.572535
  validation accuracy:		81.74 %
Epoch 1603 of 2000 took 0.162s
  training loss:		0.586136
  validation loss:		0.567602
  validation accuracy:		81.74 %
Epoch 1604 of 2000 took 0.167s
  training loss:		0.585138
  validation loss:		0.569748
  validation accuracy:		81.52 %
Epoch 1605 of 2000 took 0.161s
  training loss:		0.579918
  validation loss:		0.571497
  validation accuracy:		82.17 %
Epoch 1606 of 2000 took 0.164s
  training loss:		0.583532
  validation loss:		0.589870
  validation accuracy:		81.20 %
Epoch 1607 of 2000 took 0.162s
  training loss:		0.582726
  validation loss:		0.580524
  validation accuracy:		81.85 %
Epoch 1608 of 2000 took 0.163s
  training loss:		0.585932
  validation loss:		0.568918
  validation accuracy:		81.96 %
Epoch 1609 of 2000 took 0.167s
  training loss:		0.582235
  validation loss:		0.581129
  validation accuracy:		81.85 %
Epoch 1610 of 2000 took 0.161s
  training loss:		0.586697
  validation loss:		0.574467
  validation accuracy:		82.07 %
Epoch 1611 of 2000 took 0.164s
  training loss:		0.578367
  validation loss:		0.569099
  validation accuracy:		81.96 %
Epoch 1612 of 2000 took 0.161s
  training loss:		0.593066
  validation loss:		0.573876
  validation accuracy:		81.74 %
Epoch 1613 of 2000 took 0.163s
  training loss:		0.583386
  validation loss:		0.568572
  validation accuracy:		81.96 %
Epoch 1614 of 2000 took 0.166s
  training loss:		0.587478
  validation loss:		0.583447
  validation accuracy:		80.98 %
Epoch 1615 of 2000 took 0.161s
  training loss:		0.581442
  validation loss:		0.588226
  validation accuracy:		81.85 %
Epoch 1616 of 2000 took 0.164s
  training loss:		0.592659
  validation loss:		0.594042
  validation accuracy:		81.30 %
Epoch 1617 of 2000 took 0.163s
  training loss:		0.587544
  validation loss:		0.579671
  validation accuracy:		81.41 %
Epoch 1618 of 2000 took 0.165s
  training loss:		0.581971
  validation loss:		0.575934
  validation accuracy:		81.96 %
Epoch 1619 of 2000 took 0.163s
  training loss:		0.586177
  validation loss:		0.570457
  validation accuracy:		81.74 %
Epoch 1620 of 2000 took 0.163s
  training loss:		0.578764
  validation loss:		0.573809
  validation accuracy:		81.63 %
Epoch 1621 of 2000 took 0.165s
  training loss:		0.582717
  validation loss:		0.575305
  validation accuracy:		81.85 %
Epoch 1622 of 2000 took 0.161s
  training loss:		0.580738
  validation loss:		0.595920
  validation accuracy:		82.07 %
Epoch 1623 of 2000 took 0.165s
  training loss:		0.589507
  validation loss:		0.570860
  validation accuracy:		81.96 %
Epoch 1624 of 2000 took 0.162s
  training loss:		0.577906
  validation loss:		0.574843
  validation accuracy:		81.52 %
Epoch 1625 of 2000 took 0.163s
  training loss:		0.573784
  validation loss:		0.587967
  validation accuracy:		80.98 %
Epoch 1626 of 2000 took 0.164s
  training loss:		0.580436
  validation loss:		0.573984
  validation accuracy:		81.74 %
Epoch 1627 of 2000 took 0.161s
  training loss:		0.585571
  validation loss:		0.578223
  validation accuracy:		81.74 %
Epoch 1628 of 2000 took 0.166s
  training loss:		0.577520
  validation loss:		0.576379
  validation accuracy:		82.39 %
Epoch 1629 of 2000 took 0.161s
  training loss:		0.583459
  validation loss:		0.570780
  validation accuracy:		81.96 %
Epoch 1630 of 2000 took 0.163s
  training loss:		0.592436
  validation loss:		0.569153
  validation accuracy:		81.85 %
Epoch 1631 of 2000 took 0.164s
  training loss:		0.584756
  validation loss:		0.571807
  validation accuracy:		81.74 %
Epoch 1632 of 2000 took 0.161s
  training loss:		0.585156
  validation loss:		0.575319
  validation accuracy:		81.96 %
Epoch 1633 of 2000 took 0.167s
  training loss:		0.587089
  validation loss:		0.584031
  validation accuracy:		80.76 %
Epoch 1634 of 2000 took 0.161s
  training loss:		0.580898
  validation loss:		0.591448
  validation accuracy:		81.96 %
Epoch 1635 of 2000 took 0.164s
  training loss:		0.585890
  validation loss:		0.571990
  validation accuracy:		81.74 %
Epoch 1636 of 2000 took 0.162s
  training loss:		0.580443
  validation loss:		0.571224
  validation accuracy:		81.96 %
Epoch 1637 of 2000 took 0.163s
  training loss:		0.582887
  validation loss:		0.565904
  validation accuracy:		81.96 %
Epoch 1638 of 2000 took 0.167s
  training loss:		0.583364
  validation loss:		0.577575
  validation accuracy:		80.87 %
Epoch 1639 of 2000 took 0.161s
  training loss:		0.591144
  validation loss:		0.585839
  validation accuracy:		81.20 %
Epoch 1640 of 2000 took 0.164s
  training loss:		0.589336
  validation loss:		0.579122
  validation accuracy:		81.52 %
Epoch 1641 of 2000 took 0.161s
  training loss:		0.582245
  validation loss:		0.568837
  validation accuracy:		82.17 %
Epoch 1642 of 2000 took 0.164s
  training loss:		0.583060
  validation loss:		0.574737
  validation accuracy:		81.96 %
Epoch 1643 of 2000 took 0.166s
  training loss:		0.582679
  validation loss:		0.576074
  validation accuracy:		81.74 %
Epoch 1644 of 2000 took 0.161s
  training loss:		0.586453
  validation loss:		0.593540
  validation accuracy:		79.78 %
Epoch 1645 of 2000 took 0.164s
  training loss:		0.584611
  validation loss:		0.566567
  validation accuracy:		82.07 %
Epoch 1646 of 2000 took 0.161s
  training loss:		0.591238
  validation loss:		0.568560
  validation accuracy:		82.07 %
Epoch 1647 of 2000 took 0.165s
  training loss:		0.595328
  validation loss:		0.580833
  validation accuracy:		81.96 %
Epoch 1648 of 2000 took 0.163s
  training loss:		0.587633
  validation loss:		0.605399
  validation accuracy:		80.65 %
Epoch 1649 of 2000 took 0.163s
  training loss:		0.588242
  validation loss:		0.567202
  validation accuracy:		81.96 %
Epoch 1650 of 2000 took 0.164s
  training loss:		0.584863
  validation loss:		0.568474
  validation accuracy:		82.28 %
Epoch 1651 of 2000 took 0.161s
  training loss:		0.584055
  validation loss:		0.579056
  validation accuracy:		80.87 %
Epoch 1652 of 2000 took 0.166s
  training loss:		0.588652
  validation loss:		0.567684
  validation accuracy:		82.28 %
Epoch 1653 of 2000 took 0.161s
  training loss:		0.576200
  validation loss:		0.573103
  validation accuracy:		81.85 %
Epoch 1654 of 2000 took 0.163s
  training loss:		0.585575
  validation loss:		0.582950
  validation accuracy:		82.17 %
Epoch 1655 of 2000 took 0.164s
  training loss:		0.584054
  validation loss:		0.571205
  validation accuracy:		81.52 %
Epoch 1656 of 2000 took 0.161s
  training loss:		0.588025
  validation loss:		0.574881
  validation accuracy:		82.07 %
Epoch 1657 of 2000 took 0.167s
  training loss:		0.579273
  validation loss:		0.591701
  validation accuracy:		81.85 %
Epoch 1658 of 2000 took 0.161s
  training loss:		0.588982
  validation loss:		0.569824
  validation accuracy:		81.74 %
Epoch 1659 of 2000 took 0.164s
  training loss:		0.581888
  validation loss:		0.566679
  validation accuracy:		82.17 %
Epoch 1660 of 2000 took 0.162s
  training loss:		0.588690
  validation loss:		0.570289
  validation accuracy:		81.63 %
Epoch 1661 of 2000 took 0.162s
  training loss:		0.585744
  validation loss:		0.575394
  validation accuracy:		81.52 %
Epoch 1662 of 2000 took 0.166s
  training loss:		0.591224
  validation loss:		0.569623
  validation accuracy:		81.63 %
Epoch 1663 of 2000 took 0.161s
  training loss:		0.581603
  validation loss:		0.584206
  validation accuracy:		81.09 %
Epoch 1664 of 2000 took 0.164s
  training loss:		0.591634
  validation loss:		0.579651
  validation accuracy:		80.65 %
Epoch 1665 of 2000 took 0.162s
  training loss:		0.585748
  validation loss:		0.567544
  validation accuracy:		82.28 %
Epoch 1666 of 2000 took 0.163s
  training loss:		0.589456
  validation loss:		0.569096
  validation accuracy:		82.07 %
Epoch 1667 of 2000 took 0.167s
  training loss:		0.586157
  validation loss:		0.566591
  validation accuracy:		82.17 %
Epoch 1668 of 2000 took 0.161s
  training loss:		0.585126
  validation loss:		0.566197
  validation accuracy:		81.96 %
Epoch 1669 of 2000 took 0.164s
  training loss:		0.577195
  validation loss:		0.564153
  validation accuracy:		81.96 %
Epoch 1670 of 2000 took 0.161s
  training loss:		0.582472
  validation loss:		0.574462
  validation accuracy:		81.74 %
Epoch 1671 of 2000 took 0.164s
  training loss:		0.582696
  validation loss:		0.578989
  validation accuracy:		81.20 %
Epoch 1672 of 2000 took 0.165s
  training loss:		0.584851
  validation loss:		0.576237
  validation accuracy:		81.20 %
Epoch 1673 of 2000 took 0.161s
  training loss:		0.582704
  validation loss:		0.570686
  validation accuracy:		81.63 %
Epoch 1674 of 2000 took 0.164s
  training loss:		0.579509
  validation loss:		0.590721
  validation accuracy:		81.85 %
Epoch 1675 of 2000 took 0.161s
  training loss:		0.583902
  validation loss:		0.571731
  validation accuracy:		81.09 %
Epoch 1676 of 2000 took 0.165s
  training loss:		0.580824
  validation loss:		0.565986
  validation accuracy:		82.07 %
Epoch 1677 of 2000 took 0.163s
  training loss:		0.573832
  validation loss:		0.569915
  validation accuracy:		81.63 %
Epoch 1678 of 2000 took 0.165s
  training loss:		0.579497
  validation loss:		0.572626
  validation accuracy:		81.74 %
Epoch 1679 of 2000 took 0.164s
  training loss:		0.583962
  validation loss:		0.572566
  validation accuracy:		82.28 %
Epoch 1680 of 2000 took 0.161s
  training loss:		0.586713
  validation loss:		0.565687
  validation accuracy:		81.85 %
Epoch 1681 of 2000 took 0.166s
  training loss:		0.584218
  validation loss:		0.588686
  validation accuracy:		81.52 %
Epoch 1682 of 2000 took 0.162s
  training loss:		0.578724
  validation loss:		0.570165
  validation accuracy:		81.85 %
Epoch 1683 of 2000 took 0.163s
  training loss:		0.593038
  validation loss:		0.567399
  validation accuracy:		81.96 %
Epoch 1684 of 2000 took 0.164s
  training loss:		0.578720
  validation loss:		0.570919
  validation accuracy:		81.52 %
Epoch 1685 of 2000 took 0.161s
  training loss:		0.588067
  validation loss:		0.593127
  validation accuracy:		80.65 %
Epoch 1686 of 2000 took 0.167s
  training loss:		0.580119
  validation loss:		0.571863
  validation accuracy:		81.30 %
Epoch 1687 of 2000 took 0.161s
  training loss:		0.585284
  validation loss:		0.564239
  validation accuracy:		81.74 %
Epoch 1688 of 2000 took 0.164s
  training loss:		0.581265
  validation loss:		0.571944
  validation accuracy:		81.63 %
Epoch 1689 of 2000 took 0.163s
  training loss:		0.579463
  validation loss:		0.575699
  validation accuracy:		81.52 %
Epoch 1690 of 2000 took 0.162s
  training loss:		0.585477
  validation loss:		0.581445
  validation accuracy:		81.96 %
Epoch 1691 of 2000 took 0.167s
  training loss:		0.581595
  validation loss:		0.578075
  validation accuracy:		82.07 %
Epoch 1692 of 2000 took 0.161s
  training loss:		0.584451
  validation loss:		0.573421
  validation accuracy:		81.20 %
Epoch 1693 of 2000 took 0.164s
  training loss:		0.576750
  validation loss:		0.577577
  validation accuracy:		81.09 %
Epoch 1694 of 2000 took 0.162s
  training loss:		0.587649
  validation loss:		0.592474
  validation accuracy:		80.43 %
Epoch 1695 of 2000 took 0.163s
  training loss:		0.585960
  validation loss:		0.569498
  validation accuracy:		81.85 %
Epoch 1696 of 2000 took 0.166s
  training loss:		0.585907
  validation loss:		0.566914
  validation accuracy:		81.96 %
Epoch 1697 of 2000 took 0.161s
  training loss:		0.578036
  validation loss:		0.576630
  validation accuracy:		81.85 %
Epoch 1698 of 2000 took 0.164s
  training loss:		0.578363
  validation loss:		0.600706
  validation accuracy:		80.43 %
Epoch 1699 of 2000 took 0.161s
  training loss:		0.581992
  validation loss:		0.567577
  validation accuracy:		81.96 %
Epoch 1700 of 2000 took 0.164s
  training loss:		0.581468
  validation loss:		0.565666
  validation accuracy:		82.17 %
Epoch 1701 of 2000 took 0.165s
  training loss:		0.577273
  validation loss:		0.567627
  validation accuracy:		82.07 %
Epoch 1702 of 2000 took 0.161s
  training loss:		0.578170
  validation loss:		0.569495
  validation accuracy:		82.07 %
Epoch 1703 of 2000 took 0.164s
  training loss:		0.575483
  validation loss:		0.574188
  validation accuracy:		81.63 %
Epoch 1704 of 2000 took 0.161s
  training loss:		0.581356
  validation loss:		0.574139
  validation accuracy:		82.07 %
Epoch 1705 of 2000 took 0.166s
  training loss:		0.579709
  validation loss:		0.572859
  validation accuracy:		81.85 %
Epoch 1706 of 2000 took 0.162s
  training loss:		0.582684
  validation loss:		0.567789
  validation accuracy:		82.17 %
Epoch 1707 of 2000 took 0.163s
  training loss:		0.580457
  validation loss:		0.564626
  validation accuracy:		82.07 %
Epoch 1708 of 2000 took 0.164s
  training loss:		0.583542
  validation loss:		0.573523
  validation accuracy:		82.07 %
Epoch 1709 of 2000 took 0.161s
  training loss:		0.578094
  validation loss:		0.576890
  validation accuracy:		82.17 %
Epoch 1710 of 2000 took 0.167s
  training loss:		0.581342
  validation loss:		0.602892
  validation accuracy:		81.63 %
Epoch 1711 of 2000 took 0.161s
  training loss:		0.584344
  validation loss:		0.573121
  validation accuracy:		81.41 %
Epoch 1712 of 2000 took 0.163s
  training loss:		0.577595
  validation loss:		0.566452
  validation accuracy:		81.96 %
Epoch 1713 of 2000 took 0.164s
  training loss:		0.585860
  validation loss:		0.573845
  validation accuracy:		81.30 %
Epoch 1714 of 2000 took 0.162s
  training loss:		0.581890
  validation loss:		0.581601
  validation accuracy:		81.41 %
Epoch 1715 of 2000 took 0.167s
  training loss:		0.585462
  validation loss:		0.567587
  validation accuracy:		82.17 %
Epoch 1716 of 2000 took 0.161s
  training loss:		0.590193
  validation loss:		0.576750
  validation accuracy:		81.20 %
Epoch 1717 of 2000 took 0.164s
  training loss:		0.579069
  validation loss:		0.596189
  validation accuracy:		81.85 %
Epoch 1718 of 2000 took 0.162s
  training loss:		0.588561
  validation loss:		0.566852
  validation accuracy:		82.39 %
Epoch 1719 of 2000 took 0.163s
  training loss:		0.588962
  validation loss:		0.574679
  validation accuracy:		81.85 %
Epoch 1720 of 2000 took 0.167s
  training loss:		0.587360
  validation loss:		0.579901
  validation accuracy:		80.65 %
Epoch 1721 of 2000 took 0.161s
  training loss:		0.586891
  validation loss:		0.573138
  validation accuracy:		81.41 %
Epoch 1722 of 2000 took 0.164s
  training loss:		0.592371
  validation loss:		0.583904
  validation accuracy:		81.96 %
Epoch 1723 of 2000 took 0.162s
  training loss:		0.580682
  validation loss:		0.578157
  validation accuracy:		81.96 %
Epoch 1724 of 2000 took 0.164s
  training loss:		0.589128
  validation loss:		0.566811
  validation accuracy:		82.17 %
Epoch 1725 of 2000 took 0.166s
  training loss:		0.580453
  validation loss:		0.587017
  validation accuracy:		82.17 %
Epoch 1726 of 2000 took 0.161s
  training loss:		0.577589
  validation loss:		0.575568
  validation accuracy:		81.85 %
Epoch 1727 of 2000 took 0.164s
  training loss:		0.585672
  validation loss:		0.564371
  validation accuracy:		81.85 %
Epoch 1728 of 2000 took 0.161s
  training loss:		0.587011
  validation loss:		0.573212
  validation accuracy:		81.52 %
Epoch 1729 of 2000 took 0.165s
  training loss:		0.581838
  validation loss:		0.562727
  validation accuracy:		81.85 %
Epoch 1730 of 2000 took 0.163s
  training loss:		0.582400
  validation loss:		0.568446
  validation accuracy:		81.52 %
Epoch 1731 of 2000 took 0.163s
  training loss:		0.582409
  validation loss:		0.569707
  validation accuracy:		81.74 %
Epoch 1732 of 2000 took 0.165s
  training loss:		0.586913
  validation loss:		0.579275
  validation accuracy:		81.85 %
Epoch 1733 of 2000 took 0.161s
  training loss:		0.590659
  validation loss:		0.563490
  validation accuracy:		81.74 %
Epoch 1734 of 2000 took 0.166s
  training loss:		0.583846
  validation loss:		0.575651
  validation accuracy:		81.09 %
Epoch 1735 of 2000 took 0.166s
  training loss:		0.578309
  validation loss:		0.573337
  validation accuracy:		81.30 %
Epoch 1736 of 2000 took 0.163s
  training loss:		0.590147
  validation loss:		0.570882
  validation accuracy:		81.74 %
Epoch 1737 of 2000 took 0.164s
  training loss:		0.587939
  validation loss:		0.580633
  validation accuracy:		81.96 %
Epoch 1738 of 2000 took 0.162s
  training loss:		0.581666
  validation loss:		0.566223
  validation accuracy:		82.07 %
Epoch 1739 of 2000 took 0.169s
  training loss:		0.582289
  validation loss:		0.569704
  validation accuracy:		81.63 %
Epoch 1740 of 2000 took 0.161s
  training loss:		0.587849
  validation loss:		0.570181
  validation accuracy:		81.74 %
Epoch 1741 of 2000 took 0.164s
  training loss:		0.583207
  validation loss:		0.569372
  validation accuracy:		81.96 %
Epoch 1742 of 2000 took 0.164s
  training loss:		0.578346
  validation loss:		0.572718
  validation accuracy:		80.87 %
Epoch 1743 of 2000 took 0.161s
  training loss:		0.574205
  validation loss:		0.575864
  validation accuracy:		81.85 %
Epoch 1744 of 2000 took 0.167s
  training loss:		0.583645
  validation loss:		0.578945
  validation accuracy:		81.63 %
Epoch 1745 of 2000 took 0.161s
  training loss:		0.587543
  validation loss:		0.574897
  validation accuracy:		80.98 %
Epoch 1746 of 2000 took 0.164s
  training loss:		0.586203
  validation loss:		0.581967
  validation accuracy:		81.09 %
Epoch 1747 of 2000 took 0.161s
  training loss:		0.580793
  validation loss:		0.567552
  validation accuracy:		82.39 %
Epoch 1748 of 2000 took 0.163s
  training loss:		0.576379
  validation loss:		0.564760
  validation accuracy:		82.07 %
Epoch 1749 of 2000 took 0.167s
  training loss:		0.583867
  validation loss:		0.585838
  validation accuracy:		80.43 %
Epoch 1750 of 2000 took 0.161s
  training loss:		0.575059
  validation loss:		0.568739
  validation accuracy:		81.85 %
Epoch 1751 of 2000 took 0.164s
  training loss:		0.584082
  validation loss:		0.571508
  validation accuracy:		81.63 %
Epoch 1752 of 2000 took 0.161s
  training loss:		0.576972
  validation loss:		0.569840
  validation accuracy:		81.85 %
Epoch 1753 of 2000 took 0.164s
  training loss:		0.589131
  validation loss:		0.578179
  validation accuracy:		81.74 %
Epoch 1754 of 2000 took 0.165s
  training loss:		0.583052
  validation loss:		0.565841
  validation accuracy:		81.74 %
Epoch 1755 of 2000 took 0.161s
  training loss:		0.587966
  validation loss:		0.566816
  validation accuracy:		82.28 %
Epoch 1756 of 2000 took 0.164s
  training loss:		0.590416
  validation loss:		0.569932
  validation accuracy:		81.52 %
Epoch 1757 of 2000 took 0.161s
  training loss:		0.581729
  validation loss:		0.574269
  validation accuracy:		82.28 %
Epoch 1758 of 2000 took 0.165s
  training loss:		0.588809
  validation loss:		0.579491
  validation accuracy:		81.96 %
Epoch 1759 of 2000 took 0.162s
  training loss:		0.581760
  validation loss:		0.565343
  validation accuracy:		82.39 %
Epoch 1760 of 2000 took 0.163s
  training loss:		0.579718
  validation loss:		0.573597
  validation accuracy:		80.98 %
Epoch 1761 of 2000 took 0.164s
  training loss:		0.587043
  validation loss:		0.565772
  validation accuracy:		81.74 %
Epoch 1762 of 2000 took 0.161s
  training loss:		0.590659
  validation loss:		0.576731
  validation accuracy:		80.76 %
Epoch 1763 of 2000 took 0.167s
  training loss:		0.582197
  validation loss:		0.571594
  validation accuracy:		81.74 %
Epoch 1764 of 2000 took 0.160s
  training loss:		0.577156
  validation loss:		0.566633
  validation accuracy:		82.39 %
Epoch 1765 of 2000 took 0.163s
  training loss:		0.587203
  validation loss:		0.574428
  validation accuracy:		81.63 %
Epoch 1766 of 2000 took 0.164s
  training loss:		0.579745
  validation loss:		0.570402
  validation accuracy:		81.63 %
Epoch 1767 of 2000 took 0.161s
  training loss:		0.585103
  validation loss:		0.566328
  validation accuracy:		81.74 %
Epoch 1768 of 2000 took 0.167s
  training loss:		0.585600
  validation loss:		0.575308
  validation accuracy:		81.85 %
Epoch 1769 of 2000 took 0.161s
  training loss:		0.582151
  validation loss:		0.572964
  validation accuracy:		81.63 %
Epoch 1770 of 2000 took 0.164s
  training loss:		0.586700
  validation loss:		0.565534
  validation accuracy:		82.17 %
Epoch 1771 of 2000 took 0.162s
  training loss:		0.579042
  validation loss:		0.570108
  validation accuracy:		81.74 %
Epoch 1772 of 2000 took 0.163s
  training loss:		0.586262
  validation loss:		0.605879
  validation accuracy:		81.30 %
Epoch 1773 of 2000 took 0.167s
  training loss:		0.588035
  validation loss:		0.580085
  validation accuracy:		81.96 %
Epoch 1774 of 2000 took 0.161s
  training loss:		0.584178
  validation loss:		0.578024
  validation accuracy:		82.17 %
Epoch 1775 of 2000 took 0.164s
  training loss:		0.579425
  validation loss:		0.575284
  validation accuracy:		82.17 %
Epoch 1776 of 2000 took 0.162s
  training loss:		0.590140
  validation loss:		0.569413
  validation accuracy:		82.07 %
Epoch 1777 of 2000 took 0.164s
  training loss:		0.576754
  validation loss:		0.579571
  validation accuracy:		82.07 %
Epoch 1778 of 2000 took 0.166s
  training loss:		0.587996
  validation loss:		0.572312
  validation accuracy:		81.41 %
Epoch 1779 of 2000 took 0.161s
  training loss:		0.585616
  validation loss:		0.597765
  validation accuracy:		81.74 %
Epoch 1780 of 2000 took 0.164s
  training loss:		0.585068
  validation loss:		0.588084
  validation accuracy:		82.17 %
Epoch 1781 of 2000 took 0.161s
  training loss:		0.584151
  validation loss:		0.569771
  validation accuracy:		81.63 %
Epoch 1782 of 2000 took 0.165s
  training loss:		0.582797
  validation loss:		0.573871
  validation accuracy:		81.09 %
Epoch 1783 of 2000 took 0.163s
  training loss:		0.579141
  validation loss:		0.581560
  validation accuracy:		81.85 %
Epoch 1784 of 2000 took 0.163s
  training loss:		0.586027
  validation loss:		0.572915
  validation accuracy:		81.52 %
Epoch 1785 of 2000 took 0.164s
  training loss:		0.589048
  validation loss:		0.575658
  validation accuracy:		81.63 %
Epoch 1786 of 2000 took 0.161s
  training loss:		0.586836
  validation loss:		0.578624
  validation accuracy:		81.09 %
Epoch 1787 of 2000 took 0.166s
  training loss:		0.573172
  validation loss:		0.565133
  validation accuracy:		82.39 %
Epoch 1788 of 2000 took 0.162s
  training loss:		0.579984
  validation loss:		0.567114
  validation accuracy:		82.28 %
Epoch 1789 of 2000 took 0.163s
  training loss:		0.587758
  validation loss:		0.565850
  validation accuracy:		82.39 %
Epoch 1790 of 2000 took 0.164s
  training loss:		0.579315
  validation loss:		0.565225
  validation accuracy:		82.39 %
Epoch 1791 of 2000 took 0.162s
  training loss:		0.583626
  validation loss:		0.584448
  validation accuracy:		81.96 %
Epoch 1792 of 2000 took 0.167s
  training loss:		0.578108
  validation loss:		0.571464
  validation accuracy:		81.85 %
Epoch 1793 of 2000 took 0.161s
  training loss:		0.584943
  validation loss:		0.576578
  validation accuracy:		81.20 %
Epoch 1794 of 2000 took 0.164s
  training loss:		0.579705
  validation loss:		0.571797
  validation accuracy:		81.30 %
Epoch 1795 of 2000 took 0.162s
  training loss:		0.585952
  validation loss:		0.573261
  validation accuracy:		82.07 %
Epoch 1796 of 2000 took 0.163s
  training loss:		0.589122
  validation loss:		0.571049
  validation accuracy:		81.52 %
Epoch 1797 of 2000 took 0.167s
  training loss:		0.581927
  validation loss:		0.574140
  validation accuracy:		81.63 %
Epoch 1798 of 2000 took 0.161s
  training loss:		0.580732
  validation loss:		0.579968
  validation accuracy:		81.20 %
Epoch 1799 of 2000 took 0.164s
  training loss:		0.588420
  validation loss:		0.576856
  validation accuracy:		80.65 %
Epoch 1800 of 2000 took 0.164s
  training loss:		0.589096
  validation loss:		0.590251
  validation accuracy:		82.39 %
Epoch 1801 of 2000 took 0.164s
  training loss:		0.593963
  validation loss:		0.581231
  validation accuracy:		80.98 %
Epoch 1802 of 2000 took 0.166s
  training loss:		0.585652
  validation loss:		0.571270
  validation accuracy:		81.74 %
Epoch 1803 of 2000 took 0.161s
  training loss:		0.590338
  validation loss:		0.570433
  validation accuracy:		81.96 %
Epoch 1804 of 2000 took 0.164s
  training loss:		0.582760
  validation loss:		0.565535
  validation accuracy:		82.17 %
Epoch 1805 of 2000 took 0.161s
  training loss:		0.586406
  validation loss:		0.576979
  validation accuracy:		80.76 %
Epoch 1806 of 2000 took 0.165s
  training loss:		0.572624
  validation loss:		0.573478
  validation accuracy:		82.17 %
Epoch 1807 of 2000 took 0.164s
  training loss:		0.576502
  validation loss:		0.575034
  validation accuracy:		81.09 %
Epoch 1808 of 2000 took 0.162s
  training loss:		0.586819
  validation loss:		0.570338
  validation accuracy:		81.96 %
Epoch 1809 of 2000 took 0.164s
  training loss:		0.574274
  validation loss:		0.585048
  validation accuracy:		81.85 %
Epoch 1810 of 2000 took 0.161s
  training loss:		0.582660
  validation loss:		0.570514
  validation accuracy:		82.28 %
Epoch 1811 of 2000 took 0.166s
  training loss:		0.588383
  validation loss:		0.569850
  validation accuracy:		81.74 %
Epoch 1812 of 2000 took 0.162s
  training loss:		0.587438
  validation loss:		0.570776
  validation accuracy:		81.41 %
Epoch 1813 of 2000 took 0.163s
  training loss:		0.582476
  validation loss:		0.576531
  validation accuracy:		81.74 %
Epoch 1814 of 2000 took 0.164s
  training loss:		0.587532
  validation loss:		0.578450
  validation accuracy:		80.54 %
Epoch 1815 of 2000 took 0.161s
  training loss:		0.580643
  validation loss:		0.573396
  validation accuracy:		81.74 %
Epoch 1816 of 2000 took 0.167s
  training loss:		0.579905
  validation loss:		0.569561
  validation accuracy:		82.07 %
Epoch 1817 of 2000 took 0.161s
  training loss:		0.583217
  validation loss:		0.580730
  validation accuracy:		81.09 %
Epoch 1818 of 2000 took 0.163s
  training loss:		0.578789
  validation loss:		0.573519
  validation accuracy:		81.52 %
Epoch 1819 of 2000 took 0.164s
  training loss:		0.588381
  validation loss:		0.573712
  validation accuracy:		81.52 %
Epoch 1820 of 2000 took 0.161s
  training loss:		0.588824
  validation loss:		0.572816
  validation accuracy:		80.98 %
Epoch 1821 of 2000 took 0.167s
  training loss:		0.589849
  validation loss:		0.572485
  validation accuracy:		81.20 %
Epoch 1822 of 2000 took 0.161s
  training loss:		0.583805
  validation loss:		0.568790
  validation accuracy:		81.85 %
Epoch 1823 of 2000 took 0.164s
  training loss:		0.585231
  validation loss:		0.587548
  validation accuracy:		81.96 %
Epoch 1824 of 2000 took 0.162s
  training loss:		0.577835
  validation loss:		0.573135
  validation accuracy:		81.52 %
Epoch 1825 of 2000 took 0.163s
  training loss:		0.588310
  validation loss:		0.563421
  validation accuracy:		81.96 %
Epoch 1826 of 2000 took 0.167s
  training loss:		0.584631
  validation loss:		0.577180
  validation accuracy:		81.96 %
Epoch 1827 of 2000 took 0.161s
  training loss:		0.570055
  validation loss:		0.569853
  validation accuracy:		81.41 %
Epoch 1828 of 2000 took 0.164s
  training loss:		0.584271
  validation loss:		0.575944
  validation accuracy:		81.63 %
Epoch 1829 of 2000 took 0.161s
  training loss:		0.582508
  validation loss:		0.570696
  validation accuracy:		81.85 %
Epoch 1830 of 2000 took 0.164s
  training loss:		0.584194
  validation loss:		0.565077
  validation accuracy:		82.07 %
Epoch 1831 of 2000 took 0.166s
  training loss:		0.582177
  validation loss:		0.565440
  validation accuracy:		81.96 %
Epoch 1832 of 2000 took 0.161s
  training loss:		0.584958
  validation loss:		0.563126
  validation accuracy:		82.07 %
Epoch 1833 of 2000 took 0.164s
  training loss:		0.582668
  validation loss:		0.568217
  validation accuracy:		81.63 %
Epoch 1834 of 2000 took 0.161s
  training loss:		0.584128
  validation loss:		0.564277
  validation accuracy:		82.07 %
Epoch 1835 of 2000 took 0.165s
  training loss:		0.585115
  validation loss:		0.572149
  validation accuracy:		81.85 %
Epoch 1836 of 2000 took 0.163s
  training loss:		0.594075
  validation loss:		0.575642
  validation accuracy:		81.85 %
Epoch 1837 of 2000 took 0.163s
  training loss:		0.577347
  validation loss:		0.564924
  validation accuracy:		82.28 %
Epoch 1838 of 2000 took 0.164s
  training loss:		0.583690
  validation loss:		0.568987
  validation accuracy:		81.96 %
Epoch 1839 of 2000 took 0.162s
  training loss:		0.587526
  validation loss:		0.572458
  validation accuracy:		81.63 %
Epoch 1840 of 2000 took 0.166s
  training loss:		0.583901
  validation loss:		0.590628
  validation accuracy:		81.74 %
Epoch 1841 of 2000 took 0.161s
  training loss:		0.583873
  validation loss:		0.579540
  validation accuracy:		80.87 %
Epoch 1842 of 2000 took 0.163s
  training loss:		0.590239
  validation loss:		0.575216
  validation accuracy:		81.30 %
Epoch 1843 of 2000 took 0.165s
  training loss:		0.579943
  validation loss:		0.570661
  validation accuracy:		81.63 %
Epoch 1844 of 2000 took 0.161s
  training loss:		0.576218
  validation loss:		0.566809
  validation accuracy:		82.17 %
Epoch 1845 of 2000 took 0.167s
  training loss:		0.581570
  validation loss:		0.591507
  validation accuracy:		82.17 %
Epoch 1846 of 2000 took 0.161s
  training loss:		0.589086
  validation loss:		0.570212
  validation accuracy:		81.74 %
Epoch 1847 of 2000 took 0.164s
  training loss:		0.586503
  validation loss:		0.567122
  validation accuracy:		81.96 %
Epoch 1848 of 2000 took 0.164s
  training loss:		0.571828
  validation loss:		0.571654
  validation accuracy:		81.63 %
Epoch 1849 of 2000 took 0.161s
  training loss:		0.578832
  validation loss:		0.564698
  validation accuracy:		82.07 %
Epoch 1850 of 2000 took 0.166s
  training loss:		0.583393
  validation loss:		0.581751
  validation accuracy:		80.54 %
Epoch 1851 of 2000 took 0.161s
  training loss:		0.590548
  validation loss:		0.567195
  validation accuracy:		82.17 %
Epoch 1852 of 2000 took 0.164s
  training loss:		0.581416
  validation loss:		0.567976
  validation accuracy:		82.07 %
Epoch 1853 of 2000 took 0.161s
  training loss:		0.585717
  validation loss:		0.567770
  validation accuracy:		82.07 %
Epoch 1854 of 2000 took 0.163s
  training loss:		0.582256
  validation loss:		0.568370
  validation accuracy:		82.28 %
Epoch 1855 of 2000 took 0.167s
  training loss:		0.577132
  validation loss:		0.565649
  validation accuracy:		82.28 %
Epoch 1856 of 2000 took 0.159s
  training loss:		0.569682
  validation loss:		0.571340
  validation accuracy:		81.85 %
Epoch 1857 of 2000 took 0.164s
  training loss:		0.584174
  validation loss:		0.572696
  validation accuracy:		81.85 %
Epoch 1858 of 2000 took 0.161s
  training loss:		0.579729
  validation loss:		0.575240
  validation accuracy:		81.96 %
Epoch 1859 of 2000 took 0.164s
  training loss:		0.589484
  validation loss:		0.564968
  validation accuracy:		82.28 %
Epoch 1860 of 2000 took 0.166s
  training loss:		0.586082
  validation loss:		0.569355
  validation accuracy:		82.17 %
Epoch 1861 of 2000 took 0.161s
  training loss:		0.582289
  validation loss:		0.581616
  validation accuracy:		80.43 %
Epoch 1862 of 2000 took 0.166s
  training loss:		0.594524
  validation loss:		0.584767
  validation accuracy:		82.39 %
Epoch 1863 of 2000 took 0.161s
  training loss:		0.578563
  validation loss:		0.571996
  validation accuracy:		81.63 %
Epoch 1864 of 2000 took 0.165s
  training loss:		0.593906
  validation loss:		0.572816
  validation accuracy:		81.41 %
Epoch 1865 of 2000 took 0.163s
  training loss:		0.580777
  validation loss:		0.566968
  validation accuracy:		81.74 %
Epoch 1866 of 2000 took 0.163s
  training loss:		0.576326
  validation loss:		0.570999
  validation accuracy:		81.30 %
Epoch 1867 of 2000 took 0.164s
  training loss:		0.579225
  validation loss:		0.569897
  validation accuracy:		81.85 %
Epoch 1868 of 2000 took 0.161s
  training loss:		0.583143
  validation loss:		0.569500
  validation accuracy:		81.96 %
Epoch 1869 of 2000 took 0.166s
  training loss:		0.588991
  validation loss:		0.575589
  validation accuracy:		81.30 %
Epoch 1870 of 2000 took 0.161s
  training loss:		0.587524
  validation loss:		0.565466
  validation accuracy:		82.28 %
Epoch 1871 of 2000 took 0.163s
  training loss:		0.576752
  validation loss:		0.571066
  validation accuracy:		81.30 %
Epoch 1872 of 2000 took 0.164s
  training loss:		0.581110
  validation loss:		0.579856
  validation accuracy:		80.54 %
Epoch 1873 of 2000 took 0.161s
  training loss:		0.590100
  validation loss:		0.570414
  validation accuracy:		81.52 %
Epoch 1874 of 2000 took 0.167s
  training loss:		0.589046
  validation loss:		0.572074
  validation accuracy:		81.63 %
Epoch 1875 of 2000 took 0.161s
  training loss:		0.585463
  validation loss:		0.566302
  validation accuracy:		82.07 %
Epoch 1876 of 2000 took 0.164s
  training loss:		0.587031
  validation loss:		0.566585
  validation accuracy:		81.85 %
Epoch 1877 of 2000 took 0.162s
  training loss:		0.589555
  validation loss:		0.569299
  validation accuracy:		82.07 %
Epoch 1878 of 2000 took 0.163s
  training loss:		0.590817
  validation loss:		0.577764
  validation accuracy:		81.96 %
Epoch 1879 of 2000 took 0.167s
  training loss:		0.591576
  validation loss:		0.587666
  validation accuracy:		82.07 %
Epoch 1880 of 2000 took 0.161s
  training loss:		0.590692
  validation loss:		0.570537
  validation accuracy:		81.52 %
Epoch 1881 of 2000 took 0.164s
  training loss:		0.579554
  validation loss:		0.568039
  validation accuracy:		81.96 %
Epoch 1882 of 2000 took 0.161s
  training loss:		0.573300
  validation loss:		0.569176
  validation accuracy:		81.41 %
Epoch 1883 of 2000 took 0.163s
  training loss:		0.585201
  validation loss:		0.574808
  validation accuracy:		81.30 %
Epoch 1884 of 2000 took 0.166s
  training loss:		0.576814
  validation loss:		0.580928
  validation accuracy:		81.74 %
Epoch 1885 of 2000 took 0.161s
  training loss:		0.594343
  validation loss:		0.568464
  validation accuracy:		82.07 %
Epoch 1886 of 2000 took 0.164s
  training loss:		0.573759
  validation loss:		0.569790
  validation accuracy:		81.52 %
Epoch 1887 of 2000 took 0.161s
  training loss:		0.583382
  validation loss:		0.566256
  validation accuracy:		81.85 %
Epoch 1888 of 2000 took 0.165s
  training loss:		0.588175
  validation loss:		0.570250
  validation accuracy:		81.63 %
Epoch 1889 of 2000 took 0.165s
  training loss:		0.583580
  validation loss:		0.589824
  validation accuracy:		82.17 %
Epoch 1890 of 2000 took 0.162s
  training loss:		0.599539
  validation loss:		0.602557
  validation accuracy:		81.96 %
Epoch 1891 of 2000 took 0.164s
  training loss:		0.575064
  validation loss:		0.564866
  validation accuracy:		82.07 %
Epoch 1892 of 2000 took 0.161s
  training loss:		0.584500
  validation loss:		0.564307
  validation accuracy:		81.74 %
Epoch 1893 of 2000 took 0.166s
  training loss:		0.583196
  validation loss:		0.578282
  validation accuracy:		81.09 %
Epoch 1894 of 2000 took 0.162s
  training loss:		0.578251
  validation loss:		0.564774
  validation accuracy:		82.28 %
Epoch 1895 of 2000 took 0.163s
  training loss:		0.573586
  validation loss:		0.565833
  validation accuracy:		81.74 %
Epoch 1896 of 2000 took 0.164s
  training loss:		0.584331
  validation loss:		0.567070
  validation accuracy:		81.96 %
Epoch 1897 of 2000 took 0.161s
  training loss:		0.584222
  validation loss:		0.599348
  validation accuracy:		82.17 %
Epoch 1898 of 2000 took 0.167s
  training loss:		0.589956
  validation loss:		0.564525
  validation accuracy:		81.74 %
Epoch 1899 of 2000 took 0.161s
  training loss:		0.579136
  validation loss:		0.570214
  validation accuracy:		81.41 %
Epoch 1900 of 2000 took 0.163s
  training loss:		0.580023
  validation loss:		0.566887
  validation accuracy:		81.41 %
Epoch 1901 of 2000 took 0.164s
  training loss:		0.585281
  validation loss:		0.569899
  validation accuracy:		81.85 %
Epoch 1902 of 2000 took 0.161s
  training loss:		0.587798
  validation loss:		0.579519
  validation accuracy:		81.74 %
Epoch 1903 of 2000 took 0.167s
  training loss:		0.577212
  validation loss:		0.565609
  validation accuracy:		82.07 %
Epoch 1904 of 2000 took 0.161s
  training loss:		0.583841
  validation loss:		0.565336
  validation accuracy:		82.28 %
Epoch 1905 of 2000 took 0.164s
  training loss:		0.596327
  validation loss:		0.568913
  validation accuracy:		81.63 %
Epoch 1906 of 2000 took 0.162s
  training loss:		0.585019
  validation loss:		0.584492
  validation accuracy:		81.63 %
Epoch 1907 of 2000 took 0.163s
  training loss:		0.585941
  validation loss:		0.568222
  validation accuracy:		82.28 %
Epoch 1908 of 2000 took 0.167s
  training loss:		0.579094
  validation loss:		0.568524
  validation accuracy:		82.07 %
Epoch 1909 of 2000 took 0.161s
  training loss:		0.584588
  validation loss:		0.566604
  validation accuracy:		82.07 %
Epoch 1910 of 2000 took 0.164s
  training loss:		0.584797
  validation loss:		0.566860
  validation accuracy:		81.96 %
Epoch 1911 of 2000 took 0.161s
  training loss:		0.581416
  validation loss:		0.567420
  validation accuracy:		81.85 %
Epoch 1912 of 2000 took 0.164s
  training loss:		0.590522
  validation loss:		0.584093
  validation accuracy:		82.17 %
Epoch 1913 of 2000 took 0.166s
  training loss:		0.583990
  validation loss:		0.568860
  validation accuracy:		81.52 %
Epoch 1914 of 2000 took 0.160s
  training loss:		0.585004
  validation loss:		0.563771
  validation accuracy:		82.50 %
Epoch 1915 of 2000 took 0.164s
  training loss:		0.583288
  validation loss:		0.575286
  validation accuracy:		80.76 %
Epoch 1916 of 2000 took 0.161s
  training loss:		0.586661
  validation loss:		0.572257
  validation accuracy:		81.09 %
Epoch 1917 of 2000 took 0.165s
  training loss:		0.582453
  validation loss:		0.566123
  validation accuracy:		81.85 %
Epoch 1918 of 2000 took 0.162s
  training loss:		0.584269
  validation loss:		0.570430
  validation accuracy:		81.30 %
Epoch 1919 of 2000 took 0.163s
  training loss:		0.583110
  validation loss:		0.565946
  validation accuracy:		82.07 %
Epoch 1920 of 2000 took 0.164s
  training loss:		0.588713
  validation loss:		0.565506
  validation accuracy:		82.07 %
Epoch 1921 of 2000 took 0.161s
  training loss:		0.579113
  validation loss:		0.578066
  validation accuracy:		82.17 %
Epoch 1922 of 2000 took 0.166s
  training loss:		0.588660
  validation loss:		0.564329
  validation accuracy:		81.74 %
Epoch 1923 of 2000 took 0.163s
  training loss:		0.585421
  validation loss:		0.567850
  validation accuracy:		81.96 %
Epoch 1924 of 2000 took 0.163s
  training loss:		0.587521
  validation loss:		0.573276
  validation accuracy:		81.09 %
Epoch 1925 of 2000 took 0.164s
  training loss:		0.582181
  validation loss:		0.565486
  validation accuracy:		82.17 %
Epoch 1926 of 2000 took 0.161s
  training loss:		0.584189
  validation loss:		0.575074
  validation accuracy:		81.85 %
Epoch 1927 of 2000 took 0.167s
  training loss:		0.583623
  validation loss:		0.582489
  validation accuracy:		82.07 %
Epoch 1928 of 2000 took 0.163s
  training loss:		0.575477
  validation loss:		0.570482
  validation accuracy:		81.74 %
Epoch 1929 of 2000 took 0.163s
  training loss:		0.579171
  validation loss:		0.572276
  validation accuracy:		81.41 %
Epoch 1930 of 2000 took 0.147s
  training loss:		0.582603
  validation loss:		0.568074
  validation accuracy:		81.52 %
Epoch 1931 of 2000 took 0.104s
  training loss:		0.585756
  validation loss:		0.582455
  validation accuracy:		80.65 %
Epoch 1932 of 2000 took 0.104s
  training loss:		0.574512
  validation loss:		0.576584
  validation accuracy:		80.87 %
Epoch 1933 of 2000 took 0.104s
  training loss:		0.590349
  validation loss:		0.575706
  validation accuracy:		81.85 %
Epoch 1934 of 2000 took 0.105s
  training loss:		0.568247
  validation loss:		0.568427
  validation accuracy:		82.07 %
Epoch 1935 of 2000 took 0.105s
  training loss:		0.585060
  validation loss:		0.574344
  validation accuracy:		81.41 %
Epoch 1936 of 2000 took 0.105s
  training loss:		0.581927
  validation loss:		0.570099
  validation accuracy:		81.30 %
Epoch 1937 of 2000 took 0.105s
  training loss:		0.580291
  validation loss:		0.577215
  validation accuracy:		81.63 %
Epoch 1938 of 2000 took 0.105s
  training loss:		0.582185
  validation loss:		0.569548
  validation accuracy:		81.63 %
Epoch 1939 of 2000 took 0.105s
  training loss:		0.585908
  validation loss:		0.568830
  validation accuracy:		82.07 %
Epoch 1940 of 2000 took 0.105s
  training loss:		0.582178
  validation loss:		0.577873
  validation accuracy:		81.63 %
Epoch 1941 of 2000 took 0.105s
  training loss:		0.582944
  validation loss:		0.572393
  validation accuracy:		81.96 %
Epoch 1942 of 2000 took 0.105s
  training loss:		0.582855
  validation loss:		0.565505
  validation accuracy:		82.39 %
Epoch 1943 of 2000 took 0.105s
  training loss:		0.581610
  validation loss:		0.573647
  validation accuracy:		80.87 %
Epoch 1944 of 2000 took 0.107s
  training loss:		0.580141
  validation loss:		0.577070
  validation accuracy:		81.41 %
Epoch 1945 of 2000 took 0.106s
  training loss:		0.580266
  validation loss:		0.566090
  validation accuracy:		82.07 %
Epoch 1946 of 2000 took 0.109s
  training loss:		0.586271
  validation loss:		0.566931
  validation accuracy:		82.39 %
Epoch 1947 of 2000 took 0.109s
  training loss:		0.576110
  validation loss:		0.572325
  validation accuracy:		81.30 %
Epoch 1948 of 2000 took 0.106s
  training loss:		0.592833
  validation loss:		0.572989
  validation accuracy:		81.09 %
Epoch 1949 of 2000 took 0.108s
  training loss:		0.576452
  validation loss:		0.586599
  validation accuracy:		80.22 %
Epoch 1950 of 2000 took 0.112s
  training loss:		0.582988
  validation loss:		0.571800
  validation accuracy:		81.41 %
Epoch 1951 of 2000 took 0.106s
  training loss:		0.581041
  validation loss:		0.562727
  validation accuracy:		82.17 %
Epoch 1952 of 2000 took 0.107s
  training loss:		0.579930
  validation loss:		0.585359
  validation accuracy:		81.85 %
Epoch 1953 of 2000 took 0.106s
  training loss:		0.587035
  validation loss:		0.569044
  validation accuracy:		82.07 %
Epoch 1954 of 2000 took 0.109s
  training loss:		0.584979
  validation loss:		0.577123
  validation accuracy:		81.85 %
Epoch 1955 of 2000 took 0.109s
  training loss:		0.593976
  validation loss:		0.566758
  validation accuracy:		81.96 %
Epoch 1956 of 2000 took 0.106s
  training loss:		0.582923
  validation loss:		0.565920
  validation accuracy:		82.07 %
Epoch 1957 of 2000 took 0.107s
  training loss:		0.588230
  validation loss:		0.571509
  validation accuracy:		81.41 %
Epoch 1958 of 2000 took 0.112s
  training loss:		0.588386
  validation loss:		0.567322
  validation accuracy:		82.07 %
Epoch 1959 of 2000 took 0.106s
  training loss:		0.584039
  validation loss:		0.568465
  validation accuracy:		81.85 %
Epoch 1960 of 2000 took 0.107s
  training loss:		0.584252
  validation loss:		0.574593
  validation accuracy:		81.09 %
Epoch 1961 of 2000 took 0.106s
  training loss:		0.581991
  validation loss:		0.582525
  validation accuracy:		81.52 %
Epoch 1962 of 2000 took 0.112s
  training loss:		0.589018
  validation loss:		0.577803
  validation accuracy:		81.20 %
Epoch 1963 of 2000 took 0.109s
  training loss:		0.581877
  validation loss:		0.564183
  validation accuracy:		82.28 %
Epoch 1964 of 2000 took 0.106s
  training loss:		0.579691
  validation loss:		0.572201
  validation accuracy:		81.30 %
Epoch 1965 of 2000 took 0.108s
  training loss:		0.584108
  validation loss:		0.563052
  validation accuracy:		82.28 %
Epoch 1966 of 2000 took 0.112s
  training loss:		0.588142
  validation loss:		0.600770
  validation accuracy:		80.11 %
Epoch 1967 of 2000 took 0.106s
  training loss:		0.585757
  validation loss:		0.572220
  validation accuracy:		80.87 %
Epoch 1968 of 2000 took 0.107s
  training loss:		0.585876
  validation loss:		0.575882
  validation accuracy:		81.85 %
Epoch 1969 of 2000 took 0.106s
  training loss:		0.589311
  validation loss:		0.578318
  validation accuracy:		81.85 %
Epoch 1970 of 2000 took 0.109s
  training loss:		0.579419
  validation loss:		0.570423
  validation accuracy:		81.63 %
Epoch 1971 of 2000 took 0.109s
  training loss:		0.585739
  validation loss:		0.569305
  validation accuracy:		81.74 %
Epoch 1972 of 2000 took 0.106s
  training loss:		0.581098
  validation loss:		0.588614
  validation accuracy:		81.63 %
Epoch 1973 of 2000 took 0.107s
  training loss:		0.577820
  validation loss:		0.585132
  validation accuracy:		80.43 %
Epoch 1974 of 2000 took 0.112s
  training loss:		0.590038
  validation loss:		0.564929
  validation accuracy:		82.39 %
Epoch 1975 of 2000 took 0.106s
  training loss:		0.583091
  validation loss:		0.590343
  validation accuracy:		80.65 %
Epoch 1976 of 2000 took 0.107s
  training loss:		0.582218
  validation loss:		0.570381
  validation accuracy:		81.41 %
Epoch 1977 of 2000 took 0.106s
  training loss:		0.586219
  validation loss:		0.566398
  validation accuracy:		82.07 %
Epoch 1978 of 2000 took 0.109s
  training loss:		0.588032
  validation loss:		0.581588
  validation accuracy:		80.33 %
Epoch 1979 of 2000 took 0.109s
  training loss:		0.584613
  validation loss:		0.574153
  validation accuracy:		81.52 %
Epoch 1980 of 2000 took 0.106s
  training loss:		0.577878
  validation loss:		0.568260
  validation accuracy:		82.07 %
Epoch 1981 of 2000 took 0.107s
  training loss:		0.580642
  validation loss:		0.598218
  validation accuracy:		82.07 %
Epoch 1982 of 2000 took 0.112s
  training loss:		0.585948
  validation loss:		0.571324
  validation accuracy:		81.52 %
Epoch 1983 of 2000 took 0.106s
  training loss:		0.584127
  validation loss:		0.562758
  validation accuracy:		82.17 %
Epoch 1984 of 2000 took 0.107s
  training loss:		0.569992
  validation loss:		0.566127
  validation accuracy:		82.28 %
Epoch 1985 of 2000 took 0.106s
  training loss:		0.568893
  validation loss:		0.569763
  validation accuracy:		81.41 %
Epoch 1986 of 2000 took 0.108s
  training loss:		0.580358
  validation loss:		0.567752
  validation accuracy:		81.85 %
Epoch 1987 of 2000 took 0.110s
  training loss:		0.577801
  validation loss:		0.564918
  validation accuracy:		81.85 %
Epoch 1988 of 2000 took 0.106s
  training loss:		0.577692
  validation loss:		0.568267
  validation accuracy:		82.17 %
Epoch 1989 of 2000 took 0.107s
  training loss:		0.578877
  validation loss:		0.566704
  validation accuracy:		82.28 %
Epoch 1990 of 2000 took 0.113s
  training loss:		0.582670
  validation loss:		0.569289
  validation accuracy:		81.52 %
Epoch 1991 of 2000 took 0.106s
  training loss:		0.578390
  validation loss:		0.577591
  validation accuracy:		81.09 %
Epoch 1992 of 2000 took 0.107s
  training loss:		0.583993
  validation loss:		0.567475
  validation accuracy:		82.28 %
Epoch 1993 of 2000 took 0.106s
  training loss:		0.578991
  validation loss:		0.576946
  validation accuracy:		80.98 %
Epoch 1994 of 2000 took 0.108s
  training loss:		0.583015
  validation loss:		0.563856
  validation accuracy:		82.17 %
Epoch 1995 of 2000 took 0.110s
  training loss:		0.577970
  validation loss:		0.572885
  validation accuracy:		81.20 %
Epoch 1996 of 2000 took 0.106s
  training loss:		0.572774
  validation loss:		0.566396
  validation accuracy:		82.17 %
Epoch 1997 of 2000 took 0.107s
  training loss:		0.573068
  validation loss:		0.561218
  validation accuracy:		82.39 %
Epoch 1998 of 2000 took 0.113s
  training loss:		0.582384
  validation loss:		0.567106
  validation accuracy:		81.85 %
Epoch 1999 of 2000 took 0.106s
  training loss:		0.590578
  validation loss:		0.573358
  validation accuracy:		81.74 %
Epoch 2000 of 2000 took 0.107s
  training loss:		0.582254
  validation loss:		0.583954
  validation accuracy:		81.41 %
Final results:
  test loss:			0.907319
  test accuracy:		71.18 %
