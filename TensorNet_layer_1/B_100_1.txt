Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.057s
  training loss:		2.954111
  validation loss:		2.846169
  validation accuracy:		18.80 %
Epoch 2 of 2000 took 0.061s
  training loss:		2.771750
  validation loss:		2.610831
  validation accuracy:		18.70 %
Epoch 3 of 2000 took 0.050s
  training loss:		2.575070
  validation loss:		2.394867
  validation accuracy:		21.52 %
Epoch 4 of 2000 took 0.044s
  training loss:		2.406079
  validation loss:		2.240163
  validation accuracy:		36.96 %
Epoch 5 of 2000 took 0.041s
  training loss:		2.284946
  validation loss:		2.164729
  validation accuracy:		44.24 %
Epoch 6 of 2000 took 0.038s
  training loss:		2.215824
  validation loss:		2.129709
  validation accuracy:		47.72 %
Epoch 7 of 2000 took 0.038s
  training loss:		2.168223
  validation loss:		2.090672
  validation accuracy:		58.80 %
Epoch 8 of 2000 took 0.037s
  training loss:		2.126224
  validation loss:		2.043518
  validation accuracy:		58.26 %
Epoch 9 of 2000 took 0.038s
  training loss:		2.089256
  validation loss:		1.999150
  validation accuracy:		56.20 %
Epoch 10 of 2000 took 0.038s
  training loss:		2.050854
  validation loss:		1.959230
  validation accuracy:		67.17 %
Epoch 11 of 2000 took 0.038s
  training loss:		2.008307
  validation loss:		1.911564
  validation accuracy:		59.46 %
Epoch 12 of 2000 took 0.038s
  training loss:		1.964609
  validation loss:		1.867320
  validation accuracy:		67.93 %
Epoch 13 of 2000 took 0.038s
  training loss:		1.914200
  validation loss:		1.809914
  validation accuracy:		66.41 %
Epoch 14 of 2000 took 0.037s
  training loss:		1.864998
  validation loss:		1.752633
  validation accuracy:		67.39 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.804874
  validation loss:		1.689019
  validation accuracy:		69.89 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.740235
  validation loss:		1.623096
  validation accuracy:		72.07 %
Epoch 17 of 2000 took 0.036s
  training loss:		1.680447
  validation loss:		1.554553
  validation accuracy:		75.11 %
Epoch 18 of 2000 took 0.035s
  training loss:		1.612767
  validation loss:		1.490046
  validation accuracy:		75.76 %
Epoch 19 of 2000 took 0.035s
  training loss:		1.551414
  validation loss:		1.424694
  validation accuracy:		78.15 %
Epoch 20 of 2000 took 0.035s
  training loss:		1.490476
  validation loss:		1.359173
  validation accuracy:		79.57 %
Epoch 21 of 2000 took 0.035s
  training loss:		1.423579
  validation loss:		1.295901
  validation accuracy:		79.46 %
Epoch 22 of 2000 took 0.035s
  training loss:		1.358619
  validation loss:		1.226154
  validation accuracy:		79.57 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.296276
  validation loss:		1.177978
  validation accuracy:		80.43 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.245843
  validation loss:		1.117834
  validation accuracy:		81.85 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.192000
  validation loss:		1.065023
  validation accuracy:		81.96 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.141473
  validation loss:		1.024764
  validation accuracy:		82.28 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.090476
  validation loss:		0.970762
  validation accuracy:		83.26 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.049522
  validation loss:		0.940807
  validation accuracy:		83.04 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.004302
  validation loss:		0.895147
  validation accuracy:		83.59 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.963810
  validation loss:		0.855341
  validation accuracy:		83.80 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.930564
  validation loss:		0.814096
  validation accuracy:		84.89 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.892064
  validation loss:		0.786836
  validation accuracy:		84.46 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.857131
  validation loss:		0.757660
  validation accuracy:		85.11 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.820090
  validation loss:		0.717561
  validation accuracy:		85.00 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.788917
  validation loss:		0.705122
  validation accuracy:		85.43 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.759220
  validation loss:		0.669562
  validation accuracy:		85.87 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.733343
  validation loss:		0.643237
  validation accuracy:		86.20 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.703507
  validation loss:		0.613242
  validation accuracy:		86.74 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.683294
  validation loss:		0.606366
  validation accuracy:		86.52 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.657447
  validation loss:		0.581791
  validation accuracy:		86.96 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.636567
  validation loss:		0.562645
  validation accuracy:		87.28 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.616828
  validation loss:		0.547614
  validation accuracy:		87.07 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.593289
  validation loss:		0.533362
  validation accuracy:		87.17 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.571949
  validation loss:		0.515530
  validation accuracy:		87.72 %
Epoch 45 of 2000 took 0.036s
  training loss:		0.559821
  validation loss:		0.495109
  validation accuracy:		88.15 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.537633
  validation loss:		0.482673
  validation accuracy:		88.37 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.523149
  validation loss:		0.472362
  validation accuracy:		89.35 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.511352
  validation loss:		0.460376
  validation accuracy:		88.37 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.496608
  validation loss:		0.450806
  validation accuracy:		89.02 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.484007
  validation loss:		0.435303
  validation accuracy:		89.78 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.475852
  validation loss:		0.427931
  validation accuracy:		89.67 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.463239
  validation loss:		0.414263
  validation accuracy:		90.11 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.449070
  validation loss:		0.404210
  validation accuracy:		89.46 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.444784
  validation loss:		0.398664
  validation accuracy:		89.57 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.425768
  validation loss:		0.394917
  validation accuracy:		90.65 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.422052
  validation loss:		0.390335
  validation accuracy:		90.33 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.416158
  validation loss:		0.378638
  validation accuracy:		91.09 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.404287
  validation loss:		0.370592
  validation accuracy:		91.30 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.397355
  validation loss:		0.376237
  validation accuracy:		90.00 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.386904
  validation loss:		0.355028
  validation accuracy:		91.41 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.380535
  validation loss:		0.356315
  validation accuracy:		91.20 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.372250
  validation loss:		0.356473
  validation accuracy:		91.41 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.370956
  validation loss:		0.346521
  validation accuracy:		91.30 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.366972
  validation loss:		0.337859
  validation accuracy:		91.30 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.357447
  validation loss:		0.335545
  validation accuracy:		91.52 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.356658
  validation loss:		0.337528
  validation accuracy:		91.52 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.346111
  validation loss:		0.334414
  validation accuracy:		91.74 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.345061
  validation loss:		0.325944
  validation accuracy:		92.17 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.340222
  validation loss:		0.317012
  validation accuracy:		92.07 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.334530
  validation loss:		0.319657
  validation accuracy:		91.74 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.327849
  validation loss:		0.305121
  validation accuracy:		91.96 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.325242
  validation loss:		0.307076
  validation accuracy:		91.96 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.324778
  validation loss:		0.307436
  validation accuracy:		91.96 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.318392
  validation loss:		0.308091
  validation accuracy:		91.96 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.312900
  validation loss:		0.299407
  validation accuracy:		92.17 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.303272
  validation loss:		0.302162
  validation accuracy:		91.96 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.306000
  validation loss:		0.294323
  validation accuracy:		91.85 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.301376
  validation loss:		0.293642
  validation accuracy:		92.39 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.301588
  validation loss:		0.293172
  validation accuracy:		92.28 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.293429
  validation loss:		0.286053
  validation accuracy:		92.61 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.294419
  validation loss:		0.287437
  validation accuracy:		91.96 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.292344
  validation loss:		0.283114
  validation accuracy:		92.28 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.285123
  validation loss:		0.285784
  validation accuracy:		92.28 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.280141
  validation loss:		0.287389
  validation accuracy:		92.17 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.281822
  validation loss:		0.282876
  validation accuracy:		92.61 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.277650
  validation loss:		0.280023
  validation accuracy:		91.85 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.277148
  validation loss:		0.272740
  validation accuracy:		92.50 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.272878
  validation loss:		0.272982
  validation accuracy:		92.50 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.274244
  validation loss:		0.270072
  validation accuracy:		92.61 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.267274
  validation loss:		0.270814
  validation accuracy:		92.39 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.262728
  validation loss:		0.264627
  validation accuracy:		92.28 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.263821
  validation loss:		0.275006
  validation accuracy:		92.17 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.261547
  validation loss:		0.261451
  validation accuracy:		92.72 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.257228
  validation loss:		0.269473
  validation accuracy:		92.28 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.257925
  validation loss:		0.268523
  validation accuracy:		92.39 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.257762
  validation loss:		0.255385
  validation accuracy:		92.93 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.252114
  validation loss:		0.259276
  validation accuracy:		92.83 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.246789
  validation loss:		0.260979
  validation accuracy:		92.61 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.251585
  validation loss:		0.253060
  validation accuracy:		93.04 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.246606
  validation loss:		0.261886
  validation accuracy:		92.39 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.241821
  validation loss:		0.262244
  validation accuracy:		92.39 %
Epoch 102 of 2000 took 0.036s
  training loss:		0.244971
  validation loss:		0.250578
  validation accuracy:		93.26 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.240456
  validation loss:		0.249819
  validation accuracy:		93.04 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.240146
  validation loss:		0.252340
  validation accuracy:		92.61 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.237867
  validation loss:		0.250260
  validation accuracy:		92.72 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.238277
  validation loss:		0.241073
  validation accuracy:		92.93 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.234399
  validation loss:		0.244226
  validation accuracy:		92.93 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.232124
  validation loss:		0.247767
  validation accuracy:		92.93 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.231350
  validation loss:		0.243146
  validation accuracy:		93.26 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.227976
  validation loss:		0.245547
  validation accuracy:		93.26 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.226070
  validation loss:		0.242872
  validation accuracy:		92.93 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.222186
  validation loss:		0.241324
  validation accuracy:		93.26 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.225070
  validation loss:		0.239537
  validation accuracy:		93.15 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.224259
  validation loss:		0.237798
  validation accuracy:		93.15 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.222474
  validation loss:		0.240706
  validation accuracy:		93.04 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.222007
  validation loss:		0.236469
  validation accuracy:		93.15 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.219124
  validation loss:		0.239279
  validation accuracy:		93.37 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.216718
  validation loss:		0.236414
  validation accuracy:		93.37 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.219513
  validation loss:		0.237569
  validation accuracy:		93.15 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.216102
  validation loss:		0.240441
  validation accuracy:		92.93 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.216277
  validation loss:		0.237194
  validation accuracy:		93.04 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.214248
  validation loss:		0.231011
  validation accuracy:		93.48 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.209594
  validation loss:		0.235314
  validation accuracy:		93.15 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.207779
  validation loss:		0.231458
  validation accuracy:		93.59 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.206145
  validation loss:		0.239124
  validation accuracy:		93.15 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.211196
  validation loss:		0.234877
  validation accuracy:		93.15 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.206097
  validation loss:		0.225856
  validation accuracy:		93.26 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.203446
  validation loss:		0.232219
  validation accuracy:		93.15 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.204919
  validation loss:		0.227443
  validation accuracy:		93.37 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.200801
  validation loss:		0.237332
  validation accuracy:		93.15 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.202427
  validation loss:		0.232961
  validation accuracy:		93.15 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.199890
  validation loss:		0.222045
  validation accuracy:		93.59 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.200653
  validation loss:		0.227530
  validation accuracy:		93.37 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.198327
  validation loss:		0.222110
  validation accuracy:		93.48 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.192267
  validation loss:		0.222577
  validation accuracy:		93.37 %
Epoch 136 of 2000 took 0.038s
  training loss:		0.194179
  validation loss:		0.215234
  validation accuracy:		93.70 %
Epoch 137 of 2000 took 0.036s
  training loss:		0.198973
  validation loss:		0.219330
  validation accuracy:		93.59 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.192418
  validation loss:		0.223008
  validation accuracy:		93.59 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.190685
  validation loss:		0.216917
  validation accuracy:		93.37 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.193328
  validation loss:		0.220746
  validation accuracy:		93.48 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.193297
  validation loss:		0.216694
  validation accuracy:		93.59 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.188671
  validation loss:		0.216549
  validation accuracy:		93.59 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.187937
  validation loss:		0.218952
  validation accuracy:		93.37 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.185931
  validation loss:		0.223067
  validation accuracy:		93.37 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.187010
  validation loss:		0.236010
  validation accuracy:		92.72 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.188348
  validation loss:		0.225016
  validation accuracy:		93.15 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.186319
  validation loss:		0.217274
  validation accuracy:		93.37 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.184159
  validation loss:		0.222096
  validation accuracy:		93.37 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.185021
  validation loss:		0.220925
  validation accuracy:		93.15 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.182947
  validation loss:		0.216026
  validation accuracy:		93.48 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.179854
  validation loss:		0.220150
  validation accuracy:		93.37 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.178720
  validation loss:		0.211341
  validation accuracy:		93.37 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.181622
  validation loss:		0.222024
  validation accuracy:		93.15 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.178967
  validation loss:		0.212388
  validation accuracy:		93.26 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.179767
  validation loss:		0.215611
  validation accuracy:		93.37 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.173891
  validation loss:		0.213888
  validation accuracy:		93.37 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.176948
  validation loss:		0.212861
  validation accuracy:		93.26 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.177394
  validation loss:		0.221618
  validation accuracy:		93.26 %
Epoch 159 of 2000 took 0.036s
  training loss:		0.174059
  validation loss:		0.210161
  validation accuracy:		93.48 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.174400
  validation loss:		0.216802
  validation accuracy:		93.26 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.172189
  validation loss:		0.213233
  validation accuracy:		93.26 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.171944
  validation loss:		0.209494
  validation accuracy:		93.48 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.170835
  validation loss:		0.215370
  validation accuracy:		93.15 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.172938
  validation loss:		0.207946
  validation accuracy:		93.59 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.166094
  validation loss:		0.215677
  validation accuracy:		93.37 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.168259
  validation loss:		0.205688
  validation accuracy:		93.48 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.169623
  validation loss:		0.205293
  validation accuracy:		93.80 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.168839
  validation loss:		0.203145
  validation accuracy:		93.70 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.168766
  validation loss:		0.209421
  validation accuracy:		93.48 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.166172
  validation loss:		0.203223
  validation accuracy:		93.70 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.163819
  validation loss:		0.210217
  validation accuracy:		93.15 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.163012
  validation loss:		0.206010
  validation accuracy:		93.48 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.164306
  validation loss:		0.213601
  validation accuracy:		93.04 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.164074
  validation loss:		0.209310
  validation accuracy:		93.48 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.163779
  validation loss:		0.209527
  validation accuracy:		93.26 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.159012
  validation loss:		0.209486
  validation accuracy:		93.37 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.160264
  validation loss:		0.206001
  validation accuracy:		93.48 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.159024
  validation loss:		0.208643
  validation accuracy:		93.15 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.157645
  validation loss:		0.204192
  validation accuracy:		93.37 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.161454
  validation loss:		0.209272
  validation accuracy:		93.48 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.158551
  validation loss:		0.206588
  validation accuracy:		93.26 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.156832
  validation loss:		0.200218
  validation accuracy:		93.48 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.152857
  validation loss:		0.204988
  validation accuracy:		93.26 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.159027
  validation loss:		0.198582
  validation accuracy:		93.48 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.156143
  validation loss:		0.197369
  validation accuracy:		93.80 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.152662
  validation loss:		0.202073
  validation accuracy:		93.48 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.155268
  validation loss:		0.202216
  validation accuracy:		93.48 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.154005
  validation loss:		0.198641
  validation accuracy:		93.80 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.151748
  validation loss:		0.203802
  validation accuracy:		93.37 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.152940
  validation loss:		0.201689
  validation accuracy:		93.26 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.152660
  validation loss:		0.200721
  validation accuracy:		93.48 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.148952
  validation loss:		0.196397
  validation accuracy:		93.91 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.152976
  validation loss:		0.202203
  validation accuracy:		93.59 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.151283
  validation loss:		0.200608
  validation accuracy:		93.48 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.151314
  validation loss:		0.196107
  validation accuracy:		94.02 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.149162
  validation loss:		0.209242
  validation accuracy:		93.26 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.145515
  validation loss:		0.200920
  validation accuracy:		93.37 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.144053
  validation loss:		0.207375
  validation accuracy:		93.37 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.142312
  validation loss:		0.198302
  validation accuracy:		93.91 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.148525
  validation loss:		0.191696
  validation accuracy:		93.91 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.143534
  validation loss:		0.201403
  validation accuracy:		93.59 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.141170
  validation loss:		0.202550
  validation accuracy:		93.37 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.143910
  validation loss:		0.199016
  validation accuracy:		93.70 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.142978
  validation loss:		0.199046
  validation accuracy:		94.02 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.142446
  validation loss:		0.198003
  validation accuracy:		93.80 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.143267
  validation loss:		0.199392
  validation accuracy:		93.59 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.140037
  validation loss:		0.199559
  validation accuracy:		93.59 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.141718
  validation loss:		0.192215
  validation accuracy:		93.70 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.139426
  validation loss:		0.196628
  validation accuracy:		93.91 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.141233
  validation loss:		0.200144
  validation accuracy:		93.59 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.138496
  validation loss:		0.200775
  validation accuracy:		93.26 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.138206
  validation loss:		0.195517
  validation accuracy:		94.02 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.136629
  validation loss:		0.196692
  validation accuracy:		93.80 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.133996
  validation loss:		0.188415
  validation accuracy:		94.02 %
Epoch 215 of 2000 took 0.036s
  training loss:		0.133096
  validation loss:		0.197838
  validation accuracy:		93.70 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.138094
  validation loss:		0.199290
  validation accuracy:		94.02 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.134585
  validation loss:		0.195319
  validation accuracy:		93.80 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.133571
  validation loss:		0.193104
  validation accuracy:		93.91 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.137467
  validation loss:		0.194257
  validation accuracy:		93.80 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.136784
  validation loss:		0.194665
  validation accuracy:		93.80 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.137405
  validation loss:		0.193566
  validation accuracy:		93.70 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.130364
  validation loss:		0.194832
  validation accuracy:		93.80 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.132835
  validation loss:		0.193843
  validation accuracy:		93.91 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.130964
  validation loss:		0.191468
  validation accuracy:		93.91 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.129632
  validation loss:		0.199477
  validation accuracy:		93.70 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.129668
  validation loss:		0.192372
  validation accuracy:		93.91 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.131017
  validation loss:		0.198349
  validation accuracy:		93.70 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.131317
  validation loss:		0.192302
  validation accuracy:		94.02 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.128106
  validation loss:		0.189414
  validation accuracy:		93.91 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.129471
  validation loss:		0.196832
  validation accuracy:		93.70 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.128215
  validation loss:		0.195810
  validation accuracy:		93.80 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.127599
  validation loss:		0.199164
  validation accuracy:		93.59 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.126535
  validation loss:		0.192538
  validation accuracy:		93.80 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.127690
  validation loss:		0.189441
  validation accuracy:		93.70 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.125864
  validation loss:		0.196031
  validation accuracy:		93.70 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.126512
  validation loss:		0.193031
  validation accuracy:		93.80 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.128489
  validation loss:		0.191222
  validation accuracy:		94.02 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.128401
  validation loss:		0.190554
  validation accuracy:		93.80 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.125024
  validation loss:		0.188812
  validation accuracy:		93.91 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.126391
  validation loss:		0.187331
  validation accuracy:		94.02 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.122782
  validation loss:		0.192355
  validation accuracy:		94.02 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.122485
  validation loss:		0.192098
  validation accuracy:		93.91 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.123591
  validation loss:		0.190972
  validation accuracy:		94.02 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.123852
  validation loss:		0.190580
  validation accuracy:		94.02 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.122224
  validation loss:		0.193597
  validation accuracy:		94.02 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.122429
  validation loss:		0.193448
  validation accuracy:		93.91 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.122415
  validation loss:		0.189003
  validation accuracy:		93.80 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.121719
  validation loss:		0.193452
  validation accuracy:		93.80 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.120495
  validation loss:		0.195608
  validation accuracy:		94.02 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.118856
  validation loss:		0.203556
  validation accuracy:		93.70 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.119181
  validation loss:		0.189986
  validation accuracy:		93.80 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.118328
  validation loss:		0.189791
  validation accuracy:		93.70 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.120873
  validation loss:		0.188474
  validation accuracy:		94.02 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.118362
  validation loss:		0.188366
  validation accuracy:		93.91 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.116182
  validation loss:		0.201923
  validation accuracy:		93.80 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.118210
  validation loss:		0.193406
  validation accuracy:		93.59 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.117096
  validation loss:		0.188320
  validation accuracy:		93.91 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.118073
  validation loss:		0.198040
  validation accuracy:		93.70 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.118245
  validation loss:		0.191860
  validation accuracy:		94.02 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.115773
  validation loss:		0.191504
  validation accuracy:		94.13 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.114247
  validation loss:		0.195413
  validation accuracy:		93.91 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.115649
  validation loss:		0.196457
  validation accuracy:		93.91 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.113326
  validation loss:		0.191623
  validation accuracy:		94.02 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.117366
  validation loss:		0.200670
  validation accuracy:		93.59 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.112651
  validation loss:		0.190457
  validation accuracy:		94.13 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.116422
  validation loss:		0.194015
  validation accuracy:		94.24 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.112184
  validation loss:		0.192933
  validation accuracy:		94.13 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.113348
  validation loss:		0.189390
  validation accuracy:		94.02 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.110274
  validation loss:		0.201201
  validation accuracy:		93.80 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.113168
  validation loss:		0.190867
  validation accuracy:		94.02 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.111269
  validation loss:		0.196203
  validation accuracy:		93.91 %
Epoch 272 of 2000 took 0.036s
  training loss:		0.111067
  validation loss:		0.192930
  validation accuracy:		94.02 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.112276
  validation loss:		0.191980
  validation accuracy:		93.91 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.111914
  validation loss:		0.193542
  validation accuracy:		94.02 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.109083
  validation loss:		0.194821
  validation accuracy:		93.80 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.108332
  validation loss:		0.183184
  validation accuracy:		94.24 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.108951
  validation loss:		0.194140
  validation accuracy:		94.02 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.110435
  validation loss:		0.196461
  validation accuracy:		93.91 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.108740
  validation loss:		0.185420
  validation accuracy:		94.24 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.107553
  validation loss:		0.198657
  validation accuracy:		93.80 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.109224
  validation loss:		0.192407
  validation accuracy:		94.13 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.110276
  validation loss:		0.193108
  validation accuracy:		94.13 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.108167
  validation loss:		0.195128
  validation accuracy:		93.91 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.108045
  validation loss:		0.190336
  validation accuracy:		93.91 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.106118
  validation loss:		0.187277
  validation accuracy:		94.35 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.106751
  validation loss:		0.196209
  validation accuracy:		94.24 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.105735
  validation loss:		0.191866
  validation accuracy:		94.24 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.106397
  validation loss:		0.187025
  validation accuracy:		94.46 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.108048
  validation loss:		0.196522
  validation accuracy:		94.02 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.108288
  validation loss:		0.196092
  validation accuracy:		94.02 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.106808
  validation loss:		0.191400
  validation accuracy:		94.24 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.105827
  validation loss:		0.199263
  validation accuracy:		93.80 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.105434
  validation loss:		0.186742
  validation accuracy:		94.13 %
Epoch 294 of 2000 took 0.036s
  training loss:		0.103925
  validation loss:		0.198682
  validation accuracy:		93.91 %
Epoch 295 of 2000 took 0.036s
  training loss:		0.103316
  validation loss:		0.192592
  validation accuracy:		94.24 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.104284
  validation loss:		0.190015
  validation accuracy:		94.46 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.104003
  validation loss:		0.187189
  validation accuracy:		94.46 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.101733
  validation loss:		0.201286
  validation accuracy:		93.70 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.105527
  validation loss:		0.194843
  validation accuracy:		94.02 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.100779
  validation loss:		0.187466
  validation accuracy:		94.24 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.099116
  validation loss:		0.192460
  validation accuracy:		94.02 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.103412
  validation loss:		0.194365
  validation accuracy:		94.02 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.101956
  validation loss:		0.185269
  validation accuracy:		94.57 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.102069
  validation loss:		0.193528
  validation accuracy:		94.13 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.101670
  validation loss:		0.193681
  validation accuracy:		94.24 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.101907
  validation loss:		0.203236
  validation accuracy:		93.59 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.101903
  validation loss:		0.190658
  validation accuracy:		94.46 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.098980
  validation loss:		0.191005
  validation accuracy:		94.35 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.098522
  validation loss:		0.190966
  validation accuracy:		94.24 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.099196
  validation loss:		0.194067
  validation accuracy:		93.80 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.099440
  validation loss:		0.190049
  validation accuracy:		94.35 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.095404
  validation loss:		0.196571
  validation accuracy:		94.24 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.100127
  validation loss:		0.192398
  validation accuracy:		94.35 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.096599
  validation loss:		0.193371
  validation accuracy:		94.02 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.098448
  validation loss:		0.192848
  validation accuracy:		94.24 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.098141
  validation loss:		0.193340
  validation accuracy:		94.13 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.099127
  validation loss:		0.192185
  validation accuracy:		94.35 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.093569
  validation loss:		0.192386
  validation accuracy:		94.24 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.093760
  validation loss:		0.189067
  validation accuracy:		94.46 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.096173
  validation loss:		0.196423
  validation accuracy:		94.13 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.094497
  validation loss:		0.209366
  validation accuracy:		93.70 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.098103
  validation loss:		0.190994
  validation accuracy:		94.13 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.094902
  validation loss:		0.188725
  validation accuracy:		94.46 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.095589
  validation loss:		0.198056
  validation accuracy:		94.02 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.096402
  validation loss:		0.197504
  validation accuracy:		94.02 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.095032
  validation loss:		0.192594
  validation accuracy:		94.13 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.095802
  validation loss:		0.189824
  validation accuracy:		94.57 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.093632
  validation loss:		0.200932
  validation accuracy:		94.02 %
Epoch 329 of 2000 took 0.036s
  training loss:		0.094677
  validation loss:		0.195204
  validation accuracy:		94.02 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.090587
  validation loss:		0.196782
  validation accuracy:		94.35 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.091499
  validation loss:		0.193223
  validation accuracy:		93.91 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.093732
  validation loss:		0.197120
  validation accuracy:		94.13 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.094419
  validation loss:		0.201044
  validation accuracy:		93.91 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.091448
  validation loss:		0.201076
  validation accuracy:		94.13 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.093313
  validation loss:		0.201718
  validation accuracy:		94.02 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.090821
  validation loss:		0.190969
  validation accuracy:		94.24 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.091847
  validation loss:		0.195317
  validation accuracy:		94.24 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.092708
  validation loss:		0.193574
  validation accuracy:		94.35 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.086425
  validation loss:		0.191106
  validation accuracy:		94.35 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.091526
  validation loss:		0.194583
  validation accuracy:		94.57 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.090496
  validation loss:		0.189465
  validation accuracy:		94.35 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.090505
  validation loss:		0.192394
  validation accuracy:		94.24 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.088150
  validation loss:		0.200904
  validation accuracy:		94.24 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.089805
  validation loss:		0.194675
  validation accuracy:		94.24 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.088036
  validation loss:		0.185948
  validation accuracy:		94.46 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.091174
  validation loss:		0.192948
  validation accuracy:		94.46 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.089424
  validation loss:		0.192951
  validation accuracy:		94.02 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.089024
  validation loss:		0.194454
  validation accuracy:		94.24 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.088054
  validation loss:		0.193345
  validation accuracy:		94.13 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.088480
  validation loss:		0.191837
  validation accuracy:		94.35 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.089089
  validation loss:		0.201108
  validation accuracy:		94.13 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.088794
  validation loss:		0.200240
  validation accuracy:		94.13 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.088104
  validation loss:		0.196009
  validation accuracy:		94.24 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.087318
  validation loss:		0.197849
  validation accuracy:		94.13 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.087209
  validation loss:		0.195602
  validation accuracy:		94.24 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.086575
  validation loss:		0.198775
  validation accuracy:		94.24 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.088552
  validation loss:		0.197841
  validation accuracy:		93.91 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.086461
  validation loss:		0.193694
  validation accuracy:		94.35 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.086722
  validation loss:		0.197847
  validation accuracy:		94.24 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.085632
  validation loss:		0.203237
  validation accuracy:		94.24 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.084448
  validation loss:		0.199518
  validation accuracy:		94.02 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.085394
  validation loss:		0.197084
  validation accuracy:		93.91 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.086084
  validation loss:		0.200140
  validation accuracy:		94.02 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.084433
  validation loss:		0.200126
  validation accuracy:		94.13 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.082008
  validation loss:		0.199269
  validation accuracy:		94.24 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.085575
  validation loss:		0.204344
  validation accuracy:		93.59 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.084874
  validation loss:		0.197626
  validation accuracy:		94.24 %
Epoch 368 of 2000 took 0.037s
  training loss:		0.083861
  validation loss:		0.197463
  validation accuracy:		94.24 %
Epoch 369 of 2000 took 0.036s
  training loss:		0.082991
  validation loss:		0.202728
  validation accuracy:		94.02 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.081886
  validation loss:		0.193899
  validation accuracy:		94.46 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.082277
  validation loss:		0.198694
  validation accuracy:		94.35 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.083592
  validation loss:		0.200192
  validation accuracy:		94.13 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.082352
  validation loss:		0.200111
  validation accuracy:		94.13 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.082125
  validation loss:		0.200549
  validation accuracy:		93.91 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.081518
  validation loss:		0.200400
  validation accuracy:		94.24 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.080743
  validation loss:		0.198519
  validation accuracy:		94.13 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.083367
  validation loss:		0.191889
  validation accuracy:		94.46 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.078985
  validation loss:		0.198652
  validation accuracy:		94.13 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.082253
  validation loss:		0.199563
  validation accuracy:		94.24 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.077904
  validation loss:		0.193169
  validation accuracy:		94.13 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.077857
  validation loss:		0.206216
  validation accuracy:		93.91 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.077873
  validation loss:		0.194726
  validation accuracy:		94.35 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.078042
  validation loss:		0.202881
  validation accuracy:		93.91 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.081870
  validation loss:		0.199981
  validation accuracy:		94.02 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.079388
  validation loss:		0.213416
  validation accuracy:		93.37 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.081613
  validation loss:		0.199993
  validation accuracy:		94.35 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.078851
  validation loss:		0.203701
  validation accuracy:		94.02 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.080555
  validation loss:		0.196246
  validation accuracy:		94.46 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.078755
  validation loss:		0.199787
  validation accuracy:		94.13 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.076836
  validation loss:		0.197391
  validation accuracy:		94.13 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.079463
  validation loss:		0.203232
  validation accuracy:		94.13 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.079596
  validation loss:		0.201759
  validation accuracy:		93.91 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.079402
  validation loss:		0.201858
  validation accuracy:		94.13 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.076289
  validation loss:		0.201078
  validation accuracy:		94.24 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.077911
  validation loss:		0.202902
  validation accuracy:		94.13 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.076827
  validation loss:		0.199431
  validation accuracy:		94.02 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.076286
  validation loss:		0.207002
  validation accuracy:		93.48 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.077889
  validation loss:		0.199356
  validation accuracy:		94.02 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.076217
  validation loss:		0.199549
  validation accuracy:		93.80 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.076192
  validation loss:		0.204315
  validation accuracy:		93.80 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.076342
  validation loss:		0.197278
  validation accuracy:		93.80 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.075643
  validation loss:		0.199731
  validation accuracy:		93.80 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.077547
  validation loss:		0.202817
  validation accuracy:		94.02 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.078309
  validation loss:		0.205090
  validation accuracy:		93.91 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.073603
  validation loss:		0.204663
  validation accuracy:		94.02 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.075253
  validation loss:		0.212042
  validation accuracy:		93.59 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.074465
  validation loss:		0.199581
  validation accuracy:		94.24 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.074371
  validation loss:		0.206855
  validation accuracy:		93.70 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.073490
  validation loss:		0.207028
  validation accuracy:		94.13 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.072652
  validation loss:		0.205047
  validation accuracy:		93.80 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.073879
  validation loss:		0.202204
  validation accuracy:		94.13 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.075431
  validation loss:		0.213468
  validation accuracy:		93.26 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.074149
  validation loss:		0.200634
  validation accuracy:		94.02 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.073148
  validation loss:		0.204074
  validation accuracy:		94.13 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.071926
  validation loss:		0.201043
  validation accuracy:		93.80 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.072071
  validation loss:		0.204622
  validation accuracy:		94.13 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.071257
  validation loss:		0.211051
  validation accuracy:		93.80 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.072923
  validation loss:		0.216452
  validation accuracy:		93.37 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.073424
  validation loss:		0.204660
  validation accuracy:		93.80 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.069595
  validation loss:		0.214162
  validation accuracy:		93.48 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.072655
  validation loss:		0.197460
  validation accuracy:		94.13 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.071885
  validation loss:		0.208318
  validation accuracy:		93.70 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.072325
  validation loss:		0.202910
  validation accuracy:		94.02 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.070179
  validation loss:		0.206963
  validation accuracy:		93.80 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.071067
  validation loss:		0.200249
  validation accuracy:		93.80 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.068841
  validation loss:		0.206295
  validation accuracy:		94.02 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.070958
  validation loss:		0.202145
  validation accuracy:		94.24 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.069423
  validation loss:		0.210926
  validation accuracy:		93.70 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.069291
  validation loss:		0.209761
  validation accuracy:		94.02 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.068829
  validation loss:		0.202553
  validation accuracy:		93.80 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.068867
  validation loss:		0.223315
  validation accuracy:		93.15 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.071352
  validation loss:		0.211708
  validation accuracy:		93.59 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.066857
  validation loss:		0.203442
  validation accuracy:		94.13 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.070355
  validation loss:		0.207558
  validation accuracy:		93.91 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.068479
  validation loss:		0.209986
  validation accuracy:		93.70 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.065936
  validation loss:		0.209113
  validation accuracy:		93.91 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.069278
  validation loss:		0.211585
  validation accuracy:		93.91 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.066666
  validation loss:		0.210066
  validation accuracy:		93.59 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.068138
  validation loss:		0.215288
  validation accuracy:		93.59 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.068860
  validation loss:		0.211126
  validation accuracy:		93.80 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.069849
  validation loss:		0.201812
  validation accuracy:		94.13 %
Epoch 442 of 2000 took 0.036s
  training loss:		0.065644
  validation loss:		0.212848
  validation accuracy:		93.70 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.068427
  validation loss:		0.206202
  validation accuracy:		93.91 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.067238
  validation loss:		0.208001
  validation accuracy:		94.13 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.064445
  validation loss:		0.210298
  validation accuracy:		93.91 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.067000
  validation loss:		0.201042
  validation accuracy:		94.24 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.064906
  validation loss:		0.208982
  validation accuracy:		93.70 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.068066
  validation loss:		0.219304
  validation accuracy:		93.59 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.066127
  validation loss:		0.197591
  validation accuracy:		94.24 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.067229
  validation loss:		0.216447
  validation accuracy:		93.48 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.066646
  validation loss:		0.206016
  validation accuracy:		94.13 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.067372
  validation loss:		0.210376
  validation accuracy:		93.70 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.066317
  validation loss:		0.214665
  validation accuracy:		94.02 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.062988
  validation loss:		0.215814
  validation accuracy:		93.80 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.065941
  validation loss:		0.215836
  validation accuracy:		93.91 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.064848
  validation loss:		0.205309
  validation accuracy:		94.13 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.063930
  validation loss:		0.206877
  validation accuracy:		94.02 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.063176
  validation loss:		0.217229
  validation accuracy:		93.91 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.066877
  validation loss:		0.208106
  validation accuracy:		94.13 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.065647
  validation loss:		0.218704
  validation accuracy:		93.59 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.066359
  validation loss:		0.209729
  validation accuracy:		94.13 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.062904
  validation loss:		0.218227
  validation accuracy:		93.59 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.064318
  validation loss:		0.213912
  validation accuracy:		94.13 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.063536
  validation loss:		0.207441
  validation accuracy:		94.02 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.063426
  validation loss:		0.215628
  validation accuracy:		93.70 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.061647
  validation loss:		0.210058
  validation accuracy:		94.13 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.064411
  validation loss:		0.211912
  validation accuracy:		93.80 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.063061
  validation loss:		0.220407
  validation accuracy:		93.48 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.063349
  validation loss:		0.224516
  validation accuracy:		93.70 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.061744
  validation loss:		0.227356
  validation accuracy:		93.48 %
Epoch 471 of 2000 took 0.036s
  training loss:		0.063848
  validation loss:		0.217111
  validation accuracy:		93.91 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.061850
  validation loss:		0.211414
  validation accuracy:		93.91 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.061694
  validation loss:		0.218690
  validation accuracy:		93.70 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.062687
  validation loss:		0.205578
  validation accuracy:		94.46 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.063275
  validation loss:		0.221176
  validation accuracy:		93.48 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.060820
  validation loss:		0.213591
  validation accuracy:		93.91 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.059463
  validation loss:		0.220374
  validation accuracy:		93.80 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.062562
  validation loss:		0.216163
  validation accuracy:		93.91 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.060141
  validation loss:		0.214765
  validation accuracy:		93.80 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.060946
  validation loss:		0.215599
  validation accuracy:		94.02 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.060672
  validation loss:		0.218941
  validation accuracy:		93.70 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.059125
  validation loss:		0.220244
  validation accuracy:		93.70 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.059899
  validation loss:		0.213707
  validation accuracy:		94.13 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.059199
  validation loss:		0.217621
  validation accuracy:		93.91 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.059847
  validation loss:		0.209964
  validation accuracy:		94.13 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.060374
  validation loss:		0.222834
  validation accuracy:		93.59 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.061801
  validation loss:		0.222036
  validation accuracy:		93.59 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.060067
  validation loss:		0.208095
  validation accuracy:		94.02 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.061087
  validation loss:		0.224477
  validation accuracy:		93.37 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.060796
  validation loss:		0.209673
  validation accuracy:		93.91 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.061019
  validation loss:		0.222253
  validation accuracy:		93.59 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.059631
  validation loss:		0.218411
  validation accuracy:		93.80 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.058965
  validation loss:		0.213970
  validation accuracy:		94.24 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.057523
  validation loss:		0.216471
  validation accuracy:		93.70 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.059583
  validation loss:		0.225507
  validation accuracy:		93.48 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.058200
  validation loss:		0.220231
  validation accuracy:		93.80 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.058780
  validation loss:		0.222758
  validation accuracy:		93.48 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.056125
  validation loss:		0.219514
  validation accuracy:		94.02 %
Epoch 499 of 2000 took 0.036s
  training loss:		0.058416
  validation loss:		0.217053
  validation accuracy:		93.70 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.058632
  validation loss:		0.212805
  validation accuracy:		94.24 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.056958
  validation loss:		0.219947
  validation accuracy:		93.70 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.057908
  validation loss:		0.227047
  validation accuracy:		93.70 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.057188
  validation loss:		0.221319
  validation accuracy:		93.80 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.057352
  validation loss:		0.225998
  validation accuracy:		93.80 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.057981
  validation loss:		0.219035
  validation accuracy:		93.91 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.057593
  validation loss:		0.216172
  validation accuracy:		94.02 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.057359
  validation loss:		0.222145
  validation accuracy:		93.80 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.057666
  validation loss:		0.226681
  validation accuracy:		93.48 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.059042
  validation loss:		0.219070
  validation accuracy:		94.02 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.056720
  validation loss:		0.219677
  validation accuracy:		94.02 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.056850
  validation loss:		0.218576
  validation accuracy:		94.02 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.056664
  validation loss:		0.223038
  validation accuracy:		93.70 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.055725
  validation loss:		0.217405
  validation accuracy:		94.02 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.057250
  validation loss:		0.215044
  validation accuracy:		93.91 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.054608
  validation loss:		0.233848
  validation accuracy:		93.80 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.057159
  validation loss:		0.219987
  validation accuracy:		93.70 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.055097
  validation loss:		0.223120
  validation accuracy:		93.59 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.054887
  validation loss:		0.225712
  validation accuracy:		93.91 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.053641
  validation loss:		0.221692
  validation accuracy:		94.02 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.054326
  validation loss:		0.222203
  validation accuracy:		94.13 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.055326
  validation loss:		0.223710
  validation accuracy:		93.59 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.054634
  validation loss:		0.221297
  validation accuracy:		94.13 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.053952
  validation loss:		0.219978
  validation accuracy:		93.91 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.055038
  validation loss:		0.223116
  validation accuracy:		93.70 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.054564
  validation loss:		0.213825
  validation accuracy:		94.13 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.053811
  validation loss:		0.228082
  validation accuracy:		93.59 %
Epoch 527 of 2000 took 0.036s
  training loss:		0.053310
  validation loss:		0.222127
  validation accuracy:		94.02 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.053914
  validation loss:		0.219689
  validation accuracy:		94.13 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.054529
  validation loss:		0.220863
  validation accuracy:		93.70 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.051183
  validation loss:		0.212865
  validation accuracy:		94.13 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.054237
  validation loss:		0.222845
  validation accuracy:		93.80 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.054171
  validation loss:		0.218399
  validation accuracy:		94.02 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.054123
  validation loss:		0.221303
  validation accuracy:		93.59 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.053259
  validation loss:		0.217321
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.052470
  validation loss:		0.225291
  validation accuracy:		93.80 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.053496
  validation loss:		0.227394
  validation accuracy:		93.91 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.053806
  validation loss:		0.240211
  validation accuracy:		93.26 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.052424
  validation loss:		0.234606
  validation accuracy:		93.48 %
Epoch 539 of 2000 took 0.036s
  training loss:		0.054331
  validation loss:		0.228881
  validation accuracy:		93.70 %
Epoch 540 of 2000 took 0.036s
  training loss:		0.053148
  validation loss:		0.227997
  validation accuracy:		93.59 %
Epoch 541 of 2000 took 0.036s
  training loss:		0.051522
  validation loss:		0.222492
  validation accuracy:		93.91 %
Epoch 542 of 2000 took 0.036s
  training loss:		0.052394
  validation loss:		0.234631
  validation accuracy:		93.48 %
Epoch 543 of 2000 took 0.036s
  training loss:		0.052609
  validation loss:		0.230448
  validation accuracy:		93.80 %
Epoch 544 of 2000 took 0.036s
  training loss:		0.052677
  validation loss:		0.232111
  validation accuracy:		93.70 %
Epoch 545 of 2000 took 0.036s
  training loss:		0.052203
  validation loss:		0.235024
  validation accuracy:		93.80 %
Epoch 546 of 2000 took 0.036s
  training loss:		0.052038
  validation loss:		0.223585
  validation accuracy:		93.91 %
Epoch 547 of 2000 took 0.036s
  training loss:		0.051059
  validation loss:		0.225011
  validation accuracy:		93.80 %
Epoch 548 of 2000 took 0.036s
  training loss:		0.052398
  validation loss:		0.228126
  validation accuracy:		93.80 %
Epoch 549 of 2000 took 0.036s
  training loss:		0.051981
  validation loss:		0.224659
  validation accuracy:		94.13 %
Epoch 550 of 2000 took 0.036s
  training loss:		0.052747
  validation loss:		0.232804
  validation accuracy:		93.70 %
Epoch 551 of 2000 took 0.036s
  training loss:		0.051123
  validation loss:		0.232011
  validation accuracy:		93.70 %
Epoch 552 of 2000 took 0.036s
  training loss:		0.049853
  validation loss:		0.223448
  validation accuracy:		93.91 %
Epoch 553 of 2000 took 0.036s
  training loss:		0.050671
  validation loss:		0.218557
  validation accuracy:		94.02 %
Epoch 554 of 2000 took 0.036s
  training loss:		0.050732
  validation loss:		0.224876
  validation accuracy:		94.02 %
Epoch 555 of 2000 took 0.036s
  training loss:		0.050705
  validation loss:		0.232543
  validation accuracy:		93.37 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.050841
  validation loss:		0.225310
  validation accuracy:		94.02 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.049940
  validation loss:		0.238406
  validation accuracy:		93.48 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.050096
  validation loss:		0.239056
  validation accuracy:		93.48 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.049766
  validation loss:		0.230221
  validation accuracy:		93.80 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.050310
  validation loss:		0.226409
  validation accuracy:		93.91 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.049872
  validation loss:		0.224583
  validation accuracy:		94.02 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.050019
  validation loss:		0.226409
  validation accuracy:		93.91 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.048844
  validation loss:		0.231778
  validation accuracy:		93.70 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.050791
  validation loss:		0.228397
  validation accuracy:		93.80 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.049469
  validation loss:		0.222186
  validation accuracy:		93.91 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.047902
  validation loss:		0.237921
  validation accuracy:		93.59 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.047537
  validation loss:		0.235744
  validation accuracy:		93.59 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.049908
  validation loss:		0.238221
  validation accuracy:		93.70 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.048535
  validation loss:		0.226811
  validation accuracy:		93.59 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.047487
  validation loss:		0.229296
  validation accuracy:		93.59 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.049331
  validation loss:		0.224101
  validation accuracy:		94.24 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.046822
  validation loss:		0.240244
  validation accuracy:		93.59 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.046648
  validation loss:		0.225417
  validation accuracy:		94.02 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.048212
  validation loss:		0.232584
  validation accuracy:		93.91 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.048826
  validation loss:		0.231815
  validation accuracy:		93.80 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.048529
  validation loss:		0.235797
  validation accuracy:		93.48 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.047776
  validation loss:		0.227390
  validation accuracy:		94.02 %
Epoch 578 of 2000 took 0.036s
  training loss:		0.048284
  validation loss:		0.226560
  validation accuracy:		93.91 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.047192
  validation loss:		0.234864
  validation accuracy:		93.59 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.047320
  validation loss:		0.230083
  validation accuracy:		93.80 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.047436
  validation loss:		0.234137
  validation accuracy:		93.80 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.045744
  validation loss:		0.232014
  validation accuracy:		93.59 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.047412
  validation loss:		0.242996
  validation accuracy:		93.59 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.046984
  validation loss:		0.239472
  validation accuracy:		93.70 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.046247
  validation loss:		0.235094
  validation accuracy:		93.70 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.046567
  validation loss:		0.232014
  validation accuracy:		93.70 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.046378
  validation loss:		0.233801
  validation accuracy:		94.02 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.045749
  validation loss:		0.229511
  validation accuracy:		94.02 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.045521
  validation loss:		0.228328
  validation accuracy:		93.80 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.046547
  validation loss:		0.247754
  validation accuracy:		93.59 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.044247
  validation loss:		0.236093
  validation accuracy:		93.91 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.045544
  validation loss:		0.252476
  validation accuracy:		93.15 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.045683
  validation loss:		0.226761
  validation accuracy:		93.91 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.045022
  validation loss:		0.238939
  validation accuracy:		93.59 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.046149
  validation loss:		0.235616
  validation accuracy:		93.91 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.043959
  validation loss:		0.231566
  validation accuracy:		93.91 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.045569
  validation loss:		0.236898
  validation accuracy:		93.70 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.045397
  validation loss:		0.245300
  validation accuracy:		93.48 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.043189
  validation loss:		0.241386
  validation accuracy:		93.70 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.044685
  validation loss:		0.234270
  validation accuracy:		93.70 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.043762
  validation loss:		0.235972
  validation accuracy:		93.80 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.045236
  validation loss:		0.234142
  validation accuracy:		93.91 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.044319
  validation loss:		0.233365
  validation accuracy:		94.24 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.045108
  validation loss:		0.233914
  validation accuracy:		93.91 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.043362
  validation loss:		0.243129
  validation accuracy:		93.59 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.042077
  validation loss:		0.246971
  validation accuracy:		93.37 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.043656
  validation loss:		0.246978
  validation accuracy:		93.59 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.041227
  validation loss:		0.242122
  validation accuracy:		93.80 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.044282
  validation loss:		0.236088
  validation accuracy:		93.80 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.041827
  validation loss:		0.248160
  validation accuracy:		93.59 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.043629
  validation loss:		0.242972
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.036s
  training loss:		0.041897
  validation loss:		0.234046
  validation accuracy:		93.91 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.042500
  validation loss:		0.240481
  validation accuracy:		93.91 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.042578
  validation loss:		0.247156
  validation accuracy:		93.26 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.042079
  validation loss:		0.236028
  validation accuracy:		93.80 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.041986
  validation loss:		0.244092
  validation accuracy:		93.80 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.042059
  validation loss:		0.238781
  validation accuracy:		93.70 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.042583
  validation loss:		0.247908
  validation accuracy:		93.37 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.040643
  validation loss:		0.240596
  validation accuracy:		93.70 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.042373
  validation loss:		0.242466
  validation accuracy:		93.70 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.042629
  validation loss:		0.240163
  validation accuracy:		93.59 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.041771
  validation loss:		0.246914
  validation accuracy:		93.48 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.040734
  validation loss:		0.245598
  validation accuracy:		93.91 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.041225
  validation loss:		0.245721
  validation accuracy:		93.59 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.041900
  validation loss:		0.233576
  validation accuracy:		94.13 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.041707
  validation loss:		0.250772
  validation accuracy:		93.37 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.041085
  validation loss:		0.244031
  validation accuracy:		93.70 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.042440
  validation loss:		0.251863
  validation accuracy:		93.59 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.042364
  validation loss:		0.246894
  validation accuracy:		93.80 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.040596
  validation loss:		0.236556
  validation accuracy:		93.91 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.040946
  validation loss:		0.243918
  validation accuracy:		93.91 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.041668
  validation loss:		0.249564
  validation accuracy:		93.80 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.039809
  validation loss:		0.245110
  validation accuracy:		94.02 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.041227
  validation loss:		0.244165
  validation accuracy:		93.59 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.040948
  validation loss:		0.249795
  validation accuracy:		93.91 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.040410
  validation loss:		0.246374
  validation accuracy:		93.80 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.041248
  validation loss:		0.238602
  validation accuracy:		93.91 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.041864
  validation loss:		0.246314
  validation accuracy:		94.02 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.039810
  validation loss:		0.239597
  validation accuracy:		93.59 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.041317
  validation loss:		0.245392
  validation accuracy:		93.37 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.040184
  validation loss:		0.244085
  validation accuracy:		93.80 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.039767
  validation loss:		0.247797
  validation accuracy:		93.80 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.039362
  validation loss:		0.239810
  validation accuracy:		93.80 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.039214
  validation loss:		0.245251
  validation accuracy:		93.70 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.039842
  validation loss:		0.249319
  validation accuracy:		94.02 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.037358
  validation loss:		0.247620
  validation accuracy:		93.80 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.040379
  validation loss:		0.253475
  validation accuracy:		93.59 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.039060
  validation loss:		0.243723
  validation accuracy:		94.02 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.039190
  validation loss:		0.255608
  validation accuracy:		93.59 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.039285
  validation loss:		0.252436
  validation accuracy:		93.80 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.037474
  validation loss:		0.232468
  validation accuracy:		93.80 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.039192
  validation loss:		0.244751
  validation accuracy:		93.80 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.039137
  validation loss:		0.264612
  validation accuracy:		93.37 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.038763
  validation loss:		0.245401
  validation accuracy:		93.80 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.038201
  validation loss:		0.248563
  validation accuracy:		93.70 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.038146
  validation loss:		0.252196
  validation accuracy:		93.91 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.038257
  validation loss:		0.254700
  validation accuracy:		93.37 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.038732
  validation loss:		0.252067
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.038788
  validation loss:		0.250834
  validation accuracy:		93.70 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.037310
  validation loss:		0.261461
  validation accuracy:		93.59 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.038529
  validation loss:		0.246833
  validation accuracy:		93.91 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.038501
  validation loss:		0.251513
  validation accuracy:		93.59 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.037114
  validation loss:		0.255861
  validation accuracy:		93.70 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.038095
  validation loss:		0.267078
  validation accuracy:		93.26 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.038340
  validation loss:		0.256406
  validation accuracy:		93.80 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.037970
  validation loss:		0.249526
  validation accuracy:		93.59 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.037055
  validation loss:		0.242818
  validation accuracy:		93.80 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.036762
  validation loss:		0.254671
  validation accuracy:		93.70 %
Epoch 669 of 2000 took 0.036s
  training loss:		0.037628
  validation loss:		0.249461
  validation accuracy:		93.91 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.035833
  validation loss:		0.250409
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.037792
  validation loss:		0.248229
  validation accuracy:		93.70 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.037495
  validation loss:		0.252011
  validation accuracy:		93.80 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.036176
  validation loss:		0.250819
  validation accuracy:		93.70 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.037071
  validation loss:		0.250849
  validation accuracy:		93.80 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.035274
  validation loss:		0.255554
  validation accuracy:		93.59 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.036579
  validation loss:		0.257233
  validation accuracy:		93.70 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.036202
  validation loss:		0.257297
  validation accuracy:		93.37 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.035780
  validation loss:		0.258525
  validation accuracy:		93.59 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.036424
  validation loss:		0.257751
  validation accuracy:		93.26 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.036918
  validation loss:		0.253677
  validation accuracy:		93.70 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.034873
  validation loss:		0.249288
  validation accuracy:		94.02 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.035508
  validation loss:		0.253517
  validation accuracy:		94.02 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.036549
  validation loss:		0.259130
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.036465
  validation loss:		0.260106
  validation accuracy:		93.37 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.035301
  validation loss:		0.256999
  validation accuracy:		93.48 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.036652
  validation loss:		0.258209
  validation accuracy:		93.48 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.035580
  validation loss:		0.251742
  validation accuracy:		93.80 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.034970
  validation loss:		0.263758
  validation accuracy:		93.26 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.034406
  validation loss:		0.252995
  validation accuracy:		93.91 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.035957
  validation loss:		0.261293
  validation accuracy:		93.59 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.033760
  validation loss:		0.259105
  validation accuracy:		93.59 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.034300
  validation loss:		0.261623
  validation accuracy:		93.59 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.035322
  validation loss:		0.259239
  validation accuracy:		93.59 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.035539
  validation loss:		0.253711
  validation accuracy:		93.70 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.036011
  validation loss:		0.256405
  validation accuracy:		93.80 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.034594
  validation loss:		0.264566
  validation accuracy:		93.70 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.034937
  validation loss:		0.261224
  validation accuracy:		93.70 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.034022
  validation loss:		0.266292
  validation accuracy:		93.48 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.034663
  validation loss:		0.260048
  validation accuracy:		94.02 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.034617
  validation loss:		0.258777
  validation accuracy:		93.59 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.032668
  validation loss:		0.257844
  validation accuracy:		94.02 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.033286
  validation loss:		0.259133
  validation accuracy:		93.91 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.033760
  validation loss:		0.256860
  validation accuracy:		94.02 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.033890
  validation loss:		0.259593
  validation accuracy:		93.91 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.034338
  validation loss:		0.258604
  validation accuracy:		93.70 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.033279
  validation loss:		0.268509
  validation accuracy:		93.59 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.033587
  validation loss:		0.254957
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.034134
  validation loss:		0.258353
  validation accuracy:		93.80 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.031563
  validation loss:		0.266044
  validation accuracy:		93.70 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.033135
  validation loss:		0.259962
  validation accuracy:		93.59 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.033904
  validation loss:		0.269977
  validation accuracy:		93.91 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.033635
  validation loss:		0.265393
  validation accuracy:		93.48 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.032474
  validation loss:		0.266693
  validation accuracy:		93.59 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.032866
  validation loss:		0.265187
  validation accuracy:		93.59 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.032693
  validation loss:		0.265848
  validation accuracy:		93.48 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.033517
  validation loss:		0.267728
  validation accuracy:		93.48 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.032946
  validation loss:		0.267231
  validation accuracy:		93.59 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.032227
  validation loss:		0.257604
  validation accuracy:		94.02 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.032405
  validation loss:		0.260579
  validation accuracy:		93.80 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.031748
  validation loss:		0.263306
  validation accuracy:		93.59 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.033635
  validation loss:		0.258701
  validation accuracy:		93.91 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.032368
  validation loss:		0.263002
  validation accuracy:		93.59 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.031546
  validation loss:		0.258859
  validation accuracy:		93.91 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.031936
  validation loss:		0.266149
  validation accuracy:		93.48 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.032406
  validation loss:		0.268328
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.036s
  training loss:		0.031320
  validation loss:		0.267273
  validation accuracy:		93.80 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.031594
  validation loss:		0.262195
  validation accuracy:		93.80 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.032036
  validation loss:		0.267484
  validation accuracy:		93.80 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.033408
  validation loss:		0.262602
  validation accuracy:		93.70 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.030679
  validation loss:		0.262596
  validation accuracy:		93.80 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.028063
  validation loss:		0.268241
  validation accuracy:		93.59 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.031264
  validation loss:		0.268308
  validation accuracy:		93.70 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.031423
  validation loss:		0.270445
  validation accuracy:		93.37 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.030954
  validation loss:		0.267202
  validation accuracy:		93.80 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.031079
  validation loss:		0.260754
  validation accuracy:		93.48 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.029901
  validation loss:		0.258942
  validation accuracy:		93.91 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.031389
  validation loss:		0.264087
  validation accuracy:		93.70 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.031202
  validation loss:		0.270925
  validation accuracy:		93.59 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.031436
  validation loss:		0.272958
  validation accuracy:		93.37 %
Epoch 740 of 2000 took 0.037s
  training loss:		0.031936
  validation loss:		0.268824
  validation accuracy:		93.80 %
Epoch 741 of 2000 took 0.036s
  training loss:		0.030882
  validation loss:		0.262570
  validation accuracy:		93.37 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.030664
  validation loss:		0.267816
  validation accuracy:		93.91 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.029844
  validation loss:		0.272262
  validation accuracy:		93.48 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.029967
  validation loss:		0.274887
  validation accuracy:		93.48 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.030159
  validation loss:		0.274355
  validation accuracy:		93.70 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.030349
  validation loss:		0.272590
  validation accuracy:		93.59 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.030447
  validation loss:		0.270180
  validation accuracy:		93.80 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.028550
  validation loss:		0.271416
  validation accuracy:		93.48 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.030407
  validation loss:		0.271118
  validation accuracy:		93.59 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.029104
  validation loss:		0.279486
  validation accuracy:		93.37 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.029190
  validation loss:		0.276288
  validation accuracy:		93.48 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.029315
  validation loss:		0.277673
  validation accuracy:		93.48 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.029707
  validation loss:		0.271291
  validation accuracy:		93.48 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.028915
  validation loss:		0.274119
  validation accuracy:		93.59 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.028234
  validation loss:		0.273360
  validation accuracy:		93.70 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.028190
  validation loss:		0.275404
  validation accuracy:		93.15 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.029491
  validation loss:		0.271863
  validation accuracy:		93.91 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.029938
  validation loss:		0.273089
  validation accuracy:		93.80 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.029468
  validation loss:		0.276440
  validation accuracy:		93.70 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.029143
  validation loss:		0.274659
  validation accuracy:		93.48 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.028585
  validation loss:		0.271396
  validation accuracy:		93.70 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.029163
  validation loss:		0.273287
  validation accuracy:		93.70 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.029988
  validation loss:		0.279085
  validation accuracy:		93.48 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.028090
  validation loss:		0.283783
  validation accuracy:		93.37 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.028188
  validation loss:		0.264992
  validation accuracy:		93.91 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.029510
  validation loss:		0.278734
  validation accuracy:		93.37 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.028222
  validation loss:		0.271605
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.028760
  validation loss:		0.270160
  validation accuracy:		93.48 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.028522
  validation loss:		0.275171
  validation accuracy:		93.37 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.028013
  validation loss:		0.282315
  validation accuracy:		93.91 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.027689
  validation loss:		0.271209
  validation accuracy:		93.80 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.027242
  validation loss:		0.269825
  validation accuracy:		93.80 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.027658
  validation loss:		0.273055
  validation accuracy:		93.80 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.028309
  validation loss:		0.268481
  validation accuracy:		93.91 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.028195
  validation loss:		0.270970
  validation accuracy:		93.70 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.028239
  validation loss:		0.270619
  validation accuracy:		93.37 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.027121
  validation loss:		0.283582
  validation accuracy:		93.80 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.027674
  validation loss:		0.270354
  validation accuracy:		93.70 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.028115
  validation loss:		0.276746
  validation accuracy:		93.48 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.027035
  validation loss:		0.279610
  validation accuracy:		93.80 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.027403
  validation loss:		0.282904
  validation accuracy:		93.70 %
Epoch 782 of 2000 took 0.036s
  training loss:		0.026273
  validation loss:		0.279347
  validation accuracy:		93.91 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.027999
  validation loss:		0.278458
  validation accuracy:		93.48 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.027379
  validation loss:		0.274906
  validation accuracy:		94.02 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.027660
  validation loss:		0.274589
  validation accuracy:		93.37 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.027067
  validation loss:		0.276330
  validation accuracy:		93.59 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.027635
  validation loss:		0.279850
  validation accuracy:		93.70 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.026531
  validation loss:		0.285228
  validation accuracy:		93.37 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.026172
  validation loss:		0.274769
  validation accuracy:		93.80 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.027176
  validation loss:		0.278196
  validation accuracy:		93.70 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.027284
  validation loss:		0.277075
  validation accuracy:		93.59 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.027196
  validation loss:		0.281803
  validation accuracy:		93.48 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.027338
  validation loss:		0.273620
  validation accuracy:		93.80 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.025848
  validation loss:		0.287839
  validation accuracy:		93.04 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.027211
  validation loss:		0.279731
  validation accuracy:		93.59 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.026987
  validation loss:		0.275247
  validation accuracy:		93.59 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.026112
  validation loss:		0.282236
  validation accuracy:		93.91 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.026659
  validation loss:		0.280646
  validation accuracy:		93.37 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.027001
  validation loss:		0.279580
  validation accuracy:		93.48 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.025406
  validation loss:		0.284995
  validation accuracy:		93.37 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.026068
  validation loss:		0.281058
  validation accuracy:		93.59 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.026218
  validation loss:		0.279055
  validation accuracy:		93.91 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.025878
  validation loss:		0.278542
  validation accuracy:		93.37 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.025801
  validation loss:		0.281773
  validation accuracy:		93.91 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.025569
  validation loss:		0.289221
  validation accuracy:		93.15 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.024315
  validation loss:		0.290165
  validation accuracy:		93.37 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.025795
  validation loss:		0.285615
  validation accuracy:		93.48 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.026199
  validation loss:		0.281165
  validation accuracy:		93.59 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.025404
  validation loss:		0.284876
  validation accuracy:		93.48 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.025686
  validation loss:		0.285094
  validation accuracy:		93.48 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.025590
  validation loss:		0.280982
  validation accuracy:		93.70 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.026362
  validation loss:		0.284547
  validation accuracy:		93.70 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.024618
  validation loss:		0.289646
  validation accuracy:		93.15 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.025009
  validation loss:		0.280750
  validation accuracy:		93.59 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.025512
  validation loss:		0.282107
  validation accuracy:		93.70 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.025284
  validation loss:		0.288600
  validation accuracy:		93.37 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.025358
  validation loss:		0.278512
  validation accuracy:		93.59 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.025008
  validation loss:		0.294161
  validation accuracy:		92.93 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.025483
  validation loss:		0.290502
  validation accuracy:		93.37 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.024590
  validation loss:		0.287386
  validation accuracy:		93.70 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.024788
  validation loss:		0.277219
  validation accuracy:		93.37 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.025154
  validation loss:		0.285258
  validation accuracy:		93.37 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.024432
  validation loss:		0.277377
  validation accuracy:		93.80 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.024779
  validation loss:		0.284419
  validation accuracy:		93.37 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.024599
  validation loss:		0.293528
  validation accuracy:		93.15 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.024901
  validation loss:		0.284694
  validation accuracy:		93.59 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.024367
  validation loss:		0.291386
  validation accuracy:		93.15 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.024894
  validation loss:		0.300693
  validation accuracy:		93.37 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.023675
  validation loss:		0.287886
  validation accuracy:		93.37 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.023403
  validation loss:		0.291605
  validation accuracy:		93.26 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.023593
  validation loss:		0.281091
  validation accuracy:		93.70 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.023545
  validation loss:		0.290650
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.024115
  validation loss:		0.288241
  validation accuracy:		93.48 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.023490
  validation loss:		0.288209
  validation accuracy:		93.15 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.023843
  validation loss:		0.294294
  validation accuracy:		93.59 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.024079
  validation loss:		0.300575
  validation accuracy:		93.04 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.023879
  validation loss:		0.285333
  validation accuracy:		93.48 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.023745
  validation loss:		0.290569
  validation accuracy:		93.37 %
Epoch 839 of 2000 took 0.036s
  training loss:		0.023339
  validation loss:		0.284862
  validation accuracy:		93.70 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.024086
  validation loss:		0.291194
  validation accuracy:		93.37 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.023805
  validation loss:		0.294129
  validation accuracy:		93.48 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.023446
  validation loss:		0.294434
  validation accuracy:		93.37 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.023230
  validation loss:		0.290970
  validation accuracy:		93.59 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.023462
  validation loss:		0.293967
  validation accuracy:		93.37 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.023461
  validation loss:		0.296616
  validation accuracy:		93.59 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.022873
  validation loss:		0.299123
  validation accuracy:		93.26 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.023625
  validation loss:		0.289119
  validation accuracy:		93.37 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.022187
  validation loss:		0.295626
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.023201
  validation loss:		0.299404
  validation accuracy:		93.26 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.022524
  validation loss:		0.298767
  validation accuracy:		93.26 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.022732
  validation loss:		0.288969
  validation accuracy:		93.26 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.022763
  validation loss:		0.296829
  validation accuracy:		93.26 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.021888
  validation loss:		0.301607
  validation accuracy:		93.04 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.022725
  validation loss:		0.288897
  validation accuracy:		93.59 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.022967
  validation loss:		0.301571
  validation accuracy:		93.26 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.022665
  validation loss:		0.292010
  validation accuracy:		93.48 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.022807
  validation loss:		0.292851
  validation accuracy:		93.37 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.021575
  validation loss:		0.293645
  validation accuracy:		93.48 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.022521
  validation loss:		0.298886
  validation accuracy:		93.37 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.022332
  validation loss:		0.305894
  validation accuracy:		92.83 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.022678
  validation loss:		0.302865
  validation accuracy:		93.26 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.021669
  validation loss:		0.292495
  validation accuracy:		93.59 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.022335
  validation loss:		0.298220
  validation accuracy:		93.26 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.021579
  validation loss:		0.290072
  validation accuracy:		93.48 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.022146
  validation loss:		0.298750
  validation accuracy:		93.26 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.022392
  validation loss:		0.291887
  validation accuracy:		93.48 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.022646
  validation loss:		0.296655
  validation accuracy:		93.26 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.021928
  validation loss:		0.301330
  validation accuracy:		93.59 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.022172
  validation loss:		0.295762
  validation accuracy:		93.59 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.021240
  validation loss:		0.302079
  validation accuracy:		93.48 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.021640
  validation loss:		0.295761
  validation accuracy:		93.48 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.022741
  validation loss:		0.293434
  validation accuracy:		93.59 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.021975
  validation loss:		0.293620
  validation accuracy:		93.48 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.021722
  validation loss:		0.301494
  validation accuracy:		93.37 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.021208
  validation loss:		0.297527
  validation accuracy:		93.48 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.021432
  validation loss:		0.299751
  validation accuracy:		93.26 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.022244
  validation loss:		0.301523
  validation accuracy:		93.48 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.022201
  validation loss:		0.302882
  validation accuracy:		93.26 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.021670
  validation loss:		0.299987
  validation accuracy:		93.59 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.021225
  validation loss:		0.300326
  validation accuracy:		93.48 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.021260
  validation loss:		0.290793
  validation accuracy:		93.59 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.020918
  validation loss:		0.300280
  validation accuracy:		93.37 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.020848
  validation loss:		0.296224
  validation accuracy:		93.37 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.021373
  validation loss:		0.304818
  validation accuracy:		93.48 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.021165
  validation loss:		0.292366
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021776
  validation loss:		0.304786
  validation accuracy:		93.48 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.021408
  validation loss:		0.298512
  validation accuracy:		93.59 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.020728
  validation loss:		0.300981
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.020665
  validation loss:		0.299841
  validation accuracy:		93.59 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.020353
  validation loss:		0.301228
  validation accuracy:		93.37 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.020126
  validation loss:		0.306904
  validation accuracy:		93.59 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.020471
  validation loss:		0.305770
  validation accuracy:		93.15 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.019915
  validation loss:		0.297362
  validation accuracy:		93.48 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.019773
  validation loss:		0.301757
  validation accuracy:		93.26 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.019960
  validation loss:		0.304540
  validation accuracy:		93.26 %
Epoch 896 of 2000 took 0.036s
  training loss:		0.021091
  validation loss:		0.306184
  validation accuracy:		93.59 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.020324
  validation loss:		0.301926
  validation accuracy:		93.48 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.020437
  validation loss:		0.303178
  validation accuracy:		93.59 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.019365
  validation loss:		0.297513
  validation accuracy:		93.26 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.020395
  validation loss:		0.305504
  validation accuracy:		93.37 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.020403
  validation loss:		0.308012
  validation accuracy:		93.26 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.020660
  validation loss:		0.310056
  validation accuracy:		93.37 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.019115
  validation loss:		0.303318
  validation accuracy:		93.48 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.020298
  validation loss:		0.299438
  validation accuracy:		93.48 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.020241
  validation loss:		0.309237
  validation accuracy:		93.48 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.019712
  validation loss:		0.306949
  validation accuracy:		93.26 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.020024
  validation loss:		0.303919
  validation accuracy:		93.15 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.019776
  validation loss:		0.307294
  validation accuracy:		93.59 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.020259
  validation loss:		0.307592
  validation accuracy:		93.48 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.019279
  validation loss:		0.306959
  validation accuracy:		93.37 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.020464
  validation loss:		0.306857
  validation accuracy:		93.37 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.019759
  validation loss:		0.315714
  validation accuracy:		93.15 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.018643
  validation loss:		0.306535
  validation accuracy:		93.37 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.018847
  validation loss:		0.308195
  validation accuracy:		93.48 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.019217
  validation loss:		0.302967
  validation accuracy:		93.37 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.019669
  validation loss:		0.302230
  validation accuracy:		93.37 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.018882
  validation loss:		0.312111
  validation accuracy:		92.93 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.019737
  validation loss:		0.302408
  validation accuracy:		93.48 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.019801
  validation loss:		0.305029
  validation accuracy:		93.37 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.018934
  validation loss:		0.314819
  validation accuracy:		93.15 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.018215
  validation loss:		0.303166
  validation accuracy:		93.26 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.020120
  validation loss:		0.306597
  validation accuracy:		93.48 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.019427
  validation loss:		0.312255
  validation accuracy:		93.26 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.019443
  validation loss:		0.310889
  validation accuracy:		93.37 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.019166
  validation loss:		0.310560
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.019520
  validation loss:		0.307689
  validation accuracy:		93.48 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.018592
  validation loss:		0.310760
  validation accuracy:		93.26 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.019683
  validation loss:		0.309038
  validation accuracy:		93.48 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.018944
  validation loss:		0.312510
  validation accuracy:		93.37 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.018366
  validation loss:		0.305518
  validation accuracy:		93.59 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.019174
  validation loss:		0.317189
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.018949
  validation loss:		0.311578
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.018213
  validation loss:		0.315953
  validation accuracy:		93.04 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.019002
  validation loss:		0.313485
  validation accuracy:		93.59 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.018423
  validation loss:		0.313431
  validation accuracy:		93.48 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.018583
  validation loss:		0.311392
  validation accuracy:		93.26 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.018603
  validation loss:		0.311688
  validation accuracy:		93.48 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.018470
  validation loss:		0.314214
  validation accuracy:		93.26 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.017769
  validation loss:		0.321459
  validation accuracy:		92.93 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.018336
  validation loss:		0.318864
  validation accuracy:		93.15 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.018779
  validation loss:		0.316935
  validation accuracy:		93.15 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.018502
  validation loss:		0.322009
  validation accuracy:		93.15 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.018503
  validation loss:		0.311543
  validation accuracy:		93.48 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.018413
  validation loss:		0.309343
  validation accuracy:		93.26 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.018347
  validation loss:		0.323297
  validation accuracy:		93.04 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.018209
  validation loss:		0.317398
  validation accuracy:		93.37 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.018041
  validation loss:		0.309950
  validation accuracy:		93.37 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.018467
  validation loss:		0.315979
  validation accuracy:		93.37 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.017469
  validation loss:		0.311062
  validation accuracy:		93.48 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.017658
  validation loss:		0.307661
  validation accuracy:		93.70 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.017995
  validation loss:		0.326375
  validation accuracy:		93.04 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.018726
  validation loss:		0.320051
  validation accuracy:		92.83 %
Epoch 953 of 2000 took 0.036s
  training loss:		0.017939
  validation loss:		0.305517
  validation accuracy:		93.48 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.018623
  validation loss:		0.316015
  validation accuracy:		93.37 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.017613
  validation loss:		0.315055
  validation accuracy:		93.37 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.017051
  validation loss:		0.330370
  validation accuracy:		92.93 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.018030
  validation loss:		0.317640
  validation accuracy:		93.48 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.016909
  validation loss:		0.321706
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.017641
  validation loss:		0.322378
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.017977
  validation loss:		0.321993
  validation accuracy:		93.15 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.017114
  validation loss:		0.328901
  validation accuracy:		93.26 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.017904
  validation loss:		0.324877
  validation accuracy:		93.04 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.017499
  validation loss:		0.313396
  validation accuracy:		93.37 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.016192
  validation loss:		0.314501
  validation accuracy:		93.48 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.017388
  validation loss:		0.319331
  validation accuracy:		93.37 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.017129
  validation loss:		0.319322
  validation accuracy:		93.26 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.017136
  validation loss:		0.318553
  validation accuracy:		93.26 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.017400
  validation loss:		0.322465
  validation accuracy:		93.15 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.016712
  validation loss:		0.317619
  validation accuracy:		93.37 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.017756
  validation loss:		0.316318
  validation accuracy:		93.37 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.016707
  validation loss:		0.312678
  validation accuracy:		93.48 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.017475
  validation loss:		0.315982
  validation accuracy:		93.37 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.016756
  validation loss:		0.325879
  validation accuracy:		93.04 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.017308
  validation loss:		0.321257
  validation accuracy:		93.48 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.016053
  validation loss:		0.324581
  validation accuracy:		93.37 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.016709
  validation loss:		0.314830
  validation accuracy:		93.48 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.016795
  validation loss:		0.320481
  validation accuracy:		93.26 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.016890
  validation loss:		0.321380
  validation accuracy:		93.26 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.017204
  validation loss:		0.322934
  validation accuracy:		93.04 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.015989
  validation loss:		0.320516
  validation accuracy:		93.37 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.016681
  validation loss:		0.316530
  validation accuracy:		93.37 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.016477
  validation loss:		0.320849
  validation accuracy:		93.48 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.016896
  validation loss:		0.320888
  validation accuracy:		93.15 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.016899
  validation loss:		0.320578
  validation accuracy:		93.26 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.015743
  validation loss:		0.326117
  validation accuracy:		93.37 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.016535
  validation loss:		0.329757
  validation accuracy:		93.04 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.016820
  validation loss:		0.318526
  validation accuracy:		93.37 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.017068
  validation loss:		0.323683
  validation accuracy:		92.93 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.016213
  validation loss:		0.324387
  validation accuracy:		93.15 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.016366
  validation loss:		0.322571
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.016711
  validation loss:		0.323010
  validation accuracy:		93.26 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016471
  validation loss:		0.327398
  validation accuracy:		93.37 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.015918
  validation loss:		0.331464
  validation accuracy:		93.15 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016291
  validation loss:		0.324337
  validation accuracy:		93.26 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.015951
  validation loss:		0.325037
  validation accuracy:		93.37 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.016628
  validation loss:		0.320109
  validation accuracy:		93.15 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.016488
  validation loss:		0.324895
  validation accuracy:		93.26 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.015841
  validation loss:		0.340235
  validation accuracy:		92.83 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016026
  validation loss:		0.334435
  validation accuracy:		92.83 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.015931
  validation loss:		0.330669
  validation accuracy:		93.26 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.015770
  validation loss:		0.330634
  validation accuracy:		93.04 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.016413
  validation loss:		0.325305
  validation accuracy:		93.48 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.014998
  validation loss:		0.328717
  validation accuracy:		93.04 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.015511
  validation loss:		0.326155
  validation accuracy:		93.37 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.015901
  validation loss:		0.325335
  validation accuracy:		93.37 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.015009
  validation loss:		0.331879
  validation accuracy:		93.26 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.015921
  validation loss:		0.325783
  validation accuracy:		93.26 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.015990
  validation loss:		0.335292
  validation accuracy:		92.93 %
Epoch 1009 of 2000 took 0.036s
  training loss:		0.015789
  validation loss:		0.340659
  validation accuracy:		92.72 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.016042
  validation loss:		0.324215
  validation accuracy:		93.26 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.015037
  validation loss:		0.326570
  validation accuracy:		93.15 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.016130
  validation loss:		0.326921
  validation accuracy:		93.59 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.015321
  validation loss:		0.334223
  validation accuracy:		93.15 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.015228
  validation loss:		0.327678
  validation accuracy:		93.37 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.015242
  validation loss:		0.334991
  validation accuracy:		93.26 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.015652
  validation loss:		0.328415
  validation accuracy:		93.15 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.015976
  validation loss:		0.332758
  validation accuracy:		93.15 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.014856
  validation loss:		0.324642
  validation accuracy:		93.37 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.015081
  validation loss:		0.333250
  validation accuracy:		93.26 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.015441
  validation loss:		0.337903
  validation accuracy:		92.93 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.014802
  validation loss:		0.336586
  validation accuracy:		93.26 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.015045
  validation loss:		0.328752
  validation accuracy:		93.37 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.014961
  validation loss:		0.330914
  validation accuracy:		93.26 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.015760
  validation loss:		0.334018
  validation accuracy:		93.04 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.014610
  validation loss:		0.338278
  validation accuracy:		92.83 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.015338
  validation loss:		0.337620
  validation accuracy:		93.15 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.015078
  validation loss:		0.329331
  validation accuracy:		93.37 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.015002
  validation loss:		0.334834
  validation accuracy:		93.15 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.015091
  validation loss:		0.333543
  validation accuracy:		93.04 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.014392
  validation loss:		0.334846
  validation accuracy:		93.26 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.014691
  validation loss:		0.333419
  validation accuracy:		93.15 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.014251
  validation loss:		0.345589
  validation accuracy:		92.72 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.015163
  validation loss:		0.328911
  validation accuracy:		93.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.014579
  validation loss:		0.327290
  validation accuracy:		93.48 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.015160
  validation loss:		0.333436
  validation accuracy:		93.26 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.015016
  validation loss:		0.327981
  validation accuracy:		93.26 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.014072
  validation loss:		0.330717
  validation accuracy:		93.37 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.014332
  validation loss:		0.334209
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.014415
  validation loss:		0.336060
  validation accuracy:		93.15 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.014101
  validation loss:		0.339978
  validation accuracy:		93.26 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.014630
  validation loss:		0.338361
  validation accuracy:		93.15 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.014010
  validation loss:		0.340297
  validation accuracy:		92.93 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.014856
  validation loss:		0.331115
  validation accuracy:		93.37 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.014184
  validation loss:		0.335139
  validation accuracy:		93.15 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.014341
  validation loss:		0.340925
  validation accuracy:		93.26 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.014649
  validation loss:		0.336559
  validation accuracy:		93.04 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.014112
  validation loss:		0.348001
  validation accuracy:		92.61 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.013872
  validation loss:		0.333249
  validation accuracy:		93.37 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.013858
  validation loss:		0.335458
  validation accuracy:		93.48 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.014460
  validation loss:		0.338956
  validation accuracy:		93.15 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.014422
  validation loss:		0.332114
  validation accuracy:		93.26 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.014067
  validation loss:		0.342501
  validation accuracy:		93.04 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.013841
  validation loss:		0.334827
  validation accuracy:		93.37 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.014161
  validation loss:		0.347133
  validation accuracy:		92.72 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.014440
  validation loss:		0.344716
  validation accuracy:		92.93 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.014141
  validation loss:		0.346479
  validation accuracy:		92.83 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.013861
  validation loss:		0.345319
  validation accuracy:		92.93 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.013957
  validation loss:		0.341645
  validation accuracy:		93.04 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.014251
  validation loss:		0.335491
  validation accuracy:		93.15 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.013921
  validation loss:		0.339267
  validation accuracy:		93.15 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.013878
  validation loss:		0.343704
  validation accuracy:		93.04 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.013387
  validation loss:		0.338847
  validation accuracy:		93.15 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.014014
  validation loss:		0.344068
  validation accuracy:		93.04 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.013452
  validation loss:		0.344261
  validation accuracy:		93.15 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.013469
  validation loss:		0.339306
  validation accuracy:		93.15 %
Epoch 1066 of 2000 took 0.036s
  training loss:		0.013316
  validation loss:		0.346416
  validation accuracy:		92.93 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.013759
  validation loss:		0.338219
  validation accuracy:		93.26 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.013489
  validation loss:		0.342464
  validation accuracy:		93.15 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.013219
  validation loss:		0.343077
  validation accuracy:		93.26 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.013483
  validation loss:		0.338201
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013112
  validation loss:		0.334132
  validation accuracy:		93.26 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.012743
  validation loss:		0.340854
  validation accuracy:		93.48 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.013562
  validation loss:		0.346880
  validation accuracy:		93.04 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.013447
  validation loss:		0.340014
  validation accuracy:		93.26 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.013520
  validation loss:		0.346662
  validation accuracy:		92.83 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.012788
  validation loss:		0.346498
  validation accuracy:		93.04 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.014033
  validation loss:		0.338896
  validation accuracy:		93.26 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.013771
  validation loss:		0.344510
  validation accuracy:		93.04 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.013359
  validation loss:		0.352137
  validation accuracy:		92.72 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013181
  validation loss:		0.337338
  validation accuracy:		93.37 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.012873
  validation loss:		0.348127
  validation accuracy:		93.04 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.013282
  validation loss:		0.345072
  validation accuracy:		93.15 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.012710
  validation loss:		0.345369
  validation accuracy:		93.15 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.012929
  validation loss:		0.349819
  validation accuracy:		92.93 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.012938
  validation loss:		0.347654
  validation accuracy:		93.04 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.013094
  validation loss:		0.347816
  validation accuracy:		93.15 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.013157
  validation loss:		0.353347
  validation accuracy:		92.83 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.013157
  validation loss:		0.346678
  validation accuracy:		92.93 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.013169
  validation loss:		0.348966
  validation accuracy:		93.04 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.013149
  validation loss:		0.347622
  validation accuracy:		92.93 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.012714
  validation loss:		0.343442
  validation accuracy:		93.04 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.013047
  validation loss:		0.352679
  validation accuracy:		93.04 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.013063
  validation loss:		0.344101
  validation accuracy:		93.04 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.013029
  validation loss:		0.358540
  validation accuracy:		92.83 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.012751
  validation loss:		0.349910
  validation accuracy:		92.83 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.012873
  validation loss:		0.355566
  validation accuracy:		92.72 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.012314
  validation loss:		0.341330
  validation accuracy:		93.15 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012870
  validation loss:		0.346592
  validation accuracy:		93.15 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.012777
  validation loss:		0.352719
  validation accuracy:		93.04 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.012715
  validation loss:		0.343323
  validation accuracy:		93.04 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.012645
  validation loss:		0.349515
  validation accuracy:		92.93 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.012489
  validation loss:		0.343651
  validation accuracy:		93.15 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.012745
  validation loss:		0.347803
  validation accuracy:		93.04 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.012534
  validation loss:		0.344539
  validation accuracy:		93.26 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.012350
  validation loss:		0.353160
  validation accuracy:		92.93 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.012395
  validation loss:		0.344408
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.012529
  validation loss:		0.354954
  validation accuracy:		92.93 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.012794
  validation loss:		0.343575
  validation accuracy:		93.26 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012285
  validation loss:		0.353950
  validation accuracy:		93.04 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.012291
  validation loss:		0.354219
  validation accuracy:		92.83 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.012018
  validation loss:		0.363394
  validation accuracy:		92.72 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.012428
  validation loss:		0.348104
  validation accuracy:		92.93 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.012181
  validation loss:		0.346621
  validation accuracy:		93.26 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.012406
  validation loss:		0.349816
  validation accuracy:		93.15 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.012184
  validation loss:		0.348385
  validation accuracy:		93.15 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.012462
  validation loss:		0.346531
  validation accuracy:		93.15 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.012590
  validation loss:		0.347335
  validation accuracy:		93.04 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.012219
  validation loss:		0.357581
  validation accuracy:		92.93 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.012161
  validation loss:		0.345411
  validation accuracy:		93.15 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.012332
  validation loss:		0.343924
  validation accuracy:		93.37 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.012415
  validation loss:		0.352055
  validation accuracy:		93.15 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.012237
  validation loss:		0.347935
  validation accuracy:		93.15 %
Epoch 1123 of 2000 took 0.036s
  training loss:		0.012002
  validation loss:		0.354293
  validation accuracy:		93.15 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.012050
  validation loss:		0.355757
  validation accuracy:		92.93 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.012414
  validation loss:		0.357465
  validation accuracy:		92.83 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.011282
  validation loss:		0.354700
  validation accuracy:		93.04 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.012007
  validation loss:		0.350934
  validation accuracy:		93.04 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.011775
  validation loss:		0.356546
  validation accuracy:		92.93 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.011909
  validation loss:		0.355835
  validation accuracy:		93.04 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.011863
  validation loss:		0.351601
  validation accuracy:		93.04 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.010935
  validation loss:		0.349543
  validation accuracy:		93.15 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.011737
  validation loss:		0.357141
  validation accuracy:		93.15 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.012133
  validation loss:		0.352921
  validation accuracy:		93.04 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.011998
  validation loss:		0.350862
  validation accuracy:		93.37 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011930
  validation loss:		0.350066
  validation accuracy:		93.15 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.011432
  validation loss:		0.358666
  validation accuracy:		93.04 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.011865
  validation loss:		0.356559
  validation accuracy:		92.83 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.011964
  validation loss:		0.356701
  validation accuracy:		92.93 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011665
  validation loss:		0.352813
  validation accuracy:		92.93 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011088
  validation loss:		0.353197
  validation accuracy:		93.15 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.011947
  validation loss:		0.357727
  validation accuracy:		93.04 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.011837
  validation loss:		0.351756
  validation accuracy:		93.15 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.011535
  validation loss:		0.358056
  validation accuracy:		93.04 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.011394
  validation loss:		0.354958
  validation accuracy:		93.15 %
Epoch 1145 of 2000 took 0.036s
  training loss:		0.011433
  validation loss:		0.355110
  validation accuracy:		92.93 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.011281
  validation loss:		0.362052
  validation accuracy:		92.83 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.010984
  validation loss:		0.354252
  validation accuracy:		93.04 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.011487
  validation loss:		0.358903
  validation accuracy:		93.04 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.011127
  validation loss:		0.349771
  validation accuracy:		93.04 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.010851
  validation loss:		0.351780
  validation accuracy:		93.15 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.010910
  validation loss:		0.356181
  validation accuracy:		93.15 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.011412
  validation loss:		0.354903
  validation accuracy:		93.15 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.011098
  validation loss:		0.359845
  validation accuracy:		93.04 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.010868
  validation loss:		0.353517
  validation accuracy:		93.04 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.010660
  validation loss:		0.357054
  validation accuracy:		93.26 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.011043
  validation loss:		0.364955
  validation accuracy:		92.83 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.011418
  validation loss:		0.351378
  validation accuracy:		93.04 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011353
  validation loss:		0.362433
  validation accuracy:		93.04 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.010917
  validation loss:		0.361735
  validation accuracy:		92.83 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.011287
  validation loss:		0.357346
  validation accuracy:		93.04 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.010640
  validation loss:		0.361247
  validation accuracy:		93.04 %
Epoch 1162 of 2000 took 0.036s
  training loss:		0.010859
  validation loss:		0.359766
  validation accuracy:		92.93 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.010924
  validation loss:		0.354819
  validation accuracy:		93.04 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.010851
  validation loss:		0.359826
  validation accuracy:		92.93 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.010850
  validation loss:		0.363945
  validation accuracy:		92.83 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.011081
  validation loss:		0.354092
  validation accuracy:		93.15 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.011310
  validation loss:		0.361196
  validation accuracy:		92.93 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.010873
  validation loss:		0.359976
  validation accuracy:		93.04 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.011032
  validation loss:		0.360013
  validation accuracy:		93.04 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.010442
  validation loss:		0.374203
  validation accuracy:		92.72 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.011170
  validation loss:		0.366245
  validation accuracy:		92.93 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.010640
  validation loss:		0.366781
  validation accuracy:		92.93 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.010794
  validation loss:		0.365100
  validation accuracy:		92.93 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.010640
  validation loss:		0.365110
  validation accuracy:		93.26 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010664
  validation loss:		0.362902
  validation accuracy:		92.93 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.010105
  validation loss:		0.362381
  validation accuracy:		92.93 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.010688
  validation loss:		0.371123
  validation accuracy:		92.93 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.010767
  validation loss:		0.363807
  validation accuracy:		93.04 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.010766
  validation loss:		0.361639
  validation accuracy:		92.93 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.010790
  validation loss:		0.373083
  validation accuracy:		92.72 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010467
  validation loss:		0.359329
  validation accuracy:		93.04 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.010645
  validation loss:		0.359663
  validation accuracy:		93.04 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.010205
  validation loss:		0.364677
  validation accuracy:		93.04 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010560
  validation loss:		0.359778
  validation accuracy:		93.26 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010583
  validation loss:		0.365771
  validation accuracy:		92.93 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.010666
  validation loss:		0.368014
  validation accuracy:		92.93 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.010296
  validation loss:		0.372907
  validation accuracy:		92.72 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.010521
  validation loss:		0.364623
  validation accuracy:		92.93 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.010916
  validation loss:		0.367751
  validation accuracy:		92.93 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.010346
  validation loss:		0.358511
  validation accuracy:		93.04 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.010463
  validation loss:		0.364311
  validation accuracy:		93.15 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.010221
  validation loss:		0.367759
  validation accuracy:		93.04 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.010236
  validation loss:		0.359839
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.010312
  validation loss:		0.361179
  validation accuracy:		93.04 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.010599
  validation loss:		0.365074
  validation accuracy:		93.04 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.010330
  validation loss:		0.365170
  validation accuracy:		93.15 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.010146
  validation loss:		0.366786
  validation accuracy:		92.93 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.010481
  validation loss:		0.360114
  validation accuracy:		93.15 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.010409
  validation loss:		0.367561
  validation accuracy:		92.83 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.010466
  validation loss:		0.370324
  validation accuracy:		93.04 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.010162
  validation loss:		0.364107
  validation accuracy:		93.04 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.009913
  validation loss:		0.363083
  validation accuracy:		92.93 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.010033
  validation loss:		0.365367
  validation accuracy:		93.15 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.009901
  validation loss:		0.372348
  validation accuracy:		93.04 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.010172
  validation loss:		0.366378
  validation accuracy:		92.93 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.010004
  validation loss:		0.366186
  validation accuracy:		93.15 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.010153
  validation loss:		0.366002
  validation accuracy:		93.04 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.010169
  validation loss:		0.374864
  validation accuracy:		92.72 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.009965
  validation loss:		0.363740
  validation accuracy:		93.04 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.009678
  validation loss:		0.366612
  validation accuracy:		93.04 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.010026
  validation loss:		0.371043
  validation accuracy:		93.04 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.009753
  validation loss:		0.374504
  validation accuracy:		92.93 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.009721
  validation loss:		0.363903
  validation accuracy:		93.15 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.009924
  validation loss:		0.379966
  validation accuracy:		92.93 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009814
  validation loss:		0.366168
  validation accuracy:		92.93 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.010002
  validation loss:		0.367269
  validation accuracy:		93.04 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.009989
  validation loss:		0.363335
  validation accuracy:		92.93 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.009649
  validation loss:		0.369372
  validation accuracy:		93.15 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.009840
  validation loss:		0.374721
  validation accuracy:		92.72 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009510
  validation loss:		0.361956
  validation accuracy:		93.15 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.009945
  validation loss:		0.371745
  validation accuracy:		92.93 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.009639
  validation loss:		0.371576
  validation accuracy:		92.93 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.009958
  validation loss:		0.372849
  validation accuracy:		93.04 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.009828
  validation loss:		0.369671
  validation accuracy:		93.15 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009885
  validation loss:		0.364005
  validation accuracy:		93.04 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009575
  validation loss:		0.375699
  validation accuracy:		93.15 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.010019
  validation loss:		0.379812
  validation accuracy:		92.83 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009683
  validation loss:		0.368311
  validation accuracy:		93.15 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.009552
  validation loss:		0.376000
  validation accuracy:		92.93 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.009721
  validation loss:		0.371708
  validation accuracy:		92.93 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009506
  validation loss:		0.375715
  validation accuracy:		92.93 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.009423
  validation loss:		0.370725
  validation accuracy:		93.04 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.009293
  validation loss:		0.382376
  validation accuracy:		92.83 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009516
  validation loss:		0.377003
  validation accuracy:		92.83 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.009459
  validation loss:		0.368252
  validation accuracy:		93.15 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.009506
  validation loss:		0.373337
  validation accuracy:		92.93 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009422
  validation loss:		0.374553
  validation accuracy:		93.04 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.009530
  validation loss:		0.371726
  validation accuracy:		93.04 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009272
  validation loss:		0.375795
  validation accuracy:		93.15 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.009308
  validation loss:		0.373760
  validation accuracy:		93.15 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.009170
  validation loss:		0.375560
  validation accuracy:		92.93 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.009542
  validation loss:		0.376086
  validation accuracy:		92.93 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.009116
  validation loss:		0.372964
  validation accuracy:		92.83 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.009270
  validation loss:		0.381875
  validation accuracy:		92.83 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009245
  validation loss:		0.373090
  validation accuracy:		92.93 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.008844
  validation loss:		0.370526
  validation accuracy:		93.15 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.008925
  validation loss:		0.380879
  validation accuracy:		92.93 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.008836
  validation loss:		0.377000
  validation accuracy:		93.04 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.009065
  validation loss:		0.387582
  validation accuracy:		92.72 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.008951
  validation loss:		0.370285
  validation accuracy:		93.04 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.009178
  validation loss:		0.371741
  validation accuracy:		93.04 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009159
  validation loss:		0.380834
  validation accuracy:		92.83 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.009317
  validation loss:		0.380016
  validation accuracy:		92.93 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009311
  validation loss:		0.381120
  validation accuracy:		92.93 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.009279
  validation loss:		0.370415
  validation accuracy:		93.04 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.008871
  validation loss:		0.380354
  validation accuracy:		92.83 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.008995
  validation loss:		0.367568
  validation accuracy:		93.04 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.009047
  validation loss:		0.375778
  validation accuracy:		93.26 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.008974
  validation loss:		0.387428
  validation accuracy:		92.72 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.009521
  validation loss:		0.377799
  validation accuracy:		93.04 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.009042
  validation loss:		0.378626
  validation accuracy:		93.04 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.009238
  validation loss:		0.379676
  validation accuracy:		92.93 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.009023
  validation loss:		0.388398
  validation accuracy:		92.72 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.009015
  validation loss:		0.386967
  validation accuracy:		92.93 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.008905
  validation loss:		0.372487
  validation accuracy:		92.93 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.008816
  validation loss:		0.385511
  validation accuracy:		92.83 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.008795
  validation loss:		0.384989
  validation accuracy:		92.83 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008576
  validation loss:		0.376728
  validation accuracy:		93.04 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.009169
  validation loss:		0.380201
  validation accuracy:		92.93 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.009263
  validation loss:		0.383210
  validation accuracy:		92.72 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008799
  validation loss:		0.378248
  validation accuracy:		93.15 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008592
  validation loss:		0.379023
  validation accuracy:		92.83 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008937
  validation loss:		0.373141
  validation accuracy:		92.93 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.008693
  validation loss:		0.379557
  validation accuracy:		93.15 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008722
  validation loss:		0.387211
  validation accuracy:		92.93 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008550
  validation loss:		0.379956
  validation accuracy:		93.04 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.008350
  validation loss:		0.380452
  validation accuracy:		93.15 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.008847
  validation loss:		0.378703
  validation accuracy:		92.93 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008409
  validation loss:		0.381347
  validation accuracy:		93.04 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008583
  validation loss:		0.388181
  validation accuracy:		92.93 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.008663
  validation loss:		0.377369
  validation accuracy:		93.04 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008789
  validation loss:		0.377977
  validation accuracy:		93.04 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.008520
  validation loss:		0.385502
  validation accuracy:		92.83 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008396
  validation loss:		0.385768
  validation accuracy:		93.04 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008569
  validation loss:		0.382364
  validation accuracy:		93.15 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.008784
  validation loss:		0.378636
  validation accuracy:		93.15 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.008249
  validation loss:		0.386182
  validation accuracy:		93.04 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.008677
  validation loss:		0.390693
  validation accuracy:		92.72 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.008575
  validation loss:		0.387332
  validation accuracy:		92.83 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.008672
  validation loss:		0.390355
  validation accuracy:		92.93 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.008389
  validation loss:		0.382447
  validation accuracy:		93.04 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008270
  validation loss:		0.379733
  validation accuracy:		93.04 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.008455
  validation loss:		0.383322
  validation accuracy:		92.93 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.008431
  validation loss:		0.385206
  validation accuracy:		93.04 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.008503
  validation loss:		0.377354
  validation accuracy:		92.93 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.008395
  validation loss:		0.380898
  validation accuracy:		93.04 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.008314
  validation loss:		0.391548
  validation accuracy:		92.93 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.008307
  validation loss:		0.382282
  validation accuracy:		92.93 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.008366
  validation loss:		0.387262
  validation accuracy:		92.93 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.008104
  validation loss:		0.385697
  validation accuracy:		92.83 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.008191
  validation loss:		0.388693
  validation accuracy:		92.93 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.008662
  validation loss:		0.388898
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.008233
  validation loss:		0.389177
  validation accuracy:		92.93 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.008328
  validation loss:		0.386117
  validation accuracy:		92.93 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.008415
  validation loss:		0.388388
  validation accuracy:		92.83 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.008258
  validation loss:		0.386993
  validation accuracy:		92.93 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.008009
  validation loss:		0.380978
  validation accuracy:		92.93 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.008083
  validation loss:		0.385517
  validation accuracy:		93.15 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.008254
  validation loss:		0.386272
  validation accuracy:		92.93 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.008333
  validation loss:		0.391715
  validation accuracy:		93.04 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.008077
  validation loss:		0.387300
  validation accuracy:		92.93 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.008216
  validation loss:		0.390842
  validation accuracy:		92.93 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.008215
  validation loss:		0.391263
  validation accuracy:		93.04 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.007829
  validation loss:		0.395673
  validation accuracy:		92.83 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.007765
  validation loss:		0.385678
  validation accuracy:		92.93 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.007986
  validation loss:		0.392243
  validation accuracy:		92.93 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.008419
  validation loss:		0.390812
  validation accuracy:		93.04 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.008068
  validation loss:		0.385782
  validation accuracy:		92.93 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.008339
  validation loss:		0.381448
  validation accuracy:		92.93 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.008119
  validation loss:		0.393324
  validation accuracy:		92.93 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.007683
  validation loss:		0.394021
  validation accuracy:		92.83 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.007807
  validation loss:		0.393296
  validation accuracy:		92.83 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007972
  validation loss:		0.389776
  validation accuracy:		93.04 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.007889
  validation loss:		0.392642
  validation accuracy:		92.83 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.008297
  validation loss:		0.391900
  validation accuracy:		93.04 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.008019
  validation loss:		0.389982
  validation accuracy:		93.04 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.007682
  validation loss:		0.391693
  validation accuracy:		92.93 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.007997
  validation loss:		0.395815
  validation accuracy:		92.72 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.007861
  validation loss:		0.382693
  validation accuracy:		92.93 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.007712
  validation loss:		0.393389
  validation accuracy:		92.83 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.007855
  validation loss:		0.391204
  validation accuracy:		92.93 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.007667
  validation loss:		0.384938
  validation accuracy:		93.04 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.007773
  validation loss:		0.390608
  validation accuracy:		92.93 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007667
  validation loss:		0.385055
  validation accuracy:		92.93 %
Epoch 1335 of 2000 took 0.037s
  training loss:		0.007805
  validation loss:		0.395022
  validation accuracy:		93.04 %
Epoch 1336 of 2000 took 0.036s
  training loss:		0.007402
  validation loss:		0.391679
  validation accuracy:		92.93 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007827
  validation loss:		0.394215
  validation accuracy:		92.93 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007501
  validation loss:		0.395313
  validation accuracy:		92.83 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.007989
  validation loss:		0.392787
  validation accuracy:		93.15 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007838
  validation loss:		0.392099
  validation accuracy:		93.04 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.007942
  validation loss:		0.390919
  validation accuracy:		92.93 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.007678
  validation loss:		0.392894
  validation accuracy:		92.93 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007411
  validation loss:		0.389064
  validation accuracy:		92.93 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.007658
  validation loss:		0.387049
  validation accuracy:		92.93 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007353
  validation loss:		0.398326
  validation accuracy:		92.83 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.007730
  validation loss:		0.389281
  validation accuracy:		92.93 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.007638
  validation loss:		0.391507
  validation accuracy:		93.15 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.007669
  validation loss:		0.391721
  validation accuracy:		93.04 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.007532
  validation loss:		0.395073
  validation accuracy:		93.04 %
Epoch 1350 of 2000 took 0.036s
  training loss:		0.007509
  validation loss:		0.395740
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.007463
  validation loss:		0.396985
  validation accuracy:		92.93 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.007185
  validation loss:		0.396473
  validation accuracy:		92.93 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007694
  validation loss:		0.395408
  validation accuracy:		92.93 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.007395
  validation loss:		0.390503
  validation accuracy:		92.93 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.007314
  validation loss:		0.398028
  validation accuracy:		92.83 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.007250
  validation loss:		0.386658
  validation accuracy:		93.04 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.007658
  validation loss:		0.390881
  validation accuracy:		92.93 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.007545
  validation loss:		0.409975
  validation accuracy:		92.72 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.007274
  validation loss:		0.388859
  validation accuracy:		92.93 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007717
  validation loss:		0.395155
  validation accuracy:		93.04 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.007162
  validation loss:		0.399403
  validation accuracy:		92.83 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.007693
  validation loss:		0.394619
  validation accuracy:		92.93 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.007481
  validation loss:		0.387554
  validation accuracy:		92.93 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.007813
  validation loss:		0.393858
  validation accuracy:		92.93 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.007451
  validation loss:		0.395837
  validation accuracy:		93.15 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.007210
  validation loss:		0.395006
  validation accuracy:		93.04 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.007289
  validation loss:		0.398661
  validation accuracy:		92.83 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.007337
  validation loss:		0.397211
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.007253
  validation loss:		0.400054
  validation accuracy:		93.04 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.007517
  validation loss:		0.397362
  validation accuracy:		92.93 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.007291
  validation loss:		0.401618
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.007284
  validation loss:		0.399102
  validation accuracy:		92.83 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.007446
  validation loss:		0.398833
  validation accuracy:		92.83 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.007324
  validation loss:		0.400078
  validation accuracy:		92.83 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.007124
  validation loss:		0.408543
  validation accuracy:		92.61 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.007180
  validation loss:		0.392376
  validation accuracy:		92.93 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.007283
  validation loss:		0.404867
  validation accuracy:		92.72 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.007244
  validation loss:		0.398166
  validation accuracy:		92.93 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.007361
  validation loss:		0.398772
  validation accuracy:		92.93 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.007130
  validation loss:		0.405973
  validation accuracy:		92.83 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.007165
  validation loss:		0.399819
  validation accuracy:		92.93 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.007029
  validation loss:		0.409947
  validation accuracy:		92.61 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.007222
  validation loss:		0.400316
  validation accuracy:		92.83 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.007119
  validation loss:		0.409828
  validation accuracy:		92.72 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.007147
  validation loss:		0.402366
  validation accuracy:		92.93 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.007084
  validation loss:		0.408704
  validation accuracy:		92.83 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006942
  validation loss:		0.401173
  validation accuracy:		93.04 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.007124
  validation loss:		0.395835
  validation accuracy:		92.93 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006907
  validation loss:		0.411028
  validation accuracy:		92.72 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.007019
  validation loss:		0.403694
  validation accuracy:		92.83 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.007097
  validation loss:		0.400006
  validation accuracy:		92.93 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.006774
  validation loss:		0.400903
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.006860
  validation loss:		0.402513
  validation accuracy:		92.83 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006713
  validation loss:		0.399771
  validation accuracy:		92.83 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.006858
  validation loss:		0.403053
  validation accuracy:		92.93 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006945
  validation loss:		0.406721
  validation accuracy:		92.93 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.007186
  validation loss:		0.411784
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.007122
  validation loss:		0.400565
  validation accuracy:		92.93 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006973
  validation loss:		0.403135
  validation accuracy:		93.04 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.006899
  validation loss:		0.401269
  validation accuracy:		93.04 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.006852
  validation loss:		0.403734
  validation accuracy:		92.83 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.006673
  validation loss:		0.398833
  validation accuracy:		92.93 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.006862
  validation loss:		0.406000
  validation accuracy:		92.83 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.006864
  validation loss:		0.411026
  validation accuracy:		92.72 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.006841
  validation loss:		0.401368
  validation accuracy:		92.93 %
Epoch 1406 of 2000 took 0.036s
  training loss:		0.006766
  validation loss:		0.405731
  validation accuracy:		92.83 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006804
  validation loss:		0.400791
  validation accuracy:		92.93 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.006737
  validation loss:		0.403574
  validation accuracy:		92.93 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006853
  validation loss:		0.408583
  validation accuracy:		92.83 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.006636
  validation loss:		0.397046
  validation accuracy:		93.04 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006699
  validation loss:		0.409671
  validation accuracy:		92.83 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006526
  validation loss:		0.409127
  validation accuracy:		92.72 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.006606
  validation loss:		0.399276
  validation accuracy:		93.04 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.006953
  validation loss:		0.403526
  validation accuracy:		92.83 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.006607
  validation loss:		0.409950
  validation accuracy:		92.93 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.006711
  validation loss:		0.405399
  validation accuracy:		92.72 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006763
  validation loss:		0.415347
  validation accuracy:		92.61 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.007000
  validation loss:		0.412862
  validation accuracy:		92.83 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.006560
  validation loss:		0.406973
  validation accuracy:		92.93 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006706
  validation loss:		0.405993
  validation accuracy:		92.83 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.006606
  validation loss:		0.405591
  validation accuracy:		92.93 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.006781
  validation loss:		0.405239
  validation accuracy:		92.83 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.006672
  validation loss:		0.406435
  validation accuracy:		92.72 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.006709
  validation loss:		0.404959
  validation accuracy:		93.04 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.006540
  validation loss:		0.410277
  validation accuracy:		92.72 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006647
  validation loss:		0.407660
  validation accuracy:		92.83 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.006519
  validation loss:		0.401983
  validation accuracy:		93.04 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.006483
  validation loss:		0.409206
  validation accuracy:		92.72 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.006464
  validation loss:		0.404978
  validation accuracy:		92.93 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.006551
  validation loss:		0.406067
  validation accuracy:		92.83 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006331
  validation loss:		0.408952
  validation accuracy:		92.83 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.006646
  validation loss:		0.408600
  validation accuracy:		93.04 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.006375
  validation loss:		0.405344
  validation accuracy:		92.93 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.006503
  validation loss:		0.405677
  validation accuracy:		92.93 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.006491
  validation loss:		0.409625
  validation accuracy:		92.72 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.006476
  validation loss:		0.408320
  validation accuracy:		92.93 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.006459
  validation loss:		0.399298
  validation accuracy:		92.93 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006569
  validation loss:		0.414154
  validation accuracy:		92.83 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.006515
  validation loss:		0.411415
  validation accuracy:		92.72 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.006414
  validation loss:		0.414412
  validation accuracy:		92.83 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.006544
  validation loss:		0.407544
  validation accuracy:		92.83 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.006228
  validation loss:		0.411277
  validation accuracy:		92.93 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.006399
  validation loss:		0.409108
  validation accuracy:		92.83 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.006446
  validation loss:		0.404378
  validation accuracy:		93.04 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.006393
  validation loss:		0.406600
  validation accuracy:		92.83 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.006367
  validation loss:		0.413197
  validation accuracy:		92.72 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.006312
  validation loss:		0.412472
  validation accuracy:		92.93 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.006379
  validation loss:		0.406601
  validation accuracy:		93.04 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006231
  validation loss:		0.407992
  validation accuracy:		92.93 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.006143
  validation loss:		0.413927
  validation accuracy:		92.72 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.006167
  validation loss:		0.419506
  validation accuracy:		92.72 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.006459
  validation loss:		0.415746
  validation accuracy:		92.83 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.006314
  validation loss:		0.405776
  validation accuracy:		92.93 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.006244
  validation loss:		0.411272
  validation accuracy:		92.93 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.006130
  validation loss:		0.412781
  validation accuracy:		92.83 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.006212
  validation loss:		0.410200
  validation accuracy:		93.04 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.006403
  validation loss:		0.414595
  validation accuracy:		92.83 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.006117
  validation loss:		0.412735
  validation accuracy:		92.93 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.006173
  validation loss:		0.408520
  validation accuracy:		92.93 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.006422
  validation loss:		0.406061
  validation accuracy:		92.93 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.006280
  validation loss:		0.416664
  validation accuracy:		92.83 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.006172
  validation loss:		0.411722
  validation accuracy:		92.83 %
Epoch 1463 of 2000 took 0.036s
  training loss:		0.006001
  validation loss:		0.415611
  validation accuracy:		93.04 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.006292
  validation loss:		0.408424
  validation accuracy:		92.93 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.006212
  validation loss:		0.415673
  validation accuracy:		92.72 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.006174
  validation loss:		0.413242
  validation accuracy:		92.83 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.006379
  validation loss:		0.417472
  validation accuracy:		92.72 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.006205
  validation loss:		0.410809
  validation accuracy:		92.93 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.006141
  validation loss:		0.416347
  validation accuracy:		92.83 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.006159
  validation loss:		0.419448
  validation accuracy:		92.83 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.006145
  validation loss:		0.412620
  validation accuracy:		92.93 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.006068
  validation loss:		0.410652
  validation accuracy:		92.93 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.006182
  validation loss:		0.419264
  validation accuracy:		92.72 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.006190
  validation loss:		0.408906
  validation accuracy:		92.93 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.006074
  validation loss:		0.409858
  validation accuracy:		92.93 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.006114
  validation loss:		0.418289
  validation accuracy:		92.72 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.006060
  validation loss:		0.411418
  validation accuracy:		92.93 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.006010
  validation loss:		0.419037
  validation accuracy:		92.83 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.006104
  validation loss:		0.415456
  validation accuracy:		92.83 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.005938
  validation loss:		0.414256
  validation accuracy:		92.72 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.005940
  validation loss:		0.415125
  validation accuracy:		92.72 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.006047
  validation loss:		0.412493
  validation accuracy:		92.83 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.005959
  validation loss:		0.419573
  validation accuracy:		92.72 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.006061
  validation loss:		0.414590
  validation accuracy:		92.83 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.005918
  validation loss:		0.424249
  validation accuracy:		92.61 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005921
  validation loss:		0.413014
  validation accuracy:		92.93 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005967
  validation loss:		0.415986
  validation accuracy:		92.93 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005811
  validation loss:		0.422428
  validation accuracy:		92.83 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005819
  validation loss:		0.414202
  validation accuracy:		92.93 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005946
  validation loss:		0.412065
  validation accuracy:		92.93 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.005973
  validation loss:		0.419226
  validation accuracy:		92.72 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005897
  validation loss:		0.412003
  validation accuracy:		92.93 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.005836
  validation loss:		0.423020
  validation accuracy:		92.83 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.005807
  validation loss:		0.415578
  validation accuracy:		92.72 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005809
  validation loss:		0.418170
  validation accuracy:		92.72 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.005871
  validation loss:		0.421759
  validation accuracy:		92.83 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005908
  validation loss:		0.418219
  validation accuracy:		92.83 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005758
  validation loss:		0.417587
  validation accuracy:		92.83 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005846
  validation loss:		0.418112
  validation accuracy:		92.83 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.005689
  validation loss:		0.418496
  validation accuracy:		92.83 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005682
  validation loss:		0.417334
  validation accuracy:		92.83 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.005891
  validation loss:		0.424723
  validation accuracy:		92.72 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005674
  validation loss:		0.421193
  validation accuracy:		92.72 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.005685
  validation loss:		0.416928
  validation accuracy:		92.93 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.005877
  validation loss:		0.419425
  validation accuracy:		93.04 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005924
  validation loss:		0.419471
  validation accuracy:		92.83 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.005742
  validation loss:		0.419445
  validation accuracy:		92.72 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005757
  validation loss:		0.420107
  validation accuracy:		92.83 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.005862
  validation loss:		0.419403
  validation accuracy:		92.83 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.005748
  validation loss:		0.416117
  validation accuracy:		92.93 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005642
  validation loss:		0.426832
  validation accuracy:		92.72 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.005553
  validation loss:		0.414764
  validation accuracy:		92.83 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.005728
  validation loss:		0.423252
  validation accuracy:		92.83 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005511
  validation loss:		0.421878
  validation accuracy:		92.72 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005640
  validation loss:		0.427203
  validation accuracy:		92.83 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.005742
  validation loss:		0.417484
  validation accuracy:		92.83 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.005602
  validation loss:		0.421129
  validation accuracy:		92.93 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.005554
  validation loss:		0.421489
  validation accuracy:		92.72 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.005643
  validation loss:		0.429176
  validation accuracy:		92.50 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.418444
  validation accuracy:		92.83 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.005595
  validation loss:		0.426081
  validation accuracy:		92.72 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.005463
  validation loss:		0.422253
  validation accuracy:		92.72 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.005575
  validation loss:		0.423657
  validation accuracy:		92.72 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.005674
  validation loss:		0.426469
  validation accuracy:		92.72 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.005568
  validation loss:		0.421384
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.005556
  validation loss:		0.420786
  validation accuracy:		92.93 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005621
  validation loss:		0.420618
  validation accuracy:		92.83 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.005587
  validation loss:		0.419377
  validation accuracy:		92.83 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.005767
  validation loss:		0.419633
  validation accuracy:		92.72 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005474
  validation loss:		0.424223
  validation accuracy:		92.72 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.005607
  validation loss:		0.423026
  validation accuracy:		92.83 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.005556
  validation loss:		0.425510
  validation accuracy:		92.83 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.005399
  validation loss:		0.427534
  validation accuracy:		92.61 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.005410
  validation loss:		0.424360
  validation accuracy:		92.83 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005558
  validation loss:		0.435037
  validation accuracy:		92.50 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005754
  validation loss:		0.423308
  validation accuracy:		92.83 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005424
  validation loss:		0.426955
  validation accuracy:		92.83 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.005516
  validation loss:		0.422577
  validation accuracy:		92.93 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005659
  validation loss:		0.423311
  validation accuracy:		92.83 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.005529
  validation loss:		0.428986
  validation accuracy:		92.72 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.005404
  validation loss:		0.420092
  validation accuracy:		92.93 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.005397
  validation loss:		0.427736
  validation accuracy:		92.72 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005214
  validation loss:		0.428276
  validation accuracy:		92.72 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005563
  validation loss:		0.428173
  validation accuracy:		92.72 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.005258
  validation loss:		0.419714
  validation accuracy:		92.83 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.005472
  validation loss:		0.422579
  validation accuracy:		92.83 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.005227
  validation loss:		0.426771
  validation accuracy:		92.72 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005299
  validation loss:		0.429275
  validation accuracy:		92.72 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005429
  validation loss:		0.421756
  validation accuracy:		92.93 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.005421
  validation loss:		0.422585
  validation accuracy:		92.93 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.005316
  validation loss:		0.429078
  validation accuracy:		92.72 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.005204
  validation loss:		0.426065
  validation accuracy:		92.83 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.005288
  validation loss:		0.424543
  validation accuracy:		92.83 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.005323
  validation loss:		0.423281
  validation accuracy:		92.72 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.005329
  validation loss:		0.424214
  validation accuracy:		92.72 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.005093
  validation loss:		0.424528
  validation accuracy:		93.04 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.005131
  validation loss:		0.432328
  validation accuracy:		92.72 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.005382
  validation loss:		0.430810
  validation accuracy:		92.72 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.005428
  validation loss:		0.427049
  validation accuracy:		92.83 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.005222
  validation loss:		0.422854
  validation accuracy:		92.93 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.005398
  validation loss:		0.427684
  validation accuracy:		92.83 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.005272
  validation loss:		0.429049
  validation accuracy:		92.72 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.005166
  validation loss:		0.429488
  validation accuracy:		92.72 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.005359
  validation loss:		0.424847
  validation accuracy:		92.72 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.005236
  validation loss:		0.428444
  validation accuracy:		92.83 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.005144
  validation loss:		0.431157
  validation accuracy:		92.72 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.005102
  validation loss:		0.421360
  validation accuracy:		92.93 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.005159
  validation loss:		0.433002
  validation accuracy:		92.72 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.005139
  validation loss:		0.430849
  validation accuracy:		92.83 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.005341
  validation loss:		0.428050
  validation accuracy:		92.83 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.005211
  validation loss:		0.430467
  validation accuracy:		92.83 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.005220
  validation loss:		0.429417
  validation accuracy:		92.72 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.005052
  validation loss:		0.428221
  validation accuracy:		92.83 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.005218
  validation loss:		0.431452
  validation accuracy:		92.72 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.005110
  validation loss:		0.425745
  validation accuracy:		92.83 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.005347
  validation loss:		0.435623
  validation accuracy:		92.50 %
Epoch 1577 of 2000 took 0.036s
  training loss:		0.005174
  validation loss:		0.426163
  validation accuracy:		92.83 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005267
  validation loss:		0.432205
  validation accuracy:		92.61 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.005265
  validation loss:		0.427925
  validation accuracy:		92.83 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.005033
  validation loss:		0.427994
  validation accuracy:		92.83 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.005098
  validation loss:		0.429676
  validation accuracy:		92.83 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.005137
  validation loss:		0.432365
  validation accuracy:		92.83 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.005057
  validation loss:		0.428389
  validation accuracy:		92.93 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.005083
  validation loss:		0.434407
  validation accuracy:		92.72 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.004925
  validation loss:		0.430568
  validation accuracy:		92.83 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.005138
  validation loss:		0.430711
  validation accuracy:		92.83 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.005152
  validation loss:		0.432987
  validation accuracy:		92.72 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.005038
  validation loss:		0.430519
  validation accuracy:		92.72 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.004949
  validation loss:		0.430039
  validation accuracy:		92.83 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.004974
  validation loss:		0.435370
  validation accuracy:		92.72 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004940
  validation loss:		0.431466
  validation accuracy:		92.72 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.004950
  validation loss:		0.433976
  validation accuracy:		92.83 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.004990
  validation loss:		0.436347
  validation accuracy:		92.72 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.005168
  validation loss:		0.436931
  validation accuracy:		92.61 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005151
  validation loss:		0.434461
  validation accuracy:		92.72 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004953
  validation loss:		0.432945
  validation accuracy:		92.72 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.004912
  validation loss:		0.427423
  validation accuracy:		92.93 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.005040
  validation loss:		0.438005
  validation accuracy:		92.61 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004848
  validation loss:		0.430355
  validation accuracy:		92.83 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004916
  validation loss:		0.432868
  validation accuracy:		92.72 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004977
  validation loss:		0.433082
  validation accuracy:		92.93 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004919
  validation loss:		0.429220
  validation accuracy:		92.83 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005051
  validation loss:		0.435381
  validation accuracy:		92.72 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005000
  validation loss:		0.437651
  validation accuracy:		92.83 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.004948
  validation loss:		0.435211
  validation accuracy:		92.72 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004899
  validation loss:		0.436609
  validation accuracy:		92.72 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.004890
  validation loss:		0.434997
  validation accuracy:		92.72 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004722
  validation loss:		0.429611
  validation accuracy:		92.93 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005079
  validation loss:		0.434910
  validation accuracy:		92.72 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.435925
  validation accuracy:		92.72 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.005109
  validation loss:		0.437662
  validation accuracy:		92.72 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.004935
  validation loss:		0.431689
  validation accuracy:		92.83 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.004892
  validation loss:		0.434759
  validation accuracy:		92.83 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.435806
  validation accuracy:		92.72 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004853
  validation loss:		0.441400
  validation accuracy:		92.61 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004811
  validation loss:		0.433693
  validation accuracy:		92.72 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004977
  validation loss:		0.441150
  validation accuracy:		92.72 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005029
  validation loss:		0.437124
  validation accuracy:		92.83 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004752
  validation loss:		0.429962
  validation accuracy:		92.83 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004974
  validation loss:		0.436415
  validation accuracy:		92.83 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004942
  validation loss:		0.442408
  validation accuracy:		92.72 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004804
  validation loss:		0.436945
  validation accuracy:		92.83 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004882
  validation loss:		0.433733
  validation accuracy:		92.93 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004653
  validation loss:		0.436444
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004779
  validation loss:		0.432868
  validation accuracy:		92.83 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004676
  validation loss:		0.436276
  validation accuracy:		92.83 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.004872
  validation loss:		0.444283
  validation accuracy:		92.61 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.004897
  validation loss:		0.438671
  validation accuracy:		92.72 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004670
  validation loss:		0.434941
  validation accuracy:		92.83 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004767
  validation loss:		0.433685
  validation accuracy:		92.83 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004786
  validation loss:		0.439374
  validation accuracy:		92.83 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004678
  validation loss:		0.439295
  validation accuracy:		92.72 %
Epoch 1633 of 2000 took 0.036s
  training loss:		0.004808
  validation loss:		0.439325
  validation accuracy:		92.72 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004602
  validation loss:		0.438544
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004624
  validation loss:		0.441136
  validation accuracy:		92.72 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004741
  validation loss:		0.441214
  validation accuracy:		92.72 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004699
  validation loss:		0.441046
  validation accuracy:		92.83 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004719
  validation loss:		0.440394
  validation accuracy:		92.72 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004785
  validation loss:		0.440032
  validation accuracy:		92.72 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004598
  validation loss:		0.440346
  validation accuracy:		92.72 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004806
  validation loss:		0.448604
  validation accuracy:		92.39 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004713
  validation loss:		0.435509
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004669
  validation loss:		0.441979
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.004675
  validation loss:		0.439700
  validation accuracy:		92.83 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004712
  validation loss:		0.437743
  validation accuracy:		92.83 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004665
  validation loss:		0.438202
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004703
  validation loss:		0.442827
  validation accuracy:		92.72 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004666
  validation loss:		0.437898
  validation accuracy:		92.83 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.004594
  validation loss:		0.439837
  validation accuracy:		92.83 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004623
  validation loss:		0.436790
  validation accuracy:		92.83 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.004661
  validation loss:		0.439716
  validation accuracy:		92.83 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004610
  validation loss:		0.440850
  validation accuracy:		92.83 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004660
  validation loss:		0.440898
  validation accuracy:		92.72 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004326
  validation loss:		0.436613
  validation accuracy:		92.83 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004735
  validation loss:		0.445225
  validation accuracy:		92.72 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004544
  validation loss:		0.445242
  validation accuracy:		92.72 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.443991
  validation accuracy:		92.72 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.004535
  validation loss:		0.440157
  validation accuracy:		92.83 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.004566
  validation loss:		0.444956
  validation accuracy:		92.72 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004569
  validation loss:		0.444768
  validation accuracy:		92.72 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004685
  validation loss:		0.442440
  validation accuracy:		92.83 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.004456
  validation loss:		0.442113
  validation accuracy:		92.72 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.438146
  validation accuracy:		92.83 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004506
  validation loss:		0.445534
  validation accuracy:		92.72 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004435
  validation loss:		0.438752
  validation accuracy:		92.83 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004490
  validation loss:		0.441583
  validation accuracy:		92.83 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004541
  validation loss:		0.442598
  validation accuracy:		92.83 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004475
  validation loss:		0.442068
  validation accuracy:		92.83 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.004504
  validation loss:		0.441196
  validation accuracy:		92.72 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.443646
  validation accuracy:		92.72 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004490
  validation loss:		0.449585
  validation accuracy:		92.72 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.004646
  validation loss:		0.436093
  validation accuracy:		92.93 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004476
  validation loss:		0.441299
  validation accuracy:		92.83 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004514
  validation loss:		0.441524
  validation accuracy:		92.83 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.004567
  validation loss:		0.444090
  validation accuracy:		92.72 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.004438
  validation loss:		0.438388
  validation accuracy:		92.83 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.004575
  validation loss:		0.448713
  validation accuracy:		92.72 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.004289
  validation loss:		0.439351
  validation accuracy:		92.93 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.004393
  validation loss:		0.447935
  validation accuracy:		92.72 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004453
  validation loss:		0.444542
  validation accuracy:		92.83 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004447
  validation loss:		0.445668
  validation accuracy:		92.72 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.440695
  validation accuracy:		92.83 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.004396
  validation loss:		0.452452
  validation accuracy:		92.72 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004405
  validation loss:		0.443647
  validation accuracy:		92.83 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.004376
  validation loss:		0.444687
  validation accuracy:		92.83 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.004297
  validation loss:		0.445483
  validation accuracy:		92.83 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.004558
  validation loss:		0.438004
  validation accuracy:		92.93 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.004451
  validation loss:		0.447465
  validation accuracy:		92.83 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.004415
  validation loss:		0.444682
  validation accuracy:		92.72 %
Epoch 1690 of 2000 took 0.036s
  training loss:		0.004477
  validation loss:		0.449328
  validation accuracy:		92.72 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.004466
  validation loss:		0.446932
  validation accuracy:		92.72 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.447523
  validation accuracy:		92.72 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.004320
  validation loss:		0.449223
  validation accuracy:		92.72 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.004479
  validation loss:		0.443713
  validation accuracy:		92.72 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.004367
  validation loss:		0.451212
  validation accuracy:		92.61 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.004293
  validation loss:		0.446148
  validation accuracy:		92.72 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.004286
  validation loss:		0.447129
  validation accuracy:		92.83 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004284
  validation loss:		0.443240
  validation accuracy:		92.83 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.449046
  validation accuracy:		92.83 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.442846
  validation accuracy:		92.93 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004419
  validation loss:		0.446481
  validation accuracy:		92.83 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.004392
  validation loss:		0.446983
  validation accuracy:		92.72 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.004257
  validation loss:		0.449789
  validation accuracy:		92.72 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004263
  validation loss:		0.446870
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004307
  validation loss:		0.446088
  validation accuracy:		92.83 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004330
  validation loss:		0.450490
  validation accuracy:		92.72 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.004304
  validation loss:		0.441617
  validation accuracy:		92.83 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.449173
  validation accuracy:		92.83 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004328
  validation loss:		0.448564
  validation accuracy:		92.72 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.004156
  validation loss:		0.446184
  validation accuracy:		92.83 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.451132
  validation accuracy:		92.72 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004383
  validation loss:		0.451815
  validation accuracy:		92.72 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004182
  validation loss:		0.444260
  validation accuracy:		92.83 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.004271
  validation loss:		0.445124
  validation accuracy:		92.93 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004183
  validation loss:		0.451783
  validation accuracy:		92.72 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004208
  validation loss:		0.449054
  validation accuracy:		92.83 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004133
  validation loss:		0.452408
  validation accuracy:		92.72 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004024
  validation loss:		0.447126
  validation accuracy:		92.83 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004282
  validation loss:		0.450042
  validation accuracy:		92.83 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.450156
  validation accuracy:		92.93 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004240
  validation loss:		0.451918
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004120
  validation loss:		0.451215
  validation accuracy:		92.72 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004163
  validation loss:		0.449891
  validation accuracy:		92.72 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004264
  validation loss:		0.445003
  validation accuracy:		92.93 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004253
  validation loss:		0.447705
  validation accuracy:		92.83 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004241
  validation loss:		0.451939
  validation accuracy:		92.72 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004164
  validation loss:		0.451830
  validation accuracy:		92.83 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004190
  validation loss:		0.449830
  validation accuracy:		92.83 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004126
  validation loss:		0.450902
  validation accuracy:		92.83 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004228
  validation loss:		0.453502
  validation accuracy:		92.72 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004050
  validation loss:		0.447918
  validation accuracy:		92.72 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004158
  validation loss:		0.451262
  validation accuracy:		92.83 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004073
  validation loss:		0.446052
  validation accuracy:		92.72 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004097
  validation loss:		0.452152
  validation accuracy:		92.83 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004127
  validation loss:		0.450370
  validation accuracy:		92.83 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004121
  validation loss:		0.452518
  validation accuracy:		92.83 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004096
  validation loss:		0.451036
  validation accuracy:		92.93 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.449985
  validation accuracy:		92.83 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.003911
  validation loss:		0.446964
  validation accuracy:		92.93 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004079
  validation loss:		0.459077
  validation accuracy:		92.50 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004053
  validation loss:		0.445998
  validation accuracy:		92.83 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004086
  validation loss:		0.450769
  validation accuracy:		92.83 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004031
  validation loss:		0.456782
  validation accuracy:		92.72 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004048
  validation loss:		0.453261
  validation accuracy:		92.72 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.449488
  validation accuracy:		92.93 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004074
  validation loss:		0.451502
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.036s
  training loss:		0.003988
  validation loss:		0.456378
  validation accuracy:		92.72 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004006
  validation loss:		0.450408
  validation accuracy:		92.83 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.003963
  validation loss:		0.458111
  validation accuracy:		92.72 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.003993
  validation loss:		0.452379
  validation accuracy:		92.83 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004076
  validation loss:		0.457868
  validation accuracy:		92.61 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.003999
  validation loss:		0.448719
  validation accuracy:		92.93 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004076
  validation loss:		0.457502
  validation accuracy:		92.72 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004023
  validation loss:		0.452511
  validation accuracy:		92.83 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004060
  validation loss:		0.451732
  validation accuracy:		92.83 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.454238
  validation accuracy:		92.93 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.003841
  validation loss:		0.450979
  validation accuracy:		92.72 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004036
  validation loss:		0.456052
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004031
  validation loss:		0.453158
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.454493
  validation accuracy:		92.93 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.003916
  validation loss:		0.457027
  validation accuracy:		92.72 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.003886
  validation loss:		0.454161
  validation accuracy:		92.72 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.003876
  validation loss:		0.460523
  validation accuracy:		92.72 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003892
  validation loss:		0.454673
  validation accuracy:		92.72 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003942
  validation loss:		0.457379
  validation accuracy:		92.93 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004013
  validation loss:		0.457840
  validation accuracy:		92.72 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.455724
  validation accuracy:		92.83 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.003968
  validation loss:		0.461632
  validation accuracy:		92.61 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.003880
  validation loss:		0.451756
  validation accuracy:		92.93 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.003892
  validation loss:		0.459861
  validation accuracy:		92.83 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003868
  validation loss:		0.450189
  validation accuracy:		92.93 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004011
  validation loss:		0.455623
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003766
  validation loss:		0.456942
  validation accuracy:		92.72 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.003933
  validation loss:		0.456878
  validation accuracy:		92.72 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.003897
  validation loss:		0.458718
  validation accuracy:		92.72 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003905
  validation loss:		0.455697
  validation accuracy:		92.83 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.003916
  validation loss:		0.456142
  validation accuracy:		92.83 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003763
  validation loss:		0.457765
  validation accuracy:		92.83 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.003978
  validation loss:		0.463136
  validation accuracy:		92.72 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.003829
  validation loss:		0.454600
  validation accuracy:		92.93 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.003857
  validation loss:		0.456699
  validation accuracy:		92.93 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.460538
  validation accuracy:		92.72 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003951
  validation loss:		0.451871
  validation accuracy:		92.93 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.003827
  validation loss:		0.457710
  validation accuracy:		92.83 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003796
  validation loss:		0.457759
  validation accuracy:		92.83 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.003868
  validation loss:		0.454025
  validation accuracy:		92.93 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003808
  validation loss:		0.461264
  validation accuracy:		92.72 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003794
  validation loss:		0.453270
  validation accuracy:		92.83 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003889
  validation loss:		0.455935
  validation accuracy:		92.93 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.459184
  validation accuracy:		92.83 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003851
  validation loss:		0.458301
  validation accuracy:		92.83 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003864
  validation loss:		0.457096
  validation accuracy:		92.93 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003827
  validation loss:		0.458839
  validation accuracy:		92.72 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.456485
  validation accuracy:		92.93 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003798
  validation loss:		0.465400
  validation accuracy:		92.72 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003806
  validation loss:		0.457226
  validation accuracy:		92.83 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.003766
  validation loss:		0.458729
  validation accuracy:		92.83 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003877
  validation loss:		0.462021
  validation accuracy:		92.72 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.459216
  validation accuracy:		92.93 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003741
  validation loss:		0.461731
  validation accuracy:		92.72 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003757
  validation loss:		0.456861
  validation accuracy:		92.83 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.457434
  validation accuracy:		92.83 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003849
  validation loss:		0.460350
  validation accuracy:		92.83 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003851
  validation loss:		0.455474
  validation accuracy:		92.83 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003775
  validation loss:		0.460187
  validation accuracy:		92.83 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003661
  validation loss:		0.459225
  validation accuracy:		92.93 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003594
  validation loss:		0.463535
  validation accuracy:		92.72 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.457310
  validation accuracy:		92.93 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003763
  validation loss:		0.466695
  validation accuracy:		92.61 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003842
  validation loss:		0.461631
  validation accuracy:		92.61 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003715
  validation loss:		0.459208
  validation accuracy:		92.93 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003601
  validation loss:		0.464234
  validation accuracy:		92.83 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003797
  validation loss:		0.461041
  validation accuracy:		92.72 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003654
  validation loss:		0.464802
  validation accuracy:		92.61 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003758
  validation loss:		0.461066
  validation accuracy:		92.93 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003653
  validation loss:		0.461218
  validation accuracy:		92.72 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.467546
  validation accuracy:		92.61 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003638
  validation loss:		0.460234
  validation accuracy:		92.83 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003660
  validation loss:		0.463388
  validation accuracy:		92.83 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003620
  validation loss:		0.463230
  validation accuracy:		92.72 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003605
  validation loss:		0.467121
  validation accuracy:		92.61 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003727
  validation loss:		0.459675
  validation accuracy:		92.83 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.463092
  validation accuracy:		92.93 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003581
  validation loss:		0.461479
  validation accuracy:		92.83 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003669
  validation loss:		0.464515
  validation accuracy:		92.93 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003599
  validation loss:		0.463504
  validation accuracy:		92.83 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003665
  validation loss:		0.463173
  validation accuracy:		92.83 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003489
  validation loss:		0.464821
  validation accuracy:		92.83 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003651
  validation loss:		0.466075
  validation accuracy:		92.72 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003591
  validation loss:		0.460498
  validation accuracy:		92.83 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003587
  validation loss:		0.460902
  validation accuracy:		92.93 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003597
  validation loss:		0.465010
  validation accuracy:		92.61 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003623
  validation loss:		0.459487
  validation accuracy:		92.83 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003644
  validation loss:		0.463932
  validation accuracy:		92.72 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003600
  validation loss:		0.461239
  validation accuracy:		92.83 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003646
  validation loss:		0.462541
  validation accuracy:		92.61 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003501
  validation loss:		0.464750
  validation accuracy:		92.83 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003550
  validation loss:		0.462227
  validation accuracy:		92.83 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.464101
  validation accuracy:		92.83 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003594
  validation loss:		0.464047
  validation accuracy:		92.83 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003552
  validation loss:		0.468444
  validation accuracy:		92.61 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003621
  validation loss:		0.464568
  validation accuracy:		92.72 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003593
  validation loss:		0.464254
  validation accuracy:		92.83 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.463685
  validation accuracy:		92.93 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003669
  validation loss:		0.466986
  validation accuracy:		92.61 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.466004
  validation accuracy:		92.83 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003535
  validation loss:		0.464213
  validation accuracy:		92.72 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003539
  validation loss:		0.466824
  validation accuracy:		92.83 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003551
  validation loss:		0.463974
  validation accuracy:		92.83 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.469838
  validation accuracy:		92.72 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.463376
  validation accuracy:		92.93 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003495
  validation loss:		0.468614
  validation accuracy:		92.93 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003465
  validation loss:		0.468814
  validation accuracy:		92.83 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003538
  validation loss:		0.472387
  validation accuracy:		92.61 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003518
  validation loss:		0.463701
  validation accuracy:		92.93 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003475
  validation loss:		0.461871
  validation accuracy:		92.83 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003577
  validation loss:		0.466483
  validation accuracy:		92.83 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003535
  validation loss:		0.469774
  validation accuracy:		92.61 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003450
  validation loss:		0.467151
  validation accuracy:		92.83 %
Epoch 1860 of 2000 took 0.036s
  training loss:		0.003466
  validation loss:		0.463669
  validation accuracy:		92.93 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003471
  validation loss:		0.465312
  validation accuracy:		92.61 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003436
  validation loss:		0.469486
  validation accuracy:		92.83 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003449
  validation loss:		0.468176
  validation accuracy:		92.83 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003362
  validation loss:		0.470798
  validation accuracy:		92.72 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003398
  validation loss:		0.461014
  validation accuracy:		92.83 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003487
  validation loss:		0.470058
  validation accuracy:		92.83 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003372
  validation loss:		0.467374
  validation accuracy:		92.93 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003375
  validation loss:		0.461004
  validation accuracy:		92.83 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003475
  validation loss:		0.470772
  validation accuracy:		92.61 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003362
  validation loss:		0.469328
  validation accuracy:		92.83 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003474
  validation loss:		0.473592
  validation accuracy:		92.72 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003354
  validation loss:		0.467753
  validation accuracy:		92.83 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003513
  validation loss:		0.469067
  validation accuracy:		92.83 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003293
  validation loss:		0.471008
  validation accuracy:		92.72 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003422
  validation loss:		0.469442
  validation accuracy:		92.83 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.471604
  validation accuracy:		92.72 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003510
  validation loss:		0.464721
  validation accuracy:		92.93 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003424
  validation loss:		0.466199
  validation accuracy:		92.83 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.470038
  validation accuracy:		92.72 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003472
  validation loss:		0.468468
  validation accuracy:		92.72 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003487
  validation loss:		0.468902
  validation accuracy:		92.72 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003316
  validation loss:		0.471613
  validation accuracy:		92.83 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003294
  validation loss:		0.472714
  validation accuracy:		92.83 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003434
  validation loss:		0.466611
  validation accuracy:		92.93 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003398
  validation loss:		0.472057
  validation accuracy:		92.72 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003483
  validation loss:		0.473331
  validation accuracy:		92.72 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003404
  validation loss:		0.468395
  validation accuracy:		92.72 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003437
  validation loss:		0.471824
  validation accuracy:		92.72 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003344
  validation loss:		0.469451
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003427
  validation loss:		0.473916
  validation accuracy:		92.72 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003445
  validation loss:		0.472793
  validation accuracy:		92.61 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003420
  validation loss:		0.466010
  validation accuracy:		92.93 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003328
  validation loss:		0.474546
  validation accuracy:		92.61 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.471021
  validation accuracy:		92.83 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003400
  validation loss:		0.472010
  validation accuracy:		92.83 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003377
  validation loss:		0.470862
  validation accuracy:		92.72 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003294
  validation loss:		0.476388
  validation accuracy:		92.83 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003383
  validation loss:		0.470050
  validation accuracy:		92.83 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003271
  validation loss:		0.470463
  validation accuracy:		92.72 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003329
  validation loss:		0.476798
  validation accuracy:		92.72 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003376
  validation loss:		0.469178
  validation accuracy:		92.83 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003329
  validation loss:		0.472276
  validation accuracy:		92.72 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003379
  validation loss:		0.473382
  validation accuracy:		92.72 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003393
  validation loss:		0.474540
  validation accuracy:		92.83 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003315
  validation loss:		0.469004
  validation accuracy:		92.83 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003352
  validation loss:		0.475319
  validation accuracy:		92.61 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003277
  validation loss:		0.470483
  validation accuracy:		92.83 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003296
  validation loss:		0.474005
  validation accuracy:		92.72 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003355
  validation loss:		0.472750
  validation accuracy:		92.83 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003341
  validation loss:		0.473731
  validation accuracy:		92.83 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003247
  validation loss:		0.470034
  validation accuracy:		92.93 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003362
  validation loss:		0.472693
  validation accuracy:		92.83 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003181
  validation loss:		0.472286
  validation accuracy:		92.83 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003322
  validation loss:		0.469829
  validation accuracy:		92.83 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003388
  validation loss:		0.477736
  validation accuracy:		92.83 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003402
  validation loss:		0.472330
  validation accuracy:		92.83 %
Epoch 1917 of 2000 took 0.036s
  training loss:		0.003322
  validation loss:		0.472517
  validation accuracy:		92.83 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003254
  validation loss:		0.470311
  validation accuracy:		92.72 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003228
  validation loss:		0.474036
  validation accuracy:		92.83 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003306
  validation loss:		0.472245
  validation accuracy:		92.83 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003253
  validation loss:		0.473498
  validation accuracy:		92.83 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003319
  validation loss:		0.475150
  validation accuracy:		92.61 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003228
  validation loss:		0.470428
  validation accuracy:		92.83 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.474096
  validation accuracy:		92.83 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003315
  validation loss:		0.478221
  validation accuracy:		92.83 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003186
  validation loss:		0.475497
  validation accuracy:		92.72 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003255
  validation loss:		0.480554
  validation accuracy:		92.83 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003275
  validation loss:		0.478774
  validation accuracy:		92.83 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.471999
  validation accuracy:		92.83 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003281
  validation loss:		0.476528
  validation accuracy:		92.72 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003263
  validation loss:		0.471802
  validation accuracy:		92.61 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003205
  validation loss:		0.475553
  validation accuracy:		92.72 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003154
  validation loss:		0.476351
  validation accuracy:		92.72 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003188
  validation loss:		0.473519
  validation accuracy:		92.72 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003226
  validation loss:		0.478638
  validation accuracy:		92.72 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003220
  validation loss:		0.482268
  validation accuracy:		92.50 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003144
  validation loss:		0.475760
  validation accuracy:		92.83 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003180
  validation loss:		0.476949
  validation accuracy:		92.83 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003183
  validation loss:		0.472390
  validation accuracy:		92.83 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003086
  validation loss:		0.478253
  validation accuracy:		92.83 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003154
  validation loss:		0.475209
  validation accuracy:		92.72 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003147
  validation loss:		0.476117
  validation accuracy:		92.83 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003123
  validation loss:		0.478080
  validation accuracy:		92.72 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003139
  validation loss:		0.474535
  validation accuracy:		92.83 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003280
  validation loss:		0.474987
  validation accuracy:		92.83 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003287
  validation loss:		0.475238
  validation accuracy:		92.83 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003269
  validation loss:		0.481060
  validation accuracy:		92.83 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003254
  validation loss:		0.479819
  validation accuracy:		92.72 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003066
  validation loss:		0.476386
  validation accuracy:		92.83 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003147
  validation loss:		0.481603
  validation accuracy:		92.72 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003175
  validation loss:		0.473283
  validation accuracy:		92.83 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003189
  validation loss:		0.480984
  validation accuracy:		92.61 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003137
  validation loss:		0.475681
  validation accuracy:		92.83 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003127
  validation loss:		0.480222
  validation accuracy:		92.61 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003178
  validation loss:		0.472378
  validation accuracy:		92.83 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003240
  validation loss:		0.475234
  validation accuracy:		92.83 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003140
  validation loss:		0.479328
  validation accuracy:		92.72 %
Epoch 1958 of 2000 took 0.036s
  training loss:		0.003179
  validation loss:		0.476850
  validation accuracy:		92.83 %
Epoch 1959 of 2000 took 0.037s
  training loss:		0.003219
  validation loss:		0.475276
  validation accuracy:		92.72 %
Epoch 1960 of 2000 took 0.036s
  training loss:		0.003152
  validation loss:		0.481814
  validation accuracy:		92.61 %
Epoch 1961 of 2000 took 0.036s
  training loss:		0.003127
  validation loss:		0.475934
  validation accuracy:		92.83 %
Epoch 1962 of 2000 took 0.036s
  training loss:		0.003251
  validation loss:		0.479302
  validation accuracy:		92.72 %
Epoch 1963 of 2000 took 0.036s
  training loss:		0.003100
  validation loss:		0.478988
  validation accuracy:		92.72 %
Epoch 1964 of 2000 took 0.036s
  training loss:		0.003097
  validation loss:		0.480396
  validation accuracy:		92.72 %
Epoch 1965 of 2000 took 0.036s
  training loss:		0.003142
  validation loss:		0.475201
  validation accuracy:		92.83 %
Epoch 1966 of 2000 took 0.036s
  training loss:		0.003127
  validation loss:		0.475925
  validation accuracy:		92.83 %
Epoch 1967 of 2000 took 0.036s
  training loss:		0.003065
  validation loss:		0.479786
  validation accuracy:		92.72 %
Epoch 1968 of 2000 took 0.036s
  training loss:		0.003093
  validation loss:		0.479572
  validation accuracy:		92.83 %
Epoch 1969 of 2000 took 0.036s
  training loss:		0.003147
  validation loss:		0.476426
  validation accuracy:		92.83 %
Epoch 1970 of 2000 took 0.036s
  training loss:		0.003106
  validation loss:		0.484193
  validation accuracy:		92.61 %
Epoch 1971 of 2000 took 0.036s
  training loss:		0.003009
  validation loss:		0.478841
  validation accuracy:		92.83 %
Epoch 1972 of 2000 took 0.037s
  training loss:		0.003138
  validation loss:		0.478692
  validation accuracy:		92.83 %
Epoch 1973 of 2000 took 0.037s
  training loss:		0.003027
  validation loss:		0.481578
  validation accuracy:		92.61 %
Epoch 1974 of 2000 took 0.036s
  training loss:		0.003139
  validation loss:		0.476187
  validation accuracy:		92.83 %
Epoch 1975 of 2000 took 0.036s
  training loss:		0.002939
  validation loss:		0.480201
  validation accuracy:		92.83 %
Epoch 1976 of 2000 took 0.036s
  training loss:		0.003081
  validation loss:		0.479989
  validation accuracy:		92.72 %
Epoch 1977 of 2000 took 0.036s
  training loss:		0.003034
  validation loss:		0.475513
  validation accuracy:		92.72 %
Epoch 1978 of 2000 took 0.036s
  training loss:		0.003136
  validation loss:		0.482853
  validation accuracy:		92.61 %
Epoch 1979 of 2000 took 0.036s
  training loss:		0.002967
  validation loss:		0.479053
  validation accuracy:		92.72 %
Epoch 1980 of 2000 took 0.036s
  training loss:		0.002969
  validation loss:		0.483702
  validation accuracy:		92.61 %
Epoch 1981 of 2000 took 0.036s
  training loss:		0.003040
  validation loss:		0.478279
  validation accuracy:		92.83 %
Epoch 1982 of 2000 took 0.036s
  training loss:		0.002996
  validation loss:		0.478185
  validation accuracy:		92.83 %
Epoch 1983 of 2000 took 0.036s
  training loss:		0.003013
  validation loss:		0.484746
  validation accuracy:		92.61 %
Epoch 1984 of 2000 took 0.036s
  training loss:		0.003060
  validation loss:		0.481252
  validation accuracy:		92.72 %
Epoch 1985 of 2000 took 0.036s
  training loss:		0.003041
  validation loss:		0.481816
  validation accuracy:		92.72 %
Epoch 1986 of 2000 took 0.036s
  training loss:		0.002979
  validation loss:		0.478779
  validation accuracy:		92.83 %
Epoch 1987 of 2000 took 0.036s
  training loss:		0.003050
  validation loss:		0.484910
  validation accuracy:		92.61 %
Epoch 1988 of 2000 took 0.036s
  training loss:		0.003050
  validation loss:		0.481929
  validation accuracy:		92.72 %
Epoch 1989 of 2000 took 0.036s
  training loss:		0.002968
  validation loss:		0.479115
  validation accuracy:		92.83 %
Epoch 1990 of 2000 took 0.036s
  training loss:		0.003090
  validation loss:		0.481678
  validation accuracy:		92.72 %
Epoch 1991 of 2000 took 0.036s
  training loss:		0.002943
  validation loss:		0.478307
  validation accuracy:		92.83 %
Epoch 1992 of 2000 took 0.036s
  training loss:		0.003012
  validation loss:		0.482571
  validation accuracy:		92.72 %
Epoch 1993 of 2000 took 0.036s
  training loss:		0.002990
  validation loss:		0.481214
  validation accuracy:		92.83 %
Epoch 1994 of 2000 took 0.036s
  training loss:		0.002981
  validation loss:		0.483206
  validation accuracy:		92.72 %
Epoch 1995 of 2000 took 0.036s
  training loss:		0.002967
  validation loss:		0.482038
  validation accuracy:		92.72 %
Epoch 1996 of 2000 took 0.036s
  training loss:		0.003080
  validation loss:		0.487595
  validation accuracy:		92.61 %
Epoch 1997 of 2000 took 0.036s
  training loss:		0.003037
  validation loss:		0.482916
  validation accuracy:		92.72 %
Epoch 1998 of 2000 took 0.036s
  training loss:		0.003009
  validation loss:		0.478652
  validation accuracy:		92.83 %
Epoch 1999 of 2000 took 0.036s
  training loss:		0.002969
  validation loss:		0.481970
  validation accuracy:		92.83 %
Epoch 2000 of 2000 took 0.036s
  training loss:		0.002972
  validation loss:		0.482452
  validation accuracy:		92.83 %
Final results:
  test loss:			1.155848
  test accuracy:		84.60 %
