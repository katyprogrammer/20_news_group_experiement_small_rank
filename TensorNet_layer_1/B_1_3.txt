Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.052s
  training loss:		2.961813
  validation loss:		2.881301
  validation accuracy:		12.93 %
Epoch 2 of 2000 took 0.043s
  training loss:		2.817075
  validation loss:		2.703304
  validation accuracy:		12.93 %
Epoch 3 of 2000 took 0.040s
  training loss:		2.647503
  validation loss:		2.518742
  validation accuracy:		12.93 %
Epoch 4 of 2000 took 0.037s
  training loss:		2.491613
  validation loss:		2.365260
  validation accuracy:		12.93 %
Epoch 5 of 2000 took 0.037s
  training loss:		2.381839
  validation loss:		2.270062
  validation accuracy:		23.59 %
Epoch 6 of 2000 took 0.037s
  training loss:		2.322769
  validation loss:		2.236643
  validation accuracy:		21.85 %
Epoch 7 of 2000 took 0.060s
  training loss:		2.292417
  validation loss:		2.233071
  validation accuracy:		38.04 %
Epoch 8 of 2000 took 0.048s
  training loss:		2.274581
  validation loss:		2.212083
  validation accuracy:		33.04 %
Epoch 9 of 2000 took 0.042s
  training loss:		2.263094
  validation loss:		2.199773
  validation accuracy:		36.20 %
Epoch 10 of 2000 took 0.041s
  training loss:		2.251809
  validation loss:		2.194582
  validation accuracy:		41.63 %
Epoch 11 of 2000 took 0.041s
  training loss:		2.242822
  validation loss:		2.177400
  validation accuracy:		43.26 %
Epoch 12 of 2000 took 0.041s
  training loss:		2.233223
  validation loss:		2.168671
  validation accuracy:		36.52 %
Epoch 13 of 2000 took 0.041s
  training loss:		2.224155
  validation loss:		2.159735
  validation accuracy:		44.67 %
Epoch 14 of 2000 took 0.041s
  training loss:		2.213011
  validation loss:		2.143348
  validation accuracy:		38.26 %
Epoch 15 of 2000 took 0.041s
  training loss:		2.202382
  validation loss:		2.140465
  validation accuracy:		45.98 %
Epoch 16 of 2000 took 0.041s
  training loss:		2.192009
  validation loss:		2.121441
  validation accuracy:		54.24 %
Epoch 17 of 2000 took 0.044s
  training loss:		2.178073
  validation loss:		2.102174
  validation accuracy:		55.54 %
Epoch 18 of 2000 took 0.041s
  training loss:		2.162914
  validation loss:		2.086418
  validation accuracy:		55.33 %
Epoch 19 of 2000 took 0.041s
  training loss:		2.144600
  validation loss:		2.070853
  validation accuracy:		55.11 %
Epoch 20 of 2000 took 0.041s
  training loss:		2.131822
  validation loss:		2.059995
  validation accuracy:		49.89 %
Epoch 21 of 2000 took 0.041s
  training loss:		2.111574
  validation loss:		2.031908
  validation accuracy:		58.26 %
Epoch 22 of 2000 took 0.041s
  training loss:		2.091258
  validation loss:		2.004002
  validation accuracy:		58.59 %
Epoch 23 of 2000 took 0.041s
  training loss:		2.071275
  validation loss:		1.982314
  validation accuracy:		61.52 %
Epoch 24 of 2000 took 0.041s
  training loss:		2.044917
  validation loss:		1.961126
  validation accuracy:		54.13 %
Epoch 25 of 2000 took 0.041s
  training loss:		2.015484
  validation loss:		1.927986
  validation accuracy:		63.70 %
Epoch 26 of 2000 took 0.041s
  training loss:		1.990664
  validation loss:		1.892069
  validation accuracy:		69.46 %
Epoch 27 of 2000 took 0.041s
  training loss:		1.961088
  validation loss:		1.861815
  validation accuracy:		63.26 %
Epoch 28 of 2000 took 0.041s
  training loss:		1.926185
  validation loss:		1.826271
  validation accuracy:		62.39 %
Epoch 29 of 2000 took 0.041s
  training loss:		1.895846
  validation loss:		1.790290
  validation accuracy:		65.43 %
Epoch 30 of 2000 took 0.041s
  training loss:		1.857870
  validation loss:		1.750926
  validation accuracy:		61.85 %
Epoch 31 of 2000 took 0.041s
  training loss:		1.821969
  validation loss:		1.711472
  validation accuracy:		69.57 %
Epoch 32 of 2000 took 0.039s
  training loss:		1.784718
  validation loss:		1.671349
  validation accuracy:		70.54 %
Epoch 33 of 2000 took 0.036s
  training loss:		1.739897
  validation loss:		1.619378
  validation accuracy:		74.46 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.699787
  validation loss:		1.581304
  validation accuracy:		74.35 %
Epoch 35 of 2000 took 0.035s
  training loss:		1.656355
  validation loss:		1.538798
  validation accuracy:		76.52 %
Epoch 36 of 2000 took 0.035s
  training loss:		1.606576
  validation loss:		1.479275
  validation accuracy:		73.80 %
Epoch 37 of 2000 took 0.035s
  training loss:		1.556594
  validation loss:		1.425452
  validation accuracy:		77.72 %
Epoch 38 of 2000 took 0.035s
  training loss:		1.504201
  validation loss:		1.371756
  validation accuracy:		75.76 %
Epoch 39 of 2000 took 0.035s
  training loss:		1.454898
  validation loss:		1.325752
  validation accuracy:		79.02 %
Epoch 40 of 2000 took 0.035s
  training loss:		1.404825
  validation loss:		1.275234
  validation accuracy:		77.50 %
Epoch 41 of 2000 took 0.035s
  training loss:		1.351409
  validation loss:		1.223743
  validation accuracy:		79.46 %
Epoch 42 of 2000 took 0.035s
  training loss:		1.296543
  validation loss:		1.168041
  validation accuracy:		79.89 %
Epoch 43 of 2000 took 0.035s
  training loss:		1.249268
  validation loss:		1.123234
  validation accuracy:		80.87 %
Epoch 44 of 2000 took 0.035s
  training loss:		1.199497
  validation loss:		1.069421
  validation accuracy:		82.50 %
Epoch 45 of 2000 took 0.035s
  training loss:		1.150929
  validation loss:		1.025401
  validation accuracy:		80.65 %
Epoch 46 of 2000 took 0.035s
  training loss:		1.110140
  validation loss:		0.985365
  validation accuracy:		81.85 %
Epoch 47 of 2000 took 0.035s
  training loss:		1.063852
  validation loss:		0.939765
  validation accuracy:		83.80 %
Epoch 48 of 2000 took 0.035s
  training loss:		1.015067
  validation loss:		0.901054
  validation accuracy:		84.67 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.979666
  validation loss:		0.869803
  validation accuracy:		84.67 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.940279
  validation loss:		0.828569
  validation accuracy:		85.43 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.913210
  validation loss:		0.810622
  validation accuracy:		86.09 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.881656
  validation loss:		0.778617
  validation accuracy:		86.41 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.851555
  validation loss:		0.761607
  validation accuracy:		85.87 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.829002
  validation loss:		0.734025
  validation accuracy:		85.65 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.799129
  validation loss:		0.709276
  validation accuracy:		86.74 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.777076
  validation loss:		0.695302
  validation accuracy:		85.87 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.752392
  validation loss:		0.669477
  validation accuracy:		87.07 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.734284
  validation loss:		0.658953
  validation accuracy:		86.52 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.716564
  validation loss:		0.637215
  validation accuracy:		87.39 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.698460
  validation loss:		0.628255
  validation accuracy:		86.52 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.686381
  validation loss:		0.610646
  validation accuracy:		87.72 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.667866
  validation loss:		0.597243
  validation accuracy:		86.52 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.653203
  validation loss:		0.582294
  validation accuracy:		87.61 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.632078
  validation loss:		0.566307
  validation accuracy:		86.52 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.618816
  validation loss:		0.564391
  validation accuracy:		87.28 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.610009
  validation loss:		0.549099
  validation accuracy:		87.28 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.590062
  validation loss:		0.528965
  validation accuracy:		87.93 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.574295
  validation loss:		0.529185
  validation accuracy:		87.07 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.568557
  validation loss:		0.515091
  validation accuracy:		87.61 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.549643
  validation loss:		0.499323
  validation accuracy:		87.50 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.546826
  validation loss:		0.502696
  validation accuracy:		87.17 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.534792
  validation loss:		0.487416
  validation accuracy:		88.37 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.520354
  validation loss:		0.471766
  validation accuracy:		87.61 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.512513
  validation loss:		0.466135
  validation accuracy:		88.59 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.496334
  validation loss:		0.461642
  validation accuracy:		88.37 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.489451
  validation loss:		0.448090
  validation accuracy:		88.48 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.475665
  validation loss:		0.445120
  validation accuracy:		89.24 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.469592
  validation loss:		0.443323
  validation accuracy:		89.13 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.460101
  validation loss:		0.425958
  validation accuracy:		89.24 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.450847
  validation loss:		0.425086
  validation accuracy:		88.80 %
Epoch 81 of 2000 took 0.037s
  training loss:		0.443134
  validation loss:		0.405203
  validation accuracy:		89.78 %
Epoch 82 of 2000 took 0.036s
  training loss:		0.433679
  validation loss:		0.410519
  validation accuracy:		90.11 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.429304
  validation loss:		0.397632
  validation accuracy:		89.35 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.421221
  validation loss:		0.388883
  validation accuracy:		89.89 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.410409
  validation loss:		0.379834
  validation accuracy:		90.00 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.400001
  validation loss:		0.379568
  validation accuracy:		89.89 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.393856
  validation loss:		0.373347
  validation accuracy:		90.33 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.389158
  validation loss:		0.370251
  validation accuracy:		90.76 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.378495
  validation loss:		0.361575
  validation accuracy:		91.20 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.377036
  validation loss:		0.360749
  validation accuracy:		91.09 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.367485
  validation loss:		0.344913
  validation accuracy:		91.30 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.365626
  validation loss:		0.346612
  validation accuracy:		91.30 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.356523
  validation loss:		0.338625
  validation accuracy:		91.52 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.350965
  validation loss:		0.337593
  validation accuracy:		91.96 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.345348
  validation loss:		0.331524
  validation accuracy:		92.07 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.338741
  validation loss:		0.329372
  validation accuracy:		91.52 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.329763
  validation loss:		0.321161
  validation accuracy:		91.96 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.331079
  validation loss:		0.323657
  validation accuracy:		92.07 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.322504
  validation loss:		0.313897
  validation accuracy:		91.96 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.317024
  validation loss:		0.309149
  validation accuracy:		92.17 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.313778
  validation loss:		0.308377
  validation accuracy:		92.61 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.312072
  validation loss:		0.303611
  validation accuracy:		92.61 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.303139
  validation loss:		0.305934
  validation accuracy:		92.50 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.302836
  validation loss:		0.296279
  validation accuracy:		92.83 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.299037
  validation loss:		0.295709
  validation accuracy:		92.39 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.293162
  validation loss:		0.291263
  validation accuracy:		92.39 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.294397
  validation loss:		0.296728
  validation accuracy:		92.83 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.285852
  validation loss:		0.285603
  validation accuracy:		92.72 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.285671
  validation loss:		0.288427
  validation accuracy:		92.07 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.283422
  validation loss:		0.282603
  validation accuracy:		92.83 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.279285
  validation loss:		0.275762
  validation accuracy:		92.83 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.271342
  validation loss:		0.280156
  validation accuracy:		93.26 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.267168
  validation loss:		0.274150
  validation accuracy:		93.26 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.268337
  validation loss:		0.268242
  validation accuracy:		92.72 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.264811
  validation loss:		0.270530
  validation accuracy:		92.83 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.264381
  validation loss:		0.283282
  validation accuracy:		92.61 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.260449
  validation loss:		0.267656
  validation accuracy:		93.15 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.255575
  validation loss:		0.263568
  validation accuracy:		93.15 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.256158
  validation loss:		0.263765
  validation accuracy:		93.48 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.253070
  validation loss:		0.253876
  validation accuracy:		93.59 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.250251
  validation loss:		0.255118
  validation accuracy:		93.48 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.249016
  validation loss:		0.253499
  validation accuracy:		93.37 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.248474
  validation loss:		0.254487
  validation accuracy:		93.70 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.243668
  validation loss:		0.253264
  validation accuracy:		93.59 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.240911
  validation loss:		0.252203
  validation accuracy:		93.70 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.242516
  validation loss:		0.242310
  validation accuracy:		94.35 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.231725
  validation loss:		0.249154
  validation accuracy:		93.59 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.237321
  validation loss:		0.254208
  validation accuracy:		93.37 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.235434
  validation loss:		0.242213
  validation accuracy:		93.80 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.231979
  validation loss:		0.243092
  validation accuracy:		93.48 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.229419
  validation loss:		0.252494
  validation accuracy:		93.70 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.231936
  validation loss:		0.244842
  validation accuracy:		94.13 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.221859
  validation loss:		0.241092
  validation accuracy:		93.48 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.225155
  validation loss:		0.243464
  validation accuracy:		93.91 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.225121
  validation loss:		0.242953
  validation accuracy:		93.91 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.218103
  validation loss:		0.238056
  validation accuracy:		93.80 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.214080
  validation loss:		0.239827
  validation accuracy:		93.70 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.218350
  validation loss:		0.241018
  validation accuracy:		93.80 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.215579
  validation loss:		0.230375
  validation accuracy:		93.91 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.211120
  validation loss:		0.236199
  validation accuracy:		93.80 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.213499
  validation loss:		0.235206
  validation accuracy:		94.02 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.212039
  validation loss:		0.240565
  validation accuracy:		93.59 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.211763
  validation loss:		0.231867
  validation accuracy:		93.80 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.207761
  validation loss:		0.229004
  validation accuracy:		94.13 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.210324
  validation loss:		0.229503
  validation accuracy:		93.80 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.201932
  validation loss:		0.225148
  validation accuracy:		93.91 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.209610
  validation loss:		0.229140
  validation accuracy:		94.24 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.203119
  validation loss:		0.218139
  validation accuracy:		94.13 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.206195
  validation loss:		0.225097
  validation accuracy:		93.80 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.202884
  validation loss:		0.231626
  validation accuracy:		94.24 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.197445
  validation loss:		0.220847
  validation accuracy:		93.80 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.197609
  validation loss:		0.219479
  validation accuracy:		93.91 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.198745
  validation loss:		0.224330
  validation accuracy:		94.24 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.198192
  validation loss:		0.218623
  validation accuracy:		93.91 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.198193
  validation loss:		0.223759
  validation accuracy:		93.91 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.197141
  validation loss:		0.217691
  validation accuracy:		94.13 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.192949
  validation loss:		0.213070
  validation accuracy:		93.91 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.192096
  validation loss:		0.230633
  validation accuracy:		94.13 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.190628
  validation loss:		0.214500
  validation accuracy:		94.13 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.191124
  validation loss:		0.218424
  validation accuracy:		94.35 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.187602
  validation loss:		0.215018
  validation accuracy:		93.80 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.186204
  validation loss:		0.214213
  validation accuracy:		94.02 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.188198
  validation loss:		0.221055
  validation accuracy:		94.35 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.190740
  validation loss:		0.221155
  validation accuracy:		94.35 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.183799
  validation loss:		0.212635
  validation accuracy:		94.24 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.182440
  validation loss:		0.219641
  validation accuracy:		94.57 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.185144
  validation loss:		0.216324
  validation accuracy:		93.70 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.181366
  validation loss:		0.214278
  validation accuracy:		94.46 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.179728
  validation loss:		0.211798
  validation accuracy:		94.13 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.181161
  validation loss:		0.209285
  validation accuracy:		94.35 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.178823
  validation loss:		0.212202
  validation accuracy:		94.35 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.180130
  validation loss:		0.214481
  validation accuracy:		94.13 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.177962
  validation loss:		0.204841
  validation accuracy:		94.35 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.177219
  validation loss:		0.206788
  validation accuracy:		94.13 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.177091
  validation loss:		0.212617
  validation accuracy:		94.35 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.173295
  validation loss:		0.207110
  validation accuracy:		94.02 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.168251
  validation loss:		0.211445
  validation accuracy:		94.02 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.172278
  validation loss:		0.207942
  validation accuracy:		94.35 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.175351
  validation loss:		0.201364
  validation accuracy:		94.13 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.171596
  validation loss:		0.208553
  validation accuracy:		94.35 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.168036
  validation loss:		0.201604
  validation accuracy:		93.91 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.169944
  validation loss:		0.206402
  validation accuracy:		94.24 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.163682
  validation loss:		0.206996
  validation accuracy:		94.02 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.166904
  validation loss:		0.207962
  validation accuracy:		94.13 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.163974
  validation loss:		0.205608
  validation accuracy:		94.13 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.168542
  validation loss:		0.207667
  validation accuracy:		93.80 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.162506
  validation loss:		0.204594
  validation accuracy:		94.13 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.161817
  validation loss:		0.201926
  validation accuracy:		94.46 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.166589
  validation loss:		0.203951
  validation accuracy:		94.13 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.162669
  validation loss:		0.201081
  validation accuracy:		94.35 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.164208
  validation loss:		0.209538
  validation accuracy:		94.13 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.163339
  validation loss:		0.202365
  validation accuracy:		94.35 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.159389
  validation loss:		0.216336
  validation accuracy:		94.02 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.161588
  validation loss:		0.201677
  validation accuracy:		94.46 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.157826
  validation loss:		0.202633
  validation accuracy:		93.91 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.158938
  validation loss:		0.202664
  validation accuracy:		94.57 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.158740
  validation loss:		0.201479
  validation accuracy:		94.35 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.154989
  validation loss:		0.201538
  validation accuracy:		94.24 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.152949
  validation loss:		0.198410
  validation accuracy:		94.35 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.158020
  validation loss:		0.198958
  validation accuracy:		94.35 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.155109
  validation loss:		0.201417
  validation accuracy:		94.46 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.157826
  validation loss:		0.201965
  validation accuracy:		94.57 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.153684
  validation loss:		0.197698
  validation accuracy:		94.67 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.153865
  validation loss:		0.204972
  validation accuracy:		94.67 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.153763
  validation loss:		0.197376
  validation accuracy:		94.35 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.148649
  validation loss:		0.200677
  validation accuracy:		94.57 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.150620
  validation loss:		0.195138
  validation accuracy:		94.24 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.150551
  validation loss:		0.200882
  validation accuracy:		94.35 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.147310
  validation loss:		0.199855
  validation accuracy:		94.46 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.152564
  validation loss:		0.198650
  validation accuracy:		94.35 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.150332
  validation loss:		0.199178
  validation accuracy:		94.67 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.146573
  validation loss:		0.194973
  validation accuracy:		94.24 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.147740
  validation loss:		0.198656
  validation accuracy:		94.35 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.146530
  validation loss:		0.201774
  validation accuracy:		94.57 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.148158
  validation loss:		0.203642
  validation accuracy:		94.35 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.147549
  validation loss:		0.201322
  validation accuracy:		94.46 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.147000
  validation loss:		0.202128
  validation accuracy:		94.35 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.144568
  validation loss:		0.197783
  validation accuracy:		94.46 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.146939
  validation loss:		0.201277
  validation accuracy:		94.57 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.140604
  validation loss:		0.194089
  validation accuracy:		94.24 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.146239
  validation loss:		0.195702
  validation accuracy:		94.46 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.144694
  validation loss:		0.200971
  validation accuracy:		94.57 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.144548
  validation loss:		0.194812
  validation accuracy:		94.24 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.141600
  validation loss:		0.199468
  validation accuracy:		94.57 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.144132
  validation loss:		0.195391
  validation accuracy:		94.35 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.144728
  validation loss:		0.193197
  validation accuracy:		94.46 %
Epoch 227 of 2000 took 0.036s
  training loss:		0.138180
  validation loss:		0.199206
  validation accuracy:		94.35 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.141364
  validation loss:		0.197883
  validation accuracy:		94.46 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.138084
  validation loss:		0.194337
  validation accuracy:		94.46 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.136509
  validation loss:		0.196592
  validation accuracy:		94.57 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.139457
  validation loss:		0.202296
  validation accuracy:		94.46 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.141754
  validation loss:		0.195433
  validation accuracy:		94.46 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.134264
  validation loss:		0.198090
  validation accuracy:		94.46 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.139669
  validation loss:		0.197003
  validation accuracy:		94.35 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.137365
  validation loss:		0.196511
  validation accuracy:		94.57 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.135614
  validation loss:		0.197291
  validation accuracy:		94.57 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.137287
  validation loss:		0.196704
  validation accuracy:		94.46 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.134705
  validation loss:		0.198821
  validation accuracy:		94.67 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.136713
  validation loss:		0.195421
  validation accuracy:		94.46 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.136613
  validation loss:		0.194453
  validation accuracy:		94.46 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.137148
  validation loss:		0.196308
  validation accuracy:		94.67 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.133455
  validation loss:		0.196760
  validation accuracy:		94.35 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.136734
  validation loss:		0.196234
  validation accuracy:		94.46 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.131456
  validation loss:		0.198329
  validation accuracy:		94.35 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.131258
  validation loss:		0.200577
  validation accuracy:		94.35 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.130382
  validation loss:		0.196059
  validation accuracy:		94.67 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.132489
  validation loss:		0.201257
  validation accuracy:		94.46 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.130390
  validation loss:		0.195364
  validation accuracy:		94.35 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.128960
  validation loss:		0.194511
  validation accuracy:		94.57 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.129531
  validation loss:		0.194242
  validation accuracy:		94.67 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.130794
  validation loss:		0.193532
  validation accuracy:		94.57 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.133154
  validation loss:		0.197993
  validation accuracy:		94.24 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.129000
  validation loss:		0.198669
  validation accuracy:		94.57 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.123459
  validation loss:		0.197453
  validation accuracy:		94.46 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.125819
  validation loss:		0.196933
  validation accuracy:		94.35 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.126723
  validation loss:		0.195746
  validation accuracy:		94.57 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.128965
  validation loss:		0.195470
  validation accuracy:		94.46 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.124754
  validation loss:		0.197194
  validation accuracy:		94.46 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.127937
  validation loss:		0.201404
  validation accuracy:		94.35 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.128025
  validation loss:		0.195949
  validation accuracy:		94.57 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.123982
  validation loss:		0.196929
  validation accuracy:		94.35 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.124781
  validation loss:		0.197516
  validation accuracy:		94.35 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.128089
  validation loss:		0.197364
  validation accuracy:		94.46 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.123241
  validation loss:		0.197002
  validation accuracy:		94.46 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.125462
  validation loss:		0.198893
  validation accuracy:		94.57 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.120901
  validation loss:		0.197834
  validation accuracy:		94.57 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.124259
  validation loss:		0.201382
  validation accuracy:		94.35 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.124078
  validation loss:		0.197744
  validation accuracy:		94.57 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.121080
  validation loss:		0.193326
  validation accuracy:		94.67 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.121871
  validation loss:		0.199153
  validation accuracy:		94.35 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.121025
  validation loss:		0.200506
  validation accuracy:		94.46 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.121673
  validation loss:		0.195303
  validation accuracy:		94.24 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.121855
  validation loss:		0.195452
  validation accuracy:		94.46 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.121810
  validation loss:		0.199289
  validation accuracy:		94.35 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.122404
  validation loss:		0.204190
  validation accuracy:		94.46 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.118761
  validation loss:		0.196925
  validation accuracy:		94.24 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.121160
  validation loss:		0.202131
  validation accuracy:		94.24 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.117062
  validation loss:		0.194546
  validation accuracy:		94.46 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.120595
  validation loss:		0.198525
  validation accuracy:		94.46 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.119250
  validation loss:		0.202357
  validation accuracy:		94.13 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.117002
  validation loss:		0.201969
  validation accuracy:		94.57 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.117008
  validation loss:		0.201132
  validation accuracy:		94.35 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.115105
  validation loss:		0.195077
  validation accuracy:		94.46 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.118992
  validation loss:		0.198681
  validation accuracy:		94.35 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.115815
  validation loss:		0.193799
  validation accuracy:		94.78 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.113944
  validation loss:		0.198400
  validation accuracy:		93.91 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.110909
  validation loss:		0.197604
  validation accuracy:		94.35 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.115289
  validation loss:		0.199911
  validation accuracy:		94.46 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.113514
  validation loss:		0.202120
  validation accuracy:		94.35 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.116878
  validation loss:		0.195301
  validation accuracy:		94.24 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.115876
  validation loss:		0.195024
  validation accuracy:		94.78 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.112971
  validation loss:		0.198499
  validation accuracy:		94.67 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.114039
  validation loss:		0.200086
  validation accuracy:		94.13 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.114485
  validation loss:		0.198725
  validation accuracy:		94.57 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.111662
  validation loss:		0.197638
  validation accuracy:		94.46 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.112662
  validation loss:		0.201234
  validation accuracy:		94.78 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.114260
  validation loss:		0.198110
  validation accuracy:		94.24 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.111863
  validation loss:		0.204115
  validation accuracy:		94.24 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.109223
  validation loss:		0.198908
  validation accuracy:		94.67 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.110843
  validation loss:		0.198786
  validation accuracy:		94.35 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.112312
  validation loss:		0.203444
  validation accuracy:		93.91 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.109215
  validation loss:		0.203637
  validation accuracy:		94.24 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.110812
  validation loss:		0.199944
  validation accuracy:		94.13 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.109449
  validation loss:		0.204447
  validation accuracy:		94.35 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.109290
  validation loss:		0.199520
  validation accuracy:		94.24 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.106760
  validation loss:		0.206228
  validation accuracy:		93.70 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.113041
  validation loss:		0.206132
  validation accuracy:		94.24 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.110557
  validation loss:		0.202287
  validation accuracy:		94.35 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.109946
  validation loss:		0.203223
  validation accuracy:		94.46 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.109617
  validation loss:		0.202682
  validation accuracy:		94.02 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.108240
  validation loss:		0.205530
  validation accuracy:		94.02 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.106484
  validation loss:		0.204099
  validation accuracy:		94.35 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.102401
  validation loss:		0.203459
  validation accuracy:		93.91 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.106841
  validation loss:		0.202085
  validation accuracy:		94.46 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.104326
  validation loss:		0.213382
  validation accuracy:		94.02 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.107527
  validation loss:		0.197787
  validation accuracy:		94.46 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.105222
  validation loss:		0.201764
  validation accuracy:		94.35 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.107452
  validation loss:		0.203341
  validation accuracy:		94.02 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.105416
  validation loss:		0.198743
  validation accuracy:		94.24 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.105785
  validation loss:		0.202371
  validation accuracy:		94.13 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.104950
  validation loss:		0.206315
  validation accuracy:		94.57 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.103991
  validation loss:		0.199995
  validation accuracy:		94.13 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.101980
  validation loss:		0.200164
  validation accuracy:		94.57 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.104493
  validation loss:		0.201468
  validation accuracy:		94.13 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.105470
  validation loss:		0.203057
  validation accuracy:		94.13 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.103033
  validation loss:		0.207017
  validation accuracy:		94.02 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.100564
  validation loss:		0.207907
  validation accuracy:		94.13 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.099720
  validation loss:		0.200521
  validation accuracy:		94.57 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.102272
  validation loss:		0.205418
  validation accuracy:		94.78 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.103859
  validation loss:		0.203153
  validation accuracy:		94.02 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.100669
  validation loss:		0.209729
  validation accuracy:		93.70 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.099496
  validation loss:		0.200979
  validation accuracy:		94.67 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.099655
  validation loss:		0.202438
  validation accuracy:		94.24 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.099768
  validation loss:		0.209916
  validation accuracy:		94.24 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.100135
  validation loss:		0.203208
  validation accuracy:		94.13 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.101063
  validation loss:		0.205346
  validation accuracy:		94.35 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.099817
  validation loss:		0.205450
  validation accuracy:		94.57 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.099477
  validation loss:		0.206848
  validation accuracy:		93.80 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.097127
  validation loss:		0.209675
  validation accuracy:		94.35 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.100045
  validation loss:		0.204051
  validation accuracy:		94.24 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.098053
  validation loss:		0.201745
  validation accuracy:		94.46 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.099119
  validation loss:		0.203430
  validation accuracy:		94.35 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.095626
  validation loss:		0.205191
  validation accuracy:		94.24 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.097740
  validation loss:		0.209099
  validation accuracy:		93.48 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.097732
  validation loss:		0.203287
  validation accuracy:		94.35 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.096691
  validation loss:		0.206246
  validation accuracy:		94.46 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.097695
  validation loss:		0.202250
  validation accuracy:		94.57 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.097713
  validation loss:		0.206247
  validation accuracy:		94.57 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.097813
  validation loss:		0.206952
  validation accuracy:		94.24 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.094308
  validation loss:		0.203168
  validation accuracy:		94.57 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.095238
  validation loss:		0.208544
  validation accuracy:		94.02 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.096539
  validation loss:		0.207896
  validation accuracy:		94.24 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.092353
  validation loss:		0.208018
  validation accuracy:		94.24 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.096691
  validation loss:		0.202243
  validation accuracy:		94.24 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.096878
  validation loss:		0.210483
  validation accuracy:		94.13 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.094699
  validation loss:		0.203928
  validation accuracy:		94.24 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.091883
  validation loss:		0.207997
  validation accuracy:		94.46 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.093248
  validation loss:		0.206329
  validation accuracy:		94.24 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.092720
  validation loss:		0.209468
  validation accuracy:		94.13 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.093160
  validation loss:		0.211291
  validation accuracy:		94.13 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.094271
  validation loss:		0.204919
  validation accuracy:		94.46 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.090531
  validation loss:		0.205847
  validation accuracy:		94.35 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.093892
  validation loss:		0.210339
  validation accuracy:		94.13 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.090576
  validation loss:		0.212650
  validation accuracy:		93.91 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.094032
  validation loss:		0.208034
  validation accuracy:		94.13 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.093736
  validation loss:		0.210391
  validation accuracy:		94.46 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.092508
  validation loss:		0.209801
  validation accuracy:		93.91 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.090970
  validation loss:		0.213636
  validation accuracy:		93.59 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.090394
  validation loss:		0.215969
  validation accuracy:		94.24 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.088971
  validation loss:		0.217887
  validation accuracy:		93.70 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.089011
  validation loss:		0.217814
  validation accuracy:		93.80 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.088465
  validation loss:		0.205017
  validation accuracy:		94.67 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.090462
  validation loss:		0.210515
  validation accuracy:		94.24 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.091133
  validation loss:		0.212023
  validation accuracy:		94.35 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.090775
  validation loss:		0.205042
  validation accuracy:		94.57 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.089344
  validation loss:		0.214031
  validation accuracy:		94.35 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.088813
  validation loss:		0.212602
  validation accuracy:		93.59 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.088321
  validation loss:		0.211021
  validation accuracy:		94.46 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.085650
  validation loss:		0.216459
  validation accuracy:		93.91 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.089087
  validation loss:		0.211185
  validation accuracy:		94.02 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.087304
  validation loss:		0.212009
  validation accuracy:		94.13 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.088704
  validation loss:		0.210674
  validation accuracy:		94.24 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.089868
  validation loss:		0.210798
  validation accuracy:		94.35 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.085000
  validation loss:		0.209921
  validation accuracy:		93.80 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.084168
  validation loss:		0.209820
  validation accuracy:		94.46 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.085327
  validation loss:		0.220980
  validation accuracy:		93.80 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.087062
  validation loss:		0.213282
  validation accuracy:		93.70 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.088140
  validation loss:		0.207787
  validation accuracy:		94.57 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.088286
  validation loss:		0.215397
  validation accuracy:		94.13 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.085505
  validation loss:		0.207040
  validation accuracy:		94.46 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.086250
  validation loss:		0.208955
  validation accuracy:		94.35 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.084909
  validation loss:		0.214426
  validation accuracy:		93.70 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.084948
  validation loss:		0.214365
  validation accuracy:		93.91 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.084514
  validation loss:		0.211489
  validation accuracy:		94.02 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.086705
  validation loss:		0.213491
  validation accuracy:		94.46 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.083148
  validation loss:		0.207307
  validation accuracy:		94.67 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.085357
  validation loss:		0.212336
  validation accuracy:		94.24 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.083192
  validation loss:		0.215066
  validation accuracy:		93.91 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.081979
  validation loss:		0.214007
  validation accuracy:		93.70 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.084843
  validation loss:		0.210263
  validation accuracy:		94.24 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.079646
  validation loss:		0.225838
  validation accuracy:		94.02 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.085026
  validation loss:		0.209695
  validation accuracy:		94.35 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.083083
  validation loss:		0.213752
  validation accuracy:		94.13 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.080438
  validation loss:		0.214617
  validation accuracy:		93.59 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.080742
  validation loss:		0.214101
  validation accuracy:		94.24 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.083767
  validation loss:		0.214427
  validation accuracy:		93.59 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.081288
  validation loss:		0.211675
  validation accuracy:		94.35 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.081792
  validation loss:		0.214131
  validation accuracy:		94.02 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.080707
  validation loss:		0.218863
  validation accuracy:		93.80 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.082694
  validation loss:		0.214860
  validation accuracy:		93.70 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.081172
  validation loss:		0.211804
  validation accuracy:		94.13 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.081474
  validation loss:		0.211984
  validation accuracy:		94.02 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.079623
  validation loss:		0.224491
  validation accuracy:		94.13 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.082338
  validation loss:		0.215294
  validation accuracy:		94.24 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.081443
  validation loss:		0.213432
  validation accuracy:		94.24 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.082922
  validation loss:		0.214262
  validation accuracy:		94.13 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.080679
  validation loss:		0.216104
  validation accuracy:		94.35 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.079241
  validation loss:		0.217435
  validation accuracy:		93.91 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.077444
  validation loss:		0.216315
  validation accuracy:		93.91 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.078313
  validation loss:		0.218140
  validation accuracy:		93.91 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.079263
  validation loss:		0.214280
  validation accuracy:		94.46 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.076180
  validation loss:		0.214279
  validation accuracy:		94.02 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.077107
  validation loss:		0.219808
  validation accuracy:		93.70 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.076882
  validation loss:		0.216629
  validation accuracy:		93.91 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.077338
  validation loss:		0.214586
  validation accuracy:		93.91 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.077426
  validation loss:		0.215648
  validation accuracy:		93.91 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.079473
  validation loss:		0.213352
  validation accuracy:		94.24 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.077967
  validation loss:		0.221430
  validation accuracy:		94.24 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.077662
  validation loss:		0.223057
  validation accuracy:		93.59 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.077151
  validation loss:		0.222599
  validation accuracy:		93.91 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.078187
  validation loss:		0.220323
  validation accuracy:		94.13 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.075171
  validation loss:		0.220894
  validation accuracy:		94.24 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.076927
  validation loss:		0.223535
  validation accuracy:		94.02 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.075643
  validation loss:		0.225103
  validation accuracy:		93.80 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.075605
  validation loss:		0.218834
  validation accuracy:		94.13 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.074547
  validation loss:		0.220430
  validation accuracy:		94.35 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.077746
  validation loss:		0.221860
  validation accuracy:		94.24 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.074727
  validation loss:		0.222387
  validation accuracy:		93.91 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.074449
  validation loss:		0.220202
  validation accuracy:		94.24 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.074036
  validation loss:		0.222261
  validation accuracy:		94.02 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.070600
  validation loss:		0.217493
  validation accuracy:		93.91 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.073679
  validation loss:		0.226139
  validation accuracy:		93.80 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.075262
  validation loss:		0.224098
  validation accuracy:		93.59 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.073566
  validation loss:		0.219396
  validation accuracy:		94.02 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.074504
  validation loss:		0.218016
  validation accuracy:		93.91 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.073852
  validation loss:		0.223943
  validation accuracy:		93.59 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.073468
  validation loss:		0.232138
  validation accuracy:		93.70 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.074079
  validation loss:		0.229201
  validation accuracy:		93.70 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.073155
  validation loss:		0.222029
  validation accuracy:		93.80 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.072176
  validation loss:		0.224305
  validation accuracy:		94.02 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.072791
  validation loss:		0.234076
  validation accuracy:		94.02 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.071835
  validation loss:		0.218186
  validation accuracy:		94.13 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.070354
  validation loss:		0.224061
  validation accuracy:		93.80 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.074320
  validation loss:		0.218085
  validation accuracy:		94.24 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.073605
  validation loss:		0.225205
  validation accuracy:		93.70 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.070655
  validation loss:		0.227238
  validation accuracy:		93.59 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.070194
  validation loss:		0.223218
  validation accuracy:		93.80 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.072610
  validation loss:		0.224544
  validation accuracy:		93.80 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.069475
  validation loss:		0.226749
  validation accuracy:		93.70 %
Epoch 460 of 2000 took 0.036s
  training loss:		0.071989
  validation loss:		0.231719
  validation accuracy:		93.80 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.069325
  validation loss:		0.231417
  validation accuracy:		93.91 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.071069
  validation loss:		0.220156
  validation accuracy:		94.35 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.069473
  validation loss:		0.227662
  validation accuracy:		94.02 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.070675
  validation loss:		0.223072
  validation accuracy:		94.13 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.070131
  validation loss:		0.231977
  validation accuracy:		94.02 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.069239
  validation loss:		0.223661
  validation accuracy:		93.70 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.067509
  validation loss:		0.223498
  validation accuracy:		94.13 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.068227
  validation loss:		0.226166
  validation accuracy:		93.59 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.067706
  validation loss:		0.225433
  validation accuracy:		93.80 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.068268
  validation loss:		0.226316
  validation accuracy:		94.02 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.067916
  validation loss:		0.231809
  validation accuracy:		93.70 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.068225
  validation loss:		0.228309
  validation accuracy:		93.80 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.069196
  validation loss:		0.227236
  validation accuracy:		94.13 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.067888
  validation loss:		0.228195
  validation accuracy:		94.13 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.068411
  validation loss:		0.231710
  validation accuracy:		93.80 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.069006
  validation loss:		0.230190
  validation accuracy:		93.70 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.068173
  validation loss:		0.225765
  validation accuracy:		93.70 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.069908
  validation loss:		0.226394
  validation accuracy:		93.91 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.067899
  validation loss:		0.227466
  validation accuracy:		93.48 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.068332
  validation loss:		0.230323
  validation accuracy:		94.24 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.064775
  validation loss:		0.225158
  validation accuracy:		93.80 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.068432
  validation loss:		0.230272
  validation accuracy:		93.80 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.066581
  validation loss:		0.234858
  validation accuracy:		93.80 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.066703
  validation loss:		0.230465
  validation accuracy:		93.70 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.063529
  validation loss:		0.228605
  validation accuracy:		93.80 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.063174
  validation loss:		0.226976
  validation accuracy:		94.13 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.067434
  validation loss:		0.225206
  validation accuracy:		93.80 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.064656
  validation loss:		0.235460
  validation accuracy:		94.02 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.067563
  validation loss:		0.235285
  validation accuracy:		93.59 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.067745
  validation loss:		0.226229
  validation accuracy:		94.02 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.066664
  validation loss:		0.226600
  validation accuracy:		93.91 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.065055
  validation loss:		0.226597
  validation accuracy:		94.13 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.065392
  validation loss:		0.235775
  validation accuracy:		93.70 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.063814
  validation loss:		0.235234
  validation accuracy:		93.70 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.063244
  validation loss:		0.228120
  validation accuracy:		93.91 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.064186
  validation loss:		0.236831
  validation accuracy:		93.70 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.062106
  validation loss:		0.235560
  validation accuracy:		93.80 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.062884
  validation loss:		0.231578
  validation accuracy:		94.02 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.064220
  validation loss:		0.232195
  validation accuracy:		93.91 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.064312
  validation loss:		0.229865
  validation accuracy:		93.70 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.060262
  validation loss:		0.234130
  validation accuracy:		94.02 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.063299
  validation loss:		0.232564
  validation accuracy:		93.80 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.063451
  validation loss:		0.234081
  validation accuracy:		93.59 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.062325
  validation loss:		0.232907
  validation accuracy:		93.80 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.060657
  validation loss:		0.236832
  validation accuracy:		94.02 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.062328
  validation loss:		0.234770
  validation accuracy:		93.70 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.060611
  validation loss:		0.231754
  validation accuracy:		93.80 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.060186
  validation loss:		0.232274
  validation accuracy:		93.59 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.061269
  validation loss:		0.234853
  validation accuracy:		93.91 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.061394
  validation loss:		0.243399
  validation accuracy:		93.80 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.062750
  validation loss:		0.241555
  validation accuracy:		93.59 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.060582
  validation loss:		0.241179
  validation accuracy:		93.91 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.058461
  validation loss:		0.233380
  validation accuracy:		93.91 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.061306
  validation loss:		0.233660
  validation accuracy:		94.13 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.061109
  validation loss:		0.234256
  validation accuracy:		93.91 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.059239
  validation loss:		0.234630
  validation accuracy:		93.80 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.060388
  validation loss:		0.238004
  validation accuracy:		93.48 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.058710
  validation loss:		0.238130
  validation accuracy:		93.70 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.059196
  validation loss:		0.234352
  validation accuracy:		93.91 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.058494
  validation loss:		0.241497
  validation accuracy:		93.70 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.059253
  validation loss:		0.230870
  validation accuracy:		94.13 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.059620
  validation loss:		0.237039
  validation accuracy:		93.70 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.058260
  validation loss:		0.242104
  validation accuracy:		93.59 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.059142
  validation loss:		0.237490
  validation accuracy:		93.91 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.059169
  validation loss:		0.233574
  validation accuracy:		94.24 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.058392
  validation loss:		0.240075
  validation accuracy:		93.70 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.058675
  validation loss:		0.251662
  validation accuracy:		93.48 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.058909
  validation loss:		0.238061
  validation accuracy:		93.91 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.060220
  validation loss:		0.238202
  validation accuracy:		93.80 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.057642
  validation loss:		0.241265
  validation accuracy:		93.70 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.057806
  validation loss:		0.235957
  validation accuracy:		94.13 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.058185
  validation loss:		0.234415
  validation accuracy:		93.91 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.058134
  validation loss:		0.239306
  validation accuracy:		93.59 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.054980
  validation loss:		0.237753
  validation accuracy:		93.80 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.059083
  validation loss:		0.242622
  validation accuracy:		93.80 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.056638
  validation loss:		0.245726
  validation accuracy:		93.80 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.057036
  validation loss:		0.241982
  validation accuracy:		94.02 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.056879
  validation loss:		0.239315
  validation accuracy:		93.70 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.056531
  validation loss:		0.249566
  validation accuracy:		93.80 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.057634
  validation loss:		0.242117
  validation accuracy:		93.70 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.056208
  validation loss:		0.246836
  validation accuracy:		93.91 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.057291
  validation loss:		0.246381
  validation accuracy:		93.80 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.053738
  validation loss:		0.240762
  validation accuracy:		93.80 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.057003
  validation loss:		0.250690
  validation accuracy:		93.26 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.056995
  validation loss:		0.245771
  validation accuracy:		93.59 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.055947
  validation loss:		0.248432
  validation accuracy:		93.59 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.055807
  validation loss:		0.248031
  validation accuracy:		93.80 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.055242
  validation loss:		0.242727
  validation accuracy:		93.91 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.055819
  validation loss:		0.244043
  validation accuracy:		94.13 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.054305
  validation loss:		0.243378
  validation accuracy:		93.91 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.055190
  validation loss:		0.241276
  validation accuracy:		94.35 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.055599
  validation loss:		0.250085
  validation accuracy:		93.59 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.056297
  validation loss:		0.244738
  validation accuracy:		94.02 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.054692
  validation loss:		0.244048
  validation accuracy:		93.80 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.054803
  validation loss:		0.243672
  validation accuracy:		93.91 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.055418
  validation loss:		0.244844
  validation accuracy:		93.48 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.052230
  validation loss:		0.252973
  validation accuracy:		94.02 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.055107
  validation loss:		0.256625
  validation accuracy:		93.59 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.054131
  validation loss:		0.250540
  validation accuracy:		93.91 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.052589
  validation loss:		0.243941
  validation accuracy:		93.70 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.054107
  validation loss:		0.249109
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.052733
  validation loss:		0.258106
  validation accuracy:		93.70 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.052261
  validation loss:		0.252360
  validation accuracy:		94.02 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.051811
  validation loss:		0.242901
  validation accuracy:		93.91 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.053243
  validation loss:		0.253984
  validation accuracy:		93.70 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.051126
  validation loss:		0.256219
  validation accuracy:		93.70 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.052934
  validation loss:		0.247366
  validation accuracy:		93.91 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.049755
  validation loss:		0.251749
  validation accuracy:		93.59 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.052173
  validation loss:		0.252208
  validation accuracy:		93.91 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.051954
  validation loss:		0.250364
  validation accuracy:		93.70 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.052672
  validation loss:		0.248981
  validation accuracy:		93.70 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.051610
  validation loss:		0.247599
  validation accuracy:		93.80 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.048506
  validation loss:		0.258751
  validation accuracy:		93.80 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.052359
  validation loss:		0.249204
  validation accuracy:		93.48 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.051351
  validation loss:		0.256770
  validation accuracy:		93.80 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.051923
  validation loss:		0.250513
  validation accuracy:		93.80 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.050585
  validation loss:		0.258202
  validation accuracy:		93.80 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.051292
  validation loss:		0.258949
  validation accuracy:		93.59 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.050069
  validation loss:		0.253279
  validation accuracy:		93.80 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.050259
  validation loss:		0.253891
  validation accuracy:		93.70 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.050652
  validation loss:		0.265907
  validation accuracy:		93.37 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.050927
  validation loss:		0.261571
  validation accuracy:		93.91 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.051469
  validation loss:		0.251513
  validation accuracy:		93.80 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.050361
  validation loss:		0.252123
  validation accuracy:		93.91 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.049742
  validation loss:		0.257037
  validation accuracy:		93.59 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.050358
  validation loss:		0.248728
  validation accuracy:		93.80 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.050951
  validation loss:		0.260749
  validation accuracy:		93.70 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.048058
  validation loss:		0.258026
  validation accuracy:		93.80 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.050279
  validation loss:		0.260851
  validation accuracy:		93.70 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.049869
  validation loss:		0.255944
  validation accuracy:		93.70 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.049506
  validation loss:		0.256479
  validation accuracy:		93.80 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.050446
  validation loss:		0.263201
  validation accuracy:		93.59 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.049317
  validation loss:		0.250555
  validation accuracy:		93.80 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.048325
  validation loss:		0.252840
  validation accuracy:		93.91 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.049035
  validation loss:		0.255379
  validation accuracy:		93.80 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.049238
  validation loss:		0.263729
  validation accuracy:		93.70 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.047454
  validation loss:		0.253749
  validation accuracy:		93.80 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.046325
  validation loss:		0.260574
  validation accuracy:		93.59 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.048231
  validation loss:		0.261706
  validation accuracy:		93.80 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.048427
  validation loss:		0.256725
  validation accuracy:		93.80 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.048512
  validation loss:		0.260227
  validation accuracy:		93.80 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.045430
  validation loss:		0.258687
  validation accuracy:		93.80 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.047164
  validation loss:		0.259554
  validation accuracy:		93.80 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.046314
  validation loss:		0.253230
  validation accuracy:		93.80 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.046990
  validation loss:		0.254324
  validation accuracy:		94.02 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.047621
  validation loss:		0.254993
  validation accuracy:		93.80 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.046540
  validation loss:		0.261901
  validation accuracy:		93.80 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.046813
  validation loss:		0.253719
  validation accuracy:		93.80 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.046364
  validation loss:		0.261005
  validation accuracy:		93.80 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.045519
  validation loss:		0.253925
  validation accuracy:		93.80 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.047836
  validation loss:		0.257130
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.045603
  validation loss:		0.265598
  validation accuracy:		93.80 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.045063
  validation loss:		0.264339
  validation accuracy:		93.80 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.046068
  validation loss:		0.262367
  validation accuracy:		93.80 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.044128
  validation loss:		0.256472
  validation accuracy:		93.91 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.045937
  validation loss:		0.275884
  validation accuracy:		93.37 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.046161
  validation loss:		0.271342
  validation accuracy:		93.59 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.046110
  validation loss:		0.265586
  validation accuracy:		93.91 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.043957
  validation loss:		0.258879
  validation accuracy:		94.02 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.046044
  validation loss:		0.260316
  validation accuracy:		93.80 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.044730
  validation loss:		0.262490
  validation accuracy:		94.02 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.044320
  validation loss:		0.256334
  validation accuracy:		94.02 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.047479
  validation loss:		0.267319
  validation accuracy:		93.70 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.044980
  validation loss:		0.272094
  validation accuracy:		93.70 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.044686
  validation loss:		0.259000
  validation accuracy:		93.91 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.043641
  validation loss:		0.260919
  validation accuracy:		93.91 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.043380
  validation loss:		0.262278
  validation accuracy:		93.80 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.043509
  validation loss:		0.262385
  validation accuracy:		93.91 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.042938
  validation loss:		0.265968
  validation accuracy:		93.91 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.045079
  validation loss:		0.267970
  validation accuracy:		93.48 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.042766
  validation loss:		0.270189
  validation accuracy:		93.59 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.044467
  validation loss:		0.275640
  validation accuracy:		93.70 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.044469
  validation loss:		0.274552
  validation accuracy:		93.59 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.043567
  validation loss:		0.273453
  validation accuracy:		93.48 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.042737
  validation loss:		0.269219
  validation accuracy:		93.48 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.042273
  validation loss:		0.273539
  validation accuracy:		93.80 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.042811
  validation loss:		0.268411
  validation accuracy:		93.70 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.042593
  validation loss:		0.273249
  validation accuracy:		93.80 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.042733
  validation loss:		0.266662
  validation accuracy:		93.70 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.042080
  validation loss:		0.266581
  validation accuracy:		93.70 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.043131
  validation loss:		0.263623
  validation accuracy:		93.91 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.042396
  validation loss:		0.272891
  validation accuracy:		93.91 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.042009
  validation loss:		0.263499
  validation accuracy:		93.59 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.041888
  validation loss:		0.273794
  validation accuracy:		93.59 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.043342
  validation loss:		0.264138
  validation accuracy:		93.91 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.041586
  validation loss:		0.266743
  validation accuracy:		93.70 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.041080
  validation loss:		0.268681
  validation accuracy:		93.70 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.042562
  validation loss:		0.274499
  validation accuracy:		94.02 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.042715
  validation loss:		0.263769
  validation accuracy:		93.80 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.042502
  validation loss:		0.275463
  validation accuracy:		93.70 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.041779
  validation loss:		0.266965
  validation accuracy:		93.70 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.040744
  validation loss:		0.273297
  validation accuracy:		93.70 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.040654
  validation loss:		0.263252
  validation accuracy:		93.80 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.041389
  validation loss:		0.279737
  validation accuracy:		93.59 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.040363
  validation loss:		0.271967
  validation accuracy:		93.80 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.039308
  validation loss:		0.269891
  validation accuracy:		93.59 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.040954
  validation loss:		0.280730
  validation accuracy:		93.48 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.040847
  validation loss:		0.275519
  validation accuracy:		93.59 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.040861
  validation loss:		0.274964
  validation accuracy:		93.91 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.038282
  validation loss:		0.280175
  validation accuracy:		93.80 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.040175
  validation loss:		0.268771
  validation accuracy:		93.80 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.041217
  validation loss:		0.271471
  validation accuracy:		93.80 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.041185
  validation loss:		0.270785
  validation accuracy:		93.70 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.038523
  validation loss:		0.269906
  validation accuracy:		93.91 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.040357
  validation loss:		0.274885
  validation accuracy:		93.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.039735
  validation loss:		0.271286
  validation accuracy:		93.48 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.039867
  validation loss:		0.269591
  validation accuracy:		94.02 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.040454
  validation loss:		0.278461
  validation accuracy:		93.70 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.039475
  validation loss:		0.274966
  validation accuracy:		93.70 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.038713
  validation loss:		0.272137
  validation accuracy:		93.70 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.040555
  validation loss:		0.286016
  validation accuracy:		93.80 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.038674
  validation loss:		0.272274
  validation accuracy:		93.59 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.039349
  validation loss:		0.279669
  validation accuracy:		93.70 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.039587
  validation loss:		0.273580
  validation accuracy:		93.70 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.039397
  validation loss:		0.276169
  validation accuracy:		93.59 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.039508
  validation loss:		0.281150
  validation accuracy:		93.48 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.036468
  validation loss:		0.276069
  validation accuracy:		93.48 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.038987
  validation loss:		0.281448
  validation accuracy:		93.37 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.037940
  validation loss:		0.283082
  validation accuracy:		93.59 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.038749
  validation loss:		0.277108
  validation accuracy:		93.48 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.038373
  validation loss:		0.284998
  validation accuracy:		93.59 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.037495
  validation loss:		0.282211
  validation accuracy:		93.70 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.039501
  validation loss:		0.283387
  validation accuracy:		93.37 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.039333
  validation loss:		0.276781
  validation accuracy:		93.70 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.038152
  validation loss:		0.275320
  validation accuracy:		93.70 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.037472
  validation loss:		0.282024
  validation accuracy:		93.59 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.035712
  validation loss:		0.279899
  validation accuracy:		93.80 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.037251
  validation loss:		0.282387
  validation accuracy:		93.70 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.037021
  validation loss:		0.278230
  validation accuracy:		93.59 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.036078
  validation loss:		0.282778
  validation accuracy:		93.80 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.036693
  validation loss:		0.285623
  validation accuracy:		93.70 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.037249
  validation loss:		0.280591
  validation accuracy:		93.48 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.038097
  validation loss:		0.275525
  validation accuracy:		93.80 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.037341
  validation loss:		0.279205
  validation accuracy:		93.80 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.037243
  validation loss:		0.276887
  validation accuracy:		93.70 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.038004
  validation loss:		0.285343
  validation accuracy:		93.70 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.037325
  validation loss:		0.288633
  validation accuracy:		93.59 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.037030
  validation loss:		0.282889
  validation accuracy:		93.70 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.035566
  validation loss:		0.279660
  validation accuracy:		93.59 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.036994
  validation loss:		0.287464
  validation accuracy:		93.37 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.035169
  validation loss:		0.283620
  validation accuracy:		93.70 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.034961
  validation loss:		0.279224
  validation accuracy:		93.48 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.034743
  validation loss:		0.288128
  validation accuracy:		93.59 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.035057
  validation loss:		0.288175
  validation accuracy:		93.37 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.035495
  validation loss:		0.280191
  validation accuracy:		93.80 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.035970
  validation loss:		0.283131
  validation accuracy:		93.70 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.036497
  validation loss:		0.293583
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.034956
  validation loss:		0.280489
  validation accuracy:		93.91 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.036060
  validation loss:		0.281177
  validation accuracy:		93.48 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.035365
  validation loss:		0.290936
  validation accuracy:		93.48 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.036124
  validation loss:		0.285350
  validation accuracy:		93.59 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.035974
  validation loss:		0.290941
  validation accuracy:		93.26 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.037292
  validation loss:		0.279718
  validation accuracy:		93.48 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.033945
  validation loss:		0.298067
  validation accuracy:		93.37 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.035130
  validation loss:		0.281097
  validation accuracy:		93.70 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.034516
  validation loss:		0.284082
  validation accuracy:		93.37 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.036074
  validation loss:		0.286628
  validation accuracy:		93.70 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.035163
  validation loss:		0.291956
  validation accuracy:		93.48 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.034447
  validation loss:		0.285696
  validation accuracy:		93.70 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.034468
  validation loss:		0.295755
  validation accuracy:		93.48 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.033464
  validation loss:		0.291029
  validation accuracy:		93.48 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.033704
  validation loss:		0.288803
  validation accuracy:		93.80 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.032850
  validation loss:		0.290241
  validation accuracy:		93.48 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.032754
  validation loss:		0.293731
  validation accuracy:		93.37 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.034511
  validation loss:		0.282841
  validation accuracy:		93.70 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.033944
  validation loss:		0.286995
  validation accuracy:		93.48 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.033896
  validation loss:		0.285173
  validation accuracy:		93.48 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.033509
  validation loss:		0.304628
  validation accuracy:		93.37 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.032868
  validation loss:		0.288652
  validation accuracy:		93.48 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.033576
  validation loss:		0.291621
  validation accuracy:		93.91 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.032985
  validation loss:		0.287899
  validation accuracy:		93.48 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.031633
  validation loss:		0.285344
  validation accuracy:		93.48 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.033228
  validation loss:		0.297232
  validation accuracy:		93.91 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.031967
  validation loss:		0.297365
  validation accuracy:		93.70 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.032893
  validation loss:		0.285679
  validation accuracy:		93.48 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.032883
  validation loss:		0.287295
  validation accuracy:		93.48 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.031912
  validation loss:		0.295185
  validation accuracy:		93.70 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.033333
  validation loss:		0.297998
  validation accuracy:		93.48 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.031513
  validation loss:		0.289676
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.033285
  validation loss:		0.296173
  validation accuracy:		93.37 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.032348
  validation loss:		0.290707
  validation accuracy:		93.80 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.031497
  validation loss:		0.292180
  validation accuracy:		93.48 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.032496
  validation loss:		0.301494
  validation accuracy:		93.37 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.031394
  validation loss:		0.287725
  validation accuracy:		93.70 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.031875
  validation loss:		0.300599
  validation accuracy:		93.59 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.031466
  validation loss:		0.294513
  validation accuracy:		93.48 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.031150
  validation loss:		0.297266
  validation accuracy:		93.48 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.032469
  validation loss:		0.288454
  validation accuracy:		93.59 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.032142
  validation loss:		0.289096
  validation accuracy:		93.59 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.031588
  validation loss:		0.299717
  validation accuracy:		93.48 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.032490
  validation loss:		0.300465
  validation accuracy:		93.48 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.031587
  validation loss:		0.290665
  validation accuracy:		93.48 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.030977
  validation loss:		0.297868
  validation accuracy:		93.59 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.030467
  validation loss:		0.299828
  validation accuracy:		93.59 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.031789
  validation loss:		0.299626
  validation accuracy:		93.70 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.030933
  validation loss:		0.297471
  validation accuracy:		93.48 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.031462
  validation loss:		0.305546
  validation accuracy:		93.70 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.031248
  validation loss:		0.301849
  validation accuracy:		93.59 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.031481
  validation loss:		0.298825
  validation accuracy:		93.48 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.030591
  validation loss:		0.303791
  validation accuracy:		93.59 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.030486
  validation loss:		0.300811
  validation accuracy:		93.37 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.030338
  validation loss:		0.293024
  validation accuracy:		93.70 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.030590
  validation loss:		0.300677
  validation accuracy:		93.48 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.029834
  validation loss:		0.311943
  validation accuracy:		93.59 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.030912
  validation loss:		0.300944
  validation accuracy:		93.37 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.031447
  validation loss:		0.292674
  validation accuracy:		93.80 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.030531
  validation loss:		0.304347
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.030487
  validation loss:		0.302453
  validation accuracy:		93.59 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.030657
  validation loss:		0.301179
  validation accuracy:		93.70 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.030717
  validation loss:		0.298485
  validation accuracy:		93.37 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.030352
  validation loss:		0.314526
  validation accuracy:		93.37 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.030135
  validation loss:		0.303876
  validation accuracy:		93.48 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.030561
  validation loss:		0.317560
  validation accuracy:		93.48 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.030298
  validation loss:		0.302141
  validation accuracy:		93.48 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.029625
  validation loss:		0.291980
  validation accuracy:		93.59 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.031427
  validation loss:		0.311052
  validation accuracy:		93.80 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.028890
  validation loss:		0.302236
  validation accuracy:		93.48 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.030034
  validation loss:		0.304436
  validation accuracy:		93.59 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.029461
  validation loss:		0.315314
  validation accuracy:		93.26 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.027062
  validation loss:		0.304359
  validation accuracy:		93.70 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.028692
  validation loss:		0.305146
  validation accuracy:		93.48 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.029198
  validation loss:		0.297948
  validation accuracy:		93.59 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.029268
  validation loss:		0.311408
  validation accuracy:		93.04 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.028314
  validation loss:		0.297750
  validation accuracy:		93.48 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.029048
  validation loss:		0.305827
  validation accuracy:		93.37 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.029352
  validation loss:		0.304726
  validation accuracy:		93.59 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.029523
  validation loss:		0.304516
  validation accuracy:		93.80 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.028176
  validation loss:		0.326125
  validation accuracy:		93.04 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.029107
  validation loss:		0.308845
  validation accuracy:		93.48 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.028159
  validation loss:		0.305012
  validation accuracy:		93.70 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.028928
  validation loss:		0.300769
  validation accuracy:		93.59 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.029046
  validation loss:		0.301529
  validation accuracy:		93.59 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.029436
  validation loss:		0.309712
  validation accuracy:		93.70 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.028582
  validation loss:		0.302790
  validation accuracy:		93.59 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.028307
  validation loss:		0.307964
  validation accuracy:		93.59 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.029182
  validation loss:		0.310590
  validation accuracy:		93.59 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.027833
  validation loss:		0.302531
  validation accuracy:		93.70 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.027879
  validation loss:		0.311566
  validation accuracy:		93.59 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.027290
  validation loss:		0.315486
  validation accuracy:		93.37 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.027858
  validation loss:		0.318146
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.027795
  validation loss:		0.311299
  validation accuracy:		93.59 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.026877
  validation loss:		0.307588
  validation accuracy:		93.70 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.026906
  validation loss:		0.307974
  validation accuracy:		93.48 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.027797
  validation loss:		0.314732
  validation accuracy:		93.70 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.027003
  validation loss:		0.307786
  validation accuracy:		93.59 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.026865
  validation loss:		0.320234
  validation accuracy:		93.70 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.027245
  validation loss:		0.304823
  validation accuracy:		93.37 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.027896
  validation loss:		0.313178
  validation accuracy:		93.59 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.026193
  validation loss:		0.311297
  validation accuracy:		93.15 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.027960
  validation loss:		0.311243
  validation accuracy:		93.70 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.026685
  validation loss:		0.303083
  validation accuracy:		93.37 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.026769
  validation loss:		0.318301
  validation accuracy:		93.70 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.027501
  validation loss:		0.313172
  validation accuracy:		93.37 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.027631
  validation loss:		0.313333
  validation accuracy:		93.59 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.026570
  validation loss:		0.311924
  validation accuracy:		93.26 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.026788
  validation loss:		0.312946
  validation accuracy:		93.26 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.026897
  validation loss:		0.312347
  validation accuracy:		93.48 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.026219
  validation loss:		0.313884
  validation accuracy:		93.37 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.026006
  validation loss:		0.314891
  validation accuracy:		93.48 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.027079
  validation loss:		0.312736
  validation accuracy:		93.48 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.025838
  validation loss:		0.314187
  validation accuracy:		93.59 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.026639
  validation loss:		0.322866
  validation accuracy:		93.15 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.025892
  validation loss:		0.321359
  validation accuracy:		93.48 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.026253
  validation loss:		0.321435
  validation accuracy:		93.26 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.026302
  validation loss:		0.314204
  validation accuracy:		93.70 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.026057
  validation loss:		0.323481
  validation accuracy:		93.15 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.026041
  validation loss:		0.317406
  validation accuracy:		93.26 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.026059
  validation loss:		0.304405
  validation accuracy:		93.59 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.025123
  validation loss:		0.318569
  validation accuracy:		93.70 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.025328
  validation loss:		0.319079
  validation accuracy:		93.26 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.024231
  validation loss:		0.314224
  validation accuracy:		93.59 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.025414
  validation loss:		0.321905
  validation accuracy:		93.59 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.026286
  validation loss:		0.317888
  validation accuracy:		93.48 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.026039
  validation loss:		0.317225
  validation accuracy:		93.59 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.025258
  validation loss:		0.318050
  validation accuracy:		93.37 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.025543
  validation loss:		0.316877
  validation accuracy:		93.59 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.024779
  validation loss:		0.318358
  validation accuracy:		93.48 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.025714
  validation loss:		0.315456
  validation accuracy:		93.59 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.025246
  validation loss:		0.319407
  validation accuracy:		93.70 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.024062
  validation loss:		0.314182
  validation accuracy:		93.48 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.024676
  validation loss:		0.327190
  validation accuracy:		93.26 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.025062
  validation loss:		0.326649
  validation accuracy:		93.37 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.025158
  validation loss:		0.333529
  validation accuracy:		93.26 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.024427
  validation loss:		0.323517
  validation accuracy:		93.37 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.024623
  validation loss:		0.323355
  validation accuracy:		93.48 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.023547
  validation loss:		0.320670
  validation accuracy:		93.70 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.023801
  validation loss:		0.322199
  validation accuracy:		93.59 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.024097
  validation loss:		0.318533
  validation accuracy:		93.37 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.025688
  validation loss:		0.322134
  validation accuracy:		93.26 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.024768
  validation loss:		0.317827
  validation accuracy:		93.59 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.022061
  validation loss:		0.329618
  validation accuracy:		93.37 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.024236
  validation loss:		0.325299
  validation accuracy:		93.70 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.024248
  validation loss:		0.319782
  validation accuracy:		93.37 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.024147
  validation loss:		0.322585
  validation accuracy:		93.70 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.023572
  validation loss:		0.316916
  validation accuracy:		93.59 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.024391
  validation loss:		0.326212
  validation accuracy:		93.48 %
Epoch 857 of 2000 took 0.037s
  training loss:		0.024000
  validation loss:		0.322629
  validation accuracy:		93.70 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.023261
  validation loss:		0.322083
  validation accuracy:		93.59 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.024731
  validation loss:		0.321775
  validation accuracy:		93.48 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.023697
  validation loss:		0.322130
  validation accuracy:		93.59 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.023261
  validation loss:		0.319991
  validation accuracy:		93.48 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.023715
  validation loss:		0.321107
  validation accuracy:		93.59 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.023650
  validation loss:		0.326010
  validation accuracy:		93.26 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.023341
  validation loss:		0.324428
  validation accuracy:		93.59 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.023821
  validation loss:		0.325181
  validation accuracy:		93.48 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.023550
  validation loss:		0.328456
  validation accuracy:		93.59 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.022971
  validation loss:		0.323804
  validation accuracy:		93.48 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.023436
  validation loss:		0.331676
  validation accuracy:		93.48 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.023396
  validation loss:		0.326003
  validation accuracy:		93.70 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.023489
  validation loss:		0.323169
  validation accuracy:		93.59 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.022897
  validation loss:		0.335364
  validation accuracy:		93.48 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.023798
  validation loss:		0.333192
  validation accuracy:		93.59 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.022767
  validation loss:		0.328242
  validation accuracy:		93.48 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.022987
  validation loss:		0.330187
  validation accuracy:		93.26 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.022632
  validation loss:		0.323941
  validation accuracy:		93.70 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.022573
  validation loss:		0.334754
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.022833
  validation loss:		0.335933
  validation accuracy:		93.37 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.023221
  validation loss:		0.332227
  validation accuracy:		93.15 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.022826
  validation loss:		0.329161
  validation accuracy:		93.59 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.022352
  validation loss:		0.324535
  validation accuracy:		93.48 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.022264
  validation loss:		0.337960
  validation accuracy:		93.48 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.023035
  validation loss:		0.327353
  validation accuracy:		93.70 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.022450
  validation loss:		0.334286
  validation accuracy:		93.26 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.022229
  validation loss:		0.319153
  validation accuracy:		93.48 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.021669
  validation loss:		0.335329
  validation accuracy:		93.70 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021611
  validation loss:		0.329639
  validation accuracy:		93.48 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.021637
  validation loss:		0.328415
  validation accuracy:		93.59 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.021979
  validation loss:		0.329394
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.021330
  validation loss:		0.323124
  validation accuracy:		93.37 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.023653
  validation loss:		0.337304
  validation accuracy:		93.48 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.021759
  validation loss:		0.329955
  validation accuracy:		93.70 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.021988
  validation loss:		0.335929
  validation accuracy:		93.37 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.021166
  validation loss:		0.337447
  validation accuracy:		93.48 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.020692
  validation loss:		0.336729
  validation accuracy:		93.37 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.021629
  validation loss:		0.336603
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.021974
  validation loss:		0.334343
  validation accuracy:		93.48 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.021821
  validation loss:		0.331889
  validation accuracy:		93.59 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.021850
  validation loss:		0.331423
  validation accuracy:		93.59 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.021893
  validation loss:		0.329204
  validation accuracy:		93.59 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.021424
  validation loss:		0.337600
  validation accuracy:		93.37 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.020910
  validation loss:		0.333573
  validation accuracy:		93.70 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.021037
  validation loss:		0.342382
  validation accuracy:		93.37 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.020739
  validation loss:		0.329158
  validation accuracy:		93.59 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.020970
  validation loss:		0.337525
  validation accuracy:		93.26 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.020704
  validation loss:		0.332840
  validation accuracy:		93.48 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.020767
  validation loss:		0.337392
  validation accuracy:		93.37 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.021023
  validation loss:		0.332566
  validation accuracy:		93.59 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.021114
  validation loss:		0.339283
  validation accuracy:		93.26 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.021172
  validation loss:		0.336899
  validation accuracy:		93.48 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.021049
  validation loss:		0.331937
  validation accuracy:		93.37 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.020167
  validation loss:		0.333324
  validation accuracy:		93.70 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.021264
  validation loss:		0.334317
  validation accuracy:		93.48 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.020136
  validation loss:		0.342159
  validation accuracy:		93.37 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.019765
  validation loss:		0.344265
  validation accuracy:		93.26 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.021067
  validation loss:		0.345274
  validation accuracy:		93.59 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.021098
  validation loss:		0.337580
  validation accuracy:		93.59 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.019551
  validation loss:		0.344329
  validation accuracy:		93.37 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.021289
  validation loss:		0.343556
  validation accuracy:		93.37 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.019883
  validation loss:		0.348873
  validation accuracy:		93.26 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.020686
  validation loss:		0.349152
  validation accuracy:		93.26 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.020054
  validation loss:		0.342844
  validation accuracy:		93.26 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.020236
  validation loss:		0.342701
  validation accuracy:		93.26 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.018653
  validation loss:		0.337587
  validation accuracy:		93.70 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.019902
  validation loss:		0.339972
  validation accuracy:		93.37 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.019513
  validation loss:		0.341992
  validation accuracy:		93.59 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.019663
  validation loss:		0.336568
  validation accuracy:		93.59 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.020467
  validation loss:		0.348895
  validation accuracy:		93.26 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.019373
  validation loss:		0.350386
  validation accuracy:		93.26 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.019882
  validation loss:		0.344242
  validation accuracy:		93.37 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.019744
  validation loss:		0.347027
  validation accuracy:		93.37 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.019153
  validation loss:		0.337099
  validation accuracy:		93.37 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.019253
  validation loss:		0.340780
  validation accuracy:		93.48 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.019398
  validation loss:		0.340832
  validation accuracy:		93.37 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.019032
  validation loss:		0.346033
  validation accuracy:		93.48 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.019351
  validation loss:		0.335810
  validation accuracy:		93.59 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.019936
  validation loss:		0.347966
  validation accuracy:		93.26 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.019289
  validation loss:		0.344307
  validation accuracy:		93.48 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.019207
  validation loss:		0.344924
  validation accuracy:		93.59 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.019003
  validation loss:		0.344086
  validation accuracy:		93.37 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.018655
  validation loss:		0.341976
  validation accuracy:		93.59 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.018738
  validation loss:		0.347511
  validation accuracy:		93.59 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.018798
  validation loss:		0.345878
  validation accuracy:		93.26 %
Epoch 943 of 2000 took 0.036s
  training loss:		0.018960
  validation loss:		0.353124
  validation accuracy:		93.15 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.019047
  validation loss:		0.346191
  validation accuracy:		93.26 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.018975
  validation loss:		0.351276
  validation accuracy:		93.37 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.018404
  validation loss:		0.348735
  validation accuracy:		93.04 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.018503
  validation loss:		0.345771
  validation accuracy:		93.59 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.018831
  validation loss:		0.353824
  validation accuracy:		93.37 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.018186
  validation loss:		0.351603
  validation accuracy:		93.37 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.018608
  validation loss:		0.348298
  validation accuracy:		93.26 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.018694
  validation loss:		0.345880
  validation accuracy:		93.59 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.018570
  validation loss:		0.344712
  validation accuracy:		93.59 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.018499
  validation loss:		0.349124
  validation accuracy:		93.48 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.018295
  validation loss:		0.343796
  validation accuracy:		93.59 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.018993
  validation loss:		0.344831
  validation accuracy:		93.26 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.018115
  validation loss:		0.347178
  validation accuracy:		93.26 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.017785
  validation loss:		0.353896
  validation accuracy:		93.26 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.017737
  validation loss:		0.343724
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.018256
  validation loss:		0.342482
  validation accuracy:		93.59 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.019010
  validation loss:		0.354039
  validation accuracy:		93.37 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.018006
  validation loss:		0.342592
  validation accuracy:		93.48 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.018010
  validation loss:		0.367695
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.018283
  validation loss:		0.357729
  validation accuracy:		93.26 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.017928
  validation loss:		0.347019
  validation accuracy:		93.37 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.017488
  validation loss:		0.359755
  validation accuracy:		93.04 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.018434
  validation loss:		0.352517
  validation accuracy:		93.26 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.018129
  validation loss:		0.356052
  validation accuracy:		93.26 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.018718
  validation loss:		0.354424
  validation accuracy:		93.26 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.017951
  validation loss:		0.350312
  validation accuracy:		93.37 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.017827
  validation loss:		0.353484
  validation accuracy:		93.26 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.018119
  validation loss:		0.349160
  validation accuracy:		93.48 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.016950
  validation loss:		0.355471
  validation accuracy:		93.26 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.017574
  validation loss:		0.359635
  validation accuracy:		93.15 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.018278
  validation loss:		0.351506
  validation accuracy:		93.37 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.017319
  validation loss:		0.350403
  validation accuracy:		93.26 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.017818
  validation loss:		0.356978
  validation accuracy:		93.04 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.017340
  validation loss:		0.352460
  validation accuracy:		93.15 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.017096
  validation loss:		0.365377
  validation accuracy:		93.26 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.017201
  validation loss:		0.357918
  validation accuracy:		93.37 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.017688
  validation loss:		0.366476
  validation accuracy:		93.15 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.017674
  validation loss:		0.355141
  validation accuracy:		93.26 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.018219
  validation loss:		0.354506
  validation accuracy:		93.26 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.017328
  validation loss:		0.357274
  validation accuracy:		93.37 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.018108
  validation loss:		0.355695
  validation accuracy:		93.26 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.017150
  validation loss:		0.357823
  validation accuracy:		93.26 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.016677
  validation loss:		0.357618
  validation accuracy:		93.26 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.017045
  validation loss:		0.356367
  validation accuracy:		93.48 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.016244
  validation loss:		0.354813
  validation accuracy:		93.26 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.017077
  validation loss:		0.362885
  validation accuracy:		93.37 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.017230
  validation loss:		0.357508
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.016918
  validation loss:		0.350870
  validation accuracy:		93.37 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.017484
  validation loss:		0.361231
  validation accuracy:		93.15 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.017209
  validation loss:		0.351536
  validation accuracy:		93.37 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016967
  validation loss:		0.353573
  validation accuracy:		93.48 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.016692
  validation loss:		0.361590
  validation accuracy:		93.37 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.017001
  validation loss:		0.357755
  validation accuracy:		93.37 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.016701
  validation loss:		0.365370
  validation accuracy:		93.04 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.016855
  validation loss:		0.360328
  validation accuracy:		93.37 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016524
  validation loss:		0.358778
  validation accuracy:		93.37 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.016220
  validation loss:		0.353173
  validation accuracy:		93.26 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.016787
  validation loss:		0.358588
  validation accuracy:		93.26 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.016289
  validation loss:		0.356836
  validation accuracy:		93.15 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.016462
  validation loss:		0.356867
  validation accuracy:		93.48 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.016690
  validation loss:		0.363841
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.016741
  validation loss:		0.360920
  validation accuracy:		93.15 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.016346
  validation loss:		0.360143
  validation accuracy:		93.15 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.016027
  validation loss:		0.362038
  validation accuracy:		93.37 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.016400
  validation loss:		0.364953
  validation accuracy:		93.37 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.016348
  validation loss:		0.362154
  validation accuracy:		93.26 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.016176
  validation loss:		0.361145
  validation accuracy:		93.37 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.015857
  validation loss:		0.357071
  validation accuracy:		93.48 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.016161
  validation loss:		0.355224
  validation accuracy:		93.37 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.015984
  validation loss:		0.368424
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.016156
  validation loss:		0.369064
  validation accuracy:		93.26 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.015747
  validation loss:		0.368204
  validation accuracy:		93.15 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.015684
  validation loss:		0.345426
  validation accuracy:		93.26 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.016053
  validation loss:		0.371245
  validation accuracy:		93.15 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.016318
  validation loss:		0.362716
  validation accuracy:		93.48 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.015509
  validation loss:		0.361023
  validation accuracy:		93.15 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.016179
  validation loss:		0.367047
  validation accuracy:		93.26 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.015628
  validation loss:		0.366069
  validation accuracy:		93.37 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.015940
  validation loss:		0.359360
  validation accuracy:		93.48 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.015806
  validation loss:		0.369963
  validation accuracy:		93.26 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.015389
  validation loss:		0.365872
  validation accuracy:		93.26 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.015398
  validation loss:		0.366036
  validation accuracy:		93.37 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.015515
  validation loss:		0.363001
  validation accuracy:		93.26 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.015814
  validation loss:		0.386285
  validation accuracy:		92.83 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.015768
  validation loss:		0.365980
  validation accuracy:		93.04 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.015013
  validation loss:		0.373022
  validation accuracy:		93.15 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.014998
  validation loss:		0.366402
  validation accuracy:		93.15 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.015505
  validation loss:		0.377507
  validation accuracy:		93.04 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.015614
  validation loss:		0.372318
  validation accuracy:		92.93 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.015221
  validation loss:		0.371791
  validation accuracy:		93.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.015170
  validation loss:		0.363181
  validation accuracy:		93.26 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.014991
  validation loss:		0.360440
  validation accuracy:		93.15 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.014730
  validation loss:		0.374678
  validation accuracy:		93.04 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.015117
  validation loss:		0.359949
  validation accuracy:		93.26 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.014255
  validation loss:		0.384650
  validation accuracy:		93.04 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.015027
  validation loss:		0.363522
  validation accuracy:		93.15 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.014440
  validation loss:		0.366783
  validation accuracy:		93.26 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.015143
  validation loss:		0.361790
  validation accuracy:		93.59 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.015215
  validation loss:		0.367979
  validation accuracy:		93.48 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.014804
  validation loss:		0.374218
  validation accuracy:		93.04 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.014058
  validation loss:		0.379077
  validation accuracy:		92.93 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.015518
  validation loss:		0.366715
  validation accuracy:		93.37 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.014614
  validation loss:		0.371958
  validation accuracy:		93.26 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.014552
  validation loss:		0.366819
  validation accuracy:		93.15 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.015170
  validation loss:		0.373563
  validation accuracy:		93.04 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.014604
  validation loss:		0.371866
  validation accuracy:		93.15 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.014374
  validation loss:		0.376774
  validation accuracy:		92.93 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.014981
  validation loss:		0.367662
  validation accuracy:		93.15 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.014537
  validation loss:		0.376259
  validation accuracy:		93.15 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.014529
  validation loss:		0.372619
  validation accuracy:		93.48 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.014103
  validation loss:		0.369815
  validation accuracy:		93.15 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.014406
  validation loss:		0.370096
  validation accuracy:		93.37 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.014062
  validation loss:		0.372698
  validation accuracy:		93.37 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.014090
  validation loss:		0.378870
  validation accuracy:		93.37 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.014880
  validation loss:		0.377683
  validation accuracy:		92.93 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.013913
  validation loss:		0.364298
  validation accuracy:		93.37 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.013520
  validation loss:		0.370367
  validation accuracy:		93.26 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.013811
  validation loss:		0.378935
  validation accuracy:		93.04 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.014616
  validation loss:		0.376770
  validation accuracy:		93.04 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.014206
  validation loss:		0.384220
  validation accuracy:		92.93 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.014413
  validation loss:		0.381458
  validation accuracy:		92.93 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.013690
  validation loss:		0.369969
  validation accuracy:		93.04 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.014004
  validation loss:		0.368316
  validation accuracy:		93.48 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.014588
  validation loss:		0.375849
  validation accuracy:		93.04 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.014320
  validation loss:		0.382885
  validation accuracy:		93.04 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.013906
  validation loss:		0.376962
  validation accuracy:		93.15 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.013972
  validation loss:		0.381928
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013802
  validation loss:		0.377419
  validation accuracy:		93.04 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.014052
  validation loss:		0.375373
  validation accuracy:		93.37 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.013600
  validation loss:		0.381129
  validation accuracy:		93.04 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.014288
  validation loss:		0.378832
  validation accuracy:		93.04 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.013522
  validation loss:		0.377224
  validation accuracy:		93.15 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.014046
  validation loss:		0.387191
  validation accuracy:		93.26 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.013715
  validation loss:		0.367185
  validation accuracy:		93.26 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.013583
  validation loss:		0.383934
  validation accuracy:		93.04 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.013755
  validation loss:		0.377268
  validation accuracy:		93.37 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013763
  validation loss:		0.386805
  validation accuracy:		92.83 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.014032
  validation loss:		0.379971
  validation accuracy:		93.37 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.013664
  validation loss:		0.387442
  validation accuracy:		93.04 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.013633
  validation loss:		0.366433
  validation accuracy:		93.37 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.014124
  validation loss:		0.382545
  validation accuracy:		92.93 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.013241
  validation loss:		0.377932
  validation accuracy:		93.26 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.013315
  validation loss:		0.373071
  validation accuracy:		93.48 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.013837
  validation loss:		0.381833
  validation accuracy:		93.04 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.013353
  validation loss:		0.391971
  validation accuracy:		93.04 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.013076
  validation loss:		0.387114
  validation accuracy:		92.83 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.013359
  validation loss:		0.379675
  validation accuracy:		93.04 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.012564
  validation loss:		0.383605
  validation accuracy:		93.04 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.013116
  validation loss:		0.389627
  validation accuracy:		92.93 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.013294
  validation loss:		0.389672
  validation accuracy:		92.93 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.013082
  validation loss:		0.390620
  validation accuracy:		92.93 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.013423
  validation loss:		0.384559
  validation accuracy:		92.93 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.013553
  validation loss:		0.383803
  validation accuracy:		92.93 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.013025
  validation loss:		0.383179
  validation accuracy:		93.26 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012802
  validation loss:		0.386864
  validation accuracy:		93.04 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.013036
  validation loss:		0.388469
  validation accuracy:		93.04 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.012771
  validation loss:		0.382713
  validation accuracy:		93.26 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.012874
  validation loss:		0.382878
  validation accuracy:		93.04 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.012778
  validation loss:		0.383781
  validation accuracy:		93.15 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.013044
  validation loss:		0.381306
  validation accuracy:		93.26 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.013135
  validation loss:		0.384686
  validation accuracy:		93.26 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.012786
  validation loss:		0.385873
  validation accuracy:		92.93 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.012627
  validation loss:		0.378713
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.013131
  validation loss:		0.384656
  validation accuracy:		93.15 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.012399
  validation loss:		0.381908
  validation accuracy:		93.26 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012719
  validation loss:		0.383235
  validation accuracy:		93.04 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.012552
  validation loss:		0.384057
  validation accuracy:		93.26 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.012656
  validation loss:		0.389309
  validation accuracy:		93.04 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.012793
  validation loss:		0.388798
  validation accuracy:		92.93 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.012283
  validation loss:		0.382806
  validation accuracy:		93.26 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.012361
  validation loss:		0.383779
  validation accuracy:		93.15 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.012616
  validation loss:		0.379393
  validation accuracy:		93.15 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.012560
  validation loss:		0.385865
  validation accuracy:		93.15 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.012388
  validation loss:		0.385015
  validation accuracy:		92.93 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.012554
  validation loss:		0.384365
  validation accuracy:		93.04 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.012671
  validation loss:		0.392681
  validation accuracy:		93.15 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.012007
  validation loss:		0.390514
  validation accuracy:		92.93 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.012483
  validation loss:		0.388493
  validation accuracy:		93.04 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.012552
  validation loss:		0.383342
  validation accuracy:		93.15 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.012527
  validation loss:		0.398803
  validation accuracy:		92.72 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.012445
  validation loss:		0.385516
  validation accuracy:		93.26 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.012268
  validation loss:		0.397239
  validation accuracy:		92.72 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.012564
  validation loss:		0.389146
  validation accuracy:		92.93 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.012059
  validation loss:		0.392336
  validation accuracy:		92.83 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.012483
  validation loss:		0.392724
  validation accuracy:		93.15 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.011935
  validation loss:		0.383114
  validation accuracy:		93.15 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.012160
  validation loss:		0.383943
  validation accuracy:		93.48 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.012135
  validation loss:		0.390026
  validation accuracy:		92.93 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.012352
  validation loss:		0.399477
  validation accuracy:		92.93 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.012229
  validation loss:		0.388917
  validation accuracy:		93.04 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.011480
  validation loss:		0.397852
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011543
  validation loss:		0.387531
  validation accuracy:		93.15 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.011967
  validation loss:		0.399414
  validation accuracy:		92.83 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.012054
  validation loss:		0.392782
  validation accuracy:		92.83 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.011914
  validation loss:		0.392271
  validation accuracy:		93.04 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011846
  validation loss:		0.391775
  validation accuracy:		92.83 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011606
  validation loss:		0.395445
  validation accuracy:		93.15 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.012541
  validation loss:		0.388172
  validation accuracy:		93.04 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.011889
  validation loss:		0.394150
  validation accuracy:		92.93 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.010973
  validation loss:		0.386868
  validation accuracy:		93.15 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.011426
  validation loss:		0.387399
  validation accuracy:		93.15 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.011523
  validation loss:		0.397145
  validation accuracy:		92.93 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.011843
  validation loss:		0.396290
  validation accuracy:		92.93 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.012071
  validation loss:		0.389767
  validation accuracy:		93.04 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.011464
  validation loss:		0.397311
  validation accuracy:		92.93 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.011749
  validation loss:		0.399374
  validation accuracy:		92.83 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.011386
  validation loss:		0.392142
  validation accuracy:		92.83 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.011709
  validation loss:		0.399404
  validation accuracy:		93.04 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.011626
  validation loss:		0.386314
  validation accuracy:		93.26 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.011743
  validation loss:		0.391393
  validation accuracy:		93.26 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.011347
  validation loss:		0.400682
  validation accuracy:		92.83 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.011151
  validation loss:		0.406889
  validation accuracy:		92.61 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.011365
  validation loss:		0.396875
  validation accuracy:		92.93 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.011273
  validation loss:		0.394616
  validation accuracy:		92.93 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011239
  validation loss:		0.401334
  validation accuracy:		92.72 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.011225
  validation loss:		0.396284
  validation accuracy:		92.93 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.011217
  validation loss:		0.409013
  validation accuracy:		92.72 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.011240
  validation loss:		0.407623
  validation accuracy:		92.72 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.011217
  validation loss:		0.396765
  validation accuracy:		93.04 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.011061
  validation loss:		0.398010
  validation accuracy:		93.26 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.011182
  validation loss:		0.400366
  validation accuracy:		92.93 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.011094
  validation loss:		0.394598
  validation accuracy:		93.26 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.011609
  validation loss:		0.410485
  validation accuracy:		92.61 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.011353
  validation loss:		0.389459
  validation accuracy:		92.93 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.011051
  validation loss:		0.398399
  validation accuracy:		93.04 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.011313
  validation loss:		0.402309
  validation accuracy:		93.15 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.010835
  validation loss:		0.391420
  validation accuracy:		93.15 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.010894
  validation loss:		0.394002
  validation accuracy:		93.04 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.011471
  validation loss:		0.401009
  validation accuracy:		93.04 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.010818
  validation loss:		0.402185
  validation accuracy:		92.83 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.011539
  validation loss:		0.407239
  validation accuracy:		92.83 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.011150
  validation loss:		0.406053
  validation accuracy:		92.93 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.010819
  validation loss:		0.396682
  validation accuracy:		93.04 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.010633
  validation loss:		0.401702
  validation accuracy:		92.93 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.010696
  validation loss:		0.408817
  validation accuracy:		92.93 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.011071
  validation loss:		0.395998
  validation accuracy:		92.93 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.010708
  validation loss:		0.400559
  validation accuracy:		92.93 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010518
  validation loss:		0.406301
  validation accuracy:		92.93 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.010942
  validation loss:		0.403128
  validation accuracy:		93.04 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.011167
  validation loss:		0.395171
  validation accuracy:		93.26 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010745
  validation loss:		0.402110
  validation accuracy:		92.93 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010630
  validation loss:		0.403889
  validation accuracy:		92.93 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.010550
  validation loss:		0.408307
  validation accuracy:		92.83 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.010515
  validation loss:		0.396041
  validation accuracy:		93.04 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.010544
  validation loss:		0.410580
  validation accuracy:		92.72 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.010854
  validation loss:		0.400074
  validation accuracy:		92.93 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.010706
  validation loss:		0.409080
  validation accuracy:		92.83 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.011093
  validation loss:		0.401910
  validation accuracy:		92.93 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.010579
  validation loss:		0.401164
  validation accuracy:		93.15 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.010557
  validation loss:		0.399083
  validation accuracy:		92.93 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.010470
  validation loss:		0.415959
  validation accuracy:		92.93 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.010926
  validation loss:		0.412917
  validation accuracy:		92.83 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.010501
  validation loss:		0.404559
  validation accuracy:		92.93 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.010604
  validation loss:		0.410606
  validation accuracy:		92.93 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.010388
  validation loss:		0.408590
  validation accuracy:		92.72 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.010156
  validation loss:		0.408690
  validation accuracy:		93.15 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.010327
  validation loss:		0.400586
  validation accuracy:		93.04 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.010056
  validation loss:		0.413750
  validation accuracy:		92.83 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.010247
  validation loss:		0.401144
  validation accuracy:		93.04 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.010098
  validation loss:		0.402284
  validation accuracy:		93.04 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.010598
  validation loss:		0.398867
  validation accuracy:		93.04 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.010239
  validation loss:		0.401939
  validation accuracy:		93.04 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.009993
  validation loss:		0.420389
  validation accuracy:		92.50 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.010410
  validation loss:		0.402024
  validation accuracy:		93.04 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.009924
  validation loss:		0.416389
  validation accuracy:		92.61 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.009794
  validation loss:		0.404953
  validation accuracy:		93.04 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.010296
  validation loss:		0.412106
  validation accuracy:		92.83 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.010210
  validation loss:		0.400479
  validation accuracy:		93.04 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.010022
  validation loss:		0.411766
  validation accuracy:		92.83 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.010156
  validation loss:		0.415051
  validation accuracy:		92.83 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.010037
  validation loss:		0.409944
  validation accuracy:		93.26 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.010161
  validation loss:		0.401844
  validation accuracy:		93.04 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.009769
  validation loss:		0.412770
  validation accuracy:		92.72 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.010059
  validation loss:		0.406442
  validation accuracy:		93.04 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.009869
  validation loss:		0.408022
  validation accuracy:		92.83 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.009677
  validation loss:		0.407787
  validation accuracy:		92.93 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009928
  validation loss:		0.409121
  validation accuracy:		92.83 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.009796
  validation loss:		0.414231
  validation accuracy:		93.04 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.010157
  validation loss:		0.415209
  validation accuracy:		92.83 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.009624
  validation loss:		0.416872
  validation accuracy:		92.93 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.009825
  validation loss:		0.418566
  validation accuracy:		92.83 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009947
  validation loss:		0.406316
  validation accuracy:		93.15 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009906
  validation loss:		0.409997
  validation accuracy:		92.83 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.009710
  validation loss:		0.411392
  validation accuracy:		92.93 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009744
  validation loss:		0.411176
  validation accuracy:		93.04 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.009751
  validation loss:		0.415106
  validation accuracy:		92.83 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.009869
  validation loss:		0.412843
  validation accuracy:		92.83 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009468
  validation loss:		0.409844
  validation accuracy:		93.04 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.010023
  validation loss:		0.415253
  validation accuracy:		92.83 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.009246
  validation loss:		0.410859
  validation accuracy:		93.04 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009684
  validation loss:		0.418861
  validation accuracy:		92.83 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.009499
  validation loss:		0.420443
  validation accuracy:		92.72 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.009776
  validation loss:		0.412089
  validation accuracy:		93.04 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009719
  validation loss:		0.416804
  validation accuracy:		92.93 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.009634
  validation loss:		0.411175
  validation accuracy:		92.83 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009565
  validation loss:		0.415716
  validation accuracy:		92.93 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.009360
  validation loss:		0.416982
  validation accuracy:		92.83 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.009291
  validation loss:		0.416183
  validation accuracy:		92.83 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.009436
  validation loss:		0.423815
  validation accuracy:		92.61 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.009491
  validation loss:		0.413700
  validation accuracy:		92.93 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.009421
  validation loss:		0.414562
  validation accuracy:		93.04 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009244
  validation loss:		0.420661
  validation accuracy:		92.72 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.009102
  validation loss:		0.413341
  validation accuracy:		93.04 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.009423
  validation loss:		0.417671
  validation accuracy:		92.93 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.009222
  validation loss:		0.417118
  validation accuracy:		92.93 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.009383
  validation loss:		0.421628
  validation accuracy:		92.83 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.009386
  validation loss:		0.424201
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.009281
  validation loss:		0.418586
  validation accuracy:		92.83 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009339
  validation loss:		0.425226
  validation accuracy:		92.72 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.008993
  validation loss:		0.418844
  validation accuracy:		92.93 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009383
  validation loss:		0.424444
  validation accuracy:		92.72 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.009536
  validation loss:		0.425650
  validation accuracy:		92.72 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.009616
  validation loss:		0.417093
  validation accuracy:		92.83 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.009275
  validation loss:		0.422329
  validation accuracy:		92.61 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.009209
  validation loss:		0.417254
  validation accuracy:		92.93 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.009339
  validation loss:		0.417402
  validation accuracy:		93.04 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.008895
  validation loss:		0.418253
  validation accuracy:		92.83 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.009304
  validation loss:		0.418344
  validation accuracy:		92.93 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.009108
  validation loss:		0.422478
  validation accuracy:		92.83 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.009133
  validation loss:		0.420134
  validation accuracy:		93.04 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.009059
  validation loss:		0.429410
  validation accuracy:		92.83 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.009247
  validation loss:		0.420489
  validation accuracy:		92.83 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.008761
  validation loss:		0.419897
  validation accuracy:		93.04 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.008839
  validation loss:		0.416693
  validation accuracy:		92.93 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008998
  validation loss:		0.418432
  validation accuracy:		93.04 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.008844
  validation loss:		0.420028
  validation accuracy:		92.93 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.008961
  validation loss:		0.429273
  validation accuracy:		92.61 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008988
  validation loss:		0.419301
  validation accuracy:		92.93 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008822
  validation loss:		0.429588
  validation accuracy:		92.72 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008868
  validation loss:		0.424800
  validation accuracy:		92.83 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.009030
  validation loss:		0.430409
  validation accuracy:		92.72 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008966
  validation loss:		0.422562
  validation accuracy:		92.83 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008609
  validation loss:		0.421147
  validation accuracy:		93.04 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.008661
  validation loss:		0.423019
  validation accuracy:		93.04 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.008488
  validation loss:		0.419702
  validation accuracy:		92.83 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008544
  validation loss:		0.421364
  validation accuracy:		92.93 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008537
  validation loss:		0.420639
  validation accuracy:		92.83 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.008784
  validation loss:		0.422871
  validation accuracy:		92.83 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008645
  validation loss:		0.424124
  validation accuracy:		92.83 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.008986
  validation loss:		0.418860
  validation accuracy:		93.15 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008586
  validation loss:		0.427644
  validation accuracy:		92.83 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008638
  validation loss:		0.421927
  validation accuracy:		93.04 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.008900
  validation loss:		0.429533
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.008507
  validation loss:		0.425261
  validation accuracy:		93.04 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.008242
  validation loss:		0.431419
  validation accuracy:		92.72 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.008364
  validation loss:		0.427813
  validation accuracy:		92.83 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.008866
  validation loss:		0.429471
  validation accuracy:		92.93 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.008380
  validation loss:		0.420612
  validation accuracy:		93.04 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008370
  validation loss:		0.428540
  validation accuracy:		92.72 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.008472
  validation loss:		0.432856
  validation accuracy:		92.72 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.008350
  validation loss:		0.431503
  validation accuracy:		93.04 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.008412
  validation loss:		0.430690
  validation accuracy:		92.72 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.008477
  validation loss:		0.429253
  validation accuracy:		92.83 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.008493
  validation loss:		0.433895
  validation accuracy:		92.72 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.008650
  validation loss:		0.426628
  validation accuracy:		92.83 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.008411
  validation loss:		0.426684
  validation accuracy:		92.93 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.008615
  validation loss:		0.426264
  validation accuracy:		92.93 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.008294
  validation loss:		0.425888
  validation accuracy:		92.93 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.008092
  validation loss:		0.420793
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.008141
  validation loss:		0.439235
  validation accuracy:		92.50 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.008252
  validation loss:		0.426399
  validation accuracy:		92.83 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.008220
  validation loss:		0.429334
  validation accuracy:		92.83 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.008083
  validation loss:		0.424438
  validation accuracy:		93.04 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.008383
  validation loss:		0.424873
  validation accuracy:		93.04 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.007974
  validation loss:		0.426267
  validation accuracy:		92.83 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.008255
  validation loss:		0.419847
  validation accuracy:		92.93 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.008262
  validation loss:		0.433622
  validation accuracy:		92.72 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.008487
  validation loss:		0.430972
  validation accuracy:		92.93 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.008297
  validation loss:		0.424279
  validation accuracy:		92.93 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.008414
  validation loss:		0.430315
  validation accuracy:		92.83 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.008074
  validation loss:		0.427844
  validation accuracy:		93.04 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.008129
  validation loss:		0.437798
  validation accuracy:		92.50 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.008215
  validation loss:		0.430399
  validation accuracy:		93.04 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.007715
  validation loss:		0.435868
  validation accuracy:		92.72 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.008009
  validation loss:		0.424442
  validation accuracy:		93.04 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.008271
  validation loss:		0.423018
  validation accuracy:		93.04 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.008000
  validation loss:		0.430306
  validation accuracy:		92.83 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.008198
  validation loss:		0.433157
  validation accuracy:		92.83 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.008190
  validation loss:		0.433915
  validation accuracy:		92.83 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007951
  validation loss:		0.439662
  validation accuracy:		92.72 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.007903
  validation loss:		0.427682
  validation accuracy:		92.83 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.007973
  validation loss:		0.430361
  validation accuracy:		92.93 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.007644
  validation loss:		0.432806
  validation accuracy:		92.93 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.008009
  validation loss:		0.428975
  validation accuracy:		92.83 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.007977
  validation loss:		0.434036
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.008273
  validation loss:		0.428537
  validation accuracy:		92.83 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.008005
  validation loss:		0.433950
  validation accuracy:		92.93 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.008060
  validation loss:		0.433801
  validation accuracy:		92.83 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.008280
  validation loss:		0.428252
  validation accuracy:		93.04 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.007740
  validation loss:		0.440849
  validation accuracy:		92.61 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007981
  validation loss:		0.432449
  validation accuracy:		92.93 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.007981
  validation loss:		0.442961
  validation accuracy:		92.61 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.007968
  validation loss:		0.430037
  validation accuracy:		92.93 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.008117
  validation loss:		0.434149
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007831
  validation loss:		0.434057
  validation accuracy:		92.93 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.007740
  validation loss:		0.438394
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007680
  validation loss:		0.434745
  validation accuracy:		92.93 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.008102
  validation loss:		0.430542
  validation accuracy:		92.93 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.007804
  validation loss:		0.435151
  validation accuracy:		92.83 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.436443
  validation accuracy:		92.83 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.007825
  validation loss:		0.443437
  validation accuracy:		92.61 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007700
  validation loss:		0.433123
  validation accuracy:		92.93 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.007569
  validation loss:		0.433866
  validation accuracy:		92.93 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.007878
  validation loss:		0.435862
  validation accuracy:		92.83 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.007825
  validation loss:		0.436997
  validation accuracy:		92.93 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.007508
  validation loss:		0.440508
  validation accuracy:		92.61 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.008084
  validation loss:		0.435709
  validation accuracy:		92.93 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.007359
  validation loss:		0.440314
  validation accuracy:		92.72 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.007549
  validation loss:		0.433076
  validation accuracy:		93.04 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007702
  validation loss:		0.443524
  validation accuracy:		92.61 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.007577
  validation loss:		0.445054
  validation accuracy:		92.61 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.007531
  validation loss:		0.435316
  validation accuracy:		92.93 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.007667
  validation loss:		0.440905
  validation accuracy:		92.83 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.007713
  validation loss:		0.435572
  validation accuracy:		93.04 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.007644
  validation loss:		0.439423
  validation accuracy:		92.93 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.007633
  validation loss:		0.441020
  validation accuracy:		92.72 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007476
  validation loss:		0.439395
  validation accuracy:		92.83 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.007557
  validation loss:		0.443026
  validation accuracy:		92.93 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.007446
  validation loss:		0.437560
  validation accuracy:		92.72 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.007471
  validation loss:		0.441297
  validation accuracy:		92.83 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.007482
  validation loss:		0.447279
  validation accuracy:		92.72 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.007341
  validation loss:		0.441179
  validation accuracy:		92.93 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.007361
  validation loss:		0.435507
  validation accuracy:		92.93 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.007512
  validation loss:		0.439390
  validation accuracy:		92.83 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.007442
  validation loss:		0.447333
  validation accuracy:		92.72 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.007388
  validation loss:		0.441381
  validation accuracy:		92.93 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.007077
  validation loss:		0.444142
  validation accuracy:		92.83 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.007397
  validation loss:		0.439546
  validation accuracy:		92.93 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.006986
  validation loss:		0.442628
  validation accuracy:		92.83 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.007591
  validation loss:		0.443586
  validation accuracy:		92.83 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.007336
  validation loss:		0.442550
  validation accuracy:		92.83 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.007265
  validation loss:		0.436596
  validation accuracy:		92.93 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.007484
  validation loss:		0.446182
  validation accuracy:		92.83 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.007212
  validation loss:		0.443307
  validation accuracy:		92.83 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.007430
  validation loss:		0.448066
  validation accuracy:		92.72 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.007315
  validation loss:		0.444087
  validation accuracy:		92.83 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.007479
  validation loss:		0.449505
  validation accuracy:		92.72 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.007059
  validation loss:		0.437959
  validation accuracy:		92.93 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.007129
  validation loss:		0.433041
  validation accuracy:		93.15 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.007198
  validation loss:		0.445800
  validation accuracy:		92.83 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.007151
  validation loss:		0.451921
  validation accuracy:		92.61 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.007118
  validation loss:		0.443654
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.007137
  validation loss:		0.440499
  validation accuracy:		92.83 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006983
  validation loss:		0.441961
  validation accuracy:		92.83 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.007056
  validation loss:		0.444192
  validation accuracy:		92.72 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006860
  validation loss:		0.444980
  validation accuracy:		92.93 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.007082
  validation loss:		0.452115
  validation accuracy:		92.72 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.007007
  validation loss:		0.440240
  validation accuracy:		92.83 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.007057
  validation loss:		0.445769
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.006862
  validation loss:		0.449765
  validation accuracy:		92.83 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006963
  validation loss:		0.447231
  validation accuracy:		92.83 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.007002
  validation loss:		0.448686
  validation accuracy:		92.61 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.007041
  validation loss:		0.448160
  validation accuracy:		92.93 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.007015
  validation loss:		0.449185
  validation accuracy:		92.83 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.007142
  validation loss:		0.450430
  validation accuracy:		92.61 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006805
  validation loss:		0.450596
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.006966
  validation loss:		0.450694
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.007086
  validation loss:		0.450622
  validation accuracy:		92.83 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.006890
  validation loss:		0.446350
  validation accuracy:		92.83 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.006766
  validation loss:		0.449867
  validation accuracy:		92.83 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.007042
  validation loss:		0.447075
  validation accuracy:		92.83 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.007011
  validation loss:		0.451592
  validation accuracy:		92.72 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.006811
  validation loss:		0.449228
  validation accuracy:		92.72 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006897
  validation loss:		0.456606
  validation accuracy:		92.61 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.007045
  validation loss:		0.449260
  validation accuracy:		92.83 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006932
  validation loss:		0.445707
  validation accuracy:		92.93 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.006932
  validation loss:		0.454295
  validation accuracy:		92.72 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006675
  validation loss:		0.447052
  validation accuracy:		92.93 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006602
  validation loss:		0.453745
  validation accuracy:		92.72 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.006950
  validation loss:		0.448340
  validation accuracy:		92.93 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.006706
  validation loss:		0.449293
  validation accuracy:		92.93 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.006754
  validation loss:		0.447720
  validation accuracy:		92.93 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.006905
  validation loss:		0.447833
  validation accuracy:		92.93 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006874
  validation loss:		0.455835
  validation accuracy:		92.61 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.006565
  validation loss:		0.453405
  validation accuracy:		92.93 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.006711
  validation loss:		0.450290
  validation accuracy:		92.83 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006632
  validation loss:		0.447502
  validation accuracy:		92.93 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.006665
  validation loss:		0.448682
  validation accuracy:		92.93 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.006853
  validation loss:		0.446550
  validation accuracy:		93.04 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.006702
  validation loss:		0.452449
  validation accuracy:		92.83 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.006655
  validation loss:		0.456384
  validation accuracy:		92.61 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.006694
  validation loss:		0.448418
  validation accuracy:		93.04 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006564
  validation loss:		0.448874
  validation accuracy:		92.93 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.006955
  validation loss:		0.455554
  validation accuracy:		92.72 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.006707
  validation loss:		0.456617
  validation accuracy:		92.61 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.006765
  validation loss:		0.448683
  validation accuracy:		92.83 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.006466
  validation loss:		0.456442
  validation accuracy:		92.93 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006637
  validation loss:		0.454383
  validation accuracy:		92.72 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.006575
  validation loss:		0.451269
  validation accuracy:		92.83 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.006546
  validation loss:		0.458072
  validation accuracy:		92.61 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.006712
  validation loss:		0.457022
  validation accuracy:		92.72 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.006564
  validation loss:		0.449864
  validation accuracy:		92.93 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.006661
  validation loss:		0.448962
  validation accuracy:		93.04 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.006625
  validation loss:		0.458107
  validation accuracy:		92.83 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006537
  validation loss:		0.458861
  validation accuracy:		92.72 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.006646
  validation loss:		0.454990
  validation accuracy:		92.93 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.006272
  validation loss:		0.455773
  validation accuracy:		92.72 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.006513
  validation loss:		0.446878
  validation accuracy:		92.93 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.006817
  validation loss:		0.452600
  validation accuracy:		92.93 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.006345
  validation loss:		0.450393
  validation accuracy:		92.93 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.006446
  validation loss:		0.454522
  validation accuracy:		92.93 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.006361
  validation loss:		0.453560
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.006320
  validation loss:		0.468948
  validation accuracy:		92.50 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.006487
  validation loss:		0.454483
  validation accuracy:		92.93 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.006384
  validation loss:		0.453935
  validation accuracy:		92.93 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006149
  validation loss:		0.458422
  validation accuracy:		92.93 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.006284
  validation loss:		0.457108
  validation accuracy:		92.93 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.006320
  validation loss:		0.460415
  validation accuracy:		92.83 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.006388
  validation loss:		0.460100
  validation accuracy:		92.61 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.006378
  validation loss:		0.453291
  validation accuracy:		92.93 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.006411
  validation loss:		0.451486
  validation accuracy:		93.04 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.006445
  validation loss:		0.457970
  validation accuracy:		92.61 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.006402
  validation loss:		0.456892
  validation accuracy:		93.04 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.006297
  validation loss:		0.457832
  validation accuracy:		92.93 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.006267
  validation loss:		0.458583
  validation accuracy:		92.93 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.457889
  validation accuracy:		92.93 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.006157
  validation loss:		0.456596
  validation accuracy:		92.93 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.006132
  validation loss:		0.462576
  validation accuracy:		92.72 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.006265
  validation loss:		0.457680
  validation accuracy:		92.61 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.006023
  validation loss:		0.459553
  validation accuracy:		92.93 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.006146
  validation loss:		0.466563
  validation accuracy:		92.50 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.006136
  validation loss:		0.453569
  validation accuracy:		93.04 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.006259
  validation loss:		0.462986
  validation accuracy:		92.83 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.006237
  validation loss:		0.461031
  validation accuracy:		92.83 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.006177
  validation loss:		0.458807
  validation accuracy:		92.83 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.006091
  validation loss:		0.463654
  validation accuracy:		92.61 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.006082
  validation loss:		0.457823
  validation accuracy:		92.93 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.006178
  validation loss:		0.461836
  validation accuracy:		93.04 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.006286
  validation loss:		0.459114
  validation accuracy:		92.61 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.006162
  validation loss:		0.460677
  validation accuracy:		92.93 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.005792
  validation loss:		0.463790
  validation accuracy:		92.72 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.463923
  validation accuracy:		92.72 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.006294
  validation loss:		0.463083
  validation accuracy:		92.83 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.006190
  validation loss:		0.463957
  validation accuracy:		92.83 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.006018
  validation loss:		0.463035
  validation accuracy:		92.83 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.006312
  validation loss:		0.464584
  validation accuracy:		92.61 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.006314
  validation loss:		0.460795
  validation accuracy:		92.83 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.006147
  validation loss:		0.458191
  validation accuracy:		93.04 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.006075
  validation loss:		0.470652
  validation accuracy:		92.39 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.006001
  validation loss:		0.468849
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.006271
  validation loss:		0.468806
  validation accuracy:		92.61 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.006151
  validation loss:		0.455306
  validation accuracy:		93.15 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.006035
  validation loss:		0.469321
  validation accuracy:		92.72 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005977
  validation loss:		0.466799
  validation accuracy:		92.72 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.006099
  validation loss:		0.458039
  validation accuracy:		92.93 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005934
  validation loss:		0.471349
  validation accuracy:		92.61 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.006096
  validation loss:		0.460605
  validation accuracy:		92.93 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.006072
  validation loss:		0.470896
  validation accuracy:		92.50 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.006043
  validation loss:		0.464984
  validation accuracy:		92.83 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.005820
  validation loss:		0.460481
  validation accuracy:		92.83 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.006166
  validation loss:		0.468435
  validation accuracy:		92.50 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.006076
  validation loss:		0.462704
  validation accuracy:		92.83 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.006065
  validation loss:		0.461779
  validation accuracy:		92.83 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005679
  validation loss:		0.467532
  validation accuracy:		92.72 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005824
  validation loss:		0.459746
  validation accuracy:		92.83 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005964
  validation loss:		0.464558
  validation accuracy:		92.83 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.005924
  validation loss:		0.466863
  validation accuracy:		92.61 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.006058
  validation loss:		0.459415
  validation accuracy:		93.04 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.005861
  validation loss:		0.473640
  validation accuracy:		92.50 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005891
  validation loss:		0.460604
  validation accuracy:		93.15 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.005876
  validation loss:		0.472796
  validation accuracy:		92.39 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.005895
  validation loss:		0.468048
  validation accuracy:		92.83 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005697
  validation loss:		0.467771
  validation accuracy:		92.61 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.005852
  validation loss:		0.472074
  validation accuracy:		92.83 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005757
  validation loss:		0.465311
  validation accuracy:		92.93 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.005698
  validation loss:		0.466579
  validation accuracy:		92.83 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.005754
  validation loss:		0.469095
  validation accuracy:		92.72 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005792
  validation loss:		0.465481
  validation accuracy:		92.93 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.005679
  validation loss:		0.468368
  validation accuracy:		92.93 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.005795
  validation loss:		0.471835
  validation accuracy:		92.72 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005579
  validation loss:		0.463318
  validation accuracy:		93.04 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005665
  validation loss:		0.467350
  validation accuracy:		92.83 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.005775
  validation loss:		0.469521
  validation accuracy:		92.83 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.005974
  validation loss:		0.468015
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.005781
  validation loss:		0.472585
  validation accuracy:		92.72 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.005861
  validation loss:		0.476883
  validation accuracy:		92.50 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.005840
  validation loss:		0.468752
  validation accuracy:		92.93 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.005903
  validation loss:		0.480213
  validation accuracy:		92.39 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.005941
  validation loss:		0.467513
  validation accuracy:		92.83 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.005721
  validation loss:		0.469704
  validation accuracy:		92.83 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.005910
  validation loss:		0.478973
  validation accuracy:		92.61 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.005577
  validation loss:		0.469961
  validation accuracy:		92.93 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.005600
  validation loss:		0.473124
  validation accuracy:		92.39 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005634
  validation loss:		0.467504
  validation accuracy:		92.72 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.005823
  validation loss:		0.468388
  validation accuracy:		92.93 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.005517
  validation loss:		0.470218
  validation accuracy:		92.61 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005488
  validation loss:		0.465819
  validation accuracy:		93.04 %
Epoch 1531 of 2000 took 0.037s
  training loss:		0.005671
  validation loss:		0.476201
  validation accuracy:		92.72 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.005573
  validation loss:		0.473964
  validation accuracy:		92.72 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.005693
  validation loss:		0.471169
  validation accuracy:		92.83 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.005566
  validation loss:		0.477032
  validation accuracy:		92.61 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005712
  validation loss:		0.473887
  validation accuracy:		92.93 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005697
  validation loss:		0.475221
  validation accuracy:		92.83 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005621
  validation loss:		0.470824
  validation accuracy:		92.83 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.005591
  validation loss:		0.470535
  validation accuracy:		92.93 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005471
  validation loss:		0.476715
  validation accuracy:		92.50 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.005532
  validation loss:		0.470825
  validation accuracy:		92.93 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.005562
  validation loss:		0.477298
  validation accuracy:		92.61 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.005619
  validation loss:		0.473393
  validation accuracy:		93.04 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005454
  validation loss:		0.478844
  validation accuracy:		92.61 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005470
  validation loss:		0.468059
  validation accuracy:		92.93 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.005580
  validation loss:		0.472769
  validation accuracy:		92.93 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.005516
  validation loss:		0.473653
  validation accuracy:		92.93 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.005354
  validation loss:		0.479890
  validation accuracy:		92.72 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005383
  validation loss:		0.472806
  validation accuracy:		92.93 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005419
  validation loss:		0.483121
  validation accuracy:		92.83 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.005374
  validation loss:		0.475078
  validation accuracy:		92.72 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.005325
  validation loss:		0.475937
  validation accuracy:		92.83 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.005357
  validation loss:		0.475778
  validation accuracy:		92.61 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.005449
  validation loss:		0.479924
  validation accuracy:		92.39 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.005466
  validation loss:		0.475352
  validation accuracy:		92.93 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.005386
  validation loss:		0.474093
  validation accuracy:		92.93 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.005366
  validation loss:		0.481343
  validation accuracy:		92.83 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.005381
  validation loss:		0.480897
  validation accuracy:		92.61 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.005335
  validation loss:		0.484659
  validation accuracy:		92.93 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.005621
  validation loss:		0.471665
  validation accuracy:		93.04 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.005475
  validation loss:		0.480255
  validation accuracy:		92.93 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.005406
  validation loss:		0.479702
  validation accuracy:		92.61 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.005394
  validation loss:		0.468502
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.005366
  validation loss:		0.477857
  validation accuracy:		92.83 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.005328
  validation loss:		0.482862
  validation accuracy:		92.61 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.005381
  validation loss:		0.481634
  validation accuracy:		92.72 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.005127
  validation loss:		0.476470
  validation accuracy:		92.93 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.005429
  validation loss:		0.477992
  validation accuracy:		92.93 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.005385
  validation loss:		0.478573
  validation accuracy:		92.83 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.005229
  validation loss:		0.482668
  validation accuracy:		92.72 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.005316
  validation loss:		0.476859
  validation accuracy:		92.83 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.005297
  validation loss:		0.475650
  validation accuracy:		92.93 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.005173
  validation loss:		0.481449
  validation accuracy:		92.72 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.005393
  validation loss:		0.478681
  validation accuracy:		92.93 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.005300
  validation loss:		0.481225
  validation accuracy:		92.83 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.005258
  validation loss:		0.480932
  validation accuracy:		92.61 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.005109
  validation loss:		0.478583
  validation accuracy:		92.83 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.005173
  validation loss:		0.472087
  validation accuracy:		93.26 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005257
  validation loss:		0.486499
  validation accuracy:		92.50 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.005382
  validation loss:		0.478335
  validation accuracy:		92.83 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.005365
  validation loss:		0.486797
  validation accuracy:		92.50 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.005249
  validation loss:		0.478607
  validation accuracy:		92.93 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.005245
  validation loss:		0.483351
  validation accuracy:		92.83 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.005017
  validation loss:		0.482908
  validation accuracy:		92.61 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.005247
  validation loss:		0.481004
  validation accuracy:		92.72 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.005103
  validation loss:		0.479045
  validation accuracy:		92.83 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.005238
  validation loss:		0.488885
  validation accuracy:		92.72 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.005185
  validation loss:		0.485363
  validation accuracy:		92.61 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.005191
  validation loss:		0.479942
  validation accuracy:		93.04 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.005137
  validation loss:		0.483555
  validation accuracy:		92.61 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.005253
  validation loss:		0.484987
  validation accuracy:		92.72 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004939
  validation loss:		0.486307
  validation accuracy:		92.93 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.005015
  validation loss:		0.488669
  validation accuracy:		92.50 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.005157
  validation loss:		0.484387
  validation accuracy:		92.61 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.005032
  validation loss:		0.474752
  validation accuracy:		92.93 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005221
  validation loss:		0.485031
  validation accuracy:		92.61 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004930
  validation loss:		0.479692
  validation accuracy:		93.04 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.005115
  validation loss:		0.482877
  validation accuracy:		92.83 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.005216
  validation loss:		0.480596
  validation accuracy:		92.93 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.005144
  validation loss:		0.490337
  validation accuracy:		92.50 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.005105
  validation loss:		0.482637
  validation accuracy:		92.93 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004995
  validation loss:		0.483610
  validation accuracy:		92.83 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004946
  validation loss:		0.491180
  validation accuracy:		92.61 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005095
  validation loss:		0.482836
  validation accuracy:		92.93 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.004919
  validation loss:		0.484689
  validation accuracy:		92.83 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005003
  validation loss:		0.483459
  validation accuracy:		93.04 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004906
  validation loss:		0.487973
  validation accuracy:		92.61 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.005021
  validation loss:		0.484887
  validation accuracy:		93.04 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004939
  validation loss:		0.478383
  validation accuracy:		93.04 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005234
  validation loss:		0.487203
  validation accuracy:		92.83 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004959
  validation loss:		0.485708
  validation accuracy:		92.72 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004892
  validation loss:		0.479762
  validation accuracy:		93.04 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005024
  validation loss:		0.484466
  validation accuracy:		92.83 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005110
  validation loss:		0.486737
  validation accuracy:		92.93 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004973
  validation loss:		0.486600
  validation accuracy:		92.61 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004677
  validation loss:		0.482396
  validation accuracy:		93.04 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.005045
  validation loss:		0.489471
  validation accuracy:		92.72 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004923
  validation loss:		0.486217
  validation accuracy:		92.93 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.004858
  validation loss:		0.481019
  validation accuracy:		93.04 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004921
  validation loss:		0.494715
  validation accuracy:		92.39 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004861
  validation loss:		0.486751
  validation accuracy:		92.61 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004952
  validation loss:		0.492156
  validation accuracy:		92.72 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004902
  validation loss:		0.495552
  validation accuracy:		92.50 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004758
  validation loss:		0.482656
  validation accuracy:		93.04 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004955
  validation loss:		0.485163
  validation accuracy:		92.83 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.490575
  validation accuracy:		92.72 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004751
  validation loss:		0.481223
  validation accuracy:		93.15 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005134
  validation loss:		0.491113
  validation accuracy:		92.61 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005010
  validation loss:		0.486998
  validation accuracy:		92.83 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004851
  validation loss:		0.486016
  validation accuracy:		92.93 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004728
  validation loss:		0.490984
  validation accuracy:		92.61 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004734
  validation loss:		0.491037
  validation accuracy:		92.83 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004895
  validation loss:		0.492141
  validation accuracy:		92.93 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004688
  validation loss:		0.491718
  validation accuracy:		92.72 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004761
  validation loss:		0.494066
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004670
  validation loss:		0.484237
  validation accuracy:		93.04 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004757
  validation loss:		0.487347
  validation accuracy:		93.04 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.488284
  validation accuracy:		92.93 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004804
  validation loss:		0.488448
  validation accuracy:		92.93 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004801
  validation loss:		0.488525
  validation accuracy:		92.83 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004655
  validation loss:		0.490999
  validation accuracy:		92.72 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.493088
  validation accuracy:		92.83 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004706
  validation loss:		0.490920
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004854
  validation loss:		0.495883
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.004723
  validation loss:		0.489291
  validation accuracy:		92.93 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004620
  validation loss:		0.498619
  validation accuracy:		92.61 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004617
  validation loss:		0.492196
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004768
  validation loss:		0.487862
  validation accuracy:		92.93 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004757
  validation loss:		0.489099
  validation accuracy:		92.93 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.004857
  validation loss:		0.502745
  validation accuracy:		92.39 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004640
  validation loss:		0.486439
  validation accuracy:		93.04 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.004674
  validation loss:		0.498028
  validation accuracy:		92.50 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004546
  validation loss:		0.492414
  validation accuracy:		92.72 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004721
  validation loss:		0.495659
  validation accuracy:		92.83 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004639
  validation loss:		0.496581
  validation accuracy:		92.72 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004776
  validation loss:		0.492272
  validation accuracy:		93.04 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004585
  validation loss:		0.494809
  validation accuracy:		92.61 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004688
  validation loss:		0.486330
  validation accuracy:		92.93 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.004542
  validation loss:		0.499534
  validation accuracy:		92.72 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.004570
  validation loss:		0.487346
  validation accuracy:		93.15 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004872
  validation loss:		0.489783
  validation accuracy:		93.04 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004712
  validation loss:		0.489362
  validation accuracy:		93.04 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.004626
  validation loss:		0.498587
  validation accuracy:		92.61 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004686
  validation loss:		0.499837
  validation accuracy:		92.83 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004591
  validation loss:		0.494637
  validation accuracy:		92.83 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004525
  validation loss:		0.492964
  validation accuracy:		92.72 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004534
  validation loss:		0.488510
  validation accuracy:		93.04 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004582
  validation loss:		0.505864
  validation accuracy:		92.39 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004546
  validation loss:		0.491641
  validation accuracy:		92.93 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.004604
  validation loss:		0.492761
  validation accuracy:		93.04 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.004653
  validation loss:		0.495300
  validation accuracy:		92.83 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004535
  validation loss:		0.498021
  validation accuracy:		92.61 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.004545
  validation loss:		0.493789
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.494796
  validation accuracy:		92.93 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004408
  validation loss:		0.497913
  validation accuracy:		92.61 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.004498
  validation loss:		0.496598
  validation accuracy:		92.72 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.004581
  validation loss:		0.489264
  validation accuracy:		93.15 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.500916
  validation accuracy:		92.83 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.004550
  validation loss:		0.496129
  validation accuracy:		92.83 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.495749
  validation accuracy:		92.93 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004450
  validation loss:		0.498778
  validation accuracy:		92.72 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004548
  validation loss:		0.496495
  validation accuracy:		92.93 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004450
  validation loss:		0.499427
  validation accuracy:		92.72 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.004377
  validation loss:		0.501253
  validation accuracy:		92.39 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004543
  validation loss:		0.501120
  validation accuracy:		92.83 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.004361
  validation loss:		0.501261
  validation accuracy:		92.72 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.004452
  validation loss:		0.496760
  validation accuracy:		92.93 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.501440
  validation accuracy:		92.72 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.004489
  validation loss:		0.500514
  validation accuracy:		92.50 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.004367
  validation loss:		0.498218
  validation accuracy:		92.93 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.004428
  validation loss:		0.494563
  validation accuracy:		93.04 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.004267
  validation loss:		0.499498
  validation accuracy:		92.72 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004382
  validation loss:		0.504056
  validation accuracy:		92.39 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.004391
  validation loss:		0.499722
  validation accuracy:		92.83 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.004503
  validation loss:		0.499790
  validation accuracy:		92.72 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.004466
  validation loss:		0.497858
  validation accuracy:		93.04 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.004476
  validation loss:		0.500150
  validation accuracy:		92.72 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.004351
  validation loss:		0.496789
  validation accuracy:		93.04 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004409
  validation loss:		0.504099
  validation accuracy:		92.83 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.004261
  validation loss:		0.495845
  validation accuracy:		92.83 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004319
  validation loss:		0.501789
  validation accuracy:		92.83 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004400
  validation loss:		0.503146
  validation accuracy:		92.61 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.004222
  validation loss:		0.496893
  validation accuracy:		92.93 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.004305
  validation loss:		0.505203
  validation accuracy:		92.72 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004317
  validation loss:		0.500159
  validation accuracy:		92.83 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004243
  validation loss:		0.504430
  validation accuracy:		92.72 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004330
  validation loss:		0.497896
  validation accuracy:		93.04 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.004248
  validation loss:		0.506200
  validation accuracy:		92.72 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004436
  validation loss:		0.505084
  validation accuracy:		92.72 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004357
  validation loss:		0.502207
  validation accuracy:		92.72 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.004169
  validation loss:		0.502791
  validation accuracy:		92.83 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004255
  validation loss:		0.501406
  validation accuracy:		92.72 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004259
  validation loss:		0.502565
  validation accuracy:		92.83 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004354
  validation loss:		0.504624
  validation accuracy:		92.72 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.004282
  validation loss:		0.505294
  validation accuracy:		92.72 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004338
  validation loss:		0.499946
  validation accuracy:		92.93 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004197
  validation loss:		0.513956
  validation accuracy:		92.50 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004425
  validation loss:		0.500378
  validation accuracy:		92.83 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004189
  validation loss:		0.504601
  validation accuracy:		92.72 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004020
  validation loss:		0.505769
  validation accuracy:		92.72 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.004236
  validation loss:		0.503456
  validation accuracy:		92.72 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004308
  validation loss:		0.507807
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.504632
  validation accuracy:		92.61 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004329
  validation loss:		0.502941
  validation accuracy:		92.83 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004175
  validation loss:		0.505066
  validation accuracy:		92.83 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.501039
  validation accuracy:		92.93 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.505692
  validation accuracy:		92.83 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004139
  validation loss:		0.504819
  validation accuracy:		92.61 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004316
  validation loss:		0.498525
  validation accuracy:		93.04 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004328
  validation loss:		0.507509
  validation accuracy:		92.72 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.509947
  validation accuracy:		92.72 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004081
  validation loss:		0.507999
  validation accuracy:		92.72 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.003965
  validation loss:		0.503055
  validation accuracy:		92.93 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004177
  validation loss:		0.509145
  validation accuracy:		92.83 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004185
  validation loss:		0.506647
  validation accuracy:		92.72 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004174
  validation loss:		0.504868
  validation accuracy:		92.83 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004113
  validation loss:		0.504855
  validation accuracy:		92.83 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004231
  validation loss:		0.503712
  validation accuracy:		92.83 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004102
  validation loss:		0.505577
  validation accuracy:		92.83 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004114
  validation loss:		0.508107
  validation accuracy:		92.72 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004173
  validation loss:		0.505983
  validation accuracy:		92.83 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004172
  validation loss:		0.510226
  validation accuracy:		92.72 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.512192
  validation accuracy:		92.61 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.512434
  validation accuracy:		92.72 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004074
  validation loss:		0.500025
  validation accuracy:		93.04 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004113
  validation loss:		0.506450
  validation accuracy:		92.83 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004079
  validation loss:		0.508416
  validation accuracy:		92.72 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004100
  validation loss:		0.507716
  validation accuracy:		92.83 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004160
  validation loss:		0.511213
  validation accuracy:		92.72 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004151
  validation loss:		0.498852
  validation accuracy:		92.93 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004125
  validation loss:		0.511821
  validation accuracy:		92.61 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004085
  validation loss:		0.514084
  validation accuracy:		92.72 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004065
  validation loss:		0.510588
  validation accuracy:		92.72 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004074
  validation loss:		0.507436
  validation accuracy:		92.72 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004110
  validation loss:		0.517070
  validation accuracy:		92.50 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004056
  validation loss:		0.512909
  validation accuracy:		92.83 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004180
  validation loss:		0.511913
  validation accuracy:		92.72 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004055
  validation loss:		0.516261
  validation accuracy:		92.50 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004021
  validation loss:		0.510557
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004019
  validation loss:		0.511889
  validation accuracy:		92.72 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004003
  validation loss:		0.502568
  validation accuracy:		93.04 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004012
  validation loss:		0.510866
  validation accuracy:		92.72 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.508014
  validation accuracy:		92.83 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004054
  validation loss:		0.506601
  validation accuracy:		92.83 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003941
  validation loss:		0.515209
  validation accuracy:		92.50 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003905
  validation loss:		0.509990
  validation accuracy:		92.72 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004016
  validation loss:		0.511236
  validation accuracy:		92.72 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003968
  validation loss:		0.511293
  validation accuracy:		92.72 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004110
  validation loss:		0.507472
  validation accuracy:		92.72 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004029
  validation loss:		0.513313
  validation accuracy:		92.83 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004074
  validation loss:		0.509491
  validation accuracy:		92.72 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003894
  validation loss:		0.513524
  validation accuracy:		92.72 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.003979
  validation loss:		0.512603
  validation accuracy:		92.72 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003988
  validation loss:		0.512746
  validation accuracy:		92.72 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004022
  validation loss:		0.509126
  validation accuracy:		92.83 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004010
  validation loss:		0.510883
  validation accuracy:		92.93 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003975
  validation loss:		0.514028
  validation accuracy:		92.72 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.003870
  validation loss:		0.508825
  validation accuracy:		92.72 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003902
  validation loss:		0.514284
  validation accuracy:		92.61 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.003860
  validation loss:		0.511612
  validation accuracy:		92.83 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.516401
  validation accuracy:		92.72 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004044
  validation loss:		0.513762
  validation accuracy:		92.72 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004019
  validation loss:		0.512060
  validation accuracy:		92.72 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003877
  validation loss:		0.516397
  validation accuracy:		92.72 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004045
  validation loss:		0.513419
  validation accuracy:		92.83 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003803
  validation loss:		0.515665
  validation accuracy:		92.61 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.003855
  validation loss:		0.508971
  validation accuracy:		92.83 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003848
  validation loss:		0.518576
  validation accuracy:		92.50 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003821
  validation loss:		0.515241
  validation accuracy:		92.72 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003827
  validation loss:		0.515548
  validation accuracy:		92.72 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003919
  validation loss:		0.513547
  validation accuracy:		92.83 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003935
  validation loss:		0.512421
  validation accuracy:		92.83 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003967
  validation loss:		0.515294
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003955
  validation loss:		0.511672
  validation accuracy:		92.83 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003824
  validation loss:		0.513868
  validation accuracy:		92.72 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003884
  validation loss:		0.517646
  validation accuracy:		92.72 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003885
  validation loss:		0.517520
  validation accuracy:		92.72 %
Epoch 1797 of 2000 took 0.036s
  training loss:		0.003810
  validation loss:		0.513465
  validation accuracy:		92.83 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003917
  validation loss:		0.516192
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.518265
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003880
  validation loss:		0.520907
  validation accuracy:		92.61 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003838
  validation loss:		0.520227
  validation accuracy:		92.72 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.519806
  validation accuracy:		92.72 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003798
  validation loss:		0.514744
  validation accuracy:		92.93 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003703
  validation loss:		0.518297
  validation accuracy:		92.72 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003848
  validation loss:		0.518645
  validation accuracy:		92.72 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003784
  validation loss:		0.517112
  validation accuracy:		92.72 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.521196
  validation accuracy:		92.72 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.515553
  validation accuracy:		92.72 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003801
  validation loss:		0.521402
  validation accuracy:		92.50 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.517558
  validation accuracy:		92.72 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.520714
  validation accuracy:		92.83 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003840
  validation loss:		0.524360
  validation accuracy:		92.50 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.515217
  validation accuracy:		92.93 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003809
  validation loss:		0.513522
  validation accuracy:		92.83 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003735
  validation loss:		0.520468
  validation accuracy:		92.72 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003665
  validation loss:		0.525179
  validation accuracy:		92.61 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003744
  validation loss:		0.520668
  validation accuracy:		92.72 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003643
  validation loss:		0.514589
  validation accuracy:		92.93 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003712
  validation loss:		0.519706
  validation accuracy:		92.72 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003767
  validation loss:		0.516830
  validation accuracy:		92.93 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003696
  validation loss:		0.517710
  validation accuracy:		92.83 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003821
  validation loss:		0.522569
  validation accuracy:		92.61 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003758
  validation loss:		0.520182
  validation accuracy:		92.72 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003700
  validation loss:		0.520767
  validation accuracy:		92.83 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.524516
  validation accuracy:		92.50 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003642
  validation loss:		0.510999
  validation accuracy:		92.93 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003693
  validation loss:		0.523671
  validation accuracy:		92.61 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003656
  validation loss:		0.515975
  validation accuracy:		92.83 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003718
  validation loss:		0.522644
  validation accuracy:		92.61 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003591
  validation loss:		0.516830
  validation accuracy:		92.93 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003747
  validation loss:		0.521511
  validation accuracy:		92.72 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003652
  validation loss:		0.519660
  validation accuracy:		92.83 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.521785
  validation accuracy:		92.72 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003604
  validation loss:		0.520131
  validation accuracy:		92.72 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003608
  validation loss:		0.520223
  validation accuracy:		92.72 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.522221
  validation accuracy:		92.72 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003651
  validation loss:		0.523442
  validation accuracy:		92.83 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003744
  validation loss:		0.521490
  validation accuracy:		92.72 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003652
  validation loss:		0.518160
  validation accuracy:		92.93 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003642
  validation loss:		0.526712
  validation accuracy:		92.61 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003651
  validation loss:		0.517844
  validation accuracy:		92.72 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003571
  validation loss:		0.524466
  validation accuracy:		92.61 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003608
  validation loss:		0.524555
  validation accuracy:		92.72 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003610
  validation loss:		0.524786
  validation accuracy:		92.72 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003718
  validation loss:		0.524133
  validation accuracy:		92.72 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003611
  validation loss:		0.519855
  validation accuracy:		93.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003670
  validation loss:		0.518985
  validation accuracy:		92.83 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003581
  validation loss:		0.528502
  validation accuracy:		92.72 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003657
  validation loss:		0.522640
  validation accuracy:		92.72 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003625
  validation loss:		0.521763
  validation accuracy:		92.72 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003638
  validation loss:		0.524149
  validation accuracy:		92.72 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003505
  validation loss:		0.520920
  validation accuracy:		92.83 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003566
  validation loss:		0.521676
  validation accuracy:		92.72 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003517
  validation loss:		0.523782
  validation accuracy:		92.83 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003561
  validation loss:		0.523417
  validation accuracy:		92.72 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003563
  validation loss:		0.524762
  validation accuracy:		92.83 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003558
  validation loss:		0.521630
  validation accuracy:		92.93 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003584
  validation loss:		0.527155
  validation accuracy:		92.72 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003565
  validation loss:		0.524547
  validation accuracy:		92.72 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003607
  validation loss:		0.525983
  validation accuracy:		92.72 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003542
  validation loss:		0.520895
  validation accuracy:		92.83 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003547
  validation loss:		0.524674
  validation accuracy:		92.83 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003470
  validation loss:		0.521396
  validation accuracy:		92.93 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003655
  validation loss:		0.523787
  validation accuracy:		92.83 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003452
  validation loss:		0.529022
  validation accuracy:		92.72 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003528
  validation loss:		0.530659
  validation accuracy:		92.72 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003552
  validation loss:		0.532290
  validation accuracy:		92.61 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003562
  validation loss:		0.527634
  validation accuracy:		92.83 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003506
  validation loss:		0.523697
  validation accuracy:		92.83 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003514
  validation loss:		0.527516
  validation accuracy:		92.61 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003567
  validation loss:		0.523806
  validation accuracy:		92.72 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003480
  validation loss:		0.526975
  validation accuracy:		92.72 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003372
  validation loss:		0.529054
  validation accuracy:		92.72 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.523722
  validation accuracy:		92.83 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003435
  validation loss:		0.525355
  validation accuracy:		92.93 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003486
  validation loss:		0.523926
  validation accuracy:		92.93 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003525
  validation loss:		0.524924
  validation accuracy:		92.93 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003413
  validation loss:		0.527239
  validation accuracy:		92.72 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003394
  validation loss:		0.527482
  validation accuracy:		92.83 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003571
  validation loss:		0.523293
  validation accuracy:		92.83 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003424
  validation loss:		0.528182
  validation accuracy:		92.72 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003432
  validation loss:		0.526571
  validation accuracy:		92.72 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003479
  validation loss:		0.524574
  validation accuracy:		92.83 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003443
  validation loss:		0.529059
  validation accuracy:		92.72 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003429
  validation loss:		0.525280
  validation accuracy:		92.83 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003481
  validation loss:		0.527280
  validation accuracy:		92.72 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003314
  validation loss:		0.531468
  validation accuracy:		92.61 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003356
  validation loss:		0.529420
  validation accuracy:		92.72 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003319
  validation loss:		0.530275
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003385
  validation loss:		0.527105
  validation accuracy:		92.83 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003375
  validation loss:		0.532522
  validation accuracy:		92.61 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003433
  validation loss:		0.529597
  validation accuracy:		92.72 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003458
  validation loss:		0.526634
  validation accuracy:		92.83 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003419
  validation loss:		0.527413
  validation accuracy:		92.83 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003504
  validation loss:		0.533613
  validation accuracy:		92.50 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003376
  validation loss:		0.529444
  validation accuracy:		92.72 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003402
  validation loss:		0.523749
  validation accuracy:		92.93 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003490
  validation loss:		0.528897
  validation accuracy:		92.72 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003380
  validation loss:		0.533481
  validation accuracy:		92.61 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003443
  validation loss:		0.530806
  validation accuracy:		92.72 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003363
  validation loss:		0.528952
  validation accuracy:		92.83 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003433
  validation loss:		0.529422
  validation accuracy:		92.72 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003496
  validation loss:		0.526572
  validation accuracy:		92.83 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003407
  validation loss:		0.528500
  validation accuracy:		92.72 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003292
  validation loss:		0.533718
  validation accuracy:		92.50 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003230
  validation loss:		0.531918
  validation accuracy:		92.72 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003318
  validation loss:		0.529999
  validation accuracy:		92.72 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003310
  validation loss:		0.532802
  validation accuracy:		92.61 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003361
  validation loss:		0.531187
  validation accuracy:		92.72 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003382
  validation loss:		0.530468
  validation accuracy:		92.72 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003415
  validation loss:		0.534155
  validation accuracy:		92.50 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003258
  validation loss:		0.530261
  validation accuracy:		92.72 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003274
  validation loss:		0.532047
  validation accuracy:		92.72 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003439
  validation loss:		0.532632
  validation accuracy:		92.72 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003320
  validation loss:		0.533246
  validation accuracy:		92.72 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003405
  validation loss:		0.535667
  validation accuracy:		92.61 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003381
  validation loss:		0.535930
  validation accuracy:		92.72 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003315
  validation loss:		0.531528
  validation accuracy:		92.83 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003304
  validation loss:		0.531728
  validation accuracy:		92.72 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003272
  validation loss:		0.532391
  validation accuracy:		92.61 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003241
  validation loss:		0.533497
  validation accuracy:		92.72 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003267
  validation loss:		0.533344
  validation accuracy:		92.72 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003331
  validation loss:		0.533710
  validation accuracy:		92.72 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003285
  validation loss:		0.528505
  validation accuracy:		92.83 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003356
  validation loss:		0.532824
  validation accuracy:		92.72 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003272
  validation loss:		0.533863
  validation accuracy:		92.72 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003291
  validation loss:		0.538472
  validation accuracy:		92.72 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.537462
  validation accuracy:		92.72 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003261
  validation loss:		0.533631
  validation accuracy:		92.83 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003352
  validation loss:		0.533052
  validation accuracy:		92.72 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003240
  validation loss:		0.532767
  validation accuracy:		92.72 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003324
  validation loss:		0.534682
  validation accuracy:		92.61 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003197
  validation loss:		0.538130
  validation accuracy:		92.72 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003222
  validation loss:		0.534533
  validation accuracy:		92.61 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003289
  validation loss:		0.538600
  validation accuracy:		92.72 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003231
  validation loss:		0.532240
  validation accuracy:		92.83 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003254
  validation loss:		0.543167
  validation accuracy:		92.50 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003290
  validation loss:		0.534264
  validation accuracy:		92.72 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003163
  validation loss:		0.538072
  validation accuracy:		92.61 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003224
  validation loss:		0.529516
  validation accuracy:		92.83 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003242
  validation loss:		0.535832
  validation accuracy:		92.72 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003141
  validation loss:		0.538766
  validation accuracy:		92.72 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003311
  validation loss:		0.536960
  validation accuracy:		92.72 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003202
  validation loss:		0.534864
  validation accuracy:		92.83 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003297
  validation loss:		0.535470
  validation accuracy:		92.61 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003207
  validation loss:		0.537930
  validation accuracy:		92.72 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003085
  validation loss:		0.536505
  validation accuracy:		92.61 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003281
  validation loss:		0.532980
  validation accuracy:		92.93 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003179
  validation loss:		0.538582
  validation accuracy:		92.72 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003142
  validation loss:		0.542129
  validation accuracy:		92.61 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003204
  validation loss:		0.533395
  validation accuracy:		92.72 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003136
  validation loss:		0.534650
  validation accuracy:		92.72 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003149
  validation loss:		0.539830
  validation accuracy:		92.61 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003231
  validation loss:		0.536300
  validation accuracy:		92.61 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003126
  validation loss:		0.536821
  validation accuracy:		92.83 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003159
  validation loss:		0.538141
  validation accuracy:		92.72 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003161
  validation loss:		0.536060
  validation accuracy:		92.72 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003183
  validation loss:		0.533236
  validation accuracy:		92.72 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003114
  validation loss:		0.537312
  validation accuracy:		92.72 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.540881
  validation accuracy:		92.61 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003132
  validation loss:		0.541203
  validation accuracy:		92.61 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003140
  validation loss:		0.540336
  validation accuracy:		92.72 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003147
  validation loss:		0.539853
  validation accuracy:		92.72 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003176
  validation loss:		0.538705
  validation accuracy:		92.72 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003110
  validation loss:		0.541667
  validation accuracy:		92.61 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003144
  validation loss:		0.536099
  validation accuracy:		92.61 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003217
  validation loss:		0.542962
  validation accuracy:		92.61 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003115
  validation loss:		0.536988
  validation accuracy:		92.83 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003108
  validation loss:		0.542046
  validation accuracy:		92.72 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003092
  validation loss:		0.539749
  validation accuracy:		92.61 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003091
  validation loss:		0.539424
  validation accuracy:		92.72 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003145
  validation loss:		0.539035
  validation accuracy:		92.72 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003142
  validation loss:		0.538396
  validation accuracy:		92.93 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003102
  validation loss:		0.534235
  validation accuracy:		92.83 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003066
  validation loss:		0.546580
  validation accuracy:		92.72 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003074
  validation loss:		0.540900
  validation accuracy:		92.72 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003148
  validation loss:		0.535868
  validation accuracy:		92.93 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003148
  validation loss:		0.540655
  validation accuracy:		92.72 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003058
  validation loss:		0.541695
  validation accuracy:		92.50 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.002983
  validation loss:		0.540416
  validation accuracy:		92.72 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003144
  validation loss:		0.538501
  validation accuracy:		92.83 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003119
  validation loss:		0.544541
  validation accuracy:		92.61 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003070
  validation loss:		0.541185
  validation accuracy:		92.72 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.002996
  validation loss:		0.545006
  validation accuracy:		92.61 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003139
  validation loss:		0.538507
  validation accuracy:		92.83 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003074
  validation loss:		0.540390
  validation accuracy:		92.72 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003082
  validation loss:		0.540906
  validation accuracy:		92.83 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003127
  validation loss:		0.541649
  validation accuracy:		92.50 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003087
  validation loss:		0.539390
  validation accuracy:		92.72 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003042
  validation loss:		0.544313
  validation accuracy:		92.61 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003099
  validation loss:		0.540784
  validation accuracy:		92.83 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003128
  validation loss:		0.542134
  validation accuracy:		92.61 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003032
  validation loss:		0.549001
  validation accuracy:		92.72 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003076
  validation loss:		0.542262
  validation accuracy:		92.72 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003094
  validation loss:		0.542031
  validation accuracy:		92.61 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003029
  validation loss:		0.541477
  validation accuracy:		92.61 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003065
  validation loss:		0.543191
  validation accuracy:		92.72 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003079
  validation loss:		0.544874
  validation accuracy:		92.61 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.002950
  validation loss:		0.544658
  validation accuracy:		92.72 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.002993
  validation loss:		0.543667
  validation accuracy:		92.72 %
Final results:
  test loss:			1.233748
  test accuracy:		84.84 %
