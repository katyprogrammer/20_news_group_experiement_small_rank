Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.111s
  training loss:		2.987428
  validation loss:		2.973303
  validation accuracy:		12.39 %
Epoch 2 of 2000 took 0.106s
  training loss:		2.957730
  validation loss:		2.932937
  validation accuracy:		12.93 %
Epoch 3 of 2000 took 0.105s
  training loss:		2.919492
  validation loss:		2.889681
  validation accuracy:		12.39 %
Epoch 4 of 2000 took 0.106s
  training loss:		2.882777
  validation loss:		2.846910
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.106s
  training loss:		2.844489
  validation loss:		2.804702
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.106s
  training loss:		2.808603
  validation loss:		2.763484
  validation accuracy:		12.83 %
Epoch 7 of 2000 took 0.106s
  training loss:		2.774990
  validation loss:		2.722736
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.105s
  training loss:		2.739393
  validation loss:		2.682658
  validation accuracy:		12.83 %
Epoch 9 of 2000 took 0.106s
  training loss:		2.704961
  validation loss:		2.642176
  validation accuracy:		12.83 %
Epoch 10 of 2000 took 0.111s
  training loss:		2.672593
  validation loss:		2.602291
  validation accuracy:		12.83 %
Epoch 11 of 2000 took 0.107s
  training loss:		2.641160
  validation loss:		2.563489
  validation accuracy:		12.93 %
Epoch 12 of 2000 took 0.105s
  training loss:		2.608593
  validation loss:		2.525434
  validation accuracy:		12.93 %
Epoch 13 of 2000 took 0.106s
  training loss:		2.576111
  validation loss:		2.488491
  validation accuracy:		12.93 %
Epoch 14 of 2000 took 0.106s
  training loss:		2.546515
  validation loss:		2.451602
  validation accuracy:		12.93 %
Epoch 15 of 2000 took 0.106s
  training loss:		2.516865
  validation loss:		2.416528
  validation accuracy:		12.93 %
Epoch 16 of 2000 took 0.106s
  training loss:		2.487533
  validation loss:		2.384343
  validation accuracy:		12.93 %
Epoch 17 of 2000 took 0.106s
  training loss:		2.460769
  validation loss:		2.354686
  validation accuracy:		12.93 %
Epoch 18 of 2000 took 0.106s
  training loss:		2.434906
  validation loss:		2.327861
  validation accuracy:		12.93 %
Epoch 19 of 2000 took 0.106s
  training loss:		2.408336
  validation loss:		2.306517
  validation accuracy:		12.93 %
Epoch 20 of 2000 took 0.106s
  training loss:		2.386695
  validation loss:		2.287324
  validation accuracy:		12.93 %
Epoch 21 of 2000 took 0.106s
  training loss:		2.369580
  validation loss:		2.274499
  validation accuracy:		12.93 %
Epoch 22 of 2000 took 0.105s
  training loss:		2.353691
  validation loss:		2.268269
  validation accuracy:		15.76 %
Epoch 23 of 2000 took 0.106s
  training loss:		2.340658
  validation loss:		2.264047
  validation accuracy:		20.65 %
Epoch 24 of 2000 took 0.105s
  training loss:		2.331247
  validation loss:		2.260059
  validation accuracy:		14.13 %
Epoch 25 of 2000 took 0.106s
  training loss:		2.323385
  validation loss:		2.259554
  validation accuracy:		27.39 %
Epoch 26 of 2000 took 0.105s
  training loss:		2.317752
  validation loss:		2.257467
  validation accuracy:		20.98 %
Epoch 27 of 2000 took 0.106s
  training loss:		2.313004
  validation loss:		2.255115
  validation accuracy:		19.89 %
Epoch 28 of 2000 took 0.106s
  training loss:		2.308928
  validation loss:		2.252435
  validation accuracy:		14.57 %
Epoch 29 of 2000 took 0.106s
  training loss:		2.305971
  validation loss:		2.252392
  validation accuracy:		23.37 %
Epoch 30 of 2000 took 0.110s
  training loss:		2.304075
  validation loss:		2.248310
  validation accuracy:		22.72 %
Epoch 31 of 2000 took 0.105s
  training loss:		2.301162
  validation loss:		2.246009
  validation accuracy:		16.20 %
Epoch 32 of 2000 took 0.110s
  training loss:		2.299794
  validation loss:		2.242044
  validation accuracy:		19.24 %
Epoch 33 of 2000 took 0.146s
  training loss:		2.297985
  validation loss:		2.245259
  validation accuracy:		23.48 %
Epoch 34 of 2000 took 0.104s
  training loss:		2.297881
  validation loss:		2.244661
  validation accuracy:		19.78 %
Epoch 35 of 2000 took 0.102s
  training loss:		2.296098
  validation loss:		2.240713
  validation accuracy:		22.07 %
Epoch 36 of 2000 took 0.103s
  training loss:		2.294211
  validation loss:		2.240568
  validation accuracy:		17.39 %
Epoch 37 of 2000 took 0.101s
  training loss:		2.293659
  validation loss:		2.240182
  validation accuracy:		21.74 %
Epoch 38 of 2000 took 0.103s
  training loss:		2.293125
  validation loss:		2.238020
  validation accuracy:		15.33 %
Epoch 39 of 2000 took 0.102s
  training loss:		2.292140
  validation loss:		2.239762
  validation accuracy:		18.91 %
Epoch 40 of 2000 took 0.101s
  training loss:		2.292035
  validation loss:		2.240082
  validation accuracy:		18.26 %
Epoch 41 of 2000 took 0.101s
  training loss:		2.291277
  validation loss:		2.239095
  validation accuracy:		16.74 %
Epoch 42 of 2000 took 0.102s
  training loss:		2.290509
  validation loss:		2.239404
  validation accuracy:		18.26 %
Epoch 43 of 2000 took 0.100s
  training loss:		2.288458
  validation loss:		2.237517
  validation accuracy:		20.43 %
Epoch 44 of 2000 took 0.101s
  training loss:		2.287399
  validation loss:		2.232188
  validation accuracy:		22.39 %
Epoch 45 of 2000 took 0.102s
  training loss:		2.287863
  validation loss:		2.229670
  validation accuracy:		22.50 %
Epoch 46 of 2000 took 0.101s
  training loss:		2.287018
  validation loss:		2.232281
  validation accuracy:		19.78 %
Epoch 47 of 2000 took 0.102s
  training loss:		2.286204
  validation loss:		2.233363
  validation accuracy:		21.74 %
Epoch 48 of 2000 took 0.101s
  training loss:		2.285779
  validation loss:		2.235038
  validation accuracy:		23.48 %
Epoch 49 of 2000 took 0.103s
  training loss:		2.284380
  validation loss:		2.231062
  validation accuracy:		21.41 %
Epoch 50 of 2000 took 0.100s
  training loss:		2.284346
  validation loss:		2.228243
  validation accuracy:		24.24 %
Epoch 51 of 2000 took 0.101s
  training loss:		2.282534
  validation loss:		2.229765
  validation accuracy:		24.57 %
Epoch 52 of 2000 took 0.111s
  training loss:		2.282861
  validation loss:		2.229053
  validation accuracy:		22.50 %
Epoch 53 of 2000 took 0.103s
  training loss:		2.281840
  validation loss:		2.229020
  validation accuracy:		20.98 %
Epoch 54 of 2000 took 0.101s
  training loss:		2.279780
  validation loss:		2.229464
  validation accuracy:		23.15 %
Epoch 55 of 2000 took 0.101s
  training loss:		2.279255
  validation loss:		2.223464
  validation accuracy:		23.37 %
Epoch 56 of 2000 took 0.101s
  training loss:		2.278675
  validation loss:		2.221785
  validation accuracy:		17.83 %
Epoch 57 of 2000 took 0.101s
  training loss:		2.277557
  validation loss:		2.224366
  validation accuracy:		24.78 %
Epoch 58 of 2000 took 0.101s
  training loss:		2.275693
  validation loss:		2.221689
  validation accuracy:		24.35 %
Epoch 59 of 2000 took 0.101s
  training loss:		2.276161
  validation loss:		2.224343
  validation accuracy:		22.07 %
Epoch 60 of 2000 took 0.101s
  training loss:		2.273743
  validation loss:		2.220719
  validation accuracy:		26.85 %
Epoch 61 of 2000 took 0.101s
  training loss:		2.271643
  validation loss:		2.217425
  validation accuracy:		25.54 %
Epoch 62 of 2000 took 0.102s
  training loss:		2.270861
  validation loss:		2.214942
  validation accuracy:		23.59 %
Epoch 63 of 2000 took 0.101s
  training loss:		2.269774
  validation loss:		2.215473
  validation accuracy:		21.09 %
Epoch 64 of 2000 took 0.101s
  training loss:		2.268067
  validation loss:		2.214824
  validation accuracy:		26.09 %
Epoch 65 of 2000 took 0.101s
  training loss:		2.266566
  validation loss:		2.210792
  validation accuracy:		26.52 %
Epoch 66 of 2000 took 0.101s
  training loss:		2.264741
  validation loss:		2.211755
  validation accuracy:		25.11 %
Epoch 67 of 2000 took 0.101s
  training loss:		2.262173
  validation loss:		2.209666
  validation accuracy:		25.22 %
Epoch 68 of 2000 took 0.104s
  training loss:		2.258920
  validation loss:		2.201681
  validation accuracy:		24.67 %
Epoch 69 of 2000 took 0.102s
  training loss:		2.258730
  validation loss:		2.199384
  validation accuracy:		27.39 %
Epoch 70 of 2000 took 0.101s
  training loss:		2.254287
  validation loss:		2.200403
  validation accuracy:		27.07 %
Epoch 71 of 2000 took 0.103s
  training loss:		2.250607
  validation loss:		2.194726
  validation accuracy:		24.24 %
Epoch 72 of 2000 took 0.101s
  training loss:		2.248076
  validation loss:		2.191070
  validation accuracy:		23.80 %
Epoch 73 of 2000 took 0.152s
  training loss:		2.243843
  validation loss:		2.187012
  validation accuracy:		24.89 %
Epoch 74 of 2000 took 0.166s
  training loss:		2.240769
  validation loss:		2.183272
  validation accuracy:		25.54 %
Epoch 75 of 2000 took 0.165s
  training loss:		2.235362
  validation loss:		2.170770
  validation accuracy:		24.24 %
Epoch 76 of 2000 took 0.163s
  training loss:		2.230897
  validation loss:		2.170632
  validation accuracy:		25.33 %
Epoch 77 of 2000 took 0.173s
  training loss:		2.225294
  validation loss:		2.169489
  validation accuracy:		25.98 %
Epoch 78 of 2000 took 0.166s
  training loss:		2.218173
  validation loss:		2.157097
  validation accuracy:		24.13 %
Epoch 79 of 2000 took 0.165s
  training loss:		2.210686
  validation loss:		2.147867
  validation accuracy:		25.33 %
Epoch 80 of 2000 took 0.165s
  training loss:		2.204664
  validation loss:		2.141527
  validation accuracy:		25.11 %
Epoch 81 of 2000 took 0.308s
  training loss:		2.193743
  validation loss:		2.128776
  validation accuracy:		27.72 %
Epoch 82 of 2000 took 0.210s
  training loss:		2.182897
  validation loss:		2.116076
  validation accuracy:		27.28 %
Epoch 83 of 2000 took 0.200s
  training loss:		2.172094
  validation loss:		2.103069
  validation accuracy:		27.72 %
Epoch 84 of 2000 took 0.182s
  training loss:		2.158498
  validation loss:		2.084057
  validation accuracy:		26.09 %
Epoch 85 of 2000 took 0.165s
  training loss:		2.144409
  validation loss:		2.074030
  validation accuracy:		27.07 %
Epoch 86 of 2000 took 0.165s
  training loss:		2.127122
  validation loss:		2.056036
  validation accuracy:		26.74 %
Epoch 87 of 2000 took 0.165s
  training loss:		2.109560
  validation loss:		2.030751
  validation accuracy:		26.63 %
Epoch 88 of 2000 took 0.176s
  training loss:		2.086368
  validation loss:		2.008041
  validation accuracy:		28.26 %
Epoch 89 of 2000 took 0.164s
  training loss:		2.064163
  validation loss:		1.981812
  validation accuracy:		29.02 %
Epoch 90 of 2000 took 0.167s
  training loss:		2.044072
  validation loss:		1.953082
  validation accuracy:		28.91 %
Epoch 91 of 2000 took 0.171s
  training loss:		2.019402
  validation loss:		1.931026
  validation accuracy:		30.65 %
Epoch 92 of 2000 took 0.164s
  training loss:		1.992152
  validation loss:		1.901389
  validation accuracy:		29.24 %
Epoch 93 of 2000 took 0.166s
  training loss:		1.969255
  validation loss:		1.872785
  validation accuracy:		29.78 %
Epoch 94 of 2000 took 0.164s
  training loss:		1.944213
  validation loss:		1.847085
  validation accuracy:		32.61 %
Epoch 95 of 2000 took 0.185s
  training loss:		1.917078
  validation loss:		1.818615
  validation accuracy:		32.17 %
Epoch 96 of 2000 took 0.167s
  training loss:		1.894661
  validation loss:		1.789867
  validation accuracy:		32.72 %
Epoch 97 of 2000 took 0.165s
  training loss:		1.866948
  validation loss:		1.771317
  validation accuracy:		34.78 %
Epoch 98 of 2000 took 0.170s
  training loss:		1.851933
  validation loss:		1.745818
  validation accuracy:		35.22 %
Epoch 99 of 2000 took 0.164s
  training loss:		1.830142
  validation loss:		1.729489
  validation accuracy:		35.87 %
Epoch 100 of 2000 took 0.165s
  training loss:		1.807092
  validation loss:		1.705865
  validation accuracy:		35.54 %
Epoch 101 of 2000 took 0.162s
  training loss:		1.795690
  validation loss:		1.689314
  validation accuracy:		36.85 %
Epoch 102 of 2000 took 0.164s
  training loss:		1.774883
  validation loss:		1.668386
  validation accuracy:		37.50 %
Epoch 103 of 2000 took 0.171s
  training loss:		1.758491
  validation loss:		1.649850
  validation accuracy:		37.39 %
Epoch 104 of 2000 took 0.167s
  training loss:		1.741499
  validation loss:		1.630640
  validation accuracy:		37.17 %
Epoch 105 of 2000 took 0.166s
  training loss:		1.726132
  validation loss:		1.615982
  validation accuracy:		38.04 %
Epoch 106 of 2000 took 0.166s
  training loss:		1.704205
  validation loss:		1.599394
  validation accuracy:		39.46 %
Epoch 107 of 2000 took 0.166s
  training loss:		1.697308
  validation loss:		1.584353
  validation accuracy:		40.33 %
Epoch 108 of 2000 took 0.166s
  training loss:		1.687639
  validation loss:		1.567557
  validation accuracy:		39.78 %
Epoch 109 of 2000 took 0.166s
  training loss:		1.670637
  validation loss:		1.554425
  validation accuracy:		40.76 %
Epoch 110 of 2000 took 0.166s
  training loss:		1.652120
  validation loss:		1.551479
  validation accuracy:		40.54 %
Epoch 111 of 2000 took 0.166s
  training loss:		1.641434
  validation loss:		1.529002
  validation accuracy:		40.22 %
Epoch 112 of 2000 took 0.166s
  training loss:		1.622620
  validation loss:		1.518207
  validation accuracy:		42.93 %
Epoch 113 of 2000 took 0.166s
  training loss:		1.618121
  validation loss:		1.508142
  validation accuracy:		40.65 %
Epoch 114 of 2000 took 0.182s
  training loss:		1.603450
  validation loss:		1.491764
  validation accuracy:		41.74 %
Epoch 115 of 2000 took 0.166s
  training loss:		1.593494
  validation loss:		1.502160
  validation accuracy:		42.39 %
Epoch 116 of 2000 took 0.165s
  training loss:		1.583346
  validation loss:		1.484312
  validation accuracy:		43.26 %
Epoch 117 of 2000 took 0.165s
  training loss:		1.572020
  validation loss:		1.458508
  validation accuracy:		43.91 %
Epoch 118 of 2000 took 0.165s
  training loss:		1.561137
  validation loss:		1.449444
  validation accuracy:		44.13 %
Epoch 119 of 2000 took 0.165s
  training loss:		1.553510
  validation loss:		1.452662
  validation accuracy:		44.78 %
Epoch 120 of 2000 took 0.166s
  training loss:		1.546133
  validation loss:		1.438967
  validation accuracy:		45.43 %
Epoch 121 of 2000 took 0.166s
  training loss:		1.539303
  validation loss:		1.433191
  validation accuracy:		45.43 %
Epoch 122 of 2000 took 0.166s
  training loss:		1.534424
  validation loss:		1.419031
  validation accuracy:		46.63 %
Epoch 123 of 2000 took 0.165s
  training loss:		1.521451
  validation loss:		1.440857
  validation accuracy:		45.76 %
Epoch 124 of 2000 took 0.166s
  training loss:		1.511230
  validation loss:		1.406570
  validation accuracy:		47.17 %
Epoch 125 of 2000 took 0.166s
  training loss:		1.503492
  validation loss:		1.398146
  validation accuracy:		47.72 %
Epoch 126 of 2000 took 0.166s
  training loss:		1.500708
  validation loss:		1.392641
  validation accuracy:		48.80 %
Epoch 127 of 2000 took 0.172s
  training loss:		1.500950
  validation loss:		1.399978
  validation accuracy:		47.50 %
Epoch 128 of 2000 took 0.166s
  training loss:		1.485924
  validation loss:		1.398558
  validation accuracy:		48.26 %
Epoch 129 of 2000 took 0.165s
  training loss:		1.484163
  validation loss:		1.372319
  validation accuracy:		49.02 %
Epoch 130 of 2000 took 0.161s
  training loss:		1.477553
  validation loss:		1.368585
  validation accuracy:		48.37 %
Epoch 131 of 2000 took 0.167s
  training loss:		1.476300
  validation loss:		1.374027
  validation accuracy:		49.35 %
Epoch 132 of 2000 took 0.171s
  training loss:		1.471866
  validation loss:		1.384106
  validation accuracy:		48.70 %
Epoch 133 of 2000 took 0.164s
  training loss:		1.460828
  validation loss:		1.359047
  validation accuracy:		50.00 %
Epoch 134 of 2000 took 0.167s
  training loss:		1.455155
  validation loss:		1.352975
  validation accuracy:		50.00 %
Epoch 135 of 2000 took 0.170s
  training loss:		1.460181
  validation loss:		1.350382
  validation accuracy:		49.24 %
Epoch 136 of 2000 took 0.167s
  training loss:		1.455926
  validation loss:		1.353022
  validation accuracy:		48.15 %
Epoch 137 of 2000 took 0.168s
  training loss:		1.447306
  validation loss:		1.338283
  validation accuracy:		51.85 %
Epoch 138 of 2000 took 0.165s
  training loss:		1.461380
  validation loss:		1.344721
  validation accuracy:		50.11 %
Epoch 139 of 2000 took 0.171s
  training loss:		1.450464
  validation loss:		1.339928
  validation accuracy:		49.57 %
Epoch 140 of 2000 took 0.166s
  training loss:		1.435319
  validation loss:		1.338484
  validation accuracy:		50.43 %
Epoch 141 of 2000 took 0.166s
  training loss:		1.429304
  validation loss:		1.350756
  validation accuracy:		51.63 %
Epoch 142 of 2000 took 0.171s
  training loss:		1.428156
  validation loss:		1.341834
  validation accuracy:		51.09 %
Epoch 143 of 2000 took 0.178s
  training loss:		1.434407
  validation loss:		1.346221
  validation accuracy:		50.33 %
Epoch 144 of 2000 took 0.166s
  training loss:		1.435014
  validation loss:		1.326438
  validation accuracy:		49.24 %
Epoch 145 of 2000 took 0.164s
  training loss:		1.449342
  validation loss:		1.359919
  validation accuracy:		48.91 %
Epoch 146 of 2000 took 0.169s
  training loss:		1.428961
  validation loss:		1.331049
  validation accuracy:		50.65 %
Epoch 147 of 2000 took 0.166s
  training loss:		1.420242
  validation loss:		1.320683
  validation accuracy:		49.57 %
Epoch 148 of 2000 took 0.164s
  training loss:		1.417391
  validation loss:		1.336204
  validation accuracy:		50.76 %
Epoch 149 of 2000 took 0.170s
  training loss:		1.427123
  validation loss:		1.311536
  validation accuracy:		50.98 %
Epoch 150 of 2000 took 0.169s
  training loss:		1.416571
  validation loss:		1.313049
  validation accuracy:		49.78 %
Epoch 151 of 2000 took 0.166s
  training loss:		1.411938
  validation loss:		1.311914
  validation accuracy:		50.65 %
Epoch 152 of 2000 took 0.164s
  training loss:		1.424507
  validation loss:		1.321997
  validation accuracy:		51.20 %
Epoch 153 of 2000 took 0.166s
  training loss:		1.417338
  validation loss:		1.307087
  validation accuracy:		52.07 %
Epoch 154 of 2000 took 0.168s
  training loss:		1.409976
  validation loss:		1.358502
  validation accuracy:		49.57 %
Epoch 155 of 2000 took 0.164s
  training loss:		1.422244
  validation loss:		1.350812
  validation accuracy:		48.91 %
Epoch 156 of 2000 took 0.167s
  training loss:		1.400121
  validation loss:		1.306521
  validation accuracy:		51.30 %
Epoch 157 of 2000 took 0.167s
  training loss:		1.400881
  validation loss:		1.299131
  validation accuracy:		52.39 %
Epoch 158 of 2000 took 0.165s
  training loss:		1.441821
  validation loss:		1.345933
  validation accuracy:		47.61 %
Epoch 159 of 2000 took 0.165s
  training loss:		1.424745
  validation loss:		1.314938
  validation accuracy:		50.33 %
Epoch 160 of 2000 took 0.170s
  training loss:		1.418506
  validation loss:		1.292312
  validation accuracy:		51.20 %
Epoch 161 of 2000 took 0.169s
  training loss:		1.407793
  validation loss:		1.284017
  validation accuracy:		53.04 %
Epoch 162 of 2000 took 0.165s
  training loss:		1.402915
  validation loss:		1.312315
  validation accuracy:		50.22 %
Epoch 163 of 2000 took 0.165s
  training loss:		1.398453
  validation loss:		1.293316
  validation accuracy:		51.85 %
Epoch 164 of 2000 took 0.170s
  training loss:		1.403175
  validation loss:		1.300169
  validation accuracy:		54.02 %
Epoch 165 of 2000 took 0.164s
  training loss:		1.396108
  validation loss:		1.324869
  validation accuracy:		51.63 %
Epoch 166 of 2000 took 0.163s
  training loss:		1.466187
  validation loss:		1.301463
  validation accuracy:		52.17 %
Epoch 167 of 2000 took 0.164s
  training loss:		1.398392
  validation loss:		1.286282
  validation accuracy:		53.80 %
Epoch 168 of 2000 took 0.169s
  training loss:		1.376378
  validation loss:		1.283424
  validation accuracy:		53.59 %
Epoch 169 of 2000 took 0.166s
  training loss:		1.409557
  validation loss:		1.285707
  validation accuracy:		54.89 %
Epoch 170 of 2000 took 0.164s
  training loss:		1.377701
  validation loss:		1.290593
  validation accuracy:		54.13 %
Epoch 171 of 2000 took 0.170s
  training loss:		1.384340
  validation loss:		1.274682
  validation accuracy:		55.11 %
Epoch 172 of 2000 took 0.169s
  training loss:		1.401987
  validation loss:		1.281449
  validation accuracy:		53.80 %
Epoch 173 of 2000 took 0.165s
  training loss:		1.377094
  validation loss:		1.297127
  validation accuracy:		52.83 %
Epoch 174 of 2000 took 0.165s
  training loss:		1.398762
  validation loss:		1.416645
  validation accuracy:		45.87 %
Epoch 175 of 2000 took 0.166s
  training loss:		1.420122
  validation loss:		1.315823
  validation accuracy:		53.15 %
Epoch 176 of 2000 took 0.168s
  training loss:		1.407756
  validation loss:		1.308694
  validation accuracy:		52.39 %
Epoch 177 of 2000 took 0.164s
  training loss:		1.386164
  validation loss:		1.280302
  validation accuracy:		55.11 %
Epoch 178 of 2000 took 0.166s
  training loss:		1.371622
  validation loss:		1.300519
  validation accuracy:		53.04 %
Epoch 179 of 2000 took 0.168s
  training loss:		1.386231
  validation loss:		1.337422
  validation accuracy:		50.43 %
Epoch 180 of 2000 took 0.164s
  training loss:		1.392069
  validation loss:		1.262075
  validation accuracy:		55.22 %
Epoch 181 of 2000 took 0.163s
  training loss:		1.377990
  validation loss:		1.337274
  validation accuracy:		51.30 %
Epoch 182 of 2000 took 0.164s
  training loss:		1.386228
  validation loss:		1.263607
  validation accuracy:		55.98 %
Epoch 183 of 2000 took 0.169s
  training loss:		1.381204
  validation loss:		1.269627
  validation accuracy:		55.76 %
Epoch 184 of 2000 took 0.166s
  training loss:		1.390927
  validation loss:		1.268280
  validation accuracy:		55.54 %
Epoch 185 of 2000 took 0.165s
  training loss:		1.389441
  validation loss:		1.318426
  validation accuracy:		48.59 %
Epoch 186 of 2000 took 0.170s
  training loss:		1.421628
  validation loss:		1.272731
  validation accuracy:		55.22 %
Epoch 187 of 2000 took 0.164s
  training loss:		1.374625
  validation loss:		1.269272
  validation accuracy:		56.30 %
Epoch 188 of 2000 took 0.165s
  training loss:		1.367744
  validation loss:		1.258583
  validation accuracy:		55.65 %
Epoch 189 of 2000 took 0.164s
  training loss:		1.367881
  validation loss:		1.262146
  validation accuracy:		55.54 %
Epoch 190 of 2000 took 0.168s
  training loss:		1.419358
  validation loss:		1.272646
  validation accuracy:		55.11 %
Epoch 191 of 2000 took 0.167s
  training loss:		1.391930
  validation loss:		1.265709
  validation accuracy:		56.30 %
Epoch 192 of 2000 took 0.166s
  training loss:		1.361412
  validation loss:		1.257992
  validation accuracy:		56.41 %
Epoch 193 of 2000 took 0.169s
  training loss:		1.421176
  validation loss:		1.301701
  validation accuracy:		53.91 %
Epoch 194 of 2000 took 0.166s
  training loss:		1.364996
  validation loss:		1.260390
  validation accuracy:		56.30 %
Epoch 195 of 2000 took 0.165s
  training loss:		1.445136
  validation loss:		1.484908
  validation accuracy:		43.04 %
Epoch 196 of 2000 took 0.165s
  training loss:		1.405885
  validation loss:		1.254657
  validation accuracy:		55.98 %
Epoch 197 of 2000 took 0.166s
  training loss:		1.368958
  validation loss:		1.256713
  validation accuracy:		56.85 %
Epoch 198 of 2000 took 0.169s
  training loss:		1.379505
  validation loss:		1.267615
  validation accuracy:		54.89 %
Epoch 199 of 2000 took 0.164s
  training loss:		1.395604
  validation loss:		1.247663
  validation accuracy:		56.52 %
Epoch 200 of 2000 took 0.165s
  training loss:		1.375140
  validation loss:		1.269708
  validation accuracy:		54.57 %
Epoch 201 of 2000 took 0.169s
  training loss:		1.359749
  validation loss:		1.250632
  validation accuracy:		55.65 %
Epoch 202 of 2000 took 0.164s
  training loss:		1.362374
  validation loss:		1.250020
  validation accuracy:		56.09 %
Epoch 203 of 2000 took 0.165s
  training loss:		1.360423
  validation loss:		1.264260
  validation accuracy:		56.74 %
Epoch 204 of 2000 took 0.164s
  training loss:		1.371285
  validation loss:		1.300198
  validation accuracy:		54.13 %
Epoch 205 of 2000 took 0.169s
  training loss:		1.366535
  validation loss:		1.255195
  validation accuracy:		56.96 %
Epoch 206 of 2000 took 0.166s
  training loss:		1.368081
  validation loss:		1.333077
  validation accuracy:		47.50 %
Epoch 207 of 2000 took 0.165s
  training loss:		1.379196
  validation loss:		1.255325
  validation accuracy:		56.85 %
Epoch 208 of 2000 took 0.170s
  training loss:		1.393040
  validation loss:		1.273781
  validation accuracy:		53.59 %
Epoch 209 of 2000 took 0.164s
  training loss:		1.370459
  validation loss:		1.252559
  validation accuracy:		55.65 %
Epoch 210 of 2000 took 0.165s
  training loss:		1.394181
  validation loss:		1.365039
  validation accuracy:		50.65 %
Epoch 211 of 2000 took 0.164s
  training loss:		1.385470
  validation loss:		1.244965
  validation accuracy:		57.28 %
Epoch 212 of 2000 took 0.167s
  training loss:		1.366234
  validation loss:		1.249507
  validation accuracy:		57.17 %
Epoch 213 of 2000 took 0.168s
  training loss:		1.358858
  validation loss:		1.242315
  validation accuracy:		56.74 %
Epoch 214 of 2000 took 0.164s
  training loss:		1.349735
  validation loss:		1.241335
  validation accuracy:		57.28 %
Epoch 215 of 2000 took 0.168s
  training loss:		1.351608
  validation loss:		1.249219
  validation accuracy:		56.96 %
Epoch 216 of 2000 took 0.167s
  training loss:		1.381899
  validation loss:		1.289084
  validation accuracy:		55.22 %
Epoch 217 of 2000 took 0.165s
  training loss:		1.358523
  validation loss:		1.242425
  validation accuracy:		57.17 %
Epoch 218 of 2000 took 0.165s
  training loss:		1.355067
  validation loss:		1.249567
  validation accuracy:		57.17 %
Epoch 219 of 2000 took 0.165s
  training loss:		1.346413
  validation loss:		1.244144
  validation accuracy:		56.63 %
Epoch 220 of 2000 took 0.169s
  training loss:		1.376256
  validation loss:		1.250486
  validation accuracy:		57.17 %
Epoch 221 of 2000 took 0.165s
  training loss:		1.378457
  validation loss:		1.274400
  validation accuracy:		53.48 %
Epoch 222 of 2000 took 0.165s
  training loss:		1.393058
  validation loss:		1.253638
  validation accuracy:		57.17 %
Epoch 223 of 2000 took 0.170s
  training loss:		1.367065
  validation loss:		1.265602
  validation accuracy:		56.63 %
Epoch 224 of 2000 took 0.169s
  training loss:		1.357145
  validation loss:		1.240617
  validation accuracy:		57.83 %
Epoch 225 of 2000 took 0.166s
  training loss:		1.382238
  validation loss:		1.295258
  validation accuracy:		50.87 %
Epoch 226 of 2000 took 0.164s
  training loss:		1.407702
  validation loss:		1.255137
  validation accuracy:		57.50 %
Epoch 227 of 2000 took 0.169s
  training loss:		1.350067
  validation loss:		1.251418
  validation accuracy:		57.28 %
Epoch 228 of 2000 took 0.163s
  training loss:		1.370625
  validation loss:		1.277243
  validation accuracy:		55.43 %
Epoch 229 of 2000 took 0.164s
  training loss:		1.348783
  validation loss:		1.265047
  validation accuracy:		53.80 %
Epoch 230 of 2000 took 0.170s
  training loss:		1.401986
  validation loss:		1.320431
  validation accuracy:		54.24 %
Epoch 231 of 2000 took 0.165s
  training loss:		1.420358
  validation loss:		1.265918
  validation accuracy:		55.22 %
Epoch 232 of 2000 took 0.165s
  training loss:		1.359883
  validation loss:		1.270148
  validation accuracy:		55.76 %
Epoch 233 of 2000 took 0.164s
  training loss:		1.366181
  validation loss:		1.247980
  validation accuracy:		57.61 %
Epoch 234 of 2000 took 0.150s
  training loss:		1.365839
  validation loss:		1.259988
  validation accuracy:		54.02 %
Epoch 235 of 2000 took 0.101s
  training loss:		1.361118
  validation loss:		1.275970
  validation accuracy:		51.85 %
Epoch 236 of 2000 took 0.096s
  training loss:		1.374634
  validation loss:		1.251311
  validation accuracy:		55.43 %
Epoch 237 of 2000 took 0.100s
  training loss:		1.372352
  validation loss:		1.242373
  validation accuracy:		56.63 %
Epoch 238 of 2000 took 0.104s
  training loss:		1.361602
  validation loss:		1.249044
  validation accuracy:		57.17 %
Epoch 239 of 2000 took 0.097s
  training loss:		1.358443
  validation loss:		1.253982
  validation accuracy:		54.35 %
Epoch 240 of 2000 took 0.097s
  training loss:		1.378913
  validation loss:		1.389530
  validation accuracy:		49.57 %
Epoch 241 of 2000 took 0.096s
  training loss:		1.361486
  validation loss:		1.298837
  validation accuracy:		54.89 %
Epoch 242 of 2000 took 0.100s
  training loss:		1.364015
  validation loss:		1.251542
  validation accuracy:		57.17 %
Epoch 243 of 2000 took 0.098s
  training loss:		1.363479
  validation loss:		1.282822
  validation accuracy:		56.30 %
Epoch 244 of 2000 took 0.096s
  training loss:		1.353601
  validation loss:		1.231658
  validation accuracy:		56.74 %
Epoch 245 of 2000 took 0.099s
  training loss:		1.351588
  validation loss:		1.287194
  validation accuracy:		55.22 %
Epoch 246 of 2000 took 0.099s
  training loss:		1.361069
  validation loss:		1.258996
  validation accuracy:		53.80 %
Epoch 247 of 2000 took 0.097s
  training loss:		1.348509
  validation loss:		1.236057
  validation accuracy:		57.93 %
Epoch 248 of 2000 took 0.097s
  training loss:		1.357524
  validation loss:		1.235644
  validation accuracy:		57.72 %
Epoch 249 of 2000 took 0.097s
  training loss:		1.357827
  validation loss:		1.345520
  validation accuracy:		52.17 %
Epoch 250 of 2000 took 0.102s
  training loss:		1.379711
  validation loss:		1.241394
  validation accuracy:		57.72 %
Epoch 251 of 2000 took 0.097s
  training loss:		1.349411
  validation loss:		1.270085
  validation accuracy:		53.70 %
Epoch 252 of 2000 took 0.097s
  training loss:		1.352217
  validation loss:		1.227759
  validation accuracy:		57.83 %
Epoch 253 of 2000 took 0.103s
  training loss:		1.346583
  validation loss:		1.237966
  validation accuracy:		57.61 %
Epoch 254 of 2000 took 0.097s
  training loss:		1.344795
  validation loss:		1.243956
  validation accuracy:		56.63 %
Epoch 255 of 2000 took 0.097s
  training loss:		1.350452
  validation loss:		1.240954
  validation accuracy:		57.39 %
Epoch 256 of 2000 took 0.096s
  training loss:		1.365977
  validation loss:		1.387793
  validation accuracy:		49.24 %
Epoch 257 of 2000 took 0.097s
  training loss:		1.386912
  validation loss:		1.259782
  validation accuracy:		56.96 %
Epoch 258 of 2000 took 0.101s
  training loss:		1.381726
  validation loss:		1.348111
  validation accuracy:		53.91 %
Epoch 259 of 2000 took 0.096s
  training loss:		1.368775
  validation loss:		1.229579
  validation accuracy:		58.15 %
Epoch 260 of 2000 took 0.097s
  training loss:		1.339015
  validation loss:		1.238436
  validation accuracy:		57.39 %
Epoch 261 of 2000 took 0.102s
  training loss:		1.354179
  validation loss:		1.307896
  validation accuracy:		49.46 %
Epoch 262 of 2000 took 0.096s
  training loss:		1.363814
  validation loss:		1.241067
  validation accuracy:		57.72 %
Epoch 263 of 2000 took 0.097s
  training loss:		1.357451
  validation loss:		1.235854
  validation accuracy:		57.39 %
Epoch 264 of 2000 took 0.096s
  training loss:		1.361801
  validation loss:		1.236629
  validation accuracy:		58.04 %
Epoch 265 of 2000 took 0.099s
  training loss:		1.351563
  validation loss:		1.280930
  validation accuracy:		55.54 %
Epoch 266 of 2000 took 0.099s
  training loss:		1.348836
  validation loss:		1.228663
  validation accuracy:		57.39 %
Epoch 267 of 2000 took 0.096s
  training loss:		1.347268
  validation loss:		1.242258
  validation accuracy:		55.22 %
Epoch 268 of 2000 took 0.099s
  training loss:		1.344792
  validation loss:		1.230525
  validation accuracy:		58.04 %
Epoch 269 of 2000 took 0.100s
  training loss:		1.351015
  validation loss:		1.280637
  validation accuracy:		55.54 %
Epoch 270 of 2000 took 0.097s
  training loss:		1.360481
  validation loss:		1.255022
  validation accuracy:		56.74 %
Epoch 271 of 2000 took 0.097s
  training loss:		1.349632
  validation loss:		1.237201
  validation accuracy:		57.39 %
Epoch 272 of 2000 took 0.096s
  training loss:		1.351901
  validation loss:		1.249410
  validation accuracy:		55.54 %
Epoch 273 of 2000 took 0.101s
  training loss:		1.347407
  validation loss:		1.256729
  validation accuracy:		57.28 %
Epoch 274 of 2000 took 0.097s
  training loss:		1.351554
  validation loss:		1.244072
  validation accuracy:		57.72 %
Epoch 275 of 2000 took 0.096s
  training loss:		1.353075
  validation loss:		1.234635
  validation accuracy:		57.72 %
Epoch 276 of 2000 took 0.102s
  training loss:		1.363122
  validation loss:		1.288177
  validation accuracy:		55.76 %
Epoch 277 of 2000 took 0.096s
  training loss:		1.349342
  validation loss:		1.260748
  validation accuracy:		58.04 %
Epoch 278 of 2000 took 0.097s
  training loss:		1.370573
  validation loss:		1.279951
  validation accuracy:		55.65 %
Epoch 279 of 2000 took 0.096s
  training loss:		1.355619
  validation loss:		1.247659
  validation accuracy:		57.50 %
Epoch 280 of 2000 took 0.098s
  training loss:		1.353156
  validation loss:		1.243421
  validation accuracy:		57.28 %
Epoch 281 of 2000 took 0.101s
  training loss:		1.350453
  validation loss:		1.220772
  validation accuracy:		56.85 %
Epoch 282 of 2000 took 0.096s
  training loss:		1.340562
  validation loss:		1.228867
  validation accuracy:		58.37 %
Epoch 283 of 2000 took 0.097s
  training loss:		1.336722
  validation loss:		1.235631
  validation accuracy:		58.80 %
Epoch 284 of 2000 took 0.102s
  training loss:		1.345927
  validation loss:		1.223006
  validation accuracy:		57.93 %
Epoch 285 of 2000 took 0.096s
  training loss:		1.340157
  validation loss:		1.340471
  validation accuracy:		53.48 %
Epoch 286 of 2000 took 0.097s
  training loss:		1.377535
  validation loss:		1.229897
  validation accuracy:		58.26 %
Epoch 287 of 2000 took 0.096s
  training loss:		1.339013
  validation loss:		1.236137
  validation accuracy:		58.15 %
Epoch 288 of 2000 took 0.099s
  training loss:		1.342538
  validation loss:		1.226724
  validation accuracy:		57.07 %
Epoch 289 of 2000 took 0.099s
  training loss:		1.328983
  validation loss:		1.237055
  validation accuracy:		57.50 %
Epoch 290 of 2000 took 0.096s
  training loss:		1.340806
  validation loss:		1.254196
  validation accuracy:		57.39 %
Epoch 291 of 2000 took 0.099s
  training loss:		1.364328
  validation loss:		1.317450
  validation accuracy:		54.13 %
Epoch 292 of 2000 took 0.099s
  training loss:		1.354769
  validation loss:		1.244340
  validation accuracy:		54.57 %
Epoch 293 of 2000 took 0.097s
  training loss:		1.406427
  validation loss:		1.223508
  validation accuracy:		58.48 %
Epoch 294 of 2000 took 0.097s
  training loss:		1.345989
  validation loss:		1.231136
  validation accuracy:		58.04 %
Epoch 295 of 2000 took 0.096s
  training loss:		1.337597
  validation loss:		1.229976
  validation accuracy:		58.04 %
Epoch 296 of 2000 took 0.101s
  training loss:		1.351441
  validation loss:		1.230361
  validation accuracy:		56.74 %
Epoch 297 of 2000 took 0.097s
  training loss:		1.348032
  validation loss:		1.231005
  validation accuracy:		58.37 %
Epoch 298 of 2000 took 0.096s
  training loss:		1.344561
  validation loss:		1.231839
  validation accuracy:		56.96 %
Epoch 299 of 2000 took 0.102s
  training loss:		1.341861
  validation loss:		1.225282
  validation accuracy:		58.48 %
Epoch 300 of 2000 took 0.097s
  training loss:		1.345576
  validation loss:		1.228825
  validation accuracy:		57.61 %
Epoch 301 of 2000 took 0.097s
  training loss:		1.339844
  validation loss:		1.230565
  validation accuracy:		58.37 %
Epoch 302 of 2000 took 0.099s
  training loss:		1.337857
  validation loss:		1.220880
  validation accuracy:		58.70 %
Epoch 303 of 2000 took 0.098s
  training loss:		1.380521
  validation loss:		1.267333
  validation accuracy:		58.04 %
Epoch 304 of 2000 took 0.101s
  training loss:		1.366180
  validation loss:		1.248562
  validation accuracy:		58.26 %
Epoch 305 of 2000 took 0.096s
  training loss:		1.373942
  validation loss:		1.222820
  validation accuracy:		59.13 %
Epoch 306 of 2000 took 0.097s
  training loss:		1.334637
  validation loss:		1.253297
  validation accuracy:		53.04 %
Epoch 307 of 2000 took 0.103s
  training loss:		1.346196
  validation loss:		1.226546
  validation accuracy:		58.91 %
Epoch 308 of 2000 took 0.096s
  training loss:		1.334741
  validation loss:		1.225947
  validation accuracy:		58.59 %
Epoch 309 of 2000 took 0.097s
  training loss:		1.329441
  validation loss:		1.223908
  validation accuracy:		58.04 %
Epoch 310 of 2000 took 0.096s
  training loss:		1.333155
  validation loss:		1.225411
  validation accuracy:		59.24 %
Epoch 311 of 2000 took 0.099s
  training loss:		1.332937
  validation loss:		1.218034
  validation accuracy:		58.91 %
Epoch 312 of 2000 took 0.099s
  training loss:		1.328121
  validation loss:		1.240486
  validation accuracy:		58.59 %
Epoch 313 of 2000 took 0.096s
  training loss:		1.333452
  validation loss:		1.227536
  validation accuracy:		59.13 %
Epoch 314 of 2000 took 0.099s
  training loss:		1.353283
  validation loss:		1.218814
  validation accuracy:		59.35 %
Epoch 315 of 2000 took 0.097s
  training loss:		1.332825
  validation loss:		1.221547
  validation accuracy:		58.26 %
Epoch 316 of 2000 took 0.097s
  training loss:		1.335809
  validation loss:		1.226677
  validation accuracy:		58.59 %
Epoch 317 of 2000 took 0.099s
  training loss:		1.330192
  validation loss:		1.245290
  validation accuracy:		58.04 %
Epoch 318 of 2000 took 0.096s
  training loss:		1.339233
  validation loss:		1.208866
  validation accuracy:		59.57 %
Epoch 319 of 2000 took 0.100s
  training loss:		1.328010
  validation loss:		1.215950
  validation accuracy:		58.48 %
Epoch 320 of 2000 took 0.096s
  training loss:		1.352759
  validation loss:		1.242342
  validation accuracy:		59.35 %
Epoch 321 of 2000 took 0.097s
  training loss:		1.340915
  validation loss:		1.207763
  validation accuracy:		60.11 %
Epoch 322 of 2000 took 0.099s
  training loss:		1.328361
  validation loss:		1.218576
  validation accuracy:		57.93 %
Epoch 323 of 2000 took 0.097s
  training loss:		1.325863
  validation loss:		1.220721
  validation accuracy:		59.46 %
Epoch 324 of 2000 took 0.100s
  training loss:		1.331682
  validation loss:		1.205376
  validation accuracy:		59.78 %
Epoch 325 of 2000 took 0.096s
  training loss:		1.320238
  validation loss:		1.231345
  validation accuracy:		60.22 %
Epoch 326 of 2000 took 0.099s
  training loss:		1.311819
  validation loss:		1.208662
  validation accuracy:		59.89 %
Epoch 327 of 2000 took 0.097s
  training loss:		1.335785
  validation loss:		1.218679
  validation accuracy:		60.54 %
Epoch 328 of 2000 took 0.097s
  training loss:		1.324978
  validation loss:		1.221145
  validation accuracy:		60.43 %
Epoch 329 of 2000 took 0.099s
  training loss:		1.334805
  validation loss:		1.237941
  validation accuracy:		59.46 %
Epoch 330 of 2000 took 0.096s
  training loss:		1.323198
  validation loss:		1.206291
  validation accuracy:		59.67 %
Epoch 331 of 2000 took 0.100s
  training loss:		1.321907
  validation loss:		1.226702
  validation accuracy:		61.20 %
Epoch 332 of 2000 took 0.096s
  training loss:		1.323007
  validation loss:		1.215828
  validation accuracy:		61.63 %
Epoch 333 of 2000 took 0.098s
  training loss:		1.323527
  validation loss:		1.194869
  validation accuracy:		59.89 %
Epoch 334 of 2000 took 0.098s
  training loss:		1.329131
  validation loss:		1.218721
  validation accuracy:		61.74 %
Epoch 335 of 2000 took 0.097s
  training loss:		1.301953
  validation loss:		1.200615
  validation accuracy:		60.87 %
Epoch 336 of 2000 took 0.100s
  training loss:		1.305990
  validation loss:		1.218533
  validation accuracy:		61.96 %
Epoch 337 of 2000 took 0.096s
  training loss:		1.319239
  validation loss:		1.187609
  validation accuracy:		60.43 %
Epoch 338 of 2000 took 0.100s
  training loss:		1.316128
  validation loss:		1.204614
  validation accuracy:		62.50 %
Epoch 339 of 2000 took 0.096s
  training loss:		1.305961
  validation loss:		1.262037
  validation accuracy:		61.52 %
Epoch 340 of 2000 took 0.097s
  training loss:		1.338331
  validation loss:		1.188497
  validation accuracy:		63.70 %
Epoch 341 of 2000 took 0.102s
  training loss:		1.314944
  validation loss:		1.230792
  validation accuracy:		62.61 %
Epoch 342 of 2000 took 0.096s
  training loss:		1.300762
  validation loss:		1.218339
  validation accuracy:		63.91 %
Epoch 343 of 2000 took 0.097s
  training loss:		1.305402
  validation loss:		1.192190
  validation accuracy:		63.91 %
Epoch 344 of 2000 took 0.096s
  training loss:		1.288810
  validation loss:		1.202093
  validation accuracy:		65.00 %
Epoch 345 of 2000 took 0.100s
  training loss:		1.291424
  validation loss:		1.175600
  validation accuracy:		64.35 %
Epoch 346 of 2000 took 0.098s
  training loss:		1.296651
  validation loss:		1.167156
  validation accuracy:		64.46 %
Epoch 347 of 2000 took 0.096s
  training loss:		1.281075
  validation loss:		1.183581
  validation accuracy:		60.11 %
Epoch 348 of 2000 took 0.100s
  training loss:		1.274224
  validation loss:		1.192228
  validation accuracy:		65.54 %
Epoch 349 of 2000 took 0.099s
  training loss:		1.286909
  validation loss:		1.155056
  validation accuracy:		65.65 %
Epoch 350 of 2000 took 0.097s
  training loss:		1.266046
  validation loss:		1.169831
  validation accuracy:		66.74 %
Epoch 351 of 2000 took 0.097s
  training loss:		1.251558
  validation loss:		1.172368
  validation accuracy:		67.50 %
Epoch 352 of 2000 took 0.096s
  training loss:		1.257088
  validation loss:		1.135023
  validation accuracy:		66.30 %
Epoch 353 of 2000 took 0.101s
  training loss:		1.251872
  validation loss:		1.129287
  validation accuracy:		65.98 %
Epoch 354 of 2000 took 0.098s
  training loss:		1.237900
  validation loss:		1.114851
  validation accuracy:		67.39 %
Epoch 355 of 2000 took 0.096s
  training loss:		1.225342
  validation loss:		1.116268
  validation accuracy:		67.28 %
Epoch 356 of 2000 took 0.102s
  training loss:		1.232296
  validation loss:		1.100906
  validation accuracy:		68.15 %
Epoch 357 of 2000 took 0.096s
  training loss:		1.224887
  validation loss:		1.093683
  validation accuracy:		67.93 %
Epoch 358 of 2000 took 0.097s
  training loss:		1.203195
  validation loss:		1.081157
  validation accuracy:		68.59 %
Epoch 359 of 2000 took 0.096s
  training loss:		1.204530
  validation loss:		1.067492
  validation accuracy:		69.02 %
Epoch 360 of 2000 took 0.098s
  training loss:		1.173763
  validation loss:		1.077671
  validation accuracy:		70.00 %
Epoch 361 of 2000 took 0.101s
  training loss:		1.169237
  validation loss:		1.058818
  validation accuracy:		70.00 %
Epoch 362 of 2000 took 0.096s
  training loss:		1.167382
  validation loss:		1.031422
  validation accuracy:		69.78 %
Epoch 363 of 2000 took 0.097s
  training loss:		1.148676
  validation loss:		1.010369
  validation accuracy:		70.33 %
Epoch 364 of 2000 took 0.102s
  training loss:		1.119950
  validation loss:		0.996874
  validation accuracy:		70.65 %
Epoch 365 of 2000 took 0.096s
  training loss:		1.125118
  validation loss:		0.987558
  validation accuracy:		70.43 %
Epoch 366 of 2000 took 0.097s
  training loss:		1.100008
  validation loss:		1.012870
  validation accuracy:		71.63 %
Epoch 367 of 2000 took 0.096s
  training loss:		1.079615
  validation loss:		0.949592
  validation accuracy:		71.41 %
Epoch 368 of 2000 took 0.099s
  training loss:		1.055898
  validation loss:		0.955645
  validation accuracy:		71.52 %
Epoch 369 of 2000 took 0.099s
  training loss:		1.066153
  validation loss:		0.954097
  validation accuracy:		71.96 %
Epoch 370 of 2000 took 0.096s
  training loss:		1.076089
  validation loss:		0.937737
  validation accuracy:		72.17 %
Epoch 371 of 2000 took 0.099s
  training loss:		1.013999
  validation loss:		0.898105
  validation accuracy:		72.72 %
Epoch 372 of 2000 took 0.100s
  training loss:		0.997514
  validation loss:		0.898001
  validation accuracy:		72.17 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.995429
  validation loss:		0.897455
  validation accuracy:		72.50 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.987459
  validation loss:		0.885747
  validation accuracy:		71.96 %
Epoch 375 of 2000 took 0.096s
  training loss:		0.971687
  validation loss:		0.863130
  validation accuracy:		72.28 %
Epoch 376 of 2000 took 0.101s
  training loss:		0.956564
  validation loss:		0.848424
  validation accuracy:		71.52 %
Epoch 377 of 2000 took 0.098s
  training loss:		0.937626
  validation loss:		0.861377
  validation accuracy:		73.15 %
Epoch 378 of 2000 took 0.096s
  training loss:		0.931209
  validation loss:		0.820448
  validation accuracy:		72.50 %
Epoch 379 of 2000 took 0.102s
  training loss:		0.909987
  validation loss:		0.821815
  validation accuracy:		72.93 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.892144
  validation loss:		0.806959
  validation accuracy:		73.59 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.880440
  validation loss:		0.811024
  validation accuracy:		73.80 %
Epoch 382 of 2000 took 0.096s
  training loss:		0.871089
  validation loss:		0.792417
  validation accuracy:		74.13 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.867099
  validation loss:		0.777143
  validation accuracy:		74.13 %
Epoch 384 of 2000 took 0.101s
  training loss:		0.846566
  validation loss:		0.789895
  validation accuracy:		72.83 %
Epoch 385 of 2000 took 0.096s
  training loss:		0.843755
  validation loss:		0.750666
  validation accuracy:		74.46 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.830276
  validation loss:		0.769882
  validation accuracy:		73.59 %
Epoch 387 of 2000 took 0.102s
  training loss:		0.820481
  validation loss:		0.750192
  validation accuracy:		74.46 %
Epoch 388 of 2000 took 0.096s
  training loss:		0.821209
  validation loss:		0.740330
  validation accuracy:		73.26 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.816843
  validation loss:		0.736759
  validation accuracy:		74.78 %
Epoch 390 of 2000 took 0.096s
  training loss:		0.795916
  validation loss:		0.750869
  validation accuracy:		74.46 %
Epoch 391 of 2000 took 0.100s
  training loss:		0.783917
  validation loss:		0.720548
  validation accuracy:		74.13 %
Epoch 392 of 2000 took 0.099s
  training loss:		0.770400
  validation loss:		0.715516
  validation accuracy:		73.91 %
Epoch 393 of 2000 took 0.096s
  training loss:		0.768170
  validation loss:		0.708352
  validation accuracy:		75.11 %
Epoch 394 of 2000 took 0.099s
  training loss:		0.759534
  validation loss:		0.707377
  validation accuracy:		75.33 %
Epoch 395 of 2000 took 0.100s
  training loss:		0.756584
  validation loss:		0.705900
  validation accuracy:		75.98 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.743971
  validation loss:		0.683577
  validation accuracy:		75.43 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.733631
  validation loss:		0.689175
  validation accuracy:		75.33 %
Epoch 398 of 2000 took 0.096s
  training loss:		0.735666
  validation loss:		0.678457
  validation accuracy:		75.43 %
Epoch 399 of 2000 took 0.101s
  training loss:		0.724266
  validation loss:		0.688373
  validation accuracy:		76.09 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.716824
  validation loss:		0.687004
  validation accuracy:		75.65 %
Epoch 401 of 2000 took 0.096s
  training loss:		0.724832
  validation loss:		0.679797
  validation accuracy:		76.74 %
Epoch 402 of 2000 took 0.102s
  training loss:		0.712241
  validation loss:		0.658053
  validation accuracy:		76.41 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.729716
  validation loss:		0.679552
  validation accuracy:		77.17 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.701014
  validation loss:		0.671709
  validation accuracy:		75.87 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.699242
  validation loss:		0.659623
  validation accuracy:		75.98 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.693100
  validation loss:		0.663511
  validation accuracy:		76.85 %
Epoch 407 of 2000 took 0.100s
  training loss:		0.699881
  validation loss:		0.674672
  validation accuracy:		77.17 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.673631
  validation loss:		0.673042
  validation accuracy:		76.74 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.681160
  validation loss:		0.661526
  validation accuracy:		76.63 %
Epoch 410 of 2000 took 0.102s
  training loss:		0.669404
  validation loss:		0.643503
  validation accuracy:		78.04 %
Epoch 411 of 2000 took 0.096s
  training loss:		0.676413
  validation loss:		0.667773
  validation accuracy:		77.39 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.671732
  validation loss:		0.632620
  validation accuracy:		77.61 %
Epoch 413 of 2000 took 0.096s
  training loss:		0.662824
  validation loss:		0.633378
  validation accuracy:		77.50 %
Epoch 414 of 2000 took 0.099s
  training loss:		0.661208
  validation loss:		0.672510
  validation accuracy:		77.61 %
Epoch 415 of 2000 took 0.099s
  training loss:		0.665852
  validation loss:		0.674209
  validation accuracy:		77.72 %
Epoch 416 of 2000 took 0.096s
  training loss:		0.657147
  validation loss:		0.624440
  validation accuracy:		77.93 %
Epoch 417 of 2000 took 0.099s
  training loss:		0.649383
  validation loss:		0.647465
  validation accuracy:		78.59 %
Epoch 418 of 2000 took 0.100s
  training loss:		0.653643
  validation loss:		0.632483
  validation accuracy:		78.48 %
Epoch 419 of 2000 took 0.096s
  training loss:		0.644677
  validation loss:		0.628270
  validation accuracy:		78.59 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.649230
  validation loss:		0.626139
  validation accuracy:		77.61 %
Epoch 421 of 2000 took 0.096s
  training loss:		0.647563
  validation loss:		0.669865
  validation accuracy:		78.26 %
Epoch 422 of 2000 took 0.101s
  training loss:		0.653271
  validation loss:		0.656815
  validation accuracy:		78.04 %
Epoch 423 of 2000 took 0.098s
  training loss:		0.640608
  validation loss:		0.632058
  validation accuracy:		78.04 %
Epoch 424 of 2000 took 0.096s
  training loss:		0.634943
  validation loss:		0.636857
  validation accuracy:		78.37 %
Epoch 425 of 2000 took 0.102s
  training loss:		0.632342
  validation loss:		0.624902
  validation accuracy:		77.83 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.630268
  validation loss:		0.627894
  validation accuracy:		79.02 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.631908
  validation loss:		0.617724
  validation accuracy:		79.13 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.618860
  validation loss:		0.625406
  validation accuracy:		79.13 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.627782
  validation loss:		0.616981
  validation accuracy:		78.04 %
Epoch 430 of 2000 took 0.101s
  training loss:		0.622045
  validation loss:		0.609014
  validation accuracy:		78.15 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.623343
  validation loss:		0.651427
  validation accuracy:		78.59 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.621454
  validation loss:		0.632676
  validation accuracy:		78.80 %
Epoch 433 of 2000 took 0.103s
  training loss:		0.623529
  validation loss:		0.619980
  validation accuracy:		79.35 %
Epoch 434 of 2000 took 0.096s
  training loss:		0.615865
  validation loss:		0.621957
  validation accuracy:		79.46 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.615710
  validation loss:		0.632716
  validation accuracy:		78.91 %
Epoch 436 of 2000 took 0.096s
  training loss:		0.622396
  validation loss:		0.606437
  validation accuracy:		79.67 %
Epoch 437 of 2000 took 0.098s
  training loss:		0.618716
  validation loss:		0.616895
  validation accuracy:		78.70 %
Epoch 438 of 2000 took 0.100s
  training loss:		0.608416
  validation loss:		0.610216
  validation accuracy:		79.67 %
Epoch 439 of 2000 took 0.096s
  training loss:		0.605181
  validation loss:		0.636021
  validation accuracy:		79.24 %
Epoch 440 of 2000 took 0.102s
  training loss:		0.611678
  validation loss:		0.606055
  validation accuracy:		78.48 %
Epoch 441 of 2000 took 0.101s
  training loss:		0.611373
  validation loss:		0.602478
  validation accuracy:		78.70 %
Epoch 442 of 2000 took 0.096s
  training loss:		0.628881
  validation loss:		0.604275
  validation accuracy:		79.24 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.613551
  validation loss:		0.602927
  validation accuracy:		79.13 %
Epoch 444 of 2000 took 0.096s
  training loss:		0.598180
  validation loss:		0.623686
  validation accuracy:		79.02 %
Epoch 445 of 2000 took 0.101s
  training loss:		0.621568
  validation loss:		0.617834
  validation accuracy:		79.57 %
Epoch 446 of 2000 took 0.098s
  training loss:		0.604026
  validation loss:		0.610234
  validation accuracy:		79.13 %
Epoch 447 of 2000 took 0.096s
  training loss:		0.603111
  validation loss:		0.604069
  validation accuracy:		79.46 %
Epoch 448 of 2000 took 0.102s
  training loss:		0.601594
  validation loss:		0.613345
  validation accuracy:		79.24 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.606067
  validation loss:		0.601746
  validation accuracy:		79.13 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.603776
  validation loss:		0.627097
  validation accuracy:		79.46 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.606525
  validation loss:		0.605133
  validation accuracy:		79.67 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.597460
  validation loss:		0.636006
  validation accuracy:		78.15 %
Epoch 453 of 2000 took 0.100s
  training loss:		0.605710
  validation loss:		0.613282
  validation accuracy:		79.13 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.599452
  validation loss:		0.598156
  validation accuracy:		79.46 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.598321
  validation loss:		0.627050
  validation accuracy:		79.35 %
Epoch 456 of 2000 took 0.103s
  training loss:		0.600206
  validation loss:		0.621433
  validation accuracy:		77.83 %
Epoch 457 of 2000 took 0.096s
  training loss:		0.595521
  validation loss:		0.600566
  validation accuracy:		79.57 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.596510
  validation loss:		0.612919
  validation accuracy:		79.35 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.593940
  validation loss:		0.594770
  validation accuracy:		79.02 %
Epoch 460 of 2000 took 0.098s
  training loss:		0.607080
  validation loss:		0.590937
  validation accuracy:		78.80 %
Epoch 461 of 2000 took 0.100s
  training loss:		0.596248
  validation loss:		0.602211
  validation accuracy:		79.46 %
Epoch 462 of 2000 took 0.096s
  training loss:		0.594257
  validation loss:		0.621541
  validation accuracy:		79.02 %
Epoch 463 of 2000 took 0.098s
  training loss:		0.616804
  validation loss:		0.609531
  validation accuracy:		79.46 %
Epoch 464 of 2000 took 0.101s
  training loss:		0.596580
  validation loss:		0.591170
  validation accuracy:		79.13 %
Epoch 465 of 2000 took 0.096s
  training loss:		0.592882
  validation loss:		0.615836
  validation accuracy:		79.02 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.595052
  validation loss:		0.621877
  validation accuracy:		79.46 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.606987
  validation loss:		0.605148
  validation accuracy:		79.89 %
Epoch 468 of 2000 took 0.101s
  training loss:		0.587083
  validation loss:		0.595057
  validation accuracy:		79.35 %
Epoch 469 of 2000 took 0.098s
  training loss:		0.595460
  validation loss:		0.603392
  validation accuracy:		79.35 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.600385
  validation loss:		0.603051
  validation accuracy:		79.67 %
Epoch 471 of 2000 took 0.102s
  training loss:		0.591153
  validation loss:		0.585672
  validation accuracy:		79.67 %
Epoch 472 of 2000 took 0.098s
  training loss:		0.590230
  validation loss:		0.594928
  validation accuracy:		79.24 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.586419
  validation loss:		0.607950
  validation accuracy:		79.57 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.586598
  validation loss:		0.607357
  validation accuracy:		79.67 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.587474
  validation loss:		0.596873
  validation accuracy:		79.67 %
Epoch 476 of 2000 took 0.101s
  training loss:		0.593814
  validation loss:		0.593303
  validation accuracy:		79.57 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.599235
  validation loss:		0.599338
  validation accuracy:		79.89 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.590948
  validation loss:		0.641499
  validation accuracy:		78.26 %
Epoch 479 of 2000 took 0.103s
  training loss:		0.577701
  validation loss:		0.593651
  validation accuracy:		79.46 %
Epoch 480 of 2000 took 0.096s
  training loss:		0.593524
  validation loss:		0.598790
  validation accuracy:		79.46 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.585403
  validation loss:		0.594659
  validation accuracy:		78.80 %
Epoch 482 of 2000 took 0.096s
  training loss:		0.590021
  validation loss:		0.602989
  validation accuracy:		79.24 %
Epoch 483 of 2000 took 0.098s
  training loss:		0.586328
  validation loss:		0.601844
  validation accuracy:		79.89 %
Epoch 484 of 2000 took 0.100s
  training loss:		0.585249
  validation loss:		0.609866
  validation accuracy:		79.78 %
Epoch 485 of 2000 took 0.096s
  training loss:		0.614535
  validation loss:		0.603892
  validation accuracy:		79.89 %
Epoch 486 of 2000 took 0.098s
  training loss:		0.581046
  validation loss:		0.605917
  validation accuracy:		79.46 %
Epoch 487 of 2000 took 0.102s
  training loss:		0.588123
  validation loss:		0.592777
  validation accuracy:		80.33 %
Epoch 488 of 2000 took 0.096s
  training loss:		0.592225
  validation loss:		0.586193
  validation accuracy:		79.89 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.577959
  validation loss:		0.601927
  validation accuracy:		79.67 %
Epoch 490 of 2000 took 0.096s
  training loss:		0.580642
  validation loss:		0.592242
  validation accuracy:		79.57 %
Epoch 491 of 2000 took 0.101s
  training loss:		0.576946
  validation loss:		0.594209
  validation accuracy:		80.11 %
Epoch 492 of 2000 took 0.098s
  training loss:		0.580661
  validation loss:		0.635473
  validation accuracy:		78.37 %
Epoch 493 of 2000 took 0.096s
  training loss:		0.595831
  validation loss:		0.656907
  validation accuracy:		77.28 %
Epoch 494 of 2000 took 0.102s
  training loss:		0.588336
  validation loss:		0.595820
  validation accuracy:		79.35 %
Epoch 495 of 2000 took 0.098s
  training loss:		0.586123
  validation loss:		0.604002
  validation accuracy:		80.00 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.595751
  validation loss:		0.605254
  validation accuracy:		79.78 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.584799
  validation loss:		0.599434
  validation accuracy:		80.33 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.582999
  validation loss:		0.591244
  validation accuracy:		80.11 %
Epoch 499 of 2000 took 0.100s
  training loss:		0.574864
  validation loss:		0.596758
  validation accuracy:		79.57 %
Epoch 500 of 2000 took 0.098s
  training loss:		0.596768
  validation loss:		0.592567
  validation accuracy:		79.57 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.585260
  validation loss:		0.618883
  validation accuracy:		79.24 %
Epoch 502 of 2000 took 0.103s
  training loss:		0.578270
  validation loss:		0.608218
  validation accuracy:		79.67 %
Epoch 503 of 2000 took 0.096s
  training loss:		0.579544
  validation loss:		0.600280
  validation accuracy:		80.11 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.576687
  validation loss:		0.601958
  validation accuracy:		80.00 %
Epoch 505 of 2000 took 0.096s
  training loss:		0.578710
  validation loss:		0.599513
  validation accuracy:		79.57 %
Epoch 506 of 2000 took 0.098s
  training loss:		0.578985
  validation loss:		0.587212
  validation accuracy:		79.89 %
Epoch 507 of 2000 took 0.101s
  training loss:		0.584278
  validation loss:		0.615433
  validation accuracy:		79.24 %
Epoch 508 of 2000 took 0.096s
  training loss:		0.579075
  validation loss:		0.595023
  validation accuracy:		79.67 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.582252
  validation loss:		0.627522
  validation accuracy:		78.70 %
Epoch 510 of 2000 took 0.102s
  training loss:		0.601305
  validation loss:		0.613452
  validation accuracy:		79.67 %
Epoch 511 of 2000 took 0.096s
  training loss:		0.571357
  validation loss:		0.595838
  validation accuracy:		79.78 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.577200
  validation loss:		0.603801
  validation accuracy:		79.89 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.587385
  validation loss:		0.630324
  validation accuracy:		79.35 %
Epoch 514 of 2000 took 0.100s
  training loss:		0.583031
  validation loss:		0.594483
  validation accuracy:		79.67 %
Epoch 515 of 2000 took 0.098s
  training loss:		0.569997
  validation loss:		0.604896
  validation accuracy:		79.78 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.587486
  validation loss:		0.596705
  validation accuracy:		80.11 %
Epoch 517 of 2000 took 0.100s
  training loss:		0.593716
  validation loss:		0.592985
  validation accuracy:		80.11 %
Epoch 518 of 2000 took 0.099s
  training loss:		0.566989
  validation loss:		0.592086
  validation accuracy:		79.78 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.572217
  validation loss:		0.612243
  validation accuracy:		79.13 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.584249
  validation loss:		0.603347
  validation accuracy:		79.02 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.585616
  validation loss:		0.586571
  validation accuracy:		80.00 %
Epoch 522 of 2000 took 0.101s
  training loss:		0.576337
  validation loss:		0.599643
  validation accuracy:		80.22 %
Epoch 523 of 2000 took 0.098s
  training loss:		0.581320
  validation loss:		0.645146
  validation accuracy:		78.48 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.577343
  validation loss:		0.585618
  validation accuracy:		80.11 %
Epoch 525 of 2000 took 0.102s
  training loss:		0.572399
  validation loss:		0.588387
  validation accuracy:		79.67 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.582800
  validation loss:		0.594767
  validation accuracy:		79.35 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.574336
  validation loss:		0.596372
  validation accuracy:		79.57 %
Epoch 528 of 2000 took 0.096s
  training loss:		0.584664
  validation loss:		0.618341
  validation accuracy:		79.67 %
Epoch 529 of 2000 took 0.098s
  training loss:		0.576970
  validation loss:		0.610643
  validation accuracy:		80.11 %
Epoch 530 of 2000 took 0.101s
  training loss:		0.574489
  validation loss:		0.585667
  validation accuracy:		80.11 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.580515
  validation loss:		0.600747
  validation accuracy:		80.11 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.569833
  validation loss:		0.594947
  validation accuracy:		79.67 %
Epoch 533 of 2000 took 0.102s
  training loss:		0.581562
  validation loss:		0.616678
  validation accuracy:		79.89 %
Epoch 534 of 2000 took 0.096s
  training loss:		0.583275
  validation loss:		0.634544
  validation accuracy:		78.26 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.588216
  validation loss:		0.590075
  validation accuracy:		79.89 %
Epoch 536 of 2000 took 0.096s
  training loss:		0.584739
  validation loss:		0.618700
  validation accuracy:		79.67 %
Epoch 537 of 2000 took 0.099s
  training loss:		0.572917
  validation loss:		0.596823
  validation accuracy:		79.89 %
Epoch 538 of 2000 took 0.099s
  training loss:		0.585225
  validation loss:		0.593766
  validation accuracy:		80.22 %
Epoch 539 of 2000 took 0.096s
  training loss:		0.626836
  validation loss:		0.631078
  validation accuracy:		79.67 %
Epoch 540 of 2000 took 0.099s
  training loss:		0.572653
  validation loss:		0.584928
  validation accuracy:		80.22 %
Epoch 541 of 2000 took 0.100s
  training loss:		0.579237
  validation loss:		0.587981
  validation accuracy:		80.00 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.582704
  validation loss:		0.580644
  validation accuracy:		80.00 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.579269
  validation loss:		0.583935
  validation accuracy:		80.43 %
Epoch 544 of 2000 took 0.096s
  training loss:		0.574189
  validation loss:		0.585681
  validation accuracy:		79.89 %
Epoch 545 of 2000 took 0.101s
  training loss:		0.576421
  validation loss:		0.601283
  validation accuracy:		80.22 %
Epoch 546 of 2000 took 0.098s
  training loss:		0.581542
  validation loss:		0.591435
  validation accuracy:		79.35 %
Epoch 547 of 2000 took 0.096s
  training loss:		0.588287
  validation loss:		0.602769
  validation accuracy:		79.24 %
Epoch 548 of 2000 took 0.102s
  training loss:		0.574372
  validation loss:		0.587563
  validation accuracy:		80.43 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.595922
  validation loss:		0.594870
  validation accuracy:		80.65 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.576486
  validation loss:		0.641023
  validation accuracy:		78.59 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.576338
  validation loss:		0.584132
  validation accuracy:		80.11 %
Epoch 552 of 2000 took 0.098s
  training loss:		0.585326
  validation loss:		0.579103
  validation accuracy:		80.43 %
Epoch 553 of 2000 took 0.100s
  training loss:		0.570853
  validation loss:		0.583091
  validation accuracy:		80.54 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.564541
  validation loss:		0.608546
  validation accuracy:		79.78 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.582420
  validation loss:		0.638723
  validation accuracy:		78.48 %
Epoch 556 of 2000 took 0.102s
  training loss:		0.586707
  validation loss:		0.590786
  validation accuracy:		80.33 %
Epoch 557 of 2000 took 0.096s
  training loss:		0.584774
  validation loss:		0.585374
  validation accuracy:		80.22 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.605144
  validation loss:		0.637733
  validation accuracy:		77.93 %
Epoch 559 of 2000 took 0.096s
  training loss:		0.592881
  validation loss:		0.601136
  validation accuracy:		79.35 %
Epoch 560 of 2000 took 0.099s
  training loss:		0.575749
  validation loss:		0.597666
  validation accuracy:		80.22 %
Epoch 561 of 2000 took 0.100s
  training loss:		0.576594
  validation loss:		0.591873
  validation accuracy:		80.33 %
Epoch 562 of 2000 took 0.096s
  training loss:		0.574853
  validation loss:		0.604987
  validation accuracy:		79.24 %
Epoch 563 of 2000 took 0.098s
  training loss:		0.565046
  validation loss:		0.585305
  validation accuracy:		80.43 %
Epoch 564 of 2000 took 0.101s
  training loss:		0.582028
  validation loss:		0.588533
  validation accuracy:		79.78 %
Epoch 565 of 2000 took 0.096s
  training loss:		0.575794
  validation loss:		0.639378
  validation accuracy:		78.04 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.584750
  validation loss:		0.592829
  validation accuracy:		80.00 %
Epoch 567 of 2000 took 0.096s
  training loss:		0.580923
  validation loss:		0.586313
  validation accuracy:		80.22 %
Epoch 568 of 2000 took 0.101s
  training loss:		0.577271
  validation loss:		0.599517
  validation accuracy:		79.57 %
Epoch 569 of 2000 took 0.098s
  training loss:		0.587209
  validation loss:		0.595135
  validation accuracy:		80.33 %
Epoch 570 of 2000 took 0.096s
  training loss:		0.582659
  validation loss:		0.584051
  validation accuracy:		79.78 %
Epoch 571 of 2000 took 0.101s
  training loss:		0.570961
  validation loss:		0.576389
  validation accuracy:		80.65 %
Epoch 572 of 2000 took 0.098s
  training loss:		0.569730
  validation loss:		0.589112
  validation accuracy:		79.78 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.571562
  validation loss:		0.589489
  validation accuracy:		80.65 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.574523
  validation loss:		0.583838
  validation accuracy:		80.22 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.571610
  validation loss:		0.602958
  validation accuracy:		79.78 %
Epoch 576 of 2000 took 0.100s
  training loss:		0.573036
  validation loss:		0.602188
  validation accuracy:		80.00 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.575218
  validation loss:		0.649950
  validation accuracy:		78.59 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.583092
  validation loss:		0.596818
  validation accuracy:		80.00 %
Epoch 579 of 2000 took 0.103s
  training loss:		0.586352
  validation loss:		0.579954
  validation accuracy:		80.76 %
Epoch 580 of 2000 took 0.096s
  training loss:		0.569024
  validation loss:		0.586648
  validation accuracy:		79.89 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.573486
  validation loss:		0.588166
  validation accuracy:		80.00 %
Epoch 582 of 2000 took 0.096s
  training loss:		0.568856
  validation loss:		0.586855
  validation accuracy:		80.00 %
Epoch 583 of 2000 took 0.098s
  training loss:		0.566669
  validation loss:		0.583730
  validation accuracy:		80.33 %
Epoch 584 of 2000 took 0.100s
  training loss:		0.567205
  validation loss:		0.589938
  validation accuracy:		79.89 %
Epoch 585 of 2000 took 0.096s
  training loss:		0.581087
  validation loss:		0.590430
  validation accuracy:		79.89 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.584773
  validation loss:		0.604934
  validation accuracy:		79.78 %
Epoch 587 of 2000 took 0.102s
  training loss:		0.573972
  validation loss:		0.595283
  validation accuracy:		79.89 %
Epoch 588 of 2000 took 0.096s
  training loss:		0.588326
  validation loss:		0.596114
  validation accuracy:		79.46 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.570969
  validation loss:		0.586599
  validation accuracy:		80.22 %
Epoch 590 of 2000 took 0.096s
  training loss:		0.571776
  validation loss:		0.592583
  validation accuracy:		79.78 %
Epoch 591 of 2000 took 0.101s
  training loss:		0.569415
  validation loss:		0.595930
  validation accuracy:		80.33 %
Epoch 592 of 2000 took 0.098s
  training loss:		0.574200
  validation loss:		0.602847
  validation accuracy:		79.35 %
Epoch 593 of 2000 took 0.096s
  training loss:		0.572480
  validation loss:		0.605889
  validation accuracy:		80.11 %
Epoch 594 of 2000 took 0.101s
  training loss:		0.582473
  validation loss:		0.579323
  validation accuracy:		80.33 %
Epoch 595 of 2000 took 0.098s
  training loss:		0.612590
  validation loss:		0.626261
  validation accuracy:		79.78 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.567900
  validation loss:		0.598495
  validation accuracy:		80.11 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.584202
  validation loss:		0.584627
  validation accuracy:		80.33 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.565472
  validation loss:		0.586973
  validation accuracy:		80.00 %
Epoch 599 of 2000 took 0.100s
  training loss:		0.578028
  validation loss:		0.592411
  validation accuracy:		79.89 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.579312
  validation loss:		0.598085
  validation accuracy:		80.00 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.584727
  validation loss:		0.621038
  validation accuracy:		79.35 %
Epoch 602 of 2000 took 0.103s
  training loss:		0.575634
  validation loss:		0.579161
  validation accuracy:		80.22 %
Epoch 603 of 2000 took 0.096s
  training loss:		0.587379
  validation loss:		0.622180
  validation accuracy:		78.80 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.571732
  validation loss:		0.587887
  validation accuracy:		80.33 %
Epoch 605 of 2000 took 0.096s
  training loss:		0.571132
  validation loss:		0.591550
  validation accuracy:		79.46 %
Epoch 606 of 2000 took 0.098s
  training loss:		0.585550
  validation loss:		0.633328
  validation accuracy:		79.35 %
Epoch 607 of 2000 took 0.100s
  training loss:		0.575642
  validation loss:		0.607260
  validation accuracy:		80.00 %
Epoch 608 of 2000 took 0.096s
  training loss:		0.576496
  validation loss:		0.585383
  validation accuracy:		80.22 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.569336
  validation loss:		0.606045
  validation accuracy:		80.00 %
Epoch 610 of 2000 took 0.102s
  training loss:		0.573177
  validation loss:		0.596417
  validation accuracy:		80.11 %
Epoch 611 of 2000 took 0.096s
  training loss:		0.577681
  validation loss:		0.617918
  validation accuracy:		79.67 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.567829
  validation loss:		0.581565
  validation accuracy:		80.76 %
Epoch 613 of 2000 took 0.096s
  training loss:		0.580050
  validation loss:		0.598116
  validation accuracy:		80.11 %
Epoch 614 of 2000 took 0.100s
  training loss:		0.580445
  validation loss:		0.592761
  validation accuracy:		79.78 %
Epoch 615 of 2000 took 0.098s
  training loss:		0.585575
  validation loss:		0.580521
  validation accuracy:		80.76 %
Epoch 616 of 2000 took 0.096s
  training loss:		0.573970
  validation loss:		0.584646
  validation accuracy:		80.00 %
Epoch 617 of 2000 took 0.101s
  training loss:		0.575986
  validation loss:		0.590456
  validation accuracy:		80.00 %
Epoch 618 of 2000 took 0.098s
  training loss:		0.573057
  validation loss:		0.590816
  validation accuracy:		80.00 %
Epoch 619 of 2000 took 0.097s
  training loss:		0.578041
  validation loss:		0.593415
  validation accuracy:		79.78 %
Epoch 620 of 2000 took 0.097s
  training loss:		0.570620
  validation loss:		0.590522
  validation accuracy:		80.54 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.569945
  validation loss:		0.587747
  validation accuracy:		80.11 %
Epoch 622 of 2000 took 0.101s
  training loss:		0.582413
  validation loss:		0.624096
  validation accuracy:		79.46 %
Epoch 623 of 2000 took 0.098s
  training loss:		0.571051
  validation loss:		0.600006
  validation accuracy:		79.89 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.580917
  validation loss:		0.591094
  validation accuracy:		80.22 %
Epoch 625 of 2000 took 0.102s
  training loss:		0.575841
  validation loss:		0.608607
  validation accuracy:		79.46 %
Epoch 626 of 2000 took 0.097s
  training loss:		0.565139
  validation loss:		0.590056
  validation accuracy:		80.65 %
Epoch 627 of 2000 took 0.097s
  training loss:		0.599873
  validation loss:		0.605220
  validation accuracy:		79.24 %
Epoch 628 of 2000 took 0.096s
  training loss:		0.576806
  validation loss:		0.606709
  validation accuracy:		79.46 %
Epoch 629 of 2000 took 0.097s
  training loss:		0.574788
  validation loss:		0.578177
  validation accuracy:		80.76 %
Epoch 630 of 2000 took 0.101s
  training loss:		0.567466
  validation loss:		0.593505
  validation accuracy:		80.11 %
Epoch 631 of 2000 took 0.096s
  training loss:		0.568240
  validation loss:		0.582198
  validation accuracy:		80.43 %
Epoch 632 of 2000 took 0.097s
  training loss:		0.587971
  validation loss:		0.602462
  validation accuracy:		79.78 %
Epoch 633 of 2000 took 0.103s
  training loss:		0.581670
  validation loss:		0.594538
  validation accuracy:		79.78 %
Epoch 634 of 2000 took 0.096s
  training loss:		0.574150
  validation loss:		0.586374
  validation accuracy:		80.00 %
Epoch 635 of 2000 took 0.097s
  training loss:		0.587936
  validation loss:		0.637018
  validation accuracy:		78.80 %
Epoch 636 of 2000 took 0.096s
  training loss:		0.590816
  validation loss:		0.602335
  validation accuracy:		80.00 %
Epoch 637 of 2000 took 0.099s
  training loss:		0.567802
  validation loss:		0.600024
  validation accuracy:		79.24 %
Epoch 638 of 2000 took 0.099s
  training loss:		0.565546
  validation loss:		0.615430
  validation accuracy:		79.57 %
Epoch 639 of 2000 took 0.096s
  training loss:		0.573568
  validation loss:		0.587984
  validation accuracy:		79.89 %
Epoch 640 of 2000 took 0.099s
  training loss:		0.571179
  validation loss:		0.594651
  validation accuracy:		79.67 %
Epoch 641 of 2000 took 0.100s
  training loss:		0.580682
  validation loss:		0.581437
  validation accuracy:		80.76 %
Epoch 642 of 2000 took 0.097s
  training loss:		0.580065
  validation loss:		0.585903
  validation accuracy:		80.00 %
Epoch 643 of 2000 took 0.097s
  training loss:		0.571446
  validation loss:		0.655455
  validation accuracy:		78.48 %
Epoch 644 of 2000 took 0.096s
  training loss:		0.572368
  validation loss:		0.591568
  validation accuracy:		80.00 %
Epoch 645 of 2000 took 0.101s
  training loss:		0.567182
  validation loss:		0.583179
  validation accuracy:		80.65 %
Epoch 646 of 2000 took 0.098s
  training loss:		0.572846
  validation loss:		0.604261
  validation accuracy:		80.22 %
Epoch 647 of 2000 took 0.096s
  training loss:		0.569546
  validation loss:		0.583253
  validation accuracy:		80.43 %
Epoch 648 of 2000 took 0.102s
  training loss:		0.565787
  validation loss:		0.595978
  validation accuracy:		80.11 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.571090
  validation loss:		0.592586
  validation accuracy:		80.22 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.565852
  validation loss:		0.598081
  validation accuracy:		80.11 %
Epoch 651 of 2000 took 0.096s
  training loss:		0.571556
  validation loss:		0.586124
  validation accuracy:		80.22 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.569182
  validation loss:		0.623994
  validation accuracy:		79.24 %
Epoch 653 of 2000 took 0.100s
  training loss:		0.581733
  validation loss:		0.580488
  validation accuracy:		80.33 %
Epoch 654 of 2000 took 0.097s
  training loss:		0.569157
  validation loss:		0.609961
  validation accuracy:		79.89 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.568047
  validation loss:		0.584257
  validation accuracy:		80.43 %
Epoch 656 of 2000 took 0.103s
  training loss:		0.577721
  validation loss:		0.605448
  validation accuracy:		80.11 %
Epoch 657 of 2000 took 0.096s
  training loss:		0.583899
  validation loss:		0.585041
  validation accuracy:		80.54 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.571219
  validation loss:		0.579354
  validation accuracy:		80.33 %
Epoch 659 of 2000 took 0.096s
  training loss:		0.566028
  validation loss:		0.595744
  validation accuracy:		79.57 %
Epoch 660 of 2000 took 0.102s
  training loss:		0.573260
  validation loss:		0.616173
  validation accuracy:		78.91 %
Epoch 661 of 2000 took 0.099s
  training loss:		0.572795
  validation loss:		0.651820
  validation accuracy:		78.70 %
Epoch 662 of 2000 took 0.096s
  training loss:		0.568000
  validation loss:		0.598606
  validation accuracy:		80.00 %
Epoch 663 of 2000 took 0.099s
  training loss:		0.566217
  validation loss:		0.614390
  validation accuracy:		78.80 %
Epoch 664 of 2000 took 0.100s
  training loss:		0.568558
  validation loss:		0.626989
  validation accuracy:		78.80 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.573375
  validation loss:		0.582016
  validation accuracy:		80.76 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.568930
  validation loss:		0.594101
  validation accuracy:		80.22 %
Epoch 667 of 2000 took 0.096s
  training loss:		0.572335
  validation loss:		0.610154
  validation accuracy:		79.46 %
Epoch 668 of 2000 took 0.101s
  training loss:		0.567895
  validation loss:		0.583864
  validation accuracy:		80.43 %
Epoch 669 of 2000 took 0.098s
  training loss:		0.566095
  validation loss:		0.580254
  validation accuracy:		80.43 %
Epoch 670 of 2000 took 0.096s
  training loss:		0.581805
  validation loss:		0.614180
  validation accuracy:		79.57 %
Epoch 671 of 2000 took 0.102s
  training loss:		0.589395
  validation loss:		0.596264
  validation accuracy:		80.33 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.560544
  validation loss:		0.595820
  validation accuracy:		80.33 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.578330
  validation loss:		0.592598
  validation accuracy:		80.43 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.587197
  validation loss:		0.586238
  validation accuracy:		80.76 %
Epoch 675 of 2000 took 0.097s
  training loss:		0.566097
  validation loss:		0.602611
  validation accuracy:		80.00 %
Epoch 676 of 2000 took 0.101s
  training loss:		0.567001
  validation loss:		0.584325
  validation accuracy:		80.54 %
Epoch 677 of 2000 took 0.099s
  training loss:		0.575100
  validation loss:		0.579430
  validation accuracy:		80.65 %
Epoch 678 of 2000 took 0.100s
  training loss:		0.575218
  validation loss:		0.632532
  validation accuracy:		78.70 %
Epoch 679 of 2000 took 0.106s
  training loss:		0.578631
  validation loss:		0.589162
  validation accuracy:		80.65 %
Epoch 680 of 2000 took 0.099s
  training loss:		0.569742
  validation loss:		0.580826
  validation accuracy:		80.76 %
Epoch 681 of 2000 took 0.100s
  training loss:		0.570799
  validation loss:		0.581570
  validation accuracy:		80.11 %
Epoch 682 of 2000 took 0.099s
  training loss:		0.571355
  validation loss:		0.583621
  validation accuracy:		80.76 %
Epoch 683 of 2000 took 0.102s
  training loss:		0.573167
  validation loss:		0.587960
  validation accuracy:		80.43 %
Epoch 684 of 2000 took 0.103s
  training loss:		0.564194
  validation loss:		0.580494
  validation accuracy:		80.54 %
Epoch 685 of 2000 took 0.099s
  training loss:		0.565846
  validation loss:		0.598015
  validation accuracy:		79.57 %
Epoch 686 of 2000 took 0.102s
  training loss:		0.559551
  validation loss:		0.604977
  validation accuracy:		79.35 %
Epoch 687 of 2000 took 0.103s
  training loss:		0.563534
  validation loss:		0.579815
  validation accuracy:		80.76 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.565717
  validation loss:		0.603160
  validation accuracy:		79.67 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.577549
  validation loss:		0.590442
  validation accuracy:		80.43 %
Epoch 690 of 2000 took 0.099s
  training loss:		0.571761
  validation loss:		0.596274
  validation accuracy:		79.57 %
Epoch 691 of 2000 took 0.104s
  training loss:		0.570949
  validation loss:		0.580047
  validation accuracy:		80.87 %
Epoch 692 of 2000 took 0.101s
  training loss:		0.569943
  validation loss:		0.583249
  validation accuracy:		80.33 %
Epoch 693 of 2000 took 0.099s
  training loss:		0.564672
  validation loss:		0.580397
  validation accuracy:		80.00 %
Epoch 694 of 2000 took 0.105s
  training loss:		0.569863
  validation loss:		0.587301
  validation accuracy:		80.22 %
Epoch 695 of 2000 took 0.100s
  training loss:		0.574541
  validation loss:		0.584153
  validation accuracy:		80.33 %
Epoch 696 of 2000 took 0.100s
  training loss:		0.565426
  validation loss:		0.589421
  validation accuracy:		80.11 %
Epoch 697 of 2000 took 0.100s
  training loss:		0.573225
  validation loss:		0.595417
  validation accuracy:		79.67 %
Epoch 698 of 2000 took 0.101s
  training loss:		0.575299
  validation loss:		0.598336
  validation accuracy:		79.57 %
Epoch 699 of 2000 took 0.105s
  training loss:		0.567089
  validation loss:		0.585746
  validation accuracy:		80.43 %
Epoch 700 of 2000 took 0.100s
  training loss:		0.568193
  validation loss:		0.589605
  validation accuracy:		79.89 %
Epoch 701 of 2000 took 0.100s
  training loss:		0.570100
  validation loss:		0.608449
  validation accuracy:		79.57 %
Epoch 702 of 2000 took 0.103s
  training loss:		0.571360
  validation loss:		0.606934
  validation accuracy:		79.67 %
Epoch 703 of 2000 took 0.099s
  training loss:		0.574477
  validation loss:		0.585510
  validation accuracy:		80.11 %
Epoch 704 of 2000 took 0.103s
  training loss:		0.575539
  validation loss:		0.581298
  validation accuracy:		80.22 %
Epoch 705 of 2000 took 0.099s
  training loss:		0.559586
  validation loss:		0.601174
  validation accuracy:		79.89 %
Epoch 706 of 2000 took 0.100s
  training loss:		0.566333
  validation loss:		0.586875
  validation accuracy:		80.00 %
Epoch 707 of 2000 took 0.102s
  training loss:		0.568369
  validation loss:		0.617554
  validation accuracy:		79.24 %
Epoch 708 of 2000 took 0.100s
  training loss:		0.569090
  validation loss:		0.595172
  validation accuracy:		80.00 %
Epoch 709 of 2000 took 0.103s
  training loss:		0.562341
  validation loss:		0.616357
  validation accuracy:		78.37 %
Epoch 710 of 2000 took 0.099s
  training loss:		0.580257
  validation loss:		0.602005
  validation accuracy:		79.46 %
Epoch 711 of 2000 took 0.102s
  training loss:		0.574338
  validation loss:		0.626518
  validation accuracy:		79.24 %
Epoch 712 of 2000 took 0.100s
  training loss:		0.562756
  validation loss:		0.616369
  validation accuracy:		79.02 %
Epoch 713 of 2000 took 0.100s
  training loss:		0.577065
  validation loss:		0.605102
  validation accuracy:		79.24 %
Epoch 714 of 2000 took 0.103s
  training loss:		0.572488
  validation loss:		0.612528
  validation accuracy:		79.57 %
Epoch 715 of 2000 took 0.099s
  training loss:		0.566034
  validation loss:		0.584039
  validation accuracy:		80.33 %
Epoch 716 of 2000 took 0.103s
  training loss:		0.584843
  validation loss:		0.583083
  validation accuracy:		80.43 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.566625
  validation loss:		0.589032
  validation accuracy:		80.65 %
Epoch 718 of 2000 took 0.098s
  training loss:		0.561474
  validation loss:		0.603163
  validation accuracy:		79.57 %
Epoch 719 of 2000 took 0.098s
  training loss:		0.565627
  validation loss:		0.597034
  validation accuracy:		80.00 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.568810
  validation loss:		0.594485
  validation accuracy:		80.22 %
Epoch 721 of 2000 took 0.100s
  training loss:		0.586251
  validation loss:		0.580107
  validation accuracy:		80.43 %
Epoch 722 of 2000 took 0.096s
  training loss:		0.568284
  validation loss:		0.594460
  validation accuracy:		80.43 %
Epoch 723 of 2000 took 0.100s
  training loss:		0.559534
  validation loss:		0.611588
  validation accuracy:		79.46 %
Epoch 724 of 2000 took 0.096s
  training loss:		0.552760
  validation loss:		0.586036
  validation accuracy:		80.43 %
Epoch 725 of 2000 took 0.097s
  training loss:		0.569511
  validation loss:		0.610583
  validation accuracy:		79.46 %
Epoch 726 of 2000 took 0.099s
  training loss:		0.562853
  validation loss:		0.583643
  validation accuracy:		80.22 %
Epoch 727 of 2000 took 0.096s
  training loss:		0.565039
  validation loss:		0.604952
  validation accuracy:		79.57 %
Epoch 728 of 2000 took 0.102s
  training loss:		0.571643
  validation loss:		0.616445
  validation accuracy:		78.91 %
Epoch 729 of 2000 took 0.096s
  training loss:		0.564908
  validation loss:		0.676739
  validation accuracy:		77.83 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.574092
  validation loss:		0.582505
  validation accuracy:		80.00 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.566756
  validation loss:		0.582342
  validation accuracy:		80.43 %
Epoch 732 of 2000 took 0.098s
  training loss:		0.568446
  validation loss:		0.589821
  validation accuracy:		79.89 %
Epoch 733 of 2000 took 0.101s
  training loss:		0.564584
  validation loss:		0.588871
  validation accuracy:		80.22 %
Epoch 734 of 2000 took 0.096s
  training loss:		0.574781
  validation loss:		0.579615
  validation accuracy:		80.11 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.564615
  validation loss:		0.602980
  validation accuracy:		79.35 %
Epoch 736 of 2000 took 0.102s
  training loss:		0.577813
  validation loss:		0.593423
  validation accuracy:		79.89 %
Epoch 737 of 2000 took 0.096s
  training loss:		0.572206
  validation loss:		0.584055
  validation accuracy:		80.00 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.570424
  validation loss:		0.637660
  validation accuracy:		78.80 %
Epoch 739 of 2000 took 0.096s
  training loss:		0.569572
  validation loss:		0.578305
  validation accuracy:		80.33 %
Epoch 740 of 2000 took 0.100s
  training loss:		0.575682
  validation loss:		0.587347
  validation accuracy:		80.00 %
Epoch 741 of 2000 took 0.099s
  training loss:		0.573164
  validation loss:		0.615624
  validation accuracy:		79.35 %
Epoch 742 of 2000 took 0.096s
  training loss:		0.573868
  validation loss:		0.609033
  validation accuracy:		79.57 %
Epoch 743 of 2000 took 0.099s
  training loss:		0.566646
  validation loss:		0.606043
  validation accuracy:		79.35 %
Epoch 744 of 2000 took 0.100s
  training loss:		0.569812
  validation loss:		0.592904
  validation accuracy:		80.43 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.571682
  validation loss:		0.590881
  validation accuracy:		79.89 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.567053
  validation loss:		0.593299
  validation accuracy:		79.89 %
Epoch 747 of 2000 took 0.096s
  training loss:		0.577363
  validation loss:		0.581525
  validation accuracy:		80.33 %
Epoch 748 of 2000 took 0.101s
  training loss:		0.587516
  validation loss:		0.595642
  validation accuracy:		79.67 %
Epoch 749 of 2000 took 0.098s
  training loss:		0.565914
  validation loss:		0.594983
  validation accuracy:		79.57 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.561980
  validation loss:		0.575161
  validation accuracy:		80.43 %
Epoch 751 of 2000 took 0.102s
  training loss:		0.561967
  validation loss:		0.578733
  validation accuracy:		80.43 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.570431
  validation loss:		0.577719
  validation accuracy:		80.22 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.560215
  validation loss:		0.585747
  validation accuracy:		79.89 %
Epoch 754 of 2000 took 0.097s
  training loss:		0.566317
  validation loss:		0.607432
  validation accuracy:		79.35 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.584151
  validation loss:		0.591835
  validation accuracy:		79.57 %
Epoch 756 of 2000 took 0.100s
  training loss:		0.572757
  validation loss:		0.591210
  validation accuracy:		80.22 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.567399
  validation loss:		0.602250
  validation accuracy:		79.89 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.564534
  validation loss:		0.635789
  validation accuracy:		78.91 %
Epoch 759 of 2000 took 0.102s
  training loss:		0.562739
  validation loss:		0.578193
  validation accuracy:		80.54 %
Epoch 760 of 2000 took 0.096s
  training loss:		0.569661
  validation loss:		0.583065
  validation accuracy:		80.11 %
Epoch 761 of 2000 took 0.097s
  training loss:		0.548488
  validation loss:		0.584986
  validation accuracy:		79.89 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.566934
  validation loss:		0.610069
  validation accuracy:		79.35 %
Epoch 763 of 2000 took 0.098s
  training loss:		0.572686
  validation loss:		0.638569
  validation accuracy:		78.37 %
Epoch 764 of 2000 took 0.100s
  training loss:		0.580910
  validation loss:		0.626428
  validation accuracy:		78.91 %
Epoch 765 of 2000 took 0.096s
  training loss:		0.572143
  validation loss:		0.589576
  validation accuracy:		79.67 %
Epoch 766 of 2000 took 0.098s
  training loss:		0.558271
  validation loss:		0.578747
  validation accuracy:		80.22 %
Epoch 767 of 2000 took 0.101s
  training loss:		0.568671
  validation loss:		0.579539
  validation accuracy:		80.22 %
Epoch 768 of 2000 took 0.096s
  training loss:		0.564548
  validation loss:		0.580743
  validation accuracy:		80.11 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.568949
  validation loss:		0.597212
  validation accuracy:		79.57 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.561426
  validation loss:		0.580114
  validation accuracy:		80.00 %
Epoch 771 of 2000 took 0.101s
  training loss:		0.563092
  validation loss:		0.580559
  validation accuracy:		80.33 %
Epoch 772 of 2000 took 0.098s
  training loss:		0.573041
  validation loss:		0.594978
  validation accuracy:		80.11 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.561926
  validation loss:		0.594031
  validation accuracy:		80.00 %
Epoch 774 of 2000 took 0.102s
  training loss:		0.561717
  validation loss:		0.575906
  validation accuracy:		80.33 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.559075
  validation loss:		0.594654
  validation accuracy:		79.78 %
Epoch 776 of 2000 took 0.097s
  training loss:		0.556777
  validation loss:		0.598583
  validation accuracy:		79.89 %
Epoch 777 of 2000 took 0.097s
  training loss:		0.559674
  validation loss:		0.578252
  validation accuracy:		80.22 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.563492
  validation loss:		0.596623
  validation accuracy:		79.67 %
Epoch 779 of 2000 took 0.100s
  training loss:		0.570098
  validation loss:		0.590610
  validation accuracy:		80.11 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.554383
  validation loss:		0.584711
  validation accuracy:		80.00 %
Epoch 781 of 2000 took 0.097s
  training loss:		0.571548
  validation loss:		0.595537
  validation accuracy:		79.78 %
Epoch 782 of 2000 took 0.103s
  training loss:		0.558647
  validation loss:		0.582549
  validation accuracy:		80.22 %
Epoch 783 of 2000 took 0.096s
  training loss:		0.567601
  validation loss:		0.575776
  validation accuracy:		80.43 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.570264
  validation loss:		0.586126
  validation accuracy:		80.00 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.581411
  validation loss:		0.585997
  validation accuracy:		80.00 %
Epoch 786 of 2000 took 0.098s
  training loss:		0.565041
  validation loss:		0.598135
  validation accuracy:		79.46 %
Epoch 787 of 2000 took 0.100s
  training loss:		0.574145
  validation loss:		0.582761
  validation accuracy:		80.33 %
Epoch 788 of 2000 took 0.096s
  training loss:		0.560276
  validation loss:		0.583811
  validation accuracy:		79.67 %
Epoch 789 of 2000 took 0.098s
  training loss:		0.564977
  validation loss:		0.585452
  validation accuracy:		80.33 %
Epoch 790 of 2000 took 0.101s
  training loss:		0.580313
  validation loss:		0.588453
  validation accuracy:		79.46 %
Epoch 791 of 2000 took 0.096s
  training loss:		0.567084
  validation loss:		0.605908
  validation accuracy:		79.78 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.563082
  validation loss:		0.595061
  validation accuracy:		79.57 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.564073
  validation loss:		0.586904
  validation accuracy:		80.22 %
Epoch 794 of 2000 took 0.101s
  training loss:		0.566938
  validation loss:		0.602837
  validation accuracy:		79.78 %
Epoch 795 of 2000 took 0.098s
  training loss:		0.565972
  validation loss:		0.582551
  validation accuracy:		79.89 %
Epoch 796 of 2000 took 0.099s
  training loss:		0.561774
  validation loss:		0.596977
  validation accuracy:		79.78 %
Epoch 797 of 2000 took 0.105s
  training loss:		0.579462
  validation loss:		0.580874
  validation accuracy:		80.22 %
Epoch 798 of 2000 took 0.101s
  training loss:		0.568122
  validation loss:		0.598286
  validation accuracy:		79.24 %
Epoch 799 of 2000 took 0.100s
  training loss:		0.558071
  validation loss:		0.579013
  validation accuracy:		80.43 %
Epoch 800 of 2000 took 0.100s
  training loss:		0.564191
  validation loss:		0.595152
  validation accuracy:		79.57 %
Epoch 801 of 2000 took 0.100s
  training loss:		0.558203
  validation loss:		0.582286
  validation accuracy:		79.67 %
Epoch 802 of 2000 took 0.103s
  training loss:		0.568509
  validation loss:		0.581080
  validation accuracy:		80.11 %
Epoch 803 of 2000 took 0.100s
  training loss:		0.565321
  validation loss:		0.577960
  validation accuracy:		80.00 %
Epoch 804 of 2000 took 0.100s
  training loss:		0.565782
  validation loss:		0.613280
  validation accuracy:		79.24 %
Epoch 805 of 2000 took 0.106s
  training loss:		0.564743
  validation loss:		0.583627
  validation accuracy:		79.78 %
Epoch 806 of 2000 took 0.099s
  training loss:		0.558501
  validation loss:		0.576226
  validation accuracy:		80.22 %
Epoch 807 of 2000 took 0.100s
  training loss:		0.561930
  validation loss:		0.599026
  validation accuracy:		79.46 %
Epoch 808 of 2000 took 0.099s
  training loss:		0.565073
  validation loss:		0.622900
  validation accuracy:		79.35 %
Epoch 809 of 2000 took 0.102s
  training loss:		0.560503
  validation loss:		0.593626
  validation accuracy:		80.22 %
Epoch 810 of 2000 took 0.103s
  training loss:		0.568239
  validation loss:		0.617144
  validation accuracy:		79.67 %
Epoch 811 of 2000 took 0.099s
  training loss:		0.575438
  validation loss:		0.612885
  validation accuracy:		79.67 %
Epoch 812 of 2000 took 0.102s
  training loss:		0.566730
  validation loss:		0.593636
  validation accuracy:		79.67 %
Epoch 813 of 2000 took 0.104s
  training loss:		0.563070
  validation loss:		0.571063
  validation accuracy:		80.22 %
Epoch 814 of 2000 took 0.099s
  training loss:		0.564912
  validation loss:		0.581749
  validation accuracy:		80.00 %
Epoch 815 of 2000 took 0.100s
  training loss:		0.554464
  validation loss:		0.581225
  validation accuracy:		80.22 %
Epoch 816 of 2000 took 0.099s
  training loss:		0.566693
  validation loss:		0.579566
  validation accuracy:		80.33 %
Epoch 817 of 2000 took 0.104s
  training loss:		0.568060
  validation loss:		0.582916
  validation accuracy:		80.22 %
Epoch 818 of 2000 took 0.101s
  training loss:		0.561552
  validation loss:		0.585184
  validation accuracy:		79.89 %
Epoch 819 of 2000 took 0.099s
  training loss:		0.555820
  validation loss:		0.601420
  validation accuracy:		80.11 %
Epoch 820 of 2000 took 0.105s
  training loss:		0.560738
  validation loss:		0.600670
  validation accuracy:		79.13 %
Epoch 821 of 2000 took 0.100s
  training loss:		0.555553
  validation loss:		0.598443
  validation accuracy:		80.00 %
Epoch 822 of 2000 took 0.100s
  training loss:		0.563390
  validation loss:		0.622118
  validation accuracy:		79.46 %
Epoch 823 of 2000 took 0.100s
  training loss:		0.565604
  validation loss:		0.594267
  validation accuracy:		79.35 %
Epoch 824 of 2000 took 0.100s
  training loss:		0.583182
  validation loss:		0.581571
  validation accuracy:		80.00 %
Epoch 825 of 2000 took 0.103s
  training loss:		0.567422
  validation loss:		0.578062
  validation accuracy:		79.89 %
Epoch 826 of 2000 took 0.100s
  training loss:		0.563550
  validation loss:		0.597217
  validation accuracy:		79.24 %
Epoch 827 of 2000 took 0.100s
  training loss:		0.561908
  validation loss:		0.576812
  validation accuracy:		79.67 %
Epoch 828 of 2000 took 0.106s
  training loss:		0.563017
  validation loss:		0.586941
  validation accuracy:		80.22 %
Epoch 829 of 2000 took 0.099s
  training loss:		0.558464
  validation loss:		0.581878
  validation accuracy:		80.33 %
Epoch 830 of 2000 took 0.100s
  training loss:		0.563338
  validation loss:		0.594781
  validation accuracy:		79.67 %
Epoch 831 of 2000 took 0.099s
  training loss:		0.567691
  validation loss:		0.605312
  validation accuracy:		79.89 %
Epoch 832 of 2000 took 0.101s
  training loss:		0.555521
  validation loss:		0.590960
  validation accuracy:		79.46 %
Epoch 833 of 2000 took 0.103s
  training loss:		0.557467
  validation loss:		0.573146
  validation accuracy:		80.11 %
Epoch 834 of 2000 took 0.099s
  training loss:		0.573588
  validation loss:		0.589174
  validation accuracy:		79.89 %
Epoch 835 of 2000 took 0.100s
  training loss:		0.554638
  validation loss:		0.575192
  validation accuracy:		80.11 %
Epoch 836 of 2000 took 0.101s
  training loss:		0.562539
  validation loss:		0.593888
  validation accuracy:		79.46 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.554690
  validation loss:		0.592238
  validation accuracy:		80.22 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.562687
  validation loss:		0.571845
  validation accuracy:		80.22 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.562577
  validation loss:		0.622827
  validation accuracy:		79.02 %
Epoch 840 of 2000 took 0.101s
  training loss:		0.563930
  validation loss:		0.583668
  validation accuracy:		80.22 %
Epoch 841 of 2000 took 0.098s
  training loss:		0.567063
  validation loss:		0.592038
  validation accuracy:		79.57 %
Epoch 842 of 2000 took 0.096s
  training loss:		0.559629
  validation loss:		0.586203
  validation accuracy:		79.89 %
Epoch 843 of 2000 took 0.102s
  training loss:		0.551762
  validation loss:		0.577187
  validation accuracy:		80.22 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.555531
  validation loss:		0.590831
  validation accuracy:		79.78 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.566026
  validation loss:		0.593846
  validation accuracy:		79.46 %
Epoch 846 of 2000 took 0.097s
  training loss:		0.587427
  validation loss:		0.573059
  validation accuracy:		80.43 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.574906
  validation loss:		0.587057
  validation accuracy:		80.00 %
Epoch 848 of 2000 took 0.100s
  training loss:		0.565247
  validation loss:		0.640330
  validation accuracy:		78.59 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.562337
  validation loss:		0.589538
  validation accuracy:		79.46 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.555056
  validation loss:		0.578383
  validation accuracy:		80.00 %
Epoch 851 of 2000 took 0.103s
  training loss:		0.562618
  validation loss:		0.602752
  validation accuracy:		79.24 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.569617
  validation loss:		0.577533
  validation accuracy:		80.33 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.556154
  validation loss:		0.575728
  validation accuracy:		80.00 %
Epoch 854 of 2000 took 0.096s
  training loss:		0.557183
  validation loss:		0.590447
  validation accuracy:		79.24 %
Epoch 855 of 2000 took 0.098s
  training loss:		0.558564
  validation loss:		0.583879
  validation accuracy:		80.33 %
Epoch 856 of 2000 took 0.100s
  training loss:		0.565904
  validation loss:		0.574001
  validation accuracy:		80.54 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.571607
  validation loss:		0.574807
  validation accuracy:		80.43 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.556713
  validation loss:		0.596524
  validation accuracy:		79.78 %
Epoch 859 of 2000 took 0.102s
  training loss:		0.563031
  validation loss:		0.597218
  validation accuracy:		78.91 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.559005
  validation loss:		0.577348
  validation accuracy:		80.22 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.556070
  validation loss:		0.589079
  validation accuracy:		80.00 %
Epoch 862 of 2000 took 0.096s
  training loss:		0.559392
  validation loss:		0.588073
  validation accuracy:		79.46 %
Epoch 863 of 2000 took 0.100s
  training loss:		0.565124
  validation loss:		0.575999
  validation accuracy:		80.22 %
Epoch 864 of 2000 took 0.098s
  training loss:		0.570441
  validation loss:		0.584293
  validation accuracy:		80.22 %
Epoch 865 of 2000 took 0.096s
  training loss:		0.561106
  validation loss:		0.583901
  validation accuracy:		80.00 %
Epoch 866 of 2000 took 0.100s
  training loss:		0.562633
  validation loss:		0.571862
  validation accuracy:		80.43 %
Epoch 867 of 2000 took 0.099s
  training loss:		0.563310
  validation loss:		0.619543
  validation accuracy:		78.91 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.566729
  validation loss:		0.585763
  validation accuracy:		80.33 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.562289
  validation loss:		0.582221
  validation accuracy:		79.78 %
Epoch 870 of 2000 took 0.097s
  training loss:		0.562254
  validation loss:		0.587727
  validation accuracy:		79.57 %
Epoch 871 of 2000 took 0.101s
  training loss:		0.568548
  validation loss:		0.574145
  validation accuracy:		80.22 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.577011
  validation loss:		0.590805
  validation accuracy:		79.89 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.556056
  validation loss:		0.570684
  validation accuracy:		80.54 %
Epoch 874 of 2000 took 0.103s
  training loss:		0.560460
  validation loss:		0.573595
  validation accuracy:		80.22 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.554504
  validation loss:		0.576214
  validation accuracy:		80.00 %
Epoch 876 of 2000 took 0.099s
  training loss:		0.555303
  validation loss:		0.591723
  validation accuracy:		79.67 %
Epoch 877 of 2000 took 0.099s
  training loss:		0.558642
  validation loss:		0.590720
  validation accuracy:		79.78 %
Epoch 878 of 2000 took 0.101s
  training loss:		0.556808
  validation loss:		0.576379
  validation accuracy:		80.22 %
Epoch 879 of 2000 took 0.107s
  training loss:		0.557486
  validation loss:		0.586793
  validation accuracy:		79.89 %
Epoch 880 of 2000 took 0.102s
  training loss:		0.564963
  validation loss:		0.570539
  validation accuracy:		80.33 %
Epoch 881 of 2000 took 0.104s
  training loss:		0.550857
  validation loss:		0.586847
  validation accuracy:		79.57 %
Epoch 882 of 2000 took 0.108s
  training loss:		0.562107
  validation loss:		0.591558
  validation accuracy:		79.35 %
Epoch 883 of 2000 took 0.102s
  training loss:		0.564201
  validation loss:		0.587559
  validation accuracy:		79.78 %
Epoch 884 of 2000 took 0.104s
  training loss:		0.572442
  validation loss:		0.589731
  validation accuracy:		79.78 %
Epoch 885 of 2000 took 0.102s
  training loss:		0.565606
  validation loss:		0.594711
  validation accuracy:		79.78 %
Epoch 886 of 2000 took 0.107s
  training loss:		0.557231
  validation loss:		0.568835
  validation accuracy:		81.09 %
Epoch 887 of 2000 took 0.104s
  training loss:		0.565728
  validation loss:		0.567910
  validation accuracy:		80.98 %
Epoch 888 of 2000 took 0.102s
  training loss:		0.580053
  validation loss:		0.568836
  validation accuracy:		80.54 %
Epoch 889 of 2000 took 0.107s
  training loss:		0.555687
  validation loss:		0.588851
  validation accuracy:		80.11 %
Epoch 890 of 2000 took 0.105s
  training loss:		0.551726
  validation loss:		0.560902
  validation accuracy:		80.76 %
Epoch 891 of 2000 took 0.103s
  training loss:		0.556385
  validation loss:		0.582303
  validation accuracy:		80.54 %
Epoch 892 of 2000 took 0.103s
  training loss:		0.558960
  validation loss:		0.585025
  validation accuracy:		79.78 %
Epoch 893 of 2000 took 0.103s
  training loss:		0.556500
  validation loss:		0.573587
  validation accuracy:		80.22 %
Epoch 894 of 2000 took 0.107s
  training loss:		0.550080
  validation loss:		0.578800
  validation accuracy:		80.11 %
Epoch 895 of 2000 took 0.104s
  training loss:		0.557782
  validation loss:		0.585817
  validation accuracy:		80.54 %
Epoch 896 of 2000 took 0.103s
  training loss:		0.562760
  validation loss:		0.604302
  validation accuracy:		79.35 %
Epoch 897 of 2000 took 0.109s
  training loss:		0.545473
  validation loss:		0.577774
  validation accuracy:		80.43 %
Epoch 898 of 2000 took 0.100s
  training loss:		0.561128
  validation loss:		0.568469
  validation accuracy:		80.33 %
Epoch 899 of 2000 took 0.100s
  training loss:		0.551228
  validation loss:		0.596516
  validation accuracy:		79.57 %
Epoch 900 of 2000 took 0.099s
  training loss:		0.558989
  validation loss:		0.578412
  validation accuracy:		81.20 %
Epoch 901 of 2000 took 0.101s
  training loss:		0.568584
  validation loss:		0.593235
  validation accuracy:		80.76 %
Epoch 902 of 2000 took 0.104s
  training loss:		0.568768
  validation loss:		0.580829
  validation accuracy:		80.11 %
Epoch 903 of 2000 took 0.099s
  training loss:		0.564998
  validation loss:		0.572607
  validation accuracy:		80.11 %
Epoch 904 of 2000 took 0.100s
  training loss:		0.556326
  validation loss:		0.580762
  validation accuracy:		80.00 %
Epoch 905 of 2000 took 0.105s
  training loss:		0.563245
  validation loss:		0.627740
  validation accuracy:		78.59 %
Epoch 906 of 2000 took 0.099s
  training loss:		0.559060
  validation loss:		0.576987
  validation accuracy:		80.00 %
Epoch 907 of 2000 took 0.100s
  training loss:		0.560770
  validation loss:		0.579404
  validation accuracy:		79.67 %
Epoch 908 of 2000 took 0.099s
  training loss:		0.582926
  validation loss:		0.570664
  validation accuracy:		80.33 %
Epoch 909 of 2000 took 0.103s
  training loss:		0.556855
  validation loss:		0.570365
  validation accuracy:		80.43 %
Epoch 910 of 2000 took 0.101s
  training loss:		0.555294
  validation loss:		0.573463
  validation accuracy:		80.43 %
Epoch 911 of 2000 took 0.099s
  training loss:		0.559037
  validation loss:		0.577440
  validation accuracy:		80.11 %
Epoch 912 of 2000 took 0.104s
  training loss:		0.556850
  validation loss:		0.570488
  validation accuracy:		80.54 %
Epoch 913 of 2000 took 0.101s
  training loss:		0.557075
  validation loss:		0.598525
  validation accuracy:		79.78 %
Epoch 914 of 2000 took 0.101s
  training loss:		0.553954
  validation loss:		0.571392
  validation accuracy:		80.33 %
Epoch 915 of 2000 took 0.103s
  training loss:		0.550208
  validation loss:		0.589979
  validation accuracy:		80.00 %
Epoch 916 of 2000 took 0.103s
  training loss:		0.545674
  validation loss:		0.575569
  validation accuracy:		80.87 %
Epoch 917 of 2000 took 0.106s
  training loss:		0.558562
  validation loss:		0.586299
  validation accuracy:		79.46 %
Epoch 918 of 2000 took 0.101s
  training loss:		0.557607
  validation loss:		0.568218
  validation accuracy:		80.65 %
Epoch 919 of 2000 took 0.100s
  training loss:		0.548815
  validation loss:		0.566629
  validation accuracy:		80.43 %
Epoch 920 of 2000 took 0.106s
  training loss:		0.561410
  validation loss:		0.621195
  validation accuracy:		78.15 %
Epoch 921 of 2000 took 0.099s
  training loss:		0.552654
  validation loss:		0.568747
  validation accuracy:		80.11 %
Epoch 922 of 2000 took 0.100s
  training loss:		0.550325
  validation loss:		0.595421
  validation accuracy:		79.24 %
Epoch 923 of 2000 took 0.099s
  training loss:		0.558317
  validation loss:		0.584783
  validation accuracy:		80.11 %
Epoch 924 of 2000 took 0.101s
  training loss:		0.559758
  validation loss:		0.575333
  validation accuracy:		80.33 %
Epoch 925 of 2000 took 0.103s
  training loss:		0.558765
  validation loss:		0.564803
  validation accuracy:		80.87 %
Epoch 926 of 2000 took 0.099s
  training loss:		0.561198
  validation loss:		0.567004
  validation accuracy:		80.54 %
Epoch 927 of 2000 took 0.101s
  training loss:		0.561928
  validation loss:		0.580025
  validation accuracy:		80.43 %
Epoch 928 of 2000 took 0.104s
  training loss:		0.558888
  validation loss:		0.569689
  validation accuracy:		80.87 %
Epoch 929 of 2000 took 0.099s
  training loss:		0.555332
  validation loss:		0.569860
  validation accuracy:		81.20 %
Epoch 930 of 2000 took 0.100s
  training loss:		0.548852
  validation loss:		0.582892
  validation accuracy:		79.13 %
Epoch 931 of 2000 took 0.099s
  training loss:		0.553630
  validation loss:		0.585318
  validation accuracy:		80.22 %
Epoch 932 of 2000 took 0.104s
  training loss:		0.554859
  validation loss:		0.564233
  validation accuracy:		81.20 %
Epoch 933 of 2000 took 0.101s
  training loss:		0.552812
  validation loss:		0.563552
  validation accuracy:		80.65 %
Epoch 934 of 2000 took 0.099s
  training loss:		0.558324
  validation loss:		0.574116
  validation accuracy:		80.11 %
Epoch 935 of 2000 took 0.105s
  training loss:		0.549509
  validation loss:		0.573403
  validation accuracy:		80.65 %
Epoch 936 of 2000 took 0.101s
  training loss:		0.567526
  validation loss:		0.559768
  validation accuracy:		81.20 %
Epoch 937 of 2000 took 0.100s
  training loss:		0.555619
  validation loss:		0.571545
  validation accuracy:		80.00 %
Epoch 938 of 2000 took 0.100s
  training loss:		0.553358
  validation loss:		0.567034
  validation accuracy:		80.98 %
Epoch 939 of 2000 took 0.100s
  training loss:		0.558565
  validation loss:		0.568950
  validation accuracy:		80.87 %
Epoch 940 of 2000 took 0.104s
  training loss:		0.559015
  validation loss:		0.570601
  validation accuracy:		80.22 %
Epoch 941 of 2000 took 0.100s
  training loss:		0.552580
  validation loss:		0.560631
  validation accuracy:		81.20 %
Epoch 942 of 2000 took 0.100s
  training loss:		0.555880
  validation loss:		0.585452
  validation accuracy:		79.89 %
Epoch 943 of 2000 took 0.106s
  training loss:		0.568332
  validation loss:		0.571238
  validation accuracy:		80.65 %
Epoch 944 of 2000 took 0.099s
  training loss:		0.550509
  validation loss:		0.576558
  validation accuracy:		80.76 %
Epoch 945 of 2000 took 0.100s
  training loss:		0.555226
  validation loss:		0.569106
  validation accuracy:		80.87 %
Epoch 946 of 2000 took 0.099s
  training loss:		0.556086
  validation loss:		0.615698
  validation accuracy:		78.37 %
Epoch 947 of 2000 took 0.101s
  training loss:		0.544171
  validation loss:		0.570365
  validation accuracy:		80.65 %
Epoch 948 of 2000 took 0.103s
  training loss:		0.550506
  validation loss:		0.571433
  validation accuracy:		80.54 %
Epoch 949 of 2000 took 0.099s
  training loss:		0.555870
  validation loss:		0.575425
  validation accuracy:		80.22 %
Epoch 950 of 2000 took 0.101s
  training loss:		0.553136
  validation loss:		0.583002
  validation accuracy:		80.00 %
Epoch 951 of 2000 took 0.104s
  training loss:		0.560410
  validation loss:		0.573116
  validation accuracy:		80.65 %
Epoch 952 of 2000 took 0.099s
  training loss:		0.557269
  validation loss:		0.570590
  validation accuracy:		80.54 %
Epoch 953 of 2000 took 0.100s
  training loss:		0.555131
  validation loss:		0.566485
  validation accuracy:		80.98 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.552927
  validation loss:		0.569467
  validation accuracy:		80.76 %
Epoch 955 of 2000 took 0.101s
  training loss:		0.558873
  validation loss:		0.572370
  validation accuracy:		80.65 %
Epoch 956 of 2000 took 0.098s
  training loss:		0.563418
  validation loss:		0.580991
  validation accuracy:		79.67 %
Epoch 957 of 2000 took 0.096s
  training loss:		0.558991
  validation loss:		0.559824
  validation accuracy:		81.20 %
Epoch 958 of 2000 took 0.102s
  training loss:		0.552722
  validation loss:		0.565930
  validation accuracy:		81.09 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.567306
  validation loss:		0.564092
  validation accuracy:		81.09 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.557839
  validation loss:		0.574393
  validation accuracy:		80.11 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.551939
  validation loss:		0.561957
  validation accuracy:		81.20 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.553178
  validation loss:		0.570449
  validation accuracy:		80.98 %
Epoch 963 of 2000 took 0.100s
  training loss:		0.557444
  validation loss:		0.573762
  validation accuracy:		80.54 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.556250
  validation loss:		0.559051
  validation accuracy:		81.20 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.574828
  validation loss:		0.569492
  validation accuracy:		80.33 %
Epoch 966 of 2000 took 0.103s
  training loss:		0.558137
  validation loss:		0.595973
  validation accuracy:		79.35 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.553982
  validation loss:		0.569677
  validation accuracy:		80.65 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.551911
  validation loss:		0.561587
  validation accuracy:		80.98 %
Epoch 969 of 2000 took 0.096s
  training loss:		0.548675
  validation loss:		0.558823
  validation accuracy:		81.52 %
Epoch 970 of 2000 took 0.098s
  training loss:		0.554994
  validation loss:		0.558926
  validation accuracy:		81.41 %
Epoch 971 of 2000 took 0.100s
  training loss:		0.543929
  validation loss:		0.575788
  validation accuracy:		79.78 %
Epoch 972 of 2000 took 0.096s
  training loss:		0.551176
  validation loss:		0.561325
  validation accuracy:		80.87 %
Epoch 973 of 2000 took 0.098s
  training loss:		0.553345
  validation loss:		0.557145
  validation accuracy:		81.63 %
Epoch 974 of 2000 took 0.101s
  training loss:		0.556131
  validation loss:		0.560363
  validation accuracy:		81.30 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.554546
  validation loss:		0.586428
  validation accuracy:		80.65 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.570141
  validation loss:		0.564228
  validation accuracy:		81.74 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.549392
  validation loss:		0.566622
  validation accuracy:		80.54 %
Epoch 978 of 2000 took 0.101s
  training loss:		0.560020
  validation loss:		0.555508
  validation accuracy:		81.52 %
Epoch 979 of 2000 took 0.098s
  training loss:		0.561941
  validation loss:		0.565765
  validation accuracy:		81.09 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.542887
  validation loss:		0.559957
  validation accuracy:		81.30 %
Epoch 981 of 2000 took 0.102s
  training loss:		0.553587
  validation loss:		0.590232
  validation accuracy:		79.57 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.552451
  validation loss:		0.567033
  validation accuracy:		80.54 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.546721
  validation loss:		0.576853
  validation accuracy:		80.00 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.551857
  validation loss:		0.569797
  validation accuracy:		81.96 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.550924
  validation loss:		0.561356
  validation accuracy:		80.65 %
Epoch 986 of 2000 took 0.100s
  training loss:		0.550989
  validation loss:		0.561911
  validation accuracy:		81.30 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.553657
  validation loss:		0.558631
  validation accuracy:		81.52 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.557932
  validation loss:		0.572653
  validation accuracy:		80.65 %
Epoch 989 of 2000 took 0.103s
  training loss:		0.556172
  validation loss:		0.576292
  validation accuracy:		80.00 %
Epoch 990 of 2000 took 0.096s
  training loss:		0.558738
  validation loss:		0.579820
  validation accuracy:		80.00 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.535600
  validation loss:		0.558980
  validation accuracy:		81.63 %
Epoch 992 of 2000 took 0.096s
  training loss:		0.561800
  validation loss:		0.564754
  validation accuracy:		80.98 %
Epoch 993 of 2000 took 0.098s
  training loss:		0.542704
  validation loss:		0.561275
  validation accuracy:		81.09 %
Epoch 994 of 2000 took 0.100s
  training loss:		0.553989
  validation loss:		0.570785
  validation accuracy:		80.87 %
Epoch 995 of 2000 took 0.096s
  training loss:		0.552453
  validation loss:		0.562371
  validation accuracy:		81.20 %
Epoch 996 of 2000 took 0.098s
  training loss:		0.553562
  validation loss:		0.592627
  validation accuracy:		79.67 %
Epoch 997 of 2000 took 0.101s
  training loss:		0.553969
  validation loss:		0.568359
  validation accuracy:		80.65 %
Epoch 998 of 2000 took 0.096s
  training loss:		0.554811
  validation loss:		0.560177
  validation accuracy:		81.63 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.552479
  validation loss:		0.562504
  validation accuracy:		81.09 %
Epoch 1000 of 2000 took 0.096s
  training loss:		0.569332
  validation loss:		0.582067
  validation accuracy:		80.00 %
Epoch 1001 of 2000 took 0.101s
  training loss:		0.556872
  validation loss:		0.568556
  validation accuracy:		80.76 %
Epoch 1002 of 2000 took 0.098s
  training loss:		0.556818
  validation loss:		0.579374
  validation accuracy:		79.89 %
Epoch 1003 of 2000 took 0.096s
  training loss:		0.550316
  validation loss:		0.581355
  validation accuracy:		80.00 %
Epoch 1004 of 2000 took 0.102s
  training loss:		0.549286
  validation loss:		0.579980
  validation accuracy:		79.89 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.556053
  validation loss:		0.567191
  validation accuracy:		81.09 %
Epoch 1006 of 2000 took 0.099s
  training loss:		0.559712
  validation loss:		0.559220
  validation accuracy:		81.85 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.554859
  validation loss:		0.571332
  validation accuracy:		80.98 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.553833
  validation loss:		0.570526
  validation accuracy:		80.22 %
Epoch 1009 of 2000 took 0.100s
  training loss:		0.558542
  validation loss:		0.570376
  validation accuracy:		80.22 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.555120
  validation loss:		0.566046
  validation accuracy:		81.52 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.550382
  validation loss:		0.601545
  validation accuracy:		79.57 %
Epoch 1012 of 2000 took 0.103s
  training loss:		0.554965
  validation loss:		0.584117
  validation accuracy:		80.11 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.556290
  validation loss:		0.578127
  validation accuracy:		80.00 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.560531
  validation loss:		0.560947
  validation accuracy:		80.76 %
Epoch 1015 of 2000 took 0.096s
  training loss:		0.567570
  validation loss:		0.587051
  validation accuracy:		79.89 %
Epoch 1016 of 2000 took 0.098s
  training loss:		0.552657
  validation loss:		0.560186
  validation accuracy:		81.20 %
Epoch 1017 of 2000 took 0.100s
  training loss:		0.552154
  validation loss:		0.581370
  validation accuracy:		80.00 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.555316
  validation loss:		0.569477
  validation accuracy:		80.22 %
Epoch 1019 of 2000 took 0.098s
  training loss:		0.566329
  validation loss:		0.615740
  validation accuracy:		79.46 %
Epoch 1020 of 2000 took 0.101s
  training loss:		0.565872
  validation loss:		0.606182
  validation accuracy:		79.24 %
Epoch 1021 of 2000 took 0.096s
  training loss:		0.560761
  validation loss:		0.583013
  validation accuracy:		79.78 %
Epoch 1022 of 2000 took 0.097s
  training loss:		0.554393
  validation loss:		0.561426
  validation accuracy:		80.98 %
Epoch 1023 of 2000 took 0.096s
  training loss:		0.564008
  validation loss:		0.589435
  validation accuracy:		80.00 %
Epoch 1024 of 2000 took 0.101s
  training loss:		0.552348
  validation loss:		0.556475
  validation accuracy:		81.41 %
Epoch 1025 of 2000 took 0.098s
  training loss:		0.541114
  validation loss:		0.566520
  validation accuracy:		80.87 %
Epoch 1026 of 2000 took 0.096s
  training loss:		0.546885
  validation loss:		0.579852
  validation accuracy:		80.33 %
Epoch 1027 of 2000 took 0.101s
  training loss:		0.559144
  validation loss:		0.564178
  validation accuracy:		80.98 %
Epoch 1028 of 2000 took 0.098s
  training loss:		0.563276
  validation loss:		0.576189
  validation accuracy:		80.33 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.549911
  validation loss:		0.568845
  validation accuracy:		80.76 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.550944
  validation loss:		0.555141
  validation accuracy:		81.63 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.559190
  validation loss:		0.565344
  validation accuracy:		80.54 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.552808
  validation loss:		0.557690
  validation accuracy:		81.63 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.548991
  validation loss:		0.557909
  validation accuracy:		81.63 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.558145
  validation loss:		0.613653
  validation accuracy:		79.67 %
Epoch 1035 of 2000 took 0.103s
  training loss:		0.557049
  validation loss:		0.556314
  validation accuracy:		81.96 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.546993
  validation loss:		0.566356
  validation accuracy:		80.43 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.552357
  validation loss:		0.576879
  validation accuracy:		80.00 %
Epoch 1038 of 2000 took 0.096s
  training loss:		0.550262
  validation loss:		0.553011
  validation accuracy:		82.07 %
Epoch 1039 of 2000 took 0.098s
  training loss:		0.545155
  validation loss:		0.598182
  validation accuracy:		79.57 %
Epoch 1040 of 2000 took 0.100s
  training loss:		0.549841
  validation loss:		0.563001
  validation accuracy:		80.98 %
Epoch 1041 of 2000 took 0.096s
  training loss:		0.550969
  validation loss:		0.584342
  validation accuracy:		80.11 %
Epoch 1042 of 2000 took 0.098s
  training loss:		0.554560
  validation loss:		0.603286
  validation accuracy:		80.22 %
Epoch 1043 of 2000 took 0.101s
  training loss:		0.561999
  validation loss:		0.584639
  validation accuracy:		79.78 %
Epoch 1044 of 2000 took 0.096s
  training loss:		0.557928
  validation loss:		0.571042
  validation accuracy:		80.43 %
Epoch 1045 of 2000 took 0.097s
  training loss:		0.548928
  validation loss:		0.556195
  validation accuracy:		81.41 %
Epoch 1046 of 2000 took 0.096s
  training loss:		0.553623
  validation loss:		0.563645
  validation accuracy:		80.98 %
Epoch 1047 of 2000 took 0.101s
  training loss:		0.551321
  validation loss:		0.590867
  validation accuracy:		80.33 %
Epoch 1048 of 2000 took 0.098s
  training loss:		0.545833
  validation loss:		0.603992
  validation accuracy:		80.33 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.554880
  validation loss:		0.557685
  validation accuracy:		81.63 %
Epoch 1050 of 2000 took 0.102s
  training loss:		0.548990
  validation loss:		0.582996
  validation accuracy:		80.22 %
Epoch 1051 of 2000 took 0.097s
  training loss:		0.549812
  validation loss:		0.554732
  validation accuracy:		80.98 %
Epoch 1052 of 2000 took 0.097s
  training loss:		0.541897
  validation loss:		0.590120
  validation accuracy:		80.11 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.554939
  validation loss:		0.566620
  validation accuracy:		81.09 %
Epoch 1054 of 2000 took 0.097s
  training loss:		0.559115
  validation loss:		0.574322
  validation accuracy:		80.43 %
Epoch 1055 of 2000 took 0.100s
  training loss:		0.552863
  validation loss:		0.574317
  validation accuracy:		80.87 %
Epoch 1056 of 2000 took 0.097s
  training loss:		0.555737
  validation loss:		0.558867
  validation accuracy:		81.30 %
Epoch 1057 of 2000 took 0.097s
  training loss:		0.557925
  validation loss:		0.580345
  validation accuracy:		80.87 %
Epoch 1058 of 2000 took 0.103s
  training loss:		0.538794
  validation loss:		0.557554
  validation accuracy:		81.41 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.553709
  validation loss:		0.555090
  validation accuracy:		81.96 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.568266
  validation loss:		0.561850
  validation accuracy:		81.20 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.553598
  validation loss:		0.566711
  validation accuracy:		81.20 %
Epoch 1062 of 2000 took 0.098s
  training loss:		0.554180
  validation loss:		0.577306
  validation accuracy:		81.09 %
Epoch 1063 of 2000 took 0.100s
  training loss:		0.557034
  validation loss:		0.581385
  validation accuracy:		80.98 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.561576
  validation loss:		0.576403
  validation accuracy:		80.43 %
Epoch 1065 of 2000 took 0.098s
  training loss:		0.558743
  validation loss:		0.559716
  validation accuracy:		81.09 %
Epoch 1066 of 2000 took 0.101s
  training loss:		0.557284
  validation loss:		0.563575
  validation accuracy:		81.30 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.554718
  validation loss:		0.559823
  validation accuracy:		81.30 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.562062
  validation loss:		0.561089
  validation accuracy:		81.09 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.553683
  validation loss:		0.556063
  validation accuracy:		81.52 %
Epoch 1070 of 2000 took 0.101s
  training loss:		0.547272
  validation loss:		0.559483
  validation accuracy:		81.20 %
Epoch 1071 of 2000 took 0.098s
  training loss:		0.543703
  validation loss:		0.561378
  validation accuracy:		81.09 %
Epoch 1072 of 2000 took 0.096s
  training loss:		0.547303
  validation loss:		0.575913
  validation accuracy:		80.11 %
Epoch 1073 of 2000 took 0.102s
  training loss:		0.565002
  validation loss:		0.557397
  validation accuracy:		81.85 %
Epoch 1074 of 2000 took 0.098s
  training loss:		0.556300
  validation loss:		0.577640
  validation accuracy:		80.22 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.551461
  validation loss:		0.571867
  validation accuracy:		80.43 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.553061
  validation loss:		0.560075
  validation accuracy:		81.20 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.553283
  validation loss:		0.568139
  validation accuracy:		80.65 %
Epoch 1078 of 2000 took 0.100s
  training loss:		0.545430
  validation loss:		0.570115
  validation accuracy:		80.33 %
Epoch 1079 of 2000 took 0.098s
  training loss:		0.558693
  validation loss:		0.554604
  validation accuracy:		81.52 %
Epoch 1080 of 2000 took 0.100s
  training loss:		0.557443
  validation loss:		0.564533
  validation accuracy:		81.09 %
Epoch 1081 of 2000 took 0.106s
  training loss:		0.549367
  validation loss:		0.562346
  validation accuracy:		80.98 %
Epoch 1082 of 2000 took 0.099s
  training loss:		0.561861
  validation loss:		0.595984
  validation accuracy:		80.11 %
Epoch 1083 of 2000 took 0.100s
  training loss:		0.548935
  validation loss:		0.559620
  validation accuracy:		81.09 %
Epoch 1084 of 2000 took 0.099s
  training loss:		0.557455
  validation loss:		0.581900
  validation accuracy:		80.33 %
Epoch 1085 of 2000 took 0.101s
  training loss:		0.561861
  validation loss:		0.567158
  validation accuracy:		80.76 %
Epoch 1086 of 2000 took 0.103s
  training loss:		0.561800
  validation loss:		0.566572
  validation accuracy:		81.20 %
Epoch 1087 of 2000 took 0.099s
  training loss:		0.558605
  validation loss:		0.579613
  validation accuracy:		80.54 %
Epoch 1088 of 2000 took 0.101s
  training loss:		0.552777
  validation loss:		0.607836
  validation accuracy:		79.46 %
Epoch 1089 of 2000 took 0.101s
  training loss:		0.549355
  validation loss:		0.561787
  validation accuracy:		81.09 %
Epoch 1090 of 2000 took 0.100s
  training loss:		0.545685
  validation loss:		0.558472
  validation accuracy:		81.96 %
Epoch 1091 of 2000 took 0.103s
  training loss:		0.552542
  validation loss:		0.556821
  validation accuracy:		81.30 %
Epoch 1092 of 2000 took 0.099s
  training loss:		0.560304
  validation loss:		0.568826
  validation accuracy:		80.76 %
Epoch 1093 of 2000 took 0.103s
  training loss:		0.553364
  validation loss:		0.573779
  validation accuracy:		81.09 %
Epoch 1094 of 2000 took 0.099s
  training loss:		0.553357
  validation loss:		0.569693
  validation accuracy:		80.87 %
Epoch 1095 of 2000 took 0.100s
  training loss:		0.555896
  validation loss:		0.560092
  validation accuracy:		80.98 %
Epoch 1096 of 2000 took 0.102s
  training loss:		0.557476
  validation loss:		0.559056
  validation accuracy:		81.09 %
Epoch 1097 of 2000 took 0.099s
  training loss:		0.562172
  validation loss:		0.556411
  validation accuracy:		81.30 %
Epoch 1098 of 2000 took 0.103s
  training loss:		0.555118
  validation loss:		0.564775
  validation accuracy:		80.76 %
Epoch 1099 of 2000 took 0.099s
  training loss:		0.556970
  validation loss:		0.553673
  validation accuracy:		82.17 %
Epoch 1100 of 2000 took 0.102s
  training loss:		0.550562
  validation loss:		0.569870
  validation accuracy:		80.65 %
Epoch 1101 of 2000 took 0.100s
  training loss:		0.549929
  validation loss:		0.563314
  validation accuracy:		80.87 %
Epoch 1102 of 2000 took 0.100s
  training loss:		0.544429
  validation loss:		0.607442
  validation accuracy:		79.89 %
Epoch 1103 of 2000 took 0.103s
  training loss:		0.547150
  validation loss:		0.597052
  validation accuracy:		80.00 %
Epoch 1104 of 2000 took 0.099s
  training loss:		0.553573
  validation loss:		0.555802
  validation accuracy:		81.52 %
Epoch 1105 of 2000 took 0.103s
  training loss:		0.544201
  validation loss:		0.568871
  validation accuracy:		81.09 %
Epoch 1106 of 2000 took 0.099s
  training loss:		0.549192
  validation loss:		0.561744
  validation accuracy:		81.52 %
Epoch 1107 of 2000 took 0.100s
  training loss:		0.554917
  validation loss:		0.561676
  validation accuracy:		82.07 %
Epoch 1108 of 2000 took 0.101s
  training loss:		0.551211
  validation loss:		0.555219
  validation accuracy:		82.07 %
Epoch 1109 of 2000 took 0.100s
  training loss:		0.546318
  validation loss:		0.567941
  validation accuracy:		81.09 %
Epoch 1110 of 2000 took 0.103s
  training loss:		0.561307
  validation loss:		0.558162
  validation accuracy:		81.30 %
Epoch 1111 of 2000 took 0.099s
  training loss:		0.558350
  validation loss:		0.553305
  validation accuracy:		81.63 %
Epoch 1112 of 2000 took 0.103s
  training loss:		0.551346
  validation loss:		0.572962
  validation accuracy:		80.76 %
Epoch 1113 of 2000 took 0.100s
  training loss:		0.549153
  validation loss:		0.577212
  validation accuracy:		80.76 %
Epoch 1114 of 2000 took 0.100s
  training loss:		0.545504
  validation loss:		0.566174
  validation accuracy:		81.09 %
Epoch 1115 of 2000 took 0.105s
  training loss:		0.553383
  validation loss:		0.564133
  validation accuracy:		81.20 %
Epoch 1116 of 2000 took 0.099s
  training loss:		0.552153
  validation loss:		0.581971
  validation accuracy:		80.54 %
Epoch 1117 of 2000 took 0.100s
  training loss:		0.553719
  validation loss:		0.564607
  validation accuracy:		81.20 %
Epoch 1118 of 2000 took 0.099s
  training loss:		0.544701
  validation loss:		0.560413
  validation accuracy:		81.41 %
Epoch 1119 of 2000 took 0.106s
  training loss:		0.547580
  validation loss:		0.572113
  validation accuracy:		80.87 %
Epoch 1120 of 2000 took 0.105s
  training loss:		0.548613
  validation loss:		0.562189
  validation accuracy:		81.41 %
Epoch 1121 of 2000 took 0.102s
  training loss:		0.551405
  validation loss:		0.593527
  validation accuracy:		80.22 %
Epoch 1122 of 2000 took 0.106s
  training loss:		0.542481
  validation loss:		0.553850
  validation accuracy:		81.52 %
Epoch 1123 of 2000 took 0.106s
  training loss:		0.549772
  validation loss:		0.559280
  validation accuracy:		81.20 %
Epoch 1124 of 2000 took 0.103s
  training loss:		0.552841
  validation loss:		0.599707
  validation accuracy:		79.78 %
Epoch 1125 of 2000 took 0.103s
  training loss:		0.553412
  validation loss:		0.566698
  validation accuracy:		81.41 %
Epoch 1126 of 2000 took 0.103s
  training loss:		0.549652
  validation loss:		0.556166
  validation accuracy:		81.85 %
Epoch 1127 of 2000 took 0.107s
  training loss:		0.556424
  validation loss:		0.563093
  validation accuracy:		81.20 %
Epoch 1128 of 2000 took 0.104s
  training loss:		0.552218
  validation loss:		0.555805
  validation accuracy:		81.85 %
Epoch 1129 of 2000 took 0.103s
  training loss:		0.555051
  validation loss:		0.579160
  validation accuracy:		80.65 %
Epoch 1130 of 2000 took 0.109s
  training loss:		0.553261
  validation loss:		0.558445
  validation accuracy:		81.20 %
Epoch 1131 of 2000 took 0.103s
  training loss:		0.550362
  validation loss:		0.564061
  validation accuracy:		80.87 %
Epoch 1132 of 2000 took 0.103s
  training loss:		0.549106
  validation loss:		0.585847
  validation accuracy:		80.33 %
Epoch 1133 of 2000 took 0.103s
  training loss:		0.554168
  validation loss:		0.563367
  validation accuracy:		81.09 %
Epoch 1134 of 2000 took 0.104s
  training loss:		0.560593
  validation loss:		0.562446
  validation accuracy:		81.52 %
Epoch 1135 of 2000 took 0.107s
  training loss:		0.541380
  validation loss:		0.555567
  validation accuracy:		81.52 %
Epoch 1136 of 2000 took 0.102s
  training loss:		0.556000
  validation loss:		0.563427
  validation accuracy:		81.63 %
Epoch 1137 of 2000 took 0.103s
  training loss:		0.558053
  validation loss:		0.558168
  validation accuracy:		81.30 %
Epoch 1138 of 2000 took 0.109s
  training loss:		0.558008
  validation loss:		0.580623
  validation accuracy:		80.54 %
Epoch 1139 of 2000 took 0.102s
  training loss:		0.558419
  validation loss:		0.571571
  validation accuracy:		80.76 %
Epoch 1140 of 2000 took 0.104s
  training loss:		0.551505
  validation loss:		0.562439
  validation accuracy:		80.98 %
Epoch 1141 of 2000 took 0.102s
  training loss:		0.550328
  validation loss:		0.555992
  validation accuracy:		81.41 %
Epoch 1142 of 2000 took 0.107s
  training loss:		0.555271
  validation loss:		0.555238
  validation accuracy:		81.52 %
Epoch 1143 of 2000 took 0.104s
  training loss:		0.557706
  validation loss:		0.630328
  validation accuracy:		79.24 %
Epoch 1144 of 2000 took 0.102s
  training loss:		0.551413
  validation loss:		0.575631
  validation accuracy:		80.87 %
Epoch 1145 of 2000 took 0.107s
  training loss:		0.558919
  validation loss:		0.564847
  validation accuracy:		81.09 %
Epoch 1146 of 2000 took 0.104s
  training loss:		0.554710
  validation loss:		0.581851
  validation accuracy:		81.20 %
Epoch 1147 of 2000 took 0.103s
  training loss:		0.558105
  validation loss:		0.577228
  validation accuracy:		80.33 %
Epoch 1148 of 2000 took 0.103s
  training loss:		0.552635
  validation loss:		0.565744
  validation accuracy:		81.20 %
Epoch 1149 of 2000 took 0.103s
  training loss:		0.549383
  validation loss:		0.558729
  validation accuracy:		81.41 %
Epoch 1150 of 2000 took 0.107s
  training loss:		0.549340
  validation loss:		0.556778
  validation accuracy:		81.63 %
Epoch 1151 of 2000 took 0.104s
  training loss:		0.555664
  validation loss:		0.562504
  validation accuracy:		81.09 %
Epoch 1152 of 2000 took 0.103s
  training loss:		0.553201
  validation loss:		0.579897
  validation accuracy:		80.65 %
Epoch 1153 of 2000 took 0.109s
  training loss:		0.540928
  validation loss:		0.559884
  validation accuracy:		81.09 %
Epoch 1154 of 2000 took 0.103s
  training loss:		0.548379
  validation loss:		0.576249
  validation accuracy:		80.98 %
Epoch 1155 of 2000 took 0.104s
  training loss:		0.546282
  validation loss:		0.558245
  validation accuracy:		81.41 %
Epoch 1156 of 2000 took 0.102s
  training loss:		0.545918
  validation loss:		0.569275
  validation accuracy:		80.76 %
Epoch 1157 of 2000 took 0.102s
  training loss:		0.559293
  validation loss:		0.570657
  validation accuracy:		81.09 %
Epoch 1158 of 2000 took 0.100s
  training loss:		0.553324
  validation loss:		0.590845
  validation accuracy:		80.22 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.557577
  validation loss:		0.565678
  validation accuracy:		81.52 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.554078
  validation loss:		0.557741
  validation accuracy:		81.85 %
Epoch 1161 of 2000 took 0.102s
  training loss:		0.549971
  validation loss:		0.556342
  validation accuracy:		81.20 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.547233
  validation loss:		0.579235
  validation accuracy:		81.30 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.559549
  validation loss:		0.569467
  validation accuracy:		81.20 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.551069
  validation loss:		0.553986
  validation accuracy:		81.30 %
Epoch 1165 of 2000 took 0.101s
  training loss:		0.543759
  validation loss:		0.566929
  validation accuracy:		81.20 %
Epoch 1166 of 2000 took 0.098s
  training loss:		0.551130
  validation loss:		0.562777
  validation accuracy:		81.52 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.553377
  validation loss:		0.565791
  validation accuracy:		81.74 %
Epoch 1168 of 2000 took 0.101s
  training loss:		0.548551
  validation loss:		0.556135
  validation accuracy:		81.85 %
Epoch 1169 of 2000 took 0.098s
  training loss:		0.556015
  validation loss:		0.567347
  validation accuracy:		80.76 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.550602
  validation loss:		0.559200
  validation accuracy:		81.52 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.551930
  validation loss:		0.566155
  validation accuracy:		80.98 %
Epoch 1172 of 2000 took 0.097s
  training loss:		0.549809
  validation loss:		0.557056
  validation accuracy:		81.41 %
Epoch 1173 of 2000 took 0.100s
  training loss:		0.549789
  validation loss:		0.559798
  validation accuracy:		80.98 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.548504
  validation loss:		0.558411
  validation accuracy:		81.52 %
Epoch 1175 of 2000 took 0.097s
  training loss:		0.546952
  validation loss:		0.562418
  validation accuracy:		81.30 %
Epoch 1176 of 2000 took 0.103s
  training loss:		0.550070
  validation loss:		0.563158
  validation accuracy:		80.98 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.549936
  validation loss:		0.569294
  validation accuracy:		81.09 %
Epoch 1178 of 2000 took 0.097s
  training loss:		0.548221
  validation loss:		0.581657
  validation accuracy:		80.33 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.551485
  validation loss:		0.586858
  validation accuracy:		80.33 %
Epoch 1180 of 2000 took 0.098s
  training loss:		0.541570
  validation loss:		0.555616
  validation accuracy:		81.52 %
Epoch 1181 of 2000 took 0.100s
  training loss:		0.558160
  validation loss:		0.564056
  validation accuracy:		81.52 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.557904
  validation loss:		0.560683
  validation accuracy:		80.98 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.549914
  validation loss:		0.554197
  validation accuracy:		81.52 %
Epoch 1184 of 2000 took 0.102s
  training loss:		0.564430
  validation loss:		0.574751
  validation accuracy:		81.30 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.550468
  validation loss:		0.556760
  validation accuracy:		81.20 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.541352
  validation loss:		0.564905
  validation accuracy:		81.20 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.549832
  validation loss:		0.555882
  validation accuracy:		81.41 %
Epoch 1188 of 2000 took 0.100s
  training loss:		0.554436
  validation loss:		0.593321
  validation accuracy:		80.43 %
Epoch 1189 of 2000 took 0.098s
  training loss:		0.560103
  validation loss:		0.559859
  validation accuracy:		81.41 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.548466
  validation loss:		0.566046
  validation accuracy:		80.98 %
Epoch 1191 of 2000 took 0.101s
  training loss:		0.554776
  validation loss:		0.573466
  validation accuracy:		81.09 %
Epoch 1192 of 2000 took 0.099s
  training loss:		0.549787
  validation loss:		0.593876
  validation accuracy:		80.87 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.548501
  validation loss:		0.557819
  validation accuracy:		81.63 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.543018
  validation loss:		0.554649
  validation accuracy:		81.41 %
Epoch 1195 of 2000 took 0.097s
  training loss:		0.544542
  validation loss:		0.570690
  validation accuracy:		80.76 %
Epoch 1196 of 2000 took 0.101s
  training loss:		0.557721
  validation loss:		0.577817
  validation accuracy:		81.41 %
Epoch 1197 of 2000 took 0.097s
  training loss:		0.544246
  validation loss:		0.556355
  validation accuracy:		81.74 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.545406
  validation loss:		0.559112
  validation accuracy:		80.98 %
Epoch 1199 of 2000 took 0.103s
  training loss:		0.549931
  validation loss:		0.583179
  validation accuracy:		81.09 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.548155
  validation loss:		0.551812
  validation accuracy:		81.63 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.549306
  validation loss:		0.568297
  validation accuracy:		81.09 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.554051
  validation loss:		0.570211
  validation accuracy:		80.87 %
Epoch 1203 of 2000 took 0.098s
  training loss:		0.559489
  validation loss:		0.558008
  validation accuracy:		81.41 %
Epoch 1204 of 2000 took 0.101s
  training loss:		0.544729
  validation loss:		0.561878
  validation accuracy:		81.30 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.549205
  validation loss:		0.560885
  validation accuracy:		81.52 %
Epoch 1206 of 2000 took 0.097s
  training loss:		0.549657
  validation loss:		0.564009
  validation accuracy:		81.52 %
Epoch 1207 of 2000 took 0.102s
  training loss:		0.551378
  validation loss:		0.579037
  validation accuracy:		81.20 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.544385
  validation loss:		0.557419
  validation accuracy:		81.96 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.560382
  validation loss:		0.572851
  validation accuracy:		81.09 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.542895
  validation loss:		0.578803
  validation accuracy:		81.20 %
Epoch 1211 of 2000 took 0.099s
  training loss:		0.552876
  validation loss:		0.571860
  validation accuracy:		81.30 %
Epoch 1212 of 2000 took 0.099s
  training loss:		0.537993
  validation loss:		0.557004
  validation accuracy:		81.41 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.548582
  validation loss:		0.560013
  validation accuracy:		81.74 %
Epoch 1214 of 2000 took 0.099s
  training loss:		0.555300
  validation loss:		0.567160
  validation accuracy:		80.98 %
Epoch 1215 of 2000 took 0.100s
  training loss:		0.549145
  validation loss:		0.557006
  validation accuracy:		81.41 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.551354
  validation loss:		0.553500
  validation accuracy:		81.74 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.553376
  validation loss:		0.552588
  validation accuracy:		81.96 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.543976
  validation loss:		0.563395
  validation accuracy:		81.09 %
Epoch 1219 of 2000 took 0.101s
  training loss:		0.551233
  validation loss:		0.581218
  validation accuracy:		81.30 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.548654
  validation loss:		0.553355
  validation accuracy:		81.63 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.559995
  validation loss:		0.551138
  validation accuracy:		82.28 %
Epoch 1222 of 2000 took 0.102s
  training loss:		0.551567
  validation loss:		0.556817
  validation accuracy:		82.07 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.547140
  validation loss:		0.562412
  validation accuracy:		81.52 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.552858
  validation loss:		0.553095
  validation accuracy:		81.85 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.551750
  validation loss:		0.574968
  validation accuracy:		80.54 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.548581
  validation loss:		0.557378
  validation accuracy:		81.09 %
Epoch 1227 of 2000 took 0.100s
  training loss:		0.556728
  validation loss:		0.558437
  validation accuracy:		81.74 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.558092
  validation loss:		0.558474
  validation accuracy:		81.63 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.564229
  validation loss:		0.597937
  validation accuracy:		80.22 %
Epoch 1230 of 2000 took 0.103s
  training loss:		0.553683
  validation loss:		0.554954
  validation accuracy:		81.41 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.548667
  validation loss:		0.582247
  validation accuracy:		80.87 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.556259
  validation loss:		0.590955
  validation accuracy:		80.54 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.557488
  validation loss:		0.599778
  validation accuracy:		80.54 %
Epoch 1234 of 2000 took 0.099s
  training loss:		0.546759
  validation loss:		0.564026
  validation accuracy:		81.30 %
Epoch 1235 of 2000 took 0.099s
  training loss:		0.553357
  validation loss:		0.570864
  validation accuracy:		80.76 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.549204
  validation loss:		0.570599
  validation accuracy:		81.52 %
Epoch 1237 of 2000 took 0.099s
  training loss:		0.555466
  validation loss:		0.559010
  validation accuracy:		81.74 %
Epoch 1238 of 2000 took 0.100s
  training loss:		0.547799
  validation loss:		0.560044
  validation accuracy:		81.85 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.552192
  validation loss:		0.562155
  validation accuracy:		81.20 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.553903
  validation loss:		0.553829
  validation accuracy:		81.41 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.545084
  validation loss:		0.594806
  validation accuracy:		80.54 %
Epoch 1242 of 2000 took 0.101s
  training loss:		0.556406
  validation loss:		0.561799
  validation accuracy:		81.85 %
Epoch 1243 of 2000 took 0.098s
  training loss:		0.554386
  validation loss:		0.562909
  validation accuracy:		81.41 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.550338
  validation loss:		0.588654
  validation accuracy:		80.65 %
Epoch 1245 of 2000 took 0.102s
  training loss:		0.557347
  validation loss:		0.555295
  validation accuracy:		81.41 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.545446
  validation loss:		0.553387
  validation accuracy:		82.07 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.563069
  validation loss:		0.561696
  validation accuracy:		81.09 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.551017
  validation loss:		0.575587
  validation accuracy:		81.63 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.549513
  validation loss:		0.588046
  validation accuracy:		80.43 %
Epoch 1250 of 2000 took 0.100s
  training loss:		0.545707
  validation loss:		0.560904
  validation accuracy:		81.63 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.554420
  validation loss:		0.563617
  validation accuracy:		81.41 %
Epoch 1252 of 2000 took 0.097s
  training loss:		0.549696
  validation loss:		0.590702
  validation accuracy:		80.98 %
Epoch 1253 of 2000 took 0.102s
  training loss:		0.560349
  validation loss:		0.571573
  validation accuracy:		81.85 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.551546
  validation loss:		0.577526
  validation accuracy:		80.76 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.548944
  validation loss:		0.565542
  validation accuracy:		81.09 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.552237
  validation loss:		0.553848
  validation accuracy:		81.85 %
Epoch 1257 of 2000 took 0.098s
  training loss:		0.562284
  validation loss:		0.560554
  validation accuracy:		81.41 %
Epoch 1258 of 2000 took 0.100s
  training loss:		0.555334
  validation loss:		0.552239
  validation accuracy:		81.63 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.553981
  validation loss:		0.597413
  validation accuracy:		80.00 %
Epoch 1260 of 2000 took 0.098s
  training loss:		0.545980
  validation loss:		0.568610
  validation accuracy:		80.87 %
Epoch 1261 of 2000 took 0.101s
  training loss:		0.543621
  validation loss:		0.550752
  validation accuracy:		81.96 %
Epoch 1262 of 2000 took 0.096s
  training loss:		0.557221
  validation loss:		0.564932
  validation accuracy:		81.85 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.547314
  validation loss:		0.569971
  validation accuracy:		81.52 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.556260
  validation loss:		0.564503
  validation accuracy:		81.30 %
Epoch 1265 of 2000 took 0.101s
  training loss:		0.554033
  validation loss:		0.581779
  validation accuracy:		81.20 %
Epoch 1266 of 2000 took 0.098s
  training loss:		0.537669
  validation loss:		0.554710
  validation accuracy:		81.74 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.554049
  validation loss:		0.555026
  validation accuracy:		81.74 %
Epoch 1268 of 2000 took 0.101s
  training loss:		0.556613
  validation loss:		0.564148
  validation accuracy:		81.30 %
Epoch 1269 of 2000 took 0.098s
  training loss:		0.542257
  validation loss:		0.566842
  validation accuracy:		81.52 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.550655
  validation loss:		0.552724
  validation accuracy:		81.52 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.561987
  validation loss:		0.556304
  validation accuracy:		81.30 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.552030
  validation loss:		0.554333
  validation accuracy:		82.07 %
Epoch 1273 of 2000 took 0.101s
  training loss:		0.548480
  validation loss:		0.554425
  validation accuracy:		81.52 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.561269
  validation loss:		0.577741
  validation accuracy:		81.52 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.548935
  validation loss:		0.575158
  validation accuracy:		81.41 %
Epoch 1276 of 2000 took 0.103s
  training loss:		0.548425
  validation loss:		0.559085
  validation accuracy:		80.98 %
Epoch 1277 of 2000 took 0.100s
  training loss:		0.553623
  validation loss:		0.568519
  validation accuracy:		81.85 %
Epoch 1278 of 2000 took 0.100s
  training loss:		0.547067
  validation loss:		0.574745
  validation accuracy:		80.98 %
Epoch 1279 of 2000 took 0.099s
  training loss:		0.551948
  validation loss:		0.565815
  validation accuracy:		81.20 %
Epoch 1280 of 2000 took 0.101s
  training loss:		0.544916
  validation loss:		0.556004
  validation accuracy:		81.52 %
Epoch 1281 of 2000 took 0.104s
  training loss:		0.541054
  validation loss:		0.561014
  validation accuracy:		81.41 %
Epoch 1282 of 2000 took 0.099s
  training loss:		0.548180
  validation loss:		0.552977
  validation accuracy:		81.52 %
Epoch 1283 of 2000 took 0.100s
  training loss:		0.552970
  validation loss:		0.558138
  validation accuracy:		81.63 %
Epoch 1284 of 2000 took 0.105s
  training loss:		0.549853
  validation loss:		0.578701
  validation accuracy:		81.20 %
Epoch 1285 of 2000 took 0.099s
  training loss:		0.548748
  validation loss:		0.594616
  validation accuracy:		80.76 %
Epoch 1286 of 2000 took 0.100s
  training loss:		0.555369
  validation loss:		0.556066
  validation accuracy:		81.52 %
Epoch 1287 of 2000 took 0.099s
  training loss:		0.550846
  validation loss:		0.556340
  validation accuracy:		81.85 %
Epoch 1288 of 2000 took 0.103s
  training loss:		0.552081
  validation loss:		0.576367
  validation accuracy:		81.63 %
Epoch 1289 of 2000 took 0.101s
  training loss:		0.545885
  validation loss:		0.551679
  validation accuracy:		81.63 %
Epoch 1290 of 2000 took 0.099s
  training loss:		0.552752
  validation loss:		0.585439
  validation accuracy:		80.65 %
Epoch 1291 of 2000 took 0.103s
  training loss:		0.553453
  validation loss:		0.592350
  validation accuracy:		80.65 %
Epoch 1292 of 2000 took 0.102s
  training loss:		0.553281
  validation loss:		0.561343
  validation accuracy:		81.63 %
Epoch 1293 of 2000 took 0.100s
  training loss:		0.553872
  validation loss:		0.559081
  validation accuracy:		81.96 %
Epoch 1294 of 2000 took 0.100s
  training loss:		0.550950
  validation loss:		0.567208
  validation accuracy:		81.20 %
Epoch 1295 of 2000 took 0.100s
  training loss:		0.564501
  validation loss:		0.566477
  validation accuracy:		81.30 %
Epoch 1296 of 2000 took 0.104s
  training loss:		0.547428
  validation loss:		0.560942
  validation accuracy:		80.98 %
Epoch 1297 of 2000 took 0.101s
  training loss:		0.543593
  validation loss:		0.557627
  validation accuracy:		81.30 %
Epoch 1298 of 2000 took 0.100s
  training loss:		0.549803
  validation loss:		0.580380
  validation accuracy:		81.41 %
Epoch 1299 of 2000 took 0.106s
  training loss:		0.555131
  validation loss:		0.571226
  validation accuracy:		81.30 %
Epoch 1300 of 2000 took 0.100s
  training loss:		0.547497
  validation loss:		0.568436
  validation accuracy:		81.63 %
Epoch 1301 of 2000 took 0.100s
  training loss:		0.556840
  validation loss:		0.583316
  validation accuracy:		80.76 %
Epoch 1302 of 2000 took 0.099s
  training loss:		0.562337
  validation loss:		0.556662
  validation accuracy:		81.85 %
Epoch 1303 of 2000 took 0.103s
  training loss:		0.554666
  validation loss:		0.576915
  validation accuracy:		81.52 %
Epoch 1304 of 2000 took 0.104s
  training loss:		0.560932
  validation loss:		0.568187
  validation accuracy:		81.30 %
Epoch 1305 of 2000 took 0.099s
  training loss:		0.550338
  validation loss:		0.556204
  validation accuracy:		81.09 %
Epoch 1306 of 2000 took 0.100s
  training loss:		0.550639
  validation loss:		0.551393
  validation accuracy:		81.85 %
Epoch 1307 of 2000 took 0.105s
  training loss:		0.552551
  validation loss:		0.557004
  validation accuracy:		81.20 %
Epoch 1308 of 2000 took 0.099s
  training loss:		0.549625
  validation loss:		0.582103
  validation accuracy:		81.20 %
Epoch 1309 of 2000 took 0.100s
  training loss:		0.548400
  validation loss:		0.569062
  validation accuracy:		81.52 %
Epoch 1310 of 2000 took 0.099s
  training loss:		0.559219
  validation loss:		0.554485
  validation accuracy:		81.30 %
Epoch 1311 of 2000 took 0.103s
  training loss:		0.543856
  validation loss:		0.553965
  validation accuracy:		81.74 %
Epoch 1312 of 2000 took 0.101s
  training loss:		0.542763
  validation loss:		0.556170
  validation accuracy:		81.52 %
Epoch 1313 of 2000 took 0.099s
  training loss:		0.556717
  validation loss:		0.552510
  validation accuracy:		81.41 %
Epoch 1314 of 2000 took 0.103s
  training loss:		0.550386
  validation loss:		0.556284
  validation accuracy:		81.63 %
Epoch 1315 of 2000 took 0.102s
  training loss:		0.553962
  validation loss:		0.556408
  validation accuracy:		81.30 %
Epoch 1316 of 2000 took 0.098s
  training loss:		0.539983
  validation loss:		0.550612
  validation accuracy:		81.74 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.551489
  validation loss:		0.567023
  validation accuracy:		81.63 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.556993
  validation loss:		0.578195
  validation accuracy:		81.09 %
Epoch 1319 of 2000 took 0.101s
  training loss:		0.555765
  validation loss:		0.554555
  validation accuracy:		81.30 %
Epoch 1320 of 2000 took 0.098s
  training loss:		0.551751
  validation loss:		0.555519
  validation accuracy:		80.87 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.547470
  validation loss:		0.566318
  validation accuracy:		81.30 %
Epoch 1322 of 2000 took 0.102s
  training loss:		0.556870
  validation loss:		0.577958
  validation accuracy:		81.41 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.537698
  validation loss:		0.580638
  validation accuracy:		81.09 %
Epoch 1324 of 2000 took 0.097s
  training loss:		0.552919
  validation loss:		0.590505
  validation accuracy:		81.20 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.546295
  validation loss:		0.563066
  validation accuracy:		81.52 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.543200
  validation loss:		0.560022
  validation accuracy:		81.30 %
Epoch 1327 of 2000 took 0.101s
  training loss:		0.546562
  validation loss:		0.570629
  validation accuracy:		81.74 %
Epoch 1328 of 2000 took 0.096s
  training loss:		0.544736
  validation loss:		0.555135
  validation accuracy:		81.63 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.544032
  validation loss:		0.555964
  validation accuracy:		81.30 %
Epoch 1330 of 2000 took 0.102s
  training loss:		0.550272
  validation loss:		0.572485
  validation accuracy:		81.74 %
Epoch 1331 of 2000 took 0.096s
  training loss:		0.552568
  validation loss:		0.576718
  validation accuracy:		80.54 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.553199
  validation loss:		0.611541
  validation accuracy:		80.54 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.558633
  validation loss:		0.564386
  validation accuracy:		81.41 %
Epoch 1334 of 2000 took 0.100s
  training loss:		0.555049
  validation loss:		0.564865
  validation accuracy:		81.41 %
Epoch 1335 of 2000 took 0.098s
  training loss:		0.545998
  validation loss:		0.553872
  validation accuracy:		81.96 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.556280
  validation loss:		0.553046
  validation accuracy:		81.41 %
Epoch 1337 of 2000 took 0.099s
  training loss:		0.554662
  validation loss:		0.560840
  validation accuracy:		81.09 %
Epoch 1338 of 2000 took 0.099s
  training loss:		0.552886
  validation loss:		0.561271
  validation accuracy:		81.52 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.549851
  validation loss:		0.623637
  validation accuracy:		79.78 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.557259
  validation loss:		0.554596
  validation accuracy:		81.41 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.554004
  validation loss:		0.606768
  validation accuracy:		80.43 %
Epoch 1342 of 2000 took 0.101s
  training loss:		0.560891
  validation loss:		0.553211
  validation accuracy:		81.52 %
Epoch 1343 of 2000 took 0.098s
  training loss:		0.552885
  validation loss:		0.557773
  validation accuracy:		81.52 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.541197
  validation loss:		0.587939
  validation accuracy:		80.87 %
Epoch 1345 of 2000 took 0.102s
  training loss:		0.549383
  validation loss:		0.562086
  validation accuracy:		81.30 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.549004
  validation loss:		0.585424
  validation accuracy:		80.54 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.555224
  validation loss:		0.580818
  validation accuracy:		81.52 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.547002
  validation loss:		0.596865
  validation accuracy:		80.87 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.548588
  validation loss:		0.560597
  validation accuracy:		81.20 %
Epoch 1350 of 2000 took 0.101s
  training loss:		0.547532
  validation loss:		0.576479
  validation accuracy:		80.87 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.551499
  validation loss:		0.578446
  validation accuracy:		81.41 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.545563
  validation loss:		0.561576
  validation accuracy:		81.30 %
Epoch 1353 of 2000 took 0.102s
  training loss:		0.542255
  validation loss:		0.586176
  validation accuracy:		81.09 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.552971
  validation loss:		0.555523
  validation accuracy:		81.30 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.553318
  validation loss:		0.566915
  validation accuracy:		81.30 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.547012
  validation loss:		0.566083
  validation accuracy:		81.09 %
Epoch 1357 of 2000 took 0.099s
  training loss:		0.549375
  validation loss:		0.556386
  validation accuracy:		81.41 %
Epoch 1358 of 2000 took 0.099s
  training loss:		0.560000
  validation loss:		0.559177
  validation accuracy:		81.09 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.543428
  validation loss:		0.575815
  validation accuracy:		81.52 %
Epoch 1360 of 2000 took 0.099s
  training loss:		0.551075
  validation loss:		0.566076
  validation accuracy:		81.41 %
Epoch 1361 of 2000 took 0.100s
  training loss:		0.550308
  validation loss:		0.557145
  validation accuracy:		81.63 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.553849
  validation loss:		0.560581
  validation accuracy:		81.85 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.554216
  validation loss:		0.572084
  validation accuracy:		81.41 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.547732
  validation loss:		0.553508
  validation accuracy:		81.74 %
Epoch 1365 of 2000 took 0.101s
  training loss:		0.547400
  validation loss:		0.584258
  validation accuracy:		80.54 %
Epoch 1366 of 2000 took 0.098s
  training loss:		0.552429
  validation loss:		0.560659
  validation accuracy:		80.87 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.554500
  validation loss:		0.571585
  validation accuracy:		81.09 %
Epoch 1368 of 2000 took 0.102s
  training loss:		0.550746
  validation loss:		0.568680
  validation accuracy:		81.30 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.550343
  validation loss:		0.549078
  validation accuracy:		81.85 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.544939
  validation loss:		0.568479
  validation accuracy:		81.09 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.552790
  validation loss:		0.557242
  validation accuracy:		81.41 %
Epoch 1372 of 2000 took 0.098s
  training loss:		0.546841
  validation loss:		0.568985
  validation accuracy:		81.30 %
Epoch 1373 of 2000 took 0.100s
  training loss:		0.555328
  validation loss:		0.564003
  validation accuracy:		81.52 %
Epoch 1374 of 2000 took 0.122s
  training loss:		0.550483
  validation loss:		0.559825
  validation accuracy:		81.30 %
Epoch 1375 of 2000 took 0.118s
  training loss:		0.554048
  validation loss:		0.559368
  validation accuracy:		81.63 %
Epoch 1376 of 2000 took 0.103s
  training loss:		0.555886
  validation loss:		0.567533
  validation accuracy:		81.41 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.555416
  validation loss:		0.552000
  validation accuracy:		81.85 %
Epoch 1378 of 2000 took 0.098s
  training loss:		0.554467
  validation loss:		0.575622
  validation accuracy:		81.52 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.544492
  validation loss:		0.557562
  validation accuracy:		81.52 %
Epoch 1380 of 2000 took 0.099s
  training loss:		0.547264
  validation loss:		0.584459
  validation accuracy:		81.52 %
Epoch 1381 of 2000 took 0.100s
  training loss:		0.548853
  validation loss:		0.564874
  validation accuracy:		81.30 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.559062
  validation loss:		0.550641
  validation accuracy:		81.52 %
Epoch 1383 of 2000 took 0.098s
  training loss:		0.551638
  validation loss:		0.556099
  validation accuracy:		80.98 %
Epoch 1384 of 2000 took 0.101s
  training loss:		0.545879
  validation loss:		0.584036
  validation accuracy:		81.74 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.542787
  validation loss:		0.570847
  validation accuracy:		81.52 %
Epoch 1386 of 2000 took 0.097s
  training loss:		0.553583
  validation loss:		0.573627
  validation accuracy:		81.85 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.548653
  validation loss:		0.562411
  validation accuracy:		81.41 %
Epoch 1388 of 2000 took 0.101s
  training loss:		0.545527
  validation loss:		0.561545
  validation accuracy:		81.30 %
Epoch 1389 of 2000 took 0.098s
  training loss:		0.547276
  validation loss:		0.572894
  validation accuracy:		81.63 %
Epoch 1390 of 2000 took 0.097s
  training loss:		0.558547
  validation loss:		0.560234
  validation accuracy:		81.52 %
Epoch 1391 of 2000 took 0.102s
  training loss:		0.549820
  validation loss:		0.553259
  validation accuracy:		81.85 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.545253
  validation loss:		0.565856
  validation accuracy:		81.96 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.537681
  validation loss:		0.609516
  validation accuracy:		80.11 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.557117
  validation loss:		0.565078
  validation accuracy:		81.09 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.552438
  validation loss:		0.573193
  validation accuracy:		81.30 %
Epoch 1396 of 2000 took 0.100s
  training loss:		0.550930
  validation loss:		0.577449
  validation accuracy:		81.09 %
Epoch 1397 of 2000 took 0.097s
  training loss:		0.544401
  validation loss:		0.561342
  validation accuracy:		81.20 %
Epoch 1398 of 2000 took 0.097s
  training loss:		0.549763
  validation loss:		0.610041
  validation accuracy:		80.11 %
Epoch 1399 of 2000 took 0.103s
  training loss:		0.547895
  validation loss:		0.572009
  validation accuracy:		81.09 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.541462
  validation loss:		0.554343
  validation accuracy:		81.41 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.552312
  validation loss:		0.578118
  validation accuracy:		81.41 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.552093
  validation loss:		0.552142
  validation accuracy:		82.17 %
Epoch 1403 of 2000 took 0.098s
  training loss:		0.545510
  validation loss:		0.589651
  validation accuracy:		81.52 %
Epoch 1404 of 2000 took 0.100s
  training loss:		0.567205
  validation loss:		0.554347
  validation accuracy:		81.63 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.553117
  validation loss:		0.557352
  validation accuracy:		81.30 %
Epoch 1406 of 2000 took 0.098s
  training loss:		0.543860
  validation loss:		0.559059
  validation accuracy:		81.20 %
Epoch 1407 of 2000 took 0.101s
  training loss:		0.544302
  validation loss:		0.596079
  validation accuracy:		80.22 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.550968
  validation loss:		0.559326
  validation accuracy:		81.96 %
Epoch 1409 of 2000 took 0.097s
  training loss:		0.552887
  validation loss:		0.569269
  validation accuracy:		81.52 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.550283
  validation loss:		0.563949
  validation accuracy:		81.20 %
Epoch 1411 of 2000 took 0.101s
  training loss:		0.552693
  validation loss:		0.563046
  validation accuracy:		81.30 %
Epoch 1412 of 2000 took 0.098s
  training loss:		0.539810
  validation loss:		0.555201
  validation accuracy:		81.52 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.552667
  validation loss:		0.565570
  validation accuracy:		81.41 %
Epoch 1414 of 2000 took 0.102s
  training loss:		0.552880
  validation loss:		0.595492
  validation accuracy:		80.43 %
Epoch 1415 of 2000 took 0.098s
  training loss:		0.556325
  validation loss:		0.557909
  validation accuracy:		81.41 %
Epoch 1416 of 2000 took 0.097s
  training loss:		0.541615
  validation loss:		0.575605
  validation accuracy:		81.85 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.552455
  validation loss:		0.572504
  validation accuracy:		80.65 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.544923
  validation loss:		0.576454
  validation accuracy:		81.30 %
Epoch 1419 of 2000 took 0.100s
  training loss:		0.545787
  validation loss:		0.567016
  validation accuracy:		81.63 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.548772
  validation loss:		0.566864
  validation accuracy:		81.63 %
Epoch 1421 of 2000 took 0.097s
  training loss:		0.547286
  validation loss:		0.553438
  validation accuracy:		81.74 %
Epoch 1422 of 2000 took 0.103s
  training loss:		0.547764
  validation loss:		0.564466
  validation accuracy:		82.17 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.539912
  validation loss:		0.559175
  validation accuracy:		81.96 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.550024
  validation loss:		0.552241
  validation accuracy:		81.96 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.557190
  validation loss:		0.577711
  validation accuracy:		81.09 %
Epoch 1426 of 2000 took 0.098s
  training loss:		0.549737
  validation loss:		0.559116
  validation accuracy:		81.63 %
Epoch 1427 of 2000 took 0.100s
  training loss:		0.552488
  validation loss:		0.586000
  validation accuracy:		81.74 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.555323
  validation loss:		0.590787
  validation accuracy:		81.20 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.552508
  validation loss:		0.607467
  validation accuracy:		80.00 %
Epoch 1430 of 2000 took 0.102s
  training loss:		0.558981
  validation loss:		0.618220
  validation accuracy:		80.00 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.546848
  validation loss:		0.560684
  validation accuracy:		81.85 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.548512
  validation loss:		0.572190
  validation accuracy:		81.52 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.542093
  validation loss:		0.556830
  validation accuracy:		81.63 %
Epoch 1434 of 2000 took 0.101s
  training loss:		0.553762
  validation loss:		0.554415
  validation accuracy:		81.63 %
Epoch 1435 of 2000 took 0.098s
  training loss:		0.541216
  validation loss:		0.566046
  validation accuracy:		81.63 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.542331
  validation loss:		0.560073
  validation accuracy:		81.09 %
Epoch 1437 of 2000 took 0.101s
  training loss:		0.551967
  validation loss:		0.573326
  validation accuracy:		80.98 %
Epoch 1438 of 2000 took 0.098s
  training loss:		0.549427
  validation loss:		0.580598
  validation accuracy:		81.63 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.555148
  validation loss:		0.575423
  validation accuracy:		81.63 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.556325
  validation loss:		0.566318
  validation accuracy:		81.96 %
Epoch 1441 of 2000 took 0.098s
  training loss:		0.546781
  validation loss:		0.557391
  validation accuracy:		81.20 %
Epoch 1442 of 2000 took 0.101s
  training loss:		0.548065
  validation loss:		0.590007
  validation accuracy:		80.65 %
Epoch 1443 of 2000 took 0.098s
  training loss:		0.551730
  validation loss:		0.561594
  validation accuracy:		82.17 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.554121
  validation loss:		0.572331
  validation accuracy:		81.52 %
Epoch 1445 of 2000 took 0.103s
  training loss:		0.550889
  validation loss:		0.560542
  validation accuracy:		81.20 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.555666
  validation loss:		0.557758
  validation accuracy:		81.41 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.549693
  validation loss:		0.553824
  validation accuracy:		81.74 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.547086
  validation loss:		0.559601
  validation accuracy:		81.52 %
Epoch 1449 of 2000 took 0.098s
  training loss:		0.545421
  validation loss:		0.570150
  validation accuracy:		82.07 %
Epoch 1450 of 2000 took 0.100s
  training loss:		0.560007
  validation loss:		0.567820
  validation accuracy:		81.63 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.535615
  validation loss:		0.572836
  validation accuracy:		81.30 %
Epoch 1452 of 2000 took 0.097s
  training loss:		0.541850
  validation loss:		0.559985
  validation accuracy:		81.41 %
Epoch 1453 of 2000 took 0.102s
  training loss:		0.549823
  validation loss:		0.581913
  validation accuracy:		81.41 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.545316
  validation loss:		0.554711
  validation accuracy:		81.96 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.546421
  validation loss:		0.561105
  validation accuracy:		81.63 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.553273
  validation loss:		0.564775
  validation accuracy:		81.30 %
Epoch 1457 of 2000 took 0.101s
  training loss:		0.546944
  validation loss:		0.560243
  validation accuracy:		80.98 %
Epoch 1458 of 2000 took 0.098s
  training loss:		0.549623
  validation loss:		0.568716
  validation accuracy:		81.63 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.549347
  validation loss:		0.555267
  validation accuracy:		81.63 %
Epoch 1460 of 2000 took 0.101s
  training loss:		0.547400
  validation loss:		0.570627
  validation accuracy:		81.30 %
Epoch 1461 of 2000 took 0.098s
  training loss:		0.555331
  validation loss:		0.551204
  validation accuracy:		82.17 %
Epoch 1462 of 2000 took 0.097s
  training loss:		0.553075
  validation loss:		0.584978
  validation accuracy:		81.30 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.545431
  validation loss:		0.556436
  validation accuracy:		81.30 %
Epoch 1464 of 2000 took 0.097s
  training loss:		0.557441
  validation loss:		0.555085
  validation accuracy:		81.41 %
Epoch 1465 of 2000 took 0.101s
  training loss:		0.543395
  validation loss:		0.580651
  validation accuracy:		81.52 %
Epoch 1466 of 2000 took 0.097s
  training loss:		0.543086
  validation loss:		0.576825
  validation accuracy:		80.98 %
Epoch 1467 of 2000 took 0.097s
  training loss:		0.558468
  validation loss:		0.561751
  validation accuracy:		81.63 %
Epoch 1468 of 2000 took 0.103s
  training loss:		0.557112
  validation loss:		0.564900
  validation accuracy:		81.30 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.544350
  validation loss:		0.556033
  validation accuracy:		81.20 %
Epoch 1470 of 2000 took 0.097s
  training loss:		0.548391
  validation loss:		0.574469
  validation accuracy:		81.96 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.549985
  validation loss:		0.559181
  validation accuracy:		81.41 %
Epoch 1472 of 2000 took 0.098s
  training loss:		0.547272
  validation loss:		0.564384
  validation accuracy:		81.41 %
Epoch 1473 of 2000 took 0.100s
  training loss:		0.547567
  validation loss:		0.576795
  validation accuracy:		81.41 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.555103
  validation loss:		0.552869
  validation accuracy:		81.41 %
Epoch 1475 of 2000 took 0.097s
  training loss:		0.552655
  validation loss:		0.553998
  validation accuracy:		82.07 %
Epoch 1476 of 2000 took 0.099s
  training loss:		0.543310
  validation loss:		0.558027
  validation accuracy:		81.30 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.543280
  validation loss:		0.564712
  validation accuracy:		81.96 %
Epoch 1478 of 2000 took 0.100s
  training loss:		0.551945
  validation loss:		0.563503
  validation accuracy:		81.63 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.554764
  validation loss:		0.553722
  validation accuracy:		81.41 %
Epoch 1480 of 2000 took 0.099s
  training loss:		0.551982
  validation loss:		0.567087
  validation accuracy:		81.41 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.542777
  validation loss:		0.553696
  validation accuracy:		81.96 %
Epoch 1482 of 2000 took 0.097s
  training loss:		0.546041
  validation loss:		0.598139
  validation accuracy:		80.87 %
Epoch 1483 of 2000 took 0.099s
  training loss:		0.546092
  validation loss:		0.562525
  validation accuracy:		82.17 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.566919
  validation loss:		0.573953
  validation accuracy:		80.54 %
Epoch 1485 of 2000 took 0.100s
  training loss:		0.557971
  validation loss:		0.567613
  validation accuracy:		81.30 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.546757
  validation loss:		0.590565
  validation accuracy:		80.76 %
Epoch 1487 of 2000 took 0.098s
  training loss:		0.549195
  validation loss:		0.615688
  validation accuracy:		80.22 %
Epoch 1488 of 2000 took 0.098s
  training loss:		0.550303
  validation loss:		0.590316
  validation accuracy:		81.41 %
Epoch 1489 of 2000 took 0.097s
  training loss:		0.548818
  validation loss:		0.562757
  validation accuracy:		81.52 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.554017
  validation loss:		0.564415
  validation accuracy:		81.96 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.545590
  validation loss:		0.555016
  validation accuracy:		81.41 %
Epoch 1492 of 2000 took 0.100s
  training loss:		0.548607
  validation loss:		0.561434
  validation accuracy:		81.20 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.546199
  validation loss:		0.569889
  validation accuracy:		81.63 %
Epoch 1494 of 2000 took 0.097s
  training loss:		0.551700
  validation loss:		0.559412
  validation accuracy:		81.41 %
Epoch 1495 of 2000 took 0.099s
  training loss:		0.556494
  validation loss:		0.556483
  validation accuracy:		81.30 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.545623
  validation loss:		0.570474
  validation accuracy:		81.52 %
Epoch 1497 of 2000 took 0.100s
  training loss:		0.548649
  validation loss:		0.554899
  validation accuracy:		81.96 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.549027
  validation loss:		0.560976
  validation accuracy:		82.17 %
Epoch 1499 of 2000 took 0.098s
  training loss:		0.545642
  validation loss:		0.573509
  validation accuracy:		81.20 %
Epoch 1500 of 2000 took 0.098s
  training loss:		0.540972
  validation loss:		0.563406
  validation accuracy:		81.63 %
Epoch 1501 of 2000 took 0.097s
  training loss:		0.545588
  validation loss:		0.576485
  validation accuracy:		81.09 %
Epoch 1502 of 2000 took 0.103s
  training loss:		0.543033
  validation loss:		0.587581
  validation accuracy:		80.87 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.542619
  validation loss:		0.561642
  validation accuracy:		81.52 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.557619
  validation loss:		0.594974
  validation accuracy:		80.65 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.550785
  validation loss:		0.577352
  validation accuracy:		81.30 %
Epoch 1506 of 2000 took 0.098s
  training loss:		0.538979
  validation loss:		0.554762
  validation accuracy:		81.63 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.558231
  validation loss:		0.556654
  validation accuracy:		81.09 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.548051
  validation loss:		0.587758
  validation accuracy:		80.87 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.551442
  validation loss:		0.560985
  validation accuracy:		81.30 %
Epoch 1510 of 2000 took 0.101s
  training loss:		0.553870
  validation loss:		0.611519
  validation accuracy:		79.57 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.551012
  validation loss:		0.575887
  validation accuracy:		81.30 %
Epoch 1512 of 2000 took 0.097s
  training loss:		0.548726
  validation loss:		0.564205
  validation accuracy:		81.30 %
Epoch 1513 of 2000 took 0.096s
  training loss:		0.548052
  validation loss:		0.573217
  validation accuracy:		81.52 %
Epoch 1514 of 2000 took 0.101s
  training loss:		0.540378
  validation loss:		0.555941
  validation accuracy:		81.63 %
Epoch 1515 of 2000 took 0.098s
  training loss:		0.546942
  validation loss:		0.571692
  validation accuracy:		81.20 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.545306
  validation loss:		0.579124
  validation accuracy:		81.63 %
Epoch 1517 of 2000 took 0.102s
  training loss:		0.555071
  validation loss:		0.564525
  validation accuracy:		81.41 %
Epoch 1518 of 2000 took 0.097s
  training loss:		0.541889
  validation loss:		0.561548
  validation accuracy:		81.30 %
Epoch 1519 of 2000 took 0.097s
  training loss:		0.543267
  validation loss:		0.576841
  validation accuracy:		80.87 %
Epoch 1520 of 2000 took 0.097s
  training loss:		0.558703
  validation loss:		0.601504
  validation accuracy:		80.33 %
Epoch 1521 of 2000 took 0.097s
  training loss:		0.542991
  validation loss:		0.556212
  validation accuracy:		82.07 %
Epoch 1522 of 2000 took 0.101s
  training loss:		0.555623
  validation loss:		0.562006
  validation accuracy:		81.63 %
Epoch 1523 of 2000 took 0.098s
  training loss:		0.549570
  validation loss:		0.559814
  validation accuracy:		81.63 %
Epoch 1524 of 2000 took 0.097s
  training loss:		0.547561
  validation loss:		0.563652
  validation accuracy:		81.41 %
Epoch 1525 of 2000 took 0.103s
  training loss:		0.550379
  validation loss:		0.557573
  validation accuracy:		81.41 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.550066
  validation loss:		0.559379
  validation accuracy:		81.74 %
Epoch 1527 of 2000 took 0.097s
  training loss:		0.546673
  validation loss:		0.580137
  validation accuracy:		81.30 %
Epoch 1528 of 2000 took 0.096s
  training loss:		0.550915
  validation loss:		0.568962
  validation accuracy:		81.52 %
Epoch 1529 of 2000 took 0.098s
  training loss:		0.559527
  validation loss:		0.581510
  validation accuracy:		81.20 %
Epoch 1530 of 2000 took 0.100s
  training loss:		0.551577
  validation loss:		0.557802
  validation accuracy:		81.09 %
Epoch 1531 of 2000 took 0.096s
  training loss:		0.549377
  validation loss:		0.575484
  validation accuracy:		81.52 %
Epoch 1532 of 2000 took 0.097s
  training loss:		0.553269
  validation loss:		0.562239
  validation accuracy:		81.52 %
Epoch 1533 of 2000 took 0.102s
  training loss:		0.542404
  validation loss:		0.579683
  validation accuracy:		81.20 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.544363
  validation loss:		0.553350
  validation accuracy:		81.85 %
Epoch 1535 of 2000 took 0.097s
  training loss:		0.561173
  validation loss:		0.558632
  validation accuracy:		81.74 %
Epoch 1536 of 2000 took 0.096s
  training loss:		0.547986
  validation loss:		0.563745
  validation accuracy:		81.52 %
Epoch 1537 of 2000 took 0.100s
  training loss:		0.540221
  validation loss:		0.555561
  validation accuracy:		81.63 %
Epoch 1538 of 2000 took 0.098s
  training loss:		0.557389
  validation loss:		0.562809
  validation accuracy:		81.74 %
Epoch 1539 of 2000 took 0.096s
  training loss:		0.553334
  validation loss:		0.555067
  validation accuracy:		81.30 %
Epoch 1540 of 2000 took 0.100s
  training loss:		0.548840
  validation loss:		0.578578
  validation accuracy:		81.63 %
Epoch 1541 of 2000 took 0.099s
  training loss:		0.549577
  validation loss:		0.572235
  validation accuracy:		81.09 %
Epoch 1542 of 2000 took 0.097s
  training loss:		0.554458
  validation loss:		0.563789
  validation accuracy:		81.63 %
Epoch 1543 of 2000 took 0.097s
  training loss:		0.544523
  validation loss:		0.555956
  validation accuracy:		81.96 %
Epoch 1544 of 2000 took 0.097s
  training loss:		0.550134
  validation loss:		0.557374
  validation accuracy:		81.30 %
Epoch 1545 of 2000 took 0.101s
  training loss:		0.548411
  validation loss:		0.559804
  validation accuracy:		81.96 %
Epoch 1546 of 2000 took 0.097s
  training loss:		0.549146
  validation loss:		0.564557
  validation accuracy:		81.30 %
Epoch 1547 of 2000 took 0.097s
  training loss:		0.545224
  validation loss:		0.579365
  validation accuracy:		81.09 %
Epoch 1548 of 2000 took 0.103s
  training loss:		0.552319
  validation loss:		0.555843
  validation accuracy:		81.30 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.558963
  validation loss:		0.579902
  validation accuracy:		81.20 %
Epoch 1550 of 2000 took 0.097s
  training loss:		0.549033
  validation loss:		0.573025
  validation accuracy:		81.52 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.548734
  validation loss:		0.584823
  validation accuracy:		80.98 %
Epoch 1552 of 2000 took 0.098s
  training loss:		0.544974
  validation loss:		0.567160
  validation accuracy:		81.74 %
Epoch 1553 of 2000 took 0.101s
  training loss:		0.550710
  validation loss:		0.566483
  validation accuracy:		81.52 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.540302
  validation loss:		0.572423
  validation accuracy:		81.52 %
Epoch 1555 of 2000 took 0.097s
  training loss:		0.551742
  validation loss:		0.578903
  validation accuracy:		81.52 %
Epoch 1556 of 2000 took 0.102s
  training loss:		0.544089
  validation loss:		0.565936
  validation accuracy:		81.52 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.547605
  validation loss:		0.562974
  validation accuracy:		80.98 %
Epoch 1558 of 2000 took 0.097s
  training loss:		0.546342
  validation loss:		0.561782
  validation accuracy:		81.30 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.542818
  validation loss:		0.582728
  validation accuracy:		81.20 %
Epoch 1560 of 2000 took 0.100s
  training loss:		0.554263
  validation loss:		0.562525
  validation accuracy:		81.52 %
Epoch 1561 of 2000 took 0.098s
  training loss:		0.549428
  validation loss:		0.555256
  validation accuracy:		81.52 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.559072
  validation loss:		0.571318
  validation accuracy:		81.52 %
Epoch 1563 of 2000 took 0.100s
  training loss:		0.558649
  validation loss:		0.561263
  validation accuracy:		81.20 %
Epoch 1564 of 2000 took 0.101s
  training loss:		0.554544
  validation loss:		0.565969
  validation accuracy:		81.41 %
Epoch 1565 of 2000 took 0.098s
  training loss:		0.551897
  validation loss:		0.561263
  validation accuracy:		81.30 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.551088
  validation loss:		0.566960
  validation accuracy:		81.85 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.549034
  validation loss:		0.595498
  validation accuracy:		80.76 %
Epoch 1568 of 2000 took 0.101s
  training loss:		0.550496
  validation loss:		0.562823
  validation accuracy:		81.63 %
Epoch 1569 of 2000 took 0.097s
  training loss:		0.555973
  validation loss:		0.554320
  validation accuracy:		81.85 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.546518
  validation loss:		0.560485
  validation accuracy:		81.52 %
Epoch 1571 of 2000 took 0.103s
  training loss:		0.552648
  validation loss:		0.626180
  validation accuracy:		79.24 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.556559
  validation loss:		0.553154
  validation accuracy:		81.41 %
Epoch 1573 of 2000 took 0.097s
  training loss:		0.545941
  validation loss:		0.551440
  validation accuracy:		82.07 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.540293
  validation loss:		0.586474
  validation accuracy:		81.20 %
Epoch 1575 of 2000 took 0.098s
  training loss:		0.544388
  validation loss:		0.555952
  validation accuracy:		82.17 %
Epoch 1576 of 2000 took 0.101s
  training loss:		0.540921
  validation loss:		0.555128
  validation accuracy:		81.74 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.551114
  validation loss:		0.560450
  validation accuracy:		81.20 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.550549
  validation loss:		0.561523
  validation accuracy:		81.63 %
Epoch 1579 of 2000 took 0.102s
  training loss:		0.553708
  validation loss:		0.558047
  validation accuracy:		81.96 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.546090
  validation loss:		0.565820
  validation accuracy:		81.30 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.552322
  validation loss:		0.550099
  validation accuracy:		81.96 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.547783
  validation loss:		0.559178
  validation accuracy:		80.98 %
Epoch 1583 of 2000 took 0.100s
  training loss:		0.545829
  validation loss:		0.561287
  validation accuracy:		81.09 %
Epoch 1584 of 2000 took 0.098s
  training loss:		0.549735
  validation loss:		0.570842
  validation accuracy:		80.98 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.553097
  validation loss:		0.564299
  validation accuracy:		81.09 %
Epoch 1586 of 2000 took 0.101s
  training loss:		0.539636
  validation loss:		0.556816
  validation accuracy:		81.74 %
Epoch 1587 of 2000 took 0.098s
  training loss:		0.545706
  validation loss:		0.553721
  validation accuracy:		82.07 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.548805
  validation loss:		0.587652
  validation accuracy:		80.43 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.551651
  validation loss:		0.582575
  validation accuracy:		80.54 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.548228
  validation loss:		0.601824
  validation accuracy:		80.54 %
Epoch 1591 of 2000 took 0.101s
  training loss:		0.548837
  validation loss:		0.556292
  validation accuracy:		81.74 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.558038
  validation loss:		0.559760
  validation accuracy:		81.63 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.556729
  validation loss:		0.580183
  validation accuracy:		81.52 %
Epoch 1594 of 2000 took 0.103s
  training loss:		0.550785
  validation loss:		0.565204
  validation accuracy:		81.41 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.550182
  validation loss:		0.580936
  validation accuracy:		81.30 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.547919
  validation loss:		0.564284
  validation accuracy:		81.20 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.538026
  validation loss:		0.560595
  validation accuracy:		81.96 %
Epoch 1598 of 2000 took 0.098s
  training loss:		0.549571
  validation loss:		0.569860
  validation accuracy:		81.20 %
Epoch 1599 of 2000 took 0.100s
  training loss:		0.556104
  validation loss:		0.577898
  validation accuracy:		81.41 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.552278
  validation loss:		0.552115
  validation accuracy:		81.96 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.542718
  validation loss:		0.562189
  validation accuracy:		81.63 %
Epoch 1602 of 2000 took 0.102s
  training loss:		0.543706
  validation loss:		0.551632
  validation accuracy:		81.74 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.541201
  validation loss:		0.558462
  validation accuracy:		81.30 %
Epoch 1604 of 2000 took 0.098s
  training loss:		0.548205
  validation loss:		0.556199
  validation accuracy:		82.17 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.548919
  validation loss:		0.570821
  validation accuracy:		81.41 %
Epoch 1606 of 2000 took 0.101s
  training loss:		0.540877
  validation loss:		0.553865
  validation accuracy:		81.63 %
Epoch 1607 of 2000 took 0.098s
  training loss:		0.548100
  validation loss:		0.551054
  validation accuracy:		82.07 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.552554
  validation loss:		0.567542
  validation accuracy:		81.30 %
Epoch 1609 of 2000 took 0.101s
  training loss:		0.558957
  validation loss:		0.569604
  validation accuracy:		81.20 %
Epoch 1610 of 2000 took 0.098s
  training loss:		0.549357
  validation loss:		0.563767
  validation accuracy:		81.52 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.548783
  validation loss:		0.561087
  validation accuracy:		80.98 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.547716
  validation loss:		0.565629
  validation accuracy:		81.96 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.551100
  validation loss:		0.581331
  validation accuracy:		81.09 %
Epoch 1614 of 2000 took 0.100s
  training loss:		0.546540
  validation loss:		0.559908
  validation accuracy:		81.52 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.554204
  validation loss:		0.584465
  validation accuracy:		81.41 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.550604
  validation loss:		0.559798
  validation accuracy:		81.52 %
Epoch 1617 of 2000 took 0.103s
  training loss:		0.550300
  validation loss:		0.557411
  validation accuracy:		81.09 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.545178
  validation loss:		0.550635
  validation accuracy:		81.85 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.552377
  validation loss:		0.556357
  validation accuracy:		81.41 %
Epoch 1620 of 2000 took 0.096s
  training loss:		0.550754
  validation loss:		0.566690
  validation accuracy:		81.63 %
Epoch 1621 of 2000 took 0.098s
  training loss:		0.552483
  validation loss:		0.557146
  validation accuracy:		81.41 %
Epoch 1622 of 2000 took 0.101s
  training loss:		0.547131
  validation loss:		0.565775
  validation accuracy:		82.17 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.548144
  validation loss:		0.560321
  validation accuracy:		81.41 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.546611
  validation loss:		0.558033
  validation accuracy:		81.30 %
Epoch 1625 of 2000 took 0.102s
  training loss:		0.549618
  validation loss:		0.570947
  validation accuracy:		81.20 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.551976
  validation loss:		0.571781
  validation accuracy:		81.30 %
Epoch 1627 of 2000 took 0.097s
  training loss:		0.543718
  validation loss:		0.560705
  validation accuracy:		81.09 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.551310
  validation loss:		0.555112
  validation accuracy:		81.41 %
Epoch 1629 of 2000 took 0.100s
  training loss:		0.550461
  validation loss:		0.581426
  validation accuracy:		81.20 %
Epoch 1630 of 2000 took 0.098s
  training loss:		0.546540
  validation loss:		0.563875
  validation accuracy:		81.52 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.547250
  validation loss:		0.559070
  validation accuracy:		81.30 %
Epoch 1632 of 2000 took 0.100s
  training loss:		0.550550
  validation loss:		0.568257
  validation accuracy:		81.41 %
Epoch 1633 of 2000 took 0.099s
  training loss:		0.547321
  validation loss:		0.580848
  validation accuracy:		81.41 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.554317
  validation loss:		0.555255
  validation accuracy:		82.39 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.550256
  validation loss:		0.561467
  validation accuracy:		81.20 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.548118
  validation loss:		0.563441
  validation accuracy:		81.20 %
Epoch 1637 of 2000 took 0.101s
  training loss:		0.547849
  validation loss:		0.563906
  validation accuracy:		81.52 %
Epoch 1638 of 2000 took 0.098s
  training loss:		0.548159
  validation loss:		0.558676
  validation accuracy:		81.20 %
Epoch 1639 of 2000 took 0.097s
  training loss:		0.544915
  validation loss:		0.558645
  validation accuracy:		82.28 %
Epoch 1640 of 2000 took 0.103s
  training loss:		0.552801
  validation loss:		0.563830
  validation accuracy:		81.20 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.550424
  validation loss:		0.574874
  validation accuracy:		80.87 %
Epoch 1642 of 2000 took 0.097s
  training loss:		0.541842
  validation loss:		0.555614
  validation accuracy:		81.20 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.548702
  validation loss:		0.583130
  validation accuracy:		81.09 %
Epoch 1644 of 2000 took 0.098s
  training loss:		0.568555
  validation loss:		0.564256
  validation accuracy:		80.98 %
Epoch 1645 of 2000 took 0.101s
  training loss:		0.545562
  validation loss:		0.567905
  validation accuracy:		81.96 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.547316
  validation loss:		0.595129
  validation accuracy:		80.65 %
Epoch 1647 of 2000 took 0.097s
  training loss:		0.542264
  validation loss:		0.554962
  validation accuracy:		81.63 %
Epoch 1648 of 2000 took 0.102s
  training loss:		0.544031
  validation loss:		0.582575
  validation accuracy:		81.41 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.556432
  validation loss:		0.602658
  validation accuracy:		80.11 %
Epoch 1650 of 2000 took 0.097s
  training loss:		0.552836
  validation loss:		0.600650
  validation accuracy:		80.43 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.546543
  validation loss:		0.557419
  validation accuracy:		81.30 %
Epoch 1652 of 2000 took 0.099s
  training loss:		0.551889
  validation loss:		0.563243
  validation accuracy:		81.30 %
Epoch 1653 of 2000 took 0.099s
  training loss:		0.545626
  validation loss:		0.567666
  validation accuracy:		81.52 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.547390
  validation loss:		0.557935
  validation accuracy:		81.74 %
Epoch 1655 of 2000 took 0.099s
  training loss:		0.541570
  validation loss:		0.552747
  validation accuracy:		81.63 %
Epoch 1656 of 2000 took 0.100s
  training loss:		0.545845
  validation loss:		0.563971
  validation accuracy:		81.09 %
Epoch 1657 of 2000 took 0.097s
  training loss:		0.548354
  validation loss:		0.571037
  validation accuracy:		80.98 %
Epoch 1658 of 2000 took 0.097s
  training loss:		0.544378
  validation loss:		0.561985
  validation accuracy:		80.98 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.551044
  validation loss:		0.550259
  validation accuracy:		81.85 %
Epoch 1660 of 2000 took 0.101s
  training loss:		0.543303
  validation loss:		0.560331
  validation accuracy:		81.41 %
Epoch 1661 of 2000 took 0.098s
  training loss:		0.547388
  validation loss:		0.554392
  validation accuracy:		81.85 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.547063
  validation loss:		0.562690
  validation accuracy:		81.20 %
Epoch 1663 of 2000 took 0.102s
  training loss:		0.541747
  validation loss:		0.597376
  validation accuracy:		80.76 %
Epoch 1664 of 2000 took 0.097s
  training loss:		0.547453
  validation loss:		0.558690
  validation accuracy:		80.76 %
Epoch 1665 of 2000 took 0.097s
  training loss:		0.548054
  validation loss:		0.566375
  validation accuracy:		81.63 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.554942
  validation loss:		0.571888
  validation accuracy:		81.09 %
Epoch 1667 of 2000 took 0.097s
  training loss:		0.551813
  validation loss:		0.568714
  validation accuracy:		81.85 %
Epoch 1668 of 2000 took 0.101s
  training loss:		0.552956
  validation loss:		0.556414
  validation accuracy:		81.85 %
Epoch 1669 of 2000 took 0.096s
  training loss:		0.548191
  validation loss:		0.585685
  validation accuracy:		80.65 %
Epoch 1670 of 2000 took 0.097s
  training loss:		0.545805
  validation loss:		0.566664
  validation accuracy:		81.52 %
Epoch 1671 of 2000 took 0.102s
  training loss:		0.542345
  validation loss:		0.581918
  validation accuracy:		81.20 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.574564
  validation loss:		0.598831
  validation accuracy:		80.33 %
Epoch 1673 of 2000 took 0.097s
  training loss:		0.553411
  validation loss:		0.572399
  validation accuracy:		81.52 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.550522
  validation loss:		0.554186
  validation accuracy:		82.07 %
Epoch 1675 of 2000 took 0.099s
  training loss:		0.540743
  validation loss:		0.571607
  validation accuracy:		81.63 %
Epoch 1676 of 2000 took 0.099s
  training loss:		0.549975
  validation loss:		0.562968
  validation accuracy:		81.96 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.552019
  validation loss:		0.561178
  validation accuracy:		81.41 %
Epoch 1678 of 2000 took 0.099s
  training loss:		0.553051
  validation loss:		0.565964
  validation accuracy:		81.30 %
Epoch 1679 of 2000 took 0.100s
  training loss:		0.542573
  validation loss:		0.565044
  validation accuracy:		81.30 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.540959
  validation loss:		0.556091
  validation accuracy:		81.63 %
Epoch 1681 of 2000 took 0.097s
  training loss:		0.556706
  validation loss:		0.558104
  validation accuracy:		81.85 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.556916
  validation loss:		0.555045
  validation accuracy:		81.41 %
Epoch 1683 of 2000 took 0.101s
  training loss:		0.541989
  validation loss:		0.584023
  validation accuracy:		81.52 %
Epoch 1684 of 2000 took 0.098s
  training loss:		0.549133
  validation loss:		0.583095
  validation accuracy:		81.20 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.549557
  validation loss:		0.583378
  validation accuracy:		80.65 %
Epoch 1686 of 2000 took 0.102s
  training loss:		0.547647
  validation loss:		0.562660
  validation accuracy:		81.74 %
Epoch 1687 of 2000 took 0.101s
  training loss:		0.541723
  validation loss:		0.565734
  validation accuracy:		82.07 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.549513
  validation loss:		0.556707
  validation accuracy:		81.41 %
Epoch 1689 of 2000 took 0.095s
  training loss:		0.544168
  validation loss:		0.570472
  validation accuracy:		80.87 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.546534
  validation loss:		0.561165
  validation accuracy:		81.96 %
Epoch 1691 of 2000 took 0.099s
  training loss:		0.550306
  validation loss:		0.552214
  validation accuracy:		81.63 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.553517
  validation loss:		0.564533
  validation accuracy:		81.63 %
Epoch 1693 of 2000 took 0.095s
  training loss:		0.552532
  validation loss:		0.553220
  validation accuracy:		82.07 %
Epoch 1694 of 2000 took 0.101s
  training loss:		0.543400
  validation loss:		0.564644
  validation accuracy:		81.41 %
Epoch 1695 of 2000 took 0.095s
  training loss:		0.554195
  validation loss:		0.563144
  validation accuracy:		81.30 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.552175
  validation loss:		0.554053
  validation accuracy:		82.17 %
Epoch 1697 of 2000 took 0.095s
  training loss:		0.544350
  validation loss:		0.566512
  validation accuracy:		81.41 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.547769
  validation loss:		0.581954
  validation accuracy:		81.30 %
Epoch 1699 of 2000 took 0.099s
  training loss:		0.538339
  validation loss:		0.560067
  validation accuracy:		81.30 %
Epoch 1700 of 2000 took 0.095s
  training loss:		0.550957
  validation loss:		0.566421
  validation accuracy:		81.41 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.550246
  validation loss:		0.562876
  validation accuracy:		81.63 %
Epoch 1702 of 2000 took 0.101s
  training loss:		0.550413
  validation loss:		0.553467
  validation accuracy:		81.52 %
Epoch 1703 of 2000 took 0.095s
  training loss:		0.553000
  validation loss:		0.581556
  validation accuracy:		80.65 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.555319
  validation loss:		0.564989
  validation accuracy:		81.63 %
Epoch 1705 of 2000 took 0.095s
  training loss:		0.539233
  validation loss:		0.563622
  validation accuracy:		81.41 %
Epoch 1706 of 2000 took 0.098s
  training loss:		0.550237
  validation loss:		0.553847
  validation accuracy:		81.96 %
Epoch 1707 of 2000 took 0.098s
  training loss:		0.554137
  validation loss:		0.562513
  validation accuracy:		81.20 %
Epoch 1708 of 2000 took 0.095s
  training loss:		0.551059
  validation loss:		0.575219
  validation accuracy:		81.09 %
Epoch 1709 of 2000 took 0.097s
  training loss:		0.549866
  validation loss:		0.560677
  validation accuracy:		80.98 %
Epoch 1710 of 2000 took 0.099s
  training loss:		0.541087
  validation loss:		0.559939
  validation accuracy:		81.74 %
Epoch 1711 of 2000 took 0.095s
  training loss:		0.545126
  validation loss:		0.560600
  validation accuracy:		81.85 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.551029
  validation loss:		0.553046
  validation accuracy:		81.41 %
Epoch 1713 of 2000 took 0.095s
  training loss:		0.541453
  validation loss:		0.560611
  validation accuracy:		81.63 %
Epoch 1714 of 2000 took 0.099s
  training loss:		0.544826
  validation loss:		0.564610
  validation accuracy:		81.63 %
Epoch 1715 of 2000 took 0.097s
  training loss:		0.551862
  validation loss:		0.552115
  validation accuracy:		81.52 %
Epoch 1716 of 2000 took 0.095s
  training loss:		0.547481
  validation loss:		0.583509
  validation accuracy:		81.63 %
Epoch 1717 of 2000 took 0.100s
  training loss:		0.550105
  validation loss:		0.564744
  validation accuracy:		81.30 %
Epoch 1718 of 2000 took 0.097s
  training loss:		0.548780
  validation loss:		0.579105
  validation accuracy:		81.52 %
Epoch 1719 of 2000 took 0.095s
  training loss:		0.547231
  validation loss:		0.557311
  validation accuracy:		81.85 %
Epoch 1720 of 2000 took 0.095s
  training loss:		0.550231
  validation loss:		0.564054
  validation accuracy:		81.52 %
Epoch 1721 of 2000 took 0.095s
  training loss:		0.554522
  validation loss:		0.585206
  validation accuracy:		80.65 %
Epoch 1722 of 2000 took 0.099s
  training loss:		0.555015
  validation loss:		0.558042
  validation accuracy:		81.30 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.551096
  validation loss:		0.556193
  validation accuracy:		82.17 %
Epoch 1724 of 2000 took 0.095s
  training loss:		0.544813
  validation loss:		0.562896
  validation accuracy:		81.09 %
Epoch 1725 of 2000 took 0.102s
  training loss:		0.545692
  validation loss:		0.551635
  validation accuracy:		82.07 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.540194
  validation loss:		0.578600
  validation accuracy:		81.41 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.549831
  validation loss:		0.554648
  validation accuracy:		81.52 %
Epoch 1728 of 2000 took 0.096s
  training loss:		0.549282
  validation loss:		0.569118
  validation accuracy:		80.98 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.548705
  validation loss:		0.553527
  validation accuracy:		82.07 %
Epoch 1730 of 2000 took 0.100s
  training loss:		0.551898
  validation loss:		0.581333
  validation accuracy:		80.98 %
Epoch 1731 of 2000 took 0.096s
  training loss:		0.550919
  validation loss:		0.559567
  validation accuracy:		81.96 %
Epoch 1732 of 2000 took 0.097s
  training loss:		0.552075
  validation loss:		0.559630
  validation accuracy:		81.41 %
Epoch 1733 of 2000 took 0.102s
  training loss:		0.550513
  validation loss:		0.595995
  validation accuracy:		80.43 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.553342
  validation loss:		0.562213
  validation accuracy:		81.09 %
Epoch 1735 of 2000 took 0.097s
  training loss:		0.549532
  validation loss:		0.586792
  validation accuracy:		80.54 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.549872
  validation loss:		0.572206
  validation accuracy:		81.09 %
Epoch 1737 of 2000 took 0.099s
  training loss:		0.546519
  validation loss:		0.562585
  validation accuracy:		81.20 %
Epoch 1738 of 2000 took 0.099s
  training loss:		0.550442
  validation loss:		0.563151
  validation accuracy:		81.85 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.559143
  validation loss:		0.608231
  validation accuracy:		80.43 %
Epoch 1740 of 2000 took 0.099s
  training loss:		0.537351
  validation loss:		0.560663
  validation accuracy:		81.96 %
Epoch 1741 of 2000 took 0.100s
  training loss:		0.539748
  validation loss:		0.556254
  validation accuracy:		81.63 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.548173
  validation loss:		0.568566
  validation accuracy:		81.20 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.549917
  validation loss:		0.581965
  validation accuracy:		81.63 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.543243
  validation loss:		0.557439
  validation accuracy:		81.41 %
Epoch 1745 of 2000 took 0.101s
  training loss:		0.542396
  validation loss:		0.573535
  validation accuracy:		81.30 %
Epoch 1746 of 2000 took 0.097s
  training loss:		0.546667
  validation loss:		0.551769
  validation accuracy:		81.85 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.552387
  validation loss:		0.573270
  validation accuracy:		81.41 %
Epoch 1748 of 2000 took 0.102s
  training loss:		0.545653
  validation loss:		0.561962
  validation accuracy:		81.63 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.551185
  validation loss:		0.571728
  validation accuracy:		81.41 %
Epoch 1750 of 2000 took 0.097s
  training loss:		0.540105
  validation loss:		0.564386
  validation accuracy:		81.74 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.555300
  validation loss:		0.578191
  validation accuracy:		81.41 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.540495
  validation loss:		0.556062
  validation accuracy:		82.17 %
Epoch 1753 of 2000 took 0.100s
  training loss:		0.538121
  validation loss:		0.564208
  validation accuracy:		81.85 %
Epoch 1754 of 2000 took 0.097s
  training loss:		0.552625
  validation loss:		0.567258
  validation accuracy:		82.07 %
Epoch 1755 of 2000 took 0.097s
  training loss:		0.559330
  validation loss:		0.563654
  validation accuracy:		81.41 %
Epoch 1756 of 2000 took 0.102s
  training loss:		0.545375
  validation loss:		0.588721
  validation accuracy:		81.30 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.550939
  validation loss:		0.570989
  validation accuracy:		81.30 %
Epoch 1758 of 2000 took 0.097s
  training loss:		0.547260
  validation loss:		0.554083
  validation accuracy:		81.09 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.555195
  validation loss:		0.573082
  validation accuracy:		81.85 %
Epoch 1760 of 2000 took 0.098s
  training loss:		0.553694
  validation loss:		0.565151
  validation accuracy:		81.52 %
Epoch 1761 of 2000 took 0.100s
  training loss:		0.554718
  validation loss:		0.567722
  validation accuracy:		81.41 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.550044
  validation loss:		0.563655
  validation accuracy:		80.98 %
Epoch 1763 of 2000 took 0.097s
  training loss:		0.536935
  validation loss:		0.555175
  validation accuracy:		81.30 %
Epoch 1764 of 2000 took 0.101s
  training loss:		0.549385
  validation loss:		0.561766
  validation accuracy:		81.52 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.544845
  validation loss:		0.565778
  validation accuracy:		81.85 %
Epoch 1766 of 2000 took 0.097s
  training loss:		0.545514
  validation loss:		0.559266
  validation accuracy:		81.20 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.545970
  validation loss:		0.568098
  validation accuracy:		81.52 %
Epoch 1768 of 2000 took 0.101s
  training loss:		0.547375
  validation loss:		0.560153
  validation accuracy:		81.85 %
Epoch 1769 of 2000 took 0.098s
  training loss:		0.533517
  validation loss:		0.572068
  validation accuracy:		81.52 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.547884
  validation loss:		0.554046
  validation accuracy:		81.74 %
Epoch 1771 of 2000 took 0.101s
  training loss:		0.546405
  validation loss:		0.562801
  validation accuracy:		81.52 %
Epoch 1772 of 2000 took 0.098s
  training loss:		0.548362
  validation loss:		0.550725
  validation accuracy:		82.17 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.549230
  validation loss:		0.604041
  validation accuracy:		80.11 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.542713
  validation loss:		0.591916
  validation accuracy:		80.98 %
Epoch 1775 of 2000 took 0.097s
  training loss:		0.550036
  validation loss:		0.563559
  validation accuracy:		81.41 %
Epoch 1776 of 2000 took 0.100s
  training loss:		0.546183
  validation loss:		0.565730
  validation accuracy:		81.20 %
Epoch 1777 of 2000 took 0.097s
  training loss:		0.553805
  validation loss:		0.570977
  validation accuracy:		81.41 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.550057
  validation loss:		0.567213
  validation accuracy:		81.74 %
Epoch 1779 of 2000 took 0.102s
  training loss:		0.546032
  validation loss:		0.597799
  validation accuracy:		80.54 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.550703
  validation loss:		0.557954
  validation accuracy:		82.17 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.553524
  validation loss:		0.551835
  validation accuracy:		81.74 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.556155
  validation loss:		0.573186
  validation accuracy:		81.30 %
Epoch 1783 of 2000 took 0.097s
  training loss:		0.551787
  validation loss:		0.563313
  validation accuracy:		81.74 %
Epoch 1784 of 2000 took 0.100s
  training loss:		0.557527
  validation loss:		0.559134
  validation accuracy:		81.30 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.562501
  validation loss:		0.585820
  validation accuracy:		80.98 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.547484
  validation loss:		0.564761
  validation accuracy:		81.09 %
Epoch 1787 of 2000 took 0.102s
  training loss:		0.545058
  validation loss:		0.557392
  validation accuracy:		81.09 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.549273
  validation loss:		0.572947
  validation accuracy:		81.41 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.555048
  validation loss:		0.564610
  validation accuracy:		81.09 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.553722
  validation loss:		0.573617
  validation accuracy:		81.20 %
Epoch 1791 of 2000 took 0.098s
  training loss:		0.558202
  validation loss:		0.563444
  validation accuracy:		81.41 %
Epoch 1792 of 2000 took 0.098s
  training loss:		0.545918
  validation loss:		0.575871
  validation accuracy:		81.41 %
Epoch 1793 of 2000 took 0.095s
  training loss:		0.554940
  validation loss:		0.600572
  validation accuracy:		80.76 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.541176
  validation loss:		0.553137
  validation accuracy:		81.63 %
Epoch 1795 of 2000 took 0.099s
  training loss:		0.545070
  validation loss:		0.561754
  validation accuracy:		81.20 %
Epoch 1796 of 2000 took 0.095s
  training loss:		0.544813
  validation loss:		0.559817
  validation accuracy:		82.17 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.539263
  validation loss:		0.583329
  validation accuracy:		81.20 %
Epoch 1798 of 2000 took 0.095s
  training loss:		0.547231
  validation loss:		0.558446
  validation accuracy:		81.74 %
Epoch 1799 of 2000 took 0.100s
  training loss:		0.544636
  validation loss:		0.558592
  validation accuracy:		81.96 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.548235
  validation loss:		0.555969
  validation accuracy:		81.09 %
Epoch 1801 of 2000 took 0.095s
  training loss:		0.541749
  validation loss:		0.557143
  validation accuracy:		81.41 %
Epoch 1802 of 2000 took 0.100s
  training loss:		0.545521
  validation loss:		0.590046
  validation accuracy:		80.65 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.551433
  validation loss:		0.569015
  validation accuracy:		81.96 %
Epoch 1804 of 2000 took 0.095s
  training loss:		0.545859
  validation loss:		0.552214
  validation accuracy:		81.41 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.538519
  validation loss:		0.561866
  validation accuracy:		80.87 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.552554
  validation loss:		0.554758
  validation accuracy:		81.63 %
Epoch 1807 of 2000 took 0.100s
  training loss:		0.543884
  validation loss:		0.555058
  validation accuracy:		81.09 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.541145
  validation loss:		0.558771
  validation accuracy:		81.85 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.551041
  validation loss:		0.564286
  validation accuracy:		81.20 %
Epoch 1810 of 2000 took 0.102s
  training loss:		0.542485
  validation loss:		0.570195
  validation accuracy:		81.85 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.551224
  validation loss:		0.555485
  validation accuracy:		81.41 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.554612
  validation loss:		0.571618
  validation accuracy:		81.96 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.549929
  validation loss:		0.565202
  validation accuracy:		81.74 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.551395
  validation loss:		0.563529
  validation accuracy:		81.41 %
Epoch 1815 of 2000 took 0.100s
  training loss:		0.549135
  validation loss:		0.554088
  validation accuracy:		81.30 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.549913
  validation loss:		0.564994
  validation accuracy:		81.20 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.550398
  validation loss:		0.553678
  validation accuracy:		81.63 %
Epoch 1818 of 2000 took 0.102s
  training loss:		0.552239
  validation loss:		0.558084
  validation accuracy:		81.20 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.545864
  validation loss:		0.555118
  validation accuracy:		82.07 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.539906
  validation loss:		0.560725
  validation accuracy:		81.41 %
Epoch 1821 of 2000 took 0.096s
  training loss:		0.552142
  validation loss:		0.552117
  validation accuracy:		81.52 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.554101
  validation loss:		0.569531
  validation accuracy:		81.96 %
Epoch 1823 of 2000 took 0.098s
  training loss:		0.541581
  validation loss:		0.562834
  validation accuracy:		81.30 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.551302
  validation loss:		0.559733
  validation accuracy:		81.09 %
Epoch 1825 of 2000 took 0.099s
  training loss:		0.549076
  validation loss:		0.565603
  validation accuracy:		80.98 %
Epoch 1826 of 2000 took 0.100s
  training loss:		0.544538
  validation loss:		0.556994
  validation accuracy:		81.09 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.549832
  validation loss:		0.559677
  validation accuracy:		81.41 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.540815
  validation loss:		0.560116
  validation accuracy:		81.63 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.545713
  validation loss:		0.565902
  validation accuracy:		81.30 %
Epoch 1830 of 2000 took 0.101s
  training loss:		0.544247
  validation loss:		0.556445
  validation accuracy:		81.52 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.542687
  validation loss:		0.572431
  validation accuracy:		81.41 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.545994
  validation loss:		0.580614
  validation accuracy:		81.41 %
Epoch 1833 of 2000 took 0.102s
  training loss:		0.545186
  validation loss:		0.577500
  validation accuracy:		81.63 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.553516
  validation loss:		0.570199
  validation accuracy:		81.30 %
Epoch 1835 of 2000 took 0.097s
  training loss:		0.545277
  validation loss:		0.559184
  validation accuracy:		81.74 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.552237
  validation loss:		0.565479
  validation accuracy:		81.96 %
Epoch 1837 of 2000 took 0.097s
  training loss:		0.544915
  validation loss:		0.560984
  validation accuracy:		81.30 %
Epoch 1838 of 2000 took 0.100s
  training loss:		0.551981
  validation loss:		0.575807
  validation accuracy:		80.98 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.548651
  validation loss:		0.564519
  validation accuracy:		81.30 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.548906
  validation loss:		0.560862
  validation accuracy:		81.30 %
Epoch 1841 of 2000 took 0.102s
  training loss:		0.557503
  validation loss:		0.553349
  validation accuracy:		81.85 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.555392
  validation loss:		0.557908
  validation accuracy:		81.09 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.560790
  validation loss:		0.561336
  validation accuracy:		81.74 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.547335
  validation loss:		0.560649
  validation accuracy:		81.20 %
Epoch 1845 of 2000 took 0.098s
  training loss:		0.546723
  validation loss:		0.552662
  validation accuracy:		81.52 %
Epoch 1846 of 2000 took 0.100s
  training loss:		0.559584
  validation loss:		0.567829
  validation accuracy:		81.41 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.547885
  validation loss:		0.573159
  validation accuracy:		81.30 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.550696
  validation loss:		0.551942
  validation accuracy:		81.41 %
Epoch 1849 of 2000 took 0.101s
  training loss:		0.555751
  validation loss:		0.573868
  validation accuracy:		81.74 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.551970
  validation loss:		0.563732
  validation accuracy:		81.52 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.552051
  validation loss:		0.557855
  validation accuracy:		81.09 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.550892
  validation loss:		0.567816
  validation accuracy:		81.41 %
Epoch 1853 of 2000 took 0.100s
  training loss:		0.543212
  validation loss:		0.579589
  validation accuracy:		81.20 %
Epoch 1854 of 2000 took 0.098s
  training loss:		0.547653
  validation loss:		0.582534
  validation accuracy:		81.63 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.551564
  validation loss:		0.588271
  validation accuracy:		80.22 %
Epoch 1856 of 2000 took 0.101s
  training loss:		0.554432
  validation loss:		0.568274
  validation accuracy:		81.41 %
Epoch 1857 of 2000 took 0.098s
  training loss:		0.543453
  validation loss:		0.571115
  validation accuracy:		81.41 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.548785
  validation loss:		0.589697
  validation accuracy:		81.09 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.554324
  validation loss:		0.578917
  validation accuracy:		81.52 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.547562
  validation loss:		0.580051
  validation accuracy:		81.20 %
Epoch 1861 of 2000 took 0.100s
  training loss:		0.534769
  validation loss:		0.552060
  validation accuracy:		82.17 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.542237
  validation loss:		0.558591
  validation accuracy:		81.20 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.545082
  validation loss:		0.562588
  validation accuracy:		81.09 %
Epoch 1864 of 2000 took 0.099s
  training loss:		0.549071
  validation loss:		0.553510
  validation accuracy:		81.41 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.551819
  validation loss:		0.556446
  validation accuracy:		81.52 %
Epoch 1866 of 2000 took 0.099s
  training loss:		0.550491
  validation loss:		0.558144
  validation accuracy:		81.52 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.545025
  validation loss:		0.591445
  validation accuracy:		81.20 %
Epoch 1868 of 2000 took 0.097s
  training loss:		0.555257
  validation loss:		0.556519
  validation accuracy:		81.52 %
Epoch 1869 of 2000 took 0.099s
  training loss:		0.552881
  validation loss:		0.558081
  validation accuracy:		82.07 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.545707
  validation loss:		0.578310
  validation accuracy:		81.74 %
Epoch 1871 of 2000 took 0.100s
  training loss:		0.544546
  validation loss:		0.563589
  validation accuracy:		81.30 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.541391
  validation loss:		0.562796
  validation accuracy:		81.20 %
Epoch 1873 of 2000 took 0.098s
  training loss:		0.547958
  validation loss:		0.556680
  validation accuracy:		81.20 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.547296
  validation loss:		0.568101
  validation accuracy:		81.74 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.549958
  validation loss:		0.561045
  validation accuracy:		81.20 %
Epoch 1876 of 2000 took 0.099s
  training loss:		0.546012
  validation loss:		0.555303
  validation accuracy:		81.41 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.544759
  validation loss:		0.567297
  validation accuracy:		81.52 %
Epoch 1878 of 2000 took 0.100s
  training loss:		0.554885
  validation loss:		0.574947
  validation accuracy:		81.52 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.550504
  validation loss:		0.576238
  validation accuracy:		81.52 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.546353
  validation loss:		0.566448
  validation accuracy:		81.41 %
Epoch 1881 of 2000 took 0.099s
  training loss:		0.560210
  validation loss:		0.561529
  validation accuracy:		81.09 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.542399
  validation loss:		0.552966
  validation accuracy:		81.63 %
Epoch 1883 of 2000 took 0.099s
  training loss:		0.542258
  validation loss:		0.562332
  validation accuracy:		80.98 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.547151
  validation loss:		0.573473
  validation accuracy:		80.98 %
Epoch 1885 of 2000 took 0.098s
  training loss:		0.550683
  validation loss:		0.564105
  validation accuracy:		81.20 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.549653
  validation loss:		0.582909
  validation accuracy:		81.30 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.547908
  validation loss:		0.565773
  validation accuracy:		82.07 %
Epoch 1888 of 2000 took 0.101s
  training loss:		0.549820
  validation loss:		0.567243
  validation accuracy:		81.85 %
Epoch 1889 of 2000 took 0.099s
  training loss:		0.543287
  validation loss:		0.582202
  validation accuracy:		80.65 %
Epoch 1890 of 2000 took 0.104s
  training loss:		0.552799
  validation loss:		0.556695
  validation accuracy:		81.63 %
Epoch 1891 of 2000 took 0.101s
  training loss:		0.544401
  validation loss:		0.556892
  validation accuracy:		81.52 %
Epoch 1892 of 2000 took 0.100s
  training loss:		0.551861
  validation loss:		0.557005
  validation accuracy:		81.63 %
Epoch 1893 of 2000 took 0.100s
  training loss:		0.552073
  validation loss:		0.582097
  validation accuracy:		81.41 %
Epoch 1894 of 2000 took 0.100s
  training loss:		0.541873
  validation loss:		0.566058
  validation accuracy:		81.09 %
Epoch 1895 of 2000 took 0.103s
  training loss:		0.549571
  validation loss:		0.559661
  validation accuracy:		81.52 %
Epoch 1896 of 2000 took 0.100s
  training loss:		0.550180
  validation loss:		0.561620
  validation accuracy:		81.30 %
Epoch 1897 of 2000 took 0.100s
  training loss:		0.553290
  validation loss:		0.569263
  validation accuracy:		81.30 %
Epoch 1898 of 2000 took 0.105s
  training loss:		0.548183
  validation loss:		0.581194
  validation accuracy:		81.41 %
Epoch 1899 of 2000 took 0.099s
  training loss:		0.552481
  validation loss:		0.560639
  validation accuracy:		81.63 %
Epoch 1900 of 2000 took 0.100s
  training loss:		0.547484
  validation loss:		0.571423
  validation accuracy:		81.20 %
Epoch 1901 of 2000 took 0.099s
  training loss:		0.545641
  validation loss:		0.580015
  validation accuracy:		81.41 %
Epoch 1902 of 2000 took 0.101s
  training loss:		0.542418
  validation loss:		0.559066
  validation accuracy:		81.52 %
Epoch 1903 of 2000 took 0.103s
  training loss:		0.546412
  validation loss:		0.562434
  validation accuracy:		81.52 %
Epoch 1904 of 2000 took 0.099s
  training loss:		0.537937
  validation loss:		0.563327
  validation accuracy:		81.30 %
Epoch 1905 of 2000 took 0.100s
  training loss:		0.549010
  validation loss:		0.567178
  validation accuracy:		80.98 %
Epoch 1906 of 2000 took 0.105s
  training loss:		0.547293
  validation loss:		0.569153
  validation accuracy:		81.41 %
Epoch 1907 of 2000 took 0.099s
  training loss:		0.537509
  validation loss:		0.561306
  validation accuracy:		81.96 %
Epoch 1908 of 2000 took 0.100s
  training loss:		0.540423
  validation loss:		0.552774
  validation accuracy:		81.30 %
Epoch 1909 of 2000 took 0.099s
  training loss:		0.551044
  validation loss:		0.559665
  validation accuracy:		81.09 %
Epoch 1910 of 2000 took 0.103s
  training loss:		0.551475
  validation loss:		0.587811
  validation accuracy:		81.30 %
Epoch 1911 of 2000 took 0.101s
  training loss:		0.549852
  validation loss:		0.605015
  validation accuracy:		80.00 %
Epoch 1912 of 2000 took 0.099s
  training loss:		0.551444
  validation loss:		0.561350
  validation accuracy:		80.98 %
Epoch 1913 of 2000 took 0.103s
  training loss:		0.551362
  validation loss:		0.560906
  validation accuracy:		81.30 %
Epoch 1914 of 2000 took 0.101s
  training loss:		0.543981
  validation loss:		0.569525
  validation accuracy:		81.85 %
Epoch 1915 of 2000 took 0.099s
  training loss:		0.542723
  validation loss:		0.585232
  validation accuracy:		81.30 %
Epoch 1916 of 2000 took 0.100s
  training loss:		0.552377
  validation loss:		0.552520
  validation accuracy:		81.96 %
Epoch 1917 of 2000 took 0.099s
  training loss:		0.546507
  validation loss:		0.557048
  validation accuracy:		81.41 %
Epoch 1918 of 2000 took 0.103s
  training loss:		0.552134
  validation loss:		0.550996
  validation accuracy:		81.74 %
Epoch 1919 of 2000 took 0.100s
  training loss:		0.553081
  validation loss:		0.586925
  validation accuracy:		80.87 %
Epoch 1920 of 2000 took 0.099s
  training loss:		0.545577
  validation loss:		0.562334
  validation accuracy:		81.20 %
Epoch 1921 of 2000 took 0.105s
  training loss:		0.546057
  validation loss:		0.565488
  validation accuracy:		82.07 %
Epoch 1922 of 2000 took 0.099s
  training loss:		0.544955
  validation loss:		0.559905
  validation accuracy:		81.41 %
Epoch 1923 of 2000 took 0.100s
  training loss:		0.559366
  validation loss:		0.569118
  validation accuracy:		80.87 %
Epoch 1924 of 2000 took 0.099s
  training loss:		0.550647
  validation loss:		0.582309
  validation accuracy:		81.41 %
Epoch 1925 of 2000 took 0.100s
  training loss:		0.549160
  validation loss:		0.562459
  validation accuracy:		81.41 %
Epoch 1926 of 2000 took 0.103s
  training loss:		0.554138
  validation loss:		0.553924
  validation accuracy:		81.41 %
Epoch 1927 of 2000 took 0.099s
  training loss:		0.553591
  validation loss:		0.557713
  validation accuracy:		81.63 %
Epoch 1928 of 2000 took 0.098s
  training loss:		0.554274
  validation loss:		0.559238
  validation accuracy:		80.98 %
Epoch 1929 of 2000 took 0.102s
  training loss:		0.545643
  validation loss:		0.579640
  validation accuracy:		81.63 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.545331
  validation loss:		0.569891
  validation accuracy:		82.17 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.548577
  validation loss:		0.559824
  validation accuracy:		81.74 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.550675
  validation loss:		0.568727
  validation accuracy:		81.41 %
Epoch 1933 of 2000 took 0.098s
  training loss:		0.555921
  validation loss:		0.555786
  validation accuracy:		81.41 %
Epoch 1934 of 2000 took 0.099s
  training loss:		0.548237
  validation loss:		0.558080
  validation accuracy:		81.41 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.549884
  validation loss:		0.587791
  validation accuracy:		80.65 %
Epoch 1936 of 2000 took 0.098s
  training loss:		0.542749
  validation loss:		0.578445
  validation accuracy:		81.63 %
Epoch 1937 of 2000 took 0.100s
  training loss:		0.554858
  validation loss:		0.572835
  validation accuracy:		81.74 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.553633
  validation loss:		0.570670
  validation accuracy:		81.09 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.546573
  validation loss:		0.556087
  validation accuracy:		81.85 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.543791
  validation loss:		0.578397
  validation accuracy:		81.30 %
Epoch 1941 of 2000 took 0.101s
  training loss:		0.554875
  validation loss:		0.583646
  validation accuracy:		81.30 %
Epoch 1942 of 2000 took 0.097s
  training loss:		0.555442
  validation loss:		0.554521
  validation accuracy:		82.17 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.546300
  validation loss:		0.565059
  validation accuracy:		80.98 %
Epoch 1944 of 2000 took 0.102s
  training loss:		0.544691
  validation loss:		0.564792
  validation accuracy:		80.98 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.555779
  validation loss:		0.567020
  validation accuracy:		81.63 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.548705
  validation loss:		0.559690
  validation accuracy:		81.74 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.554907
  validation loss:		0.559987
  validation accuracy:		80.54 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.554027
  validation loss:		0.560864
  validation accuracy:		81.20 %
Epoch 1949 of 2000 took 0.100s
  training loss:		0.542886
  validation loss:		0.561156
  validation accuracy:		81.41 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.549763
  validation loss:		0.560716
  validation accuracy:		81.52 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.551222
  validation loss:		0.561470
  validation accuracy:		81.52 %
Epoch 1952 of 2000 took 0.102s
  training loss:		0.550809
  validation loss:		0.578178
  validation accuracy:		81.63 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.539263
  validation loss:		0.554547
  validation accuracy:		81.74 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.549084
  validation loss:		0.560056
  validation accuracy:		81.30 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.548793
  validation loss:		0.561288
  validation accuracy:		81.30 %
Epoch 1956 of 2000 took 0.098s
  training loss:		0.546905
  validation loss:		0.568872
  validation accuracy:		81.85 %
Epoch 1957 of 2000 took 0.100s
  training loss:		0.556240
  validation loss:		0.557893
  validation accuracy:		80.98 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.547929
  validation loss:		0.564453
  validation accuracy:		80.98 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.548371
  validation loss:		0.569505
  validation accuracy:		81.30 %
Epoch 1960 of 2000 took 0.101s
  training loss:		0.548495
  validation loss:		0.576661
  validation accuracy:		81.74 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.548754
  validation loss:		0.569860
  validation accuracy:		81.74 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.551942
  validation loss:		0.562426
  validation accuracy:		80.98 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.540594
  validation loss:		0.561115
  validation accuracy:		81.30 %
Epoch 1964 of 2000 took 0.101s
  training loss:		0.537879
  validation loss:		0.568758
  validation accuracy:		81.30 %
Epoch 1965 of 2000 took 0.098s
  training loss:		0.539932
  validation loss:		0.566727
  validation accuracy:		81.52 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.550447
  validation loss:		0.557084
  validation accuracy:		81.85 %
Epoch 1967 of 2000 took 0.101s
  training loss:		0.545252
  validation loss:		0.566271
  validation accuracy:		81.30 %
Epoch 1968 of 2000 took 0.097s
  training loss:		0.550206
  validation loss:		0.573659
  validation accuracy:		81.74 %
Epoch 1969 of 2000 took 0.097s
  training loss:		0.553815
  validation loss:		0.555473
  validation accuracy:		81.41 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.552768
  validation loss:		0.584944
  validation accuracy:		81.41 %
Epoch 1971 of 2000 took 0.097s
  training loss:		0.556542
  validation loss:		0.566185
  validation accuracy:		81.74 %
Epoch 1972 of 2000 took 0.100s
  training loss:		0.548484
  validation loss:		0.561357
  validation accuracy:		81.20 %
Epoch 1973 of 2000 took 0.097s
  training loss:		0.550186
  validation loss:		0.561310
  validation accuracy:		81.63 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.541497
  validation loss:		0.561884
  validation accuracy:		80.76 %
Epoch 1975 of 2000 took 0.102s
  training loss:		0.553245
  validation loss:		0.580375
  validation accuracy:		81.52 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.547709
  validation loss:		0.565110
  validation accuracy:		81.52 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.547689
  validation loss:		0.566111
  validation accuracy:		81.09 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.540722
  validation loss:		0.559933
  validation accuracy:		81.20 %
Epoch 1979 of 2000 took 0.098s
  training loss:		0.549186
  validation loss:		0.576918
  validation accuracy:		81.41 %
Epoch 1980 of 2000 took 0.100s
  training loss:		0.539751
  validation loss:		0.566757
  validation accuracy:		81.74 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.544956
  validation loss:		0.567539
  validation accuracy:		81.63 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.545241
  validation loss:		0.553933
  validation accuracy:		81.74 %
Epoch 1983 of 2000 took 0.102s
  training loss:		0.548148
  validation loss:		0.557854
  validation accuracy:		81.52 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.549891
  validation loss:		0.592975
  validation accuracy:		81.30 %
Epoch 1985 of 2000 took 0.097s
  training loss:		0.553432
  validation loss:		0.557898
  validation accuracy:		81.20 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.546326
  validation loss:		0.560540
  validation accuracy:		80.54 %
Epoch 1987 of 2000 took 0.099s
  training loss:		0.541619
  validation loss:		0.555730
  validation accuracy:		81.96 %
Epoch 1988 of 2000 took 0.098s
  training loss:		0.552139
  validation loss:		0.556140
  validation accuracy:		81.63 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.539490
  validation loss:		0.556421
  validation accuracy:		81.96 %
Epoch 1990 of 2000 took 0.099s
  training loss:		0.546630
  validation loss:		0.562218
  validation accuracy:		81.41 %
Epoch 1991 of 2000 took 0.099s
  training loss:		0.549950
  validation loss:		0.558518
  validation accuracy:		81.30 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.541222
  validation loss:		0.560097
  validation accuracy:		81.63 %
Epoch 1993 of 2000 took 0.097s
  training loss:		0.547789
  validation loss:		0.579260
  validation accuracy:		80.98 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.545943
  validation loss:		0.558552
  validation accuracy:		81.20 %
Epoch 1995 of 2000 took 0.100s
  training loss:		0.554843
  validation loss:		0.566683
  validation accuracy:		81.63 %
Epoch 1996 of 2000 took 0.097s
  training loss:		0.555936
  validation loss:		0.556573
  validation accuracy:		81.63 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.539372
  validation loss:		0.558487
  validation accuracy:		81.52 %
Epoch 1998 of 2000 took 0.102s
  training loss:		0.536148
  validation loss:		0.586772
  validation accuracy:		80.43 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.548439
  validation loss:		0.561315
  validation accuracy:		81.63 %
Epoch 2000 of 2000 took 0.097s
  training loss:		0.548292
  validation loss:		0.556409
  validation accuracy:		81.52 %
Final results:
  test loss:			0.798728
  test accuracy:		74.81 %
