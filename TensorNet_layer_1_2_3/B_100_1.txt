Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.106s
  training loss:		3.000964
  validation loss:		2.958686
  validation accuracy:		8.59 %
Epoch 2 of 2000 took 0.103s
  training loss:		2.930361
  validation loss:		2.861823
  validation accuracy:		11.96 %
Epoch 3 of 2000 took 0.104s
  training loss:		2.851685
  validation loss:		2.766484
  validation accuracy:		12.28 %
Epoch 4 of 2000 took 0.103s
  training loss:		2.777183
  validation loss:		2.677607
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.106s
  training loss:		2.708735
  validation loss:		2.596190
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.103s
  training loss:		2.645471
  validation loss:		2.523641
  validation accuracy:		12.93 %
Epoch 7 of 2000 took 0.103s
  training loss:		2.591480
  validation loss:		2.458798
  validation accuracy:		12.93 %
Epoch 8 of 2000 took 0.103s
  training loss:		2.539913
  validation loss:		2.400799
  validation accuracy:		12.93 %
Epoch 9 of 2000 took 0.103s
  training loss:		2.487342
  validation loss:		2.348210
  validation accuracy:		12.50 %
Epoch 10 of 2000 took 0.103s
  training loss:		2.437145
  validation loss:		2.301770
  validation accuracy:		12.17 %
Epoch 11 of 2000 took 0.103s
  training loss:		2.392288
  validation loss:		2.263523
  validation accuracy:		13.59 %
Epoch 12 of 2000 took 0.103s
  training loss:		2.347745
  validation loss:		2.234018
  validation accuracy:		16.96 %
Epoch 13 of 2000 took 0.103s
  training loss:		2.316364
  validation loss:		2.215236
  validation accuracy:		21.52 %
Epoch 14 of 2000 took 0.103s
  training loss:		2.290635
  validation loss:		2.202905
  validation accuracy:		32.61 %
Epoch 15 of 2000 took 0.103s
  training loss:		2.272093
  validation loss:		2.189972
  validation accuracy:		32.07 %
Epoch 16 of 2000 took 0.103s
  training loss:		2.257721
  validation loss:		2.180753
  validation accuracy:		30.00 %
Epoch 17 of 2000 took 0.102s
  training loss:		2.246199
  validation loss:		2.172419
  validation accuracy:		32.93 %
Epoch 18 of 2000 took 0.105s
  training loss:		2.235652
  validation loss:		2.163180
  validation accuracy:		31.74 %
Epoch 19 of 2000 took 0.104s
  training loss:		2.223599
  validation loss:		2.150782
  validation accuracy:		30.76 %
Epoch 20 of 2000 took 0.100s
  training loss:		2.213974
  validation loss:		2.135393
  validation accuracy:		30.98 %
Epoch 21 of 2000 took 0.106s
  training loss:		2.204090
  validation loss:		2.129406
  validation accuracy:		32.39 %
Epoch 22 of 2000 took 0.104s
  training loss:		2.193479
  validation loss:		2.117277
  validation accuracy:		36.96 %
Epoch 23 of 2000 took 0.103s
  training loss:		2.179298
  validation loss:		2.094194
  validation accuracy:		30.98 %
Epoch 24 of 2000 took 0.103s
  training loss:		2.165212
  validation loss:		2.079099
  validation accuracy:		31.74 %
Epoch 25 of 2000 took 0.103s
  training loss:		2.149655
  validation loss:		2.064802
  validation accuracy:		35.54 %
Epoch 26 of 2000 took 0.103s
  training loss:		2.135396
  validation loss:		2.048621
  validation accuracy:		32.83 %
Epoch 27 of 2000 took 0.103s
  training loss:		2.115620
  validation loss:		2.021617
  validation accuracy:		35.54 %
Epoch 28 of 2000 took 0.103s
  training loss:		2.095411
  validation loss:		1.998420
  validation accuracy:		36.20 %
Epoch 29 of 2000 took 0.103s
  training loss:		2.073120
  validation loss:		1.976447
  validation accuracy:		38.70 %
Epoch 30 of 2000 took 0.103s
  training loss:		2.048499
  validation loss:		1.947974
  validation accuracy:		39.13 %
Epoch 31 of 2000 took 0.103s
  training loss:		2.022524
  validation loss:		1.917818
  validation accuracy:		37.07 %
Epoch 32 of 2000 took 0.103s
  training loss:		1.995226
  validation loss:		1.887488
  validation accuracy:		39.35 %
Epoch 33 of 2000 took 0.104s
  training loss:		1.965040
  validation loss:		1.857840
  validation accuracy:		42.61 %
Epoch 34 of 2000 took 0.103s
  training loss:		1.933893
  validation loss:		1.820763
  validation accuracy:		42.17 %
Epoch 35 of 2000 took 0.103s
  training loss:		1.901102
  validation loss:		1.787373
  validation accuracy:		41.96 %
Epoch 36 of 2000 took 0.103s
  training loss:		1.873943
  validation loss:		1.757792
  validation accuracy:		44.78 %
Epoch 37 of 2000 took 0.103s
  training loss:		1.841936
  validation loss:		1.728834
  validation accuracy:		47.83 %
Epoch 38 of 2000 took 0.103s
  training loss:		1.807506
  validation loss:		1.690342
  validation accuracy:		46.30 %
Epoch 39 of 2000 took 0.103s
  training loss:		1.774112
  validation loss:		1.656243
  validation accuracy:		48.80 %
Epoch 40 of 2000 took 0.106s
  training loss:		1.746290
  validation loss:		1.632133
  validation accuracy:		50.98 %
Epoch 41 of 2000 took 0.103s
  training loss:		1.720310
  validation loss:		1.605598
  validation accuracy:		53.04 %
Epoch 42 of 2000 took 0.103s
  training loss:		1.684397
  validation loss:		1.570012
  validation accuracy:		49.35 %
Epoch 43 of 2000 took 0.103s
  training loss:		1.664261
  validation loss:		1.543472
  validation accuracy:		53.48 %
Epoch 44 of 2000 took 0.103s
  training loss:		1.628921
  validation loss:		1.520274
  validation accuracy:		55.87 %
Epoch 45 of 2000 took 0.103s
  training loss:		1.611247
  validation loss:		1.486351
  validation accuracy:		55.33 %
Epoch 46 of 2000 took 0.103s
  training loss:		1.583000
  validation loss:		1.468627
  validation accuracy:		55.65 %
Epoch 47 of 2000 took 0.103s
  training loss:		1.547969
  validation loss:		1.439756
  validation accuracy:		55.00 %
Epoch 48 of 2000 took 0.103s
  training loss:		1.529895
  validation loss:		1.402432
  validation accuracy:		56.96 %
Epoch 49 of 2000 took 0.103s
  training loss:		1.498003
  validation loss:		1.386447
  validation accuracy:		57.61 %
Epoch 50 of 2000 took 0.103s
  training loss:		1.473321
  validation loss:		1.362871
  validation accuracy:		58.70 %
Epoch 51 of 2000 took 0.103s
  training loss:		1.442438
  validation loss:		1.329196
  validation accuracy:		59.78 %
Epoch 52 of 2000 took 0.103s
  training loss:		1.421526
  validation loss:		1.301738
  validation accuracy:		59.57 %
Epoch 53 of 2000 took 0.103s
  training loss:		1.393519
  validation loss:		1.282934
  validation accuracy:		60.65 %
Epoch 54 of 2000 took 0.103s
  training loss:		1.366739
  validation loss:		1.255407
  validation accuracy:		59.57 %
Epoch 55 of 2000 took 0.103s
  training loss:		1.337456
  validation loss:		1.231043
  validation accuracy:		60.22 %
Epoch 56 of 2000 took 0.103s
  training loss:		1.317897
  validation loss:		1.208725
  validation accuracy:		61.63 %
Epoch 57 of 2000 took 0.103s
  training loss:		1.294730
  validation loss:		1.180560
  validation accuracy:		61.63 %
Epoch 58 of 2000 took 0.103s
  training loss:		1.273093
  validation loss:		1.166210
  validation accuracy:		62.72 %
Epoch 59 of 2000 took 0.103s
  training loss:		1.238057
  validation loss:		1.136288
  validation accuracy:		63.04 %
Epoch 60 of 2000 took 0.103s
  training loss:		1.222430
  validation loss:		1.118139
  validation accuracy:		63.70 %
Epoch 61 of 2000 took 0.106s
  training loss:		1.195904
  validation loss:		1.104342
  validation accuracy:		63.70 %
Epoch 62 of 2000 took 0.105s
  training loss:		1.177965
  validation loss:		1.077674
  validation accuracy:		65.22 %
Epoch 63 of 2000 took 0.103s
  training loss:		1.153636
  validation loss:		1.053282
  validation accuracy:		66.63 %
Epoch 64 of 2000 took 0.103s
  training loss:		1.131906
  validation loss:		1.050084
  validation accuracy:		65.54 %
Epoch 65 of 2000 took 0.103s
  training loss:		1.114575
  validation loss:		1.022809
  validation accuracy:		66.52 %
Epoch 66 of 2000 took 0.103s
  training loss:		1.095242
  validation loss:		1.015084
  validation accuracy:		67.83 %
Epoch 67 of 2000 took 0.103s
  training loss:		1.076135
  validation loss:		1.000324
  validation accuracy:		67.83 %
Epoch 68 of 2000 took 0.103s
  training loss:		1.047453
  validation loss:		0.973089
  validation accuracy:		69.13 %
Epoch 69 of 2000 took 0.103s
  training loss:		1.041313
  validation loss:		0.955042
  validation accuracy:		70.00 %
Epoch 70 of 2000 took 0.103s
  training loss:		1.025510
  validation loss:		0.952289
  validation accuracy:		69.46 %
Epoch 71 of 2000 took 0.103s
  training loss:		1.000581
  validation loss:		0.926449
  validation accuracy:		70.33 %
Epoch 72 of 2000 took 0.103s
  training loss:		0.995309
  validation loss:		0.909951
  validation accuracy:		70.98 %
Epoch 73 of 2000 took 0.103s
  training loss:		0.977410
  validation loss:		0.921513
  validation accuracy:		71.41 %
Epoch 74 of 2000 took 0.103s
  training loss:		0.965253
  validation loss:		0.897718
  validation accuracy:		71.63 %
Epoch 75 of 2000 took 0.103s
  training loss:		0.944756
  validation loss:		0.891370
  validation accuracy:		71.63 %
Epoch 76 of 2000 took 0.103s
  training loss:		0.932156
  validation loss:		0.860932
  validation accuracy:		73.26 %
Epoch 77 of 2000 took 0.103s
  training loss:		0.919736
  validation loss:		0.843554
  validation accuracy:		73.59 %
Epoch 78 of 2000 took 0.103s
  training loss:		0.905395
  validation loss:		0.841759
  validation accuracy:		74.24 %
Epoch 79 of 2000 took 0.103s
  training loss:		0.897141
  validation loss:		0.845268
  validation accuracy:		73.80 %
Epoch 80 of 2000 took 0.103s
  training loss:		0.879174
  validation loss:		0.825569
  validation accuracy:		75.11 %
Epoch 81 of 2000 took 0.103s
  training loss:		0.874662
  validation loss:		0.800673
  validation accuracy:		75.33 %
Epoch 82 of 2000 took 0.103s
  training loss:		0.853810
  validation loss:		0.792731
  validation accuracy:		75.76 %
Epoch 83 of 2000 took 0.103s
  training loss:		0.848713
  validation loss:		0.782585
  validation accuracy:		76.30 %
Epoch 84 of 2000 took 0.103s
  training loss:		0.841206
  validation loss:		0.790115
  validation accuracy:		75.98 %
Epoch 85 of 2000 took 0.106s
  training loss:		0.829708
  validation loss:		0.763751
  validation accuracy:		76.85 %
Epoch 86 of 2000 took 0.103s
  training loss:		0.821882
  validation loss:		0.752957
  validation accuracy:		77.07 %
Epoch 87 of 2000 took 0.103s
  training loss:		0.807130
  validation loss:		0.768933
  validation accuracy:		77.07 %
Epoch 88 of 2000 took 0.103s
  training loss:		0.800206
  validation loss:		0.730458
  validation accuracy:		77.83 %
Epoch 89 of 2000 took 0.103s
  training loss:		0.788740
  validation loss:		0.745049
  validation accuracy:		77.17 %
Epoch 90 of 2000 took 0.103s
  training loss:		0.773988
  validation loss:		0.750525
  validation accuracy:		76.52 %
Epoch 91 of 2000 took 0.104s
  training loss:		0.772916
  validation loss:		0.723001
  validation accuracy:		78.26 %
Epoch 92 of 2000 took 0.103s
  training loss:		0.760772
  validation loss:		0.703265
  validation accuracy:		79.02 %
Epoch 93 of 2000 took 0.103s
  training loss:		0.750845
  validation loss:		0.689019
  validation accuracy:		78.91 %
Epoch 94 of 2000 took 0.103s
  training loss:		0.741723
  validation loss:		0.734310
  validation accuracy:		77.72 %
Epoch 95 of 2000 took 0.103s
  training loss:		0.744116
  validation loss:		0.694769
  validation accuracy:		78.26 %
Epoch 96 of 2000 took 0.103s
  training loss:		0.714948
  validation loss:		0.692116
  validation accuracy:		78.37 %
Epoch 97 of 2000 took 0.103s
  training loss:		0.709965
  validation loss:		0.679619
  validation accuracy:		78.37 %
Epoch 98 of 2000 took 0.103s
  training loss:		0.696470
  validation loss:		0.660103
  validation accuracy:		80.54 %
Epoch 99 of 2000 took 0.103s
  training loss:		0.699713
  validation loss:		0.673383
  validation accuracy:		79.67 %
Epoch 100 of 2000 took 0.103s
  training loss:		0.680821
  validation loss:		0.639506
  validation accuracy:		80.43 %
Epoch 101 of 2000 took 0.103s
  training loss:		0.679942
  validation loss:		0.649094
  validation accuracy:		80.43 %
Epoch 102 of 2000 took 0.103s
  training loss:		0.668042
  validation loss:		0.647214
  validation accuracy:		80.22 %
Epoch 103 of 2000 took 0.103s
  training loss:		0.653549
  validation loss:		0.623308
  validation accuracy:		81.09 %
Epoch 104 of 2000 took 0.103s
  training loss:		0.645409
  validation loss:		0.626959
  validation accuracy:		80.87 %
Epoch 105 of 2000 took 0.103s
  training loss:		0.639996
  validation loss:		0.616508
  validation accuracy:		81.52 %
Epoch 106 of 2000 took 0.103s
  training loss:		0.642429
  validation loss:		0.616097
  validation accuracy:		81.85 %
Epoch 107 of 2000 took 0.103s
  training loss:		0.634102
  validation loss:		0.595023
  validation accuracy:		82.28 %
Epoch 108 of 2000 took 0.103s
  training loss:		0.622897
  validation loss:		0.587525
  validation accuracy:		82.72 %
Epoch 109 of 2000 took 0.103s
  training loss:		0.615245
  validation loss:		0.592820
  validation accuracy:		81.63 %
Epoch 110 of 2000 took 0.106s
  training loss:		0.604730
  validation loss:		0.588109
  validation accuracy:		82.17 %
Epoch 111 of 2000 took 0.103s
  training loss:		0.597087
  validation loss:		0.569759
  validation accuracy:		82.61 %
Epoch 112 of 2000 took 0.103s
  training loss:		0.590982
  validation loss:		0.581148
  validation accuracy:		82.28 %
Epoch 113 of 2000 took 0.103s
  training loss:		0.584559
  validation loss:		0.562742
  validation accuracy:		82.83 %
Epoch 114 of 2000 took 0.103s
  training loss:		0.582752
  validation loss:		0.583467
  validation accuracy:		82.07 %
Epoch 115 of 2000 took 0.103s
  training loss:		0.580613
  validation loss:		0.562125
  validation accuracy:		83.15 %
Epoch 116 of 2000 took 0.103s
  training loss:		0.567298
  validation loss:		0.541626
  validation accuracy:		83.91 %
Epoch 117 of 2000 took 0.103s
  training loss:		0.562695
  validation loss:		0.541225
  validation accuracy:		83.26 %
Epoch 118 of 2000 took 0.103s
  training loss:		0.559468
  validation loss:		0.559722
  validation accuracy:		82.93 %
Epoch 119 of 2000 took 0.103s
  training loss:		0.552970
  validation loss:		0.525114
  validation accuracy:		84.57 %
Epoch 120 of 2000 took 0.104s
  training loss:		0.542808
  validation loss:		0.542507
  validation accuracy:		82.83 %
Epoch 121 of 2000 took 0.103s
  training loss:		0.546406
  validation loss:		0.534573
  validation accuracy:		84.13 %
Epoch 122 of 2000 took 0.103s
  training loss:		0.541618
  validation loss:		0.513721
  validation accuracy:		84.46 %
Epoch 123 of 2000 took 0.103s
  training loss:		0.527186
  validation loss:		0.506973
  validation accuracy:		84.89 %
Epoch 124 of 2000 took 0.103s
  training loss:		0.533086
  validation loss:		0.508824
  validation accuracy:		84.46 %
Epoch 125 of 2000 took 0.103s
  training loss:		0.524290
  validation loss:		0.543008
  validation accuracy:		83.15 %
Epoch 126 of 2000 took 0.103s
  training loss:		0.512314
  validation loss:		0.509299
  validation accuracy:		84.13 %
Epoch 127 of 2000 took 0.103s
  training loss:		0.508290
  validation loss:		0.507441
  validation accuracy:		83.91 %
Epoch 128 of 2000 took 0.103s
  training loss:		0.508692
  validation loss:		0.485924
  validation accuracy:		85.22 %
Epoch 129 of 2000 took 0.103s
  training loss:		0.505277
  validation loss:		0.491407
  validation accuracy:		85.00 %
Epoch 130 of 2000 took 0.103s
  training loss:		0.503605
  validation loss:		0.514639
  validation accuracy:		83.80 %
Epoch 131 of 2000 took 0.103s
  training loss:		0.505702
  validation loss:		0.493192
  validation accuracy:		84.89 %
Epoch 132 of 2000 took 0.103s
  training loss:		0.495131
  validation loss:		0.484770
  validation accuracy:		84.24 %
Epoch 133 of 2000 took 0.103s
  training loss:		0.490463
  validation loss:		0.497311
  validation accuracy:		84.35 %
Epoch 134 of 2000 took 0.103s
  training loss:		0.491358
  validation loss:		0.472464
  validation accuracy:		85.00 %
Epoch 135 of 2000 took 0.103s
  training loss:		0.482850
  validation loss:		0.500435
  validation accuracy:		84.24 %
Epoch 136 of 2000 took 0.103s
  training loss:		0.479534
  validation loss:		0.460932
  validation accuracy:		85.98 %
Epoch 137 of 2000 took 0.103s
  training loss:		0.469367
  validation loss:		0.468602
  validation accuracy:		85.22 %
Epoch 138 of 2000 took 0.106s
  training loss:		0.472465
  validation loss:		0.455720
  validation accuracy:		85.76 %
Epoch 139 of 2000 took 0.104s
  training loss:		0.468655
  validation loss:		0.456994
  validation accuracy:		85.76 %
Epoch 140 of 2000 took 0.103s
  training loss:		0.462776
  validation loss:		0.450830
  validation accuracy:		86.20 %
Epoch 141 of 2000 took 0.103s
  training loss:		0.466870
  validation loss:		0.453822
  validation accuracy:		86.09 %
Epoch 142 of 2000 took 0.103s
  training loss:		0.467892
  validation loss:		0.477886
  validation accuracy:		84.35 %
Epoch 143 of 2000 took 0.103s
  training loss:		0.457104
  validation loss:		0.442634
  validation accuracy:		86.41 %
Epoch 144 of 2000 took 0.103s
  training loss:		0.460089
  validation loss:		0.439769
  validation accuracy:		85.98 %
Epoch 145 of 2000 took 0.103s
  training loss:		0.454491
  validation loss:		0.436515
  validation accuracy:		86.85 %
Epoch 146 of 2000 took 0.103s
  training loss:		0.452379
  validation loss:		0.441997
  validation accuracy:		85.98 %
Epoch 147 of 2000 took 0.103s
  training loss:		0.442759
  validation loss:		0.445750
  validation accuracy:		85.98 %
Epoch 148 of 2000 took 0.103s
  training loss:		0.440563
  validation loss:		0.452234
  validation accuracy:		85.11 %
Epoch 149 of 2000 took 0.103s
  training loss:		0.440786
  validation loss:		0.436282
  validation accuracy:		86.63 %
Epoch 150 of 2000 took 0.103s
  training loss:		0.428885
  validation loss:		0.446218
  validation accuracy:		85.87 %
Epoch 151 of 2000 took 0.103s
  training loss:		0.441393
  validation loss:		0.439603
  validation accuracy:		85.54 %
Epoch 152 of 2000 took 0.103s
  training loss:		0.430723
  validation loss:		0.432274
  validation accuracy:		86.09 %
Epoch 153 of 2000 took 0.103s
  training loss:		0.433261
  validation loss:		0.419513
  validation accuracy:		86.96 %
Epoch 154 of 2000 took 0.103s
  training loss:		0.438892
  validation loss:		0.420766
  validation accuracy:		87.07 %
Epoch 155 of 2000 took 0.103s
  training loss:		0.430156
  validation loss:		0.421065
  validation accuracy:		86.74 %
Epoch 156 of 2000 took 0.103s
  training loss:		0.429113
  validation loss:		0.422445
  validation accuracy:		86.85 %
Epoch 157 of 2000 took 0.103s
  training loss:		0.429877
  validation loss:		0.423234
  validation accuracy:		86.41 %
Epoch 158 of 2000 took 0.103s
  training loss:		0.425013
  validation loss:		0.430350
  validation accuracy:		87.50 %
Epoch 159 of 2000 took 0.103s
  training loss:		0.419830
  validation loss:		0.432296
  validation accuracy:		86.20 %
Epoch 160 of 2000 took 0.103s
  training loss:		0.422242
  validation loss:		0.419128
  validation accuracy:		86.96 %
Epoch 161 of 2000 took 0.103s
  training loss:		0.418617
  validation loss:		0.407379
  validation accuracy:		87.07 %
Epoch 162 of 2000 took 0.103s
  training loss:		0.416580
  validation loss:		0.437107
  validation accuracy:		86.30 %
Epoch 163 of 2000 took 0.103s
  training loss:		0.414543
  validation loss:		0.417237
  validation accuracy:		86.96 %
Epoch 164 of 2000 took 0.103s
  training loss:		0.409543
  validation loss:		0.400553
  validation accuracy:		87.50 %
Epoch 165 of 2000 took 0.103s
  training loss:		0.407161
  validation loss:		0.402523
  validation accuracy:		87.50 %
Epoch 166 of 2000 took 0.103s
  training loss:		0.409836
  validation loss:		0.417839
  validation accuracy:		86.96 %
Epoch 167 of 2000 took 0.103s
  training loss:		0.407866
  validation loss:		0.412401
  validation accuracy:		87.17 %
Epoch 168 of 2000 took 0.103s
  training loss:		0.408112
  validation loss:		0.409883
  validation accuracy:		87.28 %
Epoch 169 of 2000 took 0.106s
  training loss:		0.407915
  validation loss:		0.409389
  validation accuracy:		86.41 %
Epoch 170 of 2000 took 0.103s
  training loss:		0.405784
  validation loss:		0.405134
  validation accuracy:		87.50 %
Epoch 171 of 2000 took 0.103s
  training loss:		0.409306
  validation loss:		0.394315
  validation accuracy:		87.50 %
Epoch 172 of 2000 took 0.103s
  training loss:		0.399725
  validation loss:		0.404163
  validation accuracy:		87.39 %
Epoch 173 of 2000 took 0.103s
  training loss:		0.401140
  validation loss:		0.396039
  validation accuracy:		87.72 %
Epoch 174 of 2000 took 0.103s
  training loss:		0.396358
  validation loss:		0.395825
  validation accuracy:		87.50 %
Epoch 175 of 2000 took 0.103s
  training loss:		0.391760
  validation loss:		0.415661
  validation accuracy:		86.96 %
Epoch 176 of 2000 took 0.103s
  training loss:		0.398629
  validation loss:		0.408820
  validation accuracy:		87.17 %
Epoch 177 of 2000 took 0.103s
  training loss:		0.398626
  validation loss:		0.386289
  validation accuracy:		87.39 %
Epoch 178 of 2000 took 0.103s
  training loss:		0.387701
  validation loss:		0.392198
  validation accuracy:		87.93 %
Epoch 179 of 2000 took 0.104s
  training loss:		0.392550
  validation loss:		0.386682
  validation accuracy:		87.72 %
Epoch 180 of 2000 took 0.103s
  training loss:		0.396357
  validation loss:		0.388962
  validation accuracy:		87.39 %
Epoch 181 of 2000 took 0.103s
  training loss:		0.388699
  validation loss:		0.389712
  validation accuracy:		87.50 %
Epoch 182 of 2000 took 0.103s
  training loss:		0.389368
  validation loss:		0.382286
  validation accuracy:		87.72 %
Epoch 183 of 2000 took 0.102s
  training loss:		0.391464
  validation loss:		0.380461
  validation accuracy:		87.72 %
Epoch 184 of 2000 took 0.101s
  training loss:		0.388773
  validation loss:		0.391061
  validation accuracy:		87.72 %
Epoch 185 of 2000 took 0.109s
  training loss:		0.375155
  validation loss:		0.386039
  validation accuracy:		88.15 %
Epoch 186 of 2000 took 0.108s
  training loss:		0.381620
  validation loss:		0.391728
  validation accuracy:		87.61 %
Epoch 187 of 2000 took 0.105s
  training loss:		0.386862
  validation loss:		0.400859
  validation accuracy:		86.96 %
Epoch 188 of 2000 took 0.106s
  training loss:		0.385499
  validation loss:		0.383792
  validation accuracy:		87.72 %
Epoch 189 of 2000 took 0.104s
  training loss:		0.378078
  validation loss:		0.394336
  validation accuracy:		87.50 %
Epoch 190 of 2000 took 0.109s
  training loss:		0.381410
  validation loss:		0.384927
  validation accuracy:		87.39 %
Epoch 191 of 2000 took 0.106s
  training loss:		0.376096
  validation loss:		0.389118
  validation accuracy:		87.93 %
Epoch 192 of 2000 took 0.106s
  training loss:		0.382574
  validation loss:		0.406487
  validation accuracy:		87.39 %
Epoch 193 of 2000 took 0.106s
  training loss:		0.380174
  validation loss:		0.388349
  validation accuracy:		87.50 %
Epoch 194 of 2000 took 0.106s
  training loss:		0.376324
  validation loss:		0.395997
  validation accuracy:		87.07 %
Epoch 195 of 2000 took 0.106s
  training loss:		0.377003
  validation loss:		0.392144
  validation accuracy:		87.39 %
Epoch 196 of 2000 took 0.106s
  training loss:		0.371197
  validation loss:		0.378484
  validation accuracy:		88.15 %
Epoch 197 of 2000 took 0.106s
  training loss:		0.365998
  validation loss:		0.407386
  validation accuracy:		87.17 %
Epoch 198 of 2000 took 0.106s
  training loss:		0.367577
  validation loss:		0.371292
  validation accuracy:		87.83 %
Epoch 199 of 2000 took 0.106s
  training loss:		0.375314
  validation loss:		0.381152
  validation accuracy:		88.04 %
Epoch 200 of 2000 took 0.106s
  training loss:		0.377153
  validation loss:		0.395602
  validation accuracy:		86.63 %
Epoch 201 of 2000 took 0.106s
  training loss:		0.366036
  validation loss:		0.381954
  validation accuracy:		87.72 %
Epoch 202 of 2000 took 0.106s
  training loss:		0.370636
  validation loss:		0.375127
  validation accuracy:		88.37 %
Epoch 203 of 2000 took 0.110s
  training loss:		0.364673
  validation loss:		0.378922
  validation accuracy:		87.61 %
Epoch 204 of 2000 took 0.106s
  training loss:		0.368327
  validation loss:		0.382573
  validation accuracy:		87.39 %
Epoch 205 of 2000 took 0.106s
  training loss:		0.373058
  validation loss:		0.390252
  validation accuracy:		86.74 %
Epoch 206 of 2000 took 0.107s
  training loss:		0.375304
  validation loss:		0.368471
  validation accuracy:		87.93 %
Epoch 207 of 2000 took 0.107s
  training loss:		0.363684
  validation loss:		0.369094
  validation accuracy:		88.04 %
Epoch 208 of 2000 took 0.106s
  training loss:		0.364149
  validation loss:		0.389143
  validation accuracy:		87.93 %
Epoch 209 of 2000 took 0.106s
  training loss:		0.358870
  validation loss:		0.381704
  validation accuracy:		87.50 %
Epoch 210 of 2000 took 0.106s
  training loss:		0.359190
  validation loss:		0.375767
  validation accuracy:		88.04 %
Epoch 211 of 2000 took 0.106s
  training loss:		0.362284
  validation loss:		0.394047
  validation accuracy:		87.39 %
Epoch 212 of 2000 took 0.106s
  training loss:		0.360616
  validation loss:		0.372690
  validation accuracy:		87.93 %
Epoch 213 of 2000 took 0.106s
  training loss:		0.358339
  validation loss:		0.388198
  validation accuracy:		87.50 %
Epoch 214 of 2000 took 0.106s
  training loss:		0.362140
  validation loss:		0.374570
  validation accuracy:		87.93 %
Epoch 215 of 2000 took 0.106s
  training loss:		0.354184
  validation loss:		0.365848
  validation accuracy:		88.59 %
Epoch 216 of 2000 took 0.106s
  training loss:		0.360552
  validation loss:		0.379531
  validation accuracy:		88.48 %
Epoch 217 of 2000 took 0.106s
  training loss:		0.356789
  validation loss:		0.379111
  validation accuracy:		88.59 %
Epoch 218 of 2000 took 0.106s
  training loss:		0.357864
  validation loss:		0.365785
  validation accuracy:		88.26 %
Epoch 219 of 2000 took 0.106s
  training loss:		0.354775
  validation loss:		0.374836
  validation accuracy:		87.39 %
Epoch 220 of 2000 took 0.106s
  training loss:		0.359216
  validation loss:		0.375452
  validation accuracy:		87.61 %
Epoch 221 of 2000 took 0.106s
  training loss:		0.353425
  validation loss:		0.371321
  validation accuracy:		88.91 %
Epoch 222 of 2000 took 0.105s
  training loss:		0.353077
  validation loss:		0.362332
  validation accuracy:		88.70 %
Epoch 223 of 2000 took 0.103s
  training loss:		0.356545
  validation loss:		0.374787
  validation accuracy:		87.72 %
Epoch 224 of 2000 took 0.103s
  training loss:		0.349747
  validation loss:		0.367322
  validation accuracy:		88.59 %
Epoch 225 of 2000 took 0.103s
  training loss:		0.361217
  validation loss:		0.362016
  validation accuracy:		89.02 %
Epoch 226 of 2000 took 0.103s
  training loss:		0.358764
  validation loss:		0.369473
  validation accuracy:		87.83 %
Epoch 227 of 2000 took 0.103s
  training loss:		0.348991
  validation loss:		0.366577
  validation accuracy:		88.59 %
Epoch 228 of 2000 took 0.103s
  training loss:		0.354561
  validation loss:		0.378740
  validation accuracy:		88.70 %
Epoch 229 of 2000 took 0.103s
  training loss:		0.362073
  validation loss:		0.362108
  validation accuracy:		87.93 %
Epoch 230 of 2000 took 0.103s
  training loss:		0.348114
  validation loss:		0.360537
  validation accuracy:		88.70 %
Epoch 231 of 2000 took 0.103s
  training loss:		0.345758
  validation loss:		0.369214
  validation accuracy:		88.04 %
Epoch 232 of 2000 took 0.103s
  training loss:		0.345572
  validation loss:		0.372065
  validation accuracy:		87.50 %
Epoch 233 of 2000 took 0.103s
  training loss:		0.356221
  validation loss:		0.372323
  validation accuracy:		88.04 %
Epoch 234 of 2000 took 0.103s
  training loss:		0.343925
  validation loss:		0.362822
  validation accuracy:		88.15 %
Epoch 235 of 2000 took 0.103s
  training loss:		0.344636
  validation loss:		0.358758
  validation accuracy:		88.37 %
Epoch 236 of 2000 took 0.104s
  training loss:		0.341439
  validation loss:		0.358367
  validation accuracy:		88.59 %
Epoch 237 of 2000 took 0.103s
  training loss:		0.349107
  validation loss:		0.361088
  validation accuracy:		88.91 %
Epoch 238 of 2000 took 0.103s
  training loss:		0.347687
  validation loss:		0.361787
  validation accuracy:		87.93 %
Epoch 239 of 2000 took 0.104s
  training loss:		0.347024
  validation loss:		0.359357
  validation accuracy:		88.48 %
Epoch 240 of 2000 took 0.105s
  training loss:		0.345322
  validation loss:		0.363576
  validation accuracy:		88.04 %
Epoch 241 of 2000 took 0.103s
  training loss:		0.345883
  validation loss:		0.359873
  validation accuracy:		88.91 %
Epoch 242 of 2000 took 0.103s
  training loss:		0.351253
  validation loss:		0.372349
  validation accuracy:		88.04 %
Epoch 243 of 2000 took 0.103s
  training loss:		0.344373
  validation loss:		0.352650
  validation accuracy:		88.48 %
Epoch 244 of 2000 took 0.103s
  training loss:		0.344073
  validation loss:		0.358541
  validation accuracy:		88.48 %
Epoch 245 of 2000 took 0.103s
  training loss:		0.340624
  validation loss:		0.377597
  validation accuracy:		87.72 %
Epoch 246 of 2000 took 0.103s
  training loss:		0.345704
  validation loss:		0.359286
  validation accuracy:		88.59 %
Epoch 247 of 2000 took 0.103s
  training loss:		0.341127
  validation loss:		0.374585
  validation accuracy:		88.26 %
Epoch 248 of 2000 took 0.103s
  training loss:		0.348746
  validation loss:		0.366246
  validation accuracy:		88.80 %
Epoch 249 of 2000 took 0.103s
  training loss:		0.347794
  validation loss:		0.371243
  validation accuracy:		89.13 %
Epoch 250 of 2000 took 0.103s
  training loss:		0.347397
  validation loss:		0.380946
  validation accuracy:		87.61 %
Epoch 251 of 2000 took 0.103s
  training loss:		0.340466
  validation loss:		0.363152
  validation accuracy:		89.02 %
Epoch 252 of 2000 took 0.103s
  training loss:		0.336206
  validation loss:		0.359053
  validation accuracy:		89.13 %
Epoch 253 of 2000 took 0.103s
  training loss:		0.340680
  validation loss:		0.357163
  validation accuracy:		88.59 %
Epoch 254 of 2000 took 0.103s
  training loss:		0.336634
  validation loss:		0.367117
  validation accuracy:		88.26 %
Epoch 255 of 2000 took 0.103s
  training loss:		0.348417
  validation loss:		0.364941
  validation accuracy:		87.50 %
Epoch 256 of 2000 took 0.103s
  training loss:		0.331558
  validation loss:		0.364188
  validation accuracy:		88.26 %
Epoch 257 of 2000 took 0.103s
  training loss:		0.336623
  validation loss:		0.348347
  validation accuracy:		88.59 %
Epoch 258 of 2000 took 0.103s
  training loss:		0.332484
  validation loss:		0.357735
  validation accuracy:		88.80 %
Epoch 259 of 2000 took 0.103s
  training loss:		0.338629
  validation loss:		0.378903
  validation accuracy:		86.74 %
Epoch 260 of 2000 took 0.103s
  training loss:		0.346171
  validation loss:		0.365470
  validation accuracy:		88.15 %
Epoch 261 of 2000 took 0.103s
  training loss:		0.331220
  validation loss:		0.359734
  validation accuracy:		88.15 %
Epoch 262 of 2000 took 0.103s
  training loss:		0.335872
  validation loss:		0.353800
  validation accuracy:		88.26 %
Epoch 263 of 2000 took 0.103s
  training loss:		0.342051
  validation loss:		0.364281
  validation accuracy:		89.02 %
Epoch 264 of 2000 took 0.103s
  training loss:		0.328920
  validation loss:		0.350406
  validation accuracy:		88.91 %
Epoch 265 of 2000 took 0.104s
  training loss:		0.337433
  validation loss:		0.356049
  validation accuracy:		88.70 %
Epoch 266 of 2000 took 0.103s
  training loss:		0.330558
  validation loss:		0.399906
  validation accuracy:		87.28 %
Epoch 267 of 2000 took 0.103s
  training loss:		0.333700
  validation loss:		0.370678
  validation accuracy:		88.04 %
Epoch 268 of 2000 took 0.103s
  training loss:		0.339127
  validation loss:		0.364718
  validation accuracy:		88.15 %
Epoch 269 of 2000 took 0.103s
  training loss:		0.333844
  validation loss:		0.356335
  validation accuracy:		89.35 %
Epoch 270 of 2000 took 0.103s
  training loss:		0.332731
  validation loss:		0.360272
  validation accuracy:		88.59 %
Epoch 271 of 2000 took 0.103s
  training loss:		0.326015
  validation loss:		0.353192
  validation accuracy:		88.80 %
Epoch 272 of 2000 took 0.103s
  training loss:		0.335799
  validation loss:		0.352002
  validation accuracy:		88.91 %
Epoch 273 of 2000 took 0.103s
  training loss:		0.340473
  validation loss:		0.362195
  validation accuracy:		88.04 %
Epoch 274 of 2000 took 0.103s
  training loss:		0.335177
  validation loss:		0.361318
  validation accuracy:		87.83 %
Epoch 275 of 2000 took 0.103s
  training loss:		0.334577
  validation loss:		0.359758
  validation accuracy:		88.91 %
Epoch 276 of 2000 took 0.103s
  training loss:		0.331295
  validation loss:		0.363568
  validation accuracy:		88.91 %
Epoch 277 of 2000 took 0.103s
  training loss:		0.332430
  validation loss:		0.350780
  validation accuracy:		89.02 %
Epoch 278 of 2000 took 0.103s
  training loss:		0.331707
  validation loss:		0.367630
  validation accuracy:		88.04 %
Epoch 279 of 2000 took 0.103s
  training loss:		0.336811
  validation loss:		0.369628
  validation accuracy:		87.83 %
Epoch 280 of 2000 took 0.103s
  training loss:		0.335033
  validation loss:		0.349883
  validation accuracy:		88.80 %
Epoch 281 of 2000 took 0.106s
  training loss:		0.321929
  validation loss:		0.357130
  validation accuracy:		89.24 %
Epoch 282 of 2000 took 0.103s
  training loss:		0.321752
  validation loss:		0.350676
  validation accuracy:		88.80 %
Epoch 283 of 2000 took 0.103s
  training loss:		0.323318
  validation loss:		0.353917
  validation accuracy:		88.48 %
Epoch 284 of 2000 took 0.103s
  training loss:		0.330038
  validation loss:		0.349565
  validation accuracy:		88.91 %
Epoch 285 of 2000 took 0.103s
  training loss:		0.328672
  validation loss:		0.360757
  validation accuracy:		88.37 %
Epoch 286 of 2000 took 0.103s
  training loss:		0.331181
  validation loss:		0.360723
  validation accuracy:		88.70 %
Epoch 287 of 2000 took 0.103s
  training loss:		0.323544
  validation loss:		0.345663
  validation accuracy:		88.80 %
Epoch 288 of 2000 took 0.103s
  training loss:		0.330203
  validation loss:		0.349899
  validation accuracy:		88.04 %
Epoch 289 of 2000 took 0.103s
  training loss:		0.326590
  validation loss:		0.345325
  validation accuracy:		89.02 %
Epoch 290 of 2000 took 0.103s
  training loss:		0.332365
  validation loss:		0.351359
  validation accuracy:		88.48 %
Epoch 291 of 2000 took 0.103s
  training loss:		0.324461
  validation loss:		0.350170
  validation accuracy:		89.13 %
Epoch 292 of 2000 took 0.103s
  training loss:		0.323224
  validation loss:		0.348319
  validation accuracy:		88.59 %
Epoch 293 of 2000 took 0.103s
  training loss:		0.318590
  validation loss:		0.350497
  validation accuracy:		88.91 %
Epoch 294 of 2000 took 0.103s
  training loss:		0.320405
  validation loss:		0.369435
  validation accuracy:		88.48 %
Epoch 295 of 2000 took 0.103s
  training loss:		0.322480
  validation loss:		0.357434
  validation accuracy:		88.80 %
Epoch 296 of 2000 took 0.103s
  training loss:		0.325811
  validation loss:		0.356644
  validation accuracy:		88.59 %
Epoch 297 of 2000 took 0.103s
  training loss:		0.323552
  validation loss:		0.364999
  validation accuracy:		88.26 %
Epoch 298 of 2000 took 0.103s
  training loss:		0.324195
  validation loss:		0.346003
  validation accuracy:		89.02 %
Epoch 299 of 2000 took 0.105s
  training loss:		0.329882
  validation loss:		0.381116
  validation accuracy:		87.39 %
Epoch 300 of 2000 took 0.110s
  training loss:		0.328791
  validation loss:		0.350987
  validation accuracy:		89.02 %
Epoch 301 of 2000 took 0.110s
  training loss:		0.326203
  validation loss:		0.374436
  validation accuracy:		87.72 %
Epoch 302 of 2000 took 0.110s
  training loss:		0.319781
  validation loss:		0.346742
  validation accuracy:		89.02 %
Epoch 303 of 2000 took 0.110s
  training loss:		0.321750
  validation loss:		0.344198
  validation accuracy:		89.13 %
Epoch 304 of 2000 took 0.110s
  training loss:		0.321460
  validation loss:		0.359887
  validation accuracy:		88.26 %
Epoch 305 of 2000 took 0.110s
  training loss:		0.320056
  validation loss:		0.343582
  validation accuracy:		89.02 %
Epoch 306 of 2000 took 0.110s
  training loss:		0.320398
  validation loss:		0.347453
  validation accuracy:		89.02 %
Epoch 307 of 2000 took 0.110s
  training loss:		0.326758
  validation loss:		0.354811
  validation accuracy:		88.70 %
Epoch 308 of 2000 took 0.110s
  training loss:		0.325952
  validation loss:		0.353422
  validation accuracy:		88.70 %
Epoch 309 of 2000 took 0.110s
  training loss:		0.323050
  validation loss:		0.361679
  validation accuracy:		88.26 %
Epoch 310 of 2000 took 0.110s
  training loss:		0.316233
  validation loss:		0.354181
  validation accuracy:		88.59 %
Epoch 311 of 2000 took 0.105s
  training loss:		0.317735
  validation loss:		0.346234
  validation accuracy:		89.02 %
Epoch 312 of 2000 took 0.103s
  training loss:		0.320593
  validation loss:		0.344009
  validation accuracy:		89.02 %
Epoch 313 of 2000 took 0.103s
  training loss:		0.320812
  validation loss:		0.344622
  validation accuracy:		89.13 %
Epoch 314 of 2000 took 0.103s
  training loss:		0.326524
  validation loss:		0.347872
  validation accuracy:		89.24 %
Epoch 315 of 2000 took 0.103s
  training loss:		0.311439
  validation loss:		0.351011
  validation accuracy:		88.26 %
Epoch 316 of 2000 took 0.103s
  training loss:		0.320662
  validation loss:		0.383728
  validation accuracy:		87.93 %
Epoch 317 of 2000 took 0.103s
  training loss:		0.325648
  validation loss:		0.345786
  validation accuracy:		88.70 %
Epoch 318 of 2000 took 0.103s
  training loss:		0.318175
  validation loss:		0.348419
  validation accuracy:		89.02 %
Epoch 319 of 2000 took 0.103s
  training loss:		0.320074
  validation loss:		0.344170
  validation accuracy:		89.02 %
Epoch 320 of 2000 took 0.103s
  training loss:		0.314381
  validation loss:		0.347517
  validation accuracy:		89.02 %
Epoch 321 of 2000 took 0.103s
  training loss:		0.324000
  validation loss:		0.343523
  validation accuracy:		89.02 %
Epoch 322 of 2000 took 0.103s
  training loss:		0.323985
  validation loss:		0.371611
  validation accuracy:		88.37 %
Epoch 323 of 2000 took 0.105s
  training loss:		0.314640
  validation loss:		0.345375
  validation accuracy:		88.91 %
Epoch 324 of 2000 took 0.103s
  training loss:		0.312736
  validation loss:		0.366031
  validation accuracy:		88.48 %
Epoch 325 of 2000 took 0.106s
  training loss:		0.316286
  validation loss:		0.357960
  validation accuracy:		88.59 %
Epoch 326 of 2000 took 0.103s
  training loss:		0.307472
  validation loss:		0.352145
  validation accuracy:		88.70 %
Epoch 327 of 2000 took 0.103s
  training loss:		0.316456
  validation loss:		0.346528
  validation accuracy:		89.13 %
Epoch 328 of 2000 took 0.103s
  training loss:		0.318245
  validation loss:		0.360101
  validation accuracy:		88.26 %
Epoch 329 of 2000 took 0.103s
  training loss:		0.316862
  validation loss:		0.349866
  validation accuracy:		89.02 %
Epoch 330 of 2000 took 0.103s
  training loss:		0.318680
  validation loss:		0.355491
  validation accuracy:		88.59 %
Epoch 331 of 2000 took 0.103s
  training loss:		0.323495
  validation loss:		0.347083
  validation accuracy:		89.13 %
Epoch 332 of 2000 took 0.103s
  training loss:		0.316473
  validation loss:		0.368616
  validation accuracy:		87.93 %
Epoch 333 of 2000 took 0.103s
  training loss:		0.316260
  validation loss:		0.341500
  validation accuracy:		89.02 %
Epoch 334 of 2000 took 0.103s
  training loss:		0.309969
  validation loss:		0.350985
  validation accuracy:		89.02 %
Epoch 335 of 2000 took 0.103s
  training loss:		0.321763
  validation loss:		0.363807
  validation accuracy:		88.91 %
Epoch 336 of 2000 took 0.103s
  training loss:		0.314175
  validation loss:		0.355917
  validation accuracy:		88.70 %
Epoch 337 of 2000 took 0.103s
  training loss:		0.313946
  validation loss:		0.348992
  validation accuracy:		88.15 %
Epoch 338 of 2000 took 0.103s
  training loss:		0.312625
  validation loss:		0.346259
  validation accuracy:		89.67 %
Epoch 339 of 2000 took 0.103s
  training loss:		0.313397
  validation loss:		0.342629
  validation accuracy:		89.57 %
Epoch 340 of 2000 took 0.103s
  training loss:		0.310527
  validation loss:		0.342158
  validation accuracy:		89.13 %
Epoch 341 of 2000 took 0.103s
  training loss:		0.319445
  validation loss:		0.355454
  validation accuracy:		89.46 %
Epoch 342 of 2000 took 0.103s
  training loss:		0.317642
  validation loss:		0.357589
  validation accuracy:		88.37 %
Epoch 343 of 2000 took 0.103s
  training loss:		0.314519
  validation loss:		0.356889
  validation accuracy:		88.59 %
Epoch 344 of 2000 took 0.103s
  training loss:		0.313336
  validation loss:		0.342404
  validation accuracy:		89.13 %
Epoch 345 of 2000 took 0.103s
  training loss:		0.310828
  validation loss:		0.354761
  validation accuracy:		88.59 %
Epoch 346 of 2000 took 0.103s
  training loss:		0.304341
  validation loss:		0.348364
  validation accuracy:		89.02 %
Epoch 347 of 2000 took 0.103s
  training loss:		0.311663
  validation loss:		0.343333
  validation accuracy:		89.02 %
Epoch 348 of 2000 took 0.103s
  training loss:		0.310094
  validation loss:		0.355327
  validation accuracy:		89.35 %
Epoch 349 of 2000 took 0.103s
  training loss:		0.303589
  validation loss:		0.342280
  validation accuracy:		89.35 %
Epoch 350 of 2000 took 0.103s
  training loss:		0.311163
  validation loss:		0.346622
  validation accuracy:		89.02 %
Epoch 351 of 2000 took 0.103s
  training loss:		0.313198
  validation loss:		0.347040
  validation accuracy:		88.80 %
Epoch 352 of 2000 took 0.104s
  training loss:		0.318342
  validation loss:		0.353178
  validation accuracy:		88.48 %
Epoch 353 of 2000 took 0.103s
  training loss:		0.315783
  validation loss:		0.349045
  validation accuracy:		89.24 %
Epoch 354 of 2000 took 0.103s
  training loss:		0.306825
  validation loss:		0.348432
  validation accuracy:		88.70 %
Epoch 355 of 2000 took 0.103s
  training loss:		0.300562
  validation loss:		0.352077
  validation accuracy:		88.80 %
Epoch 356 of 2000 took 0.103s
  training loss:		0.300809
  validation loss:		0.340881
  validation accuracy:		89.35 %
Epoch 357 of 2000 took 0.103s
  training loss:		0.312277
  validation loss:		0.396424
  validation accuracy:		87.93 %
Epoch 358 of 2000 took 0.103s
  training loss:		0.320627
  validation loss:		0.355112
  validation accuracy:		88.70 %
Epoch 359 of 2000 took 0.103s
  training loss:		0.304894
  validation loss:		0.342735
  validation accuracy:		89.13 %
Epoch 360 of 2000 took 0.103s
  training loss:		0.312577
  validation loss:		0.351157
  validation accuracy:		88.70 %
Epoch 361 of 2000 took 0.103s
  training loss:		0.309253
  validation loss:		0.347485
  validation accuracy:		89.02 %
Epoch 362 of 2000 took 0.103s
  training loss:		0.301360
  validation loss:		0.345412
  validation accuracy:		89.02 %
Epoch 363 of 2000 took 0.103s
  training loss:		0.298825
  validation loss:		0.346982
  validation accuracy:		88.70 %
Epoch 364 of 2000 took 0.103s
  training loss:		0.302884
  validation loss:		0.340675
  validation accuracy:		89.35 %
Epoch 365 of 2000 took 0.103s
  training loss:		0.312151
  validation loss:		0.351197
  validation accuracy:		89.89 %
Epoch 366 of 2000 took 0.103s
  training loss:		0.306375
  validation loss:		0.347574
  validation accuracy:		88.80 %
Epoch 367 of 2000 took 0.103s
  training loss:		0.301237
  validation loss:		0.346212
  validation accuracy:		89.35 %
Epoch 368 of 2000 took 0.103s
  training loss:		0.303182
  validation loss:		0.358982
  validation accuracy:		88.91 %
Epoch 369 of 2000 took 0.103s
  training loss:		0.307519
  validation loss:		0.360210
  validation accuracy:		89.46 %
Epoch 370 of 2000 took 0.103s
  training loss:		0.303418
  validation loss:		0.344488
  validation accuracy:		89.13 %
Epoch 371 of 2000 took 0.103s
  training loss:		0.299713
  validation loss:		0.358787
  validation accuracy:		88.80 %
Epoch 372 of 2000 took 0.103s
  training loss:		0.315122
  validation loss:		0.350945
  validation accuracy:		89.67 %
Epoch 373 of 2000 took 0.103s
  training loss:		0.298632
  validation loss:		0.360736
  validation accuracy:		88.70 %
Epoch 374 of 2000 took 0.103s
  training loss:		0.305432
  validation loss:		0.351214
  validation accuracy:		88.70 %
Epoch 375 of 2000 took 0.106s
  training loss:		0.300994
  validation loss:		0.337285
  validation accuracy:		89.35 %
Epoch 376 of 2000 took 0.103s
  training loss:		0.306080
  validation loss:		0.353695
  validation accuracy:		88.59 %
Epoch 377 of 2000 took 0.103s
  training loss:		0.303566
  validation loss:		0.351342
  validation accuracy:		88.80 %
Epoch 378 of 2000 took 0.103s
  training loss:		0.301598
  validation loss:		0.347017
  validation accuracy:		88.80 %
Epoch 379 of 2000 took 0.103s
  training loss:		0.306370
  validation loss:		0.345448
  validation accuracy:		88.70 %
Epoch 380 of 2000 took 0.103s
  training loss:		0.303382
  validation loss:		0.356709
  validation accuracy:		88.48 %
Epoch 381 of 2000 took 0.104s
  training loss:		0.302844
  validation loss:		0.341199
  validation accuracy:		89.57 %
Epoch 382 of 2000 took 0.103s
  training loss:		0.302357
  validation loss:		0.345509
  validation accuracy:		89.46 %
Epoch 383 of 2000 took 0.103s
  training loss:		0.312196
  validation loss:		0.357330
  validation accuracy:		88.80 %
Epoch 384 of 2000 took 0.103s
  training loss:		0.303173
  validation loss:		0.345763
  validation accuracy:		88.70 %
Epoch 385 of 2000 took 0.103s
  training loss:		0.301928
  validation loss:		0.356621
  validation accuracy:		88.15 %
Epoch 386 of 2000 took 0.103s
  training loss:		0.304214
  validation loss:		0.385811
  validation accuracy:		87.39 %
Epoch 387 of 2000 took 0.103s
  training loss:		0.304854
  validation loss:		0.336692
  validation accuracy:		88.80 %
Epoch 388 of 2000 took 0.103s
  training loss:		0.297126
  validation loss:		0.350265
  validation accuracy:		88.70 %
Epoch 389 of 2000 took 0.103s
  training loss:		0.292430
  validation loss:		0.346899
  validation accuracy:		89.57 %
Epoch 390 of 2000 took 0.103s
  training loss:		0.303811
  validation loss:		0.362838
  validation accuracy:		88.04 %
Epoch 391 of 2000 took 0.103s
  training loss:		0.296696
  validation loss:		0.348645
  validation accuracy:		88.59 %
Epoch 392 of 2000 took 0.103s
  training loss:		0.302410
  validation loss:		0.371863
  validation accuracy:		88.15 %
Epoch 393 of 2000 took 0.103s
  training loss:		0.292857
  validation loss:		0.356301
  validation accuracy:		89.13 %
Epoch 394 of 2000 took 0.103s
  training loss:		0.295720
  validation loss:		0.358691
  validation accuracy:		88.59 %
Epoch 395 of 2000 took 0.103s
  training loss:		0.292698
  validation loss:		0.352600
  validation accuracy:		88.48 %
Epoch 396 of 2000 took 0.103s
  training loss:		0.298645
  validation loss:		0.356596
  validation accuracy:		88.80 %
Epoch 397 of 2000 took 0.103s
  training loss:		0.294097
  validation loss:		0.341150
  validation accuracy:		88.91 %
Epoch 398 of 2000 took 0.103s
  training loss:		0.297466
  validation loss:		0.345038
  validation accuracy:		89.46 %
Epoch 399 of 2000 took 0.103s
  training loss:		0.300929
  validation loss:		0.354029
  validation accuracy:		88.15 %
Epoch 400 of 2000 took 0.103s
  training loss:		0.296112
  validation loss:		0.356766
  validation accuracy:		88.80 %
Epoch 401 of 2000 took 0.103s
  training loss:		0.297100
  validation loss:		0.364319
  validation accuracy:		87.93 %
Epoch 402 of 2000 took 0.102s
  training loss:		0.293759
  validation loss:		0.347980
  validation accuracy:		89.46 %
Epoch 403 of 2000 took 0.104s
  training loss:		0.296302
  validation loss:		0.346389
  validation accuracy:		88.48 %
Epoch 404 of 2000 took 0.105s
  training loss:		0.295313
  validation loss:		0.338364
  validation accuracy:		89.78 %
Epoch 405 of 2000 took 0.172s
  training loss:		0.291407
  validation loss:		0.346878
  validation accuracy:		88.26 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.298777
  validation loss:		0.354897
  validation accuracy:		88.59 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.296699
  validation loss:		0.353903
  validation accuracy:		88.70 %
Epoch 408 of 2000 took 0.101s
  training loss:		0.299394
  validation loss:		0.362628
  validation accuracy:		88.80 %
Epoch 409 of 2000 took 0.106s
  training loss:		0.293671
  validation loss:		0.335626
  validation accuracy:		89.57 %
Epoch 410 of 2000 took 0.109s
  training loss:		0.301971
  validation loss:		0.362431
  validation accuracy:		88.26 %
Epoch 411 of 2000 took 0.105s
  training loss:		0.290716
  validation loss:		0.356913
  validation accuracy:		88.91 %
Epoch 412 of 2000 took 0.103s
  training loss:		0.298870
  validation loss:		0.348121
  validation accuracy:		88.15 %
Epoch 413 of 2000 took 0.100s
  training loss:		0.296127
  validation loss:		0.358516
  validation accuracy:		88.80 %
Epoch 414 of 2000 took 0.101s
  training loss:		0.297910
  validation loss:		0.347386
  validation accuracy:		88.70 %
Epoch 415 of 2000 took 0.100s
  training loss:		0.292269
  validation loss:		0.335574
  validation accuracy:		89.35 %
Epoch 416 of 2000 took 0.101s
  training loss:		0.298343
  validation loss:		0.351200
  validation accuracy:		88.37 %
Epoch 417 of 2000 took 0.102s
  training loss:		0.298513
  validation loss:		0.346131
  validation accuracy:		88.70 %
Epoch 418 of 2000 took 0.101s
  training loss:		0.290792
  validation loss:		0.344913
  validation accuracy:		89.46 %
Epoch 419 of 2000 took 0.101s
  training loss:		0.291067
  validation loss:		0.343012
  validation accuracy:		89.46 %
Epoch 420 of 2000 took 0.100s
  training loss:		0.290339
  validation loss:		0.355769
  validation accuracy:		89.35 %
Epoch 421 of 2000 took 0.101s
  training loss:		0.288952
  validation loss:		0.351163
  validation accuracy:		88.70 %
Epoch 422 of 2000 took 0.100s
  training loss:		0.292072
  validation loss:		0.357368
  validation accuracy:		88.15 %
Epoch 423 of 2000 took 0.101s
  training loss:		0.290529
  validation loss:		0.351592
  validation accuracy:		88.70 %
Epoch 424 of 2000 took 0.101s
  training loss:		0.293607
  validation loss:		0.357381
  validation accuracy:		88.70 %
Epoch 425 of 2000 took 0.101s
  training loss:		0.288847
  validation loss:		0.355007
  validation accuracy:		89.02 %
Epoch 426 of 2000 took 0.101s
  training loss:		0.295402
  validation loss:		0.339679
  validation accuracy:		89.13 %
Epoch 427 of 2000 took 0.101s
  training loss:		0.288640
  validation loss:		0.354345
  validation accuracy:		88.59 %
Epoch 428 of 2000 took 0.101s
  training loss:		0.282766
  validation loss:		0.346731
  validation accuracy:		89.35 %
Epoch 429 of 2000 took 0.100s
  training loss:		0.283615
  validation loss:		0.352606
  validation accuracy:		88.37 %
Epoch 430 of 2000 took 0.106s
  training loss:		0.292058
  validation loss:		0.343028
  validation accuracy:		89.24 %
Epoch 431 of 2000 took 0.101s
  training loss:		0.286935
  validation loss:		0.345106
  validation accuracy:		88.70 %
Epoch 432 of 2000 took 0.101s
  training loss:		0.289949
  validation loss:		0.347145
  validation accuracy:		88.91 %
Epoch 433 of 2000 took 0.101s
  training loss:		0.283469
  validation loss:		0.350022
  validation accuracy:		88.91 %
Epoch 434 of 2000 took 0.101s
  training loss:		0.288205
  validation loss:		0.344022
  validation accuracy:		88.70 %
Epoch 435 of 2000 took 0.101s
  training loss:		0.292673
  validation loss:		0.351163
  validation accuracy:		88.70 %
Epoch 436 of 2000 took 0.101s
  training loss:		0.284352
  validation loss:		0.359288
  validation accuracy:		87.93 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.287080
  validation loss:		0.335328
  validation accuracy:		89.46 %
Epoch 438 of 2000 took 0.101s
  training loss:		0.286854
  validation loss:		0.358392
  validation accuracy:		88.15 %
Epoch 439 of 2000 took 0.100s
  training loss:		0.279673
  validation loss:		0.334000
  validation accuracy:		89.24 %
Epoch 440 of 2000 took 0.107s
  training loss:		0.289593
  validation loss:		0.340504
  validation accuracy:		89.13 %
Epoch 441 of 2000 took 0.101s
  training loss:		0.282053
  validation loss:		0.336907
  validation accuracy:		89.46 %
Epoch 442 of 2000 took 0.101s
  training loss:		0.284724
  validation loss:		0.349868
  validation accuracy:		88.26 %
Epoch 443 of 2000 took 0.103s
  training loss:		0.289974
  validation loss:		0.353418
  validation accuracy:		88.15 %
Epoch 444 of 2000 took 0.101s
  training loss:		0.281441
  validation loss:		0.342790
  validation accuracy:		89.67 %
Epoch 445 of 2000 took 0.145s
  training loss:		0.285033
  validation loss:		0.347932
  validation accuracy:		88.48 %
Epoch 446 of 2000 took 0.107s
  training loss:		0.282905
  validation loss:		0.369450
  validation accuracy:		88.04 %
Epoch 447 of 2000 took 0.107s
  training loss:		0.281060
  validation loss:		0.343171
  validation accuracy:		89.46 %
Epoch 448 of 2000 took 0.107s
  training loss:		0.281783
  validation loss:		0.335303
  validation accuracy:		89.35 %
Epoch 449 of 2000 took 0.107s
  training loss:		0.282240
  validation loss:		0.339803
  validation accuracy:		88.91 %
Epoch 450 of 2000 took 0.107s
  training loss:		0.285332
  validation loss:		0.368022
  validation accuracy:		87.93 %
Epoch 451 of 2000 took 0.107s
  training loss:		0.283292
  validation loss:		0.350956
  validation accuracy:		88.37 %
Epoch 452 of 2000 took 0.113s
  training loss:		0.277822
  validation loss:		0.351248
  validation accuracy:		88.48 %
Epoch 453 of 2000 took 0.106s
  training loss:		0.274549
  validation loss:		0.370188
  validation accuracy:		88.37 %
Epoch 454 of 2000 took 0.109s
  training loss:		0.283790
  validation loss:		0.350182
  validation accuracy:		89.02 %
Epoch 455 of 2000 took 0.114s
  training loss:		0.282220
  validation loss:		0.339972
  validation accuracy:		89.13 %
Epoch 456 of 2000 took 0.106s
  training loss:		0.277233
  validation loss:		0.351175
  validation accuracy:		89.02 %
Epoch 457 of 2000 took 0.108s
  training loss:		0.267984
  validation loss:		0.343027
  validation accuracy:		89.02 %
Epoch 458 of 2000 took 0.106s
  training loss:		0.279203
  validation loss:		0.358313
  validation accuracy:		88.15 %
Epoch 459 of 2000 took 0.114s
  training loss:		0.282417
  validation loss:		0.349700
  validation accuracy:		88.91 %
Epoch 460 of 2000 took 0.109s
  training loss:		0.278341
  validation loss:		0.344449
  validation accuracy:		88.37 %
Epoch 461 of 2000 took 0.106s
  training loss:		0.275543
  validation loss:		0.355514
  validation accuracy:		88.37 %
Epoch 462 of 2000 took 0.114s
  training loss:		0.278777
  validation loss:		0.342985
  validation accuracy:		89.24 %
Epoch 463 of 2000 took 0.108s
  training loss:		0.282789
  validation loss:		0.340026
  validation accuracy:		89.35 %
Epoch 464 of 2000 took 0.107s
  training loss:		0.273575
  validation loss:		0.340272
  validation accuracy:		88.70 %
Epoch 465 of 2000 took 0.107s
  training loss:		0.279526
  validation loss:		0.354339
  validation accuracy:		87.93 %
Epoch 466 of 2000 took 0.108s
  training loss:		0.275796
  validation loss:		0.341127
  validation accuracy:		89.13 %
Epoch 467 of 2000 took 0.113s
  training loss:		0.278836
  validation loss:		0.359376
  validation accuracy:		89.02 %
Epoch 468 of 2000 took 0.108s
  training loss:		0.275690
  validation loss:		0.340267
  validation accuracy:		88.37 %
Epoch 469 of 2000 took 0.108s
  training loss:		0.265750
  validation loss:		0.349269
  validation accuracy:		88.26 %
Epoch 470 of 2000 took 0.115s
  training loss:		0.267931
  validation loss:		0.337532
  validation accuracy:		89.35 %
Epoch 471 of 2000 took 0.106s
  training loss:		0.276933
  validation loss:		0.342086
  validation accuracy:		88.80 %
Epoch 472 of 2000 took 0.108s
  training loss:		0.271750
  validation loss:		0.339245
  validation accuracy:		88.91 %
Epoch 473 of 2000 took 0.106s
  training loss:		0.276105
  validation loss:		0.343411
  validation accuracy:		88.80 %
Epoch 474 of 2000 took 0.110s
  training loss:		0.270566
  validation loss:		0.363639
  validation accuracy:		88.26 %
Epoch 475 of 2000 took 0.112s
  training loss:		0.281022
  validation loss:		0.341835
  validation accuracy:		89.13 %
Epoch 476 of 2000 took 0.106s
  training loss:		0.272688
  validation loss:		0.331205
  validation accuracy:		88.59 %
Epoch 477 of 2000 took 0.109s
  training loss:		0.281438
  validation loss:		0.348689
  validation accuracy:		88.70 %
Epoch 478 of 2000 took 0.113s
  training loss:		0.273809
  validation loss:		0.353587
  validation accuracy:		88.80 %
Epoch 479 of 2000 took 0.107s
  training loss:		0.270291
  validation loss:		0.340403
  validation accuracy:		88.70 %
Epoch 480 of 2000 took 0.108s
  training loss:		0.270493
  validation loss:		0.344938
  validation accuracy:		88.37 %
Epoch 481 of 2000 took 0.138s
  training loss:		0.269478
  validation loss:		0.359314
  validation accuracy:		88.59 %
Epoch 482 of 2000 took 0.165s
  training loss:		0.269922
  validation loss:		0.347369
  validation accuracy:		89.02 %
Epoch 483 of 2000 took 0.166s
  training loss:		0.269477
  validation loss:		0.349806
  validation accuracy:		88.26 %
Epoch 484 of 2000 took 0.166s
  training loss:		0.274798
  validation loss:		0.334415
  validation accuracy:		88.59 %
Epoch 485 of 2000 took 0.170s
  training loss:		0.270438
  validation loss:		0.334556
  validation accuracy:		89.13 %
Epoch 486 of 2000 took 0.166s
  training loss:		0.270348
  validation loss:		0.343435
  validation accuracy:		88.80 %
Epoch 487 of 2000 took 0.166s
  training loss:		0.264707
  validation loss:		0.344019
  validation accuracy:		88.80 %
Epoch 488 of 2000 took 0.166s
  training loss:		0.265951
  validation loss:		0.337497
  validation accuracy:		88.70 %
Epoch 489 of 2000 took 0.166s
  training loss:		0.265632
  validation loss:		0.362467
  validation accuracy:		88.15 %
Epoch 490 of 2000 took 0.166s
  training loss:		0.264974
  validation loss:		0.340693
  validation accuracy:		88.80 %
Epoch 491 of 2000 took 0.170s
  training loss:		0.264163
  validation loss:		0.343542
  validation accuracy:		89.02 %
Epoch 492 of 2000 took 0.166s
  training loss:		0.267382
  validation loss:		0.334874
  validation accuracy:		88.59 %
Epoch 493 of 2000 took 0.166s
  training loss:		0.261525
  validation loss:		0.353250
  validation accuracy:		88.37 %
Epoch 494 of 2000 took 0.165s
  training loss:		0.268524
  validation loss:		0.336976
  validation accuracy:		88.80 %
Epoch 495 of 2000 took 0.166s
  training loss:		0.274715
  validation loss:		0.356438
  validation accuracy:		88.80 %
Epoch 496 of 2000 took 0.166s
  training loss:		0.254299
  validation loss:		0.338480
  validation accuracy:		88.91 %
Epoch 497 of 2000 took 0.165s
  training loss:		0.263235
  validation loss:		0.342945
  validation accuracy:		89.24 %
Epoch 498 of 2000 took 0.168s
  training loss:		0.265137
  validation loss:		0.356724
  validation accuracy:		88.59 %
Epoch 499 of 2000 took 0.164s
  training loss:		0.262618
  validation loss:		0.343792
  validation accuracy:		88.48 %
Epoch 500 of 2000 took 0.164s
  training loss:		0.264559
  validation loss:		0.340029
  validation accuracy:		88.48 %
Epoch 501 of 2000 took 0.164s
  training loss:		0.264411
  validation loss:		0.341679
  validation accuracy:		88.59 %
Epoch 502 of 2000 took 0.164s
  training loss:		0.269963
  validation loss:		0.341805
  validation accuracy:		88.70 %
Epoch 503 of 2000 took 0.164s
  training loss:		0.263665
  validation loss:		0.337956
  validation accuracy:		89.13 %
Epoch 504 of 2000 took 0.164s
  training loss:		0.263964
  validation loss:		0.345331
  validation accuracy:		88.37 %
Epoch 505 of 2000 took 0.167s
  training loss:		0.261302
  validation loss:		0.344865
  validation accuracy:		89.02 %
Epoch 506 of 2000 took 0.164s
  training loss:		0.260796
  validation loss:		0.337895
  validation accuracy:		89.24 %
Epoch 507 of 2000 took 0.164s
  training loss:		0.267256
  validation loss:		0.339697
  validation accuracy:		88.80 %
Epoch 508 of 2000 took 0.164s
  training loss:		0.264138
  validation loss:		0.357306
  validation accuracy:		89.13 %
Epoch 509 of 2000 took 0.204s
  training loss:		0.263347
  validation loss:		0.341004
  validation accuracy:		88.37 %
Epoch 510 of 2000 took 0.196s
  training loss:		0.262769
  validation loss:		0.350481
  validation accuracy:		89.02 %
Epoch 511 of 2000 took 0.197s
  training loss:		0.255687
  validation loss:		0.344968
  validation accuracy:		87.93 %
Epoch 512 of 2000 took 0.193s
  training loss:		0.262168
  validation loss:		0.345699
  validation accuracy:		88.70 %
Epoch 513 of 2000 took 0.203s
  training loss:		0.264732
  validation loss:		0.351772
  validation accuracy:		88.70 %
Epoch 514 of 2000 took 0.194s
  training loss:		0.261762
  validation loss:		0.364305
  validation accuracy:		87.83 %
Epoch 515 of 2000 took 0.198s
  training loss:		0.256482
  validation loss:		0.331193
  validation accuracy:		88.59 %
Epoch 516 of 2000 took 0.208s
  training loss:		0.256419
  validation loss:		0.349756
  validation accuracy:		88.37 %
Epoch 517 of 2000 took 0.196s
  training loss:		0.259172
  validation loss:		0.337220
  validation accuracy:		89.24 %
Epoch 518 of 2000 took 0.197s
  training loss:		0.256507
  validation loss:		0.342476
  validation accuracy:		89.35 %
Epoch 519 of 2000 took 0.191s
  training loss:		0.261128
  validation loss:		0.369506
  validation accuracy:		87.93 %
Epoch 520 of 2000 took 0.217s
  training loss:		0.259523
  validation loss:		0.349246
  validation accuracy:		88.70 %
Epoch 521 of 2000 took 0.192s
  training loss:		0.258671
  validation loss:		0.360529
  validation accuracy:		88.48 %
Epoch 522 of 2000 took 0.196s
  training loss:		0.260275
  validation loss:		0.368092
  validation accuracy:		87.50 %
Epoch 523 of 2000 took 0.204s
  training loss:		0.253537
  validation loss:		0.340461
  validation accuracy:		88.37 %
Epoch 524 of 2000 took 0.195s
  training loss:		0.253556
  validation loss:		0.330030
  validation accuracy:		89.24 %
Epoch 525 of 2000 took 0.193s
  training loss:		0.251988
  validation loss:		0.345307
  validation accuracy:		88.91 %
Epoch 526 of 2000 took 0.190s
  training loss:		0.256640
  validation loss:		0.340828
  validation accuracy:		89.35 %
Epoch 527 of 2000 took 0.193s
  training loss:		0.252801
  validation loss:		0.331561
  validation accuracy:		88.70 %
Epoch 528 of 2000 took 0.195s
  training loss:		0.254461
  validation loss:		0.337535
  validation accuracy:		89.13 %
Epoch 529 of 2000 took 0.190s
  training loss:		0.252486
  validation loss:		0.333555
  validation accuracy:		88.37 %
Epoch 530 of 2000 took 0.206s
  training loss:		0.255345
  validation loss:		0.337913
  validation accuracy:		89.13 %
Epoch 531 of 2000 took 0.195s
  training loss:		0.259525
  validation loss:		0.336632
  validation accuracy:		89.46 %
Epoch 532 of 2000 took 0.194s
  training loss:		0.259731
  validation loss:		0.365176
  validation accuracy:		88.48 %
Epoch 533 of 2000 took 0.190s
  training loss:		0.252173
  validation loss:		0.342077
  validation accuracy:		89.13 %
Epoch 534 of 2000 took 0.192s
  training loss:		0.251559
  validation loss:		0.342332
  validation accuracy:		89.13 %
Epoch 535 of 2000 took 0.192s
  training loss:		0.259682
  validation loss:		0.356106
  validation accuracy:		87.83 %
Epoch 536 of 2000 took 0.190s
  training loss:		0.254639
  validation loss:		0.337613
  validation accuracy:		88.80 %
Epoch 537 of 2000 took 0.206s
  training loss:		0.251736
  validation loss:		0.337628
  validation accuracy:		88.59 %
Epoch 538 of 2000 took 0.198s
  training loss:		0.250160
  validation loss:		0.334853
  validation accuracy:		89.46 %
Epoch 539 of 2000 took 0.194s
  training loss:		0.253291
  validation loss:		0.349638
  validation accuracy:		89.02 %
Epoch 540 of 2000 took 0.190s
  training loss:		0.253422
  validation loss:		0.335501
  validation accuracy:		88.48 %
Epoch 541 of 2000 took 0.192s
  training loss:		0.250134
  validation loss:		0.324750
  validation accuracy:		89.35 %
Epoch 542 of 2000 took 0.193s
  training loss:		0.251795
  validation loss:		0.339026
  validation accuracy:		88.48 %
Epoch 543 of 2000 took 0.190s
  training loss:		0.246032
  validation loss:		0.340259
  validation accuracy:		88.48 %
Epoch 544 of 2000 took 0.207s
  training loss:		0.244099
  validation loss:		0.357193
  validation accuracy:		87.61 %
Epoch 545 of 2000 took 0.193s
  training loss:		0.252738
  validation loss:		0.329339
  validation accuracy:		89.35 %
Epoch 546 of 2000 took 0.194s
  training loss:		0.250515
  validation loss:		0.322296
  validation accuracy:		89.57 %
Epoch 547 of 2000 took 0.191s
  training loss:		0.250779
  validation loss:		0.344067
  validation accuracy:		88.15 %
Epoch 548 of 2000 took 0.191s
  training loss:		0.246882
  validation loss:		0.342344
  validation accuracy:		88.26 %
Epoch 549 of 2000 took 0.193s
  training loss:		0.251608
  validation loss:		0.334836
  validation accuracy:		89.24 %
Epoch 550 of 2000 took 0.195s
  training loss:		0.238057
  validation loss:		0.343602
  validation accuracy:		88.80 %
Epoch 551 of 2000 took 0.202s
  training loss:		0.243096
  validation loss:		0.340075
  validation accuracy:		88.48 %
Epoch 552 of 2000 took 0.195s
  training loss:		0.242619
  validation loss:		0.342114
  validation accuracy:		88.37 %
Epoch 553 of 2000 took 0.192s
  training loss:		0.253143
  validation loss:		0.326768
  validation accuracy:		88.91 %
Epoch 554 of 2000 took 0.194s
  training loss:		0.247441
  validation loss:		0.341861
  validation accuracy:		89.02 %
Epoch 555 of 2000 took 0.190s
  training loss:		0.246740
  validation loss:		0.333700
  validation accuracy:		89.02 %
Epoch 556 of 2000 took 0.194s
  training loss:		0.240950
  validation loss:		0.349371
  validation accuracy:		88.91 %
Epoch 557 of 2000 took 0.190s
  training loss:		0.238028
  validation loss:		0.329247
  validation accuracy:		88.91 %
Epoch 558 of 2000 took 0.197s
  training loss:		0.243857
  validation loss:		0.359616
  validation accuracy:		88.04 %
Epoch 559 of 2000 took 0.200s
  training loss:		0.247550
  validation loss:		0.343007
  validation accuracy:		88.70 %
Epoch 560 of 2000 took 0.195s
  training loss:		0.244640
  validation loss:		0.335828
  validation accuracy:		88.91 %
Epoch 561 of 2000 took 0.193s
  training loss:		0.244140
  validation loss:		0.326244
  validation accuracy:		88.80 %
Epoch 562 of 2000 took 0.190s
  training loss:		0.242554
  validation loss:		0.347191
  validation accuracy:		89.02 %
Epoch 563 of 2000 took 0.194s
  training loss:		0.242331
  validation loss:		0.326204
  validation accuracy:		89.13 %
Epoch 564 of 2000 took 0.191s
  training loss:		0.240978
  validation loss:		0.327629
  validation accuracy:		88.80 %
Epoch 565 of 2000 took 0.193s
  training loss:		0.243444
  validation loss:		0.356798
  validation accuracy:		88.59 %
Epoch 566 of 2000 took 0.204s
  training loss:		0.251191
  validation loss:		0.338941
  validation accuracy:		89.46 %
Epoch 567 of 2000 took 0.194s
  training loss:		0.242721
  validation loss:		0.332557
  validation accuracy:		88.70 %
Epoch 568 of 2000 took 0.194s
  training loss:		0.245015
  validation loss:		0.341109
  validation accuracy:		89.24 %
Epoch 569 of 2000 took 0.194s
  training loss:		0.239771
  validation loss:		0.339382
  validation accuracy:		89.24 %
Epoch 570 of 2000 took 0.193s
  training loss:		0.246677
  validation loss:		0.327873
  validation accuracy:		89.46 %
Epoch 571 of 2000 took 0.192s
  training loss:		0.236267
  validation loss:		0.336776
  validation accuracy:		89.13 %
Epoch 572 of 2000 took 0.190s
  training loss:		0.237064
  validation loss:		0.336488
  validation accuracy:		89.02 %
Epoch 573 of 2000 took 0.206s
  training loss:		0.236411
  validation loss:		0.339084
  validation accuracy:		88.91 %
Epoch 574 of 2000 took 0.195s
  training loss:		0.236699
  validation loss:		0.335397
  validation accuracy:		89.24 %
Epoch 575 of 2000 took 0.195s
  training loss:		0.237785
  validation loss:		0.353971
  validation accuracy:		88.91 %
Epoch 576 of 2000 took 0.190s
  training loss:		0.237842
  validation loss:		0.337756
  validation accuracy:		88.59 %
Epoch 577 of 2000 took 0.192s
  training loss:		0.234679
  validation loss:		0.332421
  validation accuracy:		88.70 %
Epoch 578 of 2000 took 0.192s
  training loss:		0.237751
  validation loss:		0.325806
  validation accuracy:		89.13 %
Epoch 579 of 2000 took 0.190s
  training loss:		0.231309
  validation loss:		0.350560
  validation accuracy:		88.80 %
Epoch 580 of 2000 took 0.206s
  training loss:		0.243227
  validation loss:		0.341118
  validation accuracy:		88.59 %
Epoch 581 of 2000 took 0.194s
  training loss:		0.240757
  validation loss:		0.342265
  validation accuracy:		88.91 %
Epoch 582 of 2000 took 0.193s
  training loss:		0.238803
  validation loss:		0.329495
  validation accuracy:		88.80 %
Epoch 583 of 2000 took 0.191s
  training loss:		0.237176
  validation loss:		0.324090
  validation accuracy:		89.35 %
Epoch 584 of 2000 took 0.192s
  training loss:		0.238179
  validation loss:		0.339641
  validation accuracy:		88.48 %
Epoch 585 of 2000 took 0.193s
  training loss:		0.234154
  validation loss:		0.338729
  validation accuracy:		88.80 %
Epoch 586 of 2000 took 0.189s
  training loss:		0.238510
  validation loss:		0.327697
  validation accuracy:		88.70 %
Epoch 587 of 2000 took 0.206s
  training loss:		0.235675
  validation loss:		0.338950
  validation accuracy:		89.02 %
Epoch 588 of 2000 took 0.192s
  training loss:		0.235426
  validation loss:		0.332843
  validation accuracy:		88.59 %
Epoch 589 of 2000 took 0.194s
  training loss:		0.238782
  validation loss:		0.337437
  validation accuracy:		88.70 %
Epoch 590 of 2000 took 0.192s
  training loss:		0.231442
  validation loss:		0.315035
  validation accuracy:		89.57 %
Epoch 591 of 2000 took 0.191s
  training loss:		0.234460
  validation loss:		0.344931
  validation accuracy:		88.26 %
Epoch 592 of 2000 took 0.194s
  training loss:		0.239404
  validation loss:		0.336909
  validation accuracy:		88.59 %
Epoch 593 of 2000 took 0.190s
  training loss:		0.234444
  validation loss:		0.323875
  validation accuracy:		89.35 %
Epoch 594 of 2000 took 0.198s
  training loss:		0.237590
  validation loss:		0.338357
  validation accuracy:		89.02 %
Epoch 595 of 2000 took 0.199s
  training loss:		0.233101
  validation loss:		0.338581
  validation accuracy:		88.80 %
Epoch 596 of 2000 took 0.194s
  training loss:		0.228031
  validation loss:		0.342058
  validation accuracy:		88.91 %
Epoch 597 of 2000 took 0.193s
  training loss:		0.239855
  validation loss:		0.332049
  validation accuracy:		89.02 %
Epoch 598 of 2000 took 0.189s
  training loss:		0.226572
  validation loss:		0.351988
  validation accuracy:		88.26 %
Epoch 599 of 2000 took 0.195s
  training loss:		0.232864
  validation loss:		0.337718
  validation accuracy:		88.80 %
Epoch 600 of 2000 took 0.195s
  training loss:		0.228162
  validation loss:		0.335750
  validation accuracy:		88.70 %
Epoch 601 of 2000 took 0.195s
  training loss:		0.236823
  validation loss:		0.346461
  validation accuracy:		88.59 %
Epoch 602 of 2000 took 0.202s
  training loss:		0.232919
  validation loss:		0.363196
  validation accuracy:		88.59 %
Epoch 603 of 2000 took 0.195s
  training loss:		0.229380
  validation loss:		0.327850
  validation accuracy:		89.02 %
Epoch 604 of 2000 took 0.194s
  training loss:		0.231428
  validation loss:		0.344965
  validation accuracy:		88.48 %
Epoch 605 of 2000 took 0.190s
  training loss:		0.230987
  validation loss:		0.343308
  validation accuracy:		88.91 %
Epoch 606 of 2000 took 0.194s
  training loss:		0.233782
  validation loss:		0.334624
  validation accuracy:		88.59 %
Epoch 607 of 2000 took 0.191s
  training loss:		0.228726
  validation loss:		0.348056
  validation accuracy:		88.80 %
Epoch 608 of 2000 took 0.191s
  training loss:		0.235250
  validation loss:		0.346225
  validation accuracy:		88.80 %
Epoch 609 of 2000 took 0.205s
  training loss:		0.230767
  validation loss:		0.345094
  validation accuracy:		88.59 %
Epoch 610 of 2000 took 0.194s
  training loss:		0.231750
  validation loss:		0.337586
  validation accuracy:		89.67 %
Epoch 611 of 2000 took 0.194s
  training loss:		0.231097
  validation loss:		0.340638
  validation accuracy:		89.02 %
Epoch 612 of 2000 took 0.189s
  training loss:		0.227506
  validation loss:		0.320897
  validation accuracy:		89.46 %
Epoch 613 of 2000 took 0.192s
  training loss:		0.225004
  validation loss:		0.346046
  validation accuracy:		88.48 %
Epoch 614 of 2000 took 0.192s
  training loss:		0.223843
  validation loss:		0.333963
  validation accuracy:		89.02 %
Epoch 615 of 2000 took 0.189s
  training loss:		0.226102
  validation loss:		0.346617
  validation accuracy:		88.70 %
Epoch 616 of 2000 took 0.206s
  training loss:		0.230753
  validation loss:		0.344449
  validation accuracy:		88.70 %
Epoch 617 of 2000 took 0.194s
  training loss:		0.225926
  validation loss:		0.328483
  validation accuracy:		88.80 %
Epoch 618 of 2000 took 0.195s
  training loss:		0.231520
  validation loss:		0.329315
  validation accuracy:		89.13 %
Epoch 619 of 2000 took 0.190s
  training loss:		0.227676
  validation loss:		0.343479
  validation accuracy:		88.80 %
Epoch 620 of 2000 took 0.192s
  training loss:		0.228359
  validation loss:		0.347416
  validation accuracy:		88.37 %
Epoch 621 of 2000 took 0.193s
  training loss:		0.221702
  validation loss:		0.336854
  validation accuracy:		89.35 %
Epoch 622 of 2000 took 0.149s
  training loss:		0.226657
  validation loss:		0.348262
  validation accuracy:		88.70 %
Epoch 623 of 2000 took 0.104s
  training loss:		0.223037
  validation loss:		0.338806
  validation accuracy:		89.02 %
Epoch 624 of 2000 took 0.109s
  training loss:		0.229048
  validation loss:		0.335531
  validation accuracy:		88.91 %
Epoch 625 of 2000 took 0.105s
  training loss:		0.222999
  validation loss:		0.342519
  validation accuracy:		89.46 %
Epoch 626 of 2000 took 0.107s
  training loss:		0.224100
  validation loss:		0.336376
  validation accuracy:		88.80 %
Epoch 627 of 2000 took 0.105s
  training loss:		0.228969
  validation loss:		0.332546
  validation accuracy:		89.24 %
Epoch 628 of 2000 took 0.110s
  training loss:		0.222036
  validation loss:		0.335448
  validation accuracy:		88.91 %
Epoch 629 of 2000 took 0.105s
  training loss:		0.226061
  validation loss:		0.331735
  validation accuracy:		89.02 %
Epoch 630 of 2000 took 0.104s
  training loss:		0.225291
  validation loss:		0.359536
  validation accuracy:		88.26 %
Epoch 631 of 2000 took 0.111s
  training loss:		0.223494
  validation loss:		0.335573
  validation accuracy:		89.24 %
Epoch 632 of 2000 took 0.104s
  training loss:		0.223409
  validation loss:		0.324648
  validation accuracy:		88.91 %
Epoch 633 of 2000 took 0.105s
  training loss:		0.223016
  validation loss:		0.352100
  validation accuracy:		88.26 %
Epoch 634 of 2000 took 0.104s
  training loss:		0.226855
  validation loss:		0.348930
  validation accuracy:		88.80 %
Epoch 635 of 2000 took 0.106s
  training loss:		0.219205
  validation loss:		0.332795
  validation accuracy:		89.13 %
Epoch 636 of 2000 took 0.110s
  training loss:		0.222617
  validation loss:		0.341126
  validation accuracy:		88.80 %
Epoch 637 of 2000 took 0.104s
  training loss:		0.222193
  validation loss:		0.337576
  validation accuracy:		89.02 %
Epoch 638 of 2000 took 0.107s
  training loss:		0.224998
  validation loss:		0.342341
  validation accuracy:		89.13 %
Epoch 639 of 2000 took 0.111s
  training loss:		0.217342
  validation loss:		0.340596
  validation accuracy:		89.57 %
Epoch 640 of 2000 took 0.103s
  training loss:		0.220306
  validation loss:		0.335117
  validation accuracy:		89.46 %
Epoch 641 of 2000 took 0.107s
  training loss:		0.224055
  validation loss:		0.334180
  validation accuracy:		88.59 %
Epoch 642 of 2000 took 0.103s
  training loss:		0.225370
  validation loss:		0.341373
  validation accuracy:		89.46 %
Epoch 643 of 2000 took 0.109s
  training loss:		0.210137
  validation loss:		0.334474
  validation accuracy:		89.13 %
Epoch 644 of 2000 took 0.106s
  training loss:		0.224162
  validation loss:		0.341309
  validation accuracy:		89.13 %
Epoch 645 of 2000 took 0.102s
  training loss:		0.220942
  validation loss:		0.329964
  validation accuracy:		89.13 %
Epoch 646 of 2000 took 0.106s
  training loss:		0.221033
  validation loss:		0.326958
  validation accuracy:		89.13 %
Epoch 647 of 2000 took 0.103s
  training loss:		0.217427
  validation loss:		0.343996
  validation accuracy:		89.02 %
Epoch 648 of 2000 took 0.101s
  training loss:		0.215613
  validation loss:		0.341401
  validation accuracy:		89.24 %
Epoch 649 of 2000 took 0.101s
  training loss:		0.224661
  validation loss:		0.330307
  validation accuracy:		89.02 %
Epoch 650 of 2000 took 0.101s
  training loss:		0.217456
  validation loss:		0.334695
  validation accuracy:		89.13 %
Epoch 651 of 2000 took 0.107s
  training loss:		0.217221
  validation loss:		0.327982
  validation accuracy:		88.80 %
Epoch 652 of 2000 took 0.102s
  training loss:		0.220709
  validation loss:		0.336497
  validation accuracy:		88.80 %
Epoch 653 of 2000 took 0.101s
  training loss:		0.219175
  validation loss:		0.344198
  validation accuracy:		88.59 %
Epoch 654 of 2000 took 0.108s
  training loss:		0.221847
  validation loss:		0.341288
  validation accuracy:		88.91 %
Epoch 655 of 2000 took 0.100s
  training loss:		0.220125
  validation loss:		0.359400
  validation accuracy:		88.59 %
Epoch 656 of 2000 took 0.102s
  training loss:		0.217334
  validation loss:		0.332791
  validation accuracy:		88.70 %
Epoch 657 of 2000 took 0.100s
  training loss:		0.217057
  validation loss:		0.343423
  validation accuracy:		88.48 %
Epoch 658 of 2000 took 0.103s
  training loss:		0.219522
  validation loss:		0.335010
  validation accuracy:		88.59 %
Epoch 659 of 2000 took 0.106s
  training loss:		0.216112
  validation loss:		0.331411
  validation accuracy:		89.35 %
Epoch 660 of 2000 took 0.100s
  training loss:		0.213838
  validation loss:		0.337866
  validation accuracy:		88.70 %
Epoch 661 of 2000 took 0.103s
  training loss:		0.220556
  validation loss:		0.329448
  validation accuracy:		89.35 %
Epoch 662 of 2000 took 0.103s
  training loss:		0.213876
  validation loss:		0.364592
  validation accuracy:		88.48 %
Epoch 663 of 2000 took 0.101s
  training loss:		0.218647
  validation loss:		0.347556
  validation accuracy:		88.48 %
Epoch 664 of 2000 took 0.105s
  training loss:		0.220693
  validation loss:		0.351326
  validation accuracy:		88.59 %
Epoch 665 of 2000 took 0.100s
  training loss:		0.218767
  validation loss:		0.323634
  validation accuracy:		89.46 %
Epoch 666 of 2000 took 0.106s
  training loss:		0.216634
  validation loss:		0.345928
  validation accuracy:		88.48 %
Epoch 667 of 2000 took 0.100s
  training loss:		0.215296
  validation loss:		0.339073
  validation accuracy:		89.02 %
Epoch 668 of 2000 took 0.102s
  training loss:		0.221334
  validation loss:		0.359134
  validation accuracy:		88.70 %
Epoch 669 of 2000 took 0.104s
  training loss:		0.217234
  validation loss:		0.335831
  validation accuracy:		89.46 %
Epoch 670 of 2000 took 0.101s
  training loss:		0.216359
  validation loss:		0.333289
  validation accuracy:		89.57 %
Epoch 671 of 2000 took 0.105s
  training loss:		0.219530
  validation loss:		0.344688
  validation accuracy:		89.24 %
Epoch 672 of 2000 took 0.103s
  training loss:		0.219455
  validation loss:		0.334041
  validation accuracy:		89.57 %
Epoch 673 of 2000 took 0.105s
  training loss:		0.215767
  validation loss:		0.319692
  validation accuracy:		89.78 %
Epoch 674 of 2000 took 0.101s
  training loss:		0.216527
  validation loss:		0.342282
  validation accuracy:		89.35 %
Epoch 675 of 2000 took 0.102s
  training loss:		0.208037
  validation loss:		0.336836
  validation accuracy:		88.59 %
Epoch 676 of 2000 took 0.104s
  training loss:		0.211075
  validation loss:		0.331450
  validation accuracy:		89.57 %
Epoch 677 of 2000 took 0.100s
  training loss:		0.209724
  validation loss:		0.340877
  validation accuracy:		88.80 %
Epoch 678 of 2000 took 0.106s
  training loss:		0.216796
  validation loss:		0.349006
  validation accuracy:		88.48 %
Epoch 679 of 2000 took 0.100s
  training loss:		0.215468
  validation loss:		0.338810
  validation accuracy:		89.24 %
Epoch 680 of 2000 took 0.104s
  training loss:		0.209719
  validation loss:		0.357672
  validation accuracy:		88.70 %
Epoch 681 of 2000 took 0.102s
  training loss:		0.216354
  validation loss:		0.347176
  validation accuracy:		89.13 %
Epoch 682 of 2000 took 0.101s
  training loss:		0.217699
  validation loss:		0.327879
  validation accuracy:		89.13 %
Epoch 683 of 2000 took 0.105s
  training loss:		0.212879
  validation loss:		0.345947
  validation accuracy:		88.80 %
Epoch 684 of 2000 took 0.100s
  training loss:		0.215880
  validation loss:		0.341118
  validation accuracy:		89.24 %
Epoch 685 of 2000 took 0.106s
  training loss:		0.218905
  validation loss:		0.338355
  validation accuracy:		89.13 %
Epoch 686 of 2000 took 0.100s
  training loss:		0.213581
  validation loss:		0.342860
  validation accuracy:		89.46 %
Epoch 687 of 2000 took 0.102s
  training loss:		0.216384
  validation loss:		0.354763
  validation accuracy:		88.59 %
Epoch 688 of 2000 took 0.103s
  training loss:		0.216660
  validation loss:		0.332332
  validation accuracy:		88.91 %
Epoch 689 of 2000 took 0.101s
  training loss:		0.208914
  validation loss:		0.334492
  validation accuracy:		89.46 %
Epoch 690 of 2000 took 0.108s
  training loss:		0.210037
  validation loss:		0.335453
  validation accuracy:		89.46 %
Epoch 691 of 2000 took 0.100s
  training loss:		0.215519
  validation loss:		0.331595
  validation accuracy:		89.67 %
Epoch 692 of 2000 took 0.102s
  training loss:		0.213685
  validation loss:		0.366778
  validation accuracy:		89.35 %
Epoch 693 of 2000 took 0.100s
  training loss:		0.209899
  validation loss:		0.345739
  validation accuracy:		89.24 %
Epoch 694 of 2000 took 0.103s
  training loss:		0.213521
  validation loss:		0.333564
  validation accuracy:		89.46 %
Epoch 695 of 2000 took 0.106s
  training loss:		0.208399
  validation loss:		0.348779
  validation accuracy:		89.13 %
Epoch 696 of 2000 took 0.100s
  training loss:		0.206879
  validation loss:		0.332455
  validation accuracy:		89.78 %
Epoch 697 of 2000 took 0.103s
  training loss:		0.214286
  validation loss:		0.353268
  validation accuracy:		89.13 %
Epoch 698 of 2000 took 0.106s
  training loss:		0.209693
  validation loss:		0.334728
  validation accuracy:		88.26 %
Epoch 699 of 2000 took 0.100s
  training loss:		0.214030
  validation loss:		0.350086
  validation accuracy:		89.13 %
Epoch 700 of 2000 took 0.103s
  training loss:		0.210672
  validation loss:		0.352287
  validation accuracy:		89.02 %
Epoch 701 of 2000 took 0.100s
  training loss:		0.210970
  validation loss:		0.342997
  validation accuracy:		89.57 %
Epoch 702 of 2000 took 0.107s
  training loss:		0.211581
  validation loss:		0.341694
  validation accuracy:		89.67 %
Epoch 703 of 2000 took 0.103s
  training loss:		0.209895
  validation loss:		0.363256
  validation accuracy:		89.02 %
Epoch 704 of 2000 took 0.100s
  training loss:		0.211178
  validation loss:		0.340643
  validation accuracy:		89.46 %
Epoch 705 of 2000 took 0.107s
  training loss:		0.203943
  validation loss:		0.350386
  validation accuracy:		89.35 %
Epoch 706 of 2000 took 0.102s
  training loss:		0.209435
  validation loss:		0.347375
  validation accuracy:		89.35 %
Epoch 707 of 2000 took 0.101s
  training loss:		0.202038
  validation loss:		0.351241
  validation accuracy:		89.24 %
Epoch 708 of 2000 took 0.101s
  training loss:		0.212007
  validation loss:		0.341288
  validation accuracy:		88.59 %
Epoch 709 of 2000 took 0.102s
  training loss:		0.206575
  validation loss:		0.333602
  validation accuracy:		89.46 %
Epoch 710 of 2000 took 0.106s
  training loss:		0.204647
  validation loss:		0.343874
  validation accuracy:		89.24 %
Epoch 711 of 2000 took 0.101s
  training loss:		0.211012
  validation loss:		0.342901
  validation accuracy:		90.00 %
Epoch 712 of 2000 took 0.102s
  training loss:		0.204825
  validation loss:		0.348267
  validation accuracy:		88.80 %
Epoch 713 of 2000 took 0.107s
  training loss:		0.205033
  validation loss:		0.346408
  validation accuracy:		89.24 %
Epoch 714 of 2000 took 0.100s
  training loss:		0.211396
  validation loss:		0.340104
  validation accuracy:		89.24 %
Epoch 715 of 2000 took 0.102s
  training loss:		0.207987
  validation loss:		0.347578
  validation accuracy:		89.02 %
Epoch 716 of 2000 took 0.100s
  training loss:		0.209697
  validation loss:		0.344172
  validation accuracy:		88.80 %
Epoch 717 of 2000 took 0.105s
  training loss:		0.200053
  validation loss:		0.353041
  validation accuracy:		89.57 %
Epoch 718 of 2000 took 0.104s
  training loss:		0.210336
  validation loss:		0.347913
  validation accuracy:		89.02 %
Epoch 719 of 2000 took 0.100s
  training loss:		0.206475
  validation loss:		0.348084
  validation accuracy:		89.02 %
Epoch 720 of 2000 took 0.104s
  training loss:		0.206611
  validation loss:		0.328435
  validation accuracy:		89.57 %
Epoch 721 of 2000 took 0.105s
  training loss:		0.201663
  validation loss:		0.347453
  validation accuracy:		89.35 %
Epoch 722 of 2000 took 0.101s
  training loss:		0.208808
  validation loss:		0.345374
  validation accuracy:		89.24 %
Epoch 723 of 2000 took 0.102s
  training loss:		0.208632
  validation loss:		0.339993
  validation accuracy:		89.57 %
Epoch 724 of 2000 took 0.100s
  training loss:		0.207241
  validation loss:		0.339933
  validation accuracy:		89.13 %
Epoch 725 of 2000 took 0.106s
  training loss:		0.206953
  validation loss:		0.327746
  validation accuracy:		89.24 %
Epoch 726 of 2000 took 0.102s
  training loss:		0.208304
  validation loss:		0.352530
  validation accuracy:		88.70 %
Epoch 727 of 2000 took 0.101s
  training loss:		0.202802
  validation loss:		0.338638
  validation accuracy:		89.02 %
Epoch 728 of 2000 took 0.108s
  training loss:		0.202757
  validation loss:		0.344263
  validation accuracy:		89.35 %
Epoch 729 of 2000 took 0.101s
  training loss:		0.209413
  validation loss:		0.337806
  validation accuracy:		89.13 %
Epoch 730 of 2000 took 0.102s
  training loss:		0.205140
  validation loss:		0.341668
  validation accuracy:		89.46 %
Epoch 731 of 2000 took 0.101s
  training loss:		0.197633
  validation loss:		0.338189
  validation accuracy:		89.13 %
Epoch 732 of 2000 took 0.103s
  training loss:		0.204040
  validation loss:		0.338447
  validation accuracy:		89.13 %
Epoch 733 of 2000 took 0.106s
  training loss:		0.206817
  validation loss:		0.344667
  validation accuracy:		89.13 %
Epoch 734 of 2000 took 0.100s
  training loss:		0.205109
  validation loss:		0.335899
  validation accuracy:		89.24 %
Epoch 735 of 2000 took 0.103s
  training loss:		0.203253
  validation loss:		0.336821
  validation accuracy:		89.13 %
Epoch 736 of 2000 took 0.107s
  training loss:		0.203565
  validation loss:		0.330330
  validation accuracy:		89.89 %
Epoch 737 of 2000 took 0.100s
  training loss:		0.208039
  validation loss:		0.340916
  validation accuracy:		89.46 %
Epoch 738 of 2000 took 0.103s
  training loss:		0.206412
  validation loss:		0.367973
  validation accuracy:		88.91 %
Epoch 739 of 2000 took 0.100s
  training loss:		0.201279
  validation loss:		0.345101
  validation accuracy:		89.24 %
Epoch 740 of 2000 took 0.106s
  training loss:		0.202264
  validation loss:		0.334008
  validation accuracy:		89.35 %
Epoch 741 of 2000 took 0.103s
  training loss:		0.207999
  validation loss:		0.362495
  validation accuracy:		88.91 %
Epoch 742 of 2000 took 0.100s
  training loss:		0.194429
  validation loss:		0.341939
  validation accuracy:		89.57 %
Epoch 743 of 2000 took 0.107s
  training loss:		0.198018
  validation loss:		0.341094
  validation accuracy:		89.24 %
Epoch 744 of 2000 took 0.102s
  training loss:		0.201400
  validation loss:		0.364687
  validation accuracy:		88.80 %
Epoch 745 of 2000 took 0.101s
  training loss:		0.199135
  validation loss:		0.361553
  validation accuracy:		88.59 %
Epoch 746 of 2000 took 0.101s
  training loss:		0.202790
  validation loss:		0.362139
  validation accuracy:		89.02 %
Epoch 747 of 2000 took 0.102s
  training loss:		0.201169
  validation loss:		0.348034
  validation accuracy:		89.13 %
Epoch 748 of 2000 took 0.106s
  training loss:		0.205325
  validation loss:		0.334860
  validation accuracy:		89.13 %
Epoch 749 of 2000 took 0.101s
  training loss:		0.207685
  validation loss:		0.342686
  validation accuracy:		88.91 %
Epoch 750 of 2000 took 0.102s
  training loss:		0.196145
  validation loss:		0.381625
  validation accuracy:		87.93 %
Epoch 751 of 2000 took 0.108s
  training loss:		0.203023
  validation loss:		0.355293
  validation accuracy:		89.24 %
Epoch 752 of 2000 took 0.100s
  training loss:		0.199088
  validation loss:		0.350966
  validation accuracy:		88.70 %
Epoch 753 of 2000 took 0.102s
  training loss:		0.202637
  validation loss:		0.359256
  validation accuracy:		89.35 %
Epoch 754 of 2000 took 0.100s
  training loss:		0.205974
  validation loss:		0.353028
  validation accuracy:		89.46 %
Epoch 755 of 2000 took 0.104s
  training loss:		0.206424
  validation loss:		0.349780
  validation accuracy:		88.91 %
Epoch 756 of 2000 took 0.105s
  training loss:		0.199890
  validation loss:		0.359877
  validation accuracy:		88.80 %
Epoch 757 of 2000 took 0.100s
  training loss:		0.205284
  validation loss:		0.364350
  validation accuracy:		89.13 %
Epoch 758 of 2000 took 0.104s
  training loss:		0.197132
  validation loss:		0.360147
  validation accuracy:		88.91 %
Epoch 759 of 2000 took 0.105s
  training loss:		0.200375
  validation loss:		0.348126
  validation accuracy:		89.35 %
Epoch 760 of 2000 took 0.101s
  training loss:		0.206294
  validation loss:		0.345060
  validation accuracy:		89.13 %
Epoch 761 of 2000 took 0.102s
  training loss:		0.196917
  validation loss:		0.336333
  validation accuracy:		89.24 %
Epoch 762 of 2000 took 0.101s
  training loss:		0.200521
  validation loss:		0.337966
  validation accuracy:		89.67 %
Epoch 763 of 2000 took 0.107s
  training loss:		0.201896
  validation loss:		0.351291
  validation accuracy:		89.24 %
Epoch 764 of 2000 took 0.102s
  training loss:		0.201775
  validation loss:		0.366935
  validation accuracy:		88.80 %
Epoch 765 of 2000 took 0.101s
  training loss:		0.203229
  validation loss:		0.352626
  validation accuracy:		88.91 %
Epoch 766 of 2000 took 0.108s
  training loss:		0.195614
  validation loss:		0.352661
  validation accuracy:		89.35 %
Epoch 767 of 2000 took 0.101s
  training loss:		0.196962
  validation loss:		0.347749
  validation accuracy:		89.02 %
Epoch 768 of 2000 took 0.102s
  training loss:		0.200743
  validation loss:		0.338781
  validation accuracy:		89.46 %
Epoch 769 of 2000 took 0.101s
  training loss:		0.196826
  validation loss:		0.344517
  validation accuracy:		89.35 %
Epoch 770 of 2000 took 0.102s
  training loss:		0.197045
  validation loss:		0.350461
  validation accuracy:		89.24 %
Epoch 771 of 2000 took 0.106s
  training loss:		0.199744
  validation loss:		0.355793
  validation accuracy:		89.35 %
Epoch 772 of 2000 took 0.100s
  training loss:		0.193871
  validation loss:		0.353068
  validation accuracy:		88.91 %
Epoch 773 of 2000 took 0.102s
  training loss:		0.193337
  validation loss:		0.360039
  validation accuracy:		88.26 %
Epoch 774 of 2000 took 0.107s
  training loss:		0.203228
  validation loss:		0.362530
  validation accuracy:		89.02 %
Epoch 775 of 2000 took 0.100s
  training loss:		0.195560
  validation loss:		0.348183
  validation accuracy:		89.24 %
Epoch 776 of 2000 took 0.103s
  training loss:		0.192731
  validation loss:		0.335262
  validation accuracy:		89.35 %
Epoch 777 of 2000 took 0.100s
  training loss:		0.195576
  validation loss:		0.338406
  validation accuracy:		89.57 %
Epoch 778 of 2000 took 0.106s
  training loss:		0.196753
  validation loss:		0.365422
  validation accuracy:		89.02 %
Epoch 779 of 2000 took 0.103s
  training loss:		0.192361
  validation loss:		0.344664
  validation accuracy:		89.46 %
Epoch 780 of 2000 took 0.100s
  training loss:		0.199545
  validation loss:		0.339724
  validation accuracy:		89.13 %
Epoch 781 of 2000 took 0.106s
  training loss:		0.197751
  validation loss:		0.341845
  validation accuracy:		89.02 %
Epoch 782 of 2000 took 0.103s
  training loss:		0.197641
  validation loss:		0.358435
  validation accuracy:		89.24 %
Epoch 783 of 2000 took 0.101s
  training loss:		0.190037
  validation loss:		0.357474
  validation accuracy:		88.80 %
Epoch 784 of 2000 took 0.101s
  training loss:		0.197261
  validation loss:		0.348627
  validation accuracy:		89.57 %
Epoch 785 of 2000 took 0.102s
  training loss:		0.195973
  validation loss:		0.357915
  validation accuracy:		89.13 %
Epoch 786 of 2000 took 0.106s
  training loss:		0.195891
  validation loss:		0.357433
  validation accuracy:		88.91 %
Epoch 787 of 2000 took 0.102s
  training loss:		0.201575
  validation loss:		0.356432
  validation accuracy:		88.80 %
Epoch 788 of 2000 took 0.101s
  training loss:		0.197287
  validation loss:		0.361826
  validation accuracy:		89.02 %
Epoch 789 of 2000 took 0.108s
  training loss:		0.195141
  validation loss:		0.358905
  validation accuracy:		88.91 %
Epoch 790 of 2000 took 0.100s
  training loss:		0.195294
  validation loss:		0.344353
  validation accuracy:		88.70 %
Epoch 791 of 2000 took 0.102s
  training loss:		0.197045
  validation loss:		0.361807
  validation accuracy:		88.59 %
Epoch 792 of 2000 took 0.100s
  training loss:		0.193204
  validation loss:		0.362322
  validation accuracy:		88.80 %
Epoch 793 of 2000 took 0.104s
  training loss:		0.196297
  validation loss:		0.342818
  validation accuracy:		88.80 %
Epoch 794 of 2000 took 0.105s
  training loss:		0.194703
  validation loss:		0.391675
  validation accuracy:		87.72 %
Epoch 795 of 2000 took 0.100s
  training loss:		0.198108
  validation loss:		0.356620
  validation accuracy:		88.70 %
Epoch 796 of 2000 took 0.104s
  training loss:		0.196396
  validation loss:		0.348929
  validation accuracy:		89.02 %
Epoch 797 of 2000 took 0.105s
  training loss:		0.195033
  validation loss:		0.346291
  validation accuracy:		89.02 %
Epoch 798 of 2000 took 0.101s
  training loss:		0.200644
  validation loss:		0.361695
  validation accuracy:		88.91 %
Epoch 799 of 2000 took 0.102s
  training loss:		0.204102
  validation loss:		0.368032
  validation accuracy:		88.80 %
Epoch 800 of 2000 took 0.100s
  training loss:		0.191017
  validation loss:		0.348416
  validation accuracy:		90.11 %
Epoch 801 of 2000 took 0.107s
  training loss:		0.195752
  validation loss:		0.346567
  validation accuracy:		89.02 %
Epoch 802 of 2000 took 0.102s
  training loss:		0.191774
  validation loss:		0.376150
  validation accuracy:		88.26 %
Epoch 803 of 2000 took 0.101s
  training loss:		0.193939
  validation loss:		0.338110
  validation accuracy:		89.13 %
Epoch 804 of 2000 took 0.108s
  training loss:		0.200300
  validation loss:		0.358517
  validation accuracy:		89.02 %
Epoch 805 of 2000 took 0.101s
  training loss:		0.193350
  validation loss:		0.359026
  validation accuracy:		87.83 %
Epoch 806 of 2000 took 0.102s
  training loss:		0.196049
  validation loss:		0.347449
  validation accuracy:		89.13 %
Epoch 807 of 2000 took 0.101s
  training loss:		0.192985
  validation loss:		0.349151
  validation accuracy:		89.46 %
Epoch 808 of 2000 took 0.103s
  training loss:		0.190354
  validation loss:		0.350787
  validation accuracy:		89.02 %
Epoch 809 of 2000 took 0.106s
  training loss:		0.192270
  validation loss:		0.349295
  validation accuracy:		88.80 %
Epoch 810 of 2000 took 0.100s
  training loss:		0.197422
  validation loss:		0.359975
  validation accuracy:		89.02 %
Epoch 811 of 2000 took 0.102s
  training loss:		0.189271
  validation loss:		0.372067
  validation accuracy:		89.02 %
Epoch 812 of 2000 took 0.107s
  training loss:		0.191597
  validation loss:		0.338138
  validation accuracy:		90.00 %
Epoch 813 of 2000 took 0.100s
  training loss:		0.195101
  validation loss:		0.348673
  validation accuracy:		89.02 %
Epoch 814 of 2000 took 0.102s
  training loss:		0.194389
  validation loss:		0.358078
  validation accuracy:		88.59 %
Epoch 815 of 2000 took 0.100s
  training loss:		0.189697
  validation loss:		0.360251
  validation accuracy:		88.04 %
Epoch 816 of 2000 took 0.106s
  training loss:		0.196342
  validation loss:		0.355257
  validation accuracy:		89.13 %
Epoch 817 of 2000 took 0.103s
  training loss:		0.190224
  validation loss:		0.349875
  validation accuracy:		88.91 %
Epoch 818 of 2000 took 0.100s
  training loss:		0.191659
  validation loss:		0.355922
  validation accuracy:		89.02 %
Epoch 819 of 2000 took 0.106s
  training loss:		0.193211
  validation loss:		0.369324
  validation accuracy:		88.91 %
Epoch 820 of 2000 took 0.105s
  training loss:		0.197301
  validation loss:		0.374721
  validation accuracy:		89.02 %
Epoch 821 of 2000 took 0.103s
  training loss:		0.199634
  validation loss:		0.357424
  validation accuracy:		89.67 %
Epoch 822 of 2000 took 0.101s
  training loss:		0.194747
  validation loss:		0.348888
  validation accuracy:		88.48 %
Epoch 823 of 2000 took 0.102s
  training loss:		0.183856
  validation loss:		0.362507
  validation accuracy:		88.37 %
Epoch 824 of 2000 took 0.106s
  training loss:		0.194808
  validation loss:		0.369560
  validation accuracy:		89.02 %
Epoch 825 of 2000 took 0.102s
  training loss:		0.195413
  validation loss:		0.353802
  validation accuracy:		88.26 %
Epoch 826 of 2000 took 0.102s
  training loss:		0.190582
  validation loss:		0.342816
  validation accuracy:		89.57 %
Epoch 827 of 2000 took 0.108s
  training loss:		0.186947
  validation loss:		0.359681
  validation accuracy:		88.91 %
Epoch 828 of 2000 took 0.100s
  training loss:		0.187903
  validation loss:		0.350598
  validation accuracy:		88.91 %
Epoch 829 of 2000 took 0.102s
  training loss:		0.192809
  validation loss:		0.361774
  validation accuracy:		89.02 %
Epoch 830 of 2000 took 0.100s
  training loss:		0.192041
  validation loss:		0.353808
  validation accuracy:		88.26 %
Epoch 831 of 2000 took 0.104s
  training loss:		0.196868
  validation loss:		0.360656
  validation accuracy:		89.46 %
Epoch 832 of 2000 took 0.105s
  training loss:		0.186832
  validation loss:		0.347623
  validation accuracy:		89.24 %
Epoch 833 of 2000 took 0.100s
  training loss:		0.187239
  validation loss:		0.364622
  validation accuracy:		88.37 %
Epoch 834 of 2000 took 0.104s
  training loss:		0.191369
  validation loss:		0.373065
  validation accuracy:		88.15 %
Epoch 835 of 2000 took 0.105s
  training loss:		0.196003
  validation loss:		0.362296
  validation accuracy:		89.13 %
Epoch 836 of 2000 took 0.101s
  training loss:		0.189245
  validation loss:		0.355565
  validation accuracy:		89.02 %
Epoch 837 of 2000 took 0.102s
  training loss:		0.186949
  validation loss:		0.346271
  validation accuracy:		89.13 %
Epoch 838 of 2000 took 0.101s
  training loss:		0.192921
  validation loss:		0.346145
  validation accuracy:		89.24 %
Epoch 839 of 2000 took 0.107s
  training loss:		0.189372
  validation loss:		0.361933
  validation accuracy:		88.59 %
Epoch 840 of 2000 took 0.103s
  training loss:		0.186672
  validation loss:		0.374696
  validation accuracy:		88.80 %
Epoch 841 of 2000 took 0.101s
  training loss:		0.185877
  validation loss:		0.359758
  validation accuracy:		88.91 %
Epoch 842 of 2000 took 0.108s
  training loss:		0.185865
  validation loss:		0.392067
  validation accuracy:		88.26 %
Epoch 843 of 2000 took 0.101s
  training loss:		0.189772
  validation loss:		0.353643
  validation accuracy:		88.80 %
Epoch 844 of 2000 took 0.102s
  training loss:		0.185013
  validation loss:		0.378991
  validation accuracy:		88.80 %
Epoch 845 of 2000 took 0.101s
  training loss:		0.188938
  validation loss:		0.356646
  validation accuracy:		89.24 %
Epoch 846 of 2000 took 0.103s
  training loss:		0.195878
  validation loss:		0.356972
  validation accuracy:		89.57 %
Epoch 847 of 2000 took 0.106s
  training loss:		0.189731
  validation loss:		0.350932
  validation accuracy:		90.00 %
Epoch 848 of 2000 took 0.101s
  training loss:		0.186574
  validation loss:		0.346756
  validation accuracy:		89.13 %
Epoch 849 of 2000 took 0.102s
  training loss:		0.183765
  validation loss:		0.342918
  validation accuracy:		89.24 %
Epoch 850 of 2000 took 0.107s
  training loss:		0.187240
  validation loss:		0.358920
  validation accuracy:		89.24 %
Epoch 851 of 2000 took 0.100s
  training loss:		0.187555
  validation loss:		0.352872
  validation accuracy:		89.02 %
Epoch 852 of 2000 took 0.102s
  training loss:		0.188294
  validation loss:		0.377042
  validation accuracy:		88.15 %
Epoch 853 of 2000 took 0.100s
  training loss:		0.189421
  validation loss:		0.350195
  validation accuracy:		88.70 %
Epoch 854 of 2000 took 0.105s
  training loss:		0.187829
  validation loss:		0.371125
  validation accuracy:		88.80 %
Epoch 855 of 2000 took 0.103s
  training loss:		0.187395
  validation loss:		0.380997
  validation accuracy:		88.80 %
Epoch 856 of 2000 took 0.100s
  training loss:		0.189733
  validation loss:		0.365426
  validation accuracy:		88.04 %
Epoch 857 of 2000 took 0.105s
  training loss:		0.188774
  validation loss:		0.357618
  validation accuracy:		88.91 %
Epoch 858 of 2000 took 0.104s
  training loss:		0.183958
  validation loss:		0.341364
  validation accuracy:		89.57 %
Epoch 859 of 2000 took 0.101s
  training loss:		0.181166
  validation loss:		0.352314
  validation accuracy:		88.15 %
Epoch 860 of 2000 took 0.101s
  training loss:		0.189959
  validation loss:		0.372763
  validation accuracy:		89.57 %
Epoch 861 of 2000 took 0.101s
  training loss:		0.190181
  validation loss:		0.349618
  validation accuracy:		88.59 %
Epoch 862 of 2000 took 0.106s
  training loss:		0.185918
  validation loss:		0.391342
  validation accuracy:		87.93 %
Epoch 863 of 2000 took 0.102s
  training loss:		0.190123
  validation loss:		0.358470
  validation accuracy:		88.59 %
Epoch 864 of 2000 took 0.101s
  training loss:		0.184692
  validation loss:		0.373565
  validation accuracy:		88.37 %
Epoch 865 of 2000 took 0.108s
  training loss:		0.186650
  validation loss:		0.356173
  validation accuracy:		88.37 %
Epoch 866 of 2000 took 0.100s
  training loss:		0.182894
  validation loss:		0.360280
  validation accuracy:		89.24 %
Epoch 867 of 2000 took 0.102s
  training loss:		0.189324
  validation loss:		0.369244
  validation accuracy:		88.70 %
Epoch 868 of 2000 took 0.100s
  training loss:		0.190244
  validation loss:		0.353918
  validation accuracy:		88.37 %
Epoch 869 of 2000 took 0.103s
  training loss:		0.182212
  validation loss:		0.364366
  validation accuracy:		88.91 %
Epoch 870 of 2000 took 0.106s
  training loss:		0.188121
  validation loss:		0.362474
  validation accuracy:		87.83 %
Epoch 871 of 2000 took 0.100s
  training loss:		0.186836
  validation loss:		0.351141
  validation accuracy:		89.67 %
Epoch 872 of 2000 took 0.103s
  training loss:		0.184428
  validation loss:		0.374025
  validation accuracy:		88.26 %
Epoch 873 of 2000 took 0.107s
  training loss:		0.190625
  validation loss:		0.353115
  validation accuracy:		88.70 %
Epoch 874 of 2000 took 0.100s
  training loss:		0.188485
  validation loss:		0.363781
  validation accuracy:		88.70 %
Epoch 875 of 2000 took 0.103s
  training loss:		0.190441
  validation loss:		0.365099
  validation accuracy:		88.59 %
Epoch 876 of 2000 took 0.100s
  training loss:		0.182851
  validation loss:		0.339781
  validation accuracy:		89.89 %
Epoch 877 of 2000 took 0.106s
  training loss:		0.186094
  validation loss:		0.364855
  validation accuracy:		88.70 %
Epoch 878 of 2000 took 0.103s
  training loss:		0.183705
  validation loss:		0.358775
  validation accuracy:		88.70 %
Epoch 879 of 2000 took 0.100s
  training loss:		0.180980
  validation loss:		0.375607
  validation accuracy:		88.70 %
Epoch 880 of 2000 took 0.107s
  training loss:		0.185823
  validation loss:		0.369816
  validation accuracy:		88.91 %
Epoch 881 of 2000 took 0.102s
  training loss:		0.185765
  validation loss:		0.373011
  validation accuracy:		88.70 %
Epoch 882 of 2000 took 0.101s
  training loss:		0.183128
  validation loss:		0.342729
  validation accuracy:		89.57 %
Epoch 883 of 2000 took 0.101s
  training loss:		0.180709
  validation loss:		0.369117
  validation accuracy:		88.80 %
Epoch 884 of 2000 took 0.102s
  training loss:		0.186687
  validation loss:		0.357958
  validation accuracy:		88.59 %
Epoch 885 of 2000 took 0.106s
  training loss:		0.188875
  validation loss:		0.357256
  validation accuracy:		88.70 %
Epoch 886 of 2000 took 0.102s
  training loss:		0.182249
  validation loss:		0.389333
  validation accuracy:		88.70 %
Epoch 887 of 2000 took 0.102s
  training loss:		0.183346
  validation loss:		0.355901
  validation accuracy:		88.37 %
Epoch 888 of 2000 took 0.108s
  training loss:		0.185379
  validation loss:		0.350135
  validation accuracy:		88.91 %
Epoch 889 of 2000 took 0.100s
  training loss:		0.188576
  validation loss:		0.375460
  validation accuracy:		88.48 %
Epoch 890 of 2000 took 0.102s
  training loss:		0.182950
  validation loss:		0.384915
  validation accuracy:		88.15 %
Epoch 891 of 2000 took 0.100s
  training loss:		0.179818
  validation loss:		0.381744
  validation accuracy:		87.72 %
Epoch 892 of 2000 took 0.104s
  training loss:		0.186563
  validation loss:		0.374389
  validation accuracy:		88.48 %
Epoch 893 of 2000 took 0.105s
  training loss:		0.181338
  validation loss:		0.368596
  validation accuracy:		88.70 %
Epoch 894 of 2000 took 0.100s
  training loss:		0.184600
  validation loss:		0.391525
  validation accuracy:		88.15 %
Epoch 895 of 2000 took 0.103s
  training loss:		0.184867
  validation loss:		0.382004
  validation accuracy:		87.72 %
Epoch 896 of 2000 took 0.106s
  training loss:		0.181318
  validation loss:		0.371375
  validation accuracy:		89.13 %
Epoch 897 of 2000 took 0.100s
  training loss:		0.184287
  validation loss:		0.370269
  validation accuracy:		89.13 %
Epoch 898 of 2000 took 0.102s
  training loss:		0.186080
  validation loss:		0.376704
  validation accuracy:		88.48 %
Epoch 899 of 2000 took 0.100s
  training loss:		0.188935
  validation loss:		0.348559
  validation accuracy:		89.35 %
Epoch 900 of 2000 took 0.107s
  training loss:		0.180424
  validation loss:		0.391560
  validation accuracy:		88.26 %
Epoch 901 of 2000 took 0.102s
  training loss:		0.184399
  validation loss:		0.367747
  validation accuracy:		89.02 %
Epoch 902 of 2000 took 0.100s
  training loss:		0.179265
  validation loss:		0.387656
  validation accuracy:		88.37 %
Epoch 903 of 2000 took 0.107s
  training loss:		0.180020
  validation loss:		0.353529
  validation accuracy:		89.46 %
Epoch 904 of 2000 took 0.101s
  training loss:		0.184193
  validation loss:		0.363094
  validation accuracy:		89.46 %
Epoch 905 of 2000 took 0.102s
  training loss:		0.183604
  validation loss:		0.371274
  validation accuracy:		88.59 %
Epoch 906 of 2000 took 0.101s
  training loss:		0.179711
  validation loss:		0.378223
  validation accuracy:		88.37 %
Epoch 907 of 2000 took 0.102s
  training loss:		0.190967
  validation loss:		0.355333
  validation accuracy:		88.80 %
Epoch 908 of 2000 took 0.106s
  training loss:		0.189404
  validation loss:		0.383388
  validation accuracy:		88.15 %
Epoch 909 of 2000 took 0.101s
  training loss:		0.177526
  validation loss:		0.358999
  validation accuracy:		88.80 %
Epoch 910 of 2000 took 0.102s
  training loss:		0.178741
  validation loss:		0.359036
  validation accuracy:		88.91 %
Epoch 911 of 2000 took 0.107s
  training loss:		0.181632
  validation loss:		0.379395
  validation accuracy:		88.70 %
Epoch 912 of 2000 took 0.100s
  training loss:		0.180557
  validation loss:		0.377687
  validation accuracy:		88.59 %
Epoch 913 of 2000 took 0.103s
  training loss:		0.183637
  validation loss:		0.358984
  validation accuracy:		88.59 %
Epoch 914 of 2000 took 0.100s
  training loss:		0.181990
  validation loss:		0.387578
  validation accuracy:		88.04 %
Epoch 915 of 2000 took 0.105s
  training loss:		0.186323
  validation loss:		0.367346
  validation accuracy:		89.13 %
Epoch 916 of 2000 took 0.104s
  training loss:		0.174966
  validation loss:		0.368013
  validation accuracy:		88.26 %
Epoch 917 of 2000 took 0.100s
  training loss:		0.180599
  validation loss:		0.373977
  validation accuracy:		88.48 %
Epoch 918 of 2000 took 0.105s
  training loss:		0.180944
  validation loss:		0.362041
  validation accuracy:		88.91 %
Epoch 919 of 2000 took 0.104s
  training loss:		0.180775
  validation loss:		0.366928
  validation accuracy:		89.24 %
Epoch 920 of 2000 took 0.102s
  training loss:		0.180199
  validation loss:		0.366427
  validation accuracy:		88.91 %
Epoch 921 of 2000 took 0.104s
  training loss:		0.180517
  validation loss:		0.363124
  validation accuracy:		89.02 %
Epoch 922 of 2000 took 0.144s
  training loss:		0.183703
  validation loss:		0.356363
  validation accuracy:		89.35 %
Epoch 923 of 2000 took 0.108s
  training loss:		0.181238
  validation loss:		0.349376
  validation accuracy:		89.13 %
Epoch 924 of 2000 took 0.102s
  training loss:		0.187494
  validation loss:		0.368841
  validation accuracy:		88.70 %
Epoch 925 of 2000 took 0.103s
  training loss:		0.180845
  validation loss:		0.364367
  validation accuracy:		88.80 %
Epoch 926 of 2000 took 0.111s
  training loss:		0.182070
  validation loss:		0.365875
  validation accuracy:		88.59 %
Epoch 927 of 2000 took 0.102s
  training loss:		0.175241
  validation loss:		0.353498
  validation accuracy:		89.02 %
Epoch 928 of 2000 took 0.104s
  training loss:		0.179721
  validation loss:		0.358125
  validation accuracy:		89.13 %
Epoch 929 of 2000 took 0.102s
  training loss:		0.178680
  validation loss:		0.372150
  validation accuracy:		88.48 %
Epoch 930 of 2000 took 0.104s
  training loss:		0.184763
  validation loss:		0.370545
  validation accuracy:		88.80 %
Epoch 931 of 2000 took 0.106s
  training loss:		0.182697
  validation loss:		0.376127
  validation accuracy:		88.26 %
Epoch 932 of 2000 took 0.100s
  training loss:		0.180461
  validation loss:		0.359755
  validation accuracy:		89.13 %
Epoch 933 of 2000 took 0.103s
  training loss:		0.176487
  validation loss:		0.375085
  validation accuracy:		88.80 %
Epoch 934 of 2000 took 0.107s
  training loss:		0.183824
  validation loss:		0.352639
  validation accuracy:		89.02 %
Epoch 935 of 2000 took 0.101s
  training loss:		0.179442
  validation loss:		0.363832
  validation accuracy:		89.02 %
Epoch 936 of 2000 took 0.103s
  training loss:		0.183271
  validation loss:		0.352017
  validation accuracy:		89.13 %
Epoch 937 of 2000 took 0.101s
  training loss:		0.182759
  validation loss:		0.373567
  validation accuracy:		88.80 %
Epoch 938 of 2000 took 0.107s
  training loss:		0.180979
  validation loss:		0.389928
  validation accuracy:		88.59 %
Epoch 939 of 2000 took 0.103s
  training loss:		0.182504
  validation loss:		0.373173
  validation accuracy:		89.02 %
Epoch 940 of 2000 took 0.100s
  training loss:		0.176794
  validation loss:		0.359997
  validation accuracy:		89.02 %
Epoch 941 of 2000 took 0.107s
  training loss:		0.184046
  validation loss:		0.393572
  validation accuracy:		88.48 %
Epoch 942 of 2000 took 0.102s
  training loss:		0.179799
  validation loss:		0.381598
  validation accuracy:		88.59 %
Epoch 943 of 2000 took 0.102s
  training loss:		0.171530
  validation loss:		0.355651
  validation accuracy:		88.80 %
Epoch 944 of 2000 took 0.101s
  training loss:		0.184562
  validation loss:		0.363242
  validation accuracy:		89.02 %
Epoch 945 of 2000 took 0.102s
  training loss:		0.175564
  validation loss:		0.358094
  validation accuracy:		89.13 %
Epoch 946 of 2000 took 0.107s
  training loss:		0.177968
  validation loss:		0.371707
  validation accuracy:		88.80 %
Epoch 947 of 2000 took 0.102s
  training loss:		0.183408
  validation loss:		0.367925
  validation accuracy:		88.91 %
Epoch 948 of 2000 took 0.102s
  training loss:		0.178940
  validation loss:		0.366914
  validation accuracy:		89.57 %
Epoch 949 of 2000 took 0.108s
  training loss:		0.180447
  validation loss:		0.366956
  validation accuracy:		89.02 %
Epoch 950 of 2000 took 0.100s
  training loss:		0.179214
  validation loss:		0.367583
  validation accuracy:		89.02 %
Epoch 951 of 2000 took 0.103s
  training loss:		0.183125
  validation loss:		0.364274
  validation accuracy:		88.91 %
Epoch 952 of 2000 took 0.100s
  training loss:		0.177300
  validation loss:		0.358865
  validation accuracy:		89.02 %
Epoch 953 of 2000 took 0.104s
  training loss:		0.173750
  validation loss:		0.376647
  validation accuracy:		88.59 %
Epoch 954 of 2000 took 0.105s
  training loss:		0.182356
  validation loss:		0.370909
  validation accuracy:		88.70 %
Epoch 955 of 2000 took 0.100s
  training loss:		0.176350
  validation loss:		0.400139
  validation accuracy:		88.59 %
Epoch 956 of 2000 took 0.105s
  training loss:		0.176957
  validation loss:		0.380692
  validation accuracy:		88.37 %
Epoch 957 of 2000 took 0.105s
  training loss:		0.186593
  validation loss:		0.373117
  validation accuracy:		89.13 %
Epoch 958 of 2000 took 0.101s
  training loss:		0.177336
  validation loss:		0.388693
  validation accuracy:		88.48 %
Epoch 959 of 2000 took 0.102s
  training loss:		0.179370
  validation loss:		0.381946
  validation accuracy:		88.59 %
Epoch 960 of 2000 took 0.101s
  training loss:		0.177846
  validation loss:		0.362793
  validation accuracy:		89.13 %
Epoch 961 of 2000 took 0.107s
  training loss:		0.175279
  validation loss:		0.352120
  validation accuracy:		89.24 %
Epoch 962 of 2000 took 0.102s
  training loss:		0.180803
  validation loss:		0.375086
  validation accuracy:		88.70 %
Epoch 963 of 2000 took 0.101s
  training loss:		0.179912
  validation loss:		0.376884
  validation accuracy:		89.02 %
Epoch 964 of 2000 took 0.138s
  training loss:		0.181934
  validation loss:		0.394571
  validation accuracy:		88.04 %
Epoch 965 of 2000 took 0.136s
  training loss:		0.180806
  validation loss:		0.383706
  validation accuracy:		88.59 %
Epoch 966 of 2000 took 0.152s
  training loss:		0.177995
  validation loss:		0.400435
  validation accuracy:		87.83 %
Epoch 967 of 2000 took 0.148s
  training loss:		0.175592
  validation loss:		0.378660
  validation accuracy:		88.91 %
Epoch 968 of 2000 took 0.132s
  training loss:		0.172867
  validation loss:		0.365827
  validation accuracy:		89.35 %
Epoch 969 of 2000 took 0.113s
  training loss:		0.174095
  validation loss:		0.368910
  validation accuracy:		88.91 %
Epoch 970 of 2000 took 0.107s
  training loss:		0.175605
  validation loss:		0.388259
  validation accuracy:		88.15 %
Epoch 971 of 2000 took 0.110s
  training loss:		0.174721
  validation loss:		0.378733
  validation accuracy:		88.59 %
Epoch 972 of 2000 took 0.114s
  training loss:		0.171271
  validation loss:		0.376190
  validation accuracy:		88.26 %
Epoch 973 of 2000 took 0.107s
  training loss:		0.171219
  validation loss:		0.390041
  validation accuracy:		88.37 %
Epoch 974 of 2000 took 0.109s
  training loss:		0.175723
  validation loss:		0.366749
  validation accuracy:		88.91 %
Epoch 975 of 2000 took 0.107s
  training loss:		0.174878
  validation loss:		0.368168
  validation accuracy:		88.26 %
Epoch 976 of 2000 took 0.113s
  training loss:		0.178248
  validation loss:		0.348583
  validation accuracy:		89.35 %
Epoch 977 of 2000 took 0.110s
  training loss:		0.174458
  validation loss:		0.370723
  validation accuracy:		88.91 %
Epoch 978 of 2000 took 0.107s
  training loss:		0.178698
  validation loss:		0.373627
  validation accuracy:		88.59 %
Epoch 979 of 2000 took 0.113s
  training loss:		0.178740
  validation loss:		0.373997
  validation accuracy:		89.02 %
Epoch 980 of 2000 took 0.110s
  training loss:		0.175169
  validation loss:		0.362921
  validation accuracy:		88.70 %
Epoch 981 of 2000 took 0.109s
  training loss:		0.173515
  validation loss:		0.370574
  validation accuracy:		88.59 %
Epoch 982 of 2000 took 0.109s
  training loss:		0.177894
  validation loss:		0.368980
  validation accuracy:		88.70 %
Epoch 983 of 2000 took 0.109s
  training loss:		0.171728
  validation loss:		0.381432
  validation accuracy:		88.59 %
Epoch 984 of 2000 took 0.113s
  training loss:		0.173640
  validation loss:		0.373819
  validation accuracy:		88.70 %
Epoch 985 of 2000 took 0.109s
  training loss:		0.175050
  validation loss:		0.371700
  validation accuracy:		88.91 %
Epoch 986 of 2000 took 0.110s
  training loss:		0.176272
  validation loss:		0.371505
  validation accuracy:		88.48 %
Epoch 987 of 2000 took 0.115s
  training loss:		0.174672
  validation loss:		0.363699
  validation accuracy:		89.02 %
Epoch 988 of 2000 took 0.108s
  training loss:		0.174899
  validation loss:		0.374495
  validation accuracy:		88.70 %
Epoch 989 of 2000 took 0.110s
  training loss:		0.176003
  validation loss:		0.356689
  validation accuracy:		89.13 %
Epoch 990 of 2000 took 0.108s
  training loss:		0.177917
  validation loss:		0.372031
  validation accuracy:		88.37 %
Epoch 991 of 2000 took 0.113s
  training loss:		0.174010
  validation loss:		0.375287
  validation accuracy:		88.59 %
Epoch 992 of 2000 took 0.111s
  training loss:		0.172349
  validation loss:		0.368669
  validation accuracy:		88.48 %
Epoch 993 of 2000 took 0.108s
  training loss:		0.173977
  validation loss:		0.366569
  validation accuracy:		89.02 %
Epoch 994 of 2000 took 0.113s
  training loss:		0.175039
  validation loss:		0.362745
  validation accuracy:		89.13 %
Epoch 995 of 2000 took 0.111s
  training loss:		0.183493
  validation loss:		0.379390
  validation accuracy:		88.37 %
Epoch 996 of 2000 took 0.109s
  training loss:		0.173495
  validation loss:		0.358305
  validation accuracy:		89.24 %
Epoch 997 of 2000 took 0.109s
  training loss:		0.169889
  validation loss:		0.365858
  validation accuracy:		88.48 %
Epoch 998 of 2000 took 0.109s
  training loss:		0.169981
  validation loss:		0.389324
  validation accuracy:		88.15 %
Epoch 999 of 2000 took 0.114s
  training loss:		0.177129
  validation loss:		0.383387
  validation accuracy:		88.80 %
Epoch 1000 of 2000 took 0.109s
  training loss:		0.173949
  validation loss:		0.374829
  validation accuracy:		87.93 %
Epoch 1001 of 2000 took 0.109s
  training loss:		0.168841
  validation loss:		0.386955
  validation accuracy:		88.37 %
Epoch 1002 of 2000 took 0.115s
  training loss:		0.173926
  validation loss:		0.374661
  validation accuracy:		88.59 %
Epoch 1003 of 2000 took 0.108s
  training loss:		0.173799
  validation loss:		0.365809
  validation accuracy:		88.80 %
Epoch 1004 of 2000 took 0.110s
  training loss:		0.173935
  validation loss:		0.390686
  validation accuracy:		88.37 %
Epoch 1005 of 2000 took 0.108s
  training loss:		0.170509
  validation loss:		0.370385
  validation accuracy:		88.80 %
Epoch 1006 of 2000 took 0.111s
  training loss:		0.173173
  validation loss:		0.359772
  validation accuracy:		89.24 %
Epoch 1007 of 2000 took 0.113s
  training loss:		0.174323
  validation loss:		0.370537
  validation accuracy:		89.24 %
Epoch 1008 of 2000 took 0.108s
  training loss:		0.171541
  validation loss:		0.352097
  validation accuracy:		89.13 %
Epoch 1009 of 2000 took 0.112s
  training loss:		0.173556
  validation loss:		0.380296
  validation accuracy:		88.70 %
Epoch 1010 of 2000 took 0.112s
  training loss:		0.176349
  validation loss:		0.359464
  validation accuracy:		89.35 %
Epoch 1011 of 2000 took 0.106s
  training loss:		0.167303
  validation loss:		0.357387
  validation accuracy:		89.02 %
Epoch 1012 of 2000 took 0.108s
  training loss:		0.169638
  validation loss:		0.362601
  validation accuracy:		88.80 %
Epoch 1013 of 2000 took 0.106s
  training loss:		0.177503
  validation loss:		0.365795
  validation accuracy:		88.91 %
Epoch 1014 of 2000 took 0.111s
  training loss:		0.171600
  validation loss:		0.371834
  validation accuracy:		88.70 %
Epoch 1015 of 2000 took 0.108s
  training loss:		0.167393
  validation loss:		0.388474
  validation accuracy:		88.59 %
Epoch 1016 of 2000 took 0.106s
  training loss:		0.166028
  validation loss:		0.368454
  validation accuracy:		89.02 %
Epoch 1017 of 2000 took 0.111s
  training loss:		0.170133
  validation loss:		0.400190
  validation accuracy:		88.15 %
Epoch 1018 of 2000 took 0.108s
  training loss:		0.172365
  validation loss:		0.380268
  validation accuracy:		88.70 %
Epoch 1019 of 2000 took 0.107s
  training loss:		0.171997
  validation loss:		0.368844
  validation accuracy:		88.91 %
Epoch 1020 of 2000 took 0.107s
  training loss:		0.170861
  validation loss:		0.384473
  validation accuracy:		88.91 %
Epoch 1021 of 2000 took 0.107s
  training loss:		0.165835
  validation loss:		0.375329
  validation accuracy:		88.59 %
Epoch 1022 of 2000 took 0.111s
  training loss:		0.174001
  validation loss:		0.371921
  validation accuracy:		89.02 %
Epoch 1023 of 2000 took 0.108s
  training loss:		0.169492
  validation loss:		0.386603
  validation accuracy:		89.02 %
Epoch 1024 of 2000 took 0.107s
  training loss:		0.169848
  validation loss:		0.363345
  validation accuracy:		89.13 %
Epoch 1025 of 2000 took 0.113s
  training loss:		0.169479
  validation loss:		0.366014
  validation accuracy:		88.91 %
Epoch 1026 of 2000 took 0.106s
  training loss:		0.170913
  validation loss:		0.389266
  validation accuracy:		88.70 %
Epoch 1027 of 2000 took 0.108s
  training loss:		0.167288
  validation loss:		0.360811
  validation accuracy:		89.35 %
Epoch 1028 of 2000 took 0.106s
  training loss:		0.167983
  validation loss:		0.360107
  validation accuracy:		89.24 %
Epoch 1029 of 2000 took 0.108s
  training loss:		0.172282
  validation loss:		0.364748
  validation accuracy:		88.91 %
Epoch 1030 of 2000 took 0.111s
  training loss:		0.165479
  validation loss:		0.370628
  validation accuracy:		88.91 %
Epoch 1031 of 2000 took 0.106s
  training loss:		0.166066
  validation loss:		0.364958
  validation accuracy:		88.91 %
Epoch 1032 of 2000 took 0.108s
  training loss:		0.169195
  validation loss:		0.370828
  validation accuracy:		88.80 %
Epoch 1033 of 2000 took 0.113s
  training loss:		0.167381
  validation loss:		0.370869
  validation accuracy:		88.80 %
Epoch 1034 of 2000 took 0.106s
  training loss:		0.165895
  validation loss:		0.362041
  validation accuracy:		89.35 %
Epoch 1035 of 2000 took 0.108s
  training loss:		0.171566
  validation loss:		0.375275
  validation accuracy:		88.70 %
Epoch 1036 of 2000 took 0.106s
  training loss:		0.171265
  validation loss:		0.384653
  validation accuracy:		89.13 %
Epoch 1037 of 2000 took 0.110s
  training loss:		0.167459
  validation loss:		0.369584
  validation accuracy:		89.13 %
Epoch 1038 of 2000 took 0.108s
  training loss:		0.167264
  validation loss:		0.359422
  validation accuracy:		89.57 %
Epoch 1039 of 2000 took 0.106s
  training loss:		0.162985
  validation loss:		0.398537
  validation accuracy:		88.37 %
Epoch 1040 of 2000 took 0.110s
  training loss:		0.167361
  validation loss:		0.362516
  validation accuracy:		89.02 %
Epoch 1041 of 2000 took 0.109s
  training loss:		0.166145
  validation loss:		0.370095
  validation accuracy:		89.35 %
Epoch 1042 of 2000 took 0.107s
  training loss:		0.166753
  validation loss:		0.384372
  validation accuracy:		88.48 %
Epoch 1043 of 2000 took 0.107s
  training loss:		0.161591
  validation loss:		0.358813
  validation accuracy:		89.46 %
Epoch 1044 of 2000 took 0.107s
  training loss:		0.166596
  validation loss:		0.362433
  validation accuracy:		89.13 %
Epoch 1045 of 2000 took 0.111s
  training loss:		0.168423
  validation loss:		0.375790
  validation accuracy:		88.91 %
Epoch 1046 of 2000 took 0.108s
  training loss:		0.160385
  validation loss:		0.381001
  validation accuracy:		88.80 %
Epoch 1047 of 2000 took 0.107s
  training loss:		0.164267
  validation loss:		0.367965
  validation accuracy:		89.02 %
Epoch 1048 of 2000 took 0.113s
  training loss:		0.160603
  validation loss:		0.370755
  validation accuracy:		89.46 %
Epoch 1049 of 2000 took 0.107s
  training loss:		0.164085
  validation loss:		0.363566
  validation accuracy:		89.35 %
Epoch 1050 of 2000 took 0.110s
  training loss:		0.172981
  validation loss:		0.388355
  validation accuracy:		88.48 %
Epoch 1051 of 2000 took 0.107s
  training loss:		0.167375
  validation loss:		0.388742
  validation accuracy:		88.70 %
Epoch 1052 of 2000 took 0.108s
  training loss:		0.165740
  validation loss:		0.363372
  validation accuracy:		89.13 %
Epoch 1053 of 2000 took 0.111s
  training loss:		0.164829
  validation loss:		0.377632
  validation accuracy:		88.80 %
Epoch 1054 of 2000 took 0.106s
  training loss:		0.165164
  validation loss:		0.385809
  validation accuracy:		88.59 %
Epoch 1055 of 2000 took 0.107s
  training loss:		0.168978
  validation loss:		0.389531
  validation accuracy:		88.37 %
Epoch 1056 of 2000 took 0.109s
  training loss:		0.163974
  validation loss:		0.371283
  validation accuracy:		88.91 %
Epoch 1057 of 2000 took 0.106s
  training loss:		0.163305
  validation loss:		0.355065
  validation accuracy:		89.46 %
Epoch 1058 of 2000 took 0.110s
  training loss:		0.165291
  validation loss:		0.368302
  validation accuracy:		89.24 %
Epoch 1059 of 2000 took 0.106s
  training loss:		0.163955
  validation loss:		0.373875
  validation accuracy:		89.02 %
Epoch 1060 of 2000 took 0.108s
  training loss:		0.165743
  validation loss:		0.384128
  validation accuracy:		88.91 %
Epoch 1061 of 2000 took 0.108s
  training loss:		0.165235
  validation loss:		0.369727
  validation accuracy:		89.02 %
Epoch 1062 of 2000 took 0.107s
  training loss:		0.164024
  validation loss:		0.376716
  validation accuracy:		89.13 %
Epoch 1063 of 2000 took 0.110s
  training loss:		0.164594
  validation loss:		0.389986
  validation accuracy:		88.26 %
Epoch 1064 of 2000 took 0.106s
  training loss:		0.160851
  validation loss:		0.378692
  validation accuracy:		89.13 %
Epoch 1065 of 2000 took 0.110s
  training loss:		0.161578
  validation loss:		0.394266
  validation accuracy:		88.48 %
Epoch 1066 of 2000 took 0.107s
  training loss:		0.167159
  validation loss:		0.381891
  validation accuracy:		88.48 %
Epoch 1067 of 2000 took 0.107s
  training loss:		0.163679
  validation loss:		0.373441
  validation accuracy:		89.24 %
Epoch 1068 of 2000 took 0.109s
  training loss:		0.164075
  validation loss:		0.359679
  validation accuracy:		89.46 %
Epoch 1069 of 2000 took 0.106s
  training loss:		0.161785
  validation loss:		0.363543
  validation accuracy:		89.13 %
Epoch 1070 of 2000 took 0.110s
  training loss:		0.161887
  validation loss:		0.374964
  validation accuracy:		89.24 %
Epoch 1071 of 2000 took 0.106s
  training loss:		0.164746
  validation loss:		0.381106
  validation accuracy:		88.80 %
Epoch 1072 of 2000 took 0.108s
  training loss:		0.162852
  validation loss:		0.362197
  validation accuracy:		89.35 %
Epoch 1073 of 2000 took 0.108s
  training loss:		0.165739
  validation loss:		0.396858
  validation accuracy:		88.59 %
Epoch 1074 of 2000 took 0.107s
  training loss:		0.163397
  validation loss:		0.374283
  validation accuracy:		88.91 %
Epoch 1075 of 2000 took 0.110s
  training loss:		0.169302
  validation loss:		0.383967
  validation accuracy:		88.91 %
Epoch 1076 of 2000 took 0.106s
  training loss:		0.157523
  validation loss:		0.400712
  validation accuracy:		88.91 %
Epoch 1077 of 2000 took 0.110s
  training loss:		0.158877
  validation loss:		0.378558
  validation accuracy:		88.80 %
Epoch 1078 of 2000 took 0.107s
  training loss:		0.159391
  validation loss:		0.367674
  validation accuracy:		89.24 %
Epoch 1079 of 2000 took 0.107s
  training loss:		0.163418
  validation loss:		0.359025
  validation accuracy:		89.35 %
Epoch 1080 of 2000 took 0.110s
  training loss:		0.163867
  validation loss:		0.388248
  validation accuracy:		88.70 %
Epoch 1081 of 2000 took 0.106s
  training loss:		0.167459
  validation loss:		0.357815
  validation accuracy:		89.13 %
Epoch 1082 of 2000 took 0.111s
  training loss:		0.166510
  validation loss:		0.374872
  validation accuracy:		89.02 %
Epoch 1083 of 2000 took 0.107s
  training loss:		0.161470
  validation loss:		0.374389
  validation accuracy:		89.24 %
Epoch 1084 of 2000 took 0.111s
  training loss:		0.166115
  validation loss:		0.372597
  validation accuracy:		89.13 %
Epoch 1085 of 2000 took 0.112s
  training loss:		0.162505
  validation loss:		0.378220
  validation accuracy:		88.91 %
Epoch 1086 of 2000 took 0.108s
  training loss:		0.166768
  validation loss:		0.369377
  validation accuracy:		89.24 %
Epoch 1087 of 2000 took 0.109s
  training loss:		0.160823
  validation loss:		0.390284
  validation accuracy:		88.91 %
Epoch 1088 of 2000 took 0.107s
  training loss:		0.164425
  validation loss:		0.380150
  validation accuracy:		89.02 %
Epoch 1089 of 2000 took 0.114s
  training loss:		0.161236
  validation loss:		0.368741
  validation accuracy:		89.35 %
Epoch 1090 of 2000 took 0.109s
  training loss:		0.155463
  validation loss:		0.369699
  validation accuracy:		89.24 %
Epoch 1091 of 2000 took 0.108s
  training loss:		0.166400
  validation loss:		0.381945
  validation accuracy:		88.59 %
Epoch 1092 of 2000 took 0.114s
  training loss:		0.163342
  validation loss:		0.360073
  validation accuracy:		89.35 %
Epoch 1093 of 2000 took 0.108s
  training loss:		0.163585
  validation loss:		0.375847
  validation accuracy:		89.02 %
Epoch 1094 of 2000 took 0.109s
  training loss:		0.158244
  validation loss:		0.372350
  validation accuracy:		89.13 %
Epoch 1095 of 2000 took 0.108s
  training loss:		0.159484
  validation loss:		0.372826
  validation accuracy:		89.13 %
Epoch 1096 of 2000 took 0.110s
  training loss:		0.160517
  validation loss:		0.377284
  validation accuracy:		88.70 %
Epoch 1097 of 2000 took 0.113s
  training loss:		0.160531
  validation loss:		0.368790
  validation accuracy:		89.35 %
Epoch 1098 of 2000 took 0.107s
  training loss:		0.162710
  validation loss:		0.370869
  validation accuracy:		89.35 %
Epoch 1099 of 2000 took 0.110s
  training loss:		0.160566
  validation loss:		0.389816
  validation accuracy:		88.37 %
Epoch 1100 of 2000 took 0.114s
  training loss:		0.162027
  validation loss:		0.389603
  validation accuracy:		89.02 %
Epoch 1101 of 2000 took 0.108s
  training loss:		0.156427
  validation loss:		0.361240
  validation accuracy:		89.35 %
Epoch 1102 of 2000 took 0.110s
  training loss:		0.159074
  validation loss:		0.412626
  validation accuracy:		88.04 %
Epoch 1103 of 2000 took 0.107s
  training loss:		0.159735
  validation loss:		0.358974
  validation accuracy:		89.46 %
Epoch 1104 of 2000 took 0.113s
  training loss:		0.158860
  validation loss:		0.357675
  validation accuracy:		89.57 %
Epoch 1105 of 2000 took 0.110s
  training loss:		0.162634
  validation loss:		0.357311
  validation accuracy:		89.67 %
Epoch 1106 of 2000 took 0.107s
  training loss:		0.161071
  validation loss:		0.375701
  validation accuracy:		88.80 %
Epoch 1107 of 2000 took 0.113s
  training loss:		0.157301
  validation loss:		0.393734
  validation accuracy:		88.59 %
Epoch 1108 of 2000 took 0.110s
  training loss:		0.158904
  validation loss:		0.373781
  validation accuracy:		89.02 %
Epoch 1109 of 2000 took 0.108s
  training loss:		0.158037
  validation loss:		0.362182
  validation accuracy:		89.57 %
Epoch 1110 of 2000 took 0.109s
  training loss:		0.158198
  validation loss:		0.378060
  validation accuracy:		89.24 %
Epoch 1111 of 2000 took 0.109s
  training loss:		0.160429
  validation loss:		0.376082
  validation accuracy:		89.02 %
Epoch 1112 of 2000 took 0.113s
  training loss:		0.154420
  validation loss:		0.387609
  validation accuracy:		88.70 %
Epoch 1113 of 2000 took 0.109s
  training loss:		0.160758
  validation loss:		0.365583
  validation accuracy:		89.24 %
Epoch 1114 of 2000 took 0.109s
  training loss:		0.160386
  validation loss:		0.368381
  validation accuracy:		89.57 %
Epoch 1115 of 2000 took 0.114s
  training loss:		0.159959
  validation loss:		0.405284
  validation accuracy:		88.26 %
Epoch 1116 of 2000 took 0.108s
  training loss:		0.157812
  validation loss:		0.362797
  validation accuracy:		89.46 %
Epoch 1117 of 2000 took 0.109s
  training loss:		0.159571
  validation loss:		0.367868
  validation accuracy:		89.35 %
Epoch 1118 of 2000 took 0.107s
  training loss:		0.156731
  validation loss:		0.368444
  validation accuracy:		89.46 %
Epoch 1119 of 2000 took 0.107s
  training loss:		0.156417
  validation loss:		0.378078
  validation accuracy:		89.13 %
Epoch 1120 of 2000 took 0.107s
  training loss:		0.157573
  validation loss:		0.381633
  validation accuracy:		88.80 %
Epoch 1121 of 2000 took 0.107s
  training loss:		0.156513
  validation loss:		0.390170
  validation accuracy:		88.80 %
Epoch 1122 of 2000 took 0.107s
  training loss:		0.154301
  validation loss:		0.370267
  validation accuracy:		89.13 %
Epoch 1123 of 2000 took 0.107s
  training loss:		0.157408
  validation loss:		0.372880
  validation accuracy:		89.78 %
Epoch 1124 of 2000 took 0.107s
  training loss:		0.156347
  validation loss:		0.399119
  validation accuracy:		88.91 %
Epoch 1125 of 2000 took 0.107s
  training loss:		0.160113
  validation loss:		0.358246
  validation accuracy:		89.35 %
Epoch 1126 of 2000 took 0.107s
  training loss:		0.159125
  validation loss:		0.369704
  validation accuracy:		88.91 %
Epoch 1127 of 2000 took 0.107s
  training loss:		0.152614
  validation loss:		0.379924
  validation accuracy:		89.13 %
Epoch 1128 of 2000 took 0.107s
  training loss:		0.155526
  validation loss:		0.366170
  validation accuracy:		89.57 %
Epoch 1129 of 2000 took 0.107s
  training loss:		0.161002
  validation loss:		0.370667
  validation accuracy:		89.13 %
Epoch 1130 of 2000 took 0.107s
  training loss:		0.157937
  validation loss:		0.372182
  validation accuracy:		89.35 %
Epoch 1131 of 2000 took 0.107s
  training loss:		0.155893
  validation loss:		0.378809
  validation accuracy:		89.35 %
Epoch 1132 of 2000 took 0.107s
  training loss:		0.151745
  validation loss:		0.385910
  validation accuracy:		88.80 %
Epoch 1133 of 2000 took 0.107s
  training loss:		0.154824
  validation loss:		0.370636
  validation accuracy:		89.35 %
Epoch 1134 of 2000 took 0.107s
  training loss:		0.154993
  validation loss:		0.372506
  validation accuracy:		89.46 %
Epoch 1135 of 2000 took 0.107s
  training loss:		0.155664
  validation loss:		0.368455
  validation accuracy:		89.57 %
Epoch 1136 of 2000 took 0.107s
  training loss:		0.157498
  validation loss:		0.369313
  validation accuracy:		89.46 %
Epoch 1137 of 2000 took 0.107s
  training loss:		0.153710
  validation loss:		0.390646
  validation accuracy:		89.02 %
Epoch 1138 of 2000 took 0.107s
  training loss:		0.151517
  validation loss:		0.377243
  validation accuracy:		89.13 %
Epoch 1139 of 2000 took 0.107s
  training loss:		0.155971
  validation loss:		0.390041
  validation accuracy:		89.02 %
Epoch 1140 of 2000 took 0.107s
  training loss:		0.157206
  validation loss:		0.362614
  validation accuracy:		89.78 %
Epoch 1141 of 2000 took 0.107s
  training loss:		0.149128
  validation loss:		0.363176
  validation accuracy:		89.89 %
Epoch 1142 of 2000 took 0.107s
  training loss:		0.154090
  validation loss:		0.387486
  validation accuracy:		89.46 %
Epoch 1143 of 2000 took 0.107s
  training loss:		0.153659
  validation loss:		0.371839
  validation accuracy:		89.89 %
Epoch 1144 of 2000 took 0.107s
  training loss:		0.155023
  validation loss:		0.375108
  validation accuracy:		89.46 %
Epoch 1145 of 2000 took 0.107s
  training loss:		0.154423
  validation loss:		0.386531
  validation accuracy:		89.13 %
Epoch 1146 of 2000 took 0.107s
  training loss:		0.152222
  validation loss:		0.359036
  validation accuracy:		89.57 %
Epoch 1147 of 2000 took 0.107s
  training loss:		0.155075
  validation loss:		0.365356
  validation accuracy:		89.35 %
Epoch 1148 of 2000 took 0.107s
  training loss:		0.151694
  validation loss:		0.360725
  validation accuracy:		89.89 %
Epoch 1149 of 2000 took 0.107s
  training loss:		0.156589
  validation loss:		0.378128
  validation accuracy:		89.35 %
Epoch 1150 of 2000 took 0.107s
  training loss:		0.152854
  validation loss:		0.378660
  validation accuracy:		89.35 %
Epoch 1151 of 2000 took 0.107s
  training loss:		0.149113
  validation loss:		0.368431
  validation accuracy:		89.67 %
Epoch 1152 of 2000 took 0.107s
  training loss:		0.153664
  validation loss:		0.365536
  validation accuracy:		89.67 %
Epoch 1153 of 2000 took 0.107s
  training loss:		0.152090
  validation loss:		0.369185
  validation accuracy:		89.67 %
Epoch 1154 of 2000 took 0.107s
  training loss:		0.153465
  validation loss:		0.366858
  validation accuracy:		89.67 %
Epoch 1155 of 2000 took 0.107s
  training loss:		0.150486
  validation loss:		0.367362
  validation accuracy:		90.00 %
Epoch 1156 of 2000 took 0.107s
  training loss:		0.156176
  validation loss:		0.377387
  validation accuracy:		89.57 %
Epoch 1157 of 2000 took 0.107s
  training loss:		0.147311
  validation loss:		0.378778
  validation accuracy:		89.67 %
Epoch 1158 of 2000 took 0.107s
  training loss:		0.145772
  validation loss:		0.383719
  validation accuracy:		89.24 %
Epoch 1159 of 2000 took 0.107s
  training loss:		0.152336
  validation loss:		0.358753
  validation accuracy:		89.78 %
Epoch 1160 of 2000 took 0.107s
  training loss:		0.150258
  validation loss:		0.356824
  validation accuracy:		89.57 %
Epoch 1161 of 2000 took 0.107s
  training loss:		0.151647
  validation loss:		0.374321
  validation accuracy:		89.57 %
Epoch 1162 of 2000 took 0.107s
  training loss:		0.149166
  validation loss:		0.364895
  validation accuracy:		89.78 %
Epoch 1163 of 2000 took 0.107s
  training loss:		0.148076
  validation loss:		0.367386
  validation accuracy:		90.00 %
Epoch 1164 of 2000 took 0.107s
  training loss:		0.148829
  validation loss:		0.369269
  validation accuracy:		89.13 %
Epoch 1165 of 2000 took 0.107s
  training loss:		0.148444
  validation loss:		0.369482
  validation accuracy:		89.78 %
Epoch 1166 of 2000 took 0.107s
  training loss:		0.149374
  validation loss:		0.376629
  validation accuracy:		89.35 %
Epoch 1167 of 2000 took 0.107s
  training loss:		0.144748
  validation loss:		0.387264
  validation accuracy:		89.13 %
Epoch 1168 of 2000 took 0.107s
  training loss:		0.150416
  validation loss:		0.391056
  validation accuracy:		88.80 %
Epoch 1169 of 2000 took 0.107s
  training loss:		0.152939
  validation loss:		0.383588
  validation accuracy:		89.46 %
Epoch 1170 of 2000 took 0.107s
  training loss:		0.150297
  validation loss:		0.406434
  validation accuracy:		89.35 %
Epoch 1171 of 2000 took 0.107s
  training loss:		0.143404
  validation loss:		0.386252
  validation accuracy:		89.02 %
Epoch 1172 of 2000 took 0.107s
  training loss:		0.151764
  validation loss:		0.388451
  validation accuracy:		89.35 %
Epoch 1173 of 2000 took 0.107s
  training loss:		0.148317
  validation loss:		0.378007
  validation accuracy:		89.46 %
Epoch 1174 of 2000 took 0.107s
  training loss:		0.147533
  validation loss:		0.391904
  validation accuracy:		89.24 %
Epoch 1175 of 2000 took 0.107s
  training loss:		0.149686
  validation loss:		0.371254
  validation accuracy:		89.46 %
Epoch 1176 of 2000 took 0.107s
  training loss:		0.146298
  validation loss:		0.393297
  validation accuracy:		88.70 %
Epoch 1177 of 2000 took 0.107s
  training loss:		0.149150
  validation loss:		0.374176
  validation accuracy:		89.78 %
Epoch 1178 of 2000 took 0.107s
  training loss:		0.149772
  validation loss:		0.365582
  validation accuracy:		89.89 %
Epoch 1179 of 2000 took 0.107s
  training loss:		0.144503
  validation loss:		0.389232
  validation accuracy:		89.24 %
Epoch 1180 of 2000 took 0.107s
  training loss:		0.150821
  validation loss:		0.371438
  validation accuracy:		89.46 %
Epoch 1181 of 2000 took 0.107s
  training loss:		0.148544
  validation loss:		0.383645
  validation accuracy:		89.35 %
Epoch 1182 of 2000 took 0.107s
  training loss:		0.150045
  validation loss:		0.386673
  validation accuracy:		89.35 %
Epoch 1183 of 2000 took 0.107s
  training loss:		0.152251
  validation loss:		0.368039
  validation accuracy:		89.78 %
Epoch 1184 of 2000 took 0.107s
  training loss:		0.144778
  validation loss:		0.382521
  validation accuracy:		89.78 %
Epoch 1185 of 2000 took 0.107s
  training loss:		0.148037
  validation loss:		0.380122
  validation accuracy:		89.02 %
Epoch 1186 of 2000 took 0.107s
  training loss:		0.146657
  validation loss:		0.374694
  validation accuracy:		89.89 %
Epoch 1187 of 2000 took 0.107s
  training loss:		0.145540
  validation loss:		0.377530
  validation accuracy:		89.57 %
Epoch 1188 of 2000 took 0.107s
  training loss:		0.151303
  validation loss:		0.390499
  validation accuracy:		89.24 %
Epoch 1189 of 2000 took 0.107s
  training loss:		0.145597
  validation loss:		0.371486
  validation accuracy:		89.67 %
Epoch 1190 of 2000 took 0.107s
  training loss:		0.146896
  validation loss:		0.365044
  validation accuracy:		90.22 %
Epoch 1191 of 2000 took 0.107s
  training loss:		0.145760
  validation loss:		0.395346
  validation accuracy:		89.24 %
Epoch 1192 of 2000 took 0.107s
  training loss:		0.145352
  validation loss:		0.377463
  validation accuracy:		89.46 %
Epoch 1193 of 2000 took 0.107s
  training loss:		0.149262
  validation loss:		0.379175
  validation accuracy:		89.89 %
Epoch 1194 of 2000 took 0.107s
  training loss:		0.145033
  validation loss:		0.409937
  validation accuracy:		88.80 %
Epoch 1195 of 2000 took 0.107s
  training loss:		0.148431
  validation loss:		0.394266
  validation accuracy:		89.46 %
Epoch 1196 of 2000 took 0.107s
  training loss:		0.148472
  validation loss:		0.372571
  validation accuracy:		89.35 %
Epoch 1197 of 2000 took 0.107s
  training loss:		0.145430
  validation loss:		0.400428
  validation accuracy:		89.57 %
Epoch 1198 of 2000 took 0.107s
  training loss:		0.148562
  validation loss:		0.372416
  validation accuracy:		89.89 %
Epoch 1199 of 2000 took 0.107s
  training loss:		0.147868
  validation loss:		0.390948
  validation accuracy:		89.13 %
Epoch 1200 of 2000 took 0.107s
  training loss:		0.147805
  validation loss:		0.389817
  validation accuracy:		89.57 %
Epoch 1201 of 2000 took 0.107s
  training loss:		0.149121
  validation loss:		0.370173
  validation accuracy:		89.78 %
Epoch 1202 of 2000 took 0.107s
  training loss:		0.148409
  validation loss:		0.384461
  validation accuracy:		89.78 %
Epoch 1203 of 2000 took 0.107s
  training loss:		0.146620
  validation loss:		0.372234
  validation accuracy:		90.00 %
Epoch 1204 of 2000 took 0.109s
  training loss:		0.142246
  validation loss:		0.371615
  validation accuracy:		89.78 %
Epoch 1205 of 2000 took 0.107s
  training loss:		0.138591
  validation loss:		0.372957
  validation accuracy:		90.11 %
Epoch 1206 of 2000 took 0.106s
  training loss:		0.146566
  validation loss:		0.396562
  validation accuracy:		89.67 %
Epoch 1207 of 2000 took 0.106s
  training loss:		0.147796
  validation loss:		0.403068
  validation accuracy:		89.89 %
Epoch 1208 of 2000 took 0.110s
  training loss:		0.148038
  validation loss:		0.373080
  validation accuracy:		90.00 %
Epoch 1209 of 2000 took 0.111s
  training loss:		0.146309
  validation loss:		0.372260
  validation accuracy:		89.78 %
Epoch 1210 of 2000 took 0.106s
  training loss:		0.143916
  validation loss:		0.379469
  validation accuracy:		89.78 %
Epoch 1211 of 2000 took 0.107s
  training loss:		0.145881
  validation loss:		0.364003
  validation accuracy:		90.11 %
Epoch 1212 of 2000 took 0.109s
  training loss:		0.140985
  validation loss:		0.385787
  validation accuracy:		89.89 %
Epoch 1213 of 2000 took 0.107s
  training loss:		0.146191
  validation loss:		0.386798
  validation accuracy:		89.24 %
Epoch 1214 of 2000 took 0.107s
  training loss:		0.145806
  validation loss:		0.368593
  validation accuracy:		89.89 %
Epoch 1215 of 2000 took 0.114s
  training loss:		0.140520
  validation loss:		0.376499
  validation accuracy:		89.89 %
Epoch 1216 of 2000 took 0.108s
  training loss:		0.143131
  validation loss:		0.380899
  validation accuracy:		89.78 %
Epoch 1217 of 2000 took 0.107s
  training loss:		0.143557
  validation loss:		0.365717
  validation accuracy:		90.11 %
Epoch 1218 of 2000 took 0.107s
  training loss:		0.143520
  validation loss:		0.372815
  validation accuracy:		90.11 %
Epoch 1219 of 2000 took 0.111s
  training loss:		0.146354
  validation loss:		0.384697
  validation accuracy:		89.46 %
Epoch 1220 of 2000 took 0.107s
  training loss:		0.143149
  validation loss:		0.376741
  validation accuracy:		90.22 %
Epoch 1221 of 2000 took 0.107s
  training loss:		0.144739
  validation loss:		0.395461
  validation accuracy:		89.78 %
Epoch 1222 of 2000 took 0.105s
  training loss:		0.139852
  validation loss:		0.376293
  validation accuracy:		89.46 %
Epoch 1223 of 2000 took 0.100s
  training loss:		0.143075
  validation loss:		0.367369
  validation accuracy:		90.33 %
Epoch 1224 of 2000 took 0.105s
  training loss:		0.139290
  validation loss:		0.377284
  validation accuracy:		89.89 %
Epoch 1225 of 2000 took 0.106s
  training loss:		0.142117
  validation loss:		0.373425
  validation accuracy:		89.89 %
Epoch 1226 of 2000 took 0.102s
  training loss:		0.142754
  validation loss:		0.391490
  validation accuracy:		89.78 %
Epoch 1227 of 2000 took 0.105s
  training loss:		0.142332
  validation loss:		0.401094
  validation accuracy:		89.57 %
Epoch 1228 of 2000 took 0.107s
  training loss:		0.141437
  validation loss:		0.385224
  validation accuracy:		90.11 %
Epoch 1229 of 2000 took 0.101s
  training loss:		0.143100
  validation loss:		0.380493
  validation accuracy:		89.89 %
Epoch 1230 of 2000 took 0.101s
  training loss:		0.137958
  validation loss:		0.369274
  validation accuracy:		90.00 %
Epoch 1231 of 2000 took 0.100s
  training loss:		0.141248
  validation loss:		0.389346
  validation accuracy:		89.57 %
Epoch 1232 of 2000 took 0.107s
  training loss:		0.143607
  validation loss:		0.376500
  validation accuracy:		90.00 %
Epoch 1233 of 2000 took 0.102s
  training loss:		0.139147
  validation loss:		0.405035
  validation accuracy:		89.13 %
Epoch 1234 of 2000 took 0.100s
  training loss:		0.136743
  validation loss:		0.363885
  validation accuracy:		90.00 %
Epoch 1235 of 2000 took 0.107s
  training loss:		0.139912
  validation loss:		0.375254
  validation accuracy:		90.00 %
Epoch 1236 of 2000 took 0.101s
  training loss:		0.136183
  validation loss:		0.384985
  validation accuracy:		89.13 %
Epoch 1237 of 2000 took 0.101s
  training loss:		0.144267
  validation loss:		0.384836
  validation accuracy:		89.67 %
Epoch 1238 of 2000 took 0.100s
  training loss:		0.144425
  validation loss:		0.392452
  validation accuracy:		89.67 %
Epoch 1239 of 2000 took 0.102s
  training loss:		0.140705
  validation loss:		0.403362
  validation accuracy:		89.02 %
Epoch 1240 of 2000 took 0.106s
  training loss:		0.134947
  validation loss:		0.390341
  validation accuracy:		89.78 %
Epoch 1241 of 2000 took 0.100s
  training loss:		0.136268
  validation loss:		0.381728
  validation accuracy:		90.33 %
Epoch 1242 of 2000 took 0.102s
  training loss:		0.134350
  validation loss:		0.382831
  validation accuracy:		89.89 %
Epoch 1243 of 2000 took 0.107s
  training loss:		0.137791
  validation loss:		0.384022
  validation accuracy:		90.33 %
Epoch 1244 of 2000 took 0.100s
  training loss:		0.141042
  validation loss:		0.394113
  validation accuracy:		90.22 %
Epoch 1245 of 2000 took 0.102s
  training loss:		0.141818
  validation loss:		0.368639
  validation accuracy:		90.33 %
Epoch 1246 of 2000 took 0.100s
  training loss:		0.143471
  validation loss:		0.386082
  validation accuracy:		89.67 %
Epoch 1247 of 2000 took 0.104s
  training loss:		0.136778
  validation loss:		0.393795
  validation accuracy:		89.89 %
Epoch 1248 of 2000 took 0.104s
  training loss:		0.138658
  validation loss:		0.374571
  validation accuracy:		90.00 %
Epoch 1249 of 2000 took 0.100s
  training loss:		0.140485
  validation loss:		0.399343
  validation accuracy:		89.46 %
Epoch 1250 of 2000 took 0.104s
  training loss:		0.140318
  validation loss:		0.382280
  validation accuracy:		89.78 %
Epoch 1251 of 2000 took 0.104s
  training loss:		0.141857
  validation loss:		0.385848
  validation accuracy:		89.78 %
Epoch 1252 of 2000 took 0.101s
  training loss:		0.136854
  validation loss:		0.372871
  validation accuracy:		90.76 %
Epoch 1253 of 2000 took 0.101s
  training loss:		0.136407
  validation loss:		0.401588
  validation accuracy:		89.67 %
Epoch 1254 of 2000 took 0.100s
  training loss:		0.137501
  validation loss:		0.411070
  validation accuracy:		89.24 %
Epoch 1255 of 2000 took 0.106s
  training loss:		0.137903
  validation loss:		0.391504
  validation accuracy:		89.57 %
Epoch 1256 of 2000 took 0.102s
  training loss:		0.136131
  validation loss:		0.398126
  validation accuracy:		90.11 %
Epoch 1257 of 2000 took 0.100s
  training loss:		0.142602
  validation loss:		0.397604
  validation accuracy:		89.35 %
Epoch 1258 of 2000 took 0.107s
  training loss:		0.139681
  validation loss:		0.376393
  validation accuracy:		90.43 %
Epoch 1259 of 2000 took 0.100s
  training loss:		0.135822
  validation loss:		0.383577
  validation accuracy:		90.11 %
Epoch 1260 of 2000 took 0.102s
  training loss:		0.133465
  validation loss:		0.404091
  validation accuracy:		89.78 %
Epoch 1261 of 2000 took 0.100s
  training loss:		0.134927
  validation loss:		0.395331
  validation accuracy:		90.11 %
Epoch 1262 of 2000 took 0.102s
  training loss:		0.134559
  validation loss:		0.394059
  validation accuracy:		89.46 %
Epoch 1263 of 2000 took 0.105s
  training loss:		0.124172
  validation loss:		0.386975
  validation accuracy:		90.22 %
Epoch 1264 of 2000 took 0.100s
  training loss:		0.135788
  validation loss:		0.400215
  validation accuracy:		89.67 %
Epoch 1265 of 2000 took 0.102s
  training loss:		0.137670
  validation loss:		0.400902
  validation accuracy:		89.57 %
Epoch 1266 of 2000 took 0.106s
  training loss:		0.135061
  validation loss:		0.403728
  validation accuracy:		89.24 %
Epoch 1267 of 2000 took 0.100s
  training loss:		0.145049
  validation loss:		0.396292
  validation accuracy:		89.35 %
Epoch 1268 of 2000 took 0.102s
  training loss:		0.131854
  validation loss:		0.397196
  validation accuracy:		89.35 %
Epoch 1269 of 2000 took 0.100s
  training loss:		0.131051
  validation loss:		0.376999
  validation accuracy:		90.65 %
Epoch 1270 of 2000 took 0.105s
  training loss:		0.130596
  validation loss:		0.382211
  validation accuracy:		90.22 %
Epoch 1271 of 2000 took 0.102s
  training loss:		0.135428
  validation loss:		0.419843
  validation accuracy:		89.46 %
Epoch 1272 of 2000 took 0.100s
  training loss:		0.141952
  validation loss:		0.405640
  validation accuracy:		89.24 %
Epoch 1273 of 2000 took 0.105s
  training loss:		0.133113
  validation loss:		0.389500
  validation accuracy:		89.67 %
Epoch 1274 of 2000 took 0.102s
  training loss:		0.140440
  validation loss:		0.395805
  validation accuracy:		89.57 %
Epoch 1275 of 2000 took 0.101s
  training loss:		0.131148
  validation loss:		0.393836
  validation accuracy:		90.22 %
Epoch 1276 of 2000 took 0.101s
  training loss:		0.131802
  validation loss:		0.407422
  validation accuracy:		90.11 %
Epoch 1277 of 2000 took 0.100s
  training loss:		0.134482
  validation loss:		0.401615
  validation accuracy:		90.11 %
Epoch 1278 of 2000 took 0.106s
  training loss:		0.135033
  validation loss:		0.397399
  validation accuracy:		90.00 %
Epoch 1279 of 2000 took 0.101s
  training loss:		0.128327
  validation loss:		0.390092
  validation accuracy:		90.65 %
Epoch 1280 of 2000 took 0.101s
  training loss:		0.129406
  validation loss:		0.403596
  validation accuracy:		89.67 %
Epoch 1281 of 2000 took 0.108s
  training loss:		0.134485
  validation loss:		0.385108
  validation accuracy:		90.33 %
Epoch 1282 of 2000 took 0.100s
  training loss:		0.131592
  validation loss:		0.404497
  validation accuracy:		89.57 %
Epoch 1283 of 2000 took 0.102s
  training loss:		0.137263
  validation loss:		0.398983
  validation accuracy:		89.78 %
Epoch 1284 of 2000 took 0.100s
  training loss:		0.132669
  validation loss:		0.413805
  validation accuracy:		89.67 %
Epoch 1285 of 2000 took 0.103s
  training loss:		0.132440
  validation loss:		0.381425
  validation accuracy:		90.54 %
Epoch 1286 of 2000 took 0.106s
  training loss:		0.134711
  validation loss:		0.407759
  validation accuracy:		89.46 %
Epoch 1287 of 2000 took 0.100s
  training loss:		0.132339
  validation loss:		0.405524
  validation accuracy:		89.78 %
Epoch 1288 of 2000 took 0.103s
  training loss:		0.135563
  validation loss:		0.419577
  validation accuracy:		89.24 %
Epoch 1289 of 2000 took 0.106s
  training loss:		0.132932
  validation loss:		0.403980
  validation accuracy:		90.00 %
Epoch 1290 of 2000 took 0.100s
  training loss:		0.134317
  validation loss:		0.386102
  validation accuracy:		90.43 %
Epoch 1291 of 2000 took 0.102s
  training loss:		0.134802
  validation loss:		0.413901
  validation accuracy:		89.24 %
Epoch 1292 of 2000 took 0.100s
  training loss:		0.131558
  validation loss:		0.405314
  validation accuracy:		89.57 %
Epoch 1293 of 2000 took 0.106s
  training loss:		0.135223
  validation loss:		0.386887
  validation accuracy:		90.33 %
Epoch 1294 of 2000 took 0.102s
  training loss:		0.133369
  validation loss:		0.409780
  validation accuracy:		89.02 %
Epoch 1295 of 2000 took 0.100s
  training loss:		0.133330
  validation loss:		0.393050
  validation accuracy:		90.43 %
Epoch 1296 of 2000 took 0.107s
  training loss:		0.130436
  validation loss:		0.399879
  validation accuracy:		89.89 %
Epoch 1297 of 2000 took 0.102s
  training loss:		0.131962
  validation loss:		0.394727
  validation accuracy:		90.22 %
Epoch 1298 of 2000 took 0.101s
  training loss:		0.135355
  validation loss:		0.410765
  validation accuracy:		89.35 %
Epoch 1299 of 2000 took 0.101s
  training loss:		0.135658
  validation loss:		0.399435
  validation accuracy:		89.89 %
Epoch 1300 of 2000 took 0.101s
  training loss:		0.128923
  validation loss:		0.408034
  validation accuracy:		89.67 %
Epoch 1301 of 2000 took 0.106s
  training loss:		0.130913
  validation loss:		0.398449
  validation accuracy:		90.22 %
Epoch 1302 of 2000 took 0.100s
  training loss:		0.131840
  validation loss:		0.412506
  validation accuracy:		89.24 %
Epoch 1303 of 2000 took 0.100s
  training loss:		0.134144
  validation loss:		0.400813
  validation accuracy:		90.33 %
Epoch 1304 of 2000 took 0.106s
  training loss:		0.129494
  validation loss:		0.410538
  validation accuracy:		90.11 %
Epoch 1305 of 2000 took 0.099s
  training loss:		0.132272
  validation loss:		0.398757
  validation accuracy:		90.11 %
Epoch 1306 of 2000 took 0.101s
  training loss:		0.135897
  validation loss:		0.405700
  validation accuracy:		90.22 %
Epoch 1307 of 2000 took 0.099s
  training loss:		0.131644
  validation loss:		0.412394
  validation accuracy:		90.11 %
Epoch 1308 of 2000 took 0.102s
  training loss:		0.136019
  validation loss:		0.411260
  validation accuracy:		90.22 %
Epoch 1309 of 2000 took 0.104s
  training loss:		0.129682
  validation loss:		0.405673
  validation accuracy:		90.00 %
Epoch 1310 of 2000 took 0.099s
  training loss:		0.129448
  validation loss:		0.397775
  validation accuracy:		90.43 %
Epoch 1311 of 2000 took 0.101s
  training loss:		0.137306
  validation loss:		0.396212
  validation accuracy:		89.89 %
Epoch 1312 of 2000 took 0.105s
  training loss:		0.129997
  validation loss:		0.420013
  validation accuracy:		89.35 %
Epoch 1313 of 2000 took 0.099s
  training loss:		0.129863
  validation loss:		0.424629
  validation accuracy:		89.78 %
Epoch 1314 of 2000 took 0.101s
  training loss:		0.130900
  validation loss:		0.406778
  validation accuracy:		90.11 %
Epoch 1315 of 2000 took 0.099s
  training loss:		0.128606
  validation loss:		0.396984
  validation accuracy:		90.43 %
Epoch 1316 of 2000 took 0.104s
  training loss:		0.130646
  validation loss:		0.419804
  validation accuracy:		89.89 %
Epoch 1317 of 2000 took 0.101s
  training loss:		0.128768
  validation loss:		0.404996
  validation accuracy:		90.22 %
Epoch 1318 of 2000 took 0.099s
  training loss:		0.129520
  validation loss:		0.408290
  validation accuracy:		90.11 %
Epoch 1319 of 2000 took 0.104s
  training loss:		0.126368
  validation loss:		0.405580
  validation accuracy:		90.00 %
Epoch 1320 of 2000 took 0.102s
  training loss:		0.126185
  validation loss:		0.410405
  validation accuracy:		89.67 %
Epoch 1321 of 2000 took 0.100s
  training loss:		0.126774
  validation loss:		0.434092
  validation accuracy:		89.78 %
Epoch 1322 of 2000 took 0.100s
  training loss:		0.131687
  validation loss:		0.389200
  validation accuracy:		90.43 %
Epoch 1323 of 2000 took 0.099s
  training loss:		0.128934
  validation loss:		0.398480
  validation accuracy:		90.11 %
Epoch 1324 of 2000 took 0.105s
  training loss:		0.127107
  validation loss:		0.396656
  validation accuracy:		90.43 %
Epoch 1325 of 2000 took 0.100s
  training loss:		0.128664
  validation loss:		0.392120
  validation accuracy:		90.65 %
Epoch 1326 of 2000 took 0.099s
  training loss:		0.128509
  validation loss:		0.407009
  validation accuracy:		90.11 %
Epoch 1327 of 2000 took 0.106s
  training loss:		0.125363
  validation loss:		0.400656
  validation accuracy:		90.43 %
Epoch 1328 of 2000 took 0.100s
  training loss:		0.129685
  validation loss:		0.392328
  validation accuracy:		90.33 %
Epoch 1329 of 2000 took 0.102s
  training loss:		0.125979
  validation loss:		0.428716
  validation accuracy:		90.11 %
Epoch 1330 of 2000 took 0.100s
  training loss:		0.123682
  validation loss:		0.438262
  validation accuracy:		89.46 %
Epoch 1331 of 2000 took 0.103s
  training loss:		0.126896
  validation loss:		0.403320
  validation accuracy:		90.00 %
Epoch 1332 of 2000 took 0.106s
  training loss:		0.128275
  validation loss:		0.411586
  validation accuracy:		89.67 %
Epoch 1333 of 2000 took 0.100s
  training loss:		0.126431
  validation loss:		0.402169
  validation accuracy:		89.78 %
Epoch 1334 of 2000 took 0.102s
  training loss:		0.128621
  validation loss:		0.416982
  validation accuracy:		90.11 %
Epoch 1335 of 2000 took 0.106s
  training loss:		0.125381
  validation loss:		0.396769
  validation accuracy:		90.43 %
Epoch 1336 of 2000 took 0.100s
  training loss:		0.125201
  validation loss:		0.405005
  validation accuracy:		89.78 %
Epoch 1337 of 2000 took 0.102s
  training loss:		0.128215
  validation loss:		0.402979
  validation accuracy:		90.65 %
Epoch 1338 of 2000 took 0.100s
  training loss:		0.126953
  validation loss:		0.411802
  validation accuracy:		89.78 %
Epoch 1339 of 2000 took 0.105s
  training loss:		0.124398
  validation loss:		0.391453
  validation accuracy:		90.76 %
Epoch 1340 of 2000 took 0.103s
  training loss:		0.126571
  validation loss:		0.421091
  validation accuracy:		89.89 %
Epoch 1341 of 2000 took 0.100s
  training loss:		0.125245
  validation loss:		0.431665
  validation accuracy:		89.35 %
Epoch 1342 of 2000 took 0.105s
  training loss:		0.126648
  validation loss:		0.402176
  validation accuracy:		90.00 %
Epoch 1343 of 2000 took 0.103s
  training loss:		0.124984
  validation loss:		0.406362
  validation accuracy:		90.00 %
Epoch 1344 of 2000 took 0.101s
  training loss:		0.123717
  validation loss:		0.415550
  validation accuracy:		89.78 %
Epoch 1345 of 2000 took 0.101s
  training loss:		0.122157
  validation loss:		0.432713
  validation accuracy:		89.57 %
Epoch 1346 of 2000 took 0.101s
  training loss:		0.126179
  validation loss:		0.419261
  validation accuracy:		89.57 %
Epoch 1347 of 2000 took 0.106s
  training loss:		0.126537
  validation loss:		0.406377
  validation accuracy:		90.43 %
Epoch 1348 of 2000 took 0.101s
  training loss:		0.125345
  validation loss:		0.403055
  validation accuracy:		90.00 %
Epoch 1349 of 2000 took 0.101s
  training loss:		0.123292
  validation loss:		0.407057
  validation accuracy:		90.11 %
Epoch 1350 of 2000 took 0.107s
  training loss:		0.122392
  validation loss:		0.427045
  validation accuracy:		89.46 %
Epoch 1351 of 2000 took 0.100s
  training loss:		0.123544
  validation loss:		0.406007
  validation accuracy:		90.54 %
Epoch 1352 of 2000 took 0.102s
  training loss:		0.125749
  validation loss:		0.413327
  validation accuracy:		90.22 %
Epoch 1353 of 2000 took 0.100s
  training loss:		0.128145
  validation loss:		0.424167
  validation accuracy:		89.89 %
Epoch 1354 of 2000 took 0.103s
  training loss:		0.124760
  validation loss:		0.418462
  validation accuracy:		89.78 %
Epoch 1355 of 2000 took 0.105s
  training loss:		0.120344
  validation loss:		0.407806
  validation accuracy:		90.54 %
Epoch 1356 of 2000 took 0.100s
  training loss:		0.124599
  validation loss:		0.416955
  validation accuracy:		89.89 %
Epoch 1357 of 2000 took 0.102s
  training loss:		0.125161
  validation loss:		0.410407
  validation accuracy:		89.89 %
Epoch 1358 of 2000 took 0.106s
  training loss:		0.126634
  validation loss:		0.426427
  validation accuracy:		89.89 %
Epoch 1359 of 2000 took 0.100s
  training loss:		0.129089
  validation loss:		0.402235
  validation accuracy:		90.43 %
Epoch 1360 of 2000 took 0.102s
  training loss:		0.124793
  validation loss:		0.415375
  validation accuracy:		89.89 %
Epoch 1361 of 2000 took 0.100s
  training loss:		0.117971
  validation loss:		0.417615
  validation accuracy:		89.78 %
Epoch 1362 of 2000 took 0.106s
  training loss:		0.126844
  validation loss:		0.422520
  validation accuracy:		89.57 %
Epoch 1363 of 2000 took 0.102s
  training loss:		0.122034
  validation loss:		0.422303
  validation accuracy:		90.33 %
Epoch 1364 of 2000 took 0.100s
  training loss:		0.120850
  validation loss:		0.429272
  validation accuracy:		89.89 %
Epoch 1365 of 2000 took 0.106s
  training loss:		0.119342
  validation loss:		0.425475
  validation accuracy:		90.22 %
Epoch 1366 of 2000 took 0.101s
  training loss:		0.122525
  validation loss:		0.430067
  validation accuracy:		90.00 %
Epoch 1367 of 2000 took 0.101s
  training loss:		0.121859
  validation loss:		0.419747
  validation accuracy:		89.78 %
Epoch 1368 of 2000 took 0.101s
  training loss:		0.126823
  validation loss:		0.421725
  validation accuracy:		90.33 %
Epoch 1369 of 2000 took 0.102s
  training loss:		0.122677
  validation loss:		0.430097
  validation accuracy:		89.46 %
Epoch 1370 of 2000 took 0.105s
  training loss:		0.119859
  validation loss:		0.412947
  validation accuracy:		90.65 %
Epoch 1371 of 2000 took 0.101s
  training loss:		0.120695
  validation loss:		0.412166
  validation accuracy:		90.22 %
Epoch 1372 of 2000 took 0.101s
  training loss:		0.117450
  validation loss:		0.410591
  validation accuracy:		90.22 %
Epoch 1373 of 2000 took 0.107s
  training loss:		0.121558
  validation loss:		0.409785
  validation accuracy:		90.33 %
Epoch 1374 of 2000 took 0.100s
  training loss:		0.122612
  validation loss:		0.433319
  validation accuracy:		90.00 %
Epoch 1375 of 2000 took 0.102s
  training loss:		0.122665
  validation loss:		0.423105
  validation accuracy:		90.22 %
Epoch 1376 of 2000 took 0.100s
  training loss:		0.120244
  validation loss:		0.413680
  validation accuracy:		90.11 %
Epoch 1377 of 2000 took 0.104s
  training loss:		0.124200
  validation loss:		0.414829
  validation accuracy:		90.54 %
Epoch 1378 of 2000 took 0.104s
  training loss:		0.121684
  validation loss:		0.412202
  validation accuracy:		90.11 %
Epoch 1379 of 2000 took 0.100s
  training loss:		0.122985
  validation loss:		0.417051
  validation accuracy:		90.65 %
Epoch 1380 of 2000 took 0.104s
  training loss:		0.119592
  validation loss:		0.444663
  validation accuracy:		89.67 %
Epoch 1381 of 2000 took 0.104s
  training loss:		0.121695
  validation loss:		0.425912
  validation accuracy:		90.00 %
Epoch 1382 of 2000 took 0.101s
  training loss:		0.119240
  validation loss:		0.454595
  validation accuracy:		89.78 %
Epoch 1383 of 2000 took 0.101s
  training loss:		0.120877
  validation loss:		0.415289
  validation accuracy:		90.11 %
Epoch 1384 of 2000 took 0.100s
  training loss:		0.119419
  validation loss:		0.421272
  validation accuracy:		90.11 %
Epoch 1385 of 2000 took 0.106s
  training loss:		0.118117
  validation loss:		0.424364
  validation accuracy:		90.33 %
Epoch 1386 of 2000 took 0.102s
  training loss:		0.120214
  validation loss:		0.423204
  validation accuracy:		90.76 %
Epoch 1387 of 2000 took 0.100s
  training loss:		0.117648
  validation loss:		0.418106
  validation accuracy:		90.00 %
Epoch 1388 of 2000 took 0.107s
  training loss:		0.121454
  validation loss:		0.424070
  validation accuracy:		90.22 %
Epoch 1389 of 2000 took 0.101s
  training loss:		0.119941
  validation loss:		0.439108
  validation accuracy:		90.11 %
Epoch 1390 of 2000 took 0.101s
  training loss:		0.121312
  validation loss:		0.421295
  validation accuracy:		90.65 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.119191
  validation loss:		0.431604
  validation accuracy:		90.22 %
Epoch 1392 of 2000 took 0.102s
  training loss:		0.117507
  validation loss:		0.419877
  validation accuracy:		90.22 %
Epoch 1393 of 2000 took 0.106s
  training loss:		0.121549
  validation loss:		0.427068
  validation accuracy:		90.22 %
Epoch 1394 of 2000 took 0.100s
  training loss:		0.121406
  validation loss:		0.426282
  validation accuracy:		90.22 %
Epoch 1395 of 2000 took 0.102s
  training loss:		0.122460
  validation loss:		0.446082
  validation accuracy:		89.78 %
Epoch 1396 of 2000 took 0.107s
  training loss:		0.125099
  validation loss:		0.432458
  validation accuracy:		90.43 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.123881
  validation loss:		0.426238
  validation accuracy:		90.11 %
Epoch 1398 of 2000 took 0.102s
  training loss:		0.117585
  validation loss:		0.438061
  validation accuracy:		90.00 %
Epoch 1399 of 2000 took 0.100s
  training loss:		0.119858
  validation loss:		0.437846
  validation accuracy:		90.22 %
Epoch 1400 of 2000 took 0.105s
  training loss:		0.121110
  validation loss:		0.428320
  validation accuracy:		90.11 %
Epoch 1401 of 2000 took 0.103s
  training loss:		0.125148
  validation loss:		0.417495
  validation accuracy:		90.43 %
Epoch 1402 of 2000 took 0.100s
  training loss:		0.119557
  validation loss:		0.429391
  validation accuracy:		90.22 %
Epoch 1403 of 2000 took 0.105s
  training loss:		0.118818
  validation loss:		0.439582
  validation accuracy:		90.00 %
Epoch 1404 of 2000 took 0.103s
  training loss:		0.114375
  validation loss:		0.433103
  validation accuracy:		90.11 %
Epoch 1405 of 2000 took 0.101s
  training loss:		0.118081
  validation loss:		0.406841
  validation accuracy:		90.22 %
Epoch 1406 of 2000 took 0.101s
  training loss:		0.117276
  validation loss:		0.444621
  validation accuracy:		90.11 %
Epoch 1407 of 2000 took 0.100s
  training loss:		0.116738
  validation loss:		0.443709
  validation accuracy:		90.11 %
Epoch 1408 of 2000 took 0.106s
  training loss:		0.115621
  validation loss:		0.443233
  validation accuracy:		89.89 %
Epoch 1409 of 2000 took 0.102s
  training loss:		0.116637
  validation loss:		0.431724
  validation accuracy:		90.54 %
Epoch 1410 of 2000 took 0.101s
  training loss:		0.117042
  validation loss:		0.462262
  validation accuracy:		90.00 %
Epoch 1411 of 2000 took 0.107s
  training loss:		0.120652
  validation loss:		0.424987
  validation accuracy:		90.33 %
Epoch 1412 of 2000 took 0.100s
  training loss:		0.115809
  validation loss:		0.424328
  validation accuracy:		90.33 %
Epoch 1413 of 2000 took 0.102s
  training loss:		0.118319
  validation loss:		0.440385
  validation accuracy:		90.22 %
Epoch 1414 of 2000 took 0.100s
  training loss:		0.122251
  validation loss:		0.448706
  validation accuracy:		90.22 %
Epoch 1415 of 2000 took 0.103s
  training loss:		0.116086
  validation loss:		0.416877
  validation accuracy:		90.11 %
Epoch 1416 of 2000 took 0.106s
  training loss:		0.113463
  validation loss:		0.422722
  validation accuracy:		90.43 %
Epoch 1417 of 2000 took 0.100s
  training loss:		0.112988
  validation loss:		0.420088
  validation accuracy:		90.22 %
Epoch 1418 of 2000 took 0.102s
  training loss:		0.118046
  validation loss:		0.423979
  validation accuracy:		90.11 %
Epoch 1419 of 2000 took 0.106s
  training loss:		0.112269
  validation loss:		0.419841
  validation accuracy:		90.54 %
Epoch 1420 of 2000 took 0.100s
  training loss:		0.114841
  validation loss:		0.438653
  validation accuracy:		89.78 %
Epoch 1421 of 2000 took 0.102s
  training loss:		0.118906
  validation loss:		0.419792
  validation accuracy:		90.33 %
Epoch 1422 of 2000 took 0.100s
  training loss:		0.121455
  validation loss:		0.421914
  validation accuracy:		90.43 %
Epoch 1423 of 2000 took 0.108s
  training loss:		0.119950
  validation loss:		0.452229
  validation accuracy:		90.11 %
Epoch 1424 of 2000 took 0.102s
  training loss:		0.120413
  validation loss:		0.435424
  validation accuracy:		89.89 %
Epoch 1425 of 2000 took 0.100s
  training loss:		0.115589
  validation loss:		0.463539
  validation accuracy:		89.67 %
Epoch 1426 of 2000 took 0.106s
  training loss:		0.114269
  validation loss:		0.440722
  validation accuracy:		90.11 %
Epoch 1427 of 2000 took 0.101s
  training loss:		0.114456
  validation loss:		0.416881
  validation accuracy:		90.43 %
Epoch 1428 of 2000 took 0.101s
  training loss:		0.116390
  validation loss:		0.420289
  validation accuracy:		90.22 %
Epoch 1429 of 2000 took 0.101s
  training loss:		0.112658
  validation loss:		0.465578
  validation accuracy:		90.22 %
Epoch 1430 of 2000 took 0.101s
  training loss:		0.112060
  validation loss:		0.438915
  validation accuracy:		90.54 %
Epoch 1431 of 2000 took 0.106s
  training loss:		0.113967
  validation loss:		0.442316
  validation accuracy:		90.33 %
Epoch 1432 of 2000 took 0.101s
  training loss:		0.118872
  validation loss:		0.425558
  validation accuracy:		90.33 %
Epoch 1433 of 2000 took 0.101s
  training loss:		0.116264
  validation loss:		0.435526
  validation accuracy:		90.22 %
Epoch 1434 of 2000 took 0.107s
  training loss:		0.113384
  validation loss:		0.448944
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.100s
  training loss:		0.116592
  validation loss:		0.429669
  validation accuracy:		90.11 %
Epoch 1436 of 2000 took 0.102s
  training loss:		0.112901
  validation loss:		0.430707
  validation accuracy:		90.54 %
Epoch 1437 of 2000 took 0.100s
  training loss:		0.109695
  validation loss:		0.416253
  validation accuracy:		90.33 %
Epoch 1438 of 2000 took 0.104s
  training loss:		0.121913
  validation loss:		0.425402
  validation accuracy:		90.43 %
Epoch 1439 of 2000 took 0.105s
  training loss:		0.112657
  validation loss:		0.436408
  validation accuracy:		90.54 %
Epoch 1440 of 2000 took 0.100s
  training loss:		0.111644
  validation loss:		0.434566
  validation accuracy:		90.33 %
Epoch 1441 of 2000 took 0.103s
  training loss:		0.111825
  validation loss:		0.461642
  validation accuracy:		90.11 %
Epoch 1442 of 2000 took 0.105s
  training loss:		0.111389
  validation loss:		0.437936
  validation accuracy:		90.33 %
Epoch 1443 of 2000 took 0.100s
  training loss:		0.109616
  validation loss:		0.445789
  validation accuracy:		90.22 %
Epoch 1444 of 2000 took 0.102s
  training loss:		0.113718
  validation loss:		0.441748
  validation accuracy:		89.78 %
Epoch 1445 of 2000 took 0.100s
  training loss:		0.114842
  validation loss:		0.420857
  validation accuracy:		90.54 %
Epoch 1446 of 2000 took 0.107s
  training loss:		0.105845
  validation loss:		0.487177
  validation accuracy:		89.46 %
Epoch 1447 of 2000 took 0.102s
  training loss:		0.112104
  validation loss:		0.430473
  validation accuracy:		90.22 %
Epoch 1448 of 2000 took 0.100s
  training loss:		0.110832
  validation loss:		0.469072
  validation accuracy:		90.00 %
Epoch 1449 of 2000 took 0.107s
  training loss:		0.111104
  validation loss:		0.442607
  validation accuracy:		89.89 %
Epoch 1450 of 2000 took 0.101s
  training loss:		0.111438
  validation loss:		0.454738
  validation accuracy:		90.43 %
Epoch 1451 of 2000 took 0.101s
  training loss:		0.113152
  validation loss:		0.463395
  validation accuracy:		90.11 %
Epoch 1452 of 2000 took 0.101s
  training loss:		0.111192
  validation loss:		0.447558
  validation accuracy:		89.89 %
Epoch 1453 of 2000 took 0.102s
  training loss:		0.111945
  validation loss:		0.428566
  validation accuracy:		90.33 %
Epoch 1454 of 2000 took 0.106s
  training loss:		0.111842
  validation loss:		0.436297
  validation accuracy:		90.54 %
Epoch 1455 of 2000 took 0.101s
  training loss:		0.113728
  validation loss:		0.436602
  validation accuracy:		90.54 %
Epoch 1456 of 2000 took 0.101s
  training loss:		0.115063
  validation loss:		0.469968
  validation accuracy:		90.11 %
Epoch 1457 of 2000 took 0.107s
  training loss:		0.110633
  validation loss:		0.479084
  validation accuracy:		89.89 %
Epoch 1458 of 2000 took 0.100s
  training loss:		0.114435
  validation loss:		0.434088
  validation accuracy:		90.00 %
Epoch 1459 of 2000 took 0.102s
  training loss:		0.117862
  validation loss:		0.452032
  validation accuracy:		90.43 %
Epoch 1460 of 2000 took 0.100s
  training loss:		0.114807
  validation loss:		0.445258
  validation accuracy:		90.22 %
Epoch 1461 of 2000 took 0.104s
  training loss:		0.110392
  validation loss:		0.454287
  validation accuracy:		90.00 %
Epoch 1462 of 2000 took 0.105s
  training loss:		0.108051
  validation loss:		0.444691
  validation accuracy:		90.00 %
Epoch 1463 of 2000 took 0.100s
  training loss:		0.110781
  validation loss:		0.445151
  validation accuracy:		90.22 %
Epoch 1464 of 2000 took 0.103s
  training loss:		0.110755
  validation loss:		0.449654
  validation accuracy:		90.22 %
Epoch 1465 of 2000 took 0.105s
  training loss:		0.109291
  validation loss:		0.451962
  validation accuracy:		90.33 %
Epoch 1466 of 2000 took 0.100s
  training loss:		0.114182
  validation loss:		0.441571
  validation accuracy:		90.54 %
Epoch 1467 of 2000 took 0.102s
  training loss:		0.109586
  validation loss:		0.438713
  validation accuracy:		90.33 %
Epoch 1468 of 2000 took 0.100s
  training loss:		0.113249
  validation loss:		0.450295
  validation accuracy:		90.54 %
Epoch 1469 of 2000 took 0.106s
  training loss:		0.113475
  validation loss:		0.453806
  validation accuracy:		90.22 %
Epoch 1470 of 2000 took 0.102s
  training loss:		0.113250
  validation loss:		0.456953
  validation accuracy:		90.54 %
Epoch 1471 of 2000 took 0.100s
  training loss:		0.110579
  validation loss:		0.450434
  validation accuracy:		90.76 %
Epoch 1472 of 2000 took 0.107s
  training loss:		0.108423
  validation loss:		0.459563
  validation accuracy:		90.11 %
Epoch 1473 of 2000 took 0.101s
  training loss:		0.110528
  validation loss:		0.485308
  validation accuracy:		89.78 %
Epoch 1474 of 2000 took 0.101s
  training loss:		0.113404
  validation loss:		0.450346
  validation accuracy:		90.22 %
Epoch 1475 of 2000 took 0.101s
  training loss:		0.109170
  validation loss:		0.492888
  validation accuracy:		90.11 %
Epoch 1476 of 2000 took 0.102s
  training loss:		0.107320
  validation loss:		0.451916
  validation accuracy:		90.33 %
Epoch 1477 of 2000 took 0.106s
  training loss:		0.105617
  validation loss:		0.439437
  validation accuracy:		90.33 %
Epoch 1478 of 2000 took 0.101s
  training loss:		0.107402
  validation loss:		0.472840
  validation accuracy:		90.00 %
Epoch 1479 of 2000 took 0.102s
  training loss:		0.107823
  validation loss:		0.457324
  validation accuracy:		89.89 %
Epoch 1480 of 2000 took 0.107s
  training loss:		0.110422
  validation loss:		0.448692
  validation accuracy:		90.54 %
Epoch 1481 of 2000 took 0.100s
  training loss:		0.107818
  validation loss:		0.477754
  validation accuracy:		90.22 %
Epoch 1482 of 2000 took 0.102s
  training loss:		0.109238
  validation loss:		0.458976
  validation accuracy:		90.33 %
Epoch 1483 of 2000 took 0.100s
  training loss:		0.105675
  validation loss:		0.473063
  validation accuracy:		90.22 %
Epoch 1484 of 2000 took 0.104s
  training loss:		0.109211
  validation loss:		0.446796
  validation accuracy:		90.54 %
Epoch 1485 of 2000 took 0.104s
  training loss:		0.106979
  validation loss:		0.475993
  validation accuracy:		89.89 %
Epoch 1486 of 2000 took 0.100s
  training loss:		0.107422
  validation loss:		0.456595
  validation accuracy:		90.22 %
Epoch 1487 of 2000 took 0.104s
  training loss:		0.109175
  validation loss:		0.454268
  validation accuracy:		90.33 %
Epoch 1488 of 2000 took 0.101s
  training loss:		0.106674
  validation loss:		0.440744
  validation accuracy:		90.33 %
Epoch 1489 of 2000 took 0.101s
  training loss:		0.108645
  validation loss:		0.458225
  validation accuracy:		90.33 %
Epoch 1490 of 2000 took 0.104s
  training loss:		0.117190
  validation loss:		0.456927
  validation accuracy:		90.33 %
Epoch 1491 of 2000 took 0.100s
  training loss:		0.109709
  validation loss:		0.465631
  validation accuracy:		90.33 %
Epoch 1492 of 2000 took 0.106s
  training loss:		0.112299
  validation loss:		0.489190
  validation accuracy:		90.11 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.110453
  validation loss:		0.469444
  validation accuracy:		90.22 %
Epoch 1494 of 2000 took 0.102s
  training loss:		0.105895
  validation loss:		0.463507
  validation accuracy:		90.33 %
Epoch 1495 of 2000 took 0.103s
  training loss:		0.110341
  validation loss:		0.471021
  validation accuracy:		89.78 %
Epoch 1496 of 2000 took 0.100s
  training loss:		0.112379
  validation loss:		0.470192
  validation accuracy:		89.67 %
Epoch 1497 of 2000 took 0.105s
  training loss:		0.106101
  validation loss:		0.475959
  validation accuracy:		90.22 %
Epoch 1498 of 2000 took 0.100s
  training loss:		0.103340
  validation loss:		0.485405
  validation accuracy:		89.35 %
Epoch 1499 of 2000 took 0.104s
  training loss:		0.107390
  validation loss:		0.466917
  validation accuracy:		90.33 %
Epoch 1500 of 2000 took 0.101s
  training loss:		0.105414
  validation loss:		0.479743
  validation accuracy:		90.00 %
Epoch 1501 of 2000 took 0.102s
  training loss:		0.110650
  validation loss:		0.461683
  validation accuracy:		90.11 %
Epoch 1502 of 2000 took 0.104s
  training loss:		0.103697
  validation loss:		0.452784
  validation accuracy:		90.43 %
Epoch 1503 of 2000 took 0.100s
  training loss:		0.117385
  validation loss:		0.478333
  validation accuracy:		90.22 %
Epoch 1504 of 2000 took 0.106s
  training loss:		0.106552
  validation loss:		0.462912
  validation accuracy:		90.22 %
Epoch 1505 of 2000 took 0.100s
  training loss:		0.107163
  validation loss:		0.509597
  validation accuracy:		89.89 %
Epoch 1506 of 2000 took 0.103s
  training loss:		0.108367
  validation loss:		0.447091
  validation accuracy:		90.43 %
Epoch 1507 of 2000 took 0.102s
  training loss:		0.107420
  validation loss:		0.494170
  validation accuracy:		90.11 %
Epoch 1508 of 2000 took 0.101s
  training loss:		0.108672
  validation loss:		0.467507
  validation accuracy:		90.00 %
Epoch 1509 of 2000 took 0.104s
  training loss:		0.105383
  validation loss:		0.463647
  validation accuracy:		90.43 %
Epoch 1510 of 2000 took 0.100s
  training loss:		0.103244
  validation loss:		0.487593
  validation accuracy:		89.78 %
Epoch 1511 of 2000 took 0.105s
  training loss:		0.107710
  validation loss:		0.462715
  validation accuracy:		90.11 %
Epoch 1512 of 2000 took 0.100s
  training loss:		0.111800
  validation loss:		0.468371
  validation accuracy:		89.89 %
Epoch 1513 of 2000 took 0.102s
  training loss:		0.104622
  validation loss:		0.477966
  validation accuracy:		90.11 %
Epoch 1514 of 2000 took 0.103s
  training loss:		0.109809
  validation loss:		0.458321
  validation accuracy:		90.43 %
Epoch 1515 of 2000 took 0.100s
  training loss:		0.107532
  validation loss:		0.474693
  validation accuracy:		90.43 %
Epoch 1516 of 2000 took 0.107s
  training loss:		0.105701
  validation loss:		0.475961
  validation accuracy:		90.33 %
Epoch 1517 of 2000 took 0.100s
  training loss:		0.110311
  validation loss:		0.468980
  validation accuracy:		89.78 %
Epoch 1518 of 2000 took 0.102s
  training loss:		0.099672
  validation loss:		0.460014
  validation accuracy:		89.89 %
Epoch 1519 of 2000 took 0.100s
  training loss:		0.102925
  validation loss:		0.448905
  validation accuracy:		90.76 %
Epoch 1520 of 2000 took 0.102s
  training loss:		0.102946
  validation loss:		0.508785
  validation accuracy:		89.89 %
Epoch 1521 of 2000 took 0.106s
  training loss:		0.106752
  validation loss:		0.460935
  validation accuracy:		90.54 %
Epoch 1522 of 2000 took 0.100s
  training loss:		0.103210
  validation loss:		0.460264
  validation accuracy:		90.33 %
Epoch 1523 of 2000 took 0.103s
  training loss:		0.106428
  validation loss:		0.458257
  validation accuracy:		90.54 %
Epoch 1524 of 2000 took 0.106s
  training loss:		0.108435
  validation loss:		0.472876
  validation accuracy:		90.33 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.105867
  validation loss:		0.465370
  validation accuracy:		90.33 %
Epoch 1526 of 2000 took 0.102s
  training loss:		0.103179
  validation loss:		0.488147
  validation accuracy:		90.00 %
Epoch 1527 of 2000 took 0.100s
  training loss:		0.105265
  validation loss:		0.471556
  validation accuracy:		90.43 %
Epoch 1528 of 2000 took 0.105s
  training loss:		0.100998
  validation loss:		0.466868
  validation accuracy:		90.33 %
Epoch 1529 of 2000 took 0.103s
  training loss:		0.105253
  validation loss:		0.481600
  validation accuracy:		90.33 %
Epoch 1530 of 2000 took 0.100s
  training loss:		0.104457
  validation loss:		0.499621
  validation accuracy:		90.00 %
Epoch 1531 of 2000 took 0.105s
  training loss:		0.107565
  validation loss:		0.473662
  validation accuracy:		90.22 %
Epoch 1532 of 2000 took 0.103s
  training loss:		0.108341
  validation loss:		0.463994
  validation accuracy:		90.11 %
Epoch 1533 of 2000 took 0.101s
  training loss:		0.107588
  validation loss:		0.459829
  validation accuracy:		90.00 %
Epoch 1534 of 2000 took 0.101s
  training loss:		0.104585
  validation loss:		0.487172
  validation accuracy:		89.89 %
Epoch 1535 of 2000 took 0.100s
  training loss:		0.103556
  validation loss:		0.471565
  validation accuracy:		90.33 %
Epoch 1536 of 2000 took 0.106s
  training loss:		0.104008
  validation loss:		0.495104
  validation accuracy:		90.22 %
Epoch 1537 of 2000 took 0.101s
  training loss:		0.103984
  validation loss:		0.475427
  validation accuracy:		90.33 %
Epoch 1538 of 2000 took 0.101s
  training loss:		0.109474
  validation loss:		0.478735
  validation accuracy:		90.54 %
Epoch 1539 of 2000 took 0.107s
  training loss:		0.101510
  validation loss:		0.476325
  validation accuracy:		90.43 %
Epoch 1540 of 2000 took 0.100s
  training loss:		0.101985
  validation loss:		0.478178
  validation accuracy:		90.54 %
Epoch 1541 of 2000 took 0.102s
  training loss:		0.105001
  validation loss:		0.498048
  validation accuracy:		89.67 %
Epoch 1542 of 2000 took 0.100s
  training loss:		0.106983
  validation loss:		0.473742
  validation accuracy:		90.54 %
Epoch 1543 of 2000 took 0.103s
  training loss:		0.102214
  validation loss:		0.484151
  validation accuracy:		90.43 %
Epoch 1544 of 2000 took 0.106s
  training loss:		0.100888
  validation loss:		0.498011
  validation accuracy:		90.33 %
Epoch 1545 of 2000 took 0.100s
  training loss:		0.101366
  validation loss:		0.480840
  validation accuracy:		89.89 %
Epoch 1546 of 2000 took 0.102s
  training loss:		0.105694
  validation loss:		0.488459
  validation accuracy:		90.22 %
Epoch 1547 of 2000 took 0.106s
  training loss:		0.105700
  validation loss:		0.463799
  validation accuracy:		90.00 %
Epoch 1548 of 2000 took 0.100s
  training loss:		0.104043
  validation loss:		0.472602
  validation accuracy:		90.54 %
Epoch 1549 of 2000 took 0.102s
  training loss:		0.108041
  validation loss:		0.485275
  validation accuracy:		90.22 %
Epoch 1550 of 2000 took 0.100s
  training loss:		0.102499
  validation loss:		0.489308
  validation accuracy:		89.67 %
Epoch 1551 of 2000 took 0.106s
  training loss:		0.105425
  validation loss:		0.473468
  validation accuracy:		90.22 %
Epoch 1552 of 2000 took 0.102s
  training loss:		0.101585
  validation loss:		0.486237
  validation accuracy:		90.33 %
Epoch 1553 of 2000 took 0.100s
  training loss:		0.102198
  validation loss:		0.474927
  validation accuracy:		90.54 %
Epoch 1554 of 2000 took 0.106s
  training loss:		0.108184
  validation loss:		0.520698
  validation accuracy:		89.67 %
Epoch 1555 of 2000 took 0.102s
  training loss:		0.105407
  validation loss:		0.469645
  validation accuracy:		90.22 %
Epoch 1556 of 2000 took 0.101s
  training loss:		0.097441
  validation loss:		0.478228
  validation accuracy:		90.33 %
Epoch 1557 of 2000 took 0.101s
  training loss:		0.099642
  validation loss:		0.498164
  validation accuracy:		90.00 %
Epoch 1558 of 2000 took 0.101s
  training loss:		0.105509
  validation loss:		0.472652
  validation accuracy:		90.54 %
Epoch 1559 of 2000 took 0.106s
  training loss:		0.101883
  validation loss:		0.480993
  validation accuracy:		89.89 %
Epoch 1560 of 2000 took 0.101s
  training loss:		0.100684
  validation loss:		0.474140
  validation accuracy:		90.33 %
Epoch 1561 of 2000 took 0.101s
  training loss:		0.106223
  validation loss:		0.488406
  validation accuracy:		90.33 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.101842
  validation loss:		0.476404
  validation accuracy:		89.89 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.099660
  validation loss:		0.479517
  validation accuracy:		90.22 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.099097
  validation loss:		0.493778
  validation accuracy:		90.33 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.099346
  validation loss:		0.485602
  validation accuracy:		90.22 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.100816
  validation loss:		0.515876
  validation accuracy:		89.67 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.101666
  validation loss:		0.501109
  validation accuracy:		90.11 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.100882
  validation loss:		0.487795
  validation accuracy:		90.43 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.100153
  validation loss:		0.484197
  validation accuracy:		90.11 %
Epoch 1570 of 2000 took 0.098s
  training loss:		0.101430
  validation loss:		0.485387
  validation accuracy:		90.54 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.101800
  validation loss:		0.486251
  validation accuracy:		90.00 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.105589
  validation loss:		0.486341
  validation accuracy:		90.22 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.094707
  validation loss:		0.532644
  validation accuracy:		89.78 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.099273
  validation loss:		0.496166
  validation accuracy:		90.22 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.100428
  validation loss:		0.528322
  validation accuracy:		89.02 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.101325
  validation loss:		0.483372
  validation accuracy:		90.22 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.098604
  validation loss:		0.488940
  validation accuracy:		90.76 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.097734
  validation loss:		0.490335
  validation accuracy:		90.54 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.096827
  validation loss:		0.495015
  validation accuracy:		89.57 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.099042
  validation loss:		0.479736
  validation accuracy:		90.54 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.094232
  validation loss:		0.479970
  validation accuracy:		89.89 %
Epoch 1582 of 2000 took 0.097s
  training loss:		0.097184
  validation loss:		0.500710
  validation accuracy:		90.22 %
Epoch 1583 of 2000 took 0.100s
  training loss:		0.100910
  validation loss:		0.490257
  validation accuracy:		90.22 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.100006
  validation loss:		0.493757
  validation accuracy:		89.78 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.104442
  validation loss:		0.482233
  validation accuracy:		89.78 %
Epoch 1586 of 2000 took 0.102s
  training loss:		0.106670
  validation loss:		0.499473
  validation accuracy:		89.78 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.098069
  validation loss:		0.497320
  validation accuracy:		90.22 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.103008
  validation loss:		0.488586
  validation accuracy:		90.65 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.099771
  validation loss:		0.496242
  validation accuracy:		90.43 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.097146
  validation loss:		0.523347
  validation accuracy:		90.22 %
Epoch 1591 of 2000 took 0.100s
  training loss:		0.102238
  validation loss:		0.503988
  validation accuracy:		90.11 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.097394
  validation loss:		0.488869
  validation accuracy:		90.33 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.098907
  validation loss:		0.490846
  validation accuracy:		90.33 %
Epoch 1594 of 2000 took 0.102s
  training loss:		0.100320
  validation loss:		0.479368
  validation accuracy:		89.89 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.103968
  validation loss:		0.484800
  validation accuracy:		90.33 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.101780
  validation loss:		0.474138
  validation accuracy:		90.54 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.101347
  validation loss:		0.492143
  validation accuracy:		90.22 %
Epoch 1598 of 2000 took 0.098s
  training loss:		0.100717
  validation loss:		0.512357
  validation accuracy:		90.11 %
Epoch 1599 of 2000 took 0.099s
  training loss:		0.104066
  validation loss:		0.476267
  validation accuracy:		90.87 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.109137
  validation loss:		0.512950
  validation accuracy:		89.67 %
Epoch 1601 of 2000 took 0.098s
  training loss:		0.097593
  validation loss:		0.495971
  validation accuracy:		90.33 %
Epoch 1602 of 2000 took 0.101s
  training loss:		0.092551
  validation loss:		0.498628
  validation accuracy:		90.43 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.097062
  validation loss:		0.559015
  validation accuracy:		89.24 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.100504
  validation loss:		0.517669
  validation accuracy:		90.33 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.098918
  validation loss:		0.509041
  validation accuracy:		90.65 %
Epoch 1606 of 2000 took 0.101s
  training loss:		0.097584
  validation loss:		0.507063
  validation accuracy:		90.22 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.095954
  validation loss:		0.513539
  validation accuracy:		90.43 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.100521
  validation loss:		0.504426
  validation accuracy:		90.22 %
Epoch 1609 of 2000 took 0.101s
  training loss:		0.097749
  validation loss:		0.492871
  validation accuracy:		90.43 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.097844
  validation loss:		0.502991
  validation accuracy:		90.11 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.098957
  validation loss:		0.491698
  validation accuracy:		90.54 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.097832
  validation loss:		0.505434
  validation accuracy:		90.11 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.092917
  validation loss:		0.544529
  validation accuracy:		89.78 %
Epoch 1614 of 2000 took 0.100s
  training loss:		0.098998
  validation loss:		0.506728
  validation accuracy:		90.11 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.109578
  validation loss:		0.513351
  validation accuracy:		90.54 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.098049
  validation loss:		0.504541
  validation accuracy:		89.57 %
Epoch 1617 of 2000 took 0.102s
  training loss:		0.095699
  validation loss:		0.509958
  validation accuracy:		90.54 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.097201
  validation loss:		0.493517
  validation accuracy:		90.11 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.095466
  validation loss:		0.504502
  validation accuracy:		90.00 %
Epoch 1620 of 2000 took 0.096s
  training loss:		0.100651
  validation loss:		0.539840
  validation accuracy:		90.33 %
Epoch 1621 of 2000 took 0.097s
  training loss:		0.097399
  validation loss:		0.504460
  validation accuracy:		90.33 %
Epoch 1622 of 2000 took 0.100s
  training loss:		0.099625
  validation loss:		0.548751
  validation accuracy:		90.22 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.100399
  validation loss:		0.510513
  validation accuracy:		90.22 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.102003
  validation loss:		0.515504
  validation accuracy:		90.11 %
Epoch 1625 of 2000 took 0.102s
  training loss:		0.092541
  validation loss:		0.530492
  validation accuracy:		89.35 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.095596
  validation loss:		0.535502
  validation accuracy:		90.22 %
Epoch 1627 of 2000 took 0.097s
  training loss:		0.096312
  validation loss:		0.554474
  validation accuracy:		89.35 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.095870
  validation loss:		0.508715
  validation accuracy:		90.43 %
Epoch 1629 of 2000 took 0.098s
  training loss:		0.102848
  validation loss:		0.516092
  validation accuracy:		90.43 %
Epoch 1630 of 2000 took 0.099s
  training loss:		0.091604
  validation loss:		0.514672
  validation accuracy:		90.22 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.097453
  validation loss:		0.513915
  validation accuracy:		90.11 %
Epoch 1632 of 2000 took 0.098s
  training loss:		0.099463
  validation loss:		0.519538
  validation accuracy:		89.78 %
Epoch 1633 of 2000 took 0.101s
  training loss:		0.089831
  validation loss:		0.503152
  validation accuracy:		90.22 %
Epoch 1634 of 2000 took 0.096s
  training loss:		0.095274
  validation loss:		0.516950
  validation accuracy:		90.33 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.096085
  validation loss:		0.503731
  validation accuracy:		90.43 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.095530
  validation loss:		0.524686
  validation accuracy:		90.33 %
Epoch 1637 of 2000 took 0.101s
  training loss:		0.099709
  validation loss:		0.563354
  validation accuracy:		89.89 %
Epoch 1638 of 2000 took 0.097s
  training loss:		0.102364
  validation loss:		0.526261
  validation accuracy:		90.22 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.096005
  validation loss:		0.501334
  validation accuracy:		90.00 %
Epoch 1640 of 2000 took 0.101s
  training loss:		0.097338
  validation loss:		0.552672
  validation accuracy:		90.00 %
Epoch 1641 of 2000 took 0.097s
  training loss:		0.096313
  validation loss:		0.543104
  validation accuracy:		90.22 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.092712
  validation loss:		0.520517
  validation accuracy:		90.00 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.094514
  validation loss:		0.545148
  validation accuracy:		89.89 %
Epoch 1644 of 2000 took 0.097s
  training loss:		0.102029
  validation loss:		0.520446
  validation accuracy:		90.11 %
Epoch 1645 of 2000 took 0.100s
  training loss:		0.093310
  validation loss:		0.530684
  validation accuracy:		90.33 %
Epoch 1646 of 2000 took 0.097s
  training loss:		0.101823
  validation loss:		0.550097
  validation accuracy:		89.35 %
Epoch 1647 of 2000 took 0.097s
  training loss:		0.092473
  validation loss:		0.523962
  validation accuracy:		90.22 %
Epoch 1648 of 2000 took 0.102s
  training loss:		0.095770
  validation loss:		0.500524
  validation accuracy:		90.65 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.099411
  validation loss:		0.527850
  validation accuracy:		90.54 %
Epoch 1650 of 2000 took 0.097s
  training loss:		0.096167
  validation loss:		0.516232
  validation accuracy:		89.89 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.092679
  validation loss:		0.521787
  validation accuracy:		90.33 %
Epoch 1652 of 2000 took 0.097s
  training loss:		0.096337
  validation loss:		0.543053
  validation accuracy:		89.78 %
Epoch 1653 of 2000 took 0.100s
  training loss:		0.089652
  validation loss:		0.531534
  validation accuracy:		90.33 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.092099
  validation loss:		0.522303
  validation accuracy:		90.33 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.096167
  validation loss:		0.492613
  validation accuracy:		91.20 %
Epoch 1656 of 2000 took 0.102s
  training loss:		0.096751
  validation loss:		0.552916
  validation accuracy:		90.00 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.094441
  validation loss:		0.538406
  validation accuracy:		90.00 %
Epoch 1658 of 2000 took 0.097s
  training loss:		0.102266
  validation loss:		0.525160
  validation accuracy:		90.11 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.095646
  validation loss:		0.508674
  validation accuracy:		90.11 %
Epoch 1660 of 2000 took 0.098s
  training loss:		0.093889
  validation loss:		0.540538
  validation accuracy:		90.33 %
Epoch 1661 of 2000 took 0.100s
  training loss:		0.095967
  validation loss:		0.541805
  validation accuracy:		90.33 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.094895
  validation loss:		0.538106
  validation accuracy:		89.78 %
Epoch 1663 of 2000 took 0.097s
  training loss:		0.088193
  validation loss:		0.530118
  validation accuracy:		90.43 %
Epoch 1664 of 2000 took 0.101s
  training loss:		0.095799
  validation loss:		0.518075
  validation accuracy:		90.43 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.093760
  validation loss:		0.524411
  validation accuracy:		90.22 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.097604
  validation loss:		0.535125
  validation accuracy:		89.67 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.087769
  validation loss:		0.527269
  validation accuracy:		90.22 %
Epoch 1668 of 2000 took 0.100s
  training loss:		0.092377
  validation loss:		0.543047
  validation accuracy:		89.89 %
Epoch 1669 of 2000 took 0.098s
  training loss:		0.089139
  validation loss:		0.519152
  validation accuracy:		89.57 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.087794
  validation loss:		0.524837
  validation accuracy:		90.11 %
Epoch 1671 of 2000 took 0.100s
  training loss:		0.087261
  validation loss:		0.510881
  validation accuracy:		89.78 %
Epoch 1672 of 2000 took 0.098s
  training loss:		0.094361
  validation loss:		0.560372
  validation accuracy:		89.89 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.089159
  validation loss:		0.525506
  validation accuracy:		90.22 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.091518
  validation loss:		0.527396
  validation accuracy:		90.22 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.088683
  validation loss:		0.527489
  validation accuracy:		89.78 %
Epoch 1676 of 2000 took 0.100s
  training loss:		0.090253
  validation loss:		0.545723
  validation accuracy:		90.11 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.087369
  validation loss:		0.531862
  validation accuracy:		89.67 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.092913
  validation loss:		0.552282
  validation accuracy:		90.00 %
Epoch 1679 of 2000 took 0.102s
  training loss:		0.102171
  validation loss:		0.533971
  validation accuracy:		90.00 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.094208
  validation loss:		0.531832
  validation accuracy:		90.22 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.095604
  validation loss:		0.543459
  validation accuracy:		90.11 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.090104
  validation loss:		0.533653
  validation accuracy:		90.11 %
Epoch 1683 of 2000 took 0.097s
  training loss:		0.091451
  validation loss:		0.547240
  validation accuracy:		90.11 %
Epoch 1684 of 2000 took 0.100s
  training loss:		0.095722
  validation loss:		0.541705
  validation accuracy:		90.00 %
Epoch 1685 of 2000 took 0.097s
  training loss:		0.094107
  validation loss:		0.559743
  validation accuracy:		90.11 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.089168
  validation loss:		0.544746
  validation accuracy:		89.67 %
Epoch 1687 of 2000 took 0.102s
  training loss:		0.092891
  validation loss:		0.543370
  validation accuracy:		90.11 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.091577
  validation loss:		0.563156
  validation accuracy:		90.11 %
Epoch 1689 of 2000 took 0.097s
  training loss:		0.089233
  validation loss:		0.534279
  validation accuracy:		90.22 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.092692
  validation loss:		0.531418
  validation accuracy:		90.43 %
Epoch 1691 of 2000 took 0.098s
  training loss:		0.093909
  validation loss:		0.537989
  validation accuracy:		89.57 %
Epoch 1692 of 2000 took 0.100s
  training loss:		0.098307
  validation loss:		0.556671
  validation accuracy:		90.33 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.088170
  validation loss:		0.596946
  validation accuracy:		89.89 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.091703
  validation loss:		0.541932
  validation accuracy:		90.00 %
Epoch 1695 of 2000 took 0.102s
  training loss:		0.085673
  validation loss:		0.536529
  validation accuracy:		90.11 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.091545
  validation loss:		0.545991
  validation accuracy:		90.22 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.088347
  validation loss:		0.551055
  validation accuracy:		90.11 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.090084
  validation loss:		0.537589
  validation accuracy:		90.22 %
Epoch 1699 of 2000 took 0.099s
  training loss:		0.090994
  validation loss:		0.599361
  validation accuracy:		89.67 %
Epoch 1700 of 2000 took 0.098s
  training loss:		0.092145
  validation loss:		0.541044
  validation accuracy:		90.11 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.087762
  validation loss:		0.537516
  validation accuracy:		90.11 %
Epoch 1702 of 2000 took 0.098s
  training loss:		0.086111
  validation loss:		0.573876
  validation accuracy:		89.89 %
Epoch 1703 of 2000 took 0.100s
  training loss:		0.096727
  validation loss:		0.542680
  validation accuracy:		90.22 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.088282
  validation loss:		0.584274
  validation accuracy:		89.67 %
Epoch 1705 of 2000 took 0.097s
  training loss:		0.087362
  validation loss:		0.553052
  validation accuracy:		89.89 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.091711
  validation loss:		0.561512
  validation accuracy:		89.89 %
Epoch 1707 of 2000 took 0.101s
  training loss:		0.094196
  validation loss:		0.588450
  validation accuracy:		90.00 %
Epoch 1708 of 2000 took 0.097s
  training loss:		0.088875
  validation loss:		0.555200
  validation accuracy:		90.33 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.089142
  validation loss:		0.538922
  validation accuracy:		90.43 %
Epoch 1710 of 2000 took 0.101s
  training loss:		0.095310
  validation loss:		0.555840
  validation accuracy:		90.22 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.089135
  validation loss:		0.561043
  validation accuracy:		90.00 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.084842
  validation loss:		0.561128
  validation accuracy:		89.78 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.090617
  validation loss:		0.549809
  validation accuracy:		90.11 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.085780
  validation loss:		0.546921
  validation accuracy:		90.43 %
Epoch 1715 of 2000 took 0.100s
  training loss:		0.089038
  validation loss:		0.572883
  validation accuracy:		89.89 %
Epoch 1716 of 2000 took 0.097s
  training loss:		0.090194
  validation loss:		0.552360
  validation accuracy:		90.33 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.089031
  validation loss:		0.543859
  validation accuracy:		89.89 %
Epoch 1718 of 2000 took 0.102s
  training loss:		0.086577
  validation loss:		0.552621
  validation accuracy:		90.43 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.093094
  validation loss:		0.570531
  validation accuracy:		89.89 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.090712
  validation loss:		0.544540
  validation accuracy:		90.43 %
Epoch 1721 of 2000 took 0.097s
  training loss:		0.089892
  validation loss:		0.566097
  validation accuracy:		90.00 %
Epoch 1722 of 2000 took 0.097s
  training loss:		0.086927
  validation loss:		0.577135
  validation accuracy:		89.67 %
Epoch 1723 of 2000 took 0.097s
  training loss:		0.090861
  validation loss:		0.545660
  validation accuracy:		89.78 %
Epoch 1724 of 2000 took 0.097s
  training loss:		0.088516
  validation loss:		0.542620
  validation accuracy:		90.22 %
Epoch 1725 of 2000 took 0.097s
  training loss:		0.087288
  validation loss:		0.557079
  validation accuracy:		90.00 %
Epoch 1726 of 2000 took 0.097s
  training loss:		0.086380
  validation loss:		0.538024
  validation accuracy:		89.57 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.083872
  validation loss:		0.598628
  validation accuracy:		90.00 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.091014
  validation loss:		0.540277
  validation accuracy:		90.11 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.086651
  validation loss:		0.542017
  validation accuracy:		90.43 %
Epoch 1730 of 2000 took 0.097s
  training loss:		0.082880
  validation loss:		0.564835
  validation accuracy:		90.00 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.082668
  validation loss:		0.569558
  validation accuracy:		90.33 %
Epoch 1732 of 2000 took 0.097s
  training loss:		0.084463
  validation loss:		0.564245
  validation accuracy:		90.00 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.089114
  validation loss:		0.554142
  validation accuracy:		90.00 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.084858
  validation loss:		0.560919
  validation accuracy:		90.22 %
Epoch 1735 of 2000 took 0.097s
  training loss:		0.089151
  validation loss:		0.553086
  validation accuracy:		90.33 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.089634
  validation loss:		0.568442
  validation accuracy:		89.78 %
Epoch 1737 of 2000 took 0.097s
  training loss:		0.097218
  validation loss:		0.578630
  validation accuracy:		89.78 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.088698
  validation loss:		0.605958
  validation accuracy:		89.67 %
Epoch 1739 of 2000 took 0.097s
  training loss:		0.093734
  validation loss:		0.550073
  validation accuracy:		90.22 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.088421
  validation loss:		0.575446
  validation accuracy:		90.00 %
Epoch 1741 of 2000 took 0.097s
  training loss:		0.085178
  validation loss:		0.554387
  validation accuracy:		90.33 %
Epoch 1742 of 2000 took 0.097s
  training loss:		0.087526
  validation loss:		0.564004
  validation accuracy:		90.22 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.084256
  validation loss:		0.574908
  validation accuracy:		90.00 %
Epoch 1744 of 2000 took 0.097s
  training loss:		0.087031
  validation loss:		0.583634
  validation accuracy:		89.78 %
Epoch 1745 of 2000 took 0.097s
  training loss:		0.086442
  validation loss:		0.578403
  validation accuracy:		89.78 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.085993
  validation loss:		0.563862
  validation accuracy:		90.22 %
Epoch 1747 of 2000 took 0.097s
  training loss:		0.085815
  validation loss:		0.560014
  validation accuracy:		90.33 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.092478
  validation loss:		0.582914
  validation accuracy:		90.11 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.081953
  validation loss:		0.565482
  validation accuracy:		90.11 %
Epoch 1750 of 2000 took 0.098s
  training loss:		0.091797
  validation loss:		0.583387
  validation accuracy:		90.11 %
Epoch 1751 of 2000 took 0.097s
  training loss:		0.087680
  validation loss:		0.586150
  validation accuracy:		89.89 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.089420
  validation loss:		0.561581
  validation accuracy:		90.00 %
Epoch 1753 of 2000 took 0.097s
  training loss:		0.085326
  validation loss:		0.605809
  validation accuracy:		89.57 %
Epoch 1754 of 2000 took 0.097s
  training loss:		0.090120
  validation loss:		0.574121
  validation accuracy:		90.11 %
Epoch 1755 of 2000 took 0.097s
  training loss:		0.090119
  validation loss:		0.558869
  validation accuracy:		90.22 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.087591
  validation loss:		0.590164
  validation accuracy:		89.67 %
Epoch 1757 of 2000 took 0.097s
  training loss:		0.094172
  validation loss:		0.555734
  validation accuracy:		90.00 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.090477
  validation loss:		0.570751
  validation accuracy:		90.00 %
Epoch 1759 of 2000 took 0.097s
  training loss:		0.089662
  validation loss:		0.550242
  validation accuracy:		90.33 %
Epoch 1760 of 2000 took 0.097s
  training loss:		0.084176
  validation loss:		0.589712
  validation accuracy:		89.89 %
Epoch 1761 of 2000 took 0.097s
  training loss:		0.086571
  validation loss:		0.599927
  validation accuracy:		89.78 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.088220
  validation loss:		0.603481
  validation accuracy:		89.89 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.084937
  validation loss:		0.576197
  validation accuracy:		90.00 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.081144
  validation loss:		0.601340
  validation accuracy:		90.11 %
Epoch 1765 of 2000 took 0.097s
  training loss:		0.091928
  validation loss:		0.576249
  validation accuracy:		89.78 %
Epoch 1766 of 2000 took 0.097s
  training loss:		0.080443
  validation loss:		0.573356
  validation accuracy:		89.89 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.081732
  validation loss:		0.595611
  validation accuracy:		89.78 %
Epoch 1768 of 2000 took 0.097s
  training loss:		0.085645
  validation loss:		0.595505
  validation accuracy:		90.00 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.086786
  validation loss:		0.578431
  validation accuracy:		89.89 %
Epoch 1770 of 2000 took 0.097s
  training loss:		0.088255
  validation loss:		0.608324
  validation accuracy:		89.57 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.085442
  validation loss:		0.586570
  validation accuracy:		89.89 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.083564
  validation loss:		0.581262
  validation accuracy:		89.89 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.081532
  validation loss:		0.571748
  validation accuracy:		90.11 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.099174
  validation loss:		0.590050
  validation accuracy:		90.11 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.091071
  validation loss:		0.607702
  validation accuracy:		89.46 %
Epoch 1776 of 2000 took 0.097s
  training loss:		0.085235
  validation loss:		0.591904
  validation accuracy:		89.57 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.095952
  validation loss:		0.567124
  validation accuracy:		89.89 %
Epoch 1778 of 2000 took 0.097s
  training loss:		0.087093
  validation loss:		0.563128
  validation accuracy:		90.00 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.085017
  validation loss:		0.601195
  validation accuracy:		89.89 %
Epoch 1780 of 2000 took 0.097s
  training loss:		0.089448
  validation loss:		0.569525
  validation accuracy:		90.11 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.087463
  validation loss:		0.580812
  validation accuracy:		89.57 %
Epoch 1782 of 2000 took 0.097s
  training loss:		0.093059
  validation loss:		0.602167
  validation accuracy:		90.11 %
Epoch 1783 of 2000 took 0.097s
  training loss:		0.088820
  validation loss:		0.609948
  validation accuracy:		89.89 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.081234
  validation loss:		0.582590
  validation accuracy:		90.00 %
Epoch 1785 of 2000 took 0.097s
  training loss:		0.082750
  validation loss:		0.592599
  validation accuracy:		89.78 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.086697
  validation loss:		0.583301
  validation accuracy:		90.00 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.084916
  validation loss:		0.577969
  validation accuracy:		90.22 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.080769
  validation loss:		0.584692
  validation accuracy:		90.00 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.080478
  validation loss:		0.608593
  validation accuracy:		89.67 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.087373
  validation loss:		0.578116
  validation accuracy:		89.89 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.085279
  validation loss:		0.581866
  validation accuracy:		90.22 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.085754
  validation loss:		0.591977
  validation accuracy:		90.22 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.084197
  validation loss:		0.572473
  validation accuracy:		89.57 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.091990
  validation loss:		0.581534
  validation accuracy:		90.33 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.083424
  validation loss:		0.583497
  validation accuracy:		90.11 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.081925
  validation loss:		0.592147
  validation accuracy:		89.89 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.085108
  validation loss:		0.625960
  validation accuracy:		89.89 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.088529
  validation loss:		0.591168
  validation accuracy:		90.00 %
Epoch 1799 of 2000 took 0.097s
  training loss:		0.080112
  validation loss:		0.602336
  validation accuracy:		90.22 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.080441
  validation loss:		0.607500
  validation accuracy:		90.00 %
Epoch 1801 of 2000 took 0.097s
  training loss:		0.084354
  validation loss:		0.603397
  validation accuracy:		90.00 %
Epoch 1802 of 2000 took 0.097s
  training loss:		0.084018
  validation loss:		0.616020
  validation accuracy:		89.78 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.083270
  validation loss:		0.575838
  validation accuracy:		90.11 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.085857
  validation loss:		0.563835
  validation accuracy:		90.33 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.084178
  validation loss:		0.592605
  validation accuracy:		90.00 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.085059
  validation loss:		0.593471
  validation accuracy:		89.89 %
Epoch 1807 of 2000 took 0.097s
  training loss:		0.080269
  validation loss:		0.605483
  validation accuracy:		89.89 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.083551
  validation loss:		0.572904
  validation accuracy:		90.33 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.080653
  validation loss:		0.601102
  validation accuracy:		89.57 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.078910
  validation loss:		0.581653
  validation accuracy:		90.00 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.088443
  validation loss:		0.592580
  validation accuracy:		89.89 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.081204
  validation loss:		0.568884
  validation accuracy:		89.67 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.085042
  validation loss:		0.614319
  validation accuracy:		89.67 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.079242
  validation loss:		0.599858
  validation accuracy:		89.89 %
Epoch 1815 of 2000 took 0.097s
  training loss:		0.083403
  validation loss:		0.605931
  validation accuracy:		90.00 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.088992
  validation loss:		0.612926
  validation accuracy:		89.57 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.085990
  validation loss:		0.595818
  validation accuracy:		90.11 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.092068
  validation loss:		0.612010
  validation accuracy:		89.78 %
Epoch 1819 of 2000 took 0.097s
  training loss:		0.081080
  validation loss:		0.580883
  validation accuracy:		90.00 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.083070
  validation loss:		0.619819
  validation accuracy:		89.67 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.083873
  validation loss:		0.604929
  validation accuracy:		89.89 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.076329
  validation loss:		0.592557
  validation accuracy:		90.00 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.077241
  validation loss:		0.595995
  validation accuracy:		89.35 %
Epoch 1824 of 2000 took 0.097s
  training loss:		0.077416
  validation loss:		0.628846
  validation accuracy:		89.89 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.087327
  validation loss:		0.600228
  validation accuracy:		89.78 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.085592
  validation loss:		0.614378
  validation accuracy:		89.57 %
Epoch 1827 of 2000 took 0.097s
  training loss:		0.082881
  validation loss:		0.582034
  validation accuracy:		90.22 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.081463
  validation loss:		0.600988
  validation accuracy:		89.57 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.088277
  validation loss:		0.595605
  validation accuracy:		89.67 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.083493
  validation loss:		0.632752
  validation accuracy:		89.35 %
Epoch 1831 of 2000 took 0.096s
  training loss:		0.085918
  validation loss:		0.583134
  validation accuracy:		90.22 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.086690
  validation loss:		0.675718
  validation accuracy:		89.02 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.100696
  validation loss:		0.618248
  validation accuracy:		89.78 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.074732
  validation loss:		0.572549
  validation accuracy:		90.11 %
Epoch 1835 of 2000 took 0.097s
  training loss:		0.083986
  validation loss:		0.601116
  validation accuracy:		89.46 %
Epoch 1836 of 2000 took 0.097s
  training loss:		0.082041
  validation loss:		0.619455
  validation accuracy:		89.67 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.073018
  validation loss:		0.616497
  validation accuracy:		89.13 %
Epoch 1838 of 2000 took 0.097s
  training loss:		0.083678
  validation loss:		0.608628
  validation accuracy:		90.00 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.078706
  validation loss:		0.600117
  validation accuracy:		90.22 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.088667
  validation loss:		0.627974
  validation accuracy:		89.67 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.085066
  validation loss:		0.585804
  validation accuracy:		90.11 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.077447
  validation loss:		0.615645
  validation accuracy:		89.78 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.088040
  validation loss:		0.584481
  validation accuracy:		90.11 %
Epoch 1844 of 2000 took 0.098s
  training loss:		0.081900
  validation loss:		0.590927
  validation accuracy:		90.43 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.084315
  validation loss:		0.594757
  validation accuracy:		89.89 %
Epoch 1846 of 2000 took 0.097s
  training loss:		0.075856
  validation loss:		0.613146
  validation accuracy:		89.78 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.079633
  validation loss:		0.579577
  validation accuracy:		90.33 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.084241
  validation loss:		0.599878
  validation accuracy:		90.11 %
Epoch 1849 of 2000 took 0.097s
  training loss:		0.081347
  validation loss:		0.613783
  validation accuracy:		89.57 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.081698
  validation loss:		0.666635
  validation accuracy:		89.57 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.088014
  validation loss:		0.600960
  validation accuracy:		90.11 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.080945
  validation loss:		0.589265
  validation accuracy:		90.33 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.073834
  validation loss:		0.633019
  validation accuracy:		89.57 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.087228
  validation loss:		0.618136
  validation accuracy:		89.89 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.083567
  validation loss:		0.622465
  validation accuracy:		90.22 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.083719
  validation loss:		0.635083
  validation accuracy:		89.78 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.080899
  validation loss:		0.627123
  validation accuracy:		89.67 %
Epoch 1858 of 2000 took 0.097s
  training loss:		0.087281
  validation loss:		0.623302
  validation accuracy:		89.78 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.074924
  validation loss:		0.602544
  validation accuracy:		90.43 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.078266
  validation loss:		0.639262
  validation accuracy:		89.67 %
Epoch 1861 of 2000 took 0.097s
  training loss:		0.079896
  validation loss:		0.594848
  validation accuracy:		90.00 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.081951
  validation loss:		0.615335
  validation accuracy:		89.67 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.070908
  validation loss:		0.623889
  validation accuracy:		89.78 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.083272
  validation loss:		0.610693
  validation accuracy:		89.89 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.079499
  validation loss:		0.582890
  validation accuracy:		90.43 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.077618
  validation loss:		0.617745
  validation accuracy:		89.89 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.078343
  validation loss:		0.597181
  validation accuracy:		89.67 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.080309
  validation loss:		0.605546
  validation accuracy:		90.00 %
Epoch 1869 of 2000 took 0.097s
  training loss:		0.086546
  validation loss:		0.628477
  validation accuracy:		89.89 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.081251
  validation loss:		0.681360
  validation accuracy:		89.57 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.078898
  validation loss:		0.617749
  validation accuracy:		90.33 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.087875
  validation loss:		0.621225
  validation accuracy:		90.00 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.091710
  validation loss:		0.599020
  validation accuracy:		90.11 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.082637
  validation loss:		0.614933
  validation accuracy:		90.11 %
Epoch 1875 of 2000 took 0.098s
  training loss:		0.075894
  validation loss:		0.606023
  validation accuracy:		89.67 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.076726
  validation loss:		0.603464
  validation accuracy:		90.33 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.078920
  validation loss:		0.625562
  validation accuracy:		89.67 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.088915
  validation loss:		0.613343
  validation accuracy:		89.78 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.080328
  validation loss:		0.659067
  validation accuracy:		89.67 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.077468
  validation loss:		0.605219
  validation accuracy:		90.22 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.076092
  validation loss:		0.624479
  validation accuracy:		89.24 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.084331
  validation loss:		0.638427
  validation accuracy:		90.22 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.081128
  validation loss:		0.628647
  validation accuracy:		89.46 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.076099
  validation loss:		0.645432
  validation accuracy:		90.11 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.089331
  validation loss:		0.614382
  validation accuracy:		89.67 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.080846
  validation loss:		0.647199
  validation accuracy:		89.67 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.075465
  validation loss:		0.630433
  validation accuracy:		89.67 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.076110
  validation loss:		0.606593
  validation accuracy:		90.00 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.077752
  validation loss:		0.614503
  validation accuracy:		90.00 %
Epoch 1890 of 2000 took 0.097s
  training loss:		0.078328
  validation loss:		0.612288
  validation accuracy:		89.67 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.077640
  validation loss:		0.628234
  validation accuracy:		89.89 %
Epoch 1892 of 2000 took 0.097s
  training loss:		0.082761
  validation loss:		0.603722
  validation accuracy:		90.33 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.075614
  validation loss:		0.612697
  validation accuracy:		89.89 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.094533
  validation loss:		0.657305
  validation accuracy:		89.89 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.079085
  validation loss:		0.621985
  validation accuracy:		90.11 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.073847
  validation loss:		0.661505
  validation accuracy:		89.67 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.078809
  validation loss:		0.652119
  validation accuracy:		90.11 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.077237
  validation loss:		0.645146
  validation accuracy:		89.67 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.077990
  validation loss:		0.633710
  validation accuracy:		89.89 %
Epoch 1900 of 2000 took 0.097s
  training loss:		0.075399
  validation loss:		0.651461
  validation accuracy:		89.89 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.075377
  validation loss:		0.673850
  validation accuracy:		89.57 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.087783
  validation loss:		0.635731
  validation accuracy:		90.11 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.074987
  validation loss:		0.650072
  validation accuracy:		89.89 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.077774
  validation loss:		0.616406
  validation accuracy:		90.00 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.083977
  validation loss:		0.618297
  validation accuracy:		90.11 %
Epoch 1906 of 2000 took 0.098s
  training loss:		0.076224
  validation loss:		0.631036
  validation accuracy:		90.54 %
Epoch 1907 of 2000 took 0.097s
  training loss:		0.086859
  validation loss:		0.657834
  validation accuracy:		90.22 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.080935
  validation loss:		0.629738
  validation accuracy:		90.11 %
Epoch 1909 of 2000 took 0.097s
  training loss:		0.081026
  validation loss:		0.647082
  validation accuracy:		89.78 %
Epoch 1910 of 2000 took 0.097s
  training loss:		0.083311
  validation loss:		0.621602
  validation accuracy:		90.11 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.078558
  validation loss:		0.617303
  validation accuracy:		89.89 %
Epoch 1912 of 2000 took 0.097s
  training loss:		0.077983
  validation loss:		0.640284
  validation accuracy:		89.78 %
Epoch 1913 of 2000 took 0.097s
  training loss:		0.076389
  validation loss:		0.628542
  validation accuracy:		89.89 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.077837
  validation loss:		0.705476
  validation accuracy:		89.78 %
Epoch 1915 of 2000 took 0.097s
  training loss:		0.086883
  validation loss:		0.634878
  validation accuracy:		90.00 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.077283
  validation loss:		0.667245
  validation accuracy:		89.67 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.075220
  validation loss:		0.649144
  validation accuracy:		89.67 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.088949
  validation loss:		0.674775
  validation accuracy:		90.00 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.080370
  validation loss:		0.643145
  validation accuracy:		90.00 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.075565
  validation loss:		0.619509
  validation accuracy:		90.00 %
Epoch 1921 of 2000 took 0.097s
  training loss:		0.073924
  validation loss:		0.644908
  validation accuracy:		90.00 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.073541
  validation loss:		0.650449
  validation accuracy:		89.89 %
Epoch 1923 of 2000 took 0.097s
  training loss:		0.074398
  validation loss:		0.615617
  validation accuracy:		89.89 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.071080
  validation loss:		0.631461
  validation accuracy:		89.89 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.075945
  validation loss:		0.659566
  validation accuracy:		90.11 %
Epoch 1926 of 2000 took 0.097s
  training loss:		0.102464
  validation loss:		0.669351
  validation accuracy:		89.35 %
Epoch 1927 of 2000 took 0.097s
  training loss:		0.092784
  validation loss:		0.621308
  validation accuracy:		90.22 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.083929
  validation loss:		0.667062
  validation accuracy:		89.78 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.080870
  validation loss:		0.640659
  validation accuracy:		89.78 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.080433
  validation loss:		0.632823
  validation accuracy:		90.00 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.069979
  validation loss:		0.626757
  validation accuracy:		89.78 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.078247
  validation loss:		0.718457
  validation accuracy:		89.57 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.073978
  validation loss:		0.640333
  validation accuracy:		89.78 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.080447
  validation loss:		0.638830
  validation accuracy:		90.65 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.083907
  validation loss:		0.644313
  validation accuracy:		89.78 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.080578
  validation loss:		0.630070
  validation accuracy:		90.11 %
Epoch 1937 of 2000 took 0.098s
  training loss:		0.072713
  validation loss:		0.667563
  validation accuracy:		89.67 %
Epoch 1938 of 2000 took 0.097s
  training loss:		0.079368
  validation loss:		0.649504
  validation accuracy:		90.54 %
Epoch 1939 of 2000 took 0.100s
  training loss:		0.086689
  validation loss:		0.667955
  validation accuracy:		90.22 %
Epoch 1940 of 2000 took 0.100s
  training loss:		0.078909
  validation loss:		0.660588
  validation accuracy:		89.46 %
Epoch 1941 of 2000 took 0.100s
  training loss:		0.079028
  validation loss:		0.680944
  validation accuracy:		89.67 %
Epoch 1942 of 2000 took 0.099s
  training loss:		0.071547
  validation loss:		0.640084
  validation accuracy:		89.89 %
Epoch 1943 of 2000 took 0.100s
  training loss:		0.078401
  validation loss:		0.689801
  validation accuracy:		89.57 %
Epoch 1944 of 2000 took 0.097s
  training loss:		0.080771
  validation loss:		0.628409
  validation accuracy:		90.00 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.083478
  validation loss:		0.630489
  validation accuracy:		90.00 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.072999
  validation loss:		0.638846
  validation accuracy:		89.78 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.071925
  validation loss:		0.654246
  validation accuracy:		89.78 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.076213
  validation loss:		0.677996
  validation accuracy:		89.89 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.076661
  validation loss:		0.664564
  validation accuracy:		90.43 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.105615
  validation loss:		0.612074
  validation accuracy:		90.22 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.076727
  validation loss:		0.637906
  validation accuracy:		90.00 %
Epoch 1952 of 2000 took 0.097s
  training loss:		0.071700
  validation loss:		0.662488
  validation accuracy:		89.67 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.106728
  validation loss:		0.631141
  validation accuracy:		90.11 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.075392
  validation loss:		0.662469
  validation accuracy:		89.57 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.077910
  validation loss:		0.629109
  validation accuracy:		90.00 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.077468
  validation loss:		0.692890
  validation accuracy:		89.67 %
Epoch 1957 of 2000 took 0.097s
  training loss:		0.078819
  validation loss:		0.650378
  validation accuracy:		89.78 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.078005
  validation loss:		0.693203
  validation accuracy:		89.67 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.079253
  validation loss:		0.713278
  validation accuracy:		89.78 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.082013
  validation loss:		0.675206
  validation accuracy:		89.78 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.074167
  validation loss:		0.645627
  validation accuracy:		90.11 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.070688
  validation loss:		0.666667
  validation accuracy:		89.67 %
Epoch 1963 of 2000 took 0.097s
  training loss:		0.077160
  validation loss:		0.658198
  validation accuracy:		90.11 %
Epoch 1964 of 2000 took 0.097s
  training loss:		0.070911
  validation loss:		0.650259
  validation accuracy:		89.67 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.087966
  validation loss:		0.656994
  validation accuracy:		89.89 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.073045
  validation loss:		0.674553
  validation accuracy:		89.89 %
Epoch 1967 of 2000 took 0.097s
  training loss:		0.083308
  validation loss:		0.666411
  validation accuracy:		89.89 %
Epoch 1968 of 2000 took 0.098s
  training loss:		0.068997
  validation loss:		0.656244
  validation accuracy:		90.00 %
Epoch 1969 of 2000 took 0.097s
  training loss:		0.083169
  validation loss:		0.662922
  validation accuracy:		89.67 %
Epoch 1970 of 2000 took 0.097s
  training loss:		0.072036
  validation loss:		0.650914
  validation accuracy:		89.35 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.080268
  validation loss:		0.661760
  validation accuracy:		89.78 %
Epoch 1972 of 2000 took 0.097s
  training loss:		0.081104
  validation loss:		0.657019
  validation accuracy:		89.67 %
Epoch 1973 of 2000 took 0.097s
  training loss:		0.075041
  validation loss:		0.640781
  validation accuracy:		90.11 %
Epoch 1974 of 2000 took 0.097s
  training loss:		0.080903
  validation loss:		0.652370
  validation accuracy:		89.89 %
Epoch 1975 of 2000 took 0.097s
  training loss:		0.077907
  validation loss:		0.650573
  validation accuracy:		90.22 %
Epoch 1976 of 2000 took 0.099s
  training loss:		0.073346
  validation loss:		0.652324
  validation accuracy:		89.67 %
Epoch 1977 of 2000 took 0.100s
  training loss:		0.071655
  validation loss:		0.644557
  validation accuracy:		90.22 %
Epoch 1978 of 2000 took 0.100s
  training loss:		0.079184
  validation loss:		0.716694
  validation accuracy:		89.57 %
Epoch 1979 of 2000 took 0.100s
  training loss:		0.078320
  validation loss:		0.698113
  validation accuracy:		89.67 %
Epoch 1980 of 2000 took 0.100s
  training loss:		0.068975
  validation loss:		0.655323
  validation accuracy:		90.11 %
Epoch 1981 of 2000 took 0.100s
  training loss:		0.077854
  validation loss:		0.683360
  validation accuracy:		89.57 %
Epoch 1982 of 2000 took 0.100s
  training loss:		0.078837
  validation loss:		0.682133
  validation accuracy:		89.46 %
Epoch 1983 of 2000 took 0.100s
  training loss:		0.076306
  validation loss:		0.680272
  validation accuracy:		89.89 %
Epoch 1984 of 2000 took 0.100s
  training loss:		0.078428
  validation loss:		0.690860
  validation accuracy:		90.00 %
Epoch 1985 of 2000 took 0.100s
  training loss:		0.075768
  validation loss:		0.690852
  validation accuracy:		89.67 %
Epoch 1986 of 2000 took 0.100s
  training loss:		0.069425
  validation loss:		0.668372
  validation accuracy:		89.78 %
Epoch 1987 of 2000 took 0.100s
  training loss:		0.067951
  validation loss:		0.684943
  validation accuracy:		89.67 %
Epoch 1988 of 2000 took 0.100s
  training loss:		0.073797
  validation loss:		0.702530
  validation accuracy:		89.57 %
Epoch 1989 of 2000 took 0.101s
  training loss:		0.076603
  validation loss:		0.683128
  validation accuracy:		89.46 %
Epoch 1990 of 2000 took 0.100s
  training loss:		0.083086
  validation loss:		0.681119
  validation accuracy:		89.67 %
Epoch 1991 of 2000 took 0.100s
  training loss:		0.075049
  validation loss:		0.660356
  validation accuracy:		90.11 %
Epoch 1992 of 2000 took 0.100s
  training loss:		0.074105
  validation loss:		0.670929
  validation accuracy:		89.35 %
Epoch 1993 of 2000 took 0.100s
  training loss:		0.082776
  validation loss:		0.678740
  validation accuracy:		90.00 %
Epoch 1994 of 2000 took 0.100s
  training loss:		0.073576
  validation loss:		0.672226
  validation accuracy:		89.89 %
Epoch 1995 of 2000 took 0.100s
  training loss:		0.072798
  validation loss:		0.633713
  validation accuracy:		90.11 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.073922
  validation loss:		0.654824
  validation accuracy:		89.78 %
Epoch 1997 of 2000 took 0.100s
  training loss:		0.067507
  validation loss:		0.670361
  validation accuracy:		90.11 %
Epoch 1998 of 2000 took 0.100s
  training loss:		0.094511
  validation loss:		0.678929
  validation accuracy:		89.78 %
Epoch 1999 of 2000 took 0.101s
  training loss:		0.074653
  validation loss:		0.675353
  validation accuracy:		89.46 %
Epoch 2000 of 2000 took 0.099s
  training loss:		0.071430
  validation loss:		0.648549
  validation accuracy:		89.89 %
Final results:
  test loss:			1.356259
  test accuracy:		82.64 %
