Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.079s
  training loss:		2.940024
  validation loss:		2.832551
  validation accuracy:		16.96 %
Epoch 2 of 2000 took 0.078s
  training loss:		2.750580
  validation loss:		2.600223
  validation accuracy:		20.11 %
Epoch 3 of 2000 took 0.076s
  training loss:		2.540982
  validation loss:		2.380806
  validation accuracy:		27.07 %
Epoch 4 of 2000 took 0.078s
  training loss:		2.373031
  validation loss:		2.237216
  validation accuracy:		45.00 %
Epoch 5 of 2000 took 0.077s
  training loss:		2.272139
  validation loss:		2.161301
  validation accuracy:		55.65 %
Epoch 6 of 2000 took 0.077s
  training loss:		2.214015
  validation loss:		2.124114
  validation accuracy:		64.46 %
Epoch 7 of 2000 took 0.075s
  training loss:		2.171148
  validation loss:		2.087257
  validation accuracy:		61.63 %
Epoch 8 of 2000 took 0.078s
  training loss:		2.136871
  validation loss:		2.050519
  validation accuracy:		63.70 %
Epoch 9 of 2000 took 0.077s
  training loss:		2.099789
  validation loss:		2.008849
  validation accuracy:		65.87 %
Epoch 10 of 2000 took 0.076s
  training loss:		2.060729
  validation loss:		1.967751
  validation accuracy:		71.09 %
Epoch 11 of 2000 took 0.076s
  training loss:		2.024074
  validation loss:		1.920000
  validation accuracy:		72.93 %
Epoch 12 of 2000 took 0.076s
  training loss:		1.980217
  validation loss:		1.874197
  validation accuracy:		74.89 %
Epoch 13 of 2000 took 0.075s
  training loss:		1.930614
  validation loss:		1.817689
  validation accuracy:		72.72 %
Epoch 14 of 2000 took 0.077s
  training loss:		1.880290
  validation loss:		1.758672
  validation accuracy:		75.87 %
Epoch 15 of 2000 took 0.077s
  training loss:		1.821929
  validation loss:		1.696247
  validation accuracy:		75.65 %
Epoch 16 of 2000 took 0.077s
  training loss:		1.759991
  validation loss:		1.630976
  validation accuracy:		74.89 %
Epoch 17 of 2000 took 0.078s
  training loss:		1.695629
  validation loss:		1.562537
  validation accuracy:		77.07 %
Epoch 18 of 2000 took 0.078s
  training loss:		1.631797
  validation loss:		1.508146
  validation accuracy:		77.50 %
Epoch 19 of 2000 took 0.075s
  training loss:		1.565336
  validation loss:		1.419661
  validation accuracy:		78.80 %
Epoch 20 of 2000 took 0.077s
  training loss:		1.496590
  validation loss:		1.359546
  validation accuracy:		77.39 %
Epoch 21 of 2000 took 0.078s
  training loss:		1.432037
  validation loss:		1.298358
  validation accuracy:		79.46 %
Epoch 22 of 2000 took 0.078s
  training loss:		1.371457
  validation loss:		1.233758
  validation accuracy:		80.22 %
Epoch 23 of 2000 took 0.079s
  training loss:		1.309192
  validation loss:		1.171733
  validation accuracy:		82.07 %
Epoch 24 of 2000 took 0.077s
  training loss:		1.255860
  validation loss:		1.120062
  validation accuracy:		82.28 %
Epoch 25 of 2000 took 0.079s
  training loss:		1.198885
  validation loss:		1.080169
  validation accuracy:		82.17 %
Epoch 26 of 2000 took 0.076s
  training loss:		1.147818
  validation loss:		1.025226
  validation accuracy:		83.15 %
Epoch 27 of 2000 took 0.076s
  training loss:		1.103266
  validation loss:		0.985503
  validation accuracy:		81.52 %
Epoch 28 of 2000 took 0.079s
  training loss:		1.062715
  validation loss:		0.941917
  validation accuracy:		83.59 %
Epoch 29 of 2000 took 0.075s
  training loss:		1.019918
  validation loss:		0.904638
  validation accuracy:		83.15 %
Epoch 30 of 2000 took 0.077s
  training loss:		0.976216
  validation loss:		0.870350
  validation accuracy:		85.33 %
Epoch 31 of 2000 took 0.078s
  training loss:		0.946302
  validation loss:		0.837212
  validation accuracy:		83.04 %
Epoch 32 of 2000 took 0.078s
  training loss:		0.905220
  validation loss:		0.800415
  validation accuracy:		85.11 %
Epoch 33 of 2000 took 0.077s
  training loss:		0.873176
  validation loss:		0.778694
  validation accuracy:		85.11 %
Epoch 34 of 2000 took 0.078s
  training loss:		0.839823
  validation loss:		0.748868
  validation accuracy:		84.89 %
Epoch 35 of 2000 took 0.075s
  training loss:		0.810811
  validation loss:		0.719902
  validation accuracy:		84.89 %
Epoch 36 of 2000 took 0.077s
  training loss:		0.787529
  validation loss:		0.701316
  validation accuracy:		86.09 %
Epoch 37 of 2000 took 0.083s
  training loss:		0.759051
  validation loss:		0.677551
  validation accuracy:		85.98 %
Epoch 38 of 2000 took 0.077s
  training loss:		0.730327
  validation loss:		0.651083
  validation accuracy:		86.30 %
Epoch 39 of 2000 took 0.073s
  training loss:		0.708416
  validation loss:		0.624687
  validation accuracy:		86.63 %
Epoch 40 of 2000 took 0.075s
  training loss:		0.686423
  validation loss:		0.601600
  validation accuracy:		86.74 %
Epoch 41 of 2000 took 0.074s
  training loss:		0.659946
  validation loss:		0.588954
  validation accuracy:		87.39 %
Epoch 42 of 2000 took 0.076s
  training loss:		0.639600
  validation loss:		0.571624
  validation accuracy:		87.28 %
Epoch 43 of 2000 took 0.075s
  training loss:		0.623817
  validation loss:		0.562263
  validation accuracy:		87.61 %
Epoch 44 of 2000 took 0.075s
  training loss:		0.600396
  validation loss:		0.539637
  validation accuracy:		87.61 %
Epoch 45 of 2000 took 0.077s
  training loss:		0.585320
  validation loss:		0.522455
  validation accuracy:		87.83 %
Epoch 46 of 2000 took 0.078s
  training loss:		0.569536
  validation loss:		0.514196
  validation accuracy:		88.04 %
Epoch 47 of 2000 took 0.077s
  training loss:		0.551598
  validation loss:		0.494829
  validation accuracy:		88.04 %
Epoch 48 of 2000 took 0.078s
  training loss:		0.535792
  validation loss:		0.475153
  validation accuracy:		89.02 %
Epoch 49 of 2000 took 0.078s
  training loss:		0.523122
  validation loss:		0.463218
  validation accuracy:		89.24 %
Epoch 50 of 2000 took 0.075s
  training loss:		0.505412
  validation loss:		0.457418
  validation accuracy:		88.70 %
Epoch 51 of 2000 took 0.076s
  training loss:		0.493637
  validation loss:		0.444756
  validation accuracy:		89.46 %
Epoch 52 of 2000 took 0.074s
  training loss:		0.481053
  validation loss:		0.438431
  validation accuracy:		89.13 %
Epoch 53 of 2000 took 0.075s
  training loss:		0.475628
  validation loss:		0.423740
  validation accuracy:		88.70 %
Epoch 54 of 2000 took 0.076s
  training loss:		0.460861
  validation loss:		0.422647
  validation accuracy:		89.24 %
Epoch 55 of 2000 took 0.075s
  training loss:		0.450772
  validation loss:		0.411348
  validation accuracy:		89.46 %
Epoch 56 of 2000 took 0.075s
  training loss:		0.438644
  validation loss:		0.394470
  validation accuracy:		89.78 %
Epoch 57 of 2000 took 0.077s
  training loss:		0.437772
  validation loss:		0.398252
  validation accuracy:		89.89 %
Epoch 58 of 2000 took 0.077s
  training loss:		0.428635
  validation loss:		0.385394
  validation accuracy:		89.89 %
Epoch 59 of 2000 took 0.077s
  training loss:		0.411662
  validation loss:		0.377753
  validation accuracy:		89.78 %
Epoch 60 of 2000 took 0.078s
  training loss:		0.402617
  validation loss:		0.377045
  validation accuracy:		90.33 %
Epoch 61 of 2000 took 0.075s
  training loss:		0.399690
  validation loss:		0.363447
  validation accuracy:		90.65 %
Epoch 62 of 2000 took 0.076s
  training loss:		0.388126
  validation loss:		0.371398
  validation accuracy:		90.00 %
Epoch 63 of 2000 took 0.077s
  training loss:		0.383671
  validation loss:		0.353388
  validation accuracy:		90.54 %
Epoch 64 of 2000 took 0.076s
  training loss:		0.380376
  validation loss:		0.351213
  validation accuracy:		90.76 %
Epoch 65 of 2000 took 0.077s
  training loss:		0.370563
  validation loss:		0.343908
  validation accuracy:		90.43 %
Epoch 66 of 2000 took 0.079s
  training loss:		0.365573
  validation loss:		0.341571
  validation accuracy:		90.98 %
Epoch 67 of 2000 took 0.078s
  training loss:		0.361842
  validation loss:		0.331119
  validation accuracy:		91.09 %
Epoch 68 of 2000 took 0.075s
  training loss:		0.358878
  validation loss:		0.337623
  validation accuracy:		90.33 %
Epoch 69 of 2000 took 0.076s
  training loss:		0.351060
  validation loss:		0.336968
  validation accuracy:		90.98 %
Epoch 70 of 2000 took 0.075s
  training loss:		0.346885
  validation loss:		0.332267
  validation accuracy:		91.09 %
Epoch 71 of 2000 took 0.075s
  training loss:		0.340139
  validation loss:		0.319723
  validation accuracy:		91.85 %
Epoch 72 of 2000 took 0.077s
  training loss:		0.330736
  validation loss:		0.314239
  validation accuracy:		91.85 %
Epoch 73 of 2000 took 0.077s
  training loss:		0.335851
  validation loss:		0.317279
  validation accuracy:		91.20 %
Epoch 74 of 2000 took 0.076s
  training loss:		0.325184
  validation loss:		0.308245
  validation accuracy:		91.63 %
Epoch 75 of 2000 took 0.076s
  training loss:		0.320500
  validation loss:		0.307844
  validation accuracy:		91.63 %
Epoch 76 of 2000 took 0.075s
  training loss:		0.317922
  validation loss:		0.304966
  validation accuracy:		91.63 %
Epoch 77 of 2000 took 0.074s
  training loss:		0.318140
  validation loss:		0.301674
  validation accuracy:		91.85 %
Epoch 78 of 2000 took 0.075s
  training loss:		0.307600
  validation loss:		0.301135
  validation accuracy:		91.85 %
Epoch 79 of 2000 took 0.075s
  training loss:		0.309066
  validation loss:		0.300386
  validation accuracy:		91.96 %
Epoch 80 of 2000 took 0.077s
  training loss:		0.302846
  validation loss:		0.290573
  validation accuracy:		91.74 %
Epoch 81 of 2000 took 0.074s
  training loss:		0.300816
  validation loss:		0.301825
  validation accuracy:		91.63 %
Epoch 82 of 2000 took 0.074s
  training loss:		0.293359
  validation loss:		0.283356
  validation accuracy:		91.96 %
Epoch 83 of 2000 took 0.077s
  training loss:		0.292354
  validation loss:		0.290228
  validation accuracy:		91.85 %
Epoch 84 of 2000 took 0.075s
  training loss:		0.290273
  validation loss:		0.286572
  validation accuracy:		92.17 %
Epoch 85 of 2000 took 0.076s
  training loss:		0.285773
  validation loss:		0.280525
  validation accuracy:		91.74 %
Epoch 86 of 2000 took 0.076s
  training loss:		0.278557
  validation loss:		0.278138
  validation accuracy:		92.28 %
Epoch 87 of 2000 took 0.075s
  training loss:		0.278397
  validation loss:		0.282864
  validation accuracy:		91.85 %
Epoch 88 of 2000 took 0.078s
  training loss:		0.271665
  validation loss:		0.278274
  validation accuracy:		92.50 %
Epoch 89 of 2000 took 0.074s
  training loss:		0.271573
  validation loss:		0.271597
  validation accuracy:		92.28 %
Epoch 90 of 2000 took 0.074s
  training loss:		0.271399
  validation loss:		0.265917
  validation accuracy:		92.17 %
Epoch 91 of 2000 took 0.077s
  training loss:		0.267749
  validation loss:		0.269890
  validation accuracy:		92.72 %
Epoch 92 of 2000 took 0.077s
  training loss:		0.268604
  validation loss:		0.267538
  validation accuracy:		91.96 %
Epoch 93 of 2000 took 0.077s
  training loss:		0.259505
  validation loss:		0.262979
  validation accuracy:		92.83 %
Epoch 94 of 2000 took 0.075s
  training loss:		0.261841
  validation loss:		0.262761
  validation accuracy:		92.17 %
Epoch 95 of 2000 took 0.073s
  training loss:		0.256923
  validation loss:		0.266949
  validation accuracy:		92.93 %
Epoch 96 of 2000 took 0.073s
  training loss:		0.254472
  validation loss:		0.259606
  validation accuracy:		92.61 %
Epoch 97 of 2000 took 0.078s
  training loss:		0.250178
  validation loss:		0.260746
  validation accuracy:		93.15 %
Epoch 98 of 2000 took 0.078s
  training loss:		0.251622
  validation loss:		0.251064
  validation accuracy:		92.93 %
Epoch 99 of 2000 took 0.078s
  training loss:		0.255996
  validation loss:		0.249739
  validation accuracy:		93.04 %
Epoch 100 of 2000 took 0.076s
  training loss:		0.243932
  validation loss:		0.252465
  validation accuracy:		92.72 %
Epoch 101 of 2000 took 0.076s
  training loss:		0.252015
  validation loss:		0.256369
  validation accuracy:		92.72 %
Epoch 102 of 2000 took 0.078s
  training loss:		0.244823
  validation loss:		0.250289
  validation accuracy:		92.50 %
Epoch 103 of 2000 took 0.078s
  training loss:		0.238498
  validation loss:		0.251258
  validation accuracy:		93.26 %
Epoch 104 of 2000 took 0.076s
  training loss:		0.241486
  validation loss:		0.246568
  validation accuracy:		93.48 %
Epoch 105 of 2000 took 0.077s
  training loss:		0.237973
  validation loss:		0.248828
  validation accuracy:		92.83 %
Epoch 106 of 2000 took 0.076s
  training loss:		0.233084
  validation loss:		0.240876
  validation accuracy:		93.26 %
Epoch 107 of 2000 took 0.077s
  training loss:		0.232423
  validation loss:		0.248761
  validation accuracy:		93.26 %
Epoch 108 of 2000 took 0.074s
  training loss:		0.229421
  validation loss:		0.237879
  validation accuracy:		93.15 %
Epoch 109 of 2000 took 0.076s
  training loss:		0.230545
  validation loss:		0.240103
  validation accuracy:		93.26 %
Epoch 110 of 2000 took 0.075s
  training loss:		0.229493
  validation loss:		0.242808
  validation accuracy:		93.48 %
Epoch 111 of 2000 took 0.080s
  training loss:		0.229148
  validation loss:		0.245697
  validation accuracy:		92.93 %
Epoch 112 of 2000 took 0.078s
  training loss:		0.223021
  validation loss:		0.238467
  validation accuracy:		93.26 %
Epoch 113 of 2000 took 0.075s
  training loss:		0.225795
  validation loss:		0.229363
  validation accuracy:		93.70 %
Epoch 114 of 2000 took 0.076s
  training loss:		0.225954
  validation loss:		0.238872
  validation accuracy:		93.26 %
Epoch 115 of 2000 took 0.077s
  training loss:		0.222267
  validation loss:		0.239922
  validation accuracy:		93.37 %
Epoch 116 of 2000 took 0.074s
  training loss:		0.222873
  validation loss:		0.242622
  validation accuracy:		92.93 %
Epoch 117 of 2000 took 0.074s
  training loss:		0.219752
  validation loss:		0.230966
  validation accuracy:		93.26 %
Epoch 118 of 2000 took 0.079s
  training loss:		0.209019
  validation loss:		0.231843
  validation accuracy:		93.48 %
Epoch 119 of 2000 took 0.076s
  training loss:		0.215077
  validation loss:		0.241191
  validation accuracy:		93.37 %
Epoch 120 of 2000 took 0.076s
  training loss:		0.216423
  validation loss:		0.234055
  validation accuracy:		93.15 %
Epoch 121 of 2000 took 0.077s
  training loss:		0.209018
  validation loss:		0.229491
  validation accuracy:		93.48 %
Epoch 122 of 2000 took 0.079s
  training loss:		0.210549
  validation loss:		0.227008
  validation accuracy:		93.48 %
Epoch 123 of 2000 took 0.080s
  training loss:		0.208782
  validation loss:		0.225659
  validation accuracy:		93.70 %
Epoch 124 of 2000 took 0.076s
  training loss:		0.207989
  validation loss:		0.230016
  validation accuracy:		93.59 %
Epoch 125 of 2000 took 0.076s
  training loss:		0.203675
  validation loss:		0.231957
  validation accuracy:		93.37 %
Epoch 126 of 2000 took 0.078s
  training loss:		0.206505
  validation loss:		0.220220
  validation accuracy:		93.70 %
Epoch 127 of 2000 took 0.074s
  training loss:		0.204181
  validation loss:		0.224016
  validation accuracy:		93.48 %
Epoch 128 of 2000 took 0.072s
  training loss:		0.200054
  validation loss:		0.232751
  validation accuracy:		93.04 %
Epoch 129 of 2000 took 0.078s
  training loss:		0.201029
  validation loss:		0.231508
  validation accuracy:		93.04 %
Epoch 130 of 2000 took 0.076s
  training loss:		0.202927
  validation loss:		0.220137
  validation accuracy:		93.70 %
Epoch 131 of 2000 took 0.077s
  training loss:		0.197804
  validation loss:		0.224482
  validation accuracy:		93.80 %
Epoch 132 of 2000 took 0.076s
  training loss:		0.198044
  validation loss:		0.225750
  validation accuracy:		93.70 %
Epoch 133 of 2000 took 0.074s
  training loss:		0.194430
  validation loss:		0.220416
  validation accuracy:		93.59 %
Epoch 134 of 2000 took 0.077s
  training loss:		0.195132
  validation loss:		0.217463
  validation accuracy:		93.70 %
Epoch 135 of 2000 took 0.079s
  training loss:		0.194710
  validation loss:		0.222022
  validation accuracy:		93.37 %
Epoch 136 of 2000 took 0.079s
  training loss:		0.188904
  validation loss:		0.212673
  validation accuracy:		94.24 %
Epoch 137 of 2000 took 0.073s
  training loss:		0.195188
  validation loss:		0.215235
  validation accuracy:		93.59 %
Epoch 138 of 2000 took 0.078s
  training loss:		0.192238
  validation loss:		0.215375
  validation accuracy:		93.70 %
Epoch 139 of 2000 took 0.076s
  training loss:		0.190752
  validation loss:		0.215905
  validation accuracy:		93.80 %
Epoch 140 of 2000 took 0.076s
  training loss:		0.189092
  validation loss:		0.222992
  validation accuracy:		92.83 %
Epoch 141 of 2000 took 0.079s
  training loss:		0.186939
  validation loss:		0.220751
  validation accuracy:		93.48 %
Epoch 142 of 2000 took 0.075s
  training loss:		0.184613
  validation loss:		0.217239
  validation accuracy:		93.37 %
Epoch 143 of 2000 took 0.078s
  training loss:		0.186006
  validation loss:		0.215599
  validation accuracy:		93.80 %
Epoch 144 of 2000 took 0.076s
  training loss:		0.187662
  validation loss:		0.210818
  validation accuracy:		93.70 %
Epoch 145 of 2000 took 0.076s
  training loss:		0.184970
  validation loss:		0.219742
  validation accuracy:		93.37 %
Epoch 146 of 2000 took 0.076s
  training loss:		0.183515
  validation loss:		0.219863
  validation accuracy:		93.37 %
Epoch 147 of 2000 took 0.073s
  training loss:		0.182254
  validation loss:		0.212333
  validation accuracy:		93.91 %
Epoch 148 of 2000 took 0.074s
  training loss:		0.181676
  validation loss:		0.212339
  validation accuracy:		93.48 %
Epoch 149 of 2000 took 0.077s
  training loss:		0.180462
  validation loss:		0.211290
  validation accuracy:		93.91 %
Epoch 150 of 2000 took 0.073s
  training loss:		0.173361
  validation loss:		0.219303
  validation accuracy:		93.37 %
Epoch 151 of 2000 took 0.074s
  training loss:		0.173666
  validation loss:		0.207473
  validation accuracy:		93.91 %
Epoch 152 of 2000 took 0.075s
  training loss:		0.176370
  validation loss:		0.212643
  validation accuracy:		93.59 %
Epoch 153 of 2000 took 0.076s
  training loss:		0.179279
  validation loss:		0.220483
  validation accuracy:		93.48 %
Epoch 154 of 2000 took 0.077s
  training loss:		0.176765
  validation loss:		0.214310
  validation accuracy:		93.59 %
Epoch 155 of 2000 took 0.075s
  training loss:		0.173752
  validation loss:		0.206752
  validation accuracy:		93.80 %
Epoch 156 of 2000 took 0.076s
  training loss:		0.173376
  validation loss:		0.213532
  validation accuracy:		93.48 %
Epoch 157 of 2000 took 0.075s
  training loss:		0.169602
  validation loss:		0.203949
  validation accuracy:		93.80 %
Epoch 158 of 2000 took 0.073s
  training loss:		0.171405
  validation loss:		0.203312
  validation accuracy:		93.80 %
Epoch 159 of 2000 took 0.076s
  training loss:		0.172680
  validation loss:		0.208130
  validation accuracy:		93.91 %
Epoch 160 of 2000 took 0.076s
  training loss:		0.170784
  validation loss:		0.201529
  validation accuracy:		94.24 %
Epoch 161 of 2000 took 0.074s
  training loss:		0.172297
  validation loss:		0.204467
  validation accuracy:		93.80 %
Epoch 162 of 2000 took 0.076s
  training loss:		0.167970
  validation loss:		0.207592
  validation accuracy:		94.35 %
Epoch 163 of 2000 took 0.074s
  training loss:		0.164859
  validation loss:		0.202618
  validation accuracy:		94.13 %
Epoch 164 of 2000 took 0.076s
  training loss:		0.165342
  validation loss:		0.199513
  validation accuracy:		94.24 %
Epoch 165 of 2000 took 0.077s
  training loss:		0.165291
  validation loss:		0.210552
  validation accuracy:		93.70 %
Epoch 166 of 2000 took 0.076s
  training loss:		0.165670
  validation loss:		0.203991
  validation accuracy:		93.70 %
Epoch 167 of 2000 took 0.076s
  training loss:		0.163489
  validation loss:		0.205492
  validation accuracy:		93.91 %
Epoch 168 of 2000 took 0.075s
  training loss:		0.160244
  validation loss:		0.199351
  validation accuracy:		94.02 %
Epoch 169 of 2000 took 0.075s
  training loss:		0.161052
  validation loss:		0.202532
  validation accuracy:		93.80 %
Epoch 170 of 2000 took 0.073s
  training loss:		0.161991
  validation loss:		0.198034
  validation accuracy:		94.02 %
Epoch 171 of 2000 took 0.074s
  training loss:		0.156686
  validation loss:		0.197740
  validation accuracy:		93.91 %
Epoch 172 of 2000 took 0.075s
  training loss:		0.160117
  validation loss:		0.203172
  validation accuracy:		94.24 %
Epoch 173 of 2000 took 0.076s
  training loss:		0.159530
  validation loss:		0.194176
  validation accuracy:		94.13 %
Epoch 174 of 2000 took 0.074s
  training loss:		0.162259
  validation loss:		0.201591
  validation accuracy:		94.24 %
Epoch 175 of 2000 took 0.076s
  training loss:		0.158706
  validation loss:		0.203851
  validation accuracy:		94.13 %
Epoch 176 of 2000 took 0.073s
  training loss:		0.159287
  validation loss:		0.201335
  validation accuracy:		93.70 %
Epoch 177 of 2000 took 0.077s
  training loss:		0.156626
  validation loss:		0.196344
  validation accuracy:		94.24 %
Epoch 178 of 2000 took 0.078s
  training loss:		0.156392
  validation loss:		0.196728
  validation accuracy:		94.24 %
Epoch 179 of 2000 took 0.077s
  training loss:		0.155541
  validation loss:		0.196884
  validation accuracy:		94.13 %
Epoch 180 of 2000 took 0.078s
  training loss:		0.153044
  validation loss:		0.197963
  validation accuracy:		93.91 %
Epoch 181 of 2000 took 0.079s
  training loss:		0.155155
  validation loss:		0.201382
  validation accuracy:		94.02 %
Epoch 182 of 2000 took 0.077s
  training loss:		0.149393
  validation loss:		0.198644
  validation accuracy:		94.13 %
Epoch 183 of 2000 took 0.077s
  training loss:		0.148812
  validation loss:		0.199202
  validation accuracy:		94.13 %
Epoch 184 of 2000 took 0.078s
  training loss:		0.151579
  validation loss:		0.198231
  validation accuracy:		93.91 %
Epoch 185 of 2000 took 0.078s
  training loss:		0.152542
  validation loss:		0.201000
  validation accuracy:		93.80 %
Epoch 186 of 2000 took 0.078s
  training loss:		0.148651
  validation loss:		0.201705
  validation accuracy:		94.24 %
Epoch 187 of 2000 took 0.077s
  training loss:		0.146574
  validation loss:		0.192769
  validation accuracy:		93.80 %
Epoch 188 of 2000 took 0.078s
  training loss:		0.146917
  validation loss:		0.206449
  validation accuracy:		94.02 %
Epoch 189 of 2000 took 0.076s
  training loss:		0.144581
  validation loss:		0.198548
  validation accuracy:		93.70 %
Epoch 190 of 2000 took 0.073s
  training loss:		0.151449
  validation loss:		0.203177
  validation accuracy:		93.80 %
Epoch 191 of 2000 took 0.074s
  training loss:		0.146638
  validation loss:		0.193649
  validation accuracy:		94.13 %
Epoch 192 of 2000 took 0.074s
  training loss:		0.143898
  validation loss:		0.194539
  validation accuracy:		94.13 %
Epoch 193 of 2000 took 0.077s
  training loss:		0.144590
  validation loss:		0.194220
  validation accuracy:		94.02 %
Epoch 194 of 2000 took 0.077s
  training loss:		0.142983
  validation loss:		0.193738
  validation accuracy:		94.13 %
Epoch 195 of 2000 took 0.075s
  training loss:		0.142946
  validation loss:		0.193436
  validation accuracy:		93.91 %
Epoch 196 of 2000 took 0.077s
  training loss:		0.140329
  validation loss:		0.192956
  validation accuracy:		94.24 %
Epoch 197 of 2000 took 0.077s
  training loss:		0.142508
  validation loss:		0.192264
  validation accuracy:		94.02 %
Epoch 198 of 2000 took 0.077s
  training loss:		0.145645
  validation loss:		0.200931
  validation accuracy:		93.70 %
Epoch 199 of 2000 took 0.077s
  training loss:		0.143732
  validation loss:		0.196617
  validation accuracy:		94.02 %
Epoch 200 of 2000 took 0.075s
  training loss:		0.142529
  validation loss:		0.198081
  validation accuracy:		94.46 %
Epoch 201 of 2000 took 0.073s
  training loss:		0.142572
  validation loss:		0.196759
  validation accuracy:		94.02 %
Epoch 202 of 2000 took 0.077s
  training loss:		0.142288
  validation loss:		0.197497
  validation accuracy:		94.13 %
Epoch 203 of 2000 took 0.078s
  training loss:		0.138652
  validation loss:		0.192065
  validation accuracy:		93.91 %
Epoch 204 of 2000 took 0.076s
  training loss:		0.135796
  validation loss:		0.189754
  validation accuracy:		94.13 %
Epoch 205 of 2000 took 0.077s
  training loss:		0.139881
  validation loss:		0.190888
  validation accuracy:		93.91 %
Epoch 206 of 2000 took 0.074s
  training loss:		0.138575
  validation loss:		0.195965
  validation accuracy:		94.13 %
Epoch 207 of 2000 took 0.077s
  training loss:		0.136631
  validation loss:		0.196607
  validation accuracy:		94.24 %
Epoch 208 of 2000 took 0.078s
  training loss:		0.134417
  validation loss:		0.196918
  validation accuracy:		93.59 %
Epoch 209 of 2000 took 0.077s
  training loss:		0.137734
  validation loss:		0.200670
  validation accuracy:		94.35 %
Epoch 210 of 2000 took 0.075s
  training loss:		0.135731
  validation loss:		0.188446
  validation accuracy:		94.13 %
Epoch 211 of 2000 took 0.078s
  training loss:		0.134513
  validation loss:		0.201853
  validation accuracy:		94.24 %
Epoch 212 of 2000 took 0.078s
  training loss:		0.136897
  validation loss:		0.190005
  validation accuracy:		93.91 %
Epoch 213 of 2000 took 0.075s
  training loss:		0.133752
  validation loss:		0.194574
  validation accuracy:		94.24 %
Epoch 214 of 2000 took 0.075s
  training loss:		0.132342
  validation loss:		0.192843
  validation accuracy:		94.35 %
Epoch 215 of 2000 took 0.077s
  training loss:		0.132792
  validation loss:		0.196600
  validation accuracy:		94.02 %
Epoch 216 of 2000 took 0.077s
  training loss:		0.134181
  validation loss:		0.185607
  validation accuracy:		94.46 %
Epoch 217 of 2000 took 0.077s
  training loss:		0.132551
  validation loss:		0.185757
  validation accuracy:		94.02 %
Epoch 218 of 2000 took 0.075s
  training loss:		0.131758
  validation loss:		0.193702
  validation accuracy:		93.91 %
Epoch 219 of 2000 took 0.079s
  training loss:		0.130046
  validation loss:		0.193638
  validation accuracy:		94.57 %
Epoch 220 of 2000 took 0.076s
  training loss:		0.132912
  validation loss:		0.187411
  validation accuracy:		94.24 %
Epoch 221 of 2000 took 0.077s
  training loss:		0.125058
  validation loss:		0.186597
  validation accuracy:		93.91 %
Epoch 222 of 2000 took 0.077s
  training loss:		0.129758
  validation loss:		0.193255
  validation accuracy:		93.80 %
Epoch 223 of 2000 took 0.074s
  training loss:		0.129600
  validation loss:		0.191392
  validation accuracy:		94.24 %
Epoch 224 of 2000 took 0.079s
  training loss:		0.129993
  validation loss:		0.188217
  validation accuracy:		94.13 %
Epoch 225 of 2000 took 0.077s
  training loss:		0.130486
  validation loss:		0.191558
  validation accuracy:		94.35 %
Epoch 226 of 2000 took 0.078s
  training loss:		0.125103
  validation loss:		0.193033
  validation accuracy:		94.13 %
Epoch 227 of 2000 took 0.077s
  training loss:		0.129717
  validation loss:		0.190447
  validation accuracy:		94.35 %
Epoch 228 of 2000 took 0.075s
  training loss:		0.129502
  validation loss:		0.182434
  validation accuracy:		94.35 %
Epoch 229 of 2000 took 0.075s
  training loss:		0.128388
  validation loss:		0.196206
  validation accuracy:		94.02 %
Epoch 230 of 2000 took 0.076s
  training loss:		0.124767
  validation loss:		0.189624
  validation accuracy:		94.24 %
Epoch 231 of 2000 took 0.075s
  training loss:		0.125057
  validation loss:		0.187981
  validation accuracy:		94.24 %
Epoch 232 of 2000 took 0.077s
  training loss:		0.127333
  validation loss:		0.192569
  validation accuracy:		94.35 %
Epoch 233 of 2000 took 0.076s
  training loss:		0.126641
  validation loss:		0.181054
  validation accuracy:		94.35 %
Epoch 234 of 2000 took 0.076s
  training loss:		0.125380
  validation loss:		0.191630
  validation accuracy:		94.02 %
Epoch 235 of 2000 took 0.076s
  training loss:		0.123862
  validation loss:		0.187454
  validation accuracy:		94.57 %
Epoch 236 of 2000 took 0.077s
  training loss:		0.125630
  validation loss:		0.192843
  validation accuracy:		94.24 %
Epoch 237 of 2000 took 0.079s
  training loss:		0.121093
  validation loss:		0.194294
  validation accuracy:		94.35 %
Epoch 238 of 2000 took 0.073s
  training loss:		0.121401
  validation loss:		0.183889
  validation accuracy:		94.35 %
Epoch 239 of 2000 took 0.077s
  training loss:		0.120697
  validation loss:		0.188163
  validation accuracy:		94.24 %
Epoch 240 of 2000 took 0.076s
  training loss:		0.121153
  validation loss:		0.191246
  validation accuracy:		94.35 %
Epoch 241 of 2000 took 0.079s
  training loss:		0.119300
  validation loss:		0.189678
  validation accuracy:		94.46 %
Epoch 242 of 2000 took 0.077s
  training loss:		0.120387
  validation loss:		0.186148
  validation accuracy:		94.02 %
Epoch 243 of 2000 took 0.077s
  training loss:		0.121470
  validation loss:		0.186102
  validation accuracy:		94.13 %
Epoch 244 of 2000 took 0.077s
  training loss:		0.118256
  validation loss:		0.186360
  validation accuracy:		94.35 %
Epoch 245 of 2000 took 0.079s
  training loss:		0.118992
  validation loss:		0.190936
  validation accuracy:		94.24 %
Epoch 246 of 2000 took 0.078s
  training loss:		0.117803
  validation loss:		0.182375
  validation accuracy:		94.24 %
Epoch 247 of 2000 took 0.077s
  training loss:		0.119941
  validation loss:		0.185967
  validation accuracy:		94.46 %
Epoch 248 of 2000 took 0.076s
  training loss:		0.120067
  validation loss:		0.189955
  validation accuracy:		94.02 %
Epoch 249 of 2000 took 0.076s
  training loss:		0.116924
  validation loss:		0.186766
  validation accuracy:		94.02 %
Epoch 250 of 2000 took 0.078s
  training loss:		0.116854
  validation loss:		0.191806
  validation accuracy:		94.13 %
Epoch 251 of 2000 took 0.079s
  training loss:		0.116528
  validation loss:		0.193557
  validation accuracy:		94.35 %
Epoch 252 of 2000 took 0.076s
  training loss:		0.116553
  validation loss:		0.185720
  validation accuracy:		94.02 %
Epoch 253 of 2000 took 0.079s
  training loss:		0.115543
  validation loss:		0.202221
  validation accuracy:		93.80 %
Epoch 254 of 2000 took 0.079s
  training loss:		0.115895
  validation loss:		0.191457
  validation accuracy:		94.46 %
Epoch 255 of 2000 took 0.073s
  training loss:		0.112958
  validation loss:		0.185305
  validation accuracy:		94.35 %
Epoch 256 of 2000 took 0.077s
  training loss:		0.112750
  validation loss:		0.184630
  validation accuracy:		94.35 %
Epoch 257 of 2000 took 0.075s
  training loss:		0.112366
  validation loss:		0.186144
  validation accuracy:		94.02 %
Epoch 258 of 2000 took 0.078s
  training loss:		0.113136
  validation loss:		0.192284
  validation accuracy:		94.35 %
Epoch 259 of 2000 took 0.075s
  training loss:		0.111581
  validation loss:		0.187550
  validation accuracy:		94.46 %
Epoch 260 of 2000 took 0.074s
  training loss:		0.115162
  validation loss:		0.188813
  validation accuracy:		94.35 %
Epoch 261 of 2000 took 0.076s
  training loss:		0.110918
  validation loss:		0.186927
  validation accuracy:		94.57 %
Epoch 262 of 2000 took 0.077s
  training loss:		0.113863
  validation loss:		0.190711
  validation accuracy:		94.13 %
Epoch 263 of 2000 took 0.076s
  training loss:		0.112130
  validation loss:		0.186937
  validation accuracy:		94.24 %
Epoch 264 of 2000 took 0.075s
  training loss:		0.110388
  validation loss:		0.184297
  validation accuracy:		94.35 %
Epoch 265 of 2000 took 0.076s
  training loss:		0.111780
  validation loss:		0.184345
  validation accuracy:		94.35 %
Epoch 266 of 2000 took 0.078s
  training loss:		0.109405
  validation loss:		0.187029
  validation accuracy:		94.35 %
Epoch 267 of 2000 took 0.077s
  training loss:		0.109994
  validation loss:		0.186199
  validation accuracy:		94.24 %
Epoch 268 of 2000 took 0.075s
  training loss:		0.109475
  validation loss:		0.180208
  validation accuracy:		94.35 %
Epoch 269 of 2000 took 0.076s
  training loss:		0.109140
  validation loss:		0.193069
  validation accuracy:		93.91 %
Epoch 270 of 2000 took 0.075s
  training loss:		0.110233
  validation loss:		0.187607
  validation accuracy:		94.35 %
Epoch 271 of 2000 took 0.076s
  training loss:		0.103388
  validation loss:		0.183690
  validation accuracy:		94.02 %
Epoch 272 of 2000 took 0.078s
  training loss:		0.110607
  validation loss:		0.192659
  validation accuracy:		93.70 %
Epoch 273 of 2000 took 0.078s
  training loss:		0.109022
  validation loss:		0.181916
  validation accuracy:		94.35 %
Epoch 274 of 2000 took 0.078s
  training loss:		0.108250
  validation loss:		0.187567
  validation accuracy:		94.35 %
Epoch 275 of 2000 took 0.075s
  training loss:		0.110469
  validation loss:		0.195492
  validation accuracy:		93.91 %
Epoch 276 of 2000 took 0.075s
  training loss:		0.105673
  validation loss:		0.188914
  validation accuracy:		94.24 %
Epoch 277 of 2000 took 0.077s
  training loss:		0.110570
  validation loss:		0.185307
  validation accuracy:		94.35 %
Epoch 278 of 2000 took 0.075s
  training loss:		0.106649
  validation loss:		0.183878
  validation accuracy:		94.35 %
Epoch 279 of 2000 took 0.076s
  training loss:		0.106119
  validation loss:		0.184964
  validation accuracy:		94.02 %
Epoch 280 of 2000 took 0.075s
  training loss:		0.105882
  validation loss:		0.185510
  validation accuracy:		94.24 %
Epoch 281 of 2000 took 0.078s
  training loss:		0.106035
  validation loss:		0.186473
  validation accuracy:		94.02 %
Epoch 282 of 2000 took 0.080s
  training loss:		0.104788
  validation loss:		0.187810
  validation accuracy:		94.02 %
Epoch 283 of 2000 took 0.075s
  training loss:		0.105380
  validation loss:		0.192567
  validation accuracy:		93.91 %
Epoch 284 of 2000 took 0.077s
  training loss:		0.102287
  validation loss:		0.201609
  validation accuracy:		93.59 %
Epoch 285 of 2000 took 0.074s
  training loss:		0.106676
  validation loss:		0.186372
  validation accuracy:		94.13 %
Epoch 286 of 2000 took 0.075s
  training loss:		0.103223
  validation loss:		0.188414
  validation accuracy:		94.24 %
Epoch 287 of 2000 took 0.077s
  training loss:		0.102606
  validation loss:		0.182651
  validation accuracy:		94.02 %
Epoch 288 of 2000 took 0.078s
  training loss:		0.102299
  validation loss:		0.190214
  validation accuracy:		94.13 %
Epoch 289 of 2000 took 0.074s
  training loss:		0.102459
  validation loss:		0.188191
  validation accuracy:		94.35 %
Epoch 290 of 2000 took 0.077s
  training loss:		0.101279
  validation loss:		0.193996
  validation accuracy:		93.80 %
Epoch 291 of 2000 took 0.077s
  training loss:		0.100029
  validation loss:		0.194918
  validation accuracy:		93.70 %
Epoch 292 of 2000 took 0.072s
  training loss:		0.102743
  validation loss:		0.188496
  validation accuracy:		94.02 %
Epoch 293 of 2000 took 0.075s
  training loss:		0.101496
  validation loss:		0.184362
  validation accuracy:		94.24 %
Epoch 294 of 2000 took 0.077s
  training loss:		0.099147
  validation loss:		0.190531
  validation accuracy:		94.13 %
Epoch 295 of 2000 took 0.076s
  training loss:		0.098706
  validation loss:		0.185489
  validation accuracy:		94.24 %
Epoch 296 of 2000 took 0.075s
  training loss:		0.102092
  validation loss:		0.184828
  validation accuracy:		94.13 %
Epoch 297 of 2000 took 0.078s
  training loss:		0.100937
  validation loss:		0.187160
  validation accuracy:		94.46 %
Epoch 298 of 2000 took 0.079s
  training loss:		0.098990
  validation loss:		0.184267
  validation accuracy:		94.24 %
Epoch 299 of 2000 took 0.079s
  training loss:		0.096427
  validation loss:		0.195455
  validation accuracy:		93.70 %
Epoch 300 of 2000 took 0.076s
  training loss:		0.096860
  validation loss:		0.189284
  validation accuracy:		94.13 %
Epoch 301 of 2000 took 0.074s
  training loss:		0.098674
  validation loss:		0.200332
  validation accuracy:		93.70 %
Epoch 302 of 2000 took 0.079s
  training loss:		0.098086
  validation loss:		0.187342
  validation accuracy:		94.24 %
Epoch 303 of 2000 took 0.075s
  training loss:		0.098027
  validation loss:		0.191000
  validation accuracy:		94.02 %
Epoch 304 of 2000 took 0.075s
  training loss:		0.096848
  validation loss:		0.185261
  validation accuracy:		94.35 %
Epoch 305 of 2000 took 0.077s
  training loss:		0.099552
  validation loss:		0.188611
  validation accuracy:		94.24 %
Epoch 306 of 2000 took 0.077s
  training loss:		0.094709
  validation loss:		0.194054
  validation accuracy:		93.80 %
Epoch 307 of 2000 took 0.074s
  training loss:		0.096138
  validation loss:		0.194845
  validation accuracy:		94.02 %
Epoch 308 of 2000 took 0.078s
  training loss:		0.098652
  validation loss:		0.189212
  validation accuracy:		94.13 %
Epoch 309 of 2000 took 0.076s
  training loss:		0.096319
  validation loss:		0.187476
  validation accuracy:		94.35 %
Epoch 310 of 2000 took 0.076s
  training loss:		0.095589
  validation loss:		0.192932
  validation accuracy:		94.02 %
Epoch 311 of 2000 took 0.076s
  training loss:		0.094064
  validation loss:		0.185882
  validation accuracy:		94.24 %
Epoch 312 of 2000 took 0.076s
  training loss:		0.095157
  validation loss:		0.179670
  validation accuracy:		94.13 %
Epoch 313 of 2000 took 0.076s
  training loss:		0.094925
  validation loss:		0.190273
  validation accuracy:		94.13 %
Epoch 314 of 2000 took 0.076s
  training loss:		0.093192
  validation loss:		0.189456
  validation accuracy:		93.91 %
Epoch 315 of 2000 took 0.077s
  training loss:		0.092308
  validation loss:		0.182045
  validation accuracy:		94.57 %
Epoch 316 of 2000 took 0.078s
  training loss:		0.093877
  validation loss:		0.192681
  validation accuracy:		94.46 %
Epoch 317 of 2000 took 0.077s
  training loss:		0.094935
  validation loss:		0.202841
  validation accuracy:		93.70 %
Epoch 318 of 2000 took 0.074s
  training loss:		0.093228
  validation loss:		0.192046
  validation accuracy:		94.24 %
Epoch 319 of 2000 took 0.076s
  training loss:		0.092672
  validation loss:		0.180613
  validation accuracy:		94.24 %
Epoch 320 of 2000 took 0.079s
  training loss:		0.091614
  validation loss:		0.184502
  validation accuracy:		93.91 %
Epoch 321 of 2000 took 0.077s
  training loss:		0.091760
  validation loss:		0.199922
  validation accuracy:		93.37 %
Epoch 322 of 2000 took 0.074s
  training loss:		0.093318
  validation loss:		0.190632
  validation accuracy:		94.02 %
Epoch 323 of 2000 took 0.077s
  training loss:		0.091826
  validation loss:		0.180945
  validation accuracy:		94.24 %
Epoch 324 of 2000 took 0.077s
  training loss:		0.092976
  validation loss:		0.187023
  validation accuracy:		93.91 %
Epoch 325 of 2000 took 0.075s
  training loss:		0.091487
  validation loss:		0.190509
  validation accuracy:		94.35 %
Epoch 326 of 2000 took 0.077s
  training loss:		0.090953
  validation loss:		0.184495
  validation accuracy:		94.24 %
Epoch 327 of 2000 took 0.076s
  training loss:		0.090017
  validation loss:		0.193171
  validation accuracy:		93.80 %
Epoch 328 of 2000 took 0.076s
  training loss:		0.091827
  validation loss:		0.190732
  validation accuracy:		94.24 %
Epoch 329 of 2000 took 0.077s
  training loss:		0.092841
  validation loss:		0.191506
  validation accuracy:		94.24 %
Epoch 330 of 2000 took 0.074s
  training loss:		0.088543
  validation loss:		0.193429
  validation accuracy:		94.13 %
Epoch 331 of 2000 took 0.073s
  training loss:		0.089605
  validation loss:		0.194373
  validation accuracy:		93.91 %
Epoch 332 of 2000 took 0.075s
  training loss:		0.086999
  validation loss:		0.193716
  validation accuracy:		94.13 %
Epoch 333 of 2000 took 0.076s
  training loss:		0.090377
  validation loss:		0.181126
  validation accuracy:		94.02 %
Epoch 334 of 2000 took 0.072s
  training loss:		0.086927
  validation loss:		0.195065
  validation accuracy:		94.02 %
Epoch 335 of 2000 took 0.074s
  training loss:		0.090374
  validation loss:		0.193435
  validation accuracy:		93.91 %
Epoch 336 of 2000 took 0.076s
  training loss:		0.090080
  validation loss:		0.188039
  validation accuracy:		93.70 %
Epoch 337 of 2000 took 0.076s
  training loss:		0.086511
  validation loss:		0.195863
  validation accuracy:		93.70 %
Epoch 338 of 2000 took 0.078s
  training loss:		0.085875
  validation loss:		0.191323
  validation accuracy:		94.24 %
Epoch 339 of 2000 took 0.075s
  training loss:		0.087524
  validation loss:		0.191545
  validation accuracy:		94.13 %
Epoch 340 of 2000 took 0.075s
  training loss:		0.086371
  validation loss:		0.194237
  validation accuracy:		93.91 %
Epoch 341 of 2000 took 0.075s
  training loss:		0.086601
  validation loss:		0.198343
  validation accuracy:		93.91 %
Epoch 342 of 2000 took 0.077s
  training loss:		0.087408
  validation loss:		0.189117
  validation accuracy:		94.13 %
Epoch 343 of 2000 took 0.078s
  training loss:		0.086734
  validation loss:		0.189396
  validation accuracy:		94.24 %
Epoch 344 of 2000 took 0.074s
  training loss:		0.087502
  validation loss:		0.185192
  validation accuracy:		94.13 %
Epoch 345 of 2000 took 0.077s
  training loss:		0.087174
  validation loss:		0.188759
  validation accuracy:		93.80 %
Epoch 346 of 2000 took 0.077s
  training loss:		0.084831
  validation loss:		0.183692
  validation accuracy:		94.24 %
Epoch 347 of 2000 took 0.077s
  training loss:		0.086102
  validation loss:		0.196132
  validation accuracy:		93.80 %
Epoch 348 of 2000 took 0.074s
  training loss:		0.084489
  validation loss:		0.186250
  validation accuracy:		94.13 %
Epoch 349 of 2000 took 0.076s
  training loss:		0.085103
  validation loss:		0.196719
  validation accuracy:		93.59 %
Epoch 350 of 2000 took 0.075s
  training loss:		0.083992
  validation loss:		0.188842
  validation accuracy:		94.02 %
Epoch 351 of 2000 took 0.081s
  training loss:		0.085216
  validation loss:		0.189707
  validation accuracy:		94.24 %
Epoch 352 of 2000 took 0.076s
  training loss:		0.084321
  validation loss:		0.185526
  validation accuracy:		94.13 %
Epoch 353 of 2000 took 0.076s
  training loss:		0.084149
  validation loss:		0.188557
  validation accuracy:		94.24 %
Epoch 354 of 2000 took 0.079s
  training loss:		0.083979
  validation loss:		0.193740
  validation accuracy:		93.91 %
Epoch 355 of 2000 took 0.077s
  training loss:		0.083816
  validation loss:		0.189785
  validation accuracy:		93.80 %
Epoch 356 of 2000 took 0.076s
  training loss:		0.081914
  validation loss:		0.190210
  validation accuracy:		94.02 %
Epoch 357 of 2000 took 0.082s
  training loss:		0.083018
  validation loss:		0.198089
  validation accuracy:		94.13 %
Epoch 358 of 2000 took 0.079s
  training loss:		0.083020
  validation loss:		0.189807
  validation accuracy:		94.02 %
Epoch 359 of 2000 took 0.077s
  training loss:		0.080800
  validation loss:		0.193186
  validation accuracy:		94.02 %
Epoch 360 of 2000 took 0.077s
  training loss:		0.082474
  validation loss:		0.197084
  validation accuracy:		94.24 %
Epoch 361 of 2000 took 0.078s
  training loss:		0.083210
  validation loss:		0.185095
  validation accuracy:		93.91 %
Epoch 362 of 2000 took 0.077s
  training loss:		0.084336
  validation loss:		0.188579
  validation accuracy:		93.91 %
Epoch 363 of 2000 took 0.079s
  training loss:		0.080142
  validation loss:		0.192840
  validation accuracy:		94.24 %
Epoch 364 of 2000 took 0.089s
  training loss:		0.079217
  validation loss:		0.193470
  validation accuracy:		94.02 %
Epoch 365 of 2000 took 0.077s
  training loss:		0.080577
  validation loss:		0.187930
  validation accuracy:		94.13 %
Epoch 366 of 2000 took 0.074s
  training loss:		0.080368
  validation loss:		0.187416
  validation accuracy:		94.02 %
Epoch 367 of 2000 took 0.078s
  training loss:		0.079485
  validation loss:		0.187704
  validation accuracy:		94.13 %
Epoch 368 of 2000 took 0.074s
  training loss:		0.080663
  validation loss:		0.191460
  validation accuracy:		94.02 %
Epoch 369 of 2000 took 0.077s
  training loss:		0.080280
  validation loss:		0.188150
  validation accuracy:		94.02 %
Epoch 370 of 2000 took 0.078s
  training loss:		0.079090
  validation loss:		0.194955
  validation accuracy:		93.91 %
Epoch 371 of 2000 took 0.077s
  training loss:		0.078674
  validation loss:		0.195885
  validation accuracy:		94.02 %
Epoch 372 of 2000 took 0.075s
  training loss:		0.080153
  validation loss:		0.185255
  validation accuracy:		93.91 %
Epoch 373 of 2000 took 0.076s
  training loss:		0.078871
  validation loss:		0.194651
  validation accuracy:		93.70 %
Epoch 374 of 2000 took 0.078s
  training loss:		0.077131
  validation loss:		0.200016
  validation accuracy:		93.70 %
Epoch 375 of 2000 took 0.077s
  training loss:		0.078657
  validation loss:		0.192617
  validation accuracy:		94.02 %
Epoch 376 of 2000 took 0.074s
  training loss:		0.076664
  validation loss:		0.192843
  validation accuracy:		93.91 %
Epoch 377 of 2000 took 0.075s
  training loss:		0.079653
  validation loss:		0.204793
  validation accuracy:		93.59 %
Epoch 378 of 2000 took 0.077s
  training loss:		0.078585
  validation loss:		0.191952
  validation accuracy:		93.91 %
Epoch 379 of 2000 took 0.076s
  training loss:		0.076813
  validation loss:		0.189423
  validation accuracy:		93.91 %
Epoch 380 of 2000 took 0.077s
  training loss:		0.077191
  validation loss:		0.199386
  validation accuracy:		93.70 %
Epoch 381 of 2000 took 0.081s
  training loss:		0.076696
  validation loss:		0.194957
  validation accuracy:		93.91 %
Epoch 382 of 2000 took 0.076s
  training loss:		0.077712
  validation loss:		0.197866
  validation accuracy:		94.02 %
Epoch 383 of 2000 took 0.077s
  training loss:		0.075115
  validation loss:		0.191247
  validation accuracy:		94.35 %
Epoch 384 of 2000 took 0.077s
  training loss:		0.076250
  validation loss:		0.189102
  validation accuracy:		94.35 %
Epoch 385 of 2000 took 0.078s
  training loss:		0.075659
  validation loss:		0.196679
  validation accuracy:		94.24 %
Epoch 386 of 2000 took 0.076s
  training loss:		0.076541
  validation loss:		0.197639
  validation accuracy:		93.70 %
Epoch 387 of 2000 took 0.075s
  training loss:		0.075178
  validation loss:		0.194122
  validation accuracy:		94.13 %
Epoch 388 of 2000 took 0.080s
  training loss:		0.075824
  validation loss:		0.191757
  validation accuracy:		94.24 %
Epoch 389 of 2000 took 0.078s
  training loss:		0.074658
  validation loss:		0.193008
  validation accuracy:		94.02 %
Epoch 390 of 2000 took 0.076s
  training loss:		0.073302
  validation loss:		0.192547
  validation accuracy:		94.02 %
Epoch 391 of 2000 took 0.076s
  training loss:		0.075116
  validation loss:		0.196147
  validation accuracy:		93.91 %
Epoch 392 of 2000 took 0.076s
  training loss:		0.072510
  validation loss:		0.193567
  validation accuracy:		94.13 %
Epoch 393 of 2000 took 0.077s
  training loss:		0.076235
  validation loss:		0.185859
  validation accuracy:		94.13 %
Epoch 394 of 2000 took 0.078s
  training loss:		0.074145
  validation loss:		0.199789
  validation accuracy:		93.80 %
Epoch 395 of 2000 took 0.077s
  training loss:		0.075140
  validation loss:		0.197356
  validation accuracy:		94.02 %
Epoch 396 of 2000 took 0.078s
  training loss:		0.074705
  validation loss:		0.199383
  validation accuracy:		93.91 %
Epoch 397 of 2000 took 0.076s
  training loss:		0.072176
  validation loss:		0.189346
  validation accuracy:		94.02 %
Epoch 398 of 2000 took 0.078s
  training loss:		0.071704
  validation loss:		0.197024
  validation accuracy:		94.02 %
Epoch 399 of 2000 took 0.077s
  training loss:		0.072791
  validation loss:		0.198527
  validation accuracy:		94.02 %
Epoch 400 of 2000 took 0.074s
  training loss:		0.073081
  validation loss:		0.187525
  validation accuracy:		93.80 %
Epoch 401 of 2000 took 0.077s
  training loss:		0.073303
  validation loss:		0.197067
  validation accuracy:		94.02 %
Epoch 402 of 2000 took 0.079s
  training loss:		0.072223
  validation loss:		0.194068
  validation accuracy:		94.02 %
Epoch 403 of 2000 took 0.079s
  training loss:		0.070683
  validation loss:		0.196396
  validation accuracy:		94.13 %
Epoch 404 of 2000 took 0.077s
  training loss:		0.071744
  validation loss:		0.200493
  validation accuracy:		93.80 %
Epoch 405 of 2000 took 0.077s
  training loss:		0.072007
  validation loss:		0.189515
  validation accuracy:		93.91 %
Epoch 406 of 2000 took 0.077s
  training loss:		0.073309
  validation loss:		0.198558
  validation accuracy:		93.91 %
Epoch 407 of 2000 took 0.078s
  training loss:		0.073908
  validation loss:		0.190038
  validation accuracy:		94.24 %
Epoch 408 of 2000 took 0.078s
  training loss:		0.068143
  validation loss:		0.201247
  validation accuracy:		93.80 %
Epoch 409 of 2000 took 0.078s
  training loss:		0.071096
  validation loss:		0.200440
  validation accuracy:		94.13 %
Epoch 410 of 2000 took 0.076s
  training loss:		0.071989
  validation loss:		0.205949
  validation accuracy:		93.80 %
Epoch 411 of 2000 took 0.078s
  training loss:		0.068943
  validation loss:		0.202924
  validation accuracy:		93.80 %
Epoch 412 of 2000 took 0.078s
  training loss:		0.069039
  validation loss:		0.195741
  validation accuracy:		93.80 %
Epoch 413 of 2000 took 0.076s
  training loss:		0.069119
  validation loss:		0.202706
  validation accuracy:		94.02 %
Epoch 414 of 2000 took 0.077s
  training loss:		0.070002
  validation loss:		0.190756
  validation accuracy:		93.91 %
Epoch 415 of 2000 took 0.078s
  training loss:		0.068758
  validation loss:		0.199876
  validation accuracy:		94.02 %
Epoch 416 of 2000 took 0.074s
  training loss:		0.069943
  validation loss:		0.196312
  validation accuracy:		93.91 %
Epoch 417 of 2000 took 0.077s
  training loss:		0.070000
  validation loss:		0.196653
  validation accuracy:		93.59 %
Epoch 418 of 2000 took 0.077s
  training loss:		0.071034
  validation loss:		0.197529
  validation accuracy:		93.91 %
Epoch 419 of 2000 took 0.076s
  training loss:		0.069448
  validation loss:		0.196671
  validation accuracy:		93.91 %
Epoch 420 of 2000 took 0.078s
  training loss:		0.068819
  validation loss:		0.201736
  validation accuracy:		93.70 %
Epoch 421 of 2000 took 0.075s
  training loss:		0.067639
  validation loss:		0.198606
  validation accuracy:		93.91 %
Epoch 422 of 2000 took 0.074s
  training loss:		0.068832
  validation loss:		0.203545
  validation accuracy:		94.46 %
Epoch 423 of 2000 took 0.075s
  training loss:		0.065392
  validation loss:		0.199530
  validation accuracy:		94.02 %
Epoch 424 of 2000 took 0.077s
  training loss:		0.067623
  validation loss:		0.189310
  validation accuracy:		93.80 %
Epoch 425 of 2000 took 0.077s
  training loss:		0.068772
  validation loss:		0.199750
  validation accuracy:		93.91 %
Epoch 426 of 2000 took 0.077s
  training loss:		0.066649
  validation loss:		0.196944
  validation accuracy:		94.02 %
Epoch 427 of 2000 took 0.076s
  training loss:		0.068496
  validation loss:		0.194434
  validation accuracy:		94.02 %
Epoch 428 of 2000 took 0.077s
  training loss:		0.064761
  validation loss:		0.199169
  validation accuracy:		94.13 %
Epoch 429 of 2000 took 0.078s
  training loss:		0.066709
  validation loss:		0.199376
  validation accuracy:		94.02 %
Epoch 430 of 2000 took 0.077s
  training loss:		0.067388
  validation loss:		0.199210
  validation accuracy:		94.13 %
Epoch 431 of 2000 took 0.077s
  training loss:		0.064876
  validation loss:		0.196761
  validation accuracy:		93.70 %
Epoch 432 of 2000 took 0.078s
  training loss:		0.066839
  validation loss:		0.203413
  validation accuracy:		94.13 %
Epoch 433 of 2000 took 0.078s
  training loss:		0.066602
  validation loss:		0.195565
  validation accuracy:		94.13 %
Epoch 434 of 2000 took 0.076s
  training loss:		0.064949
  validation loss:		0.192641
  validation accuracy:		94.13 %
Epoch 435 of 2000 took 0.077s
  training loss:		0.066418
  validation loss:		0.203407
  validation accuracy:		94.02 %
Epoch 436 of 2000 took 0.075s
  training loss:		0.066677
  validation loss:		0.207598
  validation accuracy:		94.02 %
Epoch 437 of 2000 took 0.076s
  training loss:		0.064081
  validation loss:		0.205884
  validation accuracy:		94.02 %
Epoch 438 of 2000 took 0.074s
  training loss:		0.066326
  validation loss:		0.196409
  validation accuracy:		93.91 %
Epoch 439 of 2000 took 0.075s
  training loss:		0.064336
  validation loss:		0.200723
  validation accuracy:		93.80 %
Epoch 440 of 2000 took 0.077s
  training loss:		0.065377
  validation loss:		0.199732
  validation accuracy:		94.02 %
Epoch 441 of 2000 took 0.077s
  training loss:		0.067320
  validation loss:		0.207560
  validation accuracy:		94.13 %
Epoch 442 of 2000 took 0.078s
  training loss:		0.065477
  validation loss:		0.202117
  validation accuracy:		94.24 %
Epoch 443 of 2000 took 0.077s
  training loss:		0.064898
  validation loss:		0.198171
  validation accuracy:		94.02 %
Epoch 444 of 2000 took 0.075s
  training loss:		0.063287
  validation loss:		0.191906
  validation accuracy:		93.91 %
Epoch 445 of 2000 took 0.075s
  training loss:		0.064853
  validation loss:		0.208602
  validation accuracy:		93.80 %
Epoch 446 of 2000 took 0.076s
  training loss:		0.063298
  validation loss:		0.199319
  validation accuracy:		93.91 %
Epoch 447 of 2000 took 0.079s
  training loss:		0.063550
  validation loss:		0.206752
  validation accuracy:		94.13 %
Epoch 448 of 2000 took 0.078s
  training loss:		0.063047
  validation loss:		0.199133
  validation accuracy:		93.80 %
Epoch 449 of 2000 took 0.078s
  training loss:		0.063101
  validation loss:		0.198240
  validation accuracy:		94.02 %
Epoch 450 of 2000 took 0.077s
  training loss:		0.062257
  validation loss:		0.207772
  validation accuracy:		93.80 %
Epoch 451 of 2000 took 0.077s
  training loss:		0.064037
  validation loss:		0.206244
  validation accuracy:		94.13 %
Epoch 452 of 2000 took 0.078s
  training loss:		0.061880
  validation loss:		0.201146
  validation accuracy:		94.02 %
Epoch 453 of 2000 took 0.078s
  training loss:		0.063690
  validation loss:		0.208528
  validation accuracy:		93.91 %
Epoch 454 of 2000 took 0.079s
  training loss:		0.062462
  validation loss:		0.205996
  validation accuracy:		94.13 %
Epoch 455 of 2000 took 0.078s
  training loss:		0.062001
  validation loss:		0.198338
  validation accuracy:		94.02 %
Epoch 456 of 2000 took 0.078s
  training loss:		0.063493
  validation loss:		0.211500
  validation accuracy:		93.59 %
Epoch 457 of 2000 took 0.074s
  training loss:		0.062472
  validation loss:		0.202037
  validation accuracy:		94.13 %
Epoch 458 of 2000 took 0.077s
  training loss:		0.061062
  validation loss:		0.199976
  validation accuracy:		94.13 %
Epoch 459 of 2000 took 0.078s
  training loss:		0.061323
  validation loss:		0.197959
  validation accuracy:		94.02 %
Epoch 460 of 2000 took 0.075s
  training loss:		0.059448
  validation loss:		0.207008
  validation accuracy:		93.59 %
Epoch 461 of 2000 took 0.079s
  training loss:		0.060581
  validation loss:		0.197210
  validation accuracy:		94.02 %
Epoch 462 of 2000 took 0.076s
  training loss:		0.062388
  validation loss:		0.204701
  validation accuracy:		94.24 %
Epoch 463 of 2000 took 0.077s
  training loss:		0.061259
  validation loss:		0.205224
  validation accuracy:		93.91 %
Epoch 464 of 2000 took 0.074s
  training loss:		0.059826
  validation loss:		0.202588
  validation accuracy:		94.13 %
Epoch 465 of 2000 took 0.075s
  training loss:		0.061435
  validation loss:		0.201038
  validation accuracy:		93.91 %
Epoch 466 of 2000 took 0.077s
  training loss:		0.061419
  validation loss:		0.201857
  validation accuracy:		94.02 %
Epoch 467 of 2000 took 0.076s
  training loss:		0.057150
  validation loss:		0.209117
  validation accuracy:		94.02 %
Epoch 468 of 2000 took 0.078s
  training loss:		0.058766
  validation loss:		0.204626
  validation accuracy:		94.24 %
Epoch 469 of 2000 took 0.078s
  training loss:		0.061215
  validation loss:		0.210072
  validation accuracy:		94.02 %
Epoch 470 of 2000 took 0.078s
  training loss:		0.057505
  validation loss:		0.207006
  validation accuracy:		94.13 %
Epoch 471 of 2000 took 0.078s
  training loss:		0.059280
  validation loss:		0.203307
  validation accuracy:		93.91 %
Epoch 472 of 2000 took 0.076s
  training loss:		0.058882
  validation loss:		0.203940
  validation accuracy:		94.02 %
Epoch 473 of 2000 took 0.078s
  training loss:		0.058363
  validation loss:		0.211501
  validation accuracy:		93.70 %
Epoch 474 of 2000 took 0.078s
  training loss:		0.054419
  validation loss:		0.205657
  validation accuracy:		93.80 %
Epoch 475 of 2000 took 0.079s
  training loss:		0.058714
  validation loss:		0.207253
  validation accuracy:		94.02 %
Epoch 476 of 2000 took 0.078s
  training loss:		0.059531
  validation loss:		0.220599
  validation accuracy:		93.70 %
Epoch 477 of 2000 took 0.075s
  training loss:		0.057881
  validation loss:		0.212984
  validation accuracy:		93.70 %
Epoch 478 of 2000 took 0.075s
  training loss:		0.060065
  validation loss:		0.215160
  validation accuracy:		93.80 %
Epoch 479 of 2000 took 0.079s
  training loss:		0.058736
  validation loss:		0.209183
  validation accuracy:		93.91 %
Epoch 480 of 2000 took 0.076s
  training loss:		0.058525
  validation loss:		0.218207
  validation accuracy:		93.59 %
Epoch 481 of 2000 took 0.080s
  training loss:		0.056876
  validation loss:		0.203871
  validation accuracy:		94.24 %
Epoch 482 of 2000 took 0.074s
  training loss:		0.056971
  validation loss:		0.210507
  validation accuracy:		94.02 %
Epoch 483 of 2000 took 0.074s
  training loss:		0.059363
  validation loss:		0.204116
  validation accuracy:		93.91 %
Epoch 484 of 2000 took 0.082s
  training loss:		0.057826
  validation loss:		0.205908
  validation accuracy:		94.24 %
Epoch 485 of 2000 took 0.076s
  training loss:		0.057197
  validation loss:		0.208997
  validation accuracy:		93.91 %
Epoch 486 of 2000 took 0.076s
  training loss:		0.058423
  validation loss:		0.211692
  validation accuracy:		94.02 %
Epoch 487 of 2000 took 0.076s
  training loss:		0.056441
  validation loss:		0.204103
  validation accuracy:		93.91 %
Epoch 488 of 2000 took 0.078s
  training loss:		0.055753
  validation loss:		0.209902
  validation accuracy:		94.02 %
Epoch 489 of 2000 took 0.077s
  training loss:		0.055010
  validation loss:		0.221938
  validation accuracy:		93.80 %
Epoch 490 of 2000 took 0.074s
  training loss:		0.056684
  validation loss:		0.217123
  validation accuracy:		93.70 %
Epoch 491 of 2000 took 0.076s
  training loss:		0.055066
  validation loss:		0.200995
  validation accuracy:		93.59 %
Epoch 492 of 2000 took 0.077s
  training loss:		0.057181
  validation loss:		0.208818
  validation accuracy:		93.91 %
Epoch 493 of 2000 took 0.076s
  training loss:		0.057457
  validation loss:		0.205178
  validation accuracy:		93.91 %
Epoch 494 of 2000 took 0.076s
  training loss:		0.056479
  validation loss:		0.213386
  validation accuracy:		93.59 %
Epoch 495 of 2000 took 0.076s
  training loss:		0.054438
  validation loss:		0.223430
  validation accuracy:		93.70 %
Epoch 496 of 2000 took 0.076s
  training loss:		0.056496
  validation loss:		0.217511
  validation accuracy:		94.02 %
Epoch 497 of 2000 took 0.076s
  training loss:		0.056842
  validation loss:		0.214330
  validation accuracy:		93.70 %
Epoch 498 of 2000 took 0.076s
  training loss:		0.056286
  validation loss:		0.208506
  validation accuracy:		94.02 %
Epoch 499 of 2000 took 0.075s
  training loss:		0.056615
  validation loss:		0.225634
  validation accuracy:		93.80 %
Epoch 500 of 2000 took 0.078s
  training loss:		0.054068
  validation loss:		0.218701
  validation accuracy:		93.80 %
Epoch 501 of 2000 took 0.077s
  training loss:		0.053953
  validation loss:		0.213194
  validation accuracy:		94.02 %
Epoch 502 of 2000 took 0.079s
  training loss:		0.054283
  validation loss:		0.212043
  validation accuracy:		94.02 %
Epoch 503 of 2000 took 0.075s
  training loss:		0.055884
  validation loss:		0.215246
  validation accuracy:		94.02 %
Epoch 504 of 2000 took 0.073s
  training loss:		0.055269
  validation loss:		0.211936
  validation accuracy:		94.02 %
Epoch 505 of 2000 took 0.076s
  training loss:		0.054374
  validation loss:		0.215138
  validation accuracy:		93.91 %
Epoch 506 of 2000 took 0.078s
  training loss:		0.053378
  validation loss:		0.211192
  validation accuracy:		94.02 %
Epoch 507 of 2000 took 0.078s
  training loss:		0.054438
  validation loss:		0.212898
  validation accuracy:		94.02 %
Epoch 508 of 2000 took 0.078s
  training loss:		0.053627
  validation loss:		0.204922
  validation accuracy:		93.70 %
Epoch 509 of 2000 took 0.077s
  training loss:		0.054033
  validation loss:		0.217489
  validation accuracy:		94.02 %
Epoch 510 of 2000 took 0.075s
  training loss:		0.054157
  validation loss:		0.208709
  validation accuracy:		93.70 %
Epoch 511 of 2000 took 0.076s
  training loss:		0.053219
  validation loss:		0.211856
  validation accuracy:		93.91 %
Epoch 512 of 2000 took 0.079s
  training loss:		0.053956
  validation loss:		0.200154
  validation accuracy:		93.91 %
Epoch 513 of 2000 took 0.075s
  training loss:		0.054572
  validation loss:		0.213873
  validation accuracy:		94.13 %
Epoch 514 of 2000 took 0.078s
  training loss:		0.051906
  validation loss:		0.220724
  validation accuracy:		93.59 %
Epoch 515 of 2000 took 0.074s
  training loss:		0.052945
  validation loss:		0.212161
  validation accuracy:		93.80 %
Epoch 516 of 2000 took 0.077s
  training loss:		0.054275
  validation loss:		0.217479
  validation accuracy:		93.80 %
Epoch 517 of 2000 took 0.075s
  training loss:		0.053305
  validation loss:		0.222088
  validation accuracy:		93.80 %
Epoch 518 of 2000 took 0.076s
  training loss:		0.053263
  validation loss:		0.212940
  validation accuracy:		94.02 %
Epoch 519 of 2000 took 0.078s
  training loss:		0.052256
  validation loss:		0.211794
  validation accuracy:		93.91 %
Epoch 520 of 2000 took 0.076s
  training loss:		0.052672
  validation loss:		0.212655
  validation accuracy:		94.02 %
Epoch 521 of 2000 took 0.075s
  training loss:		0.052554
  validation loss:		0.209763
  validation accuracy:		94.02 %
Epoch 522 of 2000 took 0.076s
  training loss:		0.052745
  validation loss:		0.211964
  validation accuracy:		94.02 %
Epoch 523 of 2000 took 0.075s
  training loss:		0.051069
  validation loss:		0.218836
  validation accuracy:		94.02 %
Epoch 524 of 2000 took 0.077s
  training loss:		0.051159
  validation loss:		0.214737
  validation accuracy:		93.70 %
Epoch 525 of 2000 took 0.077s
  training loss:		0.051984
  validation loss:		0.216559
  validation accuracy:		93.91 %
Epoch 526 of 2000 took 0.077s
  training loss:		0.050989
  validation loss:		0.220849
  validation accuracy:		94.24 %
Epoch 527 of 2000 took 0.077s
  training loss:		0.050567
  validation loss:		0.218019
  validation accuracy:		93.59 %
Epoch 528 of 2000 took 0.078s
  training loss:		0.049294
  validation loss:		0.226327
  validation accuracy:		93.48 %
Epoch 529 of 2000 took 0.075s
  training loss:		0.052372
  validation loss:		0.220221
  validation accuracy:		93.80 %
Epoch 530 of 2000 took 0.079s
  training loss:		0.049819
  validation loss:		0.229586
  validation accuracy:		94.02 %
Epoch 531 of 2000 took 0.078s
  training loss:		0.050749
  validation loss:		0.231719
  validation accuracy:		93.91 %
Epoch 532 of 2000 took 0.075s
  training loss:		0.049879
  validation loss:		0.215564
  validation accuracy:		94.02 %
Epoch 533 of 2000 took 0.077s
  training loss:		0.049698
  validation loss:		0.220427
  validation accuracy:		94.02 %
Epoch 534 of 2000 took 0.077s
  training loss:		0.047870
  validation loss:		0.216847
  validation accuracy:		93.80 %
Epoch 535 of 2000 took 0.079s
  training loss:		0.049260
  validation loss:		0.225635
  validation accuracy:		93.80 %
Epoch 536 of 2000 took 0.077s
  training loss:		0.049919
  validation loss:		0.220303
  validation accuracy:		93.59 %
Epoch 537 of 2000 took 0.078s
  training loss:		0.049467
  validation loss:		0.210824
  validation accuracy:		94.02 %
Epoch 538 of 2000 took 0.078s
  training loss:		0.050544
  validation loss:		0.215782
  validation accuracy:		93.70 %
Epoch 539 of 2000 took 0.077s
  training loss:		0.049974
  validation loss:		0.216690
  validation accuracy:		93.70 %
Epoch 540 of 2000 took 0.078s
  training loss:		0.049380
  validation loss:		0.222525
  validation accuracy:		93.80 %
Epoch 541 of 2000 took 0.079s
  training loss:		0.048760
  validation loss:		0.226622
  validation accuracy:		93.70 %
Epoch 542 of 2000 took 0.077s
  training loss:		0.047681
  validation loss:		0.220324
  validation accuracy:		94.24 %
Epoch 543 of 2000 took 0.077s
  training loss:		0.049388
  validation loss:		0.215908
  validation accuracy:		93.70 %
Epoch 544 of 2000 took 0.076s
  training loss:		0.048680
  validation loss:		0.226478
  validation accuracy:		93.91 %
Epoch 545 of 2000 took 0.074s
  training loss:		0.048511
  validation loss:		0.222530
  validation accuracy:		93.80 %
Epoch 546 of 2000 took 0.076s
  training loss:		0.048335
  validation loss:		0.226680
  validation accuracy:		93.37 %
Epoch 547 of 2000 took 0.075s
  training loss:		0.049716
  validation loss:		0.233724
  validation accuracy:		93.80 %
Epoch 548 of 2000 took 0.075s
  training loss:		0.049240
  validation loss:		0.217509
  validation accuracy:		94.13 %
Epoch 549 of 2000 took 0.076s
  training loss:		0.048389
  validation loss:		0.215942
  validation accuracy:		94.13 %
Epoch 550 of 2000 took 0.078s
  training loss:		0.047731
  validation loss:		0.224231
  validation accuracy:		93.80 %
Epoch 551 of 2000 took 0.075s
  training loss:		0.047757
  validation loss:		0.226728
  validation accuracy:		94.13 %
Epoch 552 of 2000 took 0.078s
  training loss:		0.047787
  validation loss:		0.222806
  validation accuracy:		93.80 %
Epoch 553 of 2000 took 0.079s
  training loss:		0.047200
  validation loss:		0.214623
  validation accuracy:		94.13 %
Epoch 554 of 2000 took 0.078s
  training loss:		0.046609
  validation loss:		0.221279
  validation accuracy:		93.80 %
Epoch 555 of 2000 took 0.076s
  training loss:		0.047872
  validation loss:		0.225878
  validation accuracy:		93.91 %
Epoch 556 of 2000 took 0.080s
  training loss:		0.046627
  validation loss:		0.221369
  validation accuracy:		93.91 %
Epoch 557 of 2000 took 0.077s
  training loss:		0.045876
  validation loss:		0.227034
  validation accuracy:		93.91 %
Epoch 558 of 2000 took 0.076s
  training loss:		0.046547
  validation loss:		0.224080
  validation accuracy:		93.80 %
Epoch 559 of 2000 took 0.079s
  training loss:		0.042704
  validation loss:		0.221018
  validation accuracy:		93.91 %
Epoch 560 of 2000 took 0.078s
  training loss:		0.044212
  validation loss:		0.221454
  validation accuracy:		93.91 %
Epoch 561 of 2000 took 0.076s
  training loss:		0.045089
  validation loss:		0.217971
  validation accuracy:		93.91 %
Epoch 562 of 2000 took 0.078s
  training loss:		0.045420
  validation loss:		0.226156
  validation accuracy:		93.48 %
Epoch 563 of 2000 took 0.077s
  training loss:		0.045476
  validation loss:		0.224190
  validation accuracy:		93.91 %
Epoch 564 of 2000 took 0.075s
  training loss:		0.045792
  validation loss:		0.223056
  validation accuracy:		94.02 %
Epoch 565 of 2000 took 0.076s
  training loss:		0.046106
  validation loss:		0.233845
  validation accuracy:		93.59 %
Epoch 566 of 2000 took 0.075s
  training loss:		0.045920
  validation loss:		0.224793
  validation accuracy:		93.91 %
Epoch 567 of 2000 took 0.075s
  training loss:		0.045994
  validation loss:		0.225003
  validation accuracy:		94.02 %
Epoch 568 of 2000 took 0.077s
  training loss:		0.045038
  validation loss:		0.224385
  validation accuracy:		94.02 %
Epoch 569 of 2000 took 0.077s
  training loss:		0.045500
  validation loss:		0.222967
  validation accuracy:		93.59 %
Epoch 570 of 2000 took 0.078s
  training loss:		0.044976
  validation loss:		0.224251
  validation accuracy:		93.70 %
Epoch 571 of 2000 took 0.080s
  training loss:		0.044345
  validation loss:		0.224529
  validation accuracy:		94.13 %
Epoch 572 of 2000 took 0.077s
  training loss:		0.042975
  validation loss:		0.227951
  validation accuracy:		93.91 %
Epoch 573 of 2000 took 0.077s
  training loss:		0.044803
  validation loss:		0.223915
  validation accuracy:		93.91 %
Epoch 574 of 2000 took 0.078s
  training loss:		0.045076
  validation loss:		0.228225
  validation accuracy:		93.59 %
Epoch 575 of 2000 took 0.077s
  training loss:		0.044188
  validation loss:		0.227947
  validation accuracy:		93.91 %
Epoch 576 of 2000 took 0.078s
  training loss:		0.041890
  validation loss:		0.230358
  validation accuracy:		93.70 %
Epoch 577 of 2000 took 0.077s
  training loss:		0.045411
  validation loss:		0.241003
  validation accuracy:		93.48 %
Epoch 578 of 2000 took 0.076s
  training loss:		0.045992
  validation loss:		0.228402
  validation accuracy:		93.91 %
Epoch 579 of 2000 took 0.077s
  training loss:		0.044045
  validation loss:		0.232581
  validation accuracy:		93.70 %
Epoch 580 of 2000 took 0.078s
  training loss:		0.044665
  validation loss:		0.218505
  validation accuracy:		94.02 %
Epoch 581 of 2000 took 0.077s
  training loss:		0.044556
  validation loss:		0.223106
  validation accuracy:		93.80 %
Epoch 582 of 2000 took 0.079s
  training loss:		0.042911
  validation loss:		0.227637
  validation accuracy:		93.91 %
Epoch 583 of 2000 took 0.074s
  training loss:		0.042766
  validation loss:		0.223330
  validation accuracy:		93.59 %
Epoch 584 of 2000 took 0.077s
  training loss:		0.042263
  validation loss:		0.224376
  validation accuracy:		93.80 %
Epoch 585 of 2000 took 0.074s
  training loss:		0.041421
  validation loss:		0.232471
  validation accuracy:		93.80 %
Epoch 586 of 2000 took 0.077s
  training loss:		0.043019
  validation loss:		0.233068
  validation accuracy:		93.80 %
Epoch 587 of 2000 took 0.076s
  training loss:		0.043256
  validation loss:		0.231158
  validation accuracy:		93.59 %
Epoch 588 of 2000 took 0.076s
  training loss:		0.042579
  validation loss:		0.228157
  validation accuracy:		94.02 %
Epoch 589 of 2000 took 0.077s
  training loss:		0.043658
  validation loss:		0.230615
  validation accuracy:		93.91 %
Epoch 590 of 2000 took 0.074s
  training loss:		0.041641
  validation loss:		0.232757
  validation accuracy:		93.70 %
Epoch 591 of 2000 took 0.076s
  training loss:		0.039337
  validation loss:		0.228535
  validation accuracy:		93.70 %
Epoch 592 of 2000 took 0.076s
  training loss:		0.042663
  validation loss:		0.225619
  validation accuracy:		93.91 %
Epoch 593 of 2000 took 0.074s
  training loss:		0.042253
  validation loss:		0.229255
  validation accuracy:		94.02 %
Epoch 594 of 2000 took 0.074s
  training loss:		0.042565
  validation loss:		0.231537
  validation accuracy:		93.80 %
Epoch 595 of 2000 took 0.074s
  training loss:		0.042888
  validation loss:		0.230270
  validation accuracy:		94.02 %
Epoch 596 of 2000 took 0.078s
  training loss:		0.042531
  validation loss:		0.229182
  validation accuracy:		93.91 %
Epoch 597 of 2000 took 0.074s
  training loss:		0.038603
  validation loss:		0.238792
  validation accuracy:		93.59 %
Epoch 598 of 2000 took 0.078s
  training loss:		0.042157
  validation loss:		0.232380
  validation accuracy:		93.59 %
Epoch 599 of 2000 took 0.077s
  training loss:		0.043160
  validation loss:		0.241980
  validation accuracy:		93.59 %
Epoch 600 of 2000 took 0.075s
  training loss:		0.042424
  validation loss:		0.234942
  validation accuracy:		94.13 %
Epoch 601 of 2000 took 0.075s
  training loss:		0.040859
  validation loss:		0.239850
  validation accuracy:		93.37 %
Epoch 602 of 2000 took 0.075s
  training loss:		0.042029
  validation loss:		0.231277
  validation accuracy:		93.91 %
Epoch 603 of 2000 took 0.077s
  training loss:		0.041149
  validation loss:		0.233364
  validation accuracy:		93.80 %
Epoch 604 of 2000 took 0.076s
  training loss:		0.041491
  validation loss:		0.234692
  validation accuracy:		93.80 %
Epoch 605 of 2000 took 0.076s
  training loss:		0.041320
  validation loss:		0.234839
  validation accuracy:		93.80 %
Epoch 606 of 2000 took 0.076s
  training loss:		0.040412
  validation loss:		0.225305
  validation accuracy:		94.13 %
Epoch 607 of 2000 took 0.077s
  training loss:		0.041673
  validation loss:		0.231162
  validation accuracy:		93.59 %
Epoch 608 of 2000 took 0.074s
  training loss:		0.040576
  validation loss:		0.239118
  validation accuracy:		93.80 %
Epoch 609 of 2000 took 0.076s
  training loss:		0.039448
  validation loss:		0.246115
  validation accuracy:		93.26 %
Epoch 610 of 2000 took 0.077s
  training loss:		0.041127
  validation loss:		0.236130
  validation accuracy:		93.59 %
Epoch 611 of 2000 took 0.076s
  training loss:		0.040948
  validation loss:		0.238666
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.077s
  training loss:		0.040292
  validation loss:		0.237004
  validation accuracy:		93.59 %
Epoch 613 of 2000 took 0.079s
  training loss:		0.040127
  validation loss:		0.234475
  validation accuracy:		93.91 %
Epoch 614 of 2000 took 0.077s
  training loss:		0.041395
  validation loss:		0.236070
  validation accuracy:		93.70 %
Epoch 615 of 2000 took 0.076s
  training loss:		0.041065
  validation loss:		0.230667
  validation accuracy:		94.13 %
Epoch 616 of 2000 took 0.075s
  training loss:		0.039906
  validation loss:		0.233733
  validation accuracy:		93.70 %
Epoch 617 of 2000 took 0.076s
  training loss:		0.040369
  validation loss:		0.239813
  validation accuracy:		93.80 %
Epoch 618 of 2000 took 0.076s
  training loss:		0.039366
  validation loss:		0.226642
  validation accuracy:		93.91 %
Epoch 619 of 2000 took 0.079s
  training loss:		0.039689
  validation loss:		0.228493
  validation accuracy:		94.02 %
Epoch 620 of 2000 took 0.078s
  training loss:		0.039946
  validation loss:		0.237946
  validation accuracy:		93.91 %
Epoch 621 of 2000 took 0.077s
  training loss:		0.039877
  validation loss:		0.241422
  validation accuracy:		93.70 %
Epoch 622 of 2000 took 0.078s
  training loss:		0.039165
  validation loss:		0.235425
  validation accuracy:		93.91 %
Epoch 623 of 2000 took 0.079s
  training loss:		0.039310
  validation loss:		0.241502
  validation accuracy:		93.91 %
Epoch 624 of 2000 took 0.078s
  training loss:		0.038846
  validation loss:		0.231548
  validation accuracy:		94.02 %
Epoch 625 of 2000 took 0.075s
  training loss:		0.036773
  validation loss:		0.234681
  validation accuracy:		93.91 %
Epoch 626 of 2000 took 0.078s
  training loss:		0.038525
  validation loss:		0.231936
  validation accuracy:		93.70 %
Epoch 627 of 2000 took 0.075s
  training loss:		0.038847
  validation loss:		0.236809
  validation accuracy:		93.91 %
Epoch 628 of 2000 took 0.076s
  training loss:		0.037657
  validation loss:		0.243138
  validation accuracy:		93.59 %
Epoch 629 of 2000 took 0.073s
  training loss:		0.038823
  validation loss:		0.235216
  validation accuracy:		93.80 %
Epoch 630 of 2000 took 0.077s
  training loss:		0.038352
  validation loss:		0.249492
  validation accuracy:		93.15 %
Epoch 631 of 2000 took 0.075s
  training loss:		0.037664
  validation loss:		0.240945
  validation accuracy:		93.37 %
Epoch 632 of 2000 took 0.076s
  training loss:		0.038461
  validation loss:		0.235034
  validation accuracy:		94.02 %
Epoch 633 of 2000 took 0.076s
  training loss:		0.037370
  validation loss:		0.248167
  validation accuracy:		93.15 %
Epoch 634 of 2000 took 0.079s
  training loss:		0.037767
  validation loss:		0.245563
  validation accuracy:		93.80 %
Epoch 635 of 2000 took 0.075s
  training loss:		0.038535
  validation loss:		0.236363
  validation accuracy:		93.48 %
Epoch 636 of 2000 took 0.076s
  training loss:		0.038432
  validation loss:		0.242123
  validation accuracy:		94.02 %
Epoch 637 of 2000 took 0.078s
  training loss:		0.037335
  validation loss:		0.239867
  validation accuracy:		93.91 %
Epoch 638 of 2000 took 0.077s
  training loss:		0.038571
  validation loss:		0.238990
  validation accuracy:		93.91 %
Epoch 639 of 2000 took 0.078s
  training loss:		0.037415
  validation loss:		0.242708
  validation accuracy:		93.70 %
Epoch 640 of 2000 took 0.075s
  training loss:		0.036391
  validation loss:		0.235195
  validation accuracy:		93.80 %
Epoch 641 of 2000 took 0.074s
  training loss:		0.037034
  validation loss:		0.246616
  validation accuracy:		93.80 %
Epoch 642 of 2000 took 0.075s
  training loss:		0.036850
  validation loss:		0.237276
  validation accuracy:		93.91 %
Epoch 643 of 2000 took 0.078s
  training loss:		0.036708
  validation loss:		0.238857
  validation accuracy:		93.91 %
Epoch 644 of 2000 took 0.078s
  training loss:		0.036332
  validation loss:		0.238834
  validation accuracy:		93.48 %
Epoch 645 of 2000 took 0.075s
  training loss:		0.036299
  validation loss:		0.241885
  validation accuracy:		93.91 %
Epoch 646 of 2000 took 0.073s
  training loss:		0.037044
  validation loss:		0.236278
  validation accuracy:		94.02 %
Epoch 647 of 2000 took 0.075s
  training loss:		0.036540
  validation loss:		0.237786
  validation accuracy:		93.80 %
Epoch 648 of 2000 took 0.075s
  training loss:		0.036732
  validation loss:		0.251976
  validation accuracy:		93.70 %
Epoch 649 of 2000 took 0.079s
  training loss:		0.035818
  validation loss:		0.238954
  validation accuracy:		94.02 %
Epoch 650 of 2000 took 0.074s
  training loss:		0.035137
  validation loss:		0.237723
  validation accuracy:		94.13 %
Epoch 651 of 2000 took 0.076s
  training loss:		0.036346
  validation loss:		0.251715
  validation accuracy:		93.48 %
Epoch 652 of 2000 took 0.076s
  training loss:		0.036760
  validation loss:		0.239439
  validation accuracy:		93.91 %
Epoch 653 of 2000 took 0.078s
  training loss:		0.037476
  validation loss:		0.249375
  validation accuracy:		93.70 %
Epoch 654 of 2000 took 0.077s
  training loss:		0.035135
  validation loss:		0.239541
  validation accuracy:		94.02 %
Epoch 655 of 2000 took 0.076s
  training loss:		0.035806
  validation loss:		0.238463
  validation accuracy:		93.70 %
Epoch 656 of 2000 took 0.075s
  training loss:		0.035519
  validation loss:		0.245792
  validation accuracy:		93.70 %
Epoch 657 of 2000 took 0.076s
  training loss:		0.036164
  validation loss:		0.249156
  validation accuracy:		93.37 %
Epoch 658 of 2000 took 0.078s
  training loss:		0.035264
  validation loss:		0.243196
  validation accuracy:		93.70 %
Epoch 659 of 2000 took 0.077s
  training loss:		0.034734
  validation loss:		0.242702
  validation accuracy:		93.91 %
Epoch 660 of 2000 took 0.077s
  training loss:		0.033806
  validation loss:		0.241655
  validation accuracy:		93.80 %
Epoch 661 of 2000 took 0.076s
  training loss:		0.032756
  validation loss:		0.234990
  validation accuracy:		93.91 %
Epoch 662 of 2000 took 0.079s
  training loss:		0.036168
  validation loss:		0.244049
  validation accuracy:		93.59 %
Epoch 663 of 2000 took 0.078s
  training loss:		0.035341
  validation loss:		0.243977
  validation accuracy:		94.02 %
Epoch 664 of 2000 took 0.077s
  training loss:		0.033531
  validation loss:		0.240241
  validation accuracy:		93.80 %
Epoch 665 of 2000 took 0.077s
  training loss:		0.034831
  validation loss:		0.247569
  validation accuracy:		93.80 %
Epoch 666 of 2000 took 0.077s
  training loss:		0.033417
  validation loss:		0.251554
  validation accuracy:		93.37 %
Epoch 667 of 2000 took 0.079s
  training loss:		0.033355
  validation loss:		0.248015
  validation accuracy:		93.91 %
Epoch 668 of 2000 took 0.079s
  training loss:		0.034245
  validation loss:		0.246828
  validation accuracy:		93.70 %
Epoch 669 of 2000 took 0.075s
  training loss:		0.035015
  validation loss:		0.256933
  validation accuracy:		93.37 %
Epoch 670 of 2000 took 0.073s
  training loss:		0.033215
  validation loss:		0.256518
  validation accuracy:		93.48 %
Epoch 671 of 2000 took 0.076s
  training loss:		0.035017
  validation loss:		0.247413
  validation accuracy:		93.59 %
Epoch 672 of 2000 took 0.074s
  training loss:		0.033116
  validation loss:		0.244963
  validation accuracy:		93.91 %
Epoch 673 of 2000 took 0.078s
  training loss:		0.033524
  validation loss:		0.253384
  validation accuracy:		93.37 %
Epoch 674 of 2000 took 0.075s
  training loss:		0.033423
  validation loss:		0.255511
  validation accuracy:		93.59 %
Epoch 675 of 2000 took 0.078s
  training loss:		0.033542
  validation loss:		0.244887
  validation accuracy:		93.91 %
Epoch 676 of 2000 took 0.077s
  training loss:		0.033358
  validation loss:		0.252439
  validation accuracy:		93.80 %
Epoch 677 of 2000 took 0.077s
  training loss:		0.033410
  validation loss:		0.241543
  validation accuracy:		93.91 %
Epoch 678 of 2000 took 0.076s
  training loss:		0.033098
  validation loss:		0.252165
  validation accuracy:		93.59 %
Epoch 679 of 2000 took 0.078s
  training loss:		0.032622
  validation loss:		0.249478
  validation accuracy:		93.37 %
Epoch 680 of 2000 took 0.078s
  training loss:		0.033278
  validation loss:		0.253697
  validation accuracy:		93.70 %
Epoch 681 of 2000 took 0.076s
  training loss:		0.031691
  validation loss:		0.252749
  validation accuracy:		93.80 %
Epoch 682 of 2000 took 0.075s
  training loss:		0.034131
  validation loss:		0.249589
  validation accuracy:		93.59 %
Epoch 683 of 2000 took 0.077s
  training loss:		0.033423
  validation loss:		0.260381
  validation accuracy:		93.70 %
Epoch 684 of 2000 took 0.074s
  training loss:		0.033412
  validation loss:		0.260536
  validation accuracy:		93.37 %
Epoch 685 of 2000 took 0.077s
  training loss:		0.033964
  validation loss:		0.250714
  validation accuracy:		94.02 %
Epoch 686 of 2000 took 0.078s
  training loss:		0.032715
  validation loss:		0.244924
  validation accuracy:		94.02 %
Epoch 687 of 2000 took 0.075s
  training loss:		0.032228
  validation loss:		0.255796
  validation accuracy:		93.80 %
Epoch 688 of 2000 took 0.077s
  training loss:		0.031627
  validation loss:		0.261872
  validation accuracy:		93.37 %
Epoch 689 of 2000 took 0.077s
  training loss:		0.033031
  validation loss:		0.256920
  validation accuracy:		93.48 %
Epoch 690 of 2000 took 0.075s
  training loss:		0.031163
  validation loss:		0.254723
  validation accuracy:		93.91 %
Epoch 691 of 2000 took 0.077s
  training loss:		0.032369
  validation loss:		0.248357
  validation accuracy:		94.02 %
Epoch 692 of 2000 took 0.076s
  training loss:		0.032829
  validation loss:		0.251136
  validation accuracy:		93.80 %
Epoch 693 of 2000 took 0.077s
  training loss:		0.032662
  validation loss:		0.247756
  validation accuracy:		93.80 %
Epoch 694 of 2000 took 0.076s
  training loss:		0.031705
  validation loss:		0.244955
  validation accuracy:		93.91 %
Epoch 695 of 2000 took 0.078s
  training loss:		0.031784
  validation loss:		0.263101
  validation accuracy:		94.02 %
Epoch 696 of 2000 took 0.078s
  training loss:		0.031518
  validation loss:		0.258373
  validation accuracy:		93.91 %
Epoch 697 of 2000 took 0.078s
  training loss:		0.032825
  validation loss:		0.261660
  validation accuracy:		93.59 %
Epoch 698 of 2000 took 0.079s
  training loss:		0.031454
  validation loss:		0.247743
  validation accuracy:		94.02 %
Epoch 699 of 2000 took 0.078s
  training loss:		0.031804
  validation loss:		0.243617
  validation accuracy:		94.02 %
Epoch 700 of 2000 took 0.077s
  training loss:		0.031634
  validation loss:		0.254074
  validation accuracy:		93.59 %
Epoch 701 of 2000 took 0.077s
  training loss:		0.032063
  validation loss:		0.261909
  validation accuracy:		93.70 %
Epoch 702 of 2000 took 0.076s
  training loss:		0.032022
  validation loss:		0.254988
  validation accuracy:		93.48 %
Epoch 703 of 2000 took 0.077s
  training loss:		0.030993
  validation loss:		0.264056
  validation accuracy:		93.48 %
Epoch 704 of 2000 took 0.076s
  training loss:		0.031060
  validation loss:		0.248622
  validation accuracy:		93.91 %
Epoch 705 of 2000 took 0.076s
  training loss:		0.030829
  validation loss:		0.247624
  validation accuracy:		94.02 %
Epoch 706 of 2000 took 0.078s
  training loss:		0.031309
  validation loss:		0.256503
  validation accuracy:		93.59 %
Epoch 707 of 2000 took 0.077s
  training loss:		0.030259
  validation loss:		0.259794
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.077s
  training loss:		0.030112
  validation loss:		0.251280
  validation accuracy:		93.80 %
Epoch 709 of 2000 took 0.078s
  training loss:		0.031892
  validation loss:		0.253942
  validation accuracy:		93.80 %
Epoch 710 of 2000 took 0.077s
  training loss:		0.031798
  validation loss:		0.256899
  validation accuracy:		93.80 %
Epoch 711 of 2000 took 0.074s
  training loss:		0.030631
  validation loss:		0.250336
  validation accuracy:		93.91 %
Epoch 712 of 2000 took 0.076s
  training loss:		0.031476
  validation loss:		0.260461
  validation accuracy:		93.70 %
Epoch 713 of 2000 took 0.075s
  training loss:		0.030304
  validation loss:		0.257688
  validation accuracy:		94.13 %
Epoch 714 of 2000 took 0.073s
  training loss:		0.029871
  validation loss:		0.248138
  validation accuracy:		93.91 %
Epoch 715 of 2000 took 0.076s
  training loss:		0.029563
  validation loss:		0.253266
  validation accuracy:		93.91 %
Epoch 716 of 2000 took 0.076s
  training loss:		0.030522
  validation loss:		0.265554
  validation accuracy:		93.48 %
Epoch 717 of 2000 took 0.073s
  training loss:		0.030702
  validation loss:		0.270407
  validation accuracy:		93.37 %
Epoch 718 of 2000 took 0.077s
  training loss:		0.030095
  validation loss:		0.261212
  validation accuracy:		93.26 %
Epoch 719 of 2000 took 0.075s
  training loss:		0.030093
  validation loss:		0.256922
  validation accuracy:		93.70 %
Epoch 720 of 2000 took 0.078s
  training loss:		0.029398
  validation loss:		0.264854
  validation accuracy:		93.59 %
Epoch 721 of 2000 took 0.077s
  training loss:		0.030102
  validation loss:		0.265107
  validation accuracy:		93.59 %
Epoch 722 of 2000 took 0.076s
  training loss:		0.029937
  validation loss:		0.268509
  validation accuracy:		93.70 %
Epoch 723 of 2000 took 0.076s
  training loss:		0.028981
  validation loss:		0.256167
  validation accuracy:		93.59 %
Epoch 724 of 2000 took 0.076s
  training loss:		0.029088
  validation loss:		0.249099
  validation accuracy:		94.02 %
Epoch 725 of 2000 took 0.076s
  training loss:		0.029457
  validation loss:		0.262166
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.076s
  training loss:		0.029324
  validation loss:		0.264081
  validation accuracy:		93.80 %
Epoch 727 of 2000 took 0.074s
  training loss:		0.029668
  validation loss:		0.260953
  validation accuracy:		93.91 %
Epoch 728 of 2000 took 0.076s
  training loss:		0.029905
  validation loss:		0.273038
  validation accuracy:		93.59 %
Epoch 729 of 2000 took 0.078s
  training loss:		0.029957
  validation loss:		0.278020
  validation accuracy:		93.59 %
Epoch 730 of 2000 took 0.076s
  training loss:		0.029212
  validation loss:		0.259133
  validation accuracy:		93.80 %
Epoch 731 of 2000 took 0.079s
  training loss:		0.029810
  validation loss:		0.259607
  validation accuracy:		94.13 %
Epoch 732 of 2000 took 0.077s
  training loss:		0.029841
  validation loss:		0.265832
  validation accuracy:		93.70 %
Epoch 733 of 2000 took 0.079s
  training loss:		0.029103
  validation loss:		0.258286
  validation accuracy:		93.80 %
Epoch 734 of 2000 took 0.076s
  training loss:		0.029896
  validation loss:		0.265230
  validation accuracy:		93.48 %
Epoch 735 of 2000 took 0.077s
  training loss:		0.028510
  validation loss:		0.261600
  validation accuracy:		93.80 %
Epoch 736 of 2000 took 0.076s
  training loss:		0.029030
  validation loss:		0.256484
  validation accuracy:		93.70 %
Epoch 737 of 2000 took 0.080s
  training loss:		0.029346
  validation loss:		0.255590
  validation accuracy:		93.91 %
Epoch 738 of 2000 took 0.078s
  training loss:		0.028821
  validation loss:		0.262525
  validation accuracy:		93.59 %
Epoch 739 of 2000 took 0.078s
  training loss:		0.028881
  validation loss:		0.265905
  validation accuracy:		93.70 %
Epoch 740 of 2000 took 0.077s
  training loss:		0.028582
  validation loss:		0.258860
  validation accuracy:		94.02 %
Epoch 741 of 2000 took 0.075s
  training loss:		0.027530
  validation loss:		0.270499
  validation accuracy:		93.48 %
Epoch 742 of 2000 took 0.076s
  training loss:		0.028305
  validation loss:		0.266784
  validation accuracy:		93.59 %
Epoch 743 of 2000 took 0.078s
  training loss:		0.028618
  validation loss:		0.274164
  validation accuracy:		93.70 %
Epoch 744 of 2000 took 0.076s
  training loss:		0.027568
  validation loss:		0.266390
  validation accuracy:		93.80 %
Epoch 745 of 2000 took 0.076s
  training loss:		0.028715
  validation loss:		0.261007
  validation accuracy:		93.80 %
Epoch 746 of 2000 took 0.077s
  training loss:		0.027935
  validation loss:		0.260382
  validation accuracy:		94.02 %
Epoch 747 of 2000 took 0.078s
  training loss:		0.028670
  validation loss:		0.266247
  validation accuracy:		93.59 %
Epoch 748 of 2000 took 0.077s
  training loss:		0.027802
  validation loss:		0.275209
  validation accuracy:		93.59 %
Epoch 749 of 2000 took 0.076s
  training loss:		0.027287
  validation loss:		0.270311
  validation accuracy:		93.48 %
Epoch 750 of 2000 took 0.075s
  training loss:		0.026673
  validation loss:		0.270896
  validation accuracy:		93.59 %
Epoch 751 of 2000 took 0.075s
  training loss:		0.027789
  validation loss:		0.268214
  validation accuracy:		93.80 %
Epoch 752 of 2000 took 0.079s
  training loss:		0.027673
  validation loss:		0.264949
  validation accuracy:		93.91 %
Epoch 753 of 2000 took 0.078s
  training loss:		0.025570
  validation loss:		0.266564
  validation accuracy:		93.80 %
Epoch 754 of 2000 took 0.077s
  training loss:		0.027547
  validation loss:		0.270964
  validation accuracy:		93.48 %
Epoch 755 of 2000 took 0.078s
  training loss:		0.027312
  validation loss:		0.278674
  validation accuracy:		93.70 %
Epoch 756 of 2000 took 0.076s
  training loss:		0.027257
  validation loss:		0.263700
  validation accuracy:		93.91 %
Epoch 757 of 2000 took 0.075s
  training loss:		0.027148
  validation loss:		0.278581
  validation accuracy:		93.37 %
Epoch 758 of 2000 took 0.076s
  training loss:		0.027119
  validation loss:		0.270925
  validation accuracy:		93.80 %
Epoch 759 of 2000 took 0.077s
  training loss:		0.027371
  validation loss:		0.271846
  validation accuracy:		93.70 %
Epoch 760 of 2000 took 0.077s
  training loss:		0.027353
  validation loss:		0.271618
  validation accuracy:		93.59 %
Epoch 761 of 2000 took 0.077s
  training loss:		0.026607
  validation loss:		0.271230
  validation accuracy:		94.13 %
Epoch 762 of 2000 took 0.077s
  training loss:		0.026668
  validation loss:		0.271885
  validation accuracy:		93.48 %
Epoch 763 of 2000 took 0.077s
  training loss:		0.027785
  validation loss:		0.270007
  validation accuracy:		93.80 %
Epoch 764 of 2000 took 0.074s
  training loss:		0.026376
  validation loss:		0.271904
  validation accuracy:		93.59 %
Epoch 765 of 2000 took 0.078s
  training loss:		0.026480
  validation loss:		0.268041
  validation accuracy:		93.91 %
Epoch 766 of 2000 took 0.076s
  training loss:		0.026541
  validation loss:		0.281827
  validation accuracy:		93.48 %
Epoch 767 of 2000 took 0.074s
  training loss:		0.026964
  validation loss:		0.273711
  validation accuracy:		93.80 %
Epoch 768 of 2000 took 0.076s
  training loss:		0.025551
  validation loss:		0.274930
  validation accuracy:		93.59 %
Epoch 769 of 2000 took 0.075s
  training loss:		0.026749
  validation loss:		0.265936
  validation accuracy:		94.02 %
Epoch 770 of 2000 took 0.076s
  training loss:		0.025818
  validation loss:		0.270522
  validation accuracy:		93.80 %
Epoch 771 of 2000 took 0.076s
  training loss:		0.025969
  validation loss:		0.274338
  validation accuracy:		93.80 %
Epoch 772 of 2000 took 0.074s
  training loss:		0.025434
  validation loss:		0.275029
  validation accuracy:		93.59 %
Epoch 773 of 2000 took 0.075s
  training loss:		0.026112
  validation loss:		0.278350
  validation accuracy:		93.59 %
Epoch 774 of 2000 took 0.077s
  training loss:		0.025514
  validation loss:		0.270023
  validation accuracy:		93.48 %
Epoch 775 of 2000 took 0.075s
  training loss:		0.025754
  validation loss:		0.270492
  validation accuracy:		93.91 %
Epoch 776 of 2000 took 0.076s
  training loss:		0.025487
  validation loss:		0.277034
  validation accuracy:		93.37 %
Epoch 777 of 2000 took 0.076s
  training loss:		0.025010
  validation loss:		0.268457
  validation accuracy:		93.80 %
Epoch 778 of 2000 took 0.074s
  training loss:		0.026009
  validation loss:		0.271748
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.075s
  training loss:		0.024869
  validation loss:		0.281158
  validation accuracy:		93.59 %
Epoch 780 of 2000 took 0.078s
  training loss:		0.025526
  validation loss:		0.280366
  validation accuracy:		93.26 %
Epoch 781 of 2000 took 0.075s
  training loss:		0.025563
  validation loss:		0.282555
  validation accuracy:		93.48 %
Epoch 782 of 2000 took 0.076s
  training loss:		0.025453
  validation loss:		0.265266
  validation accuracy:		93.70 %
Epoch 783 of 2000 took 0.077s
  training loss:		0.024867
  validation loss:		0.277472
  validation accuracy:		93.80 %
Epoch 784 of 2000 took 0.075s
  training loss:		0.024292
  validation loss:		0.278718
  validation accuracy:		93.48 %
Epoch 785 of 2000 took 0.079s
  training loss:		0.023401
  validation loss:		0.269245
  validation accuracy:		93.48 %
Epoch 786 of 2000 took 0.077s
  training loss:		0.024710
  validation loss:		0.274902
  validation accuracy:		93.48 %
Epoch 787 of 2000 took 0.073s
  training loss:		0.025481
  validation loss:		0.285943
  validation accuracy:		93.48 %
Epoch 788 of 2000 took 0.077s
  training loss:		0.025546
  validation loss:		0.278806
  validation accuracy:		93.80 %
Epoch 789 of 2000 took 0.078s
  training loss:		0.024549
  validation loss:		0.281043
  validation accuracy:		93.80 %
Epoch 790 of 2000 took 0.076s
  training loss:		0.025067
  validation loss:		0.279880
  validation accuracy:		93.70 %
Epoch 791 of 2000 took 0.079s
  training loss:		0.024929
  validation loss:		0.272181
  validation accuracy:		93.48 %
Epoch 792 of 2000 took 0.077s
  training loss:		0.025042
  validation loss:		0.273455
  validation accuracy:		93.80 %
Epoch 793 of 2000 took 0.076s
  training loss:		0.024386
  validation loss:		0.278932
  validation accuracy:		93.59 %
Epoch 794 of 2000 took 0.075s
  training loss:		0.024778
  validation loss:		0.279201
  validation accuracy:		93.91 %
Epoch 795 of 2000 took 0.076s
  training loss:		0.024692
  validation loss:		0.278135
  validation accuracy:		94.02 %
Epoch 796 of 2000 took 0.076s
  training loss:		0.024397
  validation loss:		0.274958
  validation accuracy:		93.70 %
Epoch 797 of 2000 took 0.077s
  training loss:		0.024415
  validation loss:		0.282290
  validation accuracy:		93.48 %
Epoch 798 of 2000 took 0.077s
  training loss:		0.024568
  validation loss:		0.272537
  validation accuracy:		93.70 %
Epoch 799 of 2000 took 0.075s
  training loss:		0.025166
  validation loss:		0.279875
  validation accuracy:		93.70 %
Epoch 800 of 2000 took 0.075s
  training loss:		0.023259
  validation loss:		0.280510
  validation accuracy:		93.70 %
Epoch 801 of 2000 took 0.077s
  training loss:		0.023595
  validation loss:		0.277055
  validation accuracy:		93.59 %
Epoch 802 of 2000 took 0.076s
  training loss:		0.024137
  validation loss:		0.283562
  validation accuracy:		93.70 %
Epoch 803 of 2000 took 0.076s
  training loss:		0.023728
  validation loss:		0.277121
  validation accuracy:		93.80 %
Epoch 804 of 2000 took 0.074s
  training loss:		0.023506
  validation loss:		0.290382
  validation accuracy:		93.70 %
Epoch 805 of 2000 took 0.078s
  training loss:		0.024487
  validation loss:		0.282574
  validation accuracy:		93.59 %
Epoch 806 of 2000 took 0.077s
  training loss:		0.023560
  validation loss:		0.273260
  validation accuracy:		93.59 %
Epoch 807 of 2000 took 0.074s
  training loss:		0.024130
  validation loss:		0.277126
  validation accuracy:		93.91 %
Epoch 808 of 2000 took 0.074s
  training loss:		0.023839
  validation loss:		0.300117
  validation accuracy:		93.26 %
Epoch 809 of 2000 took 0.076s
  training loss:		0.024422
  validation loss:		0.286041
  validation accuracy:		93.26 %
Epoch 810 of 2000 took 0.078s
  training loss:		0.022454
  validation loss:		0.283653
  validation accuracy:		93.70 %
Epoch 811 of 2000 took 0.075s
  training loss:		0.023381
  validation loss:		0.279723
  validation accuracy:		93.80 %
Epoch 812 of 2000 took 0.074s
  training loss:		0.023141
  validation loss:		0.283110
  validation accuracy:		93.59 %
Epoch 813 of 2000 took 0.078s
  training loss:		0.023182
  validation loss:		0.272958
  validation accuracy:		94.02 %
Epoch 814 of 2000 took 0.077s
  training loss:		0.023267
  validation loss:		0.289255
  validation accuracy:		93.37 %
Epoch 815 of 2000 took 0.075s
  training loss:		0.023264
  validation loss:		0.285867
  validation accuracy:		93.37 %
Epoch 816 of 2000 took 0.074s
  training loss:		0.023075
  validation loss:		0.286886
  validation accuracy:		93.15 %
Epoch 817 of 2000 took 0.075s
  training loss:		0.024056
  validation loss:		0.279885
  validation accuracy:		93.70 %
Epoch 818 of 2000 took 0.079s
  training loss:		0.023355
  validation loss:		0.277765
  validation accuracy:		93.80 %
Epoch 819 of 2000 took 0.075s
  training loss:		0.023193
  validation loss:		0.286835
  validation accuracy:		93.37 %
Epoch 820 of 2000 took 0.077s
  training loss:		0.024220
  validation loss:		0.278348
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.076s
  training loss:		0.022838
  validation loss:		0.288279
  validation accuracy:		93.59 %
Epoch 822 of 2000 took 0.077s
  training loss:		0.022609
  validation loss:		0.287810
  validation accuracy:		93.59 %
Epoch 823 of 2000 took 0.079s
  training loss:		0.022618
  validation loss:		0.278136
  validation accuracy:		94.02 %
Epoch 824 of 2000 took 0.075s
  training loss:		0.023459
  validation loss:		0.286520
  validation accuracy:		93.37 %
Epoch 825 of 2000 took 0.075s
  training loss:		0.022806
  validation loss:		0.283501
  validation accuracy:		93.37 %
Epoch 826 of 2000 took 0.076s
  training loss:		0.023055
  validation loss:		0.285718
  validation accuracy:		93.48 %
Epoch 827 of 2000 took 0.076s
  training loss:		0.022860
  validation loss:		0.295611
  validation accuracy:		93.04 %
Epoch 828 of 2000 took 0.075s
  training loss:		0.022988
  validation loss:		0.282418
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.077s
  training loss:		0.022834
  validation loss:		0.292806
  validation accuracy:		93.04 %
Epoch 830 of 2000 took 0.076s
  training loss:		0.023098
  validation loss:		0.287635
  validation accuracy:		93.59 %
Epoch 831 of 2000 took 0.076s
  training loss:		0.021817
  validation loss:		0.286157
  validation accuracy:		93.70 %
Epoch 832 of 2000 took 0.075s
  training loss:		0.021442
  validation loss:		0.282228
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.075s
  training loss:		0.022657
  validation loss:		0.287596
  validation accuracy:		93.59 %
Epoch 834 of 2000 took 0.076s
  training loss:		0.021956
  validation loss:		0.289977
  validation accuracy:		93.59 %
Epoch 835 of 2000 took 0.077s
  training loss:		0.021780
  validation loss:		0.279809
  validation accuracy:		93.80 %
Epoch 836 of 2000 took 0.075s
  training loss:		0.022252
  validation loss:		0.282849
  validation accuracy:		93.70 %
Epoch 837 of 2000 took 0.075s
  training loss:		0.022072
  validation loss:		0.285537
  validation accuracy:		93.37 %
Epoch 838 of 2000 took 0.081s
  training loss:		0.022270
  validation loss:		0.282259
  validation accuracy:		93.70 %
Epoch 839 of 2000 took 0.076s
  training loss:		0.021928
  validation loss:		0.277216
  validation accuracy:		93.91 %
Epoch 840 of 2000 took 0.078s
  training loss:		0.020939
  validation loss:		0.278933
  validation accuracy:		93.91 %
Epoch 841 of 2000 took 0.078s
  training loss:		0.021052
  validation loss:		0.291158
  validation accuracy:		93.26 %
Epoch 842 of 2000 took 0.077s
  training loss:		0.021831
  validation loss:		0.285833
  validation accuracy:		94.02 %
Epoch 843 of 2000 took 0.074s
  training loss:		0.022634
  validation loss:		0.294569
  validation accuracy:		93.48 %
Epoch 844 of 2000 took 0.075s
  training loss:		0.022395
  validation loss:		0.291473
  validation accuracy:		93.26 %
Epoch 845 of 2000 took 0.077s
  training loss:		0.021577
  validation loss:		0.289579
  validation accuracy:		93.37 %
Epoch 846 of 2000 took 0.076s
  training loss:		0.021562
  validation loss:		0.287338
  validation accuracy:		93.48 %
Epoch 847 of 2000 took 0.078s
  training loss:		0.020948
  validation loss:		0.279336
  validation accuracy:		93.59 %
Epoch 848 of 2000 took 0.078s
  training loss:		0.022174
  validation loss:		0.294517
  validation accuracy:		93.26 %
Epoch 849 of 2000 took 0.075s
  training loss:		0.021578
  validation loss:		0.287200
  validation accuracy:		93.80 %
Epoch 850 of 2000 took 0.076s
  training loss:		0.021325
  validation loss:		0.283729
  validation accuracy:		93.59 %
Epoch 851 of 2000 took 0.077s
  training loss:		0.021893
  validation loss:		0.289140
  validation accuracy:		93.80 %
Epoch 852 of 2000 took 0.078s
  training loss:		0.021344
  validation loss:		0.288879
  validation accuracy:		93.48 %
Epoch 853 of 2000 took 0.078s
  training loss:		0.020729
  validation loss:		0.296242
  validation accuracy:		93.91 %
Epoch 854 of 2000 took 0.078s
  training loss:		0.020751
  validation loss:		0.298594
  validation accuracy:		93.48 %
Epoch 855 of 2000 took 0.077s
  training loss:		0.021555
  validation loss:		0.291944
  validation accuracy:		93.37 %
Epoch 856 of 2000 took 0.074s
  training loss:		0.020645
  validation loss:		0.293301
  validation accuracy:		93.48 %
Epoch 857 of 2000 took 0.078s
  training loss:		0.020646
  validation loss:		0.293599
  validation accuracy:		93.48 %
Epoch 858 of 2000 took 0.079s
  training loss:		0.020796
  validation loss:		0.294713
  validation accuracy:		93.48 %
Epoch 859 of 2000 took 0.077s
  training loss:		0.021245
  validation loss:		0.297713
  validation accuracy:		93.26 %
Epoch 860 of 2000 took 0.078s
  training loss:		0.020036
  validation loss:		0.298955
  validation accuracy:		93.48 %
Epoch 861 of 2000 took 0.076s
  training loss:		0.020676
  validation loss:		0.290025
  validation accuracy:		93.48 %
Epoch 862 of 2000 took 0.076s
  training loss:		0.020934
  validation loss:		0.302233
  validation accuracy:		93.15 %
Epoch 863 of 2000 took 0.076s
  training loss:		0.021067
  validation loss:		0.290465
  validation accuracy:		93.70 %
Epoch 864 of 2000 took 0.077s
  training loss:		0.020104
  validation loss:		0.291456
  validation accuracy:		93.48 %
Epoch 865 of 2000 took 0.078s
  training loss:		0.020063
  validation loss:		0.294839
  validation accuracy:		93.48 %
Epoch 866 of 2000 took 0.077s
  training loss:		0.020367
  validation loss:		0.289950
  validation accuracy:		93.70 %
Epoch 867 of 2000 took 0.078s
  training loss:		0.020477
  validation loss:		0.285627
  validation accuracy:		93.80 %
Epoch 868 of 2000 took 0.078s
  training loss:		0.020540
  validation loss:		0.295018
  validation accuracy:		93.80 %
Epoch 869 of 2000 took 0.075s
  training loss:		0.020708
  validation loss:		0.299390
  validation accuracy:		93.26 %
Epoch 870 of 2000 took 0.077s
  training loss:		0.020442
  validation loss:		0.304816
  validation accuracy:		93.37 %
Epoch 871 of 2000 took 0.080s
  training loss:		0.020173
  validation loss:		0.289028
  validation accuracy:		93.59 %
Epoch 872 of 2000 took 0.079s
  training loss:		0.020320
  validation loss:		0.293932
  validation accuracy:		93.59 %
Epoch 873 of 2000 took 0.078s
  training loss:		0.020260
  validation loss:		0.291225
  validation accuracy:		93.59 %
Epoch 874 of 2000 took 0.075s
  training loss:		0.020414
  validation loss:		0.283840
  validation accuracy:		93.70 %
Epoch 875 of 2000 took 0.074s
  training loss:		0.019805
  validation loss:		0.295104
  validation accuracy:		93.59 %
Epoch 876 of 2000 took 0.079s
  training loss:		0.019973
  validation loss:		0.299269
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.079s
  training loss:		0.019990
  validation loss:		0.297100
  validation accuracy:		93.70 %
Epoch 878 of 2000 took 0.080s
  training loss:		0.020060
  validation loss:		0.293104
  validation accuracy:		94.02 %
Epoch 879 of 2000 took 0.078s
  training loss:		0.020032
  validation loss:		0.306677
  validation accuracy:		93.37 %
Epoch 880 of 2000 took 0.075s
  training loss:		0.020214
  validation loss:		0.298314
  validation accuracy:		93.80 %
Epoch 881 of 2000 took 0.078s
  training loss:		0.019593
  validation loss:		0.304898
  validation accuracy:		93.26 %
Epoch 882 of 2000 took 0.076s
  training loss:		0.019739
  validation loss:		0.289290
  validation accuracy:		93.59 %
Epoch 883 of 2000 took 0.079s
  training loss:		0.019279
  validation loss:		0.308525
  validation accuracy:		93.37 %
Epoch 884 of 2000 took 0.080s
  training loss:		0.019257
  validation loss:		0.299202
  validation accuracy:		93.37 %
Epoch 885 of 2000 took 0.077s
  training loss:		0.018426
  validation loss:		0.297502
  validation accuracy:		93.48 %
Epoch 886 of 2000 took 0.077s
  training loss:		0.019617
  validation loss:		0.302792
  validation accuracy:		93.26 %
Epoch 887 of 2000 took 0.076s
  training loss:		0.019542
  validation loss:		0.308370
  validation accuracy:		93.59 %
Epoch 888 of 2000 took 0.078s
  training loss:		0.020317
  validation loss:		0.308685
  validation accuracy:		93.15 %
Epoch 889 of 2000 took 0.077s
  training loss:		0.018411
  validation loss:		0.297017
  validation accuracy:		93.59 %
Epoch 890 of 2000 took 0.077s
  training loss:		0.018904
  validation loss:		0.303022
  validation accuracy:		93.37 %
Epoch 891 of 2000 took 0.079s
  training loss:		0.019531
  validation loss:		0.296104
  validation accuracy:		93.48 %
Epoch 892 of 2000 took 0.077s
  training loss:		0.018966
  validation loss:		0.304109
  validation accuracy:		93.59 %
Epoch 893 of 2000 took 0.078s
  training loss:		0.019561
  validation loss:		0.307035
  validation accuracy:		93.37 %
Epoch 894 of 2000 took 0.079s
  training loss:		0.020006
  validation loss:		0.298723
  validation accuracy:		93.70 %
Epoch 895 of 2000 took 0.075s
  training loss:		0.018770
  validation loss:		0.305897
  validation accuracy:		93.26 %
Epoch 896 of 2000 took 0.077s
  training loss:		0.019852
  validation loss:		0.299316
  validation accuracy:		93.70 %
Epoch 897 of 2000 took 0.079s
  training loss:		0.018980
  validation loss:		0.303590
  validation accuracy:		93.70 %
Epoch 898 of 2000 took 0.076s
  training loss:		0.019291
  validation loss:		0.310602
  validation accuracy:		93.37 %
Epoch 899 of 2000 took 0.077s
  training loss:		0.019242
  validation loss:		0.301234
  validation accuracy:		93.70 %
Epoch 900 of 2000 took 0.077s
  training loss:		0.019279
  validation loss:		0.303118
  validation accuracy:		93.59 %
Epoch 901 of 2000 took 0.074s
  training loss:		0.018784
  validation loss:		0.293796
  validation accuracy:		93.59 %
Epoch 902 of 2000 took 0.077s
  training loss:		0.019271
  validation loss:		0.303299
  validation accuracy:		93.48 %
Epoch 903 of 2000 took 0.078s
  training loss:		0.017748
  validation loss:		0.305361
  validation accuracy:		93.70 %
Epoch 904 of 2000 took 0.076s
  training loss:		0.019617
  validation loss:		0.302121
  validation accuracy:		93.59 %
Epoch 905 of 2000 took 0.077s
  training loss:		0.018392
  validation loss:		0.309354
  validation accuracy:		93.26 %
Epoch 906 of 2000 took 0.078s
  training loss:		0.018076
  validation loss:		0.296204
  validation accuracy:		93.80 %
Epoch 907 of 2000 took 0.079s
  training loss:		0.018760
  validation loss:		0.306224
  validation accuracy:		93.59 %
Epoch 908 of 2000 took 0.076s
  training loss:		0.018754
  validation loss:		0.310426
  validation accuracy:		93.26 %
Epoch 909 of 2000 took 0.077s
  training loss:		0.018959
  validation loss:		0.304166
  validation accuracy:		93.48 %
Epoch 910 of 2000 took 0.078s
  training loss:		0.017188
  validation loss:		0.302311
  validation accuracy:		93.80 %
Epoch 911 of 2000 took 0.078s
  training loss:		0.017978
  validation loss:		0.303220
  validation accuracy:		93.70 %
Epoch 912 of 2000 took 0.076s
  training loss:		0.018330
  validation loss:		0.304380
  validation accuracy:		93.70 %
Epoch 913 of 2000 took 0.079s
  training loss:		0.018109
  validation loss:		0.307017
  validation accuracy:		93.37 %
Epoch 914 of 2000 took 0.077s
  training loss:		0.018370
  validation loss:		0.306165
  validation accuracy:		93.48 %
Epoch 915 of 2000 took 0.077s
  training loss:		0.018294
  validation loss:		0.308245
  validation accuracy:		93.59 %
Epoch 916 of 2000 took 0.077s
  training loss:		0.018029
  validation loss:		0.300899
  validation accuracy:		93.70 %
Epoch 917 of 2000 took 0.077s
  training loss:		0.017823
  validation loss:		0.308204
  validation accuracy:		93.26 %
Epoch 918 of 2000 took 0.075s
  training loss:		0.017966
  validation loss:		0.305172
  validation accuracy:		93.37 %
Epoch 919 of 2000 took 0.080s
  training loss:		0.017788
  validation loss:		0.308089
  validation accuracy:		93.48 %
Epoch 920 of 2000 took 0.076s
  training loss:		0.018168
  validation loss:		0.298174
  validation accuracy:		93.70 %
Epoch 921 of 2000 took 0.077s
  training loss:		0.018356
  validation loss:		0.304216
  validation accuracy:		93.48 %
Epoch 922 of 2000 took 0.078s
  training loss:		0.018013
  validation loss:		0.305033
  validation accuracy:		93.59 %
Epoch 923 of 2000 took 0.077s
  training loss:		0.016998
  validation loss:		0.303602
  validation accuracy:		93.59 %
Epoch 924 of 2000 took 0.079s
  training loss:		0.018072
  validation loss:		0.314145
  validation accuracy:		93.48 %
Epoch 925 of 2000 took 0.078s
  training loss:		0.017988
  validation loss:		0.308922
  validation accuracy:		93.37 %
Epoch 926 of 2000 took 0.079s
  training loss:		0.017769
  validation loss:		0.300238
  validation accuracy:		93.70 %
Epoch 927 of 2000 took 0.077s
  training loss:		0.017874
  validation loss:		0.308120
  validation accuracy:		93.80 %
Epoch 928 of 2000 took 0.075s
  training loss:		0.018043
  validation loss:		0.302691
  validation accuracy:		93.70 %
Epoch 929 of 2000 took 0.076s
  training loss:		0.017364
  validation loss:		0.310962
  validation accuracy:		93.59 %
Epoch 930 of 2000 took 0.076s
  training loss:		0.017774
  validation loss:		0.306237
  validation accuracy:		93.59 %
Epoch 931 of 2000 took 0.077s
  training loss:		0.017383
  validation loss:		0.301165
  validation accuracy:		93.80 %
Epoch 932 of 2000 took 0.076s
  training loss:		0.017673
  validation loss:		0.313689
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.078s
  training loss:		0.017679
  validation loss:		0.317866
  validation accuracy:		93.26 %
Epoch 934 of 2000 took 0.076s
  training loss:		0.017084
  validation loss:		0.315261
  validation accuracy:		93.37 %
Epoch 935 of 2000 took 0.078s
  training loss:		0.017242
  validation loss:		0.316079
  validation accuracy:		93.48 %
Epoch 936 of 2000 took 0.077s
  training loss:		0.017693
  validation loss:		0.304065
  validation accuracy:		93.70 %
Epoch 937 of 2000 took 0.079s
  training loss:		0.017548
  validation loss:		0.310624
  validation accuracy:		93.70 %
Epoch 938 of 2000 took 0.077s
  training loss:		0.017341
  validation loss:		0.309574
  validation accuracy:		93.59 %
Epoch 939 of 2000 took 0.077s
  training loss:		0.017281
  validation loss:		0.304397
  validation accuracy:		93.80 %
Epoch 940 of 2000 took 0.077s
  training loss:		0.017238
  validation loss:		0.309501
  validation accuracy:		93.70 %
Epoch 941 of 2000 took 0.076s
  training loss:		0.017208
  validation loss:		0.327089
  validation accuracy:		93.37 %
Epoch 942 of 2000 took 0.076s
  training loss:		0.017031
  validation loss:		0.318652
  validation accuracy:		93.59 %
Epoch 943 of 2000 took 0.077s
  training loss:		0.017127
  validation loss:		0.303604
  validation accuracy:		93.59 %
Epoch 944 of 2000 took 0.078s
  training loss:		0.016878
  validation loss:		0.327269
  validation accuracy:		93.04 %
Epoch 945 of 2000 took 0.074s
  training loss:		0.017369
  validation loss:		0.318201
  validation accuracy:		93.48 %
Epoch 946 of 2000 took 0.075s
  training loss:		0.016771
  validation loss:		0.316216
  validation accuracy:		93.59 %
Epoch 947 of 2000 took 0.078s
  training loss:		0.016657
  validation loss:		0.310626
  validation accuracy:		93.80 %
Epoch 948 of 2000 took 0.078s
  training loss:		0.017336
  validation loss:		0.308880
  validation accuracy:		93.70 %
Epoch 949 of 2000 took 0.077s
  training loss:		0.016469
  validation loss:		0.306962
  validation accuracy:		93.91 %
Epoch 950 of 2000 took 0.075s
  training loss:		0.016585
  validation loss:		0.324054
  validation accuracy:		93.15 %
Epoch 951 of 2000 took 0.074s
  training loss:		0.016678
  validation loss:		0.303563
  validation accuracy:		93.70 %
Epoch 952 of 2000 took 0.077s
  training loss:		0.016762
  validation loss:		0.317986
  validation accuracy:		93.37 %
Epoch 953 of 2000 took 0.077s
  training loss:		0.016751
  validation loss:		0.320307
  validation accuracy:		93.70 %
Epoch 954 of 2000 took 0.079s
  training loss:		0.017254
  validation loss:		0.320089
  validation accuracy:		93.26 %
Epoch 955 of 2000 took 0.076s
  training loss:		0.016885
  validation loss:		0.319207
  validation accuracy:		93.26 %
Epoch 956 of 2000 took 0.073s
  training loss:		0.015886
  validation loss:		0.317669
  validation accuracy:		93.59 %
Epoch 957 of 2000 took 0.075s
  training loss:		0.016535
  validation loss:		0.320967
  validation accuracy:		93.59 %
Epoch 958 of 2000 took 0.078s
  training loss:		0.015683
  validation loss:		0.314128
  validation accuracy:		93.70 %
Epoch 959 of 2000 took 0.076s
  training loss:		0.016003
  validation loss:		0.323435
  validation accuracy:		93.59 %
Epoch 960 of 2000 took 0.075s
  training loss:		0.015984
  validation loss:		0.317624
  validation accuracy:		93.48 %
Epoch 961 of 2000 took 0.077s
  training loss:		0.015939
  validation loss:		0.311414
  validation accuracy:		93.80 %
Epoch 962 of 2000 took 0.075s
  training loss:		0.016420
  validation loss:		0.327718
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.075s
  training loss:		0.016243
  validation loss:		0.309505
  validation accuracy:		93.70 %
Epoch 964 of 2000 took 0.075s
  training loss:		0.016214
  validation loss:		0.318439
  validation accuracy:		93.59 %
Epoch 965 of 2000 took 0.080s
  training loss:		0.016454
  validation loss:		0.314985
  validation accuracy:		93.48 %
Epoch 966 of 2000 took 0.075s
  training loss:		0.015627
  validation loss:		0.316131
  validation accuracy:		93.70 %
Epoch 967 of 2000 took 0.076s
  training loss:		0.016560
  validation loss:		0.320190
  validation accuracy:		93.37 %
Epoch 968 of 2000 took 0.079s
  training loss:		0.016271
  validation loss:		0.319616
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.078s
  training loss:		0.015968
  validation loss:		0.316172
  validation accuracy:		93.70 %
Epoch 970 of 2000 took 0.078s
  training loss:		0.016359
  validation loss:		0.317577
  validation accuracy:		93.70 %
Epoch 971 of 2000 took 0.075s
  training loss:		0.015426
  validation loss:		0.313544
  validation accuracy:		93.48 %
Epoch 972 of 2000 took 0.078s
  training loss:		0.016239
  validation loss:		0.317022
  validation accuracy:		93.59 %
Epoch 973 of 2000 took 0.074s
  training loss:		0.015138
  validation loss:		0.319660
  validation accuracy:		93.48 %
Epoch 974 of 2000 took 0.075s
  training loss:		0.015951
  validation loss:		0.314427
  validation accuracy:		93.59 %
Epoch 975 of 2000 took 0.077s
  training loss:		0.015644
  validation loss:		0.316253
  validation accuracy:		93.59 %
Epoch 976 of 2000 took 0.078s
  training loss:		0.015915
  validation loss:		0.317768
  validation accuracy:		93.59 %
Epoch 977 of 2000 took 0.078s
  training loss:		0.015299
  validation loss:		0.321108
  validation accuracy:		93.70 %
Epoch 978 of 2000 took 0.079s
  training loss:		0.015880
  validation loss:		0.318479
  validation accuracy:		93.59 %
Epoch 979 of 2000 took 0.078s
  training loss:		0.015658
  validation loss:		0.325335
  validation accuracy:		93.48 %
Epoch 980 of 2000 took 0.077s
  training loss:		0.015160
  validation loss:		0.326256
  validation accuracy:		93.70 %
Epoch 981 of 2000 took 0.072s
  training loss:		0.015181
  validation loss:		0.317421
  validation accuracy:		93.91 %
Epoch 982 of 2000 took 0.078s
  training loss:		0.015714
  validation loss:		0.315610
  validation accuracy:		93.59 %
Epoch 983 of 2000 took 0.077s
  training loss:		0.015660
  validation loss:		0.316884
  validation accuracy:		93.59 %
Epoch 984 of 2000 took 0.078s
  training loss:		0.014315
  validation loss:		0.315136
  validation accuracy:		93.80 %
Epoch 985 of 2000 took 0.078s
  training loss:		0.015030
  validation loss:		0.323958
  validation accuracy:		93.59 %
Epoch 986 of 2000 took 0.078s
  training loss:		0.015584
  validation loss:		0.331331
  validation accuracy:		93.59 %
Epoch 987 of 2000 took 0.076s
  training loss:		0.015547
  validation loss:		0.319363
  validation accuracy:		93.59 %
Epoch 988 of 2000 took 0.075s
  training loss:		0.015791
  validation loss:		0.318921
  validation accuracy:		93.59 %
Epoch 989 of 2000 took 0.077s
  training loss:		0.015497
  validation loss:		0.328849
  validation accuracy:		93.48 %
Epoch 990 of 2000 took 0.076s
  training loss:		0.015128
  validation loss:		0.321245
  validation accuracy:		93.48 %
Epoch 991 of 2000 took 0.076s
  training loss:		0.015188
  validation loss:		0.317177
  validation accuracy:		93.48 %
Epoch 992 of 2000 took 0.074s
  training loss:		0.015208
  validation loss:		0.326462
  validation accuracy:		93.59 %
Epoch 993 of 2000 took 0.075s
  training loss:		0.015112
  validation loss:		0.321109
  validation accuracy:		93.59 %
Epoch 994 of 2000 took 0.075s
  training loss:		0.015112
  validation loss:		0.334020
  validation accuracy:		93.37 %
Epoch 995 of 2000 took 0.078s
  training loss:		0.015514
  validation loss:		0.327414
  validation accuracy:		93.59 %
Epoch 996 of 2000 took 0.077s
  training loss:		0.014560
  validation loss:		0.322269
  validation accuracy:		93.70 %
Epoch 997 of 2000 took 0.076s
  training loss:		0.015224
  validation loss:		0.328994
  validation accuracy:		93.59 %
Epoch 998 of 2000 took 0.074s
  training loss:		0.014680
  validation loss:		0.324570
  validation accuracy:		93.59 %
Epoch 999 of 2000 took 0.077s
  training loss:		0.014797
  validation loss:		0.323324
  validation accuracy:		93.70 %
Epoch 1000 of 2000 took 0.075s
  training loss:		0.014914
  validation loss:		0.320212
  validation accuracy:		93.59 %
Epoch 1001 of 2000 took 0.078s
  training loss:		0.015352
  validation loss:		0.323575
  validation accuracy:		93.59 %
Epoch 1002 of 2000 took 0.077s
  training loss:		0.014111
  validation loss:		0.325918
  validation accuracy:		93.59 %
Epoch 1003 of 2000 took 0.074s
  training loss:		0.014356
  validation loss:		0.320516
  validation accuracy:		93.70 %
Epoch 1004 of 2000 took 0.079s
  training loss:		0.014281
  validation loss:		0.337104
  validation accuracy:		93.37 %
Epoch 1005 of 2000 took 0.077s
  training loss:		0.014076
  validation loss:		0.317412
  validation accuracy:		93.80 %
Epoch 1006 of 2000 took 0.077s
  training loss:		0.014092
  validation loss:		0.333367
  validation accuracy:		93.37 %
Epoch 1007 of 2000 took 0.078s
  training loss:		0.014188
  validation loss:		0.325784
  validation accuracy:		93.59 %
Epoch 1008 of 2000 took 0.078s
  training loss:		0.014586
  validation loss:		0.327617
  validation accuracy:		93.59 %
Epoch 1009 of 2000 took 0.075s
  training loss:		0.014823
  validation loss:		0.326178
  validation accuracy:		93.59 %
Epoch 1010 of 2000 took 0.079s
  training loss:		0.014413
  validation loss:		0.324659
  validation accuracy:		93.70 %
Epoch 1011 of 2000 took 0.077s
  training loss:		0.014417
  validation loss:		0.327644
  validation accuracy:		93.70 %
Epoch 1012 of 2000 took 0.077s
  training loss:		0.014506
  validation loss:		0.325038
  validation accuracy:		93.70 %
Epoch 1013 of 2000 took 0.079s
  training loss:		0.014413
  validation loss:		0.331608
  validation accuracy:		93.70 %
Epoch 1014 of 2000 took 0.077s
  training loss:		0.014665
  validation loss:		0.330626
  validation accuracy:		93.48 %
Epoch 1015 of 2000 took 0.076s
  training loss:		0.014046
  validation loss:		0.317882
  validation accuracy:		93.48 %
Epoch 1016 of 2000 took 0.074s
  training loss:		0.015062
  validation loss:		0.324082
  validation accuracy:		93.48 %
Epoch 1017 of 2000 took 0.074s
  training loss:		0.014478
  validation loss:		0.330851
  validation accuracy:		93.48 %
Epoch 1018 of 2000 took 0.077s
  training loss:		0.014301
  validation loss:		0.331067
  validation accuracy:		93.59 %
Epoch 1019 of 2000 took 0.075s
  training loss:		0.014438
  validation loss:		0.329843
  validation accuracy:		93.70 %
Epoch 1020 of 2000 took 0.078s
  training loss:		0.013826
  validation loss:		0.334800
  validation accuracy:		93.37 %
Epoch 1021 of 2000 took 0.079s
  training loss:		0.013971
  validation loss:		0.321522
  validation accuracy:		93.59 %
Epoch 1022 of 2000 took 0.079s
  training loss:		0.014141
  validation loss:		0.334911
  validation accuracy:		93.59 %
Epoch 1023 of 2000 took 0.077s
  training loss:		0.014540
  validation loss:		0.327841
  validation accuracy:		93.70 %
Epoch 1024 of 2000 took 0.077s
  training loss:		0.013948
  validation loss:		0.336142
  validation accuracy:		93.48 %
Epoch 1025 of 2000 took 0.075s
  training loss:		0.013924
  validation loss:		0.331969
  validation accuracy:		93.59 %
Epoch 1026 of 2000 took 0.077s
  training loss:		0.014262
  validation loss:		0.334010
  validation accuracy:		93.59 %
Epoch 1027 of 2000 took 0.077s
  training loss:		0.014032
  validation loss:		0.329240
  validation accuracy:		93.59 %
Epoch 1028 of 2000 took 0.077s
  training loss:		0.013678
  validation loss:		0.325629
  validation accuracy:		93.70 %
Epoch 1029 of 2000 took 0.078s
  training loss:		0.014157
  validation loss:		0.333255
  validation accuracy:		93.59 %
Epoch 1030 of 2000 took 0.078s
  training loss:		0.013990
  validation loss:		0.339469
  validation accuracy:		93.48 %
Epoch 1031 of 2000 took 0.077s
  training loss:		0.013939
  validation loss:		0.328772
  validation accuracy:		93.59 %
Epoch 1032 of 2000 took 0.076s
  training loss:		0.013746
  validation loss:		0.324658
  validation accuracy:		93.59 %
Epoch 1033 of 2000 took 0.076s
  training loss:		0.014007
  validation loss:		0.327328
  validation accuracy:		93.70 %
Epoch 1034 of 2000 took 0.076s
  training loss:		0.013919
  validation loss:		0.335214
  validation accuracy:		93.59 %
Epoch 1035 of 2000 took 0.076s
  training loss:		0.013429
  validation loss:		0.331109
  validation accuracy:		93.59 %
Epoch 1036 of 2000 took 0.075s
  training loss:		0.013084
  validation loss:		0.337775
  validation accuracy:		93.48 %
Epoch 1037 of 2000 took 0.077s
  training loss:		0.013255
  validation loss:		0.333376
  validation accuracy:		93.59 %
Epoch 1038 of 2000 took 0.076s
  training loss:		0.013370
  validation loss:		0.331197
  validation accuracy:		93.59 %
Epoch 1039 of 2000 took 0.076s
  training loss:		0.013467
  validation loss:		0.333137
  validation accuracy:		93.70 %
Epoch 1040 of 2000 took 0.075s
  training loss:		0.013793
  validation loss:		0.329108
  validation accuracy:		93.70 %
Epoch 1041 of 2000 took 0.077s
  training loss:		0.012876
  validation loss:		0.336541
  validation accuracy:		93.48 %
Epoch 1042 of 2000 took 0.076s
  training loss:		0.012658
  validation loss:		0.327154
  validation accuracy:		93.70 %
Epoch 1043 of 2000 took 0.074s
  training loss:		0.013534
  validation loss:		0.326957
  validation accuracy:		93.59 %
Epoch 1044 of 2000 took 0.075s
  training loss:		0.013014
  validation loss:		0.334803
  validation accuracy:		93.59 %
Epoch 1045 of 2000 took 0.074s
  training loss:		0.012989
  validation loss:		0.330414
  validation accuracy:		93.80 %
Epoch 1046 of 2000 took 0.078s
  training loss:		0.013218
  validation loss:		0.334130
  validation accuracy:		93.59 %
Epoch 1047 of 2000 took 0.078s
  training loss:		0.013135
  validation loss:		0.336791
  validation accuracy:		93.59 %
Epoch 1048 of 2000 took 0.077s
  training loss:		0.013290
  validation loss:		0.339319
  validation accuracy:		93.59 %
Epoch 1049 of 2000 took 0.077s
  training loss:		0.012996
  validation loss:		0.339568
  validation accuracy:		93.59 %
Epoch 1050 of 2000 took 0.074s
  training loss:		0.013501
  validation loss:		0.341867
  validation accuracy:		93.48 %
Epoch 1051 of 2000 took 0.076s
  training loss:		0.013099
  validation loss:		0.337818
  validation accuracy:		93.59 %
Epoch 1052 of 2000 took 0.076s
  training loss:		0.013072
  validation loss:		0.336792
  validation accuracy:		93.70 %
Epoch 1053 of 2000 took 0.080s
  training loss:		0.013271
  validation loss:		0.337012
  validation accuracy:		93.59 %
Epoch 1054 of 2000 took 0.077s
  training loss:		0.012890
  validation loss:		0.331272
  validation accuracy:		93.70 %
Epoch 1055 of 2000 took 0.075s
  training loss:		0.013280
  validation loss:		0.330617
  validation accuracy:		93.70 %
Epoch 1056 of 2000 took 0.075s
  training loss:		0.012831
  validation loss:		0.334428
  validation accuracy:		93.70 %
Epoch 1057 of 2000 took 0.075s
  training loss:		0.013020
  validation loss:		0.339907
  validation accuracy:		93.59 %
Epoch 1058 of 2000 took 0.077s
  training loss:		0.012928
  validation loss:		0.339886
  validation accuracy:		93.59 %
Epoch 1059 of 2000 took 0.077s
  training loss:		0.012853
  validation loss:		0.346381
  validation accuracy:		93.37 %
Epoch 1060 of 2000 took 0.075s
  training loss:		0.012449
  validation loss:		0.326683
  validation accuracy:		93.70 %
Epoch 1061 of 2000 took 0.075s
  training loss:		0.012933
  validation loss:		0.337848
  validation accuracy:		93.70 %
Epoch 1062 of 2000 took 0.076s
  training loss:		0.012794
  validation loss:		0.345217
  validation accuracy:		93.70 %
Epoch 1063 of 2000 took 0.077s
  training loss:		0.012467
  validation loss:		0.330819
  validation accuracy:		93.70 %
Epoch 1064 of 2000 took 0.077s
  training loss:		0.012467
  validation loss:		0.336589
  validation accuracy:		93.59 %
Epoch 1065 of 2000 took 0.075s
  training loss:		0.012896
  validation loss:		0.338625
  validation accuracy:		93.59 %
Epoch 1066 of 2000 took 0.076s
  training loss:		0.012619
  validation loss:		0.332968
  validation accuracy:		93.70 %
Epoch 1067 of 2000 took 0.075s
  training loss:		0.012712
  validation loss:		0.340905
  validation accuracy:		93.59 %
Epoch 1068 of 2000 took 0.074s
  training loss:		0.012575
  validation loss:		0.332701
  validation accuracy:		93.70 %
Epoch 1069 of 2000 took 0.075s
  training loss:		0.012504
  validation loss:		0.335885
  validation accuracy:		93.59 %
Epoch 1070 of 2000 took 0.076s
  training loss:		0.013057
  validation loss:		0.341505
  validation accuracy:		93.59 %
Epoch 1071 of 2000 took 0.079s
  training loss:		0.012672
  validation loss:		0.335392
  validation accuracy:		93.59 %
Epoch 1072 of 2000 took 0.078s
  training loss:		0.012508
  validation loss:		0.343649
  validation accuracy:		93.70 %
Epoch 1073 of 2000 took 0.080s
  training loss:		0.012453
  validation loss:		0.338307
  validation accuracy:		93.59 %
Epoch 1074 of 2000 took 0.078s
  training loss:		0.012487
  validation loss:		0.342578
  validation accuracy:		93.59 %
Epoch 1075 of 2000 took 0.072s
  training loss:		0.012881
  validation loss:		0.338580
  validation accuracy:		93.80 %
Epoch 1076 of 2000 took 0.076s
  training loss:		0.012083
  validation loss:		0.341294
  validation accuracy:		93.70 %
Epoch 1077 of 2000 took 0.077s
  training loss:		0.012562
  validation loss:		0.337493
  validation accuracy:		93.80 %
Epoch 1078 of 2000 took 0.076s
  training loss:		0.012741
  validation loss:		0.336992
  validation accuracy:		93.70 %
Epoch 1079 of 2000 took 0.076s
  training loss:		0.012306
  validation loss:		0.340540
  validation accuracy:		93.59 %
Epoch 1080 of 2000 took 0.077s
  training loss:		0.012740
  validation loss:		0.340076
  validation accuracy:		93.59 %
Epoch 1081 of 2000 took 0.072s
  training loss:		0.012212
  validation loss:		0.346143
  validation accuracy:		93.70 %
Epoch 1082 of 2000 took 0.076s
  training loss:		0.012547
  validation loss:		0.343286
  validation accuracy:		93.59 %
Epoch 1083 of 2000 took 0.076s
  training loss:		0.012423
  validation loss:		0.343310
  validation accuracy:		93.26 %
Epoch 1084 of 2000 took 0.076s
  training loss:		0.012807
  validation loss:		0.342763
  validation accuracy:		93.59 %
Epoch 1085 of 2000 took 0.075s
  training loss:		0.011745
  validation loss:		0.335922
  validation accuracy:		93.70 %
Epoch 1086 of 2000 took 0.075s
  training loss:		0.011471
  validation loss:		0.353454
  validation accuracy:		93.26 %
Epoch 1087 of 2000 took 0.078s
  training loss:		0.012952
  validation loss:		0.343572
  validation accuracy:		93.59 %
Epoch 1088 of 2000 took 0.077s
  training loss:		0.011536
  validation loss:		0.350782
  validation accuracy:		93.48 %
Epoch 1089 of 2000 took 0.076s
  training loss:		0.011575
  validation loss:		0.340702
  validation accuracy:		93.59 %
Epoch 1090 of 2000 took 0.078s
  training loss:		0.012286
  validation loss:		0.345593
  validation accuracy:		93.59 %
Epoch 1091 of 2000 took 0.078s
  training loss:		0.011678
  validation loss:		0.343125
  validation accuracy:		93.80 %
Epoch 1092 of 2000 took 0.075s
  training loss:		0.011765
  validation loss:		0.343251
  validation accuracy:		93.70 %
Epoch 1093 of 2000 took 0.077s
  training loss:		0.011642
  validation loss:		0.342057
  validation accuracy:		93.80 %
Epoch 1094 of 2000 took 0.078s
  training loss:		0.012083
  validation loss:		0.335826
  validation accuracy:		93.80 %
Epoch 1095 of 2000 took 0.077s
  training loss:		0.011787
  validation loss:		0.341361
  validation accuracy:		93.48 %
Epoch 1096 of 2000 took 0.076s
  training loss:		0.012040
  validation loss:		0.346605
  validation accuracy:		93.59 %
Epoch 1097 of 2000 took 0.074s
  training loss:		0.011656
  validation loss:		0.339209
  validation accuracy:		93.59 %
Epoch 1098 of 2000 took 0.074s
  training loss:		0.012060
  validation loss:		0.346518
  validation accuracy:		93.59 %
Epoch 1099 of 2000 took 0.074s
  training loss:		0.011425
  validation loss:		0.342765
  validation accuracy:		93.59 %
Epoch 1100 of 2000 took 0.077s
  training loss:		0.011658
  validation loss:		0.346574
  validation accuracy:		93.70 %
Epoch 1101 of 2000 took 0.076s
  training loss:		0.011526
  validation loss:		0.351409
  validation accuracy:		93.48 %
Epoch 1102 of 2000 took 0.078s
  training loss:		0.012387
  validation loss:		0.352431
  validation accuracy:		93.37 %
Epoch 1103 of 2000 took 0.077s
  training loss:		0.011370
  validation loss:		0.352857
  validation accuracy:		93.48 %
Epoch 1104 of 2000 took 0.076s
  training loss:		0.011426
  validation loss:		0.354502
  validation accuracy:		93.48 %
Epoch 1105 of 2000 took 0.074s
  training loss:		0.011285
  validation loss:		0.343778
  validation accuracy:		93.70 %
Epoch 1106 of 2000 took 0.076s
  training loss:		0.011535
  validation loss:		0.349567
  validation accuracy:		93.48 %
Epoch 1107 of 2000 took 0.075s
  training loss:		0.011753
  validation loss:		0.347939
  validation accuracy:		93.59 %
Epoch 1108 of 2000 took 0.079s
  training loss:		0.011458
  validation loss:		0.346221
  validation accuracy:		93.59 %
Epoch 1109 of 2000 took 0.078s
  training loss:		0.011460
  validation loss:		0.354190
  validation accuracy:		93.59 %
Epoch 1110 of 2000 took 0.077s
  training loss:		0.011514
  validation loss:		0.349264
  validation accuracy:		93.59 %
Epoch 1111 of 2000 took 0.075s
  training loss:		0.011222
  validation loss:		0.351776
  validation accuracy:		93.70 %
Epoch 1112 of 2000 took 0.078s
  training loss:		0.011662
  validation loss:		0.344208
  validation accuracy:		93.48 %
Epoch 1113 of 2000 took 0.077s
  training loss:		0.012001
  validation loss:		0.351823
  validation accuracy:		93.70 %
Epoch 1114 of 2000 took 0.076s
  training loss:		0.011684
  validation loss:		0.359211
  validation accuracy:		93.37 %
Epoch 1115 of 2000 took 0.077s
  training loss:		0.011368
  validation loss:		0.351397
  validation accuracy:		93.70 %
Epoch 1116 of 2000 took 0.077s
  training loss:		0.011649
  validation loss:		0.347528
  validation accuracy:		93.70 %
Epoch 1117 of 2000 took 0.077s
  training loss:		0.011181
  validation loss:		0.347411
  validation accuracy:		93.70 %
Epoch 1118 of 2000 took 0.079s
  training loss:		0.011458
  validation loss:		0.350211
  validation accuracy:		93.37 %
Epoch 1119 of 2000 took 0.079s
  training loss:		0.011502
  validation loss:		0.341007
  validation accuracy:		93.70 %
Epoch 1120 of 2000 took 0.076s
  training loss:		0.011446
  validation loss:		0.345636
  validation accuracy:		93.70 %
Epoch 1121 of 2000 took 0.076s
  training loss:		0.011162
  validation loss:		0.360600
  validation accuracy:		93.26 %
Epoch 1122 of 2000 took 0.074s
  training loss:		0.011176
  validation loss:		0.347630
  validation accuracy:		93.70 %
Epoch 1123 of 2000 took 0.076s
  training loss:		0.011303
  validation loss:		0.348855
  validation accuracy:		93.59 %
Epoch 1124 of 2000 took 0.078s
  training loss:		0.011403
  validation loss:		0.360256
  validation accuracy:		93.48 %
Epoch 1125 of 2000 took 0.078s
  training loss:		0.011245
  validation loss:		0.352280
  validation accuracy:		93.70 %
Epoch 1126 of 2000 took 0.078s
  training loss:		0.010779
  validation loss:		0.347719
  validation accuracy:		93.70 %
Epoch 1127 of 2000 took 0.078s
  training loss:		0.010887
  validation loss:		0.348390
  validation accuracy:		93.70 %
Epoch 1128 of 2000 took 0.076s
  training loss:		0.011374
  validation loss:		0.344241
  validation accuracy:		93.70 %
Epoch 1129 of 2000 took 0.078s
  training loss:		0.011083
  validation loss:		0.353513
  validation accuracy:		93.59 %
Epoch 1130 of 2000 took 0.076s
  training loss:		0.011285
  validation loss:		0.354548
  validation accuracy:		93.48 %
Epoch 1131 of 2000 took 0.075s
  training loss:		0.010856
  validation loss:		0.352215
  validation accuracy:		93.59 %
Epoch 1132 of 2000 took 0.077s
  training loss:		0.011231
  validation loss:		0.350886
  validation accuracy:		93.48 %
Epoch 1133 of 2000 took 0.076s
  training loss:		0.010814
  validation loss:		0.348503
  validation accuracy:		93.70 %
Epoch 1134 of 2000 took 0.077s
  training loss:		0.010788
  validation loss:		0.354534
  validation accuracy:		93.48 %
Epoch 1135 of 2000 took 0.076s
  training loss:		0.010814
  validation loss:		0.353131
  validation accuracy:		93.59 %
Epoch 1136 of 2000 took 0.076s
  training loss:		0.010522
  validation loss:		0.351742
  validation accuracy:		93.37 %
Epoch 1137 of 2000 took 0.076s
  training loss:		0.010429
  validation loss:		0.350125
  validation accuracy:		93.70 %
Epoch 1138 of 2000 took 0.076s
  training loss:		0.010999
  validation loss:		0.350136
  validation accuracy:		93.70 %
Epoch 1139 of 2000 took 0.077s
  training loss:		0.010601
  validation loss:		0.355161
  validation accuracy:		93.59 %
Epoch 1140 of 2000 took 0.076s
  training loss:		0.010497
  validation loss:		0.357732
  validation accuracy:		93.70 %
Epoch 1141 of 2000 took 0.076s
  training loss:		0.011046
  validation loss:		0.355906
  validation accuracy:		93.59 %
Epoch 1142 of 2000 took 0.074s
  training loss:		0.010830
  validation loss:		0.355896
  validation accuracy:		93.70 %
Epoch 1143 of 2000 took 0.077s
  training loss:		0.010786
  validation loss:		0.358193
  validation accuracy:		93.59 %
Epoch 1144 of 2000 took 0.076s
  training loss:		0.010659
  validation loss:		0.346938
  validation accuracy:		93.70 %
Epoch 1145 of 2000 took 0.077s
  training loss:		0.010892
  validation loss:		0.358711
  validation accuracy:		93.48 %
Epoch 1146 of 2000 took 0.076s
  training loss:		0.010275
  validation loss:		0.355687
  validation accuracy:		93.48 %
Epoch 1147 of 2000 took 0.075s
  training loss:		0.010581
  validation loss:		0.348304
  validation accuracy:		93.59 %
Epoch 1148 of 2000 took 0.076s
  training loss:		0.010846
  validation loss:		0.351997
  validation accuracy:		93.70 %
Epoch 1149 of 2000 took 0.078s
  training loss:		0.010837
  validation loss:		0.351948
  validation accuracy:		93.70 %
Epoch 1150 of 2000 took 0.077s
  training loss:		0.010812
  validation loss:		0.352899
  validation accuracy:		93.80 %
Epoch 1151 of 2000 took 0.077s
  training loss:		0.010395
  validation loss:		0.354626
  validation accuracy:		93.59 %
Epoch 1152 of 2000 took 0.078s
  training loss:		0.010808
  validation loss:		0.352733
  validation accuracy:		93.80 %
Epoch 1153 of 2000 took 0.074s
  training loss:		0.009938
  validation loss:		0.359911
  validation accuracy:		93.48 %
Epoch 1154 of 2000 took 0.077s
  training loss:		0.010743
  validation loss:		0.357948
  validation accuracy:		93.59 %
Epoch 1155 of 2000 took 0.073s
  training loss:		0.010419
  validation loss:		0.353808
  validation accuracy:		93.48 %
Epoch 1156 of 2000 took 0.077s
  training loss:		0.010350
  validation loss:		0.366023
  validation accuracy:		93.15 %
Epoch 1157 of 2000 took 0.074s
  training loss:		0.010557
  validation loss:		0.357086
  validation accuracy:		93.59 %
Epoch 1158 of 2000 took 0.075s
  training loss:		0.010439
  validation loss:		0.366012
  validation accuracy:		93.37 %
Epoch 1159 of 2000 took 0.076s
  training loss:		0.010353
  validation loss:		0.360175
  validation accuracy:		93.37 %
Epoch 1160 of 2000 took 0.074s
  training loss:		0.010166
  validation loss:		0.357154
  validation accuracy:		93.70 %
Epoch 1161 of 2000 took 0.075s
  training loss:		0.009981
  validation loss:		0.363373
  validation accuracy:		93.37 %
Epoch 1162 of 2000 took 0.077s
  training loss:		0.010547
  validation loss:		0.360683
  validation accuracy:		93.48 %
Epoch 1163 of 2000 took 0.075s
  training loss:		0.009956
  validation loss:		0.366220
  validation accuracy:		93.37 %
Epoch 1164 of 2000 took 0.076s
  training loss:		0.010415
  validation loss:		0.362808
  validation accuracy:		93.59 %
Epoch 1165 of 2000 took 0.075s
  training loss:		0.009945
  validation loss:		0.359415
  validation accuracy:		93.59 %
Epoch 1166 of 2000 took 0.075s
  training loss:		0.010312
  validation loss:		0.361053
  validation accuracy:		93.59 %
Epoch 1167 of 2000 took 0.078s
  training loss:		0.010165
  validation loss:		0.357611
  validation accuracy:		93.70 %
Epoch 1168 of 2000 took 0.073s
  training loss:		0.010159
  validation loss:		0.360077
  validation accuracy:		93.70 %
Epoch 1169 of 2000 took 0.074s
  training loss:		0.009835
  validation loss:		0.356943
  validation accuracy:		93.59 %
Epoch 1170 of 2000 took 0.078s
  training loss:		0.010142
  validation loss:		0.360891
  validation accuracy:		93.59 %
Epoch 1171 of 2000 took 0.078s
  training loss:		0.009944
  validation loss:		0.361568
  validation accuracy:		93.59 %
Epoch 1172 of 2000 took 0.074s
  training loss:		0.010194
  validation loss:		0.360500
  validation accuracy:		93.48 %
Epoch 1173 of 2000 took 0.077s
  training loss:		0.010114
  validation loss:		0.364730
  validation accuracy:		93.48 %
Epoch 1174 of 2000 took 0.078s
  training loss:		0.010077
  validation loss:		0.363527
  validation accuracy:		93.70 %
Epoch 1175 of 2000 took 0.078s
  training loss:		0.010138
  validation loss:		0.360255
  validation accuracy:		93.59 %
Epoch 1176 of 2000 took 0.076s
  training loss:		0.009946
  validation loss:		0.366158
  validation accuracy:		93.59 %
Epoch 1177 of 2000 took 0.078s
  training loss:		0.010071
  validation loss:		0.370089
  validation accuracy:		93.48 %
Epoch 1178 of 2000 took 0.074s
  training loss:		0.010073
  validation loss:		0.351446
  validation accuracy:		93.70 %
Epoch 1179 of 2000 took 0.076s
  training loss:		0.009895
  validation loss:		0.361154
  validation accuracy:		93.70 %
Epoch 1180 of 2000 took 0.074s
  training loss:		0.009907
  validation loss:		0.365101
  validation accuracy:		93.59 %
Epoch 1181 of 2000 took 0.077s
  training loss:		0.009947
  validation loss:		0.362087
  validation accuracy:		93.80 %
Epoch 1182 of 2000 took 0.076s
  training loss:		0.009998
  validation loss:		0.364006
  validation accuracy:		93.59 %
Epoch 1183 of 2000 took 0.074s
  training loss:		0.010037
  validation loss:		0.372397
  validation accuracy:		93.48 %
Epoch 1184 of 2000 took 0.075s
  training loss:		0.010214
  validation loss:		0.366219
  validation accuracy:		93.48 %
Epoch 1185 of 2000 took 0.078s
  training loss:		0.009660
  validation loss:		0.358793
  validation accuracy:		93.70 %
Epoch 1186 of 2000 took 0.079s
  training loss:		0.010121
  validation loss:		0.367575
  validation accuracy:		93.59 %
Epoch 1187 of 2000 took 0.078s
  training loss:		0.009732
  validation loss:		0.367596
  validation accuracy:		93.37 %
Epoch 1188 of 2000 took 0.077s
  training loss:		0.009778
  validation loss:		0.358080
  validation accuracy:		93.70 %
Epoch 1189 of 2000 took 0.079s
  training loss:		0.009739
  validation loss:		0.372269
  validation accuracy:		93.48 %
Epoch 1190 of 2000 took 0.076s
  training loss:		0.009366
  validation loss:		0.366930
  validation accuracy:		93.37 %
Epoch 1191 of 2000 took 0.076s
  training loss:		0.009658
  validation loss:		0.360134
  validation accuracy:		93.59 %
Epoch 1192 of 2000 took 0.076s
  training loss:		0.009442
  validation loss:		0.373532
  validation accuracy:		93.37 %
Epoch 1193 of 2000 took 0.077s
  training loss:		0.009652
  validation loss:		0.364917
  validation accuracy:		93.59 %
Epoch 1194 of 2000 took 0.076s
  training loss:		0.009649
  validation loss:		0.361159
  validation accuracy:		93.70 %
Epoch 1195 of 2000 took 0.077s
  training loss:		0.009660
  validation loss:		0.364306
  validation accuracy:		93.37 %
Epoch 1196 of 2000 took 0.077s
  training loss:		0.009371
  validation loss:		0.369563
  validation accuracy:		93.37 %
Epoch 1197 of 2000 took 0.076s
  training loss:		0.009729
  validation loss:		0.363173
  validation accuracy:		93.70 %
Epoch 1198 of 2000 took 0.076s
  training loss:		0.009549
  validation loss:		0.372664
  validation accuracy:		93.37 %
Epoch 1199 of 2000 took 0.074s
  training loss:		0.009248
  validation loss:		0.360288
  validation accuracy:		93.48 %
Epoch 1200 of 2000 took 0.077s
  training loss:		0.009502
  validation loss:		0.370717
  validation accuracy:		93.59 %
Epoch 1201 of 2000 took 0.077s
  training loss:		0.009668
  validation loss:		0.367259
  validation accuracy:		93.26 %
Epoch 1202 of 2000 took 0.078s
  training loss:		0.009587
  validation loss:		0.362206
  validation accuracy:		93.59 %
Epoch 1203 of 2000 took 0.078s
  training loss:		0.009480
  validation loss:		0.376316
  validation accuracy:		93.48 %
Epoch 1204 of 2000 took 0.079s
  training loss:		0.009511
  validation loss:		0.367345
  validation accuracy:		93.70 %
Epoch 1205 of 2000 took 0.078s
  training loss:		0.009420
  validation loss:		0.368650
  validation accuracy:		93.59 %
Epoch 1206 of 2000 took 0.075s
  training loss:		0.009267
  validation loss:		0.370342
  validation accuracy:		93.37 %
Epoch 1207 of 2000 took 0.075s
  training loss:		0.009295
  validation loss:		0.363641
  validation accuracy:		93.48 %
Epoch 1208 of 2000 took 0.077s
  training loss:		0.009518
  validation loss:		0.359457
  validation accuracy:		93.59 %
Epoch 1209 of 2000 took 0.077s
  training loss:		0.009190
  validation loss:		0.366756
  validation accuracy:		93.37 %
Epoch 1210 of 2000 took 0.075s
  training loss:		0.008977
  validation loss:		0.369656
  validation accuracy:		93.37 %
Epoch 1211 of 2000 took 0.077s
  training loss:		0.009517
  validation loss:		0.364777
  validation accuracy:		93.48 %
Epoch 1212 of 2000 took 0.078s
  training loss:		0.009293
  validation loss:		0.368410
  validation accuracy:		93.48 %
Epoch 1213 of 2000 took 0.078s
  training loss:		0.009136
  validation loss:		0.363078
  validation accuracy:		93.70 %
Epoch 1214 of 2000 took 0.078s
  training loss:		0.009459
  validation loss:		0.365243
  validation accuracy:		93.59 %
Epoch 1215 of 2000 took 0.075s
  training loss:		0.008723
  validation loss:		0.371351
  validation accuracy:		93.48 %
Epoch 1216 of 2000 took 0.078s
  training loss:		0.009499
  validation loss:		0.363735
  validation accuracy:		93.70 %
Epoch 1217 of 2000 took 0.077s
  training loss:		0.008755
  validation loss:		0.366273
  validation accuracy:		93.70 %
Epoch 1218 of 2000 took 0.077s
  training loss:		0.009078
  validation loss:		0.368384
  validation accuracy:		93.59 %
Epoch 1219 of 2000 took 0.077s
  training loss:		0.009122
  validation loss:		0.369750
  validation accuracy:		93.37 %
Epoch 1220 of 2000 took 0.077s
  training loss:		0.009330
  validation loss:		0.367153
  validation accuracy:		93.48 %
Epoch 1221 of 2000 took 0.079s
  training loss:		0.009276
  validation loss:		0.369999
  validation accuracy:		93.59 %
Epoch 1222 of 2000 took 0.075s
  training loss:		0.009094
  validation loss:		0.373186
  validation accuracy:		93.59 %
Epoch 1223 of 2000 took 0.075s
  training loss:		0.009331
  validation loss:		0.366319
  validation accuracy:		93.59 %
Epoch 1224 of 2000 took 0.076s
  training loss:		0.008843
  validation loss:		0.367679
  validation accuracy:		93.59 %
Epoch 1225 of 2000 took 0.076s
  training loss:		0.009209
  validation loss:		0.366894
  validation accuracy:		93.80 %
Epoch 1226 of 2000 took 0.078s
  training loss:		0.009020
  validation loss:		0.379629
  validation accuracy:		93.48 %
Epoch 1227 of 2000 took 0.077s
  training loss:		0.008805
  validation loss:		0.380720
  validation accuracy:		93.37 %
Epoch 1228 of 2000 took 0.078s
  training loss:		0.008820
  validation loss:		0.367732
  validation accuracy:		93.48 %
Epoch 1229 of 2000 took 0.077s
  training loss:		0.008696
  validation loss:		0.372778
  validation accuracy:		93.59 %
Epoch 1230 of 2000 took 0.077s
  training loss:		0.008659
  validation loss:		0.372238
  validation accuracy:		93.59 %
Epoch 1231 of 2000 took 0.076s
  training loss:		0.009112
  validation loss:		0.374106
  validation accuracy:		93.59 %
Epoch 1232 of 2000 took 0.074s
  training loss:		0.008708
  validation loss:		0.377709
  validation accuracy:		93.59 %
Epoch 1233 of 2000 took 0.076s
  training loss:		0.008513
  validation loss:		0.368821
  validation accuracy:		93.48 %
Epoch 1234 of 2000 took 0.075s
  training loss:		0.009026
  validation loss:		0.375050
  validation accuracy:		93.59 %
Epoch 1235 of 2000 took 0.076s
  training loss:		0.008935
  validation loss:		0.372840
  validation accuracy:		93.91 %
Epoch 1236 of 2000 took 0.077s
  training loss:		0.008749
  validation loss:		0.367698
  validation accuracy:		93.48 %
Epoch 1237 of 2000 took 0.077s
  training loss:		0.008618
  validation loss:		0.372720
  validation accuracy:		93.59 %
Epoch 1238 of 2000 took 0.077s
  training loss:		0.008841
  validation loss:		0.373375
  validation accuracy:		93.70 %
Epoch 1239 of 2000 took 0.074s
  training loss:		0.008867
  validation loss:		0.375739
  validation accuracy:		93.70 %
Epoch 1240 of 2000 took 0.077s
  training loss:		0.008504
  validation loss:		0.370466
  validation accuracy:		93.48 %
Epoch 1241 of 2000 took 0.077s
  training loss:		0.008652
  validation loss:		0.372169
  validation accuracy:		93.70 %
Epoch 1242 of 2000 took 0.078s
  training loss:		0.008832
  validation loss:		0.369514
  validation accuracy:		93.48 %
Epoch 1243 of 2000 took 0.078s
  training loss:		0.008837
  validation loss:		0.374281
  validation accuracy:		93.48 %
Epoch 1244 of 2000 took 0.077s
  training loss:		0.008592
  validation loss:		0.374925
  validation accuracy:		93.59 %
Epoch 1245 of 2000 took 0.076s
  training loss:		0.008897
  validation loss:		0.372703
  validation accuracy:		93.48 %
Epoch 1246 of 2000 took 0.077s
  training loss:		0.008781
  validation loss:		0.379190
  validation accuracy:		93.48 %
Epoch 1247 of 2000 took 0.079s
  training loss:		0.008792
  validation loss:		0.374686
  validation accuracy:		93.70 %
Epoch 1248 of 2000 took 0.078s
  training loss:		0.008585
  validation loss:		0.367873
  validation accuracy:		93.59 %
Epoch 1249 of 2000 took 0.079s
  training loss:		0.008859
  validation loss:		0.369267
  validation accuracy:		93.91 %
Epoch 1250 of 2000 took 0.075s
  training loss:		0.008217
  validation loss:		0.373562
  validation accuracy:		93.59 %
Epoch 1251 of 2000 took 0.076s
  training loss:		0.008484
  validation loss:		0.382197
  validation accuracy:		93.48 %
Epoch 1252 of 2000 took 0.077s
  training loss:		0.008238
  validation loss:		0.377309
  validation accuracy:		93.70 %
Epoch 1253 of 2000 took 0.076s
  training loss:		0.008744
  validation loss:		0.374044
  validation accuracy:		93.59 %
Epoch 1254 of 2000 took 0.075s
  training loss:		0.008737
  validation loss:		0.384939
  validation accuracy:		93.48 %
Epoch 1255 of 2000 took 0.075s
  training loss:		0.008289
  validation loss:		0.378521
  validation accuracy:		93.59 %
Epoch 1256 of 2000 took 0.074s
  training loss:		0.008739
  validation loss:		0.375077
  validation accuracy:		93.48 %
Epoch 1257 of 2000 took 0.074s
  training loss:		0.008648
  validation loss:		0.380070
  validation accuracy:		93.59 %
Epoch 1258 of 2000 took 0.076s
  training loss:		0.008842
  validation loss:		0.379396
  validation accuracy:		93.37 %
Epoch 1259 of 2000 took 0.075s
  training loss:		0.008289
  validation loss:		0.376370
  validation accuracy:		93.70 %
Epoch 1260 of 2000 took 0.078s
  training loss:		0.008359
  validation loss:		0.375832
  validation accuracy:		93.48 %
Epoch 1261 of 2000 took 0.077s
  training loss:		0.008202
  validation loss:		0.375394
  validation accuracy:		93.48 %
Epoch 1262 of 2000 took 0.077s
  training loss:		0.008235
  validation loss:		0.375410
  validation accuracy:		93.48 %
Epoch 1263 of 2000 took 0.077s
  training loss:		0.008563
  validation loss:		0.374730
  validation accuracy:		93.70 %
Epoch 1264 of 2000 took 0.075s
  training loss:		0.008374
  validation loss:		0.379778
  validation accuracy:		93.70 %
Epoch 1265 of 2000 took 0.076s
  training loss:		0.008223
  validation loss:		0.373926
  validation accuracy:		93.37 %
Epoch 1266 of 2000 took 0.077s
  training loss:		0.008516
  validation loss:		0.378439
  validation accuracy:		93.80 %
Epoch 1267 of 2000 took 0.078s
  training loss:		0.008225
  validation loss:		0.380927
  validation accuracy:		93.59 %
Epoch 1268 of 2000 took 0.078s
  training loss:		0.008396
  validation loss:		0.375943
  validation accuracy:		93.48 %
Epoch 1269 of 2000 took 0.076s
  training loss:		0.008140
  validation loss:		0.381489
  validation accuracy:		93.70 %
Epoch 1270 of 2000 took 0.076s
  training loss:		0.008256
  validation loss:		0.379684
  validation accuracy:		93.48 %
Epoch 1271 of 2000 took 0.077s
  training loss:		0.008251
  validation loss:		0.379933
  validation accuracy:		93.48 %
Epoch 1272 of 2000 took 0.075s
  training loss:		0.008099
  validation loss:		0.383824
  validation accuracy:		93.70 %
Epoch 1273 of 2000 took 0.076s
  training loss:		0.008356
  validation loss:		0.385555
  validation accuracy:		93.48 %
Epoch 1274 of 2000 took 0.074s
  training loss:		0.007782
  validation loss:		0.383749
  validation accuracy:		93.59 %
Epoch 1275 of 2000 took 0.076s
  training loss:		0.007810
  validation loss:		0.380162
  validation accuracy:		93.59 %
Epoch 1276 of 2000 took 0.076s
  training loss:		0.008230
  validation loss:		0.374645
  validation accuracy:		93.70 %
Epoch 1277 of 2000 took 0.077s
  training loss:		0.008297
  validation loss:		0.379440
  validation accuracy:		93.70 %
Epoch 1278 of 2000 took 0.077s
  training loss:		0.008256
  validation loss:		0.380512
  validation accuracy:		93.59 %
Epoch 1279 of 2000 took 0.077s
  training loss:		0.007988
  validation loss:		0.381545
  validation accuracy:		93.70 %
Epoch 1280 of 2000 took 0.076s
  training loss:		0.007949
  validation loss:		0.380504
  validation accuracy:		93.70 %
Epoch 1281 of 2000 took 0.076s
  training loss:		0.008081
  validation loss:		0.381864
  validation accuracy:		93.59 %
Epoch 1282 of 2000 took 0.077s
  training loss:		0.007959
  validation loss:		0.380421
  validation accuracy:		93.59 %
Epoch 1283 of 2000 took 0.077s
  training loss:		0.008030
  validation loss:		0.376160
  validation accuracy:		93.37 %
Epoch 1284 of 2000 took 0.076s
  training loss:		0.008018
  validation loss:		0.385228
  validation accuracy:		93.48 %
Epoch 1285 of 2000 took 0.075s
  training loss:		0.007899
  validation loss:		0.379509
  validation accuracy:		93.59 %
Epoch 1286 of 2000 took 0.076s
  training loss:		0.008019
  validation loss:		0.381215
  validation accuracy:		93.48 %
Epoch 1287 of 2000 took 0.079s
  training loss:		0.007857
  validation loss:		0.378750
  validation accuracy:		93.37 %
Epoch 1288 of 2000 took 0.077s
  training loss:		0.008075
  validation loss:		0.378543
  validation accuracy:		93.48 %
Epoch 1289 of 2000 took 0.078s
  training loss:		0.008091
  validation loss:		0.382552
  validation accuracy:		93.37 %
Epoch 1290 of 2000 took 0.077s
  training loss:		0.008076
  validation loss:		0.382654
  validation accuracy:		93.59 %
Epoch 1291 of 2000 took 0.075s
  training loss:		0.007988
  validation loss:		0.375271
  validation accuracy:		93.70 %
Epoch 1292 of 2000 took 0.076s
  training loss:		0.007961
  validation loss:		0.381798
  validation accuracy:		93.70 %
Epoch 1293 of 2000 took 0.075s
  training loss:		0.007904
  validation loss:		0.382418
  validation accuracy:		93.59 %
Epoch 1294 of 2000 took 0.079s
  training loss:		0.007786
  validation loss:		0.380222
  validation accuracy:		93.48 %
Epoch 1295 of 2000 took 0.075s
  training loss:		0.007886
  validation loss:		0.381924
  validation accuracy:		93.59 %
Epoch 1296 of 2000 took 0.074s
  training loss:		0.007890
  validation loss:		0.387849
  validation accuracy:		93.26 %
Epoch 1297 of 2000 took 0.074s
  training loss:		0.007964
  validation loss:		0.380753
  validation accuracy:		93.48 %
Epoch 1298 of 2000 took 0.075s
  training loss:		0.007952
  validation loss:		0.379627
  validation accuracy:		93.59 %
Epoch 1299 of 2000 took 0.077s
  training loss:		0.007950
  validation loss:		0.385246
  validation accuracy:		93.37 %
Epoch 1300 of 2000 took 0.076s
  training loss:		0.007684
  validation loss:		0.385939
  validation accuracy:		93.59 %
Epoch 1301 of 2000 took 0.077s
  training loss:		0.007734
  validation loss:		0.387650
  validation accuracy:		93.59 %
Epoch 1302 of 2000 took 0.081s
  training loss:		0.007667
  validation loss:		0.383351
  validation accuracy:		93.70 %
Epoch 1303 of 2000 took 0.081s
  training loss:		0.007819
  validation loss:		0.384038
  validation accuracy:		93.70 %
Epoch 1304 of 2000 took 0.078s
  training loss:		0.007812
  validation loss:		0.384686
  validation accuracy:		93.48 %
Epoch 1305 of 2000 took 0.081s
  training loss:		0.007756
  validation loss:		0.390783
  validation accuracy:		93.37 %
Epoch 1306 of 2000 took 0.082s
  training loss:		0.007783
  validation loss:		0.388529
  validation accuracy:		93.59 %
Epoch 1307 of 2000 took 0.077s
  training loss:		0.007902
  validation loss:		0.386709
  validation accuracy:		93.59 %
Epoch 1308 of 2000 took 0.076s
  training loss:		0.007837
  validation loss:		0.380103
  validation accuracy:		93.48 %
Epoch 1309 of 2000 took 0.074s
  training loss:		0.007759
  validation loss:		0.385244
  validation accuracy:		93.70 %
Epoch 1310 of 2000 took 0.078s
  training loss:		0.007672
  validation loss:		0.385951
  validation accuracy:		93.59 %
Epoch 1311 of 2000 took 0.077s
  training loss:		0.007838
  validation loss:		0.396035
  validation accuracy:		93.48 %
Epoch 1312 of 2000 took 0.075s
  training loss:		0.007702
  validation loss:		0.388685
  validation accuracy:		93.48 %
Epoch 1313 of 2000 took 0.078s
  training loss:		0.007786
  validation loss:		0.380412
  validation accuracy:		93.26 %
Epoch 1314 of 2000 took 0.079s
  training loss:		0.007784
  validation loss:		0.389708
  validation accuracy:		93.70 %
Epoch 1315 of 2000 took 0.079s
  training loss:		0.007578
  validation loss:		0.384161
  validation accuracy:		93.59 %
Epoch 1316 of 2000 took 0.077s
  training loss:		0.007517
  validation loss:		0.387771
  validation accuracy:		93.37 %
Epoch 1317 of 2000 took 0.077s
  training loss:		0.007498
  validation loss:		0.389586
  validation accuracy:		93.26 %
Epoch 1318 of 2000 took 0.077s
  training loss:		0.007501
  validation loss:		0.380430
  validation accuracy:		93.48 %
Epoch 1319 of 2000 took 0.076s
  training loss:		0.007285
  validation loss:		0.399362
  validation accuracy:		93.37 %
Epoch 1320 of 2000 took 0.077s
  training loss:		0.007631
  validation loss:		0.385552
  validation accuracy:		93.37 %
Epoch 1321 of 2000 took 0.075s
  training loss:		0.007605
  validation loss:		0.382482
  validation accuracy:		93.37 %
Epoch 1322 of 2000 took 0.077s
  training loss:		0.007523
  validation loss:		0.382410
  validation accuracy:		93.48 %
Epoch 1323 of 2000 took 0.077s
  training loss:		0.007603
  validation loss:		0.385638
  validation accuracy:		93.59 %
Epoch 1324 of 2000 took 0.076s
  training loss:		0.007338
  validation loss:		0.389059
  validation accuracy:		93.70 %
Epoch 1325 of 2000 took 0.077s
  training loss:		0.007555
  validation loss:		0.398256
  validation accuracy:		93.59 %
Epoch 1326 of 2000 took 0.076s
  training loss:		0.007344
  validation loss:		0.384080
  validation accuracy:		93.59 %
Epoch 1327 of 2000 took 0.076s
  training loss:		0.007645
  validation loss:		0.391591
  validation accuracy:		93.80 %
Epoch 1328 of 2000 took 0.078s
  training loss:		0.007479
  validation loss:		0.389950
  validation accuracy:		93.59 %
Epoch 1329 of 2000 took 0.076s
  training loss:		0.007450
  validation loss:		0.393223
  validation accuracy:		93.59 %
Epoch 1330 of 2000 took 0.076s
  training loss:		0.007340
  validation loss:		0.390045
  validation accuracy:		93.70 %
Epoch 1331 of 2000 took 0.075s
  training loss:		0.007362
  validation loss:		0.384732
  validation accuracy:		93.26 %
Epoch 1332 of 2000 took 0.076s
  training loss:		0.007502
  validation loss:		0.391127
  validation accuracy:		93.59 %
Epoch 1333 of 2000 took 0.074s
  training loss:		0.007334
  validation loss:		0.391113
  validation accuracy:		93.59 %
Epoch 1334 of 2000 took 0.074s
  training loss:		0.007224
  validation loss:		0.393081
  validation accuracy:		93.59 %
Epoch 1335 of 2000 took 0.075s
  training loss:		0.006983
  validation loss:		0.385335
  validation accuracy:		93.59 %
Epoch 1336 of 2000 took 0.078s
  training loss:		0.007310
  validation loss:		0.394938
  validation accuracy:		93.48 %
Epoch 1337 of 2000 took 0.076s
  training loss:		0.007164
  validation loss:		0.391780
  validation accuracy:		93.59 %
Epoch 1338 of 2000 took 0.076s
  training loss:		0.007086
  validation loss:		0.389002
  validation accuracy:		93.48 %
Epoch 1339 of 2000 took 0.078s
  training loss:		0.007346
  validation loss:		0.394302
  validation accuracy:		93.70 %
Epoch 1340 of 2000 took 0.075s
  training loss:		0.007211
  validation loss:		0.388341
  validation accuracy:		93.37 %
Epoch 1341 of 2000 took 0.075s
  training loss:		0.007211
  validation loss:		0.395135
  validation accuracy:		93.48 %
Epoch 1342 of 2000 took 0.076s
  training loss:		0.007178
  validation loss:		0.391028
  validation accuracy:		93.59 %
Epoch 1343 of 2000 took 0.075s
  training loss:		0.007166
  validation loss:		0.393372
  validation accuracy:		93.59 %
Epoch 1344 of 2000 took 0.074s
  training loss:		0.007121
  validation loss:		0.396882
  validation accuracy:		93.37 %
Epoch 1345 of 2000 took 0.074s
  training loss:		0.007214
  validation loss:		0.395347
  validation accuracy:		93.70 %
Epoch 1346 of 2000 took 0.076s
  training loss:		0.007224
  validation loss:		0.393542
  validation accuracy:		93.59 %
Epoch 1347 of 2000 took 0.075s
  training loss:		0.006810
  validation loss:		0.396934
  validation accuracy:		93.59 %
Epoch 1348 of 2000 took 0.078s
  training loss:		0.006833
  validation loss:		0.389598
  validation accuracy:		93.80 %
Epoch 1349 of 2000 took 0.075s
  training loss:		0.007164
  validation loss:		0.392848
  validation accuracy:		93.70 %
Epoch 1350 of 2000 took 0.077s
  training loss:		0.007375
  validation loss:		0.399782
  validation accuracy:		93.48 %
Epoch 1351 of 2000 took 0.077s
  training loss:		0.006913
  validation loss:		0.397459
  validation accuracy:		93.48 %
Epoch 1352 of 2000 took 0.075s
  training loss:		0.007338
  validation loss:		0.396314
  validation accuracy:		93.70 %
Epoch 1353 of 2000 took 0.076s
  training loss:		0.007048
  validation loss:		0.393599
  validation accuracy:		93.59 %
Epoch 1354 of 2000 took 0.075s
  training loss:		0.006834
  validation loss:		0.397036
  validation accuracy:		93.48 %
Epoch 1355 of 2000 took 0.078s
  training loss:		0.007031
  validation loss:		0.396772
  validation accuracy:		93.48 %
Epoch 1356 of 2000 took 0.077s
  training loss:		0.006705
  validation loss:		0.392168
  validation accuracy:		93.70 %
Epoch 1357 of 2000 took 0.075s
  training loss:		0.007528
  validation loss:		0.395249
  validation accuracy:		93.70 %
Epoch 1358 of 2000 took 0.077s
  training loss:		0.007165
  validation loss:		0.395070
  validation accuracy:		93.48 %
Epoch 1359 of 2000 took 0.075s
  training loss:		0.007009
  validation loss:		0.394587
  validation accuracy:		93.48 %
Epoch 1360 of 2000 took 0.076s
  training loss:		0.006972
  validation loss:		0.394663
  validation accuracy:		93.48 %
Epoch 1361 of 2000 took 0.076s
  training loss:		0.006998
  validation loss:		0.397562
  validation accuracy:		93.59 %
Epoch 1362 of 2000 took 0.075s
  training loss:		0.006987
  validation loss:		0.394328
  validation accuracy:		93.59 %
Epoch 1363 of 2000 took 0.077s
  training loss:		0.007011
  validation loss:		0.391656
  validation accuracy:		93.59 %
Epoch 1364 of 2000 took 0.076s
  training loss:		0.007023
  validation loss:		0.390664
  validation accuracy:		93.48 %
Epoch 1365 of 2000 took 0.076s
  training loss:		0.006939
  validation loss:		0.395893
  validation accuracy:		93.91 %
Epoch 1366 of 2000 took 0.077s
  training loss:		0.006999
  validation loss:		0.395218
  validation accuracy:		93.59 %
Epoch 1367 of 2000 took 0.079s
  training loss:		0.006873
  validation loss:		0.402005
  validation accuracy:		93.48 %
Epoch 1368 of 2000 took 0.075s
  training loss:		0.006922
  validation loss:		0.406087
  validation accuracy:		93.37 %
Epoch 1369 of 2000 took 0.078s
  training loss:		0.007052
  validation loss:		0.389944
  validation accuracy:		93.48 %
Epoch 1370 of 2000 took 0.078s
  training loss:		0.007149
  validation loss:		0.399857
  validation accuracy:		93.59 %
Epoch 1371 of 2000 took 0.076s
  training loss:		0.006793
  validation loss:		0.395901
  validation accuracy:		93.48 %
Epoch 1372 of 2000 took 0.075s
  training loss:		0.006845
  validation loss:		0.405345
  validation accuracy:		93.48 %
Epoch 1373 of 2000 took 0.074s
  training loss:		0.006783
  validation loss:		0.393224
  validation accuracy:		93.59 %
Epoch 1374 of 2000 took 0.078s
  training loss:		0.006847
  validation loss:		0.395128
  validation accuracy:		93.59 %
Epoch 1375 of 2000 took 0.077s
  training loss:		0.006564
  validation loss:		0.400822
  validation accuracy:		93.48 %
Epoch 1376 of 2000 took 0.077s
  training loss:		0.006837
  validation loss:		0.404273
  validation accuracy:		93.48 %
Epoch 1377 of 2000 took 0.075s
  training loss:		0.006802
  validation loss:		0.396729
  validation accuracy:		93.48 %
Epoch 1378 of 2000 took 0.075s
  training loss:		0.006797
  validation loss:		0.395690
  validation accuracy:		93.70 %
Epoch 1379 of 2000 took 0.077s
  training loss:		0.006706
  validation loss:		0.398730
  validation accuracy:		93.48 %
Epoch 1380 of 2000 took 0.077s
  training loss:		0.006363
  validation loss:		0.398122
  validation accuracy:		93.15 %
Epoch 1381 of 2000 took 0.077s
  training loss:		0.006755
  validation loss:		0.407753
  validation accuracy:		93.37 %
Epoch 1382 of 2000 took 0.077s
  training loss:		0.006737
  validation loss:		0.401229
  validation accuracy:		93.59 %
Epoch 1383 of 2000 took 0.077s
  training loss:		0.006601
  validation loss:		0.394761
  validation accuracy:		93.48 %
Epoch 1384 of 2000 took 0.077s
  training loss:		0.006424
  validation loss:		0.398902
  validation accuracy:		93.59 %
Epoch 1385 of 2000 took 0.076s
  training loss:		0.007044
  validation loss:		0.396188
  validation accuracy:		93.48 %
Epoch 1386 of 2000 took 0.076s
  training loss:		0.006675
  validation loss:		0.395762
  validation accuracy:		93.48 %
Epoch 1387 of 2000 took 0.075s
  training loss:		0.006681
  validation loss:		0.401506
  validation accuracy:		93.37 %
Epoch 1388 of 2000 took 0.077s
  training loss:		0.006662
  validation loss:		0.397357
  validation accuracy:		93.48 %
Epoch 1389 of 2000 took 0.074s
  training loss:		0.006576
  validation loss:		0.401850
  validation accuracy:		93.59 %
Epoch 1390 of 2000 took 0.074s
  training loss:		0.006538
  validation loss:		0.396910
  validation accuracy:		93.59 %
Epoch 1391 of 2000 took 0.078s
  training loss:		0.006691
  validation loss:		0.396673
  validation accuracy:		93.48 %
Epoch 1392 of 2000 took 0.076s
  training loss:		0.006546
  validation loss:		0.404059
  validation accuracy:		93.70 %
Epoch 1393 of 2000 took 0.077s
  training loss:		0.006422
  validation loss:		0.401142
  validation accuracy:		93.37 %
Epoch 1394 of 2000 took 0.078s
  training loss:		0.006575
  validation loss:		0.401984
  validation accuracy:		93.48 %
Epoch 1395 of 2000 took 0.079s
  training loss:		0.006652
  validation loss:		0.399089
  validation accuracy:		93.48 %
Epoch 1396 of 2000 took 0.078s
  training loss:		0.006297
  validation loss:		0.400738
  validation accuracy:		93.48 %
Epoch 1397 of 2000 took 0.077s
  training loss:		0.006433
  validation loss:		0.395912
  validation accuracy:		93.48 %
Epoch 1398 of 2000 took 0.076s
  training loss:		0.006541
  validation loss:		0.400767
  validation accuracy:		93.59 %
Epoch 1399 of 2000 took 0.078s
  training loss:		0.006554
  validation loss:		0.396374
  validation accuracy:		93.59 %
Epoch 1400 of 2000 took 0.075s
  training loss:		0.006387
  validation loss:		0.399295
  validation accuracy:		93.59 %
Epoch 1401 of 2000 took 0.078s
  training loss:		0.006540
  validation loss:		0.400955
  validation accuracy:		93.48 %
Epoch 1402 of 2000 took 0.075s
  training loss:		0.006418
  validation loss:		0.403617
  validation accuracy:		93.70 %
Epoch 1403 of 2000 took 0.077s
  training loss:		0.006404
  validation loss:		0.403873
  validation accuracy:		93.59 %
Epoch 1404 of 2000 took 0.078s
  training loss:		0.006166
  validation loss:		0.398285
  validation accuracy:		93.48 %
Epoch 1405 of 2000 took 0.080s
  training loss:		0.006403
  validation loss:		0.404124
  validation accuracy:		93.48 %
Epoch 1406 of 2000 took 0.076s
  training loss:		0.006541
  validation loss:		0.393186
  validation accuracy:		93.37 %
Epoch 1407 of 2000 took 0.076s
  training loss:		0.006589
  validation loss:		0.407544
  validation accuracy:		93.37 %
Epoch 1408 of 2000 took 0.079s
  training loss:		0.006501
  validation loss:		0.401321
  validation accuracy:		93.59 %
Epoch 1409 of 2000 took 0.076s
  training loss:		0.006281
  validation loss:		0.401188
  validation accuracy:		93.26 %
Epoch 1410 of 2000 took 0.077s
  training loss:		0.006449
  validation loss:		0.404761
  validation accuracy:		93.59 %
Epoch 1411 of 2000 took 0.076s
  training loss:		0.006360
  validation loss:		0.405194
  validation accuracy:		93.70 %
Epoch 1412 of 2000 took 0.078s
  training loss:		0.006407
  validation loss:		0.397501
  validation accuracy:		93.48 %
Epoch 1413 of 2000 took 0.076s
  training loss:		0.006550
  validation loss:		0.404803
  validation accuracy:		93.59 %
Epoch 1414 of 2000 took 0.079s
  training loss:		0.006439
  validation loss:		0.404524
  validation accuracy:		93.70 %
Epoch 1415 of 2000 took 0.079s
  training loss:		0.006234
  validation loss:		0.400978
  validation accuracy:		93.48 %
Epoch 1416 of 2000 took 0.075s
  training loss:		0.006601
  validation loss:		0.403853
  validation accuracy:		93.70 %
Epoch 1417 of 2000 took 0.078s
  training loss:		0.006217
  validation loss:		0.401867
  validation accuracy:		93.48 %
Epoch 1418 of 2000 took 0.078s
  training loss:		0.006335
  validation loss:		0.406903
  validation accuracy:		93.59 %
Epoch 1419 of 2000 took 0.076s
  training loss:		0.006311
  validation loss:		0.406822
  validation accuracy:		93.70 %
Epoch 1420 of 2000 took 0.079s
  training loss:		0.006415
  validation loss:		0.406287
  validation accuracy:		93.37 %
Epoch 1421 of 2000 took 0.075s
  training loss:		0.006396
  validation loss:		0.410129
  validation accuracy:		93.70 %
Epoch 1422 of 2000 took 0.079s
  training loss:		0.006166
  validation loss:		0.402915
  validation accuracy:		93.59 %
Epoch 1423 of 2000 took 0.079s
  training loss:		0.006289
  validation loss:		0.402900
  validation accuracy:		93.59 %
Epoch 1424 of 2000 took 0.079s
  training loss:		0.006157
  validation loss:		0.411611
  validation accuracy:		93.59 %
Epoch 1425 of 2000 took 0.076s
  training loss:		0.006130
  validation loss:		0.405960
  validation accuracy:		93.48 %
Epoch 1426 of 2000 took 0.075s
  training loss:		0.006260
  validation loss:		0.408431
  validation accuracy:		93.80 %
Epoch 1427 of 2000 took 0.077s
  training loss:		0.006004
  validation loss:		0.400886
  validation accuracy:		93.59 %
Epoch 1428 of 2000 took 0.075s
  training loss:		0.006167
  validation loss:		0.401028
  validation accuracy:		93.48 %
Epoch 1429 of 2000 took 0.076s
  training loss:		0.006215
  validation loss:		0.409813
  validation accuracy:		93.48 %
Epoch 1430 of 2000 took 0.076s
  training loss:		0.006183
  validation loss:		0.414960
  validation accuracy:		93.59 %
Epoch 1431 of 2000 took 0.077s
  training loss:		0.006388
  validation loss:		0.410027
  validation accuracy:		93.59 %
Epoch 1432 of 2000 took 0.078s
  training loss:		0.006117
  validation loss:		0.405161
  validation accuracy:		93.59 %
Epoch 1433 of 2000 took 0.079s
  training loss:		0.006207
  validation loss:		0.411909
  validation accuracy:		93.48 %
Epoch 1434 of 2000 took 0.077s
  training loss:		0.006296
  validation loss:		0.411170
  validation accuracy:		93.59 %
Epoch 1435 of 2000 took 0.080s
  training loss:		0.006376
  validation loss:		0.404889
  validation accuracy:		93.26 %
Epoch 1436 of 2000 took 0.079s
  training loss:		0.006238
  validation loss:		0.409542
  validation accuracy:		93.80 %
Epoch 1437 of 2000 took 0.079s
  training loss:		0.006156
  validation loss:		0.404755
  validation accuracy:		93.48 %
Epoch 1438 of 2000 took 0.079s
  training loss:		0.006091
  validation loss:		0.407647
  validation accuracy:		93.59 %
Epoch 1439 of 2000 took 0.079s
  training loss:		0.005980
  validation loss:		0.415551
  validation accuracy:		93.59 %
Epoch 1440 of 2000 took 0.077s
  training loss:		0.006153
  validation loss:		0.408829
  validation accuracy:		93.37 %
Epoch 1441 of 2000 took 0.079s
  training loss:		0.006044
  validation loss:		0.403784
  validation accuracy:		93.59 %
Epoch 1442 of 2000 took 0.079s
  training loss:		0.006207
  validation loss:		0.408613
  validation accuracy:		93.70 %
Epoch 1443 of 2000 took 0.079s
  training loss:		0.006109
  validation loss:		0.412039
  validation accuracy:		93.48 %
Epoch 1444 of 2000 took 0.079s
  training loss:		0.005910
  validation loss:		0.412717
  validation accuracy:		93.80 %
Epoch 1445 of 2000 took 0.080s
  training loss:		0.006009
  validation loss:		0.411256
  validation accuracy:		93.48 %
Epoch 1446 of 2000 took 0.080s
  training loss:		0.006087
  validation loss:		0.406183
  validation accuracy:		93.48 %
Epoch 1447 of 2000 took 0.079s
  training loss:		0.006188
  validation loss:		0.405271
  validation accuracy:		93.48 %
Epoch 1448 of 2000 took 0.079s
  training loss:		0.006019
  validation loss:		0.410734
  validation accuracy:		93.59 %
Epoch 1449 of 2000 took 0.079s
  training loss:		0.005989
  validation loss:		0.408639
  validation accuracy:		93.37 %
Epoch 1450 of 2000 took 0.079s
  training loss:		0.006085
  validation loss:		0.407044
  validation accuracy:		93.48 %
Epoch 1451 of 2000 took 0.080s
  training loss:		0.005872
  validation loss:		0.414000
  validation accuracy:		93.59 %
Epoch 1452 of 2000 took 0.079s
  training loss:		0.006004
  validation loss:		0.404324
  validation accuracy:		93.48 %
Epoch 1453 of 2000 took 0.066s
  training loss:		0.006018
  validation loss:		0.409791
  validation accuracy:		93.80 %
Epoch 1454 of 2000 took 0.060s
  training loss:		0.005928
  validation loss:		0.413854
  validation accuracy:		93.37 %
Epoch 1455 of 2000 took 0.061s
  training loss:		0.006007
  validation loss:		0.410651
  validation accuracy:		93.59 %
Epoch 1456 of 2000 took 0.064s
  training loss:		0.005922
  validation loss:		0.410247
  validation accuracy:		93.48 %
Epoch 1457 of 2000 took 0.156s
  training loss:		0.005873
  validation loss:		0.412540
  validation accuracy:		93.48 %
Epoch 1458 of 2000 took 0.066s
  training loss:		0.005987
  validation loss:		0.410726
  validation accuracy:		93.48 %
Epoch 1459 of 2000 took 0.065s
  training loss:		0.005867
  validation loss:		0.414949
  validation accuracy:		93.70 %
Epoch 1460 of 2000 took 0.072s
  training loss:		0.005697
  validation loss:		0.416685
  validation accuracy:		93.48 %
Epoch 1461 of 2000 took 0.070s
  training loss:		0.005813
  validation loss:		0.404799
  validation accuracy:		93.48 %
Epoch 1462 of 2000 took 0.065s
  training loss:		0.005877
  validation loss:		0.409007
  validation accuracy:		93.59 %
Epoch 1463 of 2000 took 0.070s
  training loss:		0.005814
  validation loss:		0.416991
  validation accuracy:		93.48 %
Epoch 1464 of 2000 took 0.073s
  training loss:		0.005843
  validation loss:		0.412001
  validation accuracy:		93.48 %
Epoch 1465 of 2000 took 0.064s
  training loss:		0.005759
  validation loss:		0.417989
  validation accuracy:		93.59 %
Epoch 1466 of 2000 took 0.065s
  training loss:		0.005828
  validation loss:		0.411275
  validation accuracy:		93.48 %
Epoch 1467 of 2000 took 0.064s
  training loss:		0.005756
  validation loss:		0.406263
  validation accuracy:		93.48 %
Epoch 1468 of 2000 took 0.064s
  training loss:		0.005713
  validation loss:		0.411330
  validation accuracy:		93.48 %
Epoch 1469 of 2000 took 0.064s
  training loss:		0.006065
  validation loss:		0.411267
  validation accuracy:		93.48 %
Epoch 1470 of 2000 took 0.064s
  training loss:		0.005783
  validation loss:		0.411464
  validation accuracy:		93.37 %
Epoch 1471 of 2000 took 0.065s
  training loss:		0.005779
  validation loss:		0.407759
  validation accuracy:		93.48 %
Epoch 1472 of 2000 took 0.065s
  training loss:		0.005748
  validation loss:		0.410789
  validation accuracy:		93.48 %
Epoch 1473 of 2000 took 0.065s
  training loss:		0.005738
  validation loss:		0.414555
  validation accuracy:		93.48 %
Epoch 1474 of 2000 took 0.063s
  training loss:		0.005847
  validation loss:		0.411128
  validation accuracy:		93.48 %
Epoch 1475 of 2000 took 0.059s
  training loss:		0.005760
  validation loss:		0.411480
  validation accuracy:		93.48 %
Epoch 1476 of 2000 took 0.060s
  training loss:		0.005733
  validation loss:		0.418417
  validation accuracy:		93.59 %
Epoch 1477 of 2000 took 0.059s
  training loss:		0.005678
  validation loss:		0.411790
  validation accuracy:		93.48 %
Epoch 1478 of 2000 took 0.058s
  training loss:		0.005636
  validation loss:		0.413349
  validation accuracy:		93.59 %
Epoch 1479 of 2000 took 0.057s
  training loss:		0.005640
  validation loss:		0.410889
  validation accuracy:		93.48 %
Epoch 1480 of 2000 took 0.056s
  training loss:		0.005718
  validation loss:		0.420469
  validation accuracy:		93.59 %
Epoch 1481 of 2000 took 0.056s
  training loss:		0.005640
  validation loss:		0.414006
  validation accuracy:		93.70 %
Epoch 1482 of 2000 took 0.057s
  training loss:		0.005610
  validation loss:		0.413576
  validation accuracy:		93.59 %
Epoch 1483 of 2000 took 0.056s
  training loss:		0.005802
  validation loss:		0.412615
  validation accuracy:		93.48 %
Epoch 1484 of 2000 took 0.056s
  training loss:		0.005738
  validation loss:		0.414815
  validation accuracy:		93.59 %
Epoch 1485 of 2000 took 0.220s
  training loss:		0.005529
  validation loss:		0.420060
  validation accuracy:		93.48 %
Epoch 1486 of 2000 took 0.065s
  training loss:		0.005801
  validation loss:		0.416083
  validation accuracy:		93.48 %
Epoch 1487 of 2000 took 0.068s
  training loss:		0.005667
  validation loss:		0.413104
  validation accuracy:		93.48 %
Epoch 1488 of 2000 took 0.064s
  training loss:		0.005657
  validation loss:		0.419518
  validation accuracy:		93.37 %
Epoch 1489 of 2000 took 0.064s
  training loss:		0.005686
  validation loss:		0.415233
  validation accuracy:		93.59 %
Epoch 1490 of 2000 took 0.065s
  training loss:		0.005684
  validation loss:		0.421697
  validation accuracy:		93.59 %
Epoch 1491 of 2000 took 0.064s
  training loss:		0.005541
  validation loss:		0.413813
  validation accuracy:		93.48 %
Epoch 1492 of 2000 took 0.064s
  training loss:		0.005609
  validation loss:		0.420338
  validation accuracy:		93.59 %
Epoch 1493 of 2000 took 0.061s
  training loss:		0.005711
  validation loss:		0.416578
  validation accuracy:		93.48 %
Epoch 1494 of 2000 took 0.064s
  training loss:		0.005558
  validation loss:		0.415796
  validation accuracy:		93.48 %
Epoch 1495 of 2000 took 0.064s
  training loss:		0.005618
  validation loss:		0.417694
  validation accuracy:		93.70 %
Epoch 1496 of 2000 took 0.065s
  training loss:		0.005555
  validation loss:		0.413213
  validation accuracy:		93.48 %
Epoch 1497 of 2000 took 0.065s
  training loss:		0.005625
  validation loss:		0.409931
  validation accuracy:		93.48 %
Epoch 1498 of 2000 took 0.064s
  training loss:		0.005627
  validation loss:		0.417062
  validation accuracy:		93.59 %
Epoch 1499 of 2000 took 0.064s
  training loss:		0.005529
  validation loss:		0.425731
  validation accuracy:		93.37 %
Epoch 1500 of 2000 took 0.063s
  training loss:		0.005475
  validation loss:		0.420326
  validation accuracy:		93.26 %
Epoch 1501 of 2000 took 0.063s
  training loss:		0.005587
  validation loss:		0.422992
  validation accuracy:		93.59 %
Epoch 1502 of 2000 took 0.064s
  training loss:		0.005549
  validation loss:		0.415914
  validation accuracy:		93.48 %
Epoch 1503 of 2000 took 0.062s
  training loss:		0.005647
  validation loss:		0.422027
  validation accuracy:		93.48 %
Epoch 1504 of 2000 took 0.059s
  training loss:		0.005307
  validation loss:		0.410051
  validation accuracy:		93.48 %
Epoch 1505 of 2000 took 0.058s
  training loss:		0.005625
  validation loss:		0.417832
  validation accuracy:		93.59 %
Epoch 1506 of 2000 took 0.058s
  training loss:		0.005495
  validation loss:		0.418657
  validation accuracy:		93.37 %
Epoch 1507 of 2000 took 0.058s
  training loss:		0.005405
  validation loss:		0.423654
  validation accuracy:		93.48 %
Epoch 1508 of 2000 took 0.058s
  training loss:		0.005443
  validation loss:		0.416174
  validation accuracy:		93.59 %
Epoch 1509 of 2000 took 0.059s
  training loss:		0.005370
  validation loss:		0.420401
  validation accuracy:		93.37 %
Epoch 1510 of 2000 took 0.058s
  training loss:		0.005395
  validation loss:		0.413950
  validation accuracy:		93.48 %
Epoch 1511 of 2000 took 0.058s
  training loss:		0.005422
  validation loss:		0.420925
  validation accuracy:		93.48 %
Epoch 1512 of 2000 took 0.059s
  training loss:		0.005492
  validation loss:		0.423948
  validation accuracy:		93.48 %
Epoch 1513 of 2000 took 0.058s
  training loss:		0.005328
  validation loss:		0.416234
  validation accuracy:		93.48 %
Epoch 1514 of 2000 took 0.058s
  training loss:		0.005528
  validation loss:		0.423522
  validation accuracy:		93.37 %
Epoch 1515 of 2000 took 0.058s
  training loss:		0.005362
  validation loss:		0.423629
  validation accuracy:		93.48 %
Epoch 1516 of 2000 took 0.058s
  training loss:		0.005305
  validation loss:		0.421281
  validation accuracy:		93.48 %
Epoch 1517 of 2000 took 0.060s
  training loss:		0.005388
  validation loss:		0.422705
  validation accuracy:		93.37 %
Epoch 1518 of 2000 took 0.059s
  training loss:		0.005418
  validation loss:		0.419333
  validation accuracy:		93.48 %
Epoch 1519 of 2000 took 0.078s
  training loss:		0.005415
  validation loss:		0.418675
  validation accuracy:		93.48 %
Epoch 1520 of 2000 took 0.070s
  training loss:		0.005219
  validation loss:		0.420849
  validation accuracy:		93.48 %
Epoch 1521 of 2000 took 0.064s
  training loss:		0.005221
  validation loss:		0.421374
  validation accuracy:		93.48 %
Epoch 1522 of 2000 took 0.064s
  training loss:		0.005140
  validation loss:		0.416609
  validation accuracy:		93.48 %
Epoch 1523 of 2000 took 0.065s
  training loss:		0.005252
  validation loss:		0.418266
  validation accuracy:		93.37 %
Epoch 1524 of 2000 took 0.063s
  training loss:		0.005161
  validation loss:		0.422164
  validation accuracy:		93.59 %
Epoch 1525 of 2000 took 0.063s
  training loss:		0.005378
  validation loss:		0.418688
  validation accuracy:		93.37 %
Epoch 1526 of 2000 took 0.062s
  training loss:		0.005218
  validation loss:		0.421396
  validation accuracy:		93.15 %
Epoch 1527 of 2000 took 0.064s
  training loss:		0.005410
  validation loss:		0.423750
  validation accuracy:		93.48 %
Epoch 1528 of 2000 took 0.064s
  training loss:		0.005241
  validation loss:		0.422905
  validation accuracy:		93.37 %
Epoch 1529 of 2000 took 0.064s
  training loss:		0.005282
  validation loss:		0.420284
  validation accuracy:		93.37 %
Epoch 1530 of 2000 took 0.062s
  training loss:		0.005364
  validation loss:		0.425710
  validation accuracy:		93.59 %
Epoch 1531 of 2000 took 0.059s
  training loss:		0.005293
  validation loss:		0.423802
  validation accuracy:		93.37 %
Epoch 1532 of 2000 took 0.059s
  training loss:		0.005208
  validation loss:		0.417860
  validation accuracy:		93.48 %
Epoch 1533 of 2000 took 0.059s
  training loss:		0.005335
  validation loss:		0.425949
  validation accuracy:		93.70 %
Epoch 1534 of 2000 took 0.059s
  training loss:		0.005387
  validation loss:		0.425289
  validation accuracy:		93.59 %
Epoch 1535 of 2000 took 0.059s
  training loss:		0.005181
  validation loss:		0.420517
  validation accuracy:		93.48 %
Epoch 1536 of 2000 took 0.059s
  training loss:		0.005050
  validation loss:		0.420740
  validation accuracy:		93.48 %
Epoch 1537 of 2000 took 0.059s
  training loss:		0.005191
  validation loss:		0.423662
  validation accuracy:		93.59 %
Epoch 1538 of 2000 took 0.059s
  training loss:		0.005112
  validation loss:		0.420904
  validation accuracy:		93.59 %
Epoch 1539 of 2000 took 0.059s
  training loss:		0.005349
  validation loss:		0.428712
  validation accuracy:		93.48 %
Epoch 1540 of 2000 took 0.060s
  training loss:		0.005254
  validation loss:		0.429403
  validation accuracy:		93.37 %
Epoch 1541 of 2000 took 0.060s
  training loss:		0.005180
  validation loss:		0.418023
  validation accuracy:		93.48 %
Epoch 1542 of 2000 took 0.059s
  training loss:		0.005127
  validation loss:		0.421954
  validation accuracy:		93.37 %
Epoch 1543 of 2000 took 0.059s
  training loss:		0.005191
  validation loss:		0.425403
  validation accuracy:		93.59 %
Epoch 1544 of 2000 took 0.057s
  training loss:		0.005226
  validation loss:		0.422205
  validation accuracy:		93.48 %
Epoch 1545 of 2000 took 0.057s
  training loss:		0.005176
  validation loss:		0.421136
  validation accuracy:		93.37 %
Epoch 1546 of 2000 took 0.057s
  training loss:		0.005303
  validation loss:		0.422915
  validation accuracy:		93.59 %
Epoch 1547 of 2000 took 0.058s
  training loss:		0.005119
  validation loss:		0.424481
  validation accuracy:		93.48 %
Epoch 1548 of 2000 took 0.057s
  training loss:		0.005092
  validation loss:		0.428938
  validation accuracy:		93.48 %
Epoch 1549 of 2000 took 0.057s
  training loss:		0.004733
  validation loss:		0.425334
  validation accuracy:		93.48 %
Epoch 1550 of 2000 took 0.059s
  training loss:		0.005057
  validation loss:		0.425505
  validation accuracy:		93.70 %
Epoch 1551 of 2000 took 0.057s
  training loss:		0.004947
  validation loss:		0.429853
  validation accuracy:		93.37 %
Epoch 1552 of 2000 took 0.056s
  training loss:		0.005057
  validation loss:		0.427862
  validation accuracy:		93.37 %
Epoch 1553 of 2000 took 0.058s
  training loss:		0.005035
  validation loss:		0.422808
  validation accuracy:		93.48 %
Epoch 1554 of 2000 took 0.058s
  training loss:		0.004953
  validation loss:		0.425112
  validation accuracy:		93.48 %
Epoch 1555 of 2000 took 0.061s
  training loss:		0.005026
  validation loss:		0.430389
  validation accuracy:		93.48 %
Epoch 1556 of 2000 took 0.058s
  training loss:		0.004990
  validation loss:		0.426108
  validation accuracy:		93.48 %
Epoch 1557 of 2000 took 0.058s
  training loss:		0.004924
  validation loss:		0.421575
  validation accuracy:		93.26 %
Epoch 1558 of 2000 took 0.057s
  training loss:		0.005020
  validation loss:		0.427021
  validation accuracy:		93.59 %
Epoch 1559 of 2000 took 0.057s
  training loss:		0.004997
  validation loss:		0.425993
  validation accuracy:		93.37 %
Epoch 1560 of 2000 took 0.057s
  training loss:		0.005013
  validation loss:		0.423228
  validation accuracy:		93.37 %
Epoch 1561 of 2000 took 0.057s
  training loss:		0.004932
  validation loss:		0.428936
  validation accuracy:		93.48 %
Epoch 1562 of 2000 took 0.057s
  training loss:		0.004868
  validation loss:		0.426792
  validation accuracy:		93.48 %
Epoch 1563 of 2000 took 0.057s
  training loss:		0.004903
  validation loss:		0.424162
  validation accuracy:		93.26 %
Epoch 1564 of 2000 took 0.057s
  training loss:		0.005123
  validation loss:		0.430964
  validation accuracy:		93.37 %
Epoch 1565 of 2000 took 0.058s
  training loss:		0.004912
  validation loss:		0.426638
  validation accuracy:		93.48 %
Epoch 1566 of 2000 took 0.058s
  training loss:		0.004909
  validation loss:		0.433691
  validation accuracy:		93.59 %
Epoch 1567 of 2000 took 0.058s
  training loss:		0.004932
  validation loss:		0.427740
  validation accuracy:		93.48 %
Epoch 1568 of 2000 took 0.057s
  training loss:		0.005106
  validation loss:		0.428794
  validation accuracy:		93.48 %
Epoch 1569 of 2000 took 0.057s
  training loss:		0.005013
  validation loss:		0.428153
  validation accuracy:		93.48 %
Epoch 1570 of 2000 took 0.056s
  training loss:		0.004842
  validation loss:		0.430402
  validation accuracy:		93.59 %
Epoch 1571 of 2000 took 0.056s
  training loss:		0.004898
  validation loss:		0.428763
  validation accuracy:		93.37 %
Epoch 1572 of 2000 took 0.058s
  training loss:		0.004897
  validation loss:		0.431141
  validation accuracy:		93.48 %
Epoch 1573 of 2000 took 0.058s
  training loss:		0.004943
  validation loss:		0.429739
  validation accuracy:		93.59 %
Epoch 1574 of 2000 took 0.057s
  training loss:		0.004869
  validation loss:		0.430485
  validation accuracy:		93.48 %
Epoch 1575 of 2000 took 0.058s
  training loss:		0.004907
  validation loss:		0.425056
  validation accuracy:		93.48 %
Epoch 1576 of 2000 took 0.057s
  training loss:		0.004895
  validation loss:		0.435423
  validation accuracy:		93.37 %
Epoch 1577 of 2000 took 0.060s
  training loss:		0.004940
  validation loss:		0.431984
  validation accuracy:		93.48 %
Epoch 1578 of 2000 took 0.059s
  training loss:		0.004829
  validation loss:		0.424529
  validation accuracy:		93.26 %
Epoch 1579 of 2000 took 0.058s
  training loss:		0.004942
  validation loss:		0.430236
  validation accuracy:		93.59 %
Epoch 1580 of 2000 took 0.057s
  training loss:		0.004840
  validation loss:		0.430187
  validation accuracy:		93.48 %
Epoch 1581 of 2000 took 0.058s
  training loss:		0.004857
  validation loss:		0.432612
  validation accuracy:		93.48 %
Epoch 1582 of 2000 took 0.058s
  training loss:		0.004897
  validation loss:		0.428769
  validation accuracy:		93.48 %
Epoch 1583 of 2000 took 0.058s
  training loss:		0.004873
  validation loss:		0.433968
  validation accuracy:		93.48 %
Epoch 1584 of 2000 took 0.058s
  training loss:		0.004853
  validation loss:		0.428069
  validation accuracy:		93.37 %
Epoch 1585 of 2000 took 0.059s
  training loss:		0.004770
  validation loss:		0.429223
  validation accuracy:		93.37 %
Epoch 1586 of 2000 took 0.058s
  training loss:		0.004947
  validation loss:		0.431173
  validation accuracy:		93.48 %
Epoch 1587 of 2000 took 0.057s
  training loss:		0.004890
  validation loss:		0.436621
  validation accuracy:		93.48 %
Epoch 1588 of 2000 took 0.058s
  training loss:		0.004804
  validation loss:		0.429218
  validation accuracy:		93.37 %
Epoch 1589 of 2000 took 0.058s
  training loss:		0.004700
  validation loss:		0.430173
  validation accuracy:		93.37 %
Epoch 1590 of 2000 took 0.058s
  training loss:		0.004872
  validation loss:		0.430751
  validation accuracy:		93.48 %
Epoch 1591 of 2000 took 0.059s
  training loss:		0.004792
  validation loss:		0.431116
  validation accuracy:		93.37 %
Epoch 1592 of 2000 took 0.057s
  training loss:		0.004856
  validation loss:		0.435374
  validation accuracy:		93.37 %
Epoch 1593 of 2000 took 0.058s
  training loss:		0.004787
  validation loss:		0.433070
  validation accuracy:		93.26 %
Epoch 1594 of 2000 took 0.058s
  training loss:		0.004847
  validation loss:		0.435720
  validation accuracy:		93.70 %
Epoch 1595 of 2000 took 0.058s
  training loss:		0.004867
  validation loss:		0.436114
  validation accuracy:		93.59 %
Epoch 1596 of 2000 took 0.059s
  training loss:		0.004737
  validation loss:		0.429522
  validation accuracy:		93.37 %
Epoch 1597 of 2000 took 0.057s
  training loss:		0.004793
  validation loss:		0.436865
  validation accuracy:		93.70 %
Epoch 1598 of 2000 took 0.057s
  training loss:		0.004721
  validation loss:		0.432000
  validation accuracy:		93.59 %
Epoch 1599 of 2000 took 0.057s
  training loss:		0.004706
  validation loss:		0.432187
  validation accuracy:		93.37 %
Epoch 1600 of 2000 took 0.058s
  training loss:		0.004644
  validation loss:		0.434212
  validation accuracy:		93.37 %
Epoch 1601 of 2000 took 0.058s
  training loss:		0.004671
  validation loss:		0.438586
  validation accuracy:		93.59 %
Epoch 1602 of 2000 took 0.059s
  training loss:		0.004791
  validation loss:		0.429481
  validation accuracy:		93.37 %
Epoch 1603 of 2000 took 0.057s
  training loss:		0.004689
  validation loss:		0.434077
  validation accuracy:		93.59 %
Epoch 1604 of 2000 took 0.057s
  training loss:		0.004755
  validation loss:		0.437066
  validation accuracy:		93.37 %
Epoch 1605 of 2000 took 0.058s
  training loss:		0.004681
  validation loss:		0.431848
  validation accuracy:		93.37 %
Epoch 1606 of 2000 took 0.059s
  training loss:		0.004884
  validation loss:		0.432958
  validation accuracy:		93.37 %
Epoch 1607 of 2000 took 0.058s
  training loss:		0.004574
  validation loss:		0.441078
  validation accuracy:		93.37 %
Epoch 1608 of 2000 took 0.058s
  training loss:		0.004588
  validation loss:		0.433768
  validation accuracy:		93.48 %
Epoch 1609 of 2000 took 0.058s
  training loss:		0.004570
  validation loss:		0.430720
  validation accuracy:		93.26 %
Epoch 1610 of 2000 took 0.059s
  training loss:		0.004619
  validation loss:		0.435545
  validation accuracy:		93.48 %
Epoch 1611 of 2000 took 0.056s
  training loss:		0.004701
  validation loss:		0.436355
  validation accuracy:		93.37 %
Epoch 1612 of 2000 took 0.111s
  training loss:		0.004609
  validation loss:		0.433978
  validation accuracy:		93.37 %
Epoch 1613 of 2000 took 0.098s
  training loss:		0.004668
  validation loss:		0.436221
  validation accuracy:		93.37 %
Epoch 1614 of 2000 took 0.102s
  training loss:		0.004592
  validation loss:		0.434801
  validation accuracy:		93.48 %
Epoch 1615 of 2000 took 0.096s
  training loss:		0.004592
  validation loss:		0.433941
  validation accuracy:		93.48 %
Epoch 1616 of 2000 took 0.110s
  training loss:		0.004647
  validation loss:		0.437717
  validation accuracy:		93.37 %
Epoch 1617 of 2000 took 0.100s
  training loss:		0.004485
  validation loss:		0.433279
  validation accuracy:		93.48 %
Epoch 1618 of 2000 took 0.066s
  training loss:		0.004512
  validation loss:		0.446298
  validation accuracy:		93.59 %
Epoch 1619 of 2000 took 0.037s
  training loss:		0.004761
  validation loss:		0.439394
  validation accuracy:		93.48 %
Epoch 1620 of 2000 took 0.039s
  training loss:		0.004614
  validation loss:		0.433690
  validation accuracy:		93.48 %
Epoch 1621 of 2000 took 0.128s
  training loss:		0.004700
  validation loss:		0.433289
  validation accuracy:		93.37 %
Epoch 1622 of 2000 took 0.038s
  training loss:		0.004632
  validation loss:		0.432362
  validation accuracy:		93.37 %
Epoch 1623 of 2000 took 0.038s
  training loss:		0.004706
  validation loss:		0.439139
  validation accuracy:		93.48 %
Epoch 1624 of 2000 took 0.041s
  training loss:		0.004383
  validation loss:		0.433558
  validation accuracy:		93.26 %
Epoch 1625 of 2000 took 0.043s
  training loss:		0.004663
  validation loss:		0.440225
  validation accuracy:		93.48 %
Epoch 1626 of 2000 took 0.050s
  training loss:		0.004534
  validation loss:		0.436767
  validation accuracy:		93.48 %
Epoch 1627 of 2000 took 0.046s
  training loss:		0.004667
  validation loss:		0.437213
  validation accuracy:		93.26 %
Epoch 1628 of 2000 took 0.041s
  training loss:		0.004582
  validation loss:		0.436428
  validation accuracy:		93.48 %
Epoch 1629 of 2000 took 0.048s
  training loss:		0.004681
  validation loss:		0.432962
  validation accuracy:		93.48 %
Epoch 1630 of 2000 took 0.047s
  training loss:		0.004524
  validation loss:		0.439372
  validation accuracy:		93.48 %
Epoch 1631 of 2000 took 0.038s
  training loss:		0.004605
  validation loss:		0.436438
  validation accuracy:		93.37 %
Epoch 1632 of 2000 took 0.038s
  training loss:		0.004474
  validation loss:		0.436910
  validation accuracy:		93.37 %
Epoch 1633 of 2000 took 0.037s
  training loss:		0.004526
  validation loss:		0.437003
  validation accuracy:		93.26 %
Epoch 1634 of 2000 took 0.038s
  training loss:		0.004385
  validation loss:		0.440625
  validation accuracy:		93.80 %
Epoch 1635 of 2000 took 0.038s
  training loss:		0.004511
  validation loss:		0.439962
  validation accuracy:		93.37 %
Epoch 1636 of 2000 took 0.041s
  training loss:		0.004367
  validation loss:		0.437183
  validation accuracy:		93.37 %
Epoch 1637 of 2000 took 0.040s
  training loss:		0.004579
  validation loss:		0.439819
  validation accuracy:		93.37 %
Epoch 1638 of 2000 took 0.040s
  training loss:		0.004615
  validation loss:		0.436980
  validation accuracy:		93.59 %
Epoch 1639 of 2000 took 0.037s
  training loss:		0.004464
  validation loss:		0.440800
  validation accuracy:		93.37 %
Epoch 1640 of 2000 took 0.037s
  training loss:		0.004517
  validation loss:		0.438511
  validation accuracy:		93.37 %
Epoch 1641 of 2000 took 0.041s
  training loss:		0.004372
  validation loss:		0.440681
  validation accuracy:		93.37 %
Epoch 1642 of 2000 took 0.050s
  training loss:		0.004471
  validation loss:		0.438491
  validation accuracy:		93.37 %
Epoch 1643 of 2000 took 0.059s
  training loss:		0.004447
  validation loss:		0.438033
  validation accuracy:		93.37 %
Epoch 1644 of 2000 took 0.057s
  training loss:		0.004305
  validation loss:		0.439757
  validation accuracy:		93.37 %
Epoch 1645 of 2000 took 0.083s
  training loss:		0.004435
  validation loss:		0.441135
  validation accuracy:		93.37 %
Epoch 1646 of 2000 took 0.186s
  training loss:		0.004428
  validation loss:		0.442665
  validation accuracy:		93.37 %
Epoch 1647 of 2000 took 0.064s
  training loss:		0.004551
  validation loss:		0.438708
  validation accuracy:		93.48 %
Epoch 1648 of 2000 took 0.059s
  training loss:		0.004425
  validation loss:		0.440350
  validation accuracy:		93.48 %
Epoch 1649 of 2000 took 0.060s
  training loss:		0.004433
  validation loss:		0.442922
  validation accuracy:		93.48 %
Epoch 1650 of 2000 took 0.061s
  training loss:		0.004357
  validation loss:		0.438296
  validation accuracy:		93.37 %
Epoch 1651 of 2000 took 0.059s
  training loss:		0.004465
  validation loss:		0.439996
  validation accuracy:		93.59 %
Epoch 1652 of 2000 took 0.057s
  training loss:		0.004239
  validation loss:		0.442914
  validation accuracy:		93.37 %
Epoch 1653 of 2000 took 0.056s
  training loss:		0.004312
  validation loss:		0.437858
  validation accuracy:		93.37 %
Epoch 1654 of 2000 took 0.058s
  training loss:		0.004438
  validation loss:		0.442946
  validation accuracy:		93.37 %
Epoch 1655 of 2000 took 0.056s
  training loss:		0.004380
  validation loss:		0.435474
  validation accuracy:		93.37 %
Epoch 1656 of 2000 took 0.059s
  training loss:		0.004460
  validation loss:		0.441695
  validation accuracy:		93.37 %
Epoch 1657 of 2000 took 0.058s
  training loss:		0.004400
  validation loss:		0.442580
  validation accuracy:		93.37 %
Epoch 1658 of 2000 took 0.058s
  training loss:		0.004283
  validation loss:		0.443560
  validation accuracy:		93.37 %
Epoch 1659 of 2000 took 0.058s
  training loss:		0.004353
  validation loss:		0.440748
  validation accuracy:		93.37 %
Epoch 1660 of 2000 took 0.059s
  training loss:		0.004218
  validation loss:		0.442190
  validation accuracy:		93.37 %
Epoch 1661 of 2000 took 0.058s
  training loss:		0.004204
  validation loss:		0.436894
  validation accuracy:		93.37 %
Epoch 1662 of 2000 took 0.059s
  training loss:		0.004409
  validation loss:		0.442136
  validation accuracy:		93.37 %
Epoch 1663 of 2000 took 0.058s
  training loss:		0.004241
  validation loss:		0.445382
  validation accuracy:		93.48 %
Epoch 1664 of 2000 took 0.059s
  training loss:		0.004386
  validation loss:		0.443798
  validation accuracy:		93.26 %
Epoch 1665 of 2000 took 0.058s
  training loss:		0.004385
  validation loss:		0.441426
  validation accuracy:		93.37 %
Epoch 1666 of 2000 took 0.059s
  training loss:		0.004206
  validation loss:		0.443031
  validation accuracy:		93.37 %
Epoch 1667 of 2000 took 0.059s
  training loss:		0.004288
  validation loss:		0.445000
  validation accuracy:		93.37 %
Epoch 1668 of 2000 took 0.059s
  training loss:		0.004356
  validation loss:		0.440711
  validation accuracy:		93.48 %
Epoch 1669 of 2000 took 0.059s
  training loss:		0.004426
  validation loss:		0.445037
  validation accuracy:		93.37 %
Epoch 1670 of 2000 took 0.059s
  training loss:		0.004373
  validation loss:		0.441308
  validation accuracy:		93.37 %
Epoch 1671 of 2000 took 0.060s
  training loss:		0.004298
  validation loss:		0.443559
  validation accuracy:		93.48 %
Epoch 1672 of 2000 took 0.060s
  training loss:		0.004402
  validation loss:		0.448248
  validation accuracy:		93.15 %
Epoch 1673 of 2000 took 0.059s
  training loss:		0.004325
  validation loss:		0.440824
  validation accuracy:		93.26 %
Epoch 1674 of 2000 took 0.059s
  training loss:		0.004326
  validation loss:		0.448323
  validation accuracy:		93.37 %
Epoch 1675 of 2000 took 0.058s
  training loss:		0.004347
  validation loss:		0.439779
  validation accuracy:		93.26 %
Epoch 1676 of 2000 took 0.058s
  training loss:		0.004135
  validation loss:		0.443804
  validation accuracy:		93.48 %
Epoch 1677 of 2000 took 0.058s
  training loss:		0.004427
  validation loss:		0.444473
  validation accuracy:		93.48 %
Epoch 1678 of 2000 took 0.056s
  training loss:		0.004184
  validation loss:		0.447586
  validation accuracy:		93.37 %
Epoch 1679 of 2000 took 0.057s
  training loss:		0.004230
  validation loss:		0.446750
  validation accuracy:		93.37 %
Epoch 1680 of 2000 took 0.056s
  training loss:		0.004355
  validation loss:		0.442121
  validation accuracy:		93.26 %
Epoch 1681 of 2000 took 0.056s
  training loss:		0.004287
  validation loss:		0.439843
  validation accuracy:		93.26 %
Epoch 1682 of 2000 took 0.058s
  training loss:		0.004080
  validation loss:		0.445613
  validation accuracy:		93.48 %
Epoch 1683 of 2000 took 0.058s
  training loss:		0.004273
  validation loss:		0.446597
  validation accuracy:		93.26 %
Epoch 1684 of 2000 took 0.057s
  training loss:		0.004229
  validation loss:		0.447312
  validation accuracy:		93.37 %
Epoch 1685 of 2000 took 0.058s
  training loss:		0.004239
  validation loss:		0.439747
  validation accuracy:		93.26 %
Epoch 1686 of 2000 took 0.058s
  training loss:		0.004192
  validation loss:		0.446375
  validation accuracy:		93.26 %
Epoch 1687 of 2000 took 0.056s
  training loss:		0.004293
  validation loss:		0.443836
  validation accuracy:		93.37 %
Epoch 1688 of 2000 took 0.059s
  training loss:		0.004197
  validation loss:		0.440104
  validation accuracy:		93.26 %
Epoch 1689 of 2000 took 0.059s
  training loss:		0.004162
  validation loss:		0.445346
  validation accuracy:		93.48 %
Epoch 1690 of 2000 took 0.059s
  training loss:		0.004213
  validation loss:		0.443571
  validation accuracy:		93.26 %
Epoch 1691 of 2000 took 0.059s
  training loss:		0.004253
  validation loss:		0.444364
  validation accuracy:		93.26 %
Epoch 1692 of 2000 took 0.059s
  training loss:		0.004093
  validation loss:		0.448511
  validation accuracy:		93.48 %
Epoch 1693 of 2000 took 0.060s
  training loss:		0.004119
  validation loss:		0.443425
  validation accuracy:		93.59 %
Epoch 1694 of 2000 took 0.059s
  training loss:		0.004142
  validation loss:		0.451571
  validation accuracy:		93.48 %
Epoch 1695 of 2000 took 0.059s
  training loss:		0.004362
  validation loss:		0.448202
  validation accuracy:		93.37 %
Epoch 1696 of 2000 took 0.059s
  training loss:		0.004125
  validation loss:		0.446644
  validation accuracy:		93.37 %
Epoch 1697 of 2000 took 0.058s
  training loss:		0.004006
  validation loss:		0.442956
  validation accuracy:		93.26 %
Epoch 1698 of 2000 took 0.058s
  training loss:		0.004107
  validation loss:		0.447685
  validation accuracy:		93.48 %
Epoch 1699 of 2000 took 0.058s
  training loss:		0.004099
  validation loss:		0.446551
  validation accuracy:		93.26 %
Epoch 1700 of 2000 took 0.058s
  training loss:		0.004083
  validation loss:		0.445122
  validation accuracy:		93.37 %
Epoch 1701 of 2000 took 0.058s
  training loss:		0.004013
  validation loss:		0.449344
  validation accuracy:		93.48 %
Epoch 1702 of 2000 took 0.058s
  training loss:		0.003985
  validation loss:		0.446951
  validation accuracy:		93.26 %
Epoch 1703 of 2000 took 0.059s
  training loss:		0.004086
  validation loss:		0.445980
  validation accuracy:		93.37 %
Epoch 1704 of 2000 took 0.061s
  training loss:		0.004028
  validation loss:		0.444389
  validation accuracy:		93.26 %
Epoch 1705 of 2000 took 0.059s
  training loss:		0.004005
  validation loss:		0.453709
  validation accuracy:		93.37 %
Epoch 1706 of 2000 took 0.061s
  training loss:		0.004113
  validation loss:		0.451586
  validation accuracy:		93.59 %
Epoch 1707 of 2000 took 0.059s
  training loss:		0.004140
  validation loss:		0.446266
  validation accuracy:		93.26 %
Epoch 1708 of 2000 took 0.059s
  training loss:		0.004047
  validation loss:		0.451728
  validation accuracy:		93.48 %
Epoch 1709 of 2000 took 0.059s
  training loss:		0.004131
  validation loss:		0.444708
  validation accuracy:		93.26 %
Epoch 1710 of 2000 took 0.059s
  training loss:		0.003884
  validation loss:		0.451751
  validation accuracy:		93.37 %
Epoch 1711 of 2000 took 0.059s
  training loss:		0.004022
  validation loss:		0.444325
  validation accuracy:		93.26 %
Epoch 1712 of 2000 took 0.059s
  training loss:		0.003870
  validation loss:		0.452203
  validation accuracy:		93.59 %
Epoch 1713 of 2000 took 0.059s
  training loss:		0.004056
  validation loss:		0.444906
  validation accuracy:		93.26 %
Epoch 1714 of 2000 took 0.059s
  training loss:		0.004164
  validation loss:		0.452661
  validation accuracy:		93.37 %
Epoch 1715 of 2000 took 0.059s
  training loss:		0.003993
  validation loss:		0.445001
  validation accuracy:		93.26 %
Epoch 1716 of 2000 took 0.059s
  training loss:		0.004052
  validation loss:		0.452721
  validation accuracy:		93.59 %
Epoch 1717 of 2000 took 0.059s
  training loss:		0.003952
  validation loss:		0.448692
  validation accuracy:		93.26 %
Epoch 1718 of 2000 took 0.059s
  training loss:		0.004019
  validation loss:		0.447609
  validation accuracy:		93.26 %
Epoch 1719 of 2000 took 0.059s
  training loss:		0.004002
  validation loss:		0.445724
  validation accuracy:		93.26 %
Epoch 1720 of 2000 took 0.059s
  training loss:		0.003977
  validation loss:		0.453742
  validation accuracy:		93.48 %
Epoch 1721 of 2000 took 0.060s
  training loss:		0.003963
  validation loss:		0.446484
  validation accuracy:		93.26 %
Epoch 1722 of 2000 took 0.059s
  training loss:		0.003825
  validation loss:		0.450079
  validation accuracy:		93.37 %
Epoch 1723 of 2000 took 0.059s
  training loss:		0.003974
  validation loss:		0.453234
  validation accuracy:		93.37 %
Epoch 1724 of 2000 took 0.059s
  training loss:		0.003940
  validation loss:		0.448354
  validation accuracy:		93.26 %
Epoch 1725 of 2000 took 0.059s
  training loss:		0.004002
  validation loss:		0.449668
  validation accuracy:		93.26 %
Epoch 1726 of 2000 took 0.059s
  training loss:		0.003987
  validation loss:		0.455435
  validation accuracy:		93.59 %
Epoch 1727 of 2000 took 0.059s
  training loss:		0.004026
  validation loss:		0.448476
  validation accuracy:		93.26 %
Epoch 1728 of 2000 took 0.059s
  training loss:		0.004079
  validation loss:		0.449575
  validation accuracy:		93.37 %
Epoch 1729 of 2000 took 0.059s
  training loss:		0.004006
  validation loss:		0.448047
  validation accuracy:		93.26 %
Epoch 1730 of 2000 took 0.059s
  training loss:		0.003806
  validation loss:		0.446087
  validation accuracy:		93.48 %
Epoch 1731 of 2000 took 0.059s
  training loss:		0.003858
  validation loss:		0.453776
  validation accuracy:		93.37 %
Epoch 1732 of 2000 took 0.059s
  training loss:		0.003904
  validation loss:		0.447006
  validation accuracy:		93.37 %
Epoch 1733 of 2000 took 0.059s
  training loss:		0.004037
  validation loss:		0.451528
  validation accuracy:		93.37 %
Epoch 1734 of 2000 took 0.059s
  training loss:		0.003849
  validation loss:		0.450713
  validation accuracy:		93.37 %
Epoch 1735 of 2000 took 0.059s
  training loss:		0.003963
  validation loss:		0.452388
  validation accuracy:		93.48 %
Epoch 1736 of 2000 took 0.060s
  training loss:		0.003959
  validation loss:		0.453229
  validation accuracy:		93.26 %
Epoch 1737 of 2000 took 0.059s
  training loss:		0.003936
  validation loss:		0.450043
  validation accuracy:		93.26 %
Epoch 1738 of 2000 took 0.059s
  training loss:		0.003889
  validation loss:		0.454289
  validation accuracy:		93.26 %
Epoch 1739 of 2000 took 0.059s
  training loss:		0.003919
  validation loss:		0.448712
  validation accuracy:		93.37 %
Epoch 1740 of 2000 took 0.059s
  training loss:		0.003875
  validation loss:		0.450237
  validation accuracy:		93.48 %
Epoch 1741 of 2000 took 0.059s
  training loss:		0.004001
  validation loss:		0.453188
  validation accuracy:		93.37 %
Epoch 1742 of 2000 took 0.060s
  training loss:		0.003961
  validation loss:		0.449785
  validation accuracy:		93.37 %
Epoch 1743 of 2000 took 0.059s
  training loss:		0.004028
  validation loss:		0.454142
  validation accuracy:		93.48 %
Epoch 1744 of 2000 took 0.059s
  training loss:		0.003869
  validation loss:		0.449740
  validation accuracy:		93.26 %
Epoch 1745 of 2000 took 0.059s
  training loss:		0.003785
  validation loss:		0.453832
  validation accuracy:		93.37 %
Epoch 1746 of 2000 took 0.059s
  training loss:		0.003831
  validation loss:		0.448503
  validation accuracy:		93.48 %
Epoch 1747 of 2000 took 0.059s
  training loss:		0.003919
  validation loss:		0.456595
  validation accuracy:		93.26 %
Epoch 1748 of 2000 took 0.059s
  training loss:		0.003878
  validation loss:		0.454652
  validation accuracy:		93.26 %
Epoch 1749 of 2000 took 0.059s
  training loss:		0.003702
  validation loss:		0.451213
  validation accuracy:		93.37 %
Epoch 1750 of 2000 took 0.059s
  training loss:		0.003917
  validation loss:		0.456974
  validation accuracy:		93.37 %
Epoch 1751 of 2000 took 0.059s
  training loss:		0.003850
  validation loss:		0.453876
  validation accuracy:		93.26 %
Epoch 1752 of 2000 took 0.059s
  training loss:		0.003767
  validation loss:		0.455247
  validation accuracy:		93.48 %
Epoch 1753 of 2000 took 0.060s
  training loss:		0.003775
  validation loss:		0.459126
  validation accuracy:		93.48 %
Epoch 1754 of 2000 took 0.059s
  training loss:		0.003820
  validation loss:		0.452054
  validation accuracy:		93.37 %
Epoch 1755 of 2000 took 0.059s
  training loss:		0.003842
  validation loss:		0.457859
  validation accuracy:		93.37 %
Epoch 1756 of 2000 took 0.060s
  training loss:		0.003733
  validation loss:		0.453193
  validation accuracy:		93.26 %
Epoch 1757 of 2000 took 0.060s
  training loss:		0.003908
  validation loss:		0.454019
  validation accuracy:		93.26 %
Epoch 1758 of 2000 took 0.060s
  training loss:		0.003915
  validation loss:		0.448169
  validation accuracy:		93.26 %
Epoch 1759 of 2000 took 0.060s
  training loss:		0.003710
  validation loss:		0.459440
  validation accuracy:		93.26 %
Epoch 1760 of 2000 took 0.060s
  training loss:		0.003844
  validation loss:		0.453555
  validation accuracy:		93.26 %
Epoch 1761 of 2000 took 0.060s
  training loss:		0.003854
  validation loss:		0.454403
  validation accuracy:		93.26 %
Epoch 1762 of 2000 took 0.060s
  training loss:		0.003772
  validation loss:		0.448699
  validation accuracy:		93.26 %
Epoch 1763 of 2000 took 0.084s
  training loss:		0.003716
  validation loss:		0.454484
  validation accuracy:		93.26 %
Epoch 1764 of 2000 took 0.153s
  training loss:		0.003733
  validation loss:		0.453185
  validation accuracy:		93.37 %
Epoch 1765 of 2000 took 0.091s
  training loss:		0.003694
  validation loss:		0.451133
  validation accuracy:		93.37 %
Epoch 1766 of 2000 took 0.097s
  training loss:		0.003858
  validation loss:		0.454838
  validation accuracy:		93.37 %
Epoch 1767 of 2000 took 0.121s
  training loss:		0.003795
  validation loss:		0.458798
  validation accuracy:		93.37 %
Epoch 1768 of 2000 took 0.120s
  training loss:		0.003774
  validation loss:		0.453359
  validation accuracy:		93.26 %
Epoch 1769 of 2000 took 0.056s
  training loss:		0.003793
  validation loss:		0.456541
  validation accuracy:		93.26 %
Epoch 1770 of 2000 took 0.063s
  training loss:		0.003725
  validation loss:		0.457500
  validation accuracy:		93.26 %
Epoch 1771 of 2000 took 0.062s
  training loss:		0.003637
  validation loss:		0.454122
  validation accuracy:		93.37 %
Epoch 1772 of 2000 took 0.061s
  training loss:		0.003824
  validation loss:		0.461814
  validation accuracy:		93.37 %
Epoch 1773 of 2000 took 0.063s
  training loss:		0.003860
  validation loss:		0.457159
  validation accuracy:		93.26 %
Epoch 1774 of 2000 took 0.060s
  training loss:		0.003711
  validation loss:		0.459271
  validation accuracy:		93.48 %
Epoch 1775 of 2000 took 0.062s
  training loss:		0.003755
  validation loss:		0.459114
  validation accuracy:		93.48 %
Epoch 1776 of 2000 took 0.063s
  training loss:		0.003682
  validation loss:		0.453420
  validation accuracy:		93.26 %
Epoch 1777 of 2000 took 0.061s
  training loss:		0.003699
  validation loss:		0.458269
  validation accuracy:		93.26 %
Epoch 1778 of 2000 took 0.063s
  training loss:		0.003732
  validation loss:		0.460676
  validation accuracy:		93.48 %
Epoch 1779 of 2000 took 0.067s
  training loss:		0.003809
  validation loss:		0.453979
  validation accuracy:		93.26 %
Epoch 1780 of 2000 took 0.063s
  training loss:		0.003855
  validation loss:		0.461316
  validation accuracy:		93.26 %
Epoch 1781 of 2000 took 0.063s
  training loss:		0.003768
  validation loss:		0.455564
  validation accuracy:		93.26 %
Epoch 1782 of 2000 took 0.070s
  training loss:		0.003645
  validation loss:		0.461459
  validation accuracy:		93.37 %
Epoch 1783 of 2000 took 0.076s
  training loss:		0.003704
  validation loss:		0.459009
  validation accuracy:		93.37 %
Epoch 1784 of 2000 took 0.076s
  training loss:		0.003712
  validation loss:		0.453629
  validation accuracy:		93.37 %
Epoch 1785 of 2000 took 0.077s
  training loss:		0.003756
  validation loss:		0.461084
  validation accuracy:		93.48 %
Epoch 1786 of 2000 took 0.073s
  training loss:		0.003676
  validation loss:		0.458918
  validation accuracy:		93.37 %
Epoch 1787 of 2000 took 0.077s
  training loss:		0.003660
  validation loss:		0.458486
  validation accuracy:		93.26 %
Epoch 1788 of 2000 took 0.074s
  training loss:		0.003680
  validation loss:		0.457661
  validation accuracy:		93.37 %
Epoch 1789 of 2000 took 0.076s
  training loss:		0.003533
  validation loss:		0.457190
  validation accuracy:		93.26 %
Epoch 1790 of 2000 took 0.074s
  training loss:		0.003645
  validation loss:		0.459013
  validation accuracy:		93.26 %
Epoch 1791 of 2000 took 0.075s
  training loss:		0.003670
  validation loss:		0.460319
  validation accuracy:		93.48 %
Epoch 1792 of 2000 took 0.076s
  training loss:		0.003692
  validation loss:		0.459440
  validation accuracy:		93.26 %
Epoch 1793 of 2000 took 0.075s
  training loss:		0.003601
  validation loss:		0.459940
  validation accuracy:		93.37 %
Epoch 1794 of 2000 took 0.079s
  training loss:		0.003587
  validation loss:		0.461247
  validation accuracy:		93.37 %
Epoch 1795 of 2000 took 0.076s
  training loss:		0.003676
  validation loss:		0.461674
  validation accuracy:		93.48 %
Epoch 1796 of 2000 took 0.076s
  training loss:		0.003706
  validation loss:		0.455128
  validation accuracy:		93.26 %
Epoch 1797 of 2000 took 0.077s
  training loss:		0.003607
  validation loss:		0.460106
  validation accuracy:		93.37 %
Epoch 1798 of 2000 took 0.077s
  training loss:		0.003608
  validation loss:		0.456707
  validation accuracy:		93.26 %
Epoch 1799 of 2000 took 0.076s
  training loss:		0.003645
  validation loss:		0.456387
  validation accuracy:		93.48 %
Epoch 1800 of 2000 took 0.077s
  training loss:		0.003580
  validation loss:		0.455806
  validation accuracy:		93.26 %
Epoch 1801 of 2000 took 0.077s
  training loss:		0.003607
  validation loss:		0.460791
  validation accuracy:		93.37 %
Epoch 1802 of 2000 took 0.077s
  training loss:		0.003676
  validation loss:		0.459456
  validation accuracy:		93.48 %
Epoch 1803 of 2000 took 0.075s
  training loss:		0.003573
  validation loss:		0.461919
  validation accuracy:		93.26 %
Epoch 1804 of 2000 took 0.075s
  training loss:		0.003540
  validation loss:		0.462097
  validation accuracy:		93.26 %
Epoch 1805 of 2000 took 0.076s
  training loss:		0.003692
  validation loss:		0.462082
  validation accuracy:		93.37 %
Epoch 1806 of 2000 took 0.076s
  training loss:		0.003584
  validation loss:		0.460738
  validation accuracy:		93.37 %
Epoch 1807 of 2000 took 0.077s
  training loss:		0.003528
  validation loss:		0.462594
  validation accuracy:		93.26 %
Epoch 1808 of 2000 took 0.076s
  training loss:		0.003551
  validation loss:		0.461878
  validation accuracy:		93.26 %
Epoch 1809 of 2000 took 0.076s
  training loss:		0.003619
  validation loss:		0.462277
  validation accuracy:		93.48 %
Epoch 1810 of 2000 took 0.077s
  training loss:		0.003611
  validation loss:		0.458173
  validation accuracy:		93.26 %
Epoch 1811 of 2000 took 0.076s
  training loss:		0.003607
  validation loss:		0.461163
  validation accuracy:		93.26 %
Epoch 1812 of 2000 took 0.076s
  training loss:		0.003456
  validation loss:		0.458434
  validation accuracy:		93.37 %
Epoch 1813 of 2000 took 0.077s
  training loss:		0.003522
  validation loss:		0.459794
  validation accuracy:		93.48 %
Epoch 1814 of 2000 took 0.076s
  training loss:		0.003617
  validation loss:		0.459818
  validation accuracy:		93.26 %
Epoch 1815 of 2000 took 0.077s
  training loss:		0.003600
  validation loss:		0.462409
  validation accuracy:		93.26 %
Epoch 1816 of 2000 took 0.077s
  training loss:		0.003446
  validation loss:		0.460970
  validation accuracy:		93.26 %
Epoch 1817 of 2000 took 0.076s
  training loss:		0.003559
  validation loss:		0.467280
  validation accuracy:		93.48 %
Epoch 1818 of 2000 took 0.077s
  training loss:		0.003668
  validation loss:		0.462524
  validation accuracy:		93.26 %
Epoch 1819 of 2000 took 0.077s
  training loss:		0.003558
  validation loss:		0.461538
  validation accuracy:		93.26 %
Epoch 1820 of 2000 took 0.076s
  training loss:		0.003570
  validation loss:		0.462711
  validation accuracy:		93.48 %
Epoch 1821 of 2000 took 0.075s
  training loss:		0.003378
  validation loss:		0.459560
  validation accuracy:		93.26 %
Epoch 1822 of 2000 took 0.075s
  training loss:		0.003547
  validation loss:		0.462858
  validation accuracy:		93.48 %
Epoch 1823 of 2000 took 0.075s
  training loss:		0.003538
  validation loss:		0.463464
  validation accuracy:		93.26 %
Epoch 1824 of 2000 took 0.077s
  training loss:		0.003502
  validation loss:		0.464750
  validation accuracy:		93.26 %
Epoch 1825 of 2000 took 0.078s
  training loss:		0.003474
  validation loss:		0.466376
  validation accuracy:		93.37 %
Epoch 1826 of 2000 took 0.077s
  training loss:		0.003382
  validation loss:		0.463265
  validation accuracy:		93.48 %
Epoch 1827 of 2000 took 0.077s
  training loss:		0.003530
  validation loss:		0.465703
  validation accuracy:		93.37 %
Epoch 1828 of 2000 took 0.078s
  training loss:		0.003477
  validation loss:		0.461879
  validation accuracy:		93.26 %
Epoch 1829 of 2000 took 0.075s
  training loss:		0.003496
  validation loss:		0.462884
  validation accuracy:		93.37 %
Epoch 1830 of 2000 took 0.076s
  training loss:		0.003414
  validation loss:		0.462735
  validation accuracy:		93.26 %
Epoch 1831 of 2000 took 0.077s
  training loss:		0.003515
  validation loss:		0.464457
  validation accuracy:		93.26 %
Epoch 1832 of 2000 took 0.077s
  training loss:		0.003474
  validation loss:		0.459530
  validation accuracy:		93.26 %
Epoch 1833 of 2000 took 0.075s
  training loss:		0.003528
  validation loss:		0.463203
  validation accuracy:		93.26 %
Epoch 1834 of 2000 took 0.077s
  training loss:		0.003423
  validation loss:		0.462267
  validation accuracy:		93.26 %
Epoch 1835 of 2000 took 0.077s
  training loss:		0.003477
  validation loss:		0.464008
  validation accuracy:		93.37 %
Epoch 1836 of 2000 took 0.074s
  training loss:		0.003403
  validation loss:		0.468798
  validation accuracy:		93.26 %
Epoch 1837 of 2000 took 0.073s
  training loss:		0.003408
  validation loss:		0.459638
  validation accuracy:		93.37 %
Epoch 1838 of 2000 took 0.076s
  training loss:		0.003440
  validation loss:		0.465338
  validation accuracy:		93.37 %
Epoch 1839 of 2000 took 0.077s
  training loss:		0.003485
  validation loss:		0.463055
  validation accuracy:		93.26 %
Epoch 1840 of 2000 took 0.075s
  training loss:		0.003382
  validation loss:		0.463903
  validation accuracy:		93.26 %
Epoch 1841 of 2000 took 0.074s
  training loss:		0.003480
  validation loss:		0.465443
  validation accuracy:		93.26 %
Epoch 1842 of 2000 took 0.076s
  training loss:		0.003347
  validation loss:		0.462895
  validation accuracy:		93.37 %
Epoch 1843 of 2000 took 0.078s
  training loss:		0.003373
  validation loss:		0.465517
  validation accuracy:		93.48 %
Epoch 1844 of 2000 took 0.077s
  training loss:		0.003446
  validation loss:		0.464972
  validation accuracy:		93.26 %
Epoch 1845 of 2000 took 0.076s
  training loss:		0.003475
  validation loss:		0.463977
  validation accuracy:		93.26 %
Epoch 1846 of 2000 took 0.077s
  training loss:		0.003436
  validation loss:		0.466638
  validation accuracy:		93.26 %
Epoch 1847 of 2000 took 0.078s
  training loss:		0.003416
  validation loss:		0.467326
  validation accuracy:		93.26 %
Epoch 1848 of 2000 took 0.076s
  training loss:		0.003340
  validation loss:		0.464064
  validation accuracy:		93.26 %
Epoch 1849 of 2000 took 0.078s
  training loss:		0.003360
  validation loss:		0.466426
  validation accuracy:		93.37 %
Epoch 1850 of 2000 took 0.076s
  training loss:		0.003354
  validation loss:		0.464763
  validation accuracy:		93.26 %
Epoch 1851 of 2000 took 0.075s
  training loss:		0.003352
  validation loss:		0.466400
  validation accuracy:		93.48 %
Epoch 1852 of 2000 took 0.077s
  training loss:		0.003329
  validation loss:		0.464700
  validation accuracy:		93.37 %
Epoch 1853 of 2000 took 0.076s
  training loss:		0.003401
  validation loss:		0.464217
  validation accuracy:		93.48 %
Epoch 1854 of 2000 took 0.076s
  training loss:		0.003283
  validation loss:		0.462543
  validation accuracy:		93.37 %
Epoch 1855 of 2000 took 0.073s
  training loss:		0.003432
  validation loss:		0.466207
  validation accuracy:		93.37 %
Epoch 1856 of 2000 took 0.076s
  training loss:		0.003496
  validation loss:		0.464950
  validation accuracy:		93.26 %
Epoch 1857 of 2000 took 0.076s
  training loss:		0.003333
  validation loss:		0.469401
  validation accuracy:		93.37 %
Epoch 1858 of 2000 took 0.077s
  training loss:		0.003418
  validation loss:		0.467925
  validation accuracy:		93.26 %
Epoch 1859 of 2000 took 0.074s
  training loss:		0.003384
  validation loss:		0.464610
  validation accuracy:		93.37 %
Epoch 1860 of 2000 took 0.077s
  training loss:		0.003395
  validation loss:		0.468827
  validation accuracy:		93.26 %
Epoch 1861 of 2000 took 0.078s
  training loss:		0.003269
  validation loss:		0.466189
  validation accuracy:		93.26 %
Epoch 1862 of 2000 took 0.074s
  training loss:		0.003406
  validation loss:		0.469001
  validation accuracy:		93.26 %
Epoch 1863 of 2000 took 0.075s
  training loss:		0.003310
  validation loss:		0.470589
  validation accuracy:		93.26 %
Epoch 1864 of 2000 took 0.078s
  training loss:		0.003259
  validation loss:		0.467573
  validation accuracy:		93.37 %
Epoch 1865 of 2000 took 0.076s
  training loss:		0.003375
  validation loss:		0.468111
  validation accuracy:		93.26 %
Epoch 1866 of 2000 took 0.077s
  training loss:		0.003341
  validation loss:		0.467050
  validation accuracy:		93.15 %
Epoch 1867 of 2000 took 0.083s
  training loss:		0.003416
  validation loss:		0.466504
  validation accuracy:		93.26 %
Epoch 1868 of 2000 took 0.077s
  training loss:		0.003428
  validation loss:		0.465761
  validation accuracy:		93.37 %
Epoch 1869 of 2000 took 0.076s
  training loss:		0.003238
  validation loss:		0.469719
  validation accuracy:		93.48 %
Epoch 1870 of 2000 took 0.075s
  training loss:		0.003352
  validation loss:		0.465461
  validation accuracy:		93.37 %
Epoch 1871 of 2000 took 0.075s
  training loss:		0.003379
  validation loss:		0.466197
  validation accuracy:		93.26 %
Epoch 1872 of 2000 took 0.075s
  training loss:		0.003269
  validation loss:		0.473448
  validation accuracy:		93.37 %
Epoch 1873 of 2000 took 0.076s
  training loss:		0.003274
  validation loss:		0.463540
  validation accuracy:		93.26 %
Epoch 1874 of 2000 took 0.075s
  training loss:		0.003381
  validation loss:		0.468973
  validation accuracy:		93.26 %
Epoch 1875 of 2000 took 0.076s
  training loss:		0.003325
  validation loss:		0.464715
  validation accuracy:		93.26 %
Epoch 1876 of 2000 took 0.077s
  training loss:		0.003344
  validation loss:		0.470676
  validation accuracy:		93.48 %
Epoch 1877 of 2000 took 0.075s
  training loss:		0.003310
  validation loss:		0.465260
  validation accuracy:		93.26 %
Epoch 1878 of 2000 took 0.074s
  training loss:		0.003251
  validation loss:		0.466548
  validation accuracy:		93.37 %
Epoch 1879 of 2000 took 0.077s
  training loss:		0.003277
  validation loss:		0.469308
  validation accuracy:		93.37 %
Epoch 1880 of 2000 took 0.074s
  training loss:		0.003214
  validation loss:		0.467092
  validation accuracy:		93.26 %
Epoch 1881 of 2000 took 0.079s
  training loss:		0.003371
  validation loss:		0.469003
  validation accuracy:		93.26 %
Epoch 1882 of 2000 took 0.074s
  training loss:		0.003311
  validation loss:		0.468049
  validation accuracy:		93.26 %
Epoch 1883 of 2000 took 0.075s
  training loss:		0.003193
  validation loss:		0.470838
  validation accuracy:		93.26 %
Epoch 1884 of 2000 took 0.077s
  training loss:		0.003252
  validation loss:		0.469337
  validation accuracy:		93.37 %
Epoch 1885 of 2000 took 0.075s
  training loss:		0.003342
  validation loss:		0.470745
  validation accuracy:		93.26 %
Epoch 1886 of 2000 took 0.076s
  training loss:		0.003251
  validation loss:		0.469044
  validation accuracy:		93.37 %
Epoch 1887 of 2000 took 0.074s
  training loss:		0.003205
  validation loss:		0.471491
  validation accuracy:		93.37 %
Epoch 1888 of 2000 took 0.077s
  training loss:		0.003339
  validation loss:		0.468172
  validation accuracy:		93.26 %
Epoch 1889 of 2000 took 0.076s
  training loss:		0.003162
  validation loss:		0.470016
  validation accuracy:		93.37 %
Epoch 1890 of 2000 took 0.077s
  training loss:		0.003213
  validation loss:		0.468984
  validation accuracy:		93.26 %
Epoch 1891 of 2000 took 0.074s
  training loss:		0.003246
  validation loss:		0.469294
  validation accuracy:		93.26 %
Epoch 1892 of 2000 took 0.074s
  training loss:		0.003260
  validation loss:		0.473176
  validation accuracy:		93.48 %
Epoch 1893 of 2000 took 0.077s
  training loss:		0.003198
  validation loss:		0.468434
  validation accuracy:		93.26 %
Epoch 1894 of 2000 took 0.077s
  training loss:		0.003256
  validation loss:		0.473031
  validation accuracy:		93.37 %
Epoch 1895 of 2000 took 0.074s
  training loss:		0.003227
  validation loss:		0.472363
  validation accuracy:		93.26 %
Epoch 1896 of 2000 took 0.074s
  training loss:		0.003233
  validation loss:		0.468129
  validation accuracy:		93.26 %
Epoch 1897 of 2000 took 0.076s
  training loss:		0.003293
  validation loss:		0.468673
  validation accuracy:		93.37 %
Epoch 1898 of 2000 took 0.075s
  training loss:		0.003192
  validation loss:		0.467543
  validation accuracy:		93.26 %
Epoch 1899 of 2000 took 0.076s
  training loss:		0.003264
  validation loss:		0.472742
  validation accuracy:		93.26 %
Epoch 1900 of 2000 took 0.075s
  training loss:		0.003249
  validation loss:		0.473601
  validation accuracy:		93.26 %
Epoch 1901 of 2000 took 0.076s
  training loss:		0.003168
  validation loss:		0.470794
  validation accuracy:		93.26 %
Epoch 1902 of 2000 took 0.076s
  training loss:		0.003220
  validation loss:		0.468161
  validation accuracy:		93.26 %
Epoch 1903 of 2000 took 0.077s
  training loss:		0.003145
  validation loss:		0.474776
  validation accuracy:		93.48 %
Epoch 1904 of 2000 took 0.073s
  training loss:		0.003291
  validation loss:		0.472417
  validation accuracy:		93.26 %
Epoch 1905 of 2000 took 0.074s
  training loss:		0.003200
  validation loss:		0.475630
  validation accuracy:		93.26 %
Epoch 1906 of 2000 took 0.076s
  training loss:		0.003216
  validation loss:		0.474397
  validation accuracy:		93.37 %
Epoch 1907 of 2000 took 0.075s
  training loss:		0.003159
  validation loss:		0.470476
  validation accuracy:		93.26 %
Epoch 1908 of 2000 took 0.073s
  training loss:		0.003180
  validation loss:		0.470858
  validation accuracy:		93.37 %
Epoch 1909 of 2000 took 0.076s
  training loss:		0.003012
  validation loss:		0.472913
  validation accuracy:		93.48 %
Epoch 1910 of 2000 took 0.079s
  training loss:		0.003294
  validation loss:		0.470126
  validation accuracy:		93.48 %
Epoch 1911 of 2000 took 0.078s
  training loss:		0.003202
  validation loss:		0.470105
  validation accuracy:		93.26 %
Epoch 1912 of 2000 took 0.078s
  training loss:		0.003128
  validation loss:		0.470025
  validation accuracy:		93.37 %
Epoch 1913 of 2000 took 0.078s
  training loss:		0.003097
  validation loss:		0.472710
  validation accuracy:		93.48 %
Epoch 1914 of 2000 took 0.073s
  training loss:		0.003178
  validation loss:		0.474293
  validation accuracy:		93.37 %
Epoch 1915 of 2000 took 0.075s
  training loss:		0.003056
  validation loss:		0.472226
  validation accuracy:		93.26 %
Epoch 1916 of 2000 took 0.073s
  training loss:		0.003144
  validation loss:		0.471842
  validation accuracy:		93.26 %
Epoch 1917 of 2000 took 0.074s
  training loss:		0.003186
  validation loss:		0.471211
  validation accuracy:		93.26 %
Epoch 1918 of 2000 took 0.077s
  training loss:		0.003117
  validation loss:		0.476208
  validation accuracy:		93.37 %
Epoch 1919 of 2000 took 0.076s
  training loss:		0.003180
  validation loss:		0.469979
  validation accuracy:		93.26 %
Epoch 1920 of 2000 took 0.076s
  training loss:		0.003139
  validation loss:		0.470992
  validation accuracy:		93.26 %
Epoch 1921 of 2000 took 0.074s
  training loss:		0.003024
  validation loss:		0.474686
  validation accuracy:		93.37 %
Epoch 1922 of 2000 took 0.074s
  training loss:		0.003113
  validation loss:		0.478198
  validation accuracy:		93.37 %
Epoch 1923 of 2000 took 0.079s
  training loss:		0.003007
  validation loss:		0.472584
  validation accuracy:		93.26 %
Epoch 1924 of 2000 took 0.076s
  training loss:		0.003169
  validation loss:		0.478800
  validation accuracy:		93.48 %
Epoch 1925 of 2000 took 0.077s
  training loss:		0.003199
  validation loss:		0.474155
  validation accuracy:		93.37 %
Epoch 1926 of 2000 took 0.079s
  training loss:		0.003151
  validation loss:		0.474777
  validation accuracy:		93.26 %
Epoch 1927 of 2000 took 0.076s
  training loss:		0.003245
  validation loss:		0.479910
  validation accuracy:		93.48 %
Epoch 1928 of 2000 took 0.077s
  training loss:		0.003119
  validation loss:		0.471788
  validation accuracy:		93.26 %
Epoch 1929 of 2000 took 0.075s
  training loss:		0.003051
  validation loss:		0.475380
  validation accuracy:		93.37 %
Epoch 1930 of 2000 took 0.077s
  training loss:		0.003153
  validation loss:		0.473111
  validation accuracy:		93.26 %
Epoch 1931 of 2000 took 0.075s
  training loss:		0.003090
  validation loss:		0.471921
  validation accuracy:		93.37 %
Epoch 1932 of 2000 took 0.075s
  training loss:		0.003110
  validation loss:		0.481837
  validation accuracy:		93.37 %
Epoch 1933 of 2000 took 0.076s
  training loss:		0.003026
  validation loss:		0.470887
  validation accuracy:		93.26 %
Epoch 1934 of 2000 took 0.075s
  training loss:		0.003033
  validation loss:		0.474895
  validation accuracy:		93.26 %
Epoch 1935 of 2000 took 0.074s
  training loss:		0.003124
  validation loss:		0.476608
  validation accuracy:		93.37 %
Epoch 1936 of 2000 took 0.076s
  training loss:		0.003039
  validation loss:		0.473288
  validation accuracy:		93.26 %
Epoch 1937 of 2000 took 0.077s
  training loss:		0.003040
  validation loss:		0.475819
  validation accuracy:		93.26 %
Epoch 1938 of 2000 took 0.075s
  training loss:		0.003035
  validation loss:		0.473489
  validation accuracy:		93.37 %
Epoch 1939 of 2000 took 0.075s
  training loss:		0.003160
  validation loss:		0.479246
  validation accuracy:		93.26 %
Epoch 1940 of 2000 took 0.077s
  training loss:		0.003075
  validation loss:		0.477875
  validation accuracy:		93.26 %
Epoch 1941 of 2000 took 0.075s
  training loss:		0.003109
  validation loss:		0.477631
  validation accuracy:		93.37 %
Epoch 1942 of 2000 took 0.075s
  training loss:		0.003052
  validation loss:		0.474213
  validation accuracy:		93.37 %
Epoch 1943 of 2000 took 0.076s
  training loss:		0.003104
  validation loss:		0.477285
  validation accuracy:		93.26 %
Epoch 1944 of 2000 took 0.078s
  training loss:		0.003103
  validation loss:		0.473668
  validation accuracy:		93.26 %
Epoch 1945 of 2000 took 0.077s
  training loss:		0.003026
  validation loss:		0.478394
  validation accuracy:		93.26 %
Epoch 1946 of 2000 took 0.075s
  training loss:		0.003040
  validation loss:		0.473275
  validation accuracy:		93.26 %
Epoch 1947 of 2000 took 0.077s
  training loss:		0.003051
  validation loss:		0.475243
  validation accuracy:		93.37 %
Epoch 1948 of 2000 took 0.077s
  training loss:		0.003148
  validation loss:		0.474405
  validation accuracy:		93.37 %
Epoch 1949 of 2000 took 0.076s
  training loss:		0.003085
  validation loss:		0.478037
  validation accuracy:		93.26 %
Epoch 1950 of 2000 took 0.078s
  training loss:		0.003001
  validation loss:		0.477644
  validation accuracy:		93.37 %
Epoch 1951 of 2000 took 0.074s
  training loss:		0.002986
  validation loss:		0.475062
  validation accuracy:		93.37 %
Epoch 1952 of 2000 took 0.075s
  training loss:		0.003137
  validation loss:		0.478524
  validation accuracy:		93.26 %
Epoch 1953 of 2000 took 0.075s
  training loss:		0.002994
  validation loss:		0.480269
  validation accuracy:		93.15 %
Epoch 1954 of 2000 took 0.076s
  training loss:		0.003078
  validation loss:		0.477530
  validation accuracy:		93.37 %
Epoch 1955 of 2000 took 0.076s
  training loss:		0.003067
  validation loss:		0.480346
  validation accuracy:		93.37 %
Epoch 1956 of 2000 took 0.074s
  training loss:		0.003015
  validation loss:		0.477819
  validation accuracy:		93.26 %
Epoch 1957 of 2000 took 0.076s
  training loss:		0.002982
  validation loss:		0.480029
  validation accuracy:		93.26 %
Epoch 1958 of 2000 took 0.076s
  training loss:		0.003050
  validation loss:		0.478566
  validation accuracy:		93.26 %
Epoch 1959 of 2000 took 0.075s
  training loss:		0.002965
  validation loss:		0.480648
  validation accuracy:		93.37 %
Epoch 1960 of 2000 took 0.077s
  training loss:		0.003028
  validation loss:		0.476026
  validation accuracy:		93.26 %
Epoch 1961 of 2000 took 0.077s
  training loss:		0.003054
  validation loss:		0.478998
  validation accuracy:		93.26 %
Epoch 1962 of 2000 took 0.074s
  training loss:		0.002939
  validation loss:		0.475893
  validation accuracy:		93.37 %
Epoch 1963 of 2000 took 0.076s
  training loss:		0.003046
  validation loss:		0.478719
  validation accuracy:		93.37 %
Epoch 1964 of 2000 took 0.076s
  training loss:		0.002934
  validation loss:		0.476421
  validation accuracy:		93.37 %
Epoch 1965 of 2000 took 0.075s
  training loss:		0.002941
  validation loss:		0.478852
  validation accuracy:		93.26 %
Epoch 1966 of 2000 took 0.075s
  training loss:		0.002988
  validation loss:		0.478758
  validation accuracy:		93.37 %
Epoch 1967 of 2000 took 0.077s
  training loss:		0.002893
  validation loss:		0.476739
  validation accuracy:		93.37 %
Epoch 1968 of 2000 took 0.077s
  training loss:		0.002873
  validation loss:		0.479244
  validation accuracy:		93.48 %
Epoch 1969 of 2000 took 0.075s
  training loss:		0.003074
  validation loss:		0.477253
  validation accuracy:		93.26 %
Epoch 1970 of 2000 took 0.076s
  training loss:		0.002980
  validation loss:		0.478492
  validation accuracy:		93.26 %
Epoch 1971 of 2000 took 0.074s
  training loss:		0.002966
  validation loss:		0.476884
  validation accuracy:		93.37 %
Epoch 1972 of 2000 took 0.074s
  training loss:		0.003028
  validation loss:		0.479207
  validation accuracy:		93.37 %
Epoch 1973 of 2000 took 0.077s
  training loss:		0.002964
  validation loss:		0.474511
  validation accuracy:		93.26 %
Epoch 1974 of 2000 took 0.078s
  training loss:		0.002957
  validation loss:		0.481690
  validation accuracy:		93.37 %
Epoch 1975 of 2000 took 0.077s
  training loss:		0.002935
  validation loss:		0.476898
  validation accuracy:		93.26 %
Epoch 1976 of 2000 took 0.073s
  training loss:		0.002962
  validation loss:		0.480030
  validation accuracy:		93.48 %
Epoch 1977 of 2000 took 0.073s
  training loss:		0.003037
  validation loss:		0.478229
  validation accuracy:		93.26 %
Epoch 1978 of 2000 took 0.077s
  training loss:		0.002933
  validation loss:		0.478782
  validation accuracy:		93.26 %
Epoch 1979 of 2000 took 0.077s
  training loss:		0.002891
  validation loss:		0.480827
  validation accuracy:		93.26 %
Epoch 1980 of 2000 took 0.078s
  training loss:		0.002911
  validation loss:		0.483747
  validation accuracy:		93.26 %
Epoch 1981 of 2000 took 0.075s
  training loss:		0.003022
  validation loss:		0.481992
  validation accuracy:		93.26 %
Epoch 1982 of 2000 took 0.074s
  training loss:		0.002903
  validation loss:		0.480907
  validation accuracy:		93.37 %
Epoch 1983 of 2000 took 0.076s
  training loss:		0.002930
  validation loss:		0.481613
  validation accuracy:		93.26 %
Epoch 1984 of 2000 took 0.075s
  training loss:		0.002942
  validation loss:		0.475990
  validation accuracy:		93.26 %
Epoch 1985 of 2000 took 0.075s
  training loss:		0.003044
  validation loss:		0.480129
  validation accuracy:		93.26 %
Epoch 1986 of 2000 took 0.074s
  training loss:		0.002885
  validation loss:		0.482207
  validation accuracy:		93.26 %
Epoch 1987 of 2000 took 0.075s
  training loss:		0.003003
  validation loss:		0.487932
  validation accuracy:		93.37 %
Epoch 1988 of 2000 took 0.075s
  training loss:		0.002947
  validation loss:		0.479566
  validation accuracy:		93.26 %
Epoch 1989 of 2000 took 0.075s
  training loss:		0.002906
  validation loss:		0.479724
  validation accuracy:		93.26 %
Epoch 1990 of 2000 took 0.076s
  training loss:		0.002888
  validation loss:		0.483779
  validation accuracy:		93.37 %
Epoch 1991 of 2000 took 0.077s
  training loss:		0.002804
  validation loss:		0.481879
  validation accuracy:		93.26 %
Epoch 1992 of 2000 took 0.075s
  training loss:		0.002929
  validation loss:		0.478627
  validation accuracy:		93.26 %
Epoch 1993 of 2000 took 0.075s
  training loss:		0.002868
  validation loss:		0.482852
  validation accuracy:		93.37 %
Epoch 1994 of 2000 took 0.076s
  training loss:		0.002958
  validation loss:		0.480687
  validation accuracy:		93.26 %
Epoch 1995 of 2000 took 0.076s
  training loss:		0.002853
  validation loss:		0.484142
  validation accuracy:		93.37 %
Epoch 1996 of 2000 took 0.078s
  training loss:		0.002879
  validation loss:		0.477820
  validation accuracy:		93.26 %
Epoch 1997 of 2000 took 0.077s
  training loss:		0.002912
  validation loss:		0.485063
  validation accuracy:		93.37 %
Epoch 1998 of 2000 took 0.076s
  training loss:		0.002897
  validation loss:		0.480878
  validation accuracy:		93.37 %
Epoch 1999 of 2000 took 0.074s
  training loss:		0.002864
  validation loss:		0.485728
  validation accuracy:		93.37 %
Epoch 2000 of 2000 took 0.075s
  training loss:		0.002894
  validation loss:		0.478241
  validation accuracy:		93.37 %
Final results:
  test loss:			1.148203
  test accuracy:		85.09 %
