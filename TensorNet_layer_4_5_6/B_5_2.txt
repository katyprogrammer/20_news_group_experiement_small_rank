Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.106s
  training loss:		2.996351
  validation loss:		2.986453
  validation accuracy:		12.93 %
Epoch 2 of 2000 took 0.101s
  training loss:		2.976747
  validation loss:		2.963835
  validation accuracy:		12.93 %
Epoch 3 of 2000 took 0.097s
  training loss:		2.951274
  validation loss:		2.939560
  validation accuracy:		12.93 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.925023
  validation loss:		2.915332
  validation accuracy:		12.93 %
Epoch 5 of 2000 took 0.097s
  training loss:		2.899365
  validation loss:		2.891401
  validation accuracy:		12.93 %
Epoch 6 of 2000 took 0.096s
  training loss:		2.874078
  validation loss:		2.867351
  validation accuracy:		12.93 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.850031
  validation loss:		2.842923
  validation accuracy:		12.93 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.825293
  validation loss:		2.817568
  validation accuracy:		12.93 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.800687
  validation loss:		2.791519
  validation accuracy:		12.93 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.775676
  validation loss:		2.764466
  validation accuracy:		12.93 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.749040
  validation loss:		2.735639
  validation accuracy:		12.93 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.718878
  validation loss:		2.705664
  validation accuracy:		12.93 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.691682
  validation loss:		2.673951
  validation accuracy:		12.93 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.660690
  validation loss:		2.641359
  validation accuracy:		12.93 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.632280
  validation loss:		2.607248
  validation accuracy:		12.93 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.601180
  validation loss:		2.571565
  validation accuracy:		12.93 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.566931
  validation loss:		2.534971
  validation accuracy:		12.93 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.533900
  validation loss:		2.498005
  validation accuracy:		12.93 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.504228
  validation loss:		2.461901
  validation accuracy:		12.93 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.473077
  validation loss:		2.427580
  validation accuracy:		12.93 %
Epoch 21 of 2000 took 0.098s
  training loss:		2.445305
  validation loss:		2.395092
  validation accuracy:		12.93 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.420612
  validation loss:		2.365950
  validation accuracy:		12.93 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.397536
  validation loss:		2.342083
  validation accuracy:		12.93 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.379329
  validation loss:		2.321447
  validation accuracy:		12.93 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.364469
  validation loss:		2.304996
  validation accuracy:		12.93 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.351846
  validation loss:		2.291443
  validation accuracy:		12.93 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.343413
  validation loss:		2.281560
  validation accuracy:		13.80 %
Epoch 28 of 2000 took 0.096s
  training loss:		2.334656
  validation loss:		2.274395
  validation accuracy:		12.61 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.328028
  validation loss:		2.269753
  validation accuracy:		12.61 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.324080
  validation loss:		2.265908
  validation accuracy:		13.15 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.319028
  validation loss:		2.261297
  validation accuracy:		12.93 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.316774
  validation loss:		2.259035
  validation accuracy:		12.61 %
Epoch 33 of 2000 took 0.096s
  training loss:		2.314405
  validation loss:		2.259327
  validation accuracy:		12.72 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.311561
  validation loss:		2.259294
  validation accuracy:		15.00 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.309766
  validation loss:		2.257078
  validation accuracy:		14.13 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.307652
  validation loss:		2.255509
  validation accuracy:		13.48 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.306941
  validation loss:		2.253838
  validation accuracy:		13.26 %
Epoch 38 of 2000 took 0.100s
  training loss:		2.305567
  validation loss:		2.254320
  validation accuracy:		13.04 %
Epoch 39 of 2000 took 0.097s
  training loss:		2.304285
  validation loss:		2.253962
  validation accuracy:		14.02 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.303040
  validation loss:		2.252746
  validation accuracy:		14.46 %
Epoch 41 of 2000 took 0.096s
  training loss:		2.302454
  validation loss:		2.248894
  validation accuracy:		15.65 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.302257
  validation loss:		2.249341
  validation accuracy:		13.91 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.301105
  validation loss:		2.249312
  validation accuracy:		13.15 %
Epoch 44 of 2000 took 0.097s
  training loss:		2.301767
  validation loss:		2.251761
  validation accuracy:		13.26 %
Epoch 45 of 2000 took 0.097s
  training loss:		2.300012
  validation loss:		2.251231
  validation accuracy:		14.57 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.299360
  validation loss:		2.248676
  validation accuracy:		13.91 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.298998
  validation loss:		2.246171
  validation accuracy:		12.93 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.298870
  validation loss:		2.247624
  validation accuracy:		14.57 %
Epoch 49 of 2000 took 0.097s
  training loss:		2.298411
  validation loss:		2.246917
  validation accuracy:		14.78 %
Epoch 50 of 2000 took 0.097s
  training loss:		2.298507
  validation loss:		2.245146
  validation accuracy:		13.26 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.298439
  validation loss:		2.248512
  validation accuracy:		16.85 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.297329
  validation loss:		2.247444
  validation accuracy:		14.46 %
Epoch 53 of 2000 took 0.097s
  training loss:		2.296890
  validation loss:		2.246012
  validation accuracy:		15.54 %
Epoch 54 of 2000 took 0.097s
  training loss:		2.297475
  validation loss:		2.245533
  validation accuracy:		13.70 %
Epoch 55 of 2000 took 0.096s
  training loss:		2.297308
  validation loss:		2.245317
  validation accuracy:		15.33 %
Epoch 56 of 2000 took 0.097s
  training loss:		2.296517
  validation loss:		2.248972
  validation accuracy:		16.96 %
Epoch 57 of 2000 took 0.097s
  training loss:		2.296663
  validation loss:		2.245090
  validation accuracy:		16.85 %
Epoch 58 of 2000 took 0.097s
  training loss:		2.296435
  validation loss:		2.247920
  validation accuracy:		13.70 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.296451
  validation loss:		2.246723
  validation accuracy:		13.48 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.295437
  validation loss:		2.245845
  validation accuracy:		13.04 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.295330
  validation loss:		2.244520
  validation accuracy:		13.59 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.294935
  validation loss:		2.245324
  validation accuracy:		18.37 %
Epoch 63 of 2000 took 0.097s
  training loss:		2.295177
  validation loss:		2.243795
  validation accuracy:		15.54 %
Epoch 64 of 2000 took 0.097s
  training loss:		2.294254
  validation loss:		2.241933
  validation accuracy:		13.15 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.295320
  validation loss:		2.244402
  validation accuracy:		17.07 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.293945
  validation loss:		2.244854
  validation accuracy:		14.46 %
Epoch 67 of 2000 took 0.097s
  training loss:		2.294608
  validation loss:		2.242871
  validation accuracy:		13.59 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.293698
  validation loss:		2.242892
  validation accuracy:		14.46 %
Epoch 69 of 2000 took 0.096s
  training loss:		2.293815
  validation loss:		2.243578
  validation accuracy:		14.46 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.293969
  validation loss:		2.243290
  validation accuracy:		15.43 %
Epoch 71 of 2000 took 0.096s
  training loss:		2.293151
  validation loss:		2.241209
  validation accuracy:		15.22 %
Epoch 72 of 2000 took 0.096s
  training loss:		2.294072
  validation loss:		2.244198
  validation accuracy:		18.15 %
Epoch 73 of 2000 took 0.097s
  training loss:		2.293137
  validation loss:		2.243459
  validation accuracy:		15.76 %
Epoch 74 of 2000 took 0.096s
  training loss:		2.293410
  validation loss:		2.240721
  validation accuracy:		16.52 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.293562
  validation loss:		2.243414
  validation accuracy:		16.63 %
Epoch 76 of 2000 took 0.097s
  training loss:		2.292156
  validation loss:		2.243076
  validation accuracy:		16.41 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.293234
  validation loss:		2.240078
  validation accuracy:		15.11 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.292849
  validation loss:		2.243663
  validation accuracy:		18.37 %
Epoch 79 of 2000 took 0.096s
  training loss:		2.292607
  validation loss:		2.241358
  validation accuracy:		14.78 %
Epoch 80 of 2000 took 0.096s
  training loss:		2.292434
  validation loss:		2.241162
  validation accuracy:		16.96 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.293501
  validation loss:		2.244709
  validation accuracy:		17.07 %
Epoch 82 of 2000 took 0.096s
  training loss:		2.292933
  validation loss:		2.246982
  validation accuracy:		15.65 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.292466
  validation loss:		2.245457
  validation accuracy:		13.91 %
Epoch 84 of 2000 took 0.097s
  training loss:		2.291637
  validation loss:		2.240189
  validation accuracy:		16.63 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.291747
  validation loss:		2.239192
  validation accuracy:		18.04 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.291679
  validation loss:		2.240978
  validation accuracy:		16.85 %
Epoch 87 of 2000 took 0.097s
  training loss:		2.290708
  validation loss:		2.239562
  validation accuracy:		15.33 %
Epoch 88 of 2000 took 0.096s
  training loss:		2.291312
  validation loss:		2.237205
  validation accuracy:		14.67 %
Epoch 89 of 2000 took 0.097s
  training loss:		2.290882
  validation loss:		2.238220
  validation accuracy:		21.74 %
Epoch 90 of 2000 took 0.096s
  training loss:		2.290974
  validation loss:		2.241444
  validation accuracy:		15.54 %
Epoch 91 of 2000 took 0.097s
  training loss:		2.291401
  validation loss:		2.244072
  validation accuracy:		19.89 %
Epoch 92 of 2000 took 0.096s
  training loss:		2.291346
  validation loss:		2.243354
  validation accuracy:		16.63 %
Epoch 93 of 2000 took 0.096s
  training loss:		2.290313
  validation loss:		2.238685
  validation accuracy:		13.91 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.289971
  validation loss:		2.237254
  validation accuracy:		15.87 %
Epoch 95 of 2000 took 0.096s
  training loss:		2.289307
  validation loss:		2.237804
  validation accuracy:		17.93 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.289708
  validation loss:		2.236825
  validation accuracy:		18.48 %
Epoch 97 of 2000 took 0.097s
  training loss:		2.289616
  validation loss:		2.239631
  validation accuracy:		17.07 %
Epoch 98 of 2000 took 0.097s
  training loss:		2.289234
  validation loss:		2.240999
  validation accuracy:		19.02 %
Epoch 99 of 2000 took 0.097s
  training loss:		2.288956
  validation loss:		2.237923
  validation accuracy:		16.41 %
Epoch 100 of 2000 took 0.097s
  training loss:		2.288617
  validation loss:		2.237346
  validation accuracy:		19.67 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.289033
  validation loss:		2.235999
  validation accuracy:		20.65 %
Epoch 102 of 2000 took 0.097s
  training loss:		2.287953
  validation loss:		2.238834
  validation accuracy:		17.28 %
Epoch 103 of 2000 took 0.100s
  training loss:		2.288096
  validation loss:		2.238331
  validation accuracy:		17.28 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.288455
  validation loss:		2.238121
  validation accuracy:		20.54 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.287335
  validation loss:		2.238429
  validation accuracy:		18.15 %
Epoch 106 of 2000 took 0.097s
  training loss:		2.288084
  validation loss:		2.235886
  validation accuracy:		16.20 %
Epoch 107 of 2000 took 0.097s
  training loss:		2.287445
  validation loss:		2.240886
  validation accuracy:		22.61 %
Epoch 108 of 2000 took 0.097s
  training loss:		2.286910
  validation loss:		2.234805
  validation accuracy:		21.85 %
Epoch 109 of 2000 took 0.096s
  training loss:		2.286721
  validation loss:		2.233672
  validation accuracy:		23.04 %
Epoch 110 of 2000 took 0.096s
  training loss:		2.286054
  validation loss:		2.234700
  validation accuracy:		20.76 %
Epoch 111 of 2000 took 0.096s
  training loss:		2.285496
  validation loss:		2.237105
  validation accuracy:		20.22 %
Epoch 112 of 2000 took 0.097s
  training loss:		2.284747
  validation loss:		2.235562
  validation accuracy:		19.13 %
Epoch 113 of 2000 took 0.096s
  training loss:		2.285944
  validation loss:		2.230183
  validation accuracy:		19.02 %
Epoch 114 of 2000 took 0.097s
  training loss:		2.284177
  validation loss:		2.231914
  validation accuracy:		19.02 %
Epoch 115 of 2000 took 0.097s
  training loss:		2.283248
  validation loss:		2.233355
  validation accuracy:		17.93 %
Epoch 116 of 2000 took 0.097s
  training loss:		2.284306
  validation loss:		2.235830
  validation accuracy:		23.91 %
Epoch 117 of 2000 took 0.096s
  training loss:		2.283246
  validation loss:		2.234528
  validation accuracy:		21.74 %
Epoch 118 of 2000 took 0.097s
  training loss:		2.282793
  validation loss:		2.231672
  validation accuracy:		21.85 %
Epoch 119 of 2000 took 0.096s
  training loss:		2.282319
  validation loss:		2.230699
  validation accuracy:		23.26 %
Epoch 120 of 2000 took 0.097s
  training loss:		2.281878
  validation loss:		2.232836
  validation accuracy:		20.76 %
Epoch 121 of 2000 took 0.097s
  training loss:		2.280311
  validation loss:		2.228025
  validation accuracy:		19.67 %
Epoch 122 of 2000 took 0.097s
  training loss:		2.279647
  validation loss:		2.227944
  validation accuracy:		24.24 %
Epoch 123 of 2000 took 0.097s
  training loss:		2.279119
  validation loss:		2.227227
  validation accuracy:		22.72 %
Epoch 124 of 2000 took 0.096s
  training loss:		2.280023
  validation loss:		2.231562
  validation accuracy:		21.85 %
Epoch 125 of 2000 took 0.097s
  training loss:		2.278381
  validation loss:		2.227819
  validation accuracy:		18.48 %
Epoch 126 of 2000 took 0.097s
  training loss:		2.276865
  validation loss:		2.225312
  validation accuracy:		23.70 %
Epoch 127 of 2000 took 0.097s
  training loss:		2.276081
  validation loss:		2.225265
  validation accuracy:		25.22 %
Epoch 128 of 2000 took 0.097s
  training loss:		2.276569
  validation loss:		2.224642
  validation accuracy:		23.80 %
Epoch 129 of 2000 took 0.096s
  training loss:		2.275549
  validation loss:		2.227925
  validation accuracy:		23.48 %
Epoch 130 of 2000 took 0.096s
  training loss:		2.273787
  validation loss:		2.223987
  validation accuracy:		22.61 %
Epoch 131 of 2000 took 0.097s
  training loss:		2.272844
  validation loss:		2.221334
  validation accuracy:		23.48 %
Epoch 132 of 2000 took 0.097s
  training loss:		2.272084
  validation loss:		2.221237
  validation accuracy:		23.70 %
Epoch 133 of 2000 took 0.097s
  training loss:		2.271026
  validation loss:		2.222116
  validation accuracy:		23.70 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.269517
  validation loss:		2.219984
  validation accuracy:		24.89 %
Epoch 135 of 2000 took 0.097s
  training loss:		2.267570
  validation loss:		2.216200
  validation accuracy:		22.61 %
Epoch 136 of 2000 took 0.096s
  training loss:		2.265232
  validation loss:		2.209367
  validation accuracy:		23.04 %
Epoch 137 of 2000 took 0.097s
  training loss:		2.263168
  validation loss:		2.210515
  validation accuracy:		24.46 %
Epoch 138 of 2000 took 0.097s
  training loss:		2.262509
  validation loss:		2.207144
  validation accuracy:		23.59 %
Epoch 139 of 2000 took 0.097s
  training loss:		2.261175
  validation loss:		2.209849
  validation accuracy:		25.98 %
Epoch 140 of 2000 took 0.097s
  training loss:		2.258225
  validation loss:		2.210120
  validation accuracy:		25.00 %
Epoch 141 of 2000 took 0.097s
  training loss:		2.255225
  validation loss:		2.204081
  validation accuracy:		24.46 %
Epoch 142 of 2000 took 0.097s
  training loss:		2.254250
  validation loss:		2.201831
  validation accuracy:		25.76 %
Epoch 143 of 2000 took 0.097s
  training loss:		2.250820
  validation loss:		2.199312
  validation accuracy:		27.93 %
Epoch 144 of 2000 took 0.096s
  training loss:		2.248848
  validation loss:		2.196615
  validation accuracy:		25.00 %
Epoch 145 of 2000 took 0.097s
  training loss:		2.243942
  validation loss:		2.195159
  validation accuracy:		25.87 %
Epoch 146 of 2000 took 0.097s
  training loss:		2.240999
  validation loss:		2.187575
  validation accuracy:		26.63 %
Epoch 147 of 2000 took 0.097s
  training loss:		2.234916
  validation loss:		2.182124
  validation accuracy:		26.52 %
Epoch 148 of 2000 took 0.097s
  training loss:		2.231236
  validation loss:		2.176317
  validation accuracy:		24.02 %
Epoch 149 of 2000 took 0.097s
  training loss:		2.226105
  validation loss:		2.171759
  validation accuracy:		27.07 %
Epoch 150 of 2000 took 0.096s
  training loss:		2.220837
  validation loss:		2.167270
  validation accuracy:		27.93 %
Epoch 151 of 2000 took 0.097s
  training loss:		2.213148
  validation loss:		2.160280
  validation accuracy:		27.39 %
Epoch 152 of 2000 took 0.097s
  training loss:		2.205764
  validation loss:		2.151375
  validation accuracy:		25.33 %
Epoch 153 of 2000 took 0.097s
  training loss:		2.196189
  validation loss:		2.144855
  validation accuracy:		26.09 %
Epoch 154 of 2000 took 0.097s
  training loss:		2.188083
  validation loss:		2.129930
  validation accuracy:		25.76 %
Epoch 155 of 2000 took 0.097s
  training loss:		2.175072
  validation loss:		2.116629
  validation accuracy:		25.87 %
Epoch 156 of 2000 took 0.097s
  training loss:		2.164529
  validation loss:		2.104447
  validation accuracy:		25.54 %
Epoch 157 of 2000 took 0.097s
  training loss:		2.147005
  validation loss:		2.086982
  validation accuracy:		29.89 %
Epoch 158 of 2000 took 0.097s
  training loss:		2.132483
  validation loss:		2.067381
  validation accuracy:		26.30 %
Epoch 159 of 2000 took 0.097s
  training loss:		2.112980
  validation loss:		2.051247
  validation accuracy:		29.24 %
Epoch 160 of 2000 took 0.097s
  training loss:		2.092546
  validation loss:		2.028733
  validation accuracy:		28.70 %
Epoch 161 of 2000 took 0.096s
  training loss:		2.067684
  validation loss:		2.002353
  validation accuracy:		28.70 %
Epoch 162 of 2000 took 0.097s
  training loss:		2.041820
  validation loss:		1.972145
  validation accuracy:		30.00 %
Epoch 163 of 2000 took 0.096s
  training loss:		2.013092
  validation loss:		1.943788
  validation accuracy:		32.17 %
Epoch 164 of 2000 took 0.097s
  training loss:		1.983527
  validation loss:		1.918058
  validation accuracy:		30.87 %
Epoch 165 of 2000 took 0.096s
  training loss:		1.953256
  validation loss:		1.882239
  validation accuracy:		32.28 %
Epoch 166 of 2000 took 0.097s
  training loss:		1.922357
  validation loss:		1.856208
  validation accuracy:		33.48 %
Epoch 167 of 2000 took 0.097s
  training loss:		1.890832
  validation loss:		1.821165
  validation accuracy:		34.78 %
Epoch 168 of 2000 took 0.097s
  training loss:		1.855216
  validation loss:		1.793189
  validation accuracy:		33.70 %
Epoch 169 of 2000 took 0.097s
  training loss:		1.831583
  validation loss:		1.764299
  validation accuracy:		33.80 %
Epoch 170 of 2000 took 0.097s
  training loss:		1.803386
  validation loss:		1.738045
  validation accuracy:		34.46 %
Epoch 171 of 2000 took 0.097s
  training loss:		1.776313
  validation loss:		1.719111
  validation accuracy:		35.65 %
Epoch 172 of 2000 took 0.097s
  training loss:		1.752567
  validation loss:		1.701601
  validation accuracy:		35.11 %
Epoch 173 of 2000 took 0.097s
  training loss:		1.733123
  validation loss:		1.669041
  validation accuracy:		37.50 %
Epoch 174 of 2000 took 0.097s
  training loss:		1.711013
  validation loss:		1.652601
  validation accuracy:		37.72 %
Epoch 175 of 2000 took 0.097s
  training loss:		1.691331
  validation loss:		1.635057
  validation accuracy:		38.37 %
Epoch 176 of 2000 took 0.097s
  training loss:		1.672037
  validation loss:		1.617301
  validation accuracy:		38.26 %
Epoch 177 of 2000 took 0.097s
  training loss:		1.658333
  validation loss:		1.605491
  validation accuracy:		40.33 %
Epoch 178 of 2000 took 0.097s
  training loss:		1.629292
  validation loss:		1.584003
  validation accuracy:		42.39 %
Epoch 179 of 2000 took 0.097s
  training loss:		1.621083
  validation loss:		1.566742
  validation accuracy:		42.61 %
Epoch 180 of 2000 took 0.097s
  training loss:		1.606519
  validation loss:		1.563581
  validation accuracy:		43.37 %
Epoch 181 of 2000 took 0.097s
  training loss:		1.588913
  validation loss:		1.531549
  validation accuracy:		45.00 %
Epoch 182 of 2000 took 0.097s
  training loss:		1.581693
  validation loss:		1.527479
  validation accuracy:		44.78 %
Epoch 183 of 2000 took 0.097s
  training loss:		1.567157
  validation loss:		1.517853
  validation accuracy:		45.65 %
Epoch 184 of 2000 took 0.097s
  training loss:		1.548785
  validation loss:		1.508590
  validation accuracy:		44.78 %
Epoch 185 of 2000 took 0.097s
  training loss:		1.540288
  validation loss:		1.485740
  validation accuracy:		46.41 %
Epoch 186 of 2000 took 0.098s
  training loss:		1.529692
  validation loss:		1.478677
  validation accuracy:		46.52 %
Epoch 187 of 2000 took 0.100s
  training loss:		1.519641
  validation loss:		1.467424
  validation accuracy:		48.37 %
Epoch 188 of 2000 took 0.100s
  training loss:		1.508464
  validation loss:		1.457025
  validation accuracy:		47.72 %
Epoch 189 of 2000 took 0.100s
  training loss:		1.497078
  validation loss:		1.441390
  validation accuracy:		48.04 %
Epoch 190 of 2000 took 0.100s
  training loss:		1.485569
  validation loss:		1.443835
  validation accuracy:		47.50 %
Epoch 191 of 2000 took 0.100s
  training loss:		1.481892
  validation loss:		1.429746
  validation accuracy:		48.70 %
Epoch 192 of 2000 took 0.100s
  training loss:		1.471679
  validation loss:		1.416859
  validation accuracy:		49.24 %
Epoch 193 of 2000 took 0.103s
  training loss:		1.467273
  validation loss:		1.412739
  validation accuracy:		49.46 %
Epoch 194 of 2000 took 0.100s
  training loss:		1.454625
  validation loss:		1.404416
  validation accuracy:		49.57 %
Epoch 195 of 2000 took 0.100s
  training loss:		1.451566
  validation loss:		1.399906
  validation accuracy:		49.78 %
Epoch 196 of 2000 took 0.100s
  training loss:		1.443542
  validation loss:		1.388012
  validation accuracy:		50.76 %
Epoch 197 of 2000 took 0.100s
  training loss:		1.432882
  validation loss:		1.467017
  validation accuracy:		44.67 %
Epoch 198 of 2000 took 0.100s
  training loss:		1.437740
  validation loss:		1.380778
  validation accuracy:		50.87 %
Epoch 199 of 2000 took 0.100s
  training loss:		1.423461
  validation loss:		1.397424
  validation accuracy:		48.48 %
Epoch 200 of 2000 took 0.100s
  training loss:		1.417990
  validation loss:		1.411372
  validation accuracy:		47.61 %
Epoch 201 of 2000 took 0.100s
  training loss:		1.415472
  validation loss:		1.362108
  validation accuracy:		51.09 %
Epoch 202 of 2000 took 0.100s
  training loss:		1.403624
  validation loss:		1.369858
  validation accuracy:		48.37 %
Epoch 203 of 2000 took 0.100s
  training loss:		1.406679
  validation loss:		1.463289
  validation accuracy:		46.30 %
Epoch 204 of 2000 took 0.100s
  training loss:		1.474806
  validation loss:		1.359641
  validation accuracy:		49.13 %
Epoch 205 of 2000 took 0.100s
  training loss:		1.427348
  validation loss:		1.360650
  validation accuracy:		50.00 %
Epoch 206 of 2000 took 0.100s
  training loss:		1.397306
  validation loss:		1.355943
  validation accuracy:		49.35 %
Epoch 207 of 2000 took 0.101s
  training loss:		1.456023
  validation loss:		1.441110
  validation accuracy:		47.17 %
Epoch 208 of 2000 took 0.100s
  training loss:		1.409460
  validation loss:		1.376503
  validation accuracy:		50.22 %
Epoch 209 of 2000 took 0.100s
  training loss:		1.385250
  validation loss:		1.348876
  validation accuracy:		50.22 %
Epoch 210 of 2000 took 0.100s
  training loss:		1.398033
  validation loss:		1.483042
  validation accuracy:		44.02 %
Epoch 211 of 2000 took 0.100s
  training loss:		1.435455
  validation loss:		1.332711
  validation accuracy:		48.70 %
Epoch 212 of 2000 took 0.100s
  training loss:		1.386388
  validation loss:		1.414371
  validation accuracy:		46.20 %
Epoch 213 of 2000 took 0.100s
  training loss:		1.382596
  validation loss:		1.374590
  validation accuracy:		49.02 %
Epoch 214 of 2000 took 0.100s
  training loss:		1.425154
  validation loss:		1.353090
  validation accuracy:		49.35 %
Epoch 215 of 2000 took 0.100s
  training loss:		1.391251
  validation loss:		1.344008
  validation accuracy:		51.52 %
Epoch 216 of 2000 took 0.100s
  training loss:		1.383409
  validation loss:		1.313424
  validation accuracy:		50.22 %
Epoch 217 of 2000 took 0.100s
  training loss:		1.407941
  validation loss:		1.419778
  validation accuracy:		48.91 %
Epoch 218 of 2000 took 0.100s
  training loss:		1.383846
  validation loss:		1.353570
  validation accuracy:		50.65 %
Epoch 219 of 2000 took 0.100s
  training loss:		1.415320
  validation loss:		1.556057
  validation accuracy:		42.72 %
Epoch 220 of 2000 took 0.100s
  training loss:		1.584830
  validation loss:		1.647741
  validation accuracy:		36.20 %
Epoch 221 of 2000 took 0.100s
  training loss:		1.431426
  validation loss:		1.330829
  validation accuracy:		52.28 %
Epoch 222 of 2000 took 0.100s
  training loss:		1.359547
  validation loss:		1.324934
  validation accuracy:		51.96 %
Epoch 223 of 2000 took 0.100s
  training loss:		1.358008
  validation loss:		1.312114
  validation accuracy:		50.54 %
Epoch 224 of 2000 took 0.100s
  training loss:		1.361050
  validation loss:		1.307371
  validation accuracy:		52.17 %
Epoch 225 of 2000 took 0.100s
  training loss:		1.363762
  validation loss:		1.378801
  validation accuracy:		49.13 %
Epoch 226 of 2000 took 0.099s
  training loss:		1.363307
  validation loss:		1.323663
  validation accuracy:		51.09 %
Epoch 227 of 2000 took 0.097s
  training loss:		1.375051
  validation loss:		1.397893
  validation accuracy:		48.48 %
Epoch 228 of 2000 took 0.097s
  training loss:		1.424039
  validation loss:		1.301737
  validation accuracy:		50.87 %
Epoch 229 of 2000 took 0.097s
  training loss:		1.402908
  validation loss:		1.302725
  validation accuracy:		50.76 %
Epoch 230 of 2000 took 0.097s
  training loss:		1.400504
  validation loss:		1.436344
  validation accuracy:		46.74 %
Epoch 231 of 2000 took 0.097s
  training loss:		1.370804
  validation loss:		1.298357
  validation accuracy:		52.28 %
Epoch 232 of 2000 took 0.097s
  training loss:		1.365694
  validation loss:		1.328430
  validation accuracy:		50.54 %
Epoch 233 of 2000 took 0.097s
  training loss:		1.351889
  validation loss:		1.310183
  validation accuracy:		51.63 %
Epoch 234 of 2000 took 0.097s
  training loss:		1.346161
  validation loss:		1.288747
  validation accuracy:		53.26 %
Epoch 235 of 2000 took 0.097s
  training loss:		1.343030
  validation loss:		1.288321
  validation accuracy:		52.39 %
Epoch 236 of 2000 took 0.097s
  training loss:		1.383809
  validation loss:		1.304255
  validation accuracy:		52.83 %
Epoch 237 of 2000 took 0.097s
  training loss:		1.340348
  validation loss:		1.294934
  validation accuracy:		52.61 %
Epoch 238 of 2000 took 0.097s
  training loss:		1.434636
  validation loss:		1.559645
  validation accuracy:		43.04 %
Epoch 239 of 2000 took 0.097s
  training loss:		1.460273
  validation loss:		1.383971
  validation accuracy:		45.65 %
Epoch 240 of 2000 took 0.097s
  training loss:		1.432535
  validation loss:		1.377985
  validation accuracy:		49.13 %
Epoch 241 of 2000 took 0.097s
  training loss:		1.348965
  validation loss:		1.314792
  validation accuracy:		51.41 %
Epoch 242 of 2000 took 0.097s
  training loss:		1.356063
  validation loss:		1.295355
  validation accuracy:		52.83 %
Epoch 243 of 2000 took 0.098s
  training loss:		1.374024
  validation loss:		1.509813
  validation accuracy:		44.67 %
Epoch 244 of 2000 took 0.097s
  training loss:		1.376621
  validation loss:		1.323516
  validation accuracy:		52.07 %
Epoch 245 of 2000 took 0.097s
  training loss:		1.407284
  validation loss:		1.465554
  validation accuracy:		45.00 %
Epoch 246 of 2000 took 0.097s
  training loss:		1.437976
  validation loss:		1.309722
  validation accuracy:		53.26 %
Epoch 247 of 2000 took 0.097s
  training loss:		1.344196
  validation loss:		1.345057
  validation accuracy:		50.87 %
Epoch 248 of 2000 took 0.097s
  training loss:		1.413718
  validation loss:		1.495248
  validation accuracy:		44.89 %
Epoch 249 of 2000 took 0.097s
  training loss:		1.378683
  validation loss:		1.291430
  validation accuracy:		52.83 %
Epoch 250 of 2000 took 0.097s
  training loss:		1.354846
  validation loss:		1.286782
  validation accuracy:		52.07 %
Epoch 251 of 2000 took 0.097s
  training loss:		1.341225
  validation loss:		1.359757
  validation accuracy:		51.09 %
Epoch 252 of 2000 took 0.097s
  training loss:		1.351581
  validation loss:		1.306497
  validation accuracy:		52.50 %
Epoch 253 of 2000 took 0.096s
  training loss:		1.327739
  validation loss:		1.304534
  validation accuracy:		52.39 %
Epoch 254 of 2000 took 0.097s
  training loss:		1.337552
  validation loss:		1.318175
  validation accuracy:		53.37 %
Epoch 255 of 2000 took 0.097s
  training loss:		1.331660
  validation loss:		1.289793
  validation accuracy:		53.04 %
Epoch 256 of 2000 took 0.097s
  training loss:		1.341750
  validation loss:		1.284325
  validation accuracy:		51.41 %
Epoch 257 of 2000 took 0.096s
  training loss:		1.365871
  validation loss:		1.325952
  validation accuracy:		52.83 %
Epoch 258 of 2000 took 0.097s
  training loss:		1.343001
  validation loss:		1.313514
  validation accuracy:		53.70 %
Epoch 259 of 2000 took 0.097s
  training loss:		1.404288
  validation loss:		1.349410
  validation accuracy:		46.74 %
Epoch 260 of 2000 took 0.097s
  training loss:		1.386457
  validation loss:		1.288222
  validation accuracy:		51.20 %
Epoch 261 of 2000 took 0.097s
  training loss:		1.332455
  validation loss:		1.303627
  validation accuracy:		54.35 %
Epoch 262 of 2000 took 0.097s
  training loss:		1.394970
  validation loss:		1.356909
  validation accuracy:		45.98 %
Epoch 263 of 2000 took 0.097s
  training loss:		1.416565
  validation loss:		1.312806
  validation accuracy:		51.96 %
Epoch 264 of 2000 took 0.097s
  training loss:		1.351431
  validation loss:		1.320849
  validation accuracy:		51.63 %
Epoch 265 of 2000 took 0.097s
  training loss:		1.345468
  validation loss:		1.294753
  validation accuracy:		51.96 %
Epoch 266 of 2000 took 0.097s
  training loss:		1.334814
  validation loss:		1.311047
  validation accuracy:		52.07 %
Epoch 267 of 2000 took 0.097s
  training loss:		1.366863
  validation loss:		1.294879
  validation accuracy:		53.15 %
Epoch 268 of 2000 took 0.097s
  training loss:		1.333663
  validation loss:		1.350058
  validation accuracy:		51.63 %
Epoch 269 of 2000 took 0.097s
  training loss:		1.440569
  validation loss:		1.445221
  validation accuracy:		47.07 %
Epoch 270 of 2000 took 0.097s
  training loss:		1.354364
  validation loss:		1.293815
  validation accuracy:		52.61 %
Epoch 271 of 2000 took 0.097s
  training loss:		1.331980
  validation loss:		1.309294
  validation accuracy:		51.63 %
Epoch 272 of 2000 took 0.097s
  training loss:		1.340761
  validation loss:		1.283469
  validation accuracy:		51.30 %
Epoch 273 of 2000 took 0.097s
  training loss:		1.424119
  validation loss:		1.279288
  validation accuracy:		52.61 %
Epoch 274 of 2000 took 0.097s
  training loss:		1.348088
  validation loss:		1.274494
  validation accuracy:		53.59 %
Epoch 275 of 2000 took 0.097s
  training loss:		1.339567
  validation loss:		1.315003
  validation accuracy:		50.76 %
Epoch 276 of 2000 took 0.097s
  training loss:		1.336432
  validation loss:		1.271182
  validation accuracy:		51.74 %
Epoch 277 of 2000 took 0.097s
  training loss:		1.324540
  validation loss:		1.280871
  validation accuracy:		53.80 %
Epoch 278 of 2000 took 0.097s
  training loss:		1.352010
  validation loss:		1.274490
  validation accuracy:		52.39 %
Epoch 279 of 2000 took 0.097s
  training loss:		1.366012
  validation loss:		1.425853
  validation accuracy:		49.13 %
Epoch 280 of 2000 took 0.097s
  training loss:		1.355885
  validation loss:		1.274258
  validation accuracy:		53.15 %
Epoch 281 of 2000 took 0.097s
  training loss:		1.382152
  validation loss:		1.475411
  validation accuracy:		47.28 %
Epoch 282 of 2000 took 0.097s
  training loss:		1.404810
  validation loss:		1.282556
  validation accuracy:		50.87 %
Epoch 283 of 2000 took 0.097s
  training loss:		1.327507
  validation loss:		1.354703
  validation accuracy:		51.30 %
Epoch 284 of 2000 took 0.097s
  training loss:		1.359840
  validation loss:		1.282645
  validation accuracy:		52.17 %
Epoch 285 of 2000 took 0.097s
  training loss:		1.328410
  validation loss:		1.286842
  validation accuracy:		50.98 %
Epoch 286 of 2000 took 0.097s
  training loss:		1.364505
  validation loss:		1.284507
  validation accuracy:		51.85 %
Epoch 287 of 2000 took 0.097s
  training loss:		1.331315
  validation loss:		1.270028
  validation accuracy:		52.93 %
Epoch 288 of 2000 took 0.097s
  training loss:		1.327328
  validation loss:		1.277978
  validation accuracy:		51.52 %
Epoch 289 of 2000 took 0.097s
  training loss:		1.326195
  validation loss:		1.390518
  validation accuracy:		49.89 %
Epoch 290 of 2000 took 0.097s
  training loss:		1.374012
  validation loss:		1.274381
  validation accuracy:		50.98 %
Epoch 291 of 2000 took 0.100s
  training loss:		1.354842
  validation loss:		1.395616
  validation accuracy:		51.09 %
Epoch 292 of 2000 took 0.097s
  training loss:		1.327698
  validation loss:		1.277224
  validation accuracy:		51.74 %
Epoch 293 of 2000 took 0.097s
  training loss:		1.329220
  validation loss:		1.258062
  validation accuracy:		53.15 %
Epoch 294 of 2000 took 0.097s
  training loss:		1.353052
  validation loss:		1.270686
  validation accuracy:		51.74 %
Epoch 295 of 2000 took 0.097s
  training loss:		1.359927
  validation loss:		1.372773
  validation accuracy:		46.85 %
Epoch 296 of 2000 took 0.097s
  training loss:		1.442207
  validation loss:		1.314115
  validation accuracy:		53.70 %
Epoch 297 of 2000 took 0.097s
  training loss:		1.350379
  validation loss:		1.263327
  validation accuracy:		52.93 %
Epoch 298 of 2000 took 0.097s
  training loss:		1.320280
  validation loss:		1.288047
  validation accuracy:		52.28 %
Epoch 299 of 2000 took 0.097s
  training loss:		1.326697
  validation loss:		1.309393
  validation accuracy:		52.61 %
Epoch 300 of 2000 took 0.097s
  training loss:		1.329382
  validation loss:		1.262086
  validation accuracy:		54.57 %
Epoch 301 of 2000 took 0.097s
  training loss:		1.334763
  validation loss:		1.290900
  validation accuracy:		53.26 %
Epoch 302 of 2000 took 0.097s
  training loss:		1.317610
  validation loss:		1.253551
  validation accuracy:		54.78 %
Epoch 303 of 2000 took 0.097s
  training loss:		1.327933
  validation loss:		1.284416
  validation accuracy:		53.15 %
Epoch 304 of 2000 took 0.097s
  training loss:		1.320749
  validation loss:		1.258858
  validation accuracy:		54.57 %
Epoch 305 of 2000 took 0.097s
  training loss:		1.313307
  validation loss:		1.285276
  validation accuracy:		51.63 %
Epoch 306 of 2000 took 0.097s
  training loss:		1.465975
  validation loss:		1.320051
  validation accuracy:		53.37 %
Epoch 307 of 2000 took 0.097s
  training loss:		1.331303
  validation loss:		1.257216
  validation accuracy:		55.22 %
Epoch 308 of 2000 took 0.097s
  training loss:		1.350395
  validation loss:		1.304534
  validation accuracy:		53.59 %
Epoch 309 of 2000 took 0.097s
  training loss:		1.319203
  validation loss:		1.257228
  validation accuracy:		53.91 %
Epoch 310 of 2000 took 0.100s
  training loss:		1.339598
  validation loss:		1.304754
  validation accuracy:		53.26 %
Epoch 311 of 2000 took 0.100s
  training loss:		1.371420
  validation loss:		1.279274
  validation accuracy:		53.59 %
Epoch 312 of 2000 took 0.100s
  training loss:		1.317998
  validation loss:		1.347229
  validation accuracy:		51.85 %
Epoch 313 of 2000 took 0.100s
  training loss:		1.323548
  validation loss:		1.367179
  validation accuracy:		51.30 %
Epoch 314 of 2000 took 0.100s
  training loss:		1.370936
  validation loss:		1.383513
  validation accuracy:		50.76 %
Epoch 315 of 2000 took 0.100s
  training loss:		1.326412
  validation loss:		1.276625
  validation accuracy:		53.26 %
Epoch 316 of 2000 took 0.100s
  training loss:		1.312630
  validation loss:		1.284578
  validation accuracy:		53.70 %
Epoch 317 of 2000 took 0.100s
  training loss:		1.319081
  validation loss:		1.263380
  validation accuracy:		54.02 %
Epoch 318 of 2000 took 0.100s
  training loss:		1.314497
  validation loss:		1.259993
  validation accuracy:		54.46 %
Epoch 319 of 2000 took 0.100s
  training loss:		1.331690
  validation loss:		1.248544
  validation accuracy:		56.20 %
Epoch 320 of 2000 took 0.100s
  training loss:		1.322191
  validation loss:		1.252602
  validation accuracy:		55.54 %
Epoch 321 of 2000 took 0.100s
  training loss:		1.310783
  validation loss:		1.255472
  validation accuracy:		55.11 %
Epoch 322 of 2000 took 0.100s
  training loss:		1.311855
  validation loss:		1.273411
  validation accuracy:		53.80 %
Epoch 323 of 2000 took 0.100s
  training loss:		1.313085
  validation loss:		1.386082
  validation accuracy:		51.41 %
Epoch 324 of 2000 took 0.100s
  training loss:		1.398094
  validation loss:		1.255547
  validation accuracy:		54.89 %
Epoch 325 of 2000 took 0.100s
  training loss:		1.331507
  validation loss:		1.276665
  validation accuracy:		54.02 %
Epoch 326 of 2000 took 0.100s
  training loss:		1.348458
  validation loss:		1.429057
  validation accuracy:		49.67 %
Epoch 327 of 2000 took 0.100s
  training loss:		1.327578
  validation loss:		1.285085
  validation accuracy:		53.80 %
Epoch 328 of 2000 took 0.100s
  training loss:		1.317611
  validation loss:		1.262123
  validation accuracy:		53.70 %
Epoch 329 of 2000 took 0.100s
  training loss:		1.326400
  validation loss:		1.307842
  validation accuracy:		53.15 %
Epoch 330 of 2000 took 0.100s
  training loss:		1.343613
  validation loss:		1.251942
  validation accuracy:		56.74 %
Epoch 331 of 2000 took 0.100s
  training loss:		1.324451
  validation loss:		1.449200
  validation accuracy:		49.24 %
Epoch 332 of 2000 took 0.100s
  training loss:		1.370398
  validation loss:		1.258036
  validation accuracy:		54.35 %
Epoch 333 of 2000 took 0.100s
  training loss:		1.322333
  validation loss:		1.269373
  validation accuracy:		54.13 %
Epoch 334 of 2000 took 0.100s
  training loss:		1.337649
  validation loss:		1.289863
  validation accuracy:		53.80 %
Epoch 335 of 2000 took 0.100s
  training loss:		1.321138
  validation loss:		1.290415
  validation accuracy:		53.70 %
Epoch 336 of 2000 took 0.100s
  training loss:		1.316517
  validation loss:		1.278827
  validation accuracy:		53.48 %
Epoch 337 of 2000 took 0.100s
  training loss:		1.312699
  validation loss:		1.299472
  validation accuracy:		54.35 %
Epoch 338 of 2000 took 0.100s
  training loss:		1.330642
  validation loss:		1.288676
  validation accuracy:		54.13 %
Epoch 339 of 2000 took 0.100s
  training loss:		1.319889
  validation loss:		1.321280
  validation accuracy:		53.26 %
Epoch 340 of 2000 took 0.100s
  training loss:		1.312843
  validation loss:		1.252276
  validation accuracy:		56.41 %
Epoch 341 of 2000 took 0.100s
  training loss:		1.323044
  validation loss:		1.263552
  validation accuracy:		55.54 %
Epoch 342 of 2000 took 0.100s
  training loss:		1.303255
  validation loss:		1.248570
  validation accuracy:		55.65 %
Epoch 343 of 2000 took 0.100s
  training loss:		1.332882
  validation loss:		1.259181
  validation accuracy:		56.09 %
Epoch 344 of 2000 took 0.100s
  training loss:		1.317131
  validation loss:		1.325452
  validation accuracy:		53.59 %
Epoch 345 of 2000 took 0.100s
  training loss:		1.309970
  validation loss:		1.254977
  validation accuracy:		54.24 %
Epoch 346 of 2000 took 0.100s
  training loss:		1.343153
  validation loss:		1.303313
  validation accuracy:		54.13 %
Epoch 347 of 2000 took 0.100s
  training loss:		1.317059
  validation loss:		1.272118
  validation accuracy:		54.67 %
Epoch 348 of 2000 took 0.100s
  training loss:		1.323936
  validation loss:		1.254233
  validation accuracy:		55.98 %
Epoch 349 of 2000 took 0.102s
  training loss:		1.315572
  validation loss:		1.276191
  validation accuracy:		54.35 %
Epoch 350 of 2000 took 0.100s
  training loss:		1.310842
  validation loss:		1.271258
  validation accuracy:		55.76 %
Epoch 351 of 2000 took 0.100s
  training loss:		1.312017
  validation loss:		1.255840
  validation accuracy:		56.63 %
Epoch 352 of 2000 took 0.100s
  training loss:		1.341187
  validation loss:		1.385806
  validation accuracy:		52.61 %
Epoch 353 of 2000 took 0.100s
  training loss:		1.317029
  validation loss:		1.286698
  validation accuracy:		54.46 %
Epoch 354 of 2000 took 0.100s
  training loss:		1.324793
  validation loss:		1.319614
  validation accuracy:		53.04 %
Epoch 355 of 2000 took 0.100s
  training loss:		1.307681
  validation loss:		1.241043
  validation accuracy:		56.52 %
Epoch 356 of 2000 took 0.100s
  training loss:		1.320422
  validation loss:		1.271745
  validation accuracy:		56.20 %
Epoch 357 of 2000 took 0.100s
  training loss:		1.310784
  validation loss:		1.280190
  validation accuracy:		54.78 %
Epoch 358 of 2000 took 0.100s
  training loss:		1.319262
  validation loss:		1.311179
  validation accuracy:		52.83 %
Epoch 359 of 2000 took 0.100s
  training loss:		1.359844
  validation loss:		1.276844
  validation accuracy:		55.33 %
Epoch 360 of 2000 took 0.100s
  training loss:		1.311888
  validation loss:		1.308211
  validation accuracy:		53.80 %
Epoch 361 of 2000 took 0.100s
  training loss:		1.314654
  validation loss:		1.267017
  validation accuracy:		56.20 %
Epoch 362 of 2000 took 0.100s
  training loss:		1.296287
  validation loss:		1.235021
  validation accuracy:		57.39 %
Epoch 363 of 2000 took 0.100s
  training loss:		1.312811
  validation loss:		1.259764
  validation accuracy:		56.74 %
Epoch 364 of 2000 took 0.100s
  training loss:		1.331671
  validation loss:		1.401196
  validation accuracy:		51.30 %
Epoch 365 of 2000 took 0.100s
  training loss:		1.359095
  validation loss:		1.246623
  validation accuracy:		57.17 %
Epoch 366 of 2000 took 0.100s
  training loss:		1.297920
  validation loss:		1.249461
  validation accuracy:		56.85 %
Epoch 367 of 2000 took 0.100s
  training loss:		1.307030
  validation loss:		1.236340
  validation accuracy:		56.52 %
Epoch 368 of 2000 took 0.100s
  training loss:		1.299419
  validation loss:		1.232084
  validation accuracy:		57.72 %
Epoch 369 of 2000 took 0.100s
  training loss:		1.331941
  validation loss:		1.258520
  validation accuracy:		57.93 %
Epoch 370 of 2000 took 0.100s
  training loss:		1.309423
  validation loss:		1.238719
  validation accuracy:		55.98 %
Epoch 371 of 2000 took 0.100s
  training loss:		1.337411
  validation loss:		1.233104
  validation accuracy:		56.63 %
Epoch 372 of 2000 took 0.100s
  training loss:		1.302230
  validation loss:		1.238567
  validation accuracy:		57.72 %
Epoch 373 of 2000 took 0.100s
  training loss:		1.309877
  validation loss:		1.234947
  validation accuracy:		58.15 %
Epoch 374 of 2000 took 0.100s
  training loss:		1.302433
  validation loss:		1.247147
  validation accuracy:		56.52 %
Epoch 375 of 2000 took 0.100s
  training loss:		1.302185
  validation loss:		1.244605
  validation accuracy:		54.35 %
Epoch 376 of 2000 took 0.100s
  training loss:		1.322952
  validation loss:		1.239031
  validation accuracy:		55.98 %
Epoch 377 of 2000 took 0.100s
  training loss:		1.318037
  validation loss:		1.307880
  validation accuracy:		54.89 %
Epoch 378 of 2000 took 0.100s
  training loss:		1.318458
  validation loss:		1.240639
  validation accuracy:		58.15 %
Epoch 379 of 2000 took 0.100s
  training loss:		1.317160
  validation loss:		1.235376
  validation accuracy:		57.50 %
Epoch 380 of 2000 took 0.100s
  training loss:		1.311670
  validation loss:		1.240867
  validation accuracy:		57.93 %
Epoch 381 of 2000 took 0.100s
  training loss:		1.280781
  validation loss:		1.228736
  validation accuracy:		58.26 %
Epoch 382 of 2000 took 0.100s
  training loss:		1.296282
  validation loss:		1.230114
  validation accuracy:		58.37 %
Epoch 383 of 2000 took 0.100s
  training loss:		1.289966
  validation loss:		1.300753
  validation accuracy:		55.65 %
Epoch 384 of 2000 took 0.100s
  training loss:		1.298674
  validation loss:		1.225059
  validation accuracy:		58.26 %
Epoch 385 of 2000 took 0.100s
  training loss:		1.297159
  validation loss:		1.247115
  validation accuracy:		58.80 %
Epoch 386 of 2000 took 0.100s
  training loss:		1.294431
  validation loss:		1.218011
  validation accuracy:		58.91 %
Epoch 387 of 2000 took 0.100s
  training loss:		1.291212
  validation loss:		1.220127
  validation accuracy:		58.15 %
Epoch 388 of 2000 took 0.100s
  training loss:		1.306188
  validation loss:		1.214825
  validation accuracy:		58.48 %
Epoch 389 of 2000 took 0.100s
  training loss:		1.286306
  validation loss:		1.248703
  validation accuracy:		59.24 %
Epoch 390 of 2000 took 0.100s
  training loss:		1.286869
  validation loss:		1.214578
  validation accuracy:		58.04 %
Epoch 391 of 2000 took 0.100s
  training loss:		1.274673
  validation loss:		1.215820
  validation accuracy:		59.46 %
Epoch 392 of 2000 took 0.100s
  training loss:		1.280255
  validation loss:		1.222111
  validation accuracy:		59.67 %
Epoch 393 of 2000 took 0.100s
  training loss:		1.279584
  validation loss:		1.204083
  validation accuracy:		59.78 %
Epoch 394 of 2000 took 0.100s
  training loss:		1.260510
  validation loss:		1.197105
  validation accuracy:		60.22 %
Epoch 395 of 2000 took 0.100s
  training loss:		1.277955
  validation loss:		1.218636
  validation accuracy:		56.52 %
Epoch 396 of 2000 took 0.100s
  training loss:		1.280816
  validation loss:		1.211704
  validation accuracy:		60.11 %
Epoch 397 of 2000 took 0.101s
  training loss:		1.281881
  validation loss:		1.197861
  validation accuracy:		60.54 %
Epoch 398 of 2000 took 0.102s
  training loss:		1.268647
  validation loss:		1.206366
  validation accuracy:		60.87 %
Epoch 399 of 2000 took 0.100s
  training loss:		1.258245
  validation loss:		1.192006
  validation accuracy:		60.87 %
Epoch 400 of 2000 took 0.100s
  training loss:		1.261014
  validation loss:		1.235191
  validation accuracy:		61.41 %
Epoch 401 of 2000 took 0.100s
  training loss:		1.262433
  validation loss:		1.176973
  validation accuracy:		62.72 %
Epoch 402 of 2000 took 0.100s
  training loss:		1.256371
  validation loss:		1.207211
  validation accuracy:		63.59 %
Epoch 403 of 2000 took 0.100s
  training loss:		1.252024
  validation loss:		1.175124
  validation accuracy:		62.50 %
Epoch 404 of 2000 took 0.100s
  training loss:		1.252425
  validation loss:		1.189947
  validation accuracy:		64.57 %
Epoch 405 of 2000 took 0.100s
  training loss:		1.236257
  validation loss:		1.170301
  validation accuracy:		62.50 %
Epoch 406 of 2000 took 0.100s
  training loss:		1.241071
  validation loss:		1.199140
  validation accuracy:		64.57 %
Epoch 407 of 2000 took 0.100s
  training loss:		1.218456
  validation loss:		1.202758
  validation accuracy:		64.13 %
Epoch 408 of 2000 took 0.100s
  training loss:		1.222498
  validation loss:		1.181471
  validation accuracy:		60.00 %
Epoch 409 of 2000 took 0.100s
  training loss:		1.209030
  validation loss:		1.127054
  validation accuracy:		66.63 %
Epoch 410 of 2000 took 0.100s
  training loss:		1.199606
  validation loss:		1.114361
  validation accuracy:		67.28 %
Epoch 411 of 2000 took 0.100s
  training loss:		1.186191
  validation loss:		1.136886
  validation accuracy:		66.85 %
Epoch 412 of 2000 took 0.100s
  training loss:		1.194763
  validation loss:		1.100074
  validation accuracy:		67.07 %
Epoch 413 of 2000 took 0.100s
  training loss:		1.173330
  validation loss:		1.135086
  validation accuracy:		66.96 %
Epoch 414 of 2000 took 0.100s
  training loss:		1.156432
  validation loss:		1.071367
  validation accuracy:		68.91 %
Epoch 415 of 2000 took 0.100s
  training loss:		1.144420
  validation loss:		1.069329
  validation accuracy:		67.83 %
Epoch 416 of 2000 took 0.100s
  training loss:		1.124792
  validation loss:		1.051151
  validation accuracy:		68.37 %
Epoch 417 of 2000 took 0.100s
  training loss:		1.116645
  validation loss:		1.039431
  validation accuracy:		68.70 %
Epoch 418 of 2000 took 0.100s
  training loss:		1.111952
  validation loss:		1.021595
  validation accuracy:		68.80 %
Epoch 419 of 2000 took 0.100s
  training loss:		1.087842
  validation loss:		1.033981
  validation accuracy:		68.37 %
Epoch 420 of 2000 took 0.100s
  training loss:		1.080610
  validation loss:		1.000188
  validation accuracy:		69.13 %
Epoch 421 of 2000 took 0.100s
  training loss:		1.081285
  validation loss:		1.010511
  validation accuracy:		68.80 %
Epoch 422 of 2000 took 0.100s
  training loss:		1.050301
  validation loss:		0.977189
  validation accuracy:		70.11 %
Epoch 423 of 2000 took 0.100s
  training loss:		1.036518
  validation loss:		0.960126
  validation accuracy:		70.65 %
Epoch 424 of 2000 took 0.100s
  training loss:		1.027889
  validation loss:		0.953970
  validation accuracy:		70.87 %
Epoch 425 of 2000 took 0.100s
  training loss:		1.012763
  validation loss:		0.963244
  validation accuracy:		70.87 %
Epoch 426 of 2000 took 0.100s
  training loss:		1.005110
  validation loss:		0.934200
  validation accuracy:		71.63 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.996187
  validation loss:		0.981609
  validation accuracy:		70.22 %
Epoch 428 of 2000 took 0.100s
  training loss:		0.971650
  validation loss:		0.892415
  validation accuracy:		72.17 %
Epoch 429 of 2000 took 0.098s
  training loss:		0.969634
  validation loss:		0.891989
  validation accuracy:		72.39 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.954462
  validation loss:		0.903915
  validation accuracy:		73.59 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.942438
  validation loss:		0.870786
  validation accuracy:		73.59 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.929970
  validation loss:		0.855519
  validation accuracy:		74.35 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.919294
  validation loss:		0.869418
  validation accuracy:		74.13 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.902929
  validation loss:		0.845656
  validation accuracy:		74.78 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.905270
  validation loss:		0.824148
  validation accuracy:		74.67 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.888025
  validation loss:		0.822822
  validation accuracy:		75.87 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.878360
  validation loss:		0.804060
  validation accuracy:		75.65 %
Epoch 438 of 2000 took 0.097s
  training loss:		0.882983
  validation loss:		0.806264
  validation accuracy:		75.76 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.865573
  validation loss:		0.810250
  validation accuracy:		75.43 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.861133
  validation loss:		0.791778
  validation accuracy:		76.30 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.852558
  validation loss:		0.834596
  validation accuracy:		74.02 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.839934
  validation loss:		0.776278
  validation accuracy:		76.30 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.836625
  validation loss:		0.771080
  validation accuracy:		76.96 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.818592
  validation loss:		0.770872
  validation accuracy:		76.20 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.817590
  validation loss:		0.768293
  validation accuracy:		75.98 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.811302
  validation loss:		0.754399
  validation accuracy:		76.74 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.795452
  validation loss:		0.777291
  validation accuracy:		75.65 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.790843
  validation loss:		0.729802
  validation accuracy:		76.96 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.784964
  validation loss:		0.732390
  validation accuracy:		77.39 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.768336
  validation loss:		0.726323
  validation accuracy:		77.07 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.772056
  validation loss:		0.743128
  validation accuracy:		76.74 %
Epoch 452 of 2000 took 0.098s
  training loss:		0.754566
  validation loss:		0.736447
  validation accuracy:		76.96 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.748031
  validation loss:		0.710821
  validation accuracy:		77.50 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.744037
  validation loss:		0.714029
  validation accuracy:		77.28 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.744486
  validation loss:		0.726168
  validation accuracy:		76.63 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.738391
  validation loss:		0.694901
  validation accuracy:		77.72 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.731959
  validation loss:		0.700056
  validation accuracy:		77.50 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.730842
  validation loss:		0.719837
  validation accuracy:		76.96 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.715621
  validation loss:		0.681530
  validation accuracy:		78.04 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.711837
  validation loss:		0.689807
  validation accuracy:		77.72 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.710838
  validation loss:		0.678915
  validation accuracy:		78.15 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.706213
  validation loss:		0.670182
  validation accuracy:		78.70 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.697056
  validation loss:		0.693829
  validation accuracy:		77.28 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.702304
  validation loss:		0.661292
  validation accuracy:		78.59 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.685493
  validation loss:		0.686483
  validation accuracy:		77.28 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.685403
  validation loss:		0.664420
  validation accuracy:		78.59 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.675228
  validation loss:		0.664944
  validation accuracy:		79.13 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.676566
  validation loss:		0.664267
  validation accuracy:		77.93 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.666192
  validation loss:		0.683000
  validation accuracy:		78.15 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.671846
  validation loss:		0.679817
  validation accuracy:		77.50 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.664206
  validation loss:		0.687963
  validation accuracy:		77.61 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.662769
  validation loss:		0.678191
  validation accuracy:		77.17 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.665568
  validation loss:		0.664119
  validation accuracy:		77.83 %
Epoch 474 of 2000 took 0.103s
  training loss:		0.651144
  validation loss:		0.647110
  validation accuracy:		78.48 %
Epoch 475 of 2000 took 0.106s
  training loss:		0.648625
  validation loss:		0.669474
  validation accuracy:		77.61 %
Epoch 476 of 2000 took 0.174s
  training loss:		0.662351
  validation loss:		0.641091
  validation accuracy:		78.91 %
Epoch 477 of 2000 took 0.104s
  training loss:		0.645044
  validation loss:		0.656260
  validation accuracy:		77.93 %
Epoch 478 of 2000 took 0.104s
  training loss:		0.645650
  validation loss:		0.649702
  validation accuracy:		78.48 %
Epoch 479 of 2000 took 0.100s
  training loss:		0.650924
  validation loss:		0.636182
  validation accuracy:		79.78 %
Epoch 480 of 2000 took 0.101s
  training loss:		0.636595
  validation loss:		0.631653
  validation accuracy:		80.43 %
Epoch 481 of 2000 took 0.103s
  training loss:		0.649158
  validation loss:		0.642273
  validation accuracy:		78.37 %
Epoch 482 of 2000 took 0.101s
  training loss:		0.643625
  validation loss:		0.630428
  validation accuracy:		79.24 %
Epoch 483 of 2000 took 0.101s
  training loss:		0.632870
  validation loss:		0.641697
  validation accuracy:		78.80 %
Epoch 484 of 2000 took 0.101s
  training loss:		0.636078
  validation loss:		0.639702
  validation accuracy:		79.35 %
Epoch 485 of 2000 took 0.100s
  training loss:		0.632373
  validation loss:		0.621241
  validation accuracy:		80.22 %
Epoch 486 of 2000 took 0.101s
  training loss:		0.627296
  validation loss:		0.623191
  validation accuracy:		79.35 %
Epoch 487 of 2000 took 0.100s
  training loss:		0.622487
  validation loss:		0.620978
  validation accuracy:		80.33 %
Epoch 488 of 2000 took 0.101s
  training loss:		0.620526
  validation loss:		0.630928
  validation accuracy:		79.57 %
Epoch 489 of 2000 took 0.100s
  training loss:		0.630992
  validation loss:		0.667360
  validation accuracy:		77.72 %
Epoch 490 of 2000 took 0.101s
  training loss:		0.627445
  validation loss:		0.673665
  validation accuracy:		77.72 %
Epoch 491 of 2000 took 0.101s
  training loss:		0.624482
  validation loss:		0.626904
  validation accuracy:		80.11 %
Epoch 492 of 2000 took 0.101s
  training loss:		0.617987
  validation loss:		0.654084
  validation accuracy:		79.67 %
Epoch 493 of 2000 took 0.101s
  training loss:		0.611638
  validation loss:		0.620303
  validation accuracy:		79.78 %
Epoch 494 of 2000 took 0.101s
  training loss:		0.631502
  validation loss:		0.625439
  validation accuracy:		79.46 %
Epoch 495 of 2000 took 0.101s
  training loss:		0.612103
  validation loss:		0.624254
  validation accuracy:		79.13 %
Epoch 496 of 2000 took 0.100s
  training loss:		0.615077
  validation loss:		0.613373
  validation accuracy:		79.46 %
Epoch 497 of 2000 took 0.101s
  training loss:		0.617647
  validation loss:		0.634860
  validation accuracy:		79.24 %
Epoch 498 of 2000 took 0.101s
  training loss:		0.621752
  validation loss:		0.613430
  validation accuracy:		80.11 %
Epoch 499 of 2000 took 0.101s
  training loss:		0.606117
  validation loss:		0.620265
  validation accuracy:		80.54 %
Epoch 500 of 2000 took 0.101s
  training loss:		0.622348
  validation loss:		0.622474
  validation accuracy:		80.43 %
Epoch 501 of 2000 took 0.100s
  training loss:		0.623315
  validation loss:		0.636083
  validation accuracy:		78.80 %
Epoch 502 of 2000 took 0.101s
  training loss:		0.617355
  validation loss:		0.620686
  validation accuracy:		80.43 %
Epoch 503 of 2000 took 0.100s
  training loss:		0.614128
  validation loss:		0.663007
  validation accuracy:		78.26 %
Epoch 504 of 2000 took 0.101s
  training loss:		0.626026
  validation loss:		0.640457
  validation accuracy:		79.02 %
Epoch 505 of 2000 took 0.101s
  training loss:		0.612672
  validation loss:		0.612958
  validation accuracy:		79.89 %
Epoch 506 of 2000 took 0.101s
  training loss:		0.636958
  validation loss:		0.618271
  validation accuracy:		80.11 %
Epoch 507 of 2000 took 0.101s
  training loss:		0.618040
  validation loss:		0.615270
  validation accuracy:		80.33 %
Epoch 508 of 2000 took 0.101s
  training loss:		0.612978
  validation loss:		0.614408
  validation accuracy:		79.89 %
Epoch 509 of 2000 took 0.101s
  training loss:		0.603414
  validation loss:		0.626295
  validation accuracy:		80.33 %
Epoch 510 of 2000 took 0.101s
  training loss:		0.599594
  validation loss:		0.626398
  validation accuracy:		80.00 %
Epoch 511 of 2000 took 0.101s
  training loss:		0.611851
  validation loss:		0.615635
  validation accuracy:		80.22 %
Epoch 512 of 2000 took 0.102s
  training loss:		0.608766
  validation loss:		0.615238
  validation accuracy:		79.89 %
Epoch 513 of 2000 took 0.101s
  training loss:		0.596803
  validation loss:		0.621433
  validation accuracy:		80.00 %
Epoch 514 of 2000 took 0.107s
  training loss:		0.606364
  validation loss:		0.620890
  validation accuracy:		79.89 %
Epoch 515 of 2000 took 0.129s
  training loss:		0.609195
  validation loss:		0.642518
  validation accuracy:		78.26 %
Epoch 516 of 2000 took 0.167s
  training loss:		0.599798
  validation loss:		0.620211
  validation accuracy:		79.78 %
Epoch 517 of 2000 took 0.105s
  training loss:		0.602911
  validation loss:		0.610014
  validation accuracy:		79.67 %
Epoch 518 of 2000 took 0.100s
  training loss:		0.596991
  validation loss:		0.630762
  validation accuracy:		79.57 %
Epoch 519 of 2000 took 0.100s
  training loss:		0.595472
  validation loss:		0.608774
  validation accuracy:		79.89 %
Epoch 520 of 2000 took 0.104s
  training loss:		0.601431
  validation loss:		0.609907
  validation accuracy:		79.89 %
Epoch 521 of 2000 took 0.110s
  training loss:		0.595266
  validation loss:		0.605735
  validation accuracy:		80.33 %
Epoch 522 of 2000 took 0.100s
  training loss:		0.584705
  validation loss:		0.600922
  validation accuracy:		80.33 %
Epoch 523 of 2000 took 0.100s
  training loss:		0.611876
  validation loss:		0.634283
  validation accuracy:		79.02 %
Epoch 524 of 2000 took 0.101s
  training loss:		0.611631
  validation loss:		0.612904
  validation accuracy:		79.57 %
Epoch 525 of 2000 took 0.100s
  training loss:		0.608562
  validation loss:		0.618342
  validation accuracy:		79.78 %
Epoch 526 of 2000 took 0.100s
  training loss:		0.604637
  validation loss:		0.598959
  validation accuracy:		80.33 %
Epoch 527 of 2000 took 0.100s
  training loss:		0.595448
  validation loss:		0.624349
  validation accuracy:		78.48 %
Epoch 528 of 2000 took 0.100s
  training loss:		0.591424
  validation loss:		0.607524
  validation accuracy:		80.00 %
Epoch 529 of 2000 took 0.100s
  training loss:		0.603698
  validation loss:		0.650515
  validation accuracy:		77.39 %
Epoch 530 of 2000 took 0.101s
  training loss:		0.616183
  validation loss:		0.635820
  validation accuracy:		78.15 %
Epoch 531 of 2000 took 0.101s
  training loss:		0.602762
  validation loss:		0.617494
  validation accuracy:		79.89 %
Epoch 532 of 2000 took 0.103s
  training loss:		0.586277
  validation loss:		0.610379
  validation accuracy:		79.67 %
Epoch 533 of 2000 took 0.103s
  training loss:		0.608512
  validation loss:		0.598167
  validation accuracy:		79.78 %
Epoch 534 of 2000 took 0.100s
  training loss:		0.599341
  validation loss:		0.603609
  validation accuracy:		80.33 %
Epoch 535 of 2000 took 0.103s
  training loss:		0.595468
  validation loss:		0.602065
  validation accuracy:		80.33 %
Epoch 536 of 2000 took 0.104s
  training loss:		0.605431
  validation loss:		0.669559
  validation accuracy:		77.28 %
Epoch 537 of 2000 took 0.103s
  training loss:		0.592550
  validation loss:		0.596222
  validation accuracy:		80.33 %
Epoch 538 of 2000 took 0.103s
  training loss:		0.582590
  validation loss:		0.607187
  validation accuracy:		79.78 %
Epoch 539 of 2000 took 0.103s
  training loss:		0.593589
  validation loss:		0.597892
  validation accuracy:		80.76 %
Epoch 540 of 2000 took 0.105s
  training loss:		0.581014
  validation loss:		0.598082
  validation accuracy:		80.54 %
Epoch 541 of 2000 took 0.103s
  training loss:		0.598763
  validation loss:		0.613825
  validation accuracy:		79.78 %
Epoch 542 of 2000 took 0.103s
  training loss:		0.616695
  validation loss:		0.601004
  validation accuracy:		80.33 %
Epoch 543 of 2000 took 0.103s
  training loss:		0.593335
  validation loss:		0.613225
  validation accuracy:		79.89 %
Epoch 544 of 2000 took 0.104s
  training loss:		0.590740
  validation loss:		0.639050
  validation accuracy:		79.02 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.587890
  validation loss:		0.657318
  validation accuracy:		78.26 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.593067
  validation loss:		0.611440
  validation accuracy:		79.78 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.590633
  validation loss:		0.605448
  validation accuracy:		79.67 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.576902
  validation loss:		0.615243
  validation accuracy:		79.67 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.593381
  validation loss:		0.616120
  validation accuracy:		79.46 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.578586
  validation loss:		0.594781
  validation accuracy:		80.11 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.575292
  validation loss:		0.598452
  validation accuracy:		80.43 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.582199
  validation loss:		0.604771
  validation accuracy:		80.22 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.592055
  validation loss:		0.673736
  validation accuracy:		77.93 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.621153
  validation loss:		0.597056
  validation accuracy:		80.43 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.585319
  validation loss:		0.628512
  validation accuracy:		79.57 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.571951
  validation loss:		0.593602
  validation accuracy:		80.43 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.596478
  validation loss:		0.624508
  validation accuracy:		79.57 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.602714
  validation loss:		0.643306
  validation accuracy:		78.15 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.615595
  validation loss:		0.625794
  validation accuracy:		78.80 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.612331
  validation loss:		0.600776
  validation accuracy:		80.11 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.578152
  validation loss:		0.621686
  validation accuracy:		79.35 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.591038
  validation loss:		0.604997
  validation accuracy:		79.78 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.587638
  validation loss:		0.612583
  validation accuracy:		78.91 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.581810
  validation loss:		0.600670
  validation accuracy:		80.33 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.598500
  validation loss:		0.620600
  validation accuracy:		79.24 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.584353
  validation loss:		0.604981
  validation accuracy:		80.00 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.586024
  validation loss:		0.603314
  validation accuracy:		79.67 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.589954
  validation loss:		0.603471
  validation accuracy:		80.22 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.586241
  validation loss:		0.644630
  validation accuracy:		78.70 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.577663
  validation loss:		0.593276
  validation accuracy:		80.43 %
Epoch 571 of 2000 took 0.098s
  training loss:		0.584365
  validation loss:		0.619167
  validation accuracy:		79.67 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.581764
  validation loss:		0.592992
  validation accuracy:		80.33 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.580665
  validation loss:		0.649628
  validation accuracy:		78.37 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.572140
  validation loss:		0.597167
  validation accuracy:		80.33 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.579579
  validation loss:		0.618275
  validation accuracy:		79.02 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.597212
  validation loss:		0.599275
  validation accuracy:		80.33 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.576148
  validation loss:		0.602081
  validation accuracy:		79.89 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.581851
  validation loss:		0.690550
  validation accuracy:		76.74 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.584539
  validation loss:		0.596978
  validation accuracy:		79.67 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.584391
  validation loss:		0.630046
  validation accuracy:		78.48 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.577445
  validation loss:		0.642799
  validation accuracy:		78.48 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.577309
  validation loss:		0.612960
  validation accuracy:		78.91 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.582990
  validation loss:		0.601744
  validation accuracy:		79.89 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.572415
  validation loss:		0.618985
  validation accuracy:		79.13 %
Epoch 585 of 2000 took 0.102s
  training loss:		0.568682
  validation loss:		0.596415
  validation accuracy:		80.00 %
Epoch 586 of 2000 took 0.103s
  training loss:		0.571100
  validation loss:		0.672100
  validation accuracy:		77.83 %
Epoch 587 of 2000 took 0.142s
  training loss:		0.600093
  validation loss:		0.595690
  validation accuracy:		80.11 %
Epoch 588 of 2000 took 0.102s
  training loss:		0.598489
  validation loss:		0.601137
  validation accuracy:		80.00 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.575848
  validation loss:		0.594993
  validation accuracy:		79.89 %
Epoch 590 of 2000 took 0.101s
  training loss:		0.580850
  validation loss:		0.588572
  validation accuracy:		80.33 %
Epoch 591 of 2000 took 0.101s
  training loss:		0.578855
  validation loss:		0.605588
  validation accuracy:		80.33 %
Epoch 592 of 2000 took 0.098s
  training loss:		0.573143
  validation loss:		0.599272
  validation accuracy:		80.00 %
Epoch 593 of 2000 took 0.098s
  training loss:		0.577781
  validation loss:		0.601579
  validation accuracy:		79.89 %
Epoch 594 of 2000 took 0.096s
  training loss:		0.586324
  validation loss:		0.596844
  validation accuracy:		80.22 %
Epoch 595 of 2000 took 0.096s
  training loss:		0.580401
  validation loss:		0.600510
  validation accuracy:		79.78 %
Epoch 596 of 2000 took 0.096s
  training loss:		0.587642
  validation loss:		0.591658
  validation accuracy:		80.00 %
Epoch 597 of 2000 took 0.096s
  training loss:		0.573631
  validation loss:		0.614950
  validation accuracy:		79.67 %
Epoch 598 of 2000 took 0.096s
  training loss:		0.580416
  validation loss:		0.654382
  validation accuracy:		77.50 %
Epoch 599 of 2000 took 0.096s
  training loss:		0.582439
  validation loss:		0.602448
  validation accuracy:		80.11 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.614528
  validation loss:		0.614934
  validation accuracy:		79.67 %
Epoch 601 of 2000 took 0.098s
  training loss:		0.584871
  validation loss:		0.602443
  validation accuracy:		80.11 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.585662
  validation loss:		0.590044
  validation accuracy:		80.22 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.575748
  validation loss:		0.597377
  validation accuracy:		79.89 %
Epoch 604 of 2000 took 0.096s
  training loss:		0.563259
  validation loss:		0.604231
  validation accuracy:		79.78 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.592694
  validation loss:		0.608600
  validation accuracy:		79.67 %
Epoch 606 of 2000 took 0.096s
  training loss:		0.582853
  validation loss:		0.587980
  validation accuracy:		80.00 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.576789
  validation loss:		0.598266
  validation accuracy:		80.22 %
Epoch 608 of 2000 took 0.096s
  training loss:		0.576131
  validation loss:		0.621874
  validation accuracy:		79.67 %
Epoch 609 of 2000 took 0.096s
  training loss:		0.582297
  validation loss:		0.596268
  validation accuracy:		80.22 %
Epoch 610 of 2000 took 0.096s
  training loss:		0.591261
  validation loss:		0.673870
  validation accuracy:		77.93 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.611261
  validation loss:		0.696087
  validation accuracy:		76.63 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.595805
  validation loss:		0.640421
  validation accuracy:		78.04 %
Epoch 613 of 2000 took 0.096s
  training loss:		0.578593
  validation loss:		0.604943
  validation accuracy:		79.24 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.577971
  validation loss:		0.588751
  validation accuracy:		80.43 %
Epoch 615 of 2000 took 0.096s
  training loss:		0.578594
  validation loss:		0.612083
  validation accuracy:		79.02 %
Epoch 616 of 2000 took 0.096s
  training loss:		0.573498
  validation loss:		0.661185
  validation accuracy:		77.39 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.579552
  validation loss:		0.590083
  validation accuracy:		80.11 %
Epoch 618 of 2000 took 0.096s
  training loss:		0.578041
  validation loss:		0.664697
  validation accuracy:		77.83 %
Epoch 619 of 2000 took 0.096s
  training loss:		0.574204
  validation loss:		0.606029
  validation accuracy:		79.89 %
Epoch 620 of 2000 took 0.096s
  training loss:		0.575228
  validation loss:		0.594459
  validation accuracy:		80.11 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.572913
  validation loss:		0.591634
  validation accuracy:		80.33 %
Epoch 622 of 2000 took 0.097s
  training loss:		0.568565
  validation loss:		0.591307
  validation accuracy:		80.54 %
Epoch 623 of 2000 took 0.097s
  training loss:		0.576963
  validation loss:		0.593440
  validation accuracy:		79.78 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.572075
  validation loss:		0.613220
  validation accuracy:		79.35 %
Epoch 625 of 2000 took 0.096s
  training loss:		0.574240
  validation loss:		0.591759
  validation accuracy:		80.11 %
Epoch 626 of 2000 took 0.098s
  training loss:		0.585433
  validation loss:		0.594984
  validation accuracy:		80.54 %
Epoch 627 of 2000 took 0.130s
  training loss:		0.573819
  validation loss:		0.596436
  validation accuracy:		80.43 %
Epoch 628 of 2000 took 0.164s
  training loss:		0.575583
  validation loss:		0.594810
  validation accuracy:		80.11 %
Epoch 629 of 2000 took 0.157s
  training loss:		0.585380
  validation loss:		0.614242
  validation accuracy:		79.24 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.563357
  validation loss:		0.628634
  validation accuracy:		78.80 %
Epoch 631 of 2000 took 0.097s
  training loss:		0.574444
  validation loss:		0.618237
  validation accuracy:		79.57 %
Epoch 632 of 2000 took 0.101s
  training loss:		0.570361
  validation loss:		0.619289
  validation accuracy:		79.57 %
Epoch 633 of 2000 took 0.106s
  training loss:		0.567565
  validation loss:		0.601326
  validation accuracy:		79.89 %
Epoch 634 of 2000 took 0.104s
  training loss:		0.568650
  validation loss:		0.600331
  validation accuracy:		80.00 %
Epoch 635 of 2000 took 0.096s
  training loss:		0.576918
  validation loss:		0.601084
  validation accuracy:		80.11 %
Epoch 636 of 2000 took 0.096s
  training loss:		0.580171
  validation loss:		0.594744
  validation accuracy:		80.43 %
Epoch 637 of 2000 took 0.096s
  training loss:		0.572548
  validation loss:		0.591463
  validation accuracy:		80.11 %
Epoch 638 of 2000 took 0.096s
  training loss:		0.570440
  validation loss:		0.598913
  validation accuracy:		79.67 %
Epoch 639 of 2000 took 0.096s
  training loss:		0.561150
  validation loss:		0.600168
  validation accuracy:		80.54 %
Epoch 640 of 2000 took 0.096s
  training loss:		0.578951
  validation loss:		0.679144
  validation accuracy:		77.72 %
Epoch 641 of 2000 took 0.100s
  training loss:		0.574338
  validation loss:		0.682104
  validation accuracy:		76.63 %
Epoch 642 of 2000 took 0.096s
  training loss:		0.576865
  validation loss:		0.606079
  validation accuracy:		79.67 %
Epoch 643 of 2000 took 0.096s
  training loss:		0.564531
  validation loss:		0.592772
  validation accuracy:		80.11 %
Epoch 644 of 2000 took 0.096s
  training loss:		0.571152
  validation loss:		0.594583
  validation accuracy:		80.43 %
Epoch 645 of 2000 took 0.101s
  training loss:		0.571113
  validation loss:		0.602350
  validation accuracy:		80.22 %
Epoch 646 of 2000 took 0.097s
  training loss:		0.565340
  validation loss:		0.592189
  validation accuracy:		80.43 %
Epoch 647 of 2000 took 0.097s
  training loss:		0.566754
  validation loss:		0.598937
  validation accuracy:		79.78 %
Epoch 648 of 2000 took 0.097s
  training loss:		0.568423
  validation loss:		0.608252
  validation accuracy:		79.67 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.574097
  validation loss:		0.612750
  validation accuracy:		79.78 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.564680
  validation loss:		0.638139
  validation accuracy:		78.80 %
Epoch 651 of 2000 took 0.097s
  training loss:		0.579447
  validation loss:		0.593527
  validation accuracy:		80.54 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.567132
  validation loss:		0.600860
  validation accuracy:		79.57 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.570418
  validation loss:		0.588337
  validation accuracy:		80.43 %
Epoch 654 of 2000 took 0.097s
  training loss:		0.576366
  validation loss:		0.609155
  validation accuracy:		79.67 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.559846
  validation loss:		0.607262
  validation accuracy:		79.89 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.568007
  validation loss:		0.597053
  validation accuracy:		80.11 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.565676
  validation loss:		0.596592
  validation accuracy:		79.78 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.586962
  validation loss:		0.603261
  validation accuracy:		80.11 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.588261
  validation loss:		0.595865
  validation accuracy:		79.89 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.565296
  validation loss:		0.592193
  validation accuracy:		80.33 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.575905
  validation loss:		0.594267
  validation accuracy:		80.43 %
Epoch 662 of 2000 took 0.098s
  training loss:		0.573399
  validation loss:		0.624649
  validation accuracy:		79.46 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.561185
  validation loss:		0.618265
  validation accuracy:		79.46 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.570691
  validation loss:		0.616698
  validation accuracy:		79.24 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.585616
  validation loss:		0.609321
  validation accuracy:		79.57 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.573384
  validation loss:		0.594996
  validation accuracy:		79.67 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.557074
  validation loss:		0.634699
  validation accuracy:		79.02 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.557915
  validation loss:		0.609881
  validation accuracy:		79.67 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.568378
  validation loss:		0.598820
  validation accuracy:		80.11 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.571900
  validation loss:		0.595467
  validation accuracy:		79.78 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.577940
  validation loss:		0.590920
  validation accuracy:		80.00 %
Epoch 672 of 2000 took 0.100s
  training loss:		0.573352
  validation loss:		0.588249
  validation accuracy:		80.22 %
Epoch 673 of 2000 took 0.100s
  training loss:		0.562229
  validation loss:		0.590328
  validation accuracy:		80.54 %
Epoch 674 of 2000 took 0.100s
  training loss:		0.562854
  validation loss:		0.601818
  validation accuracy:		79.78 %
Epoch 675 of 2000 took 0.099s
  training loss:		0.580542
  validation loss:		0.595434
  validation accuracy:		80.22 %
Epoch 676 of 2000 took 0.100s
  training loss:		0.576386
  validation loss:		0.610787
  validation accuracy:		79.46 %
Epoch 677 of 2000 took 0.100s
  training loss:		0.581291
  validation loss:		0.591076
  validation accuracy:		80.22 %
Epoch 678 of 2000 took 0.100s
  training loss:		0.566953
  validation loss:		0.599261
  validation accuracy:		80.00 %
Epoch 679 of 2000 took 0.104s
  training loss:		0.561940
  validation loss:		0.617151
  validation accuracy:		80.00 %
Epoch 680 of 2000 took 0.123s
  training loss:		0.570514
  validation loss:		0.606195
  validation accuracy:		79.89 %
Epoch 681 of 2000 took 0.123s
  training loss:		0.568436
  validation loss:		0.618673
  validation accuracy:		78.70 %
Epoch 682 of 2000 took 0.123s
  training loss:		0.564877
  validation loss:		0.609557
  validation accuracy:		79.89 %
Epoch 683 of 2000 took 0.123s
  training loss:		0.557607
  validation loss:		0.597830
  validation accuracy:		79.89 %
Epoch 684 of 2000 took 0.123s
  training loss:		0.571632
  validation loss:		0.597683
  validation accuracy:		79.78 %
Epoch 685 of 2000 took 0.123s
  training loss:		0.560895
  validation loss:		0.624521
  validation accuracy:		78.91 %
Epoch 686 of 2000 took 0.123s
  training loss:		0.574057
  validation loss:		0.605985
  validation accuracy:		79.46 %
Epoch 687 of 2000 took 0.123s
  training loss:		0.565438
  validation loss:		0.591977
  validation accuracy:		80.43 %
Epoch 688 of 2000 took 0.123s
  training loss:		0.566895
  validation loss:		0.604519
  validation accuracy:		79.13 %
Epoch 689 of 2000 took 0.123s
  training loss:		0.573990
  validation loss:		0.660977
  validation accuracy:		77.93 %
Epoch 690 of 2000 took 0.124s
  training loss:		0.575395
  validation loss:		0.597024
  validation accuracy:		80.43 %
Epoch 691 of 2000 took 0.124s
  training loss:		0.569459
  validation loss:		0.609097
  validation accuracy:		80.00 %
Epoch 692 of 2000 took 0.124s
  training loss:		0.575829
  validation loss:		0.627826
  validation accuracy:		78.59 %
Epoch 693 of 2000 took 0.124s
  training loss:		0.570027
  validation loss:		0.612920
  validation accuracy:		80.00 %
Epoch 694 of 2000 took 0.124s
  training loss:		0.577828
  validation loss:		0.621862
  validation accuracy:		78.70 %
Epoch 695 of 2000 took 0.124s
  training loss:		0.581076
  validation loss:		0.666574
  validation accuracy:		77.17 %
Epoch 696 of 2000 took 0.119s
  training loss:		0.589511
  validation loss:		0.598295
  validation accuracy:		79.46 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.573628
  validation loss:		0.616547
  validation accuracy:		79.35 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.562823
  validation loss:		0.608033
  validation accuracy:		79.78 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.559183
  validation loss:		0.596868
  validation accuracy:		80.43 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.568133
  validation loss:		0.619355
  validation accuracy:		79.24 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.565747
  validation loss:		0.598889
  validation accuracy:		80.33 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.557095
  validation loss:		0.610695
  validation accuracy:		79.67 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.554814
  validation loss:		0.597977
  validation accuracy:		79.57 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.551915
  validation loss:		0.594810
  validation accuracy:		80.22 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.566639
  validation loss:		0.598748
  validation accuracy:		79.78 %
Epoch 706 of 2000 took 0.097s
  training loss:		0.570216
  validation loss:		0.600756
  validation accuracy:		79.89 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.562598
  validation loss:		0.610619
  validation accuracy:		80.22 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.561811
  validation loss:		0.599138
  validation accuracy:		79.13 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.558303
  validation loss:		0.599130
  validation accuracy:		80.33 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.568059
  validation loss:		0.619124
  validation accuracy:		79.24 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.571320
  validation loss:		0.597361
  validation accuracy:		80.43 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.569094
  validation loss:		0.601979
  validation accuracy:		79.89 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.559131
  validation loss:		0.601060
  validation accuracy:		80.98 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.563401
  validation loss:		0.591322
  validation accuracy:		79.89 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.569542
  validation loss:		0.643544
  validation accuracy:		78.04 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.579882
  validation loss:		0.593492
  validation accuracy:		79.78 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.562675
  validation loss:		0.608143
  validation accuracy:		80.22 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.572433
  validation loss:		0.601140
  validation accuracy:		80.00 %
Epoch 719 of 2000 took 0.097s
  training loss:		0.571466
  validation loss:		0.602212
  validation accuracy:		79.67 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.577324
  validation loss:		0.589867
  validation accuracy:		79.89 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.564386
  validation loss:		0.596540
  validation accuracy:		80.00 %
Epoch 722 of 2000 took 0.097s
  training loss:		0.563627
  validation loss:		0.612199
  validation accuracy:		79.57 %
Epoch 723 of 2000 took 0.097s
  training loss:		0.564250
  validation loss:		0.595203
  validation accuracy:		80.33 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.572228
  validation loss:		0.601850
  validation accuracy:		79.24 %
Epoch 725 of 2000 took 0.097s
  training loss:		0.553832
  validation loss:		0.636918
  validation accuracy:		78.91 %
Epoch 726 of 2000 took 0.097s
  training loss:		0.560259
  validation loss:		0.592801
  validation accuracy:		80.87 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.563699
  validation loss:		0.592017
  validation accuracy:		80.54 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.566725
  validation loss:		0.594373
  validation accuracy:		80.87 %
Epoch 729 of 2000 took 0.097s
  training loss:		0.588911
  validation loss:		0.604480
  validation accuracy:		80.76 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.562944
  validation loss:		0.625705
  validation accuracy:		79.78 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.566839
  validation loss:		0.600325
  validation accuracy:		80.22 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.561985
  validation loss:		0.590855
  validation accuracy:		80.43 %
Epoch 733 of 2000 took 0.097s
  training loss:		0.552717
  validation loss:		0.595303
  validation accuracy:		80.76 %
Epoch 734 of 2000 took 0.097s
  training loss:		0.554166
  validation loss:		0.594624
  validation accuracy:		80.00 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.571836
  validation loss:		0.642630
  validation accuracy:		78.37 %
Epoch 736 of 2000 took 0.097s
  training loss:		0.563862
  validation loss:		0.593635
  validation accuracy:		80.54 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.563196
  validation loss:		0.594271
  validation accuracy:		80.87 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.557324
  validation loss:		0.594120
  validation accuracy:		80.65 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.558638
  validation loss:		0.622557
  validation accuracy:		78.91 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.558783
  validation loss:		0.588729
  validation accuracy:		80.33 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.560216
  validation loss:		0.624074
  validation accuracy:		79.46 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.555700
  validation loss:		0.610306
  validation accuracy:		79.02 %
Epoch 743 of 2000 took 0.097s
  training loss:		0.566809
  validation loss:		0.623549
  validation accuracy:		78.91 %
Epoch 744 of 2000 took 0.097s
  training loss:		0.558207
  validation loss:		0.593585
  validation accuracy:		80.22 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.546322
  validation loss:		0.611604
  validation accuracy:		79.35 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.558955
  validation loss:		0.599630
  validation accuracy:		79.78 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.566668
  validation loss:		0.613499
  validation accuracy:		79.24 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.558555
  validation loss:		0.591127
  validation accuracy:		80.65 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.550059
  validation loss:		0.610880
  validation accuracy:		79.67 %
Epoch 750 of 2000 took 0.098s
  training loss:		0.557356
  validation loss:		0.612891
  validation accuracy:		80.87 %
Epoch 751 of 2000 took 0.097s
  training loss:		0.580646
  validation loss:		0.597941
  validation accuracy:		80.00 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.550884
  validation loss:		0.624972
  validation accuracy:		79.13 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.563439
  validation loss:		0.591954
  validation accuracy:		79.89 %
Epoch 754 of 2000 took 0.097s
  training loss:		0.548959
  validation loss:		0.593050
  validation accuracy:		80.00 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.552225
  validation loss:		0.615054
  validation accuracy:		79.24 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.545861
  validation loss:		0.593802
  validation accuracy:		79.89 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.558059
  validation loss:		0.604457
  validation accuracy:		80.22 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.565267
  validation loss:		0.595407
  validation accuracy:		80.00 %
Epoch 759 of 2000 took 0.097s
  training loss:		0.558221
  validation loss:		0.596916
  validation accuracy:		79.46 %
Epoch 760 of 2000 took 0.097s
  training loss:		0.547692
  validation loss:		0.588790
  validation accuracy:		80.33 %
Epoch 761 of 2000 took 0.097s
  training loss:		0.552564
  validation loss:		0.590136
  validation accuracy:		80.00 %
Epoch 762 of 2000 took 0.097s
  training loss:		0.551881
  validation loss:		0.659717
  validation accuracy:		77.61 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.557409
  validation loss:		0.598632
  validation accuracy:		79.57 %
Epoch 764 of 2000 took 0.097s
  training loss:		0.554131
  validation loss:		0.595831
  validation accuracy:		80.00 %
Epoch 765 of 2000 took 0.097s
  training loss:		0.563947
  validation loss:		0.614648
  validation accuracy:		78.80 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.555775
  validation loss:		0.586893
  validation accuracy:		80.98 %
Epoch 767 of 2000 took 0.097s
  training loss:		0.553938
  validation loss:		0.608952
  validation accuracy:		79.35 %
Epoch 768 of 2000 took 0.097s
  training loss:		0.554715
  validation loss:		0.588714
  validation accuracy:		80.33 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.552417
  validation loss:		0.591695
  validation accuracy:		80.33 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.550475
  validation loss:		0.591928
  validation accuracy:		80.33 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.550272
  validation loss:		0.589325
  validation accuracy:		81.52 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.569311
  validation loss:		0.593837
  validation accuracy:		81.52 %
Epoch 773 of 2000 took 0.097s
  training loss:		0.563121
  validation loss:		0.608285
  validation accuracy:		79.35 %
Epoch 774 of 2000 took 0.097s
  training loss:		0.569410
  validation loss:		0.594413
  validation accuracy:		81.30 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.550625
  validation loss:		0.593825
  validation accuracy:		81.30 %
Epoch 776 of 2000 took 0.097s
  training loss:		0.557539
  validation loss:		0.593756
  validation accuracy:		81.52 %
Epoch 777 of 2000 took 0.097s
  training loss:		0.546478
  validation loss:		0.584175
  validation accuracy:		80.65 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.541131
  validation loss:		0.607145
  validation accuracy:		81.41 %
Epoch 779 of 2000 took 0.097s
  training loss:		0.554985
  validation loss:		0.589534
  validation accuracy:		80.43 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.551564
  validation loss:		0.599306
  validation accuracy:		79.46 %
Epoch 781 of 2000 took 0.100s
  training loss:		0.547245
  validation loss:		0.585141
  validation accuracy:		80.76 %
Epoch 782 of 2000 took 0.097s
  training loss:		0.554197
  validation loss:		0.592568
  validation accuracy:		81.09 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.547006
  validation loss:		0.595978
  validation accuracy:		80.33 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.539719
  validation loss:		0.599650
  validation accuracy:		80.33 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.544138
  validation loss:		0.594718
  validation accuracy:		79.67 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.538161
  validation loss:		0.600757
  validation accuracy:		79.78 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.544396
  validation loss:		0.598351
  validation accuracy:		81.41 %
Epoch 788 of 2000 took 0.097s
  training loss:		0.551304
  validation loss:		0.592356
  validation accuracy:		79.89 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.547737
  validation loss:		0.619177
  validation accuracy:		80.43 %
Epoch 790 of 2000 took 0.097s
  training loss:		0.545503
  validation loss:		0.607526
  validation accuracy:		79.57 %
Epoch 791 of 2000 took 0.097s
  training loss:		0.545834
  validation loss:		0.584597
  validation accuracy:		80.87 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.565734
  validation loss:		0.589846
  validation accuracy:		81.41 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.541442
  validation loss:		0.658834
  validation accuracy:		78.15 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.547154
  validation loss:		0.616147
  validation accuracy:		79.57 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.540888
  validation loss:		0.592120
  validation accuracy:		79.89 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.547096
  validation loss:		0.586049
  validation accuracy:		81.09 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.539236
  validation loss:		0.596490
  validation accuracy:		81.63 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.556849
  validation loss:		0.591723
  validation accuracy:		80.00 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.547285
  validation loss:		0.613164
  validation accuracy:		79.35 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.552633
  validation loss:		0.594823
  validation accuracy:		81.63 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.550602
  validation loss:		0.585829
  validation accuracy:		80.76 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.537510
  validation loss:		0.666861
  validation accuracy:		78.15 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.551359
  validation loss:		0.595348
  validation accuracy:		81.30 %
Epoch 804 of 2000 took 0.098s
  training loss:		0.550652
  validation loss:		0.581837
  validation accuracy:		80.98 %
Epoch 805 of 2000 took 0.103s
  training loss:		0.546789
  validation loss:		0.595963
  validation accuracy:		81.52 %
Epoch 806 of 2000 took 0.103s
  training loss:		0.541118
  validation loss:		0.580316
  validation accuracy:		81.09 %
Epoch 807 of 2000 took 0.103s
  training loss:		0.540680
  validation loss:		0.604111
  validation accuracy:		79.57 %
Epoch 808 of 2000 took 0.103s
  training loss:		0.539987
  validation loss:		0.587508
  validation accuracy:		80.22 %
Epoch 809 of 2000 took 0.103s
  training loss:		0.531096
  validation loss:		0.587114
  validation accuracy:		80.43 %
Epoch 810 of 2000 took 0.103s
  training loss:		0.551560
  validation loss:		0.626847
  validation accuracy:		78.80 %
Epoch 811 of 2000 took 0.102s
  training loss:		0.546789
  validation loss:		0.589667
  validation accuracy:		81.52 %
Epoch 812 of 2000 took 0.099s
  training loss:		0.537327
  validation loss:		0.590353
  validation accuracy:		79.78 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.548470
  validation loss:		0.586158
  validation accuracy:		80.98 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.541116
  validation loss:		0.591084
  validation accuracy:		81.74 %
Epoch 815 of 2000 took 0.097s
  training loss:		0.546745
  validation loss:		0.588419
  validation accuracy:		81.96 %
Epoch 816 of 2000 took 0.097s
  training loss:		0.541918
  validation loss:		0.625481
  validation accuracy:		80.11 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.555928
  validation loss:		0.582766
  validation accuracy:		80.76 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.535760
  validation loss:		0.581956
  validation accuracy:		80.33 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.538624
  validation loss:		0.609312
  validation accuracy:		79.78 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.543050
  validation loss:		0.586887
  validation accuracy:		82.50 %
Epoch 821 of 2000 took 0.097s
  training loss:		0.531239
  validation loss:		0.597782
  validation accuracy:		79.67 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.539450
  validation loss:		0.578947
  validation accuracy:		81.74 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.542997
  validation loss:		0.589105
  validation accuracy:		82.61 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.527884
  validation loss:		0.600353
  validation accuracy:		80.11 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.549398
  validation loss:		0.578634
  validation accuracy:		80.76 %
Epoch 826 of 2000 took 0.097s
  training loss:		0.550596
  validation loss:		0.618100
  validation accuracy:		79.57 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.555738
  validation loss:		0.585273
  validation accuracy:		81.09 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.537238
  validation loss:		0.579832
  validation accuracy:		80.98 %
Epoch 829 of 2000 took 0.097s
  training loss:		0.530607
  validation loss:		0.601215
  validation accuracy:		81.09 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.533885
  validation loss:		0.584994
  validation accuracy:		80.43 %
Epoch 831 of 2000 took 0.097s
  training loss:		0.531104
  validation loss:		0.576372
  validation accuracy:		82.07 %
Epoch 832 of 2000 took 0.097s
  training loss:		0.528174
  validation loss:		0.594827
  validation accuracy:		80.33 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.537092
  validation loss:		0.580551
  validation accuracy:		82.50 %
Epoch 834 of 2000 took 0.097s
  training loss:		0.545056
  validation loss:		0.595325
  validation accuracy:		79.78 %
Epoch 835 of 2000 took 0.097s
  training loss:		0.538873
  validation loss:		0.589665
  validation accuracy:		81.30 %
Epoch 836 of 2000 took 0.097s
  training loss:		0.536397
  validation loss:		0.576401
  validation accuracy:		82.39 %
Epoch 837 of 2000 took 0.097s
  training loss:		0.531413
  validation loss:		0.588176
  validation accuracy:		80.65 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.527160
  validation loss:		0.596765
  validation accuracy:		79.67 %
Epoch 839 of 2000 took 0.097s
  training loss:		0.529092
  validation loss:		0.609561
  validation accuracy:		81.09 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.541180
  validation loss:		0.577766
  validation accuracy:		81.74 %
Epoch 841 of 2000 took 0.097s
  training loss:		0.546100
  validation loss:		0.601018
  validation accuracy:		80.22 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.535555
  validation loss:		0.598974
  validation accuracy:		80.65 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.536103
  validation loss:		0.590486
  validation accuracy:		81.41 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.533619
  validation loss:		0.600369
  validation accuracy:		79.78 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.542763
  validation loss:		0.586887
  validation accuracy:		80.76 %
Epoch 846 of 2000 took 0.098s
  training loss:		0.545448
  validation loss:		0.581512
  validation accuracy:		81.30 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.534399
  validation loss:		0.594283
  validation accuracy:		79.67 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.536950
  validation loss:		0.579485
  validation accuracy:		80.87 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.551399
  validation loss:		0.603358
  validation accuracy:		81.09 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.531428
  validation loss:		0.586526
  validation accuracy:		82.61 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.545280
  validation loss:		0.582250
  validation accuracy:		82.07 %
Epoch 852 of 2000 took 0.097s
  training loss:		0.537053
  validation loss:		0.577978
  validation accuracy:		81.63 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.537761
  validation loss:		0.581815
  validation accuracy:		83.04 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.545751
  validation loss:		0.592678
  validation accuracy:		80.11 %
Epoch 855 of 2000 took 0.097s
  training loss:		0.536462
  validation loss:		0.582808
  validation accuracy:		81.52 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.538175
  validation loss:		0.575554
  validation accuracy:		81.41 %
Epoch 857 of 2000 took 0.097s
  training loss:		0.534795
  validation loss:		0.583775
  validation accuracy:		82.28 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.532497
  validation loss:		0.588639
  validation accuracy:		81.52 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.534731
  validation loss:		0.594095
  validation accuracy:		80.76 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.527904
  validation loss:		0.585384
  validation accuracy:		80.87 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.530139
  validation loss:		0.581594
  validation accuracy:		83.04 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.534616
  validation loss:		0.577392
  validation accuracy:		81.63 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.524413
  validation loss:		0.588697
  validation accuracy:		81.41 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.529177
  validation loss:		0.585066
  validation accuracy:		80.87 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.536239
  validation loss:		0.578468
  validation accuracy:		81.52 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.527854
  validation loss:		0.583623
  validation accuracy:		82.39 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.526913
  validation loss:		0.588964
  validation accuracy:		80.65 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.528784
  validation loss:		0.581794
  validation accuracy:		80.98 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.533094
  validation loss:		0.580779
  validation accuracy:		81.30 %
Epoch 870 of 2000 took 0.098s
  training loss:		0.536454
  validation loss:		0.594047
  validation accuracy:		80.65 %
Epoch 871 of 2000 took 0.102s
  training loss:		0.534449
  validation loss:		0.620553
  validation accuracy:		80.43 %
Epoch 872 of 2000 took 0.103s
  training loss:		0.542173
  validation loss:		0.592497
  validation accuracy:		80.22 %
Epoch 873 of 2000 took 0.103s
  training loss:		0.543230
  validation loss:		0.599708
  validation accuracy:		80.22 %
Epoch 874 of 2000 took 0.104s
  training loss:		0.537079
  validation loss:		0.587562
  validation accuracy:		80.76 %
Epoch 875 of 2000 took 0.103s
  training loss:		0.543579
  validation loss:		0.581394
  validation accuracy:		81.63 %
Epoch 876 of 2000 took 0.103s
  training loss:		0.538281
  validation loss:		0.595902
  validation accuracy:		81.30 %
Epoch 877 of 2000 took 0.103s
  training loss:		0.538415
  validation loss:		0.583728
  validation accuracy:		82.17 %
Epoch 878 of 2000 took 0.103s
  training loss:		0.526136
  validation loss:		0.586767
  validation accuracy:		81.96 %
Epoch 879 of 2000 took 0.103s
  training loss:		0.521755
  validation loss:		0.579491
  validation accuracy:		81.30 %
Epoch 880 of 2000 took 0.103s
  training loss:		0.530933
  validation loss:		0.577552
  validation accuracy:		82.28 %
Epoch 881 of 2000 took 0.103s
  training loss:		0.534534
  validation loss:		0.580808
  validation accuracy:		81.52 %
Epoch 882 of 2000 took 0.103s
  training loss:		0.532040
  validation loss:		0.584728
  validation accuracy:		82.50 %
Epoch 883 of 2000 took 0.103s
  training loss:		0.521489
  validation loss:		0.595197
  validation accuracy:		81.52 %
Epoch 884 of 2000 took 0.103s
  training loss:		0.538861
  validation loss:		0.582947
  validation accuracy:		82.72 %
Epoch 885 of 2000 took 0.103s
  training loss:		0.527635
  validation loss:		0.603239
  validation accuracy:		80.43 %
Epoch 886 of 2000 took 0.103s
  training loss:		0.532034
  validation loss:		0.590347
  validation accuracy:		80.65 %
Epoch 887 of 2000 took 0.103s
  training loss:		0.553459
  validation loss:		0.578056
  validation accuracy:		82.72 %
Epoch 888 of 2000 took 0.103s
  training loss:		0.525045
  validation loss:		0.603683
  validation accuracy:		80.43 %
Epoch 889 of 2000 took 0.103s
  training loss:		0.537453
  validation loss:		0.583304
  validation accuracy:		81.30 %
Epoch 890 of 2000 took 0.103s
  training loss:		0.537116
  validation loss:		0.581399
  validation accuracy:		82.07 %
Epoch 891 of 2000 took 0.103s
  training loss:		0.533789
  validation loss:		0.580411
  validation accuracy:		81.63 %
Epoch 892 of 2000 took 0.101s
  training loss:		0.541507
  validation loss:		0.594313
  validation accuracy:		80.87 %
Epoch 893 of 2000 took 0.100s
  training loss:		0.542526
  validation loss:		0.596467
  validation accuracy:		81.74 %
Epoch 894 of 2000 took 0.100s
  training loss:		0.536604
  validation loss:		0.579558
  validation accuracy:		80.98 %
Epoch 895 of 2000 took 0.100s
  training loss:		0.520620
  validation loss:		0.589852
  validation accuracy:		80.54 %
Epoch 896 of 2000 took 0.100s
  training loss:		0.531515
  validation loss:		0.588991
  validation accuracy:		82.28 %
Epoch 897 of 2000 took 0.100s
  training loss:		0.528095
  validation loss:		0.578906
  validation accuracy:		81.63 %
Epoch 898 of 2000 took 0.100s
  training loss:		0.532956
  validation loss:		0.584688
  validation accuracy:		81.52 %
Epoch 899 of 2000 took 0.100s
  training loss:		0.529743
  validation loss:		0.580055
  validation accuracy:		81.74 %
Epoch 900 of 2000 took 0.100s
  training loss:		0.526505
  validation loss:		0.590994
  validation accuracy:		80.65 %
Epoch 901 of 2000 took 0.100s
  training loss:		0.532097
  validation loss:		0.583552
  validation accuracy:		81.09 %
Epoch 902 of 2000 took 0.100s
  training loss:		0.533876
  validation loss:		0.577597
  validation accuracy:		82.28 %
Epoch 903 of 2000 took 0.100s
  training loss:		0.542053
  validation loss:		0.580338
  validation accuracy:		81.20 %
Epoch 904 of 2000 took 0.101s
  training loss:		0.525979
  validation loss:		0.618107
  validation accuracy:		80.65 %
Epoch 905 of 2000 took 0.100s
  training loss:		0.540146
  validation loss:		0.581373
  validation accuracy:		81.85 %
Epoch 906 of 2000 took 0.100s
  training loss:		0.539220
  validation loss:		0.576883
  validation accuracy:		82.07 %
Epoch 907 of 2000 took 0.100s
  training loss:		0.538441
  validation loss:		0.580415
  validation accuracy:		82.07 %
Epoch 908 of 2000 took 0.100s
  training loss:		0.534871
  validation loss:		0.601380
  validation accuracy:		81.96 %
Epoch 909 of 2000 took 0.100s
  training loss:		0.535025
  validation loss:		0.580802
  validation accuracy:		82.72 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.537273
  validation loss:		0.579473
  validation accuracy:		81.41 %
Epoch 911 of 2000 took 0.097s
  training loss:		0.531704
  validation loss:		0.581652
  validation accuracy:		82.83 %
Epoch 912 of 2000 took 0.097s
  training loss:		0.530422
  validation loss:		0.585298
  validation accuracy:		81.20 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.532610
  validation loss:		0.591591
  validation accuracy:		81.96 %
Epoch 914 of 2000 took 0.097s
  training loss:		0.537950
  validation loss:		0.602777
  validation accuracy:		79.57 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.528743
  validation loss:		0.582125
  validation accuracy:		82.50 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.531927
  validation loss:		0.620139
  validation accuracy:		80.00 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.539186
  validation loss:		0.576305
  validation accuracy:		81.96 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.518539
  validation loss:		0.585778
  validation accuracy:		80.87 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.528261
  validation loss:		0.588521
  validation accuracy:		80.76 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.532786
  validation loss:		0.593159
  validation accuracy:		81.74 %
Epoch 921 of 2000 took 0.097s
  training loss:		0.523273
  validation loss:		0.590492
  validation accuracy:		81.74 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.527675
  validation loss:		0.598870
  validation accuracy:		80.87 %
Epoch 923 of 2000 took 0.097s
  training loss:		0.538443
  validation loss:		0.580693
  validation accuracy:		81.96 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.535170
  validation loss:		0.619167
  validation accuracy:		79.24 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.529019
  validation loss:		0.590571
  validation accuracy:		80.33 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.531075
  validation loss:		0.583177
  validation accuracy:		80.98 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.542382
  validation loss:		0.600379
  validation accuracy:		80.00 %
Epoch 928 of 2000 took 0.097s
  training loss:		0.539049
  validation loss:		0.580657
  validation accuracy:		81.52 %
Epoch 929 of 2000 took 0.097s
  training loss:		0.520561
  validation loss:		0.576761
  validation accuracy:		82.07 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.530237
  validation loss:		0.581444
  validation accuracy:		81.85 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.521089
  validation loss:		0.579184
  validation accuracy:		81.96 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.538507
  validation loss:		0.601595
  validation accuracy:		80.22 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.535378
  validation loss:		0.586973
  validation accuracy:		80.98 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.532288
  validation loss:		0.581571
  validation accuracy:		81.52 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.530591
  validation loss:		0.597698
  validation accuracy:		80.54 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.550492
  validation loss:		0.590716
  validation accuracy:		81.41 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.530322
  validation loss:		0.580446
  validation accuracy:		82.39 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.545999
  validation loss:		0.579161
  validation accuracy:		81.85 %
Epoch 939 of 2000 took 0.100s
  training loss:		0.526941
  validation loss:		0.591951
  validation accuracy:		80.43 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.531883
  validation loss:		0.592846
  validation accuracy:		82.17 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.523083
  validation loss:		0.591863
  validation accuracy:		82.50 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.531177
  validation loss:		0.601491
  validation accuracy:		81.41 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.530493
  validation loss:		0.586622
  validation accuracy:		81.85 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.527968
  validation loss:		0.585631
  validation accuracy:		80.98 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.526034
  validation loss:		0.596744
  validation accuracy:		81.09 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.523652
  validation loss:		0.579277
  validation accuracy:		81.41 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.525533
  validation loss:		0.592718
  validation accuracy:		80.76 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.537748
  validation loss:		0.584395
  validation accuracy:		82.93 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.525009
  validation loss:		0.578254
  validation accuracy:		82.50 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.535794
  validation loss:		0.597066
  validation accuracy:		80.33 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.538753
  validation loss:		0.615937
  validation accuracy:		79.67 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.533530
  validation loss:		0.581518
  validation accuracy:		81.09 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.530765
  validation loss:		0.581177
  validation accuracy:		81.30 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.529595
  validation loss:		0.596506
  validation accuracy:		81.63 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.532688
  validation loss:		0.610564
  validation accuracy:		80.54 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.527821
  validation loss:		0.582541
  validation accuracy:		81.09 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.521573
  validation loss:		0.588657
  validation accuracy:		81.30 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.529952
  validation loss:		0.585781
  validation accuracy:		80.87 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.529523
  validation loss:		0.604219
  validation accuracy:		79.35 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.533173
  validation loss:		0.580559
  validation accuracy:		81.74 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.536106
  validation loss:		0.584412
  validation accuracy:		82.39 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.523379
  validation loss:		0.578428
  validation accuracy:		81.96 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.527638
  validation loss:		0.583513
  validation accuracy:		81.63 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.536155
  validation loss:		0.596936
  validation accuracy:		80.98 %
Epoch 965 of 2000 took 0.099s
  training loss:		0.520992
  validation loss:		0.586179
  validation accuracy:		81.96 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.547656
  validation loss:		0.580563
  validation accuracy:		83.04 %
Epoch 967 of 2000 took 0.096s
  training loss:		0.532651
  validation loss:		0.583085
  validation accuracy:		82.28 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.523337
  validation loss:		0.588121
  validation accuracy:		81.41 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.532052
  validation loss:		0.667813
  validation accuracy:		77.93 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.525279
  validation loss:		0.592304
  validation accuracy:		80.54 %
Epoch 971 of 2000 took 0.096s
  training loss:		0.523058
  validation loss:		0.588192
  validation accuracy:		82.61 %
Epoch 972 of 2000 took 0.096s
  training loss:		0.528459
  validation loss:		0.591972
  validation accuracy:		80.65 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.526489
  validation loss:		0.582018
  validation accuracy:		81.96 %
Epoch 974 of 2000 took 0.096s
  training loss:		0.546578
  validation loss:		0.593197
  validation accuracy:		80.43 %
Epoch 975 of 2000 took 0.096s
  training loss:		0.527281
  validation loss:		0.581096
  validation accuracy:		81.20 %
Epoch 976 of 2000 took 0.096s
  training loss:		0.526413
  validation loss:		0.587330
  validation accuracy:		80.76 %
Epoch 977 of 2000 took 0.096s
  training loss:		0.528629
  validation loss:		0.587260
  validation accuracy:		80.76 %
Epoch 978 of 2000 took 0.096s
  training loss:		0.529123
  validation loss:		0.584795
  validation accuracy:		81.09 %
Epoch 979 of 2000 took 0.096s
  training loss:		0.535923
  validation loss:		0.581390
  validation accuracy:		81.20 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.542665
  validation loss:		0.578881
  validation accuracy:		81.41 %
Epoch 981 of 2000 took 0.096s
  training loss:		0.533625
  validation loss:		0.602879
  validation accuracy:		79.35 %
Epoch 982 of 2000 took 0.096s
  training loss:		0.539484
  validation loss:		0.601454
  validation accuracy:		81.63 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.530329
  validation loss:		0.612484
  validation accuracy:		79.67 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.546358
  validation loss:		0.580613
  validation accuracy:		81.52 %
Epoch 985 of 2000 took 0.096s
  training loss:		0.529728
  validation loss:		0.601118
  validation accuracy:		81.63 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.540878
  validation loss:		0.610119
  validation accuracy:		78.91 %
Epoch 987 of 2000 took 0.096s
  training loss:		0.527899
  validation loss:		0.579382
  validation accuracy:		81.41 %
Epoch 988 of 2000 took 0.096s
  training loss:		0.542507
  validation loss:		0.591479
  validation accuracy:		81.52 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.527720
  validation loss:		0.605792
  validation accuracy:		79.89 %
Epoch 990 of 2000 took 0.096s
  training loss:		0.537916
  validation loss:		0.585408
  validation accuracy:		80.87 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.529683
  validation loss:		0.579943
  validation accuracy:		81.52 %
Epoch 992 of 2000 took 0.096s
  training loss:		0.519670
  validation loss:		0.610009
  validation accuracy:		80.33 %
Epoch 993 of 2000 took 0.098s
  training loss:		0.544538
  validation loss:		0.583269
  validation accuracy:		82.07 %
Epoch 994 of 2000 took 0.100s
  training loss:		0.530086
  validation loss:		0.581074
  validation accuracy:		82.07 %
Epoch 995 of 2000 took 0.099s
  training loss:		0.525697
  validation loss:		0.598353
  validation accuracy:		81.96 %
Epoch 996 of 2000 took 0.099s
  training loss:		0.539352
  validation loss:		0.598082
  validation accuracy:		81.09 %
Epoch 997 of 2000 took 0.100s
  training loss:		0.531411
  validation loss:		0.602083
  validation accuracy:		79.35 %
Epoch 998 of 2000 took 0.099s
  training loss:		0.543989
  validation loss:		0.579747
  validation accuracy:		81.41 %
Epoch 999 of 2000 took 0.099s
  training loss:		0.530875
  validation loss:		0.587234
  validation accuracy:		81.30 %
Epoch 1000 of 2000 took 0.099s
  training loss:		0.533560
  validation loss:		0.598533
  validation accuracy:		81.09 %
Epoch 1001 of 2000 took 0.100s
  training loss:		0.533241
  validation loss:		0.585900
  validation accuracy:		81.85 %
Epoch 1002 of 2000 took 0.099s
  training loss:		0.530862
  validation loss:		0.603020
  validation accuracy:		79.89 %
Epoch 1003 of 2000 took 0.099s
  training loss:		0.526366
  validation loss:		0.576177
  validation accuracy:		81.74 %
Epoch 1004 of 2000 took 0.100s
  training loss:		0.526846
  validation loss:		0.586842
  validation accuracy:		81.63 %
Epoch 1005 of 2000 took 0.099s
  training loss:		0.538196
  validation loss:		0.587918
  validation accuracy:		81.74 %
Epoch 1006 of 2000 took 0.099s
  training loss:		0.529681
  validation loss:		0.587440
  validation accuracy:		80.98 %
Epoch 1007 of 2000 took 0.100s
  training loss:		0.527116
  validation loss:		0.587926
  validation accuracy:		82.72 %
Epoch 1008 of 2000 took 0.100s
  training loss:		0.541498
  validation loss:		0.597375
  validation accuracy:		81.41 %
Epoch 1009 of 2000 took 0.099s
  training loss:		0.535576
  validation loss:		0.584922
  validation accuracy:		81.85 %
Epoch 1010 of 2000 took 0.099s
  training loss:		0.530151
  validation loss:		0.584504
  validation accuracy:		81.09 %
Epoch 1011 of 2000 took 0.099s
  training loss:		0.522055
  validation loss:		0.590609
  validation accuracy:		81.41 %
Epoch 1012 of 2000 took 0.099s
  training loss:		0.527127
  validation loss:		0.587896
  validation accuracy:		80.43 %
Epoch 1013 of 2000 took 0.100s
  training loss:		0.528571
  validation loss:		0.582172
  validation accuracy:		81.20 %
Epoch 1014 of 2000 took 0.100s
  training loss:		0.531682
  validation loss:		0.583566
  validation accuracy:		81.52 %
Epoch 1015 of 2000 took 0.100s
  training loss:		0.528807
  validation loss:		0.594082
  validation accuracy:		81.09 %
Epoch 1016 of 2000 took 0.099s
  training loss:		0.533625
  validation loss:		0.602053
  validation accuracy:		81.85 %
Epoch 1017 of 2000 took 0.099s
  training loss:		0.531203
  validation loss:		0.585541
  validation accuracy:		82.39 %
Epoch 1018 of 2000 took 0.099s
  training loss:		0.533973
  validation loss:		0.583128
  validation accuracy:		81.52 %
Epoch 1019 of 2000 took 0.099s
  training loss:		0.523977
  validation loss:		0.580354
  validation accuracy:		81.41 %
Epoch 1020 of 2000 took 0.099s
  training loss:		0.538721
  validation loss:		0.582695
  validation accuracy:		82.28 %
Epoch 1021 of 2000 took 0.100s
  training loss:		0.531436
  validation loss:		0.592090
  validation accuracy:		81.41 %
Epoch 1022 of 2000 took 0.099s
  training loss:		0.537303
  validation loss:		0.584557
  validation accuracy:		81.20 %
Epoch 1023 of 2000 took 0.099s
  training loss:		0.526046
  validation loss:		0.590712
  validation accuracy:		80.54 %
Epoch 1024 of 2000 took 0.100s
  training loss:		0.526799
  validation loss:		0.584480
  validation accuracy:		82.93 %
Epoch 1025 of 2000 took 0.100s
  training loss:		0.522274
  validation loss:		0.583755
  validation accuracy:		82.07 %
Epoch 1026 of 2000 took 0.099s
  training loss:		0.515777
  validation loss:		0.578962
  validation accuracy:		81.30 %
Epoch 1027 of 2000 took 0.100s
  training loss:		0.544382
  validation loss:		0.579383
  validation accuracy:		81.74 %
Epoch 1028 of 2000 took 0.099s
  training loss:		0.519823
  validation loss:		0.590836
  validation accuracy:		80.87 %
Epoch 1029 of 2000 took 0.100s
  training loss:		0.524923
  validation loss:		0.583983
  validation accuracy:		82.07 %
Epoch 1030 of 2000 took 0.100s
  training loss:		0.528043
  validation loss:		0.592000
  validation accuracy:		81.52 %
Epoch 1031 of 2000 took 0.100s
  training loss:		0.526188
  validation loss:		0.608145
  validation accuracy:		80.33 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.520601
  validation loss:		0.583203
  validation accuracy:		81.52 %
Epoch 1033 of 2000 took 0.099s
  training loss:		0.530998
  validation loss:		0.597311
  validation accuracy:		81.09 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.524784
  validation loss:		0.591171
  validation accuracy:		80.33 %
Epoch 1035 of 2000 took 0.096s
  training loss:		0.536200
  validation loss:		0.581525
  validation accuracy:		82.07 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.515080
  validation loss:		0.580277
  validation accuracy:		81.74 %
Epoch 1037 of 2000 took 0.096s
  training loss:		0.533775
  validation loss:		0.585097
  validation accuracy:		80.98 %
Epoch 1038 of 2000 took 0.096s
  training loss:		0.513601
  validation loss:		0.587184
  validation accuracy:		82.28 %
Epoch 1039 of 2000 took 0.096s
  training loss:		0.533034
  validation loss:		0.586879
  validation accuracy:		82.39 %
Epoch 1040 of 2000 took 0.096s
  training loss:		0.533115
  validation loss:		0.593447
  validation accuracy:		80.33 %
Epoch 1041 of 2000 took 0.096s
  training loss:		0.528811
  validation loss:		0.589931
  validation accuracy:		81.30 %
Epoch 1042 of 2000 took 0.096s
  training loss:		0.522189
  validation loss:		0.586445
  validation accuracy:		81.96 %
Epoch 1043 of 2000 took 0.096s
  training loss:		0.524474
  validation loss:		0.577993
  validation accuracy:		82.39 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.524772
  validation loss:		0.582317
  validation accuracy:		81.09 %
Epoch 1045 of 2000 took 0.096s
  training loss:		0.529915
  validation loss:		0.582486
  validation accuracy:		81.63 %
Epoch 1046 of 2000 took 0.096s
  training loss:		0.525874
  validation loss:		0.595312
  validation accuracy:		80.98 %
Epoch 1047 of 2000 took 0.096s
  training loss:		0.530708
  validation loss:		0.605417
  validation accuracy:		81.96 %
Epoch 1048 of 2000 took 0.096s
  training loss:		0.545724
  validation loss:		0.635354
  validation accuracy:		80.00 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.530686
  validation loss:		0.602885
  validation accuracy:		82.61 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.541302
  validation loss:		0.588963
  validation accuracy:		81.74 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.516282
  validation loss:		0.585300
  validation accuracy:		81.63 %
Epoch 1052 of 2000 took 0.096s
  training loss:		0.530514
  validation loss:		0.595573
  validation accuracy:		82.17 %
Epoch 1053 of 2000 took 0.096s
  training loss:		0.524821
  validation loss:		0.611008
  validation accuracy:		80.87 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.530947
  validation loss:		0.595657
  validation accuracy:		80.98 %
Epoch 1055 of 2000 took 0.096s
  training loss:		0.533485
  validation loss:		0.586889
  validation accuracy:		81.41 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.531646
  validation loss:		0.600145
  validation accuracy:		80.76 %
Epoch 1057 of 2000 took 0.096s
  training loss:		0.536463
  validation loss:		0.590802
  validation accuracy:		80.54 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.521849
  validation loss:		0.585183
  validation accuracy:		81.09 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.528213
  validation loss:		0.601649
  validation accuracy:		81.41 %
Epoch 1060 of 2000 took 0.096s
  training loss:		0.525269
  validation loss:		0.592684
  validation accuracy:		81.20 %
Epoch 1061 of 2000 took 0.096s
  training loss:		0.526142
  validation loss:		0.590051
  validation accuracy:		80.54 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.536353
  validation loss:		0.580347
  validation accuracy:		81.63 %
Epoch 1063 of 2000 took 0.096s
  training loss:		0.530623
  validation loss:		0.612603
  validation accuracy:		80.65 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.531653
  validation loss:		0.595827
  validation accuracy:		81.30 %
Epoch 1065 of 2000 took 0.096s
  training loss:		0.529821
  validation loss:		0.607314
  validation accuracy:		80.98 %
Epoch 1066 of 2000 took 0.096s
  training loss:		0.526687
  validation loss:		0.594258
  validation accuracy:		80.65 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.535546
  validation loss:		0.607569
  validation accuracy:		79.02 %
Epoch 1068 of 2000 took 0.096s
  training loss:		0.538381
  validation loss:		0.588072
  validation accuracy:		81.09 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.533929
  validation loss:		0.587343
  validation accuracy:		80.98 %
Epoch 1070 of 2000 took 0.096s
  training loss:		0.537928
  validation loss:		0.628013
  validation accuracy:		77.93 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.531961
  validation loss:		0.598698
  validation accuracy:		82.07 %
Epoch 1072 of 2000 took 0.096s
  training loss:		0.527040
  validation loss:		0.587271
  validation accuracy:		82.17 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.532538
  validation loss:		0.581090
  validation accuracy:		81.74 %
Epoch 1074 of 2000 took 0.096s
  training loss:		0.520259
  validation loss:		0.589794
  validation accuracy:		81.63 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.530235
  validation loss:		0.600567
  validation accuracy:		81.09 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.525176
  validation loss:		0.591241
  validation accuracy:		81.09 %
Epoch 1077 of 2000 took 0.096s
  training loss:		0.521293
  validation loss:		0.598506
  validation accuracy:		80.54 %
Epoch 1078 of 2000 took 0.096s
  training loss:		0.526188
  validation loss:		0.597245
  validation accuracy:		81.63 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.522206
  validation loss:		0.583416
  validation accuracy:		81.20 %
Epoch 1080 of 2000 took 0.096s
  training loss:		0.537222
  validation loss:		0.578294
  validation accuracy:		82.07 %
Epoch 1081 of 2000 took 0.096s
  training loss:		0.528813
  validation loss:		0.589247
  validation accuracy:		81.30 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.531148
  validation loss:		0.593618
  validation accuracy:		80.76 %
Epoch 1083 of 2000 took 0.096s
  training loss:		0.533007
  validation loss:		0.583314
  validation accuracy:		82.17 %
Epoch 1084 of 2000 took 0.096s
  training loss:		0.525043
  validation loss:		0.602535
  validation accuracy:		80.43 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.528653
  validation loss:		0.579601
  validation accuracy:		81.63 %
Epoch 1086 of 2000 took 0.096s
  training loss:		0.521070
  validation loss:		0.580369
  validation accuracy:		81.85 %
Epoch 1087 of 2000 took 0.096s
  training loss:		0.533653
  validation loss:		0.605576
  validation accuracy:		79.46 %
Epoch 1088 of 2000 took 0.096s
  training loss:		0.536247
  validation loss:		0.607481
  validation accuracy:		81.09 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.520055
  validation loss:		0.599793
  validation accuracy:		80.00 %
Epoch 1090 of 2000 took 0.096s
  training loss:		0.526413
  validation loss:		0.604191
  validation accuracy:		80.33 %
Epoch 1091 of 2000 took 0.096s
  training loss:		0.529356
  validation loss:		0.590433
  validation accuracy:		81.20 %
Epoch 1092 of 2000 took 0.096s
  training loss:		0.527574
  validation loss:		0.588871
  validation accuracy:		81.20 %
Epoch 1093 of 2000 took 0.096s
  training loss:		0.533867
  validation loss:		0.581464
  validation accuracy:		81.30 %
Epoch 1094 of 2000 took 0.096s
  training loss:		0.524971
  validation loss:		0.587257
  validation accuracy:		81.20 %
Epoch 1095 of 2000 took 0.096s
  training loss:		0.523192
  validation loss:		0.578908
  validation accuracy:		81.52 %
Epoch 1096 of 2000 took 0.096s
  training loss:		0.520035
  validation loss:		0.593805
  validation accuracy:		81.09 %
Epoch 1097 of 2000 took 0.096s
  training loss:		0.520130
  validation loss:		0.585198
  validation accuracy:		81.52 %
Epoch 1098 of 2000 took 0.096s
  training loss:		0.529214
  validation loss:		0.586612
  validation accuracy:		80.98 %
Epoch 1099 of 2000 took 0.096s
  training loss:		0.534838
  validation loss:		0.582426
  validation accuracy:		81.52 %
Epoch 1100 of 2000 took 0.096s
  training loss:		0.524450
  validation loss:		0.598961
  validation accuracy:		81.96 %
Epoch 1101 of 2000 took 0.096s
  training loss:		0.526860
  validation loss:		0.585384
  validation accuracy:		82.72 %
Epoch 1102 of 2000 took 0.096s
  training loss:		0.522125
  validation loss:		0.585040
  validation accuracy:		82.28 %
Epoch 1103 of 2000 took 0.096s
  training loss:		0.527005
  validation loss:		0.594602
  validation accuracy:		81.20 %
Epoch 1104 of 2000 took 0.096s
  training loss:		0.517419
  validation loss:		0.576646
  validation accuracy:		81.96 %
Epoch 1105 of 2000 took 0.096s
  training loss:		0.528131
  validation loss:		0.586617
  validation accuracy:		81.41 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.529640
  validation loss:		0.582007
  validation accuracy:		81.41 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.528620
  validation loss:		0.596843
  validation accuracy:		81.20 %
Epoch 1108 of 2000 took 0.096s
  training loss:		0.541225
  validation loss:		0.583062
  validation accuracy:		81.30 %
Epoch 1109 of 2000 took 0.096s
  training loss:		0.530747
  validation loss:		0.591731
  validation accuracy:		81.09 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.518914
  validation loss:		0.598664
  validation accuracy:		81.74 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.534877
  validation loss:		0.585109
  validation accuracy:		80.98 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.531211
  validation loss:		0.576419
  validation accuracy:		82.07 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.522830
  validation loss:		0.602632
  validation accuracy:		80.98 %
Epoch 1114 of 2000 took 0.099s
  training loss:		0.519891
  validation loss:		0.597480
  validation accuracy:		81.09 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.529793
  validation loss:		0.589431
  validation accuracy:		80.98 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.529580
  validation loss:		0.587005
  validation accuracy:		81.52 %
Epoch 1117 of 2000 took 0.096s
  training loss:		0.524957
  validation loss:		0.605949
  validation accuracy:		80.98 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.535537
  validation loss:		0.651129
  validation accuracy:		79.46 %
Epoch 1119 of 2000 took 0.096s
  training loss:		0.530051
  validation loss:		0.587263
  validation accuracy:		81.30 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.524163
  validation loss:		0.585967
  validation accuracy:		81.52 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.534989
  validation loss:		0.582083
  validation accuracy:		81.41 %
Epoch 1122 of 2000 took 0.096s
  training loss:		0.519309
  validation loss:		0.579009
  validation accuracy:		81.30 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.531511
  validation loss:		0.590151
  validation accuracy:		80.65 %
Epoch 1124 of 2000 took 0.096s
  training loss:		0.540547
  validation loss:		0.581250
  validation accuracy:		81.63 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.520060
  validation loss:		0.585725
  validation accuracy:		82.28 %
Epoch 1126 of 2000 took 0.096s
  training loss:		0.519392
  validation loss:		0.598772
  validation accuracy:		81.09 %
Epoch 1127 of 2000 took 0.096s
  training loss:		0.530560
  validation loss:		0.604856
  validation accuracy:		80.65 %
Epoch 1128 of 2000 took 0.096s
  training loss:		0.523617
  validation loss:		0.595100
  validation accuracy:		81.20 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.524457
  validation loss:		0.586113
  validation accuracy:		81.09 %
Epoch 1130 of 2000 took 0.096s
  training loss:		0.526336
  validation loss:		0.594614
  validation accuracy:		82.72 %
Epoch 1131 of 2000 took 0.096s
  training loss:		0.523747
  validation loss:		0.586639
  validation accuracy:		81.41 %
Epoch 1132 of 2000 took 0.096s
  training loss:		0.521387
  validation loss:		0.581893
  validation accuracy:		82.39 %
Epoch 1133 of 2000 took 0.096s
  training loss:		0.521780
  validation loss:		0.580897
  validation accuracy:		81.74 %
Epoch 1134 of 2000 took 0.096s
  training loss:		0.529102
  validation loss:		0.591907
  validation accuracy:		81.09 %
Epoch 1135 of 2000 took 0.096s
  training loss:		0.519682
  validation loss:		0.591388
  validation accuracy:		82.50 %
Epoch 1136 of 2000 took 0.096s
  training loss:		0.530688
  validation loss:		0.582984
  validation accuracy:		81.96 %
Epoch 1137 of 2000 took 0.096s
  training loss:		0.522568
  validation loss:		0.586788
  validation accuracy:		80.65 %
Epoch 1138 of 2000 took 0.096s
  training loss:		0.529709
  validation loss:		0.587676
  validation accuracy:		80.76 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.533569
  validation loss:		0.604526
  validation accuracy:		80.65 %
Epoch 1140 of 2000 took 0.096s
  training loss:		0.519304
  validation loss:		0.590014
  validation accuracy:		80.87 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.531271
  validation loss:		0.589088
  validation accuracy:		81.30 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.537263
  validation loss:		0.584777
  validation accuracy:		81.52 %
Epoch 1143 of 2000 took 0.096s
  training loss:		0.526482
  validation loss:		0.586487
  validation accuracy:		81.20 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.526999
  validation loss:		0.593492
  validation accuracy:		80.43 %
Epoch 1145 of 2000 took 0.096s
  training loss:		0.534411
  validation loss:		0.588062
  validation accuracy:		81.20 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.529616
  validation loss:		0.597398
  validation accuracy:		81.63 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.537902
  validation loss:		0.578890
  validation accuracy:		81.63 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.527876
  validation loss:		0.585262
  validation accuracy:		81.09 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.536635
  validation loss:		0.592288
  validation accuracy:		81.41 %
Epoch 1150 of 2000 took 0.096s
  training loss:		0.524904
  validation loss:		0.601094
  validation accuracy:		79.89 %
Epoch 1151 of 2000 took 0.096s
  training loss:		0.522888
  validation loss:		0.582796
  validation accuracy:		81.63 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.533364
  validation loss:		0.582936
  validation accuracy:		81.74 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.529448
  validation loss:		0.585636
  validation accuracy:		81.41 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.535381
  validation loss:		0.585467
  validation accuracy:		80.76 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.530758
  validation loss:		0.583471
  validation accuracy:		81.74 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.529362
  validation loss:		0.581618
  validation accuracy:		81.52 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.536017
  validation loss:		0.593380
  validation accuracy:		80.65 %
Epoch 1158 of 2000 took 0.097s
  training loss:		0.532538
  validation loss:		0.582498
  validation accuracy:		81.85 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.525940
  validation loss:		0.578948
  validation accuracy:		81.63 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.522697
  validation loss:		0.583408
  validation accuracy:		81.20 %
Epoch 1161 of 2000 took 0.096s
  training loss:		0.529504
  validation loss:		0.594728
  validation accuracy:		80.11 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.530215
  validation loss:		0.578062
  validation accuracy:		81.96 %
Epoch 1163 of 2000 took 0.096s
  training loss:		0.529961
  validation loss:		0.586833
  validation accuracy:		81.74 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.533725
  validation loss:		0.606533
  validation accuracy:		81.20 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.524707
  validation loss:		0.595349
  validation accuracy:		82.07 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.518973
  validation loss:		0.577234
  validation accuracy:		81.63 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.530834
  validation loss:		0.628153
  validation accuracy:		80.22 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.534263
  validation loss:		0.582046
  validation accuracy:		81.20 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.523388
  validation loss:		0.585793
  validation accuracy:		82.07 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.522186
  validation loss:		0.608054
  validation accuracy:		80.33 %
Epoch 1171 of 2000 took 0.096s
  training loss:		0.529355
  validation loss:		0.624052
  validation accuracy:		80.65 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.528421
  validation loss:		0.583374
  validation accuracy:		81.30 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.530332
  validation loss:		0.587199
  validation accuracy:		80.98 %
Epoch 1174 of 2000 took 0.096s
  training loss:		0.529388
  validation loss:		0.597912
  validation accuracy:		81.52 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.526938
  validation loss:		0.585375
  validation accuracy:		81.74 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.527953
  validation loss:		0.603910
  validation accuracy:		81.74 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.522198
  validation loss:		0.586053
  validation accuracy:		81.30 %
Epoch 1178 of 2000 took 0.096s
  training loss:		0.522428
  validation loss:		0.585148
  validation accuracy:		81.96 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.523709
  validation loss:		0.585419
  validation accuracy:		82.17 %
Epoch 1180 of 2000 took 0.096s
  training loss:		0.541064
  validation loss:		0.592868
  validation accuracy:		81.96 %
Epoch 1181 of 2000 took 0.096s
  training loss:		0.528143
  validation loss:		0.588503
  validation accuracy:		81.41 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.526811
  validation loss:		0.579776
  validation accuracy:		81.52 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.514839
  validation loss:		0.581214
  validation accuracy:		81.52 %
Epoch 1184 of 2000 took 0.096s
  training loss:		0.531930
  validation loss:		0.589227
  validation accuracy:		81.20 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.526027
  validation loss:		0.586858
  validation accuracy:		81.09 %
Epoch 1186 of 2000 took 0.096s
  training loss:		0.526140
  validation loss:		0.613423
  validation accuracy:		80.22 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.540053
  validation loss:		0.577422
  validation accuracy:		82.07 %
Epoch 1188 of 2000 took 0.096s
  training loss:		0.533220
  validation loss:		0.592054
  validation accuracy:		80.76 %
Epoch 1189 of 2000 took 0.096s
  training loss:		0.528870
  validation loss:		0.580719
  validation accuracy:		81.41 %
Epoch 1190 of 2000 took 0.097s
  training loss:		0.531666
  validation loss:		0.613210
  validation accuracy:		81.20 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.526922
  validation loss:		0.595133
  validation accuracy:		80.87 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.523437
  validation loss:		0.583089
  validation accuracy:		81.30 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.529952
  validation loss:		0.588137
  validation accuracy:		81.85 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.522355
  validation loss:		0.580299
  validation accuracy:		81.63 %
Epoch 1195 of 2000 took 0.097s
  training loss:		0.526807
  validation loss:		0.586306
  validation accuracy:		81.85 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.541787
  validation loss:		0.633763
  validation accuracy:		79.67 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.534600
  validation loss:		0.586768
  validation accuracy:		81.20 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.528166
  validation loss:		0.605413
  validation accuracy:		80.87 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.536715
  validation loss:		0.605278
  validation accuracy:		80.76 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.526843
  validation loss:		0.593778
  validation accuracy:		81.30 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.525337
  validation loss:		0.580531
  validation accuracy:		81.52 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.517151
  validation loss:		0.605893
  validation accuracy:		79.67 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.524207
  validation loss:		0.606263
  validation accuracy:		81.20 %
Epoch 1204 of 2000 took 0.096s
  training loss:		0.535525
  validation loss:		0.591779
  validation accuracy:		80.98 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.531616
  validation loss:		0.581626
  validation accuracy:		81.52 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.530908
  validation loss:		0.596785
  validation accuracy:		80.98 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.524068
  validation loss:		0.601548
  validation accuracy:		80.87 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.523484
  validation loss:		0.597427
  validation accuracy:		80.33 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.522699
  validation loss:		0.581195
  validation accuracy:		81.74 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.531354
  validation loss:		0.596913
  validation accuracy:		80.43 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.528736
  validation loss:		0.601842
  validation accuracy:		81.52 %
Epoch 1212 of 2000 took 0.096s
  training loss:		0.536206
  validation loss:		0.627534
  validation accuracy:		79.67 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.531621
  validation loss:		0.584894
  validation accuracy:		81.41 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.524331
  validation loss:		0.614527
  validation accuracy:		79.67 %
Epoch 1215 of 2000 took 0.096s
  training loss:		0.514568
  validation loss:		0.582492
  validation accuracy:		81.96 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.519881
  validation loss:		0.585402
  validation accuracy:		81.74 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.525605
  validation loss:		0.585623
  validation accuracy:		81.85 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.519815
  validation loss:		0.594095
  validation accuracy:		81.20 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.526331
  validation loss:		0.600181
  validation accuracy:		81.09 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.524470
  validation loss:		0.587775
  validation accuracy:		81.09 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.514838
  validation loss:		0.594761
  validation accuracy:		80.43 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.527840
  validation loss:		0.586593
  validation accuracy:		81.20 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.521610
  validation loss:		0.588794
  validation accuracy:		81.52 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.523050
  validation loss:		0.592796
  validation accuracy:		80.98 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.528828
  validation loss:		0.598930
  validation accuracy:		80.22 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.517314
  validation loss:		0.596472
  validation accuracy:		80.98 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.524112
  validation loss:		0.589558
  validation accuracy:		81.30 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.525387
  validation loss:		0.591293
  validation accuracy:		81.85 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.538566
  validation loss:		0.590963
  validation accuracy:		81.85 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.523287
  validation loss:		0.586768
  validation accuracy:		81.85 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.526315
  validation loss:		0.583496
  validation accuracy:		81.30 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.522799
  validation loss:		0.589087
  validation accuracy:		80.76 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.525380
  validation loss:		0.594899
  validation accuracy:		81.63 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.530289
  validation loss:		0.584394
  validation accuracy:		81.20 %
Epoch 1235 of 2000 took 0.096s
  training loss:		0.521956
  validation loss:		0.588183
  validation accuracy:		82.50 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.520560
  validation loss:		0.597707
  validation accuracy:		81.52 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.537213
  validation loss:		0.603539
  validation accuracy:		79.78 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.527068
  validation loss:		0.611039
  validation accuracy:		79.13 %
Epoch 1239 of 2000 took 0.096s
  training loss:		0.520680
  validation loss:		0.588675
  validation accuracy:		82.72 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.528621
  validation loss:		0.587737
  validation accuracy:		81.63 %
Epoch 1241 of 2000 took 0.100s
  training loss:		0.529353
  validation loss:		0.596713
  validation accuracy:		80.98 %
Epoch 1242 of 2000 took 0.100s
  training loss:		0.522932
  validation loss:		0.589233
  validation accuracy:		80.65 %
Epoch 1243 of 2000 took 0.099s
  training loss:		0.521905
  validation loss:		0.596575
  validation accuracy:		81.30 %
Epoch 1244 of 2000 took 0.099s
  training loss:		0.522273
  validation loss:		0.606711
  validation accuracy:		80.98 %
Epoch 1245 of 2000 took 0.100s
  training loss:		0.527420
  validation loss:		0.583073
  validation accuracy:		82.39 %
Epoch 1246 of 2000 took 0.100s
  training loss:		0.528553
  validation loss:		0.585845
  validation accuracy:		80.98 %
Epoch 1247 of 2000 took 0.099s
  training loss:		0.533746
  validation loss:		0.583563
  validation accuracy:		81.96 %
Epoch 1248 of 2000 took 0.099s
  training loss:		0.522998
  validation loss:		0.601646
  validation accuracy:		80.22 %
Epoch 1249 of 2000 took 0.100s
  training loss:		0.524912
  validation loss:		0.586529
  validation accuracy:		81.85 %
Epoch 1250 of 2000 took 0.099s
  training loss:		0.517447
  validation loss:		0.591693
  validation accuracy:		80.65 %
Epoch 1251 of 2000 took 0.099s
  training loss:		0.527755
  validation loss:		0.584947
  validation accuracy:		81.74 %
Epoch 1252 of 2000 took 0.099s
  training loss:		0.521628
  validation loss:		0.589436
  validation accuracy:		81.30 %
Epoch 1253 of 2000 took 0.099s
  training loss:		0.517360
  validation loss:		0.585744
  validation accuracy:		81.96 %
Epoch 1254 of 2000 took 0.099s
  training loss:		0.524202
  validation loss:		0.613766
  validation accuracy:		79.13 %
Epoch 1255 of 2000 took 0.099s
  training loss:		0.530764
  validation loss:		0.616633
  validation accuracy:		80.54 %
Epoch 1256 of 2000 took 0.099s
  training loss:		0.524814
  validation loss:		0.604057
  validation accuracy:		80.87 %
Epoch 1257 of 2000 took 0.100s
  training loss:		0.531398
  validation loss:		0.619379
  validation accuracy:		80.87 %
Epoch 1258 of 2000 took 0.099s
  training loss:		0.530980
  validation loss:		0.582798
  validation accuracy:		82.17 %
Epoch 1259 of 2000 took 0.099s
  training loss:		0.518600
  validation loss:		0.585195
  validation accuracy:		81.09 %
Epoch 1260 of 2000 took 0.099s
  training loss:		0.519130
  validation loss:		0.583594
  validation accuracy:		81.30 %
Epoch 1261 of 2000 took 0.099s
  training loss:		0.524313
  validation loss:		0.588087
  validation accuracy:		81.30 %
Epoch 1262 of 2000 took 0.100s
  training loss:		0.525917
  validation loss:		0.581147
  validation accuracy:		82.07 %
Epoch 1263 of 2000 took 0.099s
  training loss:		0.536928
  validation loss:		0.590444
  validation accuracy:		81.63 %
Epoch 1264 of 2000 took 0.099s
  training loss:		0.523201
  validation loss:		0.585480
  validation accuracy:		82.28 %
Epoch 1265 of 2000 took 0.099s
  training loss:		0.532510
  validation loss:		0.585202
  validation accuracy:		81.85 %
Epoch 1266 of 2000 took 0.099s
  training loss:		0.522496
  validation loss:		0.592243
  validation accuracy:		80.98 %
Epoch 1267 of 2000 took 0.099s
  training loss:		0.532338
  validation loss:		0.583132
  validation accuracy:		81.96 %
Epoch 1268 of 2000 took 0.099s
  training loss:		0.517524
  validation loss:		0.580471
  validation accuracy:		81.52 %
Epoch 1269 of 2000 took 0.100s
  training loss:		0.526250
  validation loss:		0.582991
  validation accuracy:		81.63 %
Epoch 1270 of 2000 took 0.099s
  training loss:		0.526529
  validation loss:		0.581284
  validation accuracy:		81.41 %
Epoch 1271 of 2000 took 0.099s
  training loss:		0.523550
  validation loss:		0.597066
  validation accuracy:		80.98 %
Epoch 1272 of 2000 took 0.099s
  training loss:		0.526440
  validation loss:		0.603743
  validation accuracy:		81.63 %
Epoch 1273 of 2000 took 0.099s
  training loss:		0.523343
  validation loss:		0.616811
  validation accuracy:		79.89 %
Epoch 1274 of 2000 took 0.099s
  training loss:		0.519168
  validation loss:		0.589292
  validation accuracy:		81.41 %
Epoch 1275 of 2000 took 0.100s
  training loss:		0.529918
  validation loss:		0.579549
  validation accuracy:		81.63 %
Epoch 1276 of 2000 took 0.100s
  training loss:		0.527610
  validation loss:		0.610943
  validation accuracy:		80.54 %
Epoch 1277 of 2000 took 0.100s
  training loss:		0.531416
  validation loss:		0.596748
  validation accuracy:		80.98 %
Epoch 1278 of 2000 took 0.100s
  training loss:		0.518677
  validation loss:		0.609507
  validation accuracy:		80.65 %
Epoch 1279 of 2000 took 0.100s
  training loss:		0.532763
  validation loss:		0.586206
  validation accuracy:		81.96 %
Epoch 1280 of 2000 took 0.099s
  training loss:		0.526324
  validation loss:		0.598292
  validation accuracy:		81.30 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.520811
  validation loss:		0.595162
  validation accuracy:		81.30 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.530358
  validation loss:		0.599473
  validation accuracy:		81.30 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.528299
  validation loss:		0.589509
  validation accuracy:		81.63 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.531473
  validation loss:		0.586808
  validation accuracy:		81.30 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.524635
  validation loss:		0.596478
  validation accuracy:		81.09 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.536339
  validation loss:		0.584511
  validation accuracy:		81.63 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.525130
  validation loss:		0.617914
  validation accuracy:		80.87 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.525772
  validation loss:		0.604747
  validation accuracy:		80.87 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.525271
  validation loss:		0.591886
  validation accuracy:		81.20 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.520526
  validation loss:		0.585850
  validation accuracy:		81.30 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.520609
  validation loss:		0.603670
  validation accuracy:		81.09 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.519231
  validation loss:		0.580278
  validation accuracy:		81.52 %
Epoch 1293 of 2000 took 0.096s
  training loss:		0.532732
  validation loss:		0.646583
  validation accuracy:		79.89 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.532297
  validation loss:		0.586524
  validation accuracy:		81.96 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.517902
  validation loss:		0.607843
  validation accuracy:		79.46 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.521932
  validation loss:		0.584823
  validation accuracy:		81.63 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.534728
  validation loss:		0.617629
  validation accuracy:		78.80 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.514709
  validation loss:		0.583787
  validation accuracy:		81.74 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.531754
  validation loss:		0.588281
  validation accuracy:		81.20 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.521487
  validation loss:		0.582376
  validation accuracy:		81.52 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.526963
  validation loss:		0.588995
  validation accuracy:		82.39 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.523687
  validation loss:		0.628148
  validation accuracy:		79.24 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.536715
  validation loss:		0.610673
  validation accuracy:		80.76 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.522660
  validation loss:		0.583291
  validation accuracy:		81.74 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.521471
  validation loss:		0.624708
  validation accuracy:		79.24 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.527130
  validation loss:		0.599912
  validation accuracy:		79.67 %
Epoch 1307 of 2000 took 0.100s
  training loss:		0.529741
  validation loss:		0.590094
  validation accuracy:		80.87 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.523728
  validation loss:		0.592615
  validation accuracy:		81.52 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.531286
  validation loss:		0.589049
  validation accuracy:		80.87 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.519228
  validation loss:		0.587197
  validation accuracy:		81.09 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.531951
  validation loss:		0.582474
  validation accuracy:		81.52 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.526161
  validation loss:		0.625279
  validation accuracy:		78.91 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.525676
  validation loss:		0.590178
  validation accuracy:		81.52 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.528973
  validation loss:		0.602310
  validation accuracy:		81.74 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.522314
  validation loss:		0.593618
  validation accuracy:		80.65 %
Epoch 1316 of 2000 took 0.096s
  training loss:		0.530090
  validation loss:		0.588054
  validation accuracy:		81.30 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.517785
  validation loss:		0.583264
  validation accuracy:		82.07 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.524244
  validation loss:		0.587427
  validation accuracy:		80.76 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.526248
  validation loss:		0.589341
  validation accuracy:		81.09 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.522770
  validation loss:		0.625750
  validation accuracy:		79.46 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.526479
  validation loss:		0.611406
  validation accuracy:		81.30 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.540288
  validation loss:		0.584162
  validation accuracy:		81.63 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.523317
  validation loss:		0.586943
  validation accuracy:		80.87 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.525827
  validation loss:		0.591439
  validation accuracy:		82.28 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.523623
  validation loss:		0.585505
  validation accuracy:		81.74 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.525392
  validation loss:		0.613995
  validation accuracy:		80.22 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.532108
  validation loss:		0.587680
  validation accuracy:		81.30 %
Epoch 1328 of 2000 took 0.096s
  training loss:		0.518471
  validation loss:		0.590067
  validation accuracy:		82.39 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.523863
  validation loss:		0.593572
  validation accuracy:		82.28 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.534880
  validation loss:		0.589071
  validation accuracy:		80.98 %
Epoch 1331 of 2000 took 0.096s
  training loss:		0.526220
  validation loss:		0.617876
  validation accuracy:		79.24 %
Epoch 1332 of 2000 took 0.096s
  training loss:		0.521207
  validation loss:		0.590676
  validation accuracy:		80.43 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.526605
  validation loss:		0.589324
  validation accuracy:		81.20 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.521854
  validation loss:		0.589909
  validation accuracy:		80.87 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.528185
  validation loss:		0.639847
  validation accuracy:		77.93 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.532615
  validation loss:		0.583224
  validation accuracy:		82.07 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.520473
  validation loss:		0.603039
  validation accuracy:		81.09 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.528672
  validation loss:		0.586317
  validation accuracy:		81.85 %
Epoch 1339 of 2000 took 0.096s
  training loss:		0.531809
  validation loss:		0.597527
  validation accuracy:		82.61 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.527733
  validation loss:		0.612279
  validation accuracy:		80.33 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.526976
  validation loss:		0.586705
  validation accuracy:		81.52 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.536021
  validation loss:		0.596262
  validation accuracy:		80.76 %
Epoch 1343 of 2000 took 0.096s
  training loss:		0.527525
  validation loss:		0.586483
  validation accuracy:		81.63 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.524701
  validation loss:		0.585743
  validation accuracy:		81.74 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.520202
  validation loss:		0.589076
  validation accuracy:		81.09 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.526845
  validation loss:		0.591580
  validation accuracy:		80.87 %
Epoch 1347 of 2000 took 0.096s
  training loss:		0.530064
  validation loss:		0.642405
  validation accuracy:		79.89 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.532779
  validation loss:		0.587054
  validation accuracy:		81.52 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.520547
  validation loss:		0.589466
  validation accuracy:		81.30 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.525609
  validation loss:		0.590017
  validation accuracy:		81.52 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.534262
  validation loss:		0.599504
  validation accuracy:		82.17 %
Epoch 1352 of 2000 took 0.096s
  training loss:		0.526241
  validation loss:		0.584881
  validation accuracy:		80.98 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.526552
  validation loss:		0.607045
  validation accuracy:		80.65 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.527541
  validation loss:		0.582771
  validation accuracy:		81.41 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.526322
  validation loss:		0.591438
  validation accuracy:		81.20 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.525884
  validation loss:		0.581202
  validation accuracy:		82.61 %
Epoch 1357 of 2000 took 0.096s
  training loss:		0.534970
  validation loss:		0.586416
  validation accuracy:		81.74 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.526149
  validation loss:		0.582706
  validation accuracy:		82.28 %
Epoch 1359 of 2000 took 0.097s
  training loss:		0.530865
  validation loss:		0.587461
  validation accuracy:		81.41 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.529904
  validation loss:		0.604698
  validation accuracy:		81.09 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.521894
  validation loss:		0.584180
  validation accuracy:		82.39 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.522794
  validation loss:		0.596193
  validation accuracy:		81.74 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.528653
  validation loss:		0.589489
  validation accuracy:		81.20 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.514449
  validation loss:		0.583699
  validation accuracy:		81.85 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.515417
  validation loss:		0.603005
  validation accuracy:		81.09 %
Epoch 1366 of 2000 took 0.096s
  training loss:		0.526420
  validation loss:		0.591462
  validation accuracy:		81.30 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.534285
  validation loss:		0.601527
  validation accuracy:		81.85 %
Epoch 1368 of 2000 took 0.096s
  training loss:		0.520633
  validation loss:		0.609352
  validation accuracy:		80.22 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.521979
  validation loss:		0.604432
  validation accuracy:		80.22 %
Epoch 1370 of 2000 took 0.096s
  training loss:		0.523410
  validation loss:		0.597304
  validation accuracy:		81.30 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.528671
  validation loss:		0.599724
  validation accuracy:		80.76 %
Epoch 1372 of 2000 took 0.096s
  training loss:		0.526202
  validation loss:		0.600187
  validation accuracy:		80.87 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.521355
  validation loss:		0.585858
  validation accuracy:		81.20 %
Epoch 1374 of 2000 took 0.096s
  training loss:		0.529239
  validation loss:		0.588218
  validation accuracy:		81.41 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.528069
  validation loss:		0.591889
  validation accuracy:		80.98 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.519740
  validation loss:		0.594358
  validation accuracy:		81.30 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.508751
  validation loss:		0.584757
  validation accuracy:		81.30 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.520446
  validation loss:		0.585442
  validation accuracy:		81.30 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.521666
  validation loss:		0.596399
  validation accuracy:		81.20 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.520456
  validation loss:		0.599931
  validation accuracy:		82.28 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.526839
  validation loss:		0.637685
  validation accuracy:		79.02 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.525227
  validation loss:		0.600942
  validation accuracy:		80.98 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.522220
  validation loss:		0.602947
  validation accuracy:		79.46 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.525302
  validation loss:		0.587616
  validation accuracy:		81.52 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.523190
  validation loss:		0.584569
  validation accuracy:		81.30 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.512071
  validation loss:		0.593044
  validation accuracy:		80.98 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.523328
  validation loss:		0.596220
  validation accuracy:		81.30 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.528567
  validation loss:		0.586739
  validation accuracy:		81.74 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.535749
  validation loss:		0.583948
  validation accuracy:		81.63 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.526225
  validation loss:		0.584268
  validation accuracy:		81.63 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.527735
  validation loss:		0.592368
  validation accuracy:		80.65 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.528487
  validation loss:		0.588310
  validation accuracy:		81.74 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.525525
  validation loss:		0.609099
  validation accuracy:		80.54 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.530534
  validation loss:		0.602129
  validation accuracy:		80.11 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.520517
  validation loss:		0.589997
  validation accuracy:		81.30 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.526551
  validation loss:		0.590469
  validation accuracy:		80.54 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.519766
  validation loss:		0.589212
  validation accuracy:		81.30 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.526665
  validation loss:		0.585461
  validation accuracy:		81.63 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.535046
  validation loss:		0.593360
  validation accuracy:		81.85 %
Epoch 1400 of 2000 took 0.097s
  training loss:		0.523684
  validation loss:		0.590711
  validation accuracy:		81.85 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.514815
  validation loss:		0.604472
  validation accuracy:		79.46 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.532371
  validation loss:		0.596242
  validation accuracy:		80.76 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.520867
  validation loss:		0.589769
  validation accuracy:		80.87 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.527485
  validation loss:		0.618556
  validation accuracy:		80.65 %
Epoch 1405 of 2000 took 0.097s
  training loss:		0.523812
  validation loss:		0.583787
  validation accuracy:		81.41 %
Epoch 1406 of 2000 took 0.097s
  training loss:		0.524662
  validation loss:		0.587899
  validation accuracy:		81.20 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.528552
  validation loss:		0.583036
  validation accuracy:		81.52 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.526038
  validation loss:		0.598714
  validation accuracy:		80.98 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.528763
  validation loss:		0.595216
  validation accuracy:		80.87 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.512918
  validation loss:		0.590301
  validation accuracy:		80.76 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.520759
  validation loss:		0.590421
  validation accuracy:		81.09 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.524531
  validation loss:		0.618512
  validation accuracy:		80.54 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.521133
  validation loss:		0.589230
  validation accuracy:		81.20 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.529141
  validation loss:		0.583459
  validation accuracy:		81.30 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.526561
  validation loss:		0.586722
  validation accuracy:		81.52 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.526497
  validation loss:		0.626183
  validation accuracy:		80.00 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.536708
  validation loss:		0.585336
  validation accuracy:		81.09 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.523367
  validation loss:		0.612180
  validation accuracy:		79.24 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.524554
  validation loss:		0.592326
  validation accuracy:		80.54 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.531705
  validation loss:		0.601774
  validation accuracy:		81.52 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.523441
  validation loss:		0.590988
  validation accuracy:		81.52 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.533030
  validation loss:		0.601968
  validation accuracy:		80.98 %
Epoch 1423 of 2000 took 0.103s
  training loss:		0.533662
  validation loss:		0.596034
  validation accuracy:		80.76 %
Epoch 1424 of 2000 took 0.103s
  training loss:		0.523893
  validation loss:		0.609285
  validation accuracy:		81.30 %
Epoch 1425 of 2000 took 0.101s
  training loss:		0.526129
  validation loss:		0.587174
  validation accuracy:		81.20 %
Epoch 1426 of 2000 took 0.099s
  training loss:		0.523832
  validation loss:		0.626364
  validation accuracy:		80.00 %
Epoch 1427 of 2000 took 0.099s
  training loss:		0.522133
  validation loss:		0.601232
  validation accuracy:		81.20 %
Epoch 1428 of 2000 took 0.100s
  training loss:		0.524839
  validation loss:		0.610586
  validation accuracy:		81.09 %
Epoch 1429 of 2000 took 0.099s
  training loss:		0.528204
  validation loss:		0.585038
  validation accuracy:		81.41 %
Epoch 1430 of 2000 took 0.099s
  training loss:		0.526980
  validation loss:		0.582587
  validation accuracy:		81.74 %
Epoch 1431 of 2000 took 0.099s
  training loss:		0.538293
  validation loss:		0.590484
  validation accuracy:		80.87 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.536815
  validation loss:		0.586215
  validation accuracy:		81.41 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.525433
  validation loss:		0.586178
  validation accuracy:		82.07 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.521988
  validation loss:		0.603582
  validation accuracy:		80.43 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.518842
  validation loss:		0.595089
  validation accuracy:		80.43 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.522506
  validation loss:		0.590678
  validation accuracy:		81.63 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.522855
  validation loss:		0.590326
  validation accuracy:		81.74 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.533022
  validation loss:		0.603908
  validation accuracy:		81.09 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.527297
  validation loss:		0.586070
  validation accuracy:		81.52 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.520162
  validation loss:		0.584439
  validation accuracy:		81.30 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.529004
  validation loss:		0.616826
  validation accuracy:		80.76 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.521981
  validation loss:		0.586638
  validation accuracy:		81.30 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.523946
  validation loss:		0.586960
  validation accuracy:		80.87 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.519209
  validation loss:		0.582229
  validation accuracy:		81.85 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.524901
  validation loss:		0.585139
  validation accuracy:		81.30 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.527850
  validation loss:		0.586333
  validation accuracy:		81.09 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.520018
  validation loss:		0.591541
  validation accuracy:		81.52 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.517087
  validation loss:		0.588107
  validation accuracy:		80.87 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.523952
  validation loss:		0.588819
  validation accuracy:		82.17 %
Epoch 1450 of 2000 took 0.096s
  training loss:		0.528942
  validation loss:		0.607745
  validation accuracy:		81.20 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.518739
  validation loss:		0.593107
  validation accuracy:		81.74 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.531017
  validation loss:		0.586803
  validation accuracy:		81.41 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.521548
  validation loss:		0.589072
  validation accuracy:		81.30 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.523777
  validation loss:		0.593271
  validation accuracy:		81.20 %
Epoch 1455 of 2000 took 0.096s
  training loss:		0.528938
  validation loss:		0.593912
  validation accuracy:		81.30 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.524870
  validation loss:		0.582262
  validation accuracy:		81.52 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.515119
  validation loss:		0.589470
  validation accuracy:		81.30 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.523099
  validation loss:		0.590376
  validation accuracy:		81.30 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.524246
  validation loss:		0.590700
  validation accuracy:		81.20 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.524841
  validation loss:		0.593042
  validation accuracy:		81.30 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.519822
  validation loss:		0.586148
  validation accuracy:		82.17 %
Epoch 1462 of 2000 took 0.097s
  training loss:		0.531364
  validation loss:		0.609857
  validation accuracy:		80.65 %
Epoch 1463 of 2000 took 0.098s
  training loss:		0.529340
  validation loss:		0.592763
  validation accuracy:		82.28 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.522480
  validation loss:		0.583317
  validation accuracy:		81.52 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.533002
  validation loss:		0.590543
  validation accuracy:		82.17 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.527172
  validation loss:		0.588989
  validation accuracy:		81.09 %
Epoch 1467 of 2000 took 0.097s
  training loss:		0.529680
  validation loss:		0.595362
  validation accuracy:		80.33 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.528865
  validation loss:		0.584678
  validation accuracy:		81.96 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.528180
  validation loss:		0.606914
  validation accuracy:		79.46 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.530109
  validation loss:		0.612753
  validation accuracy:		81.74 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.532106
  validation loss:		0.608939
  validation accuracy:		80.43 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.525394
  validation loss:		0.603407
  validation accuracy:		80.98 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.541602
  validation loss:		0.583234
  validation accuracy:		81.63 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.521297
  validation loss:		0.588144
  validation accuracy:		81.41 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.519690
  validation loss:		0.588766
  validation accuracy:		81.41 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.526867
  validation loss:		0.583852
  validation accuracy:		81.85 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.525035
  validation loss:		0.588937
  validation accuracy:		81.30 %
Epoch 1478 of 2000 took 0.097s
  training loss:		0.520211
  validation loss:		0.594815
  validation accuracy:		81.20 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.531325
  validation loss:		0.591275
  validation accuracy:		81.20 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.527796
  validation loss:		0.602608
  validation accuracy:		81.09 %
Epoch 1481 of 2000 took 0.096s
  training loss:		0.515845
  validation loss:		0.586360
  validation accuracy:		81.85 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.526278
  validation loss:		0.613228
  validation accuracy:		80.98 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.524056
  validation loss:		0.588515
  validation accuracy:		81.52 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.529766
  validation loss:		0.594188
  validation accuracy:		81.30 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.520998
  validation loss:		0.584446
  validation accuracy:		81.30 %
Epoch 1486 of 2000 took 0.097s
  training loss:		0.517139
  validation loss:		0.591321
  validation accuracy:		81.20 %
Epoch 1487 of 2000 took 0.098s
  training loss:		0.530353
  validation loss:		0.581195
  validation accuracy:		81.41 %
Epoch 1488 of 2000 took 0.100s
  training loss:		0.523240
  validation loss:		0.585184
  validation accuracy:		81.74 %
Epoch 1489 of 2000 took 0.100s
  training loss:		0.521750
  validation loss:		0.586416
  validation accuracy:		81.30 %
Epoch 1490 of 2000 took 0.099s
  training loss:		0.517388
  validation loss:		0.606780
  validation accuracy:		80.54 %
Epoch 1491 of 2000 took 0.099s
  training loss:		0.523096
  validation loss:		0.593173
  validation accuracy:		80.33 %
Epoch 1492 of 2000 took 0.099s
  training loss:		0.525822
  validation loss:		0.600732
  validation accuracy:		80.98 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.525849
  validation loss:		0.595492
  validation accuracy:		80.65 %
Epoch 1494 of 2000 took 0.100s
  training loss:		0.526265
  validation loss:		0.597489
  validation accuracy:		81.20 %
Epoch 1495 of 2000 took 0.099s
  training loss:		0.526199
  validation loss:		0.591201
  validation accuracy:		81.41 %
Epoch 1496 of 2000 took 0.099s
  training loss:		0.516255
  validation loss:		0.586501
  validation accuracy:		81.63 %
Epoch 1497 of 2000 took 0.099s
  training loss:		0.519144
  validation loss:		0.588213
  validation accuracy:		81.09 %
Epoch 1498 of 2000 took 0.099s
  training loss:		0.532222
  validation loss:		0.589156
  validation accuracy:		80.98 %
Epoch 1499 of 2000 took 0.099s
  training loss:		0.531142
  validation loss:		0.594864
  validation accuracy:		80.98 %
Epoch 1500 of 2000 took 0.099s
  training loss:		0.520019
  validation loss:		0.584448
  validation accuracy:		82.07 %
Epoch 1501 of 2000 took 0.099s
  training loss:		0.524958
  validation loss:		0.599539
  validation accuracy:		81.52 %
Epoch 1502 of 2000 took 0.099s
  training loss:		0.532830
  validation loss:		0.589271
  validation accuracy:		81.41 %
Epoch 1503 of 2000 took 0.099s
  training loss:		0.526634
  validation loss:		0.589338
  validation accuracy:		81.30 %
Epoch 1504 of 2000 took 0.100s
  training loss:		0.515900
  validation loss:		0.583043
  validation accuracy:		81.30 %
Epoch 1505 of 2000 took 0.099s
  training loss:		0.526375
  validation loss:		0.587055
  validation accuracy:		81.20 %
Epoch 1506 of 2000 took 0.099s
  training loss:		0.521342
  validation loss:		0.592713
  validation accuracy:		80.65 %
Epoch 1507 of 2000 took 0.099s
  training loss:		0.529159
  validation loss:		0.591259
  validation accuracy:		81.09 %
Epoch 1508 of 2000 took 0.099s
  training loss:		0.524977
  validation loss:		0.582499
  validation accuracy:		81.52 %
Epoch 1509 of 2000 took 0.100s
  training loss:		0.515204
  validation loss:		0.604936
  validation accuracy:		81.30 %
Epoch 1510 of 2000 took 0.099s
  training loss:		0.513151
  validation loss:		0.610169
  validation accuracy:		81.09 %
Epoch 1511 of 2000 took 0.099s
  training loss:		0.527313
  validation loss:		0.602788
  validation accuracy:		80.65 %
Epoch 1512 of 2000 took 0.099s
  training loss:		0.521316
  validation loss:		0.600082
  validation accuracy:		80.76 %
Epoch 1513 of 2000 took 0.099s
  training loss:		0.519267
  validation loss:		0.598978
  validation accuracy:		80.98 %
Epoch 1514 of 2000 took 0.099s
  training loss:		0.525595
  validation loss:		0.596752
  validation accuracy:		82.07 %
Epoch 1515 of 2000 took 0.099s
  training loss:		0.526562
  validation loss:		0.588753
  validation accuracy:		81.41 %
Epoch 1516 of 2000 took 0.099s
  training loss:		0.521519
  validation loss:		0.594815
  validation accuracy:		81.20 %
Epoch 1517 of 2000 took 0.099s
  training loss:		0.534498
  validation loss:		0.588722
  validation accuracy:		81.52 %
Epoch 1518 of 2000 took 0.099s
  training loss:		0.541063
  validation loss:		0.602489
  validation accuracy:		80.00 %
Epoch 1519 of 2000 took 0.102s
  training loss:		0.523635
  validation loss:		0.586296
  validation accuracy:		81.52 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.534139
  validation loss:		0.592577
  validation accuracy:		80.98 %
Epoch 1521 of 2000 took 0.099s
  training loss:		0.530627
  validation loss:		0.582818
  validation accuracy:		82.07 %
Epoch 1522 of 2000 took 0.099s
  training loss:		0.526756
  validation loss:		0.587153
  validation accuracy:		81.30 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.518248
  validation loss:		0.595010
  validation accuracy:		81.09 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.526030
  validation loss:		0.597489
  validation accuracy:		81.20 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.522983
  validation loss:		0.584776
  validation accuracy:		80.98 %
Epoch 1526 of 2000 took 0.099s
  training loss:		0.519687
  validation loss:		0.585972
  validation accuracy:		81.20 %
Epoch 1527 of 2000 took 0.100s
  training loss:		0.519600
  validation loss:		0.584630
  validation accuracy:		81.74 %
Epoch 1528 of 2000 took 0.100s
  training loss:		0.521814
  validation loss:		0.588540
  validation accuracy:		80.98 %
Epoch 1529 of 2000 took 0.099s
  training loss:		0.516220
  validation loss:		0.599825
  validation accuracy:		80.11 %
Epoch 1530 of 2000 took 0.099s
  training loss:		0.517112
  validation loss:		0.592844
  validation accuracy:		80.98 %
Epoch 1531 of 2000 took 0.099s
  training loss:		0.519382
  validation loss:		0.590710
  validation accuracy:		80.98 %
Epoch 1532 of 2000 took 0.099s
  training loss:		0.525624
  validation loss:		0.589159
  validation accuracy:		80.76 %
Epoch 1533 of 2000 took 0.099s
  training loss:		0.522559
  validation loss:		0.590697
  validation accuracy:		81.20 %
Epoch 1534 of 2000 took 0.099s
  training loss:		0.523295
  validation loss:		0.586986
  validation accuracy:		81.09 %
Epoch 1535 of 2000 took 0.099s
  training loss:		0.522527
  validation loss:		0.600859
  validation accuracy:		81.52 %
Epoch 1536 of 2000 took 0.099s
  training loss:		0.534117
  validation loss:		0.606841
  validation accuracy:		80.65 %
Epoch 1537 of 2000 took 0.099s
  training loss:		0.520020
  validation loss:		0.587344
  validation accuracy:		82.17 %
Epoch 1538 of 2000 took 0.099s
  training loss:		0.530890
  validation loss:		0.584979
  validation accuracy:		81.85 %
Epoch 1539 of 2000 took 0.099s
  training loss:		0.529336
  validation loss:		0.583625
  validation accuracy:		81.41 %
Epoch 1540 of 2000 took 0.099s
  training loss:		0.518684
  validation loss:		0.583191
  validation accuracy:		81.96 %
Epoch 1541 of 2000 took 0.099s
  training loss:		0.522217
  validation loss:		0.614977
  validation accuracy:		80.54 %
Epoch 1542 of 2000 took 0.099s
  training loss:		0.519286
  validation loss:		0.588507
  validation accuracy:		81.20 %
Epoch 1543 of 2000 took 0.099s
  training loss:		0.520812
  validation loss:		0.601395
  validation accuracy:		81.63 %
Epoch 1544 of 2000 took 0.099s
  training loss:		0.531953
  validation loss:		0.597100
  validation accuracy:		80.11 %
Epoch 1545 of 2000 took 0.099s
  training loss:		0.526081
  validation loss:		0.594167
  validation accuracy:		80.33 %
Epoch 1546 of 2000 took 0.099s
  training loss:		0.515413
  validation loss:		0.596579
  validation accuracy:		81.20 %
Epoch 1547 of 2000 took 0.099s
  training loss:		0.521110
  validation loss:		0.585385
  validation accuracy:		82.07 %
Epoch 1548 of 2000 took 0.099s
  training loss:		0.523244
  validation loss:		0.586814
  validation accuracy:		81.30 %
Epoch 1549 of 2000 took 0.099s
  training loss:		0.517974
  validation loss:		0.631670
  validation accuracy:		78.70 %
Epoch 1550 of 2000 took 0.099s
  training loss:		0.514842
  validation loss:		0.582289
  validation accuracy:		81.74 %
Epoch 1551 of 2000 took 0.099s
  training loss:		0.516014
  validation loss:		0.589317
  validation accuracy:		81.41 %
Epoch 1552 of 2000 took 0.099s
  training loss:		0.518513
  validation loss:		0.592953
  validation accuracy:		81.30 %
Epoch 1553 of 2000 took 0.099s
  training loss:		0.520891
  validation loss:		0.593912
  validation accuracy:		80.65 %
Epoch 1554 of 2000 took 0.100s
  training loss:		0.520462
  validation loss:		0.587996
  validation accuracy:		81.20 %
Epoch 1555 of 2000 took 0.099s
  training loss:		0.511196
  validation loss:		0.585626
  validation accuracy:		80.98 %
Epoch 1556 of 2000 took 0.099s
  training loss:		0.523618
  validation loss:		0.593470
  validation accuracy:		80.65 %
Epoch 1557 of 2000 took 0.100s
  training loss:		0.519181
  validation loss:		0.595338
  validation accuracy:		81.09 %
Epoch 1558 of 2000 took 0.099s
  training loss:		0.515398
  validation loss:		0.599325
  validation accuracy:		80.33 %
Epoch 1559 of 2000 took 0.099s
  training loss:		0.523271
  validation loss:		0.594592
  validation accuracy:		81.09 %
Epoch 1560 of 2000 took 0.099s
  training loss:		0.521055
  validation loss:		0.584597
  validation accuracy:		81.09 %
Epoch 1561 of 2000 took 0.099s
  training loss:		0.516294
  validation loss:		0.593059
  validation accuracy:		80.98 %
Epoch 1562 of 2000 took 0.099s
  training loss:		0.526237
  validation loss:		0.596272
  validation accuracy:		81.30 %
Epoch 1563 of 2000 took 0.099s
  training loss:		0.533004
  validation loss:		0.603045
  validation accuracy:		80.87 %
Epoch 1564 of 2000 took 0.100s
  training loss:		0.523803
  validation loss:		0.596833
  validation accuracy:		81.30 %
Epoch 1565 of 2000 took 0.100s
  training loss:		0.521933
  validation loss:		0.599080
  validation accuracy:		80.22 %
Epoch 1566 of 2000 took 0.099s
  training loss:		0.514810
  validation loss:		0.592946
  validation accuracy:		81.52 %
Epoch 1567 of 2000 took 0.099s
  training loss:		0.525953
  validation loss:		0.594676
  validation accuracy:		81.96 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.526100
  validation loss:		0.606091
  validation accuracy:		81.52 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.524576
  validation loss:		0.595962
  validation accuracy:		81.30 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.521550
  validation loss:		0.618164
  validation accuracy:		80.87 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.520498
  validation loss:		0.607111
  validation accuracy:		80.87 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.520759
  validation loss:		0.604603
  validation accuracy:		79.67 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.521453
  validation loss:		0.594354
  validation accuracy:		80.87 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.526440
  validation loss:		0.586971
  validation accuracy:		80.98 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.522948
  validation loss:		0.603978
  validation accuracy:		81.41 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.527285
  validation loss:		0.588316
  validation accuracy:		81.41 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.511920
  validation loss:		0.589779
  validation accuracy:		81.30 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.523817
  validation loss:		0.589497
  validation accuracy:		82.28 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.522896
  validation loss:		0.589668
  validation accuracy:		81.52 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.521468
  validation loss:		0.594834
  validation accuracy:		81.20 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.526962
  validation loss:		0.586884
  validation accuracy:		81.63 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.525015
  validation loss:		0.586400
  validation accuracy:		81.41 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.520343
  validation loss:		0.593654
  validation accuracy:		81.30 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.524351
  validation loss:		0.586362
  validation accuracy:		81.41 %
Epoch 1585 of 2000 took 0.097s
  training loss:		0.526760
  validation loss:		0.587836
  validation accuracy:		81.41 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.530128
  validation loss:		0.585812
  validation accuracy:		81.41 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.521318
  validation loss:		0.585249
  validation accuracy:		81.30 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.523118
  validation loss:		0.593131
  validation accuracy:		82.28 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.528030
  validation loss:		0.612053
  validation accuracy:		81.09 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.526712
  validation loss:		0.590903
  validation accuracy:		81.85 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.521724
  validation loss:		0.593029
  validation accuracy:		80.98 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.515073
  validation loss:		0.597035
  validation accuracy:		81.52 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.521279
  validation loss:		0.587404
  validation accuracy:		81.52 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.518353
  validation loss:		0.596892
  validation accuracy:		81.09 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.536786
  validation loss:		0.585257
  validation accuracy:		82.72 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.529975
  validation loss:		0.592898
  validation accuracy:		80.76 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.522033
  validation loss:		0.583651
  validation accuracy:		81.30 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.521665
  validation loss:		0.585210
  validation accuracy:		81.30 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.520770
  validation loss:		0.592240
  validation accuracy:		81.20 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.530208
  validation loss:		0.583794
  validation accuracy:		81.09 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.518690
  validation loss:		0.599440
  validation accuracy:		81.09 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.521671
  validation loss:		0.604665
  validation accuracy:		79.67 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.526902
  validation loss:		0.587169
  validation accuracy:		82.17 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.525204
  validation loss:		0.594557
  validation accuracy:		81.30 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.522761
  validation loss:		0.626031
  validation accuracy:		78.91 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.524365
  validation loss:		0.594042
  validation accuracy:		81.30 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.533849
  validation loss:		0.597772
  validation accuracy:		80.76 %
Epoch 1608 of 2000 took 0.097s
  training loss:		0.531301
  validation loss:		0.587620
  validation accuracy:		81.41 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.521131
  validation loss:		0.585882
  validation accuracy:		81.20 %
Epoch 1610 of 2000 took 0.100s
  training loss:		0.526448
  validation loss:		0.594482
  validation accuracy:		80.98 %
Epoch 1611 of 2000 took 0.099s
  training loss:		0.523942
  validation loss:		0.589935
  validation accuracy:		81.74 %
Epoch 1612 of 2000 took 0.100s
  training loss:		0.523219
  validation loss:		0.585969
  validation accuracy:		81.30 %
Epoch 1613 of 2000 took 0.099s
  training loss:		0.522331
  validation loss:		0.592625
  validation accuracy:		80.98 %
Epoch 1614 of 2000 took 0.099s
  training loss:		0.518492
  validation loss:		0.599679
  validation accuracy:		80.98 %
Epoch 1615 of 2000 took 0.099s
  training loss:		0.520780
  validation loss:		0.595356
  validation accuracy:		81.30 %
Epoch 1616 of 2000 took 0.100s
  training loss:		0.515958
  validation loss:		0.594164
  validation accuracy:		81.30 %
Epoch 1617 of 2000 took 0.099s
  training loss:		0.517403
  validation loss:		0.588721
  validation accuracy:		81.41 %
Epoch 1618 of 2000 took 0.099s
  training loss:		0.524752
  validation loss:		0.608963
  validation accuracy:		80.98 %
Epoch 1619 of 2000 took 0.100s
  training loss:		0.522085
  validation loss:		0.587160
  validation accuracy:		81.09 %
Epoch 1620 of 2000 took 0.100s
  training loss:		0.527555
  validation loss:		0.588430
  validation accuracy:		80.98 %
Epoch 1621 of 2000 took 0.099s
  training loss:		0.521943
  validation loss:		0.605025
  validation accuracy:		80.43 %
Epoch 1622 of 2000 took 0.099s
  training loss:		0.536660
  validation loss:		0.594780
  validation accuracy:		81.30 %
Epoch 1623 of 2000 took 0.100s
  training loss:		0.526347
  validation loss:		0.603120
  validation accuracy:		81.30 %
Epoch 1624 of 2000 took 0.100s
  training loss:		0.524584
  validation loss:		0.587097
  validation accuracy:		81.41 %
Epoch 1625 of 2000 took 0.099s
  training loss:		0.523292
  validation loss:		0.589837
  validation accuracy:		81.41 %
Epoch 1626 of 2000 took 0.099s
  training loss:		0.519040
  validation loss:		0.590722
  validation accuracy:		81.52 %
Epoch 1627 of 2000 took 0.099s
  training loss:		0.525431
  validation loss:		0.600705
  validation accuracy:		80.33 %
Epoch 1628 of 2000 took 0.100s
  training loss:		0.524228
  validation loss:		0.604321
  validation accuracy:		81.20 %
Epoch 1629 of 2000 took 0.099s
  training loss:		0.520728
  validation loss:		0.591449
  validation accuracy:		81.30 %
Epoch 1630 of 2000 took 0.099s
  training loss:		0.538115
  validation loss:		0.615273
  validation accuracy:		80.00 %
Epoch 1631 of 2000 took 0.099s
  training loss:		0.527122
  validation loss:		0.597968
  validation accuracy:		81.09 %
Epoch 1632 of 2000 took 0.100s
  training loss:		0.532516
  validation loss:		0.601615
  validation accuracy:		80.87 %
Epoch 1633 of 2000 took 0.099s
  training loss:		0.526636
  validation loss:		0.607660
  validation accuracy:		81.20 %
Epoch 1634 of 2000 took 0.099s
  training loss:		0.529044
  validation loss:		0.605784
  validation accuracy:		81.52 %
Epoch 1635 of 2000 took 0.099s
  training loss:		0.520783
  validation loss:		0.587553
  validation accuracy:		81.30 %
Epoch 1636 of 2000 took 0.100s
  training loss:		0.522900
  validation loss:		0.594247
  validation accuracy:		81.09 %
Epoch 1637 of 2000 took 0.099s
  training loss:		0.528219
  validation loss:		0.603020
  validation accuracy:		81.30 %
Epoch 1638 of 2000 took 0.099s
  training loss:		0.520383
  validation loss:		0.587798
  validation accuracy:		81.52 %
Epoch 1639 of 2000 took 0.100s
  training loss:		0.519222
  validation loss:		0.581830
  validation accuracy:		81.41 %
Epoch 1640 of 2000 took 0.099s
  training loss:		0.513750
  validation loss:		0.588927
  validation accuracy:		80.87 %
Epoch 1641 of 2000 took 0.100s
  training loss:		0.519941
  validation loss:		0.585032
  validation accuracy:		81.09 %
Epoch 1642 of 2000 took 0.099s
  training loss:		0.526476
  validation loss:		0.593913
  validation accuracy:		81.85 %
Epoch 1643 of 2000 took 0.099s
  training loss:		0.525322
  validation loss:		0.591439
  validation accuracy:		80.98 %
Epoch 1644 of 2000 took 0.100s
  training loss:		0.516612
  validation loss:		0.593741
  validation accuracy:		80.98 %
Epoch 1645 of 2000 took 0.099s
  training loss:		0.521964
  validation loss:		0.593799
  validation accuracy:		81.09 %
Epoch 1646 of 2000 took 0.100s
  training loss:		0.521264
  validation loss:		0.587330
  validation accuracy:		81.74 %
Epoch 1647 of 2000 took 0.100s
  training loss:		0.517120
  validation loss:		0.591508
  validation accuracy:		82.50 %
Epoch 1648 of 2000 took 0.100s
  training loss:		0.525721
  validation loss:		0.584390
  validation accuracy:		81.85 %
Epoch 1649 of 2000 took 0.100s
  training loss:		0.528381
  validation loss:		0.593450
  validation accuracy:		81.09 %
Epoch 1650 of 2000 took 0.100s
  training loss:		0.526329
  validation loss:		0.604975
  validation accuracy:		82.61 %
Epoch 1651 of 2000 took 0.099s
  training loss:		0.532767
  validation loss:		0.588416
  validation accuracy:		81.63 %
Epoch 1652 of 2000 took 0.100s
  training loss:		0.520413
  validation loss:		0.586860
  validation accuracy:		82.61 %
Epoch 1653 of 2000 took 0.099s
  training loss:		0.521405
  validation loss:		0.585197
  validation accuracy:		81.41 %
Epoch 1654 of 2000 took 0.099s
  training loss:		0.514593
  validation loss:		0.591410
  validation accuracy:		81.41 %
Epoch 1655 of 2000 took 0.099s
  training loss:		0.525829
  validation loss:		0.588874
  validation accuracy:		81.20 %
Epoch 1656 of 2000 took 0.100s
  training loss:		0.526852
  validation loss:		0.591088
  validation accuracy:		81.52 %
Epoch 1657 of 2000 took 0.099s
  training loss:		0.530224
  validation loss:		0.598885
  validation accuracy:		80.54 %
Epoch 1658 of 2000 took 0.099s
  training loss:		0.523850
  validation loss:		0.584192
  validation accuracy:		81.52 %
Epoch 1659 of 2000 took 0.099s
  training loss:		0.522691
  validation loss:		0.609894
  validation accuracy:		80.54 %
Epoch 1660 of 2000 took 0.100s
  training loss:		0.527807
  validation loss:		0.583856
  validation accuracy:		81.52 %
Epoch 1661 of 2000 took 0.099s
  training loss:		0.521520
  validation loss:		0.585494
  validation accuracy:		81.63 %
Epoch 1662 of 2000 took 0.099s
  training loss:		0.516207
  validation loss:		0.599743
  validation accuracy:		80.87 %
Epoch 1663 of 2000 took 0.099s
  training loss:		0.515165
  validation loss:		0.616596
  validation accuracy:		80.22 %
Epoch 1664 of 2000 took 0.099s
  training loss:		0.529007
  validation loss:		0.596661
  validation accuracy:		81.09 %
Epoch 1665 of 2000 took 0.099s
  training loss:		0.521897
  validation loss:		0.604724
  validation accuracy:		81.63 %
Epoch 1666 of 2000 took 0.100s
  training loss:		0.524120
  validation loss:		0.592157
  validation accuracy:		81.09 %
Epoch 1667 of 2000 took 0.099s
  training loss:		0.524036
  validation loss:		0.589748
  validation accuracy:		82.07 %
Epoch 1668 of 2000 took 0.099s
  training loss:		0.523010
  validation loss:		0.617095
  validation accuracy:		79.78 %
Epoch 1669 of 2000 took 0.099s
  training loss:		0.537648
  validation loss:		0.615612
  validation accuracy:		79.57 %
Epoch 1670 of 2000 took 0.099s
  training loss:		0.516086
  validation loss:		0.604695
  validation accuracy:		81.09 %
Epoch 1671 of 2000 took 0.099s
  training loss:		0.523284
  validation loss:		0.586093
  validation accuracy:		81.52 %
Epoch 1672 of 2000 took 0.099s
  training loss:		0.514842
  validation loss:		0.590682
  validation accuracy:		80.98 %
Epoch 1673 of 2000 took 0.099s
  training loss:		0.519370
  validation loss:		0.587365
  validation accuracy:		81.52 %
Epoch 1674 of 2000 took 0.100s
  training loss:		0.518843
  validation loss:		0.588244
  validation accuracy:		81.41 %
Epoch 1675 of 2000 took 0.099s
  training loss:		0.526826
  validation loss:		0.599030
  validation accuracy:		81.20 %
Epoch 1676 of 2000 took 0.100s
  training loss:		0.524108
  validation loss:		0.584328
  validation accuracy:		81.41 %
Epoch 1677 of 2000 took 0.100s
  training loss:		0.528204
  validation loss:		0.594381
  validation accuracy:		81.52 %
Epoch 1678 of 2000 took 0.099s
  training loss:		0.513479
  validation loss:		0.591346
  validation accuracy:		81.20 %
Epoch 1679 of 2000 took 0.099s
  training loss:		0.528489
  validation loss:		0.594606
  validation accuracy:		81.74 %
Epoch 1680 of 2000 took 0.100s
  training loss:		0.525020
  validation loss:		0.594404
  validation accuracy:		81.09 %
Epoch 1681 of 2000 took 0.099s
  training loss:		0.523867
  validation loss:		0.601971
  validation accuracy:		80.54 %
Epoch 1682 of 2000 took 0.100s
  training loss:		0.525290
  validation loss:		0.587555
  validation accuracy:		81.30 %
Epoch 1683 of 2000 took 0.099s
  training loss:		0.528955
  validation loss:		0.585087
  validation accuracy:		82.07 %
Epoch 1684 of 2000 took 0.099s
  training loss:		0.523994
  validation loss:		0.594110
  validation accuracy:		81.20 %
Epoch 1685 of 2000 took 0.099s
  training loss:		0.533567
  validation loss:		0.594581
  validation accuracy:		81.09 %
Epoch 1686 of 2000 took 0.100s
  training loss:		0.519703
  validation loss:		0.584298
  validation accuracy:		81.96 %
Epoch 1687 of 2000 took 0.100s
  training loss:		0.526045
  validation loss:		0.590823
  validation accuracy:		81.20 %
Epoch 1688 of 2000 took 0.100s
  training loss:		0.523706
  validation loss:		0.595215
  validation accuracy:		81.30 %
Epoch 1689 of 2000 took 0.100s
  training loss:		0.542017
  validation loss:		0.602506
  validation accuracy:		81.20 %
Epoch 1690 of 2000 took 0.100s
  training loss:		0.526577
  validation loss:		0.599478
  validation accuracy:		82.50 %
Epoch 1691 of 2000 took 0.099s
  training loss:		0.529515
  validation loss:		0.587467
  validation accuracy:		81.30 %
Epoch 1692 of 2000 took 0.099s
  training loss:		0.514703
  validation loss:		0.604098
  validation accuracy:		80.98 %
Epoch 1693 of 2000 took 0.099s
  training loss:		0.521700
  validation loss:		0.591861
  validation accuracy:		80.87 %
Epoch 1694 of 2000 took 0.100s
  training loss:		0.522582
  validation loss:		0.586642
  validation accuracy:		81.20 %
Epoch 1695 of 2000 took 0.099s
  training loss:		0.520373
  validation loss:		0.583802
  validation accuracy:		80.98 %
Epoch 1696 of 2000 took 0.099s
  training loss:		0.519240
  validation loss:		0.588423
  validation accuracy:		81.74 %
Epoch 1697 of 2000 took 0.100s
  training loss:		0.514318
  validation loss:		0.589189
  validation accuracy:		80.98 %
Epoch 1698 of 2000 took 0.100s
  training loss:		0.520413
  validation loss:		0.587104
  validation accuracy:		80.76 %
Epoch 1699 of 2000 took 0.099s
  training loss:		0.518820
  validation loss:		0.588605
  validation accuracy:		81.30 %
Epoch 1700 of 2000 took 0.099s
  training loss:		0.523963
  validation loss:		0.588380
  validation accuracy:		80.87 %
Epoch 1701 of 2000 took 0.099s
  training loss:		0.525705
  validation loss:		0.585539
  validation accuracy:		80.98 %
Epoch 1702 of 2000 took 0.100s
  training loss:		0.521547
  validation loss:		0.583968
  validation accuracy:		81.74 %
Epoch 1703 of 2000 took 0.099s
  training loss:		0.522264
  validation loss:		0.591839
  validation accuracy:		80.87 %
Epoch 1704 of 2000 took 0.099s
  training loss:		0.518951
  validation loss:		0.614156
  validation accuracy:		80.98 %
Epoch 1705 of 2000 took 0.099s
  training loss:		0.528427
  validation loss:		0.581932
  validation accuracy:		81.63 %
Epoch 1706 of 2000 took 0.100s
  training loss:		0.522873
  validation loss:		0.600826
  validation accuracy:		80.33 %
Epoch 1707 of 2000 took 0.103s
  training loss:		0.526455
  validation loss:		0.590234
  validation accuracy:		81.41 %
Epoch 1708 of 2000 took 0.100s
  training loss:		0.523546
  validation loss:		0.588325
  validation accuracy:		81.09 %
Epoch 1709 of 2000 took 0.099s
  training loss:		0.522792
  validation loss:		0.587844
  validation accuracy:		81.20 %
Epoch 1710 of 2000 took 0.099s
  training loss:		0.522138
  validation loss:		0.608389
  validation accuracy:		80.33 %
Epoch 1711 of 2000 took 0.099s
  training loss:		0.523530
  validation loss:		0.586372
  validation accuracy:		81.63 %
Epoch 1712 of 2000 took 0.097s
  training loss:		0.521620
  validation loss:		0.593916
  validation accuracy:		81.20 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.521280
  validation loss:		0.601667
  validation accuracy:		79.57 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.515407
  validation loss:		0.591648
  validation accuracy:		81.20 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.510778
  validation loss:		0.583610
  validation accuracy:		81.63 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.524433
  validation loss:		0.588751
  validation accuracy:		81.30 %
Epoch 1717 of 2000 took 0.096s
  training loss:		0.526269
  validation loss:		0.608718
  validation accuracy:		80.33 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.517426
  validation loss:		0.579474
  validation accuracy:		81.20 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.521203
  validation loss:		0.584549
  validation accuracy:		81.63 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.526345
  validation loss:		0.600487
  validation accuracy:		80.98 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.522861
  validation loss:		0.587780
  validation accuracy:		81.30 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.528391
  validation loss:		0.587755
  validation accuracy:		81.41 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.520116
  validation loss:		0.621430
  validation accuracy:		79.89 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.518912
  validation loss:		0.592042
  validation accuracy:		81.30 %
Epoch 1725 of 2000 took 0.097s
  training loss:		0.520952
  validation loss:		0.583665
  validation accuracy:		81.30 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.516942
  validation loss:		0.592572
  validation accuracy:		82.61 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.516801
  validation loss:		0.590800
  validation accuracy:		81.30 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.532042
  validation loss:		0.581273
  validation accuracy:		81.74 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.520601
  validation loss:		0.594681
  validation accuracy:		82.83 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.523316
  validation loss:		0.603521
  validation accuracy:		80.33 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.524242
  validation loss:		0.605044
  validation accuracy:		80.76 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.519837
  validation loss:		0.583909
  validation accuracy:		81.30 %
Epoch 1733 of 2000 took 0.097s
  training loss:		0.511623
  validation loss:		0.590966
  validation accuracy:		81.20 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.520368
  validation loss:		0.581689
  validation accuracy:		82.07 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.519154
  validation loss:		0.586183
  validation accuracy:		81.63 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.524237
  validation loss:		0.584474
  validation accuracy:		81.85 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.519521
  validation loss:		0.616131
  validation accuracy:		80.43 %
Epoch 1738 of 2000 took 0.097s
  training loss:		0.529899
  validation loss:		0.597795
  validation accuracy:		81.09 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.522296
  validation loss:		0.590662
  validation accuracy:		81.96 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.519821
  validation loss:		0.587198
  validation accuracy:		81.41 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.530165
  validation loss:		0.597510
  validation accuracy:		80.87 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.534677
  validation loss:		0.578710
  validation accuracy:		81.96 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.526325
  validation loss:		0.595130
  validation accuracy:		81.52 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.522191
  validation loss:		0.588537
  validation accuracy:		81.20 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.524212
  validation loss:		0.583399
  validation accuracy:		81.96 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.524852
  validation loss:		0.587430
  validation accuracy:		81.85 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.528027
  validation loss:		0.603268
  validation accuracy:		80.76 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.517226
  validation loss:		0.587336
  validation accuracy:		81.20 %
Epoch 1749 of 2000 took 0.096s
  training loss:		0.521211
  validation loss:		0.590693
  validation accuracy:		81.41 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.528652
  validation loss:		0.588649
  validation accuracy:		80.98 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.529904
  validation loss:		0.610153
  validation accuracy:		79.78 %
Epoch 1752 of 2000 took 0.096s
  training loss:		0.531688
  validation loss:		0.600413
  validation accuracy:		81.30 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.528065
  validation loss:		0.597016
  validation accuracy:		81.09 %
Epoch 1754 of 2000 took 0.097s
  training loss:		0.528324
  validation loss:		0.586438
  validation accuracy:		81.41 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.520671
  validation loss:		0.593140
  validation accuracy:		80.87 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.526378
  validation loss:		0.584168
  validation accuracy:		81.96 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.517908
  validation loss:		0.595400
  validation accuracy:		81.09 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.516929
  validation loss:		0.591603
  validation accuracy:		81.20 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.521454
  validation loss:		0.602052
  validation accuracy:		81.09 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.520157
  validation loss:		0.584968
  validation accuracy:		81.41 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.526212
  validation loss:		0.589720
  validation accuracy:		81.20 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.515094
  validation loss:		0.590043
  validation accuracy:		81.52 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.521855
  validation loss:		0.597015
  validation accuracy:		80.43 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.519920
  validation loss:		0.600363
  validation accuracy:		81.20 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.528256
  validation loss:		0.588457
  validation accuracy:		81.74 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.531081
  validation loss:		0.597137
  validation accuracy:		81.20 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.523937
  validation loss:		0.593861
  validation accuracy:		80.98 %
Epoch 1768 of 2000 took 0.098s
  training loss:		0.520482
  validation loss:		0.583431
  validation accuracy:		81.20 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.523261
  validation loss:		0.593716
  validation accuracy:		81.41 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.515869
  validation loss:		0.592826
  validation accuracy:		82.50 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.516974
  validation loss:		0.590046
  validation accuracy:		81.41 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.526416
  validation loss:		0.584972
  validation accuracy:		81.30 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.519606
  validation loss:		0.589873
  validation accuracy:		81.52 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.518956
  validation loss:		0.584686
  validation accuracy:		81.41 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.520779
  validation loss:		0.586381
  validation accuracy:		80.98 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.521846
  validation loss:		0.596613
  validation accuracy:		80.98 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.525146
  validation loss:		0.583387
  validation accuracy:		81.30 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.518098
  validation loss:		0.583708
  validation accuracy:		81.30 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.520937
  validation loss:		0.585889
  validation accuracy:		81.20 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.517822
  validation loss:		0.599875
  validation accuracy:		81.30 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.521240
  validation loss:		0.596601
  validation accuracy:		81.74 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.525041
  validation loss:		0.582722
  validation accuracy:		81.52 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.523016
  validation loss:		0.586769
  validation accuracy:		81.30 %
Epoch 1784 of 2000 took 0.096s
  training loss:		0.523995
  validation loss:		0.589943
  validation accuracy:		80.87 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.524710
  validation loss:		0.593848
  validation accuracy:		81.30 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.521154
  validation loss:		0.588092
  validation accuracy:		81.20 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.512760
  validation loss:		0.588846
  validation accuracy:		81.30 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.528982
  validation loss:		0.586493
  validation accuracy:		81.85 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.522225
  validation loss:		0.589525
  validation accuracy:		81.63 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.524154
  validation loss:		0.598451
  validation accuracy:		80.43 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.525905
  validation loss:		0.587176
  validation accuracy:		81.09 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.525947
  validation loss:		0.589732
  validation accuracy:		81.30 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.518748
  validation loss:		0.588994
  validation accuracy:		81.52 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.512013
  validation loss:		0.584826
  validation accuracy:		81.74 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.522230
  validation loss:		0.599248
  validation accuracy:		81.63 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.523572
  validation loss:		0.593127
  validation accuracy:		81.20 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.525435
  validation loss:		0.614355
  validation accuracy:		81.30 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.528535
  validation loss:		0.591627
  validation accuracy:		81.41 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.525725
  validation loss:		0.595702
  validation accuracy:		80.87 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.526746
  validation loss:		0.599415
  validation accuracy:		80.98 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.529642
  validation loss:		0.592839
  validation accuracy:		80.76 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.520884
  validation loss:		0.590767
  validation accuracy:		81.52 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.527330
  validation loss:		0.596430
  validation accuracy:		81.09 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.514621
  validation loss:		0.584556
  validation accuracy:		81.74 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.517837
  validation loss:		0.585713
  validation accuracy:		81.63 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.520428
  validation loss:		0.593178
  validation accuracy:		80.65 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.528057
  validation loss:		0.598794
  validation accuracy:		80.65 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.526461
  validation loss:		0.593081
  validation accuracy:		80.87 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.521952
  validation loss:		0.592787
  validation accuracy:		81.30 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.522874
  validation loss:		0.609239
  validation accuracy:		80.87 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.527079
  validation loss:		0.587846
  validation accuracy:		81.20 %
Epoch 1812 of 2000 took 0.096s
  training loss:		0.517475
  validation loss:		0.588731
  validation accuracy:		81.63 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.517278
  validation loss:		0.593244
  validation accuracy:		81.09 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.523013
  validation loss:		0.594576
  validation accuracy:		80.22 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.536101
  validation loss:		0.584321
  validation accuracy:		81.63 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.526774
  validation loss:		0.584558
  validation accuracy:		81.85 %
Epoch 1817 of 2000 took 0.096s
  training loss:		0.519181
  validation loss:		0.614812
  validation accuracy:		80.54 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.528654
  validation loss:		0.590018
  validation accuracy:		80.65 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.514625
  validation loss:		0.595028
  validation accuracy:		81.20 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.518970
  validation loss:		0.593483
  validation accuracy:		81.09 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.520476
  validation loss:		0.586246
  validation accuracy:		81.52 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.518109
  validation loss:		0.589049
  validation accuracy:		81.09 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.525724
  validation loss:		0.602892
  validation accuracy:		81.09 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.525630
  validation loss:		0.588332
  validation accuracy:		81.41 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.525450
  validation loss:		0.599773
  validation accuracy:		80.76 %
Epoch 1826 of 2000 took 0.096s
  training loss:		0.521190
  validation loss:		0.590247
  validation accuracy:		81.20 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.530381
  validation loss:		0.600557
  validation accuracy:		80.33 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.522095
  validation loss:		0.585604
  validation accuracy:		81.41 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.516016
  validation loss:		0.583916
  validation accuracy:		82.07 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.521237
  validation loss:		0.599519
  validation accuracy:		80.65 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.517387
  validation loss:		0.590057
  validation accuracy:		81.30 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.525563
  validation loss:		0.586619
  validation accuracy:		81.63 %
Epoch 1833 of 2000 took 0.096s
  training loss:		0.524801
  validation loss:		0.587097
  validation accuracy:		81.30 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.521455
  validation loss:		0.594162
  validation accuracy:		81.20 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.520576
  validation loss:		0.582204
  validation accuracy:		81.52 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.522580
  validation loss:		0.586545
  validation accuracy:		81.52 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.518559
  validation loss:		0.603142
  validation accuracy:		80.33 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.535303
  validation loss:		0.587604
  validation accuracy:		82.39 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.515370
  validation loss:		0.592136
  validation accuracy:		81.52 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.518124
  validation loss:		0.611690
  validation accuracy:		80.98 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.524404
  validation loss:		0.587797
  validation accuracy:		81.63 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.524307
  validation loss:		0.588255
  validation accuracy:		81.41 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.522749
  validation loss:		0.588321
  validation accuracy:		80.98 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.514882
  validation loss:		0.592894
  validation accuracy:		80.87 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.516342
  validation loss:		0.603505
  validation accuracy:		80.54 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.523799
  validation loss:		0.583875
  validation accuracy:		81.41 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.530625
  validation loss:		0.587799
  validation accuracy:		81.85 %
Epoch 1848 of 2000 took 0.096s
  training loss:		0.524324
  validation loss:		0.587640
  validation accuracy:		81.74 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.518442
  validation loss:		0.607634
  validation accuracy:		80.87 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.528047
  validation loss:		0.599299
  validation accuracy:		80.65 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.520606
  validation loss:		0.587616
  validation accuracy:		81.20 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.524386
  validation loss:		0.586900
  validation accuracy:		81.30 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.521847
  validation loss:		0.615786
  validation accuracy:		80.65 %
Epoch 1854 of 2000 took 0.096s
  training loss:		0.520853
  validation loss:		0.581331
  validation accuracy:		81.52 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.521631
  validation loss:		0.607299
  validation accuracy:		80.87 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.515850
  validation loss:		0.588557
  validation accuracy:		81.63 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.517649
  validation loss:		0.584474
  validation accuracy:		81.20 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.515195
  validation loss:		0.583479
  validation accuracy:		81.41 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.525450
  validation loss:		0.607321
  validation accuracy:		80.00 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.533310
  validation loss:		0.594083
  validation accuracy:		81.09 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.523774
  validation loss:		0.598397
  validation accuracy:		80.43 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.517342
  validation loss:		0.582701
  validation accuracy:		81.41 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.521093
  validation loss:		0.583175
  validation accuracy:		82.39 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.520021
  validation loss:		0.585903
  validation accuracy:		81.09 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.506532
  validation loss:		0.588900
  validation accuracy:		81.30 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.517237
  validation loss:		0.584422
  validation accuracy:		81.41 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.523735
  validation loss:		0.587495
  validation accuracy:		81.41 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.529303
  validation loss:		0.592100
  validation accuracy:		81.30 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.525447
  validation loss:		0.591257
  validation accuracy:		81.20 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.516698
  validation loss:		0.593850
  validation accuracy:		80.87 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.518248
  validation loss:		0.594846
  validation accuracy:		80.76 %
Epoch 1872 of 2000 took 0.097s
  training loss:		0.518368
  validation loss:		0.585581
  validation accuracy:		81.96 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.514907
  validation loss:		0.583290
  validation accuracy:		81.09 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.515264
  validation loss:		0.580654
  validation accuracy:		81.52 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.523747
  validation loss:		0.600726
  validation accuracy:		81.30 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.520313
  validation loss:		0.587929
  validation accuracy:		80.98 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.525772
  validation loss:		0.599609
  validation accuracy:		80.98 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.524661
  validation loss:		0.585514
  validation accuracy:		81.41 %
Epoch 1879 of 2000 took 0.098s
  training loss:		0.530755
  validation loss:		0.584818
  validation accuracy:		81.30 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.525292
  validation loss:		0.591106
  validation accuracy:		82.17 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.511694
  validation loss:		0.617931
  validation accuracy:		80.43 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.516995
  validation loss:		0.584920
  validation accuracy:		81.96 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.526770
  validation loss:		0.593528
  validation accuracy:		81.20 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.514663
  validation loss:		0.583230
  validation accuracy:		81.74 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.521440
  validation loss:		0.590743
  validation accuracy:		80.98 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.520908
  validation loss:		0.595692
  validation accuracy:		80.00 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.521447
  validation loss:		0.587329
  validation accuracy:		81.09 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.517226
  validation loss:		0.587993
  validation accuracy:		81.63 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.520423
  validation loss:		0.590226
  validation accuracy:		81.09 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.521600
  validation loss:		0.591507
  validation accuracy:		81.20 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.517483
  validation loss:		0.586033
  validation accuracy:		81.74 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.519510
  validation loss:		0.600203
  validation accuracy:		81.09 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.520178
  validation loss:		0.596220
  validation accuracy:		80.11 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.521011
  validation loss:		0.599766
  validation accuracy:		80.65 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.522124
  validation loss:		0.600159
  validation accuracy:		80.87 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.516545
  validation loss:		0.596202
  validation accuracy:		81.09 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.514706
  validation loss:		0.594323
  validation accuracy:		81.63 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.520841
  validation loss:		0.582861
  validation accuracy:		81.20 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.528972
  validation loss:		0.586280
  validation accuracy:		81.30 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.516809
  validation loss:		0.599126
  validation accuracy:		81.09 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.524668
  validation loss:		0.589296
  validation accuracy:		81.20 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.520917
  validation loss:		0.600796
  validation accuracy:		80.87 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.528173
  validation loss:		0.591251
  validation accuracy:		81.41 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.512861
  validation loss:		0.584615
  validation accuracy:		81.30 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.514454
  validation loss:		0.589255
  validation accuracy:		81.41 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.514425
  validation loss:		0.586777
  validation accuracy:		81.41 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.517585
  validation loss:		0.585896
  validation accuracy:		81.30 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.527814
  validation loss:		0.586074
  validation accuracy:		81.52 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.524272
  validation loss:		0.585151
  validation accuracy:		81.52 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.515918
  validation loss:		0.595922
  validation accuracy:		80.33 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.522333
  validation loss:		0.598288
  validation accuracy:		80.33 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.521130
  validation loss:		0.585483
  validation accuracy:		81.30 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.524464
  validation loss:		0.587766
  validation accuracy:		81.09 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.523073
  validation loss:		0.587249
  validation accuracy:		81.30 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.522043
  validation loss:		0.582420
  validation accuracy:		81.41 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.521567
  validation loss:		0.592815
  validation accuracy:		81.20 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.512527
  validation loss:		0.612798
  validation accuracy:		80.98 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.523718
  validation loss:		0.589766
  validation accuracy:		80.54 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.516469
  validation loss:		0.603864
  validation accuracy:		80.33 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.524629
  validation loss:		0.595064
  validation accuracy:		81.20 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.526038
  validation loss:		0.590009
  validation accuracy:		81.09 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.515498
  validation loss:		0.585992
  validation accuracy:		82.50 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.515823
  validation loss:		0.587171
  validation accuracy:		81.85 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.526276
  validation loss:		0.601886
  validation accuracy:		80.98 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.521841
  validation loss:		0.588781
  validation accuracy:		81.09 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.512548
  validation loss:		0.596508
  validation accuracy:		80.87 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.522207
  validation loss:		0.601547
  validation accuracy:		80.76 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.528585
  validation loss:		0.585726
  validation accuracy:		82.28 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.520068
  validation loss:		0.595894
  validation accuracy:		80.22 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.515181
  validation loss:		0.600445
  validation accuracy:		80.22 %
Epoch 1931 of 2000 took 0.096s
  training loss:		0.530616
  validation loss:		0.599251
  validation accuracy:		80.76 %
Epoch 1932 of 2000 took 0.097s
  training loss:		0.521494
  validation loss:		0.588855
  validation accuracy:		81.09 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.523318
  validation loss:		0.595932
  validation accuracy:		80.00 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.521923
  validation loss:		0.588117
  validation accuracy:		80.98 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.517593
  validation loss:		0.613548
  validation accuracy:		80.11 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.524870
  validation loss:		0.582384
  validation accuracy:		81.41 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.523195
  validation loss:		0.588470
  validation accuracy:		82.17 %
Epoch 1938 of 2000 took 0.097s
  training loss:		0.517917
  validation loss:		0.583669
  validation accuracy:		82.17 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.529848
  validation loss:		0.604204
  validation accuracy:		80.98 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.521482
  validation loss:		0.590359
  validation accuracy:		81.20 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.514019
  validation loss:		0.584080
  validation accuracy:		81.52 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.513442
  validation loss:		0.602224
  validation accuracy:		81.09 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.522671
  validation loss:		0.600603
  validation accuracy:		80.87 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.525452
  validation loss:		0.586445
  validation accuracy:		81.09 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.522020
  validation loss:		0.602867
  validation accuracy:		81.30 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.518610
  validation loss:		0.588895
  validation accuracy:		81.41 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.518901
  validation loss:		0.586689
  validation accuracy:		80.87 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.521160
  validation loss:		0.596818
  validation accuracy:		80.54 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.522693
  validation loss:		0.602562
  validation accuracy:		80.76 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.522088
  validation loss:		0.612687
  validation accuracy:		79.78 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.523891
  validation loss:		0.583082
  validation accuracy:		81.20 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.519667
  validation loss:		0.595023
  validation accuracy:		81.09 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.521753
  validation loss:		0.585000
  validation accuracy:		82.50 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.515941
  validation loss:		0.589615
  validation accuracy:		81.09 %
Epoch 1955 of 2000 took 0.097s
  training loss:		0.521590
  validation loss:		0.581040
  validation accuracy:		81.52 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.518694
  validation loss:		0.589008
  validation accuracy:		80.98 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.520373
  validation loss:		0.591620
  validation accuracy:		81.41 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.521105
  validation loss:		0.590444
  validation accuracy:		81.20 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.517615
  validation loss:		0.594799
  validation accuracy:		81.09 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.518695
  validation loss:		0.591070
  validation accuracy:		81.41 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.518226
  validation loss:		0.584381
  validation accuracy:		81.09 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.520730
  validation loss:		0.585795
  validation accuracy:		81.09 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.520160
  validation loss:		0.591366
  validation accuracy:		81.20 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.520998
  validation loss:		0.589381
  validation accuracy:		81.20 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.520466
  validation loss:		0.583891
  validation accuracy:		81.41 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.516874
  validation loss:		0.599340
  validation accuracy:		80.76 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.519885
  validation loss:		0.590401
  validation accuracy:		80.76 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.525128
  validation loss:		0.591492
  validation accuracy:		82.17 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.516157
  validation loss:		0.580918
  validation accuracy:		81.30 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.522234
  validation loss:		0.599846
  validation accuracy:		81.41 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.519908
  validation loss:		0.603517
  validation accuracy:		80.87 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.515767
  validation loss:		0.585141
  validation accuracy:		82.83 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.523898
  validation loss:		0.581488
  validation accuracy:		81.41 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.520863
  validation loss:		0.597265
  validation accuracy:		81.30 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.523562
  validation loss:		0.589071
  validation accuracy:		80.98 %
Epoch 1976 of 2000 took 0.097s
  training loss:		0.520608
  validation loss:		0.585820
  validation accuracy:		81.20 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.520924
  validation loss:		0.584193
  validation accuracy:		81.41 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.523430
  validation loss:		0.588271
  validation accuracy:		81.63 %
Epoch 1979 of 2000 took 0.097s
  training loss:		0.519749
  validation loss:		0.587204
  validation accuracy:		81.52 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.519038
  validation loss:		0.585603
  validation accuracy:		81.30 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.522019
  validation loss:		0.585316
  validation accuracy:		80.98 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.520183
  validation loss:		0.591976
  validation accuracy:		81.09 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.517887
  validation loss:		0.605774
  validation accuracy:		80.54 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.511832
  validation loss:		0.613892
  validation accuracy:		80.54 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.522390
  validation loss:		0.599908
  validation accuracy:		81.74 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.520129
  validation loss:		0.598279
  validation accuracy:		80.65 %
Epoch 1987 of 2000 took 0.097s
  training loss:		0.525752
  validation loss:		0.587230
  validation accuracy:		81.41 %
Epoch 1988 of 2000 took 0.097s
  training loss:		0.514104
  validation loss:		0.593937
  validation accuracy:		81.20 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.512267
  validation loss:		0.602384
  validation accuracy:		80.22 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.529231
  validation loss:		0.584908
  validation accuracy:		81.63 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.521329
  validation loss:		0.583293
  validation accuracy:		81.52 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.518743
  validation loss:		0.589293
  validation accuracy:		80.87 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.525432
  validation loss:		0.585157
  validation accuracy:		81.20 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.518946
  validation loss:		0.594324
  validation accuracy:		80.98 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.516516
  validation loss:		0.587621
  validation accuracy:		81.52 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.518754
  validation loss:		0.581711
  validation accuracy:		81.09 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.513452
  validation loss:		0.589410
  validation accuracy:		81.52 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.514875
  validation loss:		0.582967
  validation accuracy:		81.74 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.520593
  validation loss:		0.593237
  validation accuracy:		80.98 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.521577
  validation loss:		0.602021
  validation accuracy:		80.65 %
Final results:
  test loss:			0.945916
  test accuracy:		72.05 %
