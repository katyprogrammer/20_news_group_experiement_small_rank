Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.148s
  training loss:		2.942634
  validation loss:		2.854716
  validation accuracy:		15.22 %
Epoch 2 of 2000 took 0.171s
  training loss:		2.776523
  validation loss:		2.654982
  validation accuracy:		17.50 %
Epoch 3 of 2000 took 0.166s
  training loss:		2.586938
  validation loss:		2.454295
  validation accuracy:		22.39 %
Epoch 4 of 2000 took 0.150s
  training loss:		2.423926
  validation loss:		2.296298
  validation accuracy:		26.85 %
Epoch 5 of 2000 took 0.150s
  training loss:		2.315670
  validation loss:		2.211361
  validation accuracy:		43.91 %
Epoch 6 of 2000 took 0.147s
  training loss:		2.260203
  validation loss:		2.174323
  validation accuracy:		45.00 %
Epoch 7 of 2000 took 0.149s
  training loss:		2.225103
  validation loss:		2.154244
  validation accuracy:		43.04 %
Epoch 8 of 2000 took 0.148s
  training loss:		2.201015
  validation loss:		2.123131
  validation accuracy:		45.43 %
Epoch 9 of 2000 took 0.147s
  training loss:		2.178149
  validation loss:		2.102576
  validation accuracy:		50.54 %
Epoch 10 of 2000 took 0.148s
  training loss:		2.157331
  validation loss:		2.076473
  validation accuracy:		47.07 %
Epoch 11 of 2000 took 0.152s
  training loss:		2.130800
  validation loss:		2.052732
  validation accuracy:		42.61 %
Epoch 12 of 2000 took 0.150s
  training loss:		2.108014
  validation loss:		2.029866
  validation accuracy:		50.65 %
Epoch 13 of 2000 took 0.143s
  training loss:		2.081235
  validation loss:		1.992596
  validation accuracy:		50.98 %
Epoch 14 of 2000 took 0.143s
  training loss:		2.051282
  validation loss:		1.964321
  validation accuracy:		49.67 %
Epoch 15 of 2000 took 0.143s
  training loss:		2.020678
  validation loss:		1.923405
  validation accuracy:		52.39 %
Epoch 16 of 2000 took 0.143s
  training loss:		1.982020
  validation loss:		1.882098
  validation accuracy:		51.63 %
Epoch 17 of 2000 took 0.153s
  training loss:		1.942966
  validation loss:		1.840719
  validation accuracy:		50.87 %
Epoch 18 of 2000 took 0.145s
  training loss:		1.904973
  validation loss:		1.795418
  validation accuracy:		57.50 %
Epoch 19 of 2000 took 0.139s
  training loss:		1.858838
  validation loss:		1.756157
  validation accuracy:		55.33 %
Epoch 20 of 2000 took 0.140s
  training loss:		1.814371
  validation loss:		1.698764
  validation accuracy:		56.85 %
Epoch 21 of 2000 took 0.145s
  training loss:		1.764458
  validation loss:		1.651614
  validation accuracy:		57.61 %
Epoch 22 of 2000 took 0.142s
  training loss:		1.714702
  validation loss:		1.601901
  validation accuracy:		59.02 %
Epoch 23 of 2000 took 0.137s
  training loss:		1.667552
  validation loss:		1.554889
  validation accuracy:		59.89 %
Epoch 24 of 2000 took 0.140s
  training loss:		1.620838
  validation loss:		1.504473
  validation accuracy:		63.15 %
Epoch 25 of 2000 took 0.142s
  training loss:		1.572021
  validation loss:		1.458491
  validation accuracy:		62.72 %
Epoch 26 of 2000 took 0.140s
  training loss:		1.521302
  validation loss:		1.414867
  validation accuracy:		64.89 %
Epoch 27 of 2000 took 0.140s
  training loss:		1.475077
  validation loss:		1.352327
  validation accuracy:		66.09 %
Epoch 28 of 2000 took 0.138s
  training loss:		1.425806
  validation loss:		1.324472
  validation accuracy:		65.65 %
Epoch 29 of 2000 took 0.140s
  training loss:		1.386266
  validation loss:		1.271095
  validation accuracy:		67.61 %
Epoch 30 of 2000 took 0.132s
  training loss:		1.337920
  validation loss:		1.230745
  validation accuracy:		68.59 %
Epoch 31 of 2000 took 0.144s
  training loss:		1.297312
  validation loss:		1.184741
  validation accuracy:		69.46 %
Epoch 32 of 2000 took 0.138s
  training loss:		1.258075
  validation loss:		1.151016
  validation accuracy:		69.35 %
Epoch 33 of 2000 took 0.141s
  training loss:		1.218708
  validation loss:		1.120905
  validation accuracy:		70.43 %
Epoch 34 of 2000 took 0.143s
  training loss:		1.180825
  validation loss:		1.078637
  validation accuracy:		71.52 %
Epoch 35 of 2000 took 0.143s
  training loss:		1.145651
  validation loss:		1.051689
  validation accuracy:		71.30 %
Epoch 36 of 2000 took 0.138s
  training loss:		1.108283
  validation loss:		1.016939
  validation accuracy:		72.93 %
Epoch 37 of 2000 took 0.142s
  training loss:		1.074346
  validation loss:		0.982946
  validation accuracy:		73.80 %
Epoch 38 of 2000 took 0.142s
  training loss:		1.045947
  validation loss:		0.961257
  validation accuracy:		74.78 %
Epoch 39 of 2000 took 0.145s
  training loss:		1.010499
  validation loss:		0.936792
  validation accuracy:		75.76 %
Epoch 40 of 2000 took 0.139s
  training loss:		0.986053
  validation loss:		0.899737
  validation accuracy:		75.98 %
Epoch 41 of 2000 took 0.138s
  training loss:		0.952152
  validation loss:		0.881099
  validation accuracy:		76.85 %
Epoch 42 of 2000 took 0.140s
  training loss:		0.930195
  validation loss:		0.854644
  validation accuracy:		77.61 %
Epoch 43 of 2000 took 0.143s
  training loss:		0.906105
  validation loss:		0.825977
  validation accuracy:		78.80 %
Epoch 44 of 2000 took 0.142s
  training loss:		0.880848
  validation loss:		0.798904
  validation accuracy:		80.33 %
Epoch 45 of 2000 took 0.136s
  training loss:		0.855653
  validation loss:		0.785870
  validation accuracy:		80.65 %
Epoch 46 of 2000 took 0.144s
  training loss:		0.832000
  validation loss:		0.765247
  validation accuracy:		80.00 %
Epoch 47 of 2000 took 0.140s
  training loss:		0.804364
  validation loss:		0.738542
  validation accuracy:		82.17 %
Epoch 48 of 2000 took 0.141s
  training loss:		0.788724
  validation loss:		0.733957
  validation accuracy:		81.63 %
Epoch 49 of 2000 took 0.142s
  training loss:		0.771286
  validation loss:		0.706274
  validation accuracy:		82.28 %
Epoch 50 of 2000 took 0.170s
  training loss:		0.742402
  validation loss:		0.691667
  validation accuracy:		82.39 %
Epoch 51 of 2000 took 0.139s
  training loss:		0.733976
  validation loss:		0.670672
  validation accuracy:		83.59 %
Epoch 52 of 2000 took 0.141s
  training loss:		0.709302
  validation loss:		0.656711
  validation accuracy:		83.80 %
Epoch 53 of 2000 took 0.144s
  training loss:		0.693115
  validation loss:		0.629510
  validation accuracy:		84.67 %
Epoch 54 of 2000 took 0.138s
  training loss:		0.676031
  validation loss:		0.621340
  validation accuracy:		84.57 %
Epoch 55 of 2000 took 0.138s
  training loss:		0.650394
  validation loss:		0.607962
  validation accuracy:		84.67 %
Epoch 56 of 2000 took 0.141s
  training loss:		0.646651
  validation loss:		0.591262
  validation accuracy:		85.65 %
Epoch 57 of 2000 took 0.139s
  training loss:		0.625115
  validation loss:		0.576239
  validation accuracy:		86.09 %
Epoch 58 of 2000 took 0.141s
  training loss:		0.610092
  validation loss:		0.565595
  validation accuracy:		85.98 %
Epoch 59 of 2000 took 0.142s
  training loss:		0.599530
  validation loss:		0.557724
  validation accuracy:		86.41 %
Epoch 60 of 2000 took 0.145s
  training loss:		0.582947
  validation loss:		0.543220
  validation accuracy:		87.07 %
Epoch 61 of 2000 took 0.135s
  training loss:		0.569205
  validation loss:		0.520656
  validation accuracy:		88.04 %
Epoch 62 of 2000 took 0.144s
  training loss:		0.557370
  validation loss:		0.517260
  validation accuracy:		86.96 %
Epoch 63 of 2000 took 0.134s
  training loss:		0.545786
  validation loss:		0.504452
  validation accuracy:		87.17 %
Epoch 64 of 2000 took 0.141s
  training loss:		0.536125
  validation loss:		0.496696
  validation accuracy:		87.83 %
Epoch 65 of 2000 took 0.144s
  training loss:		0.529030
  validation loss:		0.488137
  validation accuracy:		87.83 %
Epoch 66 of 2000 took 0.141s
  training loss:		0.514522
  validation loss:		0.485052
  validation accuracy:		87.39 %
Epoch 67 of 2000 took 0.145s
  training loss:		0.500222
  validation loss:		0.467774
  validation accuracy:		87.93 %
Epoch 68 of 2000 took 0.135s
  training loss:		0.499528
  validation loss:		0.456727
  validation accuracy:		88.59 %
Epoch 69 of 2000 took 0.138s
  training loss:		0.486569
  validation loss:		0.441996
  validation accuracy:		88.91 %
Epoch 70 of 2000 took 0.140s
  training loss:		0.478647
  validation loss:		0.440939
  validation accuracy:		89.13 %
Epoch 71 of 2000 took 0.138s
  training loss:		0.469667
  validation loss:		0.439245
  validation accuracy:		88.37 %
Epoch 72 of 2000 took 0.139s
  training loss:		0.457905
  validation loss:		0.432863
  validation accuracy:		88.26 %
Epoch 73 of 2000 took 0.142s
  training loss:		0.452412
  validation loss:		0.426158
  validation accuracy:		89.35 %
Epoch 74 of 2000 took 0.144s
  training loss:		0.443529
  validation loss:		0.413123
  validation accuracy:		89.02 %
Epoch 75 of 2000 took 0.135s
  training loss:		0.436111
  validation loss:		0.408417
  validation accuracy:		89.24 %
Epoch 76 of 2000 took 0.141s
  training loss:		0.428072
  validation loss:		0.415806
  validation accuracy:		88.80 %
Epoch 77 of 2000 took 0.133s
  training loss:		0.427438
  validation loss:		0.397091
  validation accuracy:		89.24 %
Epoch 78 of 2000 took 0.144s
  training loss:		0.413970
  validation loss:		0.392907
  validation accuracy:		89.35 %
Epoch 79 of 2000 took 0.151s
  training loss:		0.411903
  validation loss:		0.386065
  validation accuracy:		89.89 %
Epoch 80 of 2000 took 0.158s
  training loss:		0.409344
  validation loss:		0.375885
  validation accuracy:		90.00 %
Epoch 81 of 2000 took 0.158s
  training loss:		0.397942
  validation loss:		0.378569
  validation accuracy:		89.89 %
Epoch 82 of 2000 took 0.173s
  training loss:		0.393882
  validation loss:		0.370573
  validation accuracy:		89.67 %
Epoch 83 of 2000 took 0.181s
  training loss:		0.388804
  validation loss:		0.377360
  validation accuracy:		90.11 %
Epoch 84 of 2000 took 0.192s
  training loss:		0.379735
  validation loss:		0.362959
  validation accuracy:		89.78 %
Epoch 85 of 2000 took 0.155s
  training loss:		0.373563
  validation loss:		0.361649
  validation accuracy:		90.43 %
Epoch 86 of 2000 took 0.139s
  training loss:		0.372217
  validation loss:		0.370793
  validation accuracy:		90.22 %
Epoch 87 of 2000 took 0.137s
  training loss:		0.367969
  validation loss:		0.357205
  validation accuracy:		90.54 %
Epoch 88 of 2000 took 0.138s
  training loss:		0.366009
  validation loss:		0.344514
  validation accuracy:		90.54 %
Epoch 89 of 2000 took 0.133s
  training loss:		0.357556
  validation loss:		0.340918
  validation accuracy:		90.65 %
Epoch 90 of 2000 took 0.143s
  training loss:		0.352426
  validation loss:		0.340839
  validation accuracy:		90.76 %
Epoch 91 of 2000 took 0.140s
  training loss:		0.350556
  validation loss:		0.337743
  validation accuracy:		90.65 %
Epoch 92 of 2000 took 0.142s
  training loss:		0.340846
  validation loss:		0.349279
  validation accuracy:		90.33 %
Epoch 93 of 2000 took 0.146s
  training loss:		0.345677
  validation loss:		0.333987
  validation accuracy:		90.65 %
Epoch 94 of 2000 took 0.136s
  training loss:		0.334322
  validation loss:		0.330563
  validation accuracy:		91.09 %
Epoch 95 of 2000 took 0.136s
  training loss:		0.333993
  validation loss:		0.326375
  validation accuracy:		90.87 %
Epoch 96 of 2000 took 0.141s
  training loss:		0.334416
  validation loss:		0.321354
  validation accuracy:		91.09 %
Epoch 97 of 2000 took 0.135s
  training loss:		0.328072
  validation loss:		0.332383
  validation accuracy:		90.65 %
Epoch 98 of 2000 took 0.132s
  training loss:		0.326456
  validation loss:		0.324368
  validation accuracy:		91.41 %
Epoch 99 of 2000 took 0.135s
  training loss:		0.319225
  validation loss:		0.317079
  validation accuracy:		90.98 %
Epoch 100 of 2000 took 0.142s
  training loss:		0.318869
  validation loss:		0.310061
  validation accuracy:		91.63 %
Epoch 101 of 2000 took 0.141s
  training loss:		0.317082
  validation loss:		0.310780
  validation accuracy:		91.20 %
Epoch 102 of 2000 took 0.138s
  training loss:		0.312925
  validation loss:		0.311408
  validation accuracy:		91.20 %
Epoch 103 of 2000 took 0.136s
  training loss:		0.310599
  validation loss:		0.306916
  validation accuracy:		91.20 %
Epoch 104 of 2000 took 0.136s
  training loss:		0.310469
  validation loss:		0.305977
  validation accuracy:		91.20 %
Epoch 105 of 2000 took 0.145s
  training loss:		0.302852
  validation loss:		0.307632
  validation accuracy:		91.30 %
Epoch 106 of 2000 took 0.169s
  training loss:		0.302319
  validation loss:		0.299695
  validation accuracy:		91.41 %
Epoch 107 of 2000 took 0.164s
  training loss:		0.304008
  validation loss:		0.308734
  validation accuracy:		91.30 %
Epoch 108 of 2000 took 0.191s
  training loss:		0.297185
  validation loss:		0.293885
  validation accuracy:		91.30 %
Epoch 109 of 2000 took 0.155s
  training loss:		0.294880
  validation loss:		0.304383
  validation accuracy:		91.20 %
Epoch 110 of 2000 took 0.182s
  training loss:		0.297436
  validation loss:		0.295325
  validation accuracy:		91.52 %
Epoch 111 of 2000 took 0.164s
  training loss:		0.288326
  validation loss:		0.292576
  validation accuracy:		91.41 %
Epoch 112 of 2000 took 0.167s
  training loss:		0.290306
  validation loss:		0.291900
  validation accuracy:		91.30 %
Epoch 113 of 2000 took 0.140s
  training loss:		0.283393
  validation loss:		0.292852
  validation accuracy:		91.30 %
Epoch 114 of 2000 took 0.142s
  training loss:		0.285609
  validation loss:		0.291243
  validation accuracy:		91.20 %
Epoch 115 of 2000 took 0.143s
  training loss:		0.280717
  validation loss:		0.292049
  validation accuracy:		91.74 %
Epoch 116 of 2000 took 0.138s
  training loss:		0.282449
  validation loss:		0.292771
  validation accuracy:		91.41 %
Epoch 117 of 2000 took 0.139s
  training loss:		0.280878
  validation loss:		0.287718
  validation accuracy:		91.52 %
Epoch 118 of 2000 took 0.143s
  training loss:		0.280660
  validation loss:		0.286669
  validation accuracy:		91.30 %
Epoch 119 of 2000 took 0.136s
  training loss:		0.278835
  validation loss:		0.276898
  validation accuracy:		91.41 %
Epoch 120 of 2000 took 0.142s
  training loss:		0.272898
  validation loss:		0.281632
  validation accuracy:		91.20 %
Epoch 121 of 2000 took 0.141s
  training loss:		0.269245
  validation loss:		0.283247
  validation accuracy:		91.20 %
Epoch 122 of 2000 took 0.149s
  training loss:		0.268897
  validation loss:		0.275232
  validation accuracy:		91.20 %
Epoch 123 of 2000 took 0.169s
  training loss:		0.270432
  validation loss:		0.286749
  validation accuracy:		90.98 %
Epoch 124 of 2000 took 0.138s
  training loss:		0.267327
  validation loss:		0.275524
  validation accuracy:		91.41 %
Epoch 125 of 2000 took 0.138s
  training loss:		0.259122
  validation loss:		0.281304
  validation accuracy:		91.41 %
Epoch 126 of 2000 took 0.142s
  training loss:		0.262064
  validation loss:		0.266767
  validation accuracy:		91.74 %
Epoch 127 of 2000 took 0.142s
  training loss:		0.262074
  validation loss:		0.272595
  validation accuracy:		91.20 %
Epoch 128 of 2000 took 0.144s
  training loss:		0.261297
  validation loss:		0.274233
  validation accuracy:		91.63 %
Epoch 129 of 2000 took 0.139s
  training loss:		0.262213
  validation loss:		0.267467
  validation accuracy:		91.41 %
Epoch 130 of 2000 took 0.145s
  training loss:		0.256718
  validation loss:		0.267229
  validation accuracy:		91.96 %
Epoch 131 of 2000 took 0.140s
  training loss:		0.252409
  validation loss:		0.262093
  validation accuracy:		91.85 %
Epoch 132 of 2000 took 0.138s
  training loss:		0.251786
  validation loss:		0.262951
  validation accuracy:		91.85 %
Epoch 133 of 2000 took 0.158s
  training loss:		0.252029
  validation loss:		0.266424
  validation accuracy:		92.07 %
Epoch 134 of 2000 took 0.176s
  training loss:		0.253407
  validation loss:		0.260868
  validation accuracy:		91.52 %
Epoch 135 of 2000 took 0.136s
  training loss:		0.247404
  validation loss:		0.259333
  validation accuracy:		91.85 %
Epoch 136 of 2000 took 0.135s
  training loss:		0.245842
  validation loss:		0.264105
  validation accuracy:		91.96 %
Epoch 137 of 2000 took 0.138s
  training loss:		0.246717
  validation loss:		0.256056
  validation accuracy:		91.74 %
Epoch 138 of 2000 took 0.135s
  training loss:		0.246796
  validation loss:		0.253690
  validation accuracy:		92.07 %
Epoch 139 of 2000 took 0.139s
  training loss:		0.244821
  validation loss:		0.270446
  validation accuracy:		91.85 %
Epoch 140 of 2000 took 0.134s
  training loss:		0.241204
  validation loss:		0.260308
  validation accuracy:		92.07 %
Epoch 141 of 2000 took 0.140s
  training loss:		0.238785
  validation loss:		0.259688
  validation accuracy:		91.52 %
Epoch 142 of 2000 took 0.136s
  training loss:		0.238600
  validation loss:		0.255169
  validation accuracy:		92.17 %
Epoch 143 of 2000 took 0.143s
  training loss:		0.236263
  validation loss:		0.255907
  validation accuracy:		91.96 %
Epoch 144 of 2000 took 0.140s
  training loss:		0.234925
  validation loss:		0.247268
  validation accuracy:		92.07 %
Epoch 145 of 2000 took 0.142s
  training loss:		0.237788
  validation loss:		0.259075
  validation accuracy:		91.85 %
Epoch 146 of 2000 took 0.138s
  training loss:		0.232310
  validation loss:		0.250095
  validation accuracy:		92.39 %
Epoch 147 of 2000 took 0.143s
  training loss:		0.232996
  validation loss:		0.254221
  validation accuracy:		91.96 %
Epoch 148 of 2000 took 0.139s
  training loss:		0.230102
  validation loss:		0.250008
  validation accuracy:		92.17 %
Epoch 149 of 2000 took 0.141s
  training loss:		0.225312
  validation loss:		0.253769
  validation accuracy:		92.07 %
Epoch 150 of 2000 took 0.150s
  training loss:		0.231191
  validation loss:		0.241712
  validation accuracy:		92.28 %
Epoch 151 of 2000 took 0.132s
  training loss:		0.228147
  validation loss:		0.248727
  validation accuracy:		92.07 %
Epoch 152 of 2000 took 0.151s
  training loss:		0.226165
  validation loss:		0.253075
  validation accuracy:		91.96 %
Epoch 153 of 2000 took 0.166s
  training loss:		0.226698
  validation loss:		0.239825
  validation accuracy:		92.28 %
Epoch 154 of 2000 took 0.198s
  training loss:		0.226382
  validation loss:		0.257096
  validation accuracy:		92.17 %
Epoch 155 of 2000 took 0.147s
  training loss:		0.228381
  validation loss:		0.243944
  validation accuracy:		92.17 %
Epoch 156 of 2000 took 0.142s
  training loss:		0.220104
  validation loss:		0.245347
  validation accuracy:		91.96 %
Epoch 157 of 2000 took 0.151s
  training loss:		0.224784
  validation loss:		0.254063
  validation accuracy:		91.85 %
Epoch 158 of 2000 took 0.169s
  training loss:		0.222493
  validation loss:		0.249428
  validation accuracy:		91.96 %
Epoch 159 of 2000 took 0.157s
  training loss:		0.217530
  validation loss:		0.239259
  validation accuracy:		92.28 %
Epoch 160 of 2000 took 0.143s
  training loss:		0.219744
  validation loss:		0.242915
  validation accuracy:		91.85 %
Epoch 161 of 2000 took 0.135s
  training loss:		0.218758
  validation loss:		0.245245
  validation accuracy:		92.17 %
Epoch 162 of 2000 took 0.139s
  training loss:		0.218362
  validation loss:		0.246122
  validation accuracy:		91.96 %
Epoch 163 of 2000 took 0.146s
  training loss:		0.211078
  validation loss:		0.242742
  validation accuracy:		92.07 %
Epoch 164 of 2000 took 0.171s
  training loss:		0.216548
  validation loss:		0.246971
  validation accuracy:		92.28 %
Epoch 165 of 2000 took 0.169s
  training loss:		0.208424
  validation loss:		0.244669
  validation accuracy:		91.96 %
Epoch 166 of 2000 took 0.155s
  training loss:		0.212117
  validation loss:		0.242451
  validation accuracy:		92.17 %
Epoch 167 of 2000 took 0.144s
  training loss:		0.215279
  validation loss:		0.236751
  validation accuracy:		92.50 %
Epoch 168 of 2000 took 0.150s
  training loss:		0.207328
  validation loss:		0.239961
  validation accuracy:		92.07 %
Epoch 169 of 2000 took 0.144s
  training loss:		0.213453
  validation loss:		0.239597
  validation accuracy:		91.96 %
Epoch 170 of 2000 took 0.154s
  training loss:		0.208474
  validation loss:		0.240301
  validation accuracy:		92.07 %
Epoch 171 of 2000 took 0.162s
  training loss:		0.209409
  validation loss:		0.244203
  validation accuracy:		92.28 %
Epoch 172 of 2000 took 0.164s
  training loss:		0.208624
  validation loss:		0.235472
  validation accuracy:		92.07 %
Epoch 173 of 2000 took 0.152s
  training loss:		0.207788
  validation loss:		0.238633
  validation accuracy:		92.28 %
Epoch 174 of 2000 took 0.179s
  training loss:		0.203041
  validation loss:		0.236294
  validation accuracy:		92.17 %
Epoch 175 of 2000 took 0.169s
  training loss:		0.202176
  validation loss:		0.243384
  validation accuracy:		92.17 %
Epoch 176 of 2000 took 0.145s
  training loss:		0.202527
  validation loss:		0.244970
  validation accuracy:		91.85 %
Epoch 177 of 2000 took 0.159s
  training loss:		0.206094
  validation loss:		0.237991
  validation accuracy:		92.28 %
Epoch 178 of 2000 took 0.138s
  training loss:		0.204074
  validation loss:		0.232370
  validation accuracy:		92.39 %
Epoch 179 of 2000 took 0.164s
  training loss:		0.204319
  validation loss:		0.234209
  validation accuracy:		91.96 %
Epoch 180 of 2000 took 0.196s
  training loss:		0.200399
  validation loss:		0.235041
  validation accuracy:		92.39 %
Epoch 181 of 2000 took 0.166s
  training loss:		0.200296
  validation loss:		0.235707
  validation accuracy:		91.96 %
Epoch 182 of 2000 took 0.130s
  training loss:		0.196837
  validation loss:		0.235556
  validation accuracy:		92.39 %
Epoch 183 of 2000 took 0.140s
  training loss:		0.196205
  validation loss:		0.235492
  validation accuracy:		92.07 %
Epoch 184 of 2000 took 0.133s
  training loss:		0.194417
  validation loss:		0.238985
  validation accuracy:		92.39 %
Epoch 185 of 2000 took 0.159s
  training loss:		0.196264
  validation loss:		0.229856
  validation accuracy:		92.83 %
Epoch 186 of 2000 took 0.169s
  training loss:		0.194558
  validation loss:		0.229077
  validation accuracy:		92.17 %
Epoch 187 of 2000 took 0.137s
  training loss:		0.194070
  validation loss:		0.234660
  validation accuracy:		92.28 %
Epoch 188 of 2000 took 0.139s
  training loss:		0.193189
  validation loss:		0.233573
  validation accuracy:		91.85 %
Epoch 189 of 2000 took 0.141s
  training loss:		0.191661
  validation loss:		0.224857
  validation accuracy:		92.61 %
Epoch 190 of 2000 took 0.143s
  training loss:		0.190350
  validation loss:		0.231143
  validation accuracy:		92.72 %
Epoch 191 of 2000 took 0.134s
  training loss:		0.187482
  validation loss:		0.244056
  validation accuracy:		91.74 %
Epoch 192 of 2000 took 0.137s
  training loss:		0.195188
  validation loss:		0.220367
  validation accuracy:		92.93 %
Epoch 193 of 2000 took 0.145s
  training loss:		0.188636
  validation loss:		0.222780
  validation accuracy:		92.72 %
Epoch 194 of 2000 took 0.156s
  training loss:		0.189209
  validation loss:		0.232773
  validation accuracy:		92.28 %
Epoch 195 of 2000 took 0.166s
  training loss:		0.187397
  validation loss:		0.226600
  validation accuracy:		92.61 %
Epoch 196 of 2000 took 0.155s
  training loss:		0.187851
  validation loss:		0.232222
  validation accuracy:		92.17 %
Epoch 197 of 2000 took 0.147s
  training loss:		0.185837
  validation loss:		0.225097
  validation accuracy:		92.50 %
Epoch 198 of 2000 took 0.144s
  training loss:		0.186887
  validation loss:		0.224954
  validation accuracy:		92.50 %
Epoch 199 of 2000 took 0.140s
  training loss:		0.184545
  validation loss:		0.219699
  validation accuracy:		93.04 %
Epoch 200 of 2000 took 0.184s
  training loss:		0.183147
  validation loss:		0.226350
  validation accuracy:		92.83 %
Epoch 201 of 2000 took 0.162s
  training loss:		0.180682
  validation loss:		0.217151
  validation accuracy:		92.93 %
Epoch 202 of 2000 took 0.181s
  training loss:		0.184878
  validation loss:		0.227693
  validation accuracy:		92.17 %
Epoch 203 of 2000 took 0.154s
  training loss:		0.183432
  validation loss:		0.227943
  validation accuracy:		92.17 %
Epoch 204 of 2000 took 0.149s
  training loss:		0.178706
  validation loss:		0.223847
  validation accuracy:		92.61 %
Epoch 205 of 2000 took 0.145s
  training loss:		0.181853
  validation loss:		0.225306
  validation accuracy:		92.83 %
Epoch 206 of 2000 took 0.154s
  training loss:		0.178335
  validation loss:		0.216462
  validation accuracy:		93.04 %
Epoch 207 of 2000 took 0.155s
  training loss:		0.182500
  validation loss:		0.221767
  validation accuracy:		92.61 %
Epoch 208 of 2000 took 0.148s
  training loss:		0.177859
  validation loss:		0.233593
  validation accuracy:		92.28 %
Epoch 209 of 2000 took 0.143s
  training loss:		0.178998
  validation loss:		0.222839
  validation accuracy:		93.15 %
Epoch 210 of 2000 took 0.153s
  training loss:		0.181554
  validation loss:		0.217538
  validation accuracy:		92.83 %
Epoch 211 of 2000 took 0.140s
  training loss:		0.177968
  validation loss:		0.220061
  validation accuracy:		92.83 %
Epoch 212 of 2000 took 0.149s
  training loss:		0.177415
  validation loss:		0.222107
  validation accuracy:		92.83 %
Epoch 213 of 2000 took 0.149s
  training loss:		0.174660
  validation loss:		0.227805
  validation accuracy:		92.83 %
Epoch 214 of 2000 took 0.144s
  training loss:		0.172333
  validation loss:		0.226323
  validation accuracy:		92.50 %
Epoch 215 of 2000 took 0.150s
  training loss:		0.174987
  validation loss:		0.223097
  validation accuracy:		92.50 %
Epoch 216 of 2000 took 0.141s
  training loss:		0.171578
  validation loss:		0.220400
  validation accuracy:		92.50 %
Epoch 217 of 2000 took 0.151s
  training loss:		0.172982
  validation loss:		0.223640
  validation accuracy:		92.39 %
Epoch 218 of 2000 took 0.147s
  training loss:		0.174009
  validation loss:		0.223921
  validation accuracy:		92.72 %
Epoch 219 of 2000 took 0.156s
  training loss:		0.172352
  validation loss:		0.221972
  validation accuracy:		92.61 %
Epoch 220 of 2000 took 0.152s
  training loss:		0.167823
  validation loss:		0.214225
  validation accuracy:		92.93 %
Epoch 221 of 2000 took 0.151s
  training loss:		0.168820
  validation loss:		0.220651
  validation accuracy:		92.72 %
Epoch 222 of 2000 took 0.149s
  training loss:		0.169235
  validation loss:		0.222893
  validation accuracy:		93.15 %
Epoch 223 of 2000 took 0.157s
  training loss:		0.167162
  validation loss:		0.224769
  validation accuracy:		92.72 %
Epoch 224 of 2000 took 0.152s
  training loss:		0.168200
  validation loss:		0.226933
  validation accuracy:		92.39 %
Epoch 225 of 2000 took 0.149s
  training loss:		0.171578
  validation loss:		0.213418
  validation accuracy:		93.04 %
Epoch 226 of 2000 took 0.149s
  training loss:		0.168896
  validation loss:		0.220270
  validation accuracy:		92.83 %
Epoch 227 of 2000 took 0.148s
  training loss:		0.165536
  validation loss:		0.215302
  validation accuracy:		93.04 %
Epoch 228 of 2000 took 0.147s
  training loss:		0.163672
  validation loss:		0.224985
  validation accuracy:		92.39 %
Epoch 229 of 2000 took 0.148s
  training loss:		0.164780
  validation loss:		0.222542
  validation accuracy:		92.28 %
Epoch 230 of 2000 took 0.146s
  training loss:		0.163507
  validation loss:		0.216428
  validation accuracy:		92.83 %
Epoch 231 of 2000 took 0.146s
  training loss:		0.162056
  validation loss:		0.224383
  validation accuracy:		92.50 %
Epoch 232 of 2000 took 0.142s
  training loss:		0.158118
  validation loss:		0.222210
  validation accuracy:		92.83 %
Epoch 233 of 2000 took 0.144s
  training loss:		0.163438
  validation loss:		0.216341
  validation accuracy:		92.93 %
Epoch 234 of 2000 took 0.144s
  training loss:		0.162045
  validation loss:		0.220444
  validation accuracy:		93.04 %
Epoch 235 of 2000 took 0.148s
  training loss:		0.160220
  validation loss:		0.218193
  validation accuracy:		93.37 %
Epoch 236 of 2000 took 0.148s
  training loss:		0.159801
  validation loss:		0.214424
  validation accuracy:		93.15 %
Epoch 237 of 2000 took 0.143s
  training loss:		0.157066
  validation loss:		0.211127
  validation accuracy:		92.93 %
Epoch 238 of 2000 took 0.146s
  training loss:		0.156526
  validation loss:		0.224266
  validation accuracy:		92.72 %
Epoch 239 of 2000 took 0.153s
  training loss:		0.164211
  validation loss:		0.215869
  validation accuracy:		93.04 %
Epoch 240 of 2000 took 0.149s
  training loss:		0.159357
  validation loss:		0.212404
  validation accuracy:		92.93 %
Epoch 241 of 2000 took 0.144s
  training loss:		0.158657
  validation loss:		0.225445
  validation accuracy:		92.50 %
Epoch 242 of 2000 took 0.154s
  training loss:		0.159703
  validation loss:		0.217175
  validation accuracy:		93.15 %
Epoch 243 of 2000 took 0.146s
  training loss:		0.159018
  validation loss:		0.220739
  validation accuracy:		92.61 %
Epoch 244 of 2000 took 0.148s
  training loss:		0.157756
  validation loss:		0.214466
  validation accuracy:		93.15 %
Epoch 245 of 2000 took 0.146s
  training loss:		0.153429
  validation loss:		0.216530
  validation accuracy:		92.72 %
Epoch 246 of 2000 took 0.145s
  training loss:		0.155470
  validation loss:		0.216951
  validation accuracy:		93.04 %
Epoch 247 of 2000 took 0.176s
  training loss:		0.153897
  validation loss:		0.214253
  validation accuracy:		93.04 %
Epoch 248 of 2000 took 0.145s
  training loss:		0.154717
  validation loss:		0.213730
  validation accuracy:		93.26 %
Epoch 249 of 2000 took 0.153s
  training loss:		0.152286
  validation loss:		0.208416
  validation accuracy:		93.26 %
Epoch 250 of 2000 took 0.148s
  training loss:		0.154548
  validation loss:		0.218230
  validation accuracy:		92.83 %
Epoch 251 of 2000 took 0.139s
  training loss:		0.148938
  validation loss:		0.217729
  validation accuracy:		92.83 %
Epoch 252 of 2000 took 0.145s
  training loss:		0.146885
  validation loss:		0.211627
  validation accuracy:		93.04 %
Epoch 253 of 2000 took 0.149s
  training loss:		0.151084
  validation loss:		0.210419
  validation accuracy:		93.04 %
Epoch 254 of 2000 took 0.153s
  training loss:		0.147840
  validation loss:		0.223477
  validation accuracy:		92.83 %
Epoch 255 of 2000 took 0.154s
  training loss:		0.151509
  validation loss:		0.208741
  validation accuracy:		93.15 %
Epoch 256 of 2000 took 0.159s
  training loss:		0.150755
  validation loss:		0.213881
  validation accuracy:		93.26 %
Epoch 257 of 2000 took 0.138s
  training loss:		0.149257
  validation loss:		0.212648
  validation accuracy:		93.59 %
Epoch 258 of 2000 took 0.149s
  training loss:		0.152731
  validation loss:		0.214344
  validation accuracy:		92.93 %
Epoch 259 of 2000 took 0.149s
  training loss:		0.147231
  validation loss:		0.212492
  validation accuracy:		93.15 %
Epoch 260 of 2000 took 0.150s
  training loss:		0.149603
  validation loss:		0.211228
  validation accuracy:		93.26 %
Epoch 261 of 2000 took 0.150s
  training loss:		0.145563
  validation loss:		0.215990
  validation accuracy:		93.15 %
Epoch 262 of 2000 took 0.156s
  training loss:		0.147173
  validation loss:		0.214066
  validation accuracy:		92.83 %
Epoch 263 of 2000 took 0.145s
  training loss:		0.146360
  validation loss:		0.213945
  validation accuracy:		93.15 %
Epoch 264 of 2000 took 0.149s
  training loss:		0.143390
  validation loss:		0.209024
  validation accuracy:		93.26 %
Epoch 265 of 2000 took 0.144s
  training loss:		0.145944
  validation loss:		0.231704
  validation accuracy:		91.96 %
Epoch 266 of 2000 took 0.145s
  training loss:		0.143677
  validation loss:		0.208948
  validation accuracy:		93.04 %
Epoch 267 of 2000 took 0.140s
  training loss:		0.141970
  validation loss:		0.208667
  validation accuracy:		93.15 %
Epoch 268 of 2000 took 0.167s
  training loss:		0.142712
  validation loss:		0.209315
  validation accuracy:		93.26 %
Epoch 269 of 2000 took 0.146s
  training loss:		0.140702
  validation loss:		0.206876
  validation accuracy:		93.26 %
Epoch 270 of 2000 took 0.139s
  training loss:		0.141838
  validation loss:		0.211920
  validation accuracy:		93.15 %
Epoch 271 of 2000 took 0.150s
  training loss:		0.143291
  validation loss:		0.218726
  validation accuracy:		92.72 %
Epoch 272 of 2000 took 0.154s
  training loss:		0.141842
  validation loss:		0.222586
  validation accuracy:		92.61 %
Epoch 273 of 2000 took 0.148s
  training loss:		0.139302
  validation loss:		0.221993
  validation accuracy:		92.61 %
Epoch 274 of 2000 took 0.145s
  training loss:		0.141119
  validation loss:		0.205740
  validation accuracy:		93.48 %
Epoch 275 of 2000 took 0.146s
  training loss:		0.141029
  validation loss:		0.205468
  validation accuracy:		93.59 %
Epoch 276 of 2000 took 0.150s
  training loss:		0.140704
  validation loss:		0.214688
  validation accuracy:		93.04 %
Epoch 277 of 2000 took 0.153s
  training loss:		0.139901
  validation loss:		0.210932
  validation accuracy:		93.37 %
Epoch 278 of 2000 took 0.143s
  training loss:		0.137648
  validation loss:		0.221640
  validation accuracy:		92.93 %
Epoch 279 of 2000 took 0.144s
  training loss:		0.138469
  validation loss:		0.210029
  validation accuracy:		93.15 %
Epoch 280 of 2000 took 0.149s
  training loss:		0.138846
  validation loss:		0.209617
  validation accuracy:		93.15 %
Epoch 281 of 2000 took 0.144s
  training loss:		0.135532
  validation loss:		0.208580
  validation accuracy:		93.15 %
Epoch 282 of 2000 took 0.149s
  training loss:		0.138919
  validation loss:		0.213241
  validation accuracy:		93.26 %
Epoch 283 of 2000 took 0.144s
  training loss:		0.135988
  validation loss:		0.211152
  validation accuracy:		93.04 %
Epoch 284 of 2000 took 0.143s
  training loss:		0.136807
  validation loss:		0.217651
  validation accuracy:		92.83 %
Epoch 285 of 2000 took 0.180s
  training loss:		0.136749
  validation loss:		0.206068
  validation accuracy:		93.26 %
Epoch 286 of 2000 took 0.151s
  training loss:		0.135268
  validation loss:		0.214835
  validation accuracy:		93.04 %
Epoch 287 of 2000 took 0.156s
  training loss:		0.137374
  validation loss:		0.212298
  validation accuracy:		93.15 %
Epoch 288 of 2000 took 0.142s
  training loss:		0.134353
  validation loss:		0.215696
  validation accuracy:		92.93 %
Epoch 289 of 2000 took 0.149s
  training loss:		0.135161
  validation loss:		0.212954
  validation accuracy:		93.04 %
Epoch 290 of 2000 took 0.147s
  training loss:		0.134865
  validation loss:		0.217930
  validation accuracy:		93.26 %
Epoch 291 of 2000 took 0.145s
  training loss:		0.134049
  validation loss:		0.211827
  validation accuracy:		92.93 %
Epoch 292 of 2000 took 0.147s
  training loss:		0.133445
  validation loss:		0.211985
  validation accuracy:		93.26 %
Epoch 293 of 2000 took 0.150s
  training loss:		0.131950
  validation loss:		0.212009
  validation accuracy:		93.37 %
Epoch 294 of 2000 took 0.154s
  training loss:		0.130938
  validation loss:		0.212405
  validation accuracy:		93.48 %
Epoch 295 of 2000 took 0.148s
  training loss:		0.134066
  validation loss:		0.209281
  validation accuracy:		93.15 %
Epoch 296 of 2000 took 0.152s
  training loss:		0.132023
  validation loss:		0.209996
  validation accuracy:		93.37 %
Epoch 297 of 2000 took 0.148s
  training loss:		0.129160
  validation loss:		0.222065
  validation accuracy:		92.61 %
Epoch 298 of 2000 took 0.145s
  training loss:		0.128852
  validation loss:		0.219089
  validation accuracy:		92.93 %
Epoch 299 of 2000 took 0.148s
  training loss:		0.130830
  validation loss:		0.214666
  validation accuracy:		93.37 %
Epoch 300 of 2000 took 0.146s
  training loss:		0.128043
  validation loss:		0.214246
  validation accuracy:		93.15 %
Epoch 301 of 2000 took 0.146s
  training loss:		0.131194
  validation loss:		0.209367
  validation accuracy:		93.48 %
Epoch 302 of 2000 took 0.148s
  training loss:		0.131269
  validation loss:		0.223600
  validation accuracy:		92.83 %
Epoch 303 of 2000 took 0.146s
  training loss:		0.130580
  validation loss:		0.217303
  validation accuracy:		93.15 %
Epoch 304 of 2000 took 0.137s
  training loss:		0.126422
  validation loss:		0.203683
  validation accuracy:		94.02 %
Epoch 305 of 2000 took 0.148s
  training loss:		0.126012
  validation loss:		0.211875
  validation accuracy:		93.15 %
Epoch 306 of 2000 took 0.146s
  training loss:		0.130105
  validation loss:		0.211912
  validation accuracy:		93.26 %
Epoch 307 of 2000 took 0.144s
  training loss:		0.123500
  validation loss:		0.209826
  validation accuracy:		93.26 %
Epoch 308 of 2000 took 0.148s
  training loss:		0.127232
  validation loss:		0.204603
  validation accuracy:		93.37 %
Epoch 309 of 2000 took 0.146s
  training loss:		0.123802
  validation loss:		0.214744
  validation accuracy:		93.04 %
Epoch 310 of 2000 took 0.148s
  training loss:		0.129301
  validation loss:		0.213664
  validation accuracy:		93.15 %
Epoch 311 of 2000 took 0.157s
  training loss:		0.125788
  validation loss:		0.216705
  validation accuracy:		93.04 %
Epoch 312 of 2000 took 0.144s
  training loss:		0.125137
  validation loss:		0.205916
  validation accuracy:		93.48 %
Epoch 313 of 2000 took 0.166s
  training loss:		0.126415
  validation loss:		0.209887
  validation accuracy:		93.15 %
Epoch 314 of 2000 took 0.176s
  training loss:		0.124220
  validation loss:		0.209277
  validation accuracy:		93.04 %
Epoch 315 of 2000 took 0.148s
  training loss:		0.125109
  validation loss:		0.216409
  validation accuracy:		92.93 %
Epoch 316 of 2000 took 0.154s
  training loss:		0.121639
  validation loss:		0.206638
  validation accuracy:		93.48 %
Epoch 317 of 2000 took 0.166s
  training loss:		0.124231
  validation loss:		0.214693
  validation accuracy:		93.15 %
Epoch 318 of 2000 took 0.153s
  training loss:		0.122816
  validation loss:		0.211789
  validation accuracy:		93.15 %
Epoch 319 of 2000 took 0.151s
  training loss:		0.120670
  validation loss:		0.203558
  validation accuracy:		93.48 %
Epoch 320 of 2000 took 0.155s
  training loss:		0.119653
  validation loss:		0.211159
  validation accuracy:		93.26 %
Epoch 321 of 2000 took 0.154s
  training loss:		0.122415
  validation loss:		0.209219
  validation accuracy:		93.15 %
Epoch 322 of 2000 took 0.149s
  training loss:		0.118617
  validation loss:		0.207343
  validation accuracy:		93.59 %
Epoch 323 of 2000 took 0.139s
  training loss:		0.122206
  validation loss:		0.205864
  validation accuracy:		93.37 %
Epoch 324 of 2000 took 0.168s
  training loss:		0.119203
  validation loss:		0.205915
  validation accuracy:		93.37 %
Epoch 325 of 2000 took 0.145s
  training loss:		0.122093
  validation loss:		0.211214
  validation accuracy:		93.26 %
Epoch 326 of 2000 took 0.167s
  training loss:		0.117368
  validation loss:		0.213275
  validation accuracy:		93.37 %
Epoch 327 of 2000 took 0.162s
  training loss:		0.119909
  validation loss:		0.209309
  validation accuracy:		93.37 %
Epoch 328 of 2000 took 0.154s
  training loss:		0.120421
  validation loss:		0.211885
  validation accuracy:		93.26 %
Epoch 329 of 2000 took 0.156s
  training loss:		0.118894
  validation loss:		0.211215
  validation accuracy:		93.37 %
Epoch 330 of 2000 took 0.158s
  training loss:		0.118525
  validation loss:		0.207721
  validation accuracy:		93.37 %
Epoch 331 of 2000 took 0.159s
  training loss:		0.120132
  validation loss:		0.209455
  validation accuracy:		93.26 %
Epoch 332 of 2000 took 0.153s
  training loss:		0.115576
  validation loss:		0.209452
  validation accuracy:		93.37 %
Epoch 333 of 2000 took 0.148s
  training loss:		0.116211
  validation loss:		0.211038
  validation accuracy:		93.26 %
Epoch 334 of 2000 took 0.157s
  training loss:		0.117893
  validation loss:		0.220316
  validation accuracy:		93.04 %
Epoch 335 of 2000 took 0.163s
  training loss:		0.116706
  validation loss:		0.214287
  validation accuracy:		93.59 %
Epoch 336 of 2000 took 0.157s
  training loss:		0.118215
  validation loss:		0.218262
  validation accuracy:		93.37 %
Epoch 337 of 2000 took 0.146s
  training loss:		0.117868
  validation loss:		0.212526
  validation accuracy:		93.37 %
Epoch 338 of 2000 took 0.151s
  training loss:		0.116739
  validation loss:		0.204231
  validation accuracy:		93.37 %
Epoch 339 of 2000 took 0.142s
  training loss:		0.116964
  validation loss:		0.206882
  validation accuracy:		93.48 %
Epoch 340 of 2000 took 0.147s
  training loss:		0.113336
  validation loss:		0.208961
  validation accuracy:		93.37 %
Epoch 341 of 2000 took 0.146s
  training loss:		0.113323
  validation loss:		0.212672
  validation accuracy:		93.15 %
Epoch 342 of 2000 took 0.190s
  training loss:		0.112843
  validation loss:		0.213014
  validation accuracy:		93.15 %
Epoch 343 of 2000 took 0.139s
  training loss:		0.113154
  validation loss:		0.214353
  validation accuracy:		93.37 %
Epoch 344 of 2000 took 0.187s
  training loss:		0.116466
  validation loss:		0.208996
  validation accuracy:		93.37 %
Epoch 345 of 2000 took 0.151s
  training loss:		0.113823
  validation loss:		0.211561
  validation accuracy:		93.26 %
Epoch 346 of 2000 took 0.145s
  training loss:		0.110490
  validation loss:		0.214129
  validation accuracy:		93.04 %
Epoch 347 of 2000 took 0.146s
  training loss:		0.114490
  validation loss:		0.214949
  validation accuracy:		93.04 %
Epoch 348 of 2000 took 0.148s
  training loss:		0.113388
  validation loss:		0.218522
  validation accuracy:		93.04 %
Epoch 349 of 2000 took 0.141s
  training loss:		0.114173
  validation loss:		0.214430
  validation accuracy:		93.37 %
Epoch 350 of 2000 took 0.167s
  training loss:		0.114406
  validation loss:		0.211400
  validation accuracy:		92.93 %
Epoch 351 of 2000 took 0.193s
  training loss:		0.110751
  validation loss:		0.218110
  validation accuracy:		93.04 %
Epoch 352 of 2000 took 0.158s
  training loss:		0.113737
  validation loss:		0.216618
  validation accuracy:		93.04 %
Epoch 353 of 2000 took 0.138s
  training loss:		0.112272
  validation loss:		0.209070
  validation accuracy:		93.37 %
Epoch 354 of 2000 took 0.139s
  training loss:		0.109574
  validation loss:		0.211940
  validation accuracy:		93.15 %
Epoch 355 of 2000 took 0.146s
  training loss:		0.110524
  validation loss:		0.217522
  validation accuracy:		92.93 %
Epoch 356 of 2000 took 0.166s
  training loss:		0.110111
  validation loss:		0.221432
  validation accuracy:		92.93 %
Epoch 357 of 2000 took 0.196s
  training loss:		0.109477
  validation loss:		0.217939
  validation accuracy:		93.04 %
Epoch 358 of 2000 took 0.144s
  training loss:		0.111822
  validation loss:		0.214031
  validation accuracy:		92.93 %
Epoch 359 of 2000 took 0.176s
  training loss:		0.110839
  validation loss:		0.208424
  validation accuracy:		93.37 %
Epoch 360 of 2000 took 0.136s
  training loss:		0.107927
  validation loss:		0.209925
  validation accuracy:		93.26 %
Epoch 361 of 2000 took 0.146s
  training loss:		0.108162
  validation loss:		0.210963
  validation accuracy:		92.83 %
Epoch 362 of 2000 took 0.153s
  training loss:		0.110055
  validation loss:		0.207932
  validation accuracy:		93.59 %
Epoch 363 of 2000 took 0.141s
  training loss:		0.108277
  validation loss:		0.213215
  validation accuracy:		93.26 %
Epoch 364 of 2000 took 0.142s
  training loss:		0.105810
  validation loss:		0.213953
  validation accuracy:		93.37 %
Epoch 365 of 2000 took 0.173s
  training loss:		0.109176
  validation loss:		0.217361
  validation accuracy:		93.26 %
Epoch 366 of 2000 took 0.180s
  training loss:		0.107274
  validation loss:		0.222379
  validation accuracy:		92.83 %
Epoch 367 of 2000 took 0.148s
  training loss:		0.109794
  validation loss:		0.217113
  validation accuracy:		93.04 %
Epoch 368 of 2000 took 0.139s
  training loss:		0.107131
  validation loss:		0.218196
  validation accuracy:		92.61 %
Epoch 369 of 2000 took 0.135s
  training loss:		0.107283
  validation loss:		0.228499
  validation accuracy:		92.39 %
Epoch 370 of 2000 took 0.145s
  training loss:		0.107825
  validation loss:		0.214488
  validation accuracy:		93.37 %
Epoch 371 of 2000 took 0.141s
  training loss:		0.104499
  validation loss:		0.214628
  validation accuracy:		92.93 %
Epoch 372 of 2000 took 0.140s
  training loss:		0.105563
  validation loss:		0.213092
  validation accuracy:		93.26 %
Epoch 373 of 2000 took 0.142s
  training loss:		0.105925
  validation loss:		0.207049
  validation accuracy:		93.37 %
Epoch 374 of 2000 took 0.142s
  training loss:		0.105088
  validation loss:		0.210304
  validation accuracy:		93.37 %
Epoch 375 of 2000 took 0.143s
  training loss:		0.104751
  validation loss:		0.216335
  validation accuracy:		93.04 %
Epoch 376 of 2000 took 0.177s
  training loss:		0.105412
  validation loss:		0.228769
  validation accuracy:		92.72 %
Epoch 377 of 2000 took 0.176s
  training loss:		0.108650
  validation loss:		0.217135
  validation accuracy:		92.83 %
Epoch 378 of 2000 took 0.150s
  training loss:		0.106350
  validation loss:		0.229914
  validation accuracy:		92.72 %
Epoch 379 of 2000 took 0.154s
  training loss:		0.104607
  validation loss:		0.212241
  validation accuracy:		93.70 %
Epoch 380 of 2000 took 0.154s
  training loss:		0.103552
  validation loss:		0.216008
  validation accuracy:		92.93 %
Epoch 381 of 2000 took 0.152s
  training loss:		0.103804
  validation loss:		0.218768
  validation accuracy:		92.93 %
Epoch 382 of 2000 took 0.161s
  training loss:		0.105036
  validation loss:		0.215861
  validation accuracy:		92.83 %
Epoch 383 of 2000 took 0.157s
  training loss:		0.103790
  validation loss:		0.222845
  validation accuracy:		93.04 %
Epoch 384 of 2000 took 0.143s
  training loss:		0.100096
  validation loss:		0.220443
  validation accuracy:		93.15 %
Epoch 385 of 2000 took 0.147s
  training loss:		0.099627
  validation loss:		0.209626
  validation accuracy:		93.37 %
Epoch 386 of 2000 took 0.176s
  training loss:		0.099301
  validation loss:		0.218690
  validation accuracy:		93.26 %
Epoch 387 of 2000 took 0.166s
  training loss:		0.102790
  validation loss:		0.213564
  validation accuracy:		93.37 %
Epoch 388 of 2000 took 0.147s
  training loss:		0.099800
  validation loss:		0.225369
  validation accuracy:		92.83 %
Epoch 389 of 2000 took 0.151s
  training loss:		0.098415
  validation loss:		0.214255
  validation accuracy:		93.15 %
Epoch 390 of 2000 took 0.147s
  training loss:		0.099701
  validation loss:		0.220319
  validation accuracy:		92.93 %
Epoch 391 of 2000 took 0.149s
  training loss:		0.098337
  validation loss:		0.216890
  validation accuracy:		92.93 %
Epoch 392 of 2000 took 0.146s
  training loss:		0.099947
  validation loss:		0.220996
  validation accuracy:		93.15 %
Epoch 393 of 2000 took 0.148s
  training loss:		0.098506
  validation loss:		0.210366
  validation accuracy:		93.04 %
Epoch 394 of 2000 took 0.142s
  training loss:		0.100235
  validation loss:		0.215331
  validation accuracy:		93.59 %
Epoch 395 of 2000 took 0.148s
  training loss:		0.098666
  validation loss:		0.212583
  validation accuracy:		93.59 %
Epoch 396 of 2000 took 0.140s
  training loss:		0.099084
  validation loss:		0.212183
  validation accuracy:		93.59 %
Epoch 397 of 2000 took 0.139s
  training loss:		0.100840
  validation loss:		0.210786
  validation accuracy:		93.26 %
Epoch 398 of 2000 took 0.135s
  training loss:		0.100030
  validation loss:		0.213920
  validation accuracy:		93.04 %
Epoch 399 of 2000 took 0.169s
  training loss:		0.097156
  validation loss:		0.211218
  validation accuracy:		93.26 %
Epoch 400 of 2000 took 0.146s
  training loss:		0.100683
  validation loss:		0.222008
  validation accuracy:		93.04 %
Epoch 401 of 2000 took 0.150s
  training loss:		0.096608
  validation loss:		0.214252
  validation accuracy:		93.37 %
Epoch 402 of 2000 took 0.156s
  training loss:		0.096853
  validation loss:		0.219120
  validation accuracy:		93.26 %
Epoch 403 of 2000 took 0.141s
  training loss:		0.095801
  validation loss:		0.213128
  validation accuracy:		93.26 %
Epoch 404 of 2000 took 0.146s
  training loss:		0.096689
  validation loss:		0.219616
  validation accuracy:		93.15 %
Epoch 405 of 2000 took 0.148s
  training loss:		0.095945
  validation loss:		0.213309
  validation accuracy:		93.48 %
Epoch 406 of 2000 took 0.137s
  training loss:		0.097404
  validation loss:		0.218384
  validation accuracy:		93.15 %
Epoch 407 of 2000 took 0.145s
  training loss:		0.097174
  validation loss:		0.216706
  validation accuracy:		92.83 %
Epoch 408 of 2000 took 0.144s
  training loss:		0.097656
  validation loss:		0.222605
  validation accuracy:		92.93 %
Epoch 409 of 2000 took 0.142s
  training loss:		0.094671
  validation loss:		0.215911
  validation accuracy:		93.15 %
Epoch 410 of 2000 took 0.139s
  training loss:		0.094251
  validation loss:		0.222050
  validation accuracy:		93.04 %
Epoch 411 of 2000 took 0.145s
  training loss:		0.094964
  validation loss:		0.219959
  validation accuracy:		93.04 %
Epoch 412 of 2000 took 0.142s
  training loss:		0.095224
  validation loss:		0.220046
  validation accuracy:		93.04 %
Epoch 413 of 2000 took 0.149s
  training loss:		0.096969
  validation loss:		0.220522
  validation accuracy:		93.15 %
Epoch 414 of 2000 took 0.143s
  training loss:		0.094902
  validation loss:		0.222971
  validation accuracy:		93.15 %
Epoch 415 of 2000 took 0.145s
  training loss:		0.092581
  validation loss:		0.220819
  validation accuracy:		92.83 %
Epoch 416 of 2000 took 0.144s
  training loss:		0.095955
  validation loss:		0.221809
  validation accuracy:		92.93 %
Epoch 417 of 2000 took 0.143s
  training loss:		0.092951
  validation loss:		0.214883
  validation accuracy:		93.04 %
Epoch 418 of 2000 took 0.148s
  training loss:		0.094855
  validation loss:		0.211623
  validation accuracy:		93.26 %
Epoch 419 of 2000 took 0.179s
  training loss:		0.093248
  validation loss:		0.218072
  validation accuracy:		93.04 %
Epoch 420 of 2000 took 0.180s
  training loss:		0.094355
  validation loss:		0.216482
  validation accuracy:		93.04 %
Epoch 421 of 2000 took 0.182s
  training loss:		0.094349
  validation loss:		0.217922
  validation accuracy:		93.04 %
Epoch 422 of 2000 took 0.168s
  training loss:		0.090375
  validation loss:		0.214731
  validation accuracy:		93.04 %
Epoch 423 of 2000 took 0.173s
  training loss:		0.092410
  validation loss:		0.222277
  validation accuracy:		92.61 %
Epoch 424 of 2000 took 0.182s
  training loss:		0.092662
  validation loss:		0.222454
  validation accuracy:		93.04 %
Epoch 425 of 2000 took 0.148s
  training loss:		0.088204
  validation loss:		0.218079
  validation accuracy:		93.04 %
Epoch 426 of 2000 took 0.166s
  training loss:		0.093364
  validation loss:		0.220528
  validation accuracy:		92.72 %
Epoch 427 of 2000 took 0.177s
  training loss:		0.091260
  validation loss:		0.215433
  validation accuracy:		93.04 %
Epoch 428 of 2000 took 0.163s
  training loss:		0.093523
  validation loss:		0.213190
  validation accuracy:		93.70 %
Epoch 429 of 2000 took 0.137s
  training loss:		0.091418
  validation loss:		0.217170
  validation accuracy:		93.26 %
Epoch 430 of 2000 took 0.150s
  training loss:		0.090449
  validation loss:		0.231523
  validation accuracy:		92.93 %
Epoch 431 of 2000 took 0.166s
  training loss:		0.091683
  validation loss:		0.226263
  validation accuracy:		93.04 %
Epoch 432 of 2000 took 0.178s
  training loss:		0.090754
  validation loss:		0.218069
  validation accuracy:		93.37 %
Epoch 433 of 2000 took 0.176s
  training loss:		0.090374
  validation loss:		0.213551
  validation accuracy:		93.26 %
Epoch 434 of 2000 took 0.192s
  training loss:		0.088192
  validation loss:		0.231891
  validation accuracy:		92.39 %
Epoch 435 of 2000 took 0.161s
  training loss:		0.086953
  validation loss:		0.229787
  validation accuracy:		93.04 %
Epoch 436 of 2000 took 0.140s
  training loss:		0.086255
  validation loss:		0.214577
  validation accuracy:		93.80 %
Epoch 437 of 2000 took 0.152s
  training loss:		0.088683
  validation loss:		0.221743
  validation accuracy:		92.83 %
Epoch 438 of 2000 took 0.144s
  training loss:		0.087800
  validation loss:		0.217808
  validation accuracy:		93.15 %
Epoch 439 of 2000 took 0.151s
  training loss:		0.088573
  validation loss:		0.222118
  validation accuracy:		93.04 %
Epoch 440 of 2000 took 0.171s
  training loss:		0.087384
  validation loss:		0.223244
  validation accuracy:		93.04 %
Epoch 441 of 2000 took 0.146s
  training loss:		0.087779
  validation loss:		0.224262
  validation accuracy:		92.93 %
Epoch 442 of 2000 took 0.137s
  training loss:		0.088150
  validation loss:		0.224322
  validation accuracy:		93.04 %
Epoch 443 of 2000 took 0.148s
  training loss:		0.088139
  validation loss:		0.218272
  validation accuracy:		93.04 %
Epoch 444 of 2000 took 0.144s
  training loss:		0.087995
  validation loss:		0.211235
  validation accuracy:		93.26 %
Epoch 445 of 2000 took 0.150s
  training loss:		0.089506
  validation loss:		0.215430
  validation accuracy:		93.15 %
Epoch 446 of 2000 took 0.139s
  training loss:		0.087935
  validation loss:		0.231071
  validation accuracy:		92.61 %
Epoch 447 of 2000 took 0.139s
  training loss:		0.086488
  validation loss:		0.226157
  validation accuracy:		92.83 %
Epoch 448 of 2000 took 0.154s
  training loss:		0.085074
  validation loss:		0.221135
  validation accuracy:		93.26 %
Epoch 449 of 2000 took 0.150s
  training loss:		0.085878
  validation loss:		0.222174
  validation accuracy:		93.04 %
Epoch 450 of 2000 took 0.158s
  training loss:		0.086839
  validation loss:		0.212845
  validation accuracy:		93.37 %
Epoch 451 of 2000 took 0.160s
  training loss:		0.086408
  validation loss:		0.220224
  validation accuracy:		93.04 %
Epoch 452 of 2000 took 0.179s
  training loss:		0.085159
  validation loss:		0.218785
  validation accuracy:		93.37 %
Epoch 453 of 2000 took 0.156s
  training loss:		0.083879
  validation loss:		0.225003
  validation accuracy:		92.93 %
Epoch 454 of 2000 took 0.167s
  training loss:		0.086318
  validation loss:		0.225526
  validation accuracy:		93.15 %
Epoch 455 of 2000 took 0.154s
  training loss:		0.084003
  validation loss:		0.221885
  validation accuracy:		93.15 %
Epoch 456 of 2000 took 0.139s
  training loss:		0.084718
  validation loss:		0.235368
  validation accuracy:		92.39 %
Epoch 457 of 2000 took 0.154s
  training loss:		0.083953
  validation loss:		0.216853
  validation accuracy:		93.37 %
Epoch 458 of 2000 took 0.140s
  training loss:		0.085371
  validation loss:		0.226723
  validation accuracy:		93.15 %
Epoch 459 of 2000 took 0.144s
  training loss:		0.082679
  validation loss:		0.232102
  validation accuracy:		92.72 %
Epoch 460 of 2000 took 0.161s
  training loss:		0.082154
  validation loss:		0.220167
  validation accuracy:		93.15 %
Epoch 461 of 2000 took 0.151s
  training loss:		0.083445
  validation loss:		0.220384
  validation accuracy:		92.93 %
Epoch 462 of 2000 took 0.145s
  training loss:		0.083964
  validation loss:		0.225692
  validation accuracy:		93.26 %
Epoch 463 of 2000 took 0.159s
  training loss:		0.085328
  validation loss:		0.221531
  validation accuracy:		92.93 %
Epoch 464 of 2000 took 0.144s
  training loss:		0.080850
  validation loss:		0.229377
  validation accuracy:		93.15 %
Epoch 465 of 2000 took 0.181s
  training loss:		0.082215
  validation loss:		0.219281
  validation accuracy:		93.15 %
Epoch 466 of 2000 took 0.166s
  training loss:		0.082239
  validation loss:		0.222248
  validation accuracy:		92.93 %
Epoch 467 of 2000 took 0.182s
  training loss:		0.083007
  validation loss:		0.216491
  validation accuracy:		93.48 %
Epoch 468 of 2000 took 0.146s
  training loss:		0.084062
  validation loss:		0.219160
  validation accuracy:		93.04 %
Epoch 469 of 2000 took 0.144s
  training loss:		0.082471
  validation loss:		0.240613
  validation accuracy:		92.83 %
Epoch 470 of 2000 took 0.145s
  training loss:		0.082256
  validation loss:		0.223827
  validation accuracy:		92.93 %
Epoch 471 of 2000 took 0.154s
  training loss:		0.082529
  validation loss:		0.225615
  validation accuracy:		93.15 %
Epoch 472 of 2000 took 0.146s
  training loss:		0.081738
  validation loss:		0.219908
  validation accuracy:		93.37 %
Epoch 473 of 2000 took 0.182s
  training loss:		0.081709
  validation loss:		0.231530
  validation accuracy:		93.04 %
Epoch 474 of 2000 took 0.182s
  training loss:		0.080699
  validation loss:		0.220183
  validation accuracy:		93.59 %
Epoch 475 of 2000 took 0.183s
  training loss:		0.080225
  validation loss:		0.223265
  validation accuracy:		93.15 %
Epoch 476 of 2000 took 0.178s
  training loss:		0.081872
  validation loss:		0.230174
  validation accuracy:		92.93 %
Epoch 477 of 2000 took 0.182s
  training loss:		0.080791
  validation loss:		0.228444
  validation accuracy:		92.93 %
Epoch 478 of 2000 took 0.187s
  training loss:		0.080050
  validation loss:		0.227366
  validation accuracy:		93.04 %
Epoch 479 of 2000 took 0.143s
  training loss:		0.080152
  validation loss:		0.224385
  validation accuracy:		92.93 %
Epoch 480 of 2000 took 0.157s
  training loss:		0.081574
  validation loss:		0.233979
  validation accuracy:		92.72 %
Epoch 481 of 2000 took 0.138s
  training loss:		0.083073
  validation loss:		0.238540
  validation accuracy:		92.83 %
Epoch 482 of 2000 took 0.187s
  training loss:		0.080070
  validation loss:		0.220473
  validation accuracy:		93.37 %
Epoch 483 of 2000 took 0.189s
  training loss:		0.078728
  validation loss:		0.219996
  validation accuracy:		93.26 %
Epoch 484 of 2000 took 0.189s
  training loss:		0.079362
  validation loss:		0.223439
  validation accuracy:		93.15 %
Epoch 485 of 2000 took 0.192s
  training loss:		0.076506
  validation loss:		0.228452
  validation accuracy:		93.04 %
Epoch 486 of 2000 took 0.188s
  training loss:		0.077126
  validation loss:		0.225811
  validation accuracy:		93.15 %
Epoch 487 of 2000 took 0.191s
  training loss:		0.079000
  validation loss:		0.228267
  validation accuracy:		92.72 %
Epoch 488 of 2000 took 0.194s
  training loss:		0.078184
  validation loss:		0.222492
  validation accuracy:		93.26 %
Epoch 489 of 2000 took 0.142s
  training loss:		0.077985
  validation loss:		0.232187
  validation accuracy:		92.72 %
Epoch 490 of 2000 took 0.148s
  training loss:		0.078577
  validation loss:		0.223198
  validation accuracy:		93.37 %
Epoch 491 of 2000 took 0.167s
  training loss:		0.075378
  validation loss:		0.223318
  validation accuracy:		93.48 %
Epoch 492 of 2000 took 0.139s
  training loss:		0.077955
  validation loss:		0.230173
  validation accuracy:		93.04 %
Epoch 493 of 2000 took 0.143s
  training loss:		0.076495
  validation loss:		0.227884
  validation accuracy:		93.37 %
Epoch 494 of 2000 took 0.145s
  training loss:		0.076211
  validation loss:		0.225087
  validation accuracy:		93.37 %
Epoch 495 of 2000 took 0.140s
  training loss:		0.075671
  validation loss:		0.242962
  validation accuracy:		92.72 %
Epoch 496 of 2000 took 0.150s
  training loss:		0.076468
  validation loss:		0.230707
  validation accuracy:		93.04 %
Epoch 497 of 2000 took 0.142s
  training loss:		0.075744
  validation loss:		0.222987
  validation accuracy:		93.37 %
Epoch 498 of 2000 took 0.142s
  training loss:		0.075141
  validation loss:		0.237099
  validation accuracy:		92.83 %
Epoch 499 of 2000 took 0.145s
  training loss:		0.073800
  validation loss:		0.222070
  validation accuracy:		93.59 %
Epoch 500 of 2000 took 0.137s
  training loss:		0.075070
  validation loss:		0.231382
  validation accuracy:		93.15 %
Epoch 501 of 2000 took 0.143s
  training loss:		0.076625
  validation loss:		0.226752
  validation accuracy:		93.37 %
Epoch 502 of 2000 took 0.155s
  training loss:		0.075354
  validation loss:		0.222857
  validation accuracy:		93.37 %
Epoch 503 of 2000 took 0.148s
  training loss:		0.077185
  validation loss:		0.232748
  validation accuracy:		92.93 %
Epoch 504 of 2000 took 0.147s
  training loss:		0.074590
  validation loss:		0.242967
  validation accuracy:		93.04 %
Epoch 505 of 2000 took 0.146s
  training loss:		0.074698
  validation loss:		0.228742
  validation accuracy:		93.15 %
Epoch 506 of 2000 took 0.142s
  training loss:		0.074477
  validation loss:		0.225497
  validation accuracy:		93.37 %
Epoch 507 of 2000 took 0.143s
  training loss:		0.073029
  validation loss:		0.241096
  validation accuracy:		92.93 %
Epoch 508 of 2000 took 0.150s
  training loss:		0.072640
  validation loss:		0.231897
  validation accuracy:		93.15 %
Epoch 509 of 2000 took 0.178s
  training loss:		0.073059
  validation loss:		0.234016
  validation accuracy:		92.83 %
Epoch 510 of 2000 took 0.148s
  training loss:		0.076440
  validation loss:		0.231428
  validation accuracy:		93.26 %
Epoch 511 of 2000 took 0.143s
  training loss:		0.074837
  validation loss:		0.226649
  validation accuracy:		93.15 %
Epoch 512 of 2000 took 0.144s
  training loss:		0.073249
  validation loss:		0.225283
  validation accuracy:		93.37 %
Epoch 513 of 2000 took 0.147s
  training loss:		0.074001
  validation loss:		0.230867
  validation accuracy:		92.93 %
Epoch 514 of 2000 took 0.142s
  training loss:		0.074712
  validation loss:		0.231731
  validation accuracy:		93.04 %
Epoch 515 of 2000 took 0.152s
  training loss:		0.071853
  validation loss:		0.234656
  validation accuracy:		93.15 %
Epoch 516 of 2000 took 0.136s
  training loss:		0.073027
  validation loss:		0.237125
  validation accuracy:		92.72 %
Epoch 517 of 2000 took 0.144s
  training loss:		0.071727
  validation loss:		0.231338
  validation accuracy:		93.26 %
Epoch 518 of 2000 took 0.146s
  training loss:		0.073116
  validation loss:		0.229708
  validation accuracy:		93.37 %
Epoch 519 of 2000 took 0.150s
  training loss:		0.072503
  validation loss:		0.232330
  validation accuracy:		93.15 %
Epoch 520 of 2000 took 0.136s
  training loss:		0.071778
  validation loss:		0.231365
  validation accuracy:		93.15 %
Epoch 521 of 2000 took 0.145s
  training loss:		0.072857
  validation loss:		0.233536
  validation accuracy:		93.26 %
Epoch 522 of 2000 took 0.142s
  training loss:		0.071871
  validation loss:		0.233663
  validation accuracy:		93.26 %
Epoch 523 of 2000 took 0.154s
  training loss:		0.070843
  validation loss:		0.233231
  validation accuracy:		93.15 %
Epoch 524 of 2000 took 0.145s
  training loss:		0.072039
  validation loss:		0.231292
  validation accuracy:		93.26 %
Epoch 525 of 2000 took 0.145s
  training loss:		0.070918
  validation loss:		0.235492
  validation accuracy:		93.15 %
Epoch 526 of 2000 took 0.143s
  training loss:		0.071286
  validation loss:		0.231162
  validation accuracy:		93.48 %
Epoch 527 of 2000 took 0.161s
  training loss:		0.071186
  validation loss:		0.238984
  validation accuracy:		92.93 %
Epoch 528 of 2000 took 0.146s
  training loss:		0.072092
  validation loss:		0.239597
  validation accuracy:		92.93 %
Epoch 529 of 2000 took 0.151s
  training loss:		0.068478
  validation loss:		0.241922
  validation accuracy:		92.72 %
Epoch 530 of 2000 took 0.157s
  training loss:		0.071604
  validation loss:		0.235809
  validation accuracy:		92.83 %
Epoch 531 of 2000 took 0.158s
  training loss:		0.070565
  validation loss:		0.231211
  validation accuracy:		93.37 %
Epoch 532 of 2000 took 0.144s
  training loss:		0.068113
  validation loss:		0.241736
  validation accuracy:		93.04 %
Epoch 533 of 2000 took 0.147s
  training loss:		0.071442
  validation loss:		0.224397
  validation accuracy:		93.48 %
Epoch 534 of 2000 took 0.183s
  training loss:		0.067671
  validation loss:		0.232147
  validation accuracy:		93.26 %
Epoch 535 of 2000 took 0.186s
  training loss:		0.071245
  validation loss:		0.238857
  validation accuracy:		92.93 %
Epoch 536 of 2000 took 0.183s
  training loss:		0.068283
  validation loss:		0.233372
  validation accuracy:		93.37 %
Epoch 537 of 2000 took 0.171s
  training loss:		0.066107
  validation loss:		0.241088
  validation accuracy:		92.83 %
Epoch 538 of 2000 took 0.174s
  training loss:		0.070747
  validation loss:		0.238523
  validation accuracy:		93.04 %
Epoch 539 of 2000 took 0.162s
  training loss:		0.066423
  validation loss:		0.240258
  validation accuracy:		92.93 %
Epoch 540 of 2000 took 0.145s
  training loss:		0.067793
  validation loss:		0.241024
  validation accuracy:		93.04 %
Epoch 541 of 2000 took 0.145s
  training loss:		0.067639
  validation loss:		0.236587
  validation accuracy:		93.26 %
Epoch 542 of 2000 took 0.144s
  training loss:		0.070207
  validation loss:		0.243678
  validation accuracy:		92.83 %
Epoch 543 of 2000 took 0.141s
  training loss:		0.068240
  validation loss:		0.238348
  validation accuracy:		93.15 %
Epoch 544 of 2000 took 0.142s
  training loss:		0.067413
  validation loss:		0.235516
  validation accuracy:		93.37 %
Epoch 545 of 2000 took 0.141s
  training loss:		0.069155
  validation loss:		0.235588
  validation accuracy:		93.04 %
Epoch 546 of 2000 took 0.147s
  training loss:		0.064425
  validation loss:		0.229106
  validation accuracy:		93.59 %
Epoch 547 of 2000 took 0.145s
  training loss:		0.068803
  validation loss:		0.242444
  validation accuracy:		93.04 %
Epoch 548 of 2000 took 0.150s
  training loss:		0.067755
  validation loss:		0.232707
  validation accuracy:		93.48 %
Epoch 549 of 2000 took 0.147s
  training loss:		0.067170
  validation loss:		0.247496
  validation accuracy:		92.50 %
Epoch 550 of 2000 took 0.140s
  training loss:		0.068057
  validation loss:		0.247596
  validation accuracy:		92.83 %
Epoch 551 of 2000 took 0.145s
  training loss:		0.066681
  validation loss:		0.238970
  validation accuracy:		93.04 %
Epoch 552 of 2000 took 0.168s
  training loss:		0.066382
  validation loss:		0.239369
  validation accuracy:		93.04 %
Epoch 553 of 2000 took 0.168s
  training loss:		0.066420
  validation loss:		0.240902
  validation accuracy:		93.15 %
Epoch 554 of 2000 took 0.139s
  training loss:		0.065707
  validation loss:		0.234704
  validation accuracy:		93.26 %
Epoch 555 of 2000 took 0.143s
  training loss:		0.066582
  validation loss:		0.238010
  validation accuracy:		93.26 %
Epoch 556 of 2000 took 0.140s
  training loss:		0.067555
  validation loss:		0.247356
  validation accuracy:		92.93 %
Epoch 557 of 2000 took 0.149s
  training loss:		0.064432
  validation loss:		0.234032
  validation accuracy:		93.15 %
Epoch 558 of 2000 took 0.174s
  training loss:		0.065890
  validation loss:		0.239097
  validation accuracy:		93.26 %
Epoch 559 of 2000 took 0.153s
  training loss:		0.066730
  validation loss:		0.239843
  validation accuracy:		93.15 %
Epoch 560 of 2000 took 0.151s
  training loss:		0.066459
  validation loss:		0.235912
  validation accuracy:		93.26 %
Epoch 561 of 2000 took 0.151s
  training loss:		0.065434
  validation loss:		0.250971
  validation accuracy:		92.61 %
Epoch 562 of 2000 took 0.144s
  training loss:		0.063014
  validation loss:		0.236700
  validation accuracy:		93.37 %
Epoch 563 of 2000 took 0.160s
  training loss:		0.063590
  validation loss:		0.247429
  validation accuracy:		92.61 %
Epoch 564 of 2000 took 0.171s
  training loss:		0.063060
  validation loss:		0.241285
  validation accuracy:		93.15 %
Epoch 565 of 2000 took 0.152s
  training loss:		0.064080
  validation loss:		0.246309
  validation accuracy:		92.83 %
Epoch 566 of 2000 took 0.148s
  training loss:		0.067320
  validation loss:		0.242431
  validation accuracy:		93.48 %
Epoch 567 of 2000 took 0.149s
  training loss:		0.063412
  validation loss:		0.237102
  validation accuracy:		93.15 %
Epoch 568 of 2000 took 0.138s
  training loss:		0.062929
  validation loss:		0.238738
  validation accuracy:		93.26 %
Epoch 569 of 2000 took 0.161s
  training loss:		0.064889
  validation loss:		0.245349
  validation accuracy:		93.04 %
Epoch 570 of 2000 took 0.171s
  training loss:		0.064163
  validation loss:		0.243984
  validation accuracy:		93.04 %
Epoch 571 of 2000 took 0.141s
  training loss:		0.064947
  validation loss:		0.244173
  validation accuracy:		93.26 %
Epoch 572 of 2000 took 0.156s
  training loss:		0.065166
  validation loss:		0.240116
  validation accuracy:		93.26 %
Epoch 573 of 2000 took 0.165s
  training loss:		0.064314
  validation loss:		0.243290
  validation accuracy:		92.83 %
Epoch 574 of 2000 took 0.150s
  training loss:		0.060670
  validation loss:		0.238718
  validation accuracy:		93.48 %
Epoch 575 of 2000 took 0.156s
  training loss:		0.063191
  validation loss:		0.247402
  validation accuracy:		93.04 %
Epoch 576 of 2000 took 0.184s
  training loss:		0.064409
  validation loss:		0.244274
  validation accuracy:		92.93 %
Epoch 577 of 2000 took 0.138s
  training loss:		0.061374
  validation loss:		0.239674
  validation accuracy:		93.48 %
Epoch 578 of 2000 took 0.161s
  training loss:		0.061982
  validation loss:		0.234193
  validation accuracy:		93.59 %
Epoch 579 of 2000 took 0.141s
  training loss:		0.064070
  validation loss:		0.241163
  validation accuracy:		93.26 %
Epoch 580 of 2000 took 0.141s
  training loss:		0.061974
  validation loss:		0.246014
  validation accuracy:		92.93 %
Epoch 581 of 2000 took 0.153s
  training loss:		0.062862
  validation loss:		0.244669
  validation accuracy:		93.15 %
Epoch 582 of 2000 took 0.145s
  training loss:		0.063083
  validation loss:		0.238515
  validation accuracy:		93.48 %
Epoch 583 of 2000 took 0.149s
  training loss:		0.060628
  validation loss:		0.245921
  validation accuracy:		92.83 %
Epoch 584 of 2000 took 0.146s
  training loss:		0.060788
  validation loss:		0.239020
  validation accuracy:		93.48 %
Epoch 585 of 2000 took 0.147s
  training loss:		0.060827
  validation loss:		0.247554
  validation accuracy:		93.04 %
Epoch 586 of 2000 took 0.139s
  training loss:		0.061789
  validation loss:		0.243478
  validation accuracy:		93.15 %
Epoch 587 of 2000 took 0.157s
  training loss:		0.061529
  validation loss:		0.246260
  validation accuracy:		93.15 %
Epoch 588 of 2000 took 0.147s
  training loss:		0.061020
  validation loss:		0.242368
  validation accuracy:		93.26 %
Epoch 589 of 2000 took 0.142s
  training loss:		0.059401
  validation loss:		0.249708
  validation accuracy:		93.04 %
Epoch 590 of 2000 took 0.148s
  training loss:		0.061729
  validation loss:		0.238240
  validation accuracy:		93.37 %
Epoch 591 of 2000 took 0.140s
  training loss:		0.059645
  validation loss:		0.243065
  validation accuracy:		93.26 %
Epoch 592 of 2000 took 0.147s
  training loss:		0.061483
  validation loss:		0.245769
  validation accuracy:		93.37 %
Epoch 593 of 2000 took 0.139s
  training loss:		0.059040
  validation loss:		0.238794
  validation accuracy:		93.37 %
Epoch 594 of 2000 took 0.140s
  training loss:		0.060313
  validation loss:		0.256297
  validation accuracy:		92.93 %
Epoch 595 of 2000 took 0.159s
  training loss:		0.060568
  validation loss:		0.255907
  validation accuracy:		92.61 %
Epoch 596 of 2000 took 0.135s
  training loss:		0.059831
  validation loss:		0.238569
  validation accuracy:		93.37 %
Epoch 597 of 2000 took 0.152s
  training loss:		0.060219
  validation loss:		0.250351
  validation accuracy:		93.04 %
Epoch 598 of 2000 took 0.140s
  training loss:		0.059830
  validation loss:		0.249793
  validation accuracy:		93.04 %
Epoch 599 of 2000 took 0.145s
  training loss:		0.059306
  validation loss:		0.251177
  validation accuracy:		93.04 %
Epoch 600 of 2000 took 0.148s
  training loss:		0.057533
  validation loss:		0.243193
  validation accuracy:		93.37 %
Epoch 601 of 2000 took 0.143s
  training loss:		0.060023
  validation loss:		0.248561
  validation accuracy:		93.26 %
Epoch 602 of 2000 took 0.148s
  training loss:		0.058458
  validation loss:		0.249396
  validation accuracy:		93.15 %
Epoch 603 of 2000 took 0.143s
  training loss:		0.056767
  validation loss:		0.245197
  validation accuracy:		93.48 %
Epoch 604 of 2000 took 0.142s
  training loss:		0.059951
  validation loss:		0.249180
  validation accuracy:		93.37 %
Epoch 605 of 2000 took 0.164s
  training loss:		0.058025
  validation loss:		0.248365
  validation accuracy:		93.15 %
Epoch 606 of 2000 took 0.164s
  training loss:		0.059308
  validation loss:		0.250592
  validation accuracy:		93.15 %
Epoch 607 of 2000 took 0.144s
  training loss:		0.058769
  validation loss:		0.249495
  validation accuracy:		93.26 %
Epoch 608 of 2000 took 0.165s
  training loss:		0.059463
  validation loss:		0.254081
  validation accuracy:		93.15 %
Epoch 609 of 2000 took 0.140s
  training loss:		0.058552
  validation loss:		0.251068
  validation accuracy:		93.15 %
Epoch 610 of 2000 took 0.142s
  training loss:		0.056242
  validation loss:		0.247951
  validation accuracy:		93.26 %
Epoch 611 of 2000 took 0.142s
  training loss:		0.056601
  validation loss:		0.242762
  validation accuracy:		93.59 %
Epoch 612 of 2000 took 0.151s
  training loss:		0.056650
  validation loss:		0.253131
  validation accuracy:		93.15 %
Epoch 613 of 2000 took 0.145s
  training loss:		0.057928
  validation loss:		0.249353
  validation accuracy:		93.04 %
Epoch 614 of 2000 took 0.157s
  training loss:		0.057931
  validation loss:		0.249834
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.143s
  training loss:		0.056267
  validation loss:		0.249085
  validation accuracy:		93.26 %
Epoch 616 of 2000 took 0.139s
  training loss:		0.056442
  validation loss:		0.247720
  validation accuracy:		93.48 %
Epoch 617 of 2000 took 0.151s
  training loss:		0.057223
  validation loss:		0.251007
  validation accuracy:		93.15 %
Epoch 618 of 2000 took 0.163s
  training loss:		0.056249
  validation loss:		0.251978
  validation accuracy:		93.15 %
Epoch 619 of 2000 took 0.170s
  training loss:		0.055860
  validation loss:		0.249824
  validation accuracy:		93.15 %
Epoch 620 of 2000 took 0.172s
  training loss:		0.056116
  validation loss:		0.248217
  validation accuracy:		93.48 %
Epoch 621 of 2000 took 0.183s
  training loss:		0.056215
  validation loss:		0.251404
  validation accuracy:		93.59 %
Epoch 622 of 2000 took 0.170s
  training loss:		0.057340
  validation loss:		0.255142
  validation accuracy:		93.26 %
Epoch 623 of 2000 took 0.157s
  training loss:		0.054779
  validation loss:		0.258246
  validation accuracy:		93.04 %
Epoch 624 of 2000 took 0.165s
  training loss:		0.055479
  validation loss:		0.244660
  validation accuracy:		93.48 %
Epoch 625 of 2000 took 0.147s
  training loss:		0.056493
  validation loss:		0.258987
  validation accuracy:		92.83 %
Epoch 626 of 2000 took 0.152s
  training loss:		0.055585
  validation loss:		0.262011
  validation accuracy:		93.04 %
Epoch 627 of 2000 took 0.158s
  training loss:		0.054741
  validation loss:		0.251735
  validation accuracy:		93.15 %
Epoch 628 of 2000 took 0.150s
  training loss:		0.055601
  validation loss:		0.249854
  validation accuracy:		93.15 %
Epoch 629 of 2000 took 0.146s
  training loss:		0.054826
  validation loss:		0.253366
  validation accuracy:		93.15 %
Epoch 630 of 2000 took 0.145s
  training loss:		0.055156
  validation loss:		0.255758
  validation accuracy:		93.15 %
Epoch 631 of 2000 took 0.152s
  training loss:		0.053768
  validation loss:		0.253284
  validation accuracy:		93.48 %
Epoch 632 of 2000 took 0.141s
  training loss:		0.055737
  validation loss:		0.263284
  validation accuracy:		92.93 %
Epoch 633 of 2000 took 0.145s
  training loss:		0.055641
  validation loss:		0.251073
  validation accuracy:		93.48 %
Epoch 634 of 2000 took 0.146s
  training loss:		0.054127
  validation loss:		0.252782
  validation accuracy:		92.93 %
Epoch 635 of 2000 took 0.145s
  training loss:		0.054869
  validation loss:		0.253244
  validation accuracy:		93.26 %
Epoch 636 of 2000 took 0.163s
  training loss:		0.052366
  validation loss:		0.258943
  validation accuracy:		93.04 %
Epoch 637 of 2000 took 0.161s
  training loss:		0.054974
  validation loss:		0.248884
  validation accuracy:		93.48 %
Epoch 638 of 2000 took 0.138s
  training loss:		0.054245
  validation loss:		0.263503
  validation accuracy:		93.04 %
Epoch 639 of 2000 took 0.136s
  training loss:		0.055208
  validation loss:		0.260075
  validation accuracy:		92.93 %
Epoch 640 of 2000 took 0.142s
  training loss:		0.054802
  validation loss:		0.254714
  validation accuracy:		92.93 %
Epoch 641 of 2000 took 0.156s
  training loss:		0.052181
  validation loss:		0.259441
  validation accuracy:		92.93 %
Epoch 642 of 2000 took 0.159s
  training loss:		0.052886
  validation loss:		0.266274
  validation accuracy:		92.93 %
Epoch 643 of 2000 took 0.144s
  training loss:		0.053415
  validation loss:		0.261172
  validation accuracy:		93.48 %
Epoch 644 of 2000 took 0.146s
  training loss:		0.053337
  validation loss:		0.254589
  validation accuracy:		93.37 %
Epoch 645 of 2000 took 0.144s
  training loss:		0.054865
  validation loss:		0.254490
  validation accuracy:		93.15 %
Epoch 646 of 2000 took 0.146s
  training loss:		0.052833
  validation loss:		0.256505
  validation accuracy:		93.26 %
Epoch 647 of 2000 took 0.157s
  training loss:		0.053542
  validation loss:		0.262411
  validation accuracy:		92.93 %
Epoch 648 of 2000 took 0.165s
  training loss:		0.052960
  validation loss:		0.248812
  validation accuracy:		93.48 %
Epoch 649 of 2000 took 0.141s
  training loss:		0.053897
  validation loss:		0.257890
  validation accuracy:		93.26 %
Epoch 650 of 2000 took 0.149s
  training loss:		0.051784
  validation loss:		0.255849
  validation accuracy:		93.26 %
Epoch 651 of 2000 took 0.148s
  training loss:		0.051031
  validation loss:		0.267540
  validation accuracy:		93.15 %
Epoch 652 of 2000 took 0.145s
  training loss:		0.053334
  validation loss:		0.261270
  validation accuracy:		93.26 %
Epoch 653 of 2000 took 0.146s
  training loss:		0.050459
  validation loss:		0.253764
  validation accuracy:		93.48 %
Epoch 654 of 2000 took 0.144s
  training loss:		0.051904
  validation loss:		0.261012
  validation accuracy:		93.15 %
Epoch 655 of 2000 took 0.138s
  training loss:		0.052972
  validation loss:		0.254469
  validation accuracy:		93.26 %
Epoch 656 of 2000 took 0.141s
  training loss:		0.052098
  validation loss:		0.255401
  validation accuracy:		93.26 %
Epoch 657 of 2000 took 0.145s
  training loss:		0.052356
  validation loss:		0.265966
  validation accuracy:		93.15 %
Epoch 658 of 2000 took 0.149s
  training loss:		0.053279
  validation loss:		0.262911
  validation accuracy:		93.15 %
Epoch 659 of 2000 took 0.165s
  training loss:		0.051079
  validation loss:		0.258744
  validation accuracy:		93.26 %
Epoch 660 of 2000 took 0.150s
  training loss:		0.049958
  validation loss:		0.255560
  validation accuracy:		93.26 %
Epoch 661 of 2000 took 0.149s
  training loss:		0.051299
  validation loss:		0.256071
  validation accuracy:		93.37 %
Epoch 662 of 2000 took 0.146s
  training loss:		0.050467
  validation loss:		0.260890
  validation accuracy:		93.26 %
Epoch 663 of 2000 took 0.150s
  training loss:		0.048246
  validation loss:		0.262934
  validation accuracy:		93.04 %
Epoch 664 of 2000 took 0.153s
  training loss:		0.051283
  validation loss:		0.259202
  validation accuracy:		93.59 %
Epoch 665 of 2000 took 0.153s
  training loss:		0.050583
  validation loss:		0.261385
  validation accuracy:		93.26 %
Epoch 666 of 2000 took 0.161s
  training loss:		0.047674
  validation loss:		0.263783
  validation accuracy:		93.15 %
Epoch 667 of 2000 took 0.140s
  training loss:		0.050974
  validation loss:		0.263564
  validation accuracy:		93.15 %
Epoch 668 of 2000 took 0.142s
  training loss:		0.049594
  validation loss:		0.263667
  validation accuracy:		93.04 %
Epoch 669 of 2000 took 0.146s
  training loss:		0.047551
  validation loss:		0.265191
  validation accuracy:		93.37 %
Epoch 670 of 2000 took 0.183s
  training loss:		0.050647
  validation loss:		0.260765
  validation accuracy:		93.15 %
Epoch 671 of 2000 took 0.148s
  training loss:		0.047969
  validation loss:		0.265078
  validation accuracy:		93.26 %
Epoch 672 of 2000 took 0.172s
  training loss:		0.049496
  validation loss:		0.268743
  validation accuracy:		93.04 %
Epoch 673 of 2000 took 0.139s
  training loss:		0.048800
  validation loss:		0.268455
  validation accuracy:		93.04 %
Epoch 674 of 2000 took 0.142s
  training loss:		0.050293
  validation loss:		0.267985
  validation accuracy:		93.15 %
Epoch 675 of 2000 took 0.145s
  training loss:		0.048141
  validation loss:		0.265773
  validation accuracy:		92.93 %
Epoch 676 of 2000 took 0.141s
  training loss:		0.048593
  validation loss:		0.264622
  validation accuracy:		93.26 %
Epoch 677 of 2000 took 0.182s
  training loss:		0.047810
  validation loss:		0.281408
  validation accuracy:		92.28 %
Epoch 678 of 2000 took 0.152s
  training loss:		0.049527
  validation loss:		0.264269
  validation accuracy:		93.15 %
Epoch 679 of 2000 took 0.144s
  training loss:		0.048975
  validation loss:		0.261020
  validation accuracy:		93.26 %
Epoch 680 of 2000 took 0.140s
  training loss:		0.047454
  validation loss:		0.268190
  validation accuracy:		93.15 %
Epoch 681 of 2000 took 0.153s
  training loss:		0.048389
  validation loss:		0.259462
  validation accuracy:		93.26 %
Epoch 682 of 2000 took 0.138s
  training loss:		0.048073
  validation loss:		0.272111
  validation accuracy:		92.93 %
Epoch 683 of 2000 took 0.151s
  training loss:		0.049191
  validation loss:		0.262825
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.159s
  training loss:		0.047598
  validation loss:		0.266908
  validation accuracy:		93.37 %
Epoch 685 of 2000 took 0.157s
  training loss:		0.048812
  validation loss:		0.261528
  validation accuracy:		93.37 %
Epoch 686 of 2000 took 0.157s
  training loss:		0.047188
  validation loss:		0.271032
  validation accuracy:		92.93 %
Epoch 687 of 2000 took 0.161s
  training loss:		0.048820
  validation loss:		0.266373
  validation accuracy:		93.37 %
Epoch 688 of 2000 took 0.138s
  training loss:		0.046593
  validation loss:		0.270878
  validation accuracy:		93.26 %
Epoch 689 of 2000 took 0.146s
  training loss:		0.048688
  validation loss:		0.272542
  validation accuracy:		93.04 %
Epoch 690 of 2000 took 0.148s
  training loss:		0.048272
  validation loss:		0.282535
  validation accuracy:		92.61 %
Epoch 691 of 2000 took 0.142s
  training loss:		0.046925
  validation loss:		0.262524
  validation accuracy:		93.26 %
Epoch 692 of 2000 took 0.143s
  training loss:		0.048055
  validation loss:		0.267954
  validation accuracy:		93.37 %
Epoch 693 of 2000 took 0.136s
  training loss:		0.046585
  validation loss:		0.268565
  validation accuracy:		93.26 %
Epoch 694 of 2000 took 0.142s
  training loss:		0.048143
  validation loss:		0.268529
  validation accuracy:		93.37 %
Epoch 695 of 2000 took 0.145s
  training loss:		0.047725
  validation loss:		0.268615
  validation accuracy:		93.15 %
Epoch 696 of 2000 took 0.143s
  training loss:		0.047011
  validation loss:		0.262425
  validation accuracy:		93.48 %
Epoch 697 of 2000 took 0.154s
  training loss:		0.046532
  validation loss:		0.267619
  validation accuracy:		93.26 %
Epoch 698 of 2000 took 0.148s
  training loss:		0.046541
  validation loss:		0.265929
  validation accuracy:		93.48 %
Epoch 699 of 2000 took 0.140s
  training loss:		0.045030
  validation loss:		0.272352
  validation accuracy:		93.04 %
Epoch 700 of 2000 took 0.148s
  training loss:		0.046343
  validation loss:		0.271895
  validation accuracy:		93.37 %
Epoch 701 of 2000 took 0.149s
  training loss:		0.046523
  validation loss:		0.266171
  validation accuracy:		93.37 %
Epoch 702 of 2000 took 0.167s
  training loss:		0.046081
  validation loss:		0.269832
  validation accuracy:		93.15 %
Epoch 703 of 2000 took 0.153s
  training loss:		0.045248
  validation loss:		0.274200
  validation accuracy:		93.04 %
Epoch 704 of 2000 took 0.171s
  training loss:		0.044333
  validation loss:		0.269457
  validation accuracy:		92.93 %
Epoch 705 of 2000 took 0.181s
  training loss:		0.045839
  validation loss:		0.274916
  validation accuracy:		93.26 %
Epoch 706 of 2000 took 0.155s
  training loss:		0.046359
  validation loss:		0.268239
  validation accuracy:		93.37 %
Epoch 707 of 2000 took 0.148s
  training loss:		0.045858
  validation loss:		0.271731
  validation accuracy:		93.26 %
Epoch 708 of 2000 took 0.159s
  training loss:		0.046112
  validation loss:		0.274442
  validation accuracy:		92.93 %
Epoch 709 of 2000 took 0.154s
  training loss:		0.046494
  validation loss:		0.275530
  validation accuracy:		92.83 %
Epoch 710 of 2000 took 0.146s
  training loss:		0.044397
  validation loss:		0.269015
  validation accuracy:		93.37 %
Epoch 711 of 2000 took 0.144s
  training loss:		0.043875
  validation loss:		0.273003
  validation accuracy:		93.37 %
Epoch 712 of 2000 took 0.148s
  training loss:		0.043418
  validation loss:		0.273741
  validation accuracy:		93.26 %
Epoch 713 of 2000 took 0.149s
  training loss:		0.044027
  validation loss:		0.281632
  validation accuracy:		93.15 %
Epoch 714 of 2000 took 0.195s
  training loss:		0.043480
  validation loss:		0.268717
  validation accuracy:		93.37 %
Epoch 715 of 2000 took 0.156s
  training loss:		0.044344
  validation loss:		0.268671
  validation accuracy:		93.37 %
Epoch 716 of 2000 took 0.167s
  training loss:		0.044083
  validation loss:		0.277828
  validation accuracy:		93.15 %
Epoch 717 of 2000 took 0.151s
  training loss:		0.044352
  validation loss:		0.272681
  validation accuracy:		93.48 %
Epoch 718 of 2000 took 0.163s
  training loss:		0.042494
  validation loss:		0.274352
  validation accuracy:		93.37 %
Epoch 719 of 2000 took 0.164s
  training loss:		0.044128
  validation loss:		0.275004
  validation accuracy:		93.15 %
Epoch 720 of 2000 took 0.168s
  training loss:		0.045764
  validation loss:		0.281685
  validation accuracy:		93.15 %
Epoch 721 of 2000 took 0.146s
  training loss:		0.044138
  validation loss:		0.271644
  validation accuracy:		93.37 %
Epoch 722 of 2000 took 0.153s
  training loss:		0.045808
  validation loss:		0.275314
  validation accuracy:		93.15 %
Epoch 723 of 2000 took 0.146s
  training loss:		0.041785
  validation loss:		0.272672
  validation accuracy:		93.37 %
Epoch 724 of 2000 took 0.136s
  training loss:		0.043444
  validation loss:		0.271973
  validation accuracy:		93.37 %
Epoch 725 of 2000 took 0.173s
  training loss:		0.042504
  validation loss:		0.273201
  validation accuracy:		93.26 %
Epoch 726 of 2000 took 0.165s
  training loss:		0.043528
  validation loss:		0.267563
  validation accuracy:		93.48 %
Epoch 727 of 2000 took 0.152s
  training loss:		0.041975
  validation loss:		0.274592
  validation accuracy:		93.15 %
Epoch 728 of 2000 took 0.164s
  training loss:		0.041172
  validation loss:		0.280693
  validation accuracy:		92.93 %
Epoch 729 of 2000 took 0.146s
  training loss:		0.043705
  validation loss:		0.278071
  validation accuracy:		93.48 %
Epoch 730 of 2000 took 0.148s
  training loss:		0.043633
  validation loss:		0.275069
  validation accuracy:		93.15 %
Epoch 731 of 2000 took 0.146s
  training loss:		0.042270
  validation loss:		0.278754
  validation accuracy:		93.37 %
Epoch 732 of 2000 took 0.153s
  training loss:		0.041292
  validation loss:		0.282046
  validation accuracy:		93.15 %
Epoch 733 of 2000 took 0.143s
  training loss:		0.042377
  validation loss:		0.280001
  validation accuracy:		93.15 %
Epoch 734 of 2000 took 0.155s
  training loss:		0.042294
  validation loss:		0.282713
  validation accuracy:		92.93 %
Epoch 735 of 2000 took 0.159s
  training loss:		0.042982
  validation loss:		0.272724
  validation accuracy:		93.37 %
Epoch 736 of 2000 took 0.141s
  training loss:		0.042348
  validation loss:		0.279641
  validation accuracy:		93.37 %
Epoch 737 of 2000 took 0.141s
  training loss:		0.042932
  validation loss:		0.287645
  validation accuracy:		92.72 %
Epoch 738 of 2000 took 0.145s
  training loss:		0.043398
  validation loss:		0.279360
  validation accuracy:		93.26 %
Epoch 739 of 2000 took 0.142s
  training loss:		0.042516
  validation loss:		0.273557
  validation accuracy:		93.48 %
Epoch 740 of 2000 took 0.143s
  training loss:		0.042292
  validation loss:		0.279679
  validation accuracy:		93.48 %
Epoch 741 of 2000 took 0.148s
  training loss:		0.041550
  validation loss:		0.277614
  validation accuracy:		93.26 %
Epoch 742 of 2000 took 0.136s
  training loss:		0.041857
  validation loss:		0.278155
  validation accuracy:		93.48 %
Epoch 743 of 2000 took 0.166s
  training loss:		0.041310
  validation loss:		0.291781
  validation accuracy:		92.72 %
Epoch 744 of 2000 took 0.142s
  training loss:		0.040530
  validation loss:		0.271857
  validation accuracy:		93.26 %
Epoch 745 of 2000 took 0.177s
  training loss:		0.041730
  validation loss:		0.275212
  validation accuracy:		93.15 %
Epoch 746 of 2000 took 0.146s
  training loss:		0.039953
  validation loss:		0.282620
  validation accuracy:		93.26 %
Epoch 747 of 2000 took 0.147s
  training loss:		0.039160
  validation loss:		0.288439
  validation accuracy:		93.04 %
Epoch 748 of 2000 took 0.181s
  training loss:		0.041698
  validation loss:		0.277144
  validation accuracy:		93.15 %
Epoch 749 of 2000 took 0.164s
  training loss:		0.041147
  validation loss:		0.283242
  validation accuracy:		93.15 %
Epoch 750 of 2000 took 0.150s
  training loss:		0.041360
  validation loss:		0.281079
  validation accuracy:		93.15 %
Epoch 751 of 2000 took 0.152s
  training loss:		0.041657
  validation loss:		0.281774
  validation accuracy:		93.15 %
Epoch 752 of 2000 took 0.171s
  training loss:		0.040882
  validation loss:		0.283825
  validation accuracy:		93.04 %
Epoch 753 of 2000 took 0.148s
  training loss:		0.041426
  validation loss:		0.282849
  validation accuracy:		93.26 %
Epoch 754 of 2000 took 0.160s
  training loss:		0.040174
  validation loss:		0.280310
  validation accuracy:		93.37 %
Epoch 755 of 2000 took 0.167s
  training loss:		0.037816
  validation loss:		0.292231
  validation accuracy:		92.93 %
Epoch 756 of 2000 took 0.138s
  training loss:		0.040670
  validation loss:		0.276184
  validation accuracy:		93.15 %
Epoch 757 of 2000 took 0.177s
  training loss:		0.038626
  validation loss:		0.291859
  validation accuracy:		93.04 %
Epoch 758 of 2000 took 0.140s
  training loss:		0.038706
  validation loss:		0.289983
  validation accuracy:		93.04 %
Epoch 759 of 2000 took 0.135s
  training loss:		0.039233
  validation loss:		0.295844
  validation accuracy:		93.26 %
Epoch 760 of 2000 took 0.168s
  training loss:		0.039908
  validation loss:		0.282619
  validation accuracy:		93.15 %
Epoch 761 of 2000 took 0.140s
  training loss:		0.039338
  validation loss:		0.280431
  validation accuracy:		93.48 %
Epoch 762 of 2000 took 0.155s
  training loss:		0.038968
  validation loss:		0.286039
  validation accuracy:		93.26 %
Epoch 763 of 2000 took 0.138s
  training loss:		0.037335
  validation loss:		0.277624
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.146s
  training loss:		0.039780
  validation loss:		0.285679
  validation accuracy:		93.04 %
Epoch 765 of 2000 took 0.168s
  training loss:		0.040262
  validation loss:		0.285347
  validation accuracy:		93.37 %
Epoch 766 of 2000 took 0.141s
  training loss:		0.040399
  validation loss:		0.285040
  validation accuracy:		93.26 %
Epoch 767 of 2000 took 0.145s
  training loss:		0.038860
  validation loss:		0.281702
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.137s
  training loss:		0.039923
  validation loss:		0.281960
  validation accuracy:		93.37 %
Epoch 769 of 2000 took 0.143s
  training loss:		0.038574
  validation loss:		0.283143
  validation accuracy:		93.26 %
Epoch 770 of 2000 took 0.143s
  training loss:		0.038018
  validation loss:		0.289858
  validation accuracy:		93.26 %
Epoch 771 of 2000 took 0.144s
  training loss:		0.039242
  validation loss:		0.289572
  validation accuracy:		93.15 %
Epoch 772 of 2000 took 0.150s
  training loss:		0.038819
  validation loss:		0.292104
  validation accuracy:		93.26 %
Epoch 773 of 2000 took 0.174s
  training loss:		0.037850
  validation loss:		0.287431
  validation accuracy:		93.26 %
Epoch 774 of 2000 took 0.145s
  training loss:		0.039410
  validation loss:		0.288953
  validation accuracy:		93.15 %
Epoch 775 of 2000 took 0.146s
  training loss:		0.036712
  validation loss:		0.278198
  validation accuracy:		93.59 %
Epoch 776 of 2000 took 0.143s
  training loss:		0.039254
  validation loss:		0.289375
  validation accuracy:		93.26 %
Epoch 777 of 2000 took 0.156s
  training loss:		0.037757
  validation loss:		0.298279
  validation accuracy:		92.83 %
Epoch 778 of 2000 took 0.145s
  training loss:		0.039080
  validation loss:		0.290850
  validation accuracy:		93.15 %
Epoch 779 of 2000 took 0.172s
  training loss:		0.038707
  validation loss:		0.298010
  validation accuracy:		92.83 %
Epoch 780 of 2000 took 0.155s
  training loss:		0.037992
  validation loss:		0.286080
  validation accuracy:		93.26 %
Epoch 781 of 2000 took 0.147s
  training loss:		0.037881
  validation loss:		0.300390
  validation accuracy:		92.93 %
Epoch 782 of 2000 took 0.144s
  training loss:		0.037533
  validation loss:		0.289866
  validation accuracy:		93.37 %
Epoch 783 of 2000 took 0.144s
  training loss:		0.036538
  validation loss:		0.290303
  validation accuracy:		93.37 %
Epoch 784 of 2000 took 0.145s
  training loss:		0.038277
  validation loss:		0.295780
  validation accuracy:		93.04 %
Epoch 785 of 2000 took 0.146s
  training loss:		0.037834
  validation loss:		0.289445
  validation accuracy:		93.48 %
Epoch 786 of 2000 took 0.146s
  training loss:		0.037343
  validation loss:		0.284706
  validation accuracy:		93.26 %
Epoch 787 of 2000 took 0.141s
  training loss:		0.037183
  validation loss:		0.292711
  validation accuracy:		93.26 %
Epoch 788 of 2000 took 0.144s
  training loss:		0.036559
  validation loss:		0.294469
  validation accuracy:		93.15 %
Epoch 789 of 2000 took 0.144s
  training loss:		0.035561
  validation loss:		0.295742
  validation accuracy:		93.15 %
Epoch 790 of 2000 took 0.143s
  training loss:		0.037215
  validation loss:		0.284035
  validation accuracy:		93.15 %
Epoch 791 of 2000 took 0.143s
  training loss:		0.036718
  validation loss:		0.289196
  validation accuracy:		93.15 %
Epoch 792 of 2000 took 0.170s
  training loss:		0.035602
  validation loss:		0.291921
  validation accuracy:		93.26 %
Epoch 793 of 2000 took 0.161s
  training loss:		0.036719
  validation loss:		0.293068
  validation accuracy:		93.15 %
Epoch 794 of 2000 took 0.150s
  training loss:		0.037099
  validation loss:		0.291883
  validation accuracy:		93.26 %
Epoch 795 of 2000 took 0.156s
  training loss:		0.036799
  validation loss:		0.295808
  validation accuracy:		92.93 %
Epoch 796 of 2000 took 0.166s
  training loss:		0.036028
  validation loss:		0.285536
  validation accuracy:		93.70 %
Epoch 797 of 2000 took 0.164s
  training loss:		0.035927
  validation loss:		0.292440
  validation accuracy:		93.15 %
Epoch 798 of 2000 took 0.140s
  training loss:		0.036262
  validation loss:		0.295355
  validation accuracy:		93.15 %
Epoch 799 of 2000 took 0.152s
  training loss:		0.035249
  validation loss:		0.298297
  validation accuracy:		92.93 %
Epoch 800 of 2000 took 0.150s
  training loss:		0.036151
  validation loss:		0.301016
  validation accuracy:		92.83 %
Epoch 801 of 2000 took 0.189s
  training loss:		0.037149
  validation loss:		0.300931
  validation accuracy:		92.93 %
Epoch 802 of 2000 took 0.174s
  training loss:		0.036187
  validation loss:		0.289262
  validation accuracy:		93.15 %
Epoch 803 of 2000 took 0.158s
  training loss:		0.034749
  validation loss:		0.299289
  validation accuracy:		93.04 %
Epoch 804 of 2000 took 0.149s
  training loss:		0.036378
  validation loss:		0.294782
  validation accuracy:		93.37 %
Epoch 805 of 2000 took 0.182s
  training loss:		0.035390
  validation loss:		0.289826
  validation accuracy:		93.37 %
Epoch 806 of 2000 took 0.141s
  training loss:		0.034991
  validation loss:		0.300821
  validation accuracy:		92.93 %
Epoch 807 of 2000 took 0.142s
  training loss:		0.034539
  validation loss:		0.308344
  validation accuracy:		92.93 %
Epoch 808 of 2000 took 0.146s
  training loss:		0.034519
  validation loss:		0.299521
  validation accuracy:		93.04 %
Epoch 809 of 2000 took 0.143s
  training loss:		0.034463
  validation loss:		0.292812
  validation accuracy:		93.15 %
Epoch 810 of 2000 took 0.145s
  training loss:		0.035040
  validation loss:		0.296238
  validation accuracy:		93.26 %
Epoch 811 of 2000 took 0.145s
  training loss:		0.035536
  validation loss:		0.305141
  validation accuracy:		93.04 %
Epoch 812 of 2000 took 0.146s
  training loss:		0.034859
  validation loss:		0.288618
  validation accuracy:		93.37 %
Epoch 813 of 2000 took 0.151s
  training loss:		0.034592
  validation loss:		0.299129
  validation accuracy:		93.04 %
Epoch 814 of 2000 took 0.149s
  training loss:		0.034476
  validation loss:		0.293715
  validation accuracy:		93.48 %
Epoch 815 of 2000 took 0.149s
  training loss:		0.034082
  validation loss:		0.300631
  validation accuracy:		93.04 %
Epoch 816 of 2000 took 0.152s
  training loss:		0.034853
  validation loss:		0.300454
  validation accuracy:		93.37 %
Epoch 817 of 2000 took 0.156s
  training loss:		0.032926
  validation loss:		0.294786
  validation accuracy:		93.26 %
Epoch 818 of 2000 took 0.158s
  training loss:		0.034453
  validation loss:		0.306193
  validation accuracy:		92.93 %
Epoch 819 of 2000 took 0.159s
  training loss:		0.033965
  validation loss:		0.308817
  validation accuracy:		92.83 %
Epoch 820 of 2000 took 0.168s
  training loss:		0.035137
  validation loss:		0.303653
  validation accuracy:		93.15 %
Epoch 821 of 2000 took 0.143s
  training loss:		0.035457
  validation loss:		0.307424
  validation accuracy:		92.72 %
Epoch 822 of 2000 took 0.148s
  training loss:		0.031899
  validation loss:		0.298911
  validation accuracy:		93.04 %
Epoch 823 of 2000 took 0.145s
  training loss:		0.032883
  validation loss:		0.297780
  validation accuracy:		93.15 %
Epoch 824 of 2000 took 0.144s
  training loss:		0.033636
  validation loss:		0.305044
  validation accuracy:		93.04 %
Epoch 825 of 2000 took 0.145s
  training loss:		0.033642
  validation loss:		0.308042
  validation accuracy:		92.93 %
Epoch 826 of 2000 took 0.142s
  training loss:		0.032963
  validation loss:		0.291970
  validation accuracy:		93.48 %
Epoch 827 of 2000 took 0.149s
  training loss:		0.033837
  validation loss:		0.303727
  validation accuracy:		93.15 %
Epoch 828 of 2000 took 0.163s
  training loss:		0.034170
  validation loss:		0.294430
  validation accuracy:		93.15 %
Epoch 829 of 2000 took 0.152s
  training loss:		0.033109
  validation loss:		0.305902
  validation accuracy:		93.04 %
Epoch 830 of 2000 took 0.143s
  training loss:		0.033218
  validation loss:		0.300330
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.153s
  training loss:		0.033866
  validation loss:		0.301686
  validation accuracy:		93.15 %
Epoch 832 of 2000 took 0.153s
  training loss:		0.033427
  validation loss:		0.297544
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.139s
  training loss:		0.032526
  validation loss:		0.312887
  validation accuracy:		92.83 %
Epoch 834 of 2000 took 0.169s
  training loss:		0.032889
  validation loss:		0.302913
  validation accuracy:		93.37 %
Epoch 835 of 2000 took 0.163s
  training loss:		0.033080
  validation loss:		0.300590
  validation accuracy:		93.26 %
Epoch 836 of 2000 took 0.150s
  training loss:		0.031848
  validation loss:		0.301930
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.159s
  training loss:		0.032489
  validation loss:		0.310809
  validation accuracy:		93.26 %
Epoch 838 of 2000 took 0.146s
  training loss:		0.031781
  validation loss:		0.303183
  validation accuracy:		93.15 %
Epoch 839 of 2000 took 0.153s
  training loss:		0.033239
  validation loss:		0.303272
  validation accuracy:		93.26 %
Epoch 840 of 2000 took 0.144s
  training loss:		0.032329
  validation loss:		0.306186
  validation accuracy:		92.93 %
Epoch 841 of 2000 took 0.146s
  training loss:		0.032427
  validation loss:		0.314835
  validation accuracy:		92.50 %
Epoch 842 of 2000 took 0.141s
  training loss:		0.032590
  validation loss:		0.303678
  validation accuracy:		93.15 %
Epoch 843 of 2000 took 0.149s
  training loss:		0.033059
  validation loss:		0.306126
  validation accuracy:		93.26 %
Epoch 844 of 2000 took 0.144s
  training loss:		0.031558
  validation loss:		0.308763
  validation accuracy:		93.04 %
Epoch 845 of 2000 took 0.172s
  training loss:		0.032456
  validation loss:		0.318189
  validation accuracy:		92.93 %
Epoch 846 of 2000 took 0.134s
  training loss:		0.031300
  validation loss:		0.309506
  validation accuracy:		93.37 %
Epoch 847 of 2000 took 0.149s
  training loss:		0.033352
  validation loss:		0.303548
  validation accuracy:		93.26 %
Epoch 848 of 2000 took 0.147s
  training loss:		0.031782
  validation loss:		0.319257
  validation accuracy:		92.93 %
Epoch 849 of 2000 took 0.147s
  training loss:		0.031280
  validation loss:		0.303018
  validation accuracy:		93.37 %
Epoch 850 of 2000 took 0.144s
  training loss:		0.031127
  validation loss:		0.312520
  validation accuracy:		92.83 %
Epoch 851 of 2000 took 0.142s
  training loss:		0.031789
  validation loss:		0.303874
  validation accuracy:		93.37 %
Epoch 852 of 2000 took 0.140s
  training loss:		0.032643
  validation loss:		0.307242
  validation accuracy:		93.48 %
Epoch 853 of 2000 took 0.141s
  training loss:		0.032482
  validation loss:		0.305902
  validation accuracy:		93.37 %
Epoch 854 of 2000 took 0.165s
  training loss:		0.031767
  validation loss:		0.308100
  validation accuracy:		93.15 %
Epoch 855 of 2000 took 0.154s
  training loss:		0.031232
  validation loss:		0.304151
  validation accuracy:		93.48 %
Epoch 856 of 2000 took 0.148s
  training loss:		0.032343
  validation loss:		0.308438
  validation accuracy:		93.37 %
Epoch 857 of 2000 took 0.142s
  training loss:		0.031698
  validation loss:		0.309308
  validation accuracy:		93.15 %
Epoch 858 of 2000 took 0.139s
  training loss:		0.031201
  validation loss:		0.308032
  validation accuracy:		93.26 %
Epoch 859 of 2000 took 0.144s
  training loss:		0.030380
  validation loss:		0.316798
  validation accuracy:		92.83 %
Epoch 860 of 2000 took 0.143s
  training loss:		0.031042
  validation loss:		0.314708
  validation accuracy:		93.04 %
Epoch 861 of 2000 took 0.161s
  training loss:		0.032177
  validation loss:		0.307145
  validation accuracy:		93.37 %
Epoch 862 of 2000 took 0.148s
  training loss:		0.031522
  validation loss:		0.310542
  validation accuracy:		92.93 %
Epoch 863 of 2000 took 0.148s
  training loss:		0.030258
  validation loss:		0.309950
  validation accuracy:		93.37 %
Epoch 864 of 2000 took 0.138s
  training loss:		0.030186
  validation loss:		0.313649
  validation accuracy:		93.26 %
Epoch 865 of 2000 took 0.145s
  training loss:		0.029706
  validation loss:		0.312263
  validation accuracy:		93.26 %
Epoch 866 of 2000 took 0.145s
  training loss:		0.029707
  validation loss:		0.312850
  validation accuracy:		93.15 %
Epoch 867 of 2000 took 0.147s
  training loss:		0.030465
  validation loss:		0.318292
  validation accuracy:		92.72 %
Epoch 868 of 2000 took 0.135s
  training loss:		0.029525
  validation loss:		0.313491
  validation accuracy:		93.04 %
Epoch 869 of 2000 took 0.139s
  training loss:		0.029059
  validation loss:		0.324894
  validation accuracy:		92.72 %
Epoch 870 of 2000 took 0.147s
  training loss:		0.030075
  validation loss:		0.316494
  validation accuracy:		92.93 %
Epoch 871 of 2000 took 0.145s
  training loss:		0.031074
  validation loss:		0.310229
  validation accuracy:		93.26 %
Epoch 872 of 2000 took 0.147s
  training loss:		0.028780
  validation loss:		0.313017
  validation accuracy:		93.04 %
Epoch 873 of 2000 took 0.147s
  training loss:		0.027928
  validation loss:		0.315339
  validation accuracy:		92.93 %
Epoch 874 of 2000 took 0.159s
  training loss:		0.030704
  validation loss:		0.316051
  validation accuracy:		93.15 %
Epoch 875 of 2000 took 0.139s
  training loss:		0.028903
  validation loss:		0.306823
  validation accuracy:		93.37 %
Epoch 876 of 2000 took 0.182s
  training loss:		0.029620
  validation loss:		0.310761
  validation accuracy:		93.26 %
Epoch 877 of 2000 took 0.153s
  training loss:		0.030424
  validation loss:		0.316810
  validation accuracy:		92.93 %
Epoch 878 of 2000 took 0.141s
  training loss:		0.029348
  validation loss:		0.311193
  validation accuracy:		93.37 %
Epoch 879 of 2000 took 0.142s
  training loss:		0.029910
  validation loss:		0.312315
  validation accuracy:		93.26 %
Epoch 880 of 2000 took 0.140s
  training loss:		0.029370
  validation loss:		0.313564
  validation accuracy:		93.15 %
Epoch 881 of 2000 took 0.146s
  training loss:		0.029006
  validation loss:		0.313927
  validation accuracy:		93.37 %
Epoch 882 of 2000 took 0.145s
  training loss:		0.030307
  validation loss:		0.316151
  validation accuracy:		93.15 %
Epoch 883 of 2000 took 0.147s
  training loss:		0.027776
  validation loss:		0.319954
  validation accuracy:		92.72 %
Epoch 884 of 2000 took 0.158s
  training loss:		0.028933
  validation loss:		0.316192
  validation accuracy:		93.37 %
Epoch 885 of 2000 took 0.145s
  training loss:		0.029289
  validation loss:		0.315145
  validation accuracy:		93.04 %
Epoch 886 of 2000 took 0.146s
  training loss:		0.028809
  validation loss:		0.315874
  validation accuracy:		93.26 %
Epoch 887 of 2000 took 0.142s
  training loss:		0.029092
  validation loss:		0.314377
  validation accuracy:		93.04 %
Epoch 888 of 2000 took 0.145s
  training loss:		0.028937
  validation loss:		0.317080
  validation accuracy:		93.15 %
Epoch 889 of 2000 took 0.144s
  training loss:		0.027700
  validation loss:		0.319239
  validation accuracy:		93.04 %
Epoch 890 of 2000 took 0.147s
  training loss:		0.028878
  validation loss:		0.325298
  validation accuracy:		92.83 %
Epoch 891 of 2000 took 0.143s
  training loss:		0.029315
  validation loss:		0.320168
  validation accuracy:		93.15 %
Epoch 892 of 2000 took 0.148s
  training loss:		0.028734
  validation loss:		0.319517
  validation accuracy:		93.26 %
Epoch 893 of 2000 took 0.137s
  training loss:		0.028556
  validation loss:		0.313813
  validation accuracy:		93.26 %
Epoch 894 of 2000 took 0.144s
  training loss:		0.027974
  validation loss:		0.325221
  validation accuracy:		93.15 %
Epoch 895 of 2000 took 0.143s
  training loss:		0.028528
  validation loss:		0.316820
  validation accuracy:		93.15 %
Epoch 896 of 2000 took 0.141s
  training loss:		0.027209
  validation loss:		0.322479
  validation accuracy:		92.83 %
Epoch 897 of 2000 took 0.146s
  training loss:		0.029611
  validation loss:		0.316711
  validation accuracy:		93.04 %
Epoch 898 of 2000 took 0.162s
  training loss:		0.028096
  validation loss:		0.321982
  validation accuracy:		93.15 %
Epoch 899 of 2000 took 0.195s
  training loss:		0.028624
  validation loss:		0.322947
  validation accuracy:		92.83 %
Epoch 900 of 2000 took 0.174s
  training loss:		0.028233
  validation loss:		0.316982
  validation accuracy:		93.26 %
Epoch 901 of 2000 took 0.154s
  training loss:		0.028349
  validation loss:		0.317404
  validation accuracy:		92.93 %
Epoch 902 of 2000 took 0.138s
  training loss:		0.028036
  validation loss:		0.326349
  validation accuracy:		92.72 %
Epoch 903 of 2000 took 0.145s
  training loss:		0.029081
  validation loss:		0.320724
  validation accuracy:		93.04 %
Epoch 904 of 2000 took 0.169s
  training loss:		0.027448
  validation loss:		0.332076
  validation accuracy:		92.83 %
Epoch 905 of 2000 took 0.163s
  training loss:		0.028205
  validation loss:		0.318772
  validation accuracy:		93.15 %
Epoch 906 of 2000 took 0.147s
  training loss:		0.027073
  validation loss:		0.323850
  validation accuracy:		93.04 %
Epoch 907 of 2000 took 0.146s
  training loss:		0.027256
  validation loss:		0.320883
  validation accuracy:		93.15 %
Epoch 908 of 2000 took 0.146s
  training loss:		0.028096
  validation loss:		0.320524
  validation accuracy:		93.48 %
Epoch 909 of 2000 took 0.148s
  training loss:		0.028147
  validation loss:		0.315917
  validation accuracy:		93.37 %
Epoch 910 of 2000 took 0.144s
  training loss:		0.027764
  validation loss:		0.329459
  validation accuracy:		92.93 %
Epoch 911 of 2000 took 0.144s
  training loss:		0.027419
  validation loss:		0.324423
  validation accuracy:		93.04 %
Epoch 912 of 2000 took 0.145s
  training loss:		0.026828
  validation loss:		0.321706
  validation accuracy:		93.15 %
Epoch 913 of 2000 took 0.148s
  training loss:		0.026983
  validation loss:		0.323070
  validation accuracy:		93.26 %
Epoch 914 of 2000 took 0.154s
  training loss:		0.029172
  validation loss:		0.322244
  validation accuracy:		93.15 %
Epoch 915 of 2000 took 0.142s
  training loss:		0.027068
  validation loss:		0.322848
  validation accuracy:		93.15 %
Epoch 916 of 2000 took 0.143s
  training loss:		0.026823
  validation loss:		0.323614
  validation accuracy:		93.15 %
Epoch 917 of 2000 took 0.142s
  training loss:		0.026691
  validation loss:		0.331117
  validation accuracy:		92.83 %
Epoch 918 of 2000 took 0.139s
  training loss:		0.024918
  validation loss:		0.325624
  validation accuracy:		92.83 %
Epoch 919 of 2000 took 0.144s
  training loss:		0.026492
  validation loss:		0.327282
  validation accuracy:		93.15 %
Epoch 920 of 2000 took 0.145s
  training loss:		0.026716
  validation loss:		0.323920
  validation accuracy:		93.04 %
Epoch 921 of 2000 took 0.211s
  training loss:		0.025304
  validation loss:		0.326732
  validation accuracy:		93.15 %
Epoch 922 of 2000 took 0.186s
  training loss:		0.026780
  validation loss:		0.328649
  validation accuracy:		93.26 %
Epoch 923 of 2000 took 0.178s
  training loss:		0.027053
  validation loss:		0.331848
  validation accuracy:		92.83 %
Epoch 924 of 2000 took 0.190s
  training loss:		0.027044
  validation loss:		0.329941
  validation accuracy:		92.83 %
Epoch 925 of 2000 took 0.190s
  training loss:		0.026696
  validation loss:		0.325767
  validation accuracy:		92.93 %
Epoch 926 of 2000 took 0.190s
  training loss:		0.026067
  validation loss:		0.332928
  validation accuracy:		92.83 %
Epoch 927 of 2000 took 0.168s
  training loss:		0.026274
  validation loss:		0.332080
  validation accuracy:		92.61 %
Epoch 928 of 2000 took 0.176s
  training loss:		0.026054
  validation loss:		0.326661
  validation accuracy:		92.93 %
Epoch 929 of 2000 took 0.159s
  training loss:		0.024998
  validation loss:		0.326938
  validation accuracy:		93.37 %
Epoch 930 of 2000 took 0.151s
  training loss:		0.025955
  validation loss:		0.329519
  validation accuracy:		92.93 %
Epoch 931 of 2000 took 0.188s
  training loss:		0.026061
  validation loss:		0.332050
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.189s
  training loss:		0.026155
  validation loss:		0.329155
  validation accuracy:		92.83 %
Epoch 933 of 2000 took 0.189s
  training loss:		0.027090
  validation loss:		0.339556
  validation accuracy:		93.04 %
Epoch 934 of 2000 took 0.188s
  training loss:		0.027035
  validation loss:		0.333368
  validation accuracy:		92.83 %
Epoch 935 of 2000 took 0.163s
  training loss:		0.026413
  validation loss:		0.335637
  validation accuracy:		92.83 %
Epoch 936 of 2000 took 0.148s
  training loss:		0.026136
  validation loss:		0.331977
  validation accuracy:		92.93 %
Epoch 937 of 2000 took 0.188s
  training loss:		0.025898
  validation loss:		0.339351
  validation accuracy:		92.72 %
Epoch 938 of 2000 took 0.191s
  training loss:		0.025688
  validation loss:		0.340285
  validation accuracy:		92.93 %
Epoch 939 of 2000 took 0.188s
  training loss:		0.025999
  validation loss:		0.326273
  validation accuracy:		93.15 %
Epoch 940 of 2000 took 0.190s
  training loss:		0.025441
  validation loss:		0.328988
  validation accuracy:		93.04 %
Epoch 941 of 2000 took 0.179s
  training loss:		0.023792
  validation loss:		0.338355
  validation accuracy:		92.72 %
Epoch 942 of 2000 took 0.189s
  training loss:		0.025786
  validation loss:		0.333926
  validation accuracy:		92.72 %
Epoch 943 of 2000 took 0.193s
  training loss:		0.025301
  validation loss:		0.326750
  validation accuracy:		93.15 %
Epoch 944 of 2000 took 0.186s
  training loss:		0.025844
  validation loss:		0.333729
  validation accuracy:		92.83 %
Epoch 945 of 2000 took 0.205s
  training loss:		0.023796
  validation loss:		0.334620
  validation accuracy:		92.72 %
Epoch 946 of 2000 took 0.158s
  training loss:		0.024876
  validation loss:		0.331793
  validation accuracy:		93.15 %
Epoch 947 of 2000 took 0.156s
  training loss:		0.024339
  validation loss:		0.335034
  validation accuracy:		92.93 %
Epoch 948 of 2000 took 0.144s
  training loss:		0.025163
  validation loss:		0.334964
  validation accuracy:		92.72 %
Epoch 949 of 2000 took 0.153s
  training loss:		0.025132
  validation loss:		0.334853
  validation accuracy:		93.04 %
Epoch 950 of 2000 took 0.164s
  training loss:		0.024497
  validation loss:		0.338069
  validation accuracy:		93.04 %
Epoch 951 of 2000 took 0.143s
  training loss:		0.024458
  validation loss:		0.343047
  validation accuracy:		92.39 %
Epoch 952 of 2000 took 0.141s
  training loss:		0.023792
  validation loss:		0.335845
  validation accuracy:		93.04 %
Epoch 953 of 2000 took 0.140s
  training loss:		0.022170
  validation loss:		0.330521
  validation accuracy:		92.93 %
Epoch 954 of 2000 took 0.162s
  training loss:		0.024092
  validation loss:		0.333504
  validation accuracy:		93.04 %
Epoch 955 of 2000 took 0.161s
  training loss:		0.024688
  validation loss:		0.333971
  validation accuracy:		93.04 %
Epoch 956 of 2000 took 0.142s
  training loss:		0.025148
  validation loss:		0.327336
  validation accuracy:		93.26 %
Epoch 957 of 2000 took 0.147s
  training loss:		0.024104
  validation loss:		0.334870
  validation accuracy:		93.04 %
Epoch 958 of 2000 took 0.156s
  training loss:		0.023842
  validation loss:		0.338994
  validation accuracy:		93.15 %
Epoch 959 of 2000 took 0.140s
  training loss:		0.024119
  validation loss:		0.327268
  validation accuracy:		93.04 %
Epoch 960 of 2000 took 0.142s
  training loss:		0.024733
  validation loss:		0.331531
  validation accuracy:		93.15 %
Epoch 961 of 2000 took 0.147s
  training loss:		0.023351
  validation loss:		0.346381
  validation accuracy:		92.83 %
Epoch 962 of 2000 took 0.145s
  training loss:		0.024472
  validation loss:		0.337950
  validation accuracy:		92.93 %
Epoch 963 of 2000 took 0.172s
  training loss:		0.024301
  validation loss:		0.341969
  validation accuracy:		92.93 %
Epoch 964 of 2000 took 0.144s
  training loss:		0.024475
  validation loss:		0.339481
  validation accuracy:		92.83 %
Epoch 965 of 2000 took 0.145s
  training loss:		0.023967
  validation loss:		0.341112
  validation accuracy:		92.72 %
Epoch 966 of 2000 took 0.140s
  training loss:		0.024831
  validation loss:		0.342868
  validation accuracy:		92.93 %
Epoch 967 of 2000 took 0.148s
  training loss:		0.023160
  validation loss:		0.338946
  validation accuracy:		92.72 %
Epoch 968 of 2000 took 0.157s
  training loss:		0.022927
  validation loss:		0.337499
  validation accuracy:		92.72 %
Epoch 969 of 2000 took 0.152s
  training loss:		0.023828
  validation loss:		0.341390
  validation accuracy:		92.83 %
Epoch 970 of 2000 took 0.185s
  training loss:		0.023208
  validation loss:		0.341638
  validation accuracy:		92.83 %
Epoch 971 of 2000 took 0.153s
  training loss:		0.023453
  validation loss:		0.345417
  validation accuracy:		92.61 %
Epoch 972 of 2000 took 0.140s
  training loss:		0.022945
  validation loss:		0.337354
  validation accuracy:		93.26 %
Epoch 973 of 2000 took 0.147s
  training loss:		0.022915
  validation loss:		0.338838
  validation accuracy:		93.04 %
Epoch 974 of 2000 took 0.143s
  training loss:		0.023589
  validation loss:		0.337669
  validation accuracy:		92.93 %
Epoch 975 of 2000 took 0.149s
  training loss:		0.022262
  validation loss:		0.340128
  validation accuracy:		93.04 %
Epoch 976 of 2000 took 0.141s
  training loss:		0.021784
  validation loss:		0.347716
  validation accuracy:		92.83 %
Epoch 977 of 2000 took 0.145s
  training loss:		0.022959
  validation loss:		0.337061
  validation accuracy:		93.15 %
Epoch 978 of 2000 took 0.144s
  training loss:		0.022821
  validation loss:		0.340753
  validation accuracy:		93.15 %
Epoch 979 of 2000 took 0.144s
  training loss:		0.023430
  validation loss:		0.347071
  validation accuracy:		92.83 %
Epoch 980 of 2000 took 0.144s
  training loss:		0.023311
  validation loss:		0.342882
  validation accuracy:		92.72 %
Epoch 981 of 2000 took 0.143s
  training loss:		0.022908
  validation loss:		0.346687
  validation accuracy:		92.83 %
Epoch 982 of 2000 took 0.145s
  training loss:		0.022933
  validation loss:		0.338747
  validation accuracy:		93.26 %
Epoch 983 of 2000 took 0.138s
  training loss:		0.023163
  validation loss:		0.343430
  validation accuracy:		93.26 %
Epoch 984 of 2000 took 0.146s
  training loss:		0.023157
  validation loss:		0.346468
  validation accuracy:		92.72 %
Epoch 985 of 2000 took 0.144s
  training loss:		0.022794
  validation loss:		0.343068
  validation accuracy:		92.93 %
Epoch 986 of 2000 took 0.147s
  training loss:		0.022276
  validation loss:		0.340786
  validation accuracy:		93.04 %
Epoch 987 of 2000 took 0.144s
  training loss:		0.022615
  validation loss:		0.346580
  validation accuracy:		92.83 %
Epoch 988 of 2000 took 0.143s
  training loss:		0.023110
  validation loss:		0.348206
  validation accuracy:		92.93 %
Epoch 989 of 2000 took 0.139s
  training loss:		0.021292
  validation loss:		0.343393
  validation accuracy:		92.93 %
Epoch 990 of 2000 took 0.144s
  training loss:		0.023029
  validation loss:		0.339026
  validation accuracy:		93.15 %
Epoch 991 of 2000 took 0.139s
  training loss:		0.022212
  validation loss:		0.346815
  validation accuracy:		92.83 %
Epoch 992 of 2000 took 0.134s
  training loss:		0.022500
  validation loss:		0.346532
  validation accuracy:		92.93 %
Epoch 993 of 2000 took 0.156s
  training loss:		0.022190
  validation loss:		0.350198
  validation accuracy:		92.93 %
Epoch 994 of 2000 took 0.160s
  training loss:		0.022399
  validation loss:		0.345384
  validation accuracy:		92.93 %
Epoch 995 of 2000 took 0.159s
  training loss:		0.021656
  validation loss:		0.350720
  validation accuracy:		92.93 %
Epoch 996 of 2000 took 0.145s
  training loss:		0.022252
  validation loss:		0.352399
  validation accuracy:		92.72 %
Epoch 997 of 2000 took 0.141s
  training loss:		0.022428
  validation loss:		0.348324
  validation accuracy:		92.93 %
Epoch 998 of 2000 took 0.149s
  training loss:		0.022821
  validation loss:		0.347555
  validation accuracy:		92.93 %
Epoch 999 of 2000 took 0.155s
  training loss:		0.020839
  validation loss:		0.346395
  validation accuracy:		92.83 %
Epoch 1000 of 2000 took 0.139s
  training loss:		0.021892
  validation loss:		0.350715
  validation accuracy:		92.83 %
Epoch 1001 of 2000 took 0.140s
  training loss:		0.020786
  validation loss:		0.345974
  validation accuracy:		92.93 %
Epoch 1002 of 2000 took 0.139s
  training loss:		0.022059
  validation loss:		0.348051
  validation accuracy:		92.93 %
Epoch 1003 of 2000 took 0.145s
  training loss:		0.021971
  validation loss:		0.357177
  validation accuracy:		92.72 %
Epoch 1004 of 2000 took 0.146s
  training loss:		0.019983
  validation loss:		0.352493
  validation accuracy:		92.83 %
Epoch 1005 of 2000 took 0.144s
  training loss:		0.022045
  validation loss:		0.349960
  validation accuracy:		93.04 %
Epoch 1006 of 2000 took 0.149s
  training loss:		0.021423
  validation loss:		0.354460
  validation accuracy:		92.83 %
Epoch 1007 of 2000 took 0.145s
  training loss:		0.022063
  validation loss:		0.349988
  validation accuracy:		93.04 %
Epoch 1008 of 2000 took 0.148s
  training loss:		0.021939
  validation loss:		0.343408
  validation accuracy:		93.37 %
Epoch 1009 of 2000 took 0.144s
  training loss:		0.021426
  validation loss:		0.340933
  validation accuracy:		93.26 %
Epoch 1010 of 2000 took 0.159s
  training loss:		0.021758
  validation loss:		0.346868
  validation accuracy:		93.04 %
Epoch 1011 of 2000 took 0.146s
  training loss:		0.020915
  validation loss:		0.347523
  validation accuracy:		92.93 %
Epoch 1012 of 2000 took 0.139s
  training loss:		0.020312
  validation loss:		0.357186
  validation accuracy:		92.83 %
Epoch 1013 of 2000 took 0.145s
  training loss:		0.021528
  validation loss:		0.352284
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.142s
  training loss:		0.020600
  validation loss:		0.347170
  validation accuracy:		93.04 %
Epoch 1015 of 2000 took 0.142s
  training loss:		0.020647
  validation loss:		0.356076
  validation accuracy:		92.83 %
Epoch 1016 of 2000 took 0.146s
  training loss:		0.021769
  validation loss:		0.351814
  validation accuracy:		92.93 %
Epoch 1017 of 2000 took 0.147s
  training loss:		0.020610
  validation loss:		0.347744
  validation accuracy:		92.83 %
Epoch 1018 of 2000 took 0.147s
  training loss:		0.020844
  validation loss:		0.347474
  validation accuracy:		93.26 %
Epoch 1019 of 2000 took 0.139s
  training loss:		0.020892
  validation loss:		0.354530
  validation accuracy:		92.83 %
Epoch 1020 of 2000 took 0.143s
  training loss:		0.019983
  validation loss:		0.347200
  validation accuracy:		93.04 %
Epoch 1021 of 2000 took 0.144s
  training loss:		0.021474
  validation loss:		0.348807
  validation accuracy:		93.04 %
Epoch 1022 of 2000 took 0.153s
  training loss:		0.021300
  validation loss:		0.349430
  validation accuracy:		93.15 %
Epoch 1023 of 2000 took 0.155s
  training loss:		0.021572
  validation loss:		0.357606
  validation accuracy:		92.72 %
Epoch 1024 of 2000 took 0.179s
  training loss:		0.021193
  validation loss:		0.353654
  validation accuracy:		92.72 %
Epoch 1025 of 2000 took 0.186s
  training loss:		0.021043
  validation loss:		0.356563
  validation accuracy:		92.61 %
Epoch 1026 of 2000 took 0.169s
  training loss:		0.020434
  validation loss:		0.354316
  validation accuracy:		92.93 %
Epoch 1027 of 2000 took 0.144s
  training loss:		0.020760
  validation loss:		0.362288
  validation accuracy:		92.72 %
Epoch 1028 of 2000 took 0.143s
  training loss:		0.021667
  validation loss:		0.358423
  validation accuracy:		92.93 %
Epoch 1029 of 2000 took 0.143s
  training loss:		0.020798
  validation loss:		0.350794
  validation accuracy:		92.93 %
Epoch 1030 of 2000 took 0.160s
  training loss:		0.020570
  validation loss:		0.358585
  validation accuracy:		92.83 %
Epoch 1031 of 2000 took 0.147s
  training loss:		0.021354
  validation loss:		0.361076
  validation accuracy:		93.04 %
Epoch 1032 of 2000 took 0.188s
  training loss:		0.021175
  validation loss:		0.365583
  validation accuracy:		92.72 %
Epoch 1033 of 2000 took 0.167s
  training loss:		0.020762
  validation loss:		0.352272
  validation accuracy:		92.93 %
Epoch 1034 of 2000 took 0.154s
  training loss:		0.020374
  validation loss:		0.361438
  validation accuracy:		92.72 %
Epoch 1035 of 2000 took 0.157s
  training loss:		0.019960
  validation loss:		0.361329
  validation accuracy:		92.83 %
Epoch 1036 of 2000 took 0.161s
  training loss:		0.020204
  validation loss:		0.350879
  validation accuracy:		93.15 %
Epoch 1037 of 2000 took 0.151s
  training loss:		0.019792
  validation loss:		0.359101
  validation accuracy:		92.61 %
Epoch 1038 of 2000 took 0.161s
  training loss:		0.019019
  validation loss:		0.353873
  validation accuracy:		93.04 %
Epoch 1039 of 2000 took 0.160s
  training loss:		0.020260
  validation loss:		0.358655
  validation accuracy:		92.72 %
Epoch 1040 of 2000 took 0.168s
  training loss:		0.020856
  validation loss:		0.368722
  validation accuracy:		92.50 %
Epoch 1041 of 2000 took 0.157s
  training loss:		0.019262
  validation loss:		0.362267
  validation accuracy:		92.83 %
Epoch 1042 of 2000 took 0.150s
  training loss:		0.020055
  validation loss:		0.360587
  validation accuracy:		92.72 %
Epoch 1043 of 2000 took 0.142s
  training loss:		0.019476
  validation loss:		0.360325
  validation accuracy:		92.83 %
Epoch 1044 of 2000 took 0.180s
  training loss:		0.019949
  validation loss:		0.356803
  validation accuracy:		92.83 %
Epoch 1045 of 2000 took 0.138s
  training loss:		0.019482
  validation loss:		0.362406
  validation accuracy:		92.61 %
Epoch 1046 of 2000 took 0.163s
  training loss:		0.020510
  validation loss:		0.356973
  validation accuracy:		93.04 %
Epoch 1047 of 2000 took 0.174s
  training loss:		0.019867
  validation loss:		0.352154
  validation accuracy:		93.15 %
Epoch 1048 of 2000 took 0.156s
  training loss:		0.018747
  validation loss:		0.365851
  validation accuracy:		92.83 %
Epoch 1049 of 2000 took 0.157s
  training loss:		0.019868
  validation loss:		0.363698
  validation accuracy:		92.72 %
Epoch 1050 of 2000 took 0.164s
  training loss:		0.019352
  validation loss:		0.360619
  validation accuracy:		92.83 %
Epoch 1051 of 2000 took 0.166s
  training loss:		0.019837
  validation loss:		0.359720
  validation accuracy:		92.93 %
Epoch 1052 of 2000 took 0.190s
  training loss:		0.019360
  validation loss:		0.363118
  validation accuracy:		92.83 %
Epoch 1053 of 2000 took 0.145s
  training loss:		0.019536
  validation loss:		0.368964
  validation accuracy:		92.72 %
Epoch 1054 of 2000 took 0.149s
  training loss:		0.019497
  validation loss:		0.366571
  validation accuracy:		92.72 %
Epoch 1055 of 2000 took 0.140s
  training loss:		0.018959
  validation loss:		0.354910
  validation accuracy:		92.93 %
Epoch 1056 of 2000 took 0.163s
  training loss:		0.019181
  validation loss:		0.361472
  validation accuracy:		92.83 %
Epoch 1057 of 2000 took 0.180s
  training loss:		0.018901
  validation loss:		0.361635
  validation accuracy:		92.72 %
Epoch 1058 of 2000 took 0.146s
  training loss:		0.019071
  validation loss:		0.362778
  validation accuracy:		92.72 %
Epoch 1059 of 2000 took 0.144s
  training loss:		0.018027
  validation loss:		0.359030
  validation accuracy:		93.04 %
Epoch 1060 of 2000 took 0.169s
  training loss:		0.018791
  validation loss:		0.364313
  validation accuracy:		92.72 %
Epoch 1061 of 2000 took 0.150s
  training loss:		0.018893
  validation loss:		0.363606
  validation accuracy:		92.83 %
Epoch 1062 of 2000 took 0.145s
  training loss:		0.018667
  validation loss:		0.365064
  validation accuracy:		92.72 %
Epoch 1063 of 2000 took 0.168s
  training loss:		0.019410
  validation loss:		0.362095
  validation accuracy:		92.93 %
Epoch 1064 of 2000 took 0.149s
  training loss:		0.018144
  validation loss:		0.375634
  validation accuracy:		92.72 %
Epoch 1065 of 2000 took 0.151s
  training loss:		0.019252
  validation loss:		0.367181
  validation accuracy:		92.61 %
Epoch 1066 of 2000 took 0.164s
  training loss:		0.019129
  validation loss:		0.364526
  validation accuracy:		92.72 %
Epoch 1067 of 2000 took 0.146s
  training loss:		0.019569
  validation loss:		0.371232
  validation accuracy:		92.72 %
Epoch 1068 of 2000 took 0.140s
  training loss:		0.019472
  validation loss:		0.367919
  validation accuracy:		92.72 %
Epoch 1069 of 2000 took 0.147s
  training loss:		0.018215
  validation loss:		0.360260
  validation accuracy:		92.93 %
Epoch 1070 of 2000 took 0.144s
  training loss:		0.018646
  validation loss:		0.362963
  validation accuracy:		92.93 %
Epoch 1071 of 2000 took 0.151s
  training loss:		0.018398
  validation loss:		0.364636
  validation accuracy:		92.83 %
Epoch 1072 of 2000 took 0.145s
  training loss:		0.018437
  validation loss:		0.359911
  validation accuracy:		93.04 %
Epoch 1073 of 2000 took 0.149s
  training loss:		0.018575
  validation loss:		0.365253
  validation accuracy:		92.93 %
Epoch 1074 of 2000 took 0.171s
  training loss:		0.018676
  validation loss:		0.365360
  validation accuracy:		93.04 %
Epoch 1075 of 2000 took 0.154s
  training loss:		0.018402
  validation loss:		0.369000
  validation accuracy:		92.72 %
Epoch 1076 of 2000 took 0.179s
  training loss:		0.018205
  validation loss:		0.361045
  validation accuracy:		93.04 %
Epoch 1077 of 2000 took 0.159s
  training loss:		0.017597
  validation loss:		0.368725
  validation accuracy:		92.72 %
Epoch 1078 of 2000 took 0.144s
  training loss:		0.018613
  validation loss:		0.369876
  validation accuracy:		92.83 %
Epoch 1079 of 2000 took 0.161s
  training loss:		0.018070
  validation loss:		0.369667
  validation accuracy:		92.72 %
Epoch 1080 of 2000 took 0.173s
  training loss:		0.018000
  validation loss:		0.373360
  validation accuracy:		92.83 %
Epoch 1081 of 2000 took 0.166s
  training loss:		0.018382
  validation loss:		0.373104
  validation accuracy:		92.72 %
Epoch 1082 of 2000 took 0.170s
  training loss:		0.018697
  validation loss:		0.370729
  validation accuracy:		92.72 %
Epoch 1083 of 2000 took 0.183s
  training loss:		0.018324
  validation loss:		0.372737
  validation accuracy:		92.72 %
Epoch 1084 of 2000 took 0.182s
  training loss:		0.018233
  validation loss:		0.366911
  validation accuracy:		92.93 %
Epoch 1085 of 2000 took 0.183s
  training loss:		0.017497
  validation loss:		0.370150
  validation accuracy:		92.83 %
Epoch 1086 of 2000 took 0.182s
  training loss:		0.016782
  validation loss:		0.378733
  validation accuracy:		92.50 %
Epoch 1087 of 2000 took 0.183s
  training loss:		0.016503
  validation loss:		0.366997
  validation accuracy:		92.93 %
Epoch 1088 of 2000 took 0.156s
  training loss:		0.018529
  validation loss:		0.383747
  validation accuracy:		92.28 %
Epoch 1089 of 2000 took 0.151s
  training loss:		0.017869
  validation loss:		0.365627
  validation accuracy:		93.04 %
Epoch 1090 of 2000 took 0.181s
  training loss:		0.017331
  validation loss:		0.368508
  validation accuracy:		93.04 %
Epoch 1091 of 2000 took 0.168s
  training loss:		0.017625
  validation loss:		0.367744
  validation accuracy:		92.93 %
Epoch 1092 of 2000 took 0.174s
  training loss:		0.018397
  validation loss:		0.365166
  validation accuracy:		93.26 %
Epoch 1093 of 2000 took 0.175s
  training loss:		0.017730
  validation loss:		0.366337
  validation accuracy:		92.93 %
Epoch 1094 of 2000 took 0.179s
  training loss:		0.017464
  validation loss:		0.365250
  validation accuracy:		92.93 %
Epoch 1095 of 2000 took 0.182s
  training loss:		0.017879
  validation loss:		0.370865
  validation accuracy:		92.83 %
Epoch 1096 of 2000 took 0.182s
  training loss:		0.017323
  validation loss:		0.369964
  validation accuracy:		92.93 %
Epoch 1097 of 2000 took 0.180s
  training loss:		0.017637
  validation loss:		0.372991
  validation accuracy:		92.83 %
Epoch 1098 of 2000 took 0.179s
  training loss:		0.016336
  validation loss:		0.374726
  validation accuracy:		92.83 %
Epoch 1099 of 2000 took 0.180s
  training loss:		0.017506
  validation loss:		0.367391
  validation accuracy:		93.15 %
Epoch 1100 of 2000 took 0.183s
  training loss:		0.017361
  validation loss:		0.375979
  validation accuracy:		92.72 %
Epoch 1101 of 2000 took 0.179s
  training loss:		0.017353
  validation loss:		0.374281
  validation accuracy:		92.72 %
Epoch 1102 of 2000 took 0.144s
  training loss:		0.017207
  validation loss:		0.371952
  validation accuracy:		92.93 %
Epoch 1103 of 2000 took 0.159s
  training loss:		0.017863
  validation loss:		0.374777
  validation accuracy:		92.83 %
Epoch 1104 of 2000 took 0.137s
  training loss:		0.017817
  validation loss:		0.374413
  validation accuracy:		92.83 %
Epoch 1105 of 2000 took 0.180s
  training loss:		0.016871
  validation loss:		0.374253
  validation accuracy:		92.83 %
Epoch 1106 of 2000 took 0.165s
  training loss:		0.017621
  validation loss:		0.378439
  validation accuracy:		92.72 %
Epoch 1107 of 2000 took 0.159s
  training loss:		0.017286
  validation loss:		0.371302
  validation accuracy:		92.93 %
Epoch 1108 of 2000 took 0.173s
  training loss:		0.017016
  validation loss:		0.374003
  validation accuracy:		92.72 %
Epoch 1109 of 2000 took 0.180s
  training loss:		0.017232
  validation loss:		0.380763
  validation accuracy:		92.72 %
Epoch 1110 of 2000 took 0.161s
  training loss:		0.017329
  validation loss:		0.375372
  validation accuracy:		92.72 %
Epoch 1111 of 2000 took 0.162s
  training loss:		0.016230
  validation loss:		0.367934
  validation accuracy:		93.04 %
Epoch 1112 of 2000 took 0.145s
  training loss:		0.016787
  validation loss:		0.378390
  validation accuracy:		92.83 %
Epoch 1113 of 2000 took 0.168s
  training loss:		0.017318
  validation loss:		0.378663
  validation accuracy:		92.83 %
Epoch 1114 of 2000 took 0.135s
  training loss:		0.016753
  validation loss:		0.379684
  validation accuracy:		92.83 %
Epoch 1115 of 2000 took 0.140s
  training loss:		0.016893
  validation loss:		0.378548
  validation accuracy:		92.72 %
Epoch 1116 of 2000 took 0.169s
  training loss:		0.016992
  validation loss:		0.373474
  validation accuracy:		92.83 %
Epoch 1117 of 2000 took 0.146s
  training loss:		0.016837
  validation loss:		0.374753
  validation accuracy:		92.72 %
Epoch 1118 of 2000 took 0.141s
  training loss:		0.017088
  validation loss:		0.372884
  validation accuracy:		93.04 %
Epoch 1119 of 2000 took 0.148s
  training loss:		0.016543
  validation loss:		0.382585
  validation accuracy:		92.61 %
Epoch 1120 of 2000 took 0.144s
  training loss:		0.016362
  validation loss:		0.376703
  validation accuracy:		92.61 %
Epoch 1121 of 2000 took 0.145s
  training loss:		0.016960
  validation loss:		0.379011
  validation accuracy:		92.72 %
Epoch 1122 of 2000 took 0.151s
  training loss:		0.016558
  validation loss:		0.374868
  validation accuracy:		92.83 %
Epoch 1123 of 2000 took 0.137s
  training loss:		0.016120
  validation loss:		0.375979
  validation accuracy:		92.93 %
Epoch 1124 of 2000 took 0.133s
  training loss:		0.017071
  validation loss:		0.377169
  validation accuracy:		92.83 %
Epoch 1125 of 2000 took 0.139s
  training loss:		0.016247
  validation loss:		0.378108
  validation accuracy:		92.93 %
Epoch 1126 of 2000 took 0.163s
  training loss:		0.016924
  validation loss:		0.374049
  validation accuracy:		93.04 %
Epoch 1127 of 2000 took 0.101s
  training loss:		0.016060
  validation loss:		0.374626
  validation accuracy:		92.93 %
Epoch 1128 of 2000 took 0.133s
  training loss:		0.016806
  validation loss:		0.380627
  validation accuracy:		92.72 %
Epoch 1129 of 2000 took 0.157s
  training loss:		0.016186
  validation loss:		0.374734
  validation accuracy:		92.93 %
Epoch 1130 of 2000 took 0.169s
  training loss:		0.016377
  validation loss:		0.377662
  validation accuracy:		92.72 %
Epoch 1131 of 2000 took 0.137s
  training loss:		0.015720
  validation loss:		0.378331
  validation accuracy:		92.93 %
Epoch 1132 of 2000 took 0.112s
  training loss:		0.016053
  validation loss:		0.374979
  validation accuracy:		92.93 %
Epoch 1133 of 2000 took 0.123s
  training loss:		0.016766
  validation loss:		0.384073
  validation accuracy:		92.93 %
Epoch 1134 of 2000 took 0.158s
  training loss:		0.016741
  validation loss:		0.378481
  validation accuracy:		92.83 %
Epoch 1135 of 2000 took 0.127s
  training loss:		0.015878
  validation loss:		0.384477
  validation accuracy:		92.61 %
Epoch 1136 of 2000 took 0.150s
  training loss:		0.016366
  validation loss:		0.390236
  validation accuracy:		92.61 %
Epoch 1137 of 2000 took 0.127s
  training loss:		0.016433
  validation loss:		0.385356
  validation accuracy:		92.61 %
Epoch 1138 of 2000 took 0.127s
  training loss:		0.015681
  validation loss:		0.380728
  validation accuracy:		92.83 %
Epoch 1139 of 2000 took 0.119s
  training loss:		0.016072
  validation loss:		0.379558
  validation accuracy:		92.83 %
Epoch 1140 of 2000 took 0.125s
  training loss:		0.016321
  validation loss:		0.381835
  validation accuracy:		92.72 %
Epoch 1141 of 2000 took 0.128s
  training loss:		0.016180
  validation loss:		0.383449
  validation accuracy:		92.83 %
Epoch 1142 of 2000 took 0.120s
  training loss:		0.015845
  validation loss:		0.382703
  validation accuracy:		92.83 %
Epoch 1143 of 2000 took 0.132s
  training loss:		0.014310
  validation loss:		0.383872
  validation accuracy:		92.39 %
Epoch 1144 of 2000 took 0.116s
  training loss:		0.016052
  validation loss:		0.386297
  validation accuracy:		92.72 %
Epoch 1145 of 2000 took 0.099s
  training loss:		0.015450
  validation loss:		0.385747
  validation accuracy:		92.72 %
Epoch 1146 of 2000 took 0.118s
  training loss:		0.016505
  validation loss:		0.386153
  validation accuracy:		92.50 %
Epoch 1147 of 2000 took 0.115s
  training loss:		0.015844
  validation loss:		0.380406
  validation accuracy:		92.83 %
Epoch 1148 of 2000 took 0.100s
  training loss:		0.015942
  validation loss:		0.384274
  validation accuracy:		92.72 %
Epoch 1149 of 2000 took 0.120s
  training loss:		0.015923
  validation loss:		0.382046
  validation accuracy:		92.93 %
Epoch 1150 of 2000 took 0.118s
  training loss:		0.015578
  validation loss:		0.387863
  validation accuracy:		92.72 %
Epoch 1151 of 2000 took 0.114s
  training loss:		0.016124
  validation loss:		0.385343
  validation accuracy:		92.72 %
Epoch 1152 of 2000 took 0.204s
  training loss:		0.014744
  validation loss:		0.389890
  validation accuracy:		92.72 %
Epoch 1153 of 2000 took 0.182s
  training loss:		0.015480
  validation loss:		0.390769
  validation accuracy:		92.50 %
Epoch 1154 of 2000 took 0.132s
  training loss:		0.015166
  validation loss:		0.387293
  validation accuracy:		92.93 %
Epoch 1155 of 2000 took 0.134s
  training loss:		0.015717
  validation loss:		0.390663
  validation accuracy:		92.50 %
Epoch 1156 of 2000 took 0.127s
  training loss:		0.015392
  validation loss:		0.382954
  validation accuracy:		92.83 %
Epoch 1157 of 2000 took 0.106s
  training loss:		0.015820
  validation loss:		0.381523
  validation accuracy:		93.04 %
Epoch 1158 of 2000 took 0.108s
  training loss:		0.015465
  validation loss:		0.393535
  validation accuracy:		92.61 %
Epoch 1159 of 2000 took 0.124s
  training loss:		0.015041
  validation loss:		0.391679
  validation accuracy:		92.61 %
Epoch 1160 of 2000 took 0.098s
  training loss:		0.015607
  validation loss:		0.389323
  validation accuracy:		92.72 %
Epoch 1161 of 2000 took 0.050s
  training loss:		0.014921
  validation loss:		0.386868
  validation accuracy:		92.61 %
Epoch 1162 of 2000 took 0.050s
  training loss:		0.015452
  validation loss:		0.388785
  validation accuracy:		92.61 %
Epoch 1163 of 2000 took 0.068s
  training loss:		0.014634
  validation loss:		0.392690
  validation accuracy:		92.50 %
Epoch 1164 of 2000 took 0.169s
  training loss:		0.015174
  validation loss:		0.382822
  validation accuracy:		93.04 %
Epoch 1165 of 2000 took 0.051s
  training loss:		0.015350
  validation loss:		0.384681
  validation accuracy:		92.83 %
Epoch 1166 of 2000 took 0.051s
  training loss:		0.014270
  validation loss:		0.388951
  validation accuracy:		92.72 %
Epoch 1167 of 2000 took 0.076s
  training loss:		0.015315
  validation loss:		0.392229
  validation accuracy:		92.61 %
Epoch 1168 of 2000 took 0.102s
  training loss:		0.014809
  validation loss:		0.383711
  validation accuracy:		92.93 %
Epoch 1169 of 2000 took 0.112s
  training loss:		0.015127
  validation loss:		0.384182
  validation accuracy:		92.93 %
Epoch 1170 of 2000 took 0.077s
  training loss:		0.015327
  validation loss:		0.389547
  validation accuracy:		92.72 %
Epoch 1171 of 2000 took 0.095s
  training loss:		0.015460
  validation loss:		0.385249
  validation accuracy:		92.93 %
Epoch 1172 of 2000 took 0.062s
  training loss:		0.014803
  validation loss:		0.390795
  validation accuracy:		92.61 %
Epoch 1173 of 2000 took 0.051s
  training loss:		0.014456
  validation loss:		0.396189
  validation accuracy:		92.50 %
Epoch 1174 of 2000 took 0.051s
  training loss:		0.014767
  validation loss:		0.395433
  validation accuracy:		92.50 %
Epoch 1175 of 2000 took 0.052s
  training loss:		0.015779
  validation loss:		0.393511
  validation accuracy:		92.61 %
Epoch 1176 of 2000 took 0.051s
  training loss:		0.013875
  validation loss:		0.388933
  validation accuracy:		92.61 %
Epoch 1177 of 2000 took 0.050s
  training loss:		0.014749
  validation loss:		0.392905
  validation accuracy:		92.72 %
Epoch 1178 of 2000 took 0.055s
  training loss:		0.014632
  validation loss:		0.397723
  validation accuracy:		92.61 %
Epoch 1179 of 2000 took 0.051s
  training loss:		0.014943
  validation loss:		0.392170
  validation accuracy:		92.61 %
Epoch 1180 of 2000 took 0.050s
  training loss:		0.014363
  validation loss:		0.390780
  validation accuracy:		92.72 %
Epoch 1181 of 2000 took 0.051s
  training loss:		0.014519
  validation loss:		0.398535
  validation accuracy:		92.50 %
Epoch 1182 of 2000 took 0.051s
  training loss:		0.013842
  validation loss:		0.392907
  validation accuracy:		92.72 %
Epoch 1183 of 2000 took 0.052s
  training loss:		0.013919
  validation loss:		0.390889
  validation accuracy:		92.83 %
Epoch 1184 of 2000 took 0.051s
  training loss:		0.014894
  validation loss:		0.396231
  validation accuracy:		92.50 %
Epoch 1185 of 2000 took 0.052s
  training loss:		0.014739
  validation loss:		0.389122
  validation accuracy:		92.93 %
Epoch 1186 of 2000 took 0.051s
  training loss:		0.014805
  validation loss:		0.386425
  validation accuracy:		93.26 %
Epoch 1187 of 2000 took 0.051s
  training loss:		0.014626
  validation loss:		0.393967
  validation accuracy:		92.72 %
Epoch 1188 of 2000 took 0.051s
  training loss:		0.014063
  validation loss:		0.394999
  validation accuracy:		92.61 %
Epoch 1189 of 2000 took 0.050s
  training loss:		0.013900
  validation loss:		0.388964
  validation accuracy:		92.61 %
Epoch 1190 of 2000 took 0.051s
  training loss:		0.013441
  validation loss:		0.395763
  validation accuracy:		92.50 %
Epoch 1191 of 2000 took 0.051s
  training loss:		0.014353
  validation loss:		0.404599
  validation accuracy:		92.50 %
Epoch 1192 of 2000 took 0.290s
  training loss:		0.015021
  validation loss:		0.395022
  validation accuracy:		92.61 %
Epoch 1193 of 2000 took 0.095s
  training loss:		0.014236
  validation loss:		0.392086
  validation accuracy:		92.72 %
Epoch 1194 of 2000 took 0.067s
  training loss:		0.013367
  validation loss:		0.398614
  validation accuracy:		92.50 %
Epoch 1195 of 2000 took 0.115s
  training loss:		0.014768
  validation loss:		0.398552
  validation accuracy:		92.50 %
Epoch 1196 of 2000 took 0.065s
  training loss:		0.014389
  validation loss:		0.396159
  validation accuracy:		92.72 %
Epoch 1197 of 2000 took 0.050s
  training loss:		0.014472
  validation loss:		0.399118
  validation accuracy:		92.61 %
Epoch 1198 of 2000 took 0.050s
  training loss:		0.014302
  validation loss:		0.393521
  validation accuracy:		92.83 %
Epoch 1199 of 2000 took 0.050s
  training loss:		0.014170
  validation loss:		0.394867
  validation accuracy:		92.61 %
Epoch 1200 of 2000 took 0.050s
  training loss:		0.014113
  validation loss:		0.398265
  validation accuracy:		92.61 %
Epoch 1201 of 2000 took 0.050s
  training loss:		0.014304
  validation loss:		0.404522
  validation accuracy:		92.61 %
Epoch 1202 of 2000 took 0.050s
  training loss:		0.013670
  validation loss:		0.395147
  validation accuracy:		92.83 %
Epoch 1203 of 2000 took 0.079s
  training loss:		0.014408
  validation loss:		0.403385
  validation accuracy:		92.61 %
Epoch 1204 of 2000 took 0.106s
  training loss:		0.014903
  validation loss:		0.395550
  validation accuracy:		92.61 %
Epoch 1205 of 2000 took 0.103s
  training loss:		0.013296
  validation loss:		0.402031
  validation accuracy:		92.61 %
Epoch 1206 of 2000 took 0.100s
  training loss:		0.013842
  validation loss:		0.401514
  validation accuracy:		92.50 %
Epoch 1207 of 2000 took 0.077s
  training loss:		0.013428
  validation loss:		0.395072
  validation accuracy:		92.61 %
Epoch 1208 of 2000 took 0.052s
  training loss:		0.013760
  validation loss:		0.401369
  validation accuracy:		92.61 %
Epoch 1209 of 2000 took 0.051s
  training loss:		0.013663
  validation loss:		0.398340
  validation accuracy:		92.61 %
Epoch 1210 of 2000 took 0.051s
  training loss:		0.013618
  validation loss:		0.404465
  validation accuracy:		92.39 %
Epoch 1211 of 2000 took 0.051s
  training loss:		0.012580
  validation loss:		0.397266
  validation accuracy:		92.61 %
Epoch 1212 of 2000 took 0.051s
  training loss:		0.013536
  validation loss:		0.395171
  validation accuracy:		92.83 %
Epoch 1213 of 2000 took 0.051s
  training loss:		0.014138
  validation loss:		0.399757
  validation accuracy:		92.83 %
Epoch 1214 of 2000 took 0.051s
  training loss:		0.012387
  validation loss:		0.401258
  validation accuracy:		92.50 %
Epoch 1215 of 2000 took 0.051s
  training loss:		0.013342
  validation loss:		0.405784
  validation accuracy:		92.61 %
Epoch 1216 of 2000 took 0.051s
  training loss:		0.013638
  validation loss:		0.404585
  validation accuracy:		92.50 %
Epoch 1217 of 2000 took 0.051s
  training loss:		0.013690
  validation loss:		0.401975
  validation accuracy:		92.50 %
Epoch 1218 of 2000 took 0.051s
  training loss:		0.013170
  validation loss:		0.399895
  validation accuracy:		92.72 %
Epoch 1219 of 2000 took 0.051s
  training loss:		0.013353
  validation loss:		0.396438
  validation accuracy:		92.83 %
Epoch 1220 of 2000 took 0.051s
  training loss:		0.013647
  validation loss:		0.399142
  validation accuracy:		92.83 %
Epoch 1221 of 2000 took 0.051s
  training loss:		0.013164
  validation loss:		0.407433
  validation accuracy:		92.50 %
Epoch 1222 of 2000 took 0.051s
  training loss:		0.013276
  validation loss:		0.398982
  validation accuracy:		92.50 %
Epoch 1223 of 2000 took 0.051s
  training loss:		0.013421
  validation loss:		0.403303
  validation accuracy:		92.72 %
Epoch 1224 of 2000 took 0.051s
  training loss:		0.013329
  validation loss:		0.401963
  validation accuracy:		92.50 %
Epoch 1225 of 2000 took 0.051s
  training loss:		0.013039
  validation loss:		0.405765
  validation accuracy:		92.61 %
Epoch 1226 of 2000 took 0.051s
  training loss:		0.012884
  validation loss:		0.410952
  validation accuracy:		92.39 %
Epoch 1227 of 2000 took 0.051s
  training loss:		0.013581
  validation loss:		0.399166
  validation accuracy:		92.93 %
Epoch 1228 of 2000 took 0.051s
  training loss:		0.013309
  validation loss:		0.404902
  validation accuracy:		92.50 %
Epoch 1229 of 2000 took 0.051s
  training loss:		0.013461
  validation loss:		0.415880
  validation accuracy:		92.50 %
Epoch 1230 of 2000 took 0.052s
  training loss:		0.013367
  validation loss:		0.409863
  validation accuracy:		92.50 %
Epoch 1231 of 2000 took 0.052s
  training loss:		0.013074
  validation loss:		0.409218
  validation accuracy:		92.50 %
Epoch 1232 of 2000 took 0.051s
  training loss:		0.013042
  validation loss:		0.401093
  validation accuracy:		92.50 %
Epoch 1233 of 2000 took 0.051s
  training loss:		0.013135
  validation loss:		0.407228
  validation accuracy:		92.50 %
Epoch 1234 of 2000 took 0.051s
  training loss:		0.012897
  validation loss:		0.405756
  validation accuracy:		92.72 %
Epoch 1235 of 2000 took 0.051s
  training loss:		0.012906
  validation loss:		0.403439
  validation accuracy:		92.83 %
Epoch 1236 of 2000 took 0.051s
  training loss:		0.013360
  validation loss:		0.403875
  validation accuracy:		92.61 %
Epoch 1237 of 2000 took 0.051s
  training loss:		0.011644
  validation loss:		0.406799
  validation accuracy:		92.50 %
Epoch 1238 of 2000 took 0.051s
  training loss:		0.011945
  validation loss:		0.402402
  validation accuracy:		92.61 %
Epoch 1239 of 2000 took 0.051s
  training loss:		0.012915
  validation loss:		0.402297
  validation accuracy:		92.83 %
Epoch 1240 of 2000 took 0.051s
  training loss:		0.012666
  validation loss:		0.407865
  validation accuracy:		92.50 %
Epoch 1241 of 2000 took 0.052s
  training loss:		0.012620
  validation loss:		0.407582
  validation accuracy:		92.61 %
Epoch 1242 of 2000 took 0.051s
  training loss:		0.012515
  validation loss:		0.410758
  validation accuracy:		92.61 %
Epoch 1243 of 2000 took 0.051s
  training loss:		0.012811
  validation loss:		0.407365
  validation accuracy:		92.61 %
Epoch 1244 of 2000 took 0.051s
  training loss:		0.012723
  validation loss:		0.408675
  validation accuracy:		92.50 %
Epoch 1245 of 2000 took 0.051s
  training loss:		0.013001
  validation loss:		0.410222
  validation accuracy:		92.61 %
Epoch 1246 of 2000 took 0.050s
  training loss:		0.012969
  validation loss:		0.396876
  validation accuracy:		92.93 %
Epoch 1247 of 2000 took 0.051s
  training loss:		0.012984
  validation loss:		0.407655
  validation accuracy:		92.50 %
Epoch 1248 of 2000 took 0.051s
  training loss:		0.012990
  validation loss:		0.400295
  validation accuracy:		92.83 %
Epoch 1249 of 2000 took 0.051s
  training loss:		0.012733
  validation loss:		0.412335
  validation accuracy:		92.61 %
Epoch 1250 of 2000 took 0.051s
  training loss:		0.012645
  validation loss:		0.410342
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.051s
  training loss:		0.012601
  validation loss:		0.413570
  validation accuracy:		92.50 %
Epoch 1252 of 2000 took 0.051s
  training loss:		0.012822
  validation loss:		0.409910
  validation accuracy:		92.61 %
Epoch 1253 of 2000 took 0.052s
  training loss:		0.013166
  validation loss:		0.413120
  validation accuracy:		92.50 %
Epoch 1254 of 2000 took 0.051s
  training loss:		0.012687
  validation loss:		0.413120
  validation accuracy:		92.50 %
Epoch 1255 of 2000 took 0.051s
  training loss:		0.012156
  validation loss:		0.412898
  validation accuracy:		92.50 %
Epoch 1256 of 2000 took 0.051s
  training loss:		0.012438
  validation loss:		0.413810
  validation accuracy:		92.50 %
Epoch 1257 of 2000 took 0.052s
  training loss:		0.012335
  validation loss:		0.406563
  validation accuracy:		92.50 %
Epoch 1258 of 2000 took 0.051s
  training loss:		0.011708
  validation loss:		0.404170
  validation accuracy:		92.83 %
Epoch 1259 of 2000 took 0.050s
  training loss:		0.012412
  validation loss:		0.407917
  validation accuracy:		92.50 %
Epoch 1260 of 2000 took 0.050s
  training loss:		0.012563
  validation loss:		0.408422
  validation accuracy:		92.72 %
Epoch 1261 of 2000 took 0.050s
  training loss:		0.012068
  validation loss:		0.413071
  validation accuracy:		92.50 %
Epoch 1262 of 2000 took 0.051s
  training loss:		0.011961
  validation loss:		0.410285
  validation accuracy:		92.50 %
Epoch 1263 of 2000 took 0.051s
  training loss:		0.012264
  validation loss:		0.416752
  validation accuracy:		92.61 %
Epoch 1264 of 2000 took 0.050s
  training loss:		0.012668
  validation loss:		0.414539
  validation accuracy:		92.50 %
Epoch 1265 of 2000 took 0.050s
  training loss:		0.012261
  validation loss:		0.411400
  validation accuracy:		92.50 %
Epoch 1266 of 2000 took 0.050s
  training loss:		0.012615
  validation loss:		0.412714
  validation accuracy:		92.61 %
Epoch 1267 of 2000 took 0.051s
  training loss:		0.012479
  validation loss:		0.414153
  validation accuracy:		92.61 %
Epoch 1268 of 2000 took 0.051s
  training loss:		0.012101
  validation loss:		0.415320
  validation accuracy:		92.50 %
Epoch 1269 of 2000 took 0.051s
  training loss:		0.011861
  validation loss:		0.416877
  validation accuracy:		92.50 %
Epoch 1270 of 2000 took 0.051s
  training loss:		0.011763
  validation loss:		0.411912
  validation accuracy:		92.83 %
Epoch 1271 of 2000 took 0.051s
  training loss:		0.011696
  validation loss:		0.414222
  validation accuracy:		92.61 %
Epoch 1272 of 2000 took 0.051s
  training loss:		0.011597
  validation loss:		0.416381
  validation accuracy:		92.50 %
Epoch 1273 of 2000 took 0.051s
  training loss:		0.012320
  validation loss:		0.414920
  validation accuracy:		92.61 %
Epoch 1274 of 2000 took 0.051s
  training loss:		0.011879
  validation loss:		0.417077
  validation accuracy:		92.61 %
Epoch 1275 of 2000 took 0.051s
  training loss:		0.011727
  validation loss:		0.419206
  validation accuracy:		92.50 %
Epoch 1276 of 2000 took 0.051s
  training loss:		0.011952
  validation loss:		0.412729
  validation accuracy:		92.72 %
Epoch 1277 of 2000 took 0.051s
  training loss:		0.012109
  validation loss:		0.418803
  validation accuracy:		92.61 %
Epoch 1278 of 2000 took 0.050s
  training loss:		0.011600
  validation loss:		0.421130
  validation accuracy:		92.50 %
Epoch 1279 of 2000 took 0.050s
  training loss:		0.011948
  validation loss:		0.417491
  validation accuracy:		92.61 %
Epoch 1280 of 2000 took 0.050s
  training loss:		0.011888
  validation loss:		0.414631
  validation accuracy:		92.61 %
Epoch 1281 of 2000 took 0.051s
  training loss:		0.012030
  validation loss:		0.415794
  validation accuracy:		92.50 %
Epoch 1282 of 2000 took 0.051s
  training loss:		0.011884
  validation loss:		0.420509
  validation accuracy:		92.50 %
Epoch 1283 of 2000 took 0.051s
  training loss:		0.011814
  validation loss:		0.418828
  validation accuracy:		92.50 %
Epoch 1284 of 2000 took 0.051s
  training loss:		0.011475
  validation loss:		0.417022
  validation accuracy:		92.61 %
Epoch 1285 of 2000 took 0.051s
  training loss:		0.011724
  validation loss:		0.412347
  validation accuracy:		92.50 %
Epoch 1286 of 2000 took 0.051s
  training loss:		0.011600
  validation loss:		0.418655
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.051s
  training loss:		0.011873
  validation loss:		0.420312
  validation accuracy:		92.61 %
Epoch 1288 of 2000 took 0.051s
  training loss:		0.011397
  validation loss:		0.423919
  validation accuracy:		92.50 %
Epoch 1289 of 2000 took 0.051s
  training loss:		0.011885
  validation loss:		0.419322
  validation accuracy:		92.61 %
Epoch 1290 of 2000 took 0.051s
  training loss:		0.011755
  validation loss:		0.416012
  validation accuracy:		92.61 %
Epoch 1291 of 2000 took 0.051s
  training loss:		0.011728
  validation loss:		0.415946
  validation accuracy:		92.83 %
Epoch 1292 of 2000 took 0.051s
  training loss:		0.012080
  validation loss:		0.414636
  validation accuracy:		92.83 %
Epoch 1293 of 2000 took 0.051s
  training loss:		0.011661
  validation loss:		0.424643
  validation accuracy:		92.61 %
Epoch 1294 of 2000 took 0.051s
  training loss:		0.011310
  validation loss:		0.418127
  validation accuracy:		92.61 %
Epoch 1295 of 2000 took 0.051s
  training loss:		0.011508
  validation loss:		0.419207
  validation accuracy:		92.61 %
Epoch 1296 of 2000 took 0.051s
  training loss:		0.011449
  validation loss:		0.413752
  validation accuracy:		92.72 %
Epoch 1297 of 2000 took 0.051s
  training loss:		0.011561
  validation loss:		0.416198
  validation accuracy:		92.61 %
Epoch 1298 of 2000 took 0.051s
  training loss:		0.011496
  validation loss:		0.426731
  validation accuracy:		92.61 %
Epoch 1299 of 2000 took 0.051s
  training loss:		0.011281
  validation loss:		0.417225
  validation accuracy:		92.83 %
Epoch 1300 of 2000 took 0.051s
  training loss:		0.011247
  validation loss:		0.418966
  validation accuracy:		92.72 %
Epoch 1301 of 2000 took 0.051s
  training loss:		0.011525
  validation loss:		0.418267
  validation accuracy:		92.72 %
Epoch 1302 of 2000 took 0.050s
  training loss:		0.011455
  validation loss:		0.416193
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.050s
  training loss:		0.011706
  validation loss:		0.423599
  validation accuracy:		92.72 %
Epoch 1304 of 2000 took 0.050s
  training loss:		0.010953
  validation loss:		0.425533
  validation accuracy:		92.61 %
Epoch 1305 of 2000 took 0.050s
  training loss:		0.012128
  validation loss:		0.432585
  validation accuracy:		92.17 %
Epoch 1306 of 2000 took 0.050s
  training loss:		0.011525
  validation loss:		0.425095
  validation accuracy:		92.61 %
Epoch 1307 of 2000 took 0.050s
  training loss:		0.011299
  validation loss:		0.422727
  validation accuracy:		92.61 %
Epoch 1308 of 2000 took 0.051s
  training loss:		0.011108
  validation loss:		0.425035
  validation accuracy:		92.61 %
Epoch 1309 of 2000 took 0.051s
  training loss:		0.011355
  validation loss:		0.426921
  validation accuracy:		92.61 %
Epoch 1310 of 2000 took 0.051s
  training loss:		0.011258
  validation loss:		0.419642
  validation accuracy:		92.83 %
Epoch 1311 of 2000 took 0.051s
  training loss:		0.011048
  validation loss:		0.421269
  validation accuracy:		92.83 %
Epoch 1312 of 2000 took 0.051s
  training loss:		0.011039
  validation loss:		0.428236
  validation accuracy:		92.61 %
Epoch 1313 of 2000 took 0.051s
  training loss:		0.010919
  validation loss:		0.428506
  validation accuracy:		92.50 %
Epoch 1314 of 2000 took 0.051s
  training loss:		0.011019
  validation loss:		0.424298
  validation accuracy:		92.72 %
Epoch 1315 of 2000 took 0.051s
  training loss:		0.010991
  validation loss:		0.424418
  validation accuracy:		92.50 %
Epoch 1316 of 2000 took 0.052s
  training loss:		0.011228
  validation loss:		0.424407
  validation accuracy:		92.61 %
Epoch 1317 of 2000 took 0.050s
  training loss:		0.011065
  validation loss:		0.421922
  validation accuracy:		92.93 %
Epoch 1318 of 2000 took 0.050s
  training loss:		0.010675
  validation loss:		0.429208
  validation accuracy:		92.61 %
Epoch 1319 of 2000 took 0.050s
  training loss:		0.010954
  validation loss:		0.420082
  validation accuracy:		92.72 %
Epoch 1320 of 2000 took 0.050s
  training loss:		0.010682
  validation loss:		0.426534
  validation accuracy:		92.61 %
Epoch 1321 of 2000 took 0.051s
  training loss:		0.010586
  validation loss:		0.423137
  validation accuracy:		92.50 %
Epoch 1322 of 2000 took 0.051s
  training loss:		0.010832
  validation loss:		0.426879
  validation accuracy:		92.50 %
Epoch 1323 of 2000 took 0.050s
  training loss:		0.011147
  validation loss:		0.432557
  validation accuracy:		92.61 %
Epoch 1324 of 2000 took 0.050s
  training loss:		0.010930
  validation loss:		0.425960
  validation accuracy:		92.61 %
Epoch 1325 of 2000 took 0.050s
  training loss:		0.010887
  validation loss:		0.424803
  validation accuracy:		92.72 %
Epoch 1326 of 2000 took 0.051s
  training loss:		0.009976
  validation loss:		0.424762
  validation accuracy:		92.61 %
Epoch 1327 of 2000 took 0.051s
  training loss:		0.010636
  validation loss:		0.422482
  validation accuracy:		93.04 %
Epoch 1328 of 2000 took 0.051s
  training loss:		0.010872
  validation loss:		0.424296
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.051s
  training loss:		0.010590
  validation loss:		0.426169
  validation accuracy:		92.61 %
Epoch 1330 of 2000 took 0.051s
  training loss:		0.010866
  validation loss:		0.432784
  validation accuracy:		92.61 %
Epoch 1331 of 2000 took 0.051s
  training loss:		0.010706
  validation loss:		0.419688
  validation accuracy:		92.83 %
Epoch 1332 of 2000 took 0.051s
  training loss:		0.010594
  validation loss:		0.433072
  validation accuracy:		92.61 %
Epoch 1333 of 2000 took 0.051s
  training loss:		0.010582
  validation loss:		0.429535
  validation accuracy:		92.50 %
Epoch 1334 of 2000 took 0.051s
  training loss:		0.010109
  validation loss:		0.425966
  validation accuracy:		92.72 %
Epoch 1335 of 2000 took 0.051s
  training loss:		0.010767
  validation loss:		0.428823
  validation accuracy:		92.61 %
Epoch 1336 of 2000 took 0.051s
  training loss:		0.010526
  validation loss:		0.425158
  validation accuracy:		92.83 %
Epoch 1337 of 2000 took 0.051s
  training loss:		0.010532
  validation loss:		0.424522
  validation accuracy:		92.72 %
Epoch 1338 of 2000 took 0.051s
  training loss:		0.009608
  validation loss:		0.429298
  validation accuracy:		92.72 %
Epoch 1339 of 2000 took 0.051s
  training loss:		0.009933
  validation loss:		0.427806
  validation accuracy:		92.61 %
Epoch 1340 of 2000 took 0.051s
  training loss:		0.010406
  validation loss:		0.430317
  validation accuracy:		92.50 %
Epoch 1341 of 2000 took 0.051s
  training loss:		0.010450
  validation loss:		0.432507
  validation accuracy:		92.61 %
Epoch 1342 of 2000 took 0.051s
  training loss:		0.010413
  validation loss:		0.428672
  validation accuracy:		92.50 %
Epoch 1343 of 2000 took 0.051s
  training loss:		0.010575
  validation loss:		0.430791
  validation accuracy:		92.61 %
Epoch 1344 of 2000 took 0.051s
  training loss:		0.010230
  validation loss:		0.429747
  validation accuracy:		92.61 %
Epoch 1345 of 2000 took 0.051s
  training loss:		0.010409
  validation loss:		0.437725
  validation accuracy:		92.50 %
Epoch 1346 of 2000 took 0.050s
  training loss:		0.010506
  validation loss:		0.425858
  validation accuracy:		92.61 %
Epoch 1347 of 2000 took 0.049s
  training loss:		0.010183
  validation loss:		0.428073
  validation accuracy:		92.61 %
Epoch 1348 of 2000 took 0.050s
  training loss:		0.010151
  validation loss:		0.425714
  validation accuracy:		92.72 %
Epoch 1349 of 2000 took 0.050s
  training loss:		0.010573
  validation loss:		0.430675
  validation accuracy:		92.72 %
Epoch 1350 of 2000 took 0.050s
  training loss:		0.009642
  validation loss:		0.430752
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.050s
  training loss:		0.010588
  validation loss:		0.432443
  validation accuracy:		92.83 %
Epoch 1352 of 2000 took 0.050s
  training loss:		0.010053
  validation loss:		0.432929
  validation accuracy:		92.61 %
Epoch 1353 of 2000 took 0.050s
  training loss:		0.010228
  validation loss:		0.431545
  validation accuracy:		92.50 %
Epoch 1354 of 2000 took 0.052s
  training loss:		0.009861
  validation loss:		0.431446
  validation accuracy:		92.72 %
Epoch 1355 of 2000 took 0.051s
  training loss:		0.009921
  validation loss:		0.434366
  validation accuracy:		92.83 %
Epoch 1356 of 2000 took 0.051s
  training loss:		0.010845
  validation loss:		0.437309
  validation accuracy:		92.50 %
Epoch 1357 of 2000 took 0.051s
  training loss:		0.010236
  validation loss:		0.433283
  validation accuracy:		92.50 %
Epoch 1358 of 2000 took 0.051s
  training loss:		0.010209
  validation loss:		0.442458
  validation accuracy:		92.39 %
Epoch 1359 of 2000 took 0.051s
  training loss:		0.010382
  validation loss:		0.429470
  validation accuracy:		92.72 %
Epoch 1360 of 2000 took 0.050s
  training loss:		0.010149
  validation loss:		0.432372
  validation accuracy:		92.61 %
Epoch 1361 of 2000 took 0.051s
  training loss:		0.009732
  validation loss:		0.440618
  validation accuracy:		92.50 %
Epoch 1362 of 2000 took 0.052s
  training loss:		0.010217
  validation loss:		0.432147
  validation accuracy:		92.72 %
Epoch 1363 of 2000 took 0.051s
  training loss:		0.009921
  validation loss:		0.436829
  validation accuracy:		92.61 %
Epoch 1364 of 2000 took 0.111s
  training loss:		0.010104
  validation loss:		0.429356
  validation accuracy:		92.72 %
Epoch 1365 of 2000 took 0.109s
  training loss:		0.009502
  validation loss:		0.430384
  validation accuracy:		92.93 %
Epoch 1366 of 2000 took 0.147s
  training loss:		0.010362
  validation loss:		0.432566
  validation accuracy:		92.83 %
Epoch 1367 of 2000 took 0.106s
  training loss:		0.010349
  validation loss:		0.439875
  validation accuracy:		92.72 %
Epoch 1368 of 2000 took 0.087s
  training loss:		0.010050
  validation loss:		0.433810
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.067s
  training loss:		0.009740
  validation loss:		0.432991
  validation accuracy:		92.83 %
Epoch 1370 of 2000 took 0.106s
  training loss:		0.009011
  validation loss:		0.432759
  validation accuracy:		92.61 %
Epoch 1371 of 2000 took 0.108s
  training loss:		0.009769
  validation loss:		0.440266
  validation accuracy:		92.61 %
Epoch 1372 of 2000 took 0.150s
  training loss:		0.009897
  validation loss:		0.442657
  validation accuracy:		92.61 %
Epoch 1373 of 2000 took 0.112s
  training loss:		0.009938
  validation loss:		0.435701
  validation accuracy:		92.83 %
Epoch 1374 of 2000 took 0.076s
  training loss:		0.009942
  validation loss:		0.438490
  validation accuracy:		92.50 %
Epoch 1375 of 2000 took 0.051s
  training loss:		0.009596
  validation loss:		0.432074
  validation accuracy:		92.83 %
Epoch 1376 of 2000 took 0.107s
  training loss:		0.009631
  validation loss:		0.444728
  validation accuracy:		92.61 %
Epoch 1377 of 2000 took 0.107s
  training loss:		0.009676
  validation loss:		0.434781
  validation accuracy:		92.83 %
Epoch 1378 of 2000 took 0.167s
  training loss:		0.009830
  validation loss:		0.437227
  validation accuracy:		92.72 %
Epoch 1379 of 2000 took 0.115s
  training loss:		0.009594
  validation loss:		0.447829
  validation accuracy:		92.50 %
Epoch 1380 of 2000 took 0.067s
  training loss:		0.009634
  validation loss:		0.435984
  validation accuracy:		92.72 %
Epoch 1381 of 2000 took 0.103s
  training loss:		0.009420
  validation loss:		0.435238
  validation accuracy:		92.72 %
Epoch 1382 of 2000 took 0.077s
  training loss:		0.009650
  validation loss:		0.439499
  validation accuracy:		92.61 %
Epoch 1383 of 2000 took 0.067s
  training loss:		0.009998
  validation loss:		0.437917
  validation accuracy:		92.61 %
Epoch 1384 of 2000 took 0.102s
  training loss:		0.009490
  validation loss:		0.442452
  validation accuracy:		92.50 %
Epoch 1385 of 2000 took 0.119s
  training loss:		0.009745
  validation loss:		0.446127
  validation accuracy:		92.61 %
Epoch 1386 of 2000 took 0.080s
  training loss:		0.009380
  validation loss:		0.431344
  validation accuracy:		93.04 %
Epoch 1387 of 2000 took 0.050s
  training loss:		0.009411
  validation loss:		0.443613
  validation accuracy:		92.39 %
Epoch 1388 of 2000 took 0.052s
  training loss:		0.009344
  validation loss:		0.439111
  validation accuracy:		92.83 %
Epoch 1389 of 2000 took 0.054s
  training loss:		0.009839
  validation loss:		0.447333
  validation accuracy:		92.50 %
Epoch 1390 of 2000 took 0.053s
  training loss:		0.009830
  validation loss:		0.446882
  validation accuracy:		92.61 %
Epoch 1391 of 2000 took 0.084s
  training loss:		0.010015
  validation loss:		0.447988
  validation accuracy:		92.50 %
Epoch 1392 of 2000 took 0.146s
  training loss:		0.009467
  validation loss:		0.443782
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.107s
  training loss:		0.009253
  validation loss:		0.441549
  validation accuracy:		92.72 %
Epoch 1394 of 2000 took 0.104s
  training loss:		0.009522
  validation loss:		0.445784
  validation accuracy:		92.61 %
Epoch 1395 of 2000 took 0.128s
  training loss:		0.009413
  validation loss:		0.444267
  validation accuracy:		92.61 %
Epoch 1396 of 2000 took 0.133s
  training loss:		0.009241
  validation loss:		0.439464
  validation accuracy:		92.72 %
Epoch 1397 of 2000 took 0.164s
  training loss:		0.009500
  validation loss:		0.440890
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.106s
  training loss:		0.009359
  validation loss:		0.438337
  validation accuracy:		92.72 %
Epoch 1399 of 2000 took 0.114s
  training loss:		0.009161
  validation loss:		0.441952
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.112s
  training loss:		0.009598
  validation loss:		0.439155
  validation accuracy:		92.72 %
Epoch 1401 of 2000 took 0.104s
  training loss:		0.009625
  validation loss:		0.444551
  validation accuracy:		92.72 %
Epoch 1402 of 2000 took 0.109s
  training loss:		0.009478
  validation loss:		0.447575
  validation accuracy:		92.61 %
Epoch 1403 of 2000 took 0.107s
  training loss:		0.009212
  validation loss:		0.443719
  validation accuracy:		92.72 %
Epoch 1404 of 2000 took 0.114s
  training loss:		0.009219
  validation loss:		0.450348
  validation accuracy:		92.61 %
Epoch 1405 of 2000 took 0.134s
  training loss:		0.009152
  validation loss:		0.442587
  validation accuracy:		92.61 %
Epoch 1406 of 2000 took 0.052s
  training loss:		0.009244
  validation loss:		0.436632
  validation accuracy:		92.83 %
Epoch 1407 of 2000 took 0.052s
  training loss:		0.008999
  validation loss:		0.444588
  validation accuracy:		92.72 %
Epoch 1408 of 2000 took 0.085s
  training loss:		0.009324
  validation loss:		0.447471
  validation accuracy:		92.72 %
Epoch 1409 of 2000 took 0.128s
  training loss:		0.009127
  validation loss:		0.446139
  validation accuracy:		92.50 %
Epoch 1410 of 2000 took 0.154s
  training loss:		0.009310
  validation loss:		0.452628
  validation accuracy:		92.61 %
Epoch 1411 of 2000 took 0.165s
  training loss:		0.009168
  validation loss:		0.446070
  validation accuracy:		92.50 %
Epoch 1412 of 2000 took 0.124s
  training loss:		0.009200
  validation loss:		0.442668
  validation accuracy:		92.72 %
Epoch 1413 of 2000 took 0.079s
  training loss:		0.009142
  validation loss:		0.443221
  validation accuracy:		92.72 %
Epoch 1414 of 2000 took 0.059s
  training loss:		0.008927
  validation loss:		0.448710
  validation accuracy:		92.61 %
Epoch 1415 of 2000 took 0.121s
  training loss:		0.009096
  validation loss:		0.444840
  validation accuracy:		92.72 %
Epoch 1416 of 2000 took 0.103s
  training loss:		0.008365
  validation loss:		0.448551
  validation accuracy:		92.61 %
Epoch 1417 of 2000 took 0.109s
  training loss:		0.008967
  validation loss:		0.448160
  validation accuracy:		92.72 %
Epoch 1418 of 2000 took 0.102s
  training loss:		0.009027
  validation loss:		0.445504
  validation accuracy:		92.72 %
Epoch 1419 of 2000 took 0.101s
  training loss:		0.009054
  validation loss:		0.446464
  validation accuracy:		92.61 %
Epoch 1420 of 2000 took 0.089s
  training loss:		0.008514
  validation loss:		0.445957
  validation accuracy:		92.83 %
Epoch 1421 of 2000 took 0.051s
  training loss:		0.009068
  validation loss:		0.449490
  validation accuracy:		92.61 %
Epoch 1422 of 2000 took 0.107s
  training loss:		0.009025
  validation loss:		0.447082
  validation accuracy:		92.61 %
Epoch 1423 of 2000 took 0.121s
  training loss:		0.008803
  validation loss:		0.448885
  validation accuracy:		92.61 %
Epoch 1424 of 2000 took 0.161s
  training loss:		0.008834
  validation loss:		0.443912
  validation accuracy:		92.72 %
Epoch 1425 of 2000 took 0.110s
  training loss:		0.008927
  validation loss:		0.448639
  validation accuracy:		92.72 %
Epoch 1426 of 2000 took 0.124s
  training loss:		0.008823
  validation loss:		0.453087
  validation accuracy:		92.61 %
Epoch 1427 of 2000 took 0.157s
  training loss:		0.008676
  validation loss:		0.449368
  validation accuracy:		92.61 %
Epoch 1428 of 2000 took 0.114s
  training loss:		0.008625
  validation loss:		0.453463
  validation accuracy:		92.72 %
Epoch 1429 of 2000 took 0.146s
  training loss:		0.009086
  validation loss:		0.454183
  validation accuracy:		92.61 %
Epoch 1430 of 2000 took 0.120s
  training loss:		0.008952
  validation loss:		0.448215
  validation accuracy:		92.61 %
Epoch 1431 of 2000 took 0.111s
  training loss:		0.009319
  validation loss:		0.454962
  validation accuracy:		92.61 %
Epoch 1432 of 2000 took 0.111s
  training loss:		0.008857
  validation loss:		0.450484
  validation accuracy:		92.61 %
Epoch 1433 of 2000 took 0.121s
  training loss:		0.008959
  validation loss:		0.450899
  validation accuracy:		92.72 %
Epoch 1434 of 2000 took 0.070s
  training loss:		0.008755
  validation loss:		0.452651
  validation accuracy:		92.72 %
Epoch 1435 of 2000 took 0.080s
  training loss:		0.008524
  validation loss:		0.449859
  validation accuracy:		92.83 %
Epoch 1436 of 2000 took 0.151s
  training loss:		0.008726
  validation loss:		0.449378
  validation accuracy:		92.72 %
Epoch 1437 of 2000 took 0.111s
  training loss:		0.008625
  validation loss:		0.455113
  validation accuracy:		92.72 %
Epoch 1438 of 2000 took 0.088s
  training loss:		0.008478
  validation loss:		0.451312
  validation accuracy:		92.72 %
Epoch 1439 of 2000 took 0.093s
  training loss:		0.008645
  validation loss:		0.449593
  validation accuracy:		92.83 %
Epoch 1440 of 2000 took 0.142s
  training loss:		0.008524
  validation loss:		0.456933
  validation accuracy:		92.61 %
Epoch 1441 of 2000 took 0.102s
  training loss:		0.008551
  validation loss:		0.450596
  validation accuracy:		92.61 %
Epoch 1442 of 2000 took 0.153s
  training loss:		0.008519
  validation loss:		0.453219
  validation accuracy:		92.39 %
Epoch 1443 of 2000 took 0.122s
  training loss:		0.008934
  validation loss:		0.448966
  validation accuracy:		92.61 %
Epoch 1444 of 2000 took 0.087s
  training loss:		0.008538
  validation loss:		0.457523
  validation accuracy:		92.61 %
Epoch 1445 of 2000 took 0.106s
  training loss:		0.008538
  validation loss:		0.455224
  validation accuracy:		92.72 %
Epoch 1446 of 2000 took 0.103s
  training loss:		0.008498
  validation loss:		0.453186
  validation accuracy:		92.83 %
Epoch 1447 of 2000 took 0.101s
  training loss:		0.008408
  validation loss:		0.448384
  validation accuracy:		92.72 %
Epoch 1448 of 2000 took 0.137s
  training loss:		0.008545
  validation loss:		0.451586
  validation accuracy:		92.83 %
Epoch 1449 of 2000 took 0.152s
  training loss:		0.008456
  validation loss:		0.455997
  validation accuracy:		92.61 %
Epoch 1450 of 2000 took 0.100s
  training loss:		0.008679
  validation loss:		0.453472
  validation accuracy:		92.72 %
Epoch 1451 of 2000 took 0.097s
  training loss:		0.008661
  validation loss:		0.461561
  validation accuracy:		92.61 %
Epoch 1452 of 2000 took 0.103s
  training loss:		0.008581
  validation loss:		0.452052
  validation accuracy:		92.83 %
Epoch 1453 of 2000 took 0.102s
  training loss:		0.008616
  validation loss:		0.457597
  validation accuracy:		92.61 %
Epoch 1454 of 2000 took 0.161s
  training loss:		0.008158
  validation loss:		0.453679
  validation accuracy:		92.83 %
Epoch 1455 of 2000 took 0.136s
  training loss:		0.008382
  validation loss:		0.454832
  validation accuracy:		92.83 %
Epoch 1456 of 2000 took 0.086s
  training loss:		0.008223
  validation loss:		0.452211
  validation accuracy:		92.61 %
Epoch 1457 of 2000 took 0.129s
  training loss:		0.008454
  validation loss:		0.457504
  validation accuracy:		92.61 %
Epoch 1458 of 2000 took 0.103s
  training loss:		0.008759
  validation loss:		0.453914
  validation accuracy:		92.83 %
Epoch 1459 of 2000 took 0.102s
  training loss:		0.008532
  validation loss:		0.457004
  validation accuracy:		92.72 %
Epoch 1460 of 2000 took 0.150s
  training loss:		0.008350
  validation loss:		0.451563
  validation accuracy:		92.83 %
Epoch 1461 of 2000 took 0.106s
  training loss:		0.008478
  validation loss:		0.460044
  validation accuracy:		92.72 %
Epoch 1462 of 2000 took 0.087s
  training loss:		0.008338
  validation loss:		0.452031
  validation accuracy:		92.83 %
Epoch 1463 of 2000 took 0.050s
  training loss:		0.008087
  validation loss:		0.459224
  validation accuracy:		92.72 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.008380
  validation loss:		0.458771
  validation accuracy:		92.72 %
Epoch 1465 of 2000 took 0.104s
  training loss:		0.008112
  validation loss:		0.455455
  validation accuracy:		92.61 %
Epoch 1466 of 2000 took 0.139s
  training loss:		0.008465
  validation loss:		0.456228
  validation accuracy:		92.72 %
Epoch 1467 of 2000 took 0.115s
  training loss:		0.008349
  validation loss:		0.459696
  validation accuracy:		92.72 %
Epoch 1468 of 2000 took 0.115s
  training loss:		0.008108
  validation loss:		0.465014
  validation accuracy:		92.50 %
Epoch 1469 of 2000 took 0.080s
  training loss:		0.008402
  validation loss:		0.459014
  validation accuracy:		92.72 %
Epoch 1470 of 2000 took 0.077s
  training loss:		0.008281
  validation loss:		0.448304
  validation accuracy:		93.04 %
Epoch 1471 of 2000 took 0.106s
  training loss:		0.008142
  validation loss:		0.461364
  validation accuracy:		92.61 %
Epoch 1472 of 2000 took 0.132s
  training loss:		0.008219
  validation loss:		0.457116
  validation accuracy:		92.72 %
Epoch 1473 of 2000 took 0.127s
  training loss:		0.008369
  validation loss:		0.456847
  validation accuracy:		92.83 %
Epoch 1474 of 2000 took 0.107s
  training loss:		0.008028
  validation loss:		0.463329
  validation accuracy:		92.72 %
Epoch 1475 of 2000 took 0.068s
  training loss:		0.008168
  validation loss:		0.458454
  validation accuracy:		92.61 %
Epoch 1476 of 2000 took 0.105s
  training loss:		0.008144
  validation loss:		0.459043
  validation accuracy:		92.61 %
Epoch 1477 of 2000 took 0.116s
  training loss:		0.008230
  validation loss:		0.462551
  validation accuracy:		92.72 %
Epoch 1478 of 2000 took 0.177s
  training loss:		0.008148
  validation loss:		0.460499
  validation accuracy:		92.61 %
Epoch 1479 of 2000 took 0.129s
  training loss:		0.007916
  validation loss:		0.458629
  validation accuracy:		92.72 %
Epoch 1480 of 2000 took 0.073s
  training loss:		0.007399
  validation loss:		0.461544
  validation accuracy:		92.72 %
Epoch 1481 of 2000 took 0.105s
  training loss:		0.008156
  validation loss:		0.457419
  validation accuracy:		92.72 %
Epoch 1482 of 2000 took 0.107s
  training loss:		0.007991
  validation loss:		0.458948
  validation accuracy:		92.72 %
Epoch 1483 of 2000 took 0.106s
  training loss:		0.007859
  validation loss:		0.459313
  validation accuracy:		92.61 %
Epoch 1484 of 2000 took 0.084s
  training loss:		0.008031
  validation loss:		0.462049
  validation accuracy:		92.72 %
Epoch 1485 of 2000 took 0.052s
  training loss:		0.008399
  validation loss:		0.459252
  validation accuracy:		92.72 %
Epoch 1486 of 2000 took 0.104s
  training loss:		0.007975
  validation loss:		0.462762
  validation accuracy:		92.72 %
Epoch 1487 of 2000 took 0.065s
  training loss:		0.007976
  validation loss:		0.464268
  validation accuracy:		92.72 %
Epoch 1488 of 2000 took 0.106s
  training loss:		0.007972
  validation loss:		0.458400
  validation accuracy:		92.61 %
Epoch 1489 of 2000 took 0.111s
  training loss:		0.007883
  validation loss:		0.458192
  validation accuracy:		92.61 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.008075
  validation loss:		0.458231
  validation accuracy:		92.61 %
Epoch 1491 of 2000 took 0.084s
  training loss:		0.008003
  validation loss:		0.459129
  validation accuracy:		92.61 %
Epoch 1492 of 2000 took 0.052s
  training loss:		0.007850
  validation loss:		0.462781
  validation accuracy:		92.50 %
Epoch 1493 of 2000 took 0.088s
  training loss:		0.007676
  validation loss:		0.462518
  validation accuracy:		92.72 %
Epoch 1494 of 2000 took 0.103s
  training loss:		0.007769
  validation loss:		0.467086
  validation accuracy:		92.61 %
Epoch 1495 of 2000 took 0.133s
  training loss:		0.007688
  validation loss:		0.462184
  validation accuracy:		92.72 %
Epoch 1496 of 2000 took 0.157s
  training loss:		0.007768
  validation loss:		0.460606
  validation accuracy:		92.61 %
Epoch 1497 of 2000 took 0.153s
  training loss:		0.007676
  validation loss:		0.464508
  validation accuracy:		92.72 %
Epoch 1498 of 2000 took 0.088s
  training loss:		0.007813
  validation loss:		0.467442
  validation accuracy:		92.61 %
Epoch 1499 of 2000 took 0.049s
  training loss:		0.008050
  validation loss:		0.466184
  validation accuracy:		92.72 %
Epoch 1500 of 2000 took 0.053s
  training loss:		0.007706
  validation loss:		0.465019
  validation accuracy:		92.72 %
Epoch 1501 of 2000 took 0.057s
  training loss:		0.007657
  validation loss:		0.464816
  validation accuracy:		92.61 %
Epoch 1502 of 2000 took 0.057s
  training loss:		0.007630
  validation loss:		0.461884
  validation accuracy:		92.83 %
Epoch 1503 of 2000 took 0.057s
  training loss:		0.007365
  validation loss:		0.471426
  validation accuracy:		92.72 %
Epoch 1504 of 2000 took 0.052s
  training loss:		0.007799
  validation loss:		0.466432
  validation accuracy:		92.61 %
Epoch 1505 of 2000 took 0.050s
  training loss:		0.007759
  validation loss:		0.472850
  validation accuracy:		92.50 %
Epoch 1506 of 2000 took 0.050s
  training loss:		0.007685
  validation loss:		0.462915
  validation accuracy:		92.72 %
Epoch 1507 of 2000 took 0.050s
  training loss:		0.007799
  validation loss:		0.466684
  validation accuracy:		92.72 %
Epoch 1508 of 2000 took 0.049s
  training loss:		0.007752
  validation loss:		0.465694
  validation accuracy:		92.83 %
Epoch 1509 of 2000 took 0.049s
  training loss:		0.007835
  validation loss:		0.465040
  validation accuracy:		92.72 %
Epoch 1510 of 2000 took 0.056s
  training loss:		0.007573
  validation loss:		0.472774
  validation accuracy:		92.39 %
Epoch 1511 of 2000 took 0.058s
  training loss:		0.007895
  validation loss:		0.463456
  validation accuracy:		92.61 %
Epoch 1512 of 2000 took 0.057s
  training loss:		0.007648
  validation loss:		0.460763
  validation accuracy:		92.83 %
Epoch 1513 of 2000 took 0.056s
  training loss:		0.007621
  validation loss:		0.469220
  validation accuracy:		92.61 %
Epoch 1514 of 2000 took 0.051s
  training loss:		0.007560
  validation loss:		0.466204
  validation accuracy:		92.61 %
Epoch 1515 of 2000 took 0.050s
  training loss:		0.007257
  validation loss:		0.470386
  validation accuracy:		92.72 %
Epoch 1516 of 2000 took 0.049s
  training loss:		0.007734
  validation loss:		0.469600
  validation accuracy:		92.83 %
Epoch 1517 of 2000 took 0.050s
  training loss:		0.007421
  validation loss:		0.466269
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.050s
  training loss:		0.007599
  validation loss:		0.463981
  validation accuracy:		92.93 %
Epoch 1519 of 2000 took 0.050s
  training loss:		0.007433
  validation loss:		0.468019
  validation accuracy:		92.61 %
Epoch 1520 of 2000 took 0.054s
  training loss:		0.007122
  validation loss:		0.465074
  validation accuracy:		92.83 %
Epoch 1521 of 2000 took 0.057s
  training loss:		0.007390
  validation loss:		0.477000
  validation accuracy:		92.50 %
Epoch 1522 of 2000 took 0.060s
  training loss:		0.007688
  validation loss:		0.463893
  validation accuracy:		92.72 %
Epoch 1523 of 2000 took 0.083s
  training loss:		0.007468
  validation loss:		0.466925
  validation accuracy:		92.72 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.007340
  validation loss:		0.470160
  validation accuracy:		92.61 %
Epoch 1525 of 2000 took 0.118s
  training loss:		0.007414
  validation loss:		0.465303
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.113s
  training loss:		0.007895
  validation loss:		0.471182
  validation accuracy:		92.61 %
Epoch 1527 of 2000 took 0.095s
  training loss:		0.007675
  validation loss:		0.467995
  validation accuracy:		92.72 %
Epoch 1528 of 2000 took 0.141s
  training loss:		0.007308
  validation loss:		0.476981
  validation accuracy:		92.50 %
Epoch 1529 of 2000 took 0.130s
  training loss:		0.007435
  validation loss:		0.468138
  validation accuracy:		92.61 %
Epoch 1530 of 2000 took 0.129s
  training loss:		0.007211
  validation loss:		0.472036
  validation accuracy:		92.72 %
Epoch 1531 of 2000 took 0.130s
  training loss:		0.007404
  validation loss:		0.468762
  validation accuracy:		92.83 %
Epoch 1532 of 2000 took 0.127s
  training loss:		0.007573
  validation loss:		0.470023
  validation accuracy:		92.72 %
Epoch 1533 of 2000 took 0.125s
  training loss:		0.007318
  validation loss:		0.471070
  validation accuracy:		92.72 %
Epoch 1534 of 2000 took 0.124s
  training loss:		0.007509
  validation loss:		0.474587
  validation accuracy:		92.72 %
Epoch 1535 of 2000 took 0.132s
  training loss:		0.007296
  validation loss:		0.467878
  validation accuracy:		92.72 %
Epoch 1536 of 2000 took 0.131s
  training loss:		0.007093
  validation loss:		0.467912
  validation accuracy:		92.83 %
Epoch 1537 of 2000 took 0.129s
  training loss:		0.007534
  validation loss:		0.476363
  validation accuracy:		92.61 %
Epoch 1538 of 2000 took 0.129s
  training loss:		0.007204
  validation loss:		0.471337
  validation accuracy:		92.72 %
Epoch 1539 of 2000 took 0.124s
  training loss:		0.007054
  validation loss:		0.473640
  validation accuracy:		92.72 %
Epoch 1540 of 2000 took 0.125s
  training loss:		0.006975
  validation loss:		0.471014
  validation accuracy:		92.50 %
Epoch 1541 of 2000 took 0.128s
  training loss:		0.007208
  validation loss:		0.473311
  validation accuracy:		92.72 %
Epoch 1542 of 2000 took 0.120s
  training loss:		0.007301
  validation loss:		0.472917
  validation accuracy:		92.61 %
Epoch 1543 of 2000 took 0.147s
  training loss:		0.007175
  validation loss:		0.469975
  validation accuracy:		92.83 %
Epoch 1544 of 2000 took 0.115s
  training loss:		0.007113
  validation loss:		0.471263
  validation accuracy:		92.61 %
Epoch 1545 of 2000 took 0.127s
  training loss:		0.007173
  validation loss:		0.473159
  validation accuracy:		92.61 %
Epoch 1546 of 2000 took 0.131s
  training loss:		0.006756
  validation loss:		0.478879
  validation accuracy:		92.72 %
Epoch 1547 of 2000 took 0.132s
  training loss:		0.007229
  validation loss:		0.476884
  validation accuracy:		92.61 %
Epoch 1548 of 2000 took 0.230s
  training loss:		0.007326
  validation loss:		0.473278
  validation accuracy:		92.83 %
Epoch 1549 of 2000 took 0.182s
  training loss:		0.007058
  validation loss:		0.474894
  validation accuracy:		92.61 %
Epoch 1550 of 2000 took 0.168s
  training loss:		0.007117
  validation loss:		0.475264
  validation accuracy:		92.61 %
Epoch 1551 of 2000 took 0.170s
  training loss:		0.007007
  validation loss:		0.471292
  validation accuracy:		92.72 %
Epoch 1552 of 2000 took 0.184s
  training loss:		0.007430
  validation loss:		0.483986
  validation accuracy:		92.50 %
Epoch 1553 of 2000 took 0.158s
  training loss:		0.007240
  validation loss:		0.478078
  validation accuracy:		92.83 %
Epoch 1554 of 2000 took 0.127s
  training loss:		0.007080
  validation loss:		0.474656
  validation accuracy:		92.61 %
Epoch 1555 of 2000 took 0.157s
  training loss:		0.006820
  validation loss:		0.471434
  validation accuracy:		92.72 %
Epoch 1556 of 2000 took 0.181s
  training loss:		0.007402
  validation loss:		0.469165
  validation accuracy:		92.72 %
Epoch 1557 of 2000 took 0.136s
  training loss:		0.007404
  validation loss:		0.470506
  validation accuracy:		92.61 %
Epoch 1558 of 2000 took 0.119s
  training loss:		0.007162
  validation loss:		0.476730
  validation accuracy:		92.61 %
Epoch 1559 of 2000 took 0.207s
  training loss:		0.006970
  validation loss:		0.480212
  validation accuracy:		92.72 %
Epoch 1560 of 2000 took 0.180s
  training loss:		0.006932
  validation loss:		0.480948
  validation accuracy:		92.83 %
Epoch 1561 of 2000 took 0.145s
  training loss:		0.006988
  validation loss:		0.478982
  validation accuracy:		92.61 %
Epoch 1562 of 2000 took 0.118s
  training loss:		0.006946
  validation loss:		0.475880
  validation accuracy:		92.72 %
Epoch 1563 of 2000 took 0.229s
  training loss:		0.006914
  validation loss:		0.475778
  validation accuracy:		92.61 %
Epoch 1564 of 2000 took 0.168s
  training loss:		0.006921
  validation loss:		0.478108
  validation accuracy:		92.61 %
Epoch 1565 of 2000 took 0.151s
  training loss:		0.006912
  validation loss:		0.473413
  validation accuracy:		92.72 %
Epoch 1566 of 2000 took 0.143s
  training loss:		0.006909
  validation loss:		0.474928
  validation accuracy:		92.72 %
Epoch 1567 of 2000 took 0.157s
  training loss:		0.007050
  validation loss:		0.480890
  validation accuracy:		92.50 %
Epoch 1568 of 2000 took 0.129s
  training loss:		0.006848
  validation loss:		0.471940
  validation accuracy:		92.72 %
Epoch 1569 of 2000 took 0.131s
  training loss:		0.006884
  validation loss:		0.473959
  validation accuracy:		92.72 %
Epoch 1570 of 2000 took 0.126s
  training loss:		0.006899
  validation loss:		0.477530
  validation accuracy:		92.83 %
Epoch 1571 of 2000 took 0.141s
  training loss:		0.006736
  validation loss:		0.477354
  validation accuracy:		92.61 %
Epoch 1572 of 2000 took 0.132s
  training loss:		0.006732
  validation loss:		0.482632
  validation accuracy:		92.61 %
Epoch 1573 of 2000 took 0.128s
  training loss:		0.006635
  validation loss:		0.477453
  validation accuracy:		92.72 %
Epoch 1574 of 2000 took 0.122s
  training loss:		0.006663
  validation loss:		0.482117
  validation accuracy:		92.61 %
Epoch 1575 of 2000 took 0.125s
  training loss:		0.006689
  validation loss:		0.480933
  validation accuracy:		92.61 %
Epoch 1576 of 2000 took 0.191s
  training loss:		0.006845
  validation loss:		0.472647
  validation accuracy:		92.83 %
Epoch 1577 of 2000 took 0.140s
  training loss:		0.006735
  validation loss:		0.483689
  validation accuracy:		92.61 %
Epoch 1578 of 2000 took 0.123s
  training loss:		0.006829
  validation loss:		0.481501
  validation accuracy:		92.61 %
Epoch 1579 of 2000 took 0.212s
  training loss:		0.006783
  validation loss:		0.481673
  validation accuracy:		92.50 %
Epoch 1580 of 2000 took 0.141s
  training loss:		0.006684
  validation loss:		0.473022
  validation accuracy:		92.83 %
Epoch 1581 of 2000 took 0.143s
  training loss:		0.006698
  validation loss:		0.481878
  validation accuracy:		92.61 %
Epoch 1582 of 2000 took 0.144s
  training loss:		0.006874
  validation loss:		0.479748
  validation accuracy:		92.61 %
Epoch 1583 of 2000 took 0.137s
  training loss:		0.006847
  validation loss:		0.481409
  validation accuracy:		92.72 %
Epoch 1584 of 2000 took 0.148s
  training loss:		0.006787
  validation loss:		0.477003
  validation accuracy:		92.72 %
Epoch 1585 of 2000 took 0.124s
  training loss:		0.006428
  validation loss:		0.484968
  validation accuracy:		92.72 %
Epoch 1586 of 2000 took 0.088s
  training loss:		0.006760
  validation loss:		0.478732
  validation accuracy:		92.72 %
Epoch 1587 of 2000 took 0.141s
  training loss:		0.006790
  validation loss:		0.483150
  validation accuracy:		92.61 %
Epoch 1588 of 2000 took 0.130s
  training loss:		0.006489
  validation loss:		0.479276
  validation accuracy:		92.61 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.006813
  validation loss:		0.481657
  validation accuracy:		92.72 %
Epoch 1590 of 2000 took 0.098s
  training loss:		0.006642
  validation loss:		0.489389
  validation accuracy:		92.28 %
Epoch 1591 of 2000 took 0.099s
  training loss:		0.006975
  validation loss:		0.478475
  validation accuracy:		92.72 %
Epoch 1592 of 2000 took 0.180s
  training loss:		0.006427
  validation loss:		0.485641
  validation accuracy:		92.61 %
Epoch 1593 of 2000 took 0.178s
  training loss:		0.006649
  validation loss:		0.484722
  validation accuracy:		92.72 %
Epoch 1594 of 2000 took 0.145s
  training loss:		0.006767
  validation loss:		0.484467
  validation accuracy:		92.72 %
Epoch 1595 of 2000 took 0.142s
  training loss:		0.006475
  validation loss:		0.480541
  validation accuracy:		92.61 %
Epoch 1596 of 2000 took 0.136s
  training loss:		0.006678
  validation loss:		0.482604
  validation accuracy:		92.50 %
Epoch 1597 of 2000 took 0.130s
  training loss:		0.006429
  validation loss:		0.483806
  validation accuracy:		92.61 %
Epoch 1598 of 2000 took 0.120s
  training loss:		0.006478
  validation loss:		0.482150
  validation accuracy:		92.61 %
Epoch 1599 of 2000 took 0.091s
  training loss:		0.006615
  validation loss:		0.486469
  validation accuracy:		92.50 %
Epoch 1600 of 2000 took 0.124s
  training loss:		0.006566
  validation loss:		0.485165
  validation accuracy:		92.50 %
Epoch 1601 of 2000 took 0.130s
  training loss:		0.006545
  validation loss:		0.484725
  validation accuracy:		92.72 %
Epoch 1602 of 2000 took 0.130s
  training loss:		0.006517
  validation loss:		0.487074
  validation accuracy:		92.50 %
Epoch 1603 of 2000 took 0.126s
  training loss:		0.006542
  validation loss:		0.480724
  validation accuracy:		92.72 %
Epoch 1604 of 2000 took 0.131s
  training loss:		0.006713
  validation loss:		0.488547
  validation accuracy:		92.72 %
Epoch 1605 of 2000 took 0.174s
  training loss:		0.006553
  validation loss:		0.482064
  validation accuracy:		92.61 %
Epoch 1606 of 2000 took 0.171s
  training loss:		0.006357
  validation loss:		0.484612
  validation accuracy:		92.61 %
Epoch 1607 of 2000 took 0.133s
  training loss:		0.006228
  validation loss:		0.485278
  validation accuracy:		92.61 %
Epoch 1608 of 2000 took 0.175s
  training loss:		0.006286
  validation loss:		0.484417
  validation accuracy:		92.61 %
Epoch 1609 of 2000 took 0.205s
  training loss:		0.006406
  validation loss:		0.484126
  validation accuracy:		92.61 %
Epoch 1610 of 2000 took 0.235s
  training loss:		0.006316
  validation loss:		0.486122
  validation accuracy:		92.61 %
Epoch 1611 of 2000 took 0.150s
  training loss:		0.006348
  validation loss:		0.489789
  validation accuracy:		92.83 %
Epoch 1612 of 2000 took 0.172s
  training loss:		0.006369
  validation loss:		0.487054
  validation accuracy:		92.50 %
Epoch 1613 of 2000 took 0.134s
  training loss:		0.006317
  validation loss:		0.485234
  validation accuracy:		92.72 %
Epoch 1614 of 2000 took 0.127s
  training loss:		0.006280
  validation loss:		0.487233
  validation accuracy:		92.61 %
Epoch 1615 of 2000 took 0.111s
  training loss:		0.006440
  validation loss:		0.483249
  validation accuracy:		92.83 %
Epoch 1616 of 2000 took 0.222s
  training loss:		0.006307
  validation loss:		0.489722
  validation accuracy:		92.61 %
Epoch 1617 of 2000 took 0.134s
  training loss:		0.006365
  validation loss:		0.486433
  validation accuracy:		92.72 %
Epoch 1618 of 2000 took 0.159s
  training loss:		0.006247
  validation loss:		0.483217
  validation accuracy:		92.72 %
Epoch 1619 of 2000 took 0.202s
  training loss:		0.006401
  validation loss:		0.485686
  validation accuracy:		92.72 %
Epoch 1620 of 2000 took 0.145s
  training loss:		0.006183
  validation loss:		0.485792
  validation accuracy:		92.72 %
Epoch 1621 of 2000 took 0.171s
  training loss:		0.006219
  validation loss:		0.491525
  validation accuracy:		92.50 %
Epoch 1622 of 2000 took 0.108s
  training loss:		0.006127
  validation loss:		0.481274
  validation accuracy:		92.83 %
Epoch 1623 of 2000 took 0.071s
  training loss:		0.006400
  validation loss:		0.490126
  validation accuracy:		92.50 %
Epoch 1624 of 2000 took 0.083s
  training loss:		0.006299
  validation loss:		0.492243
  validation accuracy:		92.61 %
Epoch 1625 of 2000 took 0.093s
  training loss:		0.006236
  validation loss:		0.491725
  validation accuracy:		92.61 %
Epoch 1626 of 2000 took 0.104s
  training loss:		0.006290
  validation loss:		0.490180
  validation accuracy:		92.72 %
Epoch 1627 of 2000 took 0.099s
  training loss:		0.006252
  validation loss:		0.489360
  validation accuracy:		92.72 %
Epoch 1628 of 2000 took 0.107s
  training loss:		0.006250
  validation loss:		0.488967
  validation accuracy:		92.61 %
Epoch 1629 of 2000 took 0.122s
  training loss:		0.005994
  validation loss:		0.487260
  validation accuracy:		92.83 %
Epoch 1630 of 2000 took 0.121s
  training loss:		0.006425
  validation loss:		0.491501
  validation accuracy:		92.61 %
Epoch 1631 of 2000 took 0.118s
  training loss:		0.006379
  validation loss:		0.491088
  validation accuracy:		92.72 %
Epoch 1632 of 2000 took 0.116s
  training loss:		0.006156
  validation loss:		0.488665
  validation accuracy:		92.61 %
Epoch 1633 of 2000 took 0.119s
  training loss:		0.006311
  validation loss:		0.490012
  validation accuracy:		92.50 %
Epoch 1634 of 2000 took 0.118s
  training loss:		0.006519
  validation loss:		0.486186
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.119s
  training loss:		0.006042
  validation loss:		0.492525
  validation accuracy:		92.72 %
Epoch 1636 of 2000 took 0.165s
  training loss:		0.005995
  validation loss:		0.489597
  validation accuracy:		92.72 %
Epoch 1637 of 2000 took 0.184s
  training loss:		0.006150
  validation loss:		0.490215
  validation accuracy:		92.50 %
Epoch 1638 of 2000 took 0.147s
  training loss:		0.006122
  validation loss:		0.493184
  validation accuracy:		92.72 %
Epoch 1639 of 2000 took 0.115s
  training loss:		0.006176
  validation loss:		0.492496
  validation accuracy:		92.72 %
Epoch 1640 of 2000 took 0.116s
  training loss:		0.006104
  validation loss:		0.491383
  validation accuracy:		92.61 %
Epoch 1641 of 2000 took 0.140s
  training loss:		0.006073
  validation loss:		0.494320
  validation accuracy:		92.61 %
Epoch 1642 of 2000 took 0.144s
  training loss:		0.006206
  validation loss:		0.495328
  validation accuracy:		92.50 %
Epoch 1643 of 2000 took 0.175s
  training loss:		0.006103
  validation loss:		0.490297
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.184s
  training loss:		0.005922
  validation loss:		0.494071
  validation accuracy:		92.72 %
Epoch 1645 of 2000 took 0.173s
  training loss:		0.006054
  validation loss:		0.489082
  validation accuracy:		92.83 %
Epoch 1646 of 2000 took 0.168s
  training loss:		0.006024
  validation loss:		0.496298
  validation accuracy:		92.61 %
Epoch 1647 of 2000 took 0.159s
  training loss:		0.006113
  validation loss:		0.493653
  validation accuracy:		92.72 %
Epoch 1648 of 2000 took 0.139s
  training loss:		0.005860
  validation loss:		0.495182
  validation accuracy:		92.61 %
Epoch 1649 of 2000 took 0.144s
  training loss:		0.005901
  validation loss:		0.493812
  validation accuracy:		92.72 %
Epoch 1650 of 2000 took 0.156s
  training loss:		0.006136
  validation loss:		0.494378
  validation accuracy:		92.61 %
Epoch 1651 of 2000 took 0.141s
  training loss:		0.006001
  validation loss:		0.491659
  validation accuracy:		92.72 %
Epoch 1652 of 2000 took 0.164s
  training loss:		0.006147
  validation loss:		0.496348
  validation accuracy:		92.61 %
Epoch 1653 of 2000 took 0.151s
  training loss:		0.005895
  validation loss:		0.496230
  validation accuracy:		92.83 %
Epoch 1654 of 2000 took 0.176s
  training loss:		0.005882
  validation loss:		0.497182
  validation accuracy:		92.83 %
Epoch 1655 of 2000 took 0.182s
  training loss:		0.005943
  validation loss:		0.491380
  validation accuracy:		92.61 %
Epoch 1656 of 2000 took 0.180s
  training loss:		0.006052
  validation loss:		0.493640
  validation accuracy:		92.61 %
Epoch 1657 of 2000 took 0.156s
  training loss:		0.005894
  validation loss:		0.493215
  validation accuracy:		92.61 %
Epoch 1658 of 2000 took 0.130s
  training loss:		0.006040
  validation loss:		0.492116
  validation accuracy:		92.72 %
Epoch 1659 of 2000 took 0.158s
  training loss:		0.005862
  validation loss:		0.492527
  validation accuracy:		92.61 %
Epoch 1660 of 2000 took 0.135s
  training loss:		0.005839
  validation loss:		0.497597
  validation accuracy:		92.72 %
Epoch 1661 of 2000 took 0.145s
  training loss:		0.006013
  validation loss:		0.498579
  validation accuracy:		92.72 %
Epoch 1662 of 2000 took 0.156s
  training loss:		0.005931
  validation loss:		0.498429
  validation accuracy:		92.72 %
Epoch 1663 of 2000 took 0.158s
  training loss:		0.005844
  validation loss:		0.490093
  validation accuracy:		92.93 %
Epoch 1664 of 2000 took 0.141s
  training loss:		0.005923
  validation loss:		0.503876
  validation accuracy:		92.39 %
Epoch 1665 of 2000 took 0.149s
  training loss:		0.005875
  validation loss:		0.495302
  validation accuracy:		92.72 %
Epoch 1666 of 2000 took 0.146s
  training loss:		0.005724
  validation loss:		0.494871
  validation accuracy:		92.72 %
Epoch 1667 of 2000 took 0.184s
  training loss:		0.005871
  validation loss:		0.500008
  validation accuracy:		92.61 %
Epoch 1668 of 2000 took 0.156s
  training loss:		0.005734
  validation loss:		0.498586
  validation accuracy:		92.61 %
Epoch 1669 of 2000 took 0.145s
  training loss:		0.005788
  validation loss:		0.498641
  validation accuracy:		92.50 %
Epoch 1670 of 2000 took 0.178s
  training loss:		0.005657
  validation loss:		0.497057
  validation accuracy:		92.72 %
Epoch 1671 of 2000 took 0.186s
  training loss:		0.005545
  validation loss:		0.496992
  validation accuracy:		92.61 %
Epoch 1672 of 2000 took 0.178s
  training loss:		0.005581
  validation loss:		0.498559
  validation accuracy:		92.72 %
Epoch 1673 of 2000 took 0.193s
  training loss:		0.005824
  validation loss:		0.498419
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.185s
  training loss:		0.005814
  validation loss:		0.505118
  validation accuracy:		92.72 %
Epoch 1675 of 2000 took 0.166s
  training loss:		0.005863
  validation loss:		0.498952
  validation accuracy:		92.72 %
Epoch 1676 of 2000 took 0.153s
  training loss:		0.005585
  validation loss:		0.493932
  validation accuracy:		92.72 %
Epoch 1677 of 2000 took 0.148s
  training loss:		0.005852
  validation loss:		0.503299
  validation accuracy:		92.61 %
Epoch 1678 of 2000 took 0.147s
  training loss:		0.005773
  validation loss:		0.496781
  validation accuracy:		92.72 %
Epoch 1679 of 2000 took 0.138s
  training loss:		0.005669
  validation loss:		0.498652
  validation accuracy:		92.61 %
Epoch 1680 of 2000 took 0.139s
  training loss:		0.006029
  validation loss:		0.499539
  validation accuracy:		92.72 %
Epoch 1681 of 2000 took 0.164s
  training loss:		0.005624
  validation loss:		0.500125
  validation accuracy:		92.72 %
Epoch 1682 of 2000 took 0.186s
  training loss:		0.005890
  validation loss:		0.503853
  validation accuracy:		92.72 %
Epoch 1683 of 2000 took 0.164s
  training loss:		0.005677
  validation loss:		0.501201
  validation accuracy:		92.61 %
Epoch 1684 of 2000 took 0.186s
  training loss:		0.005827
  validation loss:		0.499567
  validation accuracy:		92.72 %
Epoch 1685 of 2000 took 0.152s
  training loss:		0.005583
  validation loss:		0.495592
  validation accuracy:		92.93 %
Epoch 1686 of 2000 took 0.146s
  training loss:		0.005922
  validation loss:		0.497399
  validation accuracy:		92.83 %
Epoch 1687 of 2000 took 0.143s
  training loss:		0.005963
  validation loss:		0.508577
  validation accuracy:		92.61 %
Epoch 1688 of 2000 took 0.184s
  training loss:		0.005825
  validation loss:		0.499092
  validation accuracy:		92.83 %
Epoch 1689 of 2000 took 0.184s
  training loss:		0.005853
  validation loss:		0.506415
  validation accuracy:		92.61 %
Epoch 1690 of 2000 took 0.160s
  training loss:		0.005714
  validation loss:		0.501494
  validation accuracy:		92.72 %
Epoch 1691 of 2000 took 0.137s
  training loss:		0.005694
  validation loss:		0.498178
  validation accuracy:		92.72 %
Epoch 1692 of 2000 took 0.135s
  training loss:		0.005813
  validation loss:		0.500737
  validation accuracy:		92.72 %
Epoch 1693 of 2000 took 0.139s
  training loss:		0.005571
  validation loss:		0.503227
  validation accuracy:		92.61 %
Epoch 1694 of 2000 took 0.136s
  training loss:		0.005533
  validation loss:		0.502808
  validation accuracy:		92.72 %
Epoch 1695 of 2000 took 0.163s
  training loss:		0.005680
  validation loss:		0.501313
  validation accuracy:		92.72 %
Epoch 1696 of 2000 took 0.156s
  training loss:		0.005617
  validation loss:		0.502101
  validation accuracy:		92.72 %
Epoch 1697 of 2000 took 0.159s
  training loss:		0.005688
  validation loss:		0.500032
  validation accuracy:		92.72 %
Epoch 1698 of 2000 took 0.147s
  training loss:		0.005339
  validation loss:		0.502824
  validation accuracy:		92.72 %
Epoch 1699 of 2000 took 0.167s
  training loss:		0.005672
  validation loss:		0.503697
  validation accuracy:		92.72 %
Epoch 1700 of 2000 took 0.180s
  training loss:		0.005545
  validation loss:		0.503210
  validation accuracy:		92.61 %
Epoch 1701 of 2000 took 0.178s
  training loss:		0.005594
  validation loss:		0.502655
  validation accuracy:		92.72 %
Epoch 1702 of 2000 took 0.146s
  training loss:		0.005559
  validation loss:		0.508184
  validation accuracy:		92.50 %
Epoch 1703 of 2000 took 0.144s
  training loss:		0.005676
  validation loss:		0.501540
  validation accuracy:		92.72 %
Epoch 1704 of 2000 took 0.159s
  training loss:		0.005600
  validation loss:		0.505186
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.161s
  training loss:		0.005648
  validation loss:		0.501950
  validation accuracy:		92.72 %
Epoch 1706 of 2000 took 0.150s
  training loss:		0.005394
  validation loss:		0.507232
  validation accuracy:		92.72 %
Epoch 1707 of 2000 took 0.155s
  training loss:		0.005691
  validation loss:		0.504142
  validation accuracy:		92.72 %
Epoch 1708 of 2000 took 0.162s
  training loss:		0.005513
  validation loss:		0.507448
  validation accuracy:		92.61 %
Epoch 1709 of 2000 took 0.182s
  training loss:		0.005697
  validation loss:		0.504562
  validation accuracy:		92.83 %
Epoch 1710 of 2000 took 0.162s
  training loss:		0.005728
  validation loss:		0.503583
  validation accuracy:		92.83 %
Epoch 1711 of 2000 took 0.155s
  training loss:		0.005194
  validation loss:		0.504052
  validation accuracy:		92.72 %
Epoch 1712 of 2000 took 0.153s
  training loss:		0.005402
  validation loss:		0.498734
  validation accuracy:		92.72 %
Epoch 1713 of 2000 took 0.138s
  training loss:		0.005572
  validation loss:		0.505818
  validation accuracy:		92.50 %
Epoch 1714 of 2000 took 0.150s
  training loss:		0.005420
  validation loss:		0.504087
  validation accuracy:		92.72 %
Epoch 1715 of 2000 took 0.143s
  training loss:		0.005314
  validation loss:		0.508600
  validation accuracy:		92.61 %
Epoch 1716 of 2000 took 0.153s
  training loss:		0.005202
  validation loss:		0.502658
  validation accuracy:		92.72 %
Epoch 1717 of 2000 took 0.175s
  training loss:		0.005304
  validation loss:		0.502010
  validation accuracy:		92.83 %
Epoch 1718 of 2000 took 0.183s
  training loss:		0.005366
  validation loss:		0.506588
  validation accuracy:		92.72 %
Epoch 1719 of 2000 took 0.185s
  training loss:		0.005415
  validation loss:		0.507076
  validation accuracy:		92.72 %
Epoch 1720 of 2000 took 0.151s
  training loss:		0.005364
  validation loss:		0.507736
  validation accuracy:		92.72 %
Epoch 1721 of 2000 took 0.150s
  training loss:		0.005290
  validation loss:		0.504386
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.135s
  training loss:		0.005320
  validation loss:		0.508569
  validation accuracy:		92.72 %
Epoch 1723 of 2000 took 0.177s
  training loss:		0.005297
  validation loss:		0.507719
  validation accuracy:		92.61 %
Epoch 1724 of 2000 took 0.166s
  training loss:		0.005457
  validation loss:		0.503168
  validation accuracy:		92.83 %
Epoch 1725 of 2000 took 0.150s
  training loss:		0.005434
  validation loss:		0.508596
  validation accuracy:		92.72 %
Epoch 1726 of 2000 took 0.143s
  training loss:		0.005335
  validation loss:		0.508014
  validation accuracy:		92.72 %
Epoch 1727 of 2000 took 0.144s
  training loss:		0.005352
  validation loss:		0.506129
  validation accuracy:		92.72 %
Epoch 1728 of 2000 took 0.163s
  training loss:		0.005389
  validation loss:		0.505206
  validation accuracy:		92.72 %
Epoch 1729 of 2000 took 0.146s
  training loss:		0.005191
  validation loss:		0.510463
  validation accuracy:		92.50 %
Epoch 1730 of 2000 took 0.158s
  training loss:		0.005236
  validation loss:		0.506278
  validation accuracy:		92.83 %
Epoch 1731 of 2000 took 0.150s
  training loss:		0.005263
  validation loss:		0.510995
  validation accuracy:		92.61 %
Epoch 1732 of 2000 took 0.140s
  training loss:		0.005265
  validation loss:		0.504115
  validation accuracy:		92.72 %
Epoch 1733 of 2000 took 0.152s
  training loss:		0.005270
  validation loss:		0.515090
  validation accuracy:		92.61 %
Epoch 1734 of 2000 took 0.143s
  training loss:		0.005194
  validation loss:		0.512332
  validation accuracy:		92.61 %
Epoch 1735 of 2000 took 0.151s
  training loss:		0.005261
  validation loss:		0.506096
  validation accuracy:		92.72 %
Epoch 1736 of 2000 took 0.147s
  training loss:		0.005168
  validation loss:		0.508396
  validation accuracy:		92.61 %
Epoch 1737 of 2000 took 0.146s
  training loss:		0.005372
  validation loss:		0.512209
  validation accuracy:		92.72 %
Epoch 1738 of 2000 took 0.135s
  training loss:		0.005237
  validation loss:		0.507860
  validation accuracy:		92.72 %
Epoch 1739 of 2000 took 0.149s
  training loss:		0.005338
  validation loss:		0.510545
  validation accuracy:		92.72 %
Epoch 1740 of 2000 took 0.139s
  training loss:		0.005407
  validation loss:		0.507818
  validation accuracy:		92.72 %
Epoch 1741 of 2000 took 0.173s
  training loss:		0.005200
  validation loss:		0.514090
  validation accuracy:		92.72 %
Epoch 1742 of 2000 took 0.185s
  training loss:		0.005364
  validation loss:		0.511641
  validation accuracy:		92.61 %
Epoch 1743 of 2000 took 0.182s
  training loss:		0.005363
  validation loss:		0.513008
  validation accuracy:		92.72 %
Epoch 1744 of 2000 took 0.185s
  training loss:		0.005249
  validation loss:		0.508497
  validation accuracy:		92.72 %
Epoch 1745 of 2000 took 0.156s
  training loss:		0.005109
  validation loss:		0.511203
  validation accuracy:		92.83 %
Epoch 1746 of 2000 took 0.143s
  training loss:		0.004834
  validation loss:		0.507239
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.140s
  training loss:		0.005194
  validation loss:		0.509471
  validation accuracy:		92.83 %
Epoch 1748 of 2000 took 0.163s
  training loss:		0.005103
  validation loss:		0.514414
  validation accuracy:		92.72 %
Epoch 1749 of 2000 took 0.185s
  training loss:		0.005293
  validation loss:		0.511084
  validation accuracy:		92.72 %
Epoch 1750 of 2000 took 0.162s
  training loss:		0.005107
  validation loss:		0.509592
  validation accuracy:		92.72 %
Epoch 1751 of 2000 took 0.138s
  training loss:		0.005111
  validation loss:		0.508455
  validation accuracy:		92.72 %
Epoch 1752 of 2000 took 0.140s
  training loss:		0.005118
  validation loss:		0.516478
  validation accuracy:		92.72 %
Epoch 1753 of 2000 took 0.147s
  training loss:		0.004975
  validation loss:		0.511880
  validation accuracy:		92.72 %
Epoch 1754 of 2000 took 0.155s
  training loss:		0.005221
  validation loss:		0.509754
  validation accuracy:		92.72 %
Epoch 1755 of 2000 took 0.141s
  training loss:		0.004920
  validation loss:		0.516588
  validation accuracy:		92.61 %
Epoch 1756 of 2000 took 0.151s
  training loss:		0.005135
  validation loss:		0.512550
  validation accuracy:		92.72 %
Epoch 1757 of 2000 took 0.138s
  training loss:		0.005172
  validation loss:		0.512070
  validation accuracy:		92.72 %
Epoch 1758 of 2000 took 0.148s
  training loss:		0.004927
  validation loss:		0.511791
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.144s
  training loss:		0.005157
  validation loss:		0.515407
  validation accuracy:		92.72 %
Epoch 1760 of 2000 took 0.154s
  training loss:		0.005326
  validation loss:		0.511154
  validation accuracy:		92.72 %
Epoch 1761 of 2000 took 0.147s
  training loss:		0.005271
  validation loss:		0.514661
  validation accuracy:		92.72 %
Epoch 1762 of 2000 took 0.137s
  training loss:		0.005009
  validation loss:		0.512791
  validation accuracy:		92.72 %
Epoch 1763 of 2000 took 0.185s
  training loss:		0.005053
  validation loss:		0.516537
  validation accuracy:		92.83 %
Epoch 1764 of 2000 took 0.188s
  training loss:		0.005067
  validation loss:		0.517723
  validation accuracy:		92.72 %
Epoch 1765 of 2000 took 0.193s
  training loss:		0.005171
  validation loss:		0.518741
  validation accuracy:		92.61 %
Epoch 1766 of 2000 took 0.190s
  training loss:		0.005102
  validation loss:		0.515394
  validation accuracy:		92.72 %
Epoch 1767 of 2000 took 0.154s
  training loss:		0.005012
  validation loss:		0.516561
  validation accuracy:		92.72 %
Epoch 1768 of 2000 took 0.144s
  training loss:		0.005085
  validation loss:		0.514456
  validation accuracy:		92.72 %
Epoch 1769 of 2000 took 0.144s
  training loss:		0.005042
  validation loss:		0.515952
  validation accuracy:		92.61 %
Epoch 1770 of 2000 took 0.152s
  training loss:		0.005040
  validation loss:		0.516226
  validation accuracy:		92.61 %
Epoch 1771 of 2000 took 0.180s
  training loss:		0.005117
  validation loss:		0.511216
  validation accuracy:		92.72 %
Epoch 1772 of 2000 took 0.184s
  training loss:		0.004894
  validation loss:		0.515383
  validation accuracy:		92.61 %
Epoch 1773 of 2000 took 0.184s
  training loss:		0.004955
  validation loss:		0.514034
  validation accuracy:		92.61 %
Epoch 1774 of 2000 took 0.181s
  training loss:		0.004933
  validation loss:		0.515472
  validation accuracy:		92.61 %
Epoch 1775 of 2000 took 0.184s
  training loss:		0.005113
  validation loss:		0.513460
  validation accuracy:		92.72 %
Epoch 1776 of 2000 took 0.184s
  training loss:		0.004981
  validation loss:		0.513829
  validation accuracy:		92.72 %
Epoch 1777 of 2000 took 0.178s
  training loss:		0.004926
  validation loss:		0.516106
  validation accuracy:		92.72 %
Epoch 1778 of 2000 took 0.186s
  training loss:		0.004878
  validation loss:		0.514398
  validation accuracy:		92.72 %
Epoch 1779 of 2000 took 0.185s
  training loss:		0.004836
  validation loss:		0.518879
  validation accuracy:		92.72 %
Epoch 1780 of 2000 took 0.155s
  training loss:		0.004914
  validation loss:		0.518635
  validation accuracy:		92.83 %
Epoch 1781 of 2000 took 0.172s
  training loss:		0.004971
  validation loss:		0.512588
  validation accuracy:		92.83 %
Epoch 1782 of 2000 took 0.178s
  training loss:		0.005139
  validation loss:		0.518851
  validation accuracy:		92.72 %
Epoch 1783 of 2000 took 0.147s
  training loss:		0.004783
  validation loss:		0.520474
  validation accuracy:		92.72 %
Epoch 1784 of 2000 took 0.152s
  training loss:		0.004979
  validation loss:		0.519117
  validation accuracy:		92.72 %
Epoch 1785 of 2000 took 0.148s
  training loss:		0.004814
  validation loss:		0.520254
  validation accuracy:		92.61 %
Epoch 1786 of 2000 took 0.179s
  training loss:		0.004787
  validation loss:		0.516655
  validation accuracy:		92.72 %
Epoch 1787 of 2000 took 0.157s
  training loss:		0.004827
  validation loss:		0.515493
  validation accuracy:		92.72 %
Epoch 1788 of 2000 took 0.146s
  training loss:		0.005055
  validation loss:		0.519962
  validation accuracy:		92.72 %
Epoch 1789 of 2000 took 0.141s
  training loss:		0.004996
  validation loss:		0.515131
  validation accuracy:		92.72 %
Epoch 1790 of 2000 took 0.137s
  training loss:		0.004797
  validation loss:		0.516343
  validation accuracy:		92.72 %
Epoch 1791 of 2000 took 0.157s
  training loss:		0.004802
  validation loss:		0.515864
  validation accuracy:		92.72 %
Epoch 1792 of 2000 took 0.170s
  training loss:		0.004951
  validation loss:		0.517386
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.156s
  training loss:		0.004923
  validation loss:		0.516796
  validation accuracy:		92.83 %
Epoch 1794 of 2000 took 0.171s
  training loss:		0.005012
  validation loss:		0.525329
  validation accuracy:		92.61 %
Epoch 1795 of 2000 took 0.152s
  training loss:		0.004962
  validation loss:		0.521694
  validation accuracy:		92.72 %
Epoch 1796 of 2000 took 0.150s
  training loss:		0.004585
  validation loss:		0.517604
  validation accuracy:		92.83 %
Epoch 1797 of 2000 took 0.150s
  training loss:		0.004574
  validation loss:		0.515679
  validation accuracy:		92.72 %
Epoch 1798 of 2000 took 0.144s
  training loss:		0.004829
  validation loss:		0.520448
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.147s
  training loss:		0.004753
  validation loss:		0.519432
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.142s
  training loss:		0.004737
  validation loss:		0.519925
  validation accuracy:		92.72 %
Epoch 1801 of 2000 took 0.159s
  training loss:		0.004753
  validation loss:		0.522184
  validation accuracy:		92.72 %
Epoch 1802 of 2000 took 0.166s
  training loss:		0.004719
  validation loss:		0.519352
  validation accuracy:		92.72 %
Epoch 1803 of 2000 took 0.135s
  training loss:		0.004500
  validation loss:		0.522746
  validation accuracy:		92.72 %
Epoch 1804 of 2000 took 0.180s
  training loss:		0.004837
  validation loss:		0.521888
  validation accuracy:		92.72 %
Epoch 1805 of 2000 took 0.186s
  training loss:		0.004928
  validation loss:		0.517845
  validation accuracy:		92.83 %
Epoch 1806 of 2000 took 0.183s
  training loss:		0.004881
  validation loss:		0.525646
  validation accuracy:		92.61 %
Epoch 1807 of 2000 took 0.171s
  training loss:		0.004750
  validation loss:		0.518769
  validation accuracy:		92.61 %
Epoch 1808 of 2000 took 0.185s
  training loss:		0.004700
  validation loss:		0.521099
  validation accuracy:		92.72 %
Epoch 1809 of 2000 took 0.151s
  training loss:		0.004703
  validation loss:		0.518831
  validation accuracy:		92.72 %
Epoch 1810 of 2000 took 0.132s
  training loss:		0.004756
  validation loss:		0.524794
  validation accuracy:		92.72 %
Epoch 1811 of 2000 took 0.176s
  training loss:		0.004821
  validation loss:		0.520146
  validation accuracy:		92.72 %
Epoch 1812 of 2000 took 0.181s
  training loss:		0.004747
  validation loss:		0.523515
  validation accuracy:		92.61 %
Epoch 1813 of 2000 took 0.186s
  training loss:		0.004715
  validation loss:		0.522428
  validation accuracy:		92.72 %
Epoch 1814 of 2000 took 0.182s
  training loss:		0.004776
  validation loss:		0.520425
  validation accuracy:		92.72 %
Epoch 1815 of 2000 took 0.182s
  training loss:		0.004723
  validation loss:		0.521030
  validation accuracy:		92.61 %
Epoch 1816 of 2000 took 0.184s
  training loss:		0.004727
  validation loss:		0.524228
  validation accuracy:		92.72 %
Epoch 1817 of 2000 took 0.161s
  training loss:		0.004702
  validation loss:		0.524064
  validation accuracy:		92.72 %
Epoch 1818 of 2000 took 0.168s
  training loss:		0.004787
  validation loss:		0.526600
  validation accuracy:		92.72 %
Epoch 1819 of 2000 took 0.151s
  training loss:		0.004802
  validation loss:		0.522491
  validation accuracy:		92.72 %
Epoch 1820 of 2000 took 0.150s
  training loss:		0.004597
  validation loss:		0.526362
  validation accuracy:		92.72 %
Epoch 1821 of 2000 took 0.167s
  training loss:		0.004706
  validation loss:		0.529839
  validation accuracy:		92.72 %
Epoch 1822 of 2000 took 0.137s
  training loss:		0.004621
  validation loss:		0.526491
  validation accuracy:		92.72 %
Epoch 1823 of 2000 took 0.148s
  training loss:		0.004545
  validation loss:		0.521561
  validation accuracy:		92.72 %
Epoch 1824 of 2000 took 0.136s
  training loss:		0.004651
  validation loss:		0.523582
  validation accuracy:		92.72 %
Epoch 1825 of 2000 took 0.154s
  training loss:		0.004679
  validation loss:		0.522572
  validation accuracy:		92.72 %
Epoch 1826 of 2000 took 0.145s
  training loss:		0.004565
  validation loss:		0.522173
  validation accuracy:		92.72 %
Epoch 1827 of 2000 took 0.144s
  training loss:		0.004512
  validation loss:		0.525199
  validation accuracy:		92.83 %
Epoch 1828 of 2000 took 0.140s
  training loss:		0.004426
  validation loss:		0.526831
  validation accuracy:		92.83 %
Epoch 1829 of 2000 took 0.140s
  training loss:		0.004566
  validation loss:		0.524051
  validation accuracy:		92.72 %
Epoch 1830 of 2000 took 0.167s
  training loss:		0.004485
  validation loss:		0.523995
  validation accuracy:		92.83 %
Epoch 1831 of 2000 took 0.140s
  training loss:		0.004668
  validation loss:		0.525169
  validation accuracy:		92.72 %
Epoch 1832 of 2000 took 0.141s
  training loss:		0.004665
  validation loss:		0.522187
  validation accuracy:		92.83 %
Epoch 1833 of 2000 took 0.147s
  training loss:		0.004506
  validation loss:		0.526844
  validation accuracy:		92.61 %
Epoch 1834 of 2000 took 0.177s
  training loss:		0.004459
  validation loss:		0.529205
  validation accuracy:		92.61 %
Epoch 1835 of 2000 took 0.160s
  training loss:		0.004547
  validation loss:		0.522747
  validation accuracy:		92.61 %
Epoch 1836 of 2000 took 0.171s
  training loss:		0.004589
  validation loss:		0.528796
  validation accuracy:		92.72 %
Epoch 1837 of 2000 took 0.174s
  training loss:		0.004657
  validation loss:		0.526414
  validation accuracy:		92.72 %
Epoch 1838 of 2000 took 0.182s
  training loss:		0.004500
  validation loss:		0.522835
  validation accuracy:		92.72 %
Epoch 1839 of 2000 took 0.190s
  training loss:		0.004568
  validation loss:		0.527589
  validation accuracy:		92.72 %
Epoch 1840 of 2000 took 0.182s
  training loss:		0.004596
  validation loss:		0.528461
  validation accuracy:		92.72 %
Epoch 1841 of 2000 took 0.181s
  training loss:		0.004511
  validation loss:		0.527739
  validation accuracy:		92.83 %
Epoch 1842 of 2000 took 0.184s
  training loss:		0.004668
  validation loss:		0.527843
  validation accuracy:		92.72 %
Epoch 1843 of 2000 took 0.159s
  training loss:		0.004665
  validation loss:		0.530113
  validation accuracy:		92.61 %
Epoch 1844 of 2000 took 0.159s
  training loss:		0.004522
  validation loss:		0.528236
  validation accuracy:		92.72 %
Epoch 1845 of 2000 took 0.141s
  training loss:		0.004558
  validation loss:		0.527467
  validation accuracy:		92.72 %
Epoch 1846 of 2000 took 0.146s
  training loss:		0.004426
  validation loss:		0.528392
  validation accuracy:		92.72 %
Epoch 1847 of 2000 took 0.145s
  training loss:		0.004493
  validation loss:		0.525765
  validation accuracy:		92.72 %
Epoch 1848 of 2000 took 0.162s
  training loss:		0.004506
  validation loss:		0.525033
  validation accuracy:		92.72 %
Epoch 1849 of 2000 took 0.136s
  training loss:		0.004514
  validation loss:		0.528569
  validation accuracy:		92.72 %
Epoch 1850 of 2000 took 0.178s
  training loss:		0.004513
  validation loss:		0.527889
  validation accuracy:		92.72 %
Epoch 1851 of 2000 took 0.185s
  training loss:		0.004422
  validation loss:		0.531567
  validation accuracy:		92.83 %
Epoch 1852 of 2000 took 0.163s
  training loss:		0.004505
  validation loss:		0.525436
  validation accuracy:		92.72 %
Epoch 1853 of 2000 took 0.182s
  training loss:		0.004395
  validation loss:		0.534513
  validation accuracy:		92.61 %
Epoch 1854 of 2000 took 0.188s
  training loss:		0.004463
  validation loss:		0.529463
  validation accuracy:		92.72 %
Epoch 1855 of 2000 took 0.184s
  training loss:		0.004326
  validation loss:		0.530387
  validation accuracy:		92.72 %
Epoch 1856 of 2000 took 0.183s
  training loss:		0.004489
  validation loss:		0.534131
  validation accuracy:		92.72 %
Epoch 1857 of 2000 took 0.183s
  training loss:		0.004583
  validation loss:		0.531570
  validation accuracy:		92.61 %
Epoch 1858 of 2000 took 0.165s
  training loss:		0.004335
  validation loss:		0.528886
  validation accuracy:		92.83 %
Epoch 1859 of 2000 took 0.189s
  training loss:		0.004486
  validation loss:		0.528719
  validation accuracy:		92.72 %
Epoch 1860 of 2000 took 0.188s
  training loss:		0.004191
  validation loss:		0.531836
  validation accuracy:		92.61 %
Epoch 1861 of 2000 took 0.184s
  training loss:		0.004393
  validation loss:		0.529134
  validation accuracy:		92.72 %
Epoch 1862 of 2000 took 0.181s
  training loss:		0.004407
  validation loss:		0.528465
  validation accuracy:		92.83 %
Epoch 1863 of 2000 took 0.183s
  training loss:		0.004533
  validation loss:		0.529226
  validation accuracy:		92.72 %
Epoch 1864 of 2000 took 0.190s
  training loss:		0.004437
  validation loss:		0.527876
  validation accuracy:		92.72 %
Epoch 1865 of 2000 took 0.181s
  training loss:		0.004379
  validation loss:		0.529933
  validation accuracy:		92.72 %
Epoch 1866 of 2000 took 0.177s
  training loss:		0.004397
  validation loss:		0.532044
  validation accuracy:		92.72 %
Epoch 1867 of 2000 took 0.139s
  training loss:		0.004424
  validation loss:		0.534405
  validation accuracy:		92.72 %
Epoch 1868 of 2000 took 0.141s
  training loss:		0.004491
  validation loss:		0.534688
  validation accuracy:		92.72 %
Epoch 1869 of 2000 took 0.159s
  training loss:		0.004359
  validation loss:		0.530959
  validation accuracy:		92.72 %
Epoch 1870 of 2000 took 0.153s
  training loss:		0.004379
  validation loss:		0.535195
  validation accuracy:		92.72 %
Epoch 1871 of 2000 took 0.149s
  training loss:		0.004430
  validation loss:		0.529565
  validation accuracy:		92.72 %
Epoch 1872 of 2000 took 0.151s
  training loss:		0.004505
  validation loss:		0.532750
  validation accuracy:		92.72 %
Epoch 1873 of 2000 took 0.155s
  training loss:		0.004327
  validation loss:		0.532750
  validation accuracy:		92.72 %
Epoch 1874 of 2000 took 0.156s
  training loss:		0.004325
  validation loss:		0.531467
  validation accuracy:		92.72 %
Epoch 1875 of 2000 took 0.151s
  training loss:		0.004332
  validation loss:		0.535719
  validation accuracy:		92.61 %
Epoch 1876 of 2000 took 0.157s
  training loss:		0.004135
  validation loss:		0.527673
  validation accuracy:		92.83 %
Epoch 1877 of 2000 took 0.183s
  training loss:		0.004205
  validation loss:		0.535356
  validation accuracy:		92.83 %
Epoch 1878 of 2000 took 0.186s
  training loss:		0.004401
  validation loss:		0.530547
  validation accuracy:		92.72 %
Epoch 1879 of 2000 took 0.157s
  training loss:		0.004407
  validation loss:		0.533301
  validation accuracy:		92.72 %
Epoch 1880 of 2000 took 0.145s
  training loss:		0.004259
  validation loss:		0.532179
  validation accuracy:		92.72 %
Epoch 1881 of 2000 took 0.156s
  training loss:		0.004425
  validation loss:		0.538886
  validation accuracy:		92.72 %
Epoch 1882 of 2000 took 0.141s
  training loss:		0.004332
  validation loss:		0.531227
  validation accuracy:		92.72 %
Epoch 1883 of 2000 took 0.182s
  training loss:		0.004375
  validation loss:		0.532694
  validation accuracy:		92.83 %
Epoch 1884 of 2000 took 0.155s
  training loss:		0.004335
  validation loss:		0.537090
  validation accuracy:		92.72 %
Epoch 1885 of 2000 took 0.160s
  training loss:		0.004252
  validation loss:		0.530668
  validation accuracy:		92.72 %
Epoch 1886 of 2000 took 0.191s
  training loss:		0.004236
  validation loss:		0.534497
  validation accuracy:		92.72 %
Epoch 1887 of 2000 took 0.182s
  training loss:		0.004237
  validation loss:		0.535249
  validation accuracy:		92.72 %
Epoch 1888 of 2000 took 0.152s
  training loss:		0.004341
  validation loss:		0.530846
  validation accuracy:		92.72 %
Epoch 1889 of 2000 took 0.154s
  training loss:		0.004179
  validation loss:		0.535505
  validation accuracy:		92.72 %
Epoch 1890 of 2000 took 0.154s
  training loss:		0.004154
  validation loss:		0.534013
  validation accuracy:		92.72 %
Epoch 1891 of 2000 took 0.159s
  training loss:		0.004159
  validation loss:		0.530574
  validation accuracy:		92.93 %
Epoch 1892 of 2000 took 0.144s
  training loss:		0.004180
  validation loss:		0.540024
  validation accuracy:		92.72 %
Epoch 1893 of 2000 took 0.144s
  training loss:		0.004296
  validation loss:		0.537203
  validation accuracy:		92.72 %
Epoch 1894 of 2000 took 0.153s
  training loss:		0.004266
  validation loss:		0.535891
  validation accuracy:		92.72 %
Epoch 1895 of 2000 took 0.173s
  training loss:		0.004300
  validation loss:		0.539757
  validation accuracy:		92.61 %
Epoch 1896 of 2000 took 0.168s
  training loss:		0.004111
  validation loss:		0.534873
  validation accuracy:		92.72 %
Epoch 1897 of 2000 took 0.168s
  training loss:		0.004297
  validation loss:		0.533261
  validation accuracy:		92.72 %
Epoch 1898 of 2000 took 0.183s
  training loss:		0.004103
  validation loss:		0.538388
  validation accuracy:		92.72 %
Epoch 1899 of 2000 took 0.183s
  training loss:		0.004083
  validation loss:		0.533083
  validation accuracy:		92.72 %
Epoch 1900 of 2000 took 0.181s
  training loss:		0.004195
  validation loss:		0.535843
  validation accuracy:		92.72 %
Epoch 1901 of 2000 took 0.156s
  training loss:		0.004197
  validation loss:		0.537971
  validation accuracy:		92.72 %
Epoch 1902 of 2000 took 0.149s
  training loss:		0.004302
  validation loss:		0.539677
  validation accuracy:		92.61 %
Epoch 1903 of 2000 took 0.172s
  training loss:		0.004130
  validation loss:		0.535730
  validation accuracy:		92.72 %
Epoch 1904 of 2000 took 0.183s
  training loss:		0.004130
  validation loss:		0.537398
  validation accuracy:		92.61 %
Epoch 1905 of 2000 took 0.168s
  training loss:		0.004230
  validation loss:		0.537010
  validation accuracy:		92.83 %
Epoch 1906 of 2000 took 0.150s
  training loss:		0.004157
  validation loss:		0.535804
  validation accuracy:		92.72 %
Epoch 1907 of 2000 took 0.143s
  training loss:		0.004161
  validation loss:		0.538881
  validation accuracy:		92.72 %
Epoch 1908 of 2000 took 0.171s
  training loss:		0.004234
  validation loss:		0.535150
  validation accuracy:		92.72 %
Epoch 1909 of 2000 took 0.182s
  training loss:		0.004124
  validation loss:		0.542890
  validation accuracy:		92.72 %
Epoch 1910 of 2000 took 0.175s
  training loss:		0.004025
  validation loss:		0.537360
  validation accuracy:		92.61 %
Epoch 1911 of 2000 took 0.176s
  training loss:		0.004204
  validation loss:		0.536111
  validation accuracy:		92.72 %
Epoch 1912 of 2000 took 0.176s
  training loss:		0.004189
  validation loss:		0.540139
  validation accuracy:		92.72 %
Epoch 1913 of 2000 took 0.146s
  training loss:		0.004191
  validation loss:		0.539373
  validation accuracy:		92.72 %
Epoch 1914 of 2000 took 0.155s
  training loss:		0.004136
  validation loss:		0.538061
  validation accuracy:		92.83 %
Epoch 1915 of 2000 took 0.176s
  training loss:		0.004054
  validation loss:		0.538622
  validation accuracy:		92.72 %
Epoch 1916 of 2000 took 0.157s
  training loss:		0.004090
  validation loss:		0.540472
  validation accuracy:		92.72 %
Epoch 1917 of 2000 took 0.171s
  training loss:		0.003969
  validation loss:		0.542577
  validation accuracy:		92.61 %
Epoch 1918 of 2000 took 0.183s
  training loss:		0.004014
  validation loss:		0.537320
  validation accuracy:		92.72 %
Epoch 1919 of 2000 took 0.156s
  training loss:		0.004174
  validation loss:		0.537684
  validation accuracy:		92.72 %
Epoch 1920 of 2000 took 0.144s
  training loss:		0.004124
  validation loss:		0.540683
  validation accuracy:		92.72 %
Epoch 1921 of 2000 took 0.181s
  training loss:		0.003983
  validation loss:		0.536353
  validation accuracy:		92.72 %
Epoch 1922 of 2000 took 0.158s
  training loss:		0.003998
  validation loss:		0.540270
  validation accuracy:		92.72 %
Epoch 1923 of 2000 took 0.170s
  training loss:		0.004084
  validation loss:		0.539291
  validation accuracy:		92.72 %
Epoch 1924 of 2000 took 0.138s
  training loss:		0.004089
  validation loss:		0.539514
  validation accuracy:		92.72 %
Epoch 1925 of 2000 took 0.180s
  training loss:		0.004052
  validation loss:		0.539799
  validation accuracy:		92.72 %
Epoch 1926 of 2000 took 0.180s
  training loss:		0.003951
  validation loss:		0.539180
  validation accuracy:		92.61 %
Epoch 1927 of 2000 took 0.184s
  training loss:		0.003966
  validation loss:		0.539072
  validation accuracy:		92.72 %
Epoch 1928 of 2000 took 0.161s
  training loss:		0.003989
  validation loss:		0.542394
  validation accuracy:		92.72 %
Epoch 1929 of 2000 took 0.175s
  training loss:		0.003989
  validation loss:		0.539678
  validation accuracy:		92.72 %
Epoch 1930 of 2000 took 0.159s
  training loss:		0.003991
  validation loss:		0.541176
  validation accuracy:		92.72 %
Epoch 1931 of 2000 took 0.154s
  training loss:		0.004073
  validation loss:		0.542878
  validation accuracy:		92.72 %
Epoch 1932 of 2000 took 0.159s
  training loss:		0.004030
  validation loss:		0.538878
  validation accuracy:		92.83 %
Epoch 1933 of 2000 took 0.148s
  training loss:		0.003922
  validation loss:		0.540562
  validation accuracy:		92.72 %
Epoch 1934 of 2000 took 0.157s
  training loss:		0.003993
  validation loss:		0.539867
  validation accuracy:		92.83 %
Epoch 1935 of 2000 took 0.183s
  training loss:		0.004002
  validation loss:		0.539382
  validation accuracy:		92.83 %
Epoch 1936 of 2000 took 0.168s
  training loss:		0.004007
  validation loss:		0.544466
  validation accuracy:		92.72 %
Epoch 1937 of 2000 took 0.168s
  training loss:		0.004025
  validation loss:		0.541111
  validation accuracy:		92.83 %
Epoch 1938 of 2000 took 0.145s
  training loss:		0.004038
  validation loss:		0.542150
  validation accuracy:		92.72 %
Epoch 1939 of 2000 took 0.143s
  training loss:		0.003979
  validation loss:		0.544905
  validation accuracy:		92.50 %
Epoch 1940 of 2000 took 0.146s
  training loss:		0.003956
  validation loss:		0.537282
  validation accuracy:		92.83 %
Epoch 1941 of 2000 took 0.140s
  training loss:		0.003947
  validation loss:		0.541082
  validation accuracy:		92.83 %
Epoch 1942 of 2000 took 0.141s
  training loss:		0.003971
  validation loss:		0.541726
  validation accuracy:		92.72 %
Epoch 1943 of 2000 took 0.164s
  training loss:		0.004105
  validation loss:		0.541586
  validation accuracy:		92.83 %
Epoch 1944 of 2000 took 0.155s
  training loss:		0.003787
  validation loss:		0.542359
  validation accuracy:		92.72 %
Epoch 1945 of 2000 took 0.146s
  training loss:		0.003884
  validation loss:		0.544624
  validation accuracy:		92.72 %
Epoch 1946 of 2000 took 0.149s
  training loss:		0.003906
  validation loss:		0.544211
  validation accuracy:		92.72 %
Epoch 1947 of 2000 took 0.153s
  training loss:		0.004026
  validation loss:		0.542116
  validation accuracy:		92.83 %
Epoch 1948 of 2000 took 0.152s
  training loss:		0.004033
  validation loss:		0.542290
  validation accuracy:		92.83 %
Epoch 1949 of 2000 took 0.147s
  training loss:		0.004030
  validation loss:		0.544129
  validation accuracy:		92.61 %
Epoch 1950 of 2000 took 0.150s
  training loss:		0.003934
  validation loss:		0.543933
  validation accuracy:		92.83 %
Epoch 1951 of 2000 took 0.129s
  training loss:		0.004008
  validation loss:		0.543180
  validation accuracy:		92.72 %
Epoch 1952 of 2000 took 0.143s
  training loss:		0.003956
  validation loss:		0.546014
  validation accuracy:		92.72 %
Epoch 1953 of 2000 took 0.152s
  training loss:		0.003917
  validation loss:		0.547896
  validation accuracy:		92.61 %
Epoch 1954 of 2000 took 0.145s
  training loss:		0.003775
  validation loss:		0.543983
  validation accuracy:		92.83 %
Epoch 1955 of 2000 took 0.153s
  training loss:		0.003847
  validation loss:		0.543926
  validation accuracy:		92.72 %
Epoch 1956 of 2000 took 0.142s
  training loss:		0.003892
  validation loss:		0.546250
  validation accuracy:		92.72 %
Epoch 1957 of 2000 took 0.148s
  training loss:		0.003852
  validation loss:		0.545447
  validation accuracy:		92.83 %
Epoch 1958 of 2000 took 0.147s
  training loss:		0.003835
  validation loss:		0.544591
  validation accuracy:		92.83 %
Epoch 1959 of 2000 took 0.149s
  training loss:		0.003897
  validation loss:		0.544531
  validation accuracy:		92.72 %
Epoch 1960 of 2000 took 0.148s
  training loss:		0.003840
  validation loss:		0.545685
  validation accuracy:		92.83 %
Epoch 1961 of 2000 took 0.146s
  training loss:		0.003864
  validation loss:		0.543682
  validation accuracy:		92.83 %
Epoch 1962 of 2000 took 0.156s
  training loss:		0.003908
  validation loss:		0.546317
  validation accuracy:		92.83 %
Epoch 1963 of 2000 took 0.138s
  training loss:		0.003772
  validation loss:		0.543256
  validation accuracy:		92.72 %
Epoch 1964 of 2000 took 0.137s
  training loss:		0.003837
  validation loss:		0.545156
  validation accuracy:		92.83 %
Epoch 1965 of 2000 took 0.146s
  training loss:		0.003941
  validation loss:		0.546992
  validation accuracy:		92.83 %
Epoch 1966 of 2000 took 0.147s
  training loss:		0.003903
  validation loss:		0.543105
  validation accuracy:		92.72 %
Epoch 1967 of 2000 took 0.154s
  training loss:		0.003775
  validation loss:		0.547975
  validation accuracy:		92.72 %
Epoch 1968 of 2000 took 0.192s
  training loss:		0.003999
  validation loss:		0.550558
  validation accuracy:		92.61 %
Epoch 1969 of 2000 took 0.142s
  training loss:		0.003944
  validation loss:		0.546289
  validation accuracy:		92.72 %
Epoch 1970 of 2000 took 0.183s
  training loss:		0.003749
  validation loss:		0.549534
  validation accuracy:		92.72 %
Epoch 1971 of 2000 took 0.185s
  training loss:		0.003796
  validation loss:		0.544231
  validation accuracy:		92.93 %
Epoch 1972 of 2000 took 0.163s
  training loss:		0.003917
  validation loss:		0.553167
  validation accuracy:		92.72 %
Epoch 1973 of 2000 took 0.155s
  training loss:		0.003816
  validation loss:		0.545486
  validation accuracy:		92.72 %
Epoch 1974 of 2000 took 0.150s
  training loss:		0.003806
  validation loss:		0.549724
  validation accuracy:		92.72 %
Epoch 1975 of 2000 took 0.142s
  training loss:		0.003784
  validation loss:		0.545946
  validation accuracy:		92.72 %
Epoch 1976 of 2000 took 0.145s
  training loss:		0.003770
  validation loss:		0.542229
  validation accuracy:		92.83 %
Epoch 1977 of 2000 took 0.180s
  training loss:		0.003730
  validation loss:		0.548032
  validation accuracy:		92.72 %
Epoch 1978 of 2000 took 0.185s
  training loss:		0.003777
  validation loss:		0.548041
  validation accuracy:		92.72 %
Epoch 1979 of 2000 took 0.174s
  training loss:		0.003774
  validation loss:		0.549677
  validation accuracy:		92.72 %
Epoch 1980 of 2000 took 0.188s
  training loss:		0.003742
  validation loss:		0.547163
  validation accuracy:		92.72 %
Epoch 1981 of 2000 took 0.184s
  training loss:		0.003838
  validation loss:		0.549970
  validation accuracy:		92.72 %
Epoch 1982 of 2000 took 0.184s
  training loss:		0.003774
  validation loss:		0.550655
  validation accuracy:		92.72 %
Epoch 1983 of 2000 took 0.169s
  training loss:		0.003677
  validation loss:		0.549195
  validation accuracy:		92.83 %
Epoch 1984 of 2000 took 0.155s
  training loss:		0.003718
  validation loss:		0.546395
  validation accuracy:		92.61 %
Epoch 1985 of 2000 took 0.176s
  training loss:		0.003718
  validation loss:		0.546864
  validation accuracy:		92.72 %
Epoch 1986 of 2000 took 0.173s
  training loss:		0.003682
  validation loss:		0.549889
  validation accuracy:		92.72 %
Epoch 1987 of 2000 took 0.182s
  training loss:		0.003731
  validation loss:		0.550588
  validation accuracy:		92.50 %
Epoch 1988 of 2000 took 0.136s
  training loss:		0.003694
  validation loss:		0.550173
  validation accuracy:		92.72 %
Epoch 1989 of 2000 took 0.184s
  training loss:		0.003686
  validation loss:		0.547167
  validation accuracy:		92.72 %
Epoch 1990 of 2000 took 0.181s
  training loss:		0.003767
  validation loss:		0.549896
  validation accuracy:		92.83 %
Epoch 1991 of 2000 took 0.181s
  training loss:		0.003866
  validation loss:		0.547873
  validation accuracy:		92.72 %
Epoch 1992 of 2000 took 0.165s
  training loss:		0.003680
  validation loss:		0.550318
  validation accuracy:		92.83 %
Epoch 1993 of 2000 took 0.167s
  training loss:		0.003676
  validation loss:		0.552189
  validation accuracy:		92.72 %
Epoch 1994 of 2000 took 0.146s
  training loss:		0.003853
  validation loss:		0.551794
  validation accuracy:		92.61 %
Epoch 1995 of 2000 took 0.157s
  training loss:		0.003751
  validation loss:		0.553199
  validation accuracy:		92.72 %
Epoch 1996 of 2000 took 0.149s
  training loss:		0.003748
  validation loss:		0.548437
  validation accuracy:		92.83 %
Epoch 1997 of 2000 took 0.134s
  training loss:		0.003896
  validation loss:		0.553857
  validation accuracy:		92.50 %
Epoch 1998 of 2000 took 0.144s
  training loss:		0.003766
  validation loss:		0.551093
  validation accuracy:		92.83 %
Epoch 1999 of 2000 took 0.149s
  training loss:		0.003698
  validation loss:		0.550844
  validation accuracy:		92.72 %
Epoch 2000 of 2000 took 0.139s
  training loss:		0.003569
  validation loss:		0.550849
  validation accuracy:		92.83 %
Final results:
  test loss:			1.318203
  test accuracy:		84.25 %
