Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.044s
  training loss:		2.954638
  validation loss:		2.860795
  validation accuracy:		23.80 %
Epoch 2 of 2000 took 0.040s
  training loss:		2.779255
  validation loss:		2.636617
  validation accuracy:		24.89 %
Epoch 3 of 2000 took 0.038s
  training loss:		2.579866
  validation loss:		2.422766
  validation accuracy:		26.09 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.402719
  validation loss:		2.242633
  validation accuracy:		30.43 %
Epoch 5 of 2000 took 0.038s
  training loss:		2.262823
  validation loss:		2.097638
  validation accuracy:		30.22 %
Epoch 6 of 2000 took 0.038s
  training loss:		2.155608
  validation loss:		2.005979
  validation accuracy:		33.26 %
Epoch 7 of 2000 took 0.040s
  training loss:		2.078333
  validation loss:		1.949885
  validation accuracy:		36.09 %
Epoch 8 of 2000 took 0.040s
  training loss:		2.019574
  validation loss:		1.902756
  validation accuracy:		36.30 %
Epoch 9 of 2000 took 0.071s
  training loss:		1.975606
  validation loss:		1.860424
  validation accuracy:		37.39 %
Epoch 10 of 2000 took 0.049s
  training loss:		1.931766
  validation loss:		1.816447
  validation accuracy:		38.15 %
Epoch 11 of 2000 took 0.044s
  training loss:		1.896392
  validation loss:		1.784331
  validation accuracy:		38.59 %
Epoch 12 of 2000 took 0.040s
  training loss:		1.862038
  validation loss:		1.740907
  validation accuracy:		40.22 %
Epoch 13 of 2000 took 0.039s
  training loss:		1.821048
  validation loss:		1.705819
  validation accuracy:		40.98 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.786237
  validation loss:		1.668745
  validation accuracy:		41.41 %
Epoch 15 of 2000 took 0.039s
  training loss:		1.744497
  validation loss:		1.632643
  validation accuracy:		43.37 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.715713
  validation loss:		1.601104
  validation accuracy:		45.76 %
Epoch 17 of 2000 took 0.039s
  training loss:		1.676812
  validation loss:		1.558891
  validation accuracy:		46.74 %
Epoch 18 of 2000 took 0.038s
  training loss:		1.647889
  validation loss:		1.523865
  validation accuracy:		47.61 %
Epoch 19 of 2000 took 0.038s
  training loss:		1.601930
  validation loss:		1.491380
  validation accuracy:		49.35 %
Epoch 20 of 2000 took 0.038s
  training loss:		1.573020
  validation loss:		1.461491
  validation accuracy:		49.89 %
Epoch 21 of 2000 took 0.038s
  training loss:		1.541349
  validation loss:		1.428053
  validation accuracy:		51.09 %
Epoch 22 of 2000 took 0.036s
  training loss:		1.510060
  validation loss:		1.391939
  validation accuracy:		51.74 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.471768
  validation loss:		1.368294
  validation accuracy:		52.93 %
Epoch 24 of 2000 took 0.036s
  training loss:		1.444460
  validation loss:		1.335974
  validation accuracy:		53.15 %
Epoch 25 of 2000 took 0.036s
  training loss:		1.416156
  validation loss:		1.300957
  validation accuracy:		54.02 %
Epoch 26 of 2000 took 0.036s
  training loss:		1.391029
  validation loss:		1.290195
  validation accuracy:		54.13 %
Epoch 27 of 2000 took 0.036s
  training loss:		1.364228
  validation loss:		1.264323
  validation accuracy:		55.43 %
Epoch 28 of 2000 took 0.036s
  training loss:		1.332129
  validation loss:		1.226711
  validation accuracy:		57.17 %
Epoch 29 of 2000 took 0.036s
  training loss:		1.311243
  validation loss:		1.205656
  validation accuracy:		57.61 %
Epoch 30 of 2000 took 0.036s
  training loss:		1.277681
  validation loss:		1.186387
  validation accuracy:		57.61 %
Epoch 31 of 2000 took 0.036s
  training loss:		1.249708
  validation loss:		1.154151
  validation accuracy:		58.59 %
Epoch 32 of 2000 took 0.036s
  training loss:		1.241560
  validation loss:		1.141281
  validation accuracy:		57.93 %
Epoch 33 of 2000 took 0.036s
  training loss:		1.208757
  validation loss:		1.124518
  validation accuracy:		60.33 %
Epoch 34 of 2000 took 0.036s
  training loss:		1.200412
  validation loss:		1.102592
  validation accuracy:		60.33 %
Epoch 35 of 2000 took 0.036s
  training loss:		1.179723
  validation loss:		1.090201
  validation accuracy:		60.22 %
Epoch 36 of 2000 took 0.036s
  training loss:		1.165241
  validation loss:		1.065169
  validation accuracy:		61.09 %
Epoch 37 of 2000 took 0.036s
  training loss:		1.141906
  validation loss:		1.042268
  validation accuracy:		61.74 %
Epoch 38 of 2000 took 0.036s
  training loss:		1.128690
  validation loss:		1.040625
  validation accuracy:		60.87 %
Epoch 39 of 2000 took 0.036s
  training loss:		1.108989
  validation loss:		1.022380
  validation accuracy:		61.96 %
Epoch 40 of 2000 took 0.036s
  training loss:		1.094212
  validation loss:		1.008427
  validation accuracy:		62.50 %
Epoch 41 of 2000 took 0.036s
  training loss:		1.076223
  validation loss:		0.990421
  validation accuracy:		63.26 %
Epoch 42 of 2000 took 0.036s
  training loss:		1.048356
  validation loss:		0.980956
  validation accuracy:		64.78 %
Epoch 43 of 2000 took 0.036s
  training loss:		1.047592
  validation loss:		0.975546
  validation accuracy:		64.13 %
Epoch 44 of 2000 took 0.036s
  training loss:		1.032466
  validation loss:		0.956228
  validation accuracy:		65.11 %
Epoch 45 of 2000 took 0.036s
  training loss:		1.018567
  validation loss:		0.941294
  validation accuracy:		66.20 %
Epoch 46 of 2000 took 0.036s
  training loss:		1.005629
  validation loss:		0.937643
  validation accuracy:		66.09 %
Epoch 47 of 2000 took 0.036s
  training loss:		0.995285
  validation loss:		0.930319
  validation accuracy:		67.07 %
Epoch 48 of 2000 took 0.036s
  training loss:		0.982190
  validation loss:		0.908752
  validation accuracy:		67.72 %
Epoch 49 of 2000 took 0.036s
  training loss:		0.975187
  validation loss:		0.902756
  validation accuracy:		68.15 %
Epoch 50 of 2000 took 0.036s
  training loss:		0.963449
  validation loss:		0.882779
  validation accuracy:		67.93 %
Epoch 51 of 2000 took 0.036s
  training loss:		0.942857
  validation loss:		0.871758
  validation accuracy:		68.70 %
Epoch 52 of 2000 took 0.036s
  training loss:		0.936660
  validation loss:		0.882074
  validation accuracy:		68.48 %
Epoch 53 of 2000 took 0.036s
  training loss:		0.927535
  validation loss:		0.882136
  validation accuracy:		68.04 %
Epoch 54 of 2000 took 0.036s
  training loss:		0.921568
  validation loss:		0.850426
  validation accuracy:		69.02 %
Epoch 55 of 2000 took 0.036s
  training loss:		0.898738
  validation loss:		0.849750
  validation accuracy:		69.02 %
Epoch 56 of 2000 took 0.036s
  training loss:		0.891378
  validation loss:		0.824293
  validation accuracy:		70.22 %
Epoch 57 of 2000 took 0.036s
  training loss:		0.882748
  validation loss:		0.816663
  validation accuracy:		70.98 %
Epoch 58 of 2000 took 0.036s
  training loss:		0.882935
  validation loss:		0.822510
  validation accuracy:		70.33 %
Epoch 59 of 2000 took 0.036s
  training loss:		0.861241
  validation loss:		0.814002
  validation accuracy:		71.20 %
Epoch 60 of 2000 took 0.036s
  training loss:		0.855585
  validation loss:		0.798872
  validation accuracy:		71.85 %
Epoch 61 of 2000 took 0.036s
  training loss:		0.850467
  validation loss:		0.797401
  validation accuracy:		71.09 %
Epoch 62 of 2000 took 0.036s
  training loss:		0.836730
  validation loss:		0.785496
  validation accuracy:		72.61 %
Epoch 63 of 2000 took 0.036s
  training loss:		0.829154
  validation loss:		0.780202
  validation accuracy:		72.83 %
Epoch 64 of 2000 took 0.036s
  training loss:		0.827300
  validation loss:		0.763568
  validation accuracy:		73.91 %
Epoch 65 of 2000 took 0.036s
  training loss:		0.813207
  validation loss:		0.765277
  validation accuracy:		73.04 %
Epoch 66 of 2000 took 0.036s
  training loss:		0.806590
  validation loss:		0.752023
  validation accuracy:		73.37 %
Epoch 67 of 2000 took 0.036s
  training loss:		0.796877
  validation loss:		0.750918
  validation accuracy:		73.48 %
Epoch 68 of 2000 took 0.036s
  training loss:		0.788213
  validation loss:		0.742820
  validation accuracy:		73.80 %
Epoch 69 of 2000 took 0.036s
  training loss:		0.781138
  validation loss:		0.729748
  validation accuracy:		74.57 %
Epoch 70 of 2000 took 0.036s
  training loss:		0.773900
  validation loss:		0.724666
  validation accuracy:		74.02 %
Epoch 71 of 2000 took 0.036s
  training loss:		0.771542
  validation loss:		0.712512
  validation accuracy:		76.09 %
Epoch 72 of 2000 took 0.036s
  training loss:		0.766957
  validation loss:		0.725470
  validation accuracy:		75.00 %
Epoch 73 of 2000 took 0.036s
  training loss:		0.752003
  validation loss:		0.705689
  validation accuracy:		75.87 %
Epoch 74 of 2000 took 0.036s
  training loss:		0.746218
  validation loss:		0.686665
  validation accuracy:		76.52 %
Epoch 75 of 2000 took 0.036s
  training loss:		0.746064
  validation loss:		0.698431
  validation accuracy:		76.41 %
Epoch 76 of 2000 took 0.036s
  training loss:		0.728989
  validation loss:		0.691417
  validation accuracy:		76.85 %
Epoch 77 of 2000 took 0.036s
  training loss:		0.725213
  validation loss:		0.659840
  validation accuracy:		78.48 %
Epoch 78 of 2000 took 0.038s
  training loss:		0.710315
  validation loss:		0.657757
  validation accuracy:		78.59 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.703886
  validation loss:		0.639461
  validation accuracy:		79.13 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.695741
  validation loss:		0.637929
  validation accuracy:		80.22 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.686012
  validation loss:		0.623634
  validation accuracy:		80.33 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.673922
  validation loss:		0.617886
  validation accuracy:		80.43 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.664376
  validation loss:		0.621944
  validation accuracy:		80.22 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.662177
  validation loss:		0.602624
  validation accuracy:		82.17 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.649029
  validation loss:		0.587188
  validation accuracy:		81.41 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.640817
  validation loss:		0.586637
  validation accuracy:		82.61 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.630756
  validation loss:		0.570189
  validation accuracy:		83.26 %
Epoch 88 of 2000 took 0.036s
  training loss:		0.630205
  validation loss:		0.555270
  validation accuracy:		82.83 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.616648
  validation loss:		0.546673
  validation accuracy:		84.13 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.604119
  validation loss:		0.547224
  validation accuracy:		83.26 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.589754
  validation loss:		0.534824
  validation accuracy:		83.91 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.589492
  validation loss:		0.537678
  validation accuracy:		83.26 %
Epoch 93 of 2000 took 0.036s
  training loss:		0.582058
  validation loss:		0.532236
  validation accuracy:		83.37 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.572739
  validation loss:		0.529527
  validation accuracy:		83.59 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.560504
  validation loss:		0.504669
  validation accuracy:		84.24 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.559823
  validation loss:		0.493036
  validation accuracy:		85.11 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.548411
  validation loss:		0.506237
  validation accuracy:		84.35 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.546195
  validation loss:		0.492821
  validation accuracy:		85.22 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.543089
  validation loss:		0.501125
  validation accuracy:		84.24 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.536862
  validation loss:		0.483493
  validation accuracy:		85.65 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.523107
  validation loss:		0.488825
  validation accuracy:		84.57 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.528436
  validation loss:		0.478572
  validation accuracy:		85.33 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.526474
  validation loss:		0.481154
  validation accuracy:		84.89 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.511394
  validation loss:		0.463182
  validation accuracy:		85.76 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.498430
  validation loss:		0.480604
  validation accuracy:		85.00 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.503897
  validation loss:		0.455295
  validation accuracy:		86.41 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.507291
  validation loss:		0.464960
  validation accuracy:		85.76 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.499198
  validation loss:		0.456776
  validation accuracy:		85.54 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.494634
  validation loss:		0.447127
  validation accuracy:		86.30 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.486262
  validation loss:		0.447589
  validation accuracy:		86.41 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.480250
  validation loss:		0.450749
  validation accuracy:		86.20 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.478108
  validation loss:		0.438573
  validation accuracy:		86.09 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.482221
  validation loss:		0.446326
  validation accuracy:		86.20 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.467745
  validation loss:		0.435451
  validation accuracy:		86.09 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.472948
  validation loss:		0.442454
  validation accuracy:		86.20 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.468626
  validation loss:		0.431411
  validation accuracy:		85.76 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.465911
  validation loss:		0.450066
  validation accuracy:		85.43 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.461001
  validation loss:		0.435995
  validation accuracy:		86.20 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.456986
  validation loss:		0.460550
  validation accuracy:		84.67 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.466137
  validation loss:		0.439091
  validation accuracy:		85.87 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.451081
  validation loss:		0.422913
  validation accuracy:		86.30 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.451834
  validation loss:		0.416400
  validation accuracy:		86.41 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.453793
  validation loss:		0.427127
  validation accuracy:		86.30 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.444824
  validation loss:		0.424183
  validation accuracy:		86.52 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.443012
  validation loss:		0.440253
  validation accuracy:		85.54 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.444907
  validation loss:		0.417856
  validation accuracy:		86.74 %
Epoch 127 of 2000 took 0.036s
  training loss:		0.438140
  validation loss:		0.412353
  validation accuracy:		85.98 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.436692
  validation loss:		0.427948
  validation accuracy:		86.09 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.439859
  validation loss:		0.423515
  validation accuracy:		85.76 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.431010
  validation loss:		0.410863
  validation accuracy:		87.28 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.428479
  validation loss:		0.419405
  validation accuracy:		86.52 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.428525
  validation loss:		0.424982
  validation accuracy:		85.65 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.431038
  validation loss:		0.423904
  validation accuracy:		85.65 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.422432
  validation loss:		0.421118
  validation accuracy:		85.76 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.424041
  validation loss:		0.404295
  validation accuracy:		86.52 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.423230
  validation loss:		0.402651
  validation accuracy:		86.63 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.414156
  validation loss:		0.399869
  validation accuracy:		87.07 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.418838
  validation loss:		0.412189
  validation accuracy:		86.09 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.412079
  validation loss:		0.399291
  validation accuracy:		86.74 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.410827
  validation loss:		0.405083
  validation accuracy:		86.30 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.413056
  validation loss:		0.406521
  validation accuracy:		86.96 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.409176
  validation loss:		0.386939
  validation accuracy:		87.28 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.412246
  validation loss:		0.395288
  validation accuracy:		87.17 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.406707
  validation loss:		0.417427
  validation accuracy:		86.41 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.409256
  validation loss:		0.406977
  validation accuracy:		86.52 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.413945
  validation loss:		0.421233
  validation accuracy:		86.20 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.409366
  validation loss:		0.404419
  validation accuracy:		86.52 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.406551
  validation loss:		0.399788
  validation accuracy:		86.74 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.405512
  validation loss:		0.397940
  validation accuracy:		86.52 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.406256
  validation loss:		0.382618
  validation accuracy:		87.50 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.388336
  validation loss:		0.387347
  validation accuracy:		88.04 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.402837
  validation loss:		0.376668
  validation accuracy:		87.72 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.400675
  validation loss:		0.396206
  validation accuracy:		86.63 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.394284
  validation loss:		0.386486
  validation accuracy:		87.17 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.385934
  validation loss:		0.386751
  validation accuracy:		87.17 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.383324
  validation loss:		0.381417
  validation accuracy:		87.50 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.396493
  validation loss:		0.393528
  validation accuracy:		87.07 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.386731
  validation loss:		0.374491
  validation accuracy:		87.93 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.394359
  validation loss:		0.403333
  validation accuracy:		86.74 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.390709
  validation loss:		0.418870
  validation accuracy:		86.30 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.387848
  validation loss:		0.399758
  validation accuracy:		86.52 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.391022
  validation loss:		0.391601
  validation accuracy:		87.07 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.385861
  validation loss:		0.395973
  validation accuracy:		86.74 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.383994
  validation loss:		0.382632
  validation accuracy:		87.07 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.390592
  validation loss:		0.394898
  validation accuracy:		86.85 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.385693
  validation loss:		0.408503
  validation accuracy:		86.74 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.382451
  validation loss:		0.385591
  validation accuracy:		87.50 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.381726
  validation loss:		0.396482
  validation accuracy:		87.07 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.378801
  validation loss:		0.391068
  validation accuracy:		87.17 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.378945
  validation loss:		0.377535
  validation accuracy:		87.50 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.381995
  validation loss:		0.393207
  validation accuracy:		87.28 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.385736
  validation loss:		0.404702
  validation accuracy:		86.96 %
Epoch 173 of 2000 took 0.036s
  training loss:		0.379414
  validation loss:		0.384171
  validation accuracy:		87.39 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.372870
  validation loss:		0.407668
  validation accuracy:		86.52 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.380897
  validation loss:		0.387992
  validation accuracy:		86.85 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.381889
  validation loss:		0.384127
  validation accuracy:		87.72 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.383480
  validation loss:		0.371160
  validation accuracy:		88.04 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.377724
  validation loss:		0.415524
  validation accuracy:		86.74 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.370337
  validation loss:		0.394977
  validation accuracy:		86.74 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.369967
  validation loss:		0.375727
  validation accuracy:		87.83 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.370877
  validation loss:		0.371696
  validation accuracy:		88.15 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.377079
  validation loss:		0.396149
  validation accuracy:		87.72 %
Epoch 183 of 2000 took 0.036s
  training loss:		0.366840
  validation loss:		0.382009
  validation accuracy:		87.17 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.373199
  validation loss:		0.391981
  validation accuracy:		87.17 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.372966
  validation loss:		0.384433
  validation accuracy:		87.72 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.377068
  validation loss:		0.390895
  validation accuracy:		87.39 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.374815
  validation loss:		0.392672
  validation accuracy:		87.07 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.371145
  validation loss:		0.392941
  validation accuracy:		87.72 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.371320
  validation loss:		0.384242
  validation accuracy:		87.39 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.366547
  validation loss:		0.399046
  validation accuracy:		87.83 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.376217
  validation loss:		0.402320
  validation accuracy:		87.72 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.371730
  validation loss:		0.391902
  validation accuracy:		87.39 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.375001
  validation loss:		0.386244
  validation accuracy:		87.39 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.366158
  validation loss:		0.380339
  validation accuracy:		87.50 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.360882
  validation loss:		0.385881
  validation accuracy:		87.28 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.363146
  validation loss:		0.395471
  validation accuracy:		87.50 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.361918
  validation loss:		0.388988
  validation accuracy:		87.83 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.364158
  validation loss:		0.399021
  validation accuracy:		87.17 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.359118
  validation loss:		0.386798
  validation accuracy:		87.61 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.367076
  validation loss:		0.382180
  validation accuracy:		87.61 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.363418
  validation loss:		0.389365
  validation accuracy:		87.50 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.367446
  validation loss:		0.370548
  validation accuracy:		88.59 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.364432
  validation loss:		0.401683
  validation accuracy:		87.50 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.367556
  validation loss:		0.369856
  validation accuracy:		88.48 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.363259
  validation loss:		0.402458
  validation accuracy:		87.07 %
Epoch 206 of 2000 took 0.036s
  training loss:		0.366131
  validation loss:		0.426315
  validation accuracy:		86.41 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.361691
  validation loss:		0.407552
  validation accuracy:		86.96 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.358651
  validation loss:		0.379545
  validation accuracy:		87.83 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.361216
  validation loss:		0.407460
  validation accuracy:		87.17 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.362355
  validation loss:		0.389823
  validation accuracy:		87.28 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.362393
  validation loss:		0.408711
  validation accuracy:		87.39 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.353099
  validation loss:		0.374379
  validation accuracy:		88.04 %
Epoch 213 of 2000 took 0.036s
  training loss:		0.364414
  validation loss:		0.405140
  validation accuracy:		87.07 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.360877
  validation loss:		0.381794
  validation accuracy:		87.39 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.354642
  validation loss:		0.370968
  validation accuracy:		88.37 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.360682
  validation loss:		0.380535
  validation accuracy:		87.83 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.361561
  validation loss:		0.378951
  validation accuracy:		88.04 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.359996
  validation loss:		0.376589
  validation accuracy:		88.15 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.361186
  validation loss:		0.401966
  validation accuracy:		86.74 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.349344
  validation loss:		0.383544
  validation accuracy:		87.50 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.351409
  validation loss:		0.386546
  validation accuracy:		87.72 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.353534
  validation loss:		0.401875
  validation accuracy:		86.85 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.354807
  validation loss:		0.372488
  validation accuracy:		88.59 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.357133
  validation loss:		0.375745
  validation accuracy:		87.83 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.357007
  validation loss:		0.395205
  validation accuracy:		87.28 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.362467
  validation loss:		0.369628
  validation accuracy:		88.48 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.353796
  validation loss:		0.370045
  validation accuracy:		88.37 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.360032
  validation loss:		0.402217
  validation accuracy:		87.39 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.358457
  validation loss:		0.401142
  validation accuracy:		87.17 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.357105
  validation loss:		0.384692
  validation accuracy:		87.72 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.350046
  validation loss:		0.443954
  validation accuracy:		85.22 %
Epoch 232 of 2000 took 0.037s
  training loss:		0.351235
  validation loss:		0.397912
  validation accuracy:		86.85 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.351585
  validation loss:		0.369410
  validation accuracy:		88.37 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.346064
  validation loss:		0.420547
  validation accuracy:		86.63 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.358853
  validation loss:		0.377345
  validation accuracy:		88.26 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.356963
  validation loss:		0.380164
  validation accuracy:		87.93 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.346143
  validation loss:		0.403207
  validation accuracy:		86.96 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.358621
  validation loss:		0.386563
  validation accuracy:		87.72 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.352473
  validation loss:		0.432324
  validation accuracy:		86.41 %
Epoch 240 of 2000 took 0.036s
  training loss:		0.355848
  validation loss:		0.370685
  validation accuracy:		89.02 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.357312
  validation loss:		0.375556
  validation accuracy:		87.83 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.355559
  validation loss:		0.400691
  validation accuracy:		87.50 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.352371
  validation loss:		0.396820
  validation accuracy:		86.96 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.353463
  validation loss:		0.382484
  validation accuracy:		87.83 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.353123
  validation loss:		0.382747
  validation accuracy:		88.15 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.345978
  validation loss:		0.400590
  validation accuracy:		86.96 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.354728
  validation loss:		0.396105
  validation accuracy:		87.17 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.348872
  validation loss:		0.396423
  validation accuracy:		87.07 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.345951
  validation loss:		0.387656
  validation accuracy:		87.39 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.354547
  validation loss:		0.393256
  validation accuracy:		87.07 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.345846
  validation loss:		0.406193
  validation accuracy:		87.07 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.350801
  validation loss:		0.387054
  validation accuracy:		87.83 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.350292
  validation loss:		0.373785
  validation accuracy:		88.37 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.348980
  validation loss:		0.380016
  validation accuracy:		88.15 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.351563
  validation loss:		0.378894
  validation accuracy:		88.26 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.345305
  validation loss:		0.380214
  validation accuracy:		88.80 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.349219
  validation loss:		0.397767
  validation accuracy:		86.96 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.348346
  validation loss:		0.426432
  validation accuracy:		86.09 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.347600
  validation loss:		0.375216
  validation accuracy:		88.48 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.344359
  validation loss:		0.399748
  validation accuracy:		87.07 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.350548
  validation loss:		0.382228
  validation accuracy:		88.04 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.346543
  validation loss:		0.371248
  validation accuracy:		88.26 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.348125
  validation loss:		0.391026
  validation accuracy:		87.61 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.340647
  validation loss:		0.387617
  validation accuracy:		87.61 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.347667
  validation loss:		0.382392
  validation accuracy:		88.15 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.347567
  validation loss:		0.405339
  validation accuracy:		87.17 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.343671
  validation loss:		0.370732
  validation accuracy:		88.59 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.344847
  validation loss:		0.408408
  validation accuracy:		86.96 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.342636
  validation loss:		0.376554
  validation accuracy:		88.15 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.344913
  validation loss:		0.414745
  validation accuracy:		86.52 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.339050
  validation loss:		0.408193
  validation accuracy:		87.39 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.337183
  validation loss:		0.402125
  validation accuracy:		87.07 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.343612
  validation loss:		0.382608
  validation accuracy:		87.50 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.358671
  validation loss:		0.374759
  validation accuracy:		88.26 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.337412
  validation loss:		0.416372
  validation accuracy:		86.41 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.346291
  validation loss:		0.397004
  validation accuracy:		87.17 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.349795
  validation loss:		0.372535
  validation accuracy:		88.70 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.340144
  validation loss:		0.393319
  validation accuracy:		87.28 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.343784
  validation loss:		0.391398
  validation accuracy:		86.96 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.343362
  validation loss:		0.382319
  validation accuracy:		87.61 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.353401
  validation loss:		0.388953
  validation accuracy:		87.72 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.349417
  validation loss:		0.399251
  validation accuracy:		86.96 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.335122
  validation loss:		0.396743
  validation accuracy:		87.39 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.325880
  validation loss:		0.380602
  validation accuracy:		88.15 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.349392
  validation loss:		0.374467
  validation accuracy:		88.26 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.352301
  validation loss:		0.370821
  validation accuracy:		88.04 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.340237
  validation loss:		0.411733
  validation accuracy:		86.30 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.345857
  validation loss:		0.386242
  validation accuracy:		87.93 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.343540
  validation loss:		0.361047
  validation accuracy:		88.26 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.344549
  validation loss:		0.379215
  validation accuracy:		88.48 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.342053
  validation loss:		0.425402
  validation accuracy:		86.09 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.338457
  validation loss:		0.365228
  validation accuracy:		88.48 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.337314
  validation loss:		0.368710
  validation accuracy:		88.37 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.340870
  validation loss:		0.412544
  validation accuracy:		86.41 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.340831
  validation loss:		0.378576
  validation accuracy:		88.37 %
Epoch 296 of 2000 took 0.036s
  training loss:		0.340929
  validation loss:		0.383518
  validation accuracy:		88.04 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.345323
  validation loss:		0.403758
  validation accuracy:		87.72 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.341747
  validation loss:		0.384941
  validation accuracy:		88.26 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.329532
  validation loss:		0.371339
  validation accuracy:		88.26 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.342133
  validation loss:		0.407060
  validation accuracy:		86.96 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.339144
  validation loss:		0.390340
  validation accuracy:		87.50 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.336364
  validation loss:		0.397543
  validation accuracy:		87.07 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.339650
  validation loss:		0.381134
  validation accuracy:		87.83 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.336026
  validation loss:		0.415662
  validation accuracy:		86.41 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.341566
  validation loss:		0.373907
  validation accuracy:		87.83 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.343611
  validation loss:		0.420004
  validation accuracy:		86.09 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.327410
  validation loss:		0.401299
  validation accuracy:		87.17 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.334754
  validation loss:		0.394815
  validation accuracy:		87.39 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.341960
  validation loss:		0.373541
  validation accuracy:		88.04 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.334104
  validation loss:		0.419944
  validation accuracy:		86.20 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.341271
  validation loss:		0.395035
  validation accuracy:		87.28 %
Epoch 312 of 2000 took 0.036s
  training loss:		0.337394
  validation loss:		0.405795
  validation accuracy:		86.85 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.336978
  validation loss:		0.367878
  validation accuracy:		88.26 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.338726
  validation loss:		0.381436
  validation accuracy:		87.72 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.338861
  validation loss:		0.398754
  validation accuracy:		87.17 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.344500
  validation loss:		0.375853
  validation accuracy:		88.37 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.332042
  validation loss:		0.403054
  validation accuracy:		86.96 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.340352
  validation loss:		0.384814
  validation accuracy:		87.93 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.338504
  validation loss:		0.366630
  validation accuracy:		88.15 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.333799
  validation loss:		0.383933
  validation accuracy:		87.72 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.339574
  validation loss:		0.363360
  validation accuracy:		87.93 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.339583
  validation loss:		0.386401
  validation accuracy:		87.93 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.328646
  validation loss:		0.408449
  validation accuracy:		86.63 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.334940
  validation loss:		0.419932
  validation accuracy:		85.98 %
Epoch 325 of 2000 took 0.036s
  training loss:		0.331181
  validation loss:		0.371725
  validation accuracy:		87.83 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.337981
  validation loss:		0.406134
  validation accuracy:		86.63 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.337805
  validation loss:		0.460006
  validation accuracy:		85.33 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.343646
  validation loss:		0.371090
  validation accuracy:		87.93 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.345045
  validation loss:		0.389419
  validation accuracy:		87.72 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.331134
  validation loss:		0.399399
  validation accuracy:		86.74 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.328904
  validation loss:		0.378375
  validation accuracy:		87.83 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.332704
  validation loss:		0.384491
  validation accuracy:		87.50 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.336051
  validation loss:		0.402416
  validation accuracy:		86.52 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.334256
  validation loss:		0.405361
  validation accuracy:		87.17 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.339815
  validation loss:		0.390929
  validation accuracy:		87.61 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.332733
  validation loss:		0.408039
  validation accuracy:		86.52 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.348541
  validation loss:		0.462719
  validation accuracy:		85.65 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.341607
  validation loss:		0.378934
  validation accuracy:		87.83 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.331150
  validation loss:		0.370211
  validation accuracy:		87.83 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.338617
  validation loss:		0.426480
  validation accuracy:		86.20 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.332369
  validation loss:		0.375363
  validation accuracy:		88.15 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.341309
  validation loss:		0.402234
  validation accuracy:		87.72 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.327218
  validation loss:		0.397583
  validation accuracy:		86.63 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.330841
  validation loss:		0.424044
  validation accuracy:		86.96 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.343518
  validation loss:		0.436535
  validation accuracy:		86.09 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.326822
  validation loss:		0.376562
  validation accuracy:		88.04 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.333383
  validation loss:		0.376859
  validation accuracy:		87.93 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.335531
  validation loss:		0.426371
  validation accuracy:		85.43 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.338133
  validation loss:		0.368910
  validation accuracy:		87.93 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.336290
  validation loss:		0.367931
  validation accuracy:		87.83 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.333495
  validation loss:		0.393283
  validation accuracy:		87.17 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.334895
  validation loss:		0.390367
  validation accuracy:		87.72 %
Epoch 353 of 2000 took 0.036s
  training loss:		0.333681
  validation loss:		0.375287
  validation accuracy:		88.04 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.337767
  validation loss:		0.411083
  validation accuracy:		86.85 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.339810
  validation loss:		0.445920
  validation accuracy:		86.20 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.341228
  validation loss:		0.401948
  validation accuracy:		87.28 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.323988
  validation loss:		0.377803
  validation accuracy:		87.93 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.329542
  validation loss:		0.416905
  validation accuracy:		87.07 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.334161
  validation loss:		0.381061
  validation accuracy:		87.83 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.347963
  validation loss:		0.376981
  validation accuracy:		87.72 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.335277
  validation loss:		0.390746
  validation accuracy:		87.72 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.330540
  validation loss:		0.378588
  validation accuracy:		88.15 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.324382
  validation loss:		0.408281
  validation accuracy:		86.52 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.345238
  validation loss:		0.386342
  validation accuracy:		87.83 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.334610
  validation loss:		0.373220
  validation accuracy:		88.80 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.330924
  validation loss:		0.382188
  validation accuracy:		87.83 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.335171
  validation loss:		0.392125
  validation accuracy:		86.96 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.334871
  validation loss:		0.384328
  validation accuracy:		87.83 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.337378
  validation loss:		0.417003
  validation accuracy:		86.74 %
Epoch 370 of 2000 took 0.036s
  training loss:		0.328798
  validation loss:		0.383827
  validation accuracy:		87.72 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.332355
  validation loss:		0.399217
  validation accuracy:		87.39 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.332850
  validation loss:		0.403167
  validation accuracy:		86.85 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.329523
  validation loss:		0.378006
  validation accuracy:		87.83 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.333664
  validation loss:		0.385310
  validation accuracy:		87.93 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.337219
  validation loss:		0.397867
  validation accuracy:		87.50 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.333454
  validation loss:		0.377100
  validation accuracy:		88.48 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.331749
  validation loss:		0.405427
  validation accuracy:		87.07 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.333854
  validation loss:		0.379160
  validation accuracy:		87.72 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.332701
  validation loss:		0.390044
  validation accuracy:		87.39 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.340150
  validation loss:		0.377918
  validation accuracy:		87.61 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.331743
  validation loss:		0.410433
  validation accuracy:		87.28 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.330695
  validation loss:		0.370144
  validation accuracy:		87.93 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.325607
  validation loss:		0.391265
  validation accuracy:		87.17 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.325437
  validation loss:		0.401525
  validation accuracy:		86.74 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.329571
  validation loss:		0.399595
  validation accuracy:		87.39 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.327664
  validation loss:		0.422111
  validation accuracy:		87.07 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.331108
  validation loss:		0.400606
  validation accuracy:		87.07 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.321757
  validation loss:		0.400909
  validation accuracy:		87.07 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.339563
  validation loss:		0.392572
  validation accuracy:		87.83 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.327869
  validation loss:		0.381936
  validation accuracy:		87.83 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.326572
  validation loss:		0.388912
  validation accuracy:		87.83 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.333130
  validation loss:		0.416263
  validation accuracy:		87.17 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.329609
  validation loss:		0.383647
  validation accuracy:		87.93 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.328629
  validation loss:		0.422676
  validation accuracy:		86.30 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.326888
  validation loss:		0.382042
  validation accuracy:		87.83 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.321406
  validation loss:		0.372946
  validation accuracy:		88.04 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.328677
  validation loss:		0.385164
  validation accuracy:		87.83 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.334070
  validation loss:		0.405335
  validation accuracy:		87.39 %
Epoch 399 of 2000 took 0.036s
  training loss:		0.325613
  validation loss:		0.384783
  validation accuracy:		87.50 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.329868
  validation loss:		0.391258
  validation accuracy:		87.50 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.331623
  validation loss:		0.408090
  validation accuracy:		86.74 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.326154
  validation loss:		0.387936
  validation accuracy:		87.83 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.344109
  validation loss:		0.395339
  validation accuracy:		87.39 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.329113
  validation loss:		0.387367
  validation accuracy:		87.93 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.322748
  validation loss:		0.391616
  validation accuracy:		87.28 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.329270
  validation loss:		0.428381
  validation accuracy:		86.30 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.327537
  validation loss:		0.372823
  validation accuracy:		88.59 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.328120
  validation loss:		0.406130
  validation accuracy:		86.74 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.334320
  validation loss:		0.427298
  validation accuracy:		86.09 %
Epoch 410 of 2000 took 0.036s
  training loss:		0.328181
  validation loss:		0.415778
  validation accuracy:		86.74 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.327039
  validation loss:		0.373323
  validation accuracy:		88.48 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.329236
  validation loss:		0.367415
  validation accuracy:		88.15 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.324521
  validation loss:		0.400831
  validation accuracy:		87.28 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.323550
  validation loss:		0.376738
  validation accuracy:		88.26 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.334195
  validation loss:		0.390486
  validation accuracy:		87.61 %
Epoch 416 of 2000 took 0.036s
  training loss:		0.323043
  validation loss:		0.399614
  validation accuracy:		87.61 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.336489
  validation loss:		0.372102
  validation accuracy:		88.15 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.335724
  validation loss:		0.389400
  validation accuracy:		87.72 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.322014
  validation loss:		0.383154
  validation accuracy:		88.04 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.324347
  validation loss:		0.395888
  validation accuracy:		87.50 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.329459
  validation loss:		0.406488
  validation accuracy:		87.39 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.325268
  validation loss:		0.392228
  validation accuracy:		87.39 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.329477
  validation loss:		0.380605
  validation accuracy:		88.37 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.324715
  validation loss:		0.384405
  validation accuracy:		87.93 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.330906
  validation loss:		0.405889
  validation accuracy:		87.61 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.326568
  validation loss:		0.454157
  validation accuracy:		85.87 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.329882
  validation loss:		0.393645
  validation accuracy:		87.61 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.329374
  validation loss:		0.388121
  validation accuracy:		87.61 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.325682
  validation loss:		0.416361
  validation accuracy:		86.85 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.326756
  validation loss:		0.421682
  validation accuracy:		86.85 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.327414
  validation loss:		0.397840
  validation accuracy:		87.07 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.322637
  validation loss:		0.392866
  validation accuracy:		87.39 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.324009
  validation loss:		0.385261
  validation accuracy:		88.04 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.325560
  validation loss:		0.392167
  validation accuracy:		87.39 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.328598
  validation loss:		0.391355
  validation accuracy:		87.28 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.324943
  validation loss:		0.383326
  validation accuracy:		88.15 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.330010
  validation loss:		0.379550
  validation accuracy:		88.70 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.320593
  validation loss:		0.392951
  validation accuracy:		87.72 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.322862
  validation loss:		0.423196
  validation accuracy:		87.07 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.329979
  validation loss:		0.430818
  validation accuracy:		86.30 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.320508
  validation loss:		0.380459
  validation accuracy:		88.26 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.333054
  validation loss:		0.381737
  validation accuracy:		87.93 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.323439
  validation loss:		0.404643
  validation accuracy:		87.17 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.329953
  validation loss:		0.397985
  validation accuracy:		87.50 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.318246
  validation loss:		0.382371
  validation accuracy:		87.93 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.322562
  validation loss:		0.381185
  validation accuracy:		88.26 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.329760
  validation loss:		0.391302
  validation accuracy:		87.61 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.339597
  validation loss:		0.453667
  validation accuracy:		85.33 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.322349
  validation loss:		0.367597
  validation accuracy:		88.59 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.329970
  validation loss:		0.400644
  validation accuracy:		87.83 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.321592
  validation loss:		0.392517
  validation accuracy:		87.72 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.325034
  validation loss:		0.387070
  validation accuracy:		88.15 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.322999
  validation loss:		0.413822
  validation accuracy:		86.96 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.319383
  validation loss:		0.384187
  validation accuracy:		88.04 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.328490
  validation loss:		0.377354
  validation accuracy:		88.26 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.329186
  validation loss:		0.403873
  validation accuracy:		87.93 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.326547
  validation loss:		0.395496
  validation accuracy:		87.93 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.317942
  validation loss:		0.380579
  validation accuracy:		88.37 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.320728
  validation loss:		0.421420
  validation accuracy:		86.96 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.325787
  validation loss:		0.414343
  validation accuracy:		87.07 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.322005
  validation loss:		0.366471
  validation accuracy:		88.04 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.326752
  validation loss:		0.393429
  validation accuracy:		87.50 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.338518
  validation loss:		0.375794
  validation accuracy:		88.59 %
Epoch 464 of 2000 took 0.036s
  training loss:		0.324320
  validation loss:		0.392684
  validation accuracy:		87.72 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.321243
  validation loss:		0.393389
  validation accuracy:		87.93 %
Epoch 466 of 2000 took 0.036s
  training loss:		0.326504
  validation loss:		0.394936
  validation accuracy:		87.50 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.320391
  validation loss:		0.385462
  validation accuracy:		87.93 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.332644
  validation loss:		0.406821
  validation accuracy:		87.07 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.315299
  validation loss:		0.409638
  validation accuracy:		87.07 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.328204
  validation loss:		0.409302
  validation accuracy:		87.17 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.327259
  validation loss:		0.390527
  validation accuracy:		88.04 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.329345
  validation loss:		0.382058
  validation accuracy:		88.59 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.319075
  validation loss:		0.430598
  validation accuracy:		86.41 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.318250
  validation loss:		0.438199
  validation accuracy:		86.41 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.331250
  validation loss:		0.397198
  validation accuracy:		87.39 %
Epoch 476 of 2000 took 0.036s
  training loss:		0.320275
  validation loss:		0.387287
  validation accuracy:		87.83 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.325083
  validation loss:		0.437633
  validation accuracy:		86.30 %
Epoch 478 of 2000 took 0.037s
  training loss:		0.320106
  validation loss:		0.390735
  validation accuracy:		87.72 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.318860
  validation loss:		0.371244
  validation accuracy:		88.26 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.325157
  validation loss:		0.402673
  validation accuracy:		87.83 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.314883
  validation loss:		0.396333
  validation accuracy:		87.83 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.321704
  validation loss:		0.400394
  validation accuracy:		87.28 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.311397
  validation loss:		0.450666
  validation accuracy:		85.65 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.327794
  validation loss:		0.415990
  validation accuracy:		86.63 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.323430
  validation loss:		0.414100
  validation accuracy:		86.52 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.321419
  validation loss:		0.391487
  validation accuracy:		88.15 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.333143
  validation loss:		0.393852
  validation accuracy:		87.83 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.320511
  validation loss:		0.391173
  validation accuracy:		88.15 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.320910
  validation loss:		0.379047
  validation accuracy:		88.04 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.320736
  validation loss:		0.407581
  validation accuracy:		87.17 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.321780
  validation loss:		0.388831
  validation accuracy:		88.26 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.329541
  validation loss:		0.409744
  validation accuracy:		87.39 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.328376
  validation loss:		0.380978
  validation accuracy:		87.93 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.320006
  validation loss:		0.407535
  validation accuracy:		86.85 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.316100
  validation loss:		0.387637
  validation accuracy:		87.93 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.319054
  validation loss:		0.393913
  validation accuracy:		87.93 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.317668
  validation loss:		0.398416
  validation accuracy:		87.50 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.328381
  validation loss:		0.414623
  validation accuracy:		87.39 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.322936
  validation loss:		0.397870
  validation accuracy:		87.72 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.317988
  validation loss:		0.381818
  validation accuracy:		88.59 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.321859
  validation loss:		0.453151
  validation accuracy:		85.54 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.326386
  validation loss:		0.412770
  validation accuracy:		87.50 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.321390
  validation loss:		0.378235
  validation accuracy:		88.26 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.323456
  validation loss:		0.395514
  validation accuracy:		87.61 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.318122
  validation loss:		0.384686
  validation accuracy:		88.15 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.317213
  validation loss:		0.415435
  validation accuracy:		86.96 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.319700
  validation loss:		0.382326
  validation accuracy:		88.37 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.318431
  validation loss:		0.388612
  validation accuracy:		88.37 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.319428
  validation loss:		0.368335
  validation accuracy:		88.26 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.320992
  validation loss:		0.408438
  validation accuracy:		86.85 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.320453
  validation loss:		0.440957
  validation accuracy:		85.87 %
Epoch 512 of 2000 took 0.036s
  training loss:		0.330563
  validation loss:		0.416132
  validation accuracy:		87.07 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.322276
  validation loss:		0.377953
  validation accuracy:		88.37 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.317910
  validation loss:		0.379133
  validation accuracy:		88.04 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.319736
  validation loss:		0.383401
  validation accuracy:		88.04 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.324744
  validation loss:		0.407571
  validation accuracy:		87.07 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.318122
  validation loss:		0.400782
  validation accuracy:		87.07 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.321914
  validation loss:		0.387656
  validation accuracy:		88.15 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.318612
  validation loss:		0.400391
  validation accuracy:		87.50 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.325397
  validation loss:		0.375052
  validation accuracy:		88.04 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.321855
  validation loss:		0.393739
  validation accuracy:		87.83 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.323039
  validation loss:		0.406599
  validation accuracy:		87.28 %
Epoch 523 of 2000 took 0.036s
  training loss:		0.323904
  validation loss:		0.398756
  validation accuracy:		87.72 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.322351
  validation loss:		0.388819
  validation accuracy:		88.15 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.321489
  validation loss:		0.403082
  validation accuracy:		88.04 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.325359
  validation loss:		0.390128
  validation accuracy:		87.93 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.323089
  validation loss:		0.394955
  validation accuracy:		87.72 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.317966
  validation loss:		0.372977
  validation accuracy:		88.15 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.316243
  validation loss:		0.375515
  validation accuracy:		88.15 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.320000
  validation loss:		0.429690
  validation accuracy:		86.52 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.317677
  validation loss:		0.401588
  validation accuracy:		87.39 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.324997
  validation loss:		0.424261
  validation accuracy:		86.96 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.327481
  validation loss:		0.389729
  validation accuracy:		88.04 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.329373
  validation loss:		0.395243
  validation accuracy:		87.61 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.319148
  validation loss:		0.406215
  validation accuracy:		87.28 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.321782
  validation loss:		0.379904
  validation accuracy:		88.26 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.318952
  validation loss:		0.407920
  validation accuracy:		87.39 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.314041
  validation loss:		0.426077
  validation accuracy:		86.63 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.322128
  validation loss:		0.377023
  validation accuracy:		88.04 %
Epoch 540 of 2000 took 0.036s
  training loss:		0.321446
  validation loss:		0.435253
  validation accuracy:		86.20 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.322341
  validation loss:		0.414967
  validation accuracy:		87.17 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.314619
  validation loss:		0.418585
  validation accuracy:		86.96 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.322818
  validation loss:		0.383730
  validation accuracy:		88.15 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.335721
  validation loss:		0.445793
  validation accuracy:		85.65 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.316527
  validation loss:		0.385547
  validation accuracy:		87.83 %
Epoch 546 of 2000 took 0.036s
  training loss:		0.320489
  validation loss:		0.381578
  validation accuracy:		88.15 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.312851
  validation loss:		0.400839
  validation accuracy:		87.39 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.322599
  validation loss:		0.411602
  validation accuracy:		87.28 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.321580
  validation loss:		0.386667
  validation accuracy:		87.83 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.317504
  validation loss:		0.389088
  validation accuracy:		87.93 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.319511
  validation loss:		0.417419
  validation accuracy:		86.96 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.319126
  validation loss:		0.419658
  validation accuracy:		86.96 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.316720
  validation loss:		0.385400
  validation accuracy:		88.15 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.321030
  validation loss:		0.393737
  validation accuracy:		87.72 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.324778
  validation loss:		0.425157
  validation accuracy:		86.74 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.320996
  validation loss:		0.375477
  validation accuracy:		88.26 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.313121
  validation loss:		0.396880
  validation accuracy:		88.37 %
Epoch 558 of 2000 took 0.036s
  training loss:		0.318805
  validation loss:		0.387794
  validation accuracy:		88.04 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.318134
  validation loss:		0.392140
  validation accuracy:		87.93 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.299492
  validation loss:		0.376714
  validation accuracy:		88.26 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.321877
  validation loss:		0.414642
  validation accuracy:		87.17 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.319753
  validation loss:		0.395110
  validation accuracy:		87.72 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.317947
  validation loss:		0.400871
  validation accuracy:		87.39 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.317733
  validation loss:		0.420781
  validation accuracy:		87.17 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.318780
  validation loss:		0.391061
  validation accuracy:		87.93 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.319469
  validation loss:		0.381710
  validation accuracy:		88.48 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.325074
  validation loss:		0.398265
  validation accuracy:		87.50 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.320209
  validation loss:		0.375916
  validation accuracy:		88.26 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.323204
  validation loss:		0.386958
  validation accuracy:		88.26 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.316495
  validation loss:		0.411553
  validation accuracy:		86.96 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.320767
  validation loss:		0.395453
  validation accuracy:		88.04 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.326395
  validation loss:		0.400124
  validation accuracy:		87.83 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.308758
  validation loss:		0.405910
  validation accuracy:		87.17 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.326070
  validation loss:		0.393349
  validation accuracy:		87.72 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.322040
  validation loss:		0.390006
  validation accuracy:		88.04 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.319394
  validation loss:		0.428088
  validation accuracy:		86.63 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.323737
  validation loss:		0.385151
  validation accuracy:		87.93 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.318215
  validation loss:		0.390142
  validation accuracy:		87.83 %
Epoch 579 of 2000 took 0.036s
  training loss:		0.320447
  validation loss:		0.399507
  validation accuracy:		87.39 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.316146
  validation loss:		0.386244
  validation accuracy:		88.15 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.320835
  validation loss:		0.375727
  validation accuracy:		88.59 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.325094
  validation loss:		0.400597
  validation accuracy:		87.61 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.324290
  validation loss:		0.384292
  validation accuracy:		88.15 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.314174
  validation loss:		0.398282
  validation accuracy:		87.61 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.320771
  validation loss:		0.383451
  validation accuracy:		87.93 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.317514
  validation loss:		0.402099
  validation accuracy:		87.28 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.319179
  validation loss:		0.428500
  validation accuracy:		86.74 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.312451
  validation loss:		0.418357
  validation accuracy:		87.17 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.317606
  validation loss:		0.389816
  validation accuracy:		87.93 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.319545
  validation loss:		0.423297
  validation accuracy:		86.52 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.313499
  validation loss:		0.392156
  validation accuracy:		87.83 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.314982
  validation loss:		0.407822
  validation accuracy:		87.07 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.313356
  validation loss:		0.413508
  validation accuracy:		87.07 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.319269
  validation loss:		0.407575
  validation accuracy:		87.50 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.320504
  validation loss:		0.386624
  validation accuracy:		88.04 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.324899
  validation loss:		0.397751
  validation accuracy:		87.72 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.321025
  validation loss:		0.393218
  validation accuracy:		87.72 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.319938
  validation loss:		0.425573
  validation accuracy:		86.96 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.316104
  validation loss:		0.389756
  validation accuracy:		87.83 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.314901
  validation loss:		0.392140
  validation accuracy:		87.83 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.315939
  validation loss:		0.403807
  validation accuracy:		87.72 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.311169
  validation loss:		0.386563
  validation accuracy:		88.04 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.315427
  validation loss:		0.377736
  validation accuracy:		88.04 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.307415
  validation loss:		0.384703
  validation accuracy:		88.15 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.306742
  validation loss:		0.399039
  validation accuracy:		87.61 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.324561
  validation loss:		0.412948
  validation accuracy:		87.07 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.318003
  validation loss:		0.385450
  validation accuracy:		88.15 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.313544
  validation loss:		0.391355
  validation accuracy:		87.72 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.319826
  validation loss:		0.373105
  validation accuracy:		88.37 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.321961
  validation loss:		0.383022
  validation accuracy:		88.26 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.316548
  validation loss:		0.392632
  validation accuracy:		87.83 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.314822
  validation loss:		0.411492
  validation accuracy:		87.07 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.315426
  validation loss:		0.403009
  validation accuracy:		87.39 %
Epoch 614 of 2000 took 0.036s
  training loss:		0.310473
  validation loss:		0.417440
  validation accuracy:		87.17 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.311592
  validation loss:		0.388774
  validation accuracy:		88.37 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.310791
  validation loss:		0.408384
  validation accuracy:		87.39 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.323779
  validation loss:		0.394914
  validation accuracy:		88.04 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.310577
  validation loss:		0.396015
  validation accuracy:		87.50 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.317587
  validation loss:		0.379208
  validation accuracy:		88.15 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.320622
  validation loss:		0.404198
  validation accuracy:		87.39 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.312300
  validation loss:		0.384515
  validation accuracy:		88.26 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.323342
  validation loss:		0.401266
  validation accuracy:		87.28 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.316051
  validation loss:		0.433030
  validation accuracy:		86.20 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.312659
  validation loss:		0.385544
  validation accuracy:		87.93 %
Epoch 625 of 2000 took 0.036s
  training loss:		0.316658
  validation loss:		0.393519
  validation accuracy:		87.93 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.312717
  validation loss:		0.378756
  validation accuracy:		88.15 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.318313
  validation loss:		0.396392
  validation accuracy:		87.93 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.312150
  validation loss:		0.443820
  validation accuracy:		85.87 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.321495
  validation loss:		0.387781
  validation accuracy:		88.04 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.320467
  validation loss:		0.390704
  validation accuracy:		87.72 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.318462
  validation loss:		0.387548
  validation accuracy:		88.04 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.312327
  validation loss:		0.400197
  validation accuracy:		87.61 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.302954
  validation loss:		0.413346
  validation accuracy:		87.17 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.309029
  validation loss:		0.383781
  validation accuracy:		88.15 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.319432
  validation loss:		0.402678
  validation accuracy:		87.93 %
Epoch 636 of 2000 took 0.036s
  training loss:		0.315977
  validation loss:		0.397236
  validation accuracy:		87.61 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.318301
  validation loss:		0.388776
  validation accuracy:		88.26 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.312968
  validation loss:		0.404772
  validation accuracy:		87.28 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.316560
  validation loss:		0.382829
  validation accuracy:		88.04 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.312450
  validation loss:		0.404006
  validation accuracy:		87.39 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.309704
  validation loss:		0.387178
  validation accuracy:		87.83 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.318289
  validation loss:		0.387351
  validation accuracy:		87.93 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.313443
  validation loss:		0.395916
  validation accuracy:		88.26 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.317285
  validation loss:		0.403001
  validation accuracy:		87.50 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.308151
  validation loss:		0.392792
  validation accuracy:		87.61 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.315821
  validation loss:		0.384478
  validation accuracy:		88.04 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.310179
  validation loss:		0.391063
  validation accuracy:		87.61 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.310333
  validation loss:		0.396205
  validation accuracy:		87.61 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.314766
  validation loss:		0.380731
  validation accuracy:		88.37 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.319994
  validation loss:		0.431540
  validation accuracy:		86.30 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.315549
  validation loss:		0.385712
  validation accuracy:		87.93 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.316582
  validation loss:		0.382486
  validation accuracy:		87.93 %
Epoch 653 of 2000 took 0.036s
  training loss:		0.317115
  validation loss:		0.419807
  validation accuracy:		86.96 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.313210
  validation loss:		0.389345
  validation accuracy:		87.83 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.316709
  validation loss:		0.377118
  validation accuracy:		87.83 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.320473
  validation loss:		0.400776
  validation accuracy:		87.50 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.316423
  validation loss:		0.385322
  validation accuracy:		88.04 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.313835
  validation loss:		0.393138
  validation accuracy:		87.83 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.315299
  validation loss:		0.393030
  validation accuracy:		88.26 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.308753
  validation loss:		0.430679
  validation accuracy:		86.30 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.307901
  validation loss:		0.399748
  validation accuracy:		87.72 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.307965
  validation loss:		0.397210
  validation accuracy:		87.83 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.310465
  validation loss:		0.392972
  validation accuracy:		87.83 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.316974
  validation loss:		0.395518
  validation accuracy:		87.50 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.318635
  validation loss:		0.409912
  validation accuracy:		87.28 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.313392
  validation loss:		0.394700
  validation accuracy:		87.83 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.314535
  validation loss:		0.402078
  validation accuracy:		87.50 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.319345
  validation loss:		0.402998
  validation accuracy:		87.50 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.320539
  validation loss:		0.452225
  validation accuracy:		85.65 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.314075
  validation loss:		0.418323
  validation accuracy:		87.39 %
Epoch 671 of 2000 took 0.036s
  training loss:		0.307897
  validation loss:		0.385700
  validation accuracy:		88.04 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.315503
  validation loss:		0.396436
  validation accuracy:		87.61 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.312364
  validation loss:		0.386832
  validation accuracy:		88.15 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.312109
  validation loss:		0.398037
  validation accuracy:		87.83 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.316775
  validation loss:		0.434097
  validation accuracy:		85.98 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.313227
  validation loss:		0.387971
  validation accuracy:		87.72 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.324817
  validation loss:		0.420690
  validation accuracy:		87.17 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.309292
  validation loss:		0.412669
  validation accuracy:		87.07 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.316175
  validation loss:		0.403778
  validation accuracy:		87.39 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.305869
  validation loss:		0.391546
  validation accuracy:		87.72 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.318168
  validation loss:		0.379246
  validation accuracy:		88.26 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.324791
  validation loss:		0.408679
  validation accuracy:		87.28 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.312213
  validation loss:		0.407060
  validation accuracy:		87.50 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.307622
  validation loss:		0.410767
  validation accuracy:		86.96 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.311313
  validation loss:		0.388476
  validation accuracy:		87.50 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.316623
  validation loss:		0.389979
  validation accuracy:		87.93 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.317817
  validation loss:		0.406410
  validation accuracy:		87.50 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.316556
  validation loss:		0.386076
  validation accuracy:		87.72 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.312722
  validation loss:		0.400156
  validation accuracy:		87.39 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.311674
  validation loss:		0.394747
  validation accuracy:		87.83 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.314630
  validation loss:		0.407714
  validation accuracy:		87.61 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.309974
  validation loss:		0.405336
  validation accuracy:		87.83 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.305565
  validation loss:		0.399860
  validation accuracy:		87.50 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.311089
  validation loss:		0.378138
  validation accuracy:		88.15 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.318345
  validation loss:		0.434622
  validation accuracy:		86.20 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.319592
  validation loss:		0.381327
  validation accuracy:		87.83 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.313797
  validation loss:		0.419768
  validation accuracy:		86.96 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.314258
  validation loss:		0.386709
  validation accuracy:		88.15 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.318305
  validation loss:		0.401106
  validation accuracy:		87.93 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.313680
  validation loss:		0.402694
  validation accuracy:		88.04 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.309861
  validation loss:		0.479399
  validation accuracy:		85.00 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.311979
  validation loss:		0.394707
  validation accuracy:		88.15 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.316275
  validation loss:		0.403045
  validation accuracy:		87.72 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.313983
  validation loss:		0.385155
  validation accuracy:		87.83 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.310017
  validation loss:		0.403546
  validation accuracy:		87.72 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.315925
  validation loss:		0.419631
  validation accuracy:		87.17 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.307674
  validation loss:		0.413824
  validation accuracy:		87.07 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.317459
  validation loss:		0.386907
  validation accuracy:		88.04 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.309934
  validation loss:		0.401535
  validation accuracy:		87.39 %
Epoch 710 of 2000 took 0.036s
  training loss:		0.309458
  validation loss:		0.385895
  validation accuracy:		88.26 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.312660
  validation loss:		0.398015
  validation accuracy:		88.04 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.310758
  validation loss:		0.401694
  validation accuracy:		87.72 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.317117
  validation loss:		0.396766
  validation accuracy:		87.72 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.315025
  validation loss:		0.396170
  validation accuracy:		88.04 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.312109
  validation loss:		0.406004
  validation accuracy:		87.39 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.308781
  validation loss:		0.412006
  validation accuracy:		87.39 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.308242
  validation loss:		0.383604
  validation accuracy:		88.04 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.318999
  validation loss:		0.405117
  validation accuracy:		87.72 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.315976
  validation loss:		0.392709
  validation accuracy:		87.93 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.312323
  validation loss:		0.392312
  validation accuracy:		87.61 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.307217
  validation loss:		0.418510
  validation accuracy:		87.17 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.313951
  validation loss:		0.423182
  validation accuracy:		86.96 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.310008
  validation loss:		0.397313
  validation accuracy:		87.50 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.320825
  validation loss:		0.413699
  validation accuracy:		87.17 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.331058
  validation loss:		0.398170
  validation accuracy:		87.50 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.310165
  validation loss:		0.395646
  validation accuracy:		87.83 %
Epoch 727 of 2000 took 0.036s
  training loss:		0.316235
  validation loss:		0.387856
  validation accuracy:		87.61 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.309329
  validation loss:		0.403974
  validation accuracy:		87.39 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.304949
  validation loss:		0.436100
  validation accuracy:		86.09 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.316416
  validation loss:		0.386812
  validation accuracy:		87.83 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.314979
  validation loss:		0.409176
  validation accuracy:		87.50 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.314635
  validation loss:		0.403818
  validation accuracy:		87.61 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.312318
  validation loss:		0.395091
  validation accuracy:		87.61 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.312382
  validation loss:		0.414535
  validation accuracy:		87.39 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.306508
  validation loss:		0.398690
  validation accuracy:		87.93 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.300909
  validation loss:		0.395864
  validation accuracy:		87.83 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.312743
  validation loss:		0.392589
  validation accuracy:		87.83 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.311362
  validation loss:		0.425522
  validation accuracy:		86.63 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.308794
  validation loss:		0.389676
  validation accuracy:		87.72 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.307821
  validation loss:		0.418198
  validation accuracy:		87.28 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.312095
  validation loss:		0.405676
  validation accuracy:		87.72 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.308596
  validation loss:		0.385401
  validation accuracy:		88.15 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.306376
  validation loss:		0.415658
  validation accuracy:		87.28 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.313543
  validation loss:		0.400486
  validation accuracy:		88.04 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.309157
  validation loss:		0.470572
  validation accuracy:		85.54 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.315412
  validation loss:		0.405642
  validation accuracy:		87.50 %
Epoch 747 of 2000 took 0.036s
  training loss:		0.313539
  validation loss:		0.382951
  validation accuracy:		88.04 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.308766
  validation loss:		0.395698
  validation accuracy:		87.61 %
Epoch 749 of 2000 took 0.036s
  training loss:		0.310721
  validation loss:		0.398636
  validation accuracy:		87.72 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.314386
  validation loss:		0.405807
  validation accuracy:		87.83 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.313451
  validation loss:		0.391449
  validation accuracy:		87.61 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.314685
  validation loss:		0.380924
  validation accuracy:		87.83 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.310795
  validation loss:		0.407272
  validation accuracy:		87.39 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.306802
  validation loss:		0.399288
  validation accuracy:		88.15 %
Epoch 755 of 2000 took 0.036s
  training loss:		0.314310
  validation loss:		0.421176
  validation accuracy:		86.85 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.318975
  validation loss:		0.385006
  validation accuracy:		87.83 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.318050
  validation loss:		0.426605
  validation accuracy:		86.63 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.313368
  validation loss:		0.403397
  validation accuracy:		87.39 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.315054
  validation loss:		0.431039
  validation accuracy:		86.74 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.307614
  validation loss:		0.406417
  validation accuracy:		87.17 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.307315
  validation loss:		0.411206
  validation accuracy:		87.72 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.314557
  validation loss:		0.415805
  validation accuracy:		87.17 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.313915
  validation loss:		0.387692
  validation accuracy:		87.72 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.307962
  validation loss:		0.390983
  validation accuracy:		87.93 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.308024
  validation loss:		0.450833
  validation accuracy:		85.65 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.314295
  validation loss:		0.397464
  validation accuracy:		88.04 %
Epoch 767 of 2000 took 0.036s
  training loss:		0.308731
  validation loss:		0.386302
  validation accuracy:		87.61 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.313855
  validation loss:		0.399101
  validation accuracy:		87.83 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.316726
  validation loss:		0.418754
  validation accuracy:		87.50 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.317492
  validation loss:		0.401563
  validation accuracy:		87.50 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.301991
  validation loss:		0.381084
  validation accuracy:		88.15 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.316964
  validation loss:		0.387882
  validation accuracy:		87.83 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.316603
  validation loss:		0.407550
  validation accuracy:		87.07 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.320379
  validation loss:		0.425632
  validation accuracy:		86.41 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.306264
  validation loss:		0.394385
  validation accuracy:		87.61 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.310240
  validation loss:		0.427942
  validation accuracy:		87.28 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.314155
  validation loss:		0.395200
  validation accuracy:		87.61 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.312130
  validation loss:		0.410462
  validation accuracy:		87.61 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.307470
  validation loss:		0.438432
  validation accuracy:		86.09 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.307996
  validation loss:		0.394058
  validation accuracy:		87.50 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.313696
  validation loss:		0.403149
  validation accuracy:		87.50 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.308440
  validation loss:		0.399600
  validation accuracy:		87.72 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.310986
  validation loss:		0.416402
  validation accuracy:		87.17 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.312004
  validation loss:		0.427127
  validation accuracy:		86.41 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.308722
  validation loss:		0.403020
  validation accuracy:		87.72 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.302152
  validation loss:		0.408282
  validation accuracy:		87.39 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.314691
  validation loss:		0.383669
  validation accuracy:		87.72 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.310835
  validation loss:		0.401837
  validation accuracy:		88.04 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.304819
  validation loss:		0.384079
  validation accuracy:		87.72 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.307319
  validation loss:		0.386708
  validation accuracy:		87.93 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.309258
  validation loss:		0.480927
  validation accuracy:		85.33 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.317347
  validation loss:		0.396778
  validation accuracy:		88.15 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.312918
  validation loss:		0.416956
  validation accuracy:		87.50 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.307440
  validation loss:		0.401297
  validation accuracy:		88.15 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.312510
  validation loss:		0.394350
  validation accuracy:		87.93 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.313859
  validation loss:		0.429235
  validation accuracy:		86.74 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.309362
  validation loss:		0.392292
  validation accuracy:		87.61 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.314812
  validation loss:		0.409749
  validation accuracy:		87.83 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.308428
  validation loss:		0.392559
  validation accuracy:		87.50 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.313502
  validation loss:		0.404054
  validation accuracy:		87.50 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.309384
  validation loss:		0.392137
  validation accuracy:		87.83 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.305071
  validation loss:		0.412795
  validation accuracy:		87.39 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.315234
  validation loss:		0.421995
  validation accuracy:		87.17 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.317702
  validation loss:		0.398931
  validation accuracy:		87.50 %
Epoch 805 of 2000 took 0.036s
  training loss:		0.310427
  validation loss:		0.401255
  validation accuracy:		87.93 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.306941
  validation loss:		0.389345
  validation accuracy:		87.39 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.311529
  validation loss:		0.398753
  validation accuracy:		88.04 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.313652
  validation loss:		0.407395
  validation accuracy:		87.28 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.311813
  validation loss:		0.388639
  validation accuracy:		87.50 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.314941
  validation loss:		0.407270
  validation accuracy:		87.83 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.319250
  validation loss:		0.406613
  validation accuracy:		87.50 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.308690
  validation loss:		0.408318
  validation accuracy:		87.50 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.311494
  validation loss:		0.432572
  validation accuracy:		86.74 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.312115
  validation loss:		0.390955
  validation accuracy:		87.61 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.308014
  validation loss:		0.402655
  validation accuracy:		87.83 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.312295
  validation loss:		0.408388
  validation accuracy:		87.28 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.308069
  validation loss:		0.409530
  validation accuracy:		87.50 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.314120
  validation loss:		0.423937
  validation accuracy:		87.17 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.313138
  validation loss:		0.411925
  validation accuracy:		87.39 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.319751
  validation loss:		0.406395
  validation accuracy:		87.72 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.311558
  validation loss:		0.405858
  validation accuracy:		87.61 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.308807
  validation loss:		0.405070
  validation accuracy:		87.28 %
Epoch 823 of 2000 took 0.036s
  training loss:		0.312376
  validation loss:		0.383260
  validation accuracy:		87.93 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.319711
  validation loss:		0.398285
  validation accuracy:		87.61 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.306148
  validation loss:		0.387556
  validation accuracy:		87.93 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.315219
  validation loss:		0.385713
  validation accuracy:		87.93 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.312593
  validation loss:		0.402241
  validation accuracy:		87.61 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.306361
  validation loss:		0.404506
  validation accuracy:		87.93 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.305840
  validation loss:		0.416164
  validation accuracy:		87.39 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.311799
  validation loss:		0.389236
  validation accuracy:		87.83 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.303421
  validation loss:		0.392591
  validation accuracy:		87.83 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.307323
  validation loss:		0.397736
  validation accuracy:		87.83 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.308079
  validation loss:		0.408918
  validation accuracy:		87.39 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.310457
  validation loss:		0.431804
  validation accuracy:		86.30 %
Epoch 835 of 2000 took 0.036s
  training loss:		0.307725
  validation loss:		0.413870
  validation accuracy:		87.17 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.302677
  validation loss:		0.424427
  validation accuracy:		86.96 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.315369
  validation loss:		0.406834
  validation accuracy:		87.61 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.309130
  validation loss:		0.428422
  validation accuracy:		86.30 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.315170
  validation loss:		0.396691
  validation accuracy:		87.39 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.309369
  validation loss:		0.401118
  validation accuracy:		87.61 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.307566
  validation loss:		0.413053
  validation accuracy:		87.28 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.320894
  validation loss:		0.411274
  validation accuracy:		86.85 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.312501
  validation loss:		0.388663
  validation accuracy:		87.72 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.313294
  validation loss:		0.401647
  validation accuracy:		87.72 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.314146
  validation loss:		0.401429
  validation accuracy:		87.61 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.305821
  validation loss:		0.389827
  validation accuracy:		88.04 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.309866
  validation loss:		0.418171
  validation accuracy:		87.07 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.308106
  validation loss:		0.430832
  validation accuracy:		86.09 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.309550
  validation loss:		0.394926
  validation accuracy:		87.50 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.317425
  validation loss:		0.398117
  validation accuracy:		87.61 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.313205
  validation loss:		0.387092
  validation accuracy:		87.50 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.310383
  validation loss:		0.392502
  validation accuracy:		87.61 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.305979
  validation loss:		0.397418
  validation accuracy:		87.72 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.305054
  validation loss:		0.385317
  validation accuracy:		87.72 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.312835
  validation loss:		0.395798
  validation accuracy:		87.83 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.311251
  validation loss:		0.402074
  validation accuracy:		87.61 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.307437
  validation loss:		0.397332
  validation accuracy:		87.93 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.310578
  validation loss:		0.422155
  validation accuracy:		86.63 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.312794
  validation loss:		0.377959
  validation accuracy:		87.61 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.316266
  validation loss:		0.423546
  validation accuracy:		86.85 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.315592
  validation loss:		0.396210
  validation accuracy:		87.61 %
Epoch 862 of 2000 took 0.036s
  training loss:		0.308583
  validation loss:		0.399592
  validation accuracy:		87.83 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.312349
  validation loss:		0.400206
  validation accuracy:		87.50 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.302116
  validation loss:		0.388790
  validation accuracy:		88.04 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.310404
  validation loss:		0.408116
  validation accuracy:		87.72 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.308997
  validation loss:		0.419401
  validation accuracy:		87.07 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.297640
  validation loss:		0.409082
  validation accuracy:		87.83 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.302869
  validation loss:		0.391192
  validation accuracy:		87.72 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.303877
  validation loss:		0.392227
  validation accuracy:		87.93 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.309826
  validation loss:		0.403960
  validation accuracy:		87.50 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.310928
  validation loss:		0.405066
  validation accuracy:		87.50 %
Epoch 872 of 2000 took 0.037s
  training loss:		0.305846
  validation loss:		0.428525
  validation accuracy:		85.87 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.307342
  validation loss:		0.426273
  validation accuracy:		86.74 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.305566
  validation loss:		0.405505
  validation accuracy:		87.61 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.303610
  validation loss:		0.425889
  validation accuracy:		86.74 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.315437
  validation loss:		0.398107
  validation accuracy:		87.72 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.311421
  validation loss:		0.386797
  validation accuracy:		87.93 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.307645
  validation loss:		0.416338
  validation accuracy:		87.28 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.310855
  validation loss:		0.403197
  validation accuracy:		87.39 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.311221
  validation loss:		0.389784
  validation accuracy:		87.83 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.309997
  validation loss:		0.381731
  validation accuracy:		87.50 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.309480
  validation loss:		0.401060
  validation accuracy:		87.61 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.307656
  validation loss:		0.408888
  validation accuracy:		87.28 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.309743
  validation loss:		0.385085
  validation accuracy:		87.83 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.310935
  validation loss:		0.405399
  validation accuracy:		87.50 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.303059
  validation loss:		0.415912
  validation accuracy:		86.96 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.308366
  validation loss:		0.415272
  validation accuracy:		87.07 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.321043
  validation loss:		0.419833
  validation accuracy:		87.07 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.311015
  validation loss:		0.390904
  validation accuracy:		87.83 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.306479
  validation loss:		0.410986
  validation accuracy:		86.85 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.298162
  validation loss:		0.384881
  validation accuracy:		87.83 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.309516
  validation loss:		0.434213
  validation accuracy:		86.20 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.303300
  validation loss:		0.424028
  validation accuracy:		87.07 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.299331
  validation loss:		0.408309
  validation accuracy:		87.72 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.305963
  validation loss:		0.415046
  validation accuracy:		87.39 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.313866
  validation loss:		0.392621
  validation accuracy:		87.61 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.309428
  validation loss:		0.386596
  validation accuracy:		87.83 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.311980
  validation loss:		0.406462
  validation accuracy:		87.39 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.316685
  validation loss:		0.418515
  validation accuracy:		86.96 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.306194
  validation loss:		0.409062
  validation accuracy:		87.07 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.303331
  validation loss:		0.401722
  validation accuracy:		87.61 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.301257
  validation loss:		0.391440
  validation accuracy:		88.26 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.303179
  validation loss:		0.419506
  validation accuracy:		86.85 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.312035
  validation loss:		0.398182
  validation accuracy:		87.72 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.308242
  validation loss:		0.404654
  validation accuracy:		87.17 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.304430
  validation loss:		0.387091
  validation accuracy:		87.93 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.307774
  validation loss:		0.391722
  validation accuracy:		87.83 %
Epoch 908 of 2000 took 0.036s
  training loss:		0.306390
  validation loss:		0.392161
  validation accuracy:		87.83 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.311791
  validation loss:		0.404828
  validation accuracy:		87.17 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.310661
  validation loss:		0.401833
  validation accuracy:		86.96 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.308148
  validation loss:		0.401834
  validation accuracy:		87.28 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.310851
  validation loss:		0.405577
  validation accuracy:		87.28 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.305634
  validation loss:		0.416105
  validation accuracy:		87.28 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.311408
  validation loss:		0.431459
  validation accuracy:		86.52 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.305568
  validation loss:		0.394461
  validation accuracy:		87.83 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.303453
  validation loss:		0.421202
  validation accuracy:		86.85 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.309460
  validation loss:		0.434947
  validation accuracy:		86.85 %
Epoch 918 of 2000 took 0.036s
  training loss:		0.306650
  validation loss:		0.406018
  validation accuracy:		87.83 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.310119
  validation loss:		0.412626
  validation accuracy:		87.39 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.303357
  validation loss:		0.416360
  validation accuracy:		87.28 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.314655
  validation loss:		0.465384
  validation accuracy:		85.65 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.315738
  validation loss:		0.391341
  validation accuracy:		87.83 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.303751
  validation loss:		0.393722
  validation accuracy:		87.83 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.308881
  validation loss:		0.421172
  validation accuracy:		87.28 %
Epoch 925 of 2000 took 0.036s
  training loss:		0.307185
  validation loss:		0.395877
  validation accuracy:		87.28 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.308880
  validation loss:		0.439650
  validation accuracy:		85.54 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.312792
  validation loss:		0.456860
  validation accuracy:		85.22 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.310470
  validation loss:		0.419118
  validation accuracy:		87.07 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.306303
  validation loss:		0.423416
  validation accuracy:		86.74 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.308354
  validation loss:		0.422122
  validation accuracy:		87.17 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.310355
  validation loss:		0.391599
  validation accuracy:		87.72 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.311516
  validation loss:		0.398286
  validation accuracy:		88.04 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.309839
  validation loss:		0.474800
  validation accuracy:		85.22 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.310819
  validation loss:		0.411689
  validation accuracy:		87.28 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.311319
  validation loss:		0.397458
  validation accuracy:		87.72 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.313042
  validation loss:		0.376256
  validation accuracy:		87.61 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.311504
  validation loss:		0.409999
  validation accuracy:		87.50 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.306984
  validation loss:		0.425902
  validation accuracy:		86.85 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.305936
  validation loss:		0.394845
  validation accuracy:		87.28 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.302291
  validation loss:		0.399288
  validation accuracy:		87.28 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.311119
  validation loss:		0.421961
  validation accuracy:		86.85 %
Epoch 942 of 2000 took 0.036s
  training loss:		0.312415
  validation loss:		0.392953
  validation accuracy:		88.04 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.301549
  validation loss:		0.396022
  validation accuracy:		87.61 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.309895
  validation loss:		0.401640
  validation accuracy:		87.72 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.314605
  validation loss:		0.388115
  validation accuracy:		87.93 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.312607
  validation loss:		0.400770
  validation accuracy:		87.83 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.307011
  validation loss:		0.409242
  validation accuracy:		87.17 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.307630
  validation loss:		0.390781
  validation accuracy:		87.83 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.305271
  validation loss:		0.411116
  validation accuracy:		87.28 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.311184
  validation loss:		0.409745
  validation accuracy:		87.07 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.314737
  validation loss:		0.418073
  validation accuracy:		87.07 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.306949
  validation loss:		0.405030
  validation accuracy:		87.61 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.309742
  validation loss:		0.397883
  validation accuracy:		87.61 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.305647
  validation loss:		0.448459
  validation accuracy:		85.54 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.310243
  validation loss:		0.388312
  validation accuracy:		87.83 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.308680
  validation loss:		0.390558
  validation accuracy:		87.83 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.304191
  validation loss:		0.392919
  validation accuracy:		88.04 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.311781
  validation loss:		0.411769
  validation accuracy:		86.85 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.307052
  validation loss:		0.390322
  validation accuracy:		87.61 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.311615
  validation loss:		0.426996
  validation accuracy:		86.63 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.307090
  validation loss:		0.426132
  validation accuracy:		86.52 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.310244
  validation loss:		0.407458
  validation accuracy:		87.28 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.306567
  validation loss:		0.421017
  validation accuracy:		87.17 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.316668
  validation loss:		0.405178
  validation accuracy:		87.17 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.310147
  validation loss:		0.407657
  validation accuracy:		87.93 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.307935
  validation loss:		0.417829
  validation accuracy:		87.17 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.305813
  validation loss:		0.393671
  validation accuracy:		87.72 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.298974
  validation loss:		0.383531
  validation accuracy:		87.72 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.308999
  validation loss:		0.399466
  validation accuracy:		87.50 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.310096
  validation loss:		0.391605
  validation accuracy:		87.50 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.309739
  validation loss:		0.390350
  validation accuracy:		87.61 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.304172
  validation loss:		0.385525
  validation accuracy:		87.72 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.309927
  validation loss:		0.401976
  validation accuracy:		87.17 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.308254
  validation loss:		0.415367
  validation accuracy:		86.96 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.304859
  validation loss:		0.400314
  validation accuracy:		87.61 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.307871
  validation loss:		0.449952
  validation accuracy:		85.22 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.305100
  validation loss:		0.399871
  validation accuracy:		87.39 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.308287
  validation loss:		0.425427
  validation accuracy:		86.74 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.311266
  validation loss:		0.419518
  validation accuracy:		86.74 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.300876
  validation loss:		0.386956
  validation accuracy:		87.61 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.293607
  validation loss:		0.390588
  validation accuracy:		87.61 %
Epoch 982 of 2000 took 0.036s
  training loss:		0.308773
  validation loss:		0.418277
  validation accuracy:		87.39 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.312918
  validation loss:		0.389070
  validation accuracy:		87.72 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.310901
  validation loss:		0.437522
  validation accuracy:		85.98 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.307871
  validation loss:		0.401720
  validation accuracy:		87.39 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.304740
  validation loss:		0.408559
  validation accuracy:		86.85 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.306671
  validation loss:		0.436188
  validation accuracy:		85.87 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.309266
  validation loss:		0.418216
  validation accuracy:		87.39 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.302338
  validation loss:		0.409959
  validation accuracy:		87.50 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.309349
  validation loss:		0.397997
  validation accuracy:		87.17 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.295856
  validation loss:		0.394506
  validation accuracy:		87.61 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.312110
  validation loss:		0.403862
  validation accuracy:		87.28 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.305998
  validation loss:		0.408408
  validation accuracy:		87.17 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.300006
  validation loss:		0.416983
  validation accuracy:		87.17 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.309723
  validation loss:		0.389183
  validation accuracy:		87.93 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.304120
  validation loss:		0.418488
  validation accuracy:		87.28 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.298979
  validation loss:		0.422402
  validation accuracy:		86.85 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.305932
  validation loss:		0.424439
  validation accuracy:		87.07 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.302079
  validation loss:		0.405111
  validation accuracy:		87.61 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.306796
  validation loss:		0.413810
  validation accuracy:		87.17 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.306575
  validation loss:		0.393288
  validation accuracy:		87.39 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.304785
  validation loss:		0.385528
  validation accuracy:		87.39 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.310547
  validation loss:		0.463311
  validation accuracy:		85.33 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.308643
  validation loss:		0.401202
  validation accuracy:		87.83 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.305005
  validation loss:		0.423333
  validation accuracy:		86.63 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.304888
  validation loss:		0.443906
  validation accuracy:		85.76 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.306917
  validation loss:		0.395427
  validation accuracy:		87.72 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.308380
  validation loss:		0.400752
  validation accuracy:		87.39 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.303563
  validation loss:		0.410886
  validation accuracy:		87.50 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.313157
  validation loss:		0.405790
  validation accuracy:		87.28 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.306505
  validation loss:		0.401459
  validation accuracy:		87.28 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.307424
  validation loss:		0.413137
  validation accuracy:		87.17 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.299186
  validation loss:		0.403611
  validation accuracy:		87.28 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.299219
  validation loss:		0.433965
  validation accuracy:		85.98 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.305893
  validation loss:		0.404036
  validation accuracy:		87.61 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.301405
  validation loss:		0.432074
  validation accuracy:		85.98 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.304168
  validation loss:		0.392822
  validation accuracy:		87.61 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.310385
  validation loss:		0.426675
  validation accuracy:		86.96 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.309225
  validation loss:		0.423345
  validation accuracy:		86.74 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.312864
  validation loss:		0.427332
  validation accuracy:		86.41 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.309377
  validation loss:		0.414778
  validation accuracy:		86.96 %
Epoch 1022 of 2000 took 0.036s
  training loss:		0.310186
  validation loss:		0.432466
  validation accuracy:		86.52 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.311521
  validation loss:		0.426762
  validation accuracy:		86.52 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.314200
  validation loss:		0.423810
  validation accuracy:		86.52 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.303367
  validation loss:		0.411901
  validation accuracy:		87.17 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.306941
  validation loss:		0.405848
  validation accuracy:		87.72 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.311752
  validation loss:		0.394929
  validation accuracy:		87.50 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.305592
  validation loss:		0.441236
  validation accuracy:		85.76 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.305562
  validation loss:		0.388621
  validation accuracy:		88.37 %
Epoch 1030 of 2000 took 0.036s
  training loss:		0.300353
  validation loss:		0.410288
  validation accuracy:		87.39 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.313359
  validation loss:		0.417295
  validation accuracy:		87.28 %
Epoch 1032 of 2000 took 0.036s
  training loss:		0.299382
  validation loss:		0.420720
  validation accuracy:		86.63 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.303978
  validation loss:		0.402512
  validation accuracy:		87.28 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.311644
  validation loss:		0.420847
  validation accuracy:		86.85 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.305792
  validation loss:		0.400614
  validation accuracy:		87.83 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.295358
  validation loss:		0.449281
  validation accuracy:		85.65 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.305669
  validation loss:		0.431915
  validation accuracy:		86.20 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.307091
  validation loss:		0.424193
  validation accuracy:		87.28 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.309799
  validation loss:		0.374798
  validation accuracy:		87.50 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.308813
  validation loss:		0.380465
  validation accuracy:		87.72 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.307610
  validation loss:		0.439470
  validation accuracy:		86.20 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.308381
  validation loss:		0.408610
  validation accuracy:		87.07 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.299957
  validation loss:		0.419093
  validation accuracy:		87.28 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.298176
  validation loss:		0.401964
  validation accuracy:		87.17 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.307941
  validation loss:		0.418496
  validation accuracy:		87.07 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.309409
  validation loss:		0.402266
  validation accuracy:		87.28 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.310097
  validation loss:		0.422193
  validation accuracy:		86.41 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.313113
  validation loss:		0.403439
  validation accuracy:		87.17 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.307250
  validation loss:		0.393096
  validation accuracy:		87.72 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.299519
  validation loss:		0.437734
  validation accuracy:		86.30 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.302114
  validation loss:		0.399194
  validation accuracy:		87.28 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.301461
  validation loss:		0.406317
  validation accuracy:		87.17 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.303507
  validation loss:		0.387683
  validation accuracy:		87.83 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.299710
  validation loss:		0.422206
  validation accuracy:		87.39 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.309711
  validation loss:		0.403286
  validation accuracy:		87.17 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.308617
  validation loss:		0.407082
  validation accuracy:		87.28 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.304324
  validation loss:		0.406351
  validation accuracy:		87.17 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.304469
  validation loss:		0.404418
  validation accuracy:		87.28 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.292233
  validation loss:		0.408949
  validation accuracy:		87.39 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.303619
  validation loss:		0.410427
  validation accuracy:		87.28 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.309072
  validation loss:		0.392443
  validation accuracy:		87.72 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.308098
  validation loss:		0.399963
  validation accuracy:		87.28 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.304945
  validation loss:		0.401630
  validation accuracy:		87.07 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.305451
  validation loss:		0.421747
  validation accuracy:		86.63 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.306898
  validation loss:		0.399950
  validation accuracy:		87.61 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.313601
  validation loss:		0.409353
  validation accuracy:		87.17 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.303467
  validation loss:		0.396609
  validation accuracy:		87.72 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.304215
  validation loss:		0.426938
  validation accuracy:		86.41 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.295688
  validation loss:		0.432390
  validation accuracy:		86.30 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.303828
  validation loss:		0.418693
  validation accuracy:		86.96 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.305752
  validation loss:		0.413579
  validation accuracy:		87.07 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.298261
  validation loss:		0.415885
  validation accuracy:		87.07 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.309215
  validation loss:		0.416035
  validation accuracy:		87.28 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.296676
  validation loss:		0.389822
  validation accuracy:		87.72 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.310478
  validation loss:		0.387043
  validation accuracy:		87.72 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.303711
  validation loss:		0.425719
  validation accuracy:		86.52 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.310497
  validation loss:		0.420773
  validation accuracy:		86.85 %
Epoch 1078 of 2000 took 0.036s
  training loss:		0.310162
  validation loss:		0.400576
  validation accuracy:		87.39 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.303940
  validation loss:		0.417139
  validation accuracy:		87.39 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.311359
  validation loss:		0.407024
  validation accuracy:		87.50 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.309303
  validation loss:		0.434478
  validation accuracy:		86.09 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.310521
  validation loss:		0.406371
  validation accuracy:		87.28 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.299381
  validation loss:		0.404876
  validation accuracy:		87.17 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.307599
  validation loss:		0.403980
  validation accuracy:		87.39 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.305222
  validation loss:		0.416911
  validation accuracy:		86.96 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.307539
  validation loss:		0.384755
  validation accuracy:		87.72 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.304081
  validation loss:		0.406898
  validation accuracy:		87.39 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.300694
  validation loss:		0.414382
  validation accuracy:		86.85 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.295468
  validation loss:		0.391057
  validation accuracy:		87.61 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.306896
  validation loss:		0.410399
  validation accuracy:		87.39 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.307604
  validation loss:		0.441474
  validation accuracy:		85.76 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.313567
  validation loss:		0.385361
  validation accuracy:		87.72 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.302208
  validation loss:		0.394192
  validation accuracy:		87.61 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.311365
  validation loss:		0.401234
  validation accuracy:		87.50 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.303462
  validation loss:		0.387650
  validation accuracy:		87.83 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.302004
  validation loss:		0.435208
  validation accuracy:		86.30 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.306372
  validation loss:		0.405812
  validation accuracy:		87.61 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.304521
  validation loss:		0.410696
  validation accuracy:		86.74 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.299072
  validation loss:		0.394538
  validation accuracy:		87.83 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.298350
  validation loss:		0.384777
  validation accuracy:		87.83 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.302505
  validation loss:		0.399335
  validation accuracy:		87.72 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.309317
  validation loss:		0.409504
  validation accuracy:		87.17 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.298543
  validation loss:		0.400171
  validation accuracy:		87.50 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.305364
  validation loss:		0.394364
  validation accuracy:		87.61 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.299947
  validation loss:		0.398857
  validation accuracy:		87.39 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.295323
  validation loss:		0.398791
  validation accuracy:		87.61 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.307059
  validation loss:		0.396931
  validation accuracy:		87.50 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.297423
  validation loss:		0.412752
  validation accuracy:		87.50 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.305405
  validation loss:		0.419066
  validation accuracy:		87.07 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.301085
  validation loss:		0.404230
  validation accuracy:		87.07 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.303971
  validation loss:		0.389895
  validation accuracy:		87.93 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.307601
  validation loss:		0.393082
  validation accuracy:		87.61 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.308718
  validation loss:		0.417418
  validation accuracy:		86.74 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.302589
  validation loss:		0.389672
  validation accuracy:		87.72 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.307428
  validation loss:		0.386042
  validation accuracy:		87.72 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.309630
  validation loss:		0.402297
  validation accuracy:		87.50 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.301713
  validation loss:		0.427976
  validation accuracy:		86.74 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.306295
  validation loss:		0.417620
  validation accuracy:		86.85 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.305919
  validation loss:		0.430245
  validation accuracy:		86.52 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.299496
  validation loss:		0.417280
  validation accuracy:		87.50 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.304020
  validation loss:		0.403633
  validation accuracy:		87.50 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.297439
  validation loss:		0.407181
  validation accuracy:		87.39 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.308247
  validation loss:		0.419293
  validation accuracy:		87.07 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.307678
  validation loss:		0.410626
  validation accuracy:		87.28 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.307838
  validation loss:		0.414592
  validation accuracy:		87.07 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.309412
  validation loss:		0.411134
  validation accuracy:		87.39 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.301416
  validation loss:		0.396796
  validation accuracy:		87.61 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.307572
  validation loss:		0.453543
  validation accuracy:		85.54 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.301367
  validation loss:		0.393413
  validation accuracy:		87.72 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.300146
  validation loss:		0.410045
  validation accuracy:		87.07 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.308187
  validation loss:		0.411526
  validation accuracy:		87.28 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.307276
  validation loss:		0.407382
  validation accuracy:		87.39 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.302357
  validation loss:		0.422619
  validation accuracy:		86.85 %
Epoch 1134 of 2000 took 0.036s
  training loss:		0.313395
  validation loss:		0.394151
  validation accuracy:		87.50 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.304565
  validation loss:		0.410305
  validation accuracy:		86.96 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.300502
  validation loss:		0.428643
  validation accuracy:		86.74 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.304158
  validation loss:		0.399406
  validation accuracy:		87.83 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.301214
  validation loss:		0.440682
  validation accuracy:		85.98 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.302019
  validation loss:		0.405783
  validation accuracy:		87.17 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.300900
  validation loss:		0.448002
  validation accuracy:		85.54 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.310344
  validation loss:		0.398986
  validation accuracy:		87.50 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.303712
  validation loss:		0.403765
  validation accuracy:		87.50 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.302825
  validation loss:		0.427339
  validation accuracy:		85.98 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.305475
  validation loss:		0.384989
  validation accuracy:		87.72 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.308999
  validation loss:		0.415461
  validation accuracy:		86.96 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.307402
  validation loss:		0.411008
  validation accuracy:		87.72 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.301002
  validation loss:		0.398834
  validation accuracy:		87.39 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.303321
  validation loss:		0.406130
  validation accuracy:		87.61 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.307456
  validation loss:		0.404309
  validation accuracy:		87.39 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.302757
  validation loss:		0.398442
  validation accuracy:		87.72 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.303537
  validation loss:		0.385974
  validation accuracy:		87.50 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.309665
  validation loss:		0.394348
  validation accuracy:		87.72 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.305759
  validation loss:		0.470139
  validation accuracy:		85.43 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.301166
  validation loss:		0.397816
  validation accuracy:		87.72 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.303080
  validation loss:		0.403229
  validation accuracy:		87.17 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.300947
  validation loss:		0.408186
  validation accuracy:		87.07 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.299961
  validation loss:		0.386835
  validation accuracy:		87.72 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.301916
  validation loss:		0.393289
  validation accuracy:		87.28 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.308582
  validation loss:		0.402841
  validation accuracy:		87.50 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.300523
  validation loss:		0.401098
  validation accuracy:		87.50 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.306971
  validation loss:		0.415729
  validation accuracy:		87.39 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.302938
  validation loss:		0.424483
  validation accuracy:		86.41 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.306959
  validation loss:		0.410213
  validation accuracy:		87.17 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.311224
  validation loss:		0.442131
  validation accuracy:		85.76 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.304521
  validation loss:		0.403075
  validation accuracy:		87.61 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.303599
  validation loss:		0.407526
  validation accuracy:		87.07 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.308075
  validation loss:		0.397601
  validation accuracy:		87.72 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.309269
  validation loss:		0.400315
  validation accuracy:		87.50 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.305959
  validation loss:		0.411011
  validation accuracy:		87.39 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.307810
  validation loss:		0.418118
  validation accuracy:		87.07 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.297157
  validation loss:		0.414180
  validation accuracy:		87.28 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.303351
  validation loss:		0.383692
  validation accuracy:		87.83 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.305210
  validation loss:		0.398764
  validation accuracy:		87.50 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.300105
  validation loss:		0.398649
  validation accuracy:		87.61 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.310399
  validation loss:		0.382625
  validation accuracy:		87.93 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.306991
  validation loss:		0.392754
  validation accuracy:		87.72 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.307060
  validation loss:		0.418683
  validation accuracy:		87.07 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.304342
  validation loss:		0.401342
  validation accuracy:		87.39 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.298524
  validation loss:		0.407475
  validation accuracy:		87.61 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.309114
  validation loss:		0.433578
  validation accuracy:		86.20 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.307308
  validation loss:		0.393831
  validation accuracy:		87.72 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.305949
  validation loss:		0.389600
  validation accuracy:		87.50 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.298199
  validation loss:		0.403591
  validation accuracy:		87.72 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.304037
  validation loss:		0.395513
  validation accuracy:		87.83 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.303463
  validation loss:		0.403498
  validation accuracy:		87.72 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.305034
  validation loss:		0.381851
  validation accuracy:		87.83 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.306106
  validation loss:		0.398302
  validation accuracy:		87.83 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.305316
  validation loss:		0.417964
  validation accuracy:		86.96 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.306848
  validation loss:		0.416494
  validation accuracy:		87.17 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.306581
  validation loss:		0.398493
  validation accuracy:		87.83 %
Epoch 1191 of 2000 took 0.036s
  training loss:		0.304914
  validation loss:		0.393393
  validation accuracy:		87.28 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.300686
  validation loss:		0.402762
  validation accuracy:		87.28 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.307113
  validation loss:		0.421584
  validation accuracy:		87.39 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.306191
  validation loss:		0.407387
  validation accuracy:		87.07 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.303634
  validation loss:		0.415247
  validation accuracy:		86.74 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.298467
  validation loss:		0.432555
  validation accuracy:		86.20 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.302720
  validation loss:		0.432909
  validation accuracy:		86.85 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.305043
  validation loss:		0.392736
  validation accuracy:		87.83 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.304345
  validation loss:		0.413348
  validation accuracy:		87.17 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.302815
  validation loss:		0.387202
  validation accuracy:		87.50 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.311360
  validation loss:		0.404066
  validation accuracy:		87.39 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.297579
  validation loss:		0.388852
  validation accuracy:		87.93 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.308313
  validation loss:		0.397112
  validation accuracy:		87.61 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.301512
  validation loss:		0.414782
  validation accuracy:		87.07 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.300275
  validation loss:		0.408627
  validation accuracy:		87.17 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.306719
  validation loss:		0.393845
  validation accuracy:		87.83 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.303174
  validation loss:		0.395784
  validation accuracy:		87.61 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.302748
  validation loss:		0.420186
  validation accuracy:		86.96 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.297029
  validation loss:		0.418895
  validation accuracy:		87.17 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.300681
  validation loss:		0.389969
  validation accuracy:		87.83 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.306832
  validation loss:		0.417670
  validation accuracy:		86.52 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.306847
  validation loss:		0.396296
  validation accuracy:		87.61 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.302427
  validation loss:		0.468287
  validation accuracy:		85.11 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.311296
  validation loss:		0.396325
  validation accuracy:		87.83 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.298242
  validation loss:		0.419296
  validation accuracy:		87.28 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.303291
  validation loss:		0.417967
  validation accuracy:		86.96 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.299443
  validation loss:		0.400075
  validation accuracy:		87.50 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.306376
  validation loss:		0.432340
  validation accuracy:		86.20 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.301410
  validation loss:		0.413007
  validation accuracy:		87.39 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.304000
  validation loss:		0.407114
  validation accuracy:		87.83 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.305072
  validation loss:		0.426275
  validation accuracy:		87.17 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.302246
  validation loss:		0.395415
  validation accuracy:		87.61 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.297681
  validation loss:		0.403460
  validation accuracy:		87.50 %
Epoch 1224 of 2000 took 0.036s
  training loss:		0.306287
  validation loss:		0.407819
  validation accuracy:		87.39 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.312926
  validation loss:		0.413692
  validation accuracy:		87.61 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.304409
  validation loss:		0.413005
  validation accuracy:		87.28 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.301574
  validation loss:		0.399714
  validation accuracy:		87.93 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.308547
  validation loss:		0.418745
  validation accuracy:		86.96 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.307762
  validation loss:		0.413725
  validation accuracy:		86.96 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.300798
  validation loss:		0.418281
  validation accuracy:		87.28 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.300665
  validation loss:		0.410140
  validation accuracy:		87.39 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.302782
  validation loss:		0.399629
  validation accuracy:		87.28 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.299746
  validation loss:		0.412504
  validation accuracy:		87.61 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.304249
  validation loss:		0.398180
  validation accuracy:		87.83 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.295852
  validation loss:		0.404076
  validation accuracy:		87.61 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.306561
  validation loss:		0.454729
  validation accuracy:		85.76 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.307165
  validation loss:		0.405128
  validation accuracy:		87.72 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.313932
  validation loss:		0.414895
  validation accuracy:		87.50 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.307621
  validation loss:		0.417405
  validation accuracy:		87.50 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.308897
  validation loss:		0.391280
  validation accuracy:		87.83 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.294536
  validation loss:		0.428623
  validation accuracy:		86.74 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.310187
  validation loss:		0.420666
  validation accuracy:		86.85 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.295851
  validation loss:		0.394158
  validation accuracy:		87.93 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.305749
  validation loss:		0.410817
  validation accuracy:		87.61 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.305800
  validation loss:		0.402863
  validation accuracy:		87.61 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.304511
  validation loss:		0.448066
  validation accuracy:		86.52 %
Epoch 1247 of 2000 took 0.036s
  training loss:		0.311157
  validation loss:		0.427874
  validation accuracy:		86.41 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.300378
  validation loss:		0.435392
  validation accuracy:		86.41 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.302573
  validation loss:		0.392751
  validation accuracy:		87.61 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.300235
  validation loss:		0.431894
  validation accuracy:		86.74 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.306282
  validation loss:		0.431660
  validation accuracy:		86.30 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.302014
  validation loss:		0.403963
  validation accuracy:		87.61 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.297154
  validation loss:		0.428527
  validation accuracy:		86.41 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.299767
  validation loss:		0.429132
  validation accuracy:		86.63 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.303513
  validation loss:		0.414949
  validation accuracy:		87.28 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.310414
  validation loss:		0.395069
  validation accuracy:		87.83 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.298116
  validation loss:		0.382370
  validation accuracy:		87.72 %
Epoch 1258 of 2000 took 0.036s
  training loss:		0.303011
  validation loss:		0.398813
  validation accuracy:		87.61 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.300361
  validation loss:		0.396380
  validation accuracy:		87.61 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.310186
  validation loss:		0.401124
  validation accuracy:		87.39 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.304109
  validation loss:		0.405950
  validation accuracy:		87.61 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.305509
  validation loss:		0.389936
  validation accuracy:		87.72 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.302137
  validation loss:		0.426518
  validation accuracy:		86.52 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.306684
  validation loss:		0.406515
  validation accuracy:		87.39 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.309041
  validation loss:		0.394201
  validation accuracy:		87.72 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.295913
  validation loss:		0.401806
  validation accuracy:		87.83 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.298388
  validation loss:		0.420643
  validation accuracy:		86.85 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.304198
  validation loss:		0.432676
  validation accuracy:		86.41 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.317425
  validation loss:		0.415012
  validation accuracy:		87.17 %
Epoch 1270 of 2000 took 0.036s
  training loss:		0.300607
  validation loss:		0.408833
  validation accuracy:		87.72 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.302079
  validation loss:		0.392784
  validation accuracy:		87.72 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.299711
  validation loss:		0.415365
  validation accuracy:		87.28 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.305127
  validation loss:		0.421526
  validation accuracy:		86.96 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.303233
  validation loss:		0.399660
  validation accuracy:		87.61 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.305140
  validation loss:		0.397331
  validation accuracy:		87.61 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.305315
  validation loss:		0.403748
  validation accuracy:		87.39 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.308996
  validation loss:		0.447601
  validation accuracy:		85.54 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.310316
  validation loss:		0.432275
  validation accuracy:		86.63 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.304376
  validation loss:		0.390166
  validation accuracy:		87.83 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.304188
  validation loss:		0.430444
  validation accuracy:		86.41 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.303158
  validation loss:		0.421398
  validation accuracy:		86.63 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.301626
  validation loss:		0.411193
  validation accuracy:		87.17 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.302797
  validation loss:		0.387847
  validation accuracy:		87.93 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.300905
  validation loss:		0.387474
  validation accuracy:		87.72 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.307886
  validation loss:		0.408344
  validation accuracy:		87.50 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.300725
  validation loss:		0.405073
  validation accuracy:		87.61 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.301237
  validation loss:		0.387909
  validation accuracy:		87.93 %
Epoch 1288 of 2000 took 0.036s
  training loss:		0.308484
  validation loss:		0.410969
  validation accuracy:		87.39 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.302488
  validation loss:		0.400825
  validation accuracy:		87.39 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.304745
  validation loss:		0.428140
  validation accuracy:		86.20 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.305006
  validation loss:		0.424870
  validation accuracy:		86.85 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.306751
  validation loss:		0.398913
  validation accuracy:		87.72 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.305245
  validation loss:		0.397086
  validation accuracy:		87.50 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.302073
  validation loss:		0.423974
  validation accuracy:		86.41 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.302349
  validation loss:		0.424776
  validation accuracy:		86.52 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.302151
  validation loss:		0.433984
  validation accuracy:		86.20 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.304771
  validation loss:		0.412550
  validation accuracy:		87.17 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.296969
  validation loss:		0.406243
  validation accuracy:		87.61 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.303147
  validation loss:		0.423375
  validation accuracy:		86.41 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.301243
  validation loss:		0.407181
  validation accuracy:		87.17 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.302129
  validation loss:		0.415607
  validation accuracy:		87.17 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.304598
  validation loss:		0.429490
  validation accuracy:		86.30 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.302795
  validation loss:		0.406189
  validation accuracy:		87.83 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.300604
  validation loss:		0.425149
  validation accuracy:		86.52 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.304545
  validation loss:		0.408261
  validation accuracy:		87.39 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.302008
  validation loss:		0.387287
  validation accuracy:		87.72 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.304853
  validation loss:		0.407356
  validation accuracy:		87.61 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.303134
  validation loss:		0.398233
  validation accuracy:		87.50 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.303696
  validation loss:		0.401700
  validation accuracy:		87.50 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.303784
  validation loss:		0.406378
  validation accuracy:		87.39 %
Epoch 1311 of 2000 took 0.036s
  training loss:		0.299796
  validation loss:		0.420054
  validation accuracy:		87.17 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.294282
  validation loss:		0.402133
  validation accuracy:		87.39 %
Epoch 1313 of 2000 took 0.036s
  training loss:		0.299739
  validation loss:		0.416494
  validation accuracy:		86.74 %
Epoch 1314 of 2000 took 0.036s
  training loss:		0.303127
  validation loss:		0.417434
  validation accuracy:		87.28 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.308590
  validation loss:		0.395804
  validation accuracy:		87.72 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.305541
  validation loss:		0.411847
  validation accuracy:		87.50 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.305809
  validation loss:		0.420042
  validation accuracy:		87.07 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.295831
  validation loss:		0.418188
  validation accuracy:		87.50 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.302056
  validation loss:		0.431861
  validation accuracy:		86.20 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.306035
  validation loss:		0.407590
  validation accuracy:		87.72 %
Epoch 1321 of 2000 took 0.036s
  training loss:		0.300081
  validation loss:		0.412626
  validation accuracy:		87.61 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.302706
  validation loss:		0.402301
  validation accuracy:		87.50 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.299148
  validation loss:		0.395884
  validation accuracy:		88.04 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.298655
  validation loss:		0.412037
  validation accuracy:		87.17 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.294665
  validation loss:		0.399864
  validation accuracy:		87.50 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.299286
  validation loss:		0.401889
  validation accuracy:		87.72 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.295452
  validation loss:		0.417170
  validation accuracy:		87.17 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.303413
  validation loss:		0.411036
  validation accuracy:		87.50 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.296264
  validation loss:		0.417111
  validation accuracy:		87.39 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.305110
  validation loss:		0.412179
  validation accuracy:		87.50 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.303844
  validation loss:		0.408230
  validation accuracy:		87.39 %
Epoch 1332 of 2000 took 0.036s
  training loss:		0.292843
  validation loss:		0.415703
  validation accuracy:		87.17 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.298745
  validation loss:		0.420515
  validation accuracy:		86.96 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.302941
  validation loss:		0.414901
  validation accuracy:		87.72 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.295404
  validation loss:		0.430625
  validation accuracy:		86.96 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.303545
  validation loss:		0.418702
  validation accuracy:		86.96 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.303125
  validation loss:		0.418233
  validation accuracy:		87.28 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.300414
  validation loss:		0.416317
  validation accuracy:		86.96 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.301008
  validation loss:		0.418961
  validation accuracy:		87.07 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.292740
  validation loss:		0.406758
  validation accuracy:		87.61 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.305086
  validation loss:		0.418210
  validation accuracy:		86.96 %
Epoch 1342 of 2000 took 0.036s
  training loss:		0.299698
  validation loss:		0.411680
  validation accuracy:		87.39 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.303095
  validation loss:		0.419395
  validation accuracy:		87.39 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.304937
  validation loss:		0.392950
  validation accuracy:		87.93 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.301572
  validation loss:		0.414700
  validation accuracy:		87.61 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.306590
  validation loss:		0.388916
  validation accuracy:		87.93 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.305953
  validation loss:		0.425795
  validation accuracy:		86.85 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.304137
  validation loss:		0.412786
  validation accuracy:		87.50 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.314324
  validation loss:		0.410917
  validation accuracy:		87.17 %
Epoch 1350 of 2000 took 0.036s
  training loss:		0.305696
  validation loss:		0.420877
  validation accuracy:		87.07 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.305235
  validation loss:		0.443254
  validation accuracy:		86.09 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.301704
  validation loss:		0.399549
  validation accuracy:		87.39 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.301784
  validation loss:		0.412207
  validation accuracy:		87.50 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.301679
  validation loss:		0.447566
  validation accuracy:		85.43 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.301701
  validation loss:		0.391562
  validation accuracy:		87.72 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.303364
  validation loss:		0.425903
  validation accuracy:		86.85 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.302273
  validation loss:		0.406986
  validation accuracy:		87.61 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.301039
  validation loss:		0.418313
  validation accuracy:		86.96 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.302161
  validation loss:		0.428785
  validation accuracy:		86.30 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.305426
  validation loss:		0.389309
  validation accuracy:		87.72 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.301283
  validation loss:		0.427723
  validation accuracy:		86.63 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.307318
  validation loss:		0.404609
  validation accuracy:		87.50 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.293005
  validation loss:		0.400122
  validation accuracy:		87.50 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.303071
  validation loss:		0.394731
  validation accuracy:		87.83 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.303147
  validation loss:		0.413026
  validation accuracy:		87.28 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.306285
  validation loss:		0.399835
  validation accuracy:		87.93 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.297944
  validation loss:		0.393461
  validation accuracy:		87.61 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.303413
  validation loss:		0.408286
  validation accuracy:		87.28 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.309191
  validation loss:		0.416910
  validation accuracy:		87.17 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.303607
  validation loss:		0.408210
  validation accuracy:		87.61 %
Epoch 1371 of 2000 took 0.036s
  training loss:		0.301919
  validation loss:		0.413869
  validation accuracy:		87.50 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.304714
  validation loss:		0.417743
  validation accuracy:		87.07 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.300516
  validation loss:		0.405475
  validation accuracy:		87.61 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.293104
  validation loss:		0.418282
  validation accuracy:		86.96 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.303354
  validation loss:		0.425178
  validation accuracy:		86.85 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.294546
  validation loss:		0.416909
  validation accuracy:		87.39 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.292697
  validation loss:		0.405908
  validation accuracy:		87.50 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.297350
  validation loss:		0.424387
  validation accuracy:		86.63 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.306901
  validation loss:		0.409613
  validation accuracy:		87.50 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.304986
  validation loss:		0.390275
  validation accuracy:		87.72 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.301668
  validation loss:		0.410619
  validation accuracy:		87.83 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.307021
  validation loss:		0.406697
  validation accuracy:		87.28 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.300022
  validation loss:		0.416197
  validation accuracy:		86.85 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.296713
  validation loss:		0.398949
  validation accuracy:		87.72 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.296912
  validation loss:		0.398146
  validation accuracy:		87.93 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.306580
  validation loss:		0.427333
  validation accuracy:		86.96 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.295260
  validation loss:		0.399600
  validation accuracy:		87.61 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.303034
  validation loss:		0.408639
  validation accuracy:		87.39 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.307926
  validation loss:		0.402793
  validation accuracy:		87.83 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.297159
  validation loss:		0.409798
  validation accuracy:		87.28 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.302036
  validation loss:		0.401550
  validation accuracy:		87.61 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.303812
  validation loss:		0.403567
  validation accuracy:		87.39 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.299630
  validation loss:		0.400937
  validation accuracy:		87.72 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.293050
  validation loss:		0.400544
  validation accuracy:		87.28 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.295638
  validation loss:		0.432362
  validation accuracy:		86.09 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.303763
  validation loss:		0.415160
  validation accuracy:		87.28 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.294284
  validation loss:		0.402784
  validation accuracy:		87.61 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.299911
  validation loss:		0.396851
  validation accuracy:		87.72 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.303238
  validation loss:		0.426390
  validation accuracy:		86.41 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.302742
  validation loss:		0.398114
  validation accuracy:		88.15 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.297850
  validation loss:		0.387835
  validation accuracy:		88.04 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.301644
  validation loss:		0.394941
  validation accuracy:		87.72 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.303639
  validation loss:		0.397018
  validation accuracy:		87.61 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.307581
  validation loss:		0.405842
  validation accuracy:		87.61 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.306171
  validation loss:		0.413879
  validation accuracy:		87.17 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.304098
  validation loss:		0.410101
  validation accuracy:		87.72 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.301804
  validation loss:		0.398649
  validation accuracy:		88.04 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.302128
  validation loss:		0.415915
  validation accuracy:		87.07 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.308340
  validation loss:		0.426203
  validation accuracy:		86.63 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.297759
  validation loss:		0.441567
  validation accuracy:		85.98 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.306464
  validation loss:		0.403398
  validation accuracy:		87.72 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.300589
  validation loss:		0.392700
  validation accuracy:		87.83 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.301992
  validation loss:		0.399866
  validation accuracy:		87.50 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.305201
  validation loss:		0.426889
  validation accuracy:		86.52 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.294990
  validation loss:		0.424611
  validation accuracy:		87.07 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.303998
  validation loss:		0.396051
  validation accuracy:		87.93 %
Epoch 1417 of 2000 took 0.036s
  training loss:		0.312689
  validation loss:		0.410083
  validation accuracy:		87.39 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.300911
  validation loss:		0.433202
  validation accuracy:		86.20 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.301714
  validation loss:		0.396402
  validation accuracy:		87.83 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.308264
  validation loss:		0.434643
  validation accuracy:		86.96 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.300669
  validation loss:		0.392614
  validation accuracy:		87.83 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.301865
  validation loss:		0.408658
  validation accuracy:		87.72 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.303993
  validation loss:		0.394899
  validation accuracy:		87.61 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.301151
  validation loss:		0.403215
  validation accuracy:		87.72 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.304287
  validation loss:		0.435123
  validation accuracy:		85.98 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.305671
  validation loss:		0.416563
  validation accuracy:		87.28 %
Epoch 1427 of 2000 took 0.036s
  training loss:		0.301066
  validation loss:		0.398390
  validation accuracy:		87.72 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.298147
  validation loss:		0.433109
  validation accuracy:		87.17 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.302134
  validation loss:		0.410902
  validation accuracy:		87.50 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.303027
  validation loss:		0.407153
  validation accuracy:		87.50 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.303908
  validation loss:		0.411366
  validation accuracy:		87.17 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.311278
  validation loss:		0.414195
  validation accuracy:		87.28 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.302905
  validation loss:		0.409638
  validation accuracy:		87.61 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.303833
  validation loss:		0.397169
  validation accuracy:		87.93 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.308290
  validation loss:		0.403677
  validation accuracy:		87.83 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.307189
  validation loss:		0.406840
  validation accuracy:		87.50 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.298292
  validation loss:		0.407275
  validation accuracy:		87.72 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.302948
  validation loss:		0.426018
  validation accuracy:		86.96 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.294308
  validation loss:		0.398685
  validation accuracy:		87.61 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.306365
  validation loss:		0.403180
  validation accuracy:		87.83 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.295124
  validation loss:		0.421486
  validation accuracy:		86.63 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.296454
  validation loss:		0.394781
  validation accuracy:		87.83 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.303407
  validation loss:		0.436057
  validation accuracy:		85.98 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.302865
  validation loss:		0.403511
  validation accuracy:		87.39 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.303182
  validation loss:		0.427312
  validation accuracy:		86.09 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.301621
  validation loss:		0.404527
  validation accuracy:		87.83 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.303202
  validation loss:		0.409297
  validation accuracy:		87.61 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.291287
  validation loss:		0.393396
  validation accuracy:		87.72 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.305263
  validation loss:		0.417393
  validation accuracy:		86.85 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.302161
  validation loss:		0.389508
  validation accuracy:		87.61 %
Epoch 1451 of 2000 took 0.036s
  training loss:		0.296387
  validation loss:		0.411642
  validation accuracy:		87.28 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.301253
  validation loss:		0.440286
  validation accuracy:		86.09 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.303857
  validation loss:		0.416649
  validation accuracy:		86.96 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.299608
  validation loss:		0.394885
  validation accuracy:		87.72 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.298830
  validation loss:		0.407724
  validation accuracy:		87.39 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.307525
  validation loss:		0.435969
  validation accuracy:		85.76 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.305026
  validation loss:		0.399802
  validation accuracy:		87.93 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.300495
  validation loss:		0.406019
  validation accuracy:		87.28 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.305789
  validation loss:		0.388647
  validation accuracy:		87.72 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.305018
  validation loss:		0.411676
  validation accuracy:		87.50 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.300253
  validation loss:		0.420043
  validation accuracy:		86.63 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.300341
  validation loss:		0.422729
  validation accuracy:		86.85 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.304746
  validation loss:		0.394108
  validation accuracy:		87.93 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.295478
  validation loss:		0.413572
  validation accuracy:		87.50 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.302538
  validation loss:		0.415967
  validation accuracy:		86.96 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.300147
  validation loss:		0.426365
  validation accuracy:		86.52 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.296464
  validation loss:		0.419114
  validation accuracy:		87.17 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.301667
  validation loss:		0.409273
  validation accuracy:		87.28 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.300038
  validation loss:		0.418382
  validation accuracy:		87.07 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.305211
  validation loss:		0.396642
  validation accuracy:		87.93 %
Epoch 1471 of 2000 took 0.036s
  training loss:		0.295798
  validation loss:		0.402388
  validation accuracy:		87.61 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.294404
  validation loss:		0.421545
  validation accuracy:		87.28 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.296899
  validation loss:		0.417567
  validation accuracy:		86.96 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.295317
  validation loss:		0.413398
  validation accuracy:		87.28 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.294184
  validation loss:		0.415158
  validation accuracy:		86.85 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.302114
  validation loss:		0.439471
  validation accuracy:		85.54 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.297833
  validation loss:		0.405195
  validation accuracy:		87.39 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.292874
  validation loss:		0.438176
  validation accuracy:		86.20 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.300665
  validation loss:		0.398126
  validation accuracy:		87.61 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.303838
  validation loss:		0.421307
  validation accuracy:		86.52 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.304277
  validation loss:		0.410226
  validation accuracy:		87.61 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.298403
  validation loss:		0.394061
  validation accuracy:		87.72 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.292073
  validation loss:		0.413792
  validation accuracy:		87.50 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.299224
  validation loss:		0.405085
  validation accuracy:		87.83 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.304432
  validation loss:		0.404684
  validation accuracy:		87.50 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.297046
  validation loss:		0.410350
  validation accuracy:		87.28 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.298686
  validation loss:		0.417945
  validation accuracy:		86.85 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.308381
  validation loss:		0.419035
  validation accuracy:		86.85 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.306122
  validation loss:		0.436820
  validation accuracy:		85.98 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.297119
  validation loss:		0.391795
  validation accuracy:		87.83 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.301247
  validation loss:		0.427826
  validation accuracy:		86.41 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.301733
  validation loss:		0.405263
  validation accuracy:		87.50 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.299833
  validation loss:		0.393736
  validation accuracy:		87.83 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.298881
  validation loss:		0.412461
  validation accuracy:		87.17 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.303085
  validation loss:		0.428742
  validation accuracy:		86.52 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.297710
  validation loss:		0.393385
  validation accuracy:		87.93 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.295845
  validation loss:		0.439701
  validation accuracy:		85.98 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.303391
  validation loss:		0.409140
  validation accuracy:		87.39 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.301272
  validation loss:		0.413238
  validation accuracy:		87.07 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.298205
  validation loss:		0.411587
  validation accuracy:		87.28 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.304946
  validation loss:		0.408296
  validation accuracy:		87.39 %
Epoch 1502 of 2000 took 0.037s
  training loss:		0.298352
  validation loss:		0.391321
  validation accuracy:		87.72 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.298565
  validation loss:		0.417154
  validation accuracy:		86.96 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.299799
  validation loss:		0.413072
  validation accuracy:		87.61 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.304039
  validation loss:		0.449167
  validation accuracy:		85.87 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.301156
  validation loss:		0.412179
  validation accuracy:		87.28 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.299221
  validation loss:		0.410066
  validation accuracy:		87.72 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.307459
  validation loss:		0.414504
  validation accuracy:		87.07 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.296476
  validation loss:		0.400041
  validation accuracy:		87.72 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.301049
  validation loss:		0.418522
  validation accuracy:		87.28 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.302748
  validation loss:		0.416390
  validation accuracy:		87.17 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.304449
  validation loss:		0.397314
  validation accuracy:		87.83 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.305012
  validation loss:		0.400549
  validation accuracy:		87.83 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.296489
  validation loss:		0.428832
  validation accuracy:		86.20 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.302440
  validation loss:		0.408115
  validation accuracy:		87.50 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.302654
  validation loss:		0.412788
  validation accuracy:		87.28 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.299411
  validation loss:		0.397252
  validation accuracy:		88.15 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.302513
  validation loss:		0.426757
  validation accuracy:		86.96 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.301410
  validation loss:		0.440472
  validation accuracy:		85.87 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.301930
  validation loss:		0.424950
  validation accuracy:		87.28 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.305993
  validation loss:		0.408192
  validation accuracy:		87.28 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.304030
  validation loss:		0.414571
  validation accuracy:		87.07 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.297509
  validation loss:		0.388317
  validation accuracy:		87.93 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.298864
  validation loss:		0.410296
  validation accuracy:		87.39 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.300590
  validation loss:		0.409889
  validation accuracy:		87.28 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.306067
  validation loss:		0.412551
  validation accuracy:		86.96 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.302987
  validation loss:		0.391732
  validation accuracy:		87.72 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.299213
  validation loss:		0.404463
  validation accuracy:		87.83 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.301129
  validation loss:		0.419803
  validation accuracy:		86.85 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.303827
  validation loss:		0.387174
  validation accuracy:		88.04 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.295242
  validation loss:		0.419155
  validation accuracy:		87.17 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.299381
  validation loss:		0.405428
  validation accuracy:		87.50 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.300598
  validation loss:		0.407046
  validation accuracy:		87.61 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.294885
  validation loss:		0.418325
  validation accuracy:		86.85 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.301304
  validation loss:		0.400598
  validation accuracy:		87.93 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.299784
  validation loss:		0.403305
  validation accuracy:		87.72 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.294821
  validation loss:		0.423680
  validation accuracy:		86.96 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.303192
  validation loss:		0.406103
  validation accuracy:		87.61 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.296396
  validation loss:		0.409862
  validation accuracy:		87.39 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.298873
  validation loss:		0.419564
  validation accuracy:		86.96 %
Epoch 1541 of 2000 took 0.036s
  training loss:		0.298306
  validation loss:		0.426324
  validation accuracy:		86.96 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.302660
  validation loss:		0.421371
  validation accuracy:		86.52 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.299566
  validation loss:		0.421076
  validation accuracy:		86.96 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.294107
  validation loss:		0.398231
  validation accuracy:		88.15 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.302631
  validation loss:		0.396688
  validation accuracy:		87.83 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.303871
  validation loss:		0.428345
  validation accuracy:		86.52 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.298513
  validation loss:		0.414024
  validation accuracy:		87.17 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.307405
  validation loss:		0.428658
  validation accuracy:		86.20 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.297269
  validation loss:		0.401526
  validation accuracy:		87.50 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.297274
  validation loss:		0.411257
  validation accuracy:		87.50 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.303338
  validation loss:		0.410328
  validation accuracy:		87.50 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.301726
  validation loss:		0.431119
  validation accuracy:		86.52 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.302042
  validation loss:		0.410646
  validation accuracy:		87.28 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.302821
  validation loss:		0.416163
  validation accuracy:		87.17 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.306341
  validation loss:		0.399311
  validation accuracy:		87.72 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.302444
  validation loss:		0.406010
  validation accuracy:		87.83 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.300741
  validation loss:		0.412258
  validation accuracy:		87.28 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.300589
  validation loss:		0.414691
  validation accuracy:		86.96 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.308102
  validation loss:		0.430218
  validation accuracy:		86.74 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.302002
  validation loss:		0.406127
  validation accuracy:		87.83 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.298674
  validation loss:		0.420184
  validation accuracy:		86.85 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.299430
  validation loss:		0.420369
  validation accuracy:		86.85 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.294115
  validation loss:		0.401310
  validation accuracy:		87.72 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.298319
  validation loss:		0.424267
  validation accuracy:		86.96 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.301973
  validation loss:		0.395826
  validation accuracy:		87.83 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.297305
  validation loss:		0.408207
  validation accuracy:		87.28 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.294726
  validation loss:		0.419727
  validation accuracy:		86.63 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.300009
  validation loss:		0.406247
  validation accuracy:		87.72 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.296144
  validation loss:		0.414094
  validation accuracy:		87.17 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.288090
  validation loss:		0.413897
  validation accuracy:		87.07 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.300346
  validation loss:		0.432720
  validation accuracy:		85.98 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.295539
  validation loss:		0.440402
  validation accuracy:		85.98 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.300570
  validation loss:		0.405277
  validation accuracy:		87.28 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.302272
  validation loss:		0.398125
  validation accuracy:		88.04 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.305594
  validation loss:		0.416688
  validation accuracy:		86.74 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.294043
  validation loss:		0.412493
  validation accuracy:		87.50 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.296728
  validation loss:		0.413403
  validation accuracy:		86.96 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.295997
  validation loss:		0.413902
  validation accuracy:		86.96 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.303049
  validation loss:		0.404669
  validation accuracy:		87.50 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.299156
  validation loss:		0.415421
  validation accuracy:		86.96 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.294393
  validation loss:		0.389164
  validation accuracy:		87.83 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.295367
  validation loss:		0.427000
  validation accuracy:		86.85 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.302785
  validation loss:		0.421107
  validation accuracy:		86.74 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.304669
  validation loss:		0.397721
  validation accuracy:		87.50 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.297499
  validation loss:		0.415606
  validation accuracy:		87.61 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.308565
  validation loss:		0.405178
  validation accuracy:		87.72 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.297103
  validation loss:		0.448363
  validation accuracy:		85.76 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.303503
  validation loss:		0.401535
  validation accuracy:		87.83 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.301774
  validation loss:		0.410768
  validation accuracy:		87.28 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.302772
  validation loss:		0.407921
  validation accuracy:		87.39 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.306475
  validation loss:		0.439996
  validation accuracy:		86.09 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.298138
  validation loss:		0.422190
  validation accuracy:		86.85 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.295100
  validation loss:		0.408131
  validation accuracy:		87.61 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.295368
  validation loss:		0.404391
  validation accuracy:		87.61 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.296360
  validation loss:		0.406473
  validation accuracy:		87.72 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.293662
  validation loss:		0.398049
  validation accuracy:		87.83 %
Epoch 1597 of 2000 took 0.036s
  training loss:		0.299054
  validation loss:		0.407199
  validation accuracy:		87.17 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.302048
  validation loss:		0.426860
  validation accuracy:		86.20 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.302327
  validation loss:		0.410863
  validation accuracy:		87.39 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.295284
  validation loss:		0.413126
  validation accuracy:		87.61 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.296629
  validation loss:		0.413388
  validation accuracy:		87.17 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.298474
  validation loss:		0.407328
  validation accuracy:		87.50 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.297997
  validation loss:		0.405991
  validation accuracy:		87.39 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.306058
  validation loss:		0.392079
  validation accuracy:		87.61 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.294940
  validation loss:		0.456572
  validation accuracy:		85.54 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.298640
  validation loss:		0.402140
  validation accuracy:		88.04 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.300347
  validation loss:		0.406060
  validation accuracy:		87.72 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.296552
  validation loss:		0.417268
  validation accuracy:		86.85 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.303255
  validation loss:		0.423437
  validation accuracy:		86.85 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.305574
  validation loss:		0.407258
  validation accuracy:		87.61 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.301198
  validation loss:		0.414792
  validation accuracy:		87.17 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.299553
  validation loss:		0.410020
  validation accuracy:		87.28 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.302507
  validation loss:		0.436693
  validation accuracy:		86.41 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.300422
  validation loss:		0.416334
  validation accuracy:		86.85 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.294894
  validation loss:		0.442550
  validation accuracy:		85.87 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.300455
  validation loss:		0.431368
  validation accuracy:		86.74 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.306888
  validation loss:		0.400771
  validation accuracy:		87.93 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.300411
  validation loss:		0.398813
  validation accuracy:		87.72 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.298064
  validation loss:		0.396363
  validation accuracy:		87.61 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.299816
  validation loss:		0.429361
  validation accuracy:		86.20 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.300709
  validation loss:		0.414226
  validation accuracy:		87.07 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.299291
  validation loss:		0.388175
  validation accuracy:		87.83 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.302659
  validation loss:		0.426790
  validation accuracy:		86.63 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.303548
  validation loss:		0.438788
  validation accuracy:		86.30 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.287387
  validation loss:		0.410427
  validation accuracy:		87.07 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.300709
  validation loss:		0.416377
  validation accuracy:		87.07 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.302028
  validation loss:		0.388905
  validation accuracy:		87.83 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.300144
  validation loss:		0.400855
  validation accuracy:		87.72 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.297784
  validation loss:		0.415242
  validation accuracy:		87.17 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.296237
  validation loss:		0.404802
  validation accuracy:		87.50 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.298818
  validation loss:		0.437554
  validation accuracy:		86.09 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.301602
  validation loss:		0.404048
  validation accuracy:		87.61 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.305137
  validation loss:		0.405758
  validation accuracy:		87.39 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.296703
  validation loss:		0.422300
  validation accuracy:		86.74 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.294439
  validation loss:		0.437576
  validation accuracy:		86.09 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.300700
  validation loss:		0.413282
  validation accuracy:		86.85 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.302233
  validation loss:		0.410615
  validation accuracy:		87.39 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.290820
  validation loss:		0.412168
  validation accuracy:		86.96 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.300015
  validation loss:		0.425764
  validation accuracy:		86.52 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.295244
  validation loss:		0.410102
  validation accuracy:		87.28 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.297512
  validation loss:		0.415366
  validation accuracy:		86.74 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.299334
  validation loss:		0.413506
  validation accuracy:		86.96 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.301835
  validation loss:		0.397354
  validation accuracy:		87.61 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.303120
  validation loss:		0.410401
  validation accuracy:		87.72 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.299797
  validation loss:		0.399719
  validation accuracy:		87.50 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.291808
  validation loss:		0.403295
  validation accuracy:		87.93 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.303087
  validation loss:		0.419950
  validation accuracy:		86.74 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.301230
  validation loss:		0.418111
  validation accuracy:		87.07 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.307319
  validation loss:		0.415409
  validation accuracy:		86.85 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.298320
  validation loss:		0.434582
  validation accuracy:		86.09 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.297966
  validation loss:		0.401656
  validation accuracy:		87.61 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.302204
  validation loss:		0.414383
  validation accuracy:		86.85 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.294915
  validation loss:		0.397901
  validation accuracy:		87.93 %
Epoch 1654 of 2000 took 0.036s
  training loss:		0.303279
  validation loss:		0.419724
  validation accuracy:		87.17 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.302497
  validation loss:		0.390351
  validation accuracy:		87.50 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.298243
  validation loss:		0.420905
  validation accuracy:		87.28 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.295208
  validation loss:		0.422987
  validation accuracy:		86.74 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.298610
  validation loss:		0.407276
  validation accuracy:		87.50 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.293180
  validation loss:		0.415617
  validation accuracy:		87.28 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.303477
  validation loss:		0.407227
  validation accuracy:		87.83 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.296422
  validation loss:		0.403974
  validation accuracy:		87.50 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.293981
  validation loss:		0.396338
  validation accuracy:		87.72 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.283173
  validation loss:		0.410825
  validation accuracy:		87.17 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.301462
  validation loss:		0.435941
  validation accuracy:		86.09 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.294503
  validation loss:		0.401371
  validation accuracy:		87.72 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.293829
  validation loss:		0.400595
  validation accuracy:		87.61 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.298704
  validation loss:		0.440044
  validation accuracy:		86.20 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.293235
  validation loss:		0.416834
  validation accuracy:		86.74 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.302079
  validation loss:		0.400198
  validation accuracy:		87.72 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.296544
  validation loss:		0.412400
  validation accuracy:		87.17 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.299026
  validation loss:		0.422881
  validation accuracy:		86.74 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.298199
  validation loss:		0.422361
  validation accuracy:		86.52 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.298104
  validation loss:		0.411113
  validation accuracy:		86.85 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.297573
  validation loss:		0.421571
  validation accuracy:		86.85 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.302881
  validation loss:		0.415413
  validation accuracy:		87.07 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.298822
  validation loss:		0.397644
  validation accuracy:		87.93 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.297672
  validation loss:		0.396151
  validation accuracy:		87.72 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.297495
  validation loss:		0.407776
  validation accuracy:		87.61 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.294256
  validation loss:		0.428707
  validation accuracy:		87.17 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.297725
  validation loss:		0.405665
  validation accuracy:		87.17 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.297074
  validation loss:		0.452292
  validation accuracy:		85.65 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.298153
  validation loss:		0.436104
  validation accuracy:		85.98 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.295297
  validation loss:		0.409235
  validation accuracy:		87.28 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.300376
  validation loss:		0.420299
  validation accuracy:		86.96 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.292823
  validation loss:		0.431495
  validation accuracy:		86.52 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.294848
  validation loss:		0.396544
  validation accuracy:		87.83 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.298126
  validation loss:		0.396911
  validation accuracy:		87.61 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.300130
  validation loss:		0.421942
  validation accuracy:		86.85 %
Epoch 1689 of 2000 took 0.036s
  training loss:		0.300442
  validation loss:		0.422051
  validation accuracy:		86.85 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.299911
  validation loss:		0.418143
  validation accuracy:		87.61 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.294551
  validation loss:		0.417313
  validation accuracy:		87.28 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.296472
  validation loss:		0.403017
  validation accuracy:		87.28 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.295206
  validation loss:		0.410575
  validation accuracy:		87.28 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.299224
  validation loss:		0.412989
  validation accuracy:		87.28 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.301685
  validation loss:		0.389406
  validation accuracy:		88.26 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.301711
  validation loss:		0.414267
  validation accuracy:		87.50 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.292813
  validation loss:		0.416884
  validation accuracy:		86.85 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.293187
  validation loss:		0.406830
  validation accuracy:		87.39 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.291346
  validation loss:		0.402331
  validation accuracy:		87.50 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.298221
  validation loss:		0.404143
  validation accuracy:		87.72 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.294341
  validation loss:		0.410859
  validation accuracy:		86.96 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.299246
  validation loss:		0.400130
  validation accuracy:		87.72 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.294579
  validation loss:		0.404200
  validation accuracy:		87.39 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.299373
  validation loss:		0.438572
  validation accuracy:		86.41 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.301158
  validation loss:		0.406674
  validation accuracy:		87.39 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.299839
  validation loss:		0.438590
  validation accuracy:		86.63 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.295888
  validation loss:		0.425490
  validation accuracy:		86.63 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.292393
  validation loss:		0.410701
  validation accuracy:		87.17 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.304164
  validation loss:		0.402548
  validation accuracy:		87.72 %
Epoch 1710 of 2000 took 0.036s
  training loss:		0.298950
  validation loss:		0.407641
  validation accuracy:		87.07 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.301710
  validation loss:		0.406110
  validation accuracy:		87.50 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.299152
  validation loss:		0.407545
  validation accuracy:		87.72 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.298110
  validation loss:		0.403866
  validation accuracy:		87.07 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.297383
  validation loss:		0.401998
  validation accuracy:		87.28 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.303974
  validation loss:		0.414608
  validation accuracy:		87.07 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.303067
  validation loss:		0.397718
  validation accuracy:		87.28 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.299037
  validation loss:		0.402759
  validation accuracy:		87.17 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.295272
  validation loss:		0.424976
  validation accuracy:		86.52 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.295522
  validation loss:		0.406816
  validation accuracy:		87.50 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.297533
  validation loss:		0.409144
  validation accuracy:		87.72 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.292261
  validation loss:		0.393666
  validation accuracy:		87.39 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.302965
  validation loss:		0.420879
  validation accuracy:		87.17 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.302969
  validation loss:		0.432548
  validation accuracy:		86.41 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.302591
  validation loss:		0.400214
  validation accuracy:		87.28 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.303952
  validation loss:		0.419141
  validation accuracy:		86.96 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.292512
  validation loss:		0.405615
  validation accuracy:		87.72 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.296944
  validation loss:		0.397554
  validation accuracy:		87.39 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.291876
  validation loss:		0.421815
  validation accuracy:		87.17 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.304909
  validation loss:		0.405718
  validation accuracy:		87.28 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.304208
  validation loss:		0.426462
  validation accuracy:		86.52 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.296544
  validation loss:		0.413337
  validation accuracy:		87.17 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.302010
  validation loss:		0.408288
  validation accuracy:		87.17 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.300659
  validation loss:		0.402824
  validation accuracy:		87.28 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.295922
  validation loss:		0.402402
  validation accuracy:		87.39 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.299188
  validation loss:		0.393782
  validation accuracy:		87.93 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.304834
  validation loss:		0.437972
  validation accuracy:		86.09 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.299902
  validation loss:		0.424467
  validation accuracy:		85.98 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.297528
  validation loss:		0.440735
  validation accuracy:		85.87 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.300128
  validation loss:		0.404109
  validation accuracy:		87.39 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.295343
  validation loss:		0.446791
  validation accuracy:		86.09 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.297093
  validation loss:		0.397442
  validation accuracy:		87.28 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.303067
  validation loss:		0.412960
  validation accuracy:		86.85 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.299067
  validation loss:		0.396040
  validation accuracy:		87.83 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.297558
  validation loss:		0.400095
  validation accuracy:		87.39 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.294774
  validation loss:		0.420341
  validation accuracy:		86.41 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.301287
  validation loss:		0.410484
  validation accuracy:		87.07 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.295775
  validation loss:		0.409863
  validation accuracy:		87.07 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.304740
  validation loss:		0.447937
  validation accuracy:		85.87 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.289189
  validation loss:		0.413698
  validation accuracy:		87.28 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.298088
  validation loss:		0.391815
  validation accuracy:		88.15 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.295356
  validation loss:		0.404840
  validation accuracy:		87.61 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.297333
  validation loss:		0.407728
  validation accuracy:		87.50 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.299092
  validation loss:		0.397614
  validation accuracy:		88.04 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.298883
  validation loss:		0.406560
  validation accuracy:		87.61 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.303203
  validation loss:		0.413471
  validation accuracy:		86.85 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.297325
  validation loss:		0.455439
  validation accuracy:		86.30 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.303766
  validation loss:		0.419918
  validation accuracy:		86.74 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.298486
  validation loss:		0.412717
  validation accuracy:		87.39 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.301091
  validation loss:		0.421483
  validation accuracy:		86.74 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.296538
  validation loss:		0.456343
  validation accuracy:		85.76 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.301087
  validation loss:		0.424390
  validation accuracy:		86.74 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.293344
  validation loss:		0.436366
  validation accuracy:		86.09 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.301207
  validation loss:		0.404251
  validation accuracy:		87.72 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.297572
  validation loss:		0.420323
  validation accuracy:		86.63 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.297082
  validation loss:		0.401434
  validation accuracy:		87.72 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.298144
  validation loss:		0.407054
  validation accuracy:		87.50 %
Epoch 1767 of 2000 took 0.036s
  training loss:		0.298115
  validation loss:		0.422221
  validation accuracy:		86.74 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.293718
  validation loss:		0.400604
  validation accuracy:		87.17 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.303257
  validation loss:		0.405434
  validation accuracy:		86.96 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.305730
  validation loss:		0.413131
  validation accuracy:		87.28 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.290914
  validation loss:		0.414200
  validation accuracy:		87.39 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.295066
  validation loss:		0.412305
  validation accuracy:		87.07 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.301888
  validation loss:		0.406569
  validation accuracy:		86.96 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.297661
  validation loss:		0.438706
  validation accuracy:		86.41 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.291902
  validation loss:		0.416274
  validation accuracy:		86.96 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.298048
  validation loss:		0.404850
  validation accuracy:		87.39 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.302031
  validation loss:		0.395574
  validation accuracy:		87.83 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.297846
  validation loss:		0.407448
  validation accuracy:		86.96 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.295808
  validation loss:		0.425292
  validation accuracy:		86.52 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.293568
  validation loss:		0.419499
  validation accuracy:		87.17 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.294081
  validation loss:		0.447899
  validation accuracy:		85.87 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.303255
  validation loss:		0.448684
  validation accuracy:		86.09 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.297498
  validation loss:		0.405869
  validation accuracy:		87.17 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.298926
  validation loss:		0.409528
  validation accuracy:		87.39 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.296953
  validation loss:		0.415849
  validation accuracy:		87.39 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.297496
  validation loss:		0.423696
  validation accuracy:		86.41 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.300910
  validation loss:		0.395195
  validation accuracy:		87.17 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.294726
  validation loss:		0.434943
  validation accuracy:		86.52 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.288397
  validation loss:		0.432063
  validation accuracy:		86.63 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.301392
  validation loss:		0.433962
  validation accuracy:		86.09 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.295279
  validation loss:		0.404353
  validation accuracy:		87.39 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.300240
  validation loss:		0.401049
  validation accuracy:		87.39 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.294772
  validation loss:		0.414085
  validation accuracy:		87.28 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.298412
  validation loss:		0.408114
  validation accuracy:		87.28 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.293409
  validation loss:		0.403189
  validation accuracy:		87.50 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.297029
  validation loss:		0.403129
  validation accuracy:		87.39 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.293120
  validation loss:		0.414832
  validation accuracy:		86.85 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.292306
  validation loss:		0.416148
  validation accuracy:		87.07 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.290564
  validation loss:		0.404601
  validation accuracy:		87.50 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.294201
  validation loss:		0.417995
  validation accuracy:		86.52 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.295454
  validation loss:		0.413748
  validation accuracy:		86.74 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.305961
  validation loss:		0.413794
  validation accuracy:		87.28 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.294019
  validation loss:		0.425949
  validation accuracy:		86.30 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.302594
  validation loss:		0.399830
  validation accuracy:		87.50 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.302601
  validation loss:		0.399823
  validation accuracy:		87.61 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.297693
  validation loss:		0.405724
  validation accuracy:		87.07 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.297231
  validation loss:		0.418787
  validation accuracy:		86.63 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.299087
  validation loss:		0.409076
  validation accuracy:		87.50 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.282887
  validation loss:		0.430624
  validation accuracy:		86.20 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.294966
  validation loss:		0.415037
  validation accuracy:		87.07 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.300608
  validation loss:		0.411925
  validation accuracy:		87.39 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.292822
  validation loss:		0.435846
  validation accuracy:		86.41 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.298984
  validation loss:		0.397536
  validation accuracy:		88.04 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.297865
  validation loss:		0.403640
  validation accuracy:		87.50 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.300838
  validation loss:		0.399644
  validation accuracy:		88.15 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.300337
  validation loss:		0.397800
  validation accuracy:		87.07 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.300165
  validation loss:		0.409452
  validation accuracy:		87.61 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.299794
  validation loss:		0.395149
  validation accuracy:		87.50 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.299179
  validation loss:		0.402849
  validation accuracy:		87.61 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.295174
  validation loss:		0.407780
  validation accuracy:		87.28 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.302626
  validation loss:		0.427386
  validation accuracy:		86.63 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.294277
  validation loss:		0.407659
  validation accuracy:		87.50 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.298871
  validation loss:		0.433324
  validation accuracy:		85.98 %
Epoch 1824 of 2000 took 0.036s
  training loss:		0.298226
  validation loss:		0.401281
  validation accuracy:		87.83 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.288879
  validation loss:		0.417242
  validation accuracy:		87.50 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.293677
  validation loss:		0.411150
  validation accuracy:		87.17 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.296092
  validation loss:		0.435249
  validation accuracy:		86.20 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.307258
  validation loss:		0.407026
  validation accuracy:		87.17 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.302543
  validation loss:		0.422723
  validation accuracy:		86.41 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.296334
  validation loss:		0.419030
  validation accuracy:		86.20 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.295861
  validation loss:		0.420082
  validation accuracy:		86.52 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.295264
  validation loss:		0.423052
  validation accuracy:		86.52 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.295865
  validation loss:		0.422306
  validation accuracy:		86.20 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.295077
  validation loss:		0.418121
  validation accuracy:		86.85 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.293246
  validation loss:		0.411867
  validation accuracy:		87.17 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.295865
  validation loss:		0.399831
  validation accuracy:		87.17 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.298663
  validation loss:		0.401017
  validation accuracy:		87.28 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.301369
  validation loss:		0.428657
  validation accuracy:		86.30 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.298326
  validation loss:		0.404222
  validation accuracy:		87.72 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.294802
  validation loss:		0.414617
  validation accuracy:		87.39 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.292730
  validation loss:		0.418194
  validation accuracy:		87.61 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.296016
  validation loss:		0.403125
  validation accuracy:		87.28 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.290427
  validation loss:		0.406145
  validation accuracy:		87.17 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.297960
  validation loss:		0.434094
  validation accuracy:		86.09 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.295259
  validation loss:		0.421606
  validation accuracy:		86.41 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.291046
  validation loss:		0.397768
  validation accuracy:		87.61 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.294547
  validation loss:		0.411775
  validation accuracy:		86.96 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.295779
  validation loss:		0.420130
  validation accuracy:		87.39 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.296952
  validation loss:		0.406627
  validation accuracy:		87.17 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.298671
  validation loss:		0.403838
  validation accuracy:		87.28 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.297572
  validation loss:		0.416063
  validation accuracy:		86.63 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.299366
  validation loss:		0.400375
  validation accuracy:		87.39 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.297393
  validation loss:		0.402154
  validation accuracy:		88.04 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.288897
  validation loss:		0.397421
  validation accuracy:		88.04 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.296438
  validation loss:		0.408959
  validation accuracy:		87.28 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.294742
  validation loss:		0.392734
  validation accuracy:		87.72 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.301522
  validation loss:		0.439809
  validation accuracy:		85.76 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.297000
  validation loss:		0.422522
  validation accuracy:		86.41 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.295076
  validation loss:		0.420170
  validation accuracy:		86.63 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.297271
  validation loss:		0.397199
  validation accuracy:		87.39 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.294946
  validation loss:		0.396041
  validation accuracy:		87.72 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.289597
  validation loss:		0.412325
  validation accuracy:		87.07 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.308180
  validation loss:		0.425296
  validation accuracy:		86.52 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.290960
  validation loss:		0.434027
  validation accuracy:		86.20 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.292912
  validation loss:		0.422439
  validation accuracy:		86.63 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.294625
  validation loss:		0.406596
  validation accuracy:		87.28 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.295588
  validation loss:		0.397398
  validation accuracy:		88.26 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.298778
  validation loss:		0.414739
  validation accuracy:		86.96 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.296219
  validation loss:		0.428160
  validation accuracy:		87.39 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.300358
  validation loss:		0.438161
  validation accuracy:		86.30 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.302517
  validation loss:		0.444085
  validation accuracy:		85.98 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.300527
  validation loss:		0.402489
  validation accuracy:		88.70 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.297940
  validation loss:		0.415925
  validation accuracy:		86.85 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.298851
  validation loss:		0.407091
  validation accuracy:		87.39 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.300036
  validation loss:		0.403880
  validation accuracy:		87.07 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.299335
  validation loss:		0.422884
  validation accuracy:		86.96 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.295165
  validation loss:		0.436057
  validation accuracy:		86.63 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.299867
  validation loss:		0.417221
  validation accuracy:		87.07 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.296291
  validation loss:		0.435124
  validation accuracy:		85.65 %
Epoch 1880 of 2000 took 0.036s
  training loss:		0.295573
  validation loss:		0.403242
  validation accuracy:		87.50 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.297404
  validation loss:		0.406452
  validation accuracy:		87.50 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.297705
  validation loss:		0.407160
  validation accuracy:		87.72 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.295032
  validation loss:		0.432117
  validation accuracy:		86.63 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.293012
  validation loss:		0.415844
  validation accuracy:		87.39 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.292138
  validation loss:		0.432163
  validation accuracy:		86.30 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.296820
  validation loss:		0.410838
  validation accuracy:		87.72 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.293104
  validation loss:		0.419172
  validation accuracy:		86.96 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.296960
  validation loss:		0.405683
  validation accuracy:		87.07 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.295488
  validation loss:		0.403848
  validation accuracy:		87.17 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.293673
  validation loss:		0.407795
  validation accuracy:		87.50 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.290919
  validation loss:		0.437828
  validation accuracy:		86.09 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.299255
  validation loss:		0.420203
  validation accuracy:		86.96 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.301159
  validation loss:		0.418098
  validation accuracy:		87.72 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.294054
  validation loss:		0.428795
  validation accuracy:		86.20 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.290456
  validation loss:		0.412845
  validation accuracy:		88.04 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.291570
  validation loss:		0.428962
  validation accuracy:		86.20 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.297423
  validation loss:		0.415604
  validation accuracy:		87.28 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.303089
  validation loss:		0.415045
  validation accuracy:		87.17 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.297574
  validation loss:		0.414588
  validation accuracy:		87.39 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.292383
  validation loss:		0.413926
  validation accuracy:		87.50 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.297392
  validation loss:		0.408802
  validation accuracy:		87.28 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.296809
  validation loss:		0.414793
  validation accuracy:		87.39 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.296308
  validation loss:		0.413632
  validation accuracy:		87.93 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.293112
  validation loss:		0.397405
  validation accuracy:		88.37 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.299119
  validation loss:		0.399913
  validation accuracy:		87.17 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.289950
  validation loss:		0.417367
  validation accuracy:		86.85 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.293937
  validation loss:		0.411804
  validation accuracy:		87.50 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.296313
  validation loss:		0.416164
  validation accuracy:		86.96 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.290658
  validation loss:		0.421324
  validation accuracy:		86.96 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.295373
  validation loss:		0.416835
  validation accuracy:		86.85 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.299142
  validation loss:		0.413331
  validation accuracy:		87.17 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.291555
  validation loss:		0.399726
  validation accuracy:		87.72 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.294110
  validation loss:		0.403802
  validation accuracy:		87.28 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.296413
  validation loss:		0.433606
  validation accuracy:		85.98 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.296187
  validation loss:		0.413764
  validation accuracy:		87.39 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.292573
  validation loss:		0.409081
  validation accuracy:		87.28 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.290492
  validation loss:		0.442781
  validation accuracy:		86.52 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.298847
  validation loss:		0.396441
  validation accuracy:		87.61 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.293493
  validation loss:		0.416329
  validation accuracy:		87.07 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.294609
  validation loss:		0.402111
  validation accuracy:		88.26 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.294420
  validation loss:		0.426744
  validation accuracy:		86.52 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.300181
  validation loss:		0.407924
  validation accuracy:		87.61 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.294807
  validation loss:		0.418972
  validation accuracy:		87.07 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.294128
  validation loss:		0.437663
  validation accuracy:		86.63 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.294379
  validation loss:		0.415814
  validation accuracy:		87.61 %
Epoch 1926 of 2000 took 0.036s
  training loss:		0.299936
  validation loss:		0.419646
  validation accuracy:		87.50 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.291267
  validation loss:		0.406655
  validation accuracy:		87.50 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.298962
  validation loss:		0.421036
  validation accuracy:		86.52 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.293701
  validation loss:		0.423736
  validation accuracy:		87.07 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.289339
  validation loss:		0.401919
  validation accuracy:		87.17 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.289219
  validation loss:		0.419525
  validation accuracy:		87.17 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.300284
  validation loss:		0.435060
  validation accuracy:		86.20 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.289694
  validation loss:		0.406821
  validation accuracy:		87.28 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.293273
  validation loss:		0.416072
  validation accuracy:		87.39 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.301864
  validation loss:		0.425250
  validation accuracy:		86.63 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.297067
  validation loss:		0.402841
  validation accuracy:		87.28 %
Epoch 1937 of 2000 took 0.036s
  training loss:		0.297218
  validation loss:		0.426918
  validation accuracy:		86.63 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.291622
  validation loss:		0.408478
  validation accuracy:		87.28 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.293966
  validation loss:		0.412573
  validation accuracy:		87.39 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.296670
  validation loss:		0.424575
  validation accuracy:		86.52 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.292036
  validation loss:		0.409673
  validation accuracy:		87.07 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.293796
  validation loss:		0.419347
  validation accuracy:		87.07 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.295791
  validation loss:		0.409221
  validation accuracy:		87.28 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.294783
  validation loss:		0.405292
  validation accuracy:		88.04 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.302072
  validation loss:		0.401400
  validation accuracy:		87.72 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.292774
  validation loss:		0.406578
  validation accuracy:		87.50 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.300407
  validation loss:		0.421665
  validation accuracy:		87.07 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.300320
  validation loss:		0.399659
  validation accuracy:		87.39 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.301459
  validation loss:		0.401361
  validation accuracy:		87.39 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.294108
  validation loss:		0.401126
  validation accuracy:		87.28 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.296486
  validation loss:		0.417451
  validation accuracy:		86.74 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.296539
  validation loss:		0.407012
  validation accuracy:		87.83 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.295786
  validation loss:		0.407262
  validation accuracy:		87.61 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.287804
  validation loss:		0.421594
  validation accuracy:		87.28 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.307381
  validation loss:		0.421382
  validation accuracy:		87.50 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.301229
  validation loss:		0.425414
  validation accuracy:		86.74 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.293027
  validation loss:		0.401297
  validation accuracy:		87.28 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.301681
  validation loss:		0.411153
  validation accuracy:		87.61 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.298016
  validation loss:		0.400783
  validation accuracy:		87.93 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.291808
  validation loss:		0.423426
  validation accuracy:		86.52 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.298727
  validation loss:		0.411522
  validation accuracy:		87.72 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.299666
  validation loss:		0.407381
  validation accuracy:		87.72 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.295867
  validation loss:		0.405194
  validation accuracy:		87.93 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.300558
  validation loss:		0.418259
  validation accuracy:		87.17 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.297148
  validation loss:		0.407221
  validation accuracy:		88.26 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.301528
  validation loss:		0.408459
  validation accuracy:		88.04 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.295744
  validation loss:		0.421890
  validation accuracy:		86.96 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.293316
  validation loss:		0.419699
  validation accuracy:		87.39 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.301560
  validation loss:		0.410718
  validation accuracy:		87.61 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.293486
  validation loss:		0.395761
  validation accuracy:		87.72 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.296465
  validation loss:		0.425102
  validation accuracy:		86.41 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.293227
  validation loss:		0.435816
  validation accuracy:		86.09 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.292898
  validation loss:		0.426434
  validation accuracy:		86.74 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.297985
  validation loss:		0.402040
  validation accuracy:		87.83 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.297646
  validation loss:		0.443682
  validation accuracy:		86.30 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.294919
  validation loss:		0.432228
  validation accuracy:		86.41 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.299667
  validation loss:		0.414574
  validation accuracy:		86.85 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.296828
  validation loss:		0.434312
  validation accuracy:		86.30 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.298286
  validation loss:		0.425590
  validation accuracy:		86.74 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.299440
  validation loss:		0.435309
  validation accuracy:		86.20 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.296821
  validation loss:		0.417170
  validation accuracy:		86.30 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.297608
  validation loss:		0.413200
  validation accuracy:		87.28 %
Epoch 1983 of 2000 took 0.036s
  training loss:		0.293184
  validation loss:		0.435504
  validation accuracy:		86.30 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.292609
  validation loss:		0.423931
  validation accuracy:		86.96 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.292408
  validation loss:		0.410366
  validation accuracy:		87.28 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.299447
  validation loss:		0.399614
  validation accuracy:		88.04 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.293792
  validation loss:		0.404635
  validation accuracy:		87.28 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.292059
  validation loss:		0.401887
  validation accuracy:		87.93 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.291244
  validation loss:		0.407099
  validation accuracy:		87.83 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.296244
  validation loss:		0.424109
  validation accuracy:		86.74 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.294764
  validation loss:		0.443237
  validation accuracy:		86.09 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.290123
  validation loss:		0.418798
  validation accuracy:		87.61 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.291830
  validation loss:		0.410607
  validation accuracy:		87.61 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.296716
  validation loss:		0.422707
  validation accuracy:		86.52 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.294626
  validation loss:		0.409192
  validation accuracy:		87.83 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.291335
  validation loss:		0.419652
  validation accuracy:		87.72 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.295342
  validation loss:		0.415171
  validation accuracy:		87.50 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.295989
  validation loss:		0.416700
  validation accuracy:		87.07 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.291989
  validation loss:		0.422884
  validation accuracy:		86.52 %
Epoch 2000 of 2000 took 0.036s
  training loss:		0.299497
  validation loss:		0.403881
  validation accuracy:		87.39 %
Final results:
  test loss:			0.736825
  test accuracy:		80.53 %
