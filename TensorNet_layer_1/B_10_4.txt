Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.051s
  training loss:		2.964521
  validation loss:		2.865863
  validation accuracy:		12.28 %
Epoch 2 of 2000 took 0.044s
  training loss:		2.793773
  validation loss:		2.647592
  validation accuracy:		20.98 %
Epoch 3 of 2000 took 0.040s
  training loss:		2.599846
  validation loss:		2.433385
  validation accuracy:		30.00 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.431952
  validation loss:		2.278781
  validation accuracy:		33.26 %
Epoch 5 of 2000 took 0.038s
  training loss:		2.317170
  validation loss:		2.194199
  validation accuracy:		48.91 %
Epoch 6 of 2000 took 0.038s
  training loss:		2.250077
  validation loss:		2.162188
  validation accuracy:		52.39 %
Epoch 7 of 2000 took 0.038s
  training loss:		2.208865
  validation loss:		2.133166
  validation accuracy:		53.59 %
Epoch 8 of 2000 took 0.039s
  training loss:		2.175499
  validation loss:		2.093541
  validation accuracy:		55.43 %
Epoch 9 of 2000 took 0.038s
  training loss:		2.146009
  validation loss:		2.062721
  validation accuracy:		55.98 %
Epoch 10 of 2000 took 0.038s
  training loss:		2.115343
  validation loss:		2.027298
  validation accuracy:		56.30 %
Epoch 11 of 2000 took 0.038s
  training loss:		2.082683
  validation loss:		1.994427
  validation accuracy:		56.41 %
Epoch 12 of 2000 took 0.038s
  training loss:		2.046508
  validation loss:		1.950731
  validation accuracy:		61.74 %
Epoch 13 of 2000 took 0.038s
  training loss:		2.012277
  validation loss:		1.920460
  validation accuracy:		60.98 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.970480
  validation loss:		1.871388
  validation accuracy:		60.54 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.922875
  validation loss:		1.813686
  validation accuracy:		60.65 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.874842
  validation loss:		1.764160
  validation accuracy:		61.74 %
Epoch 17 of 2000 took 0.038s
  training loss:		1.822263
  validation loss:		1.698667
  validation accuracy:		64.24 %
Epoch 18 of 2000 took 0.038s
  training loss:		1.765878
  validation loss:		1.643597
  validation accuracy:		64.46 %
Epoch 19 of 2000 took 0.035s
  training loss:		1.709303
  validation loss:		1.587754
  validation accuracy:		66.85 %
Epoch 20 of 2000 took 0.035s
  training loss:		1.657447
  validation loss:		1.522428
  validation accuracy:		67.50 %
Epoch 21 of 2000 took 0.035s
  training loss:		1.597985
  validation loss:		1.470201
  validation accuracy:		67.50 %
Epoch 22 of 2000 took 0.035s
  training loss:		1.537391
  validation loss:		1.412355
  validation accuracy:		71.09 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.479548
  validation loss:		1.351542
  validation accuracy:		70.76 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.428745
  validation loss:		1.301733
  validation accuracy:		71.74 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.377961
  validation loss:		1.261039
  validation accuracy:		71.85 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.325540
  validation loss:		1.199806
  validation accuracy:		73.70 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.278110
  validation loss:		1.161676
  validation accuracy:		74.24 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.230876
  validation loss:		1.119023
  validation accuracy:		74.78 %
Epoch 29 of 2000 took 0.036s
  training loss:		1.190691
  validation loss:		1.083077
  validation accuracy:		74.46 %
Epoch 30 of 2000 took 0.036s
  training loss:		1.152417
  validation loss:		1.047007
  validation accuracy:		75.33 %
Epoch 31 of 2000 took 0.036s
  training loss:		1.112924
  validation loss:		0.999293
  validation accuracy:		77.50 %
Epoch 32 of 2000 took 0.036s
  training loss:		1.074475
  validation loss:		0.970058
  validation accuracy:		76.74 %
Epoch 33 of 2000 took 0.036s
  training loss:		1.040175
  validation loss:		0.951835
  validation accuracy:		75.54 %
Epoch 34 of 2000 took 0.036s
  training loss:		1.012343
  validation loss:		0.910119
  validation accuracy:		77.83 %
Epoch 35 of 2000 took 0.036s
  training loss:		0.979685
  validation loss:		0.886073
  validation accuracy:		78.26 %
Epoch 36 of 2000 took 0.036s
  training loss:		0.951118
  validation loss:		0.856251
  validation accuracy:		78.91 %
Epoch 37 of 2000 took 0.036s
  training loss:		0.927840
  validation loss:		0.832040
  validation accuracy:		79.57 %
Epoch 38 of 2000 took 0.036s
  training loss:		0.902648
  validation loss:		0.813969
  validation accuracy:		79.89 %
Epoch 39 of 2000 took 0.036s
  training loss:		0.869734
  validation loss:		0.786831
  validation accuracy:		80.43 %
Epoch 40 of 2000 took 0.036s
  training loss:		0.845240
  validation loss:		0.770358
  validation accuracy:		80.43 %
Epoch 41 of 2000 took 0.036s
  training loss:		0.823594
  validation loss:		0.752319
  validation accuracy:		80.87 %
Epoch 42 of 2000 took 0.036s
  training loss:		0.796772
  validation loss:		0.718298
  validation accuracy:		82.07 %
Epoch 43 of 2000 took 0.036s
  training loss:		0.775617
  validation loss:		0.702688
  validation accuracy:		82.39 %
Epoch 44 of 2000 took 0.037s
  training loss:		0.760463
  validation loss:		0.672575
  validation accuracy:		83.37 %
Epoch 45 of 2000 took 0.036s
  training loss:		0.736781
  validation loss:		0.664422
  validation accuracy:		83.80 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.726091
  validation loss:		0.639185
  validation accuracy:		84.13 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.695229
  validation loss:		0.628296
  validation accuracy:		84.57 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.676876
  validation loss:		0.615525
  validation accuracy:		84.13 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.659574
  validation loss:		0.605446
  validation accuracy:		84.89 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.644815
  validation loss:		0.583806
  validation accuracy:		84.57 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.630789
  validation loss:		0.569368
  validation accuracy:		85.76 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.617888
  validation loss:		0.559773
  validation accuracy:		85.76 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.600508
  validation loss:		0.544694
  validation accuracy:		85.98 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.587083
  validation loss:		0.523811
  validation accuracy:		86.41 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.573848
  validation loss:		0.524564
  validation accuracy:		86.41 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.562906
  validation loss:		0.509927
  validation accuracy:		86.85 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.548716
  validation loss:		0.494611
  validation accuracy:		86.96 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.535905
  validation loss:		0.481172
  validation accuracy:		87.50 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.527637
  validation loss:		0.479192
  validation accuracy:		87.07 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.515025
  validation loss:		0.461754
  validation accuracy:		87.50 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.505190
  validation loss:		0.457354
  validation accuracy:		87.83 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.495608
  validation loss:		0.450379
  validation accuracy:		87.61 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.480261
  validation loss:		0.440990
  validation accuracy:		87.72 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.481259
  validation loss:		0.436295
  validation accuracy:		87.93 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.470071
  validation loss:		0.423654
  validation accuracy:		88.37 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.464465
  validation loss:		0.416408
  validation accuracy:		88.48 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.450130
  validation loss:		0.412886
  validation accuracy:		88.04 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.440904
  validation loss:		0.404948
  validation accuracy:		88.59 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.436305
  validation loss:		0.402953
  validation accuracy:		88.91 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.429690
  validation loss:		0.391950
  validation accuracy:		88.91 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.421579
  validation loss:		0.391673
  validation accuracy:		88.80 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.415258
  validation loss:		0.379766
  validation accuracy:		89.13 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.413398
  validation loss:		0.373551
  validation accuracy:		88.80 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.406837
  validation loss:		0.375040
  validation accuracy:		88.91 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.393481
  validation loss:		0.365973
  validation accuracy:		89.46 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.394234
  validation loss:		0.367680
  validation accuracy:		88.70 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.390628
  validation loss:		0.364808
  validation accuracy:		89.35 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.377786
  validation loss:		0.349900
  validation accuracy:		90.00 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.380515
  validation loss:		0.350889
  validation accuracy:		89.57 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.370014
  validation loss:		0.347348
  validation accuracy:		89.57 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.367228
  validation loss:		0.343004
  validation accuracy:		89.78 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.354872
  validation loss:		0.335518
  validation accuracy:		90.54 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.351790
  validation loss:		0.335031
  validation accuracy:		90.11 %
Epoch 84 of 2000 took 0.036s
  training loss:		0.351954
  validation loss:		0.335560
  validation accuracy:		90.11 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.346590
  validation loss:		0.331477
  validation accuracy:		90.43 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.347754
  validation loss:		0.327630
  validation accuracy:		90.33 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.340442
  validation loss:		0.321748
  validation accuracy:		90.65 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.341871
  validation loss:		0.321365
  validation accuracy:		90.65 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.332115
  validation loss:		0.315093
  validation accuracy:		90.87 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.337099
  validation loss:		0.321235
  validation accuracy:		90.43 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.326778
  validation loss:		0.313505
  validation accuracy:		90.98 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.322583
  validation loss:		0.303749
  validation accuracy:		91.20 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.317911
  validation loss:		0.320552
  validation accuracy:		90.43 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.320471
  validation loss:		0.307294
  validation accuracy:		90.65 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.315055
  validation loss:		0.303452
  validation accuracy:		91.09 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.314352
  validation loss:		0.302156
  validation accuracy:		91.20 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.306730
  validation loss:		0.292724
  validation accuracy:		91.09 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.303012
  validation loss:		0.301398
  validation accuracy:		91.30 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.303316
  validation loss:		0.300490
  validation accuracy:		91.20 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.295291
  validation loss:		0.290168
  validation accuracy:		90.98 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.298008
  validation loss:		0.290105
  validation accuracy:		90.98 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.290135
  validation loss:		0.285336
  validation accuracy:		91.30 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.290105
  validation loss:		0.284946
  validation accuracy:		91.52 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.283145
  validation loss:		0.281983
  validation accuracy:		91.74 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.288191
  validation loss:		0.282469
  validation accuracy:		91.30 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.285843
  validation loss:		0.279919
  validation accuracy:		91.74 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.283636
  validation loss:		0.280730
  validation accuracy:		91.63 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.282655
  validation loss:		0.274594
  validation accuracy:		91.85 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.280581
  validation loss:		0.278828
  validation accuracy:		91.30 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.276557
  validation loss:		0.271228
  validation accuracy:		91.74 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.273699
  validation loss:		0.270819
  validation accuracy:		91.96 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.267358
  validation loss:		0.276922
  validation accuracy:		91.85 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.271717
  validation loss:		0.268544
  validation accuracy:		92.07 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.265676
  validation loss:		0.266159
  validation accuracy:		91.96 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.262720
  validation loss:		0.263250
  validation accuracy:		91.85 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.262631
  validation loss:		0.269031
  validation accuracy:		92.07 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.263614
  validation loss:		0.262693
  validation accuracy:		92.07 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.258400
  validation loss:		0.263468
  validation accuracy:		91.96 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.259580
  validation loss:		0.259537
  validation accuracy:		92.17 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.251669
  validation loss:		0.261543
  validation accuracy:		92.17 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.250363
  validation loss:		0.259241
  validation accuracy:		91.96 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.252404
  validation loss:		0.258548
  validation accuracy:		92.07 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.253677
  validation loss:		0.254597
  validation accuracy:		92.17 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.246757
  validation loss:		0.256411
  validation accuracy:		92.28 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.242619
  validation loss:		0.256801
  validation accuracy:		92.39 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.243235
  validation loss:		0.250223
  validation accuracy:		92.72 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.243992
  validation loss:		0.252263
  validation accuracy:		92.50 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.239872
  validation loss:		0.252190
  validation accuracy:		92.07 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.241280
  validation loss:		0.248399
  validation accuracy:		92.61 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.236858
  validation loss:		0.248971
  validation accuracy:		92.61 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.237913
  validation loss:		0.249226
  validation accuracy:		92.17 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.235957
  validation loss:		0.247843
  validation accuracy:		92.28 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.240172
  validation loss:		0.245892
  validation accuracy:		92.17 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.232110
  validation loss:		0.245509
  validation accuracy:		92.50 %
Epoch 135 of 2000 took 0.037s
  training loss:		0.232283
  validation loss:		0.244443
  validation accuracy:		92.50 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.230617
  validation loss:		0.244078
  validation accuracy:		92.28 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.224866
  validation loss:		0.239078
  validation accuracy:		92.61 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.229986
  validation loss:		0.243296
  validation accuracy:		92.50 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.225921
  validation loss:		0.243083
  validation accuracy:		92.39 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.220667
  validation loss:		0.242179
  validation accuracy:		92.39 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.218317
  validation loss:		0.242967
  validation accuracy:		92.72 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.226130
  validation loss:		0.239575
  validation accuracy:		92.61 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.223008
  validation loss:		0.237978
  validation accuracy:		92.28 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.220254
  validation loss:		0.235559
  validation accuracy:		92.50 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.215227
  validation loss:		0.235927
  validation accuracy:		92.50 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.212226
  validation loss:		0.237369
  validation accuracy:		92.50 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.217017
  validation loss:		0.236990
  validation accuracy:		92.61 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.217027
  validation loss:		0.230888
  validation accuracy:		92.83 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.211604
  validation loss:		0.239950
  validation accuracy:		92.61 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.213460
  validation loss:		0.238604
  validation accuracy:		92.39 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.208401
  validation loss:		0.229629
  validation accuracy:		92.83 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.209951
  validation loss:		0.237720
  validation accuracy:		92.39 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.208325
  validation loss:		0.235263
  validation accuracy:		92.61 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.204699
  validation loss:		0.234969
  validation accuracy:		92.83 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.203701
  validation loss:		0.228022
  validation accuracy:		92.83 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.205409
  validation loss:		0.226103
  validation accuracy:		93.04 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.206687
  validation loss:		0.238230
  validation accuracy:		92.61 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.208821
  validation loss:		0.232736
  validation accuracy:		92.72 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.203508
  validation loss:		0.231584
  validation accuracy:		92.83 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.198559
  validation loss:		0.229856
  validation accuracy:		92.72 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.201032
  validation loss:		0.231170
  validation accuracy:		93.04 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.196589
  validation loss:		0.225849
  validation accuracy:		93.15 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.201932
  validation loss:		0.225689
  validation accuracy:		93.04 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.199953
  validation loss:		0.231416
  validation accuracy:		92.61 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.195301
  validation loss:		0.225012
  validation accuracy:		93.04 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.196985
  validation loss:		0.224309
  validation accuracy:		92.93 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.197639
  validation loss:		0.235482
  validation accuracy:		93.26 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.191259
  validation loss:		0.221857
  validation accuracy:		92.83 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.193236
  validation loss:		0.229698
  validation accuracy:		93.04 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.195439
  validation loss:		0.221321
  validation accuracy:		93.15 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.191705
  validation loss:		0.223985
  validation accuracy:		93.15 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.190447
  validation loss:		0.221917
  validation accuracy:		93.15 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.192057
  validation loss:		0.225881
  validation accuracy:		93.15 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.188905
  validation loss:		0.222001
  validation accuracy:		93.26 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.186048
  validation loss:		0.228826
  validation accuracy:		92.83 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.188248
  validation loss:		0.220704
  validation accuracy:		93.15 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.188627
  validation loss:		0.224455
  validation accuracy:		93.15 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.182646
  validation loss:		0.219322
  validation accuracy:		93.26 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.182380
  validation loss:		0.222201
  validation accuracy:		93.04 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.183299
  validation loss:		0.219778
  validation accuracy:		93.26 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.187554
  validation loss:		0.219023
  validation accuracy:		93.26 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.178613
  validation loss:		0.219933
  validation accuracy:		93.15 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.179680
  validation loss:		0.231440
  validation accuracy:		92.72 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.184714
  validation loss:		0.221065
  validation accuracy:		93.26 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.176484
  validation loss:		0.219238
  validation accuracy:		93.37 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.178881
  validation loss:		0.215743
  validation accuracy:		93.26 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.175438
  validation loss:		0.222928
  validation accuracy:		93.04 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.174010
  validation loss:		0.220153
  validation accuracy:		93.37 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.177822
  validation loss:		0.213999
  validation accuracy:		93.37 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.178545
  validation loss:		0.235124
  validation accuracy:		92.93 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.175960
  validation loss:		0.220542
  validation accuracy:		92.93 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.173895
  validation loss:		0.216430
  validation accuracy:		93.15 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.171097
  validation loss:		0.217148
  validation accuracy:		93.26 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.175202
  validation loss:		0.223785
  validation accuracy:		93.04 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.172597
  validation loss:		0.222468
  validation accuracy:		93.26 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.168745
  validation loss:		0.220944
  validation accuracy:		93.37 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.172062
  validation loss:		0.222398
  validation accuracy:		93.15 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.171434
  validation loss:		0.214447
  validation accuracy:		93.48 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.171793
  validation loss:		0.214209
  validation accuracy:		93.26 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.169195
  validation loss:		0.218199
  validation accuracy:		93.37 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.165128
  validation loss:		0.214590
  validation accuracy:		93.04 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.166427
  validation loss:		0.212767
  validation accuracy:		93.37 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.165279
  validation loss:		0.222280
  validation accuracy:		93.15 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.165871
  validation loss:		0.219978
  validation accuracy:		93.37 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.162377
  validation loss:		0.215764
  validation accuracy:		93.59 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.164423
  validation loss:		0.213195
  validation accuracy:		93.37 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.162509
  validation loss:		0.213664
  validation accuracy:		93.04 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.161132
  validation loss:		0.213451
  validation accuracy:		93.48 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.160322
  validation loss:		0.219131
  validation accuracy:		93.48 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.163333
  validation loss:		0.208717
  validation accuracy:		93.37 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.158804
  validation loss:		0.215404
  validation accuracy:		93.15 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.161076
  validation loss:		0.219086
  validation accuracy:		93.26 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.158960
  validation loss:		0.215641
  validation accuracy:		93.48 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.159333
  validation loss:		0.211866
  validation accuracy:		93.15 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.157417
  validation loss:		0.211398
  validation accuracy:		93.48 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.160202
  validation loss:		0.218842
  validation accuracy:		93.59 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.155951
  validation loss:		0.214392
  validation accuracy:		93.04 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.158757
  validation loss:		0.208704
  validation accuracy:		93.15 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.155953
  validation loss:		0.223508
  validation accuracy:		93.15 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.156576
  validation loss:		0.209891
  validation accuracy:		93.26 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.154886
  validation loss:		0.208973
  validation accuracy:		93.37 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.157284
  validation loss:		0.209614
  validation accuracy:		93.48 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.149758
  validation loss:		0.211854
  validation accuracy:		93.37 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.154869
  validation loss:		0.212562
  validation accuracy:		93.26 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.153258
  validation loss:		0.211832
  validation accuracy:		93.59 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.150512
  validation loss:		0.207280
  validation accuracy:		93.37 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.152985
  validation loss:		0.211402
  validation accuracy:		93.26 %
Epoch 228 of 2000 took 0.036s
  training loss:		0.153277
  validation loss:		0.213108
  validation accuracy:		93.37 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.151438
  validation loss:		0.208612
  validation accuracy:		93.26 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.151134
  validation loss:		0.205022
  validation accuracy:		93.48 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.151268
  validation loss:		0.221135
  validation accuracy:		92.61 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.151185
  validation loss:		0.204051
  validation accuracy:		92.93 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.145947
  validation loss:		0.207642
  validation accuracy:		93.26 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.145845
  validation loss:		0.212428
  validation accuracy:		93.26 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.148050
  validation loss:		0.206849
  validation accuracy:		93.37 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.145482
  validation loss:		0.214825
  validation accuracy:		93.26 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.142425
  validation loss:		0.206867
  validation accuracy:		93.70 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.141788
  validation loss:		0.206061
  validation accuracy:		93.26 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.144791
  validation loss:		0.206803
  validation accuracy:		93.48 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.144526
  validation loss:		0.212011
  validation accuracy:		93.15 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.139706
  validation loss:		0.206391
  validation accuracy:		93.37 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.142494
  validation loss:		0.206417
  validation accuracy:		93.37 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.146628
  validation loss:		0.209134
  validation accuracy:		93.04 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.140778
  validation loss:		0.210213
  validation accuracy:		93.59 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.139039
  validation loss:		0.212611
  validation accuracy:		93.04 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.145199
  validation loss:		0.211897
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.141044
  validation loss:		0.208634
  validation accuracy:		93.26 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.138307
  validation loss:		0.207263
  validation accuracy:		93.26 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.138222
  validation loss:		0.201567
  validation accuracy:		93.26 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.136539
  validation loss:		0.216563
  validation accuracy:		93.26 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.142438
  validation loss:		0.206391
  validation accuracy:		93.37 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.139185
  validation loss:		0.206905
  validation accuracy:		93.04 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.133628
  validation loss:		0.207264
  validation accuracy:		93.37 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.138839
  validation loss:		0.203780
  validation accuracy:		93.37 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.136547
  validation loss:		0.205422
  validation accuracy:		93.26 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.134038
  validation loss:		0.210953
  validation accuracy:		93.15 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.134049
  validation loss:		0.204746
  validation accuracy:		93.26 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.134070
  validation loss:		0.208847
  validation accuracy:		93.37 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.135224
  validation loss:		0.203675
  validation accuracy:		93.26 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.133138
  validation loss:		0.208950
  validation accuracy:		93.26 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.134047
  validation loss:		0.199353
  validation accuracy:		93.26 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.132475
  validation loss:		0.205768
  validation accuracy:		93.37 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.132131
  validation loss:		0.209466
  validation accuracy:		93.26 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.131436
  validation loss:		0.208536
  validation accuracy:		93.59 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.130935
  validation loss:		0.202150
  validation accuracy:		93.15 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.133015
  validation loss:		0.204078
  validation accuracy:		93.37 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.130980
  validation loss:		0.210793
  validation accuracy:		93.48 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.129545
  validation loss:		0.197692
  validation accuracy:		93.26 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.129823
  validation loss:		0.216403
  validation accuracy:		93.37 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.132503
  validation loss:		0.202056
  validation accuracy:		93.04 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.132365
  validation loss:		0.205467
  validation accuracy:		93.48 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.129052
  validation loss:		0.209864
  validation accuracy:		93.70 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.128280
  validation loss:		0.204535
  validation accuracy:		93.15 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.125962
  validation loss:		0.198348
  validation accuracy:		93.26 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.127466
  validation loss:		0.204047
  validation accuracy:		93.48 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.124734
  validation loss:		0.207326
  validation accuracy:		93.26 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.126271
  validation loss:		0.205088
  validation accuracy:		93.48 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.125137
  validation loss:		0.210157
  validation accuracy:		92.83 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.126627
  validation loss:		0.204936
  validation accuracy:		93.26 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.123115
  validation loss:		0.201259
  validation accuracy:		93.37 %
Epoch 281 of 2000 took 0.037s
  training loss:		0.125781
  validation loss:		0.211920
  validation accuracy:		93.37 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.127178
  validation loss:		0.209473
  validation accuracy:		93.26 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.127372
  validation loss:		0.209730
  validation accuracy:		93.37 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.121945
  validation loss:		0.201576
  validation accuracy:		93.26 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.118422
  validation loss:		0.205923
  validation accuracy:		93.26 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.122135
  validation loss:		0.202578
  validation accuracy:		93.15 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.119843
  validation loss:		0.204651
  validation accuracy:		93.26 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.119895
  validation loss:		0.203272
  validation accuracy:		93.26 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.123381
  validation loss:		0.204380
  validation accuracy:		93.59 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.123144
  validation loss:		0.205056
  validation accuracy:		93.37 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.119580
  validation loss:		0.200972
  validation accuracy:		93.48 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.123065
  validation loss:		0.214341
  validation accuracy:		93.04 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.121017
  validation loss:		0.206967
  validation accuracy:		93.37 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.118101
  validation loss:		0.201194
  validation accuracy:		93.48 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.121726
  validation loss:		0.211254
  validation accuracy:		93.48 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.120589
  validation loss:		0.208749
  validation accuracy:		93.26 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.118486
  validation loss:		0.202597
  validation accuracy:		93.26 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.120235
  validation loss:		0.200039
  validation accuracy:		93.70 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.118540
  validation loss:		0.214597
  validation accuracy:		93.59 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.118014
  validation loss:		0.199881
  validation accuracy:		93.37 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.118601
  validation loss:		0.201699
  validation accuracy:		93.15 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.116036
  validation loss:		0.202192
  validation accuracy:		93.37 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.115142
  validation loss:		0.202846
  validation accuracy:		93.26 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.116508
  validation loss:		0.209010
  validation accuracy:		93.04 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.116917
  validation loss:		0.198981
  validation accuracy:		93.70 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.117520
  validation loss:		0.201450
  validation accuracy:		93.37 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.117213
  validation loss:		0.210154
  validation accuracy:		93.37 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.116367
  validation loss:		0.201978
  validation accuracy:		93.37 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.116730
  validation loss:		0.207450
  validation accuracy:		93.26 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.115489
  validation loss:		0.198793
  validation accuracy:		93.70 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.115325
  validation loss:		0.208488
  validation accuracy:		93.26 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.113835
  validation loss:		0.205418
  validation accuracy:		93.37 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.114787
  validation loss:		0.203787
  validation accuracy:		93.37 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.115052
  validation loss:		0.202098
  validation accuracy:		93.59 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.112602
  validation loss:		0.209078
  validation accuracy:		93.37 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.112531
  validation loss:		0.210363
  validation accuracy:		93.15 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.112496
  validation loss:		0.200213
  validation accuracy:		93.59 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.113037
  validation loss:		0.211052
  validation accuracy:		93.37 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.113805
  validation loss:		0.202585
  validation accuracy:		93.37 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.114378
  validation loss:		0.211867
  validation accuracy:		93.15 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.115377
  validation loss:		0.200573
  validation accuracy:		93.91 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.112964
  validation loss:		0.206972
  validation accuracy:		93.26 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.110924
  validation loss:		0.203864
  validation accuracy:		93.26 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.109188
  validation loss:		0.207781
  validation accuracy:		93.04 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.109651
  validation loss:		0.204517
  validation accuracy:		93.37 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.108044
  validation loss:		0.209961
  validation accuracy:		93.80 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.110647
  validation loss:		0.211545
  validation accuracy:		93.15 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.107315
  validation loss:		0.204108
  validation accuracy:		93.48 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.109703
  validation loss:		0.206143
  validation accuracy:		93.48 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.110914
  validation loss:		0.207924
  validation accuracy:		93.37 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.106319
  validation loss:		0.203407
  validation accuracy:		93.15 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.104631
  validation loss:		0.207575
  validation accuracy:		93.15 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.106390
  validation loss:		0.202570
  validation accuracy:		93.37 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.107722
  validation loss:		0.205910
  validation accuracy:		93.26 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.105051
  validation loss:		0.205731
  validation accuracy:		93.48 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.105215
  validation loss:		0.203907
  validation accuracy:		93.48 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.107248
  validation loss:		0.201812
  validation accuracy:		93.48 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.106314
  validation loss:		0.204746
  validation accuracy:		93.59 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.101693
  validation loss:		0.206245
  validation accuracy:		93.59 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.104559
  validation loss:		0.207128
  validation accuracy:		93.48 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.106368
  validation loss:		0.207511
  validation accuracy:		93.48 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.106782
  validation loss:		0.204662
  validation accuracy:		93.70 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.106454
  validation loss:		0.208262
  validation accuracy:		93.26 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.108487
  validation loss:		0.209750
  validation accuracy:		93.15 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.105888
  validation loss:		0.210484
  validation accuracy:		93.91 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.103701
  validation loss:		0.205847
  validation accuracy:		93.70 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.102313
  validation loss:		0.209008
  validation accuracy:		93.37 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.102240
  validation loss:		0.212483
  validation accuracy:		93.04 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.100951
  validation loss:		0.201527
  validation accuracy:		93.48 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.102346
  validation loss:		0.208178
  validation accuracy:		93.37 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.103270
  validation loss:		0.205408
  validation accuracy:		94.13 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.101866
  validation loss:		0.205996
  validation accuracy:		93.48 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.102540
  validation loss:		0.217077
  validation accuracy:		93.15 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.103041
  validation loss:		0.207329
  validation accuracy:		94.13 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.099942
  validation loss:		0.206575
  validation accuracy:		93.37 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.101210
  validation loss:		0.208470
  validation accuracy:		93.26 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.103206
  validation loss:		0.205317
  validation accuracy:		93.91 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.101927
  validation loss:		0.213321
  validation accuracy:		93.26 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.101018
  validation loss:		0.210156
  validation accuracy:		92.93 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.098939
  validation loss:		0.210894
  validation accuracy:		93.59 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.098712
  validation loss:		0.208478
  validation accuracy:		93.48 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.099756
  validation loss:		0.217155
  validation accuracy:		93.15 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.100785
  validation loss:		0.210584
  validation accuracy:		93.91 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.099132
  validation loss:		0.211558
  validation accuracy:		92.83 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.099142
  validation loss:		0.207880
  validation accuracy:		93.37 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.099110
  validation loss:		0.212740
  validation accuracy:		93.15 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.093667
  validation loss:		0.216232
  validation accuracy:		93.37 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.099979
  validation loss:		0.210930
  validation accuracy:		93.26 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.098363
  validation loss:		0.208085
  validation accuracy:		93.70 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.099234
  validation loss:		0.212881
  validation accuracy:		93.70 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.094862
  validation loss:		0.209498
  validation accuracy:		93.26 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.096932
  validation loss:		0.208410
  validation accuracy:		93.37 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.096771
  validation loss:		0.205971
  validation accuracy:		93.80 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.095650
  validation loss:		0.208150
  validation accuracy:		93.70 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.096372
  validation loss:		0.211424
  validation accuracy:		93.37 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.095203
  validation loss:		0.210268
  validation accuracy:		93.48 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.097001
  validation loss:		0.216960
  validation accuracy:		93.15 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.095392
  validation loss:		0.210679
  validation accuracy:		93.48 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.094684
  validation loss:		0.209368
  validation accuracy:		93.59 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.095966
  validation loss:		0.203272
  validation accuracy:		93.70 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.092431
  validation loss:		0.211233
  validation accuracy:		92.93 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.090764
  validation loss:		0.208684
  validation accuracy:		93.70 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.094380
  validation loss:		0.210672
  validation accuracy:		93.26 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.091669
  validation loss:		0.212086
  validation accuracy:		93.70 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.093012
  validation loss:		0.207343
  validation accuracy:		93.26 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.096144
  validation loss:		0.211323
  validation accuracy:		93.59 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.092768
  validation loss:		0.211002
  validation accuracy:		93.48 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.090972
  validation loss:		0.215245
  validation accuracy:		93.37 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.093110
  validation loss:		0.214747
  validation accuracy:		93.59 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.089716
  validation loss:		0.209397
  validation accuracy:		93.91 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.092183
  validation loss:		0.209779
  validation accuracy:		93.48 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.091360
  validation loss:		0.212813
  validation accuracy:		93.59 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.092965
  validation loss:		0.218050
  validation accuracy:		93.59 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.091992
  validation loss:		0.212527
  validation accuracy:		93.37 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.089070
  validation loss:		0.212510
  validation accuracy:		93.59 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.089209
  validation loss:		0.209661
  validation accuracy:		93.70 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.088437
  validation loss:		0.209891
  validation accuracy:		93.80 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.091430
  validation loss:		0.213247
  validation accuracy:		93.15 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.089886
  validation loss:		0.208397
  validation accuracy:		93.70 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.092061
  validation loss:		0.208868
  validation accuracy:		93.91 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.087619
  validation loss:		0.212281
  validation accuracy:		93.59 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.091301
  validation loss:		0.210141
  validation accuracy:		93.70 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.089016
  validation loss:		0.211241
  validation accuracy:		93.37 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.090935
  validation loss:		0.209171
  validation accuracy:		93.91 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.088409
  validation loss:		0.219369
  validation accuracy:		93.26 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.087486
  validation loss:		0.209033
  validation accuracy:		93.70 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.088375
  validation loss:		0.217317
  validation accuracy:		93.48 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.090472
  validation loss:		0.212227
  validation accuracy:		93.26 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.089255
  validation loss:		0.208650
  validation accuracy:		93.70 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.089453
  validation loss:		0.221942
  validation accuracy:		93.37 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.088280
  validation loss:		0.209488
  validation accuracy:		93.70 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.087352
  validation loss:		0.219275
  validation accuracy:		93.04 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.086061
  validation loss:		0.214598
  validation accuracy:		93.80 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.084663
  validation loss:		0.215334
  validation accuracy:		93.70 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.084338
  validation loss:		0.210224
  validation accuracy:		93.70 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.087885
  validation loss:		0.217758
  validation accuracy:		93.48 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.084905
  validation loss:		0.213590
  validation accuracy:		93.91 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.084906
  validation loss:		0.207536
  validation accuracy:		93.59 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.086871
  validation loss:		0.216037
  validation accuracy:		93.48 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.086805
  validation loss:		0.214719
  validation accuracy:		93.70 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.086342
  validation loss:		0.216574
  validation accuracy:		93.91 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.084634
  validation loss:		0.215964
  validation accuracy:		93.59 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.085048
  validation loss:		0.220499
  validation accuracy:		93.48 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.085130
  validation loss:		0.210793
  validation accuracy:		93.59 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.083460
  validation loss:		0.220132
  validation accuracy:		93.59 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.084371
  validation loss:		0.216188
  validation accuracy:		93.70 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.082535
  validation loss:		0.213619
  validation accuracy:		93.70 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.086284
  validation loss:		0.211792
  validation accuracy:		93.80 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.083102
  validation loss:		0.223433
  validation accuracy:		93.70 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.085542
  validation loss:		0.220432
  validation accuracy:		93.91 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.085502
  validation loss:		0.215003
  validation accuracy:		93.70 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.084746
  validation loss:		0.218638
  validation accuracy:		93.15 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.084165
  validation loss:		0.215971
  validation accuracy:		93.59 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.082605
  validation loss:		0.209271
  validation accuracy:		93.37 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.082639
  validation loss:		0.219193
  validation accuracy:		93.48 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.079051
  validation loss:		0.225512
  validation accuracy:		93.48 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.080463
  validation loss:		0.218037
  validation accuracy:		93.37 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.083075
  validation loss:		0.217047
  validation accuracy:		93.48 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.084869
  validation loss:		0.216836
  validation accuracy:		93.59 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.080834
  validation loss:		0.221236
  validation accuracy:		93.26 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.082622
  validation loss:		0.218597
  validation accuracy:		93.59 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.080585
  validation loss:		0.220901
  validation accuracy:		93.48 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.080069
  validation loss:		0.220710
  validation accuracy:		93.59 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.080380
  validation loss:		0.222121
  validation accuracy:		93.48 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.082076
  validation loss:		0.215836
  validation accuracy:		93.91 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.081254
  validation loss:		0.224290
  validation accuracy:		93.37 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.079602
  validation loss:		0.217193
  validation accuracy:		93.59 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.078755
  validation loss:		0.219869
  validation accuracy:		93.37 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.080986
  validation loss:		0.216333
  validation accuracy:		93.48 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.079906
  validation loss:		0.220320
  validation accuracy:		93.48 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.076689
  validation loss:		0.220812
  validation accuracy:		93.70 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.080363
  validation loss:		0.218187
  validation accuracy:		93.91 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.078956
  validation loss:		0.213755
  validation accuracy:		93.70 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.077226
  validation loss:		0.222407
  validation accuracy:		93.48 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.078679
  validation loss:		0.215463
  validation accuracy:		93.80 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.077440
  validation loss:		0.217148
  validation accuracy:		93.91 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.081190
  validation loss:		0.219851
  validation accuracy:		93.59 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.077782
  validation loss:		0.218790
  validation accuracy:		93.59 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.079919
  validation loss:		0.220547
  validation accuracy:		93.48 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.077807
  validation loss:		0.230243
  validation accuracy:		93.59 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.076541
  validation loss:		0.221355
  validation accuracy:		93.48 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.079394
  validation loss:		0.218624
  validation accuracy:		93.59 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.076445
  validation loss:		0.216287
  validation accuracy:		93.48 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.075381
  validation loss:		0.218480
  validation accuracy:		93.59 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.076934
  validation loss:		0.219153
  validation accuracy:		93.80 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.077121
  validation loss:		0.223384
  validation accuracy:		93.26 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.075133
  validation loss:		0.220568
  validation accuracy:		93.70 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.078562
  validation loss:		0.230382
  validation accuracy:		93.15 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.075998
  validation loss:		0.220780
  validation accuracy:		93.80 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.076078
  validation loss:		0.220752
  validation accuracy:		93.37 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.075906
  validation loss:		0.221017
  validation accuracy:		93.48 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.075502
  validation loss:		0.229191
  validation accuracy:		93.59 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.078172
  validation loss:		0.219837
  validation accuracy:		93.91 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.076059
  validation loss:		0.227499
  validation accuracy:		93.48 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.075739
  validation loss:		0.232775
  validation accuracy:		93.70 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.073011
  validation loss:		0.225091
  validation accuracy:		93.48 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.075879
  validation loss:		0.229791
  validation accuracy:		93.48 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.074434
  validation loss:		0.219010
  validation accuracy:		93.59 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.073041
  validation loss:		0.218645
  validation accuracy:		93.80 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.073218
  validation loss:		0.227383
  validation accuracy:		93.04 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.074121
  validation loss:		0.225751
  validation accuracy:		93.70 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.074810
  validation loss:		0.219131
  validation accuracy:		93.80 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.071796
  validation loss:		0.221564
  validation accuracy:		94.02 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.072872
  validation loss:		0.222485
  validation accuracy:		93.48 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.073670
  validation loss:		0.223205
  validation accuracy:		93.59 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.072476
  validation loss:		0.224444
  validation accuracy:		93.48 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.073163
  validation loss:		0.229485
  validation accuracy:		93.91 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.070237
  validation loss:		0.222992
  validation accuracy:		93.48 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.072843
  validation loss:		0.222269
  validation accuracy:		93.70 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.072990
  validation loss:		0.227096
  validation accuracy:		93.48 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.071552
  validation loss:		0.232986
  validation accuracy:		93.48 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.071661
  validation loss:		0.230881
  validation accuracy:		93.48 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.070934
  validation loss:		0.218547
  validation accuracy:		93.59 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.068393
  validation loss:		0.222838
  validation accuracy:		93.70 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.071326
  validation loss:		0.227540
  validation accuracy:		93.26 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.072288
  validation loss:		0.225098
  validation accuracy:		93.70 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.071466
  validation loss:		0.235484
  validation accuracy:		93.59 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.072078
  validation loss:		0.226651
  validation accuracy:		93.48 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.070887
  validation loss:		0.228794
  validation accuracy:		93.37 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.069116
  validation loss:		0.226864
  validation accuracy:		93.70 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.070235
  validation loss:		0.226247
  validation accuracy:		93.37 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.069658
  validation loss:		0.229150
  validation accuracy:		93.48 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.069601
  validation loss:		0.221933
  validation accuracy:		93.80 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.069596
  validation loss:		0.230759
  validation accuracy:		93.48 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.071584
  validation loss:		0.225469
  validation accuracy:		93.70 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.070251
  validation loss:		0.230831
  validation accuracy:		93.37 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.069226
  validation loss:		0.229134
  validation accuracy:		93.37 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.068933
  validation loss:		0.233180
  validation accuracy:		93.26 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.070437
  validation loss:		0.233017
  validation accuracy:		93.70 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.069566
  validation loss:		0.226445
  validation accuracy:		93.48 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.067271
  validation loss:		0.230501
  validation accuracy:		93.59 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.070811
  validation loss:		0.226077
  validation accuracy:		93.48 %
Epoch 513 of 2000 took 0.037s
  training loss:		0.069584
  validation loss:		0.224391
  validation accuracy:		93.80 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.067480
  validation loss:		0.225264
  validation accuracy:		93.70 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.067559
  validation loss:		0.230881
  validation accuracy:		93.59 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.069932
  validation loss:		0.226082
  validation accuracy:		93.37 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.068234
  validation loss:		0.228816
  validation accuracy:		93.91 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.066919
  validation loss:		0.229858
  validation accuracy:		93.48 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.068944
  validation loss:		0.234091
  validation accuracy:		93.70 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.067164
  validation loss:		0.230910
  validation accuracy:		93.48 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.065704
  validation loss:		0.238689
  validation accuracy:		93.91 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.066086
  validation loss:		0.223273
  validation accuracy:		93.59 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.067006
  validation loss:		0.231969
  validation accuracy:		93.37 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.067163
  validation loss:		0.230743
  validation accuracy:		93.48 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.064846
  validation loss:		0.229293
  validation accuracy:		93.59 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.064382
  validation loss:		0.229915
  validation accuracy:		93.26 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.068462
  validation loss:		0.232667
  validation accuracy:		93.70 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.065991
  validation loss:		0.233500
  validation accuracy:		93.48 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.064524
  validation loss:		0.231254
  validation accuracy:		93.48 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.068034
  validation loss:		0.225323
  validation accuracy:		93.70 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.064711
  validation loss:		0.235028
  validation accuracy:		93.59 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.067458
  validation loss:		0.235193
  validation accuracy:		93.59 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.064004
  validation loss:		0.230162
  validation accuracy:		93.70 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.066050
  validation loss:		0.235491
  validation accuracy:		93.48 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.064990
  validation loss:		0.236627
  validation accuracy:		93.59 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.066781
  validation loss:		0.232731
  validation accuracy:		93.26 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.063977
  validation loss:		0.234381
  validation accuracy:		93.48 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.062842
  validation loss:		0.232485
  validation accuracy:		93.59 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.063650
  validation loss:		0.233278
  validation accuracy:		93.48 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.064448
  validation loss:		0.232268
  validation accuracy:		93.59 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.065454
  validation loss:		0.241537
  validation accuracy:		93.59 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.065967
  validation loss:		0.234012
  validation accuracy:		93.59 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.064727
  validation loss:		0.234198
  validation accuracy:		93.48 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.064998
  validation loss:		0.236139
  validation accuracy:		93.91 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.063671
  validation loss:		0.235775
  validation accuracy:		93.48 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.062721
  validation loss:		0.238182
  validation accuracy:		93.48 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.065262
  validation loss:		0.237463
  validation accuracy:		93.48 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.062270
  validation loss:		0.236147
  validation accuracy:		93.59 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.062548
  validation loss:		0.239785
  validation accuracy:		93.59 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.063601
  validation loss:		0.232982
  validation accuracy:		93.48 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.061607
  validation loss:		0.230932
  validation accuracy:		93.59 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.063889
  validation loss:		0.233387
  validation accuracy:		93.59 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.063706
  validation loss:		0.247963
  validation accuracy:		93.37 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.061986
  validation loss:		0.235495
  validation accuracy:		93.70 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.059277
  validation loss:		0.237695
  validation accuracy:		93.37 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.061142
  validation loss:		0.245385
  validation accuracy:		93.37 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.062470
  validation loss:		0.234762
  validation accuracy:		93.48 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.062562
  validation loss:		0.241804
  validation accuracy:		93.48 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.057643
  validation loss:		0.243289
  validation accuracy:		93.59 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.059842
  validation loss:		0.237042
  validation accuracy:		93.48 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.057874
  validation loss:		0.235767
  validation accuracy:		93.37 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.062593
  validation loss:		0.237455
  validation accuracy:		93.48 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.062657
  validation loss:		0.248640
  validation accuracy:		92.93 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.060367
  validation loss:		0.241616
  validation accuracy:		93.59 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.060211
  validation loss:		0.235215
  validation accuracy:		93.59 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.061760
  validation loss:		0.243650
  validation accuracy:		93.59 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.063178
  validation loss:		0.239296
  validation accuracy:		93.48 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.060778
  validation loss:		0.236427
  validation accuracy:		93.70 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.059055
  validation loss:		0.240904
  validation accuracy:		93.26 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.061304
  validation loss:		0.240564
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.059373
  validation loss:		0.238352
  validation accuracy:		93.48 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.059153
  validation loss:		0.235977
  validation accuracy:		93.48 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.060556
  validation loss:		0.245022
  validation accuracy:		93.04 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.059345
  validation loss:		0.239326
  validation accuracy:		93.37 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.058365
  validation loss:		0.238237
  validation accuracy:		93.37 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.057438
  validation loss:		0.244015
  validation accuracy:		93.37 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.060568
  validation loss:		0.239569
  validation accuracy:		93.70 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.059671
  validation loss:		0.250602
  validation accuracy:		93.37 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.060398
  validation loss:		0.237568
  validation accuracy:		93.80 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.058867
  validation loss:		0.237639
  validation accuracy:		93.59 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.058822
  validation loss:		0.245798
  validation accuracy:		93.37 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.058903
  validation loss:		0.243661
  validation accuracy:		93.37 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.059261
  validation loss:		0.241178
  validation accuracy:		93.15 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.055122
  validation loss:		0.242214
  validation accuracy:		93.48 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.058622
  validation loss:		0.244242
  validation accuracy:		93.37 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.059304
  validation loss:		0.245609
  validation accuracy:		93.59 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.059251
  validation loss:		0.242742
  validation accuracy:		93.26 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.055998
  validation loss:		0.245144
  validation accuracy:		93.37 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.056715
  validation loss:		0.247601
  validation accuracy:		93.26 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.059140
  validation loss:		0.243614
  validation accuracy:		93.48 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.057287
  validation loss:		0.243016
  validation accuracy:		93.37 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.056289
  validation loss:		0.246623
  validation accuracy:		93.37 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.053770
  validation loss:		0.252120
  validation accuracy:		93.48 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.056469
  validation loss:		0.240916
  validation accuracy:		93.59 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.054506
  validation loss:		0.243302
  validation accuracy:		93.59 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.057694
  validation loss:		0.243961
  validation accuracy:		93.26 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.055874
  validation loss:		0.250004
  validation accuracy:		93.70 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.055910
  validation loss:		0.244743
  validation accuracy:		93.59 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.056549
  validation loss:		0.244397
  validation accuracy:		93.59 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.056042
  validation loss:		0.251558
  validation accuracy:		93.26 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.055528
  validation loss:		0.251817
  validation accuracy:		93.48 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.057222
  validation loss:		0.243046
  validation accuracy:		93.26 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.054439
  validation loss:		0.250274
  validation accuracy:		93.70 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.054967
  validation loss:		0.243011
  validation accuracy:		93.26 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.057276
  validation loss:		0.245864
  validation accuracy:		93.37 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.055960
  validation loss:		0.242789
  validation accuracy:		93.59 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.056923
  validation loss:		0.249488
  validation accuracy:		93.37 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.053871
  validation loss:		0.240510
  validation accuracy:		93.48 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.054273
  validation loss:		0.250964
  validation accuracy:		93.15 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.053567
  validation loss:		0.250047
  validation accuracy:		93.59 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.054732
  validation loss:		0.244902
  validation accuracy:		93.48 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.050633
  validation loss:		0.249261
  validation accuracy:		93.37 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.055541
  validation loss:		0.246443
  validation accuracy:		93.48 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.055121
  validation loss:		0.258301
  validation accuracy:		93.26 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.055483
  validation loss:		0.249680
  validation accuracy:		93.48 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.054659
  validation loss:		0.248595
  validation accuracy:		93.48 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.052636
  validation loss:		0.246124
  validation accuracy:		93.59 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.051335
  validation loss:		0.251347
  validation accuracy:		93.48 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.054144
  validation loss:		0.253204
  validation accuracy:		93.70 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.053219
  validation loss:		0.252078
  validation accuracy:		93.48 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.053361
  validation loss:		0.250301
  validation accuracy:		93.37 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.053153
  validation loss:		0.256689
  validation accuracy:		93.26 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.052680
  validation loss:		0.247706
  validation accuracy:		93.37 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.052347
  validation loss:		0.250156
  validation accuracy:		93.37 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.052779
  validation loss:		0.247412
  validation accuracy:		93.59 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.051524
  validation loss:		0.250406
  validation accuracy:		93.37 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.052524
  validation loss:		0.255736
  validation accuracy:		93.26 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.052197
  validation loss:		0.257277
  validation accuracy:		93.48 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.052817
  validation loss:		0.253113
  validation accuracy:		93.48 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.051534
  validation loss:		0.254516
  validation accuracy:		93.70 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.052939
  validation loss:		0.254411
  validation accuracy:		93.48 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.054244
  validation loss:		0.252477
  validation accuracy:		93.37 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.052315
  validation loss:		0.253909
  validation accuracy:		93.48 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.050746
  validation loss:		0.254562
  validation accuracy:		93.37 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.051073
  validation loss:		0.258964
  validation accuracy:		93.26 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.049539
  validation loss:		0.256673
  validation accuracy:		93.37 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.051882
  validation loss:		0.261995
  validation accuracy:		93.59 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.051188
  validation loss:		0.255324
  validation accuracy:		93.48 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.048273
  validation loss:		0.249652
  validation accuracy:		93.26 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.051960
  validation loss:		0.249047
  validation accuracy:		93.48 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.049483
  validation loss:		0.256901
  validation accuracy:		93.37 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.051193
  validation loss:		0.261483
  validation accuracy:		93.59 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.050531
  validation loss:		0.250553
  validation accuracy:		93.37 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.052137
  validation loss:		0.261190
  validation accuracy:		93.26 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.051482
  validation loss:		0.258867
  validation accuracy:		93.26 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.050924
  validation loss:		0.263440
  validation accuracy:		93.37 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.050605
  validation loss:		0.252577
  validation accuracy:		93.48 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.048965
  validation loss:		0.257344
  validation accuracy:		93.26 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.050062
  validation loss:		0.250748
  validation accuracy:		93.59 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.049904
  validation loss:		0.259654
  validation accuracy:		93.59 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.050437
  validation loss:		0.250987
  validation accuracy:		93.70 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.049086
  validation loss:		0.262101
  validation accuracy:		93.37 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.049460
  validation loss:		0.251411
  validation accuracy:		93.37 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.048771
  validation loss:		0.258328
  validation accuracy:		93.37 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.048902
  validation loss:		0.261411
  validation accuracy:		93.26 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.048829
  validation loss:		0.256588
  validation accuracy:		93.26 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.049183
  validation loss:		0.253968
  validation accuracy:		93.48 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.046489
  validation loss:		0.263000
  validation accuracy:		93.15 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.048150
  validation loss:		0.257394
  validation accuracy:		93.37 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.048016
  validation loss:		0.256788
  validation accuracy:		93.48 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.048073
  validation loss:		0.258794
  validation accuracy:		93.26 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.048648
  validation loss:		0.262381
  validation accuracy:		93.26 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.047818
  validation loss:		0.260171
  validation accuracy:		93.26 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.048595
  validation loss:		0.263256
  validation accuracy:		93.70 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.047395
  validation loss:		0.266919
  validation accuracy:		93.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.048111
  validation loss:		0.259276
  validation accuracy:		93.37 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.049288
  validation loss:		0.255123
  validation accuracy:		93.37 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.047569
  validation loss:		0.256283
  validation accuracy:		93.48 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.049848
  validation loss:		0.259254
  validation accuracy:		93.37 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.047771
  validation loss:		0.266778
  validation accuracy:		93.26 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.045334
  validation loss:		0.261783
  validation accuracy:		93.26 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.048250
  validation loss:		0.259206
  validation accuracy:		93.48 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.047260
  validation loss:		0.264576
  validation accuracy:		93.48 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.048319
  validation loss:		0.260682
  validation accuracy:		93.70 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.048637
  validation loss:		0.268200
  validation accuracy:		93.37 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.047433
  validation loss:		0.261241
  validation accuracy:		93.37 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.048205
  validation loss:		0.259533
  validation accuracy:		93.59 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.046075
  validation loss:		0.268987
  validation accuracy:		93.48 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.044769
  validation loss:		0.260923
  validation accuracy:		93.70 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.047671
  validation loss:		0.272535
  validation accuracy:		93.26 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.046263
  validation loss:		0.263357
  validation accuracy:		93.26 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.047185
  validation loss:		0.259046
  validation accuracy:		93.59 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.046664
  validation loss:		0.279051
  validation accuracy:		93.04 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.045719
  validation loss:		0.262498
  validation accuracy:		93.59 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.045887
  validation loss:		0.276343
  validation accuracy:		93.70 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.045805
  validation loss:		0.269130
  validation accuracy:		93.37 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.046646
  validation loss:		0.262545
  validation accuracy:		93.48 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.045403
  validation loss:		0.266467
  validation accuracy:		93.26 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.046320
  validation loss:		0.266464
  validation accuracy:		93.48 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.043568
  validation loss:		0.270321
  validation accuracy:		93.48 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.044688
  validation loss:		0.264157
  validation accuracy:		93.48 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.047055
  validation loss:		0.270352
  validation accuracy:		93.15 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.046831
  validation loss:		0.268779
  validation accuracy:		93.48 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.045880
  validation loss:		0.271566
  validation accuracy:		93.15 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.044157
  validation loss:		0.269080
  validation accuracy:		93.26 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.042999
  validation loss:		0.264003
  validation accuracy:		93.26 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.042342
  validation loss:		0.263595
  validation accuracy:		93.48 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.043708
  validation loss:		0.268865
  validation accuracy:		93.48 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.043589
  validation loss:		0.267938
  validation accuracy:		93.48 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.045326
  validation loss:		0.263786
  validation accuracy:		93.26 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.044485
  validation loss:		0.268225
  validation accuracy:		93.37 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.041608
  validation loss:		0.267287
  validation accuracy:		93.59 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.044895
  validation loss:		0.268190
  validation accuracy:		93.48 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.043619
  validation loss:		0.271093
  validation accuracy:		93.37 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.045003
  validation loss:		0.274731
  validation accuracy:		93.59 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.043491
  validation loss:		0.273083
  validation accuracy:		93.70 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.043492
  validation loss:		0.263421
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.044129
  validation loss:		0.267681
  validation accuracy:		93.26 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.043623
  validation loss:		0.276042
  validation accuracy:		93.80 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.042684
  validation loss:		0.279437
  validation accuracy:		93.37 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.042910
  validation loss:		0.273548
  validation accuracy:		93.59 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.041811
  validation loss:		0.275372
  validation accuracy:		93.70 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.043363
  validation loss:		0.262292
  validation accuracy:		93.48 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.042623
  validation loss:		0.275536
  validation accuracy:		93.48 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.044197
  validation loss:		0.274940
  validation accuracy:		93.37 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.040376
  validation loss:		0.277564
  validation accuracy:		93.26 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.043976
  validation loss:		0.268128
  validation accuracy:		93.80 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.040899
  validation loss:		0.275842
  validation accuracy:		93.37 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.042227
  validation loss:		0.274096
  validation accuracy:		93.48 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.042191
  validation loss:		0.273557
  validation accuracy:		93.37 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.042636
  validation loss:		0.278568
  validation accuracy:		93.15 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.042423
  validation loss:		0.277902
  validation accuracy:		93.48 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.042883
  validation loss:		0.277692
  validation accuracy:		93.26 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.041320
  validation loss:		0.272445
  validation accuracy:		93.48 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.044580
  validation loss:		0.271107
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.040583
  validation loss:		0.279263
  validation accuracy:		93.15 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.041515
  validation loss:		0.278899
  validation accuracy:		93.59 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.042295
  validation loss:		0.273199
  validation accuracy:		93.37 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.041674
  validation loss:		0.277754
  validation accuracy:		93.26 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.041974
  validation loss:		0.272112
  validation accuracy:		93.48 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.040296
  validation loss:		0.272085
  validation accuracy:		93.70 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.041627
  validation loss:		0.272660
  validation accuracy:		93.48 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.040324
  validation loss:		0.273091
  validation accuracy:		93.59 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.040814
  validation loss:		0.271754
  validation accuracy:		93.37 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.039346
  validation loss:		0.276181
  validation accuracy:		93.37 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.040831
  validation loss:		0.275835
  validation accuracy:		93.48 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.040802
  validation loss:		0.283304
  validation accuracy:		93.70 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.040475
  validation loss:		0.279517
  validation accuracy:		93.15 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.040900
  validation loss:		0.273577
  validation accuracy:		93.48 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.040193
  validation loss:		0.284204
  validation accuracy:		93.48 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.041163
  validation loss:		0.274035
  validation accuracy:		93.48 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.039811
  validation loss:		0.280319
  validation accuracy:		93.37 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.041193
  validation loss:		0.282861
  validation accuracy:		93.04 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.041339
  validation loss:		0.273183
  validation accuracy:		93.59 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.039372
  validation loss:		0.286295
  validation accuracy:		93.15 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.038653
  validation loss:		0.278709
  validation accuracy:		93.59 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.040119
  validation loss:		0.277777
  validation accuracy:		93.37 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.039749
  validation loss:		0.279520
  validation accuracy:		93.59 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.040345
  validation loss:		0.280592
  validation accuracy:		93.48 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.040505
  validation loss:		0.284284
  validation accuracy:		93.15 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.039871
  validation loss:		0.277119
  validation accuracy:		93.48 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.037833
  validation loss:		0.281122
  validation accuracy:		93.48 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.038436
  validation loss:		0.282430
  validation accuracy:		93.59 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.039013
  validation loss:		0.281820
  validation accuracy:		93.37 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.038987
  validation loss:		0.279047
  validation accuracy:		93.37 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.037842
  validation loss:		0.282102
  validation accuracy:		93.48 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.036902
  validation loss:		0.281158
  validation accuracy:		93.59 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.039042
  validation loss:		0.285664
  validation accuracy:		93.04 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.036978
  validation loss:		0.288967
  validation accuracy:		93.59 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.038389
  validation loss:		0.275999
  validation accuracy:		93.37 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.039642
  validation loss:		0.282104
  validation accuracy:		93.48 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.037910
  validation loss:		0.285484
  validation accuracy:		93.48 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.038091
  validation loss:		0.275998
  validation accuracy:		93.48 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.037683
  validation loss:		0.292604
  validation accuracy:		93.48 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.038117
  validation loss:		0.282163
  validation accuracy:		93.59 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.036685
  validation loss:		0.281849
  validation accuracy:		93.59 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.037356
  validation loss:		0.281809
  validation accuracy:		93.37 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.037571
  validation loss:		0.282953
  validation accuracy:		93.59 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.036962
  validation loss:		0.290072
  validation accuracy:		93.26 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.037127
  validation loss:		0.275026
  validation accuracy:		93.48 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.038101
  validation loss:		0.290774
  validation accuracy:		93.37 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.037083
  validation loss:		0.290723
  validation accuracy:		93.59 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.036100
  validation loss:		0.280814
  validation accuracy:		93.59 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.036891
  validation loss:		0.288438
  validation accuracy:		93.48 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.035586
  validation loss:		0.280556
  validation accuracy:		93.37 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.038036
  validation loss:		0.290841
  validation accuracy:		93.15 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.036944
  validation loss:		0.290616
  validation accuracy:		93.37 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.035126
  validation loss:		0.284038
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.037905
  validation loss:		0.290895
  validation accuracy:		93.48 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.037276
  validation loss:		0.290569
  validation accuracy:		93.26 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.036458
  validation loss:		0.305200
  validation accuracy:		93.26 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.037697
  validation loss:		0.287299
  validation accuracy:		93.59 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.034635
  validation loss:		0.288771
  validation accuracy:		93.04 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.037351
  validation loss:		0.294268
  validation accuracy:		93.48 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.034896
  validation loss:		0.285303
  validation accuracy:		93.26 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.033081
  validation loss:		0.287796
  validation accuracy:		93.48 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.036095
  validation loss:		0.290622
  validation accuracy:		93.15 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.036603
  validation loss:		0.282394
  validation accuracy:		93.91 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.036130
  validation loss:		0.291313
  validation accuracy:		93.15 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.034069
  validation loss:		0.284482
  validation accuracy:		93.48 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.035252
  validation loss:		0.288137
  validation accuracy:		93.59 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.035347
  validation loss:		0.286267
  validation accuracy:		93.59 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.036746
  validation loss:		0.297802
  validation accuracy:		93.26 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.035581
  validation loss:		0.288847
  validation accuracy:		93.70 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.034517
  validation loss:		0.290326
  validation accuracy:		93.48 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.033796
  validation loss:		0.291327
  validation accuracy:		93.37 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.035923
  validation loss:		0.292688
  validation accuracy:		93.70 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.032608
  validation loss:		0.284977
  validation accuracy:		93.59 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.035486
  validation loss:		0.294680
  validation accuracy:		93.04 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.034655
  validation loss:		0.293806
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.034494
  validation loss:		0.291700
  validation accuracy:		93.48 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.035198
  validation loss:		0.296535
  validation accuracy:		93.26 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.035290
  validation loss:		0.299680
  validation accuracy:		93.26 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.033153
  validation loss:		0.290613
  validation accuracy:		93.59 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.034772
  validation loss:		0.288478
  validation accuracy:		93.59 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.033532
  validation loss:		0.292023
  validation accuracy:		93.70 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.034275
  validation loss:		0.287879
  validation accuracy:		93.70 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.034504
  validation loss:		0.296553
  validation accuracy:		93.26 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.033881
  validation loss:		0.290928
  validation accuracy:		93.48 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.034810
  validation loss:		0.297634
  validation accuracy:		93.37 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.035122
  validation loss:		0.298500
  validation accuracy:		93.15 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.032477
  validation loss:		0.301343
  validation accuracy:		93.04 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.033557
  validation loss:		0.296692
  validation accuracy:		93.26 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.033331
  validation loss:		0.288211
  validation accuracy:		93.37 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.031689
  validation loss:		0.299867
  validation accuracy:		93.15 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.030848
  validation loss:		0.293128
  validation accuracy:		93.48 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.033106
  validation loss:		0.296461
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.033221
  validation loss:		0.291023
  validation accuracy:		93.37 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.033636
  validation loss:		0.299771
  validation accuracy:		93.70 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.033535
  validation loss:		0.304772
  validation accuracy:		93.15 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.033192
  validation loss:		0.288543
  validation accuracy:		93.59 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.033440
  validation loss:		0.299893
  validation accuracy:		93.37 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.032812
  validation loss:		0.302501
  validation accuracy:		93.15 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.033675
  validation loss:		0.296148
  validation accuracy:		93.70 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.034184
  validation loss:		0.303032
  validation accuracy:		93.26 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.032958
  validation loss:		0.292420
  validation accuracy:		93.70 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.034038
  validation loss:		0.292640
  validation accuracy:		93.59 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.032547
  validation loss:		0.299246
  validation accuracy:		93.59 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.033214
  validation loss:		0.304325
  validation accuracy:		93.70 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.032772
  validation loss:		0.293840
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.033129
  validation loss:		0.298512
  validation accuracy:		93.70 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.029777
  validation loss:		0.297246
  validation accuracy:		93.48 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.032591
  validation loss:		0.302250
  validation accuracy:		93.37 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.031722
  validation loss:		0.298848
  validation accuracy:		93.80 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.031962
  validation loss:		0.297463
  validation accuracy:		93.48 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.031199
  validation loss:		0.297339
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.030393
  validation loss:		0.314702
  validation accuracy:		93.15 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.032226
  validation loss:		0.300531
  validation accuracy:		93.26 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.032007
  validation loss:		0.295433
  validation accuracy:		93.48 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.031408
  validation loss:		0.315168
  validation accuracy:		92.83 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.031625
  validation loss:		0.295637
  validation accuracy:		93.80 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.030912
  validation loss:		0.298584
  validation accuracy:		93.48 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.030642
  validation loss:		0.303317
  validation accuracy:		93.48 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.028913
  validation loss:		0.303758
  validation accuracy:		93.37 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.029427
  validation loss:		0.297673
  validation accuracy:		93.70 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.030163
  validation loss:		0.298471
  validation accuracy:		93.48 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.029774
  validation loss:		0.305311
  validation accuracy:		93.26 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.031446
  validation loss:		0.295957
  validation accuracy:		93.59 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.030208
  validation loss:		0.308703
  validation accuracy:		93.04 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.031148
  validation loss:		0.306181
  validation accuracy:		93.15 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.030977
  validation loss:		0.303122
  validation accuracy:		93.48 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.030866
  validation loss:		0.302676
  validation accuracy:		93.48 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.030562
  validation loss:		0.307547
  validation accuracy:		93.37 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.029628
  validation loss:		0.296426
  validation accuracy:		93.48 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.029972
  validation loss:		0.308208
  validation accuracy:		93.15 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.030113
  validation loss:		0.306764
  validation accuracy:		93.26 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.031336
  validation loss:		0.298511
  validation accuracy:		93.48 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.029612
  validation loss:		0.311941
  validation accuracy:		93.26 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.030998
  validation loss:		0.303504
  validation accuracy:		93.59 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.029634
  validation loss:		0.307673
  validation accuracy:		93.04 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.029079
  validation loss:		0.305061
  validation accuracy:		93.37 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.029916
  validation loss:		0.306016
  validation accuracy:		93.48 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.030284
  validation loss:		0.307461
  validation accuracy:		93.59 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.030352
  validation loss:		0.303444
  validation accuracy:		93.48 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.028943
  validation loss:		0.301858
  validation accuracy:		93.59 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.029653
  validation loss:		0.313498
  validation accuracy:		93.37 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.028901
  validation loss:		0.318910
  validation accuracy:		93.15 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.029568
  validation loss:		0.307417
  validation accuracy:		93.48 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.029548
  validation loss:		0.308315
  validation accuracy:		93.37 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.029199
  validation loss:		0.306317
  validation accuracy:		93.59 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.027351
  validation loss:		0.305644
  validation accuracy:		93.26 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.029347
  validation loss:		0.306977
  validation accuracy:		93.48 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.029515
  validation loss:		0.309396
  validation accuracy:		93.59 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.029290
  validation loss:		0.308987
  validation accuracy:		93.15 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.029646
  validation loss:		0.307870
  validation accuracy:		93.59 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.029465
  validation loss:		0.307894
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.028992
  validation loss:		0.309267
  validation accuracy:		93.26 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.027659
  validation loss:		0.310823
  validation accuracy:		93.59 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.028942
  validation loss:		0.308624
  validation accuracy:		93.26 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.028237
  validation loss:		0.309453
  validation accuracy:		93.48 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.028785
  validation loss:		0.318217
  validation accuracy:		93.37 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.029808
  validation loss:		0.312357
  validation accuracy:		93.37 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.028227
  validation loss:		0.314894
  validation accuracy:		93.37 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.027950
  validation loss:		0.307418
  validation accuracy:		93.59 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.027555
  validation loss:		0.313792
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.037s
  training loss:		0.028146
  validation loss:		0.308308
  validation accuracy:		93.48 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.028032
  validation loss:		0.306932
  validation accuracy:		93.26 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.027169
  validation loss:		0.310372
  validation accuracy:		93.59 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.028475
  validation loss:		0.306273
  validation accuracy:		93.48 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.027002
  validation loss:		0.318871
  validation accuracy:		93.26 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.026563
  validation loss:		0.309678
  validation accuracy:		93.48 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.027696
  validation loss:		0.311549
  validation accuracy:		93.70 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.027561
  validation loss:		0.310959
  validation accuracy:		93.37 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.027928
  validation loss:		0.310444
  validation accuracy:		93.26 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.026622
  validation loss:		0.315783
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.026663
  validation loss:		0.311228
  validation accuracy:		93.48 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.026506
  validation loss:		0.314762
  validation accuracy:		93.37 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.027063
  validation loss:		0.318525
  validation accuracy:		93.48 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.026819
  validation loss:		0.312626
  validation accuracy:		93.48 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.025248
  validation loss:		0.315932
  validation accuracy:		93.59 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.026811
  validation loss:		0.321318
  validation accuracy:		93.37 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.026765
  validation loss:		0.313779
  validation accuracy:		93.37 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.026209
  validation loss:		0.320855
  validation accuracy:		93.26 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.027079
  validation loss:		0.314491
  validation accuracy:		93.59 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.025599
  validation loss:		0.307727
  validation accuracy:		93.48 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.027925
  validation loss:		0.319678
  validation accuracy:		93.26 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.026988
  validation loss:		0.314627
  validation accuracy:		93.59 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.026843
  validation loss:		0.318430
  validation accuracy:		93.59 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.027598
  validation loss:		0.312858
  validation accuracy:		93.59 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.025516
  validation loss:		0.310515
  validation accuracy:		93.59 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.028313
  validation loss:		0.325515
  validation accuracy:		93.59 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.025516
  validation loss:		0.323039
  validation accuracy:		93.15 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.027079
  validation loss:		0.325006
  validation accuracy:		93.26 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.026598
  validation loss:		0.312391
  validation accuracy:		93.48 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.026759
  validation loss:		0.317201
  validation accuracy:		93.48 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.027571
  validation loss:		0.319488
  validation accuracy:		93.59 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.026360
  validation loss:		0.317205
  validation accuracy:		93.59 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.025976
  validation loss:		0.323573
  validation accuracy:		93.15 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.026369
  validation loss:		0.318217
  validation accuracy:		93.59 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.025939
  validation loss:		0.318405
  validation accuracy:		93.37 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.025761
  validation loss:		0.321619
  validation accuracy:		93.04 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.025627
  validation loss:		0.323687
  validation accuracy:		93.15 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.025364
  validation loss:		0.320792
  validation accuracy:		93.48 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.024427
  validation loss:		0.323988
  validation accuracy:		93.37 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.025526
  validation loss:		0.319700
  validation accuracy:		93.37 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.026169
  validation loss:		0.329613
  validation accuracy:		93.59 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.024498
  validation loss:		0.325255
  validation accuracy:		93.37 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.024513
  validation loss:		0.320618
  validation accuracy:		93.26 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.024523
  validation loss:		0.320485
  validation accuracy:		93.70 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.025571
  validation loss:		0.316331
  validation accuracy:		93.26 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.025104
  validation loss:		0.331119
  validation accuracy:		93.48 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.024702
  validation loss:		0.323659
  validation accuracy:		93.59 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.025411
  validation loss:		0.322865
  validation accuracy:		93.15 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.025022
  validation loss:		0.327682
  validation accuracy:		93.70 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.024903
  validation loss:		0.333579
  validation accuracy:		93.04 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.025410
  validation loss:		0.321276
  validation accuracy:		93.26 %
Epoch 937 of 2000 took 0.036s
  training loss:		0.024649
  validation loss:		0.321053
  validation accuracy:		93.26 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.024929
  validation loss:		0.321832
  validation accuracy:		93.26 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.024671
  validation loss:		0.320023
  validation accuracy:		93.59 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.025171
  validation loss:		0.320938
  validation accuracy:		93.37 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.024518
  validation loss:		0.329719
  validation accuracy:		93.48 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.023513
  validation loss:		0.327836
  validation accuracy:		93.48 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.024046
  validation loss:		0.326743
  validation accuracy:		93.48 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.024972
  validation loss:		0.324267
  validation accuracy:		93.26 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.024164
  validation loss:		0.333346
  validation accuracy:		93.15 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.024275
  validation loss:		0.327479
  validation accuracy:		93.48 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.024780
  validation loss:		0.330752
  validation accuracy:		93.48 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.023494
  validation loss:		0.326227
  validation accuracy:		93.26 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.024220
  validation loss:		0.319517
  validation accuracy:		93.37 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.023723
  validation loss:		0.335282
  validation accuracy:		93.48 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.024435
  validation loss:		0.335318
  validation accuracy:		93.04 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.023532
  validation loss:		0.329327
  validation accuracy:		93.37 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.024011
  validation loss:		0.326445
  validation accuracy:		93.26 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.022638
  validation loss:		0.326793
  validation accuracy:		93.48 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.023932
  validation loss:		0.327928
  validation accuracy:		93.26 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.023447
  validation loss:		0.327138
  validation accuracy:		93.48 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.024069
  validation loss:		0.332790
  validation accuracy:		93.48 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.024211
  validation loss:		0.324135
  validation accuracy:		93.37 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.023164
  validation loss:		0.334098
  validation accuracy:		93.15 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.023742
  validation loss:		0.333892
  validation accuracy:		93.26 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.023819
  validation loss:		0.332332
  validation accuracy:		93.26 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.023514
  validation loss:		0.337124
  validation accuracy:		93.26 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.023637
  validation loss:		0.333105
  validation accuracy:		93.15 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.023586
  validation loss:		0.335240
  validation accuracy:		93.26 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.023645
  validation loss:		0.329490
  validation accuracy:		93.37 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.022945
  validation loss:		0.329220
  validation accuracy:		93.26 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.022925
  validation loss:		0.330645
  validation accuracy:		93.15 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.022938
  validation loss:		0.329251
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.022677
  validation loss:		0.329376
  validation accuracy:		93.37 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.022549
  validation loss:		0.331746
  validation accuracy:		93.15 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.022214
  validation loss:		0.332630
  validation accuracy:		93.48 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.022100
  validation loss:		0.334287
  validation accuracy:		93.04 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.022389
  validation loss:		0.331550
  validation accuracy:		93.37 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.022291
  validation loss:		0.336237
  validation accuracy:		93.15 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.022652
  validation loss:		0.328911
  validation accuracy:		93.59 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.023294
  validation loss:		0.324182
  validation accuracy:		93.70 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.022494
  validation loss:		0.328891
  validation accuracy:		93.37 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.022685
  validation loss:		0.334141
  validation accuracy:		93.48 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.022254
  validation loss:		0.338075
  validation accuracy:		93.48 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.021718
  validation loss:		0.337126
  validation accuracy:		93.15 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.022208
  validation loss:		0.348534
  validation accuracy:		93.04 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.022603
  validation loss:		0.334209
  validation accuracy:		93.48 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.022320
  validation loss:		0.331939
  validation accuracy:		93.15 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.022187
  validation loss:		0.331499
  validation accuracy:		93.48 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.022369
  validation loss:		0.334727
  validation accuracy:		93.59 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.021850
  validation loss:		0.333944
  validation accuracy:		93.48 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.022569
  validation loss:		0.337373
  validation accuracy:		93.48 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.022088
  validation loss:		0.334789
  validation accuracy:		93.37 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.022186
  validation loss:		0.336798
  validation accuracy:		93.26 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.021366
  validation loss:		0.337461
  validation accuracy:		93.15 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.021985
  validation loss:		0.341930
  validation accuracy:		93.15 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.021016
  validation loss:		0.338027
  validation accuracy:		93.37 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.020972
  validation loss:		0.343376
  validation accuracy:		93.15 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.022082
  validation loss:		0.334915
  validation accuracy:		93.80 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.021709
  validation loss:		0.338069
  validation accuracy:		93.26 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.021123
  validation loss:		0.339146
  validation accuracy:		93.15 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.021329
  validation loss:		0.332707
  validation accuracy:		93.59 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.020968
  validation loss:		0.336883
  validation accuracy:		93.48 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.021065
  validation loss:		0.336335
  validation accuracy:		93.15 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.020103
  validation loss:		0.337821
  validation accuracy:		93.48 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.021752
  validation loss:		0.338591
  validation accuracy:		93.59 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.021330
  validation loss:		0.337520
  validation accuracy:		93.37 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.021585
  validation loss:		0.334936
  validation accuracy:		93.59 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.021324
  validation loss:		0.343213
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.020201
  validation loss:		0.345362
  validation accuracy:		93.48 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.021445
  validation loss:		0.344896
  validation accuracy:		93.37 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.020712
  validation loss:		0.343572
  validation accuracy:		93.37 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.020803
  validation loss:		0.336733
  validation accuracy:		93.48 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.020947
  validation loss:		0.347491
  validation accuracy:		93.37 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.021221
  validation loss:		0.341602
  validation accuracy:		93.04 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.020945
  validation loss:		0.336913
  validation accuracy:		93.48 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.019685
  validation loss:		0.336322
  validation accuracy:		93.37 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.020491
  validation loss:		0.347312
  validation accuracy:		93.59 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.021500
  validation loss:		0.343896
  validation accuracy:		93.04 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.019588
  validation loss:		0.343847
  validation accuracy:		93.15 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.020861
  validation loss:		0.343892
  validation accuracy:		93.26 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.020467
  validation loss:		0.350392
  validation accuracy:		93.37 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.020614
  validation loss:		0.339720
  validation accuracy:		93.48 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.018975
  validation loss:		0.340854
  validation accuracy:		93.15 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.020286
  validation loss:		0.346165
  validation accuracy:		93.59 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.020795
  validation loss:		0.345439
  validation accuracy:		93.26 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.020629
  validation loss:		0.344189
  validation accuracy:		93.48 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.020175
  validation loss:		0.342059
  validation accuracy:		93.37 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.020075
  validation loss:		0.342788
  validation accuracy:		93.26 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.019913
  validation loss:		0.347414
  validation accuracy:		93.26 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.020367
  validation loss:		0.334367
  validation accuracy:		93.48 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.020385
  validation loss:		0.346784
  validation accuracy:		93.48 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.019765
  validation loss:		0.348678
  validation accuracy:		93.15 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.020241
  validation loss:		0.349431
  validation accuracy:		93.26 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.020416
  validation loss:		0.343593
  validation accuracy:		93.59 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.019474
  validation loss:		0.344038
  validation accuracy:		93.37 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.017820
  validation loss:		0.342103
  validation accuracy:		93.59 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.019578
  validation loss:		0.340150
  validation accuracy:		93.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.019790
  validation loss:		0.353873
  validation accuracy:		93.48 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.019898
  validation loss:		0.350631
  validation accuracy:		93.48 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.018430
  validation loss:		0.343295
  validation accuracy:		93.48 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.019437
  validation loss:		0.344098
  validation accuracy:		93.59 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.019684
  validation loss:		0.343435
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.019645
  validation loss:		0.349123
  validation accuracy:		93.15 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.019752
  validation loss:		0.348188
  validation accuracy:		93.48 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.018825
  validation loss:		0.350424
  validation accuracy:		93.48 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.020161
  validation loss:		0.343652
  validation accuracy:		93.37 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.019718
  validation loss:		0.342934
  validation accuracy:		93.70 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.019284
  validation loss:		0.356302
  validation accuracy:		93.04 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.018795
  validation loss:		0.359120
  validation accuracy:		93.59 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.019800
  validation loss:		0.345356
  validation accuracy:		93.37 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.019015
  validation loss:		0.349721
  validation accuracy:		93.37 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.018641
  validation loss:		0.350111
  validation accuracy:		93.15 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.019326
  validation loss:		0.347977
  validation accuracy:		93.59 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.018430
  validation loss:		0.349277
  validation accuracy:		93.37 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.019129
  validation loss:		0.349520
  validation accuracy:		93.37 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.018557
  validation loss:		0.348514
  validation accuracy:		93.26 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.018346
  validation loss:		0.351547
  validation accuracy:		93.48 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.018040
  validation loss:		0.349780
  validation accuracy:		93.59 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.018896
  validation loss:		0.354600
  validation accuracy:		93.15 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.018751
  validation loss:		0.354497
  validation accuracy:		93.26 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.018461
  validation loss:		0.352826
  validation accuracy:		93.15 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.018708
  validation loss:		0.344128
  validation accuracy:		93.80 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.018706
  validation loss:		0.349787
  validation accuracy:		93.48 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.018721
  validation loss:		0.349645
  validation accuracy:		93.48 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.018666
  validation loss:		0.354674
  validation accuracy:		93.15 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.018690
  validation loss:		0.350270
  validation accuracy:		93.26 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.018071
  validation loss:		0.363315
  validation accuracy:		93.37 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.019284
  validation loss:		0.356949
  validation accuracy:		93.48 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.017682
  validation loss:		0.352433
  validation accuracy:		93.48 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.018414
  validation loss:		0.356079
  validation accuracy:		93.37 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.019337
  validation loss:		0.354444
  validation accuracy:		93.37 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.018140
  validation loss:		0.348579
  validation accuracy:		93.48 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.017609
  validation loss:		0.354170
  validation accuracy:		93.59 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.018486
  validation loss:		0.351193
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.018521
  validation loss:		0.357540
  validation accuracy:		93.37 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.018250
  validation loss:		0.360225
  validation accuracy:		93.59 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.017910
  validation loss:		0.348970
  validation accuracy:		93.48 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.017848
  validation loss:		0.362674
  validation accuracy:		93.59 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.018039
  validation loss:		0.366571
  validation accuracy:		93.37 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.017772
  validation loss:		0.357635
  validation accuracy:		93.59 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.018170
  validation loss:		0.363042
  validation accuracy:		93.37 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.017211
  validation loss:		0.358911
  validation accuracy:		93.37 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.018094
  validation loss:		0.352291
  validation accuracy:		93.37 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.017912
  validation loss:		0.349699
  validation accuracy:		93.48 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.017082
  validation loss:		0.352913
  validation accuracy:		93.48 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.016899
  validation loss:		0.354637
  validation accuracy:		93.37 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.017427
  validation loss:		0.353494
  validation accuracy:		93.26 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.017529
  validation loss:		0.361345
  validation accuracy:		93.15 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.017099
  validation loss:		0.353653
  validation accuracy:		93.15 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.017379
  validation loss:		0.354458
  validation accuracy:		93.48 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.017629
  validation loss:		0.358279
  validation accuracy:		93.59 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.016554
  validation loss:		0.360965
  validation accuracy:		93.59 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.016328
  validation loss:		0.362237
  validation accuracy:		93.26 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.017533
  validation loss:		0.355614
  validation accuracy:		93.26 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.017083
  validation loss:		0.372334
  validation accuracy:		93.26 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.017698
  validation loss:		0.362388
  validation accuracy:		93.48 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.016964
  validation loss:		0.355327
  validation accuracy:		93.59 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.017484
  validation loss:		0.353023
  validation accuracy:		93.59 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.018151
  validation loss:		0.359563
  validation accuracy:		93.15 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.017369
  validation loss:		0.366926
  validation accuracy:		93.59 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.016861
  validation loss:		0.354819
  validation accuracy:		93.59 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.015725
  validation loss:		0.358418
  validation accuracy:		93.26 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.017191
  validation loss:		0.363827
  validation accuracy:		93.37 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.016736
  validation loss:		0.360059
  validation accuracy:		93.26 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.016404
  validation loss:		0.357442
  validation accuracy:		93.37 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.016947
  validation loss:		0.360746
  validation accuracy:		93.15 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.016945
  validation loss:		0.361949
  validation accuracy:		93.26 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.017408
  validation loss:		0.363638
  validation accuracy:		93.48 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.016331
  validation loss:		0.357907
  validation accuracy:		93.48 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.015471
  validation loss:		0.360025
  validation accuracy:		93.48 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.015631
  validation loss:		0.356481
  validation accuracy:		93.59 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.017096
  validation loss:		0.360830
  validation accuracy:		93.48 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.016658
  validation loss:		0.360517
  validation accuracy:		93.59 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.016643
  validation loss:		0.362736
  validation accuracy:		93.48 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.015450
  validation loss:		0.360666
  validation accuracy:		93.26 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.016480
  validation loss:		0.366543
  validation accuracy:		93.04 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.017288
  validation loss:		0.366008
  validation accuracy:		93.37 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.016599
  validation loss:		0.363025
  validation accuracy:		93.70 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.016760
  validation loss:		0.362514
  validation accuracy:		93.26 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.016557
  validation loss:		0.362224
  validation accuracy:		93.26 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.016499
  validation loss:		0.366455
  validation accuracy:		93.48 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.015248
  validation loss:		0.360150
  validation accuracy:		93.48 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.016445
  validation loss:		0.370396
  validation accuracy:		93.26 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.016054
  validation loss:		0.364802
  validation accuracy:		93.59 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.015299
  validation loss:		0.367234
  validation accuracy:		93.37 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.015866
  validation loss:		0.365856
  validation accuracy:		93.15 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.015946
  validation loss:		0.362539
  validation accuracy:		93.37 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.016356
  validation loss:		0.364647
  validation accuracy:		93.04 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.015933
  validation loss:		0.366732
  validation accuracy:		93.59 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.016147
  validation loss:		0.365361
  validation accuracy:		93.15 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.016355
  validation loss:		0.362637
  validation accuracy:		93.48 %
Epoch 1128 of 2000 took 0.037s
  training loss:		0.015745
  validation loss:		0.366074
  validation accuracy:		93.48 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.015748
  validation loss:		0.367687
  validation accuracy:		93.59 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.015953
  validation loss:		0.366191
  validation accuracy:		93.37 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.015579
  validation loss:		0.365740
  validation accuracy:		93.26 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.015833
  validation loss:		0.364065
  validation accuracy:		93.48 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.015652
  validation loss:		0.367664
  validation accuracy:		93.48 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.015906
  validation loss:		0.370755
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.015359
  validation loss:		0.375642
  validation accuracy:		93.48 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.015617
  validation loss:		0.368523
  validation accuracy:		93.70 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.015890
  validation loss:		0.371577
  validation accuracy:		93.15 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.015159
  validation loss:		0.372327
  validation accuracy:		93.26 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.015912
  validation loss:		0.376863
  validation accuracy:		93.48 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.014642
  validation loss:		0.369670
  validation accuracy:		93.26 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.014577
  validation loss:		0.370377
  validation accuracy:		93.15 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.015350
  validation loss:		0.375779
  validation accuracy:		93.48 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.015776
  validation loss:		0.367391
  validation accuracy:		93.48 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.015658
  validation loss:		0.369723
  validation accuracy:		93.70 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.014002
  validation loss:		0.368506
  validation accuracy:		93.26 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.015229
  validation loss:		0.372290
  validation accuracy:		93.26 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.015124
  validation loss:		0.377299
  validation accuracy:		93.15 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.015134
  validation loss:		0.373751
  validation accuracy:		93.37 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.015047
  validation loss:		0.378617
  validation accuracy:		93.26 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.014912
  validation loss:		0.374671
  validation accuracy:		93.48 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.015325
  validation loss:		0.370830
  validation accuracy:		93.48 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.015006
  validation loss:		0.372564
  validation accuracy:		93.70 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.014059
  validation loss:		0.377738
  validation accuracy:		93.04 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.014614
  validation loss:		0.378093
  validation accuracy:		93.48 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.015041
  validation loss:		0.374322
  validation accuracy:		93.26 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.015260
  validation loss:		0.374145
  validation accuracy:		93.26 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.015249
  validation loss:		0.377774
  validation accuracy:		93.37 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.015147
  validation loss:		0.368480
  validation accuracy:		93.37 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.014797
  validation loss:		0.375715
  validation accuracy:		93.48 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.014763
  validation loss:		0.368335
  validation accuracy:		93.37 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.014891
  validation loss:		0.379332
  validation accuracy:		93.48 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.015093
  validation loss:		0.377988
  validation accuracy:		93.37 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.014232
  validation loss:		0.383878
  validation accuracy:		93.26 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.014900
  validation loss:		0.373025
  validation accuracy:		93.59 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.014712
  validation loss:		0.377153
  validation accuracy:		93.26 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.013981
  validation loss:		0.372989
  validation accuracy:		93.37 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.014577
  validation loss:		0.373161
  validation accuracy:		93.26 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.014876
  validation loss:		0.375627
  validation accuracy:		93.26 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.013994
  validation loss:		0.377974
  validation accuracy:		93.37 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.014716
  validation loss:		0.372108
  validation accuracy:		93.59 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.013396
  validation loss:		0.372989
  validation accuracy:		93.80 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.014764
  validation loss:		0.386673
  validation accuracy:		93.04 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.014763
  validation loss:		0.375560
  validation accuracy:		93.48 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.014222
  validation loss:		0.373801
  validation accuracy:		93.59 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.015239
  validation loss:		0.373833
  validation accuracy:		93.59 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.013887
  validation loss:		0.376090
  validation accuracy:		93.26 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.014066
  validation loss:		0.381648
  validation accuracy:		93.37 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.013568
  validation loss:		0.383475
  validation accuracy:		93.48 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.014392
  validation loss:		0.379638
  validation accuracy:		93.48 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.013950
  validation loss:		0.379270
  validation accuracy:		93.26 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.014258
  validation loss:		0.379105
  validation accuracy:		93.37 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.014177
  validation loss:		0.376688
  validation accuracy:		93.37 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.013382
  validation loss:		0.380662
  validation accuracy:		93.48 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.014195
  validation loss:		0.376591
  validation accuracy:		93.59 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.013366
  validation loss:		0.376244
  validation accuracy:		93.26 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.014187
  validation loss:		0.378025
  validation accuracy:		93.26 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.014104
  validation loss:		0.381727
  validation accuracy:		93.48 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.014011
  validation loss:		0.380280
  validation accuracy:		93.48 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.013933
  validation loss:		0.378989
  validation accuracy:		93.26 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.012994
  validation loss:		0.375332
  validation accuracy:		93.59 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.014409
  validation loss:		0.379321
  validation accuracy:		93.48 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.013785
  validation loss:		0.385044
  validation accuracy:		93.48 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.013971
  validation loss:		0.379356
  validation accuracy:		93.26 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.014047
  validation loss:		0.383600
  validation accuracy:		93.48 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.013366
  validation loss:		0.378729
  validation accuracy:		93.26 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.012753
  validation loss:		0.383959
  validation accuracy:		93.37 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.013785
  validation loss:		0.383632
  validation accuracy:		93.59 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.013854
  validation loss:		0.378163
  validation accuracy:		93.48 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.014012
  validation loss:		0.384702
  validation accuracy:		93.48 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.013506
  validation loss:		0.376063
  validation accuracy:		93.70 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.013740
  validation loss:		0.385126
  validation accuracy:		93.59 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.013415
  validation loss:		0.384202
  validation accuracy:		93.48 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.013587
  validation loss:		0.381975
  validation accuracy:		93.37 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.012926
  validation loss:		0.380036
  validation accuracy:		93.37 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.013479
  validation loss:		0.387535
  validation accuracy:		93.37 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.013472
  validation loss:		0.379827
  validation accuracy:		93.48 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.013314
  validation loss:		0.381770
  validation accuracy:		93.59 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.013534
  validation loss:		0.384243
  validation accuracy:		93.26 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.013312
  validation loss:		0.384837
  validation accuracy:		93.26 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.013566
  validation loss:		0.390366
  validation accuracy:		93.48 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.013669
  validation loss:		0.392312
  validation accuracy:		93.37 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.013629
  validation loss:		0.381610
  validation accuracy:		93.26 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.013395
  validation loss:		0.391317
  validation accuracy:		93.48 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.013082
  validation loss:		0.384343
  validation accuracy:		93.15 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.011975
  validation loss:		0.383392
  validation accuracy:		93.48 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.013542
  validation loss:		0.385931
  validation accuracy:		93.48 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.013245
  validation loss:		0.387908
  validation accuracy:		93.48 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.012849
  validation loss:		0.379375
  validation accuracy:		93.70 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.012788
  validation loss:		0.387028
  validation accuracy:		93.48 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.012853
  validation loss:		0.393266
  validation accuracy:		93.48 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.013020
  validation loss:		0.381869
  validation accuracy:		93.59 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.013005
  validation loss:		0.389863
  validation accuracy:		93.37 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.013100
  validation loss:		0.394183
  validation accuracy:		93.48 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.012602
  validation loss:		0.384161
  validation accuracy:		93.70 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.012374
  validation loss:		0.388754
  validation accuracy:		93.48 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.012725
  validation loss:		0.385771
  validation accuracy:		93.37 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.012204
  validation loss:		0.391506
  validation accuracy:		93.37 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.012843
  validation loss:		0.381952
  validation accuracy:		93.59 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.012937
  validation loss:		0.386004
  validation accuracy:		93.70 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.012651
  validation loss:		0.393055
  validation accuracy:		93.48 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.012708
  validation loss:		0.387701
  validation accuracy:		93.59 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.012799
  validation loss:		0.393960
  validation accuracy:		93.48 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.012783
  validation loss:		0.394776
  validation accuracy:		93.26 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.012428
  validation loss:		0.388562
  validation accuracy:		93.70 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.012580
  validation loss:		0.391818
  validation accuracy:		93.59 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.013002
  validation loss:		0.393552
  validation accuracy:		93.26 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.012841
  validation loss:		0.387559
  validation accuracy:		93.48 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.012251
  validation loss:		0.390167
  validation accuracy:		93.48 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.012948
  validation loss:		0.384021
  validation accuracy:		93.70 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.012559
  validation loss:		0.391742
  validation accuracy:		93.37 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.012159
  validation loss:		0.394296
  validation accuracy:		93.15 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.012745
  validation loss:		0.387759
  validation accuracy:		93.37 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.012397
  validation loss:		0.395641
  validation accuracy:		93.48 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.012435
  validation loss:		0.393360
  validation accuracy:		93.37 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.012469
  validation loss:		0.396201
  validation accuracy:		93.37 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.012323
  validation loss:		0.397064
  validation accuracy:		93.15 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.012498
  validation loss:		0.392866
  validation accuracy:		93.37 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.012282
  validation loss:		0.394428
  validation accuracy:		93.37 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.012418
  validation loss:		0.387857
  validation accuracy:		93.59 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.011975
  validation loss:		0.393230
  validation accuracy:		93.26 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.012276
  validation loss:		0.392834
  validation accuracy:		93.37 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.011946
  validation loss:		0.400514
  validation accuracy:		93.37 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.012384
  validation loss:		0.395560
  validation accuracy:		93.48 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.011821
  validation loss:		0.386644
  validation accuracy:		93.59 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.012092
  validation loss:		0.394490
  validation accuracy:		93.37 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.011965
  validation loss:		0.389496
  validation accuracy:		93.59 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.012087
  validation loss:		0.395938
  validation accuracy:		93.59 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.012364
  validation loss:		0.393985
  validation accuracy:		93.26 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.012374
  validation loss:		0.395443
  validation accuracy:		93.48 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.011898
  validation loss:		0.395849
  validation accuracy:		93.48 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.011750
  validation loss:		0.394284
  validation accuracy:		93.48 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.011940
  validation loss:		0.392328
  validation accuracy:		93.37 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.011123
  validation loss:		0.393361
  validation accuracy:		93.37 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.011820
  validation loss:		0.398217
  validation accuracy:		93.37 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.011944
  validation loss:		0.390434
  validation accuracy:		93.80 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.011858
  validation loss:		0.398945
  validation accuracy:		93.48 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.011162
  validation loss:		0.389033
  validation accuracy:		93.80 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.012102
  validation loss:		0.398376
  validation accuracy:		93.48 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.011553
  validation loss:		0.404393
  validation accuracy:		93.37 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.011914
  validation loss:		0.394997
  validation accuracy:		93.48 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.011929
  validation loss:		0.398303
  validation accuracy:		93.37 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.011626
  validation loss:		0.397453
  validation accuracy:		93.26 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.011706
  validation loss:		0.391724
  validation accuracy:		93.59 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.011147
  validation loss:		0.399167
  validation accuracy:		93.48 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.011117
  validation loss:		0.403240
  validation accuracy:		93.48 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.011447
  validation loss:		0.398768
  validation accuracy:		93.48 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.011521
  validation loss:		0.398627
  validation accuracy:		93.37 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.011853
  validation loss:		0.402751
  validation accuracy:		93.48 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.011465
  validation loss:		0.394892
  validation accuracy:		93.59 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.011145
  validation loss:		0.402814
  validation accuracy:		93.48 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.011490
  validation loss:		0.398510
  validation accuracy:		93.26 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.011590
  validation loss:		0.399368
  validation accuracy:		93.48 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.010927
  validation loss:		0.396686
  validation accuracy:		93.70 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.011468
  validation loss:		0.403620
  validation accuracy:		93.26 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.010894
  validation loss:		0.398596
  validation accuracy:		93.59 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.011526
  validation loss:		0.401810
  validation accuracy:		93.37 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.011599
  validation loss:		0.404715
  validation accuracy:		93.15 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.011491
  validation loss:		0.403251
  validation accuracy:		93.48 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.010751
  validation loss:		0.393889
  validation accuracy:		93.59 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.011210
  validation loss:		0.405304
  validation accuracy:		93.48 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.011260
  validation loss:		0.391164
  validation accuracy:		93.80 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.011551
  validation loss:		0.394898
  validation accuracy:		93.59 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.011271
  validation loss:		0.401039
  validation accuracy:		93.26 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.011111
  validation loss:		0.397303
  validation accuracy:		93.59 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.011002
  validation loss:		0.400832
  validation accuracy:		93.59 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.010559
  validation loss:		0.400963
  validation accuracy:		93.59 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.011045
  validation loss:		0.398261
  validation accuracy:		93.48 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.010962
  validation loss:		0.403085
  validation accuracy:		93.48 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.011261
  validation loss:		0.398862
  validation accuracy:		93.48 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.010421
  validation loss:		0.398260
  validation accuracy:		93.80 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.010870
  validation loss:		0.404743
  validation accuracy:		93.37 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.010830
  validation loss:		0.399095
  validation accuracy:		93.80 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.011130
  validation loss:		0.400352
  validation accuracy:		93.59 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.011227
  validation loss:		0.402308
  validation accuracy:		93.48 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.010993
  validation loss:		0.401272
  validation accuracy:		93.80 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.010831
  validation loss:		0.398416
  validation accuracy:		93.48 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.011008
  validation loss:		0.403182
  validation accuracy:		93.70 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.010767
  validation loss:		0.404076
  validation accuracy:		93.48 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.010892
  validation loss:		0.408562
  validation accuracy:		93.48 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.011011
  validation loss:		0.404755
  validation accuracy:		93.48 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.010686
  validation loss:		0.405750
  validation accuracy:		93.26 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.010754
  validation loss:		0.408567
  validation accuracy:		93.37 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.010854
  validation loss:		0.403488
  validation accuracy:		93.48 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.010514
  validation loss:		0.410092
  validation accuracy:		93.15 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.010973
  validation loss:		0.406731
  validation accuracy:		93.48 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.011100
  validation loss:		0.405298
  validation accuracy:		93.26 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.010551
  validation loss:		0.406028
  validation accuracy:		93.37 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.010324
  validation loss:		0.402189
  validation accuracy:		93.59 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.010739
  validation loss:		0.415679
  validation accuracy:		93.15 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.010820
  validation loss:		0.399611
  validation accuracy:		93.70 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.010404
  validation loss:		0.403612
  validation accuracy:		93.70 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.010648
  validation loss:		0.406735
  validation accuracy:		93.26 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.010251
  validation loss:		0.404154
  validation accuracy:		93.80 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.010191
  validation loss:		0.401692
  validation accuracy:		93.59 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.010606
  validation loss:		0.405211
  validation accuracy:		93.37 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.010533
  validation loss:		0.405682
  validation accuracy:		93.59 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.010425
  validation loss:		0.405813
  validation accuracy:		93.70 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.010244
  validation loss:		0.409856
  validation accuracy:		93.37 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.010325
  validation loss:		0.408148
  validation accuracy:		93.48 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.010458
  validation loss:		0.406645
  validation accuracy:		93.59 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.009709
  validation loss:		0.416237
  validation accuracy:		92.93 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.010157
  validation loss:		0.401600
  validation accuracy:		93.80 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.009772
  validation loss:		0.408989
  validation accuracy:		93.15 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.010170
  validation loss:		0.415249
  validation accuracy:		93.26 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.010499
  validation loss:		0.406826
  validation accuracy:		93.48 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.010420
  validation loss:		0.412144
  validation accuracy:		93.26 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.010200
  validation loss:		0.416506
  validation accuracy:		93.59 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.010089
  validation loss:		0.406217
  validation accuracy:		93.80 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.009473
  validation loss:		0.409542
  validation accuracy:		93.26 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.010243
  validation loss:		0.415372
  validation accuracy:		93.37 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.010203
  validation loss:		0.410209
  validation accuracy:		93.26 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.009937
  validation loss:		0.413021
  validation accuracy:		93.48 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.010156
  validation loss:		0.409027
  validation accuracy:		93.59 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.009776
  validation loss:		0.407954
  validation accuracy:		93.48 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.009984
  validation loss:		0.408444
  validation accuracy:		93.48 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.010132
  validation loss:		0.408149
  validation accuracy:		93.80 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.009424
  validation loss:		0.409782
  validation accuracy:		93.70 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.010419
  validation loss:		0.416857
  validation accuracy:		93.37 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.010487
  validation loss:		0.417713
  validation accuracy:		93.26 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.009934
  validation loss:		0.406624
  validation accuracy:		93.70 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.010307
  validation loss:		0.416933
  validation accuracy:		93.15 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.009726
  validation loss:		0.407365
  validation accuracy:		93.59 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.009598
  validation loss:		0.416175
  validation accuracy:		93.04 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.009850
  validation loss:		0.419625
  validation accuracy:		93.26 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.009917
  validation loss:		0.409657
  validation accuracy:		93.59 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.009902
  validation loss:		0.407944
  validation accuracy:		93.70 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.009580
  validation loss:		0.411985
  validation accuracy:		93.37 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.010066
  validation loss:		0.418227
  validation accuracy:		93.37 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.009695
  validation loss:		0.413886
  validation accuracy:		93.59 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.009487
  validation loss:		0.415672
  validation accuracy:		93.48 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.009147
  validation loss:		0.412062
  validation accuracy:		93.37 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.009362
  validation loss:		0.417500
  validation accuracy:		93.37 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.009611
  validation loss:		0.417067
  validation accuracy:		93.15 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.009702
  validation loss:		0.419489
  validation accuracy:		93.26 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.009735
  validation loss:		0.409862
  validation accuracy:		93.59 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.009627
  validation loss:		0.414935
  validation accuracy:		93.48 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.009685
  validation loss:		0.415584
  validation accuracy:		93.70 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.009418
  validation loss:		0.417330
  validation accuracy:		93.48 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.010057
  validation loss:		0.420564
  validation accuracy:		93.37 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.009589
  validation loss:		0.418782
  validation accuracy:		93.04 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.009344
  validation loss:		0.414308
  validation accuracy:		93.37 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.009510
  validation loss:		0.414096
  validation accuracy:		93.04 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.009111
  validation loss:		0.412001
  validation accuracy:		93.80 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.009260
  validation loss:		0.413897
  validation accuracy:		93.15 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.009224
  validation loss:		0.417450
  validation accuracy:		93.37 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.009369
  validation loss:		0.413859
  validation accuracy:		93.59 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.009255
  validation loss:		0.413045
  validation accuracy:		93.48 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.009113
  validation loss:		0.418400
  validation accuracy:		93.37 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.009613
  validation loss:		0.416070
  validation accuracy:		93.70 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.009373
  validation loss:		0.418892
  validation accuracy:		93.04 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.009219
  validation loss:		0.417116
  validation accuracy:		93.70 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.009492
  validation loss:		0.418286
  validation accuracy:		93.80 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.009506
  validation loss:		0.417250
  validation accuracy:		93.48 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.009244
  validation loss:		0.421042
  validation accuracy:		93.48 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.009127
  validation loss:		0.417671
  validation accuracy:		93.48 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.009097
  validation loss:		0.417515
  validation accuracy:		93.70 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.009143
  validation loss:		0.418898
  validation accuracy:		93.59 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.008979
  validation loss:		0.418479
  validation accuracy:		93.59 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.009238
  validation loss:		0.418899
  validation accuracy:		93.48 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.009003
  validation loss:		0.421308
  validation accuracy:		93.26 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.009227
  validation loss:		0.416839
  validation accuracy:		93.48 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.008839
  validation loss:		0.420506
  validation accuracy:		93.37 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.009011
  validation loss:		0.419178
  validation accuracy:		93.48 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.009206
  validation loss:		0.413071
  validation accuracy:		93.91 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.009056
  validation loss:		0.421906
  validation accuracy:		93.26 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.009149
  validation loss:		0.424117
  validation accuracy:		93.15 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.009030
  validation loss:		0.422449
  validation accuracy:		93.37 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.008826
  validation loss:		0.416606
  validation accuracy:		93.59 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.008969
  validation loss:		0.423249
  validation accuracy:		93.26 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.009131
  validation loss:		0.420947
  validation accuracy:		93.48 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.008875
  validation loss:		0.420924
  validation accuracy:		93.59 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.008964
  validation loss:		0.422221
  validation accuracy:		93.59 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.008904
  validation loss:		0.419945
  validation accuracy:		93.37 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.008701
  validation loss:		0.421929
  validation accuracy:		93.26 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.008818
  validation loss:		0.423182
  validation accuracy:		93.48 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.008836
  validation loss:		0.422146
  validation accuracy:		93.26 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.009019
  validation loss:		0.416048
  validation accuracy:		93.59 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.008661
  validation loss:		0.427511
  validation accuracy:		93.59 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.008690
  validation loss:		0.421715
  validation accuracy:		93.26 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.008699
  validation loss:		0.421845
  validation accuracy:		93.26 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.008845
  validation loss:		0.420939
  validation accuracy:		93.48 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.008868
  validation loss:		0.418477
  validation accuracy:		93.37 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.009040
  validation loss:		0.418690
  validation accuracy:		93.70 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.008751
  validation loss:		0.421929
  validation accuracy:		93.48 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.008562
  validation loss:		0.418491
  validation accuracy:		93.59 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.008503
  validation loss:		0.421726
  validation accuracy:		93.59 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.008775
  validation loss:		0.425033
  validation accuracy:		93.26 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.008709
  validation loss:		0.424803
  validation accuracy:		93.48 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.008445
  validation loss:		0.426415
  validation accuracy:		93.37 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.008618
  validation loss:		0.426374
  validation accuracy:		93.04 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.008295
  validation loss:		0.425550
  validation accuracy:		93.04 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.008371
  validation loss:		0.423698
  validation accuracy:		93.80 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.007995
  validation loss:		0.423678
  validation accuracy:		93.26 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.008322
  validation loss:		0.425414
  validation accuracy:		93.70 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.008455
  validation loss:		0.423340
  validation accuracy:		93.37 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.008530
  validation loss:		0.427448
  validation accuracy:		93.59 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.008203
  validation loss:		0.427565
  validation accuracy:		93.04 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.008565
  validation loss:		0.424572
  validation accuracy:		93.15 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.008645
  validation loss:		0.421498
  validation accuracy:		93.70 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.008426
  validation loss:		0.430348
  validation accuracy:		93.37 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.009159
  validation loss:		0.430906
  validation accuracy:		93.37 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.008565
  validation loss:		0.419470
  validation accuracy:		93.59 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.008486
  validation loss:		0.431892
  validation accuracy:		93.48 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.008438
  validation loss:		0.427379
  validation accuracy:		93.26 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.008207
  validation loss:		0.426151
  validation accuracy:		93.37 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.008427
  validation loss:		0.424215
  validation accuracy:		93.15 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.008212
  validation loss:		0.428181
  validation accuracy:		93.37 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.008415
  validation loss:		0.430337
  validation accuracy:		93.48 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.008599
  validation loss:		0.425906
  validation accuracy:		93.26 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.008465
  validation loss:		0.433792
  validation accuracy:		93.48 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.008202
  validation loss:		0.429808
  validation accuracy:		93.48 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.008135
  validation loss:		0.429682
  validation accuracy:		93.26 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.007673
  validation loss:		0.423641
  validation accuracy:		93.70 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.008402
  validation loss:		0.429965
  validation accuracy:		93.04 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.008291
  validation loss:		0.425037
  validation accuracy:		93.59 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.007959
  validation loss:		0.430404
  validation accuracy:		93.37 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.008356
  validation loss:		0.427199
  validation accuracy:		93.48 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.008257
  validation loss:		0.425443
  validation accuracy:		93.26 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.007766
  validation loss:		0.431660
  validation accuracy:		93.04 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.428464
  validation accuracy:		93.70 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007845
  validation loss:		0.430718
  validation accuracy:		93.48 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.008079
  validation loss:		0.429471
  validation accuracy:		93.15 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.007978
  validation loss:		0.429772
  validation accuracy:		93.37 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.007860
  validation loss:		0.432358
  validation accuracy:		93.48 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.008031
  validation loss:		0.433875
  validation accuracy:		93.15 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.008168
  validation loss:		0.428732
  validation accuracy:		93.59 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.008047
  validation loss:		0.430783
  validation accuracy:		93.59 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.007855
  validation loss:		0.430552
  validation accuracy:		93.26 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.008048
  validation loss:		0.431227
  validation accuracy:		93.15 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007976
  validation loss:		0.437281
  validation accuracy:		93.15 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.007925
  validation loss:		0.432437
  validation accuracy:		93.59 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.007834
  validation loss:		0.433998
  validation accuracy:		93.48 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.008015
  validation loss:		0.432126
  validation accuracy:		93.15 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.007747
  validation loss:		0.433268
  validation accuracy:		93.15 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.007604
  validation loss:		0.433660
  validation accuracy:		93.48 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.008164
  validation loss:		0.436263
  validation accuracy:		93.15 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.007920
  validation loss:		0.433948
  validation accuracy:		93.37 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.007814
  validation loss:		0.435163
  validation accuracy:		93.15 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.007976
  validation loss:		0.434103
  validation accuracy:		93.26 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007754
  validation loss:		0.434449
  validation accuracy:		93.04 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.007762
  validation loss:		0.435970
  validation accuracy:		93.26 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.007603
  validation loss:		0.429843
  validation accuracy:		93.15 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007789
  validation loss:		0.444519
  validation accuracy:		93.26 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007833
  validation loss:		0.432556
  validation accuracy:		93.59 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.007727
  validation loss:		0.430226
  validation accuracy:		93.48 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.007822
  validation loss:		0.433918
  validation accuracy:		93.15 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.007590
  validation loss:		0.434560
  validation accuracy:		93.37 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.007888
  validation loss:		0.431833
  validation accuracy:		93.26 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.007445
  validation loss:		0.435474
  validation accuracy:		93.15 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.007868
  validation loss:		0.430955
  validation accuracy:		93.37 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.442173
  validation accuracy:		93.26 %
Epoch 1482 of 2000 took 0.037s
  training loss:		0.007489
  validation loss:		0.434877
  validation accuracy:		93.04 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.007647
  validation loss:		0.432894
  validation accuracy:		93.48 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.007631
  validation loss:		0.442370
  validation accuracy:		93.48 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.007466
  validation loss:		0.434433
  validation accuracy:		93.26 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.007468
  validation loss:		0.429055
  validation accuracy:		93.48 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.007506
  validation loss:		0.447832
  validation accuracy:		93.26 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.007629
  validation loss:		0.435379
  validation accuracy:		93.15 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.007162
  validation loss:		0.436556
  validation accuracy:		93.26 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.007192
  validation loss:		0.444749
  validation accuracy:		93.04 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.007540
  validation loss:		0.429408
  validation accuracy:		93.70 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.007552
  validation loss:		0.441250
  validation accuracy:		93.37 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.007542
  validation loss:		0.437953
  validation accuracy:		93.15 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.007456
  validation loss:		0.434034
  validation accuracy:		93.37 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.007683
  validation loss:		0.437107
  validation accuracy:		93.37 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.007642
  validation loss:		0.438552
  validation accuracy:		93.15 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.007282
  validation loss:		0.434945
  validation accuracy:		93.59 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.007326
  validation loss:		0.439286
  validation accuracy:		93.15 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.007084
  validation loss:		0.434736
  validation accuracy:		93.48 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.007379
  validation loss:		0.446474
  validation accuracy:		93.26 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.007453
  validation loss:		0.434263
  validation accuracy:		93.26 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.007312
  validation loss:		0.435901
  validation accuracy:		93.48 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.007442
  validation loss:		0.439421
  validation accuracy:		93.26 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.007559
  validation loss:		0.439534
  validation accuracy:		93.26 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.007268
  validation loss:		0.436602
  validation accuracy:		93.26 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.007476
  validation loss:		0.437919
  validation accuracy:		93.26 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.007207
  validation loss:		0.436801
  validation accuracy:		93.48 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.007202
  validation loss:		0.442108
  validation accuracy:		93.48 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.007216
  validation loss:		0.435219
  validation accuracy:		93.48 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.007557
  validation loss:		0.438016
  validation accuracy:		93.26 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.007089
  validation loss:		0.442694
  validation accuracy:		93.59 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.006848
  validation loss:		0.435557
  validation accuracy:		93.48 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.007190
  validation loss:		0.433292
  validation accuracy:		93.59 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.007149
  validation loss:		0.446460
  validation accuracy:		93.04 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.007064
  validation loss:		0.439002
  validation accuracy:		93.26 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.007234
  validation loss:		0.442738
  validation accuracy:		93.15 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.006993
  validation loss:		0.439242
  validation accuracy:		93.37 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.007148
  validation loss:		0.443426
  validation accuracy:		93.04 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.007331
  validation loss:		0.446148
  validation accuracy:		93.04 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.006921
  validation loss:		0.442149
  validation accuracy:		93.15 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.007139
  validation loss:		0.446116
  validation accuracy:		93.15 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.007203
  validation loss:		0.437036
  validation accuracy:		93.48 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.006894
  validation loss:		0.446188
  validation accuracy:		93.15 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.007271
  validation loss:		0.438813
  validation accuracy:		93.26 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.006833
  validation loss:		0.440172
  validation accuracy:		93.59 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.007006
  validation loss:		0.440304
  validation accuracy:		93.15 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.006919
  validation loss:		0.441739
  validation accuracy:		93.15 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.006947
  validation loss:		0.440738
  validation accuracy:		93.15 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.007009
  validation loss:		0.448725
  validation accuracy:		93.15 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.006969
  validation loss:		0.441975
  validation accuracy:		93.37 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006895
  validation loss:		0.441925
  validation accuracy:		93.26 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.006851
  validation loss:		0.444472
  validation accuracy:		93.26 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.006635
  validation loss:		0.439247
  validation accuracy:		93.48 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006994
  validation loss:		0.445573
  validation accuracy:		93.26 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.006899
  validation loss:		0.444822
  validation accuracy:		93.26 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.007031
  validation loss:		0.443020
  validation accuracy:		93.26 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.006791
  validation loss:		0.443981
  validation accuracy:		93.48 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.006618
  validation loss:		0.441878
  validation accuracy:		93.48 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006870
  validation loss:		0.444259
  validation accuracy:		93.26 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.006881
  validation loss:		0.441057
  validation accuracy:		93.26 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006546
  validation loss:		0.446698
  validation accuracy:		92.93 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.006717
  validation loss:		0.445731
  validation accuracy:		93.15 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.006499
  validation loss:		0.443908
  validation accuracy:		93.15 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.006942
  validation loss:		0.448075
  validation accuracy:		93.26 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006651
  validation loss:		0.446160
  validation accuracy:		93.26 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.006580
  validation loss:		0.442733
  validation accuracy:		93.15 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006578
  validation loss:		0.445979
  validation accuracy:		93.04 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006476
  validation loss:		0.445940
  validation accuracy:		93.59 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.007030
  validation loss:		0.447009
  validation accuracy:		93.48 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006751
  validation loss:		0.450562
  validation accuracy:		93.26 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.006775
  validation loss:		0.443510
  validation accuracy:		93.26 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006693
  validation loss:		0.446147
  validation accuracy:		93.15 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.006658
  validation loss:		0.450970
  validation accuracy:		93.26 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006871
  validation loss:		0.448178
  validation accuracy:		93.15 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006836
  validation loss:		0.450573
  validation accuracy:		93.37 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.006738
  validation loss:		0.444227
  validation accuracy:		93.48 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006617
  validation loss:		0.447875
  validation accuracy:		93.26 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006455
  validation loss:		0.448274
  validation accuracy:		93.15 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.006555
  validation loss:		0.454670
  validation accuracy:		93.04 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006593
  validation loss:		0.448671
  validation accuracy:		93.15 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.006525
  validation loss:		0.445079
  validation accuracy:		93.26 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.006657
  validation loss:		0.449799
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.006609
  validation loss:		0.445145
  validation accuracy:		93.37 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.006556
  validation loss:		0.453031
  validation accuracy:		93.15 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.006618
  validation loss:		0.448112
  validation accuracy:		93.70 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.006197
  validation loss:		0.448383
  validation accuracy:		93.15 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.006621
  validation loss:		0.448488
  validation accuracy:		93.26 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006293
  validation loss:		0.449411
  validation accuracy:		93.37 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006696
  validation loss:		0.448949
  validation accuracy:		93.04 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.006537
  validation loss:		0.455520
  validation accuracy:		93.04 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.006541
  validation loss:		0.450063
  validation accuracy:		93.15 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.006393
  validation loss:		0.448500
  validation accuracy:		93.15 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.006383
  validation loss:		0.445280
  validation accuracy:		93.04 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006571
  validation loss:		0.452755
  validation accuracy:		93.04 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.006378
  validation loss:		0.450507
  validation accuracy:		93.37 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.006514
  validation loss:		0.454791
  validation accuracy:		93.04 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.006308
  validation loss:		0.448005
  validation accuracy:		93.15 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.006460
  validation loss:		0.451520
  validation accuracy:		93.04 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.006380
  validation loss:		0.450689
  validation accuracy:		93.15 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.006370
  validation loss:		0.454321
  validation accuracy:		92.93 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.006205
  validation loss:		0.450789
  validation accuracy:		93.15 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.006399
  validation loss:		0.448793
  validation accuracy:		93.15 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.006232
  validation loss:		0.452527
  validation accuracy:		93.04 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.006559
  validation loss:		0.457911
  validation accuracy:		92.93 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.006436
  validation loss:		0.452867
  validation accuracy:		93.04 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.006271
  validation loss:		0.452958
  validation accuracy:		93.04 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.006277
  validation loss:		0.452713
  validation accuracy:		93.04 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.006230
  validation loss:		0.448430
  validation accuracy:		93.48 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.006492
  validation loss:		0.454192
  validation accuracy:		93.04 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.006316
  validation loss:		0.456377
  validation accuracy:		93.15 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.006470
  validation loss:		0.448293
  validation accuracy:		93.15 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.006377
  validation loss:		0.452412
  validation accuracy:		93.37 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.006146
  validation loss:		0.451873
  validation accuracy:		93.04 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006188
  validation loss:		0.456160
  validation accuracy:		93.15 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.006310
  validation loss:		0.450814
  validation accuracy:		93.04 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.006247
  validation loss:		0.456654
  validation accuracy:		93.04 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.006337
  validation loss:		0.454063
  validation accuracy:		93.04 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.006168
  validation loss:		0.447499
  validation accuracy:		93.15 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.006124
  validation loss:		0.454773
  validation accuracy:		92.93 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.006257
  validation loss:		0.448878
  validation accuracy:		93.15 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.006093
  validation loss:		0.456340
  validation accuracy:		93.04 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.006075
  validation loss:		0.457057
  validation accuracy:		93.37 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.006231
  validation loss:		0.452586
  validation accuracy:		93.26 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005929
  validation loss:		0.459522
  validation accuracy:		93.15 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005937
  validation loss:		0.458970
  validation accuracy:		92.93 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.006043
  validation loss:		0.456668
  validation accuracy:		93.48 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.006128
  validation loss:		0.456416
  validation accuracy:		93.04 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.005863
  validation loss:		0.456593
  validation accuracy:		93.15 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.006228
  validation loss:		0.454736
  validation accuracy:		93.15 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.006147
  validation loss:		0.459503
  validation accuracy:		93.15 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.006028
  validation loss:		0.453400
  validation accuracy:		93.37 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.006091
  validation loss:		0.453576
  validation accuracy:		93.37 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005977
  validation loss:		0.458879
  validation accuracy:		92.83 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.005958
  validation loss:		0.458300
  validation accuracy:		93.37 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.005896
  validation loss:		0.451496
  validation accuracy:		93.15 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.006083
  validation loss:		0.454346
  validation accuracy:		93.15 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.005916
  validation loss:		0.459139
  validation accuracy:		93.37 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005958
  validation loss:		0.458593
  validation accuracy:		92.93 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.006197
  validation loss:		0.459516
  validation accuracy:		93.26 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.006166
  validation loss:		0.454713
  validation accuracy:		93.04 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005967
  validation loss:		0.459007
  validation accuracy:		92.93 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.006001
  validation loss:		0.459970
  validation accuracy:		92.93 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.005852
  validation loss:		0.455773
  validation accuracy:		93.37 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.005798
  validation loss:		0.458960
  validation accuracy:		93.26 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.005892
  validation loss:		0.456056
  validation accuracy:		93.15 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.005879
  validation loss:		0.462309
  validation accuracy:		93.26 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005867
  validation loss:		0.457024
  validation accuracy:		93.15 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005777
  validation loss:		0.456786
  validation accuracy:		93.15 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.006030
  validation loss:		0.457183
  validation accuracy:		93.26 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.005779
  validation loss:		0.457878
  validation accuracy:		93.04 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005828
  validation loss:		0.458365
  validation accuracy:		93.04 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005763
  validation loss:		0.455565
  validation accuracy:		93.37 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.006261
  validation loss:		0.460189
  validation accuracy:		93.15 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.006010
  validation loss:		0.458188
  validation accuracy:		93.15 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005809
  validation loss:		0.456781
  validation accuracy:		93.37 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005735
  validation loss:		0.459115
  validation accuracy:		93.04 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005745
  validation loss:		0.460631
  validation accuracy:		93.37 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.005696
  validation loss:		0.463592
  validation accuracy:		92.83 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005991
  validation loss:		0.462598
  validation accuracy:		93.26 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005825
  validation loss:		0.457386
  validation accuracy:		93.04 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.005766
  validation loss:		0.460941
  validation accuracy:		93.04 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005893
  validation loss:		0.459274
  validation accuracy:		93.15 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005757
  validation loss:		0.463334
  validation accuracy:		93.04 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005822
  validation loss:		0.460259
  validation accuracy:		93.37 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.005651
  validation loss:		0.464360
  validation accuracy:		92.93 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.005806
  validation loss:		0.460320
  validation accuracy:		93.04 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.005692
  validation loss:		0.461240
  validation accuracy:		93.04 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.005650
  validation loss:		0.459112
  validation accuracy:		93.04 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005678
  validation loss:		0.458429
  validation accuracy:		93.04 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005536
  validation loss:		0.463318
  validation accuracy:		93.15 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005567
  validation loss:		0.463138
  validation accuracy:		92.93 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005442
  validation loss:		0.463068
  validation accuracy:		93.37 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005736
  validation loss:		0.460126
  validation accuracy:		93.37 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005557
  validation loss:		0.464493
  validation accuracy:		92.93 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.005525
  validation loss:		0.463878
  validation accuracy:		93.37 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.005694
  validation loss:		0.465655
  validation accuracy:		93.04 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005643
  validation loss:		0.466028
  validation accuracy:		93.26 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005618
  validation loss:		0.463112
  validation accuracy:		93.04 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005585
  validation loss:		0.460782
  validation accuracy:		93.04 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005564
  validation loss:		0.463939
  validation accuracy:		93.26 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.005530
  validation loss:		0.459882
  validation accuracy:		93.15 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.005346
  validation loss:		0.464941
  validation accuracy:		93.04 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005604
  validation loss:		0.463049
  validation accuracy:		93.37 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.005331
  validation loss:		0.467710
  validation accuracy:		92.93 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.005452
  validation loss:		0.469158
  validation accuracy:		92.93 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.005553
  validation loss:		0.464532
  validation accuracy:		93.26 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.005593
  validation loss:		0.466904
  validation accuracy:		93.15 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005362
  validation loss:		0.466880
  validation accuracy:		92.83 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005389
  validation loss:		0.461646
  validation accuracy:		93.15 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005715
  validation loss:		0.464748
  validation accuracy:		93.04 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005641
  validation loss:		0.469008
  validation accuracy:		92.93 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005235
  validation loss:		0.465313
  validation accuracy:		93.04 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.005524
  validation loss:		0.461956
  validation accuracy:		93.04 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.005438
  validation loss:		0.471565
  validation accuracy:		93.04 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005462
  validation loss:		0.465922
  validation accuracy:		93.04 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005462
  validation loss:		0.465295
  validation accuracy:		93.15 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.005548
  validation loss:		0.468679
  validation accuracy:		92.93 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005337
  validation loss:		0.465032
  validation accuracy:		93.04 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.005573
  validation loss:		0.466694
  validation accuracy:		93.26 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005380
  validation loss:		0.470740
  validation accuracy:		93.15 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.005442
  validation loss:		0.466460
  validation accuracy:		93.04 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.005396
  validation loss:		0.464773
  validation accuracy:		93.26 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005283
  validation loss:		0.469521
  validation accuracy:		92.93 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.005423
  validation loss:		0.466109
  validation accuracy:		93.59 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.005488
  validation loss:		0.472014
  validation accuracy:		92.93 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005392
  validation loss:		0.466801
  validation accuracy:		93.15 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.005331
  validation loss:		0.465369
  validation accuracy:		93.04 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005379
  validation loss:		0.470193
  validation accuracy:		93.26 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.005213
  validation loss:		0.463914
  validation accuracy:		93.48 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005282
  validation loss:		0.469251
  validation accuracy:		93.04 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.005381
  validation loss:		0.473182
  validation accuracy:		92.93 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.005496
  validation loss:		0.468474
  validation accuracy:		93.04 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.005380
  validation loss:		0.469443
  validation accuracy:		93.04 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.005398
  validation loss:		0.474257
  validation accuracy:		92.93 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.005226
  validation loss:		0.468213
  validation accuracy:		93.15 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.005033
  validation loss:		0.475969
  validation accuracy:		93.15 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.005172
  validation loss:		0.465234
  validation accuracy:		93.15 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.005219
  validation loss:		0.468488
  validation accuracy:		93.26 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005364
  validation loss:		0.471542
  validation accuracy:		93.04 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.005469
  validation loss:		0.472923
  validation accuracy:		92.93 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.005503
  validation loss:		0.478083
  validation accuracy:		92.83 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.005297
  validation loss:		0.473572
  validation accuracy:		93.15 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005179
  validation loss:		0.470298
  validation accuracy:		93.15 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.005191
  validation loss:		0.468293
  validation accuracy:		93.26 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.005096
  validation loss:		0.472567
  validation accuracy:		93.04 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.005290
  validation loss:		0.467204
  validation accuracy:		93.15 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.005219
  validation loss:		0.466312
  validation accuracy:		93.15 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.005169
  validation loss:		0.473658
  validation accuracy:		93.04 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.005247
  validation loss:		0.468330
  validation accuracy:		93.04 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005257
  validation loss:		0.471440
  validation accuracy:		93.04 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.005037
  validation loss:		0.476014
  validation accuracy:		93.26 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.005281
  validation loss:		0.469252
  validation accuracy:		93.15 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.005107
  validation loss:		0.470131
  validation accuracy:		93.15 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.005252
  validation loss:		0.471846
  validation accuracy:		93.04 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.005115
  validation loss:		0.469743
  validation accuracy:		93.15 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.005060
  validation loss:		0.472364
  validation accuracy:		93.37 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.005057
  validation loss:		0.473996
  validation accuracy:		93.04 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004993
  validation loss:		0.471280
  validation accuracy:		93.15 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.005346
  validation loss:		0.474036
  validation accuracy:		93.15 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005234
  validation loss:		0.471427
  validation accuracy:		93.26 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.005170
  validation loss:		0.473233
  validation accuracy:		93.37 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004991
  validation loss:		0.473090
  validation accuracy:		93.15 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.005053
  validation loss:		0.470885
  validation accuracy:		93.37 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004852
  validation loss:		0.477476
  validation accuracy:		92.93 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.005183
  validation loss:		0.471788
  validation accuracy:		93.04 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.005030
  validation loss:		0.475141
  validation accuracy:		93.04 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004824
  validation loss:		0.471344
  validation accuracy:		93.04 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.005062
  validation loss:		0.478093
  validation accuracy:		92.83 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.005047
  validation loss:		0.468556
  validation accuracy:		93.15 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004962
  validation loss:		0.479262
  validation accuracy:		93.04 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004978
  validation loss:		0.476031
  validation accuracy:		93.26 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.005056
  validation loss:		0.472924
  validation accuracy:		93.04 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004886
  validation loss:		0.476693
  validation accuracy:		93.04 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.005009
  validation loss:		0.472052
  validation accuracy:		93.26 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004812
  validation loss:		0.473102
  validation accuracy:		93.15 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.005144
  validation loss:		0.477646
  validation accuracy:		93.04 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.005011
  validation loss:		0.477349
  validation accuracy:		93.15 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004872
  validation loss:		0.473888
  validation accuracy:		93.26 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004917
  validation loss:		0.481282
  validation accuracy:		92.83 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004770
  validation loss:		0.472036
  validation accuracy:		93.15 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.005011
  validation loss:		0.483452
  validation accuracy:		93.04 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.005029
  validation loss:		0.474509
  validation accuracy:		93.15 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.005002
  validation loss:		0.475398
  validation accuracy:		93.15 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004996
  validation loss:		0.472323
  validation accuracy:		93.15 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004940
  validation loss:		0.483194
  validation accuracy:		92.93 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004679
  validation loss:		0.478475
  validation accuracy:		93.26 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004776
  validation loss:		0.476363
  validation accuracy:		93.15 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004890
  validation loss:		0.475050
  validation accuracy:		93.15 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004690
  validation loss:		0.475218
  validation accuracy:		93.04 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004838
  validation loss:		0.473679
  validation accuracy:		93.26 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004937
  validation loss:		0.479979
  validation accuracy:		93.04 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004778
  validation loss:		0.474999
  validation accuracy:		93.15 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004854
  validation loss:		0.477004
  validation accuracy:		93.04 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004767
  validation loss:		0.474827
  validation accuracy:		93.26 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.474400
  validation accuracy:		93.26 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004723
  validation loss:		0.479811
  validation accuracy:		92.93 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004759
  validation loss:		0.476812
  validation accuracy:		93.04 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004762
  validation loss:		0.478586
  validation accuracy:		93.15 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004914
  validation loss:		0.481024
  validation accuracy:		93.04 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004829
  validation loss:		0.478542
  validation accuracy:		93.04 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.476935
  validation accuracy:		93.37 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004735
  validation loss:		0.478067
  validation accuracy:		93.26 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.479582
  validation accuracy:		93.04 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004741
  validation loss:		0.480466
  validation accuracy:		93.04 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004643
  validation loss:		0.478473
  validation accuracy:		93.15 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004719
  validation loss:		0.477450
  validation accuracy:		93.15 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004737
  validation loss:		0.481222
  validation accuracy:		93.15 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004865
  validation loss:		0.485923
  validation accuracy:		92.83 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004879
  validation loss:		0.481833
  validation accuracy:		93.26 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004823
  validation loss:		0.482393
  validation accuracy:		93.04 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004649
  validation loss:		0.478691
  validation accuracy:		93.26 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004720
  validation loss:		0.481662
  validation accuracy:		93.04 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004767
  validation loss:		0.475805
  validation accuracy:		93.15 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004798
  validation loss:		0.486382
  validation accuracy:		93.15 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004663
  validation loss:		0.481426
  validation accuracy:		93.04 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.476134
  validation accuracy:		93.37 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004678
  validation loss:		0.484123
  validation accuracy:		93.04 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004923
  validation loss:		0.478316
  validation accuracy:		93.26 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004693
  validation loss:		0.483041
  validation accuracy:		93.26 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004607
  validation loss:		0.483416
  validation accuracy:		93.04 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004628
  validation loss:		0.481944
  validation accuracy:		93.04 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004615
  validation loss:		0.479601
  validation accuracy:		93.04 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004557
  validation loss:		0.484535
  validation accuracy:		93.15 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004731
  validation loss:		0.483555
  validation accuracy:		93.04 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004647
  validation loss:		0.479088
  validation accuracy:		93.15 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004657
  validation loss:		0.484138
  validation accuracy:		93.15 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004500
  validation loss:		0.482988
  validation accuracy:		93.04 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004676
  validation loss:		0.484109
  validation accuracy:		93.04 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004528
  validation loss:		0.486191
  validation accuracy:		93.15 %
Epoch 1790 of 2000 took 0.036s
  training loss:		0.004647
  validation loss:		0.483305
  validation accuracy:		93.04 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004434
  validation loss:		0.479658
  validation accuracy:		93.04 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004713
  validation loss:		0.484151
  validation accuracy:		93.04 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004638
  validation loss:		0.479240
  validation accuracy:		93.37 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004616
  validation loss:		0.486910
  validation accuracy:		93.04 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004510
  validation loss:		0.484298
  validation accuracy:		93.15 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004593
  validation loss:		0.485693
  validation accuracy:		93.15 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.484646
  validation accuracy:		93.15 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004554
  validation loss:		0.482356
  validation accuracy:		93.15 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004396
  validation loss:		0.485218
  validation accuracy:		93.26 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004551
  validation loss:		0.481374
  validation accuracy:		93.15 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004531
  validation loss:		0.482502
  validation accuracy:		93.04 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004415
  validation loss:		0.482224
  validation accuracy:		93.15 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004412
  validation loss:		0.484904
  validation accuracy:		93.04 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004566
  validation loss:		0.479501
  validation accuracy:		93.26 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004405
  validation loss:		0.484479
  validation accuracy:		93.04 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004456
  validation loss:		0.482678
  validation accuracy:		93.15 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004492
  validation loss:		0.486140
  validation accuracy:		93.04 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004391
  validation loss:		0.486594
  validation accuracy:		93.04 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004571
  validation loss:		0.483562
  validation accuracy:		93.15 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004474
  validation loss:		0.488027
  validation accuracy:		93.15 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004396
  validation loss:		0.481523
  validation accuracy:		93.15 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.004356
  validation loss:		0.487268
  validation accuracy:		93.04 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004407
  validation loss:		0.481555
  validation accuracy:		93.15 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004433
  validation loss:		0.484596
  validation accuracy:		93.15 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004344
  validation loss:		0.485518
  validation accuracy:		93.26 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.483101
  validation accuracy:		93.15 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004529
  validation loss:		0.486457
  validation accuracy:		93.15 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004335
  validation loss:		0.486573
  validation accuracy:		93.04 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004477
  validation loss:		0.488046
  validation accuracy:		93.04 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004369
  validation loss:		0.483994
  validation accuracy:		93.15 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004290
  validation loss:		0.486276
  validation accuracy:		93.26 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004479
  validation loss:		0.485456
  validation accuracy:		93.15 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.004368
  validation loss:		0.488932
  validation accuracy:		93.04 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004403
  validation loss:		0.493546
  validation accuracy:		92.93 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004321
  validation loss:		0.486580
  validation accuracy:		93.15 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.004160
  validation loss:		0.488397
  validation accuracy:		93.04 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004159
  validation loss:		0.488209
  validation accuracy:		93.15 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.004338
  validation loss:		0.487709
  validation accuracy:		93.04 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004406
  validation loss:		0.489496
  validation accuracy:		93.15 %
Epoch 1830 of 2000 took 0.037s
  training loss:		0.004278
  validation loss:		0.490151
  validation accuracy:		92.93 %
Epoch 1831 of 2000 took 0.036s
  training loss:		0.004273
  validation loss:		0.483906
  validation accuracy:		93.15 %
Epoch 1832 of 2000 took 0.036s
  training loss:		0.004252
  validation loss:		0.490500
  validation accuracy:		93.26 %
Epoch 1833 of 2000 took 0.036s
  training loss:		0.004311
  validation loss:		0.490749
  validation accuracy:		93.15 %
Epoch 1834 of 2000 took 0.036s
  training loss:		0.004210
  validation loss:		0.488822
  validation accuracy:		93.15 %
Epoch 1835 of 2000 took 0.036s
  training loss:		0.004375
  validation loss:		0.490637
  validation accuracy:		93.04 %
Epoch 1836 of 2000 took 0.036s
  training loss:		0.004312
  validation loss:		0.485956
  validation accuracy:		93.26 %
Epoch 1837 of 2000 took 0.036s
  training loss:		0.004347
  validation loss:		0.492365
  validation accuracy:		93.04 %
Epoch 1838 of 2000 took 0.036s
  training loss:		0.004177
  validation loss:		0.489772
  validation accuracy:		93.15 %
Epoch 1839 of 2000 took 0.036s
  training loss:		0.004113
  validation loss:		0.488362
  validation accuracy:		93.15 %
Epoch 1840 of 2000 took 0.036s
  training loss:		0.004195
  validation loss:		0.489193
  validation accuracy:		93.15 %
Epoch 1841 of 2000 took 0.036s
  training loss:		0.004322
  validation loss:		0.490294
  validation accuracy:		93.26 %
Epoch 1842 of 2000 took 0.036s
  training loss:		0.004284
  validation loss:		0.484298
  validation accuracy:		93.26 %
Epoch 1843 of 2000 took 0.036s
  training loss:		0.004269
  validation loss:		0.493572
  validation accuracy:		93.04 %
Epoch 1844 of 2000 took 0.036s
  training loss:		0.004376
  validation loss:		0.495296
  validation accuracy:		93.15 %
Epoch 1845 of 2000 took 0.036s
  training loss:		0.004259
  validation loss:		0.491131
  validation accuracy:		93.15 %
Epoch 1846 of 2000 took 0.036s
  training loss:		0.004133
  validation loss:		0.491907
  validation accuracy:		93.04 %
Epoch 1847 of 2000 took 0.036s
  training loss:		0.004342
  validation loss:		0.484958
  validation accuracy:		93.26 %
Epoch 1848 of 2000 took 0.036s
  training loss:		0.004162
  validation loss:		0.490480
  validation accuracy:		93.04 %
Epoch 1849 of 2000 took 0.036s
  training loss:		0.004217
  validation loss:		0.487184
  validation accuracy:		93.04 %
Epoch 1850 of 2000 took 0.036s
  training loss:		0.004217
  validation loss:		0.494334
  validation accuracy:		93.04 %
Epoch 1851 of 2000 took 0.036s
  training loss:		0.004267
  validation loss:		0.490577
  validation accuracy:		93.15 %
Epoch 1852 of 2000 took 0.036s
  training loss:		0.004223
  validation loss:		0.491835
  validation accuracy:		93.04 %
Epoch 1853 of 2000 took 0.037s
  training loss:		0.004049
  validation loss:		0.491327
  validation accuracy:		93.15 %
Epoch 1854 of 2000 took 0.036s
  training loss:		0.004203
  validation loss:		0.493310
  validation accuracy:		93.04 %
Epoch 1855 of 2000 took 0.036s
  training loss:		0.004134
  validation loss:		0.488544
  validation accuracy:		93.04 %
Epoch 1856 of 2000 took 0.036s
  training loss:		0.004073
  validation loss:		0.490539
  validation accuracy:		93.26 %
Epoch 1857 of 2000 took 0.036s
  training loss:		0.004202
  validation loss:		0.490918
  validation accuracy:		93.26 %
Epoch 1858 of 2000 took 0.036s
  training loss:		0.004092
  validation loss:		0.497011
  validation accuracy:		93.04 %
Epoch 1859 of 2000 took 0.036s
  training loss:		0.004148
  validation loss:		0.492147
  validation accuracy:		93.15 %
Epoch 1860 of 2000 took 0.036s
  training loss:		0.004192
  validation loss:		0.493150
  validation accuracy:		92.93 %
Epoch 1861 of 2000 took 0.036s
  training loss:		0.004155
  validation loss:		0.489443
  validation accuracy:		93.26 %
Epoch 1862 of 2000 took 0.036s
  training loss:		0.004245
  validation loss:		0.496126
  validation accuracy:		93.15 %
Epoch 1863 of 2000 took 0.036s
  training loss:		0.004170
  validation loss:		0.491435
  validation accuracy:		93.15 %
Epoch 1864 of 2000 took 0.036s
  training loss:		0.004129
  validation loss:		0.495732
  validation accuracy:		93.26 %
Epoch 1865 of 2000 took 0.036s
  training loss:		0.004217
  validation loss:		0.494552
  validation accuracy:		93.04 %
Epoch 1866 of 2000 took 0.036s
  training loss:		0.003988
  validation loss:		0.491524
  validation accuracy:		93.04 %
Epoch 1867 of 2000 took 0.036s
  training loss:		0.004175
  validation loss:		0.494500
  validation accuracy:		93.15 %
Epoch 1868 of 2000 took 0.036s
  training loss:		0.004065
  validation loss:		0.491958
  validation accuracy:		93.04 %
Epoch 1869 of 2000 took 0.036s
  training loss:		0.004020
  validation loss:		0.491246
  validation accuracy:		93.15 %
Epoch 1870 of 2000 took 0.036s
  training loss:		0.004109
  validation loss:		0.496462
  validation accuracy:		93.15 %
Epoch 1871 of 2000 took 0.036s
  training loss:		0.004093
  validation loss:		0.496125
  validation accuracy:		92.93 %
Epoch 1872 of 2000 took 0.036s
  training loss:		0.004158
  validation loss:		0.494954
  validation accuracy:		93.37 %
Epoch 1873 of 2000 took 0.036s
  training loss:		0.004101
  validation loss:		0.495032
  validation accuracy:		92.93 %
Epoch 1874 of 2000 took 0.036s
  training loss:		0.004182
  validation loss:		0.494276
  validation accuracy:		93.26 %
Epoch 1875 of 2000 took 0.036s
  training loss:		0.004038
  validation loss:		0.502064
  validation accuracy:		93.15 %
Epoch 1876 of 2000 took 0.036s
  training loss:		0.004205
  validation loss:		0.492648
  validation accuracy:		93.15 %
Epoch 1877 of 2000 took 0.036s
  training loss:		0.004097
  validation loss:		0.494172
  validation accuracy:		93.26 %
Epoch 1878 of 2000 took 0.036s
  training loss:		0.004093
  validation loss:		0.499377
  validation accuracy:		92.93 %
Epoch 1879 of 2000 took 0.036s
  training loss:		0.003966
  validation loss:		0.493998
  validation accuracy:		93.26 %
Epoch 1880 of 2000 took 0.036s
  training loss:		0.004018
  validation loss:		0.499049
  validation accuracy:		93.15 %
Epoch 1881 of 2000 took 0.036s
  training loss:		0.004115
  validation loss:		0.494607
  validation accuracy:		93.26 %
Epoch 1882 of 2000 took 0.036s
  training loss:		0.003953
  validation loss:		0.495875
  validation accuracy:		93.15 %
Epoch 1883 of 2000 took 0.036s
  training loss:		0.003952
  validation loss:		0.495483
  validation accuracy:		93.04 %
Epoch 1884 of 2000 took 0.036s
  training loss:		0.004018
  validation loss:		0.498793
  validation accuracy:		92.93 %
Epoch 1885 of 2000 took 0.036s
  training loss:		0.004071
  validation loss:		0.494247
  validation accuracy:		93.15 %
Epoch 1886 of 2000 took 0.036s
  training loss:		0.003985
  validation loss:		0.498867
  validation accuracy:		93.15 %
Epoch 1887 of 2000 took 0.036s
  training loss:		0.003997
  validation loss:		0.493991
  validation accuracy:		93.15 %
Epoch 1888 of 2000 took 0.036s
  training loss:		0.003913
  validation loss:		0.495411
  validation accuracy:		93.15 %
Epoch 1889 of 2000 took 0.036s
  training loss:		0.003993
  validation loss:		0.496564
  validation accuracy:		93.04 %
Epoch 1890 of 2000 took 0.036s
  training loss:		0.003955
  validation loss:		0.495431
  validation accuracy:		93.15 %
Epoch 1891 of 2000 took 0.036s
  training loss:		0.004083
  validation loss:		0.495966
  validation accuracy:		93.04 %
Epoch 1892 of 2000 took 0.036s
  training loss:		0.003949
  validation loss:		0.495159
  validation accuracy:		93.26 %
Epoch 1893 of 2000 took 0.036s
  training loss:		0.003881
  validation loss:		0.492938
  validation accuracy:		93.04 %
Epoch 1894 of 2000 took 0.036s
  training loss:		0.004024
  validation loss:		0.497598
  validation accuracy:		93.15 %
Epoch 1895 of 2000 took 0.036s
  training loss:		0.003871
  validation loss:		0.500539
  validation accuracy:		93.04 %
Epoch 1896 of 2000 took 0.036s
  training loss:		0.003964
  validation loss:		0.496565
  validation accuracy:		93.15 %
Epoch 1897 of 2000 took 0.036s
  training loss:		0.003882
  validation loss:		0.498134
  validation accuracy:		93.26 %
Epoch 1898 of 2000 took 0.036s
  training loss:		0.003963
  validation loss:		0.493364
  validation accuracy:		93.15 %
Epoch 1899 of 2000 took 0.036s
  training loss:		0.003884
  validation loss:		0.498099
  validation accuracy:		93.15 %
Epoch 1900 of 2000 took 0.036s
  training loss:		0.003993
  validation loss:		0.499429
  validation accuracy:		93.26 %
Epoch 1901 of 2000 took 0.036s
  training loss:		0.004009
  validation loss:		0.497205
  validation accuracy:		93.15 %
Epoch 1902 of 2000 took 0.036s
  training loss:		0.003927
  validation loss:		0.497455
  validation accuracy:		92.93 %
Epoch 1903 of 2000 took 0.036s
  training loss:		0.003788
  validation loss:		0.499052
  validation accuracy:		93.15 %
Epoch 1904 of 2000 took 0.036s
  training loss:		0.003923
  validation loss:		0.499070
  validation accuracy:		93.15 %
Epoch 1905 of 2000 took 0.036s
  training loss:		0.003894
  validation loss:		0.496825
  validation accuracy:		93.15 %
Epoch 1906 of 2000 took 0.036s
  training loss:		0.003858
  validation loss:		0.498968
  validation accuracy:		93.04 %
Epoch 1907 of 2000 took 0.036s
  training loss:		0.003932
  validation loss:		0.497181
  validation accuracy:		93.04 %
Epoch 1908 of 2000 took 0.036s
  training loss:		0.003890
  validation loss:		0.498647
  validation accuracy:		93.15 %
Epoch 1909 of 2000 took 0.036s
  training loss:		0.003838
  validation loss:		0.495964
  validation accuracy:		93.26 %
Epoch 1910 of 2000 took 0.036s
  training loss:		0.003853
  validation loss:		0.499566
  validation accuracy:		93.04 %
Epoch 1911 of 2000 took 0.036s
  training loss:		0.003724
  validation loss:		0.500407
  validation accuracy:		93.04 %
Epoch 1912 of 2000 took 0.036s
  training loss:		0.003806
  validation loss:		0.496654
  validation accuracy:		93.15 %
Epoch 1913 of 2000 took 0.036s
  training loss:		0.003784
  validation loss:		0.501256
  validation accuracy:		92.93 %
Epoch 1914 of 2000 took 0.036s
  training loss:		0.003870
  validation loss:		0.503201
  validation accuracy:		93.04 %
Epoch 1915 of 2000 took 0.036s
  training loss:		0.003916
  validation loss:		0.498338
  validation accuracy:		93.26 %
Epoch 1916 of 2000 took 0.036s
  training loss:		0.003906
  validation loss:		0.497714
  validation accuracy:		93.15 %
Epoch 1917 of 2000 took 0.036s
  training loss:		0.003743
  validation loss:		0.500751
  validation accuracy:		93.15 %
Epoch 1918 of 2000 took 0.036s
  training loss:		0.003859
  validation loss:		0.502274
  validation accuracy:		93.04 %
Epoch 1919 of 2000 took 0.036s
  training loss:		0.003882
  validation loss:		0.499062
  validation accuracy:		93.04 %
Epoch 1920 of 2000 took 0.036s
  training loss:		0.003962
  validation loss:		0.497485
  validation accuracy:		93.15 %
Epoch 1921 of 2000 took 0.036s
  training loss:		0.003857
  validation loss:		0.501456
  validation accuracy:		92.93 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003849
  validation loss:		0.502662
  validation accuracy:		92.93 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.501331
  validation accuracy:		93.04 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003735
  validation loss:		0.498535
  validation accuracy:		93.15 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003862
  validation loss:		0.500716
  validation accuracy:		93.15 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003790
  validation loss:		0.505726
  validation accuracy:		92.83 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003819
  validation loss:		0.499951
  validation accuracy:		93.04 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.500653
  validation accuracy:		93.04 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003815
  validation loss:		0.499851
  validation accuracy:		93.15 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003899
  validation loss:		0.502739
  validation accuracy:		93.37 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003770
  validation loss:		0.501056
  validation accuracy:		92.93 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003804
  validation loss:		0.503134
  validation accuracy:		93.04 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003901
  validation loss:		0.503556
  validation accuracy:		93.26 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003821
  validation loss:		0.507229
  validation accuracy:		92.93 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003787
  validation loss:		0.499646
  validation accuracy:		93.26 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003778
  validation loss:		0.499147
  validation accuracy:		93.15 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003838
  validation loss:		0.502210
  validation accuracy:		93.15 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003816
  validation loss:		0.502064
  validation accuracy:		93.04 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003857
  validation loss:		0.507488
  validation accuracy:		93.04 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003755
  validation loss:		0.501512
  validation accuracy:		93.15 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003625
  validation loss:		0.498991
  validation accuracy:		93.15 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.506661
  validation accuracy:		92.93 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003674
  validation loss:		0.502018
  validation accuracy:		93.26 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003726
  validation loss:		0.505063
  validation accuracy:		92.93 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003700
  validation loss:		0.500676
  validation accuracy:		93.04 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003746
  validation loss:		0.504630
  validation accuracy:		93.15 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003716
  validation loss:		0.506406
  validation accuracy:		93.26 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003639
  validation loss:		0.504110
  validation accuracy:		93.15 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003732
  validation loss:		0.508664
  validation accuracy:		92.93 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003741
  validation loss:		0.502490
  validation accuracy:		93.26 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003678
  validation loss:		0.504316
  validation accuracy:		93.04 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003496
  validation loss:		0.499662
  validation accuracy:		93.15 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003736
  validation loss:		0.505043
  validation accuracy:		93.04 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003577
  validation loss:		0.501596
  validation accuracy:		93.04 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003704
  validation loss:		0.508157
  validation accuracy:		92.93 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003710
  validation loss:		0.504538
  validation accuracy:		93.04 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003588
  validation loss:		0.505535
  validation accuracy:		93.15 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003608
  validation loss:		0.506736
  validation accuracy:		93.15 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003729
  validation loss:		0.502646
  validation accuracy:		93.26 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003675
  validation loss:		0.509490
  validation accuracy:		92.93 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003629
  validation loss:		0.507345
  validation accuracy:		93.15 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.510276
  validation accuracy:		93.15 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003537
  validation loss:		0.503137
  validation accuracy:		93.04 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003573
  validation loss:		0.510163
  validation accuracy:		93.15 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003650
  validation loss:		0.506035
  validation accuracy:		92.93 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.504559
  validation accuracy:		93.04 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003640
  validation loss:		0.507271
  validation accuracy:		93.15 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003579
  validation loss:		0.505270
  validation accuracy:		93.04 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003654
  validation loss:		0.508475
  validation accuracy:		93.04 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003640
  validation loss:		0.508795
  validation accuracy:		93.04 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003490
  validation loss:		0.508189
  validation accuracy:		93.15 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003614
  validation loss:		0.506758
  validation accuracy:		93.04 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003599
  validation loss:		0.504666
  validation accuracy:		93.15 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003531
  validation loss:		0.508381
  validation accuracy:		93.15 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003670
  validation loss:		0.507166
  validation accuracy:		93.15 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003603
  validation loss:		0.506124
  validation accuracy:		93.04 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003536
  validation loss:		0.508430
  validation accuracy:		93.15 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003437
  validation loss:		0.503044
  validation accuracy:		93.04 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003578
  validation loss:		0.507688
  validation accuracy:		93.04 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003393
  validation loss:		0.510181
  validation accuracy:		93.04 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003643
  validation loss:		0.506261
  validation accuracy:		93.26 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003532
  validation loss:		0.508949
  validation accuracy:		93.15 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003531
  validation loss:		0.507488
  validation accuracy:		93.04 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003564
  validation loss:		0.510191
  validation accuracy:		93.26 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003595
  validation loss:		0.509947
  validation accuracy:		93.15 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003530
  validation loss:		0.509096
  validation accuracy:		93.04 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003525
  validation loss:		0.503830
  validation accuracy:		93.26 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003523
  validation loss:		0.509686
  validation accuracy:		93.04 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003442
  validation loss:		0.509269
  validation accuracy:		93.15 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003345
  validation loss:		0.507678
  validation accuracy:		93.04 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003457
  validation loss:		0.507942
  validation accuracy:		93.15 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003533
  validation loss:		0.510259
  validation accuracy:		93.04 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003416
  validation loss:		0.507298
  validation accuracy:		93.04 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003474
  validation loss:		0.507693
  validation accuracy:		93.15 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003529
  validation loss:		0.510551
  validation accuracy:		93.04 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003598
  validation loss:		0.507011
  validation accuracy:		93.04 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003466
  validation loss:		0.508847
  validation accuracy:		93.04 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003332
  validation loss:		0.510683
  validation accuracy:		93.15 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003481
  validation loss:		0.514646
  validation accuracy:		93.04 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003417
  validation loss:		0.507929
  validation accuracy:		93.15 %
Final results:
  test loss:			1.248393
  test accuracy:		84.63 %
