Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.102s
  training loss:		3.036623
  validation loss:		2.997253
  validation accuracy:		11.41 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.961484
  validation loss:		2.882825
  validation accuracy:		14.78 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.891094
  validation loss:		2.783824
  validation accuracy:		12.50 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.824723
  validation loss:		2.684676
  validation accuracy:		12.28 %
Epoch 5 of 2000 took 0.097s
  training loss:		2.742075
  validation loss:		2.576246
  validation accuracy:		13.80 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.639393
  validation loss:		2.455714
  validation accuracy:		17.83 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.526147
  validation loss:		2.344437
  validation accuracy:		15.65 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.421034
  validation loss:		2.272379
  validation accuracy:		19.13 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.347586
  validation loss:		2.253569
  validation accuracy:		21.52 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.305232
  validation loss:		2.238042
  validation accuracy:		23.70 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.285177
  validation loss:		2.224438
  validation accuracy:		26.74 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.275434
  validation loss:		2.212209
  validation accuracy:		24.78 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.264271
  validation loss:		2.203734
  validation accuracy:		28.37 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.260596
  validation loss:		2.206187
  validation accuracy:		21.20 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.254665
  validation loss:		2.198822
  validation accuracy:		30.98 %
Epoch 16 of 2000 took 0.098s
  training loss:		2.248697
  validation loss:		2.191347
  validation accuracy:		30.54 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.243480
  validation loss:		2.187719
  validation accuracy:		29.57 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.238199
  validation loss:		2.182406
  validation accuracy:		33.70 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.232395
  validation loss:		2.173961
  validation accuracy:		33.04 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.226397
  validation loss:		2.177499
  validation accuracy:		34.46 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.219878
  validation loss:		2.154419
  validation accuracy:		29.57 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.211815
  validation loss:		2.154447
  validation accuracy:		32.93 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.203674
  validation loss:		2.137125
  validation accuracy:		38.70 %
Epoch 24 of 2000 took 0.098s
  training loss:		2.194582
  validation loss:		2.138086
  validation accuracy:		39.46 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.187969
  validation loss:		2.131454
  validation accuracy:		41.52 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.176492
  validation loss:		2.105173
  validation accuracy:		41.41 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.165971
  validation loss:		2.106474
  validation accuracy:		42.07 %
Epoch 28 of 2000 took 0.098s
  training loss:		2.152778
  validation loss:		2.087430
  validation accuracy:		41.85 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.140240
  validation loss:		2.070948
  validation accuracy:		44.57 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.126662
  validation loss:		2.059567
  validation accuracy:		45.33 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.108050
  validation loss:		2.031024
  validation accuracy:		45.98 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.088144
  validation loss:		2.010720
  validation accuracy:		46.20 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.067127
  validation loss:		1.993252
  validation accuracy:		47.83 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.047275
  validation loss:		1.968026
  validation accuracy:		50.76 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.023752
  validation loss:		1.930761
  validation accuracy:		48.48 %
Epoch 36 of 2000 took 0.097s
  training loss:		1.992303
  validation loss:		1.902572
  validation accuracy:		53.48 %
Epoch 37 of 2000 took 0.097s
  training loss:		1.958740
  validation loss:		1.862690
  validation accuracy:		53.37 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.926401
  validation loss:		1.845876
  validation accuracy:		55.76 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.887879
  validation loss:		1.787951
  validation accuracy:		56.20 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.846576
  validation loss:		1.735420
  validation accuracy:		56.85 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.800643
  validation loss:		1.702292
  validation accuracy:		58.59 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.754653
  validation loss:		1.651752
  validation accuracy:		59.24 %
Epoch 43 of 2000 took 0.102s
  training loss:		1.704961
  validation loss:		1.593346
  validation accuracy:		61.30 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.659411
  validation loss:		1.538219
  validation accuracy:		62.39 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.603709
  validation loss:		1.490110
  validation accuracy:		64.57 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.554531
  validation loss:		1.436617
  validation accuracy:		65.33 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.510334
  validation loss:		1.398127
  validation accuracy:		65.98 %
Epoch 48 of 2000 took 0.097s
  training loss:		1.461526
  validation loss:		1.349063
  validation accuracy:		66.30 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.415629
  validation loss:		1.297301
  validation accuracy:		68.80 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.367788
  validation loss:		1.252473
  validation accuracy:		69.24 %
Epoch 51 of 2000 took 0.097s
  training loss:		1.331597
  validation loss:		1.220663
  validation accuracy:		69.13 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.293570
  validation loss:		1.185694
  validation accuracy:		70.76 %
Epoch 53 of 2000 took 0.097s
  training loss:		1.250040
  validation loss:		1.141313
  validation accuracy:		70.76 %
Epoch 54 of 2000 took 0.097s
  training loss:		1.211029
  validation loss:		1.108254
  validation accuracy:		72.61 %
Epoch 55 of 2000 took 0.097s
  training loss:		1.173934
  validation loss:		1.068842
  validation accuracy:		73.04 %
Epoch 56 of 2000 took 0.097s
  training loss:		1.138365
  validation loss:		1.046336
  validation accuracy:		73.37 %
Epoch 57 of 2000 took 0.097s
  training loss:		1.105100
  validation loss:		1.004842
  validation accuracy:		75.11 %
Epoch 58 of 2000 took 0.097s
  training loss:		1.070575
  validation loss:		0.979771
  validation accuracy:		74.24 %
Epoch 59 of 2000 took 0.098s
  training loss:		1.043363
  validation loss:		0.957601
  validation accuracy:		75.00 %
Epoch 60 of 2000 took 0.097s
  training loss:		1.009531
  validation loss:		0.918146
  validation accuracy:		73.48 %
Epoch 61 of 2000 took 0.097s
  training loss:		0.985680
  validation loss:		0.902419
  validation accuracy:		75.33 %
Epoch 62 of 2000 took 0.098s
  training loss:		0.952797
  validation loss:		0.884208
  validation accuracy:		74.67 %
Epoch 63 of 2000 took 0.097s
  training loss:		0.927639
  validation loss:		0.852214
  validation accuracy:		75.33 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.905101
  validation loss:		0.832040
  validation accuracy:		74.46 %
Epoch 65 of 2000 took 0.098s
  training loss:		0.880741
  validation loss:		0.812820
  validation accuracy:		75.00 %
Epoch 66 of 2000 took 0.097s
  training loss:		0.866431
  validation loss:		0.795643
  validation accuracy:		75.98 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.839829
  validation loss:		0.767520
  validation accuracy:		76.09 %
Epoch 68 of 2000 took 0.097s
  training loss:		0.815274
  validation loss:		0.758330
  validation accuracy:		76.30 %
Epoch 69 of 2000 took 0.097s
  training loss:		0.797267
  validation loss:		0.732916
  validation accuracy:		77.07 %
Epoch 70 of 2000 took 0.097s
  training loss:		0.778091
  validation loss:		0.716595
  validation accuracy:		76.85 %
Epoch 71 of 2000 took 0.097s
  training loss:		0.756903
  validation loss:		0.700094
  validation accuracy:		77.93 %
Epoch 72 of 2000 took 0.097s
  training loss:		0.745816
  validation loss:		0.699698
  validation accuracy:		77.61 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.727951
  validation loss:		0.696702
  validation accuracy:		78.70 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.705666
  validation loss:		0.684985
  validation accuracy:		78.15 %
Epoch 75 of 2000 took 0.097s
  training loss:		0.702401
  validation loss:		0.657386
  validation accuracy:		79.24 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.678166
  validation loss:		0.658417
  validation accuracy:		79.13 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.663178
  validation loss:		0.632238
  validation accuracy:		80.87 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.650765
  validation loss:		0.612538
  validation accuracy:		80.76 %
Epoch 79 of 2000 took 0.097s
  training loss:		0.639289
  validation loss:		0.617195
  validation accuracy:		81.85 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.627954
  validation loss:		0.601223
  validation accuracy:		82.07 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.607983
  validation loss:		0.587019
  validation accuracy:		82.39 %
Epoch 82 of 2000 took 0.097s
  training loss:		0.604739
  validation loss:		0.571354
  validation accuracy:		82.93 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.585094
  validation loss:		0.569657
  validation accuracy:		82.93 %
Epoch 84 of 2000 took 0.097s
  training loss:		0.570714
  validation loss:		0.554283
  validation accuracy:		82.50 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.567746
  validation loss:		0.536214
  validation accuracy:		83.91 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.560908
  validation loss:		0.553923
  validation accuracy:		82.93 %
Epoch 87 of 2000 took 0.097s
  training loss:		0.547888
  validation loss:		0.528080
  validation accuracy:		84.46 %
Epoch 88 of 2000 took 0.097s
  training loss:		0.539741
  validation loss:		0.521621
  validation accuracy:		84.46 %
Epoch 89 of 2000 took 0.097s
  training loss:		0.532716
  validation loss:		0.519912
  validation accuracy:		84.46 %
Epoch 90 of 2000 took 0.098s
  training loss:		0.519940
  validation loss:		0.514762
  validation accuracy:		83.59 %
Epoch 91 of 2000 took 0.097s
  training loss:		0.517000
  validation loss:		0.497460
  validation accuracy:		85.22 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.507740
  validation loss:		0.487671
  validation accuracy:		84.57 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.499154
  validation loss:		0.498122
  validation accuracy:		84.67 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.494533
  validation loss:		0.469647
  validation accuracy:		84.67 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.489331
  validation loss:		0.477116
  validation accuracy:		85.33 %
Epoch 96 of 2000 took 0.097s
  training loss:		0.485365
  validation loss:		0.468432
  validation accuracy:		85.00 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.474509
  validation loss:		0.459637
  validation accuracy:		85.43 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.473719
  validation loss:		0.454679
  validation accuracy:		84.78 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.466514
  validation loss:		0.464281
  validation accuracy:		85.54 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.448768
  validation loss:		0.446470
  validation accuracy:		85.98 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.458085
  validation loss:		0.448183
  validation accuracy:		85.65 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.448371
  validation loss:		0.433155
  validation accuracy:		85.43 %
Epoch 103 of 2000 took 0.098s
  training loss:		0.448846
  validation loss:		0.437262
  validation accuracy:		85.11 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.440324
  validation loss:		0.485457
  validation accuracy:		84.24 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.441365
  validation loss:		0.421320
  validation accuracy:		85.65 %
Epoch 106 of 2000 took 0.098s
  training loss:		0.426406
  validation loss:		0.424778
  validation accuracy:		85.54 %
Epoch 107 of 2000 took 0.097s
  training loss:		0.425135
  validation loss:		0.428787
  validation accuracy:		85.87 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.425096
  validation loss:		0.435302
  validation accuracy:		86.30 %
Epoch 109 of 2000 took 0.097s
  training loss:		0.423589
  validation loss:		0.432220
  validation accuracy:		86.20 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.417300
  validation loss:		0.409655
  validation accuracy:		86.85 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.415144
  validation loss:		0.402848
  validation accuracy:		86.85 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.408569
  validation loss:		0.411347
  validation accuracy:		86.74 %
Epoch 113 of 2000 took 0.102s
  training loss:		0.398028
  validation loss:		0.443158
  validation accuracy:		85.22 %
Epoch 114 of 2000 took 0.098s
  training loss:		0.407717
  validation loss:		0.403347
  validation accuracy:		86.85 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.398206
  validation loss:		0.403688
  validation accuracy:		87.39 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.397549
  validation loss:		0.400109
  validation accuracy:		86.85 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.391988
  validation loss:		0.400828
  validation accuracy:		87.17 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.387531
  validation loss:		0.403541
  validation accuracy:		87.50 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.381640
  validation loss:		0.387746
  validation accuracy:		87.50 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.389404
  validation loss:		0.383463
  validation accuracy:		87.72 %
Epoch 121 of 2000 took 0.098s
  training loss:		0.383363
  validation loss:		0.387352
  validation accuracy:		87.61 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.379278
  validation loss:		0.387782
  validation accuracy:		87.83 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.376527
  validation loss:		0.385800
  validation accuracy:		87.72 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.378947
  validation loss:		0.375525
  validation accuracy:		87.72 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.363242
  validation loss:		0.384758
  validation accuracy:		87.28 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.367860
  validation loss:		0.380644
  validation accuracy:		87.61 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.365065
  validation loss:		0.397941
  validation accuracy:		87.39 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.361678
  validation loss:		0.373884
  validation accuracy:		88.04 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.354369
  validation loss:		0.381539
  validation accuracy:		87.39 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.352243
  validation loss:		0.365263
  validation accuracy:		88.26 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.356894
  validation loss:		0.371715
  validation accuracy:		88.15 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.355126
  validation loss:		0.389881
  validation accuracy:		87.39 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.354000
  validation loss:		0.366744
  validation accuracy:		88.37 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.349138
  validation loss:		0.380864
  validation accuracy:		87.50 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.351725
  validation loss:		0.358032
  validation accuracy:		88.48 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.352461
  validation loss:		0.363142
  validation accuracy:		88.04 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.348013
  validation loss:		0.371902
  validation accuracy:		88.15 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.343375
  validation loss:		0.371878
  validation accuracy:		87.93 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.341364
  validation loss:		0.356561
  validation accuracy:		88.59 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.337418
  validation loss:		0.359968
  validation accuracy:		88.70 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.339511
  validation loss:		0.357825
  validation accuracy:		88.80 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.339349
  validation loss:		0.360216
  validation accuracy:		88.48 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.331868
  validation loss:		0.358315
  validation accuracy:		88.04 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.332109
  validation loss:		0.353020
  validation accuracy:		88.80 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.323639
  validation loss:		0.367064
  validation accuracy:		87.83 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.323270
  validation loss:		0.354450
  validation accuracy:		88.80 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.326785
  validation loss:		0.349376
  validation accuracy:		88.70 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.317119
  validation loss:		0.346439
  validation accuracy:		89.24 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.329625
  validation loss:		0.359460
  validation accuracy:		88.70 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.322599
  validation loss:		0.355052
  validation accuracy:		88.70 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.322362
  validation loss:		0.345012
  validation accuracy:		88.91 %
Epoch 152 of 2000 took 0.098s
  training loss:		0.316926
  validation loss:		0.349857
  validation accuracy:		89.13 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.316743
  validation loss:		0.363704
  validation accuracy:		88.15 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.317281
  validation loss:		0.346973
  validation accuracy:		89.13 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.314074
  validation loss:		0.345823
  validation accuracy:		88.37 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.306223
  validation loss:		0.340948
  validation accuracy:		89.13 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.312291
  validation loss:		0.350009
  validation accuracy:		88.04 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.308626
  validation loss:		0.343146
  validation accuracy:		88.37 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.303432
  validation loss:		0.345419
  validation accuracy:		88.80 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.301681
  validation loss:		0.352014
  validation accuracy:		88.70 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.302604
  validation loss:		0.354076
  validation accuracy:		88.48 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.301806
  validation loss:		0.337220
  validation accuracy:		88.70 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.296207
  validation loss:		0.358288
  validation accuracy:		88.80 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.305317
  validation loss:		0.342604
  validation accuracy:		88.15 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.297385
  validation loss:		0.353569
  validation accuracy:		88.37 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.295873
  validation loss:		0.350754
  validation accuracy:		88.04 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.293372
  validation loss:		0.346896
  validation accuracy:		88.48 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.293164
  validation loss:		0.347536
  validation accuracy:		89.13 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.297613
  validation loss:		0.344987
  validation accuracy:		89.13 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.292398
  validation loss:		0.348665
  validation accuracy:		88.59 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.287125
  validation loss:		0.351475
  validation accuracy:		88.59 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.291301
  validation loss:		0.336120
  validation accuracy:		88.48 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.282712
  validation loss:		0.356157
  validation accuracy:		88.48 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.286014
  validation loss:		0.330711
  validation accuracy:		89.02 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.289984
  validation loss:		0.337120
  validation accuracy:		88.70 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.286802
  validation loss:		0.334612
  validation accuracy:		89.46 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.288336
  validation loss:		0.330556
  validation accuracy:		88.91 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.281586
  validation loss:		0.363332
  validation accuracy:		88.26 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.281346
  validation loss:		0.337279
  validation accuracy:		88.15 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.278455
  validation loss:		0.333899
  validation accuracy:		88.48 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.282168
  validation loss:		0.324197
  validation accuracy:		88.80 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.279553
  validation loss:		0.329384
  validation accuracy:		89.35 %
Epoch 183 of 2000 took 0.098s
  training loss:		0.271451
  validation loss:		0.354484
  validation accuracy:		89.13 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.277469
  validation loss:		0.351528
  validation accuracy:		88.26 %
Epoch 185 of 2000 took 0.098s
  training loss:		0.277346
  validation loss:		0.342901
  validation accuracy:		88.26 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.275364
  validation loss:		0.346208
  validation accuracy:		88.59 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.267360
  validation loss:		0.334046
  validation accuracy:		89.13 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.273473
  validation loss:		0.340581
  validation accuracy:		88.70 %
Epoch 189 of 2000 took 0.097s
  training loss:		0.278111
  validation loss:		0.335296
  validation accuracy:		88.70 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.264215
  validation loss:		0.339028
  validation accuracy:		89.02 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.275279
  validation loss:		0.326290
  validation accuracy:		89.46 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.267690
  validation loss:		0.335209
  validation accuracy:		88.80 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.263168
  validation loss:		0.323406
  validation accuracy:		89.13 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.265463
  validation loss:		0.325943
  validation accuracy:		89.57 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.263601
  validation loss:		0.329063
  validation accuracy:		89.24 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.260867
  validation loss:		0.334695
  validation accuracy:		88.91 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.263604
  validation loss:		0.320296
  validation accuracy:		89.67 %
Epoch 198 of 2000 took 0.102s
  training loss:		0.261962
  validation loss:		0.322774
  validation accuracy:		89.89 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.256252
  validation loss:		0.353917
  validation accuracy:		88.59 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.265116
  validation loss:		0.319510
  validation accuracy:		90.11 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.260866
  validation loss:		0.326552
  validation accuracy:		89.46 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.262802
  validation loss:		0.321619
  validation accuracy:		89.78 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.254890
  validation loss:		0.331531
  validation accuracy:		89.67 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.257659
  validation loss:		0.325548
  validation accuracy:		89.46 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.253474
  validation loss:		0.328369
  validation accuracy:		89.24 %
Epoch 206 of 2000 took 0.097s
  training loss:		0.253173
  validation loss:		0.318492
  validation accuracy:		90.00 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.246940
  validation loss:		0.320485
  validation accuracy:		89.57 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.247881
  validation loss:		0.336242
  validation accuracy:		89.57 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.252299
  validation loss:		0.328408
  validation accuracy:		89.35 %
Epoch 210 of 2000 took 0.097s
  training loss:		0.249257
  validation loss:		0.325136
  validation accuracy:		89.57 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.252625
  validation loss:		0.316256
  validation accuracy:		89.78 %
Epoch 212 of 2000 took 0.097s
  training loss:		0.257676
  validation loss:		0.332575
  validation accuracy:		89.46 %
Epoch 213 of 2000 took 0.097s
  training loss:		0.256615
  validation loss:		0.354369
  validation accuracy:		88.04 %
Epoch 214 of 2000 took 0.098s
  training loss:		0.249083
  validation loss:		0.330306
  validation accuracy:		89.02 %
Epoch 215 of 2000 took 0.097s
  training loss:		0.245248
  validation loss:		0.337154
  validation accuracy:		89.02 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.249927
  validation loss:		0.324030
  validation accuracy:		89.57 %
Epoch 217 of 2000 took 0.097s
  training loss:		0.248160
  validation loss:		0.322097
  validation accuracy:		89.67 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.244314
  validation loss:		0.329900
  validation accuracy:		89.46 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.249128
  validation loss:		0.318634
  validation accuracy:		89.67 %
Epoch 220 of 2000 took 0.097s
  training loss:		0.246082
  validation loss:		0.336716
  validation accuracy:		89.24 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.242715
  validation loss:		0.352005
  validation accuracy:		88.70 %
Epoch 222 of 2000 took 0.097s
  training loss:		0.247414
  validation loss:		0.330238
  validation accuracy:		89.35 %
Epoch 223 of 2000 took 0.097s
  training loss:		0.247819
  validation loss:		0.338388
  validation accuracy:		88.91 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.245516
  validation loss:		0.354861
  validation accuracy:		88.59 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.249532
  validation loss:		0.330533
  validation accuracy:		89.35 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.241098
  validation loss:		0.328509
  validation accuracy:		89.02 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.239904
  validation loss:		0.358334
  validation accuracy:		88.37 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.247641
  validation loss:		0.346263
  validation accuracy:		88.80 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.239351
  validation loss:		0.319525
  validation accuracy:		90.11 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.237660
  validation loss:		0.347784
  validation accuracy:		88.48 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.237427
  validation loss:		0.340776
  validation accuracy:		88.91 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.232959
  validation loss:		0.326644
  validation accuracy:		89.35 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.246249
  validation loss:		0.331795
  validation accuracy:		89.46 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.238610
  validation loss:		0.344542
  validation accuracy:		89.02 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.239746
  validation loss:		0.354976
  validation accuracy:		88.48 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.238331
  validation loss:		0.321846
  validation accuracy:		89.67 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.239999
  validation loss:		0.346231
  validation accuracy:		88.59 %
Epoch 238 of 2000 took 0.098s
  training loss:		0.237736
  validation loss:		0.325233
  validation accuracy:		89.89 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.237609
  validation loss:		0.334608
  validation accuracy:		88.91 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.234944
  validation loss:		0.326462
  validation accuracy:		89.46 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.229657
  validation loss:		0.331813
  validation accuracy:		89.13 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.233105
  validation loss:		0.313885
  validation accuracy:		90.43 %
Epoch 243 of 2000 took 0.097s
  training loss:		0.236010
  validation loss:		0.322579
  validation accuracy:		90.00 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.235167
  validation loss:		0.328948
  validation accuracy:		89.57 %
Epoch 245 of 2000 took 0.098s
  training loss:		0.228774
  validation loss:		0.333764
  validation accuracy:		88.80 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.235736
  validation loss:		0.328576
  validation accuracy:		89.89 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.233880
  validation loss:		0.323656
  validation accuracy:		89.67 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.234751
  validation loss:		0.324323
  validation accuracy:		89.57 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.224952
  validation loss:		0.335179
  validation accuracy:		89.46 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.229478
  validation loss:		0.337227
  validation accuracy:		89.35 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.228920
  validation loss:		0.312302
  validation accuracy:		90.22 %
Epoch 252 of 2000 took 0.097s
  training loss:		0.226004
  validation loss:		0.351275
  validation accuracy:		88.70 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.231549
  validation loss:		0.330298
  validation accuracy:		89.35 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.230577
  validation loss:		0.317463
  validation accuracy:		90.43 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.223455
  validation loss:		0.334989
  validation accuracy:		88.26 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.228676
  validation loss:		0.332761
  validation accuracy:		89.67 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.226539
  validation loss:		0.336693
  validation accuracy:		90.00 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.232167
  validation loss:		0.345457
  validation accuracy:		89.02 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.231236
  validation loss:		0.356926
  validation accuracy:		88.37 %
Epoch 260 of 2000 took 0.097s
  training loss:		0.222462
  validation loss:		0.338337
  validation accuracy:		89.13 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.222230
  validation loss:		0.316819
  validation accuracy:		90.54 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.224338
  validation loss:		0.335723
  validation accuracy:		90.11 %
Epoch 263 of 2000 took 0.097s
  training loss:		0.222889
  validation loss:		0.323389
  validation accuracy:		89.78 %
Epoch 264 of 2000 took 0.097s
  training loss:		0.221553
  validation loss:		0.337825
  validation accuracy:		89.13 %
Epoch 265 of 2000 took 0.102s
  training loss:		0.231824
  validation loss:		0.332060
  validation accuracy:		89.78 %
Epoch 266 of 2000 took 0.098s
  training loss:		0.220967
  validation loss:		0.354503
  validation accuracy:		88.15 %
Epoch 267 of 2000 took 0.097s
  training loss:		0.217191
  validation loss:		0.331162
  validation accuracy:		89.89 %
Epoch 268 of 2000 took 0.097s
  training loss:		0.218925
  validation loss:		0.326190
  validation accuracy:		89.78 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.216969
  validation loss:		0.326102
  validation accuracy:		89.46 %
Epoch 270 of 2000 took 0.097s
  training loss:		0.227379
  validation loss:		0.321451
  validation accuracy:		90.87 %
Epoch 271 of 2000 took 0.097s
  training loss:		0.209711
  validation loss:		0.330435
  validation accuracy:		90.00 %
Epoch 272 of 2000 took 0.098s
  training loss:		0.219099
  validation loss:		0.325636
  validation accuracy:		90.54 %
Epoch 273 of 2000 took 0.097s
  training loss:		0.217609
  validation loss:		0.331379
  validation accuracy:		89.24 %
Epoch 274 of 2000 took 0.097s
  training loss:		0.217844
  validation loss:		0.330907
  validation accuracy:		90.33 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.217574
  validation loss:		0.343325
  validation accuracy:		89.46 %
Epoch 276 of 2000 took 0.098s
  training loss:		0.213397
  validation loss:		0.326636
  validation accuracy:		89.24 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.217091
  validation loss:		0.331039
  validation accuracy:		89.89 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.215261
  validation loss:		0.348143
  validation accuracy:		89.35 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.219991
  validation loss:		0.325273
  validation accuracy:		90.33 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.217703
  validation loss:		0.317436
  validation accuracy:		90.65 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.217820
  validation loss:		0.340034
  validation accuracy:		89.02 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.211339
  validation loss:		0.339831
  validation accuracy:		89.57 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.214017
  validation loss:		0.335562
  validation accuracy:		89.78 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.225860
  validation loss:		0.343253
  validation accuracy:		89.13 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.210142
  validation loss:		0.323170
  validation accuracy:		90.54 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.215347
  validation loss:		0.330410
  validation accuracy:		90.33 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.216788
  validation loss:		0.338005
  validation accuracy:		90.11 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.214482
  validation loss:		0.348272
  validation accuracy:		89.35 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.209856
  validation loss:		0.334877
  validation accuracy:		89.57 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.214281
  validation loss:		0.332100
  validation accuracy:		90.22 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.213506
  validation loss:		0.340852
  validation accuracy:		89.13 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.212253
  validation loss:		0.347153
  validation accuracy:		89.24 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.211216
  validation loss:		0.334414
  validation accuracy:		90.11 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.218147
  validation loss:		0.353550
  validation accuracy:		88.70 %
Epoch 295 of 2000 took 0.097s
  training loss:		0.213127
  validation loss:		0.330445
  validation accuracy:		90.22 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.215473
  validation loss:		0.352624
  validation accuracy:		89.13 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.214756
  validation loss:		0.330662
  validation accuracy:		89.67 %
Epoch 298 of 2000 took 0.097s
  training loss:		0.212582
  validation loss:		0.337714
  validation accuracy:		89.78 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.218887
  validation loss:		0.336371
  validation accuracy:		89.57 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.213334
  validation loss:		0.331845
  validation accuracy:		88.80 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.210106
  validation loss:		0.344505
  validation accuracy:		89.35 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.207919
  validation loss:		0.347930
  validation accuracy:		88.80 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.210083
  validation loss:		0.343525
  validation accuracy:		89.46 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.201711
  validation loss:		0.326666
  validation accuracy:		90.00 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.202461
  validation loss:		0.335256
  validation accuracy:		89.78 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.200840
  validation loss:		0.326623
  validation accuracy:		90.11 %
Epoch 307 of 2000 took 0.098s
  training loss:		0.205919
  validation loss:		0.351101
  validation accuracy:		89.13 %
Epoch 308 of 2000 took 0.098s
  training loss:		0.215816
  validation loss:		0.337464
  validation accuracy:		89.78 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.200813
  validation loss:		0.348087
  validation accuracy:		89.57 %
Epoch 310 of 2000 took 0.097s
  training loss:		0.204242
  validation loss:		0.354126
  validation accuracy:		88.91 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.206787
  validation loss:		0.365551
  validation accuracy:		88.37 %
Epoch 312 of 2000 took 0.097s
  training loss:		0.214727
  validation loss:		0.331667
  validation accuracy:		89.57 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.206953
  validation loss:		0.338186
  validation accuracy:		89.67 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.208649
  validation loss:		0.340896
  validation accuracy:		89.67 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.207256
  validation loss:		0.328773
  validation accuracy:		90.65 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.204510
  validation loss:		0.380606
  validation accuracy:		88.04 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.200477
  validation loss:		0.336452
  validation accuracy:		89.67 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.207747
  validation loss:		0.324357
  validation accuracy:		90.11 %
Epoch 319 of 2000 took 0.101s
  training loss:		0.205132
  validation loss:		0.350314
  validation accuracy:		89.02 %
Epoch 320 of 2000 took 0.098s
  training loss:		0.202942
  validation loss:		0.352368
  validation accuracy:		89.24 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.206276
  validation loss:		0.333479
  validation accuracy:		90.00 %
Epoch 322 of 2000 took 0.097s
  training loss:		0.199065
  validation loss:		0.349220
  validation accuracy:		89.46 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.203918
  validation loss:		0.338408
  validation accuracy:		89.67 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.202727
  validation loss:		0.332516
  validation accuracy:		89.24 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.203830
  validation loss:		0.333126
  validation accuracy:		90.22 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.199712
  validation loss:		0.355259
  validation accuracy:		89.13 %
Epoch 327 of 2000 took 0.097s
  training loss:		0.205571
  validation loss:		0.324365
  validation accuracy:		90.22 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.203469
  validation loss:		0.353841
  validation accuracy:		89.13 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.197205
  validation loss:		0.329758
  validation accuracy:		89.78 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.207374
  validation loss:		0.332280
  validation accuracy:		90.33 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.198910
  validation loss:		0.363440
  validation accuracy:		88.70 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.203346
  validation loss:		0.330899
  validation accuracy:		90.22 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.203105
  validation loss:		0.366173
  validation accuracy:		88.70 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.197793
  validation loss:		0.341575
  validation accuracy:		90.00 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.202709
  validation loss:		0.361838
  validation accuracy:		88.80 %
Epoch 336 of 2000 took 0.097s
  training loss:		0.207808
  validation loss:		0.355241
  validation accuracy:		88.91 %
Epoch 337 of 2000 took 0.097s
  training loss:		0.201867
  validation loss:		0.333139
  validation accuracy:		90.00 %
Epoch 338 of 2000 took 0.098s
  training loss:		0.196038
  validation loss:		0.334190
  validation accuracy:		89.89 %
Epoch 339 of 2000 took 0.097s
  training loss:		0.206074
  validation loss:		0.346896
  validation accuracy:		89.78 %
Epoch 340 of 2000 took 0.098s
  training loss:		0.206135
  validation loss:		0.357254
  validation accuracy:		89.13 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.201334
  validation loss:		0.359911
  validation accuracy:		88.91 %
Epoch 342 of 2000 took 0.097s
  training loss:		0.203491
  validation loss:		0.358198
  validation accuracy:		88.59 %
Epoch 343 of 2000 took 0.097s
  training loss:		0.196430
  validation loss:		0.328826
  validation accuracy:		90.54 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.203564
  validation loss:		0.392314
  validation accuracy:		87.83 %
Epoch 345 of 2000 took 0.097s
  training loss:		0.202791
  validation loss:		0.373500
  validation accuracy:		88.04 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.192258
  validation loss:		0.328937
  validation accuracy:		90.22 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.199464
  validation loss:		0.351723
  validation accuracy:		89.46 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.193682
  validation loss:		0.371227
  validation accuracy:		87.83 %
Epoch 349 of 2000 took 0.098s
  training loss:		0.203697
  validation loss:		0.335534
  validation accuracy:		90.00 %
Epoch 350 of 2000 took 0.097s
  training loss:		0.191155
  validation loss:		0.363645
  validation accuracy:		88.59 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.190252
  validation loss:		0.358520
  validation accuracy:		89.13 %
Epoch 352 of 2000 took 0.099s
  training loss:		0.196030
  validation loss:		0.347367
  validation accuracy:		89.89 %
Epoch 353 of 2000 took 0.103s
  training loss:		0.193586
  validation loss:		0.352579
  validation accuracy:		89.24 %
Epoch 354 of 2000 took 0.102s
  training loss:		0.197083
  validation loss:		0.339962
  validation accuracy:		89.78 %
Epoch 355 of 2000 took 0.100s
  training loss:		0.193032
  validation loss:		0.373110
  validation accuracy:		88.37 %
Epoch 356 of 2000 took 0.100s
  training loss:		0.194040
  validation loss:		0.373361
  validation accuracy:		88.80 %
Epoch 357 of 2000 took 0.100s
  training loss:		0.202815
  validation loss:		0.363971
  validation accuracy:		88.91 %
Epoch 358 of 2000 took 0.100s
  training loss:		0.199886
  validation loss:		0.358414
  validation accuracy:		88.80 %
Epoch 359 of 2000 took 0.100s
  training loss:		0.201786
  validation loss:		0.333848
  validation accuracy:		90.11 %
Epoch 360 of 2000 took 0.100s
  training loss:		0.192988
  validation loss:		0.348873
  validation accuracy:		90.00 %
Epoch 361 of 2000 took 0.100s
  training loss:		0.194437
  validation loss:		0.356230
  validation accuracy:		89.46 %
Epoch 362 of 2000 took 0.125s
  training loss:		0.196364
  validation loss:		0.341904
  validation accuracy:		90.00 %
Epoch 363 of 2000 took 0.124s
  training loss:		0.193103
  validation loss:		0.359532
  validation accuracy:		89.02 %
Epoch 364 of 2000 took 0.124s
  training loss:		0.194340
  validation loss:		0.350579
  validation accuracy:		89.67 %
Epoch 365 of 2000 took 0.124s
  training loss:		0.194355
  validation loss:		0.328146
  validation accuracy:		90.00 %
Epoch 366 of 2000 took 0.124s
  training loss:		0.195903
  validation loss:		0.344973
  validation accuracy:		89.78 %
Epoch 367 of 2000 took 0.124s
  training loss:		0.193452
  validation loss:		0.371511
  validation accuracy:		88.26 %
Epoch 368 of 2000 took 0.124s
  training loss:		0.195360
  validation loss:		0.388227
  validation accuracy:		88.04 %
Epoch 369 of 2000 took 0.124s
  training loss:		0.188803
  validation loss:		0.338785
  validation accuracy:		90.11 %
Epoch 370 of 2000 took 0.124s
  training loss:		0.193721
  validation loss:		0.386401
  validation accuracy:		88.15 %
Epoch 371 of 2000 took 0.124s
  training loss:		0.188541
  validation loss:		0.354059
  validation accuracy:		89.13 %
Epoch 372 of 2000 took 0.124s
  training loss:		0.192981
  validation loss:		0.356356
  validation accuracy:		89.02 %
Epoch 373 of 2000 took 0.124s
  training loss:		0.194935
  validation loss:		0.351206
  validation accuracy:		89.78 %
Epoch 374 of 2000 took 0.124s
  training loss:		0.192676
  validation loss:		0.359303
  validation accuracy:		89.24 %
Epoch 375 of 2000 took 0.124s
  training loss:		0.194742
  validation loss:		0.350771
  validation accuracy:		89.57 %
Epoch 376 of 2000 took 0.124s
  training loss:		0.196890
  validation loss:		0.347691
  validation accuracy:		89.89 %
Epoch 377 of 2000 took 0.124s
  training loss:		0.196961
  validation loss:		0.360031
  validation accuracy:		89.02 %
Epoch 378 of 2000 took 0.124s
  training loss:		0.197635
  validation loss:		0.347905
  validation accuracy:		89.67 %
Epoch 379 of 2000 took 0.124s
  training loss:		0.184465
  validation loss:		0.359911
  validation accuracy:		89.46 %
Epoch 380 of 2000 took 0.124s
  training loss:		0.189317
  validation loss:		0.348074
  validation accuracy:		89.78 %
Epoch 381 of 2000 took 0.124s
  training loss:		0.192123
  validation loss:		0.365365
  validation accuracy:		88.70 %
Epoch 382 of 2000 took 0.124s
  training loss:		0.188619
  validation loss:		0.354539
  validation accuracy:		89.35 %
Epoch 383 of 2000 took 0.124s
  training loss:		0.182144
  validation loss:		0.367739
  validation accuracy:		88.80 %
Epoch 384 of 2000 took 0.124s
  training loss:		0.194011
  validation loss:		0.358733
  validation accuracy:		89.02 %
Epoch 385 of 2000 took 0.124s
  training loss:		0.191621
  validation loss:		0.351707
  validation accuracy:		89.46 %
Epoch 386 of 2000 took 0.124s
  training loss:		0.184377
  validation loss:		0.361331
  validation accuracy:		88.80 %
Epoch 387 of 2000 took 0.124s
  training loss:		0.191424
  validation loss:		0.359067
  validation accuracy:		89.35 %
Epoch 388 of 2000 took 0.124s
  training loss:		0.186195
  validation loss:		0.375649
  validation accuracy:		88.37 %
Epoch 389 of 2000 took 0.129s
  training loss:		0.183592
  validation loss:		0.365294
  validation accuracy:		88.48 %
Epoch 390 of 2000 took 0.125s
  training loss:		0.192442
  validation loss:		0.374382
  validation accuracy:		88.59 %
Epoch 391 of 2000 took 0.124s
  training loss:		0.183022
  validation loss:		0.342635
  validation accuracy:		89.89 %
Epoch 392 of 2000 took 0.124s
  training loss:		0.188161
  validation loss:		0.361204
  validation accuracy:		89.24 %
Epoch 393 of 2000 took 0.124s
  training loss:		0.191085
  validation loss:		0.358691
  validation accuracy:		89.35 %
Epoch 394 of 2000 took 0.124s
  training loss:		0.185531
  validation loss:		0.364695
  validation accuracy:		89.13 %
Epoch 395 of 2000 took 0.119s
  training loss:		0.187142
  validation loss:		0.359932
  validation accuracy:		88.70 %
Epoch 396 of 2000 took 0.098s
  training loss:		0.192375
  validation loss:		0.359330
  validation accuracy:		89.46 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.183821
  validation loss:		0.355191
  validation accuracy:		89.67 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.190618
  validation loss:		0.366746
  validation accuracy:		88.91 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.193164
  validation loss:		0.393130
  validation accuracy:		88.04 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.190715
  validation loss:		0.365261
  validation accuracy:		89.35 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.186889
  validation loss:		0.365607
  validation accuracy:		88.91 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.193056
  validation loss:		0.343601
  validation accuracy:		90.22 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.188218
  validation loss:		0.348075
  validation accuracy:		90.11 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.185656
  validation loss:		0.359282
  validation accuracy:		89.13 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.192411
  validation loss:		0.362067
  validation accuracy:		89.35 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.189371
  validation loss:		0.357224
  validation accuracy:		89.57 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.177638
  validation loss:		0.372248
  validation accuracy:		88.48 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.181681
  validation loss:		0.355047
  validation accuracy:		89.35 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.182096
  validation loss:		0.368879
  validation accuracy:		89.02 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.190681
  validation loss:		0.373509
  validation accuracy:		88.59 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.186881
  validation loss:		0.370948
  validation accuracy:		89.13 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.189977
  validation loss:		0.362047
  validation accuracy:		89.24 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.189409
  validation loss:		0.357156
  validation accuracy:		89.46 %
Epoch 414 of 2000 took 0.097s
  training loss:		0.189952
  validation loss:		0.370630
  validation accuracy:		89.02 %
Epoch 415 of 2000 took 0.101s
  training loss:		0.180497
  validation loss:		0.368321
  validation accuracy:		89.02 %
Epoch 416 of 2000 took 0.098s
  training loss:		0.190464
  validation loss:		0.395676
  validation accuracy:		88.37 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.193070
  validation loss:		0.372153
  validation accuracy:		88.80 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.185045
  validation loss:		0.363655
  validation accuracy:		89.46 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.182534
  validation loss:		0.369352
  validation accuracy:		89.13 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.183176
  validation loss:		0.354582
  validation accuracy:		89.67 %
Epoch 421 of 2000 took 0.098s
  training loss:		0.187265
  validation loss:		0.360786
  validation accuracy:		89.57 %
Epoch 422 of 2000 took 0.097s
  training loss:		0.187774
  validation loss:		0.357666
  validation accuracy:		89.46 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.187180
  validation loss:		0.360369
  validation accuracy:		89.57 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.179597
  validation loss:		0.365622
  validation accuracy:		89.02 %
Epoch 425 of 2000 took 0.097s
  training loss:		0.179774
  validation loss:		0.346492
  validation accuracy:		90.33 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.190325
  validation loss:		0.352793
  validation accuracy:		89.89 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.179986
  validation loss:		0.371099
  validation accuracy:		89.24 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.188422
  validation loss:		0.369901
  validation accuracy:		89.24 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.192099
  validation loss:		0.376548
  validation accuracy:		88.70 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.183708
  validation loss:		0.371659
  validation accuracy:		89.02 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.183713
  validation loss:		0.351823
  validation accuracy:		89.46 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.181748
  validation loss:		0.361376
  validation accuracy:		89.46 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.188455
  validation loss:		0.363145
  validation accuracy:		89.46 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.181666
  validation loss:		0.366924
  validation accuracy:		89.57 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.183888
  validation loss:		0.345447
  validation accuracy:		90.00 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.188002
  validation loss:		0.388543
  validation accuracy:		88.48 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.183441
  validation loss:		0.369251
  validation accuracy:		89.57 %
Epoch 438 of 2000 took 0.099s
  training loss:		0.180383
  validation loss:		0.373009
  validation accuracy:		88.70 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.181650
  validation loss:		0.361201
  validation accuracy:		89.35 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.182342
  validation loss:		0.362745
  validation accuracy:		89.46 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.184722
  validation loss:		0.342875
  validation accuracy:		90.43 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.182394
  validation loss:		0.368336
  validation accuracy:		89.02 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.181238
  validation loss:		0.378524
  validation accuracy:		88.91 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.186161
  validation loss:		0.369931
  validation accuracy:		89.35 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.182917
  validation loss:		0.352936
  validation accuracy:		90.00 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.182800
  validation loss:		0.377590
  validation accuracy:		88.91 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.185237
  validation loss:		0.365630
  validation accuracy:		89.46 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.174528
  validation loss:		0.374475
  validation accuracy:		89.24 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.184266
  validation loss:		0.373447
  validation accuracy:		89.02 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.184211
  validation loss:		0.393166
  validation accuracy:		88.70 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.179328
  validation loss:		0.344296
  validation accuracy:		89.89 %
Epoch 452 of 2000 took 0.098s
  training loss:		0.181636
  validation loss:		0.357018
  validation accuracy:		90.11 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.184711
  validation loss:		0.411030
  validation accuracy:		88.04 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.186913
  validation loss:		0.350798
  validation accuracy:		89.78 %
Epoch 455 of 2000 took 0.102s
  training loss:		0.181447
  validation loss:		0.395400
  validation accuracy:		88.37 %
Epoch 456 of 2000 took 0.098s
  training loss:		0.183870
  validation loss:		0.361477
  validation accuracy:		89.24 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.184786
  validation loss:		0.383939
  validation accuracy:		88.59 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.190815
  validation loss:		0.363910
  validation accuracy:		89.35 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.182559
  validation loss:		0.359563
  validation accuracy:		89.46 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.183338
  validation loss:		0.380237
  validation accuracy:		89.02 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.176404
  validation loss:		0.360898
  validation accuracy:		89.46 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.183314
  validation loss:		0.377324
  validation accuracy:		89.89 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.182653
  validation loss:		0.376464
  validation accuracy:		89.13 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.181659
  validation loss:		0.345217
  validation accuracy:		90.33 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.192993
  validation loss:		0.354106
  validation accuracy:		90.11 %
Epoch 466 of 2000 took 0.098s
  training loss:		0.176931
  validation loss:		0.364110
  validation accuracy:		89.57 %
Epoch 467 of 2000 took 0.098s
  training loss:		0.184396
  validation loss:		0.372302
  validation accuracy:		89.13 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.184815
  validation loss:		0.367798
  validation accuracy:		89.46 %
Epoch 469 of 2000 took 0.102s
  training loss:		0.176142
  validation loss:		0.357600
  validation accuracy:		89.35 %
Epoch 470 of 2000 took 0.098s
  training loss:		0.178963
  validation loss:		0.369351
  validation accuracy:		89.13 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.176852
  validation loss:		0.357878
  validation accuracy:		89.57 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.183515
  validation loss:		0.379080
  validation accuracy:		89.46 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.182337
  validation loss:		0.377098
  validation accuracy:		89.13 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.170849
  validation loss:		0.384246
  validation accuracy:		88.80 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.171656
  validation loss:		0.385309
  validation accuracy:		88.37 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.180417
  validation loss:		0.386642
  validation accuracy:		89.24 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.173071
  validation loss:		0.368494
  validation accuracy:		89.89 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.182276
  validation loss:		0.374169
  validation accuracy:		88.91 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.178490
  validation loss:		0.386962
  validation accuracy:		88.59 %
Epoch 480 of 2000 took 0.101s
  training loss:		0.182091
  validation loss:		0.386826
  validation accuracy:		88.59 %
Epoch 481 of 2000 took 0.099s
  training loss:		0.174543
  validation loss:		0.364177
  validation accuracy:		89.46 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.178638
  validation loss:		0.416642
  validation accuracy:		87.50 %
Epoch 483 of 2000 took 0.098s
  training loss:		0.184134
  validation loss:		0.365834
  validation accuracy:		89.67 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.184255
  validation loss:		0.411819
  validation accuracy:		88.15 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.171552
  validation loss:		0.355778
  validation accuracy:		89.89 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.176152
  validation loss:		0.375633
  validation accuracy:		89.35 %
Epoch 487 of 2000 took 0.097s
  training loss:		0.178906
  validation loss:		0.375672
  validation accuracy:		88.80 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.181165
  validation loss:		0.378720
  validation accuracy:		88.91 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.177350
  validation loss:		0.370802
  validation accuracy:		89.46 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.176266
  validation loss:		0.415217
  validation accuracy:		87.93 %
Epoch 491 of 2000 took 0.103s
  training loss:		0.174517
  validation loss:		0.366635
  validation accuracy:		89.78 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.173697
  validation loss:		0.383420
  validation accuracy:		89.02 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.174844
  validation loss:		0.384787
  validation accuracy:		88.91 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.182250
  validation loss:		0.355640
  validation accuracy:		89.89 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.172819
  validation loss:		0.374834
  validation accuracy:		89.24 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.173542
  validation loss:		0.367568
  validation accuracy:		89.57 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.182160
  validation loss:		0.384031
  validation accuracy:		89.24 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.180400
  validation loss:		0.374572
  validation accuracy:		88.59 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.171945
  validation loss:		0.371763
  validation accuracy:		89.46 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.183853
  validation loss:		0.361842
  validation accuracy:		90.11 %
Epoch 501 of 2000 took 0.102s
  training loss:		0.173251
  validation loss:		0.397671
  validation accuracy:		88.80 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.170058
  validation loss:		0.382468
  validation accuracy:		89.13 %
Epoch 503 of 2000 took 0.098s
  training loss:		0.176284
  validation loss:		0.385360
  validation accuracy:		88.70 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.176040
  validation loss:		0.385147
  validation accuracy:		88.91 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.180093
  validation loss:		0.379574
  validation accuracy:		89.46 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.175946
  validation loss:		0.375625
  validation accuracy:		89.35 %
Epoch 507 of 2000 took 0.097s
  training loss:		0.179424
  validation loss:		0.384302
  validation accuracy:		88.91 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.180049
  validation loss:		0.386461
  validation accuracy:		88.91 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.177327
  validation loss:		0.360254
  validation accuracy:		90.43 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.174888
  validation loss:		0.392694
  validation accuracy:		88.80 %
Epoch 511 of 2000 took 0.102s
  training loss:		0.178226
  validation loss:		0.383038
  validation accuracy:		88.59 %
Epoch 512 of 2000 took 0.098s
  training loss:		0.171256
  validation loss:		0.382851
  validation accuracy:		89.57 %
Epoch 513 of 2000 took 0.098s
  training loss:		0.171250
  validation loss:		0.389387
  validation accuracy:		88.37 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.173716
  validation loss:		0.365578
  validation accuracy:		89.67 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.175449
  validation loss:		0.367164
  validation accuracy:		89.67 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.174535
  validation loss:		0.400906
  validation accuracy:		88.48 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.180821
  validation loss:		0.386483
  validation accuracy:		89.13 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.174368
  validation loss:		0.403550
  validation accuracy:		88.59 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.178091
  validation loss:		0.364970
  validation accuracy:		89.67 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.172872
  validation loss:		0.383780
  validation accuracy:		88.37 %
Epoch 521 of 2000 took 0.102s
  training loss:		0.175343
  validation loss:		0.377679
  validation accuracy:		89.35 %
Epoch 522 of 2000 took 0.098s
  training loss:		0.173260
  validation loss:		0.395672
  validation accuracy:		88.70 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.176225
  validation loss:		0.358190
  validation accuracy:		90.11 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.169207
  validation loss:		0.380110
  validation accuracy:		89.13 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.174339
  validation loss:		0.376224
  validation accuracy:		89.35 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.169646
  validation loss:		0.382716
  validation accuracy:		89.13 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.178651
  validation loss:		0.393726
  validation accuracy:		88.48 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.175375
  validation loss:		0.367169
  validation accuracy:		89.67 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.179606
  validation loss:		0.371021
  validation accuracy:		89.57 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.176547
  validation loss:		0.385245
  validation accuracy:		89.02 %
Epoch 531 of 2000 took 0.104s
  training loss:		0.181254
  validation loss:		0.401482
  validation accuracy:		89.13 %
Epoch 532 of 2000 took 0.107s
  training loss:		0.171615
  validation loss:		0.371659
  validation accuracy:		89.46 %
Epoch 533 of 2000 took 0.102s
  training loss:		0.171766
  validation loss:		0.377543
  validation accuracy:		89.35 %
Epoch 534 of 2000 took 0.100s
  training loss:		0.172960
  validation loss:		0.375678
  validation accuracy:		89.46 %
Epoch 535 of 2000 took 0.100s
  training loss:		0.169571
  validation loss:		0.373781
  validation accuracy:		89.78 %
Epoch 536 of 2000 took 0.101s
  training loss:		0.181158
  validation loss:		0.363300
  validation accuracy:		90.00 %
Epoch 537 of 2000 took 0.100s
  training loss:		0.174252
  validation loss:		0.366738
  validation accuracy:		89.89 %
Epoch 538 of 2000 took 0.100s
  training loss:		0.170593
  validation loss:		0.368914
  validation accuracy:		89.67 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.169904
  validation loss:		0.378740
  validation accuracy:		89.78 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.167443
  validation loss:		0.374889
  validation accuracy:		89.35 %
Epoch 541 of 2000 took 0.101s
  training loss:		0.173421
  validation loss:		0.379473
  validation accuracy:		89.57 %
Epoch 542 of 2000 took 0.099s
  training loss:		0.170309
  validation loss:		0.379323
  validation accuracy:		89.46 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.177932
  validation loss:		0.380022
  validation accuracy:		89.46 %
Epoch 544 of 2000 took 0.098s
  training loss:		0.162999
  validation loss:		0.382760
  validation accuracy:		88.80 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.181755
  validation loss:		0.381814
  validation accuracy:		90.00 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.172166
  validation loss:		0.372914
  validation accuracy:		89.46 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.172679
  validation loss:		0.385317
  validation accuracy:		89.02 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.169720
  validation loss:		0.367532
  validation accuracy:		90.00 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.168405
  validation loss:		0.389456
  validation accuracy:		89.46 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.165969
  validation loss:		0.375224
  validation accuracy:		89.67 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.165678
  validation loss:		0.400662
  validation accuracy:		88.26 %
Epoch 552 of 2000 took 0.102s
  training loss:		0.170799
  validation loss:		0.360839
  validation accuracy:		89.89 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.173803
  validation loss:		0.388198
  validation accuracy:		89.13 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.168352
  validation loss:		0.386969
  validation accuracy:		89.24 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.169699
  validation loss:		0.410695
  validation accuracy:		89.13 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.170105
  validation loss:		0.382960
  validation accuracy:		89.78 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.170735
  validation loss:		0.386551
  validation accuracy:		88.80 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.165656
  validation loss:		0.405329
  validation accuracy:		89.24 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.168037
  validation loss:		0.369726
  validation accuracy:		89.35 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.176325
  validation loss:		0.375661
  validation accuracy:		89.24 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.170580
  validation loss:		0.366201
  validation accuracy:		90.33 %
Epoch 562 of 2000 took 0.102s
  training loss:		0.174186
  validation loss:		0.379464
  validation accuracy:		89.24 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.166617
  validation loss:		0.402165
  validation accuracy:		88.91 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.172926
  validation loss:		0.382582
  validation accuracy:		89.78 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.162601
  validation loss:		0.406220
  validation accuracy:		88.80 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.173980
  validation loss:		0.369110
  validation accuracy:		89.46 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.169196
  validation loss:		0.387128
  validation accuracy:		89.57 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.172953
  validation loss:		0.384114
  validation accuracy:		89.46 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.169268
  validation loss:		0.366286
  validation accuracy:		89.67 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.171736
  validation loss:		0.373525
  validation accuracy:		89.78 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.165787
  validation loss:		0.373982
  validation accuracy:		89.78 %
Epoch 572 of 2000 took 0.102s
  training loss:		0.166713
  validation loss:		0.380032
  validation accuracy:		89.24 %
Epoch 573 of 2000 took 0.098s
  training loss:		0.166627
  validation loss:		0.376246
  validation accuracy:		89.67 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.170132
  validation loss:		0.372409
  validation accuracy:		89.78 %
Epoch 575 of 2000 took 0.098s
  training loss:		0.173588
  validation loss:		0.390430
  validation accuracy:		88.91 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.167325
  validation loss:		0.365110
  validation accuracy:		90.33 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.161577
  validation loss:		0.397740
  validation accuracy:		88.91 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.166972
  validation loss:		0.378377
  validation accuracy:		89.57 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.164946
  validation loss:		0.374225
  validation accuracy:		89.57 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.166793
  validation loss:		0.388018
  validation accuracy:		89.57 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.171616
  validation loss:		0.414335
  validation accuracy:		89.02 %
Epoch 582 of 2000 took 0.102s
  training loss:		0.175657
  validation loss:		0.385377
  validation accuracy:		89.57 %
Epoch 583 of 2000 took 0.098s
  training loss:		0.169712
  validation loss:		0.402016
  validation accuracy:		89.24 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.165323
  validation loss:		0.391361
  validation accuracy:		88.59 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.165820
  validation loss:		0.392049
  validation accuracy:		88.70 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.158792
  validation loss:		0.382457
  validation accuracy:		89.78 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.171691
  validation loss:		0.406697
  validation accuracy:		89.24 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.168696
  validation loss:		0.387742
  validation accuracy:		89.35 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.164188
  validation loss:		0.368330
  validation accuracy:		89.89 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.166974
  validation loss:		0.396144
  validation accuracy:		89.24 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.162696
  validation loss:		0.379851
  validation accuracy:		89.35 %
Epoch 592 of 2000 took 0.098s
  training loss:		0.167028
  validation loss:		0.409699
  validation accuracy:		88.91 %
Epoch 593 of 2000 took 0.101s
  training loss:		0.176152
  validation loss:		0.382421
  validation accuracy:		89.24 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.167235
  validation loss:		0.395653
  validation accuracy:		89.46 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.175041
  validation loss:		0.386756
  validation accuracy:		89.13 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.157647
  validation loss:		0.393556
  validation accuracy:		88.80 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.165994
  validation loss:		0.401251
  validation accuracy:		88.80 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.163864
  validation loss:		0.414362
  validation accuracy:		88.59 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.175551
  validation loss:		0.386469
  validation accuracy:		88.91 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.172418
  validation loss:		0.388309
  validation accuracy:		89.46 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.183534
  validation loss:		0.402872
  validation accuracy:		88.59 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.155889
  validation loss:		0.415701
  validation accuracy:		89.24 %
Epoch 603 of 2000 took 0.102s
  training loss:		0.168692
  validation loss:		0.389554
  validation accuracy:		89.46 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.165969
  validation loss:		0.403848
  validation accuracy:		89.24 %
Epoch 605 of 2000 took 0.098s
  training loss:		0.159594
  validation loss:		0.384598
  validation accuracy:		89.67 %
Epoch 606 of 2000 took 0.098s
  training loss:		0.169984
  validation loss:		0.401289
  validation accuracy:		89.13 %
Epoch 607 of 2000 took 0.100s
  training loss:		0.161266
  validation loss:		0.385879
  validation accuracy:		89.89 %
Epoch 608 of 2000 took 0.108s
  training loss:		0.164151
  validation loss:		0.398551
  validation accuracy:		89.13 %
Epoch 609 of 2000 took 0.111s
  training loss:		0.162087
  validation loss:		0.412381
  validation accuracy:		88.80 %
Epoch 610 of 2000 took 0.146s
  training loss:		0.166645
  validation loss:		0.378054
  validation accuracy:		89.67 %
Epoch 611 of 2000 took 0.103s
  training loss:		0.161513
  validation loss:		0.381784
  validation accuracy:		89.78 %
Epoch 612 of 2000 took 0.117s
  training loss:		0.160533
  validation loss:		0.386746
  validation accuracy:		89.57 %
Epoch 613 of 2000 took 0.105s
  training loss:		0.164965
  validation loss:		0.391783
  validation accuracy:		89.24 %
Epoch 614 of 2000 took 0.104s
  training loss:		0.161338
  validation loss:		0.387483
  validation accuracy:		89.35 %
Epoch 615 of 2000 took 0.104s
  training loss:		0.161848
  validation loss:		0.391497
  validation accuracy:		89.24 %
Epoch 616 of 2000 took 0.104s
  training loss:		0.160979
  validation loss:		0.388344
  validation accuracy:		89.35 %
Epoch 617 of 2000 took 0.101s
  training loss:		0.167968
  validation loss:		0.379950
  validation accuracy:		89.57 %
Epoch 618 of 2000 took 0.100s
  training loss:		0.166626
  validation loss:		0.395677
  validation accuracy:		89.46 %
Epoch 619 of 2000 took 0.100s
  training loss:		0.162326
  validation loss:		0.410129
  validation accuracy:		88.80 %
Epoch 620 of 2000 took 0.101s
  training loss:		0.166186
  validation loss:		0.395382
  validation accuracy:		89.57 %
Epoch 621 of 2000 took 0.100s
  training loss:		0.176417
  validation loss:		0.408477
  validation accuracy:		88.80 %
Epoch 622 of 2000 took 0.104s
  training loss:		0.160918
  validation loss:		0.379863
  validation accuracy:		89.67 %
Epoch 623 of 2000 took 0.100s
  training loss:		0.160834
  validation loss:		0.394291
  validation accuracy:		89.46 %
Epoch 624 of 2000 took 0.102s
  training loss:		0.162831
  validation loss:		0.374667
  validation accuracy:		89.89 %
Epoch 625 of 2000 took 0.101s
  training loss:		0.163321
  validation loss:		0.376058
  validation accuracy:		90.22 %
Epoch 626 of 2000 took 0.102s
  training loss:		0.158131
  validation loss:		0.399697
  validation accuracy:		89.24 %
Epoch 627 of 2000 took 0.101s
  training loss:		0.169139
  validation loss:		0.399792
  validation accuracy:		89.46 %
Epoch 628 of 2000 took 0.101s
  training loss:		0.171081
  validation loss:		0.389654
  validation accuracy:		89.35 %
Epoch 629 of 2000 took 0.101s
  training loss:		0.160741
  validation loss:		0.404713
  validation accuracy:		89.67 %
Epoch 630 of 2000 took 0.101s
  training loss:		0.180918
  validation loss:		0.387295
  validation accuracy:		89.78 %
Epoch 631 of 2000 took 0.101s
  training loss:		0.159384
  validation loss:		0.394552
  validation accuracy:		90.00 %
Epoch 632 of 2000 took 0.104s
  training loss:		0.173748
  validation loss:		0.417371
  validation accuracy:		88.48 %
Epoch 633 of 2000 took 0.101s
  training loss:		0.157199
  validation loss:		0.433609
  validation accuracy:		88.91 %
Epoch 634 of 2000 took 0.101s
  training loss:		0.167651
  validation loss:		0.394997
  validation accuracy:		89.13 %
Epoch 635 of 2000 took 0.100s
  training loss:		0.163588
  validation loss:		0.383653
  validation accuracy:		89.46 %
Epoch 636 of 2000 took 0.101s
  training loss:		0.161898
  validation loss:		0.389550
  validation accuracy:		89.24 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.162960
  validation loss:		0.430360
  validation accuracy:		88.37 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.165606
  validation loss:		0.366711
  validation accuracy:		90.22 %
Epoch 639 of 2000 took 0.101s
  training loss:		0.152772
  validation loss:		0.442500
  validation accuracy:		88.37 %
Epoch 640 of 2000 took 0.101s
  training loss:		0.166133
  validation loss:		0.385697
  validation accuracy:		89.78 %
Epoch 641 of 2000 took 0.102s
  training loss:		0.163893
  validation loss:		0.388708
  validation accuracy:		89.78 %
Epoch 642 of 2000 took 0.102s
  training loss:		0.158351
  validation loss:		0.387372
  validation accuracy:		89.89 %
Epoch 643 of 2000 took 0.101s
  training loss:		0.166917
  validation loss:		0.396268
  validation accuracy:		89.46 %
Epoch 644 of 2000 took 0.100s
  training loss:		0.158546
  validation loss:		0.413977
  validation accuracy:		89.35 %
Epoch 645 of 2000 took 0.100s
  training loss:		0.162584
  validation loss:		0.387296
  validation accuracy:		89.35 %
Epoch 646 of 2000 took 0.101s
  training loss:		0.160339
  validation loss:		0.378964
  validation accuracy:		89.67 %
Epoch 647 of 2000 took 0.100s
  training loss:		0.157579
  validation loss:		0.409693
  validation accuracy:		88.59 %
Epoch 648 of 2000 took 0.101s
  training loss:		0.169339
  validation loss:		0.401561
  validation accuracy:		90.11 %
Epoch 649 of 2000 took 0.102s
  training loss:		0.162859
  validation loss:		0.378436
  validation accuracy:		90.33 %
Epoch 650 of 2000 took 0.146s
  training loss:		0.157799
  validation loss:		0.388038
  validation accuracy:		89.67 %
Epoch 651 of 2000 took 0.165s
  training loss:		0.159303
  validation loss:		0.391225
  validation accuracy:		89.35 %
Epoch 652 of 2000 took 0.170s
  training loss:		0.156511
  validation loss:		0.390547
  validation accuracy:		89.02 %
Epoch 653 of 2000 took 0.165s
  training loss:		0.161742
  validation loss:		0.414664
  validation accuracy:		89.02 %
Epoch 654 of 2000 took 0.165s
  training loss:		0.156419
  validation loss:		0.388027
  validation accuracy:		89.89 %
Epoch 655 of 2000 took 0.165s
  training loss:		0.160410
  validation loss:		0.397432
  validation accuracy:		89.57 %
Epoch 656 of 2000 took 0.165s
  training loss:		0.158355
  validation loss:		0.372480
  validation accuracy:		90.54 %
Epoch 657 of 2000 took 0.165s
  training loss:		0.162181
  validation loss:		0.378894
  validation accuracy:		89.35 %
Epoch 658 of 2000 took 0.165s
  training loss:		0.164039
  validation loss:		0.382833
  validation accuracy:		89.89 %
Epoch 659 of 2000 took 0.166s
  training loss:		0.161759
  validation loss:		0.428369
  validation accuracy:		88.70 %
Epoch 660 of 2000 took 0.165s
  training loss:		0.164837
  validation loss:		0.402379
  validation accuracy:		88.91 %
Epoch 661 of 2000 took 0.170s
  training loss:		0.160725
  validation loss:		0.425431
  validation accuracy:		89.02 %
Epoch 662 of 2000 took 0.165s
  training loss:		0.170018
  validation loss:		0.396592
  validation accuracy:		89.78 %
Epoch 663 of 2000 took 0.225s
  training loss:		0.162377
  validation loss:		0.412637
  validation accuracy:		89.24 %
Epoch 664 of 2000 took 0.200s
  training loss:		0.158032
  validation loss:		0.405904
  validation accuracy:		89.13 %
Epoch 665 of 2000 took 0.165s
  training loss:		0.167596
  validation loss:		0.386219
  validation accuracy:		89.46 %
Epoch 666 of 2000 took 0.165s
  training loss:		0.158928
  validation loss:		0.402777
  validation accuracy:		89.35 %
Epoch 667 of 2000 took 0.165s
  training loss:		0.157824
  validation loss:		0.398526
  validation accuracy:		89.24 %
Epoch 668 of 2000 took 0.165s
  training loss:		0.161369
  validation loss:		0.392094
  validation accuracy:		89.78 %
Epoch 669 of 2000 took 0.165s
  training loss:		0.155999
  validation loss:		0.420263
  validation accuracy:		88.70 %
Epoch 670 of 2000 took 0.167s
  training loss:		0.157867
  validation loss:		0.407947
  validation accuracy:		88.59 %
Epoch 671 of 2000 took 0.214s
  training loss:		0.157086
  validation loss:		0.419656
  validation accuracy:		88.80 %
Epoch 672 of 2000 took 0.176s
  training loss:		0.156957
  validation loss:		0.392120
  validation accuracy:		88.80 %
Epoch 673 of 2000 took 0.207s
  training loss:		0.154347
  validation loss:		0.399378
  validation accuracy:		89.35 %
Epoch 674 of 2000 took 0.225s
  training loss:		0.151116
  validation loss:		0.413962
  validation accuracy:		89.24 %
Epoch 675 of 2000 took 0.228s
  training loss:		0.166633
  validation loss:		0.394445
  validation accuracy:		89.67 %
Epoch 676 of 2000 took 0.273s
  training loss:		0.162200
  validation loss:		0.412037
  validation accuracy:		89.13 %
Epoch 677 of 2000 took 0.218s
  training loss:		0.155451
  validation loss:		0.429637
  validation accuracy:		88.48 %
Epoch 678 of 2000 took 0.234s
  training loss:		0.154478
  validation loss:		0.442341
  validation accuracy:		88.15 %
Epoch 679 of 2000 took 0.167s
  training loss:		0.155135
  validation loss:		0.405103
  validation accuracy:		88.91 %
Epoch 680 of 2000 took 0.292s
  training loss:		0.156420
  validation loss:		0.375897
  validation accuracy:		90.54 %
Epoch 681 of 2000 took 0.216s
  training loss:		0.159124
  validation loss:		0.406853
  validation accuracy:		88.70 %
Epoch 682 of 2000 took 0.250s
  training loss:		0.153973
  validation loss:		0.402064
  validation accuracy:		89.13 %
Epoch 683 of 2000 took 0.216s
  training loss:		0.153036
  validation loss:		0.395855
  validation accuracy:		89.46 %
Epoch 684 of 2000 took 0.165s
  training loss:		0.152861
  validation loss:		0.443023
  validation accuracy:		88.26 %
Epoch 685 of 2000 took 0.165s
  training loss:		0.165114
  validation loss:		0.384456
  validation accuracy:		89.89 %
Epoch 686 of 2000 took 0.165s
  training loss:		0.152513
  validation loss:		0.408827
  validation accuracy:		89.13 %
Epoch 687 of 2000 took 0.165s
  training loss:		0.169530
  validation loss:		0.382925
  validation accuracy:		90.11 %
Epoch 688 of 2000 took 0.165s
  training loss:		0.160333
  validation loss:		0.406124
  validation accuracy:		89.24 %
Epoch 689 of 2000 took 0.165s
  training loss:		0.155076
  validation loss:		0.403152
  validation accuracy:		89.67 %
Epoch 690 of 2000 took 0.165s
  training loss:		0.160342
  validation loss:		0.409360
  validation accuracy:		89.57 %
Epoch 691 of 2000 took 0.165s
  training loss:		0.159483
  validation loss:		0.407032
  validation accuracy:		88.91 %
Epoch 692 of 2000 took 0.165s
  training loss:		0.154958
  validation loss:		0.436239
  validation accuracy:		88.70 %
Epoch 693 of 2000 took 0.167s
  training loss:		0.157688
  validation loss:		0.400668
  validation accuracy:		89.35 %
Epoch 694 of 2000 took 0.168s
  training loss:		0.158881
  validation loss:		0.379219
  validation accuracy:		90.00 %
Epoch 695 of 2000 took 0.165s
  training loss:		0.157209
  validation loss:		0.377420
  validation accuracy:		90.43 %
Epoch 696 of 2000 took 0.165s
  training loss:		0.157608
  validation loss:		0.422728
  validation accuracy:		89.02 %
Epoch 697 of 2000 took 0.165s
  training loss:		0.150714
  validation loss:		0.386915
  validation accuracy:		89.57 %
Epoch 698 of 2000 took 0.236s
  training loss:		0.156714
  validation loss:		0.392420
  validation accuracy:		89.46 %
Epoch 699 of 2000 took 0.252s
  training loss:		0.155925
  validation loss:		0.392612
  validation accuracy:		89.02 %
Epoch 700 of 2000 took 0.168s
  training loss:		0.154157
  validation loss:		0.399854
  validation accuracy:		89.46 %
Epoch 701 of 2000 took 0.234s
  training loss:		0.155318
  validation loss:		0.389491
  validation accuracy:		89.67 %
Epoch 702 of 2000 took 0.165s
  training loss:		0.152752
  validation loss:		0.384037
  validation accuracy:		89.89 %
Epoch 703 of 2000 took 0.165s
  training loss:		0.152177
  validation loss:		0.403305
  validation accuracy:		89.46 %
Epoch 704 of 2000 took 0.165s
  training loss:		0.155866
  validation loss:		0.419607
  validation accuracy:		89.02 %
Epoch 705 of 2000 took 0.165s
  training loss:		0.155883
  validation loss:		0.414503
  validation accuracy:		88.70 %
Epoch 706 of 2000 took 0.165s
  training loss:		0.158730
  validation loss:		0.392744
  validation accuracy:		89.13 %
Epoch 707 of 2000 took 0.165s
  training loss:		0.160891
  validation loss:		0.400903
  validation accuracy:		89.24 %
Epoch 708 of 2000 took 0.165s
  training loss:		0.162550
  validation loss:		0.394908
  validation accuracy:		89.67 %
Epoch 709 of 2000 took 0.165s
  training loss:		0.156177
  validation loss:		0.419110
  validation accuracy:		88.59 %
Epoch 710 of 2000 took 0.169s
  training loss:		0.161317
  validation loss:		0.415272
  validation accuracy:		89.13 %
Epoch 711 of 2000 took 0.165s
  training loss:		0.154071
  validation loss:		0.375735
  validation accuracy:		90.33 %
Epoch 712 of 2000 took 0.165s
  training loss:		0.155129
  validation loss:		0.384435
  validation accuracy:		90.22 %
Epoch 713 of 2000 took 0.165s
  training loss:		0.156376
  validation loss:		0.389405
  validation accuracy:		89.35 %
Epoch 714 of 2000 took 0.165s
  training loss:		0.157739
  validation loss:		0.389103
  validation accuracy:		89.57 %
Epoch 715 of 2000 took 0.165s
  training loss:		0.154945
  validation loss:		0.420153
  validation accuracy:		89.02 %
Epoch 716 of 2000 took 0.166s
  training loss:		0.152532
  validation loss:		0.409547
  validation accuracy:		89.57 %
Epoch 717 of 2000 took 0.167s
  training loss:		0.153893
  validation loss:		0.399253
  validation accuracy:		89.46 %
Epoch 718 of 2000 took 0.216s
  training loss:		0.147063
  validation loss:		0.410568
  validation accuracy:		89.24 %
Epoch 719 of 2000 took 0.165s
  training loss:		0.148254
  validation loss:		0.384990
  validation accuracy:		89.89 %
Epoch 720 of 2000 took 0.165s
  training loss:		0.157014
  validation loss:		0.394566
  validation accuracy:		89.57 %
Epoch 721 of 2000 took 0.165s
  training loss:		0.155521
  validation loss:		0.375438
  validation accuracy:		90.11 %
Epoch 722 of 2000 took 0.165s
  training loss:		0.152800
  validation loss:		0.406520
  validation accuracy:		89.24 %
Epoch 723 of 2000 took 0.167s
  training loss:		0.154341
  validation loss:		0.423085
  validation accuracy:		88.91 %
Epoch 724 of 2000 took 0.165s
  training loss:		0.151601
  validation loss:		0.391830
  validation accuracy:		89.46 %
Epoch 725 of 2000 took 0.165s
  training loss:		0.154137
  validation loss:		0.409225
  validation accuracy:		89.35 %
Epoch 726 of 2000 took 0.165s
  training loss:		0.163748
  validation loss:		0.414864
  validation accuracy:		89.02 %
Epoch 727 of 2000 took 0.165s
  training loss:		0.155145
  validation loss:		0.402133
  validation accuracy:		89.24 %
Epoch 728 of 2000 took 0.165s
  training loss:		0.146489
  validation loss:		0.386157
  validation accuracy:		89.78 %
Epoch 729 of 2000 took 0.165s
  training loss:		0.154193
  validation loss:		0.424911
  validation accuracy:		88.70 %
Epoch 730 of 2000 took 0.165s
  training loss:		0.146079
  validation loss:		0.399448
  validation accuracy:		89.46 %
Epoch 731 of 2000 took 0.217s
  training loss:		0.152489
  validation loss:		0.431942
  validation accuracy:		89.13 %
Epoch 732 of 2000 took 0.190s
  training loss:		0.146869
  validation loss:		0.398313
  validation accuracy:		89.78 %
Epoch 733 of 2000 took 0.165s
  training loss:		0.158524
  validation loss:		0.426432
  validation accuracy:		88.48 %
Epoch 734 of 2000 took 0.165s
  training loss:		0.154580
  validation loss:		0.436548
  validation accuracy:		89.02 %
Epoch 735 of 2000 took 0.165s
  training loss:		0.147142
  validation loss:		0.403181
  validation accuracy:		89.78 %
Epoch 736 of 2000 took 0.165s
  training loss:		0.146111
  validation loss:		0.397727
  validation accuracy:		89.67 %
Epoch 737 of 2000 took 0.165s
  training loss:		0.155688
  validation loss:		0.406506
  validation accuracy:		89.02 %
Epoch 738 of 2000 took 0.165s
  training loss:		0.158723
  validation loss:		0.401217
  validation accuracy:		90.00 %
Epoch 739 of 2000 took 0.165s
  training loss:		0.160319
  validation loss:		0.412033
  validation accuracy:		88.91 %
Epoch 740 of 2000 took 0.165s
  training loss:		0.150758
  validation loss:		0.466046
  validation accuracy:		87.61 %
Epoch 741 of 2000 took 0.165s
  training loss:		0.160544
  validation loss:		0.402761
  validation accuracy:		89.13 %
Epoch 742 of 2000 took 0.181s
  training loss:		0.164891
  validation loss:		0.425936
  validation accuracy:		88.80 %
Epoch 743 of 2000 took 0.224s
  training loss:		0.156934
  validation loss:		0.387440
  validation accuracy:		89.78 %
Epoch 744 of 2000 took 0.165s
  training loss:		0.155890
  validation loss:		0.387872
  validation accuracy:		90.11 %
Epoch 745 of 2000 took 0.165s
  training loss:		0.144322
  validation loss:		0.391136
  validation accuracy:		89.78 %
Epoch 746 of 2000 took 0.165s
  training loss:		0.150552
  validation loss:		0.400645
  validation accuracy:		89.24 %
Epoch 747 of 2000 took 0.165s
  training loss:		0.148636
  validation loss:		0.402488
  validation accuracy:		90.33 %
Epoch 748 of 2000 took 0.165s
  training loss:		0.156463
  validation loss:		0.410112
  validation accuracy:		88.80 %
Epoch 749 of 2000 took 0.165s
  training loss:		0.151988
  validation loss:		0.401598
  validation accuracy:		89.89 %
Epoch 750 of 2000 took 0.165s
  training loss:		0.148719
  validation loss:		0.390777
  validation accuracy:		89.24 %
Epoch 751 of 2000 took 0.165s
  training loss:		0.150680
  validation loss:		0.421984
  validation accuracy:		89.13 %
Epoch 752 of 2000 took 0.165s
  training loss:		0.156820
  validation loss:		0.408424
  validation accuracy:		89.24 %
Epoch 753 of 2000 took 0.165s
  training loss:		0.153510
  validation loss:		0.400307
  validation accuracy:		90.11 %
Epoch 754 of 2000 took 0.167s
  training loss:		0.146985
  validation loss:		0.414113
  validation accuracy:		89.57 %
Epoch 755 of 2000 took 0.234s
  training loss:		0.145823
  validation loss:		0.403072
  validation accuracy:		89.13 %
Epoch 756 of 2000 took 0.172s
  training loss:		0.145051
  validation loss:		0.408410
  validation accuracy:		89.24 %
Epoch 757 of 2000 took 0.191s
  training loss:		0.149475
  validation loss:		0.402166
  validation accuracy:		89.35 %
Epoch 758 of 2000 took 0.165s
  training loss:		0.151713
  validation loss:		0.385144
  validation accuracy:		89.89 %
Epoch 759 of 2000 took 0.165s
  training loss:		0.147895
  validation loss:		0.419027
  validation accuracy:		88.91 %
Epoch 760 of 2000 took 0.165s
  training loss:		0.147581
  validation loss:		0.397578
  validation accuracy:		89.24 %
Epoch 761 of 2000 took 0.168s
  training loss:		0.155376
  validation loss:		0.410229
  validation accuracy:		88.91 %
Epoch 762 of 2000 took 0.171s
  training loss:		0.145209
  validation loss:		0.401739
  validation accuracy:		89.35 %
Epoch 763 of 2000 took 0.171s
  training loss:		0.147866
  validation loss:		0.406455
  validation accuracy:		89.57 %
Epoch 764 of 2000 took 0.171s
  training loss:		0.152390
  validation loss:		0.420246
  validation accuracy:		89.57 %
Epoch 765 of 2000 took 0.171s
  training loss:		0.146918
  validation loss:		0.404100
  validation accuracy:		89.57 %
Epoch 766 of 2000 took 0.171s
  training loss:		0.148165
  validation loss:		0.406269
  validation accuracy:		89.67 %
Epoch 767 of 2000 took 0.171s
  training loss:		0.149435
  validation loss:		0.447953
  validation accuracy:		88.26 %
Epoch 768 of 2000 took 0.171s
  training loss:		0.146236
  validation loss:		0.422918
  validation accuracy:		88.70 %
Epoch 769 of 2000 took 0.170s
  training loss:		0.138753
  validation loss:		0.391400
  validation accuracy:		89.67 %
Epoch 770 of 2000 took 0.171s
  training loss:		0.151224
  validation loss:		0.406563
  validation accuracy:		89.02 %
Epoch 771 of 2000 took 0.171s
  training loss:		0.144052
  validation loss:		0.406324
  validation accuracy:		88.91 %
Epoch 772 of 2000 took 0.171s
  training loss:		0.143787
  validation loss:		0.386662
  validation accuracy:		90.11 %
Epoch 773 of 2000 took 0.171s
  training loss:		0.152169
  validation loss:		0.430034
  validation accuracy:		88.91 %
Epoch 774 of 2000 took 0.171s
  training loss:		0.152861
  validation loss:		0.426355
  validation accuracy:		88.37 %
Epoch 775 of 2000 took 0.171s
  training loss:		0.145285
  validation loss:		0.430053
  validation accuracy:		89.02 %
Epoch 776 of 2000 took 0.168s
  training loss:		0.148701
  validation loss:		0.412156
  validation accuracy:		88.80 %
Epoch 777 of 2000 took 0.244s
  training loss:		0.155677
  validation loss:		0.435120
  validation accuracy:		88.91 %
Epoch 778 of 2000 took 0.289s
  training loss:		0.147433
  validation loss:		0.405988
  validation accuracy:		89.02 %
Epoch 779 of 2000 took 0.170s
  training loss:		0.146791
  validation loss:		0.393777
  validation accuracy:		89.57 %
Epoch 780 of 2000 took 0.174s
  training loss:		0.148295
  validation loss:		0.415217
  validation accuracy:		89.13 %
Epoch 781 of 2000 took 0.170s
  training loss:		0.145733
  validation loss:		0.411738
  validation accuracy:		89.35 %
Epoch 782 of 2000 took 0.221s
  training loss:		0.153602
  validation loss:		0.388496
  validation accuracy:		89.78 %
Epoch 783 of 2000 took 0.169s
  training loss:		0.141959
  validation loss:		0.419213
  validation accuracy:		88.91 %
Epoch 784 of 2000 took 0.169s
  training loss:		0.142095
  validation loss:		0.394128
  validation accuracy:		89.89 %
Epoch 785 of 2000 took 0.173s
  training loss:		0.144057
  validation loss:		0.387341
  validation accuracy:		90.22 %
Epoch 786 of 2000 took 0.169s
  training loss:		0.148566
  validation loss:		0.406774
  validation accuracy:		89.35 %
Epoch 787 of 2000 took 0.169s
  training loss:		0.143249
  validation loss:		0.413991
  validation accuracy:		89.46 %
Epoch 788 of 2000 took 0.169s
  training loss:		0.141890
  validation loss:		0.416143
  validation accuracy:		89.46 %
Epoch 789 of 2000 took 0.171s
  training loss:		0.151536
  validation loss:		0.406047
  validation accuracy:		88.91 %
Epoch 790 of 2000 took 0.171s
  training loss:		0.144929
  validation loss:		0.405259
  validation accuracy:		89.24 %
Epoch 791 of 2000 took 0.171s
  training loss:		0.145245
  validation loss:		0.402361
  validation accuracy:		89.78 %
Epoch 792 of 2000 took 0.170s
  training loss:		0.145638
  validation loss:		0.395701
  validation accuracy:		90.11 %
Epoch 793 of 2000 took 0.266s
  training loss:		0.140878
  validation loss:		0.380200
  validation accuracy:		90.65 %
Epoch 794 of 2000 took 0.204s
  training loss:		0.142787
  validation loss:		0.399338
  validation accuracy:		89.78 %
Epoch 795 of 2000 took 0.227s
  training loss:		0.142834
  validation loss:		0.394959
  validation accuracy:		89.78 %
Epoch 796 of 2000 took 0.177s
  training loss:		0.153394
  validation loss:		0.385819
  validation accuracy:		89.89 %
Epoch 797 of 2000 took 0.171s
  training loss:		0.152868
  validation loss:		0.425489
  validation accuracy:		88.80 %
Epoch 798 of 2000 took 0.129s
  training loss:		0.145896
  validation loss:		0.401826
  validation accuracy:		89.67 %
Epoch 799 of 2000 took 0.106s
  training loss:		0.137971
  validation loss:		0.387968
  validation accuracy:		90.22 %
Epoch 800 of 2000 took 0.106s
  training loss:		0.139575
  validation loss:		0.431297
  validation accuracy:		89.02 %
Epoch 801 of 2000 took 0.108s
  training loss:		0.144790
  validation loss:		0.385523
  validation accuracy:		90.22 %
Epoch 802 of 2000 took 0.112s
  training loss:		0.146455
  validation loss:		0.414893
  validation accuracy:		89.35 %
Epoch 803 of 2000 took 0.109s
  training loss:		0.143350
  validation loss:		0.405282
  validation accuracy:		89.67 %
Epoch 804 of 2000 took 0.109s
  training loss:		0.142381
  validation loss:		0.395845
  validation accuracy:		89.78 %
Epoch 805 of 2000 took 0.109s
  training loss:		0.139097
  validation loss:		0.378739
  validation accuracy:		90.54 %
Epoch 806 of 2000 took 0.105s
  training loss:		0.148120
  validation loss:		0.410732
  validation accuracy:		89.13 %
Epoch 807 of 2000 took 0.107s
  training loss:		0.147910
  validation loss:		0.404591
  validation accuracy:		89.35 %
Epoch 808 of 2000 took 0.105s
  training loss:		0.146674
  validation loss:		0.398777
  validation accuracy:		89.57 %
Epoch 809 of 2000 took 0.109s
  training loss:		0.145206
  validation loss:		0.379838
  validation accuracy:		90.43 %
Epoch 810 of 2000 took 0.108s
  training loss:		0.132345
  validation loss:		0.389201
  validation accuracy:		90.11 %
Epoch 811 of 2000 took 0.105s
  training loss:		0.145564
  validation loss:		0.381059
  validation accuracy:		89.89 %
Epoch 812 of 2000 took 0.108s
  training loss:		0.139469
  validation loss:		0.418952
  validation accuracy:		89.35 %
Epoch 813 of 2000 took 0.111s
  training loss:		0.141878
  validation loss:		0.410848
  validation accuracy:		89.35 %
Epoch 814 of 2000 took 0.107s
  training loss:		0.143336
  validation loss:		0.383445
  validation accuracy:		90.11 %
Epoch 815 of 2000 took 0.109s
  training loss:		0.139021
  validation loss:		0.413170
  validation accuracy:		89.67 %
Epoch 816 of 2000 took 0.105s
  training loss:		0.139381
  validation loss:		0.413951
  validation accuracy:		89.57 %
Epoch 817 of 2000 took 0.110s
  training loss:		0.144927
  validation loss:		0.399661
  validation accuracy:		89.67 %
Epoch 818 of 2000 took 0.111s
  training loss:		0.151605
  validation loss:		0.393715
  validation accuracy:		89.67 %
Epoch 819 of 2000 took 0.107s
  training loss:		0.140774
  validation loss:		0.407989
  validation accuracy:		89.67 %
Epoch 820 of 2000 took 0.110s
  training loss:		0.139310
  validation loss:		0.390521
  validation accuracy:		90.11 %
Epoch 821 of 2000 took 0.112s
  training loss:		0.148741
  validation loss:		0.408755
  validation accuracy:		89.57 %
Epoch 822 of 2000 took 0.108s
  training loss:		0.144357
  validation loss:		0.421795
  validation accuracy:		89.24 %
Epoch 823 of 2000 took 0.109s
  training loss:		0.141274
  validation loss:		0.444793
  validation accuracy:		88.70 %
Epoch 824 of 2000 took 0.108s
  training loss:		0.142782
  validation loss:		0.426480
  validation accuracy:		89.35 %
Epoch 825 of 2000 took 0.110s
  training loss:		0.145434
  validation loss:		0.431525
  validation accuracy:		89.24 %
Epoch 826 of 2000 took 0.112s
  training loss:		0.150042
  validation loss:		0.404234
  validation accuracy:		89.67 %
Epoch 827 of 2000 took 0.108s
  training loss:		0.146288
  validation loss:		0.408211
  validation accuracy:		89.57 %
Epoch 828 of 2000 took 0.110s
  training loss:		0.142777
  validation loss:		0.413354
  validation accuracy:		89.78 %
Epoch 829 of 2000 took 0.113s
  training loss:		0.145733
  validation loss:		0.420270
  validation accuracy:		89.46 %
Epoch 830 of 2000 took 0.108s
  training loss:		0.137347
  validation loss:		0.419608
  validation accuracy:		89.02 %
Epoch 831 of 2000 took 0.109s
  training loss:		0.136564
  validation loss:		0.408418
  validation accuracy:		89.67 %
Epoch 832 of 2000 took 0.108s
  training loss:		0.138033
  validation loss:		0.400122
  validation accuracy:		89.24 %
Epoch 833 of 2000 took 0.113s
  training loss:		0.140519
  validation loss:		0.425457
  validation accuracy:		89.46 %
Epoch 834 of 2000 took 0.112s
  training loss:		0.137158
  validation loss:		0.431387
  validation accuracy:		88.91 %
Epoch 835 of 2000 took 0.108s
  training loss:		0.138591
  validation loss:		0.396420
  validation accuracy:		89.78 %
Epoch 836 of 2000 took 0.109s
  training loss:		0.135023
  validation loss:		0.423940
  validation accuracy:		88.91 %
Epoch 837 of 2000 took 0.113s
  training loss:		0.138584
  validation loss:		0.418714
  validation accuracy:		89.35 %
Epoch 838 of 2000 took 0.109s
  training loss:		0.144613
  validation loss:		0.426850
  validation accuracy:		89.13 %
Epoch 839 of 2000 took 0.109s
  training loss:		0.135856
  validation loss:		0.399107
  validation accuracy:		90.33 %
Epoch 840 of 2000 took 0.108s
  training loss:		0.140005
  validation loss:		0.393736
  validation accuracy:		89.89 %
Epoch 841 of 2000 took 0.109s
  training loss:		0.134935
  validation loss:		0.415061
  validation accuracy:		89.46 %
Epoch 842 of 2000 took 0.112s
  training loss:		0.136080
  validation loss:		0.396473
  validation accuracy:		89.67 %
Epoch 843 of 2000 took 0.109s
  training loss:		0.132270
  validation loss:		0.443070
  validation accuracy:		88.80 %
Epoch 844 of 2000 took 0.109s
  training loss:		0.141576
  validation loss:		0.419739
  validation accuracy:		89.46 %
Epoch 845 of 2000 took 0.112s
  training loss:		0.137521
  validation loss:		0.425189
  validation accuracy:		89.24 %
Epoch 846 of 2000 took 0.108s
  training loss:		0.139223
  validation loss:		0.401748
  validation accuracy:		89.78 %
Epoch 847 of 2000 took 0.110s
  training loss:		0.140392
  validation loss:		0.393035
  validation accuracy:		90.00 %
Epoch 848 of 2000 took 0.110s
  training loss:		0.138551
  validation loss:		0.432063
  validation accuracy:		89.46 %
Epoch 849 of 2000 took 0.108s
  training loss:		0.140509
  validation loss:		0.437695
  validation accuracy:		89.13 %
Epoch 850 of 2000 took 0.111s
  training loss:		0.136952
  validation loss:		0.476349
  validation accuracy:		88.26 %
Epoch 851 of 2000 took 0.107s
  training loss:		0.135595
  validation loss:		0.417009
  validation accuracy:		89.13 %
Epoch 852 of 2000 took 0.110s
  training loss:		0.134903
  validation loss:		0.392995
  validation accuracy:		90.54 %
Epoch 853 of 2000 took 0.110s
  training loss:		0.132878
  validation loss:		0.402502
  validation accuracy:		89.67 %
Epoch 854 of 2000 took 0.108s
  training loss:		0.135315
  validation loss:		0.406179
  validation accuracy:		89.67 %
Epoch 855 of 2000 took 0.111s
  training loss:		0.133397
  validation loss:		0.427906
  validation accuracy:		89.13 %
Epoch 856 of 2000 took 0.108s
  training loss:		0.137903
  validation loss:		0.379531
  validation accuracy:		90.76 %
Epoch 857 of 2000 took 0.110s
  training loss:		0.138705
  validation loss:		0.393148
  validation accuracy:		90.11 %
Epoch 858 of 2000 took 0.110s
  training loss:		0.135223
  validation loss:		0.420919
  validation accuracy:		89.24 %
Epoch 859 of 2000 took 0.108s
  training loss:		0.134748
  validation loss:		0.410627
  validation accuracy:		89.78 %
Epoch 860 of 2000 took 0.112s
  training loss:		0.138969
  validation loss:		0.400442
  validation accuracy:		90.54 %
Epoch 861 of 2000 took 0.108s
  training loss:		0.140652
  validation loss:		0.407142
  validation accuracy:		90.22 %
Epoch 862 of 2000 took 0.110s
  training loss:		0.135332
  validation loss:		0.412441
  validation accuracy:		89.46 %
Epoch 863 of 2000 took 0.110s
  training loss:		0.129314
  validation loss:		0.409594
  validation accuracy:		90.00 %
Epoch 864 of 2000 took 0.108s
  training loss:		0.138519
  validation loss:		0.418660
  validation accuracy:		89.67 %
Epoch 865 of 2000 took 0.111s
  training loss:		0.128831
  validation loss:		0.396798
  validation accuracy:		90.00 %
Epoch 866 of 2000 took 0.108s
  training loss:		0.130176
  validation loss:		0.433630
  validation accuracy:		89.24 %
Epoch 867 of 2000 took 0.109s
  training loss:		0.132859
  validation loss:		0.425020
  validation accuracy:		89.35 %
Epoch 868 of 2000 took 0.111s
  training loss:		0.126188
  validation loss:		0.445934
  validation accuracy:		88.70 %
Epoch 869 of 2000 took 0.107s
  training loss:		0.135277
  validation loss:		0.422204
  validation accuracy:		89.57 %
Epoch 870 of 2000 took 0.111s
  training loss:		0.132083
  validation loss:		0.428327
  validation accuracy:		89.46 %
Epoch 871 of 2000 took 0.109s
  training loss:		0.131148
  validation loss:		0.402739
  validation accuracy:		89.89 %
Epoch 872 of 2000 took 0.110s
  training loss:		0.135259
  validation loss:		0.423947
  validation accuracy:		89.67 %
Epoch 873 of 2000 took 0.112s
  training loss:		0.129093
  validation loss:		0.406491
  validation accuracy:		89.57 %
Epoch 874 of 2000 took 0.108s
  training loss:		0.131120
  validation loss:		0.432245
  validation accuracy:		89.13 %
Epoch 875 of 2000 took 0.109s
  training loss:		0.134466
  validation loss:		0.404293
  validation accuracy:		89.78 %
Epoch 876 of 2000 took 0.108s
  training loss:		0.131037
  validation loss:		0.411453
  validation accuracy:		89.78 %
Epoch 877 of 2000 took 0.109s
  training loss:		0.127690
  validation loss:		0.431849
  validation accuracy:		89.57 %
Epoch 878 of 2000 took 0.111s
  training loss:		0.127118
  validation loss:		0.430651
  validation accuracy:		89.67 %
Epoch 879 of 2000 took 0.109s
  training loss:		0.131457
  validation loss:		0.414376
  validation accuracy:		89.67 %
Epoch 880 of 2000 took 0.109s
  training loss:		0.134799
  validation loss:		0.399708
  validation accuracy:		89.89 %
Epoch 881 of 2000 took 0.113s
  training loss:		0.136278
  validation loss:		0.452092
  validation accuracy:		88.59 %
Epoch 882 of 2000 took 0.109s
  training loss:		0.133374
  validation loss:		0.427556
  validation accuracy:		89.35 %
Epoch 883 of 2000 took 0.109s
  training loss:		0.135903
  validation loss:		0.428039
  validation accuracy:		89.13 %
Epoch 884 of 2000 took 0.108s
  training loss:		0.130121
  validation loss:		0.407280
  validation accuracy:		90.00 %
Epoch 885 of 2000 took 0.108s
  training loss:		0.133725
  validation loss:		0.420569
  validation accuracy:		89.35 %
Epoch 886 of 2000 took 0.112s
  training loss:		0.129936
  validation loss:		0.402073
  validation accuracy:		90.00 %
Epoch 887 of 2000 took 0.107s
  training loss:		0.128057
  validation loss:		0.395170
  validation accuracy:		90.33 %
Epoch 888 of 2000 took 0.104s
  training loss:		0.137814
  validation loss:		0.432315
  validation accuracy:		89.13 %
Epoch 889 of 2000 took 0.108s
  training loss:		0.135501
  validation loss:		0.424108
  validation accuracy:		89.67 %
Epoch 890 of 2000 took 0.107s
  training loss:		0.132254
  validation loss:		0.405347
  validation accuracy:		90.00 %
Epoch 891 of 2000 took 0.105s
  training loss:		0.127849
  validation loss:		0.422337
  validation accuracy:		89.24 %
Epoch 892 of 2000 took 0.105s
  training loss:		0.128551
  validation loss:		0.414809
  validation accuracy:		90.00 %
Epoch 893 of 2000 took 0.103s
  training loss:		0.129997
  validation loss:		0.420981
  validation accuracy:		89.67 %
Epoch 894 of 2000 took 0.106s
  training loss:		0.128139
  validation loss:		0.423992
  validation accuracy:		89.46 %
Epoch 895 of 2000 took 0.103s
  training loss:		0.130157
  validation loss:		0.419356
  validation accuracy:		89.13 %
Epoch 896 of 2000 took 0.100s
  training loss:		0.126524
  validation loss:		0.404262
  validation accuracy:		90.00 %
Epoch 897 of 2000 took 0.105s
  training loss:		0.132460
  validation loss:		0.411125
  validation accuracy:		89.89 %
Epoch 898 of 2000 took 0.104s
  training loss:		0.127471
  validation loss:		0.419269
  validation accuracy:		89.78 %
Epoch 899 of 2000 took 0.101s
  training loss:		0.128749
  validation loss:		0.427744
  validation accuracy:		89.67 %
Epoch 900 of 2000 took 0.102s
  training loss:		0.126499
  validation loss:		0.417045
  validation accuracy:		89.89 %
Epoch 901 of 2000 took 0.101s
  training loss:		0.140537
  validation loss:		0.419157
  validation accuracy:		89.67 %
Epoch 902 of 2000 took 0.109s
  training loss:		0.132207
  validation loss:		0.426648
  validation accuracy:		89.57 %
Epoch 903 of 2000 took 0.103s
  training loss:		0.126487
  validation loss:		0.424043
  validation accuracy:		89.67 %
Epoch 904 of 2000 took 0.100s
  training loss:		0.128006
  validation loss:		0.399259
  validation accuracy:		90.33 %
Epoch 905 of 2000 took 0.105s
  training loss:		0.123031
  validation loss:		0.400387
  validation accuracy:		90.22 %
Epoch 906 of 2000 took 0.104s
  training loss:		0.128971
  validation loss:		0.405085
  validation accuracy:		90.00 %
Epoch 907 of 2000 took 0.101s
  training loss:		0.125835
  validation loss:		0.427001
  validation accuracy:		89.46 %
Epoch 908 of 2000 took 0.102s
  training loss:		0.130035
  validation loss:		0.459713
  validation accuracy:		88.59 %
Epoch 909 of 2000 took 0.100s
  training loss:		0.132314
  validation loss:		0.418987
  validation accuracy:		89.78 %
Epoch 910 of 2000 took 0.106s
  training loss:		0.133483
  validation loss:		0.407871
  validation accuracy:		90.11 %
Epoch 911 of 2000 took 0.103s
  training loss:		0.132724
  validation loss:		0.408889
  validation accuracy:		90.22 %
Epoch 912 of 2000 took 0.100s
  training loss:		0.128646
  validation loss:		0.423952
  validation accuracy:		89.78 %
Epoch 913 of 2000 took 0.105s
  training loss:		0.138216
  validation loss:		0.428632
  validation accuracy:		89.46 %
Epoch 914 of 2000 took 0.104s
  training loss:		0.127953
  validation loss:		0.414001
  validation accuracy:		89.89 %
Epoch 915 of 2000 took 0.101s
  training loss:		0.134104
  validation loss:		0.406963
  validation accuracy:		90.43 %
Epoch 916 of 2000 took 0.102s
  training loss:		0.126541
  validation loss:		0.431835
  validation accuracy:		89.57 %
Epoch 917 of 2000 took 0.100s
  training loss:		0.141703
  validation loss:		0.418517
  validation accuracy:		89.67 %
Epoch 918 of 2000 took 0.106s
  training loss:		0.127319
  validation loss:		0.410858
  validation accuracy:		90.22 %
Epoch 919 of 2000 took 0.103s
  training loss:		0.127777
  validation loss:		0.423381
  validation accuracy:		89.67 %
Epoch 920 of 2000 took 0.100s
  training loss:		0.131335
  validation loss:		0.421980
  validation accuracy:		89.46 %
Epoch 921 of 2000 took 0.105s
  training loss:		0.126081
  validation loss:		0.417917
  validation accuracy:		89.67 %
Epoch 922 of 2000 took 0.104s
  training loss:		0.127260
  validation loss:		0.417602
  validation accuracy:		89.57 %
Epoch 923 of 2000 took 0.101s
  training loss:		0.126481
  validation loss:		0.443323
  validation accuracy:		89.57 %
Epoch 924 of 2000 took 0.102s
  training loss:		0.134946
  validation loss:		0.453049
  validation accuracy:		89.02 %
Epoch 925 of 2000 took 0.100s
  training loss:		0.130708
  validation loss:		0.401828
  validation accuracy:		90.54 %
Epoch 926 of 2000 took 0.106s
  training loss:		0.127180
  validation loss:		0.409416
  validation accuracy:		90.11 %
Epoch 927 of 2000 took 0.103s
  training loss:		0.123427
  validation loss:		0.422320
  validation accuracy:		89.46 %
Epoch 928 of 2000 took 0.100s
  training loss:		0.126374
  validation loss:		0.407559
  validation accuracy:		90.33 %
Epoch 929 of 2000 took 0.105s
  training loss:		0.129176
  validation loss:		0.404200
  validation accuracy:		90.33 %
Epoch 930 of 2000 took 0.105s
  training loss:		0.129176
  validation loss:		0.425982
  validation accuracy:		90.22 %
Epoch 931 of 2000 took 0.101s
  training loss:		0.129276
  validation loss:		0.426048
  validation accuracy:		89.78 %
Epoch 932 of 2000 took 0.102s
  training loss:		0.125940
  validation loss:		0.426258
  validation accuracy:		90.00 %
Epoch 933 of 2000 took 0.100s
  training loss:		0.120641
  validation loss:		0.434060
  validation accuracy:		89.35 %
Epoch 934 of 2000 took 0.106s
  training loss:		0.123375
  validation loss:		0.421848
  validation accuracy:		89.89 %
Epoch 935 of 2000 took 0.103s
  training loss:		0.126819
  validation loss:		0.400454
  validation accuracy:		90.33 %
Epoch 936 of 2000 took 0.100s
  training loss:		0.123587
  validation loss:		0.414305
  validation accuracy:		90.43 %
Epoch 937 of 2000 took 0.105s
  training loss:		0.128970
  validation loss:		0.419554
  validation accuracy:		90.11 %
Epoch 938 of 2000 took 0.105s
  training loss:		0.120058
  validation loss:		0.408822
  validation accuracy:		90.33 %
Epoch 939 of 2000 took 0.101s
  training loss:		0.123314
  validation loss:		0.433281
  validation accuracy:		89.57 %
Epoch 940 of 2000 took 0.102s
  training loss:		0.121804
  validation loss:		0.419016
  validation accuracy:		90.11 %
Epoch 941 of 2000 took 0.100s
  training loss:		0.124768
  validation loss:		0.444320
  validation accuracy:		89.57 %
Epoch 942 of 2000 took 0.106s
  training loss:		0.127468
  validation loss:		0.427580
  validation accuracy:		90.00 %
Epoch 943 of 2000 took 0.103s
  training loss:		0.118317
  validation loss:		0.426855
  validation accuracy:		89.46 %
Epoch 944 of 2000 took 0.100s
  training loss:		0.118889
  validation loss:		0.400609
  validation accuracy:		90.43 %
Epoch 945 of 2000 took 0.104s
  training loss:		0.122476
  validation loss:		0.444347
  validation accuracy:		89.13 %
Epoch 946 of 2000 took 0.105s
  training loss:		0.122753
  validation loss:		0.450223
  validation accuracy:		89.57 %
Epoch 947 of 2000 took 0.100s
  training loss:		0.128472
  validation loss:		0.428275
  validation accuracy:		89.89 %
Epoch 948 of 2000 took 0.102s
  training loss:		0.124461
  validation loss:		0.430750
  validation accuracy:		89.67 %
Epoch 949 of 2000 took 0.100s
  training loss:		0.123625
  validation loss:		0.429385
  validation accuracy:		89.46 %
Epoch 950 of 2000 took 0.105s
  training loss:		0.120318
  validation loss:		0.442488
  validation accuracy:		89.35 %
Epoch 951 of 2000 took 0.103s
  training loss:		0.123062
  validation loss:		0.455201
  validation accuracy:		89.57 %
Epoch 952 of 2000 took 0.101s
  training loss:		0.121397
  validation loss:		0.428251
  validation accuracy:		90.00 %
Epoch 953 of 2000 took 0.104s
  training loss:		0.122385
  validation loss:		0.441322
  validation accuracy:		89.35 %
Epoch 954 of 2000 took 0.105s
  training loss:		0.123555
  validation loss:		0.431177
  validation accuracy:		89.57 %
Epoch 955 of 2000 took 0.102s
  training loss:		0.123129
  validation loss:		0.446632
  validation accuracy:		89.35 %
Epoch 956 of 2000 took 0.102s
  training loss:		0.120411
  validation loss:		0.408175
  validation accuracy:		90.33 %
Epoch 957 of 2000 took 0.100s
  training loss:		0.121394
  validation loss:		0.445936
  validation accuracy:		89.24 %
Epoch 958 of 2000 took 0.106s
  training loss:		0.121527
  validation loss:		0.441310
  validation accuracy:		90.00 %
Epoch 959 of 2000 took 0.104s
  training loss:		0.129979
  validation loss:		0.422645
  validation accuracy:		89.89 %
Epoch 960 of 2000 took 0.100s
  training loss:		0.121883
  validation loss:		0.449959
  validation accuracy:		89.57 %
Epoch 961 of 2000 took 0.104s
  training loss:		0.122693
  validation loss:		0.433390
  validation accuracy:		89.78 %
Epoch 962 of 2000 took 0.105s
  training loss:		0.116148
  validation loss:		0.430405
  validation accuracy:		90.22 %
Epoch 963 of 2000 took 0.100s
  training loss:		0.122429
  validation loss:		0.435838
  validation accuracy:		89.78 %
Epoch 964 of 2000 took 0.102s
  training loss:		0.121797
  validation loss:		0.428879
  validation accuracy:		89.78 %
Epoch 965 of 2000 took 0.100s
  training loss:		0.122024
  validation loss:		0.419646
  validation accuracy:		89.67 %
Epoch 966 of 2000 took 0.105s
  training loss:		0.120374
  validation loss:		0.475676
  validation accuracy:		88.80 %
Epoch 967 of 2000 took 0.103s
  training loss:		0.128252
  validation loss:		0.457803
  validation accuracy:		89.35 %
Epoch 968 of 2000 took 0.100s
  training loss:		0.122368
  validation loss:		0.442965
  validation accuracy:		89.67 %
Epoch 969 of 2000 took 0.104s
  training loss:		0.127933
  validation loss:		0.425132
  validation accuracy:		89.67 %
Epoch 970 of 2000 took 0.105s
  training loss:		0.123397
  validation loss:		0.436766
  validation accuracy:		89.67 %
Epoch 971 of 2000 took 0.100s
  training loss:		0.127959
  validation loss:		0.465543
  validation accuracy:		88.91 %
Epoch 972 of 2000 took 0.103s
  training loss:		0.118224
  validation loss:		0.440230
  validation accuracy:		89.24 %
Epoch 973 of 2000 took 0.100s
  training loss:		0.119020
  validation loss:		0.438347
  validation accuracy:		89.78 %
Epoch 974 of 2000 took 0.105s
  training loss:		0.121584
  validation loss:		0.442639
  validation accuracy:		89.67 %
Epoch 975 of 2000 took 0.104s
  training loss:		0.124578
  validation loss:		0.444733
  validation accuracy:		89.78 %
Epoch 976 of 2000 took 0.101s
  training loss:		0.119164
  validation loss:		0.437190
  validation accuracy:		89.78 %
Epoch 977 of 2000 took 0.104s
  training loss:		0.118032
  validation loss:		0.454090
  validation accuracy:		89.46 %
Epoch 978 of 2000 took 0.106s
  training loss:		0.116456
  validation loss:		0.446418
  validation accuracy:		90.22 %
Epoch 979 of 2000 took 0.101s
  training loss:		0.127878
  validation loss:		0.425214
  validation accuracy:		90.33 %
Epoch 980 of 2000 took 0.103s
  training loss:		0.122856
  validation loss:		0.431165
  validation accuracy:		89.89 %
Epoch 981 of 2000 took 0.100s
  training loss:		0.120788
  validation loss:		0.428141
  validation accuracy:		90.22 %
Epoch 982 of 2000 took 0.105s
  training loss:		0.119635
  validation loss:		0.425851
  validation accuracy:		90.00 %
Epoch 983 of 2000 took 0.104s
  training loss:		0.115463
  validation loss:		0.421891
  validation accuracy:		89.67 %
Epoch 984 of 2000 took 0.100s
  training loss:		0.119163
  validation loss:		0.428619
  validation accuracy:		90.00 %
Epoch 985 of 2000 took 0.104s
  training loss:		0.119438
  validation loss:		0.416525
  validation accuracy:		90.43 %
Epoch 986 of 2000 took 0.106s
  training loss:		0.117138
  validation loss:		0.439928
  validation accuracy:		89.57 %
Epoch 987 of 2000 took 0.103s
  training loss:		0.118489
  validation loss:		0.472579
  validation accuracy:		89.35 %
Epoch 988 of 2000 took 0.106s
  training loss:		0.116564
  validation loss:		0.427531
  validation accuracy:		89.78 %
Epoch 989 of 2000 took 0.104s
  training loss:		0.111073
  validation loss:		0.432372
  validation accuracy:		89.78 %
Epoch 990 of 2000 took 0.103s
  training loss:		0.118236
  validation loss:		0.480486
  validation accuracy:		88.48 %
Epoch 991 of 2000 took 0.103s
  training loss:		0.134381
  validation loss:		0.419629
  validation accuracy:		90.22 %
Epoch 992 of 2000 took 0.103s
  training loss:		0.112142
  validation loss:		0.449367
  validation accuracy:		90.22 %
Epoch 993 of 2000 took 0.103s
  training loss:		0.121648
  validation loss:		0.437154
  validation accuracy:		89.78 %
Epoch 994 of 2000 took 0.103s
  training loss:		0.114561
  validation loss:		0.455995
  validation accuracy:		90.11 %
Epoch 995 of 2000 took 0.103s
  training loss:		0.124962
  validation loss:		0.428809
  validation accuracy:		90.00 %
Epoch 996 of 2000 took 0.102s
  training loss:		0.123116
  validation loss:		0.444638
  validation accuracy:		90.11 %
Epoch 997 of 2000 took 0.103s
  training loss:		0.114469
  validation loss:		0.455247
  validation accuracy:		89.35 %
Epoch 998 of 2000 took 0.103s
  training loss:		0.115322
  validation loss:		0.474003
  validation accuracy:		88.80 %
Epoch 999 of 2000 took 0.103s
  training loss:		0.122428
  validation loss:		0.462180
  validation accuracy:		89.78 %
Epoch 1000 of 2000 took 0.103s
  training loss:		0.118640
  validation loss:		0.448484
  validation accuracy:		90.00 %
Epoch 1001 of 2000 took 0.103s
  training loss:		0.113821
  validation loss:		0.434273
  validation accuracy:		89.89 %
Epoch 1002 of 2000 took 0.102s
  training loss:		0.114247
  validation loss:		0.430252
  validation accuracy:		90.11 %
Epoch 1003 of 2000 took 0.103s
  training loss:		0.112967
  validation loss:		0.455859
  validation accuracy:		89.46 %
Epoch 1004 of 2000 took 0.106s
  training loss:		0.110197
  validation loss:		0.467960
  validation accuracy:		89.78 %
Epoch 1005 of 2000 took 0.106s
  training loss:		0.119866
  validation loss:		0.427900
  validation accuracy:		90.11 %
Epoch 1006 of 2000 took 0.106s
  training loss:		0.117869
  validation loss:		0.442740
  validation accuracy:		89.57 %
Epoch 1007 of 2000 took 0.106s
  training loss:		0.117125
  validation loss:		0.451392
  validation accuracy:		89.89 %
Epoch 1008 of 2000 took 0.106s
  training loss:		0.116431
  validation loss:		0.448617
  validation accuracy:		89.57 %
Epoch 1009 of 2000 took 0.106s
  training loss:		0.114480
  validation loss:		0.424645
  validation accuracy:		90.43 %
Epoch 1010 of 2000 took 0.106s
  training loss:		0.115300
  validation loss:		0.434397
  validation accuracy:		90.33 %
Epoch 1011 of 2000 took 0.106s
  training loss:		0.117566
  validation loss:		0.437014
  validation accuracy:		90.22 %
Epoch 1012 of 2000 took 0.106s
  training loss:		0.113509
  validation loss:		0.460966
  validation accuracy:		89.46 %
Epoch 1013 of 2000 took 0.106s
  training loss:		0.118267
  validation loss:		0.463330
  validation accuracy:		89.67 %
Epoch 1014 of 2000 took 0.106s
  training loss:		0.113677
  validation loss:		0.452025
  validation accuracy:		89.46 %
Epoch 1015 of 2000 took 0.106s
  training loss:		0.130218
  validation loss:		0.466497
  validation accuracy:		89.57 %
Epoch 1016 of 2000 took 0.106s
  training loss:		0.126110
  validation loss:		0.452562
  validation accuracy:		89.89 %
Epoch 1017 of 2000 took 0.106s
  training loss:		0.111774
  validation loss:		0.445754
  validation accuracy:		90.22 %
Epoch 1018 of 2000 took 0.103s
  training loss:		0.116060
  validation loss:		0.457523
  validation accuracy:		89.02 %
Epoch 1019 of 2000 took 0.103s
  training loss:		0.117094
  validation loss:		0.461692
  validation accuracy:		89.13 %
Epoch 1020 of 2000 took 0.103s
  training loss:		0.113630
  validation loss:		0.453235
  validation accuracy:		89.67 %
Epoch 1021 of 2000 took 0.103s
  training loss:		0.111674
  validation loss:		0.474046
  validation accuracy:		89.78 %
Epoch 1022 of 2000 took 0.103s
  training loss:		0.114299
  validation loss:		0.459327
  validation accuracy:		89.35 %
Epoch 1023 of 2000 took 0.102s
  training loss:		0.112834
  validation loss:		0.469714
  validation accuracy:		89.35 %
Epoch 1024 of 2000 took 0.103s
  training loss:		0.124231
  validation loss:		0.446038
  validation accuracy:		89.57 %
Epoch 1025 of 2000 took 0.103s
  training loss:		0.115360
  validation loss:		0.450155
  validation accuracy:		89.89 %
Epoch 1026 of 2000 took 0.103s
  training loss:		0.110614
  validation loss:		0.443551
  validation accuracy:		89.67 %
Epoch 1027 of 2000 took 0.103s
  training loss:		0.106247
  validation loss:		0.437552
  validation accuracy:		89.89 %
Epoch 1028 of 2000 took 0.103s
  training loss:		0.115989
  validation loss:		0.485121
  validation accuracy:		89.46 %
Epoch 1029 of 2000 took 0.103s
  training loss:		0.112157
  validation loss:		0.436919
  validation accuracy:		90.22 %
Epoch 1030 of 2000 took 0.103s
  training loss:		0.114660
  validation loss:		0.446907
  validation accuracy:		89.89 %
Epoch 1031 of 2000 took 0.103s
  training loss:		0.110876
  validation loss:		0.478807
  validation accuracy:		89.46 %
Epoch 1032 of 2000 took 0.103s
  training loss:		0.110344
  validation loss:		0.471327
  validation accuracy:		89.78 %
Epoch 1033 of 2000 took 0.103s
  training loss:		0.110845
  validation loss:		0.451942
  validation accuracy:		89.89 %
Epoch 1034 of 2000 took 0.103s
  training loss:		0.112777
  validation loss:		0.444236
  validation accuracy:		89.67 %
Epoch 1035 of 2000 took 0.103s
  training loss:		0.109195
  validation loss:		0.493716
  validation accuracy:		88.91 %
Epoch 1036 of 2000 took 0.103s
  training loss:		0.110880
  validation loss:		0.466661
  validation accuracy:		89.57 %
Epoch 1037 of 2000 took 0.103s
  training loss:		0.110540
  validation loss:		0.464851
  validation accuracy:		89.67 %
Epoch 1038 of 2000 took 0.103s
  training loss:		0.107711
  validation loss:		0.446038
  validation accuracy:		90.22 %
Epoch 1039 of 2000 took 0.103s
  training loss:		0.114075
  validation loss:		0.458465
  validation accuracy:		89.35 %
Epoch 1040 of 2000 took 0.103s
  training loss:		0.116221
  validation loss:		0.452397
  validation accuracy:		89.57 %
Epoch 1041 of 2000 took 0.103s
  training loss:		0.113517
  validation loss:		0.495999
  validation accuracy:		89.13 %
Epoch 1042 of 2000 took 0.103s
  training loss:		0.112330
  validation loss:		0.491212
  validation accuracy:		89.02 %
Epoch 1043 of 2000 took 0.103s
  training loss:		0.106737
  validation loss:		0.460348
  validation accuracy:		89.89 %
Epoch 1044 of 2000 took 0.103s
  training loss:		0.114694
  validation loss:		0.456159
  validation accuracy:		89.89 %
Epoch 1045 of 2000 took 0.103s
  training loss:		0.107878
  validation loss:		0.458971
  validation accuracy:		89.67 %
Epoch 1046 of 2000 took 0.103s
  training loss:		0.121659
  validation loss:		0.459314
  validation accuracy:		89.67 %
Epoch 1047 of 2000 took 0.104s
  training loss:		0.117208
  validation loss:		0.479370
  validation accuracy:		89.13 %
Epoch 1048 of 2000 took 0.103s
  training loss:		0.113774
  validation loss:		0.452475
  validation accuracy:		89.89 %
Epoch 1049 of 2000 took 0.103s
  training loss:		0.107491
  validation loss:		0.455966
  validation accuracy:		89.89 %
Epoch 1050 of 2000 took 0.103s
  training loss:		0.110175
  validation loss:		0.471204
  validation accuracy:		89.57 %
Epoch 1051 of 2000 took 0.103s
  training loss:		0.110735
  validation loss:		0.449536
  validation accuracy:		90.11 %
Epoch 1052 of 2000 took 0.104s
  training loss:		0.106685
  validation loss:		0.459389
  validation accuracy:		90.11 %
Epoch 1053 of 2000 took 0.103s
  training loss:		0.112916
  validation loss:		0.474142
  validation accuracy:		89.46 %
Epoch 1054 of 2000 took 0.103s
  training loss:		0.109989
  validation loss:		0.439384
  validation accuracy:		90.43 %
Epoch 1055 of 2000 took 0.103s
  training loss:		0.114707
  validation loss:		0.478312
  validation accuracy:		88.80 %
Epoch 1056 of 2000 took 0.103s
  training loss:		0.112000
  validation loss:		0.497832
  validation accuracy:		89.24 %
Epoch 1057 of 2000 took 0.103s
  training loss:		0.103534
  validation loss:		0.466410
  validation accuracy:		90.00 %
Epoch 1058 of 2000 took 0.103s
  training loss:		0.102793
  validation loss:		0.495891
  validation accuracy:		89.24 %
Epoch 1059 of 2000 took 0.103s
  training loss:		0.106485
  validation loss:		0.467651
  validation accuracy:		89.46 %
Epoch 1060 of 2000 took 0.103s
  training loss:		0.109226
  validation loss:		0.471373
  validation accuracy:		89.46 %
Epoch 1061 of 2000 took 0.103s
  training loss:		0.107289
  validation loss:		0.500240
  validation accuracy:		88.91 %
Epoch 1062 of 2000 took 0.103s
  training loss:		0.121411
  validation loss:		0.478292
  validation accuracy:		89.24 %
Epoch 1063 of 2000 took 0.103s
  training loss:		0.109356
  validation loss:		0.457736
  validation accuracy:		89.67 %
Epoch 1064 of 2000 took 0.103s
  training loss:		0.107666
  validation loss:		0.468391
  validation accuracy:		89.78 %
Epoch 1065 of 2000 took 0.103s
  training loss:		0.105730
  validation loss:		0.470326
  validation accuracy:		89.57 %
Epoch 1066 of 2000 took 0.103s
  training loss:		0.117789
  validation loss:		0.480315
  validation accuracy:		89.24 %
Epoch 1067 of 2000 took 0.103s
  training loss:		0.109629
  validation loss:		0.467812
  validation accuracy:		89.67 %
Epoch 1068 of 2000 took 0.103s
  training loss:		0.111730
  validation loss:		0.546774
  validation accuracy:		88.15 %
Epoch 1069 of 2000 took 0.103s
  training loss:		0.106269
  validation loss:		0.454356
  validation accuracy:		90.43 %
Epoch 1070 of 2000 took 0.103s
  training loss:		0.110797
  validation loss:		0.486842
  validation accuracy:		89.35 %
Epoch 1071 of 2000 took 0.103s
  training loss:		0.102788
  validation loss:		0.487099
  validation accuracy:		89.24 %
Epoch 1072 of 2000 took 0.103s
  training loss:		0.106258
  validation loss:		0.470254
  validation accuracy:		89.78 %
Epoch 1073 of 2000 took 0.103s
  training loss:		0.107447
  validation loss:		0.502185
  validation accuracy:		89.57 %
Epoch 1074 of 2000 took 0.103s
  training loss:		0.115489
  validation loss:		0.524916
  validation accuracy:		88.48 %
Epoch 1075 of 2000 took 0.103s
  training loss:		0.112557
  validation loss:		0.476669
  validation accuracy:		89.57 %
Epoch 1076 of 2000 took 0.104s
  training loss:		0.106606
  validation loss:		0.472712
  validation accuracy:		90.11 %
Epoch 1077 of 2000 took 0.103s
  training loss:		0.101505
  validation loss:		0.512305
  validation accuracy:		88.70 %
Epoch 1078 of 2000 took 0.103s
  training loss:		0.108875
  validation loss:		0.489545
  validation accuracy:		89.78 %
Epoch 1079 of 2000 took 0.103s
  training loss:		0.107027
  validation loss:		0.483134
  validation accuracy:		89.78 %
Epoch 1080 of 2000 took 0.103s
  training loss:		0.114375
  validation loss:		0.487995
  validation accuracy:		89.57 %
Epoch 1081 of 2000 took 0.103s
  training loss:		0.110715
  validation loss:		0.525138
  validation accuracy:		88.37 %
Epoch 1082 of 2000 took 0.103s
  training loss:		0.107905
  validation loss:		0.470892
  validation accuracy:		89.57 %
Epoch 1083 of 2000 took 0.103s
  training loss:		0.114846
  validation loss:		0.478020
  validation accuracy:		89.46 %
Epoch 1084 of 2000 took 0.103s
  training loss:		0.111597
  validation loss:		0.502234
  validation accuracy:		89.13 %
Epoch 1085 of 2000 took 0.103s
  training loss:		0.105716
  validation loss:		0.506562
  validation accuracy:		89.35 %
Epoch 1086 of 2000 took 0.103s
  training loss:		0.103010
  validation loss:		0.475300
  validation accuracy:		89.78 %
Epoch 1087 of 2000 took 0.103s
  training loss:		0.110910
  validation loss:		0.476385
  validation accuracy:		89.67 %
Epoch 1088 of 2000 took 0.103s
  training loss:		0.108084
  validation loss:		0.511914
  validation accuracy:		89.24 %
Epoch 1089 of 2000 took 0.103s
  training loss:		0.108680
  validation loss:		0.488812
  validation accuracy:		89.67 %
Epoch 1090 of 2000 took 0.103s
  training loss:		0.109710
  validation loss:		0.487462
  validation accuracy:		89.35 %
Epoch 1091 of 2000 took 0.103s
  training loss:		0.102846
  validation loss:		0.486096
  validation accuracy:		89.46 %
Epoch 1092 of 2000 took 0.106s
  training loss:		0.107605
  validation loss:		0.513047
  validation accuracy:		88.80 %
Epoch 1093 of 2000 took 0.103s
  training loss:		0.106871
  validation loss:		0.494469
  validation accuracy:		89.67 %
Epoch 1094 of 2000 took 0.103s
  training loss:		0.119825
  validation loss:		0.479517
  validation accuracy:		89.57 %
Epoch 1095 of 2000 took 0.103s
  training loss:		0.100109
  validation loss:		0.497647
  validation accuracy:		89.67 %
Epoch 1096 of 2000 took 0.103s
  training loss:		0.105917
  validation loss:		0.495697
  validation accuracy:		90.00 %
Epoch 1097 of 2000 took 0.103s
  training loss:		0.108040
  validation loss:		0.497827
  validation accuracy:		89.57 %
Epoch 1098 of 2000 took 0.103s
  training loss:		0.111386
  validation loss:		0.478052
  validation accuracy:		90.11 %
Epoch 1099 of 2000 took 0.103s
  training loss:		0.112927
  validation loss:		0.469301
  validation accuracy:		90.76 %
Epoch 1100 of 2000 took 0.103s
  training loss:		0.099513
  validation loss:		0.481163
  validation accuracy:		90.22 %
Epoch 1101 of 2000 took 0.103s
  training loss:		0.112669
  validation loss:		0.483584
  validation accuracy:		89.78 %
Epoch 1102 of 2000 took 0.103s
  training loss:		0.099755
  validation loss:		0.468089
  validation accuracy:		90.22 %
Epoch 1103 of 2000 took 0.103s
  training loss:		0.104909
  validation loss:		0.523608
  validation accuracy:		89.02 %
Epoch 1104 of 2000 took 0.103s
  training loss:		0.121280
  validation loss:		0.512299
  validation accuracy:		89.02 %
Epoch 1105 of 2000 took 0.104s
  training loss:		0.104475
  validation loss:		0.481887
  validation accuracy:		89.67 %
Epoch 1106 of 2000 took 0.103s
  training loss:		0.117818
  validation loss:		0.470632
  validation accuracy:		90.11 %
Epoch 1107 of 2000 took 0.103s
  training loss:		0.101622
  validation loss:		0.484727
  validation accuracy:		89.35 %
Epoch 1108 of 2000 took 0.103s
  training loss:		0.101542
  validation loss:		0.493069
  validation accuracy:		89.67 %
Epoch 1109 of 2000 took 0.103s
  training loss:		0.109883
  validation loss:		0.515305
  validation accuracy:		88.70 %
Epoch 1110 of 2000 took 0.103s
  training loss:		0.101557
  validation loss:		0.501354
  validation accuracy:		89.67 %
Epoch 1111 of 2000 took 0.103s
  training loss:		0.105533
  validation loss:		0.525043
  validation accuracy:		88.48 %
Epoch 1112 of 2000 took 0.103s
  training loss:		0.107785
  validation loss:		0.479464
  validation accuracy:		89.67 %
Epoch 1113 of 2000 took 0.103s
  training loss:		0.132959
  validation loss:		0.530152
  validation accuracy:		89.13 %
Epoch 1114 of 2000 took 0.103s
  training loss:		0.109430
  validation loss:		0.491376
  validation accuracy:		89.46 %
Epoch 1115 of 2000 took 0.103s
  training loss:		0.100092
  validation loss:		0.482899
  validation accuracy:		89.46 %
Epoch 1116 of 2000 took 0.103s
  training loss:		0.114737
  validation loss:		0.520357
  validation accuracy:		89.24 %
Epoch 1117 of 2000 took 0.103s
  training loss:		0.104695
  validation loss:		0.501045
  validation accuracy:		89.57 %
Epoch 1118 of 2000 took 0.103s
  training loss:		0.108054
  validation loss:		0.513009
  validation accuracy:		89.24 %
Epoch 1119 of 2000 took 0.103s
  training loss:		0.103885
  validation loss:		0.503312
  validation accuracy:		89.46 %
Epoch 1120 of 2000 took 0.103s
  training loss:		0.099057
  validation loss:		0.495076
  validation accuracy:		89.78 %
Epoch 1121 of 2000 took 0.103s
  training loss:		0.099656
  validation loss:		0.476390
  validation accuracy:		90.33 %
Epoch 1122 of 2000 took 0.103s
  training loss:		0.111857
  validation loss:		0.479269
  validation accuracy:		89.67 %
Epoch 1123 of 2000 took 0.103s
  training loss:		0.105394
  validation loss:		0.503174
  validation accuracy:		89.67 %
Epoch 1124 of 2000 took 0.103s
  training loss:		0.099924
  validation loss:		0.512091
  validation accuracy:		89.46 %
Epoch 1125 of 2000 took 0.103s
  training loss:		0.102450
  validation loss:		0.503600
  validation accuracy:		89.67 %
Epoch 1126 of 2000 took 0.103s
  training loss:		0.110678
  validation loss:		0.525343
  validation accuracy:		89.13 %
Epoch 1127 of 2000 took 0.103s
  training loss:		0.107724
  validation loss:		0.496253
  validation accuracy:		89.46 %
Epoch 1128 of 2000 took 0.103s
  training loss:		0.098675
  validation loss:		0.504662
  validation accuracy:		89.13 %
Epoch 1129 of 2000 took 0.103s
  training loss:		0.102651
  validation loss:		0.479728
  validation accuracy:		90.11 %
Epoch 1130 of 2000 took 0.103s
  training loss:		0.097685
  validation loss:		0.505178
  validation accuracy:		89.46 %
Epoch 1131 of 2000 took 0.103s
  training loss:		0.101753
  validation loss:		0.525797
  validation accuracy:		88.91 %
Epoch 1132 of 2000 took 0.103s
  training loss:		0.108526
  validation loss:		0.469447
  validation accuracy:		89.89 %
Epoch 1133 of 2000 took 0.103s
  training loss:		0.100215
  validation loss:		0.479027
  validation accuracy:		89.67 %
Epoch 1134 of 2000 took 0.104s
  training loss:		0.104926
  validation loss:		0.491395
  validation accuracy:		89.46 %
Epoch 1135 of 2000 took 0.103s
  training loss:		0.099418
  validation loss:		0.513163
  validation accuracy:		88.91 %
Epoch 1136 of 2000 took 0.103s
  training loss:		0.105270
  validation loss:		0.550299
  validation accuracy:		88.15 %
Epoch 1137 of 2000 took 0.103s
  training loss:		0.096948
  validation loss:		0.511523
  validation accuracy:		89.35 %
Epoch 1138 of 2000 took 0.103s
  training loss:		0.098977
  validation loss:		0.524431
  validation accuracy:		88.59 %
Epoch 1139 of 2000 took 0.103s
  training loss:		0.101366
  validation loss:		0.502562
  validation accuracy:		89.46 %
Epoch 1140 of 2000 took 0.103s
  training loss:		0.097291
  validation loss:		0.487263
  validation accuracy:		89.89 %
Epoch 1141 of 2000 took 0.103s
  training loss:		0.098868
  validation loss:		0.489113
  validation accuracy:		89.57 %
Epoch 1142 of 2000 took 0.103s
  training loss:		0.100242
  validation loss:		0.517056
  validation accuracy:		88.91 %
Epoch 1143 of 2000 took 0.103s
  training loss:		0.100239
  validation loss:		0.526426
  validation accuracy:		88.70 %
Epoch 1144 of 2000 took 0.103s
  training loss:		0.095231
  validation loss:		0.495942
  validation accuracy:		89.89 %
Epoch 1145 of 2000 took 0.103s
  training loss:		0.100640
  validation loss:		0.500773
  validation accuracy:		89.35 %
Epoch 1146 of 2000 took 0.103s
  training loss:		0.103751
  validation loss:		0.523520
  validation accuracy:		89.24 %
Epoch 1147 of 2000 took 0.103s
  training loss:		0.106868
  validation loss:		0.491744
  validation accuracy:		89.46 %
Epoch 1148 of 2000 took 0.103s
  training loss:		0.096114
  validation loss:		0.495010
  validation accuracy:		89.89 %
Epoch 1149 of 2000 took 0.104s
  training loss:		0.102363
  validation loss:		0.509462
  validation accuracy:		89.57 %
Epoch 1150 of 2000 took 0.103s
  training loss:		0.096563
  validation loss:		0.522520
  validation accuracy:		89.13 %
Epoch 1151 of 2000 took 0.103s
  training loss:		0.098095
  validation loss:		0.490207
  validation accuracy:		89.89 %
Epoch 1152 of 2000 took 0.103s
  training loss:		0.093510
  validation loss:		0.506815
  validation accuracy:		89.02 %
Epoch 1153 of 2000 took 0.103s
  training loss:		0.100554
  validation loss:		0.489139
  validation accuracy:		90.00 %
Epoch 1154 of 2000 took 0.103s
  training loss:		0.098802
  validation loss:		0.553217
  validation accuracy:		88.70 %
Epoch 1155 of 2000 took 0.103s
  training loss:		0.104274
  validation loss:		0.504008
  validation accuracy:		89.78 %
Epoch 1156 of 2000 took 0.103s
  training loss:		0.108358
  validation loss:		0.495709
  validation accuracy:		89.57 %
Epoch 1157 of 2000 took 0.103s
  training loss:		0.103844
  validation loss:		0.542338
  validation accuracy:		89.02 %
Epoch 1158 of 2000 took 0.103s
  training loss:		0.101509
  validation loss:		0.522847
  validation accuracy:		89.46 %
Epoch 1159 of 2000 took 0.103s
  training loss:		0.103903
  validation loss:		0.507547
  validation accuracy:		89.46 %
Epoch 1160 of 2000 took 0.103s
  training loss:		0.098047
  validation loss:		0.526718
  validation accuracy:		89.02 %
Epoch 1161 of 2000 took 0.103s
  training loss:		0.096916
  validation loss:		0.516107
  validation accuracy:		89.24 %
Epoch 1162 of 2000 took 0.103s
  training loss:		0.100226
  validation loss:		0.558924
  validation accuracy:		89.67 %
Epoch 1163 of 2000 took 0.103s
  training loss:		0.098387
  validation loss:		0.530666
  validation accuracy:		89.13 %
Epoch 1164 of 2000 took 0.104s
  training loss:		0.094384
  validation loss:		0.522233
  validation accuracy:		89.57 %
Epoch 1165 of 2000 took 0.103s
  training loss:		0.095247
  validation loss:		0.521538
  validation accuracy:		89.13 %
Epoch 1166 of 2000 took 0.103s
  training loss:		0.102325
  validation loss:		0.548291
  validation accuracy:		89.02 %
Epoch 1167 of 2000 took 0.103s
  training loss:		0.097895
  validation loss:		0.537428
  validation accuracy:		88.80 %
Epoch 1168 of 2000 took 0.103s
  training loss:		0.100320
  validation loss:		0.550203
  validation accuracy:		89.02 %
Epoch 1169 of 2000 took 0.103s
  training loss:		0.103726
  validation loss:		0.531697
  validation accuracy:		89.35 %
Epoch 1170 of 2000 took 0.103s
  training loss:		0.092663
  validation loss:		0.567783
  validation accuracy:		88.48 %
Epoch 1171 of 2000 took 0.103s
  training loss:		0.097497
  validation loss:		0.518458
  validation accuracy:		89.24 %
Epoch 1172 of 2000 took 0.103s
  training loss:		0.099588
  validation loss:		0.521291
  validation accuracy:		89.57 %
Epoch 1173 of 2000 took 0.103s
  training loss:		0.100554
  validation loss:		0.531193
  validation accuracy:		89.02 %
Epoch 1174 of 2000 took 0.103s
  training loss:		0.101339
  validation loss:		0.531471
  validation accuracy:		89.02 %
Epoch 1175 of 2000 took 0.103s
  training loss:		0.092887
  validation loss:		0.512775
  validation accuracy:		89.46 %
Epoch 1176 of 2000 took 0.103s
  training loss:		0.094454
  validation loss:		0.535754
  validation accuracy:		89.57 %
Epoch 1177 of 2000 took 0.103s
  training loss:		0.099736
  validation loss:		0.595293
  validation accuracy:		88.48 %
Epoch 1178 of 2000 took 0.103s
  training loss:		0.097655
  validation loss:		0.539556
  validation accuracy:		89.24 %
Epoch 1179 of 2000 took 0.103s
  training loss:		0.097593
  validation loss:		0.535580
  validation accuracy:		89.35 %
Epoch 1180 of 2000 took 0.103s
  training loss:		0.088564
  validation loss:		0.530054
  validation accuracy:		89.24 %
Epoch 1181 of 2000 took 0.103s
  training loss:		0.100266
  validation loss:		0.558294
  validation accuracy:		89.35 %
Epoch 1182 of 2000 took 0.103s
  training loss:		0.102785
  validation loss:		0.561838
  validation accuracy:		89.13 %
Epoch 1183 of 2000 took 0.103s
  training loss:		0.113032
  validation loss:		0.542351
  validation accuracy:		88.91 %
Epoch 1184 of 2000 took 0.103s
  training loss:		0.096386
  validation loss:		0.535323
  validation accuracy:		89.35 %
Epoch 1185 of 2000 took 0.103s
  training loss:		0.098500
  validation loss:		0.544139
  validation accuracy:		89.24 %
Epoch 1186 of 2000 took 0.103s
  training loss:		0.105668
  validation loss:		0.534338
  validation accuracy:		89.46 %
Epoch 1187 of 2000 took 0.103s
  training loss:		0.099152
  validation loss:		0.536283
  validation accuracy:		89.35 %
Epoch 1188 of 2000 took 0.103s
  training loss:		0.091468
  validation loss:		0.524943
  validation accuracy:		89.35 %
Epoch 1189 of 2000 took 0.103s
  training loss:		0.093403
  validation loss:		0.588219
  validation accuracy:		88.59 %
Epoch 1190 of 2000 took 0.103s
  training loss:		0.102595
  validation loss:		0.532518
  validation accuracy:		89.24 %
Epoch 1191 of 2000 took 0.103s
  training loss:		0.090112
  validation loss:		0.519636
  validation accuracy:		89.67 %
Epoch 1192 of 2000 took 0.103s
  training loss:		0.096987
  validation loss:		0.578451
  validation accuracy:		89.02 %
Epoch 1193 of 2000 took 0.104s
  training loss:		0.100456
  validation loss:		0.531418
  validation accuracy:		89.57 %
Epoch 1194 of 2000 took 0.103s
  training loss:		0.100386
  validation loss:		0.517010
  validation accuracy:		89.89 %
Epoch 1195 of 2000 took 0.103s
  training loss:		0.092141
  validation loss:		0.548867
  validation accuracy:		88.91 %
Epoch 1196 of 2000 took 0.103s
  training loss:		0.099733
  validation loss:		0.527583
  validation accuracy:		89.35 %
Epoch 1197 of 2000 took 0.103s
  training loss:		0.092159
  validation loss:		0.526690
  validation accuracy:		89.35 %
Epoch 1198 of 2000 took 0.103s
  training loss:		0.101354
  validation loss:		0.542619
  validation accuracy:		89.35 %
Epoch 1199 of 2000 took 0.103s
  training loss:		0.100102
  validation loss:		0.554519
  validation accuracy:		89.67 %
Epoch 1200 of 2000 took 0.103s
  training loss:		0.099361
  validation loss:		0.556383
  validation accuracy:		89.13 %
Epoch 1201 of 2000 took 0.103s
  training loss:		0.093871
  validation loss:		0.516176
  validation accuracy:		89.67 %
Epoch 1202 of 2000 took 0.103s
  training loss:		0.091636
  validation loss:		0.541565
  validation accuracy:		88.80 %
Epoch 1203 of 2000 took 0.103s
  training loss:		0.091426
  validation loss:		0.554808
  validation accuracy:		89.24 %
Epoch 1204 of 2000 took 0.103s
  training loss:		0.089854
  validation loss:		0.533322
  validation accuracy:		89.13 %
Epoch 1205 of 2000 took 0.103s
  training loss:		0.095530
  validation loss:		0.569495
  validation accuracy:		88.80 %
Epoch 1206 of 2000 took 0.103s
  training loss:		0.091930
  validation loss:		0.546906
  validation accuracy:		88.80 %
Epoch 1207 of 2000 took 0.103s
  training loss:		0.101682
  validation loss:		0.561394
  validation accuracy:		89.13 %
Epoch 1208 of 2000 took 0.103s
  training loss:		0.091782
  validation loss:		0.561305
  validation accuracy:		89.13 %
Epoch 1209 of 2000 took 0.103s
  training loss:		0.101005
  validation loss:		0.543390
  validation accuracy:		89.24 %
Epoch 1210 of 2000 took 0.103s
  training loss:		0.093442
  validation loss:		0.527822
  validation accuracy:		89.67 %
Epoch 1211 of 2000 took 0.103s
  training loss:		0.095732
  validation loss:		0.532005
  validation accuracy:		89.02 %
Epoch 1212 of 2000 took 0.103s
  training loss:		0.100858
  validation loss:		0.558251
  validation accuracy:		89.24 %
Epoch 1213 of 2000 took 0.103s
  training loss:		0.096853
  validation loss:		0.520932
  validation accuracy:		89.89 %
Epoch 1214 of 2000 took 0.103s
  training loss:		0.091000
  validation loss:		0.577065
  validation accuracy:		88.80 %
Epoch 1215 of 2000 took 0.103s
  training loss:		0.099544
  validation loss:		0.572700
  validation accuracy:		89.02 %
Epoch 1216 of 2000 took 0.103s
  training loss:		0.096338
  validation loss:		0.543665
  validation accuracy:		89.24 %
Epoch 1217 of 2000 took 0.106s
  training loss:		0.096589
  validation loss:		0.531127
  validation accuracy:		89.67 %
Epoch 1218 of 2000 took 0.103s
  training loss:		0.094937
  validation loss:		0.574828
  validation accuracy:		89.02 %
Epoch 1219 of 2000 took 0.103s
  training loss:		0.099482
  validation loss:		0.570521
  validation accuracy:		88.37 %
Epoch 1220 of 2000 took 0.103s
  training loss:		0.093369
  validation loss:		0.599346
  validation accuracy:		89.02 %
Epoch 1221 of 2000 took 0.103s
  training loss:		0.092547
  validation loss:		0.542182
  validation accuracy:		89.67 %
Epoch 1222 of 2000 took 0.104s
  training loss:		0.108430
  validation loss:		0.562229
  validation accuracy:		89.13 %
Epoch 1223 of 2000 took 0.103s
  training loss:		0.091890
  validation loss:		0.546893
  validation accuracy:		89.46 %
Epoch 1224 of 2000 took 0.103s
  training loss:		0.088603
  validation loss:		0.551745
  validation accuracy:		89.13 %
Epoch 1225 of 2000 took 0.103s
  training loss:		0.092370
  validation loss:		0.571726
  validation accuracy:		89.02 %
Epoch 1226 of 2000 took 0.103s
  training loss:		0.090577
  validation loss:		0.562226
  validation accuracy:		89.24 %
Epoch 1227 of 2000 took 0.103s
  training loss:		0.094036
  validation loss:		0.591747
  validation accuracy:		88.48 %
Epoch 1228 of 2000 took 0.103s
  training loss:		0.095903
  validation loss:		0.546625
  validation accuracy:		89.35 %
Epoch 1229 of 2000 took 0.103s
  training loss:		0.094747
  validation loss:		0.543742
  validation accuracy:		89.46 %
Epoch 1230 of 2000 took 0.103s
  training loss:		0.094356
  validation loss:		0.582996
  validation accuracy:		89.02 %
Epoch 1231 of 2000 took 0.103s
  training loss:		0.106842
  validation loss:		0.558512
  validation accuracy:		89.02 %
Epoch 1232 of 2000 took 0.103s
  training loss:		0.090720
  validation loss:		0.558665
  validation accuracy:		89.13 %
Epoch 1233 of 2000 took 0.103s
  training loss:		0.089824
  validation loss:		0.569048
  validation accuracy:		89.24 %
Epoch 1234 of 2000 took 0.103s
  training loss:		0.095258
  validation loss:		0.551354
  validation accuracy:		89.24 %
Epoch 1235 of 2000 took 0.103s
  training loss:		0.093857
  validation loss:		0.542027
  validation accuracy:		89.35 %
Epoch 1236 of 2000 took 0.103s
  training loss:		0.090841
  validation loss:		0.567169
  validation accuracy:		89.02 %
Epoch 1237 of 2000 took 0.103s
  training loss:		0.091481
  validation loss:		0.560175
  validation accuracy:		89.13 %
Epoch 1238 of 2000 took 0.103s
  training loss:		0.092970
  validation loss:		0.561444
  validation accuracy:		89.24 %
Epoch 1239 of 2000 took 0.103s
  training loss:		0.090950
  validation loss:		0.574389
  validation accuracy:		88.80 %
Epoch 1240 of 2000 took 0.103s
  training loss:		0.086171
  validation loss:		0.526466
  validation accuracy:		89.67 %
Epoch 1241 of 2000 took 0.103s
  training loss:		0.095288
  validation loss:		0.561193
  validation accuracy:		89.67 %
Epoch 1242 of 2000 took 0.103s
  training loss:		0.088447
  validation loss:		0.537485
  validation accuracy:		90.11 %
Epoch 1243 of 2000 took 0.103s
  training loss:		0.091393
  validation loss:		0.569618
  validation accuracy:		89.24 %
Epoch 1244 of 2000 took 0.103s
  training loss:		0.088621
  validation loss:		0.570586
  validation accuracy:		89.02 %
Epoch 1245 of 2000 took 0.103s
  training loss:		0.086189
  validation loss:		0.591813
  validation accuracy:		88.80 %
Epoch 1246 of 2000 took 0.104s
  training loss:		0.094112
  validation loss:		0.524768
  validation accuracy:		89.35 %
Epoch 1247 of 2000 took 0.103s
  training loss:		0.092389
  validation loss:		0.570462
  validation accuracy:		89.13 %
Epoch 1248 of 2000 took 0.103s
  training loss:		0.096439
  validation loss:		0.590701
  validation accuracy:		89.13 %
Epoch 1249 of 2000 took 0.103s
  training loss:		0.099570
  validation loss:		0.560360
  validation accuracy:		89.02 %
Epoch 1250 of 2000 took 0.103s
  training loss:		0.105434
  validation loss:		0.553142
  validation accuracy:		89.13 %
Epoch 1251 of 2000 took 0.103s
  training loss:		0.091830
  validation loss:		0.558228
  validation accuracy:		89.35 %
Epoch 1252 of 2000 took 0.104s
  training loss:		0.089618
  validation loss:		0.606464
  validation accuracy:		89.24 %
Epoch 1253 of 2000 took 0.103s
  training loss:		0.090967
  validation loss:		0.584552
  validation accuracy:		88.91 %
Epoch 1254 of 2000 took 0.103s
  training loss:		0.107855
  validation loss:		0.566279
  validation accuracy:		89.13 %
Epoch 1255 of 2000 took 0.103s
  training loss:		0.091954
  validation loss:		0.560707
  validation accuracy:		89.35 %
Epoch 1256 of 2000 took 0.103s
  training loss:		0.107219
  validation loss:		0.569709
  validation accuracy:		89.02 %
Epoch 1257 of 2000 took 0.103s
  training loss:		0.095476
  validation loss:		0.625711
  validation accuracy:		88.26 %
Epoch 1258 of 2000 took 0.103s
  training loss:		0.094684
  validation loss:		0.580585
  validation accuracy:		89.02 %
Epoch 1259 of 2000 took 0.103s
  training loss:		0.089058
  validation loss:		0.581885
  validation accuracy:		88.91 %
Epoch 1260 of 2000 took 0.103s
  training loss:		0.090470
  validation loss:		0.543680
  validation accuracy:		89.89 %
Epoch 1261 of 2000 took 0.103s
  training loss:		0.095286
  validation loss:		0.637105
  validation accuracy:		88.26 %
Epoch 1262 of 2000 took 0.103s
  training loss:		0.091478
  validation loss:		0.569946
  validation accuracy:		89.67 %
Epoch 1263 of 2000 took 0.103s
  training loss:		0.093027
  validation loss:		0.580300
  validation accuracy:		89.24 %
Epoch 1264 of 2000 took 0.103s
  training loss:		0.088880
  validation loss:		0.568073
  validation accuracy:		89.24 %
Epoch 1265 of 2000 took 0.103s
  training loss:		0.085424
  validation loss:		0.590612
  validation accuracy:		88.59 %
Epoch 1266 of 2000 took 0.103s
  training loss:		0.091669
  validation loss:		0.576362
  validation accuracy:		89.46 %
Epoch 1267 of 2000 took 0.103s
  training loss:		0.088269
  validation loss:		0.562680
  validation accuracy:		89.13 %
Epoch 1268 of 2000 took 0.103s
  training loss:		0.089890
  validation loss:		0.579251
  validation accuracy:		88.70 %
Epoch 1269 of 2000 took 0.103s
  training loss:		0.091049
  validation loss:		0.591316
  validation accuracy:		89.02 %
Epoch 1270 of 2000 took 0.103s
  training loss:		0.084867
  validation loss:		0.573085
  validation accuracy:		89.24 %
Epoch 1271 of 2000 took 0.103s
  training loss:		0.088046
  validation loss:		0.554695
  validation accuracy:		89.57 %
Epoch 1272 of 2000 took 0.103s
  training loss:		0.087280
  validation loss:		0.598732
  validation accuracy:		89.13 %
Epoch 1273 of 2000 took 0.103s
  training loss:		0.088546
  validation loss:		0.576700
  validation accuracy:		89.35 %
Epoch 1274 of 2000 took 0.103s
  training loss:		0.091011
  validation loss:		0.608893
  validation accuracy:		88.26 %
Epoch 1275 of 2000 took 0.103s
  training loss:		0.085852
  validation loss:		0.572515
  validation accuracy:		89.78 %
Epoch 1276 of 2000 took 0.103s
  training loss:		0.090451
  validation loss:		0.590147
  validation accuracy:		89.46 %
Epoch 1277 of 2000 took 0.103s
  training loss:		0.093514
  validation loss:		0.668606
  validation accuracy:		87.93 %
Epoch 1278 of 2000 took 0.103s
  training loss:		0.095365
  validation loss:		0.619664
  validation accuracy:		88.70 %
Epoch 1279 of 2000 took 0.103s
  training loss:		0.084102
  validation loss:		0.585580
  validation accuracy:		89.46 %
Epoch 1280 of 2000 took 0.103s
  training loss:		0.085595
  validation loss:		0.578445
  validation accuracy:		89.13 %
Epoch 1281 of 2000 took 0.103s
  training loss:		0.091062
  validation loss:		0.591284
  validation accuracy:		89.24 %
Epoch 1282 of 2000 took 0.103s
  training loss:		0.093512
  validation loss:		0.589763
  validation accuracy:		89.02 %
Epoch 1283 of 2000 took 0.103s
  training loss:		0.093157
  validation loss:		0.636554
  validation accuracy:		88.26 %
Epoch 1284 of 2000 took 0.103s
  training loss:		0.090175
  validation loss:		0.625812
  validation accuracy:		88.37 %
Epoch 1285 of 2000 took 0.103s
  training loss:		0.088111
  validation loss:		0.611590
  validation accuracy:		89.13 %
Epoch 1286 of 2000 took 0.103s
  training loss:		0.098533
  validation loss:		0.583344
  validation accuracy:		89.46 %
Epoch 1287 of 2000 took 0.103s
  training loss:		0.088519
  validation loss:		0.605949
  validation accuracy:		88.59 %
Epoch 1288 of 2000 took 0.103s
  training loss:		0.084658
  validation loss:		0.572742
  validation accuracy:		89.35 %
Epoch 1289 of 2000 took 0.103s
  training loss:		0.092223
  validation loss:		0.593269
  validation accuracy:		89.02 %
Epoch 1290 of 2000 took 0.103s
  training loss:		0.083841
  validation loss:		0.581964
  validation accuracy:		89.46 %
Epoch 1291 of 2000 took 0.103s
  training loss:		0.085597
  validation loss:		0.619999
  validation accuracy:		88.80 %
Epoch 1292 of 2000 took 0.103s
  training loss:		0.092635
  validation loss:		0.591661
  validation accuracy:		89.24 %
Epoch 1293 of 2000 took 0.103s
  training loss:		0.088768
  validation loss:		0.638513
  validation accuracy:		89.13 %
Epoch 1294 of 2000 took 0.103s
  training loss:		0.089877
  validation loss:		0.587690
  validation accuracy:		89.78 %
Epoch 1295 of 2000 took 0.103s
  training loss:		0.086521
  validation loss:		0.602963
  validation accuracy:		89.24 %
Epoch 1296 of 2000 took 0.103s
  training loss:		0.085654
  validation loss:		0.606775
  validation accuracy:		88.91 %
Epoch 1297 of 2000 took 0.103s
  training loss:		0.092702
  validation loss:		0.638815
  validation accuracy:		88.26 %
Epoch 1298 of 2000 took 0.103s
  training loss:		0.090194
  validation loss:		0.621273
  validation accuracy:		88.70 %
Epoch 1299 of 2000 took 0.103s
  training loss:		0.084816
  validation loss:		0.642783
  validation accuracy:		88.59 %
Epoch 1300 of 2000 took 0.103s
  training loss:		0.091784
  validation loss:		0.590319
  validation accuracy:		89.13 %
Epoch 1301 of 2000 took 0.103s
  training loss:		0.086070
  validation loss:		0.579988
  validation accuracy:		89.35 %
Epoch 1302 of 2000 took 0.103s
  training loss:		0.082624
  validation loss:		0.588457
  validation accuracy:		89.02 %
Epoch 1303 of 2000 took 0.103s
  training loss:		0.092755
  validation loss:		0.599690
  validation accuracy:		88.80 %
Epoch 1304 of 2000 took 0.103s
  training loss:		0.091129
  validation loss:		0.595882
  validation accuracy:		89.02 %
Epoch 1305 of 2000 took 0.103s
  training loss:		0.083026
  validation loss:		0.643767
  validation accuracy:		88.26 %
Epoch 1306 of 2000 took 0.103s
  training loss:		0.090030
  validation loss:		0.597897
  validation accuracy:		89.35 %
Epoch 1307 of 2000 took 0.103s
  training loss:		0.083154
  validation loss:		0.623585
  validation accuracy:		88.59 %
Epoch 1308 of 2000 took 0.103s
  training loss:		0.086205
  validation loss:		0.590484
  validation accuracy:		89.67 %
Epoch 1309 of 2000 took 0.103s
  training loss:		0.088749
  validation loss:		0.626733
  validation accuracy:		88.59 %
Epoch 1310 of 2000 took 0.104s
  training loss:		0.096312
  validation loss:		0.605105
  validation accuracy:		89.24 %
Epoch 1311 of 2000 took 0.103s
  training loss:		0.092795
  validation loss:		0.627124
  validation accuracy:		88.91 %
Epoch 1312 of 2000 took 0.103s
  training loss:		0.089775
  validation loss:		0.609106
  validation accuracy:		89.13 %
Epoch 1313 of 2000 took 0.103s
  training loss:		0.092088
  validation loss:		0.636768
  validation accuracy:		88.59 %
Epoch 1314 of 2000 took 0.103s
  training loss:		0.080356
  validation loss:		0.636809
  validation accuracy:		88.37 %
Epoch 1315 of 2000 took 0.103s
  training loss:		0.097477
  validation loss:		0.579564
  validation accuracy:		89.02 %
Epoch 1316 of 2000 took 0.103s
  training loss:		0.096646
  validation loss:		0.584885
  validation accuracy:		89.35 %
Epoch 1317 of 2000 took 0.103s
  training loss:		0.078906
  validation loss:		0.623217
  validation accuracy:		89.02 %
Epoch 1318 of 2000 took 0.103s
  training loss:		0.090436
  validation loss:		0.597170
  validation accuracy:		89.13 %
Epoch 1319 of 2000 took 0.103s
  training loss:		0.093949
  validation loss:		0.608171
  validation accuracy:		89.13 %
Epoch 1320 of 2000 took 0.103s
  training loss:		0.088289
  validation loss:		0.647982
  validation accuracy:		88.15 %
Epoch 1321 of 2000 took 0.103s
  training loss:		0.095698
  validation loss:		0.650238
  validation accuracy:		88.37 %
Epoch 1322 of 2000 took 0.103s
  training loss:		0.091556
  validation loss:		0.609825
  validation accuracy:		89.35 %
Epoch 1323 of 2000 took 0.103s
  training loss:		0.088755
  validation loss:		0.605943
  validation accuracy:		89.13 %
Epoch 1324 of 2000 took 0.103s
  training loss:		0.084484
  validation loss:		0.581869
  validation accuracy:		89.78 %
Epoch 1325 of 2000 took 0.103s
  training loss:		0.101365
  validation loss:		0.597458
  validation accuracy:		89.24 %
Epoch 1326 of 2000 took 0.103s
  training loss:		0.091542
  validation loss:		0.643310
  validation accuracy:		89.13 %
Epoch 1327 of 2000 took 0.103s
  training loss:		0.088852
  validation loss:		0.623725
  validation accuracy:		89.02 %
Epoch 1328 of 2000 took 0.103s
  training loss:		0.083313
  validation loss:		0.615415
  validation accuracy:		89.02 %
Epoch 1329 of 2000 took 0.103s
  training loss:		0.087202
  validation loss:		0.614793
  validation accuracy:		88.91 %
Epoch 1330 of 2000 took 0.103s
  training loss:		0.081238
  validation loss:		0.618877
  validation accuracy:		89.35 %
Epoch 1331 of 2000 took 0.103s
  training loss:		0.085157
  validation loss:		0.624007
  validation accuracy:		88.59 %
Epoch 1332 of 2000 took 0.103s
  training loss:		0.087240
  validation loss:		0.610539
  validation accuracy:		88.91 %
Epoch 1333 of 2000 took 0.103s
  training loss:		0.079532
  validation loss:		0.600959
  validation accuracy:		89.89 %
Epoch 1334 of 2000 took 0.103s
  training loss:		0.082020
  validation loss:		0.588047
  validation accuracy:		89.24 %
Epoch 1335 of 2000 took 0.103s
  training loss:		0.087084
  validation loss:		0.658943
  validation accuracy:		88.37 %
Epoch 1336 of 2000 took 0.103s
  training loss:		0.096916
  validation loss:		0.662608
  validation accuracy:		88.26 %
Epoch 1337 of 2000 took 0.103s
  training loss:		0.093606
  validation loss:		0.624972
  validation accuracy:		88.80 %
Epoch 1338 of 2000 took 0.103s
  training loss:		0.082985
  validation loss:		0.630214
  validation accuracy:		88.80 %
Epoch 1339 of 2000 took 0.103s
  training loss:		0.083033
  validation loss:		0.642005
  validation accuracy:		88.80 %
Epoch 1340 of 2000 took 0.103s
  training loss:		0.085845
  validation loss:		0.630423
  validation accuracy:		89.02 %
Epoch 1341 of 2000 took 0.103s
  training loss:		0.081616
  validation loss:		0.637482
  validation accuracy:		89.13 %
Epoch 1342 of 2000 took 0.103s
  training loss:		0.084243
  validation loss:		0.596144
  validation accuracy:		89.13 %
Epoch 1343 of 2000 took 0.104s
  training loss:		0.080105
  validation loss:		0.622265
  validation accuracy:		89.02 %
Epoch 1344 of 2000 took 0.103s
  training loss:		0.093877
  validation loss:		0.615027
  validation accuracy:		88.91 %
Epoch 1345 of 2000 took 0.103s
  training loss:		0.081062
  validation loss:		0.619507
  validation accuracy:		88.91 %
Epoch 1346 of 2000 took 0.103s
  training loss:		0.089284
  validation loss:		0.641471
  validation accuracy:		88.80 %
Epoch 1347 of 2000 took 0.103s
  training loss:		0.076819
  validation loss:		0.637589
  validation accuracy:		89.02 %
Epoch 1348 of 2000 took 0.103s
  training loss:		0.085993
  validation loss:		0.648372
  validation accuracy:		89.02 %
Epoch 1349 of 2000 took 0.103s
  training loss:		0.085864
  validation loss:		0.653645
  validation accuracy:		88.37 %
Epoch 1350 of 2000 took 0.103s
  training loss:		0.082466
  validation loss:		0.636034
  validation accuracy:		89.35 %
Epoch 1351 of 2000 took 0.103s
  training loss:		0.085151
  validation loss:		0.684629
  validation accuracy:		87.72 %
Epoch 1352 of 2000 took 0.103s
  training loss:		0.090880
  validation loss:		0.638335
  validation accuracy:		88.91 %
Epoch 1353 of 2000 took 0.103s
  training loss:		0.083374
  validation loss:		0.621400
  validation accuracy:		89.46 %
Epoch 1354 of 2000 took 0.103s
  training loss:		0.088062
  validation loss:		0.648998
  validation accuracy:		89.13 %
Epoch 1355 of 2000 took 0.103s
  training loss:		0.085597
  validation loss:		0.643171
  validation accuracy:		88.59 %
Epoch 1356 of 2000 took 0.103s
  training loss:		0.079979
  validation loss:		0.674404
  validation accuracy:		88.04 %
Epoch 1357 of 2000 took 0.103s
  training loss:		0.079702
  validation loss:		0.639688
  validation accuracy:		88.70 %
Epoch 1358 of 2000 took 0.103s
  training loss:		0.078990
  validation loss:		0.684926
  validation accuracy:		88.37 %
Epoch 1359 of 2000 took 0.103s
  training loss:		0.081731
  validation loss:		0.658131
  validation accuracy:		88.37 %
Epoch 1360 of 2000 took 0.103s
  training loss:		0.083352
  validation loss:		0.670786
  validation accuracy:		88.80 %
Epoch 1361 of 2000 took 0.103s
  training loss:		0.084174
  validation loss:		0.668269
  validation accuracy:		88.70 %
Epoch 1362 of 2000 took 0.103s
  training loss:		0.086059
  validation loss:		0.696562
  validation accuracy:		88.15 %
Epoch 1363 of 2000 took 0.103s
  training loss:		0.087702
  validation loss:		0.658156
  validation accuracy:		88.15 %
Epoch 1364 of 2000 took 0.103s
  training loss:		0.087042
  validation loss:		0.640274
  validation accuracy:		89.46 %
Epoch 1365 of 2000 took 0.103s
  training loss:		0.084634
  validation loss:		0.711092
  validation accuracy:		87.83 %
Epoch 1366 of 2000 took 0.103s
  training loss:		0.082694
  validation loss:		0.682236
  validation accuracy:		88.37 %
Epoch 1367 of 2000 took 0.106s
  training loss:		0.085344
  validation loss:		0.649578
  validation accuracy:		89.24 %
Epoch 1368 of 2000 took 0.103s
  training loss:		0.077461
  validation loss:		0.659973
  validation accuracy:		88.80 %
Epoch 1369 of 2000 took 0.104s
  training loss:		0.080106
  validation loss:		0.631778
  validation accuracy:		89.35 %
Epoch 1370 of 2000 took 0.103s
  training loss:		0.085698
  validation loss:		0.673417
  validation accuracy:		88.91 %
Epoch 1371 of 2000 took 0.103s
  training loss:		0.085311
  validation loss:		0.655819
  validation accuracy:		88.59 %
Epoch 1372 of 2000 took 0.103s
  training loss:		0.083428
  validation loss:		0.622927
  validation accuracy:		89.13 %
Epoch 1373 of 2000 took 0.103s
  training loss:		0.083314
  validation loss:		0.678398
  validation accuracy:		88.48 %
Epoch 1374 of 2000 took 0.103s
  training loss:		0.085284
  validation loss:		0.628572
  validation accuracy:		88.91 %
Epoch 1375 of 2000 took 0.103s
  training loss:		0.082612
  validation loss:		0.640054
  validation accuracy:		89.02 %
Epoch 1376 of 2000 took 0.103s
  training loss:		0.075359
  validation loss:		0.660054
  validation accuracy:		88.70 %
Epoch 1377 of 2000 took 0.103s
  training loss:		0.077408
  validation loss:		0.628381
  validation accuracy:		89.35 %
Epoch 1378 of 2000 took 0.103s
  training loss:		0.081362
  validation loss:		0.676735
  validation accuracy:		88.26 %
Epoch 1379 of 2000 took 0.103s
  training loss:		0.082396
  validation loss:		0.661766
  validation accuracy:		88.70 %
Epoch 1380 of 2000 took 0.103s
  training loss:		0.086187
  validation loss:		0.649592
  validation accuracy:		89.02 %
Epoch 1381 of 2000 took 0.103s
  training loss:		0.117760
  validation loss:		0.657122
  validation accuracy:		88.26 %
Epoch 1382 of 2000 took 0.103s
  training loss:		0.083928
  validation loss:		0.650839
  validation accuracy:		89.02 %
Epoch 1383 of 2000 took 0.103s
  training loss:		0.080972
  validation loss:		0.626921
  validation accuracy:		89.02 %
Epoch 1384 of 2000 took 0.103s
  training loss:		0.079254
  validation loss:		0.640938
  validation accuracy:		89.46 %
Epoch 1385 of 2000 took 0.103s
  training loss:		0.089158
  validation loss:		0.677443
  validation accuracy:		88.59 %
Epoch 1386 of 2000 took 0.103s
  training loss:		0.080542
  validation loss:		0.659751
  validation accuracy:		88.70 %
Epoch 1387 of 2000 took 0.103s
  training loss:		0.091163
  validation loss:		0.663192
  validation accuracy:		88.80 %
Epoch 1388 of 2000 took 0.103s
  training loss:		0.083999
  validation loss:		0.664661
  validation accuracy:		88.91 %
Epoch 1389 of 2000 took 0.103s
  training loss:		0.080099
  validation loss:		0.644983
  validation accuracy:		88.70 %
Epoch 1390 of 2000 took 0.103s
  training loss:		0.084981
  validation loss:		0.696238
  validation accuracy:		88.37 %
Epoch 1391 of 2000 took 0.103s
  training loss:		0.088444
  validation loss:		0.686583
  validation accuracy:		89.02 %
Epoch 1392 of 2000 took 0.103s
  training loss:		0.081052
  validation loss:		0.655191
  validation accuracy:		89.13 %
Epoch 1393 of 2000 took 0.103s
  training loss:		0.078589
  validation loss:		0.703316
  validation accuracy:		88.37 %
Epoch 1394 of 2000 took 0.103s
  training loss:		0.081305
  validation loss:		0.724535
  validation accuracy:		88.15 %
Epoch 1395 of 2000 took 0.103s
  training loss:		0.081059
  validation loss:		0.625218
  validation accuracy:		89.13 %
Epoch 1396 of 2000 took 0.103s
  training loss:		0.082079
  validation loss:		0.651301
  validation accuracy:		89.57 %
Epoch 1397 of 2000 took 0.103s
  training loss:		0.089921
  validation loss:		0.629551
  validation accuracy:		89.67 %
Epoch 1398 of 2000 took 0.104s
  training loss:		0.088602
  validation loss:		0.762685
  validation accuracy:		87.39 %
Epoch 1399 of 2000 took 0.103s
  training loss:		0.107581
  validation loss:		0.642593
  validation accuracy:		88.91 %
Epoch 1400 of 2000 took 0.103s
  training loss:		0.097823
  validation loss:		0.618532
  validation accuracy:		89.35 %
Epoch 1401 of 2000 took 0.103s
  training loss:		0.096671
  validation loss:		0.641239
  validation accuracy:		89.46 %
Epoch 1402 of 2000 took 0.103s
  training loss:		0.073729
  validation loss:		0.681852
  validation accuracy:		88.70 %
Epoch 1403 of 2000 took 0.103s
  training loss:		0.077210
  validation loss:		0.647257
  validation accuracy:		88.80 %
Epoch 1404 of 2000 took 0.103s
  training loss:		0.082738
  validation loss:		0.688805
  validation accuracy:		88.26 %
Epoch 1405 of 2000 took 0.103s
  training loss:		0.080527
  validation loss:		0.638667
  validation accuracy:		89.57 %
Epoch 1406 of 2000 took 0.103s
  training loss:		0.078391
  validation loss:		0.649411
  validation accuracy:		89.57 %
Epoch 1407 of 2000 took 0.103s
  training loss:		0.094850
  validation loss:		0.641643
  validation accuracy:		89.24 %
Epoch 1408 of 2000 took 0.103s
  training loss:		0.079072
  validation loss:		0.691114
  validation accuracy:		88.15 %
Epoch 1409 of 2000 took 0.103s
  training loss:		0.081051
  validation loss:		0.677294
  validation accuracy:		88.80 %
Epoch 1410 of 2000 took 0.103s
  training loss:		0.099394
  validation loss:		0.661767
  validation accuracy:		88.91 %
Epoch 1411 of 2000 took 0.103s
  training loss:		0.078521
  validation loss:		0.660880
  validation accuracy:		89.46 %
Epoch 1412 of 2000 took 0.103s
  training loss:		0.078947
  validation loss:		0.674520
  validation accuracy:		88.80 %
Epoch 1413 of 2000 took 0.103s
  training loss:		0.080930
  validation loss:		0.638528
  validation accuracy:		89.24 %
Epoch 1414 of 2000 took 0.103s
  training loss:		0.077545
  validation loss:		0.648730
  validation accuracy:		89.46 %
Epoch 1415 of 2000 took 0.103s
  training loss:		0.073523
  validation loss:		0.645422
  validation accuracy:		88.91 %
Epoch 1416 of 2000 took 0.103s
  training loss:		0.076663
  validation loss:		0.665522
  validation accuracy:		89.24 %
Epoch 1417 of 2000 took 0.103s
  training loss:		0.076170
  validation loss:		0.681053
  validation accuracy:		88.70 %
Epoch 1418 of 2000 took 0.103s
  training loss:		0.078474
  validation loss:		0.662077
  validation accuracy:		88.91 %
Epoch 1419 of 2000 took 0.103s
  training loss:		0.078102
  validation loss:		0.642621
  validation accuracy:		89.24 %
Epoch 1420 of 2000 took 0.103s
  training loss:		0.073363
  validation loss:		0.664893
  validation accuracy:		88.70 %
Epoch 1421 of 2000 took 0.103s
  training loss:		0.075582
  validation loss:		0.670494
  validation accuracy:		89.13 %
Epoch 1422 of 2000 took 0.103s
  training loss:		0.094715
  validation loss:		0.682444
  validation accuracy:		88.91 %
Epoch 1423 of 2000 took 0.103s
  training loss:		0.075084
  validation loss:		0.680120
  validation accuracy:		88.48 %
Epoch 1424 of 2000 took 0.103s
  training loss:		0.085341
  validation loss:		0.699106
  validation accuracy:		88.48 %
Epoch 1425 of 2000 took 0.103s
  training loss:		0.077554
  validation loss:		0.632816
  validation accuracy:		89.35 %
Epoch 1426 of 2000 took 0.103s
  training loss:		0.076254
  validation loss:		0.664000
  validation accuracy:		88.80 %
Epoch 1427 of 2000 took 0.104s
  training loss:		0.084627
  validation loss:		0.719626
  validation accuracy:		88.37 %
Epoch 1428 of 2000 took 0.103s
  training loss:		0.103248
  validation loss:		0.678129
  validation accuracy:		88.91 %
Epoch 1429 of 2000 took 0.103s
  training loss:		0.083059
  validation loss:		0.675678
  validation accuracy:		88.70 %
Epoch 1430 of 2000 took 0.103s
  training loss:		0.075647
  validation loss:		0.677589
  validation accuracy:		88.80 %
Epoch 1431 of 2000 took 0.103s
  training loss:		0.085108
  validation loss:		0.692230
  validation accuracy:		88.37 %
Epoch 1432 of 2000 took 0.103s
  training loss:		0.080452
  validation loss:		0.722293
  validation accuracy:		87.93 %
Epoch 1433 of 2000 took 0.103s
  training loss:		0.080783
  validation loss:		0.675773
  validation accuracy:		89.02 %
Epoch 1434 of 2000 took 0.103s
  training loss:		0.080886
  validation loss:		0.680793
  validation accuracy:		88.91 %
Epoch 1435 of 2000 took 0.103s
  training loss:		0.080089
  validation loss:		0.683385
  validation accuracy:		89.02 %
Epoch 1436 of 2000 took 0.103s
  training loss:		0.080667
  validation loss:		0.666466
  validation accuracy:		89.02 %
Epoch 1437 of 2000 took 0.103s
  training loss:		0.076754
  validation loss:		0.684201
  validation accuracy:		88.48 %
Epoch 1438 of 2000 took 0.103s
  training loss:		0.074408
  validation loss:		0.680997
  validation accuracy:		88.80 %
Epoch 1439 of 2000 took 0.103s
  training loss:		0.076601
  validation loss:		0.695038
  validation accuracy:		89.02 %
Epoch 1440 of 2000 took 0.104s
  training loss:		0.080650
  validation loss:		0.676146
  validation accuracy:		89.02 %
Epoch 1441 of 2000 took 0.103s
  training loss:		0.084851
  validation loss:		0.724877
  validation accuracy:		88.26 %
Epoch 1442 of 2000 took 0.103s
  training loss:		0.075089
  validation loss:		0.663270
  validation accuracy:		88.91 %
Epoch 1443 of 2000 took 0.103s
  training loss:		0.094541
  validation loss:		0.676194
  validation accuracy:		89.13 %
Epoch 1444 of 2000 took 0.103s
  training loss:		0.076334
  validation loss:		0.672274
  validation accuracy:		89.24 %
Epoch 1445 of 2000 took 0.103s
  training loss:		0.088207
  validation loss:		0.686293
  validation accuracy:		89.02 %
Epoch 1446 of 2000 took 0.103s
  training loss:		0.079255
  validation loss:		0.678743
  validation accuracy:		88.91 %
Epoch 1447 of 2000 took 0.103s
  training loss:		0.081809
  validation loss:		0.727082
  validation accuracy:		87.93 %
Epoch 1448 of 2000 took 0.103s
  training loss:		0.075317
  validation loss:		0.686089
  validation accuracy:		88.70 %
Epoch 1449 of 2000 took 0.103s
  training loss:		0.099479
  validation loss:		0.736232
  validation accuracy:		88.48 %
Epoch 1450 of 2000 took 0.103s
  training loss:		0.086286
  validation loss:		0.699421
  validation accuracy:		89.02 %
Epoch 1451 of 2000 took 0.103s
  training loss:		0.080120
  validation loss:		0.722248
  validation accuracy:		88.48 %
Epoch 1452 of 2000 took 0.103s
  training loss:		0.081567
  validation loss:		0.690484
  validation accuracy:		88.70 %
Epoch 1453 of 2000 took 0.103s
  training loss:		0.081870
  validation loss:		0.640114
  validation accuracy:		89.13 %
Epoch 1454 of 2000 took 0.103s
  training loss:		0.079344
  validation loss:		0.682427
  validation accuracy:		89.02 %
Epoch 1455 of 2000 took 0.102s
  training loss:		0.076354
  validation loss:		0.680254
  validation accuracy:		88.59 %
Epoch 1456 of 2000 took 0.103s
  training loss:		0.080449
  validation loss:		0.709843
  validation accuracy:		88.26 %
Epoch 1457 of 2000 took 0.104s
  training loss:		0.109701
  validation loss:		0.677016
  validation accuracy:		88.91 %
Epoch 1458 of 2000 took 0.103s
  training loss:		0.082693
  validation loss:		0.678334
  validation accuracy:		88.91 %
Epoch 1459 of 2000 took 0.103s
  training loss:		0.080791
  validation loss:		0.664431
  validation accuracy:		89.13 %
Epoch 1460 of 2000 took 0.103s
  training loss:		0.075540
  validation loss:		0.668305
  validation accuracy:		89.46 %
Epoch 1461 of 2000 took 0.103s
  training loss:		0.074744
  validation loss:		0.691266
  validation accuracy:		89.24 %
Epoch 1462 of 2000 took 0.103s
  training loss:		0.079660
  validation loss:		0.660885
  validation accuracy:		89.35 %
Epoch 1463 of 2000 took 0.103s
  training loss:		0.077962
  validation loss:		0.666137
  validation accuracy:		89.13 %
Epoch 1464 of 2000 took 0.103s
  training loss:		0.076636
  validation loss:		0.689037
  validation accuracy:		88.91 %
Epoch 1465 of 2000 took 0.103s
  training loss:		0.073602
  validation loss:		0.726866
  validation accuracy:		88.15 %
Epoch 1466 of 2000 took 0.103s
  training loss:		0.083235
  validation loss:		0.666954
  validation accuracy:		89.24 %
Epoch 1467 of 2000 took 0.103s
  training loss:		0.075663
  validation loss:		0.731403
  validation accuracy:		88.59 %
Epoch 1468 of 2000 took 0.103s
  training loss:		0.077582
  validation loss:		0.707446
  validation accuracy:		88.80 %
Epoch 1469 of 2000 took 0.103s
  training loss:		0.090360
  validation loss:		0.745501
  validation accuracy:		87.83 %
Epoch 1470 of 2000 took 0.103s
  training loss:		0.075304
  validation loss:		0.686798
  validation accuracy:		88.91 %
Epoch 1471 of 2000 took 0.103s
  training loss:		0.073711
  validation loss:		0.730778
  validation accuracy:		88.70 %
Epoch 1472 of 2000 took 0.103s
  training loss:		0.085590
  validation loss:		0.696353
  validation accuracy:		88.70 %
Epoch 1473 of 2000 took 0.103s
  training loss:		0.077234
  validation loss:		0.692105
  validation accuracy:		89.13 %
Epoch 1474 of 2000 took 0.103s
  training loss:		0.079336
  validation loss:		0.734843
  validation accuracy:		87.83 %
Epoch 1475 of 2000 took 0.103s
  training loss:		0.090986
  validation loss:		0.738334
  validation accuracy:		88.59 %
Epoch 1476 of 2000 took 0.103s
  training loss:		0.076800
  validation loss:		0.705405
  validation accuracy:		89.02 %
Epoch 1477 of 2000 took 0.103s
  training loss:		0.077053
  validation loss:		0.693473
  validation accuracy:		89.02 %
Epoch 1478 of 2000 took 0.103s
  training loss:		0.075556
  validation loss:		0.831973
  validation accuracy:		86.96 %
Epoch 1479 of 2000 took 0.103s
  training loss:		0.085493
  validation loss:		0.719412
  validation accuracy:		88.37 %
Epoch 1480 of 2000 took 0.103s
  training loss:		0.073644
  validation loss:		0.695970
  validation accuracy:		88.59 %
Epoch 1481 of 2000 took 0.103s
  training loss:		0.079184
  validation loss:		0.680158
  validation accuracy:		89.13 %
Epoch 1482 of 2000 took 0.103s
  training loss:		0.082939
  validation loss:		0.678145
  validation accuracy:		89.13 %
Epoch 1483 of 2000 took 0.103s
  training loss:		0.091435
  validation loss:		0.727421
  validation accuracy:		88.48 %
Epoch 1484 of 2000 took 0.103s
  training loss:		0.087190
  validation loss:		0.714532
  validation accuracy:		88.37 %
Epoch 1485 of 2000 took 0.103s
  training loss:		0.087456
  validation loss:		0.682769
  validation accuracy:		89.13 %
Epoch 1486 of 2000 took 0.104s
  training loss:		0.079650
  validation loss:		0.717126
  validation accuracy:		88.70 %
Epoch 1487 of 2000 took 0.103s
  training loss:		0.074819
  validation loss:		0.683561
  validation accuracy:		89.02 %
Epoch 1488 of 2000 took 0.103s
  training loss:		0.076859
  validation loss:		0.721480
  validation accuracy:		88.48 %
Epoch 1489 of 2000 took 0.103s
  training loss:		0.074558
  validation loss:		0.711424
  validation accuracy:		88.48 %
Epoch 1490 of 2000 took 0.103s
  training loss:		0.083290
  validation loss:		0.722694
  validation accuracy:		88.15 %
Epoch 1491 of 2000 took 0.103s
  training loss:		0.097311
  validation loss:		0.736661
  validation accuracy:		88.59 %
Epoch 1492 of 2000 took 0.103s
  training loss:		0.079768
  validation loss:		0.750836
  validation accuracy:		88.37 %
Epoch 1493 of 2000 took 0.103s
  training loss:		0.073096
  validation loss:		0.741490
  validation accuracy:		88.04 %
Epoch 1494 of 2000 took 0.103s
  training loss:		0.070926
  validation loss:		0.716149
  validation accuracy:		88.37 %
Epoch 1495 of 2000 took 0.103s
  training loss:		0.074698
  validation loss:		0.738694
  validation accuracy:		88.48 %
Epoch 1496 of 2000 took 0.103s
  training loss:		0.078083
  validation loss:		0.717375
  validation accuracy:		88.59 %
Epoch 1497 of 2000 took 0.103s
  training loss:		0.078180
  validation loss:		0.776458
  validation accuracy:		87.93 %
Epoch 1498 of 2000 took 0.103s
  training loss:		0.080940
  validation loss:		0.706275
  validation accuracy:		88.80 %
Epoch 1499 of 2000 took 0.103s
  training loss:		0.075930
  validation loss:		0.739502
  validation accuracy:		88.80 %
Epoch 1500 of 2000 took 0.103s
  training loss:		0.083113
  validation loss:		0.694667
  validation accuracy:		88.80 %
Epoch 1501 of 2000 took 0.103s
  training loss:		0.084873
  validation loss:		0.728417
  validation accuracy:		88.59 %
Epoch 1502 of 2000 took 0.103s
  training loss:		0.080537
  validation loss:		0.775176
  validation accuracy:		87.83 %
Epoch 1503 of 2000 took 0.103s
  training loss:		0.080530
  validation loss:		0.706363
  validation accuracy:		88.59 %
Epoch 1504 of 2000 took 0.103s
  training loss:		0.078849
  validation loss:		0.721532
  validation accuracy:		88.48 %
Epoch 1505 of 2000 took 0.103s
  training loss:		0.078245
  validation loss:		0.682118
  validation accuracy:		89.13 %
Epoch 1506 of 2000 took 0.103s
  training loss:		0.085076
  validation loss:		0.698789
  validation accuracy:		89.02 %
Epoch 1507 of 2000 took 0.103s
  training loss:		0.075335
  validation loss:		0.710638
  validation accuracy:		89.02 %
Epoch 1508 of 2000 took 0.103s
  training loss:		0.083617
  validation loss:		0.695285
  validation accuracy:		89.02 %
Epoch 1509 of 2000 took 0.103s
  training loss:		0.069599
  validation loss:		0.756369
  validation accuracy:		88.26 %
Epoch 1510 of 2000 took 0.103s
  training loss:		0.084509
  validation loss:		0.687679
  validation accuracy:		88.70 %
Epoch 1511 of 2000 took 0.103s
  training loss:		0.073072
  validation loss:		0.677251
  validation accuracy:		89.13 %
Epoch 1512 of 2000 took 0.103s
  training loss:		0.069940
  validation loss:		0.699628
  validation accuracy:		88.91 %
Epoch 1513 of 2000 took 0.103s
  training loss:		0.069988
  validation loss:		0.765999
  validation accuracy:		88.04 %
Epoch 1514 of 2000 took 0.103s
  training loss:		0.075064
  validation loss:		0.696510
  validation accuracy:		89.46 %
Epoch 1515 of 2000 took 0.104s
  training loss:		0.080414
  validation loss:		0.714128
  validation accuracy:		89.13 %
Epoch 1516 of 2000 took 0.103s
  training loss:		0.080341
  validation loss:		0.710043
  validation accuracy:		88.80 %
Epoch 1517 of 2000 took 0.103s
  training loss:		0.072598
  validation loss:		0.732894
  validation accuracy:		88.48 %
Epoch 1518 of 2000 took 0.103s
  training loss:		0.075698
  validation loss:		0.708491
  validation accuracy:		89.13 %
Epoch 1519 of 2000 took 0.103s
  training loss:		0.075325
  validation loss:		0.690363
  validation accuracy:		89.13 %
Epoch 1520 of 2000 took 0.103s
  training loss:		0.069639
  validation loss:		0.715817
  validation accuracy:		88.26 %
Epoch 1521 of 2000 took 0.103s
  training loss:		0.073928
  validation loss:		0.723297
  validation accuracy:		89.35 %
Epoch 1522 of 2000 took 0.103s
  training loss:		0.068758
  validation loss:		0.736848
  validation accuracy:		88.37 %
Epoch 1523 of 2000 took 0.103s
  training loss:		0.077481
  validation loss:		0.694744
  validation accuracy:		89.46 %
Epoch 1524 of 2000 took 0.103s
  training loss:		0.074786
  validation loss:		0.715509
  validation accuracy:		89.13 %
Epoch 1525 of 2000 took 0.103s
  training loss:		0.073707
  validation loss:		0.763611
  validation accuracy:		88.37 %
Epoch 1526 of 2000 took 0.103s
  training loss:		0.067806
  validation loss:		0.700107
  validation accuracy:		89.13 %
Epoch 1527 of 2000 took 0.103s
  training loss:		0.081792
  validation loss:		0.798099
  validation accuracy:		88.26 %
Epoch 1528 of 2000 took 0.103s
  training loss:		0.084266
  validation loss:		0.727747
  validation accuracy:		88.91 %
Epoch 1529 of 2000 took 0.103s
  training loss:		0.074958
  validation loss:		0.740231
  validation accuracy:		89.02 %
Epoch 1530 of 2000 took 0.103s
  training loss:		0.086847
  validation loss:		0.731063
  validation accuracy:		88.80 %
Epoch 1531 of 2000 took 0.103s
  training loss:		0.075902
  validation loss:		0.706833
  validation accuracy:		89.02 %
Epoch 1532 of 2000 took 0.103s
  training loss:		0.081920
  validation loss:		0.712589
  validation accuracy:		89.13 %
Epoch 1533 of 2000 took 0.103s
  training loss:		0.071654
  validation loss:		0.697262
  validation accuracy:		89.57 %
Epoch 1534 of 2000 took 0.103s
  training loss:		0.118308
  validation loss:		0.731763
  validation accuracy:		88.70 %
Epoch 1535 of 2000 took 0.103s
  training loss:		0.076717
  validation loss:		0.731409
  validation accuracy:		88.70 %
Epoch 1536 of 2000 took 0.103s
  training loss:		0.070092
  validation loss:		0.706701
  validation accuracy:		89.35 %
Epoch 1537 of 2000 took 0.103s
  training loss:		0.072476
  validation loss:		0.741528
  validation accuracy:		88.70 %
Epoch 1538 of 2000 took 0.104s
  training loss:		0.073458
  validation loss:		0.741337
  validation accuracy:		88.37 %
Epoch 1539 of 2000 took 0.103s
  training loss:		0.072359
  validation loss:		0.722936
  validation accuracy:		88.48 %
Epoch 1540 of 2000 took 0.103s
  training loss:		0.072657
  validation loss:		0.688891
  validation accuracy:		89.13 %
Epoch 1541 of 2000 took 0.103s
  training loss:		0.071413
  validation loss:		0.736103
  validation accuracy:		88.80 %
Epoch 1542 of 2000 took 0.103s
  training loss:		0.075493
  validation loss:		0.756387
  validation accuracy:		88.15 %
Epoch 1543 of 2000 took 0.103s
  training loss:		0.074168
  validation loss:		0.783070
  validation accuracy:		88.15 %
Epoch 1544 of 2000 took 0.103s
  training loss:		0.092161
  validation loss:		0.773915
  validation accuracy:		88.15 %
Epoch 1545 of 2000 took 0.103s
  training loss:		0.078588
  validation loss:		0.733757
  validation accuracy:		88.80 %
Epoch 1546 of 2000 took 0.103s
  training loss:		0.072052
  validation loss:		0.715650
  validation accuracy:		88.80 %
Epoch 1547 of 2000 took 0.106s
  training loss:		0.071999
  validation loss:		0.759754
  validation accuracy:		88.26 %
Epoch 1548 of 2000 took 0.103s
  training loss:		0.085723
  validation loss:		0.695034
  validation accuracy:		89.89 %
Epoch 1549 of 2000 took 0.103s
  training loss:		0.071907
  validation loss:		0.740831
  validation accuracy:		88.37 %
Epoch 1550 of 2000 took 0.103s
  training loss:		0.067846
  validation loss:		0.733840
  validation accuracy:		88.80 %
Epoch 1551 of 2000 took 0.103s
  training loss:		0.084602
  validation loss:		0.692313
  validation accuracy:		89.35 %
Epoch 1552 of 2000 took 0.103s
  training loss:		0.069695
  validation loss:		0.727069
  validation accuracy:		88.70 %
Epoch 1553 of 2000 took 0.103s
  training loss:		0.073879
  validation loss:		0.747585
  validation accuracy:		88.37 %
Epoch 1554 of 2000 took 0.103s
  training loss:		0.073414
  validation loss:		0.772173
  validation accuracy:		87.50 %
Epoch 1555 of 2000 took 0.103s
  training loss:		0.080023
  validation loss:		0.735375
  validation accuracy:		88.91 %
Epoch 1556 of 2000 took 0.103s
  training loss:		0.069601
  validation loss:		0.783376
  validation accuracy:		88.04 %
Epoch 1557 of 2000 took 0.103s
  training loss:		0.071439
  validation loss:		0.736299
  validation accuracy:		88.70 %
Epoch 1558 of 2000 took 0.103s
  training loss:		0.075476
  validation loss:		0.706209
  validation accuracy:		88.80 %
Epoch 1559 of 2000 took 0.103s
  training loss:		0.067876
  validation loss:		0.767171
  validation accuracy:		88.04 %
Epoch 1560 of 2000 took 0.103s
  training loss:		0.075043
  validation loss:		0.724483
  validation accuracy:		89.13 %
Epoch 1561 of 2000 took 0.103s
  training loss:		0.075299
  validation loss:		0.754868
  validation accuracy:		88.70 %
Epoch 1562 of 2000 took 0.103s
  training loss:		0.073088
  validation loss:		0.723162
  validation accuracy:		88.59 %
Epoch 1563 of 2000 took 0.103s
  training loss:		0.072806
  validation loss:		0.729575
  validation accuracy:		88.70 %
Epoch 1564 of 2000 took 0.103s
  training loss:		0.069367
  validation loss:		0.761076
  validation accuracy:		88.48 %
Epoch 1565 of 2000 took 0.103s
  training loss:		0.088732
  validation loss:		0.743203
  validation accuracy:		89.02 %
Epoch 1566 of 2000 took 0.103s
  training loss:		0.070853
  validation loss:		0.727365
  validation accuracy:		89.13 %
Epoch 1567 of 2000 took 0.103s
  training loss:		0.070956
  validation loss:		0.737697
  validation accuracy:		88.91 %
Epoch 1568 of 2000 took 0.103s
  training loss:		0.071554
  validation loss:		0.728388
  validation accuracy:		89.24 %
Epoch 1569 of 2000 took 0.103s
  training loss:		0.093969
  validation loss:		0.800200
  validation accuracy:		87.93 %
Epoch 1570 of 2000 took 0.103s
  training loss:		0.073830
  validation loss:		0.702106
  validation accuracy:		89.24 %
Epoch 1571 of 2000 took 0.103s
  training loss:		0.072263
  validation loss:		0.745281
  validation accuracy:		88.70 %
Epoch 1572 of 2000 took 0.103s
  training loss:		0.068851
  validation loss:		0.737781
  validation accuracy:		88.91 %
Epoch 1573 of 2000 took 0.103s
  training loss:		0.080356
  validation loss:		0.767541
  validation accuracy:		88.37 %
Epoch 1574 of 2000 took 0.103s
  training loss:		0.079822
  validation loss:		0.792131
  validation accuracy:		88.15 %
Epoch 1575 of 2000 took 0.103s
  training loss:		0.072510
  validation loss:		0.765091
  validation accuracy:		88.48 %
Epoch 1576 of 2000 took 0.103s
  training loss:		0.085028
  validation loss:		0.807036
  validation accuracy:		88.15 %
Epoch 1577 of 2000 took 0.103s
  training loss:		0.070813
  validation loss:		0.758528
  validation accuracy:		88.59 %
Epoch 1578 of 2000 took 0.103s
  training loss:		0.074036
  validation loss:		0.751922
  validation accuracy:		88.59 %
Epoch 1579 of 2000 took 0.103s
  training loss:		0.065428
  validation loss:		0.727360
  validation accuracy:		88.80 %
Epoch 1580 of 2000 took 0.103s
  training loss:		0.083606
  validation loss:		0.757625
  validation accuracy:		88.80 %
Epoch 1581 of 2000 took 0.103s
  training loss:		0.071190
  validation loss:		0.766265
  validation accuracy:		89.02 %
Epoch 1582 of 2000 took 0.103s
  training loss:		0.089917
  validation loss:		0.810749
  validation accuracy:		87.50 %
Epoch 1583 of 2000 took 0.103s
  training loss:		0.075791
  validation loss:		0.744501
  validation accuracy:		88.91 %
Epoch 1584 of 2000 took 0.103s
  training loss:		0.076247
  validation loss:		0.756527
  validation accuracy:		88.91 %
Epoch 1585 of 2000 took 0.103s
  training loss:		0.078266
  validation loss:		0.743059
  validation accuracy:		88.59 %
Epoch 1586 of 2000 took 0.103s
  training loss:		0.074318
  validation loss:		0.736165
  validation accuracy:		89.02 %
Epoch 1587 of 2000 took 0.103s
  training loss:		0.069288
  validation loss:		0.751998
  validation accuracy:		88.80 %
Epoch 1588 of 2000 took 0.108s
  training loss:		0.066434
  validation loss:		0.763580
  validation accuracy:		88.80 %
Epoch 1589 of 2000 took 0.109s
  training loss:		0.067550
  validation loss:		0.747259
  validation accuracy:		89.02 %
Epoch 1590 of 2000 took 0.110s
  training loss:		0.070529
  validation loss:		0.786766
  validation accuracy:		87.93 %
Epoch 1591 of 2000 took 0.110s
  training loss:		0.078572
  validation loss:		0.782387
  validation accuracy:		88.48 %
Epoch 1592 of 2000 took 0.109s
  training loss:		0.077572
  validation loss:		0.768174
  validation accuracy:		88.59 %
Epoch 1593 of 2000 took 0.104s
  training loss:		0.067434
  validation loss:		0.757538
  validation accuracy:		88.70 %
Epoch 1594 of 2000 took 0.107s
  training loss:		0.068416
  validation loss:		0.799598
  validation accuracy:		88.15 %
Epoch 1595 of 2000 took 0.110s
  training loss:		0.082682
  validation loss:		0.763579
  validation accuracy:		88.37 %
Epoch 1596 of 2000 took 0.134s
  training loss:		0.076775
  validation loss:		0.751062
  validation accuracy:		88.91 %
Epoch 1597 of 2000 took 0.118s
  training loss:		0.063046
  validation loss:		0.736248
  validation accuracy:		89.02 %
Epoch 1598 of 2000 took 0.101s
  training loss:		0.068395
  validation loss:		0.726393
  validation accuracy:		89.24 %
Epoch 1599 of 2000 took 0.104s
  training loss:		0.069951
  validation loss:		0.743014
  validation accuracy:		88.91 %
Epoch 1600 of 2000 took 0.112s
  training loss:		0.069914
  validation loss:		0.727028
  validation accuracy:		89.35 %
Epoch 1601 of 2000 took 0.121s
  training loss:		0.072735
  validation loss:		0.753314
  validation accuracy:		88.91 %
Epoch 1602 of 2000 took 0.104s
  training loss:		0.063494
  validation loss:		0.774202
  validation accuracy:		88.48 %
Epoch 1603 of 2000 took 0.102s
  training loss:		0.067381
  validation loss:		0.749171
  validation accuracy:		88.80 %
Epoch 1604 of 2000 took 0.101s
  training loss:		0.077347
  validation loss:		0.767660
  validation accuracy:		88.59 %
Epoch 1605 of 2000 took 0.100s
  training loss:		0.098157
  validation loss:		0.841552
  validation accuracy:		88.15 %
Epoch 1606 of 2000 took 0.100s
  training loss:		0.077475
  validation loss:		0.748534
  validation accuracy:		88.80 %
Epoch 1607 of 2000 took 0.101s
  training loss:		0.068791
  validation loss:		0.762249
  validation accuracy:		89.02 %
Epoch 1608 of 2000 took 0.100s
  training loss:		0.068587
  validation loss:		0.759019
  validation accuracy:		89.35 %
Epoch 1609 of 2000 took 0.101s
  training loss:		0.074202
  validation loss:		0.722823
  validation accuracy:		89.24 %
Epoch 1610 of 2000 took 0.101s
  training loss:		0.070695
  validation loss:		0.731844
  validation accuracy:		89.67 %
Epoch 1611 of 2000 took 0.102s
  training loss:		0.075790
  validation loss:		0.783442
  validation accuracy:		88.59 %
Epoch 1612 of 2000 took 0.101s
  training loss:		0.072642
  validation loss:		0.742713
  validation accuracy:		89.02 %
Epoch 1613 of 2000 took 0.101s
  training loss:		0.070876
  validation loss:		0.745007
  validation accuracy:		89.13 %
Epoch 1614 of 2000 took 0.101s
  training loss:		0.064518
  validation loss:		0.766395
  validation accuracy:		88.70 %
Epoch 1615 of 2000 took 0.100s
  training loss:		0.064946
  validation loss:		0.759998
  validation accuracy:		88.26 %
Epoch 1616 of 2000 took 0.101s
  training loss:		0.067873
  validation loss:		0.805673
  validation accuracy:		88.37 %
Epoch 1617 of 2000 took 0.100s
  training loss:		0.066695
  validation loss:		0.763140
  validation accuracy:		88.48 %
Epoch 1618 of 2000 took 0.100s
  training loss:		0.075107
  validation loss:		0.720476
  validation accuracy:		89.78 %
Epoch 1619 of 2000 took 0.101s
  training loss:		0.082419
  validation loss:		0.788288
  validation accuracy:		88.48 %
Epoch 1620 of 2000 took 0.100s
  training loss:		0.083190
  validation loss:		0.817023
  validation accuracy:		87.83 %
Epoch 1621 of 2000 took 0.101s
  training loss:		0.069422
  validation loss:		0.779424
  validation accuracy:		88.91 %
Epoch 1622 of 2000 took 0.100s
  training loss:		0.067554
  validation loss:		0.752267
  validation accuracy:		89.02 %
Epoch 1623 of 2000 took 0.101s
  training loss:		0.107008
  validation loss:		0.752454
  validation accuracy:		89.35 %
Epoch 1624 of 2000 took 0.101s
  training loss:		0.123551
  validation loss:		0.760148
  validation accuracy:		88.80 %
Epoch 1625 of 2000 took 0.100s
  training loss:		0.061146
  validation loss:		0.772243
  validation accuracy:		88.48 %
Epoch 1626 of 2000 took 0.101s
  training loss:		0.114868
  validation loss:		0.753177
  validation accuracy:		89.24 %
Epoch 1627 of 2000 took 0.100s
  training loss:		0.080604
  validation loss:		0.770855
  validation accuracy:		88.48 %
Epoch 1628 of 2000 took 0.101s
  training loss:		0.068614
  validation loss:		0.788096
  validation accuracy:		88.26 %
Epoch 1629 of 2000 took 0.101s
  training loss:		0.072507
  validation loss:		0.749312
  validation accuracy:		88.91 %
Epoch 1630 of 2000 took 0.101s
  training loss:		0.070824
  validation loss:		0.761286
  validation accuracy:		89.02 %
Epoch 1631 of 2000 took 0.100s
  training loss:		0.069263
  validation loss:		0.795138
  validation accuracy:		88.48 %
Epoch 1632 of 2000 took 0.102s
  training loss:		0.070065
  validation loss:		0.763295
  validation accuracy:		88.80 %
Epoch 1633 of 2000 took 0.101s
  training loss:		0.074847
  validation loss:		0.778531
  validation accuracy:		88.91 %
Epoch 1634 of 2000 took 0.102s
  training loss:		0.061184
  validation loss:		0.766764
  validation accuracy:		89.02 %
Epoch 1635 of 2000 took 0.102s
  training loss:		0.065880
  validation loss:		0.760059
  validation accuracy:		88.91 %
Epoch 1636 of 2000 took 0.134s
  training loss:		0.061473
  validation loss:		0.775431
  validation accuracy:		88.80 %
Epoch 1637 of 2000 took 0.167s
  training loss:		0.066364
  validation loss:		0.768886
  validation accuracy:		89.57 %
Epoch 1638 of 2000 took 0.167s
  training loss:		0.068014
  validation loss:		0.765274
  validation accuracy:		89.02 %
Epoch 1639 of 2000 took 0.167s
  training loss:		0.073643
  validation loss:		0.763125
  validation accuracy:		88.70 %
Epoch 1640 of 2000 took 0.167s
  training loss:		0.075265
  validation loss:		0.729838
  validation accuracy:		89.13 %
Epoch 1641 of 2000 took 0.167s
  training loss:		0.069973
  validation loss:		0.765164
  validation accuracy:		88.80 %
Epoch 1642 of 2000 took 0.167s
  training loss:		0.069165
  validation loss:		0.753206
  validation accuracy:		89.35 %
Epoch 1643 of 2000 took 0.167s
  training loss:		0.063155
  validation loss:		0.789497
  validation accuracy:		88.59 %
Epoch 1644 of 2000 took 0.167s
  training loss:		0.069526
  validation loss:		0.775559
  validation accuracy:		88.70 %
Epoch 1645 of 2000 took 0.167s
  training loss:		0.075789
  validation loss:		0.766523
  validation accuracy:		88.91 %
Epoch 1646 of 2000 took 0.167s
  training loss:		0.077834
  validation loss:		0.789365
  validation accuracy:		88.59 %
Epoch 1647 of 2000 took 0.167s
  training loss:		0.065666
  validation loss:		0.814287
  validation accuracy:		88.70 %
Epoch 1648 of 2000 took 0.167s
  training loss:		0.076835
  validation loss:		0.823421
  validation accuracy:		87.93 %
Epoch 1649 of 2000 took 0.167s
  training loss:		0.091720
  validation loss:		0.756164
  validation accuracy:		89.02 %
Epoch 1650 of 2000 took 0.167s
  training loss:		0.068823
  validation loss:		0.822955
  validation accuracy:		88.59 %
Epoch 1651 of 2000 took 0.167s
  training loss:		0.076696
  validation loss:		0.795426
  validation accuracy:		88.48 %
Epoch 1652 of 2000 took 0.124s
  training loss:		0.068834
  validation loss:		0.888755
  validation accuracy:		86.96 %
Epoch 1653 of 2000 took 0.101s
  training loss:		0.082108
  validation loss:		0.804506
  validation accuracy:		88.48 %
Epoch 1654 of 2000 took 0.105s
  training loss:		0.069331
  validation loss:		0.781354
  validation accuracy:		88.70 %
Epoch 1655 of 2000 took 0.105s
  training loss:		0.068123
  validation loss:		0.793682
  validation accuracy:		88.70 %
Epoch 1656 of 2000 took 0.111s
  training loss:		0.085499
  validation loss:		0.797478
  validation accuracy:		88.37 %
Epoch 1657 of 2000 took 0.107s
  training loss:		0.066018
  validation loss:		0.765220
  validation accuracy:		88.91 %
Epoch 1658 of 2000 took 0.101s
  training loss:		0.082949
  validation loss:		0.803653
  validation accuracy:		88.70 %
Epoch 1659 of 2000 took 0.100s
  training loss:		0.073547
  validation loss:		0.814265
  validation accuracy:		88.15 %
Epoch 1660 of 2000 took 0.106s
  training loss:		0.097217
  validation loss:		0.823849
  validation accuracy:		89.02 %
Epoch 1661 of 2000 took 0.098s
  training loss:		0.078603
  validation loss:		0.759678
  validation accuracy:		89.13 %
Epoch 1662 of 2000 took 0.097s
  training loss:		0.074982
  validation loss:		0.758087
  validation accuracy:		89.02 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.064951
  validation loss:		0.855453
  validation accuracy:		87.39 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.074026
  validation loss:		0.782660
  validation accuracy:		88.80 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.072608
  validation loss:		0.769142
  validation accuracy:		88.48 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.079898
  validation loss:		0.784004
  validation accuracy:		88.59 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.067284
  validation loss:		0.825203
  validation accuracy:		87.93 %
Epoch 1668 of 2000 took 0.103s
  training loss:		0.070105
  validation loss:		0.768012
  validation accuracy:		88.91 %
Epoch 1669 of 2000 took 0.101s
  training loss:		0.072297
  validation loss:		0.770446
  validation accuracy:		89.24 %
Epoch 1670 of 2000 took 0.099s
  training loss:		0.062664
  validation loss:		0.801791
  validation accuracy:		88.59 %
Epoch 1671 of 2000 took 0.100s
  training loss:		0.069580
  validation loss:		0.761897
  validation accuracy:		89.02 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.065192
  validation loss:		0.766023
  validation accuracy:		89.13 %
Epoch 1673 of 2000 took 0.097s
  training loss:		0.077096
  validation loss:		0.783870
  validation accuracy:		88.70 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.079129
  validation loss:		0.814713
  validation accuracy:		88.70 %
Epoch 1675 of 2000 took 0.097s
  training loss:		0.070036
  validation loss:		0.761203
  validation accuracy:		89.02 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.070790
  validation loss:		0.776410
  validation accuracy:		88.91 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.069122
  validation loss:		0.809248
  validation accuracy:		88.48 %
Epoch 1678 of 2000 took 0.097s
  training loss:		0.067606
  validation loss:		0.764136
  validation accuracy:		89.35 %
Epoch 1679 of 2000 took 0.097s
  training loss:		0.070815
  validation loss:		0.800004
  validation accuracy:		88.48 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.074214
  validation loss:		0.807469
  validation accuracy:		89.02 %
Epoch 1681 of 2000 took 0.097s
  training loss:		0.075541
  validation loss:		0.799787
  validation accuracy:		88.59 %
Epoch 1682 of 2000 took 0.098s
  training loss:		0.076305
  validation loss:		0.793306
  validation accuracy:		88.80 %
Epoch 1683 of 2000 took 0.097s
  training loss:		0.078311
  validation loss:		0.780485
  validation accuracy:		89.02 %
Epoch 1684 of 2000 took 0.097s
  training loss:		0.066815
  validation loss:		0.814119
  validation accuracy:		88.80 %
Epoch 1685 of 2000 took 0.097s
  training loss:		0.062663
  validation loss:		0.822662
  validation accuracy:		88.48 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.072732
  validation loss:		0.775662
  validation accuracy:		89.02 %
Epoch 1687 of 2000 took 0.097s
  training loss:		0.077896
  validation loss:		0.908444
  validation accuracy:		87.28 %
Epoch 1688 of 2000 took 0.097s
  training loss:		0.155100
  validation loss:		0.806215
  validation accuracy:		88.59 %
Epoch 1689 of 2000 took 0.097s
  training loss:		0.163824
  validation loss:		0.778970
  validation accuracy:		89.02 %
Epoch 1690 of 2000 took 0.097s
  training loss:		0.070845
  validation loss:		0.774313
  validation accuracy:		88.80 %
Epoch 1691 of 2000 took 0.097s
  training loss:		0.063978
  validation loss:		0.743015
  validation accuracy:		89.57 %
Epoch 1692 of 2000 took 0.097s
  training loss:		0.067759
  validation loss:		0.739613
  validation accuracy:		89.57 %
Epoch 1693 of 2000 took 0.097s
  training loss:		0.075853
  validation loss:		0.798185
  validation accuracy:		88.59 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.076901
  validation loss:		0.763545
  validation accuracy:		89.02 %
Epoch 1695 of 2000 took 0.097s
  training loss:		0.065165
  validation loss:		0.784310
  validation accuracy:		88.91 %
Epoch 1696 of 2000 took 0.097s
  training loss:		0.064308
  validation loss:		0.789521
  validation accuracy:		88.80 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.073773
  validation loss:		0.796785
  validation accuracy:		88.48 %
Epoch 1698 of 2000 took 0.097s
  training loss:		0.067825
  validation loss:		0.790407
  validation accuracy:		88.91 %
Epoch 1699 of 2000 took 0.097s
  training loss:		0.072264
  validation loss:		0.763301
  validation accuracy:		89.24 %
Epoch 1700 of 2000 took 0.097s
  training loss:		0.060804
  validation loss:		0.780276
  validation accuracy:		89.02 %
Epoch 1701 of 2000 took 0.097s
  training loss:		0.074946
  validation loss:		0.800876
  validation accuracy:		88.59 %
Epoch 1702 of 2000 took 0.097s
  training loss:		0.066697
  validation loss:		0.823649
  validation accuracy:		88.48 %
Epoch 1703 of 2000 took 0.097s
  training loss:		0.064526
  validation loss:		0.768156
  validation accuracy:		88.91 %
Epoch 1704 of 2000 took 0.097s
  training loss:		0.059241
  validation loss:		0.783907
  validation accuracy:		89.13 %
Epoch 1705 of 2000 took 0.097s
  training loss:		0.066039
  validation loss:		0.803228
  validation accuracy:		88.70 %
Epoch 1706 of 2000 took 0.097s
  training loss:		0.065968
  validation loss:		0.778699
  validation accuracy:		88.91 %
Epoch 1707 of 2000 took 0.097s
  training loss:		0.070620
  validation loss:		0.783494
  validation accuracy:		88.59 %
Epoch 1708 of 2000 took 0.097s
  training loss:		0.080962
  validation loss:		0.771680
  validation accuracy:		89.02 %
Epoch 1709 of 2000 took 0.097s
  training loss:		0.063318
  validation loss:		0.769624
  validation accuracy:		88.91 %
Epoch 1710 of 2000 took 0.097s
  training loss:		0.062210
  validation loss:		0.782078
  validation accuracy:		88.80 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.067496
  validation loss:		0.789505
  validation accuracy:		88.91 %
Epoch 1712 of 2000 took 0.097s
  training loss:		0.060268
  validation loss:		0.767725
  validation accuracy:		89.35 %
Epoch 1713 of 2000 took 0.097s
  training loss:		0.067617
  validation loss:		0.838085
  validation accuracy:		88.37 %
Epoch 1714 of 2000 took 0.097s
  training loss:		0.063393
  validation loss:		0.772358
  validation accuracy:		88.80 %
Epoch 1715 of 2000 took 0.097s
  training loss:		0.060604
  validation loss:		0.835037
  validation accuracy:		88.48 %
Epoch 1716 of 2000 took 0.097s
  training loss:		0.082529
  validation loss:		0.835535
  validation accuracy:		88.37 %
Epoch 1717 of 2000 took 0.097s
  training loss:		0.076336
  validation loss:		0.786936
  validation accuracy:		88.70 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.073225
  validation loss:		0.772416
  validation accuracy:		89.02 %
Epoch 1719 of 2000 took 0.097s
  training loss:		0.063695
  validation loss:		0.806646
  validation accuracy:		88.70 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.068868
  validation loss:		0.815128
  validation accuracy:		88.48 %
Epoch 1721 of 2000 took 0.097s
  training loss:		0.062119
  validation loss:		0.806866
  validation accuracy:		88.80 %
Epoch 1722 of 2000 took 0.097s
  training loss:		0.068072
  validation loss:		0.805688
  validation accuracy:		88.37 %
Epoch 1723 of 2000 took 0.097s
  training loss:		0.067233
  validation loss:		0.810370
  validation accuracy:		88.37 %
Epoch 1724 of 2000 took 0.097s
  training loss:		0.058247
  validation loss:		0.801934
  validation accuracy:		88.70 %
Epoch 1725 of 2000 took 0.098s
  training loss:		0.065675
  validation loss:		0.805656
  validation accuracy:		88.80 %
Epoch 1726 of 2000 took 0.097s
  training loss:		0.059309
  validation loss:		0.857838
  validation accuracy:		87.93 %
Epoch 1727 of 2000 took 0.097s
  training loss:		0.071835
  validation loss:		0.762548
  validation accuracy:		89.13 %
Epoch 1728 of 2000 took 0.096s
  training loss:		0.070080
  validation loss:		0.813434
  validation accuracy:		88.48 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.061635
  validation loss:		0.780653
  validation accuracy:		89.35 %
Epoch 1730 of 2000 took 0.097s
  training loss:		0.058101
  validation loss:		0.783158
  validation accuracy:		89.02 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.061870
  validation loss:		0.794460
  validation accuracy:		88.80 %
Epoch 1732 of 2000 took 0.097s
  training loss:		0.060691
  validation loss:		0.871718
  validation accuracy:		87.93 %
Epoch 1733 of 2000 took 0.097s
  training loss:		0.068409
  validation loss:		0.821635
  validation accuracy:		88.59 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.064081
  validation loss:		0.828268
  validation accuracy:		88.48 %
Epoch 1735 of 2000 took 0.097s
  training loss:		0.060078
  validation loss:		0.868696
  validation accuracy:		87.83 %
Epoch 1736 of 2000 took 0.097s
  training loss:		0.064781
  validation loss:		0.802595
  validation accuracy:		89.02 %
Epoch 1737 of 2000 took 0.097s
  training loss:		0.061384
  validation loss:		0.813007
  validation accuracy:		88.70 %
Epoch 1738 of 2000 took 0.097s
  training loss:		0.057918
  validation loss:		0.841730
  validation accuracy:		88.70 %
Epoch 1739 of 2000 took 0.097s
  training loss:		0.071785
  validation loss:		0.792994
  validation accuracy:		89.13 %
Epoch 1740 of 2000 took 0.097s
  training loss:		0.063045
  validation loss:		0.811839
  validation accuracy:		89.02 %
Epoch 1741 of 2000 took 0.097s
  training loss:		0.061667
  validation loss:		0.827047
  validation accuracy:		88.37 %
Epoch 1742 of 2000 took 0.097s
  training loss:		0.061518
  validation loss:		0.825045
  validation accuracy:		88.48 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.061082
  validation loss:		0.862860
  validation accuracy:		87.72 %
Epoch 1744 of 2000 took 0.097s
  training loss:		0.060428
  validation loss:		0.811147
  validation accuracy:		88.70 %
Epoch 1745 of 2000 took 0.097s
  training loss:		0.069153
  validation loss:		0.793935
  validation accuracy:		89.35 %
Epoch 1746 of 2000 took 0.097s
  training loss:		0.067199
  validation loss:		0.905849
  validation accuracy:		87.39 %
Epoch 1747 of 2000 took 0.097s
  training loss:		0.068335
  validation loss:		0.823892
  validation accuracy:		88.48 %
Epoch 1748 of 2000 took 0.097s
  training loss:		0.064860
  validation loss:		0.797141
  validation accuracy:		89.02 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.065372
  validation loss:		0.861207
  validation accuracy:		88.04 %
Epoch 1750 of 2000 took 0.097s
  training loss:		0.058553
  validation loss:		0.771897
  validation accuracy:		89.24 %
Epoch 1751 of 2000 took 0.097s
  training loss:		0.067804
  validation loss:		0.790016
  validation accuracy:		88.91 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.059841
  validation loss:		0.820632
  validation accuracy:		88.48 %
Epoch 1753 of 2000 took 0.097s
  training loss:		0.060881
  validation loss:		0.816676
  validation accuracy:		88.59 %
Epoch 1754 of 2000 took 0.097s
  training loss:		0.061076
  validation loss:		0.818165
  validation accuracy:		88.80 %
Epoch 1755 of 2000 took 0.097s
  training loss:		0.066504
  validation loss:		0.822769
  validation accuracy:		88.48 %
Epoch 1756 of 2000 took 0.097s
  training loss:		0.069051
  validation loss:		0.774790
  validation accuracy:		89.35 %
Epoch 1757 of 2000 took 0.097s
  training loss:		0.073187
  validation loss:		0.777845
  validation accuracy:		89.02 %
Epoch 1758 of 2000 took 0.099s
  training loss:		0.059078
  validation loss:		0.821180
  validation accuracy:		89.13 %
Epoch 1759 of 2000 took 0.097s
  training loss:		0.138330
  validation loss:		0.967378
  validation accuracy:		87.28 %
Epoch 1760 of 2000 took 0.097s
  training loss:		0.110385
  validation loss:		0.841626
  validation accuracy:		88.37 %
Epoch 1761 of 2000 took 0.097s
  training loss:		0.065182
  validation loss:		0.870063
  validation accuracy:		88.59 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.066864
  validation loss:		0.806551
  validation accuracy:		88.70 %
Epoch 1763 of 2000 took 0.097s
  training loss:		0.062531
  validation loss:		0.810274
  validation accuracy:		89.13 %
Epoch 1764 of 2000 took 0.097s
  training loss:		0.060479
  validation loss:		0.791846
  validation accuracy:		89.46 %
Epoch 1765 of 2000 took 0.097s
  training loss:		0.060111
  validation loss:		0.814733
  validation accuracy:		88.70 %
Epoch 1766 of 2000 took 0.097s
  training loss:		0.062862
  validation loss:		0.766302
  validation accuracy:		89.78 %
Epoch 1767 of 2000 took 0.097s
  training loss:		0.063884
  validation loss:		0.778875
  validation accuracy:		90.00 %
Epoch 1768 of 2000 took 0.097s
  training loss:		0.066085
  validation loss:		0.789596
  validation accuracy:		88.91 %
Epoch 1769 of 2000 took 0.097s
  training loss:		0.060987
  validation loss:		0.878653
  validation accuracy:		88.59 %
Epoch 1770 of 2000 took 0.097s
  training loss:		0.065727
  validation loss:		0.829959
  validation accuracy:		88.59 %
Epoch 1771 of 2000 took 0.097s
  training loss:		0.059574
  validation loss:		0.796996
  validation accuracy:		89.02 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.061678
  validation loss:		0.797769
  validation accuracy:		88.91 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.110368
  validation loss:		0.862331
  validation accuracy:		88.48 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.063583
  validation loss:		0.791316
  validation accuracy:		89.02 %
Epoch 1775 of 2000 took 0.097s
  training loss:		0.065947
  validation loss:		0.808516
  validation accuracy:		89.13 %
Epoch 1776 of 2000 took 0.097s
  training loss:		0.066987
  validation loss:		0.950698
  validation accuracy:		87.50 %
Epoch 1777 of 2000 took 0.097s
  training loss:		0.069530
  validation loss:		0.805566
  validation accuracy:		88.80 %
Epoch 1778 of 2000 took 0.097s
  training loss:		0.070601
  validation loss:		0.844876
  validation accuracy:		88.59 %
Epoch 1779 of 2000 took 0.097s
  training loss:		0.067671
  validation loss:		0.797515
  validation accuracy:		89.24 %
Epoch 1780 of 2000 took 0.097s
  training loss:		0.064494
  validation loss:		0.824173
  validation accuracy:		88.80 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.068194
  validation loss:		0.940265
  validation accuracy:		88.15 %
Epoch 1782 of 2000 took 0.097s
  training loss:		0.160870
  validation loss:		0.802301
  validation accuracy:		88.91 %
Epoch 1783 of 2000 took 0.097s
  training loss:		0.062199
  validation loss:		0.806726
  validation accuracy:		88.91 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.064462
  validation loss:		0.825442
  validation accuracy:		88.80 %
Epoch 1785 of 2000 took 0.097s
  training loss:		0.058191
  validation loss:		0.767405
  validation accuracy:		89.35 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.071470
  validation loss:		0.834008
  validation accuracy:		88.37 %
Epoch 1787 of 2000 took 0.097s
  training loss:		0.065433
  validation loss:		0.835745
  validation accuracy:		88.59 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.062848
  validation loss:		0.827864
  validation accuracy:		88.70 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.072533
  validation loss:		0.840739
  validation accuracy:		88.48 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.054893
  validation loss:		0.826404
  validation accuracy:		88.59 %
Epoch 1791 of 2000 took 0.097s
  training loss:		0.063435
  validation loss:		0.821738
  validation accuracy:		88.91 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.063405
  validation loss:		0.782861
  validation accuracy:		89.24 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.058776
  validation loss:		0.802787
  validation accuracy:		89.24 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.059895
  validation loss:		0.793616
  validation accuracy:		88.91 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.067283
  validation loss:		0.820922
  validation accuracy:		89.02 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.059144
  validation loss:		0.945949
  validation accuracy:		86.85 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.063791
  validation loss:		0.818662
  validation accuracy:		89.13 %
Epoch 1798 of 2000 took 0.097s
  training loss:		0.067103
  validation loss:		0.864723
  validation accuracy:		88.70 %
Epoch 1799 of 2000 took 0.097s
  training loss:		0.065566
  validation loss:		0.835241
  validation accuracy:		88.91 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.052398
  validation loss:		0.843593
  validation accuracy:		88.37 %
Epoch 1801 of 2000 took 0.097s
  training loss:		0.057658
  validation loss:		0.846048
  validation accuracy:		88.80 %
Epoch 1802 of 2000 took 0.097s
  training loss:		0.076956
  validation loss:		0.827757
  validation accuracy:		89.13 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.053270
  validation loss:		0.786661
  validation accuracy:		89.13 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.054811
  validation loss:		0.870276
  validation accuracy:		88.26 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.056394
  validation loss:		0.868273
  validation accuracy:		88.70 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.054365
  validation loss:		0.877034
  validation accuracy:		88.26 %
Epoch 1807 of 2000 took 0.097s
  training loss:		0.096972
  validation loss:		1.139220
  validation accuracy:		85.76 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.084088
  validation loss:		0.806807
  validation accuracy:		89.24 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.053674
  validation loss:		0.828556
  validation accuracy:		89.02 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.059560
  validation loss:		0.833062
  validation accuracy:		88.80 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.058552
  validation loss:		0.836822
  validation accuracy:		88.70 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.056002
  validation loss:		0.814444
  validation accuracy:		89.02 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.067028
  validation loss:		0.876454
  validation accuracy:		88.70 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.071082
  validation loss:		0.868354
  validation accuracy:		88.04 %
Epoch 1815 of 2000 took 0.097s
  training loss:		0.059961
  validation loss:		0.795967
  validation accuracy:		89.46 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.060967
  validation loss:		0.797543
  validation accuracy:		88.91 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.058785
  validation loss:		0.873094
  validation accuracy:		88.91 %
Epoch 1818 of 2000 took 0.097s
  training loss:		0.067727
  validation loss:		0.819745
  validation accuracy:		89.46 %
Epoch 1819 of 2000 took 0.097s
  training loss:		0.053952
  validation loss:		0.884903
  validation accuracy:		88.59 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.072224
  validation loss:		0.914462
  validation accuracy:		87.93 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.063581
  validation loss:		0.870891
  validation accuracy:		88.48 %
Epoch 1822 of 2000 took 0.097s
  training loss:		0.058213
  validation loss:		0.854378
  validation accuracy:		88.37 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.073491
  validation loss:		0.872092
  validation accuracy:		88.26 %
Epoch 1824 of 2000 took 0.097s
  training loss:		0.067942
  validation loss:		0.889382
  validation accuracy:		88.26 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.056932
  validation loss:		0.859095
  validation accuracy:		88.59 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.061206
  validation loss:		0.827783
  validation accuracy:		88.70 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.058865
  validation loss:		0.822433
  validation accuracy:		89.13 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.055447
  validation loss:		0.850391
  validation accuracy:		89.02 %
Epoch 1829 of 2000 took 0.098s
  training loss:		0.064930
  validation loss:		0.828590
  validation accuracy:		89.02 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.055930
  validation loss:		0.797331
  validation accuracy:		89.46 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.063395
  validation loss:		0.845822
  validation accuracy:		88.59 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.055859
  validation loss:		0.904632
  validation accuracy:		88.59 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.083341
  validation loss:		0.822784
  validation accuracy:		89.02 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.054029
  validation loss:		0.803374
  validation accuracy:		89.24 %
Epoch 1835 of 2000 took 0.097s
  training loss:		0.058132
  validation loss:		0.845396
  validation accuracy:		89.24 %
Epoch 1836 of 2000 took 0.097s
  training loss:		0.058866
  validation loss:		0.828146
  validation accuracy:		89.46 %
Epoch 1837 of 2000 took 0.098s
  training loss:		0.086503
  validation loss:		0.812948
  validation accuracy:		89.35 %
Epoch 1838 of 2000 took 0.097s
  training loss:		0.060257
  validation loss:		0.772435
  validation accuracy:		89.46 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.077861
  validation loss:		0.828182
  validation accuracy:		89.13 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.056713
  validation loss:		0.818282
  validation accuracy:		89.02 %
Epoch 1841 of 2000 took 0.097s
  training loss:		0.053725
  validation loss:		0.884425
  validation accuracy:		88.37 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.082654
  validation loss:		0.805334
  validation accuracy:		89.57 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.066400
  validation loss:		0.829257
  validation accuracy:		88.91 %
Epoch 1844 of 2000 took 0.097s
  training loss:		0.053578
  validation loss:		0.789298
  validation accuracy:		89.67 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.060060
  validation loss:		0.840243
  validation accuracy:		88.48 %
Epoch 1846 of 2000 took 0.097s
  training loss:		0.057070
  validation loss:		0.871445
  validation accuracy:		88.70 %
Epoch 1847 of 2000 took 0.097s
  training loss:		0.063724
  validation loss:		0.836454
  validation accuracy:		89.02 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.059537
  validation loss:		0.861210
  validation accuracy:		88.80 %
Epoch 1849 of 2000 took 0.097s
  training loss:		0.059223
  validation loss:		0.851868
  validation accuracy:		88.91 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.060681
  validation loss:		0.849672
  validation accuracy:		89.13 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.064774
  validation loss:		0.802910
  validation accuracy:		89.35 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.057553
  validation loss:		0.864954
  validation accuracy:		88.37 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.055428
  validation loss:		0.918514
  validation accuracy:		88.04 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.058280
  validation loss:		0.842007
  validation accuracy:		88.80 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.054957
  validation loss:		0.863254
  validation accuracy:		89.13 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.059126
  validation loss:		0.843262
  validation accuracy:		88.70 %
Epoch 1857 of 2000 took 0.098s
  training loss:		0.055265
  validation loss:		0.835978
  validation accuracy:		88.91 %
Epoch 1858 of 2000 took 0.108s
  training loss:		0.054873
  validation loss:		0.848498
  validation accuracy:		88.48 %
Epoch 1859 of 2000 took 0.113s
  training loss:		0.067052
  validation loss:		0.901254
  validation accuracy:		88.04 %
Epoch 1860 of 2000 took 0.104s
  training loss:		0.056657
  validation loss:		0.863408
  validation accuracy:		89.57 %
Epoch 1861 of 2000 took 0.097s
  training loss:		0.051472
  validation loss:		0.840441
  validation accuracy:		88.91 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.066174
  validation loss:		0.844206
  validation accuracy:		89.35 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.051657
  validation loss:		0.881610
  validation accuracy:		88.80 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.057402
  validation loss:		0.816383
  validation accuracy:		89.02 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.058677
  validation loss:		0.848038
  validation accuracy:		88.70 %
Epoch 1866 of 2000 took 0.097s
  training loss:		0.056037
  validation loss:		0.946028
  validation accuracy:		87.72 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.053888
  validation loss:		0.880446
  validation accuracy:		88.15 %
Epoch 1868 of 2000 took 0.098s
  training loss:		0.061110
  validation loss:		0.913329
  validation accuracy:		88.15 %
Epoch 1869 of 2000 took 0.097s
  training loss:		0.063999
  validation loss:		0.876558
  validation accuracy:		89.13 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.055204
  validation loss:		0.890937
  validation accuracy:		88.37 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.052393
  validation loss:		0.853329
  validation accuracy:		88.48 %
Epoch 1872 of 2000 took 0.097s
  training loss:		0.058524
  validation loss:		0.924434
  validation accuracy:		88.04 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.055998
  validation loss:		0.865096
  validation accuracy:		88.37 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.058871
  validation loss:		0.815625
  validation accuracy:		89.78 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.059194
  validation loss:		0.822381
  validation accuracy:		89.13 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.060304
  validation loss:		0.798725
  validation accuracy:		89.67 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.069684
  validation loss:		0.865467
  validation accuracy:		89.13 %
Epoch 1878 of 2000 took 0.097s
  training loss:		0.103603
  validation loss:		0.850657
  validation accuracy:		89.57 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.057115
  validation loss:		0.840049
  validation accuracy:		89.35 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.055111
  validation loss:		0.795600
  validation accuracy:		89.46 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.085316
  validation loss:		0.885119
  validation accuracy:		88.59 %
Epoch 1882 of 2000 took 0.097s
  training loss:		0.047711
  validation loss:		0.886214
  validation accuracy:		88.48 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.058551
  validation loss:		0.947992
  validation accuracy:		87.50 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.064732
  validation loss:		0.860815
  validation accuracy:		88.80 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.056346
  validation loss:		0.866325
  validation accuracy:		89.13 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.051313
  validation loss:		0.903353
  validation accuracy:		87.83 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.066026
  validation loss:		0.833127
  validation accuracy:		89.02 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.057226
  validation loss:		0.906425
  validation accuracy:		88.15 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.057753
  validation loss:		0.902614
  validation accuracy:		87.93 %
Epoch 1890 of 2000 took 0.097s
  training loss:		0.055609
  validation loss:		0.884385
  validation accuracy:		88.91 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.054526
  validation loss:		0.842787
  validation accuracy:		89.35 %
Epoch 1892 of 2000 took 0.097s
  training loss:		0.096161
  validation loss:		0.999444
  validation accuracy:		88.04 %
Epoch 1893 of 2000 took 0.101s
  training loss:		0.062681
  validation loss:		0.905996
  validation accuracy:		88.48 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.054224
  validation loss:		0.846700
  validation accuracy:		89.24 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.048702
  validation loss:		0.831174
  validation accuracy:		89.02 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.059003
  validation loss:		0.867466
  validation accuracy:		89.13 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.058459
  validation loss:		0.871260
  validation accuracy:		89.02 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.057258
  validation loss:		0.878248
  validation accuracy:		88.59 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.064585
  validation loss:		0.828093
  validation accuracy:		89.02 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.136297
  validation loss:		0.885342
  validation accuracy:		88.80 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.058150
  validation loss:		0.819008
  validation accuracy:		89.35 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.066274
  validation loss:		0.845993
  validation accuracy:		89.13 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.060329
  validation loss:		0.952154
  validation accuracy:		87.72 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.058580
  validation loss:		0.868801
  validation accuracy:		88.70 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.071281
  validation loss:		0.887507
  validation accuracy:		88.37 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.071054
  validation loss:		0.871666
  validation accuracy:		88.91 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.049713
  validation loss:		0.867412
  validation accuracy:		89.35 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.063349
  validation loss:		0.854931
  validation accuracy:		88.91 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.049745
  validation loss:		0.844231
  validation accuracy:		89.13 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.055367
  validation loss:		0.923592
  validation accuracy:		88.26 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.063401
  validation loss:		1.030801
  validation accuracy:		86.96 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.066484
  validation loss:		0.859684
  validation accuracy:		89.24 %
Epoch 1913 of 2000 took 0.097s
  training loss:		0.060579
  validation loss:		0.945378
  validation accuracy:		88.15 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.197900
  validation loss:		0.860158
  validation accuracy:		89.24 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.054883
  validation loss:		0.856120
  validation accuracy:		89.13 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.063036
  validation loss:		0.848628
  validation accuracy:		89.02 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.060901
  validation loss:		0.913545
  validation accuracy:		88.26 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.062112
  validation loss:		0.804802
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.057935
  validation loss:		0.837076
  validation accuracy:		89.24 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.054931
  validation loss:		0.905473
  validation accuracy:		88.59 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.057564
  validation loss:		0.850511
  validation accuracy:		89.57 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.051173
  validation loss:		0.841629
  validation accuracy:		89.57 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.098287
  validation loss:		0.909561
  validation accuracy:		88.70 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.064957
  validation loss:		0.940458
  validation accuracy:		87.83 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.064704
  validation loss:		0.887928
  validation accuracy:		88.91 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.059378
  validation loss:		0.864651
  validation accuracy:		89.13 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.052001
  validation loss:		0.883089
  validation accuracy:		88.80 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.051208
  validation loss:		0.851351
  validation accuracy:		89.67 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.056533
  validation loss:		0.851399
  validation accuracy:		89.02 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.047078
  validation loss:		0.902071
  validation accuracy:		88.80 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.062135
  validation loss:		0.864871
  validation accuracy:		88.91 %
Epoch 1932 of 2000 took 0.097s
  training loss:		0.053470
  validation loss:		0.873800
  validation accuracy:		88.91 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.052527
  validation loss:		0.871008
  validation accuracy:		89.02 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.048322
  validation loss:		0.885369
  validation accuracy:		88.70 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.047813
  validation loss:		0.889579
  validation accuracy:		89.35 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.051359
  validation loss:		0.832734
  validation accuracy:		89.78 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.055736
  validation loss:		0.917754
  validation accuracy:		88.37 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.058973
  validation loss:		0.895431
  validation accuracy:		88.91 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.082539
  validation loss:		0.921323
  validation accuracy:		88.80 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.051776
  validation loss:		0.921238
  validation accuracy:		88.04 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.055327
  validation loss:		0.854709
  validation accuracy:		89.35 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.055469
  validation loss:		0.877409
  validation accuracy:		88.80 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.061107
  validation loss:		0.892266
  validation accuracy:		88.59 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.050634
  validation loss:		0.851920
  validation accuracy:		88.91 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.069201
  validation loss:		0.861399
  validation accuracy:		89.13 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.053607
  validation loss:		0.843900
  validation accuracy:		89.57 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.054478
  validation loss:		0.870827
  validation accuracy:		88.91 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.058189
  validation loss:		0.876072
  validation accuracy:		89.46 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.050925
  validation loss:		0.905324
  validation accuracy:		88.37 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.049513
  validation loss:		0.897136
  validation accuracy:		88.70 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.051846
  validation loss:		0.911542
  validation accuracy:		88.91 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.046969
  validation loss:		0.925149
  validation accuracy:		88.37 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.047885
  validation loss:		0.943816
  validation accuracy:		88.26 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.055804
  validation loss:		0.934644
  validation accuracy:		88.59 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.054089
  validation loss:		0.927599
  validation accuracy:		88.80 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.053298
  validation loss:		0.897710
  validation accuracy:		88.59 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.043636
  validation loss:		0.861905
  validation accuracy:		89.02 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.052386
  validation loss:		0.876585
  validation accuracy:		88.91 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.048733
  validation loss:		0.894407
  validation accuracy:		88.70 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.048249
  validation loss:		0.879688
  validation accuracy:		89.02 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.051792
  validation loss:		0.888256
  validation accuracy:		89.24 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.046648
  validation loss:		0.881644
  validation accuracy:		88.80 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.049624
  validation loss:		0.941305
  validation accuracy:		88.80 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.054670
  validation loss:		0.921416
  validation accuracy:		88.59 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.055061
  validation loss:		0.921130
  validation accuracy:		88.48 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.078189
  validation loss:		1.004853
  validation accuracy:		87.50 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.055038
  validation loss:		0.882961
  validation accuracy:		89.24 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.051056
  validation loss:		0.923373
  validation accuracy:		88.80 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.059275
  validation loss:		0.906679
  validation accuracy:		88.91 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.053142
  validation loss:		0.858722
  validation accuracy:		89.13 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.048901
  validation loss:		0.954392
  validation accuracy:		88.37 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.048850
  validation loss:		0.925467
  validation accuracy:		88.70 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.054079
  validation loss:		0.933592
  validation accuracy:		88.59 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.057566
  validation loss:		0.898021
  validation accuracy:		89.13 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.051194
  validation loss:		0.924373
  validation accuracy:		88.91 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.124538
  validation loss:		1.093580
  validation accuracy:		86.74 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.098294
  validation loss:		0.913224
  validation accuracy:		88.91 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.061936
  validation loss:		0.905116
  validation accuracy:		88.91 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.064693
  validation loss:		1.097774
  validation accuracy:		87.07 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.252247
  validation loss:		0.905572
  validation accuracy:		88.59 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.053160
  validation loss:		0.853040
  validation accuracy:		89.89 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.058183
  validation loss:		0.867320
  validation accuracy:		89.67 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.054527
  validation loss:		0.849395
  validation accuracy:		89.46 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.054416
  validation loss:		0.925662
  validation accuracy:		88.70 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.061886
  validation loss:		0.818440
  validation accuracy:		89.13 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.058150
  validation loss:		0.934677
  validation accuracy:		89.02 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.057591
  validation loss:		0.922619
  validation accuracy:		88.70 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.050999
  validation loss:		0.877271
  validation accuracy:		88.91 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.048573
  validation loss:		0.873517
  validation accuracy:		88.91 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.061486
  validation loss:		0.868295
  validation accuracy:		89.02 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.050937
  validation loss:		0.860209
  validation accuracy:		89.24 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.048140
  validation loss:		0.835442
  validation accuracy:		90.00 %
Epoch 1993 of 2000 took 0.097s
  training loss:		0.049216
  validation loss:		0.910139
  validation accuracy:		88.37 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.054171
  validation loss:		0.876379
  validation accuracy:		89.67 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.060063
  validation loss:		1.069458
  validation accuracy:		87.17 %
Epoch 1996 of 2000 took 0.097s
  training loss:		0.110480
  validation loss:		0.923177
  validation accuracy:		88.48 %
Epoch 1997 of 2000 took 0.097s
  training loss:		0.051839
  validation loss:		0.898820
  validation accuracy:		89.13 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.051417
  validation loss:		0.924992
  validation accuracy:		88.37 %
Epoch 1999 of 2000 took 0.097s
  training loss:		0.054845
  validation loss:		0.877010
  validation accuracy:		88.70 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.052547
  validation loss:		0.858629
  validation accuracy:		89.24 %
Final results:
  test loss:			1.760865
  test accuracy:		82.42 %
