Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.146s
  training loss:		2.913595
  validation loss:		2.801947
  validation accuracy:		10.65 %
Epoch 2 of 2000 took 0.142s
  training loss:		2.710826
  validation loss:		2.547515
  validation accuracy:		10.76 %
Epoch 3 of 2000 took 0.142s
  training loss:		2.499739
  validation loss:		2.327913
  validation accuracy:		15.65 %
Epoch 4 of 2000 took 0.139s
  training loss:		2.353582
  validation loss:		2.223588
  validation accuracy:		32.93 %
Epoch 5 of 2000 took 0.139s
  training loss:		2.281260
  validation loss:		2.198904
  validation accuracy:		42.28 %
Epoch 6 of 2000 took 0.158s
  training loss:		2.243814
  validation loss:		2.169385
  validation accuracy:		49.57 %
Epoch 7 of 2000 took 0.139s
  training loss:		2.220074
  validation loss:		2.144502
  validation accuracy:		54.89 %
Epoch 8 of 2000 took 0.132s
  training loss:		2.196440
  validation loss:		2.121243
  validation accuracy:		52.61 %
Epoch 9 of 2000 took 0.136s
  training loss:		2.173603
  validation loss:		2.094011
  validation accuracy:		65.11 %
Epoch 10 of 2000 took 0.144s
  training loss:		2.146923
  validation loss:		2.061480
  validation accuracy:		70.98 %
Epoch 11 of 2000 took 0.141s
  training loss:		2.118177
  validation loss:		2.025857
  validation accuracy:		71.09 %
Epoch 12 of 2000 took 0.144s
  training loss:		2.086330
  validation loss:		1.995078
  validation accuracy:		72.07 %
Epoch 13 of 2000 took 0.134s
  training loss:		2.047452
  validation loss:		1.944848
  validation accuracy:		70.43 %
Epoch 14 of 2000 took 0.132s
  training loss:		2.004757
  validation loss:		1.898980
  validation accuracy:		73.80 %
Epoch 15 of 2000 took 0.145s
  training loss:		1.955625
  validation loss:		1.836778
  validation accuracy:		82.17 %
Epoch 16 of 2000 took 0.157s
  training loss:		1.897367
  validation loss:		1.777523
  validation accuracy:		71.30 %
Epoch 17 of 2000 took 0.176s
  training loss:		1.834008
  validation loss:		1.699731
  validation accuracy:		81.41 %
Epoch 18 of 2000 took 0.175s
  training loss:		1.762421
  validation loss:		1.615001
  validation accuracy:		77.93 %
Epoch 19 of 2000 took 0.175s
  training loss:		1.682764
  validation loss:		1.532746
  validation accuracy:		82.17 %
Epoch 20 of 2000 took 0.152s
  training loss:		1.604828
  validation loss:		1.450561
  validation accuracy:		84.78 %
Epoch 21 of 2000 took 0.140s
  training loss:		1.519496
  validation loss:		1.360626
  validation accuracy:		84.67 %
Epoch 22 of 2000 took 0.172s
  training loss:		1.436927
  validation loss:		1.274949
  validation accuracy:		86.74 %
Epoch 23 of 2000 took 0.139s
  training loss:		1.355432
  validation loss:		1.198741
  validation accuracy:		86.85 %
Epoch 24 of 2000 took 0.157s
  training loss:		1.280551
  validation loss:		1.126794
  validation accuracy:		87.17 %
Epoch 25 of 2000 took 0.142s
  training loss:		1.207498
  validation loss:		1.044463
  validation accuracy:		87.07 %
Epoch 26 of 2000 took 0.149s
  training loss:		1.134901
  validation loss:		0.980222
  validation accuracy:		87.61 %
Epoch 27 of 2000 took 0.125s
  training loss:		1.068306
  validation loss:		0.916677
  validation accuracy:		87.83 %
Epoch 28 of 2000 took 0.139s
  training loss:		1.007220
  validation loss:		0.859018
  validation accuracy:		86.96 %
Epoch 29 of 2000 took 0.134s
  training loss:		0.947618
  validation loss:		0.806460
  validation accuracy:		87.61 %
Epoch 30 of 2000 took 0.162s
  training loss:		0.897146
  validation loss:		0.765922
  validation accuracy:		88.26 %
Epoch 31 of 2000 took 0.175s
  training loss:		0.853236
  validation loss:		0.716638
  validation accuracy:		87.72 %
Epoch 32 of 2000 took 0.173s
  training loss:		0.804279
  validation loss:		0.672356
  validation accuracy:		87.93 %
Epoch 33 of 2000 took 0.150s
  training loss:		0.764725
  validation loss:		0.650209
  validation accuracy:		88.15 %
Epoch 34 of 2000 took 0.134s
  training loss:		0.729031
  validation loss:		0.615805
  validation accuracy:		89.13 %
Epoch 35 of 2000 took 0.137s
  training loss:		0.699086
  validation loss:		0.589963
  validation accuracy:		88.37 %
Epoch 36 of 2000 took 0.150s
  training loss:		0.661690
  validation loss:		0.559440
  validation accuracy:		88.80 %
Epoch 37 of 2000 took 0.176s
  training loss:		0.636886
  validation loss:		0.537457
  validation accuracy:		88.91 %
Epoch 38 of 2000 took 0.177s
  training loss:		0.607398
  validation loss:		0.513324
  validation accuracy:		89.89 %
Epoch 39 of 2000 took 0.128s
  training loss:		0.587079
  validation loss:		0.504909
  validation accuracy:		89.35 %
Epoch 40 of 2000 took 0.147s
  training loss:		0.565452
  validation loss:		0.480548
  validation accuracy:		88.37 %
Epoch 41 of 2000 took 0.135s
  training loss:		0.542697
  validation loss:		0.460244
  validation accuracy:		89.67 %
Epoch 42 of 2000 took 0.136s
  training loss:		0.526274
  validation loss:		0.448820
  validation accuracy:		90.65 %
Epoch 43 of 2000 took 0.155s
  training loss:		0.503399
  validation loss:		0.434702
  validation accuracy:		90.33 %
Epoch 44 of 2000 took 0.168s
  training loss:		0.492225
  validation loss:		0.424286
  validation accuracy:		90.54 %
Epoch 45 of 2000 took 0.137s
  training loss:		0.475441
  validation loss:		0.409363
  validation accuracy:		90.54 %
Epoch 46 of 2000 took 0.133s
  training loss:		0.455308
  validation loss:		0.402495
  validation accuracy:		91.09 %
Epoch 47 of 2000 took 0.150s
  training loss:		0.447836
  validation loss:		0.398008
  validation accuracy:		90.43 %
Epoch 48 of 2000 took 0.146s
  training loss:		0.434383
  validation loss:		0.377580
  validation accuracy:		90.87 %
Epoch 49 of 2000 took 0.140s
  training loss:		0.424403
  validation loss:		0.377017
  validation accuracy:		90.76 %
Epoch 50 of 2000 took 0.139s
  training loss:		0.411291
  validation loss:		0.363612
  validation accuracy:		90.76 %
Epoch 51 of 2000 took 0.140s
  training loss:		0.400671
  validation loss:		0.353535
  validation accuracy:		91.09 %
Epoch 52 of 2000 took 0.173s
  training loss:		0.390527
  validation loss:		0.339999
  validation accuracy:		91.41 %
Epoch 53 of 2000 took 0.162s
  training loss:		0.379453
  validation loss:		0.347559
  validation accuracy:		91.41 %
Epoch 54 of 2000 took 0.180s
  training loss:		0.372647
  validation loss:		0.336257
  validation accuracy:		91.41 %
Epoch 55 of 2000 took 0.175s
  training loss:		0.362262
  validation loss:		0.330403
  validation accuracy:		91.41 %
Epoch 56 of 2000 took 0.150s
  training loss:		0.352720
  validation loss:		0.321671
  validation accuracy:		92.07 %
Epoch 57 of 2000 took 0.141s
  training loss:		0.346161
  validation loss:		0.326620
  validation accuracy:		91.74 %
Epoch 58 of 2000 took 0.130s
  training loss:		0.338465
  validation loss:		0.310607
  validation accuracy:		91.63 %
Epoch 59 of 2000 took 0.141s
  training loss:		0.335010
  validation loss:		0.313678
  validation accuracy:		91.74 %
Epoch 60 of 2000 took 0.172s
  training loss:		0.324305
  validation loss:		0.307819
  validation accuracy:		92.28 %
Epoch 61 of 2000 took 0.176s
  training loss:		0.325382
  validation loss:		0.299189
  validation accuracy:		92.28 %
Epoch 62 of 2000 took 0.158s
  training loss:		0.317013
  validation loss:		0.295894
  validation accuracy:		92.28 %
Epoch 63 of 2000 took 0.134s
  training loss:		0.310231
  validation loss:		0.301050
  validation accuracy:		92.07 %
Epoch 64 of 2000 took 0.139s
  training loss:		0.306147
  validation loss:		0.289884
  validation accuracy:		92.50 %
Epoch 65 of 2000 took 0.162s
  training loss:		0.298802
  validation loss:		0.285779
  validation accuracy:		92.28 %
Epoch 66 of 2000 took 0.137s
  training loss:		0.296097
  validation loss:		0.278585
  validation accuracy:		92.50 %
Epoch 67 of 2000 took 0.147s
  training loss:		0.291375
  validation loss:		0.281809
  validation accuracy:		92.28 %
Epoch 68 of 2000 took 0.176s
  training loss:		0.288865
  validation loss:		0.280854
  validation accuracy:		92.17 %
Epoch 69 of 2000 took 0.176s
  training loss:		0.281683
  validation loss:		0.274480
  validation accuracy:		92.07 %
Epoch 70 of 2000 took 0.176s
  training loss:		0.279231
  validation loss:		0.267639
  validation accuracy:		92.61 %
Epoch 71 of 2000 took 0.176s
  training loss:		0.280841
  validation loss:		0.265039
  validation accuracy:		92.83 %
Epoch 72 of 2000 took 0.174s
  training loss:		0.271547
  validation loss:		0.264866
  validation accuracy:		92.83 %
Epoch 73 of 2000 took 0.176s
  training loss:		0.268212
  validation loss:		0.260911
  validation accuracy:		92.83 %
Epoch 74 of 2000 took 0.153s
  training loss:		0.262772
  validation loss:		0.259450
  validation accuracy:		93.04 %
Epoch 75 of 2000 took 0.144s
  training loss:		0.262084
  validation loss:		0.260471
  validation accuracy:		92.72 %
Epoch 76 of 2000 took 0.130s
  training loss:		0.260417
  validation loss:		0.258989
  validation accuracy:		92.61 %
Epoch 77 of 2000 took 0.174s
  training loss:		0.257723
  validation loss:		0.257318
  validation accuracy:		92.61 %
Epoch 78 of 2000 took 0.172s
  training loss:		0.253485
  validation loss:		0.263098
  validation accuracy:		92.72 %
Epoch 79 of 2000 took 0.137s
  training loss:		0.254256
  validation loss:		0.250145
  validation accuracy:		93.15 %
Epoch 80 of 2000 took 0.142s
  training loss:		0.247266
  validation loss:		0.244941
  validation accuracy:		93.70 %
Epoch 81 of 2000 took 0.136s
  training loss:		0.249292
  validation loss:		0.242568
  validation accuracy:		93.37 %
Epoch 82 of 2000 took 0.150s
  training loss:		0.246243
  validation loss:		0.253474
  validation accuracy:		92.93 %
Epoch 83 of 2000 took 0.139s
  training loss:		0.242369
  validation loss:		0.246610
  validation accuracy:		92.61 %
Epoch 84 of 2000 took 0.156s
  training loss:		0.241437
  validation loss:		0.244572
  validation accuracy:		92.72 %
Epoch 85 of 2000 took 0.175s
  training loss:		0.241483
  validation loss:		0.242526
  validation accuracy:		92.83 %
Epoch 86 of 2000 took 0.175s
  training loss:		0.231797
  validation loss:		0.239115
  validation accuracy:		93.80 %
Epoch 87 of 2000 took 0.174s
  training loss:		0.233692
  validation loss:		0.236041
  validation accuracy:		93.04 %
Epoch 88 of 2000 took 0.175s
  training loss:		0.229343
  validation loss:		0.232094
  validation accuracy:		93.26 %
Epoch 89 of 2000 took 0.175s
  training loss:		0.232440
  validation loss:		0.234613
  validation accuracy:		93.59 %
Epoch 90 of 2000 took 0.146s
  training loss:		0.227158
  validation loss:		0.234597
  validation accuracy:		93.04 %
Epoch 91 of 2000 took 0.176s
  training loss:		0.226564
  validation loss:		0.237187
  validation accuracy:		93.37 %
Epoch 92 of 2000 took 0.171s
  training loss:		0.222382
  validation loss:		0.229722
  validation accuracy:		93.91 %
Epoch 93 of 2000 took 0.174s
  training loss:		0.222685
  validation loss:		0.227958
  validation accuracy:		93.80 %
Epoch 94 of 2000 took 0.179s
  training loss:		0.218609
  validation loss:		0.231400
  validation accuracy:		93.26 %
Epoch 95 of 2000 took 0.180s
  training loss:		0.215804
  validation loss:		0.225885
  validation accuracy:		93.70 %
Epoch 96 of 2000 took 0.170s
  training loss:		0.214869
  validation loss:		0.226706
  validation accuracy:		93.59 %
Epoch 97 of 2000 took 0.168s
  training loss:		0.215706
  validation loss:		0.235625
  validation accuracy:		92.93 %
Epoch 98 of 2000 took 0.175s
  training loss:		0.215260
  validation loss:		0.233307
  validation accuracy:		93.04 %
Epoch 99 of 2000 took 0.164s
  training loss:		0.212075
  validation loss:		0.230153
  validation accuracy:		93.59 %
Epoch 100 of 2000 took 0.173s
  training loss:		0.211786
  validation loss:		0.226701
  validation accuracy:		93.59 %
Epoch 101 of 2000 took 0.175s
  training loss:		0.208198
  validation loss:		0.237340
  validation accuracy:		93.26 %
Epoch 102 of 2000 took 0.175s
  training loss:		0.208036
  validation loss:		0.230023
  validation accuracy:		93.48 %
Epoch 103 of 2000 took 0.148s
  training loss:		0.208025
  validation loss:		0.225734
  validation accuracy:		93.37 %
Epoch 104 of 2000 took 0.130s
  training loss:		0.204107
  validation loss:		0.220267
  validation accuracy:		93.48 %
Epoch 105 of 2000 took 0.153s
  training loss:		0.203784
  validation loss:		0.218266
  validation accuracy:		94.35 %
Epoch 106 of 2000 took 0.142s
  training loss:		0.199079
  validation loss:		0.217916
  validation accuracy:		94.13 %
Epoch 107 of 2000 took 0.110s
  training loss:		0.201483
  validation loss:		0.217826
  validation accuracy:		93.48 %
Epoch 108 of 2000 took 0.101s
  training loss:		0.199562
  validation loss:		0.216377
  validation accuracy:		93.80 %
Epoch 109 of 2000 took 0.133s
  training loss:		0.199817
  validation loss:		0.216663
  validation accuracy:		93.48 %
Epoch 110 of 2000 took 0.131s
  training loss:		0.196517
  validation loss:		0.225114
  validation accuracy:		93.48 %
Epoch 111 of 2000 took 0.150s
  training loss:		0.195506
  validation loss:		0.218151
  validation accuracy:		94.13 %
Epoch 112 of 2000 took 0.117s
  training loss:		0.190024
  validation loss:		0.214661
  validation accuracy:		93.80 %
Epoch 113 of 2000 took 0.113s
  training loss:		0.191452
  validation loss:		0.214132
  validation accuracy:		94.02 %
Epoch 114 of 2000 took 0.121s
  training loss:		0.190707
  validation loss:		0.220221
  validation accuracy:		93.04 %
Epoch 115 of 2000 took 0.101s
  training loss:		0.193487
  validation loss:		0.216680
  validation accuracy:		93.91 %
Epoch 116 of 2000 took 0.110s
  training loss:		0.192579
  validation loss:		0.214518
  validation accuracy:		93.37 %
Epoch 117 of 2000 took 0.110s
  training loss:		0.189387
  validation loss:		0.212422
  validation accuracy:		93.70 %
Epoch 118 of 2000 took 0.084s
  training loss:		0.187247
  validation loss:		0.219090
  validation accuracy:		93.59 %
Epoch 119 of 2000 took 0.072s
  training loss:		0.188326
  validation loss:		0.214321
  validation accuracy:		93.26 %
Epoch 120 of 2000 took 0.092s
  training loss:		0.183341
  validation loss:		0.225537
  validation accuracy:		93.70 %
Epoch 121 of 2000 took 0.093s
  training loss:		0.184491
  validation loss:		0.213716
  validation accuracy:		93.59 %
Epoch 122 of 2000 took 0.107s
  training loss:		0.183453
  validation loss:		0.213069
  validation accuracy:		93.70 %
Epoch 123 of 2000 took 0.114s
  training loss:		0.186047
  validation loss:		0.211062
  validation accuracy:		93.48 %
Epoch 124 of 2000 took 0.112s
  training loss:		0.182258
  validation loss:		0.216424
  validation accuracy:		93.48 %
Epoch 125 of 2000 took 0.193s
  training loss:		0.184175
  validation loss:		0.206963
  validation accuracy:		94.24 %
Epoch 126 of 2000 took 0.198s
  training loss:		0.177229
  validation loss:		0.216608
  validation accuracy:		93.48 %
Epoch 127 of 2000 took 0.127s
  training loss:		0.180929
  validation loss:		0.209663
  validation accuracy:		94.13 %
Epoch 128 of 2000 took 0.113s
  training loss:		0.173229
  validation loss:		0.208149
  validation accuracy:		93.70 %
Epoch 129 of 2000 took 0.123s
  training loss:		0.179381
  validation loss:		0.207951
  validation accuracy:		94.46 %
Epoch 130 of 2000 took 0.102s
  training loss:		0.175999
  validation loss:		0.209939
  validation accuracy:		94.24 %
Epoch 131 of 2000 took 0.142s
  training loss:		0.172262
  validation loss:		0.210788
  validation accuracy:		94.57 %
Epoch 132 of 2000 took 0.125s
  training loss:		0.173021
  validation loss:		0.209628
  validation accuracy:		93.80 %
Epoch 133 of 2000 took 0.118s
  training loss:		0.176133
  validation loss:		0.209390
  validation accuracy:		94.02 %
Epoch 134 of 2000 took 0.120s
  training loss:		0.168653
  validation loss:		0.207588
  validation accuracy:		94.24 %
Epoch 135 of 2000 took 0.113s
  training loss:		0.170249
  validation loss:		0.203314
  validation accuracy:		94.57 %
Epoch 136 of 2000 took 0.126s
  training loss:		0.171134
  validation loss:		0.211875
  validation accuracy:		93.70 %
Epoch 137 of 2000 took 0.099s
  training loss:		0.169437
  validation loss:		0.210430
  validation accuracy:		93.80 %
Epoch 138 of 2000 took 0.087s
  training loss:		0.164816
  validation loss:		0.208260
  validation accuracy:		93.80 %
Epoch 139 of 2000 took 0.112s
  training loss:		0.165062
  validation loss:		0.203888
  validation accuracy:		94.13 %
Epoch 140 of 2000 took 0.110s
  training loss:		0.167747
  validation loss:		0.207493
  validation accuracy:		93.80 %
Epoch 141 of 2000 took 0.127s
  training loss:		0.164651
  validation loss:		0.204629
  validation accuracy:		94.57 %
Epoch 142 of 2000 took 0.123s
  training loss:		0.160698
  validation loss:		0.203745
  validation accuracy:		94.46 %
Epoch 143 of 2000 took 0.125s
  training loss:		0.165814
  validation loss:		0.202708
  validation accuracy:		94.57 %
Epoch 144 of 2000 took 0.090s
  training loss:		0.161323
  validation loss:		0.209495
  validation accuracy:		93.80 %
Epoch 145 of 2000 took 0.119s
  training loss:		0.164120
  validation loss:		0.200641
  validation accuracy:		94.46 %
Epoch 146 of 2000 took 0.122s
  training loss:		0.163010
  validation loss:		0.211323
  validation accuracy:		93.48 %
Epoch 147 of 2000 took 0.123s
  training loss:		0.158059
  validation loss:		0.212412
  validation accuracy:		93.80 %
Epoch 148 of 2000 took 0.124s
  training loss:		0.160188
  validation loss:		0.206550
  validation accuracy:		94.13 %
Epoch 149 of 2000 took 0.121s
  training loss:		0.159763
  validation loss:		0.206605
  validation accuracy:		93.80 %
Epoch 150 of 2000 took 0.126s
  training loss:		0.158104
  validation loss:		0.208547
  validation accuracy:		94.57 %
Epoch 151 of 2000 took 0.127s
  training loss:		0.154403
  validation loss:		0.211620
  validation accuracy:		94.46 %
Epoch 152 of 2000 took 0.113s
  training loss:		0.155758
  validation loss:		0.207049
  validation accuracy:		93.91 %
Epoch 153 of 2000 took 0.114s
  training loss:		0.157131
  validation loss:		0.203281
  validation accuracy:		94.57 %
Epoch 154 of 2000 took 0.119s
  training loss:		0.156013
  validation loss:		0.214792
  validation accuracy:		93.70 %
Epoch 155 of 2000 took 0.122s
  training loss:		0.155556
  validation loss:		0.212776
  validation accuracy:		93.91 %
Epoch 156 of 2000 took 0.105s
  training loss:		0.153839
  validation loss:		0.203275
  validation accuracy:		94.24 %
Epoch 157 of 2000 took 0.113s
  training loss:		0.150884
  validation loss:		0.204140
  validation accuracy:		94.67 %
Epoch 158 of 2000 took 0.126s
  training loss:		0.153285
  validation loss:		0.198001
  validation accuracy:		94.67 %
Epoch 159 of 2000 took 0.128s
  training loss:		0.152334
  validation loss:		0.199888
  validation accuracy:		94.24 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.147455
  validation loss:		0.200725
  validation accuracy:		94.78 %
Epoch 161 of 2000 took 0.121s
  training loss:		0.148043
  validation loss:		0.202242
  validation accuracy:		94.02 %
Epoch 162 of 2000 took 0.121s
  training loss:		0.149300
  validation loss:		0.201693
  validation accuracy:		94.02 %
Epoch 163 of 2000 took 0.121s
  training loss:		0.149461
  validation loss:		0.201968
  validation accuracy:		94.57 %
Epoch 164 of 2000 took 0.120s
  training loss:		0.151578
  validation loss:		0.206630
  validation accuracy:		93.80 %
Epoch 165 of 2000 took 0.124s
  training loss:		0.150219
  validation loss:		0.202790
  validation accuracy:		94.24 %
Epoch 166 of 2000 took 0.094s
  training loss:		0.147619
  validation loss:		0.206702
  validation accuracy:		94.46 %
Epoch 167 of 2000 took 0.115s
  training loss:		0.146449
  validation loss:		0.198432
  validation accuracy:		94.46 %
Epoch 168 of 2000 took 0.116s
  training loss:		0.144418
  validation loss:		0.202328
  validation accuracy:		94.24 %
Epoch 169 of 2000 took 0.091s
  training loss:		0.145993
  validation loss:		0.198024
  validation accuracy:		94.89 %
Epoch 170 of 2000 took 0.124s
  training loss:		0.145243
  validation loss:		0.204039
  validation accuracy:		94.46 %
Epoch 171 of 2000 took 0.111s
  training loss:		0.141287
  validation loss:		0.204543
  validation accuracy:		93.70 %
Epoch 172 of 2000 took 0.115s
  training loss:		0.142315
  validation loss:		0.196110
  validation accuracy:		94.67 %
Epoch 173 of 2000 took 0.119s
  training loss:		0.139389
  validation loss:		0.207176
  validation accuracy:		93.80 %
Epoch 174 of 2000 took 0.106s
  training loss:		0.140720
  validation loss:		0.199015
  validation accuracy:		94.89 %
Epoch 175 of 2000 took 0.102s
  training loss:		0.139656
  validation loss:		0.199542
  validation accuracy:		94.46 %
Epoch 176 of 2000 took 0.107s
  training loss:		0.137238
  validation loss:		0.209059
  validation accuracy:		94.02 %
Epoch 177 of 2000 took 0.112s
  training loss:		0.138898
  validation loss:		0.198666
  validation accuracy:		94.57 %
Epoch 178 of 2000 took 0.114s
  training loss:		0.138544
  validation loss:		0.205380
  validation accuracy:		93.91 %
Epoch 179 of 2000 took 0.114s
  training loss:		0.139674
  validation loss:		0.198989
  validation accuracy:		94.57 %
Epoch 180 of 2000 took 0.115s
  training loss:		0.136537
  validation loss:		0.198754
  validation accuracy:		94.67 %
Epoch 181 of 2000 took 0.107s
  training loss:		0.139710
  validation loss:		0.218813
  validation accuracy:		93.48 %
Epoch 182 of 2000 took 0.086s
  training loss:		0.138006
  validation loss:		0.201681
  validation accuracy:		94.35 %
Epoch 183 of 2000 took 0.125s
  training loss:		0.136658
  validation loss:		0.203680
  validation accuracy:		94.35 %
Epoch 184 of 2000 took 0.111s
  training loss:		0.134949
  validation loss:		0.196712
  validation accuracy:		94.35 %
Epoch 185 of 2000 took 0.121s
  training loss:		0.134592
  validation loss:		0.198205
  validation accuracy:		94.46 %
Epoch 186 of 2000 took 0.124s
  training loss:		0.133468
  validation loss:		0.200125
  validation accuracy:		94.67 %
Epoch 187 of 2000 took 0.121s
  training loss:		0.133686
  validation loss:		0.197889
  validation accuracy:		94.46 %
Epoch 188 of 2000 took 0.122s
  training loss:		0.131567
  validation loss:		0.201405
  validation accuracy:		94.24 %
Epoch 189 of 2000 took 0.122s
  training loss:		0.136068
  validation loss:		0.200407
  validation accuracy:		94.35 %
Epoch 190 of 2000 took 0.111s
  training loss:		0.132979
  validation loss:		0.200946
  validation accuracy:		94.67 %
Epoch 191 of 2000 took 0.099s
  training loss:		0.132384
  validation loss:		0.205033
  validation accuracy:		94.13 %
Epoch 192 of 2000 took 0.110s
  training loss:		0.129582
  validation loss:		0.198075
  validation accuracy:		94.24 %
Epoch 193 of 2000 took 0.105s
  training loss:		0.132443
  validation loss:		0.200550
  validation accuracy:		94.67 %
Epoch 194 of 2000 took 0.131s
  training loss:		0.130052
  validation loss:		0.204583
  validation accuracy:		94.02 %
Epoch 195 of 2000 took 0.127s
  training loss:		0.130424
  validation loss:		0.197856
  validation accuracy:		94.89 %
Epoch 196 of 2000 took 0.129s
  training loss:		0.130195
  validation loss:		0.195483
  validation accuracy:		94.78 %
Epoch 197 of 2000 took 0.126s
  training loss:		0.129724
  validation loss:		0.198345
  validation accuracy:		94.67 %
Epoch 198 of 2000 took 0.120s
  training loss:		0.129172
  validation loss:		0.195894
  validation accuracy:		94.67 %
Epoch 199 of 2000 took 0.087s
  training loss:		0.124823
  validation loss:		0.200497
  validation accuracy:		94.02 %
Epoch 200 of 2000 took 0.105s
  training loss:		0.127909
  validation loss:		0.196704
  validation accuracy:		94.46 %
Epoch 201 of 2000 took 0.099s
  training loss:		0.124511
  validation loss:		0.202376
  validation accuracy:		94.13 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.123936
  validation loss:		0.198701
  validation accuracy:		94.57 %
Epoch 203 of 2000 took 0.114s
  training loss:		0.128172
  validation loss:		0.205141
  validation accuracy:		94.35 %
Epoch 204 of 2000 took 0.113s
  training loss:		0.125905
  validation loss:		0.205834
  validation accuracy:		93.80 %
Epoch 205 of 2000 took 0.127s
  training loss:		0.124398
  validation loss:		0.204289
  validation accuracy:		94.13 %
Epoch 206 of 2000 took 0.137s
  training loss:		0.122549
  validation loss:		0.199124
  validation accuracy:		94.46 %
Epoch 207 of 2000 took 0.113s
  training loss:		0.123036
  validation loss:		0.203991
  validation accuracy:		94.02 %
Epoch 208 of 2000 took 0.136s
  training loss:		0.121012
  validation loss:		0.198677
  validation accuracy:		94.57 %
Epoch 209 of 2000 took 0.124s
  training loss:		0.121153
  validation loss:		0.197972
  validation accuracy:		95.00 %
Epoch 210 of 2000 took 0.122s
  training loss:		0.120240
  validation loss:		0.197826
  validation accuracy:		94.24 %
Epoch 211 of 2000 took 0.106s
  training loss:		0.120105
  validation loss:		0.196619
  validation accuracy:		94.67 %
Epoch 212 of 2000 took 0.124s
  training loss:		0.122172
  validation loss:		0.201029
  validation accuracy:		94.35 %
Epoch 213 of 2000 took 0.122s
  training loss:		0.120419
  validation loss:		0.202128
  validation accuracy:		94.24 %
Epoch 214 of 2000 took 0.139s
  training loss:		0.118879
  validation loss:		0.196885
  validation accuracy:		94.13 %
Epoch 215 of 2000 took 0.112s
  training loss:		0.120579
  validation loss:		0.200707
  validation accuracy:		94.78 %
Epoch 216 of 2000 took 0.124s
  training loss:		0.118086
  validation loss:		0.198142
  validation accuracy:		94.46 %
Epoch 217 of 2000 took 0.128s
  training loss:		0.115707
  validation loss:		0.201876
  validation accuracy:		94.57 %
Epoch 218 of 2000 took 0.114s
  training loss:		0.114933
  validation loss:		0.198027
  validation accuracy:		94.57 %
Epoch 219 of 2000 took 0.120s
  training loss:		0.119636
  validation loss:		0.200441
  validation accuracy:		94.78 %
Epoch 220 of 2000 took 0.122s
  training loss:		0.117088
  validation loss:		0.199353
  validation accuracy:		94.67 %
Epoch 221 of 2000 took 0.129s
  training loss:		0.115403
  validation loss:		0.196135
  validation accuracy:		94.46 %
Epoch 222 of 2000 took 0.112s
  training loss:		0.116529
  validation loss:		0.203782
  validation accuracy:		94.24 %
Epoch 223 of 2000 took 0.121s
  training loss:		0.118581
  validation loss:		0.198525
  validation accuracy:		94.35 %
Epoch 224 of 2000 took 0.123s
  training loss:		0.116124
  validation loss:		0.200713
  validation accuracy:		94.13 %
Epoch 225 of 2000 took 0.099s
  training loss:		0.114580
  validation loss:		0.196360
  validation accuracy:		94.89 %
Epoch 226 of 2000 took 0.124s
  training loss:		0.112761
  validation loss:		0.199028
  validation accuracy:		94.57 %
Epoch 227 of 2000 took 0.123s
  training loss:		0.111873
  validation loss:		0.202905
  validation accuracy:		94.24 %
Epoch 228 of 2000 took 0.129s
  training loss:		0.113525
  validation loss:		0.190126
  validation accuracy:		94.89 %
Epoch 229 of 2000 took 0.172s
  training loss:		0.113333
  validation loss:		0.202086
  validation accuracy:		94.46 %
Epoch 230 of 2000 took 0.164s
  training loss:		0.110560
  validation loss:		0.203263
  validation accuracy:		94.02 %
Epoch 231 of 2000 took 0.155s
  training loss:		0.110690
  validation loss:		0.204621
  validation accuracy:		94.02 %
Epoch 232 of 2000 took 0.158s
  training loss:		0.113366
  validation loss:		0.196406
  validation accuracy:		94.67 %
Epoch 233 of 2000 took 0.153s
  training loss:		0.111027
  validation loss:		0.198862
  validation accuracy:		94.67 %
Epoch 234 of 2000 took 0.134s
  training loss:		0.109530
  validation loss:		0.201134
  validation accuracy:		94.46 %
Epoch 235 of 2000 took 0.200s
  training loss:		0.109391
  validation loss:		0.196976
  validation accuracy:		94.57 %
Epoch 236 of 2000 took 0.112s
  training loss:		0.110319
  validation loss:		0.196490
  validation accuracy:		94.67 %
Epoch 237 of 2000 took 0.152s
  training loss:		0.108531
  validation loss:		0.202312
  validation accuracy:		94.35 %
Epoch 238 of 2000 took 0.196s
  training loss:		0.108529
  validation loss:		0.192338
  validation accuracy:		94.89 %
Epoch 239 of 2000 took 0.155s
  training loss:		0.110642
  validation loss:		0.199583
  validation accuracy:		94.67 %
Epoch 240 of 2000 took 0.115s
  training loss:		0.109072
  validation loss:		0.200577
  validation accuracy:		94.67 %
Epoch 241 of 2000 took 0.186s
  training loss:		0.106459
  validation loss:		0.198390
  validation accuracy:		94.35 %
Epoch 242 of 2000 took 0.154s
  training loss:		0.107299
  validation loss:		0.199177
  validation accuracy:		94.57 %
Epoch 243 of 2000 took 0.248s
  training loss:		0.105726
  validation loss:		0.198734
  validation accuracy:		94.78 %
Epoch 244 of 2000 took 0.159s
  training loss:		0.106470
  validation loss:		0.198225
  validation accuracy:		94.78 %
Epoch 245 of 2000 took 0.158s
  training loss:		0.106018
  validation loss:		0.196993
  validation accuracy:		94.67 %
Epoch 246 of 2000 took 0.194s
  training loss:		0.105826
  validation loss:		0.197959
  validation accuracy:		95.00 %
Epoch 247 of 2000 took 0.188s
  training loss:		0.105423
  validation loss:		0.199935
  validation accuracy:		94.35 %
Epoch 248 of 2000 took 0.159s
  training loss:		0.102539
  validation loss:		0.200556
  validation accuracy:		94.46 %
Epoch 249 of 2000 took 0.197s
  training loss:		0.104526
  validation loss:		0.193860
  validation accuracy:		94.89 %
Epoch 250 of 2000 took 0.187s
  training loss:		0.106662
  validation loss:		0.201173
  validation accuracy:		94.57 %
Epoch 251 of 2000 took 0.167s
  training loss:		0.104683
  validation loss:		0.203251
  validation accuracy:		94.35 %
Epoch 252 of 2000 took 0.128s
  training loss:		0.106887
  validation loss:		0.195859
  validation accuracy:		94.67 %
Epoch 253 of 2000 took 0.175s
  training loss:		0.102413
  validation loss:		0.202363
  validation accuracy:		94.78 %
Epoch 254 of 2000 took 0.199s
  training loss:		0.101668
  validation loss:		0.192946
  validation accuracy:		95.11 %
Epoch 255 of 2000 took 0.217s
  training loss:		0.100735
  validation loss:		0.201857
  validation accuracy:		94.35 %
Epoch 256 of 2000 took 0.203s
  training loss:		0.101971
  validation loss:		0.197718
  validation accuracy:		94.78 %
Epoch 257 of 2000 took 0.137s
  training loss:		0.101669
  validation loss:		0.196776
  validation accuracy:		94.46 %
Epoch 258 of 2000 took 0.183s
  training loss:		0.102780
  validation loss:		0.200756
  validation accuracy:		94.35 %
Epoch 259 of 2000 took 0.172s
  training loss:		0.101459
  validation loss:		0.197094
  validation accuracy:		94.89 %
Epoch 260 of 2000 took 0.184s
  training loss:		0.100195
  validation loss:		0.195825
  validation accuracy:		94.57 %
Epoch 261 of 2000 took 0.167s
  training loss:		0.099147
  validation loss:		0.193673
  validation accuracy:		94.89 %
Epoch 262 of 2000 took 0.174s
  training loss:		0.098163
  validation loss:		0.203219
  validation accuracy:		94.57 %
Epoch 263 of 2000 took 0.187s
  training loss:		0.101178
  validation loss:		0.206655
  validation accuracy:		94.24 %
Epoch 264 of 2000 took 0.177s
  training loss:		0.100081
  validation loss:		0.201466
  validation accuracy:		94.67 %
Epoch 265 of 2000 took 0.197s
  training loss:		0.098001
  validation loss:		0.204185
  validation accuracy:		94.57 %
Epoch 266 of 2000 took 0.205s
  training loss:		0.099911
  validation loss:		0.202567
  validation accuracy:		94.57 %
Epoch 267 of 2000 took 0.221s
  training loss:		0.098964
  validation loss:		0.196033
  validation accuracy:		94.78 %
Epoch 268 of 2000 took 0.216s
  training loss:		0.097340
  validation loss:		0.196553
  validation accuracy:		94.78 %
Epoch 269 of 2000 took 0.202s
  training loss:		0.097735
  validation loss:		0.200523
  validation accuracy:		94.35 %
Epoch 270 of 2000 took 0.221s
  training loss:		0.097046
  validation loss:		0.196029
  validation accuracy:		94.89 %
Epoch 271 of 2000 took 0.220s
  training loss:		0.098253
  validation loss:		0.207963
  validation accuracy:		94.35 %
Epoch 272 of 2000 took 0.241s
  training loss:		0.098273
  validation loss:		0.198110
  validation accuracy:		94.78 %
Epoch 273 of 2000 took 0.180s
  training loss:		0.095289
  validation loss:		0.199881
  validation accuracy:		94.46 %
Epoch 274 of 2000 took 0.148s
  training loss:		0.095312
  validation loss:		0.201054
  validation accuracy:		94.67 %
Epoch 275 of 2000 took 0.166s
  training loss:		0.093505
  validation loss:		0.196985
  validation accuracy:		94.78 %
Epoch 276 of 2000 took 0.168s
  training loss:		0.096948
  validation loss:		0.204152
  validation accuracy:		94.02 %
Epoch 277 of 2000 took 0.171s
  training loss:		0.096031
  validation loss:		0.196113
  validation accuracy:		94.78 %
Epoch 278 of 2000 took 0.171s
  training loss:		0.097155
  validation loss:		0.205436
  validation accuracy:		94.35 %
Epoch 279 of 2000 took 0.132s
  training loss:		0.095702
  validation loss:		0.197292
  validation accuracy:		94.46 %
Epoch 280 of 2000 took 0.151s
  training loss:		0.095004
  validation loss:		0.201308
  validation accuracy:		94.67 %
Epoch 281 of 2000 took 0.121s
  training loss:		0.091878
  validation loss:		0.212621
  validation accuracy:		94.24 %
Epoch 282 of 2000 took 0.239s
  training loss:		0.094520
  validation loss:		0.198714
  validation accuracy:		94.89 %
Epoch 283 of 2000 took 0.214s
  training loss:		0.094311
  validation loss:		0.206642
  validation accuracy:		94.46 %
Epoch 284 of 2000 took 0.236s
  training loss:		0.089862
  validation loss:		0.209778
  validation accuracy:		94.02 %
Epoch 285 of 2000 took 0.177s
  training loss:		0.093125
  validation loss:		0.201531
  validation accuracy:		94.24 %
Epoch 286 of 2000 took 0.093s
  training loss:		0.094179
  validation loss:		0.201470
  validation accuracy:		94.24 %
Epoch 287 of 2000 took 0.071s
  training loss:		0.092534
  validation loss:		0.202039
  validation accuracy:		94.89 %
Epoch 288 of 2000 took 0.093s
  training loss:		0.090039
  validation loss:		0.205623
  validation accuracy:		94.67 %
Epoch 289 of 2000 took 0.109s
  training loss:		0.089609
  validation loss:		0.199820
  validation accuracy:		94.46 %
Epoch 290 of 2000 took 0.111s
  training loss:		0.091951
  validation loss:		0.203945
  validation accuracy:		94.57 %
Epoch 291 of 2000 took 0.130s
  training loss:		0.089902
  validation loss:		0.200186
  validation accuracy:		94.78 %
Epoch 292 of 2000 took 0.128s
  training loss:		0.090265
  validation loss:		0.198015
  validation accuracy:		94.46 %
Epoch 293 of 2000 took 0.128s
  training loss:		0.092140
  validation loss:		0.203578
  validation accuracy:		94.57 %
Epoch 294 of 2000 took 0.122s
  training loss:		0.090339
  validation loss:		0.202790
  validation accuracy:		94.02 %
Epoch 295 of 2000 took 0.119s
  training loss:		0.085586
  validation loss:		0.205038
  validation accuracy:		94.57 %
Epoch 296 of 2000 took 0.123s
  training loss:		0.089779
  validation loss:		0.197623
  validation accuracy:		94.89 %
Epoch 297 of 2000 took 0.114s
  training loss:		0.087724
  validation loss:		0.202324
  validation accuracy:		94.46 %
Epoch 298 of 2000 took 0.119s
  training loss:		0.091822
  validation loss:		0.195940
  validation accuracy:		94.78 %
Epoch 299 of 2000 took 0.122s
  training loss:		0.088255
  validation loss:		0.197588
  validation accuracy:		94.78 %
Epoch 300 of 2000 took 0.119s
  training loss:		0.086967
  validation loss:		0.200500
  validation accuracy:		94.57 %
Epoch 301 of 2000 took 0.125s
  training loss:		0.088968
  validation loss:		0.199480
  validation accuracy:		94.78 %
Epoch 302 of 2000 took 0.127s
  training loss:		0.087786
  validation loss:		0.202581
  validation accuracy:		94.46 %
Epoch 303 of 2000 took 0.132s
  training loss:		0.089998
  validation loss:		0.203388
  validation accuracy:		94.46 %
Epoch 304 of 2000 took 0.128s
  training loss:		0.086997
  validation loss:		0.205697
  validation accuracy:		94.46 %
Epoch 305 of 2000 took 0.125s
  training loss:		0.085383
  validation loss:		0.207632
  validation accuracy:		94.02 %
Epoch 306 of 2000 took 0.129s
  training loss:		0.086507
  validation loss:		0.203561
  validation accuracy:		94.78 %
Epoch 307 of 2000 took 0.132s
  training loss:		0.085950
  validation loss:		0.201595
  validation accuracy:		94.67 %
Epoch 308 of 2000 took 0.135s
  training loss:		0.084549
  validation loss:		0.211080
  validation accuracy:		94.46 %
Epoch 309 of 2000 took 0.137s
  training loss:		0.086619
  validation loss:		0.206292
  validation accuracy:		94.02 %
Epoch 310 of 2000 took 0.139s
  training loss:		0.085611
  validation loss:		0.204933
  validation accuracy:		94.35 %
Epoch 311 of 2000 took 0.144s
  training loss:		0.087290
  validation loss:		0.217407
  validation accuracy:		93.91 %
Epoch 312 of 2000 took 0.138s
  training loss:		0.086073
  validation loss:		0.206966
  validation accuracy:		94.35 %
Epoch 313 of 2000 took 0.133s
  training loss:		0.085376
  validation loss:		0.205834
  validation accuracy:		94.35 %
Epoch 314 of 2000 took 0.143s
  training loss:		0.082182
  validation loss:		0.198040
  validation accuracy:		94.78 %
Epoch 315 of 2000 took 0.138s
  training loss:		0.081060
  validation loss:		0.200379
  validation accuracy:		94.57 %
Epoch 316 of 2000 took 0.173s
  training loss:		0.083725
  validation loss:		0.205593
  validation accuracy:		94.78 %
Epoch 317 of 2000 took 0.163s
  training loss:		0.083692
  validation loss:		0.217561
  validation accuracy:		94.13 %
Epoch 318 of 2000 took 0.143s
  training loss:		0.084142
  validation loss:		0.205289
  validation accuracy:		94.57 %
Epoch 319 of 2000 took 0.135s
  training loss:		0.084003
  validation loss:		0.197283
  validation accuracy:		94.35 %
Epoch 320 of 2000 took 0.142s
  training loss:		0.083754
  validation loss:		0.201527
  validation accuracy:		94.35 %
Epoch 321 of 2000 took 0.144s
  training loss:		0.081086
  validation loss:		0.199180
  validation accuracy:		94.57 %
Epoch 322 of 2000 took 0.153s
  training loss:		0.082725
  validation loss:		0.199133
  validation accuracy:		94.78 %
Epoch 323 of 2000 took 0.139s
  training loss:		0.081061
  validation loss:		0.203626
  validation accuracy:		94.57 %
Epoch 324 of 2000 took 0.128s
  training loss:		0.080160
  validation loss:		0.211637
  validation accuracy:		94.13 %
Epoch 325 of 2000 took 0.144s
  training loss:		0.079654
  validation loss:		0.212926
  validation accuracy:		93.59 %
Epoch 326 of 2000 took 0.160s
  training loss:		0.082052
  validation loss:		0.210114
  validation accuracy:		94.35 %
Epoch 327 of 2000 took 0.175s
  training loss:		0.081544
  validation loss:		0.207569
  validation accuracy:		94.46 %
Epoch 328 of 2000 took 0.147s
  training loss:		0.081738
  validation loss:		0.208348
  validation accuracy:		94.46 %
Epoch 329 of 2000 took 0.134s
  training loss:		0.078690
  validation loss:		0.203214
  validation accuracy:		94.46 %
Epoch 330 of 2000 took 0.135s
  training loss:		0.080603
  validation loss:		0.203611
  validation accuracy:		94.57 %
Epoch 331 of 2000 took 0.144s
  training loss:		0.081429
  validation loss:		0.200321
  validation accuracy:		94.57 %
Epoch 332 of 2000 took 0.140s
  training loss:		0.080637
  validation loss:		0.210297
  validation accuracy:		94.24 %
Epoch 333 of 2000 took 0.144s
  training loss:		0.079639
  validation loss:		0.206535
  validation accuracy:		94.46 %
Epoch 334 of 2000 took 0.176s
  training loss:		0.081180
  validation loss:		0.207459
  validation accuracy:		94.24 %
Epoch 335 of 2000 took 0.175s
  training loss:		0.076523
  validation loss:		0.206466
  validation accuracy:		94.35 %
Epoch 336 of 2000 took 0.162s
  training loss:		0.080748
  validation loss:		0.205131
  validation accuracy:		94.24 %
Epoch 337 of 2000 took 0.129s
  training loss:		0.079181
  validation loss:		0.205584
  validation accuracy:		94.02 %
Epoch 338 of 2000 took 0.144s
  training loss:		0.078603
  validation loss:		0.208927
  validation accuracy:		94.46 %
Epoch 339 of 2000 took 0.156s
  training loss:		0.079471
  validation loss:		0.201132
  validation accuracy:		94.57 %
Epoch 340 of 2000 took 0.155s
  training loss:		0.079333
  validation loss:		0.206875
  validation accuracy:		94.57 %
Epoch 341 of 2000 took 0.140s
  training loss:		0.077485
  validation loss:		0.209588
  validation accuracy:		93.91 %
Epoch 342 of 2000 took 0.176s
  training loss:		0.073354
  validation loss:		0.209079
  validation accuracy:		94.46 %
Epoch 343 of 2000 took 0.175s
  training loss:		0.076510
  validation loss:		0.207009
  validation accuracy:		94.35 %
Epoch 344 of 2000 took 0.175s
  training loss:		0.074569
  validation loss:		0.208634
  validation accuracy:		94.02 %
Epoch 345 of 2000 took 0.135s
  training loss:		0.073394
  validation loss:		0.205637
  validation accuracy:		94.78 %
Epoch 346 of 2000 took 0.130s
  training loss:		0.076580
  validation loss:		0.208428
  validation accuracy:		94.89 %
Epoch 347 of 2000 took 0.152s
  training loss:		0.076098
  validation loss:		0.208310
  validation accuracy:		94.35 %
Epoch 348 of 2000 took 0.135s
  training loss:		0.076549
  validation loss:		0.211112
  validation accuracy:		94.02 %
Epoch 349 of 2000 took 0.141s
  training loss:		0.074718
  validation loss:		0.208344
  validation accuracy:		94.35 %
Epoch 350 of 2000 took 0.135s
  training loss:		0.075095
  validation loss:		0.209738
  validation accuracy:		94.46 %
Epoch 351 of 2000 took 0.134s
  training loss:		0.075625
  validation loss:		0.211793
  validation accuracy:		94.35 %
Epoch 352 of 2000 took 0.139s
  training loss:		0.073116
  validation loss:		0.214173
  validation accuracy:		94.35 %
Epoch 353 of 2000 took 0.142s
  training loss:		0.074573
  validation loss:		0.203879
  validation accuracy:		94.24 %
Epoch 354 of 2000 took 0.176s
  training loss:		0.071779
  validation loss:		0.211394
  validation accuracy:		94.46 %
Epoch 355 of 2000 took 0.170s
  training loss:		0.074177
  validation loss:		0.211366
  validation accuracy:		94.35 %
Epoch 356 of 2000 took 0.175s
  training loss:		0.072312
  validation loss:		0.207648
  validation accuracy:		94.35 %
Epoch 357 of 2000 took 0.169s
  training loss:		0.074752
  validation loss:		0.212311
  validation accuracy:		94.13 %
Epoch 358 of 2000 took 0.148s
  training loss:		0.071199
  validation loss:		0.204026
  validation accuracy:		94.89 %
Epoch 359 of 2000 took 0.142s
  training loss:		0.073326
  validation loss:		0.208667
  validation accuracy:		94.46 %
Epoch 360 of 2000 took 0.150s
  training loss:		0.072941
  validation loss:		0.205872
  validation accuracy:		94.46 %
Epoch 361 of 2000 took 0.150s
  training loss:		0.073557
  validation loss:		0.205295
  validation accuracy:		94.46 %
Epoch 362 of 2000 took 0.164s
  training loss:		0.070228
  validation loss:		0.212391
  validation accuracy:		94.13 %
Epoch 363 of 2000 took 0.145s
  training loss:		0.072684
  validation loss:		0.209882
  validation accuracy:		93.91 %
Epoch 364 of 2000 took 0.170s
  training loss:		0.072628
  validation loss:		0.210094
  validation accuracy:		94.13 %
Epoch 365 of 2000 took 0.165s
  training loss:		0.072339
  validation loss:		0.213172
  validation accuracy:		94.35 %
Epoch 366 of 2000 took 0.137s
  training loss:		0.072505
  validation loss:		0.211382
  validation accuracy:		94.24 %
Epoch 367 of 2000 took 0.134s
  training loss:		0.071018
  validation loss:		0.210542
  validation accuracy:		94.57 %
Epoch 368 of 2000 took 0.163s
  training loss:		0.072012
  validation loss:		0.209069
  validation accuracy:		94.02 %
Epoch 369 of 2000 took 0.180s
  training loss:		0.071633
  validation loss:		0.209866
  validation accuracy:		94.02 %
Epoch 370 of 2000 took 0.165s
  training loss:		0.072914
  validation loss:		0.214253
  validation accuracy:		93.91 %
Epoch 371 of 2000 took 0.142s
  training loss:		0.070251
  validation loss:		0.210924
  validation accuracy:		94.13 %
Epoch 372 of 2000 took 0.136s
  training loss:		0.069722
  validation loss:		0.216968
  validation accuracy:		94.02 %
Epoch 373 of 2000 took 0.138s
  training loss:		0.069719
  validation loss:		0.208793
  validation accuracy:		94.02 %
Epoch 374 of 2000 took 0.171s
  training loss:		0.071016
  validation loss:		0.213990
  validation accuracy:		93.91 %
Epoch 375 of 2000 took 0.174s
  training loss:		0.070350
  validation loss:		0.207422
  validation accuracy:		94.46 %
Epoch 376 of 2000 took 0.159s
  training loss:		0.069046
  validation loss:		0.213253
  validation accuracy:		94.02 %
Epoch 377 of 2000 took 0.166s
  training loss:		0.067742
  validation loss:		0.209776
  validation accuracy:		94.46 %
Epoch 378 of 2000 took 0.175s
  training loss:		0.069780
  validation loss:		0.220172
  validation accuracy:		94.35 %
Epoch 379 of 2000 took 0.158s
  training loss:		0.067095
  validation loss:		0.212420
  validation accuracy:		94.24 %
Epoch 380 of 2000 took 0.161s
  training loss:		0.067881
  validation loss:		0.214868
  validation accuracy:		94.02 %
Epoch 381 of 2000 took 0.175s
  training loss:		0.068695
  validation loss:		0.213950
  validation accuracy:		94.02 %
Epoch 382 of 2000 took 0.176s
  training loss:		0.068508
  validation loss:		0.207996
  validation accuracy:		94.24 %
Epoch 383 of 2000 took 0.176s
  training loss:		0.066270
  validation loss:		0.222052
  validation accuracy:		94.02 %
Epoch 384 of 2000 took 0.174s
  training loss:		0.067739
  validation loss:		0.215479
  validation accuracy:		94.13 %
Epoch 385 of 2000 took 0.151s
  training loss:		0.068228
  validation loss:		0.225217
  validation accuracy:		94.02 %
Epoch 386 of 2000 took 0.132s
  training loss:		0.068672
  validation loss:		0.208363
  validation accuracy:		94.67 %
Epoch 387 of 2000 took 0.130s
  training loss:		0.067481
  validation loss:		0.210953
  validation accuracy:		94.13 %
Epoch 388 of 2000 took 0.145s
  training loss:		0.066671
  validation loss:		0.213229
  validation accuracy:		94.13 %
Epoch 389 of 2000 took 0.140s
  training loss:		0.065725
  validation loss:		0.208369
  validation accuracy:		94.02 %
Epoch 390 of 2000 took 0.146s
  training loss:		0.068161
  validation loss:		0.213621
  validation accuracy:		94.02 %
Epoch 391 of 2000 took 0.132s
  training loss:		0.066587
  validation loss:		0.215499
  validation accuracy:		94.35 %
Epoch 392 of 2000 took 0.129s
  training loss:		0.066784
  validation loss:		0.209249
  validation accuracy:		94.24 %
Epoch 393 of 2000 took 0.131s
  training loss:		0.064034
  validation loss:		0.212788
  validation accuracy:		94.13 %
Epoch 394 of 2000 took 0.164s
  training loss:		0.066438
  validation loss:		0.214159
  validation accuracy:		94.35 %
Epoch 395 of 2000 took 0.164s
  training loss:		0.066285
  validation loss:		0.219410
  validation accuracy:		94.02 %
Epoch 396 of 2000 took 0.169s
  training loss:		0.064552
  validation loss:		0.214566
  validation accuracy:		94.24 %
Epoch 397 of 2000 took 0.149s
  training loss:		0.064945
  validation loss:		0.217031
  validation accuracy:		94.13 %
Epoch 398 of 2000 took 0.124s
  training loss:		0.065027
  validation loss:		0.218594
  validation accuracy:		94.24 %
Epoch 399 of 2000 took 0.145s
  training loss:		0.063696
  validation loss:		0.211067
  validation accuracy:		94.13 %
Epoch 400 of 2000 took 0.173s
  training loss:		0.062466
  validation loss:		0.216900
  validation accuracy:		94.13 %
Epoch 401 of 2000 took 0.156s
  training loss:		0.062629
  validation loss:		0.214833
  validation accuracy:		94.35 %
Epoch 402 of 2000 took 0.153s
  training loss:		0.066075
  validation loss:		0.210770
  validation accuracy:		94.35 %
Epoch 403 of 2000 took 0.141s
  training loss:		0.063321
  validation loss:		0.212825
  validation accuracy:		94.13 %
Epoch 404 of 2000 took 0.138s
  training loss:		0.065402
  validation loss:		0.217625
  validation accuracy:		94.24 %
Epoch 405 of 2000 took 0.137s
  training loss:		0.064699
  validation loss:		0.218092
  validation accuracy:		93.91 %
Epoch 406 of 2000 took 0.147s
  training loss:		0.059549
  validation loss:		0.216683
  validation accuracy:		94.13 %
Epoch 407 of 2000 took 0.163s
  training loss:		0.063589
  validation loss:		0.219820
  validation accuracy:		94.24 %
Epoch 408 of 2000 took 0.166s
  training loss:		0.063657
  validation loss:		0.217000
  validation accuracy:		94.13 %
Epoch 409 of 2000 took 0.159s
  training loss:		0.064288
  validation loss:		0.227738
  validation accuracy:		94.02 %
Epoch 410 of 2000 took 0.158s
  training loss:		0.063471
  validation loss:		0.226184
  validation accuracy:		93.70 %
Epoch 411 of 2000 took 0.167s
  training loss:		0.063637
  validation loss:		0.210501
  validation accuracy:		94.24 %
Epoch 412 of 2000 took 0.171s
  training loss:		0.063025
  validation loss:		0.220396
  validation accuracy:		94.02 %
Epoch 413 of 2000 took 0.176s
  training loss:		0.063518
  validation loss:		0.214489
  validation accuracy:		94.24 %
Epoch 414 of 2000 took 0.175s
  training loss:		0.061208
  validation loss:		0.225678
  validation accuracy:		93.70 %
Epoch 415 of 2000 took 0.175s
  training loss:		0.062658
  validation loss:		0.219744
  validation accuracy:		94.24 %
Epoch 416 of 2000 took 0.161s
  training loss:		0.063327
  validation loss:		0.216466
  validation accuracy:		94.24 %
Epoch 417 of 2000 took 0.147s
  training loss:		0.060137
  validation loss:		0.217592
  validation accuracy:		94.35 %
Epoch 418 of 2000 took 0.165s
  training loss:		0.061305
  validation loss:		0.222703
  validation accuracy:		93.91 %
Epoch 419 of 2000 took 0.147s
  training loss:		0.062143
  validation loss:		0.220911
  validation accuracy:		93.80 %
Epoch 420 of 2000 took 0.135s
  training loss:		0.060802
  validation loss:		0.220217
  validation accuracy:		93.91 %
Epoch 421 of 2000 took 0.142s
  training loss:		0.060320
  validation loss:		0.228587
  validation accuracy:		93.80 %
Epoch 422 of 2000 took 0.142s
  training loss:		0.060962
  validation loss:		0.223068
  validation accuracy:		93.91 %
Epoch 423 of 2000 took 0.173s
  training loss:		0.058554
  validation loss:		0.220717
  validation accuracy:		94.02 %
Epoch 424 of 2000 took 0.170s
  training loss:		0.059148
  validation loss:		0.224898
  validation accuracy:		93.91 %
Epoch 425 of 2000 took 0.168s
  training loss:		0.060371
  validation loss:		0.218737
  validation accuracy:		93.91 %
Epoch 426 of 2000 took 0.138s
  training loss:		0.060524
  validation loss:		0.221265
  validation accuracy:		94.02 %
Epoch 427 of 2000 took 0.139s
  training loss:		0.060003
  validation loss:		0.218915
  validation accuracy:		93.80 %
Epoch 428 of 2000 took 0.139s
  training loss:		0.059037
  validation loss:		0.231540
  validation accuracy:		93.70 %
Epoch 429 of 2000 took 0.143s
  training loss:		0.058408
  validation loss:		0.218297
  validation accuracy:		94.02 %
Epoch 430 of 2000 took 0.135s
  training loss:		0.057631
  validation loss:		0.221778
  validation accuracy:		93.91 %
Epoch 431 of 2000 took 0.138s
  training loss:		0.059300
  validation loss:		0.222380
  validation accuracy:		93.91 %
Epoch 432 of 2000 took 0.139s
  training loss:		0.059672
  validation loss:		0.227983
  validation accuracy:		93.91 %
Epoch 433 of 2000 took 0.126s
  training loss:		0.059321
  validation loss:		0.227063
  validation accuracy:		93.80 %
Epoch 434 of 2000 took 0.148s
  training loss:		0.057946
  validation loss:		0.222170
  validation accuracy:		93.91 %
Epoch 435 of 2000 took 0.162s
  training loss:		0.058069
  validation loss:		0.222502
  validation accuracy:		93.80 %
Epoch 436 of 2000 took 0.170s
  training loss:		0.057624
  validation loss:		0.222969
  validation accuracy:		94.13 %
Epoch 437 of 2000 took 0.171s
  training loss:		0.057635
  validation loss:		0.225056
  validation accuracy:		93.91 %
Epoch 438 of 2000 took 0.174s
  training loss:		0.057837
  validation loss:		0.227218
  validation accuracy:		93.80 %
Epoch 439 of 2000 took 0.171s
  training loss:		0.058463
  validation loss:		0.225054
  validation accuracy:		94.02 %
Epoch 440 of 2000 took 0.173s
  training loss:		0.057085
  validation loss:		0.222104
  validation accuracy:		93.80 %
Epoch 441 of 2000 took 0.156s
  training loss:		0.055726
  validation loss:		0.224226
  validation accuracy:		93.91 %
Epoch 442 of 2000 took 0.135s
  training loss:		0.058970
  validation loss:		0.226867
  validation accuracy:		94.02 %
Epoch 443 of 2000 took 0.140s
  training loss:		0.057682
  validation loss:		0.230726
  validation accuracy:		94.02 %
Epoch 444 of 2000 took 0.139s
  training loss:		0.055648
  validation loss:		0.229095
  validation accuracy:		94.13 %
Epoch 445 of 2000 took 0.135s
  training loss:		0.057938
  validation loss:		0.216390
  validation accuracy:		94.13 %
Epoch 446 of 2000 took 0.165s
  training loss:		0.057847
  validation loss:		0.221881
  validation accuracy:		93.91 %
Epoch 447 of 2000 took 0.176s
  training loss:		0.056942
  validation loss:		0.220134
  validation accuracy:		93.80 %
Epoch 448 of 2000 took 0.176s
  training loss:		0.055496
  validation loss:		0.229972
  validation accuracy:		93.70 %
Epoch 449 of 2000 took 0.176s
  training loss:		0.055753
  validation loss:		0.231898
  validation accuracy:		93.91 %
Epoch 450 of 2000 took 0.165s
  training loss:		0.057367
  validation loss:		0.224134
  validation accuracy:		93.70 %
Epoch 451 of 2000 took 0.164s
  training loss:		0.054519
  validation loss:		0.222061
  validation accuracy:		94.13 %
Epoch 452 of 2000 took 0.134s
  training loss:		0.053614
  validation loss:		0.219935
  validation accuracy:		93.91 %
Epoch 453 of 2000 took 0.135s
  training loss:		0.056798
  validation loss:		0.229278
  validation accuracy:		93.48 %
Epoch 454 of 2000 took 0.153s
  training loss:		0.054295
  validation loss:		0.221057
  validation accuracy:		94.13 %
Epoch 455 of 2000 took 0.171s
  training loss:		0.056185
  validation loss:		0.225437
  validation accuracy:		93.70 %
Epoch 456 of 2000 took 0.138s
  training loss:		0.055976
  validation loss:		0.224937
  validation accuracy:		93.91 %
Epoch 457 of 2000 took 0.141s
  training loss:		0.053054
  validation loss:		0.225289
  validation accuracy:		93.91 %
Epoch 458 of 2000 took 0.134s
  training loss:		0.054427
  validation loss:		0.221036
  validation accuracy:		93.91 %
Epoch 459 of 2000 took 0.142s
  training loss:		0.052189
  validation loss:		0.231575
  validation accuracy:		93.70 %
Epoch 460 of 2000 took 0.136s
  training loss:		0.054513
  validation loss:		0.231830
  validation accuracy:		93.80 %
Epoch 461 of 2000 took 0.148s
  training loss:		0.055237
  validation loss:		0.228999
  validation accuracy:		93.70 %
Epoch 462 of 2000 took 0.139s
  training loss:		0.053766
  validation loss:		0.230547
  validation accuracy:		93.91 %
Epoch 463 of 2000 took 0.153s
  training loss:		0.054711
  validation loss:		0.233862
  validation accuracy:		93.80 %
Epoch 464 of 2000 took 0.145s
  training loss:		0.053052
  validation loss:		0.225158
  validation accuracy:		93.91 %
Epoch 465 of 2000 took 0.138s
  training loss:		0.053333
  validation loss:		0.225694
  validation accuracy:		93.91 %
Epoch 466 of 2000 took 0.152s
  training loss:		0.050809
  validation loss:		0.224921
  validation accuracy:		94.02 %
Epoch 467 of 2000 took 0.151s
  training loss:		0.050998
  validation loss:		0.221535
  validation accuracy:		94.02 %
Epoch 468 of 2000 took 0.134s
  training loss:		0.052347
  validation loss:		0.228799
  validation accuracy:		93.91 %
Epoch 469 of 2000 took 0.147s
  training loss:		0.051544
  validation loss:		0.226098
  validation accuracy:		94.13 %
Epoch 470 of 2000 took 0.132s
  training loss:		0.052989
  validation loss:		0.230537
  validation accuracy:		93.59 %
Epoch 471 of 2000 took 0.150s
  training loss:		0.052856
  validation loss:		0.229144
  validation accuracy:		93.80 %
Epoch 472 of 2000 took 0.139s
  training loss:		0.051707
  validation loss:		0.225860
  validation accuracy:		93.91 %
Epoch 473 of 2000 took 0.144s
  training loss:		0.052231
  validation loss:		0.234187
  validation accuracy:		93.70 %
Epoch 474 of 2000 took 0.145s
  training loss:		0.053646
  validation loss:		0.231260
  validation accuracy:		93.59 %
Epoch 475 of 2000 took 0.150s
  training loss:		0.049607
  validation loss:		0.228420
  validation accuracy:		93.80 %
Epoch 476 of 2000 took 0.142s
  training loss:		0.050900
  validation loss:		0.225319
  validation accuracy:		94.13 %
Epoch 477 of 2000 took 0.142s
  training loss:		0.051760
  validation loss:		0.237694
  validation accuracy:		93.48 %
Epoch 478 of 2000 took 0.145s
  training loss:		0.053134
  validation loss:		0.232277
  validation accuracy:		93.59 %
Epoch 479 of 2000 took 0.150s
  training loss:		0.051495
  validation loss:		0.232472
  validation accuracy:		93.80 %
Epoch 480 of 2000 took 0.137s
  training loss:		0.052801
  validation loss:		0.242953
  validation accuracy:		93.48 %
Epoch 481 of 2000 took 0.136s
  training loss:		0.052261
  validation loss:		0.242547
  validation accuracy:		93.70 %
Epoch 482 of 2000 took 0.144s
  training loss:		0.050518
  validation loss:		0.236935
  validation accuracy:		93.59 %
Epoch 483 of 2000 took 0.144s
  training loss:		0.049201
  validation loss:		0.227868
  validation accuracy:		93.80 %
Epoch 484 of 2000 took 0.172s
  training loss:		0.053676
  validation loss:		0.232761
  validation accuracy:		93.70 %
Epoch 485 of 2000 took 0.172s
  training loss:		0.050941
  validation loss:		0.232331
  validation accuracy:		93.80 %
Epoch 486 of 2000 took 0.174s
  training loss:		0.049423
  validation loss:		0.231406
  validation accuracy:		93.80 %
Epoch 487 of 2000 took 0.172s
  training loss:		0.050257
  validation loss:		0.237045
  validation accuracy:		93.48 %
Epoch 488 of 2000 took 0.139s
  training loss:		0.050759
  validation loss:		0.230778
  validation accuracy:		93.91 %
Epoch 489 of 2000 took 0.164s
  training loss:		0.048036
  validation loss:		0.232182
  validation accuracy:		93.59 %
Epoch 490 of 2000 took 0.162s
  training loss:		0.049671
  validation loss:		0.232378
  validation accuracy:		93.70 %
Epoch 491 of 2000 took 0.150s
  training loss:		0.049835
  validation loss:		0.231633
  validation accuracy:		93.91 %
Epoch 492 of 2000 took 0.140s
  training loss:		0.048592
  validation loss:		0.234076
  validation accuracy:		93.48 %
Epoch 493 of 2000 took 0.142s
  training loss:		0.050391
  validation loss:		0.233713
  validation accuracy:		93.80 %
Epoch 494 of 2000 took 0.144s
  training loss:		0.048103
  validation loss:		0.238438
  validation accuracy:		93.70 %
Epoch 495 of 2000 took 0.134s
  training loss:		0.051951
  validation loss:		0.247090
  validation accuracy:		93.37 %
Epoch 496 of 2000 took 0.136s
  training loss:		0.048589
  validation loss:		0.237055
  validation accuracy:		93.70 %
Epoch 497 of 2000 took 0.176s
  training loss:		0.049798
  validation loss:		0.235639
  validation accuracy:		93.70 %
Epoch 498 of 2000 took 0.152s
  training loss:		0.047776
  validation loss:		0.237442
  validation accuracy:		93.80 %
Epoch 499 of 2000 took 0.129s
  training loss:		0.049434
  validation loss:		0.232988
  validation accuracy:		93.80 %
Epoch 500 of 2000 took 0.145s
  training loss:		0.050052
  validation loss:		0.231380
  validation accuracy:		93.70 %
Epoch 501 of 2000 took 0.162s
  training loss:		0.048852
  validation loss:		0.240175
  validation accuracy:		93.59 %
Epoch 502 of 2000 took 0.141s
  training loss:		0.047993
  validation loss:		0.238202
  validation accuracy:		93.70 %
Epoch 503 of 2000 took 0.141s
  training loss:		0.048722
  validation loss:		0.246670
  validation accuracy:		93.70 %
Epoch 504 of 2000 took 0.134s
  training loss:		0.048910
  validation loss:		0.245859
  validation accuracy:		93.48 %
Epoch 505 of 2000 took 0.137s
  training loss:		0.047978
  validation loss:		0.239271
  validation accuracy:		93.59 %
Epoch 506 of 2000 took 0.135s
  training loss:		0.047871
  validation loss:		0.232130
  validation accuracy:		93.80 %
Epoch 507 of 2000 took 0.140s
  training loss:		0.049398
  validation loss:		0.253506
  validation accuracy:		93.37 %
Epoch 508 of 2000 took 0.137s
  training loss:		0.048516
  validation loss:		0.235586
  validation accuracy:		93.70 %
Epoch 509 of 2000 took 0.134s
  training loss:		0.047969
  validation loss:		0.240065
  validation accuracy:		93.48 %
Epoch 510 of 2000 took 0.157s
  training loss:		0.046489
  validation loss:		0.234425
  validation accuracy:		93.70 %
Epoch 511 of 2000 took 0.145s
  training loss:		0.047919
  validation loss:		0.237873
  validation accuracy:		93.70 %
Epoch 512 of 2000 took 0.171s
  training loss:		0.047626
  validation loss:		0.243975
  validation accuracy:		93.26 %
Epoch 513 of 2000 took 0.170s
  training loss:		0.047792
  validation loss:		0.245815
  validation accuracy:		93.48 %
Epoch 514 of 2000 took 0.167s
  training loss:		0.045858
  validation loss:		0.240366
  validation accuracy:		93.48 %
Epoch 515 of 2000 took 0.173s
  training loss:		0.047469
  validation loss:		0.240033
  validation accuracy:		93.70 %
Epoch 516 of 2000 took 0.177s
  training loss:		0.044594
  validation loss:		0.241671
  validation accuracy:		93.70 %
Epoch 517 of 2000 took 0.160s
  training loss:		0.047199
  validation loss:		0.241002
  validation accuracy:		93.37 %
Epoch 518 of 2000 took 0.173s
  training loss:		0.046346
  validation loss:		0.237836
  validation accuracy:		93.70 %
Epoch 519 of 2000 took 0.136s
  training loss:		0.045746
  validation loss:		0.248941
  validation accuracy:		93.59 %
Epoch 520 of 2000 took 0.137s
  training loss:		0.044479
  validation loss:		0.237973
  validation accuracy:		93.48 %
Epoch 521 of 2000 took 0.156s
  training loss:		0.046913
  validation loss:		0.245226
  validation accuracy:		93.80 %
Epoch 522 of 2000 took 0.172s
  training loss:		0.047328
  validation loss:		0.235033
  validation accuracy:		93.80 %
Epoch 523 of 2000 took 0.141s
  training loss:		0.045109
  validation loss:		0.245817
  validation accuracy:		93.37 %
Epoch 524 of 2000 took 0.135s
  training loss:		0.045251
  validation loss:		0.245625
  validation accuracy:		93.37 %
Epoch 525 of 2000 took 0.146s
  training loss:		0.045045
  validation loss:		0.253367
  validation accuracy:		93.37 %
Epoch 526 of 2000 took 0.131s
  training loss:		0.045572
  validation loss:		0.239256
  validation accuracy:		93.48 %
Epoch 527 of 2000 took 0.147s
  training loss:		0.044760
  validation loss:		0.244206
  validation accuracy:		93.59 %
Epoch 528 of 2000 took 0.135s
  training loss:		0.043183
  validation loss:		0.238387
  validation accuracy:		93.80 %
Epoch 529 of 2000 took 0.157s
  training loss:		0.042701
  validation loss:		0.239623
  validation accuracy:		93.80 %
Epoch 530 of 2000 took 0.156s
  training loss:		0.045207
  validation loss:		0.264504
  validation accuracy:		93.04 %
Epoch 531 of 2000 took 0.139s
  training loss:		0.045478
  validation loss:		0.238699
  validation accuracy:		93.70 %
Epoch 532 of 2000 took 0.139s
  training loss:		0.043646
  validation loss:		0.241598
  validation accuracy:		93.26 %
Epoch 533 of 2000 took 0.128s
  training loss:		0.044997
  validation loss:		0.244031
  validation accuracy:		93.48 %
Epoch 534 of 2000 took 0.146s
  training loss:		0.044514
  validation loss:		0.248661
  validation accuracy:		93.59 %
Epoch 535 of 2000 took 0.138s
  training loss:		0.044654
  validation loss:		0.249959
  validation accuracy:		93.48 %
Epoch 536 of 2000 took 0.159s
  training loss:		0.043460
  validation loss:		0.251336
  validation accuracy:		93.70 %
Epoch 537 of 2000 took 0.136s
  training loss:		0.043079
  validation loss:		0.246287
  validation accuracy:		93.70 %
Epoch 538 of 2000 took 0.174s
  training loss:		0.045325
  validation loss:		0.238074
  validation accuracy:		93.80 %
Epoch 539 of 2000 took 0.157s
  training loss:		0.042662
  validation loss:		0.244734
  validation accuracy:		93.70 %
Epoch 540 of 2000 took 0.145s
  training loss:		0.044249
  validation loss:		0.251179
  validation accuracy:		93.37 %
Epoch 541 of 2000 took 0.175s
  training loss:		0.044730
  validation loss:		0.241374
  validation accuracy:		93.59 %
Epoch 542 of 2000 took 0.164s
  training loss:		0.043941
  validation loss:		0.251515
  validation accuracy:		93.48 %
Epoch 543 of 2000 took 0.146s
  training loss:		0.043617
  validation loss:		0.253328
  validation accuracy:		93.48 %
Epoch 544 of 2000 took 0.144s
  training loss:		0.043905
  validation loss:		0.261303
  validation accuracy:		93.48 %
Epoch 545 of 2000 took 0.139s
  training loss:		0.042929
  validation loss:		0.249637
  validation accuracy:		93.48 %
Epoch 546 of 2000 took 0.162s
  training loss:		0.042745
  validation loss:		0.241330
  validation accuracy:		93.48 %
Epoch 547 of 2000 took 0.132s
  training loss:		0.042745
  validation loss:		0.246693
  validation accuracy:		93.59 %
Epoch 548 of 2000 took 0.155s
  training loss:		0.043720
  validation loss:		0.246145
  validation accuracy:		93.59 %
Epoch 549 of 2000 took 0.175s
  training loss:		0.041538
  validation loss:		0.246774
  validation accuracy:		93.48 %
Epoch 550 of 2000 took 0.173s
  training loss:		0.042640
  validation loss:		0.250881
  validation accuracy:		93.48 %
Epoch 551 of 2000 took 0.163s
  training loss:		0.041257
  validation loss:		0.260536
  validation accuracy:		93.37 %
Epoch 552 of 2000 took 0.165s
  training loss:		0.040266
  validation loss:		0.251366
  validation accuracy:		93.26 %
Epoch 553 of 2000 took 0.168s
  training loss:		0.043191
  validation loss:		0.260876
  validation accuracy:		93.15 %
Epoch 554 of 2000 took 0.140s
  training loss:		0.042267
  validation loss:		0.250263
  validation accuracy:		93.37 %
Epoch 555 of 2000 took 0.178s
  training loss:		0.043080
  validation loss:		0.245825
  validation accuracy:		93.37 %
Epoch 556 of 2000 took 0.173s
  training loss:		0.041925
  validation loss:		0.253976
  validation accuracy:		93.70 %
Epoch 557 of 2000 took 0.178s
  training loss:		0.040714
  validation loss:		0.238537
  validation accuracy:		93.70 %
Epoch 558 of 2000 took 0.164s
  training loss:		0.042220
  validation loss:		0.250054
  validation accuracy:		93.59 %
Epoch 559 of 2000 took 0.145s
  training loss:		0.040232
  validation loss:		0.249229
  validation accuracy:		93.15 %
Epoch 560 of 2000 took 0.175s
  training loss:		0.039613
  validation loss:		0.250252
  validation accuracy:		93.26 %
Epoch 561 of 2000 took 0.152s
  training loss:		0.042220
  validation loss:		0.247156
  validation accuracy:		93.37 %
Epoch 562 of 2000 took 0.139s
  training loss:		0.041649
  validation loss:		0.255778
  validation accuracy:		93.48 %
Epoch 563 of 2000 took 0.149s
  training loss:		0.041098
  validation loss:		0.249971
  validation accuracy:		93.59 %
Epoch 564 of 2000 took 0.173s
  training loss:		0.041049
  validation loss:		0.257859
  validation accuracy:		93.26 %
Epoch 565 of 2000 took 0.188s
  training loss:		0.040740
  validation loss:		0.247131
  validation accuracy:		93.59 %
Epoch 566 of 2000 took 0.138s
  training loss:		0.040947
  validation loss:		0.253345
  validation accuracy:		93.48 %
Epoch 567 of 2000 took 0.131s
  training loss:		0.041162
  validation loss:		0.252878
  validation accuracy:		93.59 %
Epoch 568 of 2000 took 0.152s
  training loss:		0.041184
  validation loss:		0.248860
  validation accuracy:		93.37 %
Epoch 569 of 2000 took 0.177s
  training loss:		0.040595
  validation loss:		0.248855
  validation accuracy:		93.48 %
Epoch 570 of 2000 took 0.156s
  training loss:		0.040452
  validation loss:		0.249402
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.149s
  training loss:		0.039361
  validation loss:		0.254676
  validation accuracy:		93.48 %
Epoch 572 of 2000 took 0.146s
  training loss:		0.039957
  validation loss:		0.255759
  validation accuracy:		93.59 %
Epoch 573 of 2000 took 0.176s
  training loss:		0.040106
  validation loss:		0.257588
  validation accuracy:		93.15 %
Epoch 574 of 2000 took 0.137s
  training loss:		0.038072
  validation loss:		0.254092
  validation accuracy:		93.48 %
Epoch 575 of 2000 took 0.142s
  training loss:		0.040011
  validation loss:		0.259059
  validation accuracy:		93.26 %
Epoch 576 of 2000 took 0.147s
  training loss:		0.038638
  validation loss:		0.263759
  validation accuracy:		93.15 %
Epoch 577 of 2000 took 0.174s
  training loss:		0.039904
  validation loss:		0.255486
  validation accuracy:		93.26 %
Epoch 578 of 2000 took 0.175s
  training loss:		0.039851
  validation loss:		0.259248
  validation accuracy:		93.59 %
Epoch 579 of 2000 took 0.156s
  training loss:		0.038716
  validation loss:		0.250214
  validation accuracy:		93.48 %
Epoch 580 of 2000 took 0.141s
  training loss:		0.038658
  validation loss:		0.254004
  validation accuracy:		93.48 %
Epoch 581 of 2000 took 0.159s
  training loss:		0.038705
  validation loss:		0.259366
  validation accuracy:		93.26 %
Epoch 582 of 2000 took 0.176s
  training loss:		0.039394
  validation loss:		0.251987
  validation accuracy:		93.37 %
Epoch 583 of 2000 took 0.176s
  training loss:		0.038817
  validation loss:		0.260318
  validation accuracy:		93.48 %
Epoch 584 of 2000 took 0.176s
  training loss:		0.037180
  validation loss:		0.254232
  validation accuracy:		93.48 %
Epoch 585 of 2000 took 0.169s
  training loss:		0.037678
  validation loss:		0.261408
  validation accuracy:		93.04 %
Epoch 586 of 2000 took 0.168s
  training loss:		0.037831
  validation loss:		0.257038
  validation accuracy:		93.26 %
Epoch 587 of 2000 took 0.126s
  training loss:		0.038584
  validation loss:		0.265557
  validation accuracy:		93.15 %
Epoch 588 of 2000 took 0.135s
  training loss:		0.037024
  validation loss:		0.252019
  validation accuracy:		93.37 %
Epoch 589 of 2000 took 0.137s
  training loss:		0.037168
  validation loss:		0.258412
  validation accuracy:		93.48 %
Epoch 590 of 2000 took 0.172s
  training loss:		0.037767
  validation loss:		0.254167
  validation accuracy:		93.37 %
Epoch 591 of 2000 took 0.173s
  training loss:		0.039282
  validation loss:		0.254221
  validation accuracy:		93.26 %
Epoch 592 of 2000 took 0.169s
  training loss:		0.038236
  validation loss:		0.262670
  validation accuracy:		93.15 %
Epoch 593 of 2000 took 0.173s
  training loss:		0.038316
  validation loss:		0.263719
  validation accuracy:		93.26 %
Epoch 594 of 2000 took 0.172s
  training loss:		0.038086
  validation loss:		0.259542
  validation accuracy:		93.26 %
Epoch 595 of 2000 took 0.174s
  training loss:		0.037240
  validation loss:		0.267590
  validation accuracy:		93.37 %
Epoch 596 of 2000 took 0.175s
  training loss:		0.038915
  validation loss:		0.258863
  validation accuracy:		93.48 %
Epoch 597 of 2000 took 0.175s
  training loss:		0.036540
  validation loss:		0.257750
  validation accuracy:		93.37 %
Epoch 598 of 2000 took 0.175s
  training loss:		0.037756
  validation loss:		0.265012
  validation accuracy:		93.48 %
Epoch 599 of 2000 took 0.176s
  training loss:		0.037451
  validation loss:		0.263887
  validation accuracy:		93.37 %
Epoch 600 of 2000 took 0.174s
  training loss:		0.034516
  validation loss:		0.262547
  validation accuracy:		93.26 %
Epoch 601 of 2000 took 0.174s
  training loss:		0.036953
  validation loss:		0.261915
  validation accuracy:		93.04 %
Epoch 602 of 2000 took 0.167s
  training loss:		0.036789
  validation loss:		0.258052
  validation accuracy:		93.48 %
Epoch 603 of 2000 took 0.122s
  training loss:		0.035938
  validation loss:		0.269117
  validation accuracy:		93.26 %
Epoch 604 of 2000 took 0.151s
  training loss:		0.036545
  validation loss:		0.268320
  validation accuracy:		93.48 %
Epoch 605 of 2000 took 0.137s
  training loss:		0.037044
  validation loss:		0.248299
  validation accuracy:		93.48 %
Epoch 606 of 2000 took 0.148s
  training loss:		0.037839
  validation loss:		0.269625
  validation accuracy:		93.26 %
Epoch 607 of 2000 took 0.132s
  training loss:		0.035660
  validation loss:		0.260627
  validation accuracy:		93.48 %
Epoch 608 of 2000 took 0.137s
  training loss:		0.035507
  validation loss:		0.270525
  validation accuracy:		93.15 %
Epoch 609 of 2000 took 0.164s
  training loss:		0.035468
  validation loss:		0.267277
  validation accuracy:		93.37 %
Epoch 610 of 2000 took 0.172s
  training loss:		0.036866
  validation loss:		0.259403
  validation accuracy:		93.26 %
Epoch 611 of 2000 took 0.172s
  training loss:		0.035167
  validation loss:		0.254298
  validation accuracy:		93.48 %
Epoch 612 of 2000 took 0.181s
  training loss:		0.035550
  validation loss:		0.258096
  validation accuracy:		93.48 %
Epoch 613 of 2000 took 0.174s
  training loss:		0.036182
  validation loss:		0.253529
  validation accuracy:		93.37 %
Epoch 614 of 2000 took 0.170s
  training loss:		0.036294
  validation loss:		0.267286
  validation accuracy:		93.48 %
Epoch 615 of 2000 took 0.176s
  training loss:		0.034761
  validation loss:		0.262242
  validation accuracy:		93.37 %
Epoch 616 of 2000 took 0.151s
  training loss:		0.035204
  validation loss:		0.274668
  validation accuracy:		93.37 %
Epoch 617 of 2000 took 0.146s
  training loss:		0.032911
  validation loss:		0.264950
  validation accuracy:		93.37 %
Epoch 618 of 2000 took 0.172s
  training loss:		0.035945
  validation loss:		0.262126
  validation accuracy:		93.37 %
Epoch 619 of 2000 took 0.136s
  training loss:		0.034356
  validation loss:		0.258740
  validation accuracy:		93.26 %
Epoch 620 of 2000 took 0.146s
  training loss:		0.034212
  validation loss:		0.271015
  validation accuracy:		93.26 %
Epoch 621 of 2000 took 0.135s
  training loss:		0.033215
  validation loss:		0.258167
  validation accuracy:		93.37 %
Epoch 622 of 2000 took 0.134s
  training loss:		0.035240
  validation loss:		0.272463
  validation accuracy:		93.04 %
Epoch 623 of 2000 took 0.139s
  training loss:		0.034758
  validation loss:		0.261332
  validation accuracy:		93.37 %
Epoch 624 of 2000 took 0.144s
  training loss:		0.034077
  validation loss:		0.262689
  validation accuracy:		93.48 %
Epoch 625 of 2000 took 0.140s
  training loss:		0.034280
  validation loss:		0.267981
  validation accuracy:		93.26 %
Epoch 626 of 2000 took 0.143s
  training loss:		0.034825
  validation loss:		0.260849
  validation accuracy:		93.37 %
Epoch 627 of 2000 took 0.144s
  training loss:		0.034972
  validation loss:		0.263462
  validation accuracy:		93.04 %
Epoch 628 of 2000 took 0.143s
  training loss:		0.033976
  validation loss:		0.266452
  validation accuracy:		93.26 %
Epoch 629 of 2000 took 0.141s
  training loss:		0.034556
  validation loss:		0.263479
  validation accuracy:		93.26 %
Epoch 630 of 2000 took 0.137s
  training loss:		0.033951
  validation loss:		0.266016
  validation accuracy:		93.37 %
Epoch 631 of 2000 took 0.133s
  training loss:		0.034271
  validation loss:		0.268015
  validation accuracy:		93.37 %
Epoch 632 of 2000 took 0.149s
  training loss:		0.034759
  validation loss:		0.271333
  validation accuracy:		93.37 %
Epoch 633 of 2000 took 0.163s
  training loss:		0.033953
  validation loss:		0.274284
  validation accuracy:		93.37 %
Epoch 634 of 2000 took 0.174s
  training loss:		0.033470
  validation loss:		0.269472
  validation accuracy:		93.26 %
Epoch 635 of 2000 took 0.164s
  training loss:		0.034054
  validation loss:		0.269382
  validation accuracy:		93.26 %
Epoch 636 of 2000 took 0.174s
  training loss:		0.034420
  validation loss:		0.267400
  validation accuracy:		93.48 %
Epoch 637 of 2000 took 0.146s
  training loss:		0.033871
  validation loss:		0.266914
  validation accuracy:		93.04 %
Epoch 638 of 2000 took 0.131s
  training loss:		0.033761
  validation loss:		0.264974
  validation accuracy:		92.93 %
Epoch 639 of 2000 took 0.147s
  training loss:		0.032532
  validation loss:		0.260076
  validation accuracy:		93.26 %
Epoch 640 of 2000 took 0.137s
  training loss:		0.033230
  validation loss:		0.265535
  validation accuracy:		93.04 %
Epoch 641 of 2000 took 0.145s
  training loss:		0.032693
  validation loss:		0.270596
  validation accuracy:		93.37 %
Epoch 642 of 2000 took 0.133s
  training loss:		0.033137
  validation loss:		0.266123
  validation accuracy:		93.04 %
Epoch 643 of 2000 took 0.143s
  training loss:		0.033314
  validation loss:		0.272488
  validation accuracy:		93.15 %
Epoch 644 of 2000 took 0.143s
  training loss:		0.032648
  validation loss:		0.275619
  validation accuracy:		93.26 %
Epoch 645 of 2000 took 0.135s
  training loss:		0.031342
  validation loss:		0.275653
  validation accuracy:		93.04 %
Epoch 646 of 2000 took 0.163s
  training loss:		0.033514
  validation loss:		0.273440
  validation accuracy:		93.37 %
Epoch 647 of 2000 took 0.174s
  training loss:		0.032718
  validation loss:		0.276205
  validation accuracy:		92.93 %
Epoch 648 of 2000 took 0.159s
  training loss:		0.033010
  validation loss:		0.271302
  validation accuracy:		93.37 %
Epoch 649 of 2000 took 0.153s
  training loss:		0.032790
  validation loss:		0.273717
  validation accuracy:		93.15 %
Epoch 650 of 2000 took 0.144s
  training loss:		0.031978
  validation loss:		0.277391
  validation accuracy:		93.04 %
Epoch 651 of 2000 took 0.168s
  training loss:		0.033172
  validation loss:		0.276149
  validation accuracy:		93.26 %
Epoch 652 of 2000 took 0.145s
  training loss:		0.032724
  validation loss:		0.262543
  validation accuracy:		93.15 %
Epoch 653 of 2000 took 0.137s
  training loss:		0.034110
  validation loss:		0.276946
  validation accuracy:		93.04 %
Epoch 654 of 2000 took 0.133s
  training loss:		0.033085
  validation loss:		0.267416
  validation accuracy:		92.72 %
Epoch 655 of 2000 took 0.144s
  training loss:		0.031329
  validation loss:		0.273785
  validation accuracy:		93.26 %
Epoch 656 of 2000 took 0.144s
  training loss:		0.030899
  validation loss:		0.288694
  validation accuracy:		92.83 %
Epoch 657 of 2000 took 0.162s
  training loss:		0.031622
  validation loss:		0.265606
  validation accuracy:		93.15 %
Epoch 658 of 2000 took 0.172s
  training loss:		0.031011
  validation loss:		0.270178
  validation accuracy:		93.26 %
Epoch 659 of 2000 took 0.173s
  training loss:		0.031591
  validation loss:		0.291701
  validation accuracy:		93.15 %
Epoch 660 of 2000 took 0.129s
  training loss:		0.033168
  validation loss:		0.270779
  validation accuracy:		93.37 %
Epoch 661 of 2000 took 0.138s
  training loss:		0.031956
  validation loss:		0.280737
  validation accuracy:		93.26 %
Epoch 662 of 2000 took 0.166s
  training loss:		0.031697
  validation loss:		0.274811
  validation accuracy:		93.15 %
Epoch 663 of 2000 took 0.143s
  training loss:		0.031271
  validation loss:		0.278519
  validation accuracy:		93.37 %
Epoch 664 of 2000 took 0.141s
  training loss:		0.031449
  validation loss:		0.275751
  validation accuracy:		93.26 %
Epoch 665 of 2000 took 0.170s
  training loss:		0.032092
  validation loss:		0.272231
  validation accuracy:		93.37 %
Epoch 666 of 2000 took 0.174s
  training loss:		0.031125
  validation loss:		0.269917
  validation accuracy:		93.15 %
Epoch 667 of 2000 took 0.172s
  training loss:		0.029926
  validation loss:		0.278179
  validation accuracy:		93.26 %
Epoch 668 of 2000 took 0.178s
  training loss:		0.029645
  validation loss:		0.269794
  validation accuracy:		93.26 %
Epoch 669 of 2000 took 0.174s
  training loss:		0.029451
  validation loss:		0.276119
  validation accuracy:		93.37 %
Epoch 670 of 2000 took 0.175s
  training loss:		0.031036
  validation loss:		0.279147
  validation accuracy:		93.15 %
Epoch 671 of 2000 took 0.176s
  training loss:		0.029095
  validation loss:		0.273788
  validation accuracy:		93.04 %
Epoch 672 of 2000 took 0.176s
  training loss:		0.032258
  validation loss:		0.284864
  validation accuracy:		93.26 %
Epoch 673 of 2000 took 0.175s
  training loss:		0.030558
  validation loss:		0.278481
  validation accuracy:		93.04 %
Epoch 674 of 2000 took 0.154s
  training loss:		0.029775
  validation loss:		0.274410
  validation accuracy:		93.37 %
Epoch 675 of 2000 took 0.168s
  training loss:		0.029423
  validation loss:		0.266060
  validation accuracy:		93.37 %
Epoch 676 of 2000 took 0.172s
  training loss:		0.030444
  validation loss:		0.284703
  validation accuracy:		93.26 %
Epoch 677 of 2000 took 0.173s
  training loss:		0.028781
  validation loss:		0.268278
  validation accuracy:		93.15 %
Epoch 678 of 2000 took 0.173s
  training loss:		0.029739
  validation loss:		0.284510
  validation accuracy:		93.26 %
Epoch 679 of 2000 took 0.168s
  training loss:		0.029535
  validation loss:		0.278596
  validation accuracy:		93.04 %
Epoch 680 of 2000 took 0.173s
  training loss:		0.029948
  validation loss:		0.273789
  validation accuracy:		93.26 %
Epoch 681 of 2000 took 0.166s
  training loss:		0.029395
  validation loss:		0.276977
  validation accuracy:		93.26 %
Epoch 682 of 2000 took 0.133s
  training loss:		0.030000
  validation loss:		0.273065
  validation accuracy:		93.15 %
Epoch 683 of 2000 took 0.146s
  training loss:		0.029194
  validation loss:		0.276040
  validation accuracy:		92.93 %
Epoch 684 of 2000 took 0.150s
  training loss:		0.028903
  validation loss:		0.279804
  validation accuracy:		93.04 %
Epoch 685 of 2000 took 0.139s
  training loss:		0.029467
  validation loss:		0.276326
  validation accuracy:		93.26 %
Epoch 686 of 2000 took 0.149s
  training loss:		0.029384
  validation loss:		0.284247
  validation accuracy:		93.37 %
Epoch 687 of 2000 took 0.143s
  training loss:		0.029217
  validation loss:		0.284898
  validation accuracy:		93.26 %
Epoch 688 of 2000 took 0.154s
  training loss:		0.030190
  validation loss:		0.276551
  validation accuracy:		93.04 %
Epoch 689 of 2000 took 0.155s
  training loss:		0.028981
  validation loss:		0.275761
  validation accuracy:		93.15 %
Epoch 690 of 2000 took 0.170s
  training loss:		0.027571
  validation loss:		0.281409
  validation accuracy:		93.37 %
Epoch 691 of 2000 took 0.169s
  training loss:		0.028691
  validation loss:		0.277624
  validation accuracy:		93.15 %
Epoch 692 of 2000 took 0.172s
  training loss:		0.029256
  validation loss:		0.272907
  validation accuracy:		93.04 %
Epoch 693 of 2000 took 0.175s
  training loss:		0.029361
  validation loss:		0.277766
  validation accuracy:		93.37 %
Epoch 694 of 2000 took 0.168s
  training loss:		0.028326
  validation loss:		0.283984
  validation accuracy:		93.37 %
Epoch 695 of 2000 took 0.141s
  training loss:		0.028133
  validation loss:		0.281222
  validation accuracy:		93.15 %
Epoch 696 of 2000 took 0.175s
  training loss:		0.029377
  validation loss:		0.280952
  validation accuracy:		93.15 %
Epoch 697 of 2000 took 0.175s
  training loss:		0.028094
  validation loss:		0.283161
  validation accuracy:		93.26 %
Epoch 698 of 2000 took 0.159s
  training loss:		0.028936
  validation loss:		0.286913
  validation accuracy:		93.26 %
Epoch 699 of 2000 took 0.180s
  training loss:		0.027976
  validation loss:		0.286861
  validation accuracy:		93.15 %
Epoch 700 of 2000 took 0.176s
  training loss:		0.028191
  validation loss:		0.286250
  validation accuracy:		92.93 %
Epoch 701 of 2000 took 0.168s
  training loss:		0.027665
  validation loss:		0.280713
  validation accuracy:		93.37 %
Epoch 702 of 2000 took 0.159s
  training loss:		0.030417
  validation loss:		0.290502
  validation accuracy:		93.26 %
Epoch 703 of 2000 took 0.167s
  training loss:		0.027354
  validation loss:		0.282044
  validation accuracy:		93.26 %
Epoch 704 of 2000 took 0.175s
  training loss:		0.027330
  validation loss:		0.299682
  validation accuracy:		92.93 %
Epoch 705 of 2000 took 0.176s
  training loss:		0.028523
  validation loss:		0.286784
  validation accuracy:		93.15 %
Epoch 706 of 2000 took 0.176s
  training loss:		0.028095
  validation loss:		0.291100
  validation accuracy:		93.15 %
Epoch 707 of 2000 took 0.164s
  training loss:		0.027248
  validation loss:		0.285449
  validation accuracy:		93.04 %
Epoch 708 of 2000 took 0.168s
  training loss:		0.028152
  validation loss:		0.278998
  validation accuracy:		93.48 %
Epoch 709 of 2000 took 0.173s
  training loss:		0.028032
  validation loss:		0.292788
  validation accuracy:		93.15 %
Epoch 710 of 2000 took 0.175s
  training loss:		0.028132
  validation loss:		0.290128
  validation accuracy:		93.04 %
Epoch 711 of 2000 took 0.176s
  training loss:		0.027636
  validation loss:		0.293603
  validation accuracy:		93.04 %
Epoch 712 of 2000 took 0.176s
  training loss:		0.025677
  validation loss:		0.286624
  validation accuracy:		92.83 %
Epoch 713 of 2000 took 0.164s
  training loss:		0.026129
  validation loss:		0.294876
  validation accuracy:		93.04 %
Epoch 714 of 2000 took 0.171s
  training loss:		0.027435
  validation loss:		0.287111
  validation accuracy:		93.15 %
Epoch 715 of 2000 took 0.175s
  training loss:		0.027027
  validation loss:		0.288238
  validation accuracy:		93.15 %
Epoch 716 of 2000 took 0.174s
  training loss:		0.026651
  validation loss:		0.283616
  validation accuracy:		93.04 %
Epoch 717 of 2000 took 0.171s
  training loss:		0.027701
  validation loss:		0.287828
  validation accuracy:		93.26 %
Epoch 718 of 2000 took 0.176s
  training loss:		0.027544
  validation loss:		0.281958
  validation accuracy:		93.15 %
Epoch 719 of 2000 took 0.175s
  training loss:		0.026603
  validation loss:		0.285364
  validation accuracy:		93.15 %
Epoch 720 of 2000 took 0.175s
  training loss:		0.026227
  validation loss:		0.283222
  validation accuracy:		93.37 %
Epoch 721 of 2000 took 0.165s
  training loss:		0.027077
  validation loss:		0.289106
  validation accuracy:		93.15 %
Epoch 722 of 2000 took 0.144s
  training loss:		0.027281
  validation loss:		0.285729
  validation accuracy:		93.26 %
Epoch 723 of 2000 took 0.154s
  training loss:		0.026610
  validation loss:		0.287115
  validation accuracy:		93.04 %
Epoch 724 of 2000 took 0.149s
  training loss:		0.027116
  validation loss:		0.291313
  validation accuracy:		93.26 %
Epoch 725 of 2000 took 0.139s
  training loss:		0.026287
  validation loss:		0.298433
  validation accuracy:		92.72 %
Epoch 726 of 2000 took 0.172s
  training loss:		0.025723
  validation loss:		0.290237
  validation accuracy:		93.15 %
Epoch 727 of 2000 took 0.167s
  training loss:		0.026988
  validation loss:		0.301911
  validation accuracy:		93.15 %
Epoch 728 of 2000 took 0.174s
  training loss:		0.026509
  validation loss:		0.293723
  validation accuracy:		93.26 %
Epoch 729 of 2000 took 0.176s
  training loss:		0.025369
  validation loss:		0.303735
  validation accuracy:		92.83 %
Epoch 730 of 2000 took 0.167s
  training loss:		0.025658
  validation loss:		0.289953
  validation accuracy:		93.26 %
Epoch 731 of 2000 took 0.151s
  training loss:		0.024864
  validation loss:		0.287309
  validation accuracy:		93.26 %
Epoch 732 of 2000 took 0.135s
  training loss:		0.025806
  validation loss:		0.291574
  validation accuracy:		93.26 %
Epoch 733 of 2000 took 0.145s
  training loss:		0.026680
  validation loss:		0.283186
  validation accuracy:		92.93 %
Epoch 734 of 2000 took 0.154s
  training loss:		0.026570
  validation loss:		0.288206
  validation accuracy:		92.93 %
Epoch 735 of 2000 took 0.148s
  training loss:		0.024770
  validation loss:		0.296465
  validation accuracy:		92.93 %
Epoch 736 of 2000 took 0.146s
  training loss:		0.025764
  validation loss:		0.289209
  validation accuracy:		92.93 %
Epoch 737 of 2000 took 0.138s
  training loss:		0.024223
  validation loss:		0.295208
  validation accuracy:		93.04 %
Epoch 738 of 2000 took 0.134s
  training loss:		0.025974
  validation loss:		0.298421
  validation accuracy:		93.37 %
Epoch 739 of 2000 took 0.143s
  training loss:		0.025702
  validation loss:		0.289116
  validation accuracy:		93.26 %
Epoch 740 of 2000 took 0.152s
  training loss:		0.025676
  validation loss:		0.312892
  validation accuracy:		92.83 %
Epoch 741 of 2000 took 0.138s
  training loss:		0.024722
  validation loss:		0.290314
  validation accuracy:		93.15 %
Epoch 742 of 2000 took 0.141s
  training loss:		0.025202
  validation loss:		0.292842
  validation accuracy:		93.26 %
Epoch 743 of 2000 took 0.137s
  training loss:		0.025416
  validation loss:		0.294328
  validation accuracy:		93.04 %
Epoch 744 of 2000 took 0.139s
  training loss:		0.025376
  validation loss:		0.293347
  validation accuracy:		93.26 %
Epoch 745 of 2000 took 0.135s
  training loss:		0.024776
  validation loss:		0.292423
  validation accuracy:		92.93 %
Epoch 746 of 2000 took 0.139s
  training loss:		0.023551
  validation loss:		0.294642
  validation accuracy:		93.04 %
Epoch 747 of 2000 took 0.139s
  training loss:		0.025052
  validation loss:		0.295379
  validation accuracy:		93.15 %
Epoch 748 of 2000 took 0.144s
  training loss:		0.023981
  validation loss:		0.289601
  validation accuracy:		93.15 %
Epoch 749 of 2000 took 0.133s
  training loss:		0.024770
  validation loss:		0.290353
  validation accuracy:		92.83 %
Epoch 750 of 2000 took 0.150s
  training loss:		0.024787
  validation loss:		0.296328
  validation accuracy:		93.15 %
Epoch 751 of 2000 took 0.165s
  training loss:		0.025032
  validation loss:		0.296418
  validation accuracy:		93.04 %
Epoch 752 of 2000 took 0.144s
  training loss:		0.024617
  validation loss:		0.297073
  validation accuracy:		93.15 %
Epoch 753 of 2000 took 0.171s
  training loss:		0.023737
  validation loss:		0.293851
  validation accuracy:		93.15 %
Epoch 754 of 2000 took 0.154s
  training loss:		0.024508
  validation loss:		0.298096
  validation accuracy:		93.04 %
Epoch 755 of 2000 took 0.137s
  training loss:		0.024027
  validation loss:		0.294301
  validation accuracy:		93.04 %
Epoch 756 of 2000 took 0.143s
  training loss:		0.023022
  validation loss:		0.295068
  validation accuracy:		93.15 %
Epoch 757 of 2000 took 0.151s
  training loss:		0.024728
  validation loss:		0.291141
  validation accuracy:		93.15 %
Epoch 758 of 2000 took 0.151s
  training loss:		0.026289
  validation loss:		0.305799
  validation accuracy:		92.83 %
Epoch 759 of 2000 took 0.133s
  training loss:		0.024860
  validation loss:		0.290156
  validation accuracy:		93.04 %
Epoch 760 of 2000 took 0.137s
  training loss:		0.024978
  validation loss:		0.298377
  validation accuracy:		92.83 %
Epoch 761 of 2000 took 0.149s
  training loss:		0.023643
  validation loss:		0.304334
  validation accuracy:		93.04 %
Epoch 762 of 2000 took 0.137s
  training loss:		0.022985
  validation loss:		0.292568
  validation accuracy:		93.26 %
Epoch 763 of 2000 took 0.145s
  training loss:		0.023512
  validation loss:		0.296283
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.145s
  training loss:		0.023926
  validation loss:		0.299285
  validation accuracy:		92.93 %
Epoch 765 of 2000 took 0.131s
  training loss:		0.023723
  validation loss:		0.299467
  validation accuracy:		93.26 %
Epoch 766 of 2000 took 0.140s
  training loss:		0.022579
  validation loss:		0.296062
  validation accuracy:		92.93 %
Epoch 767 of 2000 took 0.140s
  training loss:		0.023860
  validation loss:		0.305334
  validation accuracy:		92.93 %
Epoch 768 of 2000 took 0.146s
  training loss:		0.022512
  validation loss:		0.303992
  validation accuracy:		93.15 %
Epoch 769 of 2000 took 0.141s
  training loss:		0.023099
  validation loss:		0.308210
  validation accuracy:		92.83 %
Epoch 770 of 2000 took 0.133s
  training loss:		0.024637
  validation loss:		0.300365
  validation accuracy:		93.26 %
Epoch 771 of 2000 took 0.131s
  training loss:		0.023953
  validation loss:		0.297086
  validation accuracy:		93.26 %
Epoch 772 of 2000 took 0.137s
  training loss:		0.022789
  validation loss:		0.311713
  validation accuracy:		92.83 %
Epoch 773 of 2000 took 0.144s
  training loss:		0.023876
  validation loss:		0.302836
  validation accuracy:		93.04 %
Epoch 774 of 2000 took 0.130s
  training loss:		0.022659
  validation loss:		0.298195
  validation accuracy:		92.93 %
Epoch 775 of 2000 took 0.138s
  training loss:		0.022827
  validation loss:		0.288281
  validation accuracy:		93.15 %
Epoch 776 of 2000 took 0.136s
  training loss:		0.023080
  validation loss:		0.301727
  validation accuracy:		92.93 %
Epoch 777 of 2000 took 0.143s
  training loss:		0.022660
  validation loss:		0.313019
  validation accuracy:		93.37 %
Epoch 778 of 2000 took 0.141s
  training loss:		0.023493
  validation loss:		0.306719
  validation accuracy:		92.93 %
Epoch 779 of 2000 took 0.135s
  training loss:		0.023732
  validation loss:		0.303176
  validation accuracy:		92.93 %
Epoch 780 of 2000 took 0.139s
  training loss:		0.022662
  validation loss:		0.306936
  validation accuracy:		92.93 %
Epoch 781 of 2000 took 0.165s
  training loss:		0.022450
  validation loss:		0.306392
  validation accuracy:		93.04 %
Epoch 782 of 2000 took 0.174s
  training loss:		0.022823
  validation loss:		0.303372
  validation accuracy:		92.93 %
Epoch 783 of 2000 took 0.171s
  training loss:		0.023286
  validation loss:		0.303438
  validation accuracy:		93.04 %
Epoch 784 of 2000 took 0.142s
  training loss:		0.022906
  validation loss:		0.317572
  validation accuracy:		92.83 %
Epoch 785 of 2000 took 0.143s
  training loss:		0.022609
  validation loss:		0.298701
  validation accuracy:		93.15 %
Epoch 786 of 2000 took 0.140s
  training loss:		0.022212
  validation loss:		0.296048
  validation accuracy:		93.26 %
Epoch 787 of 2000 took 0.132s
  training loss:		0.023276
  validation loss:		0.306858
  validation accuracy:		93.15 %
Epoch 788 of 2000 took 0.130s
  training loss:		0.021934
  validation loss:		0.295557
  validation accuracy:		93.26 %
Epoch 789 of 2000 took 0.144s
  training loss:		0.022633
  validation loss:		0.300982
  validation accuracy:		92.93 %
Epoch 790 of 2000 took 0.135s
  training loss:		0.022240
  validation loss:		0.300542
  validation accuracy:		92.93 %
Epoch 791 of 2000 took 0.149s
  training loss:		0.021876
  validation loss:		0.301331
  validation accuracy:		93.04 %
Epoch 792 of 2000 took 0.166s
  training loss:		0.021834
  validation loss:		0.307961
  validation accuracy:		93.04 %
Epoch 793 of 2000 took 0.184s
  training loss:		0.022135
  validation loss:		0.304806
  validation accuracy:		93.04 %
Epoch 794 of 2000 took 0.149s
  training loss:		0.021475
  validation loss:		0.301270
  validation accuracy:		93.04 %
Epoch 795 of 2000 took 0.139s
  training loss:		0.021405
  validation loss:		0.300947
  validation accuracy:		93.15 %
Epoch 796 of 2000 took 0.146s
  training loss:		0.021079
  validation loss:		0.305587
  validation accuracy:		92.83 %
Epoch 797 of 2000 took 0.142s
  training loss:		0.022180
  validation loss:		0.306554
  validation accuracy:		92.93 %
Epoch 798 of 2000 took 0.138s
  training loss:		0.022140
  validation loss:		0.313332
  validation accuracy:		93.15 %
Epoch 799 of 2000 took 0.142s
  training loss:		0.021757
  validation loss:		0.310450
  validation accuracy:		93.04 %
Epoch 800 of 2000 took 0.177s
  training loss:		0.020924
  validation loss:		0.306231
  validation accuracy:		93.04 %
Epoch 801 of 2000 took 0.176s
  training loss:		0.020944
  validation loss:		0.312618
  validation accuracy:		92.83 %
Epoch 802 of 2000 took 0.176s
  training loss:		0.021214
  validation loss:		0.311078
  validation accuracy:		93.15 %
Epoch 803 of 2000 took 0.173s
  training loss:		0.021618
  validation loss:		0.300330
  validation accuracy:		93.04 %
Epoch 804 of 2000 took 0.144s
  training loss:		0.021302
  validation loss:		0.303234
  validation accuracy:		93.15 %
Epoch 805 of 2000 took 0.147s
  training loss:		0.020882
  validation loss:		0.302081
  validation accuracy:		93.15 %
Epoch 806 of 2000 took 0.177s
  training loss:		0.021584
  validation loss:		0.312364
  validation accuracy:		93.04 %
Epoch 807 of 2000 took 0.177s
  training loss:		0.021947
  validation loss:		0.313957
  validation accuracy:		92.83 %
Epoch 808 of 2000 took 0.177s
  training loss:		0.020773
  validation loss:		0.307004
  validation accuracy:		93.04 %
Epoch 809 of 2000 took 0.178s
  training loss:		0.021211
  validation loss:		0.308719
  validation accuracy:		93.04 %
Epoch 810 of 2000 took 0.174s
  training loss:		0.020758
  validation loss:		0.307660
  validation accuracy:		93.15 %
Epoch 811 of 2000 took 0.136s
  training loss:		0.021232
  validation loss:		0.303234
  validation accuracy:		93.04 %
Epoch 812 of 2000 took 0.153s
  training loss:		0.020195
  validation loss:		0.314366
  validation accuracy:		93.04 %
Epoch 813 of 2000 took 0.130s
  training loss:		0.020992
  validation loss:		0.306067
  validation accuracy:		92.93 %
Epoch 814 of 2000 took 0.148s
  training loss:		0.021371
  validation loss:		0.305511
  validation accuracy:		92.93 %
Epoch 815 of 2000 took 0.140s
  training loss:		0.020287
  validation loss:		0.307860
  validation accuracy:		93.04 %
Epoch 816 of 2000 took 0.149s
  training loss:		0.020694
  validation loss:		0.310662
  validation accuracy:		92.83 %
Epoch 817 of 2000 took 0.146s
  training loss:		0.020994
  validation loss:		0.309493
  validation accuracy:		93.04 %
Epoch 818 of 2000 took 0.134s
  training loss:		0.021047
  validation loss:		0.311439
  validation accuracy:		92.61 %
Epoch 819 of 2000 took 0.143s
  training loss:		0.019849
  validation loss:		0.311505
  validation accuracy:		92.93 %
Epoch 820 of 2000 took 0.141s
  training loss:		0.020307
  validation loss:		0.307423
  validation accuracy:		93.15 %
Epoch 821 of 2000 took 0.149s
  training loss:		0.020634
  validation loss:		0.309138
  validation accuracy:		93.04 %
Epoch 822 of 2000 took 0.142s
  training loss:		0.020548
  validation loss:		0.315212
  validation accuracy:		92.83 %
Epoch 823 of 2000 took 0.135s
  training loss:		0.019079
  validation loss:		0.316172
  validation accuracy:		92.93 %
Epoch 824 of 2000 took 0.164s
  training loss:		0.020368
  validation loss:		0.315352
  validation accuracy:		92.93 %
Epoch 825 of 2000 took 0.175s
  training loss:		0.019954
  validation loss:		0.305262
  validation accuracy:		93.04 %
Epoch 826 of 2000 took 0.143s
  training loss:		0.020546
  validation loss:		0.318544
  validation accuracy:		93.04 %
Epoch 827 of 2000 took 0.146s
  training loss:		0.020469
  validation loss:		0.311929
  validation accuracy:		92.93 %
Epoch 828 of 2000 took 0.139s
  training loss:		0.019954
  validation loss:		0.317663
  validation accuracy:		92.83 %
Epoch 829 of 2000 took 0.141s
  training loss:		0.020183
  validation loss:		0.310189
  validation accuracy:		92.93 %
Epoch 830 of 2000 took 0.147s
  training loss:		0.020022
  validation loss:		0.319827
  validation accuracy:		92.83 %
Epoch 831 of 2000 took 0.171s
  training loss:		0.019721
  validation loss:		0.315350
  validation accuracy:		92.93 %
Epoch 832 of 2000 took 0.139s
  training loss:		0.019895
  validation loss:		0.322199
  validation accuracy:		92.83 %
Epoch 833 of 2000 took 0.139s
  training loss:		0.019753
  validation loss:		0.320235
  validation accuracy:		93.04 %
Epoch 834 of 2000 took 0.134s
  training loss:		0.019187
  validation loss:		0.311363
  validation accuracy:		92.93 %
Epoch 835 of 2000 took 0.142s
  training loss:		0.019833
  validation loss:		0.307731
  validation accuracy:		92.93 %
Epoch 836 of 2000 took 0.138s
  training loss:		0.019775
  validation loss:		0.315961
  validation accuracy:		92.83 %
Epoch 837 of 2000 took 0.139s
  training loss:		0.019400
  validation loss:		0.311813
  validation accuracy:		93.04 %
Epoch 838 of 2000 took 0.150s
  training loss:		0.019645
  validation loss:		0.317464
  validation accuracy:		92.93 %
Epoch 839 of 2000 took 0.159s
  training loss:		0.020139
  validation loss:		0.314413
  validation accuracy:		92.83 %
Epoch 840 of 2000 took 0.165s
  training loss:		0.019353
  validation loss:		0.319507
  validation accuracy:		92.83 %
Epoch 841 of 2000 took 0.136s
  training loss:		0.020116
  validation loss:		0.317873
  validation accuracy:		92.83 %
Epoch 842 of 2000 took 0.138s
  training loss:		0.019686
  validation loss:		0.324613
  validation accuracy:		92.83 %
Epoch 843 of 2000 took 0.138s
  training loss:		0.019056
  validation loss:		0.309032
  validation accuracy:		93.26 %
Epoch 844 of 2000 took 0.137s
  training loss:		0.019757
  validation loss:		0.321816
  validation accuracy:		92.83 %
Epoch 845 of 2000 took 0.147s
  training loss:		0.019095
  validation loss:		0.321688
  validation accuracy:		92.93 %
Epoch 846 of 2000 took 0.136s
  training loss:		0.018661
  validation loss:		0.314902
  validation accuracy:		93.04 %
Epoch 847 of 2000 took 0.169s
  training loss:		0.019003
  validation loss:		0.316935
  validation accuracy:		93.04 %
Epoch 848 of 2000 took 0.150s
  training loss:		0.019095
  validation loss:		0.315088
  validation accuracy:		93.15 %
Epoch 849 of 2000 took 0.176s
  training loss:		0.019149
  validation loss:		0.313522
  validation accuracy:		92.93 %
Epoch 850 of 2000 took 0.179s
  training loss:		0.018596
  validation loss:		0.321316
  validation accuracy:		93.04 %
Epoch 851 of 2000 took 0.141s
  training loss:		0.018523
  validation loss:		0.322692
  validation accuracy:		92.72 %
Epoch 852 of 2000 took 0.139s
  training loss:		0.018969
  validation loss:		0.320814
  validation accuracy:		92.83 %
Epoch 853 of 2000 took 0.170s
  training loss:		0.018689
  validation loss:		0.320393
  validation accuracy:		92.93 %
Epoch 854 of 2000 took 0.171s
  training loss:		0.018831
  validation loss:		0.315728
  validation accuracy:		93.04 %
Epoch 855 of 2000 took 0.138s
  training loss:		0.018745
  validation loss:		0.324869
  validation accuracy:		92.72 %
Epoch 856 of 2000 took 0.162s
  training loss:		0.017956
  validation loss:		0.326617
  validation accuracy:		92.93 %
Epoch 857 of 2000 took 0.135s
  training loss:		0.019364
  validation loss:		0.308515
  validation accuracy:		93.04 %
Epoch 858 of 2000 took 0.144s
  training loss:		0.018648
  validation loss:		0.318246
  validation accuracy:		93.15 %
Epoch 859 of 2000 took 0.150s
  training loss:		0.019152
  validation loss:		0.321503
  validation accuracy:		92.72 %
Epoch 860 of 2000 took 0.140s
  training loss:		0.018085
  validation loss:		0.320109
  validation accuracy:		93.04 %
Epoch 861 of 2000 took 0.144s
  training loss:		0.018708
  validation loss:		0.328756
  validation accuracy:		92.83 %
Epoch 862 of 2000 took 0.137s
  training loss:		0.018036
  validation loss:		0.320586
  validation accuracy:		92.83 %
Epoch 863 of 2000 took 0.136s
  training loss:		0.018582
  validation loss:		0.321029
  validation accuracy:		92.72 %
Epoch 864 of 2000 took 0.148s
  training loss:		0.017856
  validation loss:		0.314205
  validation accuracy:		93.15 %
Epoch 865 of 2000 took 0.144s
  training loss:		0.017506
  validation loss:		0.324106
  validation accuracy:		92.83 %
Epoch 866 of 2000 took 0.175s
  training loss:		0.018878
  validation loss:		0.325477
  validation accuracy:		92.83 %
Epoch 867 of 2000 took 0.178s
  training loss:		0.018718
  validation loss:		0.320539
  validation accuracy:		93.04 %
Epoch 868 of 2000 took 0.174s
  training loss:		0.018658
  validation loss:		0.322692
  validation accuracy:		92.93 %
Epoch 869 of 2000 took 0.174s
  training loss:		0.018838
  validation loss:		0.327132
  validation accuracy:		92.93 %
Epoch 870 of 2000 took 0.177s
  training loss:		0.017902
  validation loss:		0.327995
  validation accuracy:		92.72 %
Epoch 871 of 2000 took 0.174s
  training loss:		0.018200
  validation loss:		0.330136
  validation accuracy:		92.93 %
Epoch 872 of 2000 took 0.133s
  training loss:		0.018021
  validation loss:		0.324793
  validation accuracy:		92.72 %
Epoch 873 of 2000 took 0.171s
  training loss:		0.017968
  validation loss:		0.321328
  validation accuracy:		93.04 %
Epoch 874 of 2000 took 0.176s
  training loss:		0.018207
  validation loss:		0.321850
  validation accuracy:		93.04 %
Epoch 875 of 2000 took 0.146s
  training loss:		0.017416
  validation loss:		0.331536
  validation accuracy:		92.93 %
Epoch 876 of 2000 took 0.158s
  training loss:		0.017765
  validation loss:		0.321461
  validation accuracy:		92.83 %
Epoch 877 of 2000 took 0.138s
  training loss:		0.017848
  validation loss:		0.326294
  validation accuracy:		92.83 %
Epoch 878 of 2000 took 0.138s
  training loss:		0.017170
  validation loss:		0.319706
  validation accuracy:		93.26 %
Epoch 879 of 2000 took 0.138s
  training loss:		0.017898
  validation loss:		0.322079
  validation accuracy:		92.93 %
Epoch 880 of 2000 took 0.176s
  training loss:		0.017282
  validation loss:		0.325371
  validation accuracy:		92.83 %
Epoch 881 of 2000 took 0.176s
  training loss:		0.017681
  validation loss:		0.327042
  validation accuracy:		93.04 %
Epoch 882 of 2000 took 0.176s
  training loss:		0.017001
  validation loss:		0.325916
  validation accuracy:		92.83 %
Epoch 883 of 2000 took 0.140s
  training loss:		0.017404
  validation loss:		0.333407
  validation accuracy:		92.61 %
Epoch 884 of 2000 took 0.159s
  training loss:		0.016971
  validation loss:		0.328792
  validation accuracy:		93.04 %
Epoch 885 of 2000 took 0.139s
  training loss:		0.017648
  validation loss:		0.326132
  validation accuracy:		92.93 %
Epoch 886 of 2000 took 0.158s
  training loss:		0.016375
  validation loss:		0.318638
  validation accuracy:		92.93 %
Epoch 887 of 2000 took 0.174s
  training loss:		0.016407
  validation loss:		0.322877
  validation accuracy:		93.15 %
Epoch 888 of 2000 took 0.152s
  training loss:		0.017486
  validation loss:		0.331751
  validation accuracy:		92.93 %
Epoch 889 of 2000 took 0.165s
  training loss:		0.017111
  validation loss:		0.325292
  validation accuracy:		93.04 %
Epoch 890 of 2000 took 0.174s
  training loss:		0.017095
  validation loss:		0.327435
  validation accuracy:		93.04 %
Epoch 891 of 2000 took 0.173s
  training loss:		0.016903
  validation loss:		0.316693
  validation accuracy:		92.93 %
Epoch 892 of 2000 took 0.168s
  training loss:		0.017799
  validation loss:		0.334052
  validation accuracy:		92.83 %
Epoch 893 of 2000 took 0.172s
  training loss:		0.016628
  validation loss:		0.324132
  validation accuracy:		92.93 %
Epoch 894 of 2000 took 0.176s
  training loss:		0.017044
  validation loss:		0.323814
  validation accuracy:		92.93 %
Epoch 895 of 2000 took 0.172s
  training loss:		0.017547
  validation loss:		0.340129
  validation accuracy:		92.61 %
Epoch 896 of 2000 took 0.176s
  training loss:		0.017559
  validation loss:		0.330180
  validation accuracy:		92.93 %
Epoch 897 of 2000 took 0.150s
  training loss:		0.016874
  validation loss:		0.324303
  validation accuracy:		92.83 %
Epoch 898 of 2000 took 0.130s
  training loss:		0.017257
  validation loss:		0.330530
  validation accuracy:		92.93 %
Epoch 899 of 2000 took 0.139s
  training loss:		0.016742
  validation loss:		0.321256
  validation accuracy:		93.15 %
Epoch 900 of 2000 took 0.133s
  training loss:		0.016779
  validation loss:		0.324329
  validation accuracy:		93.04 %
Epoch 901 of 2000 took 0.163s
  training loss:		0.016179
  validation loss:		0.330204
  validation accuracy:		92.72 %
Epoch 902 of 2000 took 0.143s
  training loss:		0.016636
  validation loss:		0.328805
  validation accuracy:		92.93 %
Epoch 903 of 2000 took 0.162s
  training loss:		0.015876
  validation loss:		0.324519
  validation accuracy:		93.04 %
Epoch 904 of 2000 took 0.160s
  training loss:		0.016125
  validation loss:		0.329712
  validation accuracy:		92.93 %
Epoch 905 of 2000 took 0.129s
  training loss:		0.016328
  validation loss:		0.330046
  validation accuracy:		93.04 %
Epoch 906 of 2000 took 0.141s
  training loss:		0.015863
  validation loss:		0.338632
  validation accuracy:		92.72 %
Epoch 907 of 2000 took 0.172s
  training loss:		0.016536
  validation loss:		0.325723
  validation accuracy:		93.04 %
Epoch 908 of 2000 took 0.175s
  training loss:		0.016516
  validation loss:		0.337718
  validation accuracy:		92.93 %
Epoch 909 of 2000 took 0.148s
  training loss:		0.017573
  validation loss:		0.339523
  validation accuracy:		92.72 %
Epoch 910 of 2000 took 0.136s
  training loss:		0.016144
  validation loss:		0.324540
  validation accuracy:		93.04 %
Epoch 911 of 2000 took 0.170s
  training loss:		0.015589
  validation loss:		0.332948
  validation accuracy:		92.93 %
Epoch 912 of 2000 took 0.140s
  training loss:		0.015774
  validation loss:		0.323679
  validation accuracy:		92.93 %
Epoch 913 of 2000 took 0.149s
  training loss:		0.015921
  validation loss:		0.326318
  validation accuracy:		92.83 %
Epoch 914 of 2000 took 0.138s
  training loss:		0.015890
  validation loss:		0.324210
  validation accuracy:		92.93 %
Epoch 915 of 2000 took 0.143s
  training loss:		0.015433
  validation loss:		0.333059
  validation accuracy:		92.83 %
Epoch 916 of 2000 took 0.147s
  training loss:		0.017107
  validation loss:		0.334400
  validation accuracy:		92.83 %
Epoch 917 of 2000 took 0.175s
  training loss:		0.015768
  validation loss:		0.339654
  validation accuracy:		92.93 %
Epoch 918 of 2000 took 0.146s
  training loss:		0.015926
  validation loss:		0.336213
  validation accuracy:		92.83 %
Epoch 919 of 2000 took 0.158s
  training loss:		0.015962
  validation loss:		0.333594
  validation accuracy:		92.93 %
Epoch 920 of 2000 took 0.141s
  training loss:		0.015849
  validation loss:		0.335078
  validation accuracy:		92.93 %
Epoch 921 of 2000 took 0.143s
  training loss:		0.015817
  validation loss:		0.339429
  validation accuracy:		92.72 %
Epoch 922 of 2000 took 0.176s
  training loss:		0.016051
  validation loss:		0.331858
  validation accuracy:		92.72 %
Epoch 923 of 2000 took 0.175s
  training loss:		0.016050
  validation loss:		0.327652
  validation accuracy:		92.93 %
Epoch 924 of 2000 took 0.173s
  training loss:		0.015922
  validation loss:		0.332076
  validation accuracy:		92.83 %
Epoch 925 of 2000 took 0.175s
  training loss:		0.016201
  validation loss:		0.340543
  validation accuracy:		92.93 %
Epoch 926 of 2000 took 0.135s
  training loss:		0.016223
  validation loss:		0.337040
  validation accuracy:		92.83 %
Epoch 927 of 2000 took 0.151s
  training loss:		0.015202
  validation loss:		0.337481
  validation accuracy:		92.83 %
Epoch 928 of 2000 took 0.145s
  training loss:		0.015855
  validation loss:		0.329482
  validation accuracy:		92.93 %
Epoch 929 of 2000 took 0.175s
  training loss:		0.015214
  validation loss:		0.341628
  validation accuracy:		92.83 %
Epoch 930 of 2000 took 0.174s
  training loss:		0.015828
  validation loss:		0.337591
  validation accuracy:		92.83 %
Epoch 931 of 2000 took 0.168s
  training loss:		0.015019
  validation loss:		0.338267
  validation accuracy:		92.93 %
Epoch 932 of 2000 took 0.174s
  training loss:		0.015015
  validation loss:		0.329743
  validation accuracy:		93.04 %
Epoch 933 of 2000 took 0.138s
  training loss:		0.014775
  validation loss:		0.337358
  validation accuracy:		92.93 %
Epoch 934 of 2000 took 0.139s
  training loss:		0.014824
  validation loss:		0.333864
  validation accuracy:		93.04 %
Epoch 935 of 2000 took 0.151s
  training loss:		0.014818
  validation loss:		0.339283
  validation accuracy:		92.83 %
Epoch 936 of 2000 took 0.138s
  training loss:		0.015466
  validation loss:		0.336308
  validation accuracy:		92.93 %
Epoch 937 of 2000 took 0.143s
  training loss:		0.015176
  validation loss:		0.331162
  validation accuracy:		92.83 %
Epoch 938 of 2000 took 0.136s
  training loss:		0.015424
  validation loss:		0.338546
  validation accuracy:		92.72 %
Epoch 939 of 2000 took 0.146s
  training loss:		0.015142
  validation loss:		0.335597
  validation accuracy:		93.04 %
Epoch 940 of 2000 took 0.177s
  training loss:		0.015010
  validation loss:		0.344029
  validation accuracy:		92.93 %
Epoch 941 of 2000 took 0.172s
  training loss:		0.015177
  validation loss:		0.331386
  validation accuracy:		92.93 %
Epoch 942 of 2000 took 0.182s
  training loss:		0.015189
  validation loss:		0.333672
  validation accuracy:		92.93 %
Epoch 943 of 2000 took 0.177s
  training loss:		0.015485
  validation loss:		0.335113
  validation accuracy:		92.83 %
Epoch 944 of 2000 took 0.175s
  training loss:		0.014539
  validation loss:		0.333339
  validation accuracy:		92.93 %
Epoch 945 of 2000 took 0.175s
  training loss:		0.014927
  validation loss:		0.340052
  validation accuracy:		92.93 %
Epoch 946 of 2000 took 0.143s
  training loss:		0.014393
  validation loss:		0.343919
  validation accuracy:		92.83 %
Epoch 947 of 2000 took 0.163s
  training loss:		0.014535
  validation loss:		0.344525
  validation accuracy:		92.72 %
Epoch 948 of 2000 took 0.141s
  training loss:		0.015306
  validation loss:		0.337220
  validation accuracy:		92.93 %
Epoch 949 of 2000 took 0.137s
  training loss:		0.014770
  validation loss:		0.335692
  validation accuracy:		92.93 %
Epoch 950 of 2000 took 0.142s
  training loss:		0.014825
  validation loss:		0.333744
  validation accuracy:		92.93 %
Epoch 951 of 2000 took 0.175s
  training loss:		0.014614
  validation loss:		0.339677
  validation accuracy:		92.83 %
Epoch 952 of 2000 took 0.178s
  training loss:		0.014100
  validation loss:		0.343508
  validation accuracy:		92.83 %
Epoch 953 of 2000 took 0.188s
  training loss:		0.014857
  validation loss:		0.335123
  validation accuracy:		92.72 %
Epoch 954 of 2000 took 0.175s
  training loss:		0.014840
  validation loss:		0.343300
  validation accuracy:		92.83 %
Epoch 955 of 2000 took 0.160s
  training loss:		0.014424
  validation loss:		0.344210
  validation accuracy:		93.04 %
Epoch 956 of 2000 took 0.175s
  training loss:		0.014112
  validation loss:		0.338502
  validation accuracy:		92.72 %
Epoch 957 of 2000 took 0.155s
  training loss:		0.014454
  validation loss:		0.331618
  validation accuracy:		92.93 %
Epoch 958 of 2000 took 0.150s
  training loss:		0.014402
  validation loss:		0.345131
  validation accuracy:		92.72 %
Epoch 959 of 2000 took 0.143s
  training loss:		0.014304
  validation loss:		0.348077
  validation accuracy:		92.72 %
Epoch 960 of 2000 took 0.149s
  training loss:		0.014931
  validation loss:		0.345887
  validation accuracy:		92.83 %
Epoch 961 of 2000 took 0.146s
  training loss:		0.014309
  validation loss:		0.338476
  validation accuracy:		92.93 %
Epoch 962 of 2000 took 0.159s
  training loss:		0.014343
  validation loss:		0.351382
  validation accuracy:		92.72 %
Epoch 963 of 2000 took 0.141s
  training loss:		0.014340
  validation loss:		0.340344
  validation accuracy:		92.83 %
Epoch 964 of 2000 took 0.135s
  training loss:		0.013841
  validation loss:		0.340506
  validation accuracy:		92.93 %
Epoch 965 of 2000 took 0.137s
  training loss:		0.014005
  validation loss:		0.344050
  validation accuracy:		92.83 %
Epoch 966 of 2000 took 0.133s
  training loss:		0.014092
  validation loss:		0.346265
  validation accuracy:		92.83 %
Epoch 967 of 2000 took 0.137s
  training loss:		0.013916
  validation loss:		0.351164
  validation accuracy:		92.72 %
Epoch 968 of 2000 took 0.150s
  training loss:		0.013578
  validation loss:		0.348039
  validation accuracy:		92.83 %
Epoch 969 of 2000 took 0.176s
  training loss:		0.014575
  validation loss:		0.350564
  validation accuracy:		92.72 %
Epoch 970 of 2000 took 0.174s
  training loss:		0.013722
  validation loss:		0.350340
  validation accuracy:		92.72 %
Epoch 971 of 2000 took 0.162s
  training loss:		0.013616
  validation loss:		0.338209
  validation accuracy:		92.93 %
Epoch 972 of 2000 took 0.176s
  training loss:		0.013006
  validation loss:		0.348369
  validation accuracy:		92.61 %
Epoch 973 of 2000 took 0.175s
  training loss:		0.014053
  validation loss:		0.340650
  validation accuracy:		92.83 %
Epoch 974 of 2000 took 0.169s
  training loss:		0.014368
  validation loss:		0.334830
  validation accuracy:		92.72 %
Epoch 975 of 2000 took 0.139s
  training loss:		0.013521
  validation loss:		0.355542
  validation accuracy:		92.83 %
Epoch 976 of 2000 took 0.135s
  training loss:		0.013169
  validation loss:		0.342049
  validation accuracy:		92.93 %
Epoch 977 of 2000 took 0.170s
  training loss:		0.013543
  validation loss:		0.340491
  validation accuracy:		92.93 %
Epoch 978 of 2000 took 0.176s
  training loss:		0.013461
  validation loss:		0.339724
  validation accuracy:		92.61 %
Epoch 979 of 2000 took 0.171s
  training loss:		0.013278
  validation loss:		0.352080
  validation accuracy:		92.72 %
Epoch 980 of 2000 took 0.164s
  training loss:		0.013493
  validation loss:		0.360434
  validation accuracy:		92.83 %
Epoch 981 of 2000 took 0.185s
  training loss:		0.013527
  validation loss:		0.347436
  validation accuracy:		92.83 %
Epoch 982 of 2000 took 0.172s
  training loss:		0.013443
  validation loss:		0.346901
  validation accuracy:		92.83 %
Epoch 983 of 2000 took 0.168s
  training loss:		0.013632
  validation loss:		0.349986
  validation accuracy:		92.93 %
Epoch 984 of 2000 took 0.158s
  training loss:		0.013601
  validation loss:		0.354859
  validation accuracy:		92.50 %
Epoch 985 of 2000 took 0.177s
  training loss:		0.013821
  validation loss:		0.343094
  validation accuracy:		92.61 %
Epoch 986 of 2000 took 0.142s
  training loss:		0.012746
  validation loss:		0.345005
  validation accuracy:		92.83 %
Epoch 987 of 2000 took 0.145s
  training loss:		0.012803
  validation loss:		0.351368
  validation accuracy:		92.83 %
Epoch 988 of 2000 took 0.131s
  training loss:		0.013685
  validation loss:		0.343428
  validation accuracy:		92.93 %
Epoch 989 of 2000 took 0.142s
  training loss:		0.012880
  validation loss:		0.348500
  validation accuracy:		92.83 %
Epoch 990 of 2000 took 0.177s
  training loss:		0.013615
  validation loss:		0.353552
  validation accuracy:		92.72 %
Epoch 991 of 2000 took 0.172s
  training loss:		0.013185
  validation loss:		0.346440
  validation accuracy:		92.83 %
Epoch 992 of 2000 took 0.143s
  training loss:		0.013370
  validation loss:		0.346271
  validation accuracy:		92.93 %
Epoch 993 of 2000 took 0.135s
  training loss:		0.012674
  validation loss:		0.356521
  validation accuracy:		92.61 %
Epoch 994 of 2000 took 0.148s
  training loss:		0.013418
  validation loss:		0.349971
  validation accuracy:		92.83 %
Epoch 995 of 2000 took 0.146s
  training loss:		0.013078
  validation loss:		0.338890
  validation accuracy:		92.72 %
Epoch 996 of 2000 took 0.144s
  training loss:		0.012896
  validation loss:		0.348195
  validation accuracy:		92.72 %
Epoch 997 of 2000 took 0.134s
  training loss:		0.013186
  validation loss:		0.341268
  validation accuracy:		92.83 %
Epoch 998 of 2000 took 0.140s
  training loss:		0.013219
  validation loss:		0.357916
  validation accuracy:		92.72 %
Epoch 999 of 2000 took 0.154s
  training loss:		0.013216
  validation loss:		0.350002
  validation accuracy:		92.61 %
Epoch 1000 of 2000 took 0.147s
  training loss:		0.013121
  validation loss:		0.358118
  validation accuracy:		92.72 %
Epoch 1001 of 2000 took 0.152s
  training loss:		0.013079
  validation loss:		0.352667
  validation accuracy:		92.93 %
Epoch 1002 of 2000 took 0.135s
  training loss:		0.013608
  validation loss:		0.358537
  validation accuracy:		92.83 %
Epoch 1003 of 2000 took 0.133s
  training loss:		0.013413
  validation loss:		0.355860
  validation accuracy:		92.83 %
Epoch 1004 of 2000 took 0.139s
  training loss:		0.012683
  validation loss:		0.350102
  validation accuracy:		92.72 %
Epoch 1005 of 2000 took 0.135s
  training loss:		0.012636
  validation loss:		0.352580
  validation accuracy:		92.83 %
Epoch 1006 of 2000 took 0.142s
  training loss:		0.012731
  validation loss:		0.342000
  validation accuracy:		92.61 %
Epoch 1007 of 2000 took 0.135s
  training loss:		0.012737
  validation loss:		0.353976
  validation accuracy:		92.83 %
Epoch 1008 of 2000 took 0.150s
  training loss:		0.012737
  validation loss:		0.349345
  validation accuracy:		92.83 %
Epoch 1009 of 2000 took 0.147s
  training loss:		0.012307
  validation loss:		0.354640
  validation accuracy:		92.83 %
Epoch 1010 of 2000 took 0.167s
  training loss:		0.012525
  validation loss:		0.350519
  validation accuracy:		92.72 %
Epoch 1011 of 2000 took 0.156s
  training loss:		0.012784
  validation loss:		0.355432
  validation accuracy:		92.83 %
Epoch 1012 of 2000 took 0.162s
  training loss:		0.012471
  validation loss:		0.355279
  validation accuracy:		92.72 %
Epoch 1013 of 2000 took 0.137s
  training loss:		0.012485
  validation loss:		0.350815
  validation accuracy:		92.72 %
Epoch 1014 of 2000 took 0.174s
  training loss:		0.012581
  validation loss:		0.353858
  validation accuracy:		92.72 %
Epoch 1015 of 2000 took 0.176s
  training loss:		0.012265
  validation loss:		0.349484
  validation accuracy:		92.93 %
Epoch 1016 of 2000 took 0.176s
  training loss:		0.012445
  validation loss:		0.366575
  validation accuracy:		92.72 %
Epoch 1017 of 2000 took 0.175s
  training loss:		0.012566
  validation loss:		0.348976
  validation accuracy:		92.83 %
Epoch 1018 of 2000 took 0.176s
  training loss:		0.012137
  validation loss:		0.355869
  validation accuracy:		92.83 %
Epoch 1019 of 2000 took 0.164s
  training loss:		0.012553
  validation loss:		0.358830
  validation accuracy:		92.83 %
Epoch 1020 of 2000 took 0.170s
  training loss:		0.012907
  validation loss:		0.364093
  validation accuracy:		92.61 %
Epoch 1021 of 2000 took 0.175s
  training loss:		0.012237
  validation loss:		0.354172
  validation accuracy:		92.61 %
Epoch 1022 of 2000 took 0.174s
  training loss:		0.012926
  validation loss:		0.356744
  validation accuracy:		92.72 %
Epoch 1023 of 2000 took 0.165s
  training loss:		0.012328
  validation loss:		0.355220
  validation accuracy:		92.93 %
Epoch 1024 of 2000 took 0.167s
  training loss:		0.012282
  validation loss:		0.352872
  validation accuracy:		92.83 %
Epoch 1025 of 2000 took 0.175s
  training loss:		0.011882
  validation loss:		0.356619
  validation accuracy:		92.72 %
Epoch 1026 of 2000 took 0.176s
  training loss:		0.012517
  validation loss:		0.351576
  validation accuracy:		92.83 %
Epoch 1027 of 2000 took 0.175s
  training loss:		0.012145
  validation loss:		0.364234
  validation accuracy:		92.61 %
Epoch 1028 of 2000 took 0.167s
  training loss:		0.011947
  validation loss:		0.360720
  validation accuracy:		92.61 %
Epoch 1029 of 2000 took 0.175s
  training loss:		0.012220
  validation loss:		0.357082
  validation accuracy:		92.83 %
Epoch 1030 of 2000 took 0.175s
  training loss:		0.012135
  validation loss:		0.361061
  validation accuracy:		92.83 %
Epoch 1031 of 2000 took 0.175s
  training loss:		0.011848
  validation loss:		0.362118
  validation accuracy:		92.83 %
Epoch 1032 of 2000 took 0.175s
  training loss:		0.012322
  validation loss:		0.361709
  validation accuracy:		92.72 %
Epoch 1033 of 2000 took 0.164s
  training loss:		0.012620
  validation loss:		0.356414
  validation accuracy:		92.72 %
Epoch 1034 of 2000 took 0.143s
  training loss:		0.011575
  validation loss:		0.350900
  validation accuracy:		92.93 %
Epoch 1035 of 2000 took 0.139s
  training loss:		0.011819
  validation loss:		0.359953
  validation accuracy:		92.72 %
Epoch 1036 of 2000 took 0.156s
  training loss:		0.012206
  validation loss:		0.353078
  validation accuracy:		92.72 %
Epoch 1037 of 2000 took 0.130s
  training loss:		0.011645
  validation loss:		0.365468
  validation accuracy:		92.50 %
Epoch 1038 of 2000 took 0.145s
  training loss:		0.011782
  validation loss:		0.354272
  validation accuracy:		92.83 %
Epoch 1039 of 2000 took 0.141s
  training loss:		0.011555
  validation loss:		0.364498
  validation accuracy:		92.72 %
Epoch 1040 of 2000 took 0.153s
  training loss:		0.011923
  validation loss:		0.365592
  validation accuracy:		92.72 %
Epoch 1041 of 2000 took 0.152s
  training loss:		0.012020
  validation loss:		0.356342
  validation accuracy:		92.72 %
Epoch 1042 of 2000 took 0.147s
  training loss:		0.011910
  validation loss:		0.359867
  validation accuracy:		92.72 %
Epoch 1043 of 2000 took 0.149s
  training loss:		0.011788
  validation loss:		0.356340
  validation accuracy:		92.72 %
Epoch 1044 of 2000 took 0.150s
  training loss:		0.011726
  validation loss:		0.363218
  validation accuracy:		92.72 %
Epoch 1045 of 2000 took 0.141s
  training loss:		0.011882
  validation loss:		0.359978
  validation accuracy:		92.61 %
Epoch 1046 of 2000 took 0.139s
  training loss:		0.011561
  validation loss:		0.364910
  validation accuracy:		92.83 %
Epoch 1047 of 2000 took 0.143s
  training loss:		0.011479
  validation loss:		0.362737
  validation accuracy:		92.72 %
Epoch 1048 of 2000 took 0.149s
  training loss:		0.011883
  validation loss:		0.371092
  validation accuracy:		92.72 %
Epoch 1049 of 2000 took 0.142s
  training loss:		0.011605
  validation loss:		0.357332
  validation accuracy:		92.72 %
Epoch 1050 of 2000 took 0.134s
  training loss:		0.011666
  validation loss:		0.353660
  validation accuracy:		92.72 %
Epoch 1051 of 2000 took 0.147s
  training loss:		0.011811
  validation loss:		0.365546
  validation accuracy:		92.72 %
Epoch 1052 of 2000 took 0.140s
  training loss:		0.011625
  validation loss:		0.360896
  validation accuracy:		92.83 %
Epoch 1053 of 2000 took 0.136s
  training loss:		0.011301
  validation loss:		0.359334
  validation accuracy:		92.61 %
Epoch 1054 of 2000 took 0.150s
  training loss:		0.011476
  validation loss:		0.362767
  validation accuracy:		92.93 %
Epoch 1055 of 2000 took 0.136s
  training loss:		0.011386
  validation loss:		0.364823
  validation accuracy:		92.93 %
Epoch 1056 of 2000 took 0.158s
  training loss:		0.011038
  validation loss:		0.361072
  validation accuracy:		92.61 %
Epoch 1057 of 2000 took 0.145s
  training loss:		0.011158
  validation loss:		0.372941
  validation accuracy:		92.61 %
Epoch 1058 of 2000 took 0.154s
  training loss:		0.010999
  validation loss:		0.362642
  validation accuracy:		92.72 %
Epoch 1059 of 2000 took 0.134s
  training loss:		0.011145
  validation loss:		0.356927
  validation accuracy:		92.61 %
Epoch 1060 of 2000 took 0.132s
  training loss:		0.011224
  validation loss:		0.364222
  validation accuracy:		92.61 %
Epoch 1061 of 2000 took 0.133s
  training loss:		0.011164
  validation loss:		0.363854
  validation accuracy:		92.61 %
Epoch 1062 of 2000 took 0.147s
  training loss:		0.011088
  validation loss:		0.362501
  validation accuracy:		92.61 %
Epoch 1063 of 2000 took 0.144s
  training loss:		0.011726
  validation loss:		0.361033
  validation accuracy:		92.72 %
Epoch 1064 of 2000 took 0.142s
  training loss:		0.011504
  validation loss:		0.357877
  validation accuracy:		92.72 %
Epoch 1065 of 2000 took 0.148s
  training loss:		0.011593
  validation loss:		0.366536
  validation accuracy:		92.93 %
Epoch 1066 of 2000 took 0.146s
  training loss:		0.011430
  validation loss:		0.364382
  validation accuracy:		92.72 %
Epoch 1067 of 2000 took 0.148s
  training loss:		0.011027
  validation loss:		0.374017
  validation accuracy:		92.72 %
Epoch 1068 of 2000 took 0.130s
  training loss:		0.011077
  validation loss:		0.367091
  validation accuracy:		92.72 %
Epoch 1069 of 2000 took 0.144s
  training loss:		0.011148
  validation loss:		0.374736
  validation accuracy:		92.72 %
Epoch 1070 of 2000 took 0.145s
  training loss:		0.011126
  validation loss:		0.362822
  validation accuracy:		92.72 %
Epoch 1071 of 2000 took 0.153s
  training loss:		0.010665
  validation loss:		0.375818
  validation accuracy:		92.61 %
Epoch 1072 of 2000 took 0.151s
  training loss:		0.010848
  validation loss:		0.364967
  validation accuracy:		92.50 %
Epoch 1073 of 2000 took 0.175s
  training loss:		0.011161
  validation loss:		0.366534
  validation accuracy:		92.61 %
Epoch 1074 of 2000 took 0.138s
  training loss:		0.010718
  validation loss:		0.367528
  validation accuracy:		92.61 %
Epoch 1075 of 2000 took 0.174s
  training loss:		0.010732
  validation loss:		0.365750
  validation accuracy:		92.72 %
Epoch 1076 of 2000 took 0.175s
  training loss:		0.010851
  validation loss:		0.367972
  validation accuracy:		92.72 %
Epoch 1077 of 2000 took 0.165s
  training loss:		0.010637
  validation loss:		0.365162
  validation accuracy:		92.50 %
Epoch 1078 of 2000 took 0.149s
  training loss:		0.010907
  validation loss:		0.370258
  validation accuracy:		92.72 %
Epoch 1079 of 2000 took 0.142s
  training loss:		0.010627
  validation loss:		0.359336
  validation accuracy:		92.72 %
Epoch 1080 of 2000 took 0.159s
  training loss:		0.010910
  validation loss:		0.365589
  validation accuracy:		92.72 %
Epoch 1081 of 2000 took 0.161s
  training loss:		0.011007
  validation loss:		0.366521
  validation accuracy:		92.61 %
Epoch 1082 of 2000 took 0.172s
  training loss:		0.010631
  validation loss:		0.369284
  validation accuracy:		92.72 %
Epoch 1083 of 2000 took 0.175s
  training loss:		0.010958
  validation loss:		0.377081
  validation accuracy:		92.61 %
Epoch 1084 of 2000 took 0.154s
  training loss:		0.010474
  validation loss:		0.374737
  validation accuracy:		92.61 %
Epoch 1085 of 2000 took 0.143s
  training loss:		0.010805
  validation loss:		0.368677
  validation accuracy:		92.61 %
Epoch 1086 of 2000 took 0.127s
  training loss:		0.010561
  validation loss:		0.371187
  validation accuracy:		92.61 %
Epoch 1087 of 2000 took 0.178s
  training loss:		0.010905
  validation loss:		0.363405
  validation accuracy:		92.72 %
Epoch 1088 of 2000 took 0.162s
  training loss:		0.010394
  validation loss:		0.365175
  validation accuracy:		92.72 %
Epoch 1089 of 2000 took 0.143s
  training loss:		0.010657
  validation loss:		0.381349
  validation accuracy:		92.39 %
Epoch 1090 of 2000 took 0.173s
  training loss:		0.011090
  validation loss:		0.368251
  validation accuracy:		92.72 %
Epoch 1091 of 2000 took 0.176s
  training loss:		0.010303
  validation loss:		0.368162
  validation accuracy:		92.72 %
Epoch 1092 of 2000 took 0.176s
  training loss:		0.010582
  validation loss:		0.373976
  validation accuracy:		92.39 %
Epoch 1093 of 2000 took 0.175s
  training loss:		0.010534
  validation loss:		0.369001
  validation accuracy:		92.72 %
Epoch 1094 of 2000 took 0.176s
  training loss:		0.010788
  validation loss:		0.377503
  validation accuracy:		92.83 %
Epoch 1095 of 2000 took 0.176s
  training loss:		0.010450
  validation loss:		0.372423
  validation accuracy:		92.83 %
Epoch 1096 of 2000 took 0.176s
  training loss:		0.010270
  validation loss:		0.374024
  validation accuracy:		92.83 %
Epoch 1097 of 2000 took 0.176s
  training loss:		0.010295
  validation loss:		0.364388
  validation accuracy:		92.83 %
Epoch 1098 of 2000 took 0.176s
  training loss:		0.010605
  validation loss:		0.369076
  validation accuracy:		92.61 %
Epoch 1099 of 2000 took 0.171s
  training loss:		0.010322
  validation loss:		0.376417
  validation accuracy:		92.83 %
Epoch 1100 of 2000 took 0.162s
  training loss:		0.010605
  validation loss:		0.370557
  validation accuracy:		92.61 %
Epoch 1101 of 2000 took 0.148s
  training loss:		0.009895
  validation loss:		0.372517
  validation accuracy:		92.83 %
Epoch 1102 of 2000 took 0.174s
  training loss:		0.010466
  validation loss:		0.372706
  validation accuracy:		92.61 %
Epoch 1103 of 2000 took 0.173s
  training loss:		0.010399
  validation loss:		0.363017
  validation accuracy:		92.72 %
Epoch 1104 of 2000 took 0.142s
  training loss:		0.010533
  validation loss:		0.369882
  validation accuracy:		92.61 %
Epoch 1105 of 2000 took 0.134s
  training loss:		0.009816
  validation loss:		0.380876
  validation accuracy:		92.83 %
Epoch 1106 of 2000 took 0.177s
  training loss:		0.010427
  validation loss:		0.376537
  validation accuracy:		92.83 %
Epoch 1107 of 2000 took 0.175s
  training loss:		0.010506
  validation loss:		0.380288
  validation accuracy:		92.61 %
Epoch 1108 of 2000 took 0.156s
  training loss:		0.009935
  validation loss:		0.372838
  validation accuracy:		92.72 %
Epoch 1109 of 2000 took 0.175s
  training loss:		0.010286
  validation loss:		0.373873
  validation accuracy:		92.72 %
Epoch 1110 of 2000 took 0.176s
  training loss:		0.010101
  validation loss:		0.375622
  validation accuracy:		92.61 %
Epoch 1111 of 2000 took 0.175s
  training loss:		0.010088
  validation loss:		0.373202
  validation accuracy:		92.61 %
Epoch 1112 of 2000 took 0.175s
  training loss:		0.010049
  validation loss:		0.381320
  validation accuracy:		92.72 %
Epoch 1113 of 2000 took 0.171s
  training loss:		0.009932
  validation loss:		0.378855
  validation accuracy:		92.83 %
Epoch 1114 of 2000 took 0.143s
  training loss:		0.010427
  validation loss:		0.374042
  validation accuracy:		92.72 %
Epoch 1115 of 2000 took 0.139s
  training loss:		0.010157
  validation loss:		0.386257
  validation accuracy:		92.50 %
Epoch 1116 of 2000 took 0.156s
  training loss:		0.010033
  validation loss:		0.373231
  validation accuracy:		92.61 %
Epoch 1117 of 2000 took 0.172s
  training loss:		0.009823
  validation loss:		0.372234
  validation accuracy:		92.72 %
Epoch 1118 of 2000 took 0.175s
  training loss:		0.010061
  validation loss:		0.375374
  validation accuracy:		92.83 %
Epoch 1119 of 2000 took 0.175s
  training loss:		0.009866
  validation loss:		0.371854
  validation accuracy:		92.61 %
Epoch 1120 of 2000 took 0.159s
  training loss:		0.009962
  validation loss:		0.370145
  validation accuracy:		92.61 %
Epoch 1121 of 2000 took 0.133s
  training loss:		0.010069
  validation loss:		0.376529
  validation accuracy:		92.39 %
Epoch 1122 of 2000 took 0.155s
  training loss:		0.010009
  validation loss:		0.373539
  validation accuracy:		92.83 %
Epoch 1123 of 2000 took 0.155s
  training loss:		0.009750
  validation loss:		0.374718
  validation accuracy:		92.61 %
Epoch 1124 of 2000 took 0.170s
  training loss:		0.009348
  validation loss:		0.377803
  validation accuracy:		92.72 %
Epoch 1125 of 2000 took 0.145s
  training loss:		0.009579
  validation loss:		0.371730
  validation accuracy:		92.72 %
Epoch 1126 of 2000 took 0.144s
  training loss:		0.009896
  validation loss:		0.367074
  validation accuracy:		92.83 %
Epoch 1127 of 2000 took 0.127s
  training loss:		0.010011
  validation loss:		0.372992
  validation accuracy:		92.50 %
Epoch 1128 of 2000 took 0.139s
  training loss:		0.009888
  validation loss:		0.374693
  validation accuracy:		92.72 %
Epoch 1129 of 2000 took 0.137s
  training loss:		0.009519
  validation loss:		0.386671
  validation accuracy:		92.50 %
Epoch 1130 of 2000 took 0.135s
  training loss:		0.010056
  validation loss:		0.379343
  validation accuracy:		92.39 %
Epoch 1131 of 2000 took 0.133s
  training loss:		0.009395
  validation loss:		0.379010
  validation accuracy:		92.72 %
Epoch 1132 of 2000 took 0.138s
  training loss:		0.009443
  validation loss:		0.390745
  validation accuracy:		92.72 %
Epoch 1133 of 2000 took 0.133s
  training loss:		0.009731
  validation loss:		0.376232
  validation accuracy:		92.72 %
Epoch 1134 of 2000 took 0.141s
  training loss:		0.009574
  validation loss:		0.379445
  validation accuracy:		92.61 %
Epoch 1135 of 2000 took 0.174s
  training loss:		0.009558
  validation loss:		0.370427
  validation accuracy:		92.72 %
Epoch 1136 of 2000 took 0.160s
  training loss:		0.009549
  validation loss:		0.387287
  validation accuracy:		92.50 %
Epoch 1137 of 2000 took 0.137s
  training loss:		0.009719
  validation loss:		0.378717
  validation accuracy:		92.72 %
Epoch 1138 of 2000 took 0.138s
  training loss:		0.009325
  validation loss:		0.385929
  validation accuracy:		92.50 %
Epoch 1139 of 2000 took 0.176s
  training loss:		0.009585
  validation loss:		0.380691
  validation accuracy:		92.72 %
Epoch 1140 of 2000 took 0.175s
  training loss:		0.009523
  validation loss:		0.377369
  validation accuracy:		92.61 %
Epoch 1141 of 2000 took 0.172s
  training loss:		0.009475
  validation loss:		0.382521
  validation accuracy:		92.83 %
Epoch 1142 of 2000 took 0.138s
  training loss:		0.009376
  validation loss:		0.387363
  validation accuracy:		92.39 %
Epoch 1143 of 2000 took 0.146s
  training loss:		0.009563
  validation loss:		0.384848
  validation accuracy:		92.50 %
Epoch 1144 of 2000 took 0.140s
  training loss:		0.009493
  validation loss:		0.378912
  validation accuracy:		92.83 %
Epoch 1145 of 2000 took 0.144s
  training loss:		0.009432
  validation loss:		0.392561
  validation accuracy:		92.50 %
Epoch 1146 of 2000 took 0.157s
  training loss:		0.009255
  validation loss:		0.378253
  validation accuracy:		92.72 %
Epoch 1147 of 2000 took 0.170s
  training loss:		0.009177
  validation loss:		0.385071
  validation accuracy:		92.83 %
Epoch 1148 of 2000 took 0.137s
  training loss:		0.009489
  validation loss:		0.384796
  validation accuracy:		92.61 %
Epoch 1149 of 2000 took 0.169s
  training loss:		0.009182
  validation loss:		0.377646
  validation accuracy:		92.83 %
Epoch 1150 of 2000 took 0.175s
  training loss:		0.009543
  validation loss:		0.376050
  validation accuracy:		92.93 %
Epoch 1151 of 2000 took 0.143s
  training loss:		0.009494
  validation loss:		0.383558
  validation accuracy:		92.72 %
Epoch 1152 of 2000 took 0.157s
  training loss:		0.009014
  validation loss:		0.373416
  validation accuracy:		92.83 %
Epoch 1153 of 2000 took 0.166s
  training loss:		0.009120
  validation loss:		0.374860
  validation accuracy:		92.72 %
Epoch 1154 of 2000 took 0.155s
  training loss:		0.009587
  validation loss:		0.384339
  validation accuracy:		92.61 %
Epoch 1155 of 2000 took 0.144s
  training loss:		0.009053
  validation loss:		0.382110
  validation accuracy:		92.61 %
Epoch 1156 of 2000 took 0.175s
  training loss:		0.009327
  validation loss:		0.382776
  validation accuracy:		92.72 %
Epoch 1157 of 2000 took 0.175s
  training loss:		0.009072
  validation loss:		0.376871
  validation accuracy:		92.50 %
Epoch 1158 of 2000 took 0.177s
  training loss:		0.009044
  validation loss:		0.384165
  validation accuracy:		92.72 %
Epoch 1159 of 2000 took 0.174s
  training loss:		0.009353
  validation loss:		0.385568
  validation accuracy:		92.72 %
Epoch 1160 of 2000 took 0.175s
  training loss:		0.009139
  validation loss:		0.382035
  validation accuracy:		92.72 %
Epoch 1161 of 2000 took 0.173s
  training loss:		0.008994
  validation loss:		0.382556
  validation accuracy:		92.72 %
Epoch 1162 of 2000 took 0.166s
  training loss:		0.009170
  validation loss:		0.383625
  validation accuracy:		92.50 %
Epoch 1163 of 2000 took 0.147s
  training loss:		0.008941
  validation loss:		0.380094
  validation accuracy:		92.61 %
Epoch 1164 of 2000 took 0.170s
  training loss:		0.009040
  validation loss:		0.388120
  validation accuracy:		92.61 %
Epoch 1165 of 2000 took 0.174s
  training loss:		0.008812
  validation loss:		0.387689
  validation accuracy:		92.72 %
Epoch 1166 of 2000 took 0.146s
  training loss:		0.008919
  validation loss:		0.382512
  validation accuracy:		92.72 %
Epoch 1167 of 2000 took 0.158s
  training loss:		0.008960
  validation loss:		0.390243
  validation accuracy:		92.72 %
Epoch 1168 of 2000 took 0.140s
  training loss:		0.008722
  validation loss:		0.379869
  validation accuracy:		92.61 %
Epoch 1169 of 2000 took 0.131s
  training loss:		0.008752
  validation loss:		0.379859
  validation accuracy:		92.72 %
Epoch 1170 of 2000 took 0.145s
  training loss:		0.008977
  validation loss:		0.384913
  validation accuracy:		92.72 %
Epoch 1171 of 2000 took 0.156s
  training loss:		0.009030
  validation loss:		0.383372
  validation accuracy:		92.83 %
Epoch 1172 of 2000 took 0.175s
  training loss:		0.008669
  validation loss:		0.384563
  validation accuracy:		92.61 %
Epoch 1173 of 2000 took 0.175s
  training loss:		0.008959
  validation loss:		0.391655
  validation accuracy:		92.28 %
Epoch 1174 of 2000 took 0.148s
  training loss:		0.008901
  validation loss:		0.381902
  validation accuracy:		92.72 %
Epoch 1175 of 2000 took 0.149s
  training loss:		0.008648
  validation loss:		0.390533
  validation accuracy:		92.72 %
Epoch 1176 of 2000 took 0.154s
  training loss:		0.008842
  validation loss:		0.383135
  validation accuracy:		92.50 %
Epoch 1177 of 2000 took 0.161s
  training loss:		0.008753
  validation loss:		0.381230
  validation accuracy:		92.61 %
Epoch 1178 of 2000 took 0.159s
  training loss:		0.008759
  validation loss:		0.387288
  validation accuracy:		92.72 %
Epoch 1179 of 2000 took 0.169s
  training loss:		0.008660
  validation loss:		0.381169
  validation accuracy:		92.61 %
Epoch 1180 of 2000 took 0.175s
  training loss:		0.008767
  validation loss:		0.383620
  validation accuracy:		92.72 %
Epoch 1181 of 2000 took 0.150s
  training loss:		0.008463
  validation loss:		0.390929
  validation accuracy:		92.83 %
Epoch 1182 of 2000 took 0.142s
  training loss:		0.008947
  validation loss:		0.383434
  validation accuracy:		92.61 %
Epoch 1183 of 2000 took 0.138s
  training loss:		0.008395
  validation loss:		0.385525
  validation accuracy:		92.61 %
Epoch 1184 of 2000 took 0.136s
  training loss:		0.008455
  validation loss:		0.397124
  validation accuracy:		92.61 %
Epoch 1185 of 2000 took 0.159s
  training loss:		0.008516
  validation loss:		0.381679
  validation accuracy:		92.50 %
Epoch 1186 of 2000 took 0.167s
  training loss:		0.008576
  validation loss:		0.393428
  validation accuracy:		92.61 %
Epoch 1187 of 2000 took 0.142s
  training loss:		0.008310
  validation loss:		0.383881
  validation accuracy:		92.61 %
Epoch 1188 of 2000 took 0.143s
  training loss:		0.008914
  validation loss:		0.388976
  validation accuracy:		92.72 %
Epoch 1189 of 2000 took 0.150s
  training loss:		0.008399
  validation loss:		0.384549
  validation accuracy:		92.61 %
Epoch 1190 of 2000 took 0.154s
  training loss:		0.008244
  validation loss:		0.392465
  validation accuracy:		92.72 %
Epoch 1191 of 2000 took 0.170s
  training loss:		0.008350
  validation loss:		0.385347
  validation accuracy:		92.61 %
Epoch 1192 of 2000 took 0.174s
  training loss:		0.008413
  validation loss:		0.387513
  validation accuracy:		92.61 %
Epoch 1193 of 2000 took 0.160s
  training loss:		0.008646
  validation loss:		0.389027
  validation accuracy:		92.72 %
Epoch 1194 of 2000 took 0.147s
  training loss:		0.008374
  validation loss:		0.395293
  validation accuracy:		92.83 %
Epoch 1195 of 2000 took 0.161s
  training loss:		0.008360
  validation loss:		0.387331
  validation accuracy:		92.61 %
Epoch 1196 of 2000 took 0.135s
  training loss:		0.008336
  validation loss:		0.385303
  validation accuracy:		92.72 %
Epoch 1197 of 2000 took 0.141s
  training loss:		0.008005
  validation loss:		0.390571
  validation accuracy:		92.83 %
Epoch 1198 of 2000 took 0.143s
  training loss:		0.008390
  validation loss:		0.392034
  validation accuracy:		92.72 %
Epoch 1199 of 2000 took 0.175s
  training loss:		0.008237
  validation loss:		0.387203
  validation accuracy:		92.72 %
Epoch 1200 of 2000 took 0.139s
  training loss:		0.008370
  validation loss:		0.388718
  validation accuracy:		92.83 %
Epoch 1201 of 2000 took 0.145s
  training loss:		0.008504
  validation loss:		0.396228
  validation accuracy:		92.50 %
Epoch 1202 of 2000 took 0.141s
  training loss:		0.008388
  validation loss:		0.387639
  validation accuracy:		92.72 %
Epoch 1203 of 2000 took 0.134s
  training loss:		0.008111
  validation loss:		0.388327
  validation accuracy:		92.72 %
Epoch 1204 of 2000 took 0.144s
  training loss:		0.008268
  validation loss:		0.386266
  validation accuracy:		92.61 %
Epoch 1205 of 2000 took 0.172s
  training loss:		0.008171
  validation loss:		0.394339
  validation accuracy:		92.72 %
Epoch 1206 of 2000 took 0.160s
  training loss:		0.008332
  validation loss:		0.396024
  validation accuracy:		92.61 %
Epoch 1207 of 2000 took 0.134s
  training loss:		0.008186
  validation loss:		0.386426
  validation accuracy:		92.61 %
Epoch 1208 of 2000 took 0.139s
  training loss:		0.007850
  validation loss:		0.394411
  validation accuracy:		92.61 %
Epoch 1209 of 2000 took 0.150s
  training loss:		0.008183
  validation loss:		0.392751
  validation accuracy:		92.83 %
Epoch 1210 of 2000 took 0.151s
  training loss:		0.008080
  validation loss:		0.392855
  validation accuracy:		92.83 %
Epoch 1211 of 2000 took 0.140s
  training loss:		0.008106
  validation loss:		0.397587
  validation accuracy:		92.72 %
Epoch 1212 of 2000 took 0.147s
  training loss:		0.007988
  validation loss:		0.391150
  validation accuracy:		92.61 %
Epoch 1213 of 2000 took 0.139s
  training loss:		0.008148
  validation loss:		0.397693
  validation accuracy:		92.72 %
Epoch 1214 of 2000 took 0.140s
  training loss:		0.007927
  validation loss:		0.386211
  validation accuracy:		92.61 %
Epoch 1215 of 2000 took 0.136s
  training loss:		0.008001
  validation loss:		0.391407
  validation accuracy:		92.50 %
Epoch 1216 of 2000 took 0.139s
  training loss:		0.008346
  validation loss:		0.397989
  validation accuracy:		92.61 %
Epoch 1217 of 2000 took 0.149s
  training loss:		0.008191
  validation loss:		0.395100
  validation accuracy:		92.61 %
Epoch 1218 of 2000 took 0.131s
  training loss:		0.008078
  validation loss:		0.392035
  validation accuracy:		92.72 %
Epoch 1219 of 2000 took 0.175s
  training loss:		0.008332
  validation loss:		0.395272
  validation accuracy:		92.72 %
Epoch 1220 of 2000 took 0.169s
  training loss:		0.008047
  validation loss:		0.392294
  validation accuracy:		92.72 %
Epoch 1221 of 2000 took 0.172s
  training loss:		0.008069
  validation loss:		0.386683
  validation accuracy:		92.50 %
Epoch 1222 of 2000 took 0.173s
  training loss:		0.008276
  validation loss:		0.397134
  validation accuracy:		92.72 %
Epoch 1223 of 2000 took 0.145s
  training loss:		0.008003
  validation loss:		0.389106
  validation accuracy:		92.61 %
Epoch 1224 of 2000 took 0.140s
  training loss:		0.008171
  validation loss:		0.389854
  validation accuracy:		92.83 %
Epoch 1225 of 2000 took 0.132s
  training loss:		0.007949
  validation loss:		0.394183
  validation accuracy:		92.61 %
Epoch 1226 of 2000 took 0.124s
  training loss:		0.008016
  validation loss:		0.394035
  validation accuracy:		92.83 %
Epoch 1227 of 2000 took 0.167s
  training loss:		0.007955
  validation loss:		0.395337
  validation accuracy:		92.61 %
Epoch 1228 of 2000 took 0.162s
  training loss:		0.007850
  validation loss:		0.396076
  validation accuracy:		92.83 %
Epoch 1229 of 2000 took 0.142s
  training loss:		0.007914
  validation loss:		0.397710
  validation accuracy:		92.61 %
Epoch 1230 of 2000 took 0.140s
  training loss:		0.007810
  validation loss:		0.400294
  validation accuracy:		92.39 %
Epoch 1231 of 2000 took 0.139s
  training loss:		0.007954
  validation loss:		0.391978
  validation accuracy:		92.72 %
Epoch 1232 of 2000 took 0.175s
  training loss:		0.008196
  validation loss:		0.401159
  validation accuracy:		92.50 %
Epoch 1233 of 2000 took 0.136s
  training loss:		0.007746
  validation loss:		0.401832
  validation accuracy:		92.93 %
Epoch 1234 of 2000 took 0.165s
  training loss:		0.008041
  validation loss:		0.395988
  validation accuracy:		92.50 %
Epoch 1235 of 2000 took 0.175s
  training loss:		0.007910
  validation loss:		0.394048
  validation accuracy:		92.72 %
Epoch 1236 of 2000 took 0.174s
  training loss:		0.007741
  validation loss:		0.391436
  validation accuracy:		92.61 %
Epoch 1237 of 2000 took 0.173s
  training loss:		0.007384
  validation loss:		0.394544
  validation accuracy:		92.61 %
Epoch 1238 of 2000 took 0.162s
  training loss:		0.007498
  validation loss:		0.401267
  validation accuracy:		92.61 %
Epoch 1239 of 2000 took 0.149s
  training loss:		0.007913
  validation loss:		0.392650
  validation accuracy:		92.61 %
Epoch 1240 of 2000 took 0.172s
  training loss:		0.007909
  validation loss:		0.396051
  validation accuracy:		92.72 %
Epoch 1241 of 2000 took 0.176s
  training loss:		0.007820
  validation loss:		0.393446
  validation accuracy:		92.72 %
Epoch 1242 of 2000 took 0.158s
  training loss:		0.007649
  validation loss:		0.403700
  validation accuracy:		92.83 %
Epoch 1243 of 2000 took 0.175s
  training loss:		0.007677
  validation loss:		0.396379
  validation accuracy:		92.61 %
Epoch 1244 of 2000 took 0.147s
  training loss:		0.007357
  validation loss:		0.404607
  validation accuracy:		92.72 %
Epoch 1245 of 2000 took 0.170s
  training loss:		0.007691
  validation loss:		0.393233
  validation accuracy:		92.61 %
Epoch 1246 of 2000 took 0.174s
  training loss:		0.007422
  validation loss:		0.396076
  validation accuracy:		92.72 %
Epoch 1247 of 2000 took 0.166s
  training loss:		0.007449
  validation loss:		0.400201
  validation accuracy:		92.61 %
Epoch 1248 of 2000 took 0.173s
  training loss:		0.007440
  validation loss:		0.399870
  validation accuracy:		92.72 %
Epoch 1249 of 2000 took 0.141s
  training loss:		0.007660
  validation loss:		0.398677
  validation accuracy:		92.61 %
Epoch 1250 of 2000 took 0.144s
  training loss:		0.007806
  validation loss:		0.394779
  validation accuracy:		92.61 %
Epoch 1251 of 2000 took 0.132s
  training loss:		0.007677
  validation loss:		0.407769
  validation accuracy:		92.61 %
Epoch 1252 of 2000 took 0.137s
  training loss:		0.007605
  validation loss:		0.393247
  validation accuracy:		92.50 %
Epoch 1253 of 2000 took 0.142s
  training loss:		0.007332
  validation loss:		0.398654
  validation accuracy:		92.72 %
Epoch 1254 of 2000 took 0.133s
  training loss:		0.007345
  validation loss:		0.401004
  validation accuracy:		92.72 %
Epoch 1255 of 2000 took 0.155s
  training loss:		0.007459
  validation loss:		0.396050
  validation accuracy:		92.61 %
Epoch 1256 of 2000 took 0.139s
  training loss:		0.007332
  validation loss:		0.403241
  validation accuracy:		92.50 %
Epoch 1257 of 2000 took 0.144s
  training loss:		0.007890
  validation loss:		0.403187
  validation accuracy:		92.61 %
Epoch 1258 of 2000 took 0.132s
  training loss:		0.007431
  validation loss:		0.406002
  validation accuracy:		92.61 %
Epoch 1259 of 2000 took 0.178s
  training loss:		0.007291
  validation loss:		0.397157
  validation accuracy:		92.61 %
Epoch 1260 of 2000 took 0.169s
  training loss:		0.007298
  validation loss:		0.406619
  validation accuracy:		92.72 %
Epoch 1261 of 2000 took 0.138s
  training loss:		0.007337
  validation loss:		0.401616
  validation accuracy:		92.72 %
Epoch 1262 of 2000 took 0.136s
  training loss:		0.007426
  validation loss:		0.404792
  validation accuracy:		92.50 %
Epoch 1263 of 2000 took 0.161s
  training loss:		0.007306
  validation loss:		0.403390
  validation accuracy:		92.50 %
Epoch 1264 of 2000 took 0.173s
  training loss:		0.007392
  validation loss:		0.398004
  validation accuracy:		92.72 %
Epoch 1265 of 2000 took 0.173s
  training loss:		0.007364
  validation loss:		0.395316
  validation accuracy:		92.72 %
Epoch 1266 of 2000 took 0.161s
  training loss:		0.007147
  validation loss:		0.407278
  validation accuracy:		92.72 %
Epoch 1267 of 2000 took 0.168s
  training loss:		0.007179
  validation loss:		0.399199
  validation accuracy:		92.50 %
Epoch 1268 of 2000 took 0.173s
  training loss:		0.007477
  validation loss:		0.398071
  validation accuracy:		92.72 %
Epoch 1269 of 2000 took 0.145s
  training loss:		0.007466
  validation loss:		0.405069
  validation accuracy:		92.50 %
Epoch 1270 of 2000 took 0.136s
  training loss:		0.007219
  validation loss:		0.404211
  validation accuracy:		92.61 %
Epoch 1271 of 2000 took 0.150s
  training loss:		0.007731
  validation loss:		0.404203
  validation accuracy:		92.50 %
Epoch 1272 of 2000 took 0.174s
  training loss:		0.007061
  validation loss:		0.398231
  validation accuracy:		92.61 %
Epoch 1273 of 2000 took 0.167s
  training loss:		0.007028
  validation loss:		0.405841
  validation accuracy:		92.50 %
Epoch 1274 of 2000 took 0.171s
  training loss:		0.007242
  validation loss:		0.398736
  validation accuracy:		92.61 %
Epoch 1275 of 2000 took 0.169s
  training loss:		0.007164
  validation loss:		0.411087
  validation accuracy:		92.61 %
Epoch 1276 of 2000 took 0.129s
  training loss:		0.007213
  validation loss:		0.402931
  validation accuracy:		92.72 %
Epoch 1277 of 2000 took 0.145s
  training loss:		0.007160
  validation loss:		0.408670
  validation accuracy:		92.61 %
Epoch 1278 of 2000 took 0.144s
  training loss:		0.007239
  validation loss:		0.408644
  validation accuracy:		92.39 %
Epoch 1279 of 2000 took 0.140s
  training loss:		0.007201
  validation loss:		0.407223
  validation accuracy:		92.61 %
Epoch 1280 of 2000 took 0.146s
  training loss:		0.007081
  validation loss:		0.399943
  validation accuracy:		92.61 %
Epoch 1281 of 2000 took 0.138s
  training loss:		0.007033
  validation loss:		0.401377
  validation accuracy:		92.61 %
Epoch 1282 of 2000 took 0.136s
  training loss:		0.007126
  validation loss:		0.404683
  validation accuracy:		92.61 %
Epoch 1283 of 2000 took 0.171s
  training loss:		0.006982
  validation loss:		0.401339
  validation accuracy:		92.50 %
Epoch 1284 of 2000 took 0.157s
  training loss:		0.006799
  validation loss:		0.400428
  validation accuracy:		92.83 %
Epoch 1285 of 2000 took 0.170s
  training loss:		0.007188
  validation loss:		0.406053
  validation accuracy:		92.72 %
Epoch 1286 of 2000 took 0.153s
  training loss:		0.006997
  validation loss:		0.404502
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.156s
  training loss:		0.007058
  validation loss:		0.408470
  validation accuracy:		92.61 %
Epoch 1288 of 2000 took 0.174s
  training loss:		0.007243
  validation loss:		0.414602
  validation accuracy:		92.72 %
Epoch 1289 of 2000 took 0.147s
  training loss:		0.007163
  validation loss:		0.405474
  validation accuracy:		92.50 %
Epoch 1290 of 2000 took 0.139s
  training loss:		0.007176
  validation loss:		0.409099
  validation accuracy:		92.50 %
Epoch 1291 of 2000 took 0.154s
  training loss:		0.007059
  validation loss:		0.408342
  validation accuracy:		92.72 %
Epoch 1292 of 2000 took 0.162s
  training loss:		0.007056
  validation loss:		0.402077
  validation accuracy:		92.72 %
Epoch 1293 of 2000 took 0.155s
  training loss:		0.007069
  validation loss:		0.410391
  validation accuracy:		92.72 %
Epoch 1294 of 2000 took 0.138s
  training loss:		0.006949
  validation loss:		0.416131
  validation accuracy:		92.61 %
Epoch 1295 of 2000 took 0.138s
  training loss:		0.006911
  validation loss:		0.404380
  validation accuracy:		92.50 %
Epoch 1296 of 2000 took 0.169s
  training loss:		0.007070
  validation loss:		0.409777
  validation accuracy:		92.72 %
Epoch 1297 of 2000 took 0.176s
  training loss:		0.007053
  validation loss:		0.416413
  validation accuracy:		92.72 %
Epoch 1298 of 2000 took 0.173s
  training loss:		0.006829
  validation loss:		0.408873
  validation accuracy:		92.61 %
Epoch 1299 of 2000 took 0.171s
  training loss:		0.006918
  validation loss:		0.408142
  validation accuracy:		92.61 %
Epoch 1300 of 2000 took 0.138s
  training loss:		0.007121
  validation loss:		0.408178
  validation accuracy:		92.72 %
Epoch 1301 of 2000 took 0.136s
  training loss:		0.006839
  validation loss:		0.404837
  validation accuracy:		92.83 %
Epoch 1302 of 2000 took 0.135s
  training loss:		0.006938
  validation loss:		0.405220
  validation accuracy:		92.50 %
Epoch 1303 of 2000 took 0.138s
  training loss:		0.006768
  validation loss:		0.409596
  validation accuracy:		92.61 %
Epoch 1304 of 2000 took 0.133s
  training loss:		0.006835
  validation loss:		0.411467
  validation accuracy:		92.72 %
Epoch 1305 of 2000 took 0.138s
  training loss:		0.006824
  validation loss:		0.414045
  validation accuracy:		92.72 %
Epoch 1306 of 2000 took 0.140s
  training loss:		0.006778
  validation loss:		0.411162
  validation accuracy:		92.50 %
Epoch 1307 of 2000 took 0.135s
  training loss:		0.006915
  validation loss:		0.404948
  validation accuracy:		92.61 %
Epoch 1308 of 2000 took 0.131s
  training loss:		0.006675
  validation loss:		0.404913
  validation accuracy:		92.72 %
Epoch 1309 of 2000 took 0.165s
  training loss:		0.006471
  validation loss:		0.408713
  validation accuracy:		92.61 %
Epoch 1310 of 2000 took 0.137s
  training loss:		0.006908
  validation loss:		0.408007
  validation accuracy:		92.72 %
Epoch 1311 of 2000 took 0.176s
  training loss:		0.006679
  validation loss:		0.414731
  validation accuracy:		92.72 %
Epoch 1312 of 2000 took 0.174s
  training loss:		0.006878
  validation loss:		0.411299
  validation accuracy:		92.83 %
Epoch 1313 of 2000 took 0.165s
  training loss:		0.006753
  validation loss:		0.414709
  validation accuracy:		92.39 %
Epoch 1314 of 2000 took 0.169s
  training loss:		0.006585
  validation loss:		0.410325
  validation accuracy:		92.72 %
Epoch 1315 of 2000 took 0.174s
  training loss:		0.006861
  validation loss:		0.415740
  validation accuracy:		92.72 %
Epoch 1316 of 2000 took 0.175s
  training loss:		0.006521
  validation loss:		0.403735
  validation accuracy:		92.50 %
Epoch 1317 of 2000 took 0.174s
  training loss:		0.006689
  validation loss:		0.417562
  validation accuracy:		92.50 %
Epoch 1318 of 2000 took 0.159s
  training loss:		0.006574
  validation loss:		0.405998
  validation accuracy:		92.72 %
Epoch 1319 of 2000 took 0.141s
  training loss:		0.006764
  validation loss:		0.408161
  validation accuracy:		92.61 %
Epoch 1320 of 2000 took 0.136s
  training loss:		0.006476
  validation loss:		0.415774
  validation accuracy:		92.72 %
Epoch 1321 of 2000 took 0.134s
  training loss:		0.006606
  validation loss:		0.411153
  validation accuracy:		92.50 %
Epoch 1322 of 2000 took 0.157s
  training loss:		0.006450
  validation loss:		0.415616
  validation accuracy:		92.83 %
Epoch 1323 of 2000 took 0.151s
  training loss:		0.006733
  validation loss:		0.410630
  validation accuracy:		92.72 %
Epoch 1324 of 2000 took 0.144s
  training loss:		0.006537
  validation loss:		0.411505
  validation accuracy:		92.72 %
Epoch 1325 of 2000 took 0.136s
  training loss:		0.006554
  validation loss:		0.419146
  validation accuracy:		92.50 %
Epoch 1326 of 2000 took 0.134s
  training loss:		0.006560
  validation loss:		0.409155
  validation accuracy:		92.72 %
Epoch 1327 of 2000 took 0.151s
  training loss:		0.006782
  validation loss:		0.411856
  validation accuracy:		92.72 %
Epoch 1328 of 2000 took 0.159s
  training loss:		0.006356
  validation loss:		0.420415
  validation accuracy:		92.50 %
Epoch 1329 of 2000 took 0.157s
  training loss:		0.006474
  validation loss:		0.408299
  validation accuracy:		92.72 %
Epoch 1330 of 2000 took 0.134s
  training loss:		0.006458
  validation loss:		0.418206
  validation accuracy:		92.72 %
Epoch 1331 of 2000 took 0.148s
  training loss:		0.006610
  validation loss:		0.410961
  validation accuracy:		92.61 %
Epoch 1332 of 2000 took 0.145s
  training loss:		0.006452
  validation loss:		0.416878
  validation accuracy:		92.61 %
Epoch 1333 of 2000 took 0.131s
  training loss:		0.006486
  validation loss:		0.406569
  validation accuracy:		92.72 %
Epoch 1334 of 2000 took 0.145s
  training loss:		0.006375
  validation loss:		0.413883
  validation accuracy:		92.83 %
Epoch 1335 of 2000 took 0.135s
  training loss:		0.006494
  validation loss:		0.414867
  validation accuracy:		92.72 %
Epoch 1336 of 2000 took 0.130s
  training loss:		0.006361
  validation loss:		0.417681
  validation accuracy:		92.39 %
Epoch 1337 of 2000 took 0.140s
  training loss:		0.006428
  validation loss:		0.417664
  validation accuracy:		92.61 %
Epoch 1338 of 2000 took 0.142s
  training loss:		0.006530
  validation loss:		0.416137
  validation accuracy:		92.72 %
Epoch 1339 of 2000 took 0.142s
  training loss:		0.006403
  validation loss:		0.413110
  validation accuracy:		92.72 %
Epoch 1340 of 2000 took 0.137s
  training loss:		0.006442
  validation loss:		0.416457
  validation accuracy:		92.61 %
Epoch 1341 of 2000 took 0.140s
  training loss:		0.006661
  validation loss:		0.413344
  validation accuracy:		92.72 %
Epoch 1342 of 2000 took 0.144s
  training loss:		0.006392
  validation loss:		0.413991
  validation accuracy:		92.72 %
Epoch 1343 of 2000 took 0.134s
  training loss:		0.006413
  validation loss:		0.411384
  validation accuracy:		92.61 %
Epoch 1344 of 2000 took 0.129s
  training loss:		0.006567
  validation loss:		0.416984
  validation accuracy:		92.72 %
Epoch 1345 of 2000 took 0.130s
  training loss:		0.006334
  validation loss:		0.422147
  validation accuracy:		92.39 %
Epoch 1346 of 2000 took 0.135s
  training loss:		0.006301
  validation loss:		0.415793
  validation accuracy:		92.72 %
Epoch 1347 of 2000 took 0.136s
  training loss:		0.006439
  validation loss:		0.413856
  validation accuracy:		92.61 %
Epoch 1348 of 2000 took 0.127s
  training loss:		0.006443
  validation loss:		0.423584
  validation accuracy:		92.72 %
Epoch 1349 of 2000 took 0.146s
  training loss:		0.006383
  validation loss:		0.416686
  validation accuracy:		92.72 %
Epoch 1350 of 2000 took 0.135s
  training loss:		0.006156
  validation loss:		0.414152
  validation accuracy:		92.72 %
Epoch 1351 of 2000 took 0.139s
  training loss:		0.006272
  validation loss:		0.422756
  validation accuracy:		92.39 %
Epoch 1352 of 2000 took 0.142s
  training loss:		0.006080
  validation loss:		0.411598
  validation accuracy:		92.50 %
Epoch 1353 of 2000 took 0.153s
  training loss:		0.006067
  validation loss:		0.411602
  validation accuracy:		92.83 %
Epoch 1354 of 2000 took 0.146s
  training loss:		0.006265
  validation loss:		0.417978
  validation accuracy:		92.50 %
Epoch 1355 of 2000 took 0.149s
  training loss:		0.006267
  validation loss:		0.412777
  validation accuracy:		92.61 %
Epoch 1356 of 2000 took 0.143s
  training loss:		0.006271
  validation loss:		0.417931
  validation accuracy:		92.72 %
Epoch 1357 of 2000 took 0.148s
  training loss:		0.006170
  validation loss:		0.416695
  validation accuracy:		92.72 %
Epoch 1358 of 2000 took 0.168s
  training loss:		0.005991
  validation loss:		0.421758
  validation accuracy:		92.50 %
Epoch 1359 of 2000 took 0.140s
  training loss:		0.006227
  validation loss:		0.419982
  validation accuracy:		92.61 %
Epoch 1360 of 2000 took 0.129s
  training loss:		0.006215
  validation loss:		0.420870
  validation accuracy:		92.50 %
Epoch 1361 of 2000 took 0.145s
  training loss:		0.006034
  validation loss:		0.422865
  validation accuracy:		92.50 %
Epoch 1362 of 2000 took 0.162s
  training loss:		0.006098
  validation loss:		0.415563
  validation accuracy:		92.50 %
Epoch 1363 of 2000 took 0.175s
  training loss:		0.006188
  validation loss:		0.420146
  validation accuracy:		92.72 %
Epoch 1364 of 2000 took 0.161s
  training loss:		0.006138
  validation loss:		0.421954
  validation accuracy:		92.61 %
Epoch 1365 of 2000 took 0.140s
  training loss:		0.006081
  validation loss:		0.418357
  validation accuracy:		92.83 %
Epoch 1366 of 2000 took 0.136s
  training loss:		0.006162
  validation loss:		0.415759
  validation accuracy:		92.61 %
Epoch 1367 of 2000 took 0.134s
  training loss:		0.006133
  validation loss:		0.421202
  validation accuracy:		92.61 %
Epoch 1368 of 2000 took 0.148s
  training loss:		0.005968
  validation loss:		0.418445
  validation accuracy:		92.61 %
Epoch 1369 of 2000 took 0.132s
  training loss:		0.006000
  validation loss:		0.419642
  validation accuracy:		92.50 %
Epoch 1370 of 2000 took 0.143s
  training loss:		0.005984
  validation loss:		0.421490
  validation accuracy:		92.61 %
Epoch 1371 of 2000 took 0.140s
  training loss:		0.006055
  validation loss:		0.421593
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.160s
  training loss:		0.005941
  validation loss:		0.417738
  validation accuracy:		92.50 %
Epoch 1373 of 2000 took 0.174s
  training loss:		0.006183
  validation loss:		0.422628
  validation accuracy:		92.72 %
Epoch 1374 of 2000 took 0.172s
  training loss:		0.006220
  validation loss:		0.420551
  validation accuracy:		92.50 %
Epoch 1375 of 2000 took 0.136s
  training loss:		0.006003
  validation loss:		0.429221
  validation accuracy:		92.61 %
Epoch 1376 of 2000 took 0.132s
  training loss:		0.006086
  validation loss:		0.417668
  validation accuracy:		92.72 %
Epoch 1377 of 2000 took 0.149s
  training loss:		0.006003
  validation loss:		0.420339
  validation accuracy:		92.83 %
Epoch 1378 of 2000 took 0.141s
  training loss:		0.006000
  validation loss:		0.421080
  validation accuracy:		92.61 %
Epoch 1379 of 2000 took 0.144s
  training loss:		0.006068
  validation loss:		0.426039
  validation accuracy:		92.61 %
Epoch 1380 of 2000 took 0.130s
  training loss:		0.005797
  validation loss:		0.421726
  validation accuracy:		92.50 %
Epoch 1381 of 2000 took 0.153s
  training loss:		0.006015
  validation loss:		0.422752
  validation accuracy:		92.50 %
Epoch 1382 of 2000 took 0.146s
  training loss:		0.005887
  validation loss:		0.419092
  validation accuracy:		92.61 %
Epoch 1383 of 2000 took 0.136s
  training loss:		0.005872
  validation loss:		0.425859
  validation accuracy:		92.72 %
Epoch 1384 of 2000 took 0.182s
  training loss:		0.005916
  validation loss:		0.424371
  validation accuracy:		92.50 %
Epoch 1385 of 2000 took 0.167s
  training loss:		0.005859
  validation loss:		0.429559
  validation accuracy:		92.50 %
Epoch 1386 of 2000 took 0.168s
  training loss:		0.006032
  validation loss:		0.421507
  validation accuracy:		92.61 %
Epoch 1387 of 2000 took 0.144s
  training loss:		0.005947
  validation loss:		0.425073
  validation accuracy:		92.61 %
Epoch 1388 of 2000 took 0.137s
  training loss:		0.006014
  validation loss:		0.432693
  validation accuracy:		92.39 %
Epoch 1389 of 2000 took 0.132s
  training loss:		0.006153
  validation loss:		0.422819
  validation accuracy:		92.61 %
Epoch 1390 of 2000 took 0.131s
  training loss:		0.005892
  validation loss:		0.424100
  validation accuracy:		92.61 %
Epoch 1391 of 2000 took 0.140s
  training loss:		0.005818
  validation loss:		0.427539
  validation accuracy:		92.39 %
Epoch 1392 of 2000 took 0.138s
  training loss:		0.005854
  validation loss:		0.414323
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.146s
  training loss:		0.005863
  validation loss:		0.419544
  validation accuracy:		92.61 %
Epoch 1394 of 2000 took 0.133s
  training loss:		0.005790
  validation loss:		0.430453
  validation accuracy:		92.72 %
Epoch 1395 of 2000 took 0.160s
  training loss:		0.005795
  validation loss:		0.421766
  validation accuracy:		92.72 %
Epoch 1396 of 2000 took 0.148s
  training loss:		0.005722
  validation loss:		0.425497
  validation accuracy:		92.39 %
Epoch 1397 of 2000 took 0.148s
  training loss:		0.005806
  validation loss:		0.424381
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.144s
  training loss:		0.005742
  validation loss:		0.431390
  validation accuracy:		92.61 %
Epoch 1399 of 2000 took 0.149s
  training loss:		0.005930
  validation loss:		0.428572
  validation accuracy:		92.50 %
Epoch 1400 of 2000 took 0.136s
  training loss:		0.005969
  validation loss:		0.422473
  validation accuracy:		92.50 %
Epoch 1401 of 2000 took 0.134s
  training loss:		0.005965
  validation loss:		0.425862
  validation accuracy:		92.72 %
Epoch 1402 of 2000 took 0.137s
  training loss:		0.005660
  validation loss:		0.426128
  validation accuracy:		92.28 %
Epoch 1403 of 2000 took 0.140s
  training loss:		0.005643
  validation loss:		0.426108
  validation accuracy:		92.83 %
Epoch 1404 of 2000 took 0.132s
  training loss:		0.005716
  validation loss:		0.424314
  validation accuracy:		92.61 %
Epoch 1405 of 2000 took 0.131s
  training loss:		0.005793
  validation loss:		0.425147
  validation accuracy:		92.72 %
Epoch 1406 of 2000 took 0.132s
  training loss:		0.005618
  validation loss:		0.421641
  validation accuracy:		92.50 %
Epoch 1407 of 2000 took 0.141s
  training loss:		0.005605
  validation loss:		0.431874
  validation accuracy:		92.83 %
Epoch 1408 of 2000 took 0.170s
  training loss:		0.005689
  validation loss:		0.424746
  validation accuracy:		92.50 %
Epoch 1409 of 2000 took 0.174s
  training loss:		0.005703
  validation loss:		0.424248
  validation accuracy:		92.61 %
Epoch 1410 of 2000 took 0.145s
  training loss:		0.005710
  validation loss:		0.432862
  validation accuracy:		92.28 %
Epoch 1411 of 2000 took 0.145s
  training loss:		0.005609
  validation loss:		0.417955
  validation accuracy:		92.50 %
Epoch 1412 of 2000 took 0.144s
  training loss:		0.005742
  validation loss:		0.426392
  validation accuracy:		92.61 %
Epoch 1413 of 2000 took 0.140s
  training loss:		0.005629
  validation loss:		0.428945
  validation accuracy:		92.72 %
Epoch 1414 of 2000 took 0.135s
  training loss:		0.005507
  validation loss:		0.419798
  validation accuracy:		92.61 %
Epoch 1415 of 2000 took 0.143s
  training loss:		0.005639
  validation loss:		0.429395
  validation accuracy:		92.72 %
Epoch 1416 of 2000 took 0.146s
  training loss:		0.005447
  validation loss:		0.423765
  validation accuracy:		92.72 %
Epoch 1417 of 2000 took 0.147s
  training loss:		0.005451
  validation loss:		0.423115
  validation accuracy:		92.72 %
Epoch 1418 of 2000 took 0.143s
  training loss:		0.005704
  validation loss:		0.425404
  validation accuracy:		92.61 %
Epoch 1419 of 2000 took 0.143s
  training loss:		0.005491
  validation loss:		0.427586
  validation accuracy:		92.50 %
Epoch 1420 of 2000 took 0.148s
  training loss:		0.005409
  validation loss:		0.431548
  validation accuracy:		92.50 %
Epoch 1421 of 2000 took 0.129s
  training loss:		0.005567
  validation loss:		0.429566
  validation accuracy:		92.61 %
Epoch 1422 of 2000 took 0.131s
  training loss:		0.005383
  validation loss:		0.426283
  validation accuracy:		92.72 %
Epoch 1423 of 2000 took 0.144s
  training loss:		0.005678
  validation loss:		0.434153
  validation accuracy:		92.39 %
Epoch 1424 of 2000 took 0.126s
  training loss:		0.005546
  validation loss:		0.428133
  validation accuracy:		92.50 %
Epoch 1425 of 2000 took 0.144s
  training loss:		0.005218
  validation loss:		0.429637
  validation accuracy:		92.50 %
Epoch 1426 of 2000 took 0.138s
  training loss:		0.005660
  validation loss:		0.431276
  validation accuracy:		92.61 %
Epoch 1427 of 2000 took 0.137s
  training loss:		0.005556
  validation loss:		0.424281
  validation accuracy:		92.72 %
Epoch 1428 of 2000 took 0.132s
  training loss:		0.005627
  validation loss:		0.429380
  validation accuracy:		92.50 %
Epoch 1429 of 2000 took 0.141s
  training loss:		0.005336
  validation loss:		0.432065
  validation accuracy:		92.61 %
Epoch 1430 of 2000 took 0.133s
  training loss:		0.005412
  validation loss:		0.421188
  validation accuracy:		92.61 %
Epoch 1431 of 2000 took 0.149s
  training loss:		0.005458
  validation loss:		0.428542
  validation accuracy:		92.50 %
Epoch 1432 of 2000 took 0.173s
  training loss:		0.005412
  validation loss:		0.434656
  validation accuracy:		92.50 %
Epoch 1433 of 2000 took 0.176s
  training loss:		0.005490
  validation loss:		0.432615
  validation accuracy:		92.61 %
Epoch 1434 of 2000 took 0.172s
  training loss:		0.005450
  validation loss:		0.427327
  validation accuracy:		92.50 %
Epoch 1435 of 2000 took 0.163s
  training loss:		0.005385
  validation loss:		0.430609
  validation accuracy:		92.61 %
Epoch 1436 of 2000 took 0.173s
  training loss:		0.005306
  validation loss:		0.433604
  validation accuracy:		92.39 %
Epoch 1437 of 2000 took 0.173s
  training loss:		0.005435
  validation loss:		0.430041
  validation accuracy:		92.39 %
Epoch 1438 of 2000 took 0.175s
  training loss:		0.005492
  validation loss:		0.437579
  validation accuracy:		92.39 %
Epoch 1439 of 2000 took 0.161s
  training loss:		0.005572
  validation loss:		0.432377
  validation accuracy:		92.50 %
Epoch 1440 of 2000 took 0.124s
  training loss:		0.005226
  validation loss:		0.433435
  validation accuracy:		92.61 %
Epoch 1441 of 2000 took 0.177s
  training loss:		0.005299
  validation loss:		0.425732
  validation accuracy:		92.61 %
Epoch 1442 of 2000 took 0.175s
  training loss:		0.005304
  validation loss:		0.439886
  validation accuracy:		92.61 %
Epoch 1443 of 2000 took 0.176s
  training loss:		0.005542
  validation loss:		0.431385
  validation accuracy:		92.72 %
Epoch 1444 of 2000 took 0.148s
  training loss:		0.005204
  validation loss:		0.425588
  validation accuracy:		92.61 %
Epoch 1445 of 2000 took 0.180s
  training loss:		0.005444
  validation loss:		0.438160
  validation accuracy:		92.39 %
Epoch 1446 of 2000 took 0.149s
  training loss:		0.005367
  validation loss:		0.426928
  validation accuracy:		92.61 %
Epoch 1447 of 2000 took 0.162s
  training loss:		0.005297
  validation loss:		0.426253
  validation accuracy:		92.72 %
Epoch 1448 of 2000 took 0.165s
  training loss:		0.005360
  validation loss:		0.432248
  validation accuracy:		92.61 %
Epoch 1449 of 2000 took 0.139s
  training loss:		0.005300
  validation loss:		0.427511
  validation accuracy:		92.61 %
Epoch 1450 of 2000 took 0.146s
  training loss:		0.005539
  validation loss:		0.428285
  validation accuracy:		92.61 %
Epoch 1451 of 2000 took 0.149s
  training loss:		0.005486
  validation loss:		0.428002
  validation accuracy:		92.83 %
Epoch 1452 of 2000 took 0.144s
  training loss:		0.005204
  validation loss:		0.439989
  validation accuracy:		92.17 %
Epoch 1453 of 2000 took 0.143s
  training loss:		0.005441
  validation loss:		0.429526
  validation accuracy:		92.61 %
Epoch 1454 of 2000 took 0.139s
  training loss:		0.005239
  validation loss:		0.437877
  validation accuracy:		92.50 %
Epoch 1455 of 2000 took 0.147s
  training loss:		0.005452
  validation loss:		0.429561
  validation accuracy:		92.72 %
Epoch 1456 of 2000 took 0.161s
  training loss:		0.005187
  validation loss:		0.435192
  validation accuracy:		92.39 %
Epoch 1457 of 2000 took 0.138s
  training loss:		0.005121
  validation loss:		0.433606
  validation accuracy:		92.39 %
Epoch 1458 of 2000 took 0.141s
  training loss:		0.005147
  validation loss:		0.435950
  validation accuracy:		92.17 %
Epoch 1459 of 2000 took 0.146s
  training loss:		0.005368
  validation loss:		0.432635
  validation accuracy:		92.72 %
Epoch 1460 of 2000 took 0.136s
  training loss:		0.005240
  validation loss:		0.432345
  validation accuracy:		92.72 %
Epoch 1461 of 2000 took 0.148s
  training loss:		0.005347
  validation loss:		0.435666
  validation accuracy:		92.61 %
Epoch 1462 of 2000 took 0.181s
  training loss:		0.005252
  validation loss:		0.427979
  validation accuracy:		92.61 %
Epoch 1463 of 2000 took 0.172s
  training loss:		0.005268
  validation loss:		0.434489
  validation accuracy:		92.72 %
Epoch 1464 of 2000 took 0.175s
  training loss:		0.005075
  validation loss:		0.435875
  validation accuracy:		92.50 %
Epoch 1465 of 2000 took 0.174s
  training loss:		0.005184
  validation loss:		0.434716
  validation accuracy:		92.61 %
Epoch 1466 of 2000 took 0.142s
  training loss:		0.005064
  validation loss:		0.438721
  validation accuracy:		92.61 %
Epoch 1467 of 2000 took 0.140s
  training loss:		0.005203
  validation loss:		0.432977
  validation accuracy:		92.72 %
Epoch 1468 of 2000 took 0.143s
  training loss:		0.005155
  validation loss:		0.434431
  validation accuracy:		92.72 %
Epoch 1469 of 2000 took 0.138s
  training loss:		0.005107
  validation loss:		0.437667
  validation accuracy:		92.61 %
Epoch 1470 of 2000 took 0.141s
  training loss:		0.004937
  validation loss:		0.435130
  validation accuracy:		92.83 %
Epoch 1471 of 2000 took 0.144s
  training loss:		0.005159
  validation loss:		0.434261
  validation accuracy:		92.83 %
Epoch 1472 of 2000 took 0.154s
  training loss:		0.005224
  validation loss:		0.436029
  validation accuracy:		92.39 %
Epoch 1473 of 2000 took 0.174s
  training loss:		0.005193
  validation loss:		0.437021
  validation accuracy:		92.50 %
Epoch 1474 of 2000 took 0.175s
  training loss:		0.004933
  validation loss:		0.435683
  validation accuracy:		92.39 %
Epoch 1475 of 2000 took 0.175s
  training loss:		0.004903
  validation loss:		0.437881
  validation accuracy:		92.61 %
Epoch 1476 of 2000 took 0.174s
  training loss:		0.005040
  validation loss:		0.433334
  validation accuracy:		92.50 %
Epoch 1477 of 2000 took 0.174s
  training loss:		0.005124
  validation loss:		0.431303
  validation accuracy:		92.61 %
Epoch 1478 of 2000 took 0.174s
  training loss:		0.005106
  validation loss:		0.431194
  validation accuracy:		92.50 %
Epoch 1479 of 2000 took 0.169s
  training loss:		0.005210
  validation loss:		0.444459
  validation accuracy:		92.50 %
Epoch 1480 of 2000 took 0.127s
  training loss:		0.005057
  validation loss:		0.431480
  validation accuracy:		92.61 %
Epoch 1481 of 2000 took 0.147s
  training loss:		0.005217
  validation loss:		0.436578
  validation accuracy:		92.61 %
Epoch 1482 of 2000 took 0.145s
  training loss:		0.004803
  validation loss:		0.438264
  validation accuracy:		92.50 %
Epoch 1483 of 2000 took 0.153s
  training loss:		0.005024
  validation loss:		0.439731
  validation accuracy:		92.50 %
Epoch 1484 of 2000 took 0.175s
  training loss:		0.004945
  validation loss:		0.431363
  validation accuracy:		92.50 %
Epoch 1485 of 2000 took 0.176s
  training loss:		0.004984
  validation loss:		0.441800
  validation accuracy:		92.50 %
Epoch 1486 of 2000 took 0.174s
  training loss:		0.004885
  validation loss:		0.439624
  validation accuracy:		92.28 %
Epoch 1487 of 2000 took 0.172s
  training loss:		0.004814
  validation loss:		0.430936
  validation accuracy:		92.61 %
Epoch 1488 of 2000 took 0.171s
  training loss:		0.005084
  validation loss:		0.435959
  validation accuracy:		92.61 %
Epoch 1489 of 2000 took 0.173s
  training loss:		0.004972
  validation loss:		0.438865
  validation accuracy:		92.50 %
Epoch 1490 of 2000 took 0.144s
  training loss:		0.004932
  validation loss:		0.430218
  validation accuracy:		92.61 %
Epoch 1491 of 2000 took 0.175s
  training loss:		0.005101
  validation loss:		0.444003
  validation accuracy:		92.39 %
Epoch 1492 of 2000 took 0.167s
  training loss:		0.004846
  validation loss:		0.437870
  validation accuracy:		92.50 %
Epoch 1493 of 2000 took 0.129s
  training loss:		0.004897
  validation loss:		0.439505
  validation accuracy:		92.72 %
Epoch 1494 of 2000 took 0.165s
  training loss:		0.004969
  validation loss:		0.438368
  validation accuracy:		92.50 %
Epoch 1495 of 2000 took 0.145s
  training loss:		0.004829
  validation loss:		0.441895
  validation accuracy:		92.39 %
Epoch 1496 of 2000 took 0.172s
  training loss:		0.005029
  validation loss:		0.443786
  validation accuracy:		92.50 %
Epoch 1497 of 2000 took 0.143s
  training loss:		0.005114
  validation loss:		0.441615
  validation accuracy:		92.83 %
Epoch 1498 of 2000 took 0.144s
  training loss:		0.005105
  validation loss:		0.443342
  validation accuracy:		92.39 %
Epoch 1499 of 2000 took 0.163s
  training loss:		0.005010
  validation loss:		0.443290
  validation accuracy:		92.28 %
Epoch 1500 of 2000 took 0.156s
  training loss:		0.004994
  validation loss:		0.441073
  validation accuracy:		92.50 %
Epoch 1501 of 2000 took 0.163s
  training loss:		0.004749
  validation loss:		0.436364
  validation accuracy:		92.72 %
Epoch 1502 of 2000 took 0.175s
  training loss:		0.005018
  validation loss:		0.441044
  validation accuracy:		92.50 %
Epoch 1503 of 2000 took 0.173s
  training loss:		0.004823
  validation loss:		0.438351
  validation accuracy:		92.61 %
Epoch 1504 of 2000 took 0.176s
  training loss:		0.005020
  validation loss:		0.439041
  validation accuracy:		92.61 %
Epoch 1505 of 2000 took 0.176s
  training loss:		0.005006
  validation loss:		0.439001
  validation accuracy:		92.50 %
Epoch 1506 of 2000 took 0.152s
  training loss:		0.004774
  validation loss:		0.442159
  validation accuracy:		92.39 %
Epoch 1507 of 2000 took 0.140s
  training loss:		0.004870
  validation loss:		0.439632
  validation accuracy:		92.61 %
Epoch 1508 of 2000 took 0.138s
  training loss:		0.004845
  validation loss:		0.440036
  validation accuracy:		92.72 %
Epoch 1509 of 2000 took 0.153s
  training loss:		0.004937
  validation loss:		0.444728
  validation accuracy:		92.39 %
Epoch 1510 of 2000 took 0.158s
  training loss:		0.004935
  validation loss:		0.444408
  validation accuracy:		92.61 %
Epoch 1511 of 2000 took 0.148s
  training loss:		0.004886
  validation loss:		0.439623
  validation accuracy:		92.72 %
Epoch 1512 of 2000 took 0.138s
  training loss:		0.004817
  validation loss:		0.444054
  validation accuracy:		92.72 %
Epoch 1513 of 2000 took 0.133s
  training loss:		0.004795
  validation loss:		0.445987
  validation accuracy:		92.28 %
Epoch 1514 of 2000 took 0.158s
  training loss:		0.004900
  validation loss:		0.441697
  validation accuracy:		92.61 %
Epoch 1515 of 2000 took 0.138s
  training loss:		0.004788
  validation loss:		0.435772
  validation accuracy:		92.50 %
Epoch 1516 of 2000 took 0.141s
  training loss:		0.004966
  validation loss:		0.443870
  validation accuracy:		92.61 %
Epoch 1517 of 2000 took 0.179s
  training loss:		0.004835
  validation loss:		0.443608
  validation accuracy:		92.50 %
Epoch 1518 of 2000 took 0.173s
  training loss:		0.004758
  validation loss:		0.441093
  validation accuracy:		92.61 %
Epoch 1519 of 2000 took 0.172s
  training loss:		0.004666
  validation loss:		0.441029
  validation accuracy:		92.50 %
Epoch 1520 of 2000 took 0.147s
  training loss:		0.004814
  validation loss:		0.443336
  validation accuracy:		92.39 %
Epoch 1521 of 2000 took 0.172s
  training loss:		0.004785
  validation loss:		0.443664
  validation accuracy:		92.39 %
Epoch 1522 of 2000 took 0.176s
  training loss:		0.004644
  validation loss:		0.444717
  validation accuracy:		92.50 %
Epoch 1523 of 2000 took 0.162s
  training loss:		0.004654
  validation loss:		0.441897
  validation accuracy:		92.72 %
Epoch 1524 of 2000 took 0.148s
  training loss:		0.004761
  validation loss:		0.446933
  validation accuracy:		92.28 %
Epoch 1525 of 2000 took 0.149s
  training loss:		0.004699
  validation loss:		0.450550
  validation accuracy:		92.39 %
Epoch 1526 of 2000 took 0.175s
  training loss:		0.004652
  validation loss:		0.439708
  validation accuracy:		92.61 %
Epoch 1527 of 2000 took 0.171s
  training loss:		0.004625
  validation loss:		0.449146
  validation accuracy:		92.50 %
Epoch 1528 of 2000 took 0.173s
  training loss:		0.004626
  validation loss:		0.441492
  validation accuracy:		92.50 %
Epoch 1529 of 2000 took 0.139s
  training loss:		0.004687
  validation loss:		0.442920
  validation accuracy:		92.39 %
Epoch 1530 of 2000 took 0.138s
  training loss:		0.004782
  validation loss:		0.442274
  validation accuracy:		92.50 %
Epoch 1531 of 2000 took 0.151s
  training loss:		0.004794
  validation loss:		0.440524
  validation accuracy:		92.61 %
Epoch 1532 of 2000 took 0.139s
  training loss:		0.004798
  validation loss:		0.450199
  validation accuracy:		92.28 %
Epoch 1533 of 2000 took 0.131s
  training loss:		0.004691
  validation loss:		0.440637
  validation accuracy:		92.83 %
Epoch 1534 of 2000 took 0.143s
  training loss:		0.004744
  validation loss:		0.447974
  validation accuracy:		92.28 %
Epoch 1535 of 2000 took 0.166s
  training loss:		0.004709
  validation loss:		0.449403
  validation accuracy:		92.61 %
Epoch 1536 of 2000 took 0.175s
  training loss:		0.004638
  validation loss:		0.444266
  validation accuracy:		92.61 %
Epoch 1537 of 2000 took 0.175s
  training loss:		0.004636
  validation loss:		0.440578
  validation accuracy:		92.61 %
Epoch 1538 of 2000 took 0.152s
  training loss:		0.004780
  validation loss:		0.443575
  validation accuracy:		92.50 %
Epoch 1539 of 2000 took 0.151s
  training loss:		0.004756
  validation loss:		0.452588
  validation accuracy:		92.61 %
Epoch 1540 of 2000 took 0.173s
  training loss:		0.004712
  validation loss:		0.445744
  validation accuracy:		92.50 %
Epoch 1541 of 2000 took 0.162s
  training loss:		0.004560
  validation loss:		0.444740
  validation accuracy:		92.61 %
Epoch 1542 of 2000 took 0.172s
  training loss:		0.004612
  validation loss:		0.441427
  validation accuracy:		92.61 %
Epoch 1543 of 2000 took 0.152s
  training loss:		0.004568
  validation loss:		0.443343
  validation accuracy:		92.72 %
Epoch 1544 of 2000 took 0.140s
  training loss:		0.004589
  validation loss:		0.445751
  validation accuracy:		92.50 %
Epoch 1545 of 2000 took 0.174s
  training loss:		0.004849
  validation loss:		0.445352
  validation accuracy:		92.39 %
Epoch 1546 of 2000 took 0.175s
  training loss:		0.004598
  validation loss:		0.449122
  validation accuracy:		92.50 %
Epoch 1547 of 2000 took 0.152s
  training loss:		0.004552
  validation loss:		0.445075
  validation accuracy:		92.39 %
Epoch 1548 of 2000 took 0.145s
  training loss:		0.004603
  validation loss:		0.451246
  validation accuracy:		92.39 %
Epoch 1549 of 2000 took 0.141s
  training loss:		0.004667
  validation loss:		0.446515
  validation accuracy:		92.72 %
Epoch 1550 of 2000 took 0.137s
  training loss:		0.004674
  validation loss:		0.449515
  validation accuracy:		92.61 %
Epoch 1551 of 2000 took 0.131s
  training loss:		0.004475
  validation loss:		0.443982
  validation accuracy:		92.50 %
Epoch 1552 of 2000 took 0.147s
  training loss:		0.004504
  validation loss:		0.446201
  validation accuracy:		92.61 %
Epoch 1553 of 2000 took 0.171s
  training loss:		0.004508
  validation loss:		0.444459
  validation accuracy:		92.50 %
Epoch 1554 of 2000 took 0.175s
  training loss:		0.004536
  validation loss:		0.447221
  validation accuracy:		92.72 %
Epoch 1555 of 2000 took 0.170s
  training loss:		0.004532
  validation loss:		0.447940
  validation accuracy:		92.50 %
Epoch 1556 of 2000 took 0.145s
  training loss:		0.004444
  validation loss:		0.445422
  validation accuracy:		92.61 %
Epoch 1557 of 2000 took 0.138s
  training loss:		0.004344
  validation loss:		0.447300
  validation accuracy:		92.72 %
Epoch 1558 of 2000 took 0.170s
  training loss:		0.004433
  validation loss:		0.446299
  validation accuracy:		92.61 %
Epoch 1559 of 2000 took 0.151s
  training loss:		0.004651
  validation loss:		0.445428
  validation accuracy:		92.72 %
Epoch 1560 of 2000 took 0.148s
  training loss:		0.004481
  validation loss:		0.446212
  validation accuracy:		92.39 %
Epoch 1561 of 2000 took 0.132s
  training loss:		0.004510
  validation loss:		0.454710
  validation accuracy:		92.39 %
Epoch 1562 of 2000 took 0.137s
  training loss:		0.004473
  validation loss:		0.444564
  validation accuracy:		92.50 %
Epoch 1563 of 2000 took 0.171s
  training loss:		0.004504
  validation loss:		0.454939
  validation accuracy:		92.39 %
Epoch 1564 of 2000 took 0.174s
  training loss:		0.004315
  validation loss:		0.447909
  validation accuracy:		92.61 %
Epoch 1565 of 2000 took 0.174s
  training loss:		0.004472
  validation loss:		0.451224
  validation accuracy:		92.61 %
Epoch 1566 of 2000 took 0.174s
  training loss:		0.004508
  validation loss:		0.448550
  validation accuracy:		92.50 %
Epoch 1567 of 2000 took 0.174s
  training loss:		0.004482
  validation loss:		0.450610
  validation accuracy:		92.39 %
Epoch 1568 of 2000 took 0.176s
  training loss:		0.004461
  validation loss:		0.450360
  validation accuracy:		92.50 %
Epoch 1569 of 2000 took 0.167s
  training loss:		0.004245
  validation loss:		0.447184
  validation accuracy:		92.50 %
Epoch 1570 of 2000 took 0.174s
  training loss:		0.004310
  validation loss:		0.451453
  validation accuracy:		92.61 %
Epoch 1571 of 2000 took 0.173s
  training loss:		0.004626
  validation loss:		0.448426
  validation accuracy:		92.50 %
Epoch 1572 of 2000 took 0.173s
  training loss:		0.004429
  validation loss:		0.448106
  validation accuracy:		92.61 %
Epoch 1573 of 2000 took 0.139s
  training loss:		0.004465
  validation loss:		0.451596
  validation accuracy:		92.50 %
Epoch 1574 of 2000 took 0.136s
  training loss:		0.004280
  validation loss:		0.453912
  validation accuracy:		92.50 %
Epoch 1575 of 2000 took 0.139s
  training loss:		0.004233
  validation loss:		0.452039
  validation accuracy:		92.50 %
Epoch 1576 of 2000 took 0.144s
  training loss:		0.004372
  validation loss:		0.446753
  validation accuracy:		92.61 %
Epoch 1577 of 2000 took 0.145s
  training loss:		0.004388
  validation loss:		0.454153
  validation accuracy:		92.50 %
Epoch 1578 of 2000 took 0.142s
  training loss:		0.004484
  validation loss:		0.447353
  validation accuracy:		92.50 %
Epoch 1579 of 2000 took 0.140s
  training loss:		0.004353
  validation loss:		0.448192
  validation accuracy:		92.72 %
Epoch 1580 of 2000 took 0.140s
  training loss:		0.004419
  validation loss:		0.454945
  validation accuracy:		92.61 %
Epoch 1581 of 2000 took 0.150s
  training loss:		0.004366
  validation loss:		0.452218
  validation accuracy:		92.50 %
Epoch 1582 of 2000 took 0.144s
  training loss:		0.004381
  validation loss:		0.444690
  validation accuracy:		92.61 %
Epoch 1583 of 2000 took 0.138s
  training loss:		0.004398
  validation loss:		0.458376
  validation accuracy:		92.50 %
Epoch 1584 of 2000 took 0.148s
  training loss:		0.004279
  validation loss:		0.442522
  validation accuracy:		92.61 %
Epoch 1585 of 2000 took 0.153s
  training loss:		0.004411
  validation loss:		0.457269
  validation accuracy:		92.50 %
Epoch 1586 of 2000 took 0.176s
  training loss:		0.004343
  validation loss:		0.449213
  validation accuracy:		92.61 %
Epoch 1587 of 2000 took 0.158s
  training loss:		0.004222
  validation loss:		0.455405
  validation accuracy:		92.61 %
Epoch 1588 of 2000 took 0.155s
  training loss:		0.004212
  validation loss:		0.451506
  validation accuracy:		92.72 %
Epoch 1589 of 2000 took 0.161s
  training loss:		0.004379
  validation loss:		0.448634
  validation accuracy:		92.39 %
Epoch 1590 of 2000 took 0.147s
  training loss:		0.004390
  validation loss:		0.445776
  validation accuracy:		92.61 %
Epoch 1591 of 2000 took 0.149s
  training loss:		0.004427
  validation loss:		0.458477
  validation accuracy:		92.17 %
Epoch 1592 of 2000 took 0.167s
  training loss:		0.004259
  validation loss:		0.450651
  validation accuracy:		92.39 %
Epoch 1593 of 2000 took 0.138s
  training loss:		0.004355
  validation loss:		0.454086
  validation accuracy:		92.50 %
Epoch 1594 of 2000 took 0.144s
  training loss:		0.004270
  validation loss:		0.455419
  validation accuracy:		92.61 %
Epoch 1595 of 2000 took 0.148s
  training loss:		0.004298
  validation loss:		0.453267
  validation accuracy:		92.39 %
Epoch 1596 of 2000 took 0.135s
  training loss:		0.004441
  validation loss:		0.453831
  validation accuracy:		92.50 %
Epoch 1597 of 2000 took 0.154s
  training loss:		0.004204
  validation loss:		0.454890
  validation accuracy:		92.39 %
Epoch 1598 of 2000 took 0.170s
  training loss:		0.004134
  validation loss:		0.456846
  validation accuracy:		92.50 %
Epoch 1599 of 2000 took 0.176s
  training loss:		0.004215
  validation loss:		0.454366
  validation accuracy:		92.50 %
Epoch 1600 of 2000 took 0.143s
  training loss:		0.004095
  validation loss:		0.457525
  validation accuracy:		92.50 %
Epoch 1601 of 2000 took 0.151s
  training loss:		0.004310
  validation loss:		0.447225
  validation accuracy:		92.61 %
Epoch 1602 of 2000 took 0.147s
  training loss:		0.004283
  validation loss:		0.455108
  validation accuracy:		92.39 %
Epoch 1603 of 2000 took 0.133s
  training loss:		0.004068
  validation loss:		0.452191
  validation accuracy:		92.61 %
Epoch 1604 of 2000 took 0.150s
  training loss:		0.004195
  validation loss:		0.454129
  validation accuracy:		92.39 %
Epoch 1605 of 2000 took 0.143s
  training loss:		0.004315
  validation loss:		0.449882
  validation accuracy:		92.61 %
Epoch 1606 of 2000 took 0.141s
  training loss:		0.004336
  validation loss:		0.447463
  validation accuracy:		92.72 %
Epoch 1607 of 2000 took 0.144s
  training loss:		0.004300
  validation loss:		0.457964
  validation accuracy:		92.50 %
Epoch 1608 of 2000 took 0.143s
  training loss:		0.004152
  validation loss:		0.448255
  validation accuracy:		92.61 %
Epoch 1609 of 2000 took 0.134s
  training loss:		0.004160
  validation loss:		0.455739
  validation accuracy:		92.50 %
Epoch 1610 of 2000 took 0.144s
  training loss:		0.004243
  validation loss:		0.459157
  validation accuracy:		92.39 %
Epoch 1611 of 2000 took 0.134s
  training loss:		0.004180
  validation loss:		0.457160
  validation accuracy:		92.61 %
Epoch 1612 of 2000 took 0.155s
  training loss:		0.004316
  validation loss:		0.451705
  validation accuracy:		92.61 %
Epoch 1613 of 2000 took 0.147s
  training loss:		0.004148
  validation loss:		0.461256
  validation accuracy:		92.28 %
Epoch 1614 of 2000 took 0.142s
  training loss:		0.004135
  validation loss:		0.457018
  validation accuracy:		92.28 %
Epoch 1615 of 2000 took 0.136s
  training loss:		0.004107
  validation loss:		0.449234
  validation accuracy:		92.61 %
Epoch 1616 of 2000 took 0.171s
  training loss:		0.004194
  validation loss:		0.455470
  validation accuracy:		92.83 %
Epoch 1617 of 2000 took 0.147s
  training loss:		0.004339
  validation loss:		0.451943
  validation accuracy:		92.50 %
Epoch 1618 of 2000 took 0.090s
  training loss:		0.004100
  validation loss:		0.457782
  validation accuracy:		92.61 %
Epoch 1619 of 2000 took 0.076s
  training loss:		0.004157
  validation loss:		0.457526
  validation accuracy:		92.39 %
Epoch 1620 of 2000 took 0.074s
  training loss:		0.004187
  validation loss:		0.455635
  validation accuracy:		92.72 %
Epoch 1621 of 2000 took 0.076s
  training loss:		0.004172
  validation loss:		0.453105
  validation accuracy:		92.39 %
Epoch 1622 of 2000 took 0.075s
  training loss:		0.004054
  validation loss:		0.457464
  validation accuracy:		92.61 %
Epoch 1623 of 2000 took 0.077s
  training loss:		0.004098
  validation loss:		0.453168
  validation accuracy:		92.61 %
Epoch 1624 of 2000 took 0.077s
  training loss:		0.004038
  validation loss:		0.453853
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.078s
  training loss:		0.004079
  validation loss:		0.456296
  validation accuracy:		92.39 %
Epoch 1626 of 2000 took 0.074s
  training loss:		0.004055
  validation loss:		0.462122
  validation accuracy:		92.61 %
Epoch 1627 of 2000 took 0.077s
  training loss:		0.004130
  validation loss:		0.456991
  validation accuracy:		92.50 %
Epoch 1628 of 2000 took 0.077s
  training loss:		0.004098
  validation loss:		0.457780
  validation accuracy:		92.50 %
Epoch 1629 of 2000 took 0.076s
  training loss:		0.004063
  validation loss:		0.460116
  validation accuracy:		92.50 %
Epoch 1630 of 2000 took 0.075s
  training loss:		0.004043
  validation loss:		0.453870
  validation accuracy:		92.61 %
Epoch 1631 of 2000 took 0.075s
  training loss:		0.004099
  validation loss:		0.456904
  validation accuracy:		92.61 %
Epoch 1632 of 2000 took 0.074s
  training loss:		0.004029
  validation loss:		0.454354
  validation accuracy:		92.50 %
Epoch 1633 of 2000 took 0.078s
  training loss:		0.004008
  validation loss:		0.460017
  validation accuracy:		92.28 %
Epoch 1634 of 2000 took 0.075s
  training loss:		0.004064
  validation loss:		0.453850
  validation accuracy:		92.61 %
Epoch 1635 of 2000 took 0.076s
  training loss:		0.004033
  validation loss:		0.461007
  validation accuracy:		92.39 %
Epoch 1636 of 2000 took 0.075s
  training loss:		0.003987
  validation loss:		0.461586
  validation accuracy:		92.28 %
Epoch 1637 of 2000 took 0.075s
  training loss:		0.004013
  validation loss:		0.459790
  validation accuracy:		92.39 %
Epoch 1638 of 2000 took 0.076s
  training loss:		0.003942
  validation loss:		0.463815
  validation accuracy:		92.50 %
Epoch 1639 of 2000 took 0.076s
  training loss:		0.004013
  validation loss:		0.457442
  validation accuracy:		92.39 %
Epoch 1640 of 2000 took 0.075s
  training loss:		0.004135
  validation loss:		0.463502
  validation accuracy:		92.28 %
Epoch 1641 of 2000 took 0.074s
  training loss:		0.003871
  validation loss:		0.455804
  validation accuracy:		92.61 %
Epoch 1642 of 2000 took 0.073s
  training loss:		0.003992
  validation loss:		0.459509
  validation accuracy:		92.61 %
Epoch 1643 of 2000 took 0.075s
  training loss:		0.003949
  validation loss:		0.457867
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.075s
  training loss:		0.003998
  validation loss:		0.460133
  validation accuracy:		92.39 %
Epoch 1645 of 2000 took 0.077s
  training loss:		0.004016
  validation loss:		0.459655
  validation accuracy:		92.50 %
Epoch 1646 of 2000 took 0.077s
  training loss:		0.004061
  validation loss:		0.455689
  validation accuracy:		92.50 %
Epoch 1647 of 2000 took 0.074s
  training loss:		0.003870
  validation loss:		0.461459
  validation accuracy:		92.61 %
Epoch 1648 of 2000 took 0.077s
  training loss:		0.003985
  validation loss:		0.459868
  validation accuracy:		92.39 %
Epoch 1649 of 2000 took 0.075s
  training loss:		0.003941
  validation loss:		0.460134
  validation accuracy:		92.61 %
Epoch 1650 of 2000 took 0.076s
  training loss:		0.003956
  validation loss:		0.463244
  validation accuracy:		92.28 %
Epoch 1651 of 2000 took 0.075s
  training loss:		0.003975
  validation loss:		0.458066
  validation accuracy:		92.50 %
Epoch 1652 of 2000 took 0.075s
  training loss:		0.003898
  validation loss:		0.465008
  validation accuracy:		92.17 %
Epoch 1653 of 2000 took 0.074s
  training loss:		0.003926
  validation loss:		0.462831
  validation accuracy:		92.39 %
Epoch 1654 of 2000 took 0.075s
  training loss:		0.003941
  validation loss:		0.460705
  validation accuracy:		92.50 %
Epoch 1655 of 2000 took 0.076s
  training loss:		0.003956
  validation loss:		0.458622
  validation accuracy:		92.39 %
Epoch 1656 of 2000 took 0.075s
  training loss:		0.003869
  validation loss:		0.462121
  validation accuracy:		92.39 %
Epoch 1657 of 2000 took 0.074s
  training loss:		0.003937
  validation loss:		0.460736
  validation accuracy:		92.61 %
Epoch 1658 of 2000 took 0.075s
  training loss:		0.004007
  validation loss:		0.460752
  validation accuracy:		92.50 %
Epoch 1659 of 2000 took 0.076s
  training loss:		0.003947
  validation loss:		0.460054
  validation accuracy:		92.50 %
Epoch 1660 of 2000 took 0.073s
  training loss:		0.003959
  validation loss:		0.461564
  validation accuracy:		92.39 %
Epoch 1661 of 2000 took 0.073s
  training loss:		0.003776
  validation loss:		0.466759
  validation accuracy:		92.61 %
Epoch 1662 of 2000 took 0.077s
  training loss:		0.003946
  validation loss:		0.463087
  validation accuracy:		92.50 %
Epoch 1663 of 2000 took 0.075s
  training loss:		0.003965
  validation loss:		0.464204
  validation accuracy:		92.50 %
Epoch 1664 of 2000 took 0.073s
  training loss:		0.003851
  validation loss:		0.462916
  validation accuracy:		92.39 %
Epoch 1665 of 2000 took 0.077s
  training loss:		0.003848
  validation loss:		0.459162
  validation accuracy:		92.72 %
Epoch 1666 of 2000 took 0.075s
  training loss:		0.003788
  validation loss:		0.464377
  validation accuracy:		92.39 %
Epoch 1667 of 2000 took 0.076s
  training loss:		0.003856
  validation loss:		0.463517
  validation accuracy:		92.39 %
Epoch 1668 of 2000 took 0.075s
  training loss:		0.003877
  validation loss:		0.465494
  validation accuracy:		92.39 %
Epoch 1669 of 2000 took 0.075s
  training loss:		0.003963
  validation loss:		0.458589
  validation accuracy:		92.61 %
Epoch 1670 of 2000 took 0.075s
  training loss:		0.003859
  validation loss:		0.461920
  validation accuracy:		92.50 %
Epoch 1671 of 2000 took 0.073s
  training loss:		0.003743
  validation loss:		0.460125
  validation accuracy:		92.61 %
Epoch 1672 of 2000 took 0.075s
  training loss:		0.003787
  validation loss:		0.467373
  validation accuracy:		92.28 %
Epoch 1673 of 2000 took 0.076s
  training loss:		0.003811
  validation loss:		0.463429
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.077s
  training loss:		0.003796
  validation loss:		0.460718
  validation accuracy:		92.50 %
Epoch 1675 of 2000 took 0.076s
  training loss:		0.003865
  validation loss:		0.469121
  validation accuracy:		92.39 %
Epoch 1676 of 2000 took 0.077s
  training loss:		0.003765
  validation loss:		0.468231
  validation accuracy:		92.50 %
Epoch 1677 of 2000 took 0.074s
  training loss:		0.003761
  validation loss:		0.466239
  validation accuracy:		92.50 %
Epoch 1678 of 2000 took 0.076s
  training loss:		0.003915
  validation loss:		0.473347
  validation accuracy:		92.39 %
Epoch 1679 of 2000 took 0.075s
  training loss:		0.004049
  validation loss:		0.460088
  validation accuracy:		92.50 %
Epoch 1680 of 2000 took 0.074s
  training loss:		0.003961
  validation loss:		0.462750
  validation accuracy:		92.50 %
Epoch 1681 of 2000 took 0.076s
  training loss:		0.003816
  validation loss:		0.466716
  validation accuracy:		92.50 %
Epoch 1682 of 2000 took 0.076s
  training loss:		0.003748
  validation loss:		0.464569
  validation accuracy:		92.61 %
Epoch 1683 of 2000 took 0.075s
  training loss:		0.003740
  validation loss:		0.465861
  validation accuracy:		92.72 %
Epoch 1684 of 2000 took 0.074s
  training loss:		0.003824
  validation loss:		0.465180
  validation accuracy:		92.61 %
Epoch 1685 of 2000 took 0.074s
  training loss:		0.003819
  validation loss:		0.465220
  validation accuracy:		92.50 %
Epoch 1686 of 2000 took 0.075s
  training loss:		0.003776
  validation loss:		0.462468
  validation accuracy:		92.61 %
Epoch 1687 of 2000 took 0.075s
  training loss:		0.003803
  validation loss:		0.464211
  validation accuracy:		92.72 %
Epoch 1688 of 2000 took 0.075s
  training loss:		0.003633
  validation loss:		0.463721
  validation accuracy:		92.61 %
Epoch 1689 of 2000 took 0.076s
  training loss:		0.003851
  validation loss:		0.472879
  validation accuracy:		92.28 %
Epoch 1690 of 2000 took 0.074s
  training loss:		0.003829
  validation loss:		0.461230
  validation accuracy:		92.61 %
Epoch 1691 of 2000 took 0.074s
  training loss:		0.003759
  validation loss:		0.466084
  validation accuracy:		92.39 %
Epoch 1692 of 2000 took 0.076s
  training loss:		0.003792
  validation loss:		0.467529
  validation accuracy:		92.28 %
Epoch 1693 of 2000 took 0.076s
  training loss:		0.003705
  validation loss:		0.467807
  validation accuracy:		92.50 %
Epoch 1694 of 2000 took 0.076s
  training loss:		0.003740
  validation loss:		0.465316
  validation accuracy:		92.61 %
Epoch 1695 of 2000 took 0.075s
  training loss:		0.003703
  validation loss:		0.459769
  validation accuracy:		92.61 %
Epoch 1696 of 2000 took 0.074s
  training loss:		0.003630
  validation loss:		0.471584
  validation accuracy:		92.39 %
Epoch 1697 of 2000 took 0.075s
  training loss:		0.003805
  validation loss:		0.469262
  validation accuracy:		92.39 %
Epoch 1698 of 2000 took 0.074s
  training loss:		0.003754
  validation loss:		0.466068
  validation accuracy:		92.61 %
Epoch 1699 of 2000 took 0.076s
  training loss:		0.003671
  validation loss:		0.466050
  validation accuracy:		92.50 %
Epoch 1700 of 2000 took 0.075s
  training loss:		0.003613
  validation loss:		0.464602
  validation accuracy:		92.50 %
Epoch 1701 of 2000 took 0.075s
  training loss:		0.003695
  validation loss:		0.465907
  validation accuracy:		92.50 %
Epoch 1702 of 2000 took 0.076s
  training loss:		0.003689
  validation loss:		0.462690
  validation accuracy:		92.50 %
Epoch 1703 of 2000 took 0.076s
  training loss:		0.003681
  validation loss:		0.470156
  validation accuracy:		92.28 %
Epoch 1704 of 2000 took 0.074s
  training loss:		0.003714
  validation loss:		0.466270
  validation accuracy:		92.39 %
Epoch 1705 of 2000 took 0.076s
  training loss:		0.003626
  validation loss:		0.472028
  validation accuracy:		92.28 %
Epoch 1706 of 2000 took 0.075s
  training loss:		0.003725
  validation loss:		0.463405
  validation accuracy:		92.61 %
Epoch 1707 of 2000 took 0.073s
  training loss:		0.003740
  validation loss:		0.471068
  validation accuracy:		92.50 %
Epoch 1708 of 2000 took 0.077s
  training loss:		0.003658
  validation loss:		0.465158
  validation accuracy:		92.61 %
Epoch 1709 of 2000 took 0.075s
  training loss:		0.003531
  validation loss:		0.470628
  validation accuracy:		92.50 %
Epoch 1710 of 2000 took 0.074s
  training loss:		0.003643
  validation loss:		0.466496
  validation accuracy:		92.72 %
Epoch 1711 of 2000 took 0.075s
  training loss:		0.003741
  validation loss:		0.463897
  validation accuracy:		92.61 %
Epoch 1712 of 2000 took 0.076s
  training loss:		0.003742
  validation loss:		0.467690
  validation accuracy:		92.61 %
Epoch 1713 of 2000 took 0.075s
  training loss:		0.003710
  validation loss:		0.475382
  validation accuracy:		92.28 %
Epoch 1714 of 2000 took 0.076s
  training loss:		0.003554
  validation loss:		0.464096
  validation accuracy:		92.61 %
Epoch 1715 of 2000 took 0.077s
  training loss:		0.003667
  validation loss:		0.470762
  validation accuracy:		92.39 %
Epoch 1716 of 2000 took 0.078s
  training loss:		0.003706
  validation loss:		0.471159
  validation accuracy:		92.39 %
Epoch 1717 of 2000 took 0.078s
  training loss:		0.003557
  validation loss:		0.468407
  validation accuracy:		92.50 %
Epoch 1718 of 2000 took 0.077s
  training loss:		0.003577
  validation loss:		0.468102
  validation accuracy:		92.61 %
Epoch 1719 of 2000 took 0.077s
  training loss:		0.003557
  validation loss:		0.469161
  validation accuracy:		92.39 %
Epoch 1720 of 2000 took 0.078s
  training loss:		0.003647
  validation loss:		0.464100
  validation accuracy:		92.50 %
Epoch 1721 of 2000 took 0.077s
  training loss:		0.003633
  validation loss:		0.473216
  validation accuracy:		92.39 %
Epoch 1722 of 2000 took 0.075s
  training loss:		0.003621
  validation loss:		0.471222
  validation accuracy:		92.50 %
Epoch 1723 of 2000 took 0.076s
  training loss:		0.003398
  validation loss:		0.465210
  validation accuracy:		92.72 %
Epoch 1724 of 2000 took 0.075s
  training loss:		0.003521
  validation loss:		0.472122
  validation accuracy:		92.39 %
Epoch 1725 of 2000 took 0.077s
  training loss:		0.003612
  validation loss:		0.473456
  validation accuracy:		92.50 %
Epoch 1726 of 2000 took 0.078s
  training loss:		0.003619
  validation loss:		0.473879
  validation accuracy:		92.39 %
Epoch 1727 of 2000 took 0.078s
  training loss:		0.003557
  validation loss:		0.469466
  validation accuracy:		92.50 %
Epoch 1728 of 2000 took 0.076s
  training loss:		0.003605
  validation loss:		0.471373
  validation accuracy:		92.39 %
Epoch 1729 of 2000 took 0.076s
  training loss:		0.003488
  validation loss:		0.471694
  validation accuracy:		92.50 %
Epoch 1730 of 2000 took 0.075s
  training loss:		0.003634
  validation loss:		0.471423
  validation accuracy:		92.50 %
Epoch 1731 of 2000 took 0.074s
  training loss:		0.003651
  validation loss:		0.468742
  validation accuracy:		92.61 %
Epoch 1732 of 2000 took 0.075s
  training loss:		0.003552
  validation loss:		0.472511
  validation accuracy:		92.39 %
Epoch 1733 of 2000 took 0.077s
  training loss:		0.003534
  validation loss:		0.474734
  validation accuracy:		92.50 %
Epoch 1734 of 2000 took 0.077s
  training loss:		0.003623
  validation loss:		0.471406
  validation accuracy:		92.50 %
Epoch 1735 of 2000 took 0.076s
  training loss:		0.003533
  validation loss:		0.472860
  validation accuracy:		92.50 %
Epoch 1736 of 2000 took 0.072s
  training loss:		0.003560
  validation loss:		0.471542
  validation accuracy:		92.39 %
Epoch 1737 of 2000 took 0.075s
  training loss:		0.003516
  validation loss:		0.470688
  validation accuracy:		92.83 %
Epoch 1738 of 2000 took 0.076s
  training loss:		0.003530
  validation loss:		0.470613
  validation accuracy:		92.39 %
Epoch 1739 of 2000 took 0.078s
  training loss:		0.003551
  validation loss:		0.472093
  validation accuracy:		92.61 %
Epoch 1740 of 2000 took 0.075s
  training loss:		0.003508
  validation loss:		0.474710
  validation accuracy:		92.39 %
Epoch 1741 of 2000 took 0.077s
  training loss:		0.003465
  validation loss:		0.475317
  validation accuracy:		92.39 %
Epoch 1742 of 2000 took 0.079s
  training loss:		0.003586
  validation loss:		0.473679
  validation accuracy:		92.50 %
Epoch 1743 of 2000 took 0.074s
  training loss:		0.003587
  validation loss:		0.472697
  validation accuracy:		92.50 %
Epoch 1744 of 2000 took 0.075s
  training loss:		0.003541
  validation loss:		0.473978
  validation accuracy:		92.61 %
Epoch 1745 of 2000 took 0.075s
  training loss:		0.003388
  validation loss:		0.467163
  validation accuracy:		92.50 %
Epoch 1746 of 2000 took 0.074s
  training loss:		0.003463
  validation loss:		0.476694
  validation accuracy:		92.50 %
Epoch 1747 of 2000 took 0.075s
  training loss:		0.003605
  validation loss:		0.474499
  validation accuracy:		92.50 %
Epoch 1748 of 2000 took 0.078s
  training loss:		0.003493
  validation loss:		0.471980
  validation accuracy:		92.50 %
Epoch 1749 of 2000 took 0.075s
  training loss:		0.003500
  validation loss:		0.477572
  validation accuracy:		92.28 %
Epoch 1750 of 2000 took 0.076s
  training loss:		0.003556
  validation loss:		0.469167
  validation accuracy:		92.72 %
Epoch 1751 of 2000 took 0.075s
  training loss:		0.003554
  validation loss:		0.474177
  validation accuracy:		92.61 %
Epoch 1752 of 2000 took 0.077s
  training loss:		0.003476
  validation loss:		0.475402
  validation accuracy:		92.39 %
Epoch 1753 of 2000 took 0.072s
  training loss:		0.003521
  validation loss:		0.475118
  validation accuracy:		92.61 %
Epoch 1754 of 2000 took 0.077s
  training loss:		0.003521
  validation loss:		0.470980
  validation accuracy:		92.39 %
Epoch 1755 of 2000 took 0.077s
  training loss:		0.003419
  validation loss:		0.477480
  validation accuracy:		92.39 %
Epoch 1756 of 2000 took 0.075s
  training loss:		0.003399
  validation loss:		0.473068
  validation accuracy:		92.39 %
Epoch 1757 of 2000 took 0.074s
  training loss:		0.003492
  validation loss:		0.474189
  validation accuracy:		92.61 %
Epoch 1758 of 2000 took 0.075s
  training loss:		0.003437
  validation loss:		0.475542
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.075s
  training loss:		0.003401
  validation loss:		0.473425
  validation accuracy:		92.50 %
Epoch 1760 of 2000 took 0.077s
  training loss:		0.003473
  validation loss:		0.477746
  validation accuracy:		92.39 %
Epoch 1761 of 2000 took 0.075s
  training loss:		0.003454
  validation loss:		0.474859
  validation accuracy:		92.72 %
Epoch 1762 of 2000 took 0.074s
  training loss:		0.003466
  validation loss:		0.472185
  validation accuracy:		92.39 %
Epoch 1763 of 2000 took 0.074s
  training loss:		0.003516
  validation loss:		0.474121
  validation accuracy:		92.61 %
Epoch 1764 of 2000 took 0.075s
  training loss:		0.003417
  validation loss:		0.476833
  validation accuracy:		92.17 %
Epoch 1765 of 2000 took 0.077s
  training loss:		0.003376
  validation loss:		0.472477
  validation accuracy:		92.50 %
Epoch 1766 of 2000 took 0.074s
  training loss:		0.003485
  validation loss:		0.472958
  validation accuracy:		92.50 %
Epoch 1767 of 2000 took 0.076s
  training loss:		0.003384
  validation loss:		0.476426
  validation accuracy:		92.39 %
Epoch 1768 of 2000 took 0.076s
  training loss:		0.003370
  validation loss:		0.477210
  validation accuracy:		92.28 %
Epoch 1769 of 2000 took 0.075s
  training loss:		0.003297
  validation loss:		0.477890
  validation accuracy:		92.50 %
Epoch 1770 of 2000 took 0.076s
  training loss:		0.003416
  validation loss:		0.476949
  validation accuracy:		92.61 %
Epoch 1771 of 2000 took 0.077s
  training loss:		0.003300
  validation loss:		0.472647
  validation accuracy:		92.50 %
Epoch 1772 of 2000 took 0.078s
  training loss:		0.003385
  validation loss:		0.480202
  validation accuracy:		92.50 %
Epoch 1773 of 2000 took 0.079s
  training loss:		0.003353
  validation loss:		0.475457
  validation accuracy:		92.61 %
Epoch 1774 of 2000 took 0.078s
  training loss:		0.003333
  validation loss:		0.473714
  validation accuracy:		92.50 %
Epoch 1775 of 2000 took 0.079s
  training loss:		0.003316
  validation loss:		0.473666
  validation accuracy:		92.50 %
Epoch 1776 of 2000 took 0.077s
  training loss:		0.003400
  validation loss:		0.474006
  validation accuracy:		92.61 %
Epoch 1777 of 2000 took 0.077s
  training loss:		0.003378
  validation loss:		0.476973
  validation accuracy:		92.61 %
Epoch 1778 of 2000 took 0.077s
  training loss:		0.003405
  validation loss:		0.475331
  validation accuracy:		92.72 %
Epoch 1779 of 2000 took 0.076s
  training loss:		0.003279
  validation loss:		0.473767
  validation accuracy:		92.61 %
Epoch 1780 of 2000 took 0.075s
  training loss:		0.003359
  validation loss:		0.473851
  validation accuracy:		92.50 %
Epoch 1781 of 2000 took 0.075s
  training loss:		0.003339
  validation loss:		0.477668
  validation accuracy:		92.39 %
Epoch 1782 of 2000 took 0.075s
  training loss:		0.003390
  validation loss:		0.476734
  validation accuracy:		92.50 %
Epoch 1783 of 2000 took 0.076s
  training loss:		0.003136
  validation loss:		0.471926
  validation accuracy:		92.72 %
Epoch 1784 of 2000 took 0.074s
  training loss:		0.003218
  validation loss:		0.478356
  validation accuracy:		92.39 %
Epoch 1785 of 2000 took 0.075s
  training loss:		0.003289
  validation loss:		0.471218
  validation accuracy:		92.72 %
Epoch 1786 of 2000 took 0.075s
  training loss:		0.003482
  validation loss:		0.477092
  validation accuracy:		92.61 %
Epoch 1787 of 2000 took 0.076s
  training loss:		0.003324
  validation loss:		0.479107
  validation accuracy:		92.50 %
Epoch 1788 of 2000 took 0.074s
  training loss:		0.003357
  validation loss:		0.476170
  validation accuracy:		92.50 %
Epoch 1789 of 2000 took 0.075s
  training loss:		0.003260
  validation loss:		0.475731
  validation accuracy:		92.39 %
Epoch 1790 of 2000 took 0.075s
  training loss:		0.003256
  validation loss:		0.475063
  validation accuracy:		92.50 %
Epoch 1791 of 2000 took 0.073s
  training loss:		0.003282
  validation loss:		0.480188
  validation accuracy:		92.17 %
Epoch 1792 of 2000 took 0.074s
  training loss:		0.003349
  validation loss:		0.472673
  validation accuracy:		92.61 %
Epoch 1793 of 2000 took 0.076s
  training loss:		0.003374
  validation loss:		0.475008
  validation accuracy:		92.50 %
Epoch 1794 of 2000 took 0.078s
  training loss:		0.003349
  validation loss:		0.478494
  validation accuracy:		92.39 %
Epoch 1795 of 2000 took 0.076s
  training loss:		0.003271
  validation loss:		0.478511
  validation accuracy:		92.50 %
Epoch 1796 of 2000 took 0.076s
  training loss:		0.003345
  validation loss:		0.477013
  validation accuracy:		92.50 %
Epoch 1797 of 2000 took 0.077s
  training loss:		0.003314
  validation loss:		0.479516
  validation accuracy:		92.39 %
Epoch 1798 of 2000 took 0.075s
  training loss:		0.003285
  validation loss:		0.481431
  validation accuracy:		92.50 %
Epoch 1799 of 2000 took 0.074s
  training loss:		0.003282
  validation loss:		0.480655
  validation accuracy:		92.28 %
Epoch 1800 of 2000 took 0.075s
  training loss:		0.003161
  validation loss:		0.476801
  validation accuracy:		92.50 %
Epoch 1801 of 2000 took 0.077s
  training loss:		0.003189
  validation loss:		0.477552
  validation accuracy:		92.61 %
Epoch 1802 of 2000 took 0.074s
  training loss:		0.003165
  validation loss:		0.481437
  validation accuracy:		92.50 %
Epoch 1803 of 2000 took 0.076s
  training loss:		0.003220
  validation loss:		0.478457
  validation accuracy:		92.61 %
Epoch 1804 of 2000 took 0.075s
  training loss:		0.003193
  validation loss:		0.481562
  validation accuracy:		92.50 %
Epoch 1805 of 2000 took 0.074s
  training loss:		0.003179
  validation loss:		0.477088
  validation accuracy:		92.61 %
Epoch 1806 of 2000 took 0.075s
  training loss:		0.003308
  validation loss:		0.477551
  validation accuracy:		92.61 %
Epoch 1807 of 2000 took 0.076s
  training loss:		0.003309
  validation loss:		0.478322
  validation accuracy:		92.50 %
Epoch 1808 of 2000 took 0.075s
  training loss:		0.003197
  validation loss:		0.481121
  validation accuracy:		92.39 %
Epoch 1809 of 2000 took 0.074s
  training loss:		0.003207
  validation loss:		0.478979
  validation accuracy:		92.61 %
Epoch 1810 of 2000 took 0.076s
  training loss:		0.003175
  validation loss:		0.476824
  validation accuracy:		92.50 %
Epoch 1811 of 2000 took 0.076s
  training loss:		0.003219
  validation loss:		0.480009
  validation accuracy:		92.50 %
Epoch 1812 of 2000 took 0.076s
  training loss:		0.003203
  validation loss:		0.479412
  validation accuracy:		92.72 %
Epoch 1813 of 2000 took 0.074s
  training loss:		0.003258
  validation loss:		0.483304
  validation accuracy:		92.61 %
Epoch 1814 of 2000 took 0.075s
  training loss:		0.003134
  validation loss:		0.482895
  validation accuracy:		92.39 %
Epoch 1815 of 2000 took 0.075s
  training loss:		0.003116
  validation loss:		0.475797
  validation accuracy:		92.72 %
Epoch 1816 of 2000 took 0.075s
  training loss:		0.003203
  validation loss:		0.483217
  validation accuracy:		92.50 %
Epoch 1817 of 2000 took 0.077s
  training loss:		0.003292
  validation loss:		0.476223
  validation accuracy:		92.50 %
Epoch 1818 of 2000 took 0.077s
  training loss:		0.003196
  validation loss:		0.482658
  validation accuracy:		92.39 %
Epoch 1819 of 2000 took 0.075s
  training loss:		0.003277
  validation loss:		0.481778
  validation accuracy:		92.39 %
Epoch 1820 of 2000 took 0.075s
  training loss:		0.003219
  validation loss:		0.483421
  validation accuracy:		92.50 %
Epoch 1821 of 2000 took 0.075s
  training loss:		0.003064
  validation loss:		0.476171
  validation accuracy:		92.39 %
Epoch 1822 of 2000 took 0.075s
  training loss:		0.003212
  validation loss:		0.484395
  validation accuracy:		92.50 %
Epoch 1823 of 2000 took 0.073s
  training loss:		0.003271
  validation loss:		0.481475
  validation accuracy:		92.50 %
Epoch 1824 of 2000 took 0.075s
  training loss:		0.003146
  validation loss:		0.481565
  validation accuracy:		92.50 %
Epoch 1825 of 2000 took 0.074s
  training loss:		0.003111
  validation loss:		0.482035
  validation accuracy:		92.61 %
Epoch 1826 of 2000 took 0.076s
  training loss:		0.003170
  validation loss:		0.479191
  validation accuracy:		92.61 %
Epoch 1827 of 2000 took 0.075s
  training loss:		0.003188
  validation loss:		0.479439
  validation accuracy:		92.61 %
Epoch 1828 of 2000 took 0.076s
  training loss:		0.003118
  validation loss:		0.486133
  validation accuracy:		92.61 %
Epoch 1829 of 2000 took 0.075s
  training loss:		0.003198
  validation loss:		0.482274
  validation accuracy:		92.61 %
Epoch 1830 of 2000 took 0.075s
  training loss:		0.003198
  validation loss:		0.484568
  validation accuracy:		92.50 %
Epoch 1831 of 2000 took 0.075s
  training loss:		0.003046
  validation loss:		0.479468
  validation accuracy:		92.72 %
Epoch 1832 of 2000 took 0.077s
  training loss:		0.003061
  validation loss:		0.476783
  validation accuracy:		92.39 %
Epoch 1833 of 2000 took 0.073s
  training loss:		0.003154
  validation loss:		0.487983
  validation accuracy:		92.50 %
Epoch 1834 of 2000 took 0.075s
  training loss:		0.003097
  validation loss:		0.480230
  validation accuracy:		92.61 %
Epoch 1835 of 2000 took 0.077s
  training loss:		0.003069
  validation loss:		0.480735
  validation accuracy:		92.50 %
Epoch 1836 of 2000 took 0.077s
  training loss:		0.003132
  validation loss:		0.484353
  validation accuracy:		92.39 %
Epoch 1837 of 2000 took 0.078s
  training loss:		0.003035
  validation loss:		0.484857
  validation accuracy:		92.39 %
Epoch 1838 of 2000 took 0.077s
  training loss:		0.003107
  validation loss:		0.484468
  validation accuracy:		92.72 %
Epoch 1839 of 2000 took 0.073s
  training loss:		0.003122
  validation loss:		0.483176
  validation accuracy:		92.50 %
Epoch 1840 of 2000 took 0.075s
  training loss:		0.003171
  validation loss:		0.486232
  validation accuracy:		92.50 %
Epoch 1841 of 2000 took 0.074s
  training loss:		0.003063
  validation loss:		0.479506
  validation accuracy:		92.50 %
Epoch 1842 of 2000 took 0.077s
  training loss:		0.003052
  validation loss:		0.481166
  validation accuracy:		92.50 %
Epoch 1843 of 2000 took 0.074s
  training loss:		0.003131
  validation loss:		0.484625
  validation accuracy:		92.39 %
Epoch 1844 of 2000 took 0.076s
  training loss:		0.003100
  validation loss:		0.485657
  validation accuracy:		92.39 %
Epoch 1845 of 2000 took 0.079s
  training loss:		0.003084
  validation loss:		0.484937
  validation accuracy:		92.39 %
Epoch 1846 of 2000 took 0.075s
  training loss:		0.003109
  validation loss:		0.479772
  validation accuracy:		92.61 %
Epoch 1847 of 2000 took 0.074s
  training loss:		0.003032
  validation loss:		0.485698
  validation accuracy:		92.61 %
Epoch 1848 of 2000 took 0.074s
  training loss:		0.002999
  validation loss:		0.484961
  validation accuracy:		92.50 %
Epoch 1849 of 2000 took 0.074s
  training loss:		0.003062
  validation loss:		0.483253
  validation accuracy:		92.72 %
Epoch 1850 of 2000 took 0.075s
  training loss:		0.003052
  validation loss:		0.488085
  validation accuracy:		92.61 %
Epoch 1851 of 2000 took 0.076s
  training loss:		0.003078
  validation loss:		0.488182
  validation accuracy:		92.50 %
Epoch 1852 of 2000 took 0.077s
  training loss:		0.003114
  validation loss:		0.481936
  validation accuracy:		92.50 %
Epoch 1853 of 2000 took 0.077s
  training loss:		0.003168
  validation loss:		0.485451
  validation accuracy:		92.28 %
Epoch 1854 of 2000 took 0.077s
  training loss:		0.003055
  validation loss:		0.483982
  validation accuracy:		92.50 %
Epoch 1855 of 2000 took 0.078s
  training loss:		0.003039
  validation loss:		0.484594
  validation accuracy:		92.50 %
Epoch 1856 of 2000 took 0.079s
  training loss:		0.003065
  validation loss:		0.486378
  validation accuracy:		92.39 %
Epoch 1857 of 2000 took 0.076s
  training loss:		0.003017
  validation loss:		0.485124
  validation accuracy:		92.61 %
Epoch 1858 of 2000 took 0.076s
  training loss:		0.003111
  validation loss:		0.488510
  validation accuracy:		92.39 %
Epoch 1859 of 2000 took 0.077s
  training loss:		0.003083
  validation loss:		0.485785
  validation accuracy:		92.50 %
Epoch 1860 of 2000 took 0.076s
  training loss:		0.003030
  validation loss:		0.486799
  validation accuracy:		92.50 %
Epoch 1861 of 2000 took 0.075s
  training loss:		0.003011
  validation loss:		0.485986
  validation accuracy:		92.39 %
Epoch 1862 of 2000 took 0.075s
  training loss:		0.003032
  validation loss:		0.488297
  validation accuracy:		92.39 %
Epoch 1863 of 2000 took 0.074s
  training loss:		0.003114
  validation loss:		0.483548
  validation accuracy:		92.50 %
Epoch 1864 of 2000 took 0.074s
  training loss:		0.003028
  validation loss:		0.487482
  validation accuracy:		92.50 %
Epoch 1865 of 2000 took 0.076s
  training loss:		0.003066
  validation loss:		0.487254
  validation accuracy:		92.39 %
Epoch 1866 of 2000 took 0.075s
  training loss:		0.003032
  validation loss:		0.482853
  validation accuracy:		92.61 %
Epoch 1867 of 2000 took 0.075s
  training loss:		0.002993
  validation loss:		0.487297
  validation accuracy:		92.50 %
Epoch 1868 of 2000 took 0.075s
  training loss:		0.002964
  validation loss:		0.484949
  validation accuracy:		92.50 %
Epoch 1869 of 2000 took 0.074s
  training loss:		0.003067
  validation loss:		0.484383
  validation accuracy:		92.50 %
Epoch 1870 of 2000 took 0.075s
  training loss:		0.003010
  validation loss:		0.487709
  validation accuracy:		92.28 %
Epoch 1871 of 2000 took 0.075s
  training loss:		0.003057
  validation loss:		0.487694
  validation accuracy:		92.50 %
Epoch 1872 of 2000 took 0.075s
  training loss:		0.003043
  validation loss:		0.488313
  validation accuracy:		92.39 %
Epoch 1873 of 2000 took 0.078s
  training loss:		0.002984
  validation loss:		0.489394
  validation accuracy:		92.28 %
Epoch 1874 of 2000 took 0.078s
  training loss:		0.003025
  validation loss:		0.486311
  validation accuracy:		92.39 %
Epoch 1875 of 2000 took 0.076s
  training loss:		0.002930
  validation loss:		0.483224
  validation accuracy:		92.50 %
Epoch 1876 of 2000 took 0.062s
  training loss:		0.002903
  validation loss:		0.488473
  validation accuracy:		92.61 %
Epoch 1877 of 2000 took 0.059s
  training loss:		0.002981
  validation loss:		0.481063
  validation accuracy:		92.61 %
Epoch 1878 of 2000 took 0.158s
  training loss:		0.002931
  validation loss:		0.493756
  validation accuracy:		92.50 %
Epoch 1879 of 2000 took 0.060s
  training loss:		0.002967
  validation loss:		0.487149
  validation accuracy:		92.61 %
Epoch 1880 of 2000 took 0.061s
  training loss:		0.002951
  validation loss:		0.489740
  validation accuracy:		92.39 %
Epoch 1881 of 2000 took 0.084s
  training loss:		0.002922
  validation loss:		0.484011
  validation accuracy:		92.39 %
Epoch 1882 of 2000 took 0.077s
  training loss:		0.002917
  validation loss:		0.483724
  validation accuracy:		92.61 %
Epoch 1883 of 2000 took 0.059s
  training loss:		0.003097
  validation loss:		0.484763
  validation accuracy:		92.61 %
Epoch 1884 of 2000 took 0.094s
  training loss:		0.002940
  validation loss:		0.490718
  validation accuracy:		92.39 %
Epoch 1885 of 2000 took 0.066s
  training loss:		0.002960
  validation loss:		0.490910
  validation accuracy:		92.50 %
Epoch 1886 of 2000 took 0.057s
  training loss:		0.002931
  validation loss:		0.493119
  validation accuracy:		92.39 %
Epoch 1887 of 2000 took 0.058s
  training loss:		0.002998
  validation loss:		0.485293
  validation accuracy:		92.50 %
Epoch 1888 of 2000 took 0.057s
  training loss:		0.002975
  validation loss:		0.487312
  validation accuracy:		92.39 %
Epoch 1889 of 2000 took 0.056s
  training loss:		0.002948
  validation loss:		0.491980
  validation accuracy:		92.50 %
Epoch 1890 of 2000 took 0.060s
  training loss:		0.002907
  validation loss:		0.486551
  validation accuracy:		92.61 %
Epoch 1891 of 2000 took 0.060s
  training loss:		0.002961
  validation loss:		0.492121
  validation accuracy:		92.50 %
Epoch 1892 of 2000 took 0.064s
  training loss:		0.002862
  validation loss:		0.487065
  validation accuracy:		92.39 %
Epoch 1893 of 2000 took 0.065s
  training loss:		0.002902
  validation loss:		0.489499
  validation accuracy:		92.50 %
Epoch 1894 of 2000 took 0.064s
  training loss:		0.002918
  validation loss:		0.487862
  validation accuracy:		92.39 %
Epoch 1895 of 2000 took 0.065s
  training loss:		0.002850
  validation loss:		0.491555
  validation accuracy:		92.61 %
Epoch 1896 of 2000 took 0.063s
  training loss:		0.002998
  validation loss:		0.489166
  validation accuracy:		92.50 %
Epoch 1897 of 2000 took 0.066s
  training loss:		0.002918
  validation loss:		0.489083
  validation accuracy:		92.61 %
Epoch 1898 of 2000 took 0.064s
  training loss:		0.002989
  validation loss:		0.490793
  validation accuracy:		92.39 %
Epoch 1899 of 2000 took 0.066s
  training loss:		0.002925
  validation loss:		0.492740
  validation accuracy:		92.61 %
Epoch 1900 of 2000 took 0.065s
  training loss:		0.002930
  validation loss:		0.492642
  validation accuracy:		92.39 %
Epoch 1901 of 2000 took 0.064s
  training loss:		0.002824
  validation loss:		0.488205
  validation accuracy:		92.39 %
Epoch 1902 of 2000 took 0.064s
  training loss:		0.002895
  validation loss:		0.498729
  validation accuracy:		92.39 %
Epoch 1903 of 2000 took 0.234s
  training loss:		0.002998
  validation loss:		0.490053
  validation accuracy:		92.50 %
Epoch 1904 of 2000 took 0.066s
  training loss:		0.002931
  validation loss:		0.486631
  validation accuracy:		92.50 %
Epoch 1905 of 2000 took 0.062s
  training loss:		0.002925
  validation loss:		0.489638
  validation accuracy:		92.61 %
Epoch 1906 of 2000 took 0.059s
  training loss:		0.002746
  validation loss:		0.494271
  validation accuracy:		92.39 %
Epoch 1907 of 2000 took 0.058s
  training loss:		0.002765
  validation loss:		0.491443
  validation accuracy:		92.61 %
Epoch 1908 of 2000 took 0.058s
  training loss:		0.002760
  validation loss:		0.489088
  validation accuracy:		92.39 %
Epoch 1909 of 2000 took 0.059s
  training loss:		0.002899
  validation loss:		0.489630
  validation accuracy:		92.61 %
Epoch 1910 of 2000 took 0.060s
  training loss:		0.002777
  validation loss:		0.492199
  validation accuracy:		92.39 %
Epoch 1911 of 2000 took 0.059s
  training loss:		0.002848
  validation loss:		0.488785
  validation accuracy:		92.28 %
Epoch 1912 of 2000 took 0.058s
  training loss:		0.002868
  validation loss:		0.492335
  validation accuracy:		92.61 %
Epoch 1913 of 2000 took 0.060s
  training loss:		0.002792
  validation loss:		0.487998
  validation accuracy:		92.50 %
Epoch 1914 of 2000 took 0.058s
  training loss:		0.002863
  validation loss:		0.494426
  validation accuracy:		92.39 %
Epoch 1915 of 2000 took 0.058s
  training loss:		0.002887
  validation loss:		0.495254
  validation accuracy:		92.39 %
Epoch 1916 of 2000 took 0.058s
  training loss:		0.002846
  validation loss:		0.494735
  validation accuracy:		92.28 %
Epoch 1917 of 2000 took 0.058s
  training loss:		0.002758
  validation loss:		0.490425
  validation accuracy:		92.28 %
Epoch 1918 of 2000 took 0.058s
  training loss:		0.002876
  validation loss:		0.492685
  validation accuracy:		92.50 %
Epoch 1919 of 2000 took 0.058s
  training loss:		0.002926
  validation loss:		0.495344
  validation accuracy:		92.28 %
Epoch 1920 of 2000 took 0.058s
  training loss:		0.002895
  validation loss:		0.493335
  validation accuracy:		92.28 %
Epoch 1921 of 2000 took 0.058s
  training loss:		0.002794
  validation loss:		0.489415
  validation accuracy:		92.39 %
Epoch 1922 of 2000 took 0.059s
  training loss:		0.002908
  validation loss:		0.491670
  validation accuracy:		92.39 %
Epoch 1923 of 2000 took 0.059s
  training loss:		0.002834
  validation loss:		0.494407
  validation accuracy:		92.39 %
Epoch 1924 of 2000 took 0.059s
  training loss:		0.002790
  validation loss:		0.491619
  validation accuracy:		92.61 %
Epoch 1925 of 2000 took 0.058s
  training loss:		0.002871
  validation loss:		0.491094
  validation accuracy:		92.61 %
Epoch 1926 of 2000 took 0.058s
  training loss:		0.002829
  validation loss:		0.490339
  validation accuracy:		92.50 %
Epoch 1927 of 2000 took 0.058s
  training loss:		0.002751
  validation loss:		0.490871
  validation accuracy:		92.28 %
Epoch 1928 of 2000 took 0.058s
  training loss:		0.002821
  validation loss:		0.495671
  validation accuracy:		92.50 %
Epoch 1929 of 2000 took 0.058s
  training loss:		0.002795
  validation loss:		0.491697
  validation accuracy:		92.61 %
Epoch 1930 of 2000 took 0.058s
  training loss:		0.002847
  validation loss:		0.497728
  validation accuracy:		92.39 %
Epoch 1931 of 2000 took 0.058s
  training loss:		0.002806
  validation loss:		0.495697
  validation accuracy:		92.39 %
Epoch 1932 of 2000 took 0.058s
  training loss:		0.002835
  validation loss:		0.494903
  validation accuracy:		92.39 %
Epoch 1933 of 2000 took 0.058s
  training loss:		0.002835
  validation loss:		0.492224
  validation accuracy:		92.61 %
Epoch 1934 of 2000 took 0.058s
  training loss:		0.002750
  validation loss:		0.493848
  validation accuracy:		92.50 %
Epoch 1935 of 2000 took 0.057s
  training loss:		0.002741
  validation loss:		0.488563
  validation accuracy:		92.50 %
Epoch 1936 of 2000 took 0.058s
  training loss:		0.002846
  validation loss:		0.493854
  validation accuracy:		92.50 %
Epoch 1937 of 2000 took 0.057s
  training loss:		0.002837
  validation loss:		0.496145
  validation accuracy:		92.50 %
Epoch 1938 of 2000 took 0.057s
  training loss:		0.002772
  validation loss:		0.495370
  validation accuracy:		92.39 %
Epoch 1939 of 2000 took 0.057s
  training loss:		0.002809
  validation loss:		0.492976
  validation accuracy:		92.28 %
Epoch 1940 of 2000 took 0.057s
  training loss:		0.002670
  validation loss:		0.496258
  validation accuracy:		92.28 %
Epoch 1941 of 2000 took 0.057s
  training loss:		0.002820
  validation loss:		0.493831
  validation accuracy:		92.61 %
Epoch 1942 of 2000 took 0.058s
  training loss:		0.002712
  validation loss:		0.497464
  validation accuracy:		92.39 %
Epoch 1943 of 2000 took 0.058s
  training loss:		0.002753
  validation loss:		0.497938
  validation accuracy:		92.39 %
Epoch 1944 of 2000 took 0.057s
  training loss:		0.002800
  validation loss:		0.495906
  validation accuracy:		92.39 %
Epoch 1945 of 2000 took 0.057s
  training loss:		0.002753
  validation loss:		0.495091
  validation accuracy:		92.39 %
Epoch 1946 of 2000 took 0.057s
  training loss:		0.002809
  validation loss:		0.494812
  validation accuracy:		92.50 %
Epoch 1947 of 2000 took 0.058s
  training loss:		0.002742
  validation loss:		0.496498
  validation accuracy:		92.50 %
Epoch 1948 of 2000 took 0.058s
  training loss:		0.002840
  validation loss:		0.494868
  validation accuracy:		92.39 %
Epoch 1949 of 2000 took 0.058s
  training loss:		0.002736
  validation loss:		0.494755
  validation accuracy:		92.50 %
Epoch 1950 of 2000 took 0.058s
  training loss:		0.002804
  validation loss:		0.493371
  validation accuracy:		92.50 %
Epoch 1951 of 2000 took 0.058s
  training loss:		0.002780
  validation loss:		0.496830
  validation accuracy:		92.39 %
Epoch 1952 of 2000 took 0.058s
  training loss:		0.002790
  validation loss:		0.496218
  validation accuracy:		92.39 %
Epoch 1953 of 2000 took 0.058s
  training loss:		0.002772
  validation loss:		0.493877
  validation accuracy:		92.39 %
Epoch 1954 of 2000 took 0.058s
  training loss:		0.002653
  validation loss:		0.496164
  validation accuracy:		92.50 %
Epoch 1955 of 2000 took 0.058s
  training loss:		0.002785
  validation loss:		0.494979
  validation accuracy:		92.50 %
Epoch 1956 of 2000 took 0.059s
  training loss:		0.002753
  validation loss:		0.494647
  validation accuracy:		92.50 %
Epoch 1957 of 2000 took 0.059s
  training loss:		0.002754
  validation loss:		0.497503
  validation accuracy:		92.39 %
Epoch 1958 of 2000 took 0.058s
  training loss:		0.002675
  validation loss:		0.500075
  validation accuracy:		92.39 %
Epoch 1959 of 2000 took 0.058s
  training loss:		0.002644
  validation loss:		0.495135
  validation accuracy:		92.28 %
Epoch 1960 of 2000 took 0.058s
  training loss:		0.002745
  validation loss:		0.496195
  validation accuracy:		92.50 %
Epoch 1961 of 2000 took 0.058s
  training loss:		0.002779
  validation loss:		0.500671
  validation accuracy:		92.28 %
Epoch 1962 of 2000 took 0.058s
  training loss:		0.002746
  validation loss:		0.496247
  validation accuracy:		92.50 %
Epoch 1963 of 2000 took 0.058s
  training loss:		0.002696
  validation loss:		0.497774
  validation accuracy:		92.61 %
Epoch 1964 of 2000 took 0.058s
  training loss:		0.002713
  validation loss:		0.500124
  validation accuracy:		92.28 %
Epoch 1965 of 2000 took 0.057s
  training loss:		0.002728
  validation loss:		0.497382
  validation accuracy:		92.39 %
Epoch 1966 of 2000 took 0.058s
  training loss:		0.002642
  validation loss:		0.499038
  validation accuracy:		92.39 %
Epoch 1967 of 2000 took 0.058s
  training loss:		0.002770
  validation loss:		0.493817
  validation accuracy:		92.50 %
Epoch 1968 of 2000 took 0.058s
  training loss:		0.002714
  validation loss:		0.498945
  validation accuracy:		92.39 %
Epoch 1969 of 2000 took 0.058s
  training loss:		0.002721
  validation loss:		0.494061
  validation accuracy:		92.50 %
Epoch 1970 of 2000 took 0.058s
  training loss:		0.002701
  validation loss:		0.497228
  validation accuracy:		92.50 %
Epoch 1971 of 2000 took 0.058s
  training loss:		0.002689
  validation loss:		0.498505
  validation accuracy:		92.50 %
Epoch 1972 of 2000 took 0.058s
  training loss:		0.002620
  validation loss:		0.496531
  validation accuracy:		92.39 %
Epoch 1973 of 2000 took 0.058s
  training loss:		0.002709
  validation loss:		0.500553
  validation accuracy:		92.39 %
Epoch 1974 of 2000 took 0.058s
  training loss:		0.002774
  validation loss:		0.498279
  validation accuracy:		92.50 %
Epoch 1975 of 2000 took 0.059s
  training loss:		0.002660
  validation loss:		0.496275
  validation accuracy:		92.39 %
Epoch 1976 of 2000 took 0.060s
  training loss:		0.002581
  validation loss:		0.497870
  validation accuracy:		92.17 %
Epoch 1977 of 2000 took 0.058s
  training loss:		0.002645
  validation loss:		0.498094
  validation accuracy:		92.50 %
Epoch 1978 of 2000 took 0.060s
  training loss:		0.002673
  validation loss:		0.500062
  validation accuracy:		92.39 %
Epoch 1979 of 2000 took 0.059s
  training loss:		0.002695
  validation loss:		0.499797
  validation accuracy:		92.61 %
Epoch 1980 of 2000 took 0.058s
  training loss:		0.002743
  validation loss:		0.501341
  validation accuracy:		92.39 %
Epoch 1981 of 2000 took 0.058s
  training loss:		0.002734
  validation loss:		0.497062
  validation accuracy:		92.39 %
Epoch 1982 of 2000 took 0.058s
  training loss:		0.002646
  validation loss:		0.498899
  validation accuracy:		92.39 %
Epoch 1983 of 2000 took 0.058s
  training loss:		0.002597
  validation loss:		0.499955
  validation accuracy:		92.50 %
Epoch 1984 of 2000 took 0.059s
  training loss:		0.002650
  validation loss:		0.502282
  validation accuracy:		92.28 %
Epoch 1985 of 2000 took 0.059s
  training loss:		0.002659
  validation loss:		0.498207
  validation accuracy:		92.28 %
Epoch 1986 of 2000 took 0.058s
  training loss:		0.002671
  validation loss:		0.500663
  validation accuracy:		92.50 %
Epoch 1987 of 2000 took 0.058s
  training loss:		0.002601
  validation loss:		0.500913
  validation accuracy:		92.39 %
Epoch 1988 of 2000 took 0.058s
  training loss:		0.002604
  validation loss:		0.496785
  validation accuracy:		92.39 %
Epoch 1989 of 2000 took 0.058s
  training loss:		0.002664
  validation loss:		0.500328
  validation accuracy:		92.39 %
Epoch 1990 of 2000 took 0.059s
  training loss:		0.002612
  validation loss:		0.497937
  validation accuracy:		92.39 %
Epoch 1991 of 2000 took 0.059s
  training loss:		0.002657
  validation loss:		0.505374
  validation accuracy:		92.28 %
Epoch 1992 of 2000 took 0.059s
  training loss:		0.002627
  validation loss:		0.498712
  validation accuracy:		92.39 %
Epoch 1993 of 2000 took 0.059s
  training loss:		0.002603
  validation loss:		0.496330
  validation accuracy:		92.61 %
Epoch 1994 of 2000 took 0.059s
  training loss:		0.002571
  validation loss:		0.501525
  validation accuracy:		92.39 %
Epoch 1995 of 2000 took 0.059s
  training loss:		0.002745
  validation loss:		0.504394
  validation accuracy:		92.61 %
Epoch 1996 of 2000 took 0.058s
  training loss:		0.002606
  validation loss:		0.499477
  validation accuracy:		92.39 %
Epoch 1997 of 2000 took 0.059s
  training loss:		0.002692
  validation loss:		0.501082
  validation accuracy:		92.28 %
Epoch 1998 of 2000 took 0.058s
  training loss:		0.002583
  validation loss:		0.499576
  validation accuracy:		92.39 %
Epoch 1999 of 2000 took 0.058s
  training loss:		0.002609
  validation loss:		0.499315
  validation accuracy:		92.50 %
Epoch 2000 of 2000 took 0.059s
  training loss:		0.002629
  validation loss:		0.501755
  validation accuracy:		92.50 %
Final results:
  test loss:			1.279095
  test accuracy:		84.47 %
