Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.099s
  training loss:		2.995944
  validation loss:		2.992894
  validation accuracy:		0.00 %
Epoch 2 of 2000 took 0.101s
  training loss:		2.987370
  validation loss:		2.980382
  validation accuracy:		6.52 %
Epoch 3 of 2000 took 0.097s
  training loss:		2.975517
  validation loss:		2.965883
  validation accuracy:		13.26 %
Epoch 4 of 2000 took 0.096s
  training loss:		2.962768
  validation loss:		2.950770
  validation accuracy:		13.91 %
Epoch 5 of 2000 took 0.101s
  training loss:		2.949254
  validation loss:		2.935242
  validation accuracy:		14.78 %
Epoch 6 of 2000 took 0.100s
  training loss:		2.934957
  validation loss:		2.919235
  validation accuracy:		13.59 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.920264
  validation loss:		2.902696
  validation accuracy:		13.04 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.906468
  validation loss:		2.885502
  validation accuracy:		12.93 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.890425
  validation loss:		2.867416
  validation accuracy:		12.83 %
Epoch 10 of 2000 took 0.100s
  training loss:		2.874519
  validation loss:		2.848269
  validation accuracy:		12.83 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.857104
  validation loss:		2.827473
  validation accuracy:		12.83 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.838375
  validation loss:		2.805003
  validation accuracy:		12.83 %
Epoch 13 of 2000 took 0.102s
  training loss:		2.818391
  validation loss:		2.780225
  validation accuracy:		12.83 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.796509
  validation loss:		2.753311
  validation accuracy:		12.83 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.771381
  validation loss:		2.723405
  validation accuracy:		12.83 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.745259
  validation loss:		2.690404
  validation accuracy:		12.83 %
Epoch 17 of 2000 took 0.099s
  training loss:		2.713452
  validation loss:		2.653716
  validation accuracy:		12.83 %
Epoch 18 of 2000 took 0.100s
  training loss:		2.683338
  validation loss:		2.613860
  validation accuracy:		12.83 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.645528
  validation loss:		2.570697
  validation accuracy:		12.83 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.607548
  validation loss:		2.525059
  validation accuracy:		12.83 %
Epoch 21 of 2000 took 0.102s
  training loss:		2.565084
  validation loss:		2.478232
  validation accuracy:		12.83 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.524158
  validation loss:		2.433037
  validation accuracy:		12.83 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.485059
  validation loss:		2.390094
  validation accuracy:		12.83 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.447978
  validation loss:		2.353815
  validation accuracy:		13.70 %
Epoch 25 of 2000 took 0.099s
  training loss:		2.412777
  validation loss:		2.323473
  validation accuracy:		13.04 %
Epoch 26 of 2000 took 0.098s
  training loss:		2.383984
  validation loss:		2.301195
  validation accuracy:		13.04 %
Epoch 27 of 2000 took 0.095s
  training loss:		2.360050
  validation loss:		2.287187
  validation accuracy:		13.80 %
Epoch 28 of 2000 took 0.098s
  training loss:		2.344402
  validation loss:		2.278175
  validation accuracy:		13.48 %
Epoch 29 of 2000 took 0.100s
  training loss:		2.330275
  validation loss:		2.271392
  validation accuracy:		12.93 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.322220
  validation loss:		2.266325
  validation accuracy:		12.83 %
Epoch 31 of 2000 took 0.099s
  training loss:		2.315128
  validation loss:		2.258680
  validation accuracy:		14.89 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.312739
  validation loss:		2.255009
  validation accuracy:		13.26 %
Epoch 33 of 2000 took 0.101s
  training loss:		2.309428
  validation loss:		2.255159
  validation accuracy:		17.61 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.305827
  validation loss:		2.254553
  validation accuracy:		13.48 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.304310
  validation loss:		2.251058
  validation accuracy:		14.02 %
Epoch 36 of 2000 took 0.101s
  training loss:		2.303254
  validation loss:		2.250369
  validation accuracy:		15.11 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.302106
  validation loss:		2.251241
  validation accuracy:		14.02 %
Epoch 38 of 2000 took 0.096s
  training loss:		2.300462
  validation loss:		2.250289
  validation accuracy:		12.93 %
Epoch 39 of 2000 took 0.096s
  training loss:		2.299873
  validation loss:		2.249521
  validation accuracy:		13.48 %
Epoch 40 of 2000 took 0.096s
  training loss:		2.299406
  validation loss:		2.247339
  validation accuracy:		12.93 %
Epoch 41 of 2000 took 0.100s
  training loss:		2.298581
  validation loss:		2.245924
  validation accuracy:		12.93 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.298050
  validation loss:		2.247905
  validation accuracy:		16.63 %
Epoch 43 of 2000 took 0.096s
  training loss:		2.297981
  validation loss:		2.246896
  validation accuracy:		12.83 %
Epoch 44 of 2000 took 0.102s
  training loss:		2.297683
  validation loss:		2.248718
  validation accuracy:		13.26 %
Epoch 45 of 2000 took 0.096s
  training loss:		2.297534
  validation loss:		2.246052
  validation accuracy:		12.93 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.296288
  validation loss:		2.244624
  validation accuracy:		14.24 %
Epoch 47 of 2000 took 0.096s
  training loss:		2.296016
  validation loss:		2.244625
  validation accuracy:		12.93 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.296297
  validation loss:		2.243517
  validation accuracy:		12.93 %
Epoch 49 of 2000 took 0.100s
  training loss:		2.295713
  validation loss:		2.245705
  validation accuracy:		12.83 %
Epoch 50 of 2000 took 0.096s
  training loss:		2.295057
  validation loss:		2.242949
  validation accuracy:		18.48 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.296188
  validation loss:		2.243732
  validation accuracy:		13.91 %
Epoch 52 of 2000 took 0.102s
  training loss:		2.295064
  validation loss:		2.242187
  validation accuracy:		16.96 %
Epoch 53 of 2000 took 0.096s
  training loss:		2.295594
  validation loss:		2.243718
  validation accuracy:		20.54 %
Epoch 54 of 2000 took 0.099s
  training loss:		2.295509
  validation loss:		2.243391
  validation accuracy:		17.83 %
Epoch 55 of 2000 took 0.096s
  training loss:		2.295617
  validation loss:		2.243471
  validation accuracy:		12.83 %
Epoch 56 of 2000 took 0.099s
  training loss:		2.294928
  validation loss:		2.241886
  validation accuracy:		19.13 %
Epoch 57 of 2000 took 0.098s
  training loss:		2.294904
  validation loss:		2.242048
  validation accuracy:		16.96 %
Epoch 58 of 2000 took 0.096s
  training loss:		2.295133
  validation loss:		2.245624
  validation accuracy:		12.83 %
Epoch 59 of 2000 took 0.098s
  training loss:		2.294992
  validation loss:		2.245422
  validation accuracy:		12.83 %
Epoch 60 of 2000 took 0.100s
  training loss:		2.293507
  validation loss:		2.241717
  validation accuracy:		14.46 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.293278
  validation loss:		2.235357
  validation accuracy:		17.50 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.293903
  validation loss:		2.241886
  validation accuracy:		14.67 %
Epoch 63 of 2000 took 0.096s
  training loss:		2.294861
  validation loss:		2.243842
  validation accuracy:		12.83 %
Epoch 64 of 2000 took 0.100s
  training loss:		2.294462
  validation loss:		2.246499
  validation accuracy:		12.83 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.294328
  validation loss:		2.242110
  validation accuracy:		22.39 %
Epoch 66 of 2000 took 0.095s
  training loss:		2.294449
  validation loss:		2.243318
  validation accuracy:		13.59 %
Epoch 67 of 2000 took 0.101s
  training loss:		2.293989
  validation loss:		2.244062
  validation accuracy:		12.93 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.293685
  validation loss:		2.242622
  validation accuracy:		13.04 %
Epoch 69 of 2000 took 0.096s
  training loss:		2.294088
  validation loss:		2.244830
  validation accuracy:		12.93 %
Epoch 70 of 2000 took 0.096s
  training loss:		2.294096
  validation loss:		2.241702
  validation accuracy:		12.93 %
Epoch 71 of 2000 took 0.096s
  training loss:		2.292993
  validation loss:		2.241481
  validation accuracy:		13.04 %
Epoch 72 of 2000 took 0.100s
  training loss:		2.293898
  validation loss:		2.238540
  validation accuracy:		13.91 %
Epoch 73 of 2000 took 0.097s
  training loss:		2.293385
  validation loss:		2.244971
  validation accuracy:		14.35 %
Epoch 74 of 2000 took 0.096s
  training loss:		2.294206
  validation loss:		2.242699
  validation accuracy:		12.83 %
Epoch 75 of 2000 took 0.102s
  training loss:		2.292420
  validation loss:		2.238253
  validation accuracy:		12.93 %
Epoch 76 of 2000 took 0.096s
  training loss:		2.292852
  validation loss:		2.238176
  validation accuracy:		14.02 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.294211
  validation loss:		2.242714
  validation accuracy:		17.83 %
Epoch 78 of 2000 took 0.096s
  training loss:		2.293791
  validation loss:		2.242342
  validation accuracy:		13.80 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.293353
  validation loss:		2.246197
  validation accuracy:		13.37 %
Epoch 80 of 2000 took 0.100s
  training loss:		2.293352
  validation loss:		2.242705
  validation accuracy:		12.83 %
Epoch 81 of 2000 took 0.096s
  training loss:		2.292726
  validation loss:		2.238207
  validation accuracy:		12.93 %
Epoch 82 of 2000 took 0.096s
  training loss:		2.292472
  validation loss:		2.240612
  validation accuracy:		20.87 %
Epoch 83 of 2000 took 0.102s
  training loss:		2.293577
  validation loss:		2.240813
  validation accuracy:		15.22 %
Epoch 84 of 2000 took 0.096s
  training loss:		2.293522
  validation loss:		2.241643
  validation accuracy:		12.93 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.293145
  validation loss:		2.241634
  validation accuracy:		12.83 %
Epoch 86 of 2000 took 0.096s
  training loss:		2.293303
  validation loss:		2.240454
  validation accuracy:		15.65 %
Epoch 87 of 2000 took 0.098s
  training loss:		2.292830
  validation loss:		2.245218
  validation accuracy:		12.83 %
Epoch 88 of 2000 took 0.099s
  training loss:		2.292406
  validation loss:		2.240384
  validation accuracy:		13.15 %
Epoch 89 of 2000 took 0.095s
  training loss:		2.292516
  validation loss:		2.242006
  validation accuracy:		12.83 %
Epoch 90 of 2000 took 0.097s
  training loss:		2.293632
  validation loss:		2.242406
  validation accuracy:		14.02 %
Epoch 91 of 2000 took 0.103s
  training loss:		2.293152
  validation loss:		2.242965
  validation accuracy:		23.59 %
Epoch 92 of 2000 took 0.096s
  training loss:		2.293395
  validation loss:		2.241510
  validation accuracy:		13.15 %
Epoch 93 of 2000 took 0.097s
  training loss:		2.293564
  validation loss:		2.242634
  validation accuracy:		18.70 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.293093
  validation loss:		2.244424
  validation accuracy:		13.15 %
Epoch 95 of 2000 took 0.100s
  training loss:		2.291866
  validation loss:		2.239213
  validation accuracy:		14.57 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.291955
  validation loss:		2.244910
  validation accuracy:		22.28 %
Epoch 97 of 2000 took 0.096s
  training loss:		2.291842
  validation loss:		2.237150
  validation accuracy:		13.04 %
Epoch 98 of 2000 took 0.100s
  training loss:		2.292126
  validation loss:		2.236107
  validation accuracy:		15.65 %
Epoch 99 of 2000 took 0.098s
  training loss:		2.291702
  validation loss:		2.243250
  validation accuracy:		14.02 %
Epoch 100 of 2000 took 0.096s
  training loss:		2.291206
  validation loss:		2.236748
  validation accuracy:		17.72 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.292769
  validation loss:		2.241870
  validation accuracy:		16.74 %
Epoch 102 of 2000 took 0.096s
  training loss:		2.292502
  validation loss:		2.240126
  validation accuracy:		19.89 %
Epoch 103 of 2000 took 0.100s
  training loss:		2.291922
  validation loss:		2.241982
  validation accuracy:		15.54 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.292031
  validation loss:		2.240574
  validation accuracy:		21.09 %
Epoch 105 of 2000 took 0.096s
  training loss:		2.292217
  validation loss:		2.239414
  validation accuracy:		12.93 %
Epoch 106 of 2000 took 0.102s
  training loss:		2.291608
  validation loss:		2.241103
  validation accuracy:		13.04 %
Epoch 107 of 2000 took 0.096s
  training loss:		2.292521
  validation loss:		2.244105
  validation accuracy:		13.70 %
Epoch 108 of 2000 took 0.096s
  training loss:		2.292437
  validation loss:		2.236589
  validation accuracy:		21.96 %
Epoch 109 of 2000 took 0.096s
  training loss:		2.291813
  validation loss:		2.243340
  validation accuracy:		15.43 %
Epoch 110 of 2000 took 0.097s
  training loss:		2.291349
  validation loss:		2.239723
  validation accuracy:		15.87 %
Epoch 111 of 2000 took 0.100s
  training loss:		2.291335
  validation loss:		2.238695
  validation accuracy:		12.93 %
Epoch 112 of 2000 took 0.096s
  training loss:		2.290794
  validation loss:		2.235168
  validation accuracy:		14.35 %
Epoch 113 of 2000 took 0.096s
  training loss:		2.291263
  validation loss:		2.237223
  validation accuracy:		13.37 %
Epoch 114 of 2000 took 0.102s
  training loss:		2.292343
  validation loss:		2.241946
  validation accuracy:		19.24 %
Epoch 115 of 2000 took 0.096s
  training loss:		2.291405
  validation loss:		2.240289
  validation accuracy:		13.37 %
Epoch 116 of 2000 took 0.097s
  training loss:		2.290556
  validation loss:		2.239244
  validation accuracy:		13.26 %
Epoch 117 of 2000 took 0.096s
  training loss:		2.291656
  validation loss:		2.236768
  validation accuracy:		19.78 %
Epoch 118 of 2000 took 0.098s
  training loss:		2.290964
  validation loss:		2.240990
  validation accuracy:		13.59 %
Epoch 119 of 2000 took 0.100s
  training loss:		2.289874
  validation loss:		2.238882
  validation accuracy:		14.02 %
Epoch 120 of 2000 took 0.096s
  training loss:		2.290110
  validation loss:		2.236111
  validation accuracy:		12.93 %
Epoch 121 of 2000 took 0.097s
  training loss:		2.291495
  validation loss:		2.233830
  validation accuracy:		13.91 %
Epoch 122 of 2000 took 0.101s
  training loss:		2.290919
  validation loss:		2.239488
  validation accuracy:		25.76 %
Epoch 123 of 2000 took 0.096s
  training loss:		2.289675
  validation loss:		2.240863
  validation accuracy:		22.50 %
Epoch 124 of 2000 took 0.097s
  training loss:		2.291516
  validation loss:		2.240369
  validation accuracy:		18.37 %
Epoch 125 of 2000 took 0.096s
  training loss:		2.290940
  validation loss:		2.241915
  validation accuracy:		20.33 %
Epoch 126 of 2000 took 0.100s
  training loss:		2.289979
  validation loss:		2.238289
  validation accuracy:		18.59 %
Epoch 127 of 2000 took 0.098s
  training loss:		2.290154
  validation loss:		2.235516
  validation accuracy:		13.48 %
Epoch 128 of 2000 took 0.095s
  training loss:		2.288774
  validation loss:		2.232953
  validation accuracy:		21.30 %
Epoch 129 of 2000 took 0.099s
  training loss:		2.290531
  validation loss:		2.237979
  validation accuracy:		26.74 %
Epoch 130 of 2000 took 0.099s
  training loss:		2.289672
  validation loss:		2.239134
  validation accuracy:		15.11 %
Epoch 131 of 2000 took 0.096s
  training loss:		2.289918
  validation loss:		2.236500
  validation accuracy:		22.72 %
Epoch 132 of 2000 took 0.096s
  training loss:		2.290211
  validation loss:		2.237872
  validation accuracy:		25.43 %
Epoch 133 of 2000 took 0.096s
  training loss:		2.289830
  validation loss:		2.238386
  validation accuracy:		13.37 %
Epoch 134 of 2000 took 0.101s
  training loss:		2.289471
  validation loss:		2.239292
  validation accuracy:		15.11 %
Epoch 135 of 2000 took 0.097s
  training loss:		2.290491
  validation loss:		2.235573
  validation accuracy:		23.04 %
Epoch 136 of 2000 took 0.096s
  training loss:		2.289408
  validation loss:		2.228902
  validation accuracy:		20.98 %
Epoch 137 of 2000 took 0.102s
  training loss:		2.291182
  validation loss:		2.240473
  validation accuracy:		13.26 %
Epoch 138 of 2000 took 0.096s
  training loss:		2.289011
  validation loss:		2.239266
  validation accuracy:		12.83 %
Epoch 139 of 2000 took 0.096s
  training loss:		2.289372
  validation loss:		2.235894
  validation accuracy:		15.22 %
Epoch 140 of 2000 took 0.096s
  training loss:		2.289430
  validation loss:		2.240358
  validation accuracy:		24.67 %
Epoch 141 of 2000 took 0.097s
  training loss:		2.289437
  validation loss:		2.235811
  validation accuracy:		19.67 %
Epoch 142 of 2000 took 0.100s
  training loss:		2.288982
  validation loss:		2.234844
  validation accuracy:		25.22 %
Epoch 143 of 2000 took 0.096s
  training loss:		2.288527
  validation loss:		2.238189
  validation accuracy:		18.80 %
Epoch 144 of 2000 took 0.096s
  training loss:		2.288441
  validation loss:		2.234890
  validation accuracy:		16.52 %
Epoch 145 of 2000 took 0.102s
  training loss:		2.288959
  validation loss:		2.233513
  validation accuracy:		24.57 %
Epoch 146 of 2000 took 0.096s
  training loss:		2.287289
  validation loss:		2.234369
  validation accuracy:		20.87 %
Epoch 147 of 2000 took 0.097s
  training loss:		2.288501
  validation loss:		2.236781
  validation accuracy:		20.76 %
Epoch 148 of 2000 took 0.096s
  training loss:		2.287558
  validation loss:		2.235469
  validation accuracy:		28.37 %
Epoch 149 of 2000 took 0.098s
  training loss:		2.287480
  validation loss:		2.235112
  validation accuracy:		26.74 %
Epoch 150 of 2000 took 0.100s
  training loss:		2.286871
  validation loss:		2.231130
  validation accuracy:		17.07 %
Epoch 151 of 2000 took 0.098s
  training loss:		2.286439
  validation loss:		2.235483
  validation accuracy:		28.04 %
Epoch 152 of 2000 took 0.097s
  training loss:		2.287724
  validation loss:		2.232303
  validation accuracy:		13.15 %
Epoch 153 of 2000 took 0.101s
  training loss:		2.287600
  validation loss:		2.230709
  validation accuracy:		13.26 %
Epoch 154 of 2000 took 0.096s
  training loss:		2.285937
  validation loss:		2.231970
  validation accuracy:		14.57 %
Epoch 155 of 2000 took 0.097s
  training loss:		2.287206
  validation loss:		2.236978
  validation accuracy:		20.11 %
Epoch 156 of 2000 took 0.096s
  training loss:		2.286805
  validation loss:		2.233776
  validation accuracy:		22.07 %
Epoch 157 of 2000 took 0.100s
  training loss:		2.285845
  validation loss:		2.231975
  validation accuracy:		22.39 %
Epoch 158 of 2000 took 0.097s
  training loss:		2.285649
  validation loss:		2.235712
  validation accuracy:		18.37 %
Epoch 159 of 2000 took 0.095s
  training loss:		2.287102
  validation loss:		2.235273
  validation accuracy:		23.80 %
Epoch 160 of 2000 took 0.100s
  training loss:		2.285799
  validation loss:		2.233914
  validation accuracy:		15.98 %
Epoch 161 of 2000 took 0.097s
  training loss:		2.285381
  validation loss:		2.232767
  validation accuracy:		20.76 %
Epoch 162 of 2000 took 0.096s
  training loss:		2.285473
  validation loss:		2.235766
  validation accuracy:		18.26 %
Epoch 163 of 2000 took 0.096s
  training loss:		2.284276
  validation loss:		2.228300
  validation accuracy:		22.50 %
Epoch 164 of 2000 took 0.096s
  training loss:		2.284557
  validation loss:		2.229390
  validation accuracy:		21.09 %
Epoch 165 of 2000 took 0.100s
  training loss:		2.285176
  validation loss:		2.234267
  validation accuracy:		21.52 %
Epoch 166 of 2000 took 0.097s
  training loss:		2.283328
  validation loss:		2.228083
  validation accuracy:		19.24 %
Epoch 167 of 2000 took 0.096s
  training loss:		2.283506
  validation loss:		2.228655
  validation accuracy:		23.59 %
Epoch 168 of 2000 took 0.102s
  training loss:		2.283320
  validation loss:		2.230724
  validation accuracy:		24.57 %
Epoch 169 of 2000 took 0.096s
  training loss:		2.282916
  validation loss:		2.229176
  validation accuracy:		26.96 %
Epoch 170 of 2000 took 0.097s
  training loss:		2.282414
  validation loss:		2.229508
  validation accuracy:		21.74 %
Epoch 171 of 2000 took 0.096s
  training loss:		2.283138
  validation loss:		2.228155
  validation accuracy:		19.78 %
Epoch 172 of 2000 took 0.097s
  training loss:		2.282257
  validation loss:		2.224686
  validation accuracy:		16.30 %
Epoch 173 of 2000 took 0.100s
  training loss:		2.282465
  validation loss:		2.227986
  validation accuracy:		20.43 %
Epoch 174 of 2000 took 0.096s
  training loss:		2.280894
  validation loss:		2.230038
  validation accuracy:		19.67 %
Epoch 175 of 2000 took 0.096s
  training loss:		2.279407
  validation loss:		2.226617
  validation accuracy:		22.72 %
Epoch 176 of 2000 took 0.102s
  training loss:		2.281580
  validation loss:		2.227824
  validation accuracy:		21.96 %
Epoch 177 of 2000 took 0.096s
  training loss:		2.280198
  validation loss:		2.224311
  validation accuracy:		25.65 %
Epoch 178 of 2000 took 0.097s
  training loss:		2.278534
  validation loss:		2.225596
  validation accuracy:		20.54 %
Epoch 179 of 2000 took 0.096s
  training loss:		2.278534
  validation loss:		2.223156
  validation accuracy:		31.09 %
Epoch 180 of 2000 took 0.098s
  training loss:		2.278892
  validation loss:		2.222742
  validation accuracy:		24.35 %
Epoch 181 of 2000 took 0.100s
  training loss:		2.278858
  validation loss:		2.230608
  validation accuracy:		23.04 %
Epoch 182 of 2000 took 0.096s
  training loss:		2.278805
  validation loss:		2.222854
  validation accuracy:		20.54 %
Epoch 183 of 2000 took 0.100s
  training loss:		2.275916
  validation loss:		2.220305
  validation accuracy:		24.24 %
Epoch 184 of 2000 took 0.105s
  training loss:		2.277056
  validation loss:		2.224010
  validation accuracy:		30.22 %
Epoch 185 of 2000 took 0.099s
  training loss:		2.273847
  validation loss:		2.221651
  validation accuracy:		21.85 %
Epoch 186 of 2000 took 0.100s
  training loss:		2.275364
  validation loss:		2.216900
  validation accuracy:		24.57 %
Epoch 187 of 2000 took 0.099s
  training loss:		2.274680
  validation loss:		2.221642
  validation accuracy:		17.17 %
Epoch 188 of 2000 took 0.103s
  training loss:		2.273415
  validation loss:		2.222390
  validation accuracy:		24.57 %
Epoch 189 of 2000 took 0.101s
  training loss:		2.272872
  validation loss:		2.217030
  validation accuracy:		23.70 %
Epoch 190 of 2000 took 0.099s
  training loss:		2.271419
  validation loss:		2.210043
  validation accuracy:		27.72 %
Epoch 191 of 2000 took 0.102s
  training loss:		2.270369
  validation loss:		2.214588
  validation accuracy:		30.98 %
Epoch 192 of 2000 took 0.102s
  training loss:		2.268240
  validation loss:		2.215496
  validation accuracy:		23.48 %
Epoch 193 of 2000 took 0.099s
  training loss:		2.268688
  validation loss:		2.212575
  validation accuracy:		26.74 %
Epoch 194 of 2000 took 0.099s
  training loss:		2.267264
  validation loss:		2.208239
  validation accuracy:		30.87 %
Epoch 195 of 2000 took 0.099s
  training loss:		2.264961
  validation loss:		2.213023
  validation accuracy:		20.33 %
Epoch 196 of 2000 took 0.104s
  training loss:		2.263307
  validation loss:		2.205334
  validation accuracy:		31.30 %
Epoch 197 of 2000 took 0.100s
  training loss:		2.261470
  validation loss:		2.203853
  validation accuracy:		28.15 %
Epoch 198 of 2000 took 0.099s
  training loss:		2.259592
  validation loss:		2.201222
  validation accuracy:		29.46 %
Epoch 199 of 2000 took 0.105s
  training loss:		2.258956
  validation loss:		2.205897
  validation accuracy:		31.20 %
Epoch 200 of 2000 took 0.100s
  training loss:		2.255211
  validation loss:		2.197659
  validation accuracy:		27.61 %
Epoch 201 of 2000 took 0.099s
  training loss:		2.253841
  validation loss:		2.195766
  validation accuracy:		31.85 %
Epoch 202 of 2000 took 0.099s
  training loss:		2.250855
  validation loss:		2.196103
  validation accuracy:		26.85 %
Epoch 203 of 2000 took 0.100s
  training loss:		2.249688
  validation loss:		2.194123
  validation accuracy:		28.59 %
Epoch 204 of 2000 took 0.103s
  training loss:		2.246026
  validation loss:		2.185969
  validation accuracy:		31.41 %
Epoch 205 of 2000 took 0.100s
  training loss:		2.242973
  validation loss:		2.185668
  validation accuracy:		27.07 %
Epoch 206 of 2000 took 0.099s
  training loss:		2.238549
  validation loss:		2.178680
  validation accuracy:		27.93 %
Epoch 207 of 2000 took 0.105s
  training loss:		2.234517
  validation loss:		2.174937
  validation accuracy:		27.39 %
Epoch 208 of 2000 took 0.099s
  training loss:		2.230065
  validation loss:		2.170160
  validation accuracy:		32.17 %
Epoch 209 of 2000 took 0.100s
  training loss:		2.225590
  validation loss:		2.161227
  validation accuracy:		34.57 %
Epoch 210 of 2000 took 0.099s
  training loss:		2.218532
  validation loss:		2.152407
  validation accuracy:		30.87 %
Epoch 211 of 2000 took 0.101s
  training loss:		2.214621
  validation loss:		2.145613
  validation accuracy:		32.28 %
Epoch 212 of 2000 took 0.103s
  training loss:		2.205536
  validation loss:		2.146066
  validation accuracy:		28.48 %
Epoch 213 of 2000 took 0.099s
  training loss:		2.196394
  validation loss:		2.131858
  validation accuracy:		31.52 %
Epoch 214 of 2000 took 0.100s
  training loss:		2.185337
  validation loss:		2.114167
  validation accuracy:		31.41 %
Epoch 215 of 2000 took 0.105s
  training loss:		2.174907
  validation loss:		2.103918
  validation accuracy:		31.74 %
Epoch 216 of 2000 took 0.099s
  training loss:		2.164338
  validation loss:		2.086870
  validation accuracy:		34.02 %
Epoch 217 of 2000 took 0.100s
  training loss:		2.148514
  validation loss:		2.078184
  validation accuracy:		33.15 %
Epoch 218 of 2000 took 0.099s
  training loss:		2.131810
  validation loss:		2.058855
  validation accuracy:		30.76 %
Epoch 219 of 2000 took 0.103s
  training loss:		2.112224
  validation loss:		2.034837
  validation accuracy:		32.72 %
Epoch 220 of 2000 took 0.101s
  training loss:		2.090117
  validation loss:		2.012444
  validation accuracy:		33.26 %
Epoch 221 of 2000 took 0.099s
  training loss:		2.066816
  validation loss:		1.981200
  validation accuracy:		36.41 %
Epoch 222 of 2000 took 0.102s
  training loss:		2.040099
  validation loss:		1.954739
  validation accuracy:		35.00 %
Epoch 223 of 2000 took 0.102s
  training loss:		2.010929
  validation loss:		1.928498
  validation accuracy:		32.93 %
Epoch 224 of 2000 took 0.099s
  training loss:		1.976575
  validation loss:		1.894241
  validation accuracy:		34.89 %
Epoch 225 of 2000 took 0.099s
  training loss:		1.947335
  validation loss:		1.857451
  validation accuracy:		36.96 %
Epoch 226 of 2000 took 0.099s
  training loss:		1.911363
  validation loss:		1.822424
  validation accuracy:		37.50 %
Epoch 227 of 2000 took 0.104s
  training loss:		1.880525
  validation loss:		1.794334
  validation accuracy:		37.93 %
Epoch 228 of 2000 took 0.100s
  training loss:		1.848091
  validation loss:		1.758655
  validation accuracy:		39.13 %
Epoch 229 of 2000 took 0.099s
  training loss:		1.814989
  validation loss:		1.723520
  validation accuracy:		39.89 %
Epoch 230 of 2000 took 0.105s
  training loss:		1.789402
  validation loss:		1.701360
  validation accuracy:		38.26 %
Epoch 231 of 2000 took 0.099s
  training loss:		1.761426
  validation loss:		1.678254
  validation accuracy:		38.04 %
Epoch 232 of 2000 took 0.099s
  training loss:		1.736742
  validation loss:		1.651642
  validation accuracy:		39.57 %
Epoch 233 of 2000 took 0.099s
  training loss:		1.706112
  validation loss:		1.627991
  validation accuracy:		38.59 %
Epoch 234 of 2000 took 0.100s
  training loss:		1.689108
  validation loss:		1.605408
  validation accuracy:		40.00 %
Epoch 235 of 2000 took 0.103s
  training loss:		1.662779
  validation loss:		1.583015
  validation accuracy:		40.98 %
Epoch 236 of 2000 took 0.100s
  training loss:		1.638156
  validation loss:		1.569275
  validation accuracy:		42.17 %
Epoch 237 of 2000 took 0.099s
  training loss:		1.620126
  validation loss:		1.547811
  validation accuracy:		42.83 %
Epoch 238 of 2000 took 0.102s
  training loss:		1.601854
  validation loss:		1.536285
  validation accuracy:		42.07 %
Epoch 239 of 2000 took 0.099s
  training loss:		1.590877
  validation loss:		1.513286
  validation accuracy:		43.59 %
Epoch 240 of 2000 took 0.103s
  training loss:		1.575691
  validation loss:		1.509116
  validation accuracy:		43.80 %
Epoch 241 of 2000 took 0.099s
  training loss:		1.557832
  validation loss:		1.491598
  validation accuracy:		46.41 %
Epoch 242 of 2000 took 0.100s
  training loss:		1.536166
  validation loss:		1.478530
  validation accuracy:		47.07 %
Epoch 243 of 2000 took 0.102s
  training loss:		1.525371
  validation loss:		1.465646
  validation accuracy:		47.61 %
Epoch 244 of 2000 took 0.101s
  training loss:		1.517437
  validation loss:		1.453718
  validation accuracy:		47.39 %
Epoch 245 of 2000 took 0.103s
  training loss:		1.504127
  validation loss:		1.444118
  validation accuracy:		48.26 %
Epoch 246 of 2000 took 0.099s
  training loss:		1.491275
  validation loss:		1.431781
  validation accuracy:		49.24 %
Epoch 247 of 2000 took 0.100s
  training loss:		1.490464
  validation loss:		1.422387
  validation accuracy:		50.33 %
Epoch 248 of 2000 took 0.101s
  training loss:		1.477666
  validation loss:		1.422190
  validation accuracy:		49.35 %
Epoch 249 of 2000 took 0.099s
  training loss:		1.466084
  validation loss:		1.395759
  validation accuracy:		49.78 %
Epoch 250 of 2000 took 0.102s
  training loss:		1.454820
  validation loss:		1.401308
  validation accuracy:		50.43 %
Epoch 251 of 2000 took 0.099s
  training loss:		1.453381
  validation loss:		1.385145
  validation accuracy:		51.30 %
Epoch 252 of 2000 took 0.102s
  training loss:		1.436429
  validation loss:		1.378811
  validation accuracy:		51.85 %
Epoch 253 of 2000 took 0.100s
  training loss:		1.444156
  validation loss:		1.369799
  validation accuracy:		51.63 %
Epoch 254 of 2000 took 0.099s
  training loss:		1.428620
  validation loss:		1.365043
  validation accuracy:		52.07 %
Epoch 255 of 2000 took 0.102s
  training loss:		1.424280
  validation loss:		1.370972
  validation accuracy:		51.52 %
Epoch 256 of 2000 took 0.099s
  training loss:		1.442432
  validation loss:		1.353841
  validation accuracy:		52.50 %
Epoch 257 of 2000 took 0.103s
  training loss:		1.473640
  validation loss:		1.362833
  validation accuracy:		52.72 %
Epoch 258 of 2000 took 0.099s
  training loss:		1.435414
  validation loss:		1.433756
  validation accuracy:		46.63 %
Epoch 259 of 2000 took 0.100s
  training loss:		1.431692
  validation loss:		1.357476
  validation accuracy:		51.85 %
Epoch 260 of 2000 took 0.102s
  training loss:		1.414619
  validation loss:		1.359292
  validation accuracy:		50.98 %
Epoch 261 of 2000 took 0.099s
  training loss:		1.430094
  validation loss:		1.328910
  validation accuracy:		53.04 %
Epoch 262 of 2000 took 0.103s
  training loss:		1.387925
  validation loss:		1.327430
  validation accuracy:		53.48 %
Epoch 263 of 2000 took 0.099s
  training loss:		1.408610
  validation loss:		1.395622
  validation accuracy:		48.80 %
Epoch 264 of 2000 took 0.101s
  training loss:		1.494554
  validation loss:		1.421376
  validation accuracy:		45.00 %
Epoch 265 of 2000 took 0.100s
  training loss:		1.468505
  validation loss:		1.332468
  validation accuracy:		53.15 %
Epoch 266 of 2000 took 0.099s
  training loss:		1.401511
  validation loss:		1.393840
  validation accuracy:		46.85 %
Epoch 267 of 2000 took 0.105s
  training loss:		1.439374
  validation loss:		1.349907
  validation accuracy:		51.52 %
Epoch 268 of 2000 took 0.099s
  training loss:		1.417904
  validation loss:		1.310121
  validation accuracy:		53.48 %
Epoch 269 of 2000 took 0.100s
  training loss:		1.387550
  validation loss:		1.312571
  validation accuracy:		52.07 %
Epoch 270 of 2000 took 0.099s
  training loss:		1.421773
  validation loss:		1.345766
  validation accuracy:		50.98 %
Epoch 271 of 2000 took 0.101s
  training loss:		1.411054
  validation loss:		1.321635
  validation accuracy:		52.17 %
Epoch 272 of 2000 took 0.103s
  training loss:		1.393482
  validation loss:		1.355726
  validation accuracy:		51.30 %
Epoch 273 of 2000 took 0.099s
  training loss:		1.386140
  validation loss:		1.311018
  validation accuracy:		53.48 %
Epoch 274 of 2000 took 0.100s
  training loss:		1.402515
  validation loss:		1.509252
  validation accuracy:		41.96 %
Epoch 275 of 2000 took 0.104s
  training loss:		1.533494
  validation loss:		1.350932
  validation accuracy:		49.57 %
Epoch 276 of 2000 took 0.099s
  training loss:		1.418712
  validation loss:		1.382191
  validation accuracy:		49.24 %
Epoch 277 of 2000 took 0.100s
  training loss:		1.382959
  validation loss:		1.330963
  validation accuracy:		51.96 %
Epoch 278 of 2000 took 0.099s
  training loss:		1.378093
  validation loss:		1.306176
  validation accuracy:		52.07 %
Epoch 279 of 2000 took 0.103s
  training loss:		1.370281
  validation loss:		1.340918
  validation accuracy:		52.28 %
Epoch 280 of 2000 took 0.101s
  training loss:		1.402099
  validation loss:		1.286217
  validation accuracy:		52.61 %
Epoch 281 of 2000 took 0.099s
  training loss:		1.355583
  validation loss:		1.284517
  validation accuracy:		53.15 %
Epoch 282 of 2000 took 0.104s
  training loss:		1.362101
  validation loss:		1.277648
  validation accuracy:		52.72 %
Epoch 283 of 2000 took 0.101s
  training loss:		1.363520
  validation loss:		1.292953
  validation accuracy:		52.72 %
Epoch 284 of 2000 took 0.099s
  training loss:		1.364849
  validation loss:		1.280682
  validation accuracy:		52.39 %
Epoch 285 of 2000 took 0.099s
  training loss:		1.353136
  validation loss:		1.307619
  validation accuracy:		51.74 %
Epoch 286 of 2000 took 0.099s
  training loss:		1.382011
  validation loss:		1.278065
  validation accuracy:		52.72 %
Epoch 287 of 2000 took 0.104s
  training loss:		1.368380
  validation loss:		1.351215
  validation accuracy:		50.76 %
Epoch 288 of 2000 took 0.100s
  training loss:		1.384897
  validation loss:		1.306658
  validation accuracy:		52.72 %
Epoch 289 of 2000 took 0.099s
  training loss:		1.374611
  validation loss:		1.453929
  validation accuracy:		44.02 %
Epoch 290 of 2000 took 0.105s
  training loss:		1.428914
  validation loss:		1.271886
  validation accuracy:		51.20 %
Epoch 291 of 2000 took 0.099s
  training loss:		1.355754
  validation loss:		1.265921
  validation accuracy:		51.41 %
Epoch 292 of 2000 took 0.100s
  training loss:		1.355169
  validation loss:		1.308192
  validation accuracy:		52.61 %
Epoch 293 of 2000 took 0.099s
  training loss:		1.354306
  validation loss:		1.271150
  validation accuracy:		51.96 %
Epoch 294 of 2000 took 0.100s
  training loss:		1.343699
  validation loss:		1.266307
  validation accuracy:		52.50 %
Epoch 295 of 2000 took 0.103s
  training loss:		1.385769
  validation loss:		1.392604
  validation accuracy:		48.70 %
Epoch 296 of 2000 took 0.099s
  training loss:		1.400159
  validation loss:		1.313430
  validation accuracy:		52.28 %
Epoch 297 of 2000 took 0.100s
  training loss:		1.351292
  validation loss:		1.265084
  validation accuracy:		52.50 %
Epoch 298 of 2000 took 0.105s
  training loss:		1.349027
  validation loss:		1.273294
  validation accuracy:		52.83 %
Epoch 299 of 2000 took 0.099s
  training loss:		1.361874
  validation loss:		1.296616
  validation accuracy:		52.39 %
Epoch 300 of 2000 took 0.100s
  training loss:		1.355481
  validation loss:		1.273412
  validation accuracy:		52.50 %
Epoch 301 of 2000 took 0.099s
  training loss:		1.335410
  validation loss:		1.261748
  validation accuracy:		52.72 %
Epoch 302 of 2000 took 0.099s
  training loss:		1.346184
  validation loss:		1.258254
  validation accuracy:		52.07 %
Epoch 303 of 2000 took 0.099s
  training loss:		1.406281
  validation loss:		1.427514
  validation accuracy:		46.30 %
Epoch 304 of 2000 took 0.096s
  training loss:		1.416223
  validation loss:		1.263552
  validation accuracy:		53.59 %
Epoch 305 of 2000 took 0.097s
  training loss:		1.348287
  validation loss:		1.314126
  validation accuracy:		50.00 %
Epoch 306 of 2000 took 0.101s
  training loss:		1.358856
  validation loss:		1.265227
  validation accuracy:		52.72 %
Epoch 307 of 2000 took 0.096s
  training loss:		1.346159
  validation loss:		1.308032
  validation accuracy:		52.28 %
Epoch 308 of 2000 took 0.097s
  training loss:		1.340430
  validation loss:		1.295595
  validation accuracy:		51.63 %
Epoch 309 of 2000 took 0.096s
  training loss:		1.349282
  validation loss:		1.251204
  validation accuracy:		53.59 %
Epoch 310 of 2000 took 0.101s
  training loss:		1.329782
  validation loss:		1.277106
  validation accuracy:		52.61 %
Epoch 311 of 2000 took 0.098s
  training loss:		1.338241
  validation loss:		1.249472
  validation accuracy:		53.15 %
Epoch 312 of 2000 took 0.096s
  training loss:		1.376269
  validation loss:		1.272058
  validation accuracy:		52.93 %
Epoch 313 of 2000 took 0.101s
  training loss:		1.344682
  validation loss:		1.253045
  validation accuracy:		53.80 %
Epoch 314 of 2000 took 0.098s
  training loss:		1.321482
  validation loss:		1.283544
  validation accuracy:		53.37 %
Epoch 315 of 2000 took 0.096s
  training loss:		1.334032
  validation loss:		1.313096
  validation accuracy:		51.63 %
Epoch 316 of 2000 took 0.096s
  training loss:		1.432662
  validation loss:		1.349506
  validation accuracy:		47.07 %
Epoch 317 of 2000 took 0.096s
  training loss:		1.392883
  validation loss:		1.285754
  validation accuracy:		53.26 %
Epoch 318 of 2000 took 0.100s
  training loss:		1.348105
  validation loss:		1.243174
  validation accuracy:		54.57 %
Epoch 319 of 2000 took 0.097s
  training loss:		1.320108
  validation loss:		1.239395
  validation accuracy:		55.00 %
Epoch 320 of 2000 took 0.096s
  training loss:		1.337629
  validation loss:		1.241082
  validation accuracy:		55.11 %
Epoch 321 of 2000 took 0.102s
  training loss:		1.316828
  validation loss:		1.247375
  validation accuracy:		54.35 %
Epoch 322 of 2000 took 0.096s
  training loss:		1.321629
  validation loss:		1.304122
  validation accuracy:		52.50 %
Epoch 323 of 2000 took 0.097s
  training loss:		1.370104
  validation loss:		1.263263
  validation accuracy:		54.35 %
Epoch 324 of 2000 took 0.096s
  training loss:		1.351385
  validation loss:		1.240997
  validation accuracy:		54.89 %
Epoch 325 of 2000 took 0.097s
  training loss:		1.311170
  validation loss:		1.236274
  validation accuracy:		54.46 %
Epoch 326 of 2000 took 0.100s
  training loss:		1.308793
  validation loss:		1.227520
  validation accuracy:		55.65 %
Epoch 327 of 2000 took 0.096s
  training loss:		1.315219
  validation loss:		1.224966
  validation accuracy:		56.41 %
Epoch 328 of 2000 took 0.097s
  training loss:		1.308144
  validation loss:		1.231880
  validation accuracy:		55.76 %
Epoch 329 of 2000 took 0.102s
  training loss:		1.340469
  validation loss:		1.247304
  validation accuracy:		54.78 %
Epoch 330 of 2000 took 0.096s
  training loss:		1.384285
  validation loss:		1.234378
  validation accuracy:		55.76 %
Epoch 331 of 2000 took 0.097s
  training loss:		1.332623
  validation loss:		1.229150
  validation accuracy:		56.20 %
Epoch 332 of 2000 took 0.096s
  training loss:		1.313419
  validation loss:		1.222561
  validation accuracy:		56.41 %
Epoch 333 of 2000 took 0.098s
  training loss:		1.318161
  validation loss:		1.241456
  validation accuracy:		56.85 %
Epoch 334 of 2000 took 0.099s
  training loss:		1.303316
  validation loss:		1.230577
  validation accuracy:		55.65 %
Epoch 335 of 2000 took 0.096s
  training loss:		1.303769
  validation loss:		1.241916
  validation accuracy:		56.09 %
Epoch 336 of 2000 took 0.098s
  training loss:		1.316466
  validation loss:		1.230872
  validation accuracy:		56.85 %
Epoch 337 of 2000 took 0.101s
  training loss:		1.297244
  validation loss:		1.209891
  validation accuracy:		57.50 %
Epoch 338 of 2000 took 0.096s
  training loss:		1.303189
  validation loss:		1.213917
  validation accuracy:		56.85 %
Epoch 339 of 2000 took 0.097s
  training loss:		1.293366
  validation loss:		1.276174
  validation accuracy:		53.70 %
Epoch 340 of 2000 took 0.096s
  training loss:		1.312139
  validation loss:		1.210774
  validation accuracy:		57.83 %
Epoch 341 of 2000 took 0.101s
  training loss:		1.287294
  validation loss:		1.232338
  validation accuracy:		56.41 %
Epoch 342 of 2000 took 0.098s
  training loss:		1.310123
  validation loss:		1.205856
  validation accuracy:		58.15 %
Epoch 343 of 2000 took 0.096s
  training loss:		1.284158
  validation loss:		1.219738
  validation accuracy:		56.74 %
Epoch 344 of 2000 took 0.101s
  training loss:		1.284969
  validation loss:		1.198037
  validation accuracy:		58.04 %
Epoch 345 of 2000 took 0.098s
  training loss:		1.297680
  validation loss:		1.202437
  validation accuracy:		59.67 %
Epoch 346 of 2000 took 0.096s
  training loss:		1.314594
  validation loss:		1.261098
  validation accuracy:		54.57 %
Epoch 347 of 2000 took 0.096s
  training loss:		1.275514
  validation loss:		1.183292
  validation accuracy:		58.91 %
Epoch 348 of 2000 took 0.096s
  training loss:		1.263971
  validation loss:		1.178831
  validation accuracy:		59.35 %
Epoch 349 of 2000 took 0.101s
  training loss:		1.272593
  validation loss:		1.174845
  validation accuracy:		60.11 %
Epoch 350 of 2000 took 0.097s
  training loss:		1.275301
  validation loss:		1.204819
  validation accuracy:		57.39 %
Epoch 351 of 2000 took 0.096s
  training loss:		1.263293
  validation loss:		1.165282
  validation accuracy:		60.76 %
Epoch 352 of 2000 took 0.102s
  training loss:		1.262098
  validation loss:		1.169420
  validation accuracy:		60.76 %
Epoch 353 of 2000 took 0.096s
  training loss:		1.255351
  validation loss:		1.195920
  validation accuracy:		58.48 %
Epoch 354 of 2000 took 0.097s
  training loss:		1.242480
  validation loss:		1.153394
  validation accuracy:		61.09 %
Epoch 355 of 2000 took 0.096s
  training loss:		1.238907
  validation loss:		1.142748
  validation accuracy:		61.96 %
Epoch 356 of 2000 took 0.097s
  training loss:		1.226527
  validation loss:		1.134075
  validation accuracy:		61.41 %
Epoch 357 of 2000 took 0.100s
  training loss:		1.225129
  validation loss:		1.132684
  validation accuracy:		62.17 %
Epoch 358 of 2000 took 0.096s
  training loss:		1.213459
  validation loss:		1.127862
  validation accuracy:		62.07 %
Epoch 359 of 2000 took 0.097s
  training loss:		1.215307
  validation loss:		1.109087
  validation accuracy:		62.72 %
Epoch 360 of 2000 took 0.102s
  training loss:		1.196726
  validation loss:		1.104007
  validation accuracy:		63.37 %
Epoch 361 of 2000 took 0.096s
  training loss:		1.199355
  validation loss:		1.107692
  validation accuracy:		62.50 %
Epoch 362 of 2000 took 0.097s
  training loss:		1.189894
  validation loss:		1.122711
  validation accuracy:		60.98 %
Epoch 363 of 2000 took 0.096s
  training loss:		1.180182
  validation loss:		1.076740
  validation accuracy:		64.89 %
Epoch 364 of 2000 took 0.098s
  training loss:		1.168622
  validation loss:		1.073184
  validation accuracy:		64.24 %
Epoch 365 of 2000 took 0.099s
  training loss:		1.159024
  validation loss:		1.055950
  validation accuracy:		65.87 %
Epoch 366 of 2000 took 0.096s
  training loss:		1.165945
  validation loss:		1.046216
  validation accuracy:		66.20 %
Epoch 367 of 2000 took 0.098s
  training loss:		1.145423
  validation loss:		1.057899
  validation accuracy:		64.24 %
Epoch 368 of 2000 took 0.101s
  training loss:		1.135425
  validation loss:		1.024673
  validation accuracy:		66.74 %
Epoch 369 of 2000 took 0.096s
  training loss:		1.122463
  validation loss:		1.017908
  validation accuracy:		66.41 %
Epoch 370 of 2000 took 0.097s
  training loss:		1.121987
  validation loss:		1.021511
  validation accuracy:		67.93 %
Epoch 371 of 2000 took 0.096s
  training loss:		1.138441
  validation loss:		1.012058
  validation accuracy:		67.07 %
Epoch 372 of 2000 took 0.101s
  training loss:		1.095616
  validation loss:		0.985077
  validation accuracy:		68.91 %
Epoch 373 of 2000 took 0.097s
  training loss:		1.088766
  validation loss:		0.979223
  validation accuracy:		68.91 %
Epoch 374 of 2000 took 0.096s
  training loss:		1.091748
  validation loss:		0.973912
  validation accuracy:		69.89 %
Epoch 375 of 2000 took 0.101s
  training loss:		1.070980
  validation loss:		0.965258
  validation accuracy:		69.67 %
Epoch 376 of 2000 took 0.098s
  training loss:		1.067777
  validation loss:		0.957188
  validation accuracy:		70.54 %
Epoch 377 of 2000 took 0.096s
  training loss:		1.042038
  validation loss:		0.934311
  validation accuracy:		71.30 %
Epoch 378 of 2000 took 0.097s
  training loss:		1.036701
  validation loss:		0.925978
  validation accuracy:		72.39 %
Epoch 379 of 2000 took 0.096s
  training loss:		1.023210
  validation loss:		0.911883
  validation accuracy:		72.39 %
Epoch 380 of 2000 took 0.100s
  training loss:		1.054324
  validation loss:		0.906338
  validation accuracy:		72.83 %
Epoch 381 of 2000 took 0.097s
  training loss:		1.026387
  validation loss:		0.926770
  validation accuracy:		72.07 %
Epoch 382 of 2000 took 0.096s
  training loss:		0.988681
  validation loss:		0.882496
  validation accuracy:		74.13 %
Epoch 383 of 2000 took 0.102s
  training loss:		0.982248
  validation loss:		0.937709
  validation accuracy:		71.30 %
Epoch 384 of 2000 took 0.096s
  training loss:		1.000101
  validation loss:		0.866377
  validation accuracy:		74.78 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.963154
  validation loss:		0.854104
  validation accuracy:		74.78 %
Epoch 386 of 2000 took 0.096s
  training loss:		0.952595
  validation loss:		0.852571
  validation accuracy:		75.54 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.952455
  validation loss:		0.841765
  validation accuracy:		75.22 %
Epoch 388 of 2000 took 0.100s
  training loss:		0.943280
  validation loss:		0.856243
  validation accuracy:		75.54 %
Epoch 389 of 2000 took 0.096s
  training loss:		0.930123
  validation loss:		0.851028
  validation accuracy:		74.89 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.919615
  validation loss:		0.820716
  validation accuracy:		76.09 %
Epoch 391 of 2000 took 0.102s
  training loss:		0.888653
  validation loss:		0.803185
  validation accuracy:		77.07 %
Epoch 392 of 2000 took 0.096s
  training loss:		0.905589
  validation loss:		0.799504
  validation accuracy:		76.85 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.885429
  validation loss:		0.793111
  validation accuracy:		76.74 %
Epoch 394 of 2000 took 0.098s
  training loss:		0.880930
  validation loss:		0.816246
  validation accuracy:		75.22 %
Epoch 395 of 2000 took 0.099s
  training loss:		0.874085
  validation loss:		0.782878
  validation accuracy:		77.17 %
Epoch 396 of 2000 took 0.099s
  training loss:		0.864783
  validation loss:		0.812197
  validation accuracy:		74.89 %
Epoch 397 of 2000 took 0.096s
  training loss:		0.857456
  validation loss:		0.769058
  validation accuracy:		77.93 %
Epoch 398 of 2000 took 0.098s
  training loss:		0.851517
  validation loss:		0.765318
  validation accuracy:		77.28 %
Epoch 399 of 2000 took 0.101s
  training loss:		0.841169
  validation loss:		0.761283
  validation accuracy:		76.85 %
Epoch 400 of 2000 took 0.096s
  training loss:		0.838867
  validation loss:		0.851906
  validation accuracy:		72.83 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.847063
  validation loss:		0.771757
  validation accuracy:		76.74 %
Epoch 402 of 2000 took 0.096s
  training loss:		0.842243
  validation loss:		0.757725
  validation accuracy:		75.43 %
Epoch 403 of 2000 took 0.101s
  training loss:		0.826896
  validation loss:		0.751175
  validation accuracy:		76.09 %
Epoch 404 of 2000 took 0.098s
  training loss:		0.802613
  validation loss:		0.731985
  validation accuracy:		77.50 %
Epoch 405 of 2000 took 0.096s
  training loss:		0.799219
  validation loss:		0.735454
  validation accuracy:		77.50 %
Epoch 406 of 2000 took 0.100s
  training loss:		0.795695
  validation loss:		0.740955
  validation accuracy:		77.72 %
Epoch 407 of 2000 took 0.098s
  training loss:		0.785090
  validation loss:		0.724074
  validation accuracy:		78.15 %
Epoch 408 of 2000 took 0.096s
  training loss:		0.784337
  validation loss:		0.715605
  validation accuracy:		77.61 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.773890
  validation loss:		0.718398
  validation accuracy:		76.41 %
Epoch 410 of 2000 took 0.096s
  training loss:		0.756953
  validation loss:		0.704935
  validation accuracy:		78.04 %
Epoch 411 of 2000 took 0.101s
  training loss:		0.767231
  validation loss:		0.703736
  validation accuracy:		77.17 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.756511
  validation loss:		0.713426
  validation accuracy:		75.98 %
Epoch 413 of 2000 took 0.096s
  training loss:		0.747382
  validation loss:		0.699358
  validation accuracy:		77.61 %
Epoch 414 of 2000 took 0.102s
  training loss:		0.750767
  validation loss:		0.691039
  validation accuracy:		77.83 %
Epoch 415 of 2000 took 0.096s
  training loss:		0.736643
  validation loss:		0.688213
  validation accuracy:		78.37 %
Epoch 416 of 2000 took 0.097s
  training loss:		0.736425
  validation loss:		0.692692
  validation accuracy:		77.28 %
Epoch 417 of 2000 took 0.096s
  training loss:		0.714686
  validation loss:		0.724314
  validation accuracy:		75.98 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.730078
  validation loss:		0.678123
  validation accuracy:		77.07 %
Epoch 419 of 2000 took 0.100s
  training loss:		0.700748
  validation loss:		0.704932
  validation accuracy:		76.52 %
Epoch 420 of 2000 took 0.096s
  training loss:		0.720623
  validation loss:		0.672008
  validation accuracy:		76.96 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.716756
  validation loss:		0.668332
  validation accuracy:		78.80 %
Epoch 422 of 2000 took 0.102s
  training loss:		0.712315
  validation loss:		0.694913
  validation accuracy:		77.28 %
Epoch 423 of 2000 took 0.096s
  training loss:		0.711274
  validation loss:		0.660225
  validation accuracy:		78.80 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.699306
  validation loss:		0.676535
  validation accuracy:		76.52 %
Epoch 425 of 2000 took 0.096s
  training loss:		0.693906
  validation loss:		0.664333
  validation accuracy:		76.41 %
Epoch 426 of 2000 took 0.098s
  training loss:		0.675752
  validation loss:		0.686023
  validation accuracy:		76.96 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.674686
  validation loss:		0.672748
  validation accuracy:		76.41 %
Epoch 428 of 2000 took 0.096s
  training loss:		0.668191
  validation loss:		0.663807
  validation accuracy:		76.41 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.661498
  validation loss:		0.638680
  validation accuracy:		79.57 %
Epoch 430 of 2000 took 0.102s
  training loss:		0.658005
  validation loss:		0.676855
  validation accuracy:		77.50 %
Epoch 431 of 2000 took 0.096s
  training loss:		0.665072
  validation loss:		0.658804
  validation accuracy:		77.07 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.671976
  validation loss:		0.712024
  validation accuracy:		75.65 %
Epoch 433 of 2000 took 0.096s
  training loss:		0.661708
  validation loss:		0.622755
  validation accuracy:		79.78 %
Epoch 434 of 2000 took 0.100s
  training loss:		0.642365
  validation loss:		0.649044
  validation accuracy:		78.37 %
Epoch 435 of 2000 took 0.098s
  training loss:		0.637831
  validation loss:		0.613469
  validation accuracy:		80.76 %
Epoch 436 of 2000 took 0.096s
  training loss:		0.660467
  validation loss:		0.640781
  validation accuracy:		78.48 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.642285
  validation loss:		0.621893
  validation accuracy:		79.78 %
Epoch 438 of 2000 took 0.098s
  training loss:		0.653239
  validation loss:		0.609816
  validation accuracy:		80.43 %
Epoch 439 of 2000 took 0.096s
  training loss:		0.623205
  validation loss:		0.614294
  validation accuracy:		80.43 %
Epoch 440 of 2000 took 0.096s
  training loss:		0.621133
  validation loss:		0.649416
  validation accuracy:		77.61 %
Epoch 441 of 2000 took 0.096s
  training loss:		0.623181
  validation loss:		0.625410
  validation accuracy:		79.46 %
Epoch 442 of 2000 took 0.101s
  training loss:		0.625366
  validation loss:		0.602838
  validation accuracy:		80.76 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.611568
  validation loss:		0.597090
  validation accuracy:		80.43 %
Epoch 444 of 2000 took 0.096s
  training loss:		0.623683
  validation loss:		0.601642
  validation accuracy:		80.65 %
Epoch 445 of 2000 took 0.102s
  training loss:		0.604715
  validation loss:		0.589470
  validation accuracy:		80.98 %
Epoch 446 of 2000 took 0.096s
  training loss:		0.611146
  validation loss:		0.632283
  validation accuracy:		79.46 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.637045
  validation loss:		0.637024
  validation accuracy:		78.59 %
Epoch 448 of 2000 took 0.096s
  training loss:		0.621026
  validation loss:		0.614687
  validation accuracy:		80.00 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.599095
  validation loss:		0.585175
  validation accuracy:		80.87 %
Epoch 450 of 2000 took 0.100s
  training loss:		0.620017
  validation loss:		0.579799
  validation accuracy:		80.87 %
Epoch 451 of 2000 took 0.096s
  training loss:		0.586533
  validation loss:		0.591612
  validation accuracy:		81.09 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.606064
  validation loss:		0.606564
  validation accuracy:		80.33 %
Epoch 453 of 2000 took 0.102s
  training loss:		0.588374
  validation loss:		0.584270
  validation accuracy:		80.87 %
Epoch 454 of 2000 took 0.096s
  training loss:		0.605320
  validation loss:		0.575735
  validation accuracy:		81.20 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.593535
  validation loss:		0.613852
  validation accuracy:		79.24 %
Epoch 456 of 2000 took 0.096s
  training loss:		0.576058
  validation loss:		0.625088
  validation accuracy:		78.26 %
Epoch 457 of 2000 took 0.098s
  training loss:		0.581364
  validation loss:		0.569674
  validation accuracy:		81.20 %
Epoch 458 of 2000 took 0.100s
  training loss:		0.572420
  validation loss:		0.605957
  validation accuracy:		80.11 %
Epoch 459 of 2000 took 0.096s
  training loss:		0.598581
  validation loss:		0.622585
  validation accuracy:		78.91 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.596926
  validation loss:		0.626018
  validation accuracy:		78.48 %
Epoch 461 of 2000 took 0.101s
  training loss:		0.584317
  validation loss:		0.564857
  validation accuracy:		81.74 %
Epoch 462 of 2000 took 0.096s
  training loss:		0.565766
  validation loss:		0.568210
  validation accuracy:		81.20 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.573997
  validation loss:		0.623999
  validation accuracy:		77.93 %
Epoch 464 of 2000 took 0.096s
  training loss:		0.593563
  validation loss:		0.589690
  validation accuracy:		80.22 %
Epoch 465 of 2000 took 0.101s
  training loss:		0.566126
  validation loss:		0.579803
  validation accuracy:		80.11 %
Epoch 466 of 2000 took 0.098s
  training loss:		0.568236
  validation loss:		0.576033
  validation accuracy:		81.63 %
Epoch 467 of 2000 took 0.096s
  training loss:		0.559400
  validation loss:		0.564428
  validation accuracy:		81.30 %
Epoch 468 of 2000 took 0.100s
  training loss:		0.558391
  validation loss:		0.558906
  validation accuracy:		81.74 %
Epoch 469 of 2000 took 0.098s
  training loss:		0.576407
  validation loss:		0.565675
  validation accuracy:		81.63 %
Epoch 470 of 2000 took 0.096s
  training loss:		0.560652
  validation loss:		0.563139
  validation accuracy:		81.30 %
Epoch 471 of 2000 took 0.096s
  training loss:		0.568821
  validation loss:		0.571487
  validation accuracy:		80.98 %
Epoch 472 of 2000 took 0.096s
  training loss:		0.581079
  validation loss:		0.562591
  validation accuracy:		81.41 %
Epoch 473 of 2000 took 0.100s
  training loss:		0.567270
  validation loss:		0.559398
  validation accuracy:		81.63 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.551726
  validation loss:		0.552527
  validation accuracy:		82.17 %
Epoch 475 of 2000 took 0.096s
  training loss:		0.541022
  validation loss:		0.586544
  validation accuracy:		80.65 %
Epoch 476 of 2000 took 0.102s
  training loss:		0.548593
  validation loss:		0.574480
  validation accuracy:		80.76 %
Epoch 477 of 2000 took 0.096s
  training loss:		0.537071
  validation loss:		0.548675
  validation accuracy:		81.74 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.558531
  validation loss:		0.616526
  validation accuracy:		78.70 %
Epoch 479 of 2000 took 0.096s
  training loss:		0.544342
  validation loss:		0.552813
  validation accuracy:		82.83 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.557239
  validation loss:		0.577551
  validation accuracy:		81.30 %
Epoch 481 of 2000 took 0.100s
  training loss:		0.543444
  validation loss:		0.573271
  validation accuracy:		80.65 %
Epoch 482 of 2000 took 0.096s
  training loss:		0.543130
  validation loss:		0.561853
  validation accuracy:		81.30 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.534780
  validation loss:		0.592230
  validation accuracy:		80.54 %
Epoch 484 of 2000 took 0.102s
  training loss:		0.547030
  validation loss:		0.538377
  validation accuracy:		82.17 %
Epoch 485 of 2000 took 0.096s
  training loss:		0.543309
  validation loss:		0.572981
  validation accuracy:		81.20 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.530623
  validation loss:		0.572592
  validation accuracy:		81.20 %
Epoch 487 of 2000 took 0.096s
  training loss:		0.546372
  validation loss:		0.544961
  validation accuracy:		82.39 %
Epoch 488 of 2000 took 0.098s
  training loss:		0.543118
  validation loss:		0.614629
  validation accuracy:		80.54 %
Epoch 489 of 2000 took 0.099s
  training loss:		0.667330
  validation loss:		0.601045
  validation accuracy:		79.46 %
Epoch 490 of 2000 took 0.096s
  training loss:		0.550530
  validation loss:		0.549808
  validation accuracy:		82.72 %
Epoch 491 of 2000 took 0.098s
  training loss:		0.546017
  validation loss:		0.550242
  validation accuracy:		81.63 %
Epoch 492 of 2000 took 0.101s
  training loss:		0.552031
  validation loss:		0.585200
  validation accuracy:		81.09 %
Epoch 493 of 2000 took 0.096s
  training loss:		0.535490
  validation loss:		0.534875
  validation accuracy:		82.17 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.540382
  validation loss:		0.593708
  validation accuracy:		80.54 %
Epoch 495 of 2000 took 0.096s
  training loss:		0.537415
  validation loss:		0.541331
  validation accuracy:		82.61 %
Epoch 496 of 2000 took 0.101s
  training loss:		0.530182
  validation loss:		0.559556
  validation accuracy:		81.41 %
Epoch 497 of 2000 took 0.098s
  training loss:		0.533682
  validation loss:		0.587104
  validation accuracy:		79.78 %
Epoch 498 of 2000 took 0.096s
  training loss:		0.565071
  validation loss:		0.533417
  validation accuracy:		82.17 %
Epoch 499 of 2000 took 0.101s
  training loss:		0.528960
  validation loss:		0.536519
  validation accuracy:		83.04 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.560968
  validation loss:		0.528311
  validation accuracy:		82.50 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.537551
  validation loss:		0.532077
  validation accuracy:		82.72 %
Epoch 502 of 2000 took 0.096s
  training loss:		0.519853
  validation loss:		0.530358
  validation accuracy:		82.50 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.530452
  validation loss:		0.560049
  validation accuracy:		81.20 %
Epoch 504 of 2000 took 0.101s
  training loss:		0.530308
  validation loss:		0.523127
  validation accuracy:		82.83 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.544594
  validation loss:		0.523220
  validation accuracy:		82.39 %
Epoch 506 of 2000 took 0.096s
  training loss:		0.522102
  validation loss:		0.541961
  validation accuracy:		82.17 %
Epoch 507 of 2000 took 0.103s
  training loss:		0.526770
  validation loss:		0.528470
  validation accuracy:		82.83 %
Epoch 508 of 2000 took 0.096s
  training loss:		0.526726
  validation loss:		0.537423
  validation accuracy:		82.07 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.532486
  validation loss:		0.524655
  validation accuracy:		82.28 %
Epoch 510 of 2000 took 0.096s
  training loss:		0.518391
  validation loss:		0.573339
  validation accuracy:		80.22 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.526110
  validation loss:		0.549921
  validation accuracy:		82.28 %
Epoch 512 of 2000 took 0.101s
  training loss:		0.517192
  validation loss:		0.580862
  validation accuracy:		80.43 %
Epoch 513 of 2000 took 0.096s
  training loss:		0.536607
  validation loss:		0.546176
  validation accuracy:		82.07 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.513586
  validation loss:		0.515903
  validation accuracy:		83.37 %
Epoch 515 of 2000 took 0.102s
  training loss:		0.519810
  validation loss:		0.541786
  validation accuracy:		82.07 %
Epoch 516 of 2000 took 0.096s
  training loss:		0.519720
  validation loss:		0.556794
  validation accuracy:		80.98 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.507429
  validation loss:		0.524058
  validation accuracy:		82.39 %
Epoch 518 of 2000 took 0.096s
  training loss:		0.511142
  validation loss:		0.572763
  validation accuracy:		80.22 %
Epoch 519 of 2000 took 0.099s
  training loss:		0.517602
  validation loss:		0.516219
  validation accuracy:		83.26 %
Epoch 520 of 2000 took 0.099s
  training loss:		0.507582
  validation loss:		0.520443
  validation accuracy:		82.93 %
Epoch 521 of 2000 took 0.096s
  training loss:		0.514793
  validation loss:		0.528288
  validation accuracy:		83.26 %
Epoch 522 of 2000 took 0.098s
  training loss:		0.531299
  validation loss:		0.515224
  validation accuracy:		83.15 %
Epoch 523 of 2000 took 0.100s
  training loss:		0.504432
  validation loss:		0.524509
  validation accuracy:		82.50 %
Epoch 524 of 2000 took 0.096s
  training loss:		0.502809
  validation loss:		0.531622
  validation accuracy:		82.07 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.498292
  validation loss:		0.512019
  validation accuracy:		83.70 %
Epoch 526 of 2000 took 0.096s
  training loss:		0.500197
  validation loss:		0.546092
  validation accuracy:		81.41 %
Epoch 527 of 2000 took 0.101s
  training loss:		0.494622
  validation loss:		0.508670
  validation accuracy:		83.59 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.500769
  validation loss:		0.537603
  validation accuracy:		81.85 %
Epoch 529 of 2000 took 0.096s
  training loss:		0.499055
  validation loss:		0.520492
  validation accuracy:		82.28 %
Epoch 530 of 2000 took 0.101s
  training loss:		0.506940
  validation loss:		0.508146
  validation accuracy:		83.26 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.497920
  validation loss:		0.500461
  validation accuracy:		83.91 %
Epoch 532 of 2000 took 0.096s
  training loss:		0.502173
  validation loss:		0.514102
  validation accuracy:		83.04 %
Epoch 533 of 2000 took 0.096s
  training loss:		0.483533
  validation loss:		0.507591
  validation accuracy:		83.59 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.513400
  validation loss:		0.600515
  validation accuracy:		79.57 %
Epoch 535 of 2000 took 0.100s
  training loss:		0.504888
  validation loss:		0.503252
  validation accuracy:		83.70 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.489810
  validation loss:		0.515433
  validation accuracy:		82.83 %
Epoch 537 of 2000 took 0.096s
  training loss:		0.502122
  validation loss:		0.525487
  validation accuracy:		82.83 %
Epoch 538 of 2000 took 0.102s
  training loss:		0.479014
  validation loss:		0.500959
  validation accuracy:		83.26 %
Epoch 539 of 2000 took 0.096s
  training loss:		0.490639
  validation loss:		0.496488
  validation accuracy:		84.02 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.476884
  validation loss:		0.496076
  validation accuracy:		84.24 %
Epoch 541 of 2000 took 0.096s
  training loss:		0.522852
  validation loss:		0.702236
  validation accuracy:		76.20 %
Epoch 542 of 2000 took 0.098s
  training loss:		0.520611
  validation loss:		0.491474
  validation accuracy:		83.80 %
Epoch 543 of 2000 took 0.100s
  training loss:		0.492082
  validation loss:		0.510706
  validation accuracy:		82.83 %
Epoch 544 of 2000 took 0.096s
  training loss:		0.470198
  validation loss:		0.502395
  validation accuracy:		82.93 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.474780
  validation loss:		0.495973
  validation accuracy:		83.48 %
Epoch 546 of 2000 took 0.102s
  training loss:		0.476458
  validation loss:		0.488785
  validation accuracy:		84.24 %
Epoch 547 of 2000 took 0.096s
  training loss:		0.477229
  validation loss:		0.515272
  validation accuracy:		83.37 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.475424
  validation loss:		0.497847
  validation accuracy:		83.48 %
Epoch 549 of 2000 took 0.096s
  training loss:		0.490229
  validation loss:		0.506087
  validation accuracy:		82.83 %
Epoch 550 of 2000 took 0.100s
  training loss:		0.489366
  validation loss:		0.501733
  validation accuracy:		84.13 %
Epoch 551 of 2000 took 0.098s
  training loss:		0.479527
  validation loss:		0.481867
  validation accuracy:		83.91 %
Epoch 552 of 2000 took 0.096s
  training loss:		0.469704
  validation loss:		0.518337
  validation accuracy:		82.39 %
Epoch 553 of 2000 took 0.100s
  training loss:		0.489197
  validation loss:		0.482831
  validation accuracy:		84.24 %
Epoch 554 of 2000 took 0.099s
  training loss:		0.464138
  validation loss:		0.497308
  validation accuracy:		82.93 %
Epoch 555 of 2000 took 0.096s
  training loss:		0.469035
  validation loss:		0.503403
  validation accuracy:		82.93 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.469947
  validation loss:		0.489924
  validation accuracy:		83.70 %
Epoch 557 of 2000 took 0.096s
  training loss:		0.460378
  validation loss:		0.496695
  validation accuracy:		83.15 %
Epoch 558 of 2000 took 0.101s
  training loss:		0.467790
  validation loss:		0.476571
  validation accuracy:		84.46 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.462650
  validation loss:		0.493528
  validation accuracy:		83.26 %
Epoch 560 of 2000 took 0.096s
  training loss:		0.458579
  validation loss:		0.469736
  validation accuracy:		84.57 %
Epoch 561 of 2000 took 0.102s
  training loss:		0.462682
  validation loss:		0.473910
  validation accuracy:		84.78 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.451782
  validation loss:		0.477106
  validation accuracy:		84.57 %
Epoch 563 of 2000 took 0.096s
  training loss:		0.452411
  validation loss:		0.475484
  validation accuracy:		84.46 %
Epoch 564 of 2000 took 0.096s
  training loss:		0.459371
  validation loss:		0.487512
  validation accuracy:		83.70 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.449566
  validation loss:		0.488069
  validation accuracy:		83.37 %
Epoch 566 of 2000 took 0.100s
  training loss:		0.455211
  validation loss:		0.462148
  validation accuracy:		85.11 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.448863
  validation loss:		0.477779
  validation accuracy:		83.70 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.458711
  validation loss:		0.508926
  validation accuracy:		82.83 %
Epoch 569 of 2000 took 0.102s
  training loss:		0.465256
  validation loss:		0.466751
  validation accuracy:		85.11 %
Epoch 570 of 2000 took 0.096s
  training loss:		0.439257
  validation loss:		0.475109
  validation accuracy:		84.24 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.453822
  validation loss:		0.460563
  validation accuracy:		85.65 %
Epoch 572 of 2000 took 0.096s
  training loss:		0.442589
  validation loss:		0.480684
  validation accuracy:		84.35 %
Epoch 573 of 2000 took 0.098s
  training loss:		0.443025
  validation loss:		0.467889
  validation accuracy:		84.02 %
Epoch 574 of 2000 took 0.100s
  training loss:		0.453024
  validation loss:		0.461884
  validation accuracy:		84.24 %
Epoch 575 of 2000 took 0.096s
  training loss:		0.452182
  validation loss:		0.468753
  validation accuracy:		84.89 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.437842
  validation loss:		0.458072
  validation accuracy:		84.35 %
Epoch 577 of 2000 took 0.102s
  training loss:		0.429685
  validation loss:		0.471585
  validation accuracy:		84.13 %
Epoch 578 of 2000 took 0.096s
  training loss:		0.437191
  validation loss:		0.465309
  validation accuracy:		84.35 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.440250
  validation loss:		0.507723
  validation accuracy:		83.26 %
Epoch 580 of 2000 took 0.096s
  training loss:		0.458448
  validation loss:		0.458578
  validation accuracy:		85.54 %
Epoch 581 of 2000 took 0.099s
  training loss:		0.436375
  validation loss:		0.459394
  validation accuracy:		85.43 %
Epoch 582 of 2000 took 0.098s
  training loss:		0.444256
  validation loss:		0.464473
  validation accuracy:		85.11 %
Epoch 583 of 2000 took 0.096s
  training loss:		0.432485
  validation loss:		0.453901
  validation accuracy:		84.67 %
Epoch 584 of 2000 took 0.099s
  training loss:		0.432925
  validation loss:		0.453411
  validation accuracy:		85.76 %
Epoch 585 of 2000 took 0.100s
  training loss:		0.435962
  validation loss:		0.506868
  validation accuracy:		83.37 %
Epoch 586 of 2000 took 0.096s
  training loss:		0.425065
  validation loss:		0.472515
  validation accuracy:		84.46 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.439330
  validation loss:		0.449380
  validation accuracy:		84.67 %
Epoch 588 of 2000 took 0.096s
  training loss:		0.430562
  validation loss:		0.451805
  validation accuracy:		85.33 %
Epoch 589 of 2000 took 0.101s
  training loss:		0.428761
  validation loss:		0.504365
  validation accuracy:		83.59 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.436335
  validation loss:		0.456191
  validation accuracy:		84.89 %
Epoch 591 of 2000 took 0.096s
  training loss:		0.417004
  validation loss:		0.444468
  validation accuracy:		85.43 %
Epoch 592 of 2000 took 0.101s
  training loss:		0.423946
  validation loss:		0.453996
  validation accuracy:		85.65 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.429054
  validation loss:		0.477656
  validation accuracy:		84.35 %
Epoch 594 of 2000 took 0.096s
  training loss:		0.421527
  validation loss:		0.449735
  validation accuracy:		85.33 %
Epoch 595 of 2000 took 0.096s
  training loss:		0.415389
  validation loss:		0.456528
  validation accuracy:		85.11 %
Epoch 596 of 2000 took 0.096s
  training loss:		0.425148
  validation loss:		0.446584
  validation accuracy:		85.54 %
Epoch 597 of 2000 took 0.100s
  training loss:		0.427942
  validation loss:		0.467261
  validation accuracy:		84.67 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.412680
  validation loss:		0.446259
  validation accuracy:		85.87 %
Epoch 599 of 2000 took 0.096s
  training loss:		0.410160
  validation loss:		0.459240
  validation accuracy:		85.33 %
Epoch 600 of 2000 took 0.102s
  training loss:		0.421358
  validation loss:		0.490918
  validation accuracy:		83.91 %
Epoch 601 of 2000 took 0.096s
  training loss:		0.419997
  validation loss:		0.440392
  validation accuracy:		85.87 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.415532
  validation loss:		0.442022
  validation accuracy:		85.87 %
Epoch 603 of 2000 took 0.096s
  training loss:		0.418078
  validation loss:		0.451464
  validation accuracy:		85.54 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.416985
  validation loss:		0.442067
  validation accuracy:		86.30 %
Epoch 605 of 2000 took 0.100s
  training loss:		0.414145
  validation loss:		0.441891
  validation accuracy:		85.76 %
Epoch 606 of 2000 took 0.096s
  training loss:		0.410900
  validation loss:		0.442926
  validation accuracy:		85.76 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.413485
  validation loss:		0.439522
  validation accuracy:		86.30 %
Epoch 608 of 2000 took 0.102s
  training loss:		0.419424
  validation loss:		0.442724
  validation accuracy:		85.43 %
Epoch 609 of 2000 took 0.096s
  training loss:		0.408105
  validation loss:		0.437385
  validation accuracy:		86.63 %
Epoch 610 of 2000 took 0.097s
  training loss:		0.419523
  validation loss:		0.443379
  validation accuracy:		85.54 %
Epoch 611 of 2000 took 0.096s
  training loss:		0.405896
  validation loss:		0.434401
  validation accuracy:		86.96 %
Epoch 612 of 2000 took 0.100s
  training loss:		0.406242
  validation loss:		0.435124
  validation accuracy:		86.30 %
Epoch 613 of 2000 took 0.098s
  training loss:		0.408047
  validation loss:		0.443288
  validation accuracy:		86.52 %
Epoch 614 of 2000 took 0.096s
  training loss:		0.411290
  validation loss:		0.457949
  validation accuracy:		85.33 %
Epoch 615 of 2000 took 0.099s
  training loss:		0.405094
  validation loss:		0.444364
  validation accuracy:		85.87 %
Epoch 616 of 2000 took 0.099s
  training loss:		0.400836
  validation loss:		0.432813
  validation accuracy:		86.85 %
Epoch 617 of 2000 took 0.096s
  training loss:		0.406794
  validation loss:		0.452330
  validation accuracy:		85.65 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.396804
  validation loss:		0.440078
  validation accuracy:		85.76 %
Epoch 619 of 2000 took 0.096s
  training loss:		0.407506
  validation loss:		0.446483
  validation accuracy:		85.54 %
Epoch 620 of 2000 took 0.101s
  training loss:		0.403690
  validation loss:		0.474459
  validation accuracy:		84.67 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.401747
  validation loss:		0.425779
  validation accuracy:		86.96 %
Epoch 622 of 2000 took 0.096s
  training loss:		0.405799
  validation loss:		0.425696
  validation accuracy:		86.85 %
Epoch 623 of 2000 took 0.102s
  training loss:		0.400236
  validation loss:		0.443181
  validation accuracy:		86.20 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.402561
  validation loss:		0.443966
  validation accuracy:		85.54 %
Epoch 625 of 2000 took 0.096s
  training loss:		0.400653
  validation loss:		0.449139
  validation accuracy:		84.78 %
Epoch 626 of 2000 took 0.096s
  training loss:		0.402905
  validation loss:		0.442805
  validation accuracy:		86.20 %
Epoch 627 of 2000 took 0.097s
  training loss:		0.395331
  validation loss:		0.446258
  validation accuracy:		85.87 %
Epoch 628 of 2000 took 0.100s
  training loss:		0.402018
  validation loss:		0.470192
  validation accuracy:		85.00 %
Epoch 629 of 2000 took 0.097s
  training loss:		0.395372
  validation loss:		0.458492
  validation accuracy:		85.54 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.388692
  validation loss:		0.440093
  validation accuracy:		86.30 %
Epoch 631 of 2000 took 0.102s
  training loss:		0.398432
  validation loss:		0.440306
  validation accuracy:		87.07 %
Epoch 632 of 2000 took 0.096s
  training loss:		0.402592
  validation loss:		0.428105
  validation accuracy:		87.07 %
Epoch 633 of 2000 took 0.097s
  training loss:		0.400161
  validation loss:		0.431317
  validation accuracy:		86.85 %
Epoch 634 of 2000 took 0.096s
  training loss:		0.401915
  validation loss:		0.459548
  validation accuracy:		85.00 %
Epoch 635 of 2000 took 0.098s
  training loss:		0.397576
  validation loss:		0.430797
  validation accuracy:		86.09 %
Epoch 636 of 2000 took 0.100s
  training loss:		0.398866
  validation loss:		0.438755
  validation accuracy:		85.87 %
Epoch 637 of 2000 took 0.096s
  training loss:		0.390425
  validation loss:		0.432039
  validation accuracy:		86.41 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.394146
  validation loss:		0.424704
  validation accuracy:		87.07 %
Epoch 639 of 2000 took 0.098s
  training loss:		0.382415
  validation loss:		0.427717
  validation accuracy:		86.52 %
Epoch 640 of 2000 took 0.096s
  training loss:		0.388289
  validation loss:		0.433179
  validation accuracy:		86.30 %
Epoch 641 of 2000 took 0.099s
  training loss:		0.387709
  validation loss:		0.427632
  validation accuracy:		86.63 %
Epoch 642 of 2000 took 0.096s
  training loss:		0.396802
  validation loss:		0.455565
  validation accuracy:		85.22 %
Epoch 643 of 2000 took 0.099s
  training loss:		0.395304
  validation loss:		0.448993
  validation accuracy:		85.65 %
Epoch 644 of 2000 took 0.096s
  training loss:		0.386703
  validation loss:		0.432505
  validation accuracy:		85.98 %
Epoch 645 of 2000 took 0.096s
  training loss:		0.388201
  validation loss:		0.427513
  validation accuracy:		86.85 %
Epoch 646 of 2000 took 0.099s
  training loss:		0.382612
  validation loss:		0.421109
  validation accuracy:		87.07 %
Epoch 647 of 2000 took 0.096s
  training loss:		0.373264
  validation loss:		0.424640
  validation accuracy:		87.17 %
Epoch 648 of 2000 took 0.100s
  training loss:		0.398461
  validation loss:		0.458896
  validation accuracy:		85.43 %
Epoch 649 of 2000 took 0.096s
  training loss:		0.399455
  validation loss:		0.464191
  validation accuracy:		85.00 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.382117
  validation loss:		0.437458
  validation accuracy:		85.65 %
Epoch 651 of 2000 took 0.099s
  training loss:		0.383552
  validation loss:		0.433667
  validation accuracy:		86.74 %
Epoch 652 of 2000 took 0.096s
  training loss:		0.374232
  validation loss:		0.437633
  validation accuracy:		86.85 %
Epoch 653 of 2000 took 0.100s
  training loss:		0.382221
  validation loss:		0.424140
  validation accuracy:		87.17 %
Epoch 654 of 2000 took 0.096s
  training loss:		0.377521
  validation loss:		0.423451
  validation accuracy:		86.85 %
Epoch 655 of 2000 took 0.098s
  training loss:		0.379452
  validation loss:		0.450968
  validation accuracy:		84.67 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.374107
  validation loss:		0.423536
  validation accuracy:		86.74 %
Epoch 657 of 2000 took 0.096s
  training loss:		0.388810
  validation loss:		0.429313
  validation accuracy:		86.20 %
Epoch 658 of 2000 took 0.099s
  training loss:		0.378972
  validation loss:		0.424662
  validation accuracy:		86.63 %
Epoch 659 of 2000 took 0.096s
  training loss:		0.374461
  validation loss:		0.429825
  validation accuracy:		86.96 %
Epoch 660 of 2000 took 0.099s
  training loss:		0.371684
  validation loss:		0.422041
  validation accuracy:		86.63 %
Epoch 661 of 2000 took 0.096s
  training loss:		0.382262
  validation loss:		0.424497
  validation accuracy:		87.28 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.369497
  validation loss:		0.427358
  validation accuracy:		87.39 %
Epoch 663 of 2000 took 0.099s
  training loss:		0.383641
  validation loss:		0.433961
  validation accuracy:		86.52 %
Epoch 664 of 2000 took 0.096s
  training loss:		0.377684
  validation loss:		0.427204
  validation accuracy:		87.07 %
Epoch 665 of 2000 took 0.100s
  training loss:		0.379952
  validation loss:		0.421441
  validation accuracy:		86.74 %
Epoch 666 of 2000 took 0.096s
  training loss:		0.372901
  validation loss:		0.438398
  validation accuracy:		85.65 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.369450
  validation loss:		0.455883
  validation accuracy:		85.00 %
Epoch 668 of 2000 took 0.102s
  training loss:		0.376373
  validation loss:		0.431126
  validation accuracy:		86.30 %
Epoch 669 of 2000 took 0.096s
  training loss:		0.375864
  validation loss:		0.433574
  validation accuracy:		86.74 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.374156
  validation loss:		0.425827
  validation accuracy:		87.28 %
Epoch 671 of 2000 took 0.096s
  training loss:		0.375156
  validation loss:		0.430922
  validation accuracy:		86.85 %
Epoch 672 of 2000 took 0.101s
  training loss:		0.366265
  validation loss:		0.451585
  validation accuracy:		85.54 %
Epoch 673 of 2000 took 0.098s
  training loss:		0.373518
  validation loss:		0.416285
  validation accuracy:		87.83 %
Epoch 674 of 2000 took 0.096s
  training loss:		0.374650
  validation loss:		0.453916
  validation accuracy:		85.54 %
Epoch 675 of 2000 took 0.100s
  training loss:		0.372222
  validation loss:		0.415816
  validation accuracy:		87.83 %
Epoch 676 of 2000 took 0.098s
  training loss:		0.366904
  validation loss:		0.421150
  validation accuracy:		87.61 %
Epoch 677 of 2000 took 0.096s
  training loss:		0.374333
  validation loss:		0.424016
  validation accuracy:		86.30 %
Epoch 678 of 2000 took 0.096s
  training loss:		0.360842
  validation loss:		0.422586
  validation accuracy:		86.52 %
Epoch 679 of 2000 took 0.096s
  training loss:		0.371059
  validation loss:		0.431649
  validation accuracy:		86.52 %
Epoch 680 of 2000 took 0.100s
  training loss:		0.367300
  validation loss:		0.429465
  validation accuracy:		86.41 %
Epoch 681 of 2000 took 0.097s
  training loss:		0.361909
  validation loss:		0.419043
  validation accuracy:		87.61 %
Epoch 682 of 2000 took 0.096s
  training loss:		0.372420
  validation loss:		0.414131
  validation accuracy:		87.72 %
Epoch 683 of 2000 took 0.102s
  training loss:		0.359982
  validation loss:		0.430935
  validation accuracy:		86.96 %
Epoch 684 of 2000 took 0.096s
  training loss:		0.367739
  validation loss:		0.424699
  validation accuracy:		86.74 %
Epoch 685 of 2000 took 0.097s
  training loss:		0.365643
  validation loss:		0.405799
  validation accuracy:		88.04 %
Epoch 686 of 2000 took 0.096s
  training loss:		0.363562
  validation loss:		0.416696
  validation accuracy:		87.72 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.363015
  validation loss:		0.427762
  validation accuracy:		86.74 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.361224
  validation loss:		0.431945
  validation accuracy:		86.41 %
Epoch 689 of 2000 took 0.096s
  training loss:		0.362268
  validation loss:		0.421562
  validation accuracy:		86.41 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.367774
  validation loss:		0.412258
  validation accuracy:		87.39 %
Epoch 691 of 2000 took 0.102s
  training loss:		0.358900
  validation loss:		0.426347
  validation accuracy:		86.52 %
Epoch 692 of 2000 took 0.096s
  training loss:		0.358360
  validation loss:		0.442227
  validation accuracy:		85.76 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.356893
  validation loss:		0.421349
  validation accuracy:		87.50 %
Epoch 694 of 2000 took 0.096s
  training loss:		0.356330
  validation loss:		0.413854
  validation accuracy:		87.17 %
Epoch 695 of 2000 took 0.098s
  training loss:		0.358777
  validation loss:		0.417689
  validation accuracy:		87.50 %
Epoch 696 of 2000 took 0.099s
  training loss:		0.358369
  validation loss:		0.425400
  validation accuracy:		86.74 %
Epoch 697 of 2000 took 0.096s
  training loss:		0.365641
  validation loss:		0.457629
  validation accuracy:		85.65 %
Epoch 698 of 2000 took 0.098s
  training loss:		0.358540
  validation loss:		0.423250
  validation accuracy:		86.63 %
Epoch 699 of 2000 took 0.101s
  training loss:		0.356955
  validation loss:		0.408061
  validation accuracy:		88.04 %
Epoch 700 of 2000 took 0.096s
  training loss:		0.356946
  validation loss:		0.410887
  validation accuracy:		87.28 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.355620
  validation loss:		0.416117
  validation accuracy:		86.96 %
Epoch 702 of 2000 took 0.096s
  training loss:		0.360400
  validation loss:		0.419789
  validation accuracy:		86.85 %
Epoch 703 of 2000 took 0.100s
  training loss:		0.356065
  validation loss:		0.439176
  validation accuracy:		86.30 %
Epoch 704 of 2000 took 0.098s
  training loss:		0.358098
  validation loss:		0.411143
  validation accuracy:		86.96 %
Epoch 705 of 2000 took 0.096s
  training loss:		0.363282
  validation loss:		0.412274
  validation accuracy:		87.61 %
Epoch 706 of 2000 took 0.100s
  training loss:		0.349456
  validation loss:		0.438574
  validation accuracy:		85.98 %
Epoch 707 of 2000 took 0.098s
  training loss:		0.359754
  validation loss:		0.420635
  validation accuracy:		86.85 %
Epoch 708 of 2000 took 0.096s
  training loss:		0.357638
  validation loss:		0.404905
  validation accuracy:		88.04 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.346983
  validation loss:		0.417300
  validation accuracy:		86.74 %
Epoch 710 of 2000 took 0.096s
  training loss:		0.355720
  validation loss:		0.405528
  validation accuracy:		88.26 %
Epoch 711 of 2000 took 0.101s
  training loss:		0.353246
  validation loss:		0.405566
  validation accuracy:		87.61 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.347931
  validation loss:		0.430416
  validation accuracy:		87.50 %
Epoch 713 of 2000 took 0.096s
  training loss:		0.360479
  validation loss:		0.407019
  validation accuracy:		87.83 %
Epoch 714 of 2000 took 0.102s
  training loss:		0.348868
  validation loss:		0.414596
  validation accuracy:		87.39 %
Epoch 715 of 2000 took 0.096s
  training loss:		0.345398
  validation loss:		0.427565
  validation accuracy:		87.07 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.346859
  validation loss:		0.410580
  validation accuracy:		87.72 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.355748
  validation loss:		0.437495
  validation accuracy:		86.30 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.349429
  validation loss:		0.449252
  validation accuracy:		86.09 %
Epoch 719 of 2000 took 0.100s
  training loss:		0.353401
  validation loss:		0.420859
  validation accuracy:		86.96 %
Epoch 720 of 2000 took 0.096s
  training loss:		0.344237
  validation loss:		0.441295
  validation accuracy:		85.76 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.350392
  validation loss:		0.395178
  validation accuracy:		88.04 %
Epoch 722 of 2000 took 0.102s
  training loss:		0.346041
  validation loss:		0.411543
  validation accuracy:		87.83 %
Epoch 723 of 2000 took 0.096s
  training loss:		0.351945
  validation loss:		0.414024
  validation accuracy:		87.83 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.342576
  validation loss:		0.424316
  validation accuracy:		86.85 %
Epoch 725 of 2000 took 0.096s
  training loss:		0.346725
  validation loss:		0.400419
  validation accuracy:		88.04 %
Epoch 726 of 2000 took 0.098s
  training loss:		0.339816
  validation loss:		0.419701
  validation accuracy:		86.96 %
Epoch 727 of 2000 took 0.099s
  training loss:		0.348118
  validation loss:		0.449912
  validation accuracy:		85.87 %
Epoch 728 of 2000 took 0.096s
  training loss:		0.345244
  validation loss:		0.421977
  validation accuracy:		87.28 %
Epoch 729 of 2000 took 0.098s
  training loss:		0.345761
  validation loss:		0.397490
  validation accuracy:		88.15 %
Epoch 730 of 2000 took 0.101s
  training loss:		0.344574
  validation loss:		0.399871
  validation accuracy:		88.15 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.347075
  validation loss:		0.407905
  validation accuracy:		87.61 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.341364
  validation loss:		0.406043
  validation accuracy:		88.04 %
Epoch 733 of 2000 took 0.096s
  training loss:		0.350824
  validation loss:		0.426274
  validation accuracy:		86.63 %
Epoch 734 of 2000 took 0.101s
  training loss:		0.343758
  validation loss:		0.438260
  validation accuracy:		86.09 %
Epoch 735 of 2000 took 0.098s
  training loss:		0.338406
  validation loss:		0.396628
  validation accuracy:		88.04 %
Epoch 736 of 2000 took 0.096s
  training loss:		0.344513
  validation loss:		0.403580
  validation accuracy:		87.83 %
Epoch 737 of 2000 took 0.101s
  training loss:		0.342040
  validation loss:		0.403931
  validation accuracy:		87.83 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.348148
  validation loss:		0.410699
  validation accuracy:		88.15 %
Epoch 739 of 2000 took 0.096s
  training loss:		0.345708
  validation loss:		0.411342
  validation accuracy:		87.83 %
Epoch 740 of 2000 took 0.096s
  training loss:		0.342646
  validation loss:		0.401483
  validation accuracy:		88.37 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.336234
  validation loss:		0.408649
  validation accuracy:		88.15 %
Epoch 742 of 2000 took 0.100s
  training loss:		0.339210
  validation loss:		0.406531
  validation accuracy:		88.26 %
Epoch 743 of 2000 took 0.097s
  training loss:		0.340708
  validation loss:		0.399336
  validation accuracy:		88.15 %
Epoch 744 of 2000 took 0.096s
  training loss:		0.334164
  validation loss:		0.401195
  validation accuracy:		88.15 %
Epoch 745 of 2000 took 0.102s
  training loss:		0.341235
  validation loss:		0.401159
  validation accuracy:		88.04 %
Epoch 746 of 2000 took 0.096s
  training loss:		0.338324
  validation loss:		0.411628
  validation accuracy:		87.61 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.339442
  validation loss:		0.404983
  validation accuracy:		88.04 %
Epoch 748 of 2000 took 0.096s
  training loss:		0.338739
  validation loss:		0.411844
  validation accuracy:		87.83 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.331337
  validation loss:		0.413952
  validation accuracy:		87.72 %
Epoch 750 of 2000 took 0.101s
  training loss:		0.339710
  validation loss:		0.402802
  validation accuracy:		87.83 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.340000
  validation loss:		0.396058
  validation accuracy:		88.37 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.332713
  validation loss:		0.397070
  validation accuracy:		88.48 %
Epoch 753 of 2000 took 0.102s
  training loss:		0.334617
  validation loss:		0.408108
  validation accuracy:		87.72 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.345289
  validation loss:		0.404933
  validation accuracy:		87.83 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.347328
  validation loss:		0.397742
  validation accuracy:		88.15 %
Epoch 756 of 2000 took 0.096s
  training loss:		0.339464
  validation loss:		0.392722
  validation accuracy:		88.70 %
Epoch 757 of 2000 took 0.099s
  training loss:		0.332863
  validation loss:		0.400281
  validation accuracy:		88.26 %
Epoch 758 of 2000 took 0.099s
  training loss:		0.336440
  validation loss:		0.412301
  validation accuracy:		86.96 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.338915
  validation loss:		0.414974
  validation accuracy:		87.61 %
Epoch 760 of 2000 took 0.098s
  training loss:		0.333384
  validation loss:		0.402536
  validation accuracy:		88.15 %
Epoch 761 of 2000 took 0.100s
  training loss:		0.339702
  validation loss:		0.405275
  validation accuracy:		87.93 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.336199
  validation loss:		0.397130
  validation accuracy:		88.37 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.329195
  validation loss:		0.408635
  validation accuracy:		87.72 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.337772
  validation loss:		0.420331
  validation accuracy:		87.50 %
Epoch 765 of 2000 took 0.101s
  training loss:		0.335381
  validation loss:		0.403459
  validation accuracy:		88.04 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.341312
  validation loss:		0.404343
  validation accuracy:		88.15 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.332441
  validation loss:		0.405860
  validation accuracy:		88.15 %
Epoch 768 of 2000 took 0.101s
  training loss:		0.336515
  validation loss:		0.394753
  validation accuracy:		88.59 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.333432
  validation loss:		0.397582
  validation accuracy:		88.37 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.343670
  validation loss:		0.414223
  validation accuracy:		87.83 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.323647
  validation loss:		0.404096
  validation accuracy:		87.83 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.332862
  validation loss:		0.391532
  validation accuracy:		88.80 %
Epoch 773 of 2000 took 0.100s
  training loss:		0.336624
  validation loss:		0.389436
  validation accuracy:		88.70 %
Epoch 774 of 2000 took 0.097s
  training loss:		0.329295
  validation loss:		0.390362
  validation accuracy:		88.80 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.336320
  validation loss:		0.393988
  validation accuracy:		88.37 %
Epoch 776 of 2000 took 0.102s
  training loss:		0.336622
  validation loss:		0.432864
  validation accuracy:		86.74 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.335123
  validation loss:		0.423565
  validation accuracy:		86.96 %
Epoch 778 of 2000 took 0.098s
  training loss:		0.333509
  validation loss:		0.401405
  validation accuracy:		87.83 %
Epoch 779 of 2000 took 0.096s
  training loss:		0.332690
  validation loss:		0.401709
  validation accuracy:		88.37 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.326926
  validation loss:		0.428127
  validation accuracy:		86.96 %
Epoch 781 of 2000 took 0.100s
  training loss:		0.334075
  validation loss:		0.404155
  validation accuracy:		88.26 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.328974
  validation loss:		0.400742
  validation accuracy:		88.15 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.333847
  validation loss:		0.405191
  validation accuracy:		87.50 %
Epoch 784 of 2000 took 0.102s
  training loss:		0.329784
  validation loss:		0.391964
  validation accuracy:		88.37 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.333631
  validation loss:		0.403749
  validation accuracy:		87.83 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.328444
  validation loss:		0.393167
  validation accuracy:		88.91 %
Epoch 787 of 2000 took 0.096s
  training loss:		0.325159
  validation loss:		0.393503
  validation accuracy:		88.26 %
Epoch 788 of 2000 took 0.099s
  training loss:		0.327872
  validation loss:		0.402011
  validation accuracy:		88.26 %
Epoch 789 of 2000 took 0.099s
  training loss:		0.327503
  validation loss:		0.403739
  validation accuracy:		88.04 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.329795
  validation loss:		0.419561
  validation accuracy:		86.96 %
Epoch 791 of 2000 took 0.099s
  training loss:		0.322659
  validation loss:		0.399039
  validation accuracy:		88.80 %
Epoch 792 of 2000 took 0.100s
  training loss:		0.324763
  validation loss:		0.403465
  validation accuracy:		88.15 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.328649
  validation loss:		0.388342
  validation accuracy:		88.59 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.323682
  validation loss:		0.389383
  validation accuracy:		88.59 %
Epoch 795 of 2000 took 0.096s
  training loss:		0.328374
  validation loss:		0.400352
  validation accuracy:		87.93 %
Epoch 796 of 2000 took 0.101s
  training loss:		0.326789
  validation loss:		0.409969
  validation accuracy:		87.72 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.324999
  validation loss:		0.389059
  validation accuracy:		88.91 %
Epoch 798 of 2000 took 0.096s
  training loss:		0.324748
  validation loss:		0.399435
  validation accuracy:		87.83 %
Epoch 799 of 2000 took 0.102s
  training loss:		0.327606
  validation loss:		0.390545
  validation accuracy:		88.37 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.325264
  validation loss:		0.412752
  validation accuracy:		87.39 %
Epoch 801 of 2000 took 0.096s
  training loss:		0.322936
  validation loss:		0.402255
  validation accuracy:		88.04 %
Epoch 802 of 2000 took 0.096s
  training loss:		0.319546
  validation loss:		0.387180
  validation accuracy:		88.70 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.332143
  validation loss:		0.403467
  validation accuracy:		87.83 %
Epoch 804 of 2000 took 0.100s
  training loss:		0.319168
  validation loss:		0.392449
  validation accuracy:		88.59 %
Epoch 805 of 2000 took 0.097s
  training loss:		0.329494
  validation loss:		0.389715
  validation accuracy:		88.59 %
Epoch 806 of 2000 took 0.096s
  training loss:		0.324111
  validation loss:		0.387860
  validation accuracy:		88.70 %
Epoch 807 of 2000 took 0.102s
  training loss:		0.325125
  validation loss:		0.424533
  validation accuracy:		87.17 %
Epoch 808 of 2000 took 0.096s
  training loss:		0.321859
  validation loss:		0.416329
  validation accuracy:		87.07 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.332383
  validation loss:		0.393025
  validation accuracy:		88.04 %
Epoch 810 of 2000 took 0.096s
  training loss:		0.316264
  validation loss:		0.406615
  validation accuracy:		87.83 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.331870
  validation loss:		0.395487
  validation accuracy:		88.37 %
Epoch 812 of 2000 took 0.100s
  training loss:		0.321700
  validation loss:		0.391951
  validation accuracy:		88.48 %
Epoch 813 of 2000 took 0.096s
  training loss:		0.322076
  validation loss:		0.410583
  validation accuracy:		87.72 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.325376
  validation loss:		0.406173
  validation accuracy:		87.39 %
Epoch 815 of 2000 took 0.102s
  training loss:		0.319357
  validation loss:		0.390008
  validation accuracy:		88.91 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.322609
  validation loss:		0.437831
  validation accuracy:		86.52 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.337750
  validation loss:		0.397509
  validation accuracy:		88.26 %
Epoch 818 of 2000 took 0.096s
  training loss:		0.322095
  validation loss:		0.389331
  validation accuracy:		88.48 %
Epoch 819 of 2000 took 0.098s
  training loss:		0.321084
  validation loss:		0.408007
  validation accuracy:		87.93 %
Epoch 820 of 2000 took 0.099s
  training loss:		0.325418
  validation loss:		0.418320
  validation accuracy:		87.39 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.318178
  validation loss:		0.407856
  validation accuracy:		87.93 %
Epoch 822 of 2000 took 0.098s
  training loss:		0.321834
  validation loss:		0.403415
  validation accuracy:		88.15 %
Epoch 823 of 2000 took 0.101s
  training loss:		0.317374
  validation loss:		0.394747
  validation accuracy:		88.26 %
Epoch 824 of 2000 took 0.096s
  training loss:		0.320145
  validation loss:		0.394239
  validation accuracy:		88.37 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.323200
  validation loss:		0.379935
  validation accuracy:		88.59 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.324184
  validation loss:		0.386889
  validation accuracy:		88.80 %
Epoch 827 of 2000 took 0.100s
  training loss:		0.314693
  validation loss:		0.403243
  validation accuracy:		87.83 %
Epoch 828 of 2000 took 0.098s
  training loss:		0.321641
  validation loss:		0.401961
  validation accuracy:		88.48 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.318204
  validation loss:		0.407723
  validation accuracy:		87.61 %
Epoch 830 of 2000 took 0.100s
  training loss:		0.322276
  validation loss:		0.396608
  validation accuracy:		87.93 %
Epoch 831 of 2000 took 0.098s
  training loss:		0.318139
  validation loss:		0.390287
  validation accuracy:		88.37 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.322785
  validation loss:		0.397024
  validation accuracy:		88.15 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.320339
  validation loss:		0.404827
  validation accuracy:		87.93 %
Epoch 834 of 2000 took 0.096s
  training loss:		0.323199
  validation loss:		0.400622
  validation accuracy:		88.15 %
Epoch 835 of 2000 took 0.101s
  training loss:		0.317929
  validation loss:		0.390115
  validation accuracy:		88.15 %
Epoch 836 of 2000 took 0.097s
  training loss:		0.320294
  validation loss:		0.397516
  validation accuracy:		88.04 %
Epoch 837 of 2000 took 0.096s
  training loss:		0.318967
  validation loss:		0.403014
  validation accuracy:		87.83 %
Epoch 838 of 2000 took 0.102s
  training loss:		0.310345
  validation loss:		0.421953
  validation accuracy:		87.07 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.324681
  validation loss:		0.382023
  validation accuracy:		89.13 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.318450
  validation loss:		0.386879
  validation accuracy:		88.48 %
Epoch 841 of 2000 took 0.096s
  training loss:		0.313062
  validation loss:		0.390881
  validation accuracy:		88.48 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.316157
  validation loss:		0.407253
  validation accuracy:		87.61 %
Epoch 843 of 2000 took 0.100s
  training loss:		0.315658
  validation loss:		0.402446
  validation accuracy:		87.93 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.316461
  validation loss:		0.411648
  validation accuracy:		87.50 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.316580
  validation loss:		0.403610
  validation accuracy:		87.93 %
Epoch 846 of 2000 took 0.102s
  training loss:		0.316093
  validation loss:		0.406624
  validation accuracy:		87.72 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.310679
  validation loss:		0.391972
  validation accuracy:		88.26 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.318481
  validation loss:		0.383170
  validation accuracy:		88.48 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.316412
  validation loss:		0.391245
  validation accuracy:		88.15 %
Epoch 850 of 2000 took 0.098s
  training loss:		0.312410
  validation loss:		0.403848
  validation accuracy:		88.70 %
Epoch 851 of 2000 took 0.099s
  training loss:		0.316012
  validation loss:		0.389814
  validation accuracy:		89.02 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.312331
  validation loss:		0.398126
  validation accuracy:		88.26 %
Epoch 853 of 2000 took 0.098s
  training loss:		0.316038
  validation loss:		0.382278
  validation accuracy:		88.80 %
Epoch 854 of 2000 took 0.101s
  training loss:		0.312835
  validation loss:		0.380479
  validation accuracy:		88.37 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.316015
  validation loss:		0.387828
  validation accuracy:		88.26 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.317124
  validation loss:		0.402871
  validation accuracy:		87.83 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.315639
  validation loss:		0.403401
  validation accuracy:		87.72 %
Epoch 858 of 2000 took 0.101s
  training loss:		0.314059
  validation loss:		0.405771
  validation accuracy:		87.93 %
Epoch 859 of 2000 took 0.098s
  training loss:		0.317164
  validation loss:		0.397059
  validation accuracy:		88.15 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.310518
  validation loss:		0.415991
  validation accuracy:		87.28 %
Epoch 861 of 2000 took 0.101s
  training loss:		0.317520
  validation loss:		0.387808
  validation accuracy:		89.02 %
Epoch 862 of 2000 took 0.098s
  training loss:		0.318502
  validation loss:		0.399788
  validation accuracy:		88.04 %
Epoch 863 of 2000 took 0.096s
  training loss:		0.312726
  validation loss:		0.404666
  validation accuracy:		87.72 %
Epoch 864 of 2000 took 0.096s
  training loss:		0.316506
  validation loss:		0.394640
  validation accuracy:		87.93 %
Epoch 865 of 2000 took 0.096s
  training loss:		0.312687
  validation loss:		0.386097
  validation accuracy:		88.59 %
Epoch 866 of 2000 took 0.100s
  training loss:		0.308168
  validation loss:		0.394353
  validation accuracy:		88.26 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.318990
  validation loss:		0.405643
  validation accuracy:		87.83 %
Epoch 868 of 2000 took 0.096s
  training loss:		0.310092
  validation loss:		0.448132
  validation accuracy:		86.20 %
Epoch 869 of 2000 took 0.102s
  training loss:		0.324505
  validation loss:		0.399040
  validation accuracy:		88.15 %
Epoch 870 of 2000 took 0.096s
  training loss:		0.316872
  validation loss:		0.400611
  validation accuracy:		87.72 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.315626
  validation loss:		0.383999
  validation accuracy:		88.70 %
Epoch 872 of 2000 took 0.096s
  training loss:		0.314817
  validation loss:		0.398752
  validation accuracy:		88.15 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.318482
  validation loss:		0.401613
  validation accuracy:		87.93 %
Epoch 874 of 2000 took 0.100s
  training loss:		0.314992
  validation loss:		0.400611
  validation accuracy:		87.72 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.314619
  validation loss:		0.389909
  validation accuracy:		88.15 %
Epoch 876 of 2000 took 0.097s
  training loss:		0.314564
  validation loss:		0.377357
  validation accuracy:		89.13 %
Epoch 877 of 2000 took 0.102s
  training loss:		0.306013
  validation loss:		0.379316
  validation accuracy:		88.26 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.314283
  validation loss:		0.404939
  validation accuracy:		87.61 %
Epoch 879 of 2000 took 0.097s
  training loss:		0.307153
  validation loss:		0.389912
  validation accuracy:		88.15 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.311434
  validation loss:		0.402696
  validation accuracy:		87.83 %
Epoch 881 of 2000 took 0.098s
  training loss:		0.316381
  validation loss:		0.390551
  validation accuracy:		88.37 %
Epoch 882 of 2000 took 0.099s
  training loss:		0.310741
  validation loss:		0.376142
  validation accuracy:		89.13 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.307695
  validation loss:		0.402072
  validation accuracy:		87.93 %
Epoch 884 of 2000 took 0.098s
  training loss:		0.315579
  validation loss:		0.451560
  validation accuracy:		85.98 %
Epoch 885 of 2000 took 0.101s
  training loss:		0.309493
  validation loss:		0.381977
  validation accuracy:		89.35 %
Epoch 886 of 2000 took 0.096s
  training loss:		0.317264
  validation loss:		0.392704
  validation accuracy:		88.48 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.319166
  validation loss:		0.402011
  validation accuracy:		88.04 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.305430
  validation loss:		0.395760
  validation accuracy:		88.59 %
Epoch 889 of 2000 took 0.101s
  training loss:		0.309092
  validation loss:		0.379949
  validation accuracy:		89.78 %
Epoch 890 of 2000 took 0.098s
  training loss:		0.317986
  validation loss:		0.376311
  validation accuracy:		88.70 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.310399
  validation loss:		0.398661
  validation accuracy:		88.37 %
Epoch 892 of 2000 took 0.101s
  training loss:		0.311943
  validation loss:		0.394064
  validation accuracy:		88.15 %
Epoch 893 of 2000 took 0.098s
  training loss:		0.313777
  validation loss:		0.384817
  validation accuracy:		88.37 %
Epoch 894 of 2000 took 0.096s
  training loss:		0.314684
  validation loss:		0.389053
  validation accuracy:		88.37 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.306954
  validation loss:		0.386275
  validation accuracy:		89.24 %
Epoch 896 of 2000 took 0.096s
  training loss:		0.314465
  validation loss:		0.385935
  validation accuracy:		89.13 %
Epoch 897 of 2000 took 0.100s
  training loss:		0.309960
  validation loss:		0.396354
  validation accuracy:		88.91 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.301780
  validation loss:		0.383617
  validation accuracy:		89.02 %
Epoch 899 of 2000 took 0.096s
  training loss:		0.308627
  validation loss:		0.381282
  validation accuracy:		89.13 %
Epoch 900 of 2000 took 0.102s
  training loss:		0.309441
  validation loss:		0.402684
  validation accuracy:		88.37 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.313028
  validation loss:		0.393499
  validation accuracy:		88.15 %
Epoch 902 of 2000 took 0.097s
  training loss:		0.309758
  validation loss:		0.375298
  validation accuracy:		88.91 %
Epoch 903 of 2000 took 0.096s
  training loss:		0.312522
  validation loss:		0.388378
  validation accuracy:		88.37 %
Epoch 904 of 2000 took 0.097s
  training loss:		0.309115
  validation loss:		0.403425
  validation accuracy:		87.72 %
Epoch 905 of 2000 took 0.100s
  training loss:		0.311028
  validation loss:		0.387429
  validation accuracy:		88.80 %
Epoch 906 of 2000 took 0.096s
  training loss:		0.313946
  validation loss:		0.378447
  validation accuracy:		89.02 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.317349
  validation loss:		0.383726
  validation accuracy:		89.24 %
Epoch 908 of 2000 took 0.102s
  training loss:		0.316149
  validation loss:		0.389017
  validation accuracy:		88.80 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.308182
  validation loss:		0.374558
  validation accuracy:		89.57 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.309324
  validation loss:		0.396108
  validation accuracy:		88.26 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.314231
  validation loss:		0.386628
  validation accuracy:		88.80 %
Epoch 912 of 2000 took 0.098s
  training loss:		0.306729
  validation loss:		0.399062
  validation accuracy:		88.26 %
Epoch 913 of 2000 took 0.100s
  training loss:		0.309249
  validation loss:		0.384069
  validation accuracy:		89.24 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.310694
  validation loss:		0.405529
  validation accuracy:		87.93 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.305813
  validation loss:		0.378293
  validation accuracy:		89.78 %
Epoch 916 of 2000 took 0.102s
  training loss:		0.308560
  validation loss:		0.379724
  validation accuracy:		88.59 %
Epoch 917 of 2000 took 0.096s
  training loss:		0.305419
  validation loss:		0.380090
  validation accuracy:		88.80 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.310402
  validation loss:		0.384548
  validation accuracy:		89.24 %
Epoch 919 of 2000 took 0.096s
  training loss:		0.312204
  validation loss:		0.390367
  validation accuracy:		88.70 %
Epoch 920 of 2000 took 0.100s
  training loss:		0.312583
  validation loss:		0.401860
  validation accuracy:		88.59 %
Epoch 921 of 2000 took 0.098s
  training loss:		0.306585
  validation loss:		0.388457
  validation accuracy:		88.48 %
Epoch 922 of 2000 took 0.096s
  training loss:		0.310214
  validation loss:		0.412217
  validation accuracy:		87.39 %
Epoch 923 of 2000 took 0.100s
  training loss:		0.307609
  validation loss:		0.391838
  validation accuracy:		88.91 %
Epoch 924 of 2000 took 0.098s
  training loss:		0.313831
  validation loss:		0.400209
  validation accuracy:		88.15 %
Epoch 925 of 2000 took 0.096s
  training loss:		0.308117
  validation loss:		0.381102
  validation accuracy:		88.80 %
Epoch 926 of 2000 took 0.096s
  training loss:		0.311626
  validation loss:		0.382047
  validation accuracy:		89.24 %
Epoch 927 of 2000 took 0.096s
  training loss:		0.311759
  validation loss:		0.424949
  validation accuracy:		86.96 %
Epoch 928 of 2000 took 0.100s
  training loss:		0.315684
  validation loss:		0.391801
  validation accuracy:		88.59 %
Epoch 929 of 2000 took 0.097s
  training loss:		0.308004
  validation loss:		0.381549
  validation accuracy:		89.02 %
Epoch 930 of 2000 took 0.096s
  training loss:		0.307617
  validation loss:		0.396344
  validation accuracy:		88.15 %
Epoch 931 of 2000 took 0.102s
  training loss:		0.310832
  validation loss:		0.434995
  validation accuracy:		87.07 %
Epoch 932 of 2000 took 0.096s
  training loss:		0.311825
  validation loss:		0.388740
  validation accuracy:		88.59 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.306317
  validation loss:		0.377406
  validation accuracy:		89.02 %
Epoch 934 of 2000 took 0.096s
  training loss:		0.302114
  validation loss:		0.393744
  validation accuracy:		88.48 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.300692
  validation loss:		0.402669
  validation accuracy:		88.37 %
Epoch 936 of 2000 took 0.101s
  training loss:		0.314999
  validation loss:		0.376563
  validation accuracy:		89.13 %
Epoch 937 of 2000 took 0.096s
  training loss:		0.311764
  validation loss:		0.378792
  validation accuracy:		89.02 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.309256
  validation loss:		0.393106
  validation accuracy:		88.48 %
Epoch 939 of 2000 took 0.102s
  training loss:		0.311279
  validation loss:		0.410038
  validation accuracy:		88.04 %
Epoch 940 of 2000 took 0.096s
  training loss:		0.307084
  validation loss:		0.391522
  validation accuracy:		88.59 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.315084
  validation loss:		0.393931
  validation accuracy:		88.15 %
Epoch 942 of 2000 took 0.096s
  training loss:		0.303081
  validation loss:		0.404764
  validation accuracy:		87.83 %
Epoch 943 of 2000 took 0.098s
  training loss:		0.301738
  validation loss:		0.386960
  validation accuracy:		88.59 %
Epoch 944 of 2000 took 0.100s
  training loss:		0.305401
  validation loss:		0.405277
  validation accuracy:		88.37 %
Epoch 945 of 2000 took 0.096s
  training loss:		0.310872
  validation loss:		0.371505
  validation accuracy:		88.91 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.308206
  validation loss:		0.373463
  validation accuracy:		90.11 %
Epoch 947 of 2000 took 0.101s
  training loss:		0.302923
  validation loss:		0.375282
  validation accuracy:		88.70 %
Epoch 948 of 2000 took 0.096s
  training loss:		0.305466
  validation loss:		0.408678
  validation accuracy:		87.83 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.308279
  validation loss:		0.390601
  validation accuracy:		88.37 %
Epoch 950 of 2000 took 0.096s
  training loss:		0.310188
  validation loss:		0.377609
  validation accuracy:		89.13 %
Epoch 951 of 2000 took 0.101s
  training loss:		0.301642
  validation loss:		0.378817
  validation accuracy:		88.80 %
Epoch 952 of 2000 took 0.098s
  training loss:		0.309426
  validation loss:		0.420479
  validation accuracy:		88.04 %
Epoch 953 of 2000 took 0.096s
  training loss:		0.306098
  validation loss:		0.416636
  validation accuracy:		87.39 %
Epoch 954 of 2000 took 0.103s
  training loss:		0.311231
  validation loss:		0.408246
  validation accuracy:		88.26 %
Epoch 955 of 2000 took 0.101s
  training loss:		0.313139
  validation loss:		0.405043
  validation accuracy:		87.61 %
Epoch 956 of 2000 took 0.099s
  training loss:		0.298827
  validation loss:		0.375190
  validation accuracy:		89.13 %
Epoch 957 of 2000 took 0.100s
  training loss:		0.309105
  validation loss:		0.387798
  validation accuracy:		88.70 %
Epoch 958 of 2000 took 0.099s
  training loss:		0.312191
  validation loss:		0.386979
  validation accuracy:		88.15 %
Epoch 959 of 2000 took 0.104s
  training loss:		0.307083
  validation loss:		0.398643
  validation accuracy:		88.37 %
Epoch 960 of 2000 took 0.100s
  training loss:		0.307828
  validation loss:		0.411129
  validation accuracy:		87.72 %
Epoch 961 of 2000 took 0.099s
  training loss:		0.309101
  validation loss:		0.402309
  validation accuracy:		88.04 %
Epoch 962 of 2000 took 0.105s
  training loss:		0.310397
  validation loss:		0.418376
  validation accuracy:		87.72 %
Epoch 963 of 2000 took 0.099s
  training loss:		0.307849
  validation loss:		0.377144
  validation accuracy:		89.13 %
Epoch 964 of 2000 took 0.100s
  training loss:		0.301473
  validation loss:		0.379046
  validation accuracy:		89.13 %
Epoch 965 of 2000 took 0.099s
  training loss:		0.301449
  validation loss:		0.400828
  validation accuracy:		88.15 %
Epoch 966 of 2000 took 0.100s
  training loss:		0.302334
  validation loss:		0.381280
  validation accuracy:		88.91 %
Epoch 967 of 2000 took 0.104s
  training loss:		0.307202
  validation loss:		0.392158
  validation accuracy:		88.59 %
Epoch 968 of 2000 took 0.099s
  training loss:		0.307690
  validation loss:		0.379430
  validation accuracy:		89.57 %
Epoch 969 of 2000 took 0.100s
  training loss:		0.313332
  validation loss:		0.384603
  validation accuracy:		88.91 %
Epoch 970 of 2000 took 0.105s
  training loss:		0.301470
  validation loss:		0.387376
  validation accuracy:		89.13 %
Epoch 971 of 2000 took 0.099s
  training loss:		0.305196
  validation loss:		0.389341
  validation accuracy:		88.48 %
Epoch 972 of 2000 took 0.100s
  training loss:		0.314492
  validation loss:		0.424707
  validation accuracy:		87.07 %
Epoch 973 of 2000 took 0.099s
  training loss:		0.306610
  validation loss:		0.379705
  validation accuracy:		89.35 %
Epoch 974 of 2000 took 0.102s
  training loss:		0.300371
  validation loss:		0.398460
  validation accuracy:		88.26 %
Epoch 975 of 2000 took 0.101s
  training loss:		0.297492
  validation loss:		0.387606
  validation accuracy:		89.02 %
Epoch 976 of 2000 took 0.099s
  training loss:		0.300674
  validation loss:		0.390730
  validation accuracy:		88.80 %
Epoch 977 of 2000 took 0.102s
  training loss:		0.303381
  validation loss:		0.376548
  validation accuracy:		88.91 %
Epoch 978 of 2000 took 0.102s
  training loss:		0.312119
  validation loss:		0.422362
  validation accuracy:		87.61 %
Epoch 979 of 2000 took 0.099s
  training loss:		0.306108
  validation loss:		0.413112
  validation accuracy:		87.83 %
Epoch 980 of 2000 took 0.100s
  training loss:		0.313908
  validation loss:		0.391435
  validation accuracy:		88.70 %
Epoch 981 of 2000 took 0.099s
  training loss:		0.300194
  validation loss:		0.381848
  validation accuracy:		89.13 %
Epoch 982 of 2000 took 0.104s
  training loss:		0.304166
  validation loss:		0.376071
  validation accuracy:		89.67 %
Epoch 983 of 2000 took 0.100s
  training loss:		0.305786
  validation loss:		0.386140
  validation accuracy:		89.02 %
Epoch 984 of 2000 took 0.099s
  training loss:		0.307559
  validation loss:		0.382576
  validation accuracy:		89.67 %
Epoch 985 of 2000 took 0.105s
  training loss:		0.301324
  validation loss:		0.373442
  validation accuracy:		88.59 %
Epoch 986 of 2000 took 0.100s
  training loss:		0.313976
  validation loss:		0.384359
  validation accuracy:		89.35 %
Epoch 987 of 2000 took 0.100s
  training loss:		0.303079
  validation loss:		0.422881
  validation accuracy:		87.72 %
Epoch 988 of 2000 took 0.099s
  training loss:		0.306150
  validation loss:		0.384712
  validation accuracy:		88.91 %
Epoch 989 of 2000 took 0.100s
  training loss:		0.301242
  validation loss:		0.430887
  validation accuracy:		87.17 %
Epoch 990 of 2000 took 0.103s
  training loss:		0.310282
  validation loss:		0.379211
  validation accuracy:		89.57 %
Epoch 991 of 2000 took 0.100s
  training loss:		0.313138
  validation loss:		0.377939
  validation accuracy:		89.67 %
Epoch 992 of 2000 took 0.100s
  training loss:		0.317214
  validation loss:		0.396728
  validation accuracy:		89.35 %
Epoch 993 of 2000 took 0.105s
  training loss:		0.308553
  validation loss:		0.384781
  validation accuracy:		89.35 %
Epoch 994 of 2000 took 0.099s
  training loss:		0.306298
  validation loss:		0.399648
  validation accuracy:		88.70 %
Epoch 995 of 2000 took 0.100s
  training loss:		0.304632
  validation loss:		0.381477
  validation accuracy:		89.02 %
Epoch 996 of 2000 took 0.099s
  training loss:		0.303174
  validation loss:		0.396573
  validation accuracy:		88.80 %
Epoch 997 of 2000 took 0.101s
  training loss:		0.304271
  validation loss:		0.402368
  validation accuracy:		88.04 %
Epoch 998 of 2000 took 0.103s
  training loss:		0.306340
  validation loss:		0.386063
  validation accuracy:		88.80 %
Epoch 999 of 2000 took 0.099s
  training loss:		0.299827
  validation loss:		0.374172
  validation accuracy:		89.67 %
Epoch 1000 of 2000 took 0.100s
  training loss:		0.299083
  validation loss:		0.381913
  validation accuracy:		89.46 %
Epoch 1001 of 2000 took 0.105s
  training loss:		0.303715
  validation loss:		0.395610
  validation accuracy:		88.70 %
Epoch 1002 of 2000 took 0.099s
  training loss:		0.302310
  validation loss:		0.401655
  validation accuracy:		89.02 %
Epoch 1003 of 2000 took 0.100s
  training loss:		0.298641
  validation loss:		0.384320
  validation accuracy:		89.13 %
Epoch 1004 of 2000 took 0.099s
  training loss:		0.307067
  validation loss:		0.413767
  validation accuracy:		87.93 %
Epoch 1005 of 2000 took 0.103s
  training loss:		0.305191
  validation loss:		0.377751
  validation accuracy:		89.35 %
Epoch 1006 of 2000 took 0.101s
  training loss:		0.302161
  validation loss:		0.420555
  validation accuracy:		87.83 %
Epoch 1007 of 2000 took 0.099s
  training loss:		0.294893
  validation loss:		0.384401
  validation accuracy:		89.35 %
Epoch 1008 of 2000 took 0.103s
  training loss:		0.299431
  validation loss:		0.378266
  validation accuracy:		89.24 %
Epoch 1009 of 2000 took 0.101s
  training loss:		0.308982
  validation loss:		0.386365
  validation accuracy:		89.13 %
Epoch 1010 of 2000 took 0.099s
  training loss:		0.304210
  validation loss:		0.405422
  validation accuracy:		88.59 %
Epoch 1011 of 2000 took 0.100s
  training loss:		0.300912
  validation loss:		0.369210
  validation accuracy:		89.46 %
Epoch 1012 of 2000 took 0.099s
  training loss:		0.307974
  validation loss:		0.378447
  validation accuracy:		89.78 %
Epoch 1013 of 2000 took 0.104s
  training loss:		0.304655
  validation loss:		0.387976
  validation accuracy:		89.67 %
Epoch 1014 of 2000 took 0.100s
  training loss:		0.301826
  validation loss:		0.380896
  validation accuracy:		89.67 %
Epoch 1015 of 2000 took 0.099s
  training loss:		0.306066
  validation loss:		0.390484
  validation accuracy:		88.91 %
Epoch 1016 of 2000 took 0.105s
  training loss:		0.299125
  validation loss:		0.397997
  validation accuracy:		88.59 %
Epoch 1017 of 2000 took 0.099s
  training loss:		0.305805
  validation loss:		0.380900
  validation accuracy:		89.57 %
Epoch 1018 of 2000 took 0.100s
  training loss:		0.303251
  validation loss:		0.377152
  validation accuracy:		89.46 %
Epoch 1019 of 2000 took 0.099s
  training loss:		0.305216
  validation loss:		0.380241
  validation accuracy:		89.35 %
Epoch 1020 of 2000 took 0.100s
  training loss:		0.297193
  validation loss:		0.393754
  validation accuracy:		88.80 %
Epoch 1021 of 2000 took 0.103s
  training loss:		0.300775
  validation loss:		0.385382
  validation accuracy:		89.46 %
Epoch 1022 of 2000 took 0.099s
  training loss:		0.298457
  validation loss:		0.383902
  validation accuracy:		89.02 %
Epoch 1023 of 2000 took 0.100s
  training loss:		0.307031
  validation loss:		0.396090
  validation accuracy:		89.13 %
Epoch 1024 of 2000 took 0.105s
  training loss:		0.300115
  validation loss:		0.383886
  validation accuracy:		89.46 %
Epoch 1025 of 2000 took 0.101s
  training loss:		0.298078
  validation loss:		0.380895
  validation accuracy:		89.35 %
Epoch 1026 of 2000 took 0.100s
  training loss:		0.308718
  validation loss:		0.381209
  validation accuracy:		89.24 %
Epoch 1027 of 2000 took 0.099s
  training loss:		0.311593
  validation loss:		0.373629
  validation accuracy:		89.78 %
Epoch 1028 of 2000 took 0.101s
  training loss:		0.307877
  validation loss:		0.375975
  validation accuracy:		89.46 %
Epoch 1029 of 2000 took 0.102s
  training loss:		0.304597
  validation loss:		0.387990
  validation accuracy:		89.24 %
Epoch 1030 of 2000 took 0.099s
  training loss:		0.302413
  validation loss:		0.389079
  validation accuracy:		89.24 %
Epoch 1031 of 2000 took 0.101s
  training loss:		0.301485
  validation loss:		0.418733
  validation accuracy:		87.50 %
Epoch 1032 of 2000 took 0.104s
  training loss:		0.294502
  validation loss:		0.380235
  validation accuracy:		89.02 %
Epoch 1033 of 2000 took 0.099s
  training loss:		0.299240
  validation loss:		0.376806
  validation accuracy:		89.78 %
Epoch 1034 of 2000 took 0.100s
  training loss:		0.296347
  validation loss:		0.393437
  validation accuracy:		90.11 %
Epoch 1035 of 2000 took 0.099s
  training loss:		0.304078
  validation loss:		0.388799
  validation accuracy:		89.13 %
Epoch 1036 of 2000 took 0.104s
  training loss:		0.294716
  validation loss:		0.411150
  validation accuracy:		89.57 %
Epoch 1037 of 2000 took 0.101s
  training loss:		0.309971
  validation loss:		0.401491
  validation accuracy:		89.13 %
Epoch 1038 of 2000 took 0.099s
  training loss:		0.302162
  validation loss:		0.404437
  validation accuracy:		88.37 %
Epoch 1039 of 2000 took 0.103s
  training loss:		0.302060
  validation loss:		0.412111
  validation accuracy:		88.48 %
Epoch 1040 of 2000 took 0.099s
  training loss:		0.298134
  validation loss:		0.401749
  validation accuracy:		88.37 %
Epoch 1041 of 2000 took 0.100s
  training loss:		0.300450
  validation loss:		0.416220
  validation accuracy:		88.04 %
Epoch 1042 of 2000 took 0.102s
  training loss:		0.302353
  validation loss:		0.384013
  validation accuracy:		89.67 %
Epoch 1043 of 2000 took 0.099s
  training loss:		0.296660
  validation loss:		0.388594
  validation accuracy:		89.89 %
Epoch 1044 of 2000 took 0.103s
  training loss:		0.297567
  validation loss:		0.383305
  validation accuracy:		89.57 %
Epoch 1045 of 2000 took 0.099s
  training loss:		0.302798
  validation loss:		0.396655
  validation accuracy:		89.02 %
Epoch 1046 of 2000 took 0.101s
  training loss:		0.303154
  validation loss:		0.380132
  validation accuracy:		89.46 %
Epoch 1047 of 2000 took 0.100s
  training loss:		0.298043
  validation loss:		0.384274
  validation accuracy:		89.46 %
Epoch 1048 of 2000 took 0.099s
  training loss:		0.306580
  validation loss:		0.405939
  validation accuracy:		88.26 %
Epoch 1049 of 2000 took 0.102s
  training loss:		0.302548
  validation loss:		0.384806
  validation accuracy:		89.24 %
Epoch 1050 of 2000 took 0.099s
  training loss:		0.303821
  validation loss:		0.378640
  validation accuracy:		89.78 %
Epoch 1051 of 2000 took 0.103s
  training loss:		0.297801
  validation loss:		0.389750
  validation accuracy:		89.24 %
Epoch 1052 of 2000 took 0.099s
  training loss:		0.301184
  validation loss:		0.384456
  validation accuracy:		88.80 %
Epoch 1053 of 2000 took 0.100s
  training loss:		0.301606
  validation loss:		0.403988
  validation accuracy:		88.48 %
Epoch 1054 of 2000 took 0.102s
  training loss:		0.297344
  validation loss:		0.396578
  validation accuracy:		88.80 %
Epoch 1055 of 2000 took 0.099s
  training loss:		0.307181
  validation loss:		0.411164
  validation accuracy:		88.48 %
Epoch 1056 of 2000 took 0.103s
  training loss:		0.299121
  validation loss:		0.384922
  validation accuracy:		89.02 %
Epoch 1057 of 2000 took 0.099s
  training loss:		0.305530
  validation loss:		0.424284
  validation accuracy:		87.61 %
Epoch 1058 of 2000 took 0.101s
  training loss:		0.310415
  validation loss:		0.397049
  validation accuracy:		89.02 %
Epoch 1059 of 2000 took 0.100s
  training loss:		0.301432
  validation loss:		0.380061
  validation accuracy:		89.67 %
Epoch 1060 of 2000 took 0.099s
  training loss:		0.297561
  validation loss:		0.383851
  validation accuracy:		89.78 %
Epoch 1061 of 2000 took 0.102s
  training loss:		0.301623
  validation loss:		0.384754
  validation accuracy:		89.57 %
Epoch 1062 of 2000 took 0.099s
  training loss:		0.299323
  validation loss:		0.383672
  validation accuracy:		89.57 %
Epoch 1063 of 2000 took 0.102s
  training loss:		0.293886
  validation loss:		0.374259
  validation accuracy:		88.91 %
Epoch 1064 of 2000 took 0.099s
  training loss:		0.305840
  validation loss:		0.392044
  validation accuracy:		89.46 %
Epoch 1065 of 2000 took 0.099s
  training loss:		0.300042
  validation loss:		0.422517
  validation accuracy:		88.04 %
Epoch 1066 of 2000 took 0.102s
  training loss:		0.301035
  validation loss:		0.380944
  validation accuracy:		89.57 %
Epoch 1067 of 2000 took 0.099s
  training loss:		0.298056
  validation loss:		0.381459
  validation accuracy:		89.78 %
Epoch 1068 of 2000 took 0.104s
  training loss:		0.296068
  validation loss:		0.403567
  validation accuracy:		88.80 %
Epoch 1069 of 2000 took 0.100s
  training loss:		0.303578
  validation loss:		0.397609
  validation accuracy:		89.35 %
Epoch 1070 of 2000 took 0.099s
  training loss:		0.301173
  validation loss:		0.382247
  validation accuracy:		90.00 %
Epoch 1071 of 2000 took 0.100s
  training loss:		0.292997
  validation loss:		0.388614
  validation accuracy:		89.89 %
Epoch 1072 of 2000 took 0.100s
  training loss:		0.304660
  validation loss:		0.381052
  validation accuracy:		89.89 %
Epoch 1073 of 2000 took 0.102s
  training loss:		0.293034
  validation loss:		0.429339
  validation accuracy:		87.17 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.297365
  validation loss:		0.380506
  validation accuracy:		89.89 %
Epoch 1075 of 2000 took 0.096s
  training loss:		0.299998
  validation loss:		0.408445
  validation accuracy:		88.59 %
Epoch 1076 of 2000 took 0.103s
  training loss:		0.294704
  validation loss:		0.389488
  validation accuracy:		89.46 %
Epoch 1077 of 2000 took 0.096s
  training loss:		0.292048
  validation loss:		0.395517
  validation accuracy:		89.35 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.305734
  validation loss:		0.387909
  validation accuracy:		89.78 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.296104
  validation loss:		0.381466
  validation accuracy:		89.78 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.304643
  validation loss:		0.406733
  validation accuracy:		89.02 %
Epoch 1081 of 2000 took 0.101s
  training loss:		0.301612
  validation loss:		0.379703
  validation accuracy:		89.78 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.298350
  validation loss:		0.387741
  validation accuracy:		88.80 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.301479
  validation loss:		0.382496
  validation accuracy:		89.57 %
Epoch 1084 of 2000 took 0.102s
  training loss:		0.304484
  validation loss:		0.376365
  validation accuracy:		89.24 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.298707
  validation loss:		0.425842
  validation accuracy:		87.72 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.295644
  validation loss:		0.407731
  validation accuracy:		88.70 %
Epoch 1087 of 2000 took 0.096s
  training loss:		0.300413
  validation loss:		0.406287
  validation accuracy:		88.91 %
Epoch 1088 of 2000 took 0.099s
  training loss:		0.301948
  validation loss:		0.373777
  validation accuracy:		89.57 %
Epoch 1089 of 2000 took 0.098s
  training loss:		0.298826
  validation loss:		0.383050
  validation accuracy:		88.59 %
Epoch 1090 of 2000 took 0.096s
  training loss:		0.299579
  validation loss:		0.377835
  validation accuracy:		89.02 %
Epoch 1091 of 2000 took 0.099s
  training loss:		0.300837
  validation loss:		0.380825
  validation accuracy:		90.00 %
Epoch 1092 of 2000 took 0.100s
  training loss:		0.301701
  validation loss:		0.404221
  validation accuracy:		88.91 %
Epoch 1093 of 2000 took 0.096s
  training loss:		0.299444
  validation loss:		0.389079
  validation accuracy:		89.78 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.300158
  validation loss:		0.394573
  validation accuracy:		88.37 %
Epoch 1095 of 2000 took 0.096s
  training loss:		0.290243
  validation loss:		0.389069
  validation accuracy:		89.46 %
Epoch 1096 of 2000 took 0.101s
  training loss:		0.295553
  validation loss:		0.389182
  validation accuracy:		88.59 %
Epoch 1097 of 2000 took 0.098s
  training loss:		0.297903
  validation loss:		0.376183
  validation accuracy:		89.57 %
Epoch 1098 of 2000 took 0.096s
  training loss:		0.293413
  validation loss:		0.393754
  validation accuracy:		89.35 %
Epoch 1099 of 2000 took 0.102s
  training loss:		0.297631
  validation loss:		0.385300
  validation accuracy:		89.57 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.309854
  validation loss:		0.379345
  validation accuracy:		89.78 %
Epoch 1101 of 2000 took 0.096s
  training loss:		0.301815
  validation loss:		0.380947
  validation accuracy:		89.13 %
Epoch 1102 of 2000 took 0.096s
  training loss:		0.298665
  validation loss:		0.384784
  validation accuracy:		90.00 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.303667
  validation loss:		0.379080
  validation accuracy:		89.46 %
Epoch 1104 of 2000 took 0.100s
  training loss:		0.299289
  validation loss:		0.377022
  validation accuracy:		89.78 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.298457
  validation loss:		0.388475
  validation accuracy:		89.67 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.298038
  validation loss:		0.386060
  validation accuracy:		89.35 %
Epoch 1107 of 2000 took 0.102s
  training loss:		0.298512
  validation loss:		0.378247
  validation accuracy:		89.78 %
Epoch 1108 of 2000 took 0.096s
  training loss:		0.298416
  validation loss:		0.376846
  validation accuracy:		89.89 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.295930
  validation loss:		0.387705
  validation accuracy:		89.57 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.306093
  validation loss:		0.395426
  validation accuracy:		89.13 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.297673
  validation loss:		0.388911
  validation accuracy:		89.46 %
Epoch 1112 of 2000 took 0.100s
  training loss:		0.298371
  validation loss:		0.384220
  validation accuracy:		89.67 %
Epoch 1113 of 2000 took 0.096s
  training loss:		0.292050
  validation loss:		0.393027
  validation accuracy:		89.02 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.293861
  validation loss:		0.377064
  validation accuracy:		90.11 %
Epoch 1115 of 2000 took 0.102s
  training loss:		0.295023
  validation loss:		0.387184
  validation accuracy:		89.78 %
Epoch 1116 of 2000 took 0.096s
  training loss:		0.297680
  validation loss:		0.394914
  validation accuracy:		89.24 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.294865
  validation loss:		0.387430
  validation accuracy:		89.46 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.297798
  validation loss:		0.379623
  validation accuracy:		89.02 %
Epoch 1119 of 2000 took 0.099s
  training loss:		0.299386
  validation loss:		0.386738
  validation accuracy:		90.11 %
Epoch 1120 of 2000 took 0.099s
  training loss:		0.302657
  validation loss:		0.383943
  validation accuracy:		89.78 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.294965
  validation loss:		0.398640
  validation accuracy:		89.35 %
Epoch 1122 of 2000 took 0.098s
  training loss:		0.292052
  validation loss:		0.391437
  validation accuracy:		89.35 %
Epoch 1123 of 2000 took 0.100s
  training loss:		0.292958
  validation loss:		0.374958
  validation accuracy:		89.67 %
Epoch 1124 of 2000 took 0.096s
  training loss:		0.294651
  validation loss:		0.399325
  validation accuracy:		89.02 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.298334
  validation loss:		0.380147
  validation accuracy:		89.46 %
Epoch 1126 of 2000 took 0.096s
  training loss:		0.296000
  validation loss:		0.378223
  validation accuracy:		90.11 %
Epoch 1127 of 2000 took 0.101s
  training loss:		0.296154
  validation loss:		0.382894
  validation accuracy:		90.22 %
Epoch 1128 of 2000 took 0.098s
  training loss:		0.299462
  validation loss:		0.396050
  validation accuracy:		89.46 %
Epoch 1129 of 2000 took 0.096s
  training loss:		0.292802
  validation loss:		0.387577
  validation accuracy:		89.35 %
Epoch 1130 of 2000 took 0.101s
  training loss:		0.295765
  validation loss:		0.389799
  validation accuracy:		88.91 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.300562
  validation loss:		0.379704
  validation accuracy:		90.00 %
Epoch 1132 of 2000 took 0.096s
  training loss:		0.294245
  validation loss:		0.393564
  validation accuracy:		89.67 %
Epoch 1133 of 2000 took 0.096s
  training loss:		0.294605
  validation loss:		0.384674
  validation accuracy:		89.78 %
Epoch 1134 of 2000 took 0.096s
  training loss:		0.295453
  validation loss:		0.392611
  validation accuracy:		89.57 %
Epoch 1135 of 2000 took 0.100s
  training loss:		0.304001
  validation loss:		0.390971
  validation accuracy:		89.57 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.311604
  validation loss:		0.387228
  validation accuracy:		89.89 %
Epoch 1137 of 2000 took 0.096s
  training loss:		0.300443
  validation loss:		0.382318
  validation accuracy:		90.33 %
Epoch 1138 of 2000 took 0.103s
  training loss:		0.298272
  validation loss:		0.417530
  validation accuracy:		88.48 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.294861
  validation loss:		0.398402
  validation accuracy:		89.24 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.295602
  validation loss:		0.417173
  validation accuracy:		88.04 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.295395
  validation loss:		0.391427
  validation accuracy:		88.91 %
Epoch 1142 of 2000 took 0.098s
  training loss:		0.294854
  validation loss:		0.386785
  validation accuracy:		89.67 %
Epoch 1143 of 2000 took 0.100s
  training loss:		0.300359
  validation loss:		0.392355
  validation accuracy:		89.89 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.291553
  validation loss:		0.390259
  validation accuracy:		89.13 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.299044
  validation loss:		0.415314
  validation accuracy:		88.48 %
Epoch 1146 of 2000 took 0.102s
  training loss:		0.299442
  validation loss:		0.376533
  validation accuracy:		90.33 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.292873
  validation loss:		0.385972
  validation accuracy:		89.24 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.298699
  validation loss:		0.382674
  validation accuracy:		90.54 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.306368
  validation loss:		0.388015
  validation accuracy:		89.13 %
Epoch 1150 of 2000 took 0.099s
  training loss:		0.296632
  validation loss:		0.381655
  validation accuracy:		90.22 %
Epoch 1151 of 2000 took 0.098s
  training loss:		0.300869
  validation loss:		0.400325
  validation accuracy:		89.13 %
Epoch 1152 of 2000 took 0.096s
  training loss:		0.293645
  validation loss:		0.389131
  validation accuracy:		89.78 %
Epoch 1153 of 2000 took 0.099s
  training loss:		0.295799
  validation loss:		0.376210
  validation accuracy:		89.57 %
Epoch 1154 of 2000 took 0.099s
  training loss:		0.297965
  validation loss:		0.384029
  validation accuracy:		89.57 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.294087
  validation loss:		0.380462
  validation accuracy:		89.78 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.295901
  validation loss:		0.386158
  validation accuracy:		89.89 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.297342
  validation loss:		0.386873
  validation accuracy:		89.67 %
Epoch 1158 of 2000 took 0.101s
  training loss:		0.296724
  validation loss:		0.383470
  validation accuracy:		89.89 %
Epoch 1159 of 2000 took 0.098s
  training loss:		0.301412
  validation loss:		0.402212
  validation accuracy:		89.24 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.297308
  validation loss:		0.391287
  validation accuracy:		90.11 %
Epoch 1161 of 2000 took 0.102s
  training loss:		0.296762
  validation loss:		0.390917
  validation accuracy:		90.00 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.293994
  validation loss:		0.385721
  validation accuracy:		90.11 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.295240
  validation loss:		0.387098
  validation accuracy:		89.78 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.290489
  validation loss:		0.380955
  validation accuracy:		89.89 %
Epoch 1165 of 2000 took 0.097s
  training loss:		0.294557
  validation loss:		0.386542
  validation accuracy:		90.33 %
Epoch 1166 of 2000 took 0.100s
  training loss:		0.287495
  validation loss:		0.384313
  validation accuracy:		90.00 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.291416
  validation loss:		0.373545
  validation accuracy:		89.13 %
Epoch 1168 of 2000 took 0.096s
  training loss:		0.297256
  validation loss:		0.402604
  validation accuracy:		88.91 %
Epoch 1169 of 2000 took 0.102s
  training loss:		0.294003
  validation loss:		0.382604
  validation accuracy:		90.00 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.297034
  validation loss:		0.390743
  validation accuracy:		89.57 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.297752
  validation loss:		0.391455
  validation accuracy:		89.57 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.294799
  validation loss:		0.381274
  validation accuracy:		89.78 %
Epoch 1173 of 2000 took 0.098s
  training loss:		0.297274
  validation loss:		0.385787
  validation accuracy:		89.57 %
Epoch 1174 of 2000 took 0.100s
  training loss:		0.297369
  validation loss:		0.381032
  validation accuracy:		90.00 %
Epoch 1175 of 2000 took 0.101s
  training loss:		0.294483
  validation loss:		0.391626
  validation accuracy:		89.67 %
Epoch 1176 of 2000 took 0.100s
  training loss:		0.289155
  validation loss:		0.386068
  validation accuracy:		89.57 %
Epoch 1177 of 2000 took 0.105s
  training loss:		0.296486
  validation loss:		0.382594
  validation accuracy:		88.80 %
Epoch 1178 of 2000 took 0.099s
  training loss:		0.295539
  validation loss:		0.385805
  validation accuracy:		89.78 %
Epoch 1179 of 2000 took 0.100s
  training loss:		0.293909
  validation loss:		0.388250
  validation accuracy:		89.67 %
Epoch 1180 of 2000 took 0.099s
  training loss:		0.297112
  validation loss:		0.387875
  validation accuracy:		90.00 %
Epoch 1181 of 2000 took 0.102s
  training loss:		0.300829
  validation loss:		0.401615
  validation accuracy:		89.78 %
Epoch 1182 of 2000 took 0.102s
  training loss:		0.296929
  validation loss:		0.383402
  validation accuracy:		89.24 %
Epoch 1183 of 2000 took 0.099s
  training loss:		0.297432
  validation loss:		0.385610
  validation accuracy:		89.89 %
Epoch 1184 of 2000 took 0.101s
  training loss:		0.294545
  validation loss:		0.388109
  validation accuracy:		90.22 %
Epoch 1185 of 2000 took 0.103s
  training loss:		0.301739
  validation loss:		0.395776
  validation accuracy:		89.35 %
Epoch 1186 of 2000 took 0.099s
  training loss:		0.293307
  validation loss:		0.375448
  validation accuracy:		89.46 %
Epoch 1187 of 2000 took 0.100s
  training loss:		0.291703
  validation loss:		0.397718
  validation accuracy:		89.46 %
Epoch 1188 of 2000 took 0.099s
  training loss:		0.294740
  validation loss:		0.386597
  validation accuracy:		90.11 %
Epoch 1189 of 2000 took 0.102s
  training loss:		0.290963
  validation loss:		0.379941
  validation accuracy:		90.11 %
Epoch 1190 of 2000 took 0.097s
  training loss:		0.290678
  validation loss:		0.404330
  validation accuracy:		89.24 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.301048
  validation loss:		0.389139
  validation accuracy:		90.00 %
Epoch 1192 of 2000 took 0.102s
  training loss:		0.292314
  validation loss:		0.396419
  validation accuracy:		89.57 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.301072
  validation loss:		0.404677
  validation accuracy:		89.35 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.293053
  validation loss:		0.399317
  validation accuracy:		89.57 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.295911
  validation loss:		0.383216
  validation accuracy:		89.57 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.294672
  validation loss:		0.390040
  validation accuracy:		89.89 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.291330
  validation loss:		0.382682
  validation accuracy:		89.89 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.296917
  validation loss:		0.411926
  validation accuracy:		88.37 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.286776
  validation loss:		0.381969
  validation accuracy:		89.67 %
Epoch 1200 of 2000 took 0.102s
  training loss:		0.293821
  validation loss:		0.443504
  validation accuracy:		87.17 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.302535
  validation loss:		0.394575
  validation accuracy:		89.35 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.287488
  validation loss:		0.412524
  validation accuracy:		89.35 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.299713
  validation loss:		0.388883
  validation accuracy:		89.57 %
Epoch 1204 of 2000 took 0.098s
  training loss:		0.289777
  validation loss:		0.397963
  validation accuracy:		89.46 %
Epoch 1205 of 2000 took 0.100s
  training loss:		0.296684
  validation loss:		0.379988
  validation accuracy:		89.46 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.292574
  validation loss:		0.384310
  validation accuracy:		89.78 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.293910
  validation loss:		0.391026
  validation accuracy:		90.11 %
Epoch 1208 of 2000 took 0.102s
  training loss:		0.295332
  validation loss:		0.415292
  validation accuracy:		87.83 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.300890
  validation loss:		0.414851
  validation accuracy:		88.70 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.297454
  validation loss:		0.380646
  validation accuracy:		89.57 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.296740
  validation loss:		0.379416
  validation accuracy:		89.57 %
Epoch 1212 of 2000 took 0.098s
  training loss:		0.294726
  validation loss:		0.388667
  validation accuracy:		90.00 %
Epoch 1213 of 2000 took 0.099s
  training loss:		0.293246
  validation loss:		0.383874
  validation accuracy:		90.00 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.293896
  validation loss:		0.392730
  validation accuracy:		89.35 %
Epoch 1215 of 2000 took 0.098s
  training loss:		0.291011
  validation loss:		0.387408
  validation accuracy:		90.00 %
Epoch 1216 of 2000 took 0.100s
  training loss:		0.293818
  validation loss:		0.385256
  validation accuracy:		90.00 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.294002
  validation loss:		0.382849
  validation accuracy:		89.89 %
Epoch 1218 of 2000 took 0.097s
  training loss:		0.296208
  validation loss:		0.384122
  validation accuracy:		90.11 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.294965
  validation loss:		0.418084
  validation accuracy:		89.35 %
Epoch 1220 of 2000 took 0.101s
  training loss:		0.292338
  validation loss:		0.387388
  validation accuracy:		89.78 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.291195
  validation loss:		0.410512
  validation accuracy:		89.24 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.288808
  validation loss:		0.390249
  validation accuracy:		89.89 %
Epoch 1223 of 2000 took 0.101s
  training loss:		0.294370
  validation loss:		0.390693
  validation accuracy:		89.67 %
Epoch 1224 of 2000 took 0.098s
  training loss:		0.298019
  validation loss:		0.388853
  validation accuracy:		89.78 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.304666
  validation loss:		0.380878
  validation accuracy:		88.80 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.292203
  validation loss:		0.380792
  validation accuracy:		89.57 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.285131
  validation loss:		0.400665
  validation accuracy:		89.57 %
Epoch 1228 of 2000 took 0.100s
  training loss:		0.286604
  validation loss:		0.382218
  validation accuracy:		89.78 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.286844
  validation loss:		0.404637
  validation accuracy:		89.46 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.298938
  validation loss:		0.387594
  validation accuracy:		89.89 %
Epoch 1231 of 2000 took 0.102s
  training loss:		0.287477
  validation loss:		0.389521
  validation accuracy:		90.00 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.288549
  validation loss:		0.390409
  validation accuracy:		89.67 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.294870
  validation loss:		0.394101
  validation accuracy:		89.57 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.293304
  validation loss:		0.387994
  validation accuracy:		89.78 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.294594
  validation loss:		0.383933
  validation accuracy:		89.78 %
Epoch 1236 of 2000 took 0.100s
  training loss:		0.298181
  validation loss:		0.385948
  validation accuracy:		89.57 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.292768
  validation loss:		0.388231
  validation accuracy:		90.00 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.298588
  validation loss:		0.383136
  validation accuracy:		89.78 %
Epoch 1239 of 2000 took 0.103s
  training loss:		0.297521
  validation loss:		0.390758
  validation accuracy:		89.46 %
Epoch 1240 of 2000 took 0.096s
  training loss:		0.292452
  validation loss:		0.390177
  validation accuracy:		90.11 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.288034
  validation loss:		0.400863
  validation accuracy:		89.67 %
Epoch 1242 of 2000 took 0.096s
  training loss:		0.294700
  validation loss:		0.384634
  validation accuracy:		89.89 %
Epoch 1243 of 2000 took 0.098s
  training loss:		0.292500
  validation loss:		0.381474
  validation accuracy:		89.78 %
Epoch 1244 of 2000 took 0.100s
  training loss:		0.292996
  validation loss:		0.388810
  validation accuracy:		89.67 %
Epoch 1245 of 2000 took 0.096s
  training loss:		0.291956
  validation loss:		0.380042
  validation accuracy:		89.89 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.284301
  validation loss:		0.393312
  validation accuracy:		89.67 %
Epoch 1247 of 2000 took 0.101s
  training loss:		0.293194
  validation loss:		0.401274
  validation accuracy:		89.78 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.291463
  validation loss:		0.378302
  validation accuracy:		89.89 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.292238
  validation loss:		0.378974
  validation accuracy:		90.11 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.289794
  validation loss:		0.403183
  validation accuracy:		89.35 %
Epoch 1251 of 2000 took 0.101s
  training loss:		0.297967
  validation loss:		0.392723
  validation accuracy:		89.89 %
Epoch 1252 of 2000 took 0.098s
  training loss:		0.291460
  validation loss:		0.410623
  validation accuracy:		89.02 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.296656
  validation loss:		0.382873
  validation accuracy:		90.22 %
Epoch 1254 of 2000 took 0.100s
  training loss:		0.288450
  validation loss:		0.387228
  validation accuracy:		88.48 %
Epoch 1255 of 2000 took 0.098s
  training loss:		0.291590
  validation loss:		0.383611
  validation accuracy:		90.00 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.292692
  validation loss:		0.394257
  validation accuracy:		89.78 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.294401
  validation loss:		0.392461
  validation accuracy:		89.78 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.287948
  validation loss:		0.382393
  validation accuracy:		89.57 %
Epoch 1259 of 2000 took 0.100s
  training loss:		0.292430
  validation loss:		0.379768
  validation accuracy:		90.00 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.287031
  validation loss:		0.390923
  validation accuracy:		89.78 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.291515
  validation loss:		0.391976
  validation accuracy:		89.57 %
Epoch 1262 of 2000 took 0.102s
  training loss:		0.297225
  validation loss:		0.386052
  validation accuracy:		89.57 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.292660
  validation loss:		0.392854
  validation accuracy:		89.46 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.297791
  validation loss:		0.383720
  validation accuracy:		89.78 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.291775
  validation loss:		0.382149
  validation accuracy:		90.11 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.292688
  validation loss:		0.381664
  validation accuracy:		90.33 %
Epoch 1267 of 2000 took 0.100s
  training loss:		0.294990
  validation loss:		0.381314
  validation accuracy:		89.24 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.295481
  validation loss:		0.401569
  validation accuracy:		89.57 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.288856
  validation loss:		0.387047
  validation accuracy:		89.89 %
Epoch 1270 of 2000 took 0.102s
  training loss:		0.284555
  validation loss:		0.385190
  validation accuracy:		90.22 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.290124
  validation loss:		0.390666
  validation accuracy:		89.78 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.296086
  validation loss:		0.394616
  validation accuracy:		89.57 %
Epoch 1273 of 2000 took 0.096s
  training loss:		0.293227
  validation loss:		0.385896
  validation accuracy:		89.78 %
Epoch 1274 of 2000 took 0.098s
  training loss:		0.288942
  validation loss:		0.387298
  validation accuracy:		90.00 %
Epoch 1275 of 2000 took 0.100s
  training loss:		0.287775
  validation loss:		0.396254
  validation accuracy:		89.57 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.289026
  validation loss:		0.389650
  validation accuracy:		89.67 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.287461
  validation loss:		0.381768
  validation accuracy:		89.78 %
Epoch 1278 of 2000 took 0.102s
  training loss:		0.291766
  validation loss:		0.405987
  validation accuracy:		89.24 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.284523
  validation loss:		0.386753
  validation accuracy:		89.67 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.292864
  validation loss:		0.382396
  validation accuracy:		89.78 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.286162
  validation loss:		0.383376
  validation accuracy:		89.57 %
Epoch 1282 of 2000 took 0.101s
  training loss:		0.287371
  validation loss:		0.388036
  validation accuracy:		89.78 %
Epoch 1283 of 2000 took 0.098s
  training loss:		0.299531
  validation loss:		0.382186
  validation accuracy:		89.67 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.298349
  validation loss:		0.390083
  validation accuracy:		89.67 %
Epoch 1285 of 2000 took 0.100s
  training loss:		0.296542
  validation loss:		0.388303
  validation accuracy:		89.78 %
Epoch 1286 of 2000 took 0.098s
  training loss:		0.290903
  validation loss:		0.398187
  validation accuracy:		88.80 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.291229
  validation loss:		0.378430
  validation accuracy:		89.89 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.279072
  validation loss:		0.393957
  validation accuracy:		89.57 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.291825
  validation loss:		0.386204
  validation accuracy:		89.78 %
Epoch 1290 of 2000 took 0.100s
  training loss:		0.291950
  validation loss:		0.392168
  validation accuracy:		89.67 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.296637
  validation loss:		0.386058
  validation accuracy:		89.67 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.294591
  validation loss:		0.382221
  validation accuracy:		89.89 %
Epoch 1293 of 2000 took 0.102s
  training loss:		0.287595
  validation loss:		0.392287
  validation accuracy:		89.78 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.286396
  validation loss:		0.380612
  validation accuracy:		89.78 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.292186
  validation loss:		0.402577
  validation accuracy:		89.35 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.287600
  validation loss:		0.394047
  validation accuracy:		90.22 %
Epoch 1297 of 2000 took 0.097s
  training loss:		0.295270
  validation loss:		0.382590
  validation accuracy:		89.35 %
Epoch 1298 of 2000 took 0.100s
  training loss:		0.287866
  validation loss:		0.381670
  validation accuracy:		89.67 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.295198
  validation loss:		0.395059
  validation accuracy:		89.46 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.294322
  validation loss:		0.394320
  validation accuracy:		89.35 %
Epoch 1301 of 2000 took 0.102s
  training loss:		0.285475
  validation loss:		0.411691
  validation accuracy:		89.02 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.291275
  validation loss:		0.397360
  validation accuracy:		90.00 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.291441
  validation loss:		0.412501
  validation accuracy:		89.35 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.292043
  validation loss:		0.391004
  validation accuracy:		90.00 %
Epoch 1305 of 2000 took 0.098s
  training loss:		0.287226
  validation loss:		0.390911
  validation accuracy:		89.89 %
Epoch 1306 of 2000 took 0.099s
  training loss:		0.282242
  validation loss:		0.385709
  validation accuracy:		89.78 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.289039
  validation loss:		0.390250
  validation accuracy:		89.46 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.294048
  validation loss:		0.395497
  validation accuracy:		89.67 %
Epoch 1309 of 2000 took 0.101s
  training loss:		0.293805
  validation loss:		0.390512
  validation accuracy:		89.46 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.292143
  validation loss:		0.388444
  validation accuracy:		90.00 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.285329
  validation loss:		0.392758
  validation accuracy:		89.89 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.289851
  validation loss:		0.388929
  validation accuracy:		90.22 %
Epoch 1313 of 2000 took 0.101s
  training loss:		0.290989
  validation loss:		0.381164
  validation accuracy:		89.89 %
Epoch 1314 of 2000 took 0.098s
  training loss:		0.287390
  validation loss:		0.402172
  validation accuracy:		89.89 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.289673
  validation loss:		0.396849
  validation accuracy:		89.89 %
Epoch 1316 of 2000 took 0.101s
  training loss:		0.290950
  validation loss:		0.397753
  validation accuracy:		89.78 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.289596
  validation loss:		0.396682
  validation accuracy:		89.13 %
Epoch 1318 of 2000 took 0.096s
  training loss:		0.296192
  validation loss:		0.400857
  validation accuracy:		89.46 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.290296
  validation loss:		0.393554
  validation accuracy:		89.35 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.294057
  validation loss:		0.400787
  validation accuracy:		89.35 %
Epoch 1321 of 2000 took 0.101s
  training loss:		0.290107
  validation loss:		0.410213
  validation accuracy:		88.26 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.291548
  validation loss:		0.404974
  validation accuracy:		89.57 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.292037
  validation loss:		0.386597
  validation accuracy:		89.78 %
Epoch 1324 of 2000 took 0.102s
  training loss:		0.296556
  validation loss:		0.392661
  validation accuracy:		90.00 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.294854
  validation loss:		0.421502
  validation accuracy:		88.70 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.286875
  validation loss:		0.388878
  validation accuracy:		90.00 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.291034
  validation loss:		0.388650
  validation accuracy:		89.89 %
Epoch 1328 of 2000 took 0.097s
  training loss:		0.293621
  validation loss:		0.415483
  validation accuracy:		88.91 %
Epoch 1329 of 2000 took 0.100s
  training loss:		0.292152
  validation loss:		0.393284
  validation accuracy:		89.78 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.282882
  validation loss:		0.379919
  validation accuracy:		89.78 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.290691
  validation loss:		0.408777
  validation accuracy:		89.35 %
Epoch 1332 of 2000 took 0.102s
  training loss:		0.292478
  validation loss:		0.382342
  validation accuracy:		89.57 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.292317
  validation loss:		0.391884
  validation accuracy:		90.54 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.292249
  validation loss:		0.388616
  validation accuracy:		89.13 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.296614
  validation loss:		0.436003
  validation accuracy:		88.26 %
Epoch 1336 of 2000 took 0.098s
  training loss:		0.295866
  validation loss:		0.391842
  validation accuracy:		89.57 %
Epoch 1337 of 2000 took 0.099s
  training loss:		0.290054
  validation loss:		0.399813
  validation accuracy:		89.46 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.287394
  validation loss:		0.403649
  validation accuracy:		89.89 %
Epoch 1339 of 2000 took 0.098s
  training loss:		0.288161
  validation loss:		0.396263
  validation accuracy:		89.57 %
Epoch 1340 of 2000 took 0.101s
  training loss:		0.288115
  validation loss:		0.383897
  validation accuracy:		89.67 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.287669
  validation loss:		0.398506
  validation accuracy:		89.57 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.292309
  validation loss:		0.393244
  validation accuracy:		89.13 %
Epoch 1343 of 2000 took 0.096s
  training loss:		0.289415
  validation loss:		0.387577
  validation accuracy:		89.78 %
Epoch 1344 of 2000 took 0.101s
  training loss:		0.287749
  validation loss:		0.383084
  validation accuracy:		89.67 %
Epoch 1345 of 2000 took 0.098s
  training loss:		0.293379
  validation loss:		0.410996
  validation accuracy:		89.35 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.291450
  validation loss:		0.410739
  validation accuracy:		89.02 %
Epoch 1347 of 2000 took 0.100s
  training loss:		0.285651
  validation loss:		0.389611
  validation accuracy:		89.89 %
Epoch 1348 of 2000 took 0.098s
  training loss:		0.293441
  validation loss:		0.384943
  validation accuracy:		89.89 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.284029
  validation loss:		0.422299
  validation accuracy:		88.80 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.297999
  validation loss:		0.386279
  validation accuracy:		89.13 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.292023
  validation loss:		0.397401
  validation accuracy:		89.35 %
Epoch 1352 of 2000 took 0.101s
  training loss:		0.288358
  validation loss:		0.406206
  validation accuracy:		89.02 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.288522
  validation loss:		0.401280
  validation accuracy:		89.78 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.292258
  validation loss:		0.385562
  validation accuracy:		90.33 %
Epoch 1355 of 2000 took 0.102s
  training loss:		0.298672
  validation loss:		0.396651
  validation accuracy:		89.67 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.288967
  validation loss:		0.390526
  validation accuracy:		90.22 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.287007
  validation loss:		0.386791
  validation accuracy:		89.78 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.292326
  validation loss:		0.387182
  validation accuracy:		89.46 %
Epoch 1359 of 2000 took 0.097s
  training loss:		0.290035
  validation loss:		0.386924
  validation accuracy:		89.46 %
Epoch 1360 of 2000 took 0.100s
  training loss:		0.294379
  validation loss:		0.396312
  validation accuracy:		89.67 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.288823
  validation loss:		0.386094
  validation accuracy:		90.33 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.289453
  validation loss:		0.387697
  validation accuracy:		90.11 %
Epoch 1363 of 2000 took 0.105s
  training loss:		0.286939
  validation loss:		0.407784
  validation accuracy:		89.35 %
Epoch 1364 of 2000 took 0.099s
  training loss:		0.290463
  validation loss:		0.397024
  validation accuracy:		89.57 %
Epoch 1365 of 2000 took 0.100s
  training loss:		0.284870
  validation loss:		0.384415
  validation accuracy:		89.57 %
Epoch 1366 of 2000 took 0.099s
  training loss:		0.288912
  validation loss:		0.401520
  validation accuracy:		88.91 %
Epoch 1367 of 2000 took 0.101s
  training loss:		0.293090
  validation loss:		0.385870
  validation accuracy:		90.33 %
Epoch 1368 of 2000 took 0.103s
  training loss:		0.295938
  validation loss:		0.397807
  validation accuracy:		89.46 %
Epoch 1369 of 2000 took 0.099s
  training loss:		0.282751
  validation loss:		0.411297
  validation accuracy:		89.13 %
Epoch 1370 of 2000 took 0.100s
  training loss:		0.288248
  validation loss:		0.391705
  validation accuracy:		89.57 %
Epoch 1371 of 2000 took 0.105s
  training loss:		0.289054
  validation loss:		0.389582
  validation accuracy:		89.24 %
Epoch 1372 of 2000 took 0.099s
  training loss:		0.289222
  validation loss:		0.419396
  validation accuracy:		88.48 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.290014
  validation loss:		0.386053
  validation accuracy:		89.89 %
Epoch 1374 of 2000 took 0.096s
  training loss:		0.292635
  validation loss:		0.390254
  validation accuracy:		90.11 %
Epoch 1375 of 2000 took 0.100s
  training loss:		0.287640
  validation loss:		0.400837
  validation accuracy:		89.67 %
Epoch 1376 of 2000 took 0.098s
  training loss:		0.283757
  validation loss:		0.400383
  validation accuracy:		89.78 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.290247
  validation loss:		0.410770
  validation accuracy:		89.67 %
Epoch 1378 of 2000 took 0.101s
  training loss:		0.295474
  validation loss:		0.401087
  validation accuracy:		89.35 %
Epoch 1379 of 2000 took 0.098s
  training loss:		0.284301
  validation loss:		0.394000
  validation accuracy:		89.67 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.292455
  validation loss:		0.387934
  validation accuracy:		90.11 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.284904
  validation loss:		0.380742
  validation accuracy:		89.35 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.288804
  validation loss:		0.423989
  validation accuracy:		88.48 %
Epoch 1383 of 2000 took 0.101s
  training loss:		0.300758
  validation loss:		0.388863
  validation accuracy:		90.22 %
Epoch 1384 of 2000 took 0.097s
  training loss:		0.282278
  validation loss:		0.414865
  validation accuracy:		89.24 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.287487
  validation loss:		0.383534
  validation accuracy:		90.00 %
Epoch 1386 of 2000 took 0.102s
  training loss:		0.281837
  validation loss:		0.385028
  validation accuracy:		90.33 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.289352
  validation loss:		0.384205
  validation accuracy:		89.78 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.294747
  validation loss:		0.391268
  validation accuracy:		88.80 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.284794
  validation loss:		0.401634
  validation accuracy:		89.24 %
Epoch 1390 of 2000 took 0.097s
  training loss:		0.288102
  validation loss:		0.402467
  validation accuracy:		89.78 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.289442
  validation loss:		0.416843
  validation accuracy:		88.80 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.290843
  validation loss:		0.390523
  validation accuracy:		89.89 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.286741
  validation loss:		0.392633
  validation accuracy:		90.00 %
Epoch 1394 of 2000 took 0.102s
  training loss:		0.286158
  validation loss:		0.411445
  validation accuracy:		89.24 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.294846
  validation loss:		0.387449
  validation accuracy:		89.13 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.293042
  validation loss:		0.405390
  validation accuracy:		89.02 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.288183
  validation loss:		0.409414
  validation accuracy:		89.57 %
Epoch 1398 of 2000 took 0.098s
  training loss:		0.287388
  validation loss:		0.402393
  validation accuracy:		89.57 %
Epoch 1399 of 2000 took 0.100s
  training loss:		0.295299
  validation loss:		0.388041
  validation accuracy:		90.22 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.285555
  validation loss:		0.421606
  validation accuracy:		88.91 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.286808
  validation loss:		0.411877
  validation accuracy:		89.02 %
Epoch 1402 of 2000 took 0.101s
  training loss:		0.291031
  validation loss:		0.400194
  validation accuracy:		90.00 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.287670
  validation loss:		0.397315
  validation accuracy:		89.78 %
Epoch 1404 of 2000 took 0.097s
  training loss:		0.290584
  validation loss:		0.392991
  validation accuracy:		89.89 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.291263
  validation loss:		0.388538
  validation accuracy:		89.89 %
Epoch 1406 of 2000 took 0.101s
  training loss:		0.287653
  validation loss:		0.389838
  validation accuracy:		90.00 %
Epoch 1407 of 2000 took 0.098s
  training loss:		0.292503
  validation loss:		0.406606
  validation accuracy:		89.35 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.284505
  validation loss:		0.389689
  validation accuracy:		89.67 %
Epoch 1409 of 2000 took 0.100s
  training loss:		0.288217
  validation loss:		0.390445
  validation accuracy:		89.78 %
Epoch 1410 of 2000 took 0.098s
  training loss:		0.295217
  validation loss:		0.403890
  validation accuracy:		89.46 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.289033
  validation loss:		0.386712
  validation accuracy:		89.78 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.291354
  validation loss:		0.401690
  validation accuracy:		89.67 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.286535
  validation loss:		0.389889
  validation accuracy:		90.11 %
Epoch 1414 of 2000 took 0.101s
  training loss:		0.297046
  validation loss:		0.402439
  validation accuracy:		89.78 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.290977
  validation loss:		0.392192
  validation accuracy:		90.22 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.286741
  validation loss:		0.392286
  validation accuracy:		89.35 %
Epoch 1417 of 2000 took 0.102s
  training loss:		0.287790
  validation loss:		0.399737
  validation accuracy:		89.67 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.290478
  validation loss:		0.398895
  validation accuracy:		89.24 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.287573
  validation loss:		0.390069
  validation accuracy:		89.67 %
Epoch 1420 of 2000 took 0.096s
  training loss:		0.296885
  validation loss:		0.397564
  validation accuracy:		89.78 %
Epoch 1421 of 2000 took 0.097s
  training loss:		0.282395
  validation loss:		0.383153
  validation accuracy:		89.67 %
Epoch 1422 of 2000 took 0.100s
  training loss:		0.290261
  validation loss:		0.384081
  validation accuracy:		89.13 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.288784
  validation loss:		0.381439
  validation accuracy:		89.89 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.283872
  validation loss:		0.408124
  validation accuracy:		89.46 %
Epoch 1425 of 2000 took 0.102s
  training loss:		0.280651
  validation loss:		0.403741
  validation accuracy:		89.24 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.288390
  validation loss:		0.396172
  validation accuracy:		89.89 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.287794
  validation loss:		0.390606
  validation accuracy:		89.13 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.291315
  validation loss:		0.382257
  validation accuracy:		89.78 %
Epoch 1429 of 2000 took 0.098s
  training loss:		0.293205
  validation loss:		0.386474
  validation accuracy:		89.13 %
Epoch 1430 of 2000 took 0.099s
  training loss:		0.287459
  validation loss:		0.389894
  validation accuracy:		89.57 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.289304
  validation loss:		0.385271
  validation accuracy:		89.89 %
Epoch 1432 of 2000 took 0.098s
  training loss:		0.292100
  validation loss:		0.392653
  validation accuracy:		90.11 %
Epoch 1433 of 2000 took 0.101s
  training loss:		0.285835
  validation loss:		0.385563
  validation accuracy:		89.78 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.291993
  validation loss:		0.389503
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.289828
  validation loss:		0.398732
  validation accuracy:		90.00 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.287750
  validation loss:		0.408796
  validation accuracy:		89.35 %
Epoch 1437 of 2000 took 0.101s
  training loss:		0.285797
  validation loss:		0.403701
  validation accuracy:		89.89 %
Epoch 1438 of 2000 took 0.098s
  training loss:		0.291863
  validation loss:		0.394617
  validation accuracy:		89.89 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.287714
  validation loss:		0.395120
  validation accuracy:		89.78 %
Epoch 1440 of 2000 took 0.100s
  training loss:		0.283316
  validation loss:		0.388064
  validation accuracy:		89.57 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.287530
  validation loss:		0.400611
  validation accuracy:		89.89 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.278095
  validation loss:		0.391388
  validation accuracy:		89.89 %
Epoch 1443 of 2000 took 0.099s
  training loss:		0.293500
  validation loss:		0.402384
  validation accuracy:		89.89 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.296188
  validation loss:		0.386355
  validation accuracy:		90.33 %
Epoch 1445 of 2000 took 0.100s
  training loss:		0.287509
  validation loss:		0.389053
  validation accuracy:		90.33 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.288198
  validation loss:		0.397846
  validation accuracy:		89.78 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.291678
  validation loss:		0.396283
  validation accuracy:		90.00 %
Epoch 1448 of 2000 took 0.098s
  training loss:		0.284143
  validation loss:		0.399458
  validation accuracy:		89.57 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.286211
  validation loss:		0.389704
  validation accuracy:		89.67 %
Epoch 1450 of 2000 took 0.099s
  training loss:		0.286197
  validation loss:		0.396330
  validation accuracy:		89.67 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.285145
  validation loss:		0.403675
  validation accuracy:		90.00 %
Epoch 1452 of 2000 took 0.099s
  training loss:		0.289361
  validation loss:		0.404772
  validation accuracy:		89.57 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.292958
  validation loss:		0.380712
  validation accuracy:		90.00 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.280235
  validation loss:		0.408521
  validation accuracy:		89.78 %
Epoch 1455 of 2000 took 0.099s
  training loss:		0.289572
  validation loss:		0.394034
  validation accuracy:		90.22 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.291205
  validation loss:		0.406197
  validation accuracy:		89.78 %
Epoch 1457 of 2000 took 0.100s
  training loss:		0.285748
  validation loss:		0.401065
  validation accuracy:		89.46 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.291630
  validation loss:		0.380221
  validation accuracy:		89.67 %
Epoch 1459 of 2000 took 0.097s
  training loss:		0.291002
  validation loss:		0.386556
  validation accuracy:		90.22 %
Epoch 1460 of 2000 took 0.098s
  training loss:		0.288480
  validation loss:		0.411717
  validation accuracy:		89.35 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.293780
  validation loss:		0.401947
  validation accuracy:		89.57 %
Epoch 1462 of 2000 took 0.099s
  training loss:		0.286882
  validation loss:		0.395325
  validation accuracy:		89.78 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.285841
  validation loss:		0.401927
  validation accuracy:		89.46 %
Epoch 1464 of 2000 took 0.099s
  training loss:		0.293000
  validation loss:		0.401727
  validation accuracy:		89.78 %
Epoch 1465 of 2000 took 0.097s
  training loss:		0.285830
  validation loss:		0.396203
  validation accuracy:		89.89 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.292118
  validation loss:		0.387525
  validation accuracy:		90.00 %
Epoch 1467 of 2000 took 0.099s
  training loss:		0.298273
  validation loss:		0.388729
  validation accuracy:		89.35 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.289276
  validation loss:		0.394398
  validation accuracy:		89.46 %
Epoch 1469 of 2000 took 0.101s
  training loss:		0.288025
  validation loss:		0.386738
  validation accuracy:		89.67 %
Epoch 1470 of 2000 took 0.097s
  training loss:		0.288361
  validation loss:		0.383275
  validation accuracy:		90.22 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.288557
  validation loss:		0.394796
  validation accuracy:		90.11 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.289779
  validation loss:		0.398670
  validation accuracy:		89.57 %
Epoch 1473 of 2000 took 0.097s
  training loss:		0.288539
  validation loss:		0.391008
  validation accuracy:		90.43 %
Epoch 1474 of 2000 took 0.100s
  training loss:		0.284286
  validation loss:		0.385905
  validation accuracy:		90.43 %
Epoch 1475 of 2000 took 0.097s
  training loss:		0.288227
  validation loss:		0.388560
  validation accuracy:		89.57 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.281335
  validation loss:		0.405394
  validation accuracy:		90.11 %
Epoch 1477 of 2000 took 0.102s
  training loss:		0.290637
  validation loss:		0.388281
  validation accuracy:		89.78 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.282920
  validation loss:		0.398239
  validation accuracy:		89.67 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.287285
  validation loss:		0.414892
  validation accuracy:		89.46 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.294482
  validation loss:		0.393565
  validation accuracy:		89.13 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.284646
  validation loss:		0.383479
  validation accuracy:		90.00 %
Epoch 1482 of 2000 took 0.101s
  training loss:		0.291531
  validation loss:		0.381265
  validation accuracy:		90.54 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.279574
  validation loss:		0.395828
  validation accuracy:		90.22 %
Epoch 1484 of 2000 took 0.097s
  training loss:		0.293105
  validation loss:		0.408632
  validation accuracy:		89.24 %
Epoch 1485 of 2000 took 0.102s
  training loss:		0.293260
  validation loss:		0.395012
  validation accuracy:		89.57 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.283577
  validation loss:		0.401437
  validation accuracy:		89.57 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.284674
  validation loss:		0.385422
  validation accuracy:		90.11 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.283256
  validation loss:		0.396431
  validation accuracy:		89.78 %
Epoch 1489 of 2000 took 0.099s
  training loss:		0.291380
  validation loss:		0.398812
  validation accuracy:		90.00 %
Epoch 1490 of 2000 took 0.098s
  training loss:		0.295018
  validation loss:		0.405877
  validation accuracy:		90.33 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.281251
  validation loss:		0.386912
  validation accuracy:		90.33 %
Epoch 1492 of 2000 took 0.099s
  training loss:		0.288747
  validation loss:		0.390910
  validation accuracy:		89.67 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.286629
  validation loss:		0.388071
  validation accuracy:		90.54 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.285028
  validation loss:		0.385715
  validation accuracy:		89.89 %
Epoch 1495 of 2000 took 0.097s
  training loss:		0.288056
  validation loss:		0.400492
  validation accuracy:		89.46 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.283510
  validation loss:		0.390951
  validation accuracy:		89.78 %
Epoch 1497 of 2000 took 0.101s
  training loss:		0.286662
  validation loss:		0.396236
  validation accuracy:		90.22 %
Epoch 1498 of 2000 took 0.097s
  training loss:		0.288147
  validation loss:		0.398981
  validation accuracy:		89.89 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.281033
  validation loss:		0.394221
  validation accuracy:		89.57 %
Epoch 1500 of 2000 took 0.101s
  training loss:		0.287349
  validation loss:		0.388750
  validation accuracy:		89.89 %
Epoch 1501 of 2000 took 0.097s
  training loss:		0.294756
  validation loss:		0.405446
  validation accuracy:		89.35 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.292332
  validation loss:		0.395625
  validation accuracy:		90.11 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.290195
  validation loss:		0.410529
  validation accuracy:		89.24 %
Epoch 1504 of 2000 took 0.097s
  training loss:		0.284713
  validation loss:		0.401922
  validation accuracy:		89.89 %
Epoch 1505 of 2000 took 0.100s
  training loss:		0.291533
  validation loss:		0.395297
  validation accuracy:		90.22 %
Epoch 1506 of 2000 took 0.097s
  training loss:		0.285090
  validation loss:		0.394836
  validation accuracy:		90.11 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.288772
  validation loss:		0.402789
  validation accuracy:		89.89 %
Epoch 1508 of 2000 took 0.102s
  training loss:		0.288222
  validation loss:		0.392712
  validation accuracy:		89.89 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.293267
  validation loss:		0.395656
  validation accuracy:		89.57 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.288737
  validation loss:		0.392097
  validation accuracy:		90.11 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.284654
  validation loss:		0.391249
  validation accuracy:		89.89 %
Epoch 1512 of 2000 took 0.097s
  training loss:		0.288436
  validation loss:		0.385511
  validation accuracy:		90.43 %
Epoch 1513 of 2000 took 0.100s
  training loss:		0.286339
  validation loss:		0.421299
  validation accuracy:		89.24 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.279062
  validation loss:		0.393502
  validation accuracy:		89.78 %
Epoch 1515 of 2000 took 0.097s
  training loss:		0.286005
  validation loss:		0.392524
  validation accuracy:		89.78 %
Epoch 1516 of 2000 took 0.102s
  training loss:		0.290139
  validation loss:		0.389859
  validation accuracy:		90.33 %
Epoch 1517 of 2000 took 0.096s
  training loss:		0.288813
  validation loss:		0.391137
  validation accuracy:		90.22 %
Epoch 1518 of 2000 took 0.097s
  training loss:		0.286084
  validation loss:		0.384359
  validation accuracy:		90.43 %
Epoch 1519 of 2000 took 0.096s
  training loss:		0.289424
  validation loss:		0.405480
  validation accuracy:		89.78 %
Epoch 1520 of 2000 took 0.099s
  training loss:		0.281712
  validation loss:		0.389769
  validation accuracy:		90.11 %
Epoch 1521 of 2000 took 0.098s
  training loss:		0.282564
  validation loss:		0.406053
  validation accuracy:		90.22 %
Epoch 1522 of 2000 took 0.096s
  training loss:		0.285904
  validation loss:		0.400005
  validation accuracy:		89.67 %
Epoch 1523 of 2000 took 0.102s
  training loss:		0.285038
  validation loss:		0.416623
  validation accuracy:		89.13 %
Epoch 1524 of 2000 took 0.103s
  training loss:		0.289254
  validation loss:		0.387224
  validation accuracy:		90.11 %
Epoch 1525 of 2000 took 0.099s
  training loss:		0.290907
  validation loss:		0.405736
  validation accuracy:		89.89 %
Epoch 1526 of 2000 took 0.100s
  training loss:		0.295416
  validation loss:		0.396108
  validation accuracy:		89.35 %
Epoch 1527 of 2000 took 0.099s
  training loss:		0.288571
  validation loss:		0.398490
  validation accuracy:		90.11 %
Epoch 1528 of 2000 took 0.104s
  training loss:		0.285074
  validation loss:		0.411365
  validation accuracy:		89.24 %
Epoch 1529 of 2000 took 0.100s
  training loss:		0.283127
  validation loss:		0.399915
  validation accuracy:		90.00 %
Epoch 1530 of 2000 took 0.099s
  training loss:		0.284177
  validation loss:		0.406400
  validation accuracy:		89.13 %
Epoch 1531 of 2000 took 0.105s
  training loss:		0.286182
  validation loss:		0.409717
  validation accuracy:		89.24 %
Epoch 1532 of 2000 took 0.100s
  training loss:		0.283585
  validation loss:		0.392759
  validation accuracy:		90.22 %
Epoch 1533 of 2000 took 0.099s
  training loss:		0.286115
  validation loss:		0.402319
  validation accuracy:		89.57 %
Epoch 1534 of 2000 took 0.099s
  training loss:		0.288137
  validation loss:		0.389149
  validation accuracy:		90.00 %
Epoch 1535 of 2000 took 0.100s
  training loss:		0.288410
  validation loss:		0.422379
  validation accuracy:		88.91 %
Epoch 1536 of 2000 took 0.103s
  training loss:		0.291926
  validation loss:		0.400914
  validation accuracy:		89.89 %
Epoch 1537 of 2000 took 0.100s
  training loss:		0.292252
  validation loss:		0.391555
  validation accuracy:		89.78 %
Epoch 1538 of 2000 took 0.100s
  training loss:		0.287774
  validation loss:		0.398686
  validation accuracy:		89.78 %
Epoch 1539 of 2000 took 0.105s
  training loss:		0.285602
  validation loss:		0.427978
  validation accuracy:		88.37 %
Epoch 1540 of 2000 took 0.099s
  training loss:		0.286216
  validation loss:		0.401249
  validation accuracy:		90.00 %
Epoch 1541 of 2000 took 0.100s
  training loss:		0.290604
  validation loss:		0.396456
  validation accuracy:		90.11 %
Epoch 1542 of 2000 took 0.099s
  training loss:		0.288615
  validation loss:		0.384696
  validation accuracy:		89.57 %
Epoch 1543 of 2000 took 0.101s
  training loss:		0.289329
  validation loss:		0.387475
  validation accuracy:		90.22 %
Epoch 1544 of 2000 took 0.103s
  training loss:		0.286604
  validation loss:		0.393526
  validation accuracy:		90.65 %
Epoch 1545 of 2000 took 0.099s
  training loss:		0.285940
  validation loss:		0.413988
  validation accuracy:		89.46 %
Epoch 1546 of 2000 took 0.100s
  training loss:		0.284691
  validation loss:		0.404392
  validation accuracy:		89.78 %
Epoch 1547 of 2000 took 0.105s
  training loss:		0.291775
  validation loss:		0.386768
  validation accuracy:		89.78 %
Epoch 1548 of 2000 took 0.099s
  training loss:		0.283021
  validation loss:		0.396263
  validation accuracy:		89.46 %
Epoch 1549 of 2000 took 0.100s
  training loss:		0.286716
  validation loss:		0.408462
  validation accuracy:		89.67 %
Epoch 1550 of 2000 took 0.099s
  training loss:		0.284394
  validation loss:		0.393116
  validation accuracy:		90.33 %
Epoch 1551 of 2000 took 0.103s
  training loss:		0.285287
  validation loss:		0.397315
  validation accuracy:		89.78 %
Epoch 1552 of 2000 took 0.101s
  training loss:		0.285647
  validation loss:		0.399145
  validation accuracy:		89.78 %
Epoch 1553 of 2000 took 0.099s
  training loss:		0.286283
  validation loss:		0.391188
  validation accuracy:		90.22 %
Epoch 1554 of 2000 took 0.099s
  training loss:		0.285166
  validation loss:		0.385048
  validation accuracy:		90.00 %
Epoch 1555 of 2000 took 0.099s
  training loss:		0.291039
  validation loss:		0.391998
  validation accuracy:		90.22 %
Epoch 1556 of 2000 took 0.098s
  training loss:		0.290255
  validation loss:		0.384359
  validation accuracy:		90.33 %
Epoch 1557 of 2000 took 0.097s
  training loss:		0.284955
  validation loss:		0.386597
  validation accuracy:		90.22 %
Epoch 1558 of 2000 took 0.114s
  training loss:		0.286862
  validation loss:		0.393264
  validation accuracy:		89.89 %
Epoch 1559 of 2000 took 0.119s
  training loss:		0.283917
  validation loss:		0.411814
  validation accuracy:		89.24 %
Epoch 1560 of 2000 took 0.098s
  training loss:		0.285808
  validation loss:		0.403123
  validation accuracy:		89.89 %
Epoch 1561 of 2000 took 0.098s
  training loss:		0.285127
  validation loss:		0.401598
  validation accuracy:		89.67 %
Epoch 1562 of 2000 took 0.104s
  training loss:		0.283251
  validation loss:		0.396413
  validation accuracy:		90.11 %
Epoch 1563 of 2000 took 0.098s
  training loss:		0.276838
  validation loss:		0.432020
  validation accuracy:		89.13 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.289092
  validation loss:		0.393897
  validation accuracy:		89.67 %
Epoch 1565 of 2000 took 0.097s
  training loss:		0.289014
  validation loss:		0.391936
  validation accuracy:		89.57 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.289434
  validation loss:		0.411686
  validation accuracy:		89.67 %
Epoch 1567 of 2000 took 0.100s
  training loss:		0.290002
  validation loss:		0.398045
  validation accuracy:		90.11 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.284721
  validation loss:		0.402104
  validation accuracy:		89.46 %
Epoch 1569 of 2000 took 0.097s
  training loss:		0.280656
  validation loss:		0.413713
  validation accuracy:		88.70 %
Epoch 1570 of 2000 took 0.103s
  training loss:		0.284058
  validation loss:		0.396428
  validation accuracy:		90.00 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.287676
  validation loss:		0.392730
  validation accuracy:		90.54 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.285341
  validation loss:		0.405904
  validation accuracy:		89.57 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.285949
  validation loss:		0.397594
  validation accuracy:		89.46 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.289790
  validation loss:		0.408559
  validation accuracy:		89.35 %
Epoch 1575 of 2000 took 0.101s
  training loss:		0.283482
  validation loss:		0.392605
  validation accuracy:		89.46 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.283605
  validation loss:		0.384188
  validation accuracy:		90.22 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.285594
  validation loss:		0.386597
  validation accuracy:		89.35 %
Epoch 1578 of 2000 took 0.102s
  training loss:		0.284949
  validation loss:		0.394770
  validation accuracy:		90.33 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.285714
  validation loss:		0.387597
  validation accuracy:		90.54 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.286936
  validation loss:		0.383457
  validation accuracy:		89.67 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.271619
  validation loss:		0.395447
  validation accuracy:		90.33 %
Epoch 1582 of 2000 took 0.099s
  training loss:		0.285305
  validation loss:		0.389984
  validation accuracy:		90.33 %
Epoch 1583 of 2000 took 0.099s
  training loss:		0.282429
  validation loss:		0.396900
  validation accuracy:		89.78 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.279850
  validation loss:		0.391731
  validation accuracy:		89.46 %
Epoch 1585 of 2000 took 0.098s
  training loss:		0.284707
  validation loss:		0.388416
  validation accuracy:		90.43 %
Epoch 1586 of 2000 took 0.100s
  training loss:		0.286358
  validation loss:		0.397846
  validation accuracy:		89.57 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.285967
  validation loss:		0.400287
  validation accuracy:		89.89 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.288793
  validation loss:		0.397847
  validation accuracy:		90.22 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.289580
  validation loss:		0.387808
  validation accuracy:		90.00 %
Epoch 1590 of 2000 took 0.101s
  training loss:		0.287458
  validation loss:		0.394136
  validation accuracy:		90.43 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.285724
  validation loss:		0.422345
  validation accuracy:		88.91 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.284333
  validation loss:		0.398464
  validation accuracy:		89.89 %
Epoch 1593 of 2000 took 0.102s
  training loss:		0.272344
  validation loss:		0.402843
  validation accuracy:		89.89 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.287361
  validation loss:		0.408280
  validation accuracy:		90.11 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.279213
  validation loss:		0.409731
  validation accuracy:		89.24 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.286991
  validation loss:		0.388239
  validation accuracy:		90.33 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.290243
  validation loss:		0.398444
  validation accuracy:		89.67 %
Epoch 1598 of 2000 took 0.126s
  training loss:		0.282640
  validation loss:		0.385634
  validation accuracy:		90.11 %
Epoch 1599 of 2000 took 0.166s
  training loss:		0.294234
  validation loss:		0.402103
  validation accuracy:		89.89 %
Epoch 1600 of 2000 took 0.166s
  training loss:		0.289210
  validation loss:		0.395382
  validation accuracy:		90.11 %
Epoch 1601 of 2000 took 0.171s
  training loss:		0.280236
  validation loss:		0.412928
  validation accuracy:		89.35 %
Epoch 1602 of 2000 took 0.165s
  training loss:		0.284370
  validation loss:		0.424327
  validation accuracy:		88.70 %
Epoch 1603 of 2000 took 0.166s
  training loss:		0.282118
  validation loss:		0.413619
  validation accuracy:		89.57 %
Epoch 1604 of 2000 took 0.165s
  training loss:		0.281716
  validation loss:		0.400144
  validation accuracy:		89.46 %
Epoch 1605 of 2000 took 0.169s
  training loss:		0.284585
  validation loss:		0.390553
  validation accuracy:		89.35 %
Epoch 1606 of 2000 took 0.167s
  training loss:		0.278918
  validation loss:		0.390302
  validation accuracy:		90.43 %
Epoch 1607 of 2000 took 0.165s
  training loss:		0.284024
  validation loss:		0.410772
  validation accuracy:		88.59 %
Epoch 1608 of 2000 took 0.170s
  training loss:		0.285486
  validation loss:		0.417682
  validation accuracy:		88.80 %
Epoch 1609 of 2000 took 0.166s
  training loss:		0.282535
  validation loss:		0.396942
  validation accuracy:		90.43 %
Epoch 1610 of 2000 took 0.166s
  training loss:		0.283888
  validation loss:		0.388507
  validation accuracy:		90.65 %
Epoch 1611 of 2000 took 0.165s
  training loss:		0.285154
  validation loss:		0.392163
  validation accuracy:		90.76 %
Epoch 1612 of 2000 took 0.166s
  training loss:		0.286078
  validation loss:		0.415497
  validation accuracy:		88.70 %
Epoch 1613 of 2000 took 0.176s
  training loss:		0.288322
  validation loss:		0.394443
  validation accuracy:		89.89 %
Epoch 1614 of 2000 took 0.172s
  training loss:		0.290906
  validation loss:		0.405962
  validation accuracy:		90.00 %
Epoch 1615 of 2000 took 0.172s
  training loss:		0.292766
  validation loss:		0.393531
  validation accuracy:		90.43 %
Epoch 1616 of 2000 took 0.179s
  training loss:		0.287405
  validation loss:		0.399685
  validation accuracy:		89.78 %
Epoch 1617 of 2000 took 0.172s
  training loss:		0.290601
  validation loss:		0.392727
  validation accuracy:		89.46 %
Epoch 1618 of 2000 took 0.172s
  training loss:		0.282479
  validation loss:		0.401262
  validation accuracy:		89.57 %
Epoch 1619 of 2000 took 0.171s
  training loss:		0.279396
  validation loss:		0.394116
  validation accuracy:		89.13 %
Epoch 1620 of 2000 took 0.191s
  training loss:		0.286295
  validation loss:		0.412446
  validation accuracy:		89.46 %
Epoch 1621 of 2000 took 0.178s
  training loss:		0.290193
  validation loss:		0.400694
  validation accuracy:		89.89 %
Epoch 1622 of 2000 took 0.171s
  training loss:		0.280998
  validation loss:		0.400458
  validation accuracy:		90.00 %
Epoch 1623 of 2000 took 0.174s
  training loss:		0.286556
  validation loss:		0.390293
  validation accuracy:		90.11 %
Epoch 1624 of 2000 took 0.178s
  training loss:		0.282295
  validation loss:		0.391538
  validation accuracy:		89.78 %
Epoch 1625 of 2000 took 0.170s
  training loss:		0.285781
  validation loss:		0.398721
  validation accuracy:		89.46 %
Epoch 1626 of 2000 took 0.173s
  training loss:		0.280811
  validation loss:		0.385681
  validation accuracy:		90.22 %
Epoch 1627 of 2000 took 0.170s
  training loss:		0.281976
  validation loss:		0.416700
  validation accuracy:		89.67 %
Epoch 1628 of 2000 took 0.179s
  training loss:		0.288660
  validation loss:		0.417856
  validation accuracy:		89.57 %
Epoch 1629 of 2000 took 0.173s
  training loss:		0.285028
  validation loss:		0.406717
  validation accuracy:		90.33 %
Epoch 1630 of 2000 took 0.170s
  training loss:		0.281761
  validation loss:		0.389538
  validation accuracy:		90.11 %
Epoch 1631 of 2000 took 0.196s
  training loss:		0.288532
  validation loss:		0.396491
  validation accuracy:		90.11 %
Epoch 1632 of 2000 took 0.174s
  training loss:		0.279264
  validation loss:		0.411193
  validation accuracy:		88.91 %
Epoch 1633 of 2000 took 0.259s
  training loss:		0.279007
  validation loss:		0.398486
  validation accuracy:		90.11 %
Epoch 1634 of 2000 took 0.175s
  training loss:		0.281787
  validation loss:		0.408441
  validation accuracy:		89.78 %
Epoch 1635 of 2000 took 0.360s
  training loss:		0.283011
  validation loss:		0.385717
  validation accuracy:		89.67 %
Epoch 1636 of 2000 took 0.217s
  training loss:		0.280670
  validation loss:		0.389442
  validation accuracy:		90.43 %
Epoch 1637 of 2000 took 0.237s
  training loss:		0.281826
  validation loss:		0.400613
  validation accuracy:		89.89 %
Epoch 1638 of 2000 took 0.258s
  training loss:		0.281907
  validation loss:		0.390774
  validation accuracy:		89.35 %
Epoch 1639 of 2000 took 0.169s
  training loss:		0.286449
  validation loss:		0.423656
  validation accuracy:		88.91 %
Epoch 1640 of 2000 took 0.178s
  training loss:		0.281715
  validation loss:		0.397322
  validation accuracy:		90.11 %
Epoch 1641 of 2000 took 0.174s
  training loss:		0.287524
  validation loss:		0.398495
  validation accuracy:		90.00 %
Epoch 1642 of 2000 took 0.172s
  training loss:		0.281458
  validation loss:		0.401836
  validation accuracy:		89.67 %
Epoch 1643 of 2000 took 0.178s
  training loss:		0.282617
  validation loss:		0.396354
  validation accuracy:		90.43 %
Epoch 1644 of 2000 took 0.171s
  training loss:		0.291981
  validation loss:		0.414587
  validation accuracy:		89.13 %
Epoch 1645 of 2000 took 0.173s
  training loss:		0.282010
  validation loss:		0.393023
  validation accuracy:		90.33 %
Epoch 1646 of 2000 took 0.170s
  training loss:		0.283222
  validation loss:		0.405998
  validation accuracy:		90.22 %
Epoch 1647 of 2000 took 0.174s
  training loss:		0.282427
  validation loss:		0.388609
  validation accuracy:		90.22 %
Epoch 1648 of 2000 took 0.178s
  training loss:		0.285061
  validation loss:		0.395244
  validation accuracy:		89.24 %
Epoch 1649 of 2000 took 0.171s
  training loss:		0.276441
  validation loss:		0.394349
  validation accuracy:		90.11 %
Epoch 1650 of 2000 took 0.171s
  training loss:		0.289576
  validation loss:		0.414812
  validation accuracy:		89.46 %
Epoch 1651 of 2000 took 0.177s
  training loss:		0.288650
  validation loss:		0.395748
  validation accuracy:		90.33 %
Epoch 1652 of 2000 took 0.225s
  training loss:		0.280780
  validation loss:		0.397930
  validation accuracy:		89.89 %
Epoch 1653 of 2000 took 0.216s
  training loss:		0.275977
  validation loss:		0.413374
  validation accuracy:		90.00 %
Epoch 1654 of 2000 took 0.175s
  training loss:		0.293288
  validation loss:		0.396084
  validation accuracy:		90.65 %
Epoch 1655 of 2000 took 0.177s
  training loss:		0.287471
  validation loss:		0.389420
  validation accuracy:		89.57 %
Epoch 1656 of 2000 took 0.170s
  training loss:		0.291446
  validation loss:		0.390050
  validation accuracy:		90.33 %
Epoch 1657 of 2000 took 0.177s
  training loss:		0.285305
  validation loss:		0.437303
  validation accuracy:		88.04 %
Epoch 1658 of 2000 took 0.175s
  training loss:		0.284219
  validation loss:		0.400456
  validation accuracy:		89.35 %
Epoch 1659 of 2000 took 0.172s
  training loss:		0.293277
  validation loss:		0.390624
  validation accuracy:		89.57 %
Epoch 1660 of 2000 took 0.173s
  training loss:		0.280656
  validation loss:		0.394601
  validation accuracy:		90.33 %
Epoch 1661 of 2000 took 0.172s
  training loss:		0.279289
  validation loss:		0.409384
  validation accuracy:		89.35 %
Epoch 1662 of 2000 took 0.187s
  training loss:		0.285528
  validation loss:		0.387271
  validation accuracy:		90.00 %
Epoch 1663 of 2000 took 0.200s
  training loss:		0.288733
  validation loss:		0.390536
  validation accuracy:		89.89 %
Epoch 1664 of 2000 took 0.169s
  training loss:		0.285222
  validation loss:		0.392834
  validation accuracy:		90.76 %
Epoch 1665 of 2000 took 0.170s
  training loss:		0.286053
  validation loss:		0.385553
  validation accuracy:		90.22 %
Epoch 1666 of 2000 took 0.164s
  training loss:		0.283628
  validation loss:		0.387836
  validation accuracy:		89.57 %
Epoch 1667 of 2000 took 0.165s
  training loss:		0.278822
  validation loss:		0.401688
  validation accuracy:		90.22 %
Epoch 1668 of 2000 took 0.164s
  training loss:		0.287660
  validation loss:		0.401390
  validation accuracy:		90.33 %
Epoch 1669 of 2000 took 0.168s
  training loss:		0.286449
  validation loss:		0.385429
  validation accuracy:		89.13 %
Epoch 1670 of 2000 took 0.167s
  training loss:		0.290084
  validation loss:		0.392161
  validation accuracy:		90.33 %
Epoch 1671 of 2000 took 0.164s
  training loss:		0.274607
  validation loss:		0.388595
  validation accuracy:		90.22 %
Epoch 1672 of 2000 took 0.217s
  training loss:		0.288418
  validation loss:		0.387938
  validation accuracy:		89.46 %
Epoch 1673 of 2000 took 0.165s
  training loss:		0.283400
  validation loss:		0.387294
  validation accuracy:		89.57 %
Epoch 1674 of 2000 took 0.166s
  training loss:		0.276264
  validation loss:		0.391591
  validation accuracy:		90.54 %
Epoch 1675 of 2000 took 0.226s
  training loss:		0.278592
  validation loss:		0.396978
  validation accuracy:		89.67 %
Epoch 1676 of 2000 took 0.169s
  training loss:		0.295167
  validation loss:		0.392412
  validation accuracy:		90.87 %
Epoch 1677 of 2000 took 0.168s
  training loss:		0.280197
  validation loss:		0.394950
  validation accuracy:		90.22 %
Epoch 1678 of 2000 took 0.165s
  training loss:		0.279565
  validation loss:		0.398376
  validation accuracy:		90.22 %
Epoch 1679 of 2000 took 0.170s
  training loss:		0.283306
  validation loss:		0.392972
  validation accuracy:		90.11 %
Epoch 1680 of 2000 took 0.167s
  training loss:		0.286945
  validation loss:		0.405850
  validation accuracy:		89.67 %
Epoch 1681 of 2000 took 0.165s
  training loss:		0.279466
  validation loss:		0.414820
  validation accuracy:		90.00 %
Epoch 1682 of 2000 took 0.165s
  training loss:		0.277678
  validation loss:		0.397598
  validation accuracy:		90.33 %
Epoch 1683 of 2000 took 0.165s
  training loss:		0.289716
  validation loss:		0.407336
  validation accuracy:		90.00 %
Epoch 1684 of 2000 took 0.169s
  training loss:		0.281534
  validation loss:		0.398646
  validation accuracy:		90.22 %
Epoch 1685 of 2000 took 0.165s
  training loss:		0.282443
  validation loss:		0.394665
  validation accuracy:		90.00 %
Epoch 1686 of 2000 took 0.165s
  training loss:		0.287585
  validation loss:		0.401082
  validation accuracy:		90.43 %
Epoch 1687 of 2000 took 0.170s
  training loss:		0.280981
  validation loss:		0.400822
  validation accuracy:		90.43 %
Epoch 1688 of 2000 took 0.164s
  training loss:		0.284115
  validation loss:		0.415862
  validation accuracy:		89.89 %
Epoch 1689 of 2000 took 0.166s
  training loss:		0.282773
  validation loss:		0.389838
  validation accuracy:		90.33 %
Epoch 1690 of 2000 took 0.164s
  training loss:		0.280681
  validation loss:		0.396150
  validation accuracy:		90.54 %
Epoch 1691 of 2000 took 0.169s
  training loss:		0.287122
  validation loss:		0.398624
  validation accuracy:		90.54 %
Epoch 1692 of 2000 took 0.166s
  training loss:		0.291488
  validation loss:		0.404637
  validation accuracy:		89.89 %
Epoch 1693 of 2000 took 0.164s
  training loss:		0.278874
  validation loss:		0.404946
  validation accuracy:		89.89 %
Epoch 1694 of 2000 took 0.170s
  training loss:		0.286911
  validation loss:		0.417126
  validation accuracy:		89.46 %
Epoch 1695 of 2000 took 0.181s
  training loss:		0.286533
  validation loss:		0.404078
  validation accuracy:		90.43 %
Epoch 1696 of 2000 took 0.166s
  training loss:		0.278785
  validation loss:		0.408438
  validation accuracy:		89.67 %
Epoch 1697 of 2000 took 0.165s
  training loss:		0.281563
  validation loss:		0.400649
  validation accuracy:		89.78 %
Epoch 1698 of 2000 took 0.167s
  training loss:		0.289923
  validation loss:		0.409147
  validation accuracy:		90.11 %
Epoch 1699 of 2000 took 0.229s
  training loss:		0.277615
  validation loss:		0.400147
  validation accuracy:		90.00 %
Epoch 1700 of 2000 took 0.167s
  training loss:		0.289202
  validation loss:		0.413952
  validation accuracy:		89.13 %
Epoch 1701 of 2000 took 0.206s
  training loss:		0.272363
  validation loss:		0.395083
  validation accuracy:		89.78 %
Epoch 1702 of 2000 took 0.257s
  training loss:		0.280183
  validation loss:		0.392571
  validation accuracy:		89.89 %
Epoch 1703 of 2000 took 0.215s
  training loss:		0.278429
  validation loss:		0.394514
  validation accuracy:		90.00 %
Epoch 1704 of 2000 took 0.245s
  training loss:		0.283044
  validation loss:		0.389133
  validation accuracy:		90.43 %
Epoch 1705 of 2000 took 0.167s
  training loss:		0.280061
  validation loss:		0.410463
  validation accuracy:		89.46 %
Epoch 1706 of 2000 took 0.165s
  training loss:		0.279752
  validation loss:		0.396871
  validation accuracy:		90.22 %
Epoch 1707 of 2000 took 0.171s
  training loss:		0.281457
  validation loss:		0.407602
  validation accuracy:		90.00 %
Epoch 1708 of 2000 took 0.165s
  training loss:		0.281188
  validation loss:		0.404080
  validation accuracy:		89.67 %
Epoch 1709 of 2000 took 0.166s
  training loss:		0.282584
  validation loss:		0.395287
  validation accuracy:		89.78 %
Epoch 1710 of 2000 took 0.166s
  training loss:		0.283610
  validation loss:		0.390046
  validation accuracy:		90.11 %
Epoch 1711 of 2000 took 0.167s
  training loss:		0.283772
  validation loss:		0.408698
  validation accuracy:		89.24 %
Epoch 1712 of 2000 took 0.169s
  training loss:		0.279859
  validation loss:		0.399922
  validation accuracy:		90.22 %
Epoch 1713 of 2000 took 0.165s
  training loss:		0.285643
  validation loss:		0.398666
  validation accuracy:		90.33 %
Epoch 1714 of 2000 took 0.166s
  training loss:		0.280697
  validation loss:		0.395018
  validation accuracy:		89.24 %
Epoch 1715 of 2000 took 0.170s
  training loss:		0.287261
  validation loss:		0.390298
  validation accuracy:		90.43 %
Epoch 1716 of 2000 took 0.166s
  training loss:		0.280953
  validation loss:		0.404824
  validation accuracy:		90.11 %
Epoch 1717 of 2000 took 0.260s
  training loss:		0.279434
  validation loss:		0.405352
  validation accuracy:		89.67 %
Epoch 1718 of 2000 took 0.132s
  training loss:		0.288424
  validation loss:		0.406192
  validation accuracy:		90.33 %
Epoch 1719 of 2000 took 0.108s
  training loss:		0.284428
  validation loss:		0.388479
  validation accuracy:		90.43 %
Epoch 1720 of 2000 took 0.104s
  training loss:		0.279508
  validation loss:		0.416644
  validation accuracy:		89.67 %
Epoch 1721 of 2000 took 0.101s
  training loss:		0.281038
  validation loss:		0.402183
  validation accuracy:		90.33 %
Epoch 1722 of 2000 took 0.107s
  training loss:		0.286519
  validation loss:		0.413456
  validation accuracy:		89.57 %
Epoch 1723 of 2000 took 0.101s
  training loss:		0.289420
  validation loss:		0.402947
  validation accuracy:		89.78 %
Epoch 1724 of 2000 took 0.100s
  training loss:		0.285766
  validation loss:		0.401318
  validation accuracy:		90.11 %
Epoch 1725 of 2000 took 0.099s
  training loss:		0.287010
  validation loss:		0.410598
  validation accuracy:		90.00 %
Epoch 1726 of 2000 took 0.100s
  training loss:		0.280070
  validation loss:		0.390910
  validation accuracy:		90.33 %
Epoch 1727 of 2000 took 0.104s
  training loss:		0.280284
  validation loss:		0.389536
  validation accuracy:		90.22 %
Epoch 1728 of 2000 took 0.100s
  training loss:		0.283859
  validation loss:		0.393336
  validation accuracy:		90.00 %
Epoch 1729 of 2000 took 0.100s
  training loss:		0.283644
  validation loss:		0.404079
  validation accuracy:		90.33 %
Epoch 1730 of 2000 took 0.106s
  training loss:		0.280237
  validation loss:		0.403829
  validation accuracy:		90.22 %
Epoch 1731 of 2000 took 0.099s
  training loss:		0.278452
  validation loss:		0.393529
  validation accuracy:		90.43 %
Epoch 1732 of 2000 took 0.100s
  training loss:		0.280743
  validation loss:		0.396090
  validation accuracy:		90.00 %
Epoch 1733 of 2000 took 0.100s
  training loss:		0.287854
  validation loss:		0.398717
  validation accuracy:		90.22 %
Epoch 1734 of 2000 took 0.102s
  training loss:		0.277159
  validation loss:		0.412421
  validation accuracy:		89.89 %
Epoch 1735 of 2000 took 0.104s
  training loss:		0.286605
  validation loss:		0.403890
  validation accuracy:		89.78 %
Epoch 1736 of 2000 took 0.100s
  training loss:		0.280180
  validation loss:		0.399256
  validation accuracy:		90.54 %
Epoch 1737 of 2000 took 0.100s
  training loss:		0.280431
  validation loss:		0.401238
  validation accuracy:		89.78 %
Epoch 1738 of 2000 took 0.105s
  training loss:		0.280541
  validation loss:		0.396174
  validation accuracy:		90.76 %
Epoch 1739 of 2000 took 0.099s
  training loss:		0.281090
  validation loss:		0.403961
  validation accuracy:		90.22 %
Epoch 1740 of 2000 took 0.100s
  training loss:		0.283613
  validation loss:		0.392295
  validation accuracy:		89.46 %
Epoch 1741 of 2000 took 0.099s
  training loss:		0.288046
  validation loss:		0.405337
  validation accuracy:		90.33 %
Epoch 1742 of 2000 took 0.103s
  training loss:		0.275030
  validation loss:		0.391781
  validation accuracy:		90.22 %
Epoch 1743 of 2000 took 0.101s
  training loss:		0.286253
  validation loss:		0.396286
  validation accuracy:		90.33 %
Epoch 1744 of 2000 took 0.099s
  training loss:		0.283710
  validation loss:		0.405330
  validation accuracy:		90.00 %
Epoch 1745 of 2000 took 0.103s
  training loss:		0.275109
  validation loss:		0.395290
  validation accuracy:		90.54 %
Epoch 1746 of 2000 took 0.102s
  training loss:		0.282694
  validation loss:		0.395595
  validation accuracy:		89.02 %
Epoch 1747 of 2000 took 0.100s
  training loss:		0.277744
  validation loss:		0.398238
  validation accuracy:		90.65 %
Epoch 1748 of 2000 took 0.100s
  training loss:		0.284790
  validation loss:		0.390408
  validation accuracy:		90.33 %
Epoch 1749 of 2000 took 0.099s
  training loss:		0.284218
  validation loss:		0.431273
  validation accuracy:		88.80 %
Epoch 1750 of 2000 took 0.104s
  training loss:		0.281310
  validation loss:		0.389947
  validation accuracy:		90.22 %
Epoch 1751 of 2000 took 0.101s
  training loss:		0.279865
  validation loss:		0.395592
  validation accuracy:		90.43 %
Epoch 1752 of 2000 took 0.099s
  training loss:		0.280523
  validation loss:		0.399926
  validation accuracy:		90.43 %
Epoch 1753 of 2000 took 0.105s
  training loss:		0.287592
  validation loss:		0.419995
  validation accuracy:		89.57 %
Epoch 1754 of 2000 took 0.099s
  training loss:		0.282362
  validation loss:		0.419555
  validation accuracy:		88.70 %
Epoch 1755 of 2000 took 0.100s
  training loss:		0.281991
  validation loss:		0.411861
  validation accuracy:		89.57 %
Epoch 1756 of 2000 took 0.099s
  training loss:		0.287237
  validation loss:		0.400129
  validation accuracy:		88.91 %
Epoch 1757 of 2000 took 0.100s
  training loss:		0.282712
  validation loss:		0.392306
  validation accuracy:		89.78 %
Epoch 1758 of 2000 took 0.104s
  training loss:		0.272062
  validation loss:		0.408433
  validation accuracy:		90.22 %
Epoch 1759 of 2000 took 0.099s
  training loss:		0.286969
  validation loss:		0.397370
  validation accuracy:		90.11 %
Epoch 1760 of 2000 took 0.100s
  training loss:		0.282852
  validation loss:		0.393268
  validation accuracy:		90.11 %
Epoch 1761 of 2000 took 0.105s
  training loss:		0.285295
  validation loss:		0.392486
  validation accuracy:		89.57 %
Epoch 1762 of 2000 took 0.099s
  training loss:		0.283172
  validation loss:		0.402199
  validation accuracy:		90.22 %
Epoch 1763 of 2000 took 0.100s
  training loss:		0.275275
  validation loss:		0.393334
  validation accuracy:		90.22 %
Epoch 1764 of 2000 took 0.099s
  training loss:		0.280083
  validation loss:		0.399216
  validation accuracy:		89.78 %
Epoch 1765 of 2000 took 0.102s
  training loss:		0.288175
  validation loss:		0.405840
  validation accuracy:		89.57 %
Epoch 1766 of 2000 took 0.102s
  training loss:		0.272732
  validation loss:		0.419606
  validation accuracy:		89.57 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.277050
  validation loss:		0.400739
  validation accuracy:		90.43 %
Epoch 1768 of 2000 took 0.102s
  training loss:		0.283199
  validation loss:		0.403351
  validation accuracy:		90.33 %
Epoch 1769 of 2000 took 0.103s
  training loss:		0.279660
  validation loss:		0.398602
  validation accuracy:		90.22 %
Epoch 1770 of 2000 took 0.099s
  training loss:		0.276029
  validation loss:		0.401298
  validation accuracy:		89.24 %
Epoch 1771 of 2000 took 0.100s
  training loss:		0.276939
  validation loss:		0.394043
  validation accuracy:		89.78 %
Epoch 1772 of 2000 took 0.099s
  training loss:		0.281026
  validation loss:		0.392338
  validation accuracy:		89.67 %
Epoch 1773 of 2000 took 0.104s
  training loss:		0.284673
  validation loss:		0.412354
  validation accuracy:		89.78 %
Epoch 1774 of 2000 took 0.100s
  training loss:		0.283110
  validation loss:		0.393164
  validation accuracy:		90.22 %
Epoch 1775 of 2000 took 0.099s
  training loss:		0.286509
  validation loss:		0.398140
  validation accuracy:		90.00 %
Epoch 1776 of 2000 took 0.105s
  training loss:		0.285307
  validation loss:		0.412825
  validation accuracy:		89.46 %
Epoch 1777 of 2000 took 0.100s
  training loss:		0.284815
  validation loss:		0.392631
  validation accuracy:		90.11 %
Epoch 1778 of 2000 took 0.100s
  training loss:		0.279200
  validation loss:		0.398680
  validation accuracy:		90.22 %
Epoch 1779 of 2000 took 0.100s
  training loss:		0.282040
  validation loss:		0.417309
  validation accuracy:		89.46 %
Epoch 1780 of 2000 took 0.100s
  training loss:		0.280819
  validation loss:		0.417722
  validation accuracy:		89.57 %
Epoch 1781 of 2000 took 0.104s
  training loss:		0.285545
  validation loss:		0.393222
  validation accuracy:		90.22 %
Epoch 1782 of 2000 took 0.100s
  training loss:		0.283891
  validation loss:		0.413723
  validation accuracy:		89.57 %
Epoch 1783 of 2000 took 0.100s
  training loss:		0.277860
  validation loss:		0.408007
  validation accuracy:		90.33 %
Epoch 1784 of 2000 took 0.106s
  training loss:		0.282748
  validation loss:		0.420191
  validation accuracy:		89.57 %
Epoch 1785 of 2000 took 0.099s
  training loss:		0.286485
  validation loss:		0.397386
  validation accuracy:		90.00 %
Epoch 1786 of 2000 took 0.100s
  training loss:		0.280187
  validation loss:		0.413667
  validation accuracy:		89.78 %
Epoch 1787 of 2000 took 0.099s
  training loss:		0.276723
  validation loss:		0.393919
  validation accuracy:		89.35 %
Epoch 1788 of 2000 took 0.101s
  training loss:		0.277172
  validation loss:		0.410653
  validation accuracy:		89.89 %
Epoch 1789 of 2000 took 0.104s
  training loss:		0.281015
  validation loss:		0.404454
  validation accuracy:		89.78 %
Epoch 1790 of 2000 took 0.099s
  training loss:		0.279332
  validation loss:		0.396415
  validation accuracy:		90.22 %
Epoch 1791 of 2000 took 0.100s
  training loss:		0.279887
  validation loss:		0.395645
  validation accuracy:		90.43 %
Epoch 1792 of 2000 took 0.105s
  training loss:		0.283197
  validation loss:		0.401109
  validation accuracy:		90.33 %
Epoch 1793 of 2000 took 0.099s
  training loss:		0.284128
  validation loss:		0.408300
  validation accuracy:		90.22 %
Epoch 1794 of 2000 took 0.101s
  training loss:		0.277953
  validation loss:		0.412211
  validation accuracy:		88.91 %
Epoch 1795 of 2000 took 0.099s
  training loss:		0.280030
  validation loss:		0.388687
  validation accuracy:		90.33 %
Epoch 1796 of 2000 took 0.104s
  training loss:		0.283382
  validation loss:		0.392003
  validation accuracy:		90.54 %
Epoch 1797 of 2000 took 0.101s
  training loss:		0.279889
  validation loss:		0.391080
  validation accuracy:		89.89 %
Epoch 1798 of 2000 took 0.099s
  training loss:		0.277446
  validation loss:		0.437618
  validation accuracy:		88.70 %
Epoch 1799 of 2000 took 0.103s
  training loss:		0.281132
  validation loss:		0.394424
  validation accuracy:		90.11 %
Epoch 1800 of 2000 took 0.102s
  training loss:		0.281690
  validation loss:		0.407588
  validation accuracy:		90.00 %
Epoch 1801 of 2000 took 0.100s
  training loss:		0.279917
  validation loss:		0.402946
  validation accuracy:		89.57 %
Epoch 1802 of 2000 took 0.100s
  training loss:		0.285680
  validation loss:		0.405522
  validation accuracy:		90.43 %
Epoch 1803 of 2000 took 0.099s
  training loss:		0.275344
  validation loss:		0.403577
  validation accuracy:		89.78 %
Epoch 1804 of 2000 took 0.104s
  training loss:		0.278837
  validation loss:		0.430829
  validation accuracy:		88.91 %
Epoch 1805 of 2000 took 0.101s
  training loss:		0.285886
  validation loss:		0.396591
  validation accuracy:		90.43 %
Epoch 1806 of 2000 took 0.099s
  training loss:		0.280566
  validation loss:		0.405832
  validation accuracy:		89.67 %
Epoch 1807 of 2000 took 0.105s
  training loss:		0.274449
  validation loss:		0.401885
  validation accuracy:		90.11 %
Epoch 1808 of 2000 took 0.099s
  training loss:		0.286607
  validation loss:		0.401274
  validation accuracy:		89.57 %
Epoch 1809 of 2000 took 0.100s
  training loss:		0.284107
  validation loss:		0.401148
  validation accuracy:		89.67 %
Epoch 1810 of 2000 took 0.099s
  training loss:		0.281140
  validation loss:		0.391805
  validation accuracy:		90.33 %
Epoch 1811 of 2000 took 0.100s
  training loss:		0.283931
  validation loss:		0.395075
  validation accuracy:		89.89 %
Epoch 1812 of 2000 took 0.103s
  training loss:		0.277500
  validation loss:		0.402786
  validation accuracy:		90.33 %
Epoch 1813 of 2000 took 0.099s
  training loss:		0.273702
  validation loss:		0.407154
  validation accuracy:		90.33 %
Epoch 1814 of 2000 took 0.100s
  training loss:		0.282090
  validation loss:		0.399872
  validation accuracy:		90.43 %
Epoch 1815 of 2000 took 0.105s
  training loss:		0.270266
  validation loss:		0.390444
  validation accuracy:		90.00 %
Epoch 1816 of 2000 took 0.099s
  training loss:		0.278893
  validation loss:		0.407427
  validation accuracy:		89.46 %
Epoch 1817 of 2000 took 0.100s
  training loss:		0.282543
  validation loss:		0.392349
  validation accuracy:		89.89 %
Epoch 1818 of 2000 took 0.099s
  training loss:		0.275536
  validation loss:		0.394593
  validation accuracy:		89.78 %
Epoch 1819 of 2000 took 0.102s
  training loss:		0.278918
  validation loss:		0.419194
  validation accuracy:		89.78 %
Epoch 1820 of 2000 took 0.103s
  training loss:		0.286389
  validation loss:		0.402865
  validation accuracy:		89.78 %
Epoch 1821 of 2000 took 0.099s
  training loss:		0.279314
  validation loss:		0.395570
  validation accuracy:		89.89 %
Epoch 1822 of 2000 took 0.101s
  training loss:		0.280778
  validation loss:		0.407410
  validation accuracy:		89.89 %
Epoch 1823 of 2000 took 0.104s
  training loss:		0.279566
  validation loss:		0.399526
  validation accuracy:		89.89 %
Epoch 1824 of 2000 took 0.099s
  training loss:		0.275364
  validation loss:		0.410150
  validation accuracy:		89.67 %
Epoch 1825 of 2000 took 0.100s
  training loss:		0.277847
  validation loss:		0.418070
  validation accuracy:		89.67 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.284247
  validation loss:		0.390340
  validation accuracy:		90.00 %
Epoch 1827 of 2000 took 0.104s
  training loss:		0.276353
  validation loss:		0.412463
  validation accuracy:		90.22 %
Epoch 1828 of 2000 took 0.101s
  training loss:		0.280703
  validation loss:		0.398851
  validation accuracy:		89.78 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.287438
  validation loss:		0.401547
  validation accuracy:		89.46 %
Epoch 1830 of 2000 took 0.103s
  training loss:		0.284988
  validation loss:		0.399981
  validation accuracy:		89.78 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.279491
  validation loss:		0.406715
  validation accuracy:		90.00 %
Epoch 1832 of 2000 took 0.100s
  training loss:		0.281810
  validation loss:		0.398139
  validation accuracy:		89.67 %
Epoch 1833 of 2000 took 0.102s
  training loss:		0.277804
  validation loss:		0.404690
  validation accuracy:		89.57 %
Epoch 1834 of 2000 took 0.099s
  training loss:		0.279788
  validation loss:		0.412233
  validation accuracy:		90.11 %
Epoch 1835 of 2000 took 0.103s
  training loss:		0.276050
  validation loss:		0.391915
  validation accuracy:		89.78 %
Epoch 1836 of 2000 took 0.100s
  training loss:		0.279886
  validation loss:		0.389710
  validation accuracy:		90.43 %
Epoch 1837 of 2000 took 0.102s
  training loss:		0.272369
  validation loss:		0.413890
  validation accuracy:		90.00 %
Epoch 1838 of 2000 took 0.100s
  training loss:		0.284160
  validation loss:		0.400109
  validation accuracy:		90.00 %
Epoch 1839 of 2000 took 0.100s
  training loss:		0.276228
  validation loss:		0.394474
  validation accuracy:		89.89 %
Epoch 1840 of 2000 took 0.101s
  training loss:		0.278768
  validation loss:		0.399433
  validation accuracy:		90.33 %
Epoch 1841 of 2000 took 0.097s
  training loss:		0.279389
  validation loss:		0.393102
  validation accuracy:		90.22 %
Epoch 1842 of 2000 took 0.100s
  training loss:		0.273488
  validation loss:		0.411416
  validation accuracy:		89.89 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.279172
  validation loss:		0.403979
  validation accuracy:		90.33 %
Epoch 1844 of 2000 took 0.097s
  training loss:		0.276987
  validation loss:		0.403736
  validation accuracy:		90.33 %
Epoch 1845 of 2000 took 0.099s
  training loss:		0.284301
  validation loss:		0.420375
  validation accuracy:		89.46 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.273461
  validation loss:		0.413209
  validation accuracy:		89.89 %
Epoch 1847 of 2000 took 0.100s
  training loss:		0.273170
  validation loss:		0.411397
  validation accuracy:		89.89 %
Epoch 1848 of 2000 took 0.096s
  training loss:		0.278469
  validation loss:		0.396412
  validation accuracy:		89.78 %
Epoch 1849 of 2000 took 0.095s
  training loss:		0.283194
  validation loss:		0.404724
  validation accuracy:		88.70 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.279781
  validation loss:		0.442425
  validation accuracy:		88.48 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.284130
  validation loss:		0.408376
  validation accuracy:		89.78 %
Epoch 1852 of 2000 took 0.101s
  training loss:		0.276927
  validation loss:		0.394465
  validation accuracy:		89.57 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.278415
  validation loss:		0.412106
  validation accuracy:		90.11 %
Epoch 1854 of 2000 took 0.098s
  training loss:		0.272400
  validation loss:		0.431400
  validation accuracy:		89.13 %
Epoch 1855 of 2000 took 0.098s
  training loss:		0.284299
  validation loss:		0.403493
  validation accuracy:		90.22 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.270465
  validation loss:		0.393639
  validation accuracy:		90.22 %
Epoch 1857 of 2000 took 0.099s
  training loss:		0.284020
  validation loss:		0.407528
  validation accuracy:		89.78 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.278339
  validation loss:		0.399575
  validation accuracy:		90.11 %
Epoch 1859 of 2000 took 0.099s
  training loss:		0.278128
  validation loss:		0.398304
  validation accuracy:		89.67 %
Epoch 1860 of 2000 took 0.099s
  training loss:		0.271370
  validation loss:		0.399699
  validation accuracy:		90.22 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.277079
  validation loss:		0.401203
  validation accuracy:		90.00 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.276984
  validation loss:		0.401047
  validation accuracy:		89.46 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.281390
  validation loss:		0.417494
  validation accuracy:		89.89 %
Epoch 1864 of 2000 took 0.101s
  training loss:		0.283120
  validation loss:		0.418274
  validation accuracy:		89.35 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.278924
  validation loss:		0.406670
  validation accuracy:		90.00 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.291201
  validation loss:		0.397389
  validation accuracy:		89.78 %
Epoch 1867 of 2000 took 0.102s
  training loss:		0.272574
  validation loss:		0.395695
  validation accuracy:		90.11 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.279353
  validation loss:		0.399601
  validation accuracy:		90.11 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.286829
  validation loss:		0.416354
  validation accuracy:		89.24 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.283891
  validation loss:		0.414125
  validation accuracy:		88.80 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.285807
  validation loss:		0.432433
  validation accuracy:		89.46 %
Epoch 1872 of 2000 took 0.100s
  training loss:		0.276879
  validation loss:		0.395859
  validation accuracy:		90.00 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.277934
  validation loss:		0.405376
  validation accuracy:		90.43 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.277774
  validation loss:		0.409788
  validation accuracy:		89.89 %
Epoch 1875 of 2000 took 0.102s
  training loss:		0.279233
  validation loss:		0.415992
  validation accuracy:		89.57 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.274589
  validation loss:		0.399353
  validation accuracy:		90.00 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.276070
  validation loss:		0.402965
  validation accuracy:		90.22 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.279581
  validation loss:		0.407320
  validation accuracy:		90.11 %
Epoch 1879 of 2000 took 0.098s
  training loss:		0.282415
  validation loss:		0.388248
  validation accuracy:		90.33 %
Epoch 1880 of 2000 took 0.100s
  training loss:		0.279447
  validation loss:		0.409597
  validation accuracy:		90.11 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.275370
  validation loss:		0.405839
  validation accuracy:		90.22 %
Epoch 1882 of 2000 took 0.097s
  training loss:		0.268514
  validation loss:		0.404789
  validation accuracy:		90.33 %
Epoch 1883 of 2000 took 0.101s
  training loss:		0.278085
  validation loss:		0.409130
  validation accuracy:		90.00 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.277180
  validation loss:		0.403051
  validation accuracy:		89.78 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.273592
  validation loss:		0.398691
  validation accuracy:		89.24 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.277228
  validation loss:		0.414438
  validation accuracy:		89.24 %
Epoch 1887 of 2000 took 0.100s
  training loss:		0.281143
  validation loss:		0.414341
  validation accuracy:		89.35 %
Epoch 1888 of 2000 took 0.098s
  training loss:		0.281404
  validation loss:		0.397561
  validation accuracy:		90.22 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.280699
  validation loss:		0.396001
  validation accuracy:		89.89 %
Epoch 1890 of 2000 took 0.099s
  training loss:		0.281969
  validation loss:		0.403207
  validation accuracy:		89.78 %
Epoch 1891 of 2000 took 0.099s
  training loss:		0.279430
  validation loss:		0.412629
  validation accuracy:		89.57 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.280653
  validation loss:		0.401862
  validation accuracy:		89.78 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.282162
  validation loss:		0.427734
  validation accuracy:		88.04 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.281707
  validation loss:		0.406221
  validation accuracy:		88.48 %
Epoch 1895 of 2000 took 0.101s
  training loss:		0.283371
  validation loss:		0.418786
  validation accuracy:		88.91 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.278704
  validation loss:		0.414775
  validation accuracy:		89.67 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.283343
  validation loss:		0.401765
  validation accuracy:		90.33 %
Epoch 1898 of 2000 took 0.102s
  training loss:		0.279335
  validation loss:		0.425313
  validation accuracy:		89.67 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.276395
  validation loss:		0.408239
  validation accuracy:		89.89 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.279662
  validation loss:		0.401753
  validation accuracy:		89.24 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.278984
  validation loss:		0.407185
  validation accuracy:		90.00 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.274453
  validation loss:		0.399074
  validation accuracy:		89.89 %
Epoch 1903 of 2000 took 0.100s
  training loss:		0.279518
  validation loss:		0.420536
  validation accuracy:		89.57 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.283892
  validation loss:		0.396765
  validation accuracy:		90.00 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.275711
  validation loss:		0.409918
  validation accuracy:		90.22 %
Epoch 1906 of 2000 took 0.102s
  training loss:		0.280763
  validation loss:		0.395209
  validation accuracy:		90.33 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.276201
  validation loss:		0.408988
  validation accuracy:		89.46 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.275681
  validation loss:		0.394616
  validation accuracy:		90.22 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.284598
  validation loss:		0.404316
  validation accuracy:		89.24 %
Epoch 1910 of 2000 took 0.098s
  training loss:		0.277565
  validation loss:		0.405533
  validation accuracy:		90.54 %
Epoch 1911 of 2000 took 0.100s
  training loss:		0.274835
  validation loss:		0.400823
  validation accuracy:		90.33 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.274904
  validation loss:		0.414278
  validation accuracy:		89.24 %
Epoch 1913 of 2000 took 0.097s
  training loss:		0.276252
  validation loss:		0.388843
  validation accuracy:		90.43 %
Epoch 1914 of 2000 took 0.102s
  training loss:		0.276871
  validation loss:		0.420547
  validation accuracy:		89.35 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.279371
  validation loss:		0.395869
  validation accuracy:		89.89 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.274911
  validation loss:		0.395118
  validation accuracy:		89.67 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.273613
  validation loss:		0.411839
  validation accuracy:		89.78 %
Epoch 1918 of 2000 took 0.100s
  training loss:		0.275594
  validation loss:		0.409034
  validation accuracy:		89.46 %
Epoch 1919 of 2000 took 0.098s
  training loss:		0.281896
  validation loss:		0.397161
  validation accuracy:		89.89 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.274727
  validation loss:		0.414567
  validation accuracy:		88.91 %
Epoch 1921 of 2000 took 0.099s
  training loss:		0.274988
  validation loss:		0.407625
  validation accuracy:		90.22 %
Epoch 1922 of 2000 took 0.099s
  training loss:		0.279783
  validation loss:		0.400941
  validation accuracy:		90.33 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.276417
  validation loss:		0.397087
  validation accuracy:		89.89 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.271507
  validation loss:		0.407685
  validation accuracy:		89.46 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.282105
  validation loss:		0.399666
  validation accuracy:		90.11 %
Epoch 1926 of 2000 took 0.101s
  training loss:		0.276218
  validation loss:		0.406676
  validation accuracy:		90.43 %
Epoch 1927 of 2000 took 0.097s
  training loss:		0.276010
  validation loss:		0.396783
  validation accuracy:		90.11 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.280136
  validation loss:		0.409370
  validation accuracy:		89.78 %
Epoch 1929 of 2000 took 0.102s
  training loss:		0.280300
  validation loss:		0.411499
  validation accuracy:		90.00 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.280419
  validation loss:		0.407099
  validation accuracy:		90.00 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.279910
  validation loss:		0.396922
  validation accuracy:		89.78 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.274270
  validation loss:		0.409167
  validation accuracy:		90.00 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.281547
  validation loss:		0.396018
  validation accuracy:		90.11 %
Epoch 1934 of 2000 took 0.100s
  training loss:		0.280715
  validation loss:		0.402770
  validation accuracy:		90.22 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.281415
  validation loss:		0.418997
  validation accuracy:		89.46 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.282288
  validation loss:		0.395915
  validation accuracy:		90.33 %
Epoch 1937 of 2000 took 0.102s
  training loss:		0.279994
  validation loss:		0.396198
  validation accuracy:		89.89 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.281260
  validation loss:		0.410022
  validation accuracy:		88.80 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.282213
  validation loss:		0.407913
  validation accuracy:		89.89 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.277224
  validation loss:		0.409874
  validation accuracy:		90.33 %
Epoch 1941 of 2000 took 0.098s
  training loss:		0.278080
  validation loss:		0.404137
  validation accuracy:		90.22 %
Epoch 1942 of 2000 took 0.100s
  training loss:		0.281491
  validation loss:		0.415979
  validation accuracy:		88.80 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.280496
  validation loss:		0.413710
  validation accuracy:		89.67 %
Epoch 1944 of 2000 took 0.097s
  training loss:		0.284312
  validation loss:		0.415671
  validation accuracy:		89.89 %
Epoch 1945 of 2000 took 0.101s
  training loss:		0.279358
  validation loss:		0.420317
  validation accuracy:		89.57 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.277263
  validation loss:		0.401794
  validation accuracy:		89.78 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.272214
  validation loss:		0.396471
  validation accuracy:		90.00 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.272683
  validation loss:		0.395906
  validation accuracy:		90.11 %
Epoch 1949 of 2000 took 0.100s
  training loss:		0.273894
  validation loss:		0.398738
  validation accuracy:		89.67 %
Epoch 1950 of 2000 took 0.098s
  training loss:		0.288601
  validation loss:		0.417043
  validation accuracy:		88.59 %
Epoch 1951 of 2000 took 0.096s
  training loss:		0.278569
  validation loss:		0.398612
  validation accuracy:		90.00 %
Epoch 1952 of 2000 took 0.101s
  training loss:		0.285205
  validation loss:		0.405835
  validation accuracy:		89.78 %
Epoch 1953 of 2000 took 0.102s
  training loss:		0.277528
  validation loss:		0.408180
  validation accuracy:		89.35 %
Epoch 1954 of 2000 took 0.099s
  training loss:		0.275260
  validation loss:		0.395654
  validation accuracy:		89.78 %
Epoch 1955 of 2000 took 0.100s
  training loss:		0.276191
  validation loss:		0.401978
  validation accuracy:		89.89 %
Epoch 1956 of 2000 took 0.099s
  training loss:		0.274534
  validation loss:		0.398302
  validation accuracy:		90.00 %
Epoch 1957 of 2000 took 0.104s
  training loss:		0.279970
  validation loss:		0.406030
  validation accuracy:		89.89 %
Epoch 1958 of 2000 took 0.100s
  training loss:		0.272864
  validation loss:		0.394814
  validation accuracy:		90.00 %
Epoch 1959 of 2000 took 0.099s
  training loss:		0.276976
  validation loss:		0.415421
  validation accuracy:		88.91 %
Epoch 1960 of 2000 took 0.105s
  training loss:		0.280113
  validation loss:		0.403777
  validation accuracy:		89.24 %
Epoch 1961 of 2000 took 0.099s
  training loss:		0.275251
  validation loss:		0.410960
  validation accuracy:		89.67 %
Epoch 1962 of 2000 took 0.100s
  training loss:		0.277753
  validation loss:		0.393822
  validation accuracy:		90.11 %
Epoch 1963 of 2000 took 0.099s
  training loss:		0.281230
  validation loss:		0.406958
  validation accuracy:		89.78 %
Epoch 1964 of 2000 took 0.100s
  training loss:		0.281361
  validation loss:		0.401725
  validation accuracy:		89.89 %
Epoch 1965 of 2000 took 0.103s
  training loss:		0.268511
  validation loss:		0.409234
  validation accuracy:		89.13 %
Epoch 1966 of 2000 took 0.100s
  training loss:		0.280857
  validation loss:		0.405300
  validation accuracy:		89.78 %
Epoch 1967 of 2000 took 0.099s
  training loss:		0.285898
  validation loss:		0.402458
  validation accuracy:		90.11 %
Epoch 1968 of 2000 took 0.105s
  training loss:		0.277044
  validation loss:		0.397644
  validation accuracy:		90.00 %
Epoch 1969 of 2000 took 0.099s
  training loss:		0.272738
  validation loss:		0.413054
  validation accuracy:		90.00 %
Epoch 1970 of 2000 took 0.100s
  training loss:		0.278490
  validation loss:		0.430227
  validation accuracy:		89.13 %
Epoch 1971 of 2000 took 0.099s
  training loss:		0.276072
  validation loss:		0.402877
  validation accuracy:		90.22 %
Epoch 1972 of 2000 took 0.101s
  training loss:		0.270236
  validation loss:		0.421455
  validation accuracy:		89.46 %
Epoch 1973 of 2000 took 0.103s
  training loss:		0.279231
  validation loss:		0.401066
  validation accuracy:		90.22 %
Epoch 1974 of 2000 took 0.099s
  training loss:		0.279550
  validation loss:		0.400878
  validation accuracy:		89.78 %
Epoch 1975 of 2000 took 0.100s
  training loss:		0.277024
  validation loss:		0.395992
  validation accuracy:		90.22 %
Epoch 1976 of 2000 took 0.105s
  training loss:		0.269908
  validation loss:		0.401416
  validation accuracy:		89.89 %
Epoch 1977 of 2000 took 0.099s
  training loss:		0.274941
  validation loss:		0.405489
  validation accuracy:		90.00 %
Epoch 1978 of 2000 took 0.100s
  training loss:		0.274222
  validation loss:		0.425549
  validation accuracy:		88.37 %
Epoch 1979 of 2000 took 0.099s
  training loss:		0.285758
  validation loss:		0.397286
  validation accuracy:		89.89 %
Epoch 1980 of 2000 took 0.102s
  training loss:		0.271281
  validation loss:		0.426934
  validation accuracy:		88.91 %
Epoch 1981 of 2000 took 0.101s
  training loss:		0.280271
  validation loss:		0.416350
  validation accuracy:		89.67 %
Epoch 1982 of 2000 took 0.099s
  training loss:		0.279826
  validation loss:		0.396833
  validation accuracy:		89.78 %
Epoch 1983 of 2000 took 0.102s
  training loss:		0.278516
  validation loss:		0.396225
  validation accuracy:		90.11 %
Epoch 1984 of 2000 took 0.102s
  training loss:		0.281208
  validation loss:		0.402644
  validation accuracy:		88.91 %
Epoch 1985 of 2000 took 0.099s
  training loss:		0.272936
  validation loss:		0.407886
  validation accuracy:		89.67 %
Epoch 1986 of 2000 took 0.100s
  training loss:		0.275096
  validation loss:		0.403961
  validation accuracy:		89.35 %
Epoch 1987 of 2000 took 0.099s
  training loss:		0.276829
  validation loss:		0.392833
  validation accuracy:		90.33 %
Epoch 1988 of 2000 took 0.104s
  training loss:		0.275899
  validation loss:		0.414315
  validation accuracy:		89.57 %
Epoch 1989 of 2000 took 0.101s
  training loss:		0.277236
  validation loss:		0.414663
  validation accuracy:		89.57 %
Epoch 1990 of 2000 took 0.099s
  training loss:		0.277330
  validation loss:		0.403245
  validation accuracy:		89.67 %
Epoch 1991 of 2000 took 0.105s
  training loss:		0.272436
  validation loss:		0.408019
  validation accuracy:		90.00 %
Epoch 1992 of 2000 took 0.098s
  training loss:		0.280949
  validation loss:		0.402619
  validation accuracy:		89.78 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.274610
  validation loss:		0.400018
  validation accuracy:		90.33 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.278518
  validation loss:		0.394354
  validation accuracy:		90.11 %
Epoch 1995 of 2000 took 0.097s
  training loss:		0.273078
  validation loss:		0.408094
  validation accuracy:		89.57 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.277975
  validation loss:		0.404947
  validation accuracy:		89.46 %
Epoch 1997 of 2000 took 0.097s
  training loss:		0.281293
  validation loss:		0.392410
  validation accuracy:		90.22 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.280389
  validation loss:		0.444485
  validation accuracy:		88.04 %
Epoch 1999 of 2000 took 0.102s
  training loss:		0.289296
  validation loss:		0.400442
  validation accuracy:		90.00 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.274843
  validation loss:		0.404804
  validation accuracy:		89.78 %
Final results:
  test loss:			0.819123
  test accuracy:		79.10 %
