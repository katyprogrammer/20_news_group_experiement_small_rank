Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.098s
  training loss:		2.996106
  validation loss:		2.983580
  validation accuracy:		13.15 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.986212
  validation loss:		2.969988
  validation accuracy:		12.83 %
Epoch 3 of 2000 took 0.099s
  training loss:		2.973694
  validation loss:		2.954382
  validation accuracy:		13.04 %
Epoch 4 of 2000 took 0.095s
  training loss:		2.960019
  validation loss:		2.938248
  validation accuracy:		13.70 %
Epoch 5 of 2000 took 0.098s
  training loss:		2.945436
  validation loss:		2.921952
  validation accuracy:		10.98 %
Epoch 6 of 2000 took 0.102s
  training loss:		2.931404
  validation loss:		2.905638
  validation accuracy:		11.30 %
Epoch 7 of 2000 took 0.095s
  training loss:		2.917028
  validation loss:		2.889169
  validation accuracy:		11.74 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.902896
  validation loss:		2.872621
  validation accuracy:		11.85 %
Epoch 9 of 2000 took 0.095s
  training loss:		2.888500
  validation loss:		2.855831
  validation accuracy:		11.85 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.873522
  validation loss:		2.838544
  validation accuracy:		11.85 %
Epoch 11 of 2000 took 0.099s
  training loss:		2.858263
  validation loss:		2.820597
  validation accuracy:		11.85 %
Epoch 12 of 2000 took 0.095s
  training loss:		2.842498
  validation loss:		2.801750
  validation accuracy:		11.85 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.826595
  validation loss:		2.782047
  validation accuracy:		11.85 %
Epoch 14 of 2000 took 0.100s
  training loss:		2.809331
  validation loss:		2.761074
  validation accuracy:		11.85 %
Epoch 15 of 2000 took 0.095s
  training loss:		2.790041
  validation loss:		2.738657
  validation accuracy:		11.85 %
Epoch 16 of 2000 took 0.098s
  training loss:		2.771137
  validation loss:		2.714795
  validation accuracy:		11.85 %
Epoch 17 of 2000 took 0.095s
  training loss:		2.749451
  validation loss:		2.688878
  validation accuracy:		11.85 %
Epoch 18 of 2000 took 0.099s
  training loss:		2.727197
  validation loss:		2.660923
  validation accuracy:		11.85 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.702876
  validation loss:		2.630662
  validation accuracy:		11.85 %
Epoch 20 of 2000 took 0.095s
  training loss:		2.675062
  validation loss:		2.597666
  validation accuracy:		11.85 %
Epoch 21 of 2000 took 0.098s
  training loss:		2.647385
  validation loss:		2.562661
  validation accuracy:		11.85 %
Epoch 22 of 2000 took 0.098s
  training loss:		2.617119
  validation loss:		2.525817
  validation accuracy:		11.85 %
Epoch 23 of 2000 took 0.095s
  training loss:		2.586948
  validation loss:		2.488219
  validation accuracy:		11.85 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.552440
  validation loss:		2.450122
  validation accuracy:		11.85 %
Epoch 25 of 2000 took 0.095s
  training loss:		2.519421
  validation loss:		2.413414
  validation accuracy:		11.85 %
Epoch 26 of 2000 took 0.099s
  training loss:		2.483970
  validation loss:		2.377832
  validation accuracy:		11.85 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.456152
  validation loss:		2.345151
  validation accuracy:		11.85 %
Epoch 28 of 2000 took 0.095s
  training loss:		2.422535
  validation loss:		2.317812
  validation accuracy:		11.96 %
Epoch 29 of 2000 took 0.099s
  training loss:		2.396688
  validation loss:		2.295610
  validation accuracy:		12.83 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.376248
  validation loss:		2.279281
  validation accuracy:		12.93 %
Epoch 31 of 2000 took 0.096s
  training loss:		2.356630
  validation loss:		2.269311
  validation accuracy:		12.83 %
Epoch 32 of 2000 took 0.099s
  training loss:		2.342700
  validation loss:		2.262413
  validation accuracy:		12.50 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.331579
  validation loss:		2.259901
  validation accuracy:		15.76 %
Epoch 34 of 2000 took 0.100s
  training loss:		2.323941
  validation loss:		2.258476
  validation accuracy:		16.74 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.318679
  validation loss:		2.257491
  validation accuracy:		12.93 %
Epoch 36 of 2000 took 0.096s
  training loss:		2.314893
  validation loss:		2.257936
  validation accuracy:		12.93 %
Epoch 37 of 2000 took 0.102s
  training loss:		2.310415
  validation loss:		2.258527
  validation accuracy:		17.07 %
Epoch 38 of 2000 took 0.096s
  training loss:		2.308023
  validation loss:		2.255019
  validation accuracy:		14.67 %
Epoch 39 of 2000 took 0.097s
  training loss:		2.304441
  validation loss:		2.251162
  validation accuracy:		12.93 %
Epoch 40 of 2000 took 0.096s
  training loss:		2.304139
  validation loss:		2.249924
  validation accuracy:		14.24 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.302131
  validation loss:		2.245987
  validation accuracy:		14.24 %
Epoch 42 of 2000 took 0.100s
  training loss:		2.302044
  validation loss:		2.248605
  validation accuracy:		14.13 %
Epoch 43 of 2000 took 0.096s
  training loss:		2.301799
  validation loss:		2.250443
  validation accuracy:		17.07 %
Epoch 44 of 2000 took 0.096s
  training loss:		2.300683
  validation loss:		2.252340
  validation accuracy:		13.04 %
Epoch 45 of 2000 took 0.102s
  training loss:		2.299246
  validation loss:		2.249062
  validation accuracy:		13.04 %
Epoch 46 of 2000 took 0.096s
  training loss:		2.299425
  validation loss:		2.249424
  validation accuracy:		13.26 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.299621
  validation loss:		2.243607
  validation accuracy:		12.61 %
Epoch 48 of 2000 took 0.096s
  training loss:		2.299283
  validation loss:		2.247519
  validation accuracy:		12.93 %
Epoch 49 of 2000 took 0.098s
  training loss:		2.298305
  validation loss:		2.251331
  validation accuracy:		12.93 %
Epoch 50 of 2000 took 0.099s
  training loss:		2.298096
  validation loss:		2.248050
  validation accuracy:		13.04 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.297256
  validation loss:		2.250593
  validation accuracy:		12.72 %
Epoch 52 of 2000 took 0.098s
  training loss:		2.297179
  validation loss:		2.244261
  validation accuracy:		12.93 %
Epoch 53 of 2000 took 0.100s
  training loss:		2.296460
  validation loss:		2.244945
  validation accuracy:		13.26 %
Epoch 54 of 2000 took 0.096s
  training loss:		2.297604
  validation loss:		2.246501
  validation accuracy:		13.37 %
Epoch 55 of 2000 took 0.097s
  training loss:		2.297299
  validation loss:		2.248890
  validation accuracy:		12.93 %
Epoch 56 of 2000 took 0.096s
  training loss:		2.297479
  validation loss:		2.245355
  validation accuracy:		13.80 %
Epoch 57 of 2000 took 0.101s
  training loss:		2.296132
  validation loss:		2.246711
  validation accuracy:		12.93 %
Epoch 58 of 2000 took 0.099s
  training loss:		2.296637
  validation loss:		2.244316
  validation accuracy:		13.91 %
Epoch 59 of 2000 took 0.096s
  training loss:		2.295459
  validation loss:		2.244993
  validation accuracy:		13.59 %
Epoch 60 of 2000 took 0.101s
  training loss:		2.296067
  validation loss:		2.245924
  validation accuracy:		13.04 %
Epoch 61 of 2000 took 0.097s
  training loss:		2.295720
  validation loss:		2.246300
  validation accuracy:		12.50 %
Epoch 62 of 2000 took 0.096s
  training loss:		2.295527
  validation loss:		2.244838
  validation accuracy:		16.63 %
Epoch 63 of 2000 took 0.096s
  training loss:		2.295448
  validation loss:		2.247048
  validation accuracy:		17.07 %
Epoch 64 of 2000 took 0.097s
  training loss:		2.295093
  validation loss:		2.247078
  validation accuracy:		12.93 %
Epoch 65 of 2000 took 0.100s
  training loss:		2.295649
  validation loss:		2.239838
  validation accuracy:		12.93 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.295997
  validation loss:		2.244163
  validation accuracy:		12.93 %
Epoch 67 of 2000 took 0.096s
  training loss:		2.295057
  validation loss:		2.245159
  validation accuracy:		15.65 %
Epoch 68 of 2000 took 0.102s
  training loss:		2.296160
  validation loss:		2.245730
  validation accuracy:		13.04 %
Epoch 69 of 2000 took 0.096s
  training loss:		2.295635
  validation loss:		2.248350
  validation accuracy:		13.37 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.295936
  validation loss:		2.245582
  validation accuracy:		12.93 %
Epoch 71 of 2000 took 0.096s
  training loss:		2.294140
  validation loss:		2.245366
  validation accuracy:		16.09 %
Epoch 72 of 2000 took 0.098s
  training loss:		2.294683
  validation loss:		2.242185
  validation accuracy:		12.93 %
Epoch 73 of 2000 took 0.100s
  training loss:		2.294710
  validation loss:		2.244135
  validation accuracy:		13.04 %
Epoch 74 of 2000 took 0.096s
  training loss:		2.295006
  validation loss:		2.241338
  validation accuracy:		13.04 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.295803
  validation loss:		2.245950
  validation accuracy:		16.63 %
Epoch 76 of 2000 took 0.102s
  training loss:		2.295149
  validation loss:		2.244521
  validation accuracy:		12.93 %
Epoch 77 of 2000 took 0.096s
  training loss:		2.295172
  validation loss:		2.248506
  validation accuracy:		12.93 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.295723
  validation loss:		2.246042
  validation accuracy:		12.93 %
Epoch 79 of 2000 took 0.096s
  training loss:		2.294220
  validation loss:		2.242783
  validation accuracy:		14.35 %
Epoch 80 of 2000 took 0.099s
  training loss:		2.294507
  validation loss:		2.239927
  validation accuracy:		13.70 %
Epoch 81 of 2000 took 0.098s
  training loss:		2.294144
  validation loss:		2.241870
  validation accuracy:		12.93 %
Epoch 82 of 2000 took 0.096s
  training loss:		2.294916
  validation loss:		2.245580
  validation accuracy:		12.93 %
Epoch 83 of 2000 took 0.098s
  training loss:		2.295106
  validation loss:		2.246322
  validation accuracy:		15.76 %
Epoch 84 of 2000 took 0.100s
  training loss:		2.294075
  validation loss:		2.247910
  validation accuracy:		17.28 %
Epoch 85 of 2000 took 0.096s
  training loss:		2.294988
  validation loss:		2.245991
  validation accuracy:		15.11 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.294088
  validation loss:		2.239064
  validation accuracy:		12.93 %
Epoch 87 of 2000 took 0.096s
  training loss:		2.295042
  validation loss:		2.242143
  validation accuracy:		12.93 %
Epoch 88 of 2000 took 0.101s
  training loss:		2.294684
  validation loss:		2.248953
  validation accuracy:		13.15 %
Epoch 89 of 2000 took 0.097s
  training loss:		2.294581
  validation loss:		2.244786
  validation accuracy:		13.91 %
Epoch 90 of 2000 took 0.096s
  training loss:		2.293895
  validation loss:		2.236932
  validation accuracy:		12.83 %
Epoch 91 of 2000 took 0.101s
  training loss:		2.294326
  validation loss:		2.246089
  validation accuracy:		12.93 %
Epoch 92 of 2000 took 0.097s
  training loss:		2.294316
  validation loss:		2.245717
  validation accuracy:		12.93 %
Epoch 93 of 2000 took 0.096s
  training loss:		2.293613
  validation loss:		2.243784
  validation accuracy:		13.04 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.294411
  validation loss:		2.242502
  validation accuracy:		13.04 %
Epoch 95 of 2000 took 0.096s
  training loss:		2.294469
  validation loss:		2.249376
  validation accuracy:		14.89 %
Epoch 96 of 2000 took 0.100s
  training loss:		2.294277
  validation loss:		2.245513
  validation accuracy:		12.93 %
Epoch 97 of 2000 took 0.097s
  training loss:		2.293586
  validation loss:		2.242195
  validation accuracy:		16.09 %
Epoch 98 of 2000 took 0.096s
  training loss:		2.294216
  validation loss:		2.239408
  validation accuracy:		12.83 %
Epoch 99 of 2000 took 0.102s
  training loss:		2.294228
  validation loss:		2.242031
  validation accuracy:		12.93 %
Epoch 100 of 2000 took 0.098s
  training loss:		2.293817
  validation loss:		2.245907
  validation accuracy:		13.48 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.294425
  validation loss:		2.246508
  validation accuracy:		14.46 %
Epoch 102 of 2000 took 0.096s
  training loss:		2.294312
  validation loss:		2.241695
  validation accuracy:		13.04 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.292713
  validation loss:		2.240275
  validation accuracy:		13.04 %
Epoch 104 of 2000 took 0.100s
  training loss:		2.294056
  validation loss:		2.242541
  validation accuracy:		12.93 %
Epoch 105 of 2000 took 0.096s
  training loss:		2.293006
  validation loss:		2.244540
  validation accuracy:		12.83 %
Epoch 106 of 2000 took 0.097s
  training loss:		2.294022
  validation loss:		2.240885
  validation accuracy:		16.96 %
Epoch 107 of 2000 took 0.102s
  training loss:		2.293530
  validation loss:		2.242165
  validation accuracy:		13.15 %
Epoch 108 of 2000 took 0.096s
  training loss:		2.294291
  validation loss:		2.242836
  validation accuracy:		12.93 %
Epoch 109 of 2000 took 0.097s
  training loss:		2.295151
  validation loss:		2.245726
  validation accuracy:		13.70 %
Epoch 110 of 2000 took 0.096s
  training loss:		2.293457
  validation loss:		2.240969
  validation accuracy:		12.93 %
Epoch 111 of 2000 took 0.099s
  training loss:		2.294290
  validation loss:		2.242287
  validation accuracy:		12.93 %
Epoch 112 of 2000 took 0.098s
  training loss:		2.294077
  validation loss:		2.243429
  validation accuracy:		13.04 %
Epoch 113 of 2000 took 0.096s
  training loss:		2.294552
  validation loss:		2.248100
  validation accuracy:		13.37 %
Epoch 114 of 2000 took 0.098s
  training loss:		2.294172
  validation loss:		2.246120
  validation accuracy:		14.02 %
Epoch 115 of 2000 took 0.100s
  training loss:		2.294339
  validation loss:		2.247518
  validation accuracy:		16.85 %
Epoch 116 of 2000 took 0.096s
  training loss:		2.293560
  validation loss:		2.239139
  validation accuracy:		12.93 %
Epoch 117 of 2000 took 0.097s
  training loss:		2.293894
  validation loss:		2.244417
  validation accuracy:		13.15 %
Epoch 118 of 2000 took 0.096s
  training loss:		2.293238
  validation loss:		2.243435
  validation accuracy:		12.28 %
Epoch 119 of 2000 took 0.101s
  training loss:		2.293294
  validation loss:		2.243469
  validation accuracy:		13.15 %
Epoch 120 of 2000 took 0.097s
  training loss:		2.293637
  validation loss:		2.241683
  validation accuracy:		12.93 %
Epoch 121 of 2000 took 0.096s
  training loss:		2.294908
  validation loss:		2.247643
  validation accuracy:		18.59 %
Epoch 122 of 2000 took 0.101s
  training loss:		2.293540
  validation loss:		2.247806
  validation accuracy:		12.93 %
Epoch 123 of 2000 took 0.097s
  training loss:		2.293637
  validation loss:		2.238384
  validation accuracy:		13.04 %
Epoch 124 of 2000 took 0.096s
  training loss:		2.293933
  validation loss:		2.243837
  validation accuracy:		12.93 %
Epoch 125 of 2000 took 0.096s
  training loss:		2.293766
  validation loss:		2.244400
  validation accuracy:		13.80 %
Epoch 126 of 2000 took 0.096s
  training loss:		2.292925
  validation loss:		2.243711
  validation accuracy:		13.04 %
Epoch 127 of 2000 took 0.100s
  training loss:		2.293522
  validation loss:		2.241459
  validation accuracy:		14.02 %
Epoch 128 of 2000 took 0.097s
  training loss:		2.293770
  validation loss:		2.243365
  validation accuracy:		16.09 %
Epoch 129 of 2000 took 0.096s
  training loss:		2.293302
  validation loss:		2.242771
  validation accuracy:		13.70 %
Epoch 130 of 2000 took 0.102s
  training loss:		2.292953
  validation loss:		2.242611
  validation accuracy:		17.07 %
Epoch 131 of 2000 took 0.096s
  training loss:		2.293938
  validation loss:		2.243407
  validation accuracy:		14.89 %
Epoch 132 of 2000 took 0.097s
  training loss:		2.292715
  validation loss:		2.242755
  validation accuracy:		13.70 %
Epoch 133 of 2000 took 0.096s
  training loss:		2.293237
  validation loss:		2.242010
  validation accuracy:		15.76 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.293813
  validation loss:		2.245861
  validation accuracy:		18.48 %
Epoch 135 of 2000 took 0.100s
  training loss:		2.293284
  validation loss:		2.242392
  validation accuracy:		13.70 %
Epoch 136 of 2000 took 0.096s
  training loss:		2.294280
  validation loss:		2.244666
  validation accuracy:		16.85 %
Epoch 137 of 2000 took 0.097s
  training loss:		2.293623
  validation loss:		2.242128
  validation accuracy:		17.39 %
Epoch 138 of 2000 took 0.102s
  training loss:		2.292694
  validation loss:		2.246216
  validation accuracy:		13.70 %
Epoch 139 of 2000 took 0.096s
  training loss:		2.293264
  validation loss:		2.241207
  validation accuracy:		17.07 %
Epoch 140 of 2000 took 0.097s
  training loss:		2.293685
  validation loss:		2.242825
  validation accuracy:		13.26 %
Epoch 141 of 2000 took 0.096s
  training loss:		2.293140
  validation loss:		2.244078
  validation accuracy:		14.89 %
Epoch 142 of 2000 took 0.098s
  training loss:		2.291506
  validation loss:		2.240589
  validation accuracy:		16.52 %
Epoch 143 of 2000 took 0.099s
  training loss:		2.293473
  validation loss:		2.240027
  validation accuracy:		18.04 %
Epoch 144 of 2000 took 0.096s
  training loss:		2.292149
  validation loss:		2.241918
  validation accuracy:		12.93 %
Epoch 145 of 2000 took 0.098s
  training loss:		2.292187
  validation loss:		2.241423
  validation accuracy:		13.04 %
Epoch 146 of 2000 took 0.100s
  training loss:		2.293069
  validation loss:		2.241644
  validation accuracy:		16.96 %
Epoch 147 of 2000 took 0.096s
  training loss:		2.293012
  validation loss:		2.242058
  validation accuracy:		20.22 %
Epoch 148 of 2000 took 0.097s
  training loss:		2.292557
  validation loss:		2.242049
  validation accuracy:		15.87 %
Epoch 149 of 2000 took 0.096s
  training loss:		2.292987
  validation loss:		2.242824
  validation accuracy:		13.26 %
Epoch 150 of 2000 took 0.101s
  training loss:		2.291919
  validation loss:		2.244754
  validation accuracy:		13.15 %
Epoch 151 of 2000 took 0.098s
  training loss:		2.293338
  validation loss:		2.242127
  validation accuracy:		12.93 %
Epoch 152 of 2000 took 0.096s
  training loss:		2.292966
  validation loss:		2.242342
  validation accuracy:		13.04 %
Epoch 153 of 2000 took 0.101s
  training loss:		2.293228
  validation loss:		2.240501
  validation accuracy:		16.63 %
Epoch 154 of 2000 took 0.098s
  training loss:		2.292859
  validation loss:		2.245572
  validation accuracy:		16.30 %
Epoch 155 of 2000 took 0.096s
  training loss:		2.292887
  validation loss:		2.240465
  validation accuracy:		12.93 %
Epoch 156 of 2000 took 0.097s
  training loss:		2.292347
  validation loss:		2.242288
  validation accuracy:		12.83 %
Epoch 157 of 2000 took 0.096s
  training loss:		2.293345
  validation loss:		2.240794
  validation accuracy:		13.37 %
Epoch 158 of 2000 took 0.100s
  training loss:		2.293034
  validation loss:		2.242754
  validation accuracy:		13.15 %
Epoch 159 of 2000 took 0.097s
  training loss:		2.293111
  validation loss:		2.246034
  validation accuracy:		13.04 %
Epoch 160 of 2000 took 0.096s
  training loss:		2.293674
  validation loss:		2.242432
  validation accuracy:		22.07 %
Epoch 161 of 2000 took 0.102s
  training loss:		2.291864
  validation loss:		2.238457
  validation accuracy:		12.93 %
Epoch 162 of 2000 took 0.096s
  training loss:		2.291938
  validation loss:		2.241142
  validation accuracy:		13.80 %
Epoch 163 of 2000 took 0.097s
  training loss:		2.291902
  validation loss:		2.242579
  validation accuracy:		14.35 %
Epoch 164 of 2000 took 0.096s
  training loss:		2.293118
  validation loss:		2.247152
  validation accuracy:		13.15 %
Epoch 165 of 2000 took 0.097s
  training loss:		2.292259
  validation loss:		2.239882
  validation accuracy:		14.46 %
Epoch 166 of 2000 took 0.100s
  training loss:		2.291523
  validation loss:		2.237412
  validation accuracy:		13.15 %
Epoch 167 of 2000 took 0.097s
  training loss:		2.293404
  validation loss:		2.246521
  validation accuracy:		13.04 %
Epoch 168 of 2000 took 0.098s
  training loss:		2.292339
  validation loss:		2.241730
  validation accuracy:		13.04 %
Epoch 169 of 2000 took 0.102s
  training loss:		2.292100
  validation loss:		2.240890
  validation accuracy:		16.85 %
Epoch 170 of 2000 took 0.096s
  training loss:		2.290619
  validation loss:		2.240129
  validation accuracy:		13.04 %
Epoch 171 of 2000 took 0.097s
  training loss:		2.292479
  validation loss:		2.239687
  validation accuracy:		13.59 %
Epoch 172 of 2000 took 0.096s
  training loss:		2.290988
  validation loss:		2.243381
  validation accuracy:		17.17 %
Epoch 173 of 2000 took 0.098s
  training loss:		2.291980
  validation loss:		2.239154
  validation accuracy:		17.28 %
Epoch 174 of 2000 took 0.099s
  training loss:		2.291208
  validation loss:		2.242968
  validation accuracy:		12.93 %
Epoch 175 of 2000 took 0.096s
  training loss:		2.291036
  validation loss:		2.240373
  validation accuracy:		17.39 %
Epoch 176 of 2000 took 0.098s
  training loss:		2.290488
  validation loss:		2.237818
  validation accuracy:		15.43 %
Epoch 177 of 2000 took 0.100s
  training loss:		2.292401
  validation loss:		2.239433
  validation accuracy:		15.54 %
Epoch 178 of 2000 took 0.096s
  training loss:		2.291247
  validation loss:		2.242664
  validation accuracy:		13.91 %
Epoch 179 of 2000 took 0.097s
  training loss:		2.292419
  validation loss:		2.240858
  validation accuracy:		13.70 %
Epoch 180 of 2000 took 0.096s
  training loss:		2.292404
  validation loss:		2.234189
  validation accuracy:		18.04 %
Epoch 181 of 2000 took 0.100s
  training loss:		2.291802
  validation loss:		2.239392
  validation accuracy:		13.04 %
Epoch 182 of 2000 took 0.098s
  training loss:		2.290659
  validation loss:		2.242893
  validation accuracy:		15.00 %
Epoch 183 of 2000 took 0.096s
  training loss:		2.291437
  validation loss:		2.241971
  validation accuracy:		17.50 %
Epoch 184 of 2000 took 0.101s
  training loss:		2.290010
  validation loss:		2.237339
  validation accuracy:		13.26 %
Epoch 185 of 2000 took 0.098s
  training loss:		2.291197
  validation loss:		2.238412
  validation accuracy:		12.93 %
Epoch 186 of 2000 took 0.096s
  training loss:		2.292696
  validation loss:		2.247270
  validation accuracy:		15.11 %
Epoch 187 of 2000 took 0.096s
  training loss:		2.291704
  validation loss:		2.239742
  validation accuracy:		13.15 %
Epoch 188 of 2000 took 0.096s
  training loss:		2.290958
  validation loss:		2.237010
  validation accuracy:		13.70 %
Epoch 189 of 2000 took 0.100s
  training loss:		2.291468
  validation loss:		2.244723
  validation accuracy:		13.04 %
Epoch 190 of 2000 took 0.097s
  training loss:		2.291471
  validation loss:		2.242217
  validation accuracy:		15.00 %
Epoch 191 of 2000 took 0.096s
  training loss:		2.290225
  validation loss:		2.234090
  validation accuracy:		13.48 %
Epoch 192 of 2000 took 0.102s
  training loss:		2.291144
  validation loss:		2.239433
  validation accuracy:		14.24 %
Epoch 193 of 2000 took 0.096s
  training loss:		2.292673
  validation loss:		2.244322
  validation accuracy:		12.93 %
Epoch 194 of 2000 took 0.097s
  training loss:		2.291385
  validation loss:		2.239097
  validation accuracy:		13.04 %
Epoch 195 of 2000 took 0.097s
  training loss:		2.289949
  validation loss:		2.238042
  validation accuracy:		17.61 %
Epoch 196 of 2000 took 0.097s
  training loss:		2.290598
  validation loss:		2.242522
  validation accuracy:		13.04 %
Epoch 197 of 2000 took 0.100s
  training loss:		2.290406
  validation loss:		2.238109
  validation accuracy:		19.13 %
Epoch 198 of 2000 took 0.096s
  training loss:		2.290311
  validation loss:		2.237750
  validation accuracy:		13.91 %
Epoch 199 of 2000 took 0.096s
  training loss:		2.290769
  validation loss:		2.240062
  validation accuracy:		13.15 %
Epoch 200 of 2000 took 0.102s
  training loss:		2.290221
  validation loss:		2.240543
  validation accuracy:		15.87 %
Epoch 201 of 2000 took 0.096s
  training loss:		2.291552
  validation loss:		2.235470
  validation accuracy:		13.04 %
Epoch 202 of 2000 took 0.097s
  training loss:		2.291568
  validation loss:		2.242873
  validation accuracy:		13.37 %
Epoch 203 of 2000 took 0.096s
  training loss:		2.290787
  validation loss:		2.239752
  validation accuracy:		17.39 %
Epoch 204 of 2000 took 0.098s
  training loss:		2.290520
  validation loss:		2.238071
  validation accuracy:		23.26 %
Epoch 205 of 2000 took 0.099s
  training loss:		2.290195
  validation loss:		2.242425
  validation accuracy:		13.26 %
Epoch 206 of 2000 took 0.096s
  training loss:		2.289579
  validation loss:		2.238091
  validation accuracy:		18.48 %
Epoch 207 of 2000 took 0.097s
  training loss:		2.290149
  validation loss:		2.239956
  validation accuracy:		12.93 %
Epoch 208 of 2000 took 0.098s
  training loss:		2.290916
  validation loss:		2.236715
  validation accuracy:		21.20 %
Epoch 209 of 2000 took 0.096s
  training loss:		2.289511
  validation loss:		2.239191
  validation accuracy:		12.93 %
Epoch 210 of 2000 took 0.099s
  training loss:		2.290109
  validation loss:		2.237789
  validation accuracy:		12.93 %
Epoch 211 of 2000 took 0.096s
  training loss:		2.290297
  validation loss:		2.240603
  validation accuracy:		14.78 %
Epoch 212 of 2000 took 0.099s
  training loss:		2.289665
  validation loss:		2.237721
  validation accuracy:		18.37 %
Epoch 213 of 2000 took 0.096s
  training loss:		2.289878
  validation loss:		2.236474
  validation accuracy:		17.28 %
Epoch 214 of 2000 took 0.096s
  training loss:		2.290099
  validation loss:		2.237989
  validation accuracy:		13.15 %
Epoch 215 of 2000 took 0.099s
  training loss:		2.290502
  validation loss:		2.244354
  validation accuracy:		13.26 %
Epoch 216 of 2000 took 0.096s
  training loss:		2.289813
  validation loss:		2.235874
  validation accuracy:		18.37 %
Epoch 217 of 2000 took 0.100s
  training loss:		2.289336
  validation loss:		2.236031
  validation accuracy:		13.04 %
Epoch 218 of 2000 took 0.096s
  training loss:		2.289411
  validation loss:		2.240331
  validation accuracy:		13.04 %
Epoch 219 of 2000 took 0.097s
  training loss:		2.289422
  validation loss:		2.243148
  validation accuracy:		13.70 %
Epoch 220 of 2000 took 0.099s
  training loss:		2.288232
  validation loss:		2.240796
  validation accuracy:		13.04 %
Epoch 221 of 2000 took 0.096s
  training loss:		2.287467
  validation loss:		2.231266
  validation accuracy:		14.57 %
Epoch 222 of 2000 took 0.099s
  training loss:		2.289266
  validation loss:		2.232646
  validation accuracy:		14.35 %
Epoch 223 of 2000 took 0.096s
  training loss:		2.290383
  validation loss:		2.244849
  validation accuracy:		13.48 %
Epoch 224 of 2000 took 0.098s
  training loss:		2.289142
  validation loss:		2.244478
  validation accuracy:		22.72 %
Epoch 225 of 2000 took 0.097s
  training loss:		2.288394
  validation loss:		2.233551
  validation accuracy:		14.67 %
Epoch 226 of 2000 took 0.096s
  training loss:		2.288622
  validation loss:		2.236724
  validation accuracy:		14.02 %
Epoch 227 of 2000 took 0.099s
  training loss:		2.287879
  validation loss:		2.236648
  validation accuracy:		16.96 %
Epoch 228 of 2000 took 0.096s
  training loss:		2.288621
  validation loss:		2.242958
  validation accuracy:		17.28 %
Epoch 229 of 2000 took 0.099s
  training loss:		2.288037
  validation loss:		2.233853
  validation accuracy:		12.93 %
Epoch 230 of 2000 took 0.096s
  training loss:		2.287578
  validation loss:		2.235850
  validation accuracy:		13.48 %
Epoch 231 of 2000 took 0.096s
  training loss:		2.286832
  validation loss:		2.233637
  validation accuracy:		18.59 %
Epoch 232 of 2000 took 0.099s
  training loss:		2.288261
  validation loss:		2.236535
  validation accuracy:		19.89 %
Epoch 233 of 2000 took 0.096s
  training loss:		2.288018
  validation loss:		2.239688
  validation accuracy:		22.07 %
Epoch 234 of 2000 took 0.100s
  training loss:		2.288244
  validation loss:		2.238232
  validation accuracy:		13.15 %
Epoch 235 of 2000 took 0.096s
  training loss:		2.288413
  validation loss:		2.237014
  validation accuracy:		15.22 %
Epoch 236 of 2000 took 0.097s
  training loss:		2.287811
  validation loss:		2.239084
  validation accuracy:		13.37 %
Epoch 237 of 2000 took 0.102s
  training loss:		2.286797
  validation loss:		2.240311
  validation accuracy:		15.98 %
Epoch 238 of 2000 took 0.096s
  training loss:		2.286878
  validation loss:		2.231166
  validation accuracy:		13.26 %
Epoch 239 of 2000 took 0.097s
  training loss:		2.287106
  validation loss:		2.233703
  validation accuracy:		12.93 %
Epoch 240 of 2000 took 0.096s
  training loss:		2.286930
  validation loss:		2.242063
  validation accuracy:		13.48 %
Epoch 241 of 2000 took 0.099s
  training loss:		2.286382
  validation loss:		2.240265
  validation accuracy:		15.00 %
Epoch 242 of 2000 took 0.098s
  training loss:		2.286312
  validation loss:		2.234290
  validation accuracy:		14.57 %
Epoch 243 of 2000 took 0.096s
  training loss:		2.286869
  validation loss:		2.233503
  validation accuracy:		23.70 %
Epoch 244 of 2000 took 0.099s
  training loss:		2.286065
  validation loss:		2.236603
  validation accuracy:		13.04 %
Epoch 245 of 2000 took 0.099s
  training loss:		2.286029
  validation loss:		2.232954
  validation accuracy:		17.72 %
Epoch 246 of 2000 took 0.096s
  training loss:		2.286331
  validation loss:		2.239674
  validation accuracy:		22.61 %
Epoch 247 of 2000 took 0.097s
  training loss:		2.284866
  validation loss:		2.234292
  validation accuracy:		13.37 %
Epoch 248 of 2000 took 0.096s
  training loss:		2.284984
  validation loss:		2.232610
  validation accuracy:		13.15 %
Epoch 249 of 2000 took 0.100s
  training loss:		2.284614
  validation loss:		2.231467
  validation accuracy:		13.48 %
Epoch 250 of 2000 took 0.097s
  training loss:		2.284499
  validation loss:		2.233992
  validation accuracy:		16.20 %
Epoch 251 of 2000 took 0.096s
  training loss:		2.285203
  validation loss:		2.234230
  validation accuracy:		13.59 %
Epoch 252 of 2000 took 0.102s
  training loss:		2.284636
  validation loss:		2.231477
  validation accuracy:		13.91 %
Epoch 253 of 2000 took 0.097s
  training loss:		2.284099
  validation loss:		2.230460
  validation accuracy:		20.65 %
Epoch 254 of 2000 took 0.096s
  training loss:		2.283671
  validation loss:		2.232572
  validation accuracy:		13.26 %
Epoch 255 of 2000 took 0.096s
  training loss:		2.284600
  validation loss:		2.233295
  validation accuracy:		16.52 %
Epoch 256 of 2000 took 0.097s
  training loss:		2.284233
  validation loss:		2.232250
  validation accuracy:		14.35 %
Epoch 257 of 2000 took 0.100s
  training loss:		2.283652
  validation loss:		2.237888
  validation accuracy:		19.57 %
Epoch 258 of 2000 took 0.097s
  training loss:		2.283095
  validation loss:		2.230347
  validation accuracy:		19.46 %
Epoch 259 of 2000 took 0.096s
  training loss:		2.282882
  validation loss:		2.229244
  validation accuracy:		21.09 %
Epoch 260 of 2000 took 0.102s
  training loss:		2.283254
  validation loss:		2.235397
  validation accuracy:		14.67 %
Epoch 261 of 2000 took 0.096s
  training loss:		2.281869
  validation loss:		2.233088
  validation accuracy:		22.83 %
Epoch 262 of 2000 took 0.097s
  training loss:		2.282078
  validation loss:		2.228110
  validation accuracy:		17.83 %
Epoch 263 of 2000 took 0.096s
  training loss:		2.281614
  validation loss:		2.231504
  validation accuracy:		22.28 %
Epoch 264 of 2000 took 0.097s
  training loss:		2.280856
  validation loss:		2.228291
  validation accuracy:		16.74 %
Epoch 265 of 2000 took 0.100s
  training loss:		2.280592
  validation loss:		2.230180
  validation accuracy:		18.04 %
Epoch 266 of 2000 took 0.096s
  training loss:		2.279336
  validation loss:		2.231909
  validation accuracy:		15.87 %
Epoch 267 of 2000 took 0.097s
  training loss:		2.280414
  validation loss:		2.227191
  validation accuracy:		14.67 %
Epoch 268 of 2000 took 0.102s
  training loss:		2.280239
  validation loss:		2.232124
  validation accuracy:		21.30 %
Epoch 269 of 2000 took 0.096s
  training loss:		2.279202
  validation loss:		2.226571
  validation accuracy:		14.57 %
Epoch 270 of 2000 took 0.097s
  training loss:		2.280195
  validation loss:		2.227027
  validation accuracy:		23.26 %
Epoch 271 of 2000 took 0.096s
  training loss:		2.278304
  validation loss:		2.225169
  validation accuracy:		16.63 %
Epoch 272 of 2000 took 0.100s
  training loss:		2.277334
  validation loss:		2.228749
  validation accuracy:		21.74 %
Epoch 273 of 2000 took 0.098s
  training loss:		2.277407
  validation loss:		2.222898
  validation accuracy:		16.41 %
Epoch 274 of 2000 took 0.096s
  training loss:		2.277951
  validation loss:		2.227475
  validation accuracy:		20.22 %
Epoch 275 of 2000 took 0.102s
  training loss:		2.275816
  validation loss:		2.228123
  validation accuracy:		17.61 %
Epoch 276 of 2000 took 0.099s
  training loss:		2.274233
  validation loss:		2.217493
  validation accuracy:		17.83 %
Epoch 277 of 2000 took 0.097s
  training loss:		2.275374
  validation loss:		2.218607
  validation accuracy:		21.96 %
Epoch 278 of 2000 took 0.097s
  training loss:		2.274397
  validation loss:		2.226118
  validation accuracy:		15.22 %
Epoch 279 of 2000 took 0.096s
  training loss:		2.273276
  validation loss:		2.222128
  validation accuracy:		20.33 %
Epoch 280 of 2000 took 0.100s
  training loss:		2.272355
  validation loss:		2.217995
  validation accuracy:		20.76 %
Epoch 281 of 2000 took 0.097s
  training loss:		2.271638
  validation loss:		2.222684
  validation accuracy:		15.87 %
Epoch 282 of 2000 took 0.096s
  training loss:		2.270429
  validation loss:		2.218896
  validation accuracy:		24.57 %
Epoch 283 of 2000 took 0.102s
  training loss:		2.270268
  validation loss:		2.214877
  validation accuracy:		21.41 %
Epoch 284 of 2000 took 0.096s
  training loss:		2.269634
  validation loss:		2.216053
  validation accuracy:		27.50 %
Epoch 285 of 2000 took 0.096s
  training loss:		2.267158
  validation loss:		2.215220
  validation accuracy:		23.15 %
Epoch 286 of 2000 took 0.096s
  training loss:		2.266799
  validation loss:		2.214063
  validation accuracy:		21.09 %
Epoch 287 of 2000 took 0.097s
  training loss:		2.264649
  validation loss:		2.211691
  validation accuracy:		19.67 %
Epoch 288 of 2000 took 0.100s
  training loss:		2.263727
  validation loss:		2.213471
  validation accuracy:		22.50 %
Epoch 289 of 2000 took 0.097s
  training loss:		2.263263
  validation loss:		2.209634
  validation accuracy:		19.02 %
Epoch 290 of 2000 took 0.096s
  training loss:		2.260212
  validation loss:		2.206164
  validation accuracy:		21.74 %
Epoch 291 of 2000 took 0.102s
  training loss:		2.259782
  validation loss:		2.206905
  validation accuracy:		23.15 %
Epoch 292 of 2000 took 0.096s
  training loss:		2.257308
  validation loss:		2.204532
  validation accuracy:		24.13 %
Epoch 293 of 2000 took 0.097s
  training loss:		2.255655
  validation loss:		2.198822
  validation accuracy:		21.85 %
Epoch 294 of 2000 took 0.096s
  training loss:		2.253990
  validation loss:		2.201649
  validation accuracy:		20.65 %
Epoch 295 of 2000 took 0.098s
  training loss:		2.250911
  validation loss:		2.194480
  validation accuracy:		22.07 %
Epoch 296 of 2000 took 0.100s
  training loss:		2.247690
  validation loss:		2.188686
  validation accuracy:		24.35 %
Epoch 297 of 2000 took 0.096s
  training loss:		2.245868
  validation loss:		2.193675
  validation accuracy:		25.22 %
Epoch 298 of 2000 took 0.097s
  training loss:		2.241659
  validation loss:		2.183348
  validation accuracy:		24.13 %
Epoch 299 of 2000 took 0.102s
  training loss:		2.238764
  validation loss:		2.179584
  validation accuracy:		25.22 %
Epoch 300 of 2000 took 0.096s
  training loss:		2.235086
  validation loss:		2.176778
  validation accuracy:		23.80 %
Epoch 301 of 2000 took 0.097s
  training loss:		2.230761
  validation loss:		2.174372
  validation accuracy:		23.70 %
Epoch 302 of 2000 took 0.096s
  training loss:		2.225586
  validation loss:		2.167981
  validation accuracy:		23.48 %
Epoch 303 of 2000 took 0.099s
  training loss:		2.219131
  validation loss:		2.160613
  validation accuracy:		23.15 %
Epoch 304 of 2000 took 0.098s
  training loss:		2.212295
  validation loss:		2.151554
  validation accuracy:		23.26 %
Epoch 305 of 2000 took 0.096s
  training loss:		2.203772
  validation loss:		2.143074
  validation accuracy:		25.76 %
Epoch 306 of 2000 took 0.099s
  training loss:		2.197185
  validation loss:		2.133009
  validation accuracy:		23.26 %
Epoch 307 of 2000 took 0.099s
  training loss:		2.187394
  validation loss:		2.127084
  validation accuracy:		25.11 %
Epoch 308 of 2000 took 0.096s
  training loss:		2.175535
  validation loss:		2.110227
  validation accuracy:		25.76 %
Epoch 309 of 2000 took 0.097s
  training loss:		2.160743
  validation loss:		2.091399
  validation accuracy:		29.78 %
Epoch 310 of 2000 took 0.096s
  training loss:		2.144370
  validation loss:		2.072029
  validation accuracy:		24.46 %
Epoch 311 of 2000 took 0.101s
  training loss:		2.125763
  validation loss:		2.048113
  validation accuracy:		25.00 %
Epoch 312 of 2000 took 0.097s
  training loss:		2.105649
  validation loss:		2.024117
  validation accuracy:		29.35 %
Epoch 313 of 2000 took 0.096s
  training loss:		2.083494
  validation loss:		2.002127
  validation accuracy:		29.46 %
Epoch 314 of 2000 took 0.102s
  training loss:		2.057696
  validation loss:		1.973612
  validation accuracy:		26.30 %
Epoch 315 of 2000 took 0.097s
  training loss:		2.027709
  validation loss:		1.938043
  validation accuracy:		29.35 %
Epoch 316 of 2000 took 0.097s
  training loss:		1.993571
  validation loss:		1.904684
  validation accuracy:		28.15 %
Epoch 317 of 2000 took 0.096s
  training loss:		1.960054
  validation loss:		1.869156
  validation accuracy:		28.59 %
Epoch 318 of 2000 took 0.097s
  training loss:		1.929309
  validation loss:		1.833320
  validation accuracy:		31.96 %
Epoch 319 of 2000 took 0.100s
  training loss:		1.897859
  validation loss:		1.804357
  validation accuracy:		34.02 %
Epoch 320 of 2000 took 0.097s
  training loss:		1.862899
  validation loss:		1.772018
  validation accuracy:		34.13 %
Epoch 321 of 2000 took 0.097s
  training loss:		1.830898
  validation loss:		1.741568
  validation accuracy:		33.26 %
Epoch 322 of 2000 took 0.102s
  training loss:		1.804539
  validation loss:		1.708600
  validation accuracy:		35.00 %
Epoch 323 of 2000 took 0.096s
  training loss:		1.772174
  validation loss:		1.680836
  validation accuracy:		36.30 %
Epoch 324 of 2000 took 0.097s
  training loss:		1.745957
  validation loss:		1.655627
  validation accuracy:		38.15 %
Epoch 325 of 2000 took 0.096s
  training loss:		1.720608
  validation loss:		1.633011
  validation accuracy:		38.80 %
Epoch 326 of 2000 took 0.098s
  training loss:		1.689828
  validation loss:		1.610317
  validation accuracy:		39.89 %
Epoch 327 of 2000 took 0.100s
  training loss:		1.665962
  validation loss:		1.586805
  validation accuracy:		41.20 %
Epoch 328 of 2000 took 0.096s
  training loss:		1.646296
  validation loss:		1.563619
  validation accuracy:		40.98 %
Epoch 329 of 2000 took 0.097s
  training loss:		1.626942
  validation loss:		1.542237
  validation accuracy:		42.17 %
Epoch 330 of 2000 took 0.101s
  training loss:		1.604891
  validation loss:		1.526747
  validation accuracy:		42.83 %
Epoch 331 of 2000 took 0.096s
  training loss:		1.583136
  validation loss:		1.506662
  validation accuracy:		44.89 %
Epoch 332 of 2000 took 0.097s
  training loss:		1.568028
  validation loss:		1.484080
  validation accuracy:		44.46 %
Epoch 333 of 2000 took 0.096s
  training loss:		1.548122
  validation loss:		1.474255
  validation accuracy:		44.89 %
Epoch 334 of 2000 took 0.100s
  training loss:		1.535518
  validation loss:		1.453063
  validation accuracy:		45.87 %
Epoch 335 of 2000 took 0.098s
  training loss:		1.514054
  validation loss:		1.442674
  validation accuracy:		47.17 %
Epoch 336 of 2000 took 0.096s
  training loss:		1.495475
  validation loss:		1.426522
  validation accuracy:		48.37 %
Epoch 337 of 2000 took 0.100s
  training loss:		1.484073
  validation loss:		1.406960
  validation accuracy:		48.48 %
Epoch 338 of 2000 took 0.098s
  training loss:		1.475951
  validation loss:		1.397380
  validation accuracy:		48.91 %
Epoch 339 of 2000 took 0.096s
  training loss:		1.459386
  validation loss:		1.389097
  validation accuracy:		46.85 %
Epoch 340 of 2000 took 0.097s
  training loss:		1.442263
  validation loss:		1.369175
  validation accuracy:		48.26 %
Epoch 341 of 2000 took 0.096s
  training loss:		1.429964
  validation loss:		1.359216
  validation accuracy:		51.09 %
Epoch 342 of 2000 took 0.100s
  training loss:		1.435391
  validation loss:		1.351897
  validation accuracy:		50.54 %
Epoch 343 of 2000 took 0.097s
  training loss:		1.419364
  validation loss:		1.343658
  validation accuracy:		50.43 %
Epoch 344 of 2000 took 0.096s
  training loss:		1.404936
  validation loss:		1.332883
  validation accuracy:		51.52 %
Epoch 345 of 2000 took 0.102s
  training loss:		1.404907
  validation loss:		1.328129
  validation accuracy:		50.98 %
Epoch 346 of 2000 took 0.096s
  training loss:		1.385882
  validation loss:		1.317534
  validation accuracy:		51.09 %
Epoch 347 of 2000 took 0.097s
  training loss:		1.385226
  validation loss:		1.314210
  validation accuracy:		51.96 %
Epoch 348 of 2000 took 0.096s
  training loss:		1.376698
  validation loss:		1.311417
  validation accuracy:		50.54 %
Epoch 349 of 2000 took 0.097s
  training loss:		1.362378
  validation loss:		1.325719
  validation accuracy:		47.39 %
Epoch 350 of 2000 took 0.100s
  training loss:		1.367686
  validation loss:		1.294224
  validation accuracy:		52.39 %
Epoch 351 of 2000 took 0.096s
  training loss:		1.393503
  validation loss:		1.352307
  validation accuracy:		45.33 %
Epoch 352 of 2000 took 0.097s
  training loss:		1.437310
  validation loss:		1.350956
  validation accuracy:		48.26 %
Epoch 353 of 2000 took 0.102s
  training loss:		1.355766
  validation loss:		1.308202
  validation accuracy:		49.78 %
Epoch 354 of 2000 took 0.096s
  training loss:		1.375048
  validation loss:		1.275257
  validation accuracy:		52.83 %
Epoch 355 of 2000 took 0.097s
  training loss:		1.464507
  validation loss:		1.383339
  validation accuracy:		45.98 %
Epoch 356 of 2000 took 0.096s
  training loss:		1.409227
  validation loss:		1.293358
  validation accuracy:		51.74 %
Epoch 357 of 2000 took 0.098s
  training loss:		1.376000
  validation loss:		1.343889
  validation accuracy:		47.07 %
Epoch 358 of 2000 took 0.099s
  training loss:		1.327736
  validation loss:		1.258248
  validation accuracy:		53.37 %
Epoch 359 of 2000 took 0.096s
  training loss:		1.330429
  validation loss:		1.265032
  validation accuracy:		51.74 %
Epoch 360 of 2000 took 0.098s
  training loss:		1.324933
  validation loss:		1.302234
  validation accuracy:		51.30 %
Epoch 361 of 2000 took 0.100s
  training loss:		1.340752
  validation loss:		1.330375
  validation accuracy:		49.67 %
Epoch 362 of 2000 took 0.096s
  training loss:		1.411234
  validation loss:		1.348525
  validation accuracy:		47.07 %
Epoch 363 of 2000 took 0.097s
  training loss:		1.381920
  validation loss:		1.314596
  validation accuracy:		51.30 %
Epoch 364 of 2000 took 0.096s
  training loss:		1.323549
  validation loss:		1.297005
  validation accuracy:		51.63 %
Epoch 365 of 2000 took 0.101s
  training loss:		1.550395
  validation loss:		1.389590
  validation accuracy:		46.74 %
Epoch 366 of 2000 took 0.097s
  training loss:		1.358465
  validation loss:		1.299242
  validation accuracy:		52.50 %
Epoch 367 of 2000 took 0.096s
  training loss:		1.322816
  validation loss:		1.236913
  validation accuracy:		54.57 %
Epoch 368 of 2000 took 0.101s
  training loss:		1.298344
  validation loss:		1.244534
  validation accuracy:		53.48 %
Epoch 369 of 2000 took 0.098s
  training loss:		1.366199
  validation loss:		1.385035
  validation accuracy:		45.76 %
Epoch 370 of 2000 took 0.096s
  training loss:		1.344130
  validation loss:		1.234768
  validation accuracy:		54.46 %
Epoch 371 of 2000 took 0.097s
  training loss:		1.295676
  validation loss:		1.244663
  validation accuracy:		54.35 %
Epoch 372 of 2000 took 0.096s
  training loss:		1.426901
  validation loss:		1.369458
  validation accuracy:		46.96 %
Epoch 373 of 2000 took 0.100s
  training loss:		1.355942
  validation loss:		1.240403
  validation accuracy:		54.46 %
Epoch 374 of 2000 took 0.097s
  training loss:		1.280564
  validation loss:		1.223338
  validation accuracy:		54.24 %
Epoch 375 of 2000 took 0.096s
  training loss:		1.343513
  validation loss:		1.326954
  validation accuracy:		49.13 %
Epoch 376 of 2000 took 0.102s
  training loss:		1.362749
  validation loss:		1.237461
  validation accuracy:		55.00 %
Epoch 377 of 2000 took 0.096s
  training loss:		1.347320
  validation loss:		1.426501
  validation accuracy:		44.35 %
Epoch 378 of 2000 took 0.097s
  training loss:		1.424716
  validation loss:		1.262703
  validation accuracy:		54.35 %
Epoch 379 of 2000 took 0.096s
  training loss:		1.283544
  validation loss:		1.226375
  validation accuracy:		55.11 %
Epoch 380 of 2000 took 0.097s
  training loss:		1.266736
  validation loss:		1.252971
  validation accuracy:		51.20 %
Epoch 381 of 2000 took 0.101s
  training loss:		1.302894
  validation loss:		1.255901
  validation accuracy:		52.50 %
Epoch 382 of 2000 took 0.096s
  training loss:		1.284964
  validation loss:		1.250203
  validation accuracy:		53.48 %
Epoch 383 of 2000 took 0.097s
  training loss:		1.269884
  validation loss:		1.217138
  validation accuracy:		55.22 %
Epoch 384 of 2000 took 0.102s
  training loss:		1.264075
  validation loss:		1.237238
  validation accuracy:		54.13 %
Epoch 385 of 2000 took 0.096s
  training loss:		1.288991
  validation loss:		1.209496
  validation accuracy:		56.09 %
Epoch 386 of 2000 took 0.097s
  training loss:		1.255277
  validation loss:		1.213354
  validation accuracy:		56.20 %
Epoch 387 of 2000 took 0.096s
  training loss:		1.279887
  validation loss:		1.204409
  validation accuracy:		55.87 %
Epoch 388 of 2000 took 0.099s
  training loss:		1.307993
  validation loss:		1.605674
  validation accuracy:		38.59 %
Epoch 389 of 2000 took 0.099s
  training loss:		1.691847
  validation loss:		1.258200
  validation accuracy:		55.22 %
Epoch 390 of 2000 took 0.096s
  training loss:		1.288356
  validation loss:		1.213490
  validation accuracy:		55.76 %
Epoch 391 of 2000 took 0.099s
  training loss:		1.272412
  validation loss:		1.206599
  validation accuracy:		55.43 %
Epoch 392 of 2000 took 0.100s
  training loss:		1.315294
  validation loss:		1.279799
  validation accuracy:		51.63 %
Epoch 393 of 2000 took 0.096s
  training loss:		1.277884
  validation loss:		1.207623
  validation accuracy:		55.76 %
Epoch 394 of 2000 took 0.097s
  training loss:		1.253510
  validation loss:		1.201084
  validation accuracy:		55.65 %
Epoch 395 of 2000 took 0.096s
  training loss:		1.250036
  validation loss:		1.212069
  validation accuracy:		54.67 %
Epoch 396 of 2000 took 0.101s
  training loss:		1.272250
  validation loss:		1.252592
  validation accuracy:		53.37 %
Epoch 397 of 2000 took 0.100s
  training loss:		1.274340
  validation loss:		1.191002
  validation accuracy:		57.17 %
Epoch 398 of 2000 took 0.099s
  training loss:		1.274323
  validation loss:		1.207545
  validation accuracy:		56.41 %
Epoch 399 of 2000 took 0.105s
  training loss:		1.258817
  validation loss:		1.222379
  validation accuracy:		55.22 %
Epoch 400 of 2000 took 0.100s
  training loss:		1.261341
  validation loss:		1.212115
  validation accuracy:		55.00 %
Epoch 401 of 2000 took 0.100s
  training loss:		1.429084
  validation loss:		1.591362
  validation accuracy:		39.89 %
Epoch 402 of 2000 took 0.100s
  training loss:		1.442355
  validation loss:		1.216516
  validation accuracy:		57.50 %
Epoch 403 of 2000 took 0.100s
  training loss:		1.251213
  validation loss:		1.213905
  validation accuracy:		56.20 %
Epoch 404 of 2000 took 0.103s
  training loss:		1.249274
  validation loss:		1.194479
  validation accuracy:		56.20 %
Epoch 405 of 2000 took 0.100s
  training loss:		1.313483
  validation loss:		1.221814
  validation accuracy:		54.13 %
Epoch 406 of 2000 took 0.100s
  training loss:		1.273430
  validation loss:		1.273908
  validation accuracy:		53.37 %
Epoch 407 of 2000 took 0.105s
  training loss:		1.288328
  validation loss:		1.222882
  validation accuracy:		55.54 %
Epoch 408 of 2000 took 0.099s
  training loss:		1.252002
  validation loss:		1.181586
  validation accuracy:		57.93 %
Epoch 409 of 2000 took 0.100s
  training loss:		1.237286
  validation loss:		1.177890
  validation accuracy:		57.93 %
Epoch 410 of 2000 took 0.099s
  training loss:		1.247639
  validation loss:		1.225778
  validation accuracy:		56.20 %
Epoch 411 of 2000 took 0.101s
  training loss:		1.311087
  validation loss:		1.235475
  validation accuracy:		54.24 %
Epoch 412 of 2000 took 0.103s
  training loss:		1.368865
  validation loss:		1.212277
  validation accuracy:		56.85 %
Epoch 413 of 2000 took 0.099s
  training loss:		1.247879
  validation loss:		1.180970
  validation accuracy:		57.93 %
Epoch 414 of 2000 took 0.100s
  training loss:		1.273173
  validation loss:		1.195725
  validation accuracy:		57.72 %
Epoch 415 of 2000 took 0.105s
  training loss:		1.246338
  validation loss:		1.186320
  validation accuracy:		57.07 %
Epoch 416 of 2000 took 0.099s
  training loss:		1.303173
  validation loss:		1.269639
  validation accuracy:		53.37 %
Epoch 417 of 2000 took 0.100s
  training loss:		1.256393
  validation loss:		1.173730
  validation accuracy:		57.83 %
Epoch 418 of 2000 took 0.099s
  training loss:		1.245616
  validation loss:		1.166388
  validation accuracy:		57.93 %
Epoch 419 of 2000 took 0.103s
  training loss:		1.234843
  validation loss:		1.187941
  validation accuracy:		58.37 %
Epoch 420 of 2000 took 0.101s
  training loss:		1.230751
  validation loss:		1.176189
  validation accuracy:		58.37 %
Epoch 421 of 2000 took 0.099s
  training loss:		1.276164
  validation loss:		1.233076
  validation accuracy:		54.67 %
Epoch 422 of 2000 took 0.103s
  training loss:		1.263698
  validation loss:		1.171437
  validation accuracy:		58.15 %
Epoch 423 of 2000 took 0.102s
  training loss:		1.245174
  validation loss:		1.273749
  validation accuracy:		52.50 %
Epoch 424 of 2000 took 0.099s
  training loss:		1.298705
  validation loss:		1.170018
  validation accuracy:		58.70 %
Epoch 425 of 2000 took 0.100s
  training loss:		1.221196
  validation loss:		1.171252
  validation accuracy:		58.91 %
Epoch 426 of 2000 took 0.099s
  training loss:		1.234737
  validation loss:		1.225192
  validation accuracy:		54.89 %
Epoch 427 of 2000 took 0.104s
  training loss:		1.426955
  validation loss:		1.278844
  validation accuracy:		54.13 %
Epoch 428 of 2000 took 0.101s
  training loss:		1.243128
  validation loss:		1.189010
  validation accuracy:		57.93 %
Epoch 429 of 2000 took 0.099s
  training loss:		1.218811
  validation loss:		1.155310
  validation accuracy:		58.48 %
Epoch 430 of 2000 took 0.105s
  training loss:		1.222002
  validation loss:		1.160837
  validation accuracy:		58.26 %
Epoch 431 of 2000 took 0.100s
  training loss:		1.226095
  validation loss:		1.153117
  validation accuracy:		59.24 %
Epoch 432 of 2000 took 0.100s
  training loss:		1.220370
  validation loss:		1.156488
  validation accuracy:		59.13 %
Epoch 433 of 2000 took 0.099s
  training loss:		1.216414
  validation loss:		1.149908
  validation accuracy:		59.67 %
Epoch 434 of 2000 took 0.100s
  training loss:		1.231599
  validation loss:		1.196096
  validation accuracy:		56.41 %
Epoch 435 of 2000 took 0.103s
  training loss:		1.222490
  validation loss:		1.151553
  validation accuracy:		59.35 %
Epoch 436 of 2000 took 0.099s
  training loss:		1.215999
  validation loss:		1.148583
  validation accuracy:		60.11 %
Epoch 437 of 2000 took 0.097s
  training loss:		1.224777
  validation loss:		1.195628
  validation accuracy:		57.83 %
Epoch 438 of 2000 took 0.102s
  training loss:		1.251147
  validation loss:		1.177310
  validation accuracy:		57.50 %
Epoch 439 of 2000 took 0.096s
  training loss:		1.231942
  validation loss:		1.151803
  validation accuracy:		60.22 %
Epoch 440 of 2000 took 0.097s
  training loss:		1.220249
  validation loss:		1.153486
  validation accuracy:		60.33 %
Epoch 441 of 2000 took 0.096s
  training loss:		1.212603
  validation loss:		1.148477
  validation accuracy:		60.11 %
Epoch 442 of 2000 took 0.098s
  training loss:		1.296309
  validation loss:		1.249916
  validation accuracy:		55.11 %
Epoch 443 of 2000 took 0.100s
  training loss:		1.215544
  validation loss:		1.183333
  validation accuracy:		58.37 %
Epoch 444 of 2000 took 0.096s
  training loss:		1.202097
  validation loss:		1.129350
  validation accuracy:		61.20 %
Epoch 445 of 2000 took 0.097s
  training loss:		1.207365
  validation loss:		1.214731
  validation accuracy:		55.76 %
Epoch 446 of 2000 took 0.104s
  training loss:		1.248280
  validation loss:		1.132461
  validation accuracy:		60.98 %
Epoch 447 of 2000 took 0.096s
  training loss:		1.203648
  validation loss:		1.149949
  validation accuracy:		58.70 %
Epoch 448 of 2000 took 0.097s
  training loss:		1.245653
  validation loss:		1.126383
  validation accuracy:		61.96 %
Epoch 449 of 2000 took 0.096s
  training loss:		1.197472
  validation loss:		1.143395
  validation accuracy:		59.24 %
Epoch 450 of 2000 took 0.101s
  training loss:		1.187609
  validation loss:		1.124281
  validation accuracy:		61.30 %
Epoch 451 of 2000 took 0.098s
  training loss:		1.194005
  validation loss:		1.120741
  validation accuracy:		61.74 %
Epoch 452 of 2000 took 0.096s
  training loss:		1.187207
  validation loss:		1.162467
  validation accuracy:		57.50 %
Epoch 453 of 2000 took 0.100s
  training loss:		1.208890
  validation loss:		1.125408
  validation accuracy:		60.87 %
Epoch 454 of 2000 took 0.098s
  training loss:		1.187079
  validation loss:		1.109303
  validation accuracy:		62.61 %
Epoch 455 of 2000 took 0.096s
  training loss:		1.181392
  validation loss:		1.103437
  validation accuracy:		62.28 %
Epoch 456 of 2000 took 0.096s
  training loss:		1.181701
  validation loss:		1.153866
  validation accuracy:		60.00 %
Epoch 457 of 2000 took 0.096s
  training loss:		1.180792
  validation loss:		1.141265
  validation accuracy:		60.54 %
Epoch 458 of 2000 took 0.100s
  training loss:		1.177796
  validation loss:		1.088752
  validation accuracy:		63.26 %
Epoch 459 of 2000 took 0.097s
  training loss:		1.174744
  validation loss:		1.099013
  validation accuracy:		62.61 %
Epoch 460 of 2000 took 0.096s
  training loss:		1.152083
  validation loss:		1.080096
  validation accuracy:		63.59 %
Epoch 461 of 2000 took 0.102s
  training loss:		1.155122
  validation loss:		1.077013
  validation accuracy:		63.59 %
Epoch 462 of 2000 took 0.096s
  training loss:		1.210455
  validation loss:		1.073812
  validation accuracy:		63.80 %
Epoch 463 of 2000 took 0.097s
  training loss:		1.146059
  validation loss:		1.066025
  validation accuracy:		64.46 %
Epoch 464 of 2000 took 0.096s
  training loss:		1.130301
  validation loss:		1.065446
  validation accuracy:		63.70 %
Epoch 465 of 2000 took 0.097s
  training loss:		1.154462
  validation loss:		1.066134
  validation accuracy:		64.02 %
Epoch 466 of 2000 took 0.100s
  training loss:		1.158308
  validation loss:		1.147614
  validation accuracy:		61.30 %
Epoch 467 of 2000 took 0.096s
  training loss:		1.137642
  validation loss:		1.046049
  validation accuracy:		65.11 %
Epoch 468 of 2000 took 0.097s
  training loss:		1.133245
  validation loss:		1.034664
  validation accuracy:		65.54 %
Epoch 469 of 2000 took 0.102s
  training loss:		1.128473
  validation loss:		1.082521
  validation accuracy:		63.59 %
Epoch 470 of 2000 took 0.096s
  training loss:		1.114448
  validation loss:		1.023152
  validation accuracy:		66.09 %
Epoch 471 of 2000 took 0.097s
  training loss:		1.137390
  validation loss:		1.018221
  validation accuracy:		65.54 %
Epoch 472 of 2000 took 0.096s
  training loss:		1.110144
  validation loss:		1.006395
  validation accuracy:		66.20 %
Epoch 473 of 2000 took 0.098s
  training loss:		1.096422
  validation loss:		1.011023
  validation accuracy:		64.67 %
Epoch 474 of 2000 took 0.099s
  training loss:		1.085136
  validation loss:		0.996590
  validation accuracy:		66.41 %
Epoch 475 of 2000 took 0.096s
  training loss:		1.081106
  validation loss:		0.986496
  validation accuracy:		66.85 %
Epoch 476 of 2000 took 0.098s
  training loss:		1.061006
  validation loss:		0.976342
  validation accuracy:		67.39 %
Epoch 477 of 2000 took 0.101s
  training loss:		1.066639
  validation loss:		0.998266
  validation accuracy:		65.98 %
Epoch 478 of 2000 took 0.096s
  training loss:		1.062153
  validation loss:		0.956502
  validation accuracy:		67.93 %
Epoch 479 of 2000 took 0.097s
  training loss:		1.045673
  validation loss:		0.951110
  validation accuracy:		67.61 %
Epoch 480 of 2000 took 0.096s
  training loss:		1.058992
  validation loss:		1.035543
  validation accuracy:		62.17 %
Epoch 481 of 2000 took 0.101s
  training loss:		1.078425
  validation loss:		0.939977
  validation accuracy:		67.93 %
Epoch 482 of 2000 took 0.098s
  training loss:		1.034475
  validation loss:		0.925921
  validation accuracy:		68.59 %
Epoch 483 of 2000 took 0.096s
  training loss:		1.020834
  validation loss:		0.919253
  validation accuracy:		69.67 %
Epoch 484 of 2000 took 0.101s
  training loss:		1.015076
  validation loss:		0.910464
  validation accuracy:		68.91 %
Epoch 485 of 2000 took 0.098s
  training loss:		1.011494
  validation loss:		0.906230
  validation accuracy:		68.91 %
Epoch 486 of 2000 took 0.096s
  training loss:		1.002379
  validation loss:		0.891475
  validation accuracy:		70.65 %
Epoch 487 of 2000 took 0.096s
  training loss:		0.983436
  validation loss:		0.887734
  validation accuracy:		70.11 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.975640
  validation loss:		0.935455
  validation accuracy:		68.80 %
Epoch 489 of 2000 took 0.100s
  training loss:		0.986751
  validation loss:		0.888682
  validation accuracy:		69.89 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.955504
  validation loss:		0.892712
  validation accuracy:		69.89 %
Epoch 491 of 2000 took 0.096s
  training loss:		0.954864
  validation loss:		0.855067
  validation accuracy:		71.63 %
Epoch 492 of 2000 took 0.102s
  training loss:		0.946601
  validation loss:		0.860975
  validation accuracy:		71.20 %
Epoch 493 of 2000 took 0.096s
  training loss:		0.932050
  validation loss:		0.873676
  validation accuracy:		70.98 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.935751
  validation loss:		0.837442
  validation accuracy:		72.50 %
Epoch 495 of 2000 took 0.096s
  training loss:		0.933893
  validation loss:		0.827264
  validation accuracy:		72.07 %
Epoch 496 of 2000 took 0.098s
  training loss:		0.909017
  validation loss:		0.823499
  validation accuracy:		73.15 %
Epoch 497 of 2000 took 0.100s
  training loss:		0.903918
  validation loss:		0.824469
  validation accuracy:		72.50 %
Epoch 498 of 2000 took 0.096s
  training loss:		0.895997
  validation loss:		0.819667
  validation accuracy:		72.83 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.907741
  validation loss:		0.800205
  validation accuracy:		73.91 %
Epoch 500 of 2000 took 0.102s
  training loss:		0.886363
  validation loss:		0.790444
  validation accuracy:		74.78 %
Epoch 501 of 2000 took 0.096s
  training loss:		0.873456
  validation loss:		0.781064
  validation accuracy:		74.89 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.870231
  validation loss:		0.775170
  validation accuracy:		75.54 %
Epoch 503 of 2000 took 0.096s
  training loss:		0.861363
  validation loss:		0.777204
  validation accuracy:		75.22 %
Epoch 504 of 2000 took 0.099s
  training loss:		0.852546
  validation loss:		0.761941
  validation accuracy:		76.52 %
Epoch 505 of 2000 took 0.098s
  training loss:		0.847785
  validation loss:		0.754216
  validation accuracy:		76.30 %
Epoch 506 of 2000 took 0.096s
  training loss:		0.841366
  validation loss:		0.769568
  validation accuracy:		75.22 %
Epoch 507 of 2000 took 0.099s
  training loss:		0.849793
  validation loss:		0.753778
  validation accuracy:		76.20 %
Epoch 508 of 2000 took 0.100s
  training loss:		0.819847
  validation loss:		0.733565
  validation accuracy:		76.96 %
Epoch 509 of 2000 took 0.096s
  training loss:		0.816666
  validation loss:		0.726387
  validation accuracy:		77.28 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.811220
  validation loss:		0.731632
  validation accuracy:		76.63 %
Epoch 511 of 2000 took 0.096s
  training loss:		0.814385
  validation loss:		0.718072
  validation accuracy:		76.85 %
Epoch 512 of 2000 took 0.101s
  training loss:		0.795674
  validation loss:		0.743892
  validation accuracy:		75.87 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.790424
  validation loss:		0.709619
  validation accuracy:		77.17 %
Epoch 514 of 2000 took 0.096s
  training loss:		0.787747
  validation loss:		0.697927
  validation accuracy:		77.61 %
Epoch 515 of 2000 took 0.102s
  training loss:		0.771856
  validation loss:		0.695322
  validation accuracy:		77.72 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.773107
  validation loss:		0.687609
  validation accuracy:		78.59 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.762932
  validation loss:		0.679257
  validation accuracy:		77.83 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.751066
  validation loss:		0.675813
  validation accuracy:		78.15 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.754042
  validation loss:		0.667926
  validation accuracy:		78.80 %
Epoch 520 of 2000 took 0.100s
  training loss:		0.743889
  validation loss:		0.672683
  validation accuracy:		78.59 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.734433
  validation loss:		0.656553
  validation accuracy:		79.57 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.722950
  validation loss:		0.656409
  validation accuracy:		79.13 %
Epoch 523 of 2000 took 0.102s
  training loss:		0.739434
  validation loss:		0.659807
  validation accuracy:		78.70 %
Epoch 524 of 2000 took 0.096s
  training loss:		0.715717
  validation loss:		0.653773
  validation accuracy:		79.57 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.711210
  validation loss:		0.652504
  validation accuracy:		79.35 %
Epoch 526 of 2000 took 0.096s
  training loss:		0.704542
  validation loss:		0.643954
  validation accuracy:		79.57 %
Epoch 527 of 2000 took 0.098s
  training loss:		0.697281
  validation loss:		0.630858
  validation accuracy:		80.22 %
Epoch 528 of 2000 took 0.100s
  training loss:		0.707035
  validation loss:		0.629700
  validation accuracy:		80.43 %
Epoch 529 of 2000 took 0.096s
  training loss:		0.686254
  validation loss:		0.620156
  validation accuracy:		80.33 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.675467
  validation loss:		0.638823
  validation accuracy:		80.65 %
Epoch 531 of 2000 took 0.102s
  training loss:		0.683471
  validation loss:		0.625596
  validation accuracy:		80.87 %
Epoch 532 of 2000 took 0.096s
  training loss:		0.668776
  validation loss:		0.631204
  validation accuracy:		80.11 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.670005
  validation loss:		0.620353
  validation accuracy:		80.54 %
Epoch 534 of 2000 took 0.096s
  training loss:		0.660076
  validation loss:		0.611151
  validation accuracy:		81.20 %
Epoch 535 of 2000 took 0.099s
  training loss:		0.665687
  validation loss:		0.604093
  validation accuracy:		81.52 %
Epoch 536 of 2000 took 0.098s
  training loss:		0.658711
  validation loss:		0.610426
  validation accuracy:		81.52 %
Epoch 537 of 2000 took 0.096s
  training loss:		0.645597
  validation loss:		0.596298
  validation accuracy:		81.41 %
Epoch 538 of 2000 took 0.099s
  training loss:		0.645505
  validation loss:		0.597441
  validation accuracy:		81.63 %
Epoch 539 of 2000 took 0.100s
  training loss:		0.639791
  validation loss:		0.594600
  validation accuracy:		82.28 %
Epoch 540 of 2000 took 0.096s
  training loss:		0.637320
  validation loss:		0.581649
  validation accuracy:		81.96 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.629543
  validation loss:		0.585514
  validation accuracy:		82.28 %
Epoch 542 of 2000 took 0.096s
  training loss:		0.625583
  validation loss:		0.586850
  validation accuracy:		81.52 %
Epoch 543 of 2000 took 0.101s
  training loss:		0.626551
  validation loss:		0.578622
  validation accuracy:		81.52 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.618088
  validation loss:		0.585025
  validation accuracy:		82.07 %
Epoch 545 of 2000 took 0.096s
  training loss:		0.614970
  validation loss:		0.568038
  validation accuracy:		82.50 %
Epoch 546 of 2000 took 0.102s
  training loss:		0.613449
  validation loss:		0.562398
  validation accuracy:		82.61 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.613850
  validation loss:		0.564123
  validation accuracy:		82.93 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.610712
  validation loss:		0.562791
  validation accuracy:		82.39 %
Epoch 549 of 2000 took 0.096s
  training loss:		0.603556
  validation loss:		0.567025
  validation accuracy:		82.50 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.596613
  validation loss:		0.555192
  validation accuracy:		82.83 %
Epoch 551 of 2000 took 0.100s
  training loss:		0.598397
  validation loss:		0.570896
  validation accuracy:		82.39 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.595066
  validation loss:		0.549633
  validation accuracy:		82.83 %
Epoch 553 of 2000 took 0.096s
  training loss:		0.587103
  validation loss:		0.581930
  validation accuracy:		82.17 %
Epoch 554 of 2000 took 0.102s
  training loss:		0.595602
  validation loss:		0.549412
  validation accuracy:		82.93 %
Epoch 555 of 2000 took 0.096s
  training loss:		0.586766
  validation loss:		0.546454
  validation accuracy:		83.04 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.585700
  validation loss:		0.552867
  validation accuracy:		82.72 %
Epoch 557 of 2000 took 0.096s
  training loss:		0.578634
  validation loss:		0.538862
  validation accuracy:		82.83 %
Epoch 558 of 2000 took 0.098s
  training loss:		0.580375
  validation loss:		0.555334
  validation accuracy:		82.61 %
Epoch 559 of 2000 took 0.143s
  training loss:		0.574540
  validation loss:		0.531628
  validation accuracy:		83.37 %
Epoch 560 of 2000 took 0.100s
  training loss:		0.571193
  validation loss:		0.527197
  validation accuracy:		83.26 %
Epoch 561 of 2000 took 0.098s
  training loss:		0.564404
  validation loss:		0.542079
  validation accuracy:		83.15 %
Epoch 562 of 2000 took 0.105s
  training loss:		0.567477
  validation loss:		0.525279
  validation accuracy:		83.04 %
Epoch 563 of 2000 took 0.101s
  training loss:		0.556024
  validation loss:		0.532665
  validation accuracy:		82.83 %
Epoch 564 of 2000 took 0.102s
  training loss:		0.554532
  validation loss:		0.528149
  validation accuracy:		82.83 %
Epoch 565 of 2000 took 0.099s
  training loss:		0.553614
  validation loss:		0.531764
  validation accuracy:		83.04 %
Epoch 566 of 2000 took 0.104s
  training loss:		0.561235
  validation loss:		0.516604
  validation accuracy:		83.37 %
Epoch 567 of 2000 took 0.101s
  training loss:		0.553659
  validation loss:		0.523809
  validation accuracy:		82.61 %
Epoch 568 of 2000 took 0.099s
  training loss:		0.548874
  validation loss:		0.521220
  validation accuracy:		83.48 %
Epoch 569 of 2000 took 0.103s
  training loss:		0.538048
  validation loss:		0.508364
  validation accuracy:		83.15 %
Epoch 570 of 2000 took 0.102s
  training loss:		0.540593
  validation loss:		0.517861
  validation accuracy:		82.72 %
Epoch 571 of 2000 took 0.100s
  training loss:		0.533722
  validation loss:		0.505291
  validation accuracy:		84.13 %
Epoch 572 of 2000 took 0.098s
  training loss:		0.537224
  validation loss:		0.503725
  validation accuracy:		83.26 %
Epoch 573 of 2000 took 0.096s
  training loss:		0.535477
  validation loss:		0.502598
  validation accuracy:		83.26 %
Epoch 574 of 2000 took 0.101s
  training loss:		0.530319
  validation loss:		0.514274
  validation accuracy:		83.37 %
Epoch 575 of 2000 took 0.098s
  training loss:		0.533845
  validation loss:		0.509817
  validation accuracy:		83.48 %
Epoch 576 of 2000 took 0.096s
  training loss:		0.525462
  validation loss:		0.499182
  validation accuracy:		83.91 %
Epoch 577 of 2000 took 0.102s
  training loss:		0.524317
  validation loss:		0.498387
  validation accuracy:		83.70 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.519451
  validation loss:		0.506106
  validation accuracy:		84.02 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.528374
  validation loss:		0.500852
  validation accuracy:		84.13 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.519087
  validation loss:		0.501782
  validation accuracy:		83.70 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.515774
  validation loss:		0.488558
  validation accuracy:		84.35 %
Epoch 582 of 2000 took 0.100s
  training loss:		0.520297
  validation loss:		0.513891
  validation accuracy:		83.26 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.511785
  validation loss:		0.498902
  validation accuracy:		84.24 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.512111
  validation loss:		0.496551
  validation accuracy:		84.67 %
Epoch 585 of 2000 took 0.102s
  training loss:		0.514169
  validation loss:		0.490139
  validation accuracy:		84.46 %
Epoch 586 of 2000 took 0.096s
  training loss:		0.499915
  validation loss:		0.486149
  validation accuracy:		83.91 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.500782
  validation loss:		0.492717
  validation accuracy:		84.46 %
Epoch 588 of 2000 took 0.096s
  training loss:		0.507510
  validation loss:		0.478147
  validation accuracy:		84.46 %
Epoch 589 of 2000 took 0.098s
  training loss:		0.491484
  validation loss:		0.482893
  validation accuracy:		84.78 %
Epoch 590 of 2000 took 0.100s
  training loss:		0.501453
  validation loss:		0.486836
  validation accuracy:		84.35 %
Epoch 591 of 2000 took 0.096s
  training loss:		0.506501
  validation loss:		0.485784
  validation accuracy:		84.46 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.495724
  validation loss:		0.482344
  validation accuracy:		84.35 %
Epoch 593 of 2000 took 0.102s
  training loss:		0.495651
  validation loss:		0.474061
  validation accuracy:		85.00 %
Epoch 594 of 2000 took 0.096s
  training loss:		0.494687
  validation loss:		0.523379
  validation accuracy:		83.48 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.498635
  validation loss:		0.485856
  validation accuracy:		84.57 %
Epoch 596 of 2000 took 0.096s
  training loss:		0.497626
  validation loss:		0.480579
  validation accuracy:		84.89 %
Epoch 597 of 2000 took 0.100s
  training loss:		0.491698
  validation loss:		0.467789
  validation accuracy:		85.11 %
Epoch 598 of 2000 took 0.147s
  training loss:		0.489783
  validation loss:		0.494911
  validation accuracy:		83.70 %
Epoch 599 of 2000 took 0.165s
  training loss:		0.484290
  validation loss:		0.465252
  validation accuracy:		85.00 %
Epoch 600 of 2000 took 0.170s
  training loss:		0.481977
  validation loss:		0.484653
  validation accuracy:		83.91 %
Epoch 601 of 2000 took 0.167s
  training loss:		0.483029
  validation loss:		0.482651
  validation accuracy:		84.35 %
Epoch 602 of 2000 took 0.166s
  training loss:		0.486630
  validation loss:		0.468627
  validation accuracy:		85.00 %
Epoch 603 of 2000 took 0.166s
  training loss:		0.488272
  validation loss:		0.461825
  validation accuracy:		85.22 %
Epoch 604 of 2000 took 0.166s
  training loss:		0.478978
  validation loss:		0.470366
  validation accuracy:		84.78 %
Epoch 605 of 2000 took 0.169s
  training loss:		0.485617
  validation loss:		0.475613
  validation accuracy:		84.57 %
Epoch 606 of 2000 took 0.105s
  training loss:		0.471038
  validation loss:		0.456124
  validation accuracy:		86.09 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.472642
  validation loss:		0.466766
  validation accuracy:		84.78 %
Epoch 608 of 2000 took 0.103s
  training loss:		0.476839
  validation loss:		0.461032
  validation accuracy:		85.76 %
Epoch 609 of 2000 took 0.101s
  training loss:		0.472821
  validation loss:		0.466103
  validation accuracy:		84.67 %
Epoch 610 of 2000 took 0.106s
  training loss:		0.475405
  validation loss:		0.455753
  validation accuracy:		85.22 %
Epoch 611 of 2000 took 0.099s
  training loss:		0.475936
  validation loss:		0.473645
  validation accuracy:		84.89 %
Epoch 612 of 2000 took 0.100s
  training loss:		0.480402
  validation loss:		0.457476
  validation accuracy:		84.78 %
Epoch 613 of 2000 took 0.102s
  training loss:		0.456868
  validation loss:		0.454818
  validation accuracy:		85.33 %
Epoch 614 of 2000 took 0.099s
  training loss:		0.465594
  validation loss:		0.449043
  validation accuracy:		85.65 %
Epoch 615 of 2000 took 0.103s
  training loss:		0.469295
  validation loss:		0.469688
  validation accuracy:		85.00 %
Epoch 616 of 2000 took 0.099s
  training loss:		0.468925
  validation loss:		0.457548
  validation accuracy:		85.00 %
Epoch 617 of 2000 took 0.101s
  training loss:		0.464508
  validation loss:		0.454546
  validation accuracy:		85.00 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.465244
  validation loss:		0.448213
  validation accuracy:		86.20 %
Epoch 619 of 2000 took 0.097s
  training loss:		0.466461
  validation loss:		0.446827
  validation accuracy:		85.65 %
Epoch 620 of 2000 took 0.100s
  training loss:		0.460414
  validation loss:		0.453966
  validation accuracy:		84.89 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.461434
  validation loss:		0.466072
  validation accuracy:		84.78 %
Epoch 622 of 2000 took 0.100s
  training loss:		0.458993
  validation loss:		0.447247
  validation accuracy:		85.43 %
Epoch 623 of 2000 took 0.096s
  training loss:		0.457082
  validation loss:		0.454248
  validation accuracy:		85.00 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.455076
  validation loss:		0.444521
  validation accuracy:		85.98 %
Epoch 625 of 2000 took 0.099s
  training loss:		0.464345
  validation loss:		0.476116
  validation accuracy:		84.13 %
Epoch 626 of 2000 took 0.096s
  training loss:		0.460291
  validation loss:		0.457537
  validation accuracy:		84.67 %
Epoch 627 of 2000 took 0.100s
  training loss:		0.457370
  validation loss:		0.452242
  validation accuracy:		85.43 %
Epoch 628 of 2000 took 0.096s
  training loss:		0.451602
  validation loss:		0.456731
  validation accuracy:		84.78 %
Epoch 629 of 2000 took 0.098s
  training loss:		0.450201
  validation loss:		0.453107
  validation accuracy:		85.65 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.455153
  validation loss:		0.441115
  validation accuracy:		86.20 %
Epoch 631 of 2000 took 0.096s
  training loss:		0.455272
  validation loss:		0.440511
  validation accuracy:		85.76 %
Epoch 632 of 2000 took 0.099s
  training loss:		0.450814
  validation loss:		0.458308
  validation accuracy:		85.33 %
Epoch 633 of 2000 took 0.096s
  training loss:		0.448692
  validation loss:		0.443174
  validation accuracy:		85.76 %
Epoch 634 of 2000 took 0.100s
  training loss:		0.442905
  validation loss:		0.436974
  validation accuracy:		85.98 %
Epoch 635 of 2000 took 0.096s
  training loss:		0.447750
  validation loss:		0.456134
  validation accuracy:		85.54 %
Epoch 636 of 2000 took 0.097s
  training loss:		0.451585
  validation loss:		0.437894
  validation accuracy:		86.09 %
Epoch 637 of 2000 took 0.103s
  training loss:		0.449300
  validation loss:		0.442700
  validation accuracy:		85.87 %
Epoch 638 of 2000 took 0.096s
  training loss:		0.440386
  validation loss:		0.428757
  validation accuracy:		86.52 %
Epoch 639 of 2000 took 0.097s
  training loss:		0.442338
  validation loss:		0.437428
  validation accuracy:		85.43 %
Epoch 640 of 2000 took 0.096s
  training loss:		0.442142
  validation loss:		0.449743
  validation accuracy:		85.22 %
Epoch 641 of 2000 took 0.099s
  training loss:		0.439349
  validation loss:		0.453640
  validation accuracy:		86.20 %
Epoch 642 of 2000 took 0.099s
  training loss:		0.434726
  validation loss:		0.445479
  validation accuracy:		85.87 %
Epoch 643 of 2000 took 0.096s
  training loss:		0.440865
  validation loss:		0.439469
  validation accuracy:		85.98 %
Epoch 644 of 2000 took 0.098s
  training loss:		0.432902
  validation loss:		0.433605
  validation accuracy:		86.20 %
Epoch 645 of 2000 took 0.100s
  training loss:		0.428349
  validation loss:		0.429083
  validation accuracy:		86.63 %
Epoch 646 of 2000 took 0.096s
  training loss:		0.437641
  validation loss:		0.436050
  validation accuracy:		86.20 %
Epoch 647 of 2000 took 0.097s
  training loss:		0.430026
  validation loss:		0.445809
  validation accuracy:		85.98 %
Epoch 648 of 2000 took 0.096s
  training loss:		0.431593
  validation loss:		0.439018
  validation accuracy:		85.65 %
Epoch 649 of 2000 took 0.101s
  training loss:		0.433506
  validation loss:		0.434135
  validation accuracy:		85.43 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.435553
  validation loss:		0.417459
  validation accuracy:		87.07 %
Epoch 651 of 2000 took 0.096s
  training loss:		0.430145
  validation loss:		0.435018
  validation accuracy:		85.33 %
Epoch 652 of 2000 took 0.101s
  training loss:		0.432925
  validation loss:		0.425632
  validation accuracy:		86.41 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.433694
  validation loss:		0.427372
  validation accuracy:		86.20 %
Epoch 654 of 2000 took 0.096s
  training loss:		0.424491
  validation loss:		0.421427
  validation accuracy:		86.63 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.424462
  validation loss:		0.423825
  validation accuracy:		86.74 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.424031
  validation loss:		0.416282
  validation accuracy:		86.74 %
Epoch 657 of 2000 took 0.100s
  training loss:		0.421615
  validation loss:		0.439018
  validation accuracy:		85.65 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.417082
  validation loss:		0.446137
  validation accuracy:		85.65 %
Epoch 659 of 2000 took 0.096s
  training loss:		0.425216
  validation loss:		0.437516
  validation accuracy:		86.20 %
Epoch 660 of 2000 took 0.102s
  training loss:		0.425473
  validation loss:		0.424342
  validation accuracy:		86.52 %
Epoch 661 of 2000 took 0.096s
  training loss:		0.414517
  validation loss:		0.420067
  validation accuracy:		87.39 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.418633
  validation loss:		0.428543
  validation accuracy:		86.30 %
Epoch 663 of 2000 took 0.096s
  training loss:		0.419519
  validation loss:		0.414442
  validation accuracy:		86.74 %
Epoch 664 of 2000 took 0.098s
  training loss:		0.418203
  validation loss:		0.413233
  validation accuracy:		86.74 %
Epoch 665 of 2000 took 0.100s
  training loss:		0.415802
  validation loss:		0.431254
  validation accuracy:		86.96 %
Epoch 666 of 2000 took 0.096s
  training loss:		0.420935
  validation loss:		0.425850
  validation accuracy:		86.96 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.412872
  validation loss:		0.420166
  validation accuracy:		86.63 %
Epoch 668 of 2000 took 0.102s
  training loss:		0.413423
  validation loss:		0.439955
  validation accuracy:		85.65 %
Epoch 669 of 2000 took 0.096s
  training loss:		0.423999
  validation loss:		0.431573
  validation accuracy:		85.87 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.419941
  validation loss:		0.434187
  validation accuracy:		85.87 %
Epoch 671 of 2000 took 0.096s
  training loss:		0.424550
  validation loss:		0.425057
  validation accuracy:		86.74 %
Epoch 672 of 2000 took 0.100s
  training loss:		0.408994
  validation loss:		0.415119
  validation accuracy:		86.63 %
Epoch 673 of 2000 took 0.098s
  training loss:		0.413669
  validation loss:		0.417854
  validation accuracy:		87.07 %
Epoch 674 of 2000 took 0.096s
  training loss:		0.419481
  validation loss:		0.417800
  validation accuracy:		86.30 %
Epoch 675 of 2000 took 0.099s
  training loss:		0.414001
  validation loss:		0.401523
  validation accuracy:		87.28 %
Epoch 676 of 2000 took 0.099s
  training loss:		0.406744
  validation loss:		0.408781
  validation accuracy:		87.07 %
Epoch 677 of 2000 took 0.096s
  training loss:		0.410591
  validation loss:		0.407226
  validation accuracy:		87.07 %
Epoch 678 of 2000 took 0.097s
  training loss:		0.395491
  validation loss:		0.417377
  validation accuracy:		87.07 %
Epoch 679 of 2000 took 0.096s
  training loss:		0.414070
  validation loss:		0.408943
  validation accuracy:		87.39 %
Epoch 680 of 2000 took 0.101s
  training loss:		0.411151
  validation loss:		0.416441
  validation accuracy:		87.07 %
Epoch 681 of 2000 took 0.097s
  training loss:		0.413640
  validation loss:		0.424662
  validation accuracy:		86.30 %
Epoch 682 of 2000 took 0.096s
  training loss:		0.409075
  validation loss:		0.410387
  validation accuracy:		87.61 %
Epoch 683 of 2000 took 0.102s
  training loss:		0.397159
  validation loss:		0.403211
  validation accuracy:		87.07 %
Epoch 684 of 2000 took 0.096s
  training loss:		0.407623
  validation loss:		0.411081
  validation accuracy:		87.17 %
Epoch 685 of 2000 took 0.097s
  training loss:		0.402513
  validation loss:		0.413177
  validation accuracy:		87.39 %
Epoch 686 of 2000 took 0.096s
  training loss:		0.396854
  validation loss:		0.403633
  validation accuracy:		87.93 %
Epoch 687 of 2000 took 0.097s
  training loss:		0.403578
  validation loss:		0.407307
  validation accuracy:		87.39 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.406034
  validation loss:		0.407022
  validation accuracy:		87.83 %
Epoch 689 of 2000 took 0.096s
  training loss:		0.404684
  validation loss:		0.401740
  validation accuracy:		87.83 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.401138
  validation loss:		0.396534
  validation accuracy:		87.72 %
Epoch 691 of 2000 took 0.102s
  training loss:		0.398032
  validation loss:		0.399909
  validation accuracy:		87.83 %
Epoch 692 of 2000 took 0.096s
  training loss:		0.398483
  validation loss:		0.430404
  validation accuracy:		86.52 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.401946
  validation loss:		0.400880
  validation accuracy:		87.72 %
Epoch 694 of 2000 took 0.096s
  training loss:		0.395597
  validation loss:		0.395941
  validation accuracy:		87.28 %
Epoch 695 of 2000 took 0.098s
  training loss:		0.389584
  validation loss:		0.413041
  validation accuracy:		87.28 %
Epoch 696 of 2000 took 0.099s
  training loss:		0.396220
  validation loss:		0.402975
  validation accuracy:		87.61 %
Epoch 697 of 2000 took 0.096s
  training loss:		0.391215
  validation loss:		0.398928
  validation accuracy:		87.72 %
Epoch 698 of 2000 took 0.098s
  training loss:		0.387567
  validation loss:		0.405782
  validation accuracy:		87.50 %
Epoch 699 of 2000 took 0.100s
  training loss:		0.386926
  validation loss:		0.418312
  validation accuracy:		87.72 %
Epoch 700 of 2000 took 0.096s
  training loss:		0.390262
  validation loss:		0.401606
  validation accuracy:		87.83 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.389077
  validation loss:		0.394806
  validation accuracy:		87.50 %
Epoch 702 of 2000 took 0.096s
  training loss:		0.387412
  validation loss:		0.396165
  validation accuracy:		88.15 %
Epoch 703 of 2000 took 0.101s
  training loss:		0.382445
  validation loss:		0.396270
  validation accuracy:		87.93 %
Epoch 704 of 2000 took 0.098s
  training loss:		0.384046
  validation loss:		0.401136
  validation accuracy:		87.50 %
Epoch 705 of 2000 took 0.096s
  training loss:		0.390627
  validation loss:		0.391527
  validation accuracy:		87.93 %
Epoch 706 of 2000 took 0.101s
  training loss:		0.374991
  validation loss:		0.386186
  validation accuracy:		88.04 %
Epoch 707 of 2000 took 0.098s
  training loss:		0.375402
  validation loss:		0.388619
  validation accuracy:		87.83 %
Epoch 708 of 2000 took 0.096s
  training loss:		0.381046
  validation loss:		0.409396
  validation accuracy:		87.39 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.382480
  validation loss:		0.411173
  validation accuracy:		88.26 %
Epoch 710 of 2000 took 0.096s
  training loss:		0.381326
  validation loss:		0.403671
  validation accuracy:		88.04 %
Epoch 711 of 2000 took 0.100s
  training loss:		0.372858
  validation loss:		0.391804
  validation accuracy:		88.37 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.372527
  validation loss:		0.387617
  validation accuracy:		88.26 %
Epoch 713 of 2000 took 0.096s
  training loss:		0.375438
  validation loss:		0.407206
  validation accuracy:		87.72 %
Epoch 714 of 2000 took 0.105s
  training loss:		0.380208
  validation loss:		0.398797
  validation accuracy:		87.61 %
Epoch 715 of 2000 took 0.096s
  training loss:		0.370947
  validation loss:		0.407852
  validation accuracy:		88.15 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.377821
  validation loss:		0.391846
  validation accuracy:		87.83 %
Epoch 717 of 2000 took 0.096s
  training loss:		0.379189
  validation loss:		0.399174
  validation accuracy:		87.93 %
Epoch 718 of 2000 took 0.098s
  training loss:		0.377237
  validation loss:		0.392714
  validation accuracy:		87.17 %
Epoch 719 of 2000 took 0.101s
  training loss:		0.376092
  validation loss:		0.408776
  validation accuracy:		87.61 %
Epoch 720 of 2000 took 0.096s
  training loss:		0.371093
  validation loss:		0.389676
  validation accuracy:		88.04 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.371456
  validation loss:		0.395465
  validation accuracy:		88.37 %
Epoch 722 of 2000 took 0.102s
  training loss:		0.371285
  validation loss:		0.405325
  validation accuracy:		87.72 %
Epoch 723 of 2000 took 0.096s
  training loss:		0.368604
  validation loss:		0.409558
  validation accuracy:		87.50 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.365628
  validation loss:		0.386218
  validation accuracy:		88.37 %
Epoch 725 of 2000 took 0.096s
  training loss:		0.364598
  validation loss:		0.395084
  validation accuracy:		88.59 %
Epoch 726 of 2000 took 0.099s
  training loss:		0.371843
  validation loss:		0.387556
  validation accuracy:		87.93 %
Epoch 727 of 2000 took 0.098s
  training loss:		0.372560
  validation loss:		0.396115
  validation accuracy:		88.59 %
Epoch 728 of 2000 took 0.096s
  training loss:		0.368349
  validation loss:		0.383286
  validation accuracy:		88.48 %
Epoch 729 of 2000 took 0.099s
  training loss:		0.364734
  validation loss:		0.391885
  validation accuracy:		88.70 %
Epoch 730 of 2000 took 0.099s
  training loss:		0.370743
  validation loss:		0.383618
  validation accuracy:		88.48 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.363656
  validation loss:		0.423947
  validation accuracy:		87.50 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.366837
  validation loss:		0.383318
  validation accuracy:		88.48 %
Epoch 733 of 2000 took 0.096s
  training loss:		0.368766
  validation loss:		0.398480
  validation accuracy:		87.17 %
Epoch 734 of 2000 took 0.101s
  training loss:		0.362323
  validation loss:		0.382804
  validation accuracy:		89.35 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.366920
  validation loss:		0.393614
  validation accuracy:		88.26 %
Epoch 736 of 2000 took 0.096s
  training loss:		0.354963
  validation loss:		0.401396
  validation accuracy:		87.83 %
Epoch 737 of 2000 took 0.102s
  training loss:		0.363742
  validation loss:		0.381826
  validation accuracy:		88.70 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.362968
  validation loss:		0.387907
  validation accuracy:		88.37 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.363641
  validation loss:		0.380183
  validation accuracy:		88.37 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.367272
  validation loss:		0.391276
  validation accuracy:		88.59 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.363316
  validation loss:		0.392028
  validation accuracy:		87.93 %
Epoch 742 of 2000 took 0.100s
  training loss:		0.354491
  validation loss:		0.385065
  validation accuracy:		89.13 %
Epoch 743 of 2000 took 0.097s
  training loss:		0.361618
  validation loss:		0.381569
  validation accuracy:		88.70 %
Epoch 744 of 2000 took 0.096s
  training loss:		0.356619
  validation loss:		0.382639
  validation accuracy:		88.80 %
Epoch 745 of 2000 took 0.102s
  training loss:		0.356159
  validation loss:		0.391284
  validation accuracy:		88.26 %
Epoch 746 of 2000 took 0.096s
  training loss:		0.353335
  validation loss:		0.385849
  validation accuracy:		89.02 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.360846
  validation loss:		0.384128
  validation accuracy:		88.37 %
Epoch 748 of 2000 took 0.096s
  training loss:		0.368430
  validation loss:		0.393674
  validation accuracy:		88.15 %
Epoch 749 of 2000 took 0.098s
  training loss:		0.357459
  validation loss:		0.380498
  validation accuracy:		88.70 %
Epoch 750 of 2000 took 0.100s
  training loss:		0.360062
  validation loss:		0.390501
  validation accuracy:		88.70 %
Epoch 751 of 2000 took 0.096s
  training loss:		0.350406
  validation loss:		0.380107
  validation accuracy:		88.91 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.351646
  validation loss:		0.373891
  validation accuracy:		88.26 %
Epoch 753 of 2000 took 0.102s
  training loss:		0.355896
  validation loss:		0.379551
  validation accuracy:		88.15 %
Epoch 754 of 2000 took 0.096s
  training loss:		0.355167
  validation loss:		0.393642
  validation accuracy:		88.26 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.348215
  validation loss:		0.388295
  validation accuracy:		89.02 %
Epoch 756 of 2000 took 0.096s
  training loss:		0.355667
  validation loss:		0.376239
  validation accuracy:		88.80 %
Epoch 757 of 2000 took 0.100s
  training loss:		0.352473
  validation loss:		0.391781
  validation accuracy:		89.02 %
Epoch 758 of 2000 took 0.098s
  training loss:		0.350786
  validation loss:		0.388171
  validation accuracy:		88.48 %
Epoch 759 of 2000 took 0.096s
  training loss:		0.349847
  validation loss:		0.378333
  validation accuracy:		89.13 %
Epoch 760 of 2000 took 0.100s
  training loss:		0.354846
  validation loss:		0.374632
  validation accuracy:		88.59 %
Epoch 761 of 2000 took 0.099s
  training loss:		0.351417
  validation loss:		0.387018
  validation accuracy:		88.48 %
Epoch 762 of 2000 took 0.096s
  training loss:		0.352686
  validation loss:		0.388912
  validation accuracy:		88.70 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.356608
  validation loss:		0.434770
  validation accuracy:		87.07 %
Epoch 764 of 2000 took 0.096s
  training loss:		0.361750
  validation loss:		0.379518
  validation accuracy:		88.91 %
Epoch 765 of 2000 took 0.101s
  training loss:		0.345703
  validation loss:		0.383106
  validation accuracy:		88.48 %
Epoch 766 of 2000 took 0.098s
  training loss:		0.354744
  validation loss:		0.383257
  validation accuracy:		88.59 %
Epoch 767 of 2000 took 0.096s
  training loss:		0.351036
  validation loss:		0.399123
  validation accuracy:		88.48 %
Epoch 768 of 2000 took 0.102s
  training loss:		0.352519
  validation loss:		0.375231
  validation accuracy:		89.24 %
Epoch 769 of 2000 took 0.096s
  training loss:		0.344985
  validation loss:		0.392301
  validation accuracy:		88.91 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.352410
  validation loss:		0.388660
  validation accuracy:		88.80 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.344704
  validation loss:		0.410654
  validation accuracy:		86.85 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.353591
  validation loss:		0.418654
  validation accuracy:		86.85 %
Epoch 773 of 2000 took 0.100s
  training loss:		0.340957
  validation loss:		0.371885
  validation accuracy:		88.59 %
Epoch 774 of 2000 took 0.096s
  training loss:		0.341777
  validation loss:		0.383843
  validation accuracy:		89.13 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.342231
  validation loss:		0.385834
  validation accuracy:		88.70 %
Epoch 776 of 2000 took 0.102s
  training loss:		0.347114
  validation loss:		0.383048
  validation accuracy:		88.80 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.343583
  validation loss:		0.387317
  validation accuracy:		88.04 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.345636
  validation loss:		0.380429
  validation accuracy:		88.91 %
Epoch 779 of 2000 took 0.096s
  training loss:		0.342816
  validation loss:		0.379931
  validation accuracy:		89.35 %
Epoch 780 of 2000 took 0.098s
  training loss:		0.342748
  validation loss:		0.387369
  validation accuracy:		88.70 %
Epoch 781 of 2000 took 0.100s
  training loss:		0.346256
  validation loss:		0.372367
  validation accuracy:		89.13 %
Epoch 782 of 2000 took 0.096s
  training loss:		0.340390
  validation loss:		0.408980
  validation accuracy:		87.39 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.344247
  validation loss:		0.378006
  validation accuracy:		88.37 %
Epoch 784 of 2000 took 0.101s
  training loss:		0.341958
  validation loss:		0.395353
  validation accuracy:		88.48 %
Epoch 785 of 2000 took 0.096s
  training loss:		0.343313
  validation loss:		0.389968
  validation accuracy:		88.37 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.342513
  validation loss:		0.375386
  validation accuracy:		88.26 %
Epoch 787 of 2000 took 0.096s
  training loss:		0.334252
  validation loss:		0.378680
  validation accuracy:		89.35 %
Epoch 788 of 2000 took 0.101s
  training loss:		0.343354
  validation loss:		0.388117
  validation accuracy:		88.80 %
Epoch 789 of 2000 took 0.098s
  training loss:		0.341427
  validation loss:		0.378950
  validation accuracy:		89.24 %
Epoch 790 of 2000 took 0.096s
  training loss:		0.338601
  validation loss:		0.392513
  validation accuracy:		88.70 %
Epoch 791 of 2000 took 0.101s
  training loss:		0.340877
  validation loss:		0.392111
  validation accuracy:		89.13 %
Epoch 792 of 2000 took 0.098s
  training loss:		0.343642
  validation loss:		0.379584
  validation accuracy:		88.70 %
Epoch 793 of 2000 took 0.096s
  training loss:		0.340266
  validation loss:		0.383811
  validation accuracy:		89.13 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.340824
  validation loss:		0.390914
  validation accuracy:		88.59 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.338619
  validation loss:		0.382843
  validation accuracy:		88.70 %
Epoch 796 of 2000 took 0.100s
  training loss:		0.332497
  validation loss:		0.384368
  validation accuracy:		88.80 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.335909
  validation loss:		0.390427
  validation accuracy:		88.48 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.338177
  validation loss:		0.379050
  validation accuracy:		88.70 %
Epoch 799 of 2000 took 0.103s
  training loss:		0.332361
  validation loss:		0.385654
  validation accuracy:		88.91 %
Epoch 800 of 2000 took 0.096s
  training loss:		0.335160
  validation loss:		0.390603
  validation accuracy:		89.02 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.335751
  validation loss:		0.406226
  validation accuracy:		88.70 %
Epoch 802 of 2000 took 0.096s
  training loss:		0.333305
  validation loss:		0.377777
  validation accuracy:		89.02 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.339470
  validation loss:		0.402969
  validation accuracy:		88.48 %
Epoch 804 of 2000 took 0.100s
  training loss:		0.332633
  validation loss:		0.381163
  validation accuracy:		89.46 %
Epoch 805 of 2000 took 0.096s
  training loss:		0.333719
  validation loss:		0.374977
  validation accuracy:		89.35 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.332213
  validation loss:		0.380159
  validation accuracy:		89.02 %
Epoch 807 of 2000 took 0.102s
  training loss:		0.329964
  validation loss:		0.380298
  validation accuracy:		89.35 %
Epoch 808 of 2000 took 0.096s
  training loss:		0.329652
  validation loss:		0.386833
  validation accuracy:		89.02 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.336579
  validation loss:		0.388255
  validation accuracy:		89.02 %
Epoch 810 of 2000 took 0.096s
  training loss:		0.323260
  validation loss:		0.388210
  validation accuracy:		88.70 %
Epoch 811 of 2000 took 0.098s
  training loss:		0.337555
  validation loss:		0.372629
  validation accuracy:		89.13 %
Epoch 812 of 2000 took 0.099s
  training loss:		0.328645
  validation loss:		0.420211
  validation accuracy:		88.04 %
Epoch 813 of 2000 took 0.096s
  training loss:		0.333802
  validation loss:		0.391873
  validation accuracy:		89.02 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.329640
  validation loss:		0.374280
  validation accuracy:		89.57 %
Epoch 815 of 2000 took 0.101s
  training loss:		0.327478
  validation loss:		0.380170
  validation accuracy:		88.80 %
Epoch 816 of 2000 took 0.096s
  training loss:		0.333761
  validation loss:		0.401350
  validation accuracy:		89.13 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.332973
  validation loss:		0.374106
  validation accuracy:		88.80 %
Epoch 818 of 2000 took 0.096s
  training loss:		0.334924
  validation loss:		0.375551
  validation accuracy:		89.13 %
Epoch 819 of 2000 took 0.101s
  training loss:		0.328565
  validation loss:		0.395730
  validation accuracy:		89.35 %
Epoch 820 of 2000 took 0.098s
  training loss:		0.327606
  validation loss:		0.397263
  validation accuracy:		89.24 %
Epoch 821 of 2000 took 0.096s
  training loss:		0.322816
  validation loss:		0.379230
  validation accuracy:		88.91 %
Epoch 822 of 2000 took 0.100s
  training loss:		0.332249
  validation loss:		0.371939
  validation accuracy:		88.80 %
Epoch 823 of 2000 took 0.098s
  training loss:		0.325327
  validation loss:		0.386589
  validation accuracy:		89.35 %
Epoch 824 of 2000 took 0.096s
  training loss:		0.324974
  validation loss:		0.385582
  validation accuracy:		89.02 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.332532
  validation loss:		0.408966
  validation accuracy:		88.59 %
Epoch 826 of 2000 took 0.096s
  training loss:		0.331320
  validation loss:		0.378221
  validation accuracy:		89.57 %
Epoch 827 of 2000 took 0.100s
  training loss:		0.325537
  validation loss:		0.405439
  validation accuracy:		88.37 %
Epoch 828 of 2000 took 0.098s
  training loss:		0.327088
  validation loss:		0.424661
  validation accuracy:		87.83 %
Epoch 829 of 2000 took 0.096s
  training loss:		0.329510
  validation loss:		0.374578
  validation accuracy:		89.35 %
Epoch 830 of 2000 took 0.102s
  training loss:		0.326183
  validation loss:		0.382307
  validation accuracy:		88.70 %
Epoch 831 of 2000 took 0.096s
  training loss:		0.325605
  validation loss:		0.375281
  validation accuracy:		88.91 %
Epoch 832 of 2000 took 0.097s
  training loss:		0.323834
  validation loss:		0.380688
  validation accuracy:		89.13 %
Epoch 833 of 2000 took 0.096s
  training loss:		0.329320
  validation loss:		0.387816
  validation accuracy:		89.13 %
Epoch 834 of 2000 took 0.097s
  training loss:		0.327719
  validation loss:		0.386998
  validation accuracy:		89.13 %
Epoch 835 of 2000 took 0.100s
  training loss:		0.326183
  validation loss:		0.391500
  validation accuracy:		89.35 %
Epoch 836 of 2000 took 0.096s
  training loss:		0.326989
  validation loss:		0.375649
  validation accuracy:		88.80 %
Epoch 837 of 2000 took 0.097s
  training loss:		0.324529
  validation loss:		0.392748
  validation accuracy:		89.13 %
Epoch 838 of 2000 took 0.102s
  training loss:		0.325914
  validation loss:		0.393033
  validation accuracy:		89.02 %
Epoch 839 of 2000 took 0.096s
  training loss:		0.328391
  validation loss:		0.384592
  validation accuracy:		88.59 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.320122
  validation loss:		0.389336
  validation accuracy:		89.02 %
Epoch 841 of 2000 took 0.096s
  training loss:		0.323582
  validation loss:		0.380823
  validation accuracy:		89.24 %
Epoch 842 of 2000 took 0.099s
  training loss:		0.324859
  validation loss:		0.374235
  validation accuracy:		89.02 %
Epoch 843 of 2000 took 0.099s
  training loss:		0.314661
  validation loss:		0.378866
  validation accuracy:		88.91 %
Epoch 844 of 2000 took 0.096s
  training loss:		0.324501
  validation loss:		0.382500
  validation accuracy:		89.24 %
Epoch 845 of 2000 took 0.098s
  training loss:		0.324146
  validation loss:		0.412029
  validation accuracy:		87.72 %
Epoch 846 of 2000 took 0.100s
  training loss:		0.325619
  validation loss:		0.375965
  validation accuracy:		89.24 %
Epoch 847 of 2000 took 0.096s
  training loss:		0.321121
  validation loss:		0.384565
  validation accuracy:		89.02 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.318322
  validation loss:		0.381549
  validation accuracy:		88.91 %
Epoch 849 of 2000 took 0.096s
  training loss:		0.319670
  validation loss:		0.371316
  validation accuracy:		89.35 %
Epoch 850 of 2000 took 0.101s
  training loss:		0.320586
  validation loss:		0.407527
  validation accuracy:		88.59 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.323819
  validation loss:		0.385558
  validation accuracy:		89.57 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.318318
  validation loss:		0.388263
  validation accuracy:		89.02 %
Epoch 853 of 2000 took 0.101s
  training loss:		0.318530
  validation loss:		0.372105
  validation accuracy:		89.02 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.318813
  validation loss:		0.391673
  validation accuracy:		88.70 %
Epoch 855 of 2000 took 0.096s
  training loss:		0.323047
  validation loss:		0.413651
  validation accuracy:		88.70 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.321894
  validation loss:		0.406746
  validation accuracy:		88.70 %
Epoch 857 of 2000 took 0.096s
  training loss:		0.322261
  validation loss:		0.376125
  validation accuracy:		89.02 %
Epoch 858 of 2000 took 0.100s
  training loss:		0.322036
  validation loss:		0.416416
  validation accuracy:		87.72 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.325944
  validation loss:		0.374632
  validation accuracy:		89.35 %
Epoch 860 of 2000 took 0.096s
  training loss:		0.313688
  validation loss:		0.383449
  validation accuracy:		89.24 %
Epoch 861 of 2000 took 0.102s
  training loss:		0.310608
  validation loss:		0.386764
  validation accuracy:		88.80 %
Epoch 862 of 2000 took 0.096s
  training loss:		0.322818
  validation loss:		0.380085
  validation accuracy:		89.35 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.313622
  validation loss:		0.386277
  validation accuracy:		89.35 %
Epoch 864 of 2000 took 0.096s
  training loss:		0.324728
  validation loss:		0.408509
  validation accuracy:		89.13 %
Epoch 865 of 2000 took 0.097s
  training loss:		0.309915
  validation loss:		0.382616
  validation accuracy:		89.13 %
Epoch 866 of 2000 took 0.100s
  training loss:		0.316115
  validation loss:		0.385173
  validation accuracy:		89.13 %
Epoch 867 of 2000 took 0.096s
  training loss:		0.319415
  validation loss:		0.397924
  validation accuracy:		88.80 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.313097
  validation loss:		0.374050
  validation accuracy:		88.91 %
Epoch 869 of 2000 took 0.102s
  training loss:		0.315209
  validation loss:		0.375016
  validation accuracy:		89.02 %
Epoch 870 of 2000 took 0.096s
  training loss:		0.310502
  validation loss:		0.379748
  validation accuracy:		89.46 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.318492
  validation loss:		0.397658
  validation accuracy:		89.24 %
Epoch 872 of 2000 took 0.096s
  training loss:		0.312316
  validation loss:		0.381778
  validation accuracy:		88.70 %
Epoch 873 of 2000 took 0.099s
  training loss:		0.313398
  validation loss:		0.380391
  validation accuracy:		89.24 %
Epoch 874 of 2000 took 0.099s
  training loss:		0.308242
  validation loss:		0.387031
  validation accuracy:		89.02 %
Epoch 875 of 2000 took 0.096s
  training loss:		0.310313
  validation loss:		0.379126
  validation accuracy:		89.13 %
Epoch 876 of 2000 took 0.098s
  training loss:		0.309105
  validation loss:		0.386161
  validation accuracy:		89.57 %
Epoch 877 of 2000 took 0.100s
  training loss:		0.309573
  validation loss:		0.385558
  validation accuracy:		89.24 %
Epoch 878 of 2000 took 0.096s
  training loss:		0.318458
  validation loss:		0.389195
  validation accuracy:		88.80 %
Epoch 879 of 2000 took 0.097s
  training loss:		0.315824
  validation loss:		0.374857
  validation accuracy:		88.48 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.321827
  validation loss:		0.373401
  validation accuracy:		89.24 %
Epoch 881 of 2000 took 0.101s
  training loss:		0.322965
  validation loss:		0.396163
  validation accuracy:		88.48 %
Epoch 882 of 2000 took 0.098s
  training loss:		0.319024
  validation loss:		0.406858
  validation accuracy:		89.24 %
Epoch 883 of 2000 took 0.096s
  training loss:		0.316412
  validation loss:		0.385396
  validation accuracy:		89.35 %
Epoch 884 of 2000 took 0.101s
  training loss:		0.307163
  validation loss:		0.420858
  validation accuracy:		88.04 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.314911
  validation loss:		0.373028
  validation accuracy:		88.91 %
Epoch 886 of 2000 took 0.097s
  training loss:		0.304126
  validation loss:		0.382626
  validation accuracy:		88.59 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.318468
  validation loss:		0.375270
  validation accuracy:		88.59 %
Epoch 888 of 2000 took 0.096s
  training loss:		0.313486
  validation loss:		0.389580
  validation accuracy:		89.35 %
Epoch 889 of 2000 took 0.100s
  training loss:		0.314532
  validation loss:		0.372373
  validation accuracy:		89.46 %
Epoch 890 of 2000 took 0.098s
  training loss:		0.319435
  validation loss:		0.389080
  validation accuracy:		89.13 %
Epoch 891 of 2000 took 0.096s
  training loss:		0.309282
  validation loss:		0.391181
  validation accuracy:		89.02 %
Epoch 892 of 2000 took 0.102s
  training loss:		0.316223
  validation loss:		0.384551
  validation accuracy:		88.59 %
Epoch 893 of 2000 took 0.096s
  training loss:		0.324568
  validation loss:		0.394606
  validation accuracy:		88.91 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.306075
  validation loss:		0.397464
  validation accuracy:		89.13 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.313622
  validation loss:		0.379243
  validation accuracy:		89.24 %
Epoch 896 of 2000 took 0.097s
  training loss:		0.313160
  validation loss:		0.377844
  validation accuracy:		89.24 %
Epoch 897 of 2000 took 0.100s
  training loss:		0.309114
  validation loss:		0.385804
  validation accuracy:		89.24 %
Epoch 898 of 2000 took 0.096s
  training loss:		0.323059
  validation loss:		0.410328
  validation accuracy:		88.70 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.311857
  validation loss:		0.394080
  validation accuracy:		89.24 %
Epoch 900 of 2000 took 0.102s
  training loss:		0.308929
  validation loss:		0.378401
  validation accuracy:		89.13 %
Epoch 901 of 2000 took 0.096s
  training loss:		0.314774
  validation loss:		0.397493
  validation accuracy:		88.70 %
Epoch 902 of 2000 took 0.097s
  training loss:		0.310485
  validation loss:		0.373665
  validation accuracy:		89.24 %
Epoch 903 of 2000 took 0.096s
  training loss:		0.307127
  validation loss:		0.384559
  validation accuracy:		88.04 %
Epoch 904 of 2000 took 0.099s
  training loss:		0.312186
  validation loss:		0.383950
  validation accuracy:		88.48 %
Epoch 905 of 2000 took 0.099s
  training loss:		0.311907
  validation loss:		0.408246
  validation accuracy:		88.15 %
Epoch 906 of 2000 took 0.096s
  training loss:		0.313056
  validation loss:		0.382199
  validation accuracy:		89.02 %
Epoch 907 of 2000 took 0.098s
  training loss:		0.305584
  validation loss:		0.407077
  validation accuracy:		89.24 %
Epoch 908 of 2000 took 0.100s
  training loss:		0.309344
  validation loss:		0.377109
  validation accuracy:		88.59 %
Epoch 909 of 2000 took 0.096s
  training loss:		0.311039
  validation loss:		0.373333
  validation accuracy:		89.24 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.311917
  validation loss:		0.377768
  validation accuracy:		88.91 %
Epoch 911 of 2000 took 0.096s
  training loss:		0.304100
  validation loss:		0.388430
  validation accuracy:		89.13 %
Epoch 912 of 2000 took 0.101s
  training loss:		0.306628
  validation loss:		0.385802
  validation accuracy:		88.15 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.312105
  validation loss:		0.382842
  validation accuracy:		88.80 %
Epoch 914 of 2000 took 0.096s
  training loss:		0.306875
  validation loss:		0.391107
  validation accuracy:		89.24 %
Epoch 915 of 2000 took 0.101s
  training loss:		0.301112
  validation loss:		0.398084
  validation accuracy:		88.80 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.317642
  validation loss:		0.397722
  validation accuracy:		89.24 %
Epoch 917 of 2000 took 0.096s
  training loss:		0.304468
  validation loss:		0.378813
  validation accuracy:		89.35 %
Epoch 918 of 2000 took 0.096s
  training loss:		0.301423
  validation loss:		0.374229
  validation accuracy:		88.59 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.314889
  validation loss:		0.375599
  validation accuracy:		89.67 %
Epoch 920 of 2000 took 0.100s
  training loss:		0.304536
  validation loss:		0.388858
  validation accuracy:		89.24 %
Epoch 921 of 2000 took 0.098s
  training loss:		0.311751
  validation loss:		0.421527
  validation accuracy:		88.80 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.308315
  validation loss:		0.376255
  validation accuracy:		89.24 %
Epoch 923 of 2000 took 0.103s
  training loss:		0.303270
  validation loss:		0.403303
  validation accuracy:		88.70 %
Epoch 924 of 2000 took 0.098s
  training loss:		0.320960
  validation loss:		0.377280
  validation accuracy:		88.80 %
Epoch 925 of 2000 took 0.100s
  training loss:		0.305078
  validation loss:		0.404708
  validation accuracy:		89.35 %
Epoch 926 of 2000 took 0.099s
  training loss:		0.309162
  validation loss:		0.387200
  validation accuracy:		88.70 %
Epoch 927 of 2000 took 0.100s
  training loss:		0.311708
  validation loss:		0.381964
  validation accuracy:		88.70 %
Epoch 928 of 2000 took 0.103s
  training loss:		0.308447
  validation loss:		0.418754
  validation accuracy:		88.91 %
Epoch 929 of 2000 took 0.099s
  training loss:		0.304609
  validation loss:		0.382817
  validation accuracy:		87.83 %
Epoch 930 of 2000 took 0.100s
  training loss:		0.312592
  validation loss:		0.375567
  validation accuracy:		89.02 %
Epoch 931 of 2000 took 0.105s
  training loss:		0.306399
  validation loss:		0.373916
  validation accuracy:		88.91 %
Epoch 932 of 2000 took 0.099s
  training loss:		0.309986
  validation loss:		0.400490
  validation accuracy:		88.37 %
Epoch 933 of 2000 took 0.100s
  training loss:		0.307354
  validation loss:		0.389732
  validation accuracy:		89.35 %
Epoch 934 of 2000 took 0.099s
  training loss:		0.311678
  validation loss:		0.374702
  validation accuracy:		89.24 %
Epoch 935 of 2000 took 0.102s
  training loss:		0.307024
  validation loss:		0.374650
  validation accuracy:		89.02 %
Epoch 936 of 2000 took 0.102s
  training loss:		0.299037
  validation loss:		0.386771
  validation accuracy:		89.46 %
Epoch 937 of 2000 took 0.099s
  training loss:		0.301221
  validation loss:		0.369178
  validation accuracy:		89.13 %
Epoch 938 of 2000 took 0.102s
  training loss:		0.306494
  validation loss:		0.375546
  validation accuracy:		89.46 %
Epoch 939 of 2000 took 0.103s
  training loss:		0.295985
  validation loss:		0.388941
  validation accuracy:		88.91 %
Epoch 940 of 2000 took 0.099s
  training loss:		0.302773
  validation loss:		0.382763
  validation accuracy:		88.70 %
Epoch 941 of 2000 took 0.100s
  training loss:		0.303076
  validation loss:		0.374324
  validation accuracy:		88.59 %
Epoch 942 of 2000 took 0.099s
  training loss:		0.302059
  validation loss:		0.385696
  validation accuracy:		88.70 %
Epoch 943 of 2000 took 0.104s
  training loss:		0.303499
  validation loss:		0.383549
  validation accuracy:		88.37 %
Epoch 944 of 2000 took 0.101s
  training loss:		0.304845
  validation loss:		0.370392
  validation accuracy:		89.24 %
Epoch 945 of 2000 took 0.099s
  training loss:		0.299195
  validation loss:		0.373168
  validation accuracy:		89.13 %
Epoch 946 of 2000 took 0.105s
  training loss:		0.302871
  validation loss:		0.387250
  validation accuracy:		88.91 %
Epoch 947 of 2000 took 0.100s
  training loss:		0.304505
  validation loss:		0.374303
  validation accuracy:		88.59 %
Epoch 948 of 2000 took 0.100s
  training loss:		0.301108
  validation loss:		0.387812
  validation accuracy:		88.91 %
Epoch 949 of 2000 took 0.100s
  training loss:		0.299423
  validation loss:		0.383729
  validation accuracy:		89.35 %
Epoch 950 of 2000 took 0.100s
  training loss:		0.303417
  validation loss:		0.411798
  validation accuracy:		88.70 %
Epoch 951 of 2000 took 0.103s
  training loss:		0.305842
  validation loss:		0.378501
  validation accuracy:		88.48 %
Epoch 952 of 2000 took 0.100s
  training loss:		0.306551
  validation loss:		0.397682
  validation accuracy:		89.35 %
Epoch 953 of 2000 took 0.100s
  training loss:		0.301403
  validation loss:		0.373415
  validation accuracy:		88.80 %
Epoch 954 of 2000 took 0.105s
  training loss:		0.307892
  validation loss:		0.378523
  validation accuracy:		89.89 %
Epoch 955 of 2000 took 0.099s
  training loss:		0.312399
  validation loss:		0.374769
  validation accuracy:		88.70 %
Epoch 956 of 2000 took 0.100s
  training loss:		0.307389
  validation loss:		0.406455
  validation accuracy:		89.35 %
Epoch 957 of 2000 took 0.099s
  training loss:		0.306321
  validation loss:		0.387401
  validation accuracy:		89.46 %
Epoch 958 of 2000 took 0.101s
  training loss:		0.298670
  validation loss:		0.401292
  validation accuracy:		89.35 %
Epoch 959 of 2000 took 0.103s
  training loss:		0.298617
  validation loss:		0.387346
  validation accuracy:		89.35 %
Epoch 960 of 2000 took 0.099s
  training loss:		0.294639
  validation loss:		0.368915
  validation accuracy:		89.02 %
Epoch 961 of 2000 took 0.101s
  training loss:		0.298046
  validation loss:		0.398499
  validation accuracy:		88.48 %
Epoch 962 of 2000 took 0.104s
  training loss:		0.303214
  validation loss:		0.383101
  validation accuracy:		89.35 %
Epoch 963 of 2000 took 0.099s
  training loss:		0.300592
  validation loss:		0.399739
  validation accuracy:		89.24 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.302088
  validation loss:		0.390518
  validation accuracy:		89.13 %
Epoch 965 of 2000 took 0.096s
  training loss:		0.298726
  validation loss:		0.380573
  validation accuracy:		87.83 %
Epoch 966 of 2000 took 0.101s
  training loss:		0.299510
  validation loss:		0.380993
  validation accuracy:		88.48 %
Epoch 967 of 2000 took 0.098s
  training loss:		0.297357
  validation loss:		0.375304
  validation accuracy:		89.46 %
Epoch 968 of 2000 took 0.096s
  training loss:		0.302091
  validation loss:		0.374152
  validation accuracy:		89.02 %
Epoch 969 of 2000 took 0.101s
  training loss:		0.299064
  validation loss:		0.375642
  validation accuracy:		88.48 %
Epoch 970 of 2000 took 0.098s
  training loss:		0.298995
  validation loss:		0.383009
  validation accuracy:		89.13 %
Epoch 971 of 2000 took 0.097s
  training loss:		0.296462
  validation loss:		0.375083
  validation accuracy:		88.48 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.302453
  validation loss:		0.373229
  validation accuracy:		88.91 %
Epoch 973 of 2000 took 0.096s
  training loss:		0.301944
  validation loss:		0.420259
  validation accuracy:		88.91 %
Epoch 974 of 2000 took 0.100s
  training loss:		0.295476
  validation loss:		0.423159
  validation accuracy:		88.37 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.293483
  validation loss:		0.391703
  validation accuracy:		89.46 %
Epoch 976 of 2000 took 0.096s
  training loss:		0.302709
  validation loss:		0.407608
  validation accuracy:		88.80 %
Epoch 977 of 2000 took 0.102s
  training loss:		0.298378
  validation loss:		0.380849
  validation accuracy:		89.57 %
Epoch 978 of 2000 took 0.096s
  training loss:		0.296157
  validation loss:		0.381892
  validation accuracy:		89.35 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.304097
  validation loss:		0.381349
  validation accuracy:		88.80 %
Epoch 980 of 2000 took 0.096s
  training loss:		0.305142
  validation loss:		0.407684
  validation accuracy:		88.80 %
Epoch 981 of 2000 took 0.098s
  training loss:		0.296832
  validation loss:		0.382390
  validation accuracy:		89.46 %
Epoch 982 of 2000 took 0.100s
  training loss:		0.301293
  validation loss:		0.385686
  validation accuracy:		88.59 %
Epoch 983 of 2000 took 0.096s
  training loss:		0.302901
  validation loss:		0.396789
  validation accuracy:		87.72 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.302576
  validation loss:		0.379547
  validation accuracy:		87.72 %
Epoch 985 of 2000 took 0.102s
  training loss:		0.296289
  validation loss:		0.379955
  validation accuracy:		88.48 %
Epoch 986 of 2000 took 0.096s
  training loss:		0.301587
  validation loss:		0.374005
  validation accuracy:		89.46 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.303678
  validation loss:		0.384760
  validation accuracy:		87.50 %
Epoch 988 of 2000 took 0.096s
  training loss:		0.302294
  validation loss:		0.392885
  validation accuracy:		89.24 %
Epoch 989 of 2000 took 0.099s
  training loss:		0.299775
  validation loss:		0.388875
  validation accuracy:		88.26 %
Epoch 990 of 2000 took 0.099s
  training loss:		0.300436
  validation loss:		0.398333
  validation accuracy:		88.91 %
Epoch 991 of 2000 took 0.096s
  training loss:		0.299439
  validation loss:		0.383729
  validation accuracy:		88.37 %
Epoch 992 of 2000 took 0.098s
  training loss:		0.296373
  validation loss:		0.380460
  validation accuracy:		88.70 %
Epoch 993 of 2000 took 0.100s
  training loss:		0.302897
  validation loss:		0.384110
  validation accuracy:		88.48 %
Epoch 994 of 2000 took 0.096s
  training loss:		0.294161
  validation loss:		0.373993
  validation accuracy:		88.91 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.294795
  validation loss:		0.374836
  validation accuracy:		89.02 %
Epoch 996 of 2000 took 0.096s
  training loss:		0.299088
  validation loss:		0.372100
  validation accuracy:		89.02 %
Epoch 997 of 2000 took 0.101s
  training loss:		0.294465
  validation loss:		0.373887
  validation accuracy:		89.02 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.304093
  validation loss:		0.370966
  validation accuracy:		88.91 %
Epoch 999 of 2000 took 0.096s
  training loss:		0.297394
  validation loss:		0.389256
  validation accuracy:		89.02 %
Epoch 1000 of 2000 took 0.101s
  training loss:		0.305575
  validation loss:		0.373724
  validation accuracy:		89.02 %
Epoch 1001 of 2000 took 0.098s
  training loss:		0.296495
  validation loss:		0.379156
  validation accuracy:		88.70 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.298887
  validation loss:		0.395531
  validation accuracy:		88.80 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.301169
  validation loss:		0.377210
  validation accuracy:		88.70 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.295314
  validation loss:		0.387537
  validation accuracy:		89.35 %
Epoch 1005 of 2000 took 0.100s
  training loss:		0.299495
  validation loss:		0.379718
  validation accuracy:		88.70 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.293614
  validation loss:		0.376692
  validation accuracy:		88.70 %
Epoch 1007 of 2000 took 0.096s
  training loss:		0.294812
  validation loss:		0.392185
  validation accuracy:		88.59 %
Epoch 1008 of 2000 took 0.099s
  training loss:		0.300409
  validation loss:		0.384014
  validation accuracy:		88.59 %
Epoch 1009 of 2000 took 0.096s
  training loss:		0.288717
  validation loss:		0.400106
  validation accuracy:		89.46 %
Epoch 1010 of 2000 took 0.098s
  training loss:		0.297951
  validation loss:		0.374091
  validation accuracy:		88.91 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.304375
  validation loss:		0.412381
  validation accuracy:		88.91 %
Epoch 1012 of 2000 took 0.097s
  training loss:		0.300839
  validation loss:		0.392823
  validation accuracy:		88.26 %
Epoch 1013 of 2000 took 0.099s
  training loss:		0.293179
  validation loss:		0.372571
  validation accuracy:		88.59 %
Epoch 1014 of 2000 took 0.096s
  training loss:		0.294099
  validation loss:		0.388978
  validation accuracy:		89.24 %
Epoch 1015 of 2000 took 0.100s
  training loss:		0.296028
  validation loss:		0.378054
  validation accuracy:		88.91 %
Epoch 1016 of 2000 took 0.096s
  training loss:		0.292821
  validation loss:		0.373217
  validation accuracy:		88.80 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.299046
  validation loss:		0.381331
  validation accuracy:		89.35 %
Epoch 1018 of 2000 took 0.099s
  training loss:		0.287386
  validation loss:		0.377376
  validation accuracy:		89.13 %
Epoch 1019 of 2000 took 0.096s
  training loss:		0.290685
  validation loss:		0.375819
  validation accuracy:		88.80 %
Epoch 1020 of 2000 took 0.099s
  training loss:		0.288640
  validation loss:		0.400316
  validation accuracy:		89.13 %
Epoch 1021 of 2000 took 0.096s
  training loss:		0.299906
  validation loss:		0.381351
  validation accuracy:		88.80 %
Epoch 1022 of 2000 took 0.098s
  training loss:		0.289946
  validation loss:		0.380426
  validation accuracy:		88.48 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.299564
  validation loss:		0.385849
  validation accuracy:		88.91 %
Epoch 1024 of 2000 took 0.096s
  training loss:		0.290913
  validation loss:		0.400461
  validation accuracy:		89.67 %
Epoch 1025 of 2000 took 0.100s
  training loss:		0.296914
  validation loss:		0.377286
  validation accuracy:		88.70 %
Epoch 1026 of 2000 took 0.096s
  training loss:		0.284561
  validation loss:		0.387854
  validation accuracy:		88.37 %
Epoch 1027 of 2000 took 0.099s
  training loss:		0.296068
  validation loss:		0.371751
  validation accuracy:		89.35 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.293135
  validation loss:		0.378688
  validation accuracy:		88.48 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.293560
  validation loss:		0.375910
  validation accuracy:		88.48 %
Epoch 1030 of 2000 took 0.099s
  training loss:		0.294843
  validation loss:		0.376207
  validation accuracy:		88.48 %
Epoch 1031 of 2000 took 0.096s
  training loss:		0.299890
  validation loss:		0.413921
  validation accuracy:		88.59 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.300424
  validation loss:		0.402088
  validation accuracy:		89.24 %
Epoch 1033 of 2000 took 0.096s
  training loss:		0.292670
  validation loss:		0.375024
  validation accuracy:		88.91 %
Epoch 1034 of 2000 took 0.098s
  training loss:		0.291492
  validation loss:		0.397925
  validation accuracy:		90.11 %
Epoch 1035 of 2000 took 0.098s
  training loss:		0.294397
  validation loss:		0.380242
  validation accuracy:		88.91 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.295172
  validation loss:		0.378511
  validation accuracy:		88.80 %
Epoch 1037 of 2000 took 0.102s
  training loss:		0.300033
  validation loss:		0.384819
  validation accuracy:		89.46 %
Epoch 1038 of 2000 took 0.096s
  training loss:		0.296130
  validation loss:		0.401118
  validation accuracy:		88.59 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.297202
  validation loss:		0.378154
  validation accuracy:		89.46 %
Epoch 1040 of 2000 took 0.096s
  training loss:		0.293099
  validation loss:		0.388129
  validation accuracy:		88.26 %
Epoch 1041 of 2000 took 0.098s
  training loss:		0.288261
  validation loss:		0.383789
  validation accuracy:		87.83 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.289880
  validation loss:		0.403170
  validation accuracy:		89.57 %
Epoch 1043 of 2000 took 0.096s
  training loss:		0.298892
  validation loss:		0.393590
  validation accuracy:		89.46 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.292863
  validation loss:		0.373352
  validation accuracy:		88.80 %
Epoch 1045 of 2000 took 0.102s
  training loss:		0.294335
  validation loss:		0.410562
  validation accuracy:		88.59 %
Epoch 1046 of 2000 took 0.096s
  training loss:		0.298608
  validation loss:		0.385186
  validation accuracy:		88.91 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.300861
  validation loss:		0.375202
  validation accuracy:		89.02 %
Epoch 1048 of 2000 took 0.096s
  training loss:		0.287764
  validation loss:		0.373876
  validation accuracy:		88.91 %
Epoch 1049 of 2000 took 0.099s
  training loss:		0.293328
  validation loss:		0.368942
  validation accuracy:		89.35 %
Epoch 1050 of 2000 took 0.098s
  training loss:		0.293249
  validation loss:		0.370302
  validation accuracy:		88.91 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.298589
  validation loss:		0.371450
  validation accuracy:		88.80 %
Epoch 1052 of 2000 took 0.099s
  training loss:		0.292931
  validation loss:		0.372752
  validation accuracy:		88.37 %
Epoch 1053 of 2000 took 0.099s
  training loss:		0.293910
  validation loss:		0.384527
  validation accuracy:		89.67 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.291197
  validation loss:		0.372005
  validation accuracy:		88.59 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.289803
  validation loss:		0.369097
  validation accuracy:		89.46 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.300343
  validation loss:		0.397752
  validation accuracy:		88.37 %
Epoch 1057 of 2000 took 0.101s
  training loss:		0.295230
  validation loss:		0.376585
  validation accuracy:		88.80 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.292924
  validation loss:		0.394591
  validation accuracy:		89.35 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.289899
  validation loss:		0.414622
  validation accuracy:		88.91 %
Epoch 1060 of 2000 took 0.102s
  training loss:		0.290258
  validation loss:		0.396531
  validation accuracy:		89.35 %
Epoch 1061 of 2000 took 0.097s
  training loss:		0.288527
  validation loss:		0.390345
  validation accuracy:		88.37 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.292557
  validation loss:		0.374743
  validation accuracy:		88.70 %
Epoch 1063 of 2000 took 0.096s
  training loss:		0.289682
  validation loss:		0.395844
  validation accuracy:		89.13 %
Epoch 1064 of 2000 took 0.097s
  training loss:		0.301494
  validation loss:		0.376285
  validation accuracy:		88.59 %
Epoch 1065 of 2000 took 0.100s
  training loss:		0.292888
  validation loss:		0.404522
  validation accuracy:		88.91 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.297852
  validation loss:		0.374178
  validation accuracy:		88.80 %
Epoch 1067 of 2000 took 0.097s
  training loss:		0.298570
  validation loss:		0.398325
  validation accuracy:		89.35 %
Epoch 1068 of 2000 took 0.102s
  training loss:		0.288783
  validation loss:		0.382633
  validation accuracy:		88.80 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.297313
  validation loss:		0.376487
  validation accuracy:		89.24 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.287378
  validation loss:		0.392017
  validation accuracy:		89.57 %
Epoch 1071 of 2000 took 0.096s
  training loss:		0.288030
  validation loss:		0.382940
  validation accuracy:		88.26 %
Epoch 1072 of 2000 took 0.098s
  training loss:		0.294151
  validation loss:		0.374417
  validation accuracy:		88.80 %
Epoch 1073 of 2000 took 0.100s
  training loss:		0.293466
  validation loss:		0.374102
  validation accuracy:		89.02 %
Epoch 1074 of 2000 took 0.096s
  training loss:		0.298422
  validation loss:		0.382403
  validation accuracy:		88.26 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.286322
  validation loss:		0.377217
  validation accuracy:		89.13 %
Epoch 1076 of 2000 took 0.102s
  training loss:		0.295428
  validation loss:		0.372021
  validation accuracy:		89.13 %
Epoch 1077 of 2000 took 0.096s
  training loss:		0.293612
  validation loss:		0.379645
  validation accuracy:		88.91 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.303939
  validation loss:		0.390699
  validation accuracy:		89.35 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.291508
  validation loss:		0.385027
  validation accuracy:		88.04 %
Epoch 1080 of 2000 took 0.099s
  training loss:		0.283329
  validation loss:		0.381874
  validation accuracy:		88.48 %
Epoch 1081 of 2000 took 0.098s
  training loss:		0.292475
  validation loss:		0.389872
  validation accuracy:		88.15 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.292786
  validation loss:		0.400914
  validation accuracy:		88.37 %
Epoch 1083 of 2000 took 0.100s
  training loss:		0.289853
  validation loss:		0.389698
  validation accuracy:		88.91 %
Epoch 1084 of 2000 took 0.099s
  training loss:		0.295967
  validation loss:		0.372350
  validation accuracy:		88.91 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.292587
  validation loss:		0.369468
  validation accuracy:		89.24 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.293363
  validation loss:		0.371284
  validation accuracy:		89.13 %
Epoch 1087 of 2000 took 0.096s
  training loss:		0.289102
  validation loss:		0.378778
  validation accuracy:		89.02 %
Epoch 1088 of 2000 took 0.101s
  training loss:		0.295051
  validation loss:		0.374670
  validation accuracy:		88.70 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.286783
  validation loss:		0.386882
  validation accuracy:		89.35 %
Epoch 1090 of 2000 took 0.096s
  training loss:		0.291826
  validation loss:		0.375171
  validation accuracy:		88.48 %
Epoch 1091 of 2000 took 0.102s
  training loss:		0.288913
  validation loss:		0.384025
  validation accuracy:		89.57 %
Epoch 1092 of 2000 took 0.096s
  training loss:		0.289202
  validation loss:		0.380621
  validation accuracy:		88.26 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.294519
  validation loss:		0.368984
  validation accuracy:		89.02 %
Epoch 1094 of 2000 took 0.096s
  training loss:		0.289975
  validation loss:		0.381200
  validation accuracy:		89.57 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.287461
  validation loss:		0.381219
  validation accuracy:		89.24 %
Epoch 1096 of 2000 took 0.100s
  training loss:		0.290530
  validation loss:		0.371349
  validation accuracy:		89.24 %
Epoch 1097 of 2000 took 0.096s
  training loss:		0.286865
  validation loss:		0.384300
  validation accuracy:		88.26 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.289877
  validation loss:		0.398028
  validation accuracy:		87.83 %
Epoch 1099 of 2000 took 0.102s
  training loss:		0.294449
  validation loss:		0.385246
  validation accuracy:		89.02 %
Epoch 1100 of 2000 took 0.096s
  training loss:		0.293854
  validation loss:		0.378863
  validation accuracy:		88.59 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.292668
  validation loss:		0.372067
  validation accuracy:		88.70 %
Epoch 1102 of 2000 took 0.096s
  training loss:		0.287666
  validation loss:		0.391874
  validation accuracy:		89.24 %
Epoch 1103 of 2000 took 0.098s
  training loss:		0.289505
  validation loss:		0.396215
  validation accuracy:		89.78 %
Epoch 1104 of 2000 took 0.100s
  training loss:		0.285052
  validation loss:		0.368805
  validation accuracy:		89.46 %
Epoch 1105 of 2000 took 0.096s
  training loss:		0.283915
  validation loss:		0.379195
  validation accuracy:		89.13 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.292264
  validation loss:		0.387726
  validation accuracy:		89.13 %
Epoch 1107 of 2000 took 0.101s
  training loss:		0.285534
  validation loss:		0.373173
  validation accuracy:		88.80 %
Epoch 1108 of 2000 took 0.096s
  training loss:		0.286125
  validation loss:		0.390843
  validation accuracy:		88.04 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.293058
  validation loss:		0.422863
  validation accuracy:		89.13 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.289964
  validation loss:		0.376183
  validation accuracy:		89.57 %
Epoch 1111 of 2000 took 0.100s
  training loss:		0.292369
  validation loss:		0.370368
  validation accuracy:		88.70 %
Epoch 1112 of 2000 took 0.098s
  training loss:		0.290388
  validation loss:		0.368224
  validation accuracy:		89.13 %
Epoch 1113 of 2000 took 0.096s
  training loss:		0.288146
  validation loss:		0.383530
  validation accuracy:		88.59 %
Epoch 1114 of 2000 took 0.100s
  training loss:		0.286070
  validation loss:		0.396142
  validation accuracy:		88.37 %
Epoch 1115 of 2000 took 0.098s
  training loss:		0.286514
  validation loss:		0.366100
  validation accuracy:		89.46 %
Epoch 1116 of 2000 took 0.096s
  training loss:		0.301024
  validation loss:		0.378968
  validation accuracy:		88.37 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.292928
  validation loss:		0.370081
  validation accuracy:		89.13 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.290895
  validation loss:		0.376552
  validation accuracy:		88.80 %
Epoch 1119 of 2000 took 0.100s
  training loss:		0.285267
  validation loss:		0.401310
  validation accuracy:		89.35 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.294969
  validation loss:		0.374793
  validation accuracy:		89.24 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.284486
  validation loss:		0.377078
  validation accuracy:		89.24 %
Epoch 1122 of 2000 took 0.102s
  training loss:		0.288977
  validation loss:		0.379750
  validation accuracy:		87.83 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.282840
  validation loss:		0.373978
  validation accuracy:		88.59 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.285650
  validation loss:		0.369316
  validation accuracy:		88.48 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.286483
  validation loss:		0.384097
  validation accuracy:		87.72 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.288600
  validation loss:		0.377505
  validation accuracy:		89.57 %
Epoch 1127 of 2000 took 0.101s
  training loss:		0.291152
  validation loss:		0.375489
  validation accuracy:		88.26 %
Epoch 1128 of 2000 took 0.096s
  training loss:		0.285355
  validation loss:		0.406714
  validation accuracy:		88.59 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.285708
  validation loss:		0.372523
  validation accuracy:		88.91 %
Epoch 1130 of 2000 took 0.102s
  training loss:		0.285303
  validation loss:		0.388503
  validation accuracy:		88.59 %
Epoch 1131 of 2000 took 0.096s
  training loss:		0.287916
  validation loss:		0.389572
  validation accuracy:		88.59 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.283897
  validation loss:		0.376653
  validation accuracy:		88.59 %
Epoch 1133 of 2000 took 0.096s
  training loss:		0.288997
  validation loss:		0.397614
  validation accuracy:		88.37 %
Epoch 1134 of 2000 took 0.098s
  training loss:		0.291175
  validation loss:		0.399575
  validation accuracy:		88.59 %
Epoch 1135 of 2000 took 0.099s
  training loss:		0.280039
  validation loss:		0.378863
  validation accuracy:		88.91 %
Epoch 1136 of 2000 took 0.096s
  training loss:		0.284802
  validation loss:		0.382599
  validation accuracy:		88.70 %
Epoch 1137 of 2000 took 0.098s
  training loss:		0.293592
  validation loss:		0.370958
  validation accuracy:		88.80 %
Epoch 1138 of 2000 took 0.100s
  training loss:		0.287145
  validation loss:		0.376064
  validation accuracy:		88.80 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.289158
  validation loss:		0.409020
  validation accuracy:		88.26 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.290732
  validation loss:		0.423332
  validation accuracy:		89.46 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.292744
  validation loss:		0.372833
  validation accuracy:		88.48 %
Epoch 1142 of 2000 took 0.101s
  training loss:		0.286570
  validation loss:		0.370693
  validation accuracy:		89.02 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.291205
  validation loss:		0.372471
  validation accuracy:		89.02 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.290938
  validation loss:		0.392797
  validation accuracy:		88.91 %
Epoch 1145 of 2000 took 0.101s
  training loss:		0.286490
  validation loss:		0.398850
  validation accuracy:		88.04 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.298457
  validation loss:		0.399367
  validation accuracy:		88.80 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.285037
  validation loss:		0.377340
  validation accuracy:		89.24 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.284552
  validation loss:		0.376086
  validation accuracy:		89.13 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.287002
  validation loss:		0.368713
  validation accuracy:		89.13 %
Epoch 1150 of 2000 took 0.100s
  training loss:		0.288797
  validation loss:		0.389022
  validation accuracy:		88.15 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.279435
  validation loss:		0.378399
  validation accuracy:		89.13 %
Epoch 1152 of 2000 took 0.099s
  training loss:		0.279300
  validation loss:		0.380741
  validation accuracy:		89.46 %
Epoch 1153 of 2000 took 0.102s
  training loss:		0.288683
  validation loss:		0.383401
  validation accuracy:		88.15 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.281107
  validation loss:		0.381790
  validation accuracy:		88.15 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.289229
  validation loss:		0.374301
  validation accuracy:		88.37 %
Epoch 1156 of 2000 took 0.096s
  training loss:		0.290271
  validation loss:		0.372086
  validation accuracy:		89.24 %
Epoch 1157 of 2000 took 0.098s
  training loss:		0.277961
  validation loss:		0.368887
  validation accuracy:		89.35 %
Epoch 1158 of 2000 took 0.100s
  training loss:		0.286856
  validation loss:		0.386905
  validation accuracy:		88.91 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.287818
  validation loss:		0.397770
  validation accuracy:		89.46 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.292336
  validation loss:		0.397123
  validation accuracy:		89.13 %
Epoch 1161 of 2000 took 0.102s
  training loss:		0.290498
  validation loss:		0.382559
  validation accuracy:		89.35 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.288443
  validation loss:		0.376831
  validation accuracy:		89.57 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.287461
  validation loss:		0.368615
  validation accuracy:		88.80 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.284782
  validation loss:		0.377274
  validation accuracy:		89.57 %
Epoch 1165 of 2000 took 0.100s
  training loss:		0.291356
  validation loss:		0.368049
  validation accuracy:		89.57 %
Epoch 1166 of 2000 took 0.098s
  training loss:		0.290461
  validation loss:		0.377274
  validation accuracy:		89.13 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.287072
  validation loss:		0.391153
  validation accuracy:		89.46 %
Epoch 1168 of 2000 took 0.100s
  training loss:		0.288954
  validation loss:		0.385965
  validation accuracy:		88.80 %
Epoch 1169 of 2000 took 0.099s
  training loss:		0.287159
  validation loss:		0.378550
  validation accuracy:		88.91 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.289105
  validation loss:		0.380098
  validation accuracy:		89.35 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.283895
  validation loss:		0.390630
  validation accuracy:		88.26 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.282248
  validation loss:		0.371323
  validation accuracy:		89.24 %
Epoch 1173 of 2000 took 0.100s
  training loss:		0.286855
  validation loss:		0.384146
  validation accuracy:		89.78 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.285885
  validation loss:		0.386823
  validation accuracy:		89.02 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.280427
  validation loss:		0.368630
  validation accuracy:		89.67 %
Epoch 1176 of 2000 took 0.102s
  training loss:		0.288205
  validation loss:		0.373010
  validation accuracy:		88.80 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.283187
  validation loss:		0.379645
  validation accuracy:		89.46 %
Epoch 1178 of 2000 took 0.097s
  training loss:		0.279673
  validation loss:		0.373324
  validation accuracy:		88.91 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.288900
  validation loss:		0.395455
  validation accuracy:		88.80 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.285267
  validation loss:		0.394342
  validation accuracy:		89.02 %
Epoch 1181 of 2000 took 0.100s
  training loss:		0.288068
  validation loss:		0.382869
  validation accuracy:		88.59 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.287100
  validation loss:		0.384986
  validation accuracy:		88.59 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.289544
  validation loss:		0.388529
  validation accuracy:		87.61 %
Epoch 1184 of 2000 took 0.102s
  training loss:		0.286349
  validation loss:		0.366617
  validation accuracy:		89.35 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.282501
  validation loss:		0.377030
  validation accuracy:		89.35 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.286177
  validation loss:		0.378337
  validation accuracy:		88.80 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.282271
  validation loss:		0.393714
  validation accuracy:		88.91 %
Epoch 1188 of 2000 took 0.098s
  training loss:		0.280543
  validation loss:		0.374848
  validation accuracy:		89.24 %
Epoch 1189 of 2000 took 0.099s
  training loss:		0.286988
  validation loss:		0.394150
  validation accuracy:		88.26 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.281313
  validation loss:		0.378602
  validation accuracy:		89.24 %
Epoch 1191 of 2000 took 0.098s
  training loss:		0.287170
  validation loss:		0.398923
  validation accuracy:		89.13 %
Epoch 1192 of 2000 took 0.101s
  training loss:		0.289041
  validation loss:		0.401447
  validation accuracy:		89.57 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.289225
  validation loss:		0.369992
  validation accuracy:		89.46 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.280581
  validation loss:		0.380405
  validation accuracy:		88.91 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.287221
  validation loss:		0.376673
  validation accuracy:		88.15 %
Epoch 1196 of 2000 took 0.101s
  training loss:		0.285447
  validation loss:		0.392399
  validation accuracy:		88.15 %
Epoch 1197 of 2000 took 0.098s
  training loss:		0.291857
  validation loss:		0.373065
  validation accuracy:		88.37 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.287017
  validation loss:		0.391145
  validation accuracy:		88.70 %
Epoch 1199 of 2000 took 0.100s
  training loss:		0.281365
  validation loss:		0.389996
  validation accuracy:		89.13 %
Epoch 1200 of 2000 took 0.098s
  training loss:		0.290877
  validation loss:		0.374346
  validation accuracy:		88.37 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.290216
  validation loss:		0.370566
  validation accuracy:		89.13 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.289088
  validation loss:		0.382860
  validation accuracy:		88.70 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.283821
  validation loss:		0.380803
  validation accuracy:		88.80 %
Epoch 1204 of 2000 took 0.100s
  training loss:		0.287705
  validation loss:		0.378594
  validation accuracy:		88.91 %
Epoch 1205 of 2000 took 0.097s
  training loss:		0.275572
  validation loss:		0.367066
  validation accuracy:		89.13 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.285286
  validation loss:		0.373427
  validation accuracy:		88.59 %
Epoch 1207 of 2000 took 0.102s
  training loss:		0.282359
  validation loss:		0.379969
  validation accuracy:		89.02 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.291304
  validation loss:		0.377170
  validation accuracy:		89.02 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.281370
  validation loss:		0.387379
  validation accuracy:		89.35 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.293334
  validation loss:		0.374318
  validation accuracy:		88.80 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.281088
  validation loss:		0.376535
  validation accuracy:		89.02 %
Epoch 1212 of 2000 took 0.100s
  training loss:		0.286903
  validation loss:		0.368182
  validation accuracy:		88.91 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.282690
  validation loss:		0.398147
  validation accuracy:		89.24 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.285068
  validation loss:		0.387290
  validation accuracy:		88.59 %
Epoch 1215 of 2000 took 0.102s
  training loss:		0.282278
  validation loss:		0.378826
  validation accuracy:		89.02 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.275483
  validation loss:		0.396129
  validation accuracy:		89.24 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.278841
  validation loss:		0.381882
  validation accuracy:		89.02 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.288955
  validation loss:		0.369591
  validation accuracy:		89.02 %
Epoch 1219 of 2000 took 0.098s
  training loss:		0.284600
  validation loss:		0.398951
  validation accuracy:		88.59 %
Epoch 1220 of 2000 took 0.099s
  training loss:		0.285808
  validation loss:		0.381161
  validation accuracy:		88.59 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.290444
  validation loss:		0.402029
  validation accuracy:		88.59 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.273810
  validation loss:		0.394118
  validation accuracy:		88.15 %
Epoch 1223 of 2000 took 0.101s
  training loss:		0.283398
  validation loss:		0.370550
  validation accuracy:		89.35 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.282349
  validation loss:		0.378240
  validation accuracy:		88.80 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.285431
  validation loss:		0.385791
  validation accuracy:		89.02 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.281497
  validation loss:		0.379961
  validation accuracy:		88.15 %
Epoch 1227 of 2000 took 0.101s
  training loss:		0.278185
  validation loss:		0.386722
  validation accuracy:		89.67 %
Epoch 1228 of 2000 took 0.098s
  training loss:		0.286622
  validation loss:		0.367361
  validation accuracy:		89.46 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.279856
  validation loss:		0.376585
  validation accuracy:		89.24 %
Epoch 1230 of 2000 took 0.101s
  training loss:		0.285287
  validation loss:		0.371922
  validation accuracy:		89.02 %
Epoch 1231 of 2000 took 0.098s
  training loss:		0.285632
  validation loss:		0.365214
  validation accuracy:		89.46 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.283153
  validation loss:		0.386319
  validation accuracy:		89.24 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.283786
  validation loss:		0.371262
  validation accuracy:		88.80 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.283577
  validation loss:		0.370739
  validation accuracy:		89.46 %
Epoch 1235 of 2000 took 0.100s
  training loss:		0.285192
  validation loss:		0.369837
  validation accuracy:		89.57 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.280494
  validation loss:		0.383035
  validation accuracy:		89.24 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.285293
  validation loss:		0.379818
  validation accuracy:		89.13 %
Epoch 1238 of 2000 took 0.102s
  training loss:		0.280969
  validation loss:		0.388552
  validation accuracy:		88.91 %
Epoch 1239 of 2000 took 0.096s
  training loss:		0.291492
  validation loss:		0.370253
  validation accuracy:		89.24 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.281454
  validation loss:		0.370636
  validation accuracy:		89.02 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.283300
  validation loss:		0.378331
  validation accuracy:		89.46 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.283750
  validation loss:		0.371835
  validation accuracy:		89.24 %
Epoch 1243 of 2000 took 0.100s
  training loss:		0.285566
  validation loss:		0.392775
  validation accuracy:		89.02 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.283727
  validation loss:		0.382083
  validation accuracy:		89.24 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.281727
  validation loss:		0.385129
  validation accuracy:		89.35 %
Epoch 1246 of 2000 took 0.102s
  training loss:		0.281224
  validation loss:		0.377347
  validation accuracy:		89.35 %
Epoch 1247 of 2000 took 0.096s
  training loss:		0.278292
  validation loss:		0.380084
  validation accuracy:		89.13 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.281860
  validation loss:		0.399733
  validation accuracy:		88.91 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.275974
  validation loss:		0.380910
  validation accuracy:		89.46 %
Epoch 1250 of 2000 took 0.099s
  training loss:		0.284966
  validation loss:		0.379441
  validation accuracy:		89.67 %
Epoch 1251 of 2000 took 0.099s
  training loss:		0.278655
  validation loss:		0.372683
  validation accuracy:		89.02 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.279542
  validation loss:		0.388821
  validation accuracy:		88.59 %
Epoch 1253 of 2000 took 0.098s
  training loss:		0.281850
  validation loss:		0.389778
  validation accuracy:		89.02 %
Epoch 1254 of 2000 took 0.101s
  training loss:		0.279478
  validation loss:		0.372642
  validation accuracy:		88.91 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.280013
  validation loss:		0.373532
  validation accuracy:		88.70 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.275046
  validation loss:		0.374946
  validation accuracy:		88.80 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.282300
  validation loss:		0.393382
  validation accuracy:		89.24 %
Epoch 1258 of 2000 took 0.100s
  training loss:		0.279470
  validation loss:		0.385378
  validation accuracy:		89.02 %
Epoch 1259 of 2000 took 0.098s
  training loss:		0.284104
  validation loss:		0.384153
  validation accuracy:		88.91 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.274966
  validation loss:		0.374918
  validation accuracy:		89.46 %
Epoch 1261 of 2000 took 0.100s
  training loss:		0.279942
  validation loss:		0.371141
  validation accuracy:		89.35 %
Epoch 1262 of 2000 took 0.098s
  training loss:		0.281237
  validation loss:		0.385233
  validation accuracy:		88.37 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.286371
  validation loss:		0.379209
  validation accuracy:		88.80 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.281121
  validation loss:		0.392693
  validation accuracy:		89.24 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.276012
  validation loss:		0.394586
  validation accuracy:		88.37 %
Epoch 1266 of 2000 took 0.100s
  training loss:		0.283238
  validation loss:		0.384368
  validation accuracy:		89.02 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.277442
  validation loss:		0.377559
  validation accuracy:		89.46 %
Epoch 1268 of 2000 took 0.096s
  training loss:		0.275323
  validation loss:		0.381222
  validation accuracy:		88.80 %
Epoch 1269 of 2000 took 0.102s
  training loss:		0.279981
  validation loss:		0.382776
  validation accuracy:		89.24 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.276013
  validation loss:		0.396734
  validation accuracy:		88.80 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.266975
  validation loss:		0.379370
  validation accuracy:		88.91 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.279793
  validation loss:		0.383883
  validation accuracy:		89.57 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.278874
  validation loss:		0.381214
  validation accuracy:		89.02 %
Epoch 1274 of 2000 took 0.100s
  training loss:		0.279460
  validation loss:		0.370879
  validation accuracy:		89.13 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.278418
  validation loss:		0.392776
  validation accuracy:		89.67 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.273613
  validation loss:		0.390503
  validation accuracy:		89.13 %
Epoch 1277 of 2000 took 0.102s
  training loss:		0.286631
  validation loss:		0.413124
  validation accuracy:		88.37 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.288385
  validation loss:		0.388288
  validation accuracy:		89.13 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.283308
  validation loss:		0.379433
  validation accuracy:		89.35 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.282412
  validation loss:		0.387325
  validation accuracy:		88.91 %
Epoch 1281 of 2000 took 0.099s
  training loss:		0.276510
  validation loss:		0.378639
  validation accuracy:		89.13 %
Epoch 1282 of 2000 took 0.099s
  training loss:		0.283254
  validation loss:		0.403367
  validation accuracy:		88.48 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.278209
  validation loss:		0.377156
  validation accuracy:		89.02 %
Epoch 1284 of 2000 took 0.098s
  training loss:		0.276330
  validation loss:		0.375860
  validation accuracy:		89.67 %
Epoch 1285 of 2000 took 0.101s
  training loss:		0.279732
  validation loss:		0.374762
  validation accuracy:		89.46 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.279827
  validation loss:		0.374386
  validation accuracy:		88.70 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.277339
  validation loss:		0.381163
  validation accuracy:		89.57 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.276116
  validation loss:		0.396861
  validation accuracy:		88.15 %
Epoch 1289 of 2000 took 0.101s
  training loss:		0.275759
  validation loss:		0.382803
  validation accuracy:		89.35 %
Epoch 1290 of 2000 took 0.098s
  training loss:		0.278279
  validation loss:		0.380274
  validation accuracy:		88.80 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.279412
  validation loss:		0.406334
  validation accuracy:		88.59 %
Epoch 1292 of 2000 took 0.100s
  training loss:		0.291987
  validation loss:		0.414980
  validation accuracy:		88.59 %
Epoch 1293 of 2000 took 0.098s
  training loss:		0.283198
  validation loss:		0.383703
  validation accuracy:		88.91 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.278930
  validation loss:		0.370950
  validation accuracy:		89.13 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.277475
  validation loss:		0.399548
  validation accuracy:		88.59 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.280139
  validation loss:		0.378722
  validation accuracy:		89.78 %
Epoch 1297 of 2000 took 0.100s
  training loss:		0.279400
  validation loss:		0.374458
  validation accuracy:		89.02 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.279350
  validation loss:		0.384035
  validation accuracy:		89.02 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.284437
  validation loss:		0.394586
  validation accuracy:		88.37 %
Epoch 1300 of 2000 took 0.102s
  training loss:		0.279511
  validation loss:		0.378108
  validation accuracy:		89.13 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.281436
  validation loss:		0.389933
  validation accuracy:		89.78 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.284713
  validation loss:		0.375982
  validation accuracy:		89.35 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.281304
  validation loss:		0.386138
  validation accuracy:		89.13 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.281311
  validation loss:		0.393474
  validation accuracy:		89.02 %
Epoch 1305 of 2000 took 0.100s
  training loss:		0.275890
  validation loss:		0.390472
  validation accuracy:		89.24 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.278898
  validation loss:		0.379910
  validation accuracy:		89.24 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.285055
  validation loss:		0.372649
  validation accuracy:		89.46 %
Epoch 1308 of 2000 took 0.102s
  training loss:		0.283093
  validation loss:		0.385772
  validation accuracy:		89.35 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.275368
  validation loss:		0.373722
  validation accuracy:		88.70 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.281480
  validation loss:		0.383870
  validation accuracy:		89.57 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.280061
  validation loss:		0.384408
  validation accuracy:		88.70 %
Epoch 1312 of 2000 took 0.098s
  training loss:		0.279967
  validation loss:		0.374018
  validation accuracy:		89.35 %
Epoch 1313 of 2000 took 0.100s
  training loss:		0.276319
  validation loss:		0.388087
  validation accuracy:		89.35 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.273160
  validation loss:		0.374119
  validation accuracy:		89.13 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.278087
  validation loss:		0.376866
  validation accuracy:		88.91 %
Epoch 1316 of 2000 took 0.102s
  training loss:		0.280027
  validation loss:		0.380370
  validation accuracy:		88.80 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.276077
  validation loss:		0.386702
  validation accuracy:		89.57 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.282882
  validation loss:		0.379264
  validation accuracy:		89.02 %
Epoch 1319 of 2000 took 0.096s
  training loss:		0.276046
  validation loss:		0.376853
  validation accuracy:		88.91 %
Epoch 1320 of 2000 took 0.100s
  training loss:		0.278551
  validation loss:		0.377196
  validation accuracy:		89.24 %
Epoch 1321 of 2000 took 0.098s
  training loss:		0.279552
  validation loss:		0.389656
  validation accuracy:		88.91 %
Epoch 1322 of 2000 took 0.096s
  training loss:		0.277089
  validation loss:		0.399648
  validation accuracy:		89.35 %
Epoch 1323 of 2000 took 0.099s
  training loss:		0.280866
  validation loss:		0.387677
  validation accuracy:		89.02 %
Epoch 1324 of 2000 took 0.099s
  training loss:		0.282534
  validation loss:		0.375938
  validation accuracy:		88.91 %
Epoch 1325 of 2000 took 0.096s
  training loss:		0.272161
  validation loss:		0.415388
  validation accuracy:		88.37 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.277713
  validation loss:		0.388284
  validation accuracy:		88.59 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.281109
  validation loss:		0.375002
  validation accuracy:		89.24 %
Epoch 1328 of 2000 took 0.101s
  training loss:		0.279877
  validation loss:		0.385249
  validation accuracy:		88.59 %
Epoch 1329 of 2000 took 0.098s
  training loss:		0.278953
  validation loss:		0.370601
  validation accuracy:		89.24 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.278606
  validation loss:		0.379598
  validation accuracy:		88.70 %
Epoch 1331 of 2000 took 0.102s
  training loss:		0.270416
  validation loss:		0.397447
  validation accuracy:		89.35 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.279658
  validation loss:		0.381608
  validation accuracy:		89.46 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.276797
  validation loss:		0.378956
  validation accuracy:		88.91 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.286460
  validation loss:		0.393692
  validation accuracy:		88.91 %
Epoch 1335 of 2000 took 0.097s
  training loss:		0.277090
  validation loss:		0.379748
  validation accuracy:		89.46 %
Epoch 1336 of 2000 took 0.100s
  training loss:		0.277211
  validation loss:		0.379831
  validation accuracy:		89.35 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.277811
  validation loss:		0.408483
  validation accuracy:		87.72 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.281368
  validation loss:		0.376261
  validation accuracy:		89.46 %
Epoch 1339 of 2000 took 0.102s
  training loss:		0.275603
  validation loss:		0.379291
  validation accuracy:		88.91 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.271753
  validation loss:		0.396113
  validation accuracy:		89.35 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.283638
  validation loss:		0.372073
  validation accuracy:		89.24 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.282449
  validation loss:		0.376303
  validation accuracy:		89.24 %
Epoch 1343 of 2000 took 0.098s
  training loss:		0.276080
  validation loss:		0.373877
  validation accuracy:		89.24 %
Epoch 1344 of 2000 took 0.100s
  training loss:		0.278890
  validation loss:		0.386731
  validation accuracy:		89.24 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.278490
  validation loss:		0.377999
  validation accuracy:		89.24 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.278875
  validation loss:		0.379378
  validation accuracy:		89.13 %
Epoch 1347 of 2000 took 0.101s
  training loss:		0.275710
  validation loss:		0.370355
  validation accuracy:		89.35 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.272011
  validation loss:		0.390812
  validation accuracy:		89.13 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.276905
  validation loss:		0.385080
  validation accuracy:		88.91 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.272379
  validation loss:		0.385330
  validation accuracy:		89.02 %
Epoch 1351 of 2000 took 0.100s
  training loss:		0.274065
  validation loss:		0.379392
  validation accuracy:		89.35 %
Epoch 1352 of 2000 took 0.098s
  training loss:		0.285326
  validation loss:		0.408534
  validation accuracy:		88.26 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.278873
  validation loss:		0.383530
  validation accuracy:		89.13 %
Epoch 1354 of 2000 took 0.099s
  training loss:		0.275430
  validation loss:		0.396310
  validation accuracy:		88.70 %
Epoch 1355 of 2000 took 0.099s
  training loss:		0.275442
  validation loss:		0.376086
  validation accuracy:		89.24 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.275921
  validation loss:		0.382908
  validation accuracy:		89.78 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.284591
  validation loss:		0.404042
  validation accuracy:		88.91 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.276646
  validation loss:		0.391563
  validation accuracy:		89.13 %
Epoch 1359 of 2000 took 0.101s
  training loss:		0.273615
  validation loss:		0.382818
  validation accuracy:		89.02 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.275502
  validation loss:		0.394499
  validation accuracy:		88.48 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.276383
  validation loss:		0.397507
  validation accuracy:		89.02 %
Epoch 1362 of 2000 took 0.102s
  training loss:		0.277047
  validation loss:		0.388621
  validation accuracy:		89.02 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.273776
  validation loss:		0.381801
  validation accuracy:		88.48 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.273560
  validation loss:		0.397490
  validation accuracy:		89.35 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.276030
  validation loss:		0.381398
  validation accuracy:		89.02 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.279238
  validation loss:		0.376554
  validation accuracy:		89.89 %
Epoch 1367 of 2000 took 0.100s
  training loss:		0.277423
  validation loss:		0.397920
  validation accuracy:		89.24 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.272544
  validation loss:		0.377395
  validation accuracy:		89.13 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.279268
  validation loss:		0.394104
  validation accuracy:		89.35 %
Epoch 1370 of 2000 took 0.103s
  training loss:		0.273614
  validation loss:		0.386236
  validation accuracy:		89.46 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.271679
  validation loss:		0.377605
  validation accuracy:		89.35 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.274686
  validation loss:		0.385630
  validation accuracy:		89.13 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.279668
  validation loss:		0.392464
  validation accuracy:		89.35 %
Epoch 1374 of 2000 took 0.098s
  training loss:		0.275964
  validation loss:		0.373204
  validation accuracy:		89.46 %
Epoch 1375 of 2000 took 0.100s
  training loss:		0.273925
  validation loss:		0.371529
  validation accuracy:		89.35 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.274790
  validation loss:		0.388862
  validation accuracy:		89.02 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.275931
  validation loss:		0.380465
  validation accuracy:		89.13 %
Epoch 1378 of 2000 took 0.102s
  training loss:		0.281029
  validation loss:		0.385278
  validation accuracy:		89.35 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.281061
  validation loss:		0.380609
  validation accuracy:		89.46 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.266023
  validation loss:		0.379558
  validation accuracy:		89.67 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.270798
  validation loss:		0.373645
  validation accuracy:		89.57 %
Epoch 1382 of 2000 took 0.100s
  training loss:		0.273422
  validation loss:		0.382290
  validation accuracy:		89.67 %
Epoch 1383 of 2000 took 0.098s
  training loss:		0.279654
  validation loss:		0.382860
  validation accuracy:		89.57 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.282785
  validation loss:		0.417462
  validation accuracy:		89.24 %
Epoch 1385 of 2000 took 0.100s
  training loss:		0.276982
  validation loss:		0.387510
  validation accuracy:		89.24 %
Epoch 1386 of 2000 took 0.099s
  training loss:		0.273883
  validation loss:		0.387108
  validation accuracy:		89.13 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.278378
  validation loss:		0.409810
  validation accuracy:		88.80 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.269541
  validation loss:		0.386083
  validation accuracy:		89.24 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.273795
  validation loss:		0.441762
  validation accuracy:		87.17 %
Epoch 1390 of 2000 took 0.100s
  training loss:		0.288969
  validation loss:		0.403857
  validation accuracy:		88.70 %
Epoch 1391 of 2000 took 0.097s
  training loss:		0.277467
  validation loss:		0.382868
  validation accuracy:		89.78 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.274043
  validation loss:		0.379968
  validation accuracy:		89.02 %
Epoch 1393 of 2000 took 0.102s
  training loss:		0.272704
  validation loss:		0.394689
  validation accuracy:		88.48 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.274551
  validation loss:		0.385342
  validation accuracy:		89.13 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.275802
  validation loss:		0.382018
  validation accuracy:		89.13 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.278491
  validation loss:		0.373529
  validation accuracy:		89.02 %
Epoch 1397 of 2000 took 0.097s
  training loss:		0.278387
  validation loss:		0.387533
  validation accuracy:		89.35 %
Epoch 1398 of 2000 took 0.100s
  training loss:		0.276912
  validation loss:		0.382270
  validation accuracy:		89.24 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.275214
  validation loss:		0.377107
  validation accuracy:		89.57 %
Epoch 1400 of 2000 took 0.097s
  training loss:		0.277624
  validation loss:		0.382487
  validation accuracy:		89.46 %
Epoch 1401 of 2000 took 0.102s
  training loss:		0.267505
  validation loss:		0.393069
  validation accuracy:		88.59 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.274251
  validation loss:		0.398034
  validation accuracy:		89.13 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.279302
  validation loss:		0.394810
  validation accuracy:		89.02 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.272581
  validation loss:		0.388663
  validation accuracy:		89.24 %
Epoch 1405 of 2000 took 0.098s
  training loss:		0.268412
  validation loss:		0.375120
  validation accuracy:		89.24 %
Epoch 1406 of 2000 took 0.100s
  training loss:		0.280561
  validation loss:		0.378686
  validation accuracy:		89.57 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.279908
  validation loss:		0.380166
  validation accuracy:		89.46 %
Epoch 1408 of 2000 took 0.097s
  training loss:		0.276308
  validation loss:		0.389621
  validation accuracy:		89.02 %
Epoch 1409 of 2000 took 0.098s
  training loss:		0.274271
  validation loss:		0.376489
  validation accuracy:		89.78 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.277479
  validation loss:		0.382498
  validation accuracy:		89.24 %
Epoch 1411 of 2000 took 0.100s
  training loss:		0.268968
  validation loss:		0.392238
  validation accuracy:		88.80 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.276660
  validation loss:		0.380331
  validation accuracy:		89.89 %
Epoch 1413 of 2000 took 0.099s
  training loss:		0.267747
  validation loss:		0.405315
  validation accuracy:		88.48 %
Epoch 1414 of 2000 took 0.097s
  training loss:		0.275027
  validation loss:		0.378717
  validation accuracy:		89.57 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.269371
  validation loss:		0.381656
  validation accuracy:		89.46 %
Epoch 1416 of 2000 took 0.099s
  training loss:		0.270230
  validation loss:		0.399044
  validation accuracy:		89.13 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.273284
  validation loss:		0.383849
  validation accuracy:		89.24 %
Epoch 1418 of 2000 took 0.100s
  training loss:		0.272754
  validation loss:		0.377553
  validation accuracy:		89.67 %
Epoch 1419 of 2000 took 0.096s
  training loss:		0.278648
  validation loss:		0.373094
  validation accuracy:		89.35 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.279881
  validation loss:		0.381871
  validation accuracy:		89.46 %
Epoch 1421 of 2000 took 0.099s
  training loss:		0.275563
  validation loss:		0.375104
  validation accuracy:		89.57 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.273994
  validation loss:		0.390278
  validation accuracy:		89.35 %
Epoch 1423 of 2000 took 0.099s
  training loss:		0.271754
  validation loss:		0.399073
  validation accuracy:		89.35 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.277227
  validation loss:		0.378796
  validation accuracy:		89.78 %
Epoch 1425 of 2000 took 0.098s
  training loss:		0.272155
  validation loss:		0.382045
  validation accuracy:		89.46 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.273142
  validation loss:		0.373966
  validation accuracy:		89.46 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.269488
  validation loss:		0.379326
  validation accuracy:		89.24 %
Epoch 1428 of 2000 took 0.099s
  training loss:		0.278131
  validation loss:		0.383055
  validation accuracy:		89.46 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.271426
  validation loss:		0.378688
  validation accuracy:		89.46 %
Epoch 1430 of 2000 took 0.099s
  training loss:		0.276991
  validation loss:		0.408110
  validation accuracy:		88.48 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.273134
  validation loss:		0.392969
  validation accuracy:		89.35 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.272016
  validation loss:		0.399934
  validation accuracy:		88.80 %
Epoch 1433 of 2000 took 0.099s
  training loss:		0.275898
  validation loss:		0.382459
  validation accuracy:		89.24 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.279584
  validation loss:		0.385583
  validation accuracy:		89.46 %
Epoch 1435 of 2000 took 0.100s
  training loss:		0.274978
  validation loss:		0.383437
  validation accuracy:		89.89 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.268483
  validation loss:		0.391087
  validation accuracy:		89.13 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.271521
  validation loss:		0.377214
  validation accuracy:		89.67 %
Epoch 1438 of 2000 took 0.101s
  training loss:		0.271023
  validation loss:		0.393324
  validation accuracy:		89.35 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.275056
  validation loss:		0.387183
  validation accuracy:		89.57 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.270941
  validation loss:		0.398912
  validation accuracy:		89.13 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.268544
  validation loss:		0.386716
  validation accuracy:		89.57 %
Epoch 1442 of 2000 took 0.100s
  training loss:		0.268044
  validation loss:		0.377700
  validation accuracy:		89.57 %
Epoch 1443 of 2000 took 0.098s
  training loss:		0.269435
  validation loss:		0.385862
  validation accuracy:		89.46 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.277380
  validation loss:		0.389803
  validation accuracy:		89.46 %
Epoch 1445 of 2000 took 0.100s
  training loss:		0.276409
  validation loss:		0.382718
  validation accuracy:		89.57 %
Epoch 1446 of 2000 took 0.098s
  training loss:		0.270385
  validation loss:		0.402799
  validation accuracy:		88.91 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.273765
  validation loss:		0.378914
  validation accuracy:		89.57 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.273983
  validation loss:		0.386607
  validation accuracy:		89.57 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.273786
  validation loss:		0.381155
  validation accuracy:		89.46 %
Epoch 1450 of 2000 took 0.100s
  training loss:		0.276880
  validation loss:		0.385051
  validation accuracy:		89.57 %
Epoch 1451 of 2000 took 0.098s
  training loss:		0.275144
  validation loss:		0.414712
  validation accuracy:		88.48 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.279213
  validation loss:		0.388514
  validation accuracy:		89.02 %
Epoch 1453 of 2000 took 0.102s
  training loss:		0.271753
  validation loss:		0.381274
  validation accuracy:		90.00 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.274784
  validation loss:		0.380327
  validation accuracy:		89.67 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.269695
  validation loss:		0.399640
  validation accuracy:		89.46 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.265897
  validation loss:		0.383537
  validation accuracy:		89.89 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.268066
  validation loss:		0.390606
  validation accuracy:		89.02 %
Epoch 1458 of 2000 took 0.100s
  training loss:		0.269376
  validation loss:		0.409003
  validation accuracy:		88.70 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.276399
  validation loss:		0.387412
  validation accuracy:		89.24 %
Epoch 1460 of 2000 took 0.097s
  training loss:		0.283172
  validation loss:		0.403293
  validation accuracy:		89.13 %
Epoch 1461 of 2000 took 0.102s
  training loss:		0.278010
  validation loss:		0.399386
  validation accuracy:		88.37 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.273271
  validation loss:		0.382475
  validation accuracy:		89.57 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.272330
  validation loss:		0.390225
  validation accuracy:		89.24 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.272975
  validation loss:		0.375348
  validation accuracy:		89.46 %
Epoch 1465 of 2000 took 0.098s
  training loss:		0.281400
  validation loss:		0.384675
  validation accuracy:		89.57 %
Epoch 1466 of 2000 took 0.099s
  training loss:		0.274122
  validation loss:		0.385334
  validation accuracy:		89.13 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.268907
  validation loss:		0.393768
  validation accuracy:		88.91 %
Epoch 1468 of 2000 took 0.097s
  training loss:		0.271129
  validation loss:		0.378741
  validation accuracy:		89.35 %
Epoch 1469 of 2000 took 0.101s
  training loss:		0.276564
  validation loss:		0.398995
  validation accuracy:		88.48 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.274039
  validation loss:		0.403416
  validation accuracy:		89.24 %
Epoch 1471 of 2000 took 0.097s
  training loss:		0.271205
  validation loss:		0.381904
  validation accuracy:		89.46 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.265537
  validation loss:		0.392911
  validation accuracy:		89.57 %
Epoch 1473 of 2000 took 0.100s
  training loss:		0.286054
  validation loss:		0.403137
  validation accuracy:		89.13 %
Epoch 1474 of 2000 took 0.098s
  training loss:		0.266514
  validation loss:		0.377942
  validation accuracy:		89.35 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.268640
  validation loss:		0.387512
  validation accuracy:		89.24 %
Epoch 1476 of 2000 took 0.100s
  training loss:		0.276425
  validation loss:		0.412223
  validation accuracy:		88.70 %
Epoch 1477 of 2000 took 0.098s
  training loss:		0.270892
  validation loss:		0.391382
  validation accuracy:		89.13 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.266569
  validation loss:		0.397750
  validation accuracy:		89.57 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.274225
  validation loss:		0.405636
  validation accuracy:		88.59 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.275070
  validation loss:		0.380146
  validation accuracy:		89.46 %
Epoch 1481 of 2000 took 0.100s
  training loss:		0.274382
  validation loss:		0.385994
  validation accuracy:		89.57 %
Epoch 1482 of 2000 took 0.097s
  training loss:		0.272288
  validation loss:		0.374959
  validation accuracy:		89.57 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.278601
  validation loss:		0.381844
  validation accuracy:		89.78 %
Epoch 1484 of 2000 took 0.102s
  training loss:		0.266828
  validation loss:		0.387432
  validation accuracy:		89.67 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.273817
  validation loss:		0.375932
  validation accuracy:		89.46 %
Epoch 1486 of 2000 took 0.097s
  training loss:		0.270393
  validation loss:		0.378321
  validation accuracy:		89.57 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.271365
  validation loss:		0.388068
  validation accuracy:		90.00 %
Epoch 1488 of 2000 took 0.097s
  training loss:		0.267990
  validation loss:		0.384444
  validation accuracy:		89.67 %
Epoch 1489 of 2000 took 0.100s
  training loss:		0.269547
  validation loss:		0.381069
  validation accuracy:		89.67 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.278076
  validation loss:		0.378616
  validation accuracy:		89.24 %
Epoch 1491 of 2000 took 0.097s
  training loss:		0.275746
  validation loss:		0.394978
  validation accuracy:		89.13 %
Epoch 1492 of 2000 took 0.102s
  training loss:		0.266406
  validation loss:		0.381207
  validation accuracy:		89.46 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.265575
  validation loss:		0.379400
  validation accuracy:		89.67 %
Epoch 1494 of 2000 took 0.097s
  training loss:		0.273252
  validation loss:		0.395291
  validation accuracy:		89.35 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.266210
  validation loss:		0.400645
  validation accuracy:		89.24 %
Epoch 1496 of 2000 took 0.099s
  training loss:		0.272595
  validation loss:		0.388362
  validation accuracy:		89.57 %
Epoch 1497 of 2000 took 0.100s
  training loss:		0.272445
  validation loss:		0.386037
  validation accuracy:		89.46 %
Epoch 1498 of 2000 took 0.121s
  training loss:		0.267455
  validation loss:		0.390394
  validation accuracy:		89.67 %
Epoch 1499 of 2000 took 0.122s
  training loss:		0.266174
  validation loss:		0.399474
  validation accuracy:		89.24 %
Epoch 1500 of 2000 took 0.101s
  training loss:		0.265969
  validation loss:		0.380323
  validation accuracy:		89.46 %
Epoch 1501 of 2000 took 0.098s
  training loss:		0.270156
  validation loss:		0.382962
  validation accuracy:		89.46 %
Epoch 1502 of 2000 took 0.099s
  training loss:		0.273686
  validation loss:		0.387375
  validation accuracy:		89.57 %
Epoch 1503 of 2000 took 0.097s
  training loss:		0.274273
  validation loss:		0.403022
  validation accuracy:		89.02 %
Epoch 1504 of 2000 took 0.102s
  training loss:		0.267245
  validation loss:		0.395714
  validation accuracy:		89.24 %
Epoch 1505 of 2000 took 0.098s
  training loss:		0.264858
  validation loss:		0.384296
  validation accuracy:		89.89 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.276230
  validation loss:		0.382718
  validation accuracy:		90.00 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.270210
  validation loss:		0.439559
  validation accuracy:		87.28 %
Epoch 1508 of 2000 took 0.098s
  training loss:		0.278825
  validation loss:		0.387526
  validation accuracy:		89.67 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.275993
  validation loss:		0.432704
  validation accuracy:		87.83 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.272185
  validation loss:		0.387622
  validation accuracy:		89.78 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.272290
  validation loss:		0.376629
  validation accuracy:		89.78 %
Epoch 1512 of 2000 took 0.101s
  training loss:		0.270032
  validation loss:		0.389488
  validation accuracy:		89.57 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.273368
  validation loss:		0.394472
  validation accuracy:		89.13 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.269342
  validation loss:		0.389581
  validation accuracy:		89.46 %
Epoch 1515 of 2000 took 0.103s
  training loss:		0.272588
  validation loss:		0.390979
  validation accuracy:		89.24 %
Epoch 1516 of 2000 took 0.097s
  training loss:		0.276223
  validation loss:		0.392500
  validation accuracy:		89.46 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.271486
  validation loss:		0.380565
  validation accuracy:		89.89 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.273298
  validation loss:		0.394168
  validation accuracy:		89.46 %
Epoch 1519 of 2000 took 0.098s
  training loss:		0.272591
  validation loss:		0.397172
  validation accuracy:		89.35 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.264592
  validation loss:		0.382813
  validation accuracy:		89.67 %
Epoch 1521 of 2000 took 0.097s
  training loss:		0.272895
  validation loss:		0.394290
  validation accuracy:		90.00 %
Epoch 1522 of 2000 took 0.097s
  training loss:		0.268929
  validation loss:		0.395617
  validation accuracy:		89.78 %
Epoch 1523 of 2000 took 0.103s
  training loss:		0.268338
  validation loss:		0.406030
  validation accuracy:		88.80 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.264961
  validation loss:		0.390892
  validation accuracy:		89.78 %
Epoch 1525 of 2000 took 0.097s
  training loss:		0.271650
  validation loss:		0.390750
  validation accuracy:		89.46 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.270712
  validation loss:		0.387128
  validation accuracy:		89.67 %
Epoch 1527 of 2000 took 0.098s
  training loss:		0.270752
  validation loss:		0.409410
  validation accuracy:		88.91 %
Epoch 1528 of 2000 took 0.100s
  training loss:		0.272888
  validation loss:		0.378814
  validation accuracy:		89.46 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.278284
  validation loss:		0.379127
  validation accuracy:		89.57 %
Epoch 1530 of 2000 took 0.098s
  training loss:		0.273872
  validation loss:		0.381312
  validation accuracy:		89.78 %
Epoch 1531 of 2000 took 0.101s
  training loss:		0.272518
  validation loss:		0.395671
  validation accuracy:		89.35 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.272652
  validation loss:		0.392939
  validation accuracy:		89.35 %
Epoch 1533 of 2000 took 0.098s
  training loss:		0.275055
  validation loss:		0.395298
  validation accuracy:		88.91 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.269984
  validation loss:		0.418007
  validation accuracy:		88.91 %
Epoch 1535 of 2000 took 0.101s
  training loss:		0.267351
  validation loss:		0.384088
  validation accuracy:		89.89 %
Epoch 1536 of 2000 took 0.098s
  training loss:		0.265125
  validation loss:		0.381532
  validation accuracy:		88.91 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.267619
  validation loss:		0.380074
  validation accuracy:		89.67 %
Epoch 1538 of 2000 took 0.101s
  training loss:		0.273373
  validation loss:		0.384904
  validation accuracy:		90.43 %
Epoch 1539 of 2000 took 0.098s
  training loss:		0.270247
  validation loss:		0.383803
  validation accuracy:		89.78 %
Epoch 1540 of 2000 took 0.096s
  training loss:		0.265242
  validation loss:		0.378561
  validation accuracy:		89.89 %
Epoch 1541 of 2000 took 0.097s
  training loss:		0.269797
  validation loss:		0.393798
  validation accuracy:		89.24 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.269523
  validation loss:		0.403873
  validation accuracy:		88.70 %
Epoch 1543 of 2000 took 0.100s
  training loss:		0.273211
  validation loss:		0.394161
  validation accuracy:		89.57 %
Epoch 1544 of 2000 took 0.097s
  training loss:		0.273429
  validation loss:		0.399991
  validation accuracy:		89.13 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.264594
  validation loss:		0.380774
  validation accuracy:		89.89 %
Epoch 1546 of 2000 took 0.102s
  training loss:		0.275443
  validation loss:		0.378412
  validation accuracy:		90.11 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.270129
  validation loss:		0.389476
  validation accuracy:		89.13 %
Epoch 1548 of 2000 took 0.097s
  training loss:		0.270818
  validation loss:		0.385032
  validation accuracy:		89.57 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.270540
  validation loss:		0.402007
  validation accuracy:		89.13 %
Epoch 1550 of 2000 took 0.097s
  training loss:		0.269019
  validation loss:		0.384094
  validation accuracy:		89.24 %
Epoch 1551 of 2000 took 0.100s
  training loss:		0.278973
  validation loss:		0.384094
  validation accuracy:		90.00 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.269885
  validation loss:		0.383972
  validation accuracy:		89.57 %
Epoch 1553 of 2000 took 0.097s
  training loss:		0.268667
  validation loss:		0.421382
  validation accuracy:		88.37 %
Epoch 1554 of 2000 took 0.102s
  training loss:		0.267895
  validation loss:		0.385915
  validation accuracy:		90.11 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.270212
  validation loss:		0.393482
  validation accuracy:		89.78 %
Epoch 1556 of 2000 took 0.097s
  training loss:		0.262962
  validation loss:		0.382528
  validation accuracy:		90.22 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.260806
  validation loss:		0.383927
  validation accuracy:		89.57 %
Epoch 1558 of 2000 took 0.098s
  training loss:		0.269197
  validation loss:		0.395598
  validation accuracy:		89.35 %
Epoch 1559 of 2000 took 0.100s
  training loss:		0.274838
  validation loss:		0.390690
  validation accuracy:		89.46 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.269021
  validation loss:		0.401531
  validation accuracy:		89.46 %
Epoch 1561 of 2000 took 0.097s
  training loss:		0.269224
  validation loss:		0.400856
  validation accuracy:		88.80 %
Epoch 1562 of 2000 took 0.101s
  training loss:		0.266383
  validation loss:		0.384707
  validation accuracy:		89.46 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.276139
  validation loss:		0.383152
  validation accuracy:		89.78 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.272175
  validation loss:		0.384281
  validation accuracy:		90.00 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.274532
  validation loss:		0.389255
  validation accuracy:		89.67 %
Epoch 1566 of 2000 took 0.101s
  training loss:		0.274000
  validation loss:		0.381975
  validation accuracy:		89.67 %
Epoch 1567 of 2000 took 0.098s
  training loss:		0.270698
  validation loss:		0.390922
  validation accuracy:		89.67 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.260448
  validation loss:		0.391464
  validation accuracy:		89.57 %
Epoch 1569 of 2000 took 0.101s
  training loss:		0.269905
  validation loss:		0.382097
  validation accuracy:		90.00 %
Epoch 1570 of 2000 took 0.098s
  training loss:		0.268512
  validation loss:		0.398313
  validation accuracy:		89.24 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.267564
  validation loss:		0.388454
  validation accuracy:		89.46 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.269916
  validation loss:		0.392704
  validation accuracy:		89.46 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.273969
  validation loss:		0.388977
  validation accuracy:		89.78 %
Epoch 1574 of 2000 took 0.101s
  training loss:		0.262663
  validation loss:		0.389884
  validation accuracy:		89.78 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.270876
  validation loss:		0.383758
  validation accuracy:		90.00 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.264273
  validation loss:		0.413831
  validation accuracy:		88.59 %
Epoch 1577 of 2000 took 0.102s
  training loss:		0.274288
  validation loss:		0.389999
  validation accuracy:		89.89 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.269840
  validation loss:		0.379339
  validation accuracy:		89.46 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.275451
  validation loss:		0.387873
  validation accuracy:		89.89 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.266118
  validation loss:		0.426356
  validation accuracy:		88.70 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.271656
  validation loss:		0.388785
  validation accuracy:		89.78 %
Epoch 1582 of 2000 took 0.100s
  training loss:		0.268743
  validation loss:		0.400480
  validation accuracy:		89.13 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.269181
  validation loss:		0.400225
  validation accuracy:		89.67 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.260915
  validation loss:		0.399044
  validation accuracy:		89.78 %
Epoch 1585 of 2000 took 0.102s
  training loss:		0.262651
  validation loss:		0.385952
  validation accuracy:		90.00 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.268537
  validation loss:		0.398504
  validation accuracy:		89.13 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.268715
  validation loss:		0.389663
  validation accuracy:		89.78 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.272650
  validation loss:		0.390154
  validation accuracy:		90.00 %
Epoch 1589 of 2000 took 0.098s
  training loss:		0.272242
  validation loss:		0.383640
  validation accuracy:		90.00 %
Epoch 1590 of 2000 took 0.099s
  training loss:		0.273793
  validation loss:		0.435451
  validation accuracy:		88.70 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.272500
  validation loss:		0.388327
  validation accuracy:		89.78 %
Epoch 1592 of 2000 took 0.098s
  training loss:		0.271196
  validation loss:		0.391344
  validation accuracy:		89.78 %
Epoch 1593 of 2000 took 0.100s
  training loss:		0.268467
  validation loss:		0.377552
  validation accuracy:		90.33 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.273997
  validation loss:		0.381806
  validation accuracy:		89.78 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.273862
  validation loss:		0.403604
  validation accuracy:		89.24 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.279516
  validation loss:		0.395819
  validation accuracy:		89.67 %
Epoch 1597 of 2000 took 0.101s
  training loss:		0.262983
  validation loss:		0.398231
  validation accuracy:		89.78 %
Epoch 1598 of 2000 took 0.098s
  training loss:		0.267670
  validation loss:		0.398915
  validation accuracy:		89.24 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.271422
  validation loss:		0.379211
  validation accuracy:		90.54 %
Epoch 1600 of 2000 took 0.101s
  training loss:		0.270151
  validation loss:		0.384104
  validation accuracy:		90.00 %
Epoch 1601 of 2000 took 0.098s
  training loss:		0.269409
  validation loss:		0.393192
  validation accuracy:		90.11 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.263777
  validation loss:		0.410656
  validation accuracy:		88.91 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.272744
  validation loss:		0.386934
  validation accuracy:		89.89 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.264924
  validation loss:		0.388235
  validation accuracy:		89.67 %
Epoch 1605 of 2000 took 0.100s
  training loss:		0.264173
  validation loss:		0.390665
  validation accuracy:		89.78 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.263611
  validation loss:		0.390849
  validation accuracy:		89.46 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.269454
  validation loss:		0.413296
  validation accuracy:		88.70 %
Epoch 1608 of 2000 took 0.102s
  training loss:		0.271110
  validation loss:		0.395233
  validation accuracy:		89.67 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.269889
  validation loss:		0.405738
  validation accuracy:		89.35 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.261262
  validation loss:		0.394469
  validation accuracy:		89.24 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.262695
  validation loss:		0.393476
  validation accuracy:		90.00 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.274443
  validation loss:		0.392847
  validation accuracy:		89.78 %
Epoch 1613 of 2000 took 0.101s
  training loss:		0.271534
  validation loss:		0.389684
  validation accuracy:		90.11 %
Epoch 1614 of 2000 took 0.096s
  training loss:		0.260762
  validation loss:		0.389780
  validation accuracy:		89.78 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.264357
  validation loss:		0.386863
  validation accuracy:		89.89 %
Epoch 1616 of 2000 took 0.102s
  training loss:		0.269724
  validation loss:		0.405294
  validation accuracy:		89.13 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.269097
  validation loss:		0.401142
  validation accuracy:		89.02 %
Epoch 1618 of 2000 took 0.097s
  training loss:		0.268581
  validation loss:		0.380822
  validation accuracy:		90.00 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.270334
  validation loss:		0.393745
  validation accuracy:		90.22 %
Epoch 1620 of 2000 took 0.099s
  training loss:		0.264007
  validation loss:		0.385064
  validation accuracy:		89.78 %
Epoch 1621 of 2000 took 0.098s
  training loss:		0.272095
  validation loss:		0.404108
  validation accuracy:		89.46 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.272097
  validation loss:		0.390234
  validation accuracy:		90.00 %
Epoch 1623 of 2000 took 0.098s
  training loss:		0.266909
  validation loss:		0.422666
  validation accuracy:		88.80 %
Epoch 1624 of 2000 took 0.100s
  training loss:		0.270977
  validation loss:		0.386639
  validation accuracy:		89.78 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.258751
  validation loss:		0.393982
  validation accuracy:		89.89 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.261325
  validation loss:		0.388788
  validation accuracy:		89.35 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.262379
  validation loss:		0.382333
  validation accuracy:		90.00 %
Epoch 1628 of 2000 took 0.101s
  training loss:		0.268952
  validation loss:		0.392358
  validation accuracy:		89.57 %
Epoch 1629 of 2000 took 0.097s
  training loss:		0.271338
  validation loss:		0.405631
  validation accuracy:		89.67 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.264327
  validation loss:		0.390834
  validation accuracy:		89.67 %
Epoch 1631 of 2000 took 0.101s
  training loss:		0.275497
  validation loss:		0.398416
  validation accuracy:		89.02 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.276079
  validation loss:		0.386143
  validation accuracy:		89.78 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.273139
  validation loss:		0.395180
  validation accuracy:		89.46 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.271863
  validation loss:		0.398616
  validation accuracy:		89.02 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.271139
  validation loss:		0.393400
  validation accuracy:		89.89 %
Epoch 1636 of 2000 took 0.100s
  training loss:		0.276541
  validation loss:		0.386308
  validation accuracy:		89.24 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.271713
  validation loss:		0.392363
  validation accuracy:		89.57 %
Epoch 1638 of 2000 took 0.096s
  training loss:		0.270321
  validation loss:		0.390277
  validation accuracy:		90.00 %
Epoch 1639 of 2000 took 0.102s
  training loss:		0.265172
  validation loss:		0.400067
  validation accuracy:		89.24 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.273969
  validation loss:		0.389483
  validation accuracy:		89.67 %
Epoch 1641 of 2000 took 0.097s
  training loss:		0.267258
  validation loss:		0.400322
  validation accuracy:		89.13 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.268665
  validation loss:		0.398129
  validation accuracy:		89.46 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.267816
  validation loss:		0.397060
  validation accuracy:		89.67 %
Epoch 1644 of 2000 took 0.100s
  training loss:		0.275523
  validation loss:		0.403477
  validation accuracy:		89.24 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.263954
  validation loss:		0.387609
  validation accuracy:		89.67 %
Epoch 1646 of 2000 took 0.097s
  training loss:		0.265373
  validation loss:		0.395137
  validation accuracy:		89.24 %
Epoch 1647 of 2000 took 0.102s
  training loss:		0.259188
  validation loss:		0.394630
  validation accuracy:		90.00 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.266840
  validation loss:		0.383839
  validation accuracy:		89.89 %
Epoch 1649 of 2000 took 0.097s
  training loss:		0.263462
  validation loss:		0.390803
  validation accuracy:		89.67 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.266489
  validation loss:		0.383242
  validation accuracy:		89.89 %
Epoch 1651 of 2000 took 0.099s
  training loss:		0.264834
  validation loss:		0.405712
  validation accuracy:		89.13 %
Epoch 1652 of 2000 took 0.099s
  training loss:		0.263336
  validation loss:		0.406978
  validation accuracy:		89.89 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.270616
  validation loss:		0.406396
  validation accuracy:		89.13 %
Epoch 1654 of 2000 took 0.098s
  training loss:		0.265008
  validation loss:		0.386508
  validation accuracy:		89.78 %
Epoch 1655 of 2000 took 0.100s
  training loss:		0.269047
  validation loss:		0.419156
  validation accuracy:		88.70 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.265570
  validation loss:		0.390851
  validation accuracy:		90.00 %
Epoch 1657 of 2000 took 0.097s
  training loss:		0.266841
  validation loss:		0.423610
  validation accuracy:		88.48 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.275033
  validation loss:		0.386914
  validation accuracy:		90.00 %
Epoch 1659 of 2000 took 0.101s
  training loss:		0.271095
  validation loss:		0.412626
  validation accuracy:		89.02 %
Epoch 1660 of 2000 took 0.098s
  training loss:		0.264302
  validation loss:		0.406578
  validation accuracy:		89.13 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.268283
  validation loss:		0.396095
  validation accuracy:		89.46 %
Epoch 1662 of 2000 took 0.102s
  training loss:		0.270541
  validation loss:		0.395611
  validation accuracy:		89.35 %
Epoch 1663 of 2000 took 0.100s
  training loss:		0.269527
  validation loss:		0.400944
  validation accuracy:		89.35 %
Epoch 1664 of 2000 took 0.098s
  training loss:		0.264015
  validation loss:		0.386445
  validation accuracy:		90.11 %
Epoch 1665 of 2000 took 0.097s
  training loss:		0.268200
  validation loss:		0.391897
  validation accuracy:		89.57 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.265842
  validation loss:		0.400907
  validation accuracy:		89.57 %
Epoch 1667 of 2000 took 0.100s
  training loss:		0.264970
  validation loss:		0.392949
  validation accuracy:		89.46 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.264554
  validation loss:		0.396301
  validation accuracy:		89.67 %
Epoch 1669 of 2000 took 0.097s
  training loss:		0.267963
  validation loss:		0.398826
  validation accuracy:		88.70 %
Epoch 1670 of 2000 took 0.102s
  training loss:		0.277479
  validation loss:		0.412351
  validation accuracy:		89.02 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.267324
  validation loss:		0.394261
  validation accuracy:		89.89 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.268595
  validation loss:		0.415250
  validation accuracy:		89.13 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.266172
  validation loss:		0.395901
  validation accuracy:		88.48 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.274463
  validation loss:		0.404845
  validation accuracy:		89.57 %
Epoch 1675 of 2000 took 0.101s
  training loss:		0.264654
  validation loss:		0.391818
  validation accuracy:		89.89 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.268547
  validation loss:		0.388355
  validation accuracy:		90.43 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.274741
  validation loss:		0.394410
  validation accuracy:		89.57 %
Epoch 1678 of 2000 took 0.103s
  training loss:		0.267886
  validation loss:		0.387745
  validation accuracy:		89.89 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.267921
  validation loss:		0.415273
  validation accuracy:		88.70 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.269234
  validation loss:		0.395379
  validation accuracy:		89.02 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.270138
  validation loss:		0.416061
  validation accuracy:		88.80 %
Epoch 1682 of 2000 took 0.099s
  training loss:		0.274657
  validation loss:		0.385211
  validation accuracy:		90.65 %
Epoch 1683 of 2000 took 0.098s
  training loss:		0.268088
  validation loss:		0.385504
  validation accuracy:		90.22 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.276044
  validation loss:		0.388449
  validation accuracy:		90.43 %
Epoch 1685 of 2000 took 0.099s
  training loss:		0.261692
  validation loss:		0.406716
  validation accuracy:		89.13 %
Epoch 1686 of 2000 took 0.100s
  training loss:		0.266712
  validation loss:		0.388060
  validation accuracy:		90.22 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.260514
  validation loss:		0.398204
  validation accuracy:		89.57 %
Epoch 1688 of 2000 took 0.097s
  training loss:		0.269613
  validation loss:		0.415250
  validation accuracy:		89.24 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.270062
  validation loss:		0.405111
  validation accuracy:		89.35 %
Epoch 1690 of 2000 took 0.101s
  training loss:		0.264906
  validation loss:		0.411608
  validation accuracy:		89.24 %
Epoch 1691 of 2000 took 0.097s
  training loss:		0.257938
  validation loss:		0.417480
  validation accuracy:		88.70 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.268717
  validation loss:		0.392553
  validation accuracy:		90.00 %
Epoch 1693 of 2000 took 0.102s
  training loss:		0.268975
  validation loss:		0.402185
  validation accuracy:		89.89 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.273057
  validation loss:		0.407260
  validation accuracy:		88.91 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.264843
  validation loss:		0.397746
  validation accuracy:		89.57 %
Epoch 1696 of 2000 took 0.097s
  training loss:		0.265136
  validation loss:		0.387638
  validation accuracy:		90.11 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.267454
  validation loss:		0.397061
  validation accuracy:		89.35 %
Epoch 1698 of 2000 took 0.100s
  training loss:		0.266951
  validation loss:		0.400056
  validation accuracy:		89.67 %
Epoch 1699 of 2000 took 0.097s
  training loss:		0.269538
  validation loss:		0.401586
  validation accuracy:		89.24 %
Epoch 1700 of 2000 took 0.096s
  training loss:		0.259777
  validation loss:		0.390157
  validation accuracy:		89.89 %
Epoch 1701 of 2000 took 0.102s
  training loss:		0.267820
  validation loss:		0.406209
  validation accuracy:		89.46 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.267268
  validation loss:		0.394776
  validation accuracy:		89.57 %
Epoch 1703 of 2000 took 0.097s
  training loss:		0.272292
  validation loss:		0.395876
  validation accuracy:		90.22 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.273083
  validation loss:		0.396607
  validation accuracy:		89.13 %
Epoch 1705 of 2000 took 0.098s
  training loss:		0.263583
  validation loss:		0.387038
  validation accuracy:		90.54 %
Epoch 1706 of 2000 took 0.100s
  training loss:		0.273361
  validation loss:		0.394371
  validation accuracy:		90.00 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.271030
  validation loss:		0.424626
  validation accuracy:		88.59 %
Epoch 1708 of 2000 took 0.097s
  training loss:		0.261118
  validation loss:		0.392772
  validation accuracy:		89.57 %
Epoch 1709 of 2000 took 0.102s
  training loss:		0.263208
  validation loss:		0.413490
  validation accuracy:		89.02 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.266008
  validation loss:		0.406263
  validation accuracy:		89.24 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.258592
  validation loss:		0.407956
  validation accuracy:		88.91 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.268546
  validation loss:		0.400916
  validation accuracy:		89.24 %
Epoch 1713 of 2000 took 0.099s
  training loss:		0.268794
  validation loss:		0.388630
  validation accuracy:		89.78 %
Epoch 1714 of 2000 took 0.098s
  training loss:		0.269224
  validation loss:		0.393883
  validation accuracy:		89.46 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.272851
  validation loss:		0.392864
  validation accuracy:		90.11 %
Epoch 1716 of 2000 took 0.099s
  training loss:		0.270502
  validation loss:		0.394395
  validation accuracy:		89.46 %
Epoch 1717 of 2000 took 0.099s
  training loss:		0.259443
  validation loss:		0.408751
  validation accuracy:		88.59 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.262079
  validation loss:		0.401543
  validation accuracy:		89.57 %
Epoch 1719 of 2000 took 0.097s
  training loss:		0.267481
  validation loss:		0.408591
  validation accuracy:		89.35 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.263045
  validation loss:		0.394404
  validation accuracy:		89.78 %
Epoch 1721 of 2000 took 0.101s
  training loss:		0.258188
  validation loss:		0.402540
  validation accuracy:		89.46 %
Epoch 1722 of 2000 took 0.097s
  training loss:		0.262308
  validation loss:		0.385642
  validation accuracy:		89.67 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.257569
  validation loss:		0.395050
  validation accuracy:		90.22 %
Epoch 1724 of 2000 took 0.102s
  training loss:		0.266119
  validation loss:		0.392522
  validation accuracy:		89.89 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.267243
  validation loss:		0.397173
  validation accuracy:		89.24 %
Epoch 1726 of 2000 took 0.097s
  training loss:		0.261033
  validation loss:		0.393577
  validation accuracy:		90.22 %
Epoch 1727 of 2000 took 0.096s
  training loss:		0.270245
  validation loss:		0.399851
  validation accuracy:		89.35 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.263158
  validation loss:		0.403949
  validation accuracy:		89.46 %
Epoch 1729 of 2000 took 0.100s
  training loss:		0.264790
  validation loss:		0.401426
  validation accuracy:		89.35 %
Epoch 1730 of 2000 took 0.097s
  training loss:		0.265450
  validation loss:		0.392216
  validation accuracy:		89.89 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.265422
  validation loss:		0.391083
  validation accuracy:		89.67 %
Epoch 1732 of 2000 took 0.102s
  training loss:		0.269552
  validation loss:		0.401346
  validation accuracy:		89.24 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.270638
  validation loss:		0.425787
  validation accuracy:		88.48 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.257122
  validation loss:		0.388898
  validation accuracy:		90.54 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.263789
  validation loss:		0.392604
  validation accuracy:		89.57 %
Epoch 1736 of 2000 took 0.098s
  training loss:		0.266307
  validation loss:		0.399201
  validation accuracy:		89.57 %
Epoch 1737 of 2000 took 0.100s
  training loss:		0.258928
  validation loss:		0.387840
  validation accuracy:		90.33 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.264578
  validation loss:		0.407074
  validation accuracy:		89.13 %
Epoch 1739 of 2000 took 0.097s
  training loss:		0.266403
  validation loss:		0.393688
  validation accuracy:		89.24 %
Epoch 1740 of 2000 took 0.102s
  training loss:		0.265259
  validation loss:		0.438082
  validation accuracy:		88.37 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.269499
  validation loss:		0.386002
  validation accuracy:		90.65 %
Epoch 1742 of 2000 took 0.097s
  training loss:		0.266870
  validation loss:		0.393292
  validation accuracy:		89.57 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.267053
  validation loss:		0.415283
  validation accuracy:		88.80 %
Epoch 1744 of 2000 took 0.100s
  training loss:		0.260562
  validation loss:		0.401149
  validation accuracy:		90.33 %
Epoch 1745 of 2000 took 0.098s
  training loss:		0.268975
  validation loss:		0.388591
  validation accuracy:		89.67 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.261810
  validation loss:		0.401248
  validation accuracy:		89.46 %
Epoch 1747 of 2000 took 0.100s
  training loss:		0.270412
  validation loss:		0.389101
  validation accuracy:		89.89 %
Epoch 1748 of 2000 took 0.098s
  training loss:		0.267195
  validation loss:		0.408357
  validation accuracy:		89.46 %
Epoch 1749 of 2000 took 0.096s
  training loss:		0.265127
  validation loss:		0.400153
  validation accuracy:		89.67 %
Epoch 1750 of 2000 took 0.097s
  training loss:		0.268313
  validation loss:		0.397353
  validation accuracy:		89.67 %
Epoch 1751 of 2000 took 0.097s
  training loss:		0.263186
  validation loss:		0.397701
  validation accuracy:		89.67 %
Epoch 1752 of 2000 took 0.100s
  training loss:		0.262774
  validation loss:		0.403315
  validation accuracy:		89.67 %
Epoch 1753 of 2000 took 0.097s
  training loss:		0.266191
  validation loss:		0.392055
  validation accuracy:		89.57 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.268521
  validation loss:		0.387233
  validation accuracy:		90.33 %
Epoch 1755 of 2000 took 0.102s
  training loss:		0.256807
  validation loss:		0.408928
  validation accuracy:		89.24 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.266315
  validation loss:		0.406958
  validation accuracy:		89.13 %
Epoch 1757 of 2000 took 0.097s
  training loss:		0.265827
  validation loss:		0.404575
  validation accuracy:		89.13 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.264317
  validation loss:		0.389651
  validation accuracy:		90.00 %
Epoch 1759 of 2000 took 0.097s
  training loss:		0.268477
  validation loss:		0.438919
  validation accuracy:		88.04 %
Epoch 1760 of 2000 took 0.100s
  training loss:		0.266798
  validation loss:		0.408013
  validation accuracy:		89.24 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.265666
  validation loss:		0.410126
  validation accuracy:		89.02 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.266768
  validation loss:		0.451431
  validation accuracy:		87.83 %
Epoch 1763 of 2000 took 0.102s
  training loss:		0.271405
  validation loss:		0.409070
  validation accuracy:		89.13 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.264966
  validation loss:		0.415108
  validation accuracy:		88.91 %
Epoch 1765 of 2000 took 0.099s
  training loss:		0.264322
  validation loss:		0.389087
  validation accuracy:		89.67 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.262162
  validation loss:		0.401213
  validation accuracy:		89.78 %
Epoch 1767 of 2000 took 0.099s
  training loss:		0.272118
  validation loss:		0.405933
  validation accuracy:		89.57 %
Epoch 1768 of 2000 took 0.098s
  training loss:		0.261749
  validation loss:		0.403114
  validation accuracy:		89.24 %
Epoch 1769 of 2000 took 0.096s
  training loss:		0.266103
  validation loss:		0.386610
  validation accuracy:		89.67 %
Epoch 1770 of 2000 took 0.098s
  training loss:		0.263711
  validation loss:		0.392992
  validation accuracy:		89.89 %
Epoch 1771 of 2000 took 0.100s
  training loss:		0.271463
  validation loss:		0.391687
  validation accuracy:		89.78 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.264352
  validation loss:		0.389933
  validation accuracy:		89.24 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.267042
  validation loss:		0.397269
  validation accuracy:		89.35 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.261321
  validation loss:		0.385970
  validation accuracy:		90.11 %
Epoch 1775 of 2000 took 0.101s
  training loss:		0.259220
  validation loss:		0.400653
  validation accuracy:		89.89 %
Epoch 1776 of 2000 took 0.097s
  training loss:		0.266111
  validation loss:		0.394262
  validation accuracy:		90.11 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.263645
  validation loss:		0.394874
  validation accuracy:		90.33 %
Epoch 1778 of 2000 took 0.101s
  training loss:		0.277356
  validation loss:		0.396391
  validation accuracy:		89.35 %
Epoch 1779 of 2000 took 0.097s
  training loss:		0.266656
  validation loss:		0.412605
  validation accuracy:		88.80 %
Epoch 1780 of 2000 took 0.097s
  training loss:		0.271943
  validation loss:		0.393848
  validation accuracy:		90.00 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.269429
  validation loss:		0.394487
  validation accuracy:		89.78 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.269902
  validation loss:		0.396520
  validation accuracy:		88.80 %
Epoch 1783 of 2000 took 0.100s
  training loss:		0.269494
  validation loss:		0.419638
  validation accuracy:		88.70 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.269399
  validation loss:		0.387593
  validation accuracy:		89.89 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.268771
  validation loss:		0.426554
  validation accuracy:		88.59 %
Epoch 1786 of 2000 took 0.102s
  training loss:		0.267413
  validation loss:		0.400283
  validation accuracy:		89.46 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.260507
  validation loss:		0.398858
  validation accuracy:		89.89 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.265800
  validation loss:		0.401167
  validation accuracy:		89.35 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.267231
  validation loss:		0.408003
  validation accuracy:		89.24 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.269801
  validation loss:		0.406360
  validation accuracy:		89.24 %
Epoch 1791 of 2000 took 0.100s
  training loss:		0.263975
  validation loss:		0.391998
  validation accuracy:		90.33 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.260712
  validation loss:		0.395014
  validation accuracy:		89.89 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.262892
  validation loss:		0.406213
  validation accuracy:		88.70 %
Epoch 1794 of 2000 took 0.102s
  training loss:		0.257223
  validation loss:		0.406576
  validation accuracy:		89.57 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.267065
  validation loss:		0.386401
  validation accuracy:		90.00 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.262802
  validation loss:		0.395463
  validation accuracy:		89.67 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.267302
  validation loss:		0.399710
  validation accuracy:		89.78 %
Epoch 1798 of 2000 took 0.098s
  training loss:		0.262808
  validation loss:		0.407145
  validation accuracy:		88.91 %
Epoch 1799 of 2000 took 0.099s
  training loss:		0.262536
  validation loss:		0.401319
  validation accuracy:		89.24 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.258340
  validation loss:		0.412742
  validation accuracy:		89.13 %
Epoch 1801 of 2000 took 0.098s
  training loss:		0.266705
  validation loss:		0.392753
  validation accuracy:		89.67 %
Epoch 1802 of 2000 took 0.101s
  training loss:		0.266271
  validation loss:		0.390589
  validation accuracy:		90.22 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.266117
  validation loss:		0.389560
  validation accuracy:		90.43 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.258888
  validation loss:		0.404995
  validation accuracy:		89.24 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.264794
  validation loss:		0.399365
  validation accuracy:		89.35 %
Epoch 1806 of 2000 took 0.101s
  training loss:		0.265891
  validation loss:		0.392124
  validation accuracy:		89.78 %
Epoch 1807 of 2000 took 0.098s
  training loss:		0.270838
  validation loss:		0.407946
  validation accuracy:		89.24 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.269942
  validation loss:		0.399891
  validation accuracy:		89.78 %
Epoch 1809 of 2000 took 0.101s
  training loss:		0.261052
  validation loss:		0.395074
  validation accuracy:		89.57 %
Epoch 1810 of 2000 took 0.095s
  training loss:		0.267479
  validation loss:		0.412390
  validation accuracy:		89.02 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.265382
  validation loss:		0.418483
  validation accuracy:		88.70 %
Epoch 1812 of 2000 took 0.098s
  training loss:		0.261917
  validation loss:		0.405841
  validation accuracy:		89.46 %
Epoch 1813 of 2000 took 0.095s
  training loss:		0.263072
  validation loss:		0.397002
  validation accuracy:		90.11 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.264311
  validation loss:		0.397316
  validation accuracy:		89.78 %
Epoch 1815 of 2000 took 0.095s
  training loss:		0.268821
  validation loss:		0.416170
  validation accuracy:		88.48 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.269447
  validation loss:		0.403749
  validation accuracy:		89.35 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.266115
  validation loss:		0.394951
  validation accuracy:		90.22 %
Epoch 1818 of 2000 took 0.095s
  training loss:		0.268157
  validation loss:		0.405997
  validation accuracy:		89.46 %
Epoch 1819 of 2000 took 0.099s
  training loss:		0.271390
  validation loss:		0.398684
  validation accuracy:		89.35 %
Epoch 1820 of 2000 took 0.095s
  training loss:		0.261922
  validation loss:		0.387405
  validation accuracy:		90.54 %
Epoch 1821 of 2000 took 0.098s
  training loss:		0.265123
  validation loss:		0.394045
  validation accuracy:		89.13 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.267603
  validation loss:		0.400357
  validation accuracy:		89.46 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.261465
  validation loss:		0.400486
  validation accuracy:		89.46 %
Epoch 1824 of 2000 took 0.099s
  training loss:		0.267814
  validation loss:		0.413615
  validation accuracy:		89.35 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.259660
  validation loss:		0.396165
  validation accuracy:		89.02 %
Epoch 1826 of 2000 took 0.100s
  training loss:		0.256827
  validation loss:		0.402439
  validation accuracy:		89.57 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.260576
  validation loss:		0.404800
  validation accuracy:		89.46 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.266423
  validation loss:		0.392899
  validation accuracy:		89.89 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.268985
  validation loss:		0.389148
  validation accuracy:		90.11 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.265524
  validation loss:		0.398709
  validation accuracy:		89.35 %
Epoch 1831 of 2000 took 0.099s
  training loss:		0.265199
  validation loss:		0.407913
  validation accuracy:		89.13 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.265631
  validation loss:		0.407325
  validation accuracy:		88.70 %
Epoch 1833 of 2000 took 0.098s
  training loss:		0.266551
  validation loss:		0.409990
  validation accuracy:		89.24 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.258303
  validation loss:		0.406596
  validation accuracy:		89.24 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.274700
  validation loss:		0.396531
  validation accuracy:		89.57 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.265002
  validation loss:		0.392306
  validation accuracy:		89.67 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.266703
  validation loss:		0.390550
  validation accuracy:		89.57 %
Epoch 1838 of 2000 took 0.100s
  training loss:		0.260369
  validation loss:		0.419761
  validation accuracy:		89.13 %
Epoch 1839 of 2000 took 0.098s
  training loss:		0.266344
  validation loss:		0.390377
  validation accuracy:		90.11 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.259700
  validation loss:		0.388676
  validation accuracy:		90.00 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.263606
  validation loss:		0.392012
  validation accuracy:		90.22 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.267636
  validation loss:		0.409807
  validation accuracy:		89.02 %
Epoch 1843 of 2000 took 0.101s
  training loss:		0.266642
  validation loss:		0.397880
  validation accuracy:		89.57 %
Epoch 1844 of 2000 took 0.097s
  training loss:		0.260760
  validation loss:		0.394025
  validation accuracy:		89.35 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.276042
  validation loss:		0.389122
  validation accuracy:		90.00 %
Epoch 1846 of 2000 took 0.102s
  training loss:		0.255590
  validation loss:		0.397560
  validation accuracy:		89.57 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.266659
  validation loss:		0.417334
  validation accuracy:		89.13 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.268145
  validation loss:		0.396546
  validation accuracy:		88.91 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.264428
  validation loss:		0.392989
  validation accuracy:		89.78 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.260922
  validation loss:		0.398647
  validation accuracy:		89.57 %
Epoch 1851 of 2000 took 0.100s
  training loss:		0.260505
  validation loss:		0.416032
  validation accuracy:		89.02 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.266068
  validation loss:		0.406184
  validation accuracy:		88.91 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.266146
  validation loss:		0.394074
  validation accuracy:		89.67 %
Epoch 1854 of 2000 took 0.102s
  training loss:		0.265564
  validation loss:		0.405902
  validation accuracy:		89.02 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.264601
  validation loss:		0.402724
  validation accuracy:		89.35 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.263640
  validation loss:		0.403226
  validation accuracy:		89.46 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.264896
  validation loss:		0.416937
  validation accuracy:		89.13 %
Epoch 1858 of 2000 took 0.098s
  training loss:		0.265237
  validation loss:		0.390363
  validation accuracy:		90.00 %
Epoch 1859 of 2000 took 0.099s
  training loss:		0.262899
  validation loss:		0.400857
  validation accuracy:		89.57 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.265098
  validation loss:		0.408558
  validation accuracy:		89.24 %
Epoch 1861 of 2000 took 0.098s
  training loss:		0.263537
  validation loss:		0.415448
  validation accuracy:		88.91 %
Epoch 1862 of 2000 took 0.100s
  training loss:		0.261867
  validation loss:		0.389062
  validation accuracy:		89.67 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.266678
  validation loss:		0.396850
  validation accuracy:		89.24 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.258923
  validation loss:		0.395267
  validation accuracy:		90.00 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.263722
  validation loss:		0.410559
  validation accuracy:		89.89 %
Epoch 1866 of 2000 took 0.101s
  training loss:		0.272155
  validation loss:		0.422762
  validation accuracy:		88.80 %
Epoch 1867 of 2000 took 0.098s
  training loss:		0.265214
  validation loss:		0.396548
  validation accuracy:		89.89 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.268197
  validation loss:		0.398996
  validation accuracy:		90.11 %
Epoch 1869 of 2000 took 0.101s
  training loss:		0.266642
  validation loss:		0.396108
  validation accuracy:		89.67 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.263003
  validation loss:		0.403063
  validation accuracy:		89.67 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.267088
  validation loss:		0.389265
  validation accuracy:		90.33 %
Epoch 1872 of 2000 took 0.097s
  training loss:		0.268700
  validation loss:		0.385192
  validation accuracy:		90.11 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.270265
  validation loss:		0.411387
  validation accuracy:		89.89 %
Epoch 1874 of 2000 took 0.100s
  training loss:		0.269471
  validation loss:		0.410219
  validation accuracy:		89.24 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.265049
  validation loss:		0.406767
  validation accuracy:		88.91 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.263080
  validation loss:		0.412267
  validation accuracy:		89.35 %
Epoch 1877 of 2000 took 0.102s
  training loss:		0.265411
  validation loss:		0.388557
  validation accuracy:		89.67 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.257043
  validation loss:		0.404344
  validation accuracy:		89.67 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.267309
  validation loss:		0.411557
  validation accuracy:		89.02 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.257636
  validation loss:		0.393315
  validation accuracy:		89.89 %
Epoch 1881 of 2000 took 0.098s
  training loss:		0.268328
  validation loss:		0.415458
  validation accuracy:		89.89 %
Epoch 1882 of 2000 took 0.100s
  training loss:		0.268002
  validation loss:		0.418065
  validation accuracy:		89.02 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.261929
  validation loss:		0.402878
  validation accuracy:		89.35 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.257370
  validation loss:		0.405592
  validation accuracy:		89.57 %
Epoch 1885 of 2000 took 0.102s
  training loss:		0.268956
  validation loss:		0.402685
  validation accuracy:		89.46 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.264475
  validation loss:		0.415465
  validation accuracy:		89.46 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.255753
  validation loss:		0.405078
  validation accuracy:		89.46 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.264188
  validation loss:		0.406242
  validation accuracy:		89.57 %
Epoch 1889 of 2000 took 0.099s
  training loss:		0.266368
  validation loss:		0.406608
  validation accuracy:		89.24 %
Epoch 1890 of 2000 took 0.098s
  training loss:		0.260247
  validation loss:		0.395781
  validation accuracy:		90.00 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.272560
  validation loss:		0.395234
  validation accuracy:		89.67 %
Epoch 1892 of 2000 took 0.099s
  training loss:		0.261576
  validation loss:		0.404956
  validation accuracy:		89.13 %
Epoch 1893 of 2000 took 0.099s
  training loss:		0.265667
  validation loss:		0.408219
  validation accuracy:		89.13 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.259711
  validation loss:		0.403393
  validation accuracy:		89.13 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.268630
  validation loss:		0.408903
  validation accuracy:		89.13 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.262868
  validation loss:		0.411673
  validation accuracy:		89.13 %
Epoch 1897 of 2000 took 0.101s
  training loss:		0.275023
  validation loss:		0.399182
  validation accuracy:		89.89 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.260411
  validation loss:		0.403243
  validation accuracy:		89.24 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.260863
  validation loss:		0.394333
  validation accuracy:		90.65 %
Epoch 1900 of 2000 took 0.102s
  training loss:		0.269105
  validation loss:		0.409872
  validation accuracy:		89.57 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.266255
  validation loss:		0.401137
  validation accuracy:		89.67 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.274107
  validation loss:		0.415171
  validation accuracy:		89.24 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.265107
  validation loss:		0.450165
  validation accuracy:		87.93 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.265107
  validation loss:		0.394367
  validation accuracy:		90.33 %
Epoch 1905 of 2000 took 0.100s
  training loss:		0.261422
  validation loss:		0.397495
  validation accuracy:		89.35 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.264840
  validation loss:		0.386121
  validation accuracy:		90.54 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.267632
  validation loss:		0.400413
  validation accuracy:		89.67 %
Epoch 1908 of 2000 took 0.102s
  training loss:		0.256470
  validation loss:		0.405646
  validation accuracy:		89.57 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.267239
  validation loss:		0.400422
  validation accuracy:		89.67 %
Epoch 1910 of 2000 took 0.097s
  training loss:		0.269168
  validation loss:		0.396220
  validation accuracy:		90.00 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.273973
  validation loss:		0.422398
  validation accuracy:		88.37 %
Epoch 1912 of 2000 took 0.099s
  training loss:		0.261215
  validation loss:		0.420196
  validation accuracy:		88.80 %
Epoch 1913 of 2000 took 0.099s
  training loss:		0.264473
  validation loss:		0.412694
  validation accuracy:		89.02 %
Epoch 1914 of 2000 took 0.095s
  training loss:		0.260266
  validation loss:		0.392831
  validation accuracy:		90.11 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.261877
  validation loss:		0.402620
  validation accuracy:		89.35 %
Epoch 1916 of 2000 took 0.101s
  training loss:		0.254819
  validation loss:		0.401769
  validation accuracy:		89.35 %
Epoch 1917 of 2000 took 0.095s
  training loss:		0.265009
  validation loss:		0.395065
  validation accuracy:		89.13 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.263034
  validation loss:		0.404008
  validation accuracy:		89.46 %
Epoch 1919 of 2000 took 0.095s
  training loss:		0.262142
  validation loss:		0.409420
  validation accuracy:		89.24 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.263907
  validation loss:		0.415898
  validation accuracy:		88.80 %
Epoch 1921 of 2000 took 0.098s
  training loss:		0.262014
  validation loss:		0.398359
  validation accuracy:		89.57 %
Epoch 1922 of 2000 took 0.095s
  training loss:		0.265407
  validation loss:		0.393397
  validation accuracy:		89.89 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.258704
  validation loss:		0.390203
  validation accuracy:		89.78 %
Epoch 1924 of 2000 took 0.100s
  training loss:		0.264622
  validation loss:		0.410839
  validation accuracy:		90.11 %
Epoch 1925 of 2000 took 0.095s
  training loss:		0.264049
  validation loss:		0.412737
  validation accuracy:		89.13 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.261280
  validation loss:		0.395901
  validation accuracy:		89.89 %
Epoch 1927 of 2000 took 0.095s
  training loss:		0.265606
  validation loss:		0.409109
  validation accuracy:		89.24 %
Epoch 1928 of 2000 took 0.099s
  training loss:		0.267875
  validation loss:		0.399852
  validation accuracy:		90.00 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.267344
  validation loss:		0.432261
  validation accuracy:		88.59 %
Epoch 1930 of 2000 took 0.095s
  training loss:		0.271367
  validation loss:		0.412707
  validation accuracy:		88.80 %
Epoch 1931 of 2000 took 0.098s
  training loss:		0.261101
  validation loss:		0.413807
  validation accuracy:		89.24 %
Epoch 1932 of 2000 took 0.097s
  training loss:		0.260036
  validation loss:		0.398760
  validation accuracy:		89.67 %
Epoch 1933 of 2000 took 0.095s
  training loss:		0.268784
  validation loss:		0.415138
  validation accuracy:		89.35 %
Epoch 1934 of 2000 took 0.095s
  training loss:		0.264497
  validation loss:		0.407411
  validation accuracy:		89.24 %
Epoch 1935 of 2000 took 0.095s
  training loss:		0.269576
  validation loss:		0.395493
  validation accuracy:		89.57 %
Epoch 1936 of 2000 took 0.100s
  training loss:		0.266888
  validation loss:		0.426392
  validation accuracy:		88.37 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.268720
  validation loss:		0.405004
  validation accuracy:		89.35 %
Epoch 1938 of 2000 took 0.095s
  training loss:		0.266391
  validation loss:		0.427586
  validation accuracy:		88.59 %
Epoch 1939 of 2000 took 0.100s
  training loss:		0.262742
  validation loss:		0.393852
  validation accuracy:		89.89 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.258241
  validation loss:		0.428190
  validation accuracy:		88.91 %
Epoch 1941 of 2000 took 0.095s
  training loss:		0.264120
  validation loss:		0.399534
  validation accuracy:		90.65 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.260136
  validation loss:		0.406210
  validation accuracy:		89.35 %
Epoch 1943 of 2000 took 0.095s
  training loss:		0.258059
  validation loss:		0.402450
  validation accuracy:		89.78 %
Epoch 1944 of 2000 took 0.099s
  training loss:		0.267138
  validation loss:		0.401421
  validation accuracy:		89.35 %
Epoch 1945 of 2000 took 0.100s
  training loss:		0.254653
  validation loss:		0.413527
  validation accuracy:		89.35 %
Epoch 1946 of 2000 took 0.099s
  training loss:		0.263878
  validation loss:		0.414983
  validation accuracy:		89.02 %
Epoch 1947 of 2000 took 0.105s
  training loss:		0.255685
  validation loss:		0.425587
  validation accuracy:		88.80 %
Epoch 1948 of 2000 took 0.099s
  training loss:		0.262782
  validation loss:		0.399531
  validation accuracy:		89.46 %
Epoch 1949 of 2000 took 0.100s
  training loss:		0.267637
  validation loss:		0.400797
  validation accuracy:		89.78 %
Epoch 1950 of 2000 took 0.099s
  training loss:		0.265269
  validation loss:		0.424604
  validation accuracy:		88.37 %
Epoch 1951 of 2000 took 0.100s
  training loss:		0.270081
  validation loss:		0.401710
  validation accuracy:		89.35 %
Epoch 1952 of 2000 took 0.103s
  training loss:		0.260419
  validation loss:		0.400488
  validation accuracy:		89.35 %
Epoch 1953 of 2000 took 0.099s
  training loss:		0.253588
  validation loss:		0.401522
  validation accuracy:		89.35 %
Epoch 1954 of 2000 took 0.100s
  training loss:		0.265047
  validation loss:		0.408509
  validation accuracy:		89.13 %
Epoch 1955 of 2000 took 0.105s
  training loss:		0.259665
  validation loss:		0.395027
  validation accuracy:		89.24 %
Epoch 1956 of 2000 took 0.099s
  training loss:		0.265332
  validation loss:		0.396298
  validation accuracy:		89.78 %
Epoch 1957 of 2000 took 0.100s
  training loss:		0.259369
  validation loss:		0.416967
  validation accuracy:		89.13 %
Epoch 1958 of 2000 took 0.099s
  training loss:		0.268904
  validation loss:		0.408449
  validation accuracy:		89.57 %
Epoch 1959 of 2000 took 0.101s
  training loss:		0.267811
  validation loss:		0.396257
  validation accuracy:		89.57 %
Epoch 1960 of 2000 took 0.102s
  training loss:		0.253590
  validation loss:		0.422545
  validation accuracy:		89.02 %
Epoch 1961 of 2000 took 0.099s
  training loss:		0.258777
  validation loss:		0.404699
  validation accuracy:		90.00 %
Epoch 1962 of 2000 took 0.100s
  training loss:		0.264592
  validation loss:		0.398183
  validation accuracy:		89.13 %
Epoch 1963 of 2000 took 0.104s
  training loss:		0.261530
  validation loss:		0.391713
  validation accuracy:		89.89 %
Epoch 1964 of 2000 took 0.099s
  training loss:		0.265545
  validation loss:		0.401417
  validation accuracy:		89.35 %
Epoch 1965 of 2000 took 0.100s
  training loss:		0.264450
  validation loss:		0.402164
  validation accuracy:		89.67 %
Epoch 1966 of 2000 took 0.099s
  training loss:		0.259912
  validation loss:		0.394617
  validation accuracy:		89.78 %
Epoch 1967 of 2000 took 0.103s
  training loss:		0.260846
  validation loss:		0.407072
  validation accuracy:		89.13 %
Epoch 1968 of 2000 took 0.100s
  training loss:		0.259699
  validation loss:		0.398456
  validation accuracy:		89.35 %
Epoch 1969 of 2000 took 0.099s
  training loss:		0.259397
  validation loss:		0.403761
  validation accuracy:		89.57 %
Epoch 1970 of 2000 took 0.103s
  training loss:		0.258344
  validation loss:		0.409859
  validation accuracy:		89.02 %
Epoch 1971 of 2000 took 0.101s
  training loss:		0.263427
  validation loss:		0.400547
  validation accuracy:		89.35 %
Epoch 1972 of 2000 took 0.099s
  training loss:		0.257378
  validation loss:		0.411224
  validation accuracy:		88.91 %
Epoch 1973 of 2000 took 0.099s
  training loss:		0.261552
  validation loss:		0.403219
  validation accuracy:		89.67 %
Epoch 1974 of 2000 took 0.099s
  training loss:		0.264915
  validation loss:		0.394858
  validation accuracy:		90.11 %
Epoch 1975 of 2000 took 0.103s
  training loss:		0.264897
  validation loss:		0.425032
  validation accuracy:		88.48 %
Epoch 1976 of 2000 took 0.100s
  training loss:		0.260050
  validation loss:		0.409549
  validation accuracy:		89.35 %
Epoch 1977 of 2000 took 0.099s
  training loss:		0.261924
  validation loss:		0.412130
  validation accuracy:		89.02 %
Epoch 1978 of 2000 took 0.105s
  training loss:		0.265287
  validation loss:		0.420789
  validation accuracy:		88.70 %
Epoch 1979 of 2000 took 0.099s
  training loss:		0.266689
  validation loss:		0.398966
  validation accuracy:		89.78 %
Epoch 1980 of 2000 took 0.100s
  training loss:		0.267823
  validation loss:		0.419242
  validation accuracy:		89.02 %
Epoch 1981 of 2000 took 0.099s
  training loss:		0.264830
  validation loss:		0.396499
  validation accuracy:		90.11 %
Epoch 1982 of 2000 took 0.100s
  training loss:		0.259986
  validation loss:		0.403577
  validation accuracy:		89.46 %
Epoch 1983 of 2000 took 0.103s
  training loss:		0.267037
  validation loss:		0.397251
  validation accuracy:		90.00 %
Epoch 1984 of 2000 took 0.099s
  training loss:		0.260850
  validation loss:		0.405856
  validation accuracy:		89.67 %
Epoch 1985 of 2000 took 0.100s
  training loss:		0.268315
  validation loss:		0.400869
  validation accuracy:		89.35 %
Epoch 1986 of 2000 took 0.105s
  training loss:		0.265214
  validation loss:		0.414340
  validation accuracy:		89.24 %
Epoch 1987 of 2000 took 0.099s
  training loss:		0.266675
  validation loss:		0.405883
  validation accuracy:		89.46 %
Epoch 1988 of 2000 took 0.100s
  training loss:		0.263576
  validation loss:		0.407599
  validation accuracy:		89.89 %
Epoch 1989 of 2000 took 0.099s
  training loss:		0.262594
  validation loss:		0.419182
  validation accuracy:		89.02 %
Epoch 1990 of 2000 took 0.101s
  training loss:		0.263860
  validation loss:		0.406839
  validation accuracy:		90.11 %
Epoch 1991 of 2000 took 0.102s
  training loss:		0.268209
  validation loss:		0.402909
  validation accuracy:		89.57 %
Epoch 1992 of 2000 took 0.099s
  training loss:		0.262632
  validation loss:		0.400459
  validation accuracy:		90.33 %
Epoch 1993 of 2000 took 0.101s
  training loss:		0.259472
  validation loss:		0.402912
  validation accuracy:		89.67 %
Epoch 1994 of 2000 took 0.103s
  training loss:		0.262711
  validation loss:		0.405589
  validation accuracy:		89.02 %
Epoch 1995 of 2000 took 0.099s
  training loss:		0.260328
  validation loss:		0.409098
  validation accuracy:		89.35 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.259076
  validation loss:		0.417884
  validation accuracy:		88.70 %
Epoch 1997 of 2000 took 0.099s
  training loss:		0.253185
  validation loss:		0.398892
  validation accuracy:		90.11 %
Epoch 1998 of 2000 took 0.104s
  training loss:		0.262276
  validation loss:		0.397119
  validation accuracy:		88.91 %
Epoch 1999 of 2000 took 0.100s
  training loss:		0.263325
  validation loss:		0.396884
  validation accuracy:		89.46 %
Epoch 2000 of 2000 took 0.099s
  training loss:		0.255307
  validation loss:		0.401214
  validation accuracy:		89.89 %
Final results:
  test loss:			0.758306
  test accuracy:		81.02 %
