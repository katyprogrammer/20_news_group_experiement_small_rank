Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.037s
  training loss:		3.035704
  validation loss:		2.165114
  validation accuracy:		23.91 %
Epoch 2 of 2000 took 0.036s
  training loss:		1.829819
  validation loss:		1.530187
  validation accuracy:		47.83 %
Epoch 3 of 2000 took 0.035s
  training loss:		1.527056
  validation loss:		1.363571
  validation accuracy:		52.72 %
Epoch 4 of 2000 took 0.035s
  training loss:		1.383285
  validation loss:		1.265001
  validation accuracy:		55.11 %
Epoch 5 of 2000 took 0.041s
  training loss:		1.304784
  validation loss:		1.192352
  validation accuracy:		58.48 %
Epoch 6 of 2000 took 0.051s
  training loss:		1.226060
  validation loss:		1.132255
  validation accuracy:		60.22 %
Epoch 7 of 2000 took 0.044s
  training loss:		1.163762
  validation loss:		1.052392
  validation accuracy:		64.57 %
Epoch 8 of 2000 took 0.039s
  training loss:		1.111183
  validation loss:		1.011832
  validation accuracy:		66.85 %
Epoch 9 of 2000 took 0.036s
  training loss:		1.059338
  validation loss:		0.973473
  validation accuracy:		66.85 %
Epoch 10 of 2000 took 0.035s
  training loss:		1.009529
  validation loss:		0.904135
  validation accuracy:		70.33 %
Epoch 11 of 2000 took 0.035s
  training loss:		0.971049
  validation loss:		0.884006
  validation accuracy:		70.33 %
Epoch 12 of 2000 took 0.035s
  training loss:		0.916985
  validation loss:		0.837918
  validation accuracy:		73.15 %
Epoch 13 of 2000 took 0.035s
  training loss:		0.886671
  validation loss:		0.817228
  validation accuracy:		72.83 %
Epoch 14 of 2000 took 0.035s
  training loss:		0.840866
  validation loss:		0.758491
  validation accuracy:		76.52 %
Epoch 15 of 2000 took 0.035s
  training loss:		0.815487
  validation loss:		0.753464
  validation accuracy:		75.76 %
Epoch 16 of 2000 took 0.035s
  training loss:		0.777860
  validation loss:		0.716825
  validation accuracy:		77.72 %
Epoch 17 of 2000 took 0.035s
  training loss:		0.753914
  validation loss:		0.697905
  validation accuracy:		77.83 %
Epoch 18 of 2000 took 0.035s
  training loss:		0.728460
  validation loss:		0.645469
  validation accuracy:		79.89 %
Epoch 19 of 2000 took 0.035s
  training loss:		0.694918
  validation loss:		0.654721
  validation accuracy:		79.35 %
Epoch 20 of 2000 took 0.035s
  training loss:		0.661741
  validation loss:		0.624273
  validation accuracy:		80.65 %
Epoch 21 of 2000 took 0.035s
  training loss:		0.641571
  validation loss:		0.591829
  validation accuracy:		81.41 %
Epoch 22 of 2000 took 0.035s
  training loss:		0.625065
  validation loss:		0.580896
  validation accuracy:		81.74 %
Epoch 23 of 2000 took 0.035s
  training loss:		0.603087
  validation loss:		0.573956
  validation accuracy:		81.30 %
Epoch 24 of 2000 took 0.035s
  training loss:		0.587036
  validation loss:		0.566464
  validation accuracy:		81.30 %
Epoch 25 of 2000 took 0.035s
  training loss:		0.565308
  validation loss:		0.541711
  validation accuracy:		82.50 %
Epoch 26 of 2000 took 0.035s
  training loss:		0.562816
  validation loss:		0.535828
  validation accuracy:		82.28 %
Epoch 27 of 2000 took 0.035s
  training loss:		0.546092
  validation loss:		0.512863
  validation accuracy:		83.48 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.529014
  validation loss:		0.509315
  validation accuracy:		83.48 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.520333
  validation loss:		0.493355
  validation accuracy:		84.57 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.504056
  validation loss:		0.498201
  validation accuracy:		83.37 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.491415
  validation loss:		0.487139
  validation accuracy:		83.91 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.487825
  validation loss:		0.465735
  validation accuracy:		85.00 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.471758
  validation loss:		0.458314
  validation accuracy:		85.43 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.466393
  validation loss:		0.458374
  validation accuracy:		85.11 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.463127
  validation loss:		0.438588
  validation accuracy:		85.76 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.450608
  validation loss:		0.444661
  validation accuracy:		86.09 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.439142
  validation loss:		0.435855
  validation accuracy:		86.20 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.434797
  validation loss:		0.432704
  validation accuracy:		85.98 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.423473
  validation loss:		0.419102
  validation accuracy:		86.52 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.418542
  validation loss:		0.408872
  validation accuracy:		86.74 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.412377
  validation loss:		0.421324
  validation accuracy:		86.74 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.404091
  validation loss:		0.408933
  validation accuracy:		86.52 %
Epoch 43 of 2000 took 0.036s
  training loss:		0.399176
  validation loss:		0.424544
  validation accuracy:		86.09 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.392570
  validation loss:		0.390308
  validation accuracy:		87.93 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.392344
  validation loss:		0.380403
  validation accuracy:		88.37 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.386773
  validation loss:		0.382011
  validation accuracy:		87.72 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.381877
  validation loss:		0.389033
  validation accuracy:		87.61 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.372178
  validation loss:		0.381240
  validation accuracy:		88.04 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.368962
  validation loss:		0.377925
  validation accuracy:		88.15 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.360037
  validation loss:		0.370333
  validation accuracy:		88.70 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.358146
  validation loss:		0.365451
  validation accuracy:		88.70 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.357833
  validation loss:		0.354275
  validation accuracy:		88.91 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.350817
  validation loss:		0.360300
  validation accuracy:		88.80 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.347418
  validation loss:		0.355510
  validation accuracy:		88.91 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.340229
  validation loss:		0.360262
  validation accuracy:		88.37 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.338538
  validation loss:		0.353236
  validation accuracy:		88.70 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.333285
  validation loss:		0.352600
  validation accuracy:		89.13 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.332052
  validation loss:		0.355593
  validation accuracy:		88.70 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.324661
  validation loss:		0.353031
  validation accuracy:		88.59 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.322523
  validation loss:		0.339872
  validation accuracy:		89.57 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.322773
  validation loss:		0.336522
  validation accuracy:		89.24 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.318161
  validation loss:		0.330155
  validation accuracy:		89.35 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.314587
  validation loss:		0.329130
  validation accuracy:		89.78 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.308696
  validation loss:		0.341573
  validation accuracy:		89.24 %
Epoch 65 of 2000 took 0.036s
  training loss:		0.305834
  validation loss:		0.327118
  validation accuracy:		89.57 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.303208
  validation loss:		0.324093
  validation accuracy:		89.67 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.300007
  validation loss:		0.316713
  validation accuracy:		90.43 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.298278
  validation loss:		0.343035
  validation accuracy:		89.02 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.298020
  validation loss:		0.327257
  validation accuracy:		89.57 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.294609
  validation loss:		0.315916
  validation accuracy:		90.11 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.295944
  validation loss:		0.313763
  validation accuracy:		90.22 %
Epoch 72 of 2000 took 0.036s
  training loss:		0.289170
  validation loss:		0.325960
  validation accuracy:		89.24 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.287297
  validation loss:		0.322698
  validation accuracy:		89.67 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.288442
  validation loss:		0.319465
  validation accuracy:		89.35 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.280864
  validation loss:		0.311276
  validation accuracy:		89.89 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.275703
  validation loss:		0.302356
  validation accuracy:		90.54 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.273781
  validation loss:		0.312298
  validation accuracy:		90.00 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.271186
  validation loss:		0.315803
  validation accuracy:		89.89 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.270366
  validation loss:		0.303451
  validation accuracy:		90.00 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.263900
  validation loss:		0.302061
  validation accuracy:		90.54 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.266736
  validation loss:		0.305009
  validation accuracy:		90.00 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.264539
  validation loss:		0.295571
  validation accuracy:		90.76 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.266708
  validation loss:		0.296771
  validation accuracy:		90.76 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.262364
  validation loss:		0.296822
  validation accuracy:		90.76 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.262628
  validation loss:		0.297956
  validation accuracy:		90.43 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.253664
  validation loss:		0.307416
  validation accuracy:		89.89 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.254231
  validation loss:		0.304542
  validation accuracy:		90.00 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.258212
  validation loss:		0.307050
  validation accuracy:		90.54 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.250786
  validation loss:		0.304924
  validation accuracy:		90.11 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.249588
  validation loss:		0.296691
  validation accuracy:		90.43 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.250793
  validation loss:		0.301339
  validation accuracy:		90.54 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.244923
  validation loss:		0.294476
  validation accuracy:		90.33 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.249130
  validation loss:		0.281550
  validation accuracy:		90.76 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.244151
  validation loss:		0.293662
  validation accuracy:		90.54 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.244021
  validation loss:		0.287363
  validation accuracy:		90.43 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.244914
  validation loss:		0.293734
  validation accuracy:		90.22 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.240123
  validation loss:		0.281177
  validation accuracy:		91.09 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.238252
  validation loss:		0.292642
  validation accuracy:		90.43 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.239939
  validation loss:		0.282716
  validation accuracy:		90.98 %
Epoch 100 of 2000 took 0.036s
  training loss:		0.229922
  validation loss:		0.279469
  validation accuracy:		90.98 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.233051
  validation loss:		0.292436
  validation accuracy:		90.11 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.228313
  validation loss:		0.287087
  validation accuracy:		90.87 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.229154
  validation loss:		0.282145
  validation accuracy:		91.09 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.230819
  validation loss:		0.292532
  validation accuracy:		90.22 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.224412
  validation loss:		0.277409
  validation accuracy:		91.09 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.225667
  validation loss:		0.282797
  validation accuracy:		90.76 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.223294
  validation loss:		0.274831
  validation accuracy:		91.41 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.224859
  validation loss:		0.279940
  validation accuracy:		91.09 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.223004
  validation loss:		0.282565
  validation accuracy:		90.54 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.221123
  validation loss:		0.269911
  validation accuracy:		91.52 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.218533
  validation loss:		0.269091
  validation accuracy:		91.85 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.220200
  validation loss:		0.269222
  validation accuracy:		91.63 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.218420
  validation loss:		0.286033
  validation accuracy:		90.76 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.219258
  validation loss:		0.265980
  validation accuracy:		91.74 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.219051
  validation loss:		0.283624
  validation accuracy:		90.43 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.211063
  validation loss:		0.261957
  validation accuracy:		91.74 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.209425
  validation loss:		0.266030
  validation accuracy:		91.09 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.209967
  validation loss:		0.277052
  validation accuracy:		91.30 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.209781
  validation loss:		0.287785
  validation accuracy:		90.54 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.209079
  validation loss:		0.266532
  validation accuracy:		91.63 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.206303
  validation loss:		0.272714
  validation accuracy:		90.87 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.203910
  validation loss:		0.274126
  validation accuracy:		91.63 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.208998
  validation loss:		0.276422
  validation accuracy:		91.30 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.202348
  validation loss:		0.262110
  validation accuracy:		91.74 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.203275
  validation loss:		0.275015
  validation accuracy:		91.52 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.204485
  validation loss:		0.268524
  validation accuracy:		91.52 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.200020
  validation loss:		0.272160
  validation accuracy:		90.98 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.201919
  validation loss:		0.266821
  validation accuracy:		91.52 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.198116
  validation loss:		0.273878
  validation accuracy:		90.87 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.192474
  validation loss:		0.271282
  validation accuracy:		91.41 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.193642
  validation loss:		0.264903
  validation accuracy:		91.20 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.195537
  validation loss:		0.260257
  validation accuracy:		91.63 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.190983
  validation loss:		0.263337
  validation accuracy:		91.20 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.192836
  validation loss:		0.261842
  validation accuracy:		91.74 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.194407
  validation loss:		0.260811
  validation accuracy:		92.17 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.189741
  validation loss:		0.264506
  validation accuracy:		91.63 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.185762
  validation loss:		0.265282
  validation accuracy:		91.52 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.187397
  validation loss:		0.262249
  validation accuracy:		91.63 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.186993
  validation loss:		0.265599
  validation accuracy:		91.41 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.187010
  validation loss:		0.270771
  validation accuracy:		91.20 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.182977
  validation loss:		0.256784
  validation accuracy:		92.50 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.187582
  validation loss:		0.254858
  validation accuracy:		92.07 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.181759
  validation loss:		0.254388
  validation accuracy:		92.07 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.187356
  validation loss:		0.258890
  validation accuracy:		91.41 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.181852
  validation loss:		0.252726
  validation accuracy:		92.07 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.181652
  validation loss:		0.257548
  validation accuracy:		92.07 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.176670
  validation loss:		0.262465
  validation accuracy:		91.96 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.179386
  validation loss:		0.258737
  validation accuracy:		91.63 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.180984
  validation loss:		0.262352
  validation accuracy:		91.52 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.174550
  validation loss:		0.256683
  validation accuracy:		92.39 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.175383
  validation loss:		0.264573
  validation accuracy:		91.20 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.173958
  validation loss:		0.256466
  validation accuracy:		91.96 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.172978
  validation loss:		0.254465
  validation accuracy:		91.74 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.171410
  validation loss:		0.255981
  validation accuracy:		92.28 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.174903
  validation loss:		0.269750
  validation accuracy:		91.30 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.176980
  validation loss:		0.251113
  validation accuracy:		92.28 %
Epoch 157 of 2000 took 0.036s
  training loss:		0.170865
  validation loss:		0.254996
  validation accuracy:		91.85 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.171006
  validation loss:		0.255480
  validation accuracy:		92.17 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.173989
  validation loss:		0.261256
  validation accuracy:		91.74 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.169429
  validation loss:		0.263507
  validation accuracy:		91.30 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.166913
  validation loss:		0.261308
  validation accuracy:		92.17 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.171409
  validation loss:		0.255396
  validation accuracy:		92.28 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.167718
  validation loss:		0.259435
  validation accuracy:		91.74 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.167923
  validation loss:		0.254655
  validation accuracy:		92.07 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.164759
  validation loss:		0.250809
  validation accuracy:		92.39 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.167321
  validation loss:		0.260424
  validation accuracy:		92.07 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.166014
  validation loss:		0.248481
  validation accuracy:		92.50 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.161250
  validation loss:		0.257895
  validation accuracy:		92.07 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.163495
  validation loss:		0.257176
  validation accuracy:		91.74 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.160562
  validation loss:		0.254689
  validation accuracy:		92.39 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.159754
  validation loss:		0.252531
  validation accuracy:		92.50 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.160968
  validation loss:		0.252595
  validation accuracy:		92.17 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.162730
  validation loss:		0.258447
  validation accuracy:		92.07 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.160208
  validation loss:		0.256631
  validation accuracy:		91.85 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.159298
  validation loss:		0.251320
  validation accuracy:		92.61 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.160390
  validation loss:		0.265490
  validation accuracy:		91.41 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.159017
  validation loss:		0.253855
  validation accuracy:		92.17 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.158784
  validation loss:		0.255199
  validation accuracy:		91.96 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.151581
  validation loss:		0.247843
  validation accuracy:		92.93 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.151676
  validation loss:		0.258044
  validation accuracy:		92.39 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.153598
  validation loss:		0.260988
  validation accuracy:		92.17 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.155466
  validation loss:		0.250355
  validation accuracy:		92.61 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.151741
  validation loss:		0.268034
  validation accuracy:		91.41 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.154604
  validation loss:		0.248288
  validation accuracy:		92.28 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.153679
  validation loss:		0.260466
  validation accuracy:		92.28 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.151744
  validation loss:		0.253801
  validation accuracy:		92.39 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.149700
  validation loss:		0.251093
  validation accuracy:		92.28 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.148582
  validation loss:		0.243549
  validation accuracy:		93.26 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.147710
  validation loss:		0.259885
  validation accuracy:		91.85 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.149014
  validation loss:		0.255032
  validation accuracy:		92.50 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.148679
  validation loss:		0.255285
  validation accuracy:		92.07 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.146805
  validation loss:		0.244063
  validation accuracy:		92.93 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.146389
  validation loss:		0.253107
  validation accuracy:		92.39 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.145880
  validation loss:		0.247533
  validation accuracy:		92.61 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.145552
  validation loss:		0.246930
  validation accuracy:		92.83 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.148587
  validation loss:		0.269883
  validation accuracy:		91.30 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.147440
  validation loss:		0.245263
  validation accuracy:		93.04 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.143303
  validation loss:		0.257000
  validation accuracy:		92.07 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.145792
  validation loss:		0.259163
  validation accuracy:		91.85 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.140435
  validation loss:		0.248257
  validation accuracy:		93.15 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.144284
  validation loss:		0.241718
  validation accuracy:		93.26 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.141839
  validation loss:		0.245571
  validation accuracy:		92.93 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.142076
  validation loss:		0.263922
  validation accuracy:		91.85 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.140698
  validation loss:		0.243911
  validation accuracy:		93.15 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.141962
  validation loss:		0.254287
  validation accuracy:		92.17 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.134995
  validation loss:		0.251776
  validation accuracy:		93.15 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.137654
  validation loss:		0.258115
  validation accuracy:		92.17 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.135384
  validation loss:		0.256856
  validation accuracy:		92.72 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.139225
  validation loss:		0.254912
  validation accuracy:		92.39 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.138644
  validation loss:		0.258795
  validation accuracy:		92.61 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.138317
  validation loss:		0.245824
  validation accuracy:		93.04 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.134795
  validation loss:		0.252610
  validation accuracy:		92.28 %
Epoch 213 of 2000 took 0.036s
  training loss:		0.137779
  validation loss:		0.259940
  validation accuracy:		92.07 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.133500
  validation loss:		0.250152
  validation accuracy:		92.72 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.131947
  validation loss:		0.255874
  validation accuracy:		92.72 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.134955
  validation loss:		0.248079
  validation accuracy:		92.72 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.133808
  validation loss:		0.248446
  validation accuracy:		92.28 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.135370
  validation loss:		0.246846
  validation accuracy:		92.72 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.135112
  validation loss:		0.247345
  validation accuracy:		93.15 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.130121
  validation loss:		0.247378
  validation accuracy:		92.93 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.132314
  validation loss:		0.257321
  validation accuracy:		92.07 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.132918
  validation loss:		0.247930
  validation accuracy:		92.61 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.131404
  validation loss:		0.256883
  validation accuracy:		91.85 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.133973
  validation loss:		0.260107
  validation accuracy:		91.74 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.133720
  validation loss:		0.256810
  validation accuracy:		92.72 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.131937
  validation loss:		0.254930
  validation accuracy:		92.39 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.129578
  validation loss:		0.248344
  validation accuracy:		92.72 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.126869
  validation loss:		0.251576
  validation accuracy:		92.83 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.131093
  validation loss:		0.251829
  validation accuracy:		92.83 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.128519
  validation loss:		0.247548
  validation accuracy:		92.83 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.127100
  validation loss:		0.247655
  validation accuracy:		92.83 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.122513
  validation loss:		0.250500
  validation accuracy:		92.39 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.128424
  validation loss:		0.253876
  validation accuracy:		92.39 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.127129
  validation loss:		0.247438
  validation accuracy:		92.93 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.126894
  validation loss:		0.249422
  validation accuracy:		92.93 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.123598
  validation loss:		0.259043
  validation accuracy:		91.96 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.122862
  validation loss:		0.253499
  validation accuracy:		92.72 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.125552
  validation loss:		0.261200
  validation accuracy:		92.07 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.123923
  validation loss:		0.248442
  validation accuracy:		92.61 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.122098
  validation loss:		0.252365
  validation accuracy:		92.83 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.120698
  validation loss:		0.251157
  validation accuracy:		93.04 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.123857
  validation loss:		0.257657
  validation accuracy:		92.61 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.121046
  validation loss:		0.251809
  validation accuracy:		92.17 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.116948
  validation loss:		0.247584
  validation accuracy:		93.15 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.122784
  validation loss:		0.262668
  validation accuracy:		92.17 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.122295
  validation loss:		0.245328
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.119185
  validation loss:		0.262392
  validation accuracy:		92.07 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.120641
  validation loss:		0.263970
  validation accuracy:		92.28 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.120827
  validation loss:		0.255818
  validation accuracy:		92.17 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.120995
  validation loss:		0.248696
  validation accuracy:		93.26 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.119345
  validation loss:		0.253130
  validation accuracy:		92.93 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.120733
  validation loss:		0.261508
  validation accuracy:		91.85 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.120214
  validation loss:		0.239030
  validation accuracy:		93.04 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.115073
  validation loss:		0.264462
  validation accuracy:		91.63 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.118462
  validation loss:		0.254390
  validation accuracy:		92.72 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.115475
  validation loss:		0.242072
  validation accuracy:		93.48 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.116139
  validation loss:		0.264250
  validation accuracy:		91.96 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.115690
  validation loss:		0.246853
  validation accuracy:		93.15 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.114385
  validation loss:		0.259695
  validation accuracy:		92.17 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.114732
  validation loss:		0.254365
  validation accuracy:		92.50 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.114884
  validation loss:		0.255649
  validation accuracy:		92.17 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.116243
  validation loss:		0.254303
  validation accuracy:		92.28 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.112834
  validation loss:		0.247860
  validation accuracy:		92.72 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.109995
  validation loss:		0.268682
  validation accuracy:		92.39 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.113301
  validation loss:		0.264234
  validation accuracy:		91.63 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.114056
  validation loss:		0.253477
  validation accuracy:		92.83 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.112807
  validation loss:		0.250894
  validation accuracy:		92.83 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.113520
  validation loss:		0.248680
  validation accuracy:		92.93 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.113891
  validation loss:		0.261647
  validation accuracy:		92.17 %
Epoch 270 of 2000 took 0.036s
  training loss:		0.111469
  validation loss:		0.270467
  validation accuracy:		91.74 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.113424
  validation loss:		0.270307
  validation accuracy:		91.85 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.112951
  validation loss:		0.269491
  validation accuracy:		91.41 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.108980
  validation loss:		0.259897
  validation accuracy:		91.74 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.111534
  validation loss:		0.263541
  validation accuracy:		92.39 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.111382
  validation loss:		0.257123
  validation accuracy:		92.07 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.108098
  validation loss:		0.257662
  validation accuracy:		92.61 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.108389
  validation loss:		0.263799
  validation accuracy:		92.07 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.106290
  validation loss:		0.251836
  validation accuracy:		92.83 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.106946
  validation loss:		0.273537
  validation accuracy:		92.07 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.112321
  validation loss:		0.249025
  validation accuracy:		92.50 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.107676
  validation loss:		0.268182
  validation accuracy:		92.07 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.105684
  validation loss:		0.265951
  validation accuracy:		92.39 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.110576
  validation loss:		0.254486
  validation accuracy:		92.61 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.105698
  validation loss:		0.263106
  validation accuracy:		91.96 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.107255
  validation loss:		0.258920
  validation accuracy:		91.74 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.107980
  validation loss:		0.250591
  validation accuracy:		92.72 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.104987
  validation loss:		0.259203
  validation accuracy:		92.39 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.103553
  validation loss:		0.268789
  validation accuracy:		91.63 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.106570
  validation loss:		0.255143
  validation accuracy:		92.83 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.106909
  validation loss:		0.265675
  validation accuracy:		91.63 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.106396
  validation loss:		0.263521
  validation accuracy:		92.17 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.102116
  validation loss:		0.255233
  validation accuracy:		92.39 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.104188
  validation loss:		0.255826
  validation accuracy:		92.07 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.101651
  validation loss:		0.263513
  validation accuracy:		92.07 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.102675
  validation loss:		0.252206
  validation accuracy:		92.61 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.103973
  validation loss:		0.255889
  validation accuracy:		92.61 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.101491
  validation loss:		0.262436
  validation accuracy:		92.17 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.104033
  validation loss:		0.268956
  validation accuracy:		91.74 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.100658
  validation loss:		0.262409
  validation accuracy:		92.39 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.101805
  validation loss:		0.269778
  validation accuracy:		91.74 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.099463
  validation loss:		0.262871
  validation accuracy:		92.07 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.100221
  validation loss:		0.262467
  validation accuracy:		92.17 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.101308
  validation loss:		0.272971
  validation accuracy:		91.74 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.100902
  validation loss:		0.261044
  validation accuracy:		92.39 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.099350
  validation loss:		0.279004
  validation accuracy:		91.52 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.100062
  validation loss:		0.266136
  validation accuracy:		92.17 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.097750
  validation loss:		0.265366
  validation accuracy:		92.17 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.099117
  validation loss:		0.256601
  validation accuracy:		92.72 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.100456
  validation loss:		0.273298
  validation accuracy:		91.96 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.097028
  validation loss:		0.275708
  validation accuracy:		91.74 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.097617
  validation loss:		0.262426
  validation accuracy:		92.39 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.100805
  validation loss:		0.267550
  validation accuracy:		91.63 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.097535
  validation loss:		0.275324
  validation accuracy:		91.41 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.099850
  validation loss:		0.262406
  validation accuracy:		92.17 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.097637
  validation loss:		0.276616
  validation accuracy:		92.07 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.095941
  validation loss:		0.280549
  validation accuracy:		91.30 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.093675
  validation loss:		0.269067
  validation accuracy:		92.17 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.096060
  validation loss:		0.253931
  validation accuracy:		92.93 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.095592
  validation loss:		0.268197
  validation accuracy:		91.63 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.096658
  validation loss:		0.267914
  validation accuracy:		92.39 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.096719
  validation loss:		0.256710
  validation accuracy:		92.72 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.092690
  validation loss:		0.268298
  validation accuracy:		92.28 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.096293
  validation loss:		0.265825
  validation accuracy:		91.96 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.094226
  validation loss:		0.262182
  validation accuracy:		92.39 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.093197
  validation loss:		0.270052
  validation accuracy:		91.63 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.094413
  validation loss:		0.261029
  validation accuracy:		92.50 %
Epoch 327 of 2000 took 0.036s
  training loss:		0.093881
  validation loss:		0.266419
  validation accuracy:		92.17 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.093168
  validation loss:		0.262711
  validation accuracy:		92.50 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.094802
  validation loss:		0.270061
  validation accuracy:		91.85 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.090598
  validation loss:		0.278323
  validation accuracy:		92.17 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.091064
  validation loss:		0.271939
  validation accuracy:		91.63 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.093512
  validation loss:		0.257937
  validation accuracy:		92.50 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.090878
  validation loss:		0.265188
  validation accuracy:		92.50 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.092055
  validation loss:		0.260752
  validation accuracy:		91.63 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.092443
  validation loss:		0.265459
  validation accuracy:		92.39 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.091622
  validation loss:		0.271810
  validation accuracy:		91.74 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.091531
  validation loss:		0.270486
  validation accuracy:		92.17 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.090785
  validation loss:		0.271164
  validation accuracy:		92.07 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.089261
  validation loss:		0.264872
  validation accuracy:		92.61 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.089718
  validation loss:		0.265740
  validation accuracy:		92.07 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.090562
  validation loss:		0.261138
  validation accuracy:		92.83 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.090702
  validation loss:		0.272322
  validation accuracy:		91.74 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.088973
  validation loss:		0.273998
  validation accuracy:		92.39 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.087794
  validation loss:		0.271212
  validation accuracy:		92.39 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.088271
  validation loss:		0.276163
  validation accuracy:		91.63 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.087567
  validation loss:		0.281315
  validation accuracy:		91.85 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.088610
  validation loss:		0.271550
  validation accuracy:		92.50 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.084972
  validation loss:		0.274404
  validation accuracy:		91.85 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.086947
  validation loss:		0.279830
  validation accuracy:		91.85 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.085484
  validation loss:		0.266651
  validation accuracy:		92.50 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.088110
  validation loss:		0.270261
  validation accuracy:		92.17 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.087946
  validation loss:		0.273717
  validation accuracy:		92.17 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.085842
  validation loss:		0.273789
  validation accuracy:		92.17 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.087347
  validation loss:		0.260904
  validation accuracy:		92.39 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.085276
  validation loss:		0.275648
  validation accuracy:		91.96 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.080807
  validation loss:		0.274195
  validation accuracy:		92.07 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.084371
  validation loss:		0.277778
  validation accuracy:		92.17 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.087003
  validation loss:		0.275800
  validation accuracy:		92.28 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.084463
  validation loss:		0.275075
  validation accuracy:		91.96 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.087130
  validation loss:		0.266993
  validation accuracy:		92.28 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.084747
  validation loss:		0.275971
  validation accuracy:		92.17 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.085808
  validation loss:		0.277579
  validation accuracy:		92.39 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.082495
  validation loss:		0.291723
  validation accuracy:		91.85 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.085329
  validation loss:		0.271358
  validation accuracy:		92.39 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.085678
  validation loss:		0.277387
  validation accuracy:		92.17 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.087847
  validation loss:		0.278908
  validation accuracy:		92.50 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.087310
  validation loss:		0.268319
  validation accuracy:		92.50 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.081237
  validation loss:		0.278504
  validation accuracy:		91.85 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.083668
  validation loss:		0.263862
  validation accuracy:		92.61 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.078056
  validation loss:		0.285976
  validation accuracy:		91.85 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.080167
  validation loss:		0.278229
  validation accuracy:		91.85 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.081600
  validation loss:		0.279627
  validation accuracy:		92.17 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.082132
  validation loss:		0.274253
  validation accuracy:		92.61 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.081046
  validation loss:		0.297905
  validation accuracy:		91.41 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.083015
  validation loss:		0.272649
  validation accuracy:		92.83 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.081414
  validation loss:		0.288988
  validation accuracy:		91.52 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.080987
  validation loss:		0.281904
  validation accuracy:		92.61 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.081954
  validation loss:		0.278740
  validation accuracy:		92.50 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.082031
  validation loss:		0.282852
  validation accuracy:		92.17 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.081272
  validation loss:		0.280781
  validation accuracy:		91.85 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.081336
  validation loss:		0.284554
  validation accuracy:		91.85 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.081506
  validation loss:		0.285848
  validation accuracy:		91.63 %
Epoch 383 of 2000 took 0.036s
  training loss:		0.080366
  validation loss:		0.272694
  validation accuracy:		92.83 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.078417
  validation loss:		0.279305
  validation accuracy:		92.39 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.079222
  validation loss:		0.274793
  validation accuracy:		92.39 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.079751
  validation loss:		0.286504
  validation accuracy:		91.85 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.078871
  validation loss:		0.277964
  validation accuracy:		92.61 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.078345
  validation loss:		0.280893
  validation accuracy:		91.85 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.077733
  validation loss:		0.277865
  validation accuracy:		92.50 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.076034
  validation loss:		0.278601
  validation accuracy:		91.85 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.077968
  validation loss:		0.275955
  validation accuracy:		92.50 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.077285
  validation loss:		0.283447
  validation accuracy:		92.61 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.078801
  validation loss:		0.286099
  validation accuracy:		92.28 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.074714
  validation loss:		0.287591
  validation accuracy:		92.28 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.078871
  validation loss:		0.278396
  validation accuracy:		92.61 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.075967
  validation loss:		0.288611
  validation accuracy:		91.52 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.077392
  validation loss:		0.287376
  validation accuracy:		92.17 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.076571
  validation loss:		0.276532
  validation accuracy:		92.07 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.074561
  validation loss:		0.284714
  validation accuracy:		91.85 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.076008
  validation loss:		0.278703
  validation accuracy:		92.72 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.078086
  validation loss:		0.301691
  validation accuracy:		91.63 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.076628
  validation loss:		0.276090
  validation accuracy:		92.50 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.074943
  validation loss:		0.280500
  validation accuracy:		92.50 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.073649
  validation loss:		0.288073
  validation accuracy:		92.28 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.076645
  validation loss:		0.274615
  validation accuracy:		92.50 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.074600
  validation loss:		0.296791
  validation accuracy:		91.85 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.074470
  validation loss:		0.281394
  validation accuracy:		92.39 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.074535
  validation loss:		0.285616
  validation accuracy:		92.17 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.074108
  validation loss:		0.294069
  validation accuracy:		91.52 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.072598
  validation loss:		0.281276
  validation accuracy:		92.61 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.071608
  validation loss:		0.287162
  validation accuracy:		91.85 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.073631
  validation loss:		0.292335
  validation accuracy:		92.17 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.071936
  validation loss:		0.284383
  validation accuracy:		92.17 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.072146
  validation loss:		0.284971
  validation accuracy:		92.61 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.073144
  validation loss:		0.284293
  validation accuracy:		92.07 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.071233
  validation loss:		0.290056
  validation accuracy:		92.17 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.073347
  validation loss:		0.283262
  validation accuracy:		92.17 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.072090
  validation loss:		0.286497
  validation accuracy:		92.50 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.073199
  validation loss:		0.280156
  validation accuracy:		92.28 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.074212
  validation loss:		0.292551
  validation accuracy:		92.07 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.070134
  validation loss:		0.296845
  validation accuracy:		92.17 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.071578
  validation loss:		0.282879
  validation accuracy:		92.50 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.072604
  validation loss:		0.284182
  validation accuracy:		92.61 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.068872
  validation loss:		0.281059
  validation accuracy:		92.50 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.072153
  validation loss:		0.289126
  validation accuracy:		91.96 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.070284
  validation loss:		0.283328
  validation accuracy:		92.83 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.070080
  validation loss:		0.292249
  validation accuracy:		91.85 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.071305
  validation loss:		0.291423
  validation accuracy:		92.17 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.068822
  validation loss:		0.288491
  validation accuracy:		92.07 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.070308
  validation loss:		0.288701
  validation accuracy:		92.39 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.070762
  validation loss:		0.309214
  validation accuracy:		91.63 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.073436
  validation loss:		0.286196
  validation accuracy:		92.50 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.071745
  validation loss:		0.292757
  validation accuracy:		92.39 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.069114
  validation loss:		0.280274
  validation accuracy:		93.04 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.070157
  validation loss:		0.292211
  validation accuracy:		92.07 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.067083
  validation loss:		0.289445
  validation accuracy:		92.39 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.070328
  validation loss:		0.296516
  validation accuracy:		92.17 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.067721
  validation loss:		0.291064
  validation accuracy:		92.61 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.069333
  validation loss:		0.296334
  validation accuracy:		92.07 %
Epoch 440 of 2000 took 0.036s
  training loss:		0.069436
  validation loss:		0.300884
  validation accuracy:		92.39 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.069158
  validation loss:		0.303613
  validation accuracy:		91.74 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.066536
  validation loss:		0.298771
  validation accuracy:		91.85 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.067380
  validation loss:		0.297961
  validation accuracy:		92.07 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.066449
  validation loss:		0.303192
  validation accuracy:		91.85 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.064179
  validation loss:		0.298399
  validation accuracy:		92.17 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.065282
  validation loss:		0.303036
  validation accuracy:		91.74 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.067119
  validation loss:		0.301070
  validation accuracy:		92.28 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.068685
  validation loss:		0.313770
  validation accuracy:		91.96 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.066423
  validation loss:		0.290515
  validation accuracy:		92.61 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.065709
  validation loss:		0.300812
  validation accuracy:		92.07 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.062471
  validation loss:		0.308117
  validation accuracy:		91.85 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.066328
  validation loss:		0.295586
  validation accuracy:		92.39 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.064384
  validation loss:		0.303089
  validation accuracy:		92.39 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.063499
  validation loss:		0.300980
  validation accuracy:		92.07 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.065034
  validation loss:		0.305029
  validation accuracy:		91.96 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.066704
  validation loss:		0.301961
  validation accuracy:		92.28 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.065042
  validation loss:		0.298823
  validation accuracy:		92.39 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.064290
  validation loss:		0.296176
  validation accuracy:		92.50 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.063052
  validation loss:		0.296994
  validation accuracy:		92.50 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.064481
  validation loss:		0.299864
  validation accuracy:		92.07 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.062179
  validation loss:		0.297416
  validation accuracy:		92.39 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.062466
  validation loss:		0.292154
  validation accuracy:		92.72 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.064926
  validation loss:		0.299160
  validation accuracy:		92.28 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.065751
  validation loss:		0.299190
  validation accuracy:		92.50 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.062884
  validation loss:		0.302346
  validation accuracy:		91.85 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.062359
  validation loss:		0.304929
  validation accuracy:		92.17 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.065937
  validation loss:		0.308963
  validation accuracy:		92.28 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.064241
  validation loss:		0.299384
  validation accuracy:		92.17 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.065286
  validation loss:		0.300003
  validation accuracy:		92.50 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.062032
  validation loss:		0.289680
  validation accuracy:		92.83 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.062017
  validation loss:		0.310699
  validation accuracy:		92.07 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.063891
  validation loss:		0.329408
  validation accuracy:		91.63 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.062041
  validation loss:		0.296137
  validation accuracy:		92.50 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.064201
  validation loss:		0.294815
  validation accuracy:		92.61 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.061424
  validation loss:		0.308146
  validation accuracy:		92.28 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.063332
  validation loss:		0.299942
  validation accuracy:		92.61 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.061524
  validation loss:		0.308690
  validation accuracy:		91.96 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.062073
  validation loss:		0.298705
  validation accuracy:		92.39 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.061391
  validation loss:		0.297706
  validation accuracy:		92.72 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.059468
  validation loss:		0.311698
  validation accuracy:		91.85 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.061003
  validation loss:		0.306027
  validation accuracy:		92.39 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.057989
  validation loss:		0.303043
  validation accuracy:		92.72 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.061285
  validation loss:		0.321658
  validation accuracy:		91.74 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.060028
  validation loss:		0.312070
  validation accuracy:		91.96 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.062186
  validation loss:		0.309686
  validation accuracy:		92.50 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.061786
  validation loss:		0.314710
  validation accuracy:		91.74 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.059553
  validation loss:		0.311253
  validation accuracy:		92.07 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.060029
  validation loss:		0.317383
  validation accuracy:		91.85 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.061565
  validation loss:		0.305507
  validation accuracy:		92.17 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.059969
  validation loss:		0.319546
  validation accuracy:		91.96 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.059635
  validation loss:		0.311144
  validation accuracy:		92.61 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.061252
  validation loss:		0.336607
  validation accuracy:		91.30 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.058235
  validation loss:		0.310285
  validation accuracy:		92.50 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.061466
  validation loss:		0.305526
  validation accuracy:		92.39 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.059530
  validation loss:		0.311133
  validation accuracy:		92.50 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.059420
  validation loss:		0.314714
  validation accuracy:		92.28 %
Epoch 497 of 2000 took 0.036s
  training loss:		0.059997
  validation loss:		0.316012
  validation accuracy:		92.07 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.057670
  validation loss:		0.311362
  validation accuracy:		92.28 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.058495
  validation loss:		0.302700
  validation accuracy:		92.93 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.058600
  validation loss:		0.321411
  validation accuracy:		91.96 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.058660
  validation loss:		0.306505
  validation accuracy:		92.50 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.058594
  validation loss:		0.310916
  validation accuracy:		92.50 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.057833
  validation loss:		0.324284
  validation accuracy:		92.07 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.059075
  validation loss:		0.330812
  validation accuracy:		91.96 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.057154
  validation loss:		0.323764
  validation accuracy:		92.28 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.057224
  validation loss:		0.306695
  validation accuracy:		92.61 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.058951
  validation loss:		0.320530
  validation accuracy:		91.85 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.056837
  validation loss:		0.319547
  validation accuracy:		91.85 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.057546
  validation loss:		0.336220
  validation accuracy:		91.85 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.057561
  validation loss:		0.311616
  validation accuracy:		92.39 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.058493
  validation loss:		0.303597
  validation accuracy:		92.83 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.058152
  validation loss:		0.316554
  validation accuracy:		92.50 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.057128
  validation loss:		0.310086
  validation accuracy:		92.83 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.057033
  validation loss:		0.323999
  validation accuracy:		91.85 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.055747
  validation loss:		0.309617
  validation accuracy:		92.61 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.057153
  validation loss:		0.311167
  validation accuracy:		92.50 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.055238
  validation loss:		0.308222
  validation accuracy:		92.72 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.054735
  validation loss:		0.328154
  validation accuracy:		92.07 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.056537
  validation loss:		0.306855
  validation accuracy:		92.83 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.054779
  validation loss:		0.323880
  validation accuracy:		92.28 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.056587
  validation loss:		0.312691
  validation accuracy:		92.61 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.056700
  validation loss:		0.312844
  validation accuracy:		92.61 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.056188
  validation loss:		0.307655
  validation accuracy:		92.61 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.053868
  validation loss:		0.310233
  validation accuracy:		92.72 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.053036
  validation loss:		0.314132
  validation accuracy:		92.72 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.053393
  validation loss:		0.311608
  validation accuracy:		92.72 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.055209
  validation loss:		0.325924
  validation accuracy:		92.17 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.053623
  validation loss:		0.325735
  validation accuracy:		91.96 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.053357
  validation loss:		0.321140
  validation accuracy:		92.61 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.054395
  validation loss:		0.320053
  validation accuracy:		92.50 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.053754
  validation loss:		0.311453
  validation accuracy:		92.72 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.053728
  validation loss:		0.327538
  validation accuracy:		92.28 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.053196
  validation loss:		0.324502
  validation accuracy:		92.17 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.055670
  validation loss:		0.313652
  validation accuracy:		92.50 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.054483
  validation loss:		0.313147
  validation accuracy:		92.83 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.052329
  validation loss:		0.318310
  validation accuracy:		92.50 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.052166
  validation loss:		0.305367
  validation accuracy:		92.72 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.052985
  validation loss:		0.329472
  validation accuracy:		92.28 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.053500
  validation loss:		0.323932
  validation accuracy:		92.50 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.053528
  validation loss:		0.321475
  validation accuracy:		92.61 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.051735
  validation loss:		0.318997
  validation accuracy:		92.61 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.052054
  validation loss:		0.337221
  validation accuracy:		92.07 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.051936
  validation loss:		0.311414
  validation accuracy:		93.04 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.053299
  validation loss:		0.328295
  validation accuracy:		92.28 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.052779
  validation loss:		0.325929
  validation accuracy:		92.28 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.051860
  validation loss:		0.323932
  validation accuracy:		92.61 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.053245
  validation loss:		0.327756
  validation accuracy:		92.07 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.051637
  validation loss:		0.340909
  validation accuracy:		92.17 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.052804
  validation loss:		0.324021
  validation accuracy:		92.61 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.052139
  validation loss:		0.339930
  validation accuracy:		92.07 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.051814
  validation loss:		0.328990
  validation accuracy:		92.61 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.051232
  validation loss:		0.327254
  validation accuracy:		92.61 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.051190
  validation loss:		0.328975
  validation accuracy:		92.72 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.050943
  validation loss:		0.346638
  validation accuracy:		92.07 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.048872
  validation loss:		0.324147
  validation accuracy:		92.83 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.050886
  validation loss:		0.328903
  validation accuracy:		92.50 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.051443
  validation loss:		0.324508
  validation accuracy:		92.72 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.049795
  validation loss:		0.326613
  validation accuracy:		92.93 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.050596
  validation loss:		0.326727
  validation accuracy:		92.83 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.049799
  validation loss:		0.324129
  validation accuracy:		92.39 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.048873
  validation loss:		0.323102
  validation accuracy:		92.93 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.049635
  validation loss:		0.336869
  validation accuracy:		92.28 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.049316
  validation loss:		0.324732
  validation accuracy:		92.83 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.048436
  validation loss:		0.315144
  validation accuracy:		93.04 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.049594
  validation loss:		0.331204
  validation accuracy:		92.61 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.048728
  validation loss:		0.327904
  validation accuracy:		92.61 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.049899
  validation loss:		0.342446
  validation accuracy:		92.07 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.049833
  validation loss:		0.335231
  validation accuracy:		92.50 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.048997
  validation loss:		0.334275
  validation accuracy:		92.28 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.048819
  validation loss:		0.335228
  validation accuracy:		92.50 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.048744
  validation loss:		0.328701
  validation accuracy:		92.50 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.049015
  validation loss:		0.324983
  validation accuracy:		92.72 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.048983
  validation loss:		0.331124
  validation accuracy:		92.72 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.049903
  validation loss:		0.342597
  validation accuracy:		92.17 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.048254
  validation loss:		0.343085
  validation accuracy:		92.17 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.045897
  validation loss:		0.330631
  validation accuracy:		92.61 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.046545
  validation loss:		0.359278
  validation accuracy:		91.74 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.047038
  validation loss:		0.325036
  validation accuracy:		92.93 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.048492
  validation loss:		0.339053
  validation accuracy:		92.50 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.046635
  validation loss:		0.347496
  validation accuracy:		92.07 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.045362
  validation loss:		0.335102
  validation accuracy:		92.72 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.045469
  validation loss:		0.334311
  validation accuracy:		92.50 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.045986
  validation loss:		0.326103
  validation accuracy:		92.72 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.046655
  validation loss:		0.333071
  validation accuracy:		92.50 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.047393
  validation loss:		0.339668
  validation accuracy:		92.61 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.047840
  validation loss:		0.331101
  validation accuracy:		92.83 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.047047
  validation loss:		0.344168
  validation accuracy:		92.50 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.045619
  validation loss:		0.327646
  validation accuracy:		93.15 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.047380
  validation loss:		0.346977
  validation accuracy:		92.28 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.047003
  validation loss:		0.336819
  validation accuracy:		92.61 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.043234
  validation loss:		0.333573
  validation accuracy:		92.72 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.044970
  validation loss:		0.363893
  validation accuracy:		91.63 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.045632
  validation loss:		0.332109
  validation accuracy:		92.83 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.045454
  validation loss:		0.333724
  validation accuracy:		93.04 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.046465
  validation loss:		0.346579
  validation accuracy:		92.17 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.044513
  validation loss:		0.352625
  validation accuracy:		92.39 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.046234
  validation loss:		0.346241
  validation accuracy:		92.61 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.046073
  validation loss:		0.340395
  validation accuracy:		92.72 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.043695
  validation loss:		0.351455
  validation accuracy:		92.17 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.044245
  validation loss:		0.332542
  validation accuracy:		92.61 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.045521
  validation loss:		0.343391
  validation accuracy:		92.28 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.044478
  validation loss:		0.353520
  validation accuracy:		92.07 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.043338
  validation loss:		0.342353
  validation accuracy:		92.83 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.041956
  validation loss:		0.345801
  validation accuracy:		92.50 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.044745
  validation loss:		0.341771
  validation accuracy:		92.61 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.044376
  validation loss:		0.336791
  validation accuracy:		93.04 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.042985
  validation loss:		0.355526
  validation accuracy:		92.17 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.044236
  validation loss:		0.336671
  validation accuracy:		92.93 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.044543
  validation loss:		0.352255
  validation accuracy:		92.39 %
Epoch 610 of 2000 took 0.036s
  training loss:		0.043959
  validation loss:		0.347172
  validation accuracy:		92.28 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.042979
  validation loss:		0.346096
  validation accuracy:		92.39 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.043541
  validation loss:		0.334627
  validation accuracy:		93.04 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.045428
  validation loss:		0.328453
  validation accuracy:		92.72 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.042802
  validation loss:		0.345941
  validation accuracy:		92.28 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.044317
  validation loss:		0.344295
  validation accuracy:		92.50 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.042954
  validation loss:		0.352768
  validation accuracy:		92.28 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.043366
  validation loss:		0.345944
  validation accuracy:		92.50 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.043941
  validation loss:		0.354572
  validation accuracy:		91.74 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.042029
  validation loss:		0.347681
  validation accuracy:		92.61 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.042511
  validation loss:		0.344111
  validation accuracy:		92.72 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.041526
  validation loss:		0.355997
  validation accuracy:		92.07 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.043429
  validation loss:		0.345024
  validation accuracy:		92.39 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.041648
  validation loss:		0.362511
  validation accuracy:		92.17 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.042808
  validation loss:		0.340908
  validation accuracy:		92.93 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.042117
  validation loss:		0.362494
  validation accuracy:		92.39 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.042538
  validation loss:		0.360938
  validation accuracy:		91.96 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.042901
  validation loss:		0.362383
  validation accuracy:		92.28 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.042127
  validation loss:		0.355032
  validation accuracy:		92.61 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.042127
  validation loss:		0.342510
  validation accuracy:		92.72 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.041965
  validation loss:		0.352271
  validation accuracy:		92.61 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.042496
  validation loss:		0.356961
  validation accuracy:		92.28 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.041891
  validation loss:		0.353591
  validation accuracy:		92.39 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.041289
  validation loss:		0.370416
  validation accuracy:		91.74 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.039955
  validation loss:		0.355337
  validation accuracy:		92.50 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.041902
  validation loss:		0.352583
  validation accuracy:		92.50 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.041026
  validation loss:		0.351404
  validation accuracy:		92.61 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.042343
  validation loss:		0.350062
  validation accuracy:		92.83 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.041359
  validation loss:		0.357295
  validation accuracy:		92.28 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.040650
  validation loss:		0.372272
  validation accuracy:		91.85 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.040773
  validation loss:		0.355508
  validation accuracy:		92.39 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.039754
  validation loss:		0.349134
  validation accuracy:		92.83 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.040222
  validation loss:		0.365627
  validation accuracy:		92.17 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.039687
  validation loss:		0.346502
  validation accuracy:		92.93 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.036223
  validation loss:		0.345675
  validation accuracy:		92.72 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.040602
  validation loss:		0.339973
  validation accuracy:		92.61 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.040987
  validation loss:		0.360483
  validation accuracy:		92.39 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.039142
  validation loss:		0.342981
  validation accuracy:		92.50 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.039626
  validation loss:		0.368621
  validation accuracy:		92.28 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.040784
  validation loss:		0.365185
  validation accuracy:		92.39 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.038367
  validation loss:		0.352619
  validation accuracy:		92.72 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.040323
  validation loss:		0.351378
  validation accuracy:		92.93 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.038619
  validation loss:		0.348477
  validation accuracy:		92.83 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.038038
  validation loss:		0.359011
  validation accuracy:		92.28 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.038877
  validation loss:		0.347583
  validation accuracy:		93.04 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.037236
  validation loss:		0.368346
  validation accuracy:		92.28 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.038246
  validation loss:		0.355240
  validation accuracy:		92.83 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.037344
  validation loss:		0.366589
  validation accuracy:		92.28 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.038670
  validation loss:		0.359534
  validation accuracy:		92.50 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.039112
  validation loss:		0.358582
  validation accuracy:		92.93 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.039319
  validation loss:		0.370121
  validation accuracy:		92.07 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.039303
  validation loss:		0.363236
  validation accuracy:		92.61 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.037255
  validation loss:		0.360760
  validation accuracy:		92.72 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.036541
  validation loss:		0.358684
  validation accuracy:		92.50 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.040109
  validation loss:		0.357746
  validation accuracy:		92.72 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.039382
  validation loss:		0.359248
  validation accuracy:		92.50 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.038726
  validation loss:		0.353380
  validation accuracy:		92.83 %
Epoch 667 of 2000 took 0.036s
  training loss:		0.038316
  validation loss:		0.364540
  validation accuracy:		92.28 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.037361
  validation loss:		0.357562
  validation accuracy:		92.61 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.037707
  validation loss:		0.357314
  validation accuracy:		92.50 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.038306
  validation loss:		0.378136
  validation accuracy:		92.28 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.037604
  validation loss:		0.366875
  validation accuracy:		92.61 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.037284
  validation loss:		0.354057
  validation accuracy:		92.83 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.037315
  validation loss:		0.358332
  validation accuracy:		92.72 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.036103
  validation loss:		0.379291
  validation accuracy:		91.96 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.036457
  validation loss:		0.362598
  validation accuracy:		92.83 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.037600
  validation loss:		0.359274
  validation accuracy:		92.61 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.035536
  validation loss:		0.378517
  validation accuracy:		92.07 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.035516
  validation loss:		0.370671
  validation accuracy:		92.28 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.036231
  validation loss:		0.383060
  validation accuracy:		91.96 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.036419
  validation loss:		0.362549
  validation accuracy:		92.72 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.036306
  validation loss:		0.373813
  validation accuracy:		92.28 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.036507
  validation loss:		0.359534
  validation accuracy:		92.72 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.036155
  validation loss:		0.365987
  validation accuracy:		92.28 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.035661
  validation loss:		0.365725
  validation accuracy:		92.72 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.035305
  validation loss:		0.363624
  validation accuracy:		92.83 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.036045
  validation loss:		0.367043
  validation accuracy:		92.39 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.034933
  validation loss:		0.377409
  validation accuracy:		91.96 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.035118
  validation loss:		0.357406
  validation accuracy:		92.72 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.037636
  validation loss:		0.362943
  validation accuracy:		93.04 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.035633
  validation loss:		0.378655
  validation accuracy:		91.96 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.035242
  validation loss:		0.365358
  validation accuracy:		92.39 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.037126
  validation loss:		0.359941
  validation accuracy:		92.83 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.036527
  validation loss:		0.374897
  validation accuracy:		92.50 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.035156
  validation loss:		0.376302
  validation accuracy:		92.50 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.035327
  validation loss:		0.371542
  validation accuracy:		92.61 %
Epoch 696 of 2000 took 0.036s
  training loss:		0.034633
  validation loss:		0.373862
  validation accuracy:		92.28 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.034069
  validation loss:		0.367059
  validation accuracy:		92.61 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.032484
  validation loss:		0.357962
  validation accuracy:		92.83 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.034811
  validation loss:		0.380987
  validation accuracy:		92.61 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.034139
  validation loss:		0.379854
  validation accuracy:		92.28 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.034428
  validation loss:		0.375689
  validation accuracy:		92.83 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.032301
  validation loss:		0.380340
  validation accuracy:		92.17 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.033552
  validation loss:		0.386135
  validation accuracy:		92.39 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.036145
  validation loss:		0.381380
  validation accuracy:		92.28 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.034525
  validation loss:		0.359745
  validation accuracy:		92.93 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.034531
  validation loss:		0.383419
  validation accuracy:		92.28 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.032518
  validation loss:		0.377857
  validation accuracy:		92.39 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.035718
  validation loss:		0.369409
  validation accuracy:		92.83 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.035230
  validation loss:		0.364145
  validation accuracy:		92.83 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.033946
  validation loss:		0.376652
  validation accuracy:		92.50 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.033312
  validation loss:		0.380463
  validation accuracy:		92.17 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.034063
  validation loss:		0.373807
  validation accuracy:		92.93 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.031869
  validation loss:		0.388866
  validation accuracy:		92.39 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.034240
  validation loss:		0.388483
  validation accuracy:		92.17 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.033801
  validation loss:		0.366883
  validation accuracy:		92.72 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.033031
  validation loss:		0.390696
  validation accuracy:		91.96 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.033397
  validation loss:		0.372905
  validation accuracy:		92.83 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.033110
  validation loss:		0.382985
  validation accuracy:		92.39 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.033454
  validation loss:		0.395069
  validation accuracy:		91.96 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.033343
  validation loss:		0.375339
  validation accuracy:		92.28 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.033551
  validation loss:		0.395753
  validation accuracy:		91.96 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.032996
  validation loss:		0.390622
  validation accuracy:		91.96 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.033458
  validation loss:		0.379733
  validation accuracy:		92.50 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.032737
  validation loss:		0.393990
  validation accuracy:		92.28 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.033198
  validation loss:		0.384748
  validation accuracy:		92.17 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.032098
  validation loss:		0.377236
  validation accuracy:		92.72 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.033040
  validation loss:		0.392382
  validation accuracy:		92.07 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.032879
  validation loss:		0.386117
  validation accuracy:		91.96 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.032851
  validation loss:		0.375253
  validation accuracy:		92.72 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.032492
  validation loss:		0.390600
  validation accuracy:		92.07 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.032693
  validation loss:		0.372956
  validation accuracy:		92.72 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.032033
  validation loss:		0.375857
  validation accuracy:		92.83 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.031264
  validation loss:		0.380782
  validation accuracy:		92.50 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.031281
  validation loss:		0.392528
  validation accuracy:		92.17 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.031406
  validation loss:		0.387961
  validation accuracy:		91.85 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.030721
  validation loss:		0.396066
  validation accuracy:		92.17 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.032063
  validation loss:		0.401258
  validation accuracy:		91.85 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.031348
  validation loss:		0.377873
  validation accuracy:		92.61 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.030533
  validation loss:		0.400912
  validation accuracy:		91.96 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.031896
  validation loss:		0.390984
  validation accuracy:		92.17 %
Epoch 741 of 2000 took 0.036s
  training loss:		0.030759
  validation loss:		0.382847
  validation accuracy:		92.50 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.029544
  validation loss:		0.392639
  validation accuracy:		92.17 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.029879
  validation loss:		0.382504
  validation accuracy:		92.72 %
Epoch 744 of 2000 took 0.038s
  training loss:		0.030262
  validation loss:		0.397767
  validation accuracy:		92.28 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.031113
  validation loss:		0.383637
  validation accuracy:		92.28 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.029970
  validation loss:		0.387906
  validation accuracy:		92.50 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.030843
  validation loss:		0.390658
  validation accuracy:		92.28 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.029995
  validation loss:		0.381430
  validation accuracy:		92.50 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.030696
  validation loss:		0.396893
  validation accuracy:		92.07 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.030434
  validation loss:		0.390211
  validation accuracy:		92.39 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.029385
  validation loss:		0.386435
  validation accuracy:		92.50 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.028770
  validation loss:		0.393228
  validation accuracy:		92.61 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.030514
  validation loss:		0.402740
  validation accuracy:		92.28 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.028720
  validation loss:		0.389003
  validation accuracy:		92.39 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.030417
  validation loss:		0.378707
  validation accuracy:		92.72 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.030413
  validation loss:		0.389408
  validation accuracy:		92.83 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.026775
  validation loss:		0.400130
  validation accuracy:		92.07 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.028854
  validation loss:		0.391571
  validation accuracy:		92.28 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.029339
  validation loss:		0.378966
  validation accuracy:		92.93 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.029353
  validation loss:		0.399542
  validation accuracy:		92.17 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.028962
  validation loss:		0.382720
  validation accuracy:		92.93 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.029359
  validation loss:		0.402404
  validation accuracy:		92.39 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.029113
  validation loss:		0.395481
  validation accuracy:		92.17 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.027721
  validation loss:		0.397350
  validation accuracy:		92.28 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.029605
  validation loss:		0.393168
  validation accuracy:		92.07 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.029331
  validation loss:		0.391665
  validation accuracy:		92.28 %
Epoch 767 of 2000 took 0.037s
  training loss:		0.028904
  validation loss:		0.399807
  validation accuracy:		92.28 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.028670
  validation loss:		0.380520
  validation accuracy:		92.72 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.027090
  validation loss:		0.394870
  validation accuracy:		92.28 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.029322
  validation loss:		0.389918
  validation accuracy:		92.61 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.028726
  validation loss:		0.400547
  validation accuracy:		92.28 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.028344
  validation loss:		0.403185
  validation accuracy:		92.07 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.027615
  validation loss:		0.405927
  validation accuracy:		91.85 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.029516
  validation loss:		0.406776
  validation accuracy:		92.28 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.028089
  validation loss:		0.403755
  validation accuracy:		92.07 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.028530
  validation loss:		0.395765
  validation accuracy:		92.39 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.028458
  validation loss:		0.393683
  validation accuracy:		92.39 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.028343
  validation loss:		0.394105
  validation accuracy:		92.28 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.028397
  validation loss:		0.399119
  validation accuracy:		92.17 %
Epoch 780 of 2000 took 0.036s
  training loss:		0.027144
  validation loss:		0.397471
  validation accuracy:		92.39 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.027407
  validation loss:		0.398904
  validation accuracy:		92.28 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.027575
  validation loss:		0.404697
  validation accuracy:		92.17 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.027433
  validation loss:		0.398207
  validation accuracy:		92.39 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.027521
  validation loss:		0.406064
  validation accuracy:		92.17 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.026963
  validation loss:		0.397604
  validation accuracy:		92.28 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.027428
  validation loss:		0.396363
  validation accuracy:		92.50 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.026746
  validation loss:		0.404871
  validation accuracy:		92.28 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.027768
  validation loss:		0.394294
  validation accuracy:		92.83 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.026819
  validation loss:		0.409885
  validation accuracy:		92.07 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.026936
  validation loss:		0.395979
  validation accuracy:		92.50 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.026784
  validation loss:		0.404128
  validation accuracy:		92.17 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.025722
  validation loss:		0.410137
  validation accuracy:		91.96 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.026557
  validation loss:		0.403701
  validation accuracy:		92.17 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.027324
  validation loss:		0.420881
  validation accuracy:		91.85 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.026291
  validation loss:		0.421824
  validation accuracy:		91.85 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.026296
  validation loss:		0.408697
  validation accuracy:		92.39 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.025533
  validation loss:		0.406325
  validation accuracy:		92.17 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.026943
  validation loss:		0.405605
  validation accuracy:		92.50 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.026780
  validation loss:		0.400566
  validation accuracy:		92.39 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.025566
  validation loss:		0.410805
  validation accuracy:		92.28 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.026013
  validation loss:		0.402301
  validation accuracy:		92.07 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.026341
  validation loss:		0.396459
  validation accuracy:		92.39 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.026467
  validation loss:		0.405632
  validation accuracy:		92.28 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.026909
  validation loss:		0.414254
  validation accuracy:		92.07 %
Epoch 805 of 2000 took 0.036s
  training loss:		0.026582
  validation loss:		0.410892
  validation accuracy:		92.17 %
Epoch 806 of 2000 took 0.036s
  training loss:		0.025926
  validation loss:		0.400911
  validation accuracy:		92.72 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.026695
  validation loss:		0.411647
  validation accuracy:		92.17 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.025975
  validation loss:		0.410940
  validation accuracy:		92.28 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.024390
  validation loss:		0.408098
  validation accuracy:		92.17 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.025678
  validation loss:		0.407146
  validation accuracy:		92.07 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.025076
  validation loss:		0.414975
  validation accuracy:		92.07 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.025960
  validation loss:		0.416513
  validation accuracy:		92.17 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.025710
  validation loss:		0.402594
  validation accuracy:		92.50 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.024403
  validation loss:		0.405480
  validation accuracy:		92.39 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.025689
  validation loss:		0.411845
  validation accuracy:		91.96 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.024815
  validation loss:		0.405041
  validation accuracy:		92.39 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.021969
  validation loss:		0.415505
  validation accuracy:		92.17 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.025768
  validation loss:		0.401694
  validation accuracy:		92.61 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.025524
  validation loss:		0.429316
  validation accuracy:		91.96 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.025304
  validation loss:		0.422641
  validation accuracy:		91.85 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.025906
  validation loss:		0.407587
  validation accuracy:		92.39 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.025021
  validation loss:		0.406353
  validation accuracy:		92.28 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.025272
  validation loss:		0.412332
  validation accuracy:		92.39 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.024623
  validation loss:		0.412096
  validation accuracy:		92.39 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.024360
  validation loss:		0.407136
  validation accuracy:		92.39 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.024515
  validation loss:		0.401984
  validation accuracy:		92.83 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.024521
  validation loss:		0.414529
  validation accuracy:		92.07 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.024525
  validation loss:		0.419292
  validation accuracy:		92.28 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.024929
  validation loss:		0.428978
  validation accuracy:		91.96 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.024036
  validation loss:		0.421947
  validation accuracy:		92.17 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.023453
  validation loss:		0.425494
  validation accuracy:		91.96 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.024949
  validation loss:		0.420040
  validation accuracy:		92.28 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.024969
  validation loss:		0.412514
  validation accuracy:		92.07 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.024152
  validation loss:		0.419208
  validation accuracy:		92.07 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.023520
  validation loss:		0.422915
  validation accuracy:		91.85 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.021984
  validation loss:		0.419852
  validation accuracy:		92.28 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.023359
  validation loss:		0.425458
  validation accuracy:		91.96 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.023838
  validation loss:		0.424845
  validation accuracy:		92.28 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.023365
  validation loss:		0.418734
  validation accuracy:		92.07 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.023998
  validation loss:		0.408493
  validation accuracy:		92.28 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.023794
  validation loss:		0.422994
  validation accuracy:		92.17 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.022924
  validation loss:		0.424217
  validation accuracy:		91.96 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.022959
  validation loss:		0.427349
  validation accuracy:		92.07 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.023527
  validation loss:		0.418616
  validation accuracy:		92.28 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.022112
  validation loss:		0.422935
  validation accuracy:		91.96 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.023060
  validation loss:		0.422060
  validation accuracy:		92.28 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.023180
  validation loss:		0.414260
  validation accuracy:		92.50 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.023705
  validation loss:		0.421531
  validation accuracy:		92.17 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.022767
  validation loss:		0.421590
  validation accuracy:		92.39 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.023280
  validation loss:		0.433695
  validation accuracy:		91.96 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.023158
  validation loss:		0.419171
  validation accuracy:		92.28 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.022858
  validation loss:		0.423953
  validation accuracy:		92.28 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.022893
  validation loss:		0.426649
  validation accuracy:		92.07 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.022847
  validation loss:		0.421551
  validation accuracy:		92.50 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.020447
  validation loss:		0.414110
  validation accuracy:		92.39 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.022711
  validation loss:		0.428025
  validation accuracy:		92.07 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.022313
  validation loss:		0.415865
  validation accuracy:		92.28 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.023072
  validation loss:		0.432605
  validation accuracy:		92.07 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.022783
  validation loss:		0.418020
  validation accuracy:		92.72 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.020279
  validation loss:		0.443138
  validation accuracy:		91.63 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.023094
  validation loss:		0.428076
  validation accuracy:		91.96 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.022198
  validation loss:		0.427485
  validation accuracy:		92.07 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.022683
  validation loss:		0.433927
  validation accuracy:		91.96 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.020735
  validation loss:		0.422146
  validation accuracy:		92.39 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.022186
  validation loss:		0.427922
  validation accuracy:		92.07 %
Epoch 866 of 2000 took 0.036s
  training loss:		0.022083
  validation loss:		0.416254
  validation accuracy:		92.50 %
Epoch 867 of 2000 took 0.036s
  training loss:		0.022245
  validation loss:		0.412757
  validation accuracy:		92.83 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.021765
  validation loss:		0.432092
  validation accuracy:		92.17 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.021830
  validation loss:		0.429250
  validation accuracy:		91.96 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.021244
  validation loss:		0.423107
  validation accuracy:		92.39 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.021819
  validation loss:		0.423246
  validation accuracy:		92.50 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.022611
  validation loss:		0.424887
  validation accuracy:		92.28 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.021780
  validation loss:		0.427172
  validation accuracy:		92.17 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.021331
  validation loss:		0.431974
  validation accuracy:		91.96 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.021994
  validation loss:		0.434551
  validation accuracy:		92.28 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.021926
  validation loss:		0.427709
  validation accuracy:		92.28 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.021525
  validation loss:		0.430710
  validation accuracy:		92.17 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.020924
  validation loss:		0.437310
  validation accuracy:		91.85 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.021167
  validation loss:		0.441996
  validation accuracy:		91.85 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.021018
  validation loss:		0.451817
  validation accuracy:		91.52 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.021931
  validation loss:		0.437232
  validation accuracy:		92.17 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.021637
  validation loss:		0.427118
  validation accuracy:		92.07 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.020860
  validation loss:		0.437986
  validation accuracy:		91.96 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.021436
  validation loss:		0.448841
  validation accuracy:		91.85 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.020593
  validation loss:		0.433635
  validation accuracy:		92.17 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021090
  validation loss:		0.448946
  validation accuracy:		91.85 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.019132
  validation loss:		0.436132
  validation accuracy:		92.07 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.017881
  validation loss:		0.445726
  validation accuracy:		91.85 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.020159
  validation loss:		0.426886
  validation accuracy:		92.39 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.019955
  validation loss:		0.431939
  validation accuracy:		92.50 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.020624
  validation loss:		0.453589
  validation accuracy:		91.52 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.020235
  validation loss:		0.433759
  validation accuracy:		92.17 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.019956
  validation loss:		0.443231
  validation accuracy:		91.63 %
Epoch 894 of 2000 took 0.036s
  training loss:		0.020776
  validation loss:		0.436167
  validation accuracy:		92.50 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.019829
  validation loss:		0.436331
  validation accuracy:		92.07 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.020449
  validation loss:		0.435164
  validation accuracy:		92.07 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.020323
  validation loss:		0.437530
  validation accuracy:		92.17 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.019755
  validation loss:		0.424128
  validation accuracy:		92.61 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.019597
  validation loss:		0.437711
  validation accuracy:		92.07 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.020534
  validation loss:		0.442234
  validation accuracy:		91.96 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.019471
  validation loss:		0.450250
  validation accuracy:		91.85 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.020086
  validation loss:		0.444598
  validation accuracy:		91.85 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.020353
  validation loss:		0.441476
  validation accuracy:		92.17 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.019201
  validation loss:		0.428221
  validation accuracy:		92.28 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.018822
  validation loss:		0.440905
  validation accuracy:		92.07 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.020254
  validation loss:		0.433288
  validation accuracy:		92.50 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.019723
  validation loss:		0.427179
  validation accuracy:		92.28 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.019058
  validation loss:		0.438760
  validation accuracy:		92.50 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.018531
  validation loss:		0.428684
  validation accuracy:		92.72 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.018683
  validation loss:		0.443337
  validation accuracy:		92.17 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.020090
  validation loss:		0.440363
  validation accuracy:		92.07 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.019777
  validation loss:		0.451800
  validation accuracy:		91.96 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.019483
  validation loss:		0.443390
  validation accuracy:		92.28 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.019490
  validation loss:		0.436298
  validation accuracy:		91.96 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.019400
  validation loss:		0.437788
  validation accuracy:		92.17 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.019743
  validation loss:		0.437057
  validation accuracy:		91.85 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.018806
  validation loss:		0.448449
  validation accuracy:		91.96 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.019980
  validation loss:		0.440372
  validation accuracy:		92.28 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.018139
  validation loss:		0.439715
  validation accuracy:		92.17 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.018763
  validation loss:		0.445130
  validation accuracy:		92.07 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.018553
  validation loss:		0.438318
  validation accuracy:		92.39 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.018776
  validation loss:		0.444452
  validation accuracy:		92.07 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.018426
  validation loss:		0.437167
  validation accuracy:		92.39 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.018842
  validation loss:		0.447999
  validation accuracy:		91.96 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.018787
  validation loss:		0.444582
  validation accuracy:		92.17 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.018439
  validation loss:		0.432504
  validation accuracy:		92.28 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.018315
  validation loss:		0.455773
  validation accuracy:		91.85 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.018594
  validation loss:		0.452947
  validation accuracy:		91.96 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.018836
  validation loss:		0.449192
  validation accuracy:		91.96 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.018223
  validation loss:		0.441982
  validation accuracy:		92.07 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.018554
  validation loss:		0.438686
  validation accuracy:		92.50 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.016812
  validation loss:		0.437020
  validation accuracy:		92.17 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.018945
  validation loss:		0.444362
  validation accuracy:		92.07 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.018703
  validation loss:		0.444768
  validation accuracy:		92.50 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.017499
  validation loss:		0.437719
  validation accuracy:		92.28 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.018508
  validation loss:		0.466685
  validation accuracy:		91.74 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.018113
  validation loss:		0.455763
  validation accuracy:		91.74 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.017579
  validation loss:		0.448345
  validation accuracy:		91.85 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.018463
  validation loss:		0.456735
  validation accuracy:		91.63 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.016151
  validation loss:		0.438851
  validation accuracy:		92.39 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.017808
  validation loss:		0.447686
  validation accuracy:		91.96 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.018509
  validation loss:		0.458506
  validation accuracy:		91.63 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.018683
  validation loss:		0.441320
  validation accuracy:		92.28 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.018346
  validation loss:		0.450869
  validation accuracy:		91.96 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.018090
  validation loss:		0.462537
  validation accuracy:		91.63 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.018443
  validation loss:		0.437637
  validation accuracy:		92.50 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.017987
  validation loss:		0.448895
  validation accuracy:		91.96 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.017520
  validation loss:		0.453346
  validation accuracy:		92.07 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.017978
  validation loss:		0.463127
  validation accuracy:		91.74 %
Epoch 950 of 2000 took 0.036s
  training loss:		0.017421
  validation loss:		0.453844
  validation accuracy:		91.85 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.017788
  validation loss:		0.450856
  validation accuracy:		91.85 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.017649
  validation loss:		0.454257
  validation accuracy:		92.07 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.017459
  validation loss:		0.446861
  validation accuracy:		92.17 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.017733
  validation loss:		0.444229
  validation accuracy:		92.39 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.018379
  validation loss:		0.451969
  validation accuracy:		91.85 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.017860
  validation loss:		0.454834
  validation accuracy:		91.63 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.017699
  validation loss:		0.456907
  validation accuracy:		91.74 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.017335
  validation loss:		0.459422
  validation accuracy:		91.96 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.017477
  validation loss:		0.443568
  validation accuracy:		91.96 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.017751
  validation loss:		0.453375
  validation accuracy:		91.85 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.017433
  validation loss:		0.445723
  validation accuracy:		92.50 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.017662
  validation loss:		0.469299
  validation accuracy:		91.63 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.016915
  validation loss:		0.449787
  validation accuracy:		91.96 %
Epoch 964 of 2000 took 0.037s
  training loss:		0.017145
  validation loss:		0.462479
  validation accuracy:		91.52 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.017461
  validation loss:		0.444006
  validation accuracy:		92.72 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.016934
  validation loss:		0.456604
  validation accuracy:		91.74 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.017020
  validation loss:		0.448012
  validation accuracy:		92.28 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.016788
  validation loss:		0.452274
  validation accuracy:		91.96 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.015344
  validation loss:		0.447733
  validation accuracy:		91.96 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.016440
  validation loss:		0.456535
  validation accuracy:		92.07 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.017038
  validation loss:		0.454365
  validation accuracy:		91.74 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.016393
  validation loss:		0.469160
  validation accuracy:		91.63 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.016556
  validation loss:		0.478820
  validation accuracy:		91.74 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.015886
  validation loss:		0.457842
  validation accuracy:		91.52 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.017133
  validation loss:		0.453289
  validation accuracy:		91.85 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.017023
  validation loss:		0.447394
  validation accuracy:		92.50 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.016969
  validation loss:		0.463249
  validation accuracy:		92.07 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.015895
  validation loss:		0.456180
  validation accuracy:		91.74 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.016232
  validation loss:		0.476717
  validation accuracy:		91.74 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.016775
  validation loss:		0.472278
  validation accuracy:		91.63 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.016692
  validation loss:		0.458222
  validation accuracy:		91.85 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.016409
  validation loss:		0.471485
  validation accuracy:		91.85 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.017046
  validation loss:		0.470676
  validation accuracy:		91.52 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.016629
  validation loss:		0.451722
  validation accuracy:		92.17 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.016436
  validation loss:		0.466770
  validation accuracy:		91.74 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.016188
  validation loss:		0.470648
  validation accuracy:		91.52 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.016392
  validation loss:		0.465637
  validation accuracy:		92.07 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.016078
  validation loss:		0.464248
  validation accuracy:		91.63 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.016010
  validation loss:		0.477732
  validation accuracy:		91.85 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.016672
  validation loss:		0.460721
  validation accuracy:		92.07 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.015898
  validation loss:		0.461698
  validation accuracy:		91.85 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016174
  validation loss:		0.472426
  validation accuracy:		91.74 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.015035
  validation loss:		0.464238
  validation accuracy:		91.85 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016109
  validation loss:		0.459593
  validation accuracy:		92.17 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.016243
  validation loss:		0.464489
  validation accuracy:		91.85 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.015975
  validation loss:		0.454585
  validation accuracy:		92.17 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.016205
  validation loss:		0.470508
  validation accuracy:		91.52 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.015578
  validation loss:		0.469321
  validation accuracy:		91.85 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016000
  validation loss:		0.482489
  validation accuracy:		91.52 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.015535
  validation loss:		0.462887
  validation accuracy:		91.63 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.015800
  validation loss:		0.462845
  validation accuracy:		92.39 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.015483
  validation loss:		0.463164
  validation accuracy:		91.63 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.016173
  validation loss:		0.464922
  validation accuracy:		92.28 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.014985
  validation loss:		0.467845
  validation accuracy:		91.85 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.014468
  validation loss:		0.471299
  validation accuracy:		91.63 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.015602
  validation loss:		0.461054
  validation accuracy:		92.28 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.014774
  validation loss:		0.477507
  validation accuracy:		91.74 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.014763
  validation loss:		0.482024
  validation accuracy:		91.74 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.015019
  validation loss:		0.484549
  validation accuracy:		91.63 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.014681
  validation loss:		0.470892
  validation accuracy:		91.85 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.015413
  validation loss:		0.470039
  validation accuracy:		91.52 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.015579
  validation loss:		0.466361
  validation accuracy:		92.07 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.015266
  validation loss:		0.464317
  validation accuracy:		92.28 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.015227
  validation loss:		0.463280
  validation accuracy:		91.85 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.015270
  validation loss:		0.474139
  validation accuracy:		91.74 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.014415
  validation loss:		0.466272
  validation accuracy:		91.96 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.014851
  validation loss:		0.489356
  validation accuracy:		91.52 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.015125
  validation loss:		0.481886
  validation accuracy:		91.74 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.015500
  validation loss:		0.474382
  validation accuracy:		91.52 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.014956
  validation loss:		0.476280
  validation accuracy:		91.52 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.015322
  validation loss:		0.476154
  validation accuracy:		91.85 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.014983
  validation loss:		0.483451
  validation accuracy:		91.74 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.015313
  validation loss:		0.481143
  validation accuracy:		91.41 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.014939
  validation loss:		0.470754
  validation accuracy:		91.85 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.014710
  validation loss:		0.475066
  validation accuracy:		91.74 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.014712
  validation loss:		0.483654
  validation accuracy:		91.74 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.014784
  validation loss:		0.472845
  validation accuracy:		91.74 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.013676
  validation loss:		0.475473
  validation accuracy:		91.74 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.014287
  validation loss:		0.476446
  validation accuracy:		91.63 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.014567
  validation loss:		0.464739
  validation accuracy:		92.17 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.014073
  validation loss:		0.490909
  validation accuracy:		91.52 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.014300
  validation loss:		0.485276
  validation accuracy:		91.41 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.014230
  validation loss:		0.478250
  validation accuracy:		91.74 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.014589
  validation loss:		0.476504
  validation accuracy:		91.63 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.013866
  validation loss:		0.473734
  validation accuracy:		91.74 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.013650
  validation loss:		0.476231
  validation accuracy:		91.96 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.014321
  validation loss:		0.475207
  validation accuracy:		91.74 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.013635
  validation loss:		0.476268
  validation accuracy:		91.52 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.013924
  validation loss:		0.484445
  validation accuracy:		91.30 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.014262
  validation loss:		0.476644
  validation accuracy:		91.63 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.013633
  validation loss:		0.479458
  validation accuracy:		91.85 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.014376
  validation loss:		0.477285
  validation accuracy:		91.74 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.013957
  validation loss:		0.479923
  validation accuracy:		92.07 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.014390
  validation loss:		0.484198
  validation accuracy:		91.63 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.014039
  validation loss:		0.483992
  validation accuracy:		91.52 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.013795
  validation loss:		0.468943
  validation accuracy:		91.96 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.014431
  validation loss:		0.477654
  validation accuracy:		91.52 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.013918
  validation loss:		0.489915
  validation accuracy:		91.63 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.013608
  validation loss:		0.486521
  validation accuracy:		91.63 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.014114
  validation loss:		0.472047
  validation accuracy:		92.28 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.014027
  validation loss:		0.481805
  validation accuracy:		91.52 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.013990
  validation loss:		0.477581
  validation accuracy:		92.07 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.013959
  validation loss:		0.482567
  validation accuracy:		91.41 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.013583
  validation loss:		0.485522
  validation accuracy:		92.28 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.014161
  validation loss:		0.479384
  validation accuracy:		91.52 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.013294
  validation loss:		0.496641
  validation accuracy:		91.63 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.013655
  validation loss:		0.480773
  validation accuracy:		91.85 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.013484
  validation loss:		0.486788
  validation accuracy:		91.74 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.013248
  validation loss:		0.485171
  validation accuracy:		91.74 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.013193
  validation loss:		0.493594
  validation accuracy:		91.74 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.013815
  validation loss:		0.477937
  validation accuracy:		91.96 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.013342
  validation loss:		0.492736
  validation accuracy:		91.74 %
Epoch 1063 of 2000 took 0.036s
  training loss:		0.013260
  validation loss:		0.477160
  validation accuracy:		92.07 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.013100
  validation loss:		0.497858
  validation accuracy:		91.30 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.013266
  validation loss:		0.488845
  validation accuracy:		91.85 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.013460
  validation loss:		0.483879
  validation accuracy:		91.52 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.012491
  validation loss:		0.490432
  validation accuracy:		91.52 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.012228
  validation loss:		0.495732
  validation accuracy:		91.52 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.013195
  validation loss:		0.495935
  validation accuracy:		91.85 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.013499
  validation loss:		0.480298
  validation accuracy:		91.52 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013471
  validation loss:		0.492663
  validation accuracy:		91.85 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.012792
  validation loss:		0.490730
  validation accuracy:		91.74 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.012840
  validation loss:		0.502777
  validation accuracy:		91.63 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.013277
  validation loss:		0.492319
  validation accuracy:		91.74 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.012698
  validation loss:		0.484489
  validation accuracy:		91.52 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.012331
  validation loss:		0.492209
  validation accuracy:		91.85 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.012984
  validation loss:		0.485057
  validation accuracy:		91.74 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.012741
  validation loss:		0.490755
  validation accuracy:		91.74 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.012476
  validation loss:		0.474844
  validation accuracy:		92.28 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013058
  validation loss:		0.490505
  validation accuracy:		91.74 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.013005
  validation loss:		0.486910
  validation accuracy:		92.07 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.013011
  validation loss:		0.490502
  validation accuracy:		91.52 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.012168
  validation loss:		0.489974
  validation accuracy:		91.74 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.012647
  validation loss:		0.484920
  validation accuracy:		91.52 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.012941
  validation loss:		0.496267
  validation accuracy:		91.63 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.012908
  validation loss:		0.498523
  validation accuracy:		91.52 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.012570
  validation loss:		0.489648
  validation accuracy:		91.96 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.013056
  validation loss:		0.488922
  validation accuracy:		92.28 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.012786
  validation loss:		0.503433
  validation accuracy:		91.41 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.012678
  validation loss:		0.488244
  validation accuracy:		91.63 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.012815
  validation loss:		0.502746
  validation accuracy:		91.74 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.012199
  validation loss:		0.499225
  validation accuracy:		91.30 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.012697
  validation loss:		0.492470
  validation accuracy:		92.07 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.012588
  validation loss:		0.496490
  validation accuracy:		91.41 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.011829
  validation loss:		0.506368
  validation accuracy:		91.85 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.011194
  validation loss:		0.506155
  validation accuracy:		91.41 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.012143
  validation loss:		0.492785
  validation accuracy:		91.63 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012246
  validation loss:		0.498381
  validation accuracy:		91.63 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.012228
  validation loss:		0.491825
  validation accuracy:		91.52 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.012438
  validation loss:		0.504729
  validation accuracy:		91.30 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.012179
  validation loss:		0.490898
  validation accuracy:		91.74 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.012591
  validation loss:		0.487223
  validation accuracy:		92.17 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.012307
  validation loss:		0.507904
  validation accuracy:		91.52 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.012092
  validation loss:		0.496593
  validation accuracy:		91.85 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.011843
  validation loss:		0.498059
  validation accuracy:		91.96 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.011919
  validation loss:		0.497770
  validation accuracy:		91.52 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.012133
  validation loss:		0.507277
  validation accuracy:		91.74 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.012339
  validation loss:		0.501388
  validation accuracy:		91.20 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012022
  validation loss:		0.493154
  validation accuracy:		92.28 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.012036
  validation loss:		0.506732
  validation accuracy:		91.41 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.012055
  validation loss:		0.493735
  validation accuracy:		91.63 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.012188
  validation loss:		0.515117
  validation accuracy:		91.63 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.011867
  validation loss:		0.485568
  validation accuracy:		92.07 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.012508
  validation loss:		0.492212
  validation accuracy:		91.96 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.011260
  validation loss:		0.501105
  validation accuracy:		91.52 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.012024
  validation loss:		0.485771
  validation accuracy:		92.39 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.012015
  validation loss:		0.513499
  validation accuracy:		91.41 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.011725
  validation loss:		0.499617
  validation accuracy:		91.85 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.011718
  validation loss:		0.503471
  validation accuracy:		91.52 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.011676
  validation loss:		0.488604
  validation accuracy:		92.50 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.011753
  validation loss:		0.496315
  validation accuracy:		91.63 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.011381
  validation loss:		0.495898
  validation accuracy:		91.96 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.011416
  validation loss:		0.505454
  validation accuracy:		91.63 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.011504
  validation loss:		0.509004
  validation accuracy:		91.52 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.011840
  validation loss:		0.497264
  validation accuracy:		91.74 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.011150
  validation loss:		0.511242
  validation accuracy:		91.63 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.011346
  validation loss:		0.507093
  validation accuracy:		91.74 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.011207
  validation loss:		0.501184
  validation accuracy:		91.63 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.011456
  validation loss:		0.492498
  validation accuracy:		92.28 %
Epoch 1130 of 2000 took 0.036s
  training loss:		0.011392
  validation loss:		0.510981
  validation accuracy:		91.74 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.011390
  validation loss:		0.514572
  validation accuracy:		91.41 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.011054
  validation loss:		0.501995
  validation accuracy:		91.74 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.011140
  validation loss:		0.503713
  validation accuracy:		91.74 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.011860
  validation loss:		0.494620
  validation accuracy:		92.07 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011533
  validation loss:		0.494157
  validation accuracy:		92.72 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.010808
  validation loss:		0.498385
  validation accuracy:		91.85 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.011059
  validation loss:		0.511553
  validation accuracy:		91.52 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.011013
  validation loss:		0.517940
  validation accuracy:		91.52 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011036
  validation loss:		0.499538
  validation accuracy:		91.96 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011205
  validation loss:		0.505428
  validation accuracy:		91.85 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.010764
  validation loss:		0.504661
  validation accuracy:		91.52 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.011159
  validation loss:		0.518459
  validation accuracy:		91.85 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.010815
  validation loss:		0.507320
  validation accuracy:		91.52 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.011048
  validation loss:		0.509486
  validation accuracy:		91.30 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.010812
  validation loss:		0.503281
  validation accuracy:		91.85 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.010699
  validation loss:		0.514912
  validation accuracy:		91.52 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.011004
  validation loss:		0.502646
  validation accuracy:		92.07 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.010754
  validation loss:		0.503910
  validation accuracy:		91.52 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.010800
  validation loss:		0.518516
  validation accuracy:		91.74 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.011027
  validation loss:		0.511539
  validation accuracy:		91.74 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.010529
  validation loss:		0.506792
  validation accuracy:		91.96 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.010457
  validation loss:		0.514112
  validation accuracy:		91.63 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.010855
  validation loss:		0.502636
  validation accuracy:		91.74 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.010114
  validation loss:		0.518774
  validation accuracy:		91.63 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.010534
  validation loss:		0.525623
  validation accuracy:		91.52 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.010549
  validation loss:		0.500337
  validation accuracy:		91.96 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.010839
  validation loss:		0.526261
  validation accuracy:		91.52 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011265
  validation loss:		0.507873
  validation accuracy:		91.41 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.010487
  validation loss:		0.521820
  validation accuracy:		91.41 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.010571
  validation loss:		0.523101
  validation accuracy:		91.41 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.010516
  validation loss:		0.519485
  validation accuracy:		91.41 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.010049
  validation loss:		0.510280
  validation accuracy:		91.85 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.009817
  validation loss:		0.512392
  validation accuracy:		91.30 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.010371
  validation loss:		0.515490
  validation accuracy:		91.63 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.010439
  validation loss:		0.510209
  validation accuracy:		91.63 %
Epoch 1166 of 2000 took 0.036s
  training loss:		0.009901
  validation loss:		0.512708
  validation accuracy:		91.63 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.010090
  validation loss:		0.514792
  validation accuracy:		91.52 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.010322
  validation loss:		0.508352
  validation accuracy:		91.85 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.010139
  validation loss:		0.521254
  validation accuracy:		91.63 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.010190
  validation loss:		0.505670
  validation accuracy:		91.85 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.009479
  validation loss:		0.520599
  validation accuracy:		91.41 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.009990
  validation loss:		0.514682
  validation accuracy:		91.74 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.010044
  validation loss:		0.517403
  validation accuracy:		91.74 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.010070
  validation loss:		0.515037
  validation accuracy:		91.74 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010315
  validation loss:		0.529022
  validation accuracy:		91.63 %
Epoch 1176 of 2000 took 0.036s
  training loss:		0.010330
  validation loss:		0.519344
  validation accuracy:		91.52 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.009945
  validation loss:		0.524715
  validation accuracy:		91.63 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.009462
  validation loss:		0.518767
  validation accuracy:		91.52 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.009959
  validation loss:		0.515502
  validation accuracy:		91.74 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.009818
  validation loss:		0.526994
  validation accuracy:		91.96 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010532
  validation loss:		0.512524
  validation accuracy:		91.74 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.009909
  validation loss:		0.518307
  validation accuracy:		91.63 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.010238
  validation loss:		0.507325
  validation accuracy:		91.85 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010003
  validation loss:		0.525260
  validation accuracy:		91.63 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010124
  validation loss:		0.530289
  validation accuracy:		91.30 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.009986
  validation loss:		0.520636
  validation accuracy:		91.85 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.009093
  validation loss:		0.510112
  validation accuracy:		91.96 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.009632
  validation loss:		0.534306
  validation accuracy:		91.52 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.009647
  validation loss:		0.519261
  validation accuracy:		91.74 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.009815
  validation loss:		0.516863
  validation accuracy:		91.85 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.009323
  validation loss:		0.520729
  validation accuracy:		91.63 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.009475
  validation loss:		0.528491
  validation accuracy:		91.30 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.009873
  validation loss:		0.536342
  validation accuracy:		91.52 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.009762
  validation loss:		0.527853
  validation accuracy:		91.41 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.009491
  validation loss:		0.522379
  validation accuracy:		91.63 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.009019
  validation loss:		0.514795
  validation accuracy:		91.74 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.009846
  validation loss:		0.535761
  validation accuracy:		91.41 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.009978
  validation loss:		0.524352
  validation accuracy:		91.74 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.009677
  validation loss:		0.531221
  validation accuracy:		91.30 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.009429
  validation loss:		0.519005
  validation accuracy:		91.96 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.009301
  validation loss:		0.521923
  validation accuracy:		91.41 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.009804
  validation loss:		0.526919
  validation accuracy:		91.30 %
Epoch 1203 of 2000 took 0.036s
  training loss:		0.009271
  validation loss:		0.522794
  validation accuracy:		92.17 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.009394
  validation loss:		0.527382
  validation accuracy:		91.30 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.009555
  validation loss:		0.519266
  validation accuracy:		91.74 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.009564
  validation loss:		0.525563
  validation accuracy:		91.52 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.009133
  validation loss:		0.527708
  validation accuracy:		91.63 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.009522
  validation loss:		0.530347
  validation accuracy:		91.96 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.009094
  validation loss:		0.535269
  validation accuracy:		91.41 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.009720
  validation loss:		0.546903
  validation accuracy:		91.52 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.009185
  validation loss:		0.528950
  validation accuracy:		91.30 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.008808
  validation loss:		0.519552
  validation accuracy:		91.85 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.009313
  validation loss:		0.520368
  validation accuracy:		92.17 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.009517
  validation loss:		0.525301
  validation accuracy:		91.74 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009050
  validation loss:		0.522220
  validation accuracy:		92.28 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.009463
  validation loss:		0.527014
  validation accuracy:		92.07 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.009597
  validation loss:		0.520865
  validation accuracy:		91.96 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.009213
  validation loss:		0.532581
  validation accuracy:		91.63 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.009245
  validation loss:		0.526189
  validation accuracy:		91.85 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009168
  validation loss:		0.516571
  validation accuracy:		92.07 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.009250
  validation loss:		0.528264
  validation accuracy:		91.74 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.008937
  validation loss:		0.524495
  validation accuracy:		91.96 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.008999
  validation loss:		0.525491
  validation accuracy:		91.74 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.008738
  validation loss:		0.525285
  validation accuracy:		91.85 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009402
  validation loss:		0.529257
  validation accuracy:		92.07 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009226
  validation loss:		0.533313
  validation accuracy:		91.41 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.009035
  validation loss:		0.540404
  validation accuracy:		91.20 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.008990
  validation loss:		0.537792
  validation accuracy:		91.30 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.008961
  validation loss:		0.537728
  validation accuracy:		91.52 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.008829
  validation loss:		0.538529
  validation accuracy:		91.30 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009009
  validation loss:		0.544486
  validation accuracy:		91.30 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.009153
  validation loss:		0.526480
  validation accuracy:		91.52 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.008485
  validation loss:		0.522850
  validation accuracy:		92.17 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009113
  validation loss:		0.529486
  validation accuracy:		91.41 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.008613
  validation loss:		0.535611
  validation accuracy:		91.96 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.008663
  validation loss:		0.541905
  validation accuracy:		91.30 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009142
  validation loss:		0.544376
  validation accuracy:		91.30 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.008788
  validation loss:		0.539753
  validation accuracy:		91.52 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009240
  validation loss:		0.533087
  validation accuracy:		91.85 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.008842
  validation loss:		0.538668
  validation accuracy:		91.52 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.008774
  validation loss:		0.540092
  validation accuracy:		91.85 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.008702
  validation loss:		0.529394
  validation accuracy:		91.63 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.008472
  validation loss:		0.535149
  validation accuracy:		91.96 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.008666
  validation loss:		0.546339
  validation accuracy:		91.30 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.008435
  validation loss:		0.525074
  validation accuracy:		91.85 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.008361
  validation loss:		0.546756
  validation accuracy:		91.52 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.009037
  validation loss:		0.532244
  validation accuracy:		91.63 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.008452
  validation loss:		0.554119
  validation accuracy:		91.09 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.008787
  validation loss:		0.540314
  validation accuracy:		91.41 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.008806
  validation loss:		0.543332
  validation accuracy:		91.85 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.008556
  validation loss:		0.534935
  validation accuracy:		91.85 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.008661
  validation loss:		0.537285
  validation accuracy:		91.63 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.008296
  validation loss:		0.544768
  validation accuracy:		91.30 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.008576
  validation loss:		0.545237
  validation accuracy:		91.85 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.008372
  validation loss:		0.537635
  validation accuracy:		91.85 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.008016
  validation loss:		0.532830
  validation accuracy:		91.63 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.008370
  validation loss:		0.534610
  validation accuracy:		91.74 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.008587
  validation loss:		0.539923
  validation accuracy:		91.74 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.007977
  validation loss:		0.544414
  validation accuracy:		91.63 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.008086
  validation loss:		0.541960
  validation accuracy:		91.63 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.008295
  validation loss:		0.543804
  validation accuracy:		91.30 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.008065
  validation loss:		0.547407
  validation accuracy:		91.63 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.008386
  validation loss:		0.536299
  validation accuracy:		91.85 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.008474
  validation loss:		0.540825
  validation accuracy:		91.41 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.007845
  validation loss:		0.533411
  validation accuracy:		91.96 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.007968
  validation loss:		0.538835
  validation accuracy:		91.74 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.008162
  validation loss:		0.542305
  validation accuracy:		91.74 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008208
  validation loss:		0.531580
  validation accuracy:		92.07 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.008100
  validation loss:		0.547268
  validation accuracy:		91.74 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.008156
  validation loss:		0.548207
  validation accuracy:		91.30 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008581
  validation loss:		0.551148
  validation accuracy:		91.52 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008099
  validation loss:		0.538666
  validation accuracy:		91.41 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008317
  validation loss:		0.551461
  validation accuracy:		91.52 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.007809
  validation loss:		0.537614
  validation accuracy:		91.63 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008272
  validation loss:		0.545624
  validation accuracy:		91.63 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008228
  validation loss:		0.540060
  validation accuracy:		91.85 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.008129
  validation loss:		0.547071
  validation accuracy:		91.74 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.007753
  validation loss:		0.553208
  validation accuracy:		91.30 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008100
  validation loss:		0.550826
  validation accuracy:		91.52 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008210
  validation loss:		0.542197
  validation accuracy:		91.63 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.008004
  validation loss:		0.546709
  validation accuracy:		91.63 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008007
  validation loss:		0.538606
  validation accuracy:		91.52 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.007836
  validation loss:		0.556566
  validation accuracy:		91.74 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008134
  validation loss:		0.546026
  validation accuracy:		91.30 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.007838
  validation loss:		0.548111
  validation accuracy:		91.52 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.007770
  validation loss:		0.549235
  validation accuracy:		91.63 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.007651
  validation loss:		0.543729
  validation accuracy:		91.96 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.007450
  validation loss:		0.544082
  validation accuracy:		91.74 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.007688
  validation loss:		0.550671
  validation accuracy:		91.63 %
Epoch 1290 of 2000 took 0.036s
  training loss:		0.007686
  validation loss:		0.549855
  validation accuracy:		91.52 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.007511
  validation loss:		0.537691
  validation accuracy:		91.85 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008030
  validation loss:		0.552016
  validation accuracy:		91.63 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.007710
  validation loss:		0.550108
  validation accuracy:		91.41 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.007791
  validation loss:		0.557651
  validation accuracy:		91.30 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.555387
  validation accuracy:		91.74 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.007632
  validation loss:		0.541676
  validation accuracy:		91.63 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.007650
  validation loss:		0.543303
  validation accuracy:		92.07 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.007674
  validation loss:		0.552567
  validation accuracy:		91.63 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.007771
  validation loss:		0.550064
  validation accuracy:		91.52 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.007744
  validation loss:		0.549215
  validation accuracy:		91.63 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.007813
  validation loss:		0.550307
  validation accuracy:		91.41 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.007719
  validation loss:		0.552763
  validation accuracy:		91.63 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.007247
  validation loss:		0.546356
  validation accuracy:		91.85 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.007705
  validation loss:		0.544424
  validation accuracy:		91.96 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.007720
  validation loss:		0.555032
  validation accuracy:		91.74 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.007380
  validation loss:		0.550230
  validation accuracy:		91.74 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.007356
  validation loss:		0.553263
  validation accuracy:		91.52 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.007360
  validation loss:		0.551189
  validation accuracy:		91.41 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.007609
  validation loss:		0.554156
  validation accuracy:		91.74 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.007625
  validation loss:		0.549276
  validation accuracy:		91.85 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.007260
  validation loss:		0.555986
  validation accuracy:		91.74 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.007318
  validation loss:		0.548354
  validation accuracy:		91.52 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.007335
  validation loss:		0.556711
  validation accuracy:		91.63 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.007268
  validation loss:		0.548986
  validation accuracy:		91.52 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.007198
  validation loss:		0.555814
  validation accuracy:		91.41 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.007220
  validation loss:		0.551428
  validation accuracy:		91.52 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.007114
  validation loss:		0.549550
  validation accuracy:		91.63 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.007368
  validation loss:		0.547058
  validation accuracy:		91.74 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.007182
  validation loss:		0.551703
  validation accuracy:		91.85 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.006850
  validation loss:		0.552009
  validation accuracy:		91.52 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.007276
  validation loss:		0.558188
  validation accuracy:		91.52 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.007095
  validation loss:		0.561004
  validation accuracy:		91.30 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007132
  validation loss:		0.562450
  validation accuracy:		91.41 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.007320
  validation loss:		0.559135
  validation accuracy:		91.63 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.007200
  validation loss:		0.559243
  validation accuracy:		91.63 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.007366
  validation loss:		0.559945
  validation accuracy:		91.30 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.007113
  validation loss:		0.552128
  validation accuracy:		91.63 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.006975
  validation loss:		0.559227
  validation accuracy:		91.41 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.006898
  validation loss:		0.553868
  validation accuracy:		91.74 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.007184
  validation loss:		0.560027
  validation accuracy:		91.41 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.007037
  validation loss:		0.552892
  validation accuracy:		91.74 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.006827
  validation loss:		0.556226
  validation accuracy:		91.74 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.006807
  validation loss:		0.567819
  validation accuracy:		91.30 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007023
  validation loss:		0.552548
  validation accuracy:		91.96 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.007008
  validation loss:		0.552286
  validation accuracy:		91.85 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.007054
  validation loss:		0.556709
  validation accuracy:		91.85 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007090
  validation loss:		0.552472
  validation accuracy:		91.63 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007151
  validation loss:		0.560235
  validation accuracy:		91.85 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.006563
  validation loss:		0.567613
  validation accuracy:		91.30 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007194
  validation loss:		0.568722
  validation accuracy:		91.30 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.007215
  validation loss:		0.557903
  validation accuracy:		91.30 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.006900
  validation loss:		0.570732
  validation accuracy:		91.30 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007173
  validation loss:		0.563619
  validation accuracy:		91.41 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.006873
  validation loss:		0.557121
  validation accuracy:		91.63 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007065
  validation loss:		0.562604
  validation accuracy:		91.52 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.006793
  validation loss:		0.565548
  validation accuracy:		91.30 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.006723
  validation loss:		0.555245
  validation accuracy:		92.07 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.006850
  validation loss:		0.558417
  validation accuracy:		91.52 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.006717
  validation loss:		0.565956
  validation accuracy:		91.30 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.006700
  validation loss:		0.554457
  validation accuracy:		91.74 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.006769
  validation loss:		0.571414
  validation accuracy:		91.30 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.006817
  validation loss:		0.550065
  validation accuracy:		91.96 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007147
  validation loss:		0.562344
  validation accuracy:		91.52 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.006697
  validation loss:		0.559873
  validation accuracy:		91.85 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.006676
  validation loss:		0.556422
  validation accuracy:		92.07 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.006888
  validation loss:		0.559380
  validation accuracy:		91.74 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.006679
  validation loss:		0.564939
  validation accuracy:		91.41 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.006381
  validation loss:		0.567939
  validation accuracy:		91.41 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.006742
  validation loss:		0.558778
  validation accuracy:		91.74 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.006971
  validation loss:		0.569943
  validation accuracy:		91.41 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.006681
  validation loss:		0.552965
  validation accuracy:		91.85 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.006582
  validation loss:		0.565682
  validation accuracy:		91.74 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.006594
  validation loss:		0.554808
  validation accuracy:		91.85 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.006287
  validation loss:		0.563669
  validation accuracy:		91.85 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.006596
  validation loss:		0.564201
  validation accuracy:		91.63 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.006651
  validation loss:		0.559881
  validation accuracy:		92.17 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.006501
  validation loss:		0.567754
  validation accuracy:		91.41 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.006642
  validation loss:		0.556298
  validation accuracy:		92.07 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.006683
  validation loss:		0.565996
  validation accuracy:		91.52 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.006531
  validation loss:		0.552492
  validation accuracy:		92.17 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.006713
  validation loss:		0.560369
  validation accuracy:		91.96 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.006319
  validation loss:		0.572802
  validation accuracy:		91.20 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.006547
  validation loss:		0.561436
  validation accuracy:		91.74 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.006416
  validation loss:		0.570705
  validation accuracy:		91.41 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.006428
  validation loss:		0.563808
  validation accuracy:		91.52 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.006298
  validation loss:		0.563621
  validation accuracy:		91.85 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.006591
  validation loss:		0.571795
  validation accuracy:		91.41 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.006471
  validation loss:		0.557955
  validation accuracy:		91.96 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.006475
  validation loss:		0.563232
  validation accuracy:		91.63 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.006407
  validation loss:		0.567925
  validation accuracy:		91.63 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.006400
  validation loss:		0.573537
  validation accuracy:		91.63 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.006449
  validation loss:		0.566150
  validation accuracy:		91.85 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.006394
  validation loss:		0.576100
  validation accuracy:		91.52 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.006385
  validation loss:		0.561444
  validation accuracy:		91.85 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.006415
  validation loss:		0.568923
  validation accuracy:		91.96 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.006292
  validation loss:		0.565646
  validation accuracy:		91.85 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006281
  validation loss:		0.570873
  validation accuracy:		91.63 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.006590
  validation loss:		0.572696
  validation accuracy:		91.30 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006462
  validation loss:		0.562339
  validation accuracy:		91.74 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.006548
  validation loss:		0.570439
  validation accuracy:		91.52 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.006422
  validation loss:		0.571870
  validation accuracy:		91.52 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.006146
  validation loss:		0.581278
  validation accuracy:		91.20 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.006281
  validation loss:		0.562510
  validation accuracy:		91.85 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006367
  validation loss:		0.579203
  validation accuracy:		91.20 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.006295
  validation loss:		0.572621
  validation accuracy:		91.41 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006217
  validation loss:		0.577023
  validation accuracy:		91.41 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.006317
  validation loss:		0.572183
  validation accuracy:		91.30 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.006190
  validation loss:		0.565400
  validation accuracy:		91.85 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006144
  validation loss:		0.575093
  validation accuracy:		91.30 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.006111
  validation loss:		0.572678
  validation accuracy:		91.41 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.005972
  validation loss:		0.572045
  validation accuracy:		91.74 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.006043
  validation loss:		0.567980
  validation accuracy:		91.63 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.006261
  validation loss:		0.565242
  validation accuracy:		91.74 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.006328
  validation loss:		0.568007
  validation accuracy:		91.74 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.006199
  validation loss:		0.575767
  validation accuracy:		91.30 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.005962
  validation loss:		0.579976
  validation accuracy:		91.09 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.005880
  validation loss:		0.569565
  validation accuracy:		91.85 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.006141
  validation loss:		0.564744
  validation accuracy:		92.07 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006150
  validation loss:		0.583445
  validation accuracy:		91.30 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.005971
  validation loss:		0.570890
  validation accuracy:		91.63 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.005994
  validation loss:		0.580332
  validation accuracy:		91.20 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006054
  validation loss:		0.581821
  validation accuracy:		91.09 %
Epoch 1413 of 2000 took 0.037s
  training loss:		0.005966
  validation loss:		0.579957
  validation accuracy:		91.30 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.005987
  validation loss:		0.581429
  validation accuracy:		91.41 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.005859
  validation loss:		0.576351
  validation accuracy:		91.63 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.005990
  validation loss:		0.577217
  validation accuracy:		91.41 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006047
  validation loss:		0.580194
  validation accuracy:		91.30 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.005774
  validation loss:		0.578729
  validation accuracy:		91.85 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.006006
  validation loss:		0.567018
  validation accuracy:		91.96 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006119
  validation loss:		0.577451
  validation accuracy:		91.52 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.005774
  validation loss:		0.562562
  validation accuracy:		92.07 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.005640
  validation loss:		0.574391
  validation accuracy:		91.74 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.005976
  validation loss:		0.575802
  validation accuracy:		91.63 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.005861
  validation loss:		0.571282
  validation accuracy:		91.85 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.005785
  validation loss:		0.580412
  validation accuracy:		91.30 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.005707
  validation loss:		0.577662
  validation accuracy:		91.52 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.005849
  validation loss:		0.584902
  validation accuracy:		91.41 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.005771
  validation loss:		0.571758
  validation accuracy:		91.74 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.005875
  validation loss:		0.581636
  validation accuracy:		91.30 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.005655
  validation loss:		0.574558
  validation accuracy:		91.74 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.005946
  validation loss:		0.582133
  validation accuracy:		91.20 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.005805
  validation loss:		0.569048
  validation accuracy:		92.17 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.005796
  validation loss:		0.574403
  validation accuracy:		91.74 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.005988
  validation loss:		0.584304
  validation accuracy:		91.20 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.005937
  validation loss:		0.572946
  validation accuracy:		91.85 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.005713
  validation loss:		0.581863
  validation accuracy:		91.52 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.005767
  validation loss:		0.582340
  validation accuracy:		91.20 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.005882
  validation loss:		0.578406
  validation accuracy:		91.52 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.005800
  validation loss:		0.574116
  validation accuracy:		92.07 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.005820
  validation loss:		0.583455
  validation accuracy:		91.20 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.005608
  validation loss:		0.582085
  validation accuracy:		91.74 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.005590
  validation loss:		0.582766
  validation accuracy:		91.63 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.005740
  validation loss:		0.585618
  validation accuracy:		91.20 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.005519
  validation loss:		0.576221
  validation accuracy:		91.85 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.005535
  validation loss:		0.575056
  validation accuracy:		91.85 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.005530
  validation loss:		0.586589
  validation accuracy:		91.63 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.005528
  validation loss:		0.580769
  validation accuracy:		91.63 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.005588
  validation loss:		0.581584
  validation accuracy:		91.52 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.005667
  validation loss:		0.571326
  validation accuracy:		91.96 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.005701
  validation loss:		0.588994
  validation accuracy:		91.41 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.005637
  validation loss:		0.585577
  validation accuracy:		91.74 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.005668
  validation loss:		0.578283
  validation accuracy:		91.63 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.573256
  validation accuracy:		91.96 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.005631
  validation loss:		0.584268
  validation accuracy:		91.41 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.005568
  validation loss:		0.573069
  validation accuracy:		92.07 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.005611
  validation loss:		0.576369
  validation accuracy:		91.85 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.005527
  validation loss:		0.578442
  validation accuracy:		91.74 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.005592
  validation loss:		0.586667
  validation accuracy:		91.41 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.005482
  validation loss:		0.578492
  validation accuracy:		91.63 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.005446
  validation loss:		0.587060
  validation accuracy:		91.30 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.005654
  validation loss:		0.578284
  validation accuracy:		91.85 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.005585
  validation loss:		0.570364
  validation accuracy:		92.28 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.005743
  validation loss:		0.579113
  validation accuracy:		91.74 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.005443
  validation loss:		0.579720
  validation accuracy:		91.74 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.005390
  validation loss:		0.591582
  validation accuracy:		91.20 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.005443
  validation loss:		0.587876
  validation accuracy:		91.41 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.005305
  validation loss:		0.593151
  validation accuracy:		91.30 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.005508
  validation loss:		0.581556
  validation accuracy:		91.74 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.005549
  validation loss:		0.593832
  validation accuracy:		91.20 %
Epoch 1470 of 2000 took 0.036s
  training loss:		0.005406
  validation loss:		0.584555
  validation accuracy:		91.85 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.005348
  validation loss:		0.584430
  validation accuracy:		91.41 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.005567
  validation loss:		0.582796
  validation accuracy:		91.63 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.005327
  validation loss:		0.584894
  validation accuracy:		91.74 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.005376
  validation loss:		0.587783
  validation accuracy:		91.30 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.005355
  validation loss:		0.591743
  validation accuracy:		91.20 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.005334
  validation loss:		0.591571
  validation accuracy:		91.30 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.005440
  validation loss:		0.585859
  validation accuracy:		91.96 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.005321
  validation loss:		0.590279
  validation accuracy:		91.52 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.005472
  validation loss:		0.585701
  validation accuracy:		91.63 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.005326
  validation loss:		0.598667
  validation accuracy:		91.09 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.005244
  validation loss:		0.585979
  validation accuracy:		91.52 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.005369
  validation loss:		0.594007
  validation accuracy:		91.41 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.005349
  validation loss:		0.596816
  validation accuracy:		91.20 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.005193
  validation loss:		0.581900
  validation accuracy:		91.74 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.005367
  validation loss:		0.586922
  validation accuracy:		91.52 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005310
  validation loss:		0.585693
  validation accuracy:		91.85 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.590485
  validation accuracy:		91.30 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005218
  validation loss:		0.583644
  validation accuracy:		91.85 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005295
  validation loss:		0.594195
  validation accuracy:		91.52 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005154
  validation loss:		0.584436
  validation accuracy:		91.96 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.005255
  validation loss:		0.596212
  validation accuracy:		91.09 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005141
  validation loss:		0.587891
  validation accuracy:		91.63 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.005160
  validation loss:		0.597323
  validation accuracy:		91.30 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.005078
  validation loss:		0.595214
  validation accuracy:		91.30 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005113
  validation loss:		0.587694
  validation accuracy:		91.74 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.004923
  validation loss:		0.590715
  validation accuracy:		91.41 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005078
  validation loss:		0.592029
  validation accuracy:		91.63 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005043
  validation loss:		0.589358
  validation accuracy:		91.74 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005243
  validation loss:		0.591817
  validation accuracy:		91.52 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.005166
  validation loss:		0.589390
  validation accuracy:		91.63 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005059
  validation loss:		0.586277
  validation accuracy:		91.85 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.599242
  validation accuracy:		91.41 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.004918
  validation loss:		0.587807
  validation accuracy:		91.63 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.005163
  validation loss:		0.593622
  validation accuracy:		91.30 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.004791
  validation loss:		0.597224
  validation accuracy:		91.41 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005127
  validation loss:		0.595314
  validation accuracy:		91.30 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.004839
  validation loss:		0.597417
  validation accuracy:		91.30 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005025
  validation loss:		0.590574
  validation accuracy:		91.52 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.004993
  validation loss:		0.580455
  validation accuracy:		92.07 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.005115
  validation loss:		0.598080
  validation accuracy:		91.30 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.004997
  validation loss:		0.600770
  validation accuracy:		91.30 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.004855
  validation loss:		0.592517
  validation accuracy:		91.63 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.004867
  validation loss:		0.587345
  validation accuracy:		91.85 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005114
  validation loss:		0.593086
  validation accuracy:		91.74 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005149
  validation loss:		0.599360
  validation accuracy:		91.20 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.589511
  validation accuracy:		91.96 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.005180
  validation loss:		0.592797
  validation accuracy:		91.52 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.004800
  validation loss:		0.595747
  validation accuracy:		91.52 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.004810
  validation loss:		0.596561
  validation accuracy:		91.41 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.005016
  validation loss:		0.596181
  validation accuracy:		91.74 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.004832
  validation loss:		0.593173
  validation accuracy:		91.41 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.004931
  validation loss:		0.603923
  validation accuracy:		91.20 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.004908
  validation loss:		0.598745
  validation accuracy:		91.41 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.004886
  validation loss:		0.591758
  validation accuracy:		91.52 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.004944
  validation loss:		0.594123
  validation accuracy:		91.74 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.004743
  validation loss:		0.591257
  validation accuracy:		91.74 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.004952
  validation loss:		0.593230
  validation accuracy:		91.85 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.004930
  validation loss:		0.591153
  validation accuracy:		91.96 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.004930
  validation loss:		0.599855
  validation accuracy:		91.20 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.004888
  validation loss:		0.590632
  validation accuracy:		92.07 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.004763
  validation loss:		0.599715
  validation accuracy:		91.30 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.004688
  validation loss:		0.601860
  validation accuracy:		91.30 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.004825
  validation loss:		0.602576
  validation accuracy:		91.30 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.004789
  validation loss:		0.592914
  validation accuracy:		91.96 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.004925
  validation loss:		0.594589
  validation accuracy:		91.52 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005040
  validation loss:		0.593319
  validation accuracy:		91.96 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.004709
  validation loss:		0.602699
  validation accuracy:		91.41 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.004692
  validation loss:		0.596927
  validation accuracy:		91.63 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.004858
  validation loss:		0.605084
  validation accuracy:		91.30 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.004710
  validation loss:		0.598306
  validation accuracy:		91.74 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.004797
  validation loss:		0.600119
  validation accuracy:		91.41 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.004735
  validation loss:		0.605846
  validation accuracy:		90.98 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.004760
  validation loss:		0.603545
  validation accuracy:		91.20 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.004786
  validation loss:		0.600197
  validation accuracy:		91.20 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.004950
  validation loss:		0.597232
  validation accuracy:		91.63 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.004643
  validation loss:		0.596398
  validation accuracy:		91.74 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.004746
  validation loss:		0.602167
  validation accuracy:		91.41 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.004589
  validation loss:		0.600725
  validation accuracy:		91.63 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.004708
  validation loss:		0.604285
  validation accuracy:		91.41 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.004790
  validation loss:		0.600321
  validation accuracy:		91.52 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.004692
  validation loss:		0.601751
  validation accuracy:		91.09 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.004768
  validation loss:		0.611651
  validation accuracy:		91.20 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.004754
  validation loss:		0.595919
  validation accuracy:		91.74 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.004785
  validation loss:		0.598420
  validation accuracy:		91.63 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.004684
  validation loss:		0.597132
  validation accuracy:		91.85 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.004609
  validation loss:		0.603547
  validation accuracy:		91.41 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.004710
  validation loss:		0.608346
  validation accuracy:		90.98 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.004710
  validation loss:		0.597605
  validation accuracy:		91.74 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.004716
  validation loss:		0.602728
  validation accuracy:		91.30 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.600649
  validation accuracy:		91.52 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.004533
  validation loss:		0.598713
  validation accuracy:		91.63 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.004550
  validation loss:		0.604770
  validation accuracy:		91.41 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.004574
  validation loss:		0.604063
  validation accuracy:		91.63 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.004645
  validation loss:		0.613390
  validation accuracy:		91.20 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.004423
  validation loss:		0.613823
  validation accuracy:		91.09 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.004667
  validation loss:		0.610580
  validation accuracy:		91.30 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.004406
  validation loss:		0.598883
  validation accuracy:		91.96 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.004465
  validation loss:		0.604596
  validation accuracy:		91.52 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.004424
  validation loss:		0.609728
  validation accuracy:		91.09 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.004517
  validation loss:		0.608229
  validation accuracy:		91.41 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.004638
  validation loss:		0.590595
  validation accuracy:		92.39 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.004851
  validation loss:		0.601323
  validation accuracy:		91.85 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.004503
  validation loss:		0.606775
  validation accuracy:		91.63 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.004564
  validation loss:		0.600870
  validation accuracy:		91.74 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.004433
  validation loss:		0.593662
  validation accuracy:		92.17 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.004650
  validation loss:		0.603661
  validation accuracy:		91.85 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.004442
  validation loss:		0.610829
  validation accuracy:		91.30 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.004341
  validation loss:		0.603323
  validation accuracy:		91.52 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.004439
  validation loss:		0.613587
  validation accuracy:		91.09 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.004430
  validation loss:		0.608846
  validation accuracy:		91.30 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.004449
  validation loss:		0.608483
  validation accuracy:		91.30 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.004495
  validation loss:		0.611605
  validation accuracy:		91.20 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.004374
  validation loss:		0.608475
  validation accuracy:		91.52 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.004421
  validation loss:		0.600542
  validation accuracy:		91.63 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.004423
  validation loss:		0.602951
  validation accuracy:		91.85 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.004405
  validation loss:		0.617307
  validation accuracy:		91.09 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.004438
  validation loss:		0.607604
  validation accuracy:		91.20 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.609792
  validation accuracy:		91.41 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.004353
  validation loss:		0.608867
  validation accuracy:		91.63 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.004378
  validation loss:		0.610123
  validation accuracy:		91.41 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004373
  validation loss:		0.613918
  validation accuracy:		91.41 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.004416
  validation loss:		0.608839
  validation accuracy:		91.52 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.004360
  validation loss:		0.609390
  validation accuracy:		91.85 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.004555
  validation loss:		0.605438
  validation accuracy:		91.74 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.004427
  validation loss:		0.615282
  validation accuracy:		91.09 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004447
  validation loss:		0.609110
  validation accuracy:		91.63 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.004188
  validation loss:		0.609994
  validation accuracy:		91.74 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.004460
  validation loss:		0.611805
  validation accuracy:		91.30 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004430
  validation loss:		0.607342
  validation accuracy:		91.41 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004441
  validation loss:		0.611479
  validation accuracy:		91.41 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004250
  validation loss:		0.604458
  validation accuracy:		91.85 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004224
  validation loss:		0.611930
  validation accuracy:		91.30 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.004245
  validation loss:		0.611395
  validation accuracy:		91.30 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.614151
  validation accuracy:		91.30 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.004290
  validation loss:		0.617012
  validation accuracy:		91.41 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004347
  validation loss:		0.608168
  validation accuracy:		91.63 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.004292
  validation loss:		0.615275
  validation accuracy:		91.52 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.613458
  validation accuracy:		91.52 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.603766
  validation accuracy:		91.96 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004234
  validation loss:		0.617017
  validation accuracy:		91.20 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004163
  validation loss:		0.616836
  validation accuracy:		91.41 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.004082
  validation loss:		0.618624
  validation accuracy:		91.41 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.004201
  validation loss:		0.610078
  validation accuracy:		91.74 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004330
  validation loss:		0.611690
  validation accuracy:		91.63 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004006
  validation loss:		0.612459
  validation accuracy:		91.41 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004194
  validation loss:		0.611346
  validation accuracy:		91.74 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.613117
  validation accuracy:		91.63 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.004102
  validation loss:		0.617908
  validation accuracy:		91.30 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004183
  validation loss:		0.612524
  validation accuracy:		91.52 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004241
  validation loss:		0.614615
  validation accuracy:		91.63 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004267
  validation loss:		0.619666
  validation accuracy:		91.30 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004107
  validation loss:		0.607720
  validation accuracy:		91.96 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004189
  validation loss:		0.613655
  validation accuracy:		91.74 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004174
  validation loss:		0.620878
  validation accuracy:		91.30 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004140
  validation loss:		0.623105
  validation accuracy:		91.20 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004323
  validation loss:		0.613355
  validation accuracy:		91.74 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.004161
  validation loss:		0.611845
  validation accuracy:		91.52 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.623393
  validation accuracy:		91.09 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004193
  validation loss:		0.609870
  validation accuracy:		91.63 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.613932
  validation accuracy:		91.85 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004121
  validation loss:		0.616435
  validation accuracy:		91.52 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004106
  validation loss:		0.619558
  validation accuracy:		91.30 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004115
  validation loss:		0.620261
  validation accuracy:		91.41 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004093
  validation loss:		0.611730
  validation accuracy:		91.63 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.617314
  validation accuracy:		91.52 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004060
  validation loss:		0.614870
  validation accuracy:		91.74 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004130
  validation loss:		0.618308
  validation accuracy:		91.52 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004109
  validation loss:		0.627530
  validation accuracy:		91.09 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004083
  validation loss:		0.615186
  validation accuracy:		91.85 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004029
  validation loss:		0.613924
  validation accuracy:		91.85 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004000
  validation loss:		0.618853
  validation accuracy:		91.41 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.003996
  validation loss:		0.613346
  validation accuracy:		91.74 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004068
  validation loss:		0.617130
  validation accuracy:		91.41 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.003893
  validation loss:		0.626736
  validation accuracy:		91.20 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004047
  validation loss:		0.619748
  validation accuracy:		91.52 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004193
  validation loss:		0.624956
  validation accuracy:		91.30 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004055
  validation loss:		0.619637
  validation accuracy:		91.52 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.003983
  validation loss:		0.621425
  validation accuracy:		91.41 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.629558
  validation accuracy:		91.09 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004110
  validation loss:		0.620099
  validation accuracy:		91.52 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.004027
  validation loss:		0.611420
  validation accuracy:		92.07 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.003973
  validation loss:		0.619550
  validation accuracy:		91.52 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.003916
  validation loss:		0.612310
  validation accuracy:		91.96 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.003937
  validation loss:		0.617232
  validation accuracy:		91.85 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.003873
  validation loss:		0.625671
  validation accuracy:		91.30 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.003972
  validation loss:		0.618933
  validation accuracy:		91.63 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.003860
  validation loss:		0.618138
  validation accuracy:		91.85 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.003914
  validation loss:		0.621266
  validation accuracy:		91.52 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.003940
  validation loss:		0.614339
  validation accuracy:		91.96 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.003975
  validation loss:		0.621540
  validation accuracy:		91.52 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004054
  validation loss:		0.618618
  validation accuracy:		91.52 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.003976
  validation loss:		0.625868
  validation accuracy:		91.52 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004079
  validation loss:		0.630766
  validation accuracy:		91.20 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.618493
  validation accuracy:		91.74 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.619150
  validation accuracy:		91.52 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.003741
  validation loss:		0.626166
  validation accuracy:		91.30 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.003912
  validation loss:		0.623284
  validation accuracy:		91.52 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.626150
  validation accuracy:		91.41 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.003823
  validation loss:		0.616810
  validation accuracy:		91.96 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.003896
  validation loss:		0.626072
  validation accuracy:		91.52 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004030
  validation loss:		0.621075
  validation accuracy:		91.85 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.003823
  validation loss:		0.626444
  validation accuracy:		91.41 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.003836
  validation loss:		0.624058
  validation accuracy:		91.30 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.003810
  validation loss:		0.622481
  validation accuracy:		91.52 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.003867
  validation loss:		0.626436
  validation accuracy:		91.52 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.003719
  validation loss:		0.617263
  validation accuracy:		91.85 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.003880
  validation loss:		0.623061
  validation accuracy:		91.52 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.003885
  validation loss:		0.622101
  validation accuracy:		91.52 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.625381
  validation accuracy:		91.52 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.003739
  validation loss:		0.620363
  validation accuracy:		91.85 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.003903
  validation loss:		0.617829
  validation accuracy:		91.85 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.003918
  validation loss:		0.622296
  validation accuracy:		91.63 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.003732
  validation loss:		0.628968
  validation accuracy:		91.41 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.003791
  validation loss:		0.619529
  validation accuracy:		91.85 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.003786
  validation loss:		0.624308
  validation accuracy:		91.41 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.003757
  validation loss:		0.623061
  validation accuracy:		91.63 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.003831
  validation loss:		0.627505
  validation accuracy:		91.41 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.630085
  validation accuracy:		91.30 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.003852
  validation loss:		0.619126
  validation accuracy:		91.96 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.003777
  validation loss:		0.631756
  validation accuracy:		91.30 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.003921
  validation loss:		0.621260
  validation accuracy:		91.85 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.003731
  validation loss:		0.621708
  validation accuracy:		91.96 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.003881
  validation loss:		0.626204
  validation accuracy:		91.52 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.003769
  validation loss:		0.633937
  validation accuracy:		91.52 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.003653
  validation loss:		0.622070
  validation accuracy:		91.85 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.003707
  validation loss:		0.627614
  validation accuracy:		91.52 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.003670
  validation loss:		0.624899
  validation accuracy:		91.74 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.003688
  validation loss:		0.628393
  validation accuracy:		91.30 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.003713
  validation loss:		0.623531
  validation accuracy:		91.74 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.003691
  validation loss:		0.621378
  validation accuracy:		91.85 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.003707
  validation loss:		0.626801
  validation accuracy:		91.63 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.003716
  validation loss:		0.623620
  validation accuracy:		91.96 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.003638
  validation loss:		0.630121
  validation accuracy:		91.63 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.003619
  validation loss:		0.625673
  validation accuracy:		91.85 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.003727
  validation loss:		0.633901
  validation accuracy:		91.30 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.003837
  validation loss:		0.630810
  validation accuracy:		91.63 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.003835
  validation loss:		0.622727
  validation accuracy:		91.85 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.003736
  validation loss:		0.638367
  validation accuracy:		91.41 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.003672
  validation loss:		0.624354
  validation accuracy:		91.96 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.003641
  validation loss:		0.628934
  validation accuracy:		91.41 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.635776
  validation accuracy:		91.52 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.003653
  validation loss:		0.625754
  validation accuracy:		91.52 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.003601
  validation loss:		0.629664
  validation accuracy:		91.63 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.003743
  validation loss:		0.630852
  validation accuracy:		91.74 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.003632
  validation loss:		0.641164
  validation accuracy:		91.09 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.003779
  validation loss:		0.626111
  validation accuracy:		91.74 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.635668
  validation accuracy:		91.41 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.003688
  validation loss:		0.635281
  validation accuracy:		91.30 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.003613
  validation loss:		0.638523
  validation accuracy:		91.30 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.003648
  validation loss:		0.620953
  validation accuracy:		92.17 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.003553
  validation loss:		0.633011
  validation accuracy:		91.41 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.003600
  validation loss:		0.627539
  validation accuracy:		91.74 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.003653
  validation loss:		0.629018
  validation accuracy:		91.63 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.003627
  validation loss:		0.633704
  validation accuracy:		91.52 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.003560
  validation loss:		0.630302
  validation accuracy:		91.85 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.003568
  validation loss:		0.631988
  validation accuracy:		91.52 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.003498
  validation loss:		0.629862
  validation accuracy:		91.74 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.003504
  validation loss:		0.633819
  validation accuracy:		91.30 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.003649
  validation loss:		0.634221
  validation accuracy:		91.52 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.003600
  validation loss:		0.629745
  validation accuracy:		91.85 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.003385
  validation loss:		0.635765
  validation accuracy:		91.63 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.003472
  validation loss:		0.630192
  validation accuracy:		91.85 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.003500
  validation loss:		0.640606
  validation accuracy:		91.30 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.003521
  validation loss:		0.633078
  validation accuracy:		91.63 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.003501
  validation loss:		0.631735
  validation accuracy:		91.74 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.003492
  validation loss:		0.636150
  validation accuracy:		91.41 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.003473
  validation loss:		0.636306
  validation accuracy:		91.41 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.003486
  validation loss:		0.632773
  validation accuracy:		91.74 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.003500
  validation loss:		0.633790
  validation accuracy:		91.52 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.003471
  validation loss:		0.626149
  validation accuracy:		92.07 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.003500
  validation loss:		0.628749
  validation accuracy:		91.96 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.003577
  validation loss:		0.638960
  validation accuracy:		91.41 %
Epoch 1743 of 2000 took 0.036s
  training loss:		0.003486
  validation loss:		0.632967
  validation accuracy:		91.74 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.003493
  validation loss:		0.634713
  validation accuracy:		91.41 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.003426
  validation loss:		0.633110
  validation accuracy:		91.85 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.003472
  validation loss:		0.634727
  validation accuracy:		91.63 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.003445
  validation loss:		0.634617
  validation accuracy:		91.74 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.003502
  validation loss:		0.633833
  validation accuracy:		91.74 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.003441
  validation loss:		0.638608
  validation accuracy:		91.30 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.003493
  validation loss:		0.633044
  validation accuracy:		91.74 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.003434
  validation loss:		0.628083
  validation accuracy:		91.96 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.003578
  validation loss:		0.641379
  validation accuracy:		91.41 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.003420
  validation loss:		0.637847
  validation accuracy:		91.63 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.003396
  validation loss:		0.639268
  validation accuracy:		91.30 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.003534
  validation loss:		0.632003
  validation accuracy:		91.85 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.003484
  validation loss:		0.637927
  validation accuracy:		91.52 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.003325
  validation loss:		0.636079
  validation accuracy:		91.63 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.003425
  validation loss:		0.640799
  validation accuracy:		91.30 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.003469
  validation loss:		0.633089
  validation accuracy:		91.85 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.003500
  validation loss:		0.635868
  validation accuracy:		91.63 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.003441
  validation loss:		0.646034
  validation accuracy:		91.20 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.003456
  validation loss:		0.635505
  validation accuracy:		91.63 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.003381
  validation loss:		0.631080
  validation accuracy:		91.96 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003649
  validation loss:		0.633481
  validation accuracy:		91.74 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003402
  validation loss:		0.643653
  validation accuracy:		91.41 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.003451
  validation loss:		0.642292
  validation accuracy:		91.41 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003261
  validation loss:		0.630801
  validation accuracy:		91.96 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.003371
  validation loss:		0.640473
  validation accuracy:		91.63 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.003379
  validation loss:		0.639472
  validation accuracy:		91.52 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.003420
  validation loss:		0.644380
  validation accuracy:		91.52 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003443
  validation loss:		0.637173
  validation accuracy:		91.30 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.003423
  validation loss:		0.634210
  validation accuracy:		91.96 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003312
  validation loss:		0.639252
  validation accuracy:		91.74 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.003372
  validation loss:		0.639045
  validation accuracy:		91.63 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.003412
  validation loss:		0.634749
  validation accuracy:		91.96 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003300
  validation loss:		0.644142
  validation accuracy:		91.30 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.003328
  validation loss:		0.643530
  validation accuracy:		91.41 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003427
  validation loss:		0.639754
  validation accuracy:		91.74 %
Epoch 1779 of 2000 took 0.036s
  training loss:		0.003391
  validation loss:		0.642283
  validation accuracy:		91.52 %
Epoch 1780 of 2000 took 0.036s
  training loss:		0.003339
  validation loss:		0.639880
  validation accuracy:		91.74 %
Epoch 1781 of 2000 took 0.036s
  training loss:		0.003318
  validation loss:		0.641943
  validation accuracy:		91.63 %
Epoch 1782 of 2000 took 0.036s
  training loss:		0.003233
  validation loss:		0.639293
  validation accuracy:		91.52 %
Epoch 1783 of 2000 took 0.036s
  training loss:		0.003302
  validation loss:		0.637584
  validation accuracy:		91.85 %
Epoch 1784 of 2000 took 0.036s
  training loss:		0.003322
  validation loss:		0.639887
  validation accuracy:		91.63 %
Epoch 1785 of 2000 took 0.037s
  training loss:		0.003341
  validation loss:		0.644187
  validation accuracy:		91.52 %
Epoch 1786 of 2000 took 0.036s
  training loss:		0.003309
  validation loss:		0.638279
  validation accuracy:		91.74 %
Epoch 1787 of 2000 took 0.036s
  training loss:		0.003329
  validation loss:		0.646358
  validation accuracy:		91.41 %
Epoch 1788 of 2000 took 0.036s
  training loss:		0.003281
  validation loss:		0.636694
  validation accuracy:		91.96 %
Epoch 1789 of 2000 took 0.037s
  training loss:		0.003344
  validation loss:		0.648518
  validation accuracy:		91.30 %
Epoch 1790 of 2000 took 0.037s
  training loss:		0.003314
  validation loss:		0.637596
  validation accuracy:		91.85 %
Epoch 1791 of 2000 took 0.036s
  training loss:		0.003264
  validation loss:		0.646310
  validation accuracy:		91.41 %
Epoch 1792 of 2000 took 0.037s
  training loss:		0.003303
  validation loss:		0.642090
  validation accuracy:		91.52 %
Epoch 1793 of 2000 took 0.036s
  training loss:		0.003299
  validation loss:		0.645133
  validation accuracy:		91.41 %
Epoch 1794 of 2000 took 0.036s
  training loss:		0.003284
  validation loss:		0.640100
  validation accuracy:		91.63 %
Epoch 1795 of 2000 took 0.036s
  training loss:		0.003257
  validation loss:		0.645978
  validation accuracy:		91.52 %
Epoch 1796 of 2000 took 0.036s
  training loss:		0.003233
  validation loss:		0.645914
  validation accuracy:		91.52 %
Epoch 1797 of 2000 took 0.036s
  training loss:		0.003317
  validation loss:		0.637764
  validation accuracy:		91.74 %
Epoch 1798 of 2000 took 0.036s
  training loss:		0.003288
  validation loss:		0.646642
  validation accuracy:		91.63 %
Epoch 1799 of 2000 took 0.037s
  training loss:		0.003290
  validation loss:		0.637305
  validation accuracy:		91.96 %
Epoch 1800 of 2000 took 0.036s
  training loss:		0.003286
  validation loss:		0.638118
  validation accuracy:		91.96 %
Epoch 1801 of 2000 took 0.036s
  training loss:		0.003209
  validation loss:		0.639250
  validation accuracy:		91.85 %
Epoch 1802 of 2000 took 0.036s
  training loss:		0.003351
  validation loss:		0.643738
  validation accuracy:		91.63 %
Epoch 1803 of 2000 took 0.036s
  training loss:		0.003179
  validation loss:		0.643652
  validation accuracy:		91.52 %
Epoch 1804 of 2000 took 0.036s
  training loss:		0.003220
  validation loss:		0.646476
  validation accuracy:		91.41 %
Epoch 1805 of 2000 took 0.036s
  training loss:		0.003222
  validation loss:		0.638019
  validation accuracy:		91.96 %
Epoch 1806 of 2000 took 0.036s
  training loss:		0.003066
  validation loss:		0.646344
  validation accuracy:		91.52 %
Epoch 1807 of 2000 took 0.036s
  training loss:		0.003143
  validation loss:		0.641900
  validation accuracy:		91.74 %
Epoch 1808 of 2000 took 0.036s
  training loss:		0.003259
  validation loss:		0.642055
  validation accuracy:		91.85 %
Epoch 1809 of 2000 took 0.036s
  training loss:		0.003263
  validation loss:		0.639518
  validation accuracy:		91.96 %
Epoch 1810 of 2000 took 0.036s
  training loss:		0.003198
  validation loss:		0.651817
  validation accuracy:		91.41 %
Epoch 1811 of 2000 took 0.036s
  training loss:		0.003245
  validation loss:		0.641027
  validation accuracy:		91.74 %
Epoch 1812 of 2000 took 0.036s
  training loss:		0.003244
  validation loss:		0.645150
  validation accuracy:		91.74 %
Epoch 1813 of 2000 took 0.036s
  training loss:		0.003164
  validation loss:		0.648047
  validation accuracy:		91.41 %
Epoch 1814 of 2000 took 0.036s
  training loss:		0.003230
  validation loss:		0.639678
  validation accuracy:		91.96 %
Epoch 1815 of 2000 took 0.036s
  training loss:		0.003266
  validation loss:		0.640929
  validation accuracy:		91.85 %
Epoch 1816 of 2000 took 0.036s
  training loss:		0.003188
  validation loss:		0.651595
  validation accuracy:		91.30 %
Epoch 1817 of 2000 took 0.036s
  training loss:		0.003186
  validation loss:		0.646821
  validation accuracy:		91.52 %
Epoch 1818 of 2000 took 0.036s
  training loss:		0.003217
  validation loss:		0.648133
  validation accuracy:		91.41 %
Epoch 1819 of 2000 took 0.036s
  training loss:		0.003131
  validation loss:		0.640192
  validation accuracy:		91.96 %
Epoch 1820 of 2000 took 0.036s
  training loss:		0.003198
  validation loss:		0.645383
  validation accuracy:		91.74 %
Epoch 1821 of 2000 took 0.036s
  training loss:		0.003167
  validation loss:		0.645520
  validation accuracy:		91.52 %
Epoch 1822 of 2000 took 0.036s
  training loss:		0.003203
  validation loss:		0.646505
  validation accuracy:		91.74 %
Epoch 1823 of 2000 took 0.036s
  training loss:		0.003109
  validation loss:		0.641938
  validation accuracy:		91.96 %
Epoch 1824 of 2000 took 0.036s
  training loss:		0.003133
  validation loss:		0.650357
  validation accuracy:		91.52 %
Epoch 1825 of 2000 took 0.036s
  training loss:		0.003161
  validation loss:		0.651125
  validation accuracy:		91.63 %
Epoch 1826 of 2000 took 0.036s
  training loss:		0.003129
  validation loss:		0.648784
  validation accuracy:		91.63 %
Epoch 1827 of 2000 took 0.036s
  training loss:		0.003082
  validation loss:		0.642491
  validation accuracy:		91.85 %
Epoch 1828 of 2000 took 0.036s
  training loss:		0.003100
  validation loss:		0.650296
  validation accuracy:		91.41 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.002998
  validation loss:		0.643108
  validation accuracy:		91.96 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003235
  validation loss:		0.644471
  validation accuracy:		91.85 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003111
  validation loss:		0.650112
  validation accuracy:		91.30 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003112
  validation loss:		0.646623
  validation accuracy:		91.74 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003162
  validation loss:		0.652154
  validation accuracy:		91.52 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003112
  validation loss:		0.644515
  validation accuracy:		91.85 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003077
  validation loss:		0.644410
  validation accuracy:		91.74 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003085
  validation loss:		0.654745
  validation accuracy:		91.63 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003014
  validation loss:		0.642677
  validation accuracy:		92.07 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003032
  validation loss:		0.654616
  validation accuracy:		91.30 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.002994
  validation loss:		0.648439
  validation accuracy:		91.74 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.002953
  validation loss:		0.649314
  validation accuracy:		91.52 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003043
  validation loss:		0.656175
  validation accuracy:		91.41 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003041
  validation loss:		0.644874
  validation accuracy:		91.85 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003012
  validation loss:		0.648343
  validation accuracy:		91.74 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003047
  validation loss:		0.648356
  validation accuracy:		91.74 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003037
  validation loss:		0.644427
  validation accuracy:		91.74 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003017
  validation loss:		0.643455
  validation accuracy:		91.96 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003089
  validation loss:		0.648041
  validation accuracy:		91.63 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003117
  validation loss:		0.647667
  validation accuracy:		91.85 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003126
  validation loss:		0.647796
  validation accuracy:		91.85 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.002947
  validation loss:		0.646654
  validation accuracy:		91.85 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003074
  validation loss:		0.650238
  validation accuracy:		91.85 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003067
  validation loss:		0.651140
  validation accuracy:		91.74 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003074
  validation loss:		0.647414
  validation accuracy:		91.85 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.002863
  validation loss:		0.650468
  validation accuracy:		91.63 %
Epoch 1855 of 2000 took 0.036s
  training loss:		0.003026
  validation loss:		0.650761
  validation accuracy:		91.85 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003069
  validation loss:		0.649281
  validation accuracy:		91.74 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.002917
  validation loss:		0.647881
  validation accuracy:		91.85 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003024
  validation loss:		0.652402
  validation accuracy:		91.74 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.002979
  validation loss:		0.653560
  validation accuracy:		91.41 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.002928
  validation loss:		0.655421
  validation accuracy:		91.63 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.002983
  validation loss:		0.645234
  validation accuracy:		91.96 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.002948
  validation loss:		0.651840
  validation accuracy:		91.63 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.002984
  validation loss:		0.655363
  validation accuracy:		91.41 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.002928
  validation loss:		0.652703
  validation accuracy:		91.74 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.002932
  validation loss:		0.655057
  validation accuracy:		91.41 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003040
  validation loss:		0.649603
  validation accuracy:		91.85 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.002929
  validation loss:		0.656034
  validation accuracy:		91.41 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.002938
  validation loss:		0.652869
  validation accuracy:		91.74 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003047
  validation loss:		0.650404
  validation accuracy:		91.85 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.002972
  validation loss:		0.649996
  validation accuracy:		91.85 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.002865
  validation loss:		0.648504
  validation accuracy:		91.74 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.002841
  validation loss:		0.657055
  validation accuracy:		91.52 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.002856
  validation loss:		0.656650
  validation accuracy:		91.74 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.002954
  validation loss:		0.656197
  validation accuracy:		91.41 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003007
  validation loss:		0.654061
  validation accuracy:		91.74 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.002976
  validation loss:		0.655314
  validation accuracy:		91.63 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.002995
  validation loss:		0.655969
  validation accuracy:		91.63 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.002931
  validation loss:		0.653099
  validation accuracy:		91.85 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.002914
  validation loss:		0.656729
  validation accuracy:		91.52 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.002887
  validation loss:		0.654401
  validation accuracy:		91.63 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.002925
  validation loss:		0.656381
  validation accuracy:		91.74 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.002888
  validation loss:		0.657817
  validation accuracy:		91.63 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.002924
  validation loss:		0.660246
  validation accuracy:		91.41 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.002960
  validation loss:		0.660033
  validation accuracy:		91.41 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.002888
  validation loss:		0.648726
  validation accuracy:		91.96 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.002954
  validation loss:		0.654060
  validation accuracy:		91.74 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.002901
  validation loss:		0.661251
  validation accuracy:		91.41 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.002920
  validation loss:		0.654267
  validation accuracy:		91.85 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.002814
  validation loss:		0.664808
  validation accuracy:		91.41 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.002879
  validation loss:		0.651963
  validation accuracy:		91.85 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.002878
  validation loss:		0.661504
  validation accuracy:		91.52 %
Epoch 1892 of 2000 took 0.037s
  training loss:		0.002846
  validation loss:		0.653304
  validation accuracy:		91.85 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.002784
  validation loss:		0.658224
  validation accuracy:		91.74 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.002897
  validation loss:		0.653534
  validation accuracy:		91.85 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.002910
  validation loss:		0.662651
  validation accuracy:		91.41 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.002818
  validation loss:		0.660334
  validation accuracy:		91.63 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.002841
  validation loss:		0.661863
  validation accuracy:		91.41 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.002851
  validation loss:		0.655321
  validation accuracy:		91.74 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.002879
  validation loss:		0.652632
  validation accuracy:		91.85 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.002759
  validation loss:		0.661636
  validation accuracy:		91.63 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.002618
  validation loss:		0.652878
  validation accuracy:		91.74 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.002878
  validation loss:		0.657316
  validation accuracy:		91.74 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.002880
  validation loss:		0.661988
  validation accuracy:		91.52 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.002870
  validation loss:		0.653922
  validation accuracy:		91.85 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.002852
  validation loss:		0.661308
  validation accuracy:		91.41 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.002851
  validation loss:		0.656639
  validation accuracy:		91.85 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.002743
  validation loss:		0.664121
  validation accuracy:		91.52 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.002868
  validation loss:		0.661957
  validation accuracy:		91.52 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.002793
  validation loss:		0.651865
  validation accuracy:		91.85 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.002851
  validation loss:		0.656979
  validation accuracy:		91.85 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.002812
  validation loss:		0.656489
  validation accuracy:		91.74 %
Epoch 1912 of 2000 took 0.036s
  training loss:		0.002832
  validation loss:		0.655574
  validation accuracy:		91.85 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.002733
  validation loss:		0.662716
  validation accuracy:		91.52 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.002887
  validation loss:		0.658148
  validation accuracy:		91.74 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.002807
  validation loss:		0.664441
  validation accuracy:		91.41 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.002832
  validation loss:		0.649269
  validation accuracy:		92.39 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.002828
  validation loss:		0.666492
  validation accuracy:		91.41 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.002761
  validation loss:		0.657062
  validation accuracy:		91.85 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.002738
  validation loss:		0.658409
  validation accuracy:		91.74 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.002799
  validation loss:		0.664075
  validation accuracy:		91.41 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.002779
  validation loss:		0.653383
  validation accuracy:		91.74 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.002818
  validation loss:		0.662817
  validation accuracy:		91.74 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.002826
  validation loss:		0.653783
  validation accuracy:		92.07 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.002771
  validation loss:		0.666412
  validation accuracy:		91.41 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.002783
  validation loss:		0.660311
  validation accuracy:		91.74 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.002794
  validation loss:		0.663035
  validation accuracy:		91.74 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.002788
  validation loss:		0.662430
  validation accuracy:		91.63 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.002771
  validation loss:		0.662011
  validation accuracy:		91.63 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.002611
  validation loss:		0.663078
  validation accuracy:		91.63 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.002682
  validation loss:		0.662932
  validation accuracy:		91.74 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.002736
  validation loss:		0.654525
  validation accuracy:		91.85 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.002746
  validation loss:		0.661661
  validation accuracy:		91.85 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.002717
  validation loss:		0.662768
  validation accuracy:		91.74 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.002691
  validation loss:		0.659638
  validation accuracy:		91.85 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.002751
  validation loss:		0.660116
  validation accuracy:		91.74 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.002688
  validation loss:		0.664509
  validation accuracy:		91.74 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.002720
  validation loss:		0.664011
  validation accuracy:		91.63 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.002703
  validation loss:		0.662026
  validation accuracy:		91.74 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.002736
  validation loss:		0.664208
  validation accuracy:		91.74 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.002715
  validation loss:		0.661139
  validation accuracy:		91.96 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.002678
  validation loss:		0.663171
  validation accuracy:		91.74 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.002595
  validation loss:		0.666126
  validation accuracy:		91.74 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.002772
  validation loss:		0.663678
  validation accuracy:		91.74 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.002654
  validation loss:		0.666059
  validation accuracy:		91.52 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.002697
  validation loss:		0.660510
  validation accuracy:		91.85 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.002771
  validation loss:		0.664994
  validation accuracy:		91.74 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.002707
  validation loss:		0.663269
  validation accuracy:		91.74 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.002665
  validation loss:		0.662206
  validation accuracy:		91.85 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.002712
  validation loss:		0.665770
  validation accuracy:		91.74 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.002697
  validation loss:		0.664851
  validation accuracy:		91.63 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.002657
  validation loss:		0.661667
  validation accuracy:		91.85 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.002676
  validation loss:		0.666825
  validation accuracy:		91.63 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.002698
  validation loss:		0.667980
  validation accuracy:		91.63 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.002673
  validation loss:		0.660128
  validation accuracy:		91.85 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.002706
  validation loss:		0.666121
  validation accuracy:		91.52 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.002757
  validation loss:		0.664943
  validation accuracy:		91.74 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.002667
  validation loss:		0.660275
  validation accuracy:		91.74 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.002597
  validation loss:		0.667768
  validation accuracy:		91.63 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.002656
  validation loss:		0.663818
  validation accuracy:		91.63 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.002543
  validation loss:		0.663524
  validation accuracy:		91.85 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.002701
  validation loss:		0.665724
  validation accuracy:		91.74 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.002578
  validation loss:		0.662027
  validation accuracy:		91.85 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.002672
  validation loss:		0.662264
  validation accuracy:		91.85 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.002696
  validation loss:		0.662738
  validation accuracy:		91.96 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.002614
  validation loss:		0.669951
  validation accuracy:		91.52 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.002626
  validation loss:		0.662904
  validation accuracy:		91.85 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.002580
  validation loss:		0.668305
  validation accuracy:		91.41 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.002603
  validation loss:		0.665213
  validation accuracy:		91.85 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.002609
  validation loss:		0.665631
  validation accuracy:		91.74 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.002587
  validation loss:		0.668736
  validation accuracy:		91.63 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.002613
  validation loss:		0.666514
  validation accuracy:		91.63 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.002665
  validation loss:		0.667051
  validation accuracy:		91.74 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.002569
  validation loss:		0.665319
  validation accuracy:		91.74 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.002555
  validation loss:		0.667424
  validation accuracy:		91.85 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.002617
  validation loss:		0.665597
  validation accuracy:		91.74 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.002622
  validation loss:		0.668456
  validation accuracy:		91.85 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.002643
  validation loss:		0.669016
  validation accuracy:		91.63 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.002589
  validation loss:		0.664679
  validation accuracy:		91.85 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.002626
  validation loss:		0.668687
  validation accuracy:		91.63 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.002569
  validation loss:		0.668743
  validation accuracy:		91.74 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.002607
  validation loss:		0.662856
  validation accuracy:		91.85 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.002548
  validation loss:		0.671470
  validation accuracy:		91.63 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.002646
  validation loss:		0.670077
  validation accuracy:		91.74 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.002551
  validation loss:		0.663250
  validation accuracy:		91.85 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.002594
  validation loss:		0.671731
  validation accuracy:		91.63 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.002559
  validation loss:		0.671784
  validation accuracy:		91.63 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.002528
  validation loss:		0.664929
  validation accuracy:		91.74 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.002569
  validation loss:		0.666042
  validation accuracy:		91.85 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.002604
  validation loss:		0.667515
  validation accuracy:		91.74 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.002588
  validation loss:		0.674528
  validation accuracy:		91.52 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.002540
  validation loss:		0.666805
  validation accuracy:		91.85 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.002538
  validation loss:		0.665559
  validation accuracy:		91.85 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.002557
  validation loss:		0.670754
  validation accuracy:		91.74 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.002482
  validation loss:		0.675392
  validation accuracy:		91.41 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.002669
  validation loss:		0.677277
  validation accuracy:		91.52 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.002495
  validation loss:		0.666654
  validation accuracy:		91.85 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.002553
  validation loss:		0.671456
  validation accuracy:		91.74 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.002551
  validation loss:		0.670824
  validation accuracy:		91.74 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.002563
  validation loss:		0.668043
  validation accuracy:		91.85 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.002628
  validation loss:		0.676186
  validation accuracy:		91.63 %
Final results:
  test loss:			1.551850
  test accuracy:		83.51 %
