Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.091s
  training loss:		2.956879
  validation loss:		2.881910
  validation accuracy:		12.93 %
Epoch 2 of 2000 took 0.085s
  training loss:		2.848699
  validation loss:		2.724390
  validation accuracy:		12.93 %
Epoch 3 of 2000 took 0.078s
  training loss:		2.695577
  validation loss:		2.520478
  validation accuracy:		12.93 %
Epoch 4 of 2000 took 0.080s
  training loss:		2.512155
  validation loss:		2.327508
  validation accuracy:		25.98 %
Epoch 5 of 2000 took 0.082s
  training loss:		2.368861
  validation loss:		2.257134
  validation accuracy:		18.70 %
Epoch 6 of 2000 took 0.085s
  training loss:		2.310014
  validation loss:		2.251479
  validation accuracy:		36.85 %
Epoch 7 of 2000 took 0.079s
  training loss:		2.290271
  validation loss:		2.227357
  validation accuracy:		25.98 %
Epoch 8 of 2000 took 0.081s
  training loss:		2.282060
  validation loss:		2.222494
  validation accuracy:		57.07 %
Epoch 9 of 2000 took 0.080s
  training loss:		2.278494
  validation loss:		2.230912
  validation accuracy:		37.50 %
Epoch 10 of 2000 took 0.080s
  training loss:		2.274462
  validation loss:		2.220188
  validation accuracy:		35.76 %
Epoch 11 of 2000 took 0.081s
  training loss:		2.269553
  validation loss:		2.213284
  validation accuracy:		23.48 %
Epoch 12 of 2000 took 0.079s
  training loss:		2.265284
  validation loss:		2.214843
  validation accuracy:		21.85 %
Epoch 13 of 2000 took 0.078s
  training loss:		2.260447
  validation loss:		2.207050
  validation accuracy:		15.98 %
Epoch 14 of 2000 took 0.075s
  training loss:		2.256758
  validation loss:		2.205359
  validation accuracy:		27.72 %
Epoch 15 of 2000 took 0.075s
  training loss:		2.253260
  validation loss:		2.199362
  validation accuracy:		46.74 %
Epoch 16 of 2000 took 0.077s
  training loss:		2.247107
  validation loss:		2.182694
  validation accuracy:		41.41 %
Epoch 17 of 2000 took 0.077s
  training loss:		2.242811
  validation loss:		2.183666
  validation accuracy:		35.43 %
Epoch 18 of 2000 took 0.077s
  training loss:		2.236708
  validation loss:		2.176870
  validation accuracy:		65.87 %
Epoch 19 of 2000 took 0.075s
  training loss:		2.230954
  validation loss:		2.171027
  validation accuracy:		43.48 %
Epoch 20 of 2000 took 0.073s
  training loss:		2.223482
  validation loss:		2.150619
  validation accuracy:		34.78 %
Epoch 21 of 2000 took 0.075s
  training loss:		2.219738
  validation loss:		2.169232
  validation accuracy:		54.78 %
Epoch 22 of 2000 took 0.077s
  training loss:		2.211159
  validation loss:		2.146530
  validation accuracy:		51.85 %
Epoch 23 of 2000 took 0.076s
  training loss:		2.201666
  validation loss:		2.145328
  validation accuracy:		56.74 %
Epoch 24 of 2000 took 0.076s
  training loss:		2.192643
  validation loss:		2.124991
  validation accuracy:		54.46 %
Epoch 25 of 2000 took 0.074s
  training loss:		2.186030
  validation loss:		2.126927
  validation accuracy:		60.65 %
Epoch 26 of 2000 took 0.078s
  training loss:		2.173215
  validation loss:		2.105782
  validation accuracy:		64.89 %
Epoch 27 of 2000 took 0.077s
  training loss:		2.160579
  validation loss:		2.092610
  validation accuracy:		55.87 %
Epoch 28 of 2000 took 0.078s
  training loss:		2.148969
  validation loss:		2.084609
  validation accuracy:		59.13 %
Epoch 29 of 2000 took 0.078s
  training loss:		2.132327
  validation loss:		2.061689
  validation accuracy:		70.87 %
Epoch 30 of 2000 took 0.077s
  training loss:		2.115246
  validation loss:		2.047818
  validation accuracy:		68.70 %
Epoch 31 of 2000 took 0.078s
  training loss:		2.098912
  validation loss:		2.026471
  validation accuracy:		61.41 %
Epoch 32 of 2000 took 0.077s
  training loss:		2.077759
  validation loss:		1.989210
  validation accuracy:		70.22 %
Epoch 33 of 2000 took 0.074s
  training loss:		2.052488
  validation loss:		1.988173
  validation accuracy:		82.50 %
Epoch 34 of 2000 took 0.078s
  training loss:		2.023773
  validation loss:		1.935181
  validation accuracy:		73.48 %
Epoch 35 of 2000 took 0.075s
  training loss:		1.996589
  validation loss:		1.908521
  validation accuracy:		78.26 %
Epoch 36 of 2000 took 0.079s
  training loss:		1.963879
  validation loss:		1.877216
  validation accuracy:		79.24 %
Epoch 37 of 2000 took 0.076s
  training loss:		1.927748
  validation loss:		1.830694
  validation accuracy:		81.52 %
Epoch 38 of 2000 took 0.075s
  training loss:		1.889547
  validation loss:		1.790219
  validation accuracy:		83.70 %
Epoch 39 of 2000 took 0.077s
  training loss:		1.842438
  validation loss:		1.741657
  validation accuracy:		78.26 %
Epoch 40 of 2000 took 0.077s
  training loss:		1.798715
  validation loss:		1.704099
  validation accuracy:		83.04 %
Epoch 41 of 2000 took 0.077s
  training loss:		1.749523
  validation loss:		1.632768
  validation accuracy:		81.52 %
Epoch 42 of 2000 took 0.077s
  training loss:		1.699383
  validation loss:		1.575427
  validation accuracy:		84.57 %
Epoch 43 of 2000 took 0.078s
  training loss:		1.649456
  validation loss:		1.516244
  validation accuracy:		88.04 %
Epoch 44 of 2000 took 0.079s
  training loss:		1.585369
  validation loss:		1.457239
  validation accuracy:		87.50 %
Epoch 45 of 2000 took 0.078s
  training loss:		1.532797
  validation loss:		1.407344
  validation accuracy:		83.15 %
Epoch 46 of 2000 took 0.076s
  training loss:		1.473612
  validation loss:		1.329999
  validation accuracy:		87.61 %
Epoch 47 of 2000 took 0.077s
  training loss:		1.418139
  validation loss:		1.276039
  validation accuracy:		86.41 %
Epoch 48 of 2000 took 0.076s
  training loss:		1.356243
  validation loss:		1.225206
  validation accuracy:		85.43 %
Epoch 49 of 2000 took 0.077s
  training loss:		1.304078
  validation loss:		1.156248
  validation accuracy:		86.85 %
Epoch 50 of 2000 took 0.077s
  training loss:		1.249544
  validation loss:		1.110234
  validation accuracy:		87.17 %
Epoch 51 of 2000 took 0.078s
  training loss:		1.198580
  validation loss:		1.072930
  validation accuracy:		86.96 %
Epoch 52 of 2000 took 0.078s
  training loss:		1.151712
  validation loss:		1.004479
  validation accuracy:		87.61 %
Epoch 53 of 2000 took 0.079s
  training loss:		1.100494
  validation loss:		0.957383
  validation accuracy:		87.72 %
Epoch 54 of 2000 took 0.079s
  training loss:		1.052561
  validation loss:		0.921253
  validation accuracy:		87.61 %
Epoch 55 of 2000 took 0.078s
  training loss:		1.015058
  validation loss:		0.888187
  validation accuracy:		87.07 %
Epoch 56 of 2000 took 0.079s
  training loss:		0.970162
  validation loss:		0.843139
  validation accuracy:		86.96 %
Epoch 57 of 2000 took 0.079s
  training loss:		0.935436
  validation loss:		0.813118
  validation accuracy:		87.39 %
Epoch 58 of 2000 took 0.077s
  training loss:		0.899571
  validation loss:		0.775043
  validation accuracy:		87.72 %
Epoch 59 of 2000 took 0.078s
  training loss:		0.869727
  validation loss:		0.751405
  validation accuracy:		86.85 %
Epoch 60 of 2000 took 0.077s
  training loss:		0.836247
  validation loss:		0.723852
  validation accuracy:		87.39 %
Epoch 61 of 2000 took 0.077s
  training loss:		0.808861
  validation loss:		0.698664
  validation accuracy:		88.37 %
Epoch 62 of 2000 took 0.077s
  training loss:		0.780107
  validation loss:		0.679644
  validation accuracy:		86.52 %
Epoch 63 of 2000 took 0.077s
  training loss:		0.754427
  validation loss:		0.659788
  validation accuracy:		87.17 %
Epoch 64 of 2000 took 0.077s
  training loss:		0.731998
  validation loss:		0.632829
  validation accuracy:		87.61 %
Epoch 65 of 2000 took 0.079s
  training loss:		0.708234
  validation loss:		0.611981
  validation accuracy:		87.39 %
Epoch 66 of 2000 took 0.073s
  training loss:		0.685987
  validation loss:		0.597679
  validation accuracy:		87.72 %
Epoch 67 of 2000 took 0.077s
  training loss:		0.671549
  validation loss:		0.570780
  validation accuracy:		88.37 %
Epoch 68 of 2000 took 0.077s
  training loss:		0.650512
  validation loss:		0.564566
  validation accuracy:		87.72 %
Epoch 69 of 2000 took 0.079s
  training loss:		0.634011
  validation loss:		0.543686
  validation accuracy:		88.37 %
Epoch 70 of 2000 took 0.078s
  training loss:		0.612655
  validation loss:		0.534768
  validation accuracy:		88.48 %
Epoch 71 of 2000 took 0.080s
  training loss:		0.601251
  validation loss:		0.518363
  validation accuracy:		88.04 %
Epoch 72 of 2000 took 0.075s
  training loss:		0.586635
  validation loss:		0.517616
  validation accuracy:		87.61 %
Epoch 73 of 2000 took 0.078s
  training loss:		0.571029
  validation loss:		0.500044
  validation accuracy:		88.04 %
Epoch 74 of 2000 took 0.077s
  training loss:		0.556338
  validation loss:		0.479796
  validation accuracy:		88.04 %
Epoch 75 of 2000 took 0.079s
  training loss:		0.538944
  validation loss:		0.473765
  validation accuracy:		88.80 %
Epoch 76 of 2000 took 0.079s
  training loss:		0.533095
  validation loss:		0.469291
  validation accuracy:		88.15 %
Epoch 77 of 2000 took 0.079s
  training loss:		0.518588
  validation loss:		0.449652
  validation accuracy:		88.48 %
Epoch 78 of 2000 took 0.079s
  training loss:		0.498317
  validation loss:		0.452330
  validation accuracy:		89.24 %
Epoch 79 of 2000 took 0.077s
  training loss:		0.496130
  validation loss:		0.432101
  validation accuracy:		88.37 %
Epoch 80 of 2000 took 0.079s
  training loss:		0.486969
  validation loss:		0.426000
  validation accuracy:		89.46 %
Epoch 81 of 2000 took 0.078s
  training loss:		0.476431
  validation loss:		0.418533
  validation accuracy:		88.91 %
Epoch 82 of 2000 took 0.079s
  training loss:		0.466027
  validation loss:		0.403698
  validation accuracy:		89.57 %
Epoch 83 of 2000 took 0.078s
  training loss:		0.457527
  validation loss:		0.419930
  validation accuracy:		89.35 %
Epoch 84 of 2000 took 0.078s
  training loss:		0.443147
  validation loss:		0.400410
  validation accuracy:		88.80 %
Epoch 85 of 2000 took 0.079s
  training loss:		0.434718
  validation loss:		0.386754
  validation accuracy:		89.78 %
Epoch 86 of 2000 took 0.077s
  training loss:		0.428797
  validation loss:		0.381844
  validation accuracy:		89.24 %
Epoch 87 of 2000 took 0.077s
  training loss:		0.420600
  validation loss:		0.375618
  validation accuracy:		89.35 %
Epoch 88 of 2000 took 0.078s
  training loss:		0.416190
  validation loss:		0.377991
  validation accuracy:		89.46 %
Epoch 89 of 2000 took 0.080s
  training loss:		0.404152
  validation loss:		0.367953
  validation accuracy:		89.78 %
Epoch 90 of 2000 took 0.085s
  training loss:		0.402888
  validation loss:		0.364932
  validation accuracy:		90.00 %
Epoch 91 of 2000 took 0.079s
  training loss:		0.390215
  validation loss:		0.350482
  validation accuracy:		90.00 %
Epoch 92 of 2000 took 0.077s
  training loss:		0.385974
  validation loss:		0.350678
  validation accuracy:		90.22 %
Epoch 93 of 2000 took 0.066s
  training loss:		0.378913
  validation loss:		0.349869
  validation accuracy:		90.11 %
Epoch 94 of 2000 took 0.060s
  training loss:		0.366908
  validation loss:		0.345689
  validation accuracy:		90.11 %
Epoch 95 of 2000 took 0.159s
  training loss:		0.362587
  validation loss:		0.333647
  validation accuracy:		90.76 %
Epoch 96 of 2000 took 0.059s
  training loss:		0.356962
  validation loss:		0.332510
  validation accuracy:		90.43 %
Epoch 97 of 2000 took 0.060s
  training loss:		0.353900
  validation loss:		0.332925
  validation accuracy:		90.43 %
Epoch 98 of 2000 took 0.106s
  training loss:		0.347601
  validation loss:		0.328132
  validation accuracy:		90.33 %
Epoch 99 of 2000 took 0.073s
  training loss:		0.341359
  validation loss:		0.317886
  validation accuracy:		90.98 %
Epoch 100 of 2000 took 0.094s
  training loss:		0.332719
  validation loss:		0.316700
  validation accuracy:		90.54 %
Epoch 101 of 2000 took 0.059s
  training loss:		0.332158
  validation loss:		0.320935
  validation accuracy:		90.54 %
Epoch 102 of 2000 took 0.058s
  training loss:		0.323026
  validation loss:		0.305630
  validation accuracy:		90.87 %
Epoch 103 of 2000 took 0.059s
  training loss:		0.328353
  validation loss:		0.305459
  validation accuracy:		90.76 %
Epoch 104 of 2000 took 0.059s
  training loss:		0.320622
  validation loss:		0.306353
  validation accuracy:		90.76 %
Epoch 105 of 2000 took 0.057s
  training loss:		0.309708
  validation loss:		0.311156
  validation accuracy:		91.41 %
Epoch 106 of 2000 took 0.057s
  training loss:		0.311996
  validation loss:		0.293577
  validation accuracy:		90.87 %
Epoch 107 of 2000 took 0.060s
  training loss:		0.310945
  validation loss:		0.298933
  validation accuracy:		91.09 %
Epoch 108 of 2000 took 0.058s
  training loss:		0.303699
  validation loss:		0.299513
  validation accuracy:		90.98 %
Epoch 109 of 2000 took 0.056s
  training loss:		0.297790
  validation loss:		0.293219
  validation accuracy:		91.52 %
Epoch 110 of 2000 took 0.057s
  training loss:		0.296234
  validation loss:		0.283621
  validation accuracy:		91.63 %
Epoch 111 of 2000 took 0.063s
  training loss:		0.294458
  validation loss:		0.288329
  validation accuracy:		91.41 %
Epoch 112 of 2000 took 0.062s
  training loss:		0.289803
  validation loss:		0.286404
  validation accuracy:		92.07 %
Epoch 113 of 2000 took 0.226s
  training loss:		0.283779
  validation loss:		0.277554
  validation accuracy:		91.52 %
Epoch 114 of 2000 took 0.065s
  training loss:		0.281113
  validation loss:		0.278231
  validation accuracy:		91.41 %
Epoch 115 of 2000 took 0.062s
  training loss:		0.286961
  validation loss:		0.277553
  validation accuracy:		91.85 %
Epoch 116 of 2000 took 0.059s
  training loss:		0.275712
  validation loss:		0.273488
  validation accuracy:		91.85 %
Epoch 117 of 2000 took 0.058s
  training loss:		0.273484
  validation loss:		0.275299
  validation accuracy:		91.85 %
Epoch 118 of 2000 took 0.059s
  training loss:		0.273565
  validation loss:		0.274722
  validation accuracy:		92.07 %
Epoch 119 of 2000 took 0.057s
  training loss:		0.272461
  validation loss:		0.262857
  validation accuracy:		91.85 %
Epoch 120 of 2000 took 0.057s
  training loss:		0.268921
  validation loss:		0.269420
  validation accuracy:		91.74 %
Epoch 121 of 2000 took 0.056s
  training loss:		0.265912
  validation loss:		0.265837
  validation accuracy:		91.96 %
Epoch 122 of 2000 took 0.061s
  training loss:		0.260191
  validation loss:		0.263405
  validation accuracy:		91.96 %
Epoch 123 of 2000 took 0.060s
  training loss:		0.257261
  validation loss:		0.259260
  validation accuracy:		91.96 %
Epoch 124 of 2000 took 0.059s
  training loss:		0.250943
  validation loss:		0.258974
  validation accuracy:		92.17 %
Epoch 125 of 2000 took 0.058s
  training loss:		0.253227
  validation loss:		0.257343
  validation accuracy:		92.17 %
Epoch 126 of 2000 took 0.060s
  training loss:		0.251316
  validation loss:		0.256927
  validation accuracy:		92.17 %
Epoch 127 of 2000 took 0.058s
  training loss:		0.244577
  validation loss:		0.258310
  validation accuracy:		92.72 %
Epoch 128 of 2000 took 0.058s
  training loss:		0.249991
  validation loss:		0.254610
  validation accuracy:		92.28 %
Epoch 129 of 2000 took 0.057s
  training loss:		0.241899
  validation loss:		0.251908
  validation accuracy:		92.72 %
Epoch 130 of 2000 took 0.057s
  training loss:		0.239212
  validation loss:		0.251645
  validation accuracy:		92.72 %
Epoch 131 of 2000 took 0.058s
  training loss:		0.242333
  validation loss:		0.252502
  validation accuracy:		92.93 %
Epoch 132 of 2000 took 0.058s
  training loss:		0.239290
  validation loss:		0.249041
  validation accuracy:		92.17 %
Epoch 133 of 2000 took 0.059s
  training loss:		0.235821
  validation loss:		0.250064
  validation accuracy:		92.93 %
Epoch 134 of 2000 took 0.058s
  training loss:		0.237400
  validation loss:		0.243831
  validation accuracy:		92.61 %
Epoch 135 of 2000 took 0.056s
  training loss:		0.233191
  validation loss:		0.248218
  validation accuracy:		92.72 %
Epoch 136 of 2000 took 0.056s
  training loss:		0.228142
  validation loss:		0.242098
  validation accuracy:		92.72 %
Epoch 137 of 2000 took 0.056s
  training loss:		0.229562
  validation loss:		0.237814
  validation accuracy:		93.26 %
Epoch 138 of 2000 took 0.058s
  training loss:		0.229719
  validation loss:		0.242696
  validation accuracy:		93.37 %
Epoch 139 of 2000 took 0.057s
  training loss:		0.229238
  validation loss:		0.240130
  validation accuracy:		92.83 %
Epoch 140 of 2000 took 0.057s
  training loss:		0.225526
  validation loss:		0.238704
  validation accuracy:		93.15 %
Epoch 141 of 2000 took 0.059s
  training loss:		0.221854
  validation loss:		0.235468
  validation accuracy:		93.15 %
Epoch 142 of 2000 took 0.055s
  training loss:		0.220827
  validation loss:		0.235458
  validation accuracy:		92.83 %
Epoch 143 of 2000 took 0.058s
  training loss:		0.221066
  validation loss:		0.234116
  validation accuracy:		93.37 %
Epoch 144 of 2000 took 0.057s
  training loss:		0.222728
  validation loss:		0.230308
  validation accuracy:		93.04 %
Epoch 145 of 2000 took 0.056s
  training loss:		0.219361
  validation loss:		0.235688
  validation accuracy:		92.83 %
Epoch 146 of 2000 took 0.055s
  training loss:		0.217663
  validation loss:		0.232197
  validation accuracy:		93.37 %
Epoch 147 of 2000 took 0.057s
  training loss:		0.213304
  validation loss:		0.231376
  validation accuracy:		93.15 %
Epoch 148 of 2000 took 0.059s
  training loss:		0.209182
  validation loss:		0.228949
  validation accuracy:		93.26 %
Epoch 149 of 2000 took 0.059s
  training loss:		0.209701
  validation loss:		0.231579
  validation accuracy:		93.59 %
Epoch 150 of 2000 took 0.057s
  training loss:		0.206752
  validation loss:		0.233019
  validation accuracy:		93.26 %
Epoch 151 of 2000 took 0.059s
  training loss:		0.206407
  validation loss:		0.225345
  validation accuracy:		93.70 %
Epoch 152 of 2000 took 0.058s
  training loss:		0.205546
  validation loss:		0.228188
  validation accuracy:		93.70 %
Epoch 153 of 2000 took 0.058s
  training loss:		0.207756
  validation loss:		0.224456
  validation accuracy:		93.48 %
Epoch 154 of 2000 took 0.058s
  training loss:		0.203831
  validation loss:		0.221017
  validation accuracy:		93.70 %
Epoch 155 of 2000 took 0.057s
  training loss:		0.203308
  validation loss:		0.225923
  validation accuracy:		93.48 %
Epoch 156 of 2000 took 0.057s
  training loss:		0.202714
  validation loss:		0.221046
  validation accuracy:		94.13 %
Epoch 157 of 2000 took 0.058s
  training loss:		0.197264
  validation loss:		0.222085
  validation accuracy:		93.37 %
Epoch 158 of 2000 took 0.058s
  training loss:		0.201457
  validation loss:		0.222829
  validation accuracy:		93.91 %
Epoch 159 of 2000 took 0.057s
  training loss:		0.197482
  validation loss:		0.219892
  validation accuracy:		93.15 %
Epoch 160 of 2000 took 0.058s
  training loss:		0.198535
  validation loss:		0.224423
  validation accuracy:		93.59 %
Epoch 161 of 2000 took 0.057s
  training loss:		0.195285
  validation loss:		0.216151
  validation accuracy:		93.26 %
Epoch 162 of 2000 took 0.058s
  training loss:		0.194582
  validation loss:		0.217523
  validation accuracy:		93.70 %
Epoch 163 of 2000 took 0.058s
  training loss:		0.192897
  validation loss:		0.221577
  validation accuracy:		93.80 %
Epoch 164 of 2000 took 0.058s
  training loss:		0.190436
  validation loss:		0.217932
  validation accuracy:		93.48 %
Epoch 165 of 2000 took 0.056s
  training loss:		0.193572
  validation loss:		0.216436
  validation accuracy:		93.37 %
Epoch 166 of 2000 took 0.057s
  training loss:		0.187575
  validation loss:		0.212449
  validation accuracy:		94.02 %
Epoch 167 of 2000 took 0.058s
  training loss:		0.188301
  validation loss:		0.222182
  validation accuracy:		93.37 %
Epoch 168 of 2000 took 0.057s
  training loss:		0.189911
  validation loss:		0.222265
  validation accuracy:		93.91 %
Epoch 169 of 2000 took 0.057s
  training loss:		0.186945
  validation loss:		0.213582
  validation accuracy:		94.13 %
Epoch 170 of 2000 took 0.058s
  training loss:		0.184627
  validation loss:		0.210790
  validation accuracy:		93.80 %
Epoch 171 of 2000 took 0.055s
  training loss:		0.185090
  validation loss:		0.209256
  validation accuracy:		94.13 %
Epoch 172 of 2000 took 0.057s
  training loss:		0.184987
  validation loss:		0.213599
  validation accuracy:		93.48 %
Epoch 173 of 2000 took 0.057s
  training loss:		0.183231
  validation loss:		0.209594
  validation accuracy:		94.13 %
Epoch 174 of 2000 took 0.057s
  training loss:		0.184469
  validation loss:		0.215245
  validation accuracy:		93.80 %
Epoch 175 of 2000 took 0.058s
  training loss:		0.180286
  validation loss:		0.215597
  validation accuracy:		93.91 %
Epoch 176 of 2000 took 0.058s
  training loss:		0.178994
  validation loss:		0.209619
  validation accuracy:		93.70 %
Epoch 177 of 2000 took 0.058s
  training loss:		0.179298
  validation loss:		0.208713
  validation accuracy:		93.91 %
Epoch 178 of 2000 took 0.058s
  training loss:		0.179852
  validation loss:		0.204589
  validation accuracy:		94.13 %
Epoch 179 of 2000 took 0.057s
  training loss:		0.178945
  validation loss:		0.214176
  validation accuracy:		93.48 %
Epoch 180 of 2000 took 0.057s
  training loss:		0.180381
  validation loss:		0.211362
  validation accuracy:		93.91 %
Epoch 181 of 2000 took 0.058s
  training loss:		0.175346
  validation loss:		0.203346
  validation accuracy:		94.24 %
Epoch 182 of 2000 took 0.057s
  training loss:		0.177485
  validation loss:		0.211680
  validation accuracy:		94.02 %
Epoch 183 of 2000 took 0.057s
  training loss:		0.174322
  validation loss:		0.210341
  validation accuracy:		93.70 %
Epoch 184 of 2000 took 0.057s
  training loss:		0.174747
  validation loss:		0.204867
  validation accuracy:		94.13 %
Epoch 185 of 2000 took 0.057s
  training loss:		0.174622
  validation loss:		0.209538
  validation accuracy:		94.02 %
Epoch 186 of 2000 took 0.057s
  training loss:		0.168836
  validation loss:		0.208311
  validation accuracy:		93.80 %
Epoch 187 of 2000 took 0.058s
  training loss:		0.174152
  validation loss:		0.204358
  validation accuracy:		93.91 %
Epoch 188 of 2000 took 0.058s
  training loss:		0.171001
  validation loss:		0.203462
  validation accuracy:		94.24 %
Epoch 189 of 2000 took 0.057s
  training loss:		0.168311
  validation loss:		0.206749
  validation accuracy:		94.02 %
Epoch 190 of 2000 took 0.057s
  training loss:		0.167128
  validation loss:		0.203963
  validation accuracy:		94.02 %
Epoch 191 of 2000 took 0.059s
  training loss:		0.168534
  validation loss:		0.198705
  validation accuracy:		93.91 %
Epoch 192 of 2000 took 0.059s
  training loss:		0.167959
  validation loss:		0.202735
  validation accuracy:		94.24 %
Epoch 193 of 2000 took 0.060s
  training loss:		0.166598
  validation loss:		0.198267
  validation accuracy:		93.91 %
Epoch 194 of 2000 took 0.059s
  training loss:		0.167994
  validation loss:		0.197003
  validation accuracy:		94.24 %
Epoch 195 of 2000 took 0.063s
  training loss:		0.166889
  validation loss:		0.202805
  validation accuracy:		94.13 %
Epoch 196 of 2000 took 0.058s
  training loss:		0.162400
  validation loss:		0.198071
  validation accuracy:		94.02 %
Epoch 197 of 2000 took 0.057s
  training loss:		0.162118
  validation loss:		0.198104
  validation accuracy:		94.13 %
Epoch 198 of 2000 took 0.058s
  training loss:		0.163327
  validation loss:		0.197489
  validation accuracy:		94.24 %
Epoch 199 of 2000 took 0.058s
  training loss:		0.156004
  validation loss:		0.198548
  validation accuracy:		94.02 %
Epoch 200 of 2000 took 0.059s
  training loss:		0.162002
  validation loss:		0.205019
  validation accuracy:		94.02 %
Epoch 201 of 2000 took 0.057s
  training loss:		0.161501
  validation loss:		0.195187
  validation accuracy:		94.24 %
Epoch 202 of 2000 took 0.060s
  training loss:		0.159777
  validation loss:		0.201212
  validation accuracy:		94.02 %
Epoch 203 of 2000 took 0.057s
  training loss:		0.156481
  validation loss:		0.195133
  validation accuracy:		94.24 %
Epoch 204 of 2000 took 0.058s
  training loss:		0.156631
  validation loss:		0.203072
  validation accuracy:		93.91 %
Epoch 205 of 2000 took 0.060s
  training loss:		0.159321
  validation loss:		0.199587
  validation accuracy:		94.02 %
Epoch 206 of 2000 took 0.056s
  training loss:		0.154947
  validation loss:		0.195181
  validation accuracy:		94.46 %
Epoch 207 of 2000 took 0.059s
  training loss:		0.152760
  validation loss:		0.201908
  validation accuracy:		94.13 %
Epoch 208 of 2000 took 0.059s
  training loss:		0.157622
  validation loss:		0.192744
  validation accuracy:		94.46 %
Epoch 209 of 2000 took 0.056s
  training loss:		0.156375
  validation loss:		0.196574
  validation accuracy:		94.02 %
Epoch 210 of 2000 took 0.059s
  training loss:		0.154603
  validation loss:		0.195979
  validation accuracy:		94.67 %
Epoch 211 of 2000 took 0.057s
  training loss:		0.148202
  validation loss:		0.195562
  validation accuracy:		94.46 %
Epoch 212 of 2000 took 0.059s
  training loss:		0.153855
  validation loss:		0.193680
  validation accuracy:		94.89 %
Epoch 213 of 2000 took 0.058s
  training loss:		0.151730
  validation loss:		0.195391
  validation accuracy:		94.57 %
Epoch 214 of 2000 took 0.059s
  training loss:		0.153066
  validation loss:		0.191720
  validation accuracy:		94.46 %
Epoch 215 of 2000 took 0.058s
  training loss:		0.152598
  validation loss:		0.197254
  validation accuracy:		94.35 %
Epoch 216 of 2000 took 0.060s
  training loss:		0.147947
  validation loss:		0.195118
  validation accuracy:		94.67 %
Epoch 217 of 2000 took 0.057s
  training loss:		0.150857
  validation loss:		0.194619
  validation accuracy:		94.57 %
Epoch 218 of 2000 took 0.059s
  training loss:		0.145506
  validation loss:		0.192819
  validation accuracy:		94.24 %
Epoch 219 of 2000 took 0.058s
  training loss:		0.144532
  validation loss:		0.197271
  validation accuracy:		94.57 %
Epoch 220 of 2000 took 0.058s
  training loss:		0.147412
  validation loss:		0.193008
  validation accuracy:		94.35 %
Epoch 221 of 2000 took 0.057s
  training loss:		0.144111
  validation loss:		0.194053
  validation accuracy:		94.24 %
Epoch 222 of 2000 took 0.059s
  training loss:		0.145968
  validation loss:		0.201943
  validation accuracy:		94.24 %
Epoch 223 of 2000 took 0.058s
  training loss:		0.147167
  validation loss:		0.190445
  validation accuracy:		94.57 %
Epoch 224 of 2000 took 0.058s
  training loss:		0.146803
  validation loss:		0.188747
  validation accuracy:		94.24 %
Epoch 225 of 2000 took 0.058s
  training loss:		0.149235
  validation loss:		0.191635
  validation accuracy:		94.57 %
Epoch 226 of 2000 took 0.058s
  training loss:		0.143276
  validation loss:		0.189865
  validation accuracy:		94.35 %
Epoch 227 of 2000 took 0.058s
  training loss:		0.143883
  validation loss:		0.193807
  validation accuracy:		94.89 %
Epoch 228 of 2000 took 0.058s
  training loss:		0.143775
  validation loss:		0.196662
  validation accuracy:		94.46 %
Epoch 229 of 2000 took 0.058s
  training loss:		0.142586
  validation loss:		0.190706
  validation accuracy:		94.35 %
Epoch 230 of 2000 took 0.058s
  training loss:		0.141394
  validation loss:		0.188175
  validation accuracy:		94.57 %
Epoch 231 of 2000 took 0.058s
  training loss:		0.144276
  validation loss:		0.187282
  validation accuracy:		94.46 %
Epoch 232 of 2000 took 0.058s
  training loss:		0.139696
  validation loss:		0.189003
  validation accuracy:		95.00 %
Epoch 233 of 2000 took 0.057s
  training loss:		0.139114
  validation loss:		0.188899
  validation accuracy:		94.57 %
Epoch 234 of 2000 took 0.056s
  training loss:		0.137928
  validation loss:		0.192263
  validation accuracy:		94.78 %
Epoch 235 of 2000 took 0.059s
  training loss:		0.139076
  validation loss:		0.185701
  validation accuracy:		94.78 %
Epoch 236 of 2000 took 0.057s
  training loss:		0.139772
  validation loss:		0.190134
  validation accuracy:		94.46 %
Epoch 237 of 2000 took 0.058s
  training loss:		0.137283
  validation loss:		0.190465
  validation accuracy:		94.89 %
Epoch 238 of 2000 took 0.057s
  training loss:		0.139530
  validation loss:		0.188419
  validation accuracy:		94.78 %
Epoch 239 of 2000 took 0.058s
  training loss:		0.133694
  validation loss:		0.187466
  validation accuracy:		94.46 %
Epoch 240 of 2000 took 0.058s
  training loss:		0.136100
  validation loss:		0.187812
  validation accuracy:		94.35 %
Epoch 241 of 2000 took 0.056s
  training loss:		0.133874
  validation loss:		0.183462
  validation accuracy:		94.78 %
Epoch 242 of 2000 took 0.057s
  training loss:		0.137993
  validation loss:		0.192605
  validation accuracy:		95.00 %
Epoch 243 of 2000 took 0.059s
  training loss:		0.135381
  validation loss:		0.188646
  validation accuracy:		94.57 %
Epoch 244 of 2000 took 0.057s
  training loss:		0.134717
  validation loss:		0.186289
  validation accuracy:		94.46 %
Epoch 245 of 2000 took 0.058s
  training loss:		0.133029
  validation loss:		0.188806
  validation accuracy:		94.46 %
Epoch 246 of 2000 took 0.059s
  training loss:		0.135130
  validation loss:		0.186603
  validation accuracy:		94.67 %
Epoch 247 of 2000 took 0.057s
  training loss:		0.132597
  validation loss:		0.185592
  validation accuracy:		94.67 %
Epoch 248 of 2000 took 0.059s
  training loss:		0.132312
  validation loss:		0.189255
  validation accuracy:		94.57 %
Epoch 249 of 2000 took 0.059s
  training loss:		0.131391
  validation loss:		0.195738
  validation accuracy:		94.57 %
Epoch 250 of 2000 took 0.056s
  training loss:		0.131289
  validation loss:		0.186890
  validation accuracy:		95.00 %
Epoch 251 of 2000 took 0.059s
  training loss:		0.133470
  validation loss:		0.191264
  validation accuracy:		94.67 %
Epoch 252 of 2000 took 0.059s
  training loss:		0.130453
  validation loss:		0.191948
  validation accuracy:		94.24 %
Epoch 253 of 2000 took 0.058s
  training loss:		0.129575
  validation loss:		0.187464
  validation accuracy:		94.78 %
Epoch 254 of 2000 took 0.108s
  training loss:		0.132514
  validation loss:		0.185397
  validation accuracy:		94.67 %
Epoch 255 of 2000 took 0.181s
  training loss:		0.129913
  validation loss:		0.187899
  validation accuracy:		94.78 %
Epoch 256 of 2000 took 0.138s
  training loss:		0.129624
  validation loss:		0.185113
  validation accuracy:		94.67 %
Epoch 257 of 2000 took 0.126s
  training loss:		0.124256
  validation loss:		0.190880
  validation accuracy:		94.78 %
Epoch 258 of 2000 took 0.170s
  training loss:		0.123262
  validation loss:		0.186555
  validation accuracy:		94.89 %
Epoch 259 of 2000 took 0.123s
  training loss:		0.126281
  validation loss:		0.186527
  validation accuracy:		94.78 %
Epoch 260 of 2000 took 0.123s
  training loss:		0.130639
  validation loss:		0.184886
  validation accuracy:		94.67 %
Epoch 261 of 2000 took 0.145s
  training loss:		0.125257
  validation loss:		0.191689
  validation accuracy:		94.67 %
Epoch 262 of 2000 took 0.128s
  training loss:		0.125862
  validation loss:		0.184463
  validation accuracy:		94.78 %
Epoch 263 of 2000 took 0.119s
  training loss:		0.122252
  validation loss:		0.182556
  validation accuracy:		94.57 %
Epoch 264 of 2000 took 0.148s
  training loss:		0.126230
  validation loss:		0.185531
  validation accuracy:		94.46 %
Epoch 265 of 2000 took 0.094s
  training loss:		0.124869
  validation loss:		0.184443
  validation accuracy:		94.67 %
Epoch 266 of 2000 took 0.085s
  training loss:		0.123937
  validation loss:		0.182431
  validation accuracy:		94.57 %
Epoch 267 of 2000 took 0.127s
  training loss:		0.126441
  validation loss:		0.182333
  validation accuracy:		94.78 %
Epoch 268 of 2000 took 0.133s
  training loss:		0.123170
  validation loss:		0.191807
  validation accuracy:		94.35 %
Epoch 269 of 2000 took 0.108s
  training loss:		0.123940
  validation loss:		0.188459
  validation accuracy:		94.46 %
Epoch 270 of 2000 took 0.092s
  training loss:		0.120538
  validation loss:		0.184650
  validation accuracy:		94.89 %
Epoch 271 of 2000 took 0.119s
  training loss:		0.123939
  validation loss:		0.181408
  validation accuracy:		94.67 %
Epoch 272 of 2000 took 0.093s
  training loss:		0.120383
  validation loss:		0.186330
  validation accuracy:		94.78 %
Epoch 273 of 2000 took 0.101s
  training loss:		0.118237
  validation loss:		0.182588
  validation accuracy:		94.89 %
Epoch 274 of 2000 took 0.099s
  training loss:		0.118821
  validation loss:		0.188863
  validation accuracy:		94.67 %
Epoch 275 of 2000 took 0.110s
  training loss:		0.121247
  validation loss:		0.191857
  validation accuracy:		94.67 %
Epoch 276 of 2000 took 0.109s
  training loss:		0.117565
  validation loss:		0.182933
  validation accuracy:		94.57 %
Epoch 277 of 2000 took 0.110s
  training loss:		0.119227
  validation loss:		0.182893
  validation accuracy:		94.46 %
Epoch 278 of 2000 took 0.110s
  training loss:		0.120772
  validation loss:		0.182584
  validation accuracy:		94.67 %
Epoch 279 of 2000 took 0.109s
  training loss:		0.120287
  validation loss:		0.185804
  validation accuracy:		94.35 %
Epoch 280 of 2000 took 0.110s
  training loss:		0.117579
  validation loss:		0.185246
  validation accuracy:		94.24 %
Epoch 281 of 2000 took 0.123s
  training loss:		0.119801
  validation loss:		0.182695
  validation accuracy:		94.67 %
Epoch 282 of 2000 took 0.124s
  training loss:		0.118658
  validation loss:		0.183977
  validation accuracy:		94.78 %
Epoch 283 of 2000 took 0.140s
  training loss:		0.113797
  validation loss:		0.182415
  validation accuracy:		94.89 %
Epoch 284 of 2000 took 0.109s
  training loss:		0.113489
  validation loss:		0.182932
  validation accuracy:		94.78 %
Epoch 285 of 2000 took 0.109s
  training loss:		0.117599
  validation loss:		0.190999
  validation accuracy:		94.57 %
Epoch 286 of 2000 took 0.111s
  training loss:		0.114684
  validation loss:		0.184409
  validation accuracy:		94.89 %
Epoch 287 of 2000 took 0.109s
  training loss:		0.113830
  validation loss:		0.182068
  validation accuracy:		94.78 %
Epoch 288 of 2000 took 0.112s
  training loss:		0.115876
  validation loss:		0.184459
  validation accuracy:		94.57 %
Epoch 289 of 2000 took 0.105s
  training loss:		0.113491
  validation loss:		0.181231
  validation accuracy:		94.46 %
Epoch 290 of 2000 took 0.109s
  training loss:		0.112831
  validation loss:		0.181010
  validation accuracy:		94.46 %
Epoch 291 of 2000 took 0.105s
  training loss:		0.112561
  validation loss:		0.184747
  validation accuracy:		94.89 %
Epoch 292 of 2000 took 0.092s
  training loss:		0.116685
  validation loss:		0.182946
  validation accuracy:		94.78 %
Epoch 293 of 2000 took 0.112s
  training loss:		0.113267
  validation loss:		0.182399
  validation accuracy:		94.67 %
Epoch 294 of 2000 took 0.109s
  training loss:		0.111660
  validation loss:		0.180812
  validation accuracy:		94.57 %
Epoch 295 of 2000 took 0.109s
  training loss:		0.112818
  validation loss:		0.186629
  validation accuracy:		94.67 %
Epoch 296 of 2000 took 0.110s
  training loss:		0.112153
  validation loss:		0.184910
  validation accuracy:		94.57 %
Epoch 297 of 2000 took 0.102s
  training loss:		0.108188
  validation loss:		0.181676
  validation accuracy:		94.78 %
Epoch 298 of 2000 took 0.098s
  training loss:		0.113644
  validation loss:		0.183360
  validation accuracy:		94.78 %
Epoch 299 of 2000 took 0.098s
  training loss:		0.107372
  validation loss:		0.184920
  validation accuracy:		94.78 %
Epoch 300 of 2000 took 0.139s
  training loss:		0.112084
  validation loss:		0.180762
  validation accuracy:		94.89 %
Epoch 301 of 2000 took 0.140s
  training loss:		0.111362
  validation loss:		0.186284
  validation accuracy:		94.46 %
Epoch 302 of 2000 took 0.110s
  training loss:		0.112168
  validation loss:		0.180814
  validation accuracy:		94.78 %
Epoch 303 of 2000 took 0.104s
  training loss:		0.111189
  validation loss:		0.188682
  validation accuracy:		94.57 %
Epoch 304 of 2000 took 0.110s
  training loss:		0.107606
  validation loss:		0.184495
  validation accuracy:		94.46 %
Epoch 305 of 2000 took 0.111s
  training loss:		0.110769
  validation loss:		0.181028
  validation accuracy:		94.67 %
Epoch 306 of 2000 took 0.110s
  training loss:		0.107415
  validation loss:		0.185943
  validation accuracy:		94.67 %
Epoch 307 of 2000 took 0.107s
  training loss:		0.108009
  validation loss:		0.182171
  validation accuracy:		94.78 %
Epoch 308 of 2000 took 0.120s
  training loss:		0.108771
  validation loss:		0.182485
  validation accuracy:		94.67 %
Epoch 309 of 2000 took 0.150s
  training loss:		0.108716
  validation loss:		0.186797
  validation accuracy:		94.57 %
Epoch 310 of 2000 took 0.106s
  training loss:		0.107252
  validation loss:		0.187139
  validation accuracy:		94.46 %
Epoch 311 of 2000 took 0.184s
  training loss:		0.109061
  validation loss:		0.181200
  validation accuracy:		94.46 %
Epoch 312 of 2000 took 0.133s
  training loss:		0.107901
  validation loss:		0.181167
  validation accuracy:		94.57 %
Epoch 313 of 2000 took 0.160s
  training loss:		0.103032
  validation loss:		0.182924
  validation accuracy:		94.46 %
Epoch 314 of 2000 took 0.116s
  training loss:		0.105780
  validation loss:		0.183853
  validation accuracy:		94.46 %
Epoch 315 of 2000 took 0.156s
  training loss:		0.104330
  validation loss:		0.182342
  validation accuracy:		94.46 %
Epoch 316 of 2000 took 0.110s
  training loss:		0.106278
  validation loss:		0.183016
  validation accuracy:		94.57 %
Epoch 317 of 2000 took 0.120s
  training loss:		0.106743
  validation loss:		0.190016
  validation accuracy:		94.57 %
Epoch 318 of 2000 took 0.161s
  training loss:		0.107150
  validation loss:		0.184570
  validation accuracy:		94.35 %
Epoch 319 of 2000 took 0.141s
  training loss:		0.100896
  validation loss:		0.182025
  validation accuracy:		94.67 %
Epoch 320 of 2000 took 0.118s
  training loss:		0.104257
  validation loss:		0.187039
  validation accuracy:		94.89 %
Epoch 321 of 2000 took 0.135s
  training loss:		0.101902
  validation loss:		0.183182
  validation accuracy:		94.46 %
Epoch 322 of 2000 took 0.109s
  training loss:		0.104698
  validation loss:		0.180425
  validation accuracy:		94.57 %
Epoch 323 of 2000 took 0.091s
  training loss:		0.105063
  validation loss:		0.183100
  validation accuracy:		94.35 %
Epoch 324 of 2000 took 0.060s
  training loss:		0.100434
  validation loss:		0.182670
  validation accuracy:		94.46 %
Epoch 325 of 2000 took 0.058s
  training loss:		0.104157
  validation loss:		0.188339
  validation accuracy:		94.46 %
Epoch 326 of 2000 took 0.058s
  training loss:		0.101880
  validation loss:		0.183584
  validation accuracy:		94.57 %
Epoch 327 of 2000 took 0.058s
  training loss:		0.102371
  validation loss:		0.180190
  validation accuracy:		94.78 %
Epoch 328 of 2000 took 0.057s
  training loss:		0.104331
  validation loss:		0.185834
  validation accuracy:		94.78 %
Epoch 329 of 2000 took 0.059s
  training loss:		0.103607
  validation loss:		0.180436
  validation accuracy:		94.46 %
Epoch 330 of 2000 took 0.060s
  training loss:		0.098606
  validation loss:		0.185165
  validation accuracy:		94.67 %
Epoch 331 of 2000 took 0.057s
  training loss:		0.097746
  validation loss:		0.184257
  validation accuracy:		94.67 %
Epoch 332 of 2000 took 0.058s
  training loss:		0.099869
  validation loss:		0.185444
  validation accuracy:		94.57 %
Epoch 333 of 2000 took 0.056s
  training loss:		0.097591
  validation loss:		0.183145
  validation accuracy:		94.78 %
Epoch 334 of 2000 took 0.057s
  training loss:		0.098161
  validation loss:		0.181609
  validation accuracy:		94.78 %
Epoch 335 of 2000 took 0.060s
  training loss:		0.098242
  validation loss:		0.183928
  validation accuracy:		94.46 %
Epoch 336 of 2000 took 0.063s
  training loss:		0.096977
  validation loss:		0.185100
  validation accuracy:		94.46 %
Epoch 337 of 2000 took 0.062s
  training loss:		0.097171
  validation loss:		0.183795
  validation accuracy:		94.67 %
Epoch 338 of 2000 took 0.058s
  training loss:		0.097482
  validation loss:		0.182961
  validation accuracy:		94.78 %
Epoch 339 of 2000 took 0.061s
  training loss:		0.096269
  validation loss:		0.188906
  validation accuracy:		94.57 %
Epoch 340 of 2000 took 0.077s
  training loss:		0.095292
  validation loss:		0.181774
  validation accuracy:		94.46 %
Epoch 341 of 2000 took 0.074s
  training loss:		0.097454
  validation loss:		0.186021
  validation accuracy:		94.46 %
Epoch 342 of 2000 took 0.076s
  training loss:		0.098408
  validation loss:		0.184716
  validation accuracy:		94.57 %
Epoch 343 of 2000 took 0.076s
  training loss:		0.097902
  validation loss:		0.186691
  validation accuracy:		94.57 %
Epoch 344 of 2000 took 0.075s
  training loss:		0.096354
  validation loss:		0.187510
  validation accuracy:		94.78 %
Epoch 345 of 2000 took 0.075s
  training loss:		0.092819
  validation loss:		0.183652
  validation accuracy:		94.57 %
Epoch 346 of 2000 took 0.076s
  training loss:		0.096112
  validation loss:		0.178819
  validation accuracy:		94.57 %
Epoch 347 of 2000 took 0.075s
  training loss:		0.096420
  validation loss:		0.185382
  validation accuracy:		94.35 %
Epoch 348 of 2000 took 0.077s
  training loss:		0.094656
  validation loss:		0.185234
  validation accuracy:		94.67 %
Epoch 349 of 2000 took 0.076s
  training loss:		0.095373
  validation loss:		0.184635
  validation accuracy:		94.35 %
Epoch 350 of 2000 took 0.077s
  training loss:		0.094190
  validation loss:		0.184360
  validation accuracy:		93.91 %
Epoch 351 of 2000 took 0.079s
  training loss:		0.095701
  validation loss:		0.184436
  validation accuracy:		94.46 %
Epoch 352 of 2000 took 0.079s
  training loss:		0.092870
  validation loss:		0.183578
  validation accuracy:		94.35 %
Epoch 353 of 2000 took 0.077s
  training loss:		0.095660
  validation loss:		0.186540
  validation accuracy:		94.57 %
Epoch 354 of 2000 took 0.075s
  training loss:		0.092311
  validation loss:		0.190238
  validation accuracy:		94.57 %
Epoch 355 of 2000 took 0.076s
  training loss:		0.092631
  validation loss:		0.188492
  validation accuracy:		94.35 %
Epoch 356 of 2000 took 0.076s
  training loss:		0.092633
  validation loss:		0.183241
  validation accuracy:		94.78 %
Epoch 357 of 2000 took 0.079s
  training loss:		0.093688
  validation loss:		0.189508
  validation accuracy:		94.57 %
Epoch 358 of 2000 took 0.076s
  training loss:		0.090483
  validation loss:		0.182938
  validation accuracy:		94.13 %
Epoch 359 of 2000 took 0.075s
  training loss:		0.090109
  validation loss:		0.189491
  validation accuracy:		94.46 %
Epoch 360 of 2000 took 0.083s
  training loss:		0.091944
  validation loss:		0.191589
  validation accuracy:		94.67 %
Epoch 361 of 2000 took 0.081s
  training loss:		0.088872
  validation loss:		0.184517
  validation accuracy:		94.46 %
Epoch 362 of 2000 took 0.077s
  training loss:		0.090185
  validation loss:		0.186206
  validation accuracy:		94.35 %
Epoch 363 of 2000 took 0.082s
  training loss:		0.090791
  validation loss:		0.189673
  validation accuracy:		94.57 %
Epoch 364 of 2000 took 0.078s
  training loss:		0.089899
  validation loss:		0.183108
  validation accuracy:		94.78 %
Epoch 365 of 2000 took 0.076s
  training loss:		0.089303
  validation loss:		0.183768
  validation accuracy:		94.57 %
Epoch 366 of 2000 took 0.077s
  training loss:		0.091793
  validation loss:		0.193275
  validation accuracy:		94.35 %
Epoch 367 of 2000 took 0.077s
  training loss:		0.087610
  validation loss:		0.184829
  validation accuracy:		94.46 %
Epoch 368 of 2000 took 0.078s
  training loss:		0.089171
  validation loss:		0.182706
  validation accuracy:		94.46 %
Epoch 369 of 2000 took 0.078s
  training loss:		0.091348
  validation loss:		0.189220
  validation accuracy:		94.24 %
Epoch 370 of 2000 took 0.077s
  training loss:		0.088043
  validation loss:		0.189344
  validation accuracy:		94.67 %
Epoch 371 of 2000 took 0.077s
  training loss:		0.088027
  validation loss:		0.183267
  validation accuracy:		94.57 %
Epoch 372 of 2000 took 0.077s
  training loss:		0.089897
  validation loss:		0.188950
  validation accuracy:		94.35 %
Epoch 373 of 2000 took 0.077s
  training loss:		0.088581
  validation loss:		0.190940
  validation accuracy:		94.24 %
Epoch 374 of 2000 took 0.078s
  training loss:		0.085479
  validation loss:		0.182909
  validation accuracy:		94.46 %
Epoch 375 of 2000 took 0.079s
  training loss:		0.087020
  validation loss:		0.185118
  validation accuracy:		94.13 %
Epoch 376 of 2000 took 0.076s
  training loss:		0.088328
  validation loss:		0.188632
  validation accuracy:		94.57 %
Epoch 377 of 2000 took 0.076s
  training loss:		0.083913
  validation loss:		0.184018
  validation accuracy:		94.35 %
Epoch 378 of 2000 took 0.077s
  training loss:		0.087661
  validation loss:		0.189066
  validation accuracy:		94.13 %
Epoch 379 of 2000 took 0.073s
  training loss:		0.084114
  validation loss:		0.184020
  validation accuracy:		94.67 %
Epoch 380 of 2000 took 0.076s
  training loss:		0.086369
  validation loss:		0.186393
  validation accuracy:		94.57 %
Epoch 381 of 2000 took 0.076s
  training loss:		0.087352
  validation loss:		0.182812
  validation accuracy:		94.57 %
Epoch 382 of 2000 took 0.073s
  training loss:		0.087252
  validation loss:		0.187426
  validation accuracy:		94.67 %
Epoch 383 of 2000 took 0.077s
  training loss:		0.088725
  validation loss:		0.190208
  validation accuracy:		94.46 %
Epoch 384 of 2000 took 0.076s
  training loss:		0.084272
  validation loss:		0.183355
  validation accuracy:		94.57 %
Epoch 385 of 2000 took 0.077s
  training loss:		0.084084
  validation loss:		0.187340
  validation accuracy:		94.67 %
Epoch 386 of 2000 took 0.077s
  training loss:		0.084460
  validation loss:		0.186814
  validation accuracy:		94.35 %
Epoch 387 of 2000 took 0.076s
  training loss:		0.083611
  validation loss:		0.187560
  validation accuracy:		94.67 %
Epoch 388 of 2000 took 0.077s
  training loss:		0.082648
  validation loss:		0.184145
  validation accuracy:		94.35 %
Epoch 389 of 2000 took 0.075s
  training loss:		0.084376
  validation loss:		0.187224
  validation accuracy:		94.46 %
Epoch 390 of 2000 took 0.074s
  training loss:		0.084983
  validation loss:		0.194227
  validation accuracy:		94.13 %
Epoch 391 of 2000 took 0.075s
  training loss:		0.084785
  validation loss:		0.184803
  validation accuracy:		94.57 %
Epoch 392 of 2000 took 0.076s
  training loss:		0.084164
  validation loss:		0.186902
  validation accuracy:		94.46 %
Epoch 393 of 2000 took 0.073s
  training loss:		0.083422
  validation loss:		0.191233
  validation accuracy:		94.57 %
Epoch 394 of 2000 took 0.075s
  training loss:		0.083182
  validation loss:		0.186481
  validation accuracy:		94.67 %
Epoch 395 of 2000 took 0.078s
  training loss:		0.083631
  validation loss:		0.190229
  validation accuracy:		94.35 %
Epoch 396 of 2000 took 0.076s
  training loss:		0.081068
  validation loss:		0.195944
  validation accuracy:		94.78 %
Epoch 397 of 2000 took 0.074s
  training loss:		0.083150
  validation loss:		0.188958
  validation accuracy:		95.00 %
Epoch 398 of 2000 took 0.074s
  training loss:		0.082157
  validation loss:		0.188044
  validation accuracy:		94.35 %
Epoch 399 of 2000 took 0.074s
  training loss:		0.083042
  validation loss:		0.191946
  validation accuracy:		95.00 %
Epoch 400 of 2000 took 0.076s
  training loss:		0.082924
  validation loss:		0.188396
  validation accuracy:		94.24 %
Epoch 401 of 2000 took 0.074s
  training loss:		0.079845
  validation loss:		0.190033
  validation accuracy:		94.57 %
Epoch 402 of 2000 took 0.073s
  training loss:		0.081404
  validation loss:		0.184768
  validation accuracy:		94.57 %
Epoch 403 of 2000 took 0.076s
  training loss:		0.081330
  validation loss:		0.193567
  validation accuracy:		94.35 %
Epoch 404 of 2000 took 0.075s
  training loss:		0.080734
  validation loss:		0.188840
  validation accuracy:		94.24 %
Epoch 405 of 2000 took 0.079s
  training loss:		0.079725
  validation loss:		0.187356
  validation accuracy:		94.35 %
Epoch 406 of 2000 took 0.076s
  training loss:		0.080989
  validation loss:		0.188898
  validation accuracy:		94.35 %
Epoch 407 of 2000 took 0.075s
  training loss:		0.077732
  validation loss:		0.195035
  validation accuracy:		94.89 %
Epoch 408 of 2000 took 0.078s
  training loss:		0.081394
  validation loss:		0.187763
  validation accuracy:		94.67 %
Epoch 409 of 2000 took 0.078s
  training loss:		0.080106
  validation loss:		0.187615
  validation accuracy:		94.35 %
Epoch 410 of 2000 took 0.078s
  training loss:		0.077756
  validation loss:		0.192307
  validation accuracy:		94.35 %
Epoch 411 of 2000 took 0.077s
  training loss:		0.079955
  validation loss:		0.198075
  validation accuracy:		94.35 %
Epoch 412 of 2000 took 0.080s
  training loss:		0.079284
  validation loss:		0.190656
  validation accuracy:		94.24 %
Epoch 413 of 2000 took 0.078s
  training loss:		0.078938
  validation loss:		0.191033
  validation accuracy:		94.57 %
Epoch 414 of 2000 took 0.076s
  training loss:		0.078765
  validation loss:		0.193157
  validation accuracy:		94.02 %
Epoch 415 of 2000 took 0.077s
  training loss:		0.076173
  validation loss:		0.189934
  validation accuracy:		94.13 %
Epoch 416 of 2000 took 0.077s
  training loss:		0.078967
  validation loss:		0.188760
  validation accuracy:		94.46 %
Epoch 417 of 2000 took 0.079s
  training loss:		0.077734
  validation loss:		0.192466
  validation accuracy:		94.35 %
Epoch 418 of 2000 took 0.077s
  training loss:		0.077618
  validation loss:		0.191383
  validation accuracy:		94.46 %
Epoch 419 of 2000 took 0.077s
  training loss:		0.076759
  validation loss:		0.187933
  validation accuracy:		94.57 %
Epoch 420 of 2000 took 0.077s
  training loss:		0.076763
  validation loss:		0.194206
  validation accuracy:		94.57 %
Epoch 421 of 2000 took 0.076s
  training loss:		0.077538
  validation loss:		0.187319
  validation accuracy:		94.46 %
Epoch 422 of 2000 took 0.079s
  training loss:		0.077679
  validation loss:		0.195911
  validation accuracy:		94.46 %
Epoch 423 of 2000 took 0.076s
  training loss:		0.076718
  validation loss:		0.192169
  validation accuracy:		94.35 %
Epoch 424 of 2000 took 0.078s
  training loss:		0.075163
  validation loss:		0.193178
  validation accuracy:		94.46 %
Epoch 425 of 2000 took 0.077s
  training loss:		0.076238
  validation loss:		0.195827
  validation accuracy:		94.35 %
Epoch 426 of 2000 took 0.078s
  training loss:		0.077188
  validation loss:		0.188788
  validation accuracy:		94.46 %
Epoch 427 of 2000 took 0.077s
  training loss:		0.073976
  validation loss:		0.190853
  validation accuracy:		94.67 %
Epoch 428 of 2000 took 0.077s
  training loss:		0.074456
  validation loss:		0.193067
  validation accuracy:		94.13 %
Epoch 429 of 2000 took 0.078s
  training loss:		0.073496
  validation loss:		0.191428
  validation accuracy:		94.57 %
Epoch 430 of 2000 took 0.078s
  training loss:		0.075196
  validation loss:		0.197995
  validation accuracy:		94.35 %
Epoch 431 of 2000 took 0.074s
  training loss:		0.077457
  validation loss:		0.193493
  validation accuracy:		94.46 %
Epoch 432 of 2000 took 0.077s
  training loss:		0.072841
  validation loss:		0.195297
  validation accuracy:		94.67 %
Epoch 433 of 2000 took 0.079s
  training loss:		0.073547
  validation loss:		0.188453
  validation accuracy:		94.35 %
Epoch 434 of 2000 took 0.078s
  training loss:		0.074422
  validation loss:		0.189727
  validation accuracy:		94.67 %
Epoch 435 of 2000 took 0.078s
  training loss:		0.073624
  validation loss:		0.194221
  validation accuracy:		94.46 %
Epoch 436 of 2000 took 0.077s
  training loss:		0.073224
  validation loss:		0.194479
  validation accuracy:		94.35 %
Epoch 437 of 2000 took 0.079s
  training loss:		0.073324
  validation loss:		0.196061
  validation accuracy:		94.13 %
Epoch 438 of 2000 took 0.078s
  training loss:		0.075301
  validation loss:		0.193884
  validation accuracy:		94.46 %
Epoch 439 of 2000 took 0.078s
  training loss:		0.071516
  validation loss:		0.195243
  validation accuracy:		94.46 %
Epoch 440 of 2000 took 0.078s
  training loss:		0.071038
  validation loss:		0.188407
  validation accuracy:		94.46 %
Epoch 441 of 2000 took 0.077s
  training loss:		0.073849
  validation loss:		0.196470
  validation accuracy:		94.57 %
Epoch 442 of 2000 took 0.076s
  training loss:		0.071484
  validation loss:		0.198361
  validation accuracy:		94.57 %
Epoch 443 of 2000 took 0.079s
  training loss:		0.073045
  validation loss:		0.195952
  validation accuracy:		93.80 %
Epoch 444 of 2000 took 0.078s
  training loss:		0.071397
  validation loss:		0.187435
  validation accuracy:		94.67 %
Epoch 445 of 2000 took 0.076s
  training loss:		0.071693
  validation loss:		0.198508
  validation accuracy:		94.35 %
Epoch 446 of 2000 took 0.076s
  training loss:		0.072000
  validation loss:		0.194260
  validation accuracy:		94.35 %
Epoch 447 of 2000 took 0.077s
  training loss:		0.070868
  validation loss:		0.193023
  validation accuracy:		94.46 %
Epoch 448 of 2000 took 0.077s
  training loss:		0.070925
  validation loss:		0.199810
  validation accuracy:		94.13 %
Epoch 449 of 2000 took 0.076s
  training loss:		0.071580
  validation loss:		0.194711
  validation accuracy:		94.46 %
Epoch 450 of 2000 took 0.075s
  training loss:		0.070681
  validation loss:		0.192048
  validation accuracy:		94.35 %
Epoch 451 of 2000 took 0.075s
  training loss:		0.070788
  validation loss:		0.199909
  validation accuracy:		94.35 %
Epoch 452 of 2000 took 0.076s
  training loss:		0.070172
  validation loss:		0.193073
  validation accuracy:		94.35 %
Epoch 453 of 2000 took 0.076s
  training loss:		0.069296
  validation loss:		0.199926
  validation accuracy:		94.35 %
Epoch 454 of 2000 took 0.075s
  training loss:		0.068664
  validation loss:		0.198216
  validation accuracy:		94.24 %
Epoch 455 of 2000 took 0.079s
  training loss:		0.065923
  validation loss:		0.199681
  validation accuracy:		94.57 %
Epoch 456 of 2000 took 0.077s
  training loss:		0.071913
  validation loss:		0.201446
  validation accuracy:		94.46 %
Epoch 457 of 2000 took 0.075s
  training loss:		0.068859
  validation loss:		0.198304
  validation accuracy:		94.24 %
Epoch 458 of 2000 took 0.077s
  training loss:		0.070232
  validation loss:		0.199518
  validation accuracy:		94.46 %
Epoch 459 of 2000 took 0.076s
  training loss:		0.069655
  validation loss:		0.191765
  validation accuracy:		94.57 %
Epoch 460 of 2000 took 0.073s
  training loss:		0.070404
  validation loss:		0.199523
  validation accuracy:		94.24 %
Epoch 461 of 2000 took 0.075s
  training loss:		0.068316
  validation loss:		0.197768
  validation accuracy:		94.35 %
Epoch 462 of 2000 took 0.074s
  training loss:		0.069090
  validation loss:		0.196383
  validation accuracy:		94.46 %
Epoch 463 of 2000 took 0.078s
  training loss:		0.067918
  validation loss:		0.195778
  validation accuracy:		94.57 %
Epoch 464 of 2000 took 0.074s
  training loss:		0.069964
  validation loss:		0.195018
  validation accuracy:		94.57 %
Epoch 465 of 2000 took 0.077s
  training loss:		0.066044
  validation loss:		0.193977
  validation accuracy:		94.57 %
Epoch 466 of 2000 took 0.075s
  training loss:		0.069423
  validation loss:		0.198447
  validation accuracy:		94.46 %
Epoch 467 of 2000 took 0.075s
  training loss:		0.065865
  validation loss:		0.196996
  validation accuracy:		94.46 %
Epoch 468 of 2000 took 0.074s
  training loss:		0.065287
  validation loss:		0.196449
  validation accuracy:		94.57 %
Epoch 469 of 2000 took 0.075s
  training loss:		0.066371
  validation loss:		0.198552
  validation accuracy:		94.46 %
Epoch 470 of 2000 took 0.075s
  training loss:		0.065136
  validation loss:		0.194074
  validation accuracy:		94.67 %
Epoch 471 of 2000 took 0.076s
  training loss:		0.065774
  validation loss:		0.201236
  validation accuracy:		94.46 %
Epoch 472 of 2000 took 0.074s
  training loss:		0.066745
  validation loss:		0.199937
  validation accuracy:		94.46 %
Epoch 473 of 2000 took 0.076s
  training loss:		0.066507
  validation loss:		0.196531
  validation accuracy:		94.57 %
Epoch 474 of 2000 took 0.075s
  training loss:		0.066923
  validation loss:		0.200465
  validation accuracy:		94.57 %
Epoch 475 of 2000 took 0.075s
  training loss:		0.064401
  validation loss:		0.200618
  validation accuracy:		94.35 %
Epoch 476 of 2000 took 0.076s
  training loss:		0.065145
  validation loss:		0.192605
  validation accuracy:		94.57 %
Epoch 477 of 2000 took 0.074s
  training loss:		0.067175
  validation loss:		0.205355
  validation accuracy:		94.35 %
Epoch 478 of 2000 took 0.076s
  training loss:		0.065350
  validation loss:		0.202019
  validation accuracy:		94.35 %
Epoch 479 of 2000 took 0.076s
  training loss:		0.065375
  validation loss:		0.194171
  validation accuracy:		94.57 %
Epoch 480 of 2000 took 0.078s
  training loss:		0.066702
  validation loss:		0.204515
  validation accuracy:		94.24 %
Epoch 481 of 2000 took 0.076s
  training loss:		0.064223
  validation loss:		0.200366
  validation accuracy:		94.46 %
Epoch 482 of 2000 took 0.077s
  training loss:		0.064987
  validation loss:		0.205544
  validation accuracy:		94.13 %
Epoch 483 of 2000 took 0.078s
  training loss:		0.065657
  validation loss:		0.203856
  validation accuracy:		94.57 %
Epoch 484 of 2000 took 0.074s
  training loss:		0.064674
  validation loss:		0.200966
  validation accuracy:		94.35 %
Epoch 485 of 2000 took 0.076s
  training loss:		0.064318
  validation loss:		0.198611
  validation accuracy:		94.57 %
Epoch 486 of 2000 took 0.075s
  training loss:		0.063523
  validation loss:		0.202805
  validation accuracy:		94.35 %
Epoch 487 of 2000 took 0.077s
  training loss:		0.065014
  validation loss:		0.201249
  validation accuracy:		94.46 %
Epoch 488 of 2000 took 0.078s
  training loss:		0.065200
  validation loss:		0.205180
  validation accuracy:		94.46 %
Epoch 489 of 2000 took 0.076s
  training loss:		0.062683
  validation loss:		0.204332
  validation accuracy:		94.24 %
Epoch 490 of 2000 took 0.075s
  training loss:		0.061187
  validation loss:		0.203237
  validation accuracy:		94.46 %
Epoch 491 of 2000 took 0.077s
  training loss:		0.062431
  validation loss:		0.200290
  validation accuracy:		94.67 %
Epoch 492 of 2000 took 0.074s
  training loss:		0.065292
  validation loss:		0.201454
  validation accuracy:		94.35 %
Epoch 493 of 2000 took 0.077s
  training loss:		0.064726
  validation loss:		0.209367
  validation accuracy:		94.24 %
Epoch 494 of 2000 took 0.077s
  training loss:		0.062310
  validation loss:		0.201072
  validation accuracy:		94.57 %
Epoch 495 of 2000 took 0.079s
  training loss:		0.063370
  validation loss:		0.205120
  validation accuracy:		94.24 %
Epoch 496 of 2000 took 0.077s
  training loss:		0.064654
  validation loss:		0.206894
  validation accuracy:		94.35 %
Epoch 497 of 2000 took 0.078s
  training loss:		0.062848
  validation loss:		0.200351
  validation accuracy:		94.35 %
Epoch 498 of 2000 took 0.079s
  training loss:		0.062691
  validation loss:		0.204415
  validation accuracy:		94.24 %
Epoch 499 of 2000 took 0.077s
  training loss:		0.062902
  validation loss:		0.201779
  validation accuracy:		94.46 %
Epoch 500 of 2000 took 0.079s
  training loss:		0.062955
  validation loss:		0.199796
  validation accuracy:		94.67 %
Epoch 501 of 2000 took 0.076s
  training loss:		0.062036
  validation loss:		0.206328
  validation accuracy:		94.35 %
Epoch 502 of 2000 took 0.074s
  training loss:		0.062273
  validation loss:		0.205263
  validation accuracy:		94.24 %
Epoch 503 of 2000 took 0.078s
  training loss:		0.061321
  validation loss:		0.204122
  validation accuracy:		94.67 %
Epoch 504 of 2000 took 0.078s
  training loss:		0.060150
  validation loss:		0.204694
  validation accuracy:		94.46 %
Epoch 505 of 2000 took 0.077s
  training loss:		0.058842
  validation loss:		0.201198
  validation accuracy:		94.35 %
Epoch 506 of 2000 took 0.078s
  training loss:		0.061729
  validation loss:		0.208855
  validation accuracy:		94.02 %
Epoch 507 of 2000 took 0.077s
  training loss:		0.059807
  validation loss:		0.204091
  validation accuracy:		94.46 %
Epoch 508 of 2000 took 0.076s
  training loss:		0.061669
  validation loss:		0.216828
  validation accuracy:		94.02 %
Epoch 509 of 2000 took 0.075s
  training loss:		0.061393
  validation loss:		0.203870
  validation accuracy:		94.57 %
Epoch 510 of 2000 took 0.076s
  training loss:		0.061425
  validation loss:		0.213620
  validation accuracy:		94.13 %
Epoch 511 of 2000 took 0.076s
  training loss:		0.061715
  validation loss:		0.202249
  validation accuracy:		94.46 %
Epoch 512 of 2000 took 0.078s
  training loss:		0.060640
  validation loss:		0.203466
  validation accuracy:		94.57 %
Epoch 513 of 2000 took 0.077s
  training loss:		0.061688
  validation loss:		0.209756
  validation accuracy:		94.35 %
Epoch 514 of 2000 took 0.078s
  training loss:		0.059167
  validation loss:		0.209041
  validation accuracy:		94.35 %
Epoch 515 of 2000 took 0.077s
  training loss:		0.058685
  validation loss:		0.204349
  validation accuracy:		94.57 %
Epoch 516 of 2000 took 0.077s
  training loss:		0.058947
  validation loss:		0.201920
  validation accuracy:		94.35 %
Epoch 517 of 2000 took 0.077s
  training loss:		0.058823
  validation loss:		0.209302
  validation accuracy:		94.46 %
Epoch 518 of 2000 took 0.075s
  training loss:		0.059857
  validation loss:		0.217084
  validation accuracy:		93.80 %
Epoch 519 of 2000 took 0.073s
  training loss:		0.056697
  validation loss:		0.210129
  validation accuracy:		94.24 %
Epoch 520 of 2000 took 0.076s
  training loss:		0.060603
  validation loss:		0.209113
  validation accuracy:		94.24 %
Epoch 521 of 2000 took 0.079s
  training loss:		0.059704
  validation loss:		0.205578
  validation accuracy:		94.57 %
Epoch 522 of 2000 took 0.077s
  training loss:		0.057570
  validation loss:		0.202599
  validation accuracy:		94.57 %
Epoch 523 of 2000 took 0.079s
  training loss:		0.057752
  validation loss:		0.208526
  validation accuracy:		94.13 %
Epoch 524 of 2000 took 0.078s
  training loss:		0.057457
  validation loss:		0.209296
  validation accuracy:		94.35 %
Epoch 525 of 2000 took 0.077s
  training loss:		0.058420
  validation loss:		0.211427
  validation accuracy:		94.24 %
Epoch 526 of 2000 took 0.078s
  training loss:		0.059077
  validation loss:		0.211685
  validation accuracy:		94.13 %
Epoch 527 of 2000 took 0.077s
  training loss:		0.059204
  validation loss:		0.210725
  validation accuracy:		94.35 %
Epoch 528 of 2000 took 0.077s
  training loss:		0.057984
  validation loss:		0.213044
  validation accuracy:		94.24 %
Epoch 529 of 2000 took 0.079s
  training loss:		0.057652
  validation loss:		0.212229
  validation accuracy:		94.35 %
Epoch 530 of 2000 took 0.075s
  training loss:		0.057857
  validation loss:		0.208908
  validation accuracy:		94.35 %
Epoch 531 of 2000 took 0.078s
  training loss:		0.055297
  validation loss:		0.209255
  validation accuracy:		94.35 %
Epoch 532 of 2000 took 0.075s
  training loss:		0.055740
  validation loss:		0.212165
  validation accuracy:		94.35 %
Epoch 533 of 2000 took 0.076s
  training loss:		0.055294
  validation loss:		0.210255
  validation accuracy:		94.35 %
Epoch 534 of 2000 took 0.076s
  training loss:		0.057328
  validation loss:		0.218549
  validation accuracy:		94.13 %
Epoch 535 of 2000 took 0.077s
  training loss:		0.056186
  validation loss:		0.215114
  validation accuracy:		94.24 %
Epoch 536 of 2000 took 0.077s
  training loss:		0.057315
  validation loss:		0.211053
  validation accuracy:		94.35 %
Epoch 537 of 2000 took 0.078s
  training loss:		0.057716
  validation loss:		0.212152
  validation accuracy:		94.35 %
Epoch 538 of 2000 took 0.078s
  training loss:		0.056387
  validation loss:		0.211805
  validation accuracy:		94.13 %
Epoch 539 of 2000 took 0.078s
  training loss:		0.054033
  validation loss:		0.212230
  validation accuracy:		94.24 %
Epoch 540 of 2000 took 0.078s
  training loss:		0.054209
  validation loss:		0.216489
  validation accuracy:		94.02 %
Epoch 541 of 2000 took 0.077s
  training loss:		0.055519
  validation loss:		0.211741
  validation accuracy:		94.46 %
Epoch 542 of 2000 took 0.078s
  training loss:		0.054001
  validation loss:		0.211988
  validation accuracy:		94.02 %
Epoch 543 of 2000 took 0.078s
  training loss:		0.055372
  validation loss:		0.216788
  validation accuracy:		94.24 %
Epoch 544 of 2000 took 0.077s
  training loss:		0.052773
  validation loss:		0.211180
  validation accuracy:		94.46 %
Epoch 545 of 2000 took 0.077s
  training loss:		0.052148
  validation loss:		0.216714
  validation accuracy:		94.02 %
Epoch 546 of 2000 took 0.076s
  training loss:		0.055423
  validation loss:		0.214522
  validation accuracy:		94.13 %
Epoch 547 of 2000 took 0.076s
  training loss:		0.055005
  validation loss:		0.221917
  validation accuracy:		93.91 %
Epoch 548 of 2000 took 0.076s
  training loss:		0.053591
  validation loss:		0.216581
  validation accuracy:		94.02 %
Epoch 549 of 2000 took 0.076s
  training loss:		0.054922
  validation loss:		0.210958
  validation accuracy:		94.24 %
Epoch 550 of 2000 took 0.076s
  training loss:		0.051926
  validation loss:		0.216359
  validation accuracy:		94.35 %
Epoch 551 of 2000 took 0.077s
  training loss:		0.055775
  validation loss:		0.213235
  validation accuracy:		94.57 %
Epoch 552 of 2000 took 0.077s
  training loss:		0.053540
  validation loss:		0.213768
  validation accuracy:		94.13 %
Epoch 553 of 2000 took 0.077s
  training loss:		0.054559
  validation loss:		0.217288
  validation accuracy:		94.02 %
Epoch 554 of 2000 took 0.077s
  training loss:		0.052385
  validation loss:		0.214137
  validation accuracy:		94.57 %
Epoch 555 of 2000 took 0.078s
  training loss:		0.054218
  validation loss:		0.218545
  validation accuracy:		94.13 %
Epoch 556 of 2000 took 0.076s
  training loss:		0.054441
  validation loss:		0.215588
  validation accuracy:		94.13 %
Epoch 557 of 2000 took 0.078s
  training loss:		0.055104
  validation loss:		0.220108
  validation accuracy:		94.13 %
Epoch 558 of 2000 took 0.074s
  training loss:		0.052388
  validation loss:		0.208280
  validation accuracy:		94.35 %
Epoch 559 of 2000 took 0.074s
  training loss:		0.052150
  validation loss:		0.213315
  validation accuracy:		94.67 %
Epoch 560 of 2000 took 0.076s
  training loss:		0.053626
  validation loss:		0.216223
  validation accuracy:		94.35 %
Epoch 561 of 2000 took 0.076s
  training loss:		0.052322
  validation loss:		0.215248
  validation accuracy:		94.24 %
Epoch 562 of 2000 took 0.076s
  training loss:		0.052859
  validation loss:		0.219970
  validation accuracy:		94.24 %
Epoch 563 of 2000 took 0.077s
  training loss:		0.052319
  validation loss:		0.213427
  validation accuracy:		94.24 %
Epoch 564 of 2000 took 0.076s
  training loss:		0.050891
  validation loss:		0.217825
  validation accuracy:		94.02 %
Epoch 565 of 2000 took 0.076s
  training loss:		0.050120
  validation loss:		0.218831
  validation accuracy:		94.02 %
Epoch 566 of 2000 took 0.078s
  training loss:		0.051863
  validation loss:		0.215357
  validation accuracy:		94.35 %
Epoch 567 of 2000 took 0.075s
  training loss:		0.051620
  validation loss:		0.215375
  validation accuracy:		94.13 %
Epoch 568 of 2000 took 0.076s
  training loss:		0.053012
  validation loss:		0.220748
  validation accuracy:		94.13 %
Epoch 569 of 2000 took 0.075s
  training loss:		0.051476
  validation loss:		0.218220
  validation accuracy:		94.24 %
Epoch 570 of 2000 took 0.074s
  training loss:		0.051833
  validation loss:		0.215476
  validation accuracy:		94.13 %
Epoch 571 of 2000 took 0.074s
  training loss:		0.052369
  validation loss:		0.213764
  validation accuracy:		94.02 %
Epoch 572 of 2000 took 0.074s
  training loss:		0.050788
  validation loss:		0.216135
  validation accuracy:		94.24 %
Epoch 573 of 2000 took 0.077s
  training loss:		0.051823
  validation loss:		0.219987
  validation accuracy:		94.13 %
Epoch 574 of 2000 took 0.076s
  training loss:		0.051445
  validation loss:		0.219555
  validation accuracy:		93.91 %
Epoch 575 of 2000 took 0.075s
  training loss:		0.053921
  validation loss:		0.228029
  validation accuracy:		94.02 %
Epoch 576 of 2000 took 0.078s
  training loss:		0.051957
  validation loss:		0.227928
  validation accuracy:		93.91 %
Epoch 577 of 2000 took 0.074s
  training loss:		0.050111
  validation loss:		0.215268
  validation accuracy:		94.57 %
Epoch 578 of 2000 took 0.077s
  training loss:		0.049175
  validation loss:		0.224284
  validation accuracy:		94.13 %
Epoch 579 of 2000 took 0.077s
  training loss:		0.051246
  validation loss:		0.223090
  validation accuracy:		94.13 %
Epoch 580 of 2000 took 0.074s
  training loss:		0.049823
  validation loss:		0.223440
  validation accuracy:		94.02 %
Epoch 581 of 2000 took 0.077s
  training loss:		0.048697
  validation loss:		0.221489
  validation accuracy:		94.02 %
Epoch 582 of 2000 took 0.079s
  training loss:		0.050107
  validation loss:		0.222132
  validation accuracy:		94.35 %
Epoch 583 of 2000 took 0.077s
  training loss:		0.048622
  validation loss:		0.223057
  validation accuracy:		94.13 %
Epoch 584 of 2000 took 0.077s
  training loss:		0.047983
  validation loss:		0.219532
  validation accuracy:		94.24 %
Epoch 585 of 2000 took 0.077s
  training loss:		0.048058
  validation loss:		0.220059
  validation accuracy:		94.13 %
Epoch 586 of 2000 took 0.076s
  training loss:		0.047336
  validation loss:		0.222204
  validation accuracy:		94.13 %
Epoch 587 of 2000 took 0.072s
  training loss:		0.048789
  validation loss:		0.226114
  validation accuracy:		94.24 %
Epoch 588 of 2000 took 0.077s
  training loss:		0.048566
  validation loss:		0.222606
  validation accuracy:		93.91 %
Epoch 589 of 2000 took 0.075s
  training loss:		0.049366
  validation loss:		0.223074
  validation accuracy:		94.24 %
Epoch 590 of 2000 took 0.076s
  training loss:		0.047772
  validation loss:		0.221597
  validation accuracy:		94.24 %
Epoch 591 of 2000 took 0.077s
  training loss:		0.049540
  validation loss:		0.222549
  validation accuracy:		94.02 %
Epoch 592 of 2000 took 0.078s
  training loss:		0.048515
  validation loss:		0.223811
  validation accuracy:		94.13 %
Epoch 593 of 2000 took 0.076s
  training loss:		0.047190
  validation loss:		0.217100
  validation accuracy:		94.24 %
Epoch 594 of 2000 took 0.080s
  training loss:		0.048062
  validation loss:		0.229180
  validation accuracy:		93.80 %
Epoch 595 of 2000 took 0.081s
  training loss:		0.048943
  validation loss:		0.230177
  validation accuracy:		94.02 %
Epoch 596 of 2000 took 0.076s
  training loss:		0.046073
  validation loss:		0.218335
  validation accuracy:		94.24 %
Epoch 597 of 2000 took 0.076s
  training loss:		0.048789
  validation loss:		0.219624
  validation accuracy:		94.35 %
Epoch 598 of 2000 took 0.074s
  training loss:		0.048081
  validation loss:		0.226462
  validation accuracy:		93.91 %
Epoch 599 of 2000 took 0.077s
  training loss:		0.048285
  validation loss:		0.227138
  validation accuracy:		94.13 %
Epoch 600 of 2000 took 0.075s
  training loss:		0.045535
  validation loss:		0.233021
  validation accuracy:		94.24 %
Epoch 601 of 2000 took 0.077s
  training loss:		0.048326
  validation loss:		0.223171
  validation accuracy:		94.24 %
Epoch 602 of 2000 took 0.075s
  training loss:		0.045934
  validation loss:		0.230480
  validation accuracy:		94.02 %
Epoch 603 of 2000 took 0.075s
  training loss:		0.045737
  validation loss:		0.218847
  validation accuracy:		94.35 %
Epoch 604 of 2000 took 0.076s
  training loss:		0.045413
  validation loss:		0.224432
  validation accuracy:		94.02 %
Epoch 605 of 2000 took 0.079s
  training loss:		0.046248
  validation loss:		0.237965
  validation accuracy:		93.80 %
Epoch 606 of 2000 took 0.074s
  training loss:		0.048161
  validation loss:		0.224735
  validation accuracy:		94.24 %
Epoch 607 of 2000 took 0.075s
  training loss:		0.046549
  validation loss:		0.230447
  validation accuracy:		93.91 %
Epoch 608 of 2000 took 0.077s
  training loss:		0.047219
  validation loss:		0.235156
  validation accuracy:		93.91 %
Epoch 609 of 2000 took 0.074s
  training loss:		0.047238
  validation loss:		0.226617
  validation accuracy:		94.24 %
Epoch 610 of 2000 took 0.076s
  training loss:		0.046444
  validation loss:		0.237078
  validation accuracy:		93.80 %
Epoch 611 of 2000 took 0.075s
  training loss:		0.047506
  validation loss:		0.231255
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.076s
  training loss:		0.046523
  validation loss:		0.237214
  validation accuracy:		93.80 %
Epoch 613 of 2000 took 0.075s
  training loss:		0.046010
  validation loss:		0.232724
  validation accuracy:		93.80 %
Epoch 614 of 2000 took 0.075s
  training loss:		0.045183
  validation loss:		0.228450
  validation accuracy:		94.13 %
Epoch 615 of 2000 took 0.077s
  training loss:		0.044925
  validation loss:		0.232417
  validation accuracy:		93.91 %
Epoch 616 of 2000 took 0.076s
  training loss:		0.046002
  validation loss:		0.232741
  validation accuracy:		93.91 %
Epoch 617 of 2000 took 0.078s
  training loss:		0.045255
  validation loss:		0.226874
  validation accuracy:		94.02 %
Epoch 618 of 2000 took 0.076s
  training loss:		0.045930
  validation loss:		0.227572
  validation accuracy:		94.35 %
Epoch 619 of 2000 took 0.076s
  training loss:		0.045818
  validation loss:		0.229130
  validation accuracy:		93.80 %
Epoch 620 of 2000 took 0.076s
  training loss:		0.046670
  validation loss:		0.234855
  validation accuracy:		93.91 %
Epoch 621 of 2000 took 0.078s
  training loss:		0.045227
  validation loss:		0.233831
  validation accuracy:		93.70 %
Epoch 622 of 2000 took 0.076s
  training loss:		0.045298
  validation loss:		0.233816
  validation accuracy:		93.70 %
Epoch 623 of 2000 took 0.078s
  training loss:		0.044235
  validation loss:		0.230814
  validation accuracy:		94.13 %
Epoch 624 of 2000 took 0.076s
  training loss:		0.043703
  validation loss:		0.223337
  validation accuracy:		94.13 %
Epoch 625 of 2000 took 0.074s
  training loss:		0.045015
  validation loss:		0.234151
  validation accuracy:		94.02 %
Epoch 626 of 2000 took 0.075s
  training loss:		0.045031
  validation loss:		0.233019
  validation accuracy:		93.91 %
Epoch 627 of 2000 took 0.077s
  training loss:		0.044079
  validation loss:		0.228321
  validation accuracy:		94.35 %
Epoch 628 of 2000 took 0.076s
  training loss:		0.043915
  validation loss:		0.233378
  validation accuracy:		94.02 %
Epoch 629 of 2000 took 0.076s
  training loss:		0.043895
  validation loss:		0.233203
  validation accuracy:		93.80 %
Epoch 630 of 2000 took 0.078s
  training loss:		0.045204
  validation loss:		0.233497
  validation accuracy:		93.80 %
Epoch 631 of 2000 took 0.077s
  training loss:		0.043903
  validation loss:		0.233402
  validation accuracy:		94.02 %
Epoch 632 of 2000 took 0.077s
  training loss:		0.044812
  validation loss:		0.242796
  validation accuracy:		93.80 %
Epoch 633 of 2000 took 0.074s
  training loss:		0.045439
  validation loss:		0.240264
  validation accuracy:		93.91 %
Epoch 634 of 2000 took 0.077s
  training loss:		0.045559
  validation loss:		0.234380
  validation accuracy:		94.02 %
Epoch 635 of 2000 took 0.077s
  training loss:		0.041458
  validation loss:		0.231250
  validation accuracy:		94.02 %
Epoch 636 of 2000 took 0.077s
  training loss:		0.042924
  validation loss:		0.228930
  validation accuracy:		94.35 %
Epoch 637 of 2000 took 0.077s
  training loss:		0.043252
  validation loss:		0.237987
  validation accuracy:		94.13 %
Epoch 638 of 2000 took 0.077s
  training loss:		0.042111
  validation loss:		0.230072
  validation accuracy:		94.24 %
Epoch 639 of 2000 took 0.078s
  training loss:		0.043674
  validation loss:		0.240600
  validation accuracy:		93.70 %
Epoch 640 of 2000 took 0.075s
  training loss:		0.043551
  validation loss:		0.237058
  validation accuracy:		94.13 %
Epoch 641 of 2000 took 0.076s
  training loss:		0.042933
  validation loss:		0.232935
  validation accuracy:		94.35 %
Epoch 642 of 2000 took 0.076s
  training loss:		0.042565
  validation loss:		0.237363
  validation accuracy:		94.02 %
Epoch 643 of 2000 took 0.076s
  training loss:		0.043166
  validation loss:		0.233667
  validation accuracy:		94.02 %
Epoch 644 of 2000 took 0.073s
  training loss:		0.043184
  validation loss:		0.231340
  validation accuracy:		94.02 %
Epoch 645 of 2000 took 0.076s
  training loss:		0.042384
  validation loss:		0.240747
  validation accuracy:		93.70 %
Epoch 646 of 2000 took 0.079s
  training loss:		0.042784
  validation loss:		0.230968
  validation accuracy:		94.13 %
Epoch 647 of 2000 took 0.075s
  training loss:		0.043115
  validation loss:		0.240489
  validation accuracy:		93.80 %
Epoch 648 of 2000 took 0.073s
  training loss:		0.041181
  validation loss:		0.241203
  validation accuracy:		93.80 %
Epoch 649 of 2000 took 0.076s
  training loss:		0.042427
  validation loss:		0.236805
  validation accuracy:		94.02 %
Epoch 650 of 2000 took 0.076s
  training loss:		0.042580
  validation loss:		0.236442
  validation accuracy:		94.02 %
Epoch 651 of 2000 took 0.075s
  training loss:		0.042795
  validation loss:		0.241659
  validation accuracy:		93.70 %
Epoch 652 of 2000 took 0.075s
  training loss:		0.042087
  validation loss:		0.238604
  validation accuracy:		94.02 %
Epoch 653 of 2000 took 0.075s
  training loss:		0.041801
  validation loss:		0.243213
  validation accuracy:		93.80 %
Epoch 654 of 2000 took 0.075s
  training loss:		0.041671
  validation loss:		0.240401
  validation accuracy:		94.02 %
Epoch 655 of 2000 took 0.074s
  training loss:		0.039819
  validation loss:		0.242361
  validation accuracy:		94.02 %
Epoch 656 of 2000 took 0.073s
  training loss:		0.040875
  validation loss:		0.240645
  validation accuracy:		93.70 %
Epoch 657 of 2000 took 0.076s
  training loss:		0.041378
  validation loss:		0.241390
  validation accuracy:		93.80 %
Epoch 658 of 2000 took 0.077s
  training loss:		0.042448
  validation loss:		0.248996
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.074s
  training loss:		0.040817
  validation loss:		0.250338
  validation accuracy:		93.80 %
Epoch 660 of 2000 took 0.077s
  training loss:		0.042339
  validation loss:		0.233309
  validation accuracy:		94.24 %
Epoch 661 of 2000 took 0.077s
  training loss:		0.041841
  validation loss:		0.239957
  validation accuracy:		93.80 %
Epoch 662 of 2000 took 0.075s
  training loss:		0.040014
  validation loss:		0.243683
  validation accuracy:		93.80 %
Epoch 663 of 2000 took 0.078s
  training loss:		0.040362
  validation loss:		0.240078
  validation accuracy:		93.80 %
Epoch 664 of 2000 took 0.075s
  training loss:		0.040254
  validation loss:		0.238151
  validation accuracy:		94.13 %
Epoch 665 of 2000 took 0.075s
  training loss:		0.038441
  validation loss:		0.251570
  validation accuracy:		93.70 %
Epoch 666 of 2000 took 0.077s
  training loss:		0.040692
  validation loss:		0.241337
  validation accuracy:		93.70 %
Epoch 667 of 2000 took 0.075s
  training loss:		0.039745
  validation loss:		0.237990
  validation accuracy:		94.02 %
Epoch 668 of 2000 took 0.075s
  training loss:		0.040676
  validation loss:		0.244495
  validation accuracy:		93.91 %
Epoch 669 of 2000 took 0.074s
  training loss:		0.039885
  validation loss:		0.240586
  validation accuracy:		93.80 %
Epoch 670 of 2000 took 0.073s
  training loss:		0.038212
  validation loss:		0.243072
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.076s
  training loss:		0.038477
  validation loss:		0.249412
  validation accuracy:		93.48 %
Epoch 672 of 2000 took 0.076s
  training loss:		0.040798
  validation loss:		0.245706
  validation accuracy:		94.02 %
Epoch 673 of 2000 took 0.073s
  training loss:		0.039623
  validation loss:		0.245440
  validation accuracy:		94.02 %
Epoch 674 of 2000 took 0.077s
  training loss:		0.040551
  validation loss:		0.241900
  validation accuracy:		93.70 %
Epoch 675 of 2000 took 0.074s
  training loss:		0.041464
  validation loss:		0.244360
  validation accuracy:		93.80 %
Epoch 676 of 2000 took 0.075s
  training loss:		0.039287
  validation loss:		0.252206
  validation accuracy:		93.80 %
Epoch 677 of 2000 took 0.076s
  training loss:		0.038735
  validation loss:		0.245494
  validation accuracy:		93.70 %
Epoch 678 of 2000 took 0.076s
  training loss:		0.038971
  validation loss:		0.241104
  validation accuracy:		94.24 %
Epoch 679 of 2000 took 0.077s
  training loss:		0.038241
  validation loss:		0.245203
  validation accuracy:		93.80 %
Epoch 680 of 2000 took 0.074s
  training loss:		0.039322
  validation loss:		0.247708
  validation accuracy:		93.80 %
Epoch 681 of 2000 took 0.077s
  training loss:		0.039411
  validation loss:		0.249815
  validation accuracy:		94.02 %
Epoch 682 of 2000 took 0.074s
  training loss:		0.039335
  validation loss:		0.244240
  validation accuracy:		94.02 %
Epoch 683 of 2000 took 0.074s
  training loss:		0.039181
  validation loss:		0.240471
  validation accuracy:		94.02 %
Epoch 684 of 2000 took 0.074s
  training loss:		0.038828
  validation loss:		0.250959
  validation accuracy:		93.91 %
Epoch 685 of 2000 took 0.075s
  training loss:		0.039789
  validation loss:		0.250041
  validation accuracy:		93.59 %
Epoch 686 of 2000 took 0.075s
  training loss:		0.036834
  validation loss:		0.247414
  validation accuracy:		94.02 %
Epoch 687 of 2000 took 0.075s
  training loss:		0.039266
  validation loss:		0.259332
  validation accuracy:		93.70 %
Epoch 688 of 2000 took 0.075s
  training loss:		0.038424
  validation loss:		0.245170
  validation accuracy:		94.02 %
Epoch 689 of 2000 took 0.075s
  training loss:		0.039035
  validation loss:		0.247576
  validation accuracy:		93.80 %
Epoch 690 of 2000 took 0.076s
  training loss:		0.037734
  validation loss:		0.246588
  validation accuracy:		93.70 %
Epoch 691 of 2000 took 0.077s
  training loss:		0.038391
  validation loss:		0.253865
  validation accuracy:		93.37 %
Epoch 692 of 2000 took 0.075s
  training loss:		0.038412
  validation loss:		0.252761
  validation accuracy:		93.70 %
Epoch 693 of 2000 took 0.076s
  training loss:		0.037130
  validation loss:		0.249895
  validation accuracy:		93.70 %
Epoch 694 of 2000 took 0.075s
  training loss:		0.038792
  validation loss:		0.249401
  validation accuracy:		93.59 %
Epoch 695 of 2000 took 0.077s
  training loss:		0.037264
  validation loss:		0.248700
  validation accuracy:		93.91 %
Epoch 696 of 2000 took 0.076s
  training loss:		0.035929
  validation loss:		0.256924
  validation accuracy:		93.80 %
Epoch 697 of 2000 took 0.074s
  training loss:		0.037728
  validation loss:		0.247652
  validation accuracy:		93.80 %
Epoch 698 of 2000 took 0.075s
  training loss:		0.037211
  validation loss:		0.250951
  validation accuracy:		93.80 %
Epoch 699 of 2000 took 0.075s
  training loss:		0.037200
  validation loss:		0.248415
  validation accuracy:		94.02 %
Epoch 700 of 2000 took 0.077s
  training loss:		0.036087
  validation loss:		0.252496
  validation accuracy:		93.80 %
Epoch 701 of 2000 took 0.079s
  training loss:		0.036854
  validation loss:		0.254003
  validation accuracy:		93.91 %
Epoch 702 of 2000 took 0.074s
  training loss:		0.037208
  validation loss:		0.244966
  validation accuracy:		93.91 %
Epoch 703 of 2000 took 0.074s
  training loss:		0.037443
  validation loss:		0.256057
  validation accuracy:		93.91 %
Epoch 704 of 2000 took 0.075s
  training loss:		0.036550
  validation loss:		0.250657
  validation accuracy:		94.02 %
Epoch 705 of 2000 took 0.077s
  training loss:		0.036805
  validation loss:		0.251187
  validation accuracy:		93.80 %
Epoch 706 of 2000 took 0.075s
  training loss:		0.036169
  validation loss:		0.255997
  validation accuracy:		93.70 %
Epoch 707 of 2000 took 0.077s
  training loss:		0.035561
  validation loss:		0.248615
  validation accuracy:		93.91 %
Epoch 708 of 2000 took 0.074s
  training loss:		0.036316
  validation loss:		0.252867
  validation accuracy:		93.70 %
Epoch 709 of 2000 took 0.075s
  training loss:		0.037387
  validation loss:		0.251365
  validation accuracy:		94.13 %
Epoch 710 of 2000 took 0.075s
  training loss:		0.033055
  validation loss:		0.252412
  validation accuracy:		93.48 %
Epoch 711 of 2000 took 0.075s
  training loss:		0.035923
  validation loss:		0.256158
  validation accuracy:		93.80 %
Epoch 712 of 2000 took 0.078s
  training loss:		0.035210
  validation loss:		0.248747
  validation accuracy:		93.80 %
Epoch 713 of 2000 took 0.077s
  training loss:		0.036098
  validation loss:		0.254798
  validation accuracy:		93.80 %
Epoch 714 of 2000 took 0.075s
  training loss:		0.034016
  validation loss:		0.260050
  validation accuracy:		93.91 %
Epoch 715 of 2000 took 0.078s
  training loss:		0.036478
  validation loss:		0.253344
  validation accuracy:		93.80 %
Epoch 716 of 2000 took 0.075s
  training loss:		0.035715
  validation loss:		0.250918
  validation accuracy:		93.80 %
Epoch 717 of 2000 took 0.077s
  training loss:		0.035336
  validation loss:		0.258974
  validation accuracy:		93.80 %
Epoch 718 of 2000 took 0.077s
  training loss:		0.034587
  validation loss:		0.259124
  validation accuracy:		93.70 %
Epoch 719 of 2000 took 0.077s
  training loss:		0.036391
  validation loss:		0.252872
  validation accuracy:		94.02 %
Epoch 720 of 2000 took 0.078s
  training loss:		0.033440
  validation loss:		0.248604
  validation accuracy:		94.02 %
Epoch 721 of 2000 took 0.078s
  training loss:		0.034264
  validation loss:		0.267491
  validation accuracy:		93.48 %
Epoch 722 of 2000 took 0.075s
  training loss:		0.034926
  validation loss:		0.264852
  validation accuracy:		93.70 %
Epoch 723 of 2000 took 0.077s
  training loss:		0.037598
  validation loss:		0.260974
  validation accuracy:		93.91 %
Epoch 724 of 2000 took 0.076s
  training loss:		0.034692
  validation loss:		0.260457
  validation accuracy:		94.02 %
Epoch 725 of 2000 took 0.072s
  training loss:		0.034511
  validation loss:		0.257270
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.076s
  training loss:		0.035062
  validation loss:		0.253269
  validation accuracy:		93.80 %
Epoch 727 of 2000 took 0.075s
  training loss:		0.034685
  validation loss:		0.261541
  validation accuracy:		93.70 %
Epoch 728 of 2000 took 0.074s
  training loss:		0.034974
  validation loss:		0.263679
  validation accuracy:		93.70 %
Epoch 729 of 2000 took 0.076s
  training loss:		0.034517
  validation loss:		0.256180
  validation accuracy:		93.91 %
Epoch 730 of 2000 took 0.074s
  training loss:		0.035538
  validation loss:		0.268492
  validation accuracy:		93.70 %
Epoch 731 of 2000 took 0.074s
  training loss:		0.034207
  validation loss:		0.256577
  validation accuracy:		93.59 %
Epoch 732 of 2000 took 0.075s
  training loss:		0.034028
  validation loss:		0.259513
  validation accuracy:		93.91 %
Epoch 733 of 2000 took 0.077s
  training loss:		0.033013
  validation loss:		0.258971
  validation accuracy:		93.70 %
Epoch 734 of 2000 took 0.075s
  training loss:		0.034130
  validation loss:		0.259091
  validation accuracy:		93.59 %
Epoch 735 of 2000 took 0.074s
  training loss:		0.034504
  validation loss:		0.262308
  validation accuracy:		93.80 %
Epoch 736 of 2000 took 0.076s
  training loss:		0.033940
  validation loss:		0.256011
  validation accuracy:		93.91 %
Epoch 737 of 2000 took 0.074s
  training loss:		0.033130
  validation loss:		0.267802
  validation accuracy:		93.26 %
Epoch 738 of 2000 took 0.077s
  training loss:		0.035107
  validation loss:		0.263584
  validation accuracy:		93.80 %
Epoch 739 of 2000 took 0.080s
  training loss:		0.032911
  validation loss:		0.263554
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.078s
  training loss:		0.033888
  validation loss:		0.260729
  validation accuracy:		93.70 %
Epoch 741 of 2000 took 0.074s
  training loss:		0.034330
  validation loss:		0.259266
  validation accuracy:		94.02 %
Epoch 742 of 2000 took 0.076s
  training loss:		0.032290
  validation loss:		0.259858
  validation accuracy:		93.80 %
Epoch 743 of 2000 took 0.074s
  training loss:		0.033360
  validation loss:		0.265971
  validation accuracy:		93.59 %
Epoch 744 of 2000 took 0.073s
  training loss:		0.030225
  validation loss:		0.266386
  validation accuracy:		93.70 %
Epoch 745 of 2000 took 0.077s
  training loss:		0.033341
  validation loss:		0.265124
  validation accuracy:		93.59 %
Epoch 746 of 2000 took 0.074s
  training loss:		0.033776
  validation loss:		0.266637
  validation accuracy:		93.80 %
Epoch 747 of 2000 took 0.076s
  training loss:		0.032848
  validation loss:		0.258802
  validation accuracy:		93.59 %
Epoch 748 of 2000 took 0.074s
  training loss:		0.033656
  validation loss:		0.262347
  validation accuracy:		93.70 %
Epoch 749 of 2000 took 0.074s
  training loss:		0.031857
  validation loss:		0.263055
  validation accuracy:		93.48 %
Epoch 750 of 2000 took 0.077s
  training loss:		0.032660
  validation loss:		0.259898
  validation accuracy:		94.13 %
Epoch 751 of 2000 took 0.077s
  training loss:		0.031953
  validation loss:		0.268044
  validation accuracy:		93.59 %
Epoch 752 of 2000 took 0.075s
  training loss:		0.033069
  validation loss:		0.261738
  validation accuracy:		93.91 %
Epoch 753 of 2000 took 0.075s
  training loss:		0.032943
  validation loss:		0.264376
  validation accuracy:		93.70 %
Epoch 754 of 2000 took 0.075s
  training loss:		0.033609
  validation loss:		0.265822
  validation accuracy:		93.59 %
Epoch 755 of 2000 took 0.076s
  training loss:		0.032677
  validation loss:		0.264597
  validation accuracy:		93.70 %
Epoch 756 of 2000 took 0.076s
  training loss:		0.032010
  validation loss:		0.264554
  validation accuracy:		93.80 %
Epoch 757 of 2000 took 0.076s
  training loss:		0.032103
  validation loss:		0.260128
  validation accuracy:		93.80 %
Epoch 758 of 2000 took 0.076s
  training loss:		0.032424
  validation loss:		0.266316
  validation accuracy:		93.80 %
Epoch 759 of 2000 took 0.075s
  training loss:		0.032579
  validation loss:		0.263946
  validation accuracy:		93.80 %
Epoch 760 of 2000 took 0.075s
  training loss:		0.031583
  validation loss:		0.271901
  validation accuracy:		93.59 %
Epoch 761 of 2000 took 0.076s
  training loss:		0.030923
  validation loss:		0.271069
  validation accuracy:		93.59 %
Epoch 762 of 2000 took 0.074s
  training loss:		0.031934
  validation loss:		0.267405
  validation accuracy:		93.80 %
Epoch 763 of 2000 took 0.073s
  training loss:		0.031857
  validation loss:		0.261969
  validation accuracy:		93.91 %
Epoch 764 of 2000 took 0.077s
  training loss:		0.032077
  validation loss:		0.270296
  validation accuracy:		93.70 %
Epoch 765 of 2000 took 0.078s
  training loss:		0.031180
  validation loss:		0.271870
  validation accuracy:		93.48 %
Epoch 766 of 2000 took 0.077s
  training loss:		0.031124
  validation loss:		0.264845
  validation accuracy:		93.91 %
Epoch 767 of 2000 took 0.074s
  training loss:		0.031750
  validation loss:		0.270967
  validation accuracy:		93.48 %
Epoch 768 of 2000 took 0.078s
  training loss:		0.031879
  validation loss:		0.271034
  validation accuracy:		93.59 %
Epoch 769 of 2000 took 0.077s
  training loss:		0.031065
  validation loss:		0.264970
  validation accuracy:		93.91 %
Epoch 770 of 2000 took 0.076s
  training loss:		0.031341
  validation loss:		0.264946
  validation accuracy:		93.91 %
Epoch 771 of 2000 took 0.076s
  training loss:		0.032252
  validation loss:		0.269601
  validation accuracy:		93.48 %
Epoch 772 of 2000 took 0.077s
  training loss:		0.031025
  validation loss:		0.277650
  validation accuracy:		93.70 %
Epoch 773 of 2000 took 0.075s
  training loss:		0.030999
  validation loss:		0.282573
  validation accuracy:		93.37 %
Epoch 774 of 2000 took 0.075s
  training loss:		0.030722
  validation loss:		0.271018
  validation accuracy:		93.59 %
Epoch 775 of 2000 took 0.076s
  training loss:		0.030615
  validation loss:		0.270524
  validation accuracy:		93.59 %
Epoch 776 of 2000 took 0.076s
  training loss:		0.031040
  validation loss:		0.274848
  validation accuracy:		93.80 %
Epoch 777 of 2000 took 0.078s
  training loss:		0.030321
  validation loss:		0.271876
  validation accuracy:		93.59 %
Epoch 778 of 2000 took 0.075s
  training loss:		0.031348
  validation loss:		0.270989
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.074s
  training loss:		0.031127
  validation loss:		0.272315
  validation accuracy:		93.70 %
Epoch 780 of 2000 took 0.074s
  training loss:		0.030209
  validation loss:		0.273671
  validation accuracy:		93.59 %
Epoch 781 of 2000 took 0.076s
  training loss:		0.030789
  validation loss:		0.276035
  validation accuracy:		93.48 %
Epoch 782 of 2000 took 0.076s
  training loss:		0.030627
  validation loss:		0.272133
  validation accuracy:		93.70 %
Epoch 783 of 2000 took 0.075s
  training loss:		0.030600
  validation loss:		0.266900
  validation accuracy:		94.02 %
Epoch 784 of 2000 took 0.075s
  training loss:		0.030225
  validation loss:		0.272779
  validation accuracy:		93.70 %
Epoch 785 of 2000 took 0.077s
  training loss:		0.029378
  validation loss:		0.279368
  validation accuracy:		93.15 %
Epoch 786 of 2000 took 0.078s
  training loss:		0.030370
  validation loss:		0.275774
  validation accuracy:		93.80 %
Epoch 787 of 2000 took 0.079s
  training loss:		0.030421
  validation loss:		0.275498
  validation accuracy:		93.59 %
Epoch 788 of 2000 took 0.079s
  training loss:		0.029858
  validation loss:		0.275983
  validation accuracy:		93.48 %
Epoch 789 of 2000 took 0.076s
  training loss:		0.030332
  validation loss:		0.275343
  validation accuracy:		93.26 %
Epoch 790 of 2000 took 0.076s
  training loss:		0.030623
  validation loss:		0.274979
  validation accuracy:		93.70 %
Epoch 791 of 2000 took 0.076s
  training loss:		0.028648
  validation loss:		0.280901
  validation accuracy:		93.59 %
Epoch 792 of 2000 took 0.078s
  training loss:		0.030443
  validation loss:		0.271869
  validation accuracy:		93.70 %
Epoch 793 of 2000 took 0.075s
  training loss:		0.029952
  validation loss:		0.275604
  validation accuracy:		93.70 %
Epoch 794 of 2000 took 0.077s
  training loss:		0.029645
  validation loss:		0.277081
  validation accuracy:		93.26 %
Epoch 795 of 2000 took 0.077s
  training loss:		0.029038
  validation loss:		0.279190
  validation accuracy:		93.70 %
Epoch 796 of 2000 took 0.076s
  training loss:		0.030300
  validation loss:		0.272581
  validation accuracy:		93.48 %
Epoch 797 of 2000 took 0.077s
  training loss:		0.029313
  validation loss:		0.283225
  validation accuracy:		93.37 %
Epoch 798 of 2000 took 0.073s
  training loss:		0.030090
  validation loss:		0.267299
  validation accuracy:		93.91 %
Epoch 799 of 2000 took 0.077s
  training loss:		0.029135
  validation loss:		0.270741
  validation accuracy:		93.80 %
Epoch 800 of 2000 took 0.080s
  training loss:		0.029214
  validation loss:		0.280652
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.078s
  training loss:		0.029667
  validation loss:		0.279670
  validation accuracy:		93.80 %
Epoch 802 of 2000 took 0.077s
  training loss:		0.028606
  validation loss:		0.277703
  validation accuracy:		93.15 %
Epoch 803 of 2000 took 0.075s
  training loss:		0.028941
  validation loss:		0.287032
  validation accuracy:		93.80 %
Epoch 804 of 2000 took 0.077s
  training loss:		0.029054
  validation loss:		0.272247
  validation accuracy:		93.70 %
Epoch 805 of 2000 took 0.074s
  training loss:		0.029818
  validation loss:		0.279941
  validation accuracy:		93.59 %
Epoch 806 of 2000 took 0.076s
  training loss:		0.028682
  validation loss:		0.278350
  validation accuracy:		93.15 %
Epoch 807 of 2000 took 0.077s
  training loss:		0.028210
  validation loss:		0.284063
  validation accuracy:		93.15 %
Epoch 808 of 2000 took 0.073s
  training loss:		0.029484
  validation loss:		0.275645
  validation accuracy:		93.59 %
Epoch 809 of 2000 took 0.076s
  training loss:		0.027905
  validation loss:		0.279176
  validation accuracy:		93.70 %
Epoch 810 of 2000 took 0.076s
  training loss:		0.028448
  validation loss:		0.286203
  validation accuracy:		93.15 %
Epoch 811 of 2000 took 0.077s
  training loss:		0.028115
  validation loss:		0.277490
  validation accuracy:		93.37 %
Epoch 812 of 2000 took 0.076s
  training loss:		0.027769
  validation loss:		0.279268
  validation accuracy:		93.59 %
Epoch 813 of 2000 took 0.076s
  training loss:		0.027332
  validation loss:		0.276592
  validation accuracy:		93.59 %
Epoch 814 of 2000 took 0.077s
  training loss:		0.028541
  validation loss:		0.278297
  validation accuracy:		93.59 %
Epoch 815 of 2000 took 0.074s
  training loss:		0.026664
  validation loss:		0.277106
  validation accuracy:		93.70 %
Epoch 816 of 2000 took 0.073s
  training loss:		0.027116
  validation loss:		0.279409
  validation accuracy:		93.80 %
Epoch 817 of 2000 took 0.074s
  training loss:		0.028684
  validation loss:		0.280311
  validation accuracy:		93.59 %
Epoch 818 of 2000 took 0.076s
  training loss:		0.028009
  validation loss:		0.280151
  validation accuracy:		93.48 %
Epoch 819 of 2000 took 0.076s
  training loss:		0.026654
  validation loss:		0.286270
  validation accuracy:		93.15 %
Epoch 820 of 2000 took 0.076s
  training loss:		0.028393
  validation loss:		0.281164
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.075s
  training loss:		0.027634
  validation loss:		0.275787
  validation accuracy:		93.91 %
Epoch 822 of 2000 took 0.075s
  training loss:		0.027970
  validation loss:		0.285132
  validation accuracy:		93.37 %
Epoch 823 of 2000 took 0.074s
  training loss:		0.027539
  validation loss:		0.289593
  validation accuracy:		93.26 %
Epoch 824 of 2000 took 0.075s
  training loss:		0.027056
  validation loss:		0.281676
  validation accuracy:		93.26 %
Epoch 825 of 2000 took 0.075s
  training loss:		0.027886
  validation loss:		0.279228
  validation accuracy:		93.59 %
Epoch 826 of 2000 took 0.078s
  training loss:		0.027799
  validation loss:		0.288132
  validation accuracy:		93.37 %
Epoch 827 of 2000 took 0.076s
  training loss:		0.027245
  validation loss:		0.284813
  validation accuracy:		93.48 %
Epoch 828 of 2000 took 0.075s
  training loss:		0.026555
  validation loss:		0.283998
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.076s
  training loss:		0.027028
  validation loss:		0.284780
  validation accuracy:		93.59 %
Epoch 830 of 2000 took 0.074s
  training loss:		0.027606
  validation loss:		0.283850
  validation accuracy:		93.48 %
Epoch 831 of 2000 took 0.075s
  training loss:		0.027537
  validation loss:		0.296433
  validation accuracy:		93.26 %
Epoch 832 of 2000 took 0.075s
  training loss:		0.027167
  validation loss:		0.283394
  validation accuracy:		93.59 %
Epoch 833 of 2000 took 0.074s
  training loss:		0.026853
  validation loss:		0.281728
  validation accuracy:		93.70 %
Epoch 834 of 2000 took 0.076s
  training loss:		0.026843
  validation loss:		0.291826
  validation accuracy:		93.26 %
Epoch 835 of 2000 took 0.075s
  training loss:		0.027042
  validation loss:		0.279365
  validation accuracy:		93.70 %
Epoch 836 of 2000 took 0.075s
  training loss:		0.026132
  validation loss:		0.295509
  validation accuracy:		93.37 %
Epoch 837 of 2000 took 0.075s
  training loss:		0.027425
  validation loss:		0.284799
  validation accuracy:		93.59 %
Epoch 838 of 2000 took 0.075s
  training loss:		0.025771
  validation loss:		0.287763
  validation accuracy:		93.48 %
Epoch 839 of 2000 took 0.079s
  training loss:		0.025952
  validation loss:		0.292064
  validation accuracy:		93.37 %
Epoch 840 of 2000 took 0.075s
  training loss:		0.027867
  validation loss:		0.294012
  validation accuracy:		93.26 %
Epoch 841 of 2000 took 0.077s
  training loss:		0.026240
  validation loss:		0.290206
  validation accuracy:		93.48 %
Epoch 842 of 2000 took 0.073s
  training loss:		0.026521
  validation loss:		0.287537
  validation accuracy:		93.48 %
Epoch 843 of 2000 took 0.075s
  training loss:		0.025822
  validation loss:		0.291084
  validation accuracy:		93.48 %
Epoch 844 of 2000 took 0.076s
  training loss:		0.026260
  validation loss:		0.294186
  validation accuracy:		93.15 %
Epoch 845 of 2000 took 0.077s
  training loss:		0.025584
  validation loss:		0.288694
  validation accuracy:		93.37 %
Epoch 846 of 2000 took 0.078s
  training loss:		0.026399
  validation loss:		0.281400
  validation accuracy:		93.48 %
Epoch 847 of 2000 took 0.077s
  training loss:		0.026227
  validation loss:		0.288238
  validation accuracy:		93.48 %
Epoch 848 of 2000 took 0.077s
  training loss:		0.025786
  validation loss:		0.291925
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.076s
  training loss:		0.025453
  validation loss:		0.289757
  validation accuracy:		93.59 %
Epoch 850 of 2000 took 0.077s
  training loss:		0.024628
  validation loss:		0.290374
  validation accuracy:		93.48 %
Epoch 851 of 2000 took 0.079s
  training loss:		0.025999
  validation loss:		0.290283
  validation accuracy:		93.15 %
Epoch 852 of 2000 took 0.076s
  training loss:		0.026698
  validation loss:		0.285203
  validation accuracy:		93.48 %
Epoch 853 of 2000 took 0.075s
  training loss:		0.025545
  validation loss:		0.293310
  validation accuracy:		93.15 %
Epoch 854 of 2000 took 0.077s
  training loss:		0.025314
  validation loss:		0.282723
  validation accuracy:		93.37 %
Epoch 855 of 2000 took 0.077s
  training loss:		0.025943
  validation loss:		0.293667
  validation accuracy:		93.37 %
Epoch 856 of 2000 took 0.075s
  training loss:		0.025595
  validation loss:		0.288748
  validation accuracy:		93.26 %
Epoch 857 of 2000 took 0.075s
  training loss:		0.024382
  validation loss:		0.294458
  validation accuracy:		93.37 %
Epoch 858 of 2000 took 0.076s
  training loss:		0.026098
  validation loss:		0.293166
  validation accuracy:		93.15 %
Epoch 859 of 2000 took 0.078s
  training loss:		0.024591
  validation loss:		0.297910
  validation accuracy:		93.04 %
Epoch 860 of 2000 took 0.078s
  training loss:		0.025386
  validation loss:		0.290787
  validation accuracy:		93.37 %
Epoch 861 of 2000 took 0.078s
  training loss:		0.024896
  validation loss:		0.294310
  validation accuracy:		93.70 %
Epoch 862 of 2000 took 0.073s
  training loss:		0.024409
  validation loss:		0.290111
  validation accuracy:		93.15 %
Epoch 863 of 2000 took 0.075s
  training loss:		0.025543
  validation loss:		0.292883
  validation accuracy:		93.37 %
Epoch 864 of 2000 took 0.074s
  training loss:		0.023895
  validation loss:		0.291525
  validation accuracy:		93.59 %
Epoch 865 of 2000 took 0.078s
  training loss:		0.024594
  validation loss:		0.291939
  validation accuracy:		93.70 %
Epoch 866 of 2000 took 0.076s
  training loss:		0.025380
  validation loss:		0.294326
  validation accuracy:		93.48 %
Epoch 867 of 2000 took 0.074s
  training loss:		0.024611
  validation loss:		0.293175
  validation accuracy:		93.59 %
Epoch 868 of 2000 took 0.075s
  training loss:		0.024716
  validation loss:		0.292091
  validation accuracy:		93.26 %
Epoch 869 of 2000 took 0.074s
  training loss:		0.024263
  validation loss:		0.295002
  validation accuracy:		93.59 %
Epoch 870 of 2000 took 0.075s
  training loss:		0.024290
  validation loss:		0.299018
  validation accuracy:		93.37 %
Epoch 871 of 2000 took 0.077s
  training loss:		0.024436
  validation loss:		0.294967
  validation accuracy:		93.48 %
Epoch 872 of 2000 took 0.077s
  training loss:		0.024517
  validation loss:		0.296693
  validation accuracy:		93.04 %
Epoch 873 of 2000 took 0.077s
  training loss:		0.023717
  validation loss:		0.299695
  validation accuracy:		93.04 %
Epoch 874 of 2000 took 0.077s
  training loss:		0.024371
  validation loss:		0.290762
  validation accuracy:		93.48 %
Epoch 875 of 2000 took 0.077s
  training loss:		0.022730
  validation loss:		0.292890
  validation accuracy:		93.48 %
Epoch 876 of 2000 took 0.076s
  training loss:		0.023723
  validation loss:		0.298807
  validation accuracy:		93.04 %
Epoch 877 of 2000 took 0.076s
  training loss:		0.022545
  validation loss:		0.288435
  validation accuracy:		93.70 %
Epoch 878 of 2000 took 0.075s
  training loss:		0.023646
  validation loss:		0.298637
  validation accuracy:		93.04 %
Epoch 879 of 2000 took 0.077s
  training loss:		0.024354
  validation loss:		0.298225
  validation accuracy:		93.04 %
Epoch 880 of 2000 took 0.076s
  training loss:		0.023585
  validation loss:		0.299445
  validation accuracy:		93.48 %
Epoch 881 of 2000 took 0.076s
  training loss:		0.024483
  validation loss:		0.297893
  validation accuracy:		93.70 %
Epoch 882 of 2000 took 0.073s
  training loss:		0.024781
  validation loss:		0.299109
  validation accuracy:		93.15 %
Epoch 883 of 2000 took 0.078s
  training loss:		0.022632
  validation loss:		0.300942
  validation accuracy:		93.70 %
Epoch 884 of 2000 took 0.076s
  training loss:		0.024186
  validation loss:		0.302974
  validation accuracy:		92.93 %
Epoch 885 of 2000 took 0.077s
  training loss:		0.023527
  validation loss:		0.298725
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.077s
  training loss:		0.022897
  validation loss:		0.302939
  validation accuracy:		93.04 %
Epoch 887 of 2000 took 0.078s
  training loss:		0.023727
  validation loss:		0.298198
  validation accuracy:		93.48 %
Epoch 888 of 2000 took 0.077s
  training loss:		0.022725
  validation loss:		0.297287
  validation accuracy:		93.37 %
Epoch 889 of 2000 took 0.078s
  training loss:		0.022108
  validation loss:		0.303802
  validation accuracy:		93.04 %
Epoch 890 of 2000 took 0.077s
  training loss:		0.022806
  validation loss:		0.294707
  validation accuracy:		93.59 %
Epoch 891 of 2000 took 0.074s
  training loss:		0.024549
  validation loss:		0.304516
  validation accuracy:		92.93 %
Epoch 892 of 2000 took 0.074s
  training loss:		0.023378
  validation loss:		0.297610
  validation accuracy:		93.15 %
Epoch 893 of 2000 took 0.073s
  training loss:		0.023161
  validation loss:		0.298581
  validation accuracy:		93.15 %
Epoch 894 of 2000 took 0.076s
  training loss:		0.023245
  validation loss:		0.299138
  validation accuracy:		93.04 %
Epoch 895 of 2000 took 0.075s
  training loss:		0.022810
  validation loss:		0.303240
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.075s
  training loss:		0.022684
  validation loss:		0.299335
  validation accuracy:		93.26 %
Epoch 897 of 2000 took 0.079s
  training loss:		0.023093
  validation loss:		0.307511
  validation accuracy:		93.04 %
Epoch 898 of 2000 took 0.077s
  training loss:		0.022961
  validation loss:		0.305421
  validation accuracy:		92.93 %
Epoch 899 of 2000 took 0.075s
  training loss:		0.023730
  validation loss:		0.313041
  validation accuracy:		92.93 %
Epoch 900 of 2000 took 0.075s
  training loss:		0.023368
  validation loss:		0.301083
  validation accuracy:		93.26 %
Epoch 901 of 2000 took 0.076s
  training loss:		0.022169
  validation loss:		0.304934
  validation accuracy:		93.04 %
Epoch 902 of 2000 took 0.074s
  training loss:		0.022043
  validation loss:		0.306453
  validation accuracy:		93.15 %
Epoch 903 of 2000 took 0.074s
  training loss:		0.022966
  validation loss:		0.297973
  validation accuracy:		93.80 %
Epoch 904 of 2000 took 0.076s
  training loss:		0.022844
  validation loss:		0.306497
  validation accuracy:		93.04 %
Epoch 905 of 2000 took 0.074s
  training loss:		0.022018
  validation loss:		0.303406
  validation accuracy:		93.26 %
Epoch 906 of 2000 took 0.075s
  training loss:		0.022630
  validation loss:		0.303360
  validation accuracy:		93.04 %
Epoch 907 of 2000 took 0.074s
  training loss:		0.023250
  validation loss:		0.304996
  validation accuracy:		93.48 %
Epoch 908 of 2000 took 0.076s
  training loss:		0.022400
  validation loss:		0.304135
  validation accuracy:		93.15 %
Epoch 909 of 2000 took 0.075s
  training loss:		0.022325
  validation loss:		0.307402
  validation accuracy:		93.04 %
Epoch 910 of 2000 took 0.076s
  training loss:		0.022525
  validation loss:		0.306325
  validation accuracy:		93.48 %
Epoch 911 of 2000 took 0.073s
  training loss:		0.022636
  validation loss:		0.310312
  validation accuracy:		93.04 %
Epoch 912 of 2000 took 0.076s
  training loss:		0.022880
  validation loss:		0.305544
  validation accuracy:		93.37 %
Epoch 913 of 2000 took 0.075s
  training loss:		0.022411
  validation loss:		0.310642
  validation accuracy:		93.04 %
Epoch 914 of 2000 took 0.074s
  training loss:		0.022390
  validation loss:		0.308270
  validation accuracy:		93.04 %
Epoch 915 of 2000 took 0.075s
  training loss:		0.021620
  validation loss:		0.304298
  validation accuracy:		93.37 %
Epoch 916 of 2000 took 0.074s
  training loss:		0.021789
  validation loss:		0.307774
  validation accuracy:		93.37 %
Epoch 917 of 2000 took 0.072s
  training loss:		0.021937
  validation loss:		0.311241
  validation accuracy:		93.26 %
Epoch 918 of 2000 took 0.075s
  training loss:		0.021940
  validation loss:		0.306963
  validation accuracy:		93.48 %
Epoch 919 of 2000 took 0.075s
  training loss:		0.021623
  validation loss:		0.307768
  validation accuracy:		93.37 %
Epoch 920 of 2000 took 0.076s
  training loss:		0.022586
  validation loss:		0.304303
  validation accuracy:		93.37 %
Epoch 921 of 2000 took 0.075s
  training loss:		0.022240
  validation loss:		0.303599
  validation accuracy:		93.15 %
Epoch 922 of 2000 took 0.075s
  training loss:		0.021901
  validation loss:		0.315922
  validation accuracy:		93.04 %
Epoch 923 of 2000 took 0.073s
  training loss:		0.021514
  validation loss:		0.307251
  validation accuracy:		93.48 %
Epoch 924 of 2000 took 0.076s
  training loss:		0.021108
  validation loss:		0.308361
  validation accuracy:		93.04 %
Epoch 925 of 2000 took 0.077s
  training loss:		0.020478
  validation loss:		0.310419
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.074s
  training loss:		0.021348
  validation loss:		0.314531
  validation accuracy:		93.15 %
Epoch 927 of 2000 took 0.076s
  training loss:		0.021825
  validation loss:		0.311554
  validation accuracy:		93.48 %
Epoch 928 of 2000 took 0.074s
  training loss:		0.021469
  validation loss:		0.310318
  validation accuracy:		93.15 %
Epoch 929 of 2000 took 0.077s
  training loss:		0.021949
  validation loss:		0.304432
  validation accuracy:		93.59 %
Epoch 930 of 2000 took 0.078s
  training loss:		0.021038
  validation loss:		0.313273
  validation accuracy:		93.15 %
Epoch 931 of 2000 took 0.077s
  training loss:		0.020241
  validation loss:		0.306106
  validation accuracy:		93.04 %
Epoch 932 of 2000 took 0.075s
  training loss:		0.021087
  validation loss:		0.303490
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.074s
  training loss:		0.021339
  validation loss:		0.315595
  validation accuracy:		92.93 %
Epoch 934 of 2000 took 0.075s
  training loss:		0.021511
  validation loss:		0.318444
  validation accuracy:		93.26 %
Epoch 935 of 2000 took 0.075s
  training loss:		0.021576
  validation loss:		0.307580
  validation accuracy:		93.48 %
Epoch 936 of 2000 took 0.077s
  training loss:		0.021128
  validation loss:		0.313813
  validation accuracy:		93.04 %
Epoch 937 of 2000 took 0.077s
  training loss:		0.020701
  validation loss:		0.311436
  validation accuracy:		93.15 %
Epoch 938 of 2000 took 0.077s
  training loss:		0.019809
  validation loss:		0.312202
  validation accuracy:		93.48 %
Epoch 939 of 2000 took 0.078s
  training loss:		0.021643
  validation loss:		0.312191
  validation accuracy:		93.37 %
Epoch 940 of 2000 took 0.077s
  training loss:		0.020841
  validation loss:		0.318837
  validation accuracy:		92.93 %
Epoch 941 of 2000 took 0.075s
  training loss:		0.020894
  validation loss:		0.315076
  validation accuracy:		93.15 %
Epoch 942 of 2000 took 0.078s
  training loss:		0.020815
  validation loss:		0.311059
  validation accuracy:		93.15 %
Epoch 943 of 2000 took 0.078s
  training loss:		0.020507
  validation loss:		0.312551
  validation accuracy:		92.93 %
Epoch 944 of 2000 took 0.076s
  training loss:		0.020292
  validation loss:		0.315296
  validation accuracy:		93.15 %
Epoch 945 of 2000 took 0.076s
  training loss:		0.020428
  validation loss:		0.316226
  validation accuracy:		92.83 %
Epoch 946 of 2000 took 0.075s
  training loss:		0.020028
  validation loss:		0.317123
  validation accuracy:		93.37 %
Epoch 947 of 2000 took 0.075s
  training loss:		0.020765
  validation loss:		0.307791
  validation accuracy:		93.48 %
Epoch 948 of 2000 took 0.075s
  training loss:		0.020716
  validation loss:		0.321718
  validation accuracy:		92.72 %
Epoch 949 of 2000 took 0.075s
  training loss:		0.020721
  validation loss:		0.308899
  validation accuracy:		93.70 %
Epoch 950 of 2000 took 0.078s
  training loss:		0.020987
  validation loss:		0.319362
  validation accuracy:		92.93 %
Epoch 951 of 2000 took 0.075s
  training loss:		0.020154
  validation loss:		0.314334
  validation accuracy:		93.37 %
Epoch 952 of 2000 took 0.076s
  training loss:		0.020142
  validation loss:		0.316415
  validation accuracy:		92.93 %
Epoch 953 of 2000 took 0.075s
  training loss:		0.019649
  validation loss:		0.305854
  validation accuracy:		93.59 %
Epoch 954 of 2000 took 0.076s
  training loss:		0.020812
  validation loss:		0.322381
  validation accuracy:		93.15 %
Epoch 955 of 2000 took 0.076s
  training loss:		0.020266
  validation loss:		0.331813
  validation accuracy:		92.72 %
Epoch 956 of 2000 took 0.074s
  training loss:		0.020842
  validation loss:		0.323572
  validation accuracy:		92.83 %
Epoch 957 of 2000 took 0.079s
  training loss:		0.018840
  validation loss:		0.310443
  validation accuracy:		93.04 %
Epoch 958 of 2000 took 0.077s
  training loss:		0.020869
  validation loss:		0.310544
  validation accuracy:		93.59 %
Epoch 959 of 2000 took 0.075s
  training loss:		0.019861
  validation loss:		0.319665
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.075s
  training loss:		0.020070
  validation loss:		0.323716
  validation accuracy:		92.93 %
Epoch 961 of 2000 took 0.075s
  training loss:		0.019594
  validation loss:		0.308077
  validation accuracy:		93.48 %
Epoch 962 of 2000 took 0.076s
  training loss:		0.019600
  validation loss:		0.316450
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.076s
  training loss:		0.020368
  validation loss:		0.324003
  validation accuracy:		93.04 %
Epoch 964 of 2000 took 0.079s
  training loss:		0.018967
  validation loss:		0.320691
  validation accuracy:		93.04 %
Epoch 965 of 2000 took 0.079s
  training loss:		0.019320
  validation loss:		0.316150
  validation accuracy:		93.15 %
Epoch 966 of 2000 took 0.079s
  training loss:		0.019287
  validation loss:		0.331321
  validation accuracy:		92.72 %
Epoch 967 of 2000 took 0.079s
  training loss:		0.019462
  validation loss:		0.316481
  validation accuracy:		92.93 %
Epoch 968 of 2000 took 0.079s
  training loss:		0.019097
  validation loss:		0.320346
  validation accuracy:		93.15 %
Epoch 969 of 2000 took 0.078s
  training loss:		0.019690
  validation loss:		0.330495
  validation accuracy:		92.83 %
Epoch 970 of 2000 took 0.078s
  training loss:		0.019290
  validation loss:		0.317663
  validation accuracy:		93.04 %
Epoch 971 of 2000 took 0.078s
  training loss:		0.018660
  validation loss:		0.326293
  validation accuracy:		92.93 %
Epoch 972 of 2000 took 0.077s
  training loss:		0.018462
  validation loss:		0.321092
  validation accuracy:		93.26 %
Epoch 973 of 2000 took 0.078s
  training loss:		0.019299
  validation loss:		0.321264
  validation accuracy:		93.48 %
Epoch 974 of 2000 took 0.077s
  training loss:		0.019360
  validation loss:		0.317833
  validation accuracy:		93.26 %
Epoch 975 of 2000 took 0.077s
  training loss:		0.019525
  validation loss:		0.327989
  validation accuracy:		93.04 %
Epoch 976 of 2000 took 0.077s
  training loss:		0.018963
  validation loss:		0.320803
  validation accuracy:		93.15 %
Epoch 977 of 2000 took 0.077s
  training loss:		0.019158
  validation loss:		0.318759
  validation accuracy:		93.04 %
Epoch 978 of 2000 took 0.077s
  training loss:		0.019047
  validation loss:		0.316777
  validation accuracy:		93.37 %
Epoch 979 of 2000 took 0.077s
  training loss:		0.019125
  validation loss:		0.320918
  validation accuracy:		93.26 %
Epoch 980 of 2000 took 0.077s
  training loss:		0.018847
  validation loss:		0.328167
  validation accuracy:		92.93 %
Epoch 981 of 2000 took 0.075s
  training loss:		0.019077
  validation loss:		0.320771
  validation accuracy:		93.04 %
Epoch 982 of 2000 took 0.076s
  training loss:		0.018621
  validation loss:		0.329168
  validation accuracy:		92.83 %
Epoch 983 of 2000 took 0.077s
  training loss:		0.018791
  validation loss:		0.322923
  validation accuracy:		93.48 %
Epoch 984 of 2000 took 0.078s
  training loss:		0.018083
  validation loss:		0.319933
  validation accuracy:		93.15 %
Epoch 985 of 2000 took 0.075s
  training loss:		0.018830
  validation loss:		0.323940
  validation accuracy:		93.04 %
Epoch 986 of 2000 took 0.073s
  training loss:		0.018455
  validation loss:		0.331799
  validation accuracy:		92.93 %
Epoch 987 of 2000 took 0.075s
  training loss:		0.018584
  validation loss:		0.318929
  validation accuracy:		93.37 %
Epoch 988 of 2000 took 0.075s
  training loss:		0.019032
  validation loss:		0.326110
  validation accuracy:		92.83 %
Epoch 989 of 2000 took 0.077s
  training loss:		0.018607
  validation loss:		0.328808
  validation accuracy:		92.93 %
Epoch 990 of 2000 took 0.075s
  training loss:		0.017978
  validation loss:		0.320365
  validation accuracy:		93.59 %
Epoch 991 of 2000 took 0.075s
  training loss:		0.017852
  validation loss:		0.331395
  validation accuracy:		92.93 %
Epoch 992 of 2000 took 0.076s
  training loss:		0.018279
  validation loss:		0.325963
  validation accuracy:		93.15 %
Epoch 993 of 2000 took 0.075s
  training loss:		0.017835
  validation loss:		0.328106
  validation accuracy:		92.83 %
Epoch 994 of 2000 took 0.077s
  training loss:		0.018227
  validation loss:		0.334957
  validation accuracy:		93.04 %
Epoch 995 of 2000 took 0.074s
  training loss:		0.018230
  validation loss:		0.340125
  validation accuracy:		92.72 %
Epoch 996 of 2000 took 0.078s
  training loss:		0.019132
  validation loss:		0.337435
  validation accuracy:		92.83 %
Epoch 997 of 2000 took 0.079s
  training loss:		0.017968
  validation loss:		0.328405
  validation accuracy:		92.93 %
Epoch 998 of 2000 took 0.078s
  training loss:		0.018113
  validation loss:		0.332797
  validation accuracy:		92.93 %
Epoch 999 of 2000 took 0.075s
  training loss:		0.017748
  validation loss:		0.331316
  validation accuracy:		92.83 %
Epoch 1000 of 2000 took 0.079s
  training loss:		0.017901
  validation loss:		0.340255
  validation accuracy:		92.83 %
Epoch 1001 of 2000 took 0.074s
  training loss:		0.018089
  validation loss:		0.326736
  validation accuracy:		93.04 %
Epoch 1002 of 2000 took 0.074s
  training loss:		0.018176
  validation loss:		0.332055
  validation accuracy:		92.93 %
Epoch 1003 of 2000 took 0.077s
  training loss:		0.017926
  validation loss:		0.336831
  validation accuracy:		93.04 %
Epoch 1004 of 2000 took 0.076s
  training loss:		0.018763
  validation loss:		0.330776
  validation accuracy:		93.04 %
Epoch 1005 of 2000 took 0.075s
  training loss:		0.018115
  validation loss:		0.324083
  validation accuracy:		93.48 %
Epoch 1006 of 2000 took 0.077s
  training loss:		0.017586
  validation loss:		0.329632
  validation accuracy:		93.15 %
Epoch 1007 of 2000 took 0.073s
  training loss:		0.018114
  validation loss:		0.325793
  validation accuracy:		93.37 %
Epoch 1008 of 2000 took 0.075s
  training loss:		0.017802
  validation loss:		0.329716
  validation accuracy:		93.48 %
Epoch 1009 of 2000 took 0.076s
  training loss:		0.017348
  validation loss:		0.340687
  validation accuracy:		92.93 %
Epoch 1010 of 2000 took 0.074s
  training loss:		0.017981
  validation loss:		0.321720
  validation accuracy:		93.26 %
Epoch 1011 of 2000 took 0.075s
  training loss:		0.017813
  validation loss:		0.337116
  validation accuracy:		93.04 %
Epoch 1012 of 2000 took 0.076s
  training loss:		0.017301
  validation loss:		0.338686
  validation accuracy:		93.04 %
Epoch 1013 of 2000 took 0.076s
  training loss:		0.017172
  validation loss:		0.328439
  validation accuracy:		93.26 %
Epoch 1014 of 2000 took 0.076s
  training loss:		0.016932
  validation loss:		0.337916
  validation accuracy:		92.93 %
Epoch 1015 of 2000 took 0.076s
  training loss:		0.016379
  validation loss:		0.333325
  validation accuracy:		93.04 %
Epoch 1016 of 2000 took 0.078s
  training loss:		0.017014
  validation loss:		0.331825
  validation accuracy:		93.48 %
Epoch 1017 of 2000 took 0.077s
  training loss:		0.016700
  validation loss:		0.330613
  validation accuracy:		93.04 %
Epoch 1018 of 2000 took 0.076s
  training loss:		0.017488
  validation loss:		0.328152
  validation accuracy:		93.04 %
Epoch 1019 of 2000 took 0.076s
  training loss:		0.018038
  validation loss:		0.337713
  validation accuracy:		93.15 %
Epoch 1020 of 2000 took 0.074s
  training loss:		0.017153
  validation loss:		0.336977
  validation accuracy:		92.83 %
Epoch 1021 of 2000 took 0.078s
  training loss:		0.017316
  validation loss:		0.342680
  validation accuracy:		93.15 %
Epoch 1022 of 2000 took 0.075s
  training loss:		0.017390
  validation loss:		0.331095
  validation accuracy:		93.26 %
Epoch 1023 of 2000 took 0.075s
  training loss:		0.016048
  validation loss:		0.340321
  validation accuracy:		92.83 %
Epoch 1024 of 2000 took 0.074s
  training loss:		0.017218
  validation loss:		0.340168
  validation accuracy:		92.93 %
Epoch 1025 of 2000 took 0.076s
  training loss:		0.016951
  validation loss:		0.337383
  validation accuracy:		93.04 %
Epoch 1026 of 2000 took 0.076s
  training loss:		0.016931
  validation loss:		0.329799
  validation accuracy:		93.04 %
Epoch 1027 of 2000 took 0.075s
  training loss:		0.016923
  validation loss:		0.334359
  validation accuracy:		93.48 %
Epoch 1028 of 2000 took 0.076s
  training loss:		0.017055
  validation loss:		0.338983
  validation accuracy:		92.93 %
Epoch 1029 of 2000 took 0.078s
  training loss:		0.015740
  validation loss:		0.338313
  validation accuracy:		92.83 %
Epoch 1030 of 2000 took 0.075s
  training loss:		0.016866
  validation loss:		0.340075
  validation accuracy:		92.83 %
Epoch 1031 of 2000 took 0.077s
  training loss:		0.016562
  validation loss:		0.329957
  validation accuracy:		93.15 %
Epoch 1032 of 2000 took 0.075s
  training loss:		0.016394
  validation loss:		0.336201
  validation accuracy:		92.83 %
Epoch 1033 of 2000 took 0.075s
  training loss:		0.017082
  validation loss:		0.337650
  validation accuracy:		92.93 %
Epoch 1034 of 2000 took 0.074s
  training loss:		0.016747
  validation loss:		0.337255
  validation accuracy:		93.04 %
Epoch 1035 of 2000 took 0.079s
  training loss:		0.016148
  validation loss:		0.337646
  validation accuracy:		93.15 %
Epoch 1036 of 2000 took 0.076s
  training loss:		0.016445
  validation loss:		0.336648
  validation accuracy:		93.15 %
Epoch 1037 of 2000 took 0.076s
  training loss:		0.016281
  validation loss:		0.345235
  validation accuracy:		92.72 %
Epoch 1038 of 2000 took 0.077s
  training loss:		0.016844
  validation loss:		0.341260
  validation accuracy:		92.83 %
Epoch 1039 of 2000 took 0.077s
  training loss:		0.016328
  validation loss:		0.338213
  validation accuracy:		92.93 %
Epoch 1040 of 2000 took 0.079s
  training loss:		0.016150
  validation loss:		0.344536
  validation accuracy:		92.93 %
Epoch 1041 of 2000 took 0.077s
  training loss:		0.016582
  validation loss:		0.342912
  validation accuracy:		93.26 %
Epoch 1042 of 2000 took 0.078s
  training loss:		0.015534
  validation loss:		0.340129
  validation accuracy:		92.83 %
Epoch 1043 of 2000 took 0.077s
  training loss:		0.016066
  validation loss:		0.338879
  validation accuracy:		93.26 %
Epoch 1044 of 2000 took 0.078s
  training loss:		0.016421
  validation loss:		0.348029
  validation accuracy:		92.93 %
Epoch 1045 of 2000 took 0.077s
  training loss:		0.016238
  validation loss:		0.339314
  validation accuracy:		92.83 %
Epoch 1046 of 2000 took 0.078s
  training loss:		0.016008
  validation loss:		0.341146
  validation accuracy:		92.93 %
Epoch 1047 of 2000 took 0.076s
  training loss:		0.016207
  validation loss:		0.343877
  validation accuracy:		92.83 %
Epoch 1048 of 2000 took 0.075s
  training loss:		0.015973
  validation loss:		0.340011
  validation accuracy:		93.15 %
Epoch 1049 of 2000 took 0.077s
  training loss:		0.015992
  validation loss:		0.339514
  validation accuracy:		92.83 %
Epoch 1050 of 2000 took 0.073s
  training loss:		0.015431
  validation loss:		0.341835
  validation accuracy:		93.26 %
Epoch 1051 of 2000 took 0.076s
  training loss:		0.015865
  validation loss:		0.340666
  validation accuracy:		92.93 %
Epoch 1052 of 2000 took 0.078s
  training loss:		0.016351
  validation loss:		0.347258
  validation accuracy:		92.93 %
Epoch 1053 of 2000 took 0.075s
  training loss:		0.015732
  validation loss:		0.338582
  validation accuracy:		93.04 %
Epoch 1054 of 2000 took 0.076s
  training loss:		0.016106
  validation loss:		0.344417
  validation accuracy:		93.26 %
Epoch 1055 of 2000 took 0.075s
  training loss:		0.015257
  validation loss:		0.349441
  validation accuracy:		92.93 %
Epoch 1056 of 2000 took 0.076s
  training loss:		0.015916
  validation loss:		0.343552
  validation accuracy:		92.83 %
Epoch 1057 of 2000 took 0.077s
  training loss:		0.015934
  validation loss:		0.343045
  validation accuracy:		93.04 %
Epoch 1058 of 2000 took 0.076s
  training loss:		0.016118
  validation loss:		0.345649
  validation accuracy:		92.72 %
Epoch 1059 of 2000 took 0.076s
  training loss:		0.015551
  validation loss:		0.343946
  validation accuracy:		92.83 %
Epoch 1060 of 2000 took 0.076s
  training loss:		0.015263
  validation loss:		0.348102
  validation accuracy:		92.93 %
Epoch 1061 of 2000 took 0.077s
  training loss:		0.015852
  validation loss:		0.344376
  validation accuracy:		92.72 %
Epoch 1062 of 2000 took 0.077s
  training loss:		0.016198
  validation loss:		0.340311
  validation accuracy:		92.93 %
Epoch 1063 of 2000 took 0.078s
  training loss:		0.015358
  validation loss:		0.352830
  validation accuracy:		92.61 %
Epoch 1064 of 2000 took 0.074s
  training loss:		0.015656
  validation loss:		0.350116
  validation accuracy:		92.72 %
Epoch 1065 of 2000 took 0.076s
  training loss:		0.015624
  validation loss:		0.363821
  validation accuracy:		92.72 %
Epoch 1066 of 2000 took 0.077s
  training loss:		0.016458
  validation loss:		0.346636
  validation accuracy:		92.83 %
Epoch 1067 of 2000 took 0.076s
  training loss:		0.015478
  validation loss:		0.339956
  validation accuracy:		93.26 %
Epoch 1068 of 2000 took 0.078s
  training loss:		0.015312
  validation loss:		0.344414
  validation accuracy:		92.93 %
Epoch 1069 of 2000 took 0.078s
  training loss:		0.015604
  validation loss:		0.346570
  validation accuracy:		93.37 %
Epoch 1070 of 2000 took 0.076s
  training loss:		0.015380
  validation loss:		0.347075
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.074s
  training loss:		0.015860
  validation loss:		0.349848
  validation accuracy:		92.93 %
Epoch 1072 of 2000 took 0.076s
  training loss:		0.015353
  validation loss:		0.348490
  validation accuracy:		92.72 %
Epoch 1073 of 2000 took 0.077s
  training loss:		0.015137
  validation loss:		0.351384
  validation accuracy:		92.93 %
Epoch 1074 of 2000 took 0.076s
  training loss:		0.015444
  validation loss:		0.349052
  validation accuracy:		93.15 %
Epoch 1075 of 2000 took 0.074s
  training loss:		0.015070
  validation loss:		0.349849
  validation accuracy:		92.83 %
Epoch 1076 of 2000 took 0.077s
  training loss:		0.014756
  validation loss:		0.356057
  validation accuracy:		92.93 %
Epoch 1077 of 2000 took 0.074s
  training loss:		0.015600
  validation loss:		0.346838
  validation accuracy:		92.93 %
Epoch 1078 of 2000 took 0.074s
  training loss:		0.015330
  validation loss:		0.350615
  validation accuracy:		92.83 %
Epoch 1079 of 2000 took 0.075s
  training loss:		0.014714
  validation loss:		0.350231
  validation accuracy:		92.93 %
Epoch 1080 of 2000 took 0.076s
  training loss:		0.014282
  validation loss:		0.351801
  validation accuracy:		93.15 %
Epoch 1081 of 2000 took 0.077s
  training loss:		0.014582
  validation loss:		0.354753
  validation accuracy:		93.15 %
Epoch 1082 of 2000 took 0.076s
  training loss:		0.015186
  validation loss:		0.345215
  validation accuracy:		92.93 %
Epoch 1083 of 2000 took 0.078s
  training loss:		0.014659
  validation loss:		0.340835
  validation accuracy:		93.48 %
Epoch 1084 of 2000 took 0.076s
  training loss:		0.014143
  validation loss:		0.355362
  validation accuracy:		93.04 %
Epoch 1085 of 2000 took 0.077s
  training loss:		0.014872
  validation loss:		0.346052
  validation accuracy:		93.15 %
Epoch 1086 of 2000 took 0.078s
  training loss:		0.013977
  validation loss:		0.341744
  validation accuracy:		93.37 %
Epoch 1087 of 2000 took 0.078s
  training loss:		0.014838
  validation loss:		0.356875
  validation accuracy:		93.04 %
Epoch 1088 of 2000 took 0.075s
  training loss:		0.014818
  validation loss:		0.353639
  validation accuracy:		92.72 %
Epoch 1089 of 2000 took 0.076s
  training loss:		0.014152
  validation loss:		0.349671
  validation accuracy:		92.93 %
Epoch 1090 of 2000 took 0.073s
  training loss:		0.014858
  validation loss:		0.353865
  validation accuracy:		92.83 %
Epoch 1091 of 2000 took 0.077s
  training loss:		0.014973
  validation loss:		0.352701
  validation accuracy:		92.93 %
Epoch 1092 of 2000 took 0.074s
  training loss:		0.014344
  validation loss:		0.346440
  validation accuracy:		93.26 %
Epoch 1093 of 2000 took 0.077s
  training loss:		0.014627
  validation loss:		0.352610
  validation accuracy:		92.83 %
Epoch 1094 of 2000 took 0.075s
  training loss:		0.014926
  validation loss:		0.354527
  validation accuracy:		92.83 %
Epoch 1095 of 2000 took 0.075s
  training loss:		0.015080
  validation loss:		0.360893
  validation accuracy:		92.93 %
Epoch 1096 of 2000 took 0.077s
  training loss:		0.014319
  validation loss:		0.345130
  validation accuracy:		93.04 %
Epoch 1097 of 2000 took 0.076s
  training loss:		0.015122
  validation loss:		0.354997
  validation accuracy:		92.72 %
Epoch 1098 of 2000 took 0.076s
  training loss:		0.014423
  validation loss:		0.350368
  validation accuracy:		93.15 %
Epoch 1099 of 2000 took 0.074s
  training loss:		0.014410
  validation loss:		0.359737
  validation accuracy:		92.72 %
Epoch 1100 of 2000 took 0.074s
  training loss:		0.014326
  validation loss:		0.367912
  validation accuracy:		92.83 %
Epoch 1101 of 2000 took 0.076s
  training loss:		0.014456
  validation loss:		0.357470
  validation accuracy:		92.93 %
Epoch 1102 of 2000 took 0.076s
  training loss:		0.013592
  validation loss:		0.359688
  validation accuracy:		92.61 %
Epoch 1103 of 2000 took 0.076s
  training loss:		0.013759
  validation loss:		0.353890
  validation accuracy:		92.93 %
Epoch 1104 of 2000 took 0.076s
  training loss:		0.014241
  validation loss:		0.355724
  validation accuracy:		93.04 %
Epoch 1105 of 2000 took 0.076s
  training loss:		0.014628
  validation loss:		0.354444
  validation accuracy:		93.04 %
Epoch 1106 of 2000 took 0.074s
  training loss:		0.014091
  validation loss:		0.364954
  validation accuracy:		92.83 %
Epoch 1107 of 2000 took 0.076s
  training loss:		0.014084
  validation loss:		0.355656
  validation accuracy:		92.83 %
Epoch 1108 of 2000 took 0.075s
  training loss:		0.014312
  validation loss:		0.363956
  validation accuracy:		92.93 %
Epoch 1109 of 2000 took 0.076s
  training loss:		0.014381
  validation loss:		0.362517
  validation accuracy:		92.93 %
Epoch 1110 of 2000 took 0.076s
  training loss:		0.014350
  validation loss:		0.359380
  validation accuracy:		92.93 %
Epoch 1111 of 2000 took 0.075s
  training loss:		0.014005
  validation loss:		0.362685
  validation accuracy:		92.72 %
Epoch 1112 of 2000 took 0.074s
  training loss:		0.013502
  validation loss:		0.361147
  validation accuracy:		92.83 %
Epoch 1113 of 2000 took 0.076s
  training loss:		0.013112
  validation loss:		0.350733
  validation accuracy:		92.83 %
Epoch 1114 of 2000 took 0.074s
  training loss:		0.013502
  validation loss:		0.366789
  validation accuracy:		92.93 %
Epoch 1115 of 2000 took 0.076s
  training loss:		0.014135
  validation loss:		0.354813
  validation accuracy:		93.26 %
Epoch 1116 of 2000 took 0.076s
  training loss:		0.013849
  validation loss:		0.355430
  validation accuracy:		92.93 %
Epoch 1117 of 2000 took 0.076s
  training loss:		0.013870
  validation loss:		0.358378
  validation accuracy:		92.83 %
Epoch 1118 of 2000 took 0.076s
  training loss:		0.013239
  validation loss:		0.360186
  validation accuracy:		92.93 %
Epoch 1119 of 2000 took 0.074s
  training loss:		0.013345
  validation loss:		0.362603
  validation accuracy:		92.83 %
Epoch 1120 of 2000 took 0.076s
  training loss:		0.013697
  validation loss:		0.363862
  validation accuracy:		92.93 %
Epoch 1121 of 2000 took 0.076s
  training loss:		0.013685
  validation loss:		0.360366
  validation accuracy:		92.93 %
Epoch 1122 of 2000 took 0.075s
  training loss:		0.013829
  validation loss:		0.358645
  validation accuracy:		92.83 %
Epoch 1123 of 2000 took 0.075s
  training loss:		0.013294
  validation loss:		0.364283
  validation accuracy:		92.93 %
Epoch 1124 of 2000 took 0.076s
  training loss:		0.013234
  validation loss:		0.357246
  validation accuracy:		92.83 %
Epoch 1125 of 2000 took 0.078s
  training loss:		0.013387
  validation loss:		0.359634
  validation accuracy:		93.04 %
Epoch 1126 of 2000 took 0.076s
  training loss:		0.013243
  validation loss:		0.356503
  validation accuracy:		93.04 %
Epoch 1127 of 2000 took 0.074s
  training loss:		0.013421
  validation loss:		0.363470
  validation accuracy:		92.93 %
Epoch 1128 of 2000 took 0.074s
  training loss:		0.013709
  validation loss:		0.363688
  validation accuracy:		92.93 %
Epoch 1129 of 2000 took 0.075s
  training loss:		0.013223
  validation loss:		0.370364
  validation accuracy:		92.83 %
Epoch 1130 of 2000 took 0.076s
  training loss:		0.013380
  validation loss:		0.357514
  validation accuracy:		92.93 %
Epoch 1131 of 2000 took 0.077s
  training loss:		0.013755
  validation loss:		0.363375
  validation accuracy:		92.72 %
Epoch 1132 of 2000 took 0.079s
  training loss:		0.013169
  validation loss:		0.364475
  validation accuracy:		92.72 %
Epoch 1133 of 2000 took 0.078s
  training loss:		0.014190
  validation loss:		0.363771
  validation accuracy:		92.83 %
Epoch 1134 of 2000 took 0.074s
  training loss:		0.013221
  validation loss:		0.361045
  validation accuracy:		92.93 %
Epoch 1135 of 2000 took 0.076s
  training loss:		0.013328
  validation loss:		0.365052
  validation accuracy:		92.83 %
Epoch 1136 of 2000 took 0.076s
  training loss:		0.013102
  validation loss:		0.356891
  validation accuracy:		93.37 %
Epoch 1137 of 2000 took 0.076s
  training loss:		0.012258
  validation loss:		0.365290
  validation accuracy:		92.72 %
Epoch 1138 of 2000 took 0.077s
  training loss:		0.013282
  validation loss:		0.364373
  validation accuracy:		92.83 %
Epoch 1139 of 2000 took 0.074s
  training loss:		0.012872
  validation loss:		0.359062
  validation accuracy:		93.04 %
Epoch 1140 of 2000 took 0.075s
  training loss:		0.013235
  validation loss:		0.365058
  validation accuracy:		92.72 %
Epoch 1141 of 2000 took 0.074s
  training loss:		0.013766
  validation loss:		0.379378
  validation accuracy:		92.93 %
Epoch 1142 of 2000 took 0.073s
  training loss:		0.013604
  validation loss:		0.360860
  validation accuracy:		93.15 %
Epoch 1143 of 2000 took 0.078s
  training loss:		0.012598
  validation loss:		0.364920
  validation accuracy:		92.83 %
Epoch 1144 of 2000 took 0.076s
  training loss:		0.013031
  validation loss:		0.360021
  validation accuracy:		92.93 %
Epoch 1145 of 2000 took 0.076s
  training loss:		0.012546
  validation loss:		0.374990
  validation accuracy:		92.93 %
Epoch 1146 of 2000 took 0.075s
  training loss:		0.012943
  validation loss:		0.360650
  validation accuracy:		93.37 %
Epoch 1147 of 2000 took 0.078s
  training loss:		0.012287
  validation loss:		0.364475
  validation accuracy:		93.04 %
Epoch 1148 of 2000 took 0.075s
  training loss:		0.012447
  validation loss:		0.363093
  validation accuracy:		93.04 %
Epoch 1149 of 2000 took 0.076s
  training loss:		0.012557
  validation loss:		0.360316
  validation accuracy:		93.26 %
Epoch 1150 of 2000 took 0.078s
  training loss:		0.013034
  validation loss:		0.358275
  validation accuracy:		93.15 %
Epoch 1151 of 2000 took 0.076s
  training loss:		0.012914
  validation loss:		0.362956
  validation accuracy:		92.83 %
Epoch 1152 of 2000 took 0.077s
  training loss:		0.012924
  validation loss:		0.369052
  validation accuracy:		92.83 %
Epoch 1153 of 2000 took 0.077s
  training loss:		0.012864
  validation loss:		0.360206
  validation accuracy:		92.93 %
Epoch 1154 of 2000 took 0.077s
  training loss:		0.012823
  validation loss:		0.365911
  validation accuracy:		92.93 %
Epoch 1155 of 2000 took 0.079s
  training loss:		0.012865
  validation loss:		0.370821
  validation accuracy:		92.83 %
Epoch 1156 of 2000 took 0.076s
  training loss:		0.012851
  validation loss:		0.362451
  validation accuracy:		92.93 %
Epoch 1157 of 2000 took 0.076s
  training loss:		0.012167
  validation loss:		0.366523
  validation accuracy:		92.93 %
Epoch 1158 of 2000 took 0.078s
  training loss:		0.012315
  validation loss:		0.370053
  validation accuracy:		92.72 %
Epoch 1159 of 2000 took 0.076s
  training loss:		0.012577
  validation loss:		0.370852
  validation accuracy:		92.93 %
Epoch 1160 of 2000 took 0.076s
  training loss:		0.012199
  validation loss:		0.374270
  validation accuracy:		92.93 %
Epoch 1161 of 2000 took 0.075s
  training loss:		0.012995
  validation loss:		0.363933
  validation accuracy:		92.83 %
Epoch 1162 of 2000 took 0.076s
  training loss:		0.011753
  validation loss:		0.365252
  validation accuracy:		93.04 %
Epoch 1163 of 2000 took 0.075s
  training loss:		0.012618
  validation loss:		0.368192
  validation accuracy:		92.93 %
Epoch 1164 of 2000 took 0.076s
  training loss:		0.012445
  validation loss:		0.367527
  validation accuracy:		92.93 %
Epoch 1165 of 2000 took 0.078s
  training loss:		0.012751
  validation loss:		0.371769
  validation accuracy:		92.83 %
Epoch 1166 of 2000 took 0.074s
  training loss:		0.012547
  validation loss:		0.364980
  validation accuracy:		92.93 %
Epoch 1167 of 2000 took 0.076s
  training loss:		0.012110
  validation loss:		0.372244
  validation accuracy:		92.93 %
Epoch 1168 of 2000 took 0.076s
  training loss:		0.011903
  validation loss:		0.373765
  validation accuracy:		92.83 %
Epoch 1169 of 2000 took 0.074s
  training loss:		0.012461
  validation loss:		0.367815
  validation accuracy:		93.26 %
Epoch 1170 of 2000 took 0.076s
  training loss:		0.012465
  validation loss:		0.381674
  validation accuracy:		92.72 %
Epoch 1171 of 2000 took 0.078s
  training loss:		0.012436
  validation loss:		0.372512
  validation accuracy:		92.83 %
Epoch 1172 of 2000 took 0.077s
  training loss:		0.012423
  validation loss:		0.372793
  validation accuracy:		92.83 %
Epoch 1173 of 2000 took 0.076s
  training loss:		0.012234
  validation loss:		0.363672
  validation accuracy:		93.15 %
Epoch 1174 of 2000 took 0.076s
  training loss:		0.012375
  validation loss:		0.366832
  validation accuracy:		93.04 %
Epoch 1175 of 2000 took 0.077s
  training loss:		0.012200
  validation loss:		0.375096
  validation accuracy:		92.93 %
Epoch 1176 of 2000 took 0.076s
  training loss:		0.012072
  validation loss:		0.367646
  validation accuracy:		93.15 %
Epoch 1177 of 2000 took 0.075s
  training loss:		0.012298
  validation loss:		0.374644
  validation accuracy:		93.04 %
Epoch 1178 of 2000 took 0.079s
  training loss:		0.012359
  validation loss:		0.380368
  validation accuracy:		92.83 %
Epoch 1179 of 2000 took 0.073s
  training loss:		0.012402
  validation loss:		0.383626
  validation accuracy:		92.93 %
Epoch 1180 of 2000 took 0.078s
  training loss:		0.011998
  validation loss:		0.367988
  validation accuracy:		93.04 %
Epoch 1181 of 2000 took 0.076s
  training loss:		0.011972
  validation loss:		0.366830
  validation accuracy:		92.83 %
Epoch 1182 of 2000 took 0.077s
  training loss:		0.011904
  validation loss:		0.373629
  validation accuracy:		92.83 %
Epoch 1183 of 2000 took 0.076s
  training loss:		0.012383
  validation loss:		0.372280
  validation accuracy:		93.04 %
Epoch 1184 of 2000 took 0.074s
  training loss:		0.012146
  validation loss:		0.373031
  validation accuracy:		93.15 %
Epoch 1185 of 2000 took 0.077s
  training loss:		0.012176
  validation loss:		0.380095
  validation accuracy:		92.93 %
Epoch 1186 of 2000 took 0.077s
  training loss:		0.011651
  validation loss:		0.375409
  validation accuracy:		92.72 %
Epoch 1187 of 2000 took 0.078s
  training loss:		0.011913
  validation loss:		0.364978
  validation accuracy:		92.93 %
Epoch 1188 of 2000 took 0.078s
  training loss:		0.012074
  validation loss:		0.378831
  validation accuracy:		93.04 %
Epoch 1189 of 2000 took 0.073s
  training loss:		0.012068
  validation loss:		0.376999
  validation accuracy:		92.93 %
Epoch 1190 of 2000 took 0.077s
  training loss:		0.011403
  validation loss:		0.380625
  validation accuracy:		92.93 %
Epoch 1191 of 2000 took 0.076s
  training loss:		0.011618
  validation loss:		0.382394
  validation accuracy:		92.83 %
Epoch 1192 of 2000 took 0.076s
  training loss:		0.012162
  validation loss:		0.379660
  validation accuracy:		92.93 %
Epoch 1193 of 2000 took 0.075s
  training loss:		0.011727
  validation loss:		0.371800
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.075s
  training loss:		0.011667
  validation loss:		0.377053
  validation accuracy:		92.72 %
Epoch 1195 of 2000 took 0.076s
  training loss:		0.011796
  validation loss:		0.374644
  validation accuracy:		92.93 %
Epoch 1196 of 2000 took 0.075s
  training loss:		0.011783
  validation loss:		0.374639
  validation accuracy:		92.83 %
Epoch 1197 of 2000 took 0.076s
  training loss:		0.011249
  validation loss:		0.383035
  validation accuracy:		92.72 %
Epoch 1198 of 2000 took 0.077s
  training loss:		0.011903
  validation loss:		0.370443
  validation accuracy:		92.83 %
Epoch 1199 of 2000 took 0.076s
  training loss:		0.011605
  validation loss:		0.384806
  validation accuracy:		92.72 %
Epoch 1200 of 2000 took 0.078s
  training loss:		0.011834
  validation loss:		0.382242
  validation accuracy:		92.72 %
Epoch 1201 of 2000 took 0.076s
  training loss:		0.011877
  validation loss:		0.385842
  validation accuracy:		92.83 %
Epoch 1202 of 2000 took 0.075s
  training loss:		0.011647
  validation loss:		0.366074
  validation accuracy:		93.26 %
Epoch 1203 of 2000 took 0.075s
  training loss:		0.011090
  validation loss:		0.387215
  validation accuracy:		92.83 %
Epoch 1204 of 2000 took 0.075s
  training loss:		0.011348
  validation loss:		0.376656
  validation accuracy:		92.83 %
Epoch 1205 of 2000 took 0.077s
  training loss:		0.010792
  validation loss:		0.373294
  validation accuracy:		92.83 %
Epoch 1206 of 2000 took 0.075s
  training loss:		0.010970
  validation loss:		0.373688
  validation accuracy:		93.04 %
Epoch 1207 of 2000 took 0.077s
  training loss:		0.011414
  validation loss:		0.385174
  validation accuracy:		92.83 %
Epoch 1208 of 2000 took 0.076s
  training loss:		0.011386
  validation loss:		0.375886
  validation accuracy:		92.83 %
Epoch 1209 of 2000 took 0.075s
  training loss:		0.011588
  validation loss:		0.378492
  validation accuracy:		92.83 %
Epoch 1210 of 2000 took 0.075s
  training loss:		0.011364
  validation loss:		0.389887
  validation accuracy:		92.72 %
Epoch 1211 of 2000 took 0.077s
  training loss:		0.011197
  validation loss:		0.382644
  validation accuracy:		92.93 %
Epoch 1212 of 2000 took 0.074s
  training loss:		0.011151
  validation loss:		0.375719
  validation accuracy:		93.04 %
Epoch 1213 of 2000 took 0.075s
  training loss:		0.011588
  validation loss:		0.388004
  validation accuracy:		92.83 %
Epoch 1214 of 2000 took 0.074s
  training loss:		0.011181
  validation loss:		0.373057
  validation accuracy:		93.15 %
Epoch 1215 of 2000 took 0.073s
  training loss:		0.011291
  validation loss:		0.390330
  validation accuracy:		92.83 %
Epoch 1216 of 2000 took 0.074s
  training loss:		0.010954
  validation loss:		0.384532
  validation accuracy:		92.83 %
Epoch 1217 of 2000 took 0.075s
  training loss:		0.011132
  validation loss:		0.375744
  validation accuracy:		92.83 %
Epoch 1218 of 2000 took 0.074s
  training loss:		0.011106
  validation loss:		0.385199
  validation accuracy:		92.93 %
Epoch 1219 of 2000 took 0.078s
  training loss:		0.011015
  validation loss:		0.384746
  validation accuracy:		92.72 %
Epoch 1220 of 2000 took 0.076s
  training loss:		0.011129
  validation loss:		0.381435
  validation accuracy:		92.83 %
Epoch 1221 of 2000 took 0.073s
  training loss:		0.011232
  validation loss:		0.374716
  validation accuracy:		93.26 %
Epoch 1222 of 2000 took 0.076s
  training loss:		0.011324
  validation loss:		0.389660
  validation accuracy:		92.72 %
Epoch 1223 of 2000 took 0.074s
  training loss:		0.010791
  validation loss:		0.380459
  validation accuracy:		92.83 %
Epoch 1224 of 2000 took 0.075s
  training loss:		0.011298
  validation loss:		0.393551
  validation accuracy:		92.93 %
Epoch 1225 of 2000 took 0.075s
  training loss:		0.011193
  validation loss:		0.386395
  validation accuracy:		92.83 %
Epoch 1226 of 2000 took 0.076s
  training loss:		0.010626
  validation loss:		0.375391
  validation accuracy:		92.83 %
Epoch 1227 of 2000 took 0.078s
  training loss:		0.010562
  validation loss:		0.381950
  validation accuracy:		92.93 %
Epoch 1228 of 2000 took 0.074s
  training loss:		0.010940
  validation loss:		0.384975
  validation accuracy:		92.83 %
Epoch 1229 of 2000 took 0.076s
  training loss:		0.010630
  validation loss:		0.389964
  validation accuracy:		92.72 %
Epoch 1230 of 2000 took 0.074s
  training loss:		0.010653
  validation loss:		0.385697
  validation accuracy:		92.72 %
Epoch 1231 of 2000 took 0.077s
  training loss:		0.010712
  validation loss:		0.393156
  validation accuracy:		92.93 %
Epoch 1232 of 2000 took 0.075s
  training loss:		0.010485
  validation loss:		0.386197
  validation accuracy:		92.72 %
Epoch 1233 of 2000 took 0.076s
  training loss:		0.011010
  validation loss:		0.394036
  validation accuracy:		92.93 %
Epoch 1234 of 2000 took 0.077s
  training loss:		0.010737
  validation loss:		0.387640
  validation accuracy:		92.72 %
Epoch 1235 of 2000 took 0.076s
  training loss:		0.010436
  validation loss:		0.386966
  validation accuracy:		92.83 %
Epoch 1236 of 2000 took 0.074s
  training loss:		0.010642
  validation loss:		0.390331
  validation accuracy:		92.72 %
Epoch 1237 of 2000 took 0.077s
  training loss:		0.010713
  validation loss:		0.386815
  validation accuracy:		92.83 %
Epoch 1238 of 2000 took 0.076s
  training loss:		0.010222
  validation loss:		0.389088
  validation accuracy:		93.04 %
Epoch 1239 of 2000 took 0.075s
  training loss:		0.010868
  validation loss:		0.392776
  validation accuracy:		92.72 %
Epoch 1240 of 2000 took 0.076s
  training loss:		0.010717
  validation loss:		0.399396
  validation accuracy:		92.83 %
Epoch 1241 of 2000 took 0.074s
  training loss:		0.010487
  validation loss:		0.385740
  validation accuracy:		92.72 %
Epoch 1242 of 2000 took 0.075s
  training loss:		0.010930
  validation loss:		0.390765
  validation accuracy:		92.72 %
Epoch 1243 of 2000 took 0.074s
  training loss:		0.010419
  validation loss:		0.384144
  validation accuracy:		92.93 %
Epoch 1244 of 2000 took 0.075s
  training loss:		0.010533
  validation loss:		0.386534
  validation accuracy:		92.83 %
Epoch 1245 of 2000 took 0.077s
  training loss:		0.010553
  validation loss:		0.385730
  validation accuracy:		92.83 %
Epoch 1246 of 2000 took 0.076s
  training loss:		0.009769
  validation loss:		0.388661
  validation accuracy:		92.93 %
Epoch 1247 of 2000 took 0.075s
  training loss:		0.010889
  validation loss:		0.393569
  validation accuracy:		92.83 %
Epoch 1248 of 2000 took 0.076s
  training loss:		0.010483
  validation loss:		0.386156
  validation accuracy:		93.04 %
Epoch 1249 of 2000 took 0.073s
  training loss:		0.010249
  validation loss:		0.393902
  validation accuracy:		92.83 %
Epoch 1250 of 2000 took 0.077s
  training loss:		0.010569
  validation loss:		0.391003
  validation accuracy:		92.83 %
Epoch 1251 of 2000 took 0.074s
  training loss:		0.010275
  validation loss:		0.387582
  validation accuracy:		92.93 %
Epoch 1252 of 2000 took 0.076s
  training loss:		0.010231
  validation loss:		0.393761
  validation accuracy:		92.83 %
Epoch 1253 of 2000 took 0.076s
  training loss:		0.010414
  validation loss:		0.394677
  validation accuracy:		92.83 %
Epoch 1254 of 2000 took 0.077s
  training loss:		0.010046
  validation loss:		0.387881
  validation accuracy:		92.83 %
Epoch 1255 of 2000 took 0.077s
  training loss:		0.010079
  validation loss:		0.387827
  validation accuracy:		92.72 %
Epoch 1256 of 2000 took 0.075s
  training loss:		0.010444
  validation loss:		0.392028
  validation accuracy:		92.83 %
Epoch 1257 of 2000 took 0.077s
  training loss:		0.010146
  validation loss:		0.396250
  validation accuracy:		92.83 %
Epoch 1258 of 2000 took 0.077s
  training loss:		0.009860
  validation loss:		0.389095
  validation accuracy:		92.93 %
Epoch 1259 of 2000 took 0.075s
  training loss:		0.010558
  validation loss:		0.384450
  validation accuracy:		92.93 %
Epoch 1260 of 2000 took 0.077s
  training loss:		0.010397
  validation loss:		0.385276
  validation accuracy:		92.93 %
Epoch 1261 of 2000 took 0.076s
  training loss:		0.010206
  validation loss:		0.399651
  validation accuracy:		92.72 %
Epoch 1262 of 2000 took 0.075s
  training loss:		0.010101
  validation loss:		0.395482
  validation accuracy:		92.83 %
Epoch 1263 of 2000 took 0.075s
  training loss:		0.010209
  validation loss:		0.390046
  validation accuracy:		92.83 %
Epoch 1264 of 2000 took 0.074s
  training loss:		0.010115
  validation loss:		0.395018
  validation accuracy:		93.04 %
Epoch 1265 of 2000 took 0.077s
  training loss:		0.010231
  validation loss:		0.389232
  validation accuracy:		93.04 %
Epoch 1266 of 2000 took 0.079s
  training loss:		0.009951
  validation loss:		0.394277
  validation accuracy:		92.93 %
Epoch 1267 of 2000 took 0.075s
  training loss:		0.010196
  validation loss:		0.390850
  validation accuracy:		92.83 %
Epoch 1268 of 2000 took 0.075s
  training loss:		0.009972
  validation loss:		0.391134
  validation accuracy:		93.04 %
Epoch 1269 of 2000 took 0.075s
  training loss:		0.009564
  validation loss:		0.389766
  validation accuracy:		92.83 %
Epoch 1270 of 2000 took 0.073s
  training loss:		0.010083
  validation loss:		0.400730
  validation accuracy:		92.83 %
Epoch 1271 of 2000 took 0.074s
  training loss:		0.009989
  validation loss:		0.399347
  validation accuracy:		92.83 %
Epoch 1272 of 2000 took 0.078s
  training loss:		0.010161
  validation loss:		0.396703
  validation accuracy:		92.50 %
Epoch 1273 of 2000 took 0.078s
  training loss:		0.010133
  validation loss:		0.390368
  validation accuracy:		92.83 %
Epoch 1274 of 2000 took 0.079s
  training loss:		0.010102
  validation loss:		0.395984
  validation accuracy:		92.83 %
Epoch 1275 of 2000 took 0.076s
  training loss:		0.010013
  validation loss:		0.389244
  validation accuracy:		93.15 %
Epoch 1276 of 2000 took 0.076s
  training loss:		0.009825
  validation loss:		0.387002
  validation accuracy:		93.04 %
Epoch 1277 of 2000 took 0.077s
  training loss:		0.010206
  validation loss:		0.403092
  validation accuracy:		92.83 %
Epoch 1278 of 2000 took 0.078s
  training loss:		0.009831
  validation loss:		0.395399
  validation accuracy:		92.93 %
Epoch 1279 of 2000 took 0.075s
  training loss:		0.009974
  validation loss:		0.391315
  validation accuracy:		92.83 %
Epoch 1280 of 2000 took 0.078s
  training loss:		0.009811
  validation loss:		0.404389
  validation accuracy:		92.72 %
Epoch 1281 of 2000 took 0.076s
  training loss:		0.009524
  validation loss:		0.396894
  validation accuracy:		92.83 %
Epoch 1282 of 2000 took 0.075s
  training loss:		0.009923
  validation loss:		0.400625
  validation accuracy:		92.83 %
Epoch 1283 of 2000 took 0.074s
  training loss:		0.009902
  validation loss:		0.397997
  validation accuracy:		92.83 %
Epoch 1284 of 2000 took 0.074s
  training loss:		0.009471
  validation loss:		0.397222
  validation accuracy:		92.93 %
Epoch 1285 of 2000 took 0.076s
  training loss:		0.009354
  validation loss:		0.391184
  validation accuracy:		92.93 %
Epoch 1286 of 2000 took 0.073s
  training loss:		0.009361
  validation loss:		0.402798
  validation accuracy:		92.83 %
Epoch 1287 of 2000 took 0.076s
  training loss:		0.009439
  validation loss:		0.391428
  validation accuracy:		92.83 %
Epoch 1288 of 2000 took 0.073s
  training loss:		0.009728
  validation loss:		0.395428
  validation accuracy:		93.04 %
Epoch 1289 of 2000 took 0.074s
  training loss:		0.009674
  validation loss:		0.393819
  validation accuracy:		92.93 %
Epoch 1290 of 2000 took 0.078s
  training loss:		0.009490
  validation loss:		0.400734
  validation accuracy:		92.83 %
Epoch 1291 of 2000 took 0.075s
  training loss:		0.009328
  validation loss:		0.398489
  validation accuracy:		92.93 %
Epoch 1292 of 2000 took 0.078s
  training loss:		0.009240
  validation loss:		0.406139
  validation accuracy:		92.83 %
Epoch 1293 of 2000 took 0.074s
  training loss:		0.009701
  validation loss:		0.395793
  validation accuracy:		92.83 %
Epoch 1294 of 2000 took 0.074s
  training loss:		0.009606
  validation loss:		0.400033
  validation accuracy:		92.83 %
Epoch 1295 of 2000 took 0.076s
  training loss:		0.010105
  validation loss:		0.405916
  validation accuracy:		92.83 %
Epoch 1296 of 2000 took 0.076s
  training loss:		0.009707
  validation loss:		0.395247
  validation accuracy:		92.93 %
Epoch 1297 of 2000 took 0.075s
  training loss:		0.009714
  validation loss:		0.393391
  validation accuracy:		93.04 %
Epoch 1298 of 2000 took 0.076s
  training loss:		0.009177
  validation loss:		0.402512
  validation accuracy:		92.93 %
Epoch 1299 of 2000 took 0.076s
  training loss:		0.009343
  validation loss:		0.394904
  validation accuracy:		93.15 %
Epoch 1300 of 2000 took 0.076s
  training loss:		0.009551
  validation loss:		0.400963
  validation accuracy:		92.83 %
Epoch 1301 of 2000 took 0.074s
  training loss:		0.009303
  validation loss:		0.404278
  validation accuracy:		92.83 %
Epoch 1302 of 2000 took 0.076s
  training loss:		0.009327
  validation loss:		0.396377
  validation accuracy:		92.83 %
Epoch 1303 of 2000 took 0.076s
  training loss:		0.008929
  validation loss:		0.399250
  validation accuracy:		92.93 %
Epoch 1304 of 2000 took 0.074s
  training loss:		0.009189
  validation loss:		0.393738
  validation accuracy:		93.04 %
Epoch 1305 of 2000 took 0.076s
  training loss:		0.008840
  validation loss:		0.400078
  validation accuracy:		92.93 %
Epoch 1306 of 2000 took 0.075s
  training loss:		0.009586
  validation loss:		0.406992
  validation accuracy:		92.83 %
Epoch 1307 of 2000 took 0.076s
  training loss:		0.009289
  validation loss:		0.403873
  validation accuracy:		92.72 %
Epoch 1308 of 2000 took 0.075s
  training loss:		0.009193
  validation loss:		0.402758
  validation accuracy:		93.04 %
Epoch 1309 of 2000 took 0.074s
  training loss:		0.009176
  validation loss:		0.404696
  validation accuracy:		92.93 %
Epoch 1310 of 2000 took 0.078s
  training loss:		0.008927
  validation loss:		0.398925
  validation accuracy:		93.04 %
Epoch 1311 of 2000 took 0.073s
  training loss:		0.009148
  validation loss:		0.404224
  validation accuracy:		92.83 %
Epoch 1312 of 2000 took 0.077s
  training loss:		0.009083
  validation loss:		0.407010
  validation accuracy:		92.83 %
Epoch 1313 of 2000 took 0.077s
  training loss:		0.009197
  validation loss:		0.401860
  validation accuracy:		92.93 %
Epoch 1314 of 2000 took 0.076s
  training loss:		0.009270
  validation loss:		0.397184
  validation accuracy:		92.72 %
Epoch 1315 of 2000 took 0.073s
  training loss:		0.009379
  validation loss:		0.403981
  validation accuracy:		93.04 %
Epoch 1316 of 2000 took 0.077s
  training loss:		0.009085
  validation loss:		0.409470
  validation accuracy:		92.83 %
Epoch 1317 of 2000 took 0.075s
  training loss:		0.008949
  validation loss:		0.407195
  validation accuracy:		93.04 %
Epoch 1318 of 2000 took 0.075s
  training loss:		0.009282
  validation loss:		0.406104
  validation accuracy:		92.83 %
Epoch 1319 of 2000 took 0.073s
  training loss:		0.008901
  validation loss:		0.406682
  validation accuracy:		92.83 %
Epoch 1320 of 2000 took 0.076s
  training loss:		0.009192
  validation loss:		0.409702
  validation accuracy:		92.83 %
Epoch 1321 of 2000 took 0.076s
  training loss:		0.008911
  validation loss:		0.402461
  validation accuracy:		92.93 %
Epoch 1322 of 2000 took 0.077s
  training loss:		0.008828
  validation loss:		0.410296
  validation accuracy:		92.72 %
Epoch 1323 of 2000 took 0.076s
  training loss:		0.009191
  validation loss:		0.412030
  validation accuracy:		92.83 %
Epoch 1324 of 2000 took 0.077s
  training loss:		0.009209
  validation loss:		0.407391
  validation accuracy:		92.72 %
Epoch 1325 of 2000 took 0.075s
  training loss:		0.008911
  validation loss:		0.405543
  validation accuracy:		92.72 %
Epoch 1326 of 2000 took 0.075s
  training loss:		0.008813
  validation loss:		0.408088
  validation accuracy:		92.83 %
Epoch 1327 of 2000 took 0.076s
  training loss:		0.008654
  validation loss:		0.403515
  validation accuracy:		93.04 %
Epoch 1328 of 2000 took 0.078s
  training loss:		0.008891
  validation loss:		0.406421
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.074s
  training loss:		0.008671
  validation loss:		0.407346
  validation accuracy:		92.72 %
Epoch 1330 of 2000 took 0.075s
  training loss:		0.008658
  validation loss:		0.405185
  validation accuracy:		93.04 %
Epoch 1331 of 2000 took 0.076s
  training loss:		0.008973
  validation loss:		0.404862
  validation accuracy:		92.83 %
Epoch 1332 of 2000 took 0.075s
  training loss:		0.009009
  validation loss:		0.402040
  validation accuracy:		92.83 %
Epoch 1333 of 2000 took 0.075s
  training loss:		0.008963
  validation loss:		0.406239
  validation accuracy:		93.04 %
Epoch 1334 of 2000 took 0.077s
  training loss:		0.008426
  validation loss:		0.407441
  validation accuracy:		92.83 %
Epoch 1335 of 2000 took 0.073s
  training loss:		0.008964
  validation loss:		0.414249
  validation accuracy:		92.72 %
Epoch 1336 of 2000 took 0.075s
  training loss:		0.008976
  validation loss:		0.407477
  validation accuracy:		93.04 %
Epoch 1337 of 2000 took 0.075s
  training loss:		0.008674
  validation loss:		0.407342
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.075s
  training loss:		0.008829
  validation loss:		0.406236
  validation accuracy:		92.93 %
Epoch 1339 of 2000 took 0.073s
  training loss:		0.008680
  validation loss:		0.405355
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.074s
  training loss:		0.009064
  validation loss:		0.410835
  validation accuracy:		92.83 %
Epoch 1341 of 2000 took 0.074s
  training loss:		0.008968
  validation loss:		0.416470
  validation accuracy:		92.72 %
Epoch 1342 of 2000 took 0.075s
  training loss:		0.009124
  validation loss:		0.405509
  validation accuracy:		92.72 %
Epoch 1343 of 2000 took 0.074s
  training loss:		0.008389
  validation loss:		0.406092
  validation accuracy:		93.04 %
Epoch 1344 of 2000 took 0.078s
  training loss:		0.008669
  validation loss:		0.407236
  validation accuracy:		92.61 %
Epoch 1345 of 2000 took 0.077s
  training loss:		0.008470
  validation loss:		0.414146
  validation accuracy:		92.83 %
Epoch 1346 of 2000 took 0.074s
  training loss:		0.008944
  validation loss:		0.414108
  validation accuracy:		92.83 %
Epoch 1347 of 2000 took 0.075s
  training loss:		0.008890
  validation loss:		0.411767
  validation accuracy:		92.83 %
Epoch 1348 of 2000 took 0.076s
  training loss:		0.008401
  validation loss:		0.410007
  validation accuracy:		92.93 %
Epoch 1349 of 2000 took 0.075s
  training loss:		0.008494
  validation loss:		0.411971
  validation accuracy:		92.83 %
Epoch 1350 of 2000 took 0.076s
  training loss:		0.008317
  validation loss:		0.411677
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.075s
  training loss:		0.008451
  validation loss:		0.411431
  validation accuracy:		92.93 %
Epoch 1352 of 2000 took 0.076s
  training loss:		0.008341
  validation loss:		0.409382
  validation accuracy:		92.93 %
Epoch 1353 of 2000 took 0.075s
  training loss:		0.008494
  validation loss:		0.417110
  validation accuracy:		92.83 %
Epoch 1354 of 2000 took 0.076s
  training loss:		0.008376
  validation loss:		0.409673
  validation accuracy:		92.83 %
Epoch 1355 of 2000 took 0.076s
  training loss:		0.008364
  validation loss:		0.409728
  validation accuracy:		92.83 %
Epoch 1356 of 2000 took 0.075s
  training loss:		0.008435
  validation loss:		0.422502
  validation accuracy:		92.61 %
Epoch 1357 of 2000 took 0.077s
  training loss:		0.008492
  validation loss:		0.417202
  validation accuracy:		92.83 %
Epoch 1358 of 2000 took 0.074s
  training loss:		0.008095
  validation loss:		0.408774
  validation accuracy:		92.83 %
Epoch 1359 of 2000 took 0.078s
  training loss:		0.008409
  validation loss:		0.418136
  validation accuracy:		92.72 %
Epoch 1360 of 2000 took 0.075s
  training loss:		0.008111
  validation loss:		0.408727
  validation accuracy:		92.72 %
Epoch 1361 of 2000 took 0.075s
  training loss:		0.008445
  validation loss:		0.426278
  validation accuracy:		92.83 %
Epoch 1362 of 2000 took 0.076s
  training loss:		0.008573
  validation loss:		0.412308
  validation accuracy:		92.93 %
Epoch 1363 of 2000 took 0.075s
  training loss:		0.008440
  validation loss:		0.416222
  validation accuracy:		92.72 %
Epoch 1364 of 2000 took 0.074s
  training loss:		0.008388
  validation loss:		0.407714
  validation accuracy:		93.04 %
Epoch 1365 of 2000 took 0.076s
  training loss:		0.008244
  validation loss:		0.411604
  validation accuracy:		92.93 %
Epoch 1366 of 2000 took 0.075s
  training loss:		0.008399
  validation loss:		0.409597
  validation accuracy:		92.93 %
Epoch 1367 of 2000 took 0.075s
  training loss:		0.008192
  validation loss:		0.414444
  validation accuracy:		92.83 %
Epoch 1368 of 2000 took 0.077s
  training loss:		0.008319
  validation loss:		0.413605
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.074s
  training loss:		0.008158
  validation loss:		0.413210
  validation accuracy:		92.93 %
Epoch 1370 of 2000 took 0.077s
  training loss:		0.007981
  validation loss:		0.411652
  validation accuracy:		93.04 %
Epoch 1371 of 2000 took 0.076s
  training loss:		0.007922
  validation loss:		0.416515
  validation accuracy:		92.93 %
Epoch 1372 of 2000 took 0.078s
  training loss:		0.007910
  validation loss:		0.416391
  validation accuracy:		92.83 %
Epoch 1373 of 2000 took 0.075s
  training loss:		0.008068
  validation loss:		0.422917
  validation accuracy:		92.72 %
Epoch 1374 of 2000 took 0.075s
  training loss:		0.008276
  validation loss:		0.415025
  validation accuracy:		92.83 %
Epoch 1375 of 2000 took 0.074s
  training loss:		0.008324
  validation loss:		0.411766
  validation accuracy:		92.93 %
Epoch 1376 of 2000 took 0.076s
  training loss:		0.007831
  validation loss:		0.414542
  validation accuracy:		93.04 %
Epoch 1377 of 2000 took 0.075s
  training loss:		0.007789
  validation loss:		0.417142
  validation accuracy:		92.83 %
Epoch 1378 of 2000 took 0.076s
  training loss:		0.008186
  validation loss:		0.419511
  validation accuracy:		92.83 %
Epoch 1379 of 2000 took 0.078s
  training loss:		0.008205
  validation loss:		0.417301
  validation accuracy:		92.83 %
Epoch 1380 of 2000 took 0.076s
  training loss:		0.008269
  validation loss:		0.414718
  validation accuracy:		92.93 %
Epoch 1381 of 2000 took 0.074s
  training loss:		0.008051
  validation loss:		0.419711
  validation accuracy:		92.61 %
Epoch 1382 of 2000 took 0.074s
  training loss:		0.007879
  validation loss:		0.418423
  validation accuracy:		92.83 %
Epoch 1383 of 2000 took 0.077s
  training loss:		0.007912
  validation loss:		0.410667
  validation accuracy:		92.93 %
Epoch 1384 of 2000 took 0.075s
  training loss:		0.007988
  validation loss:		0.410536
  validation accuracy:		92.72 %
Epoch 1385 of 2000 took 0.074s
  training loss:		0.008090
  validation loss:		0.423673
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.076s
  training loss:		0.008115
  validation loss:		0.410937
  validation accuracy:		92.93 %
Epoch 1387 of 2000 took 0.076s
  training loss:		0.008044
  validation loss:		0.417277
  validation accuracy:		92.93 %
Epoch 1388 of 2000 took 0.076s
  training loss:		0.007865
  validation loss:		0.423567
  validation accuracy:		92.72 %
Epoch 1389 of 2000 took 0.075s
  training loss:		0.007628
  validation loss:		0.414822
  validation accuracy:		92.93 %
Epoch 1390 of 2000 took 0.075s
  training loss:		0.007993
  validation loss:		0.418606
  validation accuracy:		92.72 %
Epoch 1391 of 2000 took 0.076s
  training loss:		0.008050
  validation loss:		0.425299
  validation accuracy:		92.83 %
Epoch 1392 of 2000 took 0.075s
  training loss:		0.007756
  validation loss:		0.414937
  validation accuracy:		93.04 %
Epoch 1393 of 2000 took 0.078s
  training loss:		0.007719
  validation loss:		0.418004
  validation accuracy:		92.93 %
Epoch 1394 of 2000 took 0.079s
  training loss:		0.007558
  validation loss:		0.411443
  validation accuracy:		92.93 %
Epoch 1395 of 2000 took 0.075s
  training loss:		0.007965
  validation loss:		0.419569
  validation accuracy:		92.83 %
Epoch 1396 of 2000 took 0.077s
  training loss:		0.007955
  validation loss:		0.415596
  validation accuracy:		92.93 %
Epoch 1397 of 2000 took 0.075s
  training loss:		0.007644
  validation loss:		0.415130
  validation accuracy:		92.83 %
Epoch 1398 of 2000 took 0.074s
  training loss:		0.007468
  validation loss:		0.417157
  validation accuracy:		92.72 %
Epoch 1399 of 2000 took 0.075s
  training loss:		0.007720
  validation loss:		0.423334
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.075s
  training loss:		0.007897
  validation loss:		0.420290
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.075s
  training loss:		0.007586
  validation loss:		0.416178
  validation accuracy:		93.04 %
Epoch 1402 of 2000 took 0.074s
  training loss:		0.007363
  validation loss:		0.422484
  validation accuracy:		92.72 %
Epoch 1403 of 2000 took 0.074s
  training loss:		0.007598
  validation loss:		0.424340
  validation accuracy:		92.83 %
Epoch 1404 of 2000 took 0.075s
  training loss:		0.007842
  validation loss:		0.426066
  validation accuracy:		92.72 %
Epoch 1405 of 2000 took 0.075s
  training loss:		0.007582
  validation loss:		0.426113
  validation accuracy:		92.83 %
Epoch 1406 of 2000 took 0.076s
  training loss:		0.007213
  validation loss:		0.410247
  validation accuracy:		92.83 %
Epoch 1407 of 2000 took 0.075s
  training loss:		0.007642
  validation loss:		0.422596
  validation accuracy:		92.93 %
Epoch 1408 of 2000 took 0.076s
  training loss:		0.007670
  validation loss:		0.430586
  validation accuracy:		92.83 %
Epoch 1409 of 2000 took 0.072s
  training loss:		0.007691
  validation loss:		0.419448
  validation accuracy:		92.72 %
Epoch 1410 of 2000 took 0.077s
  training loss:		0.007666
  validation loss:		0.425594
  validation accuracy:		92.93 %
Epoch 1411 of 2000 took 0.076s
  training loss:		0.007701
  validation loss:		0.426731
  validation accuracy:		92.83 %
Epoch 1412 of 2000 took 0.078s
  training loss:		0.007436
  validation loss:		0.422282
  validation accuracy:		92.83 %
Epoch 1413 of 2000 took 0.078s
  training loss:		0.007361
  validation loss:		0.423681
  validation accuracy:		92.83 %
Epoch 1414 of 2000 took 0.075s
  training loss:		0.007675
  validation loss:		0.425062
  validation accuracy:		92.72 %
Epoch 1415 of 2000 took 0.075s
  training loss:		0.007733
  validation loss:		0.423925
  validation accuracy:		92.83 %
Epoch 1416 of 2000 took 0.077s
  training loss:		0.007506
  validation loss:		0.417786
  validation accuracy:		92.93 %
Epoch 1417 of 2000 took 0.078s
  training loss:		0.007719
  validation loss:		0.433353
  validation accuracy:		92.72 %
Epoch 1418 of 2000 took 0.075s
  training loss:		0.007523
  validation loss:		0.417557
  validation accuracy:		92.83 %
Epoch 1419 of 2000 took 0.076s
  training loss:		0.007816
  validation loss:		0.416054
  validation accuracy:		92.72 %
Epoch 1420 of 2000 took 0.074s
  training loss:		0.007483
  validation loss:		0.429648
  validation accuracy:		92.83 %
Epoch 1421 of 2000 took 0.079s
  training loss:		0.007697
  validation loss:		0.422502
  validation accuracy:		92.83 %
Epoch 1422 of 2000 took 0.077s
  training loss:		0.007432
  validation loss:		0.426469
  validation accuracy:		92.83 %
Epoch 1423 of 2000 took 0.074s
  training loss:		0.007651
  validation loss:		0.419763
  validation accuracy:		92.72 %
Epoch 1424 of 2000 took 0.076s
  training loss:		0.007469
  validation loss:		0.429506
  validation accuracy:		92.83 %
Epoch 1425 of 2000 took 0.076s
  training loss:		0.007275
  validation loss:		0.426810
  validation accuracy:		92.72 %
Epoch 1426 of 2000 took 0.075s
  training loss:		0.007493
  validation loss:		0.426276
  validation accuracy:		92.83 %
Epoch 1427 of 2000 took 0.076s
  training loss:		0.007135
  validation loss:		0.426740
  validation accuracy:		92.83 %
Epoch 1428 of 2000 took 0.075s
  training loss:		0.007329
  validation loss:		0.423766
  validation accuracy:		92.72 %
Epoch 1429 of 2000 took 0.072s
  training loss:		0.007787
  validation loss:		0.423372
  validation accuracy:		92.83 %
Epoch 1430 of 2000 took 0.076s
  training loss:		0.007558
  validation loss:		0.428179
  validation accuracy:		92.83 %
Epoch 1431 of 2000 took 0.076s
  training loss:		0.007487
  validation loss:		0.421806
  validation accuracy:		92.61 %
Epoch 1432 of 2000 took 0.074s
  training loss:		0.007278
  validation loss:		0.428596
  validation accuracy:		92.83 %
Epoch 1433 of 2000 took 0.075s
  training loss:		0.007379
  validation loss:		0.423318
  validation accuracy:		92.93 %
Epoch 1434 of 2000 took 0.075s
  training loss:		0.007352
  validation loss:		0.427096
  validation accuracy:		92.93 %
Epoch 1435 of 2000 took 0.076s
  training loss:		0.007382
  validation loss:		0.432735
  validation accuracy:		92.72 %
Epoch 1436 of 2000 took 0.075s
  training loss:		0.007059
  validation loss:		0.423169
  validation accuracy:		92.72 %
Epoch 1437 of 2000 took 0.075s
  training loss:		0.007343
  validation loss:		0.437956
  validation accuracy:		92.83 %
Epoch 1438 of 2000 took 0.079s
  training loss:		0.007351
  validation loss:		0.426425
  validation accuracy:		92.72 %
Epoch 1439 of 2000 took 0.074s
  training loss:		0.007280
  validation loss:		0.433068
  validation accuracy:		92.83 %
Epoch 1440 of 2000 took 0.073s
  training loss:		0.007333
  validation loss:		0.421222
  validation accuracy:		92.93 %
Epoch 1441 of 2000 took 0.074s
  training loss:		0.007351
  validation loss:		0.425561
  validation accuracy:		92.72 %
Epoch 1442 of 2000 took 0.075s
  training loss:		0.007304
  validation loss:		0.430407
  validation accuracy:		92.93 %
Epoch 1443 of 2000 took 0.076s
  training loss:		0.007249
  validation loss:		0.429097
  validation accuracy:		92.72 %
Epoch 1444 of 2000 took 0.074s
  training loss:		0.007034
  validation loss:		0.430128
  validation accuracy:		92.83 %
Epoch 1445 of 2000 took 0.074s
  training loss:		0.007328
  validation loss:		0.426235
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.076s
  training loss:		0.007220
  validation loss:		0.428058
  validation accuracy:		92.72 %
Epoch 1447 of 2000 took 0.077s
  training loss:		0.006969
  validation loss:		0.423556
  validation accuracy:		92.83 %
Epoch 1448 of 2000 took 0.075s
  training loss:		0.006915
  validation loss:		0.429654
  validation accuracy:		92.72 %
Epoch 1449 of 2000 took 0.076s
  training loss:		0.007310
  validation loss:		0.431019
  validation accuracy:		92.72 %
Epoch 1450 of 2000 took 0.074s
  training loss:		0.007116
  validation loss:		0.437372
  validation accuracy:		92.72 %
Epoch 1451 of 2000 took 0.076s
  training loss:		0.007091
  validation loss:		0.424846
  validation accuracy:		92.93 %
Epoch 1452 of 2000 took 0.076s
  training loss:		0.006994
  validation loss:		0.435885
  validation accuracy:		92.93 %
Epoch 1453 of 2000 took 0.074s
  training loss:		0.007280
  validation loss:		0.430022
  validation accuracy:		92.83 %
Epoch 1454 of 2000 took 0.078s
  training loss:		0.007019
  validation loss:		0.428674
  validation accuracy:		92.93 %
Epoch 1455 of 2000 took 0.082s
  training loss:		0.006720
  validation loss:		0.426984
  validation accuracy:		93.04 %
Epoch 1456 of 2000 took 0.083s
  training loss:		0.007036
  validation loss:		0.428265
  validation accuracy:		92.93 %
Epoch 1457 of 2000 took 0.079s
  training loss:		0.007254
  validation loss:		0.434959
  validation accuracy:		92.93 %
Epoch 1458 of 2000 took 0.075s
  training loss:		0.007101
  validation loss:		0.435279
  validation accuracy:		92.83 %
Epoch 1459 of 2000 took 0.076s
  training loss:		0.007114
  validation loss:		0.432350
  validation accuracy:		92.83 %
Epoch 1460 of 2000 took 0.077s
  training loss:		0.007083
  validation loss:		0.427706
  validation accuracy:		92.83 %
Epoch 1461 of 2000 took 0.078s
  training loss:		0.007060
  validation loss:		0.433813
  validation accuracy:		92.83 %
Epoch 1462 of 2000 took 0.079s
  training loss:		0.006984
  validation loss:		0.431394
  validation accuracy:		92.83 %
Epoch 1463 of 2000 took 0.075s
  training loss:		0.006952
  validation loss:		0.435094
  validation accuracy:		92.61 %
Epoch 1464 of 2000 took 0.080s
  training loss:		0.007052
  validation loss:		0.433997
  validation accuracy:		92.72 %
Epoch 1465 of 2000 took 0.081s
  training loss:		0.006734
  validation loss:		0.433855
  validation accuracy:		92.72 %
Epoch 1466 of 2000 took 0.076s
  training loss:		0.006997
  validation loss:		0.432888
  validation accuracy:		92.61 %
Epoch 1467 of 2000 took 0.075s
  training loss:		0.006846
  validation loss:		0.433710
  validation accuracy:		92.72 %
Epoch 1468 of 2000 took 0.076s
  training loss:		0.006824
  validation loss:		0.427633
  validation accuracy:		92.93 %
Epoch 1469 of 2000 took 0.076s
  training loss:		0.006948
  validation loss:		0.430264
  validation accuracy:		92.83 %
Epoch 1470 of 2000 took 0.076s
  training loss:		0.006519
  validation loss:		0.444110
  validation accuracy:		92.83 %
Epoch 1471 of 2000 took 0.078s
  training loss:		0.007042
  validation loss:		0.427039
  validation accuracy:		92.93 %
Epoch 1472 of 2000 took 0.076s
  training loss:		0.006804
  validation loss:		0.432612
  validation accuracy:		92.83 %
Epoch 1473 of 2000 took 0.076s
  training loss:		0.006795
  validation loss:		0.428109
  validation accuracy:		93.04 %
Epoch 1474 of 2000 took 0.078s
  training loss:		0.007092
  validation loss:		0.441138
  validation accuracy:		92.83 %
Epoch 1475 of 2000 took 0.075s
  training loss:		0.006736
  validation loss:		0.434339
  validation accuracy:		92.83 %
Epoch 1476 of 2000 took 0.078s
  training loss:		0.006738
  validation loss:		0.442145
  validation accuracy:		92.83 %
Epoch 1477 of 2000 took 0.077s
  training loss:		0.006772
  validation loss:		0.435460
  validation accuracy:		92.83 %
Epoch 1478 of 2000 took 0.076s
  training loss:		0.006628
  validation loss:		0.434128
  validation accuracy:		92.83 %
Epoch 1479 of 2000 took 0.077s
  training loss:		0.006403
  validation loss:		0.438062
  validation accuracy:		92.83 %
Epoch 1480 of 2000 took 0.078s
  training loss:		0.006590
  validation loss:		0.436817
  validation accuracy:		92.83 %
Epoch 1481 of 2000 took 0.074s
  training loss:		0.006638
  validation loss:		0.430616
  validation accuracy:		92.50 %
Epoch 1482 of 2000 took 0.075s
  training loss:		0.006926
  validation loss:		0.431224
  validation accuracy:		92.93 %
Epoch 1483 of 2000 took 0.074s
  training loss:		0.006667
  validation loss:		0.439177
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.074s
  training loss:		0.006619
  validation loss:		0.435429
  validation accuracy:		92.72 %
Epoch 1485 of 2000 took 0.078s
  training loss:		0.006495
  validation loss:		0.435290
  validation accuracy:		92.93 %
Epoch 1486 of 2000 took 0.074s
  training loss:		0.006667
  validation loss:		0.442043
  validation accuracy:		92.61 %
Epoch 1487 of 2000 took 0.077s
  training loss:		0.006460
  validation loss:		0.435347
  validation accuracy:		92.93 %
Epoch 1488 of 2000 took 0.078s
  training loss:		0.006710
  validation loss:		0.436415
  validation accuracy:		92.83 %
Epoch 1489 of 2000 took 0.075s
  training loss:		0.006251
  validation loss:		0.439492
  validation accuracy:		92.83 %
Epoch 1490 of 2000 took 0.077s
  training loss:		0.006481
  validation loss:		0.444716
  validation accuracy:		92.72 %
Epoch 1491 of 2000 took 0.076s
  training loss:		0.006532
  validation loss:		0.437980
  validation accuracy:		92.93 %
Epoch 1492 of 2000 took 0.075s
  training loss:		0.006758
  validation loss:		0.435646
  validation accuracy:		92.83 %
Epoch 1493 of 2000 took 0.075s
  training loss:		0.007039
  validation loss:		0.436639
  validation accuracy:		92.72 %
Epoch 1494 of 2000 took 0.074s
  training loss:		0.006498
  validation loss:		0.438116
  validation accuracy:		92.72 %
Epoch 1495 of 2000 took 0.077s
  training loss:		0.006919
  validation loss:		0.441681
  validation accuracy:		92.83 %
Epoch 1496 of 2000 took 0.075s
  training loss:		0.006724
  validation loss:		0.439066
  validation accuracy:		92.83 %
Epoch 1497 of 2000 took 0.075s
  training loss:		0.006695
  validation loss:		0.446107
  validation accuracy:		92.72 %
Epoch 1498 of 2000 took 0.078s
  training loss:		0.006371
  validation loss:		0.445269
  validation accuracy:		92.72 %
Epoch 1499 of 2000 took 0.078s
  training loss:		0.006628
  validation loss:		0.436007
  validation accuracy:		92.83 %
Epoch 1500 of 2000 took 0.075s
  training loss:		0.006660
  validation loss:		0.445644
  validation accuracy:		92.72 %
Epoch 1501 of 2000 took 0.076s
  training loss:		0.006839
  validation loss:		0.438435
  validation accuracy:		92.72 %
Epoch 1502 of 2000 took 0.076s
  training loss:		0.006723
  validation loss:		0.435865
  validation accuracy:		92.72 %
Epoch 1503 of 2000 took 0.075s
  training loss:		0.006567
  validation loss:		0.438192
  validation accuracy:		92.93 %
Epoch 1504 of 2000 took 0.075s
  training loss:		0.006405
  validation loss:		0.441137
  validation accuracy:		92.72 %
Epoch 1505 of 2000 took 0.077s
  training loss:		0.006674
  validation loss:		0.435773
  validation accuracy:		92.83 %
Epoch 1506 of 2000 took 0.074s
  training loss:		0.006416
  validation loss:		0.432611
  validation accuracy:		93.04 %
Epoch 1507 of 2000 took 0.077s
  training loss:		0.006502
  validation loss:		0.444035
  validation accuracy:		92.83 %
Epoch 1508 of 2000 took 0.077s
  training loss:		0.006467
  validation loss:		0.444067
  validation accuracy:		92.72 %
Epoch 1509 of 2000 took 0.074s
  training loss:		0.006489
  validation loss:		0.445389
  validation accuracy:		92.83 %
Epoch 1510 of 2000 took 0.075s
  training loss:		0.006451
  validation loss:		0.440968
  validation accuracy:		92.61 %
Epoch 1511 of 2000 took 0.075s
  training loss:		0.006510
  validation loss:		0.440002
  validation accuracy:		92.61 %
Epoch 1512 of 2000 took 0.077s
  training loss:		0.006511
  validation loss:		0.445861
  validation accuracy:		92.83 %
Epoch 1513 of 2000 took 0.077s
  training loss:		0.006314
  validation loss:		0.442331
  validation accuracy:		92.61 %
Epoch 1514 of 2000 took 0.076s
  training loss:		0.006255
  validation loss:		0.439504
  validation accuracy:		92.83 %
Epoch 1515 of 2000 took 0.076s
  training loss:		0.006414
  validation loss:		0.448533
  validation accuracy:		92.93 %
Epoch 1516 of 2000 took 0.074s
  training loss:		0.006587
  validation loss:		0.444671
  validation accuracy:		92.61 %
Epoch 1517 of 2000 took 0.077s
  training loss:		0.006371
  validation loss:		0.441329
  validation accuracy:		92.93 %
Epoch 1518 of 2000 took 0.074s
  training loss:		0.006263
  validation loss:		0.442765
  validation accuracy:		92.93 %
Epoch 1519 of 2000 took 0.075s
  training loss:		0.006218
  validation loss:		0.445496
  validation accuracy:		92.72 %
Epoch 1520 of 2000 took 0.076s
  training loss:		0.006144
  validation loss:		0.447942
  validation accuracy:		92.72 %
Epoch 1521 of 2000 took 0.075s
  training loss:		0.006498
  validation loss:		0.442628
  validation accuracy:		92.72 %
Epoch 1522 of 2000 took 0.078s
  training loss:		0.006545
  validation loss:		0.441462
  validation accuracy:		92.72 %
Epoch 1523 of 2000 took 0.073s
  training loss:		0.006437
  validation loss:		0.441360
  validation accuracy:		92.83 %
Epoch 1524 of 2000 took 0.077s
  training loss:		0.006415
  validation loss:		0.446217
  validation accuracy:		92.83 %
Epoch 1525 of 2000 took 0.078s
  training loss:		0.005990
  validation loss:		0.443043
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.076s
  training loss:		0.006410
  validation loss:		0.439945
  validation accuracy:		92.72 %
Epoch 1527 of 2000 took 0.074s
  training loss:		0.006306
  validation loss:		0.443982
  validation accuracy:		92.61 %
Epoch 1528 of 2000 took 0.075s
  training loss:		0.006336
  validation loss:		0.449741
  validation accuracy:		92.72 %
Epoch 1529 of 2000 took 0.077s
  training loss:		0.006275
  validation loss:		0.442919
  validation accuracy:		92.93 %
Epoch 1530 of 2000 took 0.078s
  training loss:		0.006122
  validation loss:		0.441923
  validation accuracy:		92.72 %
Epoch 1531 of 2000 took 0.078s
  training loss:		0.006431
  validation loss:		0.447203
  validation accuracy:		92.83 %
Epoch 1532 of 2000 took 0.076s
  training loss:		0.006330
  validation loss:		0.440516
  validation accuracy:		92.93 %
Epoch 1533 of 2000 took 0.077s
  training loss:		0.006279
  validation loss:		0.442382
  validation accuracy:		92.61 %
Epoch 1534 of 2000 took 0.075s
  training loss:		0.005983
  validation loss:		0.448076
  validation accuracy:		92.72 %
Epoch 1535 of 2000 took 0.077s
  training loss:		0.006057
  validation loss:		0.439232
  validation accuracy:		92.72 %
Epoch 1536 of 2000 took 0.075s
  training loss:		0.006335
  validation loss:		0.450274
  validation accuracy:		92.83 %
Epoch 1537 of 2000 took 0.077s
  training loss:		0.006162
  validation loss:		0.447383
  validation accuracy:		92.83 %
Epoch 1538 of 2000 took 0.075s
  training loss:		0.005955
  validation loss:		0.443400
  validation accuracy:		92.93 %
Epoch 1539 of 2000 took 0.077s
  training loss:		0.005872
  validation loss:		0.446092
  validation accuracy:		92.93 %
Epoch 1540 of 2000 took 0.076s
  training loss:		0.006110
  validation loss:		0.448945
  validation accuracy:		92.83 %
Epoch 1541 of 2000 took 0.075s
  training loss:		0.006032
  validation loss:		0.446975
  validation accuracy:		92.72 %
Epoch 1542 of 2000 took 0.074s
  training loss:		0.006119
  validation loss:		0.449117
  validation accuracy:		92.72 %
Epoch 1543 of 2000 took 0.077s
  training loss:		0.005956
  validation loss:		0.450254
  validation accuracy:		92.61 %
Epoch 1544 of 2000 took 0.074s
  training loss:		0.005866
  validation loss:		0.446596
  validation accuracy:		92.93 %
Epoch 1545 of 2000 took 0.073s
  training loss:		0.005924
  validation loss:		0.444836
  validation accuracy:		92.83 %
Epoch 1546 of 2000 took 0.078s
  training loss:		0.006030
  validation loss:		0.444920
  validation accuracy:		92.72 %
Epoch 1547 of 2000 took 0.076s
  training loss:		0.006080
  validation loss:		0.447481
  validation accuracy:		92.93 %
Epoch 1548 of 2000 took 0.075s
  training loss:		0.006024
  validation loss:		0.447787
  validation accuracy:		92.61 %
Epoch 1549 of 2000 took 0.075s
  training loss:		0.005843
  validation loss:		0.443873
  validation accuracy:		92.72 %
Epoch 1550 of 2000 took 0.078s
  training loss:		0.006053
  validation loss:		0.444168
  validation accuracy:		92.93 %
Epoch 1551 of 2000 took 0.077s
  training loss:		0.006098
  validation loss:		0.451374
  validation accuracy:		92.72 %
Epoch 1552 of 2000 took 0.074s
  training loss:		0.005963
  validation loss:		0.447267
  validation accuracy:		92.72 %
Epoch 1553 of 2000 took 0.078s
  training loss:		0.006152
  validation loss:		0.446848
  validation accuracy:		92.93 %
Epoch 1554 of 2000 took 0.074s
  training loss:		0.005983
  validation loss:		0.453678
  validation accuracy:		92.93 %
Epoch 1555 of 2000 took 0.075s
  training loss:		0.005958
  validation loss:		0.447024
  validation accuracy:		92.83 %
Epoch 1556 of 2000 took 0.077s
  training loss:		0.005901
  validation loss:		0.449438
  validation accuracy:		92.83 %
Epoch 1557 of 2000 took 0.074s
  training loss:		0.006023
  validation loss:		0.449350
  validation accuracy:		92.83 %
Epoch 1558 of 2000 took 0.076s
  training loss:		0.005976
  validation loss:		0.452501
  validation accuracy:		92.83 %
Epoch 1559 of 2000 took 0.073s
  training loss:		0.005887
  validation loss:		0.451032
  validation accuracy:		92.83 %
Epoch 1560 of 2000 took 0.075s
  training loss:		0.006078
  validation loss:		0.446961
  validation accuracy:		92.83 %
Epoch 1561 of 2000 took 0.078s
  training loss:		0.005906
  validation loss:		0.448761
  validation accuracy:		92.93 %
Epoch 1562 of 2000 took 0.077s
  training loss:		0.005861
  validation loss:		0.449261
  validation accuracy:		92.83 %
Epoch 1563 of 2000 took 0.076s
  training loss:		0.006077
  validation loss:		0.444170
  validation accuracy:		92.83 %
Epoch 1564 of 2000 took 0.077s
  training loss:		0.005903
  validation loss:		0.455577
  validation accuracy:		92.72 %
Epoch 1565 of 2000 took 0.076s
  training loss:		0.005813
  validation loss:		0.453524
  validation accuracy:		92.83 %
Epoch 1566 of 2000 took 0.076s
  training loss:		0.005884
  validation loss:		0.448968
  validation accuracy:		92.93 %
Epoch 1567 of 2000 took 0.078s
  training loss:		0.005882
  validation loss:		0.450039
  validation accuracy:		92.72 %
Epoch 1568 of 2000 took 0.077s
  training loss:		0.006056
  validation loss:		0.455375
  validation accuracy:		92.72 %
Epoch 1569 of 2000 took 0.075s
  training loss:		0.005555
  validation loss:		0.450594
  validation accuracy:		92.83 %
Epoch 1570 of 2000 took 0.074s
  training loss:		0.005794
  validation loss:		0.454867
  validation accuracy:		92.72 %
Epoch 1571 of 2000 took 0.077s
  training loss:		0.005676
  validation loss:		0.448079
  validation accuracy:		92.83 %
Epoch 1572 of 2000 took 0.076s
  training loss:		0.005813
  validation loss:		0.450599
  validation accuracy:		92.72 %
Epoch 1573 of 2000 took 0.078s
  training loss:		0.005723
  validation loss:		0.450542
  validation accuracy:		92.93 %
Epoch 1574 of 2000 took 0.075s
  training loss:		0.005817
  validation loss:		0.444444
  validation accuracy:		92.93 %
Epoch 1575 of 2000 took 0.074s
  training loss:		0.005971
  validation loss:		0.451884
  validation accuracy:		92.83 %
Epoch 1576 of 2000 took 0.074s
  training loss:		0.005728
  validation loss:		0.448463
  validation accuracy:		92.83 %
Epoch 1577 of 2000 took 0.078s
  training loss:		0.005720
  validation loss:		0.457621
  validation accuracy:		92.83 %
Epoch 1578 of 2000 took 0.079s
  training loss:		0.005753
  validation loss:		0.453440
  validation accuracy:		92.83 %
Epoch 1579 of 2000 took 0.073s
  training loss:		0.005718
  validation loss:		0.449265
  validation accuracy:		92.93 %
Epoch 1580 of 2000 took 0.076s
  training loss:		0.005710
  validation loss:		0.453057
  validation accuracy:		92.83 %
Epoch 1581 of 2000 took 0.077s
  training loss:		0.005877
  validation loss:		0.453002
  validation accuracy:		92.61 %
Epoch 1582 of 2000 took 0.077s
  training loss:		0.005742
  validation loss:		0.449943
  validation accuracy:		92.83 %
Epoch 1583 of 2000 took 0.079s
  training loss:		0.005913
  validation loss:		0.460971
  validation accuracy:		92.61 %
Epoch 1584 of 2000 took 0.076s
  training loss:		0.005808
  validation loss:		0.454211
  validation accuracy:		92.83 %
Epoch 1585 of 2000 took 0.077s
  training loss:		0.005653
  validation loss:		0.452716
  validation accuracy:		92.83 %
Epoch 1586 of 2000 took 0.075s
  training loss:		0.005480
  validation loss:		0.451463
  validation accuracy:		92.93 %
Epoch 1587 of 2000 took 0.076s
  training loss:		0.005684
  validation loss:		0.451386
  validation accuracy:		92.72 %
Epoch 1588 of 2000 took 0.075s
  training loss:		0.005622
  validation loss:		0.454370
  validation accuracy:		92.72 %
Epoch 1589 of 2000 took 0.076s
  training loss:		0.005739
  validation loss:		0.457289
  validation accuracy:		92.83 %
Epoch 1590 of 2000 took 0.073s
  training loss:		0.005719
  validation loss:		0.454588
  validation accuracy:		92.93 %
Epoch 1591 of 2000 took 0.077s
  training loss:		0.005934
  validation loss:		0.453777
  validation accuracy:		92.61 %
Epoch 1592 of 2000 took 0.079s
  training loss:		0.005569
  validation loss:		0.456585
  validation accuracy:		92.72 %
Epoch 1593 of 2000 took 0.077s
  training loss:		0.005609
  validation loss:		0.458101
  validation accuracy:		92.72 %
Epoch 1594 of 2000 took 0.077s
  training loss:		0.005634
  validation loss:		0.452614
  validation accuracy:		92.83 %
Epoch 1595 of 2000 took 0.077s
  training loss:		0.005565
  validation loss:		0.456605
  validation accuracy:		92.72 %
Epoch 1596 of 2000 took 0.078s
  training loss:		0.005788
  validation loss:		0.459110
  validation accuracy:		92.72 %
Epoch 1597 of 2000 took 0.077s
  training loss:		0.005570
  validation loss:		0.456974
  validation accuracy:		92.93 %
Epoch 1598 of 2000 took 0.077s
  training loss:		0.005414
  validation loss:		0.460160
  validation accuracy:		92.61 %
Epoch 1599 of 2000 took 0.075s
  training loss:		0.005662
  validation loss:		0.454321
  validation accuracy:		92.83 %
Epoch 1600 of 2000 took 0.076s
  training loss:		0.005630
  validation loss:		0.452443
  validation accuracy:		92.83 %
Epoch 1601 of 2000 took 0.078s
  training loss:		0.005691
  validation loss:		0.460956
  validation accuracy:		92.61 %
Epoch 1602 of 2000 took 0.077s
  training loss:		0.005482
  validation loss:		0.453668
  validation accuracy:		92.93 %
Epoch 1603 of 2000 took 0.076s
  training loss:		0.005577
  validation loss:		0.455379
  validation accuracy:		92.72 %
Epoch 1604 of 2000 took 0.075s
  training loss:		0.005509
  validation loss:		0.456813
  validation accuracy:		92.83 %
Epoch 1605 of 2000 took 0.073s
  training loss:		0.005620
  validation loss:		0.458144
  validation accuracy:		92.83 %
Epoch 1606 of 2000 took 0.075s
  training loss:		0.005510
  validation loss:		0.461542
  validation accuracy:		92.72 %
Epoch 1607 of 2000 took 0.076s
  training loss:		0.005530
  validation loss:		0.454918
  validation accuracy:		92.83 %
Epoch 1608 of 2000 took 0.076s
  training loss:		0.005637
  validation loss:		0.456749
  validation accuracy:		92.72 %
Epoch 1609 of 2000 took 0.076s
  training loss:		0.005566
  validation loss:		0.461086
  validation accuracy:		92.72 %
Epoch 1610 of 2000 took 0.077s
  training loss:		0.005490
  validation loss:		0.457360
  validation accuracy:		92.93 %
Epoch 1611 of 2000 took 0.074s
  training loss:		0.005470
  validation loss:		0.464146
  validation accuracy:		92.61 %
Epoch 1612 of 2000 took 0.075s
  training loss:		0.005509
  validation loss:		0.456159
  validation accuracy:		92.83 %
Epoch 1613 of 2000 took 0.075s
  training loss:		0.005390
  validation loss:		0.463485
  validation accuracy:		92.50 %
Epoch 1614 of 2000 took 0.076s
  training loss:		0.005512
  validation loss:		0.462658
  validation accuracy:		92.83 %
Epoch 1615 of 2000 took 0.075s
  training loss:		0.005411
  validation loss:		0.453908
  validation accuracy:		92.93 %
Epoch 1616 of 2000 took 0.074s
  training loss:		0.005485
  validation loss:		0.464391
  validation accuracy:		92.83 %
Epoch 1617 of 2000 took 0.077s
  training loss:		0.005415
  validation loss:		0.461681
  validation accuracy:		92.72 %
Epoch 1618 of 2000 took 0.078s
  training loss:		0.005545
  validation loss:		0.456294
  validation accuracy:		92.61 %
Epoch 1619 of 2000 took 0.076s
  training loss:		0.005314
  validation loss:		0.459499
  validation accuracy:		92.72 %
Epoch 1620 of 2000 took 0.076s
  training loss:		0.005448
  validation loss:		0.461386
  validation accuracy:		92.72 %
Epoch 1621 of 2000 took 0.077s
  training loss:		0.005454
  validation loss:		0.463732
  validation accuracy:		92.72 %
Epoch 1622 of 2000 took 0.075s
  training loss:		0.005234
  validation loss:		0.458941
  validation accuracy:		92.93 %
Epoch 1623 of 2000 took 0.076s
  training loss:		0.005188
  validation loss:		0.465087
  validation accuracy:		92.72 %
Epoch 1624 of 2000 took 0.075s
  training loss:		0.005369
  validation loss:		0.453299
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.075s
  training loss:		0.005427
  validation loss:		0.468826
  validation accuracy:		92.72 %
Epoch 1626 of 2000 took 0.076s
  training loss:		0.005441
  validation loss:		0.458698
  validation accuracy:		92.72 %
Epoch 1627 of 2000 took 0.077s
  training loss:		0.005302
  validation loss:		0.461370
  validation accuracy:		92.83 %
Epoch 1628 of 2000 took 0.075s
  training loss:		0.005381
  validation loss:		0.460848
  validation accuracy:		92.72 %
Epoch 1629 of 2000 took 0.077s
  training loss:		0.005231
  validation loss:		0.457614
  validation accuracy:		92.72 %
Epoch 1630 of 2000 took 0.075s
  training loss:		0.005284
  validation loss:		0.462868
  validation accuracy:		92.72 %
Epoch 1631 of 2000 took 0.075s
  training loss:		0.005259
  validation loss:		0.459513
  validation accuracy:		92.93 %
Epoch 1632 of 2000 took 0.075s
  training loss:		0.005275
  validation loss:		0.455998
  validation accuracy:		92.83 %
Epoch 1633 of 2000 took 0.076s
  training loss:		0.005212
  validation loss:		0.464684
  validation accuracy:		92.93 %
Epoch 1634 of 2000 took 0.074s
  training loss:		0.005337
  validation loss:		0.463033
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.075s
  training loss:		0.005214
  validation loss:		0.457267
  validation accuracy:		92.72 %
Epoch 1636 of 2000 took 0.076s
  training loss:		0.005369
  validation loss:		0.463178
  validation accuracy:		92.72 %
Epoch 1637 of 2000 took 0.076s
  training loss:		0.005323
  validation loss:		0.465405
  validation accuracy:		92.72 %
Epoch 1638 of 2000 took 0.077s
  training loss:		0.005250
  validation loss:		0.462445
  validation accuracy:		92.83 %
Epoch 1639 of 2000 took 0.077s
  training loss:		0.005131
  validation loss:		0.465186
  validation accuracy:		92.83 %
Epoch 1640 of 2000 took 0.076s
  training loss:		0.005188
  validation loss:		0.462656
  validation accuracy:		92.83 %
Epoch 1641 of 2000 took 0.075s
  training loss:		0.005223
  validation loss:		0.460234
  validation accuracy:		92.83 %
Epoch 1642 of 2000 took 0.074s
  training loss:		0.005124
  validation loss:		0.463868
  validation accuracy:		92.72 %
Epoch 1643 of 2000 took 0.078s
  training loss:		0.005322
  validation loss:		0.461530
  validation accuracy:		92.83 %
Epoch 1644 of 2000 took 0.076s
  training loss:		0.005173
  validation loss:		0.460460
  validation accuracy:		92.72 %
Epoch 1645 of 2000 took 0.076s
  training loss:		0.005179
  validation loss:		0.462850
  validation accuracy:		92.72 %
Epoch 1646 of 2000 took 0.079s
  training loss:		0.005313
  validation loss:		0.471193
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.075s
  training loss:		0.005218
  validation loss:		0.462785
  validation accuracy:		92.72 %
Epoch 1648 of 2000 took 0.076s
  training loss:		0.005257
  validation loss:		0.463977
  validation accuracy:		92.83 %
Epoch 1649 of 2000 took 0.075s
  training loss:		0.005311
  validation loss:		0.461738
  validation accuracy:		92.61 %
Epoch 1650 of 2000 took 0.077s
  training loss:		0.005177
  validation loss:		0.466780
  validation accuracy:		92.72 %
Epoch 1651 of 2000 took 0.074s
  training loss:		0.005122
  validation loss:		0.464450
  validation accuracy:		92.83 %
Epoch 1652 of 2000 took 0.075s
  training loss:		0.005277
  validation loss:		0.473333
  validation accuracy:		92.61 %
Epoch 1653 of 2000 took 0.077s
  training loss:		0.005186
  validation loss:		0.461281
  validation accuracy:		92.61 %
Epoch 1654 of 2000 took 0.074s
  training loss:		0.005150
  validation loss:		0.464943
  validation accuracy:		92.72 %
Epoch 1655 of 2000 took 0.077s
  training loss:		0.005144
  validation loss:		0.464141
  validation accuracy:		92.93 %
Epoch 1656 of 2000 took 0.076s
  training loss:		0.005147
  validation loss:		0.464797
  validation accuracy:		92.61 %
Epoch 1657 of 2000 took 0.073s
  training loss:		0.005085
  validation loss:		0.464794
  validation accuracy:		92.93 %
Epoch 1658 of 2000 took 0.075s
  training loss:		0.005040
  validation loss:		0.467067
  validation accuracy:		92.72 %
Epoch 1659 of 2000 took 0.074s
  training loss:		0.005043
  validation loss:		0.466537
  validation accuracy:		92.93 %
Epoch 1660 of 2000 took 0.074s
  training loss:		0.005281
  validation loss:		0.467855
  validation accuracy:		92.93 %
Epoch 1661 of 2000 took 0.075s
  training loss:		0.005063
  validation loss:		0.467659
  validation accuracy:		92.72 %
Epoch 1662 of 2000 took 0.076s
  training loss:		0.005077
  validation loss:		0.462220
  validation accuracy:		92.72 %
Epoch 1663 of 2000 took 0.076s
  training loss:		0.005121
  validation loss:		0.470431
  validation accuracy:		92.72 %
Epoch 1664 of 2000 took 0.074s
  training loss:		0.004978
  validation loss:		0.465471
  validation accuracy:		92.72 %
Epoch 1665 of 2000 took 0.076s
  training loss:		0.004929
  validation loss:		0.469650
  validation accuracy:		92.83 %
Epoch 1666 of 2000 took 0.076s
  training loss:		0.005047
  validation loss:		0.464872
  validation accuracy:		92.83 %
Epoch 1667 of 2000 took 0.075s
  training loss:		0.005239
  validation loss:		0.461465
  validation accuracy:		92.83 %
Epoch 1668 of 2000 took 0.076s
  training loss:		0.004974
  validation loss:		0.466770
  validation accuracy:		92.72 %
Epoch 1669 of 2000 took 0.076s
  training loss:		0.004872
  validation loss:		0.471398
  validation accuracy:		92.83 %
Epoch 1670 of 2000 took 0.075s
  training loss:		0.005191
  validation loss:		0.469093
  validation accuracy:		92.72 %
Epoch 1671 of 2000 took 0.078s
  training loss:		0.005002
  validation loss:		0.466542
  validation accuracy:		92.83 %
Epoch 1672 of 2000 took 0.075s
  training loss:		0.005034
  validation loss:		0.465510
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.075s
  training loss:		0.004919
  validation loss:		0.472109
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.077s
  training loss:		0.005049
  validation loss:		0.473121
  validation accuracy:		92.83 %
Epoch 1675 of 2000 took 0.075s
  training loss:		0.004951
  validation loss:		0.464137
  validation accuracy:		92.83 %
Epoch 1676 of 2000 took 0.076s
  training loss:		0.004993
  validation loss:		0.465656
  validation accuracy:		92.72 %
Epoch 1677 of 2000 took 0.079s
  training loss:		0.005090
  validation loss:		0.462035
  validation accuracy:		92.93 %
Epoch 1678 of 2000 took 0.075s
  training loss:		0.004841
  validation loss:		0.468062
  validation accuracy:		92.83 %
Epoch 1679 of 2000 took 0.075s
  training loss:		0.004963
  validation loss:		0.470705
  validation accuracy:		92.61 %
Epoch 1680 of 2000 took 0.076s
  training loss:		0.004918
  validation loss:		0.466694
  validation accuracy:		92.83 %
Epoch 1681 of 2000 took 0.075s
  training loss:		0.004998
  validation loss:		0.466223
  validation accuracy:		92.83 %
Epoch 1682 of 2000 took 0.075s
  training loss:		0.004903
  validation loss:		0.469358
  validation accuracy:		92.83 %
Epoch 1683 of 2000 took 0.075s
  training loss:		0.004929
  validation loss:		0.471977
  validation accuracy:		92.93 %
Epoch 1684 of 2000 took 0.076s
  training loss:		0.004785
  validation loss:		0.460249
  validation accuracy:		92.93 %
Epoch 1685 of 2000 took 0.074s
  training loss:		0.004873
  validation loss:		0.470501
  validation accuracy:		92.72 %
Epoch 1686 of 2000 took 0.078s
  training loss:		0.004838
  validation loss:		0.469959
  validation accuracy:		92.61 %
Epoch 1687 of 2000 took 0.076s
  training loss:		0.005010
  validation loss:		0.465687
  validation accuracy:		92.83 %
Epoch 1688 of 2000 took 0.075s
  training loss:		0.004829
  validation loss:		0.478330
  validation accuracy:		92.83 %
Epoch 1689 of 2000 took 0.075s
  training loss:		0.004735
  validation loss:		0.465092
  validation accuracy:		92.83 %
Epoch 1690 of 2000 took 0.077s
  training loss:		0.005059
  validation loss:		0.476050
  validation accuracy:		92.61 %
Epoch 1691 of 2000 took 0.076s
  training loss:		0.005001
  validation loss:		0.463527
  validation accuracy:		92.61 %
Epoch 1692 of 2000 took 0.076s
  training loss:		0.004965
  validation loss:		0.474576
  validation accuracy:		92.83 %
Epoch 1693 of 2000 took 0.075s
  training loss:		0.004802
  validation loss:		0.471015
  validation accuracy:		92.83 %
Epoch 1694 of 2000 took 0.073s
  training loss:		0.004868
  validation loss:		0.471851
  validation accuracy:		92.83 %
Epoch 1695 of 2000 took 0.077s
  training loss:		0.004787
  validation loss:		0.471551
  validation accuracy:		92.83 %
Epoch 1696 of 2000 took 0.076s
  training loss:		0.004972
  validation loss:		0.468864
  validation accuracy:		92.83 %
Epoch 1697 of 2000 took 0.075s
  training loss:		0.004866
  validation loss:		0.480737
  validation accuracy:		92.72 %
Epoch 1698 of 2000 took 0.076s
  training loss:		0.004665
  validation loss:		0.474260
  validation accuracy:		92.61 %
Epoch 1699 of 2000 took 0.077s
  training loss:		0.004903
  validation loss:		0.473928
  validation accuracy:		92.72 %
Epoch 1700 of 2000 took 0.077s
  training loss:		0.004794
  validation loss:		0.472563
  validation accuracy:		92.83 %
Epoch 1701 of 2000 took 0.078s
  training loss:		0.004760
  validation loss:		0.471896
  validation accuracy:		92.72 %
Epoch 1702 of 2000 took 0.077s
  training loss:		0.004827
  validation loss:		0.475752
  validation accuracy:		92.72 %
Epoch 1703 of 2000 took 0.075s
  training loss:		0.004733
  validation loss:		0.474179
  validation accuracy:		92.83 %
Epoch 1704 of 2000 took 0.075s
  training loss:		0.004822
  validation loss:		0.479215
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.075s
  training loss:		0.004801
  validation loss:		0.473054
  validation accuracy:		92.83 %
Epoch 1706 of 2000 took 0.075s
  training loss:		0.004774
  validation loss:		0.472073
  validation accuracy:		92.72 %
Epoch 1707 of 2000 took 0.074s
  training loss:		0.004799
  validation loss:		0.474014
  validation accuracy:		92.72 %
Epoch 1708 of 2000 took 0.078s
  training loss:		0.004884
  validation loss:		0.473049
  validation accuracy:		92.72 %
Epoch 1709 of 2000 took 0.077s
  training loss:		0.004781
  validation loss:		0.477486
  validation accuracy:		92.83 %
Epoch 1710 of 2000 took 0.076s
  training loss:		0.004817
  validation loss:		0.468923
  validation accuracy:		92.61 %
Epoch 1711 of 2000 took 0.076s
  training loss:		0.004618
  validation loss:		0.473569
  validation accuracy:		92.83 %
Epoch 1712 of 2000 took 0.075s
  training loss:		0.004840
  validation loss:		0.472295
  validation accuracy:		92.83 %
Epoch 1713 of 2000 took 0.076s
  training loss:		0.004741
  validation loss:		0.472145
  validation accuracy:		92.83 %
Epoch 1714 of 2000 took 0.077s
  training loss:		0.004698
  validation loss:		0.474621
  validation accuracy:		92.72 %
Epoch 1715 of 2000 took 0.078s
  training loss:		0.004768
  validation loss:		0.481705
  validation accuracy:		92.61 %
Epoch 1716 of 2000 took 0.073s
  training loss:		0.004763
  validation loss:		0.473969
  validation accuracy:		92.72 %
Epoch 1717 of 2000 took 0.074s
  training loss:		0.004698
  validation loss:		0.476523
  validation accuracy:		92.72 %
Epoch 1718 of 2000 took 0.078s
  training loss:		0.004546
  validation loss:		0.477587
  validation accuracy:		92.83 %
Epoch 1719 of 2000 took 0.073s
  training loss:		0.004688
  validation loss:		0.475517
  validation accuracy:		92.83 %
Epoch 1720 of 2000 took 0.076s
  training loss:		0.004661
  validation loss:		0.473563
  validation accuracy:		92.61 %
Epoch 1721 of 2000 took 0.074s
  training loss:		0.004533
  validation loss:		0.476543
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.074s
  training loss:		0.004512
  validation loss:		0.473628
  validation accuracy:		92.72 %
Epoch 1723 of 2000 took 0.079s
  training loss:		0.004648
  validation loss:		0.475771
  validation accuracy:		92.83 %
Epoch 1724 of 2000 took 0.078s
  training loss:		0.004564
  validation loss:		0.473967
  validation accuracy:		92.83 %
Epoch 1725 of 2000 took 0.074s
  training loss:		0.004733
  validation loss:		0.477717
  validation accuracy:		92.72 %
Epoch 1726 of 2000 took 0.074s
  training loss:		0.004647
  validation loss:		0.476625
  validation accuracy:		92.83 %
Epoch 1727 of 2000 took 0.075s
  training loss:		0.004666
  validation loss:		0.478430
  validation accuracy:		92.72 %
Epoch 1728 of 2000 took 0.076s
  training loss:		0.004623
  validation loss:		0.478669
  validation accuracy:		92.72 %
Epoch 1729 of 2000 took 0.074s
  training loss:		0.004651
  validation loss:		0.477590
  validation accuracy:		92.72 %
Epoch 1730 of 2000 took 0.075s
  training loss:		0.004616
  validation loss:		0.475233
  validation accuracy:		92.83 %
Epoch 1731 of 2000 took 0.076s
  training loss:		0.004653
  validation loss:		0.479811
  validation accuracy:		92.83 %
Epoch 1732 of 2000 took 0.077s
  training loss:		0.004494
  validation loss:		0.476453
  validation accuracy:		92.83 %
Epoch 1733 of 2000 took 0.075s
  training loss:		0.004440
  validation loss:		0.481217
  validation accuracy:		92.72 %
Epoch 1734 of 2000 took 0.075s
  training loss:		0.004421
  validation loss:		0.469393
  validation accuracy:		92.83 %
Epoch 1735 of 2000 took 0.076s
  training loss:		0.004501
  validation loss:		0.484279
  validation accuracy:		92.72 %
Epoch 1736 of 2000 took 0.075s
  training loss:		0.004464
  validation loss:		0.478101
  validation accuracy:		92.83 %
Epoch 1737 of 2000 took 0.075s
  training loss:		0.004419
  validation loss:		0.480273
  validation accuracy:		92.72 %
Epoch 1738 of 2000 took 0.075s
  training loss:		0.004471
  validation loss:		0.474474
  validation accuracy:		92.72 %
Epoch 1739 of 2000 took 0.075s
  training loss:		0.004406
  validation loss:		0.479956
  validation accuracy:		92.72 %
Epoch 1740 of 2000 took 0.076s
  training loss:		0.004597
  validation loss:		0.473330
  validation accuracy:		92.83 %
Epoch 1741 of 2000 took 0.076s
  training loss:		0.004420
  validation loss:		0.475546
  validation accuracy:		92.83 %
Epoch 1742 of 2000 took 0.075s
  training loss:		0.004470
  validation loss:		0.474502
  validation accuracy:		92.83 %
Epoch 1743 of 2000 took 0.074s
  training loss:		0.004510
  validation loss:		0.475366
  validation accuracy:		92.83 %
Epoch 1744 of 2000 took 0.074s
  training loss:		0.004533
  validation loss:		0.477344
  validation accuracy:		92.83 %
Epoch 1745 of 2000 took 0.074s
  training loss:		0.004460
  validation loss:		0.481593
  validation accuracy:		92.61 %
Epoch 1746 of 2000 took 0.075s
  training loss:		0.004528
  validation loss:		0.472122
  validation accuracy:		92.93 %
Epoch 1747 of 2000 took 0.076s
  training loss:		0.004555
  validation loss:		0.482277
  validation accuracy:		92.72 %
Epoch 1748 of 2000 took 0.076s
  training loss:		0.004489
  validation loss:		0.485917
  validation accuracy:		92.72 %
Epoch 1749 of 2000 took 0.074s
  training loss:		0.004510
  validation loss:		0.480868
  validation accuracy:		92.83 %
Epoch 1750 of 2000 took 0.075s
  training loss:		0.004573
  validation loss:		0.476619
  validation accuracy:		92.72 %
Epoch 1751 of 2000 took 0.075s
  training loss:		0.004490
  validation loss:		0.479519
  validation accuracy:		92.83 %
Epoch 1752 of 2000 took 0.075s
  training loss:		0.004460
  validation loss:		0.477276
  validation accuracy:		92.72 %
Epoch 1753 of 2000 took 0.078s
  training loss:		0.004545
  validation loss:		0.476797
  validation accuracy:		92.83 %
Epoch 1754 of 2000 took 0.076s
  training loss:		0.004555
  validation loss:		0.483010
  validation accuracy:		92.61 %
Epoch 1755 of 2000 took 0.075s
  training loss:		0.004432
  validation loss:		0.476199
  validation accuracy:		92.72 %
Epoch 1756 of 2000 took 0.077s
  training loss:		0.004513
  validation loss:		0.477947
  validation accuracy:		92.83 %
Epoch 1757 of 2000 took 0.074s
  training loss:		0.004374
  validation loss:		0.471454
  validation accuracy:		92.83 %
Epoch 1758 of 2000 took 0.076s
  training loss:		0.004409
  validation loss:		0.485502
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.076s
  training loss:		0.004450
  validation loss:		0.479272
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.078s
  training loss:		0.004521
  validation loss:		0.485253
  validation accuracy:		92.61 %
Epoch 1761 of 2000 took 0.075s
  training loss:		0.004443
  validation loss:		0.475455
  validation accuracy:		92.83 %
Epoch 1762 of 2000 took 0.076s
  training loss:		0.004353
  validation loss:		0.479402
  validation accuracy:		92.83 %
Epoch 1763 of 2000 took 0.075s
  training loss:		0.004443
  validation loss:		0.478631
  validation accuracy:		92.83 %
Epoch 1764 of 2000 took 0.072s
  training loss:		0.004330
  validation loss:		0.486226
  validation accuracy:		92.72 %
Epoch 1765 of 2000 took 0.076s
  training loss:		0.004527
  validation loss:		0.476915
  validation accuracy:		92.83 %
Epoch 1766 of 2000 took 0.078s
  training loss:		0.004563
  validation loss:		0.486933
  validation accuracy:		92.72 %
Epoch 1767 of 2000 took 0.077s
  training loss:		0.004416
  validation loss:		0.483740
  validation accuracy:		92.72 %
Epoch 1768 of 2000 took 0.077s
  training loss:		0.004300
  validation loss:		0.483423
  validation accuracy:		92.83 %
Epoch 1769 of 2000 took 0.076s
  training loss:		0.004349
  validation loss:		0.477420
  validation accuracy:		92.83 %
Epoch 1770 of 2000 took 0.078s
  training loss:		0.004297
  validation loss:		0.479396
  validation accuracy:		92.93 %
Epoch 1771 of 2000 took 0.074s
  training loss:		0.004311
  validation loss:		0.483988
  validation accuracy:		92.83 %
Epoch 1772 of 2000 took 0.074s
  training loss:		0.004367
  validation loss:		0.479676
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.075s
  training loss:		0.004339
  validation loss:		0.488705
  validation accuracy:		92.83 %
Epoch 1774 of 2000 took 0.075s
  training loss:		0.004489
  validation loss:		0.483268
  validation accuracy:		92.72 %
Epoch 1775 of 2000 took 0.077s
  training loss:		0.004279
  validation loss:		0.482646
  validation accuracy:		92.83 %
Epoch 1776 of 2000 took 0.074s
  training loss:		0.004344
  validation loss:		0.486032
  validation accuracy:		92.72 %
Epoch 1777 of 2000 took 0.074s
  training loss:		0.004300
  validation loss:		0.481044
  validation accuracy:		92.83 %
Epoch 1778 of 2000 took 0.075s
  training loss:		0.004332
  validation loss:		0.483069
  validation accuracy:		92.72 %
Epoch 1779 of 2000 took 0.076s
  training loss:		0.004340
  validation loss:		0.484047
  validation accuracy:		92.72 %
Epoch 1780 of 2000 took 0.078s
  training loss:		0.004383
  validation loss:		0.484055
  validation accuracy:		92.83 %
Epoch 1781 of 2000 took 0.079s
  training loss:		0.004410
  validation loss:		0.483087
  validation accuracy:		92.61 %
Epoch 1782 of 2000 took 0.077s
  training loss:		0.004272
  validation loss:		0.487380
  validation accuracy:		92.83 %
Epoch 1783 of 2000 took 0.075s
  training loss:		0.004166
  validation loss:		0.483483
  validation accuracy:		92.93 %
Epoch 1784 of 2000 took 0.074s
  training loss:		0.004217
  validation loss:		0.481880
  validation accuracy:		92.72 %
Epoch 1785 of 2000 took 0.074s
  training loss:		0.004104
  validation loss:		0.488395
  validation accuracy:		92.72 %
Epoch 1786 of 2000 took 0.074s
  training loss:		0.004298
  validation loss:		0.482112
  validation accuracy:		92.83 %
Epoch 1787 of 2000 took 0.077s
  training loss:		0.004387
  validation loss:		0.485542
  validation accuracy:		92.83 %
Epoch 1788 of 2000 took 0.076s
  training loss:		0.004343
  validation loss:		0.484495
  validation accuracy:		92.83 %
Epoch 1789 of 2000 took 0.075s
  training loss:		0.004288
  validation loss:		0.481377
  validation accuracy:		92.83 %
Epoch 1790 of 2000 took 0.075s
  training loss:		0.004226
  validation loss:		0.489103
  validation accuracy:		92.50 %
Epoch 1791 of 2000 took 0.074s
  training loss:		0.004259
  validation loss:		0.491390
  validation accuracy:		92.61 %
Epoch 1792 of 2000 took 0.077s
  training loss:		0.004120
  validation loss:		0.483453
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.077s
  training loss:		0.004209
  validation loss:		0.488850
  validation accuracy:		92.83 %
Epoch 1794 of 2000 took 0.077s
  training loss:		0.004185
  validation loss:		0.486878
  validation accuracy:		92.83 %
Epoch 1795 of 2000 took 0.075s
  training loss:		0.004158
  validation loss:		0.486305
  validation accuracy:		92.72 %
Epoch 1796 of 2000 took 0.077s
  training loss:		0.004196
  validation loss:		0.488727
  validation accuracy:		92.72 %
Epoch 1797 of 2000 took 0.075s
  training loss:		0.004199
  validation loss:		0.490073
  validation accuracy:		92.61 %
Epoch 1798 of 2000 took 0.078s
  training loss:		0.004027
  validation loss:		0.485780
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.076s
  training loss:		0.004176
  validation loss:		0.486464
  validation accuracy:		92.83 %
Epoch 1800 of 2000 took 0.077s
  training loss:		0.004158
  validation loss:		0.487146
  validation accuracy:		92.83 %
Epoch 1801 of 2000 took 0.076s
  training loss:		0.004199
  validation loss:		0.485169
  validation accuracy:		92.61 %
Epoch 1802 of 2000 took 0.077s
  training loss:		0.004252
  validation loss:		0.486169
  validation accuracy:		92.93 %
Epoch 1803 of 2000 took 0.075s
  training loss:		0.004082
  validation loss:		0.487548
  validation accuracy:		92.72 %
Epoch 1804 of 2000 took 0.076s
  training loss:		0.004093
  validation loss:		0.487768
  validation accuracy:		92.61 %
Epoch 1805 of 2000 took 0.077s
  training loss:		0.004122
  validation loss:		0.486468
  validation accuracy:		92.83 %
Epoch 1806 of 2000 took 0.078s
  training loss:		0.004210
  validation loss:		0.486746
  validation accuracy:		92.61 %
Epoch 1807 of 2000 took 0.074s
  training loss:		0.004298
  validation loss:		0.487329
  validation accuracy:		92.83 %
Epoch 1808 of 2000 took 0.077s
  training loss:		0.004186
  validation loss:		0.482338
  validation accuracy:		92.83 %
Epoch 1809 of 2000 took 0.074s
  training loss:		0.004154
  validation loss:		0.492663
  validation accuracy:		92.72 %
Epoch 1810 of 2000 took 0.075s
  training loss:		0.004017
  validation loss:		0.489115
  validation accuracy:		92.61 %
Epoch 1811 of 2000 took 0.076s
  training loss:		0.004121
  validation loss:		0.489293
  validation accuracy:		92.72 %
Epoch 1812 of 2000 took 0.073s
  training loss:		0.004168
  validation loss:		0.487858
  validation accuracy:		92.83 %
Epoch 1813 of 2000 took 0.077s
  training loss:		0.004231
  validation loss:		0.484450
  validation accuracy:		92.93 %
Epoch 1814 of 2000 took 0.073s
  training loss:		0.004034
  validation loss:		0.483891
  validation accuracy:		92.61 %
Epoch 1815 of 2000 took 0.073s
  training loss:		0.004084
  validation loss:		0.494035
  validation accuracy:		92.83 %
Epoch 1816 of 2000 took 0.078s
  training loss:		0.004106
  validation loss:		0.492234
  validation accuracy:		92.50 %
Epoch 1817 of 2000 took 0.074s
  training loss:		0.004153
  validation loss:		0.482343
  validation accuracy:		92.72 %
Epoch 1818 of 2000 took 0.073s
  training loss:		0.004222
  validation loss:		0.489355
  validation accuracy:		92.83 %
Epoch 1819 of 2000 took 0.076s
  training loss:		0.004098
  validation loss:		0.492351
  validation accuracy:		92.50 %
Epoch 1820 of 2000 took 0.077s
  training loss:		0.004147
  validation loss:		0.486765
  validation accuracy:		92.50 %
Epoch 1821 of 2000 took 0.077s
  training loss:		0.004160
  validation loss:		0.492445
  validation accuracy:		92.72 %
Epoch 1822 of 2000 took 0.075s
  training loss:		0.004091
  validation loss:		0.489672
  validation accuracy:		92.72 %
Epoch 1823 of 2000 took 0.075s
  training loss:		0.004137
  validation loss:		0.498814
  validation accuracy:		92.61 %
Epoch 1824 of 2000 took 0.077s
  training loss:		0.004140
  validation loss:		0.484639
  validation accuracy:		92.61 %
Epoch 1825 of 2000 took 0.077s
  training loss:		0.004092
  validation loss:		0.489570
  validation accuracy:		92.50 %
Epoch 1826 of 2000 took 0.075s
  training loss:		0.004010
  validation loss:		0.489367
  validation accuracy:		92.83 %
Epoch 1827 of 2000 took 0.075s
  training loss:		0.004118
  validation loss:		0.485549
  validation accuracy:		92.72 %
Epoch 1828 of 2000 took 0.077s
  training loss:		0.004026
  validation loss:		0.494279
  validation accuracy:		92.93 %
Epoch 1829 of 2000 took 0.077s
  training loss:		0.003948
  validation loss:		0.495121
  validation accuracy:		92.83 %
Epoch 1830 of 2000 took 0.076s
  training loss:		0.004188
  validation loss:		0.490729
  validation accuracy:		92.93 %
Epoch 1831 of 2000 took 0.076s
  training loss:		0.004029
  validation loss:		0.489613
  validation accuracy:		92.83 %
Epoch 1832 of 2000 took 0.076s
  training loss:		0.004031
  validation loss:		0.491851
  validation accuracy:		92.72 %
Epoch 1833 of 2000 took 0.078s
  training loss:		0.003976
  validation loss:		0.493614
  validation accuracy:		92.61 %
Epoch 1834 of 2000 took 0.076s
  training loss:		0.003990
  validation loss:		0.495401
  validation accuracy:		92.72 %
Epoch 1835 of 2000 took 0.077s
  training loss:		0.003979
  validation loss:		0.490601
  validation accuracy:		92.93 %
Epoch 1836 of 2000 took 0.076s
  training loss:		0.004221
  validation loss:		0.489508
  validation accuracy:		92.83 %
Epoch 1837 of 2000 took 0.076s
  training loss:		0.003899
  validation loss:		0.490015
  validation accuracy:		92.83 %
Epoch 1838 of 2000 took 0.075s
  training loss:		0.004011
  validation loss:		0.490477
  validation accuracy:		92.61 %
Epoch 1839 of 2000 took 0.078s
  training loss:		0.004077
  validation loss:		0.488775
  validation accuracy:		92.72 %
Epoch 1840 of 2000 took 0.073s
  training loss:		0.004057
  validation loss:		0.493676
  validation accuracy:		92.61 %
Epoch 1841 of 2000 took 0.077s
  training loss:		0.003984
  validation loss:		0.491577
  validation accuracy:		92.83 %
Epoch 1842 of 2000 took 0.075s
  training loss:		0.003795
  validation loss:		0.493344
  validation accuracy:		92.61 %
Epoch 1843 of 2000 took 0.076s
  training loss:		0.003954
  validation loss:		0.491723
  validation accuracy:		92.61 %
Epoch 1844 of 2000 took 0.075s
  training loss:		0.003962
  validation loss:		0.497838
  validation accuracy:		92.61 %
Epoch 1845 of 2000 took 0.074s
  training loss:		0.003921
  validation loss:		0.493743
  validation accuracy:		92.83 %
Epoch 1846 of 2000 took 0.076s
  training loss:		0.004079
  validation loss:		0.495239
  validation accuracy:		92.72 %
Epoch 1847 of 2000 took 0.077s
  training loss:		0.004121
  validation loss:		0.492046
  validation accuracy:		92.72 %
Epoch 1848 of 2000 took 0.076s
  training loss:		0.004010
  validation loss:		0.493729
  validation accuracy:		92.72 %
Epoch 1849 of 2000 took 0.078s
  training loss:		0.003912
  validation loss:		0.491059
  validation accuracy:		92.72 %
Epoch 1850 of 2000 took 0.076s
  training loss:		0.003927
  validation loss:		0.491808
  validation accuracy:		92.61 %
Epoch 1851 of 2000 took 0.077s
  training loss:		0.003865
  validation loss:		0.493273
  validation accuracy:		92.72 %
Epoch 1852 of 2000 took 0.076s
  training loss:		0.004007
  validation loss:		0.493288
  validation accuracy:		92.72 %
Epoch 1853 of 2000 took 0.075s
  training loss:		0.003950
  validation loss:		0.494313
  validation accuracy:		92.61 %
Epoch 1854 of 2000 took 0.077s
  training loss:		0.003817
  validation loss:		0.490685
  validation accuracy:		92.50 %
Epoch 1855 of 2000 took 0.074s
  training loss:		0.003954
  validation loss:		0.497713
  validation accuracy:		92.61 %
Epoch 1856 of 2000 took 0.059s
  training loss:		0.003769
  validation loss:		0.492491
  validation accuracy:		92.72 %
Epoch 1857 of 2000 took 0.057s
  training loss:		0.003931
  validation loss:		0.499250
  validation accuracy:		92.61 %
Epoch 1858 of 2000 took 0.160s
  training loss:		0.003937
  validation loss:		0.490126
  validation accuracy:		92.72 %
Epoch 1859 of 2000 took 0.077s
  training loss:		0.003816
  validation loss:		0.496906
  validation accuracy:		92.72 %
Epoch 1860 of 2000 took 0.066s
  training loss:		0.003830
  validation loss:		0.491459
  validation accuracy:		92.72 %
Epoch 1861 of 2000 took 0.071s
  training loss:		0.003822
  validation loss:		0.490632
  validation accuracy:		92.72 %
Epoch 1862 of 2000 took 0.070s
  training loss:		0.003734
  validation loss:		0.496539
  validation accuracy:		92.72 %
Epoch 1863 of 2000 took 0.065s
  training loss:		0.003848
  validation loss:		0.495189
  validation accuracy:		92.61 %
Epoch 1864 of 2000 took 0.091s
  training loss:		0.003827
  validation loss:		0.494531
  validation accuracy:		92.83 %
Epoch 1865 of 2000 took 0.075s
  training loss:		0.003819
  validation loss:		0.496768
  validation accuracy:		92.72 %
Epoch 1866 of 2000 took 0.063s
  training loss:		0.003825
  validation loss:		0.491873
  validation accuracy:		92.83 %
Epoch 1867 of 2000 took 0.062s
  training loss:		0.003838
  validation loss:		0.495379
  validation accuracy:		92.61 %
Epoch 1868 of 2000 took 0.062s
  training loss:		0.003866
  validation loss:		0.496831
  validation accuracy:		92.61 %
Epoch 1869 of 2000 took 0.061s
  training loss:		0.003816
  validation loss:		0.492717
  validation accuracy:		92.72 %
Epoch 1870 of 2000 took 0.063s
  training loss:		0.003755
  validation loss:		0.502268
  validation accuracy:		92.50 %
Epoch 1871 of 2000 took 0.063s
  training loss:		0.003885
  validation loss:		0.492610
  validation accuracy:		92.83 %
Epoch 1872 of 2000 took 0.066s
  training loss:		0.003800
  validation loss:		0.499364
  validation accuracy:		92.72 %
Epoch 1873 of 2000 took 0.065s
  training loss:		0.003762
  validation loss:		0.491216
  validation accuracy:		92.72 %
Epoch 1874 of 2000 took 0.064s
  training loss:		0.003935
  validation loss:		0.498068
  validation accuracy:		92.61 %
Epoch 1875 of 2000 took 0.066s
  training loss:		0.003692
  validation loss:		0.496608
  validation accuracy:		92.72 %
Epoch 1876 of 2000 took 0.066s
  training loss:		0.003741
  validation loss:		0.496338
  validation accuracy:		92.72 %
Epoch 1877 of 2000 took 0.064s
  training loss:		0.003765
  validation loss:		0.494876
  validation accuracy:		92.72 %
Epoch 1878 of 2000 took 0.060s
  training loss:		0.003716
  validation loss:		0.498444
  validation accuracy:		92.72 %
Epoch 1879 of 2000 took 0.059s
  training loss:		0.003785
  validation loss:		0.498235
  validation accuracy:		92.72 %
Epoch 1880 of 2000 took 0.058s
  training loss:		0.003760
  validation loss:		0.494690
  validation accuracy:		92.93 %
Epoch 1881 of 2000 took 0.058s
  training loss:		0.003744
  validation loss:		0.499823
  validation accuracy:		92.50 %
Epoch 1882 of 2000 took 0.075s
  training loss:		0.003825
  validation loss:		0.495617
  validation accuracy:		92.61 %
Epoch 1883 of 2000 took 0.195s
  training loss:		0.003768
  validation loss:		0.502212
  validation accuracy:		92.61 %
Epoch 1884 of 2000 took 0.061s
  training loss:		0.003771
  validation loss:		0.494118
  validation accuracy:		92.83 %
Epoch 1885 of 2000 took 0.060s
  training loss:		0.003807
  validation loss:		0.498946
  validation accuracy:		92.72 %
Epoch 1886 of 2000 took 0.061s
  training loss:		0.003703
  validation loss:		0.500787
  validation accuracy:		92.72 %
Epoch 1887 of 2000 took 0.060s
  training loss:		0.003857
  validation loss:		0.496541
  validation accuracy:		92.72 %
Epoch 1888 of 2000 took 0.059s
  training loss:		0.003771
  validation loss:		0.499859
  validation accuracy:		92.61 %
Epoch 1889 of 2000 took 0.059s
  training loss:		0.003710
  validation loss:		0.501890
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.060s
  training loss:		0.003671
  validation loss:		0.496489
  validation accuracy:		92.61 %
Epoch 1891 of 2000 took 0.060s
  training loss:		0.003677
  validation loss:		0.501521
  validation accuracy:		92.72 %
Epoch 1892 of 2000 took 0.062s
  training loss:		0.003712
  validation loss:		0.500643
  validation accuracy:		92.61 %
Epoch 1893 of 2000 took 0.060s
  training loss:		0.003698
  validation loss:		0.503824
  validation accuracy:		92.50 %
Epoch 1894 of 2000 took 0.061s
  training loss:		0.003650
  validation loss:		0.499035
  validation accuracy:		92.83 %
Epoch 1895 of 2000 took 0.059s
  training loss:		0.003852
  validation loss:		0.494588
  validation accuracy:		92.61 %
Epoch 1896 of 2000 took 0.059s
  training loss:		0.003750
  validation loss:		0.503924
  validation accuracy:		92.50 %
Epoch 1897 of 2000 took 0.059s
  training loss:		0.003633
  validation loss:		0.497803
  validation accuracy:		92.72 %
Epoch 1898 of 2000 took 0.058s
  training loss:		0.003600
  validation loss:		0.501298
  validation accuracy:		92.61 %
Epoch 1899 of 2000 took 0.059s
  training loss:		0.003725
  validation loss:		0.503369
  validation accuracy:		92.39 %
Epoch 1900 of 2000 took 0.059s
  training loss:		0.003665
  validation loss:		0.501427
  validation accuracy:		92.50 %
Epoch 1901 of 2000 took 0.059s
  training loss:		0.003649
  validation loss:		0.499113
  validation accuracy:		92.83 %
Epoch 1902 of 2000 took 0.059s
  training loss:		0.003440
  validation loss:		0.500345
  validation accuracy:		92.72 %
Epoch 1903 of 2000 took 0.058s
  training loss:		0.003807
  validation loss:		0.501920
  validation accuracy:		92.50 %
Epoch 1904 of 2000 took 0.058s
  training loss:		0.003690
  validation loss:		0.499357
  validation accuracy:		92.50 %
Epoch 1905 of 2000 took 0.058s
  training loss:		0.003609
  validation loss:		0.503611
  validation accuracy:		92.61 %
Epoch 1906 of 2000 took 0.059s
  training loss:		0.003669
  validation loss:		0.496281
  validation accuracy:		92.72 %
Epoch 1907 of 2000 took 0.059s
  training loss:		0.003571
  validation loss:		0.501197
  validation accuracy:		92.61 %
Epoch 1908 of 2000 took 0.059s
  training loss:		0.003570
  validation loss:		0.501323
  validation accuracy:		92.61 %
Epoch 1909 of 2000 took 0.058s
  training loss:		0.003709
  validation loss:		0.501677
  validation accuracy:		92.93 %
Epoch 1910 of 2000 took 0.059s
  training loss:		0.003731
  validation loss:		0.495106
  validation accuracy:		92.83 %
Epoch 1911 of 2000 took 0.059s
  training loss:		0.003651
  validation loss:		0.507106
  validation accuracy:		92.61 %
Epoch 1912 of 2000 took 0.059s
  training loss:		0.003623
  validation loss:		0.503332
  validation accuracy:		92.83 %
Epoch 1913 of 2000 took 0.058s
  training loss:		0.003628
  validation loss:		0.504241
  validation accuracy:		92.61 %
Epoch 1914 of 2000 took 0.058s
  training loss:		0.003727
  validation loss:		0.507082
  validation accuracy:		92.50 %
Epoch 1915 of 2000 took 0.060s
  training loss:		0.003675
  validation loss:		0.504799
  validation accuracy:		92.61 %
Epoch 1916 of 2000 took 0.059s
  training loss:		0.003700
  validation loss:		0.502753
  validation accuracy:		92.83 %
Epoch 1917 of 2000 took 0.058s
  training loss:		0.003735
  validation loss:		0.507309
  validation accuracy:		92.50 %
Epoch 1918 of 2000 took 0.059s
  training loss:		0.003662
  validation loss:		0.503990
  validation accuracy:		92.50 %
Epoch 1919 of 2000 took 0.059s
  training loss:		0.003443
  validation loss:		0.503588
  validation accuracy:		92.83 %
Epoch 1920 of 2000 took 0.059s
  training loss:		0.003521
  validation loss:		0.502942
  validation accuracy:		92.72 %
Epoch 1921 of 2000 took 0.059s
  training loss:		0.003622
  validation loss:		0.506790
  validation accuracy:		92.50 %
Epoch 1922 of 2000 took 0.059s
  training loss:		0.003508
  validation loss:		0.498354
  validation accuracy:		92.61 %
Epoch 1923 of 2000 took 0.058s
  training loss:		0.003592
  validation loss:		0.499619
  validation accuracy:		92.39 %
Epoch 1924 of 2000 took 0.059s
  training loss:		0.003588
  validation loss:		0.504715
  validation accuracy:		92.61 %
Epoch 1925 of 2000 took 0.059s
  training loss:		0.003564
  validation loss:		0.510467
  validation accuracy:		92.61 %
Epoch 1926 of 2000 took 0.059s
  training loss:		0.003546
  validation loss:		0.499105
  validation accuracy:		92.72 %
Epoch 1927 of 2000 took 0.058s
  training loss:		0.003532
  validation loss:		0.506597
  validation accuracy:		92.39 %
Epoch 1928 of 2000 took 0.059s
  training loss:		0.003617
  validation loss:		0.501829
  validation accuracy:		92.50 %
Epoch 1929 of 2000 took 0.059s
  training loss:		0.003558
  validation loss:		0.503161
  validation accuracy:		92.61 %
Epoch 1930 of 2000 took 0.060s
  training loss:		0.003533
  validation loss:		0.506257
  validation accuracy:		92.61 %
Epoch 1931 of 2000 took 0.058s
  training loss:		0.003682
  validation loss:		0.502601
  validation accuracy:		92.50 %
Epoch 1932 of 2000 took 0.059s
  training loss:		0.003537
  validation loss:		0.502859
  validation accuracy:		92.50 %
Epoch 1933 of 2000 took 0.059s
  training loss:		0.003555
  validation loss:		0.506885
  validation accuracy:		92.61 %
Epoch 1934 of 2000 took 0.059s
  training loss:		0.003524
  validation loss:		0.501704
  validation accuracy:		92.61 %
Epoch 1935 of 2000 took 0.058s
  training loss:		0.003562
  validation loss:		0.502763
  validation accuracy:		92.61 %
Epoch 1936 of 2000 took 0.058s
  training loss:		0.003487
  validation loss:		0.510581
  validation accuracy:		92.50 %
Epoch 1937 of 2000 took 0.058s
  training loss:		0.003601
  validation loss:		0.508572
  validation accuracy:		92.72 %
Epoch 1938 of 2000 took 0.058s
  training loss:		0.003413
  validation loss:		0.502013
  validation accuracy:		92.72 %
Epoch 1939 of 2000 took 0.058s
  training loss:		0.003579
  validation loss:		0.505393
  validation accuracy:		92.61 %
Epoch 1940 of 2000 took 0.058s
  training loss:		0.003581
  validation loss:		0.504088
  validation accuracy:		92.61 %
Epoch 1941 of 2000 took 0.059s
  training loss:		0.003546
  validation loss:		0.507257
  validation accuracy:		92.50 %
Epoch 1942 of 2000 took 0.059s
  training loss:		0.003502
  validation loss:		0.502479
  validation accuracy:		92.61 %
Epoch 1943 of 2000 took 0.060s
  training loss:		0.003605
  validation loss:		0.505772
  validation accuracy:		92.61 %
Epoch 1944 of 2000 took 0.059s
  training loss:		0.003354
  validation loss:		0.509283
  validation accuracy:		92.61 %
Epoch 1945 of 2000 took 0.060s
  training loss:		0.003490
  validation loss:		0.512197
  validation accuracy:		92.50 %
Epoch 1946 of 2000 took 0.060s
  training loss:		0.003443
  validation loss:		0.508380
  validation accuracy:		92.39 %
Epoch 1947 of 2000 took 0.059s
  training loss:		0.003478
  validation loss:		0.504938
  validation accuracy:		92.72 %
Epoch 1948 of 2000 took 0.059s
  training loss:		0.003601
  validation loss:		0.506169
  validation accuracy:		92.50 %
Epoch 1949 of 2000 took 0.058s
  training loss:		0.003403
  validation loss:		0.504128
  validation accuracy:		92.61 %
Epoch 1950 of 2000 took 0.059s
  training loss:		0.003542
  validation loss:		0.506587
  validation accuracy:		92.50 %
Epoch 1951 of 2000 took 0.059s
  training loss:		0.003548
  validation loss:		0.504505
  validation accuracy:		92.61 %
Epoch 1952 of 2000 took 0.059s
  training loss:		0.003472
  validation loss:		0.507018
  validation accuracy:		92.50 %
Epoch 1953 of 2000 took 0.059s
  training loss:		0.003460
  validation loss:		0.506988
  validation accuracy:		92.61 %
Epoch 1954 of 2000 took 0.059s
  training loss:		0.003286
  validation loss:		0.503664
  validation accuracy:		92.50 %
Epoch 1955 of 2000 took 0.060s
  training loss:		0.003468
  validation loss:		0.505740
  validation accuracy:		92.61 %
Epoch 1956 of 2000 took 0.060s
  training loss:		0.003522
  validation loss:		0.506277
  validation accuracy:		92.72 %
Epoch 1957 of 2000 took 0.062s
  training loss:		0.003533
  validation loss:		0.501259
  validation accuracy:		92.61 %
Epoch 1958 of 2000 took 0.061s
  training loss:		0.003251
  validation loss:		0.514780
  validation accuracy:		92.61 %
Epoch 1959 of 2000 took 0.061s
  training loss:		0.003427
  validation loss:		0.505459
  validation accuracy:		92.72 %
Epoch 1960 of 2000 took 0.059s
  training loss:		0.003445
  validation loss:		0.510328
  validation accuracy:		92.50 %
Epoch 1961 of 2000 took 0.059s
  training loss:		0.003325
  validation loss:		0.507937
  validation accuracy:		92.50 %
Epoch 1962 of 2000 took 0.059s
  training loss:		0.003380
  validation loss:		0.509068
  validation accuracy:		92.61 %
Epoch 1963 of 2000 took 0.060s
  training loss:		0.003330
  validation loss:		0.508455
  validation accuracy:		92.61 %
Epoch 1964 of 2000 took 0.058s
  training loss:		0.003464
  validation loss:		0.508621
  validation accuracy:		92.61 %
Epoch 1965 of 2000 took 0.058s
  training loss:		0.003402
  validation loss:		0.510831
  validation accuracy:		92.50 %
Epoch 1966 of 2000 took 0.058s
  training loss:		0.003492
  validation loss:		0.505603
  validation accuracy:		92.72 %
Epoch 1967 of 2000 took 0.059s
  training loss:		0.003328
  validation loss:		0.508086
  validation accuracy:		92.50 %
Epoch 1968 of 2000 took 0.058s
  training loss:		0.003371
  validation loss:		0.510831
  validation accuracy:		92.72 %
Epoch 1969 of 2000 took 0.058s
  training loss:		0.003479
  validation loss:		0.507325
  validation accuracy:		92.50 %
Epoch 1970 of 2000 took 0.058s
  training loss:		0.003353
  validation loss:		0.516935
  validation accuracy:		92.39 %
Epoch 1971 of 2000 took 0.059s
  training loss:		0.003490
  validation loss:		0.507358
  validation accuracy:		92.61 %
Epoch 1972 of 2000 took 0.059s
  training loss:		0.003344
  validation loss:		0.508138
  validation accuracy:		92.61 %
Epoch 1973 of 2000 took 0.059s
  training loss:		0.003469
  validation loss:		0.507307
  validation accuracy:		92.61 %
Epoch 1974 of 2000 took 0.061s
  training loss:		0.003459
  validation loss:		0.513193
  validation accuracy:		92.72 %
Epoch 1975 of 2000 took 0.061s
  training loss:		0.003472
  validation loss:		0.512643
  validation accuracy:		92.50 %
Epoch 1976 of 2000 took 0.059s
  training loss:		0.003423
  validation loss:		0.505293
  validation accuracy:		92.61 %
Epoch 1977 of 2000 took 0.056s
  training loss:		0.003366
  validation loss:		0.508256
  validation accuracy:		92.61 %
Epoch 1978 of 2000 took 0.057s
  training loss:		0.003221
  validation loss:		0.507301
  validation accuracy:		92.72 %
Epoch 1979 of 2000 took 0.056s
  training loss:		0.003314
  validation loss:		0.508576
  validation accuracy:		92.72 %
Epoch 1980 of 2000 took 0.058s
  training loss:		0.003280
  validation loss:		0.508435
  validation accuracy:		92.61 %
Epoch 1981 of 2000 took 0.058s
  training loss:		0.003261
  validation loss:		0.508402
  validation accuracy:		92.61 %
Epoch 1982 of 2000 took 0.059s
  training loss:		0.003364
  validation loss:		0.507973
  validation accuracy:		92.61 %
Epoch 1983 of 2000 took 0.059s
  training loss:		0.003351
  validation loss:		0.509294
  validation accuracy:		92.61 %
Epoch 1984 of 2000 took 0.059s
  training loss:		0.003365
  validation loss:		0.514569
  validation accuracy:		92.72 %
Epoch 1985 of 2000 took 0.058s
  training loss:		0.003376
  validation loss:		0.510178
  validation accuracy:		92.72 %
Epoch 1986 of 2000 took 0.059s
  training loss:		0.003316
  validation loss:		0.509541
  validation accuracy:		92.61 %
Epoch 1987 of 2000 took 0.058s
  training loss:		0.003378
  validation loss:		0.513807
  validation accuracy:		92.61 %
Epoch 1988 of 2000 took 0.058s
  training loss:		0.003374
  validation loss:		0.510984
  validation accuracy:		92.50 %
Epoch 1989 of 2000 took 0.059s
  training loss:		0.003361
  validation loss:		0.504183
  validation accuracy:		92.72 %
Epoch 1990 of 2000 took 0.059s
  training loss:		0.003286
  validation loss:		0.510803
  validation accuracy:		92.50 %
Epoch 1991 of 2000 took 0.058s
  training loss:		0.003348
  validation loss:		0.512285
  validation accuracy:		92.61 %
Epoch 1992 of 2000 took 0.059s
  training loss:		0.003354
  validation loss:		0.516451
  validation accuracy:		92.61 %
Epoch 1993 of 2000 took 0.058s
  training loss:		0.003421
  validation loss:		0.511923
  validation accuracy:		92.61 %
Epoch 1994 of 2000 took 0.059s
  training loss:		0.003356
  validation loss:		0.512237
  validation accuracy:		92.50 %
Epoch 1995 of 2000 took 0.059s
  training loss:		0.003246
  validation loss:		0.516668
  validation accuracy:		92.50 %
Epoch 1996 of 2000 took 0.058s
  training loss:		0.003108
  validation loss:		0.514106
  validation accuracy:		92.72 %
Epoch 1997 of 2000 took 0.059s
  training loss:		0.003369
  validation loss:		0.509986
  validation accuracy:		92.61 %
Epoch 1998 of 2000 took 0.059s
  training loss:		0.003360
  validation loss:		0.513789
  validation accuracy:		92.50 %
Epoch 1999 of 2000 took 0.058s
  training loss:		0.003304
  validation loss:		0.512267
  validation accuracy:		92.61 %
Epoch 2000 of 2000 took 0.058s
  training loss:		0.003354
  validation loss:		0.512314
  validation accuracy:		92.83 %
Final results:
  test loss:			1.221357
  test accuracy:		84.81 %
