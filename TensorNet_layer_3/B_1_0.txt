Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.066s
  training loss:		2.986763
  validation loss:		2.933039
  validation accuracy:		12.83 %
Epoch 2 of 2000 took 0.066s
  training loss:		2.888965
  validation loss:		2.806744
  validation accuracy:		21.85 %
Epoch 3 of 2000 took 0.075s
  training loss:		2.762801
  validation loss:		2.654197
  validation accuracy:		13.26 %
Epoch 4 of 2000 took 0.059s
  training loss:		2.613632
  validation loss:		2.473184
  validation accuracy:		24.46 %
Epoch 5 of 2000 took 0.086s
  training loss:		2.457946
  validation loss:		2.308637
  validation accuracy:		12.93 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.348449
  validation loss:		2.249691
  validation accuracy:		23.26 %
Epoch 7 of 2000 took 0.160s
  training loss:		2.304698
  validation loss:		2.246254
  validation accuracy:		38.15 %
Epoch 8 of 2000 took 0.151s
  training loss:		2.286944
  validation loss:		2.230253
  validation accuracy:		27.50 %
Epoch 9 of 2000 took 0.172s
  training loss:		2.279591
  validation loss:		2.220236
  validation accuracy:		31.09 %
Epoch 10 of 2000 took 0.104s
  training loss:		2.277829
  validation loss:		2.222858
  validation accuracy:		31.52 %
Epoch 11 of 2000 took 0.124s
  training loss:		2.270199
  validation loss:		2.210058
  validation accuracy:		14.46 %
Epoch 12 of 2000 took 0.135s
  training loss:		2.266270
  validation loss:		2.208912
  validation accuracy:		20.43 %
Epoch 13 of 2000 took 0.195s
  training loss:		2.261858
  validation loss:		2.203437
  validation accuracy:		48.70 %
Epoch 14 of 2000 took 0.246s
  training loss:		2.258204
  validation loss:		2.199623
  validation accuracy:		41.09 %
Epoch 15 of 2000 took 0.137s
  training loss:		2.253998
  validation loss:		2.197212
  validation accuracy:		45.33 %
Epoch 16 of 2000 took 0.125s
  training loss:		2.249256
  validation loss:		2.194153
  validation accuracy:		54.89 %
Epoch 17 of 2000 took 0.253s
  training loss:		2.246173
  validation loss:		2.186892
  validation accuracy:		20.98 %
Epoch 18 of 2000 took 0.191s
  training loss:		2.239793
  validation loss:		2.182105
  validation accuracy:		42.61 %
Epoch 19 of 2000 took 0.304s
  training loss:		2.235493
  validation loss:		2.170617
  validation accuracy:		39.02 %
Epoch 20 of 2000 took 0.146s
  training loss:		2.228245
  validation loss:		2.165058
  validation accuracy:		29.57 %
Epoch 21 of 2000 took 0.095s
  training loss:		2.221477
  validation loss:		2.160405
  validation accuracy:		41.41 %
Epoch 22 of 2000 took 0.091s
  training loss:		2.215410
  validation loss:		2.149489
  validation accuracy:		40.76 %
Epoch 23 of 2000 took 0.069s
  training loss:		2.206615
  validation loss:		2.148751
  validation accuracy:		63.26 %
Epoch 24 of 2000 took 0.071s
  training loss:		2.197734
  validation loss:		2.134321
  validation accuracy:		46.85 %
Epoch 25 of 2000 took 0.073s
  training loss:		2.188057
  validation loss:		2.115268
  validation accuracy:		48.91 %
Epoch 26 of 2000 took 0.071s
  training loss:		2.178640
  validation loss:		2.111588
  validation accuracy:		48.04 %
Epoch 27 of 2000 took 0.069s
  training loss:		2.166682
  validation loss:		2.106018
  validation accuracy:		56.74 %
Epoch 28 of 2000 took 0.110s
  training loss:		2.151653
  validation loss:		2.073196
  validation accuracy:		61.41 %
Epoch 29 of 2000 took 0.083s
  training loss:		2.135797
  validation loss:		2.068098
  validation accuracy:		53.37 %
Epoch 30 of 2000 took 0.084s
  training loss:		2.120021
  validation loss:		2.038092
  validation accuracy:		70.43 %
Epoch 31 of 2000 took 0.078s
  training loss:		2.101550
  validation loss:		2.024851
  validation accuracy:		64.46 %
Epoch 32 of 2000 took 0.081s
  training loss:		2.078253
  validation loss:		1.988440
  validation accuracy:		69.89 %
Epoch 33 of 2000 took 0.084s
  training loss:		2.049975
  validation loss:		1.961112
  validation accuracy:		67.17 %
Epoch 34 of 2000 took 0.083s
  training loss:		2.027338
  validation loss:		1.933031
  validation accuracy:		75.43 %
Epoch 35 of 2000 took 0.090s
  training loss:		1.989053
  validation loss:		1.893587
  validation accuracy:		69.13 %
Epoch 36 of 2000 took 0.106s
  training loss:		1.950050
  validation loss:		1.843871
  validation accuracy:		76.20 %
Epoch 37 of 2000 took 0.180s
  training loss:		1.910978
  validation loss:		1.801164
  validation accuracy:		77.07 %
Epoch 38 of 2000 took 0.152s
  training loss:		1.862138
  validation loss:		1.746796
  validation accuracy:		75.22 %
Epoch 39 of 2000 took 0.098s
  training loss:		1.809316
  validation loss:		1.686846
  validation accuracy:		81.30 %
Epoch 40 of 2000 took 0.092s
  training loss:		1.752946
  validation loss:		1.630419
  validation accuracy:		81.30 %
Epoch 41 of 2000 took 0.116s
  training loss:		1.701715
  validation loss:		1.569544
  validation accuracy:		85.00 %
Epoch 42 of 2000 took 0.127s
  training loss:		1.640708
  validation loss:		1.508020
  validation accuracy:		80.11 %
Epoch 43 of 2000 took 0.120s
  training loss:		1.582539
  validation loss:		1.443581
  validation accuracy:		86.20 %
Epoch 44 of 2000 took 0.102s
  training loss:		1.526867
  validation loss:		1.389694
  validation accuracy:		77.07 %
Epoch 45 of 2000 took 0.297s
  training loss:		1.471335
  validation loss:		1.336677
  validation accuracy:		85.00 %
Epoch 46 of 2000 took 0.169s
  training loss:		1.418915
  validation loss:		1.277607
  validation accuracy:		83.37 %
Epoch 47 of 2000 took 0.192s
  training loss:		1.370450
  validation loss:		1.223803
  validation accuracy:		85.11 %
Epoch 48 of 2000 took 0.070s
  training loss:		1.313965
  validation loss:		1.179127
  validation accuracy:		85.33 %
Epoch 49 of 2000 took 0.072s
  training loss:		1.261186
  validation loss:		1.123548
  validation accuracy:		86.74 %
Epoch 50 of 2000 took 0.069s
  training loss:		1.216397
  validation loss:		1.077552
  validation accuracy:		83.70 %
Epoch 51 of 2000 took 0.066s
  training loss:		1.177334
  validation loss:		1.034769
  validation accuracy:		85.76 %
Epoch 52 of 2000 took 0.057s
  training loss:		1.131448
  validation loss:		0.994949
  validation accuracy:		82.93 %
Epoch 53 of 2000 took 0.057s
  training loss:		1.092060
  validation loss:		0.957739
  validation accuracy:		84.57 %
Epoch 54 of 2000 took 0.063s
  training loss:		1.046460
  validation loss:		0.915402
  validation accuracy:		85.11 %
Epoch 55 of 2000 took 0.071s
  training loss:		1.014565
  validation loss:		0.884175
  validation accuracy:		86.63 %
Epoch 56 of 2000 took 0.103s
  training loss:		0.981074
  validation loss:		0.852564
  validation accuracy:		85.87 %
Epoch 57 of 2000 took 0.093s
  training loss:		0.947430
  validation loss:		0.817222
  validation accuracy:		85.54 %
Epoch 58 of 2000 took 0.065s
  training loss:		0.915530
  validation loss:		0.792416
  validation accuracy:		87.39 %
Epoch 59 of 2000 took 0.063s
  training loss:		0.888044
  validation loss:		0.757704
  validation accuracy:		86.63 %
Epoch 60 of 2000 took 0.065s
  training loss:		0.855664
  validation loss:		0.735449
  validation accuracy:		86.41 %
Epoch 61 of 2000 took 0.064s
  training loss:		0.829316
  validation loss:		0.707355
  validation accuracy:		86.52 %
Epoch 62 of 2000 took 0.083s
  training loss:		0.803471
  validation loss:		0.685598
  validation accuracy:		86.74 %
Epoch 63 of 2000 took 0.076s
  training loss:		0.784759
  validation loss:		0.669845
  validation accuracy:		87.07 %
Epoch 64 of 2000 took 0.059s
  training loss:		0.759448
  validation loss:		0.654377
  validation accuracy:		86.20 %
Epoch 65 of 2000 took 0.079s
  training loss:		0.729849
  validation loss:		0.625297
  validation accuracy:		87.50 %
Epoch 66 of 2000 took 0.073s
  training loss:		0.717174
  validation loss:		0.614640
  validation accuracy:		87.17 %
Epoch 67 of 2000 took 0.086s
  training loss:		0.692889
  validation loss:		0.603171
  validation accuracy:		87.39 %
Epoch 68 of 2000 took 0.103s
  training loss:		0.681096
  validation loss:		0.590912
  validation accuracy:		87.72 %
Epoch 69 of 2000 took 0.088s
  training loss:		0.661451
  validation loss:		0.570520
  validation accuracy:		88.15 %
Epoch 70 of 2000 took 0.091s
  training loss:		0.649316
  validation loss:		0.556822
  validation accuracy:		87.72 %
Epoch 71 of 2000 took 0.148s
  training loss:		0.631929
  validation loss:		0.551567
  validation accuracy:		87.61 %
Epoch 72 of 2000 took 0.153s
  training loss:		0.615970
  validation loss:		0.539700
  validation accuracy:		88.04 %
Epoch 73 of 2000 took 0.142s
  training loss:		0.600856
  validation loss:		0.524859
  validation accuracy:		87.93 %
Epoch 74 of 2000 took 0.092s
  training loss:		0.592341
  validation loss:		0.513320
  validation accuracy:		88.04 %
Epoch 75 of 2000 took 0.278s
  training loss:		0.579331
  validation loss:		0.496666
  validation accuracy:		88.70 %
Epoch 76 of 2000 took 0.176s
  training loss:		0.564676
  validation loss:		0.497991
  validation accuracy:		88.48 %
Epoch 77 of 2000 took 0.106s
  training loss:		0.549635
  validation loss:		0.490425
  validation accuracy:		88.80 %
Epoch 78 of 2000 took 0.235s
  training loss:		0.545625
  validation loss:		0.475574
  validation accuracy:		88.48 %
Epoch 79 of 2000 took 0.148s
  training loss:		0.535905
  validation loss:		0.464995
  validation accuracy:		88.91 %
Epoch 80 of 2000 took 0.105s
  training loss:		0.522779
  validation loss:		0.462705
  validation accuracy:		89.02 %
Epoch 81 of 2000 took 0.098s
  training loss:		0.509451
  validation loss:		0.447907
  validation accuracy:		89.78 %
Epoch 82 of 2000 took 0.093s
  training loss:		0.506986
  validation loss:		0.446537
  validation accuracy:		89.13 %
Epoch 83 of 2000 took 0.084s
  training loss:		0.493676
  validation loss:		0.438990
  validation accuracy:		89.02 %
Epoch 84 of 2000 took 0.087s
  training loss:		0.490660
  validation loss:		0.427444
  validation accuracy:		90.11 %
Epoch 85 of 2000 took 0.082s
  training loss:		0.475014
  validation loss:		0.419065
  validation accuracy:		90.33 %
Epoch 86 of 2000 took 0.093s
  training loss:		0.465077
  validation loss:		0.417515
  validation accuracy:		89.78 %
Epoch 87 of 2000 took 0.082s
  training loss:		0.458570
  validation loss:		0.410917
  validation accuracy:		89.67 %
Epoch 88 of 2000 took 0.098s
  training loss:		0.450888
  validation loss:		0.403241
  validation accuracy:		90.00 %
Epoch 89 of 2000 took 0.084s
  training loss:		0.444110
  validation loss:		0.400241
  validation accuracy:		90.00 %
Epoch 90 of 2000 took 0.311s
  training loss:		0.442025
  validation loss:		0.389981
  validation accuracy:		90.43 %
Epoch 91 of 2000 took 0.138s
  training loss:		0.432306
  validation loss:		0.383351
  validation accuracy:		90.22 %
Epoch 92 of 2000 took 0.108s
  training loss:		0.425945
  validation loss:		0.376536
  validation accuracy:		90.54 %
Epoch 93 of 2000 took 0.103s
  training loss:		0.414764
  validation loss:		0.376446
  validation accuracy:		90.65 %
Epoch 94 of 2000 took 0.193s
  training loss:		0.412092
  validation loss:		0.371108
  validation accuracy:		90.33 %
Epoch 95 of 2000 took 0.128s
  training loss:		0.405667
  validation loss:		0.366488
  validation accuracy:		90.33 %
Epoch 96 of 2000 took 0.112s
  training loss:		0.393748
  validation loss:		0.364541
  validation accuracy:		90.22 %
Epoch 97 of 2000 took 0.133s
  training loss:		0.391721
  validation loss:		0.355405
  validation accuracy:		90.54 %
Epoch 98 of 2000 took 0.229s
  training loss:		0.385024
  validation loss:		0.357071
  validation accuracy:		89.89 %
Epoch 99 of 2000 took 0.118s
  training loss:		0.382361
  validation loss:		0.346717
  validation accuracy:		90.98 %
Epoch 100 of 2000 took 0.154s
  training loss:		0.374111
  validation loss:		0.337341
  validation accuracy:		90.54 %
Epoch 101 of 2000 took 0.151s
  training loss:		0.375221
  validation loss:		0.338157
  validation accuracy:		90.65 %
Epoch 102 of 2000 took 0.138s
  training loss:		0.357261
  validation loss:		0.329502
  validation accuracy:		91.30 %
Epoch 103 of 2000 took 0.091s
  training loss:		0.359309
  validation loss:		0.329064
  validation accuracy:		91.41 %
Epoch 104 of 2000 took 0.168s
  training loss:		0.355160
  validation loss:		0.328742
  validation accuracy:		91.30 %
Epoch 105 of 2000 took 0.122s
  training loss:		0.350006
  validation loss:		0.325218
  validation accuracy:		91.09 %
Epoch 106 of 2000 took 0.080s
  training loss:		0.344013
  validation loss:		0.324743
  validation accuracy:		90.98 %
Epoch 107 of 2000 took 0.122s
  training loss:		0.337079
  validation loss:		0.317865
  validation accuracy:		91.52 %
Epoch 108 of 2000 took 0.100s
  training loss:		0.339055
  validation loss:		0.313808
  validation accuracy:		91.63 %
Epoch 109 of 2000 took 0.075s
  training loss:		0.334359
  validation loss:		0.317356
  validation accuracy:		91.20 %
Epoch 110 of 2000 took 0.074s
  training loss:		0.323105
  validation loss:		0.306006
  validation accuracy:		91.20 %
Epoch 111 of 2000 took 0.070s
  training loss:		0.324434
  validation loss:		0.301640
  validation accuracy:		91.96 %
Epoch 112 of 2000 took 0.068s
  training loss:		0.320119
  validation loss:		0.302656
  validation accuracy:		91.74 %
Epoch 113 of 2000 took 0.063s
  training loss:		0.316639
  validation loss:		0.299988
  validation accuracy:		91.96 %
Epoch 114 of 2000 took 0.077s
  training loss:		0.312630
  validation loss:		0.298772
  validation accuracy:		91.96 %
Epoch 115 of 2000 took 0.086s
  training loss:		0.311485
  validation loss:		0.291191
  validation accuracy:		92.07 %
Epoch 116 of 2000 took 0.075s
  training loss:		0.306976
  validation loss:		0.301272
  validation accuracy:		91.09 %
Epoch 117 of 2000 took 0.084s
  training loss:		0.301488
  validation loss:		0.295420
  validation accuracy:		92.07 %
Epoch 118 of 2000 took 0.117s
  training loss:		0.297509
  validation loss:		0.282323
  validation accuracy:		92.07 %
Epoch 119 of 2000 took 0.064s
  training loss:		0.292768
  validation loss:		0.283866
  validation accuracy:		92.17 %
Epoch 120 of 2000 took 0.077s
  training loss:		0.293477
  validation loss:		0.279734
  validation accuracy:		92.28 %
Epoch 121 of 2000 took 0.073s
  training loss:		0.293143
  validation loss:		0.283806
  validation accuracy:		92.28 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.282571
  validation loss:		0.277669
  validation accuracy:		92.39 %
Epoch 123 of 2000 took 0.077s
  training loss:		0.279921
  validation loss:		0.270192
  validation accuracy:		92.83 %
Epoch 124 of 2000 took 0.062s
  training loss:		0.279496
  validation loss:		0.285016
  validation accuracy:		92.17 %
Epoch 125 of 2000 took 0.057s
  training loss:		0.278477
  validation loss:		0.280928
  validation accuracy:		92.83 %
Epoch 126 of 2000 took 0.055s
  training loss:		0.277569
  validation loss:		0.271968
  validation accuracy:		92.28 %
Epoch 127 of 2000 took 0.057s
  training loss:		0.273509
  validation loss:		0.261734
  validation accuracy:		92.61 %
Epoch 128 of 2000 took 0.058s
  training loss:		0.266530
  validation loss:		0.262145
  validation accuracy:		92.61 %
Epoch 129 of 2000 took 0.059s
  training loss:		0.263067
  validation loss:		0.259786
  validation accuracy:		92.50 %
Epoch 130 of 2000 took 0.077s
  training loss:		0.263765
  validation loss:		0.258085
  validation accuracy:		92.50 %
Epoch 131 of 2000 took 0.068s
  training loss:		0.261653
  validation loss:		0.264551
  validation accuracy:		92.61 %
Epoch 132 of 2000 took 0.058s
  training loss:		0.256774
  validation loss:		0.264467
  validation accuracy:		92.50 %
Epoch 133 of 2000 took 0.057s
  training loss:		0.260271
  validation loss:		0.257159
  validation accuracy:		92.61 %
Epoch 134 of 2000 took 0.056s
  training loss:		0.253713
  validation loss:		0.258182
  validation accuracy:		92.93 %
Epoch 135 of 2000 took 0.056s
  training loss:		0.254230
  validation loss:		0.251074
  validation accuracy:		92.72 %
Epoch 136 of 2000 took 0.056s
  training loss:		0.251919
  validation loss:		0.257876
  validation accuracy:		92.61 %
Epoch 137 of 2000 took 0.056s
  training loss:		0.249932
  validation loss:		0.247281
  validation accuracy:		92.72 %
Epoch 138 of 2000 took 0.058s
  training loss:		0.249427
  validation loss:		0.247145
  validation accuracy:		93.04 %
Epoch 139 of 2000 took 0.062s
  training loss:		0.248791
  validation loss:		0.253022
  validation accuracy:		92.39 %
Epoch 140 of 2000 took 0.106s
  training loss:		0.240165
  validation loss:		0.244124
  validation accuracy:		93.37 %
Epoch 141 of 2000 took 0.105s
  training loss:		0.242659
  validation loss:		0.250253
  validation accuracy:		92.61 %
Epoch 142 of 2000 took 0.100s
  training loss:		0.240675
  validation loss:		0.244349
  validation accuracy:		93.26 %
Epoch 143 of 2000 took 0.064s
  training loss:		0.239598
  validation loss:		0.238442
  validation accuracy:		93.04 %
Epoch 144 of 2000 took 0.058s
  training loss:		0.236923
  validation loss:		0.241884
  validation accuracy:		93.48 %
Epoch 145 of 2000 took 0.057s
  training loss:		0.231375
  validation loss:		0.241506
  validation accuracy:		93.48 %
Epoch 146 of 2000 took 0.057s
  training loss:		0.228489
  validation loss:		0.243959
  validation accuracy:		92.50 %
Epoch 147 of 2000 took 0.057s
  training loss:		0.228031
  validation loss:		0.232797
  validation accuracy:		93.59 %
Epoch 148 of 2000 took 0.057s
  training loss:		0.231592
  validation loss:		0.237555
  validation accuracy:		93.15 %
Epoch 149 of 2000 took 0.058s
  training loss:		0.224861
  validation loss:		0.240660
  validation accuracy:		93.26 %
Epoch 150 of 2000 took 0.055s
  training loss:		0.227543
  validation loss:		0.233826
  validation accuracy:		93.70 %
Epoch 151 of 2000 took 0.056s
  training loss:		0.227275
  validation loss:		0.239923
  validation accuracy:		93.59 %
Epoch 152 of 2000 took 0.057s
  training loss:		0.226454
  validation loss:		0.241721
  validation accuracy:		93.37 %
Epoch 153 of 2000 took 0.060s
  training loss:		0.223583
  validation loss:		0.230594
  validation accuracy:		93.37 %
Epoch 154 of 2000 took 0.078s
  training loss:		0.219803
  validation loss:		0.238623
  validation accuracy:		93.26 %
Epoch 155 of 2000 took 0.078s
  training loss:		0.218523
  validation loss:		0.230542
  validation accuracy:		93.80 %
Epoch 156 of 2000 took 0.083s
  training loss:		0.219497
  validation loss:		0.226898
  validation accuracy:		93.37 %
Epoch 157 of 2000 took 0.171s
  training loss:		0.220159
  validation loss:		0.227412
  validation accuracy:		93.37 %
Epoch 158 of 2000 took 0.076s
  training loss:		0.213139
  validation loss:		0.231183
  validation accuracy:		93.37 %
Epoch 159 of 2000 took 0.075s
  training loss:		0.213581
  validation loss:		0.230711
  validation accuracy:		93.80 %
Epoch 160 of 2000 took 0.076s
  training loss:		0.210752
  validation loss:		0.227849
  validation accuracy:		93.59 %
Epoch 161 of 2000 took 0.057s
  training loss:		0.207603
  validation loss:		0.225485
  validation accuracy:		93.59 %
Epoch 162 of 2000 took 0.059s
  training loss:		0.208400
  validation loss:		0.221396
  validation accuracy:		94.35 %
Epoch 163 of 2000 took 0.055s
  training loss:		0.212906
  validation loss:		0.219412
  validation accuracy:		93.91 %
Epoch 164 of 2000 took 0.055s
  training loss:		0.203151
  validation loss:		0.222266
  validation accuracy:		93.80 %
Epoch 165 of 2000 took 0.056s
  training loss:		0.205932
  validation loss:		0.221067
  validation accuracy:		93.80 %
Epoch 166 of 2000 took 0.055s
  training loss:		0.208279
  validation loss:		0.223140
  validation accuracy:		93.59 %
Epoch 167 of 2000 took 0.056s
  training loss:		0.207002
  validation loss:		0.216711
  validation accuracy:		93.80 %
Epoch 168 of 2000 took 0.061s
  training loss:		0.201075
  validation loss:		0.221673
  validation accuracy:		94.02 %
Epoch 169 of 2000 took 0.079s
  training loss:		0.199881
  validation loss:		0.219876
  validation accuracy:		93.91 %
Epoch 170 of 2000 took 0.069s
  training loss:		0.200365
  validation loss:		0.223366
  validation accuracy:		93.70 %
Epoch 171 of 2000 took 0.060s
  training loss:		0.190184
  validation loss:		0.227212
  validation accuracy:		93.15 %
Epoch 172 of 2000 took 0.058s
  training loss:		0.195768
  validation loss:		0.215942
  validation accuracy:		93.91 %
Epoch 173 of 2000 took 0.058s
  training loss:		0.200884
  validation loss:		0.216433
  validation accuracy:		93.80 %
Epoch 174 of 2000 took 0.069s
  training loss:		0.200410
  validation loss:		0.217633
  validation accuracy:		94.13 %
Epoch 175 of 2000 took 0.090s
  training loss:		0.195493
  validation loss:		0.217170
  validation accuracy:		94.35 %
Epoch 176 of 2000 took 0.077s
  training loss:		0.191443
  validation loss:		0.215593
  validation accuracy:		93.80 %
Epoch 177 of 2000 took 0.056s
  training loss:		0.191670
  validation loss:		0.213360
  validation accuracy:		93.80 %
Epoch 178 of 2000 took 0.055s
  training loss:		0.193695
  validation loss:		0.216123
  validation accuracy:		94.02 %
Epoch 179 of 2000 took 0.058s
  training loss:		0.186922
  validation loss:		0.220679
  validation accuracy:		93.70 %
Epoch 180 of 2000 took 0.055s
  training loss:		0.191457
  validation loss:		0.212947
  validation accuracy:		94.24 %
Epoch 181 of 2000 took 0.055s
  training loss:		0.186456
  validation loss:		0.217749
  validation accuracy:		94.13 %
Epoch 182 of 2000 took 0.055s
  training loss:		0.184777
  validation loss:		0.211646
  validation accuracy:		94.35 %
Epoch 183 of 2000 took 0.057s
  training loss:		0.185435
  validation loss:		0.217173
  validation accuracy:		93.59 %
Epoch 184 of 2000 took 0.065s
  training loss:		0.189065
  validation loss:		0.214418
  validation accuracy:		93.37 %
Epoch 185 of 2000 took 0.055s
  training loss:		0.186511
  validation loss:		0.205950
  validation accuracy:		94.02 %
Epoch 186 of 2000 took 0.055s
  training loss:		0.184849
  validation loss:		0.211131
  validation accuracy:		93.91 %
Epoch 187 of 2000 took 0.066s
  training loss:		0.185078
  validation loss:		0.215809
  validation accuracy:		93.80 %
Epoch 188 of 2000 took 0.057s
  training loss:		0.185969
  validation loss:		0.207724
  validation accuracy:		94.24 %
Epoch 189 of 2000 took 0.057s
  training loss:		0.181700
  validation loss:		0.205961
  validation accuracy:		94.13 %
Epoch 190 of 2000 took 0.056s
  training loss:		0.183325
  validation loss:		0.205870
  validation accuracy:		94.24 %
Epoch 191 of 2000 took 0.064s
  training loss:		0.177602
  validation loss:		0.216024
  validation accuracy:		93.91 %
Epoch 192 of 2000 took 0.070s
  training loss:		0.179316
  validation loss:		0.207034
  validation accuracy:		94.24 %
Epoch 193 of 2000 took 0.070s
  training loss:		0.178339
  validation loss:		0.206984
  validation accuracy:		94.46 %
Epoch 194 of 2000 took 0.102s
  training loss:		0.178511
  validation loss:		0.204183
  validation accuracy:		94.13 %
Epoch 195 of 2000 took 0.106s
  training loss:		0.175632
  validation loss:		0.205056
  validation accuracy:		94.35 %
Epoch 196 of 2000 took 0.087s
  training loss:		0.173235
  validation loss:		0.202149
  validation accuracy:		94.35 %
Epoch 197 of 2000 took 0.083s
  training loss:		0.174746
  validation loss:		0.201652
  validation accuracy:		94.35 %
Epoch 198 of 2000 took 0.162s
  training loss:		0.175502
  validation loss:		0.209220
  validation accuracy:		94.24 %
Epoch 199 of 2000 took 0.080s
  training loss:		0.171452
  validation loss:		0.207740
  validation accuracy:		94.13 %
Epoch 200 of 2000 took 0.091s
  training loss:		0.169810
  validation loss:		0.207811
  validation accuracy:		94.13 %
Epoch 201 of 2000 took 0.099s
  training loss:		0.169342
  validation loss:		0.211356
  validation accuracy:		93.59 %
Epoch 202 of 2000 took 0.081s
  training loss:		0.169408
  validation loss:		0.202311
  validation accuracy:		94.46 %
Epoch 203 of 2000 took 0.074s
  training loss:		0.168000
  validation loss:		0.201098
  validation accuracy:		94.24 %
Epoch 204 of 2000 took 0.089s
  training loss:		0.171752
  validation loss:		0.203600
  validation accuracy:		94.24 %
Epoch 205 of 2000 took 0.107s
  training loss:		0.170474
  validation loss:		0.212969
  validation accuracy:		94.13 %
Epoch 206 of 2000 took 0.208s
  training loss:		0.168292
  validation loss:		0.198526
  validation accuracy:		94.35 %
Epoch 207 of 2000 took 0.129s
  training loss:		0.167406
  validation loss:		0.207749
  validation accuracy:		93.80 %
Epoch 208 of 2000 took 0.075s
  training loss:		0.166794
  validation loss:		0.208236
  validation accuracy:		94.02 %
Epoch 209 of 2000 took 0.077s
  training loss:		0.166970
  validation loss:		0.201524
  validation accuracy:		94.13 %
Epoch 210 of 2000 took 0.065s
  training loss:		0.159900
  validation loss:		0.206262
  validation accuracy:		94.13 %
Epoch 211 of 2000 took 0.066s
  training loss:		0.165194
  validation loss:		0.202095
  validation accuracy:		93.91 %
Epoch 212 of 2000 took 0.055s
  training loss:		0.165045
  validation loss:		0.193947
  validation accuracy:		94.46 %
Epoch 213 of 2000 took 0.071s
  training loss:		0.165894
  validation loss:		0.207277
  validation accuracy:		94.02 %
Epoch 214 of 2000 took 0.090s
  training loss:		0.162186
  validation loss:		0.197735
  validation accuracy:		94.13 %
Epoch 215 of 2000 took 0.064s
  training loss:		0.161625
  validation loss:		0.202074
  validation accuracy:		94.35 %
Epoch 216 of 2000 took 0.062s
  training loss:		0.160671
  validation loss:		0.197683
  validation accuracy:		94.02 %
Epoch 217 of 2000 took 0.062s
  training loss:		0.159369
  validation loss:		0.203541
  validation accuracy:		94.02 %
Epoch 218 of 2000 took 0.060s
  training loss:		0.160508
  validation loss:		0.194281
  validation accuracy:		94.13 %
Epoch 219 of 2000 took 0.056s
  training loss:		0.160561
  validation loss:		0.196653
  validation accuracy:		94.13 %
Epoch 220 of 2000 took 0.067s
  training loss:		0.157461
  validation loss:		0.207296
  validation accuracy:		94.13 %
Epoch 221 of 2000 took 0.098s
  training loss:		0.157254
  validation loss:		0.197020
  validation accuracy:		94.24 %
Epoch 222 of 2000 took 0.068s
  training loss:		0.156955
  validation loss:		0.194405
  validation accuracy:		94.35 %
Epoch 223 of 2000 took 0.060s
  training loss:		0.153899
  validation loss:		0.197215
  validation accuracy:		94.35 %
Epoch 224 of 2000 took 0.056s
  training loss:		0.158400
  validation loss:		0.199422
  validation accuracy:		94.35 %
Epoch 225 of 2000 took 0.112s
  training loss:		0.156230
  validation loss:		0.201849
  validation accuracy:		94.02 %
Epoch 226 of 2000 took 0.120s
  training loss:		0.154803
  validation loss:		0.199033
  validation accuracy:		94.24 %
Epoch 227 of 2000 took 0.108s
  training loss:		0.153569
  validation loss:		0.197623
  validation accuracy:		94.13 %
Epoch 228 of 2000 took 0.137s
  training loss:		0.151831
  validation loss:		0.197123
  validation accuracy:		94.13 %
Epoch 229 of 2000 took 0.108s
  training loss:		0.152007
  validation loss:		0.200121
  validation accuracy:		94.02 %
Epoch 230 of 2000 took 0.062s
  training loss:		0.152279
  validation loss:		0.191857
  validation accuracy:		94.24 %
Epoch 231 of 2000 took 0.087s
  training loss:		0.152670
  validation loss:		0.200638
  validation accuracy:		94.13 %
Epoch 232 of 2000 took 0.106s
  training loss:		0.150722
  validation loss:		0.188794
  validation accuracy:		94.78 %
Epoch 233 of 2000 took 0.114s
  training loss:		0.152151
  validation loss:		0.197611
  validation accuracy:		93.91 %
Epoch 234 of 2000 took 0.101s
  training loss:		0.149748
  validation loss:		0.192443
  validation accuracy:		94.57 %
Epoch 235 of 2000 took 0.142s
  training loss:		0.147873
  validation loss:		0.192758
  validation accuracy:		94.46 %
Epoch 236 of 2000 took 0.092s
  training loss:		0.141431
  validation loss:		0.195395
  validation accuracy:		94.13 %
Epoch 237 of 2000 took 0.065s
  training loss:		0.147010
  validation loss:		0.193011
  validation accuracy:		94.13 %
Epoch 238 of 2000 took 0.090s
  training loss:		0.148012
  validation loss:		0.197219
  validation accuracy:		94.46 %
Epoch 239 of 2000 took 0.100s
  training loss:		0.144582
  validation loss:		0.187499
  validation accuracy:		94.46 %
Epoch 240 of 2000 took 0.112s
  training loss:		0.141455
  validation loss:		0.192857
  validation accuracy:		94.46 %
Epoch 241 of 2000 took 0.062s
  training loss:		0.146318
  validation loss:		0.196227
  validation accuracy:		94.13 %
Epoch 242 of 2000 took 0.075s
  training loss:		0.145587
  validation loss:		0.197860
  validation accuracy:		94.13 %
Epoch 243 of 2000 took 0.075s
  training loss:		0.140116
  validation loss:		0.193496
  validation accuracy:		94.35 %
Epoch 244 of 2000 took 0.079s
  training loss:		0.140769
  validation loss:		0.193410
  validation accuracy:		93.91 %
Epoch 245 of 2000 took 0.064s
  training loss:		0.145826
  validation loss:		0.191196
  validation accuracy:		94.57 %
Epoch 246 of 2000 took 0.075s
  training loss:		0.144938
  validation loss:		0.191125
  validation accuracy:		94.13 %
Epoch 247 of 2000 took 0.067s
  training loss:		0.138777
  validation loss:		0.190739
  validation accuracy:		94.35 %
Epoch 248 of 2000 took 0.066s
  training loss:		0.147436
  validation loss:		0.189279
  validation accuracy:		94.35 %
Epoch 249 of 2000 took 0.084s
  training loss:		0.142186
  validation loss:		0.197982
  validation accuracy:		94.35 %
Epoch 250 of 2000 took 0.066s
  training loss:		0.139486
  validation loss:		0.197727
  validation accuracy:		94.24 %
Epoch 251 of 2000 took 0.082s
  training loss:		0.138542
  validation loss:		0.188283
  validation accuracy:		94.57 %
Epoch 252 of 2000 took 0.087s
  training loss:		0.138520
  validation loss:		0.189577
  validation accuracy:		94.35 %
Epoch 253 of 2000 took 0.072s
  training loss:		0.138264
  validation loss:		0.189606
  validation accuracy:		94.67 %
Epoch 254 of 2000 took 0.057s
  training loss:		0.137037
  validation loss:		0.191092
  validation accuracy:		94.35 %
Epoch 255 of 2000 took 0.076s
  training loss:		0.138856
  validation loss:		0.195805
  validation accuracy:		94.13 %
Epoch 256 of 2000 took 0.082s
  training loss:		0.137529
  validation loss:		0.193414
  validation accuracy:		94.24 %
Epoch 257 of 2000 took 0.065s
  training loss:		0.136233
  validation loss:		0.200294
  validation accuracy:		94.02 %
Epoch 258 of 2000 took 0.055s
  training loss:		0.135103
  validation loss:		0.192057
  validation accuracy:		94.13 %
Epoch 259 of 2000 took 0.076s
  training loss:		0.133971
  validation loss:		0.195922
  validation accuracy:		94.46 %
Epoch 260 of 2000 took 0.058s
  training loss:		0.137259
  validation loss:		0.196727
  validation accuracy:		93.91 %
Epoch 261 of 2000 took 0.055s
  training loss:		0.134699
  validation loss:		0.187715
  validation accuracy:		94.13 %
Epoch 262 of 2000 took 0.052s
  training loss:		0.134216
  validation loss:		0.187778
  validation accuracy:		94.35 %
Epoch 263 of 2000 took 0.054s
  training loss:		0.131566
  validation loss:		0.191847
  validation accuracy:		94.35 %
Epoch 264 of 2000 took 0.052s
  training loss:		0.134900
  validation loss:		0.192921
  validation accuracy:		94.24 %
Epoch 265 of 2000 took 0.059s
  training loss:		0.131088
  validation loss:		0.194636
  validation accuracy:		94.13 %
Epoch 266 of 2000 took 0.075s
  training loss:		0.130444
  validation loss:		0.198458
  validation accuracy:		94.13 %
Epoch 267 of 2000 took 0.072s
  training loss:		0.131566
  validation loss:		0.191716
  validation accuracy:		94.24 %
Epoch 268 of 2000 took 0.065s
  training loss:		0.126792
  validation loss:		0.185167
  validation accuracy:		94.13 %
Epoch 269 of 2000 took 0.078s
  training loss:		0.130608
  validation loss:		0.190219
  validation accuracy:		94.35 %
Epoch 270 of 2000 took 0.075s
  training loss:		0.129681
  validation loss:		0.187589
  validation accuracy:		94.35 %
Epoch 271 of 2000 took 0.061s
  training loss:		0.129978
  validation loss:		0.189681
  validation accuracy:		94.24 %
Epoch 272 of 2000 took 0.061s
  training loss:		0.129574
  validation loss:		0.188773
  validation accuracy:		94.24 %
Epoch 273 of 2000 took 0.055s
  training loss:		0.127658
  validation loss:		0.186906
  validation accuracy:		94.57 %
Epoch 274 of 2000 took 0.060s
  training loss:		0.129126
  validation loss:		0.193396
  validation accuracy:		94.35 %
Epoch 275 of 2000 took 0.074s
  training loss:		0.127531
  validation loss:		0.187711
  validation accuracy:		94.46 %
Epoch 276 of 2000 took 0.056s
  training loss:		0.126142
  validation loss:		0.199388
  validation accuracy:		94.13 %
Epoch 277 of 2000 took 0.055s
  training loss:		0.128064
  validation loss:		0.189151
  validation accuracy:		94.35 %
Epoch 278 of 2000 took 0.053s
  training loss:		0.126839
  validation loss:		0.194311
  validation accuracy:		94.46 %
Epoch 279 of 2000 took 0.091s
  training loss:		0.125133
  validation loss:		0.190094
  validation accuracy:		94.24 %
Epoch 280 of 2000 took 0.086s
  training loss:		0.125871
  validation loss:		0.195525
  validation accuracy:		94.35 %
Epoch 281 of 2000 took 0.135s
  training loss:		0.122316
  validation loss:		0.191475
  validation accuracy:		94.24 %
Epoch 282 of 2000 took 0.115s
  training loss:		0.126146
  validation loss:		0.196149
  validation accuracy:		94.35 %
Epoch 283 of 2000 took 0.063s
  training loss:		0.124683
  validation loss:		0.186883
  validation accuracy:		94.46 %
Epoch 284 of 2000 took 0.059s
  training loss:		0.126049
  validation loss:		0.185663
  validation accuracy:		94.13 %
Epoch 285 of 2000 took 0.053s
  training loss:		0.123887
  validation loss:		0.185942
  validation accuracy:		94.24 %
Epoch 286 of 2000 took 0.061s
  training loss:		0.126240
  validation loss:		0.186504
  validation accuracy:		94.46 %
Epoch 287 of 2000 took 0.053s
  training loss:		0.124108
  validation loss:		0.189599
  validation accuracy:		94.35 %
Epoch 288 of 2000 took 0.056s
  training loss:		0.121142
  validation loss:		0.188675
  validation accuracy:		94.24 %
Epoch 289 of 2000 took 0.058s
  training loss:		0.123594
  validation loss:		0.196302
  validation accuracy:		94.24 %
Epoch 290 of 2000 took 0.057s
  training loss:		0.120411
  validation loss:		0.187404
  validation accuracy:		94.35 %
Epoch 291 of 2000 took 0.073s
  training loss:		0.121781
  validation loss:		0.187938
  validation accuracy:		94.46 %
Epoch 292 of 2000 took 0.064s
  training loss:		0.120406
  validation loss:		0.186605
  validation accuracy:		94.24 %
Epoch 293 of 2000 took 0.058s
  training loss:		0.117951
  validation loss:		0.189080
  validation accuracy:		94.13 %
Epoch 294 of 2000 took 0.056s
  training loss:		0.119837
  validation loss:		0.186233
  validation accuracy:		94.35 %
Epoch 295 of 2000 took 0.060s
  training loss:		0.121132
  validation loss:		0.196352
  validation accuracy:		94.13 %
Epoch 296 of 2000 took 0.065s
  training loss:		0.120078
  validation loss:		0.197649
  validation accuracy:		94.35 %
Epoch 297 of 2000 took 0.068s
  training loss:		0.121381
  validation loss:		0.184577
  validation accuracy:		94.35 %
Epoch 298 of 2000 took 0.076s
  training loss:		0.118393
  validation loss:		0.187390
  validation accuracy:		94.46 %
Epoch 299 of 2000 took 0.058s
  training loss:		0.119774
  validation loss:		0.189967
  validation accuracy:		94.24 %
Epoch 300 of 2000 took 0.070s
  training loss:		0.119601
  validation loss:		0.191553
  validation accuracy:		94.35 %
Epoch 301 of 2000 took 0.060s
  training loss:		0.119793
  validation loss:		0.180362
  validation accuracy:		94.24 %
Epoch 302 of 2000 took 0.056s
  training loss:		0.118927
  validation loss:		0.193677
  validation accuracy:		94.35 %
Epoch 303 of 2000 took 0.054s
  training loss:		0.115084
  validation loss:		0.191408
  validation accuracy:		94.46 %
Epoch 304 of 2000 took 0.054s
  training loss:		0.115204
  validation loss:		0.194583
  validation accuracy:		94.35 %
Epoch 305 of 2000 took 0.057s
  training loss:		0.116282
  validation loss:		0.185759
  validation accuracy:		94.57 %
Epoch 306 of 2000 took 0.070s
  training loss:		0.115020
  validation loss:		0.189758
  validation accuracy:		94.24 %
Epoch 307 of 2000 took 0.061s
  training loss:		0.114863
  validation loss:		0.185310
  validation accuracy:		94.24 %
Epoch 308 of 2000 took 0.052s
  training loss:		0.115675
  validation loss:		0.192615
  validation accuracy:		94.35 %
Epoch 309 of 2000 took 0.054s
  training loss:		0.112966
  validation loss:		0.190981
  validation accuracy:		94.24 %
Epoch 310 of 2000 took 0.053s
  training loss:		0.114728
  validation loss:		0.188981
  validation accuracy:		94.46 %
Epoch 311 of 2000 took 0.054s
  training loss:		0.111922
  validation loss:		0.187325
  validation accuracy:		94.57 %
Epoch 312 of 2000 took 0.054s
  training loss:		0.114061
  validation loss:		0.190945
  validation accuracy:		94.24 %
Epoch 313 of 2000 took 0.055s
  training loss:		0.115860
  validation loss:		0.185222
  validation accuracy:		94.24 %
Epoch 314 of 2000 took 0.085s
  training loss:		0.112747
  validation loss:		0.192752
  validation accuracy:		94.35 %
Epoch 315 of 2000 took 0.059s
  training loss:		0.113330
  validation loss:		0.191563
  validation accuracy:		94.02 %
Epoch 316 of 2000 took 0.055s
  training loss:		0.109436
  validation loss:		0.185048
  validation accuracy:		94.67 %
Epoch 317 of 2000 took 0.056s
  training loss:		0.112798
  validation loss:		0.187053
  validation accuracy:		94.24 %
Epoch 318 of 2000 took 0.063s
  training loss:		0.111094
  validation loss:		0.188146
  validation accuracy:		94.13 %
Epoch 319 of 2000 took 0.117s
  training loss:		0.108465
  validation loss:		0.187394
  validation accuracy:		94.24 %
Epoch 320 of 2000 took 0.106s
  training loss:		0.113431
  validation loss:		0.189129
  validation accuracy:		94.02 %
Epoch 321 of 2000 took 0.076s
  training loss:		0.110507
  validation loss:		0.190464
  validation accuracy:		94.35 %
Epoch 322 of 2000 took 0.075s
  training loss:		0.107589
  validation loss:		0.191833
  validation accuracy:		94.24 %
Epoch 323 of 2000 took 0.084s
  training loss:		0.110587
  validation loss:		0.188995
  validation accuracy:		94.13 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.109321
  validation loss:		0.192324
  validation accuracy:		94.35 %
Epoch 325 of 2000 took 0.076s
  training loss:		0.109133
  validation loss:		0.186363
  validation accuracy:		94.35 %
Epoch 326 of 2000 took 0.081s
  training loss:		0.108107
  validation loss:		0.200957
  validation accuracy:		94.57 %
Epoch 327 of 2000 took 0.069s
  training loss:		0.110154
  validation loss:		0.187002
  validation accuracy:		94.24 %
Epoch 328 of 2000 took 0.073s
  training loss:		0.109269
  validation loss:		0.186533
  validation accuracy:		94.24 %
Epoch 329 of 2000 took 0.067s
  training loss:		0.108334
  validation loss:		0.200063
  validation accuracy:		94.24 %
Epoch 330 of 2000 took 0.086s
  training loss:		0.104400
  validation loss:		0.190990
  validation accuracy:		94.46 %
Epoch 331 of 2000 took 0.095s
  training loss:		0.104939
  validation loss:		0.196959
  validation accuracy:		94.02 %
Epoch 332 of 2000 took 0.055s
  training loss:		0.106233
  validation loss:		0.195131
  validation accuracy:		94.13 %
Epoch 333 of 2000 took 0.053s
  training loss:		0.103894
  validation loss:		0.196489
  validation accuracy:		94.35 %
Epoch 334 of 2000 took 0.054s
  training loss:		0.104401
  validation loss:		0.193690
  validation accuracy:		93.80 %
Epoch 335 of 2000 took 0.054s
  training loss:		0.106883
  validation loss:		0.195213
  validation accuracy:		94.35 %
Epoch 336 of 2000 took 0.053s
  training loss:		0.104676
  validation loss:		0.187937
  validation accuracy:		94.24 %
Epoch 337 of 2000 took 0.055s
  training loss:		0.105089
  validation loss:		0.193921
  validation accuracy:		94.35 %
Epoch 338 of 2000 took 0.054s
  training loss:		0.106136
  validation loss:		0.194582
  validation accuracy:		93.91 %
Epoch 339 of 2000 took 0.054s
  training loss:		0.105142
  validation loss:		0.191781
  validation accuracy:		94.35 %
Epoch 340 of 2000 took 0.056s
  training loss:		0.102399
  validation loss:		0.186606
  validation accuracy:		94.13 %
Epoch 341 of 2000 took 0.057s
  training loss:		0.102031
  validation loss:		0.196089
  validation accuracy:		94.46 %
Epoch 342 of 2000 took 0.060s
  training loss:		0.097515
  validation loss:		0.186601
  validation accuracy:		94.67 %
Epoch 343 of 2000 took 0.064s
  training loss:		0.101181
  validation loss:		0.187901
  validation accuracy:		94.35 %
Epoch 344 of 2000 took 0.068s
  training loss:		0.101415
  validation loss:		0.194907
  validation accuracy:		94.46 %
Epoch 345 of 2000 took 0.085s
  training loss:		0.103617
  validation loss:		0.186988
  validation accuracy:		94.46 %
Epoch 346 of 2000 took 0.066s
  training loss:		0.101820
  validation loss:		0.187430
  validation accuracy:		94.46 %
Epoch 347 of 2000 took 0.072s
  training loss:		0.103281
  validation loss:		0.184951
  validation accuracy:		94.24 %
Epoch 348 of 2000 took 0.066s
  training loss:		0.101281
  validation loss:		0.186713
  validation accuracy:		94.46 %
Epoch 349 of 2000 took 0.071s
  training loss:		0.102814
  validation loss:		0.185962
  validation accuracy:		94.35 %
Epoch 350 of 2000 took 0.062s
  training loss:		0.100766
  validation loss:		0.190533
  validation accuracy:		94.35 %
Epoch 351 of 2000 took 0.105s
  training loss:		0.098482
  validation loss:		0.186599
  validation accuracy:		94.24 %
Epoch 352 of 2000 took 0.089s
  training loss:		0.101332
  validation loss:		0.186745
  validation accuracy:		94.46 %
Epoch 353 of 2000 took 0.074s
  training loss:		0.099315
  validation loss:		0.186164
  validation accuracy:		94.35 %
Epoch 354 of 2000 took 0.076s
  training loss:		0.098632
  validation loss:		0.188771
  validation accuracy:		94.46 %
Epoch 355 of 2000 took 0.086s
  training loss:		0.098648
  validation loss:		0.194785
  validation accuracy:		94.24 %
Epoch 356 of 2000 took 0.084s
  training loss:		0.100033
  validation loss:		0.184473
  validation accuracy:		94.46 %
Epoch 357 of 2000 took 0.087s
  training loss:		0.098613
  validation loss:		0.191756
  validation accuracy:		94.13 %
Epoch 358 of 2000 took 0.089s
  training loss:		0.098337
  validation loss:		0.188218
  validation accuracy:		94.46 %
Epoch 359 of 2000 took 0.074s
  training loss:		0.099985
  validation loss:		0.187716
  validation accuracy:		94.13 %
Epoch 360 of 2000 took 0.081s
  training loss:		0.096174
  validation loss:		0.193257
  validation accuracy:		94.35 %
Epoch 361 of 2000 took 0.063s
  training loss:		0.099774
  validation loss:		0.187457
  validation accuracy:		94.46 %
Epoch 362 of 2000 took 0.072s
  training loss:		0.095737
  validation loss:		0.193783
  validation accuracy:		94.02 %
Epoch 363 of 2000 took 0.071s
  training loss:		0.095540
  validation loss:		0.187268
  validation accuracy:		94.35 %
Epoch 364 of 2000 took 0.057s
  training loss:		0.096018
  validation loss:		0.188690
  validation accuracy:		94.78 %
Epoch 365 of 2000 took 0.056s
  training loss:		0.097540
  validation loss:		0.194272
  validation accuracy:		94.24 %
Epoch 366 of 2000 took 0.056s
  training loss:		0.094016
  validation loss:		0.186422
  validation accuracy:		94.46 %
Epoch 367 of 2000 took 0.068s
  training loss:		0.096259
  validation loss:		0.190842
  validation accuracy:		94.46 %
Epoch 368 of 2000 took 0.060s
  training loss:		0.094813
  validation loss:		0.205263
  validation accuracy:		94.13 %
Epoch 369 of 2000 took 0.059s
  training loss:		0.097516
  validation loss:		0.191697
  validation accuracy:		94.57 %
Epoch 370 of 2000 took 0.059s
  training loss:		0.093874
  validation loss:		0.190985
  validation accuracy:		94.46 %
Epoch 371 of 2000 took 0.056s
  training loss:		0.094247
  validation loss:		0.187849
  validation accuracy:		94.13 %
Epoch 372 of 2000 took 0.056s
  training loss:		0.092343
  validation loss:		0.194535
  validation accuracy:		94.46 %
Epoch 373 of 2000 took 0.060s
  training loss:		0.095279
  validation loss:		0.193500
  validation accuracy:		94.35 %
Epoch 374 of 2000 took 0.067s
  training loss:		0.096528
  validation loss:		0.188236
  validation accuracy:		94.35 %
Epoch 375 of 2000 took 0.080s
  training loss:		0.093462
  validation loss:		0.190107
  validation accuracy:		94.24 %
Epoch 376 of 2000 took 0.060s
  training loss:		0.092340
  validation loss:		0.191886
  validation accuracy:		94.67 %
Epoch 377 of 2000 took 0.064s
  training loss:		0.093735
  validation loss:		0.188936
  validation accuracy:		94.57 %
Epoch 378 of 2000 took 0.060s
  training loss:		0.092880
  validation loss:		0.191311
  validation accuracy:		94.24 %
Epoch 379 of 2000 took 0.080s
  training loss:		0.091598
  validation loss:		0.193270
  validation accuracy:		94.13 %
Epoch 380 of 2000 took 0.054s
  training loss:		0.091834
  validation loss:		0.188909
  validation accuracy:		94.35 %
Epoch 381 of 2000 took 0.053s
  training loss:		0.092580
  validation loss:		0.191284
  validation accuracy:		94.24 %
Epoch 382 of 2000 took 0.057s
  training loss:		0.092344
  validation loss:		0.194889
  validation accuracy:		94.24 %
Epoch 383 of 2000 took 0.057s
  training loss:		0.090910
  validation loss:		0.192053
  validation accuracy:		94.57 %
Epoch 384 of 2000 took 0.061s
  training loss:		0.093733
  validation loss:		0.201288
  validation accuracy:		94.46 %
Epoch 385 of 2000 took 0.065s
  training loss:		0.092214
  validation loss:		0.188857
  validation accuracy:		94.46 %
Epoch 386 of 2000 took 0.063s
  training loss:		0.091721
  validation loss:		0.193206
  validation accuracy:		94.24 %
Epoch 387 of 2000 took 0.076s
  training loss:		0.091995
  validation loss:		0.201838
  validation accuracy:		94.57 %
Epoch 388 of 2000 took 0.061s
  training loss:		0.090826
  validation loss:		0.192632
  validation accuracy:		94.57 %
Epoch 389 of 2000 took 0.071s
  training loss:		0.089821
  validation loss:		0.195172
  validation accuracy:		94.35 %
Epoch 390 of 2000 took 0.107s
  training loss:		0.086881
  validation loss:		0.189463
  validation accuracy:		94.46 %
Epoch 391 of 2000 took 0.079s
  training loss:		0.089885
  validation loss:		0.202376
  validation accuracy:		94.24 %
Epoch 392 of 2000 took 0.068s
  training loss:		0.090557
  validation loss:		0.191517
  validation accuracy:		94.46 %
Epoch 393 of 2000 took 0.074s
  training loss:		0.089469
  validation loss:		0.194594
  validation accuracy:		94.35 %
Epoch 394 of 2000 took 0.070s
  training loss:		0.088028
  validation loss:		0.187915
  validation accuracy:		94.24 %
Epoch 395 of 2000 took 0.073s
  training loss:		0.088862
  validation loss:		0.191877
  validation accuracy:		94.24 %
Epoch 396 of 2000 took 0.080s
  training loss:		0.091018
  validation loss:		0.198263
  validation accuracy:		94.24 %
Epoch 397 of 2000 took 0.094s
  training loss:		0.090784
  validation loss:		0.196757
  validation accuracy:		94.24 %
Epoch 398 of 2000 took 0.184s
  training loss:		0.086688
  validation loss:		0.203403
  validation accuracy:		94.24 %
Epoch 399 of 2000 took 0.103s
  training loss:		0.089926
  validation loss:		0.199309
  validation accuracy:		94.35 %
Epoch 400 of 2000 took 0.074s
  training loss:		0.088503
  validation loss:		0.201144
  validation accuracy:		94.67 %
Epoch 401 of 2000 took 0.084s
  training loss:		0.087819
  validation loss:		0.193401
  validation accuracy:		94.46 %
Epoch 402 of 2000 took 0.074s
  training loss:		0.086824
  validation loss:		0.191303
  validation accuracy:		94.57 %
Epoch 403 of 2000 took 0.072s
  training loss:		0.088319
  validation loss:		0.200438
  validation accuracy:		94.46 %
Epoch 404 of 2000 took 0.072s
  training loss:		0.086857
  validation loss:		0.197894
  validation accuracy:		94.35 %
Epoch 405 of 2000 took 0.075s
  training loss:		0.087458
  validation loss:		0.198684
  validation accuracy:		94.24 %
Epoch 406 of 2000 took 0.082s
  training loss:		0.086323
  validation loss:		0.192324
  validation accuracy:		94.24 %
Epoch 407 of 2000 took 0.101s
  training loss:		0.084820
  validation loss:		0.200631
  validation accuracy:		94.24 %
Epoch 408 of 2000 took 0.109s
  training loss:		0.086415
  validation loss:		0.203225
  validation accuracy:		93.70 %
Epoch 409 of 2000 took 0.075s
  training loss:		0.085251
  validation loss:		0.200927
  validation accuracy:		94.57 %
Epoch 410 of 2000 took 0.079s
  training loss:		0.084814
  validation loss:		0.200757
  validation accuracy:		94.57 %
Epoch 411 of 2000 took 0.083s
  training loss:		0.082711
  validation loss:		0.192982
  validation accuracy:		94.57 %
Epoch 412 of 2000 took 0.068s
  training loss:		0.084952
  validation loss:		0.197329
  validation accuracy:		94.35 %
Epoch 413 of 2000 took 0.064s
  training loss:		0.084190
  validation loss:		0.201012
  validation accuracy:		94.24 %
Epoch 414 of 2000 took 0.083s
  training loss:		0.084308
  validation loss:		0.194519
  validation accuracy:		94.24 %
Epoch 415 of 2000 took 0.099s
  training loss:		0.085178
  validation loss:		0.205069
  validation accuracy:		93.91 %
Epoch 416 of 2000 took 0.081s
  training loss:		0.082406
  validation loss:		0.194003
  validation accuracy:		93.91 %
Epoch 417 of 2000 took 0.075s
  training loss:		0.080586
  validation loss:		0.203481
  validation accuracy:		94.35 %
Epoch 418 of 2000 took 0.059s
  training loss:		0.083377
  validation loss:		0.198656
  validation accuracy:		94.13 %
Epoch 419 of 2000 took 0.057s
  training loss:		0.080706
  validation loss:		0.199173
  validation accuracy:		94.67 %
Epoch 420 of 2000 took 0.055s
  training loss:		0.084914
  validation loss:		0.191021
  validation accuracy:		94.24 %
Epoch 421 of 2000 took 0.058s
  training loss:		0.084200
  validation loss:		0.212462
  validation accuracy:		94.24 %
Epoch 422 of 2000 took 0.054s
  training loss:		0.082878
  validation loss:		0.196817
  validation accuracy:		94.13 %
Epoch 423 of 2000 took 0.055s
  training loss:		0.079852
  validation loss:		0.202496
  validation accuracy:		94.57 %
Epoch 424 of 2000 took 0.056s
  training loss:		0.083659
  validation loss:		0.196993
  validation accuracy:		94.57 %
Epoch 425 of 2000 took 0.064s
  training loss:		0.080724
  validation loss:		0.197637
  validation accuracy:		94.35 %
Epoch 426 of 2000 took 0.066s
  training loss:		0.081079
  validation loss:		0.187590
  validation accuracy:		94.24 %
Epoch 427 of 2000 took 0.068s
  training loss:		0.083558
  validation loss:		0.203546
  validation accuracy:		93.80 %
Epoch 428 of 2000 took 0.064s
  training loss:		0.080571
  validation loss:		0.190658
  validation accuracy:		94.57 %
Epoch 429 of 2000 took 0.071s
  training loss:		0.081476
  validation loss:		0.196268
  validation accuracy:		94.35 %
Epoch 430 of 2000 took 0.069s
  training loss:		0.081528
  validation loss:		0.196647
  validation accuracy:		94.13 %
Epoch 431 of 2000 took 0.071s
  training loss:		0.081889
  validation loss:		0.199747
  validation accuracy:		94.46 %
Epoch 432 of 2000 took 0.100s
  training loss:		0.080838
  validation loss:		0.207561
  validation accuracy:		94.02 %
Epoch 433 of 2000 took 0.068s
  training loss:		0.081552
  validation loss:		0.199049
  validation accuracy:		94.46 %
Epoch 434 of 2000 took 0.064s
  training loss:		0.077096
  validation loss:		0.200032
  validation accuracy:		94.24 %
Epoch 435 of 2000 took 0.077s
  training loss:		0.080266
  validation loss:		0.205095
  validation accuracy:		94.46 %
Epoch 436 of 2000 took 0.076s
  training loss:		0.077104
  validation loss:		0.197605
  validation accuracy:		94.35 %
Epoch 437 of 2000 took 0.058s
  training loss:		0.077699
  validation loss:		0.198084
  validation accuracy:		94.57 %
Epoch 438 of 2000 took 0.059s
  training loss:		0.078547
  validation loss:		0.197323
  validation accuracy:		93.80 %
Epoch 439 of 2000 took 0.071s
  training loss:		0.077967
  validation loss:		0.198222
  validation accuracy:		94.35 %
Epoch 440 of 2000 took 0.055s
  training loss:		0.079134
  validation loss:		0.200591
  validation accuracy:		94.46 %
Epoch 441 of 2000 took 0.055s
  training loss:		0.080255
  validation loss:		0.199029
  validation accuracy:		94.46 %
Epoch 442 of 2000 took 0.080s
  training loss:		0.078965
  validation loss:		0.198785
  validation accuracy:		94.67 %
Epoch 443 of 2000 took 0.082s
  training loss:		0.074591
  validation loss:		0.199058
  validation accuracy:		94.35 %
Epoch 444 of 2000 took 0.094s
  training loss:		0.077515
  validation loss:		0.196824
  validation accuracy:		94.46 %
Epoch 445 of 2000 took 0.072s
  training loss:		0.077813
  validation loss:		0.192025
  validation accuracy:		94.24 %
Epoch 446 of 2000 took 0.054s
  training loss:		0.073750
  validation loss:		0.207805
  validation accuracy:		94.57 %
Epoch 447 of 2000 took 0.055s
  training loss:		0.078797
  validation loss:		0.206909
  validation accuracy:		94.13 %
Epoch 448 of 2000 took 0.057s
  training loss:		0.076118
  validation loss:		0.200572
  validation accuracy:		94.46 %
Epoch 449 of 2000 took 0.099s
  training loss:		0.078450
  validation loss:		0.196004
  validation accuracy:		94.78 %
Epoch 450 of 2000 took 0.060s
  training loss:		0.077267
  validation loss:		0.199909
  validation accuracy:		94.35 %
Epoch 451 of 2000 took 0.055s
  training loss:		0.073249
  validation loss:		0.199542
  validation accuracy:		94.35 %
Epoch 452 of 2000 took 0.083s
  training loss:		0.075462
  validation loss:		0.200868
  validation accuracy:		94.35 %
Epoch 453 of 2000 took 0.088s
  training loss:		0.076590
  validation loss:		0.200926
  validation accuracy:		94.57 %
Epoch 454 of 2000 took 0.067s
  training loss:		0.076711
  validation loss:		0.201305
  validation accuracy:		94.67 %
Epoch 455 of 2000 took 0.065s
  training loss:		0.074881
  validation loss:		0.200904
  validation accuracy:		94.57 %
Epoch 456 of 2000 took 0.088s
  training loss:		0.072118
  validation loss:		0.202646
  validation accuracy:		94.46 %
Epoch 457 of 2000 took 0.090s
  training loss:		0.074401
  validation loss:		0.197796
  validation accuracy:		94.24 %
Epoch 458 of 2000 took 0.059s
  training loss:		0.076293
  validation loss:		0.204715
  validation accuracy:		94.35 %
Epoch 459 of 2000 took 0.076s
  training loss:		0.073033
  validation loss:		0.196618
  validation accuracy:		94.46 %
Epoch 460 of 2000 took 0.060s
  training loss:		0.074899
  validation loss:		0.206651
  validation accuracy:		94.46 %
Epoch 461 of 2000 took 0.057s
  training loss:		0.074732
  validation loss:		0.209215
  validation accuracy:		94.57 %
Epoch 462 of 2000 took 0.054s
  training loss:		0.074594
  validation loss:		0.201304
  validation accuracy:		94.24 %
Epoch 463 of 2000 took 0.060s
  training loss:		0.075339
  validation loss:		0.200853
  validation accuracy:		94.35 %
Epoch 464 of 2000 took 0.067s
  training loss:		0.074758
  validation loss:		0.197277
  validation accuracy:		94.46 %
Epoch 465 of 2000 took 0.064s
  training loss:		0.075088
  validation loss:		0.206772
  validation accuracy:		94.02 %
Epoch 466 of 2000 took 0.062s
  training loss:		0.073947
  validation loss:		0.211746
  validation accuracy:		94.02 %
Epoch 467 of 2000 took 0.125s
  training loss:		0.074846
  validation loss:		0.201266
  validation accuracy:		94.78 %
Epoch 468 of 2000 took 0.086s
  training loss:		0.074716
  validation loss:		0.207879
  validation accuracy:		94.57 %
Epoch 469 of 2000 took 0.071s
  training loss:		0.070892
  validation loss:		0.197548
  validation accuracy:		94.78 %
Epoch 470 of 2000 took 0.085s
  training loss:		0.071086
  validation loss:		0.197843
  validation accuracy:		94.24 %
Epoch 471 of 2000 took 0.074s
  training loss:		0.070681
  validation loss:		0.212227
  validation accuracy:		94.57 %
Epoch 472 of 2000 took 0.081s
  training loss:		0.072329
  validation loss:		0.200938
  validation accuracy:		94.46 %
Epoch 473 of 2000 took 0.116s
  training loss:		0.071591
  validation loss:		0.199527
  validation accuracy:		94.57 %
Epoch 474 of 2000 took 0.072s
  training loss:		0.071897
  validation loss:		0.202024
  validation accuracy:		94.46 %
Epoch 475 of 2000 took 0.089s
  training loss:		0.071746
  validation loss:		0.210671
  validation accuracy:		94.46 %
Epoch 476 of 2000 took 0.088s
  training loss:		0.069237
  validation loss:		0.204474
  validation accuracy:		94.35 %
Epoch 477 of 2000 took 0.072s
  training loss:		0.071836
  validation loss:		0.208473
  validation accuracy:		93.80 %
Epoch 478 of 2000 took 0.064s
  training loss:		0.071323
  validation loss:		0.205107
  validation accuracy:		94.02 %
Epoch 479 of 2000 took 0.080s
  training loss:		0.070768
  validation loss:		0.210897
  validation accuracy:		93.91 %
Epoch 480 of 2000 took 0.057s
  training loss:		0.071003
  validation loss:		0.213509
  validation accuracy:		94.02 %
Epoch 481 of 2000 took 0.055s
  training loss:		0.071613
  validation loss:		0.199333
  validation accuracy:		94.57 %
Epoch 482 of 2000 took 0.055s
  training loss:		0.068187
  validation loss:		0.200750
  validation accuracy:		94.57 %
Epoch 483 of 2000 took 0.054s
  training loss:		0.070225
  validation loss:		0.203692
  validation accuracy:		94.35 %
Epoch 484 of 2000 took 0.053s
  training loss:		0.071779
  validation loss:		0.197393
  validation accuracy:		94.35 %
Epoch 485 of 2000 took 0.053s
  training loss:		0.069467
  validation loss:		0.203875
  validation accuracy:		94.24 %
Epoch 486 of 2000 took 0.053s
  training loss:		0.069688
  validation loss:		0.208694
  validation accuracy:		94.35 %
Epoch 487 of 2000 took 0.054s
  training loss:		0.068090
  validation loss:		0.212069
  validation accuracy:		94.24 %
Epoch 488 of 2000 took 0.057s
  training loss:		0.067632
  validation loss:		0.205887
  validation accuracy:		94.57 %
Epoch 489 of 2000 took 0.055s
  training loss:		0.068928
  validation loss:		0.212721
  validation accuracy:		94.13 %
Epoch 490 of 2000 took 0.057s
  training loss:		0.068884
  validation loss:		0.205112
  validation accuracy:		94.13 %
Epoch 491 of 2000 took 0.072s
  training loss:		0.068442
  validation loss:		0.201797
  validation accuracy:		94.35 %
Epoch 492 of 2000 took 0.060s
  training loss:		0.068681
  validation loss:		0.211895
  validation accuracy:		94.02 %
Epoch 493 of 2000 took 0.086s
  training loss:		0.066192
  validation loss:		0.201389
  validation accuracy:		94.35 %
Epoch 494 of 2000 took 0.061s
  training loss:		0.068305
  validation loss:		0.212680
  validation accuracy:		94.24 %
Epoch 495 of 2000 took 0.059s
  training loss:		0.068560
  validation loss:		0.209792
  validation accuracy:		94.13 %
Epoch 496 of 2000 took 0.059s
  training loss:		0.068215
  validation loss:		0.207036
  validation accuracy:		94.46 %
Epoch 497 of 2000 took 0.071s
  training loss:		0.067536
  validation loss:		0.205347
  validation accuracy:		94.24 %
Epoch 498 of 2000 took 0.058s
  training loss:		0.069055
  validation loss:		0.208175
  validation accuracy:		94.02 %
Epoch 499 of 2000 took 0.070s
  training loss:		0.068357
  validation loss:		0.207519
  validation accuracy:		94.67 %
Epoch 500 of 2000 took 0.061s
  training loss:		0.065799
  validation loss:		0.219218
  validation accuracy:		93.80 %
Epoch 501 of 2000 took 0.060s
  training loss:		0.066481
  validation loss:		0.208734
  validation accuracy:		94.24 %
Epoch 502 of 2000 took 0.068s
  training loss:		0.066209
  validation loss:		0.205846
  validation accuracy:		94.46 %
Epoch 503 of 2000 took 0.076s
  training loss:		0.066497
  validation loss:		0.217536
  validation accuracy:		94.13 %
Epoch 504 of 2000 took 0.062s
  training loss:		0.068964
  validation loss:		0.209291
  validation accuracy:		94.24 %
Epoch 505 of 2000 took 0.063s
  training loss:		0.068082
  validation loss:		0.201156
  validation accuracy:		94.35 %
Epoch 506 of 2000 took 0.056s
  training loss:		0.065936
  validation loss:		0.208536
  validation accuracy:		94.02 %
Epoch 507 of 2000 took 0.054s
  training loss:		0.067389
  validation loss:		0.210573
  validation accuracy:		93.91 %
Epoch 508 of 2000 took 0.054s
  training loss:		0.067719
  validation loss:		0.208181
  validation accuracy:		94.35 %
Epoch 509 of 2000 took 0.061s
  training loss:		0.066469
  validation loss:		0.210956
  validation accuracy:		94.24 %
Epoch 510 of 2000 took 0.057s
  training loss:		0.062270
  validation loss:		0.209669
  validation accuracy:		94.46 %
Epoch 511 of 2000 took 0.060s
  training loss:		0.066349
  validation loss:		0.211585
  validation accuracy:		94.02 %
Epoch 512 of 2000 took 0.061s
  training loss:		0.064790
  validation loss:		0.212160
  validation accuracy:		94.24 %
Epoch 513 of 2000 took 0.063s
  training loss:		0.063859
  validation loss:		0.205729
  validation accuracy:		94.35 %
Epoch 514 of 2000 took 0.062s
  training loss:		0.063284
  validation loss:		0.208101
  validation accuracy:		94.24 %
Epoch 515 of 2000 took 0.064s
  training loss:		0.065568
  validation loss:		0.212899
  validation accuracy:		94.24 %
Epoch 516 of 2000 took 0.063s
  training loss:		0.064202
  validation loss:		0.208626
  validation accuracy:		94.57 %
Epoch 517 of 2000 took 0.102s
  training loss:		0.066215
  validation loss:		0.207481
  validation accuracy:		94.46 %
Epoch 518 of 2000 took 0.080s
  training loss:		0.064991
  validation loss:		0.212594
  validation accuracy:		94.46 %
Epoch 519 of 2000 took 0.075s
  training loss:		0.062475
  validation loss:		0.210481
  validation accuracy:		94.13 %
Epoch 520 of 2000 took 0.056s
  training loss:		0.064323
  validation loss:		0.217683
  validation accuracy:		94.24 %
Epoch 521 of 2000 took 0.055s
  training loss:		0.062946
  validation loss:		0.211705
  validation accuracy:		94.24 %
Epoch 522 of 2000 took 0.059s
  training loss:		0.061106
  validation loss:		0.215611
  validation accuracy:		93.91 %
Epoch 523 of 2000 took 0.070s
  training loss:		0.062095
  validation loss:		0.214730
  validation accuracy:		94.13 %
Epoch 524 of 2000 took 0.060s
  training loss:		0.062783
  validation loss:		0.203648
  validation accuracy:		94.24 %
Epoch 525 of 2000 took 0.059s
  training loss:		0.064735
  validation loss:		0.221201
  validation accuracy:		94.13 %
Epoch 526 of 2000 took 0.107s
  training loss:		0.062029
  validation loss:		0.212733
  validation accuracy:		93.91 %
Epoch 527 of 2000 took 0.090s
  training loss:		0.061895
  validation loss:		0.220937
  validation accuracy:		94.02 %
Epoch 528 of 2000 took 0.073s
  training loss:		0.063801
  validation loss:		0.221228
  validation accuracy:		94.02 %
Epoch 529 of 2000 took 0.123s
  training loss:		0.061798
  validation loss:		0.212614
  validation accuracy:		94.46 %
Epoch 530 of 2000 took 0.139s
  training loss:		0.062373
  validation loss:		0.213532
  validation accuracy:		94.35 %
Epoch 531 of 2000 took 0.116s
  training loss:		0.060468
  validation loss:		0.213509
  validation accuracy:		94.57 %
Epoch 532 of 2000 took 0.089s
  training loss:		0.062293
  validation loss:		0.210833
  validation accuracy:		94.46 %
Epoch 533 of 2000 took 0.113s
  training loss:		0.060655
  validation loss:		0.213500
  validation accuracy:		94.46 %
Epoch 534 of 2000 took 0.121s
  training loss:		0.060970
  validation loss:		0.214764
  validation accuracy:		94.02 %
Epoch 535 of 2000 took 0.080s
  training loss:		0.061339
  validation loss:		0.216098
  validation accuracy:		94.57 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.060056
  validation loss:		0.222492
  validation accuracy:		94.24 %
Epoch 537 of 2000 took 0.144s
  training loss:		0.060740
  validation loss:		0.211344
  validation accuracy:		94.24 %
Epoch 538 of 2000 took 0.066s
  training loss:		0.059433
  validation loss:		0.216651
  validation accuracy:		94.24 %
Epoch 539 of 2000 took 0.062s
  training loss:		0.060334
  validation loss:		0.215507
  validation accuracy:		94.46 %
Epoch 540 of 2000 took 0.063s
  training loss:		0.058039
  validation loss:		0.212346
  validation accuracy:		94.02 %
Epoch 541 of 2000 took 0.070s
  training loss:		0.060957
  validation loss:		0.212500
  validation accuracy:		94.13 %
Epoch 542 of 2000 took 0.063s
  training loss:		0.058576
  validation loss:		0.219089
  validation accuracy:		94.46 %
Epoch 543 of 2000 took 0.059s
  training loss:		0.058216
  validation loss:		0.219424
  validation accuracy:		94.24 %
Epoch 544 of 2000 took 0.059s
  training loss:		0.059260
  validation loss:		0.225683
  validation accuracy:		94.35 %
Epoch 545 of 2000 took 0.078s
  training loss:		0.059063
  validation loss:		0.210254
  validation accuracy:		94.46 %
Epoch 546 of 2000 took 0.082s
  training loss:		0.059995
  validation loss:		0.213655
  validation accuracy:		94.02 %
Epoch 547 of 2000 took 0.089s
  training loss:		0.060006
  validation loss:		0.222146
  validation accuracy:		94.24 %
Epoch 548 of 2000 took 0.080s
  training loss:		0.057107
  validation loss:		0.213223
  validation accuracy:		94.35 %
Epoch 549 of 2000 took 0.061s
  training loss:		0.057949
  validation loss:		0.215731
  validation accuracy:		94.46 %
Epoch 550 of 2000 took 0.055s
  training loss:		0.056692
  validation loss:		0.213426
  validation accuracy:		94.13 %
Epoch 551 of 2000 took 0.067s
  training loss:		0.059880
  validation loss:		0.221266
  validation accuracy:		94.24 %
Epoch 552 of 2000 took 0.058s
  training loss:		0.058292
  validation loss:		0.222458
  validation accuracy:		94.02 %
Epoch 553 of 2000 took 0.058s
  training loss:		0.060004
  validation loss:		0.218208
  validation accuracy:		94.13 %
Epoch 554 of 2000 took 0.058s
  training loss:		0.058815
  validation loss:		0.210403
  validation accuracy:		94.35 %
Epoch 555 of 2000 took 0.063s
  training loss:		0.057650
  validation loss:		0.211160
  validation accuracy:		94.35 %
Epoch 556 of 2000 took 0.082s
  training loss:		0.059340
  validation loss:		0.211525
  validation accuracy:		94.46 %
Epoch 557 of 2000 took 0.067s
  training loss:		0.057990
  validation loss:		0.212388
  validation accuracy:		94.57 %
Epoch 558 of 2000 took 0.060s
  training loss:		0.058826
  validation loss:		0.214652
  validation accuracy:		94.57 %
Epoch 559 of 2000 took 0.056s
  training loss:		0.056632
  validation loss:		0.219496
  validation accuracy:		94.24 %
Epoch 560 of 2000 took 0.058s
  training loss:		0.057382
  validation loss:		0.218702
  validation accuracy:		94.35 %
Epoch 561 of 2000 took 0.068s
  training loss:		0.056147
  validation loss:		0.214262
  validation accuracy:		94.46 %
Epoch 562 of 2000 took 0.085s
  training loss:		0.059703
  validation loss:		0.216487
  validation accuracy:		94.35 %
Epoch 563 of 2000 took 0.072s
  training loss:		0.055967
  validation loss:		0.212800
  validation accuracy:		94.46 %
Epoch 564 of 2000 took 0.076s
  training loss:		0.055735
  validation loss:		0.214777
  validation accuracy:		94.67 %
Epoch 565 of 2000 took 0.076s
  training loss:		0.056208
  validation loss:		0.213957
  validation accuracy:		94.13 %
Epoch 566 of 2000 took 0.084s
  training loss:		0.056784
  validation loss:		0.213274
  validation accuracy:		94.57 %
Epoch 567 of 2000 took 0.083s
  training loss:		0.057408
  validation loss:		0.224760
  validation accuracy:		93.91 %
Epoch 568 of 2000 took 0.082s
  training loss:		0.056283
  validation loss:		0.228253
  validation accuracy:		94.46 %
Epoch 569 of 2000 took 0.057s
  training loss:		0.056428
  validation loss:		0.219533
  validation accuracy:		94.67 %
Epoch 570 of 2000 took 0.056s
  training loss:		0.058002
  validation loss:		0.221982
  validation accuracy:		94.35 %
Epoch 571 of 2000 took 0.056s
  training loss:		0.054839
  validation loss:		0.217233
  validation accuracy:		94.46 %
Epoch 572 of 2000 took 0.057s
  training loss:		0.054846
  validation loss:		0.220646
  validation accuracy:		94.13 %
Epoch 573 of 2000 took 0.054s
  training loss:		0.053179
  validation loss:		0.215896
  validation accuracy:		94.46 %
Epoch 574 of 2000 took 0.059s
  training loss:		0.057148
  validation loss:		0.225703
  validation accuracy:		94.02 %
Epoch 575 of 2000 took 0.061s
  training loss:		0.056002
  validation loss:		0.219613
  validation accuracy:		94.35 %
Epoch 576 of 2000 took 0.077s
  training loss:		0.053002
  validation loss:		0.210861
  validation accuracy:		94.35 %
Epoch 577 of 2000 took 0.061s
  training loss:		0.056146
  validation loss:		0.225462
  validation accuracy:		94.46 %
Epoch 578 of 2000 took 0.058s
  training loss:		0.055768
  validation loss:		0.217247
  validation accuracy:		94.57 %
Epoch 579 of 2000 took 0.059s
  training loss:		0.053508
  validation loss:		0.222475
  validation accuracy:		94.35 %
Epoch 580 of 2000 took 0.058s
  training loss:		0.054955
  validation loss:		0.221944
  validation accuracy:		94.46 %
Epoch 581 of 2000 took 0.057s
  training loss:		0.054049
  validation loss:		0.223101
  validation accuracy:		94.24 %
Epoch 582 of 2000 took 0.061s
  training loss:		0.054764
  validation loss:		0.213605
  validation accuracy:		94.67 %
Epoch 583 of 2000 took 0.059s
  training loss:		0.055307
  validation loss:		0.227292
  validation accuracy:		94.13 %
Epoch 584 of 2000 took 0.061s
  training loss:		0.054031
  validation loss:		0.228860
  validation accuracy:		94.35 %
Epoch 585 of 2000 took 0.060s
  training loss:		0.053074
  validation loss:		0.225984
  validation accuracy:		94.02 %
Epoch 586 of 2000 took 0.057s
  training loss:		0.053334
  validation loss:		0.211888
  validation accuracy:		94.46 %
Epoch 587 of 2000 took 0.066s
  training loss:		0.053436
  validation loss:		0.230705
  validation accuracy:		94.13 %
Epoch 588 of 2000 took 0.062s
  training loss:		0.052681
  validation loss:		0.220798
  validation accuracy:		94.13 %
Epoch 589 of 2000 took 0.055s
  training loss:		0.053086
  validation loss:		0.222376
  validation accuracy:		94.46 %
Epoch 590 of 2000 took 0.054s
  training loss:		0.051945
  validation loss:		0.216538
  validation accuracy:		94.46 %
Epoch 591 of 2000 took 0.055s
  training loss:		0.055309
  validation loss:		0.223085
  validation accuracy:		94.24 %
Epoch 592 of 2000 took 0.055s
  training loss:		0.053178
  validation loss:		0.226959
  validation accuracy:		94.24 %
Epoch 593 of 2000 took 0.058s
  training loss:		0.051727
  validation loss:		0.223273
  validation accuracy:		94.02 %
Epoch 594 of 2000 took 0.074s
  training loss:		0.052036
  validation loss:		0.220715
  validation accuracy:		94.24 %
Epoch 595 of 2000 took 0.075s
  training loss:		0.052521
  validation loss:		0.222837
  validation accuracy:		94.24 %
Epoch 596 of 2000 took 0.060s
  training loss:		0.053776
  validation loss:		0.218304
  validation accuracy:		94.24 %
Epoch 597 of 2000 took 0.055s
  training loss:		0.053443
  validation loss:		0.225461
  validation accuracy:		94.35 %
Epoch 598 of 2000 took 0.057s
  training loss:		0.051834
  validation loss:		0.228994
  validation accuracy:		93.80 %
Epoch 599 of 2000 took 0.057s
  training loss:		0.052152
  validation loss:		0.222814
  validation accuracy:		94.13 %
Epoch 600 of 2000 took 0.058s
  training loss:		0.052498
  validation loss:		0.222245
  validation accuracy:		94.46 %
Epoch 601 of 2000 took 0.054s
  training loss:		0.051234
  validation loss:		0.218633
  validation accuracy:		94.24 %
Epoch 602 of 2000 took 0.055s
  training loss:		0.052641
  validation loss:		0.226045
  validation accuracy:		94.24 %
Epoch 603 of 2000 took 0.054s
  training loss:		0.049845
  validation loss:		0.217812
  validation accuracy:		94.24 %
Epoch 604 of 2000 took 0.058s
  training loss:		0.050745
  validation loss:		0.228136
  validation accuracy:		94.46 %
Epoch 605 of 2000 took 0.056s
  training loss:		0.051683
  validation loss:		0.228131
  validation accuracy:		94.35 %
Epoch 606 of 2000 took 0.055s
  training loss:		0.051550
  validation loss:		0.225457
  validation accuracy:		94.46 %
Epoch 607 of 2000 took 0.053s
  training loss:		0.051690
  validation loss:		0.221290
  validation accuracy:		94.46 %
Epoch 608 of 2000 took 0.054s
  training loss:		0.050498
  validation loss:		0.215403
  validation accuracy:		94.35 %
Epoch 609 of 2000 took 0.055s
  training loss:		0.051978
  validation loss:		0.225634
  validation accuracy:		94.35 %
Epoch 610 of 2000 took 0.064s
  training loss:		0.047948
  validation loss:		0.224539
  validation accuracy:		94.02 %
Epoch 611 of 2000 took 0.068s
  training loss:		0.049373
  validation loss:		0.226796
  validation accuracy:		94.46 %
Epoch 612 of 2000 took 0.062s
  training loss:		0.051009
  validation loss:		0.222977
  validation accuracy:		94.24 %
Epoch 613 of 2000 took 0.086s
  training loss:		0.047594
  validation loss:		0.230765
  validation accuracy:		94.35 %
Epoch 614 of 2000 took 0.058s
  training loss:		0.050314
  validation loss:		0.220576
  validation accuracy:		94.35 %
Epoch 615 of 2000 took 0.054s
  training loss:		0.050759
  validation loss:		0.232133
  validation accuracy:		94.02 %
Epoch 616 of 2000 took 0.056s
  training loss:		0.049194
  validation loss:		0.227711
  validation accuracy:		94.35 %
Epoch 617 of 2000 took 0.057s
  training loss:		0.050225
  validation loss:		0.224888
  validation accuracy:		93.80 %
Epoch 618 of 2000 took 0.054s
  training loss:		0.047982
  validation loss:		0.225651
  validation accuracy:		94.46 %
Epoch 619 of 2000 took 0.060s
  training loss:		0.048994
  validation loss:		0.225865
  validation accuracy:		94.13 %
Epoch 620 of 2000 took 0.054s
  training loss:		0.049758
  validation loss:		0.230401
  validation accuracy:		94.46 %
Epoch 621 of 2000 took 0.060s
  training loss:		0.049681
  validation loss:		0.235672
  validation accuracy:		94.02 %
Epoch 622 of 2000 took 0.055s
  training loss:		0.051751
  validation loss:		0.228703
  validation accuracy:		94.24 %
Epoch 623 of 2000 took 0.055s
  training loss:		0.048680
  validation loss:		0.229302
  validation accuracy:		94.13 %
Epoch 624 of 2000 took 0.054s
  training loss:		0.049418
  validation loss:		0.239653
  validation accuracy:		93.59 %
Epoch 625 of 2000 took 0.054s
  training loss:		0.049173
  validation loss:		0.228821
  validation accuracy:		94.46 %
Epoch 626 of 2000 took 0.055s
  training loss:		0.049667
  validation loss:		0.228817
  validation accuracy:		94.13 %
Epoch 627 of 2000 took 0.060s
  training loss:		0.049833
  validation loss:		0.222834
  validation accuracy:		94.46 %
Epoch 628 of 2000 took 0.056s
  training loss:		0.047104
  validation loss:		0.233651
  validation accuracy:		94.13 %
Epoch 629 of 2000 took 0.058s
  training loss:		0.045674
  validation loss:		0.231960
  validation accuracy:		93.91 %
Epoch 630 of 2000 took 0.060s
  training loss:		0.049196
  validation loss:		0.232260
  validation accuracy:		94.02 %
Epoch 631 of 2000 took 0.058s
  training loss:		0.048978
  validation loss:		0.230521
  validation accuracy:		94.24 %
Epoch 632 of 2000 took 0.058s
  training loss:		0.048315
  validation loss:		0.227918
  validation accuracy:		94.24 %
Epoch 633 of 2000 took 0.054s
  training loss:		0.047278
  validation loss:		0.245897
  validation accuracy:		93.59 %
Epoch 634 of 2000 took 0.055s
  training loss:		0.049507
  validation loss:		0.228923
  validation accuracy:		94.02 %
Epoch 635 of 2000 took 0.056s
  training loss:		0.047654
  validation loss:		0.241744
  validation accuracy:		93.48 %
Epoch 636 of 2000 took 0.057s
  training loss:		0.048532
  validation loss:		0.236478
  validation accuracy:		94.46 %
Epoch 637 of 2000 took 0.057s
  training loss:		0.047052
  validation loss:		0.233729
  validation accuracy:		93.91 %
Epoch 638 of 2000 took 0.066s
  training loss:		0.045988
  validation loss:		0.229651
  validation accuracy:		94.02 %
Epoch 639 of 2000 took 0.079s
  training loss:		0.046776
  validation loss:		0.230464
  validation accuracy:		94.35 %
Epoch 640 of 2000 took 0.071s
  training loss:		0.046258
  validation loss:		0.240465
  validation accuracy:		93.91 %
Epoch 641 of 2000 took 0.074s
  training loss:		0.047793
  validation loss:		0.231570
  validation accuracy:		94.24 %
Epoch 642 of 2000 took 0.068s
  training loss:		0.047686
  validation loss:		0.233813
  validation accuracy:		94.35 %
Epoch 643 of 2000 took 0.066s
  training loss:		0.047549
  validation loss:		0.231637
  validation accuracy:		94.02 %
Epoch 644 of 2000 took 0.087s
  training loss:		0.046866
  validation loss:		0.227354
  validation accuracy:		94.35 %
Epoch 645 of 2000 took 0.076s
  training loss:		0.045591
  validation loss:		0.231805
  validation accuracy:		94.13 %
Epoch 646 of 2000 took 0.059s
  training loss:		0.047260
  validation loss:		0.234977
  validation accuracy:		94.46 %
Epoch 647 of 2000 took 0.064s
  training loss:		0.046163
  validation loss:		0.225343
  validation accuracy:		94.24 %
Epoch 648 of 2000 took 0.064s
  training loss:		0.046315
  validation loss:		0.230095
  validation accuracy:		94.24 %
Epoch 649 of 2000 took 0.064s
  training loss:		0.046757
  validation loss:		0.239370
  validation accuracy:		94.24 %
Epoch 650 of 2000 took 0.064s
  training loss:		0.045787
  validation loss:		0.228489
  validation accuracy:		94.24 %
Epoch 651 of 2000 took 0.068s
  training loss:		0.047090
  validation loss:		0.240126
  validation accuracy:		93.91 %
Epoch 652 of 2000 took 0.065s
  training loss:		0.046501
  validation loss:		0.228133
  validation accuracy:		94.35 %
Epoch 653 of 2000 took 0.071s
  training loss:		0.046417
  validation loss:		0.231091
  validation accuracy:		94.13 %
Epoch 654 of 2000 took 0.068s
  training loss:		0.044351
  validation loss:		0.237262
  validation accuracy:		94.13 %
Epoch 655 of 2000 took 0.071s
  training loss:		0.046299
  validation loss:		0.243785
  validation accuracy:		93.59 %
Epoch 656 of 2000 took 0.069s
  training loss:		0.045484
  validation loss:		0.232087
  validation accuracy:		94.46 %
Epoch 657 of 2000 took 0.071s
  training loss:		0.044916
  validation loss:		0.235061
  validation accuracy:		94.35 %
Epoch 658 of 2000 took 0.068s
  training loss:		0.043776
  validation loss:		0.230564
  validation accuracy:		94.24 %
Epoch 659 of 2000 took 0.063s
  training loss:		0.045468
  validation loss:		0.233485
  validation accuracy:		93.91 %
Epoch 660 of 2000 took 0.062s
  training loss:		0.045695
  validation loss:		0.238212
  validation accuracy:		93.91 %
Epoch 661 of 2000 took 0.065s
  training loss:		0.046646
  validation loss:		0.231343
  validation accuracy:		94.24 %
Epoch 662 of 2000 took 0.056s
  training loss:		0.043876
  validation loss:		0.240754
  validation accuracy:		93.80 %
Epoch 663 of 2000 took 0.055s
  training loss:		0.043510
  validation loss:		0.237488
  validation accuracy:		94.24 %
Epoch 664 of 2000 took 0.058s
  training loss:		0.045907
  validation loss:		0.234171
  validation accuracy:		93.91 %
Epoch 665 of 2000 took 0.058s
  training loss:		0.045350
  validation loss:		0.233822
  validation accuracy:		94.13 %
Epoch 666 of 2000 took 0.070s
  training loss:		0.041534
  validation loss:		0.241045
  validation accuracy:		94.02 %
Epoch 667 of 2000 took 0.071s
  training loss:		0.043661
  validation loss:		0.248820
  validation accuracy:		93.80 %
Epoch 668 of 2000 took 0.070s
  training loss:		0.043976
  validation loss:		0.239441
  validation accuracy:		94.24 %
Epoch 669 of 2000 took 0.074s
  training loss:		0.044141
  validation loss:		0.231603
  validation accuracy:		94.02 %
Epoch 670 of 2000 took 0.066s
  training loss:		0.044135
  validation loss:		0.241537
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.071s
  training loss:		0.043614
  validation loss:		0.231855
  validation accuracy:		94.35 %
Epoch 672 of 2000 took 0.068s
  training loss:		0.042809
  validation loss:		0.247184
  validation accuracy:		93.70 %
Epoch 673 of 2000 took 0.065s
  training loss:		0.044132
  validation loss:		0.233752
  validation accuracy:		94.24 %
Epoch 674 of 2000 took 0.058s
  training loss:		0.041921
  validation loss:		0.241659
  validation accuracy:		94.35 %
Epoch 675 of 2000 took 0.068s
  training loss:		0.041569
  validation loss:		0.234564
  validation accuracy:		93.91 %
Epoch 676 of 2000 took 0.070s
  training loss:		0.042565
  validation loss:		0.229696
  validation accuracy:		94.13 %
Epoch 677 of 2000 took 0.061s
  training loss:		0.042219
  validation loss:		0.234800
  validation accuracy:		94.46 %
Epoch 678 of 2000 took 0.060s
  training loss:		0.042955
  validation loss:		0.239805
  validation accuracy:		94.24 %
Epoch 679 of 2000 took 0.059s
  training loss:		0.041891
  validation loss:		0.238075
  validation accuracy:		94.24 %
Epoch 680 of 2000 took 0.071s
  training loss:		0.043236
  validation loss:		0.240031
  validation accuracy:		94.02 %
Epoch 681 of 2000 took 0.081s
  training loss:		0.041685
  validation loss:		0.237749
  validation accuracy:		94.13 %
Epoch 682 of 2000 took 0.076s
  training loss:		0.041268
  validation loss:		0.237775
  validation accuracy:		94.24 %
Epoch 683 of 2000 took 0.075s
  training loss:		0.041875
  validation loss:		0.245854
  validation accuracy:		93.59 %
Epoch 684 of 2000 took 0.061s
  training loss:		0.043999
  validation loss:		0.244563
  validation accuracy:		94.13 %
Epoch 685 of 2000 took 0.087s
  training loss:		0.041752
  validation loss:		0.236281
  validation accuracy:		94.13 %
Epoch 686 of 2000 took 0.064s
  training loss:		0.042129
  validation loss:		0.243669
  validation accuracy:		94.35 %
Epoch 687 of 2000 took 0.063s
  training loss:		0.041890
  validation loss:		0.249047
  validation accuracy:		94.13 %
Epoch 688 of 2000 took 0.060s
  training loss:		0.043233
  validation loss:		0.241579
  validation accuracy:		94.02 %
Epoch 689 of 2000 took 0.059s
  training loss:		0.042156
  validation loss:		0.230019
  validation accuracy:		94.67 %
Epoch 690 of 2000 took 0.057s
  training loss:		0.042788
  validation loss:		0.239925
  validation accuracy:		94.24 %
Epoch 691 of 2000 took 0.059s
  training loss:		0.041492
  validation loss:		0.237746
  validation accuracy:		94.13 %
Epoch 692 of 2000 took 0.058s
  training loss:		0.040787
  validation loss:		0.233793
  validation accuracy:		94.46 %
Epoch 693 of 2000 took 0.063s
  training loss:		0.040614
  validation loss:		0.237713
  validation accuracy:		94.35 %
Epoch 694 of 2000 took 0.103s
  training loss:		0.041663
  validation loss:		0.241564
  validation accuracy:		94.13 %
Epoch 695 of 2000 took 0.104s
  training loss:		0.041845
  validation loss:		0.246379
  validation accuracy:		93.70 %
Epoch 696 of 2000 took 0.092s
  training loss:		0.041812
  validation loss:		0.249281
  validation accuracy:		94.02 %
Epoch 697 of 2000 took 0.104s
  training loss:		0.041735
  validation loss:		0.236284
  validation accuracy:		94.13 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.040963
  validation loss:		0.234729
  validation accuracy:		94.24 %
Epoch 699 of 2000 took 0.077s
  training loss:		0.041807
  validation loss:		0.251360
  validation accuracy:		93.91 %
Epoch 700 of 2000 took 0.068s
  training loss:		0.039801
  validation loss:		0.246562
  validation accuracy:		93.80 %
Epoch 701 of 2000 took 0.073s
  training loss:		0.040197
  validation loss:		0.242506
  validation accuracy:		94.24 %
Epoch 702 of 2000 took 0.109s
  training loss:		0.040985
  validation loss:		0.245673
  validation accuracy:		93.70 %
Epoch 703 of 2000 took 0.096s
  training loss:		0.038979
  validation loss:		0.244804
  validation accuracy:		94.13 %
Epoch 704 of 2000 took 0.087s
  training loss:		0.039629
  validation loss:		0.245242
  validation accuracy:		94.13 %
Epoch 705 of 2000 took 0.091s
  training loss:		0.039582
  validation loss:		0.237754
  validation accuracy:		93.91 %
Epoch 706 of 2000 took 0.075s
  training loss:		0.040504
  validation loss:		0.251887
  validation accuracy:		93.70 %
Epoch 707 of 2000 took 0.067s
  training loss:		0.040558
  validation loss:		0.241496
  validation accuracy:		94.02 %
Epoch 708 of 2000 took 0.069s
  training loss:		0.039559
  validation loss:		0.244372
  validation accuracy:		94.24 %
Epoch 709 of 2000 took 0.063s
  training loss:		0.040074
  validation loss:		0.237224
  validation accuracy:		94.13 %
Epoch 710 of 2000 took 0.072s
  training loss:		0.039549
  validation loss:		0.245729
  validation accuracy:		93.80 %
Epoch 711 of 2000 took 0.074s
  training loss:		0.038399
  validation loss:		0.238896
  validation accuracy:		93.80 %
Epoch 712 of 2000 took 0.060s
  training loss:		0.039963
  validation loss:		0.247325
  validation accuracy:		93.91 %
Epoch 713 of 2000 took 0.061s
  training loss:		0.038540
  validation loss:		0.240550
  validation accuracy:		93.91 %
Epoch 714 of 2000 took 0.072s
  training loss:		0.038291
  validation loss:		0.249799
  validation accuracy:		93.80 %
Epoch 715 of 2000 took 0.105s
  training loss:		0.038871
  validation loss:		0.249875
  validation accuracy:		93.91 %
Epoch 716 of 2000 took 0.248s
  training loss:		0.038889
  validation loss:		0.257085
  validation accuracy:		93.59 %
Epoch 717 of 2000 took 0.124s
  training loss:		0.039871
  validation loss:		0.248200
  validation accuracy:		93.80 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.037630
  validation loss:		0.243200
  validation accuracy:		94.13 %
Epoch 719 of 2000 took 0.099s
  training loss:		0.039695
  validation loss:		0.244823
  validation accuracy:		94.02 %
Epoch 720 of 2000 took 0.081s
  training loss:		0.038509
  validation loss:		0.246398
  validation accuracy:		94.13 %
Epoch 721 of 2000 took 0.095s
  training loss:		0.038120
  validation loss:		0.241331
  validation accuracy:		93.80 %
Epoch 722 of 2000 took 0.137s
  training loss:		0.038708
  validation loss:		0.248020
  validation accuracy:		93.80 %
Epoch 723 of 2000 took 0.103s
  training loss:		0.038093
  validation loss:		0.258570
  validation accuracy:		93.59 %
Epoch 724 of 2000 took 0.123s
  training loss:		0.039022
  validation loss:		0.250645
  validation accuracy:		93.70 %
Epoch 725 of 2000 took 0.273s
  training loss:		0.039528
  validation loss:		0.248059
  validation accuracy:		93.70 %
Epoch 726 of 2000 took 0.169s
  training loss:		0.037028
  validation loss:		0.245289
  validation accuracy:		94.02 %
Epoch 727 of 2000 took 0.121s
  training loss:		0.037073
  validation loss:		0.250379
  validation accuracy:		93.91 %
Epoch 728 of 2000 took 0.100s
  training loss:		0.038466
  validation loss:		0.247206
  validation accuracy:		94.02 %
Epoch 729 of 2000 took 0.095s
  training loss:		0.036614
  validation loss:		0.242022
  validation accuracy:		94.13 %
Epoch 730 of 2000 took 0.101s
  training loss:		0.039672
  validation loss:		0.251357
  validation accuracy:		94.24 %
Epoch 731 of 2000 took 0.092s
  training loss:		0.038134
  validation loss:		0.254932
  validation accuracy:		94.02 %
Epoch 732 of 2000 took 0.084s
  training loss:		0.037940
  validation loss:		0.245314
  validation accuracy:		93.91 %
Epoch 733 of 2000 took 0.106s
  training loss:		0.037352
  validation loss:		0.250979
  validation accuracy:		93.91 %
Epoch 734 of 2000 took 0.122s
  training loss:		0.035725
  validation loss:		0.250075
  validation accuracy:		94.24 %
Epoch 735 of 2000 took 0.099s
  training loss:		0.038085
  validation loss:		0.248129
  validation accuracy:		93.70 %
Epoch 736 of 2000 took 0.087s
  training loss:		0.036287
  validation loss:		0.249840
  validation accuracy:		93.91 %
Epoch 737 of 2000 took 0.089s
  training loss:		0.036984
  validation loss:		0.248048
  validation accuracy:		93.91 %
Epoch 738 of 2000 took 0.104s
  training loss:		0.037597
  validation loss:		0.251115
  validation accuracy:		94.13 %
Epoch 739 of 2000 took 0.166s
  training loss:		0.036157
  validation loss:		0.255196
  validation accuracy:		93.91 %
Epoch 740 of 2000 took 0.117s
  training loss:		0.037776
  validation loss:		0.255327
  validation accuracy:		94.24 %
Epoch 741 of 2000 took 0.093s
  training loss:		0.036966
  validation loss:		0.248229
  validation accuracy:		93.91 %
Epoch 742 of 2000 took 0.114s
  training loss:		0.036516
  validation loss:		0.263023
  validation accuracy:		93.70 %
Epoch 743 of 2000 took 0.108s
  training loss:		0.036824
  validation loss:		0.262604
  validation accuracy:		93.80 %
Epoch 744 of 2000 took 0.128s
  training loss:		0.034831
  validation loss:		0.256024
  validation accuracy:		93.80 %
Epoch 745 of 2000 took 0.092s
  training loss:		0.036317
  validation loss:		0.257119
  validation accuracy:		94.13 %
Epoch 746 of 2000 took 0.098s
  training loss:		0.035689
  validation loss:		0.264948
  validation accuracy:		93.59 %
Epoch 747 of 2000 took 0.232s
  training loss:		0.035536
  validation loss:		0.248485
  validation accuracy:		94.02 %
Epoch 748 of 2000 took 0.088s
  training loss:		0.034250
  validation loss:		0.251658
  validation accuracy:		93.80 %
Epoch 749 of 2000 took 0.085s
  training loss:		0.036007
  validation loss:		0.258461
  validation accuracy:		94.13 %
Epoch 750 of 2000 took 0.080s
  training loss:		0.036056
  validation loss:		0.251049
  validation accuracy:		93.91 %
Epoch 751 of 2000 took 0.087s
  training loss:		0.035939
  validation loss:		0.258883
  validation accuracy:		93.91 %
Epoch 752 of 2000 took 0.080s
  training loss:		0.035778
  validation loss:		0.258825
  validation accuracy:		93.70 %
Epoch 753 of 2000 took 0.093s
  training loss:		0.034128
  validation loss:		0.253721
  validation accuracy:		94.24 %
Epoch 754 of 2000 took 0.071s
  training loss:		0.036773
  validation loss:		0.245901
  validation accuracy:		94.02 %
Epoch 755 of 2000 took 0.073s
  training loss:		0.033158
  validation loss:		0.247269
  validation accuracy:		93.91 %
Epoch 756 of 2000 took 0.073s
  training loss:		0.033877
  validation loss:		0.262350
  validation accuracy:		93.59 %
Epoch 757 of 2000 took 0.087s
  training loss:		0.035538
  validation loss:		0.264044
  validation accuracy:		93.70 %
Epoch 758 of 2000 took 0.075s
  training loss:		0.035343
  validation loss:		0.267746
  validation accuracy:		93.80 %
Epoch 759 of 2000 took 0.076s
  training loss:		0.034909
  validation loss:		0.251322
  validation accuracy:		93.80 %
Epoch 760 of 2000 took 0.078s
  training loss:		0.035023
  validation loss:		0.255420
  validation accuracy:		94.02 %
Epoch 761 of 2000 took 0.079s
  training loss:		0.034524
  validation loss:		0.258073
  validation accuracy:		93.91 %
Epoch 762 of 2000 took 0.084s
  training loss:		0.034847
  validation loss:		0.261255
  validation accuracy:		94.02 %
Epoch 763 of 2000 took 0.077s
  training loss:		0.033657
  validation loss:		0.254270
  validation accuracy:		93.80 %
Epoch 764 of 2000 took 0.073s
  training loss:		0.034060
  validation loss:		0.254136
  validation accuracy:		94.13 %
Epoch 765 of 2000 took 0.062s
  training loss:		0.035806
  validation loss:		0.254252
  validation accuracy:		93.91 %
Epoch 766 of 2000 took 0.068s
  training loss:		0.034712
  validation loss:		0.256051
  validation accuracy:		94.24 %
Epoch 767 of 2000 took 0.061s
  training loss:		0.034587
  validation loss:		0.260825
  validation accuracy:		93.80 %
Epoch 768 of 2000 took 0.084s
  training loss:		0.033227
  validation loss:		0.254022
  validation accuracy:		94.13 %
Epoch 769 of 2000 took 0.072s
  training loss:		0.033909
  validation loss:		0.246870
  validation accuracy:		94.13 %
Epoch 770 of 2000 took 0.067s
  training loss:		0.033810
  validation loss:		0.257576
  validation accuracy:		93.91 %
Epoch 771 of 2000 took 0.068s
  training loss:		0.034076
  validation loss:		0.258961
  validation accuracy:		93.91 %
Epoch 772 of 2000 took 0.072s
  training loss:		0.033514
  validation loss:		0.262267
  validation accuracy:		93.80 %
Epoch 773 of 2000 took 0.067s
  training loss:		0.032255
  validation loss:		0.249182
  validation accuracy:		94.02 %
Epoch 774 of 2000 took 0.066s
  training loss:		0.034119
  validation loss:		0.254577
  validation accuracy:		93.70 %
Epoch 775 of 2000 took 0.064s
  training loss:		0.034145
  validation loss:		0.252945
  validation accuracy:		93.70 %
Epoch 776 of 2000 took 0.065s
  training loss:		0.032567
  validation loss:		0.258090
  validation accuracy:		94.24 %
Epoch 777 of 2000 took 0.067s
  training loss:		0.032769
  validation loss:		0.258496
  validation accuracy:		94.02 %
Epoch 778 of 2000 took 0.064s
  training loss:		0.033851
  validation loss:		0.256818
  validation accuracy:		94.02 %
Epoch 779 of 2000 took 0.069s
  training loss:		0.034018
  validation loss:		0.264895
  validation accuracy:		94.13 %
Epoch 780 of 2000 took 0.086s
  training loss:		0.033421
  validation loss:		0.266427
  validation accuracy:		93.70 %
Epoch 781 of 2000 took 0.075s
  training loss:		0.034055
  validation loss:		0.261249
  validation accuracy:		93.80 %
Epoch 782 of 2000 took 0.082s
  training loss:		0.032935
  validation loss:		0.263196
  validation accuracy:		93.91 %
Epoch 783 of 2000 took 0.080s
  training loss:		0.033355
  validation loss:		0.259631
  validation accuracy:		94.02 %
Epoch 784 of 2000 took 0.080s
  training loss:		0.032161
  validation loss:		0.269043
  validation accuracy:		93.91 %
Epoch 785 of 2000 took 0.081s
  training loss:		0.033052
  validation loss:		0.254436
  validation accuracy:		94.02 %
Epoch 786 of 2000 took 0.083s
  training loss:		0.032955
  validation loss:		0.269661
  validation accuracy:		93.80 %
Epoch 787 of 2000 took 0.112s
  training loss:		0.032818
  validation loss:		0.266216
  validation accuracy:		93.80 %
Epoch 788 of 2000 took 0.089s
  training loss:		0.032006
  validation loss:		0.267327
  validation accuracy:		94.02 %
Epoch 789 of 2000 took 0.079s
  training loss:		0.033366
  validation loss:		0.257442
  validation accuracy:		94.24 %
Epoch 790 of 2000 took 0.071s
  training loss:		0.033270
  validation loss:		0.254356
  validation accuracy:		94.02 %
Epoch 791 of 2000 took 0.068s
  training loss:		0.033257
  validation loss:		0.258870
  validation accuracy:		93.80 %
Epoch 792 of 2000 took 0.066s
  training loss:		0.032936
  validation loss:		0.268201
  validation accuracy:		93.91 %
Epoch 793 of 2000 took 0.074s
  training loss:		0.031557
  validation loss:		0.260218
  validation accuracy:		93.80 %
Epoch 794 of 2000 took 0.069s
  training loss:		0.031901
  validation loss:		0.265103
  validation accuracy:		93.80 %
Epoch 795 of 2000 took 0.094s
  training loss:		0.031657
  validation loss:		0.264644
  validation accuracy:		94.02 %
Epoch 796 of 2000 took 0.091s
  training loss:		0.031733
  validation loss:		0.271557
  validation accuracy:		93.91 %
Epoch 797 of 2000 took 0.078s
  training loss:		0.032552
  validation loss:		0.260442
  validation accuracy:		93.91 %
Epoch 798 of 2000 took 0.078s
  training loss:		0.031050
  validation loss:		0.272346
  validation accuracy:		93.59 %
Epoch 799 of 2000 took 0.076s
  training loss:		0.031686
  validation loss:		0.268011
  validation accuracy:		93.80 %
Epoch 800 of 2000 took 0.074s
  training loss:		0.031698
  validation loss:		0.262771
  validation accuracy:		93.80 %
Epoch 801 of 2000 took 0.078s
  training loss:		0.032246
  validation loss:		0.256995
  validation accuracy:		94.35 %
Epoch 802 of 2000 took 0.074s
  training loss:		0.030572
  validation loss:		0.261022
  validation accuracy:		93.80 %
Epoch 803 of 2000 took 0.077s
  training loss:		0.032297
  validation loss:		0.275965
  validation accuracy:		93.70 %
Epoch 804 of 2000 took 0.073s
  training loss:		0.031454
  validation loss:		0.264223
  validation accuracy:		93.80 %
Epoch 805 of 2000 took 0.082s
  training loss:		0.030327
  validation loss:		0.274761
  validation accuracy:		93.80 %
Epoch 806 of 2000 took 0.093s
  training loss:		0.030906
  validation loss:		0.266799
  validation accuracy:		93.80 %
Epoch 807 of 2000 took 0.116s
  training loss:		0.032014
  validation loss:		0.280815
  validation accuracy:		93.70 %
Epoch 808 of 2000 took 0.074s
  training loss:		0.031063
  validation loss:		0.269015
  validation accuracy:		94.02 %
Epoch 809 of 2000 took 0.077s
  training loss:		0.030962
  validation loss:		0.258549
  validation accuracy:		93.91 %
Epoch 810 of 2000 took 0.074s
  training loss:		0.029938
  validation loss:		0.274183
  validation accuracy:		93.59 %
Epoch 811 of 2000 took 0.081s
  training loss:		0.030923
  validation loss:		0.281746
  validation accuracy:		93.59 %
Epoch 812 of 2000 took 0.072s
  training loss:		0.029905
  validation loss:		0.273495
  validation accuracy:		93.70 %
Epoch 813 of 2000 took 0.076s
  training loss:		0.030263
  validation loss:		0.274157
  validation accuracy:		93.70 %
Epoch 814 of 2000 took 0.082s
  training loss:		0.031140
  validation loss:		0.267883
  validation accuracy:		93.80 %
Epoch 815 of 2000 took 0.076s
  training loss:		0.030748
  validation loss:		0.276563
  validation accuracy:		93.70 %
Epoch 816 of 2000 took 0.078s
  training loss:		0.031007
  validation loss:		0.269834
  validation accuracy:		93.80 %
Epoch 817 of 2000 took 0.074s
  training loss:		0.029857
  validation loss:		0.271520
  validation accuracy:		93.70 %
Epoch 818 of 2000 took 0.095s
  training loss:		0.030747
  validation loss:		0.273893
  validation accuracy:		93.70 %
Epoch 819 of 2000 took 0.085s
  training loss:		0.030650
  validation loss:		0.267307
  validation accuracy:		93.91 %
Epoch 820 of 2000 took 0.072s
  training loss:		0.030634
  validation loss:		0.272483
  validation accuracy:		93.80 %
Epoch 821 of 2000 took 0.090s
  training loss:		0.029697
  validation loss:		0.268876
  validation accuracy:		93.70 %
Epoch 822 of 2000 took 0.073s
  training loss:		0.029995
  validation loss:		0.264462
  validation accuracy:		93.80 %
Epoch 823 of 2000 took 0.074s
  training loss:		0.030499
  validation loss:		0.264977
  validation accuracy:		94.02 %
Epoch 824 of 2000 took 0.063s
  training loss:		0.028636
  validation loss:		0.276753
  validation accuracy:		93.70 %
Epoch 825 of 2000 took 0.063s
  training loss:		0.030432
  validation loss:		0.263318
  validation accuracy:		94.13 %
Epoch 826 of 2000 took 0.066s
  training loss:		0.030205
  validation loss:		0.261465
  validation accuracy:		94.02 %
Epoch 827 of 2000 took 0.079s
  training loss:		0.029186
  validation loss:		0.273762
  validation accuracy:		93.91 %
Epoch 828 of 2000 took 0.087s
  training loss:		0.030227
  validation loss:		0.278336
  validation accuracy:		93.70 %
Epoch 829 of 2000 took 0.081s
  training loss:		0.029280
  validation loss:		0.277651
  validation accuracy:		93.80 %
Epoch 830 of 2000 took 0.077s
  training loss:		0.029655
  validation loss:		0.274359
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.101s
  training loss:		0.029570
  validation loss:		0.277269
  validation accuracy:		94.13 %
Epoch 832 of 2000 took 0.096s
  training loss:		0.029992
  validation loss:		0.275973
  validation accuracy:		93.80 %
Epoch 833 of 2000 took 0.087s
  training loss:		0.028968
  validation loss:		0.276760
  validation accuracy:		93.91 %
Epoch 834 of 2000 took 0.144s
  training loss:		0.029478
  validation loss:		0.272774
  validation accuracy:		94.02 %
Epoch 835 of 2000 took 0.096s
  training loss:		0.027514
  validation loss:		0.266805
  validation accuracy:		93.59 %
Epoch 836 of 2000 took 0.090s
  training loss:		0.029264
  validation loss:		0.270296
  validation accuracy:		93.59 %
Epoch 837 of 2000 took 0.089s
  training loss:		0.028526
  validation loss:		0.271258
  validation accuracy:		94.13 %
Epoch 838 of 2000 took 0.096s
  training loss:		0.027593
  validation loss:		0.275776
  validation accuracy:		93.70 %
Epoch 839 of 2000 took 0.095s
  training loss:		0.029160
  validation loss:		0.286746
  validation accuracy:		93.48 %
Epoch 840 of 2000 took 0.189s
  training loss:		0.029145
  validation loss:		0.279221
  validation accuracy:		93.48 %
Epoch 841 of 2000 took 0.140s
  training loss:		0.028950
  validation loss:		0.275766
  validation accuracy:		93.48 %
Epoch 842 of 2000 took 0.124s
  training loss:		0.029576
  validation loss:		0.279003
  validation accuracy:		94.02 %
Epoch 843 of 2000 took 0.086s
  training loss:		0.029154
  validation loss:		0.287421
  validation accuracy:		93.59 %
Epoch 844 of 2000 took 0.093s
  training loss:		0.028824
  validation loss:		0.282958
  validation accuracy:		93.70 %
Epoch 845 of 2000 took 0.102s
  training loss:		0.028378
  validation loss:		0.284095
  validation accuracy:		93.48 %
Epoch 846 of 2000 took 0.081s
  training loss:		0.028632
  validation loss:		0.279755
  validation accuracy:		93.59 %
Epoch 847 of 2000 took 0.075s
  training loss:		0.028793
  validation loss:		0.268305
  validation accuracy:		93.70 %
Epoch 848 of 2000 took 0.079s
  training loss:		0.029135
  validation loss:		0.277679
  validation accuracy:		93.80 %
Epoch 849 of 2000 took 0.076s
  training loss:		0.027163
  validation loss:		0.277356
  validation accuracy:		93.59 %
Epoch 850 of 2000 took 0.080s
  training loss:		0.027885
  validation loss:		0.273825
  validation accuracy:		93.91 %
Epoch 851 of 2000 took 0.072s
  training loss:		0.028095
  validation loss:		0.278964
  validation accuracy:		93.91 %
Epoch 852 of 2000 took 0.096s
  training loss:		0.027272
  validation loss:		0.272039
  validation accuracy:		93.80 %
Epoch 853 of 2000 took 0.136s
  training loss:		0.027536
  validation loss:		0.288984
  validation accuracy:		93.59 %
Epoch 854 of 2000 took 0.100s
  training loss:		0.027932
  validation loss:		0.284433
  validation accuracy:		93.37 %
Epoch 855 of 2000 took 0.118s
  training loss:		0.028085
  validation loss:		0.277810
  validation accuracy:		93.80 %
Epoch 856 of 2000 took 0.078s
  training loss:		0.027899
  validation loss:		0.280093
  validation accuracy:		94.02 %
Epoch 857 of 2000 took 0.065s
  training loss:		0.027169
  validation loss:		0.282423
  validation accuracy:		93.37 %
Epoch 858 of 2000 took 0.069s
  training loss:		0.028126
  validation loss:		0.288401
  validation accuracy:		93.37 %
Epoch 859 of 2000 took 0.074s
  training loss:		0.028157
  validation loss:		0.284215
  validation accuracy:		94.02 %
Epoch 860 of 2000 took 0.073s
  training loss:		0.025913
  validation loss:		0.274933
  validation accuracy:		94.02 %
Epoch 861 of 2000 took 0.072s
  training loss:		0.027443
  validation loss:		0.276496
  validation accuracy:		93.80 %
Epoch 862 of 2000 took 0.081s
  training loss:		0.026880
  validation loss:		0.276484
  validation accuracy:		94.02 %
Epoch 863 of 2000 took 0.070s
  training loss:		0.026103
  validation loss:		0.283007
  validation accuracy:		93.70 %
Epoch 864 of 2000 took 0.073s
  training loss:		0.026489
  validation loss:		0.280054
  validation accuracy:		93.80 %
Epoch 865 of 2000 took 0.085s
  training loss:		0.027882
  validation loss:		0.280065
  validation accuracy:		93.91 %
Epoch 866 of 2000 took 0.082s
  training loss:		0.026038
  validation loss:		0.292322
  validation accuracy:		93.59 %
Epoch 867 of 2000 took 0.074s
  training loss:		0.025939
  validation loss:		0.273759
  validation accuracy:		93.70 %
Epoch 868 of 2000 took 0.070s
  training loss:		0.026315
  validation loss:		0.278976
  validation accuracy:		93.80 %
Epoch 869 of 2000 took 0.069s
  training loss:		0.025967
  validation loss:		0.280762
  validation accuracy:		93.59 %
Epoch 870 of 2000 took 0.066s
  training loss:		0.027529
  validation loss:		0.281461
  validation accuracy:		93.91 %
Epoch 871 of 2000 took 0.069s
  training loss:		0.026966
  validation loss:		0.284748
  validation accuracy:		94.02 %
Epoch 872 of 2000 took 0.070s
  training loss:		0.026823
  validation loss:		0.287196
  validation accuracy:		93.70 %
Epoch 873 of 2000 took 0.067s
  training loss:		0.026845
  validation loss:		0.276877
  validation accuracy:		93.91 %
Epoch 874 of 2000 took 0.074s
  training loss:		0.025304
  validation loss:		0.281993
  validation accuracy:		93.80 %
Epoch 875 of 2000 took 0.072s
  training loss:		0.026212
  validation loss:		0.284566
  validation accuracy:		93.91 %
Epoch 876 of 2000 took 0.074s
  training loss:		0.026811
  validation loss:		0.281294
  validation accuracy:		93.80 %
Epoch 877 of 2000 took 0.067s
  training loss:		0.025705
  validation loss:		0.285807
  validation accuracy:		93.59 %
Epoch 878 of 2000 took 0.067s
  training loss:		0.026006
  validation loss:		0.279738
  validation accuracy:		93.80 %
Epoch 879 of 2000 took 0.067s
  training loss:		0.025964
  validation loss:		0.285151
  validation accuracy:		93.91 %
Epoch 880 of 2000 took 0.066s
  training loss:		0.025307
  validation loss:		0.285072
  validation accuracy:		94.13 %
Epoch 881 of 2000 took 0.065s
  training loss:		0.026067
  validation loss:		0.287516
  validation accuracy:		93.80 %
Epoch 882 of 2000 took 0.072s
  training loss:		0.025052
  validation loss:		0.282892
  validation accuracy:		93.70 %
Epoch 883 of 2000 took 0.086s
  training loss:		0.025430
  validation loss:		0.293041
  validation accuracy:		93.37 %
Epoch 884 of 2000 took 0.069s
  training loss:		0.025019
  validation loss:		0.283584
  validation accuracy:		93.70 %
Epoch 885 of 2000 took 0.085s
  training loss:		0.026215
  validation loss:		0.283584
  validation accuracy:		94.02 %
Epoch 886 of 2000 took 0.079s
  training loss:		0.026479
  validation loss:		0.287811
  validation accuracy:		93.91 %
Epoch 887 of 2000 took 0.080s
  training loss:		0.025805
  validation loss:		0.288842
  validation accuracy:		93.59 %
Epoch 888 of 2000 took 0.073s
  training loss:		0.024671
  validation loss:		0.279517
  validation accuracy:		94.02 %
Epoch 889 of 2000 took 0.079s
  training loss:		0.025866
  validation loss:		0.280723
  validation accuracy:		93.91 %
Epoch 890 of 2000 took 0.076s
  training loss:		0.025131
  validation loss:		0.283683
  validation accuracy:		93.80 %
Epoch 891 of 2000 took 0.077s
  training loss:		0.025188
  validation loss:		0.287500
  validation accuracy:		93.59 %
Epoch 892 of 2000 took 0.070s
  training loss:		0.025622
  validation loss:		0.287812
  validation accuracy:		93.70 %
Epoch 893 of 2000 took 0.087s
  training loss:		0.024286
  validation loss:		0.295113
  validation accuracy:		93.91 %
Epoch 894 of 2000 took 0.084s
  training loss:		0.025648
  validation loss:		0.287861
  validation accuracy:		93.91 %
Epoch 895 of 2000 took 0.077s
  training loss:		0.025244
  validation loss:		0.288568
  validation accuracy:		93.59 %
Epoch 896 of 2000 took 0.084s
  training loss:		0.025248
  validation loss:		0.283302
  validation accuracy:		93.91 %
Epoch 897 of 2000 took 0.080s
  training loss:		0.025048
  validation loss:		0.286910
  validation accuracy:		93.80 %
Epoch 898 of 2000 took 0.075s
  training loss:		0.024480
  validation loss:		0.280794
  validation accuracy:		93.80 %
Epoch 899 of 2000 took 0.072s
  training loss:		0.023978
  validation loss:		0.289117
  validation accuracy:		93.91 %
Epoch 900 of 2000 took 0.071s
  training loss:		0.024252
  validation loss:		0.284885
  validation accuracy:		93.59 %
Epoch 901 of 2000 took 0.069s
  training loss:		0.025288
  validation loss:		0.300882
  validation accuracy:		93.59 %
Epoch 902 of 2000 took 0.072s
  training loss:		0.024865
  validation loss:		0.300466
  validation accuracy:		93.37 %
Epoch 903 of 2000 took 0.078s
  training loss:		0.024051
  validation loss:		0.283077
  validation accuracy:		93.80 %
Epoch 904 of 2000 took 0.116s
  training loss:		0.024680
  validation loss:		0.284103
  validation accuracy:		93.80 %
Epoch 905 of 2000 took 0.122s
  training loss:		0.024010
  validation loss:		0.299630
  validation accuracy:		93.37 %
Epoch 906 of 2000 took 0.080s
  training loss:		0.025032
  validation loss:		0.289104
  validation accuracy:		93.70 %
Epoch 907 of 2000 took 0.075s
  training loss:		0.024150
  validation loss:		0.301956
  validation accuracy:		93.70 %
Epoch 908 of 2000 took 0.110s
  training loss:		0.023467
  validation loss:		0.291826
  validation accuracy:		93.59 %
Epoch 909 of 2000 took 0.083s
  training loss:		0.024045
  validation loss:		0.299122
  validation accuracy:		93.70 %
Epoch 910 of 2000 took 0.083s
  training loss:		0.025032
  validation loss:		0.290527
  validation accuracy:		93.59 %
Epoch 911 of 2000 took 0.082s
  training loss:		0.024767
  validation loss:		0.291768
  validation accuracy:		93.70 %
Epoch 912 of 2000 took 0.085s
  training loss:		0.023918
  validation loss:		0.296261
  validation accuracy:		93.80 %
Epoch 913 of 2000 took 0.092s
  training loss:		0.024080
  validation loss:		0.291382
  validation accuracy:		93.70 %
Epoch 914 of 2000 took 0.103s
  training loss:		0.023199
  validation loss:		0.287866
  validation accuracy:		93.59 %
Epoch 915 of 2000 took 0.077s
  training loss:		0.024362
  validation loss:		0.298834
  validation accuracy:		93.48 %
Epoch 916 of 2000 took 0.067s
  training loss:		0.023544
  validation loss:		0.284463
  validation accuracy:		93.80 %
Epoch 917 of 2000 took 0.063s
  training loss:		0.023971
  validation loss:		0.290283
  validation accuracy:		93.70 %
Epoch 918 of 2000 took 0.067s
  training loss:		0.022997
  validation loss:		0.299092
  validation accuracy:		93.70 %
Epoch 919 of 2000 took 0.073s
  training loss:		0.023322
  validation loss:		0.301755
  validation accuracy:		93.59 %
Epoch 920 of 2000 took 0.068s
  training loss:		0.023769
  validation loss:		0.290766
  validation accuracy:		93.91 %
Epoch 921 of 2000 took 0.071s
  training loss:		0.024369
  validation loss:		0.291562
  validation accuracy:		93.48 %
Epoch 922 of 2000 took 0.069s
  training loss:		0.023833
  validation loss:		0.292807
  validation accuracy:		93.80 %
Epoch 923 of 2000 took 0.069s
  training loss:		0.023099
  validation loss:		0.295389
  validation accuracy:		93.91 %
Epoch 924 of 2000 took 0.072s
  training loss:		0.022534
  validation loss:		0.297300
  validation accuracy:		93.91 %
Epoch 925 of 2000 took 0.068s
  training loss:		0.023693
  validation loss:		0.299991
  validation accuracy:		93.70 %
Epoch 926 of 2000 took 0.068s
  training loss:		0.023234
  validation loss:		0.298859
  validation accuracy:		93.59 %
Epoch 927 of 2000 took 0.073s
  training loss:		0.023366
  validation loss:		0.296909
  validation accuracy:		93.80 %
Epoch 928 of 2000 took 0.087s
  training loss:		0.023898
  validation loss:		0.294887
  validation accuracy:		93.80 %
Epoch 929 of 2000 took 0.070s
  training loss:		0.022663
  validation loss:		0.293606
  validation accuracy:		93.91 %
Epoch 930 of 2000 took 0.069s
  training loss:		0.022796
  validation loss:		0.304723
  validation accuracy:		93.59 %
Epoch 931 of 2000 took 0.066s
  training loss:		0.021977
  validation loss:		0.298382
  validation accuracy:		94.02 %
Epoch 932 of 2000 took 0.067s
  training loss:		0.023323
  validation loss:		0.294292
  validation accuracy:		93.80 %
Epoch 933 of 2000 took 0.069s
  training loss:		0.022946
  validation loss:		0.294507
  validation accuracy:		93.80 %
Epoch 934 of 2000 took 0.072s
  training loss:		0.023162
  validation loss:		0.303195
  validation accuracy:		93.59 %
Epoch 935 of 2000 took 0.082s
  training loss:		0.022360
  validation loss:		0.293659
  validation accuracy:		93.91 %
Epoch 936 of 2000 took 0.076s
  training loss:		0.022726
  validation loss:		0.292272
  validation accuracy:		93.59 %
Epoch 937 of 2000 took 0.074s
  training loss:		0.022395
  validation loss:		0.285183
  validation accuracy:		94.02 %
Epoch 938 of 2000 took 0.067s
  training loss:		0.023266
  validation loss:		0.294312
  validation accuracy:		93.91 %
Epoch 939 of 2000 took 0.067s
  training loss:		0.022866
  validation loss:		0.300653
  validation accuracy:		93.91 %
Epoch 940 of 2000 took 0.068s
  training loss:		0.021711
  validation loss:		0.301774
  validation accuracy:		93.48 %
Epoch 941 of 2000 took 0.065s
  training loss:		0.022742
  validation loss:		0.297352
  validation accuracy:		93.80 %
Epoch 942 of 2000 took 0.071s
  training loss:		0.022315
  validation loss:		0.296531
  validation accuracy:		93.70 %
Epoch 943 of 2000 took 0.066s
  training loss:		0.022739
  validation loss:		0.297933
  validation accuracy:		93.80 %
Epoch 944 of 2000 took 0.067s
  training loss:		0.022589
  validation loss:		0.298431
  validation accuracy:		93.59 %
Epoch 945 of 2000 took 0.068s
  training loss:		0.022341
  validation loss:		0.307726
  validation accuracy:		93.59 %
Epoch 946 of 2000 took 0.065s
  training loss:		0.021889
  validation loss:		0.299232
  validation accuracy:		93.70 %
Epoch 947 of 2000 took 0.067s
  training loss:		0.022098
  validation loss:		0.292700
  validation accuracy:		93.70 %
Epoch 948 of 2000 took 0.072s
  training loss:		0.022673
  validation loss:		0.292813
  validation accuracy:		93.70 %
Epoch 949 of 2000 took 0.076s
  training loss:		0.020962
  validation loss:		0.307517
  validation accuracy:		93.37 %
Epoch 950 of 2000 took 0.065s
  training loss:		0.022837
  validation loss:		0.301741
  validation accuracy:		93.48 %
Epoch 951 of 2000 took 0.068s
  training loss:		0.022731
  validation loss:		0.301978
  validation accuracy:		93.70 %
Epoch 952 of 2000 took 0.084s
  training loss:		0.021958
  validation loss:		0.306541
  validation accuracy:		93.80 %
Epoch 953 of 2000 took 0.071s
  training loss:		0.021301
  validation loss:		0.311913
  validation accuracy:		93.37 %
Epoch 954 of 2000 took 0.066s
  training loss:		0.022383
  validation loss:		0.302740
  validation accuracy:		93.80 %
Epoch 955 of 2000 took 0.064s
  training loss:		0.022200
  validation loss:		0.306551
  validation accuracy:		93.80 %
Epoch 956 of 2000 took 0.071s
  training loss:		0.022004
  validation loss:		0.303573
  validation accuracy:		93.91 %
Epoch 957 of 2000 took 0.073s
  training loss:		0.021920
  validation loss:		0.302364
  validation accuracy:		93.70 %
Epoch 958 of 2000 took 0.082s
  training loss:		0.022153
  validation loss:		0.302305
  validation accuracy:		93.70 %
Epoch 959 of 2000 took 0.069s
  training loss:		0.022301
  validation loss:		0.308894
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.071s
  training loss:		0.021388
  validation loss:		0.299708
  validation accuracy:		93.80 %
Epoch 961 of 2000 took 0.072s
  training loss:		0.021700
  validation loss:		0.309414
  validation accuracy:		93.80 %
Epoch 962 of 2000 took 0.066s
  training loss:		0.021028
  validation loss:		0.309766
  validation accuracy:		93.48 %
Epoch 963 of 2000 took 0.066s
  training loss:		0.021803
  validation loss:		0.303176
  validation accuracy:		93.37 %
Epoch 964 of 2000 took 0.068s
  training loss:		0.021824
  validation loss:		0.314062
  validation accuracy:		93.26 %
Epoch 965 of 2000 took 0.065s
  training loss:		0.022244
  validation loss:		0.309018
  validation accuracy:		93.48 %
Epoch 966 of 2000 took 0.075s
  training loss:		0.021454
  validation loss:		0.304892
  validation accuracy:		93.80 %
Epoch 967 of 2000 took 0.098s
  training loss:		0.020825
  validation loss:		0.305205
  validation accuracy:		93.70 %
Epoch 968 of 2000 took 0.080s
  training loss:		0.020632
  validation loss:		0.300146
  validation accuracy:		93.80 %
Epoch 969 of 2000 took 0.077s
  training loss:		0.021872
  validation loss:		0.303964
  validation accuracy:		93.80 %
Epoch 970 of 2000 took 0.072s
  training loss:		0.021640
  validation loss:		0.308716
  validation accuracy:		93.70 %
Epoch 971 of 2000 took 0.069s
  training loss:		0.020433
  validation loss:		0.297614
  validation accuracy:		93.70 %
Epoch 972 of 2000 took 0.070s
  training loss:		0.020324
  validation loss:		0.300004
  validation accuracy:		93.80 %
Epoch 973 of 2000 took 0.084s
  training loss:		0.021278
  validation loss:		0.312089
  validation accuracy:		93.37 %
Epoch 974 of 2000 took 0.087s
  training loss:		0.021522
  validation loss:		0.312101
  validation accuracy:		93.59 %
Epoch 975 of 2000 took 0.077s
  training loss:		0.020251
  validation loss:		0.316289
  validation accuracy:		93.59 %
Epoch 976 of 2000 took 0.077s
  training loss:		0.020625
  validation loss:		0.303371
  validation accuracy:		93.80 %
Epoch 977 of 2000 took 0.074s
  training loss:		0.020924
  validation loss:		0.304484
  validation accuracy:		93.70 %
Epoch 978 of 2000 took 0.079s
  training loss:		0.020777
  validation loss:		0.309354
  validation accuracy:		93.59 %
Epoch 979 of 2000 took 0.077s
  training loss:		0.020257
  validation loss:		0.306895
  validation accuracy:		93.80 %
Epoch 980 of 2000 took 0.091s
  training loss:		0.020363
  validation loss:		0.306372
  validation accuracy:		94.02 %
Epoch 981 of 2000 took 0.137s
  training loss:		0.020780
  validation loss:		0.314230
  validation accuracy:		93.59 %
Epoch 982 of 2000 took 0.260s
  training loss:		0.020357
  validation loss:		0.316401
  validation accuracy:		93.48 %
Epoch 983 of 2000 took 0.104s
  training loss:		0.020604
  validation loss:		0.307127
  validation accuracy:		93.80 %
Epoch 984 of 2000 took 0.100s
  training loss:		0.018139
  validation loss:		0.318444
  validation accuracy:		93.59 %
Epoch 985 of 2000 took 0.121s
  training loss:		0.021170
  validation loss:		0.308370
  validation accuracy:		93.91 %
Epoch 986 of 2000 took 0.121s
  training loss:		0.020110
  validation loss:		0.315819
  validation accuracy:		93.48 %
Epoch 987 of 2000 took 0.255s
  training loss:		0.020287
  validation loss:		0.300560
  validation accuracy:		93.70 %
Epoch 988 of 2000 took 0.142s
  training loss:		0.020803
  validation loss:		0.314396
  validation accuracy:		93.59 %
Epoch 989 of 2000 took 0.159s
  training loss:		0.019794
  validation loss:		0.311824
  validation accuracy:		93.59 %
Epoch 990 of 2000 took 0.118s
  training loss:		0.019664
  validation loss:		0.311937
  validation accuracy:		93.80 %
Epoch 991 of 2000 took 0.137s
  training loss:		0.020637
  validation loss:		0.321071
  validation accuracy:		93.80 %
Epoch 992 of 2000 took 0.128s
  training loss:		0.019485
  validation loss:		0.309297
  validation accuracy:		93.59 %
Epoch 993 of 2000 took 0.105s
  training loss:		0.019933
  validation loss:		0.312717
  validation accuracy:		93.80 %
Epoch 994 of 2000 took 0.110s
  training loss:		0.019641
  validation loss:		0.310730
  validation accuracy:		93.59 %
Epoch 995 of 2000 took 0.140s
  training loss:		0.019569
  validation loss:		0.305900
  validation accuracy:		93.80 %
Epoch 996 of 2000 took 0.125s
  training loss:		0.018818
  validation loss:		0.315899
  validation accuracy:		93.59 %
Epoch 997 of 2000 took 0.112s
  training loss:		0.020152
  validation loss:		0.318909
  validation accuracy:		93.37 %
Epoch 998 of 2000 took 0.129s
  training loss:		0.020319
  validation loss:		0.314810
  validation accuracy:		93.70 %
Epoch 999 of 2000 took 0.140s
  training loss:		0.018344
  validation loss:		0.320459
  validation accuracy:		93.37 %
Epoch 1000 of 2000 took 0.147s
  training loss:		0.019373
  validation loss:		0.314985
  validation accuracy:		93.48 %
Epoch 1001 of 2000 took 0.084s
  training loss:		0.019768
  validation loss:		0.311920
  validation accuracy:		93.80 %
Epoch 1002 of 2000 took 0.081s
  training loss:		0.019328
  validation loss:		0.314807
  validation accuracy:		93.70 %
Epoch 1003 of 2000 took 0.090s
  training loss:		0.020383
  validation loss:		0.320313
  validation accuracy:		93.59 %
Epoch 1004 of 2000 took 0.125s
  training loss:		0.018712
  validation loss:		0.309179
  validation accuracy:		93.59 %
Epoch 1005 of 2000 took 0.103s
  training loss:		0.019365
  validation loss:		0.311199
  validation accuracy:		93.80 %
Epoch 1006 of 2000 took 0.087s
  training loss:		0.019688
  validation loss:		0.312450
  validation accuracy:		93.70 %
Epoch 1007 of 2000 took 0.086s
  training loss:		0.019318
  validation loss:		0.307022
  validation accuracy:		93.70 %
Epoch 1008 of 2000 took 0.087s
  training loss:		0.018394
  validation loss:		0.307819
  validation accuracy:		93.70 %
Epoch 1009 of 2000 took 0.081s
  training loss:		0.019236
  validation loss:		0.312936
  validation accuracy:		93.70 %
Epoch 1010 of 2000 took 0.086s
  training loss:		0.019068
  validation loss:		0.321159
  validation accuracy:		93.70 %
Epoch 1011 of 2000 took 0.089s
  training loss:		0.018830
  validation loss:		0.319270
  validation accuracy:		93.59 %
Epoch 1012 of 2000 took 0.090s
  training loss:		0.018151
  validation loss:		0.315150
  validation accuracy:		93.37 %
Epoch 1013 of 2000 took 0.090s
  training loss:		0.019231
  validation loss:		0.312953
  validation accuracy:		93.70 %
Epoch 1014 of 2000 took 0.087s
  training loss:		0.018536
  validation loss:		0.319693
  validation accuracy:		93.59 %
Epoch 1015 of 2000 took 0.104s
  training loss:		0.018868
  validation loss:		0.314306
  validation accuracy:		93.59 %
Epoch 1016 of 2000 took 0.239s
  training loss:		0.019548
  validation loss:		0.314570
  validation accuracy:		93.70 %
Epoch 1017 of 2000 took 0.166s
  training loss:		0.019343
  validation loss:		0.307563
  validation accuracy:		93.70 %
Epoch 1018 of 2000 took 0.106s
  training loss:		0.018972
  validation loss:		0.316312
  validation accuracy:		93.70 %
Epoch 1019 of 2000 took 0.102s
  training loss:		0.019357
  validation loss:		0.314786
  validation accuracy:		93.70 %
Epoch 1020 of 2000 took 0.137s
  training loss:		0.019687
  validation loss:		0.322267
  validation accuracy:		93.70 %
Epoch 1021 of 2000 took 0.102s
  training loss:		0.018707
  validation loss:		0.317794
  validation accuracy:		93.70 %
Epoch 1022 of 2000 took 0.114s
  training loss:		0.018416
  validation loss:		0.320984
  validation accuracy:		93.70 %
Epoch 1023 of 2000 took 0.172s
  training loss:		0.019131
  validation loss:		0.316483
  validation accuracy:		93.80 %
Epoch 1024 of 2000 took 0.178s
  training loss:		0.018497
  validation loss:		0.314356
  validation accuracy:		93.48 %
Epoch 1025 of 2000 took 0.157s
  training loss:		0.018784
  validation loss:		0.322521
  validation accuracy:		93.70 %
Epoch 1026 of 2000 took 0.109s
  training loss:		0.017897
  validation loss:		0.324904
  validation accuracy:		93.48 %
Epoch 1027 of 2000 took 0.094s
  training loss:		0.017736
  validation loss:		0.321819
  validation accuracy:		93.59 %
Epoch 1028 of 2000 took 0.096s
  training loss:		0.018381
  validation loss:		0.321733
  validation accuracy:		93.59 %
Epoch 1029 of 2000 took 0.075s
  training loss:		0.018593
  validation loss:		0.323016
  validation accuracy:		93.59 %
Epoch 1030 of 2000 took 0.247s
  training loss:		0.018487
  validation loss:		0.321981
  validation accuracy:		93.70 %
Epoch 1031 of 2000 took 0.158s
  training loss:		0.018275
  validation loss:		0.311171
  validation accuracy:		93.70 %
Epoch 1032 of 2000 took 0.138s
  training loss:		0.018924
  validation loss:		0.311366
  validation accuracy:		93.70 %
Epoch 1033 of 2000 took 0.118s
  training loss:		0.017863
  validation loss:		0.324096
  validation accuracy:		93.59 %
Epoch 1034 of 2000 took 0.143s
  training loss:		0.018275
  validation loss:		0.315557
  validation accuracy:		93.70 %
Epoch 1035 of 2000 took 0.145s
  training loss:		0.017695
  validation loss:		0.329152
  validation accuracy:		93.48 %
Epoch 1036 of 2000 took 0.220s
  training loss:		0.018495
  validation loss:		0.318402
  validation accuracy:		93.70 %
Epoch 1037 of 2000 took 0.147s
  training loss:		0.018019
  validation loss:		0.320325
  validation accuracy:		93.70 %
Epoch 1038 of 2000 took 0.119s
  training loss:		0.018027
  validation loss:		0.338772
  validation accuracy:		93.15 %
Epoch 1039 of 2000 took 0.131s
  training loss:		0.017976
  validation loss:		0.334526
  validation accuracy:		93.37 %
Epoch 1040 of 2000 took 0.197s
  training loss:		0.018220
  validation loss:		0.328400
  validation accuracy:		93.48 %
Epoch 1041 of 2000 took 0.146s
  training loss:		0.018354
  validation loss:		0.324986
  validation accuracy:		93.70 %
Epoch 1042 of 2000 took 0.174s
  training loss:		0.017938
  validation loss:		0.321402
  validation accuracy:		93.70 %
Epoch 1043 of 2000 took 0.157s
  training loss:		0.017053
  validation loss:		0.315059
  validation accuracy:		93.80 %
Epoch 1044 of 2000 took 0.147s
  training loss:		0.017904
  validation loss:		0.326477
  validation accuracy:		93.59 %
Epoch 1045 of 2000 took 0.106s
  training loss:		0.017437
  validation loss:		0.322322
  validation accuracy:		93.70 %
Epoch 1046 of 2000 took 0.111s
  training loss:		0.017948
  validation loss:		0.319901
  validation accuracy:		93.70 %
Epoch 1047 of 2000 took 0.093s
  training loss:		0.016870
  validation loss:		0.321456
  validation accuracy:		93.70 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.016833
  validation loss:		0.320327
  validation accuracy:		93.80 %
Epoch 1049 of 2000 took 0.085s
  training loss:		0.017640
  validation loss:		0.322368
  validation accuracy:		93.59 %
Epoch 1050 of 2000 took 0.092s
  training loss:		0.017914
  validation loss:		0.337186
  validation accuracy:		93.59 %
Epoch 1051 of 2000 took 0.096s
  training loss:		0.018007
  validation loss:		0.325804
  validation accuracy:		93.59 %
Epoch 1052 of 2000 took 0.095s
  training loss:		0.017316
  validation loss:		0.329110
  validation accuracy:		93.59 %
Epoch 1053 of 2000 took 0.105s
  training loss:		0.016583
  validation loss:		0.326307
  validation accuracy:		93.70 %
Epoch 1054 of 2000 took 0.094s
  training loss:		0.016993
  validation loss:		0.325755
  validation accuracy:		93.70 %
Epoch 1055 of 2000 took 0.085s
  training loss:		0.017217
  validation loss:		0.317445
  validation accuracy:		93.59 %
Epoch 1056 of 2000 took 0.077s
  training loss:		0.017069
  validation loss:		0.318817
  validation accuracy:		93.70 %
Epoch 1057 of 2000 took 0.075s
  training loss:		0.016734
  validation loss:		0.319672
  validation accuracy:		93.70 %
Epoch 1058 of 2000 took 0.071s
  training loss:		0.017245
  validation loss:		0.332727
  validation accuracy:		93.59 %
Epoch 1059 of 2000 took 0.075s
  training loss:		0.017534
  validation loss:		0.328376
  validation accuracy:		93.59 %
Epoch 1060 of 2000 took 0.082s
  training loss:		0.017498
  validation loss:		0.334392
  validation accuracy:		93.48 %
Epoch 1061 of 2000 took 0.074s
  training loss:		0.016713
  validation loss:		0.329541
  validation accuracy:		93.70 %
Epoch 1062 of 2000 took 0.077s
  training loss:		0.018875
  validation loss:		0.333348
  validation accuracy:		93.48 %
Epoch 1063 of 2000 took 0.079s
  training loss:		0.016258
  validation loss:		0.329353
  validation accuracy:		93.48 %
Epoch 1064 of 2000 took 0.081s
  training loss:		0.016965
  validation loss:		0.329371
  validation accuracy:		93.70 %
Epoch 1065 of 2000 took 0.076s
  training loss:		0.016810
  validation loss:		0.321845
  validation accuracy:		93.59 %
Epoch 1066 of 2000 took 0.108s
  training loss:		0.017434
  validation loss:		0.331812
  validation accuracy:		93.37 %
Epoch 1067 of 2000 took 0.158s
  training loss:		0.016422
  validation loss:		0.330706
  validation accuracy:		93.70 %
Epoch 1068 of 2000 took 0.102s
  training loss:		0.016820
  validation loss:		0.335143
  validation accuracy:		93.26 %
Epoch 1069 of 2000 took 0.093s
  training loss:		0.016196
  validation loss:		0.330031
  validation accuracy:		93.48 %
Epoch 1070 of 2000 took 0.083s
  training loss:		0.016880
  validation loss:		0.332823
  validation accuracy:		93.48 %
Epoch 1071 of 2000 took 0.091s
  training loss:		0.016170
  validation loss:		0.332430
  validation accuracy:		93.48 %
Epoch 1072 of 2000 took 0.088s
  training loss:		0.016366
  validation loss:		0.336199
  validation accuracy:		93.48 %
Epoch 1073 of 2000 took 0.091s
  training loss:		0.016581
  validation loss:		0.328259
  validation accuracy:		93.59 %
Epoch 1074 of 2000 took 0.101s
  training loss:		0.015703
  validation loss:		0.328236
  validation accuracy:		93.37 %
Epoch 1075 of 2000 took 0.105s
  training loss:		0.016019
  validation loss:		0.336364
  validation accuracy:		93.26 %
Epoch 1076 of 2000 took 0.114s
  training loss:		0.016514
  validation loss:		0.333086
  validation accuracy:		93.48 %
Epoch 1077 of 2000 took 0.107s
  training loss:		0.015942
  validation loss:		0.331980
  validation accuracy:		93.70 %
Epoch 1078 of 2000 took 0.098s
  training loss:		0.015604
  validation loss:		0.332775
  validation accuracy:		93.48 %
Epoch 1079 of 2000 took 0.083s
  training loss:		0.016011
  validation loss:		0.335721
  validation accuracy:		93.48 %
Epoch 1080 of 2000 took 0.080s
  training loss:		0.015975
  validation loss:		0.344020
  validation accuracy:		93.26 %
Epoch 1081 of 2000 took 0.079s
  training loss:		0.016149
  validation loss:		0.335647
  validation accuracy:		93.59 %
Epoch 1082 of 2000 took 0.081s
  training loss:		0.016220
  validation loss:		0.330368
  validation accuracy:		93.48 %
Epoch 1083 of 2000 took 0.076s
  training loss:		0.015944
  validation loss:		0.342271
  validation accuracy:		93.26 %
Epoch 1084 of 2000 took 0.080s
  training loss:		0.015778
  validation loss:		0.337336
  validation accuracy:		93.59 %
Epoch 1085 of 2000 took 0.086s
  training loss:		0.015923
  validation loss:		0.328849
  validation accuracy:		93.70 %
Epoch 1086 of 2000 took 0.096s
  training loss:		0.016085
  validation loss:		0.327729
  validation accuracy:		93.70 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.016570
  validation loss:		0.338755
  validation accuracy:		93.59 %
Epoch 1088 of 2000 took 0.085s
  training loss:		0.015365
  validation loss:		0.330033
  validation accuracy:		93.70 %
Epoch 1089 of 2000 took 0.151s
  training loss:		0.016003
  validation loss:		0.333557
  validation accuracy:		93.70 %
Epoch 1090 of 2000 took 0.103s
  training loss:		0.015778
  validation loss:		0.341848
  validation accuracy:		93.37 %
Epoch 1091 of 2000 took 0.095s
  training loss:		0.015915
  validation loss:		0.335949
  validation accuracy:		93.59 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.015903
  validation loss:		0.335096
  validation accuracy:		93.59 %
Epoch 1093 of 2000 took 0.088s
  training loss:		0.016306
  validation loss:		0.340822
  validation accuracy:		93.26 %
Epoch 1094 of 2000 took 0.083s
  training loss:		0.015625
  validation loss:		0.335597
  validation accuracy:		93.59 %
Epoch 1095 of 2000 took 0.087s
  training loss:		0.015352
  validation loss:		0.335990
  validation accuracy:		93.59 %
Epoch 1096 of 2000 took 0.092s
  training loss:		0.015476
  validation loss:		0.337594
  validation accuracy:		93.59 %
Epoch 1097 of 2000 took 0.099s
  training loss:		0.015535
  validation loss:		0.340422
  validation accuracy:		93.59 %
Epoch 1098 of 2000 took 0.118s
  training loss:		0.015430
  validation loss:		0.334442
  validation accuracy:		93.70 %
Epoch 1099 of 2000 took 0.103s
  training loss:		0.016230
  validation loss:		0.333017
  validation accuracy:		93.59 %
Epoch 1100 of 2000 took 0.093s
  training loss:		0.015056
  validation loss:		0.341459
  validation accuracy:		93.37 %
Epoch 1101 of 2000 took 0.088s
  training loss:		0.015663
  validation loss:		0.340497
  validation accuracy:		93.59 %
Epoch 1102 of 2000 took 0.080s
  training loss:		0.014302
  validation loss:		0.332457
  validation accuracy:		93.70 %
Epoch 1103 of 2000 took 0.081s
  training loss:		0.015321
  validation loss:		0.338044
  validation accuracy:		93.70 %
Epoch 1104 of 2000 took 0.079s
  training loss:		0.014874
  validation loss:		0.334514
  validation accuracy:		93.70 %
Epoch 1105 of 2000 took 0.081s
  training loss:		0.015170
  validation loss:		0.333186
  validation accuracy:		93.70 %
Epoch 1106 of 2000 took 0.083s
  training loss:		0.015990
  validation loss:		0.331811
  validation accuracy:		93.59 %
Epoch 1107 of 2000 took 0.099s
  training loss:		0.015550
  validation loss:		0.337868
  validation accuracy:		93.48 %
Epoch 1108 of 2000 took 0.081s
  training loss:		0.014945
  validation loss:		0.339282
  validation accuracy:		93.59 %
Epoch 1109 of 2000 took 0.081s
  training loss:		0.015089
  validation loss:		0.337312
  validation accuracy:		93.59 %
Epoch 1110 of 2000 took 0.087s
  training loss:		0.014425
  validation loss:		0.330686
  validation accuracy:		93.70 %
Epoch 1111 of 2000 took 0.098s
  training loss:		0.014847
  validation loss:		0.343238
  validation accuracy:		93.48 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.015506
  validation loss:		0.340092
  validation accuracy:		93.80 %
Epoch 1113 of 2000 took 0.099s
  training loss:		0.015172
  validation loss:		0.332474
  validation accuracy:		93.70 %
Epoch 1114 of 2000 took 0.103s
  training loss:		0.015386
  validation loss:		0.337938
  validation accuracy:		93.70 %
Epoch 1115 of 2000 took 0.091s
  training loss:		0.015415
  validation loss:		0.343429
  validation accuracy:		93.59 %
Epoch 1116 of 2000 took 0.078s
  training loss:		0.014599
  validation loss:		0.344943
  validation accuracy:		93.59 %
Epoch 1117 of 2000 took 0.080s
  training loss:		0.015033
  validation loss:		0.337660
  validation accuracy:		93.59 %
Epoch 1118 of 2000 took 0.085s
  training loss:		0.014144
  validation loss:		0.333583
  validation accuracy:		93.70 %
Epoch 1119 of 2000 took 0.075s
  training loss:		0.014686
  validation loss:		0.340180
  validation accuracy:		93.70 %
Epoch 1120 of 2000 took 0.091s
  training loss:		0.014846
  validation loss:		0.352729
  validation accuracy:		93.37 %
Epoch 1121 of 2000 took 0.086s
  training loss:		0.014711
  validation loss:		0.348549
  validation accuracy:		93.37 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.015300
  validation loss:		0.339792
  validation accuracy:		93.59 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.015071
  validation loss:		0.339218
  validation accuracy:		93.70 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.014713
  validation loss:		0.346575
  validation accuracy:		93.59 %
Epoch 1125 of 2000 took 0.101s
  training loss:		0.014305
  validation loss:		0.341457
  validation accuracy:		93.59 %
Epoch 1126 of 2000 took 0.147s
  training loss:		0.014184
  validation loss:		0.336896
  validation accuracy:		93.48 %
Epoch 1127 of 2000 took 0.110s
  training loss:		0.014454
  validation loss:		0.346043
  validation accuracy:		93.59 %
Epoch 1128 of 2000 took 0.100s
  training loss:		0.014408
  validation loss:		0.339503
  validation accuracy:		93.70 %
Epoch 1129 of 2000 took 0.081s
  training loss:		0.014587
  validation loss:		0.344702
  validation accuracy:		93.59 %
Epoch 1130 of 2000 took 0.082s
  training loss:		0.014960
  validation loss:		0.345703
  validation accuracy:		93.59 %
Epoch 1131 of 2000 took 0.086s
  training loss:		0.014364
  validation loss:		0.352205
  validation accuracy:		93.37 %
Epoch 1132 of 2000 took 0.079s
  training loss:		0.014352
  validation loss:		0.346127
  validation accuracy:		93.70 %
Epoch 1133 of 2000 took 0.084s
  training loss:		0.014056
  validation loss:		0.338766
  validation accuracy:		93.70 %
Epoch 1134 of 2000 took 0.112s
  training loss:		0.014605
  validation loss:		0.351809
  validation accuracy:		93.37 %
Epoch 1135 of 2000 took 0.141s
  training loss:		0.014527
  validation loss:		0.348505
  validation accuracy:		93.48 %
Epoch 1136 of 2000 took 0.107s
  training loss:		0.014549
  validation loss:		0.346948
  validation accuracy:		93.37 %
Epoch 1137 of 2000 took 0.105s
  training loss:		0.014075
  validation loss:		0.344085
  validation accuracy:		93.59 %
Epoch 1138 of 2000 took 0.115s
  training loss:		0.013896
  validation loss:		0.339813
  validation accuracy:		93.70 %
Epoch 1139 of 2000 took 0.086s
  training loss:		0.014433
  validation loss:		0.344137
  validation accuracy:		93.70 %
Epoch 1140 of 2000 took 0.085s
  training loss:		0.013872
  validation loss:		0.343896
  validation accuracy:		93.80 %
Epoch 1141 of 2000 took 0.098s
  training loss:		0.014031
  validation loss:		0.345396
  validation accuracy:		93.70 %
Epoch 1142 of 2000 took 0.083s
  training loss:		0.013956
  validation loss:		0.350154
  validation accuracy:		93.59 %
Epoch 1143 of 2000 took 0.079s
  training loss:		0.013838
  validation loss:		0.340660
  validation accuracy:		93.70 %
Epoch 1144 of 2000 took 0.080s
  training loss:		0.014095
  validation loss:		0.347899
  validation accuracy:		93.70 %
Epoch 1145 of 2000 took 0.084s
  training loss:		0.013818
  validation loss:		0.351379
  validation accuracy:		93.59 %
Epoch 1146 of 2000 took 0.090s
  training loss:		0.014400
  validation loss:		0.348496
  validation accuracy:		93.59 %
Epoch 1147 of 2000 took 0.092s
  training loss:		0.014298
  validation loss:		0.341232
  validation accuracy:		93.59 %
Epoch 1148 of 2000 took 0.092s
  training loss:		0.014392
  validation loss:		0.345718
  validation accuracy:		93.59 %
Epoch 1149 of 2000 took 0.088s
  training loss:		0.013928
  validation loss:		0.352766
  validation accuracy:		93.48 %
Epoch 1150 of 2000 took 0.084s
  training loss:		0.013922
  validation loss:		0.351434
  validation accuracy:		93.59 %
Epoch 1151 of 2000 took 0.081s
  training loss:		0.013642
  validation loss:		0.343292
  validation accuracy:		93.70 %
Epoch 1152 of 2000 took 0.111s
  training loss:		0.013063
  validation loss:		0.346110
  validation accuracy:		93.48 %
Epoch 1153 of 2000 took 0.146s
  training loss:		0.013982
  validation loss:		0.347167
  validation accuracy:		93.59 %
Epoch 1154 of 2000 took 0.168s
  training loss:		0.013368
  validation loss:		0.353265
  validation accuracy:		93.48 %
Epoch 1155 of 2000 took 0.162s
  training loss:		0.013419
  validation loss:		0.343187
  validation accuracy:		93.59 %
Epoch 1156 of 2000 took 0.150s
  training loss:		0.013860
  validation loss:		0.340878
  validation accuracy:		93.59 %
Epoch 1157 of 2000 took 0.170s
  training loss:		0.013879
  validation loss:		0.352543
  validation accuracy:		93.70 %
Epoch 1158 of 2000 took 0.176s
  training loss:		0.013431
  validation loss:		0.344874
  validation accuracy:		93.80 %
Epoch 1159 of 2000 took 0.215s
  training loss:		0.013479
  validation loss:		0.358217
  validation accuracy:		93.37 %
Epoch 1160 of 2000 took 0.161s
  training loss:		0.013925
  validation loss:		0.354931
  validation accuracy:		93.48 %
Epoch 1161 of 2000 took 0.152s
  training loss:		0.013042
  validation loss:		0.356694
  validation accuracy:		93.37 %
Epoch 1162 of 2000 took 0.129s
  training loss:		0.013594
  validation loss:		0.346108
  validation accuracy:		93.70 %
Epoch 1163 of 2000 took 0.130s
  training loss:		0.013625
  validation loss:		0.356412
  validation accuracy:		93.37 %
Epoch 1164 of 2000 took 0.157s
  training loss:		0.013083
  validation loss:		0.348990
  validation accuracy:		93.70 %
Epoch 1165 of 2000 took 0.177s
  training loss:		0.013652
  validation loss:		0.350596
  validation accuracy:		93.70 %
Epoch 1166 of 2000 took 0.151s
  training loss:		0.013081
  validation loss:		0.351183
  validation accuracy:		93.37 %
Epoch 1167 of 2000 took 0.127s
  training loss:		0.013137
  validation loss:		0.344950
  validation accuracy:		93.59 %
Epoch 1168 of 2000 took 0.122s
  training loss:		0.013253
  validation loss:		0.356656
  validation accuracy:		93.59 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.013624
  validation loss:		0.368066
  validation accuracy:		93.04 %
Epoch 1170 of 2000 took 0.111s
  training loss:		0.013313
  validation loss:		0.347682
  validation accuracy:		93.48 %
Epoch 1171 of 2000 took 0.102s
  training loss:		0.012991
  validation loss:		0.360707
  validation accuracy:		93.37 %
Epoch 1172 of 2000 took 0.089s
  training loss:		0.013368
  validation loss:		0.350963
  validation accuracy:		93.70 %
Epoch 1173 of 2000 took 0.089s
  training loss:		0.013117
  validation loss:		0.352358
  validation accuracy:		93.59 %
Epoch 1174 of 2000 took 0.084s
  training loss:		0.013133
  validation loss:		0.364004
  validation accuracy:		93.26 %
Epoch 1175 of 2000 took 0.102s
  training loss:		0.013559
  validation loss:		0.351819
  validation accuracy:		93.70 %
Epoch 1176 of 2000 took 0.087s
  training loss:		0.013233
  validation loss:		0.351207
  validation accuracy:		93.70 %
Epoch 1177 of 2000 took 0.121s
  training loss:		0.013175
  validation loss:		0.361862
  validation accuracy:		93.37 %
Epoch 1178 of 2000 took 0.099s
  training loss:		0.012448
  validation loss:		0.350637
  validation accuracy:		93.48 %
Epoch 1179 of 2000 took 0.105s
  training loss:		0.013285
  validation loss:		0.351571
  validation accuracy:		93.70 %
Epoch 1180 of 2000 took 0.100s
  training loss:		0.012995
  validation loss:		0.355833
  validation accuracy:		93.59 %
Epoch 1181 of 2000 took 0.095s
  training loss:		0.012936
  validation loss:		0.359393
  validation accuracy:		93.37 %
Epoch 1182 of 2000 took 0.089s
  training loss:		0.013164
  validation loss:		0.348392
  validation accuracy:		93.59 %
Epoch 1183 of 2000 took 0.091s
  training loss:		0.012770
  validation loss:		0.356710
  validation accuracy:		93.59 %
Epoch 1184 of 2000 took 0.098s
  training loss:		0.012263
  validation loss:		0.359387
  validation accuracy:		93.26 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.012748
  validation loss:		0.352303
  validation accuracy:		93.70 %
Epoch 1186 of 2000 took 0.091s
  training loss:		0.012849
  validation loss:		0.362885
  validation accuracy:		93.59 %
Epoch 1187 of 2000 took 0.090s
  training loss:		0.012642
  validation loss:		0.352626
  validation accuracy:		93.59 %
Epoch 1188 of 2000 took 0.086s
  training loss:		0.012485
  validation loss:		0.354961
  validation accuracy:		93.59 %
Epoch 1189 of 2000 took 0.084s
  training loss:		0.012252
  validation loss:		0.364761
  validation accuracy:		93.37 %
Epoch 1190 of 2000 took 0.086s
  training loss:		0.012521
  validation loss:		0.362819
  validation accuracy:		93.37 %
Epoch 1191 of 2000 took 0.086s
  training loss:		0.013002
  validation loss:		0.365098
  validation accuracy:		93.37 %
Epoch 1192 of 2000 took 0.086s
  training loss:		0.012662
  validation loss:		0.358691
  validation accuracy:		93.48 %
Epoch 1193 of 2000 took 0.087s
  training loss:		0.012490
  validation loss:		0.360694
  validation accuracy:		93.48 %
Epoch 1194 of 2000 took 0.089s
  training loss:		0.012257
  validation loss:		0.363529
  validation accuracy:		93.37 %
Epoch 1195 of 2000 took 0.090s
  training loss:		0.012271
  validation loss:		0.364238
  validation accuracy:		93.48 %
Epoch 1196 of 2000 took 0.173s
  training loss:		0.012570
  validation loss:		0.354367
  validation accuracy:		93.70 %
Epoch 1197 of 2000 took 0.217s
  training loss:		0.012573
  validation loss:		0.359059
  validation accuracy:		93.59 %
Epoch 1198 of 2000 took 0.166s
  training loss:		0.012286
  validation loss:		0.361597
  validation accuracy:		93.48 %
Epoch 1199 of 2000 took 0.108s
  training loss:		0.012767
  validation loss:		0.359888
  validation accuracy:		93.48 %
Epoch 1200 of 2000 took 0.119s
  training loss:		0.012555
  validation loss:		0.352466
  validation accuracy:		93.59 %
Epoch 1201 of 2000 took 0.109s
  training loss:		0.012328
  validation loss:		0.359405
  validation accuracy:		93.48 %
Epoch 1202 of 2000 took 0.105s
  training loss:		0.012269
  validation loss:		0.355404
  validation accuracy:		93.26 %
Epoch 1203 of 2000 took 0.107s
  training loss:		0.012183
  validation loss:		0.369686
  validation accuracy:		93.37 %
Epoch 1204 of 2000 took 0.107s
  training loss:		0.012343
  validation loss:		0.369180
  validation accuracy:		93.26 %
Epoch 1205 of 2000 took 0.108s
  training loss:		0.012226
  validation loss:		0.358165
  validation accuracy:		93.70 %
Epoch 1206 of 2000 took 0.104s
  training loss:		0.011901
  validation loss:		0.368272
  validation accuracy:		93.48 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.012049
  validation loss:		0.362290
  validation accuracy:		93.59 %
Epoch 1208 of 2000 took 0.090s
  training loss:		0.012245
  validation loss:		0.357902
  validation accuracy:		93.37 %
Epoch 1209 of 2000 took 0.082s
  training loss:		0.012001
  validation loss:		0.356022
  validation accuracy:		93.59 %
Epoch 1210 of 2000 took 0.090s
  training loss:		0.012566
  validation loss:		0.367568
  validation accuracy:		93.48 %
Epoch 1211 of 2000 took 0.191s
  training loss:		0.011656
  validation loss:		0.361448
  validation accuracy:		93.48 %
Epoch 1212 of 2000 took 0.149s
  training loss:		0.011983
  validation loss:		0.359277
  validation accuracy:		93.48 %
Epoch 1213 of 2000 took 0.128s
  training loss:		0.012236
  validation loss:		0.360910
  validation accuracy:		93.48 %
Epoch 1214 of 2000 took 0.116s
  training loss:		0.011747
  validation loss:		0.360744
  validation accuracy:		93.59 %
Epoch 1215 of 2000 took 0.116s
  training loss:		0.011634
  validation loss:		0.370869
  validation accuracy:		93.26 %
Epoch 1216 of 2000 took 0.107s
  training loss:		0.011815
  validation loss:		0.362551
  validation accuracy:		93.59 %
Epoch 1217 of 2000 took 0.109s
  training loss:		0.011645
  validation loss:		0.369074
  validation accuracy:		93.37 %
Epoch 1218 of 2000 took 0.121s
  training loss:		0.012250
  validation loss:		0.369871
  validation accuracy:		93.37 %
Epoch 1219 of 2000 took 0.112s
  training loss:		0.011774
  validation loss:		0.370045
  validation accuracy:		93.15 %
Epoch 1220 of 2000 took 0.113s
  training loss:		0.011958
  validation loss:		0.371636
  validation accuracy:		93.15 %
Epoch 1221 of 2000 took 0.103s
  training loss:		0.011631
  validation loss:		0.364883
  validation accuracy:		93.59 %
Epoch 1222 of 2000 took 0.102s
  training loss:		0.011600
  validation loss:		0.369314
  validation accuracy:		93.15 %
Epoch 1223 of 2000 took 0.103s
  training loss:		0.011608
  validation loss:		0.363768
  validation accuracy:		93.59 %
Epoch 1224 of 2000 took 0.107s
  training loss:		0.011660
  validation loss:		0.359367
  validation accuracy:		93.48 %
Epoch 1225 of 2000 took 0.105s
  training loss:		0.011594
  validation loss:		0.366302
  validation accuracy:		93.48 %
Epoch 1226 of 2000 took 0.106s
  training loss:		0.011685
  validation loss:		0.367645
  validation accuracy:		93.59 %
Epoch 1227 of 2000 took 0.121s
  training loss:		0.011417
  validation loss:		0.363268
  validation accuracy:		93.59 %
Epoch 1228 of 2000 took 0.113s
  training loss:		0.011332
  validation loss:		0.373258
  validation accuracy:		93.37 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.011163
  validation loss:		0.364680
  validation accuracy:		93.26 %
Epoch 1230 of 2000 took 0.093s
  training loss:		0.011452
  validation loss:		0.362917
  validation accuracy:		93.48 %
Epoch 1231 of 2000 took 0.094s
  training loss:		0.011833
  validation loss:		0.360012
  validation accuracy:		93.37 %
Epoch 1232 of 2000 took 0.116s
  training loss:		0.011658
  validation loss:		0.366769
  validation accuracy:		93.26 %
Epoch 1233 of 2000 took 0.200s
  training loss:		0.011314
  validation loss:		0.368956
  validation accuracy:		93.48 %
Epoch 1234 of 2000 took 0.137s
  training loss:		0.011467
  validation loss:		0.385759
  validation accuracy:		92.93 %
Epoch 1235 of 2000 took 0.115s
  training loss:		0.012037
  validation loss:		0.367299
  validation accuracy:		93.59 %
Epoch 1236 of 2000 took 0.102s
  training loss:		0.011762
  validation loss:		0.366107
  validation accuracy:		93.48 %
Epoch 1237 of 2000 took 0.087s
  training loss:		0.011807
  validation loss:		0.362324
  validation accuracy:		93.59 %
Epoch 1238 of 2000 took 0.087s
  training loss:		0.011597
  validation loss:		0.374511
  validation accuracy:		93.37 %
Epoch 1239 of 2000 took 0.087s
  training loss:		0.011605
  validation loss:		0.365162
  validation accuracy:		93.70 %
Epoch 1240 of 2000 took 0.091s
  training loss:		0.011727
  validation loss:		0.361036
  validation accuracy:		93.59 %
Epoch 1241 of 2000 took 0.112s
  training loss:		0.011363
  validation loss:		0.367235
  validation accuracy:		93.48 %
Epoch 1242 of 2000 took 0.126s
  training loss:		0.011286
  validation loss:		0.367046
  validation accuracy:		93.59 %
Epoch 1243 of 2000 took 0.114s
  training loss:		0.011188
  validation loss:		0.369171
  validation accuracy:		93.48 %
Epoch 1244 of 2000 took 0.122s
  training loss:		0.011170
  validation loss:		0.372553
  validation accuracy:		93.37 %
Epoch 1245 of 2000 took 0.118s
  training loss:		0.011104
  validation loss:		0.372896
  validation accuracy:		93.59 %
Epoch 1246 of 2000 took 0.100s
  training loss:		0.011058
  validation loss:		0.372382
  validation accuracy:		93.48 %
Epoch 1247 of 2000 took 0.114s
  training loss:		0.011204
  validation loss:		0.375546
  validation accuracy:		93.48 %
Epoch 1248 of 2000 took 0.108s
  training loss:		0.011203
  validation loss:		0.375116
  validation accuracy:		93.37 %
Epoch 1249 of 2000 took 0.200s
  training loss:		0.010859
  validation loss:		0.371008
  validation accuracy:		93.48 %
Epoch 1250 of 2000 took 0.166s
  training loss:		0.011069
  validation loss:		0.375861
  validation accuracy:		93.37 %
Epoch 1251 of 2000 took 0.120s
  training loss:		0.011072
  validation loss:		0.379619
  validation accuracy:		93.26 %
Epoch 1252 of 2000 took 0.115s
  training loss:		0.011196
  validation loss:		0.373170
  validation accuracy:		93.48 %
Epoch 1253 of 2000 took 0.092s
  training loss:		0.011119
  validation loss:		0.363354
  validation accuracy:		93.59 %
Epoch 1254 of 2000 took 0.083s
  training loss:		0.011274
  validation loss:		0.370218
  validation accuracy:		93.48 %
Epoch 1255 of 2000 took 0.084s
  training loss:		0.011387
  validation loss:		0.376250
  validation accuracy:		93.37 %
Epoch 1256 of 2000 took 0.092s
  training loss:		0.010735
  validation loss:		0.375624
  validation accuracy:		93.48 %
Epoch 1257 of 2000 took 0.090s
  training loss:		0.011042
  validation loss:		0.363261
  validation accuracy:		93.59 %
Epoch 1258 of 2000 took 0.093s
  training loss:		0.010849
  validation loss:		0.383478
  validation accuracy:		93.15 %
Epoch 1259 of 2000 took 0.105s
  training loss:		0.010925
  validation loss:		0.374614
  validation accuracy:		93.59 %
Epoch 1260 of 2000 took 0.102s
  training loss:		0.010786
  validation loss:		0.377736
  validation accuracy:		93.37 %
Epoch 1261 of 2000 took 0.090s
  training loss:		0.010779
  validation loss:		0.376503
  validation accuracy:		93.48 %
Epoch 1262 of 2000 took 0.090s
  training loss:		0.011064
  validation loss:		0.375737
  validation accuracy:		93.37 %
Epoch 1263 of 2000 took 0.091s
  training loss:		0.010954
  validation loss:		0.380847
  validation accuracy:		93.37 %
Epoch 1264 of 2000 took 0.092s
  training loss:		0.011142
  validation loss:		0.376049
  validation accuracy:		93.37 %
Epoch 1265 of 2000 took 0.088s
  training loss:		0.010916
  validation loss:		0.377245
  validation accuracy:		93.48 %
Epoch 1266 of 2000 took 0.094s
  training loss:		0.010779
  validation loss:		0.376345
  validation accuracy:		93.48 %
Epoch 1267 of 2000 took 0.160s
  training loss:		0.010409
  validation loss:		0.377864
  validation accuracy:		93.26 %
Epoch 1268 of 2000 took 0.163s
  training loss:		0.010520
  validation loss:		0.375458
  validation accuracy:		93.59 %
Epoch 1269 of 2000 took 0.139s
  training loss:		0.010737
  validation loss:		0.368744
  validation accuracy:		93.48 %
Epoch 1270 of 2000 took 0.121s
  training loss:		0.010977
  validation loss:		0.379942
  validation accuracy:		93.26 %
Epoch 1271 of 2000 took 0.138s
  training loss:		0.010457
  validation loss:		0.376567
  validation accuracy:		93.37 %
Epoch 1272 of 2000 took 0.111s
  training loss:		0.010946
  validation loss:		0.378696
  validation accuracy:		93.37 %
Epoch 1273 of 2000 took 0.110s
  training loss:		0.010709
  validation loss:		0.376231
  validation accuracy:		93.37 %
Epoch 1274 of 2000 took 0.106s
  training loss:		0.010545
  validation loss:		0.378597
  validation accuracy:		93.26 %
Epoch 1275 of 2000 took 0.108s
  training loss:		0.010336
  validation loss:		0.378721
  validation accuracy:		93.37 %
Epoch 1276 of 2000 took 0.094s
  training loss:		0.010451
  validation loss:		0.374832
  validation accuracy:		93.59 %
Epoch 1277 of 2000 took 0.093s
  training loss:		0.010467
  validation loss:		0.380996
  validation accuracy:		93.26 %
Epoch 1278 of 2000 took 0.107s
  training loss:		0.010338
  validation loss:		0.387918
  validation accuracy:		93.26 %
Epoch 1279 of 2000 took 0.098s
  training loss:		0.010245
  validation loss:		0.372463
  validation accuracy:		93.37 %
Epoch 1280 of 2000 took 0.103s
  training loss:		0.010251
  validation loss:		0.379586
  validation accuracy:		93.59 %
Epoch 1281 of 2000 took 0.125s
  training loss:		0.010108
  validation loss:		0.383678
  validation accuracy:		93.26 %
Epoch 1282 of 2000 took 0.113s
  training loss:		0.010493
  validation loss:		0.381694
  validation accuracy:		93.26 %
Epoch 1283 of 2000 took 0.114s
  training loss:		0.009930
  validation loss:		0.377636
  validation accuracy:		93.37 %
Epoch 1284 of 2000 took 0.110s
  training loss:		0.010488
  validation loss:		0.385097
  validation accuracy:		93.04 %
Epoch 1285 of 2000 took 0.115s
  training loss:		0.010683
  validation loss:		0.376657
  validation accuracy:		93.37 %
Epoch 1286 of 2000 took 0.103s
  training loss:		0.010214
  validation loss:		0.374285
  validation accuracy:		93.59 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.010198
  validation loss:		0.387070
  validation accuracy:		93.26 %
Epoch 1288 of 2000 took 0.091s
  training loss:		0.009829
  validation loss:		0.377019
  validation accuracy:		93.48 %
Epoch 1289 of 2000 took 0.093s
  training loss:		0.010519
  validation loss:		0.381415
  validation accuracy:		93.48 %
Epoch 1290 of 2000 took 0.099s
  training loss:		0.009960
  validation loss:		0.382978
  validation accuracy:		93.37 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.010231
  validation loss:		0.380097
  validation accuracy:		93.26 %
Epoch 1292 of 2000 took 0.098s
  training loss:		0.009997
  validation loss:		0.387332
  validation accuracy:		93.48 %
Epoch 1293 of 2000 took 0.102s
  training loss:		0.009976
  validation loss:		0.382758
  validation accuracy:		93.37 %
Epoch 1294 of 2000 took 0.119s
  training loss:		0.010274
  validation loss:		0.380642
  validation accuracy:		93.26 %
Epoch 1295 of 2000 took 0.115s
  training loss:		0.010046
  validation loss:		0.383869
  validation accuracy:		93.37 %
Epoch 1296 of 2000 took 0.115s
  training loss:		0.009924
  validation loss:		0.385243
  validation accuracy:		93.26 %
Epoch 1297 of 2000 took 0.105s
  training loss:		0.010290
  validation loss:		0.380581
  validation accuracy:		93.37 %
Epoch 1298 of 2000 took 0.108s
  training loss:		0.010121
  validation loss:		0.388655
  validation accuracy:		93.15 %
Epoch 1299 of 2000 took 0.109s
  training loss:		0.009599
  validation loss:		0.385459
  validation accuracy:		93.37 %
Epoch 1300 of 2000 took 0.123s
  training loss:		0.009921
  validation loss:		0.387994
  validation accuracy:		93.37 %
Epoch 1301 of 2000 took 0.114s
  training loss:		0.009694
  validation loss:		0.382968
  validation accuracy:		93.26 %
Epoch 1302 of 2000 took 0.114s
  training loss:		0.009962
  validation loss:		0.386227
  validation accuracy:		93.37 %
Epoch 1303 of 2000 took 0.117s
  training loss:		0.010504
  validation loss:		0.386908
  validation accuracy:		93.15 %
Epoch 1304 of 2000 took 0.110s
  training loss:		0.009996
  validation loss:		0.389577
  validation accuracy:		93.26 %
Epoch 1305 of 2000 took 0.123s
  training loss:		0.009743
  validation loss:		0.389664
  validation accuracy:		93.26 %
Epoch 1306 of 2000 took 0.118s
  training loss:		0.009873
  validation loss:		0.386770
  validation accuracy:		93.48 %
Epoch 1307 of 2000 took 0.136s
  training loss:		0.009966
  validation loss:		0.382147
  validation accuracy:		93.26 %
Epoch 1308 of 2000 took 0.101s
  training loss:		0.010443
  validation loss:		0.386288
  validation accuracy:		93.37 %
Epoch 1309 of 2000 took 0.093s
  training loss:		0.010324
  validation loss:		0.384182
  validation accuracy:		93.48 %
Epoch 1310 of 2000 took 0.118s
  training loss:		0.009688
  validation loss:		0.377697
  validation accuracy:		93.26 %
Epoch 1311 of 2000 took 0.175s
  training loss:		0.009928
  validation loss:		0.392367
  validation accuracy:		93.15 %
Epoch 1312 of 2000 took 0.179s
  training loss:		0.009692
  validation loss:		0.389391
  validation accuracy:		93.37 %
Epoch 1313 of 2000 took 0.180s
  training loss:		0.010093
  validation loss:		0.385227
  validation accuracy:		93.37 %
Epoch 1314 of 2000 took 0.149s
  training loss:		0.009718
  validation loss:		0.388966
  validation accuracy:		93.37 %
Epoch 1315 of 2000 took 0.222s
  training loss:		0.009535
  validation loss:		0.387644
  validation accuracy:		93.37 %
Epoch 1316 of 2000 took 0.146s
  training loss:		0.009793
  validation loss:		0.382365
  validation accuracy:		93.59 %
Epoch 1317 of 2000 took 0.130s
  training loss:		0.009486
  validation loss:		0.392182
  validation accuracy:		93.26 %
Epoch 1318 of 2000 took 0.138s
  training loss:		0.010239
  validation loss:		0.387971
  validation accuracy:		93.37 %
Epoch 1319 of 2000 took 0.182s
  training loss:		0.009577
  validation loss:		0.390527
  validation accuracy:		93.26 %
Epoch 1320 of 2000 took 0.170s
  training loss:		0.009641
  validation loss:		0.395590
  validation accuracy:		93.26 %
Epoch 1321 of 2000 took 0.131s
  training loss:		0.009515
  validation loss:		0.388841
  validation accuracy:		93.37 %
Epoch 1322 of 2000 took 0.120s
  training loss:		0.009166
  validation loss:		0.393808
  validation accuracy:		93.15 %
Epoch 1323 of 2000 took 0.115s
  training loss:		0.009515
  validation loss:		0.387847
  validation accuracy:		93.26 %
Epoch 1324 of 2000 took 0.114s
  training loss:		0.009443
  validation loss:		0.389974
  validation accuracy:		93.37 %
Epoch 1325 of 2000 took 0.125s
  training loss:		0.009099
  validation loss:		0.385167
  validation accuracy:		93.26 %
Epoch 1326 of 2000 took 0.128s
  training loss:		0.009568
  validation loss:		0.389488
  validation accuracy:		93.48 %
Epoch 1327 of 2000 took 0.127s
  training loss:		0.009551
  validation loss:		0.389444
  validation accuracy:		93.59 %
Epoch 1328 of 2000 took 0.117s
  training loss:		0.009551
  validation loss:		0.393788
  validation accuracy:		93.37 %
Epoch 1329 of 2000 took 0.124s
  training loss:		0.009187
  validation loss:		0.396563
  validation accuracy:		93.04 %
Epoch 1330 of 2000 took 0.134s
  training loss:		0.009641
  validation loss:		0.387033
  validation accuracy:		93.59 %
Epoch 1331 of 2000 took 0.120s
  training loss:		0.009489
  validation loss:		0.383784
  validation accuracy:		93.15 %
Epoch 1332 of 2000 took 0.123s
  training loss:		0.009077
  validation loss:		0.393982
  validation accuracy:		93.37 %
Epoch 1333 of 2000 took 0.134s
  training loss:		0.009217
  validation loss:		0.392407
  validation accuracy:		93.26 %
Epoch 1334 of 2000 took 0.104s
  training loss:		0.009460
  validation loss:		0.396437
  validation accuracy:		93.48 %
Epoch 1335 of 2000 took 0.105s
  training loss:		0.009219
  validation loss:		0.391618
  validation accuracy:		93.26 %
Epoch 1336 of 2000 took 0.103s
  training loss:		0.009107
  validation loss:		0.391920
  validation accuracy:		93.26 %
Epoch 1337 of 2000 took 0.133s
  training loss:		0.009494
  validation loss:		0.395908
  validation accuracy:		93.37 %
Epoch 1338 of 2000 took 0.120s
  training loss:		0.009508
  validation loss:		0.389605
  validation accuracy:		93.15 %
Epoch 1339 of 2000 took 0.133s
  training loss:		0.009179
  validation loss:		0.391556
  validation accuracy:		93.48 %
Epoch 1340 of 2000 took 0.169s
  training loss:		0.009070
  validation loss:		0.391574
  validation accuracy:		93.37 %
Epoch 1341 of 2000 took 0.151s
  training loss:		0.009265
  validation loss:		0.395202
  validation accuracy:		93.26 %
Epoch 1342 of 2000 took 0.154s
  training loss:		0.009357
  validation loss:		0.394976
  validation accuracy:		93.15 %
Epoch 1343 of 2000 took 0.125s
  training loss:		0.009292
  validation loss:		0.394437
  validation accuracy:		93.37 %
Epoch 1344 of 2000 took 0.280s
  training loss:		0.009552
  validation loss:		0.397076
  validation accuracy:		93.15 %
Epoch 1345 of 2000 took 0.269s
  training loss:		0.009014
  validation loss:		0.391169
  validation accuracy:		93.48 %
Epoch 1346 of 2000 took 0.335s
  training loss:		0.009431
  validation loss:		0.389776
  validation accuracy:		93.48 %
Epoch 1347 of 2000 took 0.193s
  training loss:		0.009225
  validation loss:		0.396819
  validation accuracy:		93.26 %
Epoch 1348 of 2000 took 0.152s
  training loss:		0.009343
  validation loss:		0.388534
  validation accuracy:		93.48 %
Epoch 1349 of 2000 took 0.116s
  training loss:		0.009107
  validation loss:		0.395098
  validation accuracy:		93.26 %
Epoch 1350 of 2000 took 0.117s
  training loss:		0.009361
  validation loss:		0.393912
  validation accuracy:		93.37 %
Epoch 1351 of 2000 took 0.120s
  training loss:		0.009298
  validation loss:		0.392289
  validation accuracy:		93.37 %
Epoch 1352 of 2000 took 0.102s
  training loss:		0.009079
  validation loss:		0.387618
  validation accuracy:		93.37 %
Epoch 1353 of 2000 took 0.094s
  training loss:		0.009443
  validation loss:		0.396776
  validation accuracy:		93.26 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.009370
  validation loss:		0.399504
  validation accuracy:		93.26 %
Epoch 1355 of 2000 took 0.103s
  training loss:		0.008887
  validation loss:		0.394052
  validation accuracy:		93.26 %
Epoch 1356 of 2000 took 0.191s
  training loss:		0.008959
  validation loss:		0.396055
  validation accuracy:		93.37 %
Epoch 1357 of 2000 took 0.167s
  training loss:		0.009287
  validation loss:		0.396328
  validation accuracy:		93.04 %
Epoch 1358 of 2000 took 0.104s
  training loss:		0.008933
  validation loss:		0.400744
  validation accuracy:		93.37 %
Epoch 1359 of 2000 took 0.090s
  training loss:		0.008776
  validation loss:		0.396223
  validation accuracy:		93.37 %
Epoch 1360 of 2000 took 0.120s
  training loss:		0.008886
  validation loss:		0.404723
  validation accuracy:		93.15 %
Epoch 1361 of 2000 took 0.112s
  training loss:		0.009458
  validation loss:		0.398360
  validation accuracy:		93.37 %
Epoch 1362 of 2000 took 0.118s
  training loss:		0.009146
  validation loss:		0.400733
  validation accuracy:		93.26 %
Epoch 1363 of 2000 took 0.123s
  training loss:		0.009094
  validation loss:		0.400710
  validation accuracy:		93.37 %
Epoch 1364 of 2000 took 0.115s
  training loss:		0.009159
  validation loss:		0.396669
  validation accuracy:		93.15 %
Epoch 1365 of 2000 took 0.100s
  training loss:		0.008809
  validation loss:		0.401182
  validation accuracy:		93.37 %
Epoch 1366 of 2000 took 0.106s
  training loss:		0.008676
  validation loss:		0.397003
  validation accuracy:		93.37 %
Epoch 1367 of 2000 took 0.106s
  training loss:		0.008735
  validation loss:		0.398130
  validation accuracy:		93.37 %
Epoch 1368 of 2000 took 0.103s
  training loss:		0.008532
  validation loss:		0.395067
  validation accuracy:		93.48 %
Epoch 1369 of 2000 took 0.113s
  training loss:		0.008978
  validation loss:		0.402842
  validation accuracy:		93.15 %
Epoch 1370 of 2000 took 0.104s
  training loss:		0.008493
  validation loss:		0.400305
  validation accuracy:		93.26 %
Epoch 1371 of 2000 took 0.151s
  training loss:		0.008717
  validation loss:		0.402735
  validation accuracy:		93.37 %
Epoch 1372 of 2000 took 0.125s
  training loss:		0.008786
  validation loss:		0.402939
  validation accuracy:		93.15 %
Epoch 1373 of 2000 took 0.100s
  training loss:		0.008770
  validation loss:		0.397530
  validation accuracy:		93.37 %
Epoch 1374 of 2000 took 0.101s
  training loss:		0.008691
  validation loss:		0.405286
  validation accuracy:		92.93 %
Epoch 1375 of 2000 took 0.099s
  training loss:		0.008631
  validation loss:		0.402486
  validation accuracy:		93.37 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.008800
  validation loss:		0.402300
  validation accuracy:		93.26 %
Epoch 1377 of 2000 took 0.103s
  training loss:		0.008770
  validation loss:		0.402660
  validation accuracy:		93.26 %
Epoch 1378 of 2000 took 0.125s
  training loss:		0.008981
  validation loss:		0.404170
  validation accuracy:		93.37 %
Epoch 1379 of 2000 took 0.094s
  training loss:		0.008566
  validation loss:		0.400440
  validation accuracy:		93.37 %
Epoch 1380 of 2000 took 0.101s
  training loss:		0.008369
  validation loss:		0.399151
  validation accuracy:		93.48 %
Epoch 1381 of 2000 took 0.121s
  training loss:		0.008512
  validation loss:		0.411248
  validation accuracy:		93.04 %
Epoch 1382 of 2000 took 0.127s
  training loss:		0.009104
  validation loss:		0.407072
  validation accuracy:		93.04 %
Epoch 1383 of 2000 took 0.126s
  training loss:		0.008586
  validation loss:		0.404738
  validation accuracy:		93.15 %
Epoch 1384 of 2000 took 0.119s
  training loss:		0.008635
  validation loss:		0.404377
  validation accuracy:		93.37 %
Epoch 1385 of 2000 took 0.141s
  training loss:		0.008687
  validation loss:		0.408758
  validation accuracy:		93.04 %
Epoch 1386 of 2000 took 0.126s
  training loss:		0.008486
  validation loss:		0.398685
  validation accuracy:		93.37 %
Epoch 1387 of 2000 took 0.132s
  training loss:		0.008471
  validation loss:		0.407408
  validation accuracy:		93.26 %
Epoch 1388 of 2000 took 0.117s
  training loss:		0.008173
  validation loss:		0.396815
  validation accuracy:		93.59 %
Epoch 1389 of 2000 took 0.095s
  training loss:		0.008815
  validation loss:		0.404685
  validation accuracy:		93.37 %
Epoch 1390 of 2000 took 0.090s
  training loss:		0.008350
  validation loss:		0.403354
  validation accuracy:		93.37 %
Epoch 1391 of 2000 took 0.102s
  training loss:		0.008430
  validation loss:		0.400145
  validation accuracy:		93.48 %
Epoch 1392 of 2000 took 0.100s
  training loss:		0.008494
  validation loss:		0.403108
  validation accuracy:		93.15 %
Epoch 1393 of 2000 took 0.101s
  training loss:		0.008460
  validation loss:		0.409924
  validation accuracy:		93.04 %
Epoch 1394 of 2000 took 0.095s
  training loss:		0.008434
  validation loss:		0.402546
  validation accuracy:		93.26 %
Epoch 1395 of 2000 took 0.101s
  training loss:		0.008213
  validation loss:		0.408974
  validation accuracy:		93.04 %
Epoch 1396 of 2000 took 0.104s
  training loss:		0.008137
  validation loss:		0.404635
  validation accuracy:		93.26 %
Epoch 1397 of 2000 took 0.090s
  training loss:		0.008456
  validation loss:		0.406316
  validation accuracy:		93.15 %
Epoch 1398 of 2000 took 0.102s
  training loss:		0.008248
  validation loss:		0.408842
  validation accuracy:		93.15 %
Epoch 1399 of 2000 took 0.110s
  training loss:		0.007963
  validation loss:		0.402466
  validation accuracy:		93.04 %
Epoch 1400 of 2000 took 0.102s
  training loss:		0.008096
  validation loss:		0.407085
  validation accuracy:		93.26 %
Epoch 1401 of 2000 took 0.102s
  training loss:		0.008256
  validation loss:		0.413972
  validation accuracy:		93.04 %
Epoch 1402 of 2000 took 0.113s
  training loss:		0.008474
  validation loss:		0.405645
  validation accuracy:		93.48 %
Epoch 1403 of 2000 took 0.118s
  training loss:		0.008044
  validation loss:		0.404922
  validation accuracy:		93.15 %
Epoch 1404 of 2000 took 0.127s
  training loss:		0.008069
  validation loss:		0.410508
  validation accuracy:		93.04 %
Epoch 1405 of 2000 took 0.118s
  training loss:		0.008184
  validation loss:		0.415825
  validation accuracy:		93.04 %
Epoch 1406 of 2000 took 0.104s
  training loss:		0.008170
  validation loss:		0.404057
  validation accuracy:		93.37 %
Epoch 1407 of 2000 took 0.103s
  training loss:		0.008112
  validation loss:		0.405604
  validation accuracy:		93.26 %
Epoch 1408 of 2000 took 0.101s
  training loss:		0.008326
  validation loss:		0.413212
  validation accuracy:		93.15 %
Epoch 1409 of 2000 took 0.100s
  training loss:		0.008201
  validation loss:		0.407628
  validation accuracy:		93.26 %
Epoch 1410 of 2000 took 0.115s
  training loss:		0.008140
  validation loss:		0.410229
  validation accuracy:		93.26 %
Epoch 1411 of 2000 took 0.146s
  training loss:		0.008272
  validation loss:		0.403366
  validation accuracy:		93.37 %
Epoch 1412 of 2000 took 0.126s
  training loss:		0.007927
  validation loss:		0.402410
  validation accuracy:		93.37 %
Epoch 1413 of 2000 took 0.102s
  training loss:		0.008082
  validation loss:		0.410169
  validation accuracy:		93.04 %
Epoch 1414 of 2000 took 0.122s
  training loss:		0.008122
  validation loss:		0.406206
  validation accuracy:		93.26 %
Epoch 1415 of 2000 took 0.148s
  training loss:		0.008136
  validation loss:		0.404292
  validation accuracy:		93.15 %
Epoch 1416 of 2000 took 0.144s
  training loss:		0.007999
  validation loss:		0.407769
  validation accuracy:		93.37 %
Epoch 1417 of 2000 took 0.132s
  training loss:		0.008261
  validation loss:		0.412062
  validation accuracy:		93.26 %
Epoch 1418 of 2000 took 0.107s
  training loss:		0.008052
  validation loss:		0.407620
  validation accuracy:		93.26 %
Epoch 1419 of 2000 took 0.107s
  training loss:		0.008217
  validation loss:		0.407804
  validation accuracy:		93.26 %
Epoch 1420 of 2000 took 0.123s
  training loss:		0.007984
  validation loss:		0.400917
  validation accuracy:		93.48 %
Epoch 1421 of 2000 took 0.120s
  training loss:		0.008195
  validation loss:		0.409409
  validation accuracy:		93.15 %
Epoch 1422 of 2000 took 0.121s
  training loss:		0.008300
  validation loss:		0.413900
  validation accuracy:		93.15 %
Epoch 1423 of 2000 took 0.105s
  training loss:		0.007546
  validation loss:		0.412206
  validation accuracy:		93.26 %
Epoch 1424 of 2000 took 0.098s
  training loss:		0.008004
  validation loss:		0.415621
  validation accuracy:		93.04 %
Epoch 1425 of 2000 took 0.099s
  training loss:		0.008093
  validation loss:		0.416459
  validation accuracy:		93.15 %
Epoch 1426 of 2000 took 0.094s
  training loss:		0.008073
  validation loss:		0.413195
  validation accuracy:		93.15 %
Epoch 1427 of 2000 took 0.109s
  training loss:		0.008040
  validation loss:		0.410460
  validation accuracy:		93.15 %
Epoch 1428 of 2000 took 0.105s
  training loss:		0.007795
  validation loss:		0.411264
  validation accuracy:		93.15 %
Epoch 1429 of 2000 took 0.099s
  training loss:		0.007732
  validation loss:		0.411551
  validation accuracy:		93.15 %
Epoch 1430 of 2000 took 0.102s
  training loss:		0.007943
  validation loss:		0.410355
  validation accuracy:		93.26 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.007836
  validation loss:		0.417212
  validation accuracy:		93.04 %
Epoch 1432 of 2000 took 0.101s
  training loss:		0.008060
  validation loss:		0.413677
  validation accuracy:		93.04 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.008081
  validation loss:		0.410573
  validation accuracy:		93.26 %
Epoch 1434 of 2000 took 0.104s
  training loss:		0.007804
  validation loss:		0.408326
  validation accuracy:		93.04 %
Epoch 1435 of 2000 took 0.108s
  training loss:		0.007611
  validation loss:		0.416148
  validation accuracy:		93.04 %
Epoch 1436 of 2000 took 0.103s
  training loss:		0.007792
  validation loss:		0.420370
  validation accuracy:		92.72 %
Epoch 1437 of 2000 took 0.103s
  training loss:		0.007843
  validation loss:		0.410762
  validation accuracy:		93.15 %
Epoch 1438 of 2000 took 0.100s
  training loss:		0.007603
  validation loss:		0.413751
  validation accuracy:		93.15 %
Epoch 1439 of 2000 took 0.099s
  training loss:		0.007416
  validation loss:		0.413425
  validation accuracy:		93.37 %
Epoch 1440 of 2000 took 0.102s
  training loss:		0.007708
  validation loss:		0.416989
  validation accuracy:		93.04 %
Epoch 1441 of 2000 took 0.100s
  training loss:		0.007644
  validation loss:		0.413098
  validation accuracy:		93.26 %
Epoch 1442 of 2000 took 0.103s
  training loss:		0.007991
  validation loss:		0.418057
  validation accuracy:		92.93 %
Epoch 1443 of 2000 took 0.101s
  training loss:		0.007618
  validation loss:		0.416353
  validation accuracy:		93.15 %
Epoch 1444 of 2000 took 0.100s
  training loss:		0.007636
  validation loss:		0.415479
  validation accuracy:		93.15 %
Epoch 1445 of 2000 took 0.099s
  training loss:		0.007517
  validation loss:		0.410625
  validation accuracy:		93.26 %
Epoch 1446 of 2000 took 0.099s
  training loss:		0.007504
  validation loss:		0.412007
  validation accuracy:		93.26 %
Epoch 1447 of 2000 took 0.101s
  training loss:		0.007833
  validation loss:		0.413530
  validation accuracy:		93.15 %
Epoch 1448 of 2000 took 0.113s
  training loss:		0.007360
  validation loss:		0.414564
  validation accuracy:		93.15 %
Epoch 1449 of 2000 took 0.130s
  training loss:		0.007478
  validation loss:		0.409679
  validation accuracy:		93.15 %
Epoch 1450 of 2000 took 0.131s
  training loss:		0.006992
  validation loss:		0.409502
  validation accuracy:		93.26 %
Epoch 1451 of 2000 took 0.127s
  training loss:		0.007570
  validation loss:		0.412327
  validation accuracy:		93.37 %
Epoch 1452 of 2000 took 0.127s
  training loss:		0.007762
  validation loss:		0.411347
  validation accuracy:		93.04 %
Epoch 1453 of 2000 took 0.131s
  training loss:		0.007248
  validation loss:		0.419456
  validation accuracy:		93.04 %
Epoch 1454 of 2000 took 0.133s
  training loss:		0.007665
  validation loss:		0.417582
  validation accuracy:		93.15 %
Epoch 1455 of 2000 took 0.135s
  training loss:		0.007492
  validation loss:		0.419533
  validation accuracy:		93.04 %
Epoch 1456 of 2000 took 0.129s
  training loss:		0.007412
  validation loss:		0.411163
  validation accuracy:		93.37 %
Epoch 1457 of 2000 took 0.119s
  training loss:		0.007829
  validation loss:		0.412602
  validation accuracy:		93.26 %
Epoch 1458 of 2000 took 0.108s
  training loss:		0.007381
  validation loss:		0.422131
  validation accuracy:		93.04 %
Epoch 1459 of 2000 took 0.111s
  training loss:		0.007238
  validation loss:		0.414994
  validation accuracy:		93.15 %
Epoch 1460 of 2000 took 0.098s
  training loss:		0.007455
  validation loss:		0.416538
  validation accuracy:		93.15 %
Epoch 1461 of 2000 took 0.107s
  training loss:		0.007214
  validation loss:		0.417902
  validation accuracy:		93.15 %
Epoch 1462 of 2000 took 0.110s
  training loss:		0.007403
  validation loss:		0.416120
  validation accuracy:		93.04 %
Epoch 1463 of 2000 took 0.114s
  training loss:		0.007316
  validation loss:		0.416975
  validation accuracy:		93.37 %
Epoch 1464 of 2000 took 0.113s
  training loss:		0.007305
  validation loss:		0.415990
  validation accuracy:		93.04 %
Epoch 1465 of 2000 took 0.100s
  training loss:		0.007188
  validation loss:		0.415944
  validation accuracy:		93.15 %
Epoch 1466 of 2000 took 0.100s
  training loss:		0.007312
  validation loss:		0.414512
  validation accuracy:		93.15 %
Epoch 1467 of 2000 took 0.103s
  training loss:		0.007466
  validation loss:		0.414228
  validation accuracy:		93.04 %
Epoch 1468 of 2000 took 0.109s
  training loss:		0.007627
  validation loss:		0.412115
  validation accuracy:		93.37 %
Epoch 1469 of 2000 took 0.104s
  training loss:		0.007491
  validation loss:		0.419210
  validation accuracy:		93.04 %
Epoch 1470 of 2000 took 0.103s
  training loss:		0.007456
  validation loss:		0.419405
  validation accuracy:		93.15 %
Epoch 1471 of 2000 took 0.103s
  training loss:		0.007309
  validation loss:		0.419699
  validation accuracy:		93.04 %
Epoch 1472 of 2000 took 0.099s
  training loss:		0.007350
  validation loss:		0.427897
  validation accuracy:		93.15 %
Epoch 1473 of 2000 took 0.115s
  training loss:		0.007285
  validation loss:		0.416453
  validation accuracy:		93.15 %
Epoch 1474 of 2000 took 0.119s
  training loss:		0.007044
  validation loss:		0.420217
  validation accuracy:		93.04 %
Epoch 1475 of 2000 took 0.104s
  training loss:		0.007017
  validation loss:		0.416807
  validation accuracy:		93.04 %
Epoch 1476 of 2000 took 0.102s
  training loss:		0.007194
  validation loss:		0.425472
  validation accuracy:		92.93 %
Epoch 1477 of 2000 took 0.103s
  training loss:		0.007125
  validation loss:		0.424261
  validation accuracy:		93.15 %
Epoch 1478 of 2000 took 0.107s
  training loss:		0.007131
  validation loss:		0.419554
  validation accuracy:		93.15 %
Epoch 1479 of 2000 took 0.103s
  training loss:		0.007128
  validation loss:		0.426371
  validation accuracy:		92.83 %
Epoch 1480 of 2000 took 0.101s
  training loss:		0.007119
  validation loss:		0.416315
  validation accuracy:		93.04 %
Epoch 1481 of 2000 took 0.100s
  training loss:		0.007069
  validation loss:		0.421833
  validation accuracy:		93.15 %
Epoch 1482 of 2000 took 0.129s
  training loss:		0.007140
  validation loss:		0.422326
  validation accuracy:		93.15 %
Epoch 1483 of 2000 took 0.143s
  training loss:		0.007039
  validation loss:		0.423187
  validation accuracy:		93.15 %
Epoch 1484 of 2000 took 0.150s
  training loss:		0.007327
  validation loss:		0.418488
  validation accuracy:		93.26 %
Epoch 1485 of 2000 took 0.118s
  training loss:		0.007112
  validation loss:		0.421337
  validation accuracy:		93.04 %
Epoch 1486 of 2000 took 0.116s
  training loss:		0.007130
  validation loss:		0.425825
  validation accuracy:		92.93 %
Epoch 1487 of 2000 took 0.129s
  training loss:		0.007223
  validation loss:		0.421198
  validation accuracy:		93.04 %
Epoch 1488 of 2000 took 0.135s
  training loss:		0.007142
  validation loss:		0.422733
  validation accuracy:		93.26 %
Epoch 1489 of 2000 took 0.130s
  training loss:		0.007185
  validation loss:		0.417442
  validation accuracy:		93.04 %
Epoch 1490 of 2000 took 0.135s
  training loss:		0.007041
  validation loss:		0.421331
  validation accuracy:		93.15 %
Epoch 1491 of 2000 took 0.195s
  training loss:		0.007077
  validation loss:		0.422499
  validation accuracy:		93.04 %
Epoch 1492 of 2000 took 0.143s
  training loss:		0.007063
  validation loss:		0.428395
  validation accuracy:		93.26 %
Epoch 1493 of 2000 took 0.140s
  training loss:		0.007173
  validation loss:		0.426340
  validation accuracy:		93.04 %
Epoch 1494 of 2000 took 0.124s
  training loss:		0.006945
  validation loss:		0.428747
  validation accuracy:		92.93 %
Epoch 1495 of 2000 took 0.142s
  training loss:		0.006826
  validation loss:		0.430172
  validation accuracy:		93.15 %
Epoch 1496 of 2000 took 0.143s
  training loss:		0.006948
  validation loss:		0.426586
  validation accuracy:		93.15 %
Epoch 1497 of 2000 took 0.145s
  training loss:		0.006954
  validation loss:		0.429428
  validation accuracy:		93.04 %
Epoch 1498 of 2000 took 0.141s
  training loss:		0.007062
  validation loss:		0.422707
  validation accuracy:		93.26 %
Epoch 1499 of 2000 took 0.132s
  training loss:		0.006905
  validation loss:		0.432827
  validation accuracy:		92.83 %
Epoch 1500 of 2000 took 0.135s
  training loss:		0.006806
  validation loss:		0.419051
  validation accuracy:		93.04 %
Epoch 1501 of 2000 took 0.129s
  training loss:		0.006870
  validation loss:		0.424223
  validation accuracy:		93.15 %
Epoch 1502 of 2000 took 0.121s
  training loss:		0.006838
  validation loss:		0.427434
  validation accuracy:		93.15 %
Epoch 1503 of 2000 took 0.103s
  training loss:		0.007071
  validation loss:		0.424813
  validation accuracy:		93.15 %
Epoch 1504 of 2000 took 0.110s
  training loss:		0.006732
  validation loss:		0.429678
  validation accuracy:		92.93 %
Epoch 1505 of 2000 took 0.106s
  training loss:		0.006863
  validation loss:		0.426226
  validation accuracy:		93.04 %
Epoch 1506 of 2000 took 0.104s
  training loss:		0.006994
  validation loss:		0.427498
  validation accuracy:		93.15 %
Epoch 1507 of 2000 took 0.101s
  training loss:		0.006791
  validation loss:		0.435374
  validation accuracy:		92.83 %
Epoch 1508 of 2000 took 0.101s
  training loss:		0.006786
  validation loss:		0.424968
  validation accuracy:		93.04 %
Epoch 1509 of 2000 took 0.111s
  training loss:		0.007071
  validation loss:		0.429719
  validation accuracy:		93.04 %
Epoch 1510 of 2000 took 0.116s
  training loss:		0.006942
  validation loss:		0.433373
  validation accuracy:		92.83 %
Epoch 1511 of 2000 took 0.126s
  training loss:		0.006912
  validation loss:		0.424211
  validation accuracy:		93.15 %
Epoch 1512 of 2000 took 0.134s
  training loss:		0.006872
  validation loss:		0.421291
  validation accuracy:		92.93 %
Epoch 1513 of 2000 took 0.142s
  training loss:		0.006802
  validation loss:		0.431974
  validation accuracy:		92.83 %
Epoch 1514 of 2000 took 0.131s
  training loss:		0.007220
  validation loss:		0.428777
  validation accuracy:		93.15 %
Epoch 1515 of 2000 took 0.130s
  training loss:		0.006821
  validation loss:		0.423253
  validation accuracy:		93.15 %
Epoch 1516 of 2000 took 0.113s
  training loss:		0.006933
  validation loss:		0.422383
  validation accuracy:		93.04 %
Epoch 1517 of 2000 took 0.190s
  training loss:		0.006777
  validation loss:		0.426924
  validation accuracy:		93.15 %
Epoch 1518 of 2000 took 0.176s
  training loss:		0.006901
  validation loss:		0.428889
  validation accuracy:		93.15 %
Epoch 1519 of 2000 took 0.141s
  training loss:		0.006990
  validation loss:		0.427788
  validation accuracy:		93.04 %
Epoch 1520 of 2000 took 0.122s
  training loss:		0.006621
  validation loss:		0.424487
  validation accuracy:		93.15 %
Epoch 1521 of 2000 took 0.114s
  training loss:		0.006781
  validation loss:		0.425594
  validation accuracy:		93.04 %
Epoch 1522 of 2000 took 0.111s
  training loss:		0.006776
  validation loss:		0.428381
  validation accuracy:		93.04 %
Epoch 1523 of 2000 took 0.145s
  training loss:		0.006801
  validation loss:		0.432248
  validation accuracy:		92.93 %
Epoch 1524 of 2000 took 0.169s
  training loss:		0.006755
  validation loss:		0.428936
  validation accuracy:		93.04 %
Epoch 1525 of 2000 took 0.146s
  training loss:		0.006573
  validation loss:		0.432105
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.135s
  training loss:		0.006537
  validation loss:		0.427272
  validation accuracy:		93.15 %
Epoch 1527 of 2000 took 0.134s
  training loss:		0.006540
  validation loss:		0.432716
  validation accuracy:		93.04 %
Epoch 1528 of 2000 took 0.122s
  training loss:		0.006627
  validation loss:		0.430997
  validation accuracy:		93.15 %
Epoch 1529 of 2000 took 0.132s
  training loss:		0.006790
  validation loss:		0.433048
  validation accuracy:		92.93 %
Epoch 1530 of 2000 took 0.106s
  training loss:		0.006598
  validation loss:		0.427347
  validation accuracy:		93.04 %
Epoch 1531 of 2000 took 0.101s
  training loss:		0.006666
  validation loss:		0.436022
  validation accuracy:		92.93 %
Epoch 1532 of 2000 took 0.109s
  training loss:		0.006866
  validation loss:		0.426714
  validation accuracy:		93.15 %
Epoch 1533 of 2000 took 0.105s
  training loss:		0.006604
  validation loss:		0.429382
  validation accuracy:		93.04 %
Epoch 1534 of 2000 took 0.105s
  training loss:		0.006865
  validation loss:		0.428762
  validation accuracy:		92.93 %
Epoch 1535 of 2000 took 0.099s
  training loss:		0.006545
  validation loss:		0.431933
  validation accuracy:		92.93 %
Epoch 1536 of 2000 took 0.098s
  training loss:		0.006533
  validation loss:		0.427922
  validation accuracy:		93.04 %
Epoch 1537 of 2000 took 0.117s
  training loss:		0.006860
  validation loss:		0.425980
  validation accuracy:		93.15 %
Epoch 1538 of 2000 took 0.105s
  training loss:		0.006740
  validation loss:		0.430574
  validation accuracy:		93.15 %
Epoch 1539 of 2000 took 0.135s
  training loss:		0.006449
  validation loss:		0.436692
  validation accuracy:		92.93 %
Epoch 1540 of 2000 took 0.135s
  training loss:		0.006500
  validation loss:		0.435357
  validation accuracy:		93.04 %
Epoch 1541 of 2000 took 0.135s
  training loss:		0.006502
  validation loss:		0.436569
  validation accuracy:		92.83 %
Epoch 1542 of 2000 took 0.116s
  training loss:		0.006312
  validation loss:		0.434803
  validation accuracy:		92.93 %
Epoch 1543 of 2000 took 0.106s
  training loss:		0.006410
  validation loss:		0.429918
  validation accuracy:		92.93 %
Epoch 1544 of 2000 took 0.127s
  training loss:		0.006588
  validation loss:		0.430166
  validation accuracy:		93.04 %
Epoch 1545 of 2000 took 0.150s
  training loss:		0.006408
  validation loss:		0.424480
  validation accuracy:		93.15 %
Epoch 1546 of 2000 took 0.152s
  training loss:		0.006524
  validation loss:		0.430678
  validation accuracy:		93.04 %
Epoch 1547 of 2000 took 0.111s
  training loss:		0.006484
  validation loss:		0.435705
  validation accuracy:		93.15 %
Epoch 1548 of 2000 took 0.112s
  training loss:		0.006571
  validation loss:		0.437466
  validation accuracy:		93.04 %
Epoch 1549 of 2000 took 0.121s
  training loss:		0.006468
  validation loss:		0.439246
  validation accuracy:		92.93 %
Epoch 1550 of 2000 took 0.106s
  training loss:		0.006184
  validation loss:		0.434054
  validation accuracy:		93.04 %
Epoch 1551 of 2000 took 0.110s
  training loss:		0.006341
  validation loss:		0.429959
  validation accuracy:		93.15 %
Epoch 1552 of 2000 took 0.109s
  training loss:		0.006525
  validation loss:		0.428736
  validation accuracy:		93.04 %
Epoch 1553 of 2000 took 0.120s
  training loss:		0.006438
  validation loss:		0.434553
  validation accuracy:		93.04 %
Epoch 1554 of 2000 took 0.110s
  training loss:		0.006323
  validation loss:		0.436960
  validation accuracy:		92.93 %
Epoch 1555 of 2000 took 0.114s
  training loss:		0.006447
  validation loss:		0.439567
  validation accuracy:		92.93 %
Epoch 1556 of 2000 took 0.110s
  training loss:		0.006252
  validation loss:		0.439302
  validation accuracy:		93.15 %
Epoch 1557 of 2000 took 0.112s
  training loss:		0.006393
  validation loss:		0.431605
  validation accuracy:		93.37 %
Epoch 1558 of 2000 took 0.120s
  training loss:		0.006426
  validation loss:		0.439895
  validation accuracy:		93.04 %
Epoch 1559 of 2000 took 0.141s
  training loss:		0.006322
  validation loss:		0.437867
  validation accuracy:		92.93 %
Epoch 1560 of 2000 took 0.141s
  training loss:		0.006253
  validation loss:		0.434637
  validation accuracy:		92.83 %
Epoch 1561 of 2000 took 0.136s
  training loss:		0.006284
  validation loss:		0.434398
  validation accuracy:		93.37 %
Epoch 1562 of 2000 took 0.128s
  training loss:		0.006424
  validation loss:		0.439988
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.182s
  training loss:		0.006064
  validation loss:		0.429160
  validation accuracy:		93.26 %
Epoch 1564 of 2000 took 0.147s
  training loss:		0.006447
  validation loss:		0.433893
  validation accuracy:		93.15 %
Epoch 1565 of 2000 took 0.142s
  training loss:		0.006302
  validation loss:		0.441278
  validation accuracy:		93.04 %
Epoch 1566 of 2000 took 0.135s
  training loss:		0.006374
  validation loss:		0.439106
  validation accuracy:		93.04 %
Epoch 1567 of 2000 took 0.133s
  training loss:		0.006363
  validation loss:		0.440606
  validation accuracy:		92.93 %
Epoch 1568 of 2000 took 0.113s
  training loss:		0.006342
  validation loss:		0.433731
  validation accuracy:		93.04 %
Epoch 1569 of 2000 took 0.107s
  training loss:		0.006183
  validation loss:		0.434116
  validation accuracy:		93.04 %
Epoch 1570 of 2000 took 0.108s
  training loss:		0.006195
  validation loss:		0.441193
  validation accuracy:		92.93 %
Epoch 1571 of 2000 took 0.108s
  training loss:		0.006300
  validation loss:		0.435223
  validation accuracy:		92.83 %
Epoch 1572 of 2000 took 0.116s
  training loss:		0.006016
  validation loss:		0.438523
  validation accuracy:		93.04 %
Epoch 1573 of 2000 took 0.123s
  training loss:		0.006285
  validation loss:		0.432898
  validation accuracy:		93.04 %
Epoch 1574 of 2000 took 0.112s
  training loss:		0.006345
  validation loss:		0.441932
  validation accuracy:		92.93 %
Epoch 1575 of 2000 took 0.111s
  training loss:		0.006292
  validation loss:		0.434539
  validation accuracy:		93.15 %
Epoch 1576 of 2000 took 0.115s
  training loss:		0.006446
  validation loss:		0.439382
  validation accuracy:		92.93 %
Epoch 1577 of 2000 took 0.127s
  training loss:		0.005981
  validation loss:		0.441379
  validation accuracy:		92.83 %
Epoch 1578 of 2000 took 0.117s
  training loss:		0.006043
  validation loss:		0.440537
  validation accuracy:		93.26 %
Epoch 1579 of 2000 took 0.134s
  training loss:		0.006071
  validation loss:		0.451321
  validation accuracy:		92.83 %
Epoch 1580 of 2000 took 0.113s
  training loss:		0.006236
  validation loss:		0.442360
  validation accuracy:		92.83 %
Epoch 1581 of 2000 took 0.114s
  training loss:		0.006251
  validation loss:		0.437882
  validation accuracy:		92.93 %
Epoch 1582 of 2000 took 0.118s
  training loss:		0.006126
  validation loss:		0.438663
  validation accuracy:		93.04 %
Epoch 1583 of 2000 took 0.117s
  training loss:		0.006110
  validation loss:		0.442912
  validation accuracy:		93.15 %
Epoch 1584 of 2000 took 0.115s
  training loss:		0.006276
  validation loss:		0.441327
  validation accuracy:		93.15 %
Epoch 1585 of 2000 took 0.114s
  training loss:		0.005963
  validation loss:		0.443218
  validation accuracy:		92.93 %
Epoch 1586 of 2000 took 0.113s
  training loss:		0.005964
  validation loss:		0.442329
  validation accuracy:		93.04 %
Epoch 1587 of 2000 took 0.111s
  training loss:		0.005863
  validation loss:		0.452384
  validation accuracy:		92.72 %
Epoch 1588 of 2000 took 0.141s
  training loss:		0.006316
  validation loss:		0.442248
  validation accuracy:		92.93 %
Epoch 1589 of 2000 took 0.125s
  training loss:		0.006110
  validation loss:		0.446197
  validation accuracy:		92.93 %
Epoch 1590 of 2000 took 0.119s
  training loss:		0.006095
  validation loss:		0.435265
  validation accuracy:		93.04 %
Epoch 1591 of 2000 took 0.137s
  training loss:		0.006218
  validation loss:		0.442449
  validation accuracy:		92.93 %
Epoch 1592 of 2000 took 0.142s
  training loss:		0.005972
  validation loss:		0.441616
  validation accuracy:		92.93 %
Epoch 1593 of 2000 took 0.138s
  training loss:		0.005857
  validation loss:		0.440134
  validation accuracy:		92.83 %
Epoch 1594 of 2000 took 0.142s
  training loss:		0.005941
  validation loss:		0.447111
  validation accuracy:		92.83 %
Epoch 1595 of 2000 took 0.117s
  training loss:		0.005962
  validation loss:		0.442286
  validation accuracy:		93.04 %
Epoch 1596 of 2000 took 0.142s
  training loss:		0.005978
  validation loss:		0.447207
  validation accuracy:		92.93 %
Epoch 1597 of 2000 took 0.178s
  training loss:		0.005935
  validation loss:		0.443074
  validation accuracy:		93.04 %
Epoch 1598 of 2000 took 0.150s
  training loss:		0.005833
  validation loss:		0.439348
  validation accuracy:		92.93 %
Epoch 1599 of 2000 took 0.135s
  training loss:		0.006021
  validation loss:		0.437692
  validation accuracy:		92.83 %
Epoch 1600 of 2000 took 0.159s
  training loss:		0.005989
  validation loss:		0.441261
  validation accuracy:		92.93 %
Epoch 1601 of 2000 took 0.146s
  training loss:		0.005995
  validation loss:		0.444113
  validation accuracy:		93.15 %
Epoch 1602 of 2000 took 0.128s
  training loss:		0.006138
  validation loss:		0.446292
  validation accuracy:		92.93 %
Epoch 1603 of 2000 took 0.116s
  training loss:		0.005920
  validation loss:		0.442673
  validation accuracy:		93.04 %
Epoch 1604 of 2000 took 0.149s
  training loss:		0.005966
  validation loss:		0.447989
  validation accuracy:		92.93 %
Epoch 1605 of 2000 took 0.151s
  training loss:		0.005967
  validation loss:		0.445135
  validation accuracy:		92.83 %
Epoch 1606 of 2000 took 0.174s
  training loss:		0.005939
  validation loss:		0.442492
  validation accuracy:		92.83 %
Epoch 1607 of 2000 took 0.123s
  training loss:		0.005530
  validation loss:		0.447862
  validation accuracy:		92.83 %
Epoch 1608 of 2000 took 0.131s
  training loss:		0.005883
  validation loss:		0.440405
  validation accuracy:		92.93 %
Epoch 1609 of 2000 took 0.144s
  training loss:		0.006006
  validation loss:		0.444007
  validation accuracy:		92.93 %
Epoch 1610 of 2000 took 0.171s
  training loss:		0.005831
  validation loss:		0.442277
  validation accuracy:		92.93 %
Epoch 1611 of 2000 took 0.169s
  training loss:		0.005875
  validation loss:		0.446589
  validation accuracy:		92.93 %
Epoch 1612 of 2000 took 0.138s
  training loss:		0.005503
  validation loss:		0.446148
  validation accuracy:		92.83 %
Epoch 1613 of 2000 took 0.126s
  training loss:		0.005823
  validation loss:		0.444211
  validation accuracy:		92.93 %
Epoch 1614 of 2000 took 0.123s
  training loss:		0.005764
  validation loss:		0.440434
  validation accuracy:		92.93 %
Epoch 1615 of 2000 took 0.128s
  training loss:		0.005661
  validation loss:		0.447932
  validation accuracy:		92.83 %
Epoch 1616 of 2000 took 0.129s
  training loss:		0.005676
  validation loss:		0.444040
  validation accuracy:		92.93 %
Epoch 1617 of 2000 took 0.148s
  training loss:		0.005861
  validation loss:		0.449981
  validation accuracy:		93.04 %
Epoch 1618 of 2000 took 0.155s
  training loss:		0.005756
  validation loss:		0.443169
  validation accuracy:		93.26 %
Epoch 1619 of 2000 took 0.133s
  training loss:		0.005826
  validation loss:		0.448495
  validation accuracy:		93.04 %
Epoch 1620 of 2000 took 0.137s
  training loss:		0.005588
  validation loss:		0.442224
  validation accuracy:		92.93 %
Epoch 1621 of 2000 took 0.138s
  training loss:		0.005744
  validation loss:		0.456460
  validation accuracy:		92.83 %
Epoch 1622 of 2000 took 0.151s
  training loss:		0.005649
  validation loss:		0.449480
  validation accuracy:		93.04 %
Epoch 1623 of 2000 took 0.147s
  training loss:		0.005728
  validation loss:		0.451525
  validation accuracy:		92.83 %
Epoch 1624 of 2000 took 0.144s
  training loss:		0.005789
  validation loss:		0.447320
  validation accuracy:		92.93 %
Epoch 1625 of 2000 took 0.146s
  training loss:		0.005717
  validation loss:		0.449203
  validation accuracy:		92.93 %
Epoch 1626 of 2000 took 0.147s
  training loss:		0.005437
  validation loss:		0.444574
  validation accuracy:		92.93 %
Epoch 1627 of 2000 took 0.143s
  training loss:		0.005699
  validation loss:		0.444856
  validation accuracy:		92.93 %
Epoch 1628 of 2000 took 0.149s
  training loss:		0.005722
  validation loss:		0.450817
  validation accuracy:		92.93 %
Epoch 1629 of 2000 took 0.178s
  training loss:		0.005750
  validation loss:		0.446928
  validation accuracy:		92.93 %
Epoch 1630 of 2000 took 0.155s
  training loss:		0.005526
  validation loss:		0.450243
  validation accuracy:		92.93 %
Epoch 1631 of 2000 took 0.144s
  training loss:		0.005593
  validation loss:		0.445850
  validation accuracy:		92.83 %
Epoch 1632 of 2000 took 0.143s
  training loss:		0.005546
  validation loss:		0.453153
  validation accuracy:		92.83 %
Epoch 1633 of 2000 took 0.193s
  training loss:		0.005578
  validation loss:		0.451797
  validation accuracy:		92.83 %
Epoch 1634 of 2000 took 0.148s
  training loss:		0.005719
  validation loss:		0.455259
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.152s
  training loss:		0.005568
  validation loss:		0.449738
  validation accuracy:		92.93 %
Epoch 1636 of 2000 took 0.131s
  training loss:		0.005525
  validation loss:		0.444708
  validation accuracy:		92.93 %
Epoch 1637 of 2000 took 0.120s
  training loss:		0.005716
  validation loss:		0.440866
  validation accuracy:		93.26 %
Epoch 1638 of 2000 took 0.120s
  training loss:		0.005689
  validation loss:		0.451495
  validation accuracy:		92.83 %
Epoch 1639 of 2000 took 0.117s
  training loss:		0.005561
  validation loss:		0.452612
  validation accuracy:		92.93 %
Epoch 1640 of 2000 took 0.134s
  training loss:		0.005502
  validation loss:		0.448769
  validation accuracy:		93.15 %
Epoch 1641 of 2000 took 0.131s
  training loss:		0.005403
  validation loss:		0.441141
  validation accuracy:		92.83 %
Epoch 1642 of 2000 took 0.116s
  training loss:		0.005525
  validation loss:		0.454181
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.127s
  training loss:		0.005541
  validation loss:		0.451144
  validation accuracy:		92.93 %
Epoch 1644 of 2000 took 0.119s
  training loss:		0.005633
  validation loss:		0.454479
  validation accuracy:		93.04 %
Epoch 1645 of 2000 took 0.125s
  training loss:		0.005455
  validation loss:		0.449508
  validation accuracy:		93.15 %
Epoch 1646 of 2000 took 0.121s
  training loss:		0.005650
  validation loss:		0.450918
  validation accuracy:		92.83 %
Epoch 1647 of 2000 took 0.121s
  training loss:		0.005529
  validation loss:		0.447649
  validation accuracy:		92.93 %
Epoch 1648 of 2000 took 0.114s
  training loss:		0.005428
  validation loss:		0.457373
  validation accuracy:		92.83 %
Epoch 1649 of 2000 took 0.124s
  training loss:		0.005572
  validation loss:		0.448119
  validation accuracy:		92.93 %
Epoch 1650 of 2000 took 0.117s
  training loss:		0.005496
  validation loss:		0.451783
  validation accuracy:		92.93 %
Epoch 1651 of 2000 took 0.133s
  training loss:		0.005312
  validation loss:		0.452811
  validation accuracy:		92.83 %
Epoch 1652 of 2000 took 0.148s
  training loss:		0.005434
  validation loss:		0.455393
  validation accuracy:		92.93 %
Epoch 1653 of 2000 took 0.149s
  training loss:		0.005524
  validation loss:		0.452569
  validation accuracy:		92.83 %
Epoch 1654 of 2000 took 0.147s
  training loss:		0.005422
  validation loss:		0.453035
  validation accuracy:		92.93 %
Epoch 1655 of 2000 took 0.127s
  training loss:		0.005422
  validation loss:		0.453931
  validation accuracy:		92.83 %
Epoch 1656 of 2000 took 0.121s
  training loss:		0.005527
  validation loss:		0.454632
  validation accuracy:		92.93 %
Epoch 1657 of 2000 took 0.117s
  training loss:		0.005344
  validation loss:		0.451422
  validation accuracy:		92.93 %
Epoch 1658 of 2000 took 0.123s
  training loss:		0.005392
  validation loss:		0.457828
  validation accuracy:		93.04 %
Epoch 1659 of 2000 took 0.129s
  training loss:		0.005464
  validation loss:		0.453871
  validation accuracy:		92.83 %
Epoch 1660 of 2000 took 0.119s
  training loss:		0.005461
  validation loss:		0.455289
  validation accuracy:		93.04 %
Epoch 1661 of 2000 took 0.110s
  training loss:		0.005433
  validation loss:		0.450239
  validation accuracy:		92.93 %
Epoch 1662 of 2000 took 0.117s
  training loss:		0.005458
  validation loss:		0.452170
  validation accuracy:		92.83 %
Epoch 1663 of 2000 took 0.145s
  training loss:		0.005377
  validation loss:		0.448996
  validation accuracy:		92.93 %
Epoch 1664 of 2000 took 0.152s
  training loss:		0.005569
  validation loss:		0.447229
  validation accuracy:		92.93 %
Epoch 1665 of 2000 took 0.151s
  training loss:		0.005417
  validation loss:		0.460779
  validation accuracy:		92.93 %
Epoch 1666 of 2000 took 0.157s
  training loss:		0.005375
  validation loss:		0.450067
  validation accuracy:		93.04 %
Epoch 1667 of 2000 took 0.168s
  training loss:		0.005502
  validation loss:		0.457406
  validation accuracy:		92.93 %
Epoch 1668 of 2000 took 0.147s
  training loss:		0.005367
  validation loss:		0.453315
  validation accuracy:		92.93 %
Epoch 1669 of 2000 took 0.144s
  training loss:		0.005349
  validation loss:		0.458519
  validation accuracy:		92.83 %
Epoch 1670 of 2000 took 0.152s
  training loss:		0.005265
  validation loss:		0.455160
  validation accuracy:		92.93 %
Epoch 1671 of 2000 took 0.130s
  training loss:		0.005350
  validation loss:		0.450805
  validation accuracy:		92.93 %
Epoch 1672 of 2000 took 0.133s
  training loss:		0.005441
  validation loss:		0.455342
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.161s
  training loss:		0.005275
  validation loss:		0.455823
  validation accuracy:		92.93 %
Epoch 1674 of 2000 took 0.154s
  training loss:		0.005340
  validation loss:		0.457223
  validation accuracy:		93.04 %
Epoch 1675 of 2000 took 0.155s
  training loss:		0.005205
  validation loss:		0.456075
  validation accuracy:		92.93 %
Epoch 1676 of 2000 took 0.160s
  training loss:		0.005272
  validation loss:		0.454663
  validation accuracy:		93.04 %
Epoch 1677 of 2000 took 0.148s
  training loss:		0.005363
  validation loss:		0.461756
  validation accuracy:		92.83 %
Epoch 1678 of 2000 took 0.125s
  training loss:		0.005043
  validation loss:		0.454345
  validation accuracy:		93.04 %
Epoch 1679 of 2000 took 0.115s
  training loss:		0.005261
  validation loss:		0.461525
  validation accuracy:		92.93 %
Epoch 1680 of 2000 took 0.119s
  training loss:		0.005165
  validation loss:		0.456877
  validation accuracy:		93.04 %
Epoch 1681 of 2000 took 0.127s
  training loss:		0.005120
  validation loss:		0.455057
  validation accuracy:		92.83 %
Epoch 1682 of 2000 took 0.118s
  training loss:		0.005118
  validation loss:		0.457010
  validation accuracy:		92.83 %
Epoch 1683 of 2000 took 0.122s
  training loss:		0.005197
  validation loss:		0.456625
  validation accuracy:		92.93 %
Epoch 1684 of 2000 took 0.118s
  training loss:		0.005164
  validation loss:		0.455637
  validation accuracy:		92.93 %
Epoch 1685 of 2000 took 0.119s
  training loss:		0.005200
  validation loss:		0.458443
  validation accuracy:		92.83 %
Epoch 1686 of 2000 took 0.123s
  training loss:		0.005177
  validation loss:		0.458944
  validation accuracy:		92.83 %
Epoch 1687 of 2000 took 0.149s
  training loss:		0.005283
  validation loss:		0.458743
  validation accuracy:		92.83 %
Epoch 1688 of 2000 took 0.164s
  training loss:		0.005181
  validation loss:		0.454514
  validation accuracy:		93.04 %
Epoch 1689 of 2000 took 0.167s
  training loss:		0.004937
  validation loss:		0.460271
  validation accuracy:		92.83 %
Epoch 1690 of 2000 took 0.152s
  training loss:		0.005133
  validation loss:		0.458410
  validation accuracy:		92.93 %
Epoch 1691 of 2000 took 0.151s
  training loss:		0.005095
  validation loss:		0.460313
  validation accuracy:		92.83 %
Epoch 1692 of 2000 took 0.114s
  training loss:		0.004944
  validation loss:		0.456823
  validation accuracy:		93.04 %
Epoch 1693 of 2000 took 0.121s
  training loss:		0.005127
  validation loss:		0.463826
  validation accuracy:		92.93 %
Epoch 1694 of 2000 took 0.123s
  training loss:		0.005031
  validation loss:		0.458875
  validation accuracy:		93.04 %
Epoch 1695 of 2000 took 0.119s
  training loss:		0.005185
  validation loss:		0.462763
  validation accuracy:		92.93 %
Epoch 1696 of 2000 took 0.117s
  training loss:		0.005098
  validation loss:		0.462617
  validation accuracy:		92.83 %
Epoch 1697 of 2000 took 0.117s
  training loss:		0.005036
  validation loss:		0.459900
  validation accuracy:		92.83 %
Epoch 1698 of 2000 took 0.150s
  training loss:		0.005153
  validation loss:		0.461925
  validation accuracy:		92.83 %
Epoch 1699 of 2000 took 0.153s
  training loss:		0.005038
  validation loss:		0.457035
  validation accuracy:		92.83 %
Epoch 1700 of 2000 took 0.157s
  training loss:		0.005179
  validation loss:		0.460483
  validation accuracy:		92.93 %
Epoch 1701 of 2000 took 0.146s
  training loss:		0.005013
  validation loss:		0.464579
  validation accuracy:		92.93 %
Epoch 1702 of 2000 took 0.156s
  training loss:		0.005056
  validation loss:		0.460838
  validation accuracy:		93.04 %
Epoch 1703 of 2000 took 0.195s
  training loss:		0.005103
  validation loss:		0.462954
  validation accuracy:		92.93 %
Epoch 1704 of 2000 took 0.229s
  training loss:		0.005108
  validation loss:		0.460729
  validation accuracy:		92.83 %
Epoch 1705 of 2000 took 0.191s
  training loss:		0.005066
  validation loss:		0.461970
  validation accuracy:		92.83 %
Epoch 1706 of 2000 took 0.186s
  training loss:		0.004985
  validation loss:		0.462794
  validation accuracy:		92.93 %
Epoch 1707 of 2000 took 0.200s
  training loss:		0.005088
  validation loss:		0.459758
  validation accuracy:		92.93 %
Epoch 1708 of 2000 took 0.183s
  training loss:		0.005106
  validation loss:		0.454291
  validation accuracy:		93.04 %
Epoch 1709 of 2000 took 0.136s
  training loss:		0.005185
  validation loss:		0.462150
  validation accuracy:		92.83 %
Epoch 1710 of 2000 took 0.126s
  training loss:		0.004955
  validation loss:		0.459342
  validation accuracy:		92.93 %
Epoch 1711 of 2000 took 0.136s
  training loss:		0.005025
  validation loss:		0.464030
  validation accuracy:		92.83 %
Epoch 1712 of 2000 took 0.149s
  training loss:		0.004852
  validation loss:		0.461316
  validation accuracy:		92.83 %
Epoch 1713 of 2000 took 0.135s
  training loss:		0.004984
  validation loss:		0.459171
  validation accuracy:		93.04 %
Epoch 1714 of 2000 took 0.170s
  training loss:		0.005044
  validation loss:		0.469212
  validation accuracy:		92.83 %
Epoch 1715 of 2000 took 0.186s
  training loss:		0.005045
  validation loss:		0.462998
  validation accuracy:		92.93 %
Epoch 1716 of 2000 took 0.162s
  training loss:		0.005054
  validation loss:		0.460554
  validation accuracy:		93.04 %
Epoch 1717 of 2000 took 0.154s
  training loss:		0.004827
  validation loss:		0.464999
  validation accuracy:		92.83 %
Epoch 1718 of 2000 took 0.112s
  training loss:		0.004846
  validation loss:		0.457721
  validation accuracy:		92.83 %
Epoch 1719 of 2000 took 0.132s
  training loss:		0.004879
  validation loss:		0.466065
  validation accuracy:		92.93 %
Epoch 1720 of 2000 took 0.133s
  training loss:		0.005058
  validation loss:		0.463351
  validation accuracy:		92.93 %
Epoch 1721 of 2000 took 0.118s
  training loss:		0.004911
  validation loss:		0.464607
  validation accuracy:		92.83 %
Epoch 1722 of 2000 took 0.110s
  training loss:		0.004924
  validation loss:		0.462987
  validation accuracy:		92.83 %
Epoch 1723 of 2000 took 0.119s
  training loss:		0.004954
  validation loss:		0.469301
  validation accuracy:		92.93 %
Epoch 1724 of 2000 took 0.120s
  training loss:		0.004899
  validation loss:		0.467235
  validation accuracy:		92.93 %
Epoch 1725 of 2000 took 0.157s
  training loss:		0.004904
  validation loss:		0.459259
  validation accuracy:		93.04 %
Epoch 1726 of 2000 took 0.161s
  training loss:		0.004944
  validation loss:		0.464471
  validation accuracy:		93.04 %
Epoch 1727 of 2000 took 0.187s
  training loss:		0.004829
  validation loss:		0.466053
  validation accuracy:		92.83 %
Epoch 1728 of 2000 took 0.167s
  training loss:		0.004749
  validation loss:		0.465247
  validation accuracy:		92.93 %
Epoch 1729 of 2000 took 0.143s
  training loss:		0.004920
  validation loss:		0.467052
  validation accuracy:		92.83 %
Epoch 1730 of 2000 took 0.155s
  training loss:		0.004775
  validation loss:		0.465265
  validation accuracy:		92.83 %
Epoch 1731 of 2000 took 0.128s
  training loss:		0.004872
  validation loss:		0.465421
  validation accuracy:		92.83 %
Epoch 1732 of 2000 took 0.124s
  training loss:		0.004794
  validation loss:		0.465060
  validation accuracy:		92.93 %
Epoch 1733 of 2000 took 0.116s
  training loss:		0.004945
  validation loss:		0.466878
  validation accuracy:		92.83 %
Epoch 1734 of 2000 took 0.123s
  training loss:		0.004947
  validation loss:		0.462936
  validation accuracy:		93.04 %
Epoch 1735 of 2000 took 0.132s
  training loss:		0.004793
  validation loss:		0.474648
  validation accuracy:		92.93 %
Epoch 1736 of 2000 took 0.177s
  training loss:		0.004750
  validation loss:		0.462923
  validation accuracy:		92.83 %
Epoch 1737 of 2000 took 0.155s
  training loss:		0.004799
  validation loss:		0.465104
  validation accuracy:		93.04 %
Epoch 1738 of 2000 took 0.186s
  training loss:		0.004840
  validation loss:		0.465345
  validation accuracy:		92.93 %
Epoch 1739 of 2000 took 0.177s
  training loss:		0.004733
  validation loss:		0.465779
  validation accuracy:		92.93 %
Epoch 1740 of 2000 took 0.146s
  training loss:		0.004783
  validation loss:		0.466767
  validation accuracy:		92.83 %
Epoch 1741 of 2000 took 0.149s
  training loss:		0.004863
  validation loss:		0.462463
  validation accuracy:		93.15 %
Epoch 1742 of 2000 took 0.124s
  training loss:		0.004918
  validation loss:		0.464936
  validation accuracy:		92.83 %
Epoch 1743 of 2000 took 0.129s
  training loss:		0.004739
  validation loss:		0.469208
  validation accuracy:		92.93 %
Epoch 1744 of 2000 took 0.119s
  training loss:		0.004593
  validation loss:		0.469445
  validation accuracy:		92.93 %
Epoch 1745 of 2000 took 0.135s
  training loss:		0.004754
  validation loss:		0.471397
  validation accuracy:		92.83 %
Epoch 1746 of 2000 took 0.146s
  training loss:		0.004966
  validation loss:		0.470521
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.120s
  training loss:		0.004807
  validation loss:		0.463871
  validation accuracy:		92.83 %
Epoch 1748 of 2000 took 0.116s
  training loss:		0.004914
  validation loss:		0.468689
  validation accuracy:		93.04 %
Epoch 1749 of 2000 took 0.132s
  training loss:		0.004732
  validation loss:		0.463361
  validation accuracy:		92.93 %
Epoch 1750 of 2000 took 0.130s
  training loss:		0.004697
  validation loss:		0.468599
  validation accuracy:		92.93 %
Epoch 1751 of 2000 took 0.126s
  training loss:		0.004772
  validation loss:		0.468013
  validation accuracy:		92.83 %
Epoch 1752 of 2000 took 0.133s
  training loss:		0.004701
  validation loss:		0.475821
  validation accuracy:		92.83 %
Epoch 1753 of 2000 took 0.127s
  training loss:		0.004582
  validation loss:		0.467614
  validation accuracy:		93.04 %
Epoch 1754 of 2000 took 0.120s
  training loss:		0.004892
  validation loss:		0.469681
  validation accuracy:		92.83 %
Epoch 1755 of 2000 took 0.129s
  training loss:		0.004718
  validation loss:		0.471120
  validation accuracy:		92.93 %
Epoch 1756 of 2000 took 0.127s
  training loss:		0.004737
  validation loss:		0.465607
  validation accuracy:		92.83 %
Epoch 1757 of 2000 took 0.132s
  training loss:		0.004752
  validation loss:		0.467470
  validation accuracy:		92.83 %
Epoch 1758 of 2000 took 0.119s
  training loss:		0.004652
  validation loss:		0.469011
  validation accuracy:		92.93 %
Epoch 1759 of 2000 took 0.111s
  training loss:		0.004576
  validation loss:		0.470444
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.121s
  training loss:		0.004526
  validation loss:		0.470247
  validation accuracy:		92.83 %
Epoch 1761 of 2000 took 0.120s
  training loss:		0.004684
  validation loss:		0.471581
  validation accuracy:		92.83 %
Epoch 1762 of 2000 took 0.187s
  training loss:		0.004753
  validation loss:		0.472363
  validation accuracy:		92.93 %
Epoch 1763 of 2000 took 0.168s
  training loss:		0.004567
  validation loss:		0.472134
  validation accuracy:		92.93 %
Epoch 1764 of 2000 took 0.206s
  training loss:		0.004758
  validation loss:		0.468950
  validation accuracy:		93.04 %
Epoch 1765 of 2000 took 0.169s
  training loss:		0.004737
  validation loss:		0.473020
  validation accuracy:		92.83 %
Epoch 1766 of 2000 took 0.143s
  training loss:		0.004825
  validation loss:		0.465343
  validation accuracy:		93.04 %
Epoch 1767 of 2000 took 0.144s
  training loss:		0.004676
  validation loss:		0.469062
  validation accuracy:		92.83 %
Epoch 1768 of 2000 took 0.124s
  training loss:		0.004631
  validation loss:		0.471001
  validation accuracy:		92.83 %
Epoch 1769 of 2000 took 0.120s
  training loss:		0.004706
  validation loss:		0.477167
  validation accuracy:		92.83 %
Epoch 1770 of 2000 took 0.121s
  training loss:		0.004686
  validation loss:		0.469612
  validation accuracy:		92.83 %
Epoch 1771 of 2000 took 0.131s
  training loss:		0.004781
  validation loss:		0.470430
  validation accuracy:		92.83 %
Epoch 1772 of 2000 took 0.138s
  training loss:		0.004581
  validation loss:		0.473720
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.137s
  training loss:		0.004596
  validation loss:		0.472969
  validation accuracy:		92.83 %
Epoch 1774 of 2000 took 0.124s
  training loss:		0.004568
  validation loss:		0.472317
  validation accuracy:		92.93 %
Epoch 1775 of 2000 took 0.132s
  training loss:		0.004631
  validation loss:		0.474826
  validation accuracy:		92.83 %
Epoch 1776 of 2000 took 0.127s
  training loss:		0.004563
  validation loss:		0.471161
  validation accuracy:		93.04 %
Epoch 1777 of 2000 took 0.141s
  training loss:		0.004534
  validation loss:		0.473362
  validation accuracy:		92.93 %
Epoch 1778 of 2000 took 0.127s
  training loss:		0.004726
  validation loss:		0.470948
  validation accuracy:		93.04 %
Epoch 1779 of 2000 took 0.139s
  training loss:		0.004671
  validation loss:		0.472658
  validation accuracy:		92.83 %
Epoch 1780 of 2000 took 0.146s
  training loss:		0.004574
  validation loss:		0.472861
  validation accuracy:		93.04 %
Epoch 1781 of 2000 took 0.123s
  training loss:		0.004534
  validation loss:		0.474098
  validation accuracy:		93.04 %
Epoch 1782 of 2000 took 0.140s
  training loss:		0.004482
  validation loss:		0.474276
  validation accuracy:		92.83 %
Epoch 1783 of 2000 took 0.152s
  training loss:		0.004525
  validation loss:		0.470498
  validation accuracy:		93.04 %
Epoch 1784 of 2000 took 0.152s
  training loss:		0.004458
  validation loss:		0.471526
  validation accuracy:		92.83 %
Epoch 1785 of 2000 took 0.156s
  training loss:		0.004491
  validation loss:		0.478253
  validation accuracy:		92.93 %
Epoch 1786 of 2000 took 0.165s
  training loss:		0.004459
  validation loss:		0.477093
  validation accuracy:		92.83 %
Epoch 1787 of 2000 took 0.180s
  training loss:		0.004513
  validation loss:		0.476789
  validation accuracy:		92.93 %
Epoch 1788 of 2000 took 0.145s
  training loss:		0.004504
  validation loss:		0.476418
  validation accuracy:		92.83 %
Epoch 1789 of 2000 took 0.136s
  training loss:		0.004560
  validation loss:		0.473984
  validation accuracy:		93.04 %
Epoch 1790 of 2000 took 0.143s
  training loss:		0.004423
  validation loss:		0.474482
  validation accuracy:		93.04 %
Epoch 1791 of 2000 took 0.148s
  training loss:		0.004441
  validation loss:		0.474432
  validation accuracy:		92.83 %
Epoch 1792 of 2000 took 0.144s
  training loss:		0.004419
  validation loss:		0.475929
  validation accuracy:		92.83 %
Epoch 1793 of 2000 took 0.131s
  training loss:		0.004399
  validation loss:		0.477204
  validation accuracy:		93.04 %
Epoch 1794 of 2000 took 0.130s
  training loss:		0.004457
  validation loss:		0.470544
  validation accuracy:		93.04 %
Epoch 1795 of 2000 took 0.128s
  training loss:		0.004530
  validation loss:		0.481121
  validation accuracy:		92.83 %
Epoch 1796 of 2000 took 0.153s
  training loss:		0.004613
  validation loss:		0.473710
  validation accuracy:		93.04 %
Epoch 1797 of 2000 took 0.207s
  training loss:		0.004423
  validation loss:		0.478934
  validation accuracy:		92.83 %
Epoch 1798 of 2000 took 0.177s
  training loss:		0.004485
  validation loss:		0.478110
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.153s
  training loss:		0.004447
  validation loss:		0.475010
  validation accuracy:		93.04 %
Epoch 1800 of 2000 took 0.119s
  training loss:		0.004498
  validation loss:		0.480113
  validation accuracy:		92.83 %
Epoch 1801 of 2000 took 0.117s
  training loss:		0.004382
  validation loss:		0.474040
  validation accuracy:		93.04 %
Epoch 1802 of 2000 took 0.119s
  training loss:		0.004643
  validation loss:		0.479040
  validation accuracy:		92.83 %
Epoch 1803 of 2000 took 0.121s
  training loss:		0.004369
  validation loss:		0.479339
  validation accuracy:		92.93 %
Epoch 1804 of 2000 took 0.120s
  training loss:		0.004468
  validation loss:		0.472932
  validation accuracy:		93.04 %
Epoch 1805 of 2000 took 0.121s
  training loss:		0.004364
  validation loss:		0.474156
  validation accuracy:		92.83 %
Epoch 1806 of 2000 took 0.155s
  training loss:		0.004362
  validation loss:		0.475712
  validation accuracy:		93.04 %
Epoch 1807 of 2000 took 0.147s
  training loss:		0.004460
  validation loss:		0.475968
  validation accuracy:		93.04 %
Epoch 1808 of 2000 took 0.173s
  training loss:		0.004452
  validation loss:		0.481710
  validation accuracy:		92.83 %
Epoch 1809 of 2000 took 0.152s
  training loss:		0.004251
  validation loss:		0.477758
  validation accuracy:		92.83 %
Epoch 1810 of 2000 took 0.118s
  training loss:		0.004260
  validation loss:		0.480323
  validation accuracy:		92.93 %
Epoch 1811 of 2000 took 0.122s
  training loss:		0.004442
  validation loss:		0.474526
  validation accuracy:		92.93 %
Epoch 1812 of 2000 took 0.121s
  training loss:		0.004362
  validation loss:		0.474614
  validation accuracy:		92.93 %
Epoch 1813 of 2000 took 0.120s
  training loss:		0.004397
  validation loss:		0.479738
  validation accuracy:		92.83 %
Epoch 1814 of 2000 took 0.132s
  training loss:		0.004339
  validation loss:		0.473907
  validation accuracy:		92.83 %
Epoch 1815 of 2000 took 0.119s
  training loss:		0.004393
  validation loss:		0.482060
  validation accuracy:		92.93 %
Epoch 1816 of 2000 took 0.126s
  training loss:		0.004277
  validation loss:		0.477424
  validation accuracy:		93.04 %
Epoch 1817 of 2000 took 0.141s
  training loss:		0.004243
  validation loss:		0.472532
  validation accuracy:		93.04 %
Epoch 1818 of 2000 took 0.119s
  training loss:		0.004254
  validation loss:		0.481289
  validation accuracy:		92.83 %
Epoch 1819 of 2000 took 0.124s
  training loss:		0.004328
  validation loss:		0.480589
  validation accuracy:		93.04 %
Epoch 1820 of 2000 took 0.131s
  training loss:		0.004244
  validation loss:		0.478820
  validation accuracy:		92.83 %
Epoch 1821 of 2000 took 0.179s
  training loss:		0.004304
  validation loss:		0.478748
  validation accuracy:		92.83 %
Epoch 1822 of 2000 took 0.158s
  training loss:		0.004314
  validation loss:		0.479070
  validation accuracy:		92.83 %
Epoch 1823 of 2000 took 0.140s
  training loss:		0.004410
  validation loss:		0.478324
  validation accuracy:		93.04 %
Epoch 1824 of 2000 took 0.123s
  training loss:		0.004180
  validation loss:		0.480619
  validation accuracy:		92.93 %
Epoch 1825 of 2000 took 0.124s
  training loss:		0.004363
  validation loss:		0.481544
  validation accuracy:		92.83 %
Epoch 1826 of 2000 took 0.128s
  training loss:		0.004394
  validation loss:		0.477574
  validation accuracy:		92.83 %
Epoch 1827 of 2000 took 0.127s
  training loss:		0.004250
  validation loss:		0.478274
  validation accuracy:		92.93 %
Epoch 1828 of 2000 took 0.125s
  training loss:		0.004290
  validation loss:		0.481749
  validation accuracy:		92.83 %
Epoch 1829 of 2000 took 0.138s
  training loss:		0.004178
  validation loss:		0.483951
  validation accuracy:		92.83 %
Epoch 1830 of 2000 took 0.124s
  training loss:		0.004196
  validation loss:		0.477155
  validation accuracy:		93.04 %
Epoch 1831 of 2000 took 0.130s
  training loss:		0.004229
  validation loss:		0.482101
  validation accuracy:		92.83 %
Epoch 1832 of 2000 took 0.130s
  training loss:		0.004285
  validation loss:		0.482398
  validation accuracy:		93.04 %
Epoch 1833 of 2000 took 0.121s
  training loss:		0.004326
  validation loss:		0.480839
  validation accuracy:		92.93 %
Epoch 1834 of 2000 took 0.127s
  training loss:		0.004306
  validation loss:		0.478435
  validation accuracy:		92.93 %
Epoch 1835 of 2000 took 0.138s
  training loss:		0.004259
  validation loss:		0.482271
  validation accuracy:		92.83 %
Epoch 1836 of 2000 took 0.162s
  training loss:		0.004080
  validation loss:		0.484080
  validation accuracy:		92.83 %
Epoch 1837 of 2000 took 0.152s
  training loss:		0.004215
  validation loss:		0.480056
  validation accuracy:		93.04 %
Epoch 1838 of 2000 took 0.131s
  training loss:		0.004302
  validation loss:		0.484651
  validation accuracy:		92.83 %
Epoch 1839 of 2000 took 0.134s
  training loss:		0.004227
  validation loss:		0.480712
  validation accuracy:		92.83 %
Epoch 1840 of 2000 took 0.130s
  training loss:		0.004274
  validation loss:		0.482020
  validation accuracy:		92.93 %
Epoch 1841 of 2000 took 0.127s
  training loss:		0.004270
  validation loss:		0.483931
  validation accuracy:		92.83 %
Epoch 1842 of 2000 took 0.130s
  training loss:		0.004186
  validation loss:		0.483713
  validation accuracy:		92.83 %
Epoch 1843 of 2000 took 0.156s
  training loss:		0.004239
  validation loss:		0.483219
  validation accuracy:		92.83 %
Epoch 1844 of 2000 took 0.161s
  training loss:		0.004210
  validation loss:		0.487947
  validation accuracy:		92.83 %
Epoch 1845 of 2000 took 0.159s
  training loss:		0.004213
  validation loss:		0.481858
  validation accuracy:		92.93 %
Epoch 1846 of 2000 took 0.161s
  training loss:		0.004133
  validation loss:		0.483260
  validation accuracy:		92.93 %
Epoch 1847 of 2000 took 0.161s
  training loss:		0.004182
  validation loss:		0.481248
  validation accuracy:		93.04 %
Epoch 1848 of 2000 took 0.163s
  training loss:		0.004278
  validation loss:		0.484218
  validation accuracy:		92.93 %
Epoch 1849 of 2000 took 0.181s
  training loss:		0.004107
  validation loss:		0.489095
  validation accuracy:		92.83 %
Epoch 1850 of 2000 took 0.175s
  training loss:		0.004071
  validation loss:		0.479578
  validation accuracy:		92.93 %
Epoch 1851 of 2000 took 0.170s
  training loss:		0.004046
  validation loss:		0.480350
  validation accuracy:		93.04 %
Epoch 1852 of 2000 took 0.165s
  training loss:		0.004211
  validation loss:		0.478247
  validation accuracy:		92.72 %
Epoch 1853 of 2000 took 0.162s
  training loss:		0.004014
  validation loss:		0.483920
  validation accuracy:		92.93 %
Epoch 1854 of 2000 took 0.160s
  training loss:		0.004213
  validation loss:		0.476379
  validation accuracy:		93.04 %
Epoch 1855 of 2000 took 0.163s
  training loss:		0.004185
  validation loss:		0.482008
  validation accuracy:		92.83 %
Epoch 1856 of 2000 took 0.167s
  training loss:		0.004106
  validation loss:		0.482964
  validation accuracy:		93.04 %
Epoch 1857 of 2000 took 0.146s
  training loss:		0.004120
  validation loss:		0.481908
  validation accuracy:		92.83 %
Epoch 1858 of 2000 took 0.168s
  training loss:		0.004145
  validation loss:		0.477925
  validation accuracy:		93.04 %
Epoch 1859 of 2000 took 0.168s
  training loss:		0.004064
  validation loss:		0.489044
  validation accuracy:		93.04 %
Epoch 1860 of 2000 took 0.165s
  training loss:		0.004156
  validation loss:		0.484602
  validation accuracy:		92.93 %
Epoch 1861 of 2000 took 0.163s
  training loss:		0.004109
  validation loss:		0.482906
  validation accuracy:		93.04 %
Epoch 1862 of 2000 took 0.163s
  training loss:		0.004058
  validation loss:		0.482210
  validation accuracy:		92.93 %
Epoch 1863 of 2000 took 0.163s
  training loss:		0.004107
  validation loss:		0.482108
  validation accuracy:		92.83 %
Epoch 1864 of 2000 took 0.164s
  training loss:		0.004098
  validation loss:		0.483937
  validation accuracy:		92.93 %
Epoch 1865 of 2000 took 0.156s
  training loss:		0.004031
  validation loss:		0.486086
  validation accuracy:		93.04 %
Epoch 1866 of 2000 took 0.161s
  training loss:		0.004075
  validation loss:		0.484691
  validation accuracy:		92.83 %
Epoch 1867 of 2000 took 0.166s
  training loss:		0.004130
  validation loss:		0.488555
  validation accuracy:		92.83 %
Epoch 1868 of 2000 took 0.181s
  training loss:		0.004117
  validation loss:		0.481973
  validation accuracy:		92.83 %
Epoch 1869 of 2000 took 0.166s
  training loss:		0.004111
  validation loss:		0.485449
  validation accuracy:		93.04 %
Epoch 1870 of 2000 took 0.177s
  training loss:		0.003976
  validation loss:		0.486537
  validation accuracy:		93.04 %
Epoch 1871 of 2000 took 0.166s
  training loss:		0.004036
  validation loss:		0.481502
  validation accuracy:		92.83 %
Epoch 1872 of 2000 took 0.166s
  training loss:		0.004058
  validation loss:		0.487721
  validation accuracy:		93.04 %
Epoch 1873 of 2000 took 0.167s
  training loss:		0.004061
  validation loss:		0.479077
  validation accuracy:		92.93 %
Epoch 1874 of 2000 took 0.175s
  training loss:		0.004051
  validation loss:		0.484944
  validation accuracy:		92.93 %
Epoch 1875 of 2000 took 0.137s
  training loss:		0.004043
  validation loss:		0.491890
  validation accuracy:		92.83 %
Epoch 1876 of 2000 took 0.132s
  training loss:		0.004155
  validation loss:		0.486848
  validation accuracy:		92.93 %
Epoch 1877 of 2000 took 0.127s
  training loss:		0.004044
  validation loss:		0.484220
  validation accuracy:		92.83 %
Epoch 1878 of 2000 took 0.138s
  training loss:		0.004119
  validation loss:		0.484687
  validation accuracy:		93.04 %
Epoch 1879 of 2000 took 0.124s
  training loss:		0.004044
  validation loss:		0.493210
  validation accuracy:		92.72 %
Epoch 1880 of 2000 took 0.124s
  training loss:		0.003979
  validation loss:		0.485757
  validation accuracy:		92.93 %
Epoch 1881 of 2000 took 0.137s
  training loss:		0.003899
  validation loss:		0.492150
  validation accuracy:		92.83 %
Epoch 1882 of 2000 took 0.166s
  training loss:		0.003823
  validation loss:		0.488413
  validation accuracy:		93.04 %
Epoch 1883 of 2000 took 0.169s
  training loss:		0.003986
  validation loss:		0.486864
  validation accuracy:		92.93 %
Epoch 1884 of 2000 took 0.166s
  training loss:		0.004146
  validation loss:		0.487608
  validation accuracy:		93.04 %
Epoch 1885 of 2000 took 0.164s
  training loss:		0.003969
  validation loss:		0.486753
  validation accuracy:		93.04 %
Epoch 1886 of 2000 took 0.179s
  training loss:		0.003923
  validation loss:		0.483707
  validation accuracy:		92.93 %
Epoch 1887 of 2000 took 0.143s
  training loss:		0.004017
  validation loss:		0.489708
  validation accuracy:		92.83 %
Epoch 1888 of 2000 took 0.130s
  training loss:		0.003917
  validation loss:		0.488561
  validation accuracy:		93.04 %
Epoch 1889 of 2000 took 0.132s
  training loss:		0.003964
  validation loss:		0.490905
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.129s
  training loss:		0.003849
  validation loss:		0.486079
  validation accuracy:		92.93 %
Epoch 1891 of 2000 took 0.137s
  training loss:		0.003976
  validation loss:		0.489708
  validation accuracy:		92.83 %
Epoch 1892 of 2000 took 0.134s
  training loss:		0.003840
  validation loss:		0.492190
  validation accuracy:		93.04 %
Epoch 1893 of 2000 took 0.134s
  training loss:		0.003948
  validation loss:		0.492122
  validation accuracy:		92.83 %
Epoch 1894 of 2000 took 0.131s
  training loss:		0.003988
  validation loss:		0.491667
  validation accuracy:		92.83 %
Epoch 1895 of 2000 took 0.156s
  training loss:		0.003973
  validation loss:		0.489024
  validation accuracy:		93.04 %
Epoch 1896 of 2000 took 0.136s
  training loss:		0.004034
  validation loss:		0.488908
  validation accuracy:		92.93 %
Epoch 1897 of 2000 took 0.128s
  training loss:		0.003937
  validation loss:		0.486851
  validation accuracy:		92.83 %
Epoch 1898 of 2000 took 0.133s
  training loss:		0.003923
  validation loss:		0.493194
  validation accuracy:		93.04 %
Epoch 1899 of 2000 took 0.127s
  training loss:		0.003864
  validation loss:		0.491632
  validation accuracy:		93.04 %
Epoch 1900 of 2000 took 0.123s
  training loss:		0.003873
  validation loss:		0.486199
  validation accuracy:		93.04 %
Epoch 1901 of 2000 took 0.135s
  training loss:		0.003867
  validation loss:		0.487653
  validation accuracy:		92.83 %
Epoch 1902 of 2000 took 0.135s
  training loss:		0.003984
  validation loss:		0.495252
  validation accuracy:		92.83 %
Epoch 1903 of 2000 took 0.135s
  training loss:		0.003987
  validation loss:		0.492509
  validation accuracy:		92.83 %
Epoch 1904 of 2000 took 0.134s
  training loss:		0.003909
  validation loss:		0.489495
  validation accuracy:		93.04 %
Epoch 1905 of 2000 took 0.133s
  training loss:		0.003846
  validation loss:		0.487140
  validation accuracy:		92.93 %
Epoch 1906 of 2000 took 0.133s
  training loss:		0.003982
  validation loss:		0.492810
  validation accuracy:		93.04 %
Epoch 1907 of 2000 took 0.132s
  training loss:		0.003835
  validation loss:		0.493287
  validation accuracy:		93.04 %
Epoch 1908 of 2000 took 0.131s
  training loss:		0.003859
  validation loss:		0.493088
  validation accuracy:		92.83 %
Epoch 1909 of 2000 took 0.129s
  training loss:		0.003817
  validation loss:		0.492028
  validation accuracy:		93.04 %
Epoch 1910 of 2000 took 0.142s
  training loss:		0.003863
  validation loss:		0.490401
  validation accuracy:		92.93 %
Epoch 1911 of 2000 took 0.138s
  training loss:		0.003873
  validation loss:		0.489400
  validation accuracy:		92.93 %
Epoch 1912 of 2000 took 0.123s
  training loss:		0.003842
  validation loss:		0.492752
  validation accuracy:		92.83 %
Epoch 1913 of 2000 took 0.131s
  training loss:		0.003984
  validation loss:		0.497985
  validation accuracy:		92.83 %
Epoch 1914 of 2000 took 0.146s
  training loss:		0.003876
  validation loss:		0.485829
  validation accuracy:		92.83 %
Epoch 1915 of 2000 took 0.125s
  training loss:		0.003782
  validation loss:		0.495013
  validation accuracy:		92.93 %
Epoch 1916 of 2000 took 0.134s
  training loss:		0.003862
  validation loss:		0.493599
  validation accuracy:		93.04 %
Epoch 1917 of 2000 took 0.140s
  training loss:		0.003765
  validation loss:		0.495661
  validation accuracy:		93.04 %
Epoch 1918 of 2000 took 0.136s
  training loss:		0.003687
  validation loss:		0.487315
  validation accuracy:		92.93 %
Epoch 1919 of 2000 took 0.135s
  training loss:		0.003909
  validation loss:		0.493683
  validation accuracy:		93.04 %
Epoch 1920 of 2000 took 0.130s
  training loss:		0.003874
  validation loss:		0.496385
  validation accuracy:		92.93 %
Epoch 1921 of 2000 took 0.129s
  training loss:		0.003737
  validation loss:		0.490709
  validation accuracy:		92.83 %
Epoch 1922 of 2000 took 0.124s
  training loss:		0.003805
  validation loss:		0.493179
  validation accuracy:		93.04 %
Epoch 1923 of 2000 took 0.129s
  training loss:		0.003762
  validation loss:		0.491179
  validation accuracy:		92.72 %
Epoch 1924 of 2000 took 0.133s
  training loss:		0.003807
  validation loss:		0.495131
  validation accuracy:		93.04 %
Epoch 1925 of 2000 took 0.149s
  training loss:		0.003880
  validation loss:		0.495345
  validation accuracy:		92.93 %
Epoch 1926 of 2000 took 0.139s
  training loss:		0.003724
  validation loss:		0.493410
  validation accuracy:		93.04 %
Epoch 1927 of 2000 took 0.138s
  training loss:		0.003710
  validation loss:		0.494278
  validation accuracy:		93.04 %
Epoch 1928 of 2000 took 0.136s
  training loss:		0.003819
  validation loss:		0.492418
  validation accuracy:		92.83 %
Epoch 1929 of 2000 took 0.133s
  training loss:		0.003791
  validation loss:		0.495767
  validation accuracy:		92.83 %
Epoch 1930 of 2000 took 0.135s
  training loss:		0.003745
  validation loss:		0.501150
  validation accuracy:		92.83 %
Epoch 1931 of 2000 took 0.134s
  training loss:		0.003840
  validation loss:		0.490390
  validation accuracy:		92.83 %
Epoch 1932 of 2000 took 0.139s
  training loss:		0.003824
  validation loss:		0.490295
  validation accuracy:		93.15 %
Epoch 1933 of 2000 took 0.139s
  training loss:		0.003832
  validation loss:		0.496127
  validation accuracy:		92.83 %
Epoch 1934 of 2000 took 0.124s
  training loss:		0.003725
  validation loss:		0.496705
  validation accuracy:		92.83 %
Epoch 1935 of 2000 took 0.127s
  training loss:		0.003697
  validation loss:		0.490610
  validation accuracy:		92.93 %
Epoch 1936 of 2000 took 0.124s
  training loss:		0.003788
  validation loss:		0.496361
  validation accuracy:		93.04 %
Epoch 1937 of 2000 took 0.140s
  training loss:		0.003822
  validation loss:		0.494161
  validation accuracy:		92.93 %
Epoch 1938 of 2000 took 0.134s
  training loss:		0.003627
  validation loss:		0.500955
  validation accuracy:		92.83 %
Epoch 1939 of 2000 took 0.136s
  training loss:		0.003776
  validation loss:		0.493682
  validation accuracy:		93.04 %
Epoch 1940 of 2000 took 0.146s
  training loss:		0.003901
  validation loss:		0.499776
  validation accuracy:		92.83 %
Epoch 1941 of 2000 took 0.140s
  training loss:		0.003793
  validation loss:		0.490956
  validation accuracy:		92.83 %
Epoch 1942 of 2000 took 0.134s
  training loss:		0.003798
  validation loss:		0.493540
  validation accuracy:		93.04 %
Epoch 1943 of 2000 took 0.137s
  training loss:		0.003806
  validation loss:		0.493214
  validation accuracy:		92.93 %
Epoch 1944 of 2000 took 0.127s
  training loss:		0.003673
  validation loss:		0.498510
  validation accuracy:		93.04 %
Epoch 1945 of 2000 took 0.132s
  training loss:		0.003748
  validation loss:		0.495615
  validation accuracy:		92.93 %
Epoch 1946 of 2000 took 0.136s
  training loss:		0.003813
  validation loss:		0.502252
  validation accuracy:		92.93 %
Epoch 1947 of 2000 took 0.136s
  training loss:		0.003612
  validation loss:		0.491942
  validation accuracy:		92.93 %
Epoch 1948 of 2000 took 0.127s
  training loss:		0.003704
  validation loss:		0.496801
  validation accuracy:		93.04 %
Epoch 1949 of 2000 took 0.129s
  training loss:		0.003636
  validation loss:		0.498952
  validation accuracy:		92.83 %
Epoch 1950 of 2000 took 0.134s
  training loss:		0.003686
  validation loss:		0.492712
  validation accuracy:		92.93 %
Epoch 1951 of 2000 took 0.138s
  training loss:		0.003663
  validation loss:		0.496017
  validation accuracy:		92.83 %
Epoch 1952 of 2000 took 0.142s
  training loss:		0.003650
  validation loss:		0.498131
  validation accuracy:		92.93 %
Epoch 1953 of 2000 took 0.165s
  training loss:		0.003654
  validation loss:		0.497292
  validation accuracy:		92.93 %
Epoch 1954 of 2000 took 0.186s
  training loss:		0.003713
  validation loss:		0.494929
  validation accuracy:		92.93 %
Epoch 1955 of 2000 took 0.155s
  training loss:		0.003764
  validation loss:		0.504020
  validation accuracy:		92.93 %
Epoch 1956 of 2000 took 0.147s
  training loss:		0.003545
  validation loss:		0.498870
  validation accuracy:		92.83 %
Epoch 1957 of 2000 took 0.150s
  training loss:		0.003655
  validation loss:		0.496827
  validation accuracy:		93.04 %
Epoch 1958 of 2000 took 0.135s
  training loss:		0.003680
  validation loss:		0.499720
  validation accuracy:		92.93 %
Epoch 1959 of 2000 took 0.130s
  training loss:		0.003610
  validation loss:		0.495658
  validation accuracy:		92.83 %
Epoch 1960 of 2000 took 0.136s
  training loss:		0.003613
  validation loss:		0.500683
  validation accuracy:		92.93 %
Epoch 1961 of 2000 took 0.159s
  training loss:		0.003677
  validation loss:		0.497338
  validation accuracy:		92.93 %
Epoch 1962 of 2000 took 0.192s
  training loss:		0.003681
  validation loss:		0.497969
  validation accuracy:		92.93 %
Epoch 1963 of 2000 took 0.177s
  training loss:		0.003554
  validation loss:		0.502261
  validation accuracy:		92.83 %
Epoch 1964 of 2000 took 0.177s
  training loss:		0.003626
  validation loss:		0.495901
  validation accuracy:		93.04 %
Epoch 1965 of 2000 took 0.167s
  training loss:		0.003601
  validation loss:		0.497928
  validation accuracy:		92.93 %
Epoch 1966 of 2000 took 0.146s
  training loss:		0.003642
  validation loss:		0.499627
  validation accuracy:		92.93 %
Epoch 1967 of 2000 took 0.155s
  training loss:		0.003556
  validation loss:		0.499263
  validation accuracy:		93.04 %
Epoch 1968 of 2000 took 0.138s
  training loss:		0.003633
  validation loss:		0.495091
  validation accuracy:		92.93 %
Epoch 1969 of 2000 took 0.135s
  training loss:		0.003597
  validation loss:		0.506257
  validation accuracy:		92.83 %
Epoch 1970 of 2000 took 0.150s
  training loss:		0.003697
  validation loss:		0.499091
  validation accuracy:		92.93 %
Epoch 1971 of 2000 took 0.151s
  training loss:		0.003546
  validation loss:		0.499839
  validation accuracy:		92.93 %
Epoch 1972 of 2000 took 0.143s
  training loss:		0.003502
  validation loss:		0.498359
  validation accuracy:		92.93 %
Epoch 1973 of 2000 took 0.133s
  training loss:		0.003605
  validation loss:		0.503450
  validation accuracy:		92.83 %
Epoch 1974 of 2000 took 0.145s
  training loss:		0.003699
  validation loss:		0.498981
  validation accuracy:		93.04 %
Epoch 1975 of 2000 took 0.168s
  training loss:		0.003564
  validation loss:		0.504089
  validation accuracy:		92.83 %
Epoch 1976 of 2000 took 0.141s
  training loss:		0.003659
  validation loss:		0.495545
  validation accuracy:		92.93 %
Epoch 1977 of 2000 took 0.140s
  training loss:		0.003453
  validation loss:		0.501361
  validation accuracy:		92.93 %
Epoch 1978 of 2000 took 0.133s
  training loss:		0.003612
  validation loss:		0.501635
  validation accuracy:		93.04 %
Epoch 1979 of 2000 took 0.138s
  training loss:		0.003575
  validation loss:		0.506252
  validation accuracy:		92.83 %
Epoch 1980 of 2000 took 0.132s
  training loss:		0.003506
  validation loss:		0.497196
  validation accuracy:		92.93 %
Epoch 1981 of 2000 took 0.144s
  training loss:		0.003634
  validation loss:		0.497070
  validation accuracy:		92.83 %
Epoch 1982 of 2000 took 0.128s
  training loss:		0.003596
  validation loss:		0.509743
  validation accuracy:		92.72 %
Epoch 1983 of 2000 took 0.130s
  training loss:		0.003658
  validation loss:		0.497655
  validation accuracy:		92.93 %
Epoch 1984 of 2000 took 0.140s
  training loss:		0.003630
  validation loss:		0.502216
  validation accuracy:		92.93 %
Epoch 1985 of 2000 took 0.185s
  training loss:		0.003433
  validation loss:		0.499995
  validation accuracy:		92.93 %
Epoch 1986 of 2000 took 0.167s
  training loss:		0.003527
  validation loss:		0.503308
  validation accuracy:		93.04 %
Epoch 1987 of 2000 took 0.162s
  training loss:		0.003551
  validation loss:		0.498996
  validation accuracy:		93.04 %
Epoch 1988 of 2000 took 0.132s
  training loss:		0.003541
  validation loss:		0.504350
  validation accuracy:		92.83 %
Epoch 1989 of 2000 took 0.159s
  training loss:		0.003550
  validation loss:		0.500945
  validation accuracy:		92.93 %
Epoch 1990 of 2000 took 0.154s
  training loss:		0.003563
  validation loss:		0.499752
  validation accuracy:		92.93 %
Epoch 1991 of 2000 took 0.150s
  training loss:		0.003457
  validation loss:		0.505769
  validation accuracy:		93.04 %
Epoch 1992 of 2000 took 0.146s
  training loss:		0.003573
  validation loss:		0.506721
  validation accuracy:		92.93 %
Epoch 1993 of 2000 took 0.148s
  training loss:		0.003470
  validation loss:		0.498967
  validation accuracy:		92.93 %
Epoch 1994 of 2000 took 0.175s
  training loss:		0.003494
  validation loss:		0.502510
  validation accuracy:		92.72 %
Epoch 1995 of 2000 took 0.147s
  training loss:		0.003469
  validation loss:		0.505473
  validation accuracy:		92.93 %
Epoch 1996 of 2000 took 0.147s
  training loss:		0.003633
  validation loss:		0.503150
  validation accuracy:		92.93 %
Epoch 1997 of 2000 took 0.138s
  training loss:		0.003453
  validation loss:		0.504398
  validation accuracy:		92.93 %
Epoch 1998 of 2000 took 0.140s
  training loss:		0.003476
  validation loss:		0.500984
  validation accuracy:		92.83 %
Epoch 1999 of 2000 took 0.137s
  training loss:		0.003474
  validation loss:		0.501850
  validation accuracy:		92.93 %
Epoch 2000 of 2000 took 0.130s
  training loss:		0.003492
  validation loss:		0.499540
  validation accuracy:		92.93 %
Final results:
  test loss:			1.368079
  test accuracy:		84.60 %
