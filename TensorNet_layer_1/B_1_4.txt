Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.147s
  training loss:		2.956588
  validation loss:		2.866347
  validation accuracy:		15.00 %
Epoch 2 of 2000 took 0.145s
  training loss:		2.803465
  validation loss:		2.669758
  validation accuracy:		15.65 %
Epoch 3 of 2000 took 0.144s
  training loss:		2.632171
  validation loss:		2.478337
  validation accuracy:		20.43 %
Epoch 4 of 2000 took 0.150s
  training loss:		2.482817
  validation loss:		2.334003
  validation accuracy:		16.20 %
Epoch 5 of 2000 took 0.143s
  training loss:		2.376112
  validation loss:		2.255560
  validation accuracy:		20.00 %
Epoch 6 of 2000 took 0.141s
  training loss:		2.320514
  validation loss:		2.233112
  validation accuracy:		41.74 %
Epoch 7 of 2000 took 0.148s
  training loss:		2.289048
  validation loss:		2.231459
  validation accuracy:		50.65 %
Epoch 8 of 2000 took 0.147s
  training loss:		2.274005
  validation loss:		2.211791
  validation accuracy:		40.87 %
Epoch 9 of 2000 took 0.148s
  training loss:		2.261884
  validation loss:		2.196710
  validation accuracy:		33.48 %
Epoch 10 of 2000 took 0.152s
  training loss:		2.252285
  validation loss:		2.188305
  validation accuracy:		29.78 %
Epoch 11 of 2000 took 0.142s
  training loss:		2.243480
  validation loss:		2.183822
  validation accuracy:		53.48 %
Epoch 12 of 2000 took 0.148s
  training loss:		2.233681
  validation loss:		2.173719
  validation accuracy:		41.09 %
Epoch 13 of 2000 took 0.147s
  training loss:		2.225000
  validation loss:		2.156758
  validation accuracy:		33.26 %
Epoch 14 of 2000 took 0.150s
  training loss:		2.214921
  validation loss:		2.150938
  validation accuracy:		58.91 %
Epoch 15 of 2000 took 0.141s
  training loss:		2.204775
  validation loss:		2.135012
  validation accuracy:		53.15 %
Epoch 16 of 2000 took 0.148s
  training loss:		2.193569
  validation loss:		2.121827
  validation accuracy:		49.46 %
Epoch 17 of 2000 took 0.145s
  training loss:		2.181634
  validation loss:		2.113133
  validation accuracy:		49.13 %
Epoch 18 of 2000 took 0.151s
  training loss:		2.168742
  validation loss:		2.098448
  validation accuracy:		53.70 %
Epoch 19 of 2000 took 0.149s
  training loss:		2.153398
  validation loss:		2.080636
  validation accuracy:		56.09 %
Epoch 20 of 2000 took 0.146s
  training loss:		2.137198
  validation loss:		2.055492
  validation accuracy:		57.28 %
Epoch 21 of 2000 took 0.148s
  training loss:		2.120417
  validation loss:		2.042895
  validation accuracy:		57.83 %
Epoch 22 of 2000 took 0.151s
  training loss:		2.103525
  validation loss:		2.020404
  validation accuracy:		52.50 %
Epoch 23 of 2000 took 0.167s
  training loss:		2.085201
  validation loss:		1.997596
  validation accuracy:		56.63 %
Epoch 24 of 2000 took 0.169s
  training loss:		2.057822
  validation loss:		1.967937
  validation accuracy:		55.11 %
Epoch 25 of 2000 took 0.206s
  training loss:		2.033476
  validation loss:		1.945183
  validation accuracy:		58.15 %
Epoch 26 of 2000 took 0.161s
  training loss:		2.010680
  validation loss:		1.908128
  validation accuracy:		57.28 %
Epoch 27 of 2000 took 0.181s
  training loss:		1.984648
  validation loss:		1.886035
  validation accuracy:		60.00 %
Epoch 28 of 2000 took 0.143s
  training loss:		1.952665
  validation loss:		1.854009
  validation accuracy:		64.89 %
Epoch 29 of 2000 took 0.144s
  training loss:		1.922287
  validation loss:		1.811927
  validation accuracy:		63.48 %
Epoch 30 of 2000 took 0.148s
  training loss:		1.892930
  validation loss:		1.788326
  validation accuracy:		64.35 %
Epoch 31 of 2000 took 0.144s
  training loss:		1.854383
  validation loss:		1.737374
  validation accuracy:		64.35 %
Epoch 32 of 2000 took 0.154s
  training loss:		1.818542
  validation loss:		1.704923
  validation accuracy:		65.33 %
Epoch 33 of 2000 took 0.147s
  training loss:		1.782112
  validation loss:		1.668886
  validation accuracy:		63.15 %
Epoch 34 of 2000 took 0.143s
  training loss:		1.741208
  validation loss:		1.615962
  validation accuracy:		66.63 %
Epoch 35 of 2000 took 0.148s
  training loss:		1.699749
  validation loss:		1.572784
  validation accuracy:		70.43 %
Epoch 36 of 2000 took 0.147s
  training loss:		1.657778
  validation loss:		1.530302
  validation accuracy:		71.41 %
Epoch 37 of 2000 took 0.146s
  training loss:		1.620142
  validation loss:		1.487584
  validation accuracy:		71.41 %
Epoch 38 of 2000 took 0.150s
  training loss:		1.574888
  validation loss:		1.435196
  validation accuracy:		72.61 %
Epoch 39 of 2000 took 0.148s
  training loss:		1.524925
  validation loss:		1.397573
  validation accuracy:		75.00 %
Epoch 40 of 2000 took 0.147s
  training loss:		1.481297
  validation loss:		1.342520
  validation accuracy:		74.67 %
Epoch 41 of 2000 took 0.142s
  training loss:		1.436176
  validation loss:		1.302447
  validation accuracy:		77.07 %
Epoch 42 of 2000 took 0.147s
  training loss:		1.395249
  validation loss:		1.254810
  validation accuracy:		77.72 %
Epoch 43 of 2000 took 0.188s
  training loss:		1.352758
  validation loss:		1.207848
  validation accuracy:		78.04 %
Epoch 44 of 2000 took 0.173s
  training loss:		1.305745
  validation loss:		1.164159
  validation accuracy:		79.35 %
Epoch 45 of 2000 took 0.147s
  training loss:		1.272580
  validation loss:		1.125494
  validation accuracy:		80.11 %
Epoch 46 of 2000 took 0.152s
  training loss:		1.219635
  validation loss:		1.076454
  validation accuracy:		80.54 %
Epoch 47 of 2000 took 0.144s
  training loss:		1.180414
  validation loss:		1.032389
  validation accuracy:		81.85 %
Epoch 48 of 2000 took 0.146s
  training loss:		1.143775
  validation loss:		0.999913
  validation accuracy:		82.61 %
Epoch 49 of 2000 took 0.145s
  training loss:		1.095459
  validation loss:		0.957422
  validation accuracy:		84.24 %
Epoch 50 of 2000 took 0.150s
  training loss:		1.060606
  validation loss:		0.918592
  validation accuracy:		84.02 %
Epoch 51 of 2000 took 0.134s
  training loss:		1.026357
  validation loss:		0.880211
  validation accuracy:		84.78 %
Epoch 52 of 2000 took 0.145s
  training loss:		0.981476
  validation loss:		0.847992
  validation accuracy:		84.57 %
Epoch 53 of 2000 took 0.140s
  training loss:		0.955013
  validation loss:		0.813848
  validation accuracy:		85.87 %
Epoch 54 of 2000 took 0.150s
  training loss:		0.914122
  validation loss:		0.784278
  validation accuracy:		84.89 %
Epoch 55 of 2000 took 0.150s
  training loss:		0.883496
  validation loss:		0.748007
  validation accuracy:		85.87 %
Epoch 56 of 2000 took 0.134s
  training loss:		0.852090
  validation loss:		0.726861
  validation accuracy:		85.76 %
Epoch 57 of 2000 took 0.145s
  training loss:		0.818174
  validation loss:		0.695740
  validation accuracy:		87.17 %
Epoch 58 of 2000 took 0.150s
  training loss:		0.785179
  validation loss:		0.664922
  validation accuracy:		85.87 %
Epoch 59 of 2000 took 0.146s
  training loss:		0.758828
  validation loss:		0.653612
  validation accuracy:		86.96 %
Epoch 60 of 2000 took 0.149s
  training loss:		0.734404
  validation loss:		0.619125
  validation accuracy:		86.74 %
Epoch 61 of 2000 took 0.144s
  training loss:		0.703037
  validation loss:		0.592188
  validation accuracy:		87.28 %
Epoch 62 of 2000 took 0.147s
  training loss:		0.684878
  validation loss:		0.577076
  validation accuracy:		87.83 %
Epoch 63 of 2000 took 0.143s
  training loss:		0.656383
  validation loss:		0.560590
  validation accuracy:		87.93 %
Epoch 64 of 2000 took 0.143s
  training loss:		0.642986
  validation loss:		0.541969
  validation accuracy:		88.91 %
Epoch 65 of 2000 took 0.180s
  training loss:		0.613878
  validation loss:		0.522528
  validation accuracy:		88.48 %
Epoch 66 of 2000 took 0.170s
  training loss:		0.599399
  validation loss:		0.506086
  validation accuracy:		89.13 %
Epoch 67 of 2000 took 0.156s
  training loss:		0.576359
  validation loss:		0.491152
  validation accuracy:		89.89 %
Epoch 68 of 2000 took 0.159s
  training loss:		0.560675
  validation loss:		0.475666
  validation accuracy:		89.35 %
Epoch 69 of 2000 took 0.159s
  training loss:		0.545408
  validation loss:		0.463220
  validation accuracy:		89.89 %
Epoch 70 of 2000 took 0.149s
  training loss:		0.532303
  validation loss:		0.460621
  validation accuracy:		89.78 %
Epoch 71 of 2000 took 0.151s
  training loss:		0.516492
  validation loss:		0.442796
  validation accuracy:		89.89 %
Epoch 72 of 2000 took 0.147s
  training loss:		0.504554
  validation loss:		0.427991
  validation accuracy:		90.33 %
Epoch 73 of 2000 took 0.147s
  training loss:		0.496055
  validation loss:		0.418084
  validation accuracy:		90.87 %
Epoch 74 of 2000 took 0.165s
  training loss:		0.477762
  validation loss:		0.421771
  validation accuracy:		90.65 %
Epoch 75 of 2000 took 0.174s
  training loss:		0.470478
  validation loss:		0.406427
  validation accuracy:		90.54 %
Epoch 76 of 2000 took 0.146s
  training loss:		0.459243
  validation loss:		0.400767
  validation accuracy:		90.43 %
Epoch 77 of 2000 took 0.147s
  training loss:		0.453457
  validation loss:		0.390954
  validation accuracy:		90.54 %
Epoch 78 of 2000 took 0.168s
  training loss:		0.438870
  validation loss:		0.377279
  validation accuracy:		90.54 %
Epoch 79 of 2000 took 0.180s
  training loss:		0.426316
  validation loss:		0.375457
  validation accuracy:		90.87 %
Epoch 80 of 2000 took 0.147s
  training loss:		0.417630
  validation loss:		0.364872
  validation accuracy:		91.74 %
Epoch 81 of 2000 took 0.147s
  training loss:		0.412450
  validation loss:		0.358247
  validation accuracy:		90.65 %
Epoch 82 of 2000 took 0.177s
  training loss:		0.404281
  validation loss:		0.353319
  validation accuracy:		90.76 %
Epoch 83 of 2000 took 0.151s
  training loss:		0.400834
  validation loss:		0.349872
  validation accuracy:		91.52 %
Epoch 84 of 2000 took 0.150s
  training loss:		0.392829
  validation loss:		0.348667
  validation accuracy:		91.74 %
Epoch 85 of 2000 took 0.147s
  training loss:		0.380221
  validation loss:		0.339531
  validation accuracy:		92.39 %
Epoch 86 of 2000 took 0.152s
  training loss:		0.377000
  validation loss:		0.329884
  validation accuracy:		91.41 %
Epoch 87 of 2000 took 0.181s
  training loss:		0.367562
  validation loss:		0.328888
  validation accuracy:		91.74 %
Epoch 88 of 2000 took 0.180s
  training loss:		0.361588
  validation loss:		0.331039
  validation accuracy:		91.20 %
Epoch 89 of 2000 took 0.149s
  training loss:		0.357061
  validation loss:		0.321101
  validation accuracy:		92.28 %
Epoch 90 of 2000 took 0.153s
  training loss:		0.357897
  validation loss:		0.321928
  validation accuracy:		92.17 %
Epoch 91 of 2000 took 0.167s
  training loss:		0.352846
  validation loss:		0.315013
  validation accuracy:		93.04 %
Epoch 92 of 2000 took 0.139s
  training loss:		0.343042
  validation loss:		0.310045
  validation accuracy:		92.50 %
Epoch 93 of 2000 took 0.142s
  training loss:		0.341737
  validation loss:		0.310206
  validation accuracy:		92.39 %
Epoch 94 of 2000 took 0.144s
  training loss:		0.336373
  validation loss:		0.304845
  validation accuracy:		92.50 %
Epoch 95 of 2000 took 0.145s
  training loss:		0.326217
  validation loss:		0.304119
  validation accuracy:		92.50 %
Epoch 96 of 2000 took 0.150s
  training loss:		0.328163
  validation loss:		0.289614
  validation accuracy:		92.28 %
Epoch 97 of 2000 took 0.144s
  training loss:		0.317946
  validation loss:		0.292892
  validation accuracy:		92.39 %
Epoch 98 of 2000 took 0.143s
  training loss:		0.318549
  validation loss:		0.288965
  validation accuracy:		92.28 %
Epoch 99 of 2000 took 0.147s
  training loss:		0.309660
  validation loss:		0.293976
  validation accuracy:		92.28 %
Epoch 100 of 2000 took 0.168s
  training loss:		0.307424
  validation loss:		0.290618
  validation accuracy:		92.28 %
Epoch 101 of 2000 took 0.142s
  training loss:		0.302337
  validation loss:		0.283394
  validation accuracy:		92.39 %
Epoch 102 of 2000 took 0.146s
  training loss:		0.301430
  validation loss:		0.273858
  validation accuracy:		92.72 %
Epoch 103 of 2000 took 0.142s
  training loss:		0.298820
  validation loss:		0.272956
  validation accuracy:		92.07 %
Epoch 104 of 2000 took 0.146s
  training loss:		0.293779
  validation loss:		0.268093
  validation accuracy:		92.50 %
Epoch 105 of 2000 took 0.143s
  training loss:		0.288680
  validation loss:		0.277660
  validation accuracy:		91.85 %
Epoch 106 of 2000 took 0.147s
  training loss:		0.284265
  validation loss:		0.270394
  validation accuracy:		92.28 %
Epoch 107 of 2000 took 0.146s
  training loss:		0.282209
  validation loss:		0.266087
  validation accuracy:		92.50 %
Epoch 108 of 2000 took 0.144s
  training loss:		0.279824
  validation loss:		0.269499
  validation accuracy:		92.72 %
Epoch 109 of 2000 took 0.146s
  training loss:		0.273137
  validation loss:		0.262919
  validation accuracy:		92.50 %
Epoch 110 of 2000 took 0.146s
  training loss:		0.271728
  validation loss:		0.258761
  validation accuracy:		93.04 %
Epoch 111 of 2000 took 0.143s
  training loss:		0.270681
  validation loss:		0.260372
  validation accuracy:		92.50 %
Epoch 112 of 2000 took 0.136s
  training loss:		0.271243
  validation loss:		0.259271
  validation accuracy:		92.93 %
Epoch 113 of 2000 took 0.146s
  training loss:		0.265525
  validation loss:		0.256800
  validation accuracy:		92.39 %
Epoch 114 of 2000 took 0.136s
  training loss:		0.263429
  validation loss:		0.254835
  validation accuracy:		92.83 %
Epoch 115 of 2000 took 0.144s
  training loss:		0.261152
  validation loss:		0.259388
  validation accuracy:		92.93 %
Epoch 116 of 2000 took 0.140s
  training loss:		0.257680
  validation loss:		0.246580
  validation accuracy:		93.04 %
Epoch 117 of 2000 took 0.145s
  training loss:		0.258379
  validation loss:		0.248284
  validation accuracy:		92.83 %
Epoch 118 of 2000 took 0.148s
  training loss:		0.253365
  validation loss:		0.257181
  validation accuracy:		93.26 %
Epoch 119 of 2000 took 0.147s
  training loss:		0.249453
  validation loss:		0.248744
  validation accuracy:		93.37 %
Epoch 120 of 2000 took 0.147s
  training loss:		0.244906
  validation loss:		0.241266
  validation accuracy:		93.59 %
Epoch 121 of 2000 took 0.144s
  training loss:		0.247094
  validation loss:		0.242713
  validation accuracy:		93.04 %
Epoch 122 of 2000 took 0.146s
  training loss:		0.245364
  validation loss:		0.238511
  validation accuracy:		93.59 %
Epoch 123 of 2000 took 0.148s
  training loss:		0.244260
  validation loss:		0.235227
  validation accuracy:		93.15 %
Epoch 124 of 2000 took 0.141s
  training loss:		0.244039
  validation loss:		0.235929
  validation accuracy:		93.04 %
Epoch 125 of 2000 took 0.156s
  training loss:		0.241103
  validation loss:		0.242980
  validation accuracy:		93.48 %
Epoch 126 of 2000 took 0.175s
  training loss:		0.234538
  validation loss:		0.237609
  validation accuracy:		93.04 %
Epoch 127 of 2000 took 0.168s
  training loss:		0.235750
  validation loss:		0.237991
  validation accuracy:		93.37 %
Epoch 128 of 2000 took 0.162s
  training loss:		0.230389
  validation loss:		0.238878
  validation accuracy:		93.26 %
Epoch 129 of 2000 took 0.159s
  training loss:		0.234724
  validation loss:		0.238232
  validation accuracy:		93.70 %
Epoch 130 of 2000 took 0.142s
  training loss:		0.231930
  validation loss:		0.230156
  validation accuracy:		93.26 %
Epoch 131 of 2000 took 0.144s
  training loss:		0.230417
  validation loss:		0.229479
  validation accuracy:		93.37 %
Epoch 132 of 2000 took 0.147s
  training loss:		0.228984
  validation loss:		0.234315
  validation accuracy:		93.26 %
Epoch 133 of 2000 took 0.146s
  training loss:		0.227468
  validation loss:		0.229063
  validation accuracy:		93.59 %
Epoch 134 of 2000 took 0.149s
  training loss:		0.228080
  validation loss:		0.230338
  validation accuracy:		94.13 %
Epoch 135 of 2000 took 0.145s
  training loss:		0.223714
  validation loss:		0.231320
  validation accuracy:		93.70 %
Epoch 136 of 2000 took 0.144s
  training loss:		0.219805
  validation loss:		0.234657
  validation accuracy:		94.02 %
Epoch 137 of 2000 took 0.143s
  training loss:		0.222615
  validation loss:		0.227672
  validation accuracy:		93.70 %
Epoch 138 of 2000 took 0.145s
  training loss:		0.215286
  validation loss:		0.225697
  validation accuracy:		93.70 %
Epoch 139 of 2000 took 0.146s
  training loss:		0.212941
  validation loss:		0.220187
  validation accuracy:		93.80 %
Epoch 140 of 2000 took 0.145s
  training loss:		0.210549
  validation loss:		0.225493
  validation accuracy:		93.70 %
Epoch 141 of 2000 took 0.140s
  training loss:		0.209125
  validation loss:		0.226434
  validation accuracy:		93.70 %
Epoch 142 of 2000 took 0.144s
  training loss:		0.212407
  validation loss:		0.226329
  validation accuracy:		93.15 %
Epoch 143 of 2000 took 0.145s
  training loss:		0.209283
  validation loss:		0.222468
  validation accuracy:		93.80 %
Epoch 144 of 2000 took 0.144s
  training loss:		0.208837
  validation loss:		0.221578
  validation accuracy:		93.80 %
Epoch 145 of 2000 took 0.148s
  training loss:		0.204803
  validation loss:		0.215792
  validation accuracy:		94.13 %
Epoch 146 of 2000 took 0.148s
  training loss:		0.207639
  validation loss:		0.224858
  validation accuracy:		93.80 %
Epoch 147 of 2000 took 0.147s
  training loss:		0.207146
  validation loss:		0.224801
  validation accuracy:		93.26 %
Epoch 148 of 2000 took 0.144s
  training loss:		0.206480
  validation loss:		0.227542
  validation accuracy:		93.80 %
Epoch 149 of 2000 took 0.139s
  training loss:		0.204131
  validation loss:		0.220576
  validation accuracy:		92.72 %
Epoch 150 of 2000 took 0.146s
  training loss:		0.199977
  validation loss:		0.216844
  validation accuracy:		93.91 %
Epoch 151 of 2000 took 0.144s
  training loss:		0.200143
  validation loss:		0.215763
  validation accuracy:		93.70 %
Epoch 152 of 2000 took 0.149s
  training loss:		0.199968
  validation loss:		0.216212
  validation accuracy:		93.80 %
Epoch 153 of 2000 took 0.145s
  training loss:		0.199238
  validation loss:		0.217191
  validation accuracy:		93.59 %
Epoch 154 of 2000 took 0.145s
  training loss:		0.195944
  validation loss:		0.216466
  validation accuracy:		94.02 %
Epoch 155 of 2000 took 0.153s
  training loss:		0.197189
  validation loss:		0.217721
  validation accuracy:		94.35 %
Epoch 156 of 2000 took 0.144s
  training loss:		0.195021
  validation loss:		0.211902
  validation accuracy:		93.70 %
Epoch 157 of 2000 took 0.143s
  training loss:		0.196610
  validation loss:		0.213549
  validation accuracy:		94.02 %
Epoch 158 of 2000 took 0.145s
  training loss:		0.189896
  validation loss:		0.218040
  validation accuracy:		94.02 %
Epoch 159 of 2000 took 0.146s
  training loss:		0.189622
  validation loss:		0.214387
  validation accuracy:		94.13 %
Epoch 160 of 2000 took 0.149s
  training loss:		0.190544
  validation loss:		0.210016
  validation accuracy:		93.70 %
Epoch 161 of 2000 took 0.142s
  training loss:		0.189661
  validation loss:		0.209031
  validation accuracy:		93.70 %
Epoch 162 of 2000 took 0.145s
  training loss:		0.192917
  validation loss:		0.219254
  validation accuracy:		93.80 %
Epoch 163 of 2000 took 0.146s
  training loss:		0.185009
  validation loss:		0.208034
  validation accuracy:		93.70 %
Epoch 164 of 2000 took 0.157s
  training loss:		0.188132
  validation loss:		0.211253
  validation accuracy:		93.48 %
Epoch 165 of 2000 took 0.152s
  training loss:		0.184652
  validation loss:		0.208695
  validation accuracy:		93.80 %
Epoch 166 of 2000 took 0.185s
  training loss:		0.187470
  validation loss:		0.210311
  validation accuracy:		93.48 %
Epoch 167 of 2000 took 0.138s
  training loss:		0.183387
  validation loss:		0.211920
  validation accuracy:		93.80 %
Epoch 168 of 2000 took 0.140s
  training loss:		0.187531
  validation loss:		0.213409
  validation accuracy:		94.35 %
Epoch 169 of 2000 took 0.146s
  training loss:		0.179278
  validation loss:		0.211031
  validation accuracy:		93.70 %
Epoch 170 of 2000 took 0.149s
  training loss:		0.181515
  validation loss:		0.210018
  validation accuracy:		94.02 %
Epoch 171 of 2000 took 0.146s
  training loss:		0.180216
  validation loss:		0.207943
  validation accuracy:		93.70 %
Epoch 172 of 2000 took 0.145s
  training loss:		0.179445
  validation loss:		0.206395
  validation accuracy:		94.13 %
Epoch 173 of 2000 took 0.146s
  training loss:		0.178322
  validation loss:		0.207819
  validation accuracy:		94.24 %
Epoch 174 of 2000 took 0.143s
  training loss:		0.179080
  validation loss:		0.207827
  validation accuracy:		93.80 %
Epoch 175 of 2000 took 0.144s
  training loss:		0.175469
  validation loss:		0.211885
  validation accuracy:		94.13 %
Epoch 176 of 2000 took 0.144s
  training loss:		0.175759
  validation loss:		0.205083
  validation accuracy:		93.04 %
Epoch 177 of 2000 took 0.145s
  training loss:		0.175046
  validation loss:		0.205573
  validation accuracy:		94.13 %
Epoch 178 of 2000 took 0.143s
  training loss:		0.172014
  validation loss:		0.202546
  validation accuracy:		93.91 %
Epoch 179 of 2000 took 0.148s
  training loss:		0.174346
  validation loss:		0.210556
  validation accuracy:		93.91 %
Epoch 180 of 2000 took 0.145s
  training loss:		0.174007
  validation loss:		0.205995
  validation accuracy:		93.91 %
Epoch 181 of 2000 took 0.148s
  training loss:		0.172361
  validation loss:		0.200082
  validation accuracy:		94.35 %
Epoch 182 of 2000 took 0.160s
  training loss:		0.172540
  validation loss:		0.206092
  validation accuracy:		94.02 %
Epoch 183 of 2000 took 0.178s
  training loss:		0.170699
  validation loss:		0.206818
  validation accuracy:		94.02 %
Epoch 184 of 2000 took 0.144s
  training loss:		0.171115
  validation loss:		0.200396
  validation accuracy:		94.46 %
Epoch 185 of 2000 took 0.140s
  training loss:		0.167958
  validation loss:		0.204066
  validation accuracy:		94.13 %
Epoch 186 of 2000 took 0.138s
  training loss:		0.168904
  validation loss:		0.195153
  validation accuracy:		94.13 %
Epoch 187 of 2000 took 0.138s
  training loss:		0.167128
  validation loss:		0.203634
  validation accuracy:		94.02 %
Epoch 188 of 2000 took 0.142s
  training loss:		0.162538
  validation loss:		0.196865
  validation accuracy:		94.13 %
Epoch 189 of 2000 took 0.145s
  training loss:		0.165959
  validation loss:		0.195893
  validation accuracy:		94.02 %
Epoch 190 of 2000 took 0.148s
  training loss:		0.163159
  validation loss:		0.201743
  validation accuracy:		93.48 %
Epoch 191 of 2000 took 0.150s
  training loss:		0.164397
  validation loss:		0.206436
  validation accuracy:		94.02 %
Epoch 192 of 2000 took 0.148s
  training loss:		0.165366
  validation loss:		0.204943
  validation accuracy:		94.13 %
Epoch 193 of 2000 took 0.145s
  training loss:		0.162578
  validation loss:		0.201681
  validation accuracy:		94.13 %
Epoch 194 of 2000 took 0.144s
  training loss:		0.159815
  validation loss:		0.208707
  validation accuracy:		94.24 %
Epoch 195 of 2000 took 0.140s
  training loss:		0.164626
  validation loss:		0.200426
  validation accuracy:		93.91 %
Epoch 196 of 2000 took 0.145s
  training loss:		0.163484
  validation loss:		0.202333
  validation accuracy:		94.13 %
Epoch 197 of 2000 took 0.144s
  training loss:		0.160503
  validation loss:		0.200786
  validation accuracy:		94.35 %
Epoch 198 of 2000 took 0.149s
  training loss:		0.163708
  validation loss:		0.201358
  validation accuracy:		93.59 %
Epoch 199 of 2000 took 0.146s
  training loss:		0.158565
  validation loss:		0.199915
  validation accuracy:		93.70 %
Epoch 200 of 2000 took 0.144s
  training loss:		0.154854
  validation loss:		0.201681
  validation accuracy:		94.24 %
Epoch 201 of 2000 took 0.147s
  training loss:		0.160143
  validation loss:		0.196416
  validation accuracy:		94.24 %
Epoch 202 of 2000 took 0.165s
  training loss:		0.155946
  validation loss:		0.197665
  validation accuracy:		94.13 %
Epoch 203 of 2000 took 0.143s
  training loss:		0.156352
  validation loss:		0.204808
  validation accuracy:		93.26 %
Epoch 204 of 2000 took 0.143s
  training loss:		0.158908
  validation loss:		0.211406
  validation accuracy:		93.59 %
Epoch 205 of 2000 took 0.147s
  training loss:		0.160186
  validation loss:		0.203336
  validation accuracy:		94.02 %
Epoch 206 of 2000 took 0.146s
  training loss:		0.157531
  validation loss:		0.198560
  validation accuracy:		94.24 %
Epoch 207 of 2000 took 0.147s
  training loss:		0.155644
  validation loss:		0.204482
  validation accuracy:		93.70 %
Epoch 208 of 2000 took 0.146s
  training loss:		0.155186
  validation loss:		0.195649
  validation accuracy:		94.02 %
Epoch 209 of 2000 took 0.143s
  training loss:		0.153769
  validation loss:		0.197214
  validation accuracy:		94.13 %
Epoch 210 of 2000 took 0.152s
  training loss:		0.155282
  validation loss:		0.192224
  validation accuracy:		93.91 %
Epoch 211 of 2000 took 0.149s
  training loss:		0.155687
  validation loss:		0.206592
  validation accuracy:		94.13 %
Epoch 212 of 2000 took 0.150s
  training loss:		0.151966
  validation loss:		0.199600
  validation accuracy:		94.13 %
Epoch 213 of 2000 took 0.140s
  training loss:		0.150170
  validation loss:		0.194300
  validation accuracy:		93.91 %
Epoch 214 of 2000 took 0.135s
  training loss:		0.150604
  validation loss:		0.194775
  validation accuracy:		93.91 %
Epoch 215 of 2000 took 0.145s
  training loss:		0.151901
  validation loss:		0.202864
  validation accuracy:		93.91 %
Epoch 216 of 2000 took 0.148s
  training loss:		0.151846
  validation loss:		0.194115
  validation accuracy:		94.35 %
Epoch 217 of 2000 took 0.147s
  training loss:		0.150432
  validation loss:		0.192919
  validation accuracy:		94.24 %
Epoch 218 of 2000 took 0.144s
  training loss:		0.149841
  validation loss:		0.196091
  validation accuracy:		94.13 %
Epoch 219 of 2000 took 0.147s
  training loss:		0.148124
  validation loss:		0.201269
  validation accuracy:		93.48 %
Epoch 220 of 2000 took 0.145s
  training loss:		0.146025
  validation loss:		0.197146
  validation accuracy:		94.13 %
Epoch 221 of 2000 took 0.154s
  training loss:		0.146808
  validation loss:		0.193510
  validation accuracy:		94.02 %
Epoch 222 of 2000 took 0.144s
  training loss:		0.142010
  validation loss:		0.192449
  validation accuracy:		94.02 %
Epoch 223 of 2000 took 0.147s
  training loss:		0.144385
  validation loss:		0.194316
  validation accuracy:		94.13 %
Epoch 224 of 2000 took 0.143s
  training loss:		0.146722
  validation loss:		0.196461
  validation accuracy:		94.13 %
Epoch 225 of 2000 took 0.146s
  training loss:		0.146437
  validation loss:		0.195887
  validation accuracy:		93.80 %
Epoch 226 of 2000 took 0.148s
  training loss:		0.147523
  validation loss:		0.200501
  validation accuracy:		93.80 %
Epoch 227 of 2000 took 0.148s
  training loss:		0.141943
  validation loss:		0.192790
  validation accuracy:		94.24 %
Epoch 228 of 2000 took 0.148s
  training loss:		0.145244
  validation loss:		0.190798
  validation accuracy:		94.24 %
Epoch 229 of 2000 took 0.145s
  training loss:		0.144419
  validation loss:		0.191834
  validation accuracy:		94.13 %
Epoch 230 of 2000 took 0.142s
  training loss:		0.139188
  validation loss:		0.197352
  validation accuracy:		93.59 %
Epoch 231 of 2000 took 0.143s
  training loss:		0.143011
  validation loss:		0.200124
  validation accuracy:		94.13 %
Epoch 232 of 2000 took 0.147s
  training loss:		0.141046
  validation loss:		0.191405
  validation accuracy:		94.46 %
Epoch 233 of 2000 took 0.143s
  training loss:		0.142871
  validation loss:		0.190658
  validation accuracy:		94.46 %
Epoch 234 of 2000 took 0.144s
  training loss:		0.139799
  validation loss:		0.190748
  validation accuracy:		94.24 %
Epoch 235 of 2000 took 0.143s
  training loss:		0.143192
  validation loss:		0.193539
  validation accuracy:		94.13 %
Epoch 236 of 2000 took 0.146s
  training loss:		0.136498
  validation loss:		0.194101
  validation accuracy:		94.02 %
Epoch 237 of 2000 took 0.145s
  training loss:		0.137635
  validation loss:		0.190031
  validation accuracy:		94.13 %
Epoch 238 of 2000 took 0.146s
  training loss:		0.135893
  validation loss:		0.194621
  validation accuracy:		94.13 %
Epoch 239 of 2000 took 0.147s
  training loss:		0.133246
  validation loss:		0.189986
  validation accuracy:		94.35 %
Epoch 240 of 2000 took 0.146s
  training loss:		0.138821
  validation loss:		0.191900
  validation accuracy:		94.46 %
Epoch 241 of 2000 took 0.147s
  training loss:		0.138516
  validation loss:		0.192561
  validation accuracy:		94.24 %
Epoch 242 of 2000 took 0.143s
  training loss:		0.135491
  validation loss:		0.192196
  validation accuracy:		94.13 %
Epoch 243 of 2000 took 0.146s
  training loss:		0.137217
  validation loss:		0.197245
  validation accuracy:		93.59 %
Epoch 244 of 2000 took 0.144s
  training loss:		0.135782
  validation loss:		0.189760
  validation accuracy:		93.91 %
Epoch 245 of 2000 took 0.147s
  training loss:		0.135740
  validation loss:		0.190531
  validation accuracy:		94.46 %
Epoch 246 of 2000 took 0.174s
  training loss:		0.134817
  validation loss:		0.199863
  validation accuracy:		93.91 %
Epoch 247 of 2000 took 0.179s
  training loss:		0.133243
  validation loss:		0.190654
  validation accuracy:		94.13 %
Epoch 248 of 2000 took 0.151s
  training loss:		0.135999
  validation loss:		0.197762
  validation accuracy:		93.70 %
Epoch 249 of 2000 took 0.189s
  training loss:		0.133208
  validation loss:		0.202594
  validation accuracy:		93.26 %
Epoch 250 of 2000 took 0.181s
  training loss:		0.136915
  validation loss:		0.198462
  validation accuracy:		93.59 %
Epoch 251 of 2000 took 0.160s
  training loss:		0.132641
  validation loss:		0.193609
  validation accuracy:		94.13 %
Epoch 252 of 2000 took 0.135s
  training loss:		0.131646
  validation loss:		0.193922
  validation accuracy:		93.91 %
Epoch 253 of 2000 took 0.142s
  training loss:		0.131645
  validation loss:		0.193273
  validation accuracy:		93.70 %
Epoch 254 of 2000 took 0.140s
  training loss:		0.130764
  validation loss:		0.196370
  validation accuracy:		93.70 %
Epoch 255 of 2000 took 0.184s
  training loss:		0.128595
  validation loss:		0.192735
  validation accuracy:		93.91 %
Epoch 256 of 2000 took 0.159s
  training loss:		0.129962
  validation loss:		0.192614
  validation accuracy:		93.80 %
Epoch 257 of 2000 took 0.134s
  training loss:		0.128946
  validation loss:		0.191831
  validation accuracy:		94.02 %
Epoch 258 of 2000 took 0.148s
  training loss:		0.130614
  validation loss:		0.188989
  validation accuracy:		94.67 %
Epoch 259 of 2000 took 0.146s
  training loss:		0.130916
  validation loss:		0.187784
  validation accuracy:		94.35 %
Epoch 260 of 2000 took 0.145s
  training loss:		0.124594
  validation loss:		0.191727
  validation accuracy:		93.70 %
Epoch 261 of 2000 took 0.144s
  training loss:		0.128019
  validation loss:		0.194233
  validation accuracy:		93.70 %
Epoch 262 of 2000 took 0.135s
  training loss:		0.123637
  validation loss:		0.190924
  validation accuracy:		93.59 %
Epoch 263 of 2000 took 0.148s
  training loss:		0.129386
  validation loss:		0.195375
  validation accuracy:		93.59 %
Epoch 264 of 2000 took 0.145s
  training loss:		0.129892
  validation loss:		0.190271
  validation accuracy:		94.35 %
Epoch 265 of 2000 took 0.143s
  training loss:		0.128010
  validation loss:		0.194964
  validation accuracy:		94.02 %
Epoch 266 of 2000 took 0.150s
  training loss:		0.129078
  validation loss:		0.198529
  validation accuracy:		94.02 %
Epoch 267 of 2000 took 0.147s
  training loss:		0.126832
  validation loss:		0.196954
  validation accuracy:		94.13 %
Epoch 268 of 2000 took 0.147s
  training loss:		0.125671
  validation loss:		0.195644
  validation accuracy:		93.48 %
Epoch 269 of 2000 took 0.136s
  training loss:		0.125926
  validation loss:		0.190543
  validation accuracy:		93.70 %
Epoch 270 of 2000 took 0.148s
  training loss:		0.129611
  validation loss:		0.195480
  validation accuracy:		93.91 %
Epoch 271 of 2000 took 0.144s
  training loss:		0.125049
  validation loss:		0.200987
  validation accuracy:		93.80 %
Epoch 272 of 2000 took 0.137s
  training loss:		0.123183
  validation loss:		0.190320
  validation accuracy:		93.91 %
Epoch 273 of 2000 took 0.146s
  training loss:		0.125228
  validation loss:		0.189059
  validation accuracy:		94.35 %
Epoch 274 of 2000 took 0.145s
  training loss:		0.126747
  validation loss:		0.190507
  validation accuracy:		93.91 %
Epoch 275 of 2000 took 0.139s
  training loss:		0.122661
  validation loss:		0.189597
  validation accuracy:		94.02 %
Epoch 276 of 2000 took 0.142s
  training loss:		0.123204
  validation loss:		0.199893
  validation accuracy:		93.80 %
Epoch 277 of 2000 took 0.143s
  training loss:		0.124059
  validation loss:		0.187299
  validation accuracy:		94.35 %
Epoch 278 of 2000 took 0.142s
  training loss:		0.122684
  validation loss:		0.194546
  validation accuracy:		93.59 %
Epoch 279 of 2000 took 0.145s
  training loss:		0.118087
  validation loss:		0.190890
  validation accuracy:		93.80 %
Epoch 280 of 2000 took 0.143s
  training loss:		0.120404
  validation loss:		0.197872
  validation accuracy:		93.80 %
Epoch 281 of 2000 took 0.148s
  training loss:		0.119872
  validation loss:		0.190536
  validation accuracy:		94.13 %
Epoch 282 of 2000 took 0.136s
  training loss:		0.118659
  validation loss:		0.191139
  validation accuracy:		94.02 %
Epoch 283 of 2000 took 0.139s
  training loss:		0.121560
  validation loss:		0.191814
  validation accuracy:		93.91 %
Epoch 284 of 2000 took 0.138s
  training loss:		0.120760
  validation loss:		0.188159
  validation accuracy:		94.24 %
Epoch 285 of 2000 took 0.145s
  training loss:		0.119016
  validation loss:		0.185811
  validation accuracy:		94.13 %
Epoch 286 of 2000 took 0.140s
  training loss:		0.120187
  validation loss:		0.192420
  validation accuracy:		93.91 %
Epoch 287 of 2000 took 0.142s
  training loss:		0.118208
  validation loss:		0.187297
  validation accuracy:		94.35 %
Epoch 288 of 2000 took 0.142s
  training loss:		0.116434
  validation loss:		0.193892
  validation accuracy:		94.02 %
Epoch 289 of 2000 took 0.147s
  training loss:		0.116054
  validation loss:		0.195063
  validation accuracy:		93.59 %
Epoch 290 of 2000 took 0.140s
  training loss:		0.120618
  validation loss:		0.195012
  validation accuracy:		94.13 %
Epoch 291 of 2000 took 0.143s
  training loss:		0.119909
  validation loss:		0.192773
  validation accuracy:		93.59 %
Epoch 292 of 2000 took 0.136s
  training loss:		0.113589
  validation loss:		0.189827
  validation accuracy:		93.59 %
Epoch 293 of 2000 took 0.144s
  training loss:		0.116291
  validation loss:		0.196407
  validation accuracy:		94.02 %
Epoch 294 of 2000 took 0.145s
  training loss:		0.119227
  validation loss:		0.199453
  validation accuracy:		93.91 %
Epoch 295 of 2000 took 0.150s
  training loss:		0.115423
  validation loss:		0.200319
  validation accuracy:		94.13 %
Epoch 296 of 2000 took 0.133s
  training loss:		0.115347
  validation loss:		0.185882
  validation accuracy:		94.46 %
Epoch 297 of 2000 took 0.182s
  training loss:		0.116574
  validation loss:		0.187900
  validation accuracy:		94.24 %
Epoch 298 of 2000 took 0.155s
  training loss:		0.114974
  validation loss:		0.186016
  validation accuracy:		94.13 %
Epoch 299 of 2000 took 0.162s
  training loss:		0.115229
  validation loss:		0.191329
  validation accuracy:		94.13 %
Epoch 300 of 2000 took 0.136s
  training loss:		0.114581
  validation loss:		0.189954
  validation accuracy:		94.02 %
Epoch 301 of 2000 took 0.155s
  training loss:		0.114456
  validation loss:		0.185359
  validation accuracy:		94.02 %
Epoch 302 of 2000 took 0.185s
  training loss:		0.114347
  validation loss:		0.197375
  validation accuracy:		93.37 %
Epoch 303 of 2000 took 0.157s
  training loss:		0.116253
  validation loss:		0.196523
  validation accuracy:		93.80 %
Epoch 304 of 2000 took 0.159s
  training loss:		0.113966
  validation loss:		0.188388
  validation accuracy:		93.91 %
Epoch 305 of 2000 took 0.162s
  training loss:		0.111362
  validation loss:		0.186777
  validation accuracy:		94.13 %
Epoch 306 of 2000 took 0.139s
  training loss:		0.116237
  validation loss:		0.188870
  validation accuracy:		93.91 %
Epoch 307 of 2000 took 0.154s
  training loss:		0.112481
  validation loss:		0.197505
  validation accuracy:		93.80 %
Epoch 308 of 2000 took 0.143s
  training loss:		0.114988
  validation loss:		0.187767
  validation accuracy:		93.70 %
Epoch 309 of 2000 took 0.146s
  training loss:		0.109722
  validation loss:		0.192614
  validation accuracy:		94.02 %
Epoch 310 of 2000 took 0.143s
  training loss:		0.111537
  validation loss:		0.188230
  validation accuracy:		94.46 %
Epoch 311 of 2000 took 0.149s
  training loss:		0.111963
  validation loss:		0.193877
  validation accuracy:		93.59 %
Epoch 312 of 2000 took 0.143s
  training loss:		0.108853
  validation loss:		0.203658
  validation accuracy:		93.59 %
Epoch 313 of 2000 took 0.148s
  training loss:		0.113271
  validation loss:		0.190019
  validation accuracy:		94.02 %
Epoch 314 of 2000 took 0.152s
  training loss:		0.113175
  validation loss:		0.193056
  validation accuracy:		93.91 %
Epoch 315 of 2000 took 0.141s
  training loss:		0.109068
  validation loss:		0.186902
  validation accuracy:		93.80 %
Epoch 316 of 2000 took 0.159s
  training loss:		0.109289
  validation loss:		0.196146
  validation accuracy:		93.80 %
Epoch 317 of 2000 took 0.139s
  training loss:		0.110380
  validation loss:		0.187300
  validation accuracy:		94.24 %
Epoch 318 of 2000 took 0.145s
  training loss:		0.108166
  validation loss:		0.187065
  validation accuracy:		93.80 %
Epoch 319 of 2000 took 0.148s
  training loss:		0.110895
  validation loss:		0.197348
  validation accuracy:		93.91 %
Epoch 320 of 2000 took 0.147s
  training loss:		0.110637
  validation loss:		0.183384
  validation accuracy:		94.35 %
Epoch 321 of 2000 took 0.150s
  training loss:		0.111269
  validation loss:		0.188376
  validation accuracy:		94.02 %
Epoch 322 of 2000 took 0.157s
  training loss:		0.106304
  validation loss:		0.188939
  validation accuracy:		94.24 %
Epoch 323 of 2000 took 0.147s
  training loss:		0.108599
  validation loss:		0.192637
  validation accuracy:		94.13 %
Epoch 324 of 2000 took 0.141s
  training loss:		0.105613
  validation loss:		0.188321
  validation accuracy:		93.80 %
Epoch 325 of 2000 took 0.139s
  training loss:		0.110346
  validation loss:		0.192782
  validation accuracy:		93.70 %
Epoch 326 of 2000 took 0.135s
  training loss:		0.108002
  validation loss:		0.188270
  validation accuracy:		94.13 %
Epoch 327 of 2000 took 0.144s
  training loss:		0.107525
  validation loss:		0.187408
  validation accuracy:		93.91 %
Epoch 328 of 2000 took 0.143s
  training loss:		0.110081
  validation loss:		0.189038
  validation accuracy:		93.80 %
Epoch 329 of 2000 took 0.141s
  training loss:		0.105947
  validation loss:		0.194618
  validation accuracy:		93.91 %
Epoch 330 of 2000 took 0.145s
  training loss:		0.105349
  validation loss:		0.186901
  validation accuracy:		94.02 %
Epoch 331 of 2000 took 0.137s
  training loss:		0.104215
  validation loss:		0.183882
  validation accuracy:		94.35 %
Epoch 332 of 2000 took 0.143s
  training loss:		0.102442
  validation loss:		0.194210
  validation accuracy:		93.80 %
Epoch 333 of 2000 took 0.150s
  training loss:		0.106070
  validation loss:		0.189856
  validation accuracy:		94.46 %
Epoch 334 of 2000 took 0.143s
  training loss:		0.107689
  validation loss:		0.188724
  validation accuracy:		94.13 %
Epoch 335 of 2000 took 0.140s
  training loss:		0.105038
  validation loss:		0.188068
  validation accuracy:		94.24 %
Epoch 336 of 2000 took 0.147s
  training loss:		0.104378
  validation loss:		0.192517
  validation accuracy:		93.80 %
Epoch 337 of 2000 took 0.141s
  training loss:		0.104018
  validation loss:		0.187115
  validation accuracy:		94.02 %
Epoch 338 of 2000 took 0.155s
  training loss:		0.103597
  validation loss:		0.182847
  validation accuracy:		94.13 %
Epoch 339 of 2000 took 0.148s
  training loss:		0.103503
  validation loss:		0.188991
  validation accuracy:		93.80 %
Epoch 340 of 2000 took 0.135s
  training loss:		0.104574
  validation loss:		0.187730
  validation accuracy:		94.13 %
Epoch 341 of 2000 took 0.136s
  training loss:		0.103600
  validation loss:		0.188824
  validation accuracy:		93.91 %
Epoch 342 of 2000 took 0.142s
  training loss:		0.105537
  validation loss:		0.188325
  validation accuracy:		94.24 %
Epoch 343 of 2000 took 0.140s
  training loss:		0.101602
  validation loss:		0.189667
  validation accuracy:		93.91 %
Epoch 344 of 2000 took 0.142s
  training loss:		0.105018
  validation loss:		0.196445
  validation accuracy:		93.59 %
Epoch 345 of 2000 took 0.143s
  training loss:		0.099805
  validation loss:		0.188909
  validation accuracy:		94.13 %
Epoch 346 of 2000 took 0.142s
  training loss:		0.101185
  validation loss:		0.188642
  validation accuracy:		94.13 %
Epoch 347 of 2000 took 0.141s
  training loss:		0.100691
  validation loss:		0.189789
  validation accuracy:		93.80 %
Epoch 348 of 2000 took 0.140s
  training loss:		0.101805
  validation loss:		0.186229
  validation accuracy:		94.02 %
Epoch 349 of 2000 took 0.143s
  training loss:		0.101302
  validation loss:		0.190380
  validation accuracy:		94.24 %
Epoch 350 of 2000 took 0.144s
  training loss:		0.103688
  validation loss:		0.193011
  validation accuracy:		93.59 %
Epoch 351 of 2000 took 0.148s
  training loss:		0.100906
  validation loss:		0.187642
  validation accuracy:		93.91 %
Epoch 352 of 2000 took 0.158s
  training loss:		0.101858
  validation loss:		0.195259
  validation accuracy:		93.80 %
Epoch 353 of 2000 took 0.143s
  training loss:		0.099944
  validation loss:		0.185213
  validation accuracy:		94.02 %
Epoch 354 of 2000 took 0.138s
  training loss:		0.099881
  validation loss:		0.197468
  validation accuracy:		93.80 %
Epoch 355 of 2000 took 0.143s
  training loss:		0.097515
  validation loss:		0.183931
  validation accuracy:		94.13 %
Epoch 356 of 2000 took 0.190s
  training loss:		0.099980
  validation loss:		0.196615
  validation accuracy:		93.70 %
Epoch 357 of 2000 took 0.150s
  training loss:		0.097999
  validation loss:		0.188383
  validation accuracy:		93.91 %
Epoch 358 of 2000 took 0.152s
  training loss:		0.097665
  validation loss:		0.186519
  validation accuracy:		94.24 %
Epoch 359 of 2000 took 0.145s
  training loss:		0.093714
  validation loss:		0.188520
  validation accuracy:		94.24 %
Epoch 360 of 2000 took 0.157s
  training loss:		0.096350
  validation loss:		0.186159
  validation accuracy:		94.46 %
Epoch 361 of 2000 took 0.141s
  training loss:		0.095673
  validation loss:		0.194242
  validation accuracy:		94.13 %
Epoch 362 of 2000 took 0.137s
  training loss:		0.097320
  validation loss:		0.188569
  validation accuracy:		94.02 %
Epoch 363 of 2000 took 0.144s
  training loss:		0.096218
  validation loss:		0.187771
  validation accuracy:		94.13 %
Epoch 364 of 2000 took 0.155s
  training loss:		0.098942
  validation loss:		0.197002
  validation accuracy:		93.70 %
Epoch 365 of 2000 took 0.177s
  training loss:		0.098060
  validation loss:		0.187008
  validation accuracy:		94.02 %
Epoch 366 of 2000 took 0.144s
  training loss:		0.094885
  validation loss:		0.190458
  validation accuracy:		94.02 %
Epoch 367 of 2000 took 0.145s
  training loss:		0.098665
  validation loss:		0.190797
  validation accuracy:		93.91 %
Epoch 368 of 2000 took 0.139s
  training loss:		0.096392
  validation loss:		0.188248
  validation accuracy:		93.70 %
Epoch 369 of 2000 took 0.137s
  training loss:		0.098245
  validation loss:		0.199312
  validation accuracy:		93.59 %
Epoch 370 of 2000 took 0.148s
  training loss:		0.095769
  validation loss:		0.192987
  validation accuracy:		94.13 %
Epoch 371 of 2000 took 0.188s
  training loss:		0.095709
  validation loss:		0.192904
  validation accuracy:		93.91 %
Epoch 372 of 2000 took 0.165s
  training loss:		0.095363
  validation loss:		0.190708
  validation accuracy:		94.02 %
Epoch 373 of 2000 took 0.155s
  training loss:		0.097296
  validation loss:		0.191752
  validation accuracy:		94.02 %
Epoch 374 of 2000 took 0.141s
  training loss:		0.094246
  validation loss:		0.199080
  validation accuracy:		93.91 %
Epoch 375 of 2000 took 0.145s
  training loss:		0.093810
  validation loss:		0.198672
  validation accuracy:		93.91 %
Epoch 376 of 2000 took 0.148s
  training loss:		0.094032
  validation loss:		0.198299
  validation accuracy:		93.70 %
Epoch 377 of 2000 took 0.141s
  training loss:		0.093000
  validation loss:		0.185397
  validation accuracy:		94.24 %
Epoch 378 of 2000 took 0.149s
  training loss:		0.094293
  validation loss:		0.194581
  validation accuracy:		94.02 %
Epoch 379 of 2000 took 0.142s
  training loss:		0.093326
  validation loss:		0.193865
  validation accuracy:		93.80 %
Epoch 380 of 2000 took 0.143s
  training loss:		0.094948
  validation loss:		0.187859
  validation accuracy:		93.70 %
Epoch 381 of 2000 took 0.144s
  training loss:		0.093891
  validation loss:		0.196512
  validation accuracy:		94.02 %
Epoch 382 of 2000 took 0.142s
  training loss:		0.089134
  validation loss:		0.198934
  validation accuracy:		94.02 %
Epoch 383 of 2000 took 0.145s
  training loss:		0.094536
  validation loss:		0.192130
  validation accuracy:		94.02 %
Epoch 384 of 2000 took 0.145s
  training loss:		0.092400
  validation loss:		0.185066
  validation accuracy:		94.46 %
Epoch 385 of 2000 took 0.144s
  training loss:		0.089426
  validation loss:		0.189482
  validation accuracy:		94.35 %
Epoch 386 of 2000 took 0.140s
  training loss:		0.090075
  validation loss:		0.193341
  validation accuracy:		94.02 %
Epoch 387 of 2000 took 0.141s
  training loss:		0.088744
  validation loss:		0.199952
  validation accuracy:		93.70 %
Epoch 388 of 2000 took 0.145s
  training loss:		0.093049
  validation loss:		0.184383
  validation accuracy:		94.13 %
Epoch 389 of 2000 took 0.144s
  training loss:		0.093301
  validation loss:		0.191593
  validation accuracy:		94.46 %
Epoch 390 of 2000 took 0.139s
  training loss:		0.091610
  validation loss:		0.191921
  validation accuracy:		94.24 %
Epoch 391 of 2000 took 0.139s
  training loss:		0.092055
  validation loss:		0.195992
  validation accuracy:		93.70 %
Epoch 392 of 2000 took 0.140s
  training loss:		0.093659
  validation loss:		0.197982
  validation accuracy:		93.48 %
Epoch 393 of 2000 took 0.148s
  training loss:		0.090876
  validation loss:		0.192774
  validation accuracy:		93.70 %
Epoch 394 of 2000 took 0.140s
  training loss:		0.090826
  validation loss:		0.192128
  validation accuracy:		94.13 %
Epoch 395 of 2000 took 0.142s
  training loss:		0.085953
  validation loss:		0.199591
  validation accuracy:		93.59 %
Epoch 396 of 2000 took 0.151s
  training loss:		0.087167
  validation loss:		0.193669
  validation accuracy:		94.24 %
Epoch 397 of 2000 took 0.168s
  training loss:		0.089262
  validation loss:		0.188513
  validation accuracy:		93.70 %
Epoch 398 of 2000 took 0.177s
  training loss:		0.089730
  validation loss:		0.199265
  validation accuracy:		93.91 %
Epoch 399 of 2000 took 0.140s
  training loss:		0.090560
  validation loss:		0.197629
  validation accuracy:		93.91 %
Epoch 400 of 2000 took 0.147s
  training loss:		0.090513
  validation loss:		0.192171
  validation accuracy:		94.02 %
Epoch 401 of 2000 took 0.145s
  training loss:		0.088402
  validation loss:		0.190800
  validation accuracy:		93.91 %
Epoch 402 of 2000 took 0.180s
  training loss:		0.089841
  validation loss:		0.197751
  validation accuracy:		93.91 %
Epoch 403 of 2000 took 0.142s
  training loss:		0.091821
  validation loss:		0.192308
  validation accuracy:		94.13 %
Epoch 404 of 2000 took 0.159s
  training loss:		0.085545
  validation loss:		0.198188
  validation accuracy:		94.13 %
Epoch 405 of 2000 took 0.181s
  training loss:		0.087553
  validation loss:		0.196524
  validation accuracy:		93.80 %
Epoch 406 of 2000 took 0.141s
  training loss:		0.089753
  validation loss:		0.191555
  validation accuracy:		93.70 %
Epoch 407 of 2000 took 0.173s
  training loss:		0.086362
  validation loss:		0.187925
  validation accuracy:		94.35 %
Epoch 408 of 2000 took 0.138s
  training loss:		0.085727
  validation loss:		0.188384
  validation accuracy:		94.35 %
Epoch 409 of 2000 took 0.140s
  training loss:		0.089434
  validation loss:		0.195573
  validation accuracy:		93.80 %
Epoch 410 of 2000 took 0.144s
  training loss:		0.088638
  validation loss:		0.193344
  validation accuracy:		94.13 %
Epoch 411 of 2000 took 0.147s
  training loss:		0.087962
  validation loss:		0.191445
  validation accuracy:		94.02 %
Epoch 412 of 2000 took 0.143s
  training loss:		0.085887
  validation loss:		0.195675
  validation accuracy:		93.70 %
Epoch 413 of 2000 took 0.145s
  training loss:		0.085457
  validation loss:		0.191676
  validation accuracy:		93.91 %
Epoch 414 of 2000 took 0.139s
  training loss:		0.087487
  validation loss:		0.192669
  validation accuracy:		94.02 %
Epoch 415 of 2000 took 0.142s
  training loss:		0.087279
  validation loss:		0.199638
  validation accuracy:		93.80 %
Epoch 416 of 2000 took 0.144s
  training loss:		0.086843
  validation loss:		0.195854
  validation accuracy:		93.91 %
Epoch 417 of 2000 took 0.145s
  training loss:		0.085633
  validation loss:		0.194840
  validation accuracy:		94.24 %
Epoch 418 of 2000 took 0.156s
  training loss:		0.082792
  validation loss:		0.195153
  validation accuracy:		94.13 %
Epoch 419 of 2000 took 0.145s
  training loss:		0.086716
  validation loss:		0.194895
  validation accuracy:		94.02 %
Epoch 420 of 2000 took 0.141s
  training loss:		0.085018
  validation loss:		0.192259
  validation accuracy:		94.02 %
Epoch 421 of 2000 took 0.142s
  training loss:		0.086691
  validation loss:		0.195483
  validation accuracy:		93.80 %
Epoch 422 of 2000 took 0.141s
  training loss:		0.084089
  validation loss:		0.193635
  validation accuracy:		94.24 %
Epoch 423 of 2000 took 0.149s
  training loss:		0.082797
  validation loss:		0.193231
  validation accuracy:		94.24 %
Epoch 424 of 2000 took 0.144s
  training loss:		0.085534
  validation loss:		0.200061
  validation accuracy:		94.02 %
Epoch 425 of 2000 took 0.141s
  training loss:		0.084877
  validation loss:		0.198139
  validation accuracy:		93.80 %
Epoch 426 of 2000 took 0.144s
  training loss:		0.084948
  validation loss:		0.193677
  validation accuracy:		94.35 %
Epoch 427 of 2000 took 0.140s
  training loss:		0.083492
  validation loss:		0.195159
  validation accuracy:		94.02 %
Epoch 428 of 2000 took 0.111s
  training loss:		0.086135
  validation loss:		0.194564
  validation accuracy:		94.35 %
Epoch 429 of 2000 took 0.139s
  training loss:		0.082182
  validation loss:		0.196915
  validation accuracy:		94.13 %
Epoch 430 of 2000 took 0.145s
  training loss:		0.083659
  validation loss:		0.194899
  validation accuracy:		93.70 %
Epoch 431 of 2000 took 0.139s
  training loss:		0.084030
  validation loss:		0.197992
  validation accuracy:		94.02 %
Epoch 432 of 2000 took 0.142s
  training loss:		0.083108
  validation loss:		0.196366
  validation accuracy:		94.35 %
Epoch 433 of 2000 took 0.149s
  training loss:		0.082357
  validation loss:		0.197969
  validation accuracy:		93.70 %
Epoch 434 of 2000 took 0.146s
  training loss:		0.080293
  validation loss:		0.195840
  validation accuracy:		94.24 %
Epoch 435 of 2000 took 0.139s
  training loss:		0.079122
  validation loss:		0.194896
  validation accuracy:		94.02 %
Epoch 436 of 2000 took 0.140s
  training loss:		0.082265
  validation loss:		0.202897
  validation accuracy:		93.80 %
Epoch 437 of 2000 took 0.140s
  training loss:		0.082299
  validation loss:		0.192010
  validation accuracy:		94.02 %
Epoch 438 of 2000 took 0.141s
  training loss:		0.081893
  validation loss:		0.195977
  validation accuracy:		93.91 %
Epoch 439 of 2000 took 0.142s
  training loss:		0.081585
  validation loss:		0.194712
  validation accuracy:		94.13 %
Epoch 440 of 2000 took 0.146s
  training loss:		0.080271
  validation loss:		0.192590
  validation accuracy:		94.35 %
Epoch 441 of 2000 took 0.146s
  training loss:		0.078184
  validation loss:		0.190871
  validation accuracy:		94.24 %
Epoch 442 of 2000 took 0.144s
  training loss:		0.083035
  validation loss:		0.209627
  validation accuracy:		93.48 %
Epoch 443 of 2000 took 0.137s
  training loss:		0.082719
  validation loss:		0.206507
  validation accuracy:		93.80 %
Epoch 444 of 2000 took 0.147s
  training loss:		0.080653
  validation loss:		0.197383
  validation accuracy:		93.91 %
Epoch 445 of 2000 took 0.151s
  training loss:		0.077126
  validation loss:		0.188017
  validation accuracy:		94.46 %
Epoch 446 of 2000 took 0.144s
  training loss:		0.074365
  validation loss:		0.189519
  validation accuracy:		94.57 %
Epoch 447 of 2000 took 0.146s
  training loss:		0.078545
  validation loss:		0.202438
  validation accuracy:		93.70 %
Epoch 448 of 2000 took 0.148s
  training loss:		0.077745
  validation loss:		0.203011
  validation accuracy:		93.70 %
Epoch 449 of 2000 took 0.148s
  training loss:		0.079498
  validation loss:		0.188578
  validation accuracy:		94.13 %
Epoch 450 of 2000 took 0.147s
  training loss:		0.079921
  validation loss:		0.193749
  validation accuracy:		94.67 %
Epoch 451 of 2000 took 0.137s
  training loss:		0.079112
  validation loss:		0.195347
  validation accuracy:		94.13 %
Epoch 452 of 2000 took 0.143s
  training loss:		0.077775
  validation loss:		0.210680
  validation accuracy:		93.26 %
Epoch 453 of 2000 took 0.148s
  training loss:		0.078339
  validation loss:		0.201943
  validation accuracy:		93.59 %
Epoch 454 of 2000 took 0.157s
  training loss:		0.078588
  validation loss:		0.194427
  validation accuracy:		93.70 %
Epoch 455 of 2000 took 0.146s
  training loss:		0.079068
  validation loss:		0.195941
  validation accuracy:		94.02 %
Epoch 456 of 2000 took 0.140s
  training loss:		0.076622
  validation loss:		0.201506
  validation accuracy:		93.70 %
Epoch 457 of 2000 took 0.150s
  training loss:		0.080270
  validation loss:		0.199854
  validation accuracy:		93.70 %
Epoch 458 of 2000 took 0.155s
  training loss:		0.077728
  validation loss:		0.194311
  validation accuracy:		94.24 %
Epoch 459 of 2000 took 0.147s
  training loss:		0.078472
  validation loss:		0.193571
  validation accuracy:		94.46 %
Epoch 460 of 2000 took 0.149s
  training loss:		0.076941
  validation loss:		0.210275
  validation accuracy:		93.37 %
Epoch 461 of 2000 took 0.136s
  training loss:		0.077580
  validation loss:		0.196781
  validation accuracy:		93.91 %
Epoch 462 of 2000 took 0.166s
  training loss:		0.076538
  validation loss:		0.195143
  validation accuracy:		93.80 %
Epoch 463 of 2000 took 0.195s
  training loss:		0.077253
  validation loss:		0.206228
  validation accuracy:		93.48 %
Epoch 464 of 2000 took 0.138s
  training loss:		0.074383
  validation loss:		0.206361
  validation accuracy:		93.59 %
Epoch 465 of 2000 took 0.139s
  training loss:		0.073385
  validation loss:		0.206359
  validation accuracy:		93.80 %
Epoch 466 of 2000 took 0.137s
  training loss:		0.076383
  validation loss:		0.195704
  validation accuracy:		94.02 %
Epoch 467 of 2000 took 0.148s
  training loss:		0.074118
  validation loss:		0.198813
  validation accuracy:		94.02 %
Epoch 468 of 2000 took 0.141s
  training loss:		0.077046
  validation loss:		0.195870
  validation accuracy:		94.13 %
Epoch 469 of 2000 took 0.143s
  training loss:		0.075216
  validation loss:		0.197385
  validation accuracy:		93.80 %
Epoch 470 of 2000 took 0.171s
  training loss:		0.073250
  validation loss:		0.191947
  validation accuracy:		94.46 %
Epoch 471 of 2000 took 0.148s
  training loss:		0.074229
  validation loss:		0.214281
  validation accuracy:		93.70 %
Epoch 472 of 2000 took 0.143s
  training loss:		0.074742
  validation loss:		0.195207
  validation accuracy:		93.91 %
Epoch 473 of 2000 took 0.138s
  training loss:		0.075823
  validation loss:		0.197454
  validation accuracy:		94.46 %
Epoch 474 of 2000 took 0.144s
  training loss:		0.074610
  validation loss:		0.201291
  validation accuracy:		93.91 %
Epoch 475 of 2000 took 0.144s
  training loss:		0.074493
  validation loss:		0.205744
  validation accuracy:		94.13 %
Epoch 476 of 2000 took 0.138s
  training loss:		0.073611
  validation loss:		0.205454
  validation accuracy:		94.13 %
Epoch 477 of 2000 took 0.144s
  training loss:		0.072206
  validation loss:		0.199142
  validation accuracy:		94.35 %
Epoch 478 of 2000 took 0.141s
  training loss:		0.074926
  validation loss:		0.205642
  validation accuracy:		93.80 %
Epoch 479 of 2000 took 0.138s
  training loss:		0.075035
  validation loss:		0.218449
  validation accuracy:		93.26 %
Epoch 480 of 2000 took 0.143s
  training loss:		0.070063
  validation loss:		0.199630
  validation accuracy:		94.02 %
Epoch 481 of 2000 took 0.146s
  training loss:		0.073709
  validation loss:		0.198822
  validation accuracy:		94.24 %
Epoch 482 of 2000 took 0.147s
  training loss:		0.073246
  validation loss:		0.204464
  validation accuracy:		93.70 %
Epoch 483 of 2000 took 0.138s
  training loss:		0.073307
  validation loss:		0.209232
  validation accuracy:		93.70 %
Epoch 484 of 2000 took 0.166s
  training loss:		0.074108
  validation loss:		0.197378
  validation accuracy:		94.24 %
Epoch 485 of 2000 took 0.140s
  training loss:		0.075134
  validation loss:		0.198513
  validation accuracy:		93.91 %
Epoch 486 of 2000 took 0.139s
  training loss:		0.071452
  validation loss:		0.199891
  validation accuracy:		94.46 %
Epoch 487 of 2000 took 0.155s
  training loss:		0.072602
  validation loss:		0.203953
  validation accuracy:		94.02 %
Epoch 488 of 2000 took 0.164s
  training loss:		0.069975
  validation loss:		0.196440
  validation accuracy:		94.24 %
Epoch 489 of 2000 took 0.136s
  training loss:		0.070538
  validation loss:		0.207016
  validation accuracy:		93.80 %
Epoch 490 of 2000 took 0.140s
  training loss:		0.071475
  validation loss:		0.200840
  validation accuracy:		94.67 %
Epoch 491 of 2000 took 0.138s
  training loss:		0.073327
  validation loss:		0.209540
  validation accuracy:		94.02 %
Epoch 492 of 2000 took 0.143s
  training loss:		0.070644
  validation loss:		0.212500
  validation accuracy:		93.80 %
Epoch 493 of 2000 took 0.137s
  training loss:		0.070658
  validation loss:		0.204496
  validation accuracy:		93.80 %
Epoch 494 of 2000 took 0.147s
  training loss:		0.071296
  validation loss:		0.204329
  validation accuracy:		93.80 %
Epoch 495 of 2000 took 0.146s
  training loss:		0.070549
  validation loss:		0.207850
  validation accuracy:		93.80 %
Epoch 496 of 2000 took 0.141s
  training loss:		0.071551
  validation loss:		0.207090
  validation accuracy:		93.80 %
Epoch 497 of 2000 took 0.140s
  training loss:		0.069282
  validation loss:		0.211190
  validation accuracy:		94.13 %
Epoch 498 of 2000 took 0.143s
  training loss:		0.069136
  validation loss:		0.196354
  validation accuracy:		94.35 %
Epoch 499 of 2000 took 0.145s
  training loss:		0.069069
  validation loss:		0.202741
  validation accuracy:		93.80 %
Epoch 500 of 2000 took 0.144s
  training loss:		0.071012
  validation loss:		0.205298
  validation accuracy:		94.02 %
Epoch 501 of 2000 took 0.141s
  training loss:		0.069538
  validation loss:		0.209972
  validation accuracy:		94.13 %
Epoch 502 of 2000 took 0.138s
  training loss:		0.069929
  validation loss:		0.209977
  validation accuracy:		93.80 %
Epoch 503 of 2000 took 0.147s
  training loss:		0.069179
  validation loss:		0.208456
  validation accuracy:		94.35 %
Epoch 504 of 2000 took 0.144s
  training loss:		0.070133
  validation loss:		0.203793
  validation accuracy:		93.91 %
Epoch 505 of 2000 took 0.143s
  training loss:		0.068193
  validation loss:		0.216020
  validation accuracy:		93.37 %
Epoch 506 of 2000 took 0.143s
  training loss:		0.067772
  validation loss:		0.211658
  validation accuracy:		93.59 %
Epoch 507 of 2000 took 0.145s
  training loss:		0.071747
  validation loss:		0.213769
  validation accuracy:		93.70 %
Epoch 508 of 2000 took 0.147s
  training loss:		0.070637
  validation loss:		0.205370
  validation accuracy:		94.02 %
Epoch 509 of 2000 took 0.135s
  training loss:		0.070426
  validation loss:		0.212331
  validation accuracy:		93.91 %
Epoch 510 of 2000 took 0.141s
  training loss:		0.068117
  validation loss:		0.206110
  validation accuracy:		93.91 %
Epoch 511 of 2000 took 0.138s
  training loss:		0.068316
  validation loss:		0.207516
  validation accuracy:		94.02 %
Epoch 512 of 2000 took 0.157s
  training loss:		0.069057
  validation loss:		0.201812
  validation accuracy:		94.02 %
Epoch 513 of 2000 took 0.135s
  training loss:		0.068611
  validation loss:		0.208654
  validation accuracy:		94.13 %
Epoch 514 of 2000 took 0.142s
  training loss:		0.066844
  validation loss:		0.204563
  validation accuracy:		93.91 %
Epoch 515 of 2000 took 0.140s
  training loss:		0.069187
  validation loss:		0.200331
  validation accuracy:		94.24 %
Epoch 516 of 2000 took 0.140s
  training loss:		0.069204
  validation loss:		0.206473
  validation accuracy:		94.13 %
Epoch 517 of 2000 took 0.144s
  training loss:		0.067668
  validation loss:		0.214151
  validation accuracy:		94.02 %
Epoch 518 of 2000 took 0.135s
  training loss:		0.067528
  validation loss:		0.211703
  validation accuracy:		93.91 %
Epoch 519 of 2000 took 0.146s
  training loss:		0.067891
  validation loss:		0.209691
  validation accuracy:		93.91 %
Epoch 520 of 2000 took 0.151s
  training loss:		0.065061
  validation loss:		0.203450
  validation accuracy:		94.13 %
Epoch 521 of 2000 took 0.146s
  training loss:		0.066939
  validation loss:		0.204317
  validation accuracy:		94.24 %
Epoch 522 of 2000 took 0.150s
  training loss:		0.065609
  validation loss:		0.211396
  validation accuracy:		93.70 %
Epoch 523 of 2000 took 0.144s
  training loss:		0.067324
  validation loss:		0.218535
  validation accuracy:		93.48 %
Epoch 524 of 2000 took 0.148s
  training loss:		0.064964
  validation loss:		0.202888
  validation accuracy:		94.24 %
Epoch 525 of 2000 took 0.140s
  training loss:		0.065953
  validation loss:		0.209460
  validation accuracy:		94.13 %
Epoch 526 of 2000 took 0.144s
  training loss:		0.064639
  validation loss:		0.211965
  validation accuracy:		93.70 %
Epoch 527 of 2000 took 0.138s
  training loss:		0.067449
  validation loss:		0.212465
  validation accuracy:		94.02 %
Epoch 528 of 2000 took 0.144s
  training loss:		0.067306
  validation loss:		0.204670
  validation accuracy:		94.35 %
Epoch 529 of 2000 took 0.148s
  training loss:		0.063637
  validation loss:		0.211492
  validation accuracy:		93.80 %
Epoch 530 of 2000 took 0.170s
  training loss:		0.064219
  validation loss:		0.212179
  validation accuracy:		94.02 %
Epoch 531 of 2000 took 0.135s
  training loss:		0.064409
  validation loss:		0.204422
  validation accuracy:		94.46 %
Epoch 532 of 2000 took 0.140s
  training loss:		0.065368
  validation loss:		0.206069
  validation accuracy:		94.13 %
Epoch 533 of 2000 took 0.158s
  training loss:		0.062299
  validation loss:		0.216643
  validation accuracy:		93.80 %
Epoch 534 of 2000 took 0.137s
  training loss:		0.065055
  validation loss:		0.203082
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.149s
  training loss:		0.064269
  validation loss:		0.219233
  validation accuracy:		93.80 %
Epoch 536 of 2000 took 0.133s
  training loss:		0.063598
  validation loss:		0.212689
  validation accuracy:		94.13 %
Epoch 537 of 2000 took 0.144s
  training loss:		0.062474
  validation loss:		0.211963
  validation accuracy:		93.91 %
Epoch 538 of 2000 took 0.160s
  training loss:		0.065268
  validation loss:		0.213097
  validation accuracy:		93.48 %
Epoch 539 of 2000 took 0.186s
  training loss:		0.063202
  validation loss:		0.217513
  validation accuracy:		93.59 %
Epoch 540 of 2000 took 0.141s
  training loss:		0.061886
  validation loss:		0.206595
  validation accuracy:		93.80 %
Epoch 541 of 2000 took 0.141s
  training loss:		0.064590
  validation loss:		0.209996
  validation accuracy:		93.91 %
Epoch 542 of 2000 took 0.143s
  training loss:		0.061861
  validation loss:		0.209199
  validation accuracy:		94.13 %
Epoch 543 of 2000 took 0.170s
  training loss:		0.063026
  validation loss:		0.220087
  validation accuracy:		93.59 %
Epoch 544 of 2000 took 0.136s
  training loss:		0.064499
  validation loss:		0.214952
  validation accuracy:		93.91 %
Epoch 545 of 2000 took 0.150s
  training loss:		0.063409
  validation loss:		0.213053
  validation accuracy:		94.02 %
Epoch 546 of 2000 took 0.141s
  training loss:		0.063817
  validation loss:		0.211744
  validation accuracy:		94.02 %
Epoch 547 of 2000 took 0.159s
  training loss:		0.061568
  validation loss:		0.218359
  validation accuracy:		93.70 %
Epoch 548 of 2000 took 0.143s
  training loss:		0.063937
  validation loss:		0.213912
  validation accuracy:		94.13 %
Epoch 549 of 2000 took 0.149s
  training loss:		0.063708
  validation loss:		0.213061
  validation accuracy:		94.02 %
Epoch 550 of 2000 took 0.141s
  training loss:		0.059292
  validation loss:		0.223580
  validation accuracy:		93.70 %
Epoch 551 of 2000 took 0.148s
  training loss:		0.062968
  validation loss:		0.208491
  validation accuracy:		94.02 %
Epoch 552 of 2000 took 0.147s
  training loss:		0.061617
  validation loss:		0.214685
  validation accuracy:		94.02 %
Epoch 553 of 2000 took 0.149s
  training loss:		0.060901
  validation loss:		0.214546
  validation accuracy:		93.91 %
Epoch 554 of 2000 took 0.152s
  training loss:		0.061777
  validation loss:		0.213937
  validation accuracy:		93.80 %
Epoch 555 of 2000 took 0.147s
  training loss:		0.061362
  validation loss:		0.214943
  validation accuracy:		93.91 %
Epoch 556 of 2000 took 0.148s
  training loss:		0.061101
  validation loss:		0.215648
  validation accuracy:		93.70 %
Epoch 557 of 2000 took 0.148s
  training loss:		0.060600
  validation loss:		0.212644
  validation accuracy:		93.91 %
Epoch 558 of 2000 took 0.149s
  training loss:		0.059518
  validation loss:		0.218551
  validation accuracy:		93.91 %
Epoch 559 of 2000 took 0.142s
  training loss:		0.061929
  validation loss:		0.213501
  validation accuracy:		94.02 %
Epoch 560 of 2000 took 0.139s
  training loss:		0.059430
  validation loss:		0.221176
  validation accuracy:		93.70 %
Epoch 561 of 2000 took 0.142s
  training loss:		0.057820
  validation loss:		0.217159
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.146s
  training loss:		0.059739
  validation loss:		0.212452
  validation accuracy:		94.13 %
Epoch 563 of 2000 took 0.141s
  training loss:		0.059214
  validation loss:		0.203456
  validation accuracy:		93.91 %
Epoch 564 of 2000 took 0.140s
  training loss:		0.062753
  validation loss:		0.213516
  validation accuracy:		94.13 %
Epoch 565 of 2000 took 0.144s
  training loss:		0.059906
  validation loss:		0.218522
  validation accuracy:		94.02 %
Epoch 566 of 2000 took 0.143s
  training loss:		0.059147
  validation loss:		0.213602
  validation accuracy:		94.46 %
Epoch 567 of 2000 took 0.140s
  training loss:		0.059959
  validation loss:		0.224222
  validation accuracy:		93.70 %
Epoch 568 of 2000 took 0.150s
  training loss:		0.060540
  validation loss:		0.213383
  validation accuracy:		94.13 %
Epoch 569 of 2000 took 0.142s
  training loss:		0.059108
  validation loss:		0.220877
  validation accuracy:		93.70 %
Epoch 570 of 2000 took 0.138s
  training loss:		0.057693
  validation loss:		0.226218
  validation accuracy:		93.37 %
Epoch 571 of 2000 took 0.148s
  training loss:		0.057343
  validation loss:		0.217468
  validation accuracy:		94.13 %
Epoch 572 of 2000 took 0.147s
  training loss:		0.059924
  validation loss:		0.209493
  validation accuracy:		94.13 %
Epoch 573 of 2000 took 0.150s
  training loss:		0.058046
  validation loss:		0.229176
  validation accuracy:		93.59 %
Epoch 574 of 2000 took 0.150s
  training loss:		0.058592
  validation loss:		0.218820
  validation accuracy:		93.70 %
Epoch 575 of 2000 took 0.144s
  training loss:		0.058752
  validation loss:		0.222289
  validation accuracy:		93.70 %
Epoch 576 of 2000 took 0.145s
  training loss:		0.061424
  validation loss:		0.216027
  validation accuracy:		93.59 %
Epoch 577 of 2000 took 0.147s
  training loss:		0.059882
  validation loss:		0.217145
  validation accuracy:		94.13 %
Epoch 578 of 2000 took 0.145s
  training loss:		0.058838
  validation loss:		0.219496
  validation accuracy:		93.91 %
Epoch 579 of 2000 took 0.142s
  training loss:		0.057907
  validation loss:		0.221852
  validation accuracy:		93.70 %
Epoch 580 of 2000 took 0.146s
  training loss:		0.057938
  validation loss:		0.226158
  validation accuracy:		94.02 %
Epoch 581 of 2000 took 0.138s
  training loss:		0.057242
  validation loss:		0.216275
  validation accuracy:		94.02 %
Epoch 582 of 2000 took 0.143s
  training loss:		0.057396
  validation loss:		0.222261
  validation accuracy:		93.48 %
Epoch 583 of 2000 took 0.141s
  training loss:		0.057980
  validation loss:		0.214105
  validation accuracy:		94.35 %
Epoch 584 of 2000 took 0.146s
  training loss:		0.058175
  validation loss:		0.215140
  validation accuracy:		94.02 %
Epoch 585 of 2000 took 0.143s
  training loss:		0.057498
  validation loss:		0.223522
  validation accuracy:		93.91 %
Epoch 586 of 2000 took 0.143s
  training loss:		0.058208
  validation loss:		0.220226
  validation accuracy:		93.91 %
Epoch 587 of 2000 took 0.174s
  training loss:		0.055705
  validation loss:		0.232868
  validation accuracy:		93.91 %
Epoch 588 of 2000 took 0.149s
  training loss:		0.054690
  validation loss:		0.217401
  validation accuracy:		93.91 %
Epoch 589 of 2000 took 0.143s
  training loss:		0.055248
  validation loss:		0.220424
  validation accuracy:		93.91 %
Epoch 590 of 2000 took 0.144s
  training loss:		0.053868
  validation loss:		0.224912
  validation accuracy:		93.91 %
Epoch 591 of 2000 took 0.140s
  training loss:		0.056825
  validation loss:		0.214681
  validation accuracy:		93.91 %
Epoch 592 of 2000 took 0.143s
  training loss:		0.056466
  validation loss:		0.234276
  validation accuracy:		93.48 %
Epoch 593 of 2000 took 0.138s
  training loss:		0.057128
  validation loss:		0.220750
  validation accuracy:		93.70 %
Epoch 594 of 2000 took 0.147s
  training loss:		0.057785
  validation loss:		0.221794
  validation accuracy:		94.13 %
Epoch 595 of 2000 took 0.161s
  training loss:		0.055932
  validation loss:		0.221527
  validation accuracy:		93.80 %
Epoch 596 of 2000 took 0.146s
  training loss:		0.056627
  validation loss:		0.227424
  validation accuracy:		93.70 %
Epoch 597 of 2000 took 0.146s
  training loss:		0.055508
  validation loss:		0.221755
  validation accuracy:		94.13 %
Epoch 598 of 2000 took 0.139s
  training loss:		0.056392
  validation loss:		0.224751
  validation accuracy:		94.35 %
Epoch 599 of 2000 took 0.140s
  training loss:		0.055860
  validation loss:		0.230166
  validation accuracy:		93.70 %
Epoch 600 of 2000 took 0.149s
  training loss:		0.055960
  validation loss:		0.234750
  validation accuracy:		93.59 %
Epoch 601 of 2000 took 0.149s
  training loss:		0.055670
  validation loss:		0.225051
  validation accuracy:		93.91 %
Epoch 602 of 2000 took 0.145s
  training loss:		0.052387
  validation loss:		0.225413
  validation accuracy:		93.80 %
Epoch 603 of 2000 took 0.145s
  training loss:		0.056297
  validation loss:		0.219880
  validation accuracy:		93.80 %
Epoch 604 of 2000 took 0.143s
  training loss:		0.054596
  validation loss:		0.220288
  validation accuracy:		94.13 %
Epoch 605 of 2000 took 0.148s
  training loss:		0.053961
  validation loss:		0.230732
  validation accuracy:		93.70 %
Epoch 606 of 2000 took 0.145s
  training loss:		0.054791
  validation loss:		0.228188
  validation accuracy:		93.91 %
Epoch 607 of 2000 took 0.138s
  training loss:		0.054403
  validation loss:		0.222410
  validation accuracy:		93.80 %
Epoch 608 of 2000 took 0.144s
  training loss:		0.054171
  validation loss:		0.233155
  validation accuracy:		93.59 %
Epoch 609 of 2000 took 0.142s
  training loss:		0.053652
  validation loss:		0.228545
  validation accuracy:		94.02 %
Epoch 610 of 2000 took 0.142s
  training loss:		0.052116
  validation loss:		0.228857
  validation accuracy:		94.13 %
Epoch 611 of 2000 took 0.161s
  training loss:		0.052122
  validation loss:		0.222577
  validation accuracy:		94.13 %
Epoch 612 of 2000 took 0.161s
  training loss:		0.054991
  validation loss:		0.235803
  validation accuracy:		93.48 %
Epoch 613 of 2000 took 0.174s
  training loss:		0.053713
  validation loss:		0.229555
  validation accuracy:		93.59 %
Epoch 614 of 2000 took 0.141s
  training loss:		0.055717
  validation loss:		0.230296
  validation accuracy:		94.13 %
Epoch 615 of 2000 took 0.156s
  training loss:		0.053815
  validation loss:		0.218746
  validation accuracy:		94.02 %
Epoch 616 of 2000 took 0.134s
  training loss:		0.054028
  validation loss:		0.230404
  validation accuracy:		93.91 %
Epoch 617 of 2000 took 0.141s
  training loss:		0.054057
  validation loss:		0.230848
  validation accuracy:		93.80 %
Epoch 618 of 2000 took 0.135s
  training loss:		0.052660
  validation loss:		0.225175
  validation accuracy:		93.80 %
Epoch 619 of 2000 took 0.141s
  training loss:		0.055204
  validation loss:		0.231359
  validation accuracy:		93.80 %
Epoch 620 of 2000 took 0.143s
  training loss:		0.053181
  validation loss:		0.228062
  validation accuracy:		93.70 %
Epoch 621 of 2000 took 0.148s
  training loss:		0.053918
  validation loss:		0.237507
  validation accuracy:		93.70 %
Epoch 622 of 2000 took 0.143s
  training loss:		0.054577
  validation loss:		0.230736
  validation accuracy:		93.91 %
Epoch 623 of 2000 took 0.139s
  training loss:		0.050517
  validation loss:		0.225603
  validation accuracy:		93.80 %
Epoch 624 of 2000 took 0.139s
  training loss:		0.052544
  validation loss:		0.231131
  validation accuracy:		93.80 %
Epoch 625 of 2000 took 0.166s
  training loss:		0.052880
  validation loss:		0.231901
  validation accuracy:		93.70 %
Epoch 626 of 2000 took 0.138s
  training loss:		0.052292
  validation loss:		0.229612
  validation accuracy:		93.91 %
Epoch 627 of 2000 took 0.150s
  training loss:		0.053001
  validation loss:		0.224387
  validation accuracy:		94.02 %
Epoch 628 of 2000 took 0.142s
  training loss:		0.050896
  validation loss:		0.223155
  validation accuracy:		93.91 %
Epoch 629 of 2000 took 0.140s
  training loss:		0.051055
  validation loss:		0.232281
  validation accuracy:		93.91 %
Epoch 630 of 2000 took 0.145s
  training loss:		0.051923
  validation loss:		0.236074
  validation accuracy:		93.70 %
Epoch 631 of 2000 took 0.139s
  training loss:		0.049655
  validation loss:		0.223850
  validation accuracy:		93.80 %
Epoch 632 of 2000 took 0.139s
  training loss:		0.050181
  validation loss:		0.232564
  validation accuracy:		93.91 %
Epoch 633 of 2000 took 0.143s
  training loss:		0.051469
  validation loss:		0.235270
  validation accuracy:		94.02 %
Epoch 634 of 2000 took 0.144s
  training loss:		0.050029
  validation loss:		0.225026
  validation accuracy:		94.13 %
Epoch 635 of 2000 took 0.148s
  training loss:		0.051085
  validation loss:		0.233912
  validation accuracy:		93.70 %
Epoch 636 of 2000 took 0.145s
  training loss:		0.049087
  validation loss:		0.241189
  validation accuracy:		93.80 %
Epoch 637 of 2000 took 0.138s
  training loss:		0.050143
  validation loss:		0.225046
  validation accuracy:		94.13 %
Epoch 638 of 2000 took 0.137s
  training loss:		0.051547
  validation loss:		0.235463
  validation accuracy:		93.80 %
Epoch 639 of 2000 took 0.135s
  training loss:		0.051327
  validation loss:		0.236580
  validation accuracy:		93.48 %
Epoch 640 of 2000 took 0.142s
  training loss:		0.052737
  validation loss:		0.229101
  validation accuracy:		93.91 %
Epoch 641 of 2000 took 0.141s
  training loss:		0.049780
  validation loss:		0.226692
  validation accuracy:		94.02 %
Epoch 642 of 2000 took 0.144s
  training loss:		0.050118
  validation loss:		0.235432
  validation accuracy:		93.91 %
Epoch 643 of 2000 took 0.143s
  training loss:		0.051074
  validation loss:		0.252791
  validation accuracy:		93.04 %
Epoch 644 of 2000 took 0.138s
  training loss:		0.052852
  validation loss:		0.226260
  validation accuracy:		94.02 %
Epoch 645 of 2000 took 0.137s
  training loss:		0.050058
  validation loss:		0.229133
  validation accuracy:		94.13 %
Epoch 646 of 2000 took 0.145s
  training loss:		0.049591
  validation loss:		0.238694
  validation accuracy:		93.80 %
Epoch 647 of 2000 took 0.132s
  training loss:		0.051020
  validation loss:		0.241872
  validation accuracy:		93.91 %
Epoch 648 of 2000 took 0.146s
  training loss:		0.051799
  validation loss:		0.243032
  validation accuracy:		93.91 %
Epoch 649 of 2000 took 0.143s
  training loss:		0.047002
  validation loss:		0.231527
  validation accuracy:		93.80 %
Epoch 650 of 2000 took 0.144s
  training loss:		0.049799
  validation loss:		0.240093
  validation accuracy:		93.70 %
Epoch 651 of 2000 took 0.153s
  training loss:		0.050750
  validation loss:		0.230914
  validation accuracy:		93.80 %
Epoch 652 of 2000 took 0.176s
  training loss:		0.047853
  validation loss:		0.241641
  validation accuracy:		94.02 %
Epoch 653 of 2000 took 0.143s
  training loss:		0.048695
  validation loss:		0.238627
  validation accuracy:		93.91 %
Epoch 654 of 2000 took 0.149s
  training loss:		0.047759
  validation loss:		0.237759
  validation accuracy:		94.02 %
Epoch 655 of 2000 took 0.147s
  training loss:		0.048375
  validation loss:		0.231227
  validation accuracy:		94.13 %
Epoch 656 of 2000 took 0.146s
  training loss:		0.047908
  validation loss:		0.236455
  validation accuracy:		94.13 %
Epoch 657 of 2000 took 0.149s
  training loss:		0.048623
  validation loss:		0.234442
  validation accuracy:		94.02 %
Epoch 658 of 2000 took 0.151s
  training loss:		0.047079
  validation loss:		0.240291
  validation accuracy:		93.91 %
Epoch 659 of 2000 took 0.142s
  training loss:		0.046764
  validation loss:		0.230700
  validation accuracy:		94.13 %
Epoch 660 of 2000 took 0.150s
  training loss:		0.045909
  validation loss:		0.228391
  validation accuracy:		93.80 %
Epoch 661 of 2000 took 0.148s
  training loss:		0.045471
  validation loss:		0.229520
  validation accuracy:		93.91 %
Epoch 662 of 2000 took 0.143s
  training loss:		0.047909
  validation loss:		0.242483
  validation accuracy:		94.02 %
Epoch 663 of 2000 took 0.146s
  training loss:		0.049483
  validation loss:		0.240366
  validation accuracy:		94.02 %
Epoch 664 of 2000 took 0.138s
  training loss:		0.046097
  validation loss:		0.240429
  validation accuracy:		93.59 %
Epoch 665 of 2000 took 0.135s
  training loss:		0.049092
  validation loss:		0.234809
  validation accuracy:		94.02 %
Epoch 666 of 2000 took 0.152s
  training loss:		0.046486
  validation loss:		0.233487
  validation accuracy:		94.02 %
Epoch 667 of 2000 took 0.151s
  training loss:		0.047943
  validation loss:		0.233525
  validation accuracy:		93.80 %
Epoch 668 of 2000 took 0.144s
  training loss:		0.046016
  validation loss:		0.248669
  validation accuracy:		93.48 %
Epoch 669 of 2000 took 0.151s
  training loss:		0.046818
  validation loss:		0.240771
  validation accuracy:		94.02 %
Epoch 670 of 2000 took 0.187s
  training loss:		0.048131
  validation loss:		0.245006
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.172s
  training loss:		0.049434
  validation loss:		0.253207
  validation accuracy:		93.80 %
Epoch 672 of 2000 took 0.152s
  training loss:		0.047333
  validation loss:		0.239538
  validation accuracy:		94.02 %
Epoch 673 of 2000 took 0.158s
  training loss:		0.045723
  validation loss:		0.239868
  validation accuracy:		93.91 %
Epoch 674 of 2000 took 0.154s
  training loss:		0.046506
  validation loss:		0.235790
  validation accuracy:		94.35 %
Epoch 675 of 2000 took 0.148s
  training loss:		0.044524
  validation loss:		0.237421
  validation accuracy:		93.91 %
Epoch 676 of 2000 took 0.172s
  training loss:		0.045370
  validation loss:		0.238287
  validation accuracy:		93.91 %
Epoch 677 of 2000 took 0.177s
  training loss:		0.044714
  validation loss:		0.241572
  validation accuracy:		93.37 %
Epoch 678 of 2000 took 0.170s
  training loss:		0.044410
  validation loss:		0.243357
  validation accuracy:		94.02 %
Epoch 679 of 2000 took 0.144s
  training loss:		0.046700
  validation loss:		0.252806
  validation accuracy:		93.70 %
Epoch 680 of 2000 took 0.146s
  training loss:		0.045348
  validation loss:		0.251777
  validation accuracy:		93.59 %
Epoch 681 of 2000 took 0.144s
  training loss:		0.047175
  validation loss:		0.246774
  validation accuracy:		93.70 %
Epoch 682 of 2000 took 0.152s
  training loss:		0.046616
  validation loss:		0.246163
  validation accuracy:		93.48 %
Epoch 683 of 2000 took 0.145s
  training loss:		0.045157
  validation loss:		0.238248
  validation accuracy:		94.02 %
Epoch 684 of 2000 took 0.147s
  training loss:		0.045529
  validation loss:		0.245672
  validation accuracy:		93.80 %
Epoch 685 of 2000 took 0.146s
  training loss:		0.043548
  validation loss:		0.241605
  validation accuracy:		94.02 %
Epoch 686 of 2000 took 0.141s
  training loss:		0.045320
  validation loss:		0.243072
  validation accuracy:		94.02 %
Epoch 687 of 2000 took 0.152s
  training loss:		0.043070
  validation loss:		0.246978
  validation accuracy:		94.02 %
Epoch 688 of 2000 took 0.149s
  training loss:		0.045158
  validation loss:		0.238854
  validation accuracy:		94.02 %
Epoch 689 of 2000 took 0.162s
  training loss:		0.043579
  validation loss:		0.249001
  validation accuracy:		93.91 %
Epoch 690 of 2000 took 0.139s
  training loss:		0.045604
  validation loss:		0.239017
  validation accuracy:		93.80 %
Epoch 691 of 2000 took 0.157s
  training loss:		0.046234
  validation loss:		0.242284
  validation accuracy:		93.70 %
Epoch 692 of 2000 took 0.148s
  training loss:		0.045647
  validation loss:		0.243257
  validation accuracy:		94.13 %
Epoch 693 of 2000 took 0.147s
  training loss:		0.045196
  validation loss:		0.246991
  validation accuracy:		93.91 %
Epoch 694 of 2000 took 0.147s
  training loss:		0.042685
  validation loss:		0.251813
  validation accuracy:		93.91 %
Epoch 695 of 2000 took 0.165s
  training loss:		0.046122
  validation loss:		0.251400
  validation accuracy:		94.02 %
Epoch 696 of 2000 took 0.164s
  training loss:		0.045378
  validation loss:		0.253023
  validation accuracy:		93.91 %
Epoch 697 of 2000 took 0.197s
  training loss:		0.045153
  validation loss:		0.246580
  validation accuracy:		93.91 %
Epoch 698 of 2000 took 0.154s
  training loss:		0.045625
  validation loss:		0.247858
  validation accuracy:		93.80 %
Epoch 699 of 2000 took 0.160s
  training loss:		0.044824
  validation loss:		0.241527
  validation accuracy:		93.91 %
Epoch 700 of 2000 took 0.152s
  training loss:		0.044563
  validation loss:		0.247953
  validation accuracy:		93.70 %
Epoch 701 of 2000 took 0.163s
  training loss:		0.043862
  validation loss:		0.250142
  validation accuracy:		93.80 %
Epoch 702 of 2000 took 0.172s
  training loss:		0.042401
  validation loss:		0.244987
  validation accuracy:		94.13 %
Epoch 703 of 2000 took 0.160s
  training loss:		0.043133
  validation loss:		0.249751
  validation accuracy:		93.80 %
Epoch 704 of 2000 took 0.173s
  training loss:		0.044561
  validation loss:		0.256736
  validation accuracy:		93.59 %
Epoch 705 of 2000 took 0.171s
  training loss:		0.042200
  validation loss:		0.251608
  validation accuracy:		93.59 %
Epoch 706 of 2000 took 0.141s
  training loss:		0.042781
  validation loss:		0.243147
  validation accuracy:		94.02 %
Epoch 707 of 2000 took 0.151s
  training loss:		0.043576
  validation loss:		0.243604
  validation accuracy:		94.02 %
Epoch 708 of 2000 took 0.151s
  training loss:		0.042876
  validation loss:		0.249459
  validation accuracy:		93.80 %
Epoch 709 of 2000 took 0.151s
  training loss:		0.044160
  validation loss:		0.255510
  validation accuracy:		93.91 %
Epoch 710 of 2000 took 0.149s
  training loss:		0.040984
  validation loss:		0.249227
  validation accuracy:		94.13 %
Epoch 711 of 2000 took 0.186s
  training loss:		0.042842
  validation loss:		0.244932
  validation accuracy:		94.24 %
Epoch 712 of 2000 took 0.161s
  training loss:		0.042358
  validation loss:		0.248027
  validation accuracy:		94.02 %
Epoch 713 of 2000 took 0.154s
  training loss:		0.042604
  validation loss:		0.259934
  validation accuracy:		93.37 %
Epoch 714 of 2000 took 0.151s
  training loss:		0.043245
  validation loss:		0.251069
  validation accuracy:		93.70 %
Epoch 715 of 2000 took 0.146s
  training loss:		0.041657
  validation loss:		0.247099
  validation accuracy:		93.80 %
Epoch 716 of 2000 took 0.180s
  training loss:		0.041696
  validation loss:		0.247931
  validation accuracy:		93.80 %
Epoch 717 of 2000 took 0.157s
  training loss:		0.043350
  validation loss:		0.247241
  validation accuracy:		93.91 %
Epoch 718 of 2000 took 0.151s
  training loss:		0.040889
  validation loss:		0.251816
  validation accuracy:		93.70 %
Epoch 719 of 2000 took 0.176s
  training loss:		0.041658
  validation loss:		0.251093
  validation accuracy:		94.02 %
Epoch 720 of 2000 took 0.153s
  training loss:		0.042132
  validation loss:		0.249769
  validation accuracy:		93.80 %
Epoch 721 of 2000 took 0.164s
  training loss:		0.041970
  validation loss:		0.255028
  validation accuracy:		93.80 %
Epoch 722 of 2000 took 0.164s
  training loss:		0.041530
  validation loss:		0.251967
  validation accuracy:		94.02 %
Epoch 723 of 2000 took 0.151s
  training loss:		0.043222
  validation loss:		0.260863
  validation accuracy:		93.59 %
Epoch 724 of 2000 took 0.152s
  training loss:		0.042823
  validation loss:		0.238561
  validation accuracy:		93.80 %
Epoch 725 of 2000 took 0.143s
  training loss:		0.043324
  validation loss:		0.256118
  validation accuracy:		93.70 %
Epoch 726 of 2000 took 0.161s
  training loss:		0.042003
  validation loss:		0.251999
  validation accuracy:		93.59 %
Epoch 727 of 2000 took 0.151s
  training loss:		0.041230
  validation loss:		0.245885
  validation accuracy:		93.80 %
Epoch 728 of 2000 took 0.169s
  training loss:		0.042046
  validation loss:		0.244149
  validation accuracy:		93.80 %
Epoch 729 of 2000 took 0.170s
  training loss:		0.041070
  validation loss:		0.260336
  validation accuracy:		93.91 %
Epoch 730 of 2000 took 0.149s
  training loss:		0.039877
  validation loss:		0.249500
  validation accuracy:		93.91 %
Epoch 731 of 2000 took 0.150s
  training loss:		0.041810
  validation loss:		0.253136
  validation accuracy:		93.80 %
Epoch 732 of 2000 took 0.152s
  training loss:		0.040697
  validation loss:		0.246987
  validation accuracy:		93.91 %
Epoch 733 of 2000 took 0.156s
  training loss:		0.040473
  validation loss:		0.253987
  validation accuracy:		93.80 %
Epoch 734 of 2000 took 0.148s
  training loss:		0.040966
  validation loss:		0.254066
  validation accuracy:		94.13 %
Epoch 735 of 2000 took 0.160s
  training loss:		0.039469
  validation loss:		0.249065
  validation accuracy:		93.91 %
Epoch 736 of 2000 took 0.171s
  training loss:		0.039787
  validation loss:		0.251665
  validation accuracy:		94.24 %
Epoch 737 of 2000 took 0.165s
  training loss:		0.041101
  validation loss:		0.249852
  validation accuracy:		93.91 %
Epoch 738 of 2000 took 0.146s
  training loss:		0.040466
  validation loss:		0.249137
  validation accuracy:		94.02 %
Epoch 739 of 2000 took 0.152s
  training loss:		0.039460
  validation loss:		0.259177
  validation accuracy:		94.13 %
Epoch 740 of 2000 took 0.146s
  training loss:		0.038856
  validation loss:		0.254642
  validation accuracy:		94.02 %
Epoch 741 of 2000 took 0.156s
  training loss:		0.040533
  validation loss:		0.258524
  validation accuracy:		93.80 %
Epoch 742 of 2000 took 0.151s
  training loss:		0.041305
  validation loss:		0.250832
  validation accuracy:		93.91 %
Epoch 743 of 2000 took 0.155s
  training loss:		0.039200
  validation loss:		0.254574
  validation accuracy:		93.91 %
Epoch 744 of 2000 took 0.143s
  training loss:		0.040167
  validation loss:		0.251164
  validation accuracy:		93.91 %
Epoch 745 of 2000 took 0.148s
  training loss:		0.039860
  validation loss:		0.246652
  validation accuracy:		93.91 %
Epoch 746 of 2000 took 0.160s
  training loss:		0.038390
  validation loss:		0.254154
  validation accuracy:		93.91 %
Epoch 747 of 2000 took 0.146s
  training loss:		0.039918
  validation loss:		0.265693
  validation accuracy:		93.70 %
Epoch 748 of 2000 took 0.149s
  training loss:		0.039187
  validation loss:		0.249358
  validation accuracy:		94.35 %
Epoch 749 of 2000 took 0.146s
  training loss:		0.039116
  validation loss:		0.260282
  validation accuracy:		93.91 %
Epoch 750 of 2000 took 0.146s
  training loss:		0.038571
  validation loss:		0.262667
  validation accuracy:		94.02 %
Epoch 751 of 2000 took 0.153s
  training loss:		0.038402
  validation loss:		0.265806
  validation accuracy:		93.70 %
Epoch 752 of 2000 took 0.151s
  training loss:		0.040768
  validation loss:		0.256962
  validation accuracy:		93.80 %
Epoch 753 of 2000 took 0.149s
  training loss:		0.038111
  validation loss:		0.262125
  validation accuracy:		93.91 %
Epoch 754 of 2000 took 0.149s
  training loss:		0.039404
  validation loss:		0.271452
  validation accuracy:		93.91 %
Epoch 755 of 2000 took 0.148s
  training loss:		0.037964
  validation loss:		0.261020
  validation accuracy:		94.02 %
Epoch 756 of 2000 took 0.143s
  training loss:		0.038449
  validation loss:		0.254226
  validation accuracy:		94.02 %
Epoch 757 of 2000 took 0.146s
  training loss:		0.038707
  validation loss:		0.256904
  validation accuracy:		93.91 %
Epoch 758 of 2000 took 0.151s
  training loss:		0.040500
  validation loss:		0.262933
  validation accuracy:		93.91 %
Epoch 759 of 2000 took 0.153s
  training loss:		0.038976
  validation loss:		0.259067
  validation accuracy:		93.91 %
Epoch 760 of 2000 took 0.153s
  training loss:		0.040121
  validation loss:		0.262930
  validation accuracy:		93.80 %
Epoch 761 of 2000 took 0.151s
  training loss:		0.037932
  validation loss:		0.260324
  validation accuracy:		93.91 %
Epoch 762 of 2000 took 0.146s
  training loss:		0.037958
  validation loss:		0.268329
  validation accuracy:		93.70 %
Epoch 763 of 2000 took 0.149s
  training loss:		0.038707
  validation loss:		0.265514
  validation accuracy:		93.80 %
Epoch 764 of 2000 took 0.144s
  training loss:		0.038630
  validation loss:		0.258192
  validation accuracy:		94.02 %
Epoch 765 of 2000 took 0.150s
  training loss:		0.036739
  validation loss:		0.267827
  validation accuracy:		93.91 %
Epoch 766 of 2000 took 0.148s
  training loss:		0.036420
  validation loss:		0.259462
  validation accuracy:		94.02 %
Epoch 767 of 2000 took 0.153s
  training loss:		0.037239
  validation loss:		0.261832
  validation accuracy:		93.91 %
Epoch 768 of 2000 took 0.152s
  training loss:		0.038288
  validation loss:		0.251385
  validation accuracy:		94.13 %
Epoch 769 of 2000 took 0.146s
  training loss:		0.038245
  validation loss:		0.262074
  validation accuracy:		93.91 %
Epoch 770 of 2000 took 0.148s
  training loss:		0.038597
  validation loss:		0.265144
  validation accuracy:		93.80 %
Epoch 771 of 2000 took 0.147s
  training loss:		0.036349
  validation loss:		0.255206
  validation accuracy:		93.91 %
Epoch 772 of 2000 took 0.151s
  training loss:		0.037113
  validation loss:		0.259261
  validation accuracy:		93.80 %
Epoch 773 of 2000 took 0.144s
  training loss:		0.036110
  validation loss:		0.258641
  validation accuracy:		94.02 %
Epoch 774 of 2000 took 0.152s
  training loss:		0.036157
  validation loss:		0.257616
  validation accuracy:		93.91 %
Epoch 775 of 2000 took 0.179s
  training loss:		0.038467
  validation loss:		0.266799
  validation accuracy:		94.02 %
Epoch 776 of 2000 took 0.170s
  training loss:		0.035777
  validation loss:		0.261387
  validation accuracy:		94.02 %
Epoch 777 of 2000 took 0.141s
  training loss:		0.035584
  validation loss:		0.256682
  validation accuracy:		93.91 %
Epoch 778 of 2000 took 0.150s
  training loss:		0.035861
  validation loss:		0.269715
  validation accuracy:		93.91 %
Epoch 779 of 2000 took 0.150s
  training loss:		0.037581
  validation loss:		0.260982
  validation accuracy:		93.80 %
Epoch 780 of 2000 took 0.155s
  training loss:		0.037287
  validation loss:		0.263764
  validation accuracy:		94.02 %
Epoch 781 of 2000 took 0.154s
  training loss:		0.037454
  validation loss:		0.265770
  validation accuracy:		93.91 %
Epoch 782 of 2000 took 0.147s
  training loss:		0.037032
  validation loss:		0.259159
  validation accuracy:		93.91 %
Epoch 783 of 2000 took 0.153s
  training loss:		0.036231
  validation loss:		0.262961
  validation accuracy:		94.13 %
Epoch 784 of 2000 took 0.151s
  training loss:		0.036405
  validation loss:		0.276137
  validation accuracy:		93.91 %
Epoch 785 of 2000 took 0.157s
  training loss:		0.037894
  validation loss:		0.264562
  validation accuracy:		93.80 %
Epoch 786 of 2000 took 0.152s
  training loss:		0.036853
  validation loss:		0.270036
  validation accuracy:		94.02 %
Epoch 787 of 2000 took 0.147s
  training loss:		0.035015
  validation loss:		0.268176
  validation accuracy:		93.80 %
Epoch 788 of 2000 took 0.179s
  training loss:		0.036054
  validation loss:		0.266096
  validation accuracy:		93.91 %
Epoch 789 of 2000 took 0.148s
  training loss:		0.034232
  validation loss:		0.272595
  validation accuracy:		93.70 %
Epoch 790 of 2000 took 0.153s
  training loss:		0.035288
  validation loss:		0.272608
  validation accuracy:		93.80 %
Epoch 791 of 2000 took 0.163s
  training loss:		0.035690
  validation loss:		0.268423
  validation accuracy:		94.02 %
Epoch 792 of 2000 took 0.152s
  training loss:		0.034295
  validation loss:		0.264721
  validation accuracy:		93.80 %
Epoch 793 of 2000 took 0.153s
  training loss:		0.035873
  validation loss:		0.270524
  validation accuracy:		93.59 %
Epoch 794 of 2000 took 0.148s
  training loss:		0.035003
  validation loss:		0.267178
  validation accuracy:		94.02 %
Epoch 795 of 2000 took 0.142s
  training loss:		0.034219
  validation loss:		0.260204
  validation accuracy:		93.91 %
Epoch 796 of 2000 took 0.149s
  training loss:		0.034019
  validation loss:		0.265928
  validation accuracy:		93.91 %
Epoch 797 of 2000 took 0.146s
  training loss:		0.036293
  validation loss:		0.270023
  validation accuracy:		93.80 %
Epoch 798 of 2000 took 0.144s
  training loss:		0.037331
  validation loss:		0.267298
  validation accuracy:		93.80 %
Epoch 799 of 2000 took 0.145s
  training loss:		0.035810
  validation loss:		0.261710
  validation accuracy:		93.80 %
Epoch 800 of 2000 took 0.153s
  training loss:		0.035217
  validation loss:		0.270408
  validation accuracy:		93.80 %
Epoch 801 of 2000 took 0.171s
  training loss:		0.034201
  validation loss:		0.259821
  validation accuracy:		94.02 %
Epoch 802 of 2000 took 0.142s
  training loss:		0.035347
  validation loss:		0.268289
  validation accuracy:		93.70 %
Epoch 803 of 2000 took 0.154s
  training loss:		0.032696
  validation loss:		0.263589
  validation accuracy:		94.13 %
Epoch 804 of 2000 took 0.201s
  training loss:		0.034959
  validation loss:		0.272222
  validation accuracy:		93.91 %
Epoch 805 of 2000 took 0.147s
  training loss:		0.033810
  validation loss:		0.274885
  validation accuracy:		93.91 %
Epoch 806 of 2000 took 0.160s
  training loss:		0.036119
  validation loss:		0.267863
  validation accuracy:		93.91 %
Epoch 807 of 2000 took 0.173s
  training loss:		0.034919
  validation loss:		0.278979
  validation accuracy:		94.02 %
Epoch 808 of 2000 took 0.158s
  training loss:		0.033581
  validation loss:		0.265861
  validation accuracy:		93.80 %
Epoch 809 of 2000 took 0.162s
  training loss:		0.033619
  validation loss:		0.267316
  validation accuracy:		94.02 %
Epoch 810 of 2000 took 0.152s
  training loss:		0.031804
  validation loss:		0.273296
  validation accuracy:		93.91 %
Epoch 811 of 2000 took 0.142s
  training loss:		0.032349
  validation loss:		0.266489
  validation accuracy:		94.13 %
Epoch 812 of 2000 took 0.199s
  training loss:		0.034594
  validation loss:		0.277347
  validation accuracy:		94.02 %
Epoch 813 of 2000 took 0.169s
  training loss:		0.034330
  validation loss:		0.271424
  validation accuracy:		94.13 %
Epoch 814 of 2000 took 0.186s
  training loss:		0.033876
  validation loss:		0.279242
  validation accuracy:		94.02 %
Epoch 815 of 2000 took 0.161s
  training loss:		0.034004
  validation loss:		0.278186
  validation accuracy:		93.70 %
Epoch 816 of 2000 took 0.170s
  training loss:		0.034071
  validation loss:		0.278156
  validation accuracy:		93.70 %
Epoch 817 of 2000 took 0.187s
  training loss:		0.032670
  validation loss:		0.276806
  validation accuracy:		94.02 %
Epoch 818 of 2000 took 0.162s
  training loss:		0.034385
  validation loss:		0.272121
  validation accuracy:		93.80 %
Epoch 819 of 2000 took 0.185s
  training loss:		0.030113
  validation loss:		0.266513
  validation accuracy:		93.91 %
Epoch 820 of 2000 took 0.172s
  training loss:		0.033480
  validation loss:		0.278929
  validation accuracy:		93.70 %
Epoch 821 of 2000 took 0.159s
  training loss:		0.032973
  validation loss:		0.282015
  validation accuracy:		93.70 %
Epoch 822 of 2000 took 0.151s
  training loss:		0.033150
  validation loss:		0.279809
  validation accuracy:		94.02 %
Epoch 823 of 2000 took 0.147s
  training loss:		0.033658
  validation loss:		0.268386
  validation accuracy:		93.80 %
Epoch 824 of 2000 took 0.151s
  training loss:		0.032014
  validation loss:		0.270851
  validation accuracy:		94.02 %
Epoch 825 of 2000 took 0.160s
  training loss:		0.031930
  validation loss:		0.274091
  validation accuracy:		94.02 %
Epoch 826 of 2000 took 0.143s
  training loss:		0.032993
  validation loss:		0.267278
  validation accuracy:		94.02 %
Epoch 827 of 2000 took 0.166s
  training loss:		0.032196
  validation loss:		0.277174
  validation accuracy:		94.02 %
Epoch 828 of 2000 took 0.163s
  training loss:		0.033779
  validation loss:		0.276364
  validation accuracy:		93.91 %
Epoch 829 of 2000 took 0.149s
  training loss:		0.033624
  validation loss:		0.282750
  validation accuracy:		93.70 %
Epoch 830 of 2000 took 0.172s
  training loss:		0.032285
  validation loss:		0.277801
  validation accuracy:		93.70 %
Epoch 831 of 2000 took 0.146s
  training loss:		0.032432
  validation loss:		0.284332
  validation accuracy:		94.02 %
Epoch 832 of 2000 took 0.144s
  training loss:		0.032533
  validation loss:		0.276773
  validation accuracy:		94.13 %
Epoch 833 of 2000 took 0.165s
  training loss:		0.032397
  validation loss:		0.282655
  validation accuracy:		93.80 %
Epoch 834 of 2000 took 0.177s
  training loss:		0.033480
  validation loss:		0.279907
  validation accuracy:		93.91 %
Epoch 835 of 2000 took 0.157s
  training loss:		0.031690
  validation loss:		0.288673
  validation accuracy:		93.59 %
Epoch 836 of 2000 took 0.175s
  training loss:		0.032797
  validation loss:		0.280457
  validation accuracy:		93.80 %
Epoch 837 of 2000 took 0.149s
  training loss:		0.033962
  validation loss:		0.266494
  validation accuracy:		93.91 %
Epoch 838 of 2000 took 0.146s
  training loss:		0.032237
  validation loss:		0.274106
  validation accuracy:		94.02 %
Epoch 839 of 2000 took 0.149s
  training loss:		0.033167
  validation loss:		0.271698
  validation accuracy:		94.13 %
Epoch 840 of 2000 took 0.179s
  training loss:		0.032529
  validation loss:		0.277690
  validation accuracy:		93.91 %
Epoch 841 of 2000 took 0.152s
  training loss:		0.031988
  validation loss:		0.287023
  validation accuracy:		94.13 %
Epoch 842 of 2000 took 0.144s
  training loss:		0.031150
  validation loss:		0.274082
  validation accuracy:		93.80 %
Epoch 843 of 2000 took 0.143s
  training loss:		0.031116
  validation loss:		0.280805
  validation accuracy:		93.91 %
Epoch 844 of 2000 took 0.140s
  training loss:		0.031468
  validation loss:		0.276646
  validation accuracy:		94.02 %
Epoch 845 of 2000 took 0.145s
  training loss:		0.031893
  validation loss:		0.284437
  validation accuracy:		93.91 %
Epoch 846 of 2000 took 0.143s
  training loss:		0.030763
  validation loss:		0.279384
  validation accuracy:		94.02 %
Epoch 847 of 2000 took 0.145s
  training loss:		0.032141
  validation loss:		0.274522
  validation accuracy:		94.02 %
Epoch 848 of 2000 took 0.148s
  training loss:		0.030759
  validation loss:		0.283589
  validation accuracy:		94.02 %
Epoch 849 of 2000 took 0.145s
  training loss:		0.031794
  validation loss:		0.286061
  validation accuracy:		93.70 %
Epoch 850 of 2000 took 0.156s
  training loss:		0.030228
  validation loss:		0.279548
  validation accuracy:		93.80 %
Epoch 851 of 2000 took 0.146s
  training loss:		0.031858
  validation loss:		0.277632
  validation accuracy:		94.24 %
Epoch 852 of 2000 took 0.142s
  training loss:		0.031350
  validation loss:		0.283909
  validation accuracy:		94.02 %
Epoch 853 of 2000 took 0.176s
  training loss:		0.029615
  validation loss:		0.270706
  validation accuracy:		94.24 %
Epoch 854 of 2000 took 0.147s
  training loss:		0.031975
  validation loss:		0.279146
  validation accuracy:		93.91 %
Epoch 855 of 2000 took 0.182s
  training loss:		0.029034
  validation loss:		0.277877
  validation accuracy:		94.13 %
Epoch 856 of 2000 took 0.184s
  training loss:		0.029955
  validation loss:		0.286877
  validation accuracy:		93.91 %
Epoch 857 of 2000 took 0.147s
  training loss:		0.030972
  validation loss:		0.279119
  validation accuracy:		93.91 %
Epoch 858 of 2000 took 0.155s
  training loss:		0.030283
  validation loss:		0.282327
  validation accuracy:		94.13 %
Epoch 859 of 2000 took 0.145s
  training loss:		0.030249
  validation loss:		0.291959
  validation accuracy:		94.02 %
Epoch 860 of 2000 took 0.149s
  training loss:		0.030234
  validation loss:		0.278335
  validation accuracy:		94.02 %
Epoch 861 of 2000 took 0.156s
  training loss:		0.029390
  validation loss:		0.284736
  validation accuracy:		93.80 %
Epoch 862 of 2000 took 0.159s
  training loss:		0.030490
  validation loss:		0.278586
  validation accuracy:		94.02 %
Epoch 863 of 2000 took 0.165s
  training loss:		0.029394
  validation loss:		0.280218
  validation accuracy:		93.80 %
Epoch 864 of 2000 took 0.168s
  training loss:		0.030194
  validation loss:		0.284299
  validation accuracy:		94.02 %
Epoch 865 of 2000 took 0.151s
  training loss:		0.030138
  validation loss:		0.286874
  validation accuracy:		94.13 %
Epoch 866 of 2000 took 0.154s
  training loss:		0.029692
  validation loss:		0.279724
  validation accuracy:		94.24 %
Epoch 867 of 2000 took 0.142s
  training loss:		0.029812
  validation loss:		0.286874
  validation accuracy:		93.80 %
Epoch 868 of 2000 took 0.146s
  training loss:		0.030741
  validation loss:		0.283340
  validation accuracy:		94.02 %
Epoch 869 of 2000 took 0.138s
  training loss:		0.028808
  validation loss:		0.285030
  validation accuracy:		93.91 %
Epoch 870 of 2000 took 0.145s
  training loss:		0.030351
  validation loss:		0.285222
  validation accuracy:		93.80 %
Epoch 871 of 2000 took 0.140s
  training loss:		0.029540
  validation loss:		0.289653
  validation accuracy:		94.02 %
Epoch 872 of 2000 took 0.143s
  training loss:		0.029053
  validation loss:		0.282117
  validation accuracy:		94.02 %
Epoch 873 of 2000 took 0.142s
  training loss:		0.029260
  validation loss:		0.275622
  validation accuracy:		93.91 %
Epoch 874 of 2000 took 0.149s
  training loss:		0.028986
  validation loss:		0.284303
  validation accuracy:		93.91 %
Epoch 875 of 2000 took 0.145s
  training loss:		0.028562
  validation loss:		0.285076
  validation accuracy:		93.80 %
Epoch 876 of 2000 took 0.147s
  training loss:		0.029791
  validation loss:		0.281196
  validation accuracy:		93.91 %
Epoch 877 of 2000 took 0.148s
  training loss:		0.028807
  validation loss:		0.283374
  validation accuracy:		93.91 %
Epoch 878 of 2000 took 0.145s
  training loss:		0.028980
  validation loss:		0.285350
  validation accuracy:		93.91 %
Epoch 879 of 2000 took 0.149s
  training loss:		0.028668
  validation loss:		0.287916
  validation accuracy:		93.91 %
Epoch 880 of 2000 took 0.143s
  training loss:		0.029367
  validation loss:		0.282253
  validation accuracy:		93.91 %
Epoch 881 of 2000 took 0.142s
  training loss:		0.028644
  validation loss:		0.302286
  validation accuracy:		93.59 %
Epoch 882 of 2000 took 0.149s
  training loss:		0.029552
  validation loss:		0.274913
  validation accuracy:		94.02 %
Epoch 883 of 2000 took 0.153s
  training loss:		0.029515
  validation loss:		0.288588
  validation accuracy:		93.80 %
Epoch 884 of 2000 took 0.174s
  training loss:		0.028764
  validation loss:		0.282314
  validation accuracy:		94.13 %
Epoch 885 of 2000 took 0.146s
  training loss:		0.027827
  validation loss:		0.289206
  validation accuracy:		94.02 %
Epoch 886 of 2000 took 0.147s
  training loss:		0.029207
  validation loss:		0.292765
  validation accuracy:		94.13 %
Epoch 887 of 2000 took 0.193s
  training loss:		0.028865
  validation loss:		0.284572
  validation accuracy:		94.02 %
Epoch 888 of 2000 took 0.153s
  training loss:		0.029174
  validation loss:		0.296038
  validation accuracy:		94.24 %
Epoch 889 of 2000 took 0.138s
  training loss:		0.028597
  validation loss:		0.284798
  validation accuracy:		94.02 %
Epoch 890 of 2000 took 0.140s
  training loss:		0.027897
  validation loss:		0.296976
  validation accuracy:		94.13 %
Epoch 891 of 2000 took 0.143s
  training loss:		0.027712
  validation loss:		0.286690
  validation accuracy:		94.13 %
Epoch 892 of 2000 took 0.148s
  training loss:		0.028095
  validation loss:		0.283182
  validation accuracy:		94.02 %
Epoch 893 of 2000 took 0.142s
  training loss:		0.028149
  validation loss:		0.289653
  validation accuracy:		93.80 %
Epoch 894 of 2000 took 0.148s
  training loss:		0.027742
  validation loss:		0.283504
  validation accuracy:		93.91 %
Epoch 895 of 2000 took 0.150s
  training loss:		0.030241
  validation loss:		0.294478
  validation accuracy:		94.02 %
Epoch 896 of 2000 took 0.161s
  training loss:		0.027903
  validation loss:		0.286681
  validation accuracy:		93.80 %
Epoch 897 of 2000 took 0.173s
  training loss:		0.027109
  validation loss:		0.289236
  validation accuracy:		94.02 %
Epoch 898 of 2000 took 0.152s
  training loss:		0.027406
  validation loss:		0.295821
  validation accuracy:		93.91 %
Epoch 899 of 2000 took 0.173s
  training loss:		0.027359
  validation loss:		0.281620
  validation accuracy:		93.91 %
Epoch 900 of 2000 took 0.169s
  training loss:		0.027903
  validation loss:		0.288576
  validation accuracy:		94.24 %
Epoch 901 of 2000 took 0.172s
  training loss:		0.027326
  validation loss:		0.290519
  validation accuracy:		93.80 %
Epoch 902 of 2000 took 0.189s
  training loss:		0.027654
  validation loss:		0.291506
  validation accuracy:		93.91 %
Epoch 903 of 2000 took 0.143s
  training loss:		0.026780
  validation loss:		0.294468
  validation accuracy:		93.91 %
Epoch 904 of 2000 took 0.170s
  training loss:		0.027594
  validation loss:		0.291870
  validation accuracy:		93.70 %
Epoch 905 of 2000 took 0.173s
  training loss:		0.027306
  validation loss:		0.288233
  validation accuracy:		94.24 %
Epoch 906 of 2000 took 0.156s
  training loss:		0.027075
  validation loss:		0.294064
  validation accuracy:		94.13 %
Epoch 907 of 2000 took 0.145s
  training loss:		0.026210
  validation loss:		0.290231
  validation accuracy:		94.02 %
Epoch 908 of 2000 took 0.153s
  training loss:		0.026803
  validation loss:		0.291605
  validation accuracy:		94.13 %
Epoch 909 of 2000 took 0.136s
  training loss:		0.027910
  validation loss:		0.306598
  validation accuracy:		93.91 %
Epoch 910 of 2000 took 0.149s
  training loss:		0.025530
  validation loss:		0.287915
  validation accuracy:		93.91 %
Epoch 911 of 2000 took 0.174s
  training loss:		0.026378
  validation loss:		0.296056
  validation accuracy:		94.13 %
Epoch 912 of 2000 took 0.159s
  training loss:		0.026569
  validation loss:		0.294538
  validation accuracy:		94.02 %
Epoch 913 of 2000 took 0.138s
  training loss:		0.027245
  validation loss:		0.292884
  validation accuracy:		93.91 %
Epoch 914 of 2000 took 0.152s
  training loss:		0.026323
  validation loss:		0.293879
  validation accuracy:		94.13 %
Epoch 915 of 2000 took 0.145s
  training loss:		0.025874
  validation loss:		0.301984
  validation accuracy:		94.02 %
Epoch 916 of 2000 took 0.158s
  training loss:		0.026835
  validation loss:		0.293370
  validation accuracy:		94.02 %
Epoch 917 of 2000 took 0.179s
  training loss:		0.026887
  validation loss:		0.301122
  validation accuracy:		93.91 %
Epoch 918 of 2000 took 0.172s
  training loss:		0.025498
  validation loss:		0.292358
  validation accuracy:		94.13 %
Epoch 919 of 2000 took 0.157s
  training loss:		0.025703
  validation loss:		0.295681
  validation accuracy:		93.80 %
Epoch 920 of 2000 took 0.153s
  training loss:		0.026395
  validation loss:		0.302690
  validation accuracy:		94.02 %
Epoch 921 of 2000 took 0.148s
  training loss:		0.026244
  validation loss:		0.294156
  validation accuracy:		93.91 %
Epoch 922 of 2000 took 0.145s
  training loss:		0.026309
  validation loss:		0.299877
  validation accuracy:		93.91 %
Epoch 923 of 2000 took 0.148s
  training loss:		0.027980
  validation loss:		0.290876
  validation accuracy:		94.02 %
Epoch 924 of 2000 took 0.147s
  training loss:		0.026815
  validation loss:		0.302599
  validation accuracy:		94.24 %
Epoch 925 of 2000 took 0.149s
  training loss:		0.026487
  validation loss:		0.296618
  validation accuracy:		93.91 %
Epoch 926 of 2000 took 0.157s
  training loss:		0.026090
  validation loss:		0.302300
  validation accuracy:		94.02 %
Epoch 927 of 2000 took 0.137s
  training loss:		0.026203
  validation loss:		0.302583
  validation accuracy:		94.02 %
Epoch 928 of 2000 took 0.141s
  training loss:		0.024704
  validation loss:		0.300840
  validation accuracy:		94.02 %
Epoch 929 of 2000 took 0.138s
  training loss:		0.025659
  validation loss:		0.298650
  validation accuracy:		93.91 %
Epoch 930 of 2000 took 0.145s
  training loss:		0.025811
  validation loss:		0.295543
  validation accuracy:		94.13 %
Epoch 931 of 2000 took 0.169s
  training loss:		0.025733
  validation loss:		0.294989
  validation accuracy:		94.02 %
Epoch 932 of 2000 took 0.185s
  training loss:		0.025305
  validation loss:		0.293760
  validation accuracy:		94.13 %
Epoch 933 of 2000 took 0.171s
  training loss:		0.025525
  validation loss:		0.293904
  validation accuracy:		94.24 %
Epoch 934 of 2000 took 0.176s
  training loss:		0.025826
  validation loss:		0.300087
  validation accuracy:		93.91 %
Epoch 935 of 2000 took 0.159s
  training loss:		0.025402
  validation loss:		0.295054
  validation accuracy:		94.02 %
Epoch 936 of 2000 took 0.159s
  training loss:		0.025278
  validation loss:		0.300324
  validation accuracy:		93.91 %
Epoch 937 of 2000 took 0.179s
  training loss:		0.025364
  validation loss:		0.296243
  validation accuracy:		94.13 %
Epoch 938 of 2000 took 0.178s
  training loss:		0.024880
  validation loss:		0.307543
  validation accuracy:		93.91 %
Epoch 939 of 2000 took 0.152s
  training loss:		0.024525
  validation loss:		0.303567
  validation accuracy:		94.13 %
Epoch 940 of 2000 took 0.144s
  training loss:		0.025410
  validation loss:		0.301888
  validation accuracy:		93.91 %
Epoch 941 of 2000 took 0.104s
  training loss:		0.023986
  validation loss:		0.292651
  validation accuracy:		94.02 %
Epoch 942 of 2000 took 0.129s
  training loss:		0.024273
  validation loss:		0.307218
  validation accuracy:		93.70 %
Epoch 943 of 2000 took 0.277s
  training loss:		0.024786
  validation loss:		0.303189
  validation accuracy:		93.91 %
Epoch 944 of 2000 took 0.120s
  training loss:		0.024591
  validation loss:		0.297452
  validation accuracy:		94.02 %
Epoch 945 of 2000 took 0.092s
  training loss:		0.023875
  validation loss:		0.287071
  validation accuracy:		94.02 %
Epoch 946 of 2000 took 0.117s
  training loss:		0.025224
  validation loss:		0.292679
  validation accuracy:		94.02 %
Epoch 947 of 2000 took 0.148s
  training loss:		0.024040
  validation loss:		0.299209
  validation accuracy:		94.13 %
Epoch 948 of 2000 took 0.122s
  training loss:		0.025752
  validation loss:		0.296578
  validation accuracy:		94.13 %
Epoch 949 of 2000 took 0.154s
  training loss:		0.024193
  validation loss:		0.301861
  validation accuracy:		94.02 %
Epoch 950 of 2000 took 0.129s
  training loss:		0.024251
  validation loss:		0.301627
  validation accuracy:		94.02 %
Epoch 951 of 2000 took 0.127s
  training loss:		0.024745
  validation loss:		0.295130
  validation accuracy:		94.13 %
Epoch 952 of 2000 took 0.129s
  training loss:		0.024244
  validation loss:		0.303010
  validation accuracy:		94.13 %
Epoch 953 of 2000 took 0.129s
  training loss:		0.024951
  validation loss:		0.306671
  validation accuracy:		93.91 %
Epoch 954 of 2000 took 0.118s
  training loss:		0.025612
  validation loss:		0.302664
  validation accuracy:		94.24 %
Epoch 955 of 2000 took 0.121s
  training loss:		0.024619
  validation loss:		0.305617
  validation accuracy:		93.91 %
Epoch 956 of 2000 took 0.111s
  training loss:		0.024289
  validation loss:		0.303417
  validation accuracy:		93.91 %
Epoch 957 of 2000 took 0.121s
  training loss:		0.024320
  validation loss:		0.299154
  validation accuracy:		94.02 %
Epoch 958 of 2000 took 0.127s
  training loss:		0.023292
  validation loss:		0.295626
  validation accuracy:		93.91 %
Epoch 959 of 2000 took 0.131s
  training loss:		0.023937
  validation loss:		0.300003
  validation accuracy:		94.02 %
Epoch 960 of 2000 took 0.127s
  training loss:		0.024261
  validation loss:		0.305472
  validation accuracy:		93.80 %
Epoch 961 of 2000 took 0.129s
  training loss:		0.023934
  validation loss:		0.312994
  validation accuracy:		93.91 %
Epoch 962 of 2000 took 0.125s
  training loss:		0.024262
  validation loss:		0.310687
  validation accuracy:		94.24 %
Epoch 963 of 2000 took 0.297s
  training loss:		0.023287
  validation loss:		0.307549
  validation accuracy:		94.02 %
Epoch 964 of 2000 took 0.126s
  training loss:		0.023231
  validation loss:		0.304547
  validation accuracy:		94.13 %
Epoch 965 of 2000 took 0.125s
  training loss:		0.025088
  validation loss:		0.305126
  validation accuracy:		94.02 %
Epoch 966 of 2000 took 0.123s
  training loss:		0.024041
  validation loss:		0.315171
  validation accuracy:		94.13 %
Epoch 967 of 2000 took 0.127s
  training loss:		0.024846
  validation loss:		0.306118
  validation accuracy:		94.02 %
Epoch 968 of 2000 took 0.128s
  training loss:		0.022978
  validation loss:		0.306937
  validation accuracy:		94.02 %
Epoch 969 of 2000 took 0.125s
  training loss:		0.023921
  validation loss:		0.306663
  validation accuracy:		94.02 %
Epoch 970 of 2000 took 0.123s
  training loss:		0.023523
  validation loss:		0.307684
  validation accuracy:		93.70 %
Epoch 971 of 2000 took 0.098s
  training loss:		0.022649
  validation loss:		0.301389
  validation accuracy:		94.02 %
Epoch 972 of 2000 took 0.123s
  training loss:		0.022835
  validation loss:		0.303965
  validation accuracy:		93.70 %
Epoch 973 of 2000 took 0.129s
  training loss:		0.022525
  validation loss:		0.310730
  validation accuracy:		93.91 %
Epoch 974 of 2000 took 0.120s
  training loss:		0.022650
  validation loss:		0.305813
  validation accuracy:		93.91 %
Epoch 975 of 2000 took 0.124s
  training loss:		0.023817
  validation loss:		0.310146
  validation accuracy:		94.13 %
Epoch 976 of 2000 took 0.128s
  training loss:		0.023040
  validation loss:		0.316721
  validation accuracy:		93.91 %
Epoch 977 of 2000 took 0.137s
  training loss:		0.023386
  validation loss:		0.308389
  validation accuracy:		94.02 %
Epoch 978 of 2000 took 0.127s
  training loss:		0.022686
  validation loss:		0.312755
  validation accuracy:		93.91 %
Epoch 979 of 2000 took 0.125s
  training loss:		0.023413
  validation loss:		0.312083
  validation accuracy:		93.80 %
Epoch 980 of 2000 took 0.125s
  training loss:		0.022932
  validation loss:		0.307323
  validation accuracy:		93.80 %
Epoch 981 of 2000 took 0.125s
  training loss:		0.022267
  validation loss:		0.309576
  validation accuracy:		93.70 %
Epoch 982 of 2000 took 0.125s
  training loss:		0.022727
  validation loss:		0.307102
  validation accuracy:		94.02 %
Epoch 983 of 2000 took 0.130s
  training loss:		0.022913
  validation loss:		0.315949
  validation accuracy:		93.91 %
Epoch 984 of 2000 took 0.127s
  training loss:		0.023081
  validation loss:		0.300345
  validation accuracy:		93.91 %
Epoch 985 of 2000 took 0.130s
  training loss:		0.021797
  validation loss:		0.313679
  validation accuracy:		94.24 %
Epoch 986 of 2000 took 0.126s
  training loss:		0.022833
  validation loss:		0.316511
  validation accuracy:		93.80 %
Epoch 987 of 2000 took 0.125s
  training loss:		0.022888
  validation loss:		0.303225
  validation accuracy:		94.02 %
Epoch 988 of 2000 took 0.119s
  training loss:		0.023104
  validation loss:		0.316938
  validation accuracy:		93.91 %
Epoch 989 of 2000 took 0.106s
  training loss:		0.021895
  validation loss:		0.309715
  validation accuracy:		94.02 %
Epoch 990 of 2000 took 0.101s
  training loss:		0.021527
  validation loss:		0.308648
  validation accuracy:		94.02 %
Epoch 991 of 2000 took 0.054s
  training loss:		0.022924
  validation loss:		0.310773
  validation accuracy:		94.02 %
Epoch 992 of 2000 took 0.080s
  training loss:		0.021815
  validation loss:		0.320756
  validation accuracy:		93.91 %
Epoch 993 of 2000 took 0.140s
  training loss:		0.022255
  validation loss:		0.311520
  validation accuracy:		93.59 %
Epoch 994 of 2000 took 0.076s
  training loss:		0.021959
  validation loss:		0.310754
  validation accuracy:		94.13 %
Epoch 995 of 2000 took 0.052s
  training loss:		0.022785
  validation loss:		0.303715
  validation accuracy:		94.02 %
Epoch 996 of 2000 took 0.054s
  training loss:		0.021386
  validation loss:		0.311784
  validation accuracy:		94.02 %
Epoch 997 of 2000 took 0.054s
  training loss:		0.021855
  validation loss:		0.315445
  validation accuracy:		94.02 %
Epoch 998 of 2000 took 0.075s
  training loss:		0.021382
  validation loss:		0.320967
  validation accuracy:		94.02 %
Epoch 999 of 2000 took 0.100s
  training loss:		0.022866
  validation loss:		0.305714
  validation accuracy:		94.02 %
Epoch 1000 of 2000 took 0.069s
  training loss:		0.021516
  validation loss:		0.315355
  validation accuracy:		94.24 %
Epoch 1001 of 2000 took 0.052s
  training loss:		0.020608
  validation loss:		0.312326
  validation accuracy:		94.02 %
Epoch 1002 of 2000 took 0.068s
  training loss:		0.022197
  validation loss:		0.324414
  validation accuracy:		93.91 %
Epoch 1003 of 2000 took 0.111s
  training loss:		0.021440
  validation loss:		0.321024
  validation accuracy:		93.91 %
Epoch 1004 of 2000 took 0.101s
  training loss:		0.021223
  validation loss:		0.315310
  validation accuracy:		94.24 %
Epoch 1005 of 2000 took 0.093s
  training loss:		0.021701
  validation loss:		0.318066
  validation accuracy:		93.91 %
Epoch 1006 of 2000 took 0.102s
  training loss:		0.021474
  validation loss:		0.309979
  validation accuracy:		93.91 %
Epoch 1007 of 2000 took 0.076s
  training loss:		0.021296
  validation loss:		0.313069
  validation accuracy:		93.80 %
Epoch 1008 of 2000 took 0.053s
  training loss:		0.021238
  validation loss:		0.311303
  validation accuracy:		94.02 %
Epoch 1009 of 2000 took 0.053s
  training loss:		0.021632
  validation loss:		0.319008
  validation accuracy:		94.02 %
Epoch 1010 of 2000 took 0.086s
  training loss:		0.021439
  validation loss:		0.318043
  validation accuracy:		93.59 %
Epoch 1011 of 2000 took 0.062s
  training loss:		0.021352
  validation loss:		0.316067
  validation accuracy:		94.02 %
Epoch 1012 of 2000 took 0.050s
  training loss:		0.021805
  validation loss:		0.318834
  validation accuracy:		93.59 %
Epoch 1013 of 2000 took 0.050s
  training loss:		0.021021
  validation loss:		0.304443
  validation accuracy:		94.02 %
Epoch 1014 of 2000 took 0.051s
  training loss:		0.021576
  validation loss:		0.316518
  validation accuracy:		94.13 %
Epoch 1015 of 2000 took 0.050s
  training loss:		0.020563
  validation loss:		0.313481
  validation accuracy:		94.02 %
Epoch 1016 of 2000 took 0.050s
  training loss:		0.020892
  validation loss:		0.316147
  validation accuracy:		93.91 %
Epoch 1017 of 2000 took 0.050s
  training loss:		0.021035
  validation loss:		0.315110
  validation accuracy:		93.91 %
Epoch 1018 of 2000 took 0.050s
  training loss:		0.020636
  validation loss:		0.322995
  validation accuracy:		93.80 %
Epoch 1019 of 2000 took 0.051s
  training loss:		0.020993
  validation loss:		0.339016
  validation accuracy:		93.37 %
Epoch 1020 of 2000 took 0.051s
  training loss:		0.020928
  validation loss:		0.314440
  validation accuracy:		94.13 %
Epoch 1021 of 2000 took 0.230s
  training loss:		0.020672
  validation loss:		0.322051
  validation accuracy:		93.91 %
Epoch 1022 of 2000 took 0.092s
  training loss:		0.020770
  validation loss:		0.316402
  validation accuracy:		94.13 %
Epoch 1023 of 2000 took 0.067s
  training loss:		0.020699
  validation loss:		0.319550
  validation accuracy:		93.59 %
Epoch 1024 of 2000 took 0.101s
  training loss:		0.021046
  validation loss:		0.318236
  validation accuracy:		94.02 %
Epoch 1025 of 2000 took 0.051s
  training loss:		0.020269
  validation loss:		0.317508
  validation accuracy:		94.02 %
Epoch 1026 of 2000 took 0.051s
  training loss:		0.019551
  validation loss:		0.330185
  validation accuracy:		93.37 %
Epoch 1027 of 2000 took 0.051s
  training loss:		0.021069
  validation loss:		0.326953
  validation accuracy:		93.91 %
Epoch 1028 of 2000 took 0.050s
  training loss:		0.020097
  validation loss:		0.315683
  validation accuracy:		93.91 %
Epoch 1029 of 2000 took 0.050s
  training loss:		0.020853
  validation loss:		0.321880
  validation accuracy:		93.70 %
Epoch 1030 of 2000 took 0.051s
  training loss:		0.020028
  validation loss:		0.322921
  validation accuracy:		93.91 %
Epoch 1031 of 2000 took 0.051s
  training loss:		0.019928
  validation loss:		0.323853
  validation accuracy:		94.13 %
Epoch 1032 of 2000 took 0.051s
  training loss:		0.020405
  validation loss:		0.311281
  validation accuracy:		93.80 %
Epoch 1033 of 2000 took 0.051s
  training loss:		0.020879
  validation loss:		0.319023
  validation accuracy:		94.02 %
Epoch 1034 of 2000 took 0.052s
  training loss:		0.020493
  validation loss:		0.319398
  validation accuracy:		93.91 %
Epoch 1035 of 2000 took 0.051s
  training loss:		0.019902
  validation loss:		0.310856
  validation accuracy:		93.91 %
Epoch 1036 of 2000 took 0.050s
  training loss:		0.019872
  validation loss:		0.322149
  validation accuracy:		94.02 %
Epoch 1037 of 2000 took 0.053s
  training loss:		0.019995
  validation loss:		0.315994
  validation accuracy:		93.91 %
Epoch 1038 of 2000 took 0.050s
  training loss:		0.020090
  validation loss:		0.322709
  validation accuracy:		93.80 %
Epoch 1039 of 2000 took 0.051s
  training loss:		0.019015
  validation loss:		0.325673
  validation accuracy:		93.91 %
Epoch 1040 of 2000 took 0.050s
  training loss:		0.019463
  validation loss:		0.326252
  validation accuracy:		94.02 %
Epoch 1041 of 2000 took 0.050s
  training loss:		0.020387
  validation loss:		0.314023
  validation accuracy:		94.13 %
Epoch 1042 of 2000 took 0.051s
  training loss:		0.020283
  validation loss:		0.312464
  validation accuracy:		93.91 %
Epoch 1043 of 2000 took 0.050s
  training loss:		0.019928
  validation loss:		0.324550
  validation accuracy:		93.91 %
Epoch 1044 of 2000 took 0.050s
  training loss:		0.018371
  validation loss:		0.324426
  validation accuracy:		94.02 %
Epoch 1045 of 2000 took 0.051s
  training loss:		0.019925
  validation loss:		0.324355
  validation accuracy:		93.48 %
Epoch 1046 of 2000 took 0.068s
  training loss:		0.019872
  validation loss:		0.330728
  validation accuracy:		93.80 %
Epoch 1047 of 2000 took 0.050s
  training loss:		0.019696
  validation loss:		0.321297
  validation accuracy:		93.91 %
Epoch 1048 of 2000 took 0.051s
  training loss:		0.018964
  validation loss:		0.335005
  validation accuracy:		94.02 %
Epoch 1049 of 2000 took 0.052s
  training loss:		0.019919
  validation loss:		0.321207
  validation accuracy:		93.91 %
Epoch 1050 of 2000 took 0.051s
  training loss:		0.018357
  validation loss:		0.325146
  validation accuracy:		94.02 %
Epoch 1051 of 2000 took 0.051s
  training loss:		0.019654
  validation loss:		0.320427
  validation accuracy:		93.91 %
Epoch 1052 of 2000 took 0.051s
  training loss:		0.019225
  validation loss:		0.327844
  validation accuracy:		93.91 %
Epoch 1053 of 2000 took 0.051s
  training loss:		0.019091
  validation loss:		0.330285
  validation accuracy:		93.91 %
Epoch 1054 of 2000 took 0.051s
  training loss:		0.019642
  validation loss:		0.323299
  validation accuracy:		93.91 %
Epoch 1055 of 2000 took 0.051s
  training loss:		0.017766
  validation loss:		0.321175
  validation accuracy:		94.02 %
Epoch 1056 of 2000 took 0.050s
  training loss:		0.019154
  validation loss:		0.322467
  validation accuracy:		94.02 %
Epoch 1057 of 2000 took 0.051s
  training loss:		0.017769
  validation loss:		0.325037
  validation accuracy:		94.02 %
Epoch 1058 of 2000 took 0.051s
  training loss:		0.019382
  validation loss:		0.337203
  validation accuracy:		93.59 %
Epoch 1059 of 2000 took 0.051s
  training loss:		0.017943
  validation loss:		0.326300
  validation accuracy:		93.80 %
Epoch 1060 of 2000 took 0.051s
  training loss:		0.018541
  validation loss:		0.324721
  validation accuracy:		93.91 %
Epoch 1061 of 2000 took 0.051s
  training loss:		0.018740
  validation loss:		0.328778
  validation accuracy:		93.91 %
Epoch 1062 of 2000 took 0.051s
  training loss:		0.019024
  validation loss:		0.335367
  validation accuracy:		93.80 %
Epoch 1063 of 2000 took 0.051s
  training loss:		0.018866
  validation loss:		0.331689
  validation accuracy:		94.02 %
Epoch 1064 of 2000 took 0.051s
  training loss:		0.018768
  validation loss:		0.328747
  validation accuracy:		93.91 %
Epoch 1065 of 2000 took 0.052s
  training loss:		0.019246
  validation loss:		0.329724
  validation accuracy:		93.91 %
Epoch 1066 of 2000 took 0.052s
  training loss:		0.019218
  validation loss:		0.330416
  validation accuracy:		93.80 %
Epoch 1067 of 2000 took 0.052s
  training loss:		0.018344
  validation loss:		0.328606
  validation accuracy:		93.91 %
Epoch 1068 of 2000 took 0.051s
  training loss:		0.018672
  validation loss:		0.329099
  validation accuracy:		94.02 %
Epoch 1069 of 2000 took 0.051s
  training loss:		0.018410
  validation loss:		0.327252
  validation accuracy:		93.91 %
Epoch 1070 of 2000 took 0.052s
  training loss:		0.017784
  validation loss:		0.327780
  validation accuracy:		93.91 %
Epoch 1071 of 2000 took 0.051s
  training loss:		0.019127
  validation loss:		0.333589
  validation accuracy:		94.02 %
Epoch 1072 of 2000 took 0.050s
  training loss:		0.018749
  validation loss:		0.334121
  validation accuracy:		93.91 %
Epoch 1073 of 2000 took 0.050s
  training loss:		0.018874
  validation loss:		0.340760
  validation accuracy:		93.91 %
Epoch 1074 of 2000 took 0.051s
  training loss:		0.018988
  validation loss:		0.331180
  validation accuracy:		94.02 %
Epoch 1075 of 2000 took 0.050s
  training loss:		0.018198
  validation loss:		0.342279
  validation accuracy:		93.80 %
Epoch 1076 of 2000 took 0.051s
  training loss:		0.018097
  validation loss:		0.329107
  validation accuracy:		94.02 %
Epoch 1077 of 2000 took 0.051s
  training loss:		0.018520
  validation loss:		0.327868
  validation accuracy:		93.91 %
Epoch 1078 of 2000 took 0.051s
  training loss:		0.018061
  validation loss:		0.337017
  validation accuracy:		93.70 %
Epoch 1079 of 2000 took 0.051s
  training loss:		0.018641
  validation loss:		0.335255
  validation accuracy:		93.91 %
Epoch 1080 of 2000 took 0.051s
  training loss:		0.017732
  validation loss:		0.337534
  validation accuracy:		94.02 %
Epoch 1081 of 2000 took 0.050s
  training loss:		0.018167
  validation loss:		0.335816
  validation accuracy:		93.70 %
Epoch 1082 of 2000 took 0.050s
  training loss:		0.018832
  validation loss:		0.332023
  validation accuracy:		93.70 %
Epoch 1083 of 2000 took 0.078s
  training loss:		0.018691
  validation loss:		0.341794
  validation accuracy:		93.70 %
Epoch 1084 of 2000 took 0.051s
  training loss:		0.017879
  validation loss:		0.332641
  validation accuracy:		93.91 %
Epoch 1085 of 2000 took 0.052s
  training loss:		0.017811
  validation loss:		0.334823
  validation accuracy:		93.91 %
Epoch 1086 of 2000 took 0.051s
  training loss:		0.018195
  validation loss:		0.330735
  validation accuracy:		93.70 %
Epoch 1087 of 2000 took 0.050s
  training loss:		0.018447
  validation loss:		0.330901
  validation accuracy:		93.91 %
Epoch 1088 of 2000 took 0.051s
  training loss:		0.017381
  validation loss:		0.331095
  validation accuracy:		94.13 %
Epoch 1089 of 2000 took 0.052s
  training loss:		0.017240
  validation loss:		0.340801
  validation accuracy:		93.70 %
Epoch 1090 of 2000 took 0.052s
  training loss:		0.017919
  validation loss:		0.342945
  validation accuracy:		93.70 %
Epoch 1091 of 2000 took 0.051s
  training loss:		0.016855
  validation loss:		0.343766
  validation accuracy:		93.91 %
Epoch 1092 of 2000 took 0.051s
  training loss:		0.017897
  validation loss:		0.336764
  validation accuracy:		94.02 %
Epoch 1093 of 2000 took 0.052s
  training loss:		0.018099
  validation loss:		0.330359
  validation accuracy:		93.91 %
Epoch 1094 of 2000 took 0.051s
  training loss:		0.018739
  validation loss:		0.330658
  validation accuracy:		94.02 %
Epoch 1095 of 2000 took 0.051s
  training loss:		0.017336
  validation loss:		0.343739
  validation accuracy:		93.70 %
Epoch 1096 of 2000 took 0.051s
  training loss:		0.016517
  validation loss:		0.329285
  validation accuracy:		93.91 %
Epoch 1097 of 2000 took 0.051s
  training loss:		0.017918
  validation loss:		0.342780
  validation accuracy:		93.70 %
Epoch 1098 of 2000 took 0.050s
  training loss:		0.016626
  validation loss:		0.329406
  validation accuracy:		93.70 %
Epoch 1099 of 2000 took 0.051s
  training loss:		0.017609
  validation loss:		0.339278
  validation accuracy:		93.80 %
Epoch 1100 of 2000 took 0.051s
  training loss:		0.017858
  validation loss:		0.334511
  validation accuracy:		93.80 %
Epoch 1101 of 2000 took 0.051s
  training loss:		0.017755
  validation loss:		0.338550
  validation accuracy:		93.91 %
Epoch 1102 of 2000 took 0.051s
  training loss:		0.017750
  validation loss:		0.339175
  validation accuracy:		93.70 %
Epoch 1103 of 2000 took 0.051s
  training loss:		0.016862
  validation loss:		0.343506
  validation accuracy:		93.80 %
Epoch 1104 of 2000 took 0.051s
  training loss:		0.017340
  validation loss:		0.336658
  validation accuracy:		93.70 %
Epoch 1105 of 2000 took 0.051s
  training loss:		0.017185
  validation loss:		0.338914
  validation accuracy:		93.70 %
Epoch 1106 of 2000 took 0.051s
  training loss:		0.016897
  validation loss:		0.339356
  validation accuracy:		93.80 %
Epoch 1107 of 2000 took 0.051s
  training loss:		0.017329
  validation loss:		0.349513
  validation accuracy:		93.80 %
Epoch 1108 of 2000 took 0.051s
  training loss:		0.017103
  validation loss:		0.345640
  validation accuracy:		93.80 %
Epoch 1109 of 2000 took 0.052s
  training loss:		0.017585
  validation loss:		0.337863
  validation accuracy:		93.91 %
Epoch 1110 of 2000 took 0.051s
  training loss:		0.017062
  validation loss:		0.338318
  validation accuracy:		94.02 %
Epoch 1111 of 2000 took 0.051s
  training loss:		0.016846
  validation loss:		0.336182
  validation accuracy:		94.02 %
Epoch 1112 of 2000 took 0.051s
  training loss:		0.017204
  validation loss:		0.330518
  validation accuracy:		93.70 %
Epoch 1113 of 2000 took 0.051s
  training loss:		0.017403
  validation loss:		0.342530
  validation accuracy:		93.80 %
Epoch 1114 of 2000 took 0.051s
  training loss:		0.016503
  validation loss:		0.342959
  validation accuracy:		93.70 %
Epoch 1115 of 2000 took 0.051s
  training loss:		0.016888
  validation loss:		0.337090
  validation accuracy:		93.80 %
Epoch 1116 of 2000 took 0.051s
  training loss:		0.017097
  validation loss:		0.344675
  validation accuracy:		93.59 %
Epoch 1117 of 2000 took 0.052s
  training loss:		0.015966
  validation loss:		0.337414
  validation accuracy:		93.80 %
Epoch 1118 of 2000 took 0.052s
  training loss:		0.017636
  validation loss:		0.339954
  validation accuracy:		93.59 %
Epoch 1119 of 2000 took 0.052s
  training loss:		0.016735
  validation loss:		0.346060
  validation accuracy:		93.70 %
Epoch 1120 of 2000 took 0.078s
  training loss:		0.016944
  validation loss:		0.340664
  validation accuracy:		93.91 %
Epoch 1121 of 2000 took 0.101s
  training loss:		0.016755
  validation loss:		0.345076
  validation accuracy:		93.80 %
Epoch 1122 of 2000 took 0.082s
  training loss:		0.016775
  validation loss:		0.353076
  validation accuracy:		93.59 %
Epoch 1123 of 2000 took 0.052s
  training loss:		0.016633
  validation loss:		0.341214
  validation accuracy:		93.91 %
Epoch 1124 of 2000 took 0.051s
  training loss:		0.016998
  validation loss:		0.342247
  validation accuracy:		93.48 %
Epoch 1125 of 2000 took 0.050s
  training loss:		0.016432
  validation loss:		0.346422
  validation accuracy:		93.70 %
Epoch 1126 of 2000 took 0.051s
  training loss:		0.015930
  validation loss:		0.356183
  validation accuracy:		93.48 %
Epoch 1127 of 2000 took 0.050s
  training loss:		0.016223
  validation loss:		0.351595
  validation accuracy:		93.59 %
Epoch 1128 of 2000 took 0.051s
  training loss:		0.016009
  validation loss:		0.351766
  validation accuracy:		93.48 %
Epoch 1129 of 2000 took 0.052s
  training loss:		0.016803
  validation loss:		0.352622
  validation accuracy:		93.59 %
Epoch 1130 of 2000 took 0.051s
  training loss:		0.016913
  validation loss:		0.338758
  validation accuracy:		93.80 %
Epoch 1131 of 2000 took 0.050s
  training loss:		0.015209
  validation loss:		0.355478
  validation accuracy:		93.70 %
Epoch 1132 of 2000 took 0.051s
  training loss:		0.016611
  validation loss:		0.341738
  validation accuracy:		93.70 %
Epoch 1133 of 2000 took 0.115s
  training loss:		0.016183
  validation loss:		0.342126
  validation accuracy:		93.80 %
Epoch 1134 of 2000 took 0.055s
  training loss:		0.016542
  validation loss:		0.344556
  validation accuracy:		93.80 %
Epoch 1135 of 2000 took 0.088s
  training loss:		0.015639
  validation loss:		0.346722
  validation accuracy:		93.70 %
Epoch 1136 of 2000 took 0.114s
  training loss:		0.015989
  validation loss:		0.353199
  validation accuracy:		93.59 %
Epoch 1137 of 2000 took 0.081s
  training loss:		0.016278
  validation loss:		0.352102
  validation accuracy:		93.48 %
Epoch 1138 of 2000 took 0.055s
  training loss:		0.016077
  validation loss:		0.351889
  validation accuracy:		93.70 %
Epoch 1139 of 2000 took 0.125s
  training loss:		0.015925
  validation loss:		0.340098
  validation accuracy:		93.91 %
Epoch 1140 of 2000 took 0.122s
  training loss:		0.016017
  validation loss:		0.340664
  validation accuracy:		93.59 %
Epoch 1141 of 2000 took 0.067s
  training loss:		0.015457
  validation loss:		0.345813
  validation accuracy:		93.70 %
Epoch 1142 of 2000 took 0.056s
  training loss:		0.015766
  validation loss:		0.348571
  validation accuracy:		93.48 %
Epoch 1143 of 2000 took 0.138s
  training loss:		0.016785
  validation loss:		0.355530
  validation accuracy:		93.80 %
Epoch 1144 of 2000 took 0.114s
  training loss:		0.015622
  validation loss:		0.350616
  validation accuracy:		93.91 %
Epoch 1145 of 2000 took 0.123s
  training loss:		0.015715
  validation loss:		0.343129
  validation accuracy:		93.70 %
Epoch 1146 of 2000 took 0.137s
  training loss:		0.015442
  validation loss:		0.349191
  validation accuracy:		93.48 %
Epoch 1147 of 2000 took 0.121s
  training loss:		0.016067
  validation loss:		0.339272
  validation accuracy:		93.80 %
Epoch 1148 of 2000 took 0.112s
  training loss:		0.016085
  validation loss:		0.353130
  validation accuracy:		93.59 %
Epoch 1149 of 2000 took 0.111s
  training loss:		0.015158
  validation loss:		0.351070
  validation accuracy:		93.59 %
Epoch 1150 of 2000 took 0.170s
  training loss:		0.015779
  validation loss:		0.343001
  validation accuracy:		93.70 %
Epoch 1151 of 2000 took 0.117s
  training loss:		0.015507
  validation loss:		0.346220
  validation accuracy:		93.59 %
Epoch 1152 of 2000 took 0.108s
  training loss:		0.015175
  validation loss:		0.335829
  validation accuracy:		93.91 %
Epoch 1153 of 2000 took 0.154s
  training loss:		0.015226
  validation loss:		0.348976
  validation accuracy:		93.80 %
Epoch 1154 of 2000 took 0.143s
  training loss:		0.015235
  validation loss:		0.344228
  validation accuracy:		93.70 %
Epoch 1155 of 2000 took 0.113s
  training loss:		0.016139
  validation loss:		0.350969
  validation accuracy:		93.59 %
Epoch 1156 of 2000 took 0.157s
  training loss:		0.015254
  validation loss:		0.351634
  validation accuracy:		93.59 %
Epoch 1157 of 2000 took 0.147s
  training loss:		0.014862
  validation loss:		0.353022
  validation accuracy:		93.91 %
Epoch 1158 of 2000 took 0.180s
  training loss:		0.015159
  validation loss:		0.348956
  validation accuracy:		93.80 %
Epoch 1159 of 2000 took 0.134s
  training loss:		0.015381
  validation loss:		0.349980
  validation accuracy:		93.91 %
Epoch 1160 of 2000 took 0.114s
  training loss:		0.015322
  validation loss:		0.356182
  validation accuracy:		93.70 %
Epoch 1161 of 2000 took 0.173s
  training loss:		0.014785
  validation loss:		0.350990
  validation accuracy:		93.91 %
Epoch 1162 of 2000 took 0.176s
  training loss:		0.015341
  validation loss:		0.355326
  validation accuracy:		93.48 %
Epoch 1163 of 2000 took 0.106s
  training loss:		0.014998
  validation loss:		0.351395
  validation accuracy:		93.91 %
Epoch 1164 of 2000 took 0.116s
  training loss:		0.015030
  validation loss:		0.343285
  validation accuracy:		93.80 %
Epoch 1165 of 2000 took 0.113s
  training loss:		0.015227
  validation loss:		0.352760
  validation accuracy:		93.48 %
Epoch 1166 of 2000 took 0.118s
  training loss:		0.014918
  validation loss:		0.359751
  validation accuracy:		93.59 %
Epoch 1167 of 2000 took 0.144s
  training loss:		0.015101
  validation loss:		0.352074
  validation accuracy:		93.91 %
Epoch 1168 of 2000 took 0.131s
  training loss:		0.015083
  validation loss:		0.355287
  validation accuracy:		93.80 %
Epoch 1169 of 2000 took 0.141s
  training loss:		0.014642
  validation loss:		0.346901
  validation accuracy:		93.70 %
Epoch 1170 of 2000 took 0.116s
  training loss:		0.015046
  validation loss:		0.340596
  validation accuracy:		93.70 %
Epoch 1171 of 2000 took 0.168s
  training loss:		0.015011
  validation loss:		0.366723
  validation accuracy:		93.37 %
Epoch 1172 of 2000 took 0.171s
  training loss:		0.015509
  validation loss:		0.358700
  validation accuracy:		93.70 %
Epoch 1173 of 2000 took 0.162s
  training loss:		0.014830
  validation loss:		0.354051
  validation accuracy:		93.59 %
Epoch 1174 of 2000 took 0.144s
  training loss:		0.013574
  validation loss:		0.352295
  validation accuracy:		93.80 %
Epoch 1175 of 2000 took 0.177s
  training loss:		0.014810
  validation loss:		0.369562
  validation accuracy:		93.37 %
Epoch 1176 of 2000 took 0.135s
  training loss:		0.014893
  validation loss:		0.354459
  validation accuracy:		93.59 %
Epoch 1177 of 2000 took 0.153s
  training loss:		0.014381
  validation loss:		0.355686
  validation accuracy:		93.80 %
Epoch 1178 of 2000 took 0.156s
  training loss:		0.015000
  validation loss:		0.351409
  validation accuracy:		93.70 %
Epoch 1179 of 2000 took 0.133s
  training loss:		0.014600
  validation loss:		0.357897
  validation accuracy:		93.70 %
Epoch 1180 of 2000 took 0.152s
  training loss:		0.014532
  validation loss:		0.362208
  validation accuracy:		93.59 %
Epoch 1181 of 2000 took 0.131s
  training loss:		0.014514
  validation loss:		0.360276
  validation accuracy:		93.48 %
Epoch 1182 of 2000 took 0.163s
  training loss:		0.014534
  validation loss:		0.367993
  validation accuracy:		93.48 %
Epoch 1183 of 2000 took 0.169s
  training loss:		0.014937
  validation loss:		0.352793
  validation accuracy:		93.70 %
Epoch 1184 of 2000 took 0.152s
  training loss:		0.013625
  validation loss:		0.356315
  validation accuracy:		93.80 %
Epoch 1185 of 2000 took 0.129s
  training loss:		0.013936
  validation loss:		0.356319
  validation accuracy:		93.70 %
Epoch 1186 of 2000 took 0.103s
  training loss:		0.014748
  validation loss:		0.355756
  validation accuracy:		93.70 %
Epoch 1187 of 2000 took 0.142s
  training loss:		0.014623
  validation loss:		0.355381
  validation accuracy:		93.59 %
Epoch 1188 of 2000 took 0.123s
  training loss:		0.014200
  validation loss:		0.365426
  validation accuracy:		93.37 %
Epoch 1189 of 2000 took 0.121s
  training loss:		0.014043
  validation loss:		0.358443
  validation accuracy:		93.37 %
Epoch 1190 of 2000 took 0.165s
  training loss:		0.014097
  validation loss:		0.362117
  validation accuracy:		93.91 %
Epoch 1191 of 2000 took 0.202s
  training loss:		0.014265
  validation loss:		0.354232
  validation accuracy:		93.48 %
Epoch 1192 of 2000 took 0.172s
  training loss:		0.013439
  validation loss:		0.358852
  validation accuracy:		93.70 %
Epoch 1193 of 2000 took 0.095s
  training loss:		0.014082
  validation loss:		0.361266
  validation accuracy:		93.59 %
Epoch 1194 of 2000 took 0.159s
  training loss:		0.013750
  validation loss:		0.356894
  validation accuracy:		93.80 %
Epoch 1195 of 2000 took 0.151s
  training loss:		0.014696
  validation loss:		0.356128
  validation accuracy:		93.59 %
Epoch 1196 of 2000 took 0.144s
  training loss:		0.014082
  validation loss:		0.360662
  validation accuracy:		93.15 %
Epoch 1197 of 2000 took 0.134s
  training loss:		0.014107
  validation loss:		0.363896
  validation accuracy:		93.59 %
Epoch 1198 of 2000 took 0.177s
  training loss:		0.013784
  validation loss:		0.357997
  validation accuracy:		93.70 %
Epoch 1199 of 2000 took 0.199s
  training loss:		0.013964
  validation loss:		0.357203
  validation accuracy:		93.80 %
Epoch 1200 of 2000 took 0.194s
  training loss:		0.013970
  validation loss:		0.362347
  validation accuracy:		93.48 %
Epoch 1201 of 2000 took 0.166s
  training loss:		0.013483
  validation loss:		0.366819
  validation accuracy:		93.48 %
Epoch 1202 of 2000 took 0.199s
  training loss:		0.014257
  validation loss:		0.364514
  validation accuracy:		93.48 %
Epoch 1203 of 2000 took 0.144s
  training loss:		0.014164
  validation loss:		0.367925
  validation accuracy:		93.59 %
Epoch 1204 of 2000 took 0.163s
  training loss:		0.013785
  validation loss:		0.371605
  validation accuracy:		93.37 %
Epoch 1205 of 2000 took 0.185s
  training loss:		0.013931
  validation loss:		0.366478
  validation accuracy:		93.37 %
Epoch 1206 of 2000 took 0.116s
  training loss:		0.013747
  validation loss:		0.369333
  validation accuracy:		93.48 %
Epoch 1207 of 2000 took 0.114s
  training loss:		0.014262
  validation loss:		0.357717
  validation accuracy:		93.48 %
Epoch 1208 of 2000 took 0.119s
  training loss:		0.013604
  validation loss:		0.362118
  validation accuracy:		93.80 %
Epoch 1209 of 2000 took 0.138s
  training loss:		0.014042
  validation loss:		0.361523
  validation accuracy:		93.80 %
Epoch 1210 of 2000 took 0.135s
  training loss:		0.013539
  validation loss:		0.373718
  validation accuracy:		93.26 %
Epoch 1211 of 2000 took 0.177s
  training loss:		0.014033
  validation loss:		0.363188
  validation accuracy:		93.48 %
Epoch 1212 of 2000 took 0.081s
  training loss:		0.013623
  validation loss:		0.364834
  validation accuracy:		93.37 %
Epoch 1213 of 2000 took 0.089s
  training loss:		0.012793
  validation loss:		0.366072
  validation accuracy:		93.59 %
Epoch 1214 of 2000 took 0.125s
  training loss:		0.013149
  validation loss:		0.361869
  validation accuracy:		93.70 %
Epoch 1215 of 2000 took 0.112s
  training loss:		0.013540
  validation loss:		0.361535
  validation accuracy:		93.70 %
Epoch 1216 of 2000 took 0.130s
  training loss:		0.013561
  validation loss:		0.364568
  validation accuracy:		93.59 %
Epoch 1217 of 2000 took 0.102s
  training loss:		0.013497
  validation loss:		0.367012
  validation accuracy:		93.70 %
Epoch 1218 of 2000 took 0.100s
  training loss:		0.013672
  validation loss:		0.371370
  validation accuracy:		93.48 %
Epoch 1219 of 2000 took 0.101s
  training loss:		0.013896
  validation loss:		0.374834
  validation accuracy:		93.37 %
Epoch 1220 of 2000 took 0.102s
  training loss:		0.013416
  validation loss:		0.366955
  validation accuracy:		93.70 %
Epoch 1221 of 2000 took 0.102s
  training loss:		0.013240
  validation loss:		0.371565
  validation accuracy:		93.59 %
Epoch 1222 of 2000 took 0.104s
  training loss:		0.013745
  validation loss:		0.370205
  validation accuracy:		93.59 %
Epoch 1223 of 2000 took 0.119s
  training loss:		0.013149
  validation loss:		0.370999
  validation accuracy:		93.59 %
Epoch 1224 of 2000 took 0.071s
  training loss:		0.013054
  validation loss:		0.357104
  validation accuracy:		93.70 %
Epoch 1225 of 2000 took 0.161s
  training loss:		0.013389
  validation loss:		0.367172
  validation accuracy:		93.59 %
Epoch 1226 of 2000 took 0.126s
  training loss:		0.013067
  validation loss:		0.365640
  validation accuracy:		93.48 %
Epoch 1227 of 2000 took 0.156s
  training loss:		0.013303
  validation loss:		0.362624
  validation accuracy:		93.70 %
Epoch 1228 of 2000 took 0.122s
  training loss:		0.013389
  validation loss:		0.369296
  validation accuracy:		93.70 %
Epoch 1229 of 2000 took 0.117s
  training loss:		0.013426
  validation loss:		0.366337
  validation accuracy:		93.59 %
Epoch 1230 of 2000 took 0.115s
  training loss:		0.013124
  validation loss:		0.363920
  validation accuracy:		93.70 %
Epoch 1231 of 2000 took 0.151s
  training loss:		0.013327
  validation loss:		0.373570
  validation accuracy:		93.48 %
Epoch 1232 of 2000 took 0.110s
  training loss:		0.012683
  validation loss:		0.370057
  validation accuracy:		93.59 %
Epoch 1233 of 2000 took 0.076s
  training loss:		0.012691
  validation loss:		0.378879
  validation accuracy:		93.15 %
Epoch 1234 of 2000 took 0.053s
  training loss:		0.012948
  validation loss:		0.363631
  validation accuracy:		93.70 %
Epoch 1235 of 2000 took 0.054s
  training loss:		0.012852
  validation loss:		0.366110
  validation accuracy:		93.70 %
Epoch 1236 of 2000 took 0.098s
  training loss:		0.012939
  validation loss:		0.367478
  validation accuracy:		93.37 %
Epoch 1237 of 2000 took 0.058s
  training loss:		0.013076
  validation loss:		0.370532
  validation accuracy:		93.70 %
Epoch 1238 of 2000 took 0.058s
  training loss:		0.013030
  validation loss:		0.361836
  validation accuracy:		93.80 %
Epoch 1239 of 2000 took 0.131s
  training loss:		0.012545
  validation loss:		0.375531
  validation accuracy:		93.37 %
Epoch 1240 of 2000 took 0.105s
  training loss:		0.013278
  validation loss:		0.370905
  validation accuracy:		93.70 %
Epoch 1241 of 2000 took 0.105s
  training loss:		0.012878
  validation loss:		0.376705
  validation accuracy:		93.37 %
Epoch 1242 of 2000 took 0.092s
  training loss:		0.012395
  validation loss:		0.370266
  validation accuracy:		93.59 %
Epoch 1243 of 2000 took 0.052s
  training loss:		0.012332
  validation loss:		0.377367
  validation accuracy:		93.59 %
Epoch 1244 of 2000 took 0.052s
  training loss:		0.012297
  validation loss:		0.368138
  validation accuracy:		93.59 %
Epoch 1245 of 2000 took 0.050s
  training loss:		0.012853
  validation loss:		0.374497
  validation accuracy:		93.48 %
Epoch 1246 of 2000 took 0.050s
  training loss:		0.012309
  validation loss:		0.371167
  validation accuracy:		93.48 %
Epoch 1247 of 2000 took 0.050s
  training loss:		0.012636
  validation loss:		0.373986
  validation accuracy:		93.59 %
Epoch 1248 of 2000 took 0.076s
  training loss:		0.012447
  validation loss:		0.366581
  validation accuracy:		93.70 %
Epoch 1249 of 2000 took 0.154s
  training loss:		0.012526
  validation loss:		0.371491
  validation accuracy:		93.59 %
Epoch 1250 of 2000 took 0.124s
  training loss:		0.012619
  validation loss:		0.379704
  validation accuracy:		93.26 %
Epoch 1251 of 2000 took 0.115s
  training loss:		0.012420
  validation loss:		0.366799
  validation accuracy:		93.59 %
Epoch 1252 of 2000 took 0.106s
  training loss:		0.012700
  validation loss:		0.380653
  validation accuracy:		93.26 %
Epoch 1253 of 2000 took 0.126s
  training loss:		0.012596
  validation loss:		0.370575
  validation accuracy:		93.70 %
Epoch 1254 of 2000 took 0.161s
  training loss:		0.011976
  validation loss:		0.383790
  validation accuracy:		93.37 %
Epoch 1255 of 2000 took 0.159s
  training loss:		0.012398
  validation loss:		0.372291
  validation accuracy:		93.59 %
Epoch 1256 of 2000 took 0.150s
  training loss:		0.012361
  validation loss:		0.376285
  validation accuracy:		93.59 %
Epoch 1257 of 2000 took 0.094s
  training loss:		0.012668
  validation loss:		0.376623
  validation accuracy:		93.37 %
Epoch 1258 of 2000 took 0.104s
  training loss:		0.011994
  validation loss:		0.370501
  validation accuracy:		93.70 %
Epoch 1259 of 2000 took 0.112s
  training loss:		0.012020
  validation loss:		0.374031
  validation accuracy:		93.59 %
Epoch 1260 of 2000 took 0.103s
  training loss:		0.012225
  validation loss:		0.375975
  validation accuracy:		93.37 %
Epoch 1261 of 2000 took 0.128s
  training loss:		0.012105
  validation loss:		0.368296
  validation accuracy:		93.70 %
Epoch 1262 of 2000 took 0.184s
  training loss:		0.011529
  validation loss:		0.372668
  validation accuracy:		93.59 %
Epoch 1263 of 2000 took 0.166s
  training loss:		0.012153
  validation loss:		0.370859
  validation accuracy:		93.59 %
Epoch 1264 of 2000 took 0.099s
  training loss:		0.011651
  validation loss:		0.369906
  validation accuracy:		93.59 %
Epoch 1265 of 2000 took 0.135s
  training loss:		0.011948
  validation loss:		0.380082
  validation accuracy:		93.37 %
Epoch 1266 of 2000 took 0.121s
  training loss:		0.011999
  validation loss:		0.369960
  validation accuracy:		93.70 %
Epoch 1267 of 2000 took 0.171s
  training loss:		0.011950
  validation loss:		0.376862
  validation accuracy:		93.48 %
Epoch 1268 of 2000 took 0.142s
  training loss:		0.012216
  validation loss:		0.379768
  validation accuracy:		93.48 %
Epoch 1269 of 2000 took 0.180s
  training loss:		0.011540
  validation loss:		0.376994
  validation accuracy:		93.59 %
Epoch 1270 of 2000 took 0.199s
  training loss:		0.012427
  validation loss:		0.375147
  validation accuracy:		93.70 %
Epoch 1271 of 2000 took 0.175s
  training loss:		0.012119
  validation loss:		0.371399
  validation accuracy:		93.59 %
Epoch 1272 of 2000 took 0.245s
  training loss:		0.012435
  validation loss:		0.382038
  validation accuracy:		93.59 %
Epoch 1273 of 2000 took 0.175s
  training loss:		0.012053
  validation loss:		0.377679
  validation accuracy:		93.59 %
Epoch 1274 of 2000 took 0.157s
  training loss:		0.012239
  validation loss:		0.368998
  validation accuracy:		93.91 %
Epoch 1275 of 2000 took 0.209s
  training loss:		0.011910
  validation loss:		0.382642
  validation accuracy:		93.48 %
Epoch 1276 of 2000 took 0.239s
  training loss:		0.011982
  validation loss:		0.372532
  validation accuracy:		93.70 %
Epoch 1277 of 2000 took 0.159s
  training loss:		0.011959
  validation loss:		0.376605
  validation accuracy:		93.70 %
Epoch 1278 of 2000 took 0.185s
  training loss:		0.011919
  validation loss:		0.382646
  validation accuracy:		93.48 %
Epoch 1279 of 2000 took 0.182s
  training loss:		0.011879
  validation loss:		0.375414
  validation accuracy:		93.48 %
Epoch 1280 of 2000 took 0.180s
  training loss:		0.011351
  validation loss:		0.389341
  validation accuracy:		93.04 %
Epoch 1281 of 2000 took 0.183s
  training loss:		0.011690
  validation loss:		0.375827
  validation accuracy:		93.48 %
Epoch 1282 of 2000 took 0.177s
  training loss:		0.011449
  validation loss:		0.380951
  validation accuracy:		93.48 %
Epoch 1283 of 2000 took 0.205s
  training loss:		0.011472
  validation loss:		0.374304
  validation accuracy:		93.48 %
Epoch 1284 of 2000 took 0.154s
  training loss:		0.011320
  validation loss:		0.385593
  validation accuracy:		93.37 %
Epoch 1285 of 2000 took 0.211s
  training loss:		0.011459
  validation loss:		0.380400
  validation accuracy:		93.37 %
Epoch 1286 of 2000 took 0.157s
  training loss:		0.011725
  validation loss:		0.380061
  validation accuracy:		93.48 %
Epoch 1287 of 2000 took 0.177s
  training loss:		0.012001
  validation loss:		0.370700
  validation accuracy:		93.70 %
Epoch 1288 of 2000 took 0.128s
  training loss:		0.011684
  validation loss:		0.380401
  validation accuracy:		93.48 %
Epoch 1289 of 2000 took 0.191s
  training loss:		0.011547
  validation loss:		0.376964
  validation accuracy:		93.70 %
Epoch 1290 of 2000 took 0.193s
  training loss:		0.011839
  validation loss:		0.375325
  validation accuracy:		93.59 %
Epoch 1291 of 2000 took 0.202s
  training loss:		0.010890
  validation loss:		0.380738
  validation accuracy:		93.37 %
Epoch 1292 of 2000 took 0.170s
  training loss:		0.011224
  validation loss:		0.382665
  validation accuracy:		93.59 %
Epoch 1293 of 2000 took 0.191s
  training loss:		0.011342
  validation loss:		0.386090
  validation accuracy:		93.15 %
Epoch 1294 of 2000 took 0.173s
  training loss:		0.011459
  validation loss:		0.384635
  validation accuracy:		93.48 %
Epoch 1295 of 2000 took 0.179s
  training loss:		0.011852
  validation loss:		0.383481
  validation accuracy:		93.48 %
Epoch 1296 of 2000 took 0.197s
  training loss:		0.011674
  validation loss:		0.381433
  validation accuracy:		93.59 %
Epoch 1297 of 2000 took 0.150s
  training loss:		0.010610
  validation loss:		0.388411
  validation accuracy:		93.37 %
Epoch 1298 of 2000 took 0.165s
  training loss:		0.011469
  validation loss:		0.383081
  validation accuracy:		93.37 %
Epoch 1299 of 2000 took 0.128s
  training loss:		0.011225
  validation loss:		0.380860
  validation accuracy:		93.70 %
Epoch 1300 of 2000 took 0.122s
  training loss:		0.011251
  validation loss:		0.392463
  validation accuracy:		93.48 %
Epoch 1301 of 2000 took 0.141s
  training loss:		0.011347
  validation loss:		0.379970
  validation accuracy:		93.48 %
Epoch 1302 of 2000 took 0.214s
  training loss:		0.010883
  validation loss:		0.394024
  validation accuracy:		93.04 %
Epoch 1303 of 2000 took 0.154s
  training loss:		0.011787
  validation loss:		0.391907
  validation accuracy:		93.48 %
Epoch 1304 of 2000 took 0.200s
  training loss:		0.011403
  validation loss:		0.387909
  validation accuracy:		93.48 %
Epoch 1305 of 2000 took 0.197s
  training loss:		0.011014
  validation loss:		0.393610
  validation accuracy:		93.15 %
Epoch 1306 of 2000 took 0.123s
  training loss:		0.011293
  validation loss:		0.386958
  validation accuracy:		93.37 %
Epoch 1307 of 2000 took 0.077s
  training loss:		0.010919
  validation loss:		0.393330
  validation accuracy:		93.26 %
Epoch 1308 of 2000 took 0.067s
  training loss:		0.011127
  validation loss:		0.389760
  validation accuracy:		93.26 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.011104
  validation loss:		0.389757
  validation accuracy:		93.26 %
Epoch 1310 of 2000 took 0.116s
  training loss:		0.011043
  validation loss:		0.388753
  validation accuracy:		93.59 %
Epoch 1311 of 2000 took 0.110s
  training loss:		0.011070
  validation loss:		0.387254
  validation accuracy:		93.48 %
Epoch 1312 of 2000 took 0.110s
  training loss:		0.011092
  validation loss:		0.389963
  validation accuracy:		93.37 %
Epoch 1313 of 2000 took 0.117s
  training loss:		0.011118
  validation loss:		0.394655
  validation accuracy:		93.26 %
Epoch 1314 of 2000 took 0.125s
  training loss:		0.010914
  validation loss:		0.401317
  validation accuracy:		93.15 %
Epoch 1315 of 2000 took 0.137s
  training loss:		0.011062
  validation loss:		0.387881
  validation accuracy:		93.37 %
Epoch 1316 of 2000 took 0.116s
  training loss:		0.010803
  validation loss:		0.388520
  validation accuracy:		93.37 %
Epoch 1317 of 2000 took 0.112s
  training loss:		0.010913
  validation loss:		0.388213
  validation accuracy:		93.59 %
Epoch 1318 of 2000 took 0.111s
  training loss:		0.010352
  validation loss:		0.377937
  validation accuracy:		93.70 %
Epoch 1319 of 2000 took 0.132s
  training loss:		0.010948
  validation loss:		0.389257
  validation accuracy:		93.37 %
Epoch 1320 of 2000 took 0.148s
  training loss:		0.011150
  validation loss:		0.391770
  validation accuracy:		93.37 %
Epoch 1321 of 2000 took 0.124s
  training loss:		0.010777
  validation loss:		0.380734
  validation accuracy:		93.70 %
Epoch 1322 of 2000 took 0.126s
  training loss:		0.010843
  validation loss:		0.380445
  validation accuracy:		93.70 %
Epoch 1323 of 2000 took 0.157s
  training loss:		0.010265
  validation loss:		0.391687
  validation accuracy:		93.48 %
Epoch 1324 of 2000 took 0.182s
  training loss:		0.010713
  validation loss:		0.382211
  validation accuracy:		93.59 %
Epoch 1325 of 2000 took 0.143s
  training loss:		0.011072
  validation loss:		0.384200
  validation accuracy:		93.48 %
Epoch 1326 of 2000 took 0.155s
  training loss:		0.010323
  validation loss:		0.388685
  validation accuracy:		93.48 %
Epoch 1327 of 2000 took 0.151s
  training loss:		0.010849
  validation loss:		0.383352
  validation accuracy:		93.37 %
Epoch 1328 of 2000 took 0.141s
  training loss:		0.010656
  validation loss:		0.386374
  validation accuracy:		93.70 %
Epoch 1329 of 2000 took 0.185s
  training loss:		0.010734
  validation loss:		0.395342
  validation accuracy:		93.70 %
Epoch 1330 of 2000 took 0.183s
  training loss:		0.010404
  validation loss:		0.392902
  validation accuracy:		93.59 %
Epoch 1331 of 2000 took 0.155s
  training loss:		0.010574
  validation loss:		0.388478
  validation accuracy:		93.70 %
Epoch 1332 of 2000 took 0.143s
  training loss:		0.010796
  validation loss:		0.383603
  validation accuracy:		93.48 %
Epoch 1333 of 2000 took 0.158s
  training loss:		0.010806
  validation loss:		0.393929
  validation accuracy:		93.48 %
Epoch 1334 of 2000 took 0.152s
  training loss:		0.010535
  validation loss:		0.391537
  validation accuracy:		93.48 %
Epoch 1335 of 2000 took 0.184s
  training loss:		0.010500
  validation loss:		0.393484
  validation accuracy:		93.26 %
Epoch 1336 of 2000 took 0.185s
  training loss:		0.010601
  validation loss:		0.385334
  validation accuracy:		93.48 %
Epoch 1337 of 2000 took 0.181s
  training loss:		0.010206
  validation loss:		0.397103
  validation accuracy:		93.37 %
Epoch 1338 of 2000 took 0.174s
  training loss:		0.010239
  validation loss:		0.386055
  validation accuracy:		93.48 %
Epoch 1339 of 2000 took 0.148s
  training loss:		0.010398
  validation loss:		0.395074
  validation accuracy:		93.48 %
Epoch 1340 of 2000 took 0.171s
  training loss:		0.010394
  validation loss:		0.391680
  validation accuracy:		93.37 %
Epoch 1341 of 2000 took 0.180s
  training loss:		0.010507
  validation loss:		0.393970
  validation accuracy:		93.48 %
Epoch 1342 of 2000 took 0.180s
  training loss:		0.010622
  validation loss:		0.394172
  validation accuracy:		93.15 %
Epoch 1343 of 2000 took 0.180s
  training loss:		0.009941
  validation loss:		0.399548
  validation accuracy:		93.15 %
Epoch 1344 of 2000 took 0.174s
  training loss:		0.010203
  validation loss:		0.389263
  validation accuracy:		93.37 %
Epoch 1345 of 2000 took 0.151s
  training loss:		0.010401
  validation loss:		0.395168
  validation accuracy:		93.48 %
Epoch 1346 of 2000 took 0.149s
  training loss:		0.010576
  validation loss:		0.396502
  validation accuracy:		93.70 %
Epoch 1347 of 2000 took 0.185s
  training loss:		0.010677
  validation loss:		0.396735
  validation accuracy:		93.59 %
Epoch 1348 of 2000 took 0.180s
  training loss:		0.010349
  validation loss:		0.386324
  validation accuracy:		93.48 %
Epoch 1349 of 2000 took 0.181s
  training loss:		0.010570
  validation loss:		0.392430
  validation accuracy:		93.48 %
Epoch 1350 of 2000 took 0.181s
  training loss:		0.010026
  validation loss:		0.393224
  validation accuracy:		93.59 %
Epoch 1351 of 2000 took 0.155s
  training loss:		0.010046
  validation loss:		0.398456
  validation accuracy:		93.37 %
Epoch 1352 of 2000 took 0.144s
  training loss:		0.010032
  validation loss:		0.388664
  validation accuracy:		93.70 %
Epoch 1353 of 2000 took 0.151s
  training loss:		0.009836
  validation loss:		0.392250
  validation accuracy:		93.48 %
Epoch 1354 of 2000 took 0.156s
  training loss:		0.009732
  validation loss:		0.390388
  validation accuracy:		93.48 %
Epoch 1355 of 2000 took 0.179s
  training loss:		0.009955
  validation loss:		0.393099
  validation accuracy:		93.59 %
Epoch 1356 of 2000 took 0.152s
  training loss:		0.009863
  validation loss:		0.392197
  validation accuracy:		93.59 %
Epoch 1357 of 2000 took 0.153s
  training loss:		0.010540
  validation loss:		0.395040
  validation accuracy:		93.59 %
Epoch 1358 of 2000 took 0.155s
  training loss:		0.010001
  validation loss:		0.394162
  validation accuracy:		93.48 %
Epoch 1359 of 2000 took 0.152s
  training loss:		0.009686
  validation loss:		0.405173
  validation accuracy:		93.15 %
Epoch 1360 of 2000 took 0.144s
  training loss:		0.010018
  validation loss:		0.394910
  validation accuracy:		93.59 %
Epoch 1361 of 2000 took 0.153s
  training loss:		0.009980
  validation loss:		0.398461
  validation accuracy:		93.37 %
Epoch 1362 of 2000 took 0.146s
  training loss:		0.010085
  validation loss:		0.395704
  validation accuracy:		93.70 %
Epoch 1363 of 2000 took 0.151s
  training loss:		0.009598
  validation loss:		0.400993
  validation accuracy:		93.37 %
Epoch 1364 of 2000 took 0.141s
  training loss:		0.010094
  validation loss:		0.405347
  validation accuracy:		93.04 %
Epoch 1365 of 2000 took 0.142s
  training loss:		0.009894
  validation loss:		0.395692
  validation accuracy:		93.48 %
Epoch 1366 of 2000 took 0.175s
  training loss:		0.009747
  validation loss:		0.390018
  validation accuracy:		93.37 %
Epoch 1367 of 2000 took 0.171s
  training loss:		0.009577
  validation loss:		0.400980
  validation accuracy:		93.59 %
Epoch 1368 of 2000 took 0.141s
  training loss:		0.009552
  validation loss:		0.400508
  validation accuracy:		93.48 %
Epoch 1369 of 2000 took 0.145s
  training loss:		0.009829
  validation loss:		0.393786
  validation accuracy:		93.48 %
Epoch 1370 of 2000 took 0.152s
  training loss:		0.009748
  validation loss:		0.403824
  validation accuracy:		93.48 %
Epoch 1371 of 2000 took 0.186s
  training loss:		0.009707
  validation loss:		0.405013
  validation accuracy:		93.70 %
Epoch 1372 of 2000 took 0.178s
  training loss:		0.009775
  validation loss:		0.406627
  validation accuracy:		93.15 %
Epoch 1373 of 2000 took 0.169s
  training loss:		0.009532
  validation loss:		0.398701
  validation accuracy:		93.48 %
Epoch 1374 of 2000 took 0.148s
  training loss:		0.009676
  validation loss:		0.403277
  validation accuracy:		93.37 %
Epoch 1375 of 2000 took 0.143s
  training loss:		0.009529
  validation loss:		0.403419
  validation accuracy:		93.37 %
Epoch 1376 of 2000 took 0.151s
  training loss:		0.009117
  validation loss:		0.393508
  validation accuracy:		93.48 %
Epoch 1377 of 2000 took 0.151s
  training loss:		0.009457
  validation loss:		0.398540
  validation accuracy:		93.48 %
Epoch 1378 of 2000 took 0.152s
  training loss:		0.009783
  validation loss:		0.409719
  validation accuracy:		93.26 %
Epoch 1379 of 2000 took 0.177s
  training loss:		0.009753
  validation loss:		0.395005
  validation accuracy:		93.48 %
Epoch 1380 of 2000 took 0.149s
  training loss:		0.009689
  validation loss:		0.397324
  validation accuracy:		93.59 %
Epoch 1381 of 2000 took 0.178s
  training loss:		0.009414
  validation loss:		0.403236
  validation accuracy:		93.48 %
Epoch 1382 of 2000 took 0.139s
  training loss:		0.009888
  validation loss:		0.396556
  validation accuracy:		93.37 %
Epoch 1383 of 2000 took 0.138s
  training loss:		0.009545
  validation loss:		0.393476
  validation accuracy:		93.48 %
Epoch 1384 of 2000 took 0.135s
  training loss:		0.009716
  validation loss:		0.402539
  validation accuracy:		93.37 %
Epoch 1385 of 2000 took 0.148s
  training loss:		0.009396
  validation loss:		0.409732
  validation accuracy:		93.26 %
Epoch 1386 of 2000 took 0.139s
  training loss:		0.009813
  validation loss:		0.402746
  validation accuracy:		93.26 %
Epoch 1387 of 2000 took 0.138s
  training loss:		0.009172
  validation loss:		0.398220
  validation accuracy:		93.37 %
Epoch 1388 of 2000 took 0.148s
  training loss:		0.009517
  validation loss:		0.406263
  validation accuracy:		93.26 %
Epoch 1389 of 2000 took 0.148s
  training loss:		0.009528
  validation loss:		0.402536
  validation accuracy:		93.70 %
Epoch 1390 of 2000 took 0.137s
  training loss:		0.009518
  validation loss:		0.405348
  validation accuracy:		93.37 %
Epoch 1391 of 2000 took 0.149s
  training loss:		0.009497
  validation loss:		0.404574
  validation accuracy:		93.48 %
Epoch 1392 of 2000 took 0.140s
  training loss:		0.009146
  validation loss:		0.407075
  validation accuracy:		93.48 %
Epoch 1393 of 2000 took 0.152s
  training loss:		0.009186
  validation loss:		0.399898
  validation accuracy:		93.26 %
Epoch 1394 of 2000 took 0.151s
  training loss:		0.009203
  validation loss:		0.413004
  validation accuracy:		93.15 %
Epoch 1395 of 2000 took 0.183s
  training loss:		0.009385
  validation loss:		0.413900
  validation accuracy:		93.26 %
Epoch 1396 of 2000 took 0.171s
  training loss:		0.009375
  validation loss:		0.396220
  validation accuracy:		93.59 %
Epoch 1397 of 2000 took 0.175s
  training loss:		0.009489
  validation loss:		0.403334
  validation accuracy:		93.48 %
Epoch 1398 of 2000 took 0.182s
  training loss:		0.009354
  validation loss:		0.406813
  validation accuracy:		93.48 %
Epoch 1399 of 2000 took 0.139s
  training loss:		0.009099
  validation loss:		0.399528
  validation accuracy:		93.48 %
Epoch 1400 of 2000 took 0.143s
  training loss:		0.009204
  validation loss:		0.407240
  validation accuracy:		93.37 %
Epoch 1401 of 2000 took 0.148s
  training loss:		0.009594
  validation loss:		0.400323
  validation accuracy:		93.59 %
Epoch 1402 of 2000 took 0.146s
  training loss:		0.008873
  validation loss:		0.401099
  validation accuracy:		93.48 %
Epoch 1403 of 2000 took 0.156s
  training loss:		0.009215
  validation loss:		0.413222
  validation accuracy:		93.04 %
Epoch 1404 of 2000 took 0.156s
  training loss:		0.009388
  validation loss:		0.409071
  validation accuracy:		93.15 %
Epoch 1405 of 2000 took 0.182s
  training loss:		0.009315
  validation loss:		0.406063
  validation accuracy:		93.48 %
Epoch 1406 of 2000 took 0.185s
  training loss:		0.009035
  validation loss:		0.406725
  validation accuracy:		93.37 %
Epoch 1407 of 2000 took 0.162s
  training loss:		0.009213
  validation loss:		0.408417
  validation accuracy:		93.37 %
Epoch 1408 of 2000 took 0.141s
  training loss:		0.009193
  validation loss:		0.405943
  validation accuracy:		93.26 %
Epoch 1409 of 2000 took 0.155s
  training loss:		0.008943
  validation loss:		0.405435
  validation accuracy:		93.26 %
Epoch 1410 of 2000 took 0.137s
  training loss:		0.009088
  validation loss:		0.411401
  validation accuracy:		93.37 %
Epoch 1411 of 2000 took 0.143s
  training loss:		0.009060
  validation loss:		0.418468
  validation accuracy:		93.26 %
Epoch 1412 of 2000 took 0.134s
  training loss:		0.009462
  validation loss:		0.405657
  validation accuracy:		93.48 %
Epoch 1413 of 2000 took 0.179s
  training loss:		0.008777
  validation loss:		0.411245
  validation accuracy:		93.37 %
Epoch 1414 of 2000 took 0.174s
  training loss:		0.009018
  validation loss:		0.416083
  validation accuracy:		93.26 %
Epoch 1415 of 2000 took 0.136s
  training loss:		0.009367
  validation loss:		0.410427
  validation accuracy:		93.37 %
Epoch 1416 of 2000 took 0.140s
  training loss:		0.009244
  validation loss:		0.408368
  validation accuracy:		93.48 %
Epoch 1417 of 2000 took 0.155s
  training loss:		0.008962
  validation loss:		0.415361
  validation accuracy:		93.37 %
Epoch 1418 of 2000 took 0.139s
  training loss:		0.008992
  validation loss:		0.409712
  validation accuracy:		93.48 %
Epoch 1419 of 2000 took 0.142s
  training loss:		0.008959
  validation loss:		0.404700
  validation accuracy:		93.48 %
Epoch 1420 of 2000 took 0.142s
  training loss:		0.008913
  validation loss:		0.405316
  validation accuracy:		93.48 %
Epoch 1421 of 2000 took 0.151s
  training loss:		0.008942
  validation loss:		0.407760
  validation accuracy:		93.59 %
Epoch 1422 of 2000 took 0.140s
  training loss:		0.008928
  validation loss:		0.404134
  validation accuracy:		93.70 %
Epoch 1423 of 2000 took 0.180s
  training loss:		0.008495
  validation loss:		0.413172
  validation accuracy:		93.48 %
Epoch 1424 of 2000 took 0.158s
  training loss:		0.008908
  validation loss:		0.408282
  validation accuracy:		93.59 %
Epoch 1425 of 2000 took 0.170s
  training loss:		0.008486
  validation loss:		0.410739
  validation accuracy:		93.37 %
Epoch 1426 of 2000 took 0.189s
  training loss:		0.008849
  validation loss:		0.412030
  validation accuracy:		93.48 %
Epoch 1427 of 2000 took 0.173s
  training loss:		0.009068
  validation loss:		0.409013
  validation accuracy:		93.48 %
Epoch 1428 of 2000 took 0.182s
  training loss:		0.008944
  validation loss:		0.407400
  validation accuracy:		93.37 %
Epoch 1429 of 2000 took 0.154s
  training loss:		0.008698
  validation loss:		0.407561
  validation accuracy:		93.70 %
Epoch 1430 of 2000 took 0.185s
  training loss:		0.008340
  validation loss:		0.407986
  validation accuracy:		93.59 %
Epoch 1431 of 2000 took 0.171s
  training loss:		0.008516
  validation loss:		0.412595
  validation accuracy:		93.48 %
Epoch 1432 of 2000 took 0.171s
  training loss:		0.008740
  validation loss:		0.410749
  validation accuracy:		93.37 %
Epoch 1433 of 2000 took 0.183s
  training loss:		0.008312
  validation loss:		0.412271
  validation accuracy:		93.37 %
Epoch 1434 of 2000 took 0.180s
  training loss:		0.008600
  validation loss:		0.413807
  validation accuracy:		93.15 %
Epoch 1435 of 2000 took 0.182s
  training loss:		0.008891
  validation loss:		0.412982
  validation accuracy:		93.59 %
Epoch 1436 of 2000 took 0.183s
  training loss:		0.008303
  validation loss:		0.408119
  validation accuracy:		93.48 %
Epoch 1437 of 2000 took 0.172s
  training loss:		0.008881
  validation loss:		0.414494
  validation accuracy:		93.37 %
Epoch 1438 of 2000 took 0.155s
  training loss:		0.008871
  validation loss:		0.412664
  validation accuracy:		93.37 %
Epoch 1439 of 2000 took 0.136s
  training loss:		0.008546
  validation loss:		0.408661
  validation accuracy:		93.48 %
Epoch 1440 of 2000 took 0.147s
  training loss:		0.008697
  validation loss:		0.415175
  validation accuracy:		93.26 %
Epoch 1441 of 2000 took 0.142s
  training loss:		0.008413
  validation loss:		0.419185
  validation accuracy:		93.48 %
Epoch 1442 of 2000 took 0.160s
  training loss:		0.008422
  validation loss:		0.408628
  validation accuracy:		93.48 %
Epoch 1443 of 2000 took 0.141s
  training loss:		0.008707
  validation loss:		0.413445
  validation accuracy:		93.48 %
Epoch 1444 of 2000 took 0.149s
  training loss:		0.008444
  validation loss:		0.418455
  validation accuracy:		93.26 %
Epoch 1445 of 2000 took 0.143s
  training loss:		0.008489
  validation loss:		0.415580
  validation accuracy:		93.26 %
Epoch 1446 of 2000 took 0.185s
  training loss:		0.008363
  validation loss:		0.412013
  validation accuracy:		93.48 %
Epoch 1447 of 2000 took 0.174s
  training loss:		0.008931
  validation loss:		0.412737
  validation accuracy:		93.37 %
Epoch 1448 of 2000 took 0.145s
  training loss:		0.008223
  validation loss:		0.417264
  validation accuracy:		93.70 %
Epoch 1449 of 2000 took 0.146s
  training loss:		0.008090
  validation loss:		0.410838
  validation accuracy:		93.70 %
Epoch 1450 of 2000 took 0.145s
  training loss:		0.008506
  validation loss:		0.410361
  validation accuracy:		93.59 %
Epoch 1451 of 2000 took 0.149s
  training loss:		0.008500
  validation loss:		0.411865
  validation accuracy:		93.48 %
Epoch 1452 of 2000 took 0.168s
  training loss:		0.008437
  validation loss:		0.415990
  validation accuracy:		93.70 %
Epoch 1453 of 2000 took 0.182s
  training loss:		0.008229
  validation loss:		0.413105
  validation accuracy:		93.59 %
Epoch 1454 of 2000 took 0.179s
  training loss:		0.008227
  validation loss:		0.422731
  validation accuracy:		93.15 %
Epoch 1455 of 2000 took 0.177s
  training loss:		0.008540
  validation loss:		0.428188
  validation accuracy:		93.26 %
Epoch 1456 of 2000 took 0.160s
  training loss:		0.008238
  validation loss:		0.413030
  validation accuracy:		93.37 %
Epoch 1457 of 2000 took 0.142s
  training loss:		0.008389
  validation loss:		0.417777
  validation accuracy:		93.48 %
Epoch 1458 of 2000 took 0.141s
  training loss:		0.008126
  validation loss:		0.414680
  validation accuracy:		93.59 %
Epoch 1459 of 2000 took 0.180s
  training loss:		0.008487
  validation loss:		0.418216
  validation accuracy:		93.04 %
Epoch 1460 of 2000 took 0.183s
  training loss:		0.008280
  validation loss:		0.423083
  validation accuracy:		93.48 %
Epoch 1461 of 2000 took 0.155s
  training loss:		0.008127
  validation loss:		0.407238
  validation accuracy:		93.59 %
Epoch 1462 of 2000 took 0.148s
  training loss:		0.008389
  validation loss:		0.425760
  validation accuracy:		93.26 %
Epoch 1463 of 2000 took 0.139s
  training loss:		0.007965
  validation loss:		0.420832
  validation accuracy:		93.37 %
Epoch 1464 of 2000 took 0.149s
  training loss:		0.008245
  validation loss:		0.413298
  validation accuracy:		93.26 %
Epoch 1465 of 2000 took 0.141s
  training loss:		0.008071
  validation loss:		0.414123
  validation accuracy:		93.48 %
Epoch 1466 of 2000 took 0.135s
  training loss:		0.008399
  validation loss:		0.420345
  validation accuracy:		93.37 %
Epoch 1467 of 2000 took 0.146s
  training loss:		0.008259
  validation loss:		0.415713
  validation accuracy:		93.26 %
Epoch 1468 of 2000 took 0.132s
  training loss:		0.008189
  validation loss:		0.426104
  validation accuracy:		93.26 %
Epoch 1469 of 2000 took 0.148s
  training loss:		0.008009
  validation loss:		0.419427
  validation accuracy:		93.37 %
Epoch 1470 of 2000 took 0.148s
  training loss:		0.008074
  validation loss:		0.410668
  validation accuracy:		93.37 %
Epoch 1471 of 2000 took 0.141s
  training loss:		0.008351
  validation loss:		0.422557
  validation accuracy:		93.59 %
Epoch 1472 of 2000 took 0.144s
  training loss:		0.007902
  validation loss:		0.417978
  validation accuracy:		93.80 %
Epoch 1473 of 2000 took 0.152s
  training loss:		0.007924
  validation loss:		0.422068
  validation accuracy:		93.37 %
Epoch 1474 of 2000 took 0.146s
  training loss:		0.007894
  validation loss:		0.416423
  validation accuracy:		93.59 %
Epoch 1475 of 2000 took 0.143s
  training loss:		0.008056
  validation loss:		0.425436
  validation accuracy:		93.26 %
Epoch 1476 of 2000 took 0.143s
  training loss:		0.008095
  validation loss:		0.416680
  validation accuracy:		93.59 %
Epoch 1477 of 2000 took 0.152s
  training loss:		0.008008
  validation loss:		0.423659
  validation accuracy:		93.37 %
Epoch 1478 of 2000 took 0.166s
  training loss:		0.008067
  validation loss:		0.423290
  validation accuracy:		93.26 %
Epoch 1479 of 2000 took 0.178s
  training loss:		0.007999
  validation loss:		0.422812
  validation accuracy:		93.59 %
Epoch 1480 of 2000 took 0.183s
  training loss:		0.008081
  validation loss:		0.418898
  validation accuracy:		93.37 %
Epoch 1481 of 2000 took 0.160s
  training loss:		0.007985
  validation loss:		0.427846
  validation accuracy:		93.37 %
Epoch 1482 of 2000 took 0.167s
  training loss:		0.007944
  validation loss:		0.421368
  validation accuracy:		93.37 %
Epoch 1483 of 2000 took 0.138s
  training loss:		0.007467
  validation loss:		0.421009
  validation accuracy:		93.59 %
Epoch 1484 of 2000 took 0.152s
  training loss:		0.007817
  validation loss:		0.414135
  validation accuracy:		93.70 %
Epoch 1485 of 2000 took 0.162s
  training loss:		0.008002
  validation loss:		0.427866
  validation accuracy:		93.15 %
Epoch 1486 of 2000 took 0.143s
  training loss:		0.007574
  validation loss:		0.416492
  validation accuracy:		93.59 %
Epoch 1487 of 2000 took 0.133s
  training loss:		0.007558
  validation loss:		0.428702
  validation accuracy:		93.48 %
Epoch 1488 of 2000 took 0.156s
  training loss:		0.007662
  validation loss:		0.422911
  validation accuracy:		93.59 %
Epoch 1489 of 2000 took 0.155s
  training loss:		0.007938
  validation loss:		0.423357
  validation accuracy:		93.37 %
Epoch 1490 of 2000 took 0.155s
  training loss:		0.007803
  validation loss:		0.421779
  validation accuracy:		93.37 %
Epoch 1491 of 2000 took 0.144s
  training loss:		0.007920
  validation loss:		0.419546
  validation accuracy:		93.37 %
Epoch 1492 of 2000 took 0.142s
  training loss:		0.007797
  validation loss:		0.424688
  validation accuracy:		93.15 %
Epoch 1493 of 2000 took 0.145s
  training loss:		0.007518
  validation loss:		0.429240
  validation accuracy:		93.26 %
Epoch 1494 of 2000 took 0.179s
  training loss:		0.007788
  validation loss:		0.421237
  validation accuracy:		93.70 %
Epoch 1495 of 2000 took 0.147s
  training loss:		0.007673
  validation loss:		0.428651
  validation accuracy:		93.26 %
Epoch 1496 of 2000 took 0.138s
  training loss:		0.007849
  validation loss:		0.432274
  validation accuracy:		93.15 %
Epoch 1497 of 2000 took 0.188s
  training loss:		0.007572
  validation loss:		0.416754
  validation accuracy:		93.70 %
Epoch 1498 of 2000 took 0.149s
  training loss:		0.007657
  validation loss:		0.428196
  validation accuracy:		93.59 %
Epoch 1499 of 2000 took 0.168s
  training loss:		0.007513
  validation loss:		0.421992
  validation accuracy:		93.70 %
Epoch 1500 of 2000 took 0.183s
  training loss:		0.007438
  validation loss:		0.430004
  validation accuracy:		93.15 %
Epoch 1501 of 2000 took 0.153s
  training loss:		0.007412
  validation loss:		0.430876
  validation accuracy:		93.15 %
Epoch 1502 of 2000 took 0.141s
  training loss:		0.007809
  validation loss:		0.431794
  validation accuracy:		93.37 %
Epoch 1503 of 2000 took 0.174s
  training loss:		0.007778
  validation loss:		0.428132
  validation accuracy:		93.26 %
Epoch 1504 of 2000 took 0.146s
  training loss:		0.007459
  validation loss:		0.425870
  validation accuracy:		93.37 %
Epoch 1505 of 2000 took 0.141s
  training loss:		0.007535
  validation loss:		0.431953
  validation accuracy:		93.15 %
Epoch 1506 of 2000 took 0.139s
  training loss:		0.007439
  validation loss:		0.426336
  validation accuracy:		93.59 %
Epoch 1507 of 2000 took 0.150s
  training loss:		0.007634
  validation loss:		0.431901
  validation accuracy:		92.93 %
Epoch 1508 of 2000 took 0.144s
  training loss:		0.007594
  validation loss:		0.431538
  validation accuracy:		93.70 %
Epoch 1509 of 2000 took 0.138s
  training loss:		0.007598
  validation loss:		0.427560
  validation accuracy:		93.26 %
Epoch 1510 of 2000 took 0.154s
  training loss:		0.007335
  validation loss:		0.425766
  validation accuracy:		93.37 %
Epoch 1511 of 2000 took 0.167s
  training loss:		0.007603
  validation loss:		0.426992
  validation accuracy:		93.48 %
Epoch 1512 of 2000 took 0.180s
  training loss:		0.007607
  validation loss:		0.436764
  validation accuracy:		93.15 %
Epoch 1513 of 2000 took 0.181s
  training loss:		0.007765
  validation loss:		0.431328
  validation accuracy:		93.26 %
Epoch 1514 of 2000 took 0.166s
  training loss:		0.007725
  validation loss:		0.429615
  validation accuracy:		93.37 %
Epoch 1515 of 2000 took 0.179s
  training loss:		0.007343
  validation loss:		0.429909
  validation accuracy:		93.26 %
Epoch 1516 of 2000 took 0.184s
  training loss:		0.007507
  validation loss:		0.430986
  validation accuracy:		93.48 %
Epoch 1517 of 2000 took 0.184s
  training loss:		0.007539
  validation loss:		0.437334
  validation accuracy:		93.15 %
Epoch 1518 of 2000 took 0.184s
  training loss:		0.007335
  validation loss:		0.425323
  validation accuracy:		93.48 %
Epoch 1519 of 2000 took 0.147s
  training loss:		0.007470
  validation loss:		0.430283
  validation accuracy:		93.26 %
Epoch 1520 of 2000 took 0.151s
  training loss:		0.007506
  validation loss:		0.428614
  validation accuracy:		93.26 %
Epoch 1521 of 2000 took 0.176s
  training loss:		0.007213
  validation loss:		0.428275
  validation accuracy:		93.48 %
Epoch 1522 of 2000 took 0.169s
  training loss:		0.007180
  validation loss:		0.427230
  validation accuracy:		93.48 %
Epoch 1523 of 2000 took 0.141s
  training loss:		0.007368
  validation loss:		0.429798
  validation accuracy:		93.48 %
Epoch 1524 of 2000 took 0.138s
  training loss:		0.007300
  validation loss:		0.424809
  validation accuracy:		93.48 %
Epoch 1525 of 2000 took 0.152s
  training loss:		0.007310
  validation loss:		0.425898
  validation accuracy:		93.48 %
Epoch 1526 of 2000 took 0.147s
  training loss:		0.007500
  validation loss:		0.427171
  validation accuracy:		93.59 %
Epoch 1527 of 2000 took 0.146s
  training loss:		0.007289
  validation loss:		0.432845
  validation accuracy:		93.37 %
Epoch 1528 of 2000 took 0.141s
  training loss:		0.007316
  validation loss:		0.435026
  validation accuracy:		93.37 %
Epoch 1529 of 2000 took 0.142s
  training loss:		0.007171
  validation loss:		0.433287
  validation accuracy:		93.26 %
Epoch 1530 of 2000 took 0.180s
  training loss:		0.007131
  validation loss:		0.430587
  validation accuracy:		93.37 %
Epoch 1531 of 2000 took 0.161s
  training loss:		0.007130
  validation loss:		0.435495
  validation accuracy:		93.48 %
Epoch 1532 of 2000 took 0.153s
  training loss:		0.007269
  validation loss:		0.432751
  validation accuracy:		93.37 %
Epoch 1533 of 2000 took 0.139s
  training loss:		0.007213
  validation loss:		0.432250
  validation accuracy:		93.37 %
Epoch 1534 of 2000 took 0.157s
  training loss:		0.007193
  validation loss:		0.432802
  validation accuracy:		93.37 %
Epoch 1535 of 2000 took 0.155s
  training loss:		0.006887
  validation loss:		0.430888
  validation accuracy:		93.59 %
Epoch 1536 of 2000 took 0.144s
  training loss:		0.007411
  validation loss:		0.427273
  validation accuracy:		93.59 %
Epoch 1537 of 2000 took 0.170s
  training loss:		0.007318
  validation loss:		0.432040
  validation accuracy:		93.26 %
Epoch 1538 of 2000 took 0.160s
  training loss:		0.007241
  validation loss:		0.436754
  validation accuracy:		93.26 %
Epoch 1539 of 2000 took 0.137s
  training loss:		0.007247
  validation loss:		0.432699
  validation accuracy:		93.37 %
Epoch 1540 of 2000 took 0.156s
  training loss:		0.007184
  validation loss:		0.433129
  validation accuracy:		93.48 %
Epoch 1541 of 2000 took 0.164s
  training loss:		0.007254
  validation loss:		0.428363
  validation accuracy:		93.48 %
Epoch 1542 of 2000 took 0.155s
  training loss:		0.007063
  validation loss:		0.438205
  validation accuracy:		93.48 %
Epoch 1543 of 2000 took 0.171s
  training loss:		0.007198
  validation loss:		0.435421
  validation accuracy:		93.37 %
Epoch 1544 of 2000 took 0.181s
  training loss:		0.007192
  validation loss:		0.431131
  validation accuracy:		93.48 %
Epoch 1545 of 2000 took 0.184s
  training loss:		0.006939
  validation loss:		0.433839
  validation accuracy:		93.48 %
Epoch 1546 of 2000 took 0.181s
  training loss:		0.007210
  validation loss:		0.421980
  validation accuracy:		93.70 %
Epoch 1547 of 2000 took 0.166s
  training loss:		0.007647
  validation loss:		0.438902
  validation accuracy:		93.15 %
Epoch 1548 of 2000 took 0.137s
  training loss:		0.006910
  validation loss:		0.438273
  validation accuracy:		93.26 %
Epoch 1549 of 2000 took 0.150s
  training loss:		0.006884
  validation loss:		0.429672
  validation accuracy:		93.48 %
Epoch 1550 of 2000 took 0.148s
  training loss:		0.006919
  validation loss:		0.445280
  validation accuracy:		93.26 %
Epoch 1551 of 2000 took 0.141s
  training loss:		0.007267
  validation loss:		0.429199
  validation accuracy:		93.48 %
Epoch 1552 of 2000 took 0.159s
  training loss:		0.007105
  validation loss:		0.444638
  validation accuracy:		93.15 %
Epoch 1553 of 2000 took 0.151s
  training loss:		0.007001
  validation loss:		0.433902
  validation accuracy:		93.37 %
Epoch 1554 of 2000 took 0.145s
  training loss:		0.006920
  validation loss:		0.433163
  validation accuracy:		93.48 %
Epoch 1555 of 2000 took 0.138s
  training loss:		0.006846
  validation loss:		0.434682
  validation accuracy:		93.26 %
Epoch 1556 of 2000 took 0.159s
  training loss:		0.006977
  validation loss:		0.435581
  validation accuracy:		93.37 %
Epoch 1557 of 2000 took 0.174s
  training loss:		0.006930
  validation loss:		0.429945
  validation accuracy:		93.59 %
Epoch 1558 of 2000 took 0.176s
  training loss:		0.007004
  validation loss:		0.435942
  validation accuracy:		93.37 %
Epoch 1559 of 2000 took 0.161s
  training loss:		0.006773
  validation loss:		0.438235
  validation accuracy:		93.37 %
Epoch 1560 of 2000 took 0.138s
  training loss:		0.006573
  validation loss:		0.434903
  validation accuracy:		93.59 %
Epoch 1561 of 2000 took 0.150s
  training loss:		0.006572
  validation loss:		0.437205
  validation accuracy:		93.48 %
Epoch 1562 of 2000 took 0.145s
  training loss:		0.006875
  validation loss:		0.441546
  validation accuracy:		93.37 %
Epoch 1563 of 2000 took 0.145s
  training loss:		0.006785
  validation loss:		0.437688
  validation accuracy:		93.37 %
Epoch 1564 of 2000 took 0.176s
  training loss:		0.006799
  validation loss:		0.437052
  validation accuracy:		93.48 %
Epoch 1565 of 2000 took 0.183s
  training loss:		0.006646
  validation loss:		0.443700
  validation accuracy:		93.37 %
Epoch 1566 of 2000 took 0.153s
  training loss:		0.006824
  validation loss:		0.436220
  validation accuracy:		93.37 %
Epoch 1567 of 2000 took 0.160s
  training loss:		0.006864
  validation loss:		0.441568
  validation accuracy:		93.37 %
Epoch 1568 of 2000 took 0.184s
  training loss:		0.006660
  validation loss:		0.446892
  validation accuracy:		93.26 %
Epoch 1569 of 2000 took 0.183s
  training loss:		0.006583
  validation loss:		0.430773
  validation accuracy:		93.48 %
Epoch 1570 of 2000 took 0.142s
  training loss:		0.006623
  validation loss:		0.451260
  validation accuracy:		93.15 %
Epoch 1571 of 2000 took 0.144s
  training loss:		0.007042
  validation loss:		0.439127
  validation accuracy:		93.48 %
Epoch 1572 of 2000 took 0.154s
  training loss:		0.006828
  validation loss:		0.444765
  validation accuracy:		93.26 %
Epoch 1573 of 2000 took 0.144s
  training loss:		0.006875
  validation loss:		0.444950
  validation accuracy:		93.48 %
Epoch 1574 of 2000 took 0.142s
  training loss:		0.006695
  validation loss:		0.438961
  validation accuracy:		93.37 %
Epoch 1575 of 2000 took 0.181s
  training loss:		0.007022
  validation loss:		0.442410
  validation accuracy:		93.59 %
Epoch 1576 of 2000 took 0.157s
  training loss:		0.006634
  validation loss:		0.434924
  validation accuracy:		93.48 %
Epoch 1577 of 2000 took 0.182s
  training loss:		0.006610
  validation loss:		0.451939
  validation accuracy:		93.15 %
Epoch 1578 of 2000 took 0.181s
  training loss:		0.006596
  validation loss:		0.442001
  validation accuracy:		93.37 %
Epoch 1579 of 2000 took 0.170s
  training loss:		0.006453
  validation loss:		0.442315
  validation accuracy:		93.26 %
Epoch 1580 of 2000 took 0.146s
  training loss:		0.006434
  validation loss:		0.441330
  validation accuracy:		93.48 %
Epoch 1581 of 2000 took 0.176s
  training loss:		0.006581
  validation loss:		0.439564
  validation accuracy:		93.48 %
Epoch 1582 of 2000 took 0.181s
  training loss:		0.006660
  validation loss:		0.452946
  validation accuracy:		93.15 %
Epoch 1583 of 2000 took 0.181s
  training loss:		0.006670
  validation loss:		0.443050
  validation accuracy:		93.37 %
Epoch 1584 of 2000 took 0.178s
  training loss:		0.006755
  validation loss:		0.441828
  validation accuracy:		93.48 %
Epoch 1585 of 2000 took 0.149s
  training loss:		0.006560
  validation loss:		0.439606
  validation accuracy:		93.48 %
Epoch 1586 of 2000 took 0.160s
  training loss:		0.006553
  validation loss:		0.435400
  validation accuracy:		93.37 %
Epoch 1587 of 2000 took 0.165s
  training loss:		0.006432
  validation loss:		0.444525
  validation accuracy:		93.37 %
Epoch 1588 of 2000 took 0.159s
  training loss:		0.006611
  validation loss:		0.437985
  validation accuracy:		93.70 %
Epoch 1589 of 2000 took 0.178s
  training loss:		0.006442
  validation loss:		0.439923
  validation accuracy:		93.48 %
Epoch 1590 of 2000 took 0.184s
  training loss:		0.006465
  validation loss:		0.444345
  validation accuracy:		93.48 %
Epoch 1591 of 2000 took 0.152s
  training loss:		0.006524
  validation loss:		0.447069
  validation accuracy:		93.37 %
Epoch 1592 of 2000 took 0.154s
  training loss:		0.006681
  validation loss:		0.438729
  validation accuracy:		93.48 %
Epoch 1593 of 2000 took 0.147s
  training loss:		0.006675
  validation loss:		0.454020
  validation accuracy:		93.15 %
Epoch 1594 of 2000 took 0.149s
  training loss:		0.006600
  validation loss:		0.443273
  validation accuracy:		93.59 %
Epoch 1595 of 2000 took 0.183s
  training loss:		0.006486
  validation loss:		0.442930
  validation accuracy:		93.48 %
Epoch 1596 of 2000 took 0.184s
  training loss:		0.006558
  validation loss:		0.445994
  validation accuracy:		93.26 %
Epoch 1597 of 2000 took 0.180s
  training loss:		0.006470
  validation loss:		0.448203
  validation accuracy:		93.26 %
Epoch 1598 of 2000 took 0.157s
  training loss:		0.006391
  validation loss:		0.440724
  validation accuracy:		93.37 %
Epoch 1599 of 2000 took 0.151s
  training loss:		0.006415
  validation loss:		0.452803
  validation accuracy:		93.26 %
Epoch 1600 of 2000 took 0.138s
  training loss:		0.006541
  validation loss:		0.449148
  validation accuracy:		93.26 %
Epoch 1601 of 2000 took 0.154s
  training loss:		0.006357
  validation loss:		0.438523
  validation accuracy:		93.48 %
Epoch 1602 of 2000 took 0.152s
  training loss:		0.006361
  validation loss:		0.439659
  validation accuracy:		93.48 %
Epoch 1603 of 2000 took 0.151s
  training loss:		0.006439
  validation loss:		0.450768
  validation accuracy:		93.37 %
Epoch 1604 of 2000 took 0.146s
  training loss:		0.006206
  validation loss:		0.447900
  validation accuracy:		93.26 %
Epoch 1605 of 2000 took 0.148s
  training loss:		0.006410
  validation loss:		0.442895
  validation accuracy:		93.48 %
Epoch 1606 of 2000 took 0.154s
  training loss:		0.006317
  validation loss:		0.448322
  validation accuracy:		93.37 %
Epoch 1607 of 2000 took 0.141s
  training loss:		0.006342
  validation loss:		0.446812
  validation accuracy:		93.37 %
Epoch 1608 of 2000 took 0.178s
  training loss:		0.006198
  validation loss:		0.445036
  validation accuracy:		93.26 %
Epoch 1609 of 2000 took 0.172s
  training loss:		0.006064
  validation loss:		0.444210
  validation accuracy:		93.37 %
Epoch 1610 of 2000 took 0.148s
  training loss:		0.006403
  validation loss:		0.456087
  validation accuracy:		93.26 %
Epoch 1611 of 2000 took 0.140s
  training loss:		0.006265
  validation loss:		0.446984
  validation accuracy:		93.37 %
Epoch 1612 of 2000 took 0.169s
  training loss:		0.006274
  validation loss:		0.441685
  validation accuracy:		93.48 %
Epoch 1613 of 2000 took 0.149s
  training loss:		0.006277
  validation loss:		0.452576
  validation accuracy:		93.48 %
Epoch 1614 of 2000 took 0.167s
  training loss:		0.006215
  validation loss:		0.445640
  validation accuracy:		93.26 %
Epoch 1615 of 2000 took 0.180s
  training loss:		0.006505
  validation loss:		0.445701
  validation accuracy:		93.37 %
Epoch 1616 of 2000 took 0.146s
  training loss:		0.006131
  validation loss:		0.454277
  validation accuracy:		93.37 %
Epoch 1617 of 2000 took 0.179s
  training loss:		0.006475
  validation loss:		0.443120
  validation accuracy:		93.37 %
Epoch 1618 of 2000 took 0.160s
  training loss:		0.006350
  validation loss:		0.448967
  validation accuracy:		93.37 %
Epoch 1619 of 2000 took 0.185s
  training loss:		0.006408
  validation loss:		0.445166
  validation accuracy:		93.48 %
Epoch 1620 of 2000 took 0.151s
  training loss:		0.006071
  validation loss:		0.452085
  validation accuracy:		93.37 %
Epoch 1621 of 2000 took 0.181s
  training loss:		0.006431
  validation loss:		0.447627
  validation accuracy:		93.37 %
Epoch 1622 of 2000 took 0.185s
  training loss:		0.006376
  validation loss:		0.446230
  validation accuracy:		93.59 %
Epoch 1623 of 2000 took 0.180s
  training loss:		0.005850
  validation loss:		0.450060
  validation accuracy:		93.37 %
Epoch 1624 of 2000 took 0.170s
  training loss:		0.006185
  validation loss:		0.450686
  validation accuracy:		93.37 %
Epoch 1625 of 2000 took 0.186s
  training loss:		0.006339
  validation loss:		0.446672
  validation accuracy:		93.59 %
Epoch 1626 of 2000 took 0.189s
  training loss:		0.006264
  validation loss:		0.453961
  validation accuracy:		93.26 %
Epoch 1627 of 2000 took 0.172s
  training loss:		0.005966
  validation loss:		0.449183
  validation accuracy:		93.26 %
Epoch 1628 of 2000 took 0.138s
  training loss:		0.006174
  validation loss:		0.454935
  validation accuracy:		93.26 %
Epoch 1629 of 2000 took 0.152s
  training loss:		0.006317
  validation loss:		0.450071
  validation accuracy:		93.48 %
Epoch 1630 of 2000 took 0.156s
  training loss:		0.006102
  validation loss:		0.450423
  validation accuracy:		93.48 %
Epoch 1631 of 2000 took 0.135s
  training loss:		0.006305
  validation loss:		0.442966
  validation accuracy:		93.70 %
Epoch 1632 of 2000 took 0.153s
  training loss:		0.006146
  validation loss:		0.455566
  validation accuracy:		93.26 %
Epoch 1633 of 2000 took 0.152s
  training loss:		0.006254
  validation loss:		0.448006
  validation accuracy:		93.37 %
Epoch 1634 of 2000 took 0.138s
  training loss:		0.006036
  validation loss:		0.460274
  validation accuracy:		93.26 %
Epoch 1635 of 2000 took 0.136s
  training loss:		0.006062
  validation loss:		0.447126
  validation accuracy:		93.37 %
Epoch 1636 of 2000 took 0.153s
  training loss:		0.005875
  validation loss:		0.451491
  validation accuracy:		93.26 %
Epoch 1637 of 2000 took 0.156s
  training loss:		0.006168
  validation loss:		0.452563
  validation accuracy:		93.37 %
Epoch 1638 of 2000 took 0.157s
  training loss:		0.005984
  validation loss:		0.443966
  validation accuracy:		93.37 %
Epoch 1639 of 2000 took 0.178s
  training loss:		0.006247
  validation loss:		0.451765
  validation accuracy:		93.37 %
Epoch 1640 of 2000 took 0.181s
  training loss:		0.006137
  validation loss:		0.446887
  validation accuracy:		93.37 %
Epoch 1641 of 2000 took 0.177s
  training loss:		0.005923
  validation loss:		0.456137
  validation accuracy:		93.37 %
Epoch 1642 of 2000 took 0.152s
  training loss:		0.006158
  validation loss:		0.453812
  validation accuracy:		93.37 %
Epoch 1643 of 2000 took 0.161s
  training loss:		0.005938
  validation loss:		0.459464
  validation accuracy:		93.15 %
Epoch 1644 of 2000 took 0.154s
  training loss:		0.006117
  validation loss:		0.459359
  validation accuracy:		93.37 %
Epoch 1645 of 2000 took 0.143s
  training loss:		0.006066
  validation loss:		0.448249
  validation accuracy:		93.37 %
Epoch 1646 of 2000 took 0.146s
  training loss:		0.005944
  validation loss:		0.457330
  validation accuracy:		93.48 %
Epoch 1647 of 2000 took 0.154s
  training loss:		0.005923
  validation loss:		0.453451
  validation accuracy:		93.37 %
Epoch 1648 of 2000 took 0.152s
  training loss:		0.005971
  validation loss:		0.458026
  validation accuracy:		93.26 %
Epoch 1649 of 2000 took 0.146s
  training loss:		0.006111
  validation loss:		0.460001
  validation accuracy:		93.37 %
Epoch 1650 of 2000 took 0.176s
  training loss:		0.005685
  validation loss:		0.448776
  validation accuracy:		93.37 %
Epoch 1651 of 2000 took 0.183s
  training loss:		0.005890
  validation loss:		0.449428
  validation accuracy:		93.37 %
Epoch 1652 of 2000 took 0.177s
  training loss:		0.005975
  validation loss:		0.459907
  validation accuracy:		93.37 %
Epoch 1653 of 2000 took 0.153s
  training loss:		0.005729
  validation loss:		0.456584
  validation accuracy:		93.15 %
Epoch 1654 of 2000 took 0.154s
  training loss:		0.005981
  validation loss:		0.448537
  validation accuracy:		93.37 %
Epoch 1655 of 2000 took 0.173s
  training loss:		0.005886
  validation loss:		0.454965
  validation accuracy:		93.37 %
Epoch 1656 of 2000 took 0.184s
  training loss:		0.006054
  validation loss:		0.461563
  validation accuracy:		93.37 %
Epoch 1657 of 2000 took 0.184s
  training loss:		0.006175
  validation loss:		0.451860
  validation accuracy:		93.37 %
Epoch 1658 of 2000 took 0.176s
  training loss:		0.005759
  validation loss:		0.450856
  validation accuracy:		93.37 %
Epoch 1659 of 2000 took 0.164s
  training loss:		0.005765
  validation loss:		0.454789
  validation accuracy:		93.37 %
Epoch 1660 of 2000 took 0.181s
  training loss:		0.005731
  validation loss:		0.458327
  validation accuracy:		93.37 %
Epoch 1661 of 2000 took 0.146s
  training loss:		0.005925
  validation loss:		0.451776
  validation accuracy:		93.37 %
Epoch 1662 of 2000 took 0.164s
  training loss:		0.005594
  validation loss:		0.457648
  validation accuracy:		93.37 %
Epoch 1663 of 2000 took 0.183s
  training loss:		0.005758
  validation loss:		0.453055
  validation accuracy:		93.59 %
Epoch 1664 of 2000 took 0.187s
  training loss:		0.005780
  validation loss:		0.459374
  validation accuracy:		93.37 %
Epoch 1665 of 2000 took 0.186s
  training loss:		0.005899
  validation loss:		0.455508
  validation accuracy:		93.37 %
Epoch 1666 of 2000 took 0.167s
  training loss:		0.005978
  validation loss:		0.455455
  validation accuracy:		93.37 %
Epoch 1667 of 2000 took 0.147s
  training loss:		0.005773
  validation loss:		0.458188
  validation accuracy:		93.37 %
Epoch 1668 of 2000 took 0.129s
  training loss:		0.005806
  validation loss:		0.454074
  validation accuracy:		93.37 %
Epoch 1669 of 2000 took 0.135s
  training loss:		0.005732
  validation loss:		0.448953
  validation accuracy:		93.48 %
Epoch 1670 of 2000 took 0.142s
  training loss:		0.005937
  validation loss:		0.453113
  validation accuracy:		93.37 %
Epoch 1671 of 2000 took 0.149s
  training loss:		0.005741
  validation loss:		0.461714
  validation accuracy:		93.26 %
Epoch 1672 of 2000 took 0.140s
  training loss:		0.005734
  validation loss:		0.463235
  validation accuracy:		93.26 %
Epoch 1673 of 2000 took 0.144s
  training loss:		0.005999
  validation loss:		0.458729
  validation accuracy:		93.37 %
Epoch 1674 of 2000 took 0.148s
  training loss:		0.005882
  validation loss:		0.461233
  validation accuracy:		93.26 %
Epoch 1675 of 2000 took 0.156s
  training loss:		0.005702
  validation loss:		0.455077
  validation accuracy:		93.26 %
Epoch 1676 of 2000 took 0.140s
  training loss:		0.005662
  validation loss:		0.458455
  validation accuracy:		93.48 %
Epoch 1677 of 2000 took 0.147s
  training loss:		0.006014
  validation loss:		0.470973
  validation accuracy:		93.15 %
Epoch 1678 of 2000 took 0.142s
  training loss:		0.005728
  validation loss:		0.456427
  validation accuracy:		93.37 %
Epoch 1679 of 2000 took 0.153s
  training loss:		0.005612
  validation loss:		0.461908
  validation accuracy:		93.37 %
Epoch 1680 of 2000 took 0.149s
  training loss:		0.005727
  validation loss:		0.456169
  validation accuracy:		93.37 %
Epoch 1681 of 2000 took 0.143s
  training loss:		0.005622
  validation loss:		0.459318
  validation accuracy:		93.37 %
Epoch 1682 of 2000 took 0.142s
  training loss:		0.005775
  validation loss:		0.461944
  validation accuracy:		93.48 %
Epoch 1683 of 2000 took 0.150s
  training loss:		0.005654
  validation loss:		0.457740
  validation accuracy:		93.37 %
Epoch 1684 of 2000 took 0.137s
  training loss:		0.005650
  validation loss:		0.449362
  validation accuracy:		93.48 %
Epoch 1685 of 2000 took 0.151s
  training loss:		0.005773
  validation loss:		0.463374
  validation accuracy:		93.26 %
Epoch 1686 of 2000 took 0.155s
  training loss:		0.005457
  validation loss:		0.459080
  validation accuracy:		93.37 %
Epoch 1687 of 2000 took 0.180s
  training loss:		0.005809
  validation loss:		0.458093
  validation accuracy:		93.37 %
Epoch 1688 of 2000 took 0.165s
  training loss:		0.005623
  validation loss:		0.455308
  validation accuracy:		93.59 %
Epoch 1689 of 2000 took 0.182s
  training loss:		0.005551
  validation loss:		0.463313
  validation accuracy:		93.37 %
Epoch 1690 of 2000 took 0.181s
  training loss:		0.005577
  validation loss:		0.462108
  validation accuracy:		93.37 %
Epoch 1691 of 2000 took 0.153s
  training loss:		0.005559
  validation loss:		0.459503
  validation accuracy:		93.37 %
Epoch 1692 of 2000 took 0.139s
  training loss:		0.005576
  validation loss:		0.457807
  validation accuracy:		93.48 %
Epoch 1693 of 2000 took 0.156s
  training loss:		0.005344
  validation loss:		0.457956
  validation accuracy:		93.26 %
Epoch 1694 of 2000 took 0.147s
  training loss:		0.005746
  validation loss:		0.463518
  validation accuracy:		93.37 %
Epoch 1695 of 2000 took 0.135s
  training loss:		0.005535
  validation loss:		0.458375
  validation accuracy:		93.37 %
Epoch 1696 of 2000 took 0.158s
  training loss:		0.005675
  validation loss:		0.465898
  validation accuracy:		93.37 %
Epoch 1697 of 2000 took 0.140s
  training loss:		0.005447
  validation loss:		0.465299
  validation accuracy:		93.26 %
Epoch 1698 of 2000 took 0.140s
  training loss:		0.005442
  validation loss:		0.463932
  validation accuracy:		93.37 %
Epoch 1699 of 2000 took 0.143s
  training loss:		0.005388
  validation loss:		0.451849
  validation accuracy:		93.59 %
Epoch 1700 of 2000 took 0.145s
  training loss:		0.005631
  validation loss:		0.469101
  validation accuracy:		93.37 %
Epoch 1701 of 2000 took 0.156s
  training loss:		0.005379
  validation loss:		0.457519
  validation accuracy:		93.37 %
Epoch 1702 of 2000 took 0.148s
  training loss:		0.005504
  validation loss:		0.463543
  validation accuracy:		93.37 %
Epoch 1703 of 2000 took 0.145s
  training loss:		0.005398
  validation loss:		0.463252
  validation accuracy:		93.37 %
Epoch 1704 of 2000 took 0.156s
  training loss:		0.005546
  validation loss:		0.460280
  validation accuracy:		93.37 %
Epoch 1705 of 2000 took 0.158s
  training loss:		0.005414
  validation loss:		0.468332
  validation accuracy:		93.26 %
Epoch 1706 of 2000 took 0.138s
  training loss:		0.005600
  validation loss:		0.459876
  validation accuracy:		93.37 %
Epoch 1707 of 2000 took 0.186s
  training loss:		0.005588
  validation loss:		0.466842
  validation accuracy:		93.37 %
Epoch 1708 of 2000 took 0.187s
  training loss:		0.005375
  validation loss:		0.461229
  validation accuracy:		93.37 %
Epoch 1709 of 2000 took 0.184s
  training loss:		0.005417
  validation loss:		0.458793
  validation accuracy:		93.48 %
Epoch 1710 of 2000 took 0.191s
  training loss:		0.005410
  validation loss:		0.468806
  validation accuracy:		93.26 %
Epoch 1711 of 2000 took 0.181s
  training loss:		0.005445
  validation loss:		0.463667
  validation accuracy:		93.37 %
Epoch 1712 of 2000 took 0.155s
  training loss:		0.005397
  validation loss:		0.467995
  validation accuracy:		93.37 %
Epoch 1713 of 2000 took 0.152s
  training loss:		0.005450
  validation loss:		0.460637
  validation accuracy:		93.59 %
Epoch 1714 of 2000 took 0.136s
  training loss:		0.005477
  validation loss:		0.468791
  validation accuracy:		93.37 %
Epoch 1715 of 2000 took 0.146s
  training loss:		0.005488
  validation loss:		0.464013
  validation accuracy:		93.37 %
Epoch 1716 of 2000 took 0.136s
  training loss:		0.005339
  validation loss:		0.465193
  validation accuracy:		93.37 %
Epoch 1717 of 2000 took 0.164s
  training loss:		0.005669
  validation loss:		0.468467
  validation accuracy:		93.26 %
Epoch 1718 of 2000 took 0.181s
  training loss:		0.005429
  validation loss:		0.467795
  validation accuracy:		93.37 %
Epoch 1719 of 2000 took 0.166s
  training loss:		0.005299
  validation loss:		0.465740
  validation accuracy:		93.37 %
Epoch 1720 of 2000 took 0.186s
  training loss:		0.005340
  validation loss:		0.466126
  validation accuracy:		93.26 %
Epoch 1721 of 2000 took 0.182s
  training loss:		0.005332
  validation loss:		0.464307
  validation accuracy:		93.37 %
Epoch 1722 of 2000 took 0.183s
  training loss:		0.005547
  validation loss:		0.463391
  validation accuracy:		93.37 %
Epoch 1723 of 2000 took 0.183s
  training loss:		0.005373
  validation loss:		0.466534
  validation accuracy:		93.26 %
Epoch 1724 of 2000 took 0.183s
  training loss:		0.005258
  validation loss:		0.470195
  validation accuracy:		93.37 %
Epoch 1725 of 2000 took 0.183s
  training loss:		0.005436
  validation loss:		0.459064
  validation accuracy:		93.70 %
Epoch 1726 of 2000 took 0.172s
  training loss:		0.005488
  validation loss:		0.469607
  validation accuracy:		93.37 %
Epoch 1727 of 2000 took 0.139s
  training loss:		0.005287
  validation loss:		0.467483
  validation accuracy:		93.37 %
Epoch 1728 of 2000 took 0.143s
  training loss:		0.005232
  validation loss:		0.464978
  validation accuracy:		93.48 %
Epoch 1729 of 2000 took 0.144s
  training loss:		0.005190
  validation loss:		0.466443
  validation accuracy:		93.37 %
Epoch 1730 of 2000 took 0.151s
  training loss:		0.005401
  validation loss:		0.470970
  validation accuracy:		93.37 %
Epoch 1731 of 2000 took 0.183s
  training loss:		0.005331
  validation loss:		0.472028
  validation accuracy:		93.37 %
Epoch 1732 of 2000 took 0.183s
  training loss:		0.005317
  validation loss:		0.468503
  validation accuracy:		93.26 %
Epoch 1733 of 2000 took 0.150s
  training loss:		0.005043
  validation loss:		0.464475
  validation accuracy:		93.37 %
Epoch 1734 of 2000 took 0.183s
  training loss:		0.005176
  validation loss:		0.474502
  validation accuracy:		93.37 %
Epoch 1735 of 2000 took 0.181s
  training loss:		0.005038
  validation loss:		0.465876
  validation accuracy:		93.37 %
Epoch 1736 of 2000 took 0.181s
  training loss:		0.005093
  validation loss:		0.471198
  validation accuracy:		93.26 %
Epoch 1737 of 2000 took 0.183s
  training loss:		0.005178
  validation loss:		0.472664
  validation accuracy:		93.37 %
Epoch 1738 of 2000 took 0.183s
  training loss:		0.005284
  validation loss:		0.467658
  validation accuracy:		93.37 %
Epoch 1739 of 2000 took 0.184s
  training loss:		0.005210
  validation loss:		0.473764
  validation accuracy:		93.37 %
Epoch 1740 of 2000 took 0.183s
  training loss:		0.005096
  validation loss:		0.474218
  validation accuracy:		93.37 %
Epoch 1741 of 2000 took 0.160s
  training loss:		0.005200
  validation loss:		0.460800
  validation accuracy:		93.37 %
Epoch 1742 of 2000 took 0.141s
  training loss:		0.005131
  validation loss:		0.477048
  validation accuracy:		93.26 %
Epoch 1743 of 2000 took 0.150s
  training loss:		0.005012
  validation loss:		0.475032
  validation accuracy:		93.37 %
Epoch 1744 of 2000 took 0.155s
  training loss:		0.005100
  validation loss:		0.467588
  validation accuracy:		93.37 %
Epoch 1745 of 2000 took 0.182s
  training loss:		0.005096
  validation loss:		0.477950
  validation accuracy:		93.26 %
Epoch 1746 of 2000 took 0.184s
  training loss:		0.005306
  validation loss:		0.474701
  validation accuracy:		93.37 %
Epoch 1747 of 2000 took 0.185s
  training loss:		0.005154
  validation loss:		0.471569
  validation accuracy:		93.37 %
Epoch 1748 of 2000 took 0.184s
  training loss:		0.005073
  validation loss:		0.471729
  validation accuracy:		93.37 %
Epoch 1749 of 2000 took 0.168s
  training loss:		0.004915
  validation loss:		0.473119
  validation accuracy:		93.37 %
Epoch 1750 of 2000 took 0.162s
  training loss:		0.005061
  validation loss:		0.468721
  validation accuracy:		93.37 %
Epoch 1751 of 2000 took 0.145s
  training loss:		0.005084
  validation loss:		0.473384
  validation accuracy:		93.37 %
Epoch 1752 of 2000 took 0.148s
  training loss:		0.005089
  validation loss:		0.474286
  validation accuracy:		93.37 %
Epoch 1753 of 2000 took 0.141s
  training loss:		0.005129
  validation loss:		0.469400
  validation accuracy:		93.26 %
Epoch 1754 of 2000 took 0.145s
  training loss:		0.005041
  validation loss:		0.474919
  validation accuracy:		93.37 %
Epoch 1755 of 2000 took 0.155s
  training loss:		0.005126
  validation loss:		0.468852
  validation accuracy:		93.37 %
Epoch 1756 of 2000 took 0.137s
  training loss:		0.005285
  validation loss:		0.471611
  validation accuracy:		93.37 %
Epoch 1757 of 2000 took 0.140s
  training loss:		0.005089
  validation loss:		0.468827
  validation accuracy:		93.37 %
Epoch 1758 of 2000 took 0.134s
  training loss:		0.005032
  validation loss:		0.475492
  validation accuracy:		93.37 %
Epoch 1759 of 2000 took 0.164s
  training loss:		0.005067
  validation loss:		0.464789
  validation accuracy:		93.59 %
Epoch 1760 of 2000 took 0.160s
  training loss:		0.005168
  validation loss:		0.469398
  validation accuracy:		93.37 %
Epoch 1761 of 2000 took 0.181s
  training loss:		0.005091
  validation loss:		0.479101
  validation accuracy:		93.37 %
Epoch 1762 of 2000 took 0.178s
  training loss:		0.004915
  validation loss:		0.470012
  validation accuracy:		93.48 %
Epoch 1763 of 2000 took 0.182s
  training loss:		0.005117
  validation loss:		0.478402
  validation accuracy:		93.37 %
Epoch 1764 of 2000 took 0.182s
  training loss:		0.005053
  validation loss:		0.475398
  validation accuracy:		93.37 %
Epoch 1765 of 2000 took 0.169s
  training loss:		0.005031
  validation loss:		0.472101
  validation accuracy:		93.37 %
Epoch 1766 of 2000 took 0.183s
  training loss:		0.004952
  validation loss:		0.474763
  validation accuracy:		93.37 %
Epoch 1767 of 2000 took 0.176s
  training loss:		0.004714
  validation loss:		0.466756
  validation accuracy:		93.26 %
Epoch 1768 of 2000 took 0.140s
  training loss:		0.004958
  validation loss:		0.477900
  validation accuracy:		93.37 %
Epoch 1769 of 2000 took 0.143s
  training loss:		0.005040
  validation loss:		0.468849
  validation accuracy:		93.37 %
Epoch 1770 of 2000 took 0.141s
  training loss:		0.005037
  validation loss:		0.473320
  validation accuracy:		93.37 %
Epoch 1771 of 2000 took 0.151s
  training loss:		0.004975
  validation loss:		0.472589
  validation accuracy:		93.37 %
Epoch 1772 of 2000 took 0.141s
  training loss:		0.004803
  validation loss:		0.474871
  validation accuracy:		93.37 %
Epoch 1773 of 2000 took 0.146s
  training loss:		0.004975
  validation loss:		0.480048
  validation accuracy:		93.37 %
Epoch 1774 of 2000 took 0.134s
  training loss:		0.005071
  validation loss:		0.473216
  validation accuracy:		93.37 %
Epoch 1775 of 2000 took 0.160s
  training loss:		0.004820
  validation loss:		0.479407
  validation accuracy:		93.37 %
Epoch 1776 of 2000 took 0.141s
  training loss:		0.004917
  validation loss:		0.474002
  validation accuracy:		93.37 %
Epoch 1777 of 2000 took 0.141s
  training loss:		0.005047
  validation loss:		0.475702
  validation accuracy:		93.26 %
Epoch 1778 of 2000 took 0.169s
  training loss:		0.004865
  validation loss:		0.479867
  validation accuracy:		93.37 %
Epoch 1779 of 2000 took 0.184s
  training loss:		0.004933
  validation loss:		0.470697
  validation accuracy:		93.37 %
Epoch 1780 of 2000 took 0.160s
  training loss:		0.004810
  validation loss:		0.475152
  validation accuracy:		93.37 %
Epoch 1781 of 2000 took 0.134s
  training loss:		0.005007
  validation loss:		0.475012
  validation accuracy:		93.37 %
Epoch 1782 of 2000 took 0.152s
  training loss:		0.004731
  validation loss:		0.474206
  validation accuracy:		93.37 %
Epoch 1783 of 2000 took 0.144s
  training loss:		0.004982
  validation loss:		0.480245
  validation accuracy:		93.37 %
Epoch 1784 of 2000 took 0.142s
  training loss:		0.004793
  validation loss:		0.475326
  validation accuracy:		93.26 %
Epoch 1785 of 2000 took 0.185s
  training loss:		0.004937
  validation loss:		0.477411
  validation accuracy:		93.37 %
Epoch 1786 of 2000 took 0.160s
  training loss:		0.004776
  validation loss:		0.478590
  validation accuracy:		93.37 %
Epoch 1787 of 2000 took 0.151s
  training loss:		0.004732
  validation loss:		0.484153
  validation accuracy:		93.26 %
Epoch 1788 of 2000 took 0.143s
  training loss:		0.004939
  validation loss:		0.470673
  validation accuracy:		93.37 %
Epoch 1789 of 2000 took 0.165s
  training loss:		0.004808
  validation loss:		0.475154
  validation accuracy:		93.37 %
Epoch 1790 of 2000 took 0.184s
  training loss:		0.004736
  validation loss:		0.477196
  validation accuracy:		93.37 %
Epoch 1791 of 2000 took 0.168s
  training loss:		0.004899
  validation loss:		0.471471
  validation accuracy:		93.37 %
Epoch 1792 of 2000 took 0.149s
  training loss:		0.004807
  validation loss:		0.479586
  validation accuracy:		93.37 %
Epoch 1793 of 2000 took 0.158s
  training loss:		0.004740
  validation loss:		0.479636
  validation accuracy:		93.37 %
Epoch 1794 of 2000 took 0.141s
  training loss:		0.004689
  validation loss:		0.476859
  validation accuracy:		93.37 %
Epoch 1795 of 2000 took 0.145s
  training loss:		0.004769
  validation loss:		0.472620
  validation accuracy:		93.48 %
Epoch 1796 of 2000 took 0.159s
  training loss:		0.004974
  validation loss:		0.477832
  validation accuracy:		93.37 %
Epoch 1797 of 2000 took 0.139s
  training loss:		0.004631
  validation loss:		0.472074
  validation accuracy:		93.26 %
Epoch 1798 of 2000 took 0.148s
  training loss:		0.004782
  validation loss:		0.478174
  validation accuracy:		93.26 %
Epoch 1799 of 2000 took 0.184s
  training loss:		0.004819
  validation loss:		0.484089
  validation accuracy:		93.37 %
Epoch 1800 of 2000 took 0.184s
  training loss:		0.004838
  validation loss:		0.476913
  validation accuracy:		93.37 %
Epoch 1801 of 2000 took 0.144s
  training loss:		0.004805
  validation loss:		0.480592
  validation accuracy:		93.37 %
Epoch 1802 of 2000 took 0.168s
  training loss:		0.004752
  validation loss:		0.475576
  validation accuracy:		93.37 %
Epoch 1803 of 2000 took 0.138s
  training loss:		0.004742
  validation loss:		0.476107
  validation accuracy:		93.37 %
Epoch 1804 of 2000 took 0.167s
  training loss:		0.004645
  validation loss:		0.476933
  validation accuracy:		93.26 %
Epoch 1805 of 2000 took 0.140s
  training loss:		0.004635
  validation loss:		0.478568
  validation accuracy:		93.26 %
Epoch 1806 of 2000 took 0.142s
  training loss:		0.004880
  validation loss:		0.477564
  validation accuracy:		93.26 %
Epoch 1807 of 2000 took 0.142s
  training loss:		0.004758
  validation loss:		0.483367
  validation accuracy:		93.26 %
Epoch 1808 of 2000 took 0.143s
  training loss:		0.004766
  validation loss:		0.479621
  validation accuracy:		93.37 %
Epoch 1809 of 2000 took 0.145s
  training loss:		0.004771
  validation loss:		0.478388
  validation accuracy:		93.26 %
Epoch 1810 of 2000 took 0.160s
  training loss:		0.004657
  validation loss:		0.476887
  validation accuracy:		93.37 %
Epoch 1811 of 2000 took 0.182s
  training loss:		0.004730
  validation loss:		0.486148
  validation accuracy:		93.37 %
Epoch 1812 of 2000 took 0.144s
  training loss:		0.004813
  validation loss:		0.472931
  validation accuracy:		93.37 %
Epoch 1813 of 2000 took 0.148s
  training loss:		0.004557
  validation loss:		0.485892
  validation accuracy:		93.37 %
Epoch 1814 of 2000 took 0.155s
  training loss:		0.004578
  validation loss:		0.476101
  validation accuracy:		93.26 %
Epoch 1815 of 2000 took 0.158s
  training loss:		0.004771
  validation loss:		0.477546
  validation accuracy:		93.37 %
Epoch 1816 of 2000 took 0.150s
  training loss:		0.004617
  validation loss:		0.480107
  validation accuracy:		93.26 %
Epoch 1817 of 2000 took 0.184s
  training loss:		0.004616
  validation loss:		0.482707
  validation accuracy:		93.37 %
Epoch 1818 of 2000 took 0.180s
  training loss:		0.004560
  validation loss:		0.482452
  validation accuracy:		93.26 %
Epoch 1819 of 2000 took 0.163s
  training loss:		0.004580
  validation loss:		0.482402
  validation accuracy:		93.26 %
Epoch 1820 of 2000 took 0.170s
  training loss:		0.004755
  validation loss:		0.482372
  validation accuracy:		93.37 %
Epoch 1821 of 2000 took 0.180s
  training loss:		0.004763
  validation loss:		0.480567
  validation accuracy:		93.37 %
Epoch 1822 of 2000 took 0.155s
  training loss:		0.004519
  validation loss:		0.481737
  validation accuracy:		93.37 %
Epoch 1823 of 2000 took 0.179s
  training loss:		0.004565
  validation loss:		0.484151
  validation accuracy:		93.37 %
Epoch 1824 of 2000 took 0.161s
  training loss:		0.004569
  validation loss:		0.482393
  validation accuracy:		93.48 %
Epoch 1825 of 2000 took 0.160s
  training loss:		0.004623
  validation loss:		0.477951
  validation accuracy:		93.37 %
Epoch 1826 of 2000 took 0.178s
  training loss:		0.004601
  validation loss:		0.492637
  validation accuracy:		93.37 %
Epoch 1827 of 2000 took 0.177s
  training loss:		0.004640
  validation loss:		0.480211
  validation accuracy:		93.37 %
Epoch 1828 of 2000 took 0.148s
  training loss:		0.004414
  validation loss:		0.484502
  validation accuracy:		93.26 %
Epoch 1829 of 2000 took 0.140s
  training loss:		0.004499
  validation loss:		0.484219
  validation accuracy:		93.37 %
Epoch 1830 of 2000 took 0.142s
  training loss:		0.004467
  validation loss:		0.485296
  validation accuracy:		93.37 %
Epoch 1831 of 2000 took 0.144s
  training loss:		0.004615
  validation loss:		0.485587
  validation accuracy:		93.26 %
Epoch 1832 of 2000 took 0.152s
  training loss:		0.004564
  validation loss:		0.478099
  validation accuracy:		93.26 %
Epoch 1833 of 2000 took 0.143s
  training loss:		0.004592
  validation loss:		0.483497
  validation accuracy:		93.37 %
Epoch 1834 of 2000 took 0.147s
  training loss:		0.004542
  validation loss:		0.474360
  validation accuracy:		93.48 %
Epoch 1835 of 2000 took 0.181s
  training loss:		0.004826
  validation loss:		0.487318
  validation accuracy:		93.37 %
Epoch 1836 of 2000 took 0.181s
  training loss:		0.004396
  validation loss:		0.479350
  validation accuracy:		93.26 %
Epoch 1837 of 2000 took 0.183s
  training loss:		0.004325
  validation loss:		0.483094
  validation accuracy:		93.37 %
Epoch 1838 of 2000 took 0.161s
  training loss:		0.004427
  validation loss:		0.486756
  validation accuracy:		93.37 %
Epoch 1839 of 2000 took 0.144s
  training loss:		0.004576
  validation loss:		0.481887
  validation accuracy:		93.37 %
Epoch 1840 of 2000 took 0.145s
  training loss:		0.004573
  validation loss:		0.488240
  validation accuracy:		93.37 %
Epoch 1841 of 2000 took 0.152s
  training loss:		0.004565
  validation loss:		0.483649
  validation accuracy:		93.37 %
Epoch 1842 of 2000 took 0.142s
  training loss:		0.004612
  validation loss:		0.486052
  validation accuracy:		93.37 %
Epoch 1843 of 2000 took 0.148s
  training loss:		0.004493
  validation loss:		0.487143
  validation accuracy:		93.37 %
Epoch 1844 of 2000 took 0.178s
  training loss:		0.004502
  validation loss:		0.483545
  validation accuracy:		93.26 %
Epoch 1845 of 2000 took 0.166s
  training loss:		0.004565
  validation loss:		0.484717
  validation accuracy:		93.37 %
Epoch 1846 of 2000 took 0.167s
  training loss:		0.004524
  validation loss:		0.488720
  validation accuracy:		93.37 %
Epoch 1847 of 2000 took 0.150s
  training loss:		0.004556
  validation loss:		0.485078
  validation accuracy:		93.37 %
Epoch 1848 of 2000 took 0.180s
  training loss:		0.004654
  validation loss:		0.485013
  validation accuracy:		93.37 %
Epoch 1849 of 2000 took 0.184s
  training loss:		0.004488
  validation loss:		0.482410
  validation accuracy:		93.26 %
Epoch 1850 of 2000 took 0.162s
  training loss:		0.004482
  validation loss:		0.482952
  validation accuracy:		93.37 %
Epoch 1851 of 2000 took 0.189s
  training loss:		0.004549
  validation loss:		0.490766
  validation accuracy:		93.26 %
Epoch 1852 of 2000 took 0.179s
  training loss:		0.004493
  validation loss:		0.486584
  validation accuracy:		93.26 %
Epoch 1853 of 2000 took 0.183s
  training loss:		0.004363
  validation loss:		0.480397
  validation accuracy:		93.48 %
Epoch 1854 of 2000 took 0.161s
  training loss:		0.004503
  validation loss:		0.491854
  validation accuracy:		93.37 %
Epoch 1855 of 2000 took 0.157s
  training loss:		0.004298
  validation loss:		0.481061
  validation accuracy:		93.26 %
Epoch 1856 of 2000 took 0.166s
  training loss:		0.004491
  validation loss:		0.486105
  validation accuracy:		93.37 %
Epoch 1857 of 2000 took 0.189s
  training loss:		0.004281
  validation loss:		0.492528
  validation accuracy:		93.26 %
Epoch 1858 of 2000 took 0.179s
  training loss:		0.004305
  validation loss:		0.484926
  validation accuracy:		93.37 %
Epoch 1859 of 2000 took 0.188s
  training loss:		0.004355
  validation loss:		0.490985
  validation accuracy:		93.15 %
Epoch 1860 of 2000 took 0.154s
  training loss:		0.004468
  validation loss:		0.481370
  validation accuracy:		93.37 %
Epoch 1861 of 2000 took 0.175s
  training loss:		0.004519
  validation loss:		0.491367
  validation accuracy:		93.37 %
Epoch 1862 of 2000 took 0.183s
  training loss:		0.004414
  validation loss:		0.488415
  validation accuracy:		93.26 %
Epoch 1863 of 2000 took 0.159s
  training loss:		0.004413
  validation loss:		0.488976
  validation accuracy:		93.37 %
Epoch 1864 of 2000 took 0.138s
  training loss:		0.004374
  validation loss:		0.490008
  validation accuracy:		93.26 %
Epoch 1865 of 2000 took 0.143s
  training loss:		0.004357
  validation loss:		0.495573
  validation accuracy:		93.37 %
Epoch 1866 of 2000 took 0.141s
  training loss:		0.004322
  validation loss:		0.483626
  validation accuracy:		93.37 %
Epoch 1867 of 2000 took 0.141s
  training loss:		0.004312
  validation loss:		0.486438
  validation accuracy:		93.26 %
Epoch 1868 of 2000 took 0.167s
  training loss:		0.004448
  validation loss:		0.492085
  validation accuracy:		93.15 %
Epoch 1869 of 2000 took 0.154s
  training loss:		0.004461
  validation loss:		0.493006
  validation accuracy:		93.37 %
Epoch 1870 of 2000 took 0.160s
  training loss:		0.004397
  validation loss:		0.487087
  validation accuracy:		93.37 %
Epoch 1871 of 2000 took 0.159s
  training loss:		0.004195
  validation loss:		0.488797
  validation accuracy:		93.26 %
Epoch 1872 of 2000 took 0.145s
  training loss:		0.004227
  validation loss:		0.489092
  validation accuracy:		93.37 %
Epoch 1873 of 2000 took 0.147s
  training loss:		0.004219
  validation loss:		0.487490
  validation accuracy:		93.37 %
Epoch 1874 of 2000 took 0.140s
  training loss:		0.004296
  validation loss:		0.485105
  validation accuracy:		93.37 %
Epoch 1875 of 2000 took 0.147s
  training loss:		0.004419
  validation loss:		0.493476
  validation accuracy:		93.37 %
Epoch 1876 of 2000 took 0.140s
  training loss:		0.004312
  validation loss:		0.494395
  validation accuracy:		93.37 %
Epoch 1877 of 2000 took 0.186s
  training loss:		0.004418
  validation loss:		0.493979
  validation accuracy:		93.48 %
Epoch 1878 of 2000 took 0.172s
  training loss:		0.004349
  validation loss:		0.488315
  validation accuracy:		93.26 %
Epoch 1879 of 2000 took 0.148s
  training loss:		0.004355
  validation loss:		0.491610
  validation accuracy:		93.26 %
Epoch 1880 of 2000 took 0.159s
  training loss:		0.004380
  validation loss:		0.492766
  validation accuracy:		93.26 %
Epoch 1881 of 2000 took 0.139s
  training loss:		0.004154
  validation loss:		0.489504
  validation accuracy:		93.26 %
Epoch 1882 of 2000 took 0.158s
  training loss:		0.004128
  validation loss:		0.496605
  validation accuracy:		93.26 %
Epoch 1883 of 2000 took 0.135s
  training loss:		0.004242
  validation loss:		0.493198
  validation accuracy:		93.37 %
Epoch 1884 of 2000 took 0.177s
  training loss:		0.004212
  validation loss:		0.485806
  validation accuracy:		93.37 %
Epoch 1885 of 2000 took 0.184s
  training loss:		0.004364
  validation loss:		0.490305
  validation accuracy:		93.37 %
Epoch 1886 of 2000 took 0.184s
  training loss:		0.004183
  validation loss:		0.489019
  validation accuracy:		93.26 %
Epoch 1887 of 2000 took 0.165s
  training loss:		0.004166
  validation loss:		0.496148
  validation accuracy:		93.37 %
Epoch 1888 of 2000 took 0.142s
  training loss:		0.004327
  validation loss:		0.487672
  validation accuracy:		93.48 %
Epoch 1889 of 2000 took 0.140s
  training loss:		0.004216
  validation loss:		0.494999
  validation accuracy:		93.37 %
Epoch 1890 of 2000 took 0.140s
  training loss:		0.004202
  validation loss:		0.484244
  validation accuracy:		93.26 %
Epoch 1891 of 2000 took 0.177s
  training loss:		0.004252
  validation loss:		0.491623
  validation accuracy:		93.26 %
Epoch 1892 of 2000 took 0.183s
  training loss:		0.004207
  validation loss:		0.489981
  validation accuracy:		93.37 %
Epoch 1893 of 2000 took 0.184s
  training loss:		0.004094
  validation loss:		0.494765
  validation accuracy:		93.26 %
Epoch 1894 of 2000 took 0.188s
  training loss:		0.004179
  validation loss:		0.486719
  validation accuracy:		93.26 %
Epoch 1895 of 2000 took 0.167s
  training loss:		0.004116
  validation loss:		0.491247
  validation accuracy:		93.37 %
Epoch 1896 of 2000 took 0.160s
  training loss:		0.004221
  validation loss:		0.489607
  validation accuracy:		93.37 %
Epoch 1897 of 2000 took 0.150s
  training loss:		0.004136
  validation loss:		0.494084
  validation accuracy:		93.26 %
Epoch 1898 of 2000 took 0.141s
  training loss:		0.004183
  validation loss:		0.494073
  validation accuracy:		93.26 %
Epoch 1899 of 2000 took 0.143s
  training loss:		0.004232
  validation loss:		0.492705
  validation accuracy:		93.26 %
Epoch 1900 of 2000 took 0.176s
  training loss:		0.004021
  validation loss:		0.493064
  validation accuracy:		93.37 %
Epoch 1901 of 2000 took 0.182s
  training loss:		0.003991
  validation loss:		0.492947
  validation accuracy:		93.37 %
Epoch 1902 of 2000 took 0.182s
  training loss:		0.004172
  validation loss:		0.495344
  validation accuracy:		93.26 %
Epoch 1903 of 2000 took 0.176s
  training loss:		0.004099
  validation loss:		0.488449
  validation accuracy:		93.48 %
Epoch 1904 of 2000 took 0.183s
  training loss:		0.004191
  validation loss:		0.494247
  validation accuracy:		93.26 %
Epoch 1905 of 2000 took 0.182s
  training loss:		0.004167
  validation loss:		0.492997
  validation accuracy:		93.37 %
Epoch 1906 of 2000 took 0.183s
  training loss:		0.004204
  validation loss:		0.489509
  validation accuracy:		93.26 %
Epoch 1907 of 2000 took 0.181s
  training loss:		0.004213
  validation loss:		0.500740
  validation accuracy:		93.26 %
Epoch 1908 of 2000 took 0.164s
  training loss:		0.004130
  validation loss:		0.491789
  validation accuracy:		93.26 %
Epoch 1909 of 2000 took 0.159s
  training loss:		0.004071
  validation loss:		0.492029
  validation accuracy:		93.26 %
Epoch 1910 of 2000 took 0.157s
  training loss:		0.004104
  validation loss:		0.496391
  validation accuracy:		93.37 %
Epoch 1911 of 2000 took 0.183s
  training loss:		0.004124
  validation loss:		0.495581
  validation accuracy:		93.26 %
Epoch 1912 of 2000 took 0.183s
  training loss:		0.004196
  validation loss:		0.496504
  validation accuracy:		93.26 %
Epoch 1913 of 2000 took 0.155s
  training loss:		0.004125
  validation loss:		0.495517
  validation accuracy:		93.37 %
Epoch 1914 of 2000 took 0.167s
  training loss:		0.004018
  validation loss:		0.494853
  validation accuracy:		93.26 %
Epoch 1915 of 2000 took 0.180s
  training loss:		0.004089
  validation loss:		0.500033
  validation accuracy:		93.15 %
Epoch 1916 of 2000 took 0.161s
  training loss:		0.004060
  validation loss:		0.488703
  validation accuracy:		93.37 %
Epoch 1917 of 2000 took 0.153s
  training loss:		0.004017
  validation loss:		0.495040
  validation accuracy:		93.26 %
Epoch 1918 of 2000 took 0.152s
  training loss:		0.004064
  validation loss:		0.495893
  validation accuracy:		93.26 %
Epoch 1919 of 2000 took 0.143s
  training loss:		0.004165
  validation loss:		0.502409
  validation accuracy:		93.37 %
Epoch 1920 of 2000 took 0.141s
  training loss:		0.004100
  validation loss:		0.494017
  validation accuracy:		93.37 %
Epoch 1921 of 2000 took 0.141s
  training loss:		0.003895
  validation loss:		0.498146
  validation accuracy:		93.26 %
Epoch 1922 of 2000 took 0.153s
  training loss:		0.004021
  validation loss:		0.497572
  validation accuracy:		93.26 %
Epoch 1923 of 2000 took 0.157s
  training loss:		0.004030
  validation loss:		0.501609
  validation accuracy:		93.26 %
Epoch 1924 of 2000 took 0.153s
  training loss:		0.004105
  validation loss:		0.493181
  validation accuracy:		93.26 %
Epoch 1925 of 2000 took 0.178s
  training loss:		0.003999
  validation loss:		0.491592
  validation accuracy:		93.48 %
Epoch 1926 of 2000 took 0.150s
  training loss:		0.004021
  validation loss:		0.504409
  validation accuracy:		93.26 %
Epoch 1927 of 2000 took 0.146s
  training loss:		0.003953
  validation loss:		0.489900
  validation accuracy:		93.37 %
Epoch 1928 of 2000 took 0.155s
  training loss:		0.003918
  validation loss:		0.506807
  validation accuracy:		93.26 %
Epoch 1929 of 2000 took 0.135s
  training loss:		0.004087
  validation loss:		0.494497
  validation accuracy:		93.26 %
Epoch 1930 of 2000 took 0.194s
  training loss:		0.003973
  validation loss:		0.497105
  validation accuracy:		93.26 %
Epoch 1931 of 2000 took 0.152s
  training loss:		0.004087
  validation loss:		0.502779
  validation accuracy:		93.26 %
Epoch 1932 of 2000 took 0.139s
  training loss:		0.003914
  validation loss:		0.489206
  validation accuracy:		93.26 %
Epoch 1933 of 2000 took 0.175s
  training loss:		0.003939
  validation loss:		0.504210
  validation accuracy:		93.26 %
Epoch 1934 of 2000 took 0.182s
  training loss:		0.004044
  validation loss:		0.498475
  validation accuracy:		93.26 %
Epoch 1935 of 2000 took 0.152s
  training loss:		0.003993
  validation loss:		0.503111
  validation accuracy:		93.26 %
Epoch 1936 of 2000 took 0.146s
  training loss:		0.003950
  validation loss:		0.496824
  validation accuracy:		93.26 %
Epoch 1937 of 2000 took 0.161s
  training loss:		0.004075
  validation loss:		0.494939
  validation accuracy:		93.26 %
Epoch 1938 of 2000 took 0.179s
  training loss:		0.004023
  validation loss:		0.500063
  validation accuracy:		93.26 %
Epoch 1939 of 2000 took 0.150s
  training loss:		0.003993
  validation loss:		0.499975
  validation accuracy:		93.37 %
Epoch 1940 of 2000 took 0.144s
  training loss:		0.003942
  validation loss:		0.500813
  validation accuracy:		93.15 %
Epoch 1941 of 2000 took 0.181s
  training loss:		0.003982
  validation loss:		0.503270
  validation accuracy:		93.26 %
Epoch 1942 of 2000 took 0.176s
  training loss:		0.003981
  validation loss:		0.498191
  validation accuracy:		93.37 %
Epoch 1943 of 2000 took 0.150s
  training loss:		0.003918
  validation loss:		0.499443
  validation accuracy:		93.26 %
Epoch 1944 of 2000 took 0.162s
  training loss:		0.003845
  validation loss:		0.504000
  validation accuracy:		93.26 %
Epoch 1945 of 2000 took 0.158s
  training loss:		0.003876
  validation loss:		0.494567
  validation accuracy:		93.37 %
Epoch 1946 of 2000 took 0.139s
  training loss:		0.003939
  validation loss:		0.499929
  validation accuracy:		93.26 %
Epoch 1947 of 2000 took 0.180s
  training loss:		0.003964
  validation loss:		0.502160
  validation accuracy:		93.37 %
Epoch 1948 of 2000 took 0.183s
  training loss:		0.003903
  validation loss:		0.504152
  validation accuracy:		93.26 %
Epoch 1949 of 2000 took 0.179s
  training loss:		0.003819
  validation loss:		0.500187
  validation accuracy:		93.26 %
Epoch 1950 of 2000 took 0.182s
  training loss:		0.004078
  validation loss:		0.506769
  validation accuracy:		93.26 %
Epoch 1951 of 2000 took 0.183s
  training loss:		0.003902
  validation loss:		0.502570
  validation accuracy:		93.37 %
Epoch 1952 of 2000 took 0.179s
  training loss:		0.003860
  validation loss:		0.502774
  validation accuracy:		93.26 %
Epoch 1953 of 2000 took 0.192s
  training loss:		0.003872
  validation loss:		0.497080
  validation accuracy:		93.26 %
Epoch 1954 of 2000 took 0.174s
  training loss:		0.003912
  validation loss:		0.503711
  validation accuracy:		93.37 %
Epoch 1955 of 2000 took 0.182s
  training loss:		0.003847
  validation loss:		0.502557
  validation accuracy:		93.26 %
Epoch 1956 of 2000 took 0.181s
  training loss:		0.003880
  validation loss:		0.501506
  validation accuracy:		93.26 %
Epoch 1957 of 2000 took 0.183s
  training loss:		0.003911
  validation loss:		0.496312
  validation accuracy:		93.37 %
Epoch 1958 of 2000 took 0.190s
  training loss:		0.003972
  validation loss:		0.496329
  validation accuracy:		93.26 %
Epoch 1959 of 2000 took 0.180s
  training loss:		0.003926
  validation loss:		0.506130
  validation accuracy:		93.37 %
Epoch 1960 of 2000 took 0.184s
  training loss:		0.003763
  validation loss:		0.501960
  validation accuracy:		93.26 %
Epoch 1961 of 2000 took 0.184s
  training loss:		0.003848
  validation loss:		0.499521
  validation accuracy:		93.26 %
Epoch 1962 of 2000 took 0.181s
  training loss:		0.003830
  validation loss:		0.504238
  validation accuracy:		93.26 %
Epoch 1963 of 2000 took 0.172s
  training loss:		0.003737
  validation loss:		0.506182
  validation accuracy:		93.37 %
Epoch 1964 of 2000 took 0.161s
  training loss:		0.003759
  validation loss:		0.506096
  validation accuracy:		93.26 %
Epoch 1965 of 2000 took 0.143s
  training loss:		0.003842
  validation loss:		0.505560
  validation accuracy:		93.26 %
Epoch 1966 of 2000 took 0.153s
  training loss:		0.003955
  validation loss:		0.503918
  validation accuracy:		93.26 %
Epoch 1967 of 2000 took 0.147s
  training loss:		0.003895
  validation loss:		0.500140
  validation accuracy:		93.26 %
Epoch 1968 of 2000 took 0.183s
  training loss:		0.003794
  validation loss:		0.505106
  validation accuracy:		93.26 %
Epoch 1969 of 2000 took 0.182s
  training loss:		0.003780
  validation loss:		0.505717
  validation accuracy:		93.26 %
Epoch 1970 of 2000 took 0.182s
  training loss:		0.003785
  validation loss:		0.505964
  validation accuracy:		93.26 %
Epoch 1971 of 2000 took 0.179s
  training loss:		0.003788
  validation loss:		0.500032
  validation accuracy:		93.26 %
Epoch 1972 of 2000 took 0.158s
  training loss:		0.003777
  validation loss:		0.507728
  validation accuracy:		93.26 %
Epoch 1973 of 2000 took 0.182s
  training loss:		0.003680
  validation loss:		0.501250
  validation accuracy:		93.26 %
Epoch 1974 of 2000 took 0.176s
  training loss:		0.003864
  validation loss:		0.504938
  validation accuracy:		93.26 %
Epoch 1975 of 2000 took 0.183s
  training loss:		0.003971
  validation loss:		0.507600
  validation accuracy:		93.26 %
Epoch 1976 of 2000 took 0.183s
  training loss:		0.003603
  validation loss:		0.505526
  validation accuracy:		93.26 %
Epoch 1977 of 2000 took 0.183s
  training loss:		0.003772
  validation loss:		0.506665
  validation accuracy:		93.15 %
Epoch 1978 of 2000 took 0.167s
  training loss:		0.003734
  validation loss:		0.500836
  validation accuracy:		93.26 %
Epoch 1979 of 2000 took 0.141s
  training loss:		0.003835
  validation loss:		0.506187
  validation accuracy:		93.26 %
Epoch 1980 of 2000 took 0.175s
  training loss:		0.003904
  validation loss:		0.504886
  validation accuracy:		93.26 %
Epoch 1981 of 2000 took 0.139s
  training loss:		0.003808
  validation loss:		0.505566
  validation accuracy:		93.26 %
Epoch 1982 of 2000 took 0.153s
  training loss:		0.003704
  validation loss:		0.509337
  validation accuracy:		93.26 %
Epoch 1983 of 2000 took 0.147s
  training loss:		0.003662
  validation loss:		0.503287
  validation accuracy:		93.26 %
Epoch 1984 of 2000 took 0.163s
  training loss:		0.003741
  validation loss:		0.505383
  validation accuracy:		93.26 %
Epoch 1985 of 2000 took 0.178s
  training loss:		0.003682
  validation loss:		0.507832
  validation accuracy:		93.37 %
Epoch 1986 of 2000 took 0.151s
  training loss:		0.003703
  validation loss:		0.504019
  validation accuracy:		93.26 %
Epoch 1987 of 2000 took 0.157s
  training loss:		0.003792
  validation loss:		0.502290
  validation accuracy:		93.26 %
Epoch 1988 of 2000 took 0.143s
  training loss:		0.003749
  validation loss:		0.509643
  validation accuracy:		93.26 %
Epoch 1989 of 2000 took 0.180s
  training loss:		0.003662
  validation loss:		0.508555
  validation accuracy:		93.26 %
Epoch 1990 of 2000 took 0.189s
  training loss:		0.003729
  validation loss:		0.504993
  validation accuracy:		93.26 %
Epoch 1991 of 2000 took 0.172s
  training loss:		0.003701
  validation loss:		0.506466
  validation accuracy:		93.26 %
Epoch 1992 of 2000 took 0.155s
  training loss:		0.003703
  validation loss:		0.505136
  validation accuracy:		93.26 %
Epoch 1993 of 2000 took 0.177s
  training loss:		0.003727
  validation loss:		0.510753
  validation accuracy:		93.26 %
Epoch 1994 of 2000 took 0.184s
  training loss:		0.003673
  validation loss:		0.500402
  validation accuracy:		93.26 %
Epoch 1995 of 2000 took 0.184s
  training loss:		0.003797
  validation loss:		0.510905
  validation accuracy:		93.26 %
Epoch 1996 of 2000 took 0.180s
  training loss:		0.003564
  validation loss:		0.504042
  validation accuracy:		93.26 %
Epoch 1997 of 2000 took 0.158s
  training loss:		0.003611
  validation loss:		0.508296
  validation accuracy:		93.26 %
Epoch 1998 of 2000 took 0.145s
  training loss:		0.003701
  validation loss:		0.505409
  validation accuracy:		93.26 %
Epoch 1999 of 2000 took 0.144s
  training loss:		0.003771
  validation loss:		0.510190
  validation accuracy:		93.26 %
Epoch 2000 of 2000 took 0.156s
  training loss:		0.003661
  validation loss:		0.507984
  validation accuracy:		93.26 %
Final results:
  test loss:			1.346759
  test accuracy:		84.38 %
