Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.047s
  training loss:		2.956619
  validation loss:		2.853350
  validation accuracy:		7.83 %
Epoch 2 of 2000 took 0.052s
  training loss:		2.780685
  validation loss:		2.632233
  validation accuracy:		13.48 %
Epoch 3 of 2000 took 0.041s
  training loss:		2.584352
  validation loss:		2.419526
  validation accuracy:		16.96 %
Epoch 4 of 2000 took 0.039s
  training loss:		2.418546
  validation loss:		2.266665
  validation accuracy:		33.26 %
Epoch 5 of 2000 took 0.038s
  training loss:		2.314176
  validation loss:		2.197576
  validation accuracy:		52.83 %
Epoch 6 of 2000 took 0.037s
  training loss:		2.249135
  validation loss:		2.166036
  validation accuracy:		46.96 %
Epoch 7 of 2000 took 0.038s
  training loss:		2.212664
  validation loss:		2.133519
  validation accuracy:		56.30 %
Epoch 8 of 2000 took 0.038s
  training loss:		2.183267
  validation loss:		2.103595
  validation accuracy:		58.04 %
Epoch 9 of 2000 took 0.038s
  training loss:		2.153935
  validation loss:		2.069353
  validation accuracy:		53.59 %
Epoch 10 of 2000 took 0.037s
  training loss:		2.128249
  validation loss:		2.042010
  validation accuracy:		64.13 %
Epoch 11 of 2000 took 0.038s
  training loss:		2.096929
  validation loss:		2.010222
  validation accuracy:		57.39 %
Epoch 12 of 2000 took 0.038s
  training loss:		2.066106
  validation loss:		1.967328
  validation accuracy:		57.72 %
Epoch 13 of 2000 took 0.038s
  training loss:		2.031745
  validation loss:		1.938902
  validation accuracy:		59.24 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.992745
  validation loss:		1.887839
  validation accuracy:		61.52 %
Epoch 15 of 2000 took 0.037s
  training loss:		1.950749
  validation loss:		1.841961
  validation accuracy:		60.33 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.901688
  validation loss:		1.787898
  validation accuracy:		61.96 %
Epoch 17 of 2000 took 0.038s
  training loss:		1.853983
  validation loss:		1.738261
  validation accuracy:		61.96 %
Epoch 18 of 2000 took 0.038s
  training loss:		1.799398
  validation loss:		1.680988
  validation accuracy:		63.04 %
Epoch 19 of 2000 took 0.038s
  training loss:		1.745677
  validation loss:		1.613153
  validation accuracy:		63.59 %
Epoch 20 of 2000 took 0.037s
  training loss:		1.689093
  validation loss:		1.563415
  validation accuracy:		65.11 %
Epoch 21 of 2000 took 0.038s
  training loss:		1.627030
  validation loss:		1.491764
  validation accuracy:		66.96 %
Epoch 22 of 2000 took 0.037s
  training loss:		1.571888
  validation loss:		1.434045
  validation accuracy:		68.80 %
Epoch 23 of 2000 took 0.037s
  training loss:		1.513068
  validation loss:		1.381407
  validation accuracy:		67.50 %
Epoch 24 of 2000 took 0.037s
  training loss:		1.455588
  validation loss:		1.327785
  validation accuracy:		68.26 %
Epoch 25 of 2000 took 0.038s
  training loss:		1.404919
  validation loss:		1.264646
  validation accuracy:		71.41 %
Epoch 26 of 2000 took 0.037s
  training loss:		1.352107
  validation loss:		1.225959
  validation accuracy:		70.98 %
Epoch 27 of 2000 took 0.038s
  training loss:		1.302322
  validation loss:		1.183617
  validation accuracy:		71.63 %
Epoch 28 of 2000 took 0.037s
  training loss:		1.255564
  validation loss:		1.133513
  validation accuracy:		71.20 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.211431
  validation loss:		1.099239
  validation accuracy:		73.48 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.171311
  validation loss:		1.064675
  validation accuracy:		74.02 %
Epoch 31 of 2000 took 0.035s
  training loss:		1.128480
  validation loss:		1.027444
  validation accuracy:		74.24 %
Epoch 32 of 2000 took 0.035s
  training loss:		1.087438
  validation loss:		0.994861
  validation accuracy:		75.22 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.059581
  validation loss:		0.967998
  validation accuracy:		75.22 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.021338
  validation loss:		0.931979
  validation accuracy:		75.76 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.993391
  validation loss:		0.903045
  validation accuracy:		76.74 %
Epoch 36 of 2000 took 0.036s
  training loss:		0.972627
  validation loss:		0.883358
  validation accuracy:		76.96 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.941611
  validation loss:		0.852213
  validation accuracy:		77.72 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.912060
  validation loss:		0.827254
  validation accuracy:		78.26 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.885413
  validation loss:		0.807480
  validation accuracy:		78.91 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.864192
  validation loss:		0.782495
  validation accuracy:		78.80 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.841786
  validation loss:		0.761826
  validation accuracy:		79.67 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.819115
  validation loss:		0.745757
  validation accuracy:		79.57 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.790046
  validation loss:		0.722426
  validation accuracy:		79.89 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.775004
  validation loss:		0.698613
  validation accuracy:		80.33 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.754082
  validation loss:		0.680577
  validation accuracy:		81.85 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.733799
  validation loss:		0.666836
  validation accuracy:		81.63 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.717122
  validation loss:		0.656304
  validation accuracy:		82.28 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.698452
  validation loss:		0.632009
  validation accuracy:		83.70 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.676861
  validation loss:		0.617583
  validation accuracy:		83.59 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.654990
  validation loss:		0.590386
  validation accuracy:		84.78 %
Epoch 51 of 2000 took 0.036s
  training loss:		0.651529
  validation loss:		0.585387
  validation accuracy:		85.22 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.633209
  validation loss:		0.570674
  validation accuracy:		85.33 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.619830
  validation loss:		0.558798
  validation accuracy:		85.33 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.599020
  validation loss:		0.544736
  validation accuracy:		85.54 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.586301
  validation loss:		0.532095
  validation accuracy:		86.30 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.573216
  validation loss:		0.517331
  validation accuracy:		86.41 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.565645
  validation loss:		0.511883
  validation accuracy:		86.20 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.546086
  validation loss:		0.506916
  validation accuracy:		86.74 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.540714
  validation loss:		0.494114
  validation accuracy:		87.17 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.523333
  validation loss:		0.482572
  validation accuracy:		87.17 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.517522
  validation loss:		0.475254
  validation accuracy:		87.50 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.504616
  validation loss:		0.457986
  validation accuracy:		88.37 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.495744
  validation loss:		0.452689
  validation accuracy:		88.15 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.488073
  validation loss:		0.442571
  validation accuracy:		88.26 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.473459
  validation loss:		0.442063
  validation accuracy:		88.80 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.468188
  validation loss:		0.427257
  validation accuracy:		88.80 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.462675
  validation loss:		0.433319
  validation accuracy:		88.37 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.451952
  validation loss:		0.421307
  validation accuracy:		88.80 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.442474
  validation loss:		0.402834
  validation accuracy:		89.24 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.432920
  validation loss:		0.400211
  validation accuracy:		89.02 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.424331
  validation loss:		0.394778
  validation accuracy:		89.46 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.424798
  validation loss:		0.393768
  validation accuracy:		89.02 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.416649
  validation loss:		0.386505
  validation accuracy:		89.13 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.415938
  validation loss:		0.386330
  validation accuracy:		88.80 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.403051
  validation loss:		0.373955
  validation accuracy:		89.35 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.400070
  validation loss:		0.362278
  validation accuracy:		89.89 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.397293
  validation loss:		0.362697
  validation accuracy:		89.67 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.386980
  validation loss:		0.360643
  validation accuracy:		89.35 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.377565
  validation loss:		0.365452
  validation accuracy:		89.67 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.381480
  validation loss:		0.351657
  validation accuracy:		89.89 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.366813
  validation loss:		0.353236
  validation accuracy:		90.22 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.369468
  validation loss:		0.346363
  validation accuracy:		89.89 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.361021
  validation loss:		0.341966
  validation accuracy:		90.33 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.354567
  validation loss:		0.343589
  validation accuracy:		90.11 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.356898
  validation loss:		0.335188
  validation accuracy:		90.33 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.351885
  validation loss:		0.334619
  validation accuracy:		90.54 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.346118
  validation loss:		0.329675
  validation accuracy:		90.76 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.341524
  validation loss:		0.332216
  validation accuracy:		90.98 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.333142
  validation loss:		0.324782
  validation accuracy:		90.54 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.330797
  validation loss:		0.335546
  validation accuracy:		90.22 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.336341
  validation loss:		0.322442
  validation accuracy:		90.98 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.328451
  validation loss:		0.320720
  validation accuracy:		90.98 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.322598
  validation loss:		0.319039
  validation accuracy:		90.98 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.326029
  validation loss:		0.323498
  validation accuracy:		91.09 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.316285
  validation loss:		0.316793
  validation accuracy:		90.98 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.316454
  validation loss:		0.300175
  validation accuracy:		91.74 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.314202
  validation loss:		0.305079
  validation accuracy:		91.20 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.307978
  validation loss:		0.305009
  validation accuracy:		91.30 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.306326
  validation loss:		0.306466
  validation accuracy:		91.30 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.305495
  validation loss:		0.298999
  validation accuracy:		91.52 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.302192
  validation loss:		0.297464
  validation accuracy:		91.96 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.298267
  validation loss:		0.304230
  validation accuracy:		91.30 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.296697
  validation loss:		0.293595
  validation accuracy:		91.63 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.293672
  validation loss:		0.296594
  validation accuracy:		91.30 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.288154
  validation loss:		0.299538
  validation accuracy:		91.30 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.289214
  validation loss:		0.296920
  validation accuracy:		91.52 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.287139
  validation loss:		0.286022
  validation accuracy:		91.63 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.284006
  validation loss:		0.282898
  validation accuracy:		92.07 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.285003
  validation loss:		0.280359
  validation accuracy:		92.28 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.282484
  validation loss:		0.287006
  validation accuracy:		91.85 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.281692
  validation loss:		0.286386
  validation accuracy:		91.85 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.273814
  validation loss:		0.278518
  validation accuracy:		92.28 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.271355
  validation loss:		0.272989
  validation accuracy:		92.28 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.267950
  validation loss:		0.292115
  validation accuracy:		91.96 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.264056
  validation loss:		0.273939
  validation accuracy:		92.61 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.265323
  validation loss:		0.280305
  validation accuracy:		91.74 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.261943
  validation loss:		0.267398
  validation accuracy:		92.61 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.269314
  validation loss:		0.273468
  validation accuracy:		92.28 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.256932
  validation loss:		0.274700
  validation accuracy:		92.17 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.262839
  validation loss:		0.270958
  validation accuracy:		92.28 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.254614
  validation loss:		0.269363
  validation accuracy:		92.50 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.254700
  validation loss:		0.264688
  validation accuracy:		92.50 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.249237
  validation loss:		0.267628
  validation accuracy:		92.28 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.253294
  validation loss:		0.268993
  validation accuracy:		92.61 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.251762
  validation loss:		0.265465
  validation accuracy:		92.07 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.253055
  validation loss:		0.265364
  validation accuracy:		92.61 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.244793
  validation loss:		0.259146
  validation accuracy:		92.61 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.244906
  validation loss:		0.258429
  validation accuracy:		92.61 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.240216
  validation loss:		0.255096
  validation accuracy:		92.93 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.242885
  validation loss:		0.253509
  validation accuracy:		92.93 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.240484
  validation loss:		0.269668
  validation accuracy:		92.50 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.237854
  validation loss:		0.260795
  validation accuracy:		92.61 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.238041
  validation loss:		0.253837
  validation accuracy:		92.83 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.232705
  validation loss:		0.256724
  validation accuracy:		92.72 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.234032
  validation loss:		0.259109
  validation accuracy:		92.61 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.231366
  validation loss:		0.251822
  validation accuracy:		92.83 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.236771
  validation loss:		0.255696
  validation accuracy:		92.50 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.232429
  validation loss:		0.253966
  validation accuracy:		92.83 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.228092
  validation loss:		0.257700
  validation accuracy:		92.72 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.229742
  validation loss:		0.254568
  validation accuracy:		92.72 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.226415
  validation loss:		0.255248
  validation accuracy:		92.50 %
Epoch 142 of 2000 took 0.037s
  training loss:		0.231081
  validation loss:		0.242810
  validation accuracy:		92.83 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.223891
  validation loss:		0.248881
  validation accuracy:		92.93 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.225072
  validation loss:		0.252345
  validation accuracy:		92.72 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.222336
  validation loss:		0.245039
  validation accuracy:		92.72 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.222002
  validation loss:		0.246282
  validation accuracy:		93.04 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.215048
  validation loss:		0.244508
  validation accuracy:		92.83 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.221537
  validation loss:		0.249599
  validation accuracy:		92.17 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.217495
  validation loss:		0.243114
  validation accuracy:		92.83 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.219127
  validation loss:		0.243766
  validation accuracy:		92.61 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.215554
  validation loss:		0.245948
  validation accuracy:		92.83 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.212019
  validation loss:		0.251610
  validation accuracy:		92.61 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.209582
  validation loss:		0.241633
  validation accuracy:		93.26 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.213858
  validation loss:		0.242589
  validation accuracy:		93.04 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.206815
  validation loss:		0.242193
  validation accuracy:		92.50 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.209657
  validation loss:		0.245833
  validation accuracy:		93.04 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.208486
  validation loss:		0.232723
  validation accuracy:		93.04 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.205004
  validation loss:		0.245522
  validation accuracy:		92.83 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.206551
  validation loss:		0.247297
  validation accuracy:		92.93 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.205929
  validation loss:		0.236701
  validation accuracy:		93.26 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.207732
  validation loss:		0.235045
  validation accuracy:		92.93 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.206176
  validation loss:		0.237407
  validation accuracy:		93.04 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.203894
  validation loss:		0.239540
  validation accuracy:		93.04 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.202699
  validation loss:		0.232574
  validation accuracy:		93.04 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.199001
  validation loss:		0.239514
  validation accuracy:		93.48 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.199525
  validation loss:		0.228878
  validation accuracy:		92.93 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.196941
  validation loss:		0.233705
  validation accuracy:		93.26 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.197604
  validation loss:		0.236048
  validation accuracy:		92.83 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.199842
  validation loss:		0.247415
  validation accuracy:		92.72 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.196708
  validation loss:		0.244151
  validation accuracy:		92.93 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.190137
  validation loss:		0.230035
  validation accuracy:		93.15 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.194795
  validation loss:		0.230020
  validation accuracy:		92.83 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.193530
  validation loss:		0.234056
  validation accuracy:		93.26 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.195337
  validation loss:		0.230853
  validation accuracy:		93.15 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.192700
  validation loss:		0.230579
  validation accuracy:		93.15 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.192671
  validation loss:		0.230664
  validation accuracy:		92.61 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.191494
  validation loss:		0.226020
  validation accuracy:		92.93 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.188081
  validation loss:		0.228005
  validation accuracy:		93.26 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.188905
  validation loss:		0.228981
  validation accuracy:		93.15 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.188006
  validation loss:		0.231066
  validation accuracy:		93.37 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.185816
  validation loss:		0.230351
  validation accuracy:		93.59 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.182475
  validation loss:		0.227128
  validation accuracy:		93.15 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.184447
  validation loss:		0.235212
  validation accuracy:		93.04 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.185398
  validation loss:		0.225787
  validation accuracy:		93.26 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.183932
  validation loss:		0.232404
  validation accuracy:		93.37 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.182338
  validation loss:		0.224290
  validation accuracy:		93.26 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.181049
  validation loss:		0.231437
  validation accuracy:		93.37 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.182964
  validation loss:		0.225738
  validation accuracy:		93.15 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.175063
  validation loss:		0.230795
  validation accuracy:		93.48 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.178841
  validation loss:		0.219239
  validation accuracy:		93.48 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.175417
  validation loss:		0.225351
  validation accuracy:		93.37 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.179447
  validation loss:		0.222419
  validation accuracy:		93.37 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.177049
  validation loss:		0.221029
  validation accuracy:		93.37 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.177185
  validation loss:		0.220428
  validation accuracy:		93.48 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.173272
  validation loss:		0.220467
  validation accuracy:		93.26 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.173449
  validation loss:		0.222159
  validation accuracy:		93.15 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.170694
  validation loss:		0.224132
  validation accuracy:		93.26 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.170432
  validation loss:		0.224023
  validation accuracy:		93.37 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.171636
  validation loss:		0.221295
  validation accuracy:		93.15 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.171709
  validation loss:		0.216153
  validation accuracy:		93.37 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.170598
  validation loss:		0.228429
  validation accuracy:		93.15 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.169630
  validation loss:		0.221582
  validation accuracy:		93.26 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.168720
  validation loss:		0.216894
  validation accuracy:		93.26 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.163613
  validation loss:		0.229647
  validation accuracy:		93.48 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.169088
  validation loss:		0.219625
  validation accuracy:		93.37 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.168533
  validation loss:		0.222685
  validation accuracy:		93.59 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.161397
  validation loss:		0.217304
  validation accuracy:		93.37 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.166825
  validation loss:		0.219685
  validation accuracy:		93.37 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.160823
  validation loss:		0.217842
  validation accuracy:		93.48 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.163691
  validation loss:		0.218350
  validation accuracy:		93.26 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.163775
  validation loss:		0.218114
  validation accuracy:		93.80 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.160227
  validation loss:		0.218555
  validation accuracy:		93.48 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.161339
  validation loss:		0.219020
  validation accuracy:		93.70 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.161270
  validation loss:		0.214274
  validation accuracy:		93.37 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.164373
  validation loss:		0.219062
  validation accuracy:		93.37 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.160375
  validation loss:		0.219869
  validation accuracy:		93.37 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.160625
  validation loss:		0.215672
  validation accuracy:		93.48 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.158797
  validation loss:		0.215680
  validation accuracy:		93.59 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.157095
  validation loss:		0.214599
  validation accuracy:		93.26 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.158624
  validation loss:		0.214608
  validation accuracy:		93.37 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.158357
  validation loss:		0.206803
  validation accuracy:		93.37 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.157310
  validation loss:		0.217172
  validation accuracy:		93.59 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.157727
  validation loss:		0.214050
  validation accuracy:		93.26 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.158996
  validation loss:		0.223082
  validation accuracy:		93.80 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.155265
  validation loss:		0.212068
  validation accuracy:		93.91 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.152360
  validation loss:		0.216604
  validation accuracy:		93.59 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.153281
  validation loss:		0.215420
  validation accuracy:		93.26 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.153015
  validation loss:		0.215781
  validation accuracy:		93.48 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.154565
  validation loss:		0.214970
  validation accuracy:		93.59 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.151152
  validation loss:		0.218805
  validation accuracy:		93.48 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.153181
  validation loss:		0.219982
  validation accuracy:		93.80 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.152126
  validation loss:		0.210271
  validation accuracy:		93.80 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.147045
  validation loss:		0.210066
  validation accuracy:		93.80 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.149387
  validation loss:		0.218134
  validation accuracy:		93.70 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.147896
  validation loss:		0.212351
  validation accuracy:		93.37 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.150773
  validation loss:		0.218302
  validation accuracy:		93.70 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.153556
  validation loss:		0.218607
  validation accuracy:		93.91 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.146277
  validation loss:		0.211877
  validation accuracy:		93.37 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.146726
  validation loss:		0.206532
  validation accuracy:		93.70 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.148722
  validation loss:		0.212734
  validation accuracy:		93.59 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.145222
  validation loss:		0.208258
  validation accuracy:		93.91 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.143378
  validation loss:		0.210266
  validation accuracy:		93.59 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.147111
  validation loss:		0.209086
  validation accuracy:		93.80 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.141464
  validation loss:		0.206241
  validation accuracy:		93.48 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.148033
  validation loss:		0.210089
  validation accuracy:		93.91 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.142093
  validation loss:		0.209474
  validation accuracy:		93.91 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.143177
  validation loss:		0.211246
  validation accuracy:		93.37 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.143968
  validation loss:		0.212131
  validation accuracy:		93.91 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.143424
  validation loss:		0.207536
  validation accuracy:		93.48 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.140072
  validation loss:		0.205312
  validation accuracy:		93.48 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.142579
  validation loss:		0.209614
  validation accuracy:		93.91 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.138777
  validation loss:		0.212430
  validation accuracy:		93.48 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.143572
  validation loss:		0.215029
  validation accuracy:		94.13 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.141671
  validation loss:		0.208388
  validation accuracy:		93.70 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.134861
  validation loss:		0.209196
  validation accuracy:		94.02 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.137603
  validation loss:		0.211794
  validation accuracy:		93.80 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.139507
  validation loss:		0.205288
  validation accuracy:		93.80 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.141122
  validation loss:		0.213226
  validation accuracy:		94.24 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.138965
  validation loss:		0.211404
  validation accuracy:		93.59 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.138453
  validation loss:		0.206507
  validation accuracy:		93.80 %
Epoch 261 of 2000 took 0.036s
  training loss:		0.139277
  validation loss:		0.212446
  validation accuracy:		93.91 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.135423
  validation loss:		0.210222
  validation accuracy:		94.13 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.138093
  validation loss:		0.205838
  validation accuracy:		93.48 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.134963
  validation loss:		0.208644
  validation accuracy:		93.59 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.136582
  validation loss:		0.210222
  validation accuracy:		94.02 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.134567
  validation loss:		0.205986
  validation accuracy:		94.02 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.134566
  validation loss:		0.206733
  validation accuracy:		93.59 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.136729
  validation loss:		0.212581
  validation accuracy:		93.91 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.133804
  validation loss:		0.204396
  validation accuracy:		93.70 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.135477
  validation loss:		0.213181
  validation accuracy:		94.13 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.132971
  validation loss:		0.208055
  validation accuracy:		93.91 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.130134
  validation loss:		0.209937
  validation accuracy:		93.80 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.131001
  validation loss:		0.206795
  validation accuracy:		93.91 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.130881
  validation loss:		0.210531
  validation accuracy:		94.13 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.131946
  validation loss:		0.208436
  validation accuracy:		94.24 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.131269
  validation loss:		0.203539
  validation accuracy:		93.59 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.128877
  validation loss:		0.207621
  validation accuracy:		94.13 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.127560
  validation loss:		0.204754
  validation accuracy:		93.70 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.133038
  validation loss:		0.203680
  validation accuracy:		93.91 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.130782
  validation loss:		0.206521
  validation accuracy:		93.26 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.128497
  validation loss:		0.211187
  validation accuracy:		93.91 %
Epoch 282 of 2000 took 0.036s
  training loss:		0.128648
  validation loss:		0.210550
  validation accuracy:		93.91 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.125215
  validation loss:		0.210341
  validation accuracy:		94.24 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.128822
  validation loss:		0.206148
  validation accuracy:		94.02 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.128710
  validation loss:		0.208442
  validation accuracy:		94.24 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.126616
  validation loss:		0.200715
  validation accuracy:		93.91 %
Epoch 287 of 2000 took 0.037s
  training loss:		0.127775
  validation loss:		0.201922
  validation accuracy:		93.80 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.124268
  validation loss:		0.213516
  validation accuracy:		93.48 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.126716
  validation loss:		0.205502
  validation accuracy:		93.70 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.127284
  validation loss:		0.202096
  validation accuracy:		94.02 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.126966
  validation loss:		0.207650
  validation accuracy:		93.91 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.122717
  validation loss:		0.207354
  validation accuracy:		93.91 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.121967
  validation loss:		0.205711
  validation accuracy:		93.91 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.123864
  validation loss:		0.204549
  validation accuracy:		94.13 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.124987
  validation loss:		0.213351
  validation accuracy:		93.59 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.121827
  validation loss:		0.205598
  validation accuracy:		94.13 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.122226
  validation loss:		0.211253
  validation accuracy:		94.02 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.123297
  validation loss:		0.203156
  validation accuracy:		93.70 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.122420
  validation loss:		0.205299
  validation accuracy:		93.59 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.121667
  validation loss:		0.203829
  validation accuracy:		94.13 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.119632
  validation loss:		0.208516
  validation accuracy:		93.80 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.120231
  validation loss:		0.209664
  validation accuracy:		93.80 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.120093
  validation loss:		0.210640
  validation accuracy:		94.35 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.120217
  validation loss:		0.217562
  validation accuracy:		93.80 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.119140
  validation loss:		0.211914
  validation accuracy:		94.13 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.118730
  validation loss:		0.207517
  validation accuracy:		94.24 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.120450
  validation loss:		0.207009
  validation accuracy:		94.02 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.115539
  validation loss:		0.209419
  validation accuracy:		93.91 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.118278
  validation loss:		0.208222
  validation accuracy:		94.02 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.118169
  validation loss:		0.204866
  validation accuracy:		94.02 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.116476
  validation loss:		0.207448
  validation accuracy:		94.02 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.117136
  validation loss:		0.205089
  validation accuracy:		93.91 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.116793
  validation loss:		0.204931
  validation accuracy:		93.70 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.112754
  validation loss:		0.200961
  validation accuracy:		93.70 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.115415
  validation loss:		0.209907
  validation accuracy:		93.70 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.117206
  validation loss:		0.199934
  validation accuracy:		94.24 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.117016
  validation loss:		0.209952
  validation accuracy:		94.24 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.116771
  validation loss:		0.206347
  validation accuracy:		94.02 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.113638
  validation loss:		0.201280
  validation accuracy:		94.24 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.115625
  validation loss:		0.210513
  validation accuracy:		93.70 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.114710
  validation loss:		0.201462
  validation accuracy:		94.24 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.113707
  validation loss:		0.205081
  validation accuracy:		94.24 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.113808
  validation loss:		0.204874
  validation accuracy:		93.91 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.112316
  validation loss:		0.201325
  validation accuracy:		94.02 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.114115
  validation loss:		0.206060
  validation accuracy:		93.80 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.113087
  validation loss:		0.202439
  validation accuracy:		93.80 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.113312
  validation loss:		0.200589
  validation accuracy:		94.02 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.113458
  validation loss:		0.206013
  validation accuracy:		93.70 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.111164
  validation loss:		0.208962
  validation accuracy:		93.91 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.111918
  validation loss:		0.214252
  validation accuracy:		94.02 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.115471
  validation loss:		0.204738
  validation accuracy:		94.35 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.111594
  validation loss:		0.200841
  validation accuracy:		94.02 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.110615
  validation loss:		0.205015
  validation accuracy:		94.02 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.107125
  validation loss:		0.206960
  validation accuracy:		93.70 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.109805
  validation loss:		0.209723
  validation accuracy:		93.91 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.107605
  validation loss:		0.204576
  validation accuracy:		93.91 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.106944
  validation loss:		0.209383
  validation accuracy:		94.13 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.110441
  validation loss:		0.205639
  validation accuracy:		94.13 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.108339
  validation loss:		0.206291
  validation accuracy:		93.59 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.108677
  validation loss:		0.208589
  validation accuracy:		94.02 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.107849
  validation loss:		0.210466
  validation accuracy:		93.80 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.108878
  validation loss:		0.203334
  validation accuracy:		94.13 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.109670
  validation loss:		0.205678
  validation accuracy:		94.24 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.105955
  validation loss:		0.204341
  validation accuracy:		93.91 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.106117
  validation loss:		0.202417
  validation accuracy:		94.02 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.104314
  validation loss:		0.207322
  validation accuracy:		93.91 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.108014
  validation loss:		0.201851
  validation accuracy:		94.02 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.103448
  validation loss:		0.201351
  validation accuracy:		94.02 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.105355
  validation loss:		0.208700
  validation accuracy:		94.13 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.104900
  validation loss:		0.206691
  validation accuracy:		94.24 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.105583
  validation loss:		0.203482
  validation accuracy:		94.13 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.105966
  validation loss:		0.205604
  validation accuracy:		94.24 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.104858
  validation loss:		0.201850
  validation accuracy:		94.02 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.102760
  validation loss:		0.208364
  validation accuracy:		93.91 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.105196
  validation loss:		0.204991
  validation accuracy:		93.91 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.103376
  validation loss:		0.203937
  validation accuracy:		93.91 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.104942
  validation loss:		0.202787
  validation accuracy:		94.24 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.104561
  validation loss:		0.204524
  validation accuracy:		93.80 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.101963
  validation loss:		0.211792
  validation accuracy:		94.02 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.105199
  validation loss:		0.203131
  validation accuracy:		94.24 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.102030
  validation loss:		0.205296
  validation accuracy:		94.13 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.104022
  validation loss:		0.207299
  validation accuracy:		93.80 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.100976
  validation loss:		0.208757
  validation accuracy:		93.91 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.099920
  validation loss:		0.204268
  validation accuracy:		93.91 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.098982
  validation loss:		0.201095
  validation accuracy:		94.24 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.098027
  validation loss:		0.212866
  validation accuracy:		93.91 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.102060
  validation loss:		0.204732
  validation accuracy:		94.35 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.100589
  validation loss:		0.204621
  validation accuracy:		94.02 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.098727
  validation loss:		0.207454
  validation accuracy:		93.91 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.097093
  validation loss:		0.200682
  validation accuracy:		94.24 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.099848
  validation loss:		0.203094
  validation accuracy:		94.24 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.096800
  validation loss:		0.206787
  validation accuracy:		94.02 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.096908
  validation loss:		0.205683
  validation accuracy:		94.13 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.097446
  validation loss:		0.202084
  validation accuracy:		94.35 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.099458
  validation loss:		0.212532
  validation accuracy:		94.02 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.097577
  validation loss:		0.203328
  validation accuracy:		94.46 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.097292
  validation loss:		0.204916
  validation accuracy:		94.02 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.098497
  validation loss:		0.207726
  validation accuracy:		94.46 %
Epoch 379 of 2000 took 0.036s
  training loss:		0.097528
  validation loss:		0.205191
  validation accuracy:		94.02 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.096611
  validation loss:		0.202118
  validation accuracy:		94.24 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.094858
  validation loss:		0.205181
  validation accuracy:		94.24 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.095443
  validation loss:		0.206072
  validation accuracy:		94.57 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.096577
  validation loss:		0.208861
  validation accuracy:		93.70 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.093481
  validation loss:		0.212998
  validation accuracy:		94.46 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.095771
  validation loss:		0.218034
  validation accuracy:		94.35 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.096539
  validation loss:		0.207778
  validation accuracy:		93.91 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.097278
  validation loss:		0.207062
  validation accuracy:		94.67 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.094713
  validation loss:		0.211331
  validation accuracy:		94.02 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.095889
  validation loss:		0.208586
  validation accuracy:		93.80 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.094582
  validation loss:		0.209276
  validation accuracy:		94.46 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.095060
  validation loss:		0.207866
  validation accuracy:		94.24 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.095562
  validation loss:		0.204895
  validation accuracy:		93.91 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.092567
  validation loss:		0.210070
  validation accuracy:		94.13 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.092434
  validation loss:		0.209670
  validation accuracy:		94.13 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.094225
  validation loss:		0.204680
  validation accuracy:		94.13 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.093675
  validation loss:		0.205182
  validation accuracy:		94.46 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.092832
  validation loss:		0.209912
  validation accuracy:		94.46 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.093286
  validation loss:		0.210075
  validation accuracy:		94.13 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.094064
  validation loss:		0.203538
  validation accuracy:		94.24 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.093569
  validation loss:		0.208155
  validation accuracy:		94.35 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.092329
  validation loss:		0.205495
  validation accuracy:		94.24 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.092928
  validation loss:		0.204913
  validation accuracy:		94.13 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.092004
  validation loss:		0.206237
  validation accuracy:		94.02 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.090187
  validation loss:		0.208662
  validation accuracy:		94.46 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.090377
  validation loss:		0.208219
  validation accuracy:		94.35 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.091828
  validation loss:		0.205887
  validation accuracy:		94.24 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.091003
  validation loss:		0.208911
  validation accuracy:		94.02 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.087680
  validation loss:		0.205233
  validation accuracy:		93.91 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.089290
  validation loss:		0.208823
  validation accuracy:		93.91 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.090834
  validation loss:		0.207000
  validation accuracy:		94.57 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.090669
  validation loss:		0.208996
  validation accuracy:		94.02 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.091235
  validation loss:		0.204475
  validation accuracy:		94.24 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.089632
  validation loss:		0.209660
  validation accuracy:		94.35 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.088760
  validation loss:		0.201634
  validation accuracy:		94.13 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.089563
  validation loss:		0.207128
  validation accuracy:		94.13 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.088457
  validation loss:		0.208734
  validation accuracy:		94.13 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.090330
  validation loss:		0.215241
  validation accuracy:		94.35 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.088571
  validation loss:		0.213866
  validation accuracy:		94.35 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.087742
  validation loss:		0.213435
  validation accuracy:		94.67 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.086982
  validation loss:		0.207089
  validation accuracy:		94.13 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.086271
  validation loss:		0.210181
  validation accuracy:		94.46 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.085964
  validation loss:		0.203206
  validation accuracy:		94.35 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.085623
  validation loss:		0.211929
  validation accuracy:		93.80 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.083921
  validation loss:		0.211630
  validation accuracy:		94.35 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.087568
  validation loss:		0.208976
  validation accuracy:		94.13 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.087042
  validation loss:		0.211467
  validation accuracy:		94.13 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.086032
  validation loss:		0.213375
  validation accuracy:		94.35 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.085029
  validation loss:		0.206522
  validation accuracy:		94.24 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.082076
  validation loss:		0.205912
  validation accuracy:		94.24 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.085682
  validation loss:		0.204215
  validation accuracy:		94.13 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.086513
  validation loss:		0.214356
  validation accuracy:		94.13 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.083807
  validation loss:		0.204554
  validation accuracy:		94.02 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.084902
  validation loss:		0.212136
  validation accuracy:		94.13 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.083962
  validation loss:		0.207783
  validation accuracy:		94.02 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.085012
  validation loss:		0.205022
  validation accuracy:		94.24 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.081739
  validation loss:		0.212572
  validation accuracy:		94.13 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.084556
  validation loss:		0.209976
  validation accuracy:		94.13 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.084459
  validation loss:		0.208590
  validation accuracy:		94.13 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.082221
  validation loss:		0.207492
  validation accuracy:		94.46 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.082334
  validation loss:		0.207354
  validation accuracy:		94.24 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.080787
  validation loss:		0.210757
  validation accuracy:		94.67 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.081411
  validation loss:		0.212135
  validation accuracy:		94.24 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.083766
  validation loss:		0.207786
  validation accuracy:		94.24 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.082258
  validation loss:		0.213754
  validation accuracy:		94.24 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.083474
  validation loss:		0.211636
  validation accuracy:		94.57 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.081002
  validation loss:		0.215883
  validation accuracy:		94.13 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.082327
  validation loss:		0.213388
  validation accuracy:		94.46 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.081748
  validation loss:		0.212889
  validation accuracy:		94.13 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.083309
  validation loss:		0.208855
  validation accuracy:		94.24 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.081413
  validation loss:		0.212606
  validation accuracy:		93.70 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.081295
  validation loss:		0.222886
  validation accuracy:		94.24 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.083950
  validation loss:		0.211916
  validation accuracy:		94.02 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.081260
  validation loss:		0.202958
  validation accuracy:		94.35 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.079984
  validation loss:		0.219349
  validation accuracy:		94.57 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.081511
  validation loss:		0.221165
  validation accuracy:		94.02 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.076418
  validation loss:		0.210432
  validation accuracy:		94.35 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.079446
  validation loss:		0.212971
  validation accuracy:		94.35 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.078830
  validation loss:		0.211355
  validation accuracy:		94.13 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.080391
  validation loss:		0.211964
  validation accuracy:		94.13 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.078658
  validation loss:		0.213060
  validation accuracy:		93.80 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.079924
  validation loss:		0.209760
  validation accuracy:		94.35 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.078628
  validation loss:		0.228002
  validation accuracy:		94.35 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.079012
  validation loss:		0.207227
  validation accuracy:		94.02 %
Epoch 464 of 2000 took 0.036s
  training loss:		0.081114
  validation loss:		0.211876
  validation accuracy:		94.24 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.078786
  validation loss:		0.210823
  validation accuracy:		94.24 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.079273
  validation loss:		0.212492
  validation accuracy:		94.57 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.073612
  validation loss:		0.211077
  validation accuracy:		94.13 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.080801
  validation loss:		0.209830
  validation accuracy:		94.24 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.077609
  validation loss:		0.216920
  validation accuracy:		94.35 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.077288
  validation loss:		0.215692
  validation accuracy:		94.13 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.077827
  validation loss:		0.215753
  validation accuracy:		94.46 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.073354
  validation loss:		0.208453
  validation accuracy:		94.02 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.074391
  validation loss:		0.211819
  validation accuracy:		93.91 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.078318
  validation loss:		0.212817
  validation accuracy:		94.46 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.078897
  validation loss:		0.216430
  validation accuracy:		94.35 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.075506
  validation loss:		0.214324
  validation accuracy:		94.24 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.076983
  validation loss:		0.212028
  validation accuracy:		93.91 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.073917
  validation loss:		0.209184
  validation accuracy:		94.35 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.075970
  validation loss:		0.211220
  validation accuracy:		94.13 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.072347
  validation loss:		0.216677
  validation accuracy:		94.13 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.076664
  validation loss:		0.216095
  validation accuracy:		94.89 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.076306
  validation loss:		0.215907
  validation accuracy:		94.13 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.071887
  validation loss:		0.213502
  validation accuracy:		94.35 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.074831
  validation loss:		0.212830
  validation accuracy:		94.35 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.073994
  validation loss:		0.217710
  validation accuracy:		94.02 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.073980
  validation loss:		0.217812
  validation accuracy:		93.91 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.075452
  validation loss:		0.213038
  validation accuracy:		94.24 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.072735
  validation loss:		0.213647
  validation accuracy:		94.57 %
Epoch 489 of 2000 took 0.036s
  training loss:		0.074181
  validation loss:		0.217739
  validation accuracy:		94.24 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.071440
  validation loss:		0.209748
  validation accuracy:		94.35 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.073664
  validation loss:		0.216286
  validation accuracy:		94.02 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.074516
  validation loss:		0.210861
  validation accuracy:		94.13 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.073435
  validation loss:		0.213102
  validation accuracy:		94.24 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.072324
  validation loss:		0.213535
  validation accuracy:		94.24 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.073066
  validation loss:		0.221396
  validation accuracy:		94.24 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.071786
  validation loss:		0.218747
  validation accuracy:		94.67 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.073354
  validation loss:		0.216799
  validation accuracy:		94.13 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.071265
  validation loss:		0.220399
  validation accuracy:		93.70 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.073465
  validation loss:		0.221915
  validation accuracy:		93.91 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.072603
  validation loss:		0.217878
  validation accuracy:		94.24 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.071502
  validation loss:		0.216672
  validation accuracy:		94.46 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.071045
  validation loss:		0.221753
  validation accuracy:		94.46 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.072869
  validation loss:		0.220492
  validation accuracy:		94.02 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.072483
  validation loss:		0.212835
  validation accuracy:		94.24 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.068992
  validation loss:		0.225813
  validation accuracy:		94.02 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.071181
  validation loss:		0.219816
  validation accuracy:		94.13 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.071714
  validation loss:		0.215203
  validation accuracy:		94.35 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.071005
  validation loss:		0.219360
  validation accuracy:		94.24 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.070592
  validation loss:		0.218594
  validation accuracy:		94.24 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.070311
  validation loss:		0.213114
  validation accuracy:		94.13 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.067000
  validation loss:		0.219388
  validation accuracy:		93.80 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.071069
  validation loss:		0.223858
  validation accuracy:		94.24 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.069816
  validation loss:		0.220839
  validation accuracy:		94.02 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.068834
  validation loss:		0.215604
  validation accuracy:		94.35 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.069693
  validation loss:		0.216775
  validation accuracy:		94.24 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.067528
  validation loss:		0.215306
  validation accuracy:		94.13 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.066312
  validation loss:		0.222224
  validation accuracy:		94.35 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.067734
  validation loss:		0.215050
  validation accuracy:		94.35 %
Epoch 519 of 2000 took 0.037s
  training loss:		0.067433
  validation loss:		0.221308
  validation accuracy:		94.02 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.069181
  validation loss:		0.218224
  validation accuracy:		94.46 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.069024
  validation loss:		0.218424
  validation accuracy:		94.24 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.069335
  validation loss:		0.217357
  validation accuracy:		94.24 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.068416
  validation loss:		0.216027
  validation accuracy:		94.02 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.068701
  validation loss:		0.222609
  validation accuracy:		94.24 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.067234
  validation loss:		0.218033
  validation accuracy:		94.35 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.067966
  validation loss:		0.222455
  validation accuracy:		93.91 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.067286
  validation loss:		0.215677
  validation accuracy:		94.24 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.066591
  validation loss:		0.221172
  validation accuracy:		94.24 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.065511
  validation loss:		0.216324
  validation accuracy:		94.02 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.066132
  validation loss:		0.215804
  validation accuracy:		94.24 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.064116
  validation loss:		0.228234
  validation accuracy:		93.80 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.065113
  validation loss:		0.214984
  validation accuracy:		94.35 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.064600
  validation loss:		0.215529
  validation accuracy:		93.91 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.066689
  validation loss:		0.217887
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.064571
  validation loss:		0.216481
  validation accuracy:		94.13 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.066437
  validation loss:		0.218891
  validation accuracy:		94.24 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.066651
  validation loss:		0.220139
  validation accuracy:		94.02 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.065721
  validation loss:		0.224458
  validation accuracy:		94.02 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.067594
  validation loss:		0.219827
  validation accuracy:		94.24 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.060818
  validation loss:		0.224348
  validation accuracy:		94.24 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.064633
  validation loss:		0.224301
  validation accuracy:		93.91 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.063994
  validation loss:		0.228255
  validation accuracy:		94.02 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.064024
  validation loss:		0.218577
  validation accuracy:		94.57 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.066029
  validation loss:		0.232418
  validation accuracy:		94.46 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.065962
  validation loss:		0.225145
  validation accuracy:		94.02 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.064625
  validation loss:		0.223197
  validation accuracy:		94.24 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.062829
  validation loss:		0.220940
  validation accuracy:		93.80 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.064189
  validation loss:		0.228840
  validation accuracy:		93.91 %
Epoch 549 of 2000 took 0.036s
  training loss:		0.065597
  validation loss:		0.239124
  validation accuracy:		94.46 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.062040
  validation loss:		0.228852
  validation accuracy:		93.80 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.063585
  validation loss:		0.222597
  validation accuracy:		94.13 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.062745
  validation loss:		0.229905
  validation accuracy:		94.02 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.063353
  validation loss:		0.220718
  validation accuracy:		94.13 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.064058
  validation loss:		0.223735
  validation accuracy:		94.24 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.062966
  validation loss:		0.226790
  validation accuracy:		93.80 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.061238
  validation loss:		0.228502
  validation accuracy:		93.91 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.065570
  validation loss:		0.225982
  validation accuracy:		93.91 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.061864
  validation loss:		0.216305
  validation accuracy:		94.35 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.063840
  validation loss:		0.225125
  validation accuracy:		94.02 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.062187
  validation loss:		0.223300
  validation accuracy:		93.91 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.059640
  validation loss:		0.234618
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.061146
  validation loss:		0.223674
  validation accuracy:		94.02 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.060725
  validation loss:		0.221627
  validation accuracy:		94.35 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.061270
  validation loss:		0.225077
  validation accuracy:		93.91 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.061999
  validation loss:		0.225465
  validation accuracy:		93.80 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.058072
  validation loss:		0.225555
  validation accuracy:		93.80 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.058882
  validation loss:		0.227690
  validation accuracy:		93.91 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.059454
  validation loss:		0.226961
  validation accuracy:		94.02 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.061858
  validation loss:		0.224015
  validation accuracy:		94.02 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.061823
  validation loss:		0.227996
  validation accuracy:		93.91 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.058862
  validation loss:		0.227033
  validation accuracy:		94.13 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.060652
  validation loss:		0.225299
  validation accuracy:		93.80 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.058859
  validation loss:		0.225063
  validation accuracy:		93.91 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.060910
  validation loss:		0.223674
  validation accuracy:		94.02 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.060825
  validation loss:		0.220766
  validation accuracy:		94.13 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.059693
  validation loss:		0.228181
  validation accuracy:		94.24 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.060091
  validation loss:		0.223994
  validation accuracy:		93.91 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.059213
  validation loss:		0.235157
  validation accuracy:		93.80 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.060558
  validation loss:		0.225456
  validation accuracy:		94.02 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.060912
  validation loss:		0.221332
  validation accuracy:		94.02 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.057656
  validation loss:		0.229228
  validation accuracy:		93.70 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.058915
  validation loss:		0.232050
  validation accuracy:		93.59 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.058325
  validation loss:		0.229716
  validation accuracy:		93.91 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.058536
  validation loss:		0.222016
  validation accuracy:		94.24 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.059386
  validation loss:		0.223520
  validation accuracy:		94.02 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.059317
  validation loss:		0.223949
  validation accuracy:		94.24 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.059718
  validation loss:		0.225595
  validation accuracy:		94.13 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.058801
  validation loss:		0.229305
  validation accuracy:		94.02 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.057303
  validation loss:		0.228913
  validation accuracy:		93.80 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.056076
  validation loss:		0.235062
  validation accuracy:		94.13 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.057069
  validation loss:		0.229572
  validation accuracy:		93.80 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.058090
  validation loss:		0.226968
  validation accuracy:		93.70 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.056969
  validation loss:		0.233626
  validation accuracy:		93.70 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.058802
  validation loss:		0.223918
  validation accuracy:		93.91 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.059344
  validation loss:		0.224818
  validation accuracy:		94.13 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.057313
  validation loss:		0.229612
  validation accuracy:		94.02 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.055922
  validation loss:		0.230137
  validation accuracy:		93.80 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.057393
  validation loss:		0.236294
  validation accuracy:		93.80 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.058708
  validation loss:		0.230207
  validation accuracy:		93.80 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.055116
  validation loss:		0.230696
  validation accuracy:		94.24 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.056136
  validation loss:		0.226759
  validation accuracy:		93.91 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.056454
  validation loss:		0.236035
  validation accuracy:		93.80 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.056917
  validation loss:		0.235991
  validation accuracy:		93.91 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.056684
  validation loss:		0.237811
  validation accuracy:		93.91 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.057813
  validation loss:		0.234232
  validation accuracy:		93.80 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.055157
  validation loss:		0.229977
  validation accuracy:		93.91 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.055821
  validation loss:		0.241446
  validation accuracy:		93.80 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.056358
  validation loss:		0.233107
  validation accuracy:		93.48 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.056531
  validation loss:		0.233958
  validation accuracy:		93.91 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.055757
  validation loss:		0.237062
  validation accuracy:		93.91 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.053716
  validation loss:		0.234530
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.055552
  validation loss:		0.238563
  validation accuracy:		93.80 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.056015
  validation loss:		0.233365
  validation accuracy:		93.80 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.054135
  validation loss:		0.237981
  validation accuracy:		93.59 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.052293
  validation loss:		0.231221
  validation accuracy:		94.02 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.055426
  validation loss:		0.230722
  validation accuracy:		93.70 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.054797
  validation loss:		0.241052
  validation accuracy:		93.80 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.054177
  validation loss:		0.229790
  validation accuracy:		93.59 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.053994
  validation loss:		0.240919
  validation accuracy:		93.70 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.052374
  validation loss:		0.235592
  validation accuracy:		93.80 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.050868
  validation loss:		0.231393
  validation accuracy:		94.02 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.052686
  validation loss:		0.238261
  validation accuracy:		93.48 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.052395
  validation loss:		0.236281
  validation accuracy:		93.91 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.052964
  validation loss:		0.245344
  validation accuracy:		93.80 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.055034
  validation loss:		0.236257
  validation accuracy:		93.59 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.052988
  validation loss:		0.234553
  validation accuracy:		93.91 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.049739
  validation loss:		0.237488
  validation accuracy:		93.70 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.052414
  validation loss:		0.235336
  validation accuracy:		93.80 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.051896
  validation loss:		0.241605
  validation accuracy:		93.80 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.052463
  validation loss:		0.235826
  validation accuracy:		93.59 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.051445
  validation loss:		0.245916
  validation accuracy:		94.02 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.052224
  validation loss:		0.234269
  validation accuracy:		93.70 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.051755
  validation loss:		0.233653
  validation accuracy:		93.70 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.052305
  validation loss:		0.240285
  validation accuracy:		94.02 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.051772
  validation loss:		0.237138
  validation accuracy:		93.70 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.052079
  validation loss:		0.242941
  validation accuracy:		94.02 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.051342
  validation loss:		0.236654
  validation accuracy:		93.48 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.052673
  validation loss:		0.235468
  validation accuracy:		93.91 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.049341
  validation loss:		0.239009
  validation accuracy:		93.80 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.052012
  validation loss:		0.241878
  validation accuracy:		93.91 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.050132
  validation loss:		0.239067
  validation accuracy:		93.70 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.050135
  validation loss:		0.238887
  validation accuracy:		93.80 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.048710
  validation loss:		0.242706
  validation accuracy:		93.70 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.049743
  validation loss:		0.233159
  validation accuracy:		93.91 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.050425
  validation loss:		0.242478
  validation accuracy:		93.37 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.049859
  validation loss:		0.235486
  validation accuracy:		93.59 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.049917
  validation loss:		0.237796
  validation accuracy:		93.80 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.048389
  validation loss:		0.243046
  validation accuracy:		93.59 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.051688
  validation loss:		0.246189
  validation accuracy:		93.59 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.050512
  validation loss:		0.237794
  validation accuracy:		93.91 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.047481
  validation loss:		0.239161
  validation accuracy:		93.80 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.050502
  validation loss:		0.234856
  validation accuracy:		93.80 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.049430
  validation loss:		0.247874
  validation accuracy:		93.80 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.048806
  validation loss:		0.240353
  validation accuracy:		93.70 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.047282
  validation loss:		0.237177
  validation accuracy:		93.91 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.048802
  validation loss:		0.237915
  validation accuracy:		93.70 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.050666
  validation loss:		0.242141
  validation accuracy:		93.59 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.048634
  validation loss:		0.233052
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.050412
  validation loss:		0.237655
  validation accuracy:		93.70 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.049132
  validation loss:		0.243054
  validation accuracy:		93.70 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.048432
  validation loss:		0.241631
  validation accuracy:		93.70 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.047707
  validation loss:		0.238098
  validation accuracy:		93.59 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.048269
  validation loss:		0.242645
  validation accuracy:		93.80 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.048382
  validation loss:		0.252066
  validation accuracy:		94.02 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.049820
  validation loss:		0.244229
  validation accuracy:		93.70 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.047270
  validation loss:		0.242157
  validation accuracy:		93.70 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.047378
  validation loss:		0.239532
  validation accuracy:		93.70 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.047354
  validation loss:		0.239471
  validation accuracy:		93.59 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.046559
  validation loss:		0.245798
  validation accuracy:		93.91 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.048663
  validation loss:		0.246760
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.047664
  validation loss:		0.248919
  validation accuracy:		93.59 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.045292
  validation loss:		0.239538
  validation accuracy:		93.80 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.046934
  validation loss:		0.246092
  validation accuracy:		93.70 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.047572
  validation loss:		0.241559
  validation accuracy:		93.70 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.044659
  validation loss:		0.244148
  validation accuracy:		93.70 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.047036
  validation loss:		0.246862
  validation accuracy:		93.80 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.046919
  validation loss:		0.245512
  validation accuracy:		93.80 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.047236
  validation loss:		0.243338
  validation accuracy:		93.70 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.046174
  validation loss:		0.247308
  validation accuracy:		93.91 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.045013
  validation loss:		0.240284
  validation accuracy:		93.59 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.045766
  validation loss:		0.246603
  validation accuracy:		93.59 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.047768
  validation loss:		0.241849
  validation accuracy:		93.91 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.046080
  validation loss:		0.238120
  validation accuracy:		93.70 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.047396
  validation loss:		0.252068
  validation accuracy:		93.59 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.045321
  validation loss:		0.241093
  validation accuracy:		93.70 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.045875
  validation loss:		0.248599
  validation accuracy:		93.80 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.044840
  validation loss:		0.252484
  validation accuracy:		93.48 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.046216
  validation loss:		0.252550
  validation accuracy:		93.70 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.046386
  validation loss:		0.248163
  validation accuracy:		93.70 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.046373
  validation loss:		0.245887
  validation accuracy:		93.59 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.045204
  validation loss:		0.254929
  validation accuracy:		93.15 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.043438
  validation loss:		0.249306
  validation accuracy:		93.70 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.044755
  validation loss:		0.256043
  validation accuracy:		93.80 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.044185
  validation loss:		0.253969
  validation accuracy:		93.80 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.045910
  validation loss:		0.251690
  validation accuracy:		93.70 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.045217
  validation loss:		0.248817
  validation accuracy:		93.70 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.044183
  validation loss:		0.248326
  validation accuracy:		93.70 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.043552
  validation loss:		0.242332
  validation accuracy:		93.48 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.044890
  validation loss:		0.251229
  validation accuracy:		93.70 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.045361
  validation loss:		0.251208
  validation accuracy:		93.91 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.044645
  validation loss:		0.255949
  validation accuracy:		93.48 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.043922
  validation loss:		0.254202
  validation accuracy:		93.59 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.044115
  validation loss:		0.257581
  validation accuracy:		93.26 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.044253
  validation loss:		0.244093
  validation accuracy:		93.70 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.044078
  validation loss:		0.247278
  validation accuracy:		93.59 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.043743
  validation loss:		0.257424
  validation accuracy:		93.26 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.042525
  validation loss:		0.250143
  validation accuracy:		93.70 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.044875
  validation loss:		0.251580
  validation accuracy:		94.02 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.042060
  validation loss:		0.250572
  validation accuracy:		93.59 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.042476
  validation loss:		0.252210
  validation accuracy:		93.48 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.042421
  validation loss:		0.254918
  validation accuracy:		93.70 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.042377
  validation loss:		0.256642
  validation accuracy:		93.80 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.042660
  validation loss:		0.248454
  validation accuracy:		93.37 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.040363
  validation loss:		0.264239
  validation accuracy:		93.59 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.043313
  validation loss:		0.249391
  validation accuracy:		93.59 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.043120
  validation loss:		0.249044
  validation accuracy:		93.59 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.043537
  validation loss:		0.253104
  validation accuracy:		93.91 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.042487
  validation loss:		0.250745
  validation accuracy:		93.37 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.042718
  validation loss:		0.249313
  validation accuracy:		93.91 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.041017
  validation loss:		0.252687
  validation accuracy:		93.48 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.040764
  validation loss:		0.257515
  validation accuracy:		93.37 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.041009
  validation loss:		0.255750
  validation accuracy:		93.80 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.042907
  validation loss:		0.257345
  validation accuracy:		93.15 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.041714
  validation loss:		0.253733
  validation accuracy:		93.70 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.040954
  validation loss:		0.245875
  validation accuracy:		93.70 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.043680
  validation loss:		0.254106
  validation accuracy:		93.37 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.041845
  validation loss:		0.255377
  validation accuracy:		93.91 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.039364
  validation loss:		0.254249
  validation accuracy:		93.70 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.039685
  validation loss:		0.253468
  validation accuracy:		93.59 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.039525
  validation loss:		0.254724
  validation accuracy:		93.70 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.038588
  validation loss:		0.258952
  validation accuracy:		93.70 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.041132
  validation loss:		0.255212
  validation accuracy:		93.48 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.040881
  validation loss:		0.254218
  validation accuracy:		93.48 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.039278
  validation loss:		0.247616
  validation accuracy:		93.59 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.040829
  validation loss:		0.251891
  validation accuracy:		93.59 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.040406
  validation loss:		0.259167
  validation accuracy:		93.48 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.039762
  validation loss:		0.257700
  validation accuracy:		93.70 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.039832
  validation loss:		0.260080
  validation accuracy:		93.15 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.038875
  validation loss:		0.257444
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.039123
  validation loss:		0.257541
  validation accuracy:		93.37 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.039102
  validation loss:		0.262438
  validation accuracy:		93.70 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.038770
  validation loss:		0.262761
  validation accuracy:		93.37 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.038334
  validation loss:		0.260763
  validation accuracy:		93.48 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.040295
  validation loss:		0.259570
  validation accuracy:		93.70 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.038949
  validation loss:		0.256939
  validation accuracy:		93.37 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.038075
  validation loss:		0.257705
  validation accuracy:		93.37 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.038456
  validation loss:		0.264275
  validation accuracy:		93.37 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.038991
  validation loss:		0.260995
  validation accuracy:		93.80 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.038819
  validation loss:		0.277740
  validation accuracy:		93.26 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.038960
  validation loss:		0.257579
  validation accuracy:		93.59 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.038538
  validation loss:		0.258055
  validation accuracy:		93.70 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.036621
  validation loss:		0.270316
  validation accuracy:		93.37 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.039326
  validation loss:		0.256256
  validation accuracy:		93.59 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.038488
  validation loss:		0.260935
  validation accuracy:		93.48 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.038132
  validation loss:		0.259536
  validation accuracy:		93.80 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.038828
  validation loss:		0.258060
  validation accuracy:		93.80 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.039262
  validation loss:		0.263265
  validation accuracy:		93.37 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.038618
  validation loss:		0.259771
  validation accuracy:		93.37 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.038603
  validation loss:		0.262141
  validation accuracy:		93.26 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.038294
  validation loss:		0.264751
  validation accuracy:		93.70 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.037141
  validation loss:		0.265191
  validation accuracy:		93.59 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.035708
  validation loss:		0.270842
  validation accuracy:		93.26 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.039586
  validation loss:		0.258911
  validation accuracy:		93.48 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.038236
  validation loss:		0.261920
  validation accuracy:		93.26 %
Epoch 765 of 2000 took 0.036s
  training loss:		0.038093
  validation loss:		0.266042
  validation accuracy:		93.70 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.035803
  validation loss:		0.263043
  validation accuracy:		93.70 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.036241
  validation loss:		0.266252
  validation accuracy:		93.26 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.035374
  validation loss:		0.262040
  validation accuracy:		93.70 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.034654
  validation loss:		0.264200
  validation accuracy:		93.59 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.036907
  validation loss:		0.266270
  validation accuracy:		93.26 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.035807
  validation loss:		0.259614
  validation accuracy:		93.70 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.037353
  validation loss:		0.264146
  validation accuracy:		93.80 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.037036
  validation loss:		0.267725
  validation accuracy:		93.59 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.036693
  validation loss:		0.263712
  validation accuracy:		93.37 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.036430
  validation loss:		0.263969
  validation accuracy:		93.59 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.036730
  validation loss:		0.266373
  validation accuracy:		93.70 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.035352
  validation loss:		0.266810
  validation accuracy:		93.59 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.035237
  validation loss:		0.261050
  validation accuracy:		93.70 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.034140
  validation loss:		0.265944
  validation accuracy:		93.59 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.036250
  validation loss:		0.262114
  validation accuracy:		93.48 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.035016
  validation loss:		0.267201
  validation accuracy:		93.70 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.036248
  validation loss:		0.265451
  validation accuracy:		93.48 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.036035
  validation loss:		0.271131
  validation accuracy:		93.59 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.034531
  validation loss:		0.272279
  validation accuracy:		93.59 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.036355
  validation loss:		0.268042
  validation accuracy:		93.37 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.035531
  validation loss:		0.265568
  validation accuracy:		93.48 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.035402
  validation loss:		0.267464
  validation accuracy:		93.70 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.034978
  validation loss:		0.264636
  validation accuracy:		93.37 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.034822
  validation loss:		0.265935
  validation accuracy:		93.48 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.035936
  validation loss:		0.267121
  validation accuracy:		93.59 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.034434
  validation loss:		0.270030
  validation accuracy:		93.70 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.033645
  validation loss:		0.271595
  validation accuracy:		93.37 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.035206
  validation loss:		0.268551
  validation accuracy:		93.15 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.034216
  validation loss:		0.267025
  validation accuracy:		93.70 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.034734
  validation loss:		0.273224
  validation accuracy:		93.59 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.034955
  validation loss:		0.274014
  validation accuracy:		93.15 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.035393
  validation loss:		0.274579
  validation accuracy:		93.37 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.034876
  validation loss:		0.263265
  validation accuracy:		93.59 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.033671
  validation loss:		0.272501
  validation accuracy:		93.59 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.034168
  validation loss:		0.266099
  validation accuracy:		93.26 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.032927
  validation loss:		0.270186
  validation accuracy:		93.80 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.035116
  validation loss:		0.265721
  validation accuracy:		93.70 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.033906
  validation loss:		0.274845
  validation accuracy:		93.59 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.033924
  validation loss:		0.270142
  validation accuracy:		93.48 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.033812
  validation loss:		0.272515
  validation accuracy:		93.48 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.033363
  validation loss:		0.269519
  validation accuracy:		93.48 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.033251
  validation loss:		0.276634
  validation accuracy:		93.37 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.033696
  validation loss:		0.268408
  validation accuracy:		93.70 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.033776
  validation loss:		0.270097
  validation accuracy:		93.48 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.033052
  validation loss:		0.273640
  validation accuracy:		93.48 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.032357
  validation loss:		0.273910
  validation accuracy:		93.70 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.032677
  validation loss:		0.275723
  validation accuracy:		93.70 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.033193
  validation loss:		0.272617
  validation accuracy:		93.48 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.032239
  validation loss:		0.271487
  validation accuracy:		93.80 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.033070
  validation loss:		0.271144
  validation accuracy:		93.48 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.033127
  validation loss:		0.277490
  validation accuracy:		93.15 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.032445
  validation loss:		0.271459
  validation accuracy:		93.59 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.031339
  validation loss:		0.275605
  validation accuracy:		93.37 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.034044
  validation loss:		0.271478
  validation accuracy:		93.37 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.030975
  validation loss:		0.268633
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.032112
  validation loss:		0.281327
  validation accuracy:		93.48 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.032709
  validation loss:		0.273017
  validation accuracy:		93.37 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.032514
  validation loss:		0.279506
  validation accuracy:		93.80 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.032765
  validation loss:		0.288728
  validation accuracy:		93.37 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.033178
  validation loss:		0.282585
  validation accuracy:		93.15 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.032636
  validation loss:		0.279203
  validation accuracy:		93.37 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.030427
  validation loss:		0.279015
  validation accuracy:		93.80 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.032628
  validation loss:		0.274366
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.031798
  validation loss:		0.276571
  validation accuracy:		93.37 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.031472
  validation loss:		0.287097
  validation accuracy:		93.26 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.031018
  validation loss:		0.273122
  validation accuracy:		93.37 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.031088
  validation loss:		0.282782
  validation accuracy:		93.48 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.031959
  validation loss:		0.278604
  validation accuracy:		93.59 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.030272
  validation loss:		0.277471
  validation accuracy:		93.48 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.031695
  validation loss:		0.275196
  validation accuracy:		93.48 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.031540
  validation loss:		0.280569
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.032001
  validation loss:		0.274861
  validation accuracy:		93.59 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.031479
  validation loss:		0.278540
  validation accuracy:		93.59 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.031403
  validation loss:		0.279121
  validation accuracy:		93.48 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.031414
  validation loss:		0.273769
  validation accuracy:		93.70 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.030995
  validation loss:		0.287601
  validation accuracy:		93.59 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.030937
  validation loss:		0.280217
  validation accuracy:		93.59 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.031198
  validation loss:		0.284452
  validation accuracy:		93.59 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.030301
  validation loss:		0.281275
  validation accuracy:		93.59 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.030469
  validation loss:		0.279206
  validation accuracy:		93.59 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.029002
  validation loss:		0.282360
  validation accuracy:		93.04 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.030744
  validation loss:		0.279077
  validation accuracy:		93.70 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.031077
  validation loss:		0.273691
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.031163
  validation loss:		0.279582
  validation accuracy:		93.48 %
Epoch 850 of 2000 took 0.036s
  training loss:		0.028947
  validation loss:		0.283365
  validation accuracy:		93.59 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.028172
  validation loss:		0.283299
  validation accuracy:		93.37 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.030236
  validation loss:		0.279942
  validation accuracy:		93.59 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.030759
  validation loss:		0.275276
  validation accuracy:		93.37 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.029290
  validation loss:		0.283197
  validation accuracy:		93.15 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.029268
  validation loss:		0.279477
  validation accuracy:		93.37 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.030098
  validation loss:		0.285570
  validation accuracy:		93.48 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.029817
  validation loss:		0.284813
  validation accuracy:		93.48 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.029671
  validation loss:		0.278175
  validation accuracy:		93.48 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.030268
  validation loss:		0.281630
  validation accuracy:		93.48 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.027780
  validation loss:		0.277215
  validation accuracy:		93.59 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.028600
  validation loss:		0.289380
  validation accuracy:		93.48 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.029928
  validation loss:		0.285556
  validation accuracy:		93.37 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.028175
  validation loss:		0.278911
  validation accuracy:		93.70 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.029033
  validation loss:		0.296453
  validation accuracy:		93.26 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.029127
  validation loss:		0.285450
  validation accuracy:		93.80 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.027242
  validation loss:		0.294444
  validation accuracy:		93.26 %
Epoch 867 of 2000 took 0.037s
  training loss:		0.029532
  validation loss:		0.279105
  validation accuracy:		93.48 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.028658
  validation loss:		0.286529
  validation accuracy:		93.59 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.028108
  validation loss:		0.295179
  validation accuracy:		93.15 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.028671
  validation loss:		0.280290
  validation accuracy:		93.59 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.029332
  validation loss:		0.295454
  validation accuracy:		93.37 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.028686
  validation loss:		0.286479
  validation accuracy:		93.37 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.028693
  validation loss:		0.283054
  validation accuracy:		93.70 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.028069
  validation loss:		0.285132
  validation accuracy:		93.59 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.028282
  validation loss:		0.289952
  validation accuracy:		93.59 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.028368
  validation loss:		0.289365
  validation accuracy:		93.48 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.027299
  validation loss:		0.288241
  validation accuracy:		93.59 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.029206
  validation loss:		0.285828
  validation accuracy:		93.48 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.028015
  validation loss:		0.292519
  validation accuracy:		93.59 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.027457
  validation loss:		0.278012
  validation accuracy:		93.59 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.027981
  validation loss:		0.293529
  validation accuracy:		93.59 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.027159
  validation loss:		0.282068
  validation accuracy:		93.48 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.026927
  validation loss:		0.291042
  validation accuracy:		93.48 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.027402
  validation loss:		0.290342
  validation accuracy:		93.48 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.027720
  validation loss:		0.288650
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.027957
  validation loss:		0.284233
  validation accuracy:		93.59 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.027888
  validation loss:		0.283896
  validation accuracy:		93.48 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.026142
  validation loss:		0.289210
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.036s
  training loss:		0.027171
  validation loss:		0.291057
  validation accuracy:		93.37 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.027579
  validation loss:		0.285911
  validation accuracy:		93.48 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.026079
  validation loss:		0.288339
  validation accuracy:		93.59 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.027917
  validation loss:		0.291011
  validation accuracy:		93.59 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.026147
  validation loss:		0.291517
  validation accuracy:		93.48 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.027099
  validation loss:		0.290852
  validation accuracy:		93.48 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.026889
  validation loss:		0.288922
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.027176
  validation loss:		0.289822
  validation accuracy:		93.48 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.026745
  validation loss:		0.291899
  validation accuracy:		93.48 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.026299
  validation loss:		0.293416
  validation accuracy:		93.48 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.026197
  validation loss:		0.294083
  validation accuracy:		93.59 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.025608
  validation loss:		0.287475
  validation accuracy:		93.80 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.026100
  validation loss:		0.295274
  validation accuracy:		93.37 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.026185
  validation loss:		0.290265
  validation accuracy:		93.37 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.026551
  validation loss:		0.285609
  validation accuracy:		93.59 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.027593
  validation loss:		0.298980
  validation accuracy:		93.26 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.027240
  validation loss:		0.286675
  validation accuracy:		93.59 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.026752
  validation loss:		0.297076
  validation accuracy:		93.48 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.025897
  validation loss:		0.287008
  validation accuracy:		93.48 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.026077
  validation loss:		0.300296
  validation accuracy:		93.59 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.025854
  validation loss:		0.301641
  validation accuracy:		93.26 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.025870
  validation loss:		0.294079
  validation accuracy:		93.59 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.024898
  validation loss:		0.295862
  validation accuracy:		93.26 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.024311
  validation loss:		0.297674
  validation accuracy:		93.59 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.024722
  validation loss:		0.291638
  validation accuracy:		93.59 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.025812
  validation loss:		0.297652
  validation accuracy:		93.26 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.025894
  validation loss:		0.292911
  validation accuracy:		93.48 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.024951
  validation loss:		0.301385
  validation accuracy:		93.37 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.026064
  validation loss:		0.294427
  validation accuracy:		93.80 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.025672
  validation loss:		0.300987
  validation accuracy:		93.59 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.023943
  validation loss:		0.288028
  validation accuracy:		93.48 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.025323
  validation loss:		0.305915
  validation accuracy:		93.48 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.024913
  validation loss:		0.286454
  validation accuracy:		93.48 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.025568
  validation loss:		0.293969
  validation accuracy:		93.70 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.024313
  validation loss:		0.296198
  validation accuracy:		93.37 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.023549
  validation loss:		0.297282
  validation accuracy:		93.37 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.024815
  validation loss:		0.293982
  validation accuracy:		93.59 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.025134
  validation loss:		0.296148
  validation accuracy:		93.48 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.025009
  validation loss:		0.301432
  validation accuracy:		93.59 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.024611
  validation loss:		0.303712
  validation accuracy:		93.15 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.023710
  validation loss:		0.299206
  validation accuracy:		93.59 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.024497
  validation loss:		0.299273
  validation accuracy:		93.48 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.024390
  validation loss:		0.296188
  validation accuracy:		93.15 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.024226
  validation loss:		0.297532
  validation accuracy:		93.37 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.023726
  validation loss:		0.302327
  validation accuracy:		93.59 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.024255
  validation loss:		0.303938
  validation accuracy:		93.37 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.023907
  validation loss:		0.303266
  validation accuracy:		93.70 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.024682
  validation loss:		0.297980
  validation accuracy:		93.37 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.023511
  validation loss:		0.305097
  validation accuracy:		93.37 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.023881
  validation loss:		0.304934
  validation accuracy:		93.37 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.024296
  validation loss:		0.307476
  validation accuracy:		93.59 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.024038
  validation loss:		0.293304
  validation accuracy:		93.48 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.023624
  validation loss:		0.304933
  validation accuracy:		93.48 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.024087
  validation loss:		0.299288
  validation accuracy:		93.48 %
Epoch 943 of 2000 took 0.036s
  training loss:		0.023804
  validation loss:		0.302305
  validation accuracy:		93.48 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.022640
  validation loss:		0.304469
  validation accuracy:		93.37 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.023793
  validation loss:		0.304435
  validation accuracy:		93.59 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.024487
  validation loss:		0.303432
  validation accuracy:		93.26 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.023501
  validation loss:		0.304852
  validation accuracy:		93.48 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.023356
  validation loss:		0.305484
  validation accuracy:		93.37 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.023249
  validation loss:		0.305160
  validation accuracy:		93.04 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.024019
  validation loss:		0.303357
  validation accuracy:		93.59 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.023407
  validation loss:		0.295607
  validation accuracy:		93.70 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.023232
  validation loss:		0.300976
  validation accuracy:		93.59 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.023307
  validation loss:		0.301242
  validation accuracy:		93.59 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.022823
  validation loss:		0.310569
  validation accuracy:		93.26 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.023709
  validation loss:		0.304060
  validation accuracy:		93.48 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.022859
  validation loss:		0.303564
  validation accuracy:		93.48 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.021912
  validation loss:		0.306191
  validation accuracy:		93.37 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.023397
  validation loss:		0.302573
  validation accuracy:		93.59 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.023217
  validation loss:		0.313472
  validation accuracy:		93.04 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.022783
  validation loss:		0.316110
  validation accuracy:		93.04 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.023032
  validation loss:		0.310887
  validation accuracy:		93.37 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.022918
  validation loss:		0.307086
  validation accuracy:		93.37 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.022870
  validation loss:		0.304102
  validation accuracy:		93.37 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.022604
  validation loss:		0.302461
  validation accuracy:		93.59 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.022500
  validation loss:		0.310791
  validation accuracy:		93.26 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.022811
  validation loss:		0.306159
  validation accuracy:		93.48 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.022078
  validation loss:		0.308664
  validation accuracy:		93.48 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.021306
  validation loss:		0.305782
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.022099
  validation loss:		0.304011
  validation accuracy:		93.48 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.022609
  validation loss:		0.303284
  validation accuracy:		93.80 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.022459
  validation loss:		0.310974
  validation accuracy:		93.48 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.022472
  validation loss:		0.308250
  validation accuracy:		93.37 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.021525
  validation loss:		0.310587
  validation accuracy:		93.48 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.021427
  validation loss:		0.319104
  validation accuracy:		93.48 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.022154
  validation loss:		0.304169
  validation accuracy:		93.70 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.021667
  validation loss:		0.304814
  validation accuracy:		93.37 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.021687
  validation loss:		0.312104
  validation accuracy:		93.15 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.021948
  validation loss:		0.310335
  validation accuracy:		93.15 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.022263
  validation loss:		0.313199
  validation accuracy:		93.15 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.021751
  validation loss:		0.308910
  validation accuracy:		93.59 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.022171
  validation loss:		0.314014
  validation accuracy:		93.48 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.021409
  validation loss:		0.313237
  validation accuracy:		93.48 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.022025
  validation loss:		0.307911
  validation accuracy:		93.59 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.020691
  validation loss:		0.317992
  validation accuracy:		93.70 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.022082
  validation loss:		0.307930
  validation accuracy:		93.48 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.020560
  validation loss:		0.313215
  validation accuracy:		93.37 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.020520
  validation loss:		0.308616
  validation accuracy:		93.59 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.020119
  validation loss:		0.317278
  validation accuracy:		93.15 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.021258
  validation loss:		0.315608
  validation accuracy:		93.59 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.020999
  validation loss:		0.306575
  validation accuracy:		93.59 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.020829
  validation loss:		0.313817
  validation accuracy:		93.26 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.021471
  validation loss:		0.309140
  validation accuracy:		93.59 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.020064
  validation loss:		0.322807
  validation accuracy:		93.04 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.021180
  validation loss:		0.312108
  validation accuracy:		93.59 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.021356
  validation loss:		0.315535
  validation accuracy:		93.48 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.020621
  validation loss:		0.310571
  validation accuracy:		93.70 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.020966
  validation loss:		0.323508
  validation accuracy:		93.37 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.021121
  validation loss:		0.315315
  validation accuracy:		93.37 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.020665
  validation loss:		0.311532
  validation accuracy:		93.48 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.020224
  validation loss:		0.317749
  validation accuracy:		93.15 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.020890
  validation loss:		0.309923
  validation accuracy:		93.37 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.020907
  validation loss:		0.318097
  validation accuracy:		93.26 %
Epoch 1003 of 2000 took 0.036s
  training loss:		0.019810
  validation loss:		0.318754
  validation accuracy:		93.15 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.020945
  validation loss:		0.312006
  validation accuracy:		93.48 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.020612
  validation loss:		0.312801
  validation accuracy:		93.59 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.019576
  validation loss:		0.321170
  validation accuracy:		93.04 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.020426
  validation loss:		0.316664
  validation accuracy:		93.70 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.020638
  validation loss:		0.320278
  validation accuracy:		93.04 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.020409
  validation loss:		0.320958
  validation accuracy:		93.48 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.020604
  validation loss:		0.314677
  validation accuracy:		93.48 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.019983
  validation loss:		0.319381
  validation accuracy:		93.48 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.020077
  validation loss:		0.318887
  validation accuracy:		93.26 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.020474
  validation loss:		0.320832
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.020564
  validation loss:		0.314973
  validation accuracy:		93.80 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.020068
  validation loss:		0.322026
  validation accuracy:		92.93 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.021008
  validation loss:		0.321001
  validation accuracy:		93.26 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.019888
  validation loss:		0.320072
  validation accuracy:		93.15 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.019915
  validation loss:		0.321768
  validation accuracy:		93.26 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.019493
  validation loss:		0.316456
  validation accuracy:		93.37 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.019121
  validation loss:		0.318690
  validation accuracy:		93.48 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.019476
  validation loss:		0.320741
  validation accuracy:		93.37 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.019761
  validation loss:		0.316248
  validation accuracy:		93.70 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.019276
  validation loss:		0.320395
  validation accuracy:		93.15 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.019393
  validation loss:		0.318643
  validation accuracy:		93.37 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.018646
  validation loss:		0.317594
  validation accuracy:		93.59 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.019386
  validation loss:		0.323920
  validation accuracy:		93.37 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.019576
  validation loss:		0.326008
  validation accuracy:		93.26 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.019759
  validation loss:		0.325777
  validation accuracy:		92.72 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.018768
  validation loss:		0.314949
  validation accuracy:		93.59 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.019432
  validation loss:		0.314938
  validation accuracy:		93.48 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.019044
  validation loss:		0.317540
  validation accuracy:		93.37 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.018931
  validation loss:		0.328323
  validation accuracy:		93.48 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.018684
  validation loss:		0.320670
  validation accuracy:		93.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.019365
  validation loss:		0.320168
  validation accuracy:		93.48 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.018933
  validation loss:		0.322633
  validation accuracy:		93.59 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.018496
  validation loss:		0.319483
  validation accuracy:		93.59 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.018634
  validation loss:		0.318812
  validation accuracy:		93.59 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.019066
  validation loss:		0.326200
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.018529
  validation loss:		0.322320
  validation accuracy:		93.26 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.018276
  validation loss:		0.336934
  validation accuracy:		93.04 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.019031
  validation loss:		0.324846
  validation accuracy:		93.15 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.019122
  validation loss:		0.322794
  validation accuracy:		93.48 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.018285
  validation loss:		0.320306
  validation accuracy:		93.48 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.018863
  validation loss:		0.324025
  validation accuracy:		93.59 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.018447
  validation loss:		0.325257
  validation accuracy:		93.48 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.018303
  validation loss:		0.323039
  validation accuracy:		93.59 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.018212
  validation loss:		0.324335
  validation accuracy:		93.37 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.017919
  validation loss:		0.319270
  validation accuracy:		93.59 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.017843
  validation loss:		0.329778
  validation accuracy:		92.93 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.018186
  validation loss:		0.325976
  validation accuracy:		93.59 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.018110
  validation loss:		0.329059
  validation accuracy:		92.93 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.017718
  validation loss:		0.318223
  validation accuracy:		93.70 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.018629
  validation loss:		0.330981
  validation accuracy:		93.48 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.017962
  validation loss:		0.331332
  validation accuracy:		93.04 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.017871
  validation loss:		0.323982
  validation accuracy:		93.59 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.018055
  validation loss:		0.321373
  validation accuracy:		93.48 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.017917
  validation loss:		0.326142
  validation accuracy:		93.59 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.018065
  validation loss:		0.323261
  validation accuracy:		93.59 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.018176
  validation loss:		0.326142
  validation accuracy:		93.59 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.017635
  validation loss:		0.328493
  validation accuracy:		93.26 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.018239
  validation loss:		0.326958
  validation accuracy:		93.04 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.018419
  validation loss:		0.326494
  validation accuracy:		93.37 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.017648
  validation loss:		0.328301
  validation accuracy:		93.59 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.017042
  validation loss:		0.342896
  validation accuracy:		93.15 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.017987
  validation loss:		0.327606
  validation accuracy:		93.26 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.018231
  validation loss:		0.332865
  validation accuracy:		93.48 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.018085
  validation loss:		0.322430
  validation accuracy:		93.26 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.017765
  validation loss:		0.331541
  validation accuracy:		93.26 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.017546
  validation loss:		0.328270
  validation accuracy:		93.37 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.017392
  validation loss:		0.330412
  validation accuracy:		93.59 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.016423
  validation loss:		0.331372
  validation accuracy:		93.48 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.016933
  validation loss:		0.330913
  validation accuracy:		93.26 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.017366
  validation loss:		0.321825
  validation accuracy:		93.70 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.017528
  validation loss:		0.325373
  validation accuracy:		93.37 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.017038
  validation loss:		0.328894
  validation accuracy:		93.48 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.017046
  validation loss:		0.328167
  validation accuracy:		93.26 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.016707
  validation loss:		0.328917
  validation accuracy:		93.37 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.016765
  validation loss:		0.333626
  validation accuracy:		93.37 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.017074
  validation loss:		0.333784
  validation accuracy:		93.26 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.016992
  validation loss:		0.330034
  validation accuracy:		93.04 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.016965
  validation loss:		0.331698
  validation accuracy:		93.15 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.017155
  validation loss:		0.335944
  validation accuracy:		93.04 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.016902
  validation loss:		0.331562
  validation accuracy:		93.70 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.017323
  validation loss:		0.334036
  validation accuracy:		93.59 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.017148
  validation loss:		0.333206
  validation accuracy:		93.48 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.016771
  validation loss:		0.331648
  validation accuracy:		93.48 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.016671
  validation loss:		0.330984
  validation accuracy:		93.37 %
Epoch 1088 of 2000 took 0.036s
  training loss:		0.017266
  validation loss:		0.332098
  validation accuracy:		93.37 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.016453
  validation loss:		0.326265
  validation accuracy:		93.59 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.016641
  validation loss:		0.324966
  validation accuracy:		93.48 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.016704
  validation loss:		0.342862
  validation accuracy:		93.37 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.016602
  validation loss:		0.344183
  validation accuracy:		93.15 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.016722
  validation loss:		0.326064
  validation accuracy:		93.70 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.016583
  validation loss:		0.335621
  validation accuracy:		93.26 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.016318
  validation loss:		0.339143
  validation accuracy:		93.37 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.016587
  validation loss:		0.328346
  validation accuracy:		93.59 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.016859
  validation loss:		0.342252
  validation accuracy:		93.26 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.016306
  validation loss:		0.338016
  validation accuracy:		92.93 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.015984
  validation loss:		0.333064
  validation accuracy:		93.70 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.016276
  validation loss:		0.342807
  validation accuracy:		93.15 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.016423
  validation loss:		0.336230
  validation accuracy:		93.37 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.015963
  validation loss:		0.328112
  validation accuracy:		93.48 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.016772
  validation loss:		0.331794
  validation accuracy:		93.37 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.016172
  validation loss:		0.335856
  validation accuracy:		93.48 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.015866
  validation loss:		0.332285
  validation accuracy:		93.37 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.015832
  validation loss:		0.344509
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.015781
  validation loss:		0.339857
  validation accuracy:		93.26 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.016005
  validation loss:		0.338397
  validation accuracy:		93.48 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.016234
  validation loss:		0.336099
  validation accuracy:		93.26 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.016116
  validation loss:		0.334880
  validation accuracy:		93.26 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.015050
  validation loss:		0.336553
  validation accuracy:		93.48 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.016362
  validation loss:		0.341712
  validation accuracy:		93.48 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.014818
  validation loss:		0.332641
  validation accuracy:		93.26 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.015731
  validation loss:		0.342283
  validation accuracy:		93.48 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.015781
  validation loss:		0.338210
  validation accuracy:		93.26 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.014570
  validation loss:		0.347109
  validation accuracy:		93.37 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.015643
  validation loss:		0.337178
  validation accuracy:		93.37 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.015837
  validation loss:		0.338782
  validation accuracy:		93.37 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.015881
  validation loss:		0.339650
  validation accuracy:		93.26 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.015076
  validation loss:		0.348275
  validation accuracy:		93.04 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.015130
  validation loss:		0.332612
  validation accuracy:		93.59 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.015308
  validation loss:		0.349750
  validation accuracy:		93.26 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.015622
  validation loss:		0.345967
  validation accuracy:		93.26 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.015070
  validation loss:		0.338299
  validation accuracy:		93.37 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.015308
  validation loss:		0.337714
  validation accuracy:		93.48 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.013973
  validation loss:		0.340455
  validation accuracy:		93.37 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.015159
  validation loss:		0.343284
  validation accuracy:		93.37 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.015802
  validation loss:		0.340800
  validation accuracy:		93.26 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.015561
  validation loss:		0.341742
  validation accuracy:		93.37 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.015345
  validation loss:		0.339436
  validation accuracy:		93.26 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.015284
  validation loss:		0.345714
  validation accuracy:		93.59 %
Epoch 1132 of 2000 took 0.036s
  training loss:		0.015266
  validation loss:		0.342162
  validation accuracy:		93.26 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.015205
  validation loss:		0.337017
  validation accuracy:		93.48 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.015623
  validation loss:		0.346156
  validation accuracy:		93.37 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.015004
  validation loss:		0.335731
  validation accuracy:		93.37 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.014749
  validation loss:		0.341832
  validation accuracy:		93.26 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.014763
  validation loss:		0.339355
  validation accuracy:		93.48 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.015041
  validation loss:		0.345440
  validation accuracy:		93.37 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.014554
  validation loss:		0.346078
  validation accuracy:		93.26 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.014850
  validation loss:		0.348625
  validation accuracy:		93.37 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.013923
  validation loss:		0.347512
  validation accuracy:		93.26 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.014583
  validation loss:		0.335304
  validation accuracy:		93.59 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.015089
  validation loss:		0.348074
  validation accuracy:		93.15 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.014416
  validation loss:		0.338351
  validation accuracy:		93.37 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.014806
  validation loss:		0.341597
  validation accuracy:		93.59 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.014714
  validation loss:		0.338225
  validation accuracy:		93.59 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.014833
  validation loss:		0.349744
  validation accuracy:		93.26 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.015133
  validation loss:		0.345409
  validation accuracy:		93.15 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.014646
  validation loss:		0.346154
  validation accuracy:		93.37 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.014690
  validation loss:		0.350008
  validation accuracy:		93.04 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.014448
  validation loss:		0.343459
  validation accuracy:		93.37 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.014319
  validation loss:		0.351532
  validation accuracy:		93.37 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.014837
  validation loss:		0.341220
  validation accuracy:		93.37 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.014630
  validation loss:		0.347685
  validation accuracy:		93.37 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.014686
  validation loss:		0.342459
  validation accuracy:		93.26 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.014327
  validation loss:		0.351562
  validation accuracy:		93.37 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.013913
  validation loss:		0.349136
  validation accuracy:		93.26 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.014178
  validation loss:		0.350740
  validation accuracy:		93.26 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.013936
  validation loss:		0.345354
  validation accuracy:		93.48 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.013756
  validation loss:		0.345863
  validation accuracy:		93.26 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.013855
  validation loss:		0.348720
  validation accuracy:		93.37 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.013991
  validation loss:		0.344302
  validation accuracy:		93.37 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.013873
  validation loss:		0.350516
  validation accuracy:		93.15 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.014155
  validation loss:		0.348795
  validation accuracy:		93.48 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.014604
  validation loss:		0.359700
  validation accuracy:		93.48 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.014306
  validation loss:		0.341642
  validation accuracy:		93.59 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.013484
  validation loss:		0.352084
  validation accuracy:		93.37 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.013837
  validation loss:		0.347248
  validation accuracy:		93.26 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.013566
  validation loss:		0.343705
  validation accuracy:		93.37 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.013744
  validation loss:		0.349027
  validation accuracy:		93.15 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.013283
  validation loss:		0.352828
  validation accuracy:		93.26 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.014053
  validation loss:		0.354319
  validation accuracy:		93.15 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.013843
  validation loss:		0.351225
  validation accuracy:		93.04 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.013584
  validation loss:		0.345932
  validation accuracy:		93.37 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.013333
  validation loss:		0.342135
  validation accuracy:		93.48 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.014425
  validation loss:		0.353371
  validation accuracy:		93.04 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.014209
  validation loss:		0.350545
  validation accuracy:		93.26 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.013727
  validation loss:		0.348807
  validation accuracy:		93.37 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.013506
  validation loss:		0.357619
  validation accuracy:		93.15 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.013869
  validation loss:		0.353266
  validation accuracy:		93.15 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.014021
  validation loss:		0.350517
  validation accuracy:		93.26 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.013503
  validation loss:		0.353884
  validation accuracy:		93.15 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.013681
  validation loss:		0.346158
  validation accuracy:		93.48 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.013972
  validation loss:		0.346254
  validation accuracy:		93.48 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.013821
  validation loss:		0.352300
  validation accuracy:		93.26 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.013366
  validation loss:		0.354068
  validation accuracy:		93.15 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.013374
  validation loss:		0.352864
  validation accuracy:		93.26 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.012660
  validation loss:		0.354459
  validation accuracy:		93.37 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.013353
  validation loss:		0.353235
  validation accuracy:		93.26 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.013540
  validation loss:		0.349596
  validation accuracy:		93.70 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.013362
  validation loss:		0.352940
  validation accuracy:		93.26 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.013351
  validation loss:		0.361953
  validation accuracy:		93.15 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.013378
  validation loss:		0.346139
  validation accuracy:		93.37 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.013316
  validation loss:		0.354513
  validation accuracy:		93.26 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.012898
  validation loss:		0.351593
  validation accuracy:		93.37 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.012877
  validation loss:		0.351030
  validation accuracy:		93.37 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.013562
  validation loss:		0.350927
  validation accuracy:		93.37 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.013154
  validation loss:		0.357459
  validation accuracy:		93.26 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.013205
  validation loss:		0.351587
  validation accuracy:		93.48 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.012768
  validation loss:		0.360630
  validation accuracy:		93.37 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.012900
  validation loss:		0.358630
  validation accuracy:		93.26 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.012560
  validation loss:		0.354520
  validation accuracy:		93.48 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.013255
  validation loss:		0.353000
  validation accuracy:		93.37 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.012508
  validation loss:		0.349868
  validation accuracy:		93.48 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.012835
  validation loss:		0.348866
  validation accuracy:		93.48 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.012841
  validation loss:		0.359911
  validation accuracy:		93.26 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.012656
  validation loss:		0.347344
  validation accuracy:		93.48 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.012416
  validation loss:		0.358644
  validation accuracy:		93.26 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.012718
  validation loss:		0.358786
  validation accuracy:		93.26 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.012520
  validation loss:		0.356197
  validation accuracy:		93.59 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.013033
  validation loss:		0.356864
  validation accuracy:		93.37 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.011975
  validation loss:		0.360912
  validation accuracy:		93.26 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.012281
  validation loss:		0.360065
  validation accuracy:		93.59 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.012766
  validation loss:		0.355800
  validation accuracy:		93.37 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.012772
  validation loss:		0.355139
  validation accuracy:		93.37 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.012193
  validation loss:		0.364278
  validation accuracy:		93.26 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.012583
  validation loss:		0.362269
  validation accuracy:		93.26 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.012371
  validation loss:		0.360589
  validation accuracy:		92.83 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.011704
  validation loss:		0.363809
  validation accuracy:		93.26 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.012523
  validation loss:		0.358174
  validation accuracy:		93.48 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.012312
  validation loss:		0.359030
  validation accuracy:		93.15 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.012670
  validation loss:		0.351302
  validation accuracy:		93.48 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.012643
  validation loss:		0.365804
  validation accuracy:		93.48 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.012496
  validation loss:		0.361182
  validation accuracy:		93.04 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.011996
  validation loss:		0.360522
  validation accuracy:		93.37 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.012182
  validation loss:		0.368148
  validation accuracy:		93.37 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.012656
  validation loss:		0.355200
  validation accuracy:		93.48 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.012395
  validation loss:		0.365544
  validation accuracy:		93.04 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.012065
  validation loss:		0.362126
  validation accuracy:		93.15 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.012499
  validation loss:		0.363096
  validation accuracy:		93.15 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.012490
  validation loss:		0.362097
  validation accuracy:		93.37 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.011744
  validation loss:		0.361977
  validation accuracy:		93.26 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.012008
  validation loss:		0.363348
  validation accuracy:		93.26 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.011866
  validation loss:		0.361475
  validation accuracy:		93.48 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.012294
  validation loss:		0.359721
  validation accuracy:		93.26 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.011804
  validation loss:		0.358075
  validation accuracy:		93.26 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.011929
  validation loss:		0.356719
  validation accuracy:		93.48 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.012301
  validation loss:		0.362712
  validation accuracy:		93.15 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.011964
  validation loss:		0.360932
  validation accuracy:		93.48 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.011966
  validation loss:		0.371690
  validation accuracy:		93.04 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.011750
  validation loss:		0.358119
  validation accuracy:		93.37 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.011489
  validation loss:		0.361571
  validation accuracy:		93.26 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.012499
  validation loss:		0.368798
  validation accuracy:		93.04 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.011286
  validation loss:		0.359457
  validation accuracy:		93.26 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.012247
  validation loss:		0.367143
  validation accuracy:		93.15 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.011877
  validation loss:		0.367587
  validation accuracy:		93.15 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.011454
  validation loss:		0.366749
  validation accuracy:		93.26 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.011756
  validation loss:		0.367581
  validation accuracy:		93.04 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.011715
  validation loss:		0.357747
  validation accuracy:		93.37 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.011749
  validation loss:		0.367223
  validation accuracy:		93.26 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.011189
  validation loss:		0.366032
  validation accuracy:		93.26 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.011228
  validation loss:		0.366616
  validation accuracy:		93.15 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.011743
  validation loss:		0.371793
  validation accuracy:		93.15 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.011734
  validation loss:		0.366548
  validation accuracy:		93.59 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.012136
  validation loss:		0.365623
  validation accuracy:		93.37 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.011424
  validation loss:		0.369148
  validation accuracy:		93.15 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.011648
  validation loss:		0.361234
  validation accuracy:		93.15 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.011455
  validation loss:		0.364292
  validation accuracy:		93.26 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.011489
  validation loss:		0.365631
  validation accuracy:		93.26 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.011541
  validation loss:		0.366813
  validation accuracy:		93.15 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.011315
  validation loss:		0.364054
  validation accuracy:		93.37 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.011127
  validation loss:		0.362342
  validation accuracy:		93.37 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.011391
  validation loss:		0.366808
  validation accuracy:		93.26 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.011199
  validation loss:		0.363533
  validation accuracy:		93.48 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.011312
  validation loss:		0.366340
  validation accuracy:		93.37 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.011486
  validation loss:		0.366616
  validation accuracy:		93.15 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.011232
  validation loss:		0.363549
  validation accuracy:		93.37 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.011496
  validation loss:		0.366186
  validation accuracy:		93.37 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.011387
  validation loss:		0.372167
  validation accuracy:		93.04 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.011453
  validation loss:		0.369276
  validation accuracy:		93.26 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.011205
  validation loss:		0.365328
  validation accuracy:		93.26 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.010944
  validation loss:		0.370101
  validation accuracy:		93.48 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.011816
  validation loss:		0.369463
  validation accuracy:		93.15 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.011093
  validation loss:		0.371287
  validation accuracy:		93.15 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.010772
  validation loss:		0.373532
  validation accuracy:		93.26 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.011042
  validation loss:		0.369162
  validation accuracy:		93.48 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.011230
  validation loss:		0.367204
  validation accuracy:		93.37 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.011045
  validation loss:		0.368530
  validation accuracy:		93.37 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.010824
  validation loss:		0.371641
  validation accuracy:		93.15 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.011081
  validation loss:		0.371860
  validation accuracy:		93.26 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.011248
  validation loss:		0.374856
  validation accuracy:		93.15 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.011054
  validation loss:		0.367293
  validation accuracy:		93.37 %
Epoch 1283 of 2000 took 0.036s
  training loss:		0.010978
  validation loss:		0.366000
  validation accuracy:		93.37 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.010609
  validation loss:		0.371223
  validation accuracy:		93.15 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.010852
  validation loss:		0.370431
  validation accuracy:		93.04 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.010823
  validation loss:		0.374349
  validation accuracy:		93.15 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.010962
  validation loss:		0.369787
  validation accuracy:		93.26 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.010754
  validation loss:		0.368434
  validation accuracy:		93.26 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.010878
  validation loss:		0.366082
  validation accuracy:		93.59 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.010567
  validation loss:		0.376545
  validation accuracy:		93.04 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.010712
  validation loss:		0.378574
  validation accuracy:		93.37 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.010208
  validation loss:		0.369476
  validation accuracy:		93.37 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.010593
  validation loss:		0.371976
  validation accuracy:		93.48 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.010637
  validation loss:		0.378863
  validation accuracy:		93.26 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.010530
  validation loss:		0.368046
  validation accuracy:		93.26 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.010772
  validation loss:		0.377730
  validation accuracy:		93.15 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.010366
  validation loss:		0.372290
  validation accuracy:		93.26 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.010472
  validation loss:		0.372656
  validation accuracy:		93.59 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.010375
  validation loss:		0.373106
  validation accuracy:		93.26 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.010810
  validation loss:		0.377031
  validation accuracy:		93.04 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.010802
  validation loss:		0.372143
  validation accuracy:		93.80 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.010456
  validation loss:		0.373573
  validation accuracy:		93.26 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.010274
  validation loss:		0.368703
  validation accuracy:		93.26 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.010144
  validation loss:		0.368911
  validation accuracy:		93.37 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.010407
  validation loss:		0.380194
  validation accuracy:		93.04 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.010188
  validation loss:		0.374717
  validation accuracy:		93.04 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.010450
  validation loss:		0.374620
  validation accuracy:		93.26 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.010471
  validation loss:		0.370553
  validation accuracy:		93.04 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.010255
  validation loss:		0.375831
  validation accuracy:		93.15 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.010463
  validation loss:		0.373164
  validation accuracy:		93.37 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.010180
  validation loss:		0.374546
  validation accuracy:		93.48 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.010394
  validation loss:		0.378677
  validation accuracy:		93.26 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.010554
  validation loss:		0.380896
  validation accuracy:		93.04 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.010486
  validation loss:		0.376155
  validation accuracy:		93.37 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.010054
  validation loss:		0.375465
  validation accuracy:		93.04 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.010475
  validation loss:		0.375450
  validation accuracy:		93.26 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.010246
  validation loss:		0.376258
  validation accuracy:		93.26 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.010398
  validation loss:		0.385433
  validation accuracy:		93.15 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.009748
  validation loss:		0.378030
  validation accuracy:		93.15 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.010146
  validation loss:		0.375555
  validation accuracy:		93.26 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.010236
  validation loss:		0.377058
  validation accuracy:		93.15 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.010091
  validation loss:		0.378331
  validation accuracy:		93.15 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.010043
  validation loss:		0.375648
  validation accuracy:		93.15 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.009558
  validation loss:		0.376165
  validation accuracy:		93.48 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.010006
  validation loss:		0.380910
  validation accuracy:		93.04 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.010023
  validation loss:		0.383352
  validation accuracy:		93.04 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.010075
  validation loss:		0.380301
  validation accuracy:		93.26 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.010195
  validation loss:		0.384129
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.009841
  validation loss:		0.372135
  validation accuracy:		93.37 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.010101
  validation loss:		0.382018
  validation accuracy:		93.04 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.009614
  validation loss:		0.382542
  validation accuracy:		93.04 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.009906
  validation loss:		0.379631
  validation accuracy:		93.15 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.010027
  validation loss:		0.379819
  validation accuracy:		93.04 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.009732
  validation loss:		0.384478
  validation accuracy:		93.48 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.009684
  validation loss:		0.382526
  validation accuracy:		92.93 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.009629
  validation loss:		0.380799
  validation accuracy:		93.04 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.009909
  validation loss:		0.378691
  validation accuracy:		93.15 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.009815
  validation loss:		0.380661
  validation accuracy:		93.15 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.009752
  validation loss:		0.384915
  validation accuracy:		93.04 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.009745
  validation loss:		0.379655
  validation accuracy:		93.15 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.009510
  validation loss:		0.384184
  validation accuracy:		93.15 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.009725
  validation loss:		0.382015
  validation accuracy:		93.04 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.009783
  validation loss:		0.382302
  validation accuracy:		93.15 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.009786
  validation loss:		0.382255
  validation accuracy:		93.26 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.009546
  validation loss:		0.381074
  validation accuracy:		93.04 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.009161
  validation loss:		0.383220
  validation accuracy:		93.15 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.009577
  validation loss:		0.383689
  validation accuracy:		93.26 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.009539
  validation loss:		0.388272
  validation accuracy:		93.04 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.009486
  validation loss:		0.385225
  validation accuracy:		93.15 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.009587
  validation loss:		0.383593
  validation accuracy:		93.26 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.009859
  validation loss:		0.383144
  validation accuracy:		93.15 %
Epoch 1352 of 2000 took 0.037s
  training loss:		0.009666
  validation loss:		0.381980
  validation accuracy:		93.04 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.009521
  validation loss:		0.383004
  validation accuracy:		93.26 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.009048
  validation loss:		0.383836
  validation accuracy:		93.48 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.009066
  validation loss:		0.384101
  validation accuracy:		93.04 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.009392
  validation loss:		0.389255
  validation accuracy:		92.93 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.009241
  validation loss:		0.380568
  validation accuracy:		93.15 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.009276
  validation loss:		0.387288
  validation accuracy:		93.15 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.009099
  validation loss:		0.388385
  validation accuracy:		93.15 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.009418
  validation loss:		0.390441
  validation accuracy:		93.15 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.009571
  validation loss:		0.387124
  validation accuracy:		93.15 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.008879
  validation loss:		0.391354
  validation accuracy:		92.83 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.009323
  validation loss:		0.389227
  validation accuracy:		93.26 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.009300
  validation loss:		0.387012
  validation accuracy:		93.48 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.009079
  validation loss:		0.381418
  validation accuracy:		93.26 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.009225
  validation loss:		0.390122
  validation accuracy:		93.26 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.008921
  validation loss:		0.385257
  validation accuracy:		93.26 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.009400
  validation loss:		0.382569
  validation accuracy:		93.15 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.009040
  validation loss:		0.386871
  validation accuracy:		93.04 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.009076
  validation loss:		0.387777
  validation accuracy:		93.26 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.008953
  validation loss:		0.392105
  validation accuracy:		93.04 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.008977
  validation loss:		0.388295
  validation accuracy:		93.04 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.008872
  validation loss:		0.387257
  validation accuracy:		93.26 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.008909
  validation loss:		0.387947
  validation accuracy:		93.15 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.009050
  validation loss:		0.386657
  validation accuracy:		93.37 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.009506
  validation loss:		0.387157
  validation accuracy:		93.15 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.008838
  validation loss:		0.396938
  validation accuracy:		93.04 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.009086
  validation loss:		0.389236
  validation accuracy:		93.04 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.008974
  validation loss:		0.385842
  validation accuracy:		93.15 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.008894
  validation loss:		0.388525
  validation accuracy:		93.04 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.008950
  validation loss:		0.390038
  validation accuracy:		93.15 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.008597
  validation loss:		0.388581
  validation accuracy:		93.04 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.008877
  validation loss:		0.387506
  validation accuracy:		93.15 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.008876
  validation loss:		0.388655
  validation accuracy:		93.15 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.008668
  validation loss:		0.394455
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.008907
  validation loss:		0.391730
  validation accuracy:		93.04 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.008709
  validation loss:		0.389088
  validation accuracy:		93.26 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.008833
  validation loss:		0.393260
  validation accuracy:		93.26 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.008770
  validation loss:		0.393679
  validation accuracy:		92.83 %
Epoch 1390 of 2000 took 0.037s
  training loss:		0.008758
  validation loss:		0.386719
  validation accuracy:		93.15 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.008367
  validation loss:		0.386199
  validation accuracy:		93.15 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.008307
  validation loss:		0.396693
  validation accuracy:		92.93 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.008678
  validation loss:		0.393625
  validation accuracy:		93.37 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.008713
  validation loss:		0.385208
  validation accuracy:		93.15 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.008637
  validation loss:		0.392663
  validation accuracy:		92.93 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.008922
  validation loss:		0.392469
  validation accuracy:		93.15 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.008390
  validation loss:		0.386079
  validation accuracy:		93.15 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.008535
  validation loss:		0.393465
  validation accuracy:		93.04 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.008462
  validation loss:		0.398033
  validation accuracy:		93.04 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.008553
  validation loss:		0.392749
  validation accuracy:		93.26 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.008594
  validation loss:		0.396167
  validation accuracy:		93.04 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.008193
  validation loss:		0.392221
  validation accuracy:		93.15 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.008691
  validation loss:		0.392888
  validation accuracy:		93.04 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.008145
  validation loss:		0.394409
  validation accuracy:		93.26 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.008451
  validation loss:		0.394377
  validation accuracy:		93.04 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.008490
  validation loss:		0.390528
  validation accuracy:		93.26 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.008410
  validation loss:		0.390381
  validation accuracy:		93.04 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.008472
  validation loss:		0.389844
  validation accuracy:		93.37 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.008741
  validation loss:		0.398442
  validation accuracy:		93.37 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.008222
  validation loss:		0.389505
  validation accuracy:		93.15 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.008363
  validation loss:		0.390872
  validation accuracy:		93.15 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.008521
  validation loss:		0.393613
  validation accuracy:		93.26 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.008303
  validation loss:		0.391435
  validation accuracy:		93.26 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.008368
  validation loss:		0.396074
  validation accuracy:		92.93 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.008434
  validation loss:		0.395896
  validation accuracy:		92.93 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.008341
  validation loss:		0.398945
  validation accuracy:		93.15 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.008034
  validation loss:		0.396292
  validation accuracy:		93.26 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.008381
  validation loss:		0.399212
  validation accuracy:		92.93 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.008567
  validation loss:		0.394810
  validation accuracy:		93.04 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.008437
  validation loss:		0.394711
  validation accuracy:		93.04 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.008182
  validation loss:		0.395840
  validation accuracy:		93.26 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.008019
  validation loss:		0.395937
  validation accuracy:		93.26 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.008266
  validation loss:		0.392401
  validation accuracy:		93.04 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.007934
  validation loss:		0.399148
  validation accuracy:		92.93 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.008156
  validation loss:		0.394054
  validation accuracy:		93.15 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.008027
  validation loss:		0.400007
  validation accuracy:		93.04 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.008016
  validation loss:		0.392449
  validation accuracy:		93.15 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.007881
  validation loss:		0.397501
  validation accuracy:		93.15 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.008010
  validation loss:		0.398732
  validation accuracy:		92.93 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.007986
  validation loss:		0.398944
  validation accuracy:		92.93 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.008022
  validation loss:		0.405324
  validation accuracy:		92.83 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.008224
  validation loss:		0.397939
  validation accuracy:		93.04 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.007723
  validation loss:		0.396292
  validation accuracy:		93.15 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.007952
  validation loss:		0.400352
  validation accuracy:		93.26 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.008155
  validation loss:		0.399633
  validation accuracy:		93.15 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.008156
  validation loss:		0.399500
  validation accuracy:		93.15 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.007900
  validation loss:		0.400668
  validation accuracy:		93.04 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.007960
  validation loss:		0.400393
  validation accuracy:		93.04 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.007963
  validation loss:		0.398668
  validation accuracy:		93.15 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.007748
  validation loss:		0.400653
  validation accuracy:		93.15 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.007896
  validation loss:		0.394682
  validation accuracy:		93.26 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.007967
  validation loss:		0.394238
  validation accuracy:		93.15 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.007681
  validation loss:		0.399032
  validation accuracy:		93.04 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.007939
  validation loss:		0.399457
  validation accuracy:		93.04 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.007974
  validation loss:		0.402332
  validation accuracy:		93.15 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.007859
  validation loss:		0.400340
  validation accuracy:		93.15 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.007387
  validation loss:		0.399213
  validation accuracy:		93.04 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.007821
  validation loss:		0.397667
  validation accuracy:		93.04 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.007858
  validation loss:		0.399586
  validation accuracy:		93.15 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.007724
  validation loss:		0.395297
  validation accuracy:		93.37 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007824
  validation loss:		0.404697
  validation accuracy:		93.04 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.007534
  validation loss:		0.400831
  validation accuracy:		93.15 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.405196
  validation accuracy:		93.15 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.007719
  validation loss:		0.401777
  validation accuracy:		93.26 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.007709
  validation loss:		0.400376
  validation accuracy:		93.04 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.007464
  validation loss:		0.403430
  validation accuracy:		92.83 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.007730
  validation loss:		0.404622
  validation accuracy:		93.04 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.007742
  validation loss:		0.398345
  validation accuracy:		93.15 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.007519
  validation loss:		0.397397
  validation accuracy:		93.37 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007587
  validation loss:		0.402006
  validation accuracy:		93.15 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.007447
  validation loss:		0.407348
  validation accuracy:		92.93 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.007367
  validation loss:		0.404807
  validation accuracy:		93.04 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.007381
  validation loss:		0.401316
  validation accuracy:		93.15 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.007717
  validation loss:		0.402323
  validation accuracy:		93.15 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.007635
  validation loss:		0.405823
  validation accuracy:		92.93 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.007435
  validation loss:		0.404482
  validation accuracy:		93.04 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.007759
  validation loss:		0.404952
  validation accuracy:		93.04 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.007619
  validation loss:		0.410143
  validation accuracy:		92.83 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.007314
  validation loss:		0.401406
  validation accuracy:		93.15 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007411
  validation loss:		0.402533
  validation accuracy:		93.04 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.007489
  validation loss:		0.403833
  validation accuracy:		93.15 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.007343
  validation loss:		0.410512
  validation accuracy:		93.15 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007713
  validation loss:		0.405632
  validation accuracy:		93.37 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007358
  validation loss:		0.403834
  validation accuracy:		93.15 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.007291
  validation loss:		0.407205
  validation accuracy:		93.26 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.007436
  validation loss:		0.404785
  validation accuracy:		92.93 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.007207
  validation loss:		0.403608
  validation accuracy:		93.04 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.007203
  validation loss:		0.407679
  validation accuracy:		93.04 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.007442
  validation loss:		0.407341
  validation accuracy:		93.15 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.007440
  validation loss:		0.403776
  validation accuracy:		93.15 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.007200
  validation loss:		0.407450
  validation accuracy:		93.04 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.007242
  validation loss:		0.406063
  validation accuracy:		92.93 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.007135
  validation loss:		0.406656
  validation accuracy:		93.26 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.007473
  validation loss:		0.401765
  validation accuracy:		93.15 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.007374
  validation loss:		0.406348
  validation accuracy:		93.15 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.007227
  validation loss:		0.411392
  validation accuracy:		93.04 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.006877
  validation loss:		0.405150
  validation accuracy:		93.15 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.007231
  validation loss:		0.412596
  validation accuracy:		93.26 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.007281
  validation loss:		0.407248
  validation accuracy:		93.15 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.007386
  validation loss:		0.404717
  validation accuracy:		93.15 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.007315
  validation loss:		0.411034
  validation accuracy:		92.83 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.007034
  validation loss:		0.402663
  validation accuracy:		93.04 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.007199
  validation loss:		0.413702
  validation accuracy:		93.26 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.007224
  validation loss:		0.408589
  validation accuracy:		93.15 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.007059
  validation loss:		0.402778
  validation accuracy:		93.26 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.007162
  validation loss:		0.407096
  validation accuracy:		93.04 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.007090
  validation loss:		0.407823
  validation accuracy:		93.04 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.007108
  validation loss:		0.405665
  validation accuracy:		93.26 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.007130
  validation loss:		0.408016
  validation accuracy:		93.15 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.007030
  validation loss:		0.409383
  validation accuracy:		93.04 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.006759
  validation loss:		0.411650
  validation accuracy:		92.83 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.007230
  validation loss:		0.409950
  validation accuracy:		93.15 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.007169
  validation loss:		0.409929
  validation accuracy:		93.15 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.006970
  validation loss:		0.409705
  validation accuracy:		93.04 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.006938
  validation loss:		0.407973
  validation accuracy:		93.26 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.007117
  validation loss:		0.418177
  validation accuracy:		92.93 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.007145
  validation loss:		0.410897
  validation accuracy:		93.04 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.007016
  validation loss:		0.409617
  validation accuracy:		93.15 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.007159
  validation loss:		0.414896
  validation accuracy:		93.04 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.006779
  validation loss:		0.409386
  validation accuracy:		93.04 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.006925
  validation loss:		0.411369
  validation accuracy:		93.04 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.006851
  validation loss:		0.413872
  validation accuracy:		93.15 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.006935
  validation loss:		0.413569
  validation accuracy:		92.83 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.006722
  validation loss:		0.403238
  validation accuracy:		93.15 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.006883
  validation loss:		0.410809
  validation accuracy:		93.15 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.006980
  validation loss:		0.414777
  validation accuracy:		93.26 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.006980
  validation loss:		0.411754
  validation accuracy:		93.15 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.006402
  validation loss:		0.410115
  validation accuracy:		93.04 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.006649
  validation loss:		0.415155
  validation accuracy:		93.04 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.006730
  validation loss:		0.407675
  validation accuracy:		93.15 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.006907
  validation loss:		0.406622
  validation accuracy:		93.26 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.006897
  validation loss:		0.410010
  validation accuracy:		93.26 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.007022
  validation loss:		0.412655
  validation accuracy:		93.15 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.006836
  validation loss:		0.409545
  validation accuracy:		93.26 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.006680
  validation loss:		0.416733
  validation accuracy:		92.93 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.006720
  validation loss:		0.415864
  validation accuracy:		93.26 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.006854
  validation loss:		0.411915
  validation accuracy:		93.04 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.006766
  validation loss:		0.416660
  validation accuracy:		92.83 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.006492
  validation loss:		0.411737
  validation accuracy:		93.26 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.006766
  validation loss:		0.410646
  validation accuracy:		93.15 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006432
  validation loss:		0.415418
  validation accuracy:		93.15 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.006438
  validation loss:		0.411818
  validation accuracy:		93.04 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.006758
  validation loss:		0.415598
  validation accuracy:		93.15 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006725
  validation loss:		0.416810
  validation accuracy:		93.04 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.006674
  validation loss:		0.413657
  validation accuracy:		93.15 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.006548
  validation loss:		0.417702
  validation accuracy:		92.93 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.006577
  validation loss:		0.410806
  validation accuracy:		93.15 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.006546
  validation loss:		0.425138
  validation accuracy:		93.04 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006399
  validation loss:		0.412719
  validation accuracy:		92.93 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.006495
  validation loss:		0.417068
  validation accuracy:		93.15 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006645
  validation loss:		0.410864
  validation accuracy:		93.26 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.006906
  validation loss:		0.409436
  validation accuracy:		93.15 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.006374
  validation loss:		0.426349
  validation accuracy:		93.04 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.006601
  validation loss:		0.420440
  validation accuracy:		93.04 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006529
  validation loss:		0.414381
  validation accuracy:		93.15 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.006470
  validation loss:		0.417284
  validation accuracy:		93.04 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006570
  validation loss:		0.418426
  validation accuracy:		93.15 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006582
  validation loss:		0.414950
  validation accuracy:		93.37 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.006533
  validation loss:		0.412249
  validation accuracy:		93.15 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006427
  validation loss:		0.419485
  validation accuracy:		93.04 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.418106
  validation accuracy:		93.04 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006515
  validation loss:		0.414523
  validation accuracy:		93.26 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.006423
  validation loss:		0.416594
  validation accuracy:		93.15 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006299
  validation loss:		0.418520
  validation accuracy:		93.15 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006375
  validation loss:		0.414048
  validation accuracy:		93.04 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.006407
  validation loss:		0.418883
  validation accuracy:		93.04 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006395
  validation loss:		0.417266
  validation accuracy:		93.04 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006369
  validation loss:		0.421196
  validation accuracy:		93.15 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.006254
  validation loss:		0.413629
  validation accuracy:		93.15 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006575
  validation loss:		0.418851
  validation accuracy:		93.37 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.006186
  validation loss:		0.419379
  validation accuracy:		93.04 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.006252
  validation loss:		0.413673
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.006250
  validation loss:		0.424649
  validation accuracy:		93.26 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.006248
  validation loss:		0.413491
  validation accuracy:		93.26 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.006479
  validation loss:		0.425187
  validation accuracy:		93.04 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.006097
  validation loss:		0.416521
  validation accuracy:		93.15 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.006391
  validation loss:		0.426565
  validation accuracy:		92.93 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006291
  validation loss:		0.415353
  validation accuracy:		93.37 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006545
  validation loss:		0.423710
  validation accuracy:		93.04 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.422218
  validation accuracy:		93.15 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.006210
  validation loss:		0.413599
  validation accuracy:		93.26 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.006279
  validation loss:		0.424029
  validation accuracy:		93.04 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.006358
  validation loss:		0.425485
  validation accuracy:		93.04 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006062
  validation loss:		0.421620
  validation accuracy:		93.15 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.006428
  validation loss:		0.417263
  validation accuracy:		93.04 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.006107
  validation loss:		0.420370
  validation accuracy:		93.04 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.006010
  validation loss:		0.423554
  validation accuracy:		93.15 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.006128
  validation loss:		0.420672
  validation accuracy:		93.15 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.006078
  validation loss:		0.422211
  validation accuracy:		93.26 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.006366
  validation loss:		0.420267
  validation accuracy:		93.26 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.006048
  validation loss:		0.428331
  validation accuracy:		93.04 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.006023
  validation loss:		0.420513
  validation accuracy:		93.26 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.006210
  validation loss:		0.424070
  validation accuracy:		93.15 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.005845
  validation loss:		0.419852
  validation accuracy:		93.15 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.006290
  validation loss:		0.418960
  validation accuracy:		93.15 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.006138
  validation loss:		0.427116
  validation accuracy:		92.93 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.006157
  validation loss:		0.423922
  validation accuracy:		92.93 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.006151
  validation loss:		0.425893
  validation accuracy:		92.93 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.006073
  validation loss:		0.425742
  validation accuracy:		93.04 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.006109
  validation loss:		0.426428
  validation accuracy:		93.04 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.005935
  validation loss:		0.423557
  validation accuracy:		93.15 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.005901
  validation loss:		0.421733
  validation accuracy:		93.15 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.006124
  validation loss:		0.417876
  validation accuracy:		93.15 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006071
  validation loss:		0.422304
  validation accuracy:		93.15 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005910
  validation loss:		0.427267
  validation accuracy:		93.15 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.006038
  validation loss:		0.420737
  validation accuracy:		93.15 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.006031
  validation loss:		0.424634
  validation accuracy:		93.15 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.005977
  validation loss:		0.424704
  validation accuracy:		93.04 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.005592
  validation loss:		0.423116
  validation accuracy:		93.15 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.005846
  validation loss:		0.424787
  validation accuracy:		93.04 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.005996
  validation loss:		0.424111
  validation accuracy:		93.26 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.005847
  validation loss:		0.428839
  validation accuracy:		93.04 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.006121
  validation loss:		0.425908
  validation accuracy:		93.15 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005692
  validation loss:		0.425183
  validation accuracy:		93.04 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005862
  validation loss:		0.426252
  validation accuracy:		93.04 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.005828
  validation loss:		0.429310
  validation accuracy:		92.93 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.005997
  validation loss:		0.422140
  validation accuracy:		93.26 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.005778
  validation loss:		0.427462
  validation accuracy:		92.93 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005883
  validation loss:		0.421591
  validation accuracy:		93.15 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.005894
  validation loss:		0.426933
  validation accuracy:		93.26 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.005936
  validation loss:		0.427414
  validation accuracy:		93.15 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005668
  validation loss:		0.426189
  validation accuracy:		93.15 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005637
  validation loss:		0.425840
  validation accuracy:		93.15 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.005657
  validation loss:		0.428225
  validation accuracy:		93.15 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.005813
  validation loss:		0.429116
  validation accuracy:		93.15 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.005712
  validation loss:		0.424180
  validation accuracy:		93.15 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.005868
  validation loss:		0.426199
  validation accuracy:		93.26 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005680
  validation loss:		0.429505
  validation accuracy:		93.15 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.005462
  validation loss:		0.426337
  validation accuracy:		93.04 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.005912
  validation loss:		0.428262
  validation accuracy:		93.26 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005861
  validation loss:		0.424596
  validation accuracy:		93.15 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.005721
  validation loss:		0.427346
  validation accuracy:		93.37 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.005831
  validation loss:		0.427322
  validation accuracy:		93.04 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.005609
  validation loss:		0.430964
  validation accuracy:		93.04 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.005717
  validation loss:		0.429868
  validation accuracy:		93.15 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.005605
  validation loss:		0.431321
  validation accuracy:		93.26 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005565
  validation loss:		0.427713
  validation accuracy:		93.15 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005744
  validation loss:		0.429293
  validation accuracy:		93.15 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.005550
  validation loss:		0.429465
  validation accuracy:		93.04 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.005606
  validation loss:		0.432266
  validation accuracy:		93.15 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005814
  validation loss:		0.425396
  validation accuracy:		93.26 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005706
  validation loss:		0.432620
  validation accuracy:		93.15 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.005642
  validation loss:		0.431868
  validation accuracy:		93.15 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.005367
  validation loss:		0.430501
  validation accuracy:		93.04 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005495
  validation loss:		0.430697
  validation accuracy:		92.93 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005588
  validation loss:		0.427348
  validation accuracy:		93.26 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005477
  validation loss:		0.433205
  validation accuracy:		93.04 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.005560
  validation loss:		0.427131
  validation accuracy:		93.26 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005696
  validation loss:		0.431278
  validation accuracy:		93.26 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005603
  validation loss:		0.436652
  validation accuracy:		92.83 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.005478
  validation loss:		0.433581
  validation accuracy:		93.26 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005616
  validation loss:		0.432174
  validation accuracy:		93.15 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005506
  validation loss:		0.429674
  validation accuracy:		93.37 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005446
  validation loss:		0.433070
  validation accuracy:		93.15 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.005594
  validation loss:		0.428844
  validation accuracy:		93.15 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.005548
  validation loss:		0.434850
  validation accuracy:		92.93 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.005502
  validation loss:		0.429804
  validation accuracy:		93.15 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.005510
  validation loss:		0.439163
  validation accuracy:		92.83 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005677
  validation loss:		0.435865
  validation accuracy:		93.04 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005548
  validation loss:		0.429486
  validation accuracy:		93.04 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005312
  validation loss:		0.435047
  validation accuracy:		93.15 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005420
  validation loss:		0.436492
  validation accuracy:		93.04 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005618
  validation loss:		0.430011
  validation accuracy:		93.26 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005452
  validation loss:		0.433835
  validation accuracy:		93.37 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.005435
  validation loss:		0.436063
  validation accuracy:		93.15 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.005513
  validation loss:		0.437544
  validation accuracy:		93.04 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005531
  validation loss:		0.438271
  validation accuracy:		93.04 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005377
  validation loss:		0.428857
  validation accuracy:		93.15 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005499
  validation loss:		0.428463
  validation accuracy:		93.26 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005334
  validation loss:		0.435870
  validation accuracy:		93.04 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.005386
  validation loss:		0.434330
  validation accuracy:		93.26 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.005480
  validation loss:		0.440062
  validation accuracy:		93.04 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005168
  validation loss:		0.434051
  validation accuracy:		93.15 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.005449
  validation loss:		0.437302
  validation accuracy:		93.04 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.005319
  validation loss:		0.431097
  validation accuracy:		93.15 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.005356
  validation loss:		0.435127
  validation accuracy:		93.15 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.005244
  validation loss:		0.440191
  validation accuracy:		93.04 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005329
  validation loss:		0.436038
  validation accuracy:		93.15 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005355
  validation loss:		0.429750
  validation accuracy:		93.37 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005304
  validation loss:		0.437434
  validation accuracy:		93.26 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005415
  validation loss:		0.435426
  validation accuracy:		92.93 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005079
  validation loss:		0.435053
  validation accuracy:		93.15 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.005161
  validation loss:		0.438047
  validation accuracy:		93.15 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.005183
  validation loss:		0.439275
  validation accuracy:		93.26 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005002
  validation loss:		0.432156
  validation accuracy:		93.15 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005130
  validation loss:		0.439760
  validation accuracy:		93.04 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.005124
  validation loss:		0.436032
  validation accuracy:		93.15 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005190
  validation loss:		0.437894
  validation accuracy:		92.93 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.005281
  validation loss:		0.441999
  validation accuracy:		93.15 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005201
  validation loss:		0.439437
  validation accuracy:		93.15 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.005343
  validation loss:		0.438010
  validation accuracy:		93.04 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.005205
  validation loss:		0.439364
  validation accuracy:		93.15 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005136
  validation loss:		0.438746
  validation accuracy:		93.26 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.005261
  validation loss:		0.432789
  validation accuracy:		93.15 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.005223
  validation loss:		0.438482
  validation accuracy:		93.15 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005250
  validation loss:		0.442390
  validation accuracy:		93.15 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.005203
  validation loss:		0.440217
  validation accuracy:		93.15 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005108
  validation loss:		0.438415
  validation accuracy:		93.26 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.005167
  validation loss:		0.434630
  validation accuracy:		93.15 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005235
  validation loss:		0.439490
  validation accuracy:		93.26 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.005100
  validation loss:		0.437526
  validation accuracy:		93.26 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.005177
  validation loss:		0.444583
  validation accuracy:		93.15 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.005095
  validation loss:		0.435679
  validation accuracy:		93.26 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.005274
  validation loss:		0.440318
  validation accuracy:		93.26 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.005240
  validation loss:		0.439056
  validation accuracy:		93.04 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.005315
  validation loss:		0.448109
  validation accuracy:		93.04 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.005107
  validation loss:		0.436178
  validation accuracy:		93.15 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004941
  validation loss:		0.447597
  validation accuracy:		93.04 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005174
  validation loss:		0.442536
  validation accuracy:		93.04 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.005031
  validation loss:		0.439075
  validation accuracy:		93.15 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004886
  validation loss:		0.443203
  validation accuracy:		92.93 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.005064
  validation loss:		0.441743
  validation accuracy:		93.15 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005084
  validation loss:		0.437427
  validation accuracy:		93.15 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004975
  validation loss:		0.439608
  validation accuracy:		93.15 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.005038
  validation loss:		0.445953
  validation accuracy:		93.15 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.005035
  validation loss:		0.435750
  validation accuracy:		93.26 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.005066
  validation loss:		0.440038
  validation accuracy:		93.26 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004927
  validation loss:		0.444277
  validation accuracy:		93.15 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004995
  validation loss:		0.439283
  validation accuracy:		93.15 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005005
  validation loss:		0.445872
  validation accuracy:		93.15 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004857
  validation loss:		0.444141
  validation accuracy:		93.15 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004887
  validation loss:		0.442444
  validation accuracy:		93.15 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004946
  validation loss:		0.440471
  validation accuracy:		93.26 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.005039
  validation loss:		0.450172
  validation accuracy:		92.83 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004982
  validation loss:		0.437611
  validation accuracy:		93.15 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004825
  validation loss:		0.450184
  validation accuracy:		93.04 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004835
  validation loss:		0.441447
  validation accuracy:		93.26 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004916
  validation loss:		0.445637
  validation accuracy:		92.93 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004773
  validation loss:		0.441475
  validation accuracy:		93.26 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005038
  validation loss:		0.447007
  validation accuracy:		92.93 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004920
  validation loss:		0.443292
  validation accuracy:		93.04 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004807
  validation loss:		0.442166
  validation accuracy:		93.26 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004788
  validation loss:		0.448395
  validation accuracy:		93.15 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004829
  validation loss:		0.440319
  validation accuracy:		93.15 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004856
  validation loss:		0.443355
  validation accuracy:		93.26 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004796
  validation loss:		0.444133
  validation accuracy:		93.15 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004736
  validation loss:		0.445070
  validation accuracy:		93.26 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004787
  validation loss:		0.442882
  validation accuracy:		93.26 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004819
  validation loss:		0.446576
  validation accuracy:		92.93 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004730
  validation loss:		0.441938
  validation accuracy:		93.26 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004905
  validation loss:		0.447283
  validation accuracy:		93.04 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004697
  validation loss:		0.441640
  validation accuracy:		93.37 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004753
  validation loss:		0.444105
  validation accuracy:		93.26 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004682
  validation loss:		0.441787
  validation accuracy:		93.15 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004873
  validation loss:		0.444164
  validation accuracy:		93.37 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004900
  validation loss:		0.446576
  validation accuracy:		93.04 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004627
  validation loss:		0.443152
  validation accuracy:		93.04 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.446200
  validation accuracy:		93.37 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004663
  validation loss:		0.444679
  validation accuracy:		93.26 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004814
  validation loss:		0.446855
  validation accuracy:		93.26 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004724
  validation loss:		0.446240
  validation accuracy:		93.15 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004615
  validation loss:		0.441649
  validation accuracy:		93.15 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004698
  validation loss:		0.454866
  validation accuracy:		93.04 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004746
  validation loss:		0.443209
  validation accuracy:		93.15 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004849
  validation loss:		0.442842
  validation accuracy:		93.26 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004673
  validation loss:		0.449074
  validation accuracy:		93.26 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004711
  validation loss:		0.447590
  validation accuracy:		93.04 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004769
  validation loss:		0.449091
  validation accuracy:		93.37 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004678
  validation loss:		0.450378
  validation accuracy:		93.15 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004690
  validation loss:		0.446386
  validation accuracy:		93.26 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004539
  validation loss:		0.446106
  validation accuracy:		93.37 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004558
  validation loss:		0.448309
  validation accuracy:		93.26 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004659
  validation loss:		0.448586
  validation accuracy:		93.15 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004637
  validation loss:		0.446084
  validation accuracy:		93.15 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004663
  validation loss:		0.451347
  validation accuracy:		93.26 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004723
  validation loss:		0.449609
  validation accuracy:		93.26 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004496
  validation loss:		0.448791
  validation accuracy:		93.15 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004742
  validation loss:		0.448464
  validation accuracy:		93.26 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004588
  validation loss:		0.450124
  validation accuracy:		93.26 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004714
  validation loss:		0.449461
  validation accuracy:		93.15 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004739
  validation loss:		0.454076
  validation accuracy:		93.04 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004562
  validation loss:		0.450300
  validation accuracy:		93.26 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004553
  validation loss:		0.445102
  validation accuracy:		93.04 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004419
  validation loss:		0.450291
  validation accuracy:		93.26 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004452
  validation loss:		0.452820
  validation accuracy:		92.93 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004685
  validation loss:		0.454300
  validation accuracy:		93.26 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004590
  validation loss:		0.449664
  validation accuracy:		93.26 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004526
  validation loss:		0.452955
  validation accuracy:		92.93 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004574
  validation loss:		0.451063
  validation accuracy:		93.04 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004603
  validation loss:		0.449630
  validation accuracy:		93.15 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004548
  validation loss:		0.450743
  validation accuracy:		93.37 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004407
  validation loss:		0.450022
  validation accuracy:		93.04 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004358
  validation loss:		0.453259
  validation accuracy:		93.37 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004518
  validation loss:		0.454574
  validation accuracy:		93.15 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004539
  validation loss:		0.450035
  validation accuracy:		93.15 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004418
  validation loss:		0.451146
  validation accuracy:		93.15 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004343
  validation loss:		0.450507
  validation accuracy:		93.37 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004528
  validation loss:		0.450037
  validation accuracy:		93.04 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004479
  validation loss:		0.451339
  validation accuracy:		93.04 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004498
  validation loss:		0.452759
  validation accuracy:		93.15 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004527
  validation loss:		0.454766
  validation accuracy:		93.15 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004479
  validation loss:		0.455429
  validation accuracy:		93.04 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004454
  validation loss:		0.451075
  validation accuracy:		93.15 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004501
  validation loss:		0.452883
  validation accuracy:		93.26 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004564
  validation loss:		0.455828
  validation accuracy:		93.04 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004446
  validation loss:		0.450196
  validation accuracy:		93.15 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004510
  validation loss:		0.454523
  validation accuracy:		93.04 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004544
  validation loss:		0.452520
  validation accuracy:		93.37 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004453
  validation loss:		0.449826
  validation accuracy:		93.26 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004463
  validation loss:		0.455538
  validation accuracy:		92.93 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.453249
  validation accuracy:		93.15 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004473
  validation loss:		0.453795
  validation accuracy:		93.04 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004475
  validation loss:		0.450760
  validation accuracy:		93.04 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004399
  validation loss:		0.453088
  validation accuracy:		93.26 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.450939
  validation accuracy:		93.04 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004421
  validation loss:		0.456600
  validation accuracy:		93.26 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004275
  validation loss:		0.454349
  validation accuracy:		93.26 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.456389
  validation accuracy:		93.04 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004329
  validation loss:		0.454360
  validation accuracy:		93.15 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004399
  validation loss:		0.456962
  validation accuracy:		93.15 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004363
  validation loss:		0.453380
  validation accuracy:		93.26 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004343
  validation loss:		0.456909
  validation accuracy:		93.15 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.457732
  validation accuracy:		93.26 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004404
  validation loss:		0.454350
  validation accuracy:		93.15 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004434
  validation loss:		0.452190
  validation accuracy:		93.26 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004426
  validation loss:		0.456698
  validation accuracy:		93.04 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004185
  validation loss:		0.454562
  validation accuracy:		93.15 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004362
  validation loss:		0.455646
  validation accuracy:		93.26 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004263
  validation loss:		0.457651
  validation accuracy:		93.26 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004315
  validation loss:		0.453297
  validation accuracy:		93.26 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004451
  validation loss:		0.459910
  validation accuracy:		93.37 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.004163
  validation loss:		0.455789
  validation accuracy:		93.04 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004335
  validation loss:		0.456007
  validation accuracy:		93.26 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004338
  validation loss:		0.457688
  validation accuracy:		93.37 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004289
  validation loss:		0.454889
  validation accuracy:		93.37 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004216
  validation loss:		0.456222
  validation accuracy:		93.15 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004213
  validation loss:		0.454805
  validation accuracy:		93.37 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004261
  validation loss:		0.458103
  validation accuracy:		93.48 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004132
  validation loss:		0.461285
  validation accuracy:		93.15 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004251
  validation loss:		0.453579
  validation accuracy:		93.15 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004359
  validation loss:		0.453303
  validation accuracy:		93.48 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004370
  validation loss:		0.461092
  validation accuracy:		93.26 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.004148
  validation loss:		0.459467
  validation accuracy:		93.37 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004227
  validation loss:		0.459262
  validation accuracy:		93.04 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004093
  validation loss:		0.458645
  validation accuracy:		93.26 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.004353
  validation loss:		0.457716
  validation accuracy:		93.26 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.461036
  validation accuracy:		93.26 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.004314
  validation loss:		0.460179
  validation accuracy:		93.04 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004237
  validation loss:		0.453712
  validation accuracy:		93.26 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.004384
  validation loss:		0.460835
  validation accuracy:		92.93 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.004141
  validation loss:		0.460161
  validation accuracy:		93.15 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004224
  validation loss:		0.460398
  validation accuracy:		93.04 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.004131
  validation loss:		0.457537
  validation accuracy:		93.26 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.004174
  validation loss:		0.463376
  validation accuracy:		92.93 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.004177
  validation loss:		0.460110
  validation accuracy:		93.04 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.004112
  validation loss:		0.460179
  validation accuracy:		92.93 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004140
  validation loss:		0.461730
  validation accuracy:		93.15 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.004004
  validation loss:		0.456854
  validation accuracy:		93.26 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.004160
  validation loss:		0.460291
  validation accuracy:		93.15 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.004124
  validation loss:		0.463104
  validation accuracy:		93.04 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003942
  validation loss:		0.460183
  validation accuracy:		93.15 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.004104
  validation loss:		0.462755
  validation accuracy:		93.26 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.004143
  validation loss:		0.460178
  validation accuracy:		93.48 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003993
  validation loss:		0.465077
  validation accuracy:		93.15 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003994
  validation loss:		0.461949
  validation accuracy:		93.26 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.460549
  validation accuracy:		93.26 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003973
  validation loss:		0.461373
  validation accuracy:		93.26 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.004143
  validation loss:		0.462936
  validation accuracy:		93.26 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.457546
  validation accuracy:		93.15 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.004002
  validation loss:		0.461382
  validation accuracy:		93.26 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003986
  validation loss:		0.464510
  validation accuracy:		93.15 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.004005
  validation loss:		0.458031
  validation accuracy:		93.26 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.004046
  validation loss:		0.464683
  validation accuracy:		93.15 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.461634
  validation accuracy:		93.26 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.004126
  validation loss:		0.464391
  validation accuracy:		93.04 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.004200
  validation loss:		0.462096
  validation accuracy:		93.37 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.004101
  validation loss:		0.462064
  validation accuracy:		93.48 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.004014
  validation loss:		0.463944
  validation accuracy:		92.93 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.004120
  validation loss:		0.464999
  validation accuracy:		93.26 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.004084
  validation loss:		0.466924
  validation accuracy:		93.26 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.004023
  validation loss:		0.462652
  validation accuracy:		93.04 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003957
  validation loss:		0.465278
  validation accuracy:		93.26 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.004053
  validation loss:		0.461229
  validation accuracy:		93.15 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.004102
  validation loss:		0.467579
  validation accuracy:		93.04 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.004095
  validation loss:		0.465318
  validation accuracy:		93.26 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003934
  validation loss:		0.462619
  validation accuracy:		93.15 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003964
  validation loss:		0.466591
  validation accuracy:		93.15 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003937
  validation loss:		0.466881
  validation accuracy:		93.04 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003901
  validation loss:		0.463072
  validation accuracy:		93.26 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003995
  validation loss:		0.462137
  validation accuracy:		93.04 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.004063
  validation loss:		0.465129
  validation accuracy:		93.26 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003978
  validation loss:		0.464323
  validation accuracy:		93.15 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003972
  validation loss:		0.464779
  validation accuracy:		93.04 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003915
  validation loss:		0.461103
  validation accuracy:		93.26 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003963
  validation loss:		0.464714
  validation accuracy:		93.26 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003973
  validation loss:		0.463511
  validation accuracy:		93.15 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003839
  validation loss:		0.465471
  validation accuracy:		93.26 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003801
  validation loss:		0.468213
  validation accuracy:		93.26 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003961
  validation loss:		0.466538
  validation accuracy:		93.26 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003868
  validation loss:		0.465973
  validation accuracy:		93.26 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.004042
  validation loss:		0.465557
  validation accuracy:		93.26 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003752
  validation loss:		0.465263
  validation accuracy:		93.26 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.004024
  validation loss:		0.465288
  validation accuracy:		93.15 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003913
  validation loss:		0.462346
  validation accuracy:		93.48 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003736
  validation loss:		0.467051
  validation accuracy:		93.26 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003716
  validation loss:		0.465871
  validation accuracy:		93.15 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003958
  validation loss:		0.466024
  validation accuracy:		93.26 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003857
  validation loss:		0.464972
  validation accuracy:		93.15 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003878
  validation loss:		0.469357
  validation accuracy:		93.15 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003808
  validation loss:		0.465178
  validation accuracy:		93.26 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.469750
  validation accuracy:		92.93 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003779
  validation loss:		0.465404
  validation accuracy:		93.04 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003781
  validation loss:		0.473504
  validation accuracy:		93.26 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003875
  validation loss:		0.462647
  validation accuracy:		93.26 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003828
  validation loss:		0.470892
  validation accuracy:		93.15 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003840
  validation loss:		0.469993
  validation accuracy:		93.15 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003794
  validation loss:		0.468422
  validation accuracy:		93.26 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003996
  validation loss:		0.466043
  validation accuracy:		93.26 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003688
  validation loss:		0.468332
  validation accuracy:		93.15 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003796
  validation loss:		0.466251
  validation accuracy:		93.26 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003869
  validation loss:		0.472196
  validation accuracy:		93.26 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003782
  validation loss:		0.470883
  validation accuracy:		93.26 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003853
  validation loss:		0.466716
  validation accuracy:		93.26 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.466944
  validation accuracy:		93.26 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003873
  validation loss:		0.468542
  validation accuracy:		93.26 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003733
  validation loss:		0.468011
  validation accuracy:		93.15 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003839
  validation loss:		0.465409
  validation accuracy:		93.26 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.471990
  validation accuracy:		93.15 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003816
  validation loss:		0.468232
  validation accuracy:		93.37 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003797
  validation loss:		0.468665
  validation accuracy:		93.37 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003816
  validation loss:		0.468042
  validation accuracy:		93.26 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003791
  validation loss:		0.469718
  validation accuracy:		93.15 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.472685
  validation accuracy:		93.26 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003683
  validation loss:		0.472221
  validation accuracy:		93.26 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003784
  validation loss:		0.470160
  validation accuracy:		93.26 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003811
  validation loss:		0.470138
  validation accuracy:		93.15 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003801
  validation loss:		0.470492
  validation accuracy:		93.04 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003696
  validation loss:		0.471117
  validation accuracy:		93.15 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003876
  validation loss:		0.470874
  validation accuracy:		93.37 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003732
  validation loss:		0.468524
  validation accuracy:		93.26 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.475657
  validation accuracy:		93.15 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003465
  validation loss:		0.470230
  validation accuracy:		93.15 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003660
  validation loss:		0.470814
  validation accuracy:		93.26 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.471362
  validation accuracy:		93.26 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003655
  validation loss:		0.473489
  validation accuracy:		93.15 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003736
  validation loss:		0.472124
  validation accuracy:		93.26 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003762
  validation loss:		0.475151
  validation accuracy:		93.04 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003630
  validation loss:		0.473621
  validation accuracy:		93.26 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003611
  validation loss:		0.468099
  validation accuracy:		93.26 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003822
  validation loss:		0.471448
  validation accuracy:		93.26 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.471398
  validation accuracy:		93.15 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003736
  validation loss:		0.468479
  validation accuracy:		93.26 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003637
  validation loss:		0.471026
  validation accuracy:		93.26 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003723
  validation loss:		0.473828
  validation accuracy:		93.26 %
Epoch 1935 of 2000 took 0.036s
  training loss:		0.003620
  validation loss:		0.476296
  validation accuracy:		93.26 %
Epoch 1936 of 2000 took 0.037s
  training loss:		0.003597
  validation loss:		0.472769
  validation accuracy:		93.26 %
Epoch 1937 of 2000 took 0.036s
  training loss:		0.003646
  validation loss:		0.474426
  validation accuracy:		92.93 %
Epoch 1938 of 2000 took 0.036s
  training loss:		0.003491
  validation loss:		0.472072
  validation accuracy:		93.37 %
Epoch 1939 of 2000 took 0.036s
  training loss:		0.003593
  validation loss:		0.474339
  validation accuracy:		93.26 %
Epoch 1940 of 2000 took 0.037s
  training loss:		0.003622
  validation loss:		0.473982
  validation accuracy:		93.15 %
Epoch 1941 of 2000 took 0.036s
  training loss:		0.003740
  validation loss:		0.474165
  validation accuracy:		93.15 %
Epoch 1942 of 2000 took 0.036s
  training loss:		0.003625
  validation loss:		0.473608
  validation accuracy:		93.04 %
Epoch 1943 of 2000 took 0.036s
  training loss:		0.003636
  validation loss:		0.473818
  validation accuracy:		93.15 %
Epoch 1944 of 2000 took 0.036s
  training loss:		0.003488
  validation loss:		0.477391
  validation accuracy:		93.26 %
Epoch 1945 of 2000 took 0.036s
  training loss:		0.003648
  validation loss:		0.473213
  validation accuracy:		93.04 %
Epoch 1946 of 2000 took 0.036s
  training loss:		0.003388
  validation loss:		0.470953
  validation accuracy:		93.26 %
Epoch 1947 of 2000 took 0.036s
  training loss:		0.003562
  validation loss:		0.475105
  validation accuracy:		93.15 %
Epoch 1948 of 2000 took 0.036s
  training loss:		0.003498
  validation loss:		0.474613
  validation accuracy:		93.26 %
Epoch 1949 of 2000 took 0.036s
  training loss:		0.003639
  validation loss:		0.477202
  validation accuracy:		93.15 %
Epoch 1950 of 2000 took 0.036s
  training loss:		0.003686
  validation loss:		0.476825
  validation accuracy:		93.04 %
Epoch 1951 of 2000 took 0.036s
  training loss:		0.003448
  validation loss:		0.476211
  validation accuracy:		93.26 %
Epoch 1952 of 2000 took 0.036s
  training loss:		0.003633
  validation loss:		0.472618
  validation accuracy:		93.04 %
Epoch 1953 of 2000 took 0.036s
  training loss:		0.003636
  validation loss:		0.473503
  validation accuracy:		93.26 %
Epoch 1954 of 2000 took 0.036s
  training loss:		0.003447
  validation loss:		0.473939
  validation accuracy:		93.15 %
Epoch 1955 of 2000 took 0.036s
  training loss:		0.003473
  validation loss:		0.474626
  validation accuracy:		93.26 %
Epoch 1956 of 2000 took 0.036s
  training loss:		0.003613
  validation loss:		0.475866
  validation accuracy:		93.26 %
Epoch 1957 of 2000 took 0.036s
  training loss:		0.003593
  validation loss:		0.476343
  validation accuracy:		93.26 %
Epoch 1958 of 2000 took 0.036s
  training loss:		0.003494
  validation loss:		0.474702
  validation accuracy:		93.26 %
Epoch 1959 of 2000 took 0.036s
  training loss:		0.003469
  validation loss:		0.475648
  validation accuracy:		93.15 %
Epoch 1960 of 2000 took 0.036s
  training loss:		0.003502
  validation loss:		0.475089
  validation accuracy:		93.26 %
Epoch 1961 of 2000 took 0.036s
  training loss:		0.003597
  validation loss:		0.474351
  validation accuracy:		93.26 %
Epoch 1962 of 2000 took 0.037s
  training loss:		0.003555
  validation loss:		0.477638
  validation accuracy:		93.15 %
Epoch 1963 of 2000 took 0.036s
  training loss:		0.003441
  validation loss:		0.474927
  validation accuracy:		93.26 %
Epoch 1964 of 2000 took 0.036s
  training loss:		0.003490
  validation loss:		0.484258
  validation accuracy:		92.83 %
Epoch 1965 of 2000 took 0.036s
  training loss:		0.003608
  validation loss:		0.473034
  validation accuracy:		93.15 %
Epoch 1966 of 2000 took 0.036s
  training loss:		0.003593
  validation loss:		0.479729
  validation accuracy:		92.93 %
Epoch 1967 of 2000 took 0.036s
  training loss:		0.003476
  validation loss:		0.474932
  validation accuracy:		93.15 %
Epoch 1968 of 2000 took 0.036s
  training loss:		0.003459
  validation loss:		0.476687
  validation accuracy:		93.26 %
Epoch 1969 of 2000 took 0.036s
  training loss:		0.003464
  validation loss:		0.476937
  validation accuracy:		93.37 %
Epoch 1970 of 2000 took 0.036s
  training loss:		0.003423
  validation loss:		0.474298
  validation accuracy:		93.26 %
Epoch 1971 of 2000 took 0.036s
  training loss:		0.003509
  validation loss:		0.474895
  validation accuracy:		93.15 %
Epoch 1972 of 2000 took 0.036s
  training loss:		0.003509
  validation loss:		0.478468
  validation accuracy:		93.26 %
Epoch 1973 of 2000 took 0.036s
  training loss:		0.003430
  validation loss:		0.475952
  validation accuracy:		93.04 %
Epoch 1974 of 2000 took 0.036s
  training loss:		0.003452
  validation loss:		0.477553
  validation accuracy:		93.26 %
Epoch 1975 of 2000 took 0.036s
  training loss:		0.003468
  validation loss:		0.478507
  validation accuracy:		93.26 %
Epoch 1976 of 2000 took 0.036s
  training loss:		0.003581
  validation loss:		0.478565
  validation accuracy:		93.15 %
Epoch 1977 of 2000 took 0.036s
  training loss:		0.003413
  validation loss:		0.473583
  validation accuracy:		93.15 %
Epoch 1978 of 2000 took 0.036s
  training loss:		0.003530
  validation loss:		0.479499
  validation accuracy:		93.26 %
Epoch 1979 of 2000 took 0.036s
  training loss:		0.003329
  validation loss:		0.479289
  validation accuracy:		93.26 %
Epoch 1980 of 2000 took 0.036s
  training loss:		0.003509
  validation loss:		0.476720
  validation accuracy:		93.26 %
Epoch 1981 of 2000 took 0.036s
  training loss:		0.003413
  validation loss:		0.481761
  validation accuracy:		93.26 %
Epoch 1982 of 2000 took 0.036s
  training loss:		0.003480
  validation loss:		0.477727
  validation accuracy:		93.37 %
Epoch 1983 of 2000 took 0.036s
  training loss:		0.003324
  validation loss:		0.479852
  validation accuracy:		93.26 %
Epoch 1984 of 2000 took 0.036s
  training loss:		0.003429
  validation loss:		0.479624
  validation accuracy:		93.26 %
Epoch 1985 of 2000 took 0.036s
  training loss:		0.003487
  validation loss:		0.477147
  validation accuracy:		93.26 %
Epoch 1986 of 2000 took 0.036s
  training loss:		0.003443
  validation loss:		0.479559
  validation accuracy:		93.26 %
Epoch 1987 of 2000 took 0.036s
  training loss:		0.003458
  validation loss:		0.478057
  validation accuracy:		93.15 %
Epoch 1988 of 2000 took 0.036s
  training loss:		0.003419
  validation loss:		0.480285
  validation accuracy:		93.26 %
Epoch 1989 of 2000 took 0.036s
  training loss:		0.003433
  validation loss:		0.483149
  validation accuracy:		93.26 %
Epoch 1990 of 2000 took 0.036s
  training loss:		0.003423
  validation loss:		0.479437
  validation accuracy:		93.26 %
Epoch 1991 of 2000 took 0.036s
  training loss:		0.003255
  validation loss:		0.476573
  validation accuracy:		93.26 %
Epoch 1992 of 2000 took 0.036s
  training loss:		0.003430
  validation loss:		0.481423
  validation accuracy:		93.15 %
Epoch 1993 of 2000 took 0.036s
  training loss:		0.003381
  validation loss:		0.475374
  validation accuracy:		93.26 %
Epoch 1994 of 2000 took 0.036s
  training loss:		0.003485
  validation loss:		0.479488
  validation accuracy:		93.26 %
Epoch 1995 of 2000 took 0.036s
  training loss:		0.003323
  validation loss:		0.482422
  validation accuracy:		93.26 %
Epoch 1996 of 2000 took 0.036s
  training loss:		0.003384
  validation loss:		0.481454
  validation accuracy:		93.15 %
Epoch 1997 of 2000 took 0.036s
  training loss:		0.003349
  validation loss:		0.480584
  validation accuracy:		93.15 %
Epoch 1998 of 2000 took 0.036s
  training loss:		0.003330
  validation loss:		0.482822
  validation accuracy:		93.26 %
Epoch 1999 of 2000 took 0.036s
  training loss:		0.003381
  validation loss:		0.482142
  validation accuracy:		93.26 %
Epoch 2000 of 2000 took 0.036s
  training loss:		0.003403
  validation loss:		0.481882
  validation accuracy:		93.15 %
Final results:
  test loss:			1.230989
  test accuracy:		84.29 %
